{"title": "RT-DEMT: A hybrid real-time acupoint detection\nmodel combining mamba and transformer", "authors": ["Shilong Yang", "Qi Zang", "Chulong Zhang", "Lingfeng Huang", "Yaoqin Xie"], "abstract": "Abstract-Traditional Chinese acupuncture methods often face\ncontroversy in clinical practice due to their high subjectivity. Ad-\nditionally, current intelligent-assisted acupuncture systems have\ntwo major limitations: slow acupoint localization speed and low\naccuracy. To address these limitations, a new method leverages\nthe excellent inference efficiency of the state-space model Mamba,\nwhile retaining the advantages of the attention mechanism in the\ntraditional DETR architecture, to achieve efficient global infor-\nmation integration and provide high-quality feature information\nfor acupoint localization tasks. Furthermore, by employing the\nconcept of residual likelihood estimation, it eliminates the need\nfor complex upsampling processes, thereby accelerating the\nacupoint localization task. Our method achieved state-of-the-art\n(SOTA) accuracy on a private dataset of acupoints on the human\nback, with an average Euclidean distance pixel error (EPE) of\n7.792 and an average time consumption of 10.05 milliseconds\nper localization task. Compared to the second-best algorithm,\nour method improved both accuracy and speed by approximately\n14%. This significant advancement not only enhances the efficacy\nof acupuncture treatment but also demonstrates the commercial\npotential of automated acupuncture robot systems. Access to our\nmethod is available at https://github.com/Sohyu1/RT-DEMT", "sections": [{"title": "I. INTRODUCTION", "content": "BREAST As artificial intelligence technology advances,\nAl has increasingly intersected with numerous fields,\nparticularly aligning well with the medical domain. The con-\ntinuous growth in demand for rapid and accurate diagnostic\nand treatment services has also become a key driver in the\nadvancement of intelligent healthcare. The automation of clin-\nical tasks with robotics and artificial intelligence technology\nhas great potential in improving the accuracy, consistency, and\naccessibility of treatment [1] [2]. Intelligent acupuncture robot\nis one of the most promising development fields [3] [4] [5].\nAcupuncture is a kind of traditional Chinese medical prac-\ntice, which has been widely recognized in modern medical\ncircles for its effectiveness in relieving inflammation and pain.\nIn addition, acupuncture also shows great potential in immune\nregulation and treatment of some mental diseases [6] [7] [8]\n[9]. Related research proved the feasibility of acupuncture\nas an alternative therapy for inflammation and pain [6] [7]\n[8]. Moreover, some scholars have found that acupuncture\ncan independently mobilize the body's self-healing mechanism\nto restore the body's homeostasis, so as to effectively treat\nimmune diseases [10]. In addition, some studies tried to apply\nacupuncture in the treatment of mental diseases, such as\ndepression and Parkinson's disease, and achieved remarkable\nresults, thus expanding its scope of application [11] [9]. And\nnow many scholars tend to link acupuncture and neuroscience\nto explain the clinical applicability of acupuncture [12] [13]\n[14].\nHowever, one of the critical challenges in developing ef-\nfective acupuncture robots is the accurate localization of\nacupoints. Acupoints localization tasks are often solved using\ntechniques related to key points localization [1]. In computer\nvision field,key point detection is a core subtask within pose\nestimation, involving the identification of critical human body\nparts such as the head, shoulders, elbows, wrists, and knees.\nPose estimation is a significant research area in the field of\ncomputer vision, primarily aimed at identifying various human\nbody parts from images or videos and accurately estimating\ntheir spatial positions and orientations. However, there are\nseveral different aspects between the acupoints detection field\nand point detection in CV field, which makes acupoints\ndetection more challenging. Firstly, the number of acupoints is\nmuch more than key points in the task of pose estimation.\nSecondly, due to the lack of corner points, skin texture\nfeatures, and other obvious features, the task of feature ex-\ntraction becomes difficult. This table, along with the acupoint\npositioning diagram in the upper left corner of Figure 3, clearly\noutlines the method for locating acupoints based on the human\nskeltal structure. The relative positions of acupoints vary\nwith different skeletal forms, adding complexity to intelligent\nacupoint localization tasks. More precise location standards\nwill further advance posture estimation solutions. And, in the\ndescription of localization methods, the unit \"cun\" can be\ndynamically defined as a fraction of the distance between\ncertain parts of the patient's own body, and used as a unit for\nmeasuring acupoint locations. There are two main methods\nfor determining this: the bone proportional measurement and\nthe finger cun method. In traditional Chinese medicine clinical\npractice, the latter is more commonly used due to the difficulty\nof conveniently obtaining the distance between the patient's\nbones and joints [15] [16].\nThe initial pose estimation tasks are often solved using\ntraditional image processing techniques, such as edge detection\nand shape matching. With the emergence of deep learning\ntechniques such as convolution networks and transform net-\nworks, and their continuous application in pose estimation\ntasks [17] [18] [19] [20] [21] [22]. Now pose estimation tasks\nhas evolved into two main methods: top-down and bottom-up\napproaches. The top-down approach requires first detecting"}, {"title": "METHOD", "content": "the bounding boxes of all targets, and then detecting the\nkey points within these boxes. This method usually provides\nhigher accuracy, but it is slower and prone to errors such as\nmissed detection and false detection in bounding box detection\n[23], [24], [25]. On the contrary, the bottom-up approach first\ndetects all key points and then assembles them into human\nbody shapes, sacrificing some accuracy to improve processing\nspeed [26], [27].\nThere are two approaches for identifying and locating key\npoints: Registration-based and Detection-based. The registra-\ntion based key points recognition and localization method\nfirst aligns the same structures in different images into a\ncommon coordinate framework, and then matches and locates\nkey points based on registration knowledge. This method first\nrequires a predefined model that defines the structure and\nrelative positions of key points. The purpose of registration is\nto minimize the error between template key points and their\ncorresponding positions in the image [28], [29], [30], [31].\nKey point recognition and localization based on detection first\nutilizes the feature extraction capability of object detection\nnetworks to extract image features, which are then output as\nkey point coordinates through the classification header at the\nend of the network [26], [32], [33]. The classification header\nis often divided into three technical routes: Regression-Based\n[34] [35] [36] [28], Heatmap-Based [37], and Coordinate\nClassification (SimCC) [38].\nThe feature extraction capability of object detection net-\nworks determines the quality of image features and further\naffects the accuracy of the final localization task. About object\ndetection networks, YOLO, popular for its balance between\nspeed and accuracy, is negatively impacted by Non-Maximum\nSuppression (NMS) [39] [40] [41] [42] [43]. The Transformer\nbased end-to-end detector (DETR), an alternative that elimi-\nnates NMS, suffers from high computational costs [44], [45].\nRT-DETR [46], a real-time, end-to-end object detection model\nwith an efficient hybrid encoder, this decoder rapidly processes\nmulti-scale features by decoupling intra-scale interactions and\ncross-scale fusion to enhance speed. Subsequently, utilize\nuncertainty-minimized query selection to provide high-quality\ninitial queries for the decoder, thereby improving accuracy.\nHowever, the image features downsampled by CNN inherently\nlose some precision and global information. When these\ntruncated features are fed into a transformer architecture, they\nlargely fail to fully unleash the potential of the global receptive\nfield offered by the attention mechanism. Consequently, it is\nquite natural for us to embed Mamba into the network as the\nvision backbone, replacing the original CNN, to achieve the\ncapability of extracting image features with linear complexity\nwithout sacrificing the global receptive field.\nFor classification header, in the Regression-based approach,\nall key points share the same feature, and the calculation\nof all key points is completed simultaneously, so the speed\nis faster than other methods, but the accuracy is often rela-\ntively low and overfitting is prone to occur during training\n[34] [35] [36] [28]. The Heatmap-based approach generates\ncorresponding Gaussian heatmaps through features, performs\nfeature matching in the spatial dimension, and focuses more on\nand utilizes local features. Each key points are independently\ncalculated. However, generating heatmaps through upsampling\ninevitably introduces quantization errors and requires a signif-\nicant amount of computational resources [37]. The coordinate\nclassification method (SimCC) combines the first two meth-\nods and reconstructs the key points localization task into a\nregression task on the horizontal and vertical axes, reducing\ncomputational complexity and eliminating quantization errors\nwhile maintaining accuracy [38]. Recent work introduction\nof residual likelihood estimation into coordinate regression\ntasks has achieved significant success, making regression\nbased methods surpass heatmap based methods in accuracy\nfor the first time [36]. residual likelihood estimation is a\nstatistical method used to estimate parameters of a model by\nfocusing on the residuals, which are the differences between\nobserved values and the values predicted by the model. This\napproach often involves maximizing the likelihood function\nof the residuals, assuming they follow a certain probability\ndistribution. It is particularly useful in models where the"}, {"title": "METHOD", "content": "residuals are assumed to be normally distributed and can\nprovide more robust parameter estimates in the presence of\nmodel misspecification or outliers. In pose estimation, residual\nlikelihood estimation offers significant benefits by enhancing\nrobustness to noise, improving accuracy, and ensuring sta-\ntistical efficiency. It allows for better model validation and\nflexibility in handling complex error structures, ultimately\nleading to enhanced predictive performance. Recent work in-\nnovatively bypasses Gaussian heatmaps and directly calculates\napproximate maximum response points from feature maps,\nbreaking down the barriers between regression based and\nheatmap based methods and enabling the model to make direct\nregression predictions on coordinate values [35]. Differentiable\nSpatial to Numerical Transform (DSNT) is a technique used in\ncomputer vision, particularly in the context of pose estimation.\nIt provides a way to convert spatial heatmaps into precise\nnumerical coordinates in a differentiable manner, which is\nessential for end-to-end training of neural networks. The key\nidea behind DSNT is to use a soft-argmax operation to obtain\nthe coordinates of key points from heatmaps, allowing the\ngradients to flow through the entire network during back-\npropagation. DSNT offers several advantages in pose esti-\nmation: it is fully differentiable, enabling end-to-end train-\ning within neural networks; it converts heatmaps to precise\nnumerical coordinates, essential for high-accuracy tasks; it\nensures smooth gradients through the soft-argmax operation,\nfacilitating stable and efficient training; it is robust to noisy\nheatmaps by considering the entire distribution rather than just\npeak values; and it is easily integrable with various network\narchitectures and heatmap-based keypoint detection methods.\nThus, DSNT is a valuable tool for precise and robust keypoint\nlocalization in pose estimation.\nMamba [47] [48] is a novel architecture based on the\nstate space model designed to address the limitations of\ntraditional transformer models [49] in handling long sequences\nefficiently. The state space model consists of two main equa-\ntions: the state equation and the observation equation. This\nequation describes how the state of the system evolves over\ntime. Mamba integrates selective state space models (SSMs)\n[50]with hardware-aware algorithms, enabling linear-time se-\nquence modeling without sacrificing performance on dense\nmodalities like language, audio, and genomics. Observation\nequation describes how the observations (or measurements) are\nrelated to the state of the system. Mamba replaces the attention\nmechanism found in transformers with a simplified struc-\nture that combines SSMs with multi-layer perceptron (MLP)\nblocks. Mamba's design ensures smooth scaling with model\nsize, maintaining high pretraining quality and downstream\nperformance across various tasks and datasets. By leverag-\ning techniques like kernel fusion and recomputation, Mamba\nminimizes memory usage, aligning with the requirements of\nmodern hardware accelerators like GPUs.Mamba addresses the\npain points of SSM through three optimizations: discretized\nSSM, cyclic/convolutional representation, and HiPPO-based\nlong sequence processing [51] [52]. Initially, it employs zero-\norder hold techniques for continuous representation and sam-\npling. When Mamba receives a discrete signal, it retains its\nvalue until a new discrete signal is received, thereby creating\na continuous signal usable by SSM. This retention period is\ndetermined by a learnable parameter, the step size (siz), which\nrepresents the resolution of the input's phase hold. With the\ncontinuous input signal, continuous output can be generated,\nand values are sampled based solely on the input's step size.\nMamba can be represented in the form of a convolution,\nallowing for parallel training similar to Convolutional Neural\nNetworks (CNNs). However, due to the fixed size of convolu-\ntion kernels, their inference is not as fast as that of Recurrent\nNeural Networks (RNNs). Consequently, Mamba employs a\nstrategy of using an RNN structure for inference and a CNN\nstructure for training, significantly enhancing inference speed.\nRecent studies have found that combining Mamba [47]\n[48] and Transformer modules [49] yields significantly better\nresults than using each individually [53] [54] [55]. This is be-\ncause the integration of Mamba's long-sequence processing ca-\npability with the Transformer's modeling ability can markedly\nenhance computational efficiency and model performance.\nOur work focuses on the clinical pain points of acupuncture:\nprecision and speed. We combined mamba and transformer\nto build a real-time and accurate acupoints recognition and\npositioning network. Our primary contribution include:\n\u2022 We leverage the excellent long-sequence processing ca-\npability and inference efficiency of the state space model\nMamba, while retaining the global modeling advantages\nof the attention mechanism in the traditional DETR\narchitecture, to achieve efficient global information in-\ngration. This integration significantly enhances compu-\ntational efficiency and model performance while reducing\nthe number of parameters.\n\u2022 Our model achieved state-of-the-art accuracy and de-\ntection rate on our proprietary human back acupoint\ndetection dataset.\n\u2022 Our network architecture fully leverages the advantages\nof the state space model Mamba, which can be approxi-\nmated as an RNN during inference, significantly reducing\nthe model's runtime. Additionally, the classification head\nin the network bypasses the upsampling operation in\nthe keypoint localization step. By employing a residual\nlikelihood estimation approach, the model enhances speed\nwhile maintaining accuracy."}, {"title": "METHOD", "content": "Our study is aimed at developing an efficient key points\ndetection network, the RT-DEMT, to address the challenges\nof speed and accuracy in acupuncture clinical settings. In\nthis section, we described our proposed RT-DEMT network\narchitecture. In the first subsection, we formalized the key\npoint detection task. In the second subsection, we provided\na detailed description of the RT-DEMT framework. In the\nthird subsection, we introduced the evaluation metrics used\nfor acupoints detection tasks."}, {"title": "A. Key Points Detection Task", "content": "The key point detection task can be viewed as a regression\nproblem, where the objective is to predict the coordinates of\nkey points in the human body in the image. Given an image I"}, {"title": "Network Structure", "content": "containing a human body, our goal is to predict the coordinates\nof N key points of the human body ((x1,y1), ..., (xN,yN)).\nWe can define a mapping function f that maps the image I\nto a 2N dimensional output vector p, where\np = [x_1, y_1, ..., x_N, y_N]^T\nThe problem of key points location can be formalized as the\nfollowing optimization problem:\nmin \\sum_{i=1}^{m} L(F(I_i), p_i)\nAmong them, m is the number of training samples, F is\na concise representation of the model, I_i is the image of\nthe i training sample, and p_i is the corresponding real key\npoint coordinate, L is the loss function used to measure the\ndifference between predicted key points and real key points.\nThe F can be represented as follow.\nF(I_i) = H(D(E_{hy}(Mamba(I_i))))\nThe first component is the Mamba section, serialize the image\nand input it into the Mamba Backbone for feature extraction,\nand get F_{py}: The size of the extracted multi-layer features\nF_{py}.i is as follows:\nFeed the extracted image features into the Efficient Hybrid\nEncoder E_{hy}, F_{ei} represents the encoded feature data. During\nthis period, image features undergo intra scale interaction for\nfeature fusion, enabling the model to better understand the re-\nlationship between the target and its surrounding environment,\nand greatly reducing information loss. The scale of F_{py} is\nconsistent with that of F_{e}..\nThe encoded data is decoded by the Decoder D and passed\nto the classification head, and get F_{di}.\nThe classification head H ultimately outputs the categories,\ncoordinates, and confidence scores of the key points required\nfor the task.\nN \\times (c_n, (x_n, y_n), s_n)_{n\\in N} = H(F_{d.i})\nwhere c_i denotes the class of the n-th key point, (x_n, y_n)\nrepresents its coordinates, s_n indicates the confidence score.\nand N is the number of detected key points..\nThe loss function L selects the mean square error (MSE)\nthat is highly consistent with the inter pixel error:\nL(p, q) = \\frac{1}{2n} \\sum_{j=1}^{2\\eta} (p^j - q^j)^2\nAmong them, p and q represent the normalized predicted\nkey points coordinates and the normalized actual key points\ncoordinates, respectively. By minimizing this loss function, we\ncan train model F to more accurately predict human key points\nin the image.\nNetwork Structure\nWe elucidate the RT-DEMT network architecture, as shown\nin Figure 1. mapping the acupoints detection task smoothly\nonto a key points detection task. Our model, built upon the"}, {"title": "Network Structure", "content": "foundation of RT-DETR, is optimized in two main aspects:\nthe feature extractor and the classification head. Following\nserialization, the input image is processed by a Mamba-based\nfeature extraction network, which extracts pyramid-structured\nfeature data enriched with high-quality global information.\nThese image features are then fed into an efficient hybrid\nencoder. This encoder employs intra-scale interaction and\ncross-scale fusion to encode the multi-scale pyramid-structured\nfeatures and utilizes an IOU querying mechanism for selection.\nThe selected features are subsequently directed to various\nclassification heads at the model's end, yielding bounding\nboxes and key points coordinates with associated confidence\nscores.\nIn terms of the feature extractor, to fully leverage the\npotential of the global receptive field offered by attention\nmechanisms, we replace the conventional CNN backbone\nwith Mamba based on state space model.This substitution\naddresses the issue of truncated features typical in CNN.\nMamba enhances the efficiency and flexibility of process-\ning sequential data through the adoption of a state-space\nmodel with time-varying parameters and the introduction of\nhardware-aware algorithms. It is naturally suited for handling\nlong sequence problems. The inherent global receptive field\nof the state-space model-based Mamba is particularly bene-\nficial in acupoints detection tasks, which often lack corner\npoints and skin texture. Studies indicate that a hybrid use of\nMamba with Transformer modules, combining Mamba's long-\nsequence processing capabilities with the modeling power of\nTransformers, significantly improves computational efficiency\nand model performance over using either alone.\nMamba backbone: The essence of Mamba is the state space\nmodel which represents a system using a set of first-order\ndifferential (or difference) equations [50] [56] [57] [58]. These\nequations describe the dynamics of the system's state variables\nand how they are influenced by inputs, outputs, and noise.\nWe definext is the state vector at time t, A is the state\ntransition matrix, ut is the control input vector at time t, B is\nthe input matrix, wt is the process noise vector, often assumed\nto be normally distributed with zero mean and covariance\nmatrix Q.\nThe state space model can be compactly represented as:\nX_{t+1} = A x_t + B u_t + W_t  y_t = Cx_t + Du_t + V_t\nThe matrices A, B, C, and D define the system dynamics\nand observation model, while wt and vt represent the process\nand observation noise, respectively. These models are widely\nused because they provide a structured way to model complex\nsystems and can be analyzed and controlled using various\nmathematical and computational techniques.\nClassification Header: Our classification header framework\nintegrates the advantages of both of the RLE and DSNT,\neliminating the upsampling process to reduce computational\nload, and introduces residual likelihood estimation to enhance\nthe accuracy of localization.\nThe high-quality feature maps extracted by the combined\nMamba and Transformer architecture directly compute an\napproximated maximum response point to obtain the distribu-\ntion of x and y coordinates. Subsequently, residual likelihood"}, {"title": "Network Structure", "content": "estimation is introduced to perform standardized regression on\nthis distribution. Not only do we bypass the upsampling step,\nsignificantly reducing the model's computational complexity,\nbut the standardization through residual likelihood estimation\nalso achieves coordinate precision comparable to heatmap-\nbased approaches.\nEfficient Hybrid Encoder: We can regard the Mamba archi-\ntecture as a specialized CNN network, which can transform\ninto an RNN during the inference process to achieve rapid\ninference. And the efficient hybrid encoder can combine\nthe strengths of convolutional neural networks (CNNs) and\nTransformer architectures to effectively capture both local and\nglobal features.\nThe hybrid feature representation combines the local fea-\ntures from the convolutional layer and the global features from\nthe Transformer encoder:\nF_{hybrid} = \\sum_{k=1}^{pl} Fusion (F_{pyramid})_k\nwhere pl is the total number of layers in the pyramid.\nThe features extracted by the Mamba architecture inherently\ncarry global information. This combination ensures that the en-\ncoder captures both local and global context more effectively.\nThe IOU selection mechanism is used to evaluate the\noverlap between predicted bounding boxes and ground truth\nbounding boxes, thereby optimizing detection performance.\nIOU (Intersection over Union) is a commonly used metric, de-\nfined as the ratio of the area of intersection to the area of union\nbetween the predicted bounding box and the ground truth\nbounding box. Specifically, assuming the predicted bounding\nbox is Bp and the ground truth bounding box is Bg, the\nIntersection over Union (IOU) can be expressed as:\nIOU(B_p, B_g) = \\frac{| B_p \\cap B_g|}{|B_p \\cup B_g|}\nwhere | B_p \\cap B_g| represents the area of the intersection\nbetween the predicted and ground truth bounding boxes, and\n|B_p\\cup B_g| represents the area of their union.\nThrough this mechanism, model can effectively evaluate and\noptimize detection results, enhancing the model's accuracy and\nrobustness."}, {"title": "B. evaluating indicator", "content": "To quantitatively assess the performance of our key points\ndetection algorithm, we employ the following evaluation met-\nrics:\n1) Euclidean-distance pixel error (EPE): The average\npixel Euclidean distance between the detected key points\nand the ground truth key points, assessing the spatial\naccuracy of the detection task.\nEPE = \\frac{1}{N} \\sum_{n=1}^N \\sqrt{(x_n - x_n^{gt})^2 + (y_n \u2013 y_n^{gt})^2}\nwhere (x_n, y_n) and (x_n^{gt}, y_n^{gt}) are the pixel coordinates\nof the detected and ground truth key points, respectively."}, {"title": "Prediction Result", "content": "2) Percentage of Correct Key points (PCK): Often used\nin human pose estimation, PCK measures the percentage\nof detected key points that fall within a specified distance\nthreshold from the true key points locations. This metric\nis adaptable to various scales by adjusting the threshold.\nHere we select threshold values of 0.05 and 0.1.\nPCK = \\frac{1}{N} \\sum_{n=1}^{N} I(\\sqrt{(x_n-x_n^{gt})^2 + (y_n \u2013 y_n^{gt})^2} \\le \\alpha \\cdot max(hwbox))\nwhere \u03b1 is a threshold parameter, h and w are the height\nand width of the bounding box or image.\n3) Average inference time and Final Throughput: The\naverage time taken by the algorithm to process an image\nand detect key points, which is crucial for real-time ap-\nplications. Final Throughput is the rate at which a model\ncan process inputs over a given period, usually measured\nin inputs per second. The relationship between average\ninference time (Tavg) and final throughput (Fthroughput)\ncan be expressed as:\nF_{throughput} = \\frac{1}{T_{avg}}\nWe can evaluate the efficiency of algorithmic reasoning\nfrom different perspectives using these two metrics.\nThese metrics collectively provide a robust framework for\nevaluating the effectiveness and efficiency of our key points\ndetection method."}, {"title": "Datasets and processing", "content": "Our experimental data is based on a privately developed\ndataset of back acupoint locations, independently created by\nour team in collaboration with traditional Chinese medicine\npractitioners from Shenzhen People's Hospital. Professional\nTCM clinicians manually annotated the 84 acupoint locations,\nwhile we assisted in the data collection process and managed\nit, ultimately preprocessing the experimental data to obtain\na reliable clinical acupoint location dataset. We recruited\nnearly 200 healthy participants with normal body types and\nno apparent spinal deformities, all of whom provided informed\nconsent."}, {"title": "RESULT", "content": "Our network outputs a set of coordinate values and con-\nfidence scores for each acupoint prediction. By setting a\nconfidence threshold, we filter the final outputs. Figure 2\nvisually demonstrates the potential of our network in the task\nof acupoints localization on the human back. In Figure 2, green\nmarkers represent the ground truth distribution of acupoints,\nred markers indicate the predicted positions by our\nnetwork.\nWe compared our network with the SOAT model on the\ntest set. We used all models to perform acupoints local-\nization tasks on the same test set, recording the Euclidean\npixel distance error (EPE) between the predicted acupoints\nposition obtained by each model and the actual position of\nthe acupoint, as well as the percentage of correctly located\nkey points (PCK) with a set reprojection error threshold of\n0.05 and 0.1, respectively. We also compared the networks\nby their parameter count, i.e., the number of parameters in\nthe neural network (measured in millions), to represent their\ncomplexity and capacity. The computational cost of a single\nforward pass is measured in floating-point operations per\nsecond (FLOPs). Additionally, the average inference time is\nthe mean time required for the network to process a single\ninput and produce an output (measured in milliseconds), while\nthe final throughput indicates the number of inferences the\nnetwork can perform per second, reflecting its efficiency and\nspeed in real-time applications. Combined analysis of these\nmetrics provides an intuitive measure of the model's real-time\nperformance.\nTable II clearly demonstrates that our network has achieved\na significant accuracy advantage while maintaining real-time\nperformance. In contrast, the YOLO series models [39] [40]\n[41] [42] [43] exhibit advantages in inference speed but\nfail to address localization accuracy issues. Furthermore, our\nmethod shows dual improvements in both accuracy and speed\ncompared to RT-DETR [46], achieving nearly 1.5 times the\naccuracy while retaining real-time capabilities. Compared to\nVitPose [61], another approach utilizing transformers in the\nvisual domain, our method also surpasses in both accuracy and\nspeed. Additionally, VitPose [61] face training difficulties due\nto their larger parameter sizes, which hinder their performance\non smaller datasets. Uniformer ranks highly in all metrics\nexcept pck0.05, indicating that the model's robustness is sub-\noptimal for tasks involving weak feature images. However, it"}, {"title": "Alation studies", "content": "still has significant advantages compared to other lightweight\nmodels like YOLO and PVT.Swin-pose [60] also exhibits a\nsimilarly low pck0.05 performance.\nAlation studies\nFeature extractor: We validated the feasibility of the\nMamba-based feature extractor backbone by comparing with\nthose of ResNet [63], HRNet [64], and MobileNetv3 [65] in\nterms of accuracy and efficiency. In the ablation experiments\nof the feature extractor, we uniformly set the classification\nhead to our proposed classification head. From table III, we\ncan observe that our method achieved an absolute advantage\nin accuracy, being the only method with an average Euclidean\npixel error of less than 10 on the test set, nearly doubling the\naccuracy of HRNet.This experiment validated that the combi-\nnation of the inherent global feature extraction capability of the\nmamba-based feature extractor and the modeling ability of the\ntransformer significantly enhances the model's performance on\nweak feature images.\nClassification Header: In the ablation experiments on clas-\nsification heads, all models only replaced the classification\nhead. We select a representative from each of the three main-\nstream classification head approaches for comparison. In table\nIV we can clearly draw the conclusion, our improved method\nmaintains the inference speed of regression-based approaches\nwhile slightly surpassing heatmap-based methods in accuracy.\nThis experiment validates that our classification head method\nachieves optimal performance in both aspects."}, {"title": "DISCUSSION", "content": "The prospect of integrating intelligence into acupuncture\npractices presents a transformative opportunity to enhance\nboth the precision and efficiency of this ancient therapeutic\nmodality. The integration of advanced technologies such as the\nMamba and Transformer-based keypoint detection networks\nsignifies a pivotal advancement in addressing the critical\nchallenges faced in clinical acupuncture, particularly in the\naccurate and swift localization of acupoints.\nAcupoint localization, a fundamental step in acupuncture,\nhas traditionally been slow and imprecise, largely due to the\nreliance on manual identification by practitioners. This process\nis complicated by the vast number of acupoints and their spe-\ncific anatomical correlations to bones, joints, and skin features.\nThe task of acupoint localization aligns with the core task\nin pose estimation: the task of keypoint recognition, sharing\na common logical framework for resolution. By leveraging\nsuch technologies, practitioners can achieve a more accurate\nmapping of acupoints, thereby enhancing treatment efficacy\nand patient outcomes.\nThe advancements in acupoints recognition tasks not only\nimprove the accuracy of acupoints localization but also con-\ntribute to the broader field of posture estimation. As these\ntechnologies evolve, they enable a more nuanced understand-\ning of human anatomy in real-time, which is crucial for both\ntargeted acupuncture treatments and various other medical\nand therapeutic applications. Moreover, in traditional pose\nestimation tasks, the selection of key points is often limited\nto a few locations such as the head, shoulders, and joints."}, {"title": "DISCUSSION", "content": "For example, the two images in the bottom left and bottom\nright of Figure 3 represent solutions in traditional pose esti-\nmation tasks. However, the abundance of acupuncture points\nsignificantly expands our options, enabling more diverse pose\nlocalization.\nIncreasing the number of reference points and enhancing\nthe precision of these points in localization schemes can\nsignificantly advance pose estimation solutions. More refer-\nence points provide a denser spatial framework, improving\nthe granularity and accuracy of the estimated pose. Stricter\nlocalization criteria ensure higher fidelity in the reference data,\nreducing errors and ambiguities in the pose estimation process.\nTogether, these improvements can lead to more robust and\nreliable pose estimation, facilitating advancements in appli-\ncations such as robotics, augmented reality, and autonomous\nnavigation.\nIn conclusion, the intelligent automation of acupoints de-\ntection through sophisticated neural networks like Mamba and\nTransformer represents a significant leap forward in the field of\nacupuncture. This innovation not only promises to elevate the\nprecision and speed of treatments but also paves the way for\nbroader applications in healthcare diagnostics and personalized\nmedicine, ultimately leading to improved patient care and\ntreatment outcomes."}, {"title": "CONCLUSIONS", "content": "In this study, we developed a novel network by integrating\nMamba and Transformer to enhance the accuracy and speed\nof key points recognition and localization. The network has\nproven effective in addressing typical weak image feature\nacupoint detection tasks, improving computational efficiency\nand detection accuracy with fewer parameters. This work not\nonly advances the intelligentization of clinical acupuncture but\nalso lays the foundation for more accurate and diverse posture\nestimation applications. We conducted extensive experiments\nto validate the performance of our proposed network. The\nresults demonstrated significant improvements in both speed\nand accuracy compared to existing methods. Specifically, our\nnetwork achieved a higher detection rate with fewer false\npositives, making it highly reliable for clinical applications\nwhere precision is paramount.\nBeyond clinical acupuncture, the principles and techniques\ndeveloped in this study have broader implications. The en-\nhanced key point recognition and localization capabilities\ncan be applied to various fields such as sports science,\nrehabilitation, and human-computer interaction. For instance,\naccurate posture estimation can lead to better injury preven-\ntion strategies in athletes or more effective physical therapy\nregimens for patients. In conclusion, our work represents a\nsignificant step forward in the integration of advanced neural\nnetwork architectures for practical applications. By combining\nthe efficiency of Mamba with the contextual understanding of\nTransformers, we have created a powerful tool that not only\nmeets the demands of"}]}