{"title": "Enhancing CTR prediction in Recommendation Domain with Search Query Representation", "authors": ["Yuening Wang", "Man Chen", "Yaochen Hu", "Wei Guo", "Yingxue Zhang", "Huifeng Guo", "Yong Liu", "Mark Coates"], "abstract": "Many platforms, such as e-commerce websites, offer both search and recommendation services simultaneously to better meet users' diverse needs. Recommendation services suggest items based on user preferences, while search services allow users to search for items before providing recommendations. Since users and items are often shared between the search and recommendation domains, there is a valuable opportunity to enhance the recommendation domain by leveraging user preferences extracted from the search domain. Existing approaches either overlook the shift in user intention between these domains or fail to capture the significant impact of learning from users' search queries on understanding their interests.\nIn this paper, we propose a framework that learns from user search query embeddings within the context of user preferences in the recommendation domain. Specifically, user search query sequences from the search domain are used to predict the items users will click at the next time point in the recommendation domain. Additionally, the relationship between queries and items is explored through contrastive learning. To address issues of data sparsity, the diffusion model is incorporated to infer positive items the user will select after searching with certain queries in a denoising manner, which is particularly effective in preventing false positives. Effectively extracting this information, the queries are integrated into click-through rate prediction in the recommendation domain.", "sections": [{"title": "1 Introduction", "content": "The rapid expansion of online information has underscored the essential roles of recommender systems and search engines in enabling users to efficiently access relevant and appealing content. Numerous online platforms and applications, such as Amazon, Kuaishou, and YouTube, provide both recommendation and search services concurrently to adequately meet diverse user needs. Recommender systems offer suggestions to users as they browse, whereas search services allow users to actively seek out specific items. The integration of user interactions across these services on the same platforms presents a valuable opportunity to leverage behavior data from both domains, enhancing the accuracy of click-through rate (CTR) predictions in recommender systems.\nSeveral studies have explored joint learning frameworks across recommendation and search domains. IV4REC+ [18] and SESRec [19] incorporate search data to better understand user behavior in the recommendation domain. USER [26] and SRJGraph [32] integrate both domains by taking the recommendation behavior as a special case of the search behavior with zero queries.\nDespite these advances, several challenges remain unaddressed. Existing approaches often neglect the significant role of user-generated queries in search services, which not only reflect explicit user interests but also influence subsequent user behaviors by exposing different sets of items. For example, SESRec [19] considers search queries as mere features, utilizing similar embedding techniques without introducing specialized mechanisms that can capture the rich information queries convey. Additionally, these models assume a uniformity of user interests across domains, disregarding potential shifts in user intent between browsing and specific searches. This assumption overlooks scenarios where a user's preferences might differ based on the context of their interactions. For example, a user who prefers pink might choose a pink umbrella while just browsing on the e-commerce platform. On the other hand, this user could select a black umbrella if he/she has searched for an \"umbrella\" because he/she is in more urgent need of an umbrella and the black one can be shipped more quickly.\nTo confirm our conjecture, we conducted an analysis based on KuaiSAR-small to determine if there is indeed an interest shift between the recommendation and search domains. As shown in figure 2 and section 5.2.1, when we compare the selected users' categorical distribution of clicked items, with JS divergence value \u2265 0.5, the interest shift is observed. Hence, handling potential shifts in user preferences between the search and recommendation domains is essential for effectively transitioning preferences. Queries within the search domain are often directly linked to specific items or provide descriptive text about these items. A deeper understanding of the structural relationships between queries and items could lead to information-enriched query representations. Given that items overlap across domains, such insights gained from query representations can be invaluable in the recommendation domain. Previous studies, such as SESRec [19], have also explored query-item alignment. However, our data analysis reveals a significant challenge: a large number of users do not actively click on items after performing searches (e.g., one-third of users in the Kuaishou-small dataset). Simply disregarding these non-click instances, as is done in other studies, prevents us from fully capturing the complexity of query-item relationships. This suggests a need for a more nuanced approach that accounts for queries with no corresponding clicked item records.\nTo address the aforementioned problem, we design a search-enhanced framework for CTR prediction named QueryRec. This framework aims to utilize the search domain to enhance prediction accuracy in the recommendation domain by integrating refined query representations. Specifically, the query history is explicitly added to the recommendation domain as an augmented feature. To fully exploit the interaction history in the search domain, we design two auxiliary training losses to enhance the learned query embeddings: next-item prediction to align the query embedding with the user's interests in the recommender domain and query-item constructive learning to implicitly align the query embedding with their correlated items. Furthermore, we adopt a diffusion module to alleviate the issue that a significant amount of queries do not have positively interacted items.\nIn the next-item prediction module, we align the representation of the query list and the next clicked item in the recommendation domain. We adopt the self-attention sequential encoder [4] to aggregate the embeddings of all the queries from the query list and push them close to the next clicked items. This approach directly aligns the query representation with user interests in the recommendation domain, effectively addressing the issue of interest shifts.\nWe implement a contrastive loss to capture query-item relations in the search domain and align the query embeddings with the clicked item embeddings under that search query. To alleviate the issue of sparse positively interacted items for queries (even no positively interacted items for a significant amount of queries), we train a diffusion model to predict how likely the user will click an item given the positive and negative lists of items. We select the topK items (those assigned the highest probability by the generative model) to augment the positive list items. This allows the diffusion model to effectively perform a form of denoising when generating the positive items, which can effectively avoid false positives [3]. Besides, this also serves as an imputation mechanism for the positive list of items for those queries without an empty one.\nIn summary, we make the following contributions:\n\u2022 This framework represents the first known effort to focus on the representation learning of queries, which are crucial for capturing user preferences within the search domain. This approach enables a more effective transfer of knowledge to the recommendation domain.\n\u2022 We introduce a next-item prediction module that integrates information from both the search and recommendation domains, effectively bridging the gap in user interests between these two domains. This integration ensures that the information transferred to the recommendation domain is more accurately aligned with target performance expectations.\n\u2022 We propose a constrictive learning module with the samples in the search domain to better align the query embedding and item embedding. Furthermore, We design and train a diffusion model to generate positive item suggestions based on the clicked and non-clicked item lists under specific queries, which better extract training labels from the non-clicked item list."}, {"title": "2 Related work", "content": null}, {"title": "2.1 Recommendation systems", "content": "Numerous cross-domain recommendation systems have been devised to harness shared knowledge across different domains, thereby enhancing the performance within target domains. Leveraging common users or items as conduits for knowledge transfer, certain models employ these shared entities as bridges. For instance, in [14, 15] matrix factorization is applied to user-item interactions within each domain, using overlapping user or item information as constraints to guide the factorization process. The approaches in [36, 37] combine representations of overlapping users or items to transfer information, whereas mapping functions are trained to project representations between overlapping users or items between the two domains in [10, 38]. Graph-based methods such as the technique of [11] build user-item interaction graphs using overlapping user/item nodes to link the different domains. Non-linear and high-order cross-domain knowledge is captured through message passing on the graph. Some other models, instead of directly associating users and items between different domains, assume other content to be related, such as rating patterns [29], or tag/review information [7, 24]. The typical process involves mapping the user-item interaction matrix to the same latent space, which captures a common pattern shared by the different domains, enabling knowledge transfer. However, these methods often do not fully utilize the rich data available from user behaviors or contextual features, which are frequently highly informative."}, {"title": "2.2 Cross-domain recommendation systems", "content": "Some existing methods focus on click-through rate (CTR) prediction problems in different domains. PLE [21] improves MMOE [9] by explicitly separating domain-shared and domain-specific experts to avoid negative transfers. 3MN [31] adds three meta-networks to PLE, so that the embedding layer is capable of learning the domain-related knowledge explicitly. STAR [17] facilitates effective information transfer between different domains by combining the weights of a shared fully connected network (FCN) and a domain-specific FCN. Shen et al. develop SAR-net [16], which applies an attention mechanism to merge domain-specific and domain-shared information. MiNet [12] learns users' long-term domain-shared interests and short-term domain-specific interests. CCTL [30] applies different sample importance weights when transferring information from the source domain to the target domain in order to only transfer useful knowledge and avoid conflicting information. Liu et al. [6] introduce a novel adaptive loss to harmonize training across multiple domains. Although these methods have shown promising performance, they are suboptimal for our problem. First, as these models are designed for general cross-domain systems, they do not explicitly extract users' interests from search queries. Search queries are strong signals that reflect users' preferences. Most of the models do not consider how unique features within the different domains can be more effectively processed or learned via the application of different mechanisms."}, {"title": "2.3 Joint learning of search and recommendation", "content": "There are also existing works that focus on joint learning of search and recommendation. Zamini et al. [27, 28] train models in both the search and the recommendation domain with a joint loss and shared item information. IV4REC+ [18] enhances recommendation with search data through a causal learning framework. The search queries are used as treatment variables to decompose item embedding vectors into a causal part and a non-causal part. The causal part better reflects why a user prefers an item. By doing so, they implicitly assume that the user intentions in the search domain could represent that of the recommendation domain without considering the interest shift across the two domains. SESRec [19] leverages users' search interests for the recommendation domain by disentangling similar and dissimilar representations within the search and recommendation behavior. However, the dissimilar and similar representations are then concatenated together for prediction, not further distinguishing the transferable and non-transferable parts between the recommendation and the search domains. USER [26] integrates users' behavior in search and recommendation into a heterogeneous behavior sequence by treating recommendation as search with an EMPTY query. SRJGraph [32] builds a unified graph between the search and recommendation domains, using a query as an edge. A specific \"zero\"-type query is used as the edge for the recommendation domain. These two works overlook that the item exposure mechanism is different in two domains. For recommendation, the items exposed depend on the put feature information, whether the item is exposed in the search domain is mainly determined by the queries searched. Therefore, simply considering the recommendation behavior as a special search behavior is not optimal.\nIn contrast, our model matches the interest of the two domains by predicting items clicked at the next time point in the recommendation domain with historical query search history in the search domain. Besides, the model addresses the importance of the query search information and the query-item relationship with an additional diffusion-augmented contrastive learning module."}, {"title": "3 Preliminary material", "content": null}, {"title": "3.1 Problem formulation", "content": "Consider a recommendation domain and a search domain that share the same set of users $U$ and items $I$. Each user $u \\in U$ is associated with a vector of categorical features $x_u$, and each item has a vector of categorical features $x_i$.\nIn the recommendation domain, we have a collection of user-item interactions. Each interaction is a 4-tuple $(u, i, t, y)$, where $u$ and $i$ are the user and item index, $t$ is the time when the interaction occurred, and $y \\in \\{0, 1\\}$ indicates whether the user $u$ clicked the item $i$. We associated with each user $u$ a list $b_t$ containing all the items that the user $u$ clicked before time $t$.\nThe search domain has a set of queries $Q$. Each interaction is a 5-tuple $(q, u, i, t, y)$, where $q\\in Q$ is the query, $u \\in U$ is the user, $i \\in I$ is the item, $t$ is the time of the interaction, and $y \\in \\{0, 1\\}$ indicates whether the user $u$ clicked the item $i$ after searching with query $q$. A query is a string that a user inputs to the search domain platform to find some items. Associated with each user $u$ is a list $q_t$ containing all the queries conducted by the user $u$ before time $t$.\nWe aim to utilize the historical interactions from both the recommendation and search domains to predict $\\tilde{y}$, the probability of a user $u$ clicking the item $i$, i.e., the click-through rate (CTR). Specifically, to make the most of the information from both domains, the model takes input $(u, i, t, x_u, x_i, b_t, q_t)$, and predict $\\tilde{y}$. We call $b_t$ and $q_t$ the user behavior features. Compared with the single recommendation domain setting, the user query list $q_t$ in the task input is explicitly augmented from the search domain."}, {"title": "3.2 Backbone models", "content": "There has been enormous work on CTR prediction [2, 13, 25, 33, 34]. We call them the backbone models, which can be directly applied to the input in the task input. The typical designs utilize an embedding layer to transfer all the input features into embeddings, followed by various neural network structures to extract the deep correlation between the features. Without loss of generality, we take DIN [35] as an illustration example in this work. In DIN, for each user behavior feature, it utilizes a target-aware adaptive pooling to aggregate the behavior embeddings of the items to learn enhanced user interest representations. Those enhanced user interest representations are concatenated with the embedding of other features. Finally, an MLP is adopted to generate the final prediction.\nEmbedding Layer. The embedding layer is used to convert the sparse, high-dimensional input into dense, low-dimensional embedding vectors via lookup to an embedding table. Specifically, we denote $e_u$ as the user embedding and $e_i$ as the item embedding. Each element in $x_u$ is mapped into an embedding, and we denote the concatenated embedding as $e_{x_u}$. Similarly, we define $e_{x_i}$ for $x_i$. For $\\forall j \\in b_t$, we have $e_j$ that share the same set of embeddings with the item embeddings. For $\\forall q \\in q_u$, we have $e_q$.\nPrediction with Adaptive Pooling. Adaptive pooling is adopted to model user interest from behavioral features. Specifically, for $b_u$, and the target item $i$, we define the user's interest representation from $b_u$ as\n$v_b = \\sum_{j \\in b_u} a(e_j, e_i) e_j$,\nwhere $e_i$ is the embedding of target item $i$, $a(\\cdot, \\cdot)$ represents some feed-forward neural network model for the adaptive weights. Similarly, for $q_u$, and the target item $i$, we define the user's interest representation from $q_u$ as\n$v_q = \\sum_{j \\in q_u} a(e_j, e_i) e_j$.\nThen, we concatenate all the embeddings\n$e_{in} = (e_u || e_i || e_{x_u} || e_{x_i} || v_b || v_q)$\n$e_{in}$ is then fed into an MLP to get the final prediction $\\tilde{y}$, i.e.,\n$\\tilde{y} = MLP(e_{in})$.\nLoss function. Cross entropy loss is employed. For each sample $(u, i, t, y)$ in the training set in the recommendation domain, we have\n$L_1 = -y \\log{\\tilde{y}} - (1 - y) \\log{(1 - \\tilde{y})}.$."}, {"title": "3.3 Diffusion model for recommender systems", "content": "The diffusion model is a powerful generative model [23] and [3] adapt it for recommender systems. Specifically, let $x_0 \\in R^{|I|}$ denote the interaction vector for a user, where the $i$th element is 1 if the user has interacted with item $i$; otherwise it is 0. Based on this vector, the diffusion model generates $x_0$ to predict whether the user will interact with all the other items.\nForward process. From the initial state $x_0$, the iterative forward process can be parameterized as:\n$q(x_t | x_{t-1}) = N(x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_t I)$,\nwhere $\\beta_t \\in (0, 1)$ controls the Gaussian noise scales added at each step $t$. As we know, by adding two independent Gaussian noises together, we can get a new Gaussian noise. By reparameterization trick, we can directly obtain $x_t$ from $x_0$:\n$q(x_t | x_0) = N(x_t; \\sqrt{\\bar{a}_t}x_0, (1 - \\bar{a}_t) I)$,\nwhere $a_t = 1 - \\beta_t$, $\\bar{a}_t = \\prod_{t'=1}^{t} a_{t'}$, and then\n$x_t = \\sqrt{\\bar{a}_t}x_0 + \\sqrt{1 - \\bar{a}_t} \\epsilon$,\ncan be reparameterized with $\\epsilon \\sim N(0, I)$. The forward process is defined as Markov chain [3].\nReversed process. [3] defines the joint distribution $p_\\theta(x_{0:T})$ as the reverse process. It is regarded as a Markov chain with learned Gaussian transitions starting at\n$p(x_T) = N(x_T; 0, I), p_\\theta(x_{0:T}) := p(x_T) \\prod_{t=1}^{T} P_\\theta(x_{t-1} | x_t),$\n$P_\\theta(x_{t-1} | x_t) := N(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t))$,\nwhere $\\mu_\\theta(x_t, t)$ and $\\Sigma_\\theta(x_t, t)$ are the mean and covariance of the Gaussian distribution predicted by a neural network with parameters $\\theta$. According to Baye's rule and the property of the Markov chain, $q(x_{t-1} | x_t, x_0)$ can be rewritten as the following:\n$q(x_{t-1} | x_t, x_0) \\propto N(x_{t-1}; \\tilde{\\mu}(x_t, x_0, t), \\tilde{\\sigma}^2(t)I)$,\nwhere $\\tilde{\\mu}(x_t, x_0, t) = \\frac{\\sqrt{a_t}(1 - \\bar{a}_{t-1})}{1 - \\bar{a}_t}x_t + \\frac{\\sqrt{\\bar{a}_{t-1}}(1 - a_t)}{1 - \\bar{a}_t}x_0$,\n$\\tilde{\\sigma}^2(t) = \\frac{(1 - a_t)(1 - \\bar{a}_{t-1})}{1 - \\bar{a}_t}$.\nOptimization. DDPM [3] is optimized by maximizing the Evidence Lower Bound (ELBO) of the likelihood of observed input data $x_0$:\n$\\log p(x_0) = \\log \\int p(x_{0:T}) dx_{1:T}$\n$= \\log \\int E_{q(x_{1:T}|x_0)} \\frac{p(x_{0:T})}{q(x_{1:T}|x_0)}$\n$\\ge E_{q(x_{1:T}|x_0)} [\\log p_\\theta(x_0 | x_1)] - D_{KL}(q(x_T | x_0) || p(x_T))$\n$ - \\sum_{t=2}^{T} E_{q(x_T|x_0)} [D_{KL}(q(x_{t-1} | x_t, x_0) || P_\\theta(x_{t-1} | x_t))]$.\nThe denoising matching term $L_t$ at step $t$ can be calculated by\n$L_t = E_{q(x_t|x_0)} [D_{KL}(q(x_{t-1} | x_t, x_0) || P_\\theta(x_{t-1} | x_t))]$\n$=\\frac{1}{2 \\sigma^2(t)} || \\tilde{\\mu}(x_t, x_0, t) - \\mu_\\theta(x_t, x_0, t) ||^2$.\nThe simplified $L_t$ is the training loss [3, 8, 23]."}, {"title": "4 Methodology", "content": "Any backbone model can fit the input in the task input into a prediction of CTR. However, the vanilla training method for the backbone models is not designed to extract information from the search domain and is prone to sub-optimal performance. First, the query list from the search domain is usually not aligned with the user's interest in the recommendation domain. Without a proper mapping, the user query list can provide little information to the recommendation domain. Second, there are rich historical interactions in the search domain. Without a proper mechanism, the backbone models cannot learn such information.\nWith the SOTA structure for CTR models, one critical issue is learning informative query embeddings that incorporate the interaction history from the search domain and utilize the correlation of recommendation and search domain. Specifically, we design the next item prediction loss to directly align aggregated embedding from the query list into the user's interest in the recommendation domain. Besides, we propose a contrastive loss to inject the relations of the embeddings between queries and items. We adopt the diffusion model to enhance the query embedding for those with few or no positive item interactions by utilizing the lists of non-clicked items."}, {"title": "4.1 Interest alignment with next item prediction", "content": "The goal of incorporating query embedding is to help better understand users' preferences in the recommendation domain. Therefore, it is expected that the query embedding can be more informative in a way that better matches users' interest in the recommendation domain. To achieve the goal, we map interaction records of recommendation and search domains in chronological order. Then, we orient learning of query representation to directly predict the items the user intends to click at the next time point in the recommendation domain.\nIn the recommendation domain, from all the interaction history $(u, i, y, t)$, we can construct two lists of items: $r_u^+$ rut and $r_u^-$ rut, which are the list of items with $y = 1$ and $y = 0$ for user $u$ after time $t$ in chronological order. And similarly, a list of search sequence $q_t$ and interacted items in the search domain $s_t$. Given a training sample $(u, i, y, t)$ in the recommendation domain, we can collect the corresponding $r_u^+, r_u^-$ and $q_u$. The query list $q_u$ is encoded by self-attention sequential (SAS) [4] encoder into d-dimensional embedding $e_{q_t}$, which captures long-term semantics.\nOn the other hand, we can get the d-dimensional item embeddings for the items from both $r_u^+$ and $r_u^-$ with the same embedding mechanism in Sec. 3.2. To make the query embedding reflect users' preferences in the recommendation domain better, we drive the embedding $e_{q_t}$ to be closer to the embeddings from $r_u^+$ than those from $r_u^-$. Specifically, we define\n$L_2 = - \\frac{1}{|r_u^+|} \\sum_{j \\in r_u^+} \\log(e_{q_t} \\cdot e_j) - \\frac{1}{|r_u^-|} \\sum_{j \\in r_u^-} \\log(1 - (e_{q_t} \\cdot e_j))$,\nwhere $(\\cdot, \\cdot)$ denotes the dot product. For efficient implementation, we sample $n_{pos}$ items from $r_u^+$, and denote the sampled list as $r_u^{+'}$. Similar we sample $n_{neg}$ items from $r_u^-$, and denote it as $r_u^{-'}$. We define the loss as\n$L_2 = - \\frac{1}{n_{pos}} \\sum_{j \\in r_u^{+'}} \\log(e_{q_t} \\cdot e_j) - \\frac{1}{n_{neg}} \\sum_{j \\in r_u^{-'}} \\log(1 - (e_{q_t} \\cdot e_j)).$"}, {"title": "4.2 Query-item contrastive learning with diffusion data augmentation", "content": "Given the user's intense activities in the search domain, it is worthwhile to capture more transferable knowledge from the search domain and thus make query representation more useful in item recommendation. One important piece of information is the relationship between the queries and the items. The probability of items being selected after certain search behaviors mostly depends on the queries searched. The relationship is extracted with the queries and their corresponding clicked items. Inspired by [5], we leverage contrastive loss to learn similarities and dissimilarities between searched query items.\nContrastive learning. From the interaction history from the search domain, for each query q, we collect the set of positive items for query q and denote it as $I_q^+$, where for each item $i \\in I$, at least one user clicked it after she searched with q and item i was exposed to her. For each sample $(u, i, t, y)$ in the recommendation domain, denote $q_t$ as the last query User u has before t. Then, the contrastive loss at $(u, i, t, y)$ is defined as\n$L_3 = - \\log \\frac{\\exp(s(e_{q_t}, e_i) / \\beta)}{\\sum_{j \\in I \\backslash I_q^+} \\exp(s(e_{q_t}, e_j) / \\beta)}$,\nwhere $s(e_i, e_j) = \\tanh(e_i^T W e_j)$. $W \\in R^{d \\times d}$ is the learnable transformation matrix between queries and items and $I$ is the item set.\nDiffusion data augmentation. One common problem for the search datasets is the sparse record of users' click behavior after searching certain queries, and a significant proportion of queries do not have positively interacted items, namely, the $I_q^+$ is empty for a significant amount of query q. The query with empty $I_q^+$ will thus have no labels in the contrastive loss. However, those query has the list of non-clicked items $I_q^-$, where for each item $i \\in I_q^-$, no user clicked it after she searched with q and item i was exposed to her. We could utilize $I_q^-$ for the contrastive signal. In light of the success of diffusion models in image generation and Top-K recommendation [3, 23], we take advantage of the diffusion module to augment information of items clicked given queries searched. We aim to enhance $I_q^+$ with $I_q^-$ and $I \\backslash (I_q^+ \\cup I_q^-)$ by a diffusion model.\nSpecifically, we take $x_q \\in R^{|I|}$ as the query-item interaction vector, where the ith element represents how likely a user will click i after search with query q. For each query q, the items are divided into three groups, i.e., $I_q^+, I_q^-$, and $I \\backslash (I_q^+ \\cup I_q^-)$. For all the positions with indexes from $I_q^+$ in $x_q$, we assign value $r_p \\in [0, 1]$. Similarly, for all the positions with indexes from $I_q^-$ and $I \\backslash (I_q^+ \\cup I_q^-)$ in $x_q$, we assign value $r_n \\in [-1, 0)$ and $r_0 = 0$. The $r_p, r_n$ and $r_0$ are hyper-parameters.\nThe diffusion model is trained by the same method introduced in Sec. 3.3 after we assign $x_0 = x_q$. Furthermore, to learn a better model for sparse $I_q^+$, we do some random masking to intentionally remove some items for $x_t$ in the forward process but keep the original $x_q$ as the $x_0$ for the reconstruction term in (11).\nAfter we trained a diffusion model, for each query q, we generate $\\tilde{x}_q$. We take the index with topK values in $\\tilde{x}_q$ as the enhanced $I_q^+$ for the contrastive loss in (15)."}, {"title": "4.3 Training", "content": "With all the components, we train the model with the loss\n$L = L_1 + \\lambda_2 L_2 + \\lambda_3 L_3$,\nwhere $\\lambda_2$ and $\\lambda_3$ are the hyper-parameters."}, {"title": "5 Experiments", "content": null}, {"title": "5.1 Dataset", "content": "KuaiSAR [20] datasets include two versions: KuaiSAR-large and KuaiSAR-small. KuaiSAR-large contains data from 2023/5/22 to 2023/6/10, while KuaiSAR-small consists of data from 2023/5/22 to 2023/5/31. Unlike other commonly used datasets, KuaiSAR datasets are collected from a real-world platform. Due to the different selection periods, as indicated by the statistics in Table 2, KuaiSAR-large and KuaiSAR-small can be considered two datasets with varying degrees of actions and correlations across two domains. It is important to note that a query is a specific list of words, with each word hashed into integers for anonymization. The query set comprises all queries from selected users, and the corresponding words form the word set.\nWe tested QueryRec with an industrial dataset, which includes two sub-datasets collected from two separate services: search and recommendation. The users and items of these two services are overlapped. This industrial dataset contains more than 200,000,000 records and 1,000,0000 different queries, along with other information-enriched feature fields. Besides, Only DIN, DCN, and QueryRec are tested with this industrial dataset to save extra costs."}, {"title": "5.2 Data analysis", "content": null}, {"title": "5.2.1 Empirical user interest distributions in the search and the recommendation domains", "content": "Suppose there are total K categories of all items, then we model a user u interest distribution by the frequency of categories clicked by u. Specifically, we denote $C_{u}^{src}$ as the clicked items in the search domain, and $C_{u}^{rec}$ as the clicked items in the recommendation domain. Taking the search domain as an example, then the interest distribution of u over K categories is:\n$p_{u}^{src}(k) = \\frac{\\sum_{i \\in C_{u}^{src}} I(i \\in k)}{|C_{u}^{src}|}, k = 1, 2, ..., K$\nSimilarly, u's interest distribution in the recommendation domain is defined as:\n$p_{u}^{rec}(k) = \\frac{\\sum_{i \\in C_{u}^{rec}} I(i \\in k)}{|C_{u}^{rec}|}, k = 1, 2, ..., K$\nAfter obtaining the interest distributions, we measure the degree of u's interest shift by Jensen-Shannon (JS) Divergence of $p_{u}^{src}(k)$ and $p_{u}^{rec}(k)$:\n$D^{JS}(p_{u}^{src} || p_{u}^{rec}) = \\frac{1}{2}D^{KL}(p_{u}^{src} || M) + \\frac{1}{2}D^{KL}(p_{u}^{rec} || M)$,\n$M = \\frac{p_{u}^{src} + p_{u}^{rec}}{2}$\nJS Divergence is bounded by 1, given the base 2 logarithm. If $D^{JS} > 0.5$, we can assume u's interest distribution shifts as the domain changes.\nWe randomly select 10000 users and visualize their JS values by histogram. Figure 2 indicates that at least half of users have displayed unignorable changes in interest distribution across domains. Only 24.8% users have shown no obvious evidence of interest shift given $D^{JS} \\le 0.5$."}, {"title": "5.2.2 Correlation between the search and the recommendation domains", "content": "To see whether the information from the search domain would be an enhancement to the recommendation domain", "obtain": "n$\\{(u^1, i^1, y^1, t^1), .., (u^k, i^k, y^k, t^k), ...(u^n, i^n, y^n, t^n)\\}$,\nwhere $y^k = 1$ for $k = 1, 2, .., n$.\n$(u^k, i^k, y^k, t^k)$ denotes that the user k clicked the item $i^k$ in the recommendation domain at time $t^k$. $q^k = [q_1, q_2, ..., q_m"}]}