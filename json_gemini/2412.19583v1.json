{"title": "A Comparative Study of Machine Unlearning Techniques for Image and Text Classification Models", "authors": ["Omar M. Safa", "Mahmoud M. Abdelaziz", "Mustafa Eltawy", "Mohamed Mamdouh", "Moamen Gharib", "Salaheldin Eltenihy", "Nagia M. Ghanem", "Mohamed M. Ismail"], "abstract": "Machine Unlearning has emerged as a critical area in artificial intelligence, addressing the need to selectively remove learned data from machine learning models in response to data privacy regulations. This paper provides a comprehensive comparative analysis of six state-of-the-art unlearning techniques applied to image and text classification tasks. We evaluate their performance, efficiency, and compliance with regulatory requirements, highlighting their strengths and limitations in practical scenarios. By systematically analyzing these methods, we aim to provide insights into their applicability, challenges, and trade-offs, fostering advancements in the field of ethical and adaptable machine learning.", "sections": [{"title": "Introduction", "content": "The rapid expansion of machine learning (ML) applications has raised significant concerns over data privacy. With the integration of ML models across industries, regulations like the GDPR and CCPA mandate that individuals can request the removal of their personal data. This creates a challenge for organizations to comply with privacy laws while maintaining model performance. Traditional ML training often results in models memorizing sensitive data, and removing this data typically requires retraining from scratch, which is resource-intensive. Machine unlearning has been proposed as a solution to allow models to \"forget\" specific data efficiently without complete retraining, preserving performance and ensuring privacy compliance. Previous work on unlearning in classification models has categorized the problem into three distinct scenarios: (1) Full-class unlearning, which entails removing an entire class from the model, with the forget set containing all instances of a specific class; (2) Sub-class unlearning, which focuses on forgetting a subset of instances within a single class; and (3) Random forgetting, which involves removing arbitrary instances across multiple classes. Despite progress in this field, a critical gap remains in the literature: the absence of a comprehensive, unified study comparing unlearning techniques across diverse datasets and models. Existing research typically evaluates methods on specific datasets or tasks, leading to fragmented insights and a lack of standardized benchmarks for performance comparison. This paper aims to bridge this gap by conducting a comparative analysis of prominent machine unlearning techniques in the context of image and text classification tasks. By evaluating these methods across multiple datasets and offering a unified framework for comparison, we aim"}, {"title": "Related Work", "content": "Foster, Schopf, and Brintrup [5] introduced an unlearning algorithm called Selective Synaptic Dampening SSD that uses weight sensitivity to adjust model parameters selectively for forgetting specific data. The method identifies weights heavily influenced by the \"forget set\" compared to the remaining data and dampens these weights, reducing their impact on predictions. Weight sensitivities are computed using the Fisher Information Matrix (FIM), enabling targeted adjustments to the most sensitive model parameters. Graves, Nagisetty, and Ganesh [6] proposed an unlearning method called Mislabel Unlearning, a simple approach in which the labels of data in the forget set are randomly changed to those of other classes. The modified data is then used to fine-tune the model for a few epochs, enabling selective forgetting. Chundawat, et al [2] proposed an unlearning method called Incompetent Teacher that uses selective knowledge transfer between student and teacher models. The student model learns from the forget set under the influence of an incompetent teacher, while a competent teacher provides corrective guidance for the retain set. Kurmanji et al. [9] proposed SCRUB, an unlearning method based on the teacher-student framework. Similar to the \"Incompetent Teacher\" approach, SCRUB uses a student model that learns from a teacher model. However, SCRUB modifies loss function to increase error on the forget set while optimizing accuracy on the retained data. This is achieved through alternating \"max-steps\" (focused on forgetting) and \"min-steps\" (focused on retaining), with additional steps to restore performance or the retain set. Tarun et al. [12] introduced the UNSIR algorithm. This approach consists of three steps: generating an error-maximizing noise matrix, impairing the model by training it with this noise on a subset of data, and repairing the model on the retained data. The noise matrix, which maximizes error for the targeted class, is key to disrupting the model's ability to recall the forgotten data. Following the impair step, the repair step ensures that the model retains its performance on the remaining data."}, {"title": "Methodology", "content": "This study evaluates machine unlearning techniques using image and text classification models, focusing on the trade-off between retaining accuracy on non-forgotten data and effectively forgetting target data. The experiments involve fine-tuning pre-trained models, applying unlearning processes, and measuring performance using key metrics."}, {"title": "Models and Datasets", "content": "Image Classification Models:\n\u2022 ResNet18 [7]: A lightweight residual convolutional network, known for its efficient training.\n\u2022 ViT(google/vit-base-patch16-224) [13]: Vision Transformer [3], which treats image patches as tokens and utilizes transformer architecture.\nText Classification Model:\n\u2022 MARBERT [1]: An Arabic variant of BERT, pre-trained on 128 GB of Arabic text data.\nImage Datasets:\n\u2022 CIFAR-10 [8]: Contains 60,000 color images of size 32x32 pixels across 10 classes (e.g., airplanes, cars, birds, etc.). It is used for random forgetting experiments, with 50,000 training and 10,000 test images.\n\u2022 CIFAR-100: A more challenging dataset with 100 classes and 600 images per class. Used for full-class unlearning experiments, it is split into 50,000 training and 10,000 test images.\nText Dataset:\n\u2022 Hotel Arabic Reviews Dataset (HARD) [4]: Contains 93,700 Arabic hotel reviews (only 50,000 were used), labeled from 1 to 5, split into 40,000 training samples and the 10,000 for testing."}, {"title": "Evaluation Metrics", "content": "The effectiveness of machine unlearning is assessed using the following metrics:"}, {"title": "Relative Retain Accuracy (Ar)", "content": "Retain accuracy measures the performance of the unlearned model on data not targeted for forgetting. It is computed as:\n$A_r = \\frac{A_u}{A_b} \u00d7 100,$\nwhere Au is the accuracy of the unlearned model on the retain set, and As is the baseline accuracy of the original model. An ideal unlearning method should preserve Ar close to 100%."}, {"title": "Relative Forget Accuracy (Af)", "content": "Forget accuracy quantifies the model's accuracy on the forget set after unlearning. Lower Af values indicate effective forgetting. It is defined as:\n$A_f = \\frac{A_u}{A_b} \u00d7 100,$"}, {"title": "Membership Inference Attack (\u039c\u0399\u0391)", "content": "MIA [11] evaluates the model's susceptibility to leaking information about the forget set. Based on logistic regression, MIA returns a probability score indicating the likelihood of a data sample being part of the training set. The optimal MIA value is defined as: An optimal value for MIA might appear to be closer to 0, however as argued by Chundawat et. al [2], an abnormally small probability provides as much information to an attacker as an exceedingly large probability. Thus, optimal values for MIA are somewhere between and ideally very close to the values that would be produced by a retrained model."}, {"title": "Zero Retrain Forgetting (ZRF)", "content": "ZRF evaluates the randomness of predictions on the forget set without requiring a retrained model. It is computed using Jensen-Shannon divergence (JS) [10] as:\n$JS(M(x), Td(x)) = 0.5 KL(M(x)||m) + 0.5 KL(Td(x)||m),$\nwhere $m = \\frac{M(x)+Td(x)}{2}$ is the mean distribution, M(x) is the output of the unlearned model, and Td(x) is the output of an incompetent teacher model. The ZRF score is given by:\n$ZRF = 1 - \\frac{1}{n_f} \\sum_{i=1}^{n_f} JS(M(x_i), Td(x_i)),$\nwhere nf is the number of samples in the forget set. ZRF values closer to 1 indicate highly randomized predictions, signifying effective forgetting."}, {"title": "Computation Time", "content": "The time required for applying the unlearning process is recorded as a practical metric. Efficient computation time is crucial for scalability, especially in compliance with privacy laws such as GDPR and CCPA."}, {"title": "Experiments", "content": "In our experiments, the models were fine-tuned on the datasets mentioned above. The experiment aimed to perform Full-Class Unlearning and/or Random Forgetting using six unlearning methods: SSD, Incompetent Teacher, SCRUB, UNSIR, and Mislabel. Retraining from scratch was also included as a baseline for comparison. For the full-class forgetting process, the class to be forgotten for each of the ResNet18 and ViT image classification models is (Rocket). Whereas for the MARBERT sentiment analysis classification task, the experiments are done for each of the 5 classes in HARD dataset (Rating from 1 to 5)."}, {"title": "Hyperparameters", "content": "For Full-Class Unlearning and Random Forgetting in ResNet:\nFor Selective Synaptive Dampening the values"}, {"title": "Results", "content": "First for Image Classification Models"}, {"title": "Full Class Forgetting", "content": ""}, {"title": "ResNet18 Results", "content": "For ResNet18, SCRUB demonstrated the best performance in terms of both test accuracy and retain accuracy in the full-class forgetting scenario. The improvement in retain accuracy relative to the baseline is attributed to the inclusion of a cross-entropy loss term in SCRUB's loss function, which enhances accuracy during the unlearning process.\nSelective Synaptic Dampening (SSD) also achieved very high retain accuracy, trailing only SCRUB. SSD was only slightly behind Incompetent Teacher and Mislabel Unlearning in the ZRF and MIA metrics. Furthermore, SSD was more than twice as fast as SCRUB (although slightly slower than Mislabel Unlearning) and achieved marginally better ZRF and MIA metric values, establishing SSD as a balanced and efficient method for this experiment.\nUNSIR, while achieving stronger-than-retrain results across all metrics, trailed the other methods in overall performance. Interestingly, UNSIR retained some performance on the forget set, highlighting UNSIR unability to completely forget classes while keeping constant retain accuracy.\nEven the slowest algorithm applied in this experiment achieved approximately a 95% speed-up compared to naive retraining, with better retain accuracy and nearly equivalent performance in the MIA and ZRF metrics."}, {"title": "ViT Results", "content": "Mislabel Unlearning demonstrated the most significant improvement in relative test and retain accuracy, with ZRF and MIA values closely aligning with those of the retrain algorithm. This underscores its effectiveness in unlearning while maintaining high accuracy. SCRUB, while achieving strong ZRF values, exhibited elevated MIA metrics, suggesting reliable forgetting but reduced security. Selective Synaptic Dampening (SSD), although unable to fully preserve overall accuracy, offered a balanced unlearning approach with low MIA. Its performance, combined with being twice as fast as Mislabel Unlearning and four times faster than SCRUB, positions SSD as a more efficient alternative. In contrast, Incompetent Teacher failed to completely unlearn the Rocket class; however, this moderate unlearning resulted in a secure model with zero MIA, enhancing its robustness. It is important to note that several methods improved the overall accuracy of the model, with Mislabel Unlearning demonstrating the most substantial increase. This improvement can be attributed to two key factors: the baseline model not being fully trained to saturation and the ViT model's reliance on transfer learning. Consequently, additional training epochs, whether for learning or unlearning, facilitate further fine-tuning and enhance the model's accuracy."}, {"title": "Random Forgetting", "content": ""}, {"title": "ResNet18 Results", "content": "Most unlearning algorithms struggle with random forgetting, regardless of forget set size. SSD, however, maintains consistent test, retain, and forget accuracy, unlike Mislabel, Incompetent Teacher, and SCRUB, which fail to preserve model performance. SCRUB leads to a significant accuracy drop despite increased forget accuracy, due to issues with distinguishing forget and retain sets. Selective Synaptic Dampening fails to forget across all percentage values, likely due to similarities in Fisher Information Matrix values, while the naive retrain shows only minimal changes in MIA and ZRF metrics."}, {"title": "ViT Results", "content": "Similar to the results of ResNet18, the random forgetting experiment shows that both the naive retrain and Selective Synaptic Dampening fail to achieve unlearning at any percentage value. In contrast, Incompetent Teacher and Mislabel successfully achieve unlearning across all percentages. Incompetent Teacher performs better at smaller percentages but retains less model accuracy than Mislabel. Mislabel, however, excels at higher percentages, offering better unlearning performance and model accuracy retention, though at the cost of more than twice the time required for the unlearning procedure. Second, text classification models."}, {"title": "MARBERT Results", "content": "In the Full-Class Forgetting experiments, MARBERT was fine-tuned on HARD dataset. Since classes vary significantly in size, unlearning experiments were done for each of the 5 classes in HARD. We note that Selective Synaptive Dampening achieves the highest retain accuracy values with very strong MIA and ZRF values for classes 1, 2, and 3 but more time taken compared to other methods and fails to unlearn in both classes 4, and 5 corresponding to the largest portion of the dataset. Evaluating Incompetent Teacher, we note that for classes 1 and 4 we obtain higher accuracy retention with near equivalent unlearning performance by utilizing a smaller learning rate, whereas for class 2, the higher learning rate provides better accuracy retention with a minuscule decrease in unlearning performance and for classes 3 and 5, performance is equivalent between both learning rates. Overall, incompetent teacher manages to achieve unlearning but model performance starts to degrade sharply for classes 4 and 5 which contain large portions of the training dataset.\nEvaluating Mislabel Unlearning, we note very high degradation in model performance across all five classes, but achieves complete forgetting at the cost of model prediction randomness.\nEvaluating UNSIR, we note catastrophic performance by the algorithm using le-4 and 2e-4 learning rates respectively in forgetting class 1, and catastrophic performance by the higher learning rate in forgetting class 2 as well, with the MIA value rising to 1.0. The MIA value for the higher learning rate inflects to 0 for classes 3, 4, and 5 however with near Mislabel Unlearning accuracy retention. For class 2, the lower learning rate achieves slightly worse than Incompetent Teacher accuracy retention with good MIA and ZRF metrics at a lower time taken, and for class 3 accuracy retention remains slightly below Incompetent Teacher but MIA and ZRF values degrade. For classes 4 and 5 the lower learning rate option fails to achieve unlearning. SCRUB, despite being top performer in Full-class forgetting in ResNet, and one of the best methods with ViT, failed to adapt to new task and achived worst results among all algorithms, overall model accuracy dropped to less than half, highlighting algorithm's inability to unlearn textual information. We note as well the failure of the naive retrain to achieve unlearning in all but class 4 where it achieves the best retain accuracy but with slightly higher MIA values and lower ZRF values.\nOverall, for this experiment we identify a failure by most algorithms to provide satisfactory unlearning, with Incompetent Teacher providing the best all around results using differing learning rates. We attribute the difficulty in achieving unlearning during this experiment to the imbalanced nature of the dataset used."}, {"title": "Conclusion", "content": "Combining the observations and conclusions from the previous experiments, we identify that Incompetent Teacher achieves the most balanced results in all work loads, however for specific work loads, other methods achieve better results. Mislabel Unlearning achieves better unlearning performance in full-class forgetting on models utilizing transfer learning, and goes head to head with Incompetent Teacher in random forgetting work loads. SCRUB demonstrates superior results in the Full-Class forgetting task on ResNet, and achieves competitive results with ViT. However, SCRUB's adaptation to new tasks, such as Text Classification, proved inadequate, as it yielded low overall model accuracy and retention accuracy. Additionally, SCRUB resulted in catastrophic unlearning when applied to Random Forgetting scenario. Selective Synaptive Dampening achieves better results in the full-class forgetting process on a model trained from scratch, While UNSIR provides good performance in many of the previous experiments, it lags in accuracy retention and unlearning performance as well as time taken to be an alternative to Incompetent Teacher in any workload."}]}