{"title": "radarODE-MTL: A Multi-Task Learning Framework with Eccentric Gradient Alignment for Robust Radar-Based ECG Reconstruction", "authors": ["Yuanyuan Zhang", "Rui Yang", "Yutao Yue", "Eng Gee Lim"], "abstract": "Millimeter-wave radar is promising to provide robust and accurate vital sign monitoring in an unobtrusive manner. However, the radar signal might be distorted in propagation by ambient noise or random body movement, ruining the subtle cardiac activities and destroying the vital sign recovery. In particular, the recovery of electrocardiogram (ECG) signal heavily relies on the deep-learning model and is sensitive to noise. Therefore, this work creatively deconstructs the radar-based ECG recovery into three individual tasks and proposes a multi-task learning (MTL) framework, radarODE-MTL, to increase the robustness against consistent and abrupt noises. In addition, to alleviate the potential conflicts in optimizing individual tasks, a novel multi-task optimization strategy, eccentric gradient alignment (EGA), is proposed to dynamically trim the task-specific gradients based on task difficulties in orthogonal space. The proposed radarODE-MTL with EGA is evaluated on the public dataset with prominent improvements in accuracy, and the performance remains consistent under noises. The experimental results indicate that radarODE-MTL could reconstruct accurate ECG signals robustly from radar signals and imply the application prospect in real-life situations.", "sections": [{"title": "I. INTRODUCTION", "content": "Electrocardiogram (ECG) signal is commonly recognized as the golden standard in cardiac monitoring compared with other vital signs (e.g., heart rate, photoplethysmography), because ECG describes the fine-grained cardiac activities, such as atrial/ventricular depolarization/repolarization, through the featured waveform (i.e., PQRST peaks) and is crucial to the diagnosis of cardiovascular diseases [1]. The traditional ECG measurement relies on the adhesive electrode patches with wired connections to the monitor to provide real-time and accurate ECG signals and is mainly used in clinical scenarios due to the cumbersome apparatus. However, the contact-based ECG collection is unfriendly to long-term monitoring and is not applicable to daily wellness monitoring [2]. Recently, radar has become a promising contactless sensor to provide non-invasive and accurate ECG monitoring by using advanced signal-processing algorithm and deep neural network [2]\u2013[5].\n\nThe trials on the radar-based ECG recovery can be categorized into two paradigms. The first paradigm only performs the extraction of high-resolution cardiac mechanical activities to produce quasi-ECG signals, omitting the morphological ECG features while maintaining certain fine-grained features. For example, the mostly adopted quasi-ECG signal only preserves R and T peaks and can be realized by signal decomposition [6] or state estimation [7], [8]. In contrast, the second paradigm aims to reconstruct the ECG waveform as measured by clinical apparatus, because the doctor and ECG analysis toolbox all rely on the shape of ECG to make diagnosis [9]. However, decoupling the ECG signal from the measured radar signal requires establishing an extremely complex model from the perspective of electrophysiology (i.e., excitation-contraction coupling [1]), and the existing research can only leverage deep learning methods to learning such domain transformation from the dataset containing numerous radar/ECG pairs [2]\u2013[5].\n\nIn the literature, radar-based ECG waveform recovery has been achieved based on various deep-learning architectures, such as convolutional neural network (CNN) [2], [5], long short-term memory (LSTM) network [7], and Transformer [2], [3]. However, the noise robustness of the deep-learning framework is rarely investigated in the literature, especially for the random body movement (RBM) noise that is inevitable in contactless monitoring and has orders of magnitude larger than cardiac activities. The existing work either discarded the data during the RBM [4] or reported the heavy distortion as the future work [2]. Additionally, the existing deep-learning methods are also blamed for being purely data-drove as a black box and the transformation between cardiac mechanical and electrical activities lacks the theoretical explanation [5].\n\nBased on the limitations of the existing methods, it is necessary to provide a feasible model that explains the trans- formation inside radar-based long-term ECG recovery and is also robust to real-life noises. Therefore, this work proposes to deconstruct the radar-based ECG reconstruction into three individual tasks as a multi-task learning (MTL) problem to extract cardiac features with different levels of granularity, i.e., coarse features: heartbeat detection and cardiac cycle timing; fine-grained feature: ECG waveform. However, another consequent problem is to simultaneously optimize three individual tasks under the MTL paradigm, because the optimization of one task may degrade the performance of the others [10], [11].\n\nIn the literature, MTL is a widely-used deep learning paradigm in various fields such as scene understanding [12], [13], autonomous driving [14] and speech/text processing [15]. However, the MTL paradigm has never been applied in radar-based ECG recovery, and the existing MTL optimization strategies cannot fairly optimize all the tasks due to the imbalanced task difficulties [16]. In this work, the difficulty of extracting the ECG waveform is much higher than the other two, and simply applying the existing optimization strategies cannot achieve an ideal result with fair improvements on all tasks according to our initial experiments.\n\nInspired by the above discussion, the contributions of this work can be concluded as:\n\n\u2022 A novel optimization strategy called eccentric gradient alignment (EGA) is proposed for updating shared parameters in the MTL neural network, aiming to balance the intrinsic difficulty across tasks during network training and also prevent the negative transfer phenomenon.\n\n\u2022 To the best of our knowledge, this is the first work that models the radar-based long-term ECG recovery as three tasks and realized by an end-to-end MTL framework named radarODE-MTL, improving the robustness against both constant and abrupt noises.\n\n\u2022 Sufficient experiments show that the proposed radarODE- MTL with EGA optimization strategy outperforms other frameworks and optimization strategies under various noise conditions and datasets.\n\nThe rest of the paper is organized as follows. Section II provides the background for radar-based ECG recovery and MTL optimization. The proposed radarODE-MTL framework with EGA strategy is elaborated in Section III, and the experimental settings and results are shown in Section IV. At last, Section V concludes this paper with future work."}, {"title": "II. BACKGROUND AND PROBLEM STATEMENT", "content": "This section will provide compact explanations of the domain transformation in ECG recovery and the optimization problem in MTL network, with the corresponding problem statements."}, {"title": "A. Model for Domain Transformation and Problem Statement", "content": "1) Signal Model for Cardiac Mechanical Activities: The first step for any contactless vital sign monitoring is to obtain the displacement near the chest region by unwrapping the chest displacement $\\tilde{a}(t)$ from the phase change $\\Delta\\phi(t)$ of the received radar signal with wavelength $\\lambda$ as:\n\n$\\Delta\\phi(t) = \\frac{4\\pi\\tilde{a}(t)}{\\lambda}$                                                              (1)\n\nThe demodulated chest displacement contains the interested cardiac mechanical activities with multiple noises, such as respiration noise [17] and RBM noise [2]. In ECG recovery, some periodic or high-frequency noise can be filtered in pre- processing following the methods in [6], while some constant or abrupt noises are hard to remove. Therefore, the original chest displacement $\\tilde{x}(t)$ can be processed to $x(t)$ for ECG recovery after initial noise removal as:\n\n$x(t) = \\hat{x}(t) + N_{abr}(t) + n_{con}(t)$                                                              (2)\n\nwhere $x(t)$ contains the interested cardiac mechanical activities, $n_{abr}(t)$ represents the abrupt noises (e.g., RBM) and $n_{con}(t)$ describes many other constant noises that affect the signal-to-noise ratio (SNR), such as thermal noise [6], [18], monitoring from random directions [19] and long-range monitoring [17].\n\nAccording to our previous work [5], the fine-grained cardiac mechanical activities include aortic valve opening/closure (AO/AC) and mitral valve opening/closure (MO/MC), revealed by the corresponding prominent vibrations $v_1$ and $v_2$ as measured in radar signal $x(t)$ as depicted in Figure 1. Therefore, the signal model $x(t)$ can be further refined into subtle cardiac activities for $K$ cardiac cycles as:\n\n$x(t) = \\sum_{k=1}^K v_1^k(t) + \\sum_{k=1}^K v_2^k(t) + n_{abr}(t) + n_{con}(t)$                                                    (3)\n\nwith\n\n$v_1^k(t) = a_1^*cos(2\\pi f_1^k t) exp(-\\frac{(t-T_1^k)^2}{64^2})$                                                              (4)\n\n$v_2^k(t) = a_2^*cos(2\\pi f_2^k t) exp(-\\frac{(t-T_2^k)^2}{64^2})$\n\nwhere $a_1^k, b_1^k$ and $a_2^k, b_2^k$ jointly determine the amplitudes and lengths of the first and second prominent vibrations for $k^{th}$ cardiac cycle, $f_1^k, f_2^k$ are the corresponding central frequencies and $T_1^k, T_2^k$ represent when the vibrations happen.\n\n2) Model of Domain Transformation: The radar signal modeled in (3) shares a strong temporal consistency with the ECG signal as shown in Figure 1, because the excitation-contraction coupling indicates that the electrical signal (ECG)"}, {"title": "B. Optimization Strategies for MTL", "content": "1) Optimization of MTL Network: A standard definition for an MTL optimization problem with n tasks under hard parameter sharing (HPS [20]) architecture is given by:\n\n$\\theta^* = \\underset{\\theta \\in \\Theta}{argmin} F(\\theta) = \\sum_{i=1}^n L_i(\\theta)$                                                                        (5)\n\nwhere $\\theta \\in \\mathbb{R}^m$ denotes the shared parameter space, $L_i(\\theta)$ is the task-specific non-negative objective function for $\\mathbb{R}^m \\rightarrow \\mathbb{R}^+$, and $F(\\theta)$ represents a mapping from the parameter space to the objective space as $\\mathbb{R}^m \\rightarrow \\mathbb{R}^n$. The MTL optimization strategy aims to find the optimal parameter set $\\theta^*$ that minimizes the average loss.\n\nThe dilemma in the design of MTL optimization strategies is mainly on avoiding negative transfer when the optimization of individual tasks conflicts with each other [21]\u2013[28], spawning two main categories of methods, loss balancing method and gradient balancing methods, to impartially search for the optimal solution(s) subjecting to Pareto optimality [24].\n\nThe loss balancing methods add the weight to each task loss $L_i(\\theta)$ based on various criteria, such as learning rate [26], inherent task uncertainty [28] or the loss magnitude [23]. In contrast, gradient balancing methods address the negative transfer by balancing both magnitudes and the directions of the task-specific gradient $g_i = \\nabla_{\\theta}L_i(\\theta)$, according to certain criteria such as the cosine similarity between gradients [24], descending rate [24] or the orthogonality of the gradient system [21].\n\n2) Problem Statement for Designing MTL Optimization Strategies: The existing methods perform not well on the proposed radarODE-MTL framework because most methods aim to treat all the tasks equally and pay too much attention to the easy tasks with the least achievement after convergence (e.g., slow learning rate in GradNorm [29], small singular value in Aligned-MTL [21]), while the hard task tolerates a slow convergence rate due to the limited gradient magnitudes or update frequencies [16]. Several studies in the literature proposed to increase the weight for the hard task metered the learning rate [16], [30]. However, the forcible change of the weight may aggravate the gradient conflict and hence degrade other tasks, because the loss-balancing method can not alleviate the gradient conflict issue [24].\n\nIn addition, the slow learning rate can be interpreted in two ways: (a) The optimization stalls due to the compromise in gradients normalization, and the constraint on the hard task should be released as adopted in GradNorm [29] and DWA [26]; (b) The optimization has already achieved convergence and should be terminated as in the early stop technique [31]. Unfortunately, it is hardly investigated whether the optimization actually converges or stalls, or say, should more computational resources be skewed towards the task with limited learning progress. Therefore, EGA is proposed in this paper to estimate the intrinsic task difficulty based on the current learning progress and dynamically alter the gradients in orthogonal space to fairly benefit all the tasks without knowing the actual optimization status (i.e., stall or convergence)."}, {"title": "III. METHODOLOGY", "content": ""}, {"title": "A. Overview of radarODE-MTL with EGA Strategy", "content": "The aforementioned three deconstructed tasks for radar- based ECG recovery can be realized by the proposed radarODE-MTL framework as shown in Figure 3, and the dataset used for training and validation is provided in [2]. Firstly, the 50 synchronous radar signals will be pre-processed into spectrograms by synchrosqueezed wavelet transform (SST) to highlight the central frequencies for locating the prominent vibrations $v_1$ and $v_2$. Then, radarODE-MTL is designed to generate the long-term ECG recovery in an end-to- end manner with certain shared layers to capture the common representations for all tasks and three task-specific decoders to recover the ECG morphological features, detect ECG anchors (R peaks) and estimate single-cardiac-cycle length respectively, as shown in Figure 3(a)-(d).\n\nDuring the training stage, the network optimization of three decoders follows the standard single-task optimization method, and the share parameter space (Backbone&Encoder) is updated using the proposed EGA strategy based on the task-specific loss $L_1, L_2, L_3$, as shown in Figure 3(e). In general, the EGA strategy first tries to eliminate the conflict and dominance among the original task-specific gradients, e.g., $g_1, g_2$ have opposite directions and $g_3$ has large magnitude. Secondly, the eccentric vector ($v_{ecc}$) is introduced for balancing the task difficulties to fairly optimize all the tasks.\n\nRemark 1: The latent information needed in different tasks can be broadcasted across layers to improve the generalization of the model and the performance of every single task [10], [21]. Therefore, in addition to the design of optimization strategies, challenges also arise to designing the efficient MTL structure for knowledge sharing that benefits all the tasks [26]."}, {"title": "B. Backbone and Encoder", "content": "The backbone of radarODE-MTL is used to extract the latent features from the input SST spectrograms and is expected to figure out the remarkable patterns for vibrations $v_1$ and $v_2$ with certain central frequencies and periodicity. Specifically, ResNet is adopted in this work as the backbone and has been proven to be an efficient structure in computer vision or signal processing [32]\u2013[34]. Then, the encoder contains only one 2D convolutional layer to further compress the feature in the time-frequency domain into the 1D time domain for later processing. The performance has been verified in our previous work with the detailed structure shown in [5]."}, {"title": "C. Morphological Decoder", "content": "The morphological decoder has been designed in our previous work radarODE [5] as the single cycle ECG generate (SCEG) module to realize the robust domain transformation in a single cardiac cycle with a fast rate of convergence, because an ODE model is introduced in the ODE decoder to provide morphological feature as the prior knowledge to guide/constrain the ECG recovery. Similarly, in radarODE- MTL, a morphological decoder will be used to realize the mapping function $T(\u00b7)$ in Task 1 and generate morphological reference by fusing both temporal and morphological features, as shown in Figure 3(b)."}, {"title": "D. ECG Anchor Decoder and Cycle Length Decoder", "content": "The ECG anchor decoder and cycle length decoder are designed to identify the time-domain anchors $T_r^k$ and single-cardiac-cycle length $PPI_k$ in Task 2 and 3 simultaneously for the accurate alignment of ECG pieces as shown in Figure 3(c) and (d), avoiding the impact of error accumulation in long- term ECG recovery [5]. In addition, the prediction of the ECG anchors and cycle lengths can leverage the context information even if the current cardiac cycle is ruined by noises, because the vital signs are nearly unchanged for healthy people in successive cardiac cycles [8].\n\nThe structures of the ECG anchor decoder and cycle length decoder are the same as shown in Figure 3(c) and (d), with several layers of 1D CNN-based encoder/decoder followed by a linear projection block. Specifically, the encoder is assembled by four 1D CNN blocks with each block containing 1D convolution, batch normalization (BN) and rectified linear unit (ReLU) activation function; the decoder is composed of two 1D transposed CNN blocks with each block containing 1D transposed convolution, BN and ReLu; and the linear projection block is assembled by linear layer, BN and ReLU with one linear layer appended at last as the output layer."}, {"title": "E. Input, Output and Loss Function", "content": "The inputs of radarODE-MTL are the 4-sec segments divided from long-term radar signal with a step length of 1 sec, and the middle cardiac cycle is selected as the ground truth ECG piece. Then, to calculate the loss value, the ground truth ECG piece should be resampled as a fixed length 200 to match the output dimension, and the RMSE is used to calculate $L_1$. The output of the ECG anchor decoder should contain multiple predicted anchors within 4-sec segment, and the cross-entropy loss is used for $L_2$ calculation as a multi- class classification problem (i.e., each time index acts as a possible class). Differently, the output of the cycle length decoder only represents the length of the current evaluated cardiac cycle with only one true label (value = 1), and the cross-entropy loss is used for $L_3$ calculation as a one-class classification problem.\n\nEventually, the calculated $L_1, L_2, L_3$ will be used for optimization using the later proposed EGA strategy during training, otherwise the three outputs can directly form the long-term ECG recovery by aligning the recovered ECG pieces (Task 1) with the predicted anchors (Task 2) after resampling the ECG pieces as the cycle lengths (Task 3)."}, {"title": "F. Eccentric Gradient Alignment (EGA) Strategy", "content": "According to the discussion in Section II-B, the imbalanced difficulties among three tasks will raise a new challenge to not only simultaneously optimize all the tasks without negative transfer [25], but also keep improving the hard tasks even if the easy tasks have already achieved convergence.\n\nIn this case, EGA first needs to solve the gradient conflict and magnitude dominance within the original task-specific gradients $g_1, g_2, g_3$ as shown in Figure 4(a), e.g., $g_1$ and $g_2$ may have opposite directions hence canceling with each other, and $g_3$ may have a large magnitude hence dominating the linear combination of all the gradients, with the resultant $\\tilde{g}_{joint}$ leaning on $g_3$. A common solution is to project all the gradients into an orthogonal space to eliminate gradient conflict [21], [35], and hence the optimization based on $\\tilde{g}_{joint}$ will not degrade any of the tasks. Then, the magnitude of the gradients will be unified as the same value (e.g., $\\tilde{g}$) to obtain new task-specific gradients $\\tilde{g}_1, \\tilde{g}_2, \\tilde{g}_3$, as shown in Figure 4(b).\n\nFurthermore, instead of categorically selecting the hard task based on the learning rate and only increasing the corresponding weight, EGA creatively provides an adjustable estimation of the intrinsic task difficulty by mapping the learning rate through a softmax with hyperparameter $T$. In other words, suitable intrinsic task difficulty can be obtained by adjusting $T$ without knowing the actual optimization status (i.e., stall or convergence), and the discrepancy among task difficulties can be adjusted to avoid overlooking or overrating any task. In practice, to integrate the estimated intrinsic task difficulty with MTL optimization, EGA proposed to add an eccentric vector $v_{ecc}$ to eccentrically align the joint gradient $\\acute{g}_{joint}$ to the hard task, as shown in Figure 4(c).\n\nThe detailed EGA strategy will be explained in this section in terms of the preparation stage, gradient projection and normalization, and eccentric gradient alignment.\n\n1) Preparations for EGA Optimization: As a gradient- based MTL optimization method with objective function in (5), EGA requires to access task-specific gradient in terms of the shared parameters $\\theta$, and the gradients can be obtained as $g_i = \\nabla_{\\theta}L_i(\\theta)$, $i \\in [n]$, forming the original gradient matrix as $G = \\{g_1,...,g_n\\} \\in \\mathbb{R}^{n \\times m}$. Then, the joint gradient for optimizing the shared parameter space can be linearly combined as $g_{joint} = Gw$, with $w = [1,...,1]^T$ representing the weights for each $g_i$. The original gradient matrix $G$ normally has gradient conflict and magnitude dominance issues, as shown in Figure 4(a).\n\n2) Gradients Projection and Normalization: In order to solve the conflict inside the gradient matrix $G$, the orthogonal projection problem can be formulated as finding a gradient matrix $\\acute{G}$ with the new joint gradient $\\acute{g}_{joint} = \\acute{G}^Tw$ close to the original $g_{joint}$:\n\n$\\underset{G}{min} ||g_{joint} - \\acute{g}_{joint}||^2 \\quad s.t.\\quad \\acute{G}\\acute{G}^T = I$                                                                         (6)\n\nThen, according to the derivation based on triangle inequality:\n\n$||g_{joint} - \\acute{g}_{joint}||^2 = ||G^Tw - \\acute{G}^Tw||^2 < ||G^T - \\acute{G}^T||_F^2||w||^2$                                                                 (7)\n\nAt last, the projection problem can be finally formulated as:\n\n$\\underset{G}{min} ||G - \\acute{G}||_F^2 \\quad s.t.\\quad \\acute{G}\\acute{G}^T = I$                                                                            (8)\n\nThe solution to the problem in (8) has been given in the orthogonal Procrustes problem [36] by simply applying singular value decomposition (SVD) to $G$ as:\n\n$G = UE V^T$                                                                                               (9)\n\nThen, the orthogonal gradient matrix $\\acute{G}$ with unit singular values can be obtained as:\n\n$\\acute{G} = UV^T$                                                                                              (10)\n\nIn addition, the calculation can be simplified by applying the eigenvalue decomposition to the Gram matrices $GG^T$ as:\n\n$GG^T = U (\\Sigma \\Sigma^T) U^T$                                                                                     (11)\n\nThen, the final solution in (10) can be rewritten by combining (9) and (11) as:\n\n$\\acute{G} = U\\Sigma^{-1} U^T G$                                                                                            (12)\n\nThe current $\\acute{G}$ in (12) is orthogonal but with unit singular values, and the next step is to re-scale the task-specific gradients to avoid magnitude dominance. According to the literature [21], the original magnitude of task-specific gradients is proportional to the singular values of $\\Sigma$. Therefore, to ensure the convergence to the optima of all the tasks, the minimal singular value is selected to calculate the scaling factor instead of using the original singular values, and the re-scaled $\\tilde{G}$ can be obtained as:\n\n$\\tilde{G} = \\acute{g} U \\Sigma^{-1} U^T G$, with $\\acute{g} = min(\u221aeigenvalue(GG^T))$                                                 (13)\n\nAt last, the orthogonal gradient matrix with equal magnitude is shown in Figure 4(b), but all the tasks are currently compromised on the same learning rate, causing the stall of the optimization for certain hard tasks.\n\n3) Eccentric Gradient Alignment: To estimate the intrinsic task difficulty, the first step is to assess the current learning rate $lri$ based on the loss value $L_i$ of each task:\n\n$lri(t - 1) = \\frac{L_i(t - 1)}{L_i(t_{warm})}$                                                                                                    (14)\n\nwith $L_i(t-1)$ and $L_i(t_{warm})$ representing the loss value for Task $i$ at the previous epoch and the warmup epoch (e.g., $t_{warm} = 4$ in this paper), and the $lri$ is inversely proportional to the learning rate (i.e., small $lri$ for fast learning rate). Then, a softmax function is applied to mapping the $lri$ to the intrinsic task difficulty $k_i$ as:\n\n$k_i(t) = softmax(lri(t - 1)) = \\frac{exp(lri(t-1)/T)}{\\sum_{j=1}^n exp(lrj(t-1)/T)}$                                                        (15)\n\nwith $T$ controlling the discrepancy of the mapped task difficulties (i.e., small $T$ enlarges the discrepancy between $k_i$), and the summation of the weights should be $\\sum_{i=1}^n k_i = n$. In addition, the intrinsic task difficult $k_i$ is positive without the negative transfer issue and can be formed as eccentric vector $v_{ecc} = [k_1,...,k_n]$ as in Figure 4(c) to guide the final joint gradient $\\acute{g}_{ecc}$ for optimization as $\\acute{g}_{ecc} = \\acute{G} V_{ecc}$. At last, the optimal parameter set $\\theta^*$ for updating the shared parameter space can be obtained after providing a step length $\u03b7$ based on the current parameter set $\\theta$ as $\\theta^* = \\theta - \\acute{g} _{ecc}$.\n\nThe entire EGA optimization strategy is summarized in Algorithm 1 to repeatedly update the shared parameter space"}, {"title": "IV. EXPERIMENTAL SETTING AND RESULT EVALUATION", "content": ""}, {"title": "A. Dataset and Implementation", "content": "1) Dataset: MMECG [2] is a dataset used for radar-based ECG recovery and is collected by TI AWR-1843 radar with 77Ghz start frequency and 3.8GHz bandwidth. In addition, the respiration noise has been filtered in pre-processing, but this dataset still contains signals with low SNR or RBM noise. NYUv2 [12] is a dataset for indoor scene understanding recorded using the RGB and Depth cameras and has been widely used as a unified task for validating MTL optimization strategies based on the performance of semantic segmentation, depth estimation, and surface normal prediction [21]\u2013[28].\n\n2) Implementation Details: The proposed radarODE-MTL along with the radarODE [5] and MMECG [2] are coded using PyTorch and trained on the NVIDIA RTX A4000 (16GB) for 200 epochs with batch size 32, SGD optimizer [37], learning rate 5 \u00d7 10\u22123, weight decay 5 \u00d7 10-4 and momentum 0.937. The dataset is split into training, validation and testing sets following 80%: 10%: 10%. At last, the Python package NeuriKit2 [9] is applied to all the evaluations regarding ECG signals, such as the identification of single cardiac cycles, PQRST peaks detection and heart rate estimation.\n\nThe deep learning framework used for scene understanding is implemented in [10] with many popular MTL optimization strategies embedded for comparison. The training is on the same GPU as before with 200 epochs, batch size 18, Adam optimizer [38], learning rate 10-4 and weight decay 10-5."}, {"title": "B. Performance of EGA", "content": "1) Radar-based ECG Recovery: The performance of EGA is evaluated on three tasks in terms of different metrics: RMSE/PCC for the recovered single-cycle ECG pieces, absolute PPI Error for the cycle lengths estimation and absolute Timing Error and missed detected rate (MDR) for the anchors prediction, with the corresponding comparison across other MTL optimization strategies as shown in Table I. In addition, the last column \u0394m% in Table I shows a comprehensively assessment across n tasks and is calculated as:\n\n$\\Delta m\\% = \\frac{1}{n}\\sum_{i=1}^n\\sum_{j=1}^{n_i}S_{i,j} \\frac{M_{m,i,j} - M_{b,i,j}}{M_{b,i,j}} \\times 100\\%$                                                             (16)\n\nwhere $n_i$ is the number of metrics for task i, $M_{m,i,j}$ means the performance of a method m on the task i measured with the metric j, $M_{b,i,j}$ represents the performance for the single- task baseline, and $S_{i,j} = 1/0$ if lower/higher values are better for the current metric (indicated by \u2193/ \u2191).\n\nIn general, the proposed EGA strategy meets the expectation by adjusting the value of $T$ with the following evaluations:\n\n\u2022 EGA with T = 1.0 achieves the largest improvement of Am% but none of the individual metrics gets the best or second-best result, and T = 1.0 can be viewed as a suitable estimation of intrinsic task difficulty, earning unbiased improvements on all tasks.\n\n\u2022 EGA with T = 0.5 obtains the second-best overall improvement and becomes the best in learning ECG mor- phological features according to RMSE/PCC, indicating T = 0.5 slightly overrates the difficulty of Task 1.\n\n\u2022 EGA with T = 0.1 cannot balance the task difficulties, hence getting a low score.\n\n\u2022 EGA with large T values (1.5 and 2.0) tend to evenly distribute the task difficulty weights, and the performance should be similar to other orthogonality-based method (e.g., Aligned-MTL)."}, {"title": "D. Noise Robustness Test", "content": "In this work, 10 trails (No. 75 - 84) are selected for the noise robustness test by adding different types of synthesized noises with certain decibel (dB).\n\n1) Constant Noise: The constant noise normally affects the SNR of the signal, and can be simulated by adding Gaussian noise with different intensities as implemented in [6], [19], [40]\u2013[42]. The baseline results for three frameworks are firstly obtained in terms of the RMSE, PCC, R-peak error and MDR as shown in Table III, and Am% is calculated as 0%, 7.47% and 10.64% as indicated by the initial points in Figure 8. Then, the Gaussian noises with 6 to -3dB are added into the raw radar signal without retraining the deep-learning framework, and the results are shown in Table III with the trends of performance degradation shown in Figure 8.\n\nA general observation of Table III is that all the frameworks perform well before 0dB with a similar degradation rate as in Figure 8(a). Then, radarODE-MTL could still provide reasonable results with mild degradation after 0dB because the MTL paradigm split the ECG reconstruction task into several sub-tasks, and each task can either be constrained by prior knowledge or leverage the information from context data with less pollution. In contrast, radarODE could generate high-fidelity ECG pieces as claimed in [5] and gets the second best baseline result in Table III, but the design of PPI estimation stage does not consider the noise robustness. Therefore, the performance is heavily dropped to the worst in Figure 8(a) because of the bad results of Peak Error as shown in Table III. Lastly, the MMECG considers the ECG recovery as an arbitrary domain transformation problem without any constraints in the network design, and the performance also heavily degrades in Figure 8(a) because only meaningless results will be generated as shown previously in Figure 5(a).\n\n2) Abrupt Noise: In this part, the Gaussian noises with different intensities (0 and -9dB) are used to simulate mild body movement (e.g., during talking or writing) and extensive body movement (e.g., during torso movement) as suggested in the literature [43]. Only 20% of the segments randomly selected from one trial are doped, and the duration of noise varies from 1 to 3 sec.\n\nFor mild body movement, the experimental results are shown in Table IV with the changes of Am% shown in Figure 8(b). Firstly, it is evident that the impact of 1-sec abrupt noise is limited for all the frameworks, and the results for ODE-based methods are almost equivalent to the baselines. Secondly, 2-sec noise starts to have a noticeable impact on MMECG, while the ODE-based methods could preserve the performance on the morphological features (RMSE/PCC) with small degradation on the Peak Error and MDR. Lastly, 3-sec noise has distorted 3/4 of the input radar segment, and the performances of MMECG and radarODE drop obviously as shown in Figure 8(b), while radarODE-MTL only loses some points on MDR = 5.12% as shown in Table IV."}, {"title": "V. CONCLUSIONS", "content": "This paper investigates the radar-based ECG monitoring technique and proposes a deep-learning framework radarODE-MTL to provide accurate ECG monitoring under noises. The radarODE-MTL adopts the MTL paradigm to realize the ECG reconstruction through 3 sub-tasks, and a novel optimization strategy called EGA is also proposed to simultaneously op- timize all the tasks without stall or negative transfer issues. The performance of EGA has been evaluated on various MTL tasks, and the experimental results evidence that EGA is competitive with other state-of-the-art optimization strategies on the unified task and achieves outstanding results on radar- based EGA recovery with unbalanced task difficulties. In addition, the well-trained radarODE-MTL could provide long- term ECG reconstructions with high fidelity in terms of MDR, morphological similarity and peak accuracy. Lastly, this is the first study that conducts noise-robustness tests for deep- learning frameworks, and the proposed radarODE-MTL could also achieve reasonable ECG recovery with mild degradation under constant and abrupt noises. In the future, the proposed method needs to be verified for patients with cardiovascular diseases to enable potential clinical use."}]}