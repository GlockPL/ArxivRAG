{"title": "Learning Granularity Representation for Temporal Knowledge Graph Completion", "authors": ["Jinchuan Zhang", "Tianqi Wan", "Chong Mu", "Guangxi Lu", "Ling Tian"], "abstract": "Temporal Knowledge Graphs (TKGs) incorporate temporal information to reflect the dynamic structural knowledge and evolutionary patterns of real-world facts. Nevertheless, TKGs are still limited in downstream applications due to the problem of incompleteness. Consequently, TKG completion (also known as link prediction) has been widely studied, with recent research focusing on incorporating independent embeddings of time or combining them with entities and relations to form temporal representations. However, most existing methods overlook the impact of history from a multi-granularity aspect. The inherent semantics of human-defined temporal granularities, such as ordinal dates, reveal general patterns to which facts typically adhere. To counter this limitation, this paper proposes Learning Granularity Representation (termed LGRe) for TKG completion. It comprises two main components: Granularity Representation Learning (GRL) and Adaptive Granularity Balancing (AGB). Specifically, GRL employs time-specific multi-layer convolutional neural networks to capture interactions between entities and relations at different granularities. After that, AGB generates adaptive weights for these embeddings according to temporal semantics, resulting in expressive representations of predictions. Moreover, to reflect similar semantics of adjacent timestamps, a temporal loss function is introduced. Extensive experimental results on four event benchmarks demonstrate the effectiveness of LGRe in learning time-related representations. To ensure reproducibility, our code is available at https://github.com/KcAcoZhang/LGRe.", "sections": [{"title": "1 Introduction", "content": "Temporal Knowledge Graphs (TKGs) [13,2] extend KGs with temporal information t, to indicate the dynamics and evolutionary patterns of real-world facts. TKGs commonly represent facts as quadruples like (subject, relation, object, timestamp), i.e., (s, r, o, t), broadening the perspective of knowledge-based downstream applications [18,16]. Nevertheless, TKGs still face the challenge of incompleteness, necessitating efficient methods to complete missing quadruples. Involving reasoning about missing entities at known or future timestamps, the link prediction task of TKGs can be divided into interpolation and extrapolation. Notably, this paper focuses on interpolation, also known as TKG completion, which can be regarded as a temporal extension of KG completion.\nAddressing the incompleteness of TKGs necessitates consideration of the temporal evolution of facts. Consequently, numerous methods conceptualize dynamics as transformations within semantic space, incorporating temporal information into the translation [7,5], rotation [11,20,19], or decomposition [23,25,24] of facts in Euclidean or Complex spaces, employing specialized score functions. Building upon these KG-derived approaches, more advanced techniques utilize Convolutional Neural Networks (CNNs) [9] or Graph Neural Networks (GNNs) [17] to uncover more complex patterns within temporal information. However, most existing approaches treat time as an independent embedding, merely considering its fusion with entities and relations to represent dynamic knowledge. Furthermore, they often overlook the latent impact of multi-granularity temporal information (e.g., ordinal dates) inherent in real-world facts.\nIn reality, the periodicity and variability in these granularities reveal general patterns to which facts typically adhere, with the semantics of real-world facts being closely associated with their multi-granularity temporal attributes. To make accurate predictions, these granularities should be considered collectively. For instance, as illustrated in Figure 1, the query (Barack Obama, Make a visit, ?) exhibits varying semantics at different granularities (year, month, and day) of history.\nTo tackle these limitations, we propose an effective method that delves into Learning Granularity Representation (LGRe). The model consists of two consecutive modules centered around temporal information: a) Granularity Representation Learning (GRL) that employs multi-layer CNNs parametered by temporal semantics, to capture the correlations among entities, relations and time within facts and further learn representations belonging to different granularities (i.e., year, month or day); b) Adaptive Granularity Balancing (AGB) that distinguishes the contributions of representations at different granularities to predictions based on temporal semantics. Additionally, we design a specific temporal loss function to optimize the embeddings of time based on the similarity constraints of adjacent timestamps. Extensive evaluations conducted on four event-based benchmark datasets demonstrate the superiority and effectiveness of LGRe. The contributions of this paper can be summarized as follows:\nWe propose LGRe, a simple yet effective TKG completion method that sufficiently discovers representations at different granularities of TKGs.\nThrough time encoding and adaptive granularity balancing, LGRe effectively allocates predictive contributions from various temporal granularities.\nExperiments on four widely-used TKG benchmarks demonstrate that LGRe outperforms state-of-the-art TKG completion baselines, showcasing its superiority in learning time-related representations."}, {"title": "2 Related Work", "content": "KG completion task, also known as link prediction, has been widely studied to infer missing facts based on existing knowledge. This task is divided into completions on static KGs and TKGs due to the dynamics of knowledge."}, {"title": "2.1 Static KG Completion", "content": "Static KG completion models focus on representing correlations between entities and relations within triples. Translation-based approaches, such as TransE [1], view objects as the result of transformations of subjects and relations in euclidean embedding space. Additionally, methods such as semantic matching [22], tensor decomposition [14], and complex space embedding [26,12] offer different perspectives on analyzing latent interactions within triples. Neural network models, such as ConvE [4] and CompGCN [15], demonstrate the effectiveness of Convolutional Neural Networks (CNNs) and Graph Neural Networks (GNNs) in learning interactions among entities and relations, or among neighboring facts. However, existing static methods still fall short in exploiting temporal information and capturing the evolutionary patterns of facts."}, {"title": "2.2 TKG Completion", "content": "In the realm of transformation, TTransE [7] is the first to propose the temporal ordering relation assumption (i.e., $r_{\\\u00bfT} \\approx r_j$), introducing time into the traditional translation model TransE. ChronoR [11] extends RotatE by incorporating time-parametrized rotation transformations. TA-DistMult [5] adapts DistMult to account for temporal information in learning relation types. HyTE [3], driven by the semantics of time, constructs temporally aware hyperplanes for each timestamp to represent the entity-relation space. DE-SimplE [6] introduces a diachronic function to represent entity embeddings at any temporal point. TComplEx [8], BDME [23], Joint-MTComplEx [25] and CEC-BD [24] employ tensor decomposition to involve temporal embeddings in quadruple embeddings. Building on this, TeLM [19] treats each relation as a dual multivector to enhance generalization in TKG representation. BoxTE [10] introduces unique temporal information for each relation using box embeddings. Recently, SANe [9] incorporates a time-aware parameter generator to capture the dynamic features of facts using CNNs, and TGeomE++ [21] leverages a geometric algebra-based product to model diverse entities, relations, and temporal dynamics. However, many facts exhibit different semantics at various temporal levels. Most existing methods treat the semantics of timestamps as holistic, independent vectors, neglecting to learn representations at different temporal granularities for each fact. This approach overlooks the analysis of how these varied granularities influence fact representation and reasoning."}, {"title": "3 Method", "content": "The framework of LGRe is shown in Figure 2. It maintains a simple encoder-decoder architecture containing two key modules: (a) Granularity Representation Learning (\u00a73.2), which captures interactions among entities, relations, and timestamps through multi-layer convolutional operators and generates representations at different granularities, and (b) Adaptive Granularity Balancing (\u00a73.3), which assigns different weights to representations based on embeddings of temporal semantics. Notably, the decoder only necessitates a simple linear transformation since the above modules effectively fuse the features of quadruples."}, {"title": "3.1 Notations", "content": "In this paper, Temporal Knowledge Graphs (TKGs) are represented as a set of quadruples with temporal information, denoted as $\\mathcal{G} = \\{(s,r,o,t)|s, o \\in \\mathcal{E}, r \\in \\mathcal{R}, t \\in \\mathcal{T}\\}$. Here, $\\mathcal{E}$, $\\mathcal{R}$, and $\\mathcal{T}$ represent the sets of entities, relations, and timestamps, respectively. Each quadruple $(s, r, o,t)$ in $\\mathcal{G}$ is distributed in a specific timestamp t. Given a query set $\\mathcal{Q} = \\{(s,r,?,t)|s \\in \\mathcal{E}, r \\in \\mathcal{R}, t \\in \\mathcal{T}\\}$, the objective of TKG completion is to predict the missing object o at some known timestamps, which is also considered as a link prediction task. In this paper, lowercase letters indicate corresponding semantics, and bold letters denote vectors. Table 1 summarizes the important notations. Notably, while we generally use object prediction as an example, both object and subject predictions are considered in our study."}, {"title": "3.2 Granularity Representation Learning", "content": "In practice, temporal information can represent potential periodic semantics (e.g., the same month each year or the same day each month). However, representing temporal information as a whole unit fails to capture these patterns effectively. Hence, we decompose time into the format \"year-month-day\", with each part denoting distinct semantics to preserve the integrity of the temporal information. The separated temporal embeddings are then combined into a sequence format and processed through a Gated Recurrent Unit (GRU) as follows:\n$\\big\\{y, m, d\\big\\} = GRU(\\big\\{y_{init}, m_{init}, d_{init}\\big\\}),$\nwhere $\\{y_{init}, m_{init}, d_{init}\\}$ are initial temporal embeddings from Xavier initialization. Then we combined all temporal embeddings with initial subject $s_{init}$ and relation $r_{init}$ to obtain the initial input of our CNNs:\n$\\mathbf{t} = \\sigma(\\mathbf{W}_{t}[\\mathbf{y}||\\mathbf{m}||\\mathbf{d}] + \\mathbf{b}_{t}),$\n$\\mathbf{r} = \\sigma(\\mathbf{W}_{r}[\\mathbf{r}_{init}||\\mathbf{t}] + \\mathbf{b}_{r}),$\n$\\mathbf{x}_{input} = [\\mathbf{s}_{init}||\\mathbf{r}],$"}, {"title": "3.3 Adaptive Granularity Balancing", "content": "As LGRe learns granularity representations from the above modules, they should be assigned different weights according to the temporal semantics to form the final representations of queries. The separate representations of time for each query are first transformed into a one-dimensional vector to indicate the weight of the corresponding granularities. The adaptive weight $\\{\\theta_y, \\theta_m, \\theta_d\\}$ of different granularities can be calculated as follows:\n$\\big\\{\\theta_y, \\theta_m, \\theta_d\\big\\} = \\sigma[\\mathbf{W}_y\\mathbf{y}||\\mathbf{W}_m\\mathbf{m}||\\mathbf{W}_d\\mathbf{d}],$\nwhere $\\mathbf{W}_y, \\mathbf{W}_m, \\mathbf{W}_d \\in \\mathbb{R}^{1\\times d}$ denote the linear transformations for different granularities, $\\sigma$ denotes softmax activation function.\nThe final output of our model can be calculated as follows:\n$\\mathbf{x}_{output} = \\sigma(\\theta_y\\mathbf{x}_y + \\theta_m\\mathbf{x}_m + \\theta_d\\mathbf{x}_d),$\nwhere $\\sigma$ denotes ReLU activation function. The sequential learning in our model in line with the rationality of Residual Connections. The final prediction scores can be represented as:\n$p(o|s,r,t) = \\sigma(\\mathbf{x}_{output} \\mathbf{E}^T),$\nwhere $\\sigma$ is Sigmoid function and $\\mathbf{E}$ denotes the transpose matrix of entity embeddings, used to represent the probability of each entity."}, {"title": "3.4 Training Objective", "content": "The main objective of training in LGRe is to minimize the negative log-likelihood loss function:\n$\\mathcal{L}_{main} = \\frac{1}{|\\mathcal{G}|} \\sum_{(s,r,o,t) \\in \\mathcal{G}} \\log p(o|s,r,t) + |\\mathcal{N}_{(s,r,t)}|\\sum_{\\hat{o} \\in \\mathcal{N}_{(s,r,t)}} \\log(1-p(\\hat{o}|s, r,t)),$\nwhere the loss measures the binary cross entropy between true targets and probabilities, simultaneously distancing the representation from negative samples $\\hat{o} \\in \\mathcal{N}_{(s,r,t)}$ corresponding to each query $(s,r,?,t)$.\nGiven the role of temporal representations in LGRe, it is crucial to include precise and comprehensive semantics in these representations and consistently optimize them. As our temporal embedding t is consist of separate embeddings of years, months and days to ensure the periodic semantics, the integrated representations of adajacent timestamps should be similar. Therefore, we propose a temporal loss function to smooth the temporal embeddings.\n$\\mathcal{L}_{T} = \\frac{1}{|\\mathcal{T}|-1}\\sum_{i=1}^{\\mathcal{T}-1} ||\\mathbf{t}_i - \\mathbf{t}_{i+1}||,$\nwhere ||\u00b7||p denote L-2 normalization. The overall loss $\\mathcal{L}$ of LGRe can be defined as:\n$\\mathcal{L} = \\mathcal{L}_{main} + \\alpha \\mathcal{L}_{T},$\nwhere \u03b1 is the coefficient of temporal regularization."}, {"title": "3.5 Complexity analysis", "content": "LGRe contains two main modules, Granularity Representation Learning (GRL) and Adaptive Granularity Balancing (AGB). We set batch size as m with embedding dimension d. The computational complexity of GRL is O(3md\u00b2 + Amd) since it employs GRU and convolutional operators. The complexity of AGB is O(md\u00b2+md) as we only use linear transformations and sum operations in AGB. The final prediction with transpose has a complexity of O(|E|md). Thus, the overall computational complexity of training can be simplified to O(md\u00b2 + (1+ |E|)md). Additionally, the space complexity of LGRe is O(|E|d+|R|d+|T|d) since we simultaneously consider entity, relation, and time encoding in our model."}, {"title": "4 Experiments", "content": null}, {"title": "4.1 Experimental Setup", "content": "In this section, we provide detailed description of benchmarks, baselines and evaluation metrics employed in our study, as well as the implementation details of the proposed LGRe."}, {"title": "4.2 Main Results", "content": "The main results for the four datasets are shown in Table 3 and Table 4. Above the middle horizontal line are completion methods on static KGs, while below are TKG completion methods. We observe that the early studies in TKG completion, which are mostly based on static methods, do not significantly outperform those static models. This indicates that simply introducing or combining time is not sufficient to capture temporal dependencies, as the unique dynamics in TKGs require deeper consideration. On this basis, newer studies that incorporate temporal information into entities and relations provide a more innovative use of time. Consequently, LGRe outperforms the static methods (e.g., QuatE) with significant average improvements of 57.39% and 93.69% on MRR and Hits@1 across all benchmarks, demonstrating the importance of considering temporal information from multiple perspectives. Additionally, compared with the SOTAs of TKG completion, LGRe still achieves average improvements of 1.83% and 2.59% on MRR and Hits@1, showcasing the effectiveness of considering the interactions between entities and relations at different time granularities.\nSpecifically, compared with these advanced methods on event-based datasets with multi-granularity in Table 3, LGRe excels at learning representations with complex interactions between entities and relations joint with different time granularities. This combination captures the dynamic knowledge within facts and reflects their evolutionary patterns. Furthermore, LGRe can assign different weights to these representations, as the semantics of the same entity or relation may change across different time granularities. As a result, it exhibits average improvements of 1.13% and 1.45% on MRR and Hits@1.\nMoreover, compared with SOTAs on common-sense and pedia KGs (in Table 4), which have coarse-grained but large time spans, LGRe achieves average improvements of 2.53% and 3.73% on MRR and Hits@1. The results show that LGRe can smooth the influence of large-grained time (e.g., \"year\") through pseudo-labels and uncover deeper associations using multi-layer convolutions to optimize the overall representation quality. Additionally, through the temporal loss, LGRe can model the similarity of timestamps in adjacent years. This allows the model to express similar semantics for recent facts with the combination of entities and relations, aligning with the evolution pattern of facts."}, {"title": "4.3 Ablation Study", "content": "To demonstrate the effectiveness of our key innovation and proposed modules, we conduct ablation studies on all benchmarks, which are shown in Table 5.\nEffect of RU. Relation Updating (RU) denotes the linear transformation and combination of our initial input in granularity representation learning, corresponding to equation (2). It is beneficial to capture a comprehensive representation of time from multiple granularities, endowing each fact with dynamism through multiple linear layers combined with relations and entities. The results show that RU enhances LGRe with average improvements of 0.68% and 0.99% on MRR and Hits@1, demonstrating the importance of representing dynamic knowledge in encoding. Notably, more significant improvements (1.05% and 1.71% on MRR and Hits@1) are achieved on YAGO1lk and Wikidata12k. Unlike ICEWS, both of these datasets span long time periods, while their facts are long-lived, potentially spanning multiple centuries. Therefore, incorporating temporal information into these facts is crucial to better reflect long-term dynamic semantics.\nEffect of AGB. Adaptive Granularity Balancing (AGB), which achieves average improvements of 1.37% and 1.28% on MRR and Hits@1, is used to assign different weight for representations from different granularities. Specifically, performance of AGB is more prominent on the multi-granularity or large-scale datasets like ICEWS05-15 (with improvements of 2.51% and 3.18% on MRR and Hits@1), which has a \"year-month-day\" granularity and across eleven years. This fine-grained raw time format highlights the effectiveness of AGB. Additionally, in YAGO1lk and Wikidata12k, AGB can smooth the effect of year by constant values of month and day to obtain better scores. Overall, the results demonstrate the importance of learning representations from different granularities, with varying degrees of attention.\nEffect of TL. Temporal Loss (TL) is employed to control the regularization coefficient in temporal representation learning. It ensures that adjacent timestamps have similar semantics, reflecting the similar characteristics of real-time adjacent facts. Consequently, TL enhances LGRe by 0.62% and 0.70% on MRR and Hits@1, demonstrating its effectiveness. Notably, TL shows even greater efficiency on pedia datasets, with gains of 0.85% and 0.96% on MRR and Hits@1. We suggest that due to the extremely large time span, the factual associations may expire and are more sensitive to temporal semantics. This observation aligns with the analysis in \"Effect of RU\"."}, {"title": "4.4 Sensitivity Analysis", "content": "In the sensitivity analysis, we assess the impact of the hyper-parameter \u03b1, which governs the temporal regularization coefficient to optimize temporal embeddings. The value is determined over a smaller scale range of {1e-5, 5e-5, 1e-4, 5e-4, ..., 0.1} to ensure that the main loss works. The results show that LGRe maintains stable performance across all benchmarks. Specifically, for the ICEWS datasets, which have finer time granularity but smaller time spans, the model is less sensitive to temporal semantic similarity. In contrast, for YAGO1lk and Wikidata12k, which have much larger time spans, the model is more sensitive to the learning of temporal semantics. Therefore, better time representation is beneficial to their overall performance."}, {"title": "4.5 Visualization of Weight Analysis", "content": "To investigate the effectiveness of considering multiple granularities for queries, as well as the unique influence from each granularity, we visualize the weight assignment of adaptive granularity balancing in LGRe. We adopt object prediction on ICEWS05-15 as an example, shown in Figure 4. The average weights for year, month, and day are 0.1573, 0.4394, and 0.4032, respectively. It can be observed that the weight of the year representation is lower than that of month and day in most cases. Additionally, for the latter two temporal semantics, 72.25% of queries rely more on month representations than day, indicating that many facts in real-world maintain similar semantics over longer periods (e.g., month). As a consequence, each fact exhibits unequal dependence on the three temporal representations, further demonstrating the importance of considering and distinguishing multiple granularities simultaneously."}, {"title": "5 Conclusion", "content": "In this paper, we propose LGRe, a simple yet effective method for TKG completion that excels at learning varied TKG representations based on different temporal granularities. It encompasses two key modules: 1) granularity representation learning, which achieves diverse representations of entities and relations at the granularity level according to discrete temporal semantics, and 2) adaptive granularity balancing, which adaptively generates corresponding weights for unique embeddings based on the temporal semantics of each granularity to make the final prediction. Extensive experiments on four datasets with dynamic knowledge demonstrate the superiority and effectiveness of LGRe. Future research directions include investigating more efficient encoding methods for entities and relations, and exploring deeper dynamic interactions between entities."}]}