{"title": "On Tradeoffs in Learning-Augmented Algorithms", "authors": ["Ziyad Benomar", "Vianney Perchet"], "abstract": "The field of learning-augmented algorithms has gained significant attention in recent years. These algorithms, using potentially inaccurate predictions, must exhibit three key properties: consistency, robustness, and smoothness. In scenarios where distributional information about predictions is available, a strong expected performance is required. Typically, the design of these algorithms involves a natural tradeoff between consistency and robustness, and previous works aimed to achieve Pareto-optimal tradeoffs for specific problems. However, in some settings, this comes at the expense of smoothness. In this paper, we demonstrate that certain problems involve multiple tradeoffs between consistency, robustness, smoothness, and average performance.", "sections": [{"title": "Introduction", "content": "Many decision-making problems under uncertainty are commonly studied using competitive analysis. In this context, the performance of online algorithms, operating under uncertainty, is compared to that of the optimal offline algorithm, which has full knowledge of the problem instance. While competitive analysis provides a rigorous method for evaluating online algorithms, it is often overly pessimistic. In real-world scenarios, decision-makers can have some prior knowledge, though possibly imperfect, about the complete problem instance. For example, predictions of unknown variables might be obtained via machine learning models, or an expert might provide advice on the best course of action. This more realistic setting was formalized by Lykouris and Vassilvtiskii [2018] and Purohit et al. [2018] leading to the development of what is now known as learning-augmented algorithms. In this paradigm, the algorithm receives predictions about the current problem instance, but without any guarantees on their accuracy, and must satisfy three main properties:\n\u2022 Consistency: perform almost as well as the optimal offline algorithm if the predictions are perfect.\n\u2022 Robustness: maintain a performance level close to the worst-case scenario without predictions when the predictions are arbitrarily bad.\n\u2022 Smoothness: the performance should degrade gracefully as the prediction error increases.\nConsistency, robustness, and brittleness. Consider a minimization problem under uncertainty, and let ALG be an algorithm augmented with a prediction y of an unknown parameter x. The input of the algorithm can contain parameters other than x, but for simplicity, we denote by ALG(x, y) the value of the objective function achieved by ALG, and OPT(x) the value of the optimal offline algorithm. The consistency c and robustness r of ALG are defined as\n$c = \\sup_{x} \\frac{ALG(x, x)}{OPT(x)}$ and $r = \\sup_{x,y} \\frac{ALG(x, y)}{OPT(x)}$\nConsistency is the worst-case ratio when the prediction is perfectly accurate, i.e. y = x, while robustness is the worst-case ratio with adversarial prediction. Most research on learning-augmented algorithms focuses on achieving good tradeoffs between consistency and robustness. Some studies also establish algorithms with"}, {"title": "1.1 Contributions", "content": "In this work, we explore various tradeoffs that arise in the design and analysis of learning-augmented algorithms. While existing literature has primarily focused on the tradeoff between consistency and robustness, our investigation centers on the tradeoffs between consistency and smoothness, as well as the relationships between the standard criteria for learning-augmented algorithms namely consistency, robustness, and smoothness and their average performance under stochastic assumptions regarding predictions.\nWe begin by examining the line search problem, revisiting the algorithm proposed by Angelopoulos et al. [2019]. This algorithm achieves a Pareto-optimal tradeoff between consistency and robustness among deterministic algorithms, but we demonstrate that it is inherently brittle. We show that this brittleness can be mitigated by introducing randomness into the predictions used by the algorithm. The variance of this randomization is quantified by a parameter $p \\geq 0$. Our analysis reveals that tuning this parameter leads to opposing effects on the consistency and smoothness of the algorithm, thus yielding a tradeoff between these two criteria.\nNext, we apply a similar approach to the one-max search problem. We examine the Pareto-optimal algorithm introduced by Sun et al. [2021], and we show its brittleness. Furthermore, we demonstrate how randomization can be used to guarantee smoothness at the cost of consistency. Once again, the resulting tradeoff is governed by a parameter $p \\geq 0$.\nFinally, we address the ski-rental problem, proposing an algorithm that generalizes that of Purohit et al. [2018]. Through a tight analysis of its performance, we prove that the Pareto-optimal tradeoff between consistency and robustness can be achieved with different levels of smoothness. However, we show that striving for optimal smoothness degrades the average-case performance of the algorithm, assuming that the prediction induces the correct decision (renting or buying at time 0) with a probability $Q \\in [\\frac{1}{2}, 1]$. In this context, a parameter $p \\in [0,1]$ can be utilized to tune the levels of smoothness and average-case performance, all while maintaining fixed levels of consistency and robustness.\nAdditionally, we conduct numerical experiments for the three problems studied in the paper, highlighting the various tradeoffs demonstrated in our analysis."}, {"title": "1.2 Related work", "content": "Learning-augmented algorithms. The design of learning-augmented algorithms [Lykouris and Vassil- vtiskii, 2018, Purohit et al., 2018] relies on using machine-learned advice to go beyond worst-case limitations. These algorithms operate under the assumption that the decision-maker has access to noisy predictions about certain problem parameters. The goal of learning-augmented algorithms is to improve performance if the predictions are accurate, while also ensuring robustness in the face of incorrect or adversarial predictions. Many fundamental algorithmic problems were studied in this setting, such as ski rental [Gollapudi and Panigrahi, 2019, Diakonikolas et al., 2021, Antoniadis et al., 2021, Shin et al., 2023], caching [Lykouris and Vassilvtiskii, 2018, Chlkedowski et al., 2021, Antoniadis et al., 2023b,a], scheduling [Purohit et al., 2018, Merlis et al., 2023, Lassota et al., 2023, Benomar and Perchet, 2024], and the design of data structures [Kraska et al., 2018, Lin et al., 2022, Zeynali et al., Benomar and Coester, 2024].\nOvercoming brittleness. Pareto-optimal tradeoffs between consistency and robustness were studied in [Angelopoulos et al., 2019, Bamas et al., 2020, Wei and Zhang, 2020, Sun et al., 2021, Angelopoulos, 2023]. However, the proposed algorithms do not always have smoothness guarantees. For example, Angelopoulos et al. [2024a] proved that any Pareto-optimal algorithm for the one-way trading problem is necessarily brittle (Definition 1.1). In this paper, we will show in the line search and in the one-max search problems how a randomized deviation from the Pareto-optimal algorithm allows for overcoming brittleness. A similar approach was used to guarantee smoothness in non-clairvoyant scheduling with limited predictions [Benomar and Perchet, 2024].\nLine search. The line search problem [Beck, 1964], also known as the cow path problem, consists of finding a hidden target on an infinite line starting from an initial position, without any information regarding the direction or distance to the target. The goal is to minimize the total distance traveled before reaching the target. The best deterministic algorithm is based on doubling the search distance in alternating directions, and it ensures a competitive ratio of 9 [Beck and Newman, 1970, Baezayates et al., 1993]. The line search problem has been extensively studied in the learning-augmented framework with different types of predictions [Angelopoulos, 2023, Angelopoulos et al., 2024b].\nOne-max search. In the one-max search problem [El-Yaniv et al., 2001], the decision-maker observes a sequence of adversarially chosen prices $p_1,...,p_n \\in [L,U]$, with $0 < L < U$. At each step i, the price $p_i$ is revealed to the decision-maker, and the latter can decide to stop the game and have a payoff of $p_i$, or reject it irrevocably and move to the next observation. The best deterministic algorithm for this problem consists simply in selecting the first price larger than $\\sqrt{LU}$, which guarantees a payoff of at least $\\sqrt{L/U} \\max_{i \\in [n]} p_i$ This problem, as well as its randomized version\u2014online conversion\u2014were studied in the learning-augmented setting with a prediction of the maximal price [Sun et al., 2021].\nSki-rental In the ski-rental problem, the decision maker faces a daily choice between renting a ski at a unit cost or buying it for a one-time cost of b, after which skiing becomes free. The length of the ski season, x, is unknown, and the goal is to minimize the total cost of renting and buying. A straightforward algorithm for this problem is renting for the first b-1 days and then buying at day b, resulting in a competitive ratio of 2, which is the best achievable by any deterministic algorithm Karlin et al. [1988]. The best competitive ratio with randomized algorithms is $\\frac{e}{e-1}$ [Karlin et al., 1994]."}, {"title": "2 Smooth Algorithm for Line Search", "content": "In the line search problem, a target is hidden in an unknown position $x \\in \\mathbb{R}$ on the line, with $|x| \\geq 1$, and the searcher, initially at the origin of the line O, must find the target, minimizing the total traveled distance. The optimal offline algorithm only travels a distance of $|x|$ to find the target. On the other hand, the searcher, ignoring if x is to the left or the right side of O, must alternate the search direction multiple times before finding the target. Any deterministic algorithm for this problem can be defined as an iterative strategy, parameterized by an initial search direction $s_0 \\in \\{-1,1\\}$ and a sequence of turn points $(d_i)_{i \\in \\mathbb{N}} \\in [1,\\infty]^{\\mathbb{N}}$. At"}, {"title": "2.1 Brittleness of the Pareto-optimal algorithm", "content": "In the following, we will prove that $A_{LS}$ is brittle, in the sense of Definition 1.1, then we will demonstrate how a simple randomization idea enables making the algorithm smooth. To better understand the impact of the prediction error on the performance of $A_{LS}$, we first prove an expression of $A_{LS}(x, y)/x$ as a function of y and x.\nLemma 2.1. Let $x > 1, y > 0$ and $j = \\lfloor \\log_{b^2}(x/y)\\rfloor \\in \\mathbb{Z}$, so that $1 < \\frac{x}{b^{2j} y} < b^2$. It holds that\n$\\frac{A_{LS}(x, y)}{x} = 1 + \\frac{2 b^2}{b-1} - \\frac{2 b^2}{b-1} \\frac{(b^{2(j-1)} y)}{x} + o(1/x)$."}, {"title": "2.2 Smoothness via randomization", "content": "In all the following, we assume without loss of generality that $x > 0$. The worst-case ratio $A_{LS}(x, y)/x$, given in Proposition 2.2, occurs when $x = y + \\epsilon$ with $\\epsilon$ arbitrarily small. To avoid it, we perturb y and run instead the algorithm $A_{LS}$ with a randomized prediction of the form $\\tilde{y} = (1 + \\rho \\xi)y$, where $\\rho > 0$ is a hyperparameter and $\\xi$ a positive random variable.\nTheorem 2.3. Let $b \\geq 2$, $\\rho \\in [0, 1]$, and $\\xi$ a random variable with tail distribution $\\Pr(\\xi > t) = \\frac{1}{(1+t)^2}$ for all $t \\geq 0$. Then for any $x \\geq 1$ and $y \\in \\mathbb{R}$, denoting by $\\eta = |x - y|$, we have for $\\tilde{y} = (1 + \\rho \\xi)y$ that\n$\\mathbb{E}_{\\xi} [\\frac{A_{LS}(x, \\tilde{y})}{x}] < \\frac{b + 1 + 2 \\rho}{b-1} + \\begin{cases} \\frac{2(1+\\rho)}{b-1} \\frac{\\eta}{x} & \\text{if } y \\geq x\\\\ \\frac{4(b+1)}{\\rho} \\frac{\\eta}{x} & \\text{if } y < x \\end{cases}$"}, {"title": "3 Smooth Algorithm for One-Max Search", "content": "In the one-max search problem, a decision-maker sequentially observes prices $P_1,...,P_n \\in [L,U]$, where $0 < L < U$, and upon observing each price $p_i$ they must decide either to select it, halting the process and receiving a payoff of $p_i$, or to reject it irrevocably and move on to the next price."}, {"title": "3.1 Brittleness of the Pareto-optimal algorithm", "content": "We will prove in the following that this algorithm is brittle, and we will show, similarly to the line search problem, how this brittleness can be overcome via randomization. In the following, we simply write c, r instead of c(\u03bb), r(\u03bb), and we denote by \u03b7 := |p* - y| the prediction error. Our first result is that the competitive ratio of $A^M_{\\lambda}$ degrades smoothly as a function of the prediction error when $y \\in [1, \\frac{1}{r})$. Then, we will prove the brittleness of the algorithm in Proposition 3.3 by considering $y \\geq \\frac{1}{r}$. The following lemma shows smoothness for $y \\in [1, \\frac{1}{r})$.\nLemma 3.1. If $y \\in [1, \\frac{1}{r})$, then\n$\\frac{A^M_{\\lambda}(P, y)}{p^*} \\geq c - c \\frac{\\eta}{p^*}$\nProof. If $y \\in [1, \\frac{1}{c})$, then $\\Phi(\\lambda, y) = \\frac{1}{c}$. If $p^* < \\frac{1}{c}$ then all the observed prices are below the threshold, and the algorithm selects $p_n$, which is 1 in the worst case, hence\n$\\frac{A^M_{\\lambda}(P, y)}{p^*} \\geq \\frac{1}{p^*} \\geq c$.\nOn the other hand, if $p^* \\geq \\frac{1}{c}$, then the value selected by the algorithm is at least $\\frac{1}{c}$ and\n$\\frac{A^M_{\\lambda}(P, y)}{p^*} \\geq \\frac{1/c}{p^*} = \\frac{c}{p^*} = 1 - \\frac{c\\eta}{p^*}$"}, {"title": "3.2 Smoothness via randomization", "content": "As we proved in Lemmas 3.1 and 3.2, if $y \\in [1, \\frac{1}{r})$ then performance of $A^M_{\\lambda}$ degrades smoothly with the prediction error. The brittleness of $A^M_{\\lambda}$ in Proposition 3.3 arises in the case where $y \\in [\\frac{1}{r}, \\theta]$: the ratio $A^M_{\\lambda}(P, y)/p^*$ is larger than c for $p^* > \\frac{1}{r}$, but it drops immediately to r for $p^* < \\frac{1}{r}$, even arbitrarily close to $\\frac{1}{r}$.\nTo attenuate this extreme behavior, we randomize the threshold used when $y \\in [\\frac{1}{r}, \\theta]$. Let $A_{\\lambda,\\rho}^M$ the algorithm accepting the first price at least equal to the random threshold $\\Phi(\\lambda, \\rho, y)$ defined by\n$U \\sim U[0, 1], \\hspace{0.5cm} \\Phi(\\lambda, \\rho, y) = \\begin{cases} \\Phi(\\lambda, y) & \\text{if } y \\in [1, \\frac{1}{r}) \\\\ \\frac{e^{-\\rho U}}{r} & \\text{if } y \\in [\\frac{1}{r}, \\theta] \\end{cases}$\nIf $y \\in [1, \\frac{1}{r})$, then $A_{\\lambda,\\rho}^M$ is equivalent to $A_{\\lambda}^M$, thus $A_{\\lambda,\\rho}^M$ is r-robust in that case, and the consistency and smoothness guarantees from Lemmas 3.1 and 3.2 extend to $A_{\\lambda,\\rho}^M$. Consequently, it suffices to study $A_{\\lambda,\\rho}^M$ when $y \\in [\\frac{1}{r}, \\theta]$, and we obtain the following result.\nTheorem 3.4. Let $\\lambda\\in [0,1]$, $\\rho \\geq 0$, and let c = c(\u03bb) and r = r(\u03bb) as defined in (3). For any sequence of prices p = (p1,...,pn) \u2208 [1,\u03b8]n and prediction y \u2208 [1,\u03b8] of p* := maxi\u2208[n] Pi, it holds that\n$\\mathbb{E}_U [\\frac{A_{\\lambda,\\rho}^M(p, y)}{p^*}] \\geq \\frac{1-e^{-\\rho}}{\\rho} r$,\nand denoting by \u03b7 = |p* - y|, the ratio $\\mathbb{E}_U [\\frac{A_{\\lambda,\\rho}^M(p, y)}{p^*}]$ is at least\n$\\begin{cases} c - c \\frac{\\eta}{p^*} & \\text{if } y \\in [1,1/c) \\\\ c - (1 - \\lambda) \\max(1, \\frac{\\eta}{p^*}) & \\text{if } y \\in [1/c,1/r) \\\\ \\frac{1-e^{-\\rho}}{\\rho} (\\frac{c}{r}) - (\\frac{\\eta}{p^*}) & \\text{if } y \\in [1/r, \\theta] \\end{cases}$,\nThe first lower bound, independent of the prediction error \u03b7, is the robustness of the algorithm, while the second bound characterizes its consistency and smoothness. The theorem shows that, in order to guarantee a certain level of smoothness, $A_{\\lambda,\\rho}^M$ degrades both the consistency and robustness of $A_{\\lambda}^M$ by a factor of $\\frac{(1-e^{-\\rho})}{\\rho}$, hence exhibiting a tradeoff between smoothness and both consistency and robustness.\nThe consistency/smoothness bounds for y \u2208 [1,1/r) are proved in Lemmas 3.1 and 3.2, and the robustness in that case is $r > \\frac{(1-e^{-\\rho})}{\\rho} r$ because $A_{\\lambda,\\rho}^M$ is identical to $A_{\\lambda}^M$. Therefore, it only remains to prove the claimed bounds for $y \\in [1/r, \\theta)$. We demonstrate in Lemma 3.5 the consistency and smoothness of the algorithm, while the robustness is proved in Lemma 3.6.\nLemma 3.5 (Consitency-Smoothness). For any sequence of prices p, if $y \\in [\\frac{1}{r}, \\theta]$, then\n$\\mathbb{E}_U [\\frac{A_{\\lambda,\\rho}^M(p, y)}{p^*}] > (\\frac{c}{r} ) = \\frac{e^{-\\rho}}{r} (\\frac{r}{c} ) \\frac{\\eta}{p^*}$\nProof. Let $y \\in [\\frac{1}{r}, \\theta]$, hence $\\Phi(\\lambda, \\rho,y) = \\frac{e^{-\\rho U}}{r}$, where U is a uniform random variable in [0,1]. If p* > $\\Phi(\\lambda, \\rho, y)$, then the algorithm has a reward of at least $\\Phi(\\lambda, \\rho, y)$, and by (3) we obtain\n$\\frac{A_{\\lambda,\\rho}^M(p, y)}{p^*} > \\frac{\\Phi(\\lambda, \\rho, y)}{p^*} = \\frac{e^{-\\rho U}}{r} = e^{-\\rho U} c$,\nand if p* < $\\Phi(\\lambda, \\rho, y)$ then\n$\\frac{A_{\\lambda,\\rho}^M(p, y)}{p^*} = \\frac{1}{\\Phi(\\lambda, \\rho, y)} = \\frac{r}{e^{\\rho U}}$"}, {"title": "4 Average-Case Analysis in Ski-Rental", "content": "In this section, we focus on ski-rental, which is one of the fundamental problems in competitive analysis. In this problem, the decision-maker must choose each day between renting a ski for a unit cost or buying it for a fixed cost b, allowing them to ski for free for the remainder of the ski season, which has an unknown duration x. The objective is to minimize the total cost incurred from renting and buying. To simplify our presentation, we consider the continuous version of the problem, where the number of skiing days increases continuously, with x, b > 0. In this model, the cost of renting for a time period [t, t + d) is equal to \u03b4.\nThe ski-rental problem was one of the first problems studied in the learning-augmented framework. Purohit et al. [2018] proved that, with a prediction y of x, there is a deterministic algorithm with a competitive ratio of at most\n$\\min \\left( 1 + \\frac{\\lambda b}{x}, (1 + \\frac{1}{\\lambda}) + \\frac{|x - y|}{x} \\right)$, where \u03bb\u2208 [0, 1]. It was proved later in Wei and Zhang [2020] that the consistency (1 + \u03bb) and robustness $(1 + \\frac{1}{\\lambda})$ are Pareto-optimal. On the other hand, Benomar and Perchet [2023] analyzed the same algorithm under the assumption that $\\Pr(1_{y>b} = 1_{x>b}) = Q$ for some $Q \\in [\\frac{1}{2}, 1]$, and showed how to optimally choose \u03bb to minimize the expected cost of the algorithm.\nIn the following, we combine the analysis of average-case performance with the criteria of consistency, robustness, and smoothness. To achieve this, we propose a modified version $A_{SR}^{\\lambda, \\rho}$ of the algorithm introduced by Purohit et al. [2018], which is parameterized by two parameters \u03bb, \u03c1\u03b5 [0, 1].\nNote that the algorithm of Purohit et al. [2018] corresponds to $A_{SR}^{\\lambda, \\rho}$ with \u03c1 = 1, i.e. buying at time b/\u03bb if y < b. We start by proving the consistency, robustness, and smoothness of this algorithm.\nTheorem 4.1. For all x, y > 0, denoting by $\\eta = |x - y|$, it holds that $\\frac{A_{SR}^{\\lambda, \\rho}(x,y)}{\\min(x,b)}$ is at most\n$\\min \\left( 1 + \\frac{\\lambda b}{x}, (1 + \\frac{1}{\\lambda}) + (1 + \\frac{\\lambda b}{x}) \\frac{\\eta}{\\min(x, b)} \\right)$\nThe theorem above demonstrates that, for any value of p\u2208 [0, 1], the algorithm $A_{SR}^{\\lambda, \\rho}$ achieves Pareto-optimal consistency and robustness, albeit with varying levels of smoothness. Furthermore, note that our analysis is tighter than that of Purohit et al. [2018]. Specifically, when p = 1, we obtain a smoothness factor of 1 + \u03bb instead of \u03bb.\nProof. For simplicity, let us denote by $\\beta = (1 + \\rho(\\frac{1}{\\lambda} - 1))$. Note that $1 \\leq \\beta \\leq \\frac{1}{\\lambda}$, and recall that, $\\min(x, b) = \\min(x, b)$.\nRobustness. We first prove the robustness bound. If y \u2265 b:\n\u2022 if x < b then $A_{SR}^{\\lambda, \\rho}(x, y) = x = \\min(x, b)$,\n\u2022 if \u03bbb < x < b then $A_{SR}^{\\lambda, \\rho}(x, y) = (1 + \u03bb)b \\leq (1 + \u03bb)x = (1 + \u03bb) \\min(x, b)$,\n\u2022 if b \u2264 x, then $A_{SR}^{\\lambda, \\rho}(x, y) = (1 + \u03bb)b = (1 + \u03bb) \\min(x, b) \\leq (1 + \u03bb) \\min(x, b)$.\nOn the other hand, if y <b:\n\u2022 if x < b then $A_{SR}^{\\lambda, \\rho}(x, y) = x = \\min(x, b)$,\n\u2022 if b < x < \u03b2b then $A_{SR}^{\\lambda, \\rho}(x, y) = x < \\beta b = \\beta \\min(x, b) \\leq (1+ \\frac{1}{\\lambda}) \\min(x, b)$,\n\u2022 if x \u2265 Bx then $A_{SR}^{\\lambda, \\rho}(x, y) = (1 + \u03b2)b = (1 + \u03b2) \\min(x, b) \\leq (1+ \\frac{1}{\\lambda}) \\min(x, b)$."}, {"title": "4.2 For all x > 0, if the prediction y is a random variable satisfying Pr(1y>b = 1x>b) \u2265 Q for some Q\u2208 [1, 1], then ,,,,,is at most", "content": "In all the cases, it always holds that $A_{SR}^{\\lambda, \\rho}(x, y) \\leq (1+ \\frac{1}{\\lambda}) \\min(x, b)$.\nConsistency/Smoothness. Let us first consider the case of y \u2265 b.\n\u2022 if x < b then $A_{SR}^{\\lambda, \\rho}(x, y) = x = \\min(x, b)$,\n\u2022 if \u03bbb < x < b then $A_{SR}^{\\lambda, \\rho}(x, y) 1 = (1 + \u03bb)b \\leq (1 + \u03bb)y \\leq (1 + \u03bb) \\min(x, b) + (1 + \u03bb)\u03b7,\n\u2022 if b \u2264 x, then $A_{SR}^{\\lambda, \\rho}(x, y) = (1 + \u03bb)b = (1 + \u03bb) \\min(x, b)$.\nIn the case of y < b, we obtain that\n\u2022 if x < b then $A_{SR}^{\\lambda, \\rho}(x, y) = x = \\min(x, b)$,\n\u2022 if b < x < \u03b2b then\n$A_{SR}^{\\lambda, \\rho}(x, y) = x < y + \u03b7\n\\leq b + \u03b7 = (1 + \\lambda)b - \\lambda b + \u03b7\n\\leq (1 + \\lambda) \\min(x, b) + (1 - \\frac{1}{\\lambda})\u03b7\n\\leq (1 + \\lambda) \\min(x, b) + \\frac{\\beta - \\lambda}{\\beta-1}\\eta$,\nwhere we used in the penultimate inequality that \u03b7 = x - y \\leq x \\leq \\beta b.\n\u2022 if x > \u03b2x then\n$A_{SR}^{\\lambda, \\rho}(x, y) = (1 + \u03b2)b = (1 + \u03bb)b + (\u03b2 - \u03bb)b\n= (1 + \u03bb) \\min(x, b) + (\\frac{1}{\\lambda} - 1)b\n\\leq (1 + \u03bb) \\min(x, b) + \\frac{\\frac{1}{\\lambda}-\\lambda}{\\beta-1}\u03b7$,\nwhere we used in the last inequality that \u03b7 = x \u2212 y \u2265 (\u03b2 \u2212 1)b.\nAll in all, we deduce that\n$\\forall x,y: A_{SR}^{\\lambda, \\rho}(x, y) \\leq (1 + \u03bb) \\min(x, b) - + \\max \\left( (1 + \\lambda, \\frac{\\frac{1}{\\lambda}-\\lambda}{\\beta-1} \\right)$\nand by definition of \u03b2 we have\n$\\frac{\\frac{1}{\\lambda}-\\lambda}{\\beta-1} = \\frac{(\\rho + 1)(\\frac{1}{\\lambda}-1)}{\\rho(\\frac{1}{\\lambda}-1)} = 1 + \\frac{\\lambda}{\\rho}$\nhence\n$A_{SR}^{\\lambda, \\rho}(x, y) \\leq (1+\u03bb) \\min(x,b) + (1+\\frac{\\lambda}{\\rho}) \\eta$,\nwhich concludes the proof.\nIn the subsequent theorem, we assume that the prediction y lies on the same side of bas x with a probability of at least $Q\\in [\\frac{1}{2}, 1]$, and we establish an upper bound on the expected cost of Algorithm 1. The assumption on y is pertinent for this setting, as the decision made by the algorithm depends only on where y is situated compared to b. The same assumption was considered in Benomar and Perchet [2023].\nTheorem 4.2. For all x > 0, if the prediction y is a random variable satisfying $\\Pr(1_{y>b} = 1_{x>b}) \\geq Q$ for some $Q\\in [\\frac{1}{2}, 1]$, then $\\frac{\\mathbb{E}_y [A(x,y)]}{\\min(x,b)}$ is at most\n$\\max \\left( 2 + (\\frac{1}{\\lambda}-1) ( (1 - Q)\\rho - Q\\lambda), 1 + \\frac{1-Q}{\\lambda} \\right)$"}, {"title": "5 EXPERIMENTS", "content": "In this section, we present experimental results to validate our theoretical findings and provide additional insights into the tradeoffs discussed in the paper.\nLine Search. As established in Lemma 2.1 and illustrated in Figure 1, given a target position $x \\geq 1$ and prediction $y > 0$, the ratio between the distance traveled by Algorithm $A_{LS}$ and the optimal offline algorithm depends solely on the ratio $x/y$ when x is large. To investigate the impact of the parameter p, we fix x = 100 and b = 2.5, then compare the behavior of the algorithm presented in Section 2 for three different values of p\u2208 {0.05, 0.5, 5}, with y \u2208 [$b^{-2}x,b^{2}x$]. For each point in the experiment, the average and standard deviation are computed over $10^5$ independent trials. Figure 3 demonstrates that smaller values of p lead to better consistency, but make the algorithm highly sensitive to prediction errors. This highlights the consistency-smoothness tradeoff established in Theorem 2.3.\nOne-Max Search. We conduct an analogous experiment for the one-max search problem to demonstrate the consistency-smoothness tradeoff for $A^M_{\\lambda}$. Given a sequence with a maximal price p*, the algorithm is provided with a noisy prediction in the form $y = p^* + \\epsilon$, where $\\epsilon ~ U[-\\sigma, \\sigma]$. The threshold set by $A_{\\lambda,\\rho}^M$, denoted as $\\Phi(\\lambda, \\rho, y)$, determines its worst-case payoff: if $p^* > \\Phi(\\lambda, \\rho, y)$, the algorithm gains $\\Phi(\\lambda, \\rho, y)$; otherwise, the gain is 1, which is the minimum possible price in the sequence. This scenario is asymptotically achieved by the sequence p = ($P_1,...,P_{n+1}$), where $p_i = 1 + \\frac{(p^* - 1)}{i}$ for i < n, and $p_{n+1} = 1$. In the experiment, $\\lambda = 0.1$ and $0 = 5$ are fixed, and for each $\\sigma\\in [0,\\theta]$, the worst-case average ratio $\\sup_{p^* \\in [1,\\theta]} \\mathbb{E}[\\frac{A_{\\lambda,\\rho}^Q(p, p^* + \\epsilon)}{p^*}]$ and the corresponding standard deviation are evaluated over $10^5$ independent samples. Figure 4 shows that the algorithm suffers from brittleness for $\\rho = 0$, as the slightest prediction error substantially degrades its performance. In contrast, as $\\rho$ increases and randomization is introduced, the algorithm becomes smoother; at the cost of consistency.\nSki Rental. For the ski-rental problem, two experiments are conducted to investigate, on one hand, the impact of the parameter \u03c1 on the consistency and smoothness of the algorithm $A_{SR}^{\\lambda, \\rho}$, and on the other hand,"}]}