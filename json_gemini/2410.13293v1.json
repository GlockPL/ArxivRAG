{"title": "SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation", "authors": ["Prakhar Dixit", "Tim Oates"], "abstract": "Many students struggle with math word problems (MWPs), often finding it difficult to identify key information and select the appropriate mathematical operations. Schema-based instruction (SBI) is an evidence-based strategy that helps students categorize problems based on their structure, improving problem-solving accuracy. Building on this, we propose a Schema-Based Instruction Retrieval-Augmented Generation (SBI-RAG) framework that incorporates a large language model (LLM). Our approach emphasizes step-by-step reasoning by leveraging schemas to guide solution generation. We evaluate its performance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo, and introduce a \"reasoning score\" metric to assess solution quality. Our findings suggest that SBI-RAG enhances reasoning clarity and problem-solving accuracy, potentially providing educational benefits for students.", "sections": [{"title": "Introduction", "content": "Proficiency in solving math word problems (MWPs) is not only measured by students' ability to arrive at the correct solution but also by their capacity to follow a structured, step-by-step reasoning process [8]. This approach is vital for developing critical thinking and mathematical reasoning abilities, which are essential for tackling complex word problems effectively [18]. Unfortunately, many students struggle with word problems, often failing to identify key information or select the appropriate operations despite understanding the underlying mathematical concepts. This difficulty is a significant barrier to academic success, as highlighted by a survey from the EdWeek Research Center, which reported that nearly 50% of students can read a word problem's text but fail to grasp the mathematical question being asked [24]. Consequently, poor problem-solving skills in MWPs can lead to academic challenges and even failure in school.\nWord problems, as a core component of the mathematics curriculum, serve an important function by fostering logical analysis, mental abilities, and creative thinking. Educators and researchers have explored various methods to improve students' proficiency in solving these problems. One such method is Schema-Based Instruction (SBI) [27, 7], an evidence-based approach widely used in the field of Mathematics that helps students classify word problems based on their underlying structure or schema. SBI has been shown to enhance students' ability to identify relevant information and apply the appropriate mathematical operations for problem-solving. In addition to educational approaches like SBI, Intelligent Tutoring Systems (ITSs) have emerged as valuable tools in addressing challenges associated with MWPs. ITSs leverage artificial intelligence (AI) and interactive interfaces to provide personalized, step-by-step guidance. Examples of ITSs designed for word problem-solving include AnimalWatch [2], MathCAL [4], PAT (Pump Algebra Tutor) [15] and HINTS [35]. These systems have proven effective in supporting learners by offering feedback, hints, and individualized learning paths. However, many ITSs rely on rule-based algorithms and lack the transformative potential of more recent AI advancements, like those in Natural Language Processing (NLP) [19] and the"}, {"title": "Approach", "content": "As seen in Figure 1, our approach is divided into four main parts: 1) Schema Classifier, 2) Prompt Creation, 3) Context Retrieval, and 4) Answer and Response Generation. The training and dataset details are described in Appendix C and D, respectively.\nA schema is a structured framework that represents a generalized method for solving a specific type of problem [25]. In the context of MWPs, schemas help categorize problems based on their underlying structure, making it easier to determine which mathematical operations to use [9]. For example, MWPs can often be grouped into two major schemas: Additive and Multiplicative [20].\nEach schema can be further divided into sub-categories. For instance, the Additive schema can include Additive Change (where a value is increased or decreased), Additive Difference (problems that focus on the difference between two values), and Additive Total (where two or more quantities are combined to get a total) [31]. Similarly, the Multiplicative schema can include Multiplicative Comparison (where one quantity is compared to another using multiplication), Multiplicative Equal Groups (where the total is divided into equal parts), and Multiplicative Ratios/Proportions (problems that involve finding ratios or proportional relationships) [30].\nThese schemas provide a structured framework for problem-solving, helping both the language model and learners identify the type of problem and apply the appropriate operations.\nBuilding a Schema Classifier: We develop a schema classifier that performs supervised learning to predict the relevant schema (Si) and sub-category (Sci) for a given problem (P). This classifier is built using a DistilBERT model, which has been fine-tuned on a custom dataset of schema-based instruction problems.\nEach problem in the dataset is labelled with its associated schema and sub-category, helping the classifier learn the relationships between different types of word problems and their corresponding schemas. Specifically, the input problem is tokenized and processed by the DistilBERT model, which then outputs the most suitable schema (Si) and sub-category (Sci)."}, {"title": "Evaluation", "content": "For evaluating the utility of our approach, we focus on the step-by-step reasoning provided by the generated responses, rather than solely on accuracy. Our goal is to ensure that the reasoning process is clear, logical and follows schema-driven methodologies, which helps improve understanding in solving MWPs [25]. To address this, we introduce a new metric, the reasoning score, to measure the quality of the reasoning in the generated solutions. We also evaluate the performance of our schema classifier and analyze both the training and validation losses, ensuring that it generalizes well to unseen data. We also make use of the LLM-as-a-Judge approach [36] to get feedback and evaluate our response from LLMs like GPT-4 and GPT-3.5 Turbo. This approach is a scalable and explainable method for approximating human preferences [14], which are otherwise costly to obtain."}, {"title": "Conclusion", "content": "Despite the promising results of our Schema-Based Instruction Retrieval-Augmented Generation (SBI-RAG) framework for improving math word problem reasoning, some limitations exist. This study relies on the LLM-as-a-Judge method, lacking direct human evaluation from educators or students, which would provide more informative feedback. The success of the RAG framework hinges on the relevance and quality of retrieved documents, which may vary and impact the generated solutions. The evaluation focuses on arithmetic word problems (GSM8K). More complex problem datasets are needed to assess the framework's generalizability. Finally, extending the framework to different subjects or educational levels may present challenges, requiring further adaptation. These limitations highlight areas for future research, particularly in improving schema coverage, expanding dataset diversity, and incorporating human evaluations.\nIn conclusion, we proposed a Schema-Based Retrieval-Augmented Generation framework that enhances reasoning and understanding in solving math word problems. Our approach, combining schema-based instruction with large language models, outperformed existing LLM responses in quality and step-by-step reasoning. This framework provides a strong foundation for improving problem-solving in education, with future work focused on refining the system with user feedback. Additionally, this work could have applications in enhancing the reasoning capabilities of LLMs themselves."}, {"title": "Appendix / supplemental material", "content": null}, {"title": "Related Work", "content": null}, {"title": "Statistical Significance", "content": "To test the statistical significance, a paired sample t-test, also known as a dependent sample t-test, was conducted to compare the reasoning performance of SBI-RAG with two language models, GPT 3.5"}]}