{"title": "Experiments with Large Language Models on Retrieval-Augmented Generation for Closed-Source Simulation Software", "authors": ["Andreas Baumann", "Peter Eberhard"], "abstract": "Large Language Models (LLMs) are increasingly helpful in text generation, even writing code in programming languages based on user prompts written in natural language. They are even applied to generate simulation models for multibody systems from natural language. Research results suggest that LLMs surpass the mere replication of existing code examples, where some LLMs have been trained on an open-source multibody simulation code. However, for closed-source simulation software, such results are not to be expected as their ideas and concepts might differ from other publicly available ones. LLMs can hallucinate for knowledge-intensive tasks, such as model creation, which can lead to wrong responses. This is especially the case for the LLM unknown closed-source simulation software. The same applies to other internal knowledge kept private to protect intellectual property or data privacy. The Retrieval-Augmented Generation (RAG) approach might yield a solution for these knowledge-intensive tasks. This paper explores the application of RAG to closed-source simulation software and presents first experiments. After a brief introduction to LLMs, the RAG approach, and the simulation method applied by the close-source simulation software, several examples are provided to test LLMs' knowledge of the simulation software and the creation of simulation models using two RAG systems. The examples show promising results indicating the benefits of applying RAG systems to closed-source simulation software, helping to access their knowledge. Nevertheless, they also reveal gaps in the applied information and open questions for further research.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) are becoming increasingly important and have become an integral part of everyday use. Writing texts or developing programming codes are just two examples that are generated using LLMs in the shortest time using questions and instructions written in natural human language. Among the most commonly used tools are ChatGPT or GitHub Copilot.\nOverly simplified, however, it must be stressed that classic LLMs do not understand the posed tasks but rather predict the response on the prompt based on learned word and sentence sequence relationships. To obtain these relationships of natural language, large training sets are required. This allows LLMs to answer also prompts which were not included in its training set.\nHowever, for knowledge-intensive tasks this often leads to wrong answers, so-called hallucinations [18,17]. One example of such knowledge-intensive task is generating simulation models for, e.g., multibody simulations. Research shows that LLMs are well able in writing basic simulation codes for dynamic systems [13], especially when LLMs include this knowledge in their training. For example, in [13] the investigated multibody simulation library Exudyn [12] is available as open-source on GitHub, which is reported to be part of the training data for LLMs like ChatGPT.\nFor closed-source software packages no such abilities are to be expected, simply because the ideas and concepts of these software packages are not known to the LLM. Therefore, any LLM response will be guessed based only on other publicly available software packages. This assumption will later be tested.\nNevertheless, the abilities of LLMs to develop simulation models and support developers of these closed-source simulation packages would be of tremendous help. The protection of the intellectual property, data privacy, or independence from a few of companies, which are able to develop such LLMs, are just some reasons why these software packages or other knowledge remain internally. The same applies for other internal knowledge, ranging from software projects to internal project reports.\nIn principle, LLMs can also be developed in-house or fine-tuned on the internal data on the basis of open-source LLMs. Examples for open-source LLMs are Teuken 7B from OpenGPT-X [2] or the Llama models from Meta [16]. Nevertheless, the training or fine-tuning of such LLMs requires massive computational resources. For example, the training of Llama 3.2 3B required up to 460k GPU hours on Nvidia H100-80GB GPUs [20], which is not feasible for many researchers or companies. On the other hand, pretrained LLMs can be evaluated on a single gaming GPU. This is also referred to as LLM inferencing, where the LLM is used to generate a reply, respective a response, on an input prompt.\nRetrieval-Augmented Generation (RAG) [18] provides an approach to combine additional knowledge with the application of LLMs. This additional information is searched based on the user prompt and relevant documents are supplied to the LLM for response generation. As knowledge bases, internal documents or closed-source simulation packages can be used. RAG also reduces the risk of hallucinations [28,31], as relevant information for knowledge-intensive tasks can be provided. Additionally, as the evaluation of an LLM can be done locally, the supplied knowledge not needs to be disclosed.\nThis work provides first experiments of RAG for closed-source simulation software in order to asses its further application. Several small examples are provided and issues in the LLM responses are discussed before open questions for future research are pointed out. The tests are performed using the closed-source simulation software Pasimodo [10]. Pasimodo is a program package for particle-based simulation methods, such as Smoothed Particle Hydrodynamics (SPH) and the Discrete Element Method (DEM). In order to understand the challenges involved in carrying out the experiments, a brief"}, {"title": "1.1 Smoothed Particle Hydrodynamics", "content": "Smoothed particle hydrodynamics (SPH) is a mesh-free Lagrangian method that discretizes a continuum medium through discrete integration points, called particles. SPH can be used to approximate any partial differential equations and is frequently applied in fluid dynamics, such as modeling the complex chip evacuation process during deep-hole drilling, where fluid-structure interaction plays a key role [4]. The meshless nature of SPH makes it particularly suitable for handling dynamic surfaces and interfaces, which can be computationally expensive to track with traditional mesh-based methods.\nSome basic theoretical aspects are shortly summarized to provide some background for the following tests. However, this work is not intended to be an introduction into SPH, the interested reader is referred to additional literature [30] about SPH.\nBasically, SPH applies a summation over neighboring particles b to determine the properties of the current particle a. Consequently, applying SPH on the Navier-Stokes questions leads to the discretization of the momentum equation as\n$\\frac{dv_a}{dt} = g - \\sum_b m_b \\left[ \\frac{p_a}{\\rho_a^2} + \\frac{p_b}{\\rho_b^2} \\right] \\frac{(\\mu_a + \\mu_b) v_{ab} r_{ab}}{\\rho_a \\rho_b ||r_{ab}||^2 + 0.01h^2} \\nabla_a W_{ab}$ (1)\nand the continuity equation reads\n$\\frac{d\\rho_a}{dt} = \\rho_a \\sum_b \\frac{m_b}{\\rho_b} (v_a - v_b) \\nabla_a W_{ab}$, (2)\nHere, v is the velocity, t is time, g is gravity, m is the mass, p is the pressure, $\\rho$, is the density, and $\\mu$ is the dynamic viscosity of particle b respective particle a. The smoothing kernel function W(x \u2013 x', h) has compact support, which is defined by the smoothing length h. Therefore, it allows the summation to be restricted to the effective neighboring particles b for any given particle a in the fluid domain. Instead of considering every particle combination in the complete domain, a neighborhood search is carried out reducing the computational effort significantly."}, {"title": "2 Application of Large Language Models", "content": "Large Language Models (LLMs) are a type of machine learning model designed to generate text based on user input. The user input, also called prompt, can be natural language, which significantly simplifies the application. LLMs are trained on large sets of data, hence the name large, to learn word and sentence sequence relationships. In oversimplified terms, a LLM learns to predict the most likely text sequence following the previous sequences. Although, the LLM does not actually comprehend the problem behind the user input, it can create based on likelihoods responses on prompt which have not been part of its training set.\nIn the following, we give a brief introduction in the concept behind LLMs and the computational resources needed for them. Afterwards, we test their knowledge about a closed-source simulation software which has not been part of their training data."}, {"title": "2.1 Brief Introduction into Large Language Models", "content": "The latest LLMs are based on the transformer [29] approach, which consists primarily of an encoder and a decoder. The encoder and the decoder are both made of multiple layers of self-attention and feedforward neural networks. It is beyond the scope of this work to explain the details on these mechanisms, therefore only a brief introduction is provided. For more details, the interested reader is referred to further literature, e.g. [29,19,1,27].\nThe encoder starts with the embedding. Neural networks are not based on the words the input consists of, but on numbers respective a numerical vector representation of each word. Therefore, the encoder converts the input into a vector representation, which is referred to as embedding. Any position information is lost by this at first. However, the position and order of the words in the input are crucial for its understanding. Therefore, the positional information of the input words is added into the embeddings. The following layers of self-attention allow the LLM to learn which words of the input are connected. This allows the LLM to detect the important words while ignoring others. This also allows the LLM to learn that words ordered in a certain pattern, e.g., typically compose a question to respond accordingly.\nThe decoder creates the actual response for the input. Its structure is similar to the encoder, but it has a different job. The decoder takes as input the information from the encoder and the list of the previous outputs. Based on these, the decoder predicts the next word creating the output word by word.\nDepending on the number of words known to the LLM and the number of layers, the size of current LLMs reaches into the billions of parameters. Usually the name indicates the model size, where the word billion is shortened to B."}, {"title": "2.2 Example 1: Knowledge about Pasimodo", "content": "Depending on their training data, LLMs are able to answer questions reliable without further data. Therefore, the LLMs listed in Table 1 are asked about Pasimodo and their responses are listed in Table 2.\nWhereas the local evaluation of the Llama 3.2 3B model diverted and offered a summery on the fictional character Quasimodo, the other two LLMs performed a web search about Pasimodo. Both compiled their answers from the websites available on Pasimodo, which they listed as sources too. Apparently, all three LLMs did not include any information about Pasimodo in their training. The web searches of ChatGPT and Gemini indicate that both are not pure LLMs but rather have already capabilities to retrieve additional information before generating their answers. However, as the public information on Pasimodo is limited, more detailed questions were not asked. The next section will present an approach to leverage more internal knowledge about Pasimodo for answering questions and task using LLMs."}, {"title": "3 Application of Retrieval-Augmented Generation", "content": "Retrieval-Augmented Generation (RAG) [18] refers to an approach where additional information is retrieved and provided additionally to the LLM. In consequence, more knowledge can be used than the internal memory of the LLM. Next follows a brief introduction into RAG, which is followed by examples of the out-of-the-box performance of two available solutions. Therefore, NotebookLM [15], a RAG tool from Google using Gemini 1.5, and AnythingLLM [22], an open-source RAG application, which can be run locally using a local LLM instance, are tested."}, {"title": "3.1 Brief Introduction into Retrieval-Augmented Generation", "content": "A RAG system combines the abilities of an LLM with an additional knowledge database to provide up-to-date and context-specific information. It combines the information retrieval with natural language processing. The additional information can be internal documents, wiki or internet pages, or existing databases. The user prompt is then used to perform a semantic search on the document, in some cases also a fuzzy search or a search engine in the case of webpages can be used.\nBefore the documents can be retrieved, they need to be added to a vector database. Therefore, they are embedded into a vector representation, similar to the embedding of the user prompt done by the LLM. Depending on the data format of the documents, they are converted into plain text files first before embedding. LLMs are limited in the input length they can handle, thus the input documents are also split into smaller parts, so-called chunks [11].\nFor new user prompts, the retriever searches based on the embedded user prompt for close matches within the vector database. The retrieved documents with the highest similarity to the query are combined with the original prompt, which is called augmentation, before they are handed for the response generation [11]. For the response generation, any existing LLM can be used. As with the classic use of the LLM, previous dialog can be added too."}, {"title": "3.2 System Setup", "content": "NotebookLM does not provide much setup options allowing only the selection of the uploaded sources which should be used for answering the posted questions. AnythingLLM allows for more modifications such as choos-"}, {"title": "3.3 Data Preprocessing", "content": "The experiments are conducted using a collection of input examples of Pasimodo and a documentation on the most important points written as wiki including multiple tutorials for creating models with Pasimodo. The same data is supplied to new students as introduction and first steps to get familiar with Pasimodo.\nThe data needs to be pre-processed before adding it to the RAG systems. NotebookLM has a limit of 50 sources, e.g. pdf, text, or markdown-files, which each can contain up to 500,000 words. First, the repositories containing the input examples and the wiki were converted into a single text file. These text files were split into multiple files each containing 400,000 words, which were identified by being separated by spaces, equals signs, and slashes. In a first test, NotebookLM removed all XML markup from the uploaded plain text files. This was problematic as the input files for Pasimodo are written in XML, therefore, the output of NotebookLM was utter garbage. To prevent the XML markup removal, the plain text files were printed as pdf files before uploading them to NotebookLM. The same pdf files were added to AnythingLLM without further processing."}, {"title": "3.4 Example 2: Knowledge about Pasimodo using RAG", "content": "The previous test is repeated with the RAG systems questioning both about their knowledge regarding Pasimodo. The answers are given in Table 4. This time, the systems answer the question with more details about Pasimodo. In particular, both systems replicate the information provided in the Pasimodo wiki which was provided to them as input. Both tools provide also citations, what parts of the sources were considered for generating the input. By default, AnythingLLM is limited to retrieving 4 sources. A limit for NotebookLM cannot be determined."}, {"title": "3.5 Example 3: How to define a liquid with the properties of oil?", "content": "After showing that both systems are able to access the provided data, we test their abilities on unknown questions. In general, the Wiki and the input examples are using water for the fluid simulations. Therefore, the systems are asked how a liquid with the properties of oil is defined. The answers are listed in Table 5.\nBoth systems are able to provide the basics parameters of the SPH_Fluid component, which are important for defining a liquid within Pasimodo. NotebookLM provides a more detailed answer explaining the individual"}, {"title": "3.6 Example 4: Simulation Model with an SPH Particle and the Properties of Oil", "content": "Next, both systems are asked to create a complete input file for a simulation with an SPH particle and the properties of oil. Table 6 lists excerpts from the answers of both system. The output is shortened, and the whitespace is manually adjusted. Both input files from the answers are syntactically correct, but some shortcomings are present. AnythingLLM is able to correct the definition of the SPH fluid with the new citations found for the new prompt but includes variables such as height or density_in which are not defined as constants beforehand. NotebookLM, on the other hand, provides all variables used through the input file in the Constants section while taking over values for oil in the ranges earlier provided. AnythingLLM already includes a particle state used for the kernel gradient correction scheme as it mentioned in one of its citations, whereas NotebookLM does not include any additional particle state.\nBoth systems include the needed neighborhood search in the response, but AnythingLLM adds the wrong attributes. Apparently the retrieved text chunk ends immediately after the first line of the neighborhood search definition, therefore, lacking any information about its attributes. Funnily enough, it copies a typo in the documentation (double oo in Neighboorhood Search). NotebookLM, furthermore, includes the basic SPH fluid interaction between the individual liquid particles whereas AnythingLLM only adds an empty scenarios section. However, NotebookLM uses an outdated formulation for the fluid interaction, which is listed in the documentation next to the current implementation."}, {"title": "3.7 Example 5: Replying to the RAG Systems Response", "content": "As both simulation models created in the previous section are either incomplete or have several issues, issues are pointed out to the RAG systems and they are asked to correct them. NotebookLM was told it uses an older version of the SPH scenario and to use the newer version, which it correctly included. The choice of the sound velocity as the physical value of 1400 m/s was not corrected by us as detailed knowledge about its choice is not part of the Pasimodo documentation. In the past, students are referred to the SPH literature [23] for deeper information about this simulation parameter, so the tests reveal some gaps in the documentation.\nThe same applies for the output of AnythingLLM, where an approximation for the artificial sound velocity (10 * sqrt(2 * 9.81 * height)) is used, which is given in [23] for the collapse of a dam. Apparently, one of the used text chunks originates from a bursting dam example. Instead, the RAG system is instructed to add the definitions of the missing variables (single_mass, density_in, init_dx, height), to fix the neighborhood search attributes, and to include the missing SPH fluid scenario. However, the updated response does not fix the mentioned problems, but the LLM adds new variables (e.g. fluid_mass_in) and expands the attributes of the neighborhood search leading to a worse output.\nEven providing an example of the correct neighborhood interaction definition does not help the RAG system to improve its answer.\nIn conclusion, providing additional information, e.g. about issues in previous responses, can help the LLM and the RAG system to improve their response in some cases. This is described in literature as few-shot learning [7]. However, especially for knowledge-intensive problems, this is rather difficult, and can lead to further issues in the response as seen."}, {"title": "4 Conclusions and Outlook", "content": "Large Language Models have become very useful tools in creating text or developing scripts and software. Information that has not been part of their training sets is not available for them. Especially for closed-source software, LLMs cannot be applied as they lack the information for solving tasks about them.\nRetrieval-Augmented Generation presents an approach to overcome this issue by providing additional information to the LLM along the user prompt. A commercial implementation, NotebookLM, and an open-source version, AnythingLLM, of such a RAG system have been tested in this work. Whereas NotebookLM is powered by the LLM Gemini from Google, AnythingLLM can be set up using a local LLM allowing to keep all information locally. As local LLM, the open-source Llama 3.2 3B model from Meta was used. The test of the RAG systems was carried out using the closed-source simulation software Pasimodo. Both RAG systems were supplied with a collection of input examples and the short documentation for Pasimodo.\nThe two systems were tested using several examples. In addition to defining a fluid with the properties of oil, the systems were instructed to create a complete input example. Both systems are able to answer basic questions to previously unknown information and about simulation aspects such as the definition of liquids for Pasimodo.\nHowever, for more detailed inquiries, the RAG systems have their limits. In general, NotebookLM provided better results, but it was not immune to contradictory information such as double definition of the fluid scenario including an older version of it. Especially, the choice of retrieved additional knowledge which was handed to the LLM before answering the user input proved to be critical.\nFurther improvement of the user experience of the tested RAG systems would be desirable. Both systems are designed as chat interfaces with a linear history or order. In general, the chat history is also provided as context for later prompts. As the LLMs deviated on complex problems, the ability to revert the history or to branch of a response in multiple separate follow-up prompts would be beneficial. This would increase the control on the information provided to the LLM and hopefully result in better responses.\nAnythingLLM retrieved only four text chunks of 1,000 character length from the provided sources by default. This did not offer sufficient information for the RAG system to answer complicate questions like creating a complete simulation input file. NotebookLM does not disclose the number of retrieved sources, but the citations offered along the answer indicate that more and longer text chunks are used than in AnythingLLM. When lacking context, AnythingLLM respective the underlying Llama 3.2 3B LLM stuck closely to the provided information, leading often to merely copying text from its citations. As we have seen, the quality of the answer depends largely on the provided text excerpts to the LLM. Therefore, the choice and amount of sources provided to the LLM are challenges for the further improvement of the systems. Depending on the selected LLM, the maximum input length the LLM can handle larger inputs, thus larger and more text chunks could be provided.\nBesides the potential of improvement the actual retriever provides, other options need to be tested in the future. The capabilities of LLMs are increasing, allowing them to execute generated source code or calling tools to provide additional input for generating their responses. Larger version of the applied Llama LLM, such as the 7B and 70B, are promised to better be able to use these tools while maintaining the conversation with the user [21]. Allowing the LLM to retrieve information as needed or additional lookups for the components used in input examples offer possible improvements for the system.\nAdditional potential for improving the responses offers the fine-tuning the LLM by training it on new data. Especially for the specific format of Pasimodo input files, this fine-tuning could be carried out on the set of Pasimodo input examples. However, the before-mentioned challenges of the required computational effort remain.\nThe tests provided insights for the further application of LLMs and RAG systems. The examples of applications range from details about single model parts to creating complete simulation models. In general, the problem must be clearly described regarding dimension and resolution. The results for the examples also reveal that the documentation is lacking information in some points. An example for this is the choice of the artificial sound velocity, a simulation parameter for which the relevant literature is usually referred. Therefore, future work must also include the improvement of the used information sources. The RAG system also provides reference points for this.\nIt should also be mentioned, that the results of LLMS are hardly reproducible due to the inherent nature of LLMs. Furthermore, as already discussed, especially retrieving different sources leads to significantly different outcomes. This can be seen especially for NotebookLM, which received an update after the tests were conducted and now is powered by latest version of the Gemini 2.0 Flash LLM. In general, NotebookLM showed the better results compared to AnythingLLM, however, responses"}]}