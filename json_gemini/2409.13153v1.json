{"title": "Towards Efficient Neuro-Symbolic AI: From Workload Characterization to Hardware Architecture", "authors": ["Zishen Wan", "Che-Kai Liu", "Hanchen Yang", "Ritik Raj", "Chaojian Li", "Haoran You", "Yonggan Fu", "Cheng Wan", "Sixu Li", "Youbin Kim", "Ananda Samajdar", "Yingyan (Celine) Lin", "Mohamed Ibrahim", "Jan M. Rabaey", "Tushar Krishna", "Arijit Raychowdhury"], "abstract": "The remarkable advancements in artificial intelligence (AI), primarily driven by deep neural networks, are facing challenges surrounding unsustainable computational trajectories, limited robustness, and a lack of explainability. To develop next-generation cognitive AI systems, neuro-symbolic AI emerges as a promising paradigm, fusing neural and symbolic approaches to enhance interpretability, robustness, and trustworthiness, while facilitating learning from much less data. Recent neuro-symbolic systems have demonstrated great potential in collaborative human-AI scenarios with reasoning and cognitive capabilities. In this paper, we aim to understand the workload characteristics and potential architectures for neuro-symbolic AI. We first systematically categorize neuro-symbolic AI algorithms, and then experimentally evaluate and analyze them in terms of runtime, memory, computational operators, sparsity, and system characteristics on CPUs, GPUs, and edge SoCs. Our studies reveal that neuro-symbolic models suffer from inefficiencies on off-the-shelf hardware, due to the memory-bound nature of vector-symbolic and logical operations, complex flow control, data dependencies, sparsity variations, and limited scalability. Based on profiling insights, we suggest cross-layer optimization solutions and present a hardware acceleration case study for vector-symbolic architecture to improve the performance, efficiency, and scalability of neuro-symbolic computing. Finally, we discuss the challenges and potential future directions of neuro-symbolic AI from both system and architectural perspectives.", "sections": [{"title": "I. INTRODUCTION", "content": "The remarkable advancements in AI have had a profound impact on our society. These advancements are primarily driven by deep neural networks and a virtuous cycle involving large networks, extensive datasets, and augmented computing power. As we reap the benefits of this success, there is growing evidence that continuing our current trajectory may not be viable for realizing Al's full potential. First, the escalating computational requirements and energy consumption associated with AI are on an unsustainable trajectory [1], threatening to reach a level that could stifle innovation by restricting it to fewer organizations. Second, the lack of robustness and explainability remains a significant challenge, likely due to inherent limitations in current learning methodologies [2], [3]. Third, contemporary AI systems often operate in isolation with limited collaboration among humans and other AI agents. Hence, it is imperative to develop next-generation AI paradigms that address the growing demand for enhanced efficiency, explainability, and trust in AI systems.\nNeuro-symbolic AI [4] represents an emerging AI paradigm that integrates the neural and symbolic approaches with prob-abilistic representations to enhance explainability, robustness and facilitates learning from much less data in AI (Fig. 1).\nNeural methods are highly effective in extracting complex features from data for vision and language tasks. On the other hand, symbolic methods enhance explainability and reduce the dependence on extensive training data by incorporating established models of the physical world, and probabilistic representations enable cognitive systems to more effectively handle uncertainty, resulting in improved robustness under unstructured conditions. The synergistic fusion of neural and symbolic methods positions neuro-symbolic AI as a promising paradigm capable of ushering in the third wave of AI [5], [6].\nNeuro-symbolic AI promises possibilities for systems that acquire human-like communication and reasoning capabilities, enabling them to recognize, classify, and adapt to new situations autonomously. For example, neuro-vector-symbolic architecture [7] is able to reach 98.8% accuracy on spatial-temporal reasoning tasks, greatly surpassing human performance (84.4%), neuro-only ResNet (53.4%) and GPT-4 performance (89.0%). In addition to its superior performance in vision and language [8], neuro-symbolic AI holds significant potential for enhancing explainability and trustworthiness of collaborative human-AI applications [9]. These applications include collaborative robotics, mixed-reality systems, and"}, {"title": "II. NEURO-SYMBOLIC AI ALGORITHMS", "content": "In this section, we systematically review and categorize the recent research progress in neuro-symbolic AI algorithms.\nOverview. Neuro-symbolic AI represents an interdisciplinary approach that synergistically combines symbolic reasoning with neural network (NN) learning to create intelligent systems, leveraging the complementary strengths of both to enhance the accuracy and interpretability of the resulting models. Given that neuro-symbolic algorithms incorporate symbolic and neural components, various paradigms can be categorized based on how these components are integrated into a cohesive system. Inspired by Henry Kautz's taxonomy [31], we systematically categorize these algorithms into five paradigms (Tab. I). We elaborate on each of these paradigms below. Additionally, Tab. II provides examples of several underlying operations based on the categorization in Tab. I.\nSymbolic [Neuro] refers to an intelligent system that empowers symbolic reasoning with the statistical learning capabilities of NNs. These systems typically consist of a comprehensive symbolic problem solver that includes loosely-coupled neural subroutines for statistical learning. Examples include DeepMind's AlphaGo [16] and AlphaZero [32], which use Monte-Carlo Tree Search (MCTS) as the symbolic solver and NN state estimators for learning statistical patterns.\nNeuro|Symbolic refers to a hybrid system that combines neural and symbolic components in a pipeline, where each component typically specializes in complementary tasks. To the best of our knowledge, the majority of neuro-symbolic algorithms fall into this category. For example, IBM's neuro-vector-symbolic architecture (NVSA) [7] uses an NN as the perception frontend for semantic parsing and a symbolic reasoner as the backend for probabilistic abductive reasoning on the RAVEN [33] and I-RAVEN [34] datasets. Probabilistic abduction and execution (PrAE) learner [22] adopts a similar approach where the difference lies in features are first projected to high-dimensional vectors in NVSA, whereas PrAE utilizes the original features directly as the NN's input. Other examples include vector symbolic architecture-based image-to-image translation (VSAIT) [21], neuro-probabilistic soft logic (NeuPSL) [17], neural probabilistic logic programming (DeepProbLog) [35], neuro-answer set programming (NeurASP) [18], neural symbolic dynamic reasoning [36], neural symbolic concept learner (NSCL) [8], abductive learning (ABL) [19], and neuro-symbolic visual question answering (NSVQA) [20] on the CLEVRER dataset [36].\nNeuro:Symbolic Neuro approach incorporates symbolic rules into NNs to guide the learning process, where symbolic knowledge is compiled into the structure of neural models for enhancing the model interpretability. For instance, logical NNs (LNNs) [23] encode knowledge or domain expertise as symbolic rules (first-order logic or fuzzy logic) that act as constraints on the NN output. Other examples include the application of deep learning for symbolic mathematics [24] and differentiable inductive logic programming (ILP) [25].\nNeuroSymbolic is a type of hybrid approach that combines symbolic logic rules with NNs. It involves mapping symbolic logic rules onto embeddings that serve as soft constraints or"}, {"title": "III. REPRESENTATIVE NEURO-SYMBOLIC MODELS", "content": "This section presents selected widely-used neuro-symbolic AI workloads as representative ones for our analysis. We consider them representative because they are diverse in terms of applications, model structures, and computational patterns.\nA. Model Overview.\nWe select seven neuro-symbolic AI models for profiling analysis (Tab. III): LNN on logic program tasks [23], LTN on querying and reasoning tasks [26], NVSA [7] on the Raven's Progressive Matrices task [33], NLM on relational reasoning and decision making tasks [30], VSAIT on unpaired image-to-image translation tasks [21], ZeroC on cross-domain classification and detection tasks [29], and PrAE on spatial-temporal reasoning tasks [22]. These selected workloads represent Neuro:Symbolic\u2192Neuro, NeuroSymbolic, Neuro|Symbolic, and Neuro[Symbolic] systems (Sec. II), respectively. Interested readers could refer to their references for more details.\nB. Logical Neural Network (LNN)\nLNN is a neuro-symbolic framework that integrates neural learning with symbolic logic, enabling direct interpretability, domain knowledge utilization, and robust problem-solving [23]. LNNs map neurons to logical formula elements, using parameterized functions to represent logical connectives (e.g., \u2227, \u2228) with constraints to preserve logical behavior. By combining facts and rules within a neural framework, LNNs use weighted real-valued logics via \u0141ukasiewicz logic [26]. Compared to neural models, LNNs offer superior logical expressivity, tolerance to incomplete knowledge, and general task applicability, excelling in theorem proving with compositional, modular structures.\nC. Logical Tensor Network (LTN)\nLTN is a neuro-symbolic framework for querying, learning, and reasoning with data and abstract knowledge using fuzzy first-order logic (FOL) [26]. LTN grounds FOL elements in data using neural graphs and fuzzy logic, transforming"}, {"title": "IV. WORKLOAD CHARACTERIZATION METHODOLOGY", "content": "This section presents our neuro-symbolic AI workload profiling methodology (Sec. IV-A) and operator characterization taxonomy (Sec. IV-B) that will be leveraged in Sec. V."}, {"title": "A. Workload Profiling Methodology", "content": "We first conduct function-level profiling to capture statistics such as runtime, memory, invocation counts, tensor sizes, and sparsity of each model, by leveraging the built-in PyTorch Profiler. We also perform post-processing to partition the characterization results into various operation categories. The experiments are conducted on a system with Intel Xeon Silver 4114 CPU and Nvidia RTX 2080 Ti GPU (250W), as well as edge SoCs such as Xavier NX (20W) and Jetson TX2 (15W)."}, {"title": "B. Workload Characterization Taxonomy", "content": "On top of function-level profiling, we further conduct compute operator-level profiling for further analysis. We classify each neural and symbolic workload of the LNN, LTN, NVSA, NLM, VSAIT, ZeroC, and PrAE neuro-symbolic models into six operator categories: convolution, matrix multiplication (MatMul), vector/element-wise tensor operation, data transformation, data movement, and others [52].\nConvolution: refers to operations involving overlaying a matrix (kernel) onto another matrix (input) and computing the sum of element-wise products. This process is slid across the entire matrix and transforms the data. Convolution is common in neural networks and leads to high operational intensity.\nMatrix Multiplication: refers to general matrix multiplication (GEMM) with two matrices, either dense or sparse. Fully-connected layers in neural networks use GEMM as their primary mathematical operation. Multiplication of large, dense matrices is typically computationally intensive but highly parallelizable. There is typically a trade-off between the generality of the sparsity and the overhead of hardware optimization. Sparse matrix multiplication requires efficient mechanisms to perform lookups into the tables of non-zero values.\nVector/Element-wise Tensor Operation: refers to operations performed element-wise on tensors (generalized matrices, vectors, and higher-dimensional arrays), including addition, subtraction, multiplication, and division, applied between two tensors element by element, as well as activation, normalization, and relational operations in neuron models.\nData Transformation: refers to operations that reshape or subsample data, including matrix transposes, tensor reordering, masked selection, and coalescing which is a process in which duplicate entries for the same coordinates in a sparse matrix are eliminated by summing their associated values.\nData Movement: refers to data transferring from memory-to-compute, host-to-device, and device-to-host, as well as operations such as tensor duplication and assignment.\nOthers: refers to operations such as fuzzy first of logic and logical rules that are utilized in some symbolic AI workloads."}, {"title": "V. WORKLOAD CHARACTERIZATION RESULTS", "content": "This section analyzes the performance characteristics of representative neuro-symbolic workloads and discusses their runtime and scalability (Sec. V-A), compute operators (Sec. V-B), memory usage (Sec. V-C), operation graph (Sec. V-D), hardware utilization (Sec. V-E), and sparsity (Sec. V-F)."}, {"title": "A. Compute Latency Analysis", "content": "End-to-end latency breakdown. We first characterize the end-to-end latency of representative neuro-symbolic A\u0399 workloads (Fig. 2). We can observe that (1) Compared to neural workloads, symbolic workloads are not negligible in computing latency and may become a system bottleneck. For example, the neural (symbolic) workloads account for 54.6% (45.4%), 48.0% (52.0%), 7.9% (92.1%), 39.4% (60.6%), 16.3% (83.7%), 73.2% (26.8%), and 19.5% (80.5%) runtime of LNN, LTN, NVSA, NLM, VSAIT, ZeroC, and PrAE models, respectively (Fig. 2a). Notably, the symbolic workload dominates the NVSA's runtime, predominately due to the sequential and computational-intensive rule detection during the involved reasoning procedure. (2) The real-time performance cannot be satisfied, e.g., RTX 2080Ti GPU takes 380 s and TX2 takes 7507 s for RPM task in NVSA (Fig. 2b). Even if more computing resources are available to reduce neural inference time, the significant overhead of vector-symbolic-based reasoning still prohibits real-time execution. (3) The symbolic operations may not be well accelerated by GPU. For example, symbolic counts for 92.1% of total NVSA inference time while its floating-point operations (FLOPS) count for only 19% of total FLOPS, indicating inefficient computation.\nTakeaway 1: Neuro-symbolic AI models typically exhibit high latency compared to neural models, prohibiting them from real-time applications. Symbolic operations are processed inefficiently on CPU/GPUs and may result in system bottlenecks.\nEnd-to-end latency scalability. We evaluate the end-to-end runtime across various task sizes and complexities, as shown in Fig. 2c of RPM task for NVSA. We can observe that (1) The neural vs. symbolic runtime proportion remains relatively stable across various task sizes. For example, when task size increases from 2\u00d72 to 3\u00d73, the symbolic runtime slightly changes from 91.59% to 87.35%. (2) The total runtime increases quadratically with task size evolving. For example, the total runtime increases 5.02\u00d7 in the above case, indicating the potential scalability bottleneck of neuro-symbolic models.\nTakeaway 2: The neural and symbolic components runtime ratio remains relatively stable while total latency explodes with the task complexity evolving. The potential scalability bottleneck calls for highly scalable and efficient architecture.\nRecommendation 1: Optimization on neuro-symbolic workloads from algorithm-system-hardware cross-layer perspectives is highly desirable for achieving real-time, efficient and scalable cognitive systems."}, {"title": "B. Compute Operator Analysis", "content": "Fig. 3a partitions the neural and symbolic workloads of the LNN, LTN, NVSA, NLM, VSAIT, ZeroC, and PrAE workloads into six operator categories (Sec. IV-B) with runtime latency breakdown. We make the following observations:\nNeural Workload Analysis. The neural workload is dominated by the MatMul and activation operations. LTN (neuro) is dominated by MatMul due to its heavy MLP components, while NVSA, VSAIT, and PrAE's (neuro) majority runtime is on MatMul and convolution because they adopt the neural network as the perception backbone for feature extraction. By contrast, a large portion of LNN and NLM's (neuro) runtime is on vector and element-wise tensor operations due to the sparse syntax tree structure composed of proposition logic and the sequential logic deduction computations on multi-group architecture. Notably, data movement also takes up a significant amount of LNN (neuro) runtime because of its unique bidirectional dataflow during reasoning inference.\nSymbolic Workload Analysis. The symbolic workload is dominated by vector and scalar operations that exhibit low operational intensities and complex control flows. Both LNN, LTN, and NLM's (symbolic) have a large number of logic operations, posing parallelism optimization opportunities in their database queries and arithmetic operations, especially for larger symbolic models. Meanwhile, LNN (symbolic) is severally data movement-bounded due to its sparse and irregular memory accesses and bidirectional inference, where model-aware dataflow architecture would likely be beneficial for alleviating this bottleneck. NVSA, VSAIT, and PrAE's (symbolic) are composed of vectors for vector-symbolic operations. Notably, these operations usually stem from high-dimensional distributed vector computations (e.g., binding, bundling) for symbolic representation, which are difficult to process efficiently on GPUs. Therefore, the challenges of accelerating these computations will become increasingly important as the task and feature complexities further grow. We leverage VSA kernels as a case study and present a cross-layer optimization solution in Sec. VI to improve system efficiency.\nTakeaway 3: The neural components mainly consist of MatMul and Convs, while the symbolic components are dominated by vector/element-wise tensor and logical operations."}, {"title": "C. Memory and System Analysis", "content": "Memory Usage Analysis. Fig. 3b characterizes the memory usage of the LNN, LTN, NVSA, NLM, VSAIT, ZeroC, and PrAE workloads during computation. We can observe that (1) PrAE (symbolic) consumes a high ratio of memory due to its large number of vector operations depending on intermediate results and exhaustive symbolic search. NVSA (symbolic) slightly alleviates the vector-symbolic operation memory by leveraging probabilistic abduction reasoning. ZeroC (neuro) contains energy-based models and process images in a large ensemble thus taking much memory. (2) In terms of storage footprint, neural weights and symbolic codebooks typically consume more storage. For example, neural network and holographic vector-inspired codebook account for >90% memory footprint in NVSA, because NVSA neural frontend enables the expression of more object combinations than vector space dimensions, requiring the codebook to be large enough to contain all object combinations and ensure quasi-orthogonality.\nSystem Roofline Analysis. Fig. 3c employs the roofline model to quantify the memory boundedness of RTX 2080Ti"}, {"title": "D. Operation and Dataflow", "content": "Fig. 4 analyzes the operation dependency in representative neuro-symbolic workloads. We can observe that the reasoning computation of NVSA, VSAIT, and PrAE depends on the result of the frontend neural workload and thus lies on the critical path during inference. LNN, LTN, NLM, and ZeroC need to compile the symbolic knowledge in neural representation or input embeddings. The complex control results in inefficiency in CPU and GPU, and the vector-symbolic computation period results in low hardware utilization. There are opportunities for data pre-processing, parallel rule query, and heterogeneous and reconfigurable hardware design to reduce this bottleneck.\nTakeaway 5: The symbolic operations depend on the neural module results or need to compile into the neural structure, thus lying on the critical path of end-to-end neuro-symbolic systems. The vector-symbolic computation phase and complex control of neuro-symbolic components bring low hardware resource utilization and inefficiency in CPU/GPU."}, {"title": "E. Hardware Inefficiency Analysis", "content": "The hardware inefficiencies of executing neuro-symbolic workloads mainly come from ALU underutilization, low cache hit rate, and massive data transfer. We leverage Nsight Systems/Compute tools to further characterize the GPU behavior of executing selected neuro-symbolic workloads. Tab. IV lists the compute, memory, and data movement characteristics of representative neural and symbolic kernels in NVSA as an example. We observe that typically in symbolic operations, the ALU utilization is <10%, the L1 cache hit rate is around 20%, the L2 cache hit rate is around 40%, and DRAM bandwidth utilization is around 90% with several memory-bounded. The data transfer memory operations account for around 50% of total latency, where >80% is from host CPU to GPU. Additionally, the synchronization overhead and waiting for GPU operations to complete results in CPU underutilization.\nTakeaway 6: While neural kernels exhibit high compute utilization and memory efficiency in GPUs, symbolic operations suffer from low ALU utilization, low L1 cache hit rates, and high memory transactions, resulting in low efficiency."}, {"title": "F. Sparsity Analysis", "content": "Neuro-symbolic workloads also exhibit sparsity features. For example, Fig. 5 characterizes the sparsity of NVSA symbolic modules, including probabilistic mass function (PMF)-to-VSA transform, probability computation, and VSA-to-PMF transform, under different reasoning rule attributes. We can observe that NVSA has a high sparsity ratio (>95%) with variations for specific attributes and unstructured patterns. Similarly, ZeroC and LNN also demonstrate >90% sparsity ratio, while LTN features a dense computation pattern.\nTakeaway 7: Some neural and vector-symbolic components demonstrate a high level of unstructured sparsity with variations under different task scenarios and attributes."}, {"title": "G. Uniqueness of Neuro-Symbolic vs. Neural Networks", "content": "To summarize, based on above analysis, neuro-symbolic AI workloads differ from neural networks mainly in three aspects:"}, {"title": "VI. CASE STUDY: HARDWARE ACCELERATION OF VECTOR-SYMBOLIC ARCHITECTURE", "content": "This section presents a cross-layer acceleration case study for vector-symbolic architecture (VSA), which is a powerful model in many neuro-symbolic tasks [7], [21], [53], [54]. We develop a design method consisting of accelerated vector-symbolic kernel formulation (Sec. VI-A, VI-B), architecture and dataflow (Sec. VI-C), and programming method (Sec. VI-D), that overcomes computational inefficiencies from executing VSA components on CPUs and GPUs (Sec. VI-E).\nOur proposed hardware design is inspired by neuro-symbolic workload insights from the characterization study in Sec. V. Specifically, as shown in Tab. V, it features (1) an energy-efficient dataflow with heterogeneous arithmetic units that can flexibly execute key vector-symbolic operations, (2) a distributed memory system employing near-memory computing to enhance scalability and memory performance, (3) compressed storage of symbolic operators to reduce the memory footprint of vector codebooks, and (4) a tiled design for vector-symbolic units to minimize data movement and optimize computational efficiency. These features collectively enable a highly efficient and scalable vector-symbolic hardware accelerator that significantly outperforms traditional platforms."}, {"title": "A. Vector-Symbolic Operations", "content": "In the vector-symbolic kernel, computational elements, such as scalars and objects, are represented with hypervectors which can be manipulated by a set of algebraic operations [15], [55], specifically, (1) binding, or element-wise multiplication, which creates a new hypervector that is quasi-orthogonal (dissimilar) to its constituents; (2) bundling, or element-wise addition, which combines hypervectors using element-wise majority count; (3) permutation, which rearranges the elements of a hypervector to preserve its order within a sequence; (4) scalar multiplication, which scales hypervector elements with a scalar weight The similarity between vectors is measured using a variety of distance metrics, such as the dot product, Hamming distance, L1, and L2 [56], [57]. These operations collectively form a mathematical framework for implementing various cognitive functions tailored for VSA operations [58]."}, {"title": "B. Vector-Symbolic Kernel Formulation", "content": "We present a description of operations and programmability features of our proposed hardware accelerator using a formal representation, i.e., kernel function. We express this kernel function as O := F(y, s), where F(\u00b7) integrates an array of kernel sub-functions fi that together cover the whole domain of accelerator operations, and y = {y1, y2,...} represents an array combining all item and prototype vectors used in computation. The argument s is defined by a group of conditional variables s = {$1,82,...}, which together are used to draw the sub-domains associated with the sub-functions fi.\nThe kernel functionality integrates computations for encoding and decoding, memory, and reasoning. Next, we formulate sub-functions fi to describe these computations.\nEncoding and Decoding Kernel. To facilitate the encoding and decoding, the kernel function needs to allow for flexible configuration of hypervector operations (binding, bundling, permutation). We take into account that binding can be distributed over bundling [59], and propose the kernel function:\na(y, ($1,82) := b(y, (82));\n$1 = 0\ny;\n$1 = 1\nb(y, (s2)) :=\n\u03a3i [b(Yi, (S2))]; $2 = 0, \u2200{i, j} \u2286 N\nj(yj);\n$2 = 1, \u2200{i, j} \u2286 N\nPj (Yj);\n$2 = 2\njP(j-1) (Yj); $2 = 3\nwhere pj means that the permutation operation (p) is repeated j times, i.e., $p_3(x) = \\rho(\\rho(\\rho(x)))$. Likewise, when j = 3, the termj(xj) becomes equivalent to (X1 X2 X3), and also jP(j-1)(xj) becomes equivalent to (x1&p(x2)&p(p(x3))).\nResonator-Network Kernel. This is a template VSA kernel for reasoning functions. Specifically, it takes as input a composed vector (which may represent a visual scene involving multiple objects as in the RPM problem) and seeks to factorize the vector into its constituent factors. The operation of the resonator network involves iterative steps for similarity evaluation and projection [54]. The kernel function used for projection can be defined as follows: $c(y) := \\sum_{i}[n_i \\times y_i]; \\forall i \\in N; n_i e Z$. Here, c(y) calculates a weighted sum of the vectors in y."}, {"title": "C. Hardware Architecture and Dataflow", "content": "We present a method for constructing architecture dataflow informed by the derived VSA kernels. Fig. 7 shows the overall architecture, consisting of three subsystems: (1) memory and codebook-generation subsystem (MCG), (2) vector-symbolic operations subsystem (VOP), and (3) distance computation subsystem (DC). A control unit is used to decode instructions and determine control configurations. A description of these subsystems and their internal operations are presented below."}, {"title": "D. Accelerator Control Methods", "content": "The configuration of the different modules as described above exhibits a pipelined architecture that consists of seven pipeline stages, with each stage associated with a certain type of operation (Fig. 8). Such a pipelined configuration motivates a streamlined integration of dataflow and control-flow primitives, allowing different control methods to be applied without hazard. To perform this study, we particularly examine two control methods for this accelerator: single-operation-per-cycle (SOPC) and multiple-operations-per-cycle (MOPC).\nSOPC and MOPC. SOPC simplifies programming and reduces power consumption since only one pipeline stage switches during each cycle. However, this approach increases runtime, making it unsuitable for high-throughput applications. Conversely, MOPC enables pipeline stages to perform operations simultaneously, thus increasing the number of operations per cycle. However, MOPC leads to increased power consumption and requires a complex mapping framework to analyze program dependencies and optimize control activities. MOPC is better suited for high-throughput applications that require a balance between runtime and power consumption.\nControl Methods Comparison. We compare SOPC and MOPC by implementing factorization using the resonator network kernel. Fig. 9 compares the runtime and power consumption of SOPC and MOPC when executing at various complexity levels (number of factors). We observe that MOPC achieves lower runtime in comparison with SOPC, and that the speed-up gained by using MOPC increases from 1.8 to"}, {"title": "E. Evaluation Results", "content": "Experimental Setup. The design was implemented in SystemVerilog and synthesized with Synopsys Design Compiler using foundry 28nm library. Tab. VI lists the architectural parameters. The energy is measured using Synopsys PrimeTime PX. VSA workloads are also simulated on NVIDIA V100 GPU as the baseline, and GPU power was measured using the nvidia-smi utility. The algorithms listed in Tab. VII are used for evaluation, facilitating a comprehensive assessment of multi-layer cognition systems.\nLatency. We first evaluate the impact of varying VSA accelerator (Acc) size on latency. Fig. 11a shows that Acc4 provides speed-up of 1.3-1.8\u00d7 compared to Acc2, highlighting resource underprovisioning in Acc2. However, we observe that the benefits of scaling up the design from Acc4 to Acc8 are not equally realized by all algorithms. Specifically, only 1.16\u00d7 speed-up is achieved by MULT. This is because MULT typically performs VOP-intensive computations for sequence encoding and thus its response to further increase in design size is minimal. On the other hand, REACT achieves 1.69\u00d7 speed-up when Acc8 is used. This result is attributed to the fact that REACT performs extensive clean-up memory operations, which can be efficiently distributed across all tiles."}, {"title": "VII. OUTLOOK AND RESEARCH OPPORTUNITIES", "content": "In this section, we discuss the challenges and opportunities for neuro-symbolic systems, and outline our vision for the future, focusing on the system and architecture perspectives.\nBuilding ImageNet-like neuro-symbolic datasets. Neuro-symbolic systems hold great potential in achieving human-like performance [63]. However, their current applications are still limited to basic decision-making and reasoning problems, falling short of the broader vision of human cognitive abilities, such as deductive reasoning, compositionality, and counterfactual thinking. It is still an open question of how perception learned from other domains can be transferred to abstract reasoning tasks. To significantly advance the metacognitive capabilities of neuro-symbolic systems, more challenging and suitable datasets are highly desirable to unleash its potential.\nUnifying neuro-symbolic models. Integrating neural, symbolic, and probabilistic approaches offers promise to improve Al models' explainability and robustness. However, the current attempts to combine these complementary approaches are still in a nascent manner how to integrate them in a principled manner remains an open challenge. Particularly, symbolic components can be combined with Large Language Models (LLMs) to improve their planning and reasoning capabilities [64]. We envision a unified framework to design algorithms that opportunistically combine neural and symbolic with probabilistic representations, and for quantifying scaling laws for neuro-symbolic inference versus large neural models.\nDeveloping efficient software frameworks. Neuro-symbolic AI systems typically utilize underlying logic, such as fuzzy logic, parameterization, and differentiable structures, to support learning and reasoning capabilities. However, most system implementations create custom software for deduction for the particular logic, which limits modularity and extensibility. Thus, new software frameworks are needed that can encompass a broad set of reasoning logical capabilities and provide practical syntactic and semantic extensions while being fast and memory-efficient. Moreover, new programming models and compilers that can facilitate the ease and efficient realization of the neuro-symbolic models are of significance to realize the full promise of neuro-symbolic AI paradigms.\nBenchmarking diverse neuro-symbolic workloads. Given the proliferation of neuro-symbolic algorithms and the rapid hardware advancements, it is crucial to benchmark neuro-symbolic AI systems in a comparable and validated manner. To achieve this, from the system aspect, we need representative benchmarks that capture the essential workload characteristics (e.g., compute kernels, access patterns, and sparsity) of neural and symbolic models, and that can be quantitatively tested in human-AI applications. From an architectural and hardware perspective, we need modeling-simulation frameworks to enable the development of novel architectures for these workloads and build optimized modular blocks as libraries by leveraging workload characteristics. Benchmarking neuro-symbolic computing will guide ML researchers and system architects in investigating the trade-offs in accuracy, performance, and efficiency of various neuro-symbolic algorithms, and in implementing systems in a performance-portable way.\nDesigning cognitive hardware architectures. Neuro-symbolic workloads that combine neural, symbolic, and probabilistic methods feature much greater heterogeneity in compute kernels, sparsity, irregularity in access patterns, and higher memory intensity than DNNs. This leads to an increasing divergence with the current hardware roadmap that largely focuses on matrix multiplication and regular dataflow. Therefore, we need novel architectures with dedicated processing units, memory hierarchies, and NoCs that can handle the additional complexities in computations and communications. Additionally, the architecture needs to provide flexibility with both configurable interconnects and full addressable memories to keep pace with neuro-symbolic AI algorithmic innovations."}, {"title": "VIII. CONCLUSION", "content": "Neuro-symbolic AI is an emerging paradigm for developing efficient, robust, explainable, and cognitively advanced AI systems. This paper provides a systematic characterization of neuro-symbolic system performance and analyzes their operational components. Leveraging insights from profiling, we propose cross-layer optimization techniques and present a case study of a hardware architecture designed to enhance their performance and efficiency. We believe this research will address key challenges and highlight opportunities essential for advancing next-generation neuro-symbolic AI systems."}]}