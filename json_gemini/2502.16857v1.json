{"title": "Sarang at DEFACTIFY 4.0: Detecting Al-Generated Text\nUsing Noised Data and an Ensemble of DeBERTa Models", "authors": ["Avinash Trivedi", "Sangeetha Sivanesan"], "abstract": "This paper presents an effective approach to detect AI-generated text, developed for the Defactify 4.0 shared task\nat the fourth workshop on multimodal fact checking and hate speech detection. The task consists of two subtasks:\nTask-A, classifying whether a text is AI generated or human written, and Task-B, classifying the specific large\nlanguage model that generated the text. Our team (Sarang) achieved the 1st place in both tasks with F1 scores of\n1.0 and 0.9531, respectively. The methodology involves adding noise to the dataset to improve model robustness\nand generalization. We used an ensemble of DeBERTa models to effectively capture complex patterns in the text.\nThe result indicates the effectiveness of our noise-driven and ensemble-based approach, setting a new standard\nin Al-generated text detection and providing guidance for future developments.", "sections": [{"title": "1. Introduction", "content": "Large Language Models (LLMs), such as ChatGPT [1], are really good at writing long pieces of text\nthat sound very human. While these developments have various beneficial applications, they also raise\nconcerns about potential misuse, such as the automatic creation of fake news articles and academic\ncontents [2]. To address these risks, various algorithms have been developed to detect AI-generated\ntext, which include watermarking techniques [3], tools like GPTZero [4], DetectGPT [5], and OpenAI's\ntext classifier [6].\nThe task of detecting AI-generated text is inherently challenging, as recent research [7] highlights\nthe increasing sophistication of newer, more capable LLMs. Early studies demonstrated that humans\nstruggle to tell if something was written by a computer or a human. Given the ethical implications and\nthe complexity of the problem, creating robust detection systems remains an active area of research.\nThe Defactify 4.0 shared task 1 [8], part of the fourth workshop on multimodal fact-checking and hate\nspeech detection, featured two subtasks: Task-A focused on distinguishing between AI-generated and\nhuman-authored text, while Task-B aimed to identify the specific LLM responsible for generating the\ntext. This paper proposes an ensemble based DeBERTa model, trained and validated on noisy dataset to\nmake the model more robust. This work highlights how adding noise to the dataset makes the model\nremain resilient to disturbances. It captures features invariant under perturbations and demonstrates\nsignificantly improved robustness against such disturbances.\nThe rest of the paper is as follows. Section 2 contains related work, section 3 describes the dataset,\nsection 4 describes our methodology, section 5 contains experimental results and section 6 includes\nconclusions and future work."}, {"title": "2. Related work", "content": "Recent advancements have demonstrated significant progress in methods for detecting AI-generated\ntext. These methods broadly fall into three categories: statistical approaches, classifier-based detectors,\nand watermarking techniques.\nTraditional statistical detection methods leverage metrics such as entropy, perplexity, and n-\ngram frequency to identify differences in linguistic patterns between human and machine-generated\ntext [9, 10]. A recent innovation, DetectGPT [5], builds on these principles, focusing on the negative\ncurvature areas of a model's log probability. By generating and comparing perturbed variations of\ntext, DetectGPT determines its likelihood of being machine-generated based on log probabilities. This\nmethod achieves significantly higher AUROC scores compared to other zero-shot detection approaches,\nmaking it a notable advancement in statistical detection techniques.\nClassifier-based detection methods are commonly employed in identifying fake news and mis-\ninformation [11, 12]. OpenAI, for example, fine-tuned a GPT model using datasets from Wikipedia,\nWebText, and human-labeled samples to create a classifier capable of discerning machine-generated\ntext. This model combines automated classification with human evaluation, demonstrating its effi-\ncacy in detecting AI-generated content. Such advancements contribute to mitigating the spread of\nmisinformation and improving societal trust in online content [13].\nWatermark-Based Identification has emerged as a compelling alternative for machine-generated\ntext detection. Historically used in image processing for copyright protection and data hiding [14, 15],\nwatermarking techniques have recently been adapted for natural language. [16] proposed a novel\nwatermarking approach that utilizes language model logits to embed invisible watermarks in text. This\nmethod categorizes tokens into green and red lists, guiding token selection to create patterns that are\nimperceptible to human readers. These advancements not only enhance content authentication and\ncopyright enforcement but also pave the way for secure communication, digital rights management,\nand privacy protection.\nWhile existing methods effectively identify unaltered LLM-generated content, their reliability against\nuser-modified versions remains underexplored. Research shows that even small changes can significantly\nweaken the performance of these detection techniques. We proposed a noise-driven, DeBERTa based\nensemble approach to address the issue, as it remains largely unaffected by disturbances and highlight\ndifferences between human and LLM-generated text. This method improves robustness in detecting\nperturbed LLM-generated content.\nOur method is inspired from [17, 18, 19], where [17] observed that training machine translation\nmodels on a balanced mix of simple synthetic noise enhances robustness to character-level variations,\nsuch as typos, without compromising performance on clean text. Authors in [18] introduces Easy Data\nAugmentation (EDA) four simple yet effective techniques, synonym replacement, random insertion,\nrandom swap, and random deletion. It significantly improves text classification performance, especially\nfor smaller datasets, achieving comparable results with reduced training data. Authors in [19] highlights\nthat adding noise can be beneficial for model generalization. It proposes two Noising technique, First is\nUnigram Noising, Which randomly replaces tokens in a sequence with words sampled from the unigram\nfrequency distribution at a probability \u03b3, introducing corpus-wide diversity. Second is Blank Noising,\nWhich replaces tokens with a placeholder token (\u201c_\u201d) at a probability y, simulating missing context to\nenhance generalization. We used DeBERTa [20] as our base model, which is becoming popular in NLP\nbecause they can predict words using both the left and right context and are trained on a large amount\nof plain text from the internet."}, {"title": "3. Dataset", "content": "The dataset [21] provided in this shared task consists of three columns namely Text, Label_A and\nLabel_B, where Text is the AI or Human generated text, Label_A denoting class 0 or 1 (Human/AI),\nLabel_B denotes one of the specific LLMs (Human_story, gemma-2-9b, mistral-7B, qwen-2-72B, llama-8B,"}, {"title": "4. Methodology", "content": "4.1. Finetuning of DeBERTa on Original Dataset\nWe started by fine-tuning a set of DeBERTa models on original train set and validated on original val set\nto create a trustworthy baseline for our investigations. Table 2 provides a summary of the findings from\nthese experiments. Out of all the evaluated configurations, the DeBERTa-v3-small model performed the\nbest on Task-A, showing the most promising result on test set. This suggests that the model is capable\nof successfully capturing the subtleties and patterns required to meet Task-A's requirements.\nWhile working on Task-B, we found that all models, including DeBERTa-v3-small, exhibited signs of\noverfitting in spite of our various attempts. The training and testing performances diverged significantly\nas a result of this overfitting, which eventually resulted in less than ideal generalisation for Task-B.\nThese results imply that in order to enhance performance on Task-B while preserving strong outcomes\nfor Task-A, further tactics, such as regularisation schemes, data augmentation, or different modelling\napproaches, might be required.\n4.2. Best performing system\nInspired from [17, 18, 19], we implemented a data noising strategy to enhance the robustness of our\nlanguage model. This technique, inspired by the authors' insights on the benefits of noise injection\nfor smoothing, involves introducing controlled disruptions to the dataset. The architecture of our\nbest-performing system is illustrated in Fig 1. We noised our dataset by injecting 10% junk or garbled\nwords into each data points as shown in Table 3. These junk words were randomly generated with\nlengths varying between 3 to 8 characters, ensuring the injected noise was both unpredictable and\ndiverse. This approach mimics real-world scenarios where noisy or corrupted data is often encountered,\nenabling the model to learn more resilient representations."}, {"title": "5. Experimental Results", "content": "The result of our experiments, detailed in Table 2 and Table 4, reveal valuable insights into the impact\nof noised data on model performance. It also highlights the potential benefits of incorporating noise\ninto training dataset, particularly for tasks requiring high resilience to incomplete inputs. These noisy\ndata-driven experiments demonstrates significant performance improvements, particularly for the\nDeBERTa-v3-small model, across both Task-A and Task-B with F1-score of 1.0 and 0.9454 respectively.\nThis improvement underscores the effectiveness of noise injection as a regularization strategy, enhancing\nthe model's generalization capabilities.\nAdditionally, for Task-B, we explored a sequential fine-tuning approach by further training the\nDeBERTa-v3-small model on the noisy dataset after it had already been fine-tuned on the original\ntraining data. It achieves F1-score of 0.9167, Although this method did not outperform the results\nachieved through direct fine-tuning (F1-score of 0.9454) on the noisy dataset, it captured distinct patterns"}, {"title": "6. Conclusions and Future Work", "content": "We have performed various experiments which include fine-tuning on original train data, noise-injected\ndataset, and a combination of sequential fine-tuning and weighted ensemble modeling. Among these,\nthe DeBERTa-v3-small model fine-tuned directly on the noisy dataset demonstrated the most promising\nresults, achieving significant improvements across both Task-A and Task-B. Furthermore, utilizing\nan ensemble of models fine-tuned on original and noisy data allowed us to capture diverse patterns,\nultimately outperforming all previous individual model attempts.\nOur findings highlight the importance of data augmentation technique, such as noise injection, for\nenhancing model generalization and robustness. Future work will aim to explore further the potential of\ndynamic data noising strategies and ensemble techniques with more variants of the DeBERTa models."}]}