{"title": "Exploring Semantic Clustering in Deep Reinforcement\nLearning for Video Games", "authors": ["Liang Zhang", "Adarsh Pyarelal", "Justin Lieffers"], "abstract": "In this paper, we investigate the semantic clustering properties of deep reinforce-\nment learning (DRL) for video games, enriching our understanding of the internal\ndynamics of DRL and advancing its interpretability. In this context, semantic\nclustering refers to the inherent capacity of neural networks to internally group\nvideo inputs based on semantic similarity. To achieve this, we propose a novel DRL\narchitecture that integrates a semantic clustering module featuring both feature\ndimensionality reduction and online clustering. This module seamlessly integrates\ninto the DRL training pipeline, addressing instability issues observed in previous\nt-SNE-based analysis methods and eliminating the necessity for extensive manual\nannotation of semantic analysis. Through experiments, we validate the effective-\nness of the proposed module and the semantic clustering properties in DRL for\nvideo games. Additionally, based on these properties, we introduce new analytical\nmethods to help understand the hierarchical structure of policies and the semantic\ndistribution within the feature space.", "sections": [{"title": "1 Introduction", "content": "Human beings excel at summarizing and categorizing knowledge from complex tasks with large\namounts of information, enabling rapid skill acquisition for better adaptation to their environment\n[1-3]. Some applications of neural networks that simulate the human brain, have revealed semantic\nclustering properties. We use the term semantic clustering to refer to a neural network's intrinsic\nability to internally organize information based on semantic similarity. For example, in natural\nlanguage processing (NLP), the spatial arrangement of word embeddings [4, 5] mirrors semantic\nsimilarities between words, resulting in clusters of semantically related words in the embedding\nspace. In computer vision (CV), semantic clustering denotes neural networks' intrinsic ability to\norganize visual information based on semantic similarity, improving efficiency in tasks such as image\nclassification, clustering, segmentation [6-9].\nWhile semantic clustering has been extensively explored in NLP and CV, our understanding of its\nimplications in deep reinforcement learning (DRL) remains limited. This is primarily due to the\ncomplexity of DRL, characterized by its temporal dynamics and lack of direct guiding signals from\nsupervised learning. The interplay of sequential decisions over time presents a challenge in capturing\nthe evolving semantics within the framework of DRL. Early efforts in this domain sought to introduce\nexternal constraints, e.g., bisimulation [10, 11] and contrastive learning [12-14], to construct feature\nspaces with distributions conducive to semantic clustering. In contrast to these works, we investigate\nwhether DRL inherently possesses the capacity to perform semantic clustering."}, {"title": "2 Related Work", "content": "Semantic Clustering in NLP and CV Prior work has demonstrated that the spatial configuration\nof word embeddings reflects semantic similarities among words, resulting in the formation of clusters\ncontaining semantically related terms in the embedding space [4, 5]. Similarly, in CV, semantic\nclustering characterizes the inherent capability of neural networks to structure visual information\nbased on semantic similarity. This process demonstrates that images sharing semantic content\nare proximal in the learned feature space. The intrinsic semantic structure in visual data supports\nimproved performance in CV tasks, e.g., image classification, clustering, and segmentation [6-9].\nSemantic Clustering in DRL The use of t-SNE for visualizing the feature space in DRL has been\npreviously explored by Mnih et al. [15] and Zahavy et al. [16]. t-SNE methods transform the distance\nmetric between data points into conditional probabilities in both the original high-dimensional and\nmapped low-dimensional spaces. The optimization process involves minimizing the Kullback-Leibler\ndivergence between these probabilities. The t-SNE visualizations in these studies, driven by RL\npolicy training for dimensionality reduction in the feature space, reveal that features of states with\nclose pixel distances tend to cluster together. However, due to the fixed nature of the tested Atari game\nscenarios, the existence of semantic clustering could not be effectively verified. This observation\nmotivates our usage of Procgen to validate our approach, since it supports the generation of varied\nenvironments that are nevertheless semantically similar.\nInterpretability of DRL Many studies have contributed to enhancing the interpretability of DRL.\nApproaches such as attention mechanisms generate attention maps for individual frames to elucidate\nthe agent's decision-making focus [19, 20]. The Symbolic Deep Reinforcement Learning (SDRL)\nframework [21] explicitly represents symbolic knowledge for high-level symbolic planning, incor-\nporating intrinsic goals, and uses DRL for learning low-level control policies, thereby improving\ntask-level interpretability. Linear Model U-trees (LMUTs) [22] approximate neural network pre-\ndictions with expressive power suitable for approximating a Q-value function. Other works have\nexplored diverse visualization methods to enhance RL interpretability [16, 23, 24]. Unlike the\naforementioned works, we focus on understanding how DRL models internally group information,\nproviding insights into the spatial structure of the learned representations."}, {"title": "3 Method", "content": "The proposed architecture with a novel semantic clustering module is presented in Figure 1.\nBackground Vector-quantized variational autoencoeders (VQ-VAE) [25] comprise a successful\nfamily of generative models that combine the variational autoencoder (VAE) framework with discrete\nlatent representations through a novel parameterization of the posterior distribution. The VQ-VAE\nworkflow starts with an encoder network \u00ca that maps an input x to a latent representation \u00ca(x). This\nrepresentation is then quantized by mapping it to the nearest embedding in a codebook {e1, . . ., \u0435\u043a},\nwhere e; is the ith embedding in the codebook and K is the number of embeddings in the codebook.\nThis nearest neighbor embedding is then fed into a decoder network \u00cel to reconstruct the input x. The\nloss function for VQ-VAE is given by\n$L_{VQ-VAE} = ||x - D(e_k)||^2 + ||sg [E (x)] \u2013 e_k||^2 + \\beta ||sg [e_k] \u2013 E(x)||^2,$\nwhere sg is a stop-gradient operator and \u03b2 weights the distance reduction between the encoded output\n\u00ca (x) and its closest embedding ek."}, {"title": "3.1 Semantic Clustering Module", "content": "Inspired by the findings of Mnih et al. [15] and Zahavy et al. [16], we hypothesize the presence of\nsemantic clustering properties in DRL models for Procgen's environments, facilitating the clustering\nof features based on their mutual proximity. Furthermore, to address limitations identified in the\nprevious t-SNE-based semantic analysis (see \u00a7 1), we introduce a novel semantic clustering module.\nDimensionality Reduction Considering the complexity of video game states, their features are\nfrequently high-dimensional; e.g., DQN [15] requires 512-dimensional features when trained on Atari\ngames. Since it is challenging to cluster high-dimensional features directly, we propose to reduce the\ndimensionality of video game features and ensure the distance relationship between features in high-\nand low-dimensional spaces as much as possible (measured by pairwise similarities in \u00a7 3.2), which\nis functionally similar to the idea of t-SNE used in [15, 16]. Dimensionality reduction can also show\nthe feature distribution in a human-interpretable manner, usually by visualizing it in a 2D space.\nTo mitigate the limitations of t-SNE techniques, we propose the Feature Dimensionality Reduction\n(FDR) network. This network remaps high-dimensional features to 2D, using policy training data\nfor online training, ensuring stable and quick mapping post-training. As detailed in \u00a7 3.2, the FDR\nnetwork's loss function is designed to maintain the consistency of feature distance relationships\nbetween high-dimensional and 2D spaces."}, {"title": "3.2 Loss Function Design", "content": "The loss function for our proposed framework is given by\n$L_{total} = L_{DRL} + f_{control} (\\omega_{FDR}L_{FDR} + \\omega_{VQ-VAE}L_{VQ-VAE}).$\nThe DRL loss function LDRL comes from the original DRL model without any changes. \\omegaFDR\nand wvQ-VAE are the weights of the FDR loss (LFDR) and the modified VQ-VAE loss (L\u00fdQ-VAE),\nrespectively.\nFDR Loss The FDR loss function is based on the state features in the training batch and the FDR\nfeatures mapped with the FDR net. Our goal is to keep the conditional probabilities of features in\nlow-dimensional space as consistent as possible with those in high-dimensional space to ensure the\naccuracy of our distance-based clustering. The Student's t-distribution with a high degree of freedom\ncan approximate a Gaussian distribution, thus avoiding tuning and estimating other parameters for\nthe Gaussian distribution [29]. For this reason, we use it to measure the pairwise similarities of state\nfeatures pij in the two spaces, given by\n$p_{ij} = \\frac{d(i, j)}{\\sum_{kl}d(k, l)}$ where $d(m, n) = (1 + ||f (s_m) - f (s_n) ||^2/\\alpha)^{-\\alpha - 1}$\nwhere f is the feature extractor, s is a state in a batch, and \u03b1 is the degree of freedom of the Student's\nt-distribution. The pairwise similarities for FDR features, qij are computed using the same expression\nas (3), but with f replaced by go f, where g is the FDR net. In contrast to other deep clustering\nstudies, e.g., Xie et al. [30] and Li et al. [31], the same degree of freedom a is selected for both high-\nand low-dimensional similarities, ensuring that the original distance relationship between features is\nmaintained as much as possible in the low-dimensional space.\nFurthermore, rather than using traditional clustering methods (e.g., k-means), we perform VQ\nencoding online for clustering based on the preserved distance relationship of features in the low-\ndimensional space. The FDR loss is given by\n$L_{FDR} = - \\sum_{ij} p_{ij} log (q_{ij}) .$\nModified VQ-VAE Loss The first term in LVQ-VAE from (1) supports input reconstruction, which\nour model does not need. The third term causes FDR features to align with their nearest VQ\nembeddings, while the second term moves VQ embeddings closer to adjacent FDR features. Therefore,\nwe eliminate the first and third terms and modify the second term to obtain the modified VQ-VAE\nloss:\n$L_{VQ-VAE} = ||sg[g(f(s))] \u2013 e||^2,$\nwhere e is the closest embedding in the codebook to the FDR feature g(f(s)).\nControl Factor Since effective semantic clustering relies on a clear and distinguishable semantic\ndistribution that is often difficult to achieve in the early stage of training, we propose an adaptive\ncontrol factor strategy updated according to training performance, see Appendix A. fcontrol in (2)\nrepresents the control factor."}, {"title": "4 Simulations", "content": "In this section, we aim to: 1) validate the clustering effectiveness of our proposed method, 2) assess\nthe semantic clustering properties of DRL for video games, and 3) introduce new methods for policy\nand model analysis."}, {"title": "4.1 Assessing Clustering Effectiveness", "content": "We illustrate the clustering effectiveness of our proposed approach using CoinRun as an example.\nA similar conclusion can be easily extended to other games by using the code and checkpoints in\nthe supplementary material. We employ a trained model to collect states, using a strategy where\nthe agent randomly selects an action with probability 0.2 while following the trained policy with\nprobability 0.8 to ensure diverse state coverage. States are collected with probability 0.8, and 64\nparallel environments gather states for 500 steps, resulting in the collection of nearly 25,000 states\nfor visualization.\nCluster Separation The t-SNE visualization of PPO (Figure 2a), spreads features across the space\nwithout forming clear clusters, limiting its utility for clustering analysis and requiring detailed manual\nexamination of certain areas, as in previous studies. In contrast, the t-SNE visualization of our method\n(Figure 2b), reveals numerous distinct, small clusters. States within each of these clusters originate\nfrom the same semantic group identified by our method. This dispersion into multiple smaller clusters\nis due to t-SNE's focus on local structures and its tendency to avoid crowding, causing complete\nsemantic clusters to scatter. The visualization in the FDR space (Figure 2d), displays clear and\nseparate complete clusters, which are identified by VQ codes.\nSensitivity to Number of States Our method's stability is showcased in Figures 2c and 2e, where\nthe number of processed states is reduced by 50%. Unlike the drastic changes in feature distribution\nseen in the t-SNE space (Figure 2c), the FDR space (Figure 2e) exhibits a stable mapping, merely\nreducing the quantity of features without altering their spatial distribution.\nSensitivity to Random Seed While the t-SNE representation is sensitive to randomness, as demon-\nstrated by the significant difference between Figures 2c and 2f, the FDR space's mapping remains\nunchanged even when the random seed is altered, maintaining a consistent distribution as in Figure 2e.\nt-SNE's randomness primarily stems from its random initialization and non-convex optimization\nprocess, leading to different visualizations with different random seeds. In contrast, our model\nproduces a stable feature mapping after training, which does not vary with random seeds."}, {"title": "4.2 Semantic Clustering in DRL", "content": "In this section, we illustrate semantic clustering analysis using the Ninja game. In the Ninja game,\nthe agent navigates from the leftmost to the rightmost part of the scene, jumping over various ledges\nand scoring points by touching the mushroom on the far right. In the appendix, we analyze additional\ngames, reaching similar conclusions.\nMean Image Analysis We performed a qualitative analysis of the mean images of states within\neach cluster. Figure 3 presents state examples from the FDR space of Ninja, along with the mean\nimages of each semantic cluster, and Table 1 contains natural language descriptions of the clusters as\nwell as notable features of the mean images corresponding to each cluster. Corresponding videos can\nbe found in the supplementary material.\nUnlike static semantic clustering in some CV and NLP tasks, where clustering is based on a single\nimage or word, DRL's semantic clustering is dynamic in nature-state sequences with similar\nsemantics are grouped into the same semantic cluster. Notably, this semantic clustering goes beyond\npixel distances and operates on a semantic understanding level of the environment, as illustrated in\nfigures 3 and 4. This generalized semantic clustering emerges from the DRL model's inherent ability\nto learn and summarize from changing scene dynamics, independent of external constraints like\nbisimulation or contrastive learning, and without the need for supervised signals. The neural network's\ninternal organization of policy-relevant knowledge indicates clustering-based spatial organization\nbased on semantic similarity. Furthermore, we find that video sequences within clusters can be\nsummarized using natural language, akin to the 'skills' humans abstract during learning processes.\nHuman Evaluation In addition to qualitatively analyzing the mean images, we hired 15 human\nevaluators to validate the semantic clustering properties. Specifically, video sequences from each\nepisode are segmented into multiple clips based on the cluster each frame belongs to, and these clips"}, {"title": "4.3 Model and Policy Analysis", "content": "To better explore the knowledge organization within the internal space of DRL models, we developed\na visualization tool (see Figure 5 for an example). The tool supports 'statically' analyzing the semantic\ndistribution of models-specifically, (i) when the mouse cursor hovers over a specific feature point,\nthe corresponding state image is displayed, and (ii) the tool includes a zooming functionality to\nobserve the semantic distribution of features in detail within clusters.\nIn addition, we propose a more 'dynamic' analysis method\u2014the VQ code enables us to determine the\ncluster to which the current state belongs, which allows for the semantic segmentation of episodes, as\nexemplified in Figure 4. Our model excels at breaking down complex policies, thereby shedding light\non their inherent hierarchical structures. Moreover, this segmentation is based on semantics, making it\nunderstandable to humans and likely to improve interpretability in downstream hierarchical learning\ntasks. Consequently, this method introduces a 'dynamic' strategy for dissecting policy structures.\nWe also present several examples of policy analysis in Figure 6, based on the clustering result from\nour approach. In 6(a) and 6(b), two consecutive states are shown, with 6(a) and 6(b) belonging to\nclusters 5 and 7 respectively. We see that determining whether the agent will exhibit the behavior of\napproaching the mushroom does not depend on the appearance of the mushroom, but rather on the\npresence of the right-side wall. This is validated in another episode shown in 6(c), which belongs to"}, {"title": "5 Limitations and Future Work", "content": "Our approach has a few known limitations, which we aim to address in future work. First, semantic\nclustering depends on clear semantic distributions in the FDR space, posing challenges when policies\ndeviate significantly from the optimum, resulting in chaotic semantic distributions. Second, as\napproach uses unsupervised learning, the selection of the number of clusters is crucial; we opted for\neight clusters to predominantly ensure a singular semantic interpretation, although a few clusters\nmight encompass up to two interpretations. Finally, we will extend our exploration to additional DRL\nalgorithms, benchmarks, and practical applications."}, {"title": "6 Conclusion", "content": "In this paper, we investigated the semantic clustering properties of DRL for video games. Using\na novel approach that combines dimensionality reduction and online clustering, we analyzed the\ninternal organization of knowledge within the feature space of a DRL model (PPO). Our method not\nonly provides a stable mapping of feature positions but also enhances semantic clustering, revealing\nmeaningful structures within continuous sequences of video game states. We show that in DRL,\nthe dynamic nature of semantic clustering arises organically through the agent's interaction with its\nenvironment. As the agent explores diverse states during reinforcement learning, it naturally clusters\nsemantically related states based on spatial and temporal relationships within the environment. This\ndynamic clustering is a result of the agent's ability to exploit regularities, showcasing a distinctive\napproach compared to static semantic clustering approaches common in natural language processing\nand computer vision."}]}