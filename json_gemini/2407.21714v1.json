{"title": "UMMAN: Unsupervised Multi-graph Merge\nAdversarial Network for Disease Prediction Based\non Intestinal Flora", "authors": ["Dingkun Liu", "Hongjie Zhou", "Yilu Qu", "Huimei Zhang", "Yongdong Xu"], "abstract": "The abundance of intestinal flora is closely related\nto human diseases, but diseases are not caused by a single\ngut microbe. Instead, they result from the complex interplay\nof numerous microbial entities. This intricate and implicit con-\nnection among gut microbes poses a significant challenge for\ndisease prediction using abundance information from OTU data.\nRecently, several methods have shown potential in predicting\ncorresponding diseases. However, these methods fail to learn\nthe inner association among gut microbes from different hosts,\nleading to unsatisfactory performance. In this paper, we present a\nnovel architecture, Unsupervised Multi-graph Merge Adversarial\nNetwork (UMMAN). UMMAN can obtain the embeddings of\nnodes in the Multi-Graph in an unsupervised scenario, so that it\nhelps learn the multiplex association. Our method is the first to\ncombine Graph Neural Network with the task of intestinal flora\ndisease prediction. We employ complex relation-types to construct\nthe Original-Graph and disrupt the relationships among nodes\nto generate corresponding Shuffled-Graph. We introduce the\nNode Feature Global Integration (NFGI) module to represent the\nglobal features of the graph. Furthermore, we design a joint loss\ncomprising adversarial loss and hybrid attention loss to ensure\nthat the real graph embedding aligns closely with the Original-\nGraph and diverges from the Shuffled-Graph. Comprehensive\nexperiments on five classical OTU gut microbiome datasets\ndemonstrate the effectiveness and stability of our method. (We\nwill release our code soon.)", "sections": [{"title": "I. INTRODUCTION", "content": "ACCORDING to incomplete statistics, there are at least\n500 trillion microorganisms in the human body, outnum-\nbering human cells by more than tenfold [23]. Microorganisms\nare not only large in number, but also diverse in types,\nincluding viruses, bacteria, fungi, eukaryotes, etc. Collectively,\nthese microbes constitute the human microbiome, an essential\nfocus of contemporary biomedical research.\nSome specific diseases are closely related to the abundance\nof microbial communities in the human body, with the vast\nmajority of these microorganisms residing in the gut [37].\nAs the largest microbial habitat in the human body, the gut\nmicrobiome has a direct impact on human health and diseases.\nFor example, researchers have found significant differences\nin the proportions of Bacteroides and Actinobacteria in the\nintestines of obese and lean individuals, with the propor-\ntion of Firmicutes also influencing obesity [6, 15]. Various\nmetabolites of gut microbes, such as short-chain fatty acid\nand aromatic amino acids, all directly or indirectly induce\ntype 2 diabetes [24]. Patients with inflammatory bowel disease\n(IBD) exhibit a relatively disordered intestinal microbiota\n[8, 19], with microbial metabolites such as acetate and butyrate\nplaying crucial roles in immune regulation. The concentration\nof butyrate is notably decreased in patients with ulcerative\ncolitis, highlighting the influence of gut microbes on IBD.\nIn recent years, with the rise of 16SrRNA sequencing tech-\nnology [17], new studies have shown that the number of\nlactic acid bacteria in the intestines of patients with irritable\nbowel syndrome decreased significantly, while the number of\nVeillonella in patients with constipation-predominant irritable\nbowel syndrome increased [29]. These findings further confirm\nthe close connection between intestinal microbes and human\nhealth [4, 28].\nWith the rapid advancement of medical technology, ob-\ntaining relevant data has become increasingly convenient.\n16SrRNA sequencing technology [5] can be used to obtain\nthe abundance of human intestinal flora. Compared to whole\ngenome sequencing, this technology is widely used due to\nits relatively low cost. However, processing this data to de-\nrive meaningful disease analysis results remains a significant\nchallenge. Expert analysis of intestinal flora is complex and\ntime-consuming, making it imperative to leverage artificial\nintelligence to enhance efficiency and reduce costs.\nHowever, diagnosing diseases based on intestinal flora infor-\nmation has not achieved satisfactory results due to the complex\nand multiplex connections among the intestinal flora. Most\nexisting approaches consider only a single relation-type even\nignore the connection, fail to cover the intricate connection\namong the gut microbes of different hosts. Graph learning\n[33, 35, 36] are well-suited for handling graph-structured data\nwith rich relationships [30, 3], and can represent information at\nvarious depths. Therefore, we utilize Graph Neural Networks\n(GNNs) to learn the connections among gut microbes from\ndifferent hosts, effectively guiding disease prediction. It is\nworth noting that our method does not rely on the labels in\nthe process of obtaining the embeddings of the nodes and\nthe graphs, which can obtain satisfactory embeddings in an\nunsupervised scenario.\nConsidering all the above challenges, we summarize the\ncontributions of this paper as follows:\n\u2022 We are the first to introduce graph machine learning to\nthe field of disease prediction based on gut microbiota.\nWe propose a novel Unsupervised Multi-graph Merge"}, {"title": "II. RELATED WORK", "content": "Benefiting from the rapid advancement of medical tech-\nnology, many studies have been able to use OTU data for\nanalysis [7, 20]. Pasolli et al. [22] comprehensively evaluated\nthe prediction tasks based on shotgun metagenomics and the\nmethod of microbial phenotype association evaluation, mainly\nusing support vector machines and random forest models\nto predict diseases, and with the help of Lasso and elastic\nnet (ENet) Regularized Multiple Logistic Regression. In their\nstudy, cirrhosis was the most predictive disease, and the model\nused in the study had good generalization ability for cross-\nstage data, but poor generalization ability for cross-datasets.\nSharma et al. [27] proposed TaxoNN to predict the conn\nbetween gut microbes and diseases, but only used two datasets\nto test the effect.\nManandhar et al. [18] used fecal 16S metagenomics data\nto analyze 729 IBD patients and 700 healthy individuals\nthrough 5 machine learning methods. After identifying 50\nmicroorganisms with significant differences, the prediction\nwas obtained through the random forest algorithm. Based on\nthe data of the gut project in the United States, Linares et al.\n[16] used the glmnet model and the random forest model to\npredict the country of origin. Wong et al. [32] investigated\nthe possible gastrointestinal effects of neratinib in the treatment of\nbreast cancer. By collecting stool samples from 11 drug-taking\npatients and classifying patients who may develop diarrhea by\na tree-based classification method.\nIn general, at present, for data in the form of OTU datasets\nthat are extended to table types, the traditional machine\nlearning algorithm may be relatively more effective [34].\nHowever, these algorithms are relatively fixed and there is\nnot much space for improvement, reaching a bottleneck on\nthe problem. More disappointing, basic CNNs perform well\nin many applications, but it can't beat the traditional machine\nlearning algorithm in this case. This is because the basic\nCNN's method cannot solve the problem of long-distance\ndependencies, nor can it adapt to data whose order can be\nchanged at will. The exchange of rows and columns of the\ntabular datasets do not affect the results of pattern recognition,\nand more challengingly, diseases are not caused by a single gut\nmicrobe, but by a combination of a large number of microbial\ninformation. However, Graph Learning can help learn the intri-\ncate connection among the intestinal flora of different hosts.\nWe propose the UMMAN unsupersived method, combining\nGraph Neural Network with gut microbiome for the first\ntime, and it has achieved excellent performance on benchmark\ndatasets."}, {"title": "III. METHOD", "content": "In this section, we will first introduce the overview of the\narchitecture of our method UMMAN. In the following\nsection, we introduce how to construct the Original-Graph\nand the Shuffled-Graph. We then present the details of the\ntwo stages of the Node Feature Global Integration descriptor:\nnode-level stage and graph-level stage. Then we introduce the\nattention block to derive the embedding of each node. We also\npropose the joint loss which consists of adversarial loss $\\mathcal{L}_{adv}$\nand hybrid attention loss $\\mathcal{L}_{h-attn}$ in the end."}, {"title": "A. THE OVERVIEW OF UMMAN ARCHITECTURE", "content": "The architecture of UMMAN we propose will be introduced\ndetailedly in this part. As stated above, it exists close but ex-\ntremely complex connection among gut microbes of different\nhosts, and such relation is implicit. Specifically, it is not the\nabundance of a single intestinal microbe that can establish\na direct relationship with the final disease, but it is caused\nby the combined information of various microbes. For tabular\ndatasets in the form of OTUs(A table with rows representing\ngut microbiota abundance and columns representing samples),\ntheir adjacent data are not correlated, so traditional convolu-\ntional neural networks are not applicable. Therefore, how to\nlearn the connection among gut microbes of different hosts\nhas become the biggest difficulty in this field, and we are\nthe first to combine graph machine learning with gut flora\ndisease prediction tasks which helps learn the connection. The\nfollowing will introduce the architecture of UMMAN that we\npropose in detail.\nThe overview architecture of UMMAN is shown in Fig\n.1. Each node represents a host. We use multiplex indica-\ntors to measure the similarity among nodes to build the\nOriginal-Graph. In order to make UMMAN learn associations\nmore accurately, we destroy the Original-Graph's association\namong nodes to get Shuffled-Graph. The Original-Graph and\nShuffled-Graph are updated through the Graph Convolutional\nNetwork at the same time in order to obtain the embeddings\nof each node. We introduce the attention block to obtain\nthe embeddings of the nodes in the Original-Graph and the\nembeddings of the nodes in the Shuffled-Graph respectively. In\naddition, we design a Node Feature Global Integration (NFGI)\ndescriptor to denote the embedding of a graph. Then, in order\nto make the true embedding that includes the complex and\nimplicit relationships among gut microbes of different hosts\nagree with the Original-Graph as much as possible and dis-\nagree with the Shuffled-Graph as much as possible, we design\nthe total joint loss function consists of an adversarial loss and"}, {"title": "B. CONSTRUCT MULTI-GRAPH AND NODE EMBEDDING", "content": "We find that the abundance data of a part of the intestinal\nflora in the dataset was extremely low in most hosts whose\nimpact on the performance of the algorithm is detailed above.\nIf all the data of the original dataset is retained, it may cause\nsome intestinal flora to be almost completely absent in all\nhosts. We can consider such data as \"dirty data\", which will\nlead to training effects decline. Therefore, we removed the\nintestinal flora with low abundance in most hosts to improve\nthe effect of feature extraction.\nIn order to make the motivation more convincing, we show\nthe connection of the 10 most abundant flora in the cirrhosis\ndataset in the sample intestine in Fig.2. The diagonal graph\ndescribes the distribution histogram of the flora, and the off-\ndiagonal represents the relationships between the flora and\nthe abundance in the intestinal tract of the sample, where the\nred dots represent healthy hosts, and the blue dots represent\ndiseased samples. It can be found that the correlation is not\nobvious and appears to be disorganized, which proves that it\nis unreliable to measure the relation-type among hosts only\nbased on the abundance of flora. To explore the implicit\ninformation of fused features in intestinal flora, we consider\nmultiplex relation-types [1, 10] to measure the relationships\namong vectors during the initialization of building the edges\namong nodes in the graph:\n$S_1(m, n) = \\sum_{i=1}^{d} \\frac{|m_i-n_i|}{\\sum_{i=1}^d m_i + \\sum_{i=1}^d n_i}$ (1)\n$S_2(m, n) = \\frac{\\sum_{i=1}^{d} (m_i-n_i)^2}{\\sqrt{\\sum_{i=1}^d m_i - \\sum_{i=1}^d n_i}}$ (2)\n$S_3(m,n) = \\sum_{i=1}^{d} \\frac{|m_i-n_i|}{m_i + n_i},$ (3)\nwhere Bray Curtis Distance, Euclidean Distance and Can-\nberra Distance are used to initialize a graph. We construct\nthe original graph by measuring the multivariate discrepancy\nbetween nodes, two nodes are considered to be connected if\nthe discrepancy among their embeddings is below a variable\nthreshold 0. In order to make our model more robust, and\nto obtain the correlation among nodes more reliably, we\ndesign the adversarial control group, i.e., keep the position\nof the edges unchanged, randomly disrupt the nodes to get\nthe Shuffled-graphs, and train the discriminator to get the\nadversarial loss. The specific process will be introduced in\ndetail later.\nWe introduce an encoder module for each relation type\ninspired by the Graph Convolutional Network[12], aiming\nto obtain the embedding of each node in the graph. We\ndefine a conditional function $\\mathcal{F}$ as an update function between\nlayers, the Shuffled-Graph is operated by the same process\n$X^{(l+1)} = \\mathcal{F}(X^{(l)}, \\hat{A}; W^{(l)}, b^{(l)})$.\n$\\hat{A} = \\mathcal{D}^{-\\frac{1}{2}}\\tilde{A}\\mathcal{D}^{-\\frac{1}{2}}$.\n$\\mathcal{F}(X^{(l)}) = \\sigma(\\hat{A}X^{(l)}W^{(l)} + b^{(l)})$ (4)\nwhere $X_j^{(l)}$ is the embedding of the l layer of the node\nwhose index is j, $\\mathcal{N}_j$ represents the set of nodes adjacent to\n$X_j^{(l)}$, $\\hat{A}$ and $\\mathcal{D}$ are the adjacency matrix and degree matrix of a\ncertain graph, $W^{(l)}$ and $b^{(l)}$ are the trainable parameters of the\nl-th layer's weight matrix and bias, $\\sigma$ is the nonlinearity layer\nwhich is designed as ReLU in our method. Through Graph\nConvolutional Network, $X^{(t)}$ become a D-dimensional tensor\nrepresenting the embeddings of the node with index j of the\nt-th relation-type."}, {"title": "C. NODE FEATURE GLOBAL INTEGRATION DESCRIP-\nTOR WITH TWO STAGES", "content": "In the NFGI module, we propose a novel contribution to\ncharacterize a graph $\\mathcal{J}^{(t)}/\\mathcal{J}^{(t)}$ with two stages($\\mathcal{J}^{(t)}$ is the\nOriginal Graph constructed according to the t-th relation-type,\nand $\\mathcal{J}^{(t)}$ , is the corresponding graph after being shuffled,\nsince the operations of the two graphs are equivalent, we"}, {"title": "D. CONVERGE MULTI-GRAPH BY ATTENTION", "content": "Single-scale CNN fail to capture the intricate relationships\namong intestinal flora, while conventional multi-scale CNNS\nsometimes fall short in effectively integrating information from\nvarious scales using concatenation-based approaches."}, {"title": "E. LOSS FUNCTIONS", "content": "The loss functions of our model consists of an adversarial\nloss $\\mathcal{L}_{adv}$ and hybrid attention loss $\\mathcal{L}_{h-attn}$. The total loss\nfunction is as follows:\n$\\mathcal{L} = \\mathcal{L}_{adv} + \\eta\\mathcal{L}_{h-attn},$ (10)\nwhere $\\eta$ is a learnable coefficient for the loss terms.\n1) ADVERSARIAL LOSS: We not only use a variety of\nrelation-types to construct Multi-graph and obtain the em-\nbedding of each Node through Graph Convolutional Network\nand Attention Block, but also the Original-Grpah Randomly\nshuffle to break the correlation among nodes. Therefore, we\ncalculate the positive correlation loss between the global em-\nbedding obtained by NFGI (Node Feature Global Integration\nDescriptor) and the embedding of the nodes of the Original-\nGraph obtained by each relation-type. At the same time, on\nthe converse side, we calculate the negative correlation loss\nbetween the global embedding and the embedding of the\nnodes of the Shuffled-Graph, and define this joint loss as\nAdversarial Loss inspired by [21]. In other words, we calculate\nthe adversarial loss from the embedding obtained from the\nconstructed Original-Graph (Positive) and the Shuffled-Graph\n(Negative) that destroys the correlation among nodes, which\nis defined as:\n$\\mathcal{L}_{adv} = \\sum_{t\\in \\mathcal{T}} \\sum_{i=1}^{N} log \\sigma ((\\mathcal{H}^{(t)})^T\\mathcal{W}^{(t)} x_i^{(t)}) + \\sum_{t\\in \\mathcal{T}} \\sum_{j=1}^{N} log (1-\\sigma ((\\mathcal{H}^{(t)})^T\\mathcal{W}^{(t)} \\hat{x}_j^{(t)})).$ (11)\n2) HYBRID ATTENTION LOSS: The Hybrid Attention\nLoss we proposed comprehensively considers the embedding\nafter the nodes of the Original-Graph and the Shuffled-Graph\npass through the attention block. The Hybrid Attention Loss\n$\\mathcal{L}_{h-attn}$ can make the global embedding matrix of real graph\nagree with $X_{attn}^{(t)}$ and disagree with $\\hat{X}_{attn}^{(t)}$, thereby improving\nthe confidence of the attention block. The Hybrid Attention\nLoss function is defined as:\n$\\mathcal{L}_{h-attn} = ||(P - X_{attn})||^2 - ||(P - \\hat{X}_{attn})||^2.$ (12)\nAlgorithm 1 Unsupervised Multi-graph Merge Adversarial\nNetwork\nInput: feature F, origin data O, shuffled data S, graph num\nNg, head num Nh\nOutput: loss L\nfor i = 1 to Ng do\npos \u2190 GCN(F[i], O[i], i)\np\u2190 NFGI(pos)\nneg \u2190 GCN(S[i], O[i], i)\n$\\mathcal{L}_{adv}$ \u2190 Disc(p, pos, neg)\nP.append(pos)\nN.append(neg)\nend for\nfor h = 1 to Nh do\nPattn, Nattn\u2190 Attn[h](P,N)\nend for\n$X_{attn}$\u2190 mean(Pattn)\n$\\hat{X}_{attn}$\u2190 mean(Nattn)\n$\\mathcal{L}_{pos}$\u2190 (($P-X_{attn}$)^2).sum()\n$\\mathcal{L}_{neg}$\u2190 (($P-\\hat{X}_{attn}$)^2).sum()\n$\\mathcal{L}_{h-attn}$ = $\\mathcal{L}_{pos}$ - $\\mathcal{L}_{neg}$\n$\\mathcal{L}$\u2190 $\\mathcal{L}_{adv}$ + $\\mathcal{L}_{h-attn}$\nreturn $\\mathcal{L}$"}, {"title": "IV. EXPERIMENT", "content": "We performe extensive experiments on five real-world\ndatasets to evaluate the performance of our UMMAN model.\nWe also compare it to several state-of-the-art machine learning\nand deep learning models. In pre-processing, we removed the\nintestinal flora which abundance lower than 0.01 in most hosts\n(set to 120). During the initialization of the graph, set the\nthreshold 0 to 0.6. We randomly divide each dataset into five"}, {"title": "B. DATASETS", "content": "Five classical gut microbiota datasets are used for the exper-\niments. We use five available disease-associated metage nomic\ndatasets spanning four diseases: liver cirrhosis, inflammatory\nbowel diseases (IBD), obesity, and type 2 diabetes in Asia\nand Europe, respectively. These datasets have recorded the\nabundance of 1331 gut microbes in the sample intestine, as\nwell as information such as gender, age, and region.\nCirrhosis [25]. Qin et al. extracted total DNA libraries from\nfecal samples of patients with cirrhosis and healthy controls,\nwhich can characterize the gut microbiome of patients with\ncirrhosis. Specifically, they used Illumina HiSeq 2000 for\nsequencing, which produced an average of 4.74 Gb of high-\nquality sequences per sample, and a total of 860 Gb of\n16SrRNA gene sequence data.\nIBD [23]. Qin et al. collected stool samples from volunteers\nand performed Illumina GA sequencing. All Reads were\nassembled using Soapnovo19. Using BLAT36 to construct a\nnon-redundant gene set for inflammatory bowel disease by\npairwise comparison of all genes. Each sample yields an\naverage of 4.5Gb of high-quality sequences.\nObesity [14]. Obesity is one of the most serious (propor-\ntional) gut microbiota-related diseases facing the world. Le et\nal. extracted the abundance of more than a thousand species\nof flora in the gut by sequencing fecal samples from Obesity\npatients and thinner stature.\nT2D [24]. Stool samples are collected from patients with\ntype 2 diabetes and healthy controls in order to obtain the\nDNA data of the flora in the samples, using the whole\ngenome sequencing method, and then sequenced all the DNA\nsamples, and analyzed the intestinal microbial DNA of 345\nChinese Two-stage MGWAS was performed for deep shotgun\nsequencing, with an average of 2.61 Gb per sample and a total\nof 378.4 Gb of high-quality DNA data.\nWT2D [11]. Shotgun sequencing is used to analyze the\nwhole genome sequence of fecal samples from European\nwomen, sequenced on Illumina HiSeq 2000, obtained an\naverage of 2Gb of sequencing data per sample, and a total\nof about 449 Gb of data. Different from T2D, the target of\nT2D dataset is Chinese, while WT2D is sampled in Europe."}, {"title": "C. COMPARISON WITH EXISTING WORK", "content": "We carry out quantitative comparisons on the results be-\ntween our method and existing work on five datasets. The\nRandom Forest and Support Vector Machine can be used in the\ndisease prediction of intestinal flora [22], although the results\nobtained are acceptable, the performance of such algorithms\nhas reached the bottleneck so that it is difficult to improve. The\nbasic CNN series methods are particularly effective at extract-\ning closely located features, but they encounter difficulty in\ncapturing attention over long distances. Additionally, due to\nthe property of uncorrelated adjacent data in the OTU tabular\ndataset, traditional convolutional neural networks struggle to\nextract the intrinsic connections among gut microbiota. We\ninnovatively combine a graph machine learning algorithm with\nthe gut microbiota disease prediction task. We first compared\nthe performance results of our method and the previous 8\nmethods on the Acc and AUC indicators on the benchmark\ndatasets, as shown in Table 1 (bold indicates the best perfor-"}, {"title": "D. ABLATION STUDY", "content": "In our method, Attention block, Node Feature Global In-\ntegration (NFGI) descriptor and Adversarial loss are three\ncore components, which is to improve the performance on the\nOTU datasets. We conduct an ablation study on eight variants:\na) Ours (Base), only with the framework of the UMMAN\nmodel; b) Ours (Adv), with Adversarial loss which is used\nto extract the features of the Original-Graph; c) Ours (Attn),\nwith Attention block which is used to get the embedding of\nthe Original-Graph and the Shuffled-Graph. In this study, we\nuse the global average pooling of Multi-Graphs to replace\nAttention block, the global average pooling is defined as:\nv = GAP((X)) (13)\nd) Ours (NFGI), adopting Node Feature Global Integra-\ntion(NFGI) which is designed to describe the global graph\nembedding, replace this module with the average value of each\nnode in this part; e) Ours (Attn+Adv), with Attention block\nand Adversarial loss; f) Ours (NFGI+Adv), with NFGI and\nAdversarial loss; g) Ours (Attn+NFGI), with Attention block\nand NFGI. h) Ours (Full), with Attention block, NFGI and\nAdversarial loss. The numeric comparisons on Cirrhosis, IBD,\nObesity, T2D, WT2D are shown in Table 3. On the whole, the\nmethod with Attention block, NFGI and Adversarial loss, i.e.,\nOurs (Full) performs the best. It is worth mentioning that even\nif our method is ablated, the effect on most indicators is better\nthan previous work."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose a novel architecture UMMAN\nwhich combines GNN with disease prediction tasks based"}]}