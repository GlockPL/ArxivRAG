{"title": "AER-LLM: Ambiguity-aware Emotion Recognition Leveraging Large Language Models", "authors": ["Xin Hong", "Yuan Gong", "Vidhyasaharan Sethu", "Ting Dang"], "abstract": "Recent advancements in Large Language Models (LLMs) have demonstrated great success in many Natural Language Processing (NLP) tasks. In addition to their cognitive intelligence, exploring their capabilities in emotional intelligence is also crucial, as it enables more natural and empathetic conversational AI. Recent studies have shown LLMs' capability in recognizing emotions, but they often focus on single emotion labels and overlook the complex and ambiguous nature of human emotions. This study is the first to address this gap by exploring the potential of LLMs in recognizing ambiguous emotions, leveraging their strong generalization capabilities and in-context learning. We design zero-shot and few-shot prompting and incorporate past dialogue as context information for ambiguous emotion recognition. Experiments conducted using three datasets indicate significant potential for LLMs in recognizing ambiguous emotions, and highlight the substantial benefits of including context information. Furthermore, our findings indicate that LLMs demonstrate a high degree of effectiveness in recognizing less ambiguous emotions and exhibit potential for identifying more ambiguous emotions, paralleling human perceptual capabilities.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent advancements in large language models (LLMs) [1] have shown remarkable abilities in comprehending, interpreting, and gen-erating human-like text. This cognitive intelligence facilitates effec-tive human-AI interactions of conversational AI. Equally important is the emotional and social intelligence, which enables it to understand human emotions and adapt its communication accordingly.\nText-based emotion recognition has shown considerable potential, with various feature engineering techniques and advanced deep learning models [2]\u2013[4]. With the emerging capabilities of LLMs, particularly their proficiency in in-context learning and robust gen-eralization without extensive training, research on exploring their potential for emotion recognition and further use as annotation tools have attracted increasing attentions [5]\u2013[8]. Nonetheless, these investigations predominantly focus on recognizing single emotions, thereby overlooking the complex nature of human emotions. Typi-cally, a single emotion label is obtained from the majority vote of multiple annotators labeling the same stimuli. This approach disre-gards discrepancies among annotators, which indicates the inherent ambiguity of emotions. High ambiguity, i.e., high disagreement, in-dicates more complex emotions, and such ambiguity impacts conver-sations, leading to modified communication strategies and affecting relationship dynamics [9]. For example, the listener might use more cautious language and tones or avoid sensitive topics to prevent misunderstandings if high emotional ambiguity is perceived. Future LLMs need to understand the complexity of emotions, recognize emotional ambiguity, and adjust their responses dynamically.\nLLMs, trained on diverse and large-scale datasets, enable seman-tic richness and offer significant potential in comprehending the complexity of emotions. Additionally, their long-range contextual understanding allows them to decode emotions through in-context learning by analyzing conversational history, which is particularly noteworthy. This study aims to explore the potential of LLMs in recognizing inherently ambiguous emotions and the contributions are summarized below:\nThis is the first study to analyze LLMs in recognizing ambiguity-aware emotions, demonstrating their potential for human-like emotional intelligence.\nWe proposed zero-shot and few-shot prompt designs and incor-porated in-context learning capabilities to enhance recognition, demonstrating an average 35% relative improvements in terms of Bhattacharyya coefficient.\nWe further included speech features as textual prompt to enhance learning, further enhancing the ambiguous emotion recognition.\nFurther analysis concerning different levels of ambiguity re-vealed that LLMs are more effective at recognizing less am-biguous emotions and less effective with more ambiguous ones.\nThis investigation offers valuable insights into emotional intel-ligence in LLMs and could potentially advance the development of more natural and empathetic conversational AI systems through dynamic emotional responses."}, {"title": "II. RELATED WORK", "content": "A range of feature sets and modeling frameworks have been developed to advance text-based emotion recognition. TF-IDF, which highlights frequent keywords to indicate emotional cues, has been effectively used in emotion classification [10]. Subsequently, word embeddings have demonstrated greater effectiveness in capturing semantic relationships, such as Word2Vec, GloVe, and BERT [2]\u2013[4]. Deep learning models have also advanced, with Bi-Gated Recurrent"}, {"title": "III. AMBIGUOUS EMOTION RECOGNITION VIA LLMS", "content": ""}, {"title": "A. System overview", "content": "Fig. 1 illustrates our framework for recognizing ambiguous emo-tions using LLMs. For each target utterance, we construct detailed prompts for ambiguous emotion recognition. To evaluate the perfor-mance of the LLMs, we compare the predicted emotion distribution p(x) with the ground truth distribution p(x), which is inferred from N different human annotators A1 to AN."}, {"title": "B. Prompt design", "content": "1) Zero-shot and few-shot prompting: Carefully designed zero-shot (ZS) and few-shot (FS) prompting are key for LLMs to gener-alize across various domains [18]. Zero-shot prompting evaluates the capability of pre-trained knowledge in LLMs. Few-shot prompting includes a limited set of demonstration examples within the prompts, facilitating the adaptation of pre-trained knowledge to specific new tasks. We design zero-shot prompt as outlined in Table I and Eq. (1):\nPromptzs = BG + C + TU + Task + OC\n(1)\n2) Prompt with speech features: As humans express emotions through multiple cues, we further included speech in addition to text for ambiguity-emotion recognition. We transformed speech features into text format and incorporated them into the prompt design. Since LLMs have been trained extensively on text data, they are expected to understand speech information in text format, e.g., high pitch values: 4. Specifically, we extracted 88-dimensional eGeMAPS features [19]"}, {"title": "C. Context-aware recognition", "content": "A major advantage of LLMs lies in their capability for in-context learning, offering the potential to analyze long past conversation histories for emotion recognition. Since emotions generally evolve smoothly within dynamic conversations, considering past conversa-tions provides a more comprehensive understanding of the emotional state over time. A longer context window enables LLMs to effectively decode information over extended ranges, and we formally study this by increasing the number M of context windows in the prompt design, i.e., including the corresponding text information from the past M utterances, and evaluated the performance accordingly."}, {"title": "IV. EXPERIMENTAL SETUP AND RESULTS", "content": ""}, {"title": "A. Experimental setup", "content": "1) Dataset: Three datasets are used, MSP-Podcast [20], IEMO-CAP [21] and GoEmotions [22]. MSP-Podcast contains recordings cover a wide range of subjects in Podcasts. We selected four emotional labels: neutral, angry, happy, and sad. Any utterances annotated by annotators outside of these four categories will be excluded from the analysis, leading to 4114 utterances. We manually reorganized sentences into the original full podcast to enable dynamic information. For IEMOCAP, we also selected the same four emotional labels, resulting in a total of 4370 utterances.\nGoEmotions is a text-based dataset sourced from Reddit. Given the long-tail distribution of emotion labels, we selected the 4 most common labels (admiration, gratitude, approval, and amusement) along with Neutral. To ensure adequate representation of ambiguous emotions (more than one label per utterance), we applied log inverse frequency weighting and selected 210 instances, with 33% being multi-labeled.\n2) Models: Gemini-1.5-Flash was chosen as the LLM backbone due to its capability for processing long-range contexts, with a context window of up to one million tokens. The experiments were conducted using the Gemini API [23]. For few-shot prompts, we tested 5 and 10 examples in GoEmotions. In MSP-Podcast and IEMOCAP, we matched the number of few-shot examples to the context window, varying the context window within [0,30]2.\n3) Evaluations: We include both uncertainty-centric and accuracy-centric metrics to evaluate our model's performance. For uncertainty-centric metrics, we use Jensen-Shannon Divergence (JS), Bhat-tacharyya coefficient (BC), and R2. JS divergence measures the difference between predicted and ground truth distributions, with lower values indicating better predictions. BC measures the similarity between these distributions, and R2 assesses the goodness-of-fit,"}, {"title": "B. Performance on ambiguity-aware prediction", "content": "Table IV demonstrates the performance on three datasets. For the text modality, the zero-shot prompt achieves relatively acceptable performance, e.g., R2 of 0.41 for MSP-Podcast, 0.49 for IEMOCAP, and 0.43 for GoEmotions. With few-shot prompting, it demonstrates significant improvement, with approximately 25% reduction in JS, 49% increase in BC, and 31% increase in R2 for MSP-Podcast. Sim-ilar increasing trend is also observed in IEMOCAP and GoEmotions. This suggests that LLMs are strong in learning from few examples for ambiguous emotion recognition, and leveraging their in-context learning capabilities by looking at past examples is highly beneficial. For the joint modeling of text and speech modality, both zero-shot and few-shot demonstrate significant improvement compared to the corresponding performance using text only, suggesting the LLMs' capabilities in recognizing speech information despite being in textual format. Furthermore, the few-shot prompting consistently outperforms the zero-shot prompting, exhibiting superior performance for all three datasts. The consistent trend in ECE also implies a similar effect on probability calibrations."}, {"title": "C. Impact of context window", "content": "Fig. 2 shows the few-shot performance using text and speech with the increasing context windows from 0 to 30 in MSP-Podcast. Including context information proves significantly beneficial com-pared to that without contextual information. When the window size increases from 0 to 5, we observe a 16%, 28%, 22% and 19% improvements in terms of JS, BC, R\u00b2 and ECE, respectively. As the context window expands beyond 10 to 30, the observed improvements become marginal, indicating that further increasing the context window size beyond 10 may not substantially enhance ambiguous emotion recognition. In the IEMOCAP dataset, the most benefit was obtained when the context window increases to 20. These findings collectively suggest that incorporating context information is crucial for ambiguous emotion recognition in LLMs, and a context window of 10 to 20 is likely to be adequate. This is reasonable, as humans do not need infinite context to recognize emotion."}, {"title": "D. Performance with differnt ambiguity levels", "content": "To gain deeper insights into how LLMs recognize varying levels of ambiguity in emotions, we evaluated their performance with respect to different ambiguity levels. We used entropy, inferred from the ground truth distributions, as an indicator of the ambiguity levels. As entropy increases, the utterance exhibits greater ambiguity in emotion. An entropy of 0 indicates unanimous agreement on one emotion class. As shown in Fig. 3, six majority entropy with each more than 100 utterances are shown.\nAs entropy increases, the medians (black lines) of JS rise, while BC and R2 decrease in general, except when entropy is 0.7219. The trend indicates that LLMs are more effective at recognizing less ambiguous emotions. This is likely due to the inherent complexity of predicting a high entropy emotional distribution. This observation aligns with the human difficulty in recognizing more ambiguous emotions [24]. Better performance is observed with an entropy of 0.7219, as we found that 92% of the utterances are annotated with at least a neutral class, more than in neighbouring entropy groups, and LLMs recognize neutral with a 75% true positive rate, leading to higher performance."}, {"title": "E. Prediction on majority vote", "content": "We further estimated the single emotion from the distribution by selecting the one with the highest probability and compared it with the majority vote. Noted that the prompt design for LLMS is not optimized for recognizing the majority vote, this analysis is designed to provide insights into LLMs capabilities in understanding the most likely emotion.\nAs shown in Table V, the best performances on MSP-Podcast, IEMOCAP and GoEmotions achieve 56.15%, 59.06% and 51.05% in terms of W-F1, respectively, demonstrating emotional understanding of LLMs. Note that the prompt is not designed for single-label emotion recognition and LLMs is not trained, but it still achieves comparable performance to the models specifically trained for single-label emotion recognition. The accuracy with respect to the context"}, {"title": "V. CONCLUSION", "content": "We investigated LLMs potential in recognizing ambiguous emo-tions and discovered that it can comprehend such emotions to a certain extent without additional training. Incorporating previous dialogues by leveraging LLMs in-context learning capabilities sig-nificantly enhances its emotional intelligence, with a context window of 10 to 20 being adequate. Moreover, these models demonstrate greater proficiency in recognizing less ambiguous emotions compared to highly ambiguous ones, similar to human perception. These findings highlight the potential of LLMs for application in emotional conversational AI."}]}