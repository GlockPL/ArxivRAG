{"title": "KABB: Knowledge-Aware Bayesian Bandits\nfor Dynamic Expert Coordination in Multi-Agent Systems", "authors": ["Jusheng Zhang", "Zimeng Huang", "Yijia Fan", "Ningyuan Liu", "Mingyan Li", "Zhuojie Yang", "Jiawei Yao", "Jian Wang", "Keze Wang"], "abstract": "As scaling large language models faces pro-\nhibitive costs, multi-agent systems emerge as\na promising alternative, though challenged by\nstatic knowledge assumptions and coordination\ninefficiencies. We introduce Knowledge-Aware\nBayesian Bandits (KABB), a novel framework\nthat enhances multi-agent system coordination\nthrough semantic understanding and dynamic\nadaptation. The framework features three key\ninnovations: a three-dimensional knowledge dis-\ntance model for deep semantic understanding, a\ndual-adaptation mechanism for continuous expert\noptimization, and a knowledge-aware Thompson\nSampling strategy for efficient expert selection.\nExtensive evaluation demonstrates that our KABB\nachieves an optimal cost-performance balance,\nmaintaining high performance while keeping com-\nputational demands relatively low in multi-agent\ncoordination. We will release the source code of\nour method in accordance with the review policy.", "sections": [{"title": "1. Introduction", "content": "With the rapid advancement of large language models\n(LLMs), their applications have expanded to complex tasks\nsuch as cross-domain knowledge integration and multistep\ndecision-making. Although many LLMs (Achiam et al.,\n2023; Liu et al., 2024; Adams et al., 2024; Team et al., 2024;\nBai et al., 2023) demonstrate impressive versatility in vari-\nous tasks through techniques such as in-context learning and\ninstruction-tuning, their performance remains constrained\nby factors such as model size and the limitations of train-\ning data (Jiang et al., 2023; Lu et al., 2024). Scaling these\nmodels further to improve performance is prohibitively ex-"}, {"title": "2. Related Work", "content": "2.1. Large Language Model Ensemble\nThe ensemble of large language models (LLMs) has\nemerged as an effective strategy to leverage the complemen-\ntary strengths of different models and improve performance\nacross diverse tasks. Early approaches primarily focused\non combining outputs from multiple models through tech-\nniques like reranking or probability distribution averaging.\nFor instance, Jiang et al. (2023) proposed PAIRRANKER\nfor pairwise output comparisons and GENFUSER for gen-\nerating improved responses by synthesizing multiple candi-\ndates. Similarly, Huang et al. (2024) explored output fusion"}, {"title": "2.2. Multi-Armed Bandit for Decision Optimization", "content": "The Multi-Armed Bandit (MAB) framework balances explo-\nration and exploitation in sequential decision-making under\nuncertainty. Classical algorithms like UCB and Thompson\nSampling excel in recommendation and resource alloca-\ntion, while Contextual Bandits and adaptive methods refine\ndecision-making in dynamic settings (Li et al., 2010). Re-\ncent advances integrate Large Language Models (LLMs)\nto reduce learning regret and enhance decision-making by\nleveraging pre-trained knowledge (Alamdari et al., 2024).\nBandit-based reinforcement learning frameworks further aid\nretrieval in knowledge-intensive tasks (Tang et al., 2024). In-\nnovations in clustering and transfer learning have improved\nMAB efficiency across applications like clinical trials and\nrecommendation systems (Qi et al., 2025; Sharma & Sug-\ngala, 2025). These developments highlight the importance\nof semantic understanding and adaptation, aligning with the\nKnowledge-Aware Bayesian Bandits (KABB) framework\nintroduced in this paper."}, {"title": "3. Method", "content": "This chapter presents the Knowledge-Aware Bayesian Multi-\nArmed Bandits (KABB) framework for solving the expert\nselection problem in multi-agent collaborative systems. We"}, {"title": "3.1. System Architecture", "content": "The overall decision-making process of the KABB system\n(see Figure 2) consists of several key steps:\n1. Task Reception and Concept Extraction: the system\nreceives a user-input task $T_t$ and employs natural lan-\nguage processing techniques to parse the task into a\nconcept requirement (Chen et al., 2018; Wang et al.,\n2020; Li et al., 2019)vector $d_t \\in \\mathbb{R}^{|C|}$, where $C$ is a\npredefined set of concepts.\n2. Expert Capability Mapping: each expert(Radford\net al., 2019) (i.e., different LLMs(Liu et al., 2021))\nis represented by an ability vector $v_e \\in \\mathbb{R}^{|C|}$, re-\nflecting its expertise across various concepts. Mul-\ntiple LLMs are thus mapped into an expert set $E =$\n{1, 2,..., en}.\n3. Expert Subset Selection: The optimal expert sub-\nset $S_t \\subset E$ is identified through a knowledge-aware\nThompson sampling process that leverages both the\ntask requirement vector $d_t$ and expert capability vec-\ntors $v_e$. This process integrates a dynamic Bayesian\nMAB algorithm with the knowledge distance metric\nDist(S, t) to maximize task success probability. Se-\nlected experts in $S_t$ independently process task $T_t$,\nafter which an aggregator synthesizes their responses\nthrough semantic conflict detection and weighted in-\nformation fusion to generate the final output.\n4. Performance Feedback and Model Update: The sys-\ntem collects performance metrics (e.g., success rates\nand user ratings) for each task completion. These feed-\nback signals are used to update the Bayesian model\nparameters a and B, enhancing the accuracy and adapt-\nability of future decisions.\nThrough this pipeline, the KABB system achieves a closed-\nloop process from task parsing to expert selection and an-\nswer aggregation, ensuring precise alignment between task\nrequirements and expert capabilities while continuously im-\nproving decision-making efficiency and effectiveness."}, {"title": "3.2. Knowledge Distance and Complementarity in\nMulti-Agent Teams", "content": "To better characterize the collaborative properties of multi-\nagent(Guo et al., 2024a) (expert (Cai et al., 2024)subset)\nteams, we extend the knowledge distance metric from indi-\nvidual experts to expert subsets, introducing the concepts of\nteam synergy and conflict(Bengio et al., 2014). The knowl-\nedge distance (Qi et al., 2025)metric Dist(S, t) serves as a\ncore component of the KABB model, integrating five key di-\nmensions of information: task difficulty, semantic matching,\ndependency relations, team complementarity, and histori-\ncal effectiveness. These dimensions are balanced through\nlearnable weights. The formal definition is given as follows:\nDefinition 3.1 (Knowledge Distance Function). The knowl-\nedge distance metric Dist(S, t) integrating five dimensions\nis formally defined as:"}, {"title": "3.3. Dynamic Bayesian Multi-Armed Bandit (MAB)\nAlgorithm Derivation for Multi-Agent Systems", "content": "To effectively select the most suitable expert subset for\nspecific tasks in expert systems remains a key challenge.\nTraditional MAB algorithms (e.g., UCB(Behari et al., 2024;\nGuo & Yang, 2020), Thompson Sampling) rely solely on\nhistorical feedback for decision-making. However, these\nmethods face two significant limitations in practice: (1) they\nfail to account for the dynamic nature of expert performance\nover time, and (2) they overlook the critical alignment be-\ntween task requirements and the knowledge structure of\nexpert teams. To address these issues, we propose a Dy-\nnamic Bayesian MAB framework that integrates knowledge\ndistance metrics, team complementarity, and temporal de-\ncay mechanisms into Bayesian inference. This framework\nestablishes a joint optimization objective, enabling dynamic\nadjustment of expert subset selection strategies. As a result,\nthe system can rapidly adapt to changes in expert perfor-\nmance while identifying the best-matched expert teams for\nincoming tasks.\nDynamic Beta Distribution Modeling and Parameter\nEvolution. We model the success probability of an expert\nsubset S at time step t using a time-varying Beta distribu-\ntion:"}, {"title": "4. Experiments", "content": "In this section, we detail the experimental setup, present the\nmain results, and provide an in-depth analysis of KABB.\n4.1. Experimental Setup\nModels. To construct the default configuration of KABB,\nwe use 6 open-source models including Qwen2-72B-\nInstruct (Bai et al., 2023), LLaMa-3-70B-Instruct (Adams\net al., 2024), WizardLM-2-8x22B (Xu et al., 2024), Gemma-\n2-27B (Team et al., 2024), Deepseek-V3 (Liu et al., 2024),\nand Deepseek-R1 (Guo et al., 2025). 12 knowledge con-\ncepts and 24 experts are defined, and the models are evenly\ndistributed across these experts using tailored prompts to\nspecialize their expertise, resulting in a straightforward yet\neffective multi-agent system. By default, the system dynam-\nically routes queries to top-3 experts from top-2 knowledge\nconcepts. Following the insights from MoA (Wang et al.,\n2024), we designated Qwen2-72B-Instruct as the aggrega-\ntor. Two variants are also developed: KABB w/o Deepseek,\nwhich excludes the Deepseek-V3 and Deepseek-R1 models"}, {"title": "4.4. Budget and Consumption Analysis", "content": "Cost Effectiveness. In Figure 4, we plot the LC Win Rate\nof KABB and several baseline models on AlpacaEval 2.0\nagainst their inference costs. The chart shows the trade-off\nbetween cost and performance across models. Our plots\ndepict a Pareto frontier that optimally balances performance\nand cost. We demonstrate that the KABB systems are po-"}, {"title": "5. Conclusion", "content": "This work introduces Knowledge-Aware Bayesian Bandits\n(KABB), a novel framework that significantly advances\nmulti-agent system coordination through three key inno-\nvations: a three-dimensional knowledge distance model,\na dual adaptation mechanism, and a knowledge-aware\nThompson sampling strategy. Extensive evaluations demon-\nstrate KABB's superior performance across multiple bench-\nmarks. Ablation experiments validate the effectiveness of\nthe Knowledge-Aware mechanism and our MAB strategy.\nIt is also verified that KABB is capable of addressing the\nchallenges of dynamic expert coordination while maintain-\ning computational efficiency, requiring fewer experts than\nbaseline approaches. Our framework provides a promising\ndirection for developing more adaptive and semantically-\ninformed multi-agent systems, though future work could\nfocus on optimizing output conciseness while maintaining\nresponse quality.\nDiscussion. The KABB framework advances interpretable\nand trustworthy AI systems through three transparent com-\nponents: a knowledge distance metric for expert selection\nrationale, a graph-guided response integration process for"}, {"title": "A. Details of Method Comparison", "content": "In this section, we provide detailed explanations of the configurations used in our experiments for comparison, including the\nrouting mechanisms, optimization algorithms, and evaluation metrics.\nA.1. Routing Mechanisms and Optimization Algorithms\nClassifier-Based (CL) Routing: We replaced our Knowledge-Aware (KA) routing mechanism with a classifier-based\nrouting (CL) approach. The CL mechanism uses Sentence-BERT to encode both the instruction and the expert's knowledge\nconcept into vector representations. Cosine similarity is then calculated between these vectors, and the expert with the\nhighest similarity score is selected.\nProximal Policy Optimization (PPO): A reinforcement learning algorithm that updates policies in a stable and efficient\nmanner. It was applied to optimize expert selection by training a policy network to maximize routing performance.\nMonte Carlo Tree Search (MCTS): MCTS is employed to explore potential expert selections by simulating multiple\ndecision paths and backpropagating scores from the outcomes. This algorithm is particularly useful for decision-making in\nenvironments with large search spaces.\nAdvantage Actor-Critic (A2C): A2C combines the actor-critic framework with an advantage function to improve policy\nupdates. The actor selects experts, while the critic evaluates the quality of these decisions, enabling more efficient learning.\nA.2. Metrics to Evaluate Routing Quality\nWe provide detailed definitions and formulations for the two metrics used to evaluate the performance of the routing\nstrategies: Routing Alignment Score (RAS) and Preference-Weighted Routing Score (PWRS).\nA.2.1. ROUTING ALIGNMENT SCORE (RAS)\nThe Routing Alignment Score (RAS) measures the degree to which the router's expert selection aligns with human expert\nannotations. It quantifies the consistency between the router's decisions and the ground truth labels provided by human\nannotators.\nHuman Evaluation Protocol To establish reliable ground truth labels, we engaged a panel of 7 domain experts with\n3+ years of experience in Al system evaluation. Each expert independently annotated 1,610 routing instances (805\ninstruction-expert pairs \u00d7 2 routing paths) through a two-phase process:\n\u2022 Calibration Phase: Experts jointly reviewed 200 samples to establish annotation guidelines and resolve edge cases.\n\u2022 Final Annotation: The remaining 1,410 instances were randomly distributed (200 instances per expert) with 10%\noverlap for inter-annotator agreement calculation.\nWe achieved substantial agreement with Fleiss' \u043a = 0.78, calculated on the overlapping samples. Final labels were\ndetermined through majority voting.\nThe RAS provides a basic measure of alignment between the router's decisions and the ground truth, reflecting the accuracy\nof the routing mechanism in selecting the most appropriate experts.\nA.2.2. PREFERENCE-WEIGHTED ROUTING SCORE (PWRS)\nThe Preference-Weighted Routing Score (PWRS) extends traditional routing accuracy metrics by incorporating human\npreference scores derived from the AlpacaEval 2.0 evaluation framework. This metric weights routing decisions based on\nthe quality of the expert outputs as judged by human evaluators. The PWRS is defined as follows:"}, {"title": "\u0392. Supplementary Experimental Validation and Analysis", "content": "B.1. Performance Evaluation\nIn order to perform a comprehensive and controlled performance evaluation, we selected two representative tasks from\nthe BIG-bench Hard (BBH) dataset: commonsense reasoning (550 samples) and logical reasoning (600 samples). The\nreasons for choosing these two tasks are: (1) they effectively validate the core capabilities of the model; (2) they have\nclear evaluation criteria; (3) the sample size is moderate, which facilitates sufficient multi-round cross-validation. In this\nexperiment, we compare KABB with MoA and its lightweight version MoA-lite. Three key metrics were used for evaluation:\n(1) Knowledge matching F1 score, computed using BERT to calculate the semantic similarity between expert capabilities\nand knowledge graph concepts (threshold of 0.75); (2) Path prediction accuracy, based on standard knowledge dependency\npaths, with a perfect match scoring full points, a path length difference of < 1 and key node matches scoring 0.5 points; (3)\nHistorical performance prediction accuracy, using the dynamic weight a/(\u03b1 + \u03b2) (where a and \u1e9e represent the number of\nsuccessful and failed tasks, respectively), with a prediction error \u2264 0.1 considered correct. The experimental results are\nshown in Table 3:\nThe performance of the three models on key metrics is as follows:\nEvaluation Metric\nKABB\nMoA MoA-lite vs. MoA\nvs. lite\nKnowledge Matching F1 (%)\n86.5 71.2\n46.8\n+15.3%\n+39.7%\nPath Prediction Accuracy (%)\n84.9 69.5\n44.2\n+15.4%\n+40.7%\nHistorical Performance Prediction (%)\n85.2 70.1\n45.5\n+15.1%\n+39.7%\nThe experimental results show that KABB significantly outperforms the baseline models on all key metrics. Compared to the\nstandard MoA, KABB shows an average improvement of 15.3% across all indicators; compared to the lightweight MoA-lite,\nthe improvement reaches 40%. This performance enhancement is primarily attributed to the knowledge-aware attention\nmechanism and dynamic path prediction strategy that we proposed. Notably, KABB exhibits stronger generalization ability\nin the commonsense reasoning task, validating the effectiveness of our knowledge-enhanced approach.\nB.2. Parameter Sensitivity Analysis\nThis section explores the impact of three key parameters in the KABB framework\u2014knowledge distance threshold, time\ndecay factor, and efficiency metric-on system performance. The experiment uses the BBH dataset (commonsense reasoning\n580 samples, logical reasoning 570 samples), with standard MoA and MoA-lite as baselines, and evaluates parameter\nsensitivity using a controlled variable approach. The evaluation metrics used are: knowledge matching F1 score, reasoning\naccuracy, and response efficiency. The experiment tests different values for the knowledge distance threshold [0.55-0.95]\nand time decay factor [0.2-1.0]."}, {"title": "G. Supplementary Proofs and Theoretical Analysis", "content": "To better illustrate the theoretical derivations and implementation details regarding the Knowledge-Aware Bayesian Bandit\n(KABB) model in Section 3, we provide the following supplementary proofs and theoretical analysis.\nG.1. Proof of Pseudo-Metric Properties of Knowledge Distance Theorem\nWe provide proofs of Pseudo-Metric Properties of Knowledge Distance Theorem Theorem 3.2 which enhances the reliability\nand effectiveness of the model in expert selection and task allocation.\nProof. This follows directly from the non-negativity of log(1 + dt) and all other terms in the definition of Dist(S, t). Each\nterm (e.g., 1 Poverlap, dependency complexity, etc.) is non-negative by construction.\nProof of Conditional Symmetry: If the dependency graph G is undirected and poverlap(S1,t) = poverlap(S2, t), and if S\u2081\nand S2 are symmetric in terms of knowledge and dependencies, then all terms in the distance function (e.g., |Rdep|, Hs, and\nweights) are equal for S\u2081 and S2. Thus, Dist(S1, t) = Dist(S2, t).\nProof of Approximate Triangle Inequality: Using the properties of the knowledge graph as a metric space, the subadditivity\nof the graph metric ensures that the dependency-based terms satisfy a triangle inequality. Similarly, the Jaccard similarity is\nused in Lemma G.2. Combining these with the weight terms, the inequality holds with a relaxation factor c \u2265 1 determined\nby the extrema of the weights.\nG.2. Proof Sketch of Convergence Analysis for the Dynamic Selection Strategy\nThe proof of convergence is outlined as follows:\n1. Stability of Beta Distribution Parameters: Analyze the stability of the Beta distribution parameter evolution by\nleveraging KL divergence to quantify changes over time.\n2. Lyapunov Function Construction: Construct a Lyapunov function"}]}