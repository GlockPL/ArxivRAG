{"title": "Diversity-grounded Channel Prototypical Learning for Out-of-Distribution Intent Detection", "authors": ["Bo Liu", "Liming Zhan", "Yujie Feng", "Zexin Lu", "Chengqiang Xie", "Lei Xue", "Xiao-Ming Wu", "Albert Y.S. Lam"], "abstract": "In the realm of task-oriented dialogue systems, a robust intent detection mechanism must effectively handle malformed utterances encountered in real-world scenarios. This study presents a novel fine-tuning framework for large language models (LLMs) aimed at enhancing in-distribution (ID) intent classification and out-of-distribution (OOD) intent detection, which utilizes semantic matching with prototypes derived from ID class names. By harnessing the highly distinguishable representations of LLMs, we construct semantic prototypes for each ID class using a diversity-grounded prompt tuning approach. We rigorously test our framework in a challenging OOD context, where ID and OOD classes are semantically close yet distinct, referred to as near OOD detection. For a thorough assessment, we benchmark our method against the prevalent fine-tuning approaches. The experimental findings reveal that our method demonstrates superior performance in both few-shot ID intent classification and near-OOD intent detection tasks.", "sections": [{"title": "1 Introduction", "content": "Task-oriented conversational systems have become widespread across numerous scenarios, including banking, travel, and medical diagnosis (Yan et al., 2017; Zhang et al., 2020b; Feng et al., 2024), where they provide a variety of services. Intent recognition (Zhang et al., 2022a), a key element of these systems, is crucial for enabling automated assistance to address customer needs. Given the wide range of user inquiries, out-of-distribution (OOD) intent detection (Hendrycks et al., 2020; Zhan et al., 2021; Uppaal et al., 2023; Zhan et al., 2024) seeks to protect the intent recognition system by identifying and alerting to malformed inputs.\nRecent advancements in large language models (LLMs) (Touvron et al., 2023; Chiang et al., 2023; OpenAI, 2023) have significantly improved the detection of semantically distinct out-of-distribution (far-OOD) intents (Liu et al., 2023). However, identifying semantically similar (near-OOD) intents continues to pose significant challenges (Fort et al., 2021; Liu et al., 2023). Given its critical importance in practical applications, our study concentrates on near-OOD detection, specifically in a few-shot scenario (Jiang et al., 2024; Zhang et al., 2022b). Particularly, in the few-shot learning context, the training model can receive only a few in-distribution (ID) examples per class. Obtaining discriminative information from limited ID examples for OOD detection is inherently challenging (Zhang et al., 2020a). Previous strategies have involved using extra unlabeled data (Wang et al., 2023) or generating pseudo-ID examples (Zhan et al., 2022) to increase training samples. Instead, we focus on leveraging the inner knowledge of LLMs as a supplement without dataset expansion.\nWe propose a novel channel prototypical learning framework for few-shot near-OOD detection, shown in Figure 1. It employs a set of learned class prototypes to conduct semantic matching for ID classification and OOD detection. To effectively leverage the pre-existing knowledge in LLMs and the limited ID examples, our framework involves using both the ID class names and utterances to develop the class prototypes. Drawing inspiration from channel models (Min et al., 2021; Brown et al., 1993) and prompt tuning (Lester et al., 2021), we feed into the LLMs the ID class names preceded by a series of learnable continuous prompt embeddings to generate a semantic prototype for each ID class. Furthermore, to ensure a wider variety of class representations\u2014a factor known to improve OOD detection (Winkens et al., 2020)\u2014we adopt a diversified learning strategy aimed at reducing the mutual information between classes.\nFor evaluation, we construct few-shot near-OOD intent detection tasks by sampling classes from the"}, {"title": "2 Approach", "content": "Problem Statement A complete intent recognition system typically encompasses two tasks: ID intent classification and OOD intent detection. Formally, given an ID training set {x\u1d62}\u1d62=1N \u2282 XID with N samples, an ID classifier fID is trained, mapping each utterance into ID intent label set {y\u1d62}\u1d62=1K \u2282 YID with K categories. In practical application, due to a possible distribution mismatch between the practical and training data, the ID classifier fID may meet OOD samples (x\u2c7c \u2208 XID). Therefore, an OOD confidence scoring function fOOD is applied to accept or reject such inputs.\n2.1 Semantic Matching as ID Classification\nInspired by Liu et al. (2024), LLMs (like LLaMA (Touvron et al., 2023)) have shown impressive isotropy (Ethayarajh, 2019; Gao et al., 2019), whereby the sentence embeddings produced by LLMs are distinguishable by Cosine distance. As such, we transform the ID classification task into a semantic matching task, shown in Figure 1."}, {"title": "2.1.1 Diversity-grounded Channel Prototypical Learning", "content": "Class Prototypes Our key idea is to push the input sentence closer to its corresponding class prototypes (treated as class-center representations (Snell et al., 2017)). Thus, we first prompt each class into a learnable sequence {c\u1d62}\u1d62=1K based on its category name (Min et al., 2021) and then generate prototypes {p\u1d62}\u1d62=1K with LLM model g(\u00b7) through:\nc\u1d62 = [S]\u2081[S]\u2082...[S]M[NAME], (1a)\np\u1d62 = g(c\u1d62), (1b)\nwhere [S]\u2c7c (j \u2208 {1, ..., M}) is a learnable token with the same dimension as word embeddings (i.e., 4096 for LLaMA), M is the number of learnable tokens, and \"NAME\" corresponds to token embeddings of category names. In practice, the initialization of each learnable token [S]\u2c7c is derived from the token embeddings of a specific prompt, e.g., \"[SCENARIO] intent of\u201d where SCENARIO is \"banking\" for a banking system and is \u201ctravel\u201d for a travel system.\nDiversity Learning To employ semantic matching as classification, the semantics between class prototypes p\u1d62 must be distinguishable with satisfied mutual exclusion. Therefore, a diversity loss is proposed to help the class prototypes focus on diversified independent semantics:\nLDiversity = 1/K \u2211\u1d62=1K \u2211\u2c7c=1,\u2c7c\u2260iK (cos(p\u1d62, p\u2c7c))\u00b2, (2)\nwhere cos denotes the Cosine similarity. Obviously, the semantic similarities between different class prototypes are expected to be 0."}, {"title": "2.1.2 Semantic Matching", "content": "In representation space, for input sentence x, we push its representation closer to the corresponding class prototype p\u2c7c and farther away from other ones in a contrastive manner:\nLMatch = -log \u2211\u1d62=1K exp(cos(g(x), p\u2c7c)/\u03c4) / \u2211\u1d62 exp(cos(g(x), p\u1d62)/\u03c4), (3)\nwhere \u03c4 is the temperature (Hinton et al., 2015)."}, {"title": "2.1.3 Optimization", "content": "We optimize the LLM model g(\u00b7) as well as learnable tokens {[S]\u2c7c}\u2c7c=1M with a joint training objective:\nLJoint = \u03bbLDiversity + LMatch, (4)\nwhere \u03bb is a balancing hyper-parameter. Note that different from Lester et al. (2021) that froze the backbone LLM, we utilize the low-rank adaptation (LORA) (Hu et al., 2021) technique to parameter-efficient tune it (detailed in Section 3.1)."}, {"title": "2.2 OOD Detection with Post-hoc Scoring", "content": "After fine-tuning with ID data, we mainly focus on a distance-base scoring function in post-hoc paradigm, i.e., Cosine distance (Cosine) (Zhou et al., 2021), due to its exceptional performance in the LLM era (Liu et al., 2023). In particular, the Cosine confidence score is defined as the highest cosine similarity between the test input representation and the representations in the validation set:\nS(x) = max{cos(z, zval)\u1d65}\u1d65=1V, (5)\nwhere representation z = g(x) is the output obtained from the penultimate layer of LLMs."}, {"title": "3 Experiment", "content": "3.1 Experimental Setup\nDatasets We explore a more challenging scenario, termed the near-OOD setting, where ID and OOD samples come from the same domain but with disjoint label sets. Following Liu et al. (2023), we use CLINC150 (Larson et al., 2019) intent dataset and choose Banking and Travel domains. Within each domain, 50% of the classes are designated as ID, and the remaining classes as OOD. Detailed dataset statistics are provided in Table 2.\nEvaluation Metrics In accordance with Liu et al. (2023), we adopt three widely accepted measures for OOD detection: (1) AUROC (area under the receiver operating characteristic curve), (2) FAR@95 (false alarm rate at 95% recall), which indicates the likelihood of erroneously labeling a negative sample as positive when recall or true positive rate (TPR) is 95%; Here, we consider the the OOD class as negative, and (3) AUPR (area under the precision-recall curve). Furthermore, accuracy serves as a metric for the ID classification task.\nImplementation Details Following prior work for OOD detection with LLMs (Liu et al., 2023), we employ the LLaMA-7B as g(\u00b7). For both class prototypes and input representations, we use the representation of the last token. \u03c4 in Eq. 3 is set to 0.01 and \u03bb in Eq. 4 is set to 0.2 through cross-validation. We train the whole network for 25"}, {"title": "3.2 Main Results", "content": "The main results are shown in Table 1. On one hand, the proposed semantic matching fine-tuning framework consistently outperforms other tuning methods in most cases, especially for the intent classification task with low training data. Take the results of 5-shot classification on CLINC-Banking as an example. Semantic matching outperforms discriminative and generative tuning by 4.5% and 8.2% respectively, demonstrating the high data-efficient ability of our framework. Meanwhile, the OOD detection performance of Cosine distance improves accordingly due to more accurate and dense representations of classes. On the other hand, in the full-shot setting, while semantic matching yields slightly lower ID classification results on CLINC-Banking compared to the discriminative one, its OOD detection performance is superior, and it also remains competitive on the CLINC-Travel dataset."}, {"title": "3.3 Analysis and Ablation Study", "content": "Variants of Class Prototypes As elaborated in Sec 2.1, we use learnable vectors initialized with scenario-specific prompts plus a class name embedding to generate prototypes. A question worth exploring is what are the effects of other choices? Here, we additionally try 3 types: (1) randomly initialized learnable vectors plus class name embeddings; (2) only randomly initialized learnable vectors; (3) only class name embeddings, e.g., \"trans-"}, {"title": "Effectiveness of Diversity Learning", "content": "We investigate the effectiveness of each training objective in the semantic matching framework with results shown in Table 3. We can find that (1) Incorporating diversity learning can boost the overall performance on both tasks. Notably, it enhances about 11% on the FAR@95 metric, showing strong effectiveness; (2) To better understand why diversity learning provides an improvement, we visualize the corresponding sentence representations in Figure 3. Intuitively, diversity learning makes the separation between classes clearer, thereby enhancing the classification performance of ID data. Simultaneously, it could implicitly distinguish potential OOD data, clarifying the boundaries between ID and OOD data and thus improving OOD detection accuracy."}, {"title": "4 Conclusion", "content": "In this paper, we have proposed a semantic matching fine-tuning framework for boosting ID intent classification and OOD intent detection. By prompting class names into learnable vectors and pushing their representations yielded by LLMs closer to belonged sentence representations,"}, {"title": "Limitation", "content": "This paper mainly has two limitations: (1) we only utilized the LLaMA-7B model, without investigating other open-source large models such as OPT (Zhang et al., 2022c), LLaMA-2&3 (Touvron et al., 2023), and Mistral (Jiang et al., 2023). Furthermore, the impact of instruct-tuning LLMs like LLaMA-Chat on this task was also left unexplored. In the proposed semantic matching framework, strong backbone models could potentially yield superior overall results. (2) Presently, this study predominantly builds upon prior research by Liu et al. (2023), focusing on the CLINC dataset. Therefore, intent datasets such as BANKING77 (Casanueva et al., 2020) and StackOverflow (Xu et al., 2015) remain unexplored in this context. Further exploration of these datasets would be beneficial."}, {"title": "A Appendix", "content": "A.1 Training Details\nAll experiments are conducted over five seeds (1, 2, 3, 4, 5) on an NVIDIA A100 80G GPU card. The LoRA configurations are that rank r is 16, scaling \u03b1 is 16, and query/key/value/output projection matrices {Wq, Wk, Wv, Wo} in each self-attention module need to be updated."}]}