{"title": "AI-Powered Urban Transportation Digital Twin: Methods and Applications", "authors": ["Xuan Di", "Yongjie Fu", "Mehmet K.Turkcan", "Mahshid Ghasemi", "Zhaobin Mo", "Chengbo Zang", "Abhishek Adhikari", "Zoran Kostic", "Gil Zussman"], "abstract": "We present a survey paper on methods and applications of digital twins (DT) for urban traffic management. While the majority of studies on the DT focus on its \"eyes,\" which is the emerging sensing and perception like object detection and tracking, what really distinguishes the DT from a traditional simulator lies in its \"brain,\" the prediction and decision making capabilities of extracting patterns and making informed decisions from what has been seen and perceived. In order to add values to urban transportation management, DTs need to be powered by artificial intelligence and complement with low-latency high-bandwidth sensing and networking technologies. We will first review the DT pipeline leveraging cyberphysical systems and propose our DT architecture deployed on a real-world testbed in New York City. This survey paper can be a pointer to help researchers and practitioners identify challenges and opportunities for the development of DTs; a bridge to initiate conversations across disciplines; and a road map to exploiting potentials of DTs for diverse urban transportation applications.", "sections": [{"title": "1 Introduction", "content": "Urban transportation systems are complex to model and simulate, due to heterogeneous road users (such as cars, pedestrians, cyclists, scooters) interacting in multimodal traffic environments consisting of public and private travel modes. With fast-changing traffic evolution in time and space, traffic simulation if improperly calibrated, might produce traffic management strategies that largely deviate from the reality, potentially leading to suboptimal or even detrimental outcomes. With ubiquitous sensors in smart cities, it is the time to augment conventional traffic simulators, many of which were developed in an era when only \u201csmall data\u201d became available. Emerging traffic sensors are expected to generate big volumes of data, transmitted via communication networks and processed on edge cloud computing with artificial intelligence (AI) for real-time traffic management. Such a transformation poses challenges that call for the development of a new paradigm, namely, digital twin (DT), which will push the envelope in urban transportation management.\nLiterally, DT is the digital replica of a physical object or asset [48], where a digital world mirrors a physical world for real-time diagnosis, prognosis, and decision making. Recent years have seen a growing amount of studies on DT in various domains, ranging from manufacturing [48], aerospace [76], to smart cities [82]. In particular, there is a sizable body of articles on transportation DTs powered by vehicular technologies such as connectivity and autonomy [134, 162, 57, 199, 80]. With such a growing trend, we would like to restrict the scope of this survey paper. Here we are particularly interested in urban traffic settings where cars have to interact with vulnerable road users (VRU) (i.e., non-motorists such as pedestrian, bicyclists, other cyclists, or persons on personal conveyance [153]), who are an integral part and also potential users of the DT. We will primarily focus on two use cases, namely, intersection safety warning and network wide traffic signal control, for improved traffic safety and efficiency. The literature on DTs for urban traffic management is lacking, partly because the development of a DT for a system is non-trivial, particularly involved with human participants like VRUs. The development of such a DT must engage with expertise in sensing,"}, {"title": "2 Preliminaries", "content": ""}, {"title": "2.1 Variants of DT definitions", "content": "The definition of DT has evolved rapidly. Despite presenting its own version, these articles all share common elements and resemble certain characteristics [48, 114]. In general, there is a physical world (aka. the physical) and a digital world (aka. the digital). The physical world evolves in time and space. To ensure that the physical system is run in a desired direction, it requires close monitoring, operation, and management. Thus, the role a digital world plays is to model and simulate the dynamics of the physical world in a synchronized fashion, so that the digital can also predict the future states of the physical precisely, which offers a ground for optimal decision making. The physical and the digital exchange data and information flows via a two-way communication. Specifically, the physical sends the data of its own state to the digital, and the digital feeds back the actuation signals to the physical. The actuation would trigger a change in the stage of the physical, and the updated state is sensed and sent back to the digital again. This iterative process runs between the physical and the digital as time unfolds. The sequential states of the physical should move towards a more desired state than without a DT. In other words, the ultimate goal of a DT development is to add values to the physical for improved safety and efficiency.\nDepending on whether there is any interaction between the physical and the digital via data and/or information exchange, there are three types of digital twinning concepts [47], namely,\n1. digital model: with no automatic data exchange;\n2. digital shadow: with only one-way data exchange from the physical to the digital;\n3. digital twin: with two-way communication.\nLet us specify a definition of DT in transportation."}, {"title": "Definition 2.1", "content": "Traffic digital twin is a digital system integrating the pipeline from object detection and tracking, resource allocation, edge-cloud computing and communication, for online simulation, operation, control and management. It is updated online using continuously fed data collected from the physical and send control policies or issue warnings back to the physical, leveraging big data and AI tools. Traffic DTs are closed-loop with two-way communication, where data, information, and control signals are exchanged with the physical sequentially and reiteratively."}, {"title": "2.2 Cyberphysical transportation systems", "content": ""}, {"title": "Definition 2.2", "content": "Cyberphyscial systems (CPS) [49] are smart systems that include engineered interacting networks of physical and computational components. CPS holds great potential to enable real-time applications thanks to emerging technologies in sensing, communication, and computing."}, {"title": "2.2.1 CPS as DT technological enabler", "content": "A transportation CPS interlinks physical and cyber layers, where the cyber layer consists of sensing, networking, computing, and traffic management application modules (see Fig. 1). The DT encloses the cyber layer, and relies on all the modules for two-way interaction with the physical.\nTo enable the technological development of a DT, a physical testbed is needed as a platform for sensing, computing, experimentation, evaluation, as well as design constraints determination. In Secs. 3.1-3.3, we will review the CPS"}, {"title": "2.2.2 DT as CPS testing tool", "content": "An automatic system like CPS demands high degree of autonomy for urban traffic management, with increased complexity and scale. Thus, DT becomes crucial for the test and verification of a CPS. We need to verify the system behavior of a CPS to ensure that it performs as desired [141], such as safety, efficiency, timeliness, and accuracy.\nDue to the integration of cyber and physical components, as well as their two-way coupling via communication and networking, testing a CPS is non-trivial. Given that the digital is expected to be the twin of the physical, it is natural to compare the difference in the outputs of both the physical and the DT using \"Grieves performance test\" [48]. Hardware-in-the-loop testing, such as vehicle-in-the-loop [172], could help test directly the performance of some physical components \"live,\" while allowing the rest to be simulated within a DT. For DTs that involve the feedback to humans, human-in-the-loop test is widely used on driving simulators [183, 79]. Recent years have seen a growing trend of using augmented reality and virtual reality (AR/VR) or Metaverse to engage humans as pedestrians, cyclists, or scooters in virtual environments without inducing real-world risks [164, 72].\nSince there does not exist a unified approach for the DT testing in the context of transportation, in Sec. 3.4, we will review evaluation metrics employed by various use cases."}, {"title": "3 Related work", "content": "In this section, we will review technological enablers of DT along the pipeline depicted in Fig. 1."}, {"title": "3.1 Sensing and perception", "content": "Sensors are the \"eyes\" (and \u201cears\u201d) of a DT. Tab. 2 summarizes the pros and cons of each sensing technology, namely, mobile devices, on-board vehicles, and roadside infrastructure, for urban traffic applications. The former two are mobile sensors with wider spatial coverage but challenge in precision because of moving references, while the latter at fixed locations could face limited sensing ranges and coverage."}, {"title": "3.2 Object detection and tracking", "content": "Object detection identifies and classifies objects within the environment using sensors like cameras, Lidar, and Radar. Object tracking is the process of monitoring the detected objects over time to determine their position and movement. Multi-object tracking is concerned with maintaining the identity of the objects and generating their trajectories. Trajectory prediction involves forecasting the future paths of detected and tracked objects. These tasks highly rely on training datasets for urban traffic scenes. Note that there is a much larger size of public datasets collected from on-board vehicles [31], but fewer from other sensor types. Here we thus summarize commonly used and emerging datasets from non-vehicle sensors in Tab. 1.\nObject detection has been studied extensively for urban applications. Single-stage object detectors, following the original single shot multibox detector [93] and You Look Only Once (YOLO) [126] architectures, have become popular due to their real-time deployment capabilities. In the last few years, transformer-based object detection approaches, competitive with YOLO models, have emerged as the state-of-the-art in object detection when designed to be deployed in real-time settings [197]. Recent progress in YOLO object detection performance has been enabled through multiple small tricks in architecture and training that all together provide significant improvements in empirical performance [155].\nWhen multiple camera views are available, 3D object detection has been studied heavily for autonomous driving [46, 146], as well as for infrastructure-based 3D object detection [117, 152, 181, 11]. Many approaches to 3D object detection use object queries [160], bird's-eye view transformations [173], or a combination of the two [90].\nTo build models that make weaker assumptions regarding the sensors, some models have considered the harder task of monocular 3D object detection. MonoCon uses extra regression head branches for learning auxiliary contexts, that are then discarded during inference [95]. DEVIANT is a model architecture equivariant to depth translations [70]. MonoLSS introduces a learnable sample selection module to improve the stability and reliability of the model at test time [81]. Different models have been proposed for infrastructure-based 3D object detection, as many models developed for vehicle-side perception make strong assumptions regarding the position of the cameras. BEVHeight predicts height to the ground to support 3D object detection [175]. CoBEV combines depth and height features to further improve the performance of infrastructure-based 3D object detection [137]. MonoUNI presents the idea of normalized depth, which makes depth prediction independent of camera pitch angle and focal length [61].\nTo improve the limitations of camera-only perception methods, different sensor combinations are explored. For example, LiDARS or radars, combined with cameras, can detect objects in scenarios where using only the camera is insufficient, such as extreme lighting and weather conditions, or anomalous situations where the camera data is significantly out-of-distribution. Sensor fusion for self-driving cars is now being studied including sensor data for these modalities [23, 87]. These methods often involve the projection of camera, radar and LiDAR features independently to a bird's-eye view feature space, wherein an aggregation function could be used to merge the features extracted from these different sensors."}, {"title": "3.3 Real-time video analytics", "content": "Developing end-to-end real-time video analytics systems on a large scale for time-sensitive and safety-critical traffic and crowd management applications presents challenges. Video analytics requires the collection and processing of large volumes of video data, which can be resource-intensive and costly. Optimizing computation and network resource usage while maintaining or enhancing the accuracy of analytical results can be challenging. This challenge is further complicated by the need to adapt to varying network conditions, computational resources, and dynamic scene changes in real-time. Tab. 3 provides a comparative analysis of various approaches to address these challenges. The approaches differ in their focus-some prioritize reducing latency and resource consumption, while others emphasize maintaining or enhancing accuracy, especially under constrained conditions. This comparison provided in Tab. 3 highlights the trade-offs inherent in real-time video analytics and emphasizes different optimization methods to balance throughput, accuracy, energy consumption, and computational efficiency across diverse deployment scenarios, including edge devices, cloud platforms, and hybrid environments."}, {"title": "3.4 Use cases", "content": "The value of a DT for urban transportation management ranges from traffic state prediction, spatiotemporal traffic flow forecasting, to urban planning and policy making. Here we focus on two that are particularly important in urban settings."}, {"title": "3.4.1 VRU safety warning: Safety-critical application", "content": "Safety-critical applications, making automated life-and-death decisions such as collision avoidance warning between automobiles and pedestrians, need to activate at the precise time and the right moment with bounded latency. Safety-critical systems are often time-critical and reactive, because they need to react to external signals in precise time [69], and require tasks to be executed in a timely manner. Theses systems hold the substantial potential to enhance road safety and save lives. They are, however, risky to test and run, because rare events like automobile collisions are challenging and unethical to replicate. Thanks to emerging technologies in ubiquitous sensing, low-latency high-bandwidth communication, high-speed computing and AI, safety critical applications could potentially be modeled, simulated, processed, and tested in a DT. The applications of DTs on safety-critical scenarios, however, remains understudied, because it necessitates short runtime and real-time reaction, posing high requirements for communication and computing technologies, pipeline architecture design, and testing.\nWe summarize the safety-critical applications to address conflict risks between vehicles and VRUs in Tab. 4, and offer an outlook of safety guarantee related methods in Sec. 5.1.4."}, {"title": "3.4.2 Networkwide adaptive traffic signal control", "content": "Learning methods for network wide adaptive traffic signal control (ATSC), including reinforcement learning (RL) and federated learning (FL), aim to learn optimal traffic signal control strategies in traffic environments with unknown state transitions and unknown rewards. Assuming that traffic signal controllers are intelligent autonomous agents, their goal is to make sequential decisions to optimize an objective function, such as minimization of traffic delay or maximization of traffic throughput. To train an optimal policy for traffic signal controllers, a traffic simulator or DT, needs to be built, where dynamic traffic is simulated in the training environment aligned with the testing environment in principle. The trained policies leveraging such a DT need to be executed in the real world, which triggers updated environments for future decision making. Related work are summarized in Tab. 5."}, {"title": "3.5 Close the loop", "content": "To realize the value of a DT, the feedback from the digital to the physical is the key. The type of feedback and to what entities would define the technological constraints.\n\u2022 Feedback to VRUs (super local): When users react to an issued warning, the state of the environment for the VRU would change, and the DT could update its status about whether continuous warning is needed. Normally the warning is safety related, thus demanding low latency and high bandwidth.\n\u2022 Feedback to cars (super local): The feedback to cars includes hierarchies: (1) strategic driving feedback, such as routing recommendations, allowing higher latency and lower bandwidth; (2) tactical feedback on tactical driving decisions, such as lane-change, with medium latency and bandwidth; and (3) operational feedback such as throttle control, demanding (ultra) low latency and bandwidth. When cars change their driving maneuvers, the traffic environment needs to be updated and unsafe outcomes could be potentially avoided.\n\u2022 Feedback to traffic operators and infrastructure (local or networkwide): For traffic operators, DTs could provide anomaly detection for diagnosis, and predict future traffic states or collisions for prognosis, which would help with variable speed limit, dynamic speed advisory, lane usage adaptation, ramp metering, traffic signal timing optimization, and network wide traffic management, with increasing requirements for latency and bandwidth.\n\u2022 Feedback to city planners (citywide): In the long-term, a DT could provide aggregate traffic information to city planners to assess the potential societal impact of new infrastructure planning. Thus, the technological requirement is relatively low, but the collected data needs to cover a relatively large spatiotemporal range for citywide decision making,"}, {"title": "3.6 Communication and networking", "content": "A DT for safety-critical applications requires real time communications with aggressively low latency. We explore issues related to low latency communications, and survey component technologies and protocols that can be utilized to achieve very low latency."}, {"title": "3.6.1 Real-time requirements and low latency targets", "content": "Sensor and control data in a real time system is subject to latency created by the stages, namely, (1) data acquisition from traffic participants (such as camera recordings and encoding, harvesting data from autonomous vehicles, and collect information from fiber); (2) transmission of data across communications links from sensors to inferencing servers using communications protocols such as Transmission Control Protocol (TCP), Unreliable Data Protocol (UDP) and Real-Time Streaming Protocol (RTSP); (3) data preprocessing (video decoding, and cropping); (4) AI inferencing; (5) higher level reasoning about required feedback to traffic participants; and (6) sending feedback to traffic participants across communications links via low-latency broadcast or dedicated channels over wired and wireless.\nSmart city applications can be grouped according to their latency requirements. Many, if not all, pedestrian-associated application (facilitated by pedestrian detection/observations and message notifications) are likely to expect the round trip delay in the range of a couple of seconds. Such latency can be supported by contemporary cameras, communication protocols and inferencing engines. Applications which would attempt to close the observation/notification loop for vehicles moving at about 10kmph may expect latency in tens of millisecond. Using conventional video compression, RTP/RTSP streaming and edge computing is inadequate to support such latency. This presents the opportunity to pursue novel engineering solutions and research problems."}, {"title": "3.6.2 Communication techniques and protocols", "content": "Ultra-Reliable Low Latency Communications (URLLC), a key component of 5G wireless, can help achieve the low latency targets. Along with enhanced mobile broadband (eMBB) and massive machine-type communication (mMTC), URLLC [123] represents one of the three main capabilities of 5G New Radio (5G NR), as standardized by the 3rd Generation Partnership Project (3GPP). In the context of transportation systems, URLLC aims to deliver up to 99.999% reliability and single-digit millisecond latency [2]. However, meeting these performance metrics is challenging in practice due to complex channel environments, particularly in dense urban areas, which can reduce reliability. For intelligent transportation systems, where URLLC may be used as infrastructure backhaul, the target is an end-to-end latency of 30 ms [1].\nAn emerging technology in this space is Cellular-Vehicle-to-Everything (C-V2X), which has largely replaced the ear-lier Wi-Fi-based Dedicated Short-Range Communications (DSRC). Unlike DSRC, C-V2X leverages cellular networks, allowing network providers to offer always-on connectivity, which is a critical feature for time-sensitive applications. Additionally, private 5G networks are being developed to ensure this level of connectivity, overcoming the congestion and range limitations inherent to Wi-Fi [37]. In transportation systems, active collaboration between wireless service providers and vehicle manufacturers is in progress to integrate private 5G networks into vehicular networks [3].\nMessage Queuing Telemetry Transport (MQTT) is a lightweight communication protocol that offers efficient, reliable, and scalable data transfer necessary for real-time, safety-critical applications. Such a protocol can efficiently collects and distributes traffic data from numerous sensors to update DTs in real-time, and facilitates fast communication of incidents and emergencies, allowing timely interventions. Key features include [122]:\n\u2022 Lightweight and scalable: MQTT is designed with a minimal fixed header of only 2 bytes, which reduces the communication overhead significantly. It decouples message producers and consumers, allowing easy scalability and flexibility in handling numerous sensors and devices.\n\u2022 QoS levels and reliability: MQTT's different QoS levels enhance reliability by ensuring message delivery according to the application's criticality. QoS 0 delivers messages at most once without acknowledgment. QoS 1 ensures messages are delivered at least once, while QoS 2 guarantees exactly one delivery through a four-step handshake, preventing duplication and ensuring data integrity for critical communications. Moreover, MQTT's LWT (Last Will and Testament) feature allows the system to detect and respond to unexpected device disconnections, maintaining the robustness of the network."}, {"title": "4 Proposed DT pipeline", "content": "In this section, we present a DT architecture called \"Urban Hybrid Twin, based on the sensing/communication/computing testbed deployed in NYC (Fig. 1). The proposed architecture of \"Urban Hybrid Twin\" is enabled by CPS, user software defined radios (SDR), cameras and LiDARs, high speed communications, and AI computing deployed in the edge cloud."}, {"title": "4.1 System components", "content": ""}, {"title": "4.1.1 Physical Infrastructure", "content": "The physical functionality of the proposed DT is built on top of the COSMOS testbed (\"Cloud enhanced Open Software defined mobile wireless testbed for city-Scale deployment\" [125] developed for real-world research, development, and"}, {"title": "4.1.2 Digital twin", "content": "Building on data collected from the physical world, we built an Unreal Engine based simulation platform for generating photorealistic street scenes. Moving objects are populated into an integrated SUMO-CARLA simulation platform to validate our safety warning application [43], where vehicle locations are synchronized from the real-world MQTT messages."}, {"title": "4.2 System functionality", "content": ""}, {"title": "4.2.1 Resource optimization", "content": "Due to the computational needs of complex computer vision models and the high volume of video data, ensuring scalability in a video analytics pipeline requires optimization of its configuration to maintain performance. However, the system's performance is impacted by factors such as the video content, network conditions, and available computational resources. As a result, it is crucial to implement a dynamic, real-time optimization mechanism that adjusts key configuration parameterssuch as resolution, frame rate, and bitratebased on these varying conditions. This adaptive approach allows the system to continuously balance performance with resource efficiency, ensuring scalable and reliable video analytics. Accordingly, we have equipped our video analytics pipeline with a Resource Optimization (see Fig. 2) component that continuously adapts the system's configuration parameters to maintain its performance."}, {"title": "4.2.2 Use cases", "content": ""}, {"title": "4.2.2.1 Pedestrian-vehicle safety warning", "content": "Leveraging existing sensors at the intersection, we have developed a combined VRU and vehicle warning application. The cameras and the LiDAR sense the presence of VRUs at urban intersections, make predictions of their movements, apply traffic operation and control strategies, and feedback to system controllers and road users, with the primary goal of increasing traffic safety and efficiency. (see Fig. 3).\nA variety of AI models have been developed to predict future trajectories of interacting road users at the intersection, including InfoSTGCAN (An Information-Maximizing Spatial-Temporal Graph Convolutional Attention Network) integrating InfoGAN and spatiotemporal graph convolutional attention network [131], and PI-NeuGODE using physics-informed graph neural ordinary differential equations[107, 110], and uncertainty quantification (UQ) to characterize the predictive confidence [105]."}, {"title": "4.2.2.2 Learn to optimize adaptive traffic signal control", "content": "To optimize traffic signal control over a road network requires first to predict traffic patterns on road segments and intersections. The AI models we developed include PINO (physics-informed neural operator) [45] that predicts future traffic dynamics by training a mapping from initial conditions to traffic states in time and space, building on our previous work on PIDL [138, 139] and the UQ problem [108, 106]. For ATSC, we have developed an RL method, CVLight [109], and an FRL method [42] on the COSMOS network [42]. Their performances are illustrated in Fig. 4."}, {"title": "4.3 Evaluation", "content": "In safety-critical applications, it is infeasible to perform field experiments for such assessment. DT simulation is thus used to assess the effectiveness of the system."}, {"title": "4.3.1 End-to-end latency", "content": "Measuring latency could be particularly problematic due to the need for cross-network timing synchronization of devices and compute server. Spot measurements of several components are shown in Table 6. This table presents the latency incurred by the main components of a typical video analytics pipeline for object detection and tracking, as depicted in Fig. 3, which has been systematically optimized in terms of memory and resource usage. These elements usually run on an edge device or server. The results in Table 6 identify potential bottlenecks within the pipeline and indicate which components could benefit from further optimization. Additionally, the table illustrates the impact of video content complexity on the latency of each component, providing insights into performance variations during busy and sparse traffic conditions.\nTo understand the sensitivity and complexities of real-time video analytics, we measured the latency introduced by key components of a typical video analytics pipeline, illustrated in Fig. 3. For object detection, we used the YOLOv8m model [149] (batch size: 1) with the Nvidia DCF-based tracker. The YOLOv8m model was configured to accept input images at 832\u00d7832 resolution, corresponding to the size of the regions cropped by the Rol cropping component. The 5G and LTE networking latency was measured using iPhone 13 Pro Max, while wired and wireless networks provided by Columbia University Information Technology were used for the Ethernet and WiFi measurements. Latency measurements are conducted at various times of the day with different traffic densities. Tab. 6 summarizes the results of these measurements by comparing the average and standard deviation of latency per frame for the main components of the pipeline.\nThese latency measurements demonstrate how each pipeline component influences overall latency and its variability under different video content densities. The results highlight the necessity of optimizing these components for real-time applications, particularly in environments with dynamic traffic patterns. In the following, we describe the function of each element in the inference pipeline (see Fig. 3) and their associated latencies based on the results presented in"}, {"title": "\u2022 Reception:", "content": "Receives RTP (Real-time Transport Protocol) data packets and, after parsing and decoding, converts them to raw video frames. The latency increases under busy traffic conditions, primarily due to higher complexity of the data being processed, such as larger frame sizes and more variation in the number of data packets per frame."}, {"title": "\u2022 Pre-processing:", "content": "Extracts regions of interest (RoIs) from raw video frames and discards irrelevant regions. It incurs low latency with minimal variations, indicating the effectiveness of pre-processing in optimizing video analytics performance."}, {"title": "\u2022 Object detection:", "content": "Applies the object detection model to the cropped Rols. This element incurs the highest latency in the pipeline. The latency is slightly higher in busy traffic/crowd conditions due to more objects in each video frame."}, {"title": "\u2022 Object tracking:", "content": "Assigns unique IDs to detected objects across video frames for tracking. It has higher latency under busy conditions due to the increased number of objects being tracked simultaneously."}, {"title": "\u2022 MQTT message creator:", "content": "Converts the extracted metadata into MQTT format [104] and transmits it over a designated topic. Its latency is consistently low, with a slight increase during busy conditions due to the need to assemble larger messages."}, {"title": "\u2022 MQTT message retriever:", "content": "A web application captures round-trip time (RTT) of MQTT messages, and measures the latency as half an RTT."}, {"title": "4.3.2 Safety warning performance", "content": "To validate the accuracy of our trajectory prediction and risk assessment algorithms for warning generation, we conducted three rounds of simulation, each lasting 10 minutes and generating a total of 232 virtual pedestrians in CARLA. We then compared the number of collision warning messages with the actual number of simulated collisions. The process is illustrated in Fig. 5.\nMetrics for risk assessment include time to collision (TTC) (i.e., the time remaining before a collision occurs) and post-encroachment time (PET) (i.e., the time interval between when the encroaching vehicle leaves the conflict point and when the vehicle of the right-of-way arrives at the conflict point). For prediction, we select TTC and set its threshold as 1.2 seconds to minimize both false positives (FP) and false negatives (FN) while optimizing true positives (TP) and true negatives (TN). The resultant confusion matrix is [[TP, FP], [FN, TN]] = [[66, 45], [2, 119]]."}, {"title": "5 Conclusions and open questions", "content": "Transportation applications in urban settings are generally challenging to design, develop, deploy, and test for their potential unsafe and unethical consequences. Thus, AI-empowered DT plays a critical role in effective implementation of these applications. Despite relatively sparse literature in this domain, we review an ensemble body of literature on how to leverage emerging technologies in sensing, communication, edge and cloud computing, for urban traffic management. We hope this paper can serve as a pointer to help researchers and practitioners identify challenges and opportunities on the development of DTs; a bridge to initiate conversations across interdisciplinary researchers in sensing, communication and networking, traffic engineering, and AI; a road map to exploiting potentials of DTs for diverse transportation applications."}, {"title": "5.1 Emerging trends", "content": "While literature on DTs for individual components has been surging, how each element of the DT works collectively and function organically is key to the development of the next-generation DT, which could empower the intelligence and automation of transportation applications."}, {"title": "5.1.1 Engineering the pipeline", "content": "Engineering a DT via the integration of multiple subsystems poses technical challenges, and we will name a few."}, {"title": "5.1.1.1 Datasets for urban computer vision", "content": "Due to limited availability and single perspective of real-world datasets, synthetic data generation from realistic 3D simulators has become increasingly popular for urban computer vision problems. The SYNTHIA dataset, for example, provides a diverse set of images from a simulated city with pixel-level semantic annotations, aiding tasks like semantic segmentation and scene understanding [129]. CARLA has been widely used in object detection and segmentation [115, 59, 101]. Similarly, GTA V has been employed to collect game frames for training autonomous agents [128]. Unreal Engine has gained traction as a rendering engine for various vision tasks [4, 55, 29]. MatrixCity utilizes Unreal Engine 5's City Sample project to benchmark neural rendering models, focusing on pedestrian- and vehicle-free environments [78]. The Boundless project shows YOLOv8x's enhanced performance on real-world datasets when trained with Unreal Engine 5-synthesized data [151]. However, mixed-perspective datasets that adapt to diverse deployment conditions remain scarce. Advances in open-vocabulary object detection offer a promising avenue for addressing this gap [92, 103, 24]."}, {"title": "5.1.1.2 Sensor fusion with time synchronization", "content": "Various methods have been proposed to tackle the time-synchronization problem in multi-camera settings for a single intersection or area, either utilizing visual cues or through explicit clock synchronization between the cameras. [144] estimates the spatial transformation between the views. [9] proposes an approach at time synchronization based on the temporal alignment of matching trajectories of entities present in the overlapping scenes. [33] proposes solving a global alignment problem based on video feature descriptors. [17] uses image features to train neural networks for solving the alignment problem. [170] proposes a neural network that uses pose cues to align videos temporally. [140] proposes the use of abrupt lighting changes as temporal cues for facilitating alignment for rolling shutter cameras. Other approaches include estimations of camera capture and transmission latency [74], or clock synchronization [88, 6, 14]. These approaches address the problem of synchronizing sensors across different road intersections. Efficient, low-latency implementation of these methods are vital for synchronization and fusion of camera predictions."}, {"title": "5.1.2 Designing edge-cloud architecture and networking", "content": "To facilitate the development of a DT in an urban setting with numerous intersections capable of communicating with vehicles and VRUs, an extended network of cloud-connected edge devices and sensors, such as cameras, is required. These sensors generate substantial amounts of real-time data that must be transmitted to edge or cloud systems and processed with bounded latency. The data from all sensors should be integrated into a centralized platform. Given the extensive distribution of these devices, privacy and data security become critical considerations. To safeguard privacy, encoded sensor data is transmitted only to edge devices, where it is processed to extract relevant metadata. Only this metadata is then forwarded to the cloud or central platform for further analysis and integration, ensuring that no raw data or personal information is shared. To this end, data and device federation using federated (reinforcement) learning has gained growing traction [96, 35, 42].\nIntegrated sensing and communication (ISAC) is an emerging direction in the design of Beyond-5G wireless networks, enabling transmitted communication waveforms to be opportunistically used as radar-like sensors [89, 166]. In urban mmWave and sub-THz networks, ISAC can enable real-time tracking of vehicles and pedestrians, enhancing sensor fusion algorithms without compromising the network's primary communication responsibilities. Future research directions may focus on leveraging high angular resolution from densely packed phased arrays to achieve precise beamforming, with the potential to introduce imaging-like capabilities within communication networks [120, 50]."}, {"title": "5.1.3 Physics-informed DT development", "content": "The mutual interaction between domain knowledge and AI is necessary. Domain knowledge in traffic flow and road safety that has been developed for decades, provides valuable insights into every stage of the DT pipeline. In particular, it helps inform technological advancement and testbed deployment, data collection, model selection and training,"}, {"title": "5.1.4 Safety guarantee of AI", "content": "DTs, heavily relying on hardware, software, and algorithms, are vulnerable to risks posed by probabilistic events. Failures in sensors, communication channels, or algorithms can result in erroneous or missing inputs to downstream prediction or decision-making, ultimately compromising the feedback loop from the DT to the physical. The rise of AI-empowered DTs introduces additional risks, including adversarial attacks, and trustworthiness in real-world applications. How can DTs be designed with provable safety"}]}