{"title": "CoVoSwitch: Machine Translation of Synthetic Code-Switched Text Based on Intonation Units", "authors": ["Yeeun Kang"], "abstract": "Multilingual code-switching research is often hindered by the lack and linguistically biased status of available datasets. To expand language representation, we synthesize code-switching data by replacing intonation units detected through PSST, a speech segmentation model fine-tuned from OpenAI's Whisper, using a speech-to-text translation dataset, CoVoST 2. With our dataset, CoVoSwitch, spanning 13 lan-guages, we evaluate the code-switching trans-lation performance of two multilingual transla-tion models, M2M-100 418M and NLLB-200 600M. We reveal that the inclusion of code-switching units results in higher translation per-formance than monolingual settings and that models are better at code-switching transla-tion into English than non-English. Further, low-resource languages gain most from inte-gration of code-switched units when translat-ing into English but much less when translat-ing into non-English. Translations into low-resource languages also perform worse than even raw code-switched inputs. We find that systems excel at copying English tokens but struggle with non-English tokens, that the off-target problem in monolingual settings is also relevant in code-switching settings, and that models hallucinate in code-switching transla-tion by introducing words absent in both of the original source sentences.", "sections": [{"title": "1 Introduction", "content": "Code-switching (CSW), otherwise known as code-mixing, refers to the use of linguistic units from multiple languages in a conversation or utterance (Pratapa et al., 2018). In general, researching code-switching comprehensively is a complicated task due to the lack of code-switched data. One so-lution is to use existing code-switching datasets (Weller et al., 2022; Nguyen et al., 2023), but there is a limited number of such datasets and us-ing them constrains research to the few language pairs that datasets are concentrated in, such as Spanish-English or Hindi-English (Winata et al., 2023). To alleviate the problem, previous work (Alastruey et al., 2023) brought together multiple datasets, such as Fisher (Cieri et al., 2004) and Ban-gor Miami (Deuchar et al., 2014). Nevertheless, in the multilingual setting, collecting data from multiple sources mixes different degrees of code-switching and blocks parallel understanding across languages.\nAlternatively, most works have introduced syn-thetic datasets (Winata et al., 2023). These have been based on linguistic theories, such as the Matrix Language Frame (MLF) Model (Myers-Scotton, 1997) and the Equivalence Constraint (Poplack, 1980). Applying the Equivalence Con-straint requires the use of constituency parsers. (Rizvi et al., 2021) utilized the Stanford Parser (Klein and Manning, 2003) and the Berkeley Neu-ral Parser (Kitaev and Klein, 2018; Kitaev et al., 2019). However, as of now, the Stanford Parser sup-ports Arabic, Chinese, English, French, German, and Spanish, while the Berkeley Neural Parser sup-ports Arabic, Basque, English, French, German, Hebrew, Hungarian, Korean, Polish, and Swedish. This presents a bottleneck in the number of lan-guages that can be used for research and impedes the creation of code-switching data for unsupported or low-resource languages such as Tamil.\nSynthetic datasets have also introduced code-switching mainly based on words. These include random replacements based on words (Rijhwani et al., 2017; Xu and Yvon, 2021; Rizvi et al., 2021; Tarunesh et al., 2021) and replacements based on connected components of aligned words (Iyer et al., 2023). However, word-based switching may not completely reflect the code-switching phenomenon. Recent research (Pattichis et al., 2023) demon-"}, {"title": "2 Synthetic Data Generation", "content": "We use the En\u2192X subset of the CoVOST 2 dataset, as this subset contains English recordings that we use to detect English prosodic boundaries. For non-English languages, we select Arabic (ar), Catalan (ca), Welsh (cy), German (de), Estonian (et), Per-sian (fa), Indonesian (id), Latvian (lv), Mongolian (mn), Slovenian (sl), Swedish (sv), Tamil (ta), and Turkish (tr). We follow the classification scheme of (Costa-juss\u00e0 et al., 2022) and denote Welsh, Mon-golian, and Tamil as low-resource and others as high-resource. To match units of measurement for metrics such as CMI and SPF detailed later in this study, we exclude Chinese and Japanese, which are not whitespace separated. Further information on languages covered is contained in Appendix A.1.\nUsing the PSST model\u00b2 (Roll et al., 2023) fine-tuned from OpenAI's Whisper\u00b3 (Radford et al., 2023), we both generate transcriptions and detect intonation unit (IU) boundaries for English utter-ances in the original Common Voice 4.0 Corpus"}, {"title": "2.1 Intonation Unit Detection", "content": "strated that code-switching is more common across intonation units than within as a result of looser syn-tactic relationships and that intonation units should therefore serve as new replacement units instead of words. This constraint is referred to as the Intona-tion Unit Boundary Constraint.\nTo expand language representation, experiment with intonation units as basis units of code-switching, and reflect both linguistic and prosodic constraints, we synthesize data by following the Matrix Language Frame Model and the Intonation Unit Boundary Constraint. We keep English as the matrix language and embed segments from non-English languages by replacing English intonation units of utterances from CoVOST 2 (Wang et al., 2021), a speech-to-text translation (S2TT) dataset, detected with PSST (Roll et al., 2023), an English prosodic speech segmentation model fine-tuned from OpenAI's speech recognition model Whis-per (Radford et al., 2023). Utilizing S2TT datasets is advantageous for several reasons. First, they include transcripts for both languages and audio files for one language in each pair, which allows the simultaneous incorporation of text and speech features in code-switching data creation. Moreover, recent datasets cover a multitude of high-resource and low-resource languages, which enables the in-clusion of diverse language pairs for synthetic code-switching data.\nMeanwhile, we observe that while recent works (Zhang et al., 2023; Khatri et al., 2023) have demon-strated the translation performance of multilingual large language models with billions of parameters such as XGLM-7.5B and BLOOMZ-7b1 on code-switching data, performance of multilingual neural machine translation (MNMT) models with millions of parameters remains relatively underexplored. We therefore measure the zero-shot code-switching translation performance of M2M-100 418M (Fan et al., 2021) and NLLB-200 600M (Costa-juss\u00e0 et al., 2022), capable of multilingual translation for 100 and 200 languages respectively, on our syn-thetic dataset.\nOur contributions are summarized as follows: We (1) apply a single synthetic data generation method to different language pairs, including low-resource languages such as Tamil, based on a sin-gle dataset and thereby eliminate differences that emerge from the discrepancies in data generation methodology, (2) release a new code-switching dataset, CoVoSwitch, with similar code-switching levels across 13 languages, and (3) compare trans-"}, {"title": "2.2 Alignment Extraction and Intonation Unit Replacement", "content": "We obtain word alignments between English and non-English text from CoVoST 2 using an aligner following previous research (Rizvi et al., 2021; Winata et al., 2019; Pratapa et al., 2018), but replace fast_align (Dyer et al., 2013), a reparametrization of IBM Model 2, with a neural aligner, awesome-align\u2074 (Dou and Neubig, 2021), because it outperforms fast_align in alignment error rate. This aligner supports all target languages covered in this work as it is a fine-tuned aligner from mBERT (Devlin et al., 2019).\nWe pick the number of intonation units to re-place, r, from 1 to number of English intonation units - 1 for each English sentence. For each r, we randomly select a combination of r intonation unit indices, but nonconsecutive IU indices, if they exist, are prioritized over consecutive ones to rep-resent more active code-switching. For each of the tokens in each replacement intonation unit selected, we find corresponding non-English tokens using word alignments. When replacing English tokens with non-English tokens, we preserve the original order in non-English languages. If no tokens are mapped by the aligner, empty strings are appended to the code-switched text, following previous work (Pratapa et al., 2018). For tokens that are not in the intonation units selected for replacement, English"}, {"title": "2.3 Dataset Evaluation and Analysis", "content": "To evaluate our synthetic dataset, we report two automatic metrics, Code Mixing Index (CMI) and Switch Point Fraction (SPF). These metrics can be computed at either the utterance or corpus level, but we report at the corpus level to facilitate parallel understanding across languages.\nCMI, first proposed by (Das and Gamb\u00e4ck, 2014), measures the level of code-switching in a text. We follow the definition of (Mondal et al., 2022) and report CMI as follows. For a code-switching sentence comprised of \u03b7 tokens, with 71 and 72 tokens in each language and \u03b7 = 71 + 72, CMI is defined as 1 - max(71,72). We adhere to pre-vious convention and multiply this number by 100.\nSPF was proposed by (Pratapa et al., 2018) and measures the rate at which code-switching points occur in the code-switched text. SPF is defined as \u03a3\u03b7-2i=0 S(i,i+1)/\u03b7-1 where S(i, i + 1) is an indicator variable that is equal to 1 if the tokens of indices i and i + 1 belong to different languages and else 0."}, {"title": "3 Machine Translation Experimental Setup", "content": "Models. We use the HuggingFace pre-trained model checkpoints facebook/m2m100_418M and facebook/nllb-200-distilled-600M for the M2M-100 418M and NLLB-200 600M models. These two models were chosen for their excep-tional multilingual capabilities, with M2M-100 intended for non-English centric translation and NLLB-200 designed to improve translation perfor-mance in low-resource languages. Both support all languages covered by our synthetic dataset.\nTranslation Settings. We experiment with four translation settings for each of the English and non-English language pairs. First is csw\u2192En, in which code-switched text is translated into English. This setting was examined in previous research (Nguyen et al., 2023; Xu and Yvon, 2021), but we also ex-periment with csw\u2192X to analyze any performance gaps that may arise by setting target language for translation differently. We compare these two code-switching translation settings to two monolingual translation settings, X\u2192En and En\u2192X, where X is a non-English language and En is English.\nBaselines. Our baselines are twofold. First, we compare code-switching translations with monolin-gual translations and interpret deltas from monolin-gual baselines as the gains or losses from introduc-ing code-switching units. We set our second base-line in consideration of our synthetic code-switched inputs. Because synthetic code-switched inputs al-ready contain segments from reference texts, eval-uation scores for these may be higher than trans-lations of solely monolingual texts. In light of"}, {"title": "4 Results and Discussion", "content": "Results are shown in Table 4."}, {"title": "4.1 Code-Switched Inputs Relative to Monolingual Translations", "content": "Inspection of sp-BLEU in the to English setting reveals that 12 out of 13 synthetic code-switched inputs score higher than M2M-100 translation outputs when evaluated against reference English texts. For NLLB-200, however, only 5 code-switched inputs score higher than monolingual translations. In contrast, in the to non-English setting, raw inputs score higher than monolingual translations for 11 and 10 lan-guages. We thus reaffirm the findings of (Nguyen et al., 2023) that code-switched inputs score higher than monolingual translations but with qualifica-tions that exceptional monolingual translations by stronger models can outperform code-switched in-"}, {"title": "4.2 Deltas Relative to Monolingual Baselines", "content": "Inclusion of code-switched units results in better translation than monolingual settings. This is seen in the predominantly positive deltas across spBLEU and chrF++ in Table 5. In particular, whether the languages are low-resource or high-"}, {"title": "4.3 Deltas Relative to Code-Switched Input Baselines", "content": "Models are better in code-switching translation into English than non-English. (Goyal et al., 2022) established that multilingual translation mod-"}, {"title": "4.4 Analysis of Translations", "content": "We report copy rates in Table 8."}, {"title": "5 Conclusion", "content": "In this work, we present CoVoSwitch, a code-switching dataset created by replacing intonation units detected by PSST, a speech segmentation model fine-tuned from Whisper, on CoVoST 2, a speech-to-text translation dataset. Using CoV-oSwitch, we examine the performance of two MNMT models with millions of parameters, M2M-100 418M and NLLB-200 600M, and compare code-switching translations against monolingual translations and high-resource languages against low-resource languages. We discover that the introduction of code-switching units results in higher performing translations compared to mono-lingual settings and that models are better at code-switching translation into English than into non-English. Meanwhile, low-resource languages gain most from monolingual baselines compared to other languages in csw En but much less in csw\u2192X. Systems also exhibit poor translation abil-ities in low-resource csw X translation to the ex-tent that performance already gained from code-switched inputs is lost. Additionally, we find that models struggle to copy non-English tokens, iden-tify the off-target problem in code-switching set-tings, and confirm that models hallucinate in code-switching translation by creating words nonexistent in the original source sentences. By releasing CoV-oSwitch, we aim to support the inclusion of a wider variety of languages in code-switching research."}, {"title": "A Appendix", "content": "A.3 Hallucinations in csw\u2192X Translation\nHallucinations, as shown in the csw\u2192En setting in Figure 2, are also seen in csw\u2192X. As such, we provide a few observations of the problem in Welsh-English in Figures 4 and 5. Besides the hal-lucination of creating words noted in Figure 2, we find repetitions of the same word. Additionally, we observe that even if two different code-switching sentences share the same source sentences, transla-tion results can be significantly different, as seen in NLLB-200 outputs with one yielding repeated words with no meaning and the other translated but also including the repeated word Mae, highlighted in pink."}, {"title": "A.1 Languages in the Synthesized Dataset", "content": "We report the ISO 639-1 code, language name, fam-ily, subgrouping, script, and resource level for the 13 languages that we incorporated from CoVoST 2 in Table 12. We draw the information on language family, subgrouping, script, and resource level from (Costa-juss\u00e0 et al., 2022). (Costa-juss\u00e0 et al., 2022) indicates resource level with either high or low."}, {"title": "A.2 Statistics on Train and Validation Subsets", "content": "We include statistics on train and validation subsets of CoVoSwitch, created from the train and valida-tion subsets of COVOST 2 in Tables 10 and 11."}, {"title": "A.4 Parallel Examples of Code-Switching Sentences Generated", "content": "All code-switched texts in CoVoSwitch are made from parallel corpora in the En\u2192X subset of CoV-OST 2, and so are created using the same set of English sentences. As a result, code-switched sen-tences across languages share English fragments. We include an example from the test subset in Fig-ure 6. For some languages, we demonstrate dif-ferent intonation unit replacements than others to illustrate how resulting code-switched texts diverge based on which intonation units are selected."}]}