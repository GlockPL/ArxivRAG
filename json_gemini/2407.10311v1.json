{"title": "Sora and V-JEPA Have Not Learned The Complete Real World Model", "authors": ["Jianqiu Zhang"], "abstract": "Sora from Open Al has shown exceptional performance, yet it faces scrutiny over whether its technological prowess equates to an authentic comprehension of reality. Critics contend that it lacks a foundational grasp of the world, a deficiency V-JEPA from Meta aims to amend with its joint embedding approach. This debate is vital for steering the future direction of Artificial General Intelligence(AGI). We enrich this debate by developing a theory of productive imagination that generates a coherent world model based on Kantian philosophy. We identify three indispensable components of the coherent world model capable of genuine world understanding: representations of isolated objects, an a priori law of change across space and time, and Kantian categories. Our analysis reveals that Sora is limited because of its oversight of the a priori law of change and Kantian categories, flaws that are not rectifiable through scaling up the training. V-JEPA learns the context-dependent aspect of the a priori law of change. Yet it fails to fully comprehend Kantian categories and incorporate experience, leading us to conclude that neither system currently achieves a comprehensive world understanding. Nevertheless, each system has developed components essential to advancing an integrated Al productive imagination-understanding engine. Finally, we propose an innovative training framework for an Al productive imagination-understanding engine, centered around a joint embedding system designed to transform disordered perceptual input into a structured, coherent world model. Our philosophical analysis pinpoints critical challenges within contemporary video Al technologies and a pathway toward achieving an Al system capable of genuine world understanding, such that it can be applied for reasoning and planning in the future.", "sections": [{"title": "Introduction", "content": "OpenAl and Meta, forefront innovators in artificial intelligence, have each introduced their latest video Al technologies, Sora (OpenAI 2024) and V-JEPA (Bardes et al. 2024), targeting the ambitious goal of achieving \"real-world understanding.\" Such endeavors are not just deemed as technological valuable but also crucial towards the realization of Artificial General Intelligence (AGI), promising Al systems that can engage in sophisticated planning and reasoning by simulating physical realities with precision.\nOpenAl's Sora is heralded as a \"World Simulator,\" aiming to replicate complex real world phenomena, and it has garnered a lot of attention for its advanced ability to produce highly realistic videos from textual prompts, an achievement some researchers argue signifies a leap towards AGI (Trabert 2024). It utilizes text annotations, refined by a state-of-the-art captioning model using a technique similar to Dall.E's re-captioning approach (Betker et al. 2023). Through diffusion models, Sora learns the statistical distributions of videos, enabling video generation conditioned on specific text prompts. Nonetheless, OpenAl notes certain limitations: Sora's simulation of complex physical interactions and its grasp on cause-and-effect remain underdeveloped (OpenAl 2024).\nProminent figures in Al research, such as Yan LeCun, have voiced skepticism about equating current generative Al capabilities with AGI. LeCun argues that true understanding of the world extends beyond generating compelling video samples from text prompts (LeCun, 2024; LeCun, 2022). He advocates for a focus on \"world models\" based methods aiming to model the latent variables essential for a genuine understanding of the world . World model based video Als utilize techniques including variational auto-encoders (VAEs), transformers, and joint embedding predictive architectures (JEPA) (Ha and Schmidhuber 2018; Robine et al. 2023; Chen et al. 2022; Hafner et al. 2019; Bardes et al. 2024). Meta's newly released V-JEPA (Bardes et al. 2024) is designed to learn the correlation of video patches across space and time, which is deemed as a form of \u201ctrue\u201d understanding of the world.\nHowever, the real-world applicability of such \u201cworld model\u201d based video Als remains in exploratory stages. V-JEPA, for instance, has been trained using short video segments from a massive dataset of 2M video clips. Its performance has been accessed on tasks like action recognition and motion classification. Despite achieving satisfactory results on simpler datasets such as Kinetics400 (K400) (Kay et al. 2017) and Something-Something-v2 (SSv2) (Goyal et al. 2017), V-JEPA's performance is still poor when applied to the AVA dataset (Gu et al. 2017), which presents complex scenarios involving multiple actors and actions.\nThe rapid advancements in video Al technology, exemplified by OpenAl's Sora and Meta's V-JEPA, have brought the concept of \"real-world understanding\" into sharp focus. Discussions revolve around key questions: Can Sora's expanded training datasets address its problems and achieve genuine world understanding? Is V-JEPA's methodology a game-changing breakthrough? Could a combination of these technologies provide a comprehensive framework for modeling real-world phenomena? Establishing criteria for what constitutes a genuine \"real\" world model-identifying the critical elements it must include-is central to this discourse.\nTo tackle these complex discussions, philosophical inquiry is essential. This inquiry should clarify the nature of the data inputs and outputs, and the overarching goals of video Al technologies. Key questions include:\n\u2022 Characteristics of Perceptual Data: How do the characteristics of video clips used in Al training align with human perceptions of the world? What are the distinct features of these clips?\n\u2022 Sources of Input: What types of input are crucial for building a world model? How do these sources influence the model's development?\n\u2022 Purpose and Functionality: What are the objectives of creating a world model from this data? Is the primary function of the model to recognize objects, or does it focus on identifying abstract, non-representational variables?\n\u2022 Representation Requirements: What types of representations are necessary to support the functionalities designated for the world model?\n\u2022 Grounding to Reality: How can the world model be validated or checked against actual reality to ensure its accuracy and relevance?\n\u2022 Comparison with Human Cognition: Which aspects of human cognitive abilities are mirrored in the processes of video Al models? How do contemporary video Als stand in comparison to human cognitive structures and functionalities in terms of design and effectiveness? By comparing video Als to human cognitive processes, we can uncover both the capabilities and limitations of these technologies.\nThese questions go beyond the usual scope of technology-focused research, which typically concentrates on a limited set of specific objectives. For example, Sora is mainly designed to train a statistical model using diffusion-transformers to create video clips from textual prompts or other inputs. Yet, the broader context of perception and understanding encompasses various factors and objectives that shape the development of a world model. Thus, a philosophical examination becomes essential to address these issues comprehensively, which not only delves into the technical functionalities of Al but also explores how these technologies mirror complex human cognitive processes.\nGiven these considerations, the philosophical framework outlined by Immanuel Kant in his \"Critique of Pure Reason\"(Kant 1908) becomes relevant for our investigation into the nature of video Als in the larger context of human perception and understanding. Kant proposes that our perceptions are triggered by external stimuli that activate our sensory organs. These perceptions are inherently fragmented: we do not perceive the entire world simultaneously but rather begin with specific parts and explore others in a seemingly random time sequence. From this, Kant deduces the necessity of an internal mental process that synthesizes these scattered and disjointed inputs into a coherent, unified perception, which he calls \"the unity of the manifold of intuition,\" facilitated by what he terms the \"productive imagination\" (CPR, A123). This mental function, according to Kant, is crucial not only for the basic perception of objects but also for imparting meaning and coherence to our sensory experiences, thereby foundational to object recognition (CPR, A146).\nApplying Kant's insights to video Als provides clear answers to some of our questions. First, Kant's observation that our perceptions are fragmented is also true for video clips: they offer a disorganized view of the world from human perspectives, albeit with greater editorial freedom. In videos, scenes from different perspectives can be stitched together, but they must still adhere to logical rules. We can recognize illogical sequences when they contradict these established rules. Second, Kant's concept of \"the unity of all manifolds of intuition\" can be likened to what we describe as a \"coherent world model\" in Al systems. Drawing from this comparison, we see that the role of a coherent world model extends beyond merely sequencing time-series data. It also involves enabling Al to accurately identify objects and their relationships, which is crucial for attaining a realistic comprehension of the world. The development of such coherent world models in Al is intricately linked to the process of understanding, which entails the integration and interpretation of fragmented sensory data in a manner that reflects human cognitive functions.\nKant's exploration of productive imagination introduces four crucial categories of pure understanding recognized through schemata\u2014innate, rule-based frameworks that precede empirical experience and shape our comprehension of time, sequences of events, and the overarching concept of time as it relates to experiential phenomena (CPR, B185). For instance, within the relation category, Kant illustrates that the schema governing cause and effect posits a rule-based sequence where specific conditions reliably lead to certain outcomes (CPR, B184). This exemplifies the critical role of category in temporal event comprehension.\nKant's categories are crucial for object recognition. This is clearly illustrated in the optical illusion where one might see either two faces or a vase, depending on the perceptual interpretation. The Kantian category of \"quantity\" plays a decisive role in this cognitive process\u2014if perceived as a single object, it is seen as a vase; if seen as two, then as faces. This example highlights the significant role that Kantian interpretative frameworks play in guiding how we recognize objects.\nWhile Kant delineates these categories as fundamental a priori conditions for cognition, he stops short of claiming an exhaustive list, thereby acknowledging the potential for additional a priori conditions necessary for a nuanced understanding of time and event sequences. This opens up a rich area for philosophical debate and interpretation of Kant's theory.\nPredictive Processing (PP) is another relevant theory in cognitive science which posits that perception is constructed by the brain by testing hypotheses about the hidden causes of incoming sensory stimulation, and the hypotheses are generated by a hierarchical generative model of the world which is constantly updated based prediction errors (Rao and Ballard 1999; Friston 2003, 2005, 2008, 2010; J. Hohwy 2010; Clark 2015). Some researchers argue that this theory has conceptual ground with Kantian philosophy (Swanson 2016), particularly in its interpretation of perception forming\u2014an active process characterized by the synthesis of intuition and concepts, as opposed to a mere building up of percepts from sensory inputs (G\u0142adziejewski 2016).\nPP encompasses a range of paradigms, from unsupervised learning methods that build models of sensory inputs by learning from previously learned image patterns (Rao and Ballard 1999) to modeling sensory data as an auto-regressive process (Friston 2008). Additionally, there are supervised learning approaches that connect complex symbols to sensory data within a generative framework (Santana and Principe 2015; Principe and Chalasani 2014). Note that world model based Video Als typically align with the unsupervised paradigm of PP, including systems that adhere to unsupervised temporal predictive coding frameworks (Ha and Schmidhuber 2018; van den Oord, Li, and Vinyals 2018) and those that utilize unsupervised spatial predictive coding or a combination of both spatial and temporal approaches (Doersch, Gupta, and Efros 2015; Zhang, Isola, and Efros 2016; LeCun and Courant 2022; Bardes et al. 2024).\nThe challenges faced by PP include, firstly, its failure to recognize the problem of fragmented perceptual data. Secondly, the lack of a unified PP framework that integrates its various paradigms highlights the theory's conceptual fragmentation. Moreover, ongoing debates concerning the philosophical foundations of PP, especially its stance on representationalism, complicate its application as a comprehensive theoretical framework for analyzing video Als, as discussed in works by (G\u0142adziejewski 2016; Facchin 2021).\nTherefore, while PP presents an intriguing intersection with Kantian theory and offers additional insights to understanding video Als, its practical application in analyzing video Al technologies like Sora and V-JEPA requires more precise conceptual development given the significant unresolved issues within the PP framework, and it becomes crucial to analyze these video Al technologies using the broader concepts of a coherent world model and productive imagination that we propose.\nIn pursuing this analysis, we choose not to delve deeply into debates of Kantian philosophy or PP theory interpretation, but rather to use their foundational concepts as a springboard for proposing a modified theory of productive imagination. For historical context and a review of previous applications of Kantian philosophy in Al, readers can refer to (Schlicht 2022). To assist those unfamiliar with Kantian terminology, we clearly defined critical concepts such as \"unity of manifold of intuitions,\u201d \u201cproductive imagination,\u201d or \u201cschemata\".\nAs we revisit the initial questions about video Als, it becomes clear that while Kant's theory provides answers to some, many remain unaddressed: He elucidated the fragmented and chaotic nature of our perceptual inputs. He also identified the function of productive imagination in forming a coherent world model (the unity of manifold of intuitions), preparing it for object recognition through applying the schemata of Kantian categories. However, he left other questions unanswered. To leverage Kant's insights for the analysis of video Al technology, it is crucial to enhance his theoretical model to encompass all the important elements outlined in our list of questions.\nIn this paper, we developed a novel theory of productive imagination, applying a Kantian analytical method often referred to as \"reverse engineering\" or \"top-down\" analysis(Swanson 2016). This method critically assesses the input and output of Al systems to deduce the functionalities of their intermediate processing stages.\nOur analysis indicates that productive imagination synthesizes fragmented perceptual data with experience to develop coherent world models. This position contrasts with Kantian theory, which overlooks the role of experience in the creation of coherent models. Additionally, this perspective differs from the PP theory, which posits that perception is entirely constructed from pre-existing models.\nOur research indicates that productive imagination can handle dual input sources and function in various modes, serving diverse purposes. It can track reality, react to unrecognizable objects, simulate scenarios or generate illusions in a dreaming mode, and blend past experiences with current perceptual data to enhance understanding. In comparison, neither Kant's theory nor PP explicitly addresses the use of multiple input sources, the variety of operating modes, or the multifaceted purposes of our visual perception and understanding engine.\nEssential to this process is the correct temporal organization of objects and events within fragmented perceptual data, and the application of Kantian categories. We introduce an a priori law of change, reflecting Kant's concept of transcendental affinity (CPR, A113), which governs the changes of objects' movements, shapes, and appearances over space and time. By establishing spatial and temporal contexts and clarifying object relationships, the coherent world model represents objects and their associated events in time in a context, enabling the cognition module to recognize them and engage associated experience, which allows further refining the model.\nEchoing PP, our theory includes a reality check module, a feature not present in Kant's framework. This module uses the coherent world model to predict future scenes and then compares these predictions to actual perceptual data. Any discrepancies, likely stemming from biases in experience, lead to adjustments in the model, ensuring that it remains closely aligned with reality.\nOur analysis addresses all aspects of the inquiring questions and leads to a complete analytical framework for describing the productive imagination-understanding engine. We then extend our philosophical framework to analyze the two prominent video Al systems, Sora and V-JEPA, revealing that both systems, despite their innovative approaches, fail to address key aspects of productive imagination. Sora, operating in a \"dreaming mode,\" uses a diffusion-transformer as an experience composer, generating videos from text prompts from past experiences or creating illusions based on the prompt's realism. However, its failure to integrate Kantian categories and the a priori law of change limits its ability to organize perceptual data correctly in time, supporting LeCun's critique that generating convincing videos does not equate to genuine understanding. V-JEPA, while capturing some aspects of the a priori law of change by learning video patch correlations, also overlooks Kantian categories and lacks the capability to incorporate experience, which limits its field of application and its performance in complex scenarios.\nIn summary, while both Sora and V-JEPA lay foundational groundwork for an Al perceptual-understanding framework, neither is adequate for achieving AGI. For improvements, both systems should incorporate Kantian categories and the a priori law of change to enhance object recognition and relation understanding, integrate all three operational modes of productive imagination, and employ mechanisms to organize and utilize experience effectively, ensuring a coherent and temporally accurate world model.\nTo address the challenges, we propose a new architecture designed to fully develop an Al productive imagination-understanding engine. This architecture involves training a coherent world model encoder based on fragmented, out-of-order video clips. The goal is to ensure that the output from this encoder matches the output of an encoder trained on non-fragmented, correctly ordered video clips.\nThis paper makes contributions to the field of video Al in three key areas: 1. It provides a philosophical analysis and outlines a detailed methodology for transforming fragmented perceptual data into coherent world models and cognitive frameworks. 2.\nIt examines two leading video Al systems, demonstrating that although each captures certain elements effectively, neither succeeds in achieving a truly coherent world model; 3. It introduces a Coherent World Model Learning Architecture (CWMLA) which showcases how the training of coherent world models can be deeply rooted in philosophical principles, particularly those espoused by Kant.\nOur analysis leads to a deeper, philosophically-grounded understanding of existing video Al systems and facilitates the creation of advanced Al systems genuinely equipped for real-world comprehension, essential for effective planning and reasoning based on accurate world simulations. The findings from this research could significantly influence future Al development strategies, guiding substantial investments towards achieving breakthroughs in AGI."}, {"title": "Section 1: A Theory of Productive Imagination", "content": "Kant characterized productive imagination as a crucial intermediary faculty that bridges sensory perception and intellectual understanding. One primary function of productive imagination is to synthesize fragmented and disordered perceptual data into a coherent world model. Additionally, it is also tasked with isolating individual objects from their contexts, tracking their changes over time, and establishing their interrelationships, which are essential before they can be recognized by understanding. This process allows contingent perceptual data to be associated with specific defined concepts, forming the basis for subsequent Al actions.\nKant identified four essential categories of pure understanding necessary for constructing this coherent world model, split into two groups: the mathematical categories, which include the quantity and quality of objects, and the dynamical categories, which cover the objects' inter relationships and modalities. These categories need to be universally applied across all experiences to facilitate object recognition.\nWe argue that the Kantian categories function to separate objects from their surroundings, determine their properties, and recognize their relations and interactions with their environment for the purpose of ordering and identify the events and objects contained in the perceptual data: Segmenting perception into distinct objects allows us to evaluate their quantity (Unity, Plurality, Totality). By understanding the properties of objects, we can assess their quality (Reality, Negation, and Limitation). For example, hardness is real in solid objects, fluids have no shape, and transparency is limited by purity of materials. Understanding object modality (Possibility, Existence, Necessity) constraints the status of object existence across time under changing context. For example, it is necessary that a force is present if an object is moved. It is possible that a solid object will break into pieces if dropped, and there must exist a container if liquid doesn't flow. Finally, recognizing an object's relationships to others (Inherence and Subsistence, Causality and Dependence, Community) helps determine how dynamically changing objects are related, and establish the timeline of their interactions. For example bumping one solid object into another causes the second to move, a predator and a prey's interaction form a community. These categories collectively address the question: What are the distinct objects, their generic properties, and how can they be isolated in space and time for recognition? What might happen given the context and their own properties? How are they related to each other in time events?\nAccording to some Kantian scholars, the categories are innate in the input/output sense: \u201ceven though their acquisition may have been occasioned by sensory stimuli, its content does not derive from sensory stimuli, but it is contributed by the mind (Vanzo 2018).\u201d Given this interpretation, video Als may acquire categories through training and abstraction of existing patterns in data.\nKant explains that categories of pure understanding are recognized through schemata: \u201cThe schemata are therefore nothing but a priori time-determinations in accordance with rules, and these concern, according to the order of the categories, the time-series, the content of time, the order of time, and finally the sum total of time in regard to all possible objects. (CPR, B185).\u201d This ordering of events over time is critical for a coherent experience and is necessary for object recognition within the understanding process.\nThe determination of isolatable objects and their temporal arrangement are two intertwined goals. Without identifying discrete objects (content of time), it's impossible to establish a sequence of events (order of time); conversely, without recognizing the sequence, the content cannot be accurately determined. This suggests that understanding both aspects requires an iterative process where time content and time order are mutually informative.\nThe exploration of Kantian categories sheds light on key components required for a coherent world model that enables understanding. Notably, the proper sequencing of time is fundamental and impacts all other cognitive functions. However, the task of organizing fragmented, disordered data into a logical sequence remains a substantial challenge. In the next section, we introduce and develop the concept of an a priori law of change, crucial for establishing the correct temporal order."}, {"title": "Section 1.1.1 The Deduction of the a priori law of change", "content": "Kant posits that during the synthesis of perceptions, there exists 'a rule by which a representation is conjoined in the imagination with one representation rather than with another' (CPR, A121). He explained that \u201cthe representation of a universal condition according to which a certain manifold can be uniformly posited is called a rule, and, when it must be so posited, a law. Thus all appearances stand in thoroughgoing connection according to necessary laws, and therefore in a transcendental affinity, of which the empirical is a mere consequence.\u201c (CPR, A114). However, the concept of \"transcendental affinity\" is not comprehensively explained, and it is unclear exactly what this law entails and how an Al system could potentially learn it. The primary focus of this paper is to explore the specific contents of this law rather than delve into detailed interpretations of Kantian theories. For a thorough examination of Kant's views on this matter, please consult the detailed analyses available in the referenced works (Westphal 2005; Griffith 2012; McLear 2015).\nKant's insights indicate that the primary role of productive imagination is to construct a timeline of objects and events from fragmented perceptual data. Transcendental affinity dictates how this timeline should be structured, yet the specifics of this rule remain unclear. To better understand this rule, we can reconsider the problem from a different angle: once a timeline is formulated from disjointed perceptions, the isolation and contextualization of objects within this timeline facilitate the modeling of their visually detectable changes in movement, appearance, and shape. Essentially, in creating a timeline and isolating objects within it, models of object changes over space and time are simultaneously established. Consequently, the rule that governs the formation of timelines and time-content determination is the same rule that regulates these models of object change, evaluating the plausibility of timelines and setting constraints on the acceptable changes of objects over time. Since this rule is the basis for synthesizing fragmented perceptual data, it embodies transcendental affinity, and we refer to it as the a priori law of change over space and time, highlighting its role in governing object changes in movement, appearance, and shapes.\nThe next crucial question concerns the relationship between this law and Kantian categories, as both serve as a priori conditions for the creation of a coherent world model. Are they independent or interconnected? Does the a priori law of change override the Kantian categories? Our analysis suggests that while the a priori law of change complements Kantian categories, it remains distinct from them. On one hand, the properties of objects influence how the a priori law of change is applied; on the other, this law itself helps define certain Kantian categories. This interplay indicates that while they are interrelated, each maintains its unique influence within the framework of constructing a coherent world model.\nFor example, a rigid object retains its shape, whereas a pliable one may deform, thus necessitating different applications of the a priori law based on the material properties, a factor within the Kantian category of quality. Conversely, Kantian categories can sometimes be derived from this law, as shown in the infant number-tracking experiment conducted by Xu and Carey in (1996). In this study, a column and a ball behind a screen were pushed out and shown one by one before returning behind the screen. The a priori law of change dictates that the column cannot suddenly transform into a ball behind the screen, leading infants in the experiment to infer the presence of two distinct objects. This illustrates how the a priori law can guide the understanding of the Kantian category of quantity.\nThe a priori law of change is also context-dependent, reflecting Kant's category of modality, where the possibilities and necessities of events are shaped by the interactions between objects and their surroundings. For instance, a solid object will drop in mid-air is a necessary outcome within that context. Conversely, the shattering of a glass when it hits a hard surface represents a contextual possibility. Yet, invariant object properties like color do not influence this law of change, indicating the clear distinction between the categories and the law."}, {"title": "Section 1.1.2 Coherent world model and experience", "content": "Kant did not explicitly address how experience is integrated into the \"unity of manifold of intuition.\" Nevertheless, this integration is readily apparent: observing the front of a house naturally leads us to infer its backside. Our perceptions and accumulated experiences converge to form a unified mental model, an integration that hinges on our experience and current perceptual data. The extent of this integration varies with our familiarity with the objects in a scene. At one extreme, lacking prior experience, productive imagination must rely solely on perceptual input to construct a coherent world model. At the other extreme, even in the absence of perceptual data, we can envisage a world drawn from our well of experience.\nConsequently, we conclude that productive imagination draws from two input sources: fragmented perceptual input and experience. With different configuration of inputs, it can operate in three distinct modes: 1. Reality tracking mode, in situations devoid of experience, 2. Dreaming mode, where imagination is based solely on past experiences without new sensory input, and 3. Mixing mode, where both perceptual data and experience inform the construction of the world model.\nNone of the three modes of productive imagination is purely passive that only respond to incoming sensory information; each requires the active participation of the mind. For example, even in reality tracking mode, the mind actively engages the a priori law of change and Kantian categories to synthesize information.\nRegarding the structure of experience, it can be categorized into three types: reproductive, compositional, or a combination of both. Reproductive experience is derived directly from memory. In contrast, compositional experience is formed from conscious or unconscious thoughts. The nature of compositional experience can range from realistic to illusionary, depending on the rationality of the thoughts that initiate the composition process. In the context of artificial intelligence, this compositional process is akin to the function of the diffusion-transformer in Sora which produces video clips based on \u201cthoughts\u201d in the form of text prompts. In the following discussion, we refer to all types of experience without differentiating the subtypes.\nIn summary, the coherent world model encompasses latent variables of at least three key aspects: those associated with isolated objects, those detailing object changes across space and time constrained by the a priori law of change and experience, and those pertaining to Kantian categories. In future sections, we will evaluate the completeness of various video Al world models based on these aspects."}, {"title": "Section 1.2. Anchoring of productive imagination to reality", "content": "In the preceding discussion, we've delineated that productive imagination must synthesize fragmented perceptual data and experience to construct a coherent world model. However, to ensure that such a model does not diverge into fantasy all the time, there must be a process that grounds it in reality.\nThe validation of the coherent world model against reality can only occur through comparison with new, incoming perceptual data because the current model is derived from previous perceptual data and experience. Consequently, for the reality check, the current model must align its prediction with fresh perceptual input. When there's a strong correspondence, the model can be considered accurate.\nThis process entails a balance between experience and perceptual data: The outcome of this reality check influences the weight placed on experience. A discrepancy would necessitate a greater reliance on current perceptual data, minimizing potential biases inherent in experience.\nOur understanding of how productive imagination is grounded to reality resonates with the PP theory, which asserts that \u201cThe sensory input to the brain does not shape perception directly: sensory input is better and more perplexingly characterized as feedback to the queries issued by the brain\" (Jakob Hohwy 2013) . In other words, the current perceptual data is used as a comparison to the model that PP constructs such that it can adjust its model to fit the reality. While both PP and our perspective endorse the use of world model predictions for reality checking, our theory uniquely focuses on calibrating the balance between perceptual data (formed directly from sensory stimuli) and experience, whereas PP aims to refine the model to better fit the sensory inputs to form perception.\nGiven different degrees of adherence to reality that is permissible in our theory of productive imagination, it's crucial to distinguish between the predictive and the dreaming mode. Prediction is specifically aimed at reality testing, whereas dreaming serves no such purpose. Predictions are made when productive imagination integrates current perceptual data into the coherent world model, necessitating a immediate-future focus for reality checks. Dreaming, in contrast, leans heavily on experience when perceptual data is absent. An extended forecast into the future resembles a dream more than an immediate prediction. Between these extremes lies a spectrum where prediction and dreaming intermingle."}, {"title": "Section 1.3: The productive imagination-understanding engine", "content": "In the previous two sections, specific aspects of productive imagination are addressed. This section takes a holistic view of the entire productive imagination-understanding engine. Kant suggested that the process from sensory stimuli to understanding progresses linearly, starting with sensory intuition (perception), progressing through imagination (for forming coherent world models), and culminating in apperception (for recognizing objects). However, for the coherent world model's predictions to be validated against new perceptual data\u2014a process defined as the reality check-recognition of objects must already be in place. Without this recognition, it is not possible to utilize experience about identified objects or correct cognitive mistakes. Therefore, an iterative loop that integrates productive imagination with understanding is essential: Initially, fragmented perceptual data and/or experience are used to create a coherent world model. This model facilitates object recognition, which then allows the integration of associated experience and new perceptual data to refine the model during the reality check. This cycle of model updating and reality checking is repeated with each new iteration.\nThe a priori law of change offers a foundational framework of physical laws, abstracted from specific object details, which enables the productive imagination to transform disordered perceptual input into a structured, coherent world model. Knowledge of specific objects, gained through experience, subsequently enriches this model after recognition has taken place. This integration of general physical laws with experience introduces both objective and subjective elements into the world model, with the latter prone to biases and inaccuracies. Consequently, a reality check is essential to keep the productive imagination anchored in reality. Without such verification, the cognitive process risks drifting into ungrounded, dream-like illusions."}, {"title": "Section 2: A diagnosis analysis of Sora's world model", "content": "Recently released by OpenAl", "world simulator\" in OpenAl's technical documentation (OpenAl 2024).\nThis analysis does not intend to delve into the intricate technical details of Sora's implementation as discussed by Liu et al. (Liu et al. 2024), instead, we offer a high-level overview to assess its structure and identify any limitations. Sora leverages diffusion models and is trained on video clips that are annotated with text. These annotations are produced by a sophisticated captioning model that is trained using a re-captioning technique similar to that employed in Dall.E (Ramesh et al. 2022), which generates Descriptive Synthetic Captions (DSC), providing detailed descriptions that include not only the main subjects but also background elements and detailed attributes of each object.\nOpenAl's technical documentation provides an overview of the Sora framework, which includes a front-end video compression network that condenses video clips into latent variables (Kingma and Welling 2013; Rombach et al. 2022). These latent variables are then broken down into space-time patches, which are utilized as input tokens for transformers. Sora employs a novel diffusion transformer approach (Peebles and Xie 2023), replacing the conventional U-Net architecture with transformers to effectively capture the distribution of input images conditioned on text captions.\nThese latent variables, which represent the non-coherent world model, are then converted into space-time patches, which are processed by a diffusion-transformer, a deep neural network designed to capture the probability distributions of the patches based on the text descriptions accompanying them. If we compare the function of the diffusion-transformer with components that interact with productive imagination in Figure 1, it can be elucidated that the diffusion-transformer is equivalent to a repository of experience in function. When prompted with text, it composes and generates space-time patch samples from the video clips' conditional distribution that align with the text description.\nTo train a genuine coherent world model, the input to the diffusion-transformer should include all outputs of productive imagination and cognition including latent variables representing coherent world models such as the Kantian categories and the associated experience of the recognized objects. However, comparing Figures 1 and 2 in terms of the list of elements, it is evident that while some Kantian categories may have been incorporated into the DSCs, there is a lack of systematic incorporation of all Kantian categories. Other coherent world model latent variables and genuine experience are also absent from the training process.\nUpon completion of training, the Sora system is capable of generating 60-second video clips that appear realistic sometimes.\nSora demonstrated composing capability in creating non-realistic objects and scenes from text prompts. It implies that Sora has learned distinct latent variables representing individual objects, allowing it to creatively combine elements, such as generating a hybrid creature from a giraffe and a flamingo (donalleniii 2024). Sora's composability suggests that latent parameters related to individual objects have been captured, based on which non-existent creatures become possible.\nHowever, Sora-generated videos also exhibit significant flaws. By comparing the video generation process illustrated in Figure 3 with the productive imagination-understanding engine in Figure 1, it's evident that Sora operates similarly to the dreaming mode of productive imagination-relying solely on text prompts and associated experience to compose scenes, without real-world perceptual data to anchor its outputs in reality.\nSince Sora does not construct a coherent world model during its training, the experience it gathers is deficient in temporal ordering. Additionally, free composition in the dreaming mode often results in deviations from physical laws due to a lack of constraint from the a priori law of change and Kantian categories . These shortcomings manifest as several identifiable flaws in the videos it generates": "nFragmented Perception: The generated videos assemble fragmented perceptual data not unified in a coherent world model.\nInconsistency in Kantian Categories: Since Kantian categories were not integrated into the Descriptive Synthetic Captions (DSCs) or any other aspect of training", "Laws": "The a priori law of change is not learned during training", "Sense": "The lack of genuine experience based on correct time ordering can result in scenes that do not adhere to common sense.\nThese deficiencies align with observations from Sora's output. For instance, in a video from the Sora technical report (OpenAl 2024), a glass is depicted as lifting off from a desk, changing shape, and spilling its contents before touching down again, which showcases errors in physical representation, sequence timing, and causality. Such errors indicate that the training process did not incorporate necessary constraints on object change over time, nor did it correctly sequence events, reflecting a fundamental misunderstanding of basic physical and causal relationships.\nIn summary, Sora generates a non-coherent world model based on pseudo-experience that lacks appropriate time-ordering and consequently the understanding of physical laws during its training process. Sora operates predominantly in what can be described as the dreaming mode"}]}