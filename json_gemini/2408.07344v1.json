{"title": "RTAT: A Robust Two-stage Association Tracker for Multi-Object Tracking", "authors": ["Song Guo", "Rujie Liu", "Narishige Abe"], "abstract": "Data association is an essential part in the tracking-by-detection based Multi-Object Tracking (MOT). Most trackers focus on how to design a better data association strategy to improve the tracking performance. The rule-based handcrafted association methods are simple and highly efficient but lack generalization capability to deal with complex scenes. While the learnt association methods can learn high-order contextual information to deal with complex scenes, but they have the limitations of higher complexity and cost. To address these limitations, we propose a Robust Two-stage Association Tracker, named RTAT. The first-stage association is performed between tracklets and detections to generate tracklets with high purity, and the second-stage association is performed between tracklets to form complete trajectories. For the first-stage association, we use a simple data association strategy to generate tracklets with high purity by setting a low threshold for the matching cost in the assignment process. We conduct the tracklet association in the second-stage based on the framework of message-passing GNN. Our method models the tracklet association as a series of edge classification problem in hierarchical graphs, which can recursively merge short tracklets into longer ones. Our tracker RTAT ranks first on the test set of MOT17 and MOT20 benchmarks in most of the main MOT metrics: HOTA, IDF1, and AssA. We achieve 67.2 HOTA, 84.7 IDF1, and 69.7 AssA on MOT17, and 66.2 HOTA, 82.5 IDF1, and 68.2 AssA on MOT20.", "sections": [{"title": "Introduction", "content": "Multi-Object Tracking (MOT) aims to detect and identify all the objects, and ideally to form one complete trajectory for each object in a video. It is an essential technology for various applications, such as intelligent surveillance, autonomous driving, and robotics. Tracking-by-Detection (TbD) is currently the most effective paradigm for MOT, which contains two steps: object detection and data association. Most trackers focus on how to design a better data association strategy to enhance the tracking performance. Various strategies have been proposed and they broadly fall into two categories: handcrafted association and learnt association."}, {"title": "Related works", "content": null}, {"title": "Handcrafted association", "content": "The handcrafted association methods match the detections to the tracklets based on well-designed cost matrix by leveraging various strategies. Intersection over union (IoU) and appearance distance are the most commonly used metrics to construct the cost matrix. Motion model is adopted to predict the locations of tracklets to calculate the IoU distance with the detections, while person Re-identification (ReID) model is used to extract the appearance features to calculate the appearance distance. Generally, IoU distance is more useful in short-term matching, while appearance information is more accurate in long-term matching.\nThere are four main research directions in the handcrafted association methods. (1) Learn more accurate motion models: Kalman filter (KF) and its variants, camera motion compensation (CMC) etc. (2) Extract more discriminative ReID feature: independent ReID model, occlusion-aware ReID feature, dynamic ReID feature etc. (3) Design more sophisticated strategy to construct the cost matrix: different combination of the IoU and appearance distance, such as weighted sum, minimum cost etc. (4) Develop better matching strategy: single matching, cascade matching, etc. Many researchers have invested a great deal of time and effort in designing a better data association strategy. However, it is hard and exhausting to design a generic data association that can deal with various scenes. Therefore, we turn to use a simple association method to obtain tracklets with high purity, and further merge them by using tracklet association."}, {"title": "Graph-based association", "content": "Graph-based methods perform data association on constructed graphs, where nodes represent detections and edges indicate linkage between them. The data association is formulated as a graph optimization problem, which is solved by different algorithms, such as network flows, k-shortest paths, minimum cost lifted multicut, lifted disjoint paths, etc. Recently, GNN is introduced as an extension of neural networks that can operate on graph. GNN can extract high-order contextual information by adopting a message passing mechanism, which propagates the information encoded in the features of neighboring nodes and edges across the graph. MPNTrack designs a tracker based on Message Passing Network to learn features for nodes and edges and treats the data association as an edge classification task. SUSHI proposes a unified tracker for short and long-term tracking by using a hierarchy of message passing GNNs. SGT employs GNNs to recover the missed detections to enhance the tracking performance for online graph tracker.\nIn contrast to handcrafted association, graph-based association methods seek for global optimization over longer range frames. Specially, GNN-based methods can"}, {"title": "Tracklet association", "content": "Tracklet association has drawn much attention in TbD based MOT. Several methods exploit the idea of multi-level association, which first generates short tracklets in adjacent frames and then merges them into trajectories by tracklet association. Some works follow the split-merge pipeline to refine the tracking results of existing trackers, and tracklet association is employed in the merging process. TAT employs a Multi-Layer Perceptron (MLP) to link detections in adjacent frames to generate short tracklets, and then trains a network flow to associate the tracklets into trajectories. ReMOT splits tracklets by using appearance and motion features, and then associates the tracklets by hierarchical clustering on a designed distance matrix.  proposes a tracklet booster for existing trackers, which trains a Splitter to split tracklets into small pieces, and then learns a Connector to merge the tracklet pieces that are from the same identity. These methods generate short tracklets either in a sliding window with limited size or by splitting existing tracklets into small pieces. The generated tracklets are often too short, which will increase the burden for the following tracklet association. Furthermore, performing tracklet association by using the message-passing GNN has not been fully exploited in these methods."}, {"title": "Methodology", "content": null}, {"title": "Motivation", "content": "The motivation of our Robust Two-stage Association Tracker (RTAT) is simple and effective. It is hard and exhausting to design a generic data association strategy that can handle various scenes by explicitly leveraging simple cues, while learnt association methods have the limitations of higher complexity and cost, although they can learn high-order information to deal with more complex scenes. Therefore, we propose to use simple cues to generate clean tracklet pieces, and then employ GNN for tracklet association to obtain the final trajectories. RTAT consists of two-stage associations, where the first-stage association is performed between tracklets and detections to generate tracklets with high purity, and the second-stage association is performed between tracklets to obtain complete trajectories. The workflow of RTAT is shown in Fig. 1. We will describe the details of our method in the following sections."}, {"title": "Method formulation", "content": "Given a video sequence with K frames and a set of detections \\(D = \\{d_i, i \\in [1, M]\\}\\), where M is the total number of detections obtained from the K frames. Each detection \\(d_i\\) can be represented by its bounding box coordinates, image region, and timestamp. Let us define the set of tracklets as \\(T = \\{t_j, j \\in [1, N]\\}\\), where N is the number of tracklets in the video sequence. Each tracklet consists of a set of detections \\(t_j = \\{d_i, i \\in [1, n_j]\\}\\), where \\(n_j\\) is the number of detections in the tracklet of \\(t_j\\). The aim of our first-stage association is to generate the initial set of tracklets \\(T\\).\nIn the task of tracklet association, we construct an undirected graph \\(G = (V, E)\\), where nodes represent the tracklets (e.g., \\(V = T\\)) and edges indicate the connections between them. The set of edges can be denoted as \\(E = \\{e_{ij} = (t_i, t_j) \\in N \\times N, i \\neq j\\}\\), where \\(e_{ij}\\) represents the linkage of a pair of tracklets \\((t_i, t_j)\\). We introduce a binary variable \\(y_{e_{ij}}\\) to indicate whether \\(t_i\\) and \\(t_j\\) are from the same identity. Specifically, if they are from the same identity \\(y_{e_{ij}} = 1\\) and the edge \\(e_{ij}\\) is active, otherwise it is inactive. We perform edge classification to predict the values of each edge based on the learnt edge feature and merge the tracklets belong to the same identity, i.e., nodes are linked by active edge. Different from other graph-based association methods which take detections in a short video clip with limited number of frames as input, we take all the tracklets in a video as input to obtain the final trajectories."}, {"title": "First-stage: tracklet generation", "content": "The aim of the first-stage association is to generate tracklets with high purity. Any tracker can be used in this stage, but we prefer trackers with simple data association strategy, such as ByteTrack, BoT-SORT. The matching is usually done by bipartite matching, which is solved by Hungarian algorithm. In the assignment process, we set a cost threshold \\(\\theta_c\\) for possible matching and reject the matchings with higher cost than \\(\\theta_c\\). For simplification, we normalize the value of the cost in cost matrix to be [0, 1] for different tracker. By setting a lower cost threshold \\(\\theta_c\\), we can obtain tracklets with higher purity. Consequently, there are less identity switches in each tracklet, but the number of tracklet fragments will increase. We will focus on solving the fragmentation problem in the next stage by using tracklets association."}, {"title": "Second-stage: tracklet association", "content": "The aim of the second-stage association is to merge the tracklet pieces into trajectories. We perform the tracklet association based on the framework of message-passing GNN. Our method models the tracklet merging as a series of edge classification problem in hierarchical graphs, which can recursively merge short tracklets into longer ones. We use the message passing mechanism to update the feature vectors for nodes and edges across the graph and the edge classification is performed based on the final edge feature. This process is performed hierarchically for graph in each level and the workflow of each level contains four main steps:\nGraph construction. We construct an undirected graph \\(G = (V, E)\\), where each node represents a tracklet and each edge indicates the possible connection for a pair of tracklets. Compared to detection association, the number of nodes is largely reduced for tracklet association. However, the number of edges is still very large if all the connections between each pair of nodes are considered. Moreover, it will cause a severe label imbalance between active and inactive edges. Therefore, we only consider the edge between a pair of nodes that have no temporal overlap. We further limit the number of edges for each node to be K, which are selected by its top K nearest neighbors according to the similarity measures of appearance, motion, and spatial position. Hence, we construct a sparse graph with limited number of edges, which can reduce the computational complexity, and alleviate the edge label imbalance problem.\nGraph initialization. The node feature vector is initialized by the feature of its corresponding tracklet. We first extract appearance features for all the detections in each tracklet, and then calculate their average feature as the tracklet feature. The averaged tracklet feature is more robust to motion blur, partial occlusion, and illumination change than single detection appearance feature. The tracklet feature is fed into a node encoder \\(E_{nnc}\\), whose output is used to initialize its corresponding node feature."}, {"title": null, "content": "The edge feature vector is initialized with the output of an MLP, the input of which is a concatenated vector of the association features from two connected tracklets. We adopt spatial and temporal distance, appearance and motion information to construct the initial feature vector, which is an extension of MPNTrack and SUSHI.\nFor a pair of tracklets \\(T_a\\) and \\(T_b\\) with their detection box coordinates and timestamps, which can be described as \\(T_a = \\{(x_i, y_i, w_i, h_i, t_i), i \\in [a_1, a_n]\\}\\) and \\(T_b = \\{(x_j, y_j, w_j, h_j, t_j), j\\in [b_1, b_n]\\}\\), where \\([a_1, a_n]\\) and \\([b_1, b_n]\\) are the frame range of \\(T_a\\) and \\(T_b\\) respectively. Assuming that \\(T_a\\) ends before \\(T_b\\) starts, so we have \\(t_{a_n} < t_{b_1}\\). We use their closest detection boxes to compute the relative spatial distance and scale difference, which is formulated as:\n\\(\\frac{\\sqrt{2(x_j-x_i)^2 + 2(y_j-y_i)^2}}{w_j+w_i}, \\frac{\\sqrt{2(y_j-y_i)^2}}{h_j+h_i}, log\\frac{w_j}{w_i}, log \\frac{h_j}{h_i}\\)  (1)\nwhere \\(i = a_n\\) and \\(j = b_1\\). Supposing the FPS (Frames Per Second) of the given video is fps, we calculate their time difference by the formula: \\((t_{b_1} - t_{a_n})/fps\\).\nTo encode the appearance information, we use the Euclidean distance of the tracklets feature and the average cosine similarity of the top L closest detections for each pair of tracklets, which can be formulated as:\n\\( [||app_a^{avg}-app_b^{avg}||,\\frac{1}{L}\\sum_{l=1}^{L}cos(app_a^l, app_b^l)]\\) (2)\nwhere the first distance encodes global appearance discrepancy between two tracklets, and the second similarity describes local appearance similarity, which is helpful to remove the influence of large appearance variations inside a tracklet, such as large pose, long-time occlusion, and etc.\nThe tracklets belong to the same trajectory are expected to satisfy motion consistency, so we add the motion information into the edge feature. For a pair of tracklets \\(T_a\\) and \\(T_b\\), we calculate their middle frame \\(t_{mid} = t_{a_n} + (t_{b_1} - t_{a_n})/2\\), and predict their box positions at this frame using KF, which are respectively denoted as \\(pred\\_box_a^{tmid}\\) and \\(pred\\_box_b^{tmid}\\). We adopt the Generalized Intersection over Union (GIOU) score of these two estimated boxes to measure their motion consistency:\n\\(GIOU(pred\\_box_a^{tmid}, pred\\_box_b^{tmid})\\)\nFinally, the concatenation of these feature vectors, the dimension of which is 8, is fed into an edge encoder \\(E_{enc}\\) to obtain the initial edge feature.\nGraph update. We employ the message-passing mechanism to update the features for nodes and edges. During each step of message-passing, every node and edge aggregates their received information, and then combine the incoming information with their own to update their feature vectors. Specifically, for the construct graph \\(G = (V, E)\\), we obtain the initial feature vector \\(f_i^0\\) and \\(f_{(i,j)}^0\\) for each node \\(i \\in V\\) and each edge \\((i, j) \\in E\\) from the graph initialization step. The mechanism of message-passing is to propagate messages between neighboring nodes and edges across the graph. The propagation is performed by alternately updating the features of"}, {"title": null, "content": "edges and nodes, which is divided into two steps: update edge feature using neighboring nodes and update node feature using neighboring edges. Both updates are sequentially performed for L iterations. For each iteration \\(l \\in [1, L]\\), the edges and nodes features are updated as follows:\n\\(f_{(i,j)}^l = U_e([f_{(i,j)}^{l-1}, \\phi_e^l]), \\phi_e^l = \\phi_n([f_i^{l-1}, f_j^{l-1}])\\) (3)\nwhere \\(U_e\\) and \\(U_n\\) are MLP networks that aggregate information from neighboring nodes and edges. \\(N_i\\) is the set of nodes adjacent to node i, and \\(\\phi\\) denotes an order-invariant operation, e.g., maximum, summation or average. After L iterations, we obtain the final node and edge features, which contain high-order contextual information from neighboring nodes and edges in a distance of L along the graph.\nEdge classification. We use an MLP with sigmoid function as the edge classifier \\(C_{class}\\) and then perform edges classification based on their final features \\(f_{(i,j)}^L\\).\n\\(y_{(i,j)} = C_{class} (f_{(i,j)}^L), (i,j) \\in E\\) (4)\nwhere the predicted edge score \\(Y_{(i,j)} \\in (0, 1)\\). The scores are further rounded to binary values using the exact rounding solution described in . The edges are classified as active or inactive, and the tracklets linked by the active edges are merged into longer ones. We update the set of tracklets and hierarchically perform the four steps, i.e., graph construction, graph initialization, graph update and edge classification.\nData augmentation. In this stage, a training sample consists of a video sequence and a set of tracklets. There are very few training samples in MOT17 and MOT20 , which are 7 and 4 respectively. Therefore, we introduce data augmentations from both video-level and tracklet-level to train the GNN networks with higher robustness and generality. In video-level augmentation, we generate more video clips from the original video sequences. We sample a video clip in every 50 frames (i.e., start points), and the start frame is randomly selected with a fluctuation of 15 frames at each start point. The length of a video clip is randomly selected from 25% to 100% of the length for the whole video. In tracklet-level augmentation, we generate more sets of tracklets by adopting different data association strategies under different cost thresholds in Section 3.3.\nTraining GNN. We use the same GNN architectures for graphs in different hierarchical levels. Since the aims of all hierarchical levels are the same, which is to merge tracklets that belong to the same identity into longer ones, we also share the parameters for all hierarchical levels. The difference among different levels is the lengths and numbers of tracklets, so we learn a level adapter which is added to edge feature in each level of GNN. The level adapter will help the GNN model to learn the most important cues for each level in a data-driven manner. We adopt the focal loss to train the edge classifier in each level and the loss is a summation of the losses in all levels."}, {"title": "Experiments", "content": null}, {"title": "Experimental Settings", "content": "Datasets. We conduct our experiments on two of the most popular MOT benchmarks: MOT17 and MOT20, under the \u201cprivate detection\" protocol. MOT17 contains 14 video sequences which are filmed under a variety of conditions, such as different camera motions, viewpoints, and weather conditions. MOT20 contains 8 video sequences in very crowded scenes.\nMetrics. Our method focuses on robust data association, so we adopt HOTA and IDF1 as the main metrics. We also use the metrics MOTA, AssA, and IDs to provide comparisons from more perspectives. HOTA maintains a good balance between the accuracy of object detection and association. IDF1 measures the identity preservation ability and focus more on the association ability. AssA is used to evaluate the association performance, while MOTA focuses on the detection performance.\nWe introduce a new metric, named High Purity Rate (HPR), to measure the rate of high purity tracklets in a video sequence. A tracklet has high purity if more than 80% of its detections are from the same identity. HPR is the rate of high purity tracklets in all the tracklets for a given video."}, {"title": "Ablation Studies", "content": "We perform 3-fold cross-validation on the MOT17 training set for ablation studies following the experimental setup in  and use IDF1 as the primary metric. We study three main aspects of our method in this section. 1) How to select the proper cost threshold \\(\\theta_c\\) to obtain tracklets with high purity. 2) How different training strategies affect the tracklet-association performance. 3) The effect of using different data association methods to generate tracklets in the first-stage.\nObtain tracklets with high purity. We select BoT-SORT-ReID to generate tracklets for analysis in this experiment. We set a cost threshold \\(\\theta_c\\) to reject the matchings that have higher cost in the assignment process. Obviously, lower cost threshold can obtain more tracklets with higher purity. However, it is meaningless if we set a very small threshold, such as 0, where each detection is a tracklet with 100% purity. We need to keep a balance between the number of tracklets and the high purity rate (HPR). We list the tracking performance in the first-stage and second-stage with different cost threshold in Table 1. The number of tracklets in the ground-truth is also list for comparison. In the first-stage association, the number of tracklets and HPR constantly increase as we decrease the matching cost threshold, while the IDF1 score decreases slightly when the \\(\\theta_c \\geq 0.2\\). We perform tracklet association based on the tracklets generated in the first-stage, the IDF1 score has increased after the second-stage association under all cost thresholds, even when the \\(\\theta_c = 0.7\\) which is the default setting in BoT-SORT. The best result is achieved when the \\(\\theta_c = 0.2\\), which has the highest IDF1 score and the fewest ID switches. When the \\(\\theta_c = 0.1\\), the largest increasement on IDF1 (i.e., 19.2%) occurs, however its IDF1 score is lower than that of \\(\\theta_c = 0.2\\) in both stages, and it has much more tracklet (4964 versus 1693) which will bring more computational cost during inference. Therefore, we choose 0.2 as the cost threshold in our experiments."}, {"title": "Benchmarks Evaluation", "content": "We present the results of the state-of-the-art trackers on the test set of MOT17 and MOT20 benchmarks under the \u201cprivate detection\" protocol in Table 5 and Table 6, respectively. All the results are obtained from the official MOTChallenge server . We adopt ByteTrack and BoT-SORT to generate tracklets in the first-stage association, which are named RTAT-ByteTrack and RTAT-BoT-SORT, respectively. Both versions of our method outperform all the other trackers in almost all the main metrics. Our method can achieve the best performance in all association related metrics, i.e., HOTA, IDF1, and AssA, on both benchmarks, which demonstrate the effectiveness of our method for data association. For example, RTAT-BoT-SORT outperforms the tracker in second place by a large margin (i.e., +1.4 HOTA, +2.3 IDF1, and +1.9 AssA) on MOT20 benchmark.\nBoth RTAT-ByteTrack and RTAT-BoT-SORT outperform their respective baseline by a large margin on both MOT17 and MOT20. It is worth noting that RTAT-ByteTrack can achieve similar performance with RTAT-BoT-SORT in all metrics. The performance gap between ByteTrack and BoT-SORT are filled by using the tracklet associations in our method. This observation demonstrates that simple association strategy is enough to generate tracklets with high purity for the tracklet association in the second-stage, and there is no need to design more sophisticated data association strategy by investing a great deal of time and effort."}, {"title": "Conclusion", "content": "We propose a Robust Two-stage Association Tracker (RTAT), which can achieve higher association performance by utilizing the advantages of two kinds of data association methods: the simplicity and efficiency of handcrafted association methods and the effective high-order contextual information of learnt association methods. We use a simple data association method to generate tracklets with high purity in the first-stage and use message-passing GNNs to perform tracklet association in the second-stage. We further design data augmentation strategies from video-level and tracklet-level to improve the generalization ability of our tracklet association model. Ablation studies and MOT benchmarks results validate the effectiveness of our method. We hope our work is helpful to release researchers from the hard and exhausting work of designing more and more sophisticated data association strategy to obtain minor improvement in tracking performance. We also expect this work can push forward the development of multiple-object tracking."}]}