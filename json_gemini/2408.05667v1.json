{"title": "Utilizing Large Language Models to Optimize the Detection and Explainability of Phishing Websites", "authors": ["Sayak Saha Roy", "Shirin Nilizadeh"], "abstract": "In this paper, we introduce PhishLang, an open-source, lightweight Large Language Model (LLM) specifically designed for phishing website detection through contextual analysis of the website. Unlike traditional heuristic or machine learning models that rely on static features and struggle to adapt to new threats, and deep learning models that are computationally intensive, our model utilizes the advanced language processing capabilities of LLMs to learn granular features that are characteristic of phishing attacks. Furthermore, PhishLang operates with minimal data preprocessing and offers performance comparable to leading deep learning tools, while being significantly faster and less resource-intensive. Over a 3.5 months testing period, PhishLang successfully identified approximately 26K phishing URLs, many of which were undetected by popular antiphishing blocklists, thus demonstrating its potential to aid current detection measures. We also evaluate PhishLang against several realistic adversarial attacks, and develop six patches that make it very robust against such threats. Furthermore, we integrate PhishLang with GPT-3.5 Turbo to create explainable blocklisting - warnings that provide users with contextual information into different features that led to a website being marked as phishing. Finally, we have open-sourced the PhishLang framework, and developed a Chromium-based browser extension and URL scanner website, which implement explainable warnings for end-users.", "sections": [{"title": "1 INTRODUCTION", "content": "Phishing attacks have resulted in numerous data breaches and cases of credential theft, causing financial losses exceeding $52M and impacting over 300K users during the last year alone [6, 104]. These scams are largely successful due to sophisticated social engineering techniques [42] that enable the creation of websites imitating legitimate organizations. To counter these threats, researchers across industry and academia have focused on developing countermeasures that leverage unique phishing signals, such as URL characteristics, network patterns, heuristic features in source code, and advanced machine learning methods [74, 97]. A more recent focus has been on the visual aspects of phishing sites [13, 71], with several methods now using image-based content, such as screenshots, for phishing detection [11, 69]. Although these models demonstrate high detection rates in controlled environments, they often do not fare well against complex evasion techniques [23, 110]. Keeping these models up-to-date also poses significant challenges, as attackers continuously develop evasion tactics. Updating models to counter new threats often requires the creation of revised ground truth datasets and the identification of novel feature sets or strategies. Additionally, the inherent complexity and resource demands of the more recent deep learning models, especially those that depend on image content - limit their practicality for large-scale, real-time deployment [77, 90]. Furthermore, their reliance on opaque, black-box approaches complicates explainability [40], limiting opportunities for iterative improvement. To address these challenges, we have developed PhishLang, an efficient and transparent phishing detection framework that harnesses the capabilities of Large Language Models (LLMs) which are trained to comprehend the context of potential phishing websites. By evaluating these sites against known phishing patterns, our framework avoids reliance on static feature sets. Instead, it utilizes the advanced linguistic skills of LLMs to identify subtle patterns in the source code. Our model not only operates with significantly lower resource requirements-using up to three times less memory and seventeen times less storage than traditional deep learning-based phishing detection models-but also performs better than several ML-based models at detecting new attacks, especially those which contain evasive features. It is also highly resilient against realistic adversarial attacks. We also utilize our model in conjunction with GPT 3.5 Turbo [78] to build \"Explainable Blocklisting\" - an approach that provides users with contextual information on why a phishing website was blocked. This can not only help users understand and engage with the protection mechanism more effectively but also educate them on recognizing phishing attempts independently when protections are unavailable or fail. Finally, we open-source our framework, PhishLang, and also provide a Chromium-based browser extension that can proactively block threats from within the users' web browser, as well as an online scanning website, which can be used to scan new URLs on demand. The structure of the paper is as follows: Section 3 elaborates on our methodology for parsing source code to isolate critical tags associated with phishing functionality (Section 3.1). This technique significantly reduces the input data size for the Large Language Models (LLMs), enhancing both training and inference efficiency. We employ this method to develop our training ground truth from a vast collection of both phishing and benign websites from the open-source PhishPedia [69] dataset (Section 3.2). Following this, we describe our training process for LLMs using a \"sliding window\" technique that divides the parsed code into smaller chunks, optimizing the contextual information available to the model (Section 3.3), a technique that has been used to maximize LLM training efficiency [28]. To strike a balance between processing speed and detection accuracy, we evaluate various leading open-source language models to select the most effective one for our purpose (Section 3.4). To interpret the prediction capabilities of our model, we also perform a Local Interpretable Model-Agnostic Explanations (LIME) analysis [88], identifying the features that our model focuses on (Sec-tion 7.3). Section 4 details the development and implementation of our real-time phishing detection system, PhishLang, which operates on a continuous stream of live URLs from Certstream to identify new phishing threats (Section 4.1). To identify how PhishLang compares to other prevalent countermeasures, we benchmark our model's performance against traditional deep-learning-based phishing models (Section 4.2), as well as established anti-phishing tools (Section 4.3, also focusing on the detection of evasive phishing categories. We then assess the robustness of our model against adversarial phishing websites by testing sixteen realistic attacks that manipulate the website's source code and develop patches as countermeasures. 5). In Section 7, we introduce a novel \"Explainable Blocklist\" mechanism that utilizes our model in conjunction with GPT 3.5T to generate phishing warnings that include contextual explanations that can clarify why a website was flagged, thereby enhancing user comprehension of the detection process. This approach can not only bolster the credibility of phishing alerts but also deepen users' understanding of different phishing techniques. The primary contributions of our work are:\n(1) We utilized a Large Language model to build a lightweight open-source phishing detection framework - PhishLang, that can not only outperform several popular machine learning-based models, but also provide a better trade-off between inference speed, space complexity, and performance, making it more viable for real-world implementations.\n(2) Running PhishLang on a live URL stream of URLs from 28th September 2023 to January 11th, 2024, we identified 25,796 unique phishing websites. Lower coverage of these attacks by both blocklist and URL hosting providers, especially for evasive attacks, led to PhishLang reporting and successfully bringing down 74% of these threats, indicating its usefulness to the anti-phishing ecosystem.\n(3) We provide six countermeasures (patches) that make Phish-Lang very robust against highly effective and realistic adversarial attacks that make perturbations in the problem space without modifying the layout of the website.\n(4) We build a system, \"Explainable blocklisting,\" which utilizes GPT 3.5T on PhishLang's predictions to provide users with context-aware information on the features that made a website be detected as phishing.\n(5) We open-source PhishLang and make it available make it available as a browser extension (both available at https://tinyurl.com/vcjer5my) and a URL scanning website (https://freephish.org)."}, {"title": "2 RELATED WORK", "content": "Phishing detection measures: Numerous studies have explored the various techniques employed by attackers to execute phishing attacks [14, 30, 49]. Insights derived from these studies have been subsequently utilized to develop various detection measures. Scholars have introduced mechanisms for detecting phishing websites that leverage a combination of URL-based (such as Domain reputation, SSL Certification abuse, level of domain and reputation of TLD, etc.) and source code-based heuristic features (such as DOM content, presence of form fields, encoding exploits, etc.) [74, 97] as well as machine learning approaches [91]. However, several studies [76, 102] have highlighted that these models tend to overfit the features they are trained on and exhibit a lack of resilience against evasive attacks. The common factor in all these cases was the automated models were not trained on the newer features, or the features were simply not available. For a phishing attack to be successful, it is imperative that the message is effectively conveyed to the potential victim [13]. This intuition led to the development of frameworks that study the screenshot of the website [12, 100] to identify suspicious features, comparing their appearance with that of known phishing websites [56], or identifying malicious artifacts, such as brand logos [70]. While showing good performance in a controlled research environment, in practice, these models are extremely resource-intensive with respect to processing power and storage required, as well as much slower than traditional heuristic or machine learning-based phishing detection methods [75, 90]. Such limitations severely restrict their utility in real-world anti-phishing frameworks, which must process millions of URLs daily [19, 77].\nLLMs in Content Moderation: Open-source LLMs have previously shown promise as content moderation tools in diverse areas of social computing and security. For example, fine-tuned BERT models are used to identify cyberbullying instances [24] and to discern toxic triggers on Reddit platforms [31]. Demicir [37] combined LSTM and GPT-2 techniques to spot elusive malware. Several of these papers have demonstrated how LLMs can be trained on small amounts of data, with minimal data processing and without the need for defining specific features, which in turn outperform several traditional machine learning-based methods. However, utilizing LLMs to identify online scams and malicious websites has been very limited. Existing work [52, 62] have predominantly focused on using proprietary LLMs like ChatGPT [10], Claude [8], and Perplexity [9]. These models, while powerful, possess a proprietary architecture, thus preventing potential enhancements or alterations by the broader research community. Their reliance on a cost-per-use API model [78] further impedes scalability- a critical component in the fight against harmful content [95]. Moreover, Derner at al. [38] has pointed out how attackers can adversarially exploit these commercial LLMs to evade classifications, thus significantly impacting their protective capabilities. A notable exception towards utilizing LLMs for scam detection is Su et al. [99], who have attempted to use BERT to detect malicious websites, though the analysis is limited only to the URL of the website. Thus, the current state accentuates the pressing need for an efficient open-source model tailored for phishing website detection, which is also resilient against adversarial attacks.\nExplainable warnings: Security systems often use warning dialogs to convey crucial information, particularly when blocking malicious content or changes in system configurations that could affect usability [87]. However, repetitive and generic warnings provide minimal insight into actual threats, leading to user desensitization and ignored alerts [13, 64, 108]. This issue is prevalent in antiphishing systems integrated into web browsers or installed as plugins [3, 7], which typically indicate a dangerous website without explaining why it was flagged. Despite evidence that providing contextual information about threats enhances user understanding and trust [39, 73], this approach is largely unadopted in commercial antiphishing tools. This study thus explores using LLMs to automatically generate detailed contextual warnings about phishing threats. Our approach highlights specific features of a website and explains their malicious nature. By combining features detected by our local LLM model with the advanced language synthesis of GPT-3.5T, our system generates high-quality warnings that inform users about malicious features, their locations, and harmful implications, aiming to enhance user trust and understanding in a scalable manner."}, {"title": "3 METHOD", "content": "Large Language Models excel at comprehending the semantics of natural language, enabling them to detect subtle nuances and patterns in text [93, 113]. This capability is particularly beneficial for understanding complex textual data. The flexibility of LLMs extends to the realm of source code analysis as well. Researchers have effectively utilized models like BERT to analyze source code snippets, creating embeddings that capture the contextual relationships within the code [59], which have also proven useful for applications such as code completion [33]. Building on this foundation, LLMs have been adapted for malware identification [86, 109]. By training on a large repository of source code, these models can predict the characteristics of the syntax that should appear in a malicious file versus that in a benign file, detecting threats without the need for specific feature definitions or predefined rules during the training stage. We use a similar methodology for building our phishing detection model, which is capable of anticipating the necessary content (text or syntax) in a website to classify it as phishing, both at a macro level (the overall website context) and a micro level (specific code snippets). More specifically, if any part of a website's source code - or a combination thereof-resembles that of known phishing sites, it is flagged as phishing. Conversely, if it reflects the characteristics of known benign sites, it is marked as safe. We break down the various processes in our architecture below:"}, {"title": "3.1 Parsing the source code", "content": "A large part of a website's source code consists of aesthetic features, which include visual elements like layouts, colors, and styles [54] - primarily serving to enhance the user experience but are not reliable indicators for phishing detection [16]. Both legitimate and phishing websites may include high-quality designs [11] (in some cases, they might even utilize identical templates [90]). Moreover, these aesthetic components are generally unrelated to the actionable areas of a website-such as forms, input fields, buttons, and text which users interact with, and thus where phishing tactics are typically included [29]. Thus, including them in our training data not only introduces artifacts that will not be useful for phishing detection and may impact model performance but also increases the overall complexity and the time required for training the model, as the LLM needs to create more complex embeddings to map relationships between different tokens in the dataset [46].\nThus, to identify tags that will be relevant for phishing detection, we at first manually evaluated a set of 500 phishing websites from our training dataset (See Section 3.3), co-relating the source code of each website with its rendered website (as well as it's screenshot) to identify several tags which are used to include actionable phishing objects, i.e., elements in the source code that are either involved in user interactions, execute some malicious functionality or contain deceptive text. We dedicate the proceeding text to listing the chosen tags and why they are relevant: We analyze Headings (h1, h2, h3) as they are used to grab attention and may contain misleading language on phishing sites. Paragraphs (p) contain the main textual content and are often employed to convey deceptive messages. Links (a) are critical because they can redirect users to malicious sites or mimic legitimate URLs. Lists (ul, ol, li) on phishing sites might outline deceptive instructions. Form Tags (form) are used to collect sensitive data, making them a strong indicator of phishing. We also use title tags which appear on the browser tab and attackers might insert misleading titles that closely mimic legitimate sites. For example, a phishing site might use a title such as \"Secure Banking Login\" to deceive users into thinking they are accessing their bank's official website, which might give the (phishing website) credibility. We also include Footer tags as benign websites often contain more links or information in the footer compared to phishing sites [112], since the former is trying to provide resources to enhance user experience, whereas phishing attacks may provide little to no information in the footer. Script Tags (script) are utilized for various malicious purposes, including capturing keystrokes or loading phishing content. Input Tags (input) in phishing sites are designed to illicitly gather personal information. Button Tags (button) can be manipulated to execute harmful actions such as downloading malware. Iframe Tags (iframe) allow the stealthy embedding of malicious content. Meta Tags (meta) related to redirection can automatically redirect users to fraudulent sites. Anchor Tags with JavaScript (a with JS) can run malicious scripts upon clicking. Image Map Tags (map, area) are used in phishing attempts to create misleading graphics or hidden links. We use these tags to build a parser that can automatically retrieve content enclosed within these key HTML tags, and each selected element is processed to extract its textual content and specific attributes. The output from this parsing process is formatted in a structured text representation. Each element is represented by its tag type, followed by its content and relevant attributes. Even tags that do not contain any elements are preserved with <EMPTY> tag notations. This is because phishing sites frequently utilize empty  or  tags to simulate legitimacy, misleading the users. All text content in the tags is converted to lowercase since LLMs are often sensitive to case differences, which can be interpreted as different tokens. Also, the number of unique tokens that the model needs to learn is significantly reduced. To give further credence to our tag selection, we queried GPT-4 with 3,000 true positive samples from our training dataset (Section 3.2), asking it to identify tags crucial for phishing detection in these websites. Prior literature has evaluated GPT-4 as highly proficient at detecting phishing websites [27, 62], making it a suitable choice for our analysis. The model confirmed all our selected tags and additionally suggested the applet and img tags. We chose not to include the applet tag, as it is outdated and deprecated in HTML5, which is predominantly used by modern phishing websites [75]. Only 5 of the websites provided to GPT-4 and 42 in the entire dataset contained an applet tag. Similarly, we excluded the img tag because it typically contains unique image filenames or externally sourced images Our framework, based on a language model, is not equipped to process images.\nAs mentioned, our chosen tags focus on actionable areas of the webpage that cannot be removed without affecting functionality, which attackers need for their malicious intent (e.g., capturing credentials). However, in Section 5, we explore how content within these tags can be manipulated by adversarial perturbations, preventing our detection model from identifying malicious websites. We subsequently suggest countermeasures (patches) through parser modification and adversarial training in Section 5 to prevent these attacks."}, {"title": "3.2 Training data", "content": "To establish a ground-truth dataset for training our classifier, we utilized Lin at el's PhishPedia dataset [69], which includes 30K phishing and 30K benign websites. PhishPedia is not only the largest publicly available phishing dataset but is also notable for its reliability, having been used in several prior literature [48, 70]. Each entry in this dataset typically includes associated metadata, such as HTML source code, screenshots, and OCR text. The phishing URLs were originally obtained from OpenPhish [79], a widely recognized antiphishing blocklist. These URLs underwent preprocessing to eliminate inactive sites and false positives, and the researchers also implemented strategies to counteract evasive tactics like cloaking and conducted manual verifications to correct any inaccuracies in target brand representations. Conversely, the benign URLs were sourced from the Alexa Rankings list [5], a (now defunct) online database that ranked websites based on popularity. For the purposes of training our model, we only required the HTML source file, such that it can be parsed into a collection of relevant segments as previously detailed in Section 3.1. Out of the 30K phishing entries, 22,419 had an HTML file, whereas the same number for benign URLs was 26K. We further analyzed this dataset beyond targeted organizations [69], to obtain the distribution of HTML tags, libraries and frameworks used, and JavaScript APIs and function calls. Notably, phishing websites contain fewer tags than benign websites. This is because phishing websites primarily focus on capturing user credentials, whereas benign websites need to offer a wide range of functionalities, requiring a more extensive and complex HTML structure. To identify the technology stack utilized by the phishing and benign websites, we used Wappalyzer [32], a tool that uses various heuristics and pattern-matching techniques to identify the libraries and frameworks implemented in websites. It is evident from the figures that phishing websites exhibit less diversity in the frameworks used compared to benign websites. This is because phishing websites only need the frameworks necessary to carry out their attacks, while benign websites use a variety of frameworks to support the myriad of features required by their users. We also focus on the distribution of JavaScript function calls used by phishing websites by utilizing Esprima [1], an ECMAScript (JavaScript) parser that generates an Abstract Syntax Tree (AST), allowing us to identify JS function calls and categorize the usage of specific APIs. We include this illustration in Prior work [45] noted how Esprima has been reliable for this purpose.\nFinally, we are interested in identifying whether PhishLang can detect evasive phishing attacks, although our model cannot categorize the types of evasion directly. Therefore, we applied separate heuristics, derived from specific studies [20, 68, 75, 101, 106], to classify the phishing URLs in the Phishpedia dataset into five categories: i) Regular phishing attacks (18,401), ii) Behavioral JS Evasions (715), iii) Clickjacking attacks (1,726), iv) Exploiting DOM (536), and v) Text encoding attacks (1,041). Behavioral JS Evasions, as highlighted by Oest et al. [75], include JS-based redirection triggered by user interactions, mouse movement detections, and popup interactions, exploiting weaknesses in several prominent blocklists. In contrast, DOM Manipulations involve altering the HTML Document Object Model (DOM) to evade detection, such as dynamically generating phishing content, hiding malicious elements with CSS, and modifying the DOM structure post-page load. Liang et al. [68] identified features of these tactics that bypass Google's phishing page filter (GPPF), which are also transferable to other detection models. Text encoding attacks include obfuscating the character encoding, nested encoding, encoding to obfuscate JavaScript (JS), and white space obfuscation, hiding malicious code within seemingly harmless text by manipulating how the text is interpreted by different browsers."}, {"title": "3.3 Training and inference", "content": "During the training phase, we propose a sliding window approach, where each website sample, represented as parsed HTML content, is processed using this approach. The window size, W, is set to the maximum token count that the LLM can handle. However, to ensure coherence and completeness, the window is adjusted to include only complete tags. This adjustment is crucial as it prevents the misinterpretation of partial data. Each window of content inherits the label of the entire website. Despite the possibility that some sections that are benign are incorrectly assigned the phishing label due to belonging to a phishing website a window, given that the majority of the phishing websites were shorter, with most having fewer than 900 tokens (compared to benign sites having a media of 2,415 tokens), it is unlikely for a chunk not to have significant phishing features. The model is then trained on these chunks, $w_i$, defined as:\n$w_i = content[i \\times S + 1:min((i \\times S + W), T)]$\nWhere S is the step size or stride of the sliding window. It determines how much the window moves forward after each iteration, and T is the total token count of the website's content. It represents the length of the content in terms of tokens, which is used to determine the boundaries for the sliding window approach. Here i ranges from 0 to $\\lfloor (T-W)/S \\rfloor$, ensuring full coverage of the content, and each window $w_i$ is assigned the label y, corresponding to the entire website's classification (either phishing or benign). We use 70% of our ground truth data for training the model and reserve 30% for testing. The model is trained using 5-fold cross-validation, with each fold undergoing 10 epochs of training.\nThe inference process mirrors the training setup. The model analyzes the parsed content of a website by breaking it down into chunks using the same sliding window technique. Each chunk is evaluated independently for signs of phishing. If any chunk is predicted as phishing, the entire website is classified accordingly:\nWebsite Classification = $\\begin{cases}  Phishing & \\text{if } p_i = Phishing} \\\\  Benign & \\text{otherwise} \\end{cases}$\nTo counteract evasion techniques where attackers might pad websites with non-functional elements to dilute phishing content across chunks [81], a dynamic merging strategy is employed. If all chunks are initially predicted as benign, they are progressively merged and re-evaluated. This merging starts with the first two chunks, and if the combined chunk remains benign, it is further merged with the next chunk, continuing until a definitive phishing signal is detected or all chunks have been evaluated:\n$P_{merge} = Model(w_1 + w_2 + ... + w_k)$\nFinal Classification = $\\begin{cases}  Phishing & \\text{if } p_{merge} = Phishing} \\\\  Benign & \\text{otherwise} \\end{cases}$\nThe sliding window method to break down the parsed website content into multiple chunks for both training and inference is essential for several reasons. Firstly, it circumvents the token limitations of the LLM models, as most of them can process only a finite number of"}, {"title": "3.4 Choosing the optimum model", "content": "To choose the language model most suitable for building our classifier, we evaluated and compared eight language models that are considered to provide good performance in binary classification tasks (the number of parameters for the models in parenthesis): DistilBERT(66M) [92], TinyBERT(15M) [57], DeBERTA-base [51], FastText (10M) [47], and GPT-2 (117M) [85], Llama (7B), Bloom and T5. Our aim was to choose the model which provides the best tradeoff between performance, speed, and memory usage. We trained each of these models on the training split (70%) of our ground truth dataset and tested them on our test split (30%).\nThe performance of these models is illustrated in Table 2. We found Llama 2 to have the best performance out of all the models tested, with an F1 score of 0.96. However, its median inference time of 34s is impractical for real-world usage where a phishing detection tool would need to process hundreds of thousands of URLs every day, and it has the highest median memory usage at 4,873.47MB. While the other two LLMs, Bloom and T5, had lower median inference times of 7.49 and 12.40 seconds respectively, they also performed worse (F1 scores of 0.88 and 0.74, respectively) and had high memory requirements (7351.89MB for Bloom and 1,279.49MB for T5). GPT-2 had the lowest median inference time (1.81 seconds) but also had the worst performance among the LLMs (F1 0.68) and required 922.41MB of memory. Moreover, all four LLMs required inference over GPUs (while they can be used for inference using the CPU, the prediction times will be much slower), and consequently required a large amount of VRAM for said inference per sample. Requiring GPU to provide good inference time is not ideal in a practical setting, as most consumer-end devices where the inference needs to occur (such as portable/mobile systems) might not have GPUs.\nWhen considering the Small Language Models (SLMs), DistilBERT had the highest accuracy level at 0.94, with both precision and recall impressively scoring 0.94. While not the quickest, its prediction times were reasonably efficient, with a median of 0.85 seconds per prediction and a memory usage of 502.17MB. In comparison, DeBERTa-base delivered lower precision and recall also fell short in time efficiency, and had a higher memory usage of 1,341.39MB. FastText, though more compact with a memory usage of 201.88MB, suffered from reduced accuracy and median prediction times of 1.43 seconds. Meanwhile, TinyBERT, the smallest model tested, offered quicker results at 0.78 seconds but at the cost of lower performance metrics and required 495.15MB of memory. All SLMs could provide inference over CPUs.\nAlso, due to the unavailability of commercial LLMs such as ChatGPT and Claude as local implementations, fine-tuning and testing on these models would incur significant costs for training and, especially for inference, given the millions of URLs an anti-phishing tool needs to process daily. However, we compare ChatGPT (3.5 Turbo) and GPT 4 with our model, and other ML-based phishing detection tools in Section 4.\nThus, considering all eight language models, based on a combination of high precision and recall, fast prediction times, and efficient memory usage, DistilBERT was the most suitable choice for our framework and was thus chosen as the final language model for our PhishLang framework. Recent studies have also found that foundation models (and their derivatives like DistilBERT) perform well for binary classification tasks [53, 58]."}, {"title": "4 REAL-TIME FRAMEWORK", "content": "We implement our model as a framework that continuously identifies new phishing websites and reports them to various antiphishing entities, including browser protection tools, commercial blocklists, scanners, and hosting providers."}, {"title": "4.1 Identifying new URLs", "content": "We run our model on Certstream [25], a Certificate Transparency Log that streams all SSL-certified URLs. This platform is extensively utilized to detect new phishing URLs, as a vast majority of phishing sites now employ SSL certification [63]. Prior research has also frequently leveraged this data source [70, 90]. If a website is flagged as benign with low confidence (<0.5), the model investigates the first five links in the website's source to detect phishing attacks that might not be apparent on the landing page, such as hidden phishing elements or image-based links. We observed an average of 27 domains per second on Certstream, and despite occasional delays in processing due to network bottlenecks, the model provided predictions within a median time of 9 minutes. From September 28, 2023, to January 11, 2024, PhishLang scanned 42.7M domains (172M websites through links), flagging 25,796 as phishing (0.057%).\nWe detected 17,396 regular, 3,159 JavaScript evasion, 3,349 Clickjacking, 1,057 DOM, and 835 Text encoding attacks. Some evasions might not have been identified and could have been classified as regular attacks. To verify the accuracy of the model, two coders, experienced in computer security concepts, manually assessed 2.5k websites flagged as phishing, ensuring a representative sample of each attack type. They first checked if the websites impersonated any of the 409 brands identified as common phishing targets by OpenPhish in August 2022 [80], followed by examining if the sites solicited sensitive information or triggered suspicious downloads. Downloads with four or more detections on VirusTotal were deemed malicious, after taking previous findings [82]. The inter-rater reliability (Cohen's kappa) was 0.82, indicating high agreement and any disagreements were mutually resolved. Ultimately, 2,388 sites were confirmed as phishing, demonstrating the model's accuracy of approximately 94% for regular attacks and an average detection of 91% for the four evasive categories. We break down the model's performance against each type of attack in Table 3. It is evident that PhishLang is capable of detecting a range of evasive phishing attacks."}, {"title": "4.2 Comparison with other ML models", "content": "We compared the performance of PhishLang with other popular open-source ML-based phishing detection models. Two of these models rely on the visual features of the website: VisualPhishNet [11] and PhishIntention [70], one relies on both the URL string and HTML representation of the website: StackModel [67], and one that relies on the semantic representation of the URL string only: URLNet [65]. Each of these models was tested on the 5K samples, which we had labeled earlier. We also include the commercially available models of ChatGPT (GPT 3.5T and GPT 4). Since the focus of PhishLang is not only on prediction performance but also on the overhead of the models, which is crucial for practical implementation, we add two metrics - Median Artifact size, i.e., the amount of data (source code, URL, image, etc. based on the model) that needs to be provided to the model for prediction, and Median Prediction Time, which is the median time required for the respective model to provide the prediction label. Also, since GPT 3.5T and 4 are general LLM models that can predict any text content, we pass both the full HTML and the parsed versions as artifacts for evaluation. We note that PhishIntention, despite showing the best performance among all the models, requires a relatively large artifact size of 348KB and has a longer prediction time of 10.7 seconds. PhishLang, on the other hand, shows strong performance metrics with the advantage of a significantly smaller artifact size (7KB) and faster prediction time (0.9 seconds), indicating a balance between high performance and operational efficiency. Visual PhishNet and StackModel show moderate performance in all metrics, with the former requiring a much larger artifact size and longer prediction time compared to StackModel. Finally, URLNet has the lowest performance metrics but benefits from the smallest artifact size (0.2KB) and shortest prediction time (0.7 seconds). In the case of the ChatGPT models, we found that GPT 3.5 was only able to process 822 phishing + 1031 benign samples when the full HTML was given, while GPT 4 was able to process 1,469 phishing + 2,147 benign samples due to the token size limit. We find that both models perform very well against the threats and are almost on par with both PhishLang and PhishIntention. Note that these GPT models are general models and were not specifically fine-tuned using phishing training data. Thus, it is possible that it can outperform our model if fine-tuned on appropriate data. However, restricting GPT models for commercial use and the overall expense required for training them could make them unfeasible for practical implementation."}, {"title": "4.3 Evaluating Commercial Phishing Countermeasures", "content": "In this section, we evaluate the effectiveness of different phishing countermeasures against websites identified by PhishLang. These include two commercial browser protection tools-Google Safe Browsing and Microsoft SmartScreen-and two open-source phishing blocklists, PhishTank [4", "79": ".", "98": ".", "77": ".", "90": ".", "68": ".", "41": "we automate opening each website in a browser and take screenshots to confirm detection by these tools. All tools initially have low coverage, with Google Safe Browsing outperforming SmartScreen. Reporting undetected URLs significantly improved detection rates, especially for evasive phishing attacks. For instance, Google Safe Browsing's detection of JS evasion attacks increased from 35% to 73%, and SmartScreen's detection of DOM-based attacks rose from 18% to 86%. Regular phishing URL detection also improved significantly. Despite these improvements, it is important to note that these tools generally maintain high detection rates and low false positives [77"}]}