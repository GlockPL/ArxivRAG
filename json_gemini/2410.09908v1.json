{"title": "Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning", "authors": ["Pengfei Jin", "Peng Shu", "Sekeun Kim", "Qing Xiao", "Sifan Song", "Cheng Chen", "Tianming Liu", "Xiang Li", "Quanzheng Li"], "abstract": "Foundation models have become a cornerstone in deep learning, with techniques like Low-Rank Adaptation (LoRA) offering efficient fine-tuning of large models. Similarly, methods such as Retrieval-Augmented Generation (RAG), which leverage vectorized databases, have further improved model performance by grounding outputs in external information. While these approaches have demonstrated notable success, they often require extensive training or labeled data, which can limit their adaptability in resource-constrained environments. To address these challenges, we introduce Retrieval-based Parameter Ensemble (RPE), a new method that creates a vectorized database of LoRAs, enabling efficient retrieval and application of model adaptations to new tasks. RPE minimizes the need for extensive training and eliminates the requirement for labeled data, making it particularly effective for zero-shot learning. Additionally, RPE is well-suited for privacy-sensitive domains like healthcare, as it modifies model parameters without accessing raw data. When applied to tasks such as medical report generation and image segmentation, RPE not only proved effective but also surpassed supervised fine-tuning methods in certain cases, highlighting its potential to enhance both computational efficiency and privacy in deep learning applications.", "sections": [{"title": "1 Introduction", "content": "In recent years, foundation models such as CLIP [Radford et al., 2021], LLaMA [Touvron et al., 2023] and SAM [Kirillov et al., 2023] have captured significant attention for their ability to handle various tasks with minimal adaptation. Pre-trained on large datasets, these models have been successfully applied in fields such as natural language processing, computer vision, and healthcare, driving major advancements in artificial intelligence [Shu et al., 2024, Zhao et al., 2024, Rezayi et al., 2024, Yang et al., 2024].\nHowever, fine-tuning these large models for specific tasks remains resource-intensive, often requiring substantial computational power and large-scale data. Low-Rank Adaptation (LoRA) [Hu et al., 2021] offers a solution by freezing most of the model parameters and fine-tuning only a small portion, significantly reducing the computational overhead while maintaining high performance. This is especially valuable in resource-constrained environments. Nonetheless, LoRA and similar methods are still susceptible to hallucinations where the model generates plausible but inaccurate content which can undermine the reliability of predictions. To address hallucination, Retrieval-Augmented Generation (RAG) [Lewis et al., 2020] incorporates an external retrieval step, grounding model outputs in factual data. Additionally, RAG excels at zero-shot learning, allowing models to handle tasks or categories without prior exposure. This is particularly important in healthcare, where models may need to recognize new diseases or interpret unfamiliar medical data with minimal labeled examples, accelerating diagnostic advancements.\nDespite their strengths, fine-tuning and RAG each present significant challenges. Fine-tuning delivers superior task-specific performance but requires extensive computational and data resources. RAG, on the other hand, mitigates hallucination and supports zero-shot learning but relies on access to raw data, which poses privacy concerns in fields like healthcare. Our research seeks to combine the strengths of LORA and RAG to address both computational and privacy concerns in model adaptation. Specifically, we introduce the Retrieval-based Parameter Ensemble (RPE) model, which leverages retrieval techniques to replace traditional fine-tuning.\nAs shown in Figure 1, the pipeline of RPE begins by establishing a vectorized database, LORA-VecDB, for a given foundation model. This database serves as a comprehensive repository of LoRAs {$\\theta_i$} and their corresponding representations {$\\mathbf{z}_i$} across various tasks. Rather than being created by a single entity, LoRA-VecDB is a community-driven effort, promoting collaboration and ensuring the database remains accessible, diverse, and up-to-date. When a new task or dataset arises, especially in cases with limited labels or computational resources, the model's representation $\\mathbf{z}_{trg}$ can be extracted and used to query LoRA-VecDB for similar adaptors {$\\theta_{ref}$}. By calculating appropriate weights {$\\mathbf{w}_i$}, these LoRAs are combined to form a parameter ensemble, effectively adapting the model to the new task without the need for extensive fine-tuning.\nThis approach offers several key advantages. First, it significantly reduces the redundancy and computational costs typically associated with traditional fine-tuning methods. Additionally, it enhances privacy by avoiding the need to access raw data during the adaptation process. As foundation models continue to scale, the energy consumption [Samsi et al., 2023] and privacy issues [Bommasani et al., 2021] associated with their deployment become more pressing, making our RPE method a timely and valuable solution.\nOur main contributions are summarized as follows:\n\u2022 Zero-shot Learning Model via LoRA Retrieval: We introduce a pioneering zero-shot learning framework that leverages LoRA retrieval, eliminating the need for additional labeling or training, while also preserving data privacy.\n\u2022 Insights into Relationship between Parameter and Feature Spaces: Our analysis reveals how parameter and feature spaces interact, leading to a new weighting strategy that enhances"}, {"title": "2 Related Work", "content": "We review related work on RAG, parameter combination methods, and zero-shot learning, highlighting key advancements and differences from our approach.\nRAG integrates external knowledge into large language models (LLMs) by retrieving relevant information to enhance generation accuracy [Ma et al., 2023]. Recent advancements focus on optimizing query prompting, indexing structures, and retrieval mechanisms [Ma et al., 2023, Peng et al., 2024, Gao et al., 2022], addressing limitations of naive RAG approaches. These improvements enhance retrieval precision and reduce hallucinations in generated outputs, especially in low-resource domains. For instance, [Seo et al., 2024] leverages retrieved instances to generate new training samples with LLMs, mitigating data scarcity in specialized areas. Similarly, [Parvez et al., 2022] expands positive examples in privacy policy question-answering tasks through retriever models. However, reliance on external data introduces challenges related to privacy and computational constraints, limiting applicability in certain scenarios.\nParameter Combination Methods Various methods have been developed to combine or utilize model parameters to enhance performance, robustness, and generalization. Although these approaches differ in focus, they all aim to leverage multiple models or parameter sets for improved outcomes.\nOne such method is Model Soup [Wortsman et al., 2022], which simplifies model combination through parameter averaging. Instead of fine-tuning individual models and selecting the best, Model Soup averages parameters from different models, achieving state-of-the-art performance without added inference or memory costs. This approach is particularly effective when models are trained with slight hyperparameter variations.\nAnother method is Federated Learning (FL) [McMahan et al., 2017], which focuses on distributed learning. In FL, multiple devices train models locally on their own data, and only parameter updates are sent to a central server, which aggregates them into a global model. This decentralized setup preserves privacy, making FL ideal for privacy-sensitive applications. FL often incorporates secure protocols and privacy-enhancing techniques, such as secret sharing [Cheng et al., 2021], to ensure data security.\nMixture of Experts (MoE) [Xue et al., 2024, Lin et al., 2024] is a method gaining traction in LLMs due to its dynamic expert selection capabilities. MoE architectures employ a gating network to route inputs to specialized sub-models, or \"experts,\" that handle specific tasks. This dynamic routing optimizes the model's capacity by activating only a subset of experts for each input, improving performance and efficiency. MoE's flexible specialization makes it particularly well-suited for large-scale LLMs, though its scalability is often limited by the fixed number of available experts. In contrast, our approach introduces a more flexible mechanism that allows for the retrieval of all available LORA models, enabling greater versatility and optimization.\nZero-shot Learning is a machine learning technique where a model is trained to recognize objects, categories, or concepts that it has not seen during training [Wang et al., 2019, Xian et al., 2017, Fu et al., 2018]. This technique relies on the transfer of knowledge from known (seen) tasks to unknown (unseen) tasks by utilizing shared attributes or semantic relationships. In the realm of zero-shot learning, a model must from familiar tasks, denoted as $T_{ref}$ with corresponding parameters $\\theta_{ref}$ to a novel task $T_{trg}$. This process requires a specific task representation $\\mathbf{z}^{ref}$, which is often extracted from prior knowledge sources such as textual data or structured entities. Notable studies in this field have employed neural networks to facilitate the mapping A from $\\mathbf{z}_i$ to $\\theta_i$. For instance, DeViSE [Frome et al., 2013] used a linear mapping from image features to a joint embedding space. GCN-ZL [Wang et al., 2018] utilized Graph Neural Networks to map from word embeddings to semantic embeddings."}, {"title": "3 Method", "content": "In this section, we elaborate on two key components of our approach: the construction of the LoRA-VecDB, a vectorized database for storing model adaptations and their corresponding representations, and the retrieval and weighted ensemble mechanism. This mechanism utilizes the database to adapt foundation models dynamically to new tasks by transforming task data into query representations, retrieving relevant LoRAs, and calculating weights to configure a tailored model, thus enabling significant flexibility and performance in data-scarce or privacy-sensitive scenarios.", "subsections": [{"title": "3.1 Construction of LoRA-VecDB", "content": "The vectorized database, named LoRA-VecDB, stands as a central repository that catalogs LoRAs {$\\theta_i$} and their corresponding representations {$\\mathbf{z}_i$} for various tasks. This database not only facilitates accessibility but also encourages ongoing contributions from the community, maintaining a collaborative and up-to-date resource.\nFor each specific dataset $D_i$, a LORA $\\delta\\theta_i$ is trained using the foundation model $F(\\cdot, \\theta_0)$. LORA achieves this by freezing the pre-trained model weights and introducing trainable low-rank matrices into each layer, significantly reducing the number of parameters required for adaptation. This process also generates a representation $\\mathbf{z}_i$, capturing the essential features or transformations unique to $D_i$. Typically, the representation $\\mathbf{z}_i$ is derived directly from the feature map of $F$'s encoder, maintaining a raw projection of data features. However, for enhanced interpretability and to manage multiple adaptations, an additional encoder can be employed to refine these features into a more contextually appropriate form. This strategy draws from techniques such as RAG, where specialized encoders are employed to effectively handle large datasets.\nIn our application, unless explicitly stated, we utilize the feature map output from the encoder of $F$, denoted as $E_F(\\mathbf{x}_j,\\theta_0)$, for individual data items $\\mathbf{x}_j$, which may represent an image or a document. This approach aligns with the strategy used in the encoder component of the MoE, where feature maps serve a pivotal role in the model architecture. It is crucial to emphasize that these feature maps are utilized in their original form, without any fine-tuning, ensuring that the integrity and the originality of the model's initial pre-training are maintained.\nFor simplicity and practicality in representing dataset features, we initially explored using various distribution distance metrics, such as the Chamfer distance [Borgefors, 1986], Nearest Neighbor Distance [Alt and Godau, 1995], Mean Distance [Carroll and Arabie, 1998], to measure similarities between datasets. However, these metrics did not show significant differences in dataset characteristics. Therefore, to streamline our approach, we represent the features of dataset $D_i$ by averaging all associated data feature maps:\n$\\mathbf{z}_i = \\frac{1}{|D_i|} \\sum_{\\mathbf{x}_j \\in D_i} E_F(\\mathbf{x}_j, \\theta_0),$\nwhere $|D_i|$ denotes the number of elements in dataset $D_i$, ensuring each dataset's characteristic is represented as the mean of its features. This method not only simplifies the computational process but also facilitates the efficient storage of these averaged features in the VecDB, maintaining the integrity and accessibility of the original data representation.\nThrough these methodologies, LoRA-VecDB not only provides a structured and efficient way to store and retrieve adaptations but also supports a scalable framework for experimentation and enhancement in model adaptability. This open and maintained database promises to be a valuable asset for researchers and practitioners aiming to leverage existing foundation models to new datasets and problems."}, {"title": "3.2 Retrieval and Weighted Ensemble", "content": "The process begins by transforming the dataset for the new task into a query representation $\\mathbf{z}_{trg}$. We then search for the most relevant LoRAs, retrieving a set of {$\\mathbf{z}_{ref}^i$} and {$\\delta\\theta_{ref}^i$}. The weights {$\\mathbf{w}_i$} are computed as a function of $\\mathbf{z}_{trg}$ and {$\\mathbf{z}_{ref}^i$}, enabling the model to utilize $F(\\cdot, \\theta_0 + \\sum \\mathbf{w}_i \\delta\\theta_{ref}^i)$, where $\\theta_0$ represents the parameters of the foundational model and $\\mathbf{w}_i\\delta\\theta_{ref}^i$ are the weighted adjustments from the retrieved LoRAs. This methodology supports dynamic adaptation of foundational models to new tasks, leveraging community-generated adaptations and sophisticated retrieval techniques to enhance model performance without extensive retraining. The algorithm is detailed in Algorithm 1."}]}, {"title": "4 Experiments", "content": "To validate our approach, we conduct experiments using two foundational models: Llama 3.1 8B [Dubey et al., 2024] and SAM [Kirillov et al., 2023]. We use 8 H100 80G GPUs for the training and fine-tuning.\nFor Llama 3.1 8B model, we evaluate its performance on generating medical report impressions from provided findings. Specifically, we fine tune four LoRA models derived from the pre-trained Llama 3.1 8B model using four distinct datasets collected from Massachusetts General Hospital (MGH). These datasets comprise 24,801 CT abdomen reports, 63,745 CT head reports, 18,157 MR image reports, and 60,000 X-ray image reports. Each report includes detailed image findings and corresponding impressions. The fine-tuning process employ consistent hyperparameter settings: training batch size = 8, gradient accumulation steps = 4, optimizer = paged adamw 32bit, learning rate = 5*10-6, weight decay = 0.001, maximum gradient normal = 0.3, LoRA r = 16, LoRA alpha = 0.05. The number of training epochs is set as follows: 2 for CT abdomen, 1 for CT head, 3 for MR, and 1 for X-ray reports. In testing, we collecte 200 new reports for each type of medical image.\nFor SAM model, we focus on medical image segmentation tasks. Consistent with the MA-SAM framework [Chen et al., 2023], we use the same hyperparameter settings. We reproduce and train six individual MA-SAM models, each corresponding to one prostate dataset [Liu et al., 2020] that the original MA-SAM applies. For both tasks, each dataset is iteratively treated as the target dataset, while the remaining datasets serve as reference datasets for zero-shot learning."}, {"title": "4.2 Medical report impression", "content": "We form ensemble models for each type of medical reports by utilizing both similarity calculation and linear combination but without regularization. Following [Shi et al., 2024], we apply ROUGE-L [Lin, 2004], BertScore [Zhang et al., 2019] and GPT score defined in [Shi et al., 2024] in our evaluation to have a comprehensive observation for both fundamental word matching and semantic level accuracy."}, {"title": "4.3 Medical Image segmentation", "content": "We initiated our experiments by training LoRAs on six distinct datasets sourced from various manufacturers, each differing significantly in signal strength and resolution. This diversity introduced notable shifts in data distribution, which posed significant challenges for a single LoRA model, underscoring the necessity of training models on similar datasets to enhance task performance. For an in-depth analysis of the datasets and specific numerical evaluations, please refer to Appendix A.2.\nTo evaluate the efficacy of our methodology, we investigated the correlation between the similarity of datasets and the accuracy of LoRA models."}, {"title": "4.4 Ablation Study", "content": "In this section, we present a series of ablation studies aimed at evaluating the efficacy of using the nearest LORA compared to an ensemble approach. Additionally, we explore the potential benefits of incorporating LoRAs derived from multiple training sets in enhancing the performance of models developed through Supervised Fine-Tuning."}, {"title": "4.4.1 Nearest LoRA vs. Ensemble Methods", "content": "A natural concern arises regarding whether it is more effective to use a model trained on the most similar dataset directly, or to employ a fusion of parameters. In this context, we explore a boundary scenario where we select only the nearest dataset's LoRA during retrieval, effectively setting k = 1 in a k-NN search.\nResults from different datasets displayed in Table 5 reveal that relying solely on the most similar training set exhibit highly variable outcomes. Compared to the ensemble approach, using a single model tends to result in overfitting to the specific dataset it was trained on. For a more detailed discussion and numerical analysis, please refer to Table 15 in Appendix A.2. This suggests that integrating multiple models might provide a more robust and stable performance across diverse datasets."}, {"title": "4.4.2 Whether to Improve SFT", "content": "Our model is capable of performing zero-shot learning and also serves as a method to enhance SFT. This approach proves particularly effective in scenarios where there is a shift in data distribution between the training and testing datasets, outperforming the original LoRA in certain tasks and data contexts.\nTable 6 illustrates an example where ensemble coefficients are derived using all LoRA (including C's training set) variants on dataset C's testing set using linear combination. This reflects the inter-dataset relationships; notably, a negative correlation exists between the testing set of dataset C and the training set of dataset A. Using these weights, we achieved a performance of 90.8%, which slightly surpasses the 90.5% achieved by SFT. Although the improvement is marginal, it suggests potential for further enhancing SFT methods, marking a promising direction for future research."}, {"title": "5 Discussion and Future work", "content": "From the experiments, it is evident that our approach yields promising results. An overall analysis based on the experimental section reveals that the RPE model significantly enhances the adaptability and efficiency of foundational models in tasks where labeled data is scarce or unavailable.\nHowever, there are still some limitations to consider. Due to the limited number of LoRAs available, some aspects of our architecture merit further discussion. One such aspect is the potential for improving the encoder used to derive the representation z. This could involve utilizing a pre-trained model or specifically training an encoder to optimize weight determination. Another challenge arises when there"}, {"title": "6 Conclusion", "content": "We have introduced a RPE model that achieves zero-shot learning without the need for additional data and training, while also maintaining data privacy. This model has produced promising results in medical application scenarios. Such a paradigm significantly reduces the redundant computational resource consumption of community groups and holds the potential to become an important framework in the future."}]}