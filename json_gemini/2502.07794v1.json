{"title": "Regulatory Science Innovation for Generative AI and Large Language Models\nin Health and Medicine: A Global Call for Action", "authors": ["Jasmine Chiat Ling Ong", "Yilin Ning", "Mingxuan Liu", "Yian Ma", "Zhao Liang", "Kuldev Singh", "Robert T Chang", "Silke Vogel", "John CW Lim", "Iris Siu Kwan Tan", "Oscar Freyer", "Stephen Gilbert", "Danielle S Bitterman", "Xiaoxuan Liu", "Alastair K Denniston", "Nan Liu"], "abstract": "The integration of generative Al (GenAI) and large language models (LLMs) in healthcare presents\nboth unprecedented opportunities and challenges, necessitating innovative regulatory approaches.\nGenAl and LLMs offer broad applications, from automating clinical workflows to personalizing\ndiagnostics. However, the non-deterministic outputs, broad functionalities and complex integration of\nGenAl and LLMs challenge existing medical device regulatory frameworks, including the total product\nlife cycle (TPLC) approach. Here we discuss the constraints of the TPLC approach to GenAl and\nLLM-based medical device regulation, and advocate for global collaboration in regulatory science\nresearch. This serves as the foundation for developing innovative approaches including adaptive\npolicies and regulatory sandboxes, to test and refine governance in real-world settings. International\nharmonization, as seen with the International Medical Device Regulators Forum, is essential to\nmanage implications of LLM on global health, including risks of widening health inequities driven by\ninherent model biases. By engaging multidisciplinary expertise, prioritizing iterative, data-driven\napproaches, and focusing on the needs of diverse populations, global regulatory science research\nenables the responsible and equitable advancement of LLM innovations in healthcare.", "sections": [{"title": "Introduction", "content": "The rapid integration of generative artificial intelligence (GenAl) in healthcare has exposed a\nsignificant regulatory gap. Generative Al algorithms are now capable of producing new text, audio,\nimage and video outputs from training data. Examples of these algorithms used in healthcare\napplications include generative adversarial networks (GAN), variational autoencoders (VAE), diffusion\nmodels and transformer-based models. The transformer architecture forms the foundation for large\nlanguage models (LLMs). Despite a notable increase in healthcare Al applications, existing health\nproducts regulatory frameworks across jurisdictions differ and are not specifically tailored to address\nthe unique challenges posed by GenAl and LLMs. Current regulatory approaches were developed for\nAl models purposefully designed to generate specific healthcare decisions or recommendations. In\ncontrast, LLM models are capable of a broad range of functions such as summarization of general\nmedical information and suggesting differential diagnoses and are often applied in task for which they\nwere not purposefully designed. This represents a shift from intended use-specific medical decision-\nmaking, which was relatively straightforward to regulate, to more generalized and flexible applications\nof Al.\nTo enable timely, safe and high accessibility to effective Al/machine learning (ML)-based medical\ndevices, regulators including the US Food and Drug Administration (FDA) and UK Medicines and\nHealthcare Products Regulatory Agency (MHRA) are adaption the Total Product Life Cycle (TPLC)\napproach for these models. 1,2 This approach was also emphasized in the executive summary of\nFDA's Digital Health Advisory Committee Meeting, forming the bedrock of the committee's\nrecommendations for regulating GenAl-enabled medical devices.3 TPLC broadly encompasses the"}, {"title": "The Constraints of the TPLC Approach", "content": "Substantial differences exist between LLMs and Al-technologies that are already part of approved\nmedical devices, creating unique challenges for regulation.5 First, LLMs are trained on extensive\ndatasets gathered from the internet and other diverse sources, making it virtually impossible to\nthoroughly examine or scrutinize the training data. Second, long form LLM outputs are subject to\nconcerns over poor repeatability even with the same prompt strategy. Decision support systems using\nLLMs may experience performance deterioration when used in real-world settings particularly if LLMs\nare sensitive to changes in syntax of input queries. Third, the risk of privacy and confidentiality\nbreaches remains unresolved. In the following section, we discuss the limits of regulatory oversight\nusing the TPLC approach for LLMs. Figure 1 shows different phases of TPLC, and regulatory\nconsiderations specific to LLMs."}, {"title": "Ambiguity in Medical Device Definitions for LLMs and LLM-based applications", "content": "The qualification of LLMs and LLM-based applications as medical devices remains a topic of debate.\nThe applicability of various regulatory frameworks, including the European Union's Medical Device\nRegulation (MDR) and US FDA's Software as a Medical Device (SaMD), is based on the Al model's\nor Al-based device's intended use and proposed indications. For the EU, that means that the\nregulation of such LLMs under the MDR is unclear, unless they have a clear intended medical\npurpose. They are considered as generative Al models under the EU AI Act but only face substantive\nregulation if they are classified as being of high risk or systemic risk. The downstream LLM-based\napplications with a medical purpose, however, would qualify as medical devices under the MDR and,\nif MDR risk class lia or higher, as high-risk Al systems under the EU AI Act. Table 1 summarises how\ndifferent regulatory frameworks define a medical device. Many LLMs and LLM-based applications will\nlikely fall into a grey area where their classification remains unclear. The description of the intended\nuse and indications of use is less straightforward for LLMs due to their generalist nature and broad\nutilities. One example is LLM tools built to transcribe and summarize patient-physician interactions\ninto a clinical document. Creation of the clinical summary requires the model to interpret clinical data\nand suggest medical information that may influence decisions made by subsequent reviewing\nclinicians. Various companies have marketed a variety of clinical documentation automation products\nwithout the need for regulatory approval as medical device. The commercial presence of these\nproducts may signal a need for stricter enforcement.\nUnlike predictive models, LLM outputs are non-deterministic in nature, even when the model\ntemperature is set to zero. Frequency of hallucinations by LLMs under different conditions of use is\npoorly quantified and require further examination and documentation. The risk classification and\ndegree of control required for LLM-based medical device may need revision to cater for risks specific\nto LLM-based devices."}, {"title": "Lack of Robust Evaluation for LLM Performance", "content": "We are faced with unprecedented challenges as a result of the unique capabilities of LLMs in open-\nended output generation. Unlike diagnostic tests, where accuracy can be assessed, or interventional\ntrials, where causal effects can be quantified, the evaluation of LLMs often relies on subjective and\nlargely qualitative assessments. Multiples studies have evaluated the performance of LLMs on\nisolated medical tasks such as information extraction from clinical notes or answering patient\nenquiries. The performance of LLMs in such tasks have largely been tested in structurally simple case\nvignettes, medical licencing exams or medical question and answer datasets. However, there is\nincreasing recognition that the strong performance of LLMs in these tasks is not reflective of these\nmodels' performance in real-world clinical decision making. Hager et al. evaluated leading open-\naccess LLMs using a comprehensive evaluation framework. LLMs were assessed for their\nperformance in making diagnosis, gathering information and providing guideline adherence\nrecommendations using real-world cases. The results revealed significant limitations of LLMs, with all\nmodels performing worse than clinicians in making diagnosis, interpreting laboratory results and\nadherence with established treatment guidelines.\nRobust evaluation of LLM bias is similarly critical to surface risks that may perpetuate health\ninequities. Before LLMs can be approved and used widely in clinical settings, contextualized\nevaluations with setting up of suitable guardrails is necessary to ensure patient safety. Various\napproaches to LLM bias evaluation have been proposed. One approach is to rely on physician\nevaluation of different dimensions of LLM bias including inaccuracy across axes of identity, lack of\ninclusion, stereotypical language or characterization, omission of structural explanations for inequity,\nfailure to challenge a biased premise and potential for disproportionate withholding of opportunities or\nresources. Another approach involves adversarial testing to probe for different failure modes and\nconditions whereby LLMs will generate harmful and biased outputs. Convergence among regulators,\nmanufacturers and researchers is necessary to develop evaluation methodology and metrics that are\nclinically relevant. The complexity of developing benchmarks depends on the deployment scenario of"}, {"title": "Challenges to Monitoring and Regulatory Enforcement", "content": "The training of LLMs on vast and diverse datasets present challenges in monitoring and enforcement,\nin particular concerning data provenance. LLM models are often trained on vast, diverse, and\ninconsistently documented datasets, making it difficult to trace the origins and licensing of the data\nused. This complicates efforts to ensure compliance with regulatory standards, such as those\ngoverning data privacy, consent, and intellectual property rights. A recent large-scale audit of over\n1,800 text datasets on Hugging Face revealed frequent misclassifications. License omission was\nreported in 70% of datasets and errors were detected in 50% of listed licences. This highlights a\nproblem in misattribution of datasets and informed use in Al and LLM development.11 In addition, the\nopen-sourced models allow modifications and retraining by third parties to be performed freely, further\nobscuring data provenance and undermining data authenticity. Addressing these challenges\nnecessitates the development of robust frameworks for data auditing and provenance tracking to\nenable more effective oversight of LLM-based tools.\nPost-marketing surveillance of approved LLM-based tools has similar challenges to monitoring the\neffects of medicinal products post licensure12,13. First, the inability to track \"off-labelled\" use of domain\nspecific-LLMs for example when applying the models for unapproved indications and/or patient\npopulations14. Signal detection of public health risks is very challenging given the pervasiveness of\nLLM tools with diverse applications and uses. Second, reliance on voluntary reporting of adverse\nevents by clinicians to potential under-reporting and delays in signal detection.15-17 LLM-based tools,\nsuch as Ambient Al medical scribes, heighten the challenge of identifying potential adverse events\nattributed to use of these tools. Unedited \u201challucinations\u201d or inappropriate redaction of pertinent\ninformation may be carried forward to subsequent clinical notes, resulting in errors of unknown\nprovenance. Finally, high cost and extensive resources are required to develop a robust vigilance\nprogram due to the diverse nature of LLM applications and unknown profile of risk to patients.\nAccelerated market approval processes pose additional challenges for monitoring programs. For\nexample, the FDA has approved close to two-third of all Al-based SaMD devices via the 510(k)\npathway. 18 This process for medical devices is based on \"substantial equivalence\" to devices cleared\npre-1976 or legally marketed thereafter, known as predicate devices.19 A 'predicate creep' has been\ndescribed as a cycle of technology change through repeated clearance of devices based on\npredicates with slightly different technological characteristics. While the 510(k) pathway has facilitated\nfaster clearance of devices, these may have referenced multiple iterations of predicates, resulting in\ndevices with significant differences in features and deviating from the design intent of the first\nrigorously reviewed and approved reference model; this could pose risks to patient safety. 20,21\nDepending on risk assessment, some GenAl tools may be approved via the 510(k) pathway on the\npremise of 'low-risk, design iterations' built upon the same pre-trained foundation models such as"}, {"title": "Ethical Considerations Beyond Current Regulatory Oversight", "content": "The widespread availability and rapid adoption of LLM tools, either directly applied to or adapted for\nhealthcare, are raising numerous ethical dilemmas and posing potential risks to the broader public.\nRisks that remain inadequately addressed include low trust of LLM-based health applications due to\nrisks of hallucinations and poor reproducibility of output; embedded bias in LLMs exacerbating health\ninequities; and bioethical concerns such as patient privacy arising from the use of healthcare data in\nmodel pre-training. 30-34 Despite its promise, current evidence is still lacking on the impact of LLMs on\npatient outcomes. In addition, the impact of LLM applications on population health and minority\npopulations is still largely unknown.\nRegulatory guidance for responsible and ethical LLM use is critical. The issue of bias being\ndemonstrated or exacerbated by Al algorithms is an increasing concern within the healthcare industry.\nSeveral initiatives such as the STANDING Together initiative (standards for data diversity, inclusivity,\nand generalizability)35 and the FDA's \u201cArtificial Intelligence/Machine Learning (AI/ML)-Based Software\nas a Medical Device Action Plan\" serve to bridge the gaps inherent in existing research and regulatory\nstandards/guidance.36 However, there has been little formal consideration of the impact of patient\ninteractions with Al programs, including the impact of LLM medical tools on patient autonomy, dignity,\nthe patient-clinician relationship and trust.37 Conversational applications (chatbots) powered by LLMs\nallow dynamic, context-aware exchanges in patient education. However, LLM interactions are\nnuanced, thus model fine-tuning is typically needed, and requires post launch monitoring and policy\noptimization to reduce risks of embedded cognitive biases such as confirmation bias, automation bias\nand automation complacency as well as avoiding model drift.\nDeveloping effective regulatory policies which take into consideration the vast number of ethical\nprinciples is challenging. Interpretation of ethical principles can be highly subjective, and may vary in"}, {"title": "Regulatory Science in LLM Innovation \u2013 Opportunities and Trends", "content": "Regulatory science is the science of developing new tools, standards, and approaches to assess the\nsafety, efficacy, quality, and performance of health products that are assessed by regulatory\nagencies. 38 Regulatory authorities such as the FDA, European Medicines Agency (EMA), Australian\nTherapeutic Goods Administration (TGA) and the Singapore Health Sciences Authority (HSA) conduct\nresearch or partner with regulatory research groups in the development of guidance material. Such\nregulatory collaborative groups include Centres of Excellence in Regulatory Science and Innovation in\nthe United States, Centre for Regulatory Science and Innovation in the United Kingdom, the Duke-\nNUS Centre of Regulatory Excellence in Singapore; and at a global level, the Global Coalition for\nRegulatory Science Research and World Health Organization (WHO). In this section, we discuss the\npriorities of regulatory science research in advancing the goals of responsible LLM innovation and\nbalanced regulation."}, {"title": "Applying Adaptive Regulatory Approaches", "content": "Adaptive regulatory approaches may be adopted for policies characterized by a fast pace of\ninnovation. LLM-based tools are prime candidates for this regulatory approach and could catalyse\nadvances in this area, commanding the attention of regulators and industry stakeholders to keep up to\ndate with growing scientific evidence of risks and benefits of the technology.39 Adaptive approaches\nare those that empower regulators to be less restrictive in the absence of negative outcomes\ndemonstrated in clinical trials, and reinstate restrictions should evidence of harm emerge in the\nprocess of post-marketing surveillance.39 For example, accelerated approval (in the US) and\nconditional marketing authorization/approval (in the EU, Singapore and Japan) pathways are in place\nfor emerging therapeutics. 40 The predetermined change control plan proposal put together by FDA,\nHealth Canada and MHRA supplements the TPLC, allowing certain changes that were predicted and\npredefined in a submitted plan, to be made without requiring another approval process; these\nchanges could be a result of information from real-world use. A more flexible approach is an\nanticipatory regulatory approach, whereby regulatory rules are iteratively developed alongside\ndevelopment of new products or services. Regulatory sandboxes are outcomes-oriented tools used to\nguide anticipatory regulation, whereby new services, health products or digital health tools can be\ntested in a constrained environment with less regulatory requirements. Examples include the United\nKingdom's MHRA AI Airlock and Singapore's Infocomm Media Development Authority (IMDA) Privacy\nEnhancing Technology Regulatory Sandbox.41,42 Similarly, the EU AI Act calls for establishing\nregulatory sandboxes for improving regulatory compliance with the act (detailed in Article 57 of the EU\nAl Act). These sandboxes allow developers and researchers to work closely with regulators to\nidentify, quantify and prospectively develop solutions to mitigate potential risks in early stages."}, {"title": "Convergence of Regulatory Frameworks: Medical Device and Health Services", "content": "Al agents powered by LLMs and agentic systems show promise in enabling greater level of\nautomation in clinical tasks.44 Al agents in healthcare are intelligent systems designed to assist,\nautomate, and enhance various aspects of medical care. Agentic systems have demonstrated\nimproved capabilities over single LLM models in medical information processing, planning and making\nclinical or operational decisions through interacting and collaborating among different agents.45 These\ncapabilities are shifting LLM agents from being pure assistive tools into service agents with elevated\nlevels of autonomy, much like a skilled worker performing a service. The development of Al agents\npowered by LLMs, in particular agents with reasoning capabilities,46 is introducing a paradigm shift.\nFor example, OpenAl 01 model was designed to answer complex questions through a series of\nintermediate reasoning steps, a strategy known as \u201cchain-of-thought\".47 The scaling of automation\nbeyond repetitive, low skill tasks lends in to a 'Software as a Medical Service' (SaMS) model. Coupled\nwith high accessibility to cloud-computing resources, implementation barriers and costs to health\nsystems of Al-based software and tools is significantly lowered. This allows healthcare providers and\npatients to access cutting-edge tools including Al agents without the need for extensive upfront\ninfrastructure investments.\nAs opposed to a tangible product with defined functionalities, SaMS is focused on service-oriented\ndelivery, much like a digital health service. In Singapore, health services regulation is coming under\nthe ambit of HSA which had previously only regulated health products; this will result in greater\nconvergence of products and services regulation in future, providing a more optimal framework for\nregulating healthcare Al.48 Such novel regulatory frameworks will need to be co-developed with\nregulatory science groups and studied before LLM agents and systems can be adopted at scale.\""}, {"title": "Increase Focus on Al Supply Chain", "content": "The recent global IT outage incident that started with a single software update by the cybersecurity\ncompany CrowdStrike is a prominent example of how a single failure point in the digital delivery\nsystem can lead to a global disruption of critical health services including individual products.49\nWidespread digitization, adoption of electronic medical records, mHealth and proliferation of Al-based\ntools add to our dependency on digital solutions and growing complexity which cannot afford any\ndisruptive down time. Beyond predictive, diagnostic and decision support algorithms, it is important to\nrecognize that Al is likely to be pervasive in operating systems, software and even embedded within\nhardware such as computer chips. 50 Ensuring continuity of care delivered to patients requires a\nscrutiny of vulnerabilities in the use of Al across the process of provision of healthcare delivery, both\nin the business and service value chain. Figure 2 shows the healthcare Al supply chain and examples\nof governance and guidance frameworks.\nA global collaborative effort in regulatory science enhances and strengthens the following: internal\nand global visibility on various components of the supply chain; frameworks to guide identification,\ntesting and validation of critical components and pipelines; sharing good practice for resilience teams\nand business continuity plans (BCP); facilitate communications strategy across supply chain\nnetworks. We also propose this global effort to support health systems build Al development\ncapabilities, develop infrastructure for local deployment (on premise or edge) of these models. This\nserves as a fail-safe strategy, reducing dependency on commercially available, leading technologies.\nIn addition, such deployment strategies improve availability of services and lower dependence from\ncommercial cloud-based products. This approach could lower privacy risks while having its own\ncybersecurity challenges. There is a need to ensure that capacity building and participation in a global\ncollaborative effort is not limited to researchers from high income countries and representing top-tier\nresearch institutions.30 Along the same line, continued efforts to improve open-sourced models (e.g.\nopen-sourced LLMs) aligns with commercial competition laws.51 Government policies and health\nsystem investments need to align with these strategies, emphasizing diversity in technology\ninvestments to build a more resilient healthcare Al infrastructure."}, {"title": "Future Directions for Regulatory Science and Regulators", "content": "Al has significant potential to influence various aspects of medical product development, and this\nimpact is already in progress. The drug development industry has undergone a revolution with\nintroduction of computational approaches including deep learning, foundation models and quantum\ncomputing. 52 Deep generative Al has shown huge promise in de novo molecular design and early\ndevelopment stages e.g. predict protein folding, molecular interactions, and cellular disease\nprocesses. 53,54 ADMET (Absorption, Distribution, Metabolism, Elimination and Toxicity) properties of\nsmall molecules can now be predicted with high degree of accuracy. 55 As these Al-designed targets\nmove into clinical testing, the industry is embracing another revolution in the clinical research process\nto accelerate and streamline the process of clinical trials. In particular, the advent of LLMs has\nbrought about rapid advancements in Al-aided clinical trial design, participation selection and\nrecruitment as well as tracking and promoting adherence to trial protocols. Such applications present\nimmense promise in shortening the cost and development time for new drug entities. However,\nunknown risks associated with using the technology to augment or automate critical processes\nwarrants close scrutiny by the research community and regulators.\nWe believe that LLMs can bring about significant value in reducing administrative burden within\nregulatory agencies, and increase sensitivity and reliability of post-marketing surveillance and\nevaluation. Studies suggest promising performance in early identification and classification of adverse\ndrug events and automation of drug approval processes.56 Such tools are of low clinical risk, but bring\nabout significant returns in reducing documentation burden and turnaround time for new drug\napplications. More funding and collective support for research in this area will bring about benefits in\naccelerating medical product time to market."}, {"title": "Global Call to Action", "content": "The International Medical Device Regulators Forum (IMDRF) is an example of a global effort to\npromote harmonization medical device regulations including ML/Al-enabled devices. 57 The committee\nis represented by regulatory authority representatives from different jurisdictions including Australia's\nTGA, Health Canada, Singapore's HSA, the EU's European Commission - Directorate-General for\nHealth and Food Safety and the US FDA. Global regulatory research organizations, such as the\nGlobal Coalition for Regulatory Science Research and the Global Network for Regulatory Science,\nare pivotal in advancing regulatory research through fostering international collaboration. By engaging\nwith industry and regulatory stakeholders from various regions, they play a crucial role in establishing\ncross-industry, cross-national conversations, global harmonization and drive outcomes research to\nfacilitate formulation of regulatory guidelines for responsible adoption of Al and LLMs. The worldwide,\ninterconnected nature of digital health and Al technologies underscores the importance of adopting a\nglobal perspective and collaboratively addressing pressing issues at hand."}, {"title": "Advancing the Collective Goals of Heath Equity", "content": "Global divides between high-income countries (HICs) and low- and middle-income countries (LMICs)\nare leading to disturbing health inequities.69,70 Regulatory bodies and international organizations are\ntaking actions to push health equity to the forefront in regulatory strategies, e.g. the World Health\nOrganization global Guidance for best practices for clinical trials to promote equitable clinical trials,\nand the FDA's Health Care at Home Initiative to drive equity in digital medicine.71 LLMs have the\npotential to both bridge and exacerbate health inequities. Potential harms can arise if social and\nstructural health determinants; geographic, linguistic, and demographic biases in datasets72,\nmisconceptions tied to patient identity; prioritization of privileged perspectives; and systemic\ndisparities in system performance and accessibility across populations are not appropriately\naddressed. There is also a need to identify and understand the various nuanced failure modes of\nLLM tools when implemented at scale, to allow health delivery systems to devise more effective real-\ntime monitoring programs. For example, repeated testing (conducted over a thousand times) of LLMs\nusing hypothetical clinical scenarios revealed clear gender and racial biases.73 These may not be\napparent when tested in a clinical trial, but emerge as critical public health concerns when deployed in\na real world setting. LLMs and GenAl risk perpetuating biases in clinical applications at production\nscale with biases accumulating throughout data processing and modelling process.\nGlobal regulatory science groups can advance the goals of health equity beyond country borders and\ngeopolitical regions. Intentional inclusion of LMIC perspectives in global discussions to tailor Al\nsolutions that address specific regional health challenges and resource constraints. The goal of such\nefforts is to democratize resources and extend support to regions and ecosystems with limited\naccess. Knowledge and resource transfer enables accessible and affordable digital and Al"}, {"title": "Conclusion", "content": "As GenAl and LLM continue to transform healthcare and diversify its applications, we will see greater\nchallenges and uncertainties in development of regulatory policies. There will be a paradigm shift in\nhow we view the TPLC approach, and a need for innovative and responsive regulatory framework.\nWe recognize the importance of ethical considerations, services regulation and other challenges that\nthat fall beyond the traditional boundaries and oversight of health product regulators. Adherence to\nethical guidelines, maintenance of good supply chain practice policies, and effective education for\nboth manufacturers and users will be critical for LLMs to deliver on the promise of improving global\nhealth. Independent global regulatory science research groups can play an important role in\nintegrating insights from different sources of information and industries to ensure safe, beneficial, and\nequitable use of LLMs in healthcare."}]}