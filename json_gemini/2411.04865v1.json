{"title": "ZAHA: Introducing the Level of Facade Generalization and the Large-Scale Point Cloud Facade Semantic Segmentation Benchmark Dataset", "authors": ["Olaf Wysocki", "Yue Tan", "Thomas Froech", "Yan Xia", "Magdalena Wysocki", "Ludwig Hoegner", "Daniel Cremers", "Christoph Holst"], "abstract": "Facade semantic segmentation is a long-standing challenge in photogrammetry and computer vision. Although the last decades have witnessed the influx of facade segmentation methods, there is a lack of comprehensive facade classes and data covering the architectural variability. In ZAHA\u00b9, we introduce Level of Facade Generalization (LoFG), novel hierarchical facade classes designed based on international urban modeling standards, ensuring compatibility with real-world challenging classes and uniform methods' comparison. Realizing the LoFG, we present to date the largest semantic 3D facade segmentation dataset, providing 601 million annotated points at five and 15 classes of LoFG2 and LoFG3, respectively. Moreover, we analyze the performance of baseline semantic segmentation methods on our introduced LoFG classes and data, complementing it with a discussion on the unresolved challenges for facade segmentation. We firmly believe that ZAHA shall facilitate further development of 3D facade semantic segmentation methods, enabling robust segmentation indispensable in creating urban digital twins.", "sections": [{"title": "1. Introduction", "content": "Facade semantic segmentation is a fundamental issue in photogrammetry and computer vision [51]. The issue has became compounded thanks to such innovative architects as Zaha Hadid, challenging the standard assumptions of the wall's planarity, utilizing new materials, and mingling old with new architecture.\nThroughout the years, various methods have been created for image-based facade segmentation, predominantly facilitated by datasets of annotated facade images [26, 32, 38]. Although the segmentation performance on the orthorectified images can reach even 90% [32], the 2D-image nature hinders the immediate understanding of 3D scenes, limiting the 3D facade segmentation capabilities. The striking example are intruded and extruded facade elements, which have been under-explored, owing to inability to capture their structure and depth with 2D ortho-rectified images. These flaws impact other research fields frequently relying on a 3D facade semantic segmentation, such as 3D semantic building reconstruction at a high level of detail [66], finding its applications in simulating flood risk [1] or testing automated driving functions [45], among others [61,64].\nRecent developments have demonstrated that mobile laser scanning (MLS) devices can fill this 3D data gap: Once they are mounted on a mobile platform, they deliver dense, street-level point clouds, enabling capturing a 3D urban environment and, thus, 3D facade geometry (Fig. 1) [68]. This trait has sparked significant growth in urban point cloud benchmark datasets [23, 63] and the development of many semantic segmentation methods [30, 52, 68].\nYet, one of the crucial impediments in developing facade segmentation methods is the facade classes heterogeneity; leading to misinterpretations of facade element characteristics and hampering the development of a large-scale, high-variability data. This overlooked issue also impedes applying semantically segmented facades directly to the 3D semantic building reconstruction tasks since they mismatch taxonomically and geometrically the well-established modeling classes defined in the international standards [17, 66, 68]. Another key issue pertains to the limited annotated facade samples for methods' training and validation. Only two relatively small datasets comprise facade-level classes: TUM-FA\u00c7ADE [63] and ArCH [35], which however either focus on a single university dataset or on only specific cultural heritage buildings, respectively.\nTo tackle the challenges mentioned above, in this paper,"}, {"title": "2. Related Works", "content": null}, {"title": "2.1. Facade-Related Point Cloud Datasets", "content": "For many years researchers have invested a great deal of effort in introducing multiple image-based facade segmentation datasets for methods development [12, 26,43,51,56]. For instance, in one the first works over a decade ago, the eTRIMS dataset has introduced 60 facade images [26] and eight facade-relevant labels. Yet, these and following works [56] have been inconsistent with their facade elements definitions and have been limited concerning intruded and extruded 3D facade elements (e.g., arches).\nUnlike the image-based data, the point cloud datasets for facade segmentation remain in their infancy (see Table 1). Although many benchmarks are devoted to 3D urban semantic segmentation, only ArCH [35] and TUM-FA\u00c7ADE [63] datasets comprise facade-level classes. Yet, the ArCH dataset focuses on cultural heritage buildings, which trait renders it infeasible for methods' testing on common facade types; Whereas the TUM-FA\u00c7ADE represents solely university buildings, and its relatively small size of 14 facades makes it insufficient for extensive methods' development;\nFurthermore, such important facade classes as balcony have no data representation.\nInterestingly, the Oakland 3D [37] and the Paris-rue-Madame [47] datasets also cover some aspects of the facade element classes. Oakland 3D comprises only a few facade-related classes, inadequately capturing the key facade elements (e.g., windows are absent). Similarly, the Paris-rue-Madame dataset is restricted to merely wall lights, wall signs, and balcony plants, limiting its application for facade segmentation. Another limitation of the datasets comprising facade classes is their limited size: TUM-FA\u00c7ADE and ArCH comprise around 100 million points, Paris-rue-Madame scores 20 million, and Oakland 3D has less than 2 million annotated points.\nMoreover, as shown in Table 1, the class variability among the datasets is high, which hinders the standardized comparison between benchmarks and their reported segmentation results. This trend is underscored by their high class-wise standard deviation of approximately 13, ranging from eight to up to 50 classes (excluding the non-labeled datasets). On the other hand, multiple international organizations exist that create standardized descriptions of urban objects, including facade elements. One of the leading bodies is Open Geospatial Consortium (OGC), which has been releasing the international CityGML standard [17,25], providing a comprehensive description of geometries, structures, taxonomies, and aggregations at the scale of buildings but also entire countries [24]. Its wide adoption is highlighted by the example of more than 200 million open-data 3D building models available in Switzerland, Germany, the United States, the Netherlands, and Poland, among others [65]. The complementing sources for facade description are the Art and Architecture Thesaurus (AAT) and the Industry Foundation Classes (IFC) standard, which are widely applied in the architecture and civil engineering domains [28, 35], for instance, in the building information modeling"}, {"title": "2.2. 3D Facade Semantic Segmentation Methods", "content": "The advent of the aforementioned image-based benchmarks has sparked advancements in facade segmentation using images. Various methods have been proposed to tackle this challenge, starting with non-learning [38, 51], gramma-based [6, 36], and recently deep learning approaches [19,22, 32]. However, 2D-image-reliance restricts the methods to 2D image information, which hampers its direct application to the 3D facade segmentation and thus limits capturing the facade intruded and extruded elements depth [19, 66].\nA different strategy focuses on direct 3D facade segmentation using laser scanning point clouds, leveraging the detailed and accurate depth information provided by MLS point clouds [67, 68]. Recently, the deep learning approaches have shown great potential in 3D point cloud segmentation [41, 42, 71]. Qi et al., [41] present the PointNet architecture, which enables efficient point-wise 3D point cloud segmentation on unordered sets. Following works [42, 60, 71], have further improved segmentation performance.\nNotably, significant advancements in point-wise, learning-based techniques have been applied to 3D facades segmentation as well [3, 16, 34, 53, 62]. They typically perform well on the planar-like, ubiquitous classes, reaching around 75% in F1 score for the wall class when applying DGCNN [40]. However, the research shows the off-the-shelf methods face challenges when dealing with sparse- and under-represented classes, such as decorations, moldings, stairs, windows, and doors [34, 40]. Essentially, facing the typical long-tail data distribution recognition problem of real-world data [7, 11, 69, 70]. This issue is reflected in, for example, low scores for the standard Point Transformer network [71], which can merely reach F1 scores of 49%, 2%, and 48%, for window, door, and molding class, respectively [62]. Also, as reported by Pierdicca et al., recall scores for column, arc, decoration, door, and stair classes can oscillate around 0-1% for PointNet and PointNet++ [40].\nYet, caution must be exercised while analyzing the reports, as the tests are currently inadequate, performed on heterogeneous classes and small datasets comprising a limited number of facades and their types [34, 63]; underscoring the need for developing classes harmonization and large-scale point cloud facade datasets. The methods' performance is also dependent on the granularity of the target classes, where the reception field and sampling strategies play pivotal role [54]. This characteristic results in varying performance for dense-distribution objects (e.g., walls) and sparse and thin objects (e.g., windows) depending on"}, {"title": "3. The LoFG and Its Realization", "content": null}, {"title": "3.1. 3D Semantic Facade Classes", "content": "As shown in Table 1, there is a lack of high facade variability and hierarchical facade-level point cloud benchmarks available. Understanding the need for 3D facade semantic segmentation gradation due to different methods' assumptions, downstream tasks, and data availability, we introduce LoFG, where we distinguish three levels of facade generalization: LoFG1, LoFG2, and LoFG3. This concept and its presented logic in Fig. 3 aim to allow for precisely formulating 3D facade semantic segmentation and classification problems. Furthermore, it shall enable seamless adoption of such techniques as transfer learning [48], epoch-to-epoch labels transferring [46], and a unified comparison of different methods.\nWithin the scope of this work, we introduce the harmonized 15 facade classes (LoFG3) generalizing to five classes (LoFG2), and one abstract class (LoFG1), developed concerning the international urban modeling standards such as CityGML, IFC, and Art and Architecture Thesaurus (AAT), and related works [34, 63]. The detailed description of the introduced classes is provided in Tab. 2 whereas the visualization is in Fig. 1 and Fig. 2. Moreover, owing to leveraging the modeling standards the presented classes correspond to the established 3D semantic reconstruction classes, aiming to provide a seamless platform for applying the 3D facade semantic segmentation results to the 3D facade semantic reconstruction [17, 27, 66].\nThe LoFG3 describes the most detailed facade representation comprising 15 facade classes of ground surface, terrain, molding, deco, wall, stairs, balcony, column, arch, blinds, door, window, roof, interior, and other (for the detailed description see Tab. 2). The LoFG2 aggregates the 15 classes of LoFG3 into five less detailed classes based on syntactic, semantic, and geometrical analysis, as we illustrate in Fig. 3. The group facade & its vicinity represents the abstract class and is referred to as LoFG1.\nNote that the LoFG is driven mainly by the semantics of facade elements and their structural definition and not sole geometrical representation. For example, roof is often regarded as a structural element of a building; however, in the case of terrestrial-acquired datasets, roofs are barely within the scanner field-of-view and thus resemble noise, for example, shown in [63] or in Fig. 1, Fig. 2. Furthermore, the ground and terrain classes are also clearly defined in the international standards and are considered key parts of a facade, e.g., the intersection of terrain with a facade is essential in establishing the total facade height, while ground surface is vital in analyzing overarching structures and their volumetric extent, e.g., underpasses. Another example are the classes windows and blinds, which at LoFG3 are separate, owing to they different features, functions, and importance of such separation for window segmentation [55, 66]; Yet, at LoFG2 they are aggregated, as a blind is indissolubly linked to a window."}, {"title": "3.2. Data Acquisition", "content": "Based on the conducted research (Tab. 1) and seeing the potential of already created urban-related point cloud benchmarks, we present an approach to reducing the workload while developing new benchmark datasets. This reduction is achieved by enriching existing benchmarks with facade-related semantics. The data acquired for the ZAHA dataset stems from the open dataset of TUM-MLS-2016 [72], featuring a challenging, urban environment with real-world, dense, and georeferenced MLS point clouds. The measuring campaign is performed within the city of Munich, Germany. We utilize this dataset owing to its versatile architectural style of buildings built between the late 19th and early 21st century and different facade functions ranging from regular dwellings, educational, cultural heritage, shops, and traffic underpasses. Notably, the datasets are subject to active development, including level of detail (LoD)3 building models, which may be used as an additional validation set [2]."}, {"title": "3.2.1 Mobile Laser Scans", "content": "The used TUM-MLS-2016 relies on the Mobile Distributed Situation Awareness (MODISSA) platform, employing two Velodyne HDL-64E LiDAR sensors obliquely mounted at the front and two Velodyne VLP-16 sensors at the rear of the van-type vehicle. The inertial navigation system is complemented by real-time kinematic (RTK) correction data from the German satellite positioning service (SAPOS), enhancing accurate georeferencing throughout the data collection process [5, 72]. Due to large float numbers, we present the data in a local coordinate reference system (CRS) and attach the transformation matrix, which enables back-transformation of the projected CRS of UTM 32 (EPSG: 25832)."}, {"title": "3.2.2 Semantic Annotation", "content": "We leverage the georeferencing to support the annotation and data extraction process. We acquire cm-grade footprints from governmental, open-data CityGML LoD2 building models [58], which are available in the same CRS as the obtained point clouds. To extract the facades and their vicinity, we draw a buffer around each building footprint with a radius of 3m. Furthermore, in this process, each point cloud obtains its corresponding unique global identification (ID) of the building entity, matching the governmental database and thus enabling model-to-point-cloud comparison.\nThe manual annotation of point cloud entities is performed using Semantic Segmentation Editor [21]. The point clouds are divided into batches of approximately four million points, considering software and hardware capabilities and the operator's ability to discern various facade features. We expand the software annotation set to accommodate our specific classes, outlined in Tab. 2, and create the setup file available in our repository. After the point clouds are merged back into entities, another round of manual inspection is applied to minimize the manually induced errors between batches. Here, we employ another software, Cyclone 3DR [20], to reduce errors induced by differences in visualization and annotation tools. For the first round of annotations, we estimate that depending on the complexity of an object, labeling requires between seven to 23 hours per building, averaging approximately six hours per facade. The following correction round of annotations requires approximately two hours per facade."}, {"title": "3.3. Main Benchmark Challenges", "content": "We believe that the main challenges while developing the methods performing using the ZAHA classes and dataset are as follows:\n\u2022 Classes relevant to the built environment We introduce LoFG that harmonizes the so-far unstructured facade element classes, whereby we utilize the facade-related international standards. This characteristic ensures a homogeneous comparison of the developed algorithms and exposes the dataset to the practical challenges of the built environment. Furthermore, different levels of generalization allow the testing of various methods' assumptions. Such design also challenges the current methods, as such classes are often highly imbalanced, see the common long-tail recognition issue in [7, 69, 70] and in our Fig. 4.\n\u2022 Facade type variations Unlike the other facade-related datasets, we present 66 facades in various architectural styles and function types, having more than four times as many points for training and validation when compared to the largest datasets to date [35, 63]. This trait allows testing the generalization capabilities of 3D facade semantic segmentation algorithms. Simultaneously, it poses a scientific challenge in designing a generic method agnostic to the architectural facade types.\n\u2022 Consumer-grade MLS measurements We provide the non-filtered point cloud acquired with an off-the-shelf LiDAR devices (Velodyne). No special noise corrections and dynamic object removal are applied; interior reflections and adjacent to facade objects are kept, too. Furthermore, the given point cloud comprises only geometrical representation and no spectral information. As such, the dataset yields a challenging, real-world, and raw point clouds, useful for testing not only facade but also any generic semantic segmentation method."}, {"title": "4. Experiments", "content": "We conducted the experiments on the ZAHA benchmark dataset comprising 601 million semantic-annotated points\u00b2. The validation set comprised typical residential facades, educational and cultural heritage facades, and facades with an underpass. The test set reflected in functions the validation set. We designated the rest of the facades for training. In our training setup, we also ensured that training, validation, and test data subsets each covered all 15 (LoFG3) and five (LoFG2) introduced classes; Consequently, the applied training and testing methods were exposed to each facade class. We also evaluated the introduced LoFG classes by applying the same training routine to both LoFG2 and LoFG3 levels and comparing the results."}, {"title": "4.1. Baseline Semantic Segmentation Methods", "content": "To investigate the unresolved 3D facade segmentation challenges, we tested a set of well-established semantic segmentation networks and metrics along with their original implementations on ZAHA (see the supplement for more settings' details). To evaluate the networks' performance, we used Overall Accuracy, Precision, Recall, and Jaccard Index, also known as Intersection over Union (IoU) [30, 40, 62]. Our methods selection was not only dictated by their performance reported in other urban-related works"}, {"title": "5. Results and Discussion", "content": null}, {"title": "5.1. Well-Performing Class Segmentation", "content": "Our experiments corroborate the research consensus that classes that are well-represented and characterized by planar geometries are likely to be correctly segmented. As we show in Figure 5 and Figure 6, this trend is reflected in both generalization levels LoFG2 and LoFG3. The most prominent example for the LoFG3 is the wall class, which was the overall best-performing class with a median score of 73% (Tab. 3) across all the applied networks. For the LoFG2, it was the floor class comprising primarily planar-like objects that achieved a high median F1 score, reaching approximately 91% across the tested baseline methods (Tab. 4). Interestingly, also interior and other classes were reliably distinguished with up to 88% and 74% F1 scores, respectively (Tab. 3). They differentiate themselves strongly by exposing highly unstructured local patterns followed by structured global patterns, i.e., outside-inside of a facade."}, {"title": "5.2. Challenging Class Segmentation", "content": "Confirming our hypothesis, one of the most challenging classes was deco, scoring at best approximately 5% (Tab. 3) and remained largely unsegmented, as shown in Fig. 5. We attribute it to the high structure complexity, uniqueness among the samples, and high under-representation, i.e., being at the long tail of sample distribution (see Fig. 4 for the distribution). When aggregated in LoFG2 with molding, the score increased and reached, on average, 48%; as such, however, remaining an unresolved challenge.\nAs shown in Fig. 5 and Fig. 6, the window and door classes, which are the most prominent facade features, yet typically label-sparse due to their translucent main parts, were merely partially segmented. As our experiments in Tab. 3 show, window at best scored 64%, while door merely 22%; Also, the related blinds class scored at best 20%. When generalized to LoFG2 as opening, their performance reached at best 66%. Oscillating in the range of scores of 50% and less were also arch, stairs, ground surface, column, molding, and roof; underlining the need for designing more robust 3D facade segmentation methods."}, {"title": "5.3. Level of Facade Generalization (LoFG)", "content": "Our experiments show the usability of the proposed aggregation hierarchy design as a concept addressing 3D semantic facade segmentation at different generalization levels while maintaining facade-related semantics. As expected, all the metric scores increased when testing on aggregated LoFG2 instead of high-detail LoFG3, with OA difference maximum for PointNet of 12% and the median of approximately 10% across the tested methods (Tab. 4 and Tab. 3). When analyzing LoFG2 only, we deem the decoration and opening the most challenging classes owing to their low-performance median scores of 47% and 32%, respectively. On the other hand, we observe high to medium performance for floor, structural, and other elements classes, that median scores were approximately 91%, 66%, 75%, respectively.\nNotably networks performance ranking also varied depending on the generalization level, corroborating our assumption that methods' performance is largely dependent on the segmentation objective classes: At LoFG2 the DGCNN outperformed the Point Transformer network (e.g., in recall by around 5%), and vice versa for LoFG3 (e.g., in recall by around 9%). Per-class analysis at LoFG3 also unveils that transformer-based network (PT) can have higher scores on different classes than the graph-based network (DGCNN)."}, {"title": "6. Conclusion", "content": "In this work, we present ZAHA: a) The hierarchical segmentation classes for facade segmentation, called Level of Facade Generalization (LoFG), designed based on the international facade-related standards; b) Complemented by the classes realization on the to date largest, real-world, large-scale point cloud facade benchmark data comprising approximately 601 million points, surpassing the current largest facade benchmark four times.\nThe findings of this study indicate that 3D facade segmentation remains challenging and necessitates comprehensive benchmark data and unified classes introduced by LoFG. The semantic segmentation methods perform well on planar-like facade elements (up to 84% for wall) but struggle on intricate and sparsely represented objects (up to 5% for deco). We also observe that the critical elements of a facade, such as a door and a window, still necessitate novel segmentation methods (accuracy up to 22% for the door, 64% for the window). Moreover, the performance of the neural networks largely varies depending on the selected generalization level: At LoFG2 the graph-based DGCNN outperformed transformer-based Point Transformer, and inversely for LoFG3; underscoring the need for evaluation at different generalization levels.\nBased on the observed trend in the 2D image-based facade segmentation domain, we firmly believe this 3D facade segmentation dataset will foster further development of 3D facade-oriented methods. Consequently, unlocking various downstream and related tasks, such as robust 3D semantic facade reconstruction for autonomous driving testing [45] or flood damage assessment [39]. We plan to extend our work by organizing a 3D facade semantic segmentation challenge and leaderboard\u00b3 to further facilitate these developments."}, {"title": "A. Experiments", "content": null}, {"title": "A.1. Evaluation Metrics", "content": "To evaluate the performance of the 3D facade segmentation, we used the established semantic segmentation network metrics, such as Overall Accuraccy, Precision, Recall, and Jaccard Index also known as Intersection over Union (IoU) [?]. They were defined as follows:\nOverall Accuracy = $\\frac{True Positives + True Negatives}{Total Instances}$\nPrecision = $\\frac{True Positives}{True Positives + False Positives}$\nRecall = $\\frac{True Positives}{True Positives + False Negatives}$\nF1 = 2 x $\\frac{Precision \\times Recall}{Precision + Recall}$\nIoU = $\\frac{Intersection Area}{Union Area}$ = $\\frac{True Positives}{True Positives + False Positives + False Negatives}$"}, {"title": "A.2. Parameter Settings", "content": "We conducted all the experiments using an NVIDIA GeForce RTX 4090 GPU with 16 GB VRAM with a fixed number of 100 epochs per training. The implementation will be released under our repository web page.\u00b9\nTo train the PointNet and PointNet++, we utilized the implementation sourced from [?, ?, ?]. We used the point cloud coordinates as input layers to adapt the model and modify the corresponding classes. We employed a batch size of 32 for training and testing, and each batch contains 1024 points per sample point cloud. Stochastic gradient descent with a momentum of 0.1 and a learning rate 0.001 was employed."}, {"title": "A.3. Extra Baseline Experiment on a Large-Scale- Oriented Network", "content": "Owing to the space limitation and similar performance scores to the other networks, we have moved the extra experiments on the large-scale-oriented KPConv [?] network to the supplemental material. Here, we show the extra set of experiments that we conducted on the KPConv network, whereby we also fine-tuned the hyper-parameters. KPConv introduces a deformable convolution operation, allowing the neural network to learn flexible and adaptive convolutional filters. The use of kernel points in KPConv allows for more efficient processing of point clouds, and as such, it has often been used in the context of large-scale, outdoor point clouds [?]. However, corroborating our experiment results in the main paper, there were no significant performance differences observed, as we visualize in Figure 1 and Figure 2, and list in Table 1 and Table 2.\nTo train the KPConv, we employed the implementation sourced from [?,?]. The input radius of the input sphere was"}, {"title": "A.4. Benchmark and Leaderboard", "content": "We introduce the ZAHA as a benchmark to foster the research on facade semantic segmentation. It is a common practice to publish a leaderboard, which encourages researchers to delve into a challenge. We initialize the leaderboard at the webpage 2 and invite researchers to develop novel and more efficient facade segmentation methods."}, {"title": "A.5. Extra visuals", "content": "Additional visuals are included at the project page 3 showing an animated gif file, and the full dataset and annotations according to the 15 introduced classes at LoFG3 and their generalization at LoFG2."}]}