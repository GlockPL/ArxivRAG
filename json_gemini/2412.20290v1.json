{"title": "Transformer-Based Contrastive Meta-Learning For Low-Resource Generalizable Activity Recognition", "authors": ["Junyao Wang", "Mohammad Abdullah Al Faruque"], "abstract": "Deep learning has been widely adopted for human activity recognition (HAR) while generalizing a trained model across diverse users and scenarios remains challenging due to distribution shifts (DS). The inherent low-resource challenge in HAR, i.e., collecting and labeling adequate human-involved data can be prohibitively costly, further raising the difficulty of tackling DS. We propose TACO, a novel transformer-based contrastive meta-learning approach for generalizable HAR. TACO addresses DS by synthesizing virtual target domains in training with explicit consideration of model generalizability. Additionally, we extract expressive feature with the attention mechanism of Transformer and incorporate the supervised contrastive loss function within our meta-optimization to enhance representation learning. Our evaluation demonstrates that TACO achieves notably better performance across various low-resource DS scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Human activity recognition (HAR), using sensor data to identify user activities, is essential for advancing healthcare and improving human well-being [1]. Deep neural networks have been widely adopted for time-series data processing [2]-[4] and notably improved HAR over traditional methods [5], [6]. However, model generalizability remains a critical challenge due to distribution shifts (DS) caused by user and configuration discrepancies, e.g., different living habits and sensor positions. Existing HAR models rely on the strong assumption that training and inference samples come from the same data distribution while this can be easily violated in practice and cause model failures [7], [8]. For instance, a model trained on data from existing patients can seriously fail when tested on new patients in different body status [9], [10]. Additionally, existing deep learning-based HAR require extensive labeled data to achieve reasonable performance while human-involved data are privacy-sensitive, costly to annotate, and susceptible to variations of sensors and environments [11], [12]. The low-resource data hardly represent the diverse human activities and heightens the difficulty of developing generalizable models.\nTo address these challenges, we propose TACO, a novel transformer-based contrastive meta-learning approach for the domain generalization (DG) of HAR. TACO learns domain-invariant and class-discriminative representations that can be effectively generalized to unseen instances in target domains with limited training samples. We mitigate the low-resource challenge in HAR by expanding the diversity of the data space with specially designed sensor data augmentations and extracting expressive features leveraging the attention mechanism of Transformer. We then simulate DS during the training of meta-learning by synthesizing virtual target domains within each mini-batch. Our meta-optimization objective explicitly considers model generalizability, requiring optimization steps that improve the performance in meta-train domains simultaneously improve the performance in virtual target domains. We incorporate a supervised contrastive loss function within our meta-optimization to further enhance representation learning. Our contributions are listed as follows:\n\u2022\nWe propose TACO, a novel robust and generalizable HAR algorithm that consistently provides high-quality performance across various low-resource distribution shift scenarios. TACO exhibits on average 4.08% higher accuracy than state-of-the-art domain generalization approaches.\n\u2022\nTo the best of our knowledge, TACO is the first HAR algorithm with supervised contrastive learning incorporated in meta-learning. Our meta-optimization explicitly considers domain generalizability, wherein the supervised contrastive loss function enhances semantic discrimination of features.\n\u2022\nTACO utilizes well-designed data augmentation techniques to expand the diversity of data space and employs the attention mechanism of Transformer to enhance the representation learning of multivariate time series data, effectively alleviating the demand for massive labeled data."}, {"title": "II. METHODOLOGY", "content": "A. Problem Formulation\nA domain is defined as a joint probability distribution P(x,y) on X \u00d7 Y, where X and Y denote the instance space and label space, respectively. Our goal is to learn a classification model f : X \u2192 Y with samples in source domains S to capture domain-invariant representations so that f can be generalized to new instances from unseen target domains T. Note that only information from source domains can be used for training, i.e., data from target domains cannot be accessed until deployment. DS is a prevalent issue in HAR due to the diversity of users and configurations. It arises when a target domain has notably different joint probability distribution from the source domains, i.e., P(x,y) \u2260 P(x,y),\nso that a model trained on source domains can fail to adapt to instances from target domains. Additionally, given the low-resource challenge in HAR, source domains often consist of"}, {"title": "B. Data Diversity Expansion", "content": "We expand data diversity with the following data augmentations motivated by [1], [11], [13], explicitly considering temporal properties and motion patterns in sensor-based time series data.\n\u2022 Rotation: Rotate data to simulate sensor orientations on human bodies to achieve sensor-placement invariance\n\u2022 Permutation: Slice a window of data into segments and randomly permute them to form a new window. This helps to explore permutation-invariant properties in learning.\n\u2022 Scaling: Scale the magnitude of window-length data to enhance robustness against amplitude and offset variances.\n\u2022 Time Warping: Perturb the temporal location by smoothly distorting the time intervals between samples. This broadens local diversity in the temporal dimension.\n\u2022 Magnitude Warping: Convolve data window with a smooth curve to broaden magnitude diversity.\n\u2022 Jittering: Add random noise to samples, enabling the model to capture features that are invariant to minor corruption."}, {"title": "C. Transformer-Based Feature Extraction", "content": "Transformer captures connections between elements in a sequence and is considered an ideal approach for extracting local semantic information and analyzing connections among time steps. We leverage the patch time series Transformer (PatchTST) encoder [14] to capture comprehensive semantic information. We segment time series data into subseries-level patches and feed them to Transformer as input tokens. As shown in Fig. 1, we consider a collection of multivariate time series samples with look-back window L: (X1,..., XL), where each xt at time step t (t = 1,...,L) is a vector of dimension M representing values from M sensors. We split the multivariate input (x1,...,x\u2081) into Munivariate series, and denote the univariate series from the i-th sensor as"}, {"title": "D. Contrastive Meta-Learning", "content": "As demonstrated in Fig. 1, we propose a novel contrastive meta-learning approach to enhance representation learning and improve model generalizability. Motivated by [15], we simulate DS in the training of meta-learning by synthesizing virtual testing domains in each iteration. We split U source domains into (U \u2013 V) meta-train and V meta-test domains (virtual target domains) to mimic real DS. Our meta-optimization objective requires optimization steps improving performance in meta-train domains simultaneously improve performance in virtual target domains. Our meta-loss function incorporates supervised contrastive loss [16] with task-oriented classification loss to further ensure accurate HAR.\n1) Supervised Contrastive Loss: We employ the supervised contrastive loss function [16] nested within our meta-optimization to enhance the semantic discrimination of representations. We enlarge the inter-class distance, i.e., the distance between samples from different classes, and minimize the intra-class distance, i.e., the distance between samples from the same class for all the original and augmented samples. We randomly regard a sample as the anchor, and consider all the other samples in the same class positive of the anchor while all the others negative of the anchor. Mathematically,\nLsupcon = \u2212\u2211i\u2208I\u2211p\u2208P(i)logexp(zi\u22c5zp/\u03c4)\u2211a\u2208A(i)exp(zi\u22c5za/\u03c4)\u22121\nwhere I is the index set of the original and the augmented representations and the index i denotes the anchor. A(i) = I\\{i} is all the samples excluding the anchor, P(i) = {p \u2208 A(i) : yp = \u1ef9i} is the set of indices of the representations with the same label as the anchor, zp is the positive representation, and \u03c4\u2208 R+ is the scalar temperature. Note that we only consider samples from the (U - V) meta-train domains for meta-train and samples from the V virtual target domains for meta-test. Minimizing the distance between the original and augmented samples enables the model to capture intrinsic representations and become more robust against real-world DS. Additionally, with the presence of labels, supervised contrastive learning enhances the model's ability to learn class-discriminative representations and deliver accurate HAR.\n2) Task-Oriented Classification Loss: We utilize fully connected layers for human activity classification. We learn the model f: Xall \u2192 Y, where Xall includes the original and the augmented data and Y denotes the label space. We calculate the classification loss with cross-entropy, i.e.,\nLcls = \u2212\u2211i=1Cyi\u22c5log\u0177i\nwhere C denotes the number of classes, \u0177i denotes the output of the linear classifier for the i-th class and yi denotes the true binary indicator for the i-th class.\n3) Meta Optimization: Our meta-optimization loss function is defined as the combination of the supervised contrastive loss and the task-oriented classification loss, i.e.,\nLmeta(\u22c5) = \u03b7\u22c5Lcls(\u22c5) + (1 \u2212 \u03b7)\u22c5Lsupcon(\u22c5) (1)\nwhere \u03b7 is a hyper-parameter controlling the relative impact of the task-oriented classification loss and the supervised contrastive loss. Denoting the meta-train domains as S1, S2,..., SU-V and the model parameters as \u0398, in the meta-train stage, the model is updated on the meta-loss calculated with all the (U \u2013 V) meta-train domains, i.e.,\nLtrainmeta(\u0398) = 1U\u2212V\u2211i=1U\u2212V1|Si|\u2211j=1|Si|Lmeta(\u0398) (2)\nwhere Si denotes the number of samples in meta-train domain i (1 \u2264 i \u2264 S \u2013 V). The meta-train stage updates the model with a learning rate \u03b1, which can be formulated as\n\u0398\u2032 = \u0398 \u2212 \u03b1\u2202Ltrainmeta(\u0398)\u2202\u0398\nThe updated model is then evaluated on V virtual target domains in the meta-test stage, simulating testing on new domains with different data distributions. Denoting the virtual target domains as T1, T2,..., Tv, the loss of adapted parameters on the virtual target domains can be calculated as\nLtestmeta(\u0398\u2032) = 1V\u2211i=1V1|Ti|\u2211j=1|Ti|Lmeta(\u0398\u2032) (3)\nwhere |Ti| (1 \u2264 i \u2264 V) is the number of samples in the virtual target domain Ti. Note that the loss on the virtual target domain is calculated with the updated parameters \u0398' from meta-train. To enable optimization in both the meta-train and virtual target domains, the final loss function is defined as:\nL(\u0398) = Ltrainmeta(\u0398) + \u03b2\u22c5(Ltestmeta(\u0398\u2212\u03b1\u2202Ltrainmeta\u2202\u0398))\n(4)"}, {"title": "III. EXPERIMENTAL RESULT", "content": "A. Setup\nWe evaluate TACO on popular public HAR datasets including DSADS [17], PAMAP2 [18], and USC-HAD [19]. To construct DS scenarios, we randomly divide subjects into groups for leave-one-domain-out (LODO) evaluation. For DSADS and PAMAP2, we divide 8 subjects into 4 groups, each consisting of data from 2 subjects. For USC-HAD, we divide 14 subjects into 5 groups, where each of the first three groups contains 3 subjects and the last group contains 2 subjects. For LODO evaluation, we consider one group of subjects as the target domain and the remaining groups as source domains. In meta-learning, we split source domains into meta-train domains and virtual target domains in a similar LODO manner. To simulate low-resource scenarios in HAR, we construct training data by randomly sampling 20% to 100% data from source domains with a step of 20%, and evaluate the trained model on the target domain to show the robustness of TACO across various low-resource scenarios."}, {"title": "B. Network Architecture and Training", "content": "We conduct experiments on a Linux server with an Intel Xeon Silver 4310 CPU and an NVIDIA GeForce RTX 4090 GPU, and reproduce the result of each model following DomainBed [25]. TACO is implemented with PyTorch. For our Transformer encoder, denoting the look-back window as L and the patch length as L', we set L = 125 and L' = 16 for DSADS, L = 512 and L' = 64 for PAMAP2, and L = 500 and L' = 64 for USC-HAD. We set stride as 4 for DSADS, and as 8 for PAMAP2 and USC-HAD. Our Transformer encoder contains 3 layers with the head number H = 4, the dimension of latent space D = 32, and a dropout rate of 0.2. We apply a 1D convolutional layer (kernel size = 8) to"}, {"title": "C. Overall Performance", "content": "In TABLE I, we evaluate TACO in low-resource scenarios using only 20% of the training data. We regard each group of subjects, denoted as {To, T\u2081,...}, as a target domain and the remaining groups as source domains. We repeat each experiment 3 times with 3 different random seeds and report the mean and standard deviation of LODO classification accuracy. TACO exhibits notably higher accuracy and smaller standard"}, {"title": "D. Robustness in Low-Resource Scenarios", "content": "We evaluate the robustness of TACO by training our model with varying proportions of training data, i.e., {100%, 80%, 60%, 40%, 20%} of data samples from source domains, and evaluating the trained model with the target domain. For each dataset, we report the average performance of our model on different target domains for each training data proportion in TABLE II. With the decreasing amount of training data, while all models show performance degradation, TACO consistently exhibits notably better performance compared to existing works. This indicates TACO is considerably more robust to tackle DS across low-resource scenarios."}, {"title": "IV. CONCLUSION", "content": "We propose TACO, a novel transformer-based contrastive meta-learning approach to achieve robust and generalizable HAR in low-resource distribution shift scenarios, outperforming SOTA algorithms across various low-resource scenarios."}]}