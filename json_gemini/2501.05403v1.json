{"title": "TimeDP: Learning to Generate Multi-Domain Time Series with Domain Prompts", "authors": ["Yu-Hao Huang", "Chang Xu", "Yueying Wu", "Wu-Jun Li", "Jiang Bian"], "abstract": "Time series generation models are crucial for applications like data augmentation and privacy preservation. Most existing time series generation models are typically designed to generate data from one specified domain. While leveraging data from other domain for better generalization is proved to work in other application areas, this approach remains challenging for time series modeling due to the large divergence in patterns among different real world time series categories. In this paper, we propose a multi-domain time series diffusion model with domain prompts, named TimeDP. In TimeDP, we utilize a time series semantic prototype module which defines time series prototypes to represent time series basis, each prototype vector serving as \"word\" representing some elementary time series feature. A prototype assignment module is applied to extract the extract domain specific prototype weights, for learning domain prompts as generation condition. During sampling, we extract \u201cdomain prompt\u201d with few-shot samples from the target domain and use the domain prompts as condition to generate time series samples. Experiments demonstrate that our method outperforms baselines to provide the state-of-the-art in-domain generation quality and strong unseen domain generation capability.", "sections": [{"title": "Introduction", "content": "In the landscape of large models and advanced machine learning techniques, time series foundation models (Das et al. 2024; Gao et al. 2024) have garnered increasing attention. These models, typically trained on extensive datasets spanning various domains (Woo et al. 2024), have predominantly emphasized forecasting tasks rather than the generation of new data. However, the accurate and meaningful generation of time series is critical for applications such as medical record synthetic (Li, Yu, and Pr\u00edncipe 2023) and financial scenario simulations (Coletta et al. 2021; Huang et al. 2024), as well as for augmenting datasets where historical records are limited or incomplete (Kollovieh et al. 2023a). Although some research has been conducted on time series generation, most efforts have been confined to the development of generation model for single-domain data. In contrast, cross-domain time series generation presents a significantly more complex challenge, as it requires the creation of new data across various domains without relying on existing historical records. This stands out as a gap, underscoring a substantial opportunity for further advancements in multi-domain time series generation. One straightforward approach to multi-domain time series generation involves the use of predefined domain labels during the training process (Lee, Malacarne, and Aune 2023). This method relies on the availability of domain labels to formulate the conditional generation process. However, this approach may struggle generalizing to large number of domains or unseen domains. Moreover, the challenge intensifies when domain labels are not explicitly available. An alternative approach frames cross-domain time series generation as a conditional generation task by describing the domain using natural language (Jin et al. 2024; Jiang et al. 2024). However, the use of natural language descriptions introduces significant challenges. Domain-specific nuances are often difficult to articulate precisely, leading to noisy, incomplete, or ambiguous prompts. Moreover, for entirely new or evolving domains, crafting these domain descriptors can be impractical. This has underscored a critical need for a more systematic and robust way to represent and utilize domain-specific information in time series generation. To address these challenges, we propose a label-free, text-free method that learns time series prototypes as basic elements to construct domain prompts for generating time series with a diffusion model, named TimeDP. Through training, the prototypes learn to represent time series basis, serving as \"word\" with time series semantics. A prototype assignment module is applied for each training samples to construct the specific \"prompt\" for generating this sample. During sampling, we extract \u201cprompt\" with few-shot samples from the target domain to construct the population of domain prompts and use the domain prompts as condition to generate time series samples. To summarize, the main contributions of this paper are listed as follows:\n\u2022 We propose TimeDP, a multi-domain time series generation model by learning a set of time series prototypes and prototype assignment module to construct domain prompts, where the domain prompts serve as condition for a time series diffusion model."}, {"title": "Related Work and Backgrounds", "content": "Existing time series generation models has based on various foundational type of generative models. GAN-based methods has been introduced to encourage the network to consider temporal dynamic by jointly optimize both supervised and adversarial objectives for a learned embedding space (Yoon, Jarrett, and van der Schaar 2019). VAE-based methods have designed specific decoder structure for temporal data considering trend and seasonal decomposition (Desai et al. 2021), and first introduces vector quantization technique together with bidirectional transformers to better capture temporal consistency (Lee, Malacarne, and Aune 2023). Another category is considered as mixed-type methods, combining GANs, flows and ODEs (Jeon et al. 2022). Different from these methods, we utilize denoising diffusion probabilistic models (DDPM) as our generation backbone. Existing diffusion-based time series generation methods leverage both unconditional and conditional diffusion models for generating time series data with various denoising network backbones (Kollovieh et al. 2023b; Yang et al. 2024). Researchers have also considered combining diffusion models with the constrained generation problem (Coletta et al. 2023) and the extraction of time series intrinsic such as seasonal-trend decomposition techniques (Yuan and Qiao 2024). Compared with these single-domain methods, we first propose to utilize label-free, text-free domain prompts as condition for generating time series.\nThere have been several recent work consider utilizing multiple-domain time series data for training time series foundation models. These works can be divided into two branches. The first branch builds two-stage models. Kraus et al. (2024) pretrains a representation learning model on 75 datasets for the first stage and finetuning to task specific models at the second stage. Gao et al. (2024) conducts masked reconstruction pretraining on 38 multi-domain datasets for the first stage and a multi-task supervised learning for downstream tasks. The second branch pretrains end-to-end transformer models with patch tokenizers for time series forecasting. Woo et al. (2024) pretrains on a dataset with over 2B observations and Das et al. (2024) pretrains on a dataset with 100B time-points, both using patching and instance normalizing to unify across different data scale, frequencies and lengths. These methods employ instance normalization to generate forecasts based on historical data without explicitly addressing domain differences. Compared with these approaches, we propose to use time series prototypes, constructing domain prompts to explicitly distinguish domains as well as bridge them."}, {"title": "Denoising Diffusion Probabilistic Models (DDPMs)", "content": "A diffusion probabilistic model (Sohl-Dickstein et al. 2015) learns to reverse the transitions of a Markov chain which is known as the diffusion process that gradually adds noise to data, ultimately destroying the signal.\nLet $x_0 \\in R^d \\sim q(x_0)$ be real data of dimension $d$ from space $\\mathcal{X}$. The diffusion process generates $x_1,..., x_N$ from the same space with the same shape as $x_0$, using a Markov chain that adds Gaussian noise over $N$ time steps:\n$q(x_1, ..., x_N|x_0) := \\prod_{n=1}^N q(x_n|x_{n-1})$. The transition kernel is commonly defined as:\n$q(x_n|x_{n-1}) := \\mathcal{N}(x_n; \\sqrt{1 - \\beta_n}x_{n-1}, \\beta_n I)$, (1)\nwhere ${\\beta_n \\in (0,1)}_{n=1,...,N}$ defines the variance schedule. Note that $x_n$ at any arbitrary time step $n$ can be derived in a closed form $q(x_n|x_0) = \\mathcal{N}(x_n; \\sqrt{\\bar{a}_n}x_0, (1 - \\bar{a}_n)I)$, where $a_n := 1 - \\beta_n$ and $\\bar{a}_n := \\prod_{j=1}^n a_j$. For the reverse process, the diffusion model, parameterized by $\\theta$, yields:\n$p_\\theta(x_0, x_1, ..., x_N) := p(x_N) \\prod_{n=1}^N p_\\theta(x_{n-1}|x_n)$, (2)\nwhere $p_\\theta(x_{n-1}|x_n) := \\mathcal{N}(x_{n-1}; \\mu_\\theta(x_n, n), \\Sigma_\\theta(x_n, n))$ and the transitions start at $p(x_N) = \\mathcal{N}(x_N; 0, I)$. The optimization objective is derived into the maximizing of an approximation of the evidence lower bound (ELBO) of the log-likelihood $\\log p_\\theta(x_0)$. With a widely adopted parameterization:\n$\\mu_\\theta(x_n, n) = \\frac{1}{\\sqrt{a_n}} (x_n - \\frac{\\beta_n}{\\sqrt{1-\\bar{a}_n}} \\epsilon_\\theta(x_n, n))$, (3)\nthe training is performed to predict the noise term added in the forward process which simplifies the objective to:\n$L_{simple} := \\mathbb{E}_{x_0,\\epsilon,n} [||\\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{a}_n}x_0 + \\sqrt{1 - \\bar{a}_n}\\epsilon, n) ||^2]$. (4)\nOn sampling, $x_{n-1} = \\frac{1}{\\sqrt{a_n}} (x_n - \\frac{\\beta_n}{\\sqrt{1-\\bar{a}_n}} \\epsilon_\\theta(x_n, n)) + \\sigma_n z$, where $\\sigma_n = \\sqrt{\\beta_n}$ and $z \\sim \\mathcal{N}(0, I)$ (Ho, Jain, and Abbeel 2020).\nTypical time series diffusion models for forecasting task (Rasul et al. 2021; Shen and Kwok 2023; Fan et al. 2024) encodes history context into $\\epsilon$ as condition and make use of the conditional form of DDPMs (Ho and Salimans 2021) for generating future time series:\n$p_\\theta(x_0, x_1, ..., x_N|c) := p(x_N) \\prod_{n=1}^N p_\\theta(x_{n-1}|x_n, c)$, (5)\nIn the problem setting of time series generation, the generation process does not rely on time series history. We explore the use of term c to provide domain semantics for time series generation model in this work."}, {"title": "Problem Formulation", "content": "Let $D = {x_i \\in R^T}_{i=1}^{N_i}, x_i = (x_1, x_2, ..., x_T)$ denote a time series dataset domain i with $N_i$ time series samples, where each sample contains $T$ sequential values. A straightforward single-domain time series generation model fits the joint distribution over time steps $p(x_1, x_2, ..., x_T)$ of each dataset with a separate model parameterized by $\\theta_i$, namely $p_{\\theta_i} : (x_1, x_2, ..., x_T)$ for all $x$ in $D_i$.\nIn this paper, we explore a domain-unified setting where the mixture of M domain datasets with sequence length T is denoted by $D_T = \\cup_{i=1}^M D_i$ and we aim to build one model for the mixed dataset parameterized by $\\theta$, namely $p_\\theta(x_1, x_2, ..., x_T|i)$ for all $x$ in $D_T$.\nAdhering to the channel-independent setting (Nie et al. 2023) that is widely accepted by recent researches, we formulate the problem studied in this paper in a uni-variate time series generation manner to handle the heterogeneity of time series in terms of dimension (Woo et al. 2024)."}, {"title": "Methodology", "content": "With sequences from all data domains mixed together during training, all time series features within latent representation are entangled without a explicit way for distinguishing specific time series data domain. Although utilizing domain labels as class labels for training the time series generation model can provide instruction for identifying specific domain, this approach implies an assumption that all domains are independent from each other, neglecting the different similarity levels among domain pairs. Therefore, it is challenging to equip the model with the ability of generating time series in selected domain while considering the inter-relationship among domains. To overcome this challenge, the key is to build a triggering mechanism for cross-domain time series model that can control the model for generating time series data from specific domain. Motivated by the recent advancements in controllable content generation with prompting technique, we propose to construct domain prompts for controlling a cross-domain model.\nIn the rest of this section, we first describe the model architecture design. Then, we describe the optimization objective and training algorithm of the proposed model. Finally, we discuss the procedure for in-domain sampling and unseen domain generation using the proposed model."}, {"title": "Domain Prompts", "content": "Different from text and image modality where the generation target can be expressed by natural language or categorized into discrete classes, it is difficult to obtain explicit representation of time series with words or class labels. Inspired by the widely adopted technique to extract \u201cbasis\u201d which are the elementary features of time series (Ni et al. 2023), these basis can be utilized as the shared \u201cdictionary\u201d among different domains, each of which encodes different semantic feature for time series.\nEach basis represents certain elementary time series feature like trend and seasonality, that may exist in time series data samples. Different individual time series samples are assumed to share the same collection of basis but reflect distinct subset of the collection. As a result, each time series gets unique realization of these underlying features, similar to variable weighted allocations to all the basis. Based on this assumption, a set of latent arrays is introduced as time series prototypes $P \\in R^{N_p \\times d}$ for representing cross-domain time series common knowledge, where each prototype vector $p \\in R^{1 \\times d}$ serves as the representation of a time series basis. In practice, the time series prototypes $P$ are initialized with random orthogonal vectors and are frozen afterwards.\nGiven the assumption that each time series sample corresponds to a distinct allocation of all the basis, the mapping from time series samples to the allocations needs to be established for explicitly identifying important prototypes for each time series instance as well as distinguishing among domains. We propose to extract a prototype assignment for each time series instance as the importance weights of each time series on each prototype, and the prototype assignments then serve as conditions for the generation model.\nSpecifically, each input sequence $x$ is mapped into a weight vector whose dimension equals to the number of prototypes using weight extractor $\\phi$, which is a neural network. The vector $f(x)$ represents the weight of each vector inside $P$, and the weights are utilized to modify the attention weight within the cross-attention mechanism so that the predicted noises are only conditioned on the assigned prototypes. Therefore, sequences from different domains are represented by different $m$ weighted combinations of the shared same set of time series prototypes. For ensuring sparsity on prototype assignments, all negative weights are discarded when conducting prototype assignment. Formally, the prototype assignments $m$ is extracted with the following formula:\n$m = \\phi(x_0) \\cdot I_{\\phi(x_0)<=0,\\infty}$, (6)\nwhere $I_{<0}$ is the indicator function of negative elements."}, {"title": "Domain-Unified Training", "content": "Instead of training individual model for each specific dataset, we train one model with data from multiple datasets at the same time for generating different domain data. Here, we treat each dataset as a separate domain. While data from each domain only represent limited fraction of possible data distribution, leveraging data from other domain can help model capture a more diverse time series data distribution.\nOther than taking the unconditional denoising diffusion objective stated in eq. (4), we employ the conditional denoising objective using c from eq. (5) as condition to make use of the encoded semantic context for denoising process, where the conditions are incorporated into the intermediate layers of noise prediction network by spatial attention.\n$Q^{(i)} = z^{(i-1)} \\cdot W_Q^{(i)}$, (7)\n$K^{(i)} = P \\cdot W_K^{(i)}, V^{(i)} = P \\cdot W_V^{(i)}$, (8)\n$z^{(i)} = FF(softmax(\\frac{Q^{(i)} K^{(i)T}}{\\sqrt{d}} + m) \\cdot V^{(i)})$, (9)\nwhere $z^{(i)} \\in R^{N \\times d}$ denotes the output of the $i^{th}$ last U-Net block. $W_Q^{(i)} \\in R^{d \\times d}, W_K^{(i)} \\in R^{d \\times d}$ and $W_V^{(i)} \\in R^{d \\times d}$ are learnable projection matrices applied on the sequence dimension. FF denotes feed forward layer. The attention output $z_{final}$ is followed by another feed forward network to produce final block output $\\hat{\\epsilon} = FF(z_{final})$.\nWith the conditional denoising mechanism described above, the denoising objective using $\\epsilon$-parameterization can be written and simplified into:\n$L_{cond} = \\mathbb{E}[||\\epsilon - \\hat{\\epsilon}||^2] = \\mathbb{E}_{x_0\\in D_T, \\epsilon \\sim \\mathcal{N}(0,I), n} [||\\epsilon - \\epsilon_{\\theta, P}(x_n, n, m) ||^2]$. (10)\nDue to the imbalance number of training samples across domain, we adopt a re-weight sampling method for making the probability equal for training on samples from each domain. Let $N_i$ denote the number of sample sequences in dataset i, we set the weight for sampling each sample of this dataset as $w_i = \\frac{1}{N_i} * |D_T|$, such that the probability for sampling sequence from each dataset is balanced. The pseudo code for training algorithm is shown at Algorithm 1."}, {"title": "Generation with Domain Prompt", "content": "To generate time series samples of selected domain after the domain-unified training on multiple datasets, we first extract domain-specific prototype assignments of a small random subset of training samples for the selected domain and group them into a distribution of domain prompt representing the selected domain. Let K denotes the number of selected samples from dataset i, the domain prompt is denoted by $m^{D_i} = {m_1, ..., m_K}$. By constructing the conditioning input, the model generates samples adhere to the selected domain while is not constrained by the general temporal patterns exhibited in the selected samples. When the number of expected generated samples is larger than K, we use a strategy of repeatedly generate with each assignment in K samples until the number of expected samples is satisfied. The sampling algorithm is described as Algorithm 2."}, {"title": "Unseen Domain Generation", "content": "Since the prototypes provide representations for time series basis, their representation ability is not restricted to the domains in training sets. Therefore, they can be utilized to represent unseen domain or datasets. For any unseen dataset or domain $D_j$ with respect to the training set, we can extract \u201cfew-shot\u201d samples $x_1^j, ..., x_k^j$ from the dataset to construct domain prompt $m^{D_j} = {m_1, ..., m_k}$, and then feed them into the model as condition to generate new samples of the required dataset."}, {"title": "Experiments", "content": "In this section, we provide empirical experiment results for our method using multiple real-world datasets. The experiment goal is to investigate on the following research questions: (a) How good is the quality of prompted generation on trained domain? (b) Can the learned prototype help the model generalize to unseen domains?"}, {"title": "Model Details", "content": "Architecture The denoising network of the diffusion model used in this paper is built with U-Net structure, with 4 up/down sampling blocks. Each up/down sampling block consists of 2 residual blocks and 1 cross-attention block, where each residual block contains two 1-D convolution layers and each cross-attention block uses 1-D convolution as input/output projection layers and uses 8 attention heads. There is a middle block containing two residual blocks and one attention blocks, placed after the down sampling blocks and before the up sampling blocks. There are also additional input and output blocks, each with one 1-D convolution layer. We use SiLU as the non-linear activation function in this module.\nFor the prototype assignment module, we use two 1-D convolution layers as feature extractor. Then there are another two 1-D convolution layers with residual connection, followed by a linear projection layer, as assignment generator producing final prototype assignment. All non-linear activation functions in this module are chosen to be ReLU."}, {"title": "Additional Results for Generation Quality Experiment", "content": "The additional marginal distribution distance score results for the generation quality experiment are shown in Table 4. Table 4 shows that TimeDP gets overall best result on the MDD metrics, obtaining the best score for 10 out of 12 datasets.\nTable 6, Table 7 and Table 8 show results for sequence lengths 24, 96 and 336 respectively. These results show that TimeDP consistently outperforms baselines when generating time series with different sequence lengths, verifying the robustness of TimeDP."}]}