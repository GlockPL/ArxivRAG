{"title": "Conformal Prediction as Bayesian Quadrature", "authors": ["Jake C. Snell", "Thomas L. Griffiths"], "abstract": "As machine learning-based prediction systems are\nincreasingly used in high-stakes situations, it is\nimportant to understand how such predictive mod-\nels will perform upon deployment. Distribution-\nfree uncertainty quantification techniques such as\nconformal prediction provide guarantees about\nthe loss black-box models will incur even when\nthe details of the models are hidden. However,\nsuch methods are based on frequentist probability,\nwhich unduly limits their applicability. We revisit\nthe central aspects of conformal prediction from\na Bayesian perspective and thereby illuminate the\nshortcomings of frequentist guarantees. We pro-\npose a practical alternative based on Bayesian\nquadrature that provides interpretable guarantees\nand offers a richer representation of the likely\nrange of losses to be observed at test time.", "sections": [{"title": "1. Introduction", "content": "Machine learning systems based on deep learning are in-\ncreasingly used in high-stakes settings, such as medical\ndiagnosis or financial applications. These settings impose\nunique constraints on the performance of these systems: we\nwant them to produce good outcomes in the aggregate, but\nalso do so fairly and with a guarantee of a low probability of\nharm. However, predictive models based on deep learning\ncan be difficult to interpret, and commercial models increas-\ningly tend to offer little information about the techniques\nused in training. This creates a new challenge: How can we\nflexibly and reliably quantify the suitability of a model for\ndeployment without making too many assumptions about\nhow the model was trained or in which settings it will be\nused?\nRecent research on quantifying uncertainty has employed\nmethods based on conformal prediction (Vovk et al., 2005),\nwhich aim to provide guarantees for model performance in a\ndistribution-free way. However, these techniques are based\non ideas from frequentist statistics, making it difficult to\nincorporate prior knowledge that might be available about\nspecific models. For example, in a particular setting we\nmight have access to some information about the distribution\nof the data that is likely to be encountered, and can construct\ntighter guarantees on the performance of models by making\nuse of this information. Moreover, they focus on controlling\nthe expected loss averaged over many unobserved datasets\nrather than focusing on the actual set of observations.\nIn this paper, we show how methods for guaranteeing model\nperformance can be understood and extended by viewing\nthem from a Bayesian perspective. We develop a framework\nin which we explicitly model uncertainty in the quantile\nvalues associated with particular observations, providing a\nnonparametric tool for characterizing possible distributions\nwhere the model might be deployed that is appropriately\nconstrained by observed data. This framework allows us to\ndraw upon methods from the fields of statistical prediction\nanalysis (Aitchison & Dunsmore, 1975) and probabilistic\nnumerics (Cockayne et al., 2019; Hennig et al., 2022) to\ndevelop guarantees that are interpretable and make adaptive\nuse of available information.\nWe show that two popular uncertainty quantification meth-\nods, split conformal prediction (Vovk et al., 2005; Pa-\npadopoulos et al., 2002) and conformal risk control (An-\ngelopoulos et al., 2024), can both be recovered as spe-\ncial cases of our framework. Our approach gives a more\ncomplete characterization of the performance of these ap-\nproaches, as we are able to determine the full distribution\nof possible outcomes rather than a single point estimate.\nSince our approach is grounded in Bayesian probability, we\ncan easily incorporate knowledge relevant to evaluating the\nperformance of these models when it is present, such as\nmonotonicity or distributional assumptions, while default-\ning to existing methods when absent. Our results show\nthat Bayesian probability, while it is often discarded due to\nthe apparent need to specify prior distributions, is actually\nwell-suited for distribution-free uncertainty quantification."}, {"title": "2. Background", "content": "Conformal prediction methods apply a wrapper on top of\nblack-box predictive models to be able to subject them to sta-\ntistical analysis. In order to generate meaningful predictions"}, {"title": "2.1. Distribution-free Uncertainty Quantification Techniques", "content": "Uncertainty quantification techniques provide guarantees\non the future performance of a black-box predictive model\nmapping inputs X to outputs Y based on a calibration set\nconsisting of X1,..., Xn and Y\u2081,..., Yn. Different ap-\nproaches do so in different ways. For more information\non these techniques, refer to Shafer & Vovk (2008) or An-\ngelopoulos & Bates (2023).\nSplit Conformal Prediction The goal of Split Conformal\nPrediction (Vovk et al., 2005; Papadopoulos et al., 2002)\nis to generate a prediction set or interval that contains the\nground-truth output with high probability. This is often\nexpressed in terms of the coverage level 1 \u2013 a. It relies on\na score function s(x, y) which measures the disagreement\nbetween a predictor's output and the ground truth.\nThe conformal guarantee is\n$Pr (Y_{n+1} \\in C(X_{n+1})) \\leq \\alpha,$\nwhere\n$C(X_{n+1}) = \\{y : s(X_{n+1},y) \\leq q\\}$\nand q is the $[(n+1)(1-\\alpha)]$ quantile of $s_{1} =$\ns(X1,Y1), ..., Sn = s(Xn, Yn). Here, C(Xn+1) is a\nprediction set or interval which aims to include the\nground-truth output.\nConformal Risk Control In Conformal Risk Control (An-\ngelopoulos et al., 2024), the goal is to generalize conformal\nprediction to more general loss functions that are mono-\ntonic functions of a single parameter \u5165. Conformal Risk\nControl (CRC) proceeds by viewing the coverage guaran-\ntee (1) as the expected value of a 0-1 loss. It is assumed\nthat the maximum possible value of the loss is B and that\nthe problem is \"achievable\" by design in that there exists\nsome setting Amax that satisfies the conformal guarantee.\nAdditionally, each loss function L\u2081(1) is assumed to be a\nmonotonic non-increasing function of \u5165. The guarantee\noffered by Conformal Risk Control is of the form\n$E (l(C_{\\lambda}(X_{n+1}), Y_{n+1})) \\leq \\alpha,$\nwhere\n$\\hat{\\lambda} = inf \\{ \\lambda: \\frac{1}{n} \\sum_{i=1}^n L_{\\lambda}(l_i) + \\frac{B}{n+1} \\} \\leq \\alpha ,$\nand $R_n(\\lambda) = \\frac{1}{n} \\sum_{i=1}^n L_{\\lambda}(l_i)$ is the empirical risk."}, {"title": "2.2. Bayesian Quadrature", "content": "Bayesian quadrature (Diaconis, 1988; O'Hagan, 1991) is\na general technique for evaluating integrals that allows for\nuncertainty in the integrand. It estimates the value of an\nintegral $\\int f(x) dx$ by the following four steps: (1) place\na prior p(f) on functions, (2) evaluate f at X1,X2, ..., Xn,\n(3) compute a posterior given the observed values of f by\nBayes' rule, and (4) estimate $\\int_a^b f(x)dx$. Suppose that\nf(xi) = yi for i = 1, 2, . . ., n. The posterior over f is\n$p(f | x_{1:n}, y_{1:n}) \\propto p(f) \\prod_{i=1}^n \\delta(y_i - f(x_i)),$\nwhere $\\delta(\\cdot)$ is the Dirac delta function. The posterior mean\nthen provides an estimate for the integral:\n$\\int_a^b f(x) dx \\approx \\int_a^b f_n(x) dx$, where\nf_n(t) = E(f(t) | X1:n, Y1:n).\nIt has been demonstrated that many classical quadrature\nprocedures such as the trapezoid rule can be recovered by\nplacing a Gaussian process prior on functions (Karvonen &\nS\u00e4rkk\u00e4, 2017)."}, {"title": "2.3. Summary and Prospectus", "content": "Bayesian quadrature provides an illustration of how a pri-\nmarily numerical method can be connected to Bayesian\ninference, and in doing so potentially admit additional in-\nformation about the underlying function that can be incor-\nporated via a prior distribution. In next section, we will\nsee how a similar approach can be applied to conformal\nprediction, identifying a Bayesian framework that repro-\nduces existing distribution-free uncertainty quantification\ntechniques. The challenge in doing so is that we want guar-\nantees of the style obtained from Bayesian models, but we\nwant to make the approach as general as possible in its\nassumptions about the underlying distribution. We solve\nthis problem via an approach inspired by probabilistic nu-\nmerics to construct a nonparametric characterization of the\nunderlying distribution based on the calibration set."}, {"title": "3. Decision-theoretic Formulation", "content": "In this section we show how split conformal prediction and\nconformal risk control can be formulated as instances of a\ngeneral decision problem.\nLet z = (z1,..., Zn) be a set of calibration data where each\nobservation zi = (xi, Yi) consists of an input and a ground\ntruth label. Let 0 denote the true state of nature that defines a"}, {"title": "4. Our Approach", "content": "We introduce our approach by reinterpeting conformal pre-\ndiction as a frequentist special case of a more general\nBayesian procedure. In order to do so, we borrow ideas from\nboth Bayesian quadrature (Diaconis, 1988; O'Hagan, 1991)\nand distribution-free tolerance regions (Guttman, 1970).\nBayesian quadrature (Section 2.2) solves a numerical in-\ntegration problem by placing a prior on functions and using\nBayesian inference to compute a distribution over the value\nof the integral. Distribution-free tolerance regions provide\na distribution over quantile spacings that holds regardless\nof the original underlying distribution. Putting these ideas\ntogether allows us to extend conformal prediction by pro-\nducing bounds on expected loss tailored to the actual losses\nobserved in the calibration set.\nThe remainder of this section is structured as follows. In\nSection 4.1, we discuss the relationship between risk control\nand Bayes risk. In Section 4.2, we describe a general ap-\nproach for using Bayesian quadrature to bound the posterior\nrisk. In Section 4.3, we make the quadrature \"distribution-\nfree\" by removing the dependence on a prior over functions.\nIn Section 4.4 we handle uncertainty in the evaluation loca-\ntions of the function by applying results that characterize\nthe spacing between consecutive quantiles. In Section 4.5,"}, {"title": "4.1. Bayes Risk", "content": "The risk R(0, \u5165) measures the expected loss for one who\nalready knows the true state of nature 0 but not the particular\ndata observed. However, in practical applications the situa-\ntion is reversed: we do know the observed data but there is\nuncertainty about the state of nature. Therefore, we want a\ndecision rule that protects against high loss for a range of\npossible 0. This idea is expressed as the integrated risk:\n$r(\\pi, \\lambda) = \\int R(\\theta, \\lambda) \\pi(\\theta) d\\theta,$\nwhere the prior \u03c0(\u03b8) \u2265 0 measures the relative importance\nof the different possible states of nature. It is well-known\nthat the minimizer of the integrated risk is the so-called\nBayes decision rule:\n$\\lambda^* \\stackrel{\\triangle}{=} argmin_\\lambda r(\\lambda | z),$\nwhere $r(\\lambda | z)$ is the posterior risk\n$r(\\lambda | z) = E(L_\\lambda | z) = \\int L(\\theta, \\lambda(z)) \\pi(\\theta | z) d\\theta,$\nand \u03c0(\u03b8 | z) \u03b1 \u03c0(\u03b8) f(z | \u03b8). Interestingly, the worst-case\nintegrated risk of a decision rule is identical to its maximum\nrisk (9)\n$r(\\lambda) \\stackrel{\\triangle}{=} sup_\\pi r(\\pi, \\lambda) = sup_\\theta R(\\theta, \\lambda) = R(\\lambda).$\nWe can therefore focus on bounding the worst-case inte-\ngrated risk r(\u03bb), since this will also bound the maximum\nrisk R(x)."}, {"title": "4.2. Reformulation as Bayesian Quadrature", "content": "We now turn our attention to finding A minimizing the pos-\nterior risk (18). Consider risks that can be expressed as the\nexpectation over individual losses:\n$L(\\theta, \\lambda) = \\int l(z_{new}, \\lambda) f (z_{new} |\\theta) dz_{new}.$\nIt is well-known that the expectation of a random variable is\nequal to the definite integral of its quantile function over its\ndomain (Shorack, 2000, p. 116). Consider the distribution\nfunction of individual losses induced by A for a particular\nvalue of 0:\n$F(l) \\stackrel{\\triangle}{=} Pr\\{l(z_{new}, \\lambda) \\leq l | \\theta\\}$"}, {"title": "4.3. Elimination of the Prior Distribution", "content": "In order to address the dependence of the posterior risk on\nthe prior \u03c0(K), we derive an upper bound on the posterior\nexpected loss. The bound takes the form of a weighted sum\nof the observed losses, where the weights are determined by\nthe spacing between consecutive quantiles.\nTheorem 4.1. Let t(0) = 0, t(n+1) = 1, and l(n+1) = B.\nThen\n$sup_\\pi E(L | t_{1:n}, l_{1:n}) \\leq \\sum_{i=1}^{n+1} u_i l_{(i)},$\nwhere ui = t(i) t(i-1).\nTheorem 4.1 is based on the definite integral of the \"worst-\ncase\" quantile function that is consistent with the observa-\ntions. This strategy eliminates the need to specify a prior\nor evaluate an integral over functions K. We now turn our\nattention to handling the uncertainty over the quantiles t1:n."}, {"title": "4.4. Random Quantile Spacings", "content": "We now appeal to a result about distribution-free tolerance\nregions that characterizes the distribution of spacings be-\ntween consecutive ordered quantiles. Knowledge of this"}, {"title": "4.5. Bound on Maximum Posterior Risk", "content": "Putting together Lemma 4.2 and Theorem 4.1 allows us to\nbound the maximum posterior risk.\nTheorem 4.3. Define l(i) to be the order statistics of\nl1,..., ln for i = 1,...,n and l(n+1) \u2261 B. Let L+ be\nthe random variable defined as follows:\n$U_1,..., U_{n+1} \\sim Dir(1, . . ., 1), L^+ = \\sum_{i=1}^{n+1} U_i l_{(i)}.$\nThen for any b \u2208 (-\u221e, B],\n$inf_\\pi Pr(L < b | l_{1:n}) \\geq Pr(L^+ < b).$\nTheorem 4.3 states that L+ stochastically dominates the\nposterior risk, which allows us to directly form upper confi-\ndence bounds as follows."}, {"title": "4.6. Recovering Conformal Methods", "content": "This perspective puts the previous distribution-free uncer-\ntainty techniques in a new light. Taking the expected value\nof L+, we find\n$E(L^+) = \\sum_{i=1}^{n+1} E(U_i) l_{(i)} = \\frac{1}{n+1} \\sum_{i=1}^{n+1} (l_i+B).$\nThe Conformal Risk Control decision rule (15) then is sim-\nply the infimum over \u5165 for which E(L+) < \u03b1.\nFor, split conformal prediction, the individual loss is defined\nas li = 1 \u2212 1{si \u2264 1}. Therefore, suppose that \u5165 = s(k)\u00b7\nThe expected value of L+ then becomes:\n$E(L^+) = \\frac{1}{n+1} (k + \\sum_{i=1}^{n+1} \\{1- \\mathbb{1}_{s_i \\leq s_{(k)}} \\}) $\n$= 1 - \\frac{k}{n+1}.$\nTherefore, E(L+) \u2264 a is satisfied whenever k \u2265 (n +\n1)(1-a), and in particular by $k^* = [(n+1)(1-a)]$. This\nrecovers (12) when [(n + 1)(1 \u2013 a)] \u2264 n."}, {"title": "5. Experiments", "content": "The primary goal of our experiments is to demonstrate the\nutility of producing a posterior distribution over the expected\nloss. We conduct experiments on both syntheticldata and\ncalibration data collected from MS-COCO (Lin et al., 2014).\nFor each data setting, we randomly generate M = 10,000\ndata splits. Each method is used to select A with the goal\nof controlling the risk such that R(0, 1) \u2264 a for unknown\n0. We compare algorithms on the basis of both the relative\nfrequency of incurring risk greater than a and the prediction\nset size of the chosen \u5165. The ideal algorithm would select\nA such that the relative frequency of exceeding the target\nrisk is at most a target failure rate of 1 \u03b2 = 0.05 while\nminimizing prediction set size.\nAs demonstrated in Section 4.6, our method recovers con-\nformal risk control by taking the expected value of L\u207a.\nTherefore, in order to demonstrate the effect of targeting a\nconditional guarantee (as opposed to a marginal one as in\nconformal risk control), we use our Bayesian quadrature-\nbased method to compute the decision rule based on the\none-sided highest posterior density (HPD) interval:\n$ \\lambda_\\text{hpd}^\\beta \\stackrel{\\triangle}{=} inf\\{ \\lambda: Pr(L^+ < a | l_{i:n}) \\geq \\beta \\},$\nby finding the corresponding critical values $b_\\beta$ according\nto (29) via Monte Carlo simulation of Dirichlet random\nvariates with 1000 samples."}, {"title": "5.1. Synthetic Data", "content": "Setup. In our synthetic experiments, we sample from a\nknown loss distribution so that we can directly compute the\nfrequency of excessively large risk. Here the loss distribu-\ntion is chosen to be a scaled binomial distribution, normal-\nized to have a maximum loss of B = 1 and probability of\nfailure set to 1 \u5165. This was simulated by computing\n$l(z_i, \\lambda) = \\frac{1}{K} \\sum_{k=1}^K \\mathbb{1}\\{V_{ik} > \\lambda\\},$\nwhere Vik ~ Uniform(0, 1) for i = 1,...,n and\nk = 1,..., K. This loss is therefore monotonically non-\nincreasing in A and achieves zero loss at Amax = 1. We set\nn = 10, K = 4, and a = 0.4.\nResults. Since the expectation of the loss (34) is 1 \u2013 \u03bb,\nany trial for which \u5165 < 0.6 constitutes a risk exceeding\nthe a threshold."}, {"title": "5.2. False Negative Rate on MS-COCO", "content": "We also compare methods on controlling the false neg-\native rate of multilabel classification on the MS-COCO\ndataset (Lin et al., 2014). The experimental setup mirrors\nthat used by Angelopoulos & Bates (2023, Section 5.1).\nEach random split contains 1000 calibration examples and\n3952 test examples. We also include Risk-controlling Pre-\ndiction Sets (RCPS) (Bates et al., 2021) with Hoeffding\nupper confidence bound as an additional baseline. The re-\nsults of this experiment are summarized in Table 5.2."}, {"title": "6. Discussion", "content": "Our results in Table 5.1 demonstrate that even though the\nConformal Risk Control marginal guarantee holds, a sig-\nnificant number of individual trials (20.92%) may incur\nrisk exceeding the target threshold. In contrast, by using\nthe more conservative HPD criterion, very few of the trials\n(0.11%) exceeded the target risk. This points to the quali-\ntative difference in a marginal guarantee, which averages\nover an \"imaginary population\u201d of unobserved data sets vs.\na conditional guarantee which focuses on knowledge about\nthe state of nature conditioned on the calibration data ac-\ntually observed. These results are confirmed in Table 5.2\non MS-COCO, which show that the marginal guarantees of\nConformal Risk Control lead to an even greater percentage\nof trials exceeding the risk threshold. On the other hand,\nRCPS is able to control the risk but this comes at the cost of\nlarger prediction sets. Our approach successfully balances\nthese two concerns. It is also clear that the distribution of\nthe expected loss upper bound L+ in Figure 4 provides a\nmore complete view of the range of possible losses and\nits dependence on A, a perspective that is not offered by\nprevious methods.\nThe limitations of our method lie primarily in the two main\nassumptions it makes. First, it assumes that the data at\ndeployment time are independent and identically distributed\nto the calibration data. Second, it assumes an upper bound\nB on the losses. If either of these assumptions do not hold,\nthen the guarantees produced by our method are no longer\nvalid. Additionally, the bounds produced by our method\nare conservative in the sense that they hold for any choice\nof prior for the loss distribution (provided that the prior is\nconsistent with the calibration data). Therefore, if the two\naforementioned assumptions do hold, the actual loss values\nmay be significantly less than indicated by our method.\nOverall, our approach demonstrates how conformal pre-\ndiction techniques can be recovered and extended using\nBayesian probability, all without having to specify a prior\ndistribution. This Bayesian formulation is highly flexible\ndue to its nonparametric nature, yet is amenable to incorpo-\nrating specific information about the distribution of losses\nlikely to be encountered. In practical applications, maximiz-ing the risk with respect to all possible priors may be too\nconservative, and thus future work may explore the effect\nof specific priors on the risk estimate."}, {"title": "7. Related Work", "content": "Statistical Prediction Analysis. Statistical prediction\nanalysis (Aitchison & Dunsmore, 1975) deals with the use\nof statistical inference to reason about the likely outcomes\nof future prediction tasks given past ones. Within statistical\nprediction analysis, the area of distribution-free prediction\nassumes that the parameters or the form of the distribu-\ntions involved cannot be identified. This idea can be traced\nback to Wilks (1941), who constructed a method to form\ndistribution-free tolerance regions. Tukey (1947; 1948) gen-\neralized distribution-free tolerance regions and introduced\nthe concept of statistically equivalent blocks, which are anal-\nogous to the intervals between consecutive order statistics\nof the losses. Much of the relevant theory is summarized\nby Guttman (1970), and the Dirichlet distribution of quan-\ntile spacing is discussed by Aitchison & Dunsmore (1975).\nWe build upon these works by connecting them to Bayesian\nquadrature and applying them in the more modern context\nof distribution-free uncertainty quantification.\nBayesian Quadrature. The use of Bayesian probability to\nrepresent the outcome of a arbitrary computation is termed"}, {"title": "8. Conclusion", "content": "Safely deploying black-box predictive models, such as those\nbased on deep neural networks, requires developing meth-\nods that provide guarantees of their performance. Existing\ntechniques for solving this problem are based on frequen-\ntist statistics, and are thus difficult to extend to incorporate\nknowledge about the situation in which models may be de-\nployed. In this work we provided a Bayesian alternative\nto distribution-free uncertainty quantification, showing that\ntwo popular existing methods are special cases of this ap-\nproach. Our results show that Bayesian probability can be\nused to extend uncertainty quantification techniques, mak-\ning their underlying assumptions more explicit, allowing in-\ncorporation of additional knowledge, and providing a more\nintuitive foundation for constructing performance guaran-\ntees that avoids overly-optimistic guarantees that can be\nproduced by existing methods."}, {"title": "A. Theoretical Preliminaries", "content": "We first review some relevant aspects of our problem setup.\nLoss Function. We assume an upper bound on the losses: li \u2208 (\u2212\u221e, B] for i = 1, . . ., n. We assume the same upper\nbound for lnew.\nBayesian Quadrature of Quantile Functions. Recall Bayes rule for quantile functions:\n$p(K | t_{1:n}, l_{1:n}) \\propto \\pi(K) \\prod_{i=1}^n \\delta(l_i - K(t_i)),$\nwhere \u03b4 is the Dirac delta function. The prior \u03c0(K) is assumed to be sufficiently expressive to have nonzero measure for the\nset Kn of quantile functions such that K(ti) = li for i = 1, . . ., n and K \u2208 Kn. This is necessary to prevent the posterior\ndistribution in (35) from becoming degenerate."}, {"title": "A.2. Background", "content": "We begin by recalling some basic properties of distribution functions and quantile functions.\nProposition A.1 (Properties of Distribution Functions (Shao, 2003, p. 4)). Let F(x) = Pr(X < x) be a distribution\nfunction. Then F(-\u221e) = limx\u2192\u221e F(x) = 0, F(\u221e) = limx\u2192\u221e F(x) = 1, F is nondecreasing (i.e., F(x) < F(y) if\nx \u2264 y), and F is right continuous (i.e., limy\u2192x,y>x F(y) = F(x)).\nLet F be a distribution function and K(t) = F-1(t) = inf{x : F(x) \u2265 t} be the corresponding quantile function.\nProposition A.2 (Quantile Functions are Nondecreasing). If t < u, then K(t) < K(u).\nProof. Since u > t, it follows that {x : F(x) \u2265 u} \u2286 {x : F(x) \u2265 t}. Taking the infimum of both sides yields\n$inf\\{x: F(x) \\geq u\\} > inf\\{x : F(x) \\geq t\\} \\Rightarrow K(u) \\geq K(t).$\nWe also will make use of the probability integral transformation, which we state here for convenience.\nProposition A.3 (Probability Integral Transformation (Shorack & Wellner, 2009, p. 5)). If X has distribution function F,\nthen\n$Pr(F(X) \\leq t \\leq t$\nfor all 0 \u2264 t \u2264 1,\nwith equality failing if and only if t is not in the closure of the range of F. Thus if F is continuous, then T = F(X) is\nUniform(0, 1)."}, {"title": "B. Proof of Results from the Main Paper", "content": "Recall that Lscp(0, 1) is the miscoverage loss:\n$L_{scp}(0, \\lambda) = Pr\\{s(z_{new}) > \\lambda\\}$\n$= 1 - Pr\\{s(z_{new}) \\leq \\lambda\\}$\n$=1- \\int \\mathbb{1}\\{s(z_{new}) \\leq \\lambda\\}f(z_{new} |\\theta) dz_{new},$\nwhere s is an arbitrary nonconformity function."}, {"title": "B.1. Proof of Proposition 3.1", "content": "Proposition 3.1. Define si \u2261 s(zi) for i = 1, . . ., n and let s(1) \u2264 s(2) \u2264 ... \u2264 s(n) be the corresponding order statistics.\nLet Ascp be the following decision rule:\n$A_{scp} =$\n$\\begin{cases}\ns_{[(n+1)(1-\\alpha)]}, & \\text{if } [(n + 1)(1 - \\alpha)] < n \\\\\n\\infty, & \\text{otherwise}.\n\\end{cases}$\nThen Ascp is an a-acceptable decision rule for the miscoverage loss Lscp defined in (11).\nProof. By Lei et al. (2018, Section 2),\n$Pr(s_{new} \\leq q_{1-\\alpha}) \\geq 1 - \\alpha,$\nwhere\n$q_{1-\\alpha} =$\n$\\begin{cases}\ns_{[(n+1)(1-\\alpha)]} & \\text{if } [(n + 1)(1 - \\alpha)] \\leq n \\\\\n\\infty, & \\text{otherwise}.\n\\end{cases}$\nBut Lscp(0, 1) = 1 - Pr(snew \u2264 X | \u03b8), so for \u5165 = 91-a, R(0, Ascp) < \u03b1. This statement not depend on 0, and so\nR(Ascp) < \u03b1."}, {"title": "B.2. Proof of Proposition 3.2", "content": "Recall that the Lcrc is defined as:\n$L_{crc} (\\theta,\\lambda) = \\int l(z_{new},\\lambda)f(z_{new} | \\theta) dz_{new},$\nwhere l(znew, \u5165) is an individual loss function that is monotonically non-increasing in \u5165.\nProposition 3.2. Let Acrc be the following decision rule:\n$\\hat{\\lambda} = inf \\{ \\lambda: \\frac{1}{n} \\sum_{i=1}^n L_{\\lambda}(l_i) + \\frac{B}{n+1} \\} \\leq \\alpha \\}.$\nThen Acrc is an a-acceptable decision rule for Lcrc defined in (14).\nProof. Let L1,..., Ln, Ln+1 be an exchangeable collection of non-increasing random functions Li : A \u2192 (-infty, B].\nBy Angelopoulos et al. (2024, Theorem 1),\n$\\mathbb{E}[L_{n+1}(\\hat{\\lambda})] \\leq \\alpha,$\nwhere\n$\\hat{\\lambda} = inf \\{ \\lambda: \\frac{1}{n} R_n(\\lambda) + \\frac{B}{n+1} \\leq \\alpha \\}.$\nInterpreting these results using the notation from Section 3 of the main paper, we identify:\n\u2022 Li(x) = l(zi, 1) for i = 1, . . ., n and Ln+1(X) = l(znew, \u03bb),\n\u2022 Acrc is identical to \u00c2 from (43), and\n\u2022 (42) states that R(0, Acrc) \u2264 a for any \u03b8.\nTherefore, R(Acrc) = supe R(0, Acrc) < \u03b1."}, {"title": "B.3. Proof of Theorem 4.1", "content": "In order to prove Theorem 4.1", "problem": "n$I[f", "b": "where fa \u2264 ft. Then I[f", "I[f^*": "b \u2013 a) f_b$.\nProof. We apply Euler's method (Kot"}, {"b": "be divided into m+1 subintervals of equal width \u2206x\n$\\frac{b-a"}, {"\u03bek": "n$\\frac{\\partial I"}, {"becomes": "n$\\frac{\\delta I}{\\delta \\xi} = -2 \\xi.$\nSetting $\\frac{\\delta I}{\\delta \\xi} = 0$ yields \u03be(x) = 0, which recovers f(x) = fb"}]}