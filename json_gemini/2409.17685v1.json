{"title": "Artificial Data Point Generation in Clustered Latent Space for Small Medical Datasets", "authors": ["Yasaman Haghbin", "Hadi Moradi", "Reshad Hosseini"], "abstract": "One of the growing trends in machine learning is the use of data generation techniques, since the performance of machine learning models is dependent on the quantity of the training dataset. However, in many medical applications, collecting large datasets is challenging due to resource constraints, which leads to overfitting and poor generalization. This paper introduces a novel method, Artificial Data Point Generation in Clustered Latent Space (AGCL), designed to enhance classification performance on small medical datasets through synthetic data generation. The AGCL framework involves feature extraction, K-means clustering, cluster evaluation based on a class separation metric, and the generation of synthetic data points from clusters with distinct class representations. This method was applied to Parkinson's disease screening, utilizing facial expression data, and evaluated across multiple machine learning classifiers. Experimental results demonstrate that AGCL significantly improves classification accuracy compared to baseline, GN and kNNMTD. AGCL achieved the highest overall test accuracy of 83.33% and cross-validation accuracy of 90.90% in majority voting over different emotions, confirming its effectiveness in augmenting small datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "THE performance of machine learning models heavily relies on the training dataset [1]. However, collecting a large amount of data is time-consuming and demands considerable resources. Unfortunately, many medical applications do not have enough data to properly train machine learning models. In many practical scenarios, where annotating labels extensively is labor-intensive or only limited datasets are accessible, machine learning models are prone to overfitting and poor generalization [2], [3].\nIn strict small dataset scenarios, the learner has access to a small number of labeled examples from each class, and the number of classes can also be quite small. In the fields of transfer learning, few-shot learning, and semi-supervised learning, several methods have been proposed. However, learning using small datasets is different from all three research areas. Methods designed to address strict small samples sce- narios cannot rely on transfer learning from large amounts of peripheral data. The problem can be notably alleviated by imposing a strong prior on the model. Unfortunately, in many medical applications, we face an unknown domain where such prior knowledge is not available. In the few-shot scenario, the learner has access to a large number of labeled examples from classes not participating in the current classification task, while in the semi-supervised scenario, the learner typically has access to a large number of unlabeled examples [4]-[6].\nData augmentation and data generation techniques are ef- fective strategies to address the issues of data scarcity [7]. Generating new synthetic samples is a valuable approach that enables models to generalize better and achieve higher accu- racy when encountering unseen data. Leveraging generative adversarial networks to enhance a limited training dataset is particularly attractive, especially now that highly powerful deep generative models are increasingly available. However, these models typically demand a substantial sample size to train effectively, leading to poor performance in scenarios with limited data [8].\nIn this paper, we introduce the Artificial Data Point Gen- eration in Clustered Latent Space (AGCL) as a solution to address the challenging problems of small medical datasets. The proposed method can be implemented as follows: first, perform feature extraction and then apply K-means clustering. We then assess the results of the clustering for class separation and, if necessary, perform re-clustering. Next, to introduce variety into the dataset, we create additional synthetic data points using the normal distribution based on each cluster's parameters. Finally, the updated dataset, which combines original and synthetic data, is used to train machine learning models for improved classification performance.\nThe aim of this study is to tackle the issue of limited training data in the medical field, which makes it challenging to develop an effective classification model. While our primary focus in this paper is on Parkinson's screening, our methodol- ogy can easily be applied to augmenting data in various other fields.\nThe rest of this article is structured as follows. Section II reviews related work. Section III outlines the methodology. Section IV describes the Dataset which we used for our exper- iments. Section V presents simulation results and discussions. Finally, Section VI concludes with key takeaways."}, {"title": "II. RELATED WORK", "content": "When it comes to working with small datasets, data aug- mentation appears to be one of the few unmatched methods to boost the efficiency of machine learning models. There are many augmentation methods used for image classification, including random rotation, mirroring, and the addition of Gaussian noise [9]. Heuristic methods such as Cutout [10] partially occlude a square area in each training process to affect the learned features, and Random Erasing [11] partially covers or replaces certain areas of an image. Although these methods are very useful, they may not yield the best results on very small datasets and can negatively affect classification. Blending is another significant method of data augmentation that involves combining images or regions of interest within a single image. For example, the CutMix [12] technique replaces deleted pixels with portions of other images to create a good combination. However, problems can arise with methods such as CutMix, as the pasted patches can clash with the background of the original image and differ semantically from it, causing confusion during label assignment in the training process.\nAutomatic augmentation [13] has seen significant ad- vancements, focusing on enhancing augmentation techniques through the use of reinforcement learning. This approach aims to automate the selection and fine-tuning of augmen- tation strategies, promising efficiency gains. However, a key challenge lies in the computational demands of the search algorithm to identify the optimal augmentation approach, particularly as data dimensions and model parameters increase. Feature augmentation represents another common approach to data enhancement, focusing on expanding learned features rather than the input space of the data. FitMatch [14] is one of the methods in this category which uses learned features to create different and elaborate transformations. Since FitMatch increases the number of features, this overloads the data dimensionality and the complexity of the models that would take more time to train when costs are incurred.\nAddressing the problem of small datasets, the Least-Square Generative Adversarial Network (LS-GAN) was proposed. This algorithm begins with the independence test on feature removal by correlation measures and eliminates features that are linearly associated with other features. Next the feature selection method of Burato is used which employ random forest algorithm for the enhancement of feature selection. Yet another and rather important aspect of the generative network in the adversarial least squares sense is that the least squares cost function is utilized in this case, which do not allow vanishing gradient to come through [15].\nSivakumar et al. [16] have introduced a modified mega-trend diffusion to address the issues of generating artificial samples for small datasets. The algorithm involves identifying the k nearest neighbors for each sample in the dataset using the k-Nearest Neighbor and then applying Mega-Trend Diffusion to estimate the domain ranges of the neighboring samples. This is a multifunctional approach that can be used to provide artificial data needed in other data-centric tasks other than used in image classification tasks.\nAlthough Oversampling [17] differs with the data gen- eration, its algorithms can be employe in this area. Wei et al. [18] introduce the Improved and Random Synthetic Minority Oversampling Technique (IR-SMOTE). In data pre-processing, the K-means algorithm is utilized to cluster both majority and minority class samples, enabling the removal of noise samples in the minority class based on a distance metric. Subsequently, the kernel density estimation technique is employed to dynamically assign the number of synthetic samples to each cluster within the minority class. Finally, a synthetic approach that considers the attributes of the data is introduced to generate a more diverse set of synthetic samples."}, {"title": "III. METHODOLOGY", "content": "As shown in fig 1, the general methodology of AGCL includes feature extraction, K-means clustering for grouping data samples, and assessment of the obtained clusters to identify class representation. The cluster evaluation is based on the separation criterion, with a threshold guiding the decision to further subdivide for improved class separation. These steps pave the way for the subsequent steps in the algorithm involved in data synthesis. The analysis of each part of the methodology is presented in the subsequent sections of the paper."}, {"title": "A. Feature Extraction and Clustering", "content": "In the first step, relevant features are extracted from the dataset. Let $X = {X_1,X_2, ..., X_n}$ be the dataset in the latent space. By K-means clustering, data points are organized into clusters $C = {C_1, C_2, ..., C_k}$. The K-means algorithm operates through an iterative process aimed at minimizing the total sum of distances between each point in a cluster and its centroid [19]. By computing the mean of data points, new cluster centroids are determined, resulting in an arrangement where data points align effectively with their respective clusters. Each cluster $c_j$ comprises data points $x_{i,j}$ where $i = 1,2,...,n_j$, with $n_j$ representing the number of data points in cluster $C_j$. Moreover, all the hyperparameters of K-means clustering algorithm are also hyperparameters of the proposed method particularly k the number of clusters. It is essential to select k appropriately, ensuring it is greater than the number of classes present in the dataset. The determination of the number of clusters should initially be done using techniques like the elbow method."}, {"title": "B. Cluster Evaluation and Re-Clustering Process", "content": "The next step involves identifying clusters containing points from a particular class. This evaluation aims to identify clusters that capture distinct classes within the dataset. When a cluster contains data points from only one class, it indicates that the cluster is homogeneous and well-separated from others, making it suitable for use in the generation step. However, if a cluster contains points from multiple classes, its quality needs to be evaluated further. For such mixed clusters, a separation criterion is applied to assess how well- separated the different classes are within the cluster. This helps decide whether the cluster should be further divided to improve its homogeneity. The separation criterion combines the Class Separation Metric (CSM) and entropy to provide a measure of cluster purity and class distribution.\nThe CSM for each cluster is defined as the ratio of inter- class separation to intra-class cohesion. Mathematically, it can be expressed as:\n$CSM(c_j) = \\frac{S_{inter}(c_j)}{C_{intra}(c_j)}$\nwhere\n$C_{intra}(c_j) = \\frac{1}{m(l_i)-1}\\sum_{l_i \\in L}\\sum_{x_i, x_k \\in l_i}||x_i - x_k||$\n$S_{inter}(c_j) = \\sum_{l_i,l_k \\in L \\atop l_i \\neq l_j} \\frac{1}{N_{l_i}N_{l_k}}\\sum_{x_i \\in l_i \\atop x_k \\in l_k}||X_i - X_k ||$\nThe measure $C_{intra}$ and $S_{inter}$ are calculated separately for each cluster containing points from multiple classes. $C_{intra}$ measures the average pairwise distance between all points with the same label within a cluster, where $n_i$ is the number of points in class l, and $||x_i - x_k||$ is the Euclidean distance between points within the same class. $S_{inter}$ measures the average pairwise distance between points in different classes $l_i$ and $l_k$, where $n_{l_i}$ and $n_{l_k}$ are the numbers of points in classes $l_i$ and $l_k$, respectively.\nA high CSM indicates that the clusters are well-separated in the feature space. This means that the average distance between data points from different classes is relatively large. This suggests that the classes are not heavily intermixed, and the data has some orders.\nFor each cluster, entropy can be calculated based on the distribution of class labels. A low entropy value indicates that most of the data points within the cluster belong to the same class, implying that the cluster is homogeneous. Conversely, a high entropy value suggests that the cluster contains a mix of different class labels, indicating that it is more heterogeneous or mixed.\nFor a given cluster $c_j$, the entropy $H(c_j)$ can be defined as:\n$H(c_j) = - \\sum_{l \\in L} p(l) \\log_2 p(l)$\nwhere p(l) is the probability of a point belonging to class l within the cluster. A low entropy value (close to 0) indicates that the cluster is mostly made up of data points from a single class, which is desirable for further dividing.\nFinally, the separation criterion combines CSM and entropy metrics to assess the quality of a cluster in terms of both spatial separation and label distribution. It is defined as:\n$Separation Criterion(c_j) = \\frac{CSM(c_j)}{H(c)}$\nA high separation criterion indicates that the cluster is well-separated in the feature space. This means that the data points belonging to different classes are far apart from each other.\nBy normalizing it, the separation criterion ranges between zero and one. Selecting a suitable threshold for the separation criterion check is vital. In cases where a cluster does meet the specified threshold, a re-clustering process is triggered to im- prove the grouping of data points and enhance the separation of classes within that cluster. This iterative evaluation and re- clustering process aims to optimize the clustering results and identify better different class patterns. If it is observed that a specific cluster requires splitting into smaller clusters, the number of clusters for that particular cluster should be set to the number of classes in the dataset.\nA threshold closer to one ensures fewer subdivisions in clustering, while a threshold closer to zero splits more existing clusters into smaller sub-clusters. For example, setting the threshold exactly at one would execute the K-means algorithm only once, while a threshold of zero would continue K-means clustering hierarchically until each cluster contains a single class.\nThis process is somewhat analogous to the bias-variance trade-off in machine learning. A threshold closer to one, resulting in fewer subdivisions, can be likened to higher bias. The model makes simpler assumptions about the data (fewer clusters), which might not capture all the nuances of the dataset. Conversely, a threshold closer to zero, leading to more subdivisions, can be compared to higher variance. The model makes more complex assumptions (more clusters), capturing more details and variations within the data, potentially leading to overfitting, as it may represent noise and subtle details too closely."}, {"title": "C. Synthetic Data Generation", "content": "Clusters that contain data points from a single class are deemed suitable for generating synthetic data. On the other hand, clusters that contain data points from multiple classes after assessing separation criterion are considered mixed and are typically discarded. We produce synthetic data points based on the estimated parameters of clusters containing points from a particular class using normal distribution. It depicts the process of obtaining new artificial data points starting with clustering radius and the center to fit the observed distribution.\nFor clusters with more than one data point, the cluster radius ($r_j$) is calculated based on the maximum distance between any point in the cluster and the cluster center (\u00b5j), plus a small augmentation factor proportional to the range of these distances. This ensures that the radius takes into account the spread of points around the center, while also allowing for a slight margin beyond the maximum distance. For clusters with only a single data point, the radius is set to a constant value, which is derived from the average standard deviation of the features, scaled by a small factor. Therefore, the radius rj for each cluster j is defined as:\n$r_j \\leftarrow \\begin{cases} 0.01 \\times \\sigma_j & \\text{if } nc_j == 1\\\\ max(D_{x,\\mu_j}) + 0.1 \\times (max(D_{x,\\mu_j}) - min(D_{x,\\mu_j})) & \\text{if } nc_j > 1 \\end{cases}$\n$\\sigma_j$ is the standard deviation of the j-th feature calculated based on the data points from the previous clustering step. This indicates that the variability is measured considering the feature distribution observed in the last iteration or phase of clustering. Also, $D_{x,\\mu_j}$ refers to the distance of each point $x \\in X_j$ from the cluster center $\\mu_j$.\nThe generation of synthetic data points involves sampling q artificial data points from a normal distribution centered at the cluster mean (\u00b5j), as depicted in Equation 7:\n$X_{new,g} \\sim \\mathcal{N}(\\mu_j, \\Sigma_j)$\n$\\Sigma_j$ represents the covariance matrix calculated based on the variance of $r_j$.\nThe number of synthetic data points generated in each cluster is proportional to $nc_j$, denoted by the coefficient a.\nq = a. ncj\nThe coefficient a controls the number of synthetic data points against the number of data points of the given set. It is flexible according to requirements of a specific dataset and clustering needs. This proportional augmentation approach makes it possible to assign more synthetic data points to areas of the input space that are densely occupied by training data points. By applying this customized augmentation strategy, the clustering algorithm is better equipped to handle outliers and variations in cluster sizes."}, {"title": "D. Dataset Update and Classification", "content": "The dataset is updated with the synthetic data points to form $X_{augmented} \\leftarrow X \\cup {X_{synth}}$, providing an enriched set of training data for machine learning models. Leveraging machine learning models on the updated dataset enables the classification tasks for identifying patterns and making predic- tions.\nIn summary, AGCL tackles the challenges of small medical datasets by combining feature extraction, iterative K-means clustering, and synthetic data generation. The augmented dataset, comprising both original and synthetic data points, is utilized to train machine learning models, enhancing their performance in classification tasks. Ultimately, the algorithm is presented generically in Algorithm 1."}, {"title": "IV. DATASET", "content": "Parkinson's disease is a prevalent clinical syndrome that be- longs to the group of neurodegenerative movement disorders, manifesting as progressive motor disability in the elderly. This condition is characterized by the progressive decay of nerve cells in the substantia nigra, a part of the brain, reducing the manufacture of dopamine, a chemical that plays an important role in the control of body movements [20]-[22].\nParkinson's disease significantly impacts the motor sys- tem, with key symptoms including bradykinesia, rest tremor, stiffness, and rigidity that often appear in the early stages of the condition. Bradykinesia is characterized by reduced and slowed movements, which can also affect the facial muscles in PD patients, making it challenging to produce facial expressions. This reduction in facial expression is commonly referred to as hypomimia or masked faces [23], [24]."}, {"title": "V. EXPERIMENTS", "content": "In this section, we evaluate the AGCL method in various scenarios. Our objective is to provide a thorough assessment of AGCL's performance under diverse conditions."}, {"title": "A. Feature Extraction and Latent Space", "content": "Utilizing Openface [27], we extracted action unit (AU) values for each participant's picture. Facial action units are linked to specific muscle movements of the face, with each unit corresponding to the movement of a distinct group of facial muscles. For example, activation of AU1 (also known as Outer Brow Raiser) indicates the simultaneous movement of two facial muscles - the frontalis and pars lateralis. The OpenFace software provides a binary activation (0 or 1) and a raw magnitude (ranging from 0 to 5) for each AU for every frame of a video containing a human face.\nA facial expression can be associated with multiple action units. In this paper, each facial expression is associated with three Aus by analyzing Aus' mean, concept of each AU associated with facial expression and Pearson Correlation. Table II shows the AUs associated with facial expressions."}, {"title": "B. Statistical evaluations", "content": "Three different tests were conducted to verify that the real data and synthetic data do not differ statistically. Twenty random samples were selected from each class of the two datasets (real and synthetic). The p-values for each test are shown in the table III. In the t-test [28], it is observed that the p-value is above 0.05 for all variables except one, indicating that the means of the two datasets are not signif- icantly different. Levene's test [29] was used to compare the variances between the datasets. The p-value is above 0.05 for all variables except one, suggesting that the variances are not statistically significant. Similarly, the most p-values from the Kolmogorov-Smirnov test (ks-test) [30] are also above 0.05, showing that the distribution of variables in the two datasets is not statistically significant. Therefore, we can conclude that the two datasets are statistically similar."}, {"title": "C. Classification", "content": "In the previous section, we analyzed the data statistically. In this section, we evaluate how the data behaves when subjected to machine learning algorithms for classifying Parkinson's and control data. A two-leave-out cross-validation method was applied to the training data, resulting in 25 unique folds. Each fold served as an independent subset for training separate models using the same hyperparameters. Throughout the cross- validation process, hyperparameter tuning was carried out to identify the optimal hyperparameters based on performance across all folds. The test data consisted of 11 control samples and 7 Parkinson's disease samples. Instead of selecting a single model, all 25 models generated during the cross-validation process were applied to the test data. Their predictions were aggregated using a weighted majority voting approach to produce the final classification.\nBy comparing the effectiveness of AGCL against baseline, perturbation mechanisms and kNNMTD [16], we aim to evaluate its performance in classifying facial expressions. The baseline approach serves as a reference point without any aug- mentation, providing a foundational measure of classification performance.\nIn contrast, the perturbation-based synthetic data generation mechanism is stated as: $x_s = x_i + e$ where e is a noise sampled from a certain distribution. According to Gaussian approach, e is sampled with N(0, \u03c3). This method usually utilizes n-way marginals for purposes of creating variability in the categorical features [31]. Therefore, we employed the Gaussian approach to add noise to each sample in the latent space. To elucidate the impact of different levels of noise, we consider a range of standard deviations (\u03c3= 0.001, 0.005, 0.01, 0.025, 0.05, 0.075, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 1]) to identify the optimal performance of Gaussian Noise (GN) for comparison with the AGCL method.\nMoreover, We estimated the number of generated data points in the cluster for AGCL through grid search, gradually testing the a value from 2 to 60 with a step size of 5.\nFor the rage emotion, AGCL demonstrated superior per- formance compared to other methods across all classifiers. The best validation accuracy was achieved using the MLP classifier, where AGCL reached 74.00%, whereas the baseline validation accuracy was lower at 66.00%. In the test results, AGCL also led with the highest accuracy of 76.92% with kNN, outperforming the other algorithms test accuracy of 69.23%.\nIn the happy emotion, AGCL achieved the highest valida- tion accuracy of 81.25% with MLP, significantly improving over the kNNMTD's validation accuracy of 68.75%. The test accuracy of 83.33% with both SVM and MLP shows the ef- fectiveness of AGCL in generating high-quality synthetic data that enhances classification performance, compared to the GN and kNNMTD. While AGCL performed well in test accuracy compared to the baseline and other augmentation methods, the overall improvement in cross-validation was less pronounced than in other emotions. The validation accuracy of 81.25% with RF and MLP showed moderate gains, which suggests that the happy expression might be easier for classifiers to distinguish even without extensive data augmentation.\nFor the disgust emotion, AGCL also led to noticeable perfor- mance improvements. The best validation accuracy of 84.00% was achieved using the Random Forest classifier. AGCL also reached a test accuracy of 76.92% with MLP, which is the best test accuracy across all four algorithms. The fear emotion further highlights the advantages of AGCL in small dataset classification. AGCL achieved the highest validation accuracy of 74.00% with the Random Forest classifier, while the GN struggled with only 66.00%. On the test set, AGCL achieved its best accuracy with MLP, reaching an outstanding 92.30%, far exceeding the other algorithms.\nIn the surprise emotion, AGCL continued to outperform the baseline and other methods. The highest validation accuracy was 84.00% with MLP for AGCL. In the test phase, AGCL again demonstrated strong performance, achieving 75.00% accuracy with MLP, surpassing the baseline's test accuracy of 62.50%. When results across all emotions were aggregated using majority voting, AGCL achieved the highest overall test accuracy of 83.33% with the MLP classifier. This marks a sig- nificant improvement over the other algorithms. The validation accuracy of 90.90% with Random Forest and 84.09% with MLP further confirms AGCL's effectiveness in augmenting small medical datasets and improving classification results."}, {"title": "VI. CONCLUSION", "content": "In this paper, we introduced the Artificial Data Point Gen- eration in Clustered Latent Space (AGCL) method to address the challenges of limited training data in medical applications, particularly in the classification of Parkinson's disease through facial expression analysis. By generating synthetic data points in a clustered latent space, AGCL enhances the performance of machine learning models in scenarios with small datasets. The framework employs feature extraction, K-means clustering, and a separation criterion to guide synthetic data generation, ensuring that only well-separated clusters contribute to data augmentation.\nExperimental results across multiple classifiers and emo- tions demonstrate that AGCL consistently outperforms base- line methods, as well as other data augmentation techniques like Gaussian noise and kNNMTD. AGCL achieved the high- est overall test accuracy of 83.33% through majority voting, confirming its effectiveness in improving classification in small datasets.\nAGCL's ability to generate synthetic data points tailored to the structure of the dataset offers significant advantages in enhancing the generalization capabilities of machine learning models. This method holds promise for broader applications in medical domains and other fields where data scarcity is a critical issue. Future work may explore the extension of AGCL to different datasets and further refinement of clustering techniques to increase its applicability across a wider range of tasks."}]}