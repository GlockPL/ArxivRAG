{"title": "Semantic Revolution from Communications to Orchestration for 6G: Challenges, Enablers, and Research Directions", "authors": ["Masoud Shokrnezhad", "Hamidreza Mazandarani", "Tarik Taleb", "Jaeseung Song", "Richard Li"], "abstract": "In the context of emerging 6G services, the re-alization of everything-to-everything interactions involving a myriad of physical and digital entities presents a crucial chal-lenge. This challenge is exacerbated by resource scarcity in communication infrastructures, necessitating innovative solutions for effective service implementation. Exploring the potential of Semantic Communications (SemCom) to enhance point-to-point physical layer efficiency shows great promise in addressing this challenge. However, achieving efficient SemCom requires overcoming the significant hurdle of knowledge sharing between semantic decoders and encoders, particularly in the dynamic and non-stationary environment with stringent end-to-end quality requirements. To bridge this gap in existing literature, this paper introduces the Knowledge Base Management And Orchestration (KB-MANO) framework. Rooted in the concepts of Computing-Network Convergence (CNC) and lifelong learning, KB-MANO is crafted for the allocation of network and computing resources dedicated to updating and redistributing KBs across the system. The primary objective is to minimize the impact of knowledge management activities on actual service provisioning. A proof-of-concept is proposed to showcase the integration of KB-MANO with resource allocation in radio access networks. Finally, the paper offers insights into future research directions, emphasizing the transformative potential of semantic-oriented communication systems in the realm of 6G technology.", "sections": [{"title": "I. INTRODUCTION", "content": "In the foreseeable future of 6G communication systems, connections are expected to expand to everything-to-everything interactions within platforms like the Metaverse, involving diverse physical and digital objects continually engaging, traversing, and coexisting. A consequential outcome of deploying such immersive environments is the continual proliferation of connected objects, leading to significant increases in upstream traffic. Predictions suggest that 6G will be linked to highly dense environments with a considerable number of entities and a substantial volume of global data, of which a significant portion will be routed to computing resources, particularly for services such as telemedicine, holographic teleportation, immersive learning, precision agriculture, smart supply chaining, and intelligent transportation. These services necessitate rigorous End-to-End (E2E) Quality of Service/Experience (QoS/QoE) prerequisites, encompassing requirements such as microsecond-level latency, bounded jitter, multi-gigabit-level throughput, ultra-high reliability, exceptionally high computing capacity, and superior energy efficiency [1], as illustrated in Fig. 1.\nTo meet the substantial demand with stringent performance requirements, the scarcity of infrastructure resources emerges as a significant challenge. To tackle this challenge, there has been notable interest in a recent paradigm, recognized as Semantic Communications (SemCom). This paradigm extends beyond the conventional Shannon paradigm (which primarily optimizes opaque data pipes aiming to reproduce exactly exchanged sequences of symbols) and centers on effectively inferring the meaning of what has been communicated. This process is facilitated through the utilization of background and contextual knowledge, known as Knowledge Bases (KBs), shared a priori between communicating parties necessary for achieving a predefined shared view on the goal of communication [2]. To facilitate this, the sender and receiver engage in semantic encoding/decoding (transcoding), as detailed in Fig. 2. This semantic shift promises a ubiquitous connection"}, {"title": "II. FUNDAMENTALS, CHALLENGES, & ENABLERS", "content": "lacks a real-time and systematic approach to address the chal-lenge of KB management, particularly tailored to the structure of 6G and its ever-fluctuating services. To address this gap, we first describe future 6G systems and their components in Section II, highlighting the most challenging aspects of enabling SemCom: KB refinement and KB arrangement. Subsequently, we introduce the KB Management And Orchestration (KB-MANO) framework in Section III, designed for the allocation of network and computing resources dedicated to updating and redistributing KBs across the system. The primary objective is to minimize the impact of knowledge management on actual service provisioning. Given that KB-MANO is grounded in the principles of Computing-Network Convergence (CNC) and lifelong learning, this section also delves into strategies suitable for KB updating across various scenarios. Section IV features a proof-of-concept scenario evaluating the efficiency of semantic-aware orchestration enabled by KB-MANO, followed by an exploration of open research directions in Section V. The paper concludes in Section VI, summarizing key findings and implications.\nA. Service Provision over Integrated 6G\nIn the context of 6G systems, decentralized computing resources extend across in-network, edge, regional, and central nodes dispersed across vast geographical areas. These nodes interconnect through diverse networking technologies in radio access, transmission, and core network sub-domains, featuring varied network devices and links. Provisioning future services over such infrastructures necessitates precise resource orchestration. A Metaverse scenario depicting users participating in a holographic presence service within a virtual conference room by a live lakeshore is illustrated in Fig. 3. The service integrates rendering, motion tracking, stereoscopic 3D display, and audio spatialization functionalities. To bring this experience to life, the software instances of these functionalities should be loaded onto available computing nodes. Subsequently, users' video, audio, and motion data are transmitted to the instances through their designated network paths. These instances collaborate in accordance with a predetermined order specified in the service's function chaining map. Following that, the generated rendered content is transmitted back to users' devices, such as headsets. Throughout these processes, strict compliance is maintained with factors such as the QoS/QoE requirements of the service (as delineated in Fig. 1) and the availability of resources.\nB. Semantic Mastery in Orchestration\nIn the context of SemCom for future extensive-scale ser-vices, users employ semantic encoders to compress data into semantic segments (or semantics), transmitting these semantics instead of raw bulk data to their designated instances. The instances, in turn, utilize semantic decoders to reconstruct the intended output. In scenarios such as holographic conferences, spatial, visual, and auditory semantics\u2014including positioning, gestures, and ambient sounds are extracted using semantic encoders, and semantic decoding captures user interactions"}, {"title": "C. Semantic Costs in Play", "content": "In achieving effective semantic-aware provision and orches-tration, a significant challenge arises from the dynamic nature inherent in future systems. To comprehend this dynamism, consider the holographic meeting scenario, wherein the ever-changing nature of interactions is influenced by a multitude of sources. For instance, users may fluidly transition between various roles, each accompanied by distinct QoS require-ments, or they may modify their receivers, evolving their QoE standards for immersive experiences across each receiver. Additionally, physical mobility at varying speeds introduces changes in users' connection points to the system. Considering the temporal fluctuations in 6G resources, distributed across diverse domains and operating under different supervisions, two primary challenges are anticipated: knowledge refinement"}, {"title": "D. The Era of Intelligent Integration", "content": "Addressing knowledge refinement involves utilizing the concept of lifelong learning, which accommodates a theoreti-cally unlimited number and variety of tasks, segregating train-ing procedures for different contexts by assigning each one to a task. This results in the long-term applicability and coherence of trained tasks for recurring scenarios, diminishing the need for frequent retraining, as well as the effectiveness of training from scratch for new situations. The approach mitigates the environmental impact and computational overhead associated with traditional ML techniques. In the realm of SemCom, this proves advantageous for adeptly managing emerging sit-uations. For instance, in the holographic meeting scenario, lifelong learning can be applied to 1) dedicate an individual task to maintain each existing KB updated with changes in data streams (such as emerging words and meanings in supported languages) and 2) initiate new tasks in response to the demand for new KBs (such as the introduction of new data streams facilitated by emerging user-side technologies)."}, {"title": "III. PROPOSED FRAMEWORK", "content": "Another crucial enabler is the concept of CNC. In the con-text of the integrated infrastructure of 6G, consisting of distinct computing and network domains, CNC aims to orchestrate diverse domain resources collectively, establishing network-aware, detectable, assignable, and schedulable computing re-source pools. By actively monitoring computing and network domains in real-time and discerning system-wide states, the CNC E2E orchestrator adeptly allocates resources for each domain, facilitated not only by leveraging its own domain state but also by incorporating the state information from the other domain. This dynamic adjustment considers changes in net-work accessibility, availability, and computing capacity quality [13], stemming from factors like dynamic traffic patterns or administrative restrictions imposed by different domains or regions. Employing the CNC concept ensures that data collection, the training process for KBs, and subsequent dis-tribution among users, instances, and entities making resource allocation decisions are conducted with careful consideration to prevent overloads on actual network traffic and running services.\nA. The System Model\nTo enable semantic-aware provision and orchestration for 6G's dynamic, massive-scale services with stringent QoS/QoE requirements, we consider a system equipped with integrated computing and network resources, referred to as the infrastructure. Within this system, service providers (like those facilitating the holographic meeting scenario) register services, encompassing functional instances (e.g., rendering, motion tracking, etc.). The registered services incorporate SemCom, enabled by their corresponding KBs, and introduce their own lifelong learning tasks (or simply, training tasks) that ensure KBs remain updated. Users initiate requests to access the registered services within the system, establishing E2E connections that manage the transmission of semantics to the instances of their requested services. Processed data (such as a live-rendered holographic meeting scene) is then delivered back to users. Resource allocation for service instances and user requests occurs through the multi-layer, CNC-empowered resource orchestration framework, named CNCO, implement-ing decisions at the network's edge devices, named the Points of Arrival (PoAs), the entry points for requests into the system. CNCO employs KBs associated with each service at PoAs to comprehend the transmitted semantics, integrating them into its decision-making process.\nB. KB-MANO\nConsidering the system model and adhering to the defined challenges of knowledge refinement and arrangement, we intend to optimize the allocation of network and computing resources for updating and (re)distributing KBs throughout the system. This ensures that users, service instances, and PoAs have access to the latest KBs, aiming to minimize the impact of knowledge management and orchestration activities on actual service provisioning. To achieve this objective, we propose the KB-MANO framework, which addresses knowledge re-finement by incorporating KB training strategies enabled by lifelong learning and dynamically switching between them based on available resource information received from CNCO. Additionally, it handles knowledge arrangement by managing the organization of KB distribution among users, instances, and PoAs through proactive measures initiated by service-level QoS/QoE degradation thresholds, guided by monitoring information provided by CNCO. The components of KB-MANO are categorized into three distinct layers: E2E, Domain, and Resource, as depicted in Fig. 4 and elaborated upon in the following subsections.\n1) E2E layer:\nThe E2E layer assumes the responsibility of high-level decision-making related to knowledge refinement and ar-rangement. Its initial function involves gathering computing and network utilization data from CNCO's E2E orchestrator, which is then stored in the Memory Bank over time. Addi-tionally, performance metrics for active services across all users are received from CNCO. Note that the collection of this information is conducted anonymously to uphold user privacy. The Workload Analyzer component accumulates this historical data over the last $T_e$ time slots, predicts future utilization patterns across computing and network domains, and anticipates QoS/QoE trends for each active service. The derived insights are subsequently stored in the memory bank. Evidently, $T_e$ (the history window size) is adjustable, catering to the dynamics of the system. Smaller window sizes capture recent fluctuations with computational efficiency, while larger window sizes yield more stable predictions using more complex prediction models. ML techniques, such as explainable Long Short-Term Memory (XLSTM) and transformers, are employed to analyze historical and temporal data, enabling the forecasting of future states.\nNow, the KB Refinement Manager relies on present and anticipated resource states to allocate resources for KB updates. This entails two primary steps: selecting a KB training strategy, which assesses the suitability of distributed versus centralized processing based on current and future resource availability (elaborated in Section III-C), and subsequently placing the KB training tasks on computing resources while establishing network paths for data transmission from users to the assigned computing nodes. As these training tasks are implemented and executed by the service provider (for example, the entity in charge of the holographic meeting setup), the data remains in their custody, alleviating privacy concerns.\nThe conclusive module, designated as the KB Deployment Manager, is tasked with disseminating the latest KB versions to users, service instances, and PoAs. The distribution process hinges on predetermined QoS/QoE thresholds for active services and the current and anticipated network resources. A heightened sensitivity to slight quality alterations prompts increased network resource utilization for KB distribution, ensuring continual updates across the system. Conversely, adopting more lenient thresholds leads to reduced network consumption, albeit potentially resulting in less precise semantic transcoding."}, {"title": "2) Domain Layer:", "content": "The Domain layer oversees intra-domain resource allocation for knowledge refinement and arrangement. In the network domain, historical data on the availability of the network graph is received from CNCO's network orchestrator and stored in the Memory Bank, along with usage predictions from the domain-level Workload Analyzer. The history window size in this layer ($T_d$) can be set smaller than $T_e$ to capture transient changes with reduced complexity. Based on the strategy chosen by the KB Refinement Manager and current and predicted network usage, the Domain KB Manager adjusts network paths for data transmission (between users and the allocated computing nodes) and KB distribution. In the absence of a feasible network path for either conveying user data or distributing the latest KBs, this module prompts the E2E layer to reassess its chosen strategy, optimizing it to align with the current network conditions. Path feasibility is compromised when the necessary bandwidth surpasses the thresholds established to protect actual network traffic. Another factor is the excessive latency of bandwidth-feasible paths, preventing the timely update of KBs within the predefined time constraints dictated by the QoS/QoE requirements of their associated services. The computing domain mirrors this process, readjusting computing capacity for assigned tasks."}, {"title": "3) Resource Layer:", "content": "The Resource layer manages resource allocation for knowl-edge refinement and arrangement across network devices and computing nodes. It gathers availability information from var-ious resource elements, predicts their future states, and stores this data in the resource Memory Bank. The history window size in this layer ($T_r$) is kept minimal to reduce resource consumption during the prediction process and capture subtle resource-level fluctuations. Subsequently, the Resource KB Manager utilizes this information to dynamically adjust the capacity allocated for KB refinement and/or arrangement. On network devices, this adjustment includes (re)allocating bandwidth for transmitting user data from users to training tasks or prioritizing traffic for distributing the latest KBs from training tasks to users, service instances, or PoAs. On computing nodes, the adjustment entails (re)scaling allocated computation, memory, and storage capacity for training tasks or migrating them to nodes accessible via the assigned network paths. In cases of infeasibility, the Domain layer is notified by the KB Refinement Resource Manager to reallocate resources at the domain level.\nC. KB Training Strategies\nConcerning the system state, which denotes the current availability and the predicted availability of resources for future time slots, the KB Refinement Manager in the E2E layer can adopt various strategies for updating KBs. As illustrated in Fig. 5, the most favorable strategies include:\n1) Centralized Training:\nThe straightforward strategy is to treat each KB's training tasks as an atomic operation and place them on computing nodes, either at the network edge or in core data centers, to"}, {"title": "IV. PERFORMANCE EVALUATION", "content": "In this section, we present a proof-of-concept scenario designed to assess the effectiveness of the KB-MANO framework in facilitating semantic-aware orchestration. Specifically, we investigate a radio cell served by a Small Base Station (SBS), where $N$ intelligent users contend for access to $C$ time-slotted uplink channels allocated to the SBS. Collisions occur when multiple users attempt to transmit data over the same channel within the same time slot. The aim is to illustrate that by enabling users to extract semantic information from their transmitted data and subsequently sharing this knowledge with the SBS through the implementation of KB-MANO, the semantic throughput (or simply throughput), defined as the number of successful semantic transmissions, can be improved. To accomplish this, we utilize a Double and Dueling Deep Q-Learning (D3QL)-based approach to categorize users' data into a predefined set of $K$ semantics. The training and execution of this model, as well as the sharing of its weights (KBs) with the SBS, are facilitated through the application of federated training, as discussed in Section III-C3.\nSubsequent to the extraction of semantic information by the SBS, we employ a method termed Semantic Aware Multiple Access (SAMA)-D3QL, serving as part of OCNC as detailed in [14], to manage user channel access. Throughout the training phase of this approach, each user constructs a historical"}, {"title": "V. FUTURE RESEARCH DIRECTIONS", "content": "To achieve an efficient and effective implementation of semantic-enabled 6G systems, meticulous consideration must be devoted to addressing various technological and societal challenges, some of which are outlined in the following:\n1) E2E Management of KB Refinement and Deployment:\nWithin the E2E layer of KB-MANO, two crucial components stand out: the KB Refinement and Deployment Managers. These components address optimization problems related to resource allocation, including running KB training tasks, fa-cilitating data transmission between users and these tasks, and distributing KBs across the infrastructure. In scenarios where federated training is enabled (see Section III-C), training tasks occur on user devices, eliminating the need for data transmis-sion during training, and model weights (which have negligible size compared to user data) are transmitted to distribute KBs. However, for distributed or centralized training (when device resources are insufficient), training tasks must migrate to edge or cloud resources, requiring data transmission between users and these tasks. In these cases, precise allocation of computing and network resources, taking into account service charac-teristics and real-time system state, is essential to minimize the impact on actual traffic. Challenges include selecting and configuring training strategies, allocating network bandwidth for KB updates and computing power for model trainings, and prioritizing traffic for deploying updated KBs. ML-based or heuristic approaches offer potential solutions within specified time constraints and considering the dynamic nature of the system, representing a promising avenue for future research.\n2) E2E Calculation of Semantic Performance:\nIn the E2E management of KB refinement and arrange-ment, a crucial consideration lies in constraining service char-acteristics, particularly semantic-based service performance requirements. Unlike traditional networks with well-defined E2E performance parameters, translating the E2E QoS/QoE performance of semantic-enabled systems into metrics such as E2E latency or minimum required network and computing capacity poses challenges. For example, speech-based services commonly utilize metrics like Word Error Rate (WER) and Signal-to-Distortion Ratio (S2DR), while video-based services rely on Video Quality Assessment (VQA) metrics for performance evaluation [15]. Furthermore, the subjective nature of semantics adds complexity, as different services, users, or service providers in multi-domain scenarios may perceive performance differently. Addressing semantic-based metrics and transforming them into constraints and thresholds for resource allocation through innovative research initiatives will aid in overcoming current challenges associated with assessing system-wide semantic awareness comprehensively.\n3) E2E Deterministic Provision of Services:\nIn the holistic oversight of E2E KB refinement and arrangement, it is crucial to integrate not solely the service characteristics but also the real-time system state. Among these, a pivotal component is the real-time states of semantic transcoding blocks, in conjunction with the examination of resource states enabled by CNCO. For example, live services like the holographic meeting may involve intensive semantic extraction during certain time slots when users initiate the use of a specific device. In this time frame, considering semantic extraction delays is crucial, which influences E2E quality metrics and makes edge resources the only viable option to implement corresponding service instances. Conversely, during time slots requiring lighter semantic extraction with negligible delay, instances can be migrated to cost-effective regional or core data centers. Thus, dynamic resource allo-cation, considering the impact of reduced performance due to semantic transcoding, is imperative for E2E deterministic semantic awareness.\n4) Sustainable Design of Semantic-Aware Systems:\nIn the pursuit of service providers' strategic objectives, refining and deploying KBs can be strategically structured to enhance various operational metrics. This includes reducing resource utilization, decreasing E2E latency, and augmenting user support capacity. However, integrating SemCom and orchestration requires incorporating semantic transcoding at various stages within the framework, leading to increased demand for computing resources and higher energy consump-tion. Hence, alongside these objectives, sustainably respon-sible resource allocation becomes paramount. This involves prioritizing renewable energy sources for computing resources and consolidating tasks and traffic to free up computing and network space, enabling surplus resource deactivation. More-over, the advent of novel semantic transcoding paradigms, anchored in causality and advanced cognitive capabilities, along with lifelong learning mechanisms such as Continual Learning (CL) that systematically integrate new information to prevent catastrophic forgetting, presents potential for mitigat-ing unnecessary retrains or redistributions. This advancement holds promise for nurturing more environmentally sustainable, semantically-enabled systems."}, {"title": "VI. CONCLUSION", "content": "This paper focused on addressing challenges related to KB refinement and arrangement to enable efficient SemCom for dynamic 6G services. It first introduced the 6G infrastructure and its entities, explained the concept of SemCom, highlighted the benefits of incorporating semantics in resource orchestra-tion, outlined challenges in implementing efficient semantic-enabled 6G systems, and proposed enabling technologies to overcome these challenges. Subsequently, the KB-MANO framework was introduced, designed for allocating network and computing resources dedicated to updating and distribut-ing KBs across the system, aiming to minimize the impact of knowledge management on service provisioning. Addi-tionally, a proof-of-concept scenario demonstrated semantic-aware radio resource orchestration empowered by KB-MANO. The paper concluded by outlining various research avenues that are crucial for the advancement of semantic-oriented communication systems. These directions are essential for paving the way toward an optimized, resilient, inclusive, and future-proof 6G infrastructure."}]}