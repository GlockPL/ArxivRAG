{"title": "HistoSmith: Single-Stage Histology Image-Label Generation via Conditional Latent Diffusion for Enhanced Cell Segmentation and Classification", "authors": ["Valentina Vadori", "Jean-Marie Gra\u00efc", "Antonella Peruffo", "Livio Finos", "Ujwala Kiran Chaudhari", "Enrico Grisan"], "abstract": "Precise segmentation and classification of cell instances are vital for analyzing the tissue microenvironment in histology images, supporting medical diagnosis, prognosis, treatment planning, and studies of brain cytoarchitecture. However, the creation of high-quality annotated datasets for training remains a major challenge. This study introduces a novel single-stage approach (HistoSmith) for generating image-label pairs to augment histology datasets. Unlike state-of-the-art methods that utilize diffusion models with separate components for label and image generation, our approach employs a latent diffusion model to learn the joint distribution of cellular layouts, classification masks, and histology images. This model enables tailored data generation by conditioning on user-defined parameters such as cell types, quantities, and tissue types. Trained on the Conic H&E histopathology dataset and the Nissl-stained CytoDArk0 dataset, the model generates realistic and diverse labeled samples. Experimental results demonstrate improvements in cell instance segmentation and classification, particularly for underrepresented cell types like neutrophils in the Conic dataset. These findings underscore the potential of our approach to address data scarcity challenges.", "sections": [{"title": "1 Introduction", "content": "Deep learning (DL) can be applied directly to histological sections for diagnostic or prognostic purposes, but this approach often suffers from limited interpretability. Alternatively, using DL to detect, segment, and classify cells or nuclei allows for the extraction of interpretable biomarkers that characterize the tissue microenvironment through cell-related features such as quantity, size, morphology, and spatial arrangement. These biomarkers, in turn, enable downstream applications including disease detection, outcome prediction, and the design of personalized treatments [21,16]. In neuroscience, the segmentation and classification of"}, {"title": "2 Method", "content": "Our goal is to augment a labeled image dataset with generated samples to improve CS and CC performance. We propose an LDM [17] that concurrently generates a histological image and its masks. As shown in Fig. 1, these include a cellular layout encoded as a distance map and a semantic mask for cell types, post-processed into a label map and unique cell-type assignments via thresholding, morphological operations, and majority voting.\nAs per [17] and Fig. 2, a VQ-VAE is trained on a dataset D = {(xi, mi)}=1 to learn a discrete latent representation z of the input images x and corresponding masks m. A diffusion model is then trained in the learned latent space.\nThe VQ-VAE encoder, parameterized by a convolutional neural network (CNN), maps an input image concatenated with its masks along the channel dimension xm to a continuous latent representation, reducing the resolution by a factor of 4. The latent vectors forming this representation are mapped to the nearest prototype in a codebook, yielding a quantized representation z. A CNN-based decoder reconstructs the original image and masks. Our decoder has two heads: one predicts the input image and distance map, the other the semantic mask of cell types. The training objective for the first head includes a reconstruction and perceptual loss for fidelity, a commitment loss for stable encoder representations, a codebook loss for optimizing discrete representation learning, and an adversarial loss to mitigate blurriness, consistent with previous work. For the second head, inspired by semantic segmentation tasks, we apply a categorical cross-entropy loss and a Tversky loss [18].\nIn the diffusion model, the forward process gradually adds Gaussian noise to the latent variables z over T timesteps with a linear schedule. In the reverse process, a time-conditional U-Net learns to denoise the latent representations by predicting the added noise at each step. For more details we refer to [29,17].\nWe condition the reverse diffusion process with an 10-dimensional vector encoding staining type, tissue type, and cellular composition. The first element specifies the staining method (0 for HE, 1 for Nissl). The next five represent normalized cell counts for neutrophils, epithelial cells, eosinophils, other cells, and neuron/glia. The final four use one-hot encoding for colon, auditory cortex, cerebellum, and hippocampus. Cell counts are normalized by the maximum value observed in a training patch to enable global quantity learning. The conditioning vector is mapped to an embedding vector, initialized from a normal distribution, which is then combined with the time embedding to condition the U-Net on the timestep. At inference, a random Gaussian noise sample and the conditioning vector are fed into the reverse diffusion process. After denoising, the VQ-VAE decoder reconstructs a new image and its corresponding masks."}, {"title": "3 Experiments", "content": "We assessed HistoSmith's output quality by training it on a merged dataset comprising the CoNIC [5] and CytoDArk0 [27] datasets. CoNIC includes 4,981"}, {"title": "4 Results", "content": "Table 1 presents the overall CS and CC results on CONIC and CytoDArk. We evaluate performance using the Dice coefficient, Precision (P), Recall (R), Detection Quality (DQ), Segmentation Quality (SQ), Panoptic Quality (PQ), Coefficient of Determination (R2), and Multi-class Panoptic Quality (mPQ+) [5,28,26].\nThe CISCA model trained on the augmented dataset DUD outperforms the one trained on the original dataset D across both datasets and most metrics. Specifically, it achieves an average improvement of 1.9% across metrics on CoNIC and 3.4% on CytoDArk0. Marked average improvements across metrics were observed for neutrophils (+5.4%) and eosinophils (+1.4%), as well as the hippocampus (+2.8%) and visual cortex (+2.6%). Notably, the visual cortex is missing from the CytoDArk0 training set, and hippocampus cells in the test set differ in appearance from those in the training set. This suggests that HistoSmith effectively enhances generalization.\nFig. 4 presents both qualitative and quantitative analyses of the relationship between conditioning and generated cell quantities. Panels (a-c) illustrate how varying input conditioning values affects synthetic cell type semantic masks and histology images. The difference between generated (n.) and conditioned (ni) normalized cell counts is reported below each pair. As expected, the model effectively generates more cells as the input cell quantity increases. This trend is evident for the cerebellum (panel a) and neutrophils (panel b). However, for neutrophils, a saturation effect occurs when the cell quantity is increased excessively. In this case, we conditioned the generation process to produce H&E-stained colon tissue with randomly sampled cell quantities for each type, as outlined in Section 3, setting neurons/glia to zero. For neutrophils, instead of sampling, we systematically increased the cell quantity from a minimum to a maximum value. Within the range nmax to max, where nmax is the maximum value observed in the training set, HistoSmith generates neutrophils in proportion to the input (panel b). However, when the cell quantity is varied across the full possible range 0-1 (panel c), cells transition into the other cell type and eventually into neurons/glia, and the image loses realism. It appears that the conditioning on tissue and cell types is almost entirely overridden to achieve the requested cell quantity, leading to the generation of non-neutrophil cell types.\nPanels (d-f) provide quantitative evaluations using Bland-Altman plots, Pearson's correlation, linear regression model fits, and density distribution comparisons for 100 samples of the cerebellum, auditory cortex, and neutrophils, respectively. In the Bland-Altman plots, the y-axis represents ni rather than the conventional average of the compared measures, as it reflects the \u201ctrue count\" expected in the synthetic images. Overall, the bias is minimal; however, as observed qualitatively, the discrepancy between no and ni increases with higher input values. Correlation is strong for the cerebellum and auditory cortex (r = 0.98), with a linear fit closely matching the line of equality and the distribution of no largely aligned with that of ni, although the latter deviates from the training data distribution ND. For neutrophils (panel f, r = 0.39), correlation is lower. While the linear trend is increasing, n, is systematically lower than ni, as the model is consistently pushed to generate images containing neutrophils, despite their rarity in the Conic dataset (1% of the total cells in the original training set and 2.7% in the oversampled dataset used for training). In the distribution plots, no\""}, {"title": "5 Conclusions", "content": "We introduced HistoSmith, the first LDM-based approach for histology dataset augmentation in CS and CC. Designed to address data scarcity, it also mitigates class imbalance by guiding generation toward underrepresented cell types, such as neutrophils in CONIC. Training the CISCA model on an augmented dataset improved performance across both CoNIC and CytoDArk, with average metric gains of 1.9% and 3.4%, respectively. Notable improvements were seen for neutrophils (+5.4%), eosinophils (+1.4%), hippocampus (+2.8%), and visual cortex (+2.6%), indicating enhanced generalization. Additionally, HistoSmith effectively generates realistic histology images with controllable cell quantities, though accuracy depends on the conditioning range.\nThese findings highlight the potential of generative data augmentation while raising key considerations. Synthetic data can improve segmentation and classification, but its effectiveness depends on the model's generalization capacity excessive deviation from the training distribution may introduce artifacts. Moreover, computational costs must be weighed against alternatives. While expert annotation is costly and time-intensive, motivating this study and others, it is worth exploring whether selectively annotating a well-curated subset of challenging cases offers a better trade-off between accuracy gains and cost."}]}