{"title": "Count-based Novelty Exploration in Classical Planning", "authors": ["Giacomo Rosa", "Nir Lipovetzky"], "abstract": "Count-based exploration methods are widely employed to improve the exploratory behavior of learning agents over sequential decision problems. Meanwhile, Novelty search has achieved success in Classical Planning through recording of the first, but not successive, occurrences of tuples. In order to structure the exploration, however, the number of tuples considered needs to grow exponentially as the search progresses. We propose a new novelty technique, classical count-based novelty, which aims to explore the state space with a constant number of tuples, by leveraging the frequency of each tuple's appearance in a search tree. We then justify the mechanisms through which lower tuple counts lead the search towards novel tuples. We also introduce algorithmic contributions in the form of a trimmed open list that maintains a constant size by pruning nodes with bad novelty values. These techniques are shown to complement existing novelty heuristics when integrated in a classical solver, achieving competitive results in challenging benchmarks from recent International Planning Competitions. Moreover, adapting our solver as the frontend planner in dual configurations that utilize both memory and time thresholds demonstrates a significant increase in instance coverage, surpassing current state-of-the-art solvers.", "sections": [{"title": "1 Introduction", "content": "Research on width-based search methods [16] has had a significant impact in planning, over the past decade, through the introduction of search algorithms which rely on novelty heuristics to induce an efficient exploration of the state-space. Novelty metrics achieve this by comparing a state's information content with that of states visited in the past. Width-based algorithms adopting Novelty alongside traditional heuristics have been central to improving state-of-the-art results in Classical Planning in recent years [14], with search performance often being attributed to a balance between exploration and exploitation, where Novelty drives the exploration while traditional heuristics direct exploitation. This does not come without limitations, as Lipovetzky and Geffner [16, 17] show that the complexity of computing novelty metrics needed to solve planning problems is exponential in their cardinality. In practice, this causes novelty metrics of cardinality greater than 2 to be computationally unfeasible, limiting the technique's effectiveness in domains that would benefit from a higher cardinality. The cardinality is connected with a hardness measure for Classical Planning known as classical planning atomic width. Multiple contributions have sought to address this limitation. Lipovetzky and Geffner [18] introduce partition functions, which subdivide planning problems into smaller sub-problems through the use of partitioning heuristics to control the direction of search and increase the number of novel nodes. Katz et al. [13] provide a definition of novelty of a state with respect to its heuristic estimate, providing multiple novelty measures which quantify the novelty degree of a state in terms of the number of novel and non-novel state facts. More recently, Singh et al. [27] introduce approximate novelty, which uses an approximate measurement of state novelty which is more time and memory efficient, proving capable of estimating novelty values of cardinality greater than 2 in practical scenarios. Relating Novelty with other concepts, such as dominance pruning, also constitutes an active area of research [5, 8].\nAll mentioned techniques limit themselves to the original idea of measuring state information content through the occurrence of tuples in the search history. Instead, we propose a count-based measure of state novelty, classical count-based novelty, which seeks to induce efficient exploration of the state space by making use of the additional information contained in the count of occurrences of tuples in the search history. This addresses shortcomings of the current Novelty framework (see [14]), which we refer to as width-novelty to distinguish from our contributions in this paper. Our proposed count-based metric is not limited by width-novelty's binary classification of novel information, providing a more fine-tuned separation of the degree of novelty of a state and maintaining its informedness without the risk of exhausting novel nodes. A key motivation behind our study is thus to obtain a more general novelty framework that can maintain its efficacy across diverse sets of problems in Classical Planning, such as domains that require higher atomic widths.\nIn this regard, we note that count-based exploration techniques are well studied in relation to the exploration-exploitation problem in Multi-Arm Bandits and Reinforcement Learning (RL) settings. Such algorithms record state visitation to obtain an exploration bonus used to guide the agent towards a more efficient exploration of the state-space, where algorithms such as MBIE-EB [29] achieve theoretical bounds on sample complexity in tabular settings. The focus of our research diverges from these methods, as we aim to discover a heuristic to control the order of state exploration in a Classical Planning context. Instead of state counts, we base our approach on the frequency of tuple events, inspired by work on width-novelty in the field of Classical Planning [16, 17, 19]. Still, our contributions provide a useful basis to connect count-based exploration across the two fields.\nWe also introduce algorithmic contributions in the form of a simple memory-efficient open list designed with count-based novelty in mind. Polynomial width-based planning algorithms prune nodes whose novelty cardinality is worse than a given bound to achieve a more efficient search [19]. Inspired on this idea, our contribution allows us to prune nodes with bad novelty values with a gradual and"}, {"title": "2 Background", "content": "Classical Planning The classical planning model is defined as S = (S, S_0, S_G, A, f), where S is a discrete finite state space, s_0 is the initial state, S_G is the set of goal states, and A(s) denotes the set of actions a \u2208 A that deterministically map one state s into another s' = f(a, s), where A(s) is the set of actions applicable in s. We adopt a notation whereby, in a classical planning problem, a state is visited (generated) sequentially at each time-step t. Let s_t\u2208 S denote the t^{th} visited (generated) state in a search problem. We use s_{0:t} to denote the sequence of t + 1 states generated at time-steps 0, 1, ..., t. A solution to a classical planning model is given by a plan, a sequence of actions a_0,..., a_{xm} that induces a state sequence s_{0:xm+1} such that a_{x_i} \u2208 A(S_{x_i}), S_{x_{i+1}} = f(a_{x_i}, S_{x_i}), and S_{xm+1} \u2208 S_G.\nWe use STRIPS planning language [9] to define a classical planning problem P = (F,O, I, G), where F denotes the set of boolean variables, O denotes the set of operators, I \u2286 F is the set of atoms that fully describe the initial state, and G \u2286 F is the set of atoms present in the goal state. An optimal plan consists of the shortest possible solution to a given problem P. In this research, we look at satisficing planners, that is, planners which are not constrained to searching for optimal plans, but rather aim for computing good-quality plans fast.\nWidth-Based Search Best-First Width Search (BFWS) [19] refers to a family of planners which adopt a greedy best-first search algorithm, using a novelty measure as first heuristic. A greedy best first search planner is a planner which visits nodes in the order specified solely by an evaluation function h, potentially breaking ties through the use of secondary heuristics. The main peculiarity of using a primary novelty heuristic comes from the fact that it is goal-unaware, thus prioritizing an efficient exploration of the state space over seeking states which are expected to be closer to the goal. The search is then directed to the goal through the use of secondary tie-breaking heuristics as well as partition functions, that is, evaluation functions h used to partition the set of states considered in the computation of novelty measures into disjoint subsets, ignoring occurrences of variables in states belonging to separate subsets.\nCount-based exploration Count-based exploration methods have been studied to address the exploration-exploitation dilemma inherent in learning algorithms by allowing agents to prioritize actions that lead to states with uncertain or unexplored dynamics, thereby facilitating more effective learning of the environment's structure. This is often achieved by incorporating an exploration bonus added to the agent's reward upon visiting a state, encouraging the exploration of states with low visitation counts. Among the best-known examples is the UCB1 bandit algorithm [2], which performs a near-optimal balancing of exploration and exploitation in the stateless multi-armed bandit problem. This is achieved by selecting actions, referred to as the arms of a bandit, which maximize an upper confidence bound, the sum of the empirical average rewards Q_t(i) of selecting arm i, and a confidence interval term $\\sqrt{\\frac{2 \\log N}{N(i)}}$, where N(i) is the count of pulls of arm i, and N is count of total arm pulls."}, {"title": "3 Count Based Novelty", "content": "Classical count-based novelty operates over states that assign a value to a finite number of variables $v \\in V$ over finite and discrete domains. In problems defined via STRIPS, without loss of generality, $V \u2286 F$ are boolean variables. Let V be the set of all variables, and $U(k) = \\{X \u2286 V | |X| = k\\}$ the set of all k-element variable conjunctions. A tuple $u \u2208 U(k)$, specifically $u = \\{v_1, v_2, . . . , v_k\\}$, represents a conjunction of k variables. Given a state s that assigns a boolean value to each variable in V, the value of the tuple u in state s, denoted s(u), is defined as the conjunction of the values of the k variables in u, $s(u) = s(v_1) \u2227 s(v_2) \u2227 ... \u2227 s(v_k)$, where s(v_i) is the value of variable $v_i$ in state s. We say s(u) is true if all v \u2208 s(u) are true, and tuple u is true in s if s(u) is true. Let s_{0:t}(u) denote the sequence of values of tuple $u \u2208 U(k)$ in state sequence s_{0:t}, and let $U^+(k)(s) \u2286 U(k)$ denote the set of tuples u in state s where s(u) is true.\nDefinition 1 (Classical count-based novelty). The count-based novelty $c_U(s)$ of a newly generated state s at time-step t + 1 given a history of generated states $s_{0:t}$ and set of variable conjunctions $U = U(k)$ for some tuple size k is:\n$c_U(s_{t+1}) := \\min_{u \\in U^+(s_{t+1})} (N_u(s_{t+1}))$\nWhere $N_u(s_{t+1})$ counts the number of states $s_i \u2208 s_{0:t}$ where $s_i(u) = s_{t+1}(u)$.\nThat is, for each tuple u that is true in $s_{t+1}$, we count the number of states $s_i \u2208 s_{0:t}$ where $s_i(u)$ is true, and we select the minimum out of those counts.\nFollowing prior work on Novelty [18], we also define a version of count-based novelty which uses partition functions to separate the search space into distinct sub-spaces.\nDefinition 2 (Partitioned classical count-based novelty). The partitioned count-based novelty $c_U(s)$ of a newly generated state s at time-step t + 1 given partition functions $h_1, ..., h_m$ is:\n$c_{h_1,...,h_m}^U (s_{t+1}) := \\min_{u \\in U^+(s_{t+1})} (N_{u;h_1,...,h_m}(s_{t+1}))$\nWhere $N_{h_1,...,h_m}(s_{t+1})$ counts the number of states $s_i \u2208 \\{s_{0:t} | h_1(s_i) = h_1(s_{t+1}) \u2227 ... h_m(s_i) = h_m(s_{t+1})\\}$ where $s_i(u) = s_{t+1}(u)$."}, {"title": "3.1 Theoretical results", "content": "In this section, we justify the notion that classical count-based novelty achieves an efficient exploration of the state space that benefits planner performance, and present the mechanisms through which this is achieved. Firstly, we focus on the exploratory aspect of our heuristic, by detailing how size-1-tuple counts can be leveraged to direct the search towards lesser explored areas of the state space. We do so by exploiting a Hamming distance measure of a state to all previously visited states, as it provides an intuitively appealing means of quantifying how different a newly visited state is to the solver's visitation history. By demonstrating that information on size-1-tuple counts leads to improved bounds with respect to the Hamming distance of newly visited states in Theorems 3 to 6, we highlight the extent to which classical count-based novelty identifies under-explored areas of the state space. This exploratory aspect alone, however, does not validate the heuristic's effectiveness, as it fails to reveal whether the novel information is beneficial to the search. We address this aspect in Theorems 7 and 8 by using information on size-1-tuple counts and average Hamming distance of states to estimate the expected number of novel tuples. Gro\u00df et al. [8] show that novel tuples benefit search performance by indicating potential new paths towards the goal. Our results identify the two mechanisms through which classical count-based novelty increases the expectation of such novel tuples.\nWe define node $n_i = n_i(s_i)$ as referring to a state $s_i$, where the sequence $n_{0:t}$ corresponds to sequence $s_{0:t}$. The distinction between a node $n_i$ and its corresponding state $s_i$ lies in the equality operator: $n_i = n_j$ iff $i = j$, implying that $s_i = s_j$, whereas $s_i = s_j$ denotes the equality of all underlying variable values v in $s_i$ and $s_j$. Crucially, throughout the entire section we assume that $U = U(1) = V$, that is, we are only looking at counts over single-variable tuples. We thus simplify the tuple notation by denoting $s^i = s(v_i)$. Let L = |s| = |V|, and Hamming distance $H(n_i,n_j) = H(n(s), n_j(s_j)) = \\sum_{l=0}^{L-1} 1_{s_l \\neq s'_l}$. We then define normalized Hamming distance as $\\delta(n, n_j) = \\frac{H(n,n_j)}{L} = \\frac{\\sum_{l=0}^{L-1} 1_{s_l \\neq s'_l}}{L}$, and the average normalized Hamming distance of a node n with respect to all nodes in $n_{0:t}$ as $a_{0:t}(n) = \\frac{1}{W} \\sum_{i=0; n_i \\neq n}^{t} \\delta(n, n_i)$ where $W = t$ if $n \u2208 n_{0:t}$ or $W = t + 1$ otherwise, noting that in the first case we are skipping a node's comparison with itself.\nLet the empirical count distribution be $\\mu_i^t(s) = \\frac{N_{v_i}(s)}{t+1}$, and $\\mu_{\\min}^t(s) = \\min_{i \\in V} (\\mu_i^t(s))$, noting that the minimum is over the entire set of variables $V = U(1)$ rather than the set of true variables $U^+(1)$ in a state s used in Definition 1 and 2, and $0 \u2264 \\mu_i^t(s) \u2264 1$. We provide a justification of this change through Propositions 1 and 2, demonstrating a correspondence between empirical counts and Hamming distances over U(1) in binary vectors, and the same metrics over the set $U^+(1)$ in binary vectors that include negated variables. This allows us to align our results with a STRIPS representation that includes negated variables. For the set of L variables V, we define $s_{neg}$ for states s over $V_{neg} = V \\cup \\{\u00acv | v \u2208 V\\}$ such that $s_{neg}(v) = s(v), s_{neg}(\u00acv) = \u00acs(v)$ for all $v_i \u2208 V$. Since $H(s, s') = |\\{i | s(v_i) \\neq s'(v_i)\\}|$, we define $H_{true}(s, s') = |\\{i | s(v_i) \\neq s'(v_i), s(v_i) = 1\\}|$ and $H_{false}(s, s') = |\\{i | s(v_i) \\neq s'(v_i), s(v_i) = 0\\}|$, noting that $H(s, s') = H_{true}(s, s') + H_{false}(s, s')$.\nProposition 1. The Hamming distance H(s,s') between states s and s' equals the true Hamming distance $H_{true}(s_{neg}, s'_{neg})$, considering only variables in $s_{neg}$ that are true.\nProof. Since for each variable $s(v_i) = 1 \u2208 s$ there are two variables $s_{neg}(v_i) = 1 \u2208 s_{neg}$ and $s_{neg}(\u00acv_i) = 0$, and for each variable $s(v_i) = 0 \u2208 s$ there are two variables $s_{neg}(v_i) = 1 \u2208 s_{neg}$ and $s_{neg}(\u00acv_i) = 0$, follows that $H_{true}(s_{neg}, s'_{neg}) = H_{true}(s, s') + H_{false}(s, s') = H(s, s')\nProposition 2. The empirical count $N_i^t(s)$ for any value $s(v_i)$ corresponds to the empirical count $N_x^t(s_{neg})$, where $x = i$ if $s(v_i) = 1$ and $x = j$ if $s(v_i) = 0$ where $s_{neg}(v_j) = s_{neg}(\u00acv_i)$.\nProof. From the definition of $s_{neg}$, for every variable $s_j(v_i) = 0 \u2208 s_{0:t}(v_i)$ we have that $s_{neg;j}(v_i) = 0$ and $s_{neg;j}(\u00acv_i) = 1$. The proof for $s_j(v_i) = 1$ case is symmetrical. Proposition 2 follows.\nIt then follows from Proposition 2 that selecting the minimum count $c_{V_{neg}}^t (s_{neg;t+1}) = \\min_{v \u2208 V} (N_i^t (s_{t+1}))$.\nTheorem 3. The average normalized Hamming distance $a_{0:t}(s)$ of a state s to the t + 1 states in history $s_{0:t}$ is upper bounded by:\n$a_{0:t}(s) \u2264 1 \u2013 \\mu_{\\min}^t (s)$\nProof. The average Hamming distance of $s(v_i)$ with respect to the value of variable i in all states $s_j \u2208 s_{0:t}$ is equivalent to\n$\\frac{1}{t+1} \\sum_{j=0}^{t} 1_{s_j^i \\neq s^i} = \\frac{1}{t+1} \\sum_{j=0}^{t} 1_{s^i \\neq s_i} = 1 - \\mu_i^t(s)$\nThus we have\n$\\begin{aligned}\na_{0:t}(s) &= \\frac{1}{L} \\sum_{i=0}^{L-1} \\frac{1}{t+1} \\sum_{j=0}^{t} 1_{s_i \\neq s_j} = \\frac{1}{L} \\sum_{i=0}^{L-1} (1 - \\mu_i^t(s)) \\\\\n &= 1 - \\frac{1}{L} \\sum_{i=0}^{L-1} \\mu_i^t(s) \u2264 \\frac{1}{L} \\sum_{i=0}^{L-1} (1 - \\mu_{\\min}^t(s)) = (1 - \\mu_{\\min}^t(s)) \\\\\n &= 1 \u2013 \\mu_{\\min}^t (s)\n\\end{aligned}$\nParent-child average distance comparison We provide a set of results on the average normalized Hamming distances of a child node with respect to its parent node, and the impact that the count-based novelty of a node has on this value. Incorporating constraints on the changes between parent and child nodes enables us to obtain much tighter bounds compared to Theorem 3, reflecting the parent-child dynamic that exists between expanded and generated nodes. Let $n^p$ and $n^c$ be the child and parent node respectively, where an action $a \u2208 A$ is performed on $n^p$ to flip the value of e variables, which we refer to as the effects. Let n be a newly generated node nt.\nTheorem 4. Lower and upper bounds for $a_{0:t}(n)$ are given by:\n$a_{0:t}(n^p) - \\frac{t-1}{t} \\frac{e}{L} \u2264 a_{0:t}(n^c) \u2264 a_{0:t}(n^p) + \\frac{t-1}{t} \\frac{e}{L}$"}, {"title": "4 Trimmed Open List", "content": "Balancing the amount of memory occupied by low-rank nodes is a common strategy which allows for better ranked exploratory nodes to appear further down the search. Polynomial width-novelty planners prune nodes with novelty value greater than a threshold, as they are deemed not useful for the search. Similarly, count exploration methods generate many nodes with high counts, which are unlikely to ever be expanded. However, adopting a threshold as in the width-novelty case is unfeasible due to the granularity of the metric.\nTo address the challenge of high memory usage by poorly ranked nodes in the open list, we introduce the Trimmed Open List (Alg. 1). Built on a binary heap, this open list limits its growth by pruning less promising nodes when it exceeds a predefined size limit Z. This pruning process involves randomly selecting a leaf node, comparing its heuristic value with a new node n using the open list's comparison function, and then pruning or swapping nodes based on their heuristic values. A unique heapify-up operation is applied to the inserted leaf, which, unlike standard heaps, is not required to be the last element.\nFurthermore, we developed a Double Trimmed Open List for heuristic alternation [24], accommodating dual open lists for node insertion under distinct heuristics and enabling alternate node retrieval. This variant employs the same pruning strategy but distinguishes itself by tracking each node's interaction with the open lists either being popped or trimmed. A node becomes eligible for deletion when its interaction count equals the number of lists it is associated with,"}, {"title": "5 Experiments", "content": "Our experiments were conducted using Downward Lab's experiment module [25], adhering to the IPC satisficing track constraints of 1800 seconds and 8 GB memory. Each test was ran on a single core of a cloud instance AMD EPYC 7702 2GHz processor. We implemented all proposed planners in C++, using LAPKT's [21] planning modules. For hybrid experiments, LAMA-First [23] and Scorpion-Maidu [3, 26] served as backend components, employing Fast-Downward [10] and the IPC2023 code repository [4], respectively. Except for Approximate-BFWS, BFWS variants utilized the FD-grounder for grounding [11], however in problems where the FD grounder produces axioms (unsupported by LAPKT), LAPKT automatically switched to the Tarski grounder [7]. Approximate-BFWS exclusively used the Tarski grounder, following its initial setup and IPC-2023 configuration. We utilized IPC satisficing track benchmarks as in [27], selecting the latest problem sets for recurring domains. We conducted two sets of experiments. The first benchmarked our planners against the base BFWS(f5) solver, evaluating the degree to which our proposed classical count-based novelty and trimmed open list techniques improve the coverage of BFWS(f5) and its exploration efficiency, measured as the number of expansions required to find a solution. The second set of experiments compared our hybrid configurations to Dual-BFWS, Approximate-BFWS, LAMA-First, and a \"first\" version of the IPC-2023 satisficing track winner Scorpion-Maidu that runs its first iteration, in order to assess the coverage gains obtainable by adopting our proposed frontend solver alongside existing solvers in a dual configuration, relying on memory thresholds alongside more traditional time thresholds to trigger the frontend to fallback."}, {"title": "5.1 Count-based solvers", "content": "We define three new planning solvers to evaluate the performance of our proposed trimmed open list and classical partitioned count-based novelty techniques. All our solvers are based on the BFWS(f5) search algorithm [18]. f5 is the evaluation function (w, #g) where w is the novelty measure and the goal counter #g counts the number of atomic goals not true in s. The novelty measure w is computed given partition functions #g and #r(s), that is $w(##g,#r)$ (see [18])."}, {"title": "5.2 Hybrid solvers with BFNOS frontend", "content": "We adopt BFNOS+(f5(C1), f5(W2)) as a frontend solver, capped by a 6 GB memory threshold and a time threshold close to the overall time limit, to enable backend fallback for all unresolved searches. We pair it with three backend planners from literature: the Dual-BFWS backend component (BFNOS-Dual), LAMA-First (BFNOS-LAMA), and the \"first\" version of Scorpion-Maidu (BFNOS-Maidu-h\u00b2), in its IPC2023 configuration with the h\u00b2-preprocessor [1]. These were chosen for their complementary heuristics to our frontend's f5 partitioning, promoting diverse solution strategies to enhance coverage diversity. Frontend time thresholds are set to 1600 sec with BFNOS-Dual and BFNOS-LAMA, and 1400 sec for BFNOS-Maidu-h\u00b2, to account for up to 180 sec of preprocessing allowance.\nMemory threshold Solvers tend to exhibit diminishing returns in the number of instances solved with respect to both time and memory. Thus, as memory usage increases while solving an instance, it is more likely that the instance will not be solvable within the defined memory constraint, indicating that the adopted heuristics are not effective for that particular problem. Novelty heuristics W2 and"}, {"title": "6 Conclusion", "content": "In this paper we introduce the concept of count-based novelty as an alternative novelty exploration framework in Classical Planning, showing that the arity-1 variant of our proposed metric is capable of effectively predicting states with novel k-tuples only using a constant number of tuples. We introduce the use of counts and Hamming distances to relate the exploratory behavior of count-based novelty to the existing body of knowledge on Novelty. We also propose single and double Trimmed Open List variants which allow us to upper bound the open list size by pruning nodes unlikely to be expanded. Our techniques used in the BFNOS solver demonstrate the effectiveness of combining distinct novelty metrics, achieving competitive coverage compared to state-of-the-art planners. Finally, we detail a dual-configuration strategy adopting a BFNOS frontend solver and introducing memory thresholds alongside customary time thresholds, justify the suitability of our proposed strategy, and demonstrate improved coverage performance compared to state-of-the-art planners.\nOur work provides foundational knowledge on count-based novelty through basic solutions that mirror our theoretical analysis. Future directions may include alternative count-based variants over tuples or extracted features to guide exploration in general and domain-specific planners, as well as adaptation to the existing body of work blending Novelty and heuristic estimates. Our contributions also provide the basis to bridge Classical Planning with the broader paradigm of count-based exploration, benefiting knowledge transfer with related areas such as Reinforcement Learning. Trimmed open lists and memory thresholds also proved to be simple yet effective solutions, pointing at the potential for a deeper analysis of similar ideas in Classical Planning."}]}