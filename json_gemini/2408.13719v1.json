{"title": "Count-based Novelty Exploration in Classical Planning", "authors": ["Giacomo Rosa", "Nir Lipovetzky"], "abstract": "Count-based exploration methods are widely employed to improve the exploratory behavior of learning agents over sequential decision problems. Meanwhile, Novelty search has achieved success in Classical Planning through recording of the first, but not successive, occurrences of tuples. In order to structure the exploration, however, the number of tuples considered needs to grow exponentially as the search progresses. We propose a new novelty technique, classical count-based novelty, which aims to explore the state space with a constant number of tuples, by leveraging the frequency of each tuple's appearance in a search tree. We then justify the mechanisms through which lower tuple counts lead the search towards novel tuples. We also introduce algorithmic contributions in the form of a trimmed open list that maintains a constant size by pruning nodes with bad novelty values. These techniques are shown to complement existing novelty heuristics when integrated in a classical solver, achieving competitive results in challenging benchmarks from recent International Planning Competitions. Moreover, adapting our solver as the frontend planner in dual configurations that utilize both memory and time thresholds demonstrates a significant increase in instance coverage, surpassing current state-of-the-art solvers.", "sections": [{"title": "1 Introduction", "content": "Research on width-based search methods [16] has had a significant impact in planning, over the past decade, through the introduction of search algorithms which rely on novelty heuristics to induce an efficient exploration of the state-space. Novelty metrics achieve this by comparing a state's information content with that of states visited in the past. Width-based algorithms adopting Novelty alongside traditional heuristics have been central to improving state-of-the-art results in Classical Planning in recent years [14], with search performance often being attributed to a balance between exploration and exploitation, where Novelty drives the exploration while traditional heuristics direct exploitation. This does not come without limitations, as Lipovetzky and Geffner [16, 17] show that the complexity of computing novelty metrics needed to solve planning problems is exponential in their cardinality. In practice, this causes novelty metrics of cardinality greater than 2 to be computationally unfeasible, limiting the technique's effectiveness in domains that would benefit from a higher cardinality. The cardinality is connected with a hardness measure for Classical Planning known as classical planning atomic width. Multiple contributions have sought to address this limitation. Lipovetzky and Geffner [18] introduce partition functions, which subdivide planning problems into smaller sub-problems through the use of partitioning heuristics to control the direction of search and increase the number of novel nodes. Katz et al. [13] provide a definition of novelty of a state with respect to its heuristic estimate, providing multiple novelty measures which quantify the novelty degree of a state in terms of the number of novel and non-novel state facts. More recently, Singh et al. [27] introduce approximate novelty, which uses an approximate measurement of state novelty which is more time and memory efficient, proving capable of estimating novelty values of cardinality greater than 2 in practical scenarios. Relating Novelty with other concepts, such as dominance pruning, also constitutes an active area of research [5, 8].\nAll mentioned techniques limit themselves to the original idea of measuring state information content through the occurrence of tuples in the search history. Instead, we propose a count-based measure of state novelty, classical count-based novelty, which seeks to induce efficient exploration of the state space by making use of the additional information contained in the count of occurrences of tuples in the search history. This addresses shortcomings of the current Novelty framework (see [14]), which we refer to as width-novelty to distinguish from our contributions in this paper. Our proposed count-based metric is not limited by width-novelty's binary classification of novel information, providing a more fine-tuned separation of the degree of novelty of a state and maintaining its informedness without the risk of exhausting novel nodes. A key motivation behind our study is thus to obtain a more general novelty framework that can maintain its efficacy across diverse sets of problems in Classical Planning, such as domains that require higher atomic widths.\nIn this regard, we note that count-based exploration techniques are well studied in relation to the exploration-exploitation problem in Multi-Arm Bandits and Reinforcement Learning (RL) settings. Such algorithms record state visitation to obtain an exploration bonus used to guide the agent towards a more efficient exploration of the state-space, where algorithms such as MBIE-EB [29] achieve theoretical bounds on sample complexity in tabular settings. The focus of our research diverges from these methods, as we aim to discover a heuristic to control the order of state exploration in a Classical Planning context. Instead of state counts, we base our approach on the frequency of tuple events, inspired by work on width-novelty in the field of Classical Planning [16, 17, 19]. Still, our contributions provide a useful basis to connect count-based exploration across the two fields.\nWe also introduce algorithmic contributions in the form of a simple memory-efficient open list designed with count-based novelty in mind. Polynomial width-based planning algorithms prune nodes whose novelty cardinality is worse than a given bound to achieve a more efficient search [19]. Inspired on this idea, our contribution allows us to prune nodes with bad novelty values with a gradual and"}, {"title": "2 Background", "content": "Classical Planning The classical planning model is defined as S = (S, So, SG, A, f), where S is a discrete finite state space, so is the initial state, SG is the set of goal states, and A(s) denotes the set of actions $a \\in A$ that deterministically map one state s into another $s' = f(a, s)$, where A(s) is the set of actions applicable in s. We adopt a notation whereby, in a classical planning problem, a state is visited (generated) sequentially at each time-step t. Let $s_t \\in S$ denote the $t^{th}$ visited (generated) state in a search problem. We use $s_{0:t}$ to denote the sequence of t + 1 states generated at time-steps 0, 1, ..., t. A solution to a classical planning model is given by a plan, a sequence of actions $a_0,..., a_{xm}$ that induces a state sequence $s_{0:xm+1}$ such that $a_{x_i} \\in A(s_{x_i})$, $s_{x_{i+1}} = f(a_{x_i}, s_{x_i})$, and $s_{xm+1} \\in S_G$.\nWe use STRIPS planning language [9] to define a classical planning problem P = (F,O, I, G), where F denotes the set of boolean variables, O denotes the set of operators, $I \\subseteq F$ is the set of atoms that fully describe the initial state, and $G \\subseteq F$ is the set of atoms present in the goal state. An optimal plan consists of the shortest possible solution to a given problem P. In this research, we look at satisficing planners, that is, planners which are not constrained to searching for optimal plans, but rather aim for computing good-quality plans fast.\nWidth-Based Search Best-First Width Search (BFWS) [19] refers to a family of planners which adopt a greedy best-first search algorithm, using a novelty measure as first heuristic. A greedy best first search planner is a planner which visits nodes in the order specified solely by an evaluation function h, potentially breaking ties through the use of secondary heuristics. The main peculiarity of using a primary novelty heuristic comes from the fact that it is goal-unaware, thus prioritizing an efficient exploration of the state space over seeking states which are expected to be closer to the goal. The search is then directed to the goal through the use of secondary tie-breaking heuristics as well as partition functions, that is, evaluation functions h used to partition the set of states considered in the computation of"}, {"title": "Count Based Novelty", "content": "Classical count-based novelty operates over states that assign a value to a finite number of variables $v \\in V$ over finite and discrete domains. In problems defined via STRIPS, without loss of generality, $V \\equiv F$ are boolean variables. Let V be the set of all variables, and $U(k) = \\{X \\subseteq V | |X| = k\\}$ the set of all k-element variable conjunctions. A tuple $u \\in U(k)$, specifically $u = \\{v_1, v_2, ..., v_k\\}$, represents a conjunction of k variables. Given a state s that assigns a boolean value to each variable in V, the value of the tuple u in state s, denoted s(u), is defined as the conjunction of the values of the k variables in u, $s(u) = s(v_1) \\land s(v_2) \\land ... \\land s(v_k)$, where s(vi) is the value of variable vi in state s. We say s(u) is true if all $v \\in s(u)$ are true, and tuple u is true in s if s(u) is true. Let $s_{0:t}(u)$ denote the sequence of values of tuple $u \\in U(k)$ in state sequence $s_{0:t}$, and let $U^+(k)(s) \\subseteq U(k)$ denote the set of tuples u in state s where s(u) is true.\nDefinition 1 (Classical count-based novelty). The count-based novelty $c_u(s)$ of a newly generated state s at time-step t + 1 given a history of generated states $s_{0:t}$ and set of variable conjunctions $U = U(k)$ for some tuple size k is:\n$c_u(s_{t+1}) := min_{u \\in U^+(s_{t+1})} (N_u(s_{t+1}))$\nWhere $N_u(s_{t+1})$ counts the number of states $s_i \\in s_{0:t}$ where $s_i(u) = s_{t+1}(u)$.\nThat is, for each tuple u that is true in $s_{t+1}$, we count the number of states $s_i \\in s_{0:t}$ where $s_i(u)$ is true, and we select the minimum out of those counts.\nFollowing prior work on Novelty [18], we also define a version of count-based novelty which uses partition functions to separate the search space into distinct sub-spaces.\nDefinition 2 (Partitioned classical count-based novelty). The partitioned count-based novelty $c_u(s)$ of a newly generated state s at time-step t + 1 given partition functions $h_1, ..., h_m$ is:\n$c_{h_1,...,h_m}(s_{t+1}) := min_{u \\in U^+(s_{t+1})} (N^{h_1,...,h_m}_u(s_{t+1}))$\nWhere $N^{h_1,...,h_m}_u(s_{t+1})$ counts the number of states $s_i \\in \\{s_{0:t} | h_1(s_i) = h_1(s_{t+1}) \\land ... h_m(s_i) = h_m(s_{t+1}) \\}$ where $s_i(u) = s_{t+1}(u)$."}, {"title": "3.1 Theoretical results", "content": "In this section, we justify the notion that classical count-based novelty achieves an efficient exploration of the state space that benefits planner performance, and present the mechanisms through which this is achieved. Firstly, we focus on the exploratory aspect of our heuristic, by detailing how size-1-tuple counts can be leveraged to direct the search towards lesser explored areas of the state space. We do so by exploiting a Hamming distance measure of a state to all previously visited states, as it provides an intuitively appealing means of quantifying how different a newly visited state is to the solver's visitation history. By demonstrating that information on size-1-tuple counts leads to improved bounds with respect to the Hamming distance of newly visited states in Theorems 3 to 6, we highlight the extent to which classical count-based novelty identifies under-explored areas of the state space. This exploratory aspect alone, however, does not validate the heuristic's effectiveness, as it fails to reveal whether the novel information is beneficial to the search. We address this aspect in Theorems 7 and 8 by using information on size-1-tuple counts and average Hamming distance of states to estimate the expected number of novel tuples. Gro\u00df et al. [8] show that novel tuples benefit search performance by indicating potential new paths towards the goal. Our results identify the two mechanisms through which classical count-based novelty increases the expectation of such novel tuples.\nWe define node $n_i = n_i(s_i)$ as referring to a state $s_i$, where the sequence $n_{0:t}$ corresponds to sequence $s_{0:t}$. The distinction between a node $n_i$ and its corresponding state $s_i$ lies in the equality operator: $n_i = n_j$ iff $i = j$, implying that $s_i = s_j$, whereas $s_i = s_j$ denotes the equality of all underlying variable values $v$ in $s_i$ and $s_j$. Crucially, throughout the entire section we assume that $U = U(1) = V$, that is, we are only looking at counts over single-variable tuples. We thus simplify the tuple notation by denoting $s^i = s(v_i)$. Let $L = |s| = |V|$, and Hamming distance $H(n_i, n_j) = H(n(s_i), n(s_j)) = \\sum_{i=0}^{L-1} 1_{s_i \\neq s_j}$. We then define normalized Hamming distance as $\\delta(n, n_j) = \\frac{1}{L} (H(n, n_j)) = \\frac{1}{L} \\sum_{i=0}^{L-1} 1_{s_i \\neq s_j}$, and the average normalized Hamming distance of a node n with respect to all nodes in $n_{0:t}$ as $a_{0:t}(n) = \\frac{1}{W} \\sum_{i=0; n_i \\neq n} \\delta(n, n_i)$ where W = t if $n \\in n_{0:t}$ or W = t + 1 otherwise, noting that in the first case we are skipping a node's comparison with itself.\nLet the empirical count distribution be $\\mu_i(s) = \\frac{N_{v_i}(s)}{t+1}$, and $\\mu_{min}(s) = min_{i \\in V} (\\mu_i(s))$, noting that the minimum is over the entire set of variables $V = U(1)$ rather than the set of true variables $U^+(1)$ in a state s used in Definition 1 and 2, and $0 \\leq \\mu_i(s) \\leq 1$. We provide a justification of this change through Propositions 1 and 2, demonstrating a correspondence between empirical counts and Hamming distances over U(1) in binary vectors, and the same metrics over the set $U^+(1)$ in binary vectors that include negated variables. This allows us to align our results with a STRIPS representation that includes negated variables. For the set of L variables V, we define $s_{neg}$ for states s over $V_{neg} = V \\cup \\{ \\neg v | v \\in V\\}$ such that $s_{neg}(v) = s(v)$, $s_{neg}(\\neg v) = \\neg s(v)$ for all $v_i \\in V$. Since $H(s, s') = |\\{i | s(v_i) \\neq s'(v_i)\\}|$, we define $H_{true}(s, s') = |\\{i | s(v_i) \\neq s'(v_i), s(v_i) = 1\\}|$ and $H_{false}(s, s') = |\\{i | s(v_i) \\neq s'(v_i), s(v_i) = 0\\}|$, noting that $H(s, s') = H_{true}(s, s') + H_{false}(s, s')$.\nProposition 1. The Hamming distance H(s, s') between states s and s' equals the true Hamming distance $H_{true}(s_{neg}, s'_{neg})$, considering only variables in $s_{neg}$ that are true.\nProof. Since for each variable $s(v_i) = 1 \\in s$ there are two variables $s_{neg}(v_i) = 1 \\in s_{neg}$ and $s_{neg}(\\neg v_i) = 0$, and for each variable $s(v_i) = 0 \\in s$ there are two variables $s_{neg}(\\neg v_i) = 1 \\in s_{neg}$ and $s_{neg}(v_i) = 0$, follows that $H_{true}(s_{neg}, s'_{neg}) = H_{true}(s, s') + H_{false}(s, s') = H(s, s') $\\Box\nProposition 2. The empirical count $N_i(s)$ for any value $s(v_i)$ corresponds to the empirical count $N_x(s_{neg})$, where x = i if s(vi) = 1 and x = j if s(vi) = 0 where $s_{neg}(u_j) = s_{neg}(v_i)$.\nProof. From the definition of $s_{neg}$, for every variable $s_j(v_i) = 0 \\in s_{0:t}(v_i)$ we have that $s_{neg;j}(v_i) = 0$ and $s_{neg;j}(\\neg v_i) = 1$. The proof for $s_j(v_i) = 1$ case is symmetrical. Proposition 2 follows. \\Box\nIt then follows from Proposition 2 that selecting the minimum count $c_{V_{neg}}(s_{neg;t+1}) = min_{v \\in V} (N_i(s_{t+1}))$.\nTheorem 3. The average normalized Hamming distance $a_{0:t}(s)$ of a state s to the t + 1 states in history $s_{0:t}$ is upper bounded by:\n$a_{0:t}(s) \\leq 1 - \\mu_{min}(s)$\nProof. The average Hamming distance of $s(v_i)$ with respect to the value of variable i in all states $s_j \\in s_{0:t}$ is equivalent to\n$\\frac{1}{t+1} \\sum_{j=0}^{t} 1_{s_j \\neq s_i} = 1 - \\frac{1}{t+1} N_{v_i}(s) = 1 - \\mu_i(s)$\nThus we have\n$a_{0:t}(s) = \\frac{1}{L} \\sum_{i=0}^{L-1} \\frac{1}{t+1} \\sum_{j=0}^{t} 1_{s_j \\neq s_i} = \\frac{1}{L} \\sum_{i=0}^{L-1} 1 - \\frac{1}{t+1} N_{v_i}(s)$\n$= \\frac{1}{L} \\sum_{i=0}^{L-1} 1 - \\mu_i(s) = \\frac{1}{L} \\sum_{i=0}^{L-1} \\frac{t+1 - N_{v_i}(s)}{t+1} \\leq \\frac{1}{L} \\sum_{i=0}^{L-1} (1 - \\mu_{min}(s)) = 1 - \\mu_{min}(s)$ $\\Box$\nParent-child average distance comparison We provide a set of results on the average normalized Hamming distances of a child node with respect to its parent node, and the impact that the count-based novelty of a node has on this value. Incorporating constraints on the changes between parent and child nodes enables us to obtain much tighter bounds compared to Theorem 3, reflecting the parent-child dynamic that exists between expanded and generated nodes. Let $n^p$ and $n^c$ be the child and parent node respectively, where an action $a \\in A$ is performed on $n^p$ to flip the value of e variables, which we refer to as the effects. Let n be a newly generated node $n_t$.\nTheorem 4. Lower and upper bounds for $a_{0:t}(n^c)$ are given by:\n$a_{0:t}(n^p) - \\frac{t-1}{t} \\frac{e}{L} \\leq a_{0:t}(n^c) \\leq a_{0:t}(n^p) + \\frac{t-1}{t} \\frac{e}{L}$"}, {"title": "Proof", "content": "In the lower bound, all e effect variables change their corresponding valuation to match with all states in history except for the parent node, reducing Hamming distance to each state by 1 for each effect e. Parent and child states share all variable valuations except for the e effects, which change valuation from parent to child node. This yields, for all cases where $n' \\in n_{0:t}, n' \\neq n^p$ and $n' \\neq n^c$\n$\\delta(n^c, n') \\geq \\frac{1}{L} (H(n^p, n') - e) = \\delta(n^p, n') - \\frac{e}{L}$ (2)\n$\\delta(n^c, n^p) = \\frac{1}{L} (H(n^p, n^p) + e) = \\frac{e}{L}$ (3)\nWe can redefine the average $a_{0:t}(n)$ as\n$a_{0:t}(n) = \\frac{1}{t} [\\sum_{i=0; n_i \\notin \\{n^p, n^c\\}} \\delta(n, n_i) + \\delta(n, n^p)]$ (4)\nSince we define that $n = n^c$:\n$a_{0:t}(n) = \\frac{1}{t} [\\sum_{i=0; n_i \\notin \\{n^p, n^c\\}} (\\delta(n^p, n_i)) + \\delta(n^c, n^p)]$ (5)\nSubstituting (2) and (3) into (4), noting that $\\sum_{i=0; n_i \\notin \\{n^p, n^c\\}} (\\cdot) = (t - 1)$, and then substituting (5) yields Theorem 4.\nFor the upper bound, we note that it is symmetrical in that in the upper bound all effects e are novel, that is, their variable valuation in $n^c$ has never been observed in $n_{0:t-1}$. Thus we get $\\delta(n^c, n') \\leq \\delta(n^p, n') + \\frac{e}{L}$. Following the same procedure yields the upper bound.\nTheorem 5. Given a minimum empirical count distribution $\\mu = \\mu_{min} (n)$, the upper bound $a_{0:t}(n)$ with respect to $\\mu$ is given by:\n$a_{0:t}(n) \\leq a_{0:t}(n^p) + \\frac{t-1}{t} \\frac{e - 2e\\mu}{L}$ $\\Box$\nProof. Since $\\mu$ is the minimum feature occurrence, acting as a constraint, upper bound occurs when all effects e have occurrence equal to $\\mu$, that is, the minimum possible occurrence they are allowed to have. Thus, for t - 1 nodes $n' \\in n_{0:t-1}, n' \\neq n^p$, we have that $\\delta(n^c, n') = \\frac{1}{L} (H(n^p, n') + e)$ a total of $(1 - \\mu) \\cdot (t - 1)$ times, and $\\delta(n^c, n') = \\frac{1}{L} (H(n^p, n') - e)$ a total of $\\mu \\cdot (t - 1)$ times. Proof follows from derivation in Theorem 4. $\\Box$\nTheorem 6. Lower bound for $a_{0:t} (n)$ when $\\mu_{min} (n) = 0$ is given by:\n$a_{0:t}(n) \\geq a_{0:t} (n^p) - \\frac{t-1}{t} \\frac{e-2}{L}$ $\\Box$\nProof. In the lower bound, one effect is novel, and e-1 effects match all previous history except $n^p$. Thus $\\delta(n^p, n') = \\frac{1}{L} (H(n^p, n') - (e - 1) + 1)$. Proof follows from derivation in Theorem 4. $\\Box$\nA comparison of the bounds in Theorem 4 with those in Theorems 5 and 6 demonstrates the relation between novelty count and Hamming distance through improved bounds, in terms of changes in the average distances from parent to child node, for nodes with a low empirical count $N$, which acts through the empirical count distribution $\\mu$. The upper bound in Theorem 5 details the main improvement, signalling greater potential of the child node being located in newer areas of the state space. Theorem 6 is a notable special case for novel variable valuations never encountered before, which guarantees an improvement of the lower bound through the novel information that could not have already been observed in the parent node. Through"}, {"title": "Theorems 7", "content": "the recursive nature of Theorems 4 to 6, we also conclude that paths consisting of low count-based novelty nodes are more likely to exhibit rapidly increasing average Hamming distances, thus facilitating a quicker exploration of novel state spaces. We cannot establish a tighter lower bound in Theorem 5 because the least common feature might not be an effect, however modifying count-based novelty metrics to consider effect occurrences could overcome this limitation. Still, greater Hamming distances alone fail to explain how count-based novelty benefits search efficiency. We provide Theorems 7 and 8 to tie our results to prior theoretical contributions on novelty-based search (see [5, 8, 17]) through an analysis of the expected count of novel tuples of size k (k-tuples).\nEstimating novel k-tuples Let history $s_{0:t}$ represent t + 1 independent and uniformly distributed binary vectors of size L. A tuple is novel if its valuation in $s = s_{t+1}$ was not observed in any state in history $s_{0:t}$.\nTheorem 7. The expected number of novel tuples of size k found in $s = s_{t+1}$ given search history $s_{0:t}$ is given by:\n$E[\\#\\, novel \\, k-tuple] = {L \\choose k} [1 - (1 - a_{0:t}(s))^k]^{t+1}$ (6)\nProof. From equation (1) we can obtain $a_{0:t}(s) = \\frac{1}{t+1} \\sum_{j=0}^{t} \\sum_{v_i \\in V} [1\\{s_j(v_i) \\neq s(v_i)\\}] = E_{s_j \\in s_{0:t}, v_i \\in V} [1\\{s_j(v_i) \\neq s(v_i)\\}] = P(s_j(v_i) \\neq s(v_i) for some j, i). Thus, the probability that it has the same value becomes $1 - a_{0:t}(s)$, and for a tuple of size k, the probability that any of its constituent variable values is different in $s_j$ than in s is $1 - (1 - a_{0:t}(s))^k$. Calculating the union for a tuple over the full history and multiplying by the number of possible tuples of size k yields the expectation in (6).\nTheorem 8. The expected number of novel tuples of size k found in state $s = s_{t+1}$ given information on occurrence count $N = N(s)$ for some variable $v \\in V$ and search history $s_{0:t}$ is given by:\n$E[\\#\\, novel \\, k-tuple | N(s) = N] = \\frac{{L-1 \\choose k} [1 - (1 - a_{0:t}(s))^k]^{N} + {L \\choose k} [1 - (1 - \\beta_{0:t}(s))^{k-1}]^{t+1-N}}{L \\choose k} [1 - (1 - \\beta_{0:t}(s))^k]$\nwhere $\\beta_{0:t}(s)$ represents the average normalized Hamming distance after discounting the contribution of variable v:\n$\\beta_{0:t}(s) = \\frac{a_{0:t}(s) \\cdot L - (1 - \\mu)}{L-1}$\nProof. The left-hand side component of the addition is given by equation (6) taken over tuples deriving from variables except for the variable v whose empirical count N we observe. The right-hand side component is given by the probability $1 - (1 - \\beta_{0:t}(s))^{k-1}$ that, for some variable x other than v in a k-tuple containing v and in a state $s_j$ where $s_j(v) = s(v), s_j(x) \\neq s(x)$. Thus, the tuple's valuation in $s_j$ is different than in s. Taking a union over N states with matching v valuation and multiplying by the total number of tuples in s containing v yields the right-hand side component. Summing the two expectations proves the theorem.\nTheorem 7 reveals that, without count information, the expectation decreases exponentially with increasing t, rendering the measure effective only for small history sizes. Conversely, Theorem 8 introduces a component independent of t and exponential in count number N, emphasizing the crucial role of the minimum count function in identifying states likely to contain novel tuples, necessary to fulfill new action preconditions."}, {"title": "4 Trimmed Open List", "content": "Balancing the amount of memory occupied by low-rank nodes is a common strategy which allows for better ranked exploratory nodes to appear further down the search. Polynomial width-novelty planners prune nodes with novelty value greater than a threshold, as they are deemed not useful for the search. Similarly, count exploration methods generate many nodes with high counts, which are unlikely to ever be expanded. However, adopting a threshold as in the width-novelty case is unfeasible due to the granularity of the metric.\nTo address the challenge of high memory usage by poorly ranked nodes in the open list, we introduce the Trimmed Open List (Alg. 1). Built on a binary heap, this open list limits its growth by pruning less promising nodes when it exceeds a predefined size limit Z. This pruning process involves randomly selecting a leaf node, comparing its heuristic value with a new node n using the open list's comparison function, and then pruning or swapping nodes based on their heuristic values. A unique heapify-up operation is applied to the inserted leaf, which, unlike standard heaps, is not required to be the last element.\nFurthermore, we developed a Double Trimmed Open List for heuristic alternation [24], accommodating dual open lists for node insertion under distinct heuristics and enabling alternate node retrieval. This variant employs the same pruning strategy but distinguishes itself by tracking each node's interaction with the open lists either being popped or trimmed. A node becomes eligible for deletion when its interaction count equals the number of lists it is associated with,"}, {"title": "5 Experiments", "content": "Our experiments were conducted using Downward Lab's experiment module [25], adhering to the IPC satisficing track constraints of 1800 seconds and 8 GB memory. Each test was ran on a single core of a cloud instance AMD EPYC 7702 2GHz processor. We implemented all proposed planners in C++, using LAPKT's [21] planning modules. For hybrid experiments, LAMA-First [23] and Scorpion-Maidu [3, 26] served as backend components, employing Fast-Downward [10] and the IPC2023 code repository [4], respectively. Except for Approximate-BFWS, BFWS variants utilized the FD-grounder for grounding [11], however in problems where the FD grounder produces axioms (unsupported by LAPKT), LAPKT automatically switched to the Tarski grounder [7]. Approximate-BFWS exclusively used the Tarski grounder, following its initial setup and IPC-2023 configuration. We utilized IPC satisficing track benchmarks as in [27], selecting the latest problem sets for recurring domains. We conducted two sets of experiments. The first benchmarked our planners against the base BFWS(f5) solver, evaluating the degree to which our proposed classical count-based novelty and trimmed open list techniques improve the coverage of BFWS(f5) and its exploration efficiency, measured as the number of expansions required to find a solution. The second set of experiments compared our hybrid configurations to Dual-BFWS, Approximate-BFWS, LAMA-First, and a \"first\" version of the IPC-2023 satisficing track winner Scorpion-Maidu that runs its first iteration, in order to assess the coverage gains obtainable by adopting our proposed frontend solver alongside existing solvers in a dual configuration, relying on memory thresholds alongside more traditional time thresholds to trigger the frontend to fallback."}, {"title": "5.1 Count-based solvers", "content": "We define three new planning solvers to evaluate the performance of our proposed trimmed open list and classical partitioned count-based novelty techniques. All our solvers are based on the BFWS(f5) search algorithm [18]. f5 is the evaluation function (w, #g) where w is the novelty measure and the goal counter #g counts the number of atomic goals not true in s. The novelty measure w is computed given partition functions #g and #r(s), that is $w\\{\\#g,\\#r\\} (see"}, {"title": "5.2 Hybrid solvers with BFNOS frontend", "content": "We adopt BFNOS_t (f5 (C1), f5 (W2)) as a frontend solver, capped by a 6 GB memory threshold and a time threshold close to the overall time limit, to enable backend fallback for all unresolved searches. We pair it with three backend planners from literature: the Dual-BFWS backend component (BFNOS-Dual), LAMA-First (BFNOS-LAMA), and the \"first\" version of Scorpion-Maidu (BFNOS-Maidu-h\u00b2), in its IPC2023 configuration with the h\u00b2-preprocessor [1]. These were chosen for their complementary heuristics to our frontend's f5 partitioning, promoting diverse solution strategies to enhance coverage diversity. Frontend time thresholds are set to 1600 sec with BFNOS-Dual and BFNOS-LAMA, and 1400 sec for BFNOS-Maidu-h\u00b2, to account for up to 180 sec of preprocessing allowance.\nMemory threshold Solvers tend to exhibit diminishing returns in the number of instances solved with respect to both time and memory. Thus, as memory usage increases while solving an instance, it is more likely that the instance will not be solvable within the defined memory constraint, indicating that the adopted heuristics are not effective for that particular problem. Novelty heuristics W2 and"}, {"title": "Conclusion", "content": "In this paper we introduce the concept of count-based novelty as an alternative novelty exploration framework in Classical Planning, showing that the arity-1 variant of our proposed metric is capable of effectively predicting states with novel k-tuples only using a constant number of tuples. We introduce the use of counts and Hamming distances to relate the exploratory behavior of count-based novelty to the existing body of knowledge on Novelty"}]}