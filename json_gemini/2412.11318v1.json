{"title": "Generics are puzzling.\nCan language models find the missing piece?", "authors": ["Gustavo Cilleruelo Calder\u00f3n", "Emily Allaway", "Barry Haddow", "Alexandra Birch"], "abstract": "Generic sentences express generalisations\nabout the world without explicit quantification.\nAlthough generics are central to everyday com-\nmunication, building a precise semantic frame-\nwork has proven difficult, in part because speak-\ners use generics to generalise properties with\nwidely different statistical prevalence. In this\nwork, we study the implicit quantification and\ncontext-sensitivity of generics by leveraging\nlanguage models as models of language. We\ncreate CONGEN, a dataset of 2873 naturally\noccurring generic and quantified sentences in\ncontext, and define p-acceptability, a metric\nbased on surprisal that is sensitive to quantifica-\ntion. Our experiments show generics are more\ncontext-sensitive than determiner quantifiers\nand about 20% of naturally occurring generics\nwe analyze express weak generalisations. We\nalso explore how human biases in stereotypes\ncan be observed in language models\u00b9.", "sections": [{"title": "1 Introduction", "content": "Humans use generalisations to abstract away from\nparticular objects, events or facts and convey regu-\nlarities about the world.\nIn this work, our focus is on generic sentences,\nsuch as insects have six legs or mosquitoes carry\nmalaria, which express generalisations without ex-\nplicit quantification. These two generic sentences\nare acceptable in many contexts, but the quantifi-\ncations they convey are widely different: almost\nall insects have six legs, but fewer than 1% of\nmosquitoes carry malaria.\nOne way of expressing generalisations in lan-\nguage is through explicitly quantified sentences,\nsuch as most insects are nocturnal or some\nmosquitoes have white stripes. Quantified sen-\ntences express statistical claims about the members\nof a kind that share the predicated property: for\nexample most if a majority of insects are nocturnal\nor some if a minority of mosquitoes have white\nstripes.\nEven as generics seem to express inconsistent\nquantifications, they are at the heart of commu-\nnication and dissemination in science (DeJesus\net al., 2019; Bowker, 2022), medical research (Pe-\nters et al., 2024), and politics (Novoa et al., 2023).\nFurthermore, in the social realm generics serve as\nlinguistic vehicle for social essentialism (Rhodes\net al., 2012) and stereotyping (Leslie, 2017; Bosse,\n2022).\nThe nature of generics and their importance\nin communication has led to extensive literature\non the semantics of generic sentences (e.g., Carl-\nson, 1977b; Cohen, 1999; Leslie, 2008; Liebesman,\n2011; Sterken, 2015a; Nickel, 2016; Tessler and\nGoodman, 2016; Stovall, 2019; Nguyen, 2020;\nBosse, 2021; Kirkpatrick, 2023). However, many\nopen questions remain. These include how they re-\nlate to quantifiers and the degree to which generics\nare context sensitive. In this work, we use language\nmodels to explore the implicit quantification and\ncontext-sensitivity of generics, and how they are\naffected by human biases around stereotypes.\nLanguage models have demonstrated unprece-\ndented performance in a variety of linguistic tasks,\nsuch as machine translation (Kocmi et al., 2024) or\nconversational assistance (Chiang et al., 2024). We\ndescribe how speakers use generics by studying the\nsurprisal in language models for various naturally\noccurring generic and quantified sentences.\nMost existing datasets of generics are synthetic,\noften derived from knowledge bases or generated\nby language models (Bhakthavatsalam et al., 2020;\nAllaway et al., 2024). Since the examples in these\ndatasets are machine-generated and/or lack a con-\ntext in which they might be uttered, there is no\nguarantee that they represent how speakers actually\nuse generics. Therefore, in this work we introduce\nCONGEN, a dataset of naturally occurring generic"}, {"title": "2 Background", "content": "Semantic theories of generics guide and scaffold\nour experimental design. In what follows, we\npresent linguistic background on generics (\u00a72.1)\nand then we sketch two theories of genericity\nrelated to our experiments (\u00a72.2): generics-as-\ndefaults and contextualism. Finally, we introduce\ntwo phenomena that involve generics (\u00a72.3): stereo-\ntypes and generic overgeneralisation. These the-\noretical elements motivate our research questions\nand frame the interpretation of experimental re-\nsults."}, {"title": "2.1 Generics", "content": "The term generics covers multiple linguistic phe-\nnomena that abstract away from particular objects,\nmembers, or events. In our work, we focus on one\nspecific kind of generics: bare plural character-\nistic sentences. Bare plurals are noun phrases in\nplural form without a definite or indefinite article2.\nCharacteristic sentences are propositions that do\nnot express specific episodes or isolated facts, but\nrather report a kind of general property or regularity\n(Carlson and Pelletier, 1995).\nIn linguistics, generics are traditionally analyzed\nas quantifiers (Carlson, 1977b), with an unpro-\nnounced implicit operator GEN that has a role simi-"}, {"title": "2.2 Generics in Philosophy of language", "content": "In this section we introduce two influential ac-\ncounts from philosophy of language: generics-as-\ndefaults and contextualism. These supply contrast-\ning views on how to explain the diversity in generic\nuse and how they are affected by context; topics\nwe discuss in our experiments (\u00a75.2 and \u00a75.3 re-\nspectively).\nGenerics as defaults. The generics-as-defaults\ntheory posits generics as the linguistic manifesta-\ntion of a default cognitive mechanism of general-\nisation (Leslie, 2008). In contrast to quantifiers,\nwhich express generalisations based on statistical\nsurveying, generics express primitive generalisa-\ntions based on what we perceive as characteristic,\ndistinctive or striking in the world (Leslie, 2007).\nContextualism. Sterken (2015a) argues for a\ncontextualist view of generics: generics express\nwidely different generalisations in different con-\ntexts. The unpronounced generic operator GEN\npicks out a generalisation as a function of the con-\ntext of the utterance, similarly to how the deter-\nminer that picks out a referent."}, {"title": "2.3 Human biases in the usage of generics", "content": "Generics are often used in ways that do not follow\nlogical reasoning and highlight human cognitive\nbiases (Leslie, 2017; Neufeld et al., forthcoming).\nOne important example is the connection generics\nhave with how we express stereotypes; we explore\nthis in experiment \u00a75.4.\nGeneric overgeneralisation. One example of\nillogical use of generics is generic overgenerali-\nsation (Leslie et al., 2011; Lazaridou-Chatzigoga\net al., 2017): humans often use universal quan-\ntification (all) in situations where the generic is\nacceptable even when exceptions exist. This effect\nhas also been documented in language models (All-\naway et al., 2024; Ralethe and Buys, 2022).\nStereotypes. In the social realm, striking gener-\nics are linked to stereotyping and the essentializa-\ntion of social groups (Rhodes et al., 2012; Leslie,\n2017). In particular, Cimpian et al. (2010) and\nKhemlani et al. (2009) demonstrate a psycholog-\nical connection between striking information and\nan overestimation of statistical frequencies. This\nmeans that humans seem to reason from the quan-\ntifier some to most and even to all when striking\nproperties are at play (Leslie, 2008). Addition-\nally, generics are also central in recent NLP studies\non preventing and countering stereotypes (Bosse,\n2022; Allaway et al., 2023b; Mun et al., 2023)."}, {"title": "3 Related work", "content": "Recent works that study generics and language\nmodels use prompting to test generic overgenerali-\nsation, property inheritance (Allaway et al., 2024)\nand, more generally, the effect of quantifiers on sen-\ntence meaning (Collacciani et al., 2024). However,\nfor studying how language models model quantifi-\ncation and generics, prompting has several short-\ncomings. In particular, the effect of small variations\nin the prompt on model behavior is not well under-\nstood (Salinas and Morstatter, 2024). Additionally,\nprompting requires an instruction tuned model, of-\nten trained to be a virtual assistant (Zhang et al.,\n2024), which may skew the underlying language\ndistribution in unaccounted ways.\nTo avoid the drawbacks of prompting, studies\nhave also looked at the internal states of pre-trained\nmodels. Collacciani et al. (2024) compare the sur-\nprisals of quantified sentences but fail to find a\nsensitivity to quantification in language models.\nAs the authors note, this may be due to their metric\nnot being sufficiently expressive. While the work\nfrom Gupta (2023) also uses surprisal, in this case\nof critical words, to draw conclusions about quan-\ntifier comprehension in language models, it does\nnot take generics into consideration. In contrast,\nin this work we develop a new metric that uses\nthe surprisal of the predicated property tokens, and\nshow that it describes rich quantificational dynam-\nics modelled by language models.\nSeveral datasets exist that specifically target\ngenerics. GENERICSKB is a dataset (3M samples)\nthat combines naturally occurring generic and quan-\ntified statements with synthetic examples derived\nfrom knowledge bases (Bhakthavatsalam et al.,\n2020). The naturally occurring generics are se-\nlected with a BERT-based scorer trained on human\nannotations. The GEN-A-TOMIC corpus contains\nsynthetic generics generated by GPT2-XL (Bha-\ngavatula et al., 2023). Additionally, datasets of\nsynthetic generics exemplars (i.e., cases where the\ngeneric does and does not hold) have been con-\nstructed (Allaway et al., 2023a, 2024).\nAll of these datasets contain synthetic examples\n(either machine generated or derived from knowl-\nedge bases) and do not include context, which is\nkey to understanding how speakers use generics. In\ncontrast, our CONGEN dataset contains only natu-\nrally occurring human-annotated sentences, each\nwith an associated document as context."}, {"title": "4 Methodology", "content": "Theorists emphasize the context-sensitivity of\ngeneric sentences (Sterken, 2015a; Nickel, 2016;\nAlmotahari, 2023). The lack of consensus on how\ncontext affects the use of generics motivates the\nconstruction of CONGEN. To the best of our knowl-\nedge, this is the first dataset that targets generics in\ncontext.\nCONGEN consists of naturally occurring bare\nplural generics and quantified statements (with\nsome, most and all) in context. These are drawn\nfrom a subset of DOLMA (Soldaini et al., 2024)\nand from 2024 Reddit comments. DOLMA is a\ncleaner version of Common Crawl and may have\nbeen used in the training data for popular language\nmodels (e.g., MISTRAL). Therefore, we include\nrecent Reddit comments to validate our findings on\ndata the models have not been trained on.\nIn order to find bare plural generic sentences in\nsuch massive collections of data, we train a binary"}, {"title": "4.2 Metric: p-acceptability", "content": "Generic sentences can be used to express gen-\neralisations with vastly different quantificational\nstrength: from weak generics (e.g., mosquitoes\ncarry malaria) to quasi-definitional ones (e.g.,\nmosquitoes are insects). To describe and study\nthese quantificational dynamics in language mod-\nels, we introduce a criterion to answer the following\nquestion: What is the quantifier that best fits the\nkind-property relation expressed in a sentence?\nConsider quantified bare plural generalisations\nwith a simple structure (context + quantifier + bare\nplural + verb + property), where the quantifier\nis one of all, most, some or the generic (\u00d8). We\npropose a notion of acceptability that selects the\nquantifier that makes the property more likely given\nthe subject, verb and context.\nDefinition 4.1 (p-acceptability). Let Q be a set of\ncandidate quantifiers, s a bare plural generic and 0 a\nlanguage model. We construct {q + s | q \u2208 Q} the\nset of variations of s\u00b3. We call q the p-acceptable\nquantifier for s if q + s is the sentence with the\nlowest surprisal of the property tokens (i.e. tokens\nafter the verb):\np-acceptable(s; Q, 0) := argmin Hp(q + s; 0)\nqEQ\nwhere Hp is the surprisal of the property tokens\nHp(s; 0) := 1/|P| \u03a3(i\u2208P)logp\u03b8(ti|t<i)\nwith P is the set of indices of the property tokens\nand ti the tokens in sentence s.\nWe build the set of variations of s as {s, 'all'+s,\n'most'+s, 'some'+s}. For sentences that originally\nhad an explicit quantifier, we remove the quanti-\nfier to obtain s. To compute the p-acceptability\nof a sentence s with context c, we build the set of\nvariations {c + q + s | q \u2208 Q}.\nFor example, consider the sentence s = \ntigers have stripes which can be split into word\ntokens to = tigers, t\u2081 = have t2 = stripes.\nRecall that the candidate quantifiers are Q = \n{all, most, some, \u00d8}. Then, the set of variations\nwill be all tigers have stripes, most tigers have\nstripes, some tigers have stripes and tigers have\nstripes. The surprisal on the property tokens (in this\ncase t2) with the quantifier \u201call\u201d is then calculated"}, {"title": "5 Experiments", "content": "The experiments that follow use p-acceptability (de-\nfined in \u00a74.2) to study quantification and generics\nthrough language models. First, we validate that p-\nacceptability describes quantification in CONGEN\nand GENERICSKB (\u00a75.1). Then, we explore three\naspects of generics: their implicit quantificational\nstrength (\u00a75.2), their context-sensitivity (\u00a75.3), and\ntheir role in stereotypes (\u00a75.4).\nWe use three state-of-the-art open-source lan-\nguage models of increasing size: MISTRAL-7B,\nMISTRAL-8\u00d77B and MISTRAL-8\u00d722B (Jiang\net al., 2023). Additional details on the models used\nare available in Appendix A.\nBecause our focus is on bare plural generics, we\nfilter out of GENERICSKB those generics that are\nnot bare plural and call this subset GENERICSKB-\nBP (N = 570358). Implementation details can be\nfound in Appendix D."}, {"title": "5.1 Can p-acceptability describe\nquantification?", "content": "Quantifiers specify a prevalence relation between\nmembers of a kind and a property. In terms of this\nrelation, we would expect all and most to be in-\nterchangeable in many contexts, likewise for most\nand some but never for all and some. This exper-\niment recovers these commonsense intuitions of\nquantification with p-acceptability.\nExperimental setup. For each sentence in CON-\nGEN and GENERICSKB-BP, we build the set of\nvariations and get the p-acceptable quantifier. We\nplot these p-acceptability percentages against the\noriginal quantifiers of the sentences, that is, how\noften each quantifier makes the property tokens\neasier to predict for the language model.\nResults. In both datasets, the most prevalent p-\nacceptable quantifier corresponds to the original\nquantifier (Figure 1). In GENERICSKB data, the\ndistinctions are less clear, with bigger confusion\nbetween, for example, all and most.\nFor sentences that were originally generic, all\nand most are the most prevalent wrongly p-\naccepted quantifiers. This agrees with most gener-\nics being majority generics.\nThe prevalence of all in originally some sen-\ntences from GENERICSKB-BP seems counter-\nintuitive. We believe that this is due to noise in the\ndataset, rather than the metric. On CONGEN, p-\nacceptability recovers an intuitive profile for some\nsentences: some is the most prevalent quantifier\nand is mostly confused with most, rarely with all\nor the generic.\nP-acceptability captures semantic intuitions on\nquantification across both datasets. In what follows,\nwe use p-acceptability to investigate some aspects\nof how speakers use generics."}, {"title": "5.2 What is the implicit quantification of\ngenerics?", "content": "Although generic sentences present no overt quan-\ntification operator, we can investigate which quanti-\nfier better describes the kind-property relationship\nexpressed in a generic with p-acceptability. Given\na generic sentence, we study its implicit quantifica-\ntion by finding the p-acceptable explicit quantifier.\nExperimental setup. In this experiment we con-\nsider generics from CONGEN and GENERICSKB-\nBP. We compute the p-acceptability excluding"}, {"title": "5.3 Are generics context-sensitive?", "content": "Semantic theories in philosophy of language hy-\npothesize that the context of generic sentences de-\ntermines the semantic content of GEN (\u00a72.2). We\nquantify the effect of different context windows on\nimplicit quantification using p-acceptablility and\nthe multi-sentence contexts in CONGEN.\nExperimental setup. For each sentence in CON-\nGEN, we compute the p-acceptable quantifier at\nincreasing sizes of left-side context. We increase\nthe context size in chunks of 4 tokens, irrespective\nof word or sentence boundaries (Table I.6).\nWe measure the percentage of correct predic-\ntions by p-acceptability as instances where it re-\ncovers the original quantifier. For sentences that\nare originally generics, we also replicate this setup\n(excluding GEN from the candidate quantifiers) for\ndifferent left-context windows.\nResults. Figure 3 shows the percentage of cor-\nrect predictions for each original quantifier (e.g.\ngreen corresponds to the percentage of times gen\nis p-accepted on generic sentences at each context\nlength). In originally generic sentences, we have\na 20% increase in accuracy across the first 20 to-\nkens of context, which roughly correspond to the\npreceding sentence. For explicitly quantified ex-\npressions, context does not improve the accuracy\nof p-acceptability as much as for generics.\nAs control, we replicate the experiment with ran-\ndom context sampled from other documents with\nthe same original source (DOLMA or Reddit) and\nfind no improvement on any quantifier, including\nGEN. Details are available in Appendix F.\nWe investigate if the increase in accuracy that\ncontext has on generic sentences is related to their\nimplicit quantification. In Figure 4 the relative per-\ncentages of each quantifier are mostly unaffected by\ncontext, with a slight increase of all and decrease\nof most.\nFor those samples where context is needed for\np-acceptability to predict the correct quantifier, we\ndefine the minimal context as the smallest context\nneeded for the correct prediction. We find a very\nlow presence of quantifiers in the minimal contexts\nof generic sentences. A preliminary analysis of\nthe linguistic characteristics of these contexts is"}, {"title": "5.4 Are stereotyping generics different?", "content": "Stereotypes are often expressed linguistically\nthrough striking generics where the subject is a so-\ncial group. This is partly because, when dangerous\nproperties are predicated, humans perceive them as\nmore prevalent than they really are (Cimpian et al.,\n2010; Leslie, 2017). In the following experiment,\nwe study the implicit quantification in language\nmodels of negative and positive stereotypes.\nExperimental setup. To study the implicit quan-\ntification in this subset of generics, we collect a\nsmall dataset of stereotypes (N = 504) divided\ninto real (the subject-property is a real-world stereo-\ntype) and invented sentences (the subject is an in-\nvented word that morphologically resembles a de-\nmonym).\nWe extract real negative stereotypes from the\nSocial Bias Frames dataset (Sap et al., 2020), a\ncollection of offensive texts annotated with implied\nstereotypes. For real positive stereotypes, we gener-\nate samples based on tradition and culture for differ-\nent social groups. The invented sentences are built\nby combining invented demonyms with a list of\nnegative and positive predicates (e.g., craguils are\nmurderers or corriards are warm and hospitable).\nDetails are available in Appendix H and Table I.7.\nTo further explore how effective purely linguis-\ntic strategies are at mitigating the bias in striking\ngenerics (Leslie, 2017; Carnaghi et al., 2008; Gel-\nman and Heyman, 1999), we generate the following\nthree paraphrases for each social group in a stereo-\ntype: bare plural (catalans are lovely), singular +\n'people' (catalan people are lovely) and \u2018people\nwho are\u2019 + singular (people who are catalan are\nlovely).\nWe compare the results between the pre-trained\nand instruction tuned versions of MISTRAL-7B, as\none objective of language model designers when\ninstruction-tuning models is to mitigate social bi-\nases (Zhang et al., 2024).\nResults. Figure 5 reports the percentage of p-\nacceptable quantifiers for each paraphrase and type\nof stereotyping generic. For negative stereotypes,\nall is the predominant quantifier. This aligns with\nthe theoretical and empirical observation that speak-\ners use universal quantification with this subset of\nstriking generics (Cimpian et al., 2010). Note that\nwith the people who are paraphrase this is not the\ncase; we observe a stark contrast, where some is\nthe most prevalent p-acceptable quantifier. The\ninstruction-tuned model predicts more some and\nless all. Interestingly, for invented negative cases\neven in the ppl who paraphrase, all is the most\nprevalent quantifier.\nIn contrast to the negative stereotypes, the pre-\ndominant quantifier is most for positive stereotypes.\nThis further supports hypotheses that the implicit\nuniversal quantification of negative stereotypes is\ndue to the strikingness of the predicate."}, {"title": "6 Discussion", "content": "In this work, we study different aspects of generics\nand quantified sentences through language models. We now discuss our results in relation to existing\ntheories of generics.\nWeak generics. Weak generics are central to dis-\ncussions of generics in philosophy of language. On\nthe one hand, Leslie (2008) uses the prevalence of\nstriking generics to support the idea that generics\nexpress primitive psychological generalisations. In\ncontrast, Sterken (2015b) proposes an error the-\nory where striking generics are false. Addition-\nally, Gustafsson (2023) examines weak (striking)\ngenerics and argues that generics are more hetero-\ngeneous than what the previous theories take them\nto be. Although these works use striking generics"}, {"title": "7 Conclusion", "content": "Generics are similar to quantifiers, yet speakers use\nthem in logically inconsistent ways. In this work,\nwe study the dynamics of quantification on generic\nand quantified sentences through language models.\nTo do so, we introduce a new dataset (CONGEN)\nand metric (p-acceptability). With these tools we\nestimate the prevalence of weak generics, identify\na distinct context-sensitivity in generics and show\nhow linguistic strategies can help mitigate stereo-\ntypes.\nWe believe our findings and methodology open\nnew doors for research on generics and quantifica-\ntion in language."}, {"title": "8 Limitations", "content": "Language models. Even though we use SOTA\nopen-source language models for our experiments,\ncurrently all competitive language models are\ntrained for profit rather than research; this in-\nevitably hinders any research effort.\nCompute limitations mean we run MISTRAL-\n8\u00d77B 8-quantized and MISTRAL-8\u00d722B 4-\nquantized. There is empirical evidence that quanti-\nzation does not have a big impact on performance\nfor MISTRAL models across a wide range of tasks\n(Badshah and Sajjad, 2024).\nWe test on a family of models with the autore-\ngressive transformer architecture. Exploration of\nhow other autoregressive families or architectures\n(such as MAMBA or diffusion) model quantifica-\ntion and generics is left for future work.\nMetric. The p-acceptability metric, as defined, is\nspecific to English sentences with a simple struc-\nture, as the bare plural does not exist in many other\nlanguages.\nImplicit quantification The implicit quantifica-\ntion in generic sentences could be more closely\nrelated to adverbial quantifiers than to the deter-\nminer quantifiers we study (Kirkpatrick, 2024). Fu-\nture work will need to expand both the metric and\ndataset to include other quantifiers like many, ev-\nery or few, in order to get a more comprehensive\npicture of quantification and its relation to generics.\nData. Sentences in CONGEN are first collected\nfrom DOLMA and Reddit by a classifier trained\nto identify generic and quantified sentences. Per-\nformance and biases of this classifier are not well\nexplored in this work and could affect the signifi-\ncance of the sampling. Another source of bias in\nCONGEN is that the first author annotates most of\nthe data. We plan on adressing these issues and\nexpanding CONGEN in future work.\nIn the stereotypes collection we build, the stereo-\ntypes are derived from a dataset based on Ameri-\ncan Twitter, which means they are centered around\nAmerican and Western culture and prejudice.\nContext. The concept of context can broadly\nmean three things in the philosophy of language\nliterature: the spatial and temporal context of the ut-\nterance, the subjective context of the speaker (such\nas intentions) or the linguistic context (previous\nutterances). In this work, we assume linguistic con-\ntext as the only source of context-sensitivity, as we\nstudy how language models model the context. If\ngenerics were context-sensitive in ways that are not\nexpressed or conveyed in language, our methodol-\nogy could not capture it."}]}