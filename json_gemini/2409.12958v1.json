{"title": "MURI: High-Quality Instruction Tuning Datasets for Low-Resource Languages via Reverse Instructions", "authors": ["Abdullatif K\u00f6ksal", "Marion Thaler", "Ayyoob Imani", "Ahmet \u00dcst\u00fcn", "Anna Korhonen", "Hinrich Sch\u00fctze"], "abstract": "Instruction tuning enhances large language models (LLMs) by aligning them with human preferences across diverse tasks. Traditional approaches to create instruction tuning datasets face serious challenges for low-resource languages due to their dependence on data annotation. This work introduces a novel method, Multilingual Reverse Instructions (MURI), which generates high-quality instruction tuning datasets for low-resource languages without requiring human annotators or pre-existing multilingual models. Utilizing reverse instructions and a translation pipeline, MURI produces instruction-output pairs from existing human-written texts in low-resource languages. This method ensures cultural relevance and diversity by sourcing texts from different native domains and applying filters to eliminate inappropriate content. Our dataset, MURI-IT, includes more than 2 million instruction-output pairs across 200 languages. Evaluation by native speakers and fine-tuning experiments with mT5 models demonstrate the approach's effectiveness for both NLU and open-ended generation. We publicly release datasets and models at https://github.com/akoksal/muri.", "sections": [{"title": "Introduction", "content": "Instruction tuning refines large language models (LLMs) based on user intentions, enhancing their ability to generalize across tasks and align with human preferences (Ouyang et al., 2022; Sanh et al., 2022; Muennighoff et al., 2023; Wang et al., 2022). While pre-training data can be automatically collected from the web, preparing instruction tuning data is challenging as it requires aligned instruction-output pairs. Three main approaches have been applied to create instruction tuning datasets: human annotation (Ouyang et al., 2022; K\u00f6pf et al., 2023; Conover et al., 2023), templatized NLP tasks (Sanh et al., 2022; Wang et al., 2022; Longpre et al., 2023a), and synthetic data generation via LLMs (Wang et al., 2023; Honovich et al., 2022).\nFor low-resource languages, these approaches face serious limitations. Human annotation is costly, and finding native speakers for low-resource languages is challenging. Templatizing NLP tasks restricts datasets to specific structures and domains, limiting their general applicability, and there is insufficient NLP task-annotated data for low-resource languages (ImaniGooghari et al., 2023). Synthetic data generation is constrained by the languages supported by existing models and suffers from validity (Wang et al., 2023) and creativity (Honovich et al., 2022) issues. Moreover, outputs of both template-based and synthetic data generation methods heavily rely on translation pipelines and are particularly prone to artifacts known as \u201ctranslationese\u201d (Gellerstam, 1986). These artifacts include simplified vocabulary and grammar, unidiomatic word order and expressions, and often neglect linguistic and cultural contexts. Such occurrences of translationese have been shown to negatively impact model training (Yu et al., 2022) by distorting examples and further distancing them from their linguistic and cultural context.\nConsequently, no existing model, open source or proprietary, supports low-resource languages with the quality necessary for high-quality instruction tuning dataset generation. This has resulted in a disparity, with English dominating 73% of the most popular datasets (Longpre et al., 2023), leaving low-resource language communities underserved.\nIn this work, we introduce Multilingual Reverse Instructions (MURI), a novel approach to generate instruction tuning datasets for low-resource languages without requiring annotators, task-annotated data, or pre-trained multilingual models. MURI employs the reverse instructions method proposed by K\u00f6ksal et al. (2024) and"}, {"title": "Related Work", "content": "Instruction Tuning Datasets Instruction tuning has emerged as a powerful approach to enhancing the instruction-following capabilities of LLMs, as demonstrated by numerous studies (Ouyang et al., 2022; Sanh et al., 2022; Muennighoff et al., 2023; Wang et al., 2022). The three primary strategies to create instruction tuning datasets are human curation, templatized tasks, and synthetic generation via LLMs.\nHuman-curated datasets, like Open Assistant (K\u00f6pf et al., 2023) and Dolly (Conover et al., 2023), involve extensive human annotation but are difficult to scale and extend to more languages due to high cost. Alternatively, datasets such as Public Pool of Prompts (P3) (Sanh et al., 2022), SuperNatural Instructions (NIv2) (Wang et al., 2022), and FLAN (Longpre et al., 2023a) utilize NLP task reformulation to reduce cost and enhance applicability but still struggle with general-purpose instruction following since their main focus is on NLU tasks.\nTo address these issues, synthetic datasets have been developed, such as Self-Instruct (Wang et al., 2023), TeGit (Chen et al., 2023), Unnatural Instructions (Honovich et al., 2022). These datasets offer greater task diversity but are challenged by issues of validity and creativity. The reverse instruction method (K\u00f6ksal et al., 2024), employing data augmentation via generative models and pre-training corpora, further exemplifies cost-effective dataset generation. A similar method has been successfully applied in Bactrian-X (Li et al., 2023), demonstrating its effectiveness in multilingual settings by leveraging translation for synthetic data.\nMultilingual instruction tuning has shown substantial benefits, especially for low-resource languages (Muennighoff et al., 2023). It not only maintains performance in English but also enhances capabilities in non-English languages with the help of a large scale of English examples (Shaham et al., 2024; AI@Meta, 2024). Despite these advancements, large-scale multilingual datasets often remain limited. Efforts to overcome this include"}, {"title": "The MURI-IT Dataset", "content": "We introduce MURI-IT, which includes 2,228,499 instruction-output pairs in 200 languages. The dataset is primarily constructed by applying Multilingual Reverse Instructions (MURI) to the CulturaX (Nguyen et al., 2023) and Wikipedia corpora. The core idea is summarized in Figure 1. Our goal is to utilize existing high-quality human-written multilingual corpora to generate a diverse instruction-following dataset. For a randomly selected text, we aim to generate an instruction for"}, {"title": "Multilingual Reverse Instructions (MURI)", "content": "Step 1. Data Selection: We randomly sample documents from two multilingual corpora: CulturaX (1,076,575 documents) and Wikipedia (1,554,207 documents). CulturaX encompasses 167 languages, merging the OSCAR (Ortiz Su\u00e1rez et al., 2020) and mC4 (Xue et al., 2021) corpora with additional cleaning, deduplication, language identification, and diversification procedures (Nguyen et al., 2023). Wikipedia spans over 350 languages with high-quality documents.\nInstruction Generation After selecting high-quality outputs, the next step is generating suitable instructions in the source language. Since recent LLMs support a limited number of languages, we utilize machine translation models and English LLMs. Let (i, d) be an instruction-output pair in a target low-resource language \u03c4. Given a corpus of human-written documents $D_\\tau = {d_1, d_2, ..., d_n }$, we aim to create an instruction tuning dataset $D_{I_\\tau} = {(i_1, d_1), (i_2, d_2), ..., (i_n, d_n) }$.\nStep 2. Document Translation: First, each document $d_i$ is translated to English using a machine translation model, resulting in $d_i^{eng}$. We use MADLAD-400-3B-MT (Kudugunta et al., 2023), with top_p=1 sampling for translation.\nStep3. Reverse Instructions: Next, we employ an English LLM for instruction generation. We modify the reverse instructions prompt in (K\u00f6ksal et al., 2024) to generate an instruction $i_i^{eng}$ for $d_i^{eng}$ in a few-shot manner, as illustrated in Table 7 in Appendix. We use Mixtral-8x7B (Jiang et al., 2024) with greedy decoding for instruction generation.\nStep 4. Translating Instruction to the Source Language and Ensuring Language Consistency: Finally, the generated instruction $i_i^{eng}$ is translated back to its source language using MADLAD-400-3B-MT, denoted as $i_i$. To verify language consistency, we utilize GlotLID (Kargaran et al., 2023)"}, {"title": "WikiHow Data", "content": "We collected articles from the multilingual WikiHow website using PyWikiHow (JarbasAI, 2024) in 18 languages (Arabic, Chinese, Czech, Dutch, English, French, German, Hindi, Italian, Japanese, Korean, Malay, Portuguese, Russian, Spanish, Thai, Turkish, and Vietnamese), based on the URLs provided by Wikilingua (Ladhak et al., 2020). Each WikiHow page is comprised of the following sections: (i) A title that starts with \u201cHow to\u201d, (ii) an abstract answer to the question, (iii) a number of steps, each comprised of a step-title and a step-text paragraph. We use the title of each WikiHow page as the instruction. To introduce variation in the style of the answers, we render the answers to the questions as follows: In 50% of cases, we include the abstract in the answer and in the other 50% we don't. Regardless of whether the abstract is included or not, in 50% of the cases we only include the step-titles, and in the other 50% we include both the step-titles and step-texts."}, {"title": "NLP Tasks", "content": "To further improve diversity of tasks in MURI-IT, we incorporated several existing multilingual instruction following datasets based on NLP tasks, expanding language coverage and task diversity. These additions, totaling 455,472 samples across 74 languages, complement our primary data sources:"}, {"title": "Languages and Linguistic Diversity", "content": "MURI aims to provide a methodology inclusive of low-resource languages through a culturally respectful approach, utilizing materials in their native languages and avoiding outputs in translationese (Bizzoni et al., 2020; Vanmassenhove et al., 2021). Given that the majority of languages used in NLP systems share typological similarities and geographical origins (Joshi et al., 2021), this often leads to an uneven distribution of resources and tools available to the global community. MURI-IT therefore focuses particularly on languages with limited resources and diverse features.\nJoshi et al. (2021) outlined a taxonomy categorizing languages based on their resource levels, ranging from 0 (left-behinds) such as Balinese with severely limited resources, to 5 (winners) like English or French. Our dataset encompasses a large number of low-resource languages, as shown in Figure 2.a, with over 700,000 examples falling into category 1. Despite this, access to outputs for these low-resource languages remains limited, with 33 languages containing fewer than 1,000 examples each. Nonetheless, MURI-IT proves to be one of the most diverse instruction-tuning datasets to date.\nNezhad and Agrawal (2024) emphasize script and word order as important factors in analyzing linguistic diversity. While the majority of languages in MURI-IT employ Latin script or a combination of Latin, Arabic, and Cyrillic scripts (Figure 2.b), a notable portion (more than one-fifth, categorized as \"Other\") features low-resource scripts such as Lao or Georgian. As the output texts have not been translated, idiomatic use of these scripts is assured, ensuring correct orthography.\nTo further investigate linguistic diversity, we examined word order and case marking. Focusing on the order of subject, verb, and object, Figure 2.c shows that while European SVO languages predominate (Dryer, 2013) and there are no rare OVS and OSV languages, all frequent patterns are represented. This showcases the \u201cstructural\u201d diversity of our dataset.\nCase-marking patterns align with geographical distribution; e.g., mid-size to large inventories are"}, {"title": "Quality Assessment of MURI-IT", "content": "A distinctive feature of MURI-IT is its preservation of cultural and linguistic nuances, often lost in translated datasets. To enhance our linguistic analysis, we conducted a thorough evaluation of a random subset of the dataset, involving native speakers proficient in 13 languages. Each annotator examined 30 randomly selected instruction-output pairs from the reverse instruction subset of MURI-IT using five predefined evaluation criteria. These criteria assess the quality of both instructions and outputs using \u2013 except for Proper Instruction Format \u2013 a Likert scale. (i) Alignment (range 1-5): Measures the alignment between instruction and output. (ii) Instruction Correctness, (iii) Output Correctness (range 1-5): Assess lexical and grammatical accuracy of instruction and output. (iv) Informational Sufficiency (range 1-5): Determines whether the instruction can be adequately answered without external context. (v) Proper Instruction Format (0: No, 1: Yes): Indicates whether the instruction is appropriately formatted for a language model."}, {"title": "Experimental Setup", "content": "To evaluate the effectiveness of MURI-IT, we instruction-tune mT5-XXL (Xue et al., 2021). While recent autoregressive models exist with"}, {"title": "Multilingual Model Evaluation", "content": "We first evaluate our model MURI-101 on the few-shot multilingual MMLU task. shows that MURI-101 clearly outperforms previous mod-"}, {"title": "Monolingual Evaluation in Low-Resource Setting", "content": "To evaluate the capabilities of MURI-IT and Aya in low-resource settings, we conduct an additional set of experiments with only monolingual training. We first select ten low-resource languages: Azerbaijani, Kazakh, Lao, Khmer, Welsh, Scottish Gaelic, Belarusian, Bulgarian, Slovenian, and Slovak. While available in Aya, these languages are not part of the human-annotated portion of Aya and only have examples via translation, thus possibly lacking in cultural context and idiomaticity. We test in our experiment how well MURI-IT complements translated content in this setting. Furthermore, the languages were chosen to represent diverse language families: Turkic, Tai-Kadai, Austroasiatic, Celtic, and Slavic.\nFor this low-resource scenario, we sample at most 15K examples from both Aya and MURI-IT. Then we instruction-tune mT5-XXL for each language and for Aya and Aya+MURI-IT separately, resulting in Aya\u2081 and Aya1+MURI\u2081 models.\nSince many of these languages are not supported by multilingual MMLU and Command R+, we use the few-shot classification task Taxi1500 (Ma et al., 2023) for NLU. For NLG, we use TranslatedDolly; however, we translate model outputs to English (via Google Translate) and calculate win rates with Llama-3-70B-Instruct of translated outputs vs. Dolly's gold English human outputs.\nshows that incorporating MURI-IT con-"}, {"title": "Conclusion", "content": "This study presents Multilingual Reverse Instructions (MURI), a novel approach for generating high-quality instruction tuning datasets for low-resource languages. Our method addresses limitations of translation-focused multilingual datasets by using human-written texts as outputs, combined with a translation pipeline and LLMs to create contextually appropriate instructions. The resulting dataset, MURI-IT, of more than 2 million pairs across 200 languages greatly expands the resources available for multilingual language models.\nEvaluation by native speakers from 13 languages confirmed the dataset's quality and idiomaticity. Our instruction-tuned mT5-XXL model, MURI-101, strongly outperformed previous models on NLU and NLG in both multi- and monolingually. Notably, incorporating MURI-IT improved performance for most low-resource languages, effectively complementing existing datasets like Aya.\nWhile challenges remain, particularly in NLG for low-resource languages, MURI-IT represents a an important step towards more inclusive and linguistically diverse language models. Future work will focus on refining data quality and leveraging advanced multilingual models to further improve performance across languages."}, {"title": "Limitations", "content": "Despite the promising results obtained, several limitations must be acknowledged in this study. First, we did not perform clustering \u2013 in contrast to K\u00f6ksal et al. \u2013 due to uncertainties regarding the performance of multilingual encoders. Clustering could potentially enhance content diversity, ensuring a greater variety of linguistic and cultural contexts.\nAdditionally, the quality of the data can be further improved through more rigorous cleaning such as the removal of headers and footers from documents. Similarly, the Multilingual Reverse Instructions methodology, particularly for low-resource languages, would benefit from more standardized source data. Our evaluation, involving native speakers, noted deficits in languages with less standardized orthography or prominent regional dialects. Additional preprocessing could address this issue.\nAddressing these limitations in future work will involve integrating advanced clustering algorithms, enhancing data cleaning protocols, and expanding the dataset to include a wider range of languages."}, {"title": "Appendices", "content": "Few-shot example used for Reverse Instruction generation\nAnswer: Apache Kafka is a distributed system. The main components of Apache Kafka [...]\n> What kind of instruction could this be the answer to?\nInstruction: What are the main components of Apache Kafka?\n(three more few shot examples)\nAnswer: [DOC]\n> What kind of instruction could this be the answer to?\nInstruction:\nFew-shot examples used for reverse instruction generation.\nGuideline for Evaluating MURI-IT\nTask Description\nYou will be presented with a series of 30 instructions (prompts) and corresponding outputs (answers) based on them. Your task is to evaluate the instruction-output pairs based on several attributes to determine their quality and effectiveness in guiding a Large Language Model toward generating appropriate outputs.\nExample Instruction-Output Pair\nInstruction: What is a fracture?\nOutput: A fracture is the (local) separation of a body into two or more pieces under the action of stress.\nAttributes for Evaluation\nAlignment: Determine whether the instruction aligns with the output on a scale of 1 to 5, where:"}]}