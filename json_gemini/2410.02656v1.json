{"title": "SCALABLE SIMULATION-FREE ENTROPIC UNBALANCED OPTIMAL TRANSPORT", "authors": ["Jaemoo Choi", "Jaewoong Choi"], "abstract": "The Optimal Transport (OT) problem investigates a transport map that connects\ntwo distributions while minimizing a given cost function. Finding such a trans-\nport map has diverse applications in machine learning, such as generative mod-\neling and image-to-image translation. In this paper, we introduce a scalable and\nsimulation-free approach for solving the Entropic Unbalanced Optimal Transport\n(EUOT) problem. We derive the dynamical form of this EUOT problem, which\nis a generalization of the Schr\u00f6dinger bridges (SB) problem. Based on this, we\nderive dual formulation and optimality conditions of the EUOT problem from\nthe stochastic optimal control interpretation. By leveraging these properties, we\npropose a simulation-free algorithm to solve EUOT, called Simulation-free EUOT\n(SF-EUOT). While existing SB models require expensive simulation costs during\ntraining and evaluation, our model achieves simulation-free training and one-step\ngeneration by utilizing the reciprocal property. Our model demonstrates signifi-\ncantly improved scalability in generative modeling and image-to-image translation\ntasks compared to previous SB methods.", "sections": [{"title": "1 INTRODUCTION", "content": "The distribution transport problem investigates finding a transport map that bridges one distribution\nto another. The distribution transport problem has various applications in machine learning, such\nas generative modeling (Rout et al., 2022; Choi et al., 2023a; 2024; Jordan et al., 1998; Shi et al.,\n2024), image-to-image translation (Kim et al., 2024), and biology (Bunne et al., 2023b; 2022).\nOptimal Transport (OT) (Peyr\u00e9 et al., 2019; Villani et al., 2009) explores the most cost-efficient\ntransport map among them. For discrete measures, the OT map can be computed exactly through\nconvex optimization, but it is computationally expensive. In contrast, the Entropic Optimal Transport\n(EOT) problem presents strict convexity and can be computed more efficiently through the Sinkhorn\nalgorithm (Sinkhorn, 1967; Cuturi, 2013). For continuous measures, several machine learning\napproaches have been proposed for learning the EOT problem (Chen et al., 2021a; Shi et al., 2024;\nGushchin et al., 2024). These approaches typically utilize a dynamic version of EOT, known as the\nSchr\u00f6dinger Bridge problem (L\u00e9onard, 2013; Shi et al., 2024).\nThe Schr\u00f6dinger Bridge (SB) is a finite-time diffusion process that bridges two given distributions\nwhile minimizing the KL divergence to a reference process (Chen et al., 2021b; L\u00e9onard, 2013).\nVarious works for solving this SB problem have been proposed (Stromme, 2023; Finlay et al., 2020;\nBortoli et al., 2021; Chen et al., 2021a; Shi et al., 2024). However, these methods tend to exhibit\nscalability challenges when the source and target distributions are in high-dimensional spaces and the\ndistance between them is large. Consequently, these approaches tend to be limited to low-dimensional\ndatasets (Stromme, 2023; Finlay et al., 2020) or rely on a pretraining process for generative modeling\ntask (Chen et al., 2021a; Shi et al., 2024). Moreover, existing approaches require simulation of the\ndiffusion process, leading to excessive training and evaluation costs (Shi et al., 2024; Chen et al.,\n2021a; Gushchin et al., 2024).\nIn this paper, we propose an algorithm for solving the Entropic Unbalanced Optimal Transport\n(EUOT) problem, called Simulation-free EUOT (SF-EUOT). The EUOT problem generalizes the\nEOT problem by relaxing the precise matching of the target distribution into soft matching through\nf-divergence minimization. Depending on the chosen divergence measure, the EUOT problem can"}, {"title": "2 BACKGROUND", "content": "In this section, we provide a brief overview of key concepts in the OT theory and the Schr\u00f6dinger\nBridge (SB) problem. For detailed discussion on related works, please refer to Appendix B."}, {"title": "2.1 OPTIMAL TRANSPORT PROBLEMS", "content": "Kantorovich's Optimal Transport (OT) Kantorovich's Optimal Transport (OT) (Kantorovich,\n1948) problem addresses the problem of searching for the most cost-effective way to transform the\nsource distribution \u03bc to the target distribution v. Formally, it can be expressed as the following\nminimization problem:\n$\\inf_{\\pi \\in \\Pi(\\mu,\\nu)} \\iint \\frac{1}{2} ||x - y||^2 d\\pi(x, y)$$\nHere, we consider the quadratic cost $\\frac{1}{2}||x - y||^2$. For an absolutely continuous \u03bc \u2208 P2(X), the\noptimal transport plan \u03c0* exists. Moreover, the optimal transport is deterministic. In other words,\nthere exists a deterministic OT map T* : X \u2192 X such that (Id\u00d7T*)#\u03bc = \u03c0*, i.e. \u03c0*(\u00b7|x) = \u03b4T*(x)\nis a delta measure.\nEntropic Optimal Transport (EOT) The Entropic Optimal Transport (EOT) problem is an entropy-\nregularized version of the OT problem, which introduces an entropy term for the coupling \u03c0 to the\nstandard OT problem. Formally, EOT can be written as the following minimization problem:\n$\\inf_{\\pi \\in \\Pi(\\mu,\\nu)} \\iint \\frac{1}{2} ||x - y||^2 d\\pi(x, y) - \\sigma^2 H(\\pi),$$"}, {"title": "2.2 SCHR\u00d6DINGER BRIDGE PROBLEM AND ITS PROPERTIES", "content": "In this section, we discuss the properties of the Schr\u00f6dinger Bridge (SB) problem (Chen et al., 2021b;\nL\u00e9onard, 2013). First, we describe the reciprocal property of SB (L\u00e9onard et al., 2014). Then, we\nintroduce the equivalence between the SB problem and EOT (Chen et al., 2021b; L\u00e9onard, 2013).\nFinally, we present the dual formulation of EOT (Gushchin et al., 2024). These properties will be\nextended to the Entropic Unbalanced Optimal Transport (EUOT) in Sec. 3.\nSchr\u00f6dinger Bridge (SB) with Wiener prior Let \u03a9 := [0, 1] \u00d7 X, where t \u2208 [0, 1] represents the\ntime variable. Throughout this paper, we denote the probability density induced by the following\nstochastic process {Xt}t as Pu \u2208 P2(\u03a9). In other words, Pu represents the distribution of the\nstochastic process {Xt}:\n$dX_t = u(t, X_t)dt + \\sigma dW_t, X_0 \\sim \\mu.$\nwith drift u : \u03a9 \u2192 X, diffusion term \u03c3 > 0, and initial distribution \u03bc. Moreover, let Q be the Wiener\nprocess with a diffusion term of \u03c3. Then, the SB problem aims to find the probability density Pu that\nis most close to the Wiener process Q. Formally, the SB problem is defined as follows:\n$\\inf_u D_{KL} (P^u | Q) \\text{ s.t. } P^u_0 = \\mu, P^u_1 = \\nu \\quad \\text{ where } dQ_t = \\sigma dW_t, Q_0 \\sim \\mu.$\nThen, we can express this SB problem in terms of the drift u and the path measure {pt}t\u2208[0,1] of the\nstochastic process Xt. By Girsanov's theorem (S\u00e4rkk\u00e4 & Solin, 2019),\n$D_{KL}(P^u | Q) = \\frac{1}{2\\sigma^2} \\mathbb{E} \\left[ \\int_0^1 ||u_t(X_t^*)||^2 dt \\right].$\nMoreover, by the Fokker-Planck equation (Risken & Risken, 1996), {pt}t\u2208[0,1] satisfies the following\nequation:\n$\\partial_t p_t + \\nabla \\cdot (u_t p_t) - \\frac{\\sigma^2}{2} \\Delta p_t = 0, \\quad p_0 = \\mu.$\nTherefore, by combining Eq. 5 and 6, the SB problem (Eq. 4) can be reformulated as follows:\n$\\inf_u \\int_0^1 \\int_X \\frac{1}{2} ||u_t(x)||^2 d\\rho_t(x)dt, \\text{ s.t. } \\partial_t \\rho_t + \\nabla \\cdot (u_t \\rho_t) - \\frac{\\sigma^2}{2} \\Delta \\rho_t = 0, p_0 = \\mu, \\rho_1 = \\nu.$\nReciprocal Property of SB In this paragraph, we provide an intuition of the Reciprocal Property\n(L\u00e9onard et al., 2014; Chen et al., 2021b; Shi et al., 2024) of SB. To begin with, the minimization\nobjective of the SB problem in Eq. 4 can be decomposed into the KL divergence of the joint distribu-\ntion between t = 0 and t = 1, and the conditional KL divergence. Formally, the decomposition is\nwritten as follows:\n$D_{KL}(P|Q) = D_{KL}(P_{0,1}|Q_{0,1}) + \\int_{X\\times X} \\int_0^1 D_{KL} (P_t^u(\\cdot|x, y)|Q_t(\\cdot|x, y)) dt dP_{0,1}(x, y),$\nwhere Pu0,1 \u2208 \u03a0(\u03bc, \u03bd) denotes the joint distribution on t = 0 and t = 1 induced by Pu. Let P* be the\noptimal solution for the LHS of Eq. 8. Surprisingly, L\u00e9onard et al. (2014) discovered that the last\nterm on the RHS of Eq. 8 is zero for P*, i.e., $P_t^u(\\cdot|x, y) = Q_t(\\cdot|x, y)$ for (x, y) ~ $P^*_{0,1}$ almost surely.\nThis property allows us to characterize the bridge measure between X0 = x and X1 = y.\n$P^*_t(\\cdot|x, y) = Q_t(\\cdot|x, y) = \\mathcal{N}(\\cdot|(1 - t)x + ty, \\sigma^2 t(1 - t)I).$\nWe refer to Eq. 9 as the reciprocal property of SB. This property will be utilized in our neural network\nparametrization in Sec. 4."}, {"title": "3 DYNAMCIAL AND DUAL FORM OF ENTROPIC UNBALANCED OPTIMAL TRANSPORT", "content": "In this section, we derive various formulations of the Entropic Unbalanced Optimal Transport\n(EUOT). First, we introduce the EUOT problem and derive its dynamical formulation (Theorem 3.2).\nThe dynamical formulation of EUOT encompasses the Schr\u00f6dinger Bridge (SB) problem, which is a\ndynamical form of EOT (Sec. 2.2). Next, we derive the dynamical dual form of EUOT by leveraging\nthe SB theory (Theorem 3.4). The dynamical dual will play a crucial role in deriving our learning\nobjective and we will utilize the reciprocal property from the dynamical for our simulation-free\nparametrization in Sec 4.2. For detailed proof of the theorems, refer to Appendix A.1.\nEntropic Unbalanced Optimal Transport (EUOT) In this paper, we consider the EUOT problem\nwith a fixed source measure constraint, i.e., \u03c00 = \u03bc (Eq. 14). While EOT assumes precise matching\nof two measures, i.e., \u03c00 = \u03bc, \u03c01 = \u03bd (Eq. 2), EUOT relaxes the marginal constraint using the\nf-divergence D\u03a8. This unbalanced variant of the optimal transport problem offers outlier robustness\n(Balaji et al., 2020; Choi et al., 2023a) and the ability to handle class imbalance in datasets (Eyring\net al., 2024). Formally, the EUOT problem is defined as follows:\n$\\inf_{\\pi_0 = \\mu, \\pi \\in \\mathcal{P}_2(X \\times X)} \\iint_{X\\times X} \\frac{1}{2} ||x - y||^2 d\\pi(x, y) - \\sigma^2 H(\\pi) + \\alpha D_{\\Psi}(\\pi_1 | \\nu)]$,\nwhere \u03b1 > 0 denotes the divergence penalization intensity and \u03a8 : [0,\u221e) \u2192 [0,\u221e] is assumed to\nbe a convex, lower semi-continuous, non-negative function, and \u03a8(1) = 0. We call \u03a8 an entropy\nfunction of D. Furthermore, due to the convexity of \u03a8, the solution \u03c0* of Eq. 14 is unique.\nRemark 3.1 (EUOT is a Generalization of EOT). Suppose \u03a8 is a convex indicator \u03b9 at {1}, i.e.\n\u03b9(x) = 0 if x = 1 and \u03b9(x) = \u221e otherwise. Then, the corresponding f-divergence D\u03b9(p1|p2) equals\n0 if p1 = p2 almost surely and \u221e otherwise. To obtain a finite objective in Eq. 14, it must hold\n\u03c01 = \u03bd almost surely. Therefore, when \u03a8 = \u03b9, EUOT becomes EOT."}, {"title": "4 METHOD", "content": "In this section, we propose our scalable and simulation-free algorithm for solving the EUOT problem.\nIn Sec 4.1, we reinterpret our dual form (Eq. 17) through various formulations. Specifically,"}, {"title": "4.1 STOCHASTIC OPTIMAL CONTROL INTERPRETATION OF DUAL FORM OF EUOT", "content": "SOC Interpretation of Inner-loop Problem First, we investigate the inner optimization with\nrespect to u in the dual form of EUOT (Eq. 17). By applying the SOC interpretation to this inner\nproblem, we extend the value function V : Y \u2192 R to be time-dependent. The inner optimization of\nthe dual form of EUOT is given as follows:\n$\\inf_u \\mathbb{E} \\left[ \\int_0^1 \\frac{1}{2} ||u(t, X_t)||^2dt + V_1(X_1) \\right]$\nThis optimization problem can be regarded as a stochastic optimal control (SOC) problem (Fleming\n& Rishel, 2012) by regarding Xt as the controlled SDE and V1(\u00b7) as the terminal cost. Now, let\nV : [0, 1] \u00d7 X \u2192 R be the value function of this problem, i.e.\n$V(t, x) = \\inf_u \\mathbb{E} \\left[ \\int_t^1 \\frac{1}{2} ||u_s||^2ds + V_1(X_1^u) \\middle| X_t^u = x \\right].$\nThen, the inner minimization problem (Eq. 18) can be reformulated by the HJB equation for this\ntime-dependent value function V (N\u00fcsken & Richter, 2021; Yong & Zhou, 2012):\n$\\partial_t V_t - \\frac{1}{2} ||\\nabla V_t||^2 + \\frac{\\sigma^2}{2} \\Delta V_t = 0, V_1 = V \\text{ and } u^* = - \\nabla V.$\nwhere u* denotes the optimal control in Eq. 18. Since V1 := V(1, \u00b7) = V, we can say V is an\ntime-dependent extension of V. For simplicity, we will denote the time-dependent value function V\nusing the same notation as the original value function, specifically V : [0, 1] \u00d7 X \u2192 R.\nReinterpretation of Dual Form We begin by interpreting the dual form of EUOT (Eq. 17) as a\nbilevel optimization problem. Our goal is to represent this optimization problem concerning\nthe value function V and the path measure pt. By splitting Eq. 17 into inner-minimization and\nouter-maximization, we arrive at the following optimization problem:\n$\\sup_{V \\in \\Phi_{2,b}} \\mathbb{E} \\left[ \\int_0^1 \\frac{1}{2} ||u_t(X_t)||^2dt + V_1(X_1) \\right] - \\int_X \\frac{\\alpha}{\\Psi^* \\left( \\frac{V_1(y)}{\\alpha} \\right)} d\\nu(y),$\n$\\text{s.t. } u^* = \\arg \\inf_u \\mathbb{E} \\left[ \\int_0^1 \\frac{1}{2} ||u_t(X_t)||^2dt + V_1(X_1) \\right],$\nwhere dXt = u(t, Xt)dt + \u03c3dWt with X0 ~ \u03bc. Then, we can rewrite Xt using pt = Law(Xt)\nby the Fokker-Plank equation:\n$\\sup_{V \\in \\Phi_{2,b}} \\int_0^1 \\int_X \\frac{1}{2} ||u_t^*||^2 \\rho_t dxdt + \\mathbb{E}_{\u0177 \\sim \\rho_1} [V_1(\u0177)] - \\int_X \\frac{\\alpha}{\\Psi^* \\left( \\frac{V_1(y)}{\\alpha} \\right)} d\\nu(y).$\n$\\text{s.t. } (u^*, \\rho^*) = \\arg \\inf_{(u, \\rho)} \\mathbb{E} \\left[ \\int_0^1 \\frac{1}{2} ||u_t||^2 dt \\right] + \\mathbb{E}_{\u0177 \\sim \\rho_1} [V_1(\u0177)].$\nwhere \u2202t\u03c1 + \u2207 \u00b7 (u\u03c1) \u2212 (\u03c3\u00b2/2)\u2206\u03c1 = 0, \u03c10 = \u03bc. Finally, by incorporating the HJB optimality\ncondition (Eq. 20) into (Eq. 23 and using u* = \u2212\u2207V, we can represent the entire bilevel optimization\nproblem above with respect to V and the optimal \u03c1 as follows:\n$\\sup_{V \\in \\Phi_{2,b}} \\int_0^1 \\int_X \\frac{1}{2} ||\\nabla V||^2 \\rho_t^* dxdt + \\mathbb{E}_{\u0177 \\sim \\rho_1} [V_1(\u0177)] - \\int_X \\frac{\\alpha}{\\Psi^* \\left( \\frac{V_1(y)}{\\alpha} \\right)} d\\nu(y).$\n$\\text{s.t. } (HJB) \\quad \\partial_t V - \\frac{1}{2} ||\\nabla V||^2 + \\frac{\\sigma^2}{2} \\Delta V = 0 \\quad \\rho^*\\text{-a.s.},\n(Fokker-Plank) \\quad \\partial_t \\rho + \\nabla \\cdot(- \\nabla V \\rho) - \\frac{\\sigma^2}{2} \\Delta \\rho = 0, \\rho_0 = \\mu..$"}, {"title": "4.2 SIMULATION-FREE EUOT", "content": "In this section, we propose our algorithm for solving the EUOT problem (Eq. 14), called Simulation-\nfree EUOT (SF-EUOT). Specifically, we optimize the dynamic value function V and the path\nmeasure \u03c1t. Our model is derived from two optimization problems (Eq. 24 and 25) for V and \u03c1t\npresented in Sec 4.1. Additionally, we introduce a simulation-free parametrization of pt using the\nreciprocal property (Theorem 3.2), leading to Algorithm 1.\nOptimization of Value V We present our loss function for the value function V, which is derived\nfrom Eq. 24. Note that the V optimization in Eq. 24 consists of two parts: the maximization of target\nfunctional and the HJB optimality conditions. Therefore, we introduce the following loss function by\nintroducing the HJB condition as a regularization term for the target functional:\n$\\mathcal{L}_{V} = \\lambda_G \\int_0^1 \\int_X \\left| \\partial_t V - \\frac{1}{2} ||\\nabla V||^2 + \\frac{\\sigma^2}{2} \\Delta V \\right|^p d \\rho_t dt - \\int_X V_1 d \\rho_1 + \\frac{\\alpha}{\\Psi^* \\left( \\frac{V_1(y)}{\\alpha} \\right)} d\\nu,$\nwhere 1 < p < 2. To achieve a simple parametrization, we set V = \u03b1\u03c5\u03c6. Then, up to a constant\nfactor, Eq. 26 can be rewritten as our loss function L for V as follows:\n$\\mathcal{L}_{V} = \\lambda_G \\int_0^1 \\int_X \\left| \\partial_t v_{\\phi} - \\frac{1}{2} ||\\nabla v_{\\phi}||^2 + \\frac{\\sigma^2}{2} \\Delta v_{\\phi} \\right|^p d \\rho_t dt - \\int_X v_{\\phi}(1, \\cdot) d \\rho_1 + \\frac{\\alpha}{\\Psi^* \\left( v_{\\phi}(1, \\cdot) \\right)} d\\nu.$\nOptimization of Path Measure \u03c1t By introducing the same parametrization V = \u03b1\u03c5\u03c6 as L\u00a2 into\nEq. 25, we also derive the following loss function Le for pt:\n$\\mathcal{L}_{\\rho} = \\inf_{\\rho \\sim \\mu} \\int_0^1 \\int_X \\left( \\partial_t v_{\\phi} - \\frac{1}{2} ||\\nabla v_{\\phi}||^2 + \\frac{\\sigma^2}{2} \\Delta v_{\\phi} \\right) d \\rho (t, x).$\nTo minimize Eq. 28, it is necessary to obtain the sample xt ~ pt. Here, we exploit the optimality\ncondition for p, i.e., the reciprocal property, for parametrizing pt. Specifically, we introduce the\nstatic generator network T\u03b8(x, z) for parametrizing P\u202010(\u00b7|x) (Eq. 16), where z ~ N(0, I) is an\nauxiliary variable. In other words, the conditional transport plan \u03c0\u00ba (y|x) := P110(y|x) is parametrized\nas \u03c0\u00ba(\u00b7|x) = T\u03b8(x, \u00b7)#N(0, I). Then, we can simply obtain xt by leveraging reciprocal property:\n$x_t = (1 - t)x + t\u0177 + \\sigma \\sqrt{t(1 - t)} \\eta, \\quad \u0177 \\sim \\pi^\\theta(\\cdot|x), \\quad \\eta \\sim \\mathcal{N}(0, I).$"}, {"title": "5 EXPERIMENTS", "content": "In this section, we evaluate our model on various datasets to assess its performance. In Sec. 5.1,\nwe compare our model's scalability on image datasets with other dynamic OT models. In Sec. 5.2,\nwe test our model on the synthetic datasets to evaluate whether our model learns the correct EUOT\nsolution. Note that the goal of this paper is to develop a scalable simulation-free EUOT algorithm\n(Eq. 15). Therefore, in this section, we compare our model with (1) the dynamical (Entropic) Optimal\nTransport generative models, such as Schr\u00f6dinger Bridge models (Chen et al., 2021a; Shi et al., 2024;\nGushchin et al., 2024) and (2) the dynamic generative models, such as diffusion models (Song et al.,\n2021b; Vahdat et al., 2021) and flow matching (Lipman et al., 2023; Tong et al., 2024)."}, {"title": "5.1 SCALABILITY AND SCRATCH TRAINABILITY ON IMAGE DATASETS", "content": "Scalability Comparison on Generative Modeling with SB Models Solving the dynamical (en-\ntropic) optimal transport is a challenging problem. The previous SB models (Chen et al., 2021a;\nShi et al., 2024; Gushchin et al., 2024) exhibit scalability challenges when the distance between\nthe source and target distributions is large. One example of such a transport problem is generative\nmodeling on an image dataset, where the source is a Gaussian distribution and the target is a high-\ndimensional image dataset. To address this, the previous SB models (Chen et al., 2021a; Shi et al.,\n2024) rely on a pretraining strategy, such as the diffusion model with VP SDE (Song et al., 2021b)."}, {"title": "5.2 COMPARISON TO EOT SOLUTION ON SYNTHETIC DATASET", "content": "Qualitative Results on 2D Toy Datasets We evaluate whether our model can learn the ground-\ntruth solution of the EOT (EUOT with \u03a8 = \u03b9) problem. Specifically, we compare the trained\nstatic coupling \u03c0\u03b8 (Eq. 14) with the proxy ground-truth coupling obtained using the convex OT solver\nin the POT library (Flamary et al., 2021). Note that the POT library provides the solution between\ntwo empirical discrete measures derived from the training data, while our goal is to solve the EUOT\nproblem between two continuous measures \u03bc, \u03bd."}, {"title": "6 CONCLUSION", "content": "In this paper, we propose an algorithm for solving the Entropic Unbalanced Optimal Transport\n(EUOT) problem. We derived the dynamical formulation of EUOT. Then, we established the dual\nform and analyzed this dual form from the stochastic optimal control perspective. Our model is based\non the simulation-free algorithm leveraging the reciprocal property of the dynamical formulation of\nEUOT problem. Our experiments demonstrated that our model addresses the scalability challenges\nof previous Schr\u00f6dinger Bridge models. Specifically, our model offers simulation-free training\nand achieves state-of-the-art results in generative modeling on CIFAR-10 without diffusion model\npretraining. A limitation of this work is that our method demonstrates lower accuracy in learning\nthe EUOT compared to other models. We hypothesize that this is due to the inherent difficulty of\nachieving precise matching using a PINN-style loss function. Additionally, due to computational\nresource constraints, we were unable to test our model on high-resolution datasets such as CelebA-HQ\n(Liu et al., 2015) (256 \u00d7 256)."}, {"title": "ETHICS STATEMENT", "content": "Our approach significantly enhances the scalability of EOT algorithms, enabling the generation of\nhigh-quality samples from large-scale datasets while maintaining an accurate representation of the\ndata distribution. As a result, we expect our model to impact various fields, including image transfer,\nfinance, image synthesis, healthcare, and anomaly detection. However, it is important to recognize\nthe potential negative societal implications of our work. Generative models can unintentionally learn\nand magnify existing biases within the data, which may reinforce societal biases. Therefore, careful\nmonitoring and control are crucial when deploying these models in real-world applications. Rigorous\nmanagement of both the training data and the modeling process is essential to mitigate any potential\nnegative societal effects."}, {"title": "REPRODUCIBILITY STATEMENT", "content": "To ensure the reproducibility of our work, we submitted the anonymized source in the supplementary\nmaterial, provided complete proofs of our theoretical results in Appendix A, and included the\nimplementation and experiment details in Appendix C."}, {"title": "A PROOFS AND DERIVATIONS", "content": "In this section, we provide the proof of the theorems in Sec. 3. Moreover, we introduce another\ndual form and its relationship to our work. Furthermore, we derive the optimization problem Eq. 25\nand justify the conditional sampling in line 5 of Algorithm 1. For all theorems, we assume that \u03a8 is\nan differentiable entropy function that satisfies superlinearity, i.e. $\\Psi = \\lim_{x \\to \\infty} \\frac{\\Psi(x)}{x} = x$.\nIn this case, D\u03a8(p1|\u03bd) is infinity whenever p1 has singularity with respect to \u03bd. Thanks to the\nsuperlinearity, continuity and convexity of \u03a8, D\u03a8 is a lower semi-conitinuous function."}, {"title": "A.1 PROOFS", "content": "The following lemma implies that the search space of the joint distribution \u03c0 in the EUOT problem\ncan be extended to unnormalized density space M2. Based on this lemma, we abuse the notation for\nthe search space in the following theorems.\nLemma A.1. Let \u03c0* be the optimal plan for\n$\\inf_{\\pi_0 = \\mu, \\pi \\in M_2(X \\times X)} \\iint_{X\\times X} \\frac{1}{2} ||x - y||^2 d\\pi(x, y) - \\sigma^2 H(\\pi) + \\alpha D_{\\Psi}(\\pi_1 | \\nu)].$\nNote that the search space of \u03c0 is extended to unnormalized density space M2 instead of using P2 as\nin EUOT problem defined in Eq. 14. Even if the search space is extended, the mass of the optimal\ntarget marginal \u03c01 is 1. In other words, the problem Eq. 31 is equivalent to Eq. 14.\nProof. The well-known dual form of the Eq. 31 Genevay (2019) is defined as follows:\n$\\sup_{u,v} \\int_X u(x) d \\mu(x) - \\int_X \\Psi^*(-v(y))d\\nu(y) - e^{\\frac{u(x)+v(y)-c(x,y)}{\\sigma^2}} d \\mu(x) d \\nu(y).$\nThanks to the Fenchel-Rockafellar theorem Singer (1979), the strong duality holds (See Proposition\n4.2 in S\u00e9journ\u00e9 et al. (2022). The first variation of Eq. 32 with respect to the pair of the optimal\npotentials (u*, v*) is as follows:\n$\\int_X \\delta u(x) d \\mu(x) + \\int_X \\Psi^{'}(-v^*(y))d \\nu(y) - \\frac{e^{\\frac{u^*(x)+v^*(y)-c(x,y)}{\\sigma^2}}}{\\sigma^2}} \\delta u(x) d \\mu(x) d \\nu(y).$\nNow, let \u1e7d(y) = \u03a8*'(\u2212v*(y))\u03bd(y). If the (\u03b4u, \u03b4v) = (\u03bb, \u22121), then the Eq. 33 can be written as\nfollows:\n$\\int \\lambda d \\mu - \\tilde{\\nu} = \\lambda (1 - m(v)),$\nwhere m(\u00b7) denotes the mass of the measure. Since the potentials are optimal, the mass of \u1e7d should\nbe 1. Furthermore, reordering the first variation with respect to \u03b4v in Eq. 33, we can derive that\n$\\Psi^{'}(-v^*(y) = \\frac{e^{\\frac{u^*(x)+v^*(y)-c(x,y)}{\\sigma^2}}}{\\sigma^2}} d \\mu(x).$\nThen, by leveraging the primal-dual relationship S\u00e9journ\u00e9 et al. (2022), i.e.\n$d\\pi^*(x, y) = e^{\\frac{u^*(x)+v^*(y)-c(x,y)}{\\sigma^2}} d \\mu(x) d \\nu(y),$\nwe can derive the following equation:\n$\\pi^*_1(y) = \\int \\pi^*(x, y) dx = \\int \\left( \\int e^{\\frac{u^*(x)+v^*(y)-c(x,y)}{\\sigma^2}} d \\mu(x) \\right) \\nu(y) = \\Psi^{'}(-v^*(y)) \\nu(y) = \\tilde{\\nu}(y).$\nSince m(v) = 1, \u03c01 has a mass of 1."}, {"title": "A.2 DERIVATIONS", "content": "We provide the another dual formulation of dynamical EUOT. Then, we also introduce the connection\nto our dual form, i.e. Eq. 17. Furthermore, we derive the optimization problem Eq. 25. Finally, we\nprovide the justification of conditional sampling in line 5 of Algorithm 1."}, {"title": "B CONNECTION TO RELATED WORKS", "content": "In this section, we clarify the connection of our method to various existing OT algorithms."}, {"title": "B.1 CONNECTION TO WASSERSTEIN LAGRANGIAN FLOW", "content": "In this section, we clarify the relationship of our approach compared to Neklyudov et al. (2023).\nIn Neklyudov et al. (2023), they suggests a general framework for handling dynamical optimal\ntransport problems for various cost functionals where the marginal distributions are fixed for some\ntimesteps {0 = t0, ..., tn\u22121, tn = 1}. The algorithm is derived by leveraging the Lagrangian dual\nformulations of these problems. Technically, this algorithm alternately updates the probability density\n\u03c1t and value function V. It is easy to show that when the methodology proposed in Neklyudov et al.\n(2023) is reduced to our problem, it becomes a max-min problem of Dual II (Proposition A.4)."}, {"title": "B.2 CONNECTION TO DIFFUSION SCHR\u00d6DINGER BRIDGE MATCHING (DSBM)", "content": "A key difference between our method and Schr\u00f6dinger bridge matching Shi et al. (2024); Liu et al.\n(2024) is that our approach eliminates burdensome simulations by directly parametrizing the transport\nplan T\u03b8. In Shi et al. (2024)", "u": "u\u03b8 of the"}]}