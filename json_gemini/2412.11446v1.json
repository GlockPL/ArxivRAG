{"title": "THEORETICAL ANALYSIS OF QUALITY DIVERSITY ALGORITHMS FOR A CLASSICAL PATH PLANNING PROBLEM", "authors": ["Duc-Cuong Dang", "Aneta Neumann", "Frank Neumann", "Andre Opris", "Dirk Sudholt"], "abstract": "Quality diversity (QD) algorithms have shown to provide sets of high quality solutions for challenging problems in robotics, games, and combinatorial optimisation. So far, theoretical foundational explaining their good behaviour in practice lack far behind their practical success. We contribute to the theoretical understanding of these algorithms and study the behaviour of QD algorithms for a classical planning problem seeking several solutions. We study the all-pairs-shortest-paths (APSP) problem which gives a natural formulation of the behavioural space based on all pairs of nodes of the given input graph that can be used by Map-Elites QD algorithms. Our results show that Map-Elites QD algorithms are able to compute a shortest path for each pair of nodes efficiently in parallel. Furthermore, we examine parent selection techniques for crossover that exhibit significant speed ups compared to the standard QD approach.", "sections": [{"title": "1 Introduction", "content": "In recent years, computing diverse sets of high quality solutions for combinatorial optimisation problems has gained significant attention in the area of artificial intelligence from both theoretical (Baste et al., 2022, 2019; Fomin et al., 2024; Hanaka et al., 2023) and experimental (Von\u00e1sek and Saska, 2018; Ingmar et al., 2020) perspectives. Prominent examples where diverse sets of high quality solutions are sought come from the area of path planning (Hanaka et al., 2021; Gao et al., 2022). Particularly, quality diversity (QD) algorithms have shown to produce excellent results for challenging problems in the areas such as robotics (Miao et al., 2022; Shen et al., 2020), games (Cully and Demiris, 2018) and combinatorial optimisation (Nikfarjam et al., 2024a).\nThis work contributes to the theoretical understanding of QD algorithms. Such algorithms compute several solutions that occupy different areas of a so-called behavioural space. Approaches that use a multidimensional archive of phenotypic elites, called Map-Elites (Mouret and Clune, 2015), are among the most commonly used QD algorithms."}, {"title": "1.1 Related work", "content": "Evolutionary computation methods provide a flexible way of generating diverse sets of high-quality solutions by directly incorporating diversity measures into the population. Generating diverse and high-quality solution sets has gained significant interest in evolutionary computation, particularly under the notion of evolutionary diver- sity optimisation (EDO) (Gao and Neumann, 2014; Gao et al., 2021; Neumann et al., 2018) and quality diversity (QD) (Lehman and Stanley, 2011; Mouret and Clune, 2015; Hagg et al., 2018).\nIn the context of combinatorial optimisation, EDO methods have been developed to compute sets of problem in- stances (Neumann et al., 2018, 2019; Gao et al., 2021) that are capable of distinguishing two algorithms by their performances. More recently, this approach has been applied to compute diverse sets of high-quality solutions for combinatorial optimisation problems such as the knapsack problem (Bossek et al., 2021), the traveling salesperson problem (Do et al., 2020; Nikfarjam et al., 2021), the computation of minimum spanning trees (Bossek and Neumann, 2021), the maximum matching problem (Harder et al., 2024), communication problems in the area of de- fence (Neumann et al., 2023), and constrained monotone submodular functions (Neumann et al., 2021).\nEDO algorithms maintain a fixed population size and focus on maximising diversity based on a specified diversity metric by ensuring that all solutions meet a given quality criteria. In contrast, QD algorithms typically utilise a vari- able population size to identify optimal solutions across different niches within a specified behavioural space. Both approaches have initially been applied to design problems (Hagg et al., 2018; Neumann et al., 2019). In fields such as robotics and gaming, several variants of QD algorithms have been developed (Pugh et al., 2016; Gravina et al., 2018; Fontaine et al., 2020; Zardini et al., 2021; Fontaine et al., 2021; Medina et al., 2023). Moreover, QD has been used to evolve instances for the traveling salesperson problem (Bossek and Neumann, 2022), for solving the traveling thief problem (Nikfarjam et al., 2024a), and in context of time-use optimisation to improve health out- comes (Nikfarjam et al., 2024b).\nRigorous theoretical studies of QD algorithms have only been started recently. The first runtime analysis has been provided for the classical knapsack problem (Nikfarjam et al., 2022) where it has been shown that QD is able to solve this problem in expected pseudo-polynomial time. Afterwards, runtime results have been proven for the com- putation of minimum spanning trees and the optimisation of submodular monotone functions under cardinality con- straints (Bossek and Sudholt, 2024) and its generalisation to approximately submodular functions as well as the clas- sical set cover problems (Qian et al., 2024). The mentioned studies have in common that they only seek on a single solution. To our knowledge, the only study analysing QD algorithms for problems with multiple solutions has been carried out by Schmidbauer et al. (2024). The authors considered monotone submodular functions with different ar- tificial Boolean constraints which defined subproblems that served as stepping stones to solve the main optimisation problem."}, {"title": "1.2 Our contribution", "content": "In general, QD approaches aim to solve problems where several solutions that belong to different areas of a behaviour space are sought. We provide a first runtime analysis for a natural and classical problem seeking several solutions by studying QD approaches for the classical APSP problem. Note that the APSP can be solved in polynomial time using classical algorithms (Floyd, 1962; Johnson, 1977). The goal of the investigations of evolutionary computation techniques for this problem is not to beat these classical algorithms in terms of runtime, but to provide a theoretical understanding of their working behaviour for this important fundamental problem.\nOur work is built upon the previous analysis from (Doerr et al., 2012) for the so-called $(\\leq \\mu+1)$ GA/EA algorithms where they showed that the expected runtime can be sped up to $O(n^{3.5} \\sqrt{\\log n})$ from $\\Omega(n^4)$ when enabling crossover (or using the GA variant). The upper bound was improved to $O(n^{3.25} \\log n)$ in (Doerr and Theile, 2009) with a more refined analysis (which was also shown to be asymptotically tight in the worst case), and later to $O(n^3 \\log n)$ in (Doerr et al., 2013) using better operators. Despite some criticisms of the (< \u03bc+1) scheme at the time, e. g. see (Corus and Lehre, 2018), we believe such scheme is natural in the modern view of QD algorithms because not-yet existing solutions (those not-yet occupying their slots) in the population of the GA/EA can be seen as equivalent to empty cells in the archive of a Map-Elites algorithm. We therefore define and analyse the so-called QD-GA algorithms, in which a map of n by n is maintained to store the best-so-far shortest paths between all source-destination pairs for"}, {"title": "2 Quality Diversity and the APSP", "content": "The all-pairs-shortest-path (APSP) problem is a classical combinatorial optimisation problem. Given a directed strongly connected graph G(V, E) with n = |V| and a weight function $w: E \\rightarrow \\mathbb{N}$ on the edges, the goal is to compute for any given pair of nodes (s,t) \u2208 V \u00d7 (V \\ {s}), a shortest path (in terms of the weight of the chosen edges) from s to t. If one only looks for the shortest path between two specific nodes, the problem is referred as the single-source single-destination shortest-path problem (SSSDSP). Like in (Doerr et al., 2012), we assume that G is strongly connected, thus there exists a path from s to t for any distinct pair (s, t) of nodes.\nIn light of QD approach, we see solving APSP as evolving both diverse and high quality solutions of multiple SSSDSP. Therefore, a valid search point I is a set of chosen edges, denoted by E(I), that forms a valid path from a starting node s to a target node t. This path can also be represented by a sequence of nodes to visit, i. e. $I := (s = V_1, V_2, ..., V_k = t)$"}, {"title": "2.1 Mutation and Crossover", "content": "We use the following mutation and crossover operators introduced in (Doerr et al., 2012). For a given path Ist, starting at node s and ending at node t, let Est be the set of all edges incident to s ort. Mutation relies on the elementary operation of choosing an edge $e \\in E_{st}$ uniformly at random dependent on a given individual Ist. If e is part of I', then e is removed from I'. Otherwise, e is added I' with potentially extends the path at its start or end node. The offspring I' is obtained by creating a copy of Ist and applying this elementary operation k + 1 times to I' where k is chosen according to a Poisson distribution $Pois(\\lambda)$ with parameter \u03bb = 1. Note that an elementary operation might create an invalid individual when adding an outgoing edge to s or an incoming edge to t. Such invalid individuals are rejected by the algorithm according to the update procedure given in Algorithm 2.\nOur analysis will rely on mutation steps carrying out a single valid elementary operation extending a given path. For crossover, we choose two Ist and Iuv from the current map M uniformly at random. If t = u, then the resulting offspring I is obtained by appending Iuv to Ist and constitutes a path from s to v. If I does not constitute a path, then the individual is discarded and has no effect during the update procedure of Algorithm 2."}, {"title": "2.2 Analytical tools", "content": "We use the following tail bound from (Witt, 2014) for sum of geometric variables in our analyses.\nLemma 1 (Theorem 1 in (Witt, 2014)). Let ${X_i}_{i\\in[n]}$ be independent random geometric variables with parameter $p_i \\geq 0$, and let $X := \\sum_{i=1}^n X_i$, and $p := \\min_{i\\in[n]}{p_i}$. If $\\sum_{i=1}^n p_i^2 < s < \\infty$ then for any $x \\geq 0$ it holds that\n$\\Pr \\left(X > \\mathbb{E}[X] + x\\right) < e^{-min(xp, s)} .$\nWe then have the following corollary for a single variable."}, {"title": "3 Runtime Analysis of QD-GA on the APSP", "content": "We first consider the optimisation progress achievable through mutation only. Particularly, we refer to QD-GA (Algo- rithm 1) with pc = 0 as QD-EA. The following theorem shows that QD-GA with a constant probability of carrying out mutation, thus including QD-EA as a special case, solves APSP efficiently and bounds its optimisation time depending on the structural parameters \u2206 and l of the given input.\nTheorem 1. The optimisation time of QD-GA with $p_c = 1 - \\Omega(1)$ is $O(n^2\\Delta \\max{l, \\log n})$ in expectation and with probability 1 \u2013 o(1). In particular, the statement on the optimisation time also holds for QD-EA.\nProof. We first estimate the number of iterations Tst to optimise an arbitrary cell Mst. Let $I = (s = V_1, ..., V_k = t)$ be any shortest path of this cell, then let $X_i$ be the number of iterations in which cell $M_{s V_i}$ is optimised but $M_{s V_{i+1}}$ is not yet optimised, for any $i \\in [k \u2212 1]$, so $T_{st} = \\sum_{i=1}^{k-1} X_i$. Since multiple elementary operations are allowed in one mutation, it is possible to optimise longer paths before the shorter ones, in other words some Xi can take value zero. However, for an upper bound on the optimisation time it suffices to consider the case where the path is extended by adding only one correct edge at a time. That is, to optimise $M_{s V_{i+1}}$, it suffices to pick the solution in the optimised cell $M_{s V_i}$ as parent, i. e. probability 1/(n(n-1)), note that this solution has an equal weight to that of the path $(V_1, ..., V_i)$. Then the mutation is applied with only one elementary operation, i. e. with probability $(1 \u2013 p_c)/e$ for the distribution Pois(1), where the edge $(V_i, V_{i+1})$ is chosen for adding to the parent, i. e. with probability $1/|E_{st}| \\geq 1/(2\\Delta)$. The obtained offspring therefore has equal weight to that of the shortest path $(0_1,..., V_{i+1})$ thus it is used to update and hence optimise $M_{s V_{i+1}}$, and so variable $X_i$ is stochastically dominated by a geometric random variable $Y_i$ with parameter $p := (1 \u2212 p_c)/(2en^2\\Delta)$ regardless of i and of the target path I. Furthermore,\n$|I| = k \u2212 1 < l \\leq \\max{l, 5\\log n} =: l'$\nand therefore\n$\\mathbb{E}[Y] = \\frac{2en^2 \\Delta}{1-p_c}$\nBy linearity of expectation\n$T_{st} = \\sum_{i=1}^{k-1} X_i \\leq \\sum_{i=1}^{l'} Y_i =: Y .$\n$\\mathbb{E}[Y] = \\frac{2en^2 \\Delta l'}{1-p_c}$, thus applying Lemma 1 with $\\lambda := \\frac{12 n^2 \\Delta l'}{1-p_c}$ gives\n$\\Pr \\left(T_{st} \\geq \\frac{12 n^2 \\Delta l'}{1-p_c}\\right) < \\Pr(Y > \\mathbb{E}[Y] + \\lambda)$"}, {"title": "4 Speed-ups through Improved Operators", "content": "We now consider improvements through feasible parent selection for crossover as inspired by Doerr et al. (2013). In this selection, the first parent is selected from a cell of M chosen uniformly at random. Assume this selection is successful, and this first chosen cell is Mst then the second parent is selected uniformly at random from a cell in the row t but excluding column s (and of course excluding column t). There is a chance that this selection fails, i. e. an empty cell in one of those steps, in this case no crossover occurs and the algorithm skips directly to the next iteration.\nTheorem 5. The optimisation time of QD-GA with $p_c = \\Omega(1)$ and using the above improved crossover operator is $O(n^3 \\log n)$ in expectation and with probability 1 0(1).\nProof. We use the same notion of representative of a cell as in the proof of Theorem 3. The run of the algorithm is divided into $[\\log_{3/2}l] < [\\log_{3/2}n\\rfloor$ phases and a phase i ends when all cells with representative solutions of cardinality at most $[(3/2)^i]$ have been optimised. Note that phase 1 is completed at initialisation, thus we only look at phases i + 1 for i \u2265 1. During such a phase, all cells with representatives of cardinality at most $[(3/2)^i]$ have been optimised while the optimisation of those with cardinality $k \\in [[(3/2)^i] + 1, [(3/2)^{i+1}]]$ is underway, and we refer to the latter cells as target cells.\nFor a target cell, assume that $I = (U_1,..., U_{k+1})$ is its representative solution, then for any integer $j \\in [k + 1 \u2013 [(3/2)^i], [(3/2)^i] + 1]$ the paths $I_{v_1v_j} = (V_1,..., V_j)$ and $I_{v_jv_{k+1}} = (U_j,..., U_{k+1})$ are optimal solutions for cells $M_{U_1U_j}$ and $M_{U_jU_{k+1}}$ respectively. Furthermore, those paths have the same cardinalities as the corresponding represen- tatives of those cells, because otherwise I is not the representative of $M_{v_1v_{k+1}}$ and this contradicts our assumption. These imply that $M_{U_1U_j}$ and $M_{U_jU_{k+1}}$ have already been optimised since the cardinalities of $I_{v_1v_j}$ and $I_{v_juk+1}$ are at most $[(3/2)^i]$. Thus picking solutions in those cells as parents then applying crossover, i. e. with probability $p_c/(n(n-1)(n-2))$, optimise the cell $M_{v_1v_{k+1}}$ by creating either solution I or an equivalently optimal solution. The number of such pairs of cells (or parents) is the number of possible integers j which is at least\n$[(3/2)^i] + 1 \u2212 (k + 1 \u2212 [(3/2)^i]) + 1 = 2[(3/2)^i] \u2212 k + 1 > 2[(3/2)^i] - [(3/2)^{i+1}] + 1 =: \\xi_i.$\nTherefore, the number of iterations to optimise an arbitrary target cell in phase i + 1 is stochastically dominated by a geometric random variable with parameter $p_c\\xi_i/n^3 =: p_i$.\nApplying Corollary 1 with c = 9 for this variable implies that with probability at most $n^{-9/4}$, an arbitrary target cell is not optimised after $\\tau_i := (9 \\ln n + 1)n^3/(p_c\\xi_i)$ iterations. By a union bound on at most n(n - 1) target cells, the probability that the phase is not finished after \u03c4 iterations is at most $n(n \u2212 1)n^{\u22129/4} = n^{\u22121/4}$. Then by a union bound on at most $[\\log_{3/2} n\\rfloor$ phases the probability that all phases are not finished after $\\tau := \\sum_{i=1}^{[\\log_{3/2} n]} \\tau_i$ iterations is at most $n^{-1/4} \\log_{3/2} n = o(1)$. Thus with probability 1 o(1), all cells are optimised in time \u03c4, and if this does not happen, we can repeat the argument, thus the expected running time of the algorithm is at most (1 + o(1))\u03c4. Note that\n$\\tau = O(n^3 \\log n) \\sum_{i=1}^{[\\log_{3/2} n]} \\xi_i^{-1}$\nsince $p_c = \\Omega(1)$ thus it suffices to show that $\\sum_{i=1}^{[\\log_{3/2} n]} \\xi_i^{-1} = O(1)$ to complete the proof. It is easy to check that \u03bei \u2265 1 for i \u2208 [1, 4], thus we separate the sum by the first four summands and for the rest we estimate \u00a7\u00bf by Lemmas 2 and 3 with x = (3/2)\u00b2:\n$ \\sum_{i=1}^{[\\log_{3/2} n]} \\xi_i^{-1} \\leq 4+ \\sum_{i=5}^{[\\log_{3/2} n]} \\xi_i^{-1} \\leq 4+ \\sum_{i=5}^{[\\log_{3/2} n]} \\frac{1}{\\frac{1}{2}[(\\frac{3}{2})^i]-1}  \\leq 4+ \\sum_{i=0}^{\\infty} \\frac{2}{2} [(\\frac{3}{2})^i]-1 \\frac{4}{(3/2)^i} = O(1).$"}, {"title": "5 Conclusions", "content": "Computing diverse sets of high quality solutions is important in various areas of artificial intelligence. Quality diversity algorithms have received a lot of attention in recent years due to their ability of tackling problems from a wide range of domains. We contributed to the theoretical understanding of these algorithms by providing the first analysis of a classical combinatorial optimisation problem that seeks multiple solutions in a natural behaviour space. Our analysis for the APSP points out the working behaviour of Map-Elites for this problems and shows that these algorithms can provably solve it efficiently. Afterwards, we presented speed up techniques that provide significantly better upper bounds than the standard Map-Elites approach.\nEstablishing a rigorous theoretical foundation and obtaining a better understanding of QD has the potential to improve practical applications across various domains. We hope that this work serves as a stepping stone towards the devel- opment of more efficient quality diversity algorithms and provides a basis for understanding QD algorithms for more complex planning problems."}]}