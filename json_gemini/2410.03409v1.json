{"title": "Comparative study of regression vs pairwise models for surrogate-based heuristic optimisation", "authors": ["Pablo S. Naharro", "Pablo Toharia", "Antonio LaTorre", "Jos\u00e9-Mar\u00eda Pe\u00f1a"], "abstract": "Heuristic optimisation is a popular tool for solving problems in the sciences and engineering fields. These algorithms explore the search space by sampling solutions, evaluating their fitness, and biasing the search in the direction of promising solutions. However, in many cases, this fitness function involves executing expensive computational calculations, drastically reducing the reasonable number of evaluations. In this context, surrogate models have emerged as an excellent alternative to alleviate these computational problems. This paper addresses the formulation of surrogate problems as both regression models that approximate fitness (surface surrogate models) and a novel way to connect classification models (pairwise surrogate models). The pairwise approach can be directly exploited by some algorithms, such as Differential Evolution, in which the fitness value is not actually needed to drive the search, and it is sufficient to know whether a solution is better than another one or not.\nBased on these modelling approaches, we have conducted a multidimensional analysis of surrogate models under different configurations: different machine learning algorithms (regularised regression, neural networks, decision trees, boosting methods, and random forests), different surrogate strategies (encouraging diversity or relaxing prediction thresholds), and compare them for both surface and pairwise surrogate models. The experimental part of the article includes the benchmark problems already proposed for the SOCO'2011 competition in continuous optimisation and a simulation problem included in the recent GECCO'2021 Industrial Challenge.\nThis paper shows that the performance of the overall search, when using online machine learning-based surrogate models, depends not only on the accuracy of the predictive model but also on both the kind of bias towards positive or negative cases and how the optimisation uses those predictions to decide whether to execute the actual fitness function.", "sections": [{"title": "1. Introduction", "content": "Heuristic optimisation methods are based on the stochas-\ntic exploration of the search space of potential solutions\nto a problem based on a quality function to be maximised\nor minimised. In essence, these methods perform an iter-\native process by testing tentative solutions driven by this\nquality function and guided by a search method (for in-\nstance, population-based evolutionary methods, trajectory\nmethods, Quasi-Newton methods, among many others). Al-\nthough there is repetitive testing of candidate solutions in\nthe search space, the design of these configurations aims to\nminimise the number of calls to the fitness function needed\nto find a good-quality solution to the problem. This is far\nmore efficient than any brute-force or systematic testing\nalternative. However, there is still a trade-off between the\nnumber of candidate solutions explored in the course of\nthe optimisation process and the quality, or even optimality\nof the search. In theory, Wolpert and Macready (1997)\nsuggested that there is no best overall algorithm for every\npotential problem. However, the research of better and more\nefficient heuristic optimisation methods has demonstrated\nthat methods perform better or worse depending on the\ncharacteristics of real-world problems and non-tailor-made\nfunctions (designed to deceive particular search strategies),\nas stated in (Ho and Pepyne, 2002; Koehler, 2007). Nonethe-\nless, even the best-suited algorithm still requires the evalua-\ntion of potential solutions, calculating the result of the qual-\nity function and using this value to propose the subsequent\nsolutions to evaluate.\nThe use of heuristic optimisation in fields such as engi-\nneering, science, or finance has shown to be effective in over-\ncoming complex problems (Deb, 2012; Tapia and Coello,\n2007; Ponsich et al., 2012). However, in many real-world\napplication cases, the evaluation of candidate solutions re-\nquires the execution of a simulation or an equivalent expen-\nsive computational calculation. For instance, in computa-\ntional mechanics, the optimisation of material properties or\ndesign shapes requires finite element calculations (Muelas\net al., 2008; Dubourg, 2011; Pe\u00f1a et al., 2019). Other exam-\nples are wing design problems, in which the fitness function\nperforms fluid dynamics calculations (Moore et al., 2016); or\ncomputational neuroscience, in which multiphysics simula-\ntions are conducted to calibrate models with experimental\nresults (LaTorre et al., 2020). Therefore, making quality\nfunction evaluations as computationally efficient as possible\nis essential in this kind of problems. Hence, some advanced\ncomputing techniques to reduce computational time have\nbeen proposed, such as CPU multiprocessing or parallel exe-\ncution (Alba, 2002), GPU computation (Luong et al., 2010),"}, {"title": "2. Related Work", "content": "Surrogate-based optimisation (Jin, 2011) is an active\nfield, in which an optimisation method (typically a heuristic\nmethod, such as evolutionary algorithms or local search\nmethods) uses a model (named surrogate) to approximate\nthe fitness function. This surrogate can be used to optimise\nthe problem instead of the actual fitness function (making\nthe search method to explore over this approximate fitness\nlandscape) or can be used online during the optimisation\nto alternatively use either the surrogate or the actual fitness\nfunction (Nikolos, 2013).\nSurrogate-based optimisation has been extensively used\nwhen the fitness function is a simulation, such as finite\nelement models (Dubourg, 2011; Awad et al., 2018; Pe\u00f1a\net al., 2019), fluid dynamics (Zhou et al., 2006; Forrester\net al., 2006; Nikolos, 2013; Moore et al., 2016), or energy\nefficiency models (Nguyen et al., 2014; Westermann and\nEvins, 2019).\nThe most common surrogate models use Design of Ex-\nperiments (DoE) methods to preliminary sample the solution\nspace using a limited number of points (typically sam-\npling by using strategies such as Orthogonal Array Design,\nLatin Hypercube Sampling, or Sobol Sequences; (Giunta\net al., 2003)). Once these points are sampled, surrogates\nare modeled by using Gaussian Processes (GP), also known\nas Kriging methods (Ong et al., 2003; Zhou et al., 2006;\nForrester et al., 2006; Lim et al., 2009; Dubourg, 2011; D\u00edaz-\nManr\u00edquez et al., 2016; Awad et al., 2018), or Response\nSurface Methodology (RSM) (D\u00edaz-Manr\u00edquez et al., 2016;\nYang et al., 2016). However, and in particular for those\nmethods updating the surrogates during the execution of the\noptimisation algorithm, different machine learning methods\nhave also been proposed; methods such as artificial neural\nnetworks (ANN) (Nikolos, 2013; Moore et al., 2016), Radial\nBasis Kernels (RBK) (Ong et al., 2003; Lim et al., 2009;\nD\u00edaz-Manr\u00edquez et al., 2016), K-nearest neighbours (KNN)\n(Moore et al., 2016), n-order polynomial regression (Lim\net al., 2009; D\u00edaz-Manr\u00edquez et al., 2016), or Support Vector\nMachines/Regressors (SVM/R) (Mallipeddi and Lee, 2015).\nMoreover, due to the wide variety of possibilities when\nconnecting machine learning models with the optimisation\nalgorithm, Talbi (2021) proposes a taxonomy to define how\nthe model drives the process.\nDespite the fact that some surrogate-based optimisations\nuse trajectory or even non-stochastic techniques (Forrester\net al., 2006), most of the typical approaches are based on\nevolutionary methods and tend to use genetic algorithms.\nHowever, more recent approaches have also included other\nmetaheuristics, such as Differential Evolution (DE) (Niko-\nlos, 2013; Mallipeddi and Lee, 2015; Awad et al., 2018),\nParticle Swarm Optimisation (PSO) (Nguyen et al., 2014),\nand hybrid/memetic approaches (Ong et al., 2003; Zhou\net al., 2006; Lim et al., 2009; Nguyen et al., 2014). There is\nalso some relevant literature in multi-objective optimisation\n(Lim et al., 2009; Yang et al., 2016).\nDifferent metrics to compare the performance of surro-\ngate algorithms were proposed by Moore et al. (2016), and\nthey address four different criteria: (1) accuracy, (2) effi-\nciency, (3) robustness, and (4) performance.\n1.  Accuracy is measured as the error between predictions\nfrom the model compared to the actual result of the\nfitness function. These are typically measures such\nas the mean square error (MSE) or the coefficient of\ndetermination (R2).\n2.  Efficiency represents how many samples are needed\nfor the surrogate to approximate the fitness function.\n3.  Robustness measures the variability in the perfor-\nmance of the algorithm when varying the initial con-\nditions. It is typically measured by analysing several\nruns of the algorithm with different random seeds.\n4.  Performance, which is the final goal, measures both\nthe time and the value of the best fitness found by\nthe algorithm after the stop conditions. In this field,\nRehbach et al. (2018) criticises the way the perfor-\nmance is measured when enabling parallelism. Mean-\nwhile, pure sequential executions are likely to get\ngood results with a low number of fitness function\nevaluations; parallel executions are prone to reduce\nthe execution time but need more evaluations.\nFinally, in (Viana et al., 2010), the design principle to\nconstruct effective surrogate models is analysed, which\nincludes (1) feature selection (either explicitly feature filter-\ning or by using machine learning algorithms that perform\ninternal feature selection or regularisation, sometimes even a\nsensibility analysis (Nguyen et al., 2014)), (2) consideration\nof different surrogate models (simultaneously, dynamically\nelecting them or by ensemble or competition), and (3) the\nuse of conservative estimators. This last point poses the\nquestion whether the criteria for selecting a surrogate model\ndiffer from the accuracy measures typically used in machine\nlearning. In surrogate-based optimisation, the kind of errors\nderived from the approximate estimation of the fitness func-\ntion do not have the same impact on the overall performance\nof the algorithm. This is very clear when the surrogate is"}, {"title": "3. Design of the Study", "content": "The objective of this analysis is to compare the effec-\ntiveness of different machine learning algorithms to model\na surrogate that will be updated during the optimisation.\nThe selection of these algorithms is detailed in Section 3.1.\nA second aspect under analysis is how the optimisation\nmethod uses the surrogate to decide whether it is interesting\nor not to calculate the actual values of the quality function\nfor a given candidate solution. This decision process not\nonly has an impact on the effectiveness of the surrogate\nmodel (to save quality function evaluations by discarding\nsolutions that would not improve the current best solution),\nbut also on the collection of additional data points to update\nthe surrogate model itself. Section 3.2 proposes a baseline\nstrategy for the application of surrogates and Section 3.3\nthree complementary criteria that can be combined to create\nup to eight different strategies. The complete analysis uses\nall these strategies in conjunction with each of the machine\nlearning models to identify synergies that perform better\ndepending on the characteristics of the machine learning\ntechnique to tackle the quality function modelling.\nFollowing the taxonomy proposed in (Talbi, 2021), this\npaper uses a population-based evolutionary algorithm in\ncombination with a low-level data-driven approach. This\nis achieved by introducing a machine learning layer as\na surrogate model in the solution recombination process."}, {"title": "3.1. Machine Learning Methods", "content": "Several machine learning algorithms have been used as\nmodel surrogates. This study has selected five of them that\nrepresent a broad range in both complexity and expressive\npower to capture the quality function characteristics. Al-\nthough there are more advanced versions of these algorithms\nin the literature, for the sake of generality, this study includes\nonly the most common ones. The rationale behind this\nselection is to focus on the aspects of these models that\ncomplement the different strategies for the decision process\nthat uses them as surrogates.\nThe algorithms used for surrogate modelling are the\nfollowing:\n1.  Ridge Regression (Ridge/R): A regression model that\nminimises the linear least square error using L2-norm\nregularisation (Hoerl and Kennard, 1970).\n2.  Multilayered Perceptron Regressor(MLP/R): A 100-\nneuron hidden layer network activated by a rectified\nlinear unit function and solved by square-loss min-\nimisation using a stochastic gradient-based descender\n(Kingma and Ba, 2014)."}, {"title": "3.2. Surrogate-based Strategies", "content": "The objective of using a surrogate is to predict, in an\napproximate way, the result of the quality function without\nexecuting it. Although there are surrogate-based optimis-\ners that directly optimise this surrogate model, this study\naddresses the approach that applies the surrogate in con-\njunction with the actual quality function. This approach, as\nit keeps executing the quality function of new candidate\nsolutions, generates additional data points. Therefore, the\noptimisation process can use these new data points to update\nthe surrogate model on-the-fly and refine its results.\nThis study has established that the surrogate model up-\ndate occurs at the end of every generation of the evolutionary\nalgorithm. Section 5 describes the specific implementation\ndetails and parameters that have been used for the experi-\nmental setup."}, {"title": "3.2.1. Baseline Algorithm and Default Strategy", "content": "DE also has a characteristic that makes it interesting for\nthis study. Evolutionary or population-based optimisation\nalgorithms maintain a set of candidate solutions (popula-\ntion) that evolves during the optimisation process. Generally,\nthese algorithms rank these solutions according to the value\nof the quality function to perform operations such as selec-\ntion or replacement. However, in DE, each of the candidate\nsolutions is compared with a newly produced solution (the\nchallenger) to test if it improves its current value. If so, the\nnew solution replaces the old one, and this process is re-\npeated at every generation. This means that DE does not need\nto rank the solutions on the population. Instead, it compares\ncurrent solutions with the corresponding challenger. This\none-to-one comparison allows surrogate-based optimisation\nto have a criterion to discard candidate solutions if the\nsurrogate estimates that the challenger is not improving the\nquality of the current solution.\nLet $q: X \\rightarrow \\mathbb{R}$ be the quality function to optimise. The\nobjective of the optimisation is to find $x^*$ such as:\n$\\forall x \\in X : q(x) < q(x^*)$  (1)\nLet $X$ be the solution space and $< \\,$ the binary relation\n\"being better than that compares quality function values (if\nthe goal of the optimisation problem is to minimise the qual-\nity function $< = <)$. The baseline algorithm (Algorithm 1)\ntakes a regression-based surrogate $\\hat{q}: X \\rightarrow \\mathbb{R}$ to model the\nsurface of the quality function. This surrogate $\\hat{q}$ shall predict"}, {"title": "3.2.2. Probability-based Strategy", "content": "With the default strategy mentioned above, the optimisa-\ntion algorithm only calculates the actual quality function if\nthe surrogate prediction indicates that it would improve the\nexisting solution in the population. However, this approach\nmay lead to poor performance if the surrogate overestimates\nthe quality of the solutions. In this case, the surrogate-\nbased strategy will not affect the optimisation process as it\nwould evaluate all candidate solutions (there would be no\nsolution filtering). The opposite effect is also possible, as this\napproach may cause stagnation if the surrogate were biased\ntowards low-quality estimations. This bias causes the opti-\nmisation algorithm to discard all new candidates. The latter\nof these situations is more likely when the first surrogate has\nnot had enough information to model those areas close to the\noptimal value, where high-quality solutions are located.\nAlgorithm 3 shows a simple variation of the default\nselection/discard strategy used by the baseline algorithm\nwhich incorporates an additional condition that selects a\nchallenger for evaluation. This new condition will be mod-\nelled based on a Bernoulli distribution $X \\sim \\text{Bernoulli}(p)$\nwith coefficient $p = 0.2$ regardless of the estimation cast\nby the surrogate, i. e., Being A the current (challenged)\nsolution and B the new (challenger) solution. If the surrogate\nestimates that B is better than A, then B is real calculated.\nOtherwise, B still have a 0.2 probability of being real calcu-\nlated."}, {"title": "3.2.3. Quality Distance Strategy", "content": "The probability-based strategy provides additional solu-\ntions by randomly selecting challengers independently of the\nestimated quality. Although this strategy ensures a mecha-\nnism to avoid stagnation induced by quality underestimation,\nthe surrogate would update the model with potentially low-\nquality solutions. Alternatively, if the optimisation algo-\nrithm wanted to improve the surrogate with new solutions,\nit would instead need to select those with expected better\nquality.\nThis strategy proposes an alternative criterion that will\ngive a second chance to some solutions to be evaluated\nwith the actual quality function. It is based on how sure\nthe surrogate is, that whether the predicted quality of the\nchallenger is not going to improve the current candidate\nsolution. Let x be the current solution, and x' the challenger.\nHence, this strategy is controlled by the difference $d(x, x')$\nbetween the estimated value provided by the surrogate and\nthe predicted quality value of the current solution.\n$d(x, x') = |\\hat{q}(x) - \\hat{q}(x')|$  (3)\nThe range of values that this difference $d(x, x')$ calcu-\nlates will vary in the course of the optimisation. In order to\nbring it to scale, a correction based on the average values of\nthese differences is applied:\n$\\bar{d} = \\frac{\\sum_{(x, x') \\in P_i} d(x, x')}{\\text{card}(P_i)}$  (4)\nWhere $\\bar{d}$ is the mean of all differences between the pairs\n$(x, x')$ of comparisons belonging to $P_i$, where $P_i$ repre-\nsents the set of all pairwise comparisons the algorithm has\nchecked up to the instant i. Let $\\text{card}(P_i)$ be the cardinality\nof that set of pairs. The value of $\\bar{d}$ shall be calculated at each\niteration of the original Algorithm 1 as more pairs $(x, x')$ are\nincluded into the set $P_{i+1} = P_i \\cup \\{(x, x')\\}$.\nThis quality distance strategy uses the average pairwise\ndistance $\\bar{d}$ to establish the probability for a solution to get\nselected based on the distance in the quality space. This\nprobability is provided by the function $p_q(x, y)$, which shall\nbe of the form:\n$p_q(x, y) = b^{-d(x, y)}$  (5)\nTo calibrate the base b in the function $p_q(x, y)$, a refer-\nence point corresponding to the average pairwise distance $\\bar{d}$\nis set to probability 0.2:\n$p_q(x, y) = 0.2 \\,\\forall x, y \\in X : d(x, y) = \\bar{d}$  (6)\nTherefore, applying Equation 5 to the calibration condi-\ntion set by Equation 6, the value of b is determined as:\n$b^{-\\bar{d}} = 0.2$  (7)\n$\\log_{0.2}(b) = \\frac{1}{-\\bar{d}}$  (8)\n$b = 0.2^{\\frac{1}{-\\bar{d}}}$  (9)"}, {"title": "3.2.4. Candidate Diversity Strategy", "content": "The previous strategy helps to calculate challenger so-\nlutions when the estimation of its quality is close to the\nthreshold set by the quality of the current solution. Hence,\nthe optimisation may at least evaluate and eventually include\npromising solutions, if the estimation error is reasonably\nlow. However, the quality distance strategy does not nec-\nessarily improve the quality of the surrogate, as the new\nsolutions that it evaluates are with high probability very\nclose to those already used in training. The candidate di-\nversity strategy proposes to select solutions for evaluation\n(they will be either included or excluded from the population\ndepending on the regular conditions of DE selection) based\non the diversity they provide in the space of candidate\nsolutions. The more different the new solution is, compared\nto the ones already evaluated, the higher the probability of\ncalculating it becomes.\nThis strategy is meant to encourage the exploration of\nother areas of the search space. The optimisation algorithm\nis the one eventually generating the candidate solutions in\nthose unexplored areas. However, if the estimation of the\nquality is not good enough to suggest its calculation, this\nstrategy helps in the analysis of the undersampled regions\nof the search space.\nLet x be a current solution, $S_i \\subset X$ the set of solutions\nalready calculated at the instant i, and x' the challenger\nsolution. The function $v: X \\rightarrow \\mathbb{R}$ is defined as:\n$v(x', S_i) = \\min_{x \\in S_i} ||x - x'||$  (13)\nLet $||y||$ be a norm function defined on the vector space\nof the potential solutions X. In particular, the L2 norm (eu-\nclidean distance) has been used for this study. The function"}, {"title": "3.3. Combined Strategies", "content": "This article aims to analyse the performance of the\ndifferent machine learning models, listed in Section 3.1, as\nsurrogates. This analysis also includes the application of the\ndifferent strategies mentioned before, independently and in\ncombination (see Table 1).\nAll the combinations implement the default strategy and\npotentially, one or more of the other strategies. In the cases\nin which multiple strategies are combined, the condition to\ncalculate a challenger solution is the disjunction of all the\nIsAcceptedByFilter conditions (logical or-clause). If any of\nthe conditions are met, the challenger is calculated.\nThe experiments (Section 5) will analyse all the eight\ncombinations of the three strategies to determine their indi-\nvidual contribution and their potential synergies.\nThese experiments, using any continuous variable super-\nvised learning (regression) model, are referred hereinafter as\nsurface surrogates."}, {"title": "4. Pairwise Surrogate Model", "content": "Most of the surrogate-based literature approaches the\ncreation of models as a continuous variable surface surro-\ngate (as a supervised learning problem using regression).\nThere are few cases in which these models are designed\nas discrete variable supervised learners (classifiers), and\nmostly only in multiobjective optimisation (Pan et al., 2018)\nto predict solution dominance using artificial neural net-\nworks. However, DE and other similar algorithms compare\nsolutions in a pairwise way. A newly generated candidate\nsolution is compared to a reference solution. These methods\ndo not need to rank the solutions on the population. They\nonly need to determine if a given solution is better or not\nthan a reference solution. This same feature is part of local\nsearch and trajectory methods: these methods keep just one\nworking solution that is iteratively updated and compared\nwith neighboring solutions.\nIf the optimisation algorithms perform this pairwise\ncomparison as a mechanism to carry out solution selection\nand replacement, there is an alternative way to model the\nsurrogate as a pairwise classification problem. If this com-\nparison between two solutions is not part of the mechanism\nof the optimisation algorithm, the application of the pairwise\nsurrogate model is not as straightforward as in the case of DE\nor local searches. However, there are indirect mechanisms to\nuse this approach in other algorithms. For instance, GA may\nuse tournament selection, a pairwise operation by definition.\nIf the algorithm implements any form of elitism to select\nwhether a solution is included in the population or not,"}, {"title": "4.1. Training Pairwise Surrogates", "content": "This paper introduces the use of pairwise surrogate\nmodels as an alternative to approximate the selection process\nin a heuristic optimisation problem instead of using an ap-\nproximation of the quality function. The proposed approach\ntrains a binary classifier on a dataset made of all the pairwise\ncombinations of the available data points to predict whether\nthe reference solution is the worst current solution already\nevaluated. Nonetheless, even though there could be no direct\napplication of the approach and it is needed to implement\nit indirectly, the advantage of augmenting the ratio of data\npoints for training per fitness evaluation is an interesting\nbenefit for applying this surrogate approach to a problem.\nThis paper is not going to address these issues, which are\nopen for future research.\nLet $w: X \\times X \\rightarrow \\{0, 1\\}$ be a boolean function defined\nin the domain of the pairs of potential solutions X:\n$w(x, y) = \\begin{cases} 1, & q(y) < q(x) \\\\ 0, & \\text{otherwise} \\end{cases}$  (23)\nThe function $w(x, x')$ controls the selection of solutions\nin DE (and other similar algorithms) when x is the current\nsolution and x' is the corresponding challenger solution.\nWhen $w(x, x')$ returns 1, x' value is selected and therefore\nwill replace x. Otherwise, x', the challenger, is discarded.\nConsequently, pairwise surrogate $\\hat{w}(x, x')$ is defined as an\nestimator of the function $w(x, x')$.\nDefinition 1. The boolean function $\\hat{w}: X \\times X \\rightarrow \\{0, 1\\}$\nis the pairwise surrogate, defined by the selection control\n$w(x, y)$, as the function that approaches:\n$\\forall x, y \\in X : \\hat{w}(x, y) \\approx w(x, y)$  (24)\nIts implementation keeps using Algorithm 1 but filter is\nreplaced by Algorithm 4. i. e., Being A the challenged and\nB the challenger. The pairwise surrogate model estimates\nwhether if B should be calculated or not."}, {"title": "4.2. Machine Learning Models for Pairwise Surrogates", "content": "Although there is the possibility of choosing a different\nset of binary classifiers as the algorithm to train the pairwise\nsurrogate models, this study proposes to use the classifier\n(discrete) version of the regression algorithms mentioned in\nSection 3.1.\nTable 2 shows the regression algorithms used to con-\nstruct the surface surrogate and the equivalent classification\nalgorithm used to model the pairwise surrogate equivalents.\nThis selection of machine learning algorithms covers\nthe most representative methods. Ridge, which is mainly a"}, {"title": "5. Experimental Scenario", "content": "For the experimental analysis of the different surrogate\nmodels, we have selected a well-known benchmark pro-\nposed in (Lozano et al., 2011) for the SOCO'2011 special\nissue on the \"Scalability of evolutionary algorithms and\nother metaheuristics for large-scale continuous optimisation\nproblems\". In order to adjust the experimentation to the\ninherent characteristics of the problems that are normally\nsolved with the help of surrogate models, we have conducted\nthe following changes to the usual experimental conditions\nof this benchmark: each configuration is run 15 times instead\nof the usual 25, same run number is guaranteed to start from\nthe same initial population, maximum fitness evaluations has\nbeen fixed to 15D and problem size to D = 50 (further\ndetails can be found in S 2)\nThe primary goal of this article is to analyse the potential\nof using surrogate models, based on different strategies, in\norder to save computation time while achieving a good-\nquality solution. It is not expected for any of the configura-\ntions to reach the optimal value in just 750 quality function\nevaluations, but to provide the best possible solution given\nthe aforementioned budget. Additionally, this study aims to\ncompare the pairwise surrogate modelling techniques (based\non classifiers) with the surface (regression-based) equiva-\nlents. In order to face different models and strategies among\nthem, the lowest quality value reached in the optimisation\nwill be used as the comparison criterion."}, {"title": "5.1. Reference Algorithm", "content": "Several advanced self-adaptive hybrid algorithms have\ndominated continuous optimisation competitions during the\nlast years (Tvrd\u00edk and Pol\u00e1kov\u00e1, 2013; LaTorre et al., 2013;\nGuo and Yang, 2014; Qin and Li, 2013; Tanabe and Fuku-\nnaga, 2013; LaTorre et al., 2015; Draa et al., 2015; LaTorre\nand Pe\u00f1a, 2017). Furthermore, many of these approaches\nhave also exhibited a great performance in real-world prob-\nlems beyond these competitions (Molina et al., 2019). Many"}, {"title": "5.2. Statistical evaluation", "content": "To assess the relevance of the results obtained in our ex-\nperiments, we have conducted a statistical validation based\non the following procedure. First, the average ranking of\nthe algorithms on the whole set of functions has been com-\nputed. Then, the algorithm with the best overall ranking has\nbeen selected as the reference algorithm. Finally, pairwise\ncomparisons have been conducted between the reference\nalgorithm and all the other methods with both the Friedman\nand the Wilcoxon tests. Furthermore, p-values have been\ncorrected to account for the family-wise error in multiple\ncomparisons with the Holm method."}, {"title": "5.3. Hyper-parameter definition", "content": "Although this study is meant to be a general compari-\nson of different machine learning models, approaches, and\nstrategies in the context of an integrated optimisation frame-\nwork, there are several parameters of such framework that\nneed to be adjusted in order to obtain reasonable results.\nWhenever it has been possible (in terms of computational\ncost) the parameters have been independently.\nIn this section we analyse each of the parameters iden-\ntified in the integrated framework. Among them, two of\nthem are of paramount importance: the warm-up cycles and\nthe retrain frequency of the models. Additionally, several\nspecific parameters that control either early convergence\ndetection or other computational aspects are also considered\nin the following sections."}, {"title": "5.3.1. Retrain frequency", "content": "The retrain frequency establishes when the framework\nupdates the surrogate model with the available data. For\nthis study, we have set this frequency to every generation.\nHence, the machine learning model is re-trained at the end of\nevery DE generation (regardless of whether the framework\nactually evaluates the quality function or not). This value is\na reasonable trade-off, considering that training a machine\nlearning model for a few hundred data points is by far more\nefficient than the execution of a quality function that might\ninvolve a simulation or a similar computation."}, {"title": "5.3.2. Pairwise approaches", "content": "One of the main characteristics of the pairwise surrogate\nmodels is that the available data points can grow very fast\n(quadratically with the number of quality function evalua-\ntions). For each new individual, multiple new data points\ncan be generated by comparing it with all the previously"}, {"title": "5.3.3. Warm-up Phase", "content": "The third parameter establishes the required number of\nsamples the surrogate needs to create the initial model.\nThese experiments calibrate this warm-up value for each\nproposed machine learning algorithm, because this number\ndramatically depends on the characteristics of the algorithm\nand how much information it requires to make a reasonably\naccurate first prediction. The selected value is based on the\nranking of the 19 functions according to the same evaluation\ncriteria mentioned in Section 5.2."}, {"title": "5.3.4. No-improvement condition", "content": "Stagnation (no progress during the search) might hap-\npen when using surrogate models when they underestimate\nthe quality of the candidate solutions. In those cases, the\ncombination of the surrogate strategy and the optimisation\nsearch is biased in a way that prevents any candidate solution\nfrom meeting the conditions for being evaluated with the\nactual quality function. This effect is an artefact that causes\nthe optimisation to get stuck and iterate many generations\nwithout spending the quality function evaluation budget. To\navoid this undesired effect, the optimisation algorithm must\ndetect this situation and stop the search. We have included\nan additional convergence criterion based on a parameter\nthat establishes the maximum number of generations without\nimprovement."}, {"title": "6. Analysis of the Experimental Results", "content": "This section presents the results of the experiments con-\nducted on the benchmarks introduced in Section 5 accord-\ning to the statistical analysis methodology and the hyper-\nparameters calibration carried out, also presented in the\nsame section.\nThe first part of this section compares the default strategy\nimplementation for the surrogate models when using differ-\nent machine learning algorithms. This preliminary analysis\nalso compares the surface approach with the pairwise surro-\ngate model (introduced in Section 4).\nThe second part of the section carries out an analysis\nof the different strategies (see Section 3.2). This analysis\ncompares the strategies independently and in combination\nwith all the algorithms and models (surface and pairwise)."}, {"title": "6.1. Default Strategy", "content": "Tables 4 compare the ranking for both the surface and the\npairwise surrogate models. The results clearly show"}]}