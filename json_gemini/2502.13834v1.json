{"title": "PROVING OLYMPIAD INEQUALITIES BY SYNERGIZING LLMS AND SYMBOLIC REASONING", "authors": ["Zenan Li", "Zhaoyu Li", "Wen Tang", "Xian Zhang", "Yuan Yao", "Xujie Si", "Fan Yang", "Kaiyu Yang", "Xiaoxing Ma"], "abstract": "Large language models (LLMs) can prove mathematical theorems formally by generating proof steps (a.k.a. tactics) within a proof system. However, the space of possible tactics is vast and complex, while the available training data for formal proofs is limited, posing a significant challenge to LLM-based tactic generation. To address this, we introduce a neuro-symbolic tactic generator that synergizes the mathematical intuition learned by LLMs with domain-specific insights encoded by symbolic methods. The key aspect of this integration is identifying which parts of mathematical reasoning are best suited to LLMs and which to symbolic methods. While the high-level idea of neuro-symbolic integration is broadly applicable to various mathematical problems, in this paper, we focus specifically on Olympiad inequalities. We analyze how humans solve these problems and distill the techniques into two types of tactics: (1) scaling, handled by symbolic methods, and (2) rewriting, handled by LLMs. In addition, we combine symbolic tools with LLMs to prune and rank the proof goals for efficient proof search. We evaluate our framework on 161 challenging inequalities from multiple mathematics competitions, achieving state-of-the-art performance and significantly outperforming existing LLM and symbolic approaches without requiring additional training data.", "sections": [{"title": "1 INTRODUCTION", "content": "Automated theorem proving has been a long-standing goal in AI (Newell & Simon, 1956). Recent research explores leveraging large language models (LLMs) to generate formal proofs that can be verified in formal proof systems like Lean (de Moura et al., 2015), opening a new avenue to theorem proving (Li et al., 2024). This promising approach has already led to tools that assist human mathematicians (Song et al., 2024) and the first AI that achieves silver-medal performance in the International Mathematical Olympiad (IMO) (AlphaProof and AlphaGeometry teams, 2024).\nWhile LLM-based proof generation shows great promise across various mathematical domains, its performance is constrained by the scarcity of formal proof data. More importantly, it remains an open problem whether LLMs can perform precise and complex symbolic manipulations (Hammond & Leake, 2023). To address these limitations, mechanical symbolic reasoning is still essential. Unlike LLMs, symbolic methods leverage domain-specific knowledge to achieve greater efficiency and generalization without relying on extensive training data (Wu, 2008; Heule et al., 2016). Integrating LLMs with symbolic methods presents a promising strategy for tactic generation and theorem proving. This raises a key question: Which aspects of mathematical reasoning are best suited to LLMs, and which to symbolic methods? By exploring this question, we aim to combine the strengths of both approaches effectively. Since symbolic methods are inherently domain-specific, we focus on a concrete domain: inequalities, which offers an ideal balance between feasibility and practicality.\nMathematical Inequalities. Inequalities arise from various branches of mathematics (Hardy et al., 1952). Their proofs often rely on a relatively small set of fundamental techniques, yet these techniques can be applied in remarkably intricate and nuanced ways. In this paper, we further constrain our scope to elementary algebraic inequalities, which were prevalent in mathematics competitions (Manfrino et al., 2010), e.g., Problem 2 in IMO 2000. Additionally, these inequalities are closely related to quantifier-free real arithmetic in satisfiability modulo theories (SMT) (Barrett & Tinelli, 2018), which have numerous practical applications in formal verification.\nEven this restricted class of inequalities poses significant challenges that surpass the capabilities of current symbolic or neural provers. Symbolic methods (Yang, 1999; Uray, 2020) partition the variable space (e.g., \u211d\u00b3 for three variables) into a finite number of cells, which are then exhaustively enumerated. These approaches suffer from combinatorial explosion and quickly become computationally infeasible for competition-level problems. Furthermore, due to their enumerative nature, these methods are black boxes that cannot produce human-readable proofs. On the other hand, neural approaches (Wu et al., 2020; Wei et al., 2024) fine-tune language models to generate formal proofs by predicting tactics or evaluating subgoals during proof search. However, due to data scarcity and difficulties in generalization, they frequently underperform on certain types of problems.\nOur Approach. We introduce LIPS (LLM-based inequality prover with symbolic reasoning), a neuro-symbolic framework that synergistically combines LLMs with domain-specific symbolic techniques, as illustrated in Figure 2. Specifically, we analyze common proving strategies used by humans in inequality proofs and categorize them into two types of tactics: scaling and rewriting. Scaling tactics apply existing lemmas (e.g., the Cauchy-Schwarz inequality) to scale a subterm in the current goal. The set of lemmas is finite, and each lemma can be applied only in a limited number of ways. Therefore, we can enumerate all possible scaling tactics using symbolic tools like SymPy (Meurer et al., 2017). However, not all scaling tactics are useful for the current goal; over-scaling may render the goal invalid. We filter out such invalid scaling tactics by using symbolic tools such as SMT solvers to check for counterexamples of the resulting goals. Rewriting tactics, on the other hand, transform a term into an equivalent form (e.g., subtracting 2ab from both sides of the current goal). Any term can be rewritten in infinite ways, making exhaustive enumeration impossible. To address this, we use LLMs to generate rewriting tactics by designing a series of prompts for different rewriting formats. By leveraging the mathematical intuition embedded in LLMs, we implicitly prune the infinite tactic space, sampling the most promising equivalent transformations.\nScaling and rewriting the current goal leads to a set of subgoals with new inequalities to prove."}, {"title": "2 INEQUALITY THEOREM PROVING", "content": "In this section, we briefly review the existing neural and symbolic methods for inequality proving. In a nutshell, symbolic methods are mechanical, completing proofs through an exhaustive exploration of the problem space; neural methods are heuristic, using LLMs to search and construct proof steps within a vast tactic space. Each approach offers distinct advantages and faces unique challenges."}, {"title": "2.1 SYMBOLIC METHODS", "content": "Consider a set of polynomial inequalities \u03a6\u1d62 \u227c 0, i = 1,...,m, where \u227c\u2208 {<, \u2264, >, \u2265, =, \u2260},\nand each polynomial is of n variables expressed as \u03a6\u1d62(x\u2081,...,x\u2099) := \u2211 \u03b1\u1d62\u2081,...,\u1d62\u2099 x\u2081\u2071\u00b9...x\u2099\u2071\u207f, cylindrical algebraic decomposition (CAD) (Arnon et al., 1984; Caviness & Johnson, 2012; Kremer, 2020) divides the underlying space \u211d\u207f into multiple connected semi-algebraic sets, known as cells. Within each cell, the sign of every polynomial remains constant (positive, negative, or zero). By exploiting this sign invariance, we can determine the satisfiability of inequalities by enumerating and checking all the cells, rather than searching the entire infinite space \u211d\u207f.\nCAD and its variants have been extensively utilized in modern SMT solvers (Jovanovi\u0107 & De Moura, 2013; Kremer et al., 2022; Uncu et al., 2023). For inequality theorem proving, CAD transforms the problem into an enumeration task, exhaustively examining all cells to assess whether the inequality can be satisfied. While it is capable, CAD's performance remains unsatisfactory for several reasons. Firstly, CAD's heuristic strategies are primarily designed to efficiently find counterexamples rather than to optimize the proof search process. Secondly, CAD's proving mechanism fails to generate explicit and interpretable reasoning paths, hindering both automatic verification by existing interactive theorem provers and human interpretation of the proofs. Additionally, CAD suffers from double exponential computational complexity relative to the number of variables n (Davenport & Heintz, 1988), causing its efficiency to decrease significantly as the number of variables increases. Notably, when dealing with nonlinear inequalities involving fractions or radical expressions, auxiliary variables are always introduced to eliminate these terms (e.g., converting \u221ax\u2081 + \u221ax\u2082 + x\u2083 = 0 into {x\u2084 + x\u2085 + x\u2083 = 0, x\u2084 = x\u2081, x\u2085 = x\u2082}). Although this transformation successfully rewrites the inequality into polynomial form, it drastically degrades the performance of CAD."}, {"title": "2.2 NEURAL METHODS", "content": "In contrast to symbolic methods based on CAD, some approaches leverage neural networks to predict tactics within an interactive theorem prover, generating human-like, step-by-step formal proofs. Specifically, these inequality proofs are typically structured in a top-down sequential manner, where each tactic either transforms the current goal into a new subgoal or directly completes the proof.  Figure 6(c) provides an example proof of the inequality ab + bc + ca < a\u00b2 + b\u00b2 + c\u00b2.\nAmong existing work, INT (Wu et al., 2021) designs a theorem generator for elementary-level inequalities by randomly sampling axioms from a fixed set. It trains a Transformer (Vaswani, 2017) model to predict tactics and utilizes another value network with the Monte Carlo Tree Search to"}, {"title": "3 TACTIC GENERATION & PRUNING", "content": "Compared to general theorem proving, the tactics used in inequality proofs are more well-structured: they can all be categorized into two types, namely scaling and rewriting (Lee, 2004; Ikenaga, 2018). Scaling refines the given inequality using a known inequality lemma, such as the arithmetic and geometric means (AM-GM) inequality, while rewriting transforms the given inequality using equivalent transformations, such as multiplying both sides of the inequality by two.\nThis categorization arises from their unique characteristics. First, scaling tactics rely on a finite set of lemmas, whereas rewriting tactics pertain to a set of equivalent operations that is inherently infinite in size. This fundamental difference leads to varying strategies for tactic generation. Second, scaling tactics involve non-equivalent transformations and may not preserve the provability of the inequality, unlike rewriting tactics, which are based on equivalent transformations. Therefore, the pruning strategies for these two tactics also differ: scaling tactics can be pruned based on the validity of the deduction, while the evaluation of rewriting tactics requires some algebraic intuition.\nIn the following, we consider the inequality problem in Figure 1 as a running example. To the best of our knowledge, the proof for this problem is not readily available online, and neither the most advanced LLMs (e.g., OpenAI 01-preview) nor existing CAD solvers can solve this inequality."}, {"title": "3.1 SCALING TACTICS", "content": "Given an inequality lemma, we first enumerate all possible values of its arguments (e.g., determining u and v in the two-variable AM-GM inequality u\u00b2 + v\u00b2 > 2uv). Although this step can be directly implemented using the SymPy pattern match function (Meurer et al., 2017), it introduces a challenge due to the potentially large number of possible patterns. In our running example, there are a total of 162 possible pattern matches for the two-variable AM-GM inequality, including cases like {u := a\u00b2, v := \u221a2}, {u := 1, v := (b\u00b2+2/2)}.\nSince scaling tactics refine the inequality goal, they may produce potentially incorrect subgoals (i.e., unprovable statements). For instance, applying the AM-GM inequality with the pattern {u := \u03b1\u00b2, v := \u221a2} would transform the original inequality (1) into\n 1/2\u221a2a + 1/2\u221a2b + 1/2\u221a2c < 1/6ab+c\u00b2 + 1/6bc+a\u00b2 + 1/6ca+b\u00b2\nHowever, this inequality does not hold when a = b = c = 1/\u221a3. Specifically, out of the 162 possible patterns for applying the AM-GM inequality in our running example, only six (i.e., {u := a, v := b} and its symmetric or cyclical versions) yield correct deductions. Therefore, we propose using CAD to identify counterexamples in the new inequality goals and eliminate the scaling tactics that produce them. Moreover, since most scaling tactics are incorrect and thus induce counterexamples, CAD can efficiently detect and discard them using well-established heuristic strategies.\nTo further enhance the efficacy and efficiency of scaling tactic pruning, we propose several additional methods to complement CAD in searching for counterexamples:\nQuick Check via Test Cases. When CAD identifies a counterexample for a scaling tactic, we store it as a \"test case\". For any subsequent scaling tactic, we will perform a quick check using this test case before invoking CAD to determine if the counterexample invalidates the tactic.\nIncorporation of Numerical Optimization. Since most inequality problems are differentiable, we also use gradient-based optimization as an effective alternative when CAD fails. Specifically, we"}, {"title": "3.2 REWRITING TACTICS", "content": "Returning to the running example, after pruning scaling tactics, only a few tactics are applicable. We may choose to apply the two-variable AM-GM inequality (with pattern {u := a, v := b} and its cyclical versions) and derive a new proof goal from the initial goal (1), formulated as\n1/a\u00b2+2 + 1/b\u00b2+2 + 1/c\u00b2+2 < 1/3a\u00b2+3b\u00b2+c\u00b2 + 1/3b\u00b2+3c\u00b2+a\u00b2 + 1/3c\u00b2+3a\u00b2+b\u00b2\nTo solve the current proof goal, some equivalent transformations are required. For example, one may replace the term 3a\u00b2+3b\u00b2+c\u00b2 with 1/a\u00b2+b\u00b2+c\u00b2 using the assumption a\u00b2 + b\u00b2 + c\u00b2 = 1, which makes the proof goal clearer. However, such transformation insights are inherently creative rather than mechanical and cannot be readily derived through brute-force methods. Consequently, relying solely on symbolic pattern matching tends to be highly ineffective. Moreover, the argument space for rewriting tactics is typically infinite. For example, the assumption a\u00b2 + b\u00b2 + c\u00b2 = 1 can be inserted at almost any point within the inequality, significantly broadening the scope of rewriting tactics.\nTo generate and prune the rewriting tactics, we propose directly prompting an LLM to generate candidates. Specifically, for different operations (e.g., rearrangement, simplification, denominator cancellation, etc.), we design tailored prompts that guide the LLM to transform the current proof goal into an appropriate form. The details of these prompts can be referred to Appendix C. In this setting, tactic pruning is implicitly performed by leveraging the algebraic intuition of LLMs, thereby effectively reducing the space of possible rewriting tactics.\nBesides these neural-guided transformation tactics, we incorporate two additional symbolic-based transformation tactics, i.e., the sum-of-squares (Chen, 2013) and tangent line (Li, 2005) tricks. The sum-of-squares trick attempts to rewrite the current expression into a summation of non-negative terms, which is quite useful in cases where the inequality proof requires intricate calculations rather than ingenious manipulations (e.g., proving 2x\u00b2 + 2xy \u2212 3x + y\u00b2 + 2 > 0). The tangent line trick is also a potent technique, particularly in competition-level inequality proving, which simplifies the problem by converting the multivariable inequality into a new single-variable problem."}, {"title": "4 GOAL FILTERING & SELECTION", "content": "The application of scaling and rewriting tactics yields a collection of new proof goals. By combining these newly generated goals with existing unexplored ones, we can derive a candidate set. The next step is to select the most appropriate goal from this candidate set for subsequent proving. In our running example, we can derive 16 new proof goals from the current goal (3). Below, we present three of these new goals, each derived by applying the two-variable AM-GM inequality, the three-variable Titu inequality, and simplifying using the given assumption a\u00b2 + b\u00b2 + c\u00b2 = 1, respectively:\n1/a\u00b2+2 + 1/b\u00b2+2 + 1/c\u00b2+2 = 1/(2a\u00b2+3b\u00b2+3c\u00b2) + 1/(b\u00b2+3a\u00b2+3c\u00b2) + 1/(c\u00b2+3a\u00b2+3b\u00b2)\n1/a\u00b2+2 + 1/b\u00b2+2 + 1/c\u00b2+2 < 9/(7a\u00b2+7b\u00b2+7c\u00b2)\n1/a\u00b2+2 + 1/b\u00b2+2 + 1/c\u00b2+2 \u2264 1/3-2a\u00b2 + 1/3-2b\u00b2 + 1/3-2c\u00b2\nFor effective goal selection in proof search, existing methods often train a language model as a value function to evaluate and rank each goal in the candidate set. However, limitations in data quantity and diversity can significantly degrade the performance of these fine-tuned models. For example, the largest collected inequality dataset in Lean comprises only 46K samples (Ying et al., 2024), while the largest synthesized dataset of competition-level inequalities contains merely 191K cyclically symmetric instances (Wei et al., 2024). Consequently, we opt to directly employ an off-the-shelf LLM (e.g., GPT-4) without fine-tuning. Furthermore, as more proof goals accumulate, the context length required for prompting an LLM for goal ranking becomes substantial, potentially leading to the issue of LLMs being \u201clost in the middle\" (Liu et al., 2024). To address this, we propose dividing the goal selection pipeline into two stages: symbolic filtering and neural ranking."}, {"title": "4.1 SYMBOLIC FILTERING", "content": "Given a series of proof goals, we first eliminate those that are less promising based on carefully designed symbolic rules. Specifically, we prioritize two key properties: (1) homogeneity, meaning both sides of the inequality have the same degree (e.g., a\u00b2 + b\u00b2 \u2265 2ab); and (2) decoupling, which refers to whether the inequality contains mixed-variable terms (e.g., abc is considered coupled).\nBoth properties are reasonable criteria for prioritization. Regarding homogeneity, most substitution and transformation tactics preserve homogeneity. Hence, a homogeneous inequality allows for a broader range of tactics to be applied, thereby producing more valuable proof goals. For decoupling, an inequality with fewer coupled terms is not only clearer but also amenable to a greater variety of techniques, such as the sum-of-squares and tangent line tricks.\nTo measure decoupling and homogeneity, we first approximate the proof goal by a polynomial inequality using Taylor expansion. We then compute the expectation of the number of variables in each term and the variance of the degree of each term, respectively. Formally, given a polynomial inequality expressed as \u03a6(x\u2081,...,x\u2099) = \u2211\u2096 \u2211\u1d62\u2081,...,\u1d62\u2099 \u03b1\u1d62\u2081,...,\u1d62\u2099 x\u2081\u2071\u00b9 x\u2082\u2071\u00b2...x\u2099\u2071\u207f \u227c 0, the decoupling score (DC) and homogeneity score (HM) are computed as:\nDC(\u03a6) = 1/k \u2211\u1d62\u208c\u2081 \u2211\u2c7c\u208c\u2081\u207f (\u03a0(i\u2c7c > 0)), HM(\u03a6) = 1/k \u2211\u1d62\u208c\u2081 (d\u1d62 - 1/k \u2211\u2c7c\u208c\u2081 d\u2c7c)\u00b2\nwhere d\u1d62 = i\u2081 + \u00b7\u00b7\u00b7 + i\u2099 is the total degree of i-th term.\nIt is worth noting that the homogeneity score and the decoupling score are not always consistent. In our running example, the newly generated goals in (4), (5), and (6) achieve homogeneity scores of 0.56, 0.55, and 0.80, and decoupling scores of 0.44, 0.48, and 0.66, respectively. As a result, we normalize the scores into [0, 1] and then compute the average score to filter the candidates."}, {"title": "4.2 NEURAL RANKING", "content": "Symbolic rules are not universally effective. Hence, we use these rules solely to eliminate unpromising proof goals, leaving top-k candidates, for final selection by an LLM. Unlike symbolic filtering, which requires explicit definitions of inequality metrics, we use the chain-of-thought prompting (Wei et al., 2022; Chu et al., 2023) to query an LLM to rank the proof goals based on their proving difficulty."}, {"title": "5 EXPERIMENTS", "content": "In this section, we conduct a series of experiments to address the following three research questions:\nRQ1: Efficacy \u2013 Compared to existing SoTA methods, can LIPS successfully prove more problems?\nRQ2: Efficiency \u2013 Compared to SoTA methods or alternatives, can LIPS obtain proofs in less time?\nRQ3: Scalability \u2013 Can LIPS become more effective or efficient by incorporating more scaling lemmas or employing more powerful LLMs?"}, {"title": "5.1 EXPERIMENTAL SETUP", "content": "Datasets. We evaluate LIPS on three datasets: ChenNEQ, MO-INT-20, and 567NEQ, respectively. ChenNEQ comprises 41 Olympiad-level inequalities collected by Chen (2014); MO-INT is a new competition-level inequality benchmark introduced in AIPS (Wei et al., 2024), featuring 20 problems sourced from IMO shortlists and various national mathematical Olympiads; 567NEQ consists of 567 hard inequalities created by Tung (2012) and we randomly selected 100 problems from the original problem set as the testbed for our framework. To formalize the problems in Lean 4, we directly translate the LaTeX source code into Lean format using manually defined rules.\nBaselines. We compare LIPS with five baselines: DSP (Jiang et al., 2022), CAD (Kremer, 2020), MMA (Wolfram Research), MCTS (Wu et al., 2020), and AIPS (Wei et al., 2024). DSP consists of two steps, natural language reasoning generation and proof autoformalization, and we instantiate the LLM used in each step GPT-40. MCTS (a.k.a Monte Carlo tree search) has been explored in previous studies (Wu et al., 2020) and serves as an alternative method for proof goal selection. AIPS is an inequality prover system based on SymPy, which has demonstrated the capability to prove competition-level inequalities. CAD integrates a series of CAD-based inequality solvers including Z3 (De Moura & Bj\u00f8rner, 2008), CVC5 (Kremer et al., 2022), RC-CAD (Lemaire et al., 2005), and Bottema (Lu, 1998). MMA, referring to Mathematica, incorporates the CAD algorithm with other reduction strategies, providing a powerful algebraic system for inequality verification (Wolfram Research, 2020).\nImplementation. The detailed processes of tactic generation, goal selection, as well as the overall framework are provided in Appendix B. To construct the tactics, we design a total of 96 scaling tactics and 16 rewriting tactics, each formalized in Lean 4. The corresponding premises and LLM prompts are summarized in Appendix C. For counterexample search in scaling tactic pruning, we integrate four CAD-based solvers (Z3, CVC5, RC-CAD, and Bottema) and implement an optimizer based on SciPy (Virtanen et al., 2020). In symbolic filtering, we fix the size of filtered goal set to 10, as it is the largest size that ensures GPT-4's efficacy. For the LLM involved in transformation tactic generation and proof goal ranking, we use GPT-40 (version Azure-0501)."}, {"title": "5.2 EXPERIMENTS", "content": "RQ1: Efficacy. We evaluate the proof success rates of LIPS and the five comparative methods across the three datasets. For each proving task, a time limit of 90 minutes is imposed, consistent with that of AIPS and the standard problem-solving time constraint in the IMO. The overall results are presented in Table 1. First, we observe that the neural methods (DSP and MCTS) cannot"}, {"title": "RQ2: Efficiency", "content": "Since existing methods are built on different deduction engine, a direct comparison of their proving time could be unfair. Instead, we break down the efficiency evaluation into two aspects, i.e., the pruning ratio of scaling tactics and the number of iterations in goal selection. Given that AIPS uses the equality check as the scaling tactic pruning strategy, we compare this approach with the CAD-based strategy employed in LIPS.  LIPS outperforms the existing method in 13 out of 20 problems, and achieves an average improvement of 7.92%.\nFurthermore, we count the number of goal selection iterations for each successfully proved problem, and present the results in Figure 3. Due to the absence of a comparison method, we only include the oracle (i.e., optimal goal selection) as a reference. We can observe that LIPS performs no more than 33 search loops to successfully obtain a proof, and for 12 out of 16 problems, it exceeds the oracle by fewer than 10 steps. In addition, LIPS requires an average of 15.75 search loops, which is only 2.17 times that of the oracle (7.25), demonstrating that LIPS's efficiency also stems from its high accuracy in generating proving paths."}, {"title": "RQ3: Scability", "content": "We conduct four experiments on the ChenNEQ dataset to explore the scalability of LIPS's symbolic and neural components. For the symbolic part, we first examine how expanding the scaling tactics affects the performance of LIPS. To this end, we randomly select 7 sets of scaling tactics with varying sizes and plot the performance curve. The results show that the proof success rate consistently increases as more scaling tactics are included, suggesting potential benefits in further enlarging our scaling tactic library. The second experiment investigates the effect of different sizes of the filtered set. The corresponding performance curve is shown in Figure 4(b). We observe that the success rate remains robust (over 85%) with sizes from 8 to 16, but decreases significantly when the set is either too small or too large.\nFor the neural part, we explore the performance of LIPS with different LLMs serving in rewriting tactic generation and neural ranking. We select three alternative LLMs, i.e., Mathstral 7B (Jiang et al., 2023), LLaMA-3 8B (AI@Meta, 2024), and DeepSeek-chat V2.5 (DeepSeek-AI, 2024). We also include a baseline method as an ablative study. In rewriting tactic generation, the baseline uses SymPy simplify function instead of existing LLM-based rewriting tactics. In neural ranking, we directly use random selection as the baseline."}, {"title": "Ablation study", "content": "To showcase the strength of our neuro-symbolic paradigm, we present the results of removing neural or symbolic modules of LIPS in Appendix D. We also analyze the performance of symbolic solvers, offering guidance on optimal time limit settings in LIPS."}, {"title": "Case study", "content": "Besides the running example (1), we provide two additional examples in Appendix F to illustrate that LIPS can discover new proofs, which are previously unavailable online. Moreover, we also present two examples in Appendix F to demonstrate that users can verify human-written proofs by comparing them with the reasoning paths generated by LIPS."}, {"title": "6 RELATED WORK", "content": "In this section, we review related work on symbolic methods and LLMs for general mathematical reasoning and formal theorem proving, extending beyond inequality proving problems."}, {"title": "Symbolic Tools for Mathematical Reasoning", "content": "Symbolic tools are essential for performing exact computations and formal reasoning in mathematics. Interactive theorem provers such as Isabelle (Paulson, 1994), Coq (Coq, 1996), and Lean (de Moura et al., 2015) enable users to build verifiable proofs manually, ensuring correctness through rigorous formal logic. These systems have been instrumental in formalizing and verifying significant mathematical theorems, including the Four Color Theorem (Gonthier, 2008) and the Kepler Conjecture (Hales et al., 2017). Alternatively, some symbolic reasoning tools aim to solve mathematical problems without human intervention. Automated theorem provers like E (Schulz, 2002) and Vampire (Kov\u00e1cs & Voronkov, 2013) are designed to prove mathematical statements by systematically exploring possible proofs within a logical framework, particularly excelling in first-order logic. SMT solvers such as Z3 (De Moura & Bj\u00f8rner, 2008) and CVC5 (Barbosa et al., 2022) determine the satisfiability of logical formulas with respect to background theories like arithmetic, bit-vectors, and arrays by integrating logical reasoning with theory-specific decision procedures. Computer algebra systems like Mathematica (Wolfram Research), Maple (Heck & Koepf, 1993), and SymPy (Meurer et al., 2017) manipulate mathematical expressions symbolically, supporting functionalities such as simplification, differentiation, integration, and equation solving. Despite their capabilities, these automated solvers struggle with competitive mathematical problems and often cannot generate human-readable reasoning steps."}, {"title": "Machine Learning for Formal Theorem Proving", "content": "There is a longstanding tradition of leveraging machine learning techniques to automate theorem proving (Urban et al., 2008; Gauthier et al., 2018; Zhang et al., 2021; Piotrowski et al., 2023; Blaauwbroek et al.). Recently, the emergence of LLMs has expanded the potential of these techniques, offering new opportunities for automating theorem proving (Li et al., 2024). A line of research (Polu & Sutskever, 2020; Wu et al., 2021; Han et al., 2022; First et al., 2023; Yang et al., 2023; Xin et al., 2024a; Wu et al., 2024) fine-tunes pre-trained language models on large-scale formal datasets to predict the tactics given a proof goal. Alternative approaches (Jiang et al., 2022; Xin et al., 2024b; Zhao et al., 2024; Zheng et al., 2024; Thakur et al.,"}, {"title": "7 LIMITATIONS AND FUTURE WORK", "content": "While LIPS has shown significant promise in generating formal proofs for Olympiad inequalities, several avenues remain open for enhancement and expansion."}, {"title": "Automating the Formalization of Tactics", "content": "Our framework currently relies on a set of manually crafted tactics for scaling and rewriting inequalities, such as various forms of the AM-GM inequality. This manual effort may impact scalability, given that the effectiveness of our approach is closely tied to the breadth of available tactics. Future work could focus on automating the discovery, formalization, and proof of new tactics to expand the tactic library. Developing methods for automatic tactic generation would reduce human effort and enhance the framework's scalability and adaptability."}, {"title": "Enhancing the Reasoning Capabilities of LLMs", "content": "We leverage the mathematical insights learned by LLMs in our framework, and there is potential to further improve their reasoning performance. One promising direction is to collect or generate additional formal inequality problems and their corresponding proofs to create a richer dataset for fine-tuning LLMs specifically for this task. Some existing techniques may be useful for generating diverse and high-quality problems to enhance the LLMs' capabilities in handling inequalities, leading to better overall performance."}, {"title": "Broadening the Application Domain", "content": "While our framework currently focuses on Olympiad-level elementary algebraic inequalities, extending it to more complex problems, such as concentration inequalities in machine learning theory, presents an exciting avenue for future research. This would involve improving the symbolic solver to handle inequality structures that consist of infinite variables and higher-order concepts like expectations or variances. Developing efficient algorithms and symbolic reasoning methods for these advanced mathematical constructs could significantly broaden the applicability of our neuro-symbolic paradigm. Extending our approach to other mathematical domains holds great potential and is a promising direction for future work."}, {"title": "8 CONCLUSION", "content": "In this paper, we introduce a neuro-symbolic framework for generating formal proofs that integrates the mathematical intuition learned by LLMs with domain-specific insights encoded by symbolic methods, specifically focusing on the domain of Olympiad inequalities. We categorize the tactics used in inequality proofs into two types: scaling and rewriting. Symbolic methods are employed to generate and filter scaling tactics by applying a set of lemmas through mechanical symbolic reasoning. LLMs are leveraged to generate rewriting tactics, implicitly pruning the infinite number of equivalent transformations to a manageable set. We further combine symbolic tools with LLMs to prune and rank subgoals, enhancing the efficiency of proof search. Experiments on challenging inequalities from three problem sets show that our neuro-symbolic inequality prover LIPS significantly outperforms both LLMs and symbolic methods, demonstrating the effectiveness of the neuro-symbolic integration and laying a solid foundation for its adoption in broader domains."}, {"title": "C ADDITIONAL DETAILS FOR EXPERIMENTS", "content": "The experiments were conducted on four Linux servers equipped with 4 Intel(R) Xeon(R) Platinum 8280L CPU @ 2.80GHz. Each server ran Ubuntu 22.04 with GNU/Linux kernel 6.5.0-1015-azure. Each proving task was performed within a docker sandbox, utilizing 192 assigned CPU cores.\nNeural provers. For DSP, we directly use the official code, and adapt it to Lean language and GPT-40 (version Azure-05-01). MCTS is implemented based on classic upper confidence bounds applied to trees algorithm. The value function is defined as f(\u03d5) = U + C \u221a(log(N)/n_\u03d5), where n\u03d5 is the number of the proof goal \u03d5 is selected and explored, N\u03d5 represents the number of \u03d5's parent represents selected and explored, and C is a hyperparameter set to C = \u221a2. For the average reward v\u03d5 of the proof goal \u03d5, we use the same heuristic function as Wei et al. (2024), which calculates the maximum depth of the expression trees on both sides.\nSymbolic provers. For CAD, we utilize a portfolio including a suite of solvers, i.e., Z3, CVC5, RC-CAD, and Bottema. It will claim the problem is successfully proved if any one of four tools outputs unsat, and vice vica. Among four tools, Z3 and CVC5 are two popular SMT solvers; RC-CAD refers to the CylindricalAlgebraicDecompose function in Maple 2024 RegularChain package;\nLIPS. In our framework, the symbolic solver employed for pruning scaling tactics also consists of solvers Z3, CVC5, RC-CAD, and Bottema, complemented by a numerical optimizer grounded in SciPy (Virtanen et al., 2020). The time limit of searching counterexamples is set to 5 seconds. Scaling tactics encompasses a comprehensive array of inequality lemma, including AM-GM, AM-HM, Cauchy-Schwarz, Power Mean, Chebyshev, Muirhead, Jensen, Titu, Schur, Holder inequalities,"}, {"title": "D ABLATION STUDY", "content": "Scaling tactics. Figure 4(a) has shown how the performance on the ChenNEQ dataset (Y-axis) changes as we increase the number of lemmas used by scaling tactics (X-axis). When X = 0 (without scaling tactics), only 3 out of 41 theorems can be proved, whereas LIPS can prove 39 theorems.\nRewriting tactics. We observed that the successfully proved 3 theorems without scaling tactics are achieved by two"}]}