{"title": "HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications", "authors": ["Ziming Zhao", "Tiehua Zhang", "Zijian Yi", "Zhishu Shen"], "abstract": "Hypergraphs are increasingly utilized in both uni- modal and multimodal data scenarios due to their superior ability to model and extract higher-order relationships among nodes, compared to traditional graphs. However, current hypergraph models are encountering challenges related to imbalanced data, as this imbalance can lead to biases in the model towards the more prevalent classes. While the existing techniques, such as GraphSMOTE, have improved classification accuracy for minority samples in graph data, they still fall short when addressing the unique structure of hypergraphs. Inspired by SMOTE concept, we propose HyperSMOTE as a solution to alleviate the class imbalance issue in hypergraph learning. This method involves a two-step process: initially synthesizing mi- nority class nodes, followed by the nodes integration into the original hypergraph. We synthesize new nodes based on samples from minority classes and their neighbors. At the same time, in order to solve the problem on integrating the new node into the hypergraph, we train a decoder based on the original hypergraph incidence matrix to adaptively associate the augmented node to hyperedges. We conduct extensive evaluation on multiple single- modality datasets, such as Cora, Cora-CA and Citeseer, as well as multimodal conversation dataset MELD to verify the effectiveness of HyperSMOTE, showing an average performance gain of 3.38% and 2.97% on accuracy, respectively.", "sections": [{"title": "I. INTRODUCTION", "content": "Hypergraph learning has gained increasingly attention ow- ing to its potential in modeling and extracting high-order correlations within data compared to the ordinary graphs [1]. A key benefit of the hypergraph is that a hypergraph can encompass various types of hyperedges and nodes, while one hyperedge can connect multiple nodes, enabling a more accurate representation of group concepts that aligns with the deep relationships among entities in certain contexts [2]. This characteristic is particularly relevant in areas such as recom- mendation systems in social media [3], emotion detection in multimodal dialogue [4], and multi-source sleep quality assessment [5]. However, similar to the cases in ordinary graphs, hypergraphs also face significant challenges when dealing with class imbalances issues.\nIn machine learning field, class imbalance occurs when a dataset is skewed, resulting in one class significantly out- numbering the others. This imbalance can cause models that excel in identifying the dominant class while struggling with the underrepresented one. In general, solutions for tackling imbalanced data classification can be classified into three categories: data-level models [6], [7], algorithm-level models [8], and hybrid models [9], [10]. Data-level models aim to achieve the balance by either oversampling the minority class or undersampling the majority class [11]. Algorithm-level models enhance the model's sensitivity to the classification loss of the minority class by adjusting the class loss weights [12]. Hybrid models combine elements of both data-level and algorithm-level strategies [13]. One of the most classic models is SMOTE [14], which synthesizes new instances in non-Euclidean data by selecting the two closest samples from the minority class. GraphSMOTE [15] applies the prin- ciples of SMOTE to graph learning by introducing innovative schemes for creating connections between newly generated nodes and existing nodes in the graph structure. Nonetheless, GraphSMOTE is not applicable to accommodate the unique structure of hypergraphs. The objective of this paper is to explore a general solution for pairwise ordinary graphs to alleviate the class imbalance issue.\nOur work includes two main steps: The first step involves generating new nodes from the minority class. In a hypergraph topology that lacks physical meaning, such as multi-modal dataset MELD [16], the nearest neighbor is defined as the most similar minority class node. In contrast, for data with explicit graph structure like Cora [17], the nearest neighbor is determined by the average of all hyperedges associated with the node to simulate the context. In this paper, the existing nodes are referred to as target nodes, while the newly generated node is the augmented node. It is crucial to focus on the alignment among various modalities in multimodal data, as they are inter-related and can influence each other. As a solution, we propose designating one modality as the dominant mode for the above operations, with the other modalities being referred to as following modes, replicating the operations of the dominant mode.\nSubsequently, it is essential to construct the integration of augmented nodes into the hypergraph. Four potential method- ologies are employed for this construction: Nearest Source Node Assignment: it involves assigning the new node to the hyperedge corresponding to the nearest source node, thereby minimizing spatial discrepancies. Comprehensive Allocation:"}, {"title": "II. RELATED WORK", "content": "A. Hypergraph Learning\nCompared with the ordinary graphs that are limited to pair- wise connections, hypergraphs represent an advanced form of graph learning that can capture high-order correlations within data [1]. By allowing multiple nodes to be connected through a single hyperedge, hyperedges can represent diverse types of relationships, thus mimicking real-world structures while preserving abundant information [18]. To date, several variants of hypergraph learning have emerged, including HGNN [18], HGNN+ [19], HyperAttn [20] and HyperGCN [21]. Despite differences in implementation, these hypergraph models all employ a convolutional approach, where the information from connected nodes is aggregated via hyperedges and subse- quently transmitted back to the nodes. Hypergraph learning has demonstrated its effectiveness in various data association tasks [22]\u2013[24]. Although there have been significant advance- ments in hypergraph learning for data modeling and multi- modal fusion, the class imbalance issues remains unresolved, hindering the broader adoption of hypergraph techniques.\nB. Class Imbalance Problem\nClass imbalance is a critical issue in machine learning, which often leads to generated models perform well on the majority class while underperforming on the minority class [14]. Such an imbalance can introduce model bias and hinder generalization, as the model may overlook important patterns within the minority class.\nVarious strategies, including resampling techniques such as oversampling the minority class [6] or undersampling the majority class [7], are proposed to address this issue. Additionally, cost-sensitive learning [8] can be used to impose greater penalties for misclassifying the minority class. Overall, tackling class imbalance is essential for developing robust machine learning models, and experimenting with different strategies is crucial for achieving balanced performance.\nDespite the notable success of GraphSMOTE in extend- ing the concept of SMOTE to graph learning through the incorporation of learnable edge predictors, it is not applicable to hypergraph learning due to three main reasons: Struc- tural Differences: Hyperedges possess fundamentally differ- ent structures compared to ordinary graph edges. Contextual Representation: In hypergraphs with practical significance, selecting the most similar node as the neighbor for generat- ing a new node fails to accurately represent the contextual relationships of the node, leading to discrepancies with the actual node. Challenges in Multimodal Integration: In multimodal hypergraphs, GraphSMOTE encounters difficulties in synthesizing multimodal information that closely resembles the original data. This challenge arises from the complex inter- actions and constraints among different modalities associated with the same entity."}, {"title": "III. METHODOLOGY", "content": "The overall pipeline of HyperSMOTE is composed of three modules, including the feature extraction, node feature genera- tion, and hypergraph expansion. \n\nA. Feature Extraction\nThe initial hypergraph can be represented with notation G =\n{V, E, X}, where X \u2208 R|V|\u00d7D denotes the raw feature of each\nnode. Following the concept of message passing from MPNN\n[25], convolution on hypergraph can be considered as a two- step process. Information from nodes are first aggregated to their corresponding edges, resulting in the feature embeddding of hyperedges. Then the message is propagated back to nodes, which further updates the node embeddings. The process of hypergraph convolution can be formulated as follows:\n\u0395\u03b5 = Aggr(\u03b5, \u03c3(W\u2081X)) (1)\n\u0395\u03c5 = Aggr(\u03b5, \u03c3(W2E\u03b5)) (2)\nwhere E\u025b \u2208 R|E|\u00d7D stands for the hyperedge embedding\nand Ev \u2208 R|V|\u00d7D represents the updated node embedding.\nW\u2081 and W2 are linear projection matrices and \u03c3 stands for\nthe activation function. The aggregation is chosen with a\nmean pooling layer, which equivalently provides normalization\nbased on the degree of hyperedges and nodes.\nB. Node Generation\nIn order to augment the training samples from minority\nclasses to alleviate the class imbalance problem by increasing\nthe size of the training set, the augmentation process is\nrepeated multiple times for each single sample within the\nminority classes. In Fig 1(a), samples from majority classes\nare represented with green nodes while samples from the minority classes are denoted in blue. The specific target node that is being augmented is represented by the blue node surrounded by black dash boundary, which is denoted as vt, and the paired augmented node is represented by the blue node surrounded by orange dash boundary, which is denoted as vg. It is required to build up the feature embedding for vg from the context of hypergraph. To make sure the synthesized embedding lies in the same feature space with the target node Ut, the feature embeddings from both vt and its neighbors should be considered for feature generation. Denote the feature embedding of the augmented node as Evg, and it is generated as follows:\n\u0395\u03c5\u03c2 = \u03c4\u0395\u03c5\u03c4 + (1 \u2212 \u03c4)Mean({Ev\u2081|Vi \u2208 N(vt)}) (3)\nwhere N(vg) represents the neighbor nodes of vt and a certain node is considered as the neighbor node of vt if it is connected by any hyperedge that includes vt. T herein refers to the hyperparameter that determines the weight between the target node embedding and neighbor node embeddings. Based on the general assumption that nodes with close attributes are more likely to be connected, by adding the feature of the target node and its neighbor embeddings, it is possible to generate a synthesis node that is similar to the target node in the feature space. The generated embedding is illustrated as the orange vector in Fig 1(b). Moreover, the label of all augmented nodes should maintain the same with the target nodes, which means\nY(vg) = Y(vt).\nC. Hypergraph Expansion\nTo fuse the augmented node into the hypergraph as well as perform hypergraph convolution on both original nodes and augmented nodes, the augmented nodes need to be adaptively appended to the inital hypergraph. A specific form of decoder is designed to reconstruct the hypergraph incidence matrix H. The decoder can be fomulated with the following transforma- tion:\n\u0397\u03b5,\u03c5\u03c2 = \u03c3(\u0395\u03c5\u03c1\u00b7 \u03a1\u00b7 \u0395\u20ac) (4)\nwhere P \u2208 RD\u00d7D denotes the learnable projection matrix that projects the dot product between the feature embedding of hyperedges and nodes into a scalar. As all elements of hypergraph incidence matrix take on value of either 0 or 1, the sigmoid activation function is applied to limit the range of the decoder output. The decoder is trained based on the original incidence matrix with no augmented nodes. By optimizing the following loss\nLP = - \u03a3\u03a3(He,vi log Hev + (1 \u2212 He,vi) log(1\u2212\u0124e,v\u2081)), (5)\nViEV \u0395\u0395\u0395\nthe decoder is able to capture the topology of the hypergraph and reconstruct the hypergraph incidence matrix based on node embeddings and hyperedge embeddings. The augmented node will be attached to a single hyperedge that is most relevant to it, in other words,\nHe,ug =  1, if He,vg = max({\u0124ei,v9, \u20aci \u2208 E}) \n                0, otherwise (6)\nwhich means the augmented node will be attached to the hyperedge with the highest inference probability from the incidence matrix predicted by the decoder. The extended hy- peredge is illustrated as the orange dash line from Fig 1(c). The overall augmentation process of HyperSMOTE is completed before task-specific supervised training, which means the node augmentation and hyperedge expansion are performed to the dataset independently and a single round of augmentation can be generally applied to multiple downstream tasks on the same dataset."}, {"title": "IV. EXPERIMENTS", "content": "A. Experimental Setting\nHyperSMOTE is evaluated on three widely adopted datasets from graph learning field and a multimodal dataset from the field of emotional recognition. We apply HyperSMOTE on Cora, Cora-Cocitation and Citeseer datasets, where each hyperedge explicitly represents co-citation or co-authorship relationships between papers. While for multimodal dataset MELD, each hyperedge represents the correlation among audio, visual and textual modalities. We apply this setting of datasets in order to justify that HyperSMOTE is able to augment both hyperedges with practical significance and hyperedges with abstract usage for feature fusion.\nB. Experimental Result\nThe experiment results are summarized in Since we aim to evaluate models that can best improve the performance of minority categories while not impairing the performance of other categories, Macro-F1 score and Accuracy are applied as evaluation metrics.\nHyperSMOTE is able to reach an average performance gain of 3.84% in Macro-F1 score and 3.38% in Accuracy on citation datasets and 3.85% in Macro-F1 score and 2.97% in Accuracy on multimodal datasets. The results indicate that HyperSMOTE enhances model performance by balancing the number of training samples across all classes. It is achieved by generating in-distribution nodes that conform to the training data's distribution and adaptively attach the augmented node to the most relevant hyperedge, informed by the data's topology. Such augmentation of HyperSMOTE acts as a solution to imbalanced labels."}, {"title": "V. CONCLUSION", "content": "We propose HyperSMOTE in this work o alleviate the class imbalance problem on both unimodal and multimodal datasets, which synthesizes node feature based on target nodes from minority classes with their neighbors and trains the decoder on incidence matrix to attach the augmented node into the most relevant hyperedge. Extensive comparison with various baselines on three graph structure unimodal datasets and one multimodal dataset demonstrates that HyperSMOTE is able to augment the minority class with samples that help improve the performance of the model."}]}