{"title": "VISTA: A Panoramic View of Neural Representations", "authors": ["Tom White"], "abstract": "We present VISTA (Visualization of Internal States and Their Associations), a novel pipeline for visually exploring and interpreting neural network representa-tions. VISTA addresses the challenge of analyzing vast multidimensional spaces in modern machine learning models by mapping representations into a semantic 2D space. The resulting collages visually reveal patterns and relationships within internal representations. We demonstrate VISTA's utility by applying it to sparse autoencoder latents uncovering new properties and interpretations. We review the VISTA methodology, present findings from our case study, and discuss im-plications for neural network interpretability across various domains of machine learning.", "sections": [{"title": "1 Introduction", "content": "Deciphering the internal representations of neural networks and biological brains remains a formidable challenge in both artificial intelligence and neuroscience. As models grow in complexity and scale, traditional methods of analysis struggle to provide comprehensive insights into the vast landscape of learned features and concepts. This challenge is further compounded by the emerging evidence that different learning systems, when exposed to similar stimuli, often develop comparable internal representations a phenomenon that demands novel approaches for investigation and understanding (Sucholutsky et al., 2023)."}, {"title": "2 Methodology", "content": "The VISTA pipeline consists of several steps designed to create an interactive, visual representation of high-dimensional data.\n1. Representation and Dataset Selection: Choose a dataset of interest and a representation that assigns a feature vector to each input.\n2. Data Encoding: Encode the dataset using the selected representation.\n3. Dimensionality Reduction: Apply UMAP clustering to project the encoded data into a 2D space, preserving nearest neighbor relationships from the higher-dimensional representation (McInnes et al., 2020).\n4. Cartographic Rendering: Generate a visual map of the 2D space. This process involves dividing the 2D space into smaller tiles, extracting the subset of the original dataset that corresponds to each area of the UMAP projection, and rendering one item from each subset as part of a MultiDiffusion panorama (Bar-Tal et al., 2023).\n5. Interactive Visualization: Present the resulting graphic in an interactive interface, allowing exploration of the visual space alongside the corresponding data points.\nThe cartographic rendering has been iteratively refined to highlight semantic structure. The UMAP clusters abstracted into areas of high probability with connections between clusters explicitly shown and overlaid with semantic information from the text-to-image process. Taking advantage of the iterative nature of the diffusion pipeline, we select different inputs within each region at each step of the diffusion process to semantically smooth out the drawing process and remove outliers. Together these produce a more coherent and representative visualization.\nThe final result is an interactive graphic that invites exploration. Visual anomalies naturally draw attention, encouraging closer inspection and potentially revealing unexpected patterns or relationships within the data.\nOur efforts of understanding shared representational structure are grounded in using mutual nearest neighbor metric for measuring alignment. This is consistent with recent research on representational alignment (Huh et al., 2024). The fidelity of the resulting VISTA map itself can also be measured directly as nearest neighbor analysis is meaningful across both low and high dimensional spaces. We report these map accuracies as mutual-knn \"gain\" which explicitly removes the null hypothesis of chance neighbor pairings as k increases (see appendix A for notes).\nIn the following section, we present a specific use case and implementation results to demonstrate the effectiveness of the VISTA pipeline in practice."}, {"title": "3 Experiment: Interpreting Sparse Latents", "content": "Sparse autoencoders (SAEs) have emerged as a promising technique in machine interpretability, but understanding the \"meaning\" encoded in each of the thousands of latents remains elusive. Current best practice is \"Automated Interpretability\" in which the latents are fed into LLMs and they come up with suggested labels for each of the latents (Bills et al., 2023).\nWe constructed a VISTA pipeline to explore the latents of the publicly released Gemma2-2B SAE latents (Lieberum et al., 2024). Here we use the implementation covered above and look at the resulting visualizations for 3 latents in particular to see how our approach is compatible with the automated techniques, but able to surface new and previously hidden properties."}, {"title": "3.1 Implementation", "content": "Following the steps outlined in our methodology:\n\u2022 Representation and Dataset: We chose Gemma2-2B SAE 16k residual layer 20 as the representation. For the dataset we chose 200,000 auto-generated short captions from the Human Preference Synthetic Dataset (ProGamerGov, 2024) which follows the methodology of Betker et al. (2023). For each map we take the top 4000 (2%) captions that maximize the selected latent, and each caption is represented by this SAE representation.\n\u2022 Dimensionality Reduction: We applied a custom distanct metric which sums the cosine distance in SAE space with the absolute difference along the latent axis. This was mapped into a UMAP with an asymmetric aspect ratio.\n\u2022 Cartographic Rendering: We used a version of MultiDiffusion running on the Flux.1 [dev] diffusion model (Labs, 2024), with 100 diffusion steps and a minimum of 4 points per cluster for semantic smoothing.\n\u2022 Interactive Visualization: The resulting graphic was placed in an interactive interface for exploration, with the original 4000 captions arranged spatially to preserve nearest neighbors.\nThese choices provided a practical way to make an initial evaluation of our approach. The dataset was selected as it contains a variety of subjects and is already well suited for use in a text-to-image context. The UMAP hyperparameters were intended to allow \"stretching\" along the latent axis and though this wasn't always achieved as intended we did see stable clustering across runs with different random seeds. Using a single A100 GPU we could generate one 144 megapixel (9k x 16k) panorama image in a few hours. VISTA interfaces for twelve Gemma Scope latents were created and can be explored in our online interface; three of these are explored below as case studies."}, {"title": "3.2 Case Studies", "content": "We examined three specific latents to demonstrate the capabilities of our VISTA approach:"}, {"title": "3.2.1 Case Study 1: \"ingredients\" [gemma-2-2b/20-res-16k/5011]", "content": "Our findings: Visual inspection confirmed a large number of food-related ingredients, supporting the Gemma Scope label. The visualization hinted at specific ingredients triggering this latent code and their proportions in the dataset. For example, Figure 2 includes inputs referencing champagne, beer, iced tea, chips, honey, pizza, pretzels, and cheese. This map has a mutual-knn gain max of 0.129 at k=9%."}, {"title": "3.2.2 Case Study 2: \"muscle\" [gemma-2-2b/20-res-16k/9745]", "content": "Our findings (see Figure 1): Initial inspection agreed with the label, showing many regions with muscular imagery. However, we discovered an additional pattern: about 40% of the inputs lacked muscular references, instead clustering around words beginning with \"M\" (e.g., \"musical\", \"mus-tache\", \"mystic\", \"mossy\"). This suggests the latent is also weakly triggered by certain \"M\" words. This map has a stronger mutual-knn gain max of 0.273 at k=5%."}, {"title": "3.2.3 Case Study 3: \"indebted\" [gemma-2-2b/20-res-16k/9220]", "content": "Our findings: This case was the most divergent from the Gemma Scope label. VISTA visualization showed clear visual clusters with no references to finance. Further examination revealed that this latent is triggered by conjunctions of visual forms, such as \"a dramatic sunset or sunrise\", \"in a medieval or fantasy setting\", \"in a black & red attire\", and \"a unique half-deer, half-human figure\". This discrepancy could be due to domain skew between datasets or limitations in automated techniques for identifying complex associative patterns. This map has a relatively weaker mutual-knn gain max of 0.099 at k=12%.\nThese case studies demonstrate VISTA's ability to confirm automated interpretations and uncover additional, sometimes unexpected, patterns in SAE latents."}, {"title": "4 Conclusion", "content": "VISTA (Visualization of Internal States and Their Associations) introduces a novel approach to exploring and interpreting neural representations through visual cartography. Our experiment with sparse latents from the Gemma2-2B model demonstrates VISTA's potential to complement and extend current automated interpretability techniques.\nKey findings include:\n\u2022 Confirmation of some automated interpretations, validating VISTA's basic functionality.\n\u2022 Discovery of additional patterns not captured by automated methods, such as secondary triggers for certain latents.\n\u2022 Revelation of unexpected associations, highlighting potential limitations in current auto-mated techniques."}, {"title": "A Notes on mutual knn gain metric", "content": "We have attempted to quantitatively measure the fidelity of the resulting VISTA visualizations using mutual-knn scoring as is covered in more detail in (Huh et al., 2024). We have found two conventions useful in adapting this metric:\n1) We generally express k as a percentage instead of an absolute number, which is easier to compare across different size datasets. We have also found in practice that mutual-knn can be quickly estimated my taking a smaller subset of the data, which is useful for iterative development. Each of our case study datasets were 4000 points, so absolute k reported can be found by multiplying (eg: mutual-knn at 1% refers here to k=40)\n2) We generally allow higher values of k (5-10%) than usually used found in alignment studies as we expect mapping down to two dimensions to be quite lossy. However for unaligned and randomly distributed data, the mutual-knn will grow linearly with k. So we report mutual knn \"gain\" - which subtracts off this k percentage expected by chance. Note that when k is expressed as a percentage, the maximum gain is now 1-k and misaligned datasets can even have negative gain up to -k. With this calibration, randomly distributed data has an expected mutual-knn gain of zero across all values of k.\nWe've found these conventions useful in understanding how the alignment is behaving at various resolutions. For example, we can vary k to verify the mutual knn gain in case study one is maximized at k=9% and also characterize the degradation at finer and courser settings. (Figure 4)"}]}