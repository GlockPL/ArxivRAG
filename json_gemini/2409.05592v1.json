{"title": "ExDDI: Explaining Drug-Drug Interaction Predictions with Natural Language", "authors": ["Zhaoyue Sun", "Jiazheng Li", "Gabriele Pergola", "Yulan He"], "abstract": "Predicting unknown drug-drug interactions (DDIs) is crucial\nfor improving medication safety. Previous efforts in DDI pre-\ndiction have typically focused on binary classification or pre-\ndicting DDI categories, with the absence of explanatory in-\nsights that could enhance trust in these predictions. In this\nwork, we propose to generate natural language explanations\nfor DDI predictions, enabling the model to reveal the un-\nderlying pharmacodynamics and pharmacokinetics mecha-\nnisms simultaneously as making the prediction. To do this,\nwe have collected DDI explanations from DDInter and Drug-\nBank and developed various models for extensive experi-\nments and analysis. Our models can provide accurate expla-\nnations for unknown DDIs between known drugs. This paper\ncontributes new tools to the field of DDI prediction and lays\na solid foundation for further research on generating explana-\ntions for DDI predictions.", "sections": [{"title": "Introduction", "content": "Drug-drug interaction (DDI) refers to the alteration of the ef-\nfects of one or more drugs when drugs are taken simultane-\nously (Zhang et al. 2023). Such changes may lead to loss of\ntherapeutic effect or occurrence of toxicity, threatening pa-\ntient safety (Zhang et al. 2023). With the increasing number\nof approved drugs in recent years, the likelihood of interac-\ntions between drugs has also increased (Khori, Semnani, and\nRoshandel 2011; Han et al. 2022). Although wet lab experi-\nments are available for validating DDIs, they are hindered by\nstrict experimental conditions and high costs (Safdari et al.\n2016), making it unfeasible to explore all potential inter-\naction combinations. Therefore, computational methods for\npredicting DDIs have been extensively researched, and nu-\nmerous models have demonstrated strong predictive capa-\nbilities. However, as predictive capabilities advance, mod-\nels tend to become more complex and opaque, obstructing\nusers' understanding of the predicted results (Vo et al. 2022).\nSpecifically, the majority of previous methods have fo-\ncused only on binary classification, i.e., predicting whether\nthere is an interaction between two drugs (Figure 1(b)), yet\noverlooking the mechanisms and outcomes of DDIs (Zhang\net al. 2023). To help users better grasp DDI knowledge\nfrom predictions, some studies have proposed DDI-type pre-\ndiction (Ryu, Kim, and Lee 2018; Deng et al. 2020; Lin\net al. 2022), which is defined as a multi-classification prob-\nlem that categorises DDIs into various subtypes accord-\ning to their effects. For example, Deng et al. (2020) used\nNLP techniques to extract quadruples (drugA, drugB,\nmechanism, action) from DDI descriptions collected\nfrom DrugBank, where \u2018mechanism' refers to the drugs'\neffects on metabolism, serum concentration, therapeutic ef-\nficacy, etc., and 'action' indicates an increase or decrease.\nThey summarised DDIs into 65 types based on the extracted\nquadruples used for classification (Figure 1(c)).\nWhile DDI-type prediction reveals the outcomes of DDI\nevents, the granularity is coarse, lacking attention to the un-\nderlying causes of DDIs. As a valuable resource, Xiong et al.\n(2022) constructed the DDInter database, gathering infor-\nmation on 1.8k approved drugs and 0.24M associated DDIs,\nalong with detailed explanations. The explanations were col-\nlected from scientific literature in PubMed and medication\nguides of drugs, and reviewed by a clinical pharmacist team.\nCompared to DDI types defined by previous research, the\nDDI explanations provided in DDInter are more informa-\ntive, encompassing not only the consequences of DDIs but"}, {"title": "Related Work", "content": "DDI Prediction and Interpretability Many efforts have\nbeen dedicated to DDI prediction over the years. Some\nof them are based on similarity measurements, which are\ngrounded on the assumption that similar drugs may possess\nsimilar biological activity. Various similarity matrices - tar-\ngeting molecule structure, side effect, protein targets, etc. -\ncan be used for direct matching (Vilar et al. 2012; Fer-\ndousi, Safdari, and Omidi 2017) or as features to train ma-\nchine learning classifiers (Gottlieb et al. 2012; Cheng and\nZhao 2014; Sridhar, Fakhraei, and Getoor 2016) and neural\nnetworks (Rohani and Eslahchi 2019; Lee, Park, and Ahn\n2019; Zhang, Lu, and Zang 2022). Other approaches involve\nmatrix decomposition of known DDI matrices combined\nwith multiple relation matrices to predict unknown DDIs\n(Zhang et al. 2018; Rohani, Eslahchi, and Katanforoush\n2020). Additionally, recent advancements have incorporated\nknowledge graphs (Asada, Miwa, and Sasaki 2023; Ren\net al. 2022) and graph neural networks for learning single\nor paired molecular structures (Baitai et al. 2023; Li et al.\n2023b; Nyamabo et al. 2022) to enhance prediction accu-\nracy.\nIn recent years, the transparency of DDI prediction mod-\nels has gained significant attention. Some studies have em-\nployed matrix factorization (Zhu et al. 2022) or attention\nmechanisms (Ma and Lei 2023; Li et al. 2023b) to iden-\ntify representative features or substructures in DDI inter-\nactions, offering valuable insights into the underlying pre-\ndiction mechanisms. However, generating natural language\nexplanations that focus on elucidating the pharmacological\nprinciples of DDIs offers another promising direction for\nfurther exploration. Additionally, exploring whether intro-\nducing supervision signals from these explanations could\nenhance the prediction task itself is an intriguing question.\nFurthermore, natural language explanations are more user-\nfriendly for human understanding and could be integrated\nwith substructure-highlighting methods in future work."}, {"title": "Natural Language Explanation Generation", "content": "Natural lan-\nguage explanation generation aims to create free-text expla-\nnations for model predictions to help users better understand\nmodel behaviour and make decisions. Previous work had ex-\nplored various training paradigms over prediction and expla-\nnation generation, which were categorised into four types by\nHase et al. (2020) based on whether the model is provided\nwith labels (RA) or not (RE) during the generation of ex-\nplanations and whether the generated explanations are used\nas part of the input for predicting (ST) or not (MT). Specifi-\ncally, the ST-RE paradigm in the first stage trains the model\nto generate explanations based on the input text and, in the\nsecond stage, learns to predict labels based on explanations\ngenerated in the first stage (Rajani et al. 2019). The ST-RA\nparadigm first learns to produce explanations based on la-\nbels and input, then generates an explanation for each label\nin the second stage and trains the model to make predic-\ntions based on all explanations (Hase et al. 2020). The MT-\nRE paradigm refers to jointly training the model to generate\nboth labels and explanations simultaneously (Narang et al.\n2020; Yordanov et al. 2022). The MT-RA paradigm not only\njointly trains the prediction and explanation generation, but\nalso provides labels during the explanation generation pro-\ncess (Camburu et al. 2018; Li et al. 2023a). This is achieved\nby feeding the gold label to train the explanation genera-\ntion model and using the label predicted by the model for\ninference. For the DDI explanation generation task, expla-\nnations for negative cases are naturally absent. We use arti-\nficially constructed explanations for negative cases to train\nthe model, but the relationship between such explanations"}, {"title": "Method", "content": "Task Formulation Given a drug pair (d1,d2),\none of our objectives is to predict DDI label\nl\u2208 {\"positive\u201d, \u201cnegative\"}, denoting the presence\nor absence of interactions between these drugs when\nadministered together. Additionally, we aim to generate\na textual explanation, s, elucidating the rationale behind\nthe existence or non-existence of DDIs. For positive\ninstances, we rely on DDI descriptions sourced from\nDDInter (Xiong et al. 2022) or DrugBank as the target\nexplanation, while for negative instances lacking natural\nlanguage explanations, we formulate target explana-\ntions using a predefined template: s = \u2018<DRUG1_DEF>.\n<DRUG2_DEF>. There were no known direct\ninteractions reported between them.',\nwhere <DRUG1_DEF> and <DRUG2_DEF> represent the\ndrug descriptions retrieved from the DDInter database for\nd\u2081 and d2 respectively.\nWe explored three setups: fine-tuning methods with dif-\nferent paradigms, retrieval-based methods, and LLM-based\nin-context demonstration prompting methods on this task."}, {"title": "Fine-tuning Methods", "content": "For the fine-tuning methods, we constructed a Seq-to-Seq\nmodel (ExDDI-S2S), a Multi-Task training model with an\nadditional classifier (ExDDI-MT) and a Multi-Task training\nmodel with Staged generation constrained by the classifier's\nprediction (ExDDI-MTS). We use MolT5 (Edwards et al.\n2022) as the backbone encoder-decoder for these models as\nit has been pre-trained on molecule-text translation tasks that\nestablish a connection that maps molecular features and nat-\nural language representations into a shared space, thereby\nenhancing the model's generalisability.\nExDDI-S2S For each query drug pair (d1,d2), we con-\nstruct the model's input x as 'DRUG1 <SMILES1>;\nDRUG2 <SMILES2>', where <SMILES1> and\n<SMILES2> correspond to the SMILES representa-\ntions of d\u2081 and d2, respectively. For the target output, we\nfirst replace mentions of drug names in the target expla-\nnations with 'DRUG1' and 'DRUG2' through regularised\nexpression matching, and then construct the generation\ntarget sequence y = '<s> <LABEL> Explanation:\n<EXP> </s>', where <LABEL> represents 'positive' or\n'negative' and <EXP> is the preprocessed explanation text.\nThen the model is trained by the following text generation\nloss:\n$L_{gen} = \\sum_{i=1}^{N} \\sum_{t=1}^{T} log (p(y_t^{(i)} | x^{(i)}, y_{<t}^{(i)}, \\Theta)),$ (1)\nwhere N represents the size of the training set, T denotes the\nlength of the target sequence, and \u0398 signifies the parameters\nof the encoder and decoder.\nExDDI-MT Simultaneously generating prediction labels\nduring the target sequence generation process could poten-\ntially divert the model's attention from learning the classifi-\ncation task effectively. Hence, we attempt to introduce an ex-\ntra classification module for multi-task training. The design\nof the classification module is inspired by Nyamabo et al.\n(2022), where a linear transformation matrix M is learned"}, {"title": "Experiments", "content": "Experimental Setup\nFor hyper-parameter selection and training details, please re-\nfer to Appendix B.\nDatasets We evaluate the model performance based on\ntwo databases: DDInter (Xiong et al. 2022) and DrugBank\n(v5.1.10). DrugBank is a widely used resource for training\nand evaluating DDI prediction models, but it only provides\nbrief DDI explanations for open download. On the other\nhand, DDInter offers more extensive and detailed expla-\nnations involving pharmacodynamics and pharmacokinetics\nprinciples. The selection of these two datasets is motivated\nby their coverage of explanations with varying lengths, en-\nabling us to gain insights into the model's performance when\ngenerating explanations of different complexities. We col-\nlected data on drug SMILES representations, drug descrip-\ntions, annotations of DDIs and relevant explanations to con-\nstruct the datasets.\nSettings for Model Generalisation Evaluation To exam-\nine the model's generalisation ability to new drugs, we fol-\nlowed previous work (Nyamabo et al. 2022; Li et al. 2023b)\nto evaluate the model under both transductive and inductive\nsettings. For transductive setting, we evaluate the models'\nperformance on unknown DDI pairs, allowing drugs from\nthe training set to also appear in the test set. We randomly\ndivided all positive and negative samples into training/vali-\ndation/test sets with a ratio of 0.7/0.1/0.2. For inductive set-\nting, we evaluate the model's performance not only on un-\nknown DDIs but also on unknown drugs. Specifically, the\ntest set is split into inductive S1 and inductive S2 subsets ac-\ncording to whether both drugs are unavailable in the training\nset or only one drug is unavailable in the training set. We first\ndivided drugs into three sets, M1, M2, and M3, with propor-\ntions of 0.75/0.05/0.2. Then, the training set consists of DDI\nsamples where both drugs in the queried drug pair are from\nM1; The validation set includes samples where both drugs\nare from M2, or one is from M2 and the other is from M1;\nThe inductive S1 test set contains samples where both drugs"}, {"title": "Conclusion", "content": "This work introduces the task of generating natural language\nexplanations for DDI predictions, advancing DDI computa-\ntional methods towards a more trustworthy AI direction. We\ndeveloped the ExDDI family of models for this task and con-\nducted a thorough evaluation, providing tools and baselines\nfor future research. The experimental results reveal that the\ntop-performing methods can effectively predict and explain\nnew DDI relationships for known drugs, but their ability to\npredict and explain DDIs involving new drugs still requires\nsignificant improvement. Additionally, our experiments in-\ndicate that training models to generate more detailed DDI\nexplanations can enhance the prediction task itself. We be-\nlieve that generalising to molecular structures unseen dur-\ning training is a significant challenge for current DDI pre-\ndiction and explanation generation models. Future research\nshould consider incorporating the graph structure of chemi-\ncal molecules and utilising multi-dimensional similarity in-\nformation to learn more informative drug representations."}]}