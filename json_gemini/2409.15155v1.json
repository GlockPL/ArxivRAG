{"title": "MAR-DTN: Metal Artifact Reduction using\nDomain Transformation Network for\nRadiotherapy Planning", "authors": ["Bel\u00e9n Serrano-Ant\u00f3n", "Mubashara Rehman", "Niki Martinel", "Michele Avanzo", "Riccardo Spizzo", "Giuseppe Fanetti", "Alberto P. Mu\u00f1uzuri", "Christian Micheloni"], "abstract": "For the planning of radiotherapy treatments for head and\nneck cancers, Computed Tomography (CT) scans of the patients are\ntypically employed. However, in patients with head and neck cancer,\nthe quality of standard CT scans generated using kilo-Voltage (kVCT)\ntube potentials is severely degraded by streak artifacts occurring in the\npresence of metallic implants such as dental fillings. Some radiotherapy\ndevices offer the possibility of acquiring Mega-Voltage CT (MVCT) for\ndaily patient setup verification, due to the higher energy of X-rays used,\nMVCT scans are almost entirely free from artifacts making them more\nsuitable for radiotherapy treatment planning.\nIn this study, we leverage the advantages of kVCT scans with those of\nMVCT scans (artifact-free). We propose a deep learning-based approach\ncapable of generating artifact-free MVCT images from acquired kVCT\nimages. The outcome offers the benefits of artifact-free MVCT images\nwith enhanced soft tissue contrast, harnessing valuable information ob-\ntained through kVCT technology for precise therapy calibration. Our\nproposed method employs UNet-inspired model, and is compared with\nadversarial learning and transformer networks. This first and unique ap-\nproach achieves remarkable success, with PSNR of 30.02dB across the\nentire patient volume and 27.47dB in artifact-affected regions exclusively.\nIt is worth noting that the PSNR calculation excludes the background,\nconcentrating solely on the region of interest.", "sections": [{"title": "1 Introduction", "content": "Since their introduction in the 1970s, advanced medical imaging techniques,\nparticularly high-resolution Computed Tomography (CT), have been crucial for\ncomputer-assisted diagnosis [5]. However, when patients with metal implants\nundergo imaging, such as dental fillings or hip prostheses, severe beam attenua-\ntion occurs, resulting in discernible streaks that compromise image fidelity and\nhampering clinical assessment [1].\nRecent advancements in deep learning have shown promise in mitigating\nmetal artifacts through supervised learning methodologies. However, obtaining\nground truth images without artifacts is challenging. [9] tackles this issue by\ngenerating datasets with and without metal artifacts, enabling the development\nof numerous algorithms for Metal Artifact Reduction (MAR). Other approaches\nencompass a variety of image-to-image deep learning models, including deep\nresidual architectures [6] and interpretable convolutional dictionary networks\n[24]. Numerous other methodologies utilize sinogram-to-sinogram deep learn-\ning models [20,30] or dual-domain deep learning models using both image and\nsinogram data [15,12,28]. These models can be further extended by incorporat-\ning state-of-the-art interpolation-based algorithm Normalized MAR corrected\ndata as an extra input [4,14]. A combination of multiple supervised deep learn-\ning methods can be effective in reducing metal artifacts from complex cases of\ncardiac CT images [17]. Approach [25] uses pix2pix [7] for MAR, it introduces\nband-wise normalization method, which splits a CT image into three channels ac-\ncording to the intensity value and considerably improves the performance of the\nCGAN. CNN-based approach [29] is introduced to predict an artifact-suppressed\nprior image. Extending these concepts, [15] introduced DuDoNet, a dual-domain\nlearning technique combining sinogram enhancement and image domain recon-\nstruction. Improved version of DuDoNet [15], restores sinogram consistency and\nsimultaneously enhance CT images by incorporating metal segmentation in both\ndomains. In more recent work, [18] introduced an alternative dual-domain ap-\nproach, emphasizing deep sinogram completion for improved MAR performance.\nMega-Voltage Computed Tomography (MVCT) is used for verification of pa-\ntient positioning immediately before the radiotherapy treatment. It is less prone\nto streak artifacts from metallic implants because it uses high-energy beams pro-\nduced by a radiotherapy linear accelerator, which are less attenuated by metal\nthan conventional diagnostic X-rays. The main drawback of MVCT is that it\nis available only in some specialized radiotherapy machines [5]. [16] proposes to\nreduce metal artifacts in kVCT by using MVCT images as prior images. The\niterative method proposed in [19] segments tissue regions in Megavoltage cone-\nbeam CT images and the metal region in kVCT images for template creation.\nForward projection of the templates generates sinograms. Artifact images are\nreconstructed from the sinograms. Finally, corrected images are obtained by sub-\ntracting artifact images from original kVCT images. [21] utilizes the sinogram\nof kVCT and MVCT along with the corresponding metal trace to ultimately\nproduce artifact-free kVCT images. Methodology proposed in [10], employing\nconvolutional neural networks to obtain artifact-free kVCT images, by utilizing"}, {"title": "2 Methods", "content": "2.1 Dataset Collection and Processing\nDue to the lack of available aligned kVCT and MVCT datasets, a new dataset\nconsisting of 5469 images from 52 patients from the National Cancer Institute\n(CRO) IRCCS6. For each patient, we acquired kVCT and MVCT images; the\nkVCT images obtained have matrix size of 512x 512, on the axial plane with a\npixel size of 1.074 mm \u00d7 1.074 mm, and slice thickness of 2 mm, furthermore,\nthe MVCT images obtained have a matrix size of 512 \u00d7 512, on the axial plane\nwith a pixel spacing of 0.754 mm \u00d7 0.754 mm with the slice thickness of 2 mm\nor 4 mm.\nPatients underwent intensity-modulated radiotherapy for oropharyngeal or\nnasopharyngeal cancer. Non-contrast-enhanced CT imaging was performed us-\ning a 32-slice scanner (Toshiba Aquilion LB, Toshiba Medical Systems Europe,\nZoetermeer, the Netherlands) with parameters set at 120 kVp, 2-5 mm slice\nthickness, and 1.07-1.17 mm pixel size. Additionally, patients underwent scan-\nning with helical tomotherapy (Hi-Art II Tomotherapy System, Tomotherapy\nInc., Madison, Wisconsin, USA), utilizing a radiotherapy 6MV linear accelera-\ntor capable of acquiring MVCT images for daily patient setup verification. The\nimaging beam, produced by the same LINAC as the therapeutic beam, had a\nnominal energy of 3.5 MV, with slice thickness ranging from 2-5 mm and a pixel\nsize of 0.75 mm.\nThe slices of each modality volume are manually categorized into three re-\ngions: head, neck, and body (see Fig. 1b). The head region comprises from the\nbeginning of the cranial cavity to the chin, while the neck region spans from"}, {"title": "2.2 kVCT-MVCT Alignment and Preprocessing", "content": "The primary goal is to create a dataset with aligned kVCT and MVCT images.\nDespite originating from the same patient and reference system (with the same\norigin point), both image volumes (kVCT and MVCT) were not pixel-aligned\nleading to increased challenges (i.e., such as the need to address alignment and\nartifact reduction simultaneously). To achieve this, image alignment was per-\nformed using the Elastix module of 3D Slicer, open source software (version\n5.6.1) [3,11].\nThe aligned kVCT and MVCT volumes undergo normalization to the range\n[-1,1]. This process involves setting the lower threshold at -1000 for air and\nupper thresholds at 2000 for kVCT artifacts and 1000 for MVCT artifacts. Ad-\nditionally, utilizing the segmentation provided by clinicians (depicted as green\nsegmentation in Fig. 1b), the image background is standardized to the value of\n-1. The result of such a preprocessing on two sample kVCT and MVCT slices\nis shown in Fig.1c."}, {"title": "2.3 Proposed Methodology", "content": "The objective is to project images acquired in the kVCT domain onto the MVCT\ndomain while removing/reducing the artifacts induced by metallic implants.\nIn what follows, with m denoting the kVCT (k) or MVCT (M) modality, we\nlet $X_m \\in \\mathbb{R}^{d \\times d}$ be a raw (r) slice with d = 512 denoting the image resolution.\nThe volume containing the n slices of a patient is $V_m \\in \\mathbb{R}^{d \\times d \\times n}$. The original\nimages undergo an alignment process (see Section 2.2), resulting in two new\nvolumes, $V_k, V_M = \\text{alignment}(V_k, V_M)$, which are aligned pixel by pixel.\nAfter this process, all the slices in a volume are preprocessed (see Section\n2.2) to obtain $X_m = \\text{preprocess}(X_m^r)$, $X_k, X_M \\in V^a$ that collectively define the\ndataset for the experiments. The summary diagram is shown in Fig.2.\nThe input to our model is a preprocessed kVCT image, $X_P$, while the ground\ntruth is the corresponding preprocessed MVCT image, $X_M$. The output of the\nmodel is the domain transferred kVCT to MVCT slice, denoted as $\\hat{X}_M \\in \\mathbb{R}^{d \\times d}$.\nNetwork architectures We propose a Metal Artifact Reduction using Domain\nTransformation Network (MAR-DTN), which closely aligns with the architec-\ntural principles of the UNet framework [22]. The UNet architecture has been\nwidely used in previous works for pixel-to-pixel image tasks. In medical imag-\ning, specifically, it has demonstrated excellent results in segmentation, denois-\ning, and MAR [22,23,25]. The detailed architectural explanation of our proposed\nmodel, named MAR-DTN, can be found in the supplementary material (Section\n1: Explanation of Proposed Model Architecture).\nOur investigation involves a comparative analysis of the performance of\nMAR-DTN against three contemporary state-of-the-art methods. The first one\nis a Conditional Generative Adversarial Network (cGAN), named pix2pix [7]."}, {"title": "3 Experimental Results", "content": "3.1 Loss function analysis\nThe impact of different loss functions, whether used individually or in combina-\ntion, is analyzed in this study. We excluded the INet network from our evaluation\nbecause its performance, as detailed in Section 3.1, is significantly lower com-\npared to the other architectures. Including INet could skew the comparative\nanalysis and potentially introduce biases, thus detracting from a fair assessment\nof the loss functions' effects on more competitive networks.\nFirst, we explore the impact of using an $L_1$ loss function with weights ($L_1^w$) on\nimages containing artifacts. Weight assignment is based on body segmentation\nprovided by clinicians (see Fig. 1b), where $w[i, j]$ is set to 0.1 outside the body\nsegment and varies within the set {1,25,50, 100} inside the segment for slices\nwith artifacts. Slices without artifacts maintain a weight of 1 throughout the\nbody segment. Since the only variable is the weight within the body segment,\nwe simplify the notation in the following sections and denote this value as w.\nTherefore, $L_1^{100}$ indicates a weight of 100 within the body segment for slices with\nartifacts.\nAdditionally, the parameters $\\beta$ and $\\alpha$ of the $C_{FFL}^{\\beta,\\alpha}$ are discretely varied in the\nset of values (0.5, 1, 1.5}. This variation allows for exploring different weightings\nand contributions of both parameters in the neural network's learning process,\nparticularly in handling images with artifacts.\n$L_1^w$ Analysis Fig. 3a and Fig. 3b show the PSNR and SSIM values obtained by\nthe networks of the study after training with $L_1^w$ loss when w $\\in$ {1,25, 50, 100}\nusing $D_{All}$.\nThe first thing to note is the limited variability of results obtained when\nmodifying the parameter w. In terms of PSNR, the results do not vary by more\nthan 3dB, while for SSIM, the results demonstrate a variance of no more than\n10%."}, {"title": "3.2 State-of-the-Art Comparison", "content": "Ts\nFurthermore, as we compare the performance of models trained on DArt,\nMAR-DTN achieves the highest performance on this dataset with the combina-\ntion of L100 + LMS-SSIM, achieving a PSNR of 27.46 dB and an SSIM of 0.69\nwhen tested on Drts. Overall, MAR-DTN performs better than all other models\nacross various loss combinations, particularly on the Dall dataset. Model pix2pix\nand custom-pix2pix show similar PSNR and SSIM values, typically around 26-27\ndB for PSNR and 0.64-0.68 for SSIM, depending on the loss function combina-\ntion used. Model custom-pix2pix slightly outperforms pix2pix in most of the\ncombinations. Model SwinIR performs reasonably well, achieving PSNR values\naround 25-26 dB and SSIM values around 0.64-0.67, depending on the loss func-\ntion combination but it is outperformed by MAR-DTN in most combinations.\nINet shows the poorest performance on DArt. We can conclude that it is not\ncapable of eliminating artifacts using the loss functions in this study, falling far\nbehind its competitors. What is achieved, however, is an increase in contrast\nbetween different bone and muscle structures. Nevertheless, it also introduces\nnew artifacts, which hinder the correct evaluation of the images. It is important\nto note that INet's initial goal is image segmentation, not image generation.\nAdditionally, INet performs better with low-resolution images, making it less\nappropriate for our dataset."}, {"title": "4 Discussion and Conclusion", "content": "In this study, we compared our proposed domain transformation methodology\nwith some state-of-the-art methods, where kVCT images serve as input and\nMVCT images as output. Our results demonstrate that a lightweight model like\nMAR-DTN can effectively reduce artifacts with the appropriate combination\nof loss functions, even with a reasonable dataset size. The performance of the\nmodels is evaluated on two datasets: DArt, which contains only images with\nartifacts, and DAll includes both artifact-affected and non-affected images.\nNumerous combinations of loss functions were tested, though only a select\nfew are presented in due to space constraints. Consequently, a deliberate"}, {"title": "3.3 Clinical evaluation", "content": "Initial feedback from clinicians indicates that the quality of the MVCT images\ngenerated through our proposed method is highly regarded. Clinicians have noted\nthat synthetic MVCT images exhibit excellent contrast for both soft tissues\nand bones, which is essential for accurate diagnosis and treatment planning in\nclinical practice. These qualitative observations suggest promising outcomes in\nterms of image quality and clinical utility, laying a strong foundation for further\nquantitative evaluation and validation studies in the future."}]}