{"title": "An Interpretable Implicit-Based Approach for Modeling Local Spatial Effects: A Case Study of Global Gross Primary Productivity Estimation", "authors": ["Siqi Du", "Hongsheng Huang", "Kaixin Shen", "Ziqi Liu", "Shengjun Tang"], "abstract": "In Earth sciences, unobserved factors exhibit non-stationary spatial distributions, causing the relationships between features and targets to display spatial heterogeneity. In geographic machine learning tasks, conventional statistical learning methods often struggle to capture spatial heterogeneity, leading to unsatisfactory prediction accuracy and unreliable interpretability. While approaches like Geographically Weighted Regression (GWR) capture local variations, they fall short of uncovering global patterns and tracking the continuous evolution of spatial heterogeneity. Motivated by this limitation, we propose a novel perspective-that is, simultaneously modeling common features across different locations alongside spatial differences using deep neural networks. The proposed method is a dual-branch neural network with an encoder-decoder structure. In the encoding stage, the method aggregates node information in a spatiotemporal conditional graph using GCN and LSTM, encoding location-specific spatiotemporal heterogeneity as an implicit conditional vector. Additionally, a self-attention-based encoder is used to extract location-invariant common features from the data. In the decoding stage, the approach employs a conditional generation strategy that predicts response variables and interpretative weights based on data features under spatiotemporal conditions. The approach is validated by predicting vegetation gross primary productivity (GPP) using global climate and land cover data from 2001 to 2020. Trained on 50 million samples and tested on 2.8 million, the proposed model achieves an RMSE of 0.836, outperforming LightGBM (1.063) and TabNet (0.944). Visualization analyses indicate that our method can reveal the distribution differences of the dominant factors of GPP across various times and locations.", "sections": [{"title": "1. Introduction", "content": "In Earth science, machine learning method like XGBoost (Chen and Guestrin, 2016) is widely used to model environmental and geographical relationships, such as predicting climate change impacts on vegetation (Lu et al., 2024) and understanding tropical cyclones' effects on precipitation (Qin et al., 2024). However, a fundamental challenge in geographical modeling is the presence of spatiotemporal heterogeneity, where relationships between independent and target variables vary across both space and time. Most machine learning methods, which assume unordered samples and stationary relationships, lack the capability to model such spatiotemporal heterogeneity. This limitation calls for novel approaches specifically designed for geographical machine learning problems that can capture these varying relationships while maintaining model accuracy and interpretability.\nOne solution is to fit, at different spatial locations, a set of weights that vary with the coordinates by locally sampling the data, with Geographically Weighted Regression (GWR) (Fotheringham et al., 2009) serving as a representative method. However, GWR lacks temporal modeling, limiting its ability to capture the evolution of spatial heterogeneity. To address GWR's temporal limitation, Geographically and Temporally Weighted Regression (GTWR) (Fotheringham et al., 2015) was developed, using spatiotemporal metrics to model variability. Despite these advancements, current methods still fit spatial weights locally,"}, {"title": "3. Method", "content": "The proposed method is built upon a multi-branch architecture with an encoder-decoder structure that jointly addresses two key objectives: extracting location invariant common features and learning location specific spatiotemporal differential conditions. In the encoding stage, one branch utilizes a dual self-attention mechanism within a tabular data encoder to capture shared, common features from data. Concurrently, another branch focuses on learning spatiotemporal differential conditions, representing location specific variations via implicit latent vectors. These latent representations are derived through a locally shared spatiotemporal condition graph and further refined using Graph Convolutional Networks (GCN) and Long Short-Term Memory (LSTM) networks.\nIn the decoding stage, a multi-branch decoder integrates the location-invariant features with the spatiotemporal conditions through cross-attention interactions. This decoder is designed under two distinct objectives: predicting the target variable and estimating feature importance weights. The architecture, divided into a target variable prediction branch and a feature importance estimation branch, ensures that predictions are made under the appropriate spatiotemporal constraints while maintaining model interpretability. Finally, all parameters are jointly optimized under both the main loss and the auxiliary loss."}, {"title": "3.1 Extraction of Location-Invariant Common Features", "content": "In our task, the extraction of location-invariant common features means learning robust representations from time series meteorological data. To achieve this, we designed a module that decomposes the feature extraction task into two complementary objectives: (1) capturing inter-feature relationships among the data attributes, and (2) extracting temporal patterns inherent in the time series of each attribute.\nTo address these objectives, we extend a transformer encoder originally developed for tabular data (Hu et al., 2024). This enhanced encoder, as illustrated in Figure 2(a), incorporates a dual attention (DA) mechanism that simultaneously operates in both feature and temporal dimensions. To further accommodate the large-scale geoscience data and reduce the computational complexity, we implement a novel linear self-attention mechanism (Katharopoulos et al., 2020). After performing linear embedding and applying temporal position encoding (Su et al., 2024) to the input meteorological data, the stacked DA modules progressively refine the representations, ultimately yielding data features that are invariant to location-specific factors.\nDual Attention Mechanism: Given an input tensor $X \\in \\mathbb{R}^{L \\times D}$, where $L$ represents the sequence length (time dimension) and $D$ is the feature dimension, the DA module sequentially computes self-attention (Katharopoulos et al., 2020) across the temporal and feature dimensions. First, temporal self-attention is applied across the time steps for each feature. Queries, keys, and values are computed as:\n$Q^{temp} = XW_Q^{temp}, K^{temp} = XW_K^{temp}, V^{temp} = XW_V^{temp}$"}, {"title": "3.2 Learning Spatiotemporal Differential Conditions", "content": "The Learning Spatiotemporal Differential Conditions subsection is dedicated to directly learning implicit condition vectors that capture the distinct spatiotemporal variations present across locations. To achieve this, each location is assigned a hidden vector representing its unique spatiotemporal condition. These vectors, together with their spatial relationships, form the Spatiotemporal Conditional Graph. By leveraging a combination of Graph Convolutional Networks (GCN) and Long Short-Term"}, {"title": "3.3 Decoder Design for Constrained Prediction", "content": "In the prediction stage, a conditional prediction approach is adopted to estimate the target variables corresponding to meteorological data under spatiotemporal conditions. The prediction can be formulated under the maximum a posteriori (MAP) framework as follows:\n$\\hat{y} = arg max_{y} p(y | c(x,y,t), t), x)$\nwhere $c(x, y, t)$ denotes a function of spatial coordinates $(x, y)$ and time $(t)$ representing the spatiotemporal condition and $X$ stands for the input data. To achieve a higher level of interpretability similar to geographically weighted regression (GWR), our design employs two independent branches: one for predicting the target variable and another for estimating the interpretable weights associated with the intarget variables.\nDecoder Structure: For the decoder, we utilize the standard Transformer decoder (Vaswani, 2017), which naturally serves as a conditional predictor. Its core component is the cross-attention mechanism. In our framework, the query $Q$ and key $K$ are embedded from the data features obtained in the Extraction of Location-Invariant Common Features, while the value $V$ is given by $V^{final}$, which aggregates the spatiotemporal conditional graph information. The cross-attention mechanism is formulated as follows:\nAttention(Q, K,V) = softmax($\\frac{QK^T}{\\sqrt{d_k}}$)V,\nwhere $d_k$ is the dimension of the key vectors."}, {"title": "4. Experiments", "content": "Dataset: To validate our approach, we created the Climate2GPP dataset. We used data from Google Earth Engine spanning January 1, 2001, to December 17, 2020. The data sources include:\nTraining Setting: Our method is implemented in PyTorch 2.1.2 with CUDA 11.8. All features, except GPP, are normalized."}, {"title": "4.2 Result Comparison", "content": "Experiment Setting: To validate the suitability of our proposed method for machine learning tasks in the Earth sciences, we conducted a comparative evaluation against a range of widely adopted machine learning baselines, including Random Forest (Breiman, 2001), XGBoost (Chen and Guestrin, 2016), CatBoost (Prokhorenkova et al., 2018), the LightGBM family (Ke et al., 2017), and KNN. Additionally, we compared our method with state-of-the-art tabular deep learning approaches, including TabNet (Arik and Pfister, 2019), ExcelFormer (Chen et al., 2024), ResNet (Gorishniy et al., 2021), and FTTransformer (Gorishniy et al., 2021). All models were trained using the complete dataset of 50 million samples to assess their scalability and performance on large-scale data. The prediction accuracy of each method was evaluated on the Climate2GPP test set for estimating the total gross primary productivity (GPP) for the year 2020, as detailed in the table (1).\nComparison: As shown in Table 1, the best-performing machine learning and deep learning methods on this task were LightGBM Large and TabNet, achieving RMSEs of 1.063 and 0.944, respectively. However, our proposed method outperformed both, achieving a lower RMSE of 0.836 and an R2 of 0.932. These results underscore the superior capability of our approach in handling large-scale Earth science data."}, {"title": "4.3 Comparison of Spatial and Spatiotemporal Heterogeneity Methods", "content": "Experiment Setting: Furthermore, we aim to compare our method with other approaches that are capable of modeling spatial or spatiotemporal heterogeneity. The computational complexity of the GWR series methods is proportional to the number of spatial locations in the dataset and require exactly one"}, {"title": "4.4 Visualization", "content": "Our visualization analysis aims to demonstrate the potential of our method in spatial analysis through three sets of results. The Figure 4 presents the temporal variation curves of explanatory variables at different spatial locations, covering six distinct climate-vegetation zones: \"Amazon Rainforest\", \"Southeast Asia Rainforest\", \"Eastern Temperate Deciduous Forest\", \"Mediterranean Region\", \"Siberian Coniferous Forest\", and \"Temperate Grassland\". The Figure 5 illustrates the spatial distribution of the explanatory weights for the temperature_2m variable at Weeks 01, 10, 20, and 30, along with the corresponding model-predicted GPP. These visualizations are designed to"}, {"title": "5. Conclusion", "content": "In this paper, we have identified key challenges in geographical machine learning, notably the difficulty of capturing spatiotemporal heterogeneity. While traditional statistical learning methods fail to model these variations, existing approaches such as the GWR family can capture spatiotemporal heterogeneity but rely on locally sampled data, which often leads to overfitting in spatial regions.\nTo address these issues, we have proposed a novel deep learning-based framework that decomposes a geographical regression task into learning location-independent data features and capturing spatiotemporal variations. Unlike conventional methods, our approach optimizes over the entire data space, significantly alleviating overfitting in local areas.\nWe validated our method on a large-scale dataset built from ERA5 and PML_V2, comprising 50 million training samples and 2.8 million test samples. The experimental results demonstrate the effectiveness of our design: our method achieved a test RMSE of 0.836, outperforming GWR (RMSE 1.937), classical tabular machine learning methods like LightGBM Large (RMSE 1.063), and other deep learning approaches such as TabNet (RMSE 0.944). These findings confirm that our proposed framework not only captures spatiotemporal heterogeneity effectively, but also delivers superior predictive performance in geographical machine learning tasks."}, {"title": "6. Discussion", "content": "While our proposed method shows promising performance, several aspects remain open for future improvement. First, regarding interpretability, our visualizations indicate that our approach holds potential for explaining complex spatiotemporal relationships. However, to accurately characterize causal effects, we plan to integrate additional causal constraints and develop methods that infer dominant factors directly from the explanatory weights. Second, the current modeling of spatial interactions relies on a simple linear mechanism using graph convolutions, where interaction patterns are predetermined and fixed. In future work, we intend to explore more sophisticated and dynamic spatial interaction models, including refined embedding techniques for spatiotemporal condition graphs and improved strategies for handling multimodal information during prediction. Lastly, our model has so far been validated only on the Climate2GPP dataset; additionally, we plan to test our method on simulated datasets and other real-world tasks to further verify its generalizability and robustness."}]}