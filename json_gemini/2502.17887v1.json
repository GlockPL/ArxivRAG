{"title": "Arrhythmia Classification from 12-Lead ECG Signals Using Convolutional and Transformer-Based Deep Learning Models", "authors": ["Andrei Apostol", "Maria Nut"], "abstract": "In Romania, cardiovascular problems are the leading cause of death, accounting for nearly one-third of annual fatalities. The severity of this situation calls for innovative diagnosis method for cardiovascular diseases. This article aims to explore efficient, light-weight and rapid methods for arrhythmia diagnosis, in resource-constrained healthcare settings. Due to the lack of Romanian public medical data, we trained our systems using international public datasets, having in mind that the ECG signals are the same regardless the patients' nationality. Within this purpose, we combined multiple datasets, usually used in the field of arrhythmias classification: PTB-XL electrocardiography dataset [41], PTB Diagnostic ECG Database [3], China 12-Lead ECG Challenge Database [24], Georgia 12-Lead ECG Challenge Database [13], and St. Petersburg INCART 12-lead Arrhythmia Database [37]. For the input data, we employed ECG signal processing methods, specifically a variant of the Pan-Tompkins algorithm, useful in arrhythmia classification because it provides a robust and efficient method for detecting QRS complexes in ECG signals. Additionally, we used machine learning techniques, widely used for the task of classification, including convolutional neural networks (1D CNNs, 2D CNNs, ResNet) and Vision Transformers (ViTs). The systems were evaluated in terms of accuracy and F1 score. We annalysed our dataset from two perspectives. First, we fed the systems with the ECG signals and the GRU-based 1D CNN model achieved the highest accuracy of 93.4% among all the tested architectures. Secondly, we transformed ECG signals into images and the CNN2D model achieved an accuracy of 92.16%.", "sections": [{"title": "1. Introduction", "content": "Arrhythmia diagnosing is one of key roles of an electrocardiogram (ECG), a better method for this task is yet to be found. The ECG is an essential instrument in cardiology for assessing a patient's heart condition. Fundamentally, the ECG is a capture of the heart muscle's electrical activity. Changes in the heart's electrical potential are detected on the body's surface using electrodes [26]. The aim of this paper is to develop a computer-aided system to help cardiologists by providing a smart, cost-effective, and time-saving diagnostic solution. To achieve this goal, traditional ECG signal processing techniques are used alongside deep learning methods.\nTraditional arrhythmia classification methods rely on manually designed features such as heart rate variability and QRS duration. Although these features can provide useful insights, they often fail to generalize across diverse patient populations due to variations in ECG morphology, noise, and recording conditions. In addition, many conventional approaches depend on segmenting individual heartbeats for classification, which can lead to the loss\nof important temporal patterns that span multiple cardiac cycles. These limitations make rule-based and feature-engineered methods less reliable, especially in real-world clinical applications where ECG signals are highly variable. Deep learning addresses these challenges by allowing automated feature extraction from unprocessed ECG data, thus removing the necessity for manual feature engineering. Neural networks, especially convolutional and recurrent structures like CNNs and LSTMs, adeptly capture the spatial and temporal dependencies present in the signal, resulting in more reliable and precise classification. Compared to traditional approaches, deep learning models offer superior generalization across diverse patients and recording environments, making them more suitable for large-scale, real-time arrhythmia detection.\nFrom 2000 to 2019, the life expectancy in Romania rose by over four years; however, in 2020, it suffered a brief decline of 1.4 years as a result of the COVID-19 pandemic. Cardiovascular diseases remain the primary cause of death, responsible for more than one-third of fatalities in 2018 [27] and over half in 2020 [28]. The healthcare system's inefficiency has brought the avoidable mortality to the third-highest in the EU [27]. This can be attributed to restricted access to healthcare services linked to income; in 2022, Romania was positioned seventh among nations encountering significant challenges in obtaining medical services by income level [10]. Considering the aspects previously discussed, there was a desire to develop a tool to aid in diagnosing patients with cardiovascular conditions, particularly asymptomatic arrhythmias or those with minimal mortality risk. Deep learning methods enhance diagnostic automation, decreasing both the time needed for interpretation and the reliance on physician involvement, thereby reducing analysis costs. Additionally, this tool can act as a foundational resource for training medical students.\nThe work of Pranav Rajpurkar [31], Tae Joon Jun [21], Zhaohan Xiong [43], and Tsai-Min Chen [5] significantly influenced the foundation of this study. Building on the ideas they formulated, we experimented with similar architectures to classify different types of arrhythmia. In the development of this work, several datasets for electrocardiograms (ECG) were used. For the purpose of optimizing the training process, these datasets were integrated into a single entity, stored as a .npy file.\nECG-based arrhythmia classification presents several challenges due to the complex and highly variable nature of ECG signals. One of the most significant difficulties is accurate QRS detection, as the shape, amplitude,"}, {"title": "2. Related work", "content": "The field of ECG signal analysis and arrhythmia classification has evolved significantly in recent years, thanks to advances in machine learning and deep learning. Numerous studies have explored various neural network architectures and preprocessing techniques to improve the accuracy of automated diagnosis.\nA key reference for this paper was the article published by Rajpurkar and Hannun [31]. In this study, the authors developed a convolutional neural network (CNN) model capable of detecting arrhythmia at a level comparable to that of cardiologists. The model was trained on a large dataset consisting of 64,121 ECG recordings, covering a duration of 30 seconds each. The neural network was designed to identify 14 different types of cardiac rhythms, including atrial fibrillation and various forms of heart block. The article presents a deep convolutional neural network architecture (CNN) for detecting cardiac arrhythmia directly from raw ECG signals. The architecture\nconsists of several convolutional and pooling layers, followed by dense layers and a softmax output layer, allowing for accurate arrhythmia classification. This comprehensive model autonomously identifies essential features, negating the necessity for manual feature extraction from ECG data. While the article showcases promising outcomes in arrhythmia detection using convolutional neural networks, subsequent implementations have faced difficulties in maintaining similar consistent performance. The F1 score for the proposed method ranges between 0.656 and 0.939, with an average of approximately 0.809.\nThe study of Isin and Ozdalilib [18] uses convolutional neural networks and is notable for employing AlexNet to extract significant features from the R-T intervals of ECG signals. These features are then dimensionally reduced using Principal Component Analysis (PCA), thereby decreasing computational load and reducing the risk of overfitting. This approach leverages deep transfer learning to avoid training networks from scratch, focusing on the automated classification of cardiac conditions such as normal rhythm, incomplete right bundle branch block (RBBB), and paced beats, achieving a test accuracy of approximately 92%.\nIn the collection of our reviewed articles, the research of Dhyani et al. [8] is noteworthy due to its implementation of the Support Vector Machine (SVM) technique for the analysis and diagnosis of cardiac arrhythmias using electrocardiograms (ECG). Their method showcased impressive accuracy in classifying nine different heartbeat types within the CPSC 2018 dataset 7000 recordings\nThe study also employed 3D Discrete Wavelet Transform (DWT) for ECG signal preprocessing, encompassing noise reduction and essential feature extraction, resulting in a powerful approach for the analysis and interpretation of complex cardiac signals, with an accuracy reported of around 98%.\nTaloba et al. [35] made notable advancements by integrating various methods for detecting and analyzing arrhythmias from ECG signals. Their research introduces a novel approach combining TERMA (Temporal Event Recognition and Model Analysis) with the fractional Fourier transform (FFT). A prominent feature of their work is the employment of a Moving Average"}, {"title": "2.1. Medical Image Classification", "content": "After achieving remarkable success in natural language tasks, Transformers have been effectively adapted to various computer vision challenges, delivering state-of-the-art performance and leading researchers to question the dominance of convolutional neural networks (CNNs) as the default choice. Building on these advancements in computer vision, the medical imaging field has also seen increasing interest in Transformers, which can capture global context more effectively than CNNs, which rely on local receptive fields [33].\nThe study conducted by Liangrui Pan et al. [30] introduces an innovative framework for classifying images, intended for detecting osteosarcoma in histological images. Osteosarcoma is a cancerous bone tumor that complicates early detection because of its intricate visual patterns in microscopic imagery. Earlier methods, like CNNs and other machine learning techniques, often struggle with noise management and capturing multiscale contextual details. To overcome these limitations, the researchers introduced a hybrid approach incorporating vision transformers (ViTs) with a Noise Reduction Convolutional Autoencoder (NRCA) and a Feature Cross Fusion Learning (FCFL) layer. These elements work together to enhance the precision and reliability of classifying tumors. The NRCA-FCFL implementation starts with noise reduction, using the NRCA to preprocess histological images by filtering out irrelevant noise. The images are then divided into patches at different scales, where separate ViTs process these patches to derive multiscale features. An evaluation conducted on a publicly available dataset for osteosarcoma [22] demonstrated an impressive accuracy of 99.17%"}, {"title": "3. Theoretical Background", "content": "The heart beats at a regular pace, between 60 to 100 beats per minute. This rhythm is known as normal sinus rhythm, having it's origin in the depolarization of the sinoatrial node. Any disruption of this rhythm is referred to as an arrhythmia, which can manifest as an isolated irregular beat, an extended pause, or a persistent irregularity throughout the patient's life [36].\n\u2022 The P wave represents the contraction of the atria, corresponding to their depolarization. Originating from the sinoatrial node in the right atrium, the depolarization starts in the right atrium and is followed by the left atrium. Consequently, the first half of the P wave symbolizes the depolarization of the left atrium, while the second half represents that of the right atrium rhythm [2] [32].\n\u2022 The QRS complex represents the contractions of both ventricles and corresponds to ventricular depolarization. A wider QRS complex may\nbe associated with a premature ventricular contraction or a ventricular rhythm[32]\n\u2022 The R wave is the tallest peak of the QRS complex, representing the electrical stimulus as it passes through the ventricles during depolarization. A reduced R wave progression has several causes, including an anteroseptal myocardial infarction, left ventricular hypertrophy, incorrect lead placement, etc. [46].\n\u2022 The T wave represents ventricular repolarization. Its morphology is highly susceptible to both cardiac and non-cardiac influences, such as hormonal imbalances, certain neurological factors, myocarditis, pericarditis, fever, infections, anemia, etc. [4].\nThis paper aims to classify five types of cardiac arrhythmia, including atrial fibrillation (AF), first-degree atrioventricular block (IAVB), sinus bradycardia (SB), normal sinus rhythm (NSR), and sinus tachycardia (STach). These classifications are essential for improving the diagnosis and management of heart conditions, thereby contributing to the prevention of severe complications associated with these types of arrhythmia.\nAtrial Fibrillation. During atrial fibrillation episodes, atrial activity is completely chaotic (as illustrated in Figure 3), and the atrioventricular node can be overwhelmed with over 500 impulses per minute! True P waves cannot be observed. Instead, the baseline appears flat or slightly wavy. The atrioventricular node, faced with this extraordinary surge of atrial impulses, allows only a few impulses to pass at variable intervals, resulting in an irregular ventricular rate, usually between 120 and 180 beats per minute [36]. The irregular aspect of the QRS complexes and the absence of distinct P waves is the key to identifying atrial fibrillation. The wavy forms that can be observed upon close inspection of the undulating baseline are called fibrillation waves [36].\nAtrial fibrillation is the most common and clinically significant sustained arrhythmia in the general population. Atrial fibrillation can cause palpitations, chest pain, shortness of breath, or dizziness. A significant number of patients, especially the elderly, may have no symptoms at all and may be unaware that they are in atrial fibrillation."}, {"title": "3.2. Pan-Tompkins Algorithm", "content": "The Pan-Tompkins algorithm[29] is widely used for QRS detection due to its efficiency in enhancing the signal-to-noise ratio and accurately identifying QRS complexes in real time, even in noisy ECG recordings. Its adaptive thresholding and differentiation techniques make it a robust choice for various physiological conditions. Recent advancements, such as the Pan-Tompkins++ algorithm [17], have further improved its performance by introducing additional filtering and adaptive thresholding methods, enhancing accuracy in noisy environments."}, {"title": "3.3. Deep learning architectures", "content": "As a subset of the deep learning algorithms, the Convolutional Neural Networks (CNN) were first used in\nimage processing tasks. Their name is inspired from Latin (convolvere = \"to roll together\") and mathematics (the convolution is an integral measurement of how two functions' shapes change as they interact). A CNN architecture is a sequence of succesive groups of:\n\u2022 convolutional layer - responsible for computing the product of two matrixes: one (the kernel) represents the set of learnable parameters of the network, the other expresses the restricted portion of the processed data. The output is a feature map, a matrix with fewer features than the original input.\n\u2022 pooling layer - extracts the dominant characteristics of the feature map (thus reducing even more the complexity of the problem), flattens the output and passes it to the a fully connected layer.\nTo the above described sequence, the backpropagation algorithm is applied and the system is trained for a certain number of epochs.\nThe Long-Short Term Memory (LSTM). The recurrent neural network receive as input not only the current state, but also part of information seen at a previous step. The Long-Short Term Memory cell (LSTM) [16] uses a three-gated mechanism in order to chose what information from the past to be used in the nest steps. The input gate selects the information to be stored for the current step, the unnecessary content is discarded by the forget gate, while the output gate will provide the activation to the final output of the LSTM cell. Figure 14 illustrates the structure of a LSTM cell."}, {"title": "Gated Recurrent Unit (GRU)", "content": "GRU was introduced by Kyunghyun Cho et al [6] in 2014 for Statistical Machine Translation. This layer can process sequential data such as text processing [49], speech synthesis [42] and time-series data [44]. As the name suggests, GRU unit uses a gating mechanism in order to control at each step the content of information to be passed to the hidden states. There are two types of gates: the reset gate - handles the amount of information from previous hidden state which should be forgotten and the update gate - handles how much from the new input should be used to update the hidden state The output of the GRU is calculated based on the updated hidden state. A GRU cell is illustrated in Figure 12."}, {"title": "Vision Transformers (ViT)", "content": "Although initially applied in machine translation, tranformers [40] achieved excellent results in the field of image classification [9]. The transformer architecture consists in a sequence-to-sequence approach enriched with an attention mechanism, which was designed to emphasize relationships between data regardless of their position in the sequence (in a past step or in a future one)."}, {"title": "Residual Networks - ResNet", "content": "are a deep learning architecture in which the layers learn residual functions with reference to the layer inputs. It was developed in 2015 by Kaiming He et al.[15] for image recognition, and won the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) of that year. Within the residual blocks, the input of the block is directly added to its output, forming a residual connection (or a skip connection), as"}, {"title": "4. Preprocessing", "content": "Extracting the QRS complexes is an important step in the analysis of ECG signals, as it is essential for diagnosing arrhythmias. To detect the QRS intervals, we implemented a function based on the Pan-Tompkins alorithm [17, 29], that applies a series of preprocessing and filtering steps to isolate the QRS complexes from the ECG signal:"}, {"title": "4.2. Converting ECGs into images", "content": "We apply 2D models on the signal images generated by the algorithm below. The chosen image size (506x187), maintains quality without compromising performance, ensuring faster training and classification, making it more suitable for use on hardware with limited capabilities. While Pan-Tompkins is generally reliable, it can produce false positives in the presence of noise or ectopic beats. In our case, the algorithm performs poorly in situations with extreme noise, and we did not implement post-processing specifically to handle these issues. If there are visible instances of abnormal noise that are clearly identifiable in the signal, the image will be excluded from the classification process to prevent inaccurate results. This helps maintain the integrity of the classification even in challenging conditions.\nTransforming 1D ECG signals into 2D images allows deep learning models to extract spatial and texture-based features that may be less apparent in raw waveforms. CNNs excel at detecting local patterns, such as wave morphology and textures, through hierarchical feature extraction using convolutional filters. Transformers, on the other hand, leverage self-attention to capture long-range dependencies and global contextual relationships within the image. This transformation enables the use of well-optimized vision architectures, improving pattern recognition and classification performance. All these steps were essential to prepare the dataset for training the 2D CNN model, ensuring consistency and quality in the input data."}, {"title": "5. Experimental setup", "content": "In the development of this work, the following datasets were used: PTB-XL electrocardiography dataset [41], PTB Diagnostic ECG Database [3], China 12-Lead ECG Challenge Database [24], Georgia 12-Lead ECG Challenge Database [13], and St. Petersburg INCART 12-lead Arrhythmia Database [37]. These datasets contain electrocardiograms in 12 leads. The selected arrhythmias include atrial fibrillation (AF), first-degree atrioventricular block (IAVB), sinus bradycardia (SB), normal sinus rhythm (NSR), and sinus tachycardia (STach).\nAll the datasets used contain .mat and .hea files recorded at a 500 Hz frequency and follow the same format. Therefore, we simply combined all the files into one location and used them without requiring data cleaning, since there were no discrepancies in the labeling standards. We selected AF, IAVB, SB, NSR, and STach because these arrhythmias are generally asymptomatic or have a minimal mortality risk, so the penalty for occasional misclassification is lower. Additionally, these classes had the most recordings available across the datasets, making them ideal for training.\nThe number of recordings varied between classes, so in order to balance the dataset, an equal number of examples from each selected arrhythmia was used, amounting to a total of 8360 recordings, with 1672 for each type of arrhythmia. The extra recordings from each class were discarded so that the number of recordings in each class was exactly the same, avoiding bias in the training process and ensured that no class was overrepresented. The dataset was split into 80% for training and validation, utilizing 10-fold cross-validation for model evaluation. The remaining 20% of the dataset was reserved for testing, ensuring an unbiased assessment of the model's performance.\nFor our experiments, we analyzed the input data from two perspectives. First, we fed the entire ECG signal into a raw 1D CNN-based architecture. Building on this foundation, we developed three additional variants of the model by incorporating the QRS complexes: a 1D CNN + GRU model, a GRU-based model, an LSTM-based model, and a GRU + LSTM hybrid model. Notably, even the GRU-based, LSTM-based, and GRU + LSTM models included a 1D CNN layer as a preliminary step. This inclusion helped accelerate model training and improve performance by enabling the model to extract key temporal features from the ECG data efficiently."}, {"title": "6. Proposed Models", "content": "In the first scenario, the proposed models employ a one-dimensional convolutional neural network (1D CNN) for ECG arrhythmia classification (Figure 10). Aiming to improve the system accuracy, we enriched the convolutional layers with different combinations of LSTM and GRU layers, resulting four more architectures described in Figures 11-14. All the systems were trained with the CategoricalCrossentropy loss function and the Adam optimizer, starting with a learning rate of 0.001, which is progressively reduced to 0.0000016. A batch size of 50 and 50 epochs are used for training. In terms of evaluation, the 10-fold cross-validation was used to ensure robust performance assessment.\nThe input data comprises 8360 ECG signals with 12 leads, divided into 1672 samples per class for each of the 5 arrhythmia classes, ensuring balanced training and evaluation, as described in Section 5. The hyperparameters and the architectures of each model are synthesised in Table 2. All the paramters were chosen based on initial tests.\nArchitectures (Trained from scratch). To classify the arrhythmia based on the image of the ECG signal, we started with the CNN architecture described previously in Table 2.\nThen, we annalysed the backbones CNN architecture in the field of image classification, ResNet [15], ViT [9] and DeepVit [48] and we trained each system from scratch for 300 epochs over our dataset. The results are described in Table 4."}, {"title": "Pretrained Backbone Architectures", "content": "Inspired by the works synthesised in [25] and [34], we started from the pretrained ViT [9], BEIT [1], DeiT [38] and we fine-tuned each system for 10 epochs over our dataset, with an early stopping mechanism of 3 epochs patience step. The results are described in Table 4."}, {"title": "7. Results and Discussions", "content": "All 12 systems were evaluated with the classification accuracy metrics, which is expressed as the ratio between the correct predicted items out of the total samples.\nGiven the medical context, we have also considered the F1 score, which is the harmonic mean of precision and recall, meaning that it penalizes extreme values of either, as a low precision combined with a high recall implies that the classifier is prone to set of false alarms.\n$F1 = 2 \\times \\frac{\\text{precision} \\times \\text{recall}}{\\text{precision} + \\text{recall}}$\nTo be more specific, according to the Ntional Library of Medicine, the precision denotes the proportion of the retrieved samples which are relevant and is calculated as the ratio between correctly classified samples and all samples assigned to that class. The recall denotes the rate of positive samples\ncorrectly classified, and is calculated as the ratio between correctly classified positive samples and all samples assigned to the positive class.\nThe results for the CNN1D architectures are illustrated in Table 3 (on validation datset) and Figure 16 (for both train and validation steps). We can notice that the GRU based architecture achieved the highest accuracy rate.\nFrom Table 4 we can conclude that the hybrid system CNN1D+GRU obtained the highest accuracy of 93.42%, along with the highest F1-score 0.9338.\nThe confusion matrices from Figure 17 show that 1st degree Atrioventricular Block (IAVB) exhibits the poorest classification performance, evidenced by numerous errors categorizing it as other types. This lower accuracy is likely due to IAVB's subtle characteristics, such as a prolonged PR interval, which can resemble normal sinus rhythms (SNR) or sinus bradycardia (SB). The significant misclassification into SB and SNR suggests that the network struggles to differentiate IAVB from these rhythms, probably due to overlapping features or a lack of training data highlighting the significance of the PR interval. Furthermore, the moderate misclassification of IAVB as AF or STach suggests more general problems with feature representation, which could be mitigated through improved feature extraction techniques.\nOur classification models can be integrated into clinical workflows by embedding them into decision-support systems that receive ECG signals and provide automated arrhythmia predictions. In a cardiologist's diagnosis pipeline, these predictions could serve as an initial screening tool, flagging abnormal rhythms for further review and aiding in triage. The cardiologist can then analyze the raw ECG data alongside the model's insights to confirm or refine the diagnosis. Additionally, these models have educational applications, helping medical students learn ECG interpretation by visualizing arrhythmia patterns, QRS complexes, and other key features, fostering a deeper understanding of electrophysiological signals."}, {"title": "7.1. Comparison with State-of-the-Art Benchmarks", "content": "When comparing our results with existing literature, we observe that many prior works achieve exceptionally high accuracy, particularly those focusing on beat classification rather than direct arrhythmia classification. Approaches such as those by Tae Joon Jun et al.[21] and Dhyani et al.[8] report accuracy values as high as 99%, but they classify individual heartbeats rather than full arrhythmia episodes. While this approach is effective, it requires an additional post-processing step to group beats into arrhythmia categories, which can introduce complexity and potential misclassification when applied in real-world clinical settings. However, studies that classify arrhythmias directly, such as those by Zhang et al.[47] and Li et al[23], of-\nten employ deep architectures like CNNs with SHAP analysis or specialized networks such as DSE-ResNet. Although these models achieve excellent accuracy, their complexity can pose challenges for real-world deployment, particularly in resource-limited medical facilities that may not have the computational infrastructure to support such models efficiently. Our results, while not surpassing the top-performing methods, demonstrate competitive performance with a lightweight approach. The best-performing model in our study, CNN1D + GRU, achieves 93.42% accuracy, which is higher than several related works that rely on simpler deep learning architectures. Similarly, our CNN2D model, trained on ECG images, achieves 92.16% accuracy, making it a strong contender in 2D-based classification."}, {"title": "8. Conclusions and Future Work", "content": "In this paper we have analysed 12 different deep convolutional neural and transformer based networks in the context of arrhythmia classification. The systems were trained on labeled pairs of ECG images/signals and the corresponding type of arrhythmia. The input data was processed within two scenarios: the exracted QRS complexes and the ECG images.\nWhile related works often achieve exceptional results by focusing on individual heartbeat classification, using inputs such as segmented beats, our approach diverges by leveraging the entire ECG signal in various ways to classify arrhythmias. This comprehensive analysis of the full ECG signal allows us to capture broader temporal and morphological patterns that may span multiple heartbeats, offering a holistic perspective. In contrast, other works primarily classify arrhythmias by identifying and analyzing each abnormal beat in isolation, which, while effective for beat-specific abnormalities, might miss the contextual information provided by the continuous signal.\nEnhancing our feature extraction and preprocessing steps could further refine classification performance, particularly in differentiating challenging arrhythmia types. Future work should focus on optimizing feature engineering while keeping computational efficiency in mind, ensuring that our approach remains lightweight and accessible for lower-income regions where high-end computational resources may not be available. By leveraging advancements in machine learning, we plan to incorporate techniques such as deep learning and feature extraction to adapt the algorithm to various signal variations and noise levels.\nIn terms of real-world applicability, our approach could be integrated\ninto wearable ECG monitoring systems for real-time arrhythmia detection. A patient fitted with a wearable device, such as a smartwatch or chest patch, would have their ECG continuously recorded and transmitted either to a local processing unit (e.g., a smartphone) or a cloud-based server. The classification model would then analyze the signal in real time, detecting potential arrhythmias. If an abnormal rhythm is identified, alerts could be sent to both the patient and their doctor, allowing for timely medical intervention."}]}