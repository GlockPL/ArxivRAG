{"title": "On Measuring Unnoticeability of Graph Adversarial Attacks: Observations, New Measure, and Applications", "authors": ["Hyeonsoo Jo", "Hyunjin Hwang", "Fanchen Bu", "Soo Yong Lee", "Chanyoung Park", "Kijung Shin"], "abstract": "Adversarial attacks are allegedly unnoticeable. Prior studies have designed attack noticeability measures on graphs, primarily using statistical tests to compare the topology of original and (possibly) attacked graphs. However, we observe two critical limitations in the existing measures. First, because the measures rely on simple rules, attackers can readily enhance their attacks to bypass them, reducing their attack \u201cnoticeability\" and, yet, maintaining their attack performance. Second, because the measures naively leverage global statistics, such as degree distributions, they may entirely overlook attacks until severe perturbations occur, letting the attacks be almost \"totally unnoticeable.\"\nTo address the limitations, we introduce HIDENSEEK, a learnable measure for graph attack noticeability. First, to mitigate the bypass problem, HIDENSEEK learns to distinguish the original and (potential) attack edges using a learnable edge scorer (LEO), which scores each edge on its likelihood of being an attack. Second, to mitigate the overlooking problem, HIDENSEEK conducts imbalance-aware aggregation of all the edge scores to obtain the final noticeability score. Using six real-world graphs, we empirically demonstrate that HIDENSEEK effectively alleviates the observed limitations, and LEO (i.e., our learnable edge scorer) outperforms eleven competitors in distinguishing attack edges under five different attack methods.\nFor an additional application, we show that LEO can boost the performance of robust GNNs by removing attack-like edges.", "sections": [{"title": "1 Introduction", "content": "Recently, graph neural networks (GNNs) have shown remarkable performance in various tasks, including node classification [8, 11, 17, 35], link prediction [1, 25, 42], and graph classification [19, 43]. However, GNNs are susceptible to adversarial attacks, which is a common issue in deep learning approaches [13, 37, 40, 48].\nAn adversarial attack generates adversarial examples intention- ally designed to induce incorrect predictions from an attacked model. Adversarial examples are supposed to be imperceptible or unnoticeable [2, 9, 18, 21]. Otherwise, defenders (who are at- tacked) would easily detect the attacks to avoid potential harm. In the image domain, adversarial examples should visually look like normal images. However, in the graph domain, whether two graphs \"look similar\" may be vague and subjective. Therefore, numerical noticeability measures are necessary to evaluate attack noticeability.\nStudying graph (topological) adversarial attacks and measur- ing their noticeability has unique challenges, primarily due to the discrete nature of graph changes, i.e., the minimal change is insert- ing/deleting an edge. There have been several attempts using a statistical test on graphs to define (un)noticeable attacks, where an attack is considered \"unnoticeable\" if the difference after the at- tack is not statistically significant. Examples include the likelihood- ratio (LR) test on degree distributions [47, 48] and the two-sample Kolmogorov-Smirnov (KS) test on degree distributions, clustering coefficient distributions, and node-level homophily scores [4, 12].\nHowever, we posit that such existing \"noticeability measures\" unrealistically assume naive defenders using a simple and rule-based measure. Hence, we raise suspicion that the existing measures may be inadequate and do not well evaluate noticeability. Intuitively, two graphs can significantly differ, even if they share the same topo- logical statistics (e.g., degree distributions or clustering coefficient"}, {"title": "2 Preliminaries and Related Work", "content": "Graphs. A graph G = (A, X) with n nodes (WLOG, assume the nodes are V = [n] = {1, 2, ..., n}) is defined by (1) its graph topol- ogy, i.e., an adjacency matrix A \u2208 {0, 1}^{nxn}, where each edge (i, j) exists if and only if A_{ij} = 1, and (2) its node features X \u2208 R^{n\u00d7k}, where each node i has a k-dimensional node feature X_{i} \u2208 R^{k}.\nGraph statistics. The set of neighbors N_{i} = {j \u2208 [n] : A_{ij} = 1} of a node i consists of the nodes adjacent to i. The degree of i, d_{i} = |N_{i}|, is the number of neighbors of i. The clustering coeffi- cient of i, c_i = (\u2211_{(j,k)\u2208(N_i)} A_{jk}) / (\\binom{d_i}{2}), measures the connectiv- ity among the neighbors of i. The node homophily [4] of i, h_{i} = CosSim(X_{i}, \u2211_{j\u2208N_i} A_{ij} X_{j}), measures the similarity between i and its neighbors, where CosSim is the cosine similarity.\nGraph adversarial attacks. For attackers, a graph adversarial at- tack [31] is a constrained optimization problem:\nProblem 1 (Graph adversarial attacks). \u2022 Given: A graph G = (A, X), a target model f_{tgt}, an attack budget \u2206, a noticeability constraint \u03b4, and an noticeability measure U;\n\u2022 Find: A perturbed graph (i.e., an attack) \u011c = (\u00c2, X);\n\u2022 to Minimize: The performance of the target model f_{tgt} on \u011c, denoted by P(\u011c; f_{tgt});\n\u2022 with Constraints: Limited perturbations ||\u00c2 \u2013 A|| + ||X-X|| \u2264 \u0394 (or \u03b3||A||_1; see below) and limited noticeability U(G|G) \u2264 \u03b4.\nFor topological attacks (i.e., X = X), the perturbation budget can be rewritten as \u2206 = \u03b3||A||_1 for a attack rate \u03b3 \u2208 (0, 1).\nAn attack has high attack performance if the performance of the target model P(\u011c; f_{tgt}) is low. Adding malicious edges or deleting crucial edges has been introduced for graph adversarial attacks on the node classification task. For example, DICE [36] connects nodes with different labels and removes the edges between same- labeled nodes. STRUCTACK [12] uses node centrality (e.g., Pagerank) or similarity (e.g., Katz) metrics, selecting nodes with the lowest centrality and connecting the node pairs with the lowest similarity. Gradient-based attacks [5, 37, 40, 47] have also been developed, including PGD ATTACK [40] and METATTACK [48], which are based on projected gradient descent and meta-learning, respectively. In addition, graph attacks through node injection [4, 32, 34] and node feature perturbation [20, 33, 41, 47, 48] have been explored.\nThis work focuses on topological attacks (i.e., X = X) due to the relative scarcity of feature attack methods and especially the limited study of their noticeability, which is our focus. However, note that our proposed measure, HIDENSEEK, is extended for the noticeability of node feature attacks, as discussed in the Appendix A.\nBesides the development of attack methods, generating unnotice- able attacks is another major challenge. In this context, we discuss perturbation budgets and noticeability measures below.\nNoticeability measures. The noticeability measure U(G|G) in Problem 1 numerically evaluates the difference between \u011c and G,"}, {"title": "3 Observations: Limitations of Existing \"Noticeability Measures\"", "content": "Intuition. What makes a good noticeability measure? Attackers use noticeability measures for self-evaluation. That is, attackers assume that defenders (i.e., who are attacked) use a specific mea- sure and check whether their attacks are unnoticeable under that measure. Hence, attackers should consider measures that defend- ers would realistically use. For defenders, on the contrary, a good measure should (1) be a strong constraint to enforce the attackers to sacrifice attack performance to reduce noticeability and (2) have high sensitivity, detecting even a small number of attack edges.\nOverview. We raise suspicion that the existing noticeability mea- sure U's inadequately imply unrealistic defenders who warrant at- tack detection with some graph statistics similarity. Accordingly, we observe two critical limitations in the existing measure U's:\nL1) Bypassable (Fig. 1): Attackers can readily, yet significantly, reduce the existing noticeability measures while largely main- taining the attack performance.\nL2) Overlooking (Fig. 2): Until severe perturbations to graph topology occur, an attack is overlooked by the existing no- ticeability measures (i.e., near-zero noticeability).\nDetails of our observations are provided in the rest of this section. General settings. Throughout this section, we use four existing measure U's: (1; DEGREEKS) KS test on degree distribution [12], (2; CLSCOEFKS) KS test on clustering coefficient distribution [12], (3; DEGREELR) LR test on degree distributions [47, 48], and (4; Ho- MOPHKS) KS test on node homophily distributions [4]. For attacks, as suggested by Mujkanovic et al. [24], we design an adaptive at- tack (refer to Def. 1 for details) and use it throughout our analysis.\nDefinition 1 (Adaptive Attack). Given a candidate budget Ac (\u2265 \u2206) and an attack method K, in addition to the inputs of Problem 1 (i.e., a graph G, an attack budget \u0394, a noticeability constraint \u03b4, and an noticeability measure U), the adaptive attack K^a (built upon K) (1) obtains Ac candidate attack edges (i.e., by using Ac as the budget instead of \u0394) using K without considering noticeability (i.e., \u03b4 = \u221e), and (2) among them, greedily adds \u0394 attack edges one by one to G to minimize U, resulting in the attacked graph \u011c_U."}, {"title": "3.1 Limitation 1: Bypassable", "content": "Hypothesis. We question whether the existing measures are read- ily bypassable. Intuitively, since they are non-adaptive and rule- based, attackers can bypass them with adaptive attacks that inten- tionally minimize the corresponding noticeability scores. We define the bypassable problem as follows:\nDefinition 2 (Bypassability). Given an unattacked graph G, an orig- inal attack graph \u011c, an adaptive attack graph \u011c_U, and a target model f_{tgt}, a noticeability measure U is bypassable if (1) the noticeability score is significantly reduced (i.e., U(\u011c_U|G) \u00ab U(\u011c|G)) and (2) the attack performance is largely maintained (i.e., the target model performance P(\u00b7 ; f_{tgt}) satisfies that P(\u011c_U; f_{tgt}) \u2248 P(\u011c; f_{tgt})).\nExperimental settings. We empirically test the bypassable prob- lem of the existing measure U's. Original attack graphs (\u011c's) are generated using K = PGD ATTACK [40] on the CORA dataset, with an attack rate \u03b3 \u2208 {4%, 8%, 12%, 16%, 20%} (recall that \u0394 = \u03b3||A||_1; see Problem 1). For each measure U and each attack rate \u03b3, we generate an adaptive attack graph \u011c_U (see Def. 1) with Ac = 4\u0394."}, {"title": "3.2 Limitation 2: Overlooking", "content": "Hypothesis. We further question whether the existing measures overlook attacks until severe perturbations to graph topology occur. Intuitively, we suspect they suffer from the overlooking problem because they naively leverage global graph statistics, which may require substantial perturbation to reach statistical significance. We define the overlooking problem as follows:\nDefinition 3 (Overlookingness). Given an unattacked graph G, an adaptive attack graph \u011c_U, and an attack rate \u03b3, the noticeability measure U is overlooking if the attack has near-zero noticeability score (i.e., U(\u011c_U|G) \u2248 0), when \u03b3 is considerably high (i.e., \u03b3 >> 0).\nExperimental settings. We empirically test the overlooking prob- lem of the existing measure U's. First, we use K = PGD ATTACK on the CORA dataset with candidate budget Ac = \u03b3_c||A||_1 with \u03b3_c = 20%, to generate attack edge candidates. As described in Def. 1, for each measure U, to generate adaptive attacks, we greedily add attack edges from the candidates, to minimize the noticeability score. To test the hypothesis, we observe the minimum attack rate \u03b3 (recall that \u0394 = \u03b3||A||_1; see Problem 1) necessary for the adaptive attack to be noticeable."}, {"title": "4 Proposed Noticeability Measure", "content": "In this section, we propose a novel noticeability measure, Hi- DENSEEK, that significantly alleviates the observed limitations."}, {"title": "4.1 HIDENSEEK", "content": "Outline. To prevent HIDENSEEK from being bypassed, we use a learnable edge scorer (LEO; see Sec. 4.2). LEO output scores indi- cating how attack-like each edge is. Unlike the existing measures, HIDENSEEK is robust to bypassing by learning to distinguish be- tween original and (potential) attack edges, instead of relying on simple rules. To address the issue of overlooking, we aggregate the scores in an imbalance-aware manner to obtain the final noticeabil- ity score. By using imbalance-aware aggregation, HIDENSEEK can notice attacks even when the attack rate is very small.\nDetailed definition. Given an unattacked graph G, an attacked graph \u011c, and a trained LEO on \u011c (see Sec. 4.2), HIDENSEEK is defined as the Area Under the Receiver Operating Characteristic Curve (AUROC) of the edge scores output by LEO as (soft) predictions. Specifically, let E_0 = {(u,v)|A_{uv} = 1 or \u00c2_{uv} = 1} be the union of edge sets in G and \u011c. Then, we (1) sort the pairs in E_0 w.r.t. their edge scores in descending order, (2) add the pairs one by one and records the true-positive and false-positive rates, forming a curve, and (3) compute the area under the curve (see Appendix B for more details). Since AUROC is based on rankings (instead of absolute values) and uses normalized values (true-positive and false-positive rates), it is robust to class imbalance, e.g., with a low attack rate.\nThe more accurately LEO distinguishes the original edges in G and the attack edges (in \u011c but not in G), the higher the AUROC value is, and the more noticeable the attack is considered to be. This process is illustrated in Fig. 3 and detailed in Algorithm 1 in Appendix B."}, {"title": "4.2 LEO: Learnable Edge Scorer", "content": "As discussed, we use LEO to obtain edge scores, which are then aggregated to produce the final HIDENSEEK scores. Below, we present how we design LEO and how it is trained in a self- supervised manner without knowing the original unattacked graph.\nStructure. The input of LEO is an attacked graph \u011c, and the output is an edge score f ((u, v); \u011c) for each node pair (u, v) indicating how likely (u, v) is an edge in the original graph. Since LEO is trained on the attacked graph, we use an ensemble model with three modules to enhance its robustness. Each ensemble module uses information from a different perspective. The first module M_G is a vanilla Graph"}, {"title": "4.3 Extension to Node-Feature Attacks", "content": "While we have focused on topological attacks, HIDENSEEK can be applied to node-feature attacks. In Appendix A, we introduce a learnable feature scorer (LFO), an extension of LEO designed for node-feature attacks, and use it to measure the noticeability score on RWCS [20] and METATTACK [48]. See Appendix A for details."}, {"title": "5 Empirical Justification", "content": "In this section, we evaluate HIDENSEEK to answer the Q1-Q3:\nQ1. Justification of LEO: Does LEO accurately distinguish at- tack edges, compared to baselines?\nQ2. Effectiveness of HIDENSEEK: Does HIDENSEEK overcome limitations suffered by existing measures?\nQ3. Additional Application: Can abnormal edge scores ob- tained from LEO enhance the performance of various GNNs?"}, {"title": "5.2 Q1. Justification of LEO", "content": "Recall that HIDENSEEK uses the edge scores output by LEO to compute attack noticeability. We shall show that LEO is effective in detecting attack edges, supporting the reliability of HIDENSEEK.\nCompetitors. We compare LEO with various competitors that as- sign scores to edges: (a) two node proximity-based methods (SVD, COSINE SIM.), (b) three logistic regression-based methods that uti- lizes the properties used in existing noticeability measure (DEGREE MODEL, CLUSTERING COEFF. MODEL, and HOMOPHILY MODEL), and (c) six GCN-based methods (GCN [17], GCNSVD [6], RGCN [46], MEDIANGCN [3], GNNGUARD [44], and METAGC [14]). See Online Appendix E.2 [15] for more details.\nEvaluation. For all the models, AUROC is used for performance evaluation, where a higher AUROC score indicates better classifica- tion of attack edges from real edges. For each setting, we report the mean and standard deviation, computed over five trials. For each attack method and each model, we also report the average rank (AR) over all datasets. See Appendix B for more details.\nResults. In Table 1, we present the noticeability scores obtained from all twelve edge-scoring methods (LEO and eleven baselines). First of all, LEO performs the best overall in distinguishing attack edges, achieving the best average rank (1.0 to 2.8) for each attack method, among all twelve methods. Additional experiment results with different attack rates can be found in Online Appendix F.2 [15].\nAblation studies. We further examine how much each module contributes to the performance of LEO. We compare 8 variants of LEO, each consisting of a different combination of the three modules used in LEO (MG, Ms, and Mp). In summary, the results indicate that each module of LEO positively contributes to performance improvements. The detailed results are in Online Appendix F.1 [15]."}, {"title": "5.3 Q2 & Q3. Effectiveness of HIDENSEEK", "content": "We show that HIDENSEEK is non-bypassable and sensitive (Prop- erties 1 & 2) to underscore its efficacy as a noticeability measure.\nExperiment design. For each dataset and each noticeability mea- sure U, we consider two versions of PGD ATTACK: (1) original: we generate \u0394 = 0.1||A||_1 attack edges using PGD ATTACK and add them to the original (unattacked) graph one by one in random or- der, and (2) adaptive: the same attack edges are added one by one greedily to minimize the noticeability score w.r.t. U (as described in Def. 1). In Table 3, for original (sky blue curves) and adaptive (dark blue curves) attacks, we present the trade-off curves be- tween the node classification accuracy and the noticeability scores (w.r.t. each measure) as attack edges are added one by one (from 0 to 0.1||A||_1). The node classification accuracy is evaluated using a GCN model trained on the original graph G without attack.\nCompetitors. We compare HIDENSEEK with four measures: DE- GREEKS, CLSCOEFKS, DEGREELR, and HOMOPHKS (see Sec. 2).\nEvaluation. To analyze measures in terms of non-bypassability (Property 1), we propose a metric called bypassable rate. Roughly speaking, the bypassable rate is the expected reduction in noticeabil- ity with the same attack performance. Specifically, it is defined as  $\\frac{\\text{dark-blue area}}{\\text{sky-blue area}}$ (see Table 3). To analyze the measures in terms of sensitivity (Property 2), we marked the noticeability measure of"}, {"title": "6 Further Applications", "content": "In this section, we show additional applications of LEO to en- hance the performance of GNNs on downstream tasks, e.g., node classification. Based on the edge scores output by LEO, we can re- move suspicious (i.e., attack-like) edges with low scores. Compared to training GNNs on attacked graphs as they are, training on graphs after removing suspicious edges is supposed to perform better.\nExperiment design. We consider the node classification task which is widely considered to evaluate the performance of GNNs [22, 39]. We use three different GNN models, including robust GNNs: GCN [17], RGCN [46], and MEDIANGCN [3]. Given an attacked graph \u011c, we train LEO on \u011c, obtain the edge scores of all the edges in \u011c, and remove the suspicious edges with the lowest scores to obtain \u011c_{LEO}. We compare the performance of the aforementioned GNN models when trained on \u011c and when trained on G_{LEO}. For LEO and all the competitors (to be introduced later), we consistently use attack rate \u03b3 = 10% and remove the same number of suspicious edges.\nCompetitors. We compare LEO with four competitors that be used to identify suspicious edges: SVD Filtering [6], Jaccard Filtering [37], GNNGuard Filtering [44], and MetaGC Filtering [14]. For their details, see Online Appendix E.3 [15].\nResults. As shown in Fig. 5, LEO consistently improves the perfor- mance of not only vanilla GCN but also robust GNNs (RGCN and"}, {"title": "7 Conclusion", "content": "In this work, we revisit the problem of measuring the unnotice- ability of graph adversarial attacks. We observe two critical limita- tions of the existing unnoticeability measures: they are bypassable (Fig. 1) and overlooking (Fig. 2). We propose a novel noticeability measure, HIDENSEEK, that is less bypassable and less overlooking, by adopting LEO (learnable edge scorer) and imbalance-aware ag- gregation, respectively. Specifically, HIDENSEEK is 0.38\u00d7 to 5.75\u00d7 less bypassable than the strongest baseline and returns considerable noticeability scores even with a small attack rate (Tab. 3). In addi- tion, LEO outperforms eleven competitors in detecting attack edges in 23 out of 28 cases across five different attack methods (Tab. 1), and consistently boosts the performance of GNNs (including those known for their robustness) by removing attack-like edges (Fig. 5).\nAcknowledgements. This work was partly supported by the Na- tional Research Foundation of Korea (NRF) grant funded by the Korea government (MSIT) (No. RS-2024-00406985) (50%). This work was partly supported by Institute of Information & Communica- tions Technology Planning & Evaluation (IITP) grant funded by the Korea government (MSIT) (No. 2022-0-00871 / RS-2022-II220871, Development of AI Autonomy and Knowledge Enhancement for AI Agent Collaboration, 40%) (No. RS-2019-II190075, Artificial In- telligence Graduate School Program (KAIST), 10%)."}, {"title": "A HIDENSEEK on Node-Feature Attacks", "content": "In the main paper, we focus on topological attacks and propose a novel measure HIDENSEEK (see Sec. 4). In this section, we shall show that HIDENSEEK can be easily extended to a noticeability measure on node-feature attacks.\nNode-feature attack methods. There are several methods de- signed to perform attacks on the node features [20, 33, 41, 47, 48]. Although these methods significantly degrade GNN performance, most of these methods either do not consider the noticeability of attacked node features, or apply a simple L1 or L2 norm constraint on the difference between the original features and the attacked fea- tures. To our best knowledge, the only exception is a co-occurrence- based feature score [47], which we will use as a competitor below (see Sec. A.2). Moreover, despite the fact that many real-world datasets [27, 29] use binary node features (e.g., bag-of-words), some methods [20, 33, 41] perturb the features with continuous values, which makes the attacks blatant and easily distinguishable."}, {"title": "A.1 LFO: Learnable Feature Scorer", "content": "Like LEO (learnable edge scorer) designed for topological attacks (see Sec. 4.1), to measure the noticeability of attacked node features, a learnable feature scorer (LFO) can be employed in HIDENSEEK to identify suspicious features. Below, we present how we design the LFO and how it is trained in a self-supervised manner without knowing the original unattacked features.\nStructure. Recall that X \u2208 R^{n\u00d7k} denotes node features, where each node v \u2208 [n] has a k-dimensional node feature X_v \u2208 R^k. The input of LFO is an attacked graph \u011c, and the output is a feature score f((v, i); X) for each node v \u2208 [n] and each feature (index) i \u2208 [k], which indicates how likely each X_{vi} \u2208 R is an unattacked node feature (element). For the results here, we use an autoencoder as the backbone of LFO. Note that any model that can output feature scores can be used as the backbone. The autoencoder is designed to take the attacked node features X as input and output a matrix X' of the same size, where each element X'_{vi} represents the score for the corresponding feature X_{vi}.\nTraining. Since LFO is trained on (potentially) attacked features, i.e., LFO does not assume to know whether the given feature is attacked or not, we determine the feature labels for training LFO in a self-supervised manner. As in Sec. 4.2, given attacked node features X, the positive samples are T_p = {(v, i)|X_{vi} \u2260 0}, and the negative samples T_n are randomly sampled from {(v, i)|X_{vi} = 0}. The number of negative samples is a hyperparameter. Furthermore, to train LFO, a similar loss function is used as the one used to train LEO (see Sec. 4.2). That is, the loss function for training LFO is based on the cross-entropy loss and adaptive filtering."}, {"title": "A.2 Experiments", "content": "Datasets. To generate attacked node features, we employ two node feature attack methods, RWCS [20] and METATTACK [48], on CORA. We obtain attacked features with different attack rates (4%, 8%, 12%, and 16%). All results are averaged over five trials.\nCompetitor. We compare LFO with a co-occurrence-based fea- ture score [47], denoted by Co-OCCUR. In Co-OCCUR, a probabilis- tic random walker is employed on the co-occurrence graph C = (V(X), E(X)) of the node features X \u2208 R^{n\u00d7k}, where the node"}, {"title": "B Algorithmic Details of HIDENSEEK", "content": "The key algorithmic step in HIDENSEEK is the computation of AUROC scores. Below, we shall describe the details.\nGiven an original graph G and an attacked graph \u011c, let E = {(u,v) | A_{uv} = 1} denote the edge set in the original graph, let \u00ca = {(u,v) | \u00c2_{uv} = 1} denote the edge set in the attacked graph, and let E_0 = E \u222a \u00ca denote the union of edge sets in the original graph and the attacked graph. For scores on E_0, i.e., f(e; \u011c) for e \u2208 E_0, we compute the AUROC score AUROC(E_0, E, f) w.r.t. f = f(e;\u011c)'s as follows:"}, {"title": "C Additional Analysis on HIDENSEEK", "content": "C.1 Analysis on the Bypassability and Overlookingness of HIDENSEEK\nWe provide the analysis on HIDENSEEK regarding the properties of bypassability and overlookingness (supplementing Sec. 3.1 and Sec. 3.2). Fig. 6(a) shows that HIDENSEEK is very sensitive, noticing the change immediately and increasing the attack rate rapidly, while the existing measures fail to do so (c.f. Fig. 2). Fig. 6(b) shows that HIDENSEEK is less bypassable than the existing measures; recall that the existing noticeability measures reduce at least 64%, and some even reduce near 100% (c.f. Fig. 1). Below, we shall provide more analysis regarding the bypassability of HIDENSEEK."}, {"title": "D Complexity Analysis", "content": "We provide the time and space complexity of each noticeability measure shown in Table 5.\nConsider an original graph G and an attacked graph \u011c, each with their corresponding adjacency matrix. Let n represent the number of nodes in both G and \u011c, and let m and m represent the number of edges in G and \u011c, respectively. Let k denote the dimension of the raw node features. Additionally, we assume that the attacked graph \u011c is also stored in the form of an adjacency list, which contains the list of the neighbors of each node. For the analysis, we assume that LEO consists of l layers of GCN, where the hidden dimension of each layer is O(k)."}, {"title": "D.1 Time Complexity", "content": "The process of calculating HIDENSEEK includes inferring scores for m edges in \u011c using LEO and calculate AUROC with label consist- ing of m real edges in G labeled as 1 and m-m attack edges existing in G labeled as 0. The time complexity of inferring scores for m edges in \u011c using LEO is dominated by the forward pass of the GCN [38] (O(lk(m + nk))) and the bilinear operation (O(k\u00b2m)). Specifically, the time complexity of training LEO is equivalent to multiplying the inference complexity by the number of training iterations, which is a constant, so the time complexity remains O(k((l + k)m + lkn)).\nThe time complexity of calculating AUROC is dominated by sorting scores of m edges, which is O(m log m). Therefore, the total time complexity is O(m log m + k((l + k)m + lkn))."}, {"title": "D.2 Space Complexity", "content": "The space complexity of HIDENSEEK depends on the training pa- rameters of LEO. Specifically, the Graph Structure Learning (GSL) module within LEO is the most dominant factor, as most GSL meth- ods typically require high space complexity [45]. To alleviate this, we use a GSL method that constructs a k-nearest neighbor (kNN) graph based on node embeddings, as described in [7]. The space complexity of this GSL method is O(lk(n + k)) (where l is the number of layers), which is comparable to the space complexity of the GCN. For the other parts, the space complexity involves storing G, \u011c, and node features, which is O(n + m + m). Therefore, the total space complexity is O(lk(n + k) + m + m)."}]}