{"title": "Low-Resolution Face Recognition via Adaptable Instance-Relation Distillation", "authors": ["Ruixin Shi", "Weijia Guo", "Shiming Ge"], "abstract": "Low-resolution face recognition is a challenging task due to the missing of informative details. Recent approaches based on knowledge distillation have proven that high-resolution clues can well guide low-resolution face recognition via proper knowledge transfer. However, due to the distribution difference between training and testing faces, the learned models often suffer from poor adaptability. To address that, we split the knowledge transfer process into distillation and adaptation steps, and propose an adaptable instance-relation distillation approach to facilitate low-resolution face recognition. In the approach, the student distills knowledge from high-resolution teacher in both instance level and relation level, providing sufficient cross-resolution knowledge transfer. Then, the learned student can be adaptable to recognize low-resolution faces with adaptive batch normalization in inference. In this manner, the capability of recovering missing details of familiar low-resolution faces can be effectively enhanced, leading to a better knowledge transfer. Extensive experiments on low-resolution face recognition clearly demonstrate the effectiveness and adaptability of our approach.", "sections": [{"title": "I. INTRODUCTION", "content": "Low-resolution face recognition plays a vital role in many practical applications, such as verifying face pairs in video surveillance and classifying face identities in automatic driving. Although, deep models have proven success in face recognition applications [1] on public benchmark [2], accuracy would decrease when directly applying them to recognize low-resolution ones in practical scenarios. On the one hand, there is a resolution gap challenge: low-resolution faces contain much fewer informative details and recognizable-related discriminative features. On the other hand, there is a data gap challenge: the distribution difference between the well-organized training faces and testing low-resolution ones cannot be neglected in the open-set settings. Another intuitive way is to train a new model on massive low-resolution faces from scratch, which is very time and labor-consuming. Consequently, fully leveraging pre-trained off-the-shelf deep models to facilitate low-resolution face recognition tasks is an effective yet economical solution, which can be divided into two types. The hallucination-based methods [3], [4] aim to reconstruct high-resolution faces before recognizing them. However, these methods impose non-ignorable computational burden. In contrast, the embedding-based methods [5]\u2013[7] directly recognize low-resolution faces leveraging transferred knowledge. The knowledge here can be grouped into two levels. Instance-level knowledge transfer draws teacher and student representation space closer in a sample-to-sample way [8]. However, this transferring may be limited and insufficient, which cannot preserve inter-sample relations well. Relation-level knowledge transfer attempts to transfer structural relations between samples [9], where relation matters a lot in recognition tasks [10]. In this way, high-order knowledge can be mined and transferred. Also, contrastive learning has been introduced to gain better performance [11], [12]. Such distillation-based methods can well guide low-resolution face recognition via proper knowledge transfer of high-resolution clues [13]. However, due to the difference of data distribution between training and testing faces, the learned models often suffer from poor adaptability. Moreover, the gap issues mentioned above are still not well addressed.\nTo address that, we split the knowledge transfer process into distillation and adaptation steps, and propose an adaptable instance-relation distillation (AIRD) approach to facilitate low-resolution face recognition, as shown in Fig. 1. The teacher contains rich knowledge of high-resolution faces, while the student learns to generate discriminative features without losing accuracy and preserve the network performance. Our method first performs instance-relation distillation in a teach-student learning manner, which aims to reduce the large resolution gap by making the student mimic the behaviors of a well-trained teacher in the representation space, providing sufficient cross-resolution knowledge transfer. To do so, we propose instance-level distillation module (IID) which distills well-constructed decoupled smooth probability constraints between the predictions point-to-point, and relation-level distillation module (RID) which distills contrastive relational structure knowledge between the teacher and student representation space. By combining them, our approach not only can align the embedding space of student and teacher well, but also can maximize the inter-class discriminative ability and the intra-class compactness for low-resolution face recognition. Our instance-relation distillation applies a similar concept with CRCD [12] and DKD [8], but has two main differences: i) The motivation is different. Our method is designed for cross-resolution knowledge transfer in low-resolution face recognition task. In addition to distilling a large network into a smaller one, we need to maximize the inter-class distance while minimizing the intra-class distance, considering low-resolution faces contain much fewer recognizable-related details, as shown in Fig 2; ii) The distillation algorithm is very different. Unlike CRCD [12] which transfers relation knowledge from the same domain without considering sample difference and DKD [8] which transfers knowledge point-to-point, our method focuses on the harder low-resolution samples by pre-selecting positive and negative pairs offline, leveraging the idea of hard example mining because low-resolution faces always have small inter- and intra-class distance. Also, a more specific facial classifier replaces the original softmax layer.\nWhile the student model has learned enough knowledge to close the resolution gap, it can still be improved when recognizing faces in unknown environments since the datasets' distribution can be quite different. In light of this, we propose an inference adaptation method to improve transfer ability of the learned model in recognizing real-world low-resolution faces by introducing an online domain adaptive batch normalization (FaceBN) technique. Adaptive batch normalization is often used for effective test-time adaptation by updating the parameters of batch normalization layers with testing data. Practical face recognition task like surveillance face searching needs to extract features from a set of low-resolution gallery faces to match a probe face, where FaceBN is a suitable and effective solution because data distribution is inconsistent between faces captured in surveillance and those used for training. It narrows the non-negligible data gap between a well-organized low-resolution training faces and testing faces by replacing the statistics in batch normalization layers across the student network to more closely match the actual distribution of testing faces without any additional parameters or components. In this way, the learned student can be adaptable to recognize testing low-resolution faces effectively.\nOur major contributions are as follows: 1) we propose an adaptable instance-relation distillation approach to facilitate low-resolution face recognition by combining instance-level distillation and relation-level distillation, 2) we propose an inference adaptation method to improve transfer ability of the learned model in recognizing real-world low-resolution faces, and 3) we conduct experimental evaluations to demonstrate that our proposed approach achieves state-of-the-art performance in low-resolution face recognition."}, {"title": "II. RELATED WORK", "content": "Previous studies have illustrated that directly applying off-the-shelf deep models trained on public high-resolution datasets to recognize low-resolution ones is flawed. Consequently, fully leveraging the prior knowledge of pre-trained high-resolution face recognition models to facilitate low-resolution face recognition tasks is a reasonable solution, which can be divided into two categories. The hallucination-based methods reconstruct high-resolution faces from low-resolution ones before recognizing them [3], [14]. However, hallucination methods increase computational complexity and impose a computational burden.\nIn contrast, the embedding-based methods directly recognize low-resolution faces based on the knowledge transferred from pre-trained high-resolution face recognition models. Zangeneh et al. [15] proposed a new coupled mapping method consisting of two DCNN branches for mapping high and low-resolution faces to non-linear transformed public space. Zha et al. [6] proposed an end-to-end transferable coupling network in high-resolution and low-resolution domains respectively. In addition, knowledge distillation is a teacher-student learning framework, which has been proven effective for facilitating visual applications. On the one hand, the instance-level knowledge transfer aims to draw the representation space of teacher and student model closer by reducing the distance of individual samples' output. [8], [16]\u2013[18] aim to directly imitate the neural response of the last output layer of the teacher model. While [19]\u2013[21] mimic the intermediate representations of teacher model to improve the learning of student model by matching original or transformed features. The second one is relation-level knowledge transfer which attempts to transfer structural relations between samples of outputs rather than individual outputs themselves [9], [12], [22]\u2013[24]. Tung et al. [22] used pairwise activation similarities in each input mini-batch to supervise the student learning, and Park et al. [9] proposed to transfer explicit sample relations from pretrained teacher. Besides, contrastive learning has been introduced to mine more complex high-dimensional relations [12]. From these works, we find transferring the knowledge from high-resolution to low-resolution models is helpful and can avoid the computationally-intensive face reconstruction."}, {"title": "B. Adaptive Batch Normalization", "content": "Adaptive batch normalization has been extensively re-searched to enhance model generalization, which is often used for effective test-time adaptation by updating the parameters of batch normalization layers with test data. Batch normalization is a typical method used to mitigate the negative impact of domain gap, which can scale and shift the value of network activations during training and is fixed in the inference phase. But data distributions can be quite different, and those statistics are always inconsistent with testing dataset domain. [25] propose adaptive batch normalization to increase the generalization ability of a deep neural networks. By modulating the statistics from the source domain to the target domain in all batch normalization layers across the network. [26] presents a solution to the task of unsupervised domain adaptation of a given pre-trained semantic segmentation model without relying on any source domain representations. [27] has shown to be effective at tackling distribution shifts between training and testing data by adapting a given model on test samples."}, {"title": "III. PROPOSED APPROACH", "content": null}, {"title": "A. Problem Formulation", "content": "Our objective is learning an adaptable student model \\(\\phi_s(x; w_s)\\) with parameters \\(w_s\\) that can provide discriminative-enhanced representations for recognizing low-resolution faces \\(x\\) in the inference. Let \\(\\mathbb{I}\\mathbb{D} = \\{(x_i, X_i, y_i)\\}_{i=1}^N\\), denotes the training dataset, where \\(x_i\\) denotes the i-th labeled high-resolution face with the identity of \\(y_i\\) and \\(X_i\\) is the corresponding down-sampled low-resolution one. Note that the data distribution of training and testing low-resolution faces is different.The complex teacher model \\(\\phi_t(x; w_t)\\) with parameters \\(w_t\\) is in the form \\(\\phi_t = (F_t,C_t)\\), where \\(F_t\\) is a feature extraction backbone and \\(C_t\\) is a classification layer. The compact student model has the same architecture \\(\\phi_s = (F_s, C_s)\\). We denote \\(f_t\\) and \\(f_s\\) as extracted features, and \\(p_t\\) and \\(p_s\\) as the model predictions."}, {"title": "B. Instance-Relation Distillation", "content": "First, we perform an instance-relation distillation in learning \\(\\phi_s\\). \\(\\phi_s\\) aims to close the resolution gap to approximate teacher network's ability with minimal accuracy loss, ideally having:\n\\(\\phi_t(x; w_t) = \\phi_s(x; w_s).\\)\n(1)\nThe \"equivalence\" in some metrics, e.g., similarity of representations or consistence of output. To solve it, we propose instance-level distillation module (IID) and relation-level distillation module (RID). By combining them, our approach can provide sufficient cross-resolution knowledge transfer, as shown in Fig. 2.\nRID aims to transfer cross-resolution contrastive relational structure knowledge. As in [10], relation matters a lot in recognition tasks, because it is important for improving the discriminative ability of feature embedding. We formulate a new cross-resolution student relation \\(r_{t,s}\\) as relation between each \\(x\\) and the rest \\(x\\) except its corresponding one, which can pay more attention to the complex higher-order inter-sample dependency. And the relation in the teacher space is denoted as \\(r_t\\). To model relation between features, we denote \\(R_t\\) and \\(R_{t,s}\\) as relation extraction networks including a linear transformation layer and a ReLU function, which can capture the complex deep representations and high-dimensional knowledge. Here,\n\\(r_t = R_t(f_t(x_i), f_t(x_j)),\\)\n\\(r_{t,s} = R_{t,s}(f_t(x_i), f_t(x_j)).\\)\n(2)\nInspired by contrastive learning [11], we use \\(r_t\\) as supervision to distill \\(r_{t,s}\\) by maximizing the mutual information for contrastive objective:\n\\(I (r_t, r_{t,s}) = E_{P(r_t, r_{t,s})} \\log \\frac{P(r_t, r_{t,s})}{P (r_t) P (r_{t,s})}.\\)\n(3)\nHere, \\(P (r_t, r_{t,s})\\) and \\(P (r_t), P (r_{t,s})\\) are the conditional joint distribution and marginal distribution.\nConsidering low-resolution faces always have small inter- and intra-class distance, we focus more on the harder samples, leveraging the idea of hard example mining [28], given the specificity of the low-resolution face recognition tasks.In a mini-batch, we select positive and negative pairs offline in advance. The positive pairs consist of two samples with the same identity, and are sorted by the similarity scores. After embedding face pairs into a high-dimensional feature space by \\(\\phi_t\\), the similarity of a positive pair can be obtained by \\(< \\phi_t(X_i, X_j) >\\). The negative pairs with different identities are selected via hard negative mining, which are selected with the largest similarities obtained by \\(< \\phi_t(x_i, x_k) >\\), where \\(x_i, x_k\\) are from different identities. Once the similarities of positive and negative pairs are constructed, the corresponding distributions can be estimated.\nTo obtain a solvable loss, we maximize the mutual information by maximizing the log likelihood similarly as NCE [29], which is equivalent to minimizing the loss function:\n\\(L_{RID} = - \\sum_{q(k=1)} log h (r_t, r_{t,s}) \\)\n\\(- \\eta \\sum_{q(k=0)} log [1-h (r_t, r_{t,s})],\\)\n(4)\nwhere \\(q(k = 1)\\) acts as positive pairs, while \\(q(k = 0)\\) acts as negative pairs. The function \\(h\\) can be any family of functions that satisfy \\(h: \\{r_t, r_{t,s}\\} \\rightarrow [0,1]\\).\nIID aims to transfer well-constructed decoupled smooth probability constraints between the predictions point-to-point. Instead of using conventional soft-target distilling methods, which are not well-designed for this task, we introduce a decoupled logits-based method to explicitly emphasizes predictions of each \\(y\\) as in [8]. It reformulates the predictions into two parts: one is target class related which transfers the difficulty of training samples, and the other is non-target class related which contains important dark knowledge. We define \\(p = [p_1, p_2, ..., p_{tar},..., p_c] \\in \\mathbb{R}^{1\\times c}\\), where \\(p_i\\) is the probability of the i-th class. \\(p_{tar}\\) is the probabilities of the target class and \\(p_{\\bar{tar}}\\) are all the other probabilities of non-target classes, which can be calculated by:\n\\(p_{tar} = \\frac{exp (p_{tar})}{\\sum_{j=1}^C exp (p_j)}, p_{\\bar{tar}} = \\frac{\\sum_{k=1, k \\neq tar}^C exp (p_k)}{\\sum_{j=1}^C exp (p_j)}\\)\n(5)"}, {"title": "C. Inference Adaptation", "content": "While the student model has learn enough knowledge to close the resolution gap between high-resolution faces and their corresponding down-scaled ones, it can still be improved when recognizing faces in unknown environment. Next, we conducts inference adaptation, which aims to improve the transfer ability of the learned student by adapting it to the testing faces. We denote \\(p_{dl}(x)\\) and \\(p_{rl}(x)\\) as the data distribution of low-resolution faces during training and inferring. The key is to eliminate the data distribution discrepancy between training and testing faces. By performing normalization to \\(p_{dl}\\), the covariant shift can be removed, ideally having:\n\\(\\frac{p_{dl}(x) - E_{dl}(x)}{\\sqrt{V_{dl}(x)}} \\approx \\frac{p_{rl}(x) - E_{rl}(x)}{\\sqrt{V_{rl}(x)}},\\)\n(8)\nwhere \\(E_{dl}\\) and \\(V_{dl}\\) represent the expectation and variance in the training data, and \\(E_{rl}\\) and \\(V_{rl}\\) represent the expectation and variance in the testing data.\nTo achieve this, we introduce FaceBN, an online domain adaptive batch normalization technique, into the distilled student model. It replaces the parameters in all batch normalization layers across the student with the mixture of re-estimated statistics of testing faces over batches and the original statistics obtained during training without any additional components. The recalculate mean and variance are:\n\\(\\mu_{\\beta}^{rl} = \\gamma \\cdot \\mu_{\\beta}^{dl} + (1 - \\gamma) \\cdot \\frac{1}{M} \\sum_{i=1}^M X_i,\\)\n\\((\\sigma_{\\beta}^{rl})^2 = \\gamma \\cdot ((\\sigma_{\\beta}^{dl})^2 + (1 - \\gamma) \\cdot (\\frac{1}{M} \\sum_{i=1}^M (X_i - \\mu_{\\beta})^2),\\)\n(9)\nwhere \\(\\mu_{\\beta}^{dl}\\) and \\((\\sigma_{\\beta}^{dl})^2\\) denote the mean and variance value, \\(M\\) is mini-batch size, and \\(\\gamma\\) is the momentum parameter which is set to 0.1."}, {"title": "IV. EXPERIMENTS", "content": "To verify the effectiveness and adaptability of our approach AIRD on low-resolution face recognition, we conduct experiments on both verification and identification tasks. We use high-resolution CASIA-WebFace [30] and its downsampled version as training dataset. Then we evaluate the recognition accuracy on LFW [2], Age-DB [31] and UCCS [32]. CASIA-WebFace [30] is a large-scale dataset for face recognition containing 10,575 subjects and 494,414 images, which was built using a semi-automatic approach collecting face images from the Internet. LFW [2] contains 13,233 faces of 5,749 identities. We follow the same protocol to preprocess them and 6,000 pairs (including 3,000 positive and 3,000 negative pairs) are selected to evaluate the face verification performance of the recognition models. Age-DB [31] contains 16,488 collected faces of 568 distinct subjects annotated with year, noise-free labels. Also, 6,000 pairs are selected. UCCS [32] contains 16,149 faces in 1,732 subjects, which is collected in real surveillance scenarios and is a benchmark for challenging face recognition in unconstrained scenario. These faces are resized according to the student and teacher model input size accordingly.\nFace verification task confirms whether two faces belong to the same person using a 1:1 comparison. We extract features of each input pair and the accuracy is determined using constructed probe and gallery set pairs following the LFW protocol by calculating the cosine similarity with a pre-set threshold. Face identification attempts to identify the face by comparing it to gallery faces through a 1:N comparison. In the experiment, the backbone network are fixed and the final layer are fine-tuned accordingly. We compare the proposed approach following the standard top-K error metric.\nIn the experiments, we take the pretrained ArcFace [1] as the teacher which uses ResNet50 with a 112\u00d7112 input resolution. And ResNet18, a smaller model, as the student. Following previous work, we apply bicubic interpolation to obtain low-resolution faces with three resolutions of 16\u00d716, 32\u00d732 and 64\u00d764. The batch size is set as 96, and the learning rate is initialized as 0.05 and multiplied by 0.1 when the epoch is equal to 21, 28 and 32. All the experiments are implemented by PyTorch on a TITAN XP GPU."}, {"title": "A. Results on Face Verification", "content": "We consider two practical low-resolution face recognition scenarios where the probe face is low-resolution and the gallery face is low or high-resolution, denoting as LR-LR and LR-HR, respectively. We conduct the comparisons with state-of-the-art low-resolution models, including 4 normal-resolution ones(FaceNet [33], CosFace [34], ArcFace [1] and MagFace [35]) and 7 low-resolution models (SKD [36], BridgeKD [37], HORKD [38], EKD [39], RPCL [40]). To ensure fair comparisons, we follow the protocols as in previous studies to prepare the data for evaluation. The accuracy is the percentage of correct predictions, where the threshold is decided as the one with the highest accuracy.\nFirst, we consider two kinds of baselines. The first kind is directly using pre-trained teacher with high-resolution faces, which is denoted as model_I. The second kind is the student trained with the low-resolution faces from scratch, denoted as model_II. These experiments are designed to demonstrate the validity of our distillation framework, as well as the effectiveness of knowledge transfer. As in Tab I, three main conclusions can be drawn. First, lower-resolution result in evident accuracy drop, which is in accord with discoveries of previous researches. Second, LR-HR is more difficult than LR-LR scenario because of the resolution of the input differences significantly affects the accuracy. Finally, our AIRD outperforms two baselines in both scenarios, especially when probe resolution is lower, which is more challenging.\nIn order to verify the robustness of our low-resolution student models, we then emphatically check the accuracy when the input resolution is 16 \u00d7 16. We conduct comparisons with the state-of-the-art low-resolution face recognition methods at a much lower-resolution on both LFW [2] and Age-DB [31], as in Tab II and Tab III. Compared to distillation-based ones, AIRD achieves better accuracy since it extracts instance-relation level knowledge which is more effective than lower-order transferring. Also, our AIRD performs well in both LR-LR and LR-HR scenarios, demonstrating the robustness of our method. RPCL [40] models learn margin-based discriminative features, our method still outperforms it in both recognition scenarios since it implicitly encodes the knowledge by using anchor-based high-order relation preserving distillation.\nTo provide a more intuitional demonstration, Fig. 3 exhibits the distribution of similarity scores achieved by different models on LFW under LR-LR and LR-HR settings. In each subfigure, the scores of the positive and negative pairs are presented in green and red color, separately. Smaller overlapping suggests a more distinct separation between pairs. It is clear that the proposed AIRD presents a smaller overlapping. Compared with the others, our method shows better performance."}, {"title": "B. Results on Face Identification", "content": "UCCS is collected in real surveillance scenarios, including blurred images and bad illumination, which is a challenging benchmark for face recognition in unconstrained scenarios. We follow the training and testing settings in [37], [38], randomly select a 180-subject subset, separate the faces into 3918 training and 907 testing faces, and finetune the layer parameters on training set. We show the accuracy at a resolution of 16 \u00d7 16. As shown in Tab. IV, AIRD achieves the best identification accuracy compared with others, at least an improvement of 1.56%. This suggests that although low-resolution faces lack some important information needed for recognition, our ARID can learn discriminative representations that are beneficial for improving low-resolution face recognition performance."}, {"title": "C. Ablation Studies", "content": "Ablation studies are conducted to validate the effectiveness of each components on LFW and Age-DB under LR-LR settings with the resolution of 16 \u00d7 16 to evaluate the efficiency of the detailed design of our method. We conduct experiments to show the contribution of each loss component. Our ARID consists of instance-relation distillation and inference adaptation.\nFirst, we show the effect of instance-relation distillation without FaceBN. As in Tab. V, both IID and RID improve the results compared to baseline which only use a general classification loss for face recognition. Besides, RID increases more, which means that transferring high-order relational contrastive knowledge is helpful for student to learn discriminative representations. When combining them, AIRD achieves a higher accuracy, which means that only instance or relation level knowledge transfer may not enough and these two can complement each other. This illustrates the effectiveness of our instance-relation distillation.\nSecond, as in Tab. V, applying FaceBN further improves the accuracy, demonstrating the adaptability of FaceBN. Moreover, we show the data mean distribution of LFW (in blue) and CASIA-WebFace (in green) in Fig. 5 visually. We train the student model with the CASIA-WebFace dataset, and observe the distribution statistics in the feature map during inference using LFW. Fig. 5 shows the close-ups. The feature distribution of LFW with the traditional batch normalization has an obvious shift compared with that of CASIA-WebFace, which is the training dataset. Fortunately, equipped with FaceBN, the distribution statistics of LFW seem more close to the training dataset. This indicates that FaceBN can mitigate data gap, delivering a reasonable distribution to the following layers. In this way, it can improve the generalization ability of models and facilitate recognition accuracy.\nThird, we verify the effect of pre-selecting positive and negative pairs' sampling policy, which is one of the main differences of the previous, like CRCD [12] and DKD [8]. We consider our sampling method as well as random sampling. As in Fig. 6, pre-selecting positive and negative pairs can bring at least 0.25% improvement at accuracy on LFW. Then, we also validate five different negative pairs numbers (64, 128, 256, 512 and 1024), as the negative number has a crucial impact on the final performance in contrastive learning. The results is in the right of Fig. 6. Here, increasing negative number will lead to performance improvement, which means higher-order relation knowledge is built. However, larger negative number requires more computations, which means the negative number should be carefully selected to balance the accuracy and computation cost."}, {"title": "V. CONCLUSION", "content": "In this paper, we propose an adaptable instance-relation distillation approach to facilitate low-resolution face recognition. The approach distills the teacher knowledge from instance and relation levels, and then the learned student model can be used to effectively recognize testing low-resolution faces via inference adaptation. In this way, our method improves the transfer ability of the learned model in recognizing real-world low-resolution faces. Extensive experiments on low-resolution face recognition tasks show the effectiveness and adaptability of our proposed approach. In the future, we will explore its potential on more low-resolution object recognition tasks."}]}