{"title": "Generalized Out-of-Distribution Detection and Beyond in Vision Language Model Era: A Survey", "authors": ["Atsuyuki Miyai", "Jingkang Yang", "Jingyang Zhang", "Yifei Ming", "Yueqian Lin", "Qing Yu", "Go Irie", "Shafiq Joty", "Yixuan Li", "Hai Li", "Ziwei Liu", "Toshihiko Yamasaki", "Kiyoharu Aizawa"], "abstract": "Detecting out-of-distribution (OOD) samples is crucial for ensuring the safety of machine learning systems and has shaped the field of OOD detection. Meanwhile, several other problems are closely related to OOD detection, including anomaly detection (AD), novelty detection (ND), open set recognition (OSR), and outlier detection (OD). To unify these problems, a generalized OOD detection framework was proposed, taxonomically categorizing these five problems. However, Vision Language Models (VLMs) such as CLIP have significantly changed the paradigm and blurred the boundaries between these fields, again confusing researchers. In this survey, we first present a generalized OOD detection v2, encapsulating the evolution of AD, ND, OSR, OOD detection, and OD in the VLM era. Our framework reveals that, with some field inactivity and integration, the demanding challenges have become OOD detection and AD. In addition, we also highlight the significant shift in the definition, problem settings, and benchmarks; we thus feature a comprehensive review of the methodology for OOD detection, including the discussion over other related tasks to clarify their relationship to OOD detection. Finally, we explore the advancements in the emerging Large Vision Language Model (LVLM) era, such as GPT-4V. We conclude this survey with open challenges and future directions.", "sections": [{"title": "1 INTRODUCTION", "content": "Reliable visual recognition system should not only accurately predict known contexts, but also identify and reject unknown examples [1], [2], [3], [4]. In critical applications like autonomous driving, the system must alert and cede control to the driver upon encountering unfamiliar scenes or objects not seen during training. However, most existing machine learning models are trained based on the closed-world assumption [5], [6], where the test data is assumed to be drawn i.i.d. from the same distribution as the training data, known as in-distribution (ID). Therefore, the development of classifiers capable of detecting out-ofdistribution (OOD) samples is a crucial challenge for realworld applications. This challenge is precisely the focus of research in the field of OOD detection.\nWhile OOD detection primarily focuses on semantic distribution shift, several other tasks share similar goals and motivations, including outlier detection (OD) [7], [8], [9], [10], anomaly detection (AD) [11], [12], [13], [14], novelty detection (ND) [15], [16], [17], [18], and open set recognition (OSR) [19], [20], [21]. Subtle differences in the specific definitions among these sub-topics have caused confusion in the field, leading to similar approaches being proposed across them. To address this issue, the generalized OOD detection framework was introduced [22]. The taxonomy of the generalized OOD detection framework is shown in Fig. 1. The generalized OOD detection framework classifies these tasks as special cases or sub-tasks under a unified taxonomy. This framework provides clear definitions and fosters a deeper understanding of each field.\nIn recent years, the emergence of Vision Language Models (VLMs), represented by CLIP [23], has rapidly accelerated research in the field of Computer Vision. This has changed the paradigm of the recognition field, allowing for zeroshot [23] or few-shot learning [24], [25] in various domains. VLMs have significantly influenced the aforementioned five problems (OD, AD, ND, OSR, and OOD detection), and the application of VLMs has become a highly notable research field [26], [27], [28], [29]. However, alongside this remarkable progress, the paradigm shift with the advent of the VLMs has blurred the boundaries between the five problems. Due to the difficulty of a clear understanding of the distinctions and interrelations between these tasks, each community within the fields is facing significant challenges in identifying the optimal direction to pursue in this VLM era.\nIn this survey, we introduce a novel unified framework termed generalized"}, {"title": "2 GENERALIZED OOD DETECTION V2", "content": "In this section, we introduce a novel unified framework termed generalized OOD detection v2, which summarizes the evolution of the five related fields in the VLM era. We first revisit the previous generalized OOD detection framework in Sec. 2.1. Next, we introduce the evolution of each problem."}, {"title": "2.1 Background: Generalized OOD Detection V1", "content": "We first briefly revisit a previous generalized OOD detection, which encapsulates five related sub-topics: anomaly detection (AD), novelty detection (ND), open set recognition (OSR), out-of-distribution (OOD) detection, and outlier detection (OD). These sub-topics can be similar in the sense that they all define a certain in-distribution, with the common goal of detecting out-of-distribution samples under the openworld assumption. Previously, subtle differences existed among the sub-topics in terms of the specific definition and properties of in-distribution (ID) and OOD data.\nTo provide a clear definition, a generalized OOD detection framework was proposed [22]. The taxonomy for generalized OOD detection is shown in Fig. 1. It is based on the following four bases: (1) Distribution shift to detect: The task focuses on detecting either covariate shift (e.g., OOD samples from a different domain) or semantic shift (e.g., OOD samples from a different semantic). (2) ID data type: The in-distribution (ID) data contains either a single class or multiple classes. (3) Whether the task requires ID classification: Some tasks require classification of the ID data, while others do not. (4) Transductive vs. inductive learning: Transductive tasks require all observations (both ID and OOD), while inductive tasks follow the common train-test scheme. According to the above taxonomy, these five problems can be clearly categorized as shown in Fig. 1: Anomaly detection is categorized into sensory anomaly detection, which deals with covariate shift, and semantic anomaly detection, which deals with semantic shift. Novelty detection falls under the same category as semantic anomaly detection. When addressing a multi-class scenario that necessitates ID classification, both open-set recognition and out-of-distribution detection are encompassed within this category. The main difference between OSR and OOD detection was the benchmark setup [22], [55] (Sec. 2.2 (c)). Outlier detection belongs to a different category from the other tasks, as this problem is transductive (i.e., it has access to all observations).\nFor the detailed definition of each task, we refer the readers to the previous generalized OOD detection survey paper [22]."}, {"title": "2.2 Evolution of Each Problem in VLM Era", "content": "We review how each problem has evolved in the VLM era. To make a fair judgment, we comprehensively investigated papers that use VLMs from top venues and summarized them in Table 1. Our survey revealed that CLIP [23] is predominantly used as the VLM for OOD detection and other sub-tasks, and other VLMs [56], [57] are rarely utilized. Therefore, we focus on CLIP as the target VLM in this survey and refer to OOD detection using CLIP as CLIP-based OOD detection. Similarly, we will prefix other tasks with \u201cCLIPbased\" (e.g., CLIP-based AD). As OOD detection research is primarily focused on the image domain, we conduct a survey of other tasks within the image domain that are common and have strong connections to OOD detection research. For instance, our survey does not cover video domain tasks [58], [59], [60] due to their limited connection to OOD detection.\na) Sensory AD \u2192 CLIP-based AD Sensory AD has continued to develop as a common problem setting for CLIPbased AD, inheriting the challenges of traditional sensory AD [27], [29], [33], [35], [61], [62], [62], [63], [64], [65]. As shown in Table 1, the first appearance in a top venue was at CVPR 2023, and since then, a total of six papers have been published in top venues. In addition, there are numerous other papers [61], [63], [64], [65], [66]. Moreover, in terms of benchmarks, in addition to the commonly used MVTecAD [52], the largest industrial anomaly detection dataset VisA [53] has also become a standard benchmark in the field. Therefore, it is evident that sensory AD has become a highly active and noteworthy field in the VLM era.\nb) Semantic AD/ND \u2192 Inactive Research on semantic AD/ND appears to become inactive in the VLM era. As shown in Table 1, there are only two papers, TMLR 2022 [37] and CVPR 2024 [35]. However, the CVPR 2024 work [35] aims to build a generalist anomaly detector that solves many AD tasks, including sensory AD and semantic AD, and is not primarily focused on semantic AD. The reasons for the inactivity include saturation of performance for oneclass semantic AD/ND, and incompatibility of methods with CLIP for multi-class semantic AD/ND. As for one-class semantic AD/ND, TMLR [37] exists, but the performances with common CIFAR and ImageNet-30 datasets have already achieved around 99%. As for multi-class semantic AD/ND, a common approach is to treat ID classes as a single class, but treating ID classes as a single class is less compatible with CLIP's class-wise discriminative capability.\nc) OSR \u2192 CLIP-based OOD Detection We consider that OSR has been integrated into CLIP-based hard OOD detection. According to Table 1, there are no top venue publications on OSR research in the VLM era. Originally, the main difference between OSR and OOD detection was the benchmark setup [22], [55]. OSR typically divides the classes in the one dataset into some known (ID) classes and unknown (OOD) classes, as seen in MNIST-4/6 [67] CIFAR4/6 [68], CIFAR-50/50 [69], and TinyImageNet-20/180 [70]. However, in recent years, some works on CLIP-based OOD detection incorporate the benchmark setup of OSR and create new benchmarks such as ImageNet-10/ImageNet-20 [26] and ImageNet-protocol [47], [54] for hard OOD detection. Therefore, the boundary between OOD detection and OSR has effectively disappeared, and all research in the VLM era has been integrated into OOD detection.\nNevertheless, while pure OSR research is declining, some studies have used the term \"open-set\" in the context of domain generalization [71]. These studies deviate from the original scope of OSR research and are rather closely aligned with the field of domain generalization [72]. Therefore, within our generalized OOD detection v2, we do not classify these studies as falling under OSR research. We will discuss them in the context of full-spectrum OOD detection, a research field combining generalization and detection, in Sec. 7.2.\nd) OOD Detection \u2192 CLIP-based OOD Detection OOD detection is a highly active research area in the VLM era. As shown in Table 1, there are many papers in top venues, indicating a high interest from the community. Additionally, as mentioned above, OSR has been integrated with OOD detection as a field of hard OOD detection [26], [47]. Therefore, it is expected that OOD detection will continue to grow and develop further.\ne) OD \u2192 Inactive OD has become less active in the VLM era. Previously, OD was used for open-set semisupervised learning [73], [74], [75], learning with open-set noisy labels [76], and novelty discovery [77], [78], [79], [80], [81]. The reason for the inactivity is that the use of CLIP led to a reduction in training costs and only a small amount of data needs to be collected, eliminating the need for large amounts of unlabeled data and reducing the need to consider noisy data. However, recently, Liang et al. [49] proposed Unsupervised Universal Fine-Tuning, a new problem setting for CLIP-based OD in ICML2024. Unsupervised Universal Fine-Tuning assumes a more realistic problem setting for unsupervised tuning of the downstream task with CLIP where some OOD samples are included in the unlabeled samples. With this new problem setting, there is still a possibility that OD will become active in the future. However, as OD is not currently an active area, we exclude OD from the main discussion of this survey. Unsupervised Universal Fine-Tuning is deeply related to OOD detection and will be discussed in detail in Sec. 4.3."}, {"title": "2.3 Discussion", "content": "Through Sec. 2.2, we found that previously mixed fields have been correctly organized in the VLM era, and that the focus should be on OOD detection and sensory AD. These fields are still developing, with an increasing number of methodologies and benchmarks, and are expected to become more active in the future. Note here that this does not mean that other fields have come to an end. For example, one reason why one-class semantic AD/ND has not been studied is the saturation of performance [37]. If more fine-grained and challenging datasets could be constructed, the field could be reactive. We put this in out-of-scope for this survey paper, but this is an important future challenge."}, {"title": "3 OVERVIEW OF EACH PROBLEM IN VLM ERA", "content": "In addition to the above inter-field evolution, we emphasize that the advent of VLMs has significantly changed the field of OOD detection itself. In this section, we present an overview of CLIP-based OOD detection, highlighting the key changes in the problem definition, the problem setting, and benchmarks. In addition, we also present an overview of CLIP-based AD in the hope that the understanding of each field will lead to a deeper understanding of CLIPbased OOD detection. For items that remain unchanged from traditional problems, such as background, applications, and evaluation, we refer the readers to the original generalized OOD detection paper [22]."}, {"title": "3.1 CLIP-based Out-of-Distribution Detection", "content": "Definition The definition of CLIP-based OOD detection differs significantly from that of conventional OOD detection. Conventional OOD detection aims to detect test samples drawn from a distribution that is different from the training distribution. As another definition, OOD detection is defined as a task to detect test samples that the model cannot or does not want to generalize [22]. However, for CLIP-based OOD detection, CLIP has a vast amount of knowledge, so the OOD sample is completely unrelated to the distribution of the CLIP's pretraining data or the CLIP's own generalization ability. Therefore, traditional definitions cannot adequately describe the definition of CLIP-based OOD detection.\nUnlike the previous definition, CLIP-based OOD detection is defined as follows [26], [39]: CLIP-based OOD detection aims to detect samples that do not belong to any ID class text provided by the user. Given a pre-trained model, a classification task of interest is defined by a set of class labels $V_{ID}$, which we refer to as the ID classes. The semantic distribution is represented by the distribution $P(V_{ID})$. CLIPbased OOD detection aims to detect test samples that come from the distribution with the semantic shift from the ID classes, i.e., $P(V_{ID}) \\neq P(Y_{OOD})$. Following the definition of the generalized OOD detection framework [22], ideal OOD detectors should keep the classification performance on test samples from ID class space $V_{ID}$, and reject OOD test samples with semantics outside the support of $V_{ID}$.\nProblem Setting CLIP-based OOD detection focuses on solving the image classification task in a computationally efficient way. Unlike traditional OOD detection settings, which primarily involve training an ID classifier with whole ID data, CLIP-based OOD detection primarily focuses on a zero-shot [26] (i.e., without utilizing ID images) or fewshot [28] (i.e., utilizing only a few ID images) setting. Each detailed definition of both settings are described later in Sec. 4. The field is advancing towards greater computational efficiency, requiring minimal or no training data.\nBenchmark Most recent works in CLIP-based OOD detection use high-resolution and large-scale datasets such as ImageNet [26], [28], [46], [47], [48]. The common ImageNet OOD benchmark uses ImageNet as ID and other datasets [82], [83], [84], [85] as OOD. However, in this common benchmark, the semantics between ID and OOD are far, which may allow easy distinction between the ID and OOD. Therefore, recent works use more challenging OOD benchmarks where they split ImageNet classes into ID and OOD categories for hard OOD detection [26], [47], [86]. The representative datasets are ImageNet-20 [26], ImageNet-10 [26], and the recently proposed ImageNet-protocol [54] created by dividing into multiple variations of ID/OOD pairs from ImageNet-1K. This creation strategy initially focused on OSR but has recently been repurposed for OOD detection. These changes in the datasets shift OOD detection closer to the real world and make it a more challenging and practical task."}, {"title": "3.2 CLIP-based Anomaly Detection", "content": "Definition Unlike OOD detection, the definition of anomaly detection (AD) has not changed between conventional AD and CLIP-based AD. AD is intended for use in specific circumstances (industrial inspection), where samples that deviate from predefined normality are considered an anomaly [11], [22]. Whether a model can generalize is irrelevant to the definition of \u201cAnomaly\u201d. Therefore, even with the emergence of CLIP, the definition has not changed.\nProblem Setting CLIP-based AD focuses on solving anomaly classification and segmentation in a computationally efficient way. Anomaly classification, like conventional AD, is a binary classification task that distinguishes between normality and abnormality. Anomaly segmentation, also following conventional AD, involves segmenting the location of anomalies. Like CLIP-based OOD detection, CLIP-based AD also primarily focuses on a zero-shot [27] (i.e., without utilizing images in the target dataset) or few-shot [27] (i.e., using only a few normal images in the target dataset) setting. Each detailed definition of zero-shot and few-shot settings is described later in Sec. 5. As another shift, conventional AD created separate models for each category [87], [88], [89], [90], [91], [92], [93], while CLIP-based AD creates a single unified model across multiple categories [27], [29], [35], [61], [63], which leads to a more computationally efficient approach.\nOne key difference from CLIP-based OOD detection is that CLIP-based OOD detection does not involve localization tasks, while these are mainstream in CLIP-based AD. This will be discussed in detail in Sec. 5.4.\nBenchmark Most works on CLIP-based AD tackle industrial inspection [52], [94], [95]. As for the benchmarks, besides the common MVTec-AD dataset [52], the more challenging dataset VisA [53] has been newly employed [27]. The VisA benchmark includes objects with complex structures such as printed circuit boards and multiple instances with different locations within a single view, making it one of the most challenging datasets currently available in the open datasets. Since the pioneering work in CLIP-based AD (i.e., WinCLIP [27]) used MVTec-AD and VisA, many subsequent works have also used these datasets [33], [63], [65]."}, {"title": "4 CLIP-BASED OOD DETECTION: METHODOLOGY", "content": "In this section, we introduce the methodologies for CLIPbased out-of-distribution (OOD) detection. Fig. 3 presents the timeline for representative methodologies for CLIP-based OOD detection. Table 2 presents representative methods. We introduce methods for zero-shot OOD detection in Sec. 4.1, few-shot OOD detection in Sec. 4.2, and other research directions in Sec. 4.3. For each methodology, we categorize them by the type of training and whether additional OOD prompts were employed."}, {"title": "4.1 Zero-shot Out-of-Distribution Detection", "content": "Zero-shot OOD detection was proposed in 2021 by Fort et al. [38]. Since then, a growing number of methods have been proposed year by year.\nDefinition of Zero-shot OOD Detection In zero-shot OOD detection, the term \"Zero-shot\" refers to the non-use of ID images during both training and inference phases. For instance, the method with additional training with auxiliary datasets (non-use of ID images) can be regarded as a zeroshot method [40]. The method with the pre-processing of the ID class texts can also be regarded as a zero-shot method [38], [39], [45], [48]."}, {"title": "4.1.1 Training-free Methods", "content": "a. With OOD Prompts CLIP-based OOD detection started in this setting. The earliest work is ZeroOE [38]. ZeroOE feeds the potential OOD labels to the textual encoder of CLIP. However, the method of using known OOD labels is infeasible for real-world applications. To solve this problem, ZOC [39] proposed to train an OOD label generator based on the visual encoder of CLIP and use the generated pseudoOOD labels for OOD detection. However, when dealing with large-scale datasets encompassing a multitude of ID classes, the label generator may not generate effective candidate OOD labels, resulting in poor performance. Building on these early works [38], [39], recent works focus on how to obtain high-quality OOD labels through either (i) OOD label retrieval [45], [100] or (2) OOD label generation [48]. (i) One of the representative retrieval-based methods is NegLabel [45]. NegLabel selects high-quality OOD labels from extensive corpus databases by calculating the distance between an extracted OOD label and ID label. (ii) One of the representative generation-based methods is EOE [48]. EOE utilizes Large Language Models (LLMs) to produce highquality OOD labels. By modifying the prompts given to the LLM, EOE can be generalized to a variety of tasks, including far and near OOD detection.\nb. Without OOD Prompts In zero-shot OOD detection, many methods utilize OOD labels, but the difficulty and cost of creating these labels pose challenges. To address these issues, Ming et al. [26] proposed MCM, which uses only ID labels to detect OOD. MCM is a simple approach that devises softmax scaling to align visual features with textual concepts for OOD detection. Despite its simplicity, MCM has high effectiveness and scalability, and it serves as a crucial baseline in CLIP-based OOD detection. Building on the concept of MCM, Miyai et al. [96] proposed GLMCM, which extends MCM by just adding a local MCM score to enhance the fine-grained detection capability in local regions. SeTAR [97] enhances MCM and GL-MCM by changing the model's weight matrices using a simple greedy search algorithm. We consider these methods to be posthoc methods for CLIP-based OOD detection in that they directly employ an ID classifier for OOD detection. Due to their simplicity and high scalability, these post-hoc methods can bring fundamental performance improvements for many subsequent methods [28], [44], [47]. Therefore, we expect that this field should be developed further in the future, reflecting the trajectory of the field before CLIP emerged [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111]."}, {"title": "4.1.2 Auxiliary Training-based Methods", "content": "CLIPN [40] is the only auxiliary training-based method for zero-shot OOD detection. CLIPN aims to empower the logic of saying \u201cno\u201d within CLIP, and it designs a novel learnable \"no\" prompt and an additional \u201cno\u201d text encoder to capture negation semantics within images. To create an additional text encoder, CLIPN needs to be pre-trained on the CC-3M dataset [112]. While the extensive pre-training of CLIPN may indeed lead to intensive computations and lower scalability, once pre-trained, it performs zero-shot OOD detection across a wide range of domains with comparable performance to few-shot OOD detection methods [28], [44].\nIn the future, within this field, there is potential for zeroshot open-vocabulary OOD detection to further advance the realm of zero-shot OOD detection, which will be discussed later in Sec. 7.2."}, {"title": "4.2 Few-shot Out-of-Distribution Detection", "content": "Few-shot OOD detection was concurrently proposed by Miyai et al. [28] and Ming et al. [41] in June 2023. Since then, it has become the most active research area in CLIP-based OOD detection.\nDefinition of Few-shot OOD Detection CLIP-based fewshot OOD detection aims to detect OOD images using only a few labeled ID images. In few-shot OOD detection, the term \"Few-shot\" refers to the use of a few ID images during training or inference phases. For instance, the method with additional training with a few ID images can be regarded as a few-shot method [33]. Even without training, if a method uses a few ID images as a reference, we regard it as a few-shot method [27]. Regarding the number of shots, it is common to experiment with 1-shot to 16-shot [28], [99], following the closed-set setting [24]."}, {"title": "4.2.1 ID Training-based Methods", "content": "a. Without OOD Prompts Few-shot OOD detection began in this setting. Ming et al. [41] proposed PEFT-MCM for CLIP-based OOD detection, which demonstrates the effectiveness of combining parameter-efficient tuning methods (e.g., prompt learning [24] or adapter [113]) and MCM [26]. Concurrently, Miyai et al. [28] proposed LoCoOp, a pioneer prompt learning approach for few-shot OOD detection. LoCoOp enhances CoOp's [24] OOD detection capabilities by performing OOD regularization with local OOD features. LoCoOp is the simplest prompt learning method and serves as a crucial baseline in few-shot OOD detection. Unlike LoCoOp, which utilizes non-ID local regions for OOD regularization, GalLoP [98] proposes an approach that utilizes local ID regions to enable a more fine-grained distinction between ID and OOD samples. GalLoP learns a diverse set of prompts by utilizing both global and local visual representations, thereby enhancing the detection capabilities.\nb. With OOD Prompts Similar to zero-shot OOD detection, recent works in few-shot OOD detection utilize additional OOD prompts [44], [46], [47]. As representative methods, LSN [44] and NegPrompt [47] were proposed concurrently. They state that the simple negative prompts added \"not\" (e.g., \"not a photo of a [cls]\") fail to capture the dissimilarity for identifying OOD samples. Therefore, by preparing negative prompts and training with them, LSN and NegPrompt can learn suitable negative prompts, enabling more accurate detection of OOD samples. The difference between LSN and NegPrompt lies in their approach to the use of negative prompts. LSN prepares unique negative prompts for each class and learns suitable negative prompts for each class. In contrast, NegPrompt prepares multiple negative prompts common to all ID classes and trains them to learn generic templates representing the negative semantics of any given class labels. Also, NegPrompt tested the performances in the hard OOD detection setting with ImageNet-protocol [54], outperforming LoCoOp and CoOp. Alternatively, IDPrompt [46] takes a different approach by introducing ID-like prompts, which are designed for OOD features that are close to the ID features. It extracts ID-like OOD regions in ID training images and trains ID-like prompts with these extracted OOD data. In a unique direction, LAPT [114] proposes an automatic sample collection strategy that retrieves or generates training ID images only with ID class names, which achieves high performance without image collection and annotation costs. LAPT then performs distribution-aware prompt learning, which distinguishes between ID class and OOD class tokens. LAPT is positioned within the context of more efficient few-shot OOD detection in this survey paper since it requires generating or retrieving \u201cID images\u201d for the data collection.\nIn the context of few-shot OOD detection, recently, Li et al. [47] proposed a new problem setting called openvocabulary OOD (OV-OOD) detection. While common fewshot OOD detection involves training on images from all ID classes during training, OV-OOD detection involves training on images from just a small subset of ID classes and performing OOD detection using all ID classes at inference time. Formally, we define a subset of semantic labels $V_{ID,sub} \\subset V_{ID}$, where $V_{ID}$ represents all ID labels. Based on this subset of labels, we define a corresponding subset dataset $D^{train}_{sub} \\subset D$. During training, only $D^{train}_{sub}$ is used. Then, at inference time, all ID classes $V_{ID}$ are used, and the goal is to detect OOD from a combination of all ID test data $D^{test}_{ID}$ with $V_{ID}$ and OOD test data $D^{test}_{OOD}$ with $Y_{OOD}$. For this setting, existing few-shot OOD detection methods [28], [47] can be easily applied by simply combining the rest of the ID classes. In particular, NegPrompt [47] learns general negative prompts that are not specific to the training ID classes, so it achieves high performance in OV-OOD detection."}, {"title": "4.2.2 Training-free Methods", "content": "Training-free few-shot OOD detection is a novel research field, and only Dual-Adapter [99] falls under this category. Dual-Adapter adopts a prior-based method TipAdapter [113], which leverages both textual and visual features with a cache model and enhances performance without training. To adapt this to few-shot OOD detection, Dual-Adapter employs the concept of dual cache modeling and constructs Positive-Adapter and Negative-Adapter, and identifies OOD samples with the prediction difference with both adapters."}, {"title": "4.3 Other Important Research Directions", "content": "4.3.1 CLIP-based Full-spectrum OOD Detection\nCLIP-based full-spectrum OOD (FS-OOD) detection is a crucial challenge [115]. FS-OOD detection was proposed by Yang et al. [116] in 2022 as an important setting that considers both OOD generalization [117], [118] and OOD detection simultaneously. Unlike standard OOD detection, which only focuses on semantic shifts between training and test distributions, FS-OOD detection further considers non-semantic covariate shift by including covariate-shifted ID images. As for the benchmarks, OpenOOD v1.5 [119] provides two large-scale benchmarks based on ImageNet200 and ImageNet-1K, incorporating ImageNet-C [117] with image corruptions, ImageNet-R [118] with style changes, and ImageNet-V2 [120] with resampling bias as ID. As for CLIP-based methods, LSA [115] uses a bidirectional prompt customization mechanism, which adjusts discriminative ID and OOD boundary.\n4.3.2 Other Tasks with CLIP-based OOD Detection\nUnsupervised Universal Fine-Tuning CLIP-based OOD detection is useful for a new task called Unsupervised Universal Fine-Tuning (UUFT) [49]. UUFT is a problem of unsupervised learning for outlier detection (OD). Existing studies for unsupervised learning assumed that all unlabeled images belong to one of the ID classes [121], [122], [123], but they require prior knowledge of exact class names linked to ground truth labels, which restricts their usefulness in various real-world situations. For a more realistic setting, UUFT assumes that OOD images are included in the unlabeled images. To detect OOD images during training, they developed MCM [26] and proposed UEO, which leverages sample-level confidence to approximately minimize the conditional entropy of confident instances and maximize the marginal entropy of less confident instances.\nOpen-world Prompt Tuning CLIP-based OOD detection is useful for a new task called Open-world Prompt Tuning [124]. Open-world Prompt Tuning is a task that evaluates the classification accuracy on a mix of known and novel ID classes while training the model with known classes. To solve this problem, Zhou et al. [124] proposed DeCoOp which incorporates OOD detection into the inference pipelines and improves the base-to-new separability, preventing performance degradation on new classes."}, {"title": "5 CLIP-BASED AD: METHODOLOGY", "content": "In this section, we introduce methodologies for CLIP-based anomaly detection (AD) in the hope that the contrast with OOD detection clarifies the similarities and differences between each task and facilitates a deeper understanding of CLIP-based OOD detection."}, {"title": "5.1 Zero-shot Anomaly Detection", "content": "CLIP-based zero-shot AD was proposed in 2023 by Jeong et al. [27]. Although it started about two years later than OOD detection, many methods have been proposed up to the present.\nDefinition of Zero-shot AD The meaning of the term \"Zero-shot\" for zero-shot AD is similar to that for zero-shot OOD detection. In zero-shot AD, the term \"Zero-shot\" refers to the non-use of the images in the target domain during both training and inference phases. For instance, the method with additional training with auxiliary datasets can be regarded as a zero-shot method [29], [62], [63], [64], [65]. The method with the pre-processing of the target class texts can also be regarded as a zero-shot method [27], [61], [62]."}, {"title": "5.1.1 Training-free Methods", "content": "With Anomaly Prompts In zero-shot AD, a common approach is to utilize anomaly prompts to detect anomalies. This hypothesis is supported by several observations from existing work [27]. Firstly, the concepts of normality and anomalies are context-dependent states [125] of an object, with language playing a crucial role in defining these states. Secondly, language provides additional insights that help differentiate defects from acceptable variations in normality. The simplest zero-shot AD methods are (i) to perform anomaly classification with CLIP using text prompts for normality and anomalies as classes (i.e., \u201cnormal [class]\u201d vs. \"anomalous [class]", "normal [class": ") as the score. These methods are called CLIP-AC [27", "27": "reported that CLIP-AC with both normal and anomaly prompts outperforms that with only normal text prompts, which indicates the importance of the use of anomaly prompts. However, the performances for this naive method are not yet satisfactory due to the wide range of variations of anomalies. To solve this issue, Jeong et al. [27"}]}