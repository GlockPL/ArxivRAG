{"title": "TraM : Enhancing User Sleep Prediction with Transformer-based Multivariate Time Series Modeling and Machine Learning Ensembles", "authors": ["Jinjae Kim", "Minjeong Ma", "Eunjee Choi", "Keunhee Cho", "Changwoo Lee"], "abstract": "This paper presents a novel approach that leverages Transformer-based multivariate time series model and Machine Learning Ensembles to predict the quality of human sleep, emotional states, and stress levels. A formula to calculate the labels was developed, and the various models were applied to user data. Time Series Transformer was used for labels where time series characteristics are crucial, while Machine Learning Ensembles was employed for labels requiring comprehensive daily activity statistics. Time Series Transformer excels at capturing the characteristics of time series through pre-training, while Machine Learning Ensembles selects machine learning models that meet our categorization criteria. In experiments, the proposed model, TraM, scored 6.10 out of 10, demonstrating superior performance compared to other methodologies. The code and configuration for the TraM framework are available at: https://github.com/jin-jae/ETRI-Paper-Contest.", "sections": [{"title": "I. INTRODUCTION", "content": "The prevalence of sleep-related issues has led to a decline in sleep quality, increasing the risk of cardiovascular diseases and depression [1]. Poor sleep quality impacts physical and mental health, impairing cognitive function, weakening the immune system, and increasing illness vulnerability. Chronic sleep deprivation is linked to heightened stress, impaired judgment, and an increased risk of accidents, contributing to conditions such as hypertension, diabetes, obesity, and worsening mental health disorders.\nAdditionally, poor sleep quality is strongly associated with emotional regulation and stress. Chronic sleep deprivation leads to heightened stress levels, which further worsen sleep problems, creating a vicious cycle. Insufficient sleep disrupts the brain's ability to manage stress, resulting in increased irritability, anxiety, and mood swings. Studies show that sleep deprivation affects the emotional processing areas of the brain, such as the amygdala, leading to an overactive response to negative stimuli. [2]\nThe pandemic has led to lifestyle changes such as lock-downs, remote work, and increased screen time, significantly altering sleep patterns. Reduced physical exercise and irregular routines have disrupted circadian rhythms, making falling and staying asleep harder. Researchers have recognized the need to improve sleep quality by focusing on personalized solutions through technology and data analysis.\nUnderstanding the relationship between sleep patterns and factors such as physical activity, stress, and environmental conditions can help develop targeted interventions. Improving sleep quality enhances productivity and contributes to long-term health benefits. Building a healthier society requires pri-oritizing sleep health in public health initiatives and individual wellness plans.\nChriskos et al. [3] collected biometric signals, including skin temperature, heart rate, and respiratory rate to train a deep-learning model for predicting sleep quality. Ezati et al. [4] showed that regular aerobic exercise improves sleep quality. Chang et al. [5] found that individuals who perceive themselves as healthy or are satisfied with their physical activity levels tend to have better sleep quality. However, these models still require validation with diverse biometric data.\nTo address the issue, this paper proposes a novel approach combining a Time Series Transformer (TST) [6] and Machine Learning Ensembles to predict sleep quality and related metrics. By integrating these advanced methodologies, our study aims to provide a robust framework for predicting and improving sleep quality. The combined strengths of TST and Machine Learning Ensembles offer an integrated solution for accurately predicting sleep quality and related life quality labels, contributing to improved health management and per-sonalized intervention strategies.\nThe contributions of this paper are as follows:\n\u2022 Implemented methods for handling missing values, nor-malizing data, and ensuring temporal alignment in mul-tivariate time series data.\n\u2022 Refined a regression model to predict daily user responses based on historical time series data.\n\u2022 Utilized ensemble method to improve the accuracy and robustness of life-quality predictions."}, {"title": "II. RELATED WORKS", "content": "Time series forecasting is essential in statistical analysis and machine learning. ARIMA [7] combines autoregressive, moving average components, and differencing for stationarity, excelling in short-term predictions. Exponential Smoothing methods [8], such as Holt's Linear Trend Model and Holt-Winters Seasonal Model, apply exponentially decreasing weights to past data, effectively capturing trends and seasonality. Recurrent Neural Networks (RNNs) [9] handle sequential data with hidden states incorporating previous time steps but struggle with long-term dependencies, addressed by Long Short-Term Memory networks [10] and Gated Recurrent Units [11]. Convolutional Neural Networks [12], adapted for time series with one-dimensional convolutions, often pair with RNNs to improve performance. Transformer models use self-attention mechanisms for capturing long-term dependencies, which are suitable for multivariate time series forecasting.\nMachine Learning Ensembles enhances predictive modeling by combining algorithms for improved performance and robustness. Techniques include Bagging, Boosting, and Stacking. Bagging, like in Random Forests [13], aggregates predictions from multiple decision trees [14] to reduce overfitting. Boosting, in algorithms such as Gradient Boosting Machines [15] and AdaBoost [16], sequentially improves weak learners to form a strong model. Stacking trains a meta-model on predictions from multiple models. In time series forecasting and sleep quality prediction, Ensembles manages diverse data patterns and improves accuracy by capturing complex dependencies. Combining models like Support Vector Machines, Decision Trees, and K-Nearest Neighbors [17] enhances predictions."}, {"title": "III. PROPOSED METHODS", "content": "The objective of this competition [18] was to predict both the Q1-Q3 labels, representing users' self-reported satisfaction via surveys and the S1-S4 labels, assessing sleep quality based on sensor data collected while sleeping. Before modeling, we examined the characteristics of each of the 7 labels.\nUsing descriptions of each metric [18] and the NSF sleep health guidelines [19] [20], we created formulas capable of predicting each label. For the Q1-Q3 labels, users' response on a particular day was assigned a 1 if it exceeded the average daily response of that user and a 0 if it was less. For the S1-S4 labels, a response is assigned a 1 if it meets the established threshold and a 0 if it does not. The detailed explanation and formula of labels can be found in TABLE I.\nThe Q1, Q2, and Q3 labels represent 'satisfaction with sleep,' 'emotional state before sleep,' and 'stress level before sleep' respectively. These labels indicate an individual's state which varies over time. It is crucial to consider the physical movements and changes resulting from daily activities. Capturing the emotional or stress levels derived from daily activity records in the training data is also essential. The time series data from daytime activities, which show clearer patterns and contents compared to nighttime, can be used to predict user responses based on sensor activity records. Given that specific users and dates as conditions, it is vital to reflect the time series characteristics particular to each user. The formula for the Q labels can be found in (1).\n\n$Q_{i,d} = \\begin{cases}\n1 & \\text{if } r_{i,d} > \\mu_i \\\\\n0 & \\text{if } r_{i,d} \\leq \\mu_i\n\\end{cases}$\n\nwhere $r_{i,d}$ denotes the survey value reported by a specific user i on a specific day d, $\\mu_i$ represents the daily average response of user i. Consequently, $Q_{i,d}$ is defined as the binary value assigned based on the conditions i and d.\nIn contrast, the S1, S2, S3, and S4 labels represent specific, measurable sleep activities such as 'total sleep time,' 'sleep efficiency,' 'time to fall asleep,' and 'time to wake up.' These labels encompass numerous detailed aspects of sleep, such as its depth and continuity, which are not entirely recordable by smartphone or watch sensors in the dataset. The combinations of these columns are evaluated by comparing them to specific benchmarks. Given the granularity of the sensor data and the measured data, it is feasible to model the problem by classifying whether the conditions or states of a day meet these benchmarks. The formula for the S labels can be found in (2).\n\n$S=\\begin{cases}\n1 & \\text{if } 7*60*60 < t < 9*60*60 \\text{ (for S1)} \\\\\n1 & \\text{if } p > 0.85 * 100 \\text{ (for S2)} \\\\\n1 & \\text{if } t < 30*60 \\text{ (for S3)} \\\\\n1 & \\text{if } t < 20*60 \\text{ (for S4)} \\\\\n0 & \\text{otherwise}\n\\end{cases}$\n\nwhere t represents the measurement time in seconds, p represents the percentage, and S denotes the binary value assigned to each user based on specific criteria."}, {"title": "A. Time Series Transformer", "content": "1) Preprocessing: Based on the Transformer Encoder, the TST model was used to predict the Q1-Q3 columns. This model is capable of performing both classification and regression tasks. Since the training and validation data had significant differences in their collection period and content, the data preprocessing step involved extracting common columns from both sets to create a model with high interpretability.\nTo align the varied collection frequencies of each variable, we performed preprocessing to standardize the data collection periods. First, the collected data was resampled to a one-second interval, simply filling in any gaps with the preceding values to ensure a uniform time unit across all data. Then, to manage concerns about model size, the data was resampled again into ten-minute intervals for training. Since resampling from one-second to ten-minute intervals might not capture all the characteristics of the original data, we extracted the mean, standard deviation, minimum, and maximum for continuous variables. Additionally, for the categorical variable 'm_activity', we applied one-hot encoding to capture the range of activities within each ten-minute interval, representing them using the maximum values. Ultimately, we were able to extract 128 days' worth of sleep data, formatted in a way that the model could interpret based on daily sleep cycles. Since the test data had the same variable names as the validation data, we applied the same preprocessing method for both.\n2) Time Series Transformer Model: TST Model [6] is a Transformer-based model designed for multivariate time series classification and regression. This model employs the encoder part of the Transformer architecture and utilizes several techniques to effectively handle classification and regression tasks for time series data. Firstly, it incorporates a new type of positional encoding, specially designed to emphasize the sequential nature of time series data and capture temporal context. This enables the model to learn patterns effectively such as the cycle of the time series data. Secondly, the model generates input vectors using 1D-convolutional layers. This approach allows for enhanced performance on long, low-dimensional data. These filters extract essential features and adjust the dimensionality of the input. Additionally, modifying the stride or dilation of the filters facilitates effective data processing with large periodicities. Thirdly, a maximum sequence length is defined to address the issue of varying input data lengths inherent in time series data, and a padding mask is applied to shorter samples to maintain consistent input sizes. Finally, instead of layer normalization, batch normalization is employed to mitigate the impact of outliers in time series data. This allowed us to address the issue of anomalies in time series data, which could not be resolved using Transformer models.\na) Pre-training: Pre-training involved the auto-regressive denoising task of predicting masked values in the input data, where masking followed a geometric distribution rather than a random assignment. This approach allowed the model to better reflect the structural characteristics of the input data. Such pre-training processes enable models to better understand the internal structure and correlations within the input data, offering the advantage of enhanced performance in downstream tasks such as classification and regression. According to results presented in TST, models that underwent supervised learning without pre-training generally recorded higher performance across most datasets than pre-trained ones. Pre-training was conducted using the preprocessed data specified in III-A1.\nb) Fine-tuning: Fine-tuning was conducted on a pre-trained model by generating a long vector that concatenated representation vectors for each time step. This vector was then passed to a linear output layer. The model's loss was calculated based on mean squared error, and the training was configured as a regression task. We trained the model as a regression, despite the final output being a classification of 0 or 1, because the threshold for classifying between 0 and 1 varied based on the average for each user. Consequently, actual user responses on a 1-5 scale for columns Q1, Q2, and Q3 were required for the fine-tuning process. However, among the provided datasets, only the train dataset contained actual user responses, while the validation dataset only included labels indicating whether responses exceeded the average. Therefore, only the train dataset was utilized for fine-tuning."}, {"title": "B. Machine Learning Ensembles", "content": "1) Preprocessing: Various machine learning methodologies were employed to analyze the correlations among multiple features and identify the factors that most significantly impact sleep quality. To create a more generalized model, features applicable to both training and validation datasets were explored. Given the vast amount of sensor data available, each user was sampled minute-by-minute, and the average and variance values of daily accelerometer, heart rate, activity, and GPS data were calculated.\nFeature engineering was attempted using libraries such as tsfresh [21] and various preprocessing techniques. Due to the tendency to overfit the training data with too many features, we ultimately proceeded with modeling using only the following 10 features. These overlapping ten columns in the training and validation datasets were all used for model training, and the evaluation data was used directly for prediction.\n2) MultiOutputClassifier: Our goal was to predict multiple labels from a single dataset simultaneously. The MultiOutputClassifier provided by Sklearn is a representative methodology capable of predicting several labels, each with a cardinality of two. This model predicts the characteristics of samples where the features are not mutually exclusive, assigning a binary output to each class for all samples. This approach allows for the handling of multiple classes simultaneously and can explain interrelated behaviors.\nPredictions were performed using six different models: RandomForestClassifier [13], GradientBoostingClassifier [15], LogisticRegression [22], SVC [23], DecisionTreeClassifier [14], and KNeighborsClassifier [17]. Each model interprets data and performs predictions differently. By combining various models, it is possible to leverage the strengths and mitigate the weaknesses of each. For example, Decision Trees are sensitive to variables with high feature importance but are prone to overfitting, whereas KNN effectively reflects local characteristics but is sensitive to noise.\nThe six models can be broadly categorized into four types: ensemble-based model, linear model, nonlinear model, and geometric model. The first type includes ensemble-based models such as Random Forest and Gradient Boosting, which combine multiple decision trees or sequentially enhance weak learners, using a strategy to improve prediction performance by combining several base models. The second type includes the linear model, Logistic Regression, which uses a probabilistic approach through a linear decision boundary to predict outcomes. The third type comprises nonlinear models such as the Support Vector Machine and Decision Tree, which utilize the kernel trick to find the optimal separating hyperplane in high-dimensional space or identify branching points that effectively separate data, thus adeptly handling nonlinear data patterns. The fourth type is the geometric-based model, K-nearest Neighbors. It classifies based on the nearest k data points around a given data point, making it a model whose complexity directly depends on the data.\nThese varied models were combined, and soft voting was used to average the probabilities of each classifier's predictions to make the final decision. If one model has high confidence in a particular class but others do not, soft voting incorporates this confidence as a probability, enabling more accurate predictions. Consequently, this allowed for more general and robust performance by considering the probabilities predicted by each model."}, {"title": "IV. EXPERIMENTS", "content": "A. Experiment Setup\nBoth models were utilized for the experiments on Ubuntu 18.04 and Python version 3.8.19, and dependencies were installed accordingly for each model. The training was conducted using two RTX 2080-Ti GPUs. During the pre-training phase of TST, the RAdam optimizer was used with a learning rate of 0.001 for 2000 epochs. The learning rate was set to 0.1 for 400 epochs during the fine-tuning. The batch size for both training phases was set to 128, and the model dimension (d_model) was also set to 128. The random seed was fixed to 42 throughout the training process for both the Machine Learning Ensembles and TST to ensure reproducibility.\nB. Dataset\nThe train dataset from ETRI [24] contains sleep records for 508 days from 22 users. It includes sensor data measured by the e4 sensor and mobile devices, such as accelerometers, blood volume pressure, GPS, and gyroscopes, along with labeled activity information regarding the user's location and type of activity. The validation and test datasets, also provided by ETRI, consist of sleep data for 105 and 115 days, respectively, for each of the 4 users. These datasets include sensor data measured by Android OS watches and smartphones, including accelerometer, light sensor, heart rate, and GPS. While the train dataset was collected in 2020, the validation and test dataset was collected in 2023, differing in their collection times and many of the sensors used. Both the train and validation datasets were used to extract common sensor data, which helped develop a model with high interpretability.\nC. Results\nPredictions for Q1-Q3 were made using TST, followed by various modifications in the machine learning methodology S1-S4 predictions. The KNNImputer was utilized for handling missing values, and hyperparameters were optimized using grid search to enhance the performance of various classifiers. The data used in modeling, such as accelerometers, heart rate, activity, and GPS values, represent different types of data, which can have complex inherent relationships or vary in scale. Treating these heterogeneous data types similarly may have prevented finding appropriate neighbors. Replacing missing values by simply finding the nearest neighbors without considering temporal continuity led to a performance decrease to 5.92. Additionally, the performance slightly decreased to 6.08 after hyperparameter optimization, possibly due to overfitting caused by overly complex or deep model settings. Therefore, we reverted to using a basic model that replaces missing values with zeros and does not undergo hyperparameter tuning. The results are summarized in TABLE VI."}, {"title": "V. CONCLUSION", "content": "In this paper, we introduce TST regression and Machine Learning Ensembles to predict user emotions, stress, and sleep quality. TST regression enhanced the accuracy of regression predictions for columns Q1, Q2, and Q3 through unsupervised pre-training. Meanwhile, Machine Learning Ensembles facilitated accurate classification predictions for columns S1, S2, S3, and S4. Using the public test dataset from the competition, we achieved an F1-Score(Macro) of 6.10 on a scale of 10."}]}