{"title": "PROCEDURAL CONTENT GENERATION VIA GENERATIVE\nARTIFICIAL INTELLIGENCE", "authors": ["Xinyu Mao", "Wanli Yu", "Kazunori D Yamada", "Michael R. Zielewski"], "abstract": "The attempt to utilize machine learning in PCG has been made in the past. In this survey paper, we\ninvestigate how generative artificial intelligence (AI), which saw a significant increase in interest\nin the mid-2010s, is being used for PCG. We review applications of generative AI for the creation\nof various types of content, including terrains, items, and even storylines. While generative AI\nis effective for PCG, one significant issues it faces is that building high-performance generative\nAI requires vast amounts of training data. Because content generally highly customized, domain-\nspecific training data is scarce, and straightforward approaches to generative AI models may not\nwork well. For PCG research to advance further, issues related to limited training data must be\novercome. Thus, we also give special consideration to research that addresses the challenges posed\nby limited training data.", "sections": [{"title": "Introduction", "content": "Video games have been continuously advancing technologically from their inception to the present day. From the\nearly pixel-based games to modern high-resolution, physics-based rendering, the evolution of games has been remark-\nable. Amidst these technological revolutions, the approach to game content generation has also undergone significant\nchanges. The emergence of PCG has played a major role in this transformation.\nPCG is a technology that dynamically generates game content using algorithm-based methods Togelius et al. (2011a).\nBy \"content\" here, we refer to everything within the game, including terrain, characters, items, stories, music, and so\non. This technology is useful in reducing development costs by automatically generating content that would otherwise\nrequire a significant amount of human effort. For example, PCG is especially useful for small development teams,\nwhich may not have developers dedicated to generating content, and for large-scale open-world games, which require\nvast amounts of content. Moreover, it is an essential technique for roguelike games that offer different experiences,\nthrough unique and new content, with each playthrough.\nInitial approaches to PCG relied on simple randomization algorithms and fixed rule sets, but over time, PCG has\nbecome more sophisticated. Amidst this evolution, the 2000s saw a boom in artificial intelligence, spurred by advance-\nments in deep neural networks. While most developments have been in the realms of computer vision and natural\nlanguage processing, the applications of AI have expanded and it is now utilized in many fields. Notably, recent ad-\nvancements in AI, especially in machine learning, have further expanded the potential of PCG. Deep neural networks\ncontribute to the generation of diverse game content, from game environments and character behaviors to narrative cre-\nation. In the mid-2010s, generative AI gained significant attention due to highly influential developments in the field."}, {"title": "Prerequisites", "content": null}, {"title": "The Rise of Procedural Content Generation", "content": "PCG refers to the semi-automatic generation of in-game content using algorithms. These methods are designed to\nfunction with limited input or instructions. The scope of PCG encompasses everything within the game, including\nterrain, characters, items, stories, music, and more. While PCG is most often utilized to aid game development, there\nare also games that have been developed featuring PCG as a core element of their design.\nOne of the primary reasons for implementing PCG is to reduce the cost of content creation. Considerations include\nthe cost-saving perspective of disk space constraints on devices running the game, as well as the reduction of manual\nlabor involved in content generation by humans. For example, modern video games often encompass vast spaces\nfilled with various items and characters. Creating such expansive content might take hundreds of hours across many\ngame developers, which may be impractical for smaller development teams. PCG has the potential to reduce these\ndevelopment costs, allowing smaller teams to produce high-quality games that rival those produced by large studios.\nAnother reason for implementing PCG is to provide players with a novel content experience. For instance, in games\nlike roguelikes where the content changes with each playthrough, PCG is not just a tool to aid game development but\nan indispensable element. Thus, without PCG, games that rely on an extensive variety of unique content might not\neven exist. From the perspective of offering a novel content experience, there are instances where PCG is utilized to\ngenerate content that, due to its algorithmic nature, exceeds what is feasible by human developers.\nWhile PCG has been utilized for video game development from various standpoints, the earliest video game that\nemployed PCG was Rogue, developed in 1980. Rogue is a game where players explore dungeons, encountering various\nmonsters and obstacles while searching for treasures and leveling up. A distinctive feature of the game is that dungeon\nlayout, monster placement, and item appearance is randomly generated each playthrough. While the content generation\nalgorithm in Rogue primarily relies on randomness, rule-based algorithms supplement the randomly generated content\nto ensure consistency. For instance, the task of connecting rooms randomly generated on a map follows specific rules.\nGenerating content purely at random, without any constraints, could lead to issues with game balance or even result in\na non-functional game."}, {"title": "Procedural Content Generation and Artificial Intelligence", "content": "AI is an entity constructed on a computer that imitates human intelligence. Given such a definition, the randomness-\nbased content generation methods used in Rogue and subsequent roguelike games can be broadly considered a type\nof AI. The inclusion of human designed rules does not detract from this, as the rules are typically created to limit the\nspace of combinations of content and to guide the AI towards generating content that is meaningful and functional.\nHowever, with the evolution of video games, there has been a growing demand for more complex content generation\nand real-time content creation, among other requirements. To meet these needs, instead of relying solely on human-\ndefined rule-based methods, there has been increasing interest in using machine learning methods based on player\nbehavior and experience-derived data. Especially recently, with the booming interest in AI, various PCG methods\nincorporating the latest technologies are being devised.\nMachine learning methods create AI based on data. From the perspective of training AI, machine learning methods\ncan often be categorized into the following three types:\n1. Supervised learning,\n2. Unsupervised learning,\n3. Reinforcement learning.\nSupervised learning trains AI using a combination of input data and associated label data. The goal of supervised learn-\ning is to ensure that when new input data is fed into the constructed AI, it produces an appropriate label corresponding\nto that input. It can be used to predict continuous and discrete values, in the tasks of regression and classification,\nrespectively. Machine learning models that can be trained using supervised learning include neural networks, support\nvector machines, linear regression, decision trees, among others.\nUnsupervised learning refers to a method of training AI without the use of labeled data. Thus, in unsupervised\nlearning, the only data used to train the machine learning model is the input data. Typically, AI trained through\nunsupervised learning do not produce predictive values for given input data. Instead, these AI are often used to\ngrasp trends present in the given data. They are utilized for tasks such as clustering, which groups data with similar\ncharacteristics, visualizing high-dimensional data that might be incomprehensible through human capabilities, and\nextracting features from data. Algorithms used in unsupervised learning include k-means, hierarchical clustering,\nprincipal component analysis, neural networks, among others.\nReinforcement learning is a method of training AI by providing it with feedback called a reward, and optimizing the\nAI to maximize the accumulated value of rewards. In the field of reinforcement learning, this AI is referred to as\nan agent. The agent exists in some environment and learns to maximize the rewards it obtains through a series of\nactions. Algorithms used in reinforcement learning include Markov decision processes, dynamic programming, and\nQ-learning, among others.\nAs described above, there are several types of machine learning methods. Moreover, even within the same machine\nlearning method, various models exist. For instance, the support vector machine, which can be trained using supervised\nlearning, is a classical model used for solving regression and classification problems. On the other hand, within the\nsame supervised learning category, there are models used to construct generative AI, which generates data as if starting\nfrom a state with no input values. This generative AI experienced a boom in the mid-2010s, expanding the possibilities\nof AI. Another field that has been vigorously researched in recent AI studies, alongside generative AI, is reinforcement\nlearning."}, {"title": "Applications of Classical Machine Learning and Reinforcement Learning", "content": "Classical machine learning methods, other than generative AI or reinforcement learning, have been utilized in PCG\nresearch in various ways, as detailed in the prior survey paper (Summerville et al., 2018). Classical machine learn-\ning models include support vector machines, decision trees, principal component analysis, and many others. In the\ncontext of PCG, these models are sometimes used to interpret content generation as a kind of sequence. For instance,\nSnodgrass et al. employed Markov chains for PCG (Snodgrass and Onta\u00f1\u00f3n, 2014). In deep learning, there is a model\ndesigned to handle sequence data, long short-term memory, which is a type of recurrent neural network. Summerville\net al. utilized this architecture for PCG (Summerville and Mateas, 2016).\nReinforcement learning is currently being actively researched and developed, and various techniques are being devised\ndaily in the field of game research. For instance, deep Q-networks, which are deep reinforcement learning algorithms\nthat utilize deep neural networks, have demonstrated performance surpassing humans in certain games. In terms of\nreinforcement learning agents playing games, AlphaGo is the most renowned (Silver et al., 2016). AlphaGo is an AI"}, {"title": "Generative Artificial Intelligence", "content": "Machine learning models can be classified into discriminative models and generative models. Firstly, the discrimina-\ntive model is represented by the following equation:\n$f(x) = \\text{arg max}\\_y p(y|x).$ (1)\nwhere, $f$ represents the model, $x$ is the input data to the model, and $y$ is the output value from the model. In this\nmodel, the $y$ that maximizes the probability of occurrence when some data $x$ is given is determined. For instance,\nwhen considering a classification problem, $p(y|x)$ is the probability that $x$ belongs to class $y$.\nOn the other hand, the generative model is represented by the following equation:\n$f(x) = \\text{arg max}\\_y p(x|y)p(y).$ (2)\nIn this model, $p(y)$ represents the occurrence probability of $y$. Moreover, $p(x|y)$ represents the occurrence probability\nof $x$ when a class $y$ is given. In this model, it is considered that $x$ is generated based on some probability distribution.\nIt is also considered that this probability distribution varies for each class $y$. In other words, $p(x|y)$ can be interpreted\nas the probability that $x$ arises from the class $y$. In this model, the $y$ that maximizes this probability is identified.\nBoth of these models have the capability to be used for predictive purposes, and thus may seem similar. However, in\nthe generative model, the probability distribution for $p(x|y)$ is modeled. Therefore, using this probability distribution\nmodel, it is possible to generate new pseudo-data that belongs to the class $y$.\nA representative example of a generative model is the generative adversarial network (GAN). A GAN consists of a\nmodel called the generator, which generates data that belongs to the \"real\" class, and another model called the dis-\ncriminator, which determines the authenticity of the generated data. Additionally, diffusion models and large language\nmodels (LLMs) like ChatGPT can also be considered as generative models."}, {"title": "Types of Content", "content": "Games, as a form of interactive entertainment media, have significantly different content generation requirements\ncompared to non-interactive media. Most game content must be coherent, as the aesthetic generally suffers when\ncoherence is lacking (Liu et al., 2021).\nAdditionally, because different content types play distinct roles in the overall presentation of a game, their generation\nrequirements often vary greatly. Certain types of game content are crucial to the core gaming experience of players,\nsuch as level designs in most games and storyline generation in narrative-driven games. For these types of content,\nthe primary goal of content generation is to make sense, or to be playable, to the player. A secondary goal would\nbe to make content that is more entertaining. Other types of content may be less critical; assets like sprites of minor\ncharacters or textures for less significant scenes may be allowed to be imperfect for greater efficiency."}, {"title": "Game Environments", "content": null}, {"title": "2D Game Levels", "content": "Game levels are fundamental components of many games, particularly in genres like platformers, role-playing games,\nor rougelike games. While actual game levels often serve complex and varied purposes, in research related to proce-\ndural level generation, a level typically refers to a playable scene unit. Since related research usually distinguishes\nbetween 2D game levels and 3D terrain generation, the discussion in this section will not cover 3D games.\nThe most distinguished feature of game levels is their functional requirements. Unlike faces or sentences that can\nstill be understood even with generation errors, game levels that that block access to essential paths or objectives are"}, {"title": "3D Terrain", "content": "Terrain, often used in 3D open world games and sandbox games, refers to the topography in virtual environments,\ntypically represented by a heightmap.\nResearches on terrain modeling have spanned over thirty years, accumulating many classic methods. Fractal Subdi-\nvision, one of the oldest and most common procedural terrain generation techniques, generates terrain by recursively\nincreasing the resolution of the terrain and adjusting the height of each new point(Raffe et al., 2012). The terrains\nproduced by this method typically have a fractal, self-similar structure and details. Other mainstream or efficient pro-\ncedural terrain generation methods include evolutionary algorithms, erosion simulation, parameter-controlled methods,\nand user-assisted methods.\nIn the field of Generative AI, Gu\u00e9rin et al. presents a novel example-based authoring pipeline for generating realistic\nvirtual terrains using Conditional Generative Adversarial Networks (cGANs) (Gu\u00e9rin et al., 2017). They proposed that\nGANs offer significant advantages in terrain generation, including enhanced realism, user control, efficiency, learning\nfrom real-world examples, and ease of use, making them a superior choice over traditional terrain modeling techniques."}, {"title": "Art and Visual Assets", "content": null}, {"title": "Sprites", "content": "Sprites are graphic elements widely used in game development. They first appeared in early computer and video\ngames, and over time, they continue to play a crucial role in modern game development. Sprites can represent various\nactions of game characters (such as walking, running, jumping, etc.), where each action consists of multiple frames to\nachieve smooth animation effects. It can also be used as background elements in game scenes or as map tiles in 2D\ngames to create complex game environments. These individual sprites are often organized into sprite sheets, which\nconsolidate multiple small images into a single large image for efficient storage and rendering.\nAs project scales increase, the number of sprites also grows, making the management and maintenance of these in-\ndividual graphic elements increasingly complex. Adding new sprites, deleting old ones, or updating existing ones\nall require manual adjustments, which is not only time-consuming but also prone to errors. Moreover, for content\nthat needs frequent updates or dynamic loading, traditional methods of sprite management struggle to meet efficiency\nrequirements and demand more optimization and new technological solutions. This is particularly true when dealing\nwith sprite sheets, which are collections of individual sprites organized into a single image for efficient storage and\nrendering.\nIn recent years, there has been a growing interest in combining generative networks with sprites to find better methods\nfor improving the efficiency of image generation and processing."}, {"title": "Motion", "content": "In games, human movement, such as walking, running, and jumping, is driven by the skeleton that moves the torso\nand limbs. Skeletal animation is a method of 3D animation that uses a hierarchical set of interconnected bones to\nanimate a mesh or character model. It simulates the movement of bones to create realistic and efficient animations for\ncharacters and objects in games and other digital media. It breaks down characters into two parts: bones and the skin,\nand manipulates the bones to drive the movement of the skin. This method provides dynamic and lifelike movements\nfor characters and objects in games.\nCreating skeletal animations that adhere to anatomical and physical principles while also considering character person-\nality and emotional expression is a challenging aspect of animation production. Overall, skeletal animation presents a"}, {"title": "Character Face", "content": "Facial customization systems are a key feature in modern video games and virtual character creation, allowing players\nto design and customize the facial features of game characters according to their preferences. This system is widely\nused in role-playing games, simulation games, and social platforms. By utilizing generative networks, it is possible to\ngenerate personalized facial features based on player inputs and make adjustments to enhance player engagement.\nIn the process of character creation and animation, game developers often start with a base model known as a neutral\nface. These neutral face models are designed with minimal expression, serving as a blank canvas for further customiza-\ntion and animation. This approach allows developers to add various expressions and emotional portrayals on top of\nthis neutral base, ensuring consistency across different characters and animations.\nBy leveraging the adversarial training mechanisms in GANs, it is possible to effectively decouple expression parame-\nters from identity parameters. This decoupling allows the system to generate and manipulate neutral face characters\nwhile preserving the unique facial features of the characters. This capability is particularly valuable in facial cus-\ntomization systems, as it enables players to create distinctive characters that can express a wide range of emotions\nwithout losing their core identity features."}, {"title": "Narrative Components", "content": "Narrative components are the essential elements that complete a game. Well-crafted narratives can deeply engage\nplayers, providing motivation and context for their actions within the game world.\nNarrative in games comprise a story and discourse (Kybartas and Bidarra, 2017). A story is composed of plot and\nspace, where plot involves structured events, and space includes characters and settings. The other component of\nnarrative, discourse, determines how the story is presented.\nOne of the most recent research examples that resonates this definition is made by Park et al., who shows a revolution-\nary approach to narrative content in games using generative AI (Park et al., 2023). By creating AI-driven characters\nwith sophisticated memory and planning capabilities, the generative agents framework introduced in the paper enables\nthe emergence of dynamic, player-influenced narratives. These generative agents populate the game world, forming\nthe space of the narrative with their distinct personalities and behaviors. As they interact with each other and the envi-\nronment, they generate a plot filled with structured yet unpredictable events. The way these interactions unfold and are\nperceived by the player forms the discourse of the narrative. This AI-driven approach allows for a level of narrative\ncomplexity and responsiveness previously unattainable in games. Players can experience unique stories that evolve\norganically based on their choices and the autonomous decisions of the AI agents, leading to heightened immersion\nand replayability. By leveraging generative AI in this manner, game developers can create living, breathing worlds\nwhere every playthrough tells a different story, pushing the boundaries of interactive storytelling in the digital age."}, {"title": "Music and Sound Effects", "content": "Music and sound effects, while not essential for the core gameplay progression, are significant elements that greatly\nenhance the immersive experience of a game.\nTraditional sound synthesis methods have certain limitations in terms of generation quality, control over diversity,\nefficiency, and ease of use. Sampling synthesis methods require pre-recorded source materials, and then create sound\neffects by mixing and processing different layers of sound, which is time-consuming and labor-intensive. Procedural\naudio synthesis methods generate sound effects in real-time using mathematical models, but the generated sound\nquality is often poor and cannot match the quality of recorded sound effects. These traditional methods struggle\nto efficiently produce a sufficient number of sound effect variants, which fails to effectively reduce auditory fatigue\nduring gameplay, thereby affecting immersion.\nNew methods based on deep learning are attempting to address these issues. For example, Andreu and Aylagas\npresent a method for generating controllable variations of sound effects that can be used in the creative process of"}, {"title": "Methods for Generating Content", "content": null}, {"title": "Generative Adversarial Networks", "content": "GANs are a kind of generative model based on game theory(Goodfellow et al., 2020). GANs train two networks\nsimultaneously: a generator that creates fake data and a discriminator that classifies data as real or fake. The generator\naims to fool the discriminator, while the discriminator learns to distinguish between real and generated samples. This\nadversarial process continues as both networks improve over time.\nIn 2018, Giacomello et al. applied GANs to PCG for the game DOOM (Giacomello et al., 2018), which is a seminal\nfirst-person shooter where players navigate through a series of levels filled with demons and monsters, fighting to reach\nthe exit while collecting weapons, ammunition, and power-ups. The authors trained two GAN models using a dataset\nof over 1000 human-designed DOOM levels. The first model was an unconditional GAN using only images, while\nthe second was a cGAN that included additional topological features extracted from the levels. The authors analyzed\neach level to extract six types of images representing various features such as walls, floor height, and game objects.\nThey also extracted numerical and categorical attributes describing the topology of the level. The cGAN included a\nselection of seven features, such as the number of rooms and equivalent diameter. Their results demonstrated that both\nGANs could capture the intrinsic structure of DOOM levels, with the cGAN generating levels that were structurally\ncloser to human-designed ones. They evaluated the generated levels using custom metrics inspired by those used for\nindoor map quality assessment. This research shows that GANs can be a promising tool for procedural generation in\nfirst-person shooter games.\nSimilarly, Volz et al. also applied GANs to level creation, but for the game Super Mario Bros (Volz et al., 2018). In\nSuper Mario Bros, players must traverse a side-scrolling level to reach the end of the level, while avoiding dangerous\nterrain and enemies. In this work, the authors evaluated the ability of a GAN to generate content when trained on\na single sample level. Additionally, they also investigated how the latent space of the GAN could be searched with\nlatent variable evolution (LVE) to create levels with desired properties. The results showed that performing one-hot\nencoding on tile types provided sufficient information for the GAN to learn level structure. Furthermore, despite only\nusing a single training level, the model produced playable levels resembling those created by human designers. The\nexperiments with LVE showed that level content and properties could be controlled by modifying the fitness function\nof covariance matrix adaptation evolution strategy (CMA-ES). In their first representation-based approach, the fitness\nfunction depended upon the presence of certain types of tiles in the level. By varying the target tile counts, the authors\ncould accurately control the content in the level and craft a progressively harder experience. The second approach\nwas agent-based, and used a fitness function that examined the actions of an agent in a playthrough of the level. Their\nresults showed that this approach was also able to successfully vary the difficulty of a level. This work showed that\nGANS can be successfully trained even in cases with limited training data, and that LVE could be used to search the\nlatent space for levels with desired properties.\nInspired by the work of Volz et al. (Volz et al., 2018), Irfan et al.(Irfan et al., 2019) adopted a similar approach of\ngenerating game levels with GANs. However, one primary difference is the use of image-based data rather than tile\ntype-based data. The dataset used to train their model was itself generated using a random level generator. Additionally,\nthe authors generate levels for three games, namely, Freeway, Zelda, and Colourscape. These games were selected due\nto how challenging they are for game-playing agents, and are classified as, difficult, average, and easy, respectively.\nThe training process shows that while the model initially cannot generate valid levels, it eventually learns to do so,\nsupporting the use of image-based data for level generation. Finally, after evaluating the generated levels with a game-\nplaying agent, the authors observe that only less than 20% of the levels generated for each game are unplayable. By\nshowing that GANs can generate valid levels with image-based data, this study emphasizes the flexibility of GANs,\nand provides supporting evidence for their use in generating content for games.\nAn often-mentioned barrier to using GANs for PCG in games is the necessity of domain-specific training data. This\nneed is driven by the requirement for the GAN not only to generate usable content, but for the content to also have de-\nsired properties, such as realism. Wulff-Jensen et al. (Wulff-Jensen et al., 2018) study the generation of 3D landscapes\nwith GANs. As a core component of a 3D playable space, landscapes should contain a mixture of hills, mountains,\nravines, and other suitable features. While hand-crafted landscapes may be one of the first choices for training data,\nthey are scarcely available due to high development costs. Instead of using such data, Wulff-Jensen et al. train a\nGAN on digital elevation data from real locations in Norway and the Alps. One benefit of using data based on real\nlocations is the ability of a GAN to capture and generate features specific to individual locations. Another benefit is\nthe expected realism of generated content. Indeed, evaluators found the generated content to be acceptable realistic,"}, {"title": "Diffusion Models", "content": "A diffusion model is a Markov chain that adds random noise to existing data and then learns the reversed process to\ntransform the noise into structured outputs gradually. It uses neural networks to model Gaussian transitions, enabling\nit to generate samples matching the original data distribution(Ho et al., 2020).\nZhang et al. are one of the first to propose using diffusion models to generate human motion from text in-\nput (Zhang et al., 2024a). Their proposal, MotionDiffuse, offers many improvements over other types of models\nand architectures. First, motions are generated in a probabilistic way, leading to increased diversity over deterministic\ncounterparts. Second, the model learns a variety of movements and is able to accurately reproduce fine details from\ntext. Finally, the model coordinates signals for different body parts and allows time-varied instructions. Experimental\nresults show that MotionDiffuse is superior to existing methods in all metrics tested, and that movements generated\nare perceived to be more natural. The remarkable results of MotionDiffuse demonstrate the suitability of diffusion\nmodels for generation of complex content.\nGenerating long sequences of human motion is generally considered challenging, as many approaches result in unnat-\nural artifacts between repeated motions and a lack in motion diversity. Zhang et al. discuss the promising nature of\ndiffusion models, but note the challenges of long-term generation (Zhang et al., 2023). They propose a diffusion-based\nmodel in which they align the temporal-axis of the motion sequence with the time-axis of the diffusion process, com-\nbined with a buffer of frames of temporally-varying noise. This results in the ability to continuously produce clean and\nnatural frames of motion while allowing the model to explore realistic future movements through increasingly noisy\nframes. Additionally, guided generation is also possible by replacing frames with a set of guide frames, and allowing\nthe model to smoothly transition towards them. The evaluation shows that the proposal successfully generates natural\nlong-term motions.\nAnother significant work regarding the use of diffusion models in human motion generation was conducted by Tevet\net al., who introduced the Motion Diffusion Model (Tevet et al., 2023). It achieves state-of-the-art results in various\nhuman motion generation tasks while being more efficient and versatile than previous approaches. Motion Diffusion\nModel is a generic approach that can handle different types of conditioning like text and action classes, or even\nunconditioned generation, all within a single model. One of the most significant improvements of Motion Diffusion\nModel is its ability to incorporate geometric losses. Geometric losses refer to the loss functions used in human motion\ngeneration models to enforce physical properties and prevent artifacts. These loss functions encourage the generation\nof natural and coherent motions. In the paper, three common geometric losses are experimented with: positions, foot\ncontact, and velocities. By combining geometric loss functions with conventional generative loss functions, the model\nis designed to enhance the quality and realism of the generated motions. Using these loss functions in diffusion models\nis challenging but crucial for the motion domain.\nTo generate materials for computer graphics, Vecchio et al. propose MatFuse, an approach that uses diffusion models\nto generate spatially-varying bidirectional reflectance distribution function (SVBRDF) maps (Vecchio et al., 2024).\nThe novelty of their approach lies in the ability of MatFuse to use multiple sources of conditioning, including text,\ncolor palettes, pictures, and sketches. Additionally, conditions can be applied both at the global level, influencing\nhigh-level features of the material, and at the local level, influencing specific details of the material. These features\nof MatFuse enable a high degree of controllability in material generation. The effectiveness of MatFuse is evident\nthrough its performance in quantitative and qualitative evaluations, showing that it can compete with and surpass other\ngenerative models.\nDai et al. apply unconditional diffusion models to the task of level generation from single examples for Super Mario\nBros, a 2D game, and Minecraft, a 3D game (Dai et al., 2024). To overcome the challenges faced by many generative\nmodels and distinguish their proposal from others, the authors make several modifications to common practices. First,\ninstead of using one-hot encoded vectors to represent pieces in levels, the authors adopt a word embedding approach\nto represent pieces using dense continuously valued vectors. This modification proves to be more scalable and leads"}, {"title": "Transformers", "content": "The Transformer is a straightforward network architecture based solely on attention mechanisms, eliminating the\nneed for recurrence and convolutions(Vaswani et al., 2017). This architecture has revolutionized various aspects of\nAI, including natural language processing and content generation. Its ability to handle sequential data and capture\nlong-range dependencies has made it particularly useful in creative applications.\nCreating movies is a complex process that requires graphic animation rendering. In 2023, He et al. proposed an AI for\ngenerating videos from query texts (He et al., 2023). The AI constructed in this study searches for video candidates\nwith scenes and motions suitable for the query texts and then generates videos by combining them to follow the desired\nplot. Various machine learning technologies such as LLMs, Markov chains, and diffusion models have been applied\nto construct the AI proposed in this study. Although this research is not specifically focused on content generation in\nvideo games, its nature suggests that it could be easily applied to video games.\nSudhakaran et al. identify one of the main shortcomings of popular generative methods that rely on latent spaces,\nsuch as GANs; tunable generation can only be achieved through a costly search process (Sudhakaran et al., 2023).\nThey propose MarioGPT, a method that generates game levels for Super Mario Bros. By proposing an approach\nthat leverages the capabilities of LLMs trained on a diverse corpus, the authors overcome the limitations of latent\nspace-based methods. In terms of usability, the most significant improvement from this approach is tunable generation\nwithout the need for searching. This is enabled by the natural language nature of the LLM, allowing one to simply\nask for a desired result, rather than searching for it. Additionally, content quality also high, with the majority of levels\nbeing diverse and playable. This is a result of using a pre-trained LLM without adding unnecessary layers, such as\nadaptors. This work highlights the potential of LLMs for PCG, demonstrating simple usage with quality results.\nZhang et al. take a multi-modal approach to generating human motion (Zhang et al., 2024b). They approach human\nmotion generation by asking a transformer-based LLM to produce desired human motion from an instruction prompt.\nWhat makes their proposal unique, and multi-modal, is the inclusion of non-text pose information in the form of\ndiscrete codes learned by a vector quantized-variational autoencoder model (van den Oord et al., 2017). Their results\nindicate that the inclusion of pose information is the main factor responsible for the ability of their approach to surpass\nthe performance of other state-of-the-art approaches. They also find that including information of multiple poses\nthroughout a movement are more effective than that of initial or final poses. This work sets a precedent for multi-\nmodal approaches with LLMs and indicates additional improvements may be achieved through other types of data,\nsuch as audio."}, {"title": "Discussion", "content": null}, {"title": "Challenges in Procedural Content Generation for Generative Artificial Intelligence", "content": "In the area of PCG, generative networks face a series of challenges in the domain of visual assets. Firstly, a major\nissue is the lack of diversity; existing models often perform inadequately when generating visual assets of different\nstyles or types, resulting in outcomes that are neither rich nor diverse. Additionally, generating complex scenes and\nrichly detailed characters remains a significant challenge, especially when dealing with the creation of large-scale\ngame worlds. Current generative models may struggle to handle high-complexity visual content, and the generated\nvisual assets might fall short in terms of realism and aesthetic appeal, with noise issues potentially compromising the\nquality of the final results.\nSimilar issues also arise in game level generation. Since datasets for game levels often come from specific games,\ntheir training data is typically small in scale, which is insufficient for training effective generative AI. Additionally,\nlearning for game levels not only requires models to understand spatial relationships, so as to select appropriate tiles\nand terrains, but also player behavior logic. Learning this logic is necessary to create levels of varying difficulty as well\nas levels that require various skills. However, neural network models often struggle learning this, leading to content\nthat overly imitates training data.\nAnother challenge in PCG is the validation of generated content. While flawed content is undesirable, the effects of\nit on a game highly depend upon the flaw and type of content. For example, mismatched styles of tiles or colors in\na sprite may be visually unappealing, but do not necessarily change gameplay. On the other hand, a level generated"}, {"title": "Current Approaches to Procedural Content Generation With Generative AI", "content": "The works that we focus on use different techniques for generation, and there is a clear pattern in their usage over time.\nInitially, GANs were popular as they were a breakthrough in generative neural networks. Later, when diffusion models\nand transformers were proposed, they demonstrated significant improvements and gained popularity. Compared to\nGANs, diffusion models often exhibit more stable training, fewer problems with convergence, and higher quality\nresults. For transformer models, the primary advantage is being able to query a model in natural language. This\ntrend indicates that breakthroughs in neural network technologies result in rapid changes to state-of-the-art methods,\nsuggesting that developers must be flexible when using generative AI methods.\nOne common factor among many papers is a combination of techniques and algorithms to produce a generative AI\nsystem. For example, a standard GAN alone may not produce desired output every time the generator is used to\ngenerate content. This may be improved through the use of a cGAN, in which output can be influenced. However,\nrepeating the generation process is still not guaranteed to produce output with specific features. To address this, the\nlatent space can be searched with an optimization method, resulting in in a guided search that gradually becomes\ncloser to the desired output (Volz et al., 2018). This work demonstrates that a combination of effective techniques,\nalgorithms, and models is key to high quality generative AI.\nIt is worth noting that generative AI is typically constructed using supervised or unsupervised machine learning meth-\nods, which differ from reinforcement learning. Generative AI is built by learning rules encapsulated within vast\namounts of data, while reinforcement learning involves providing predefined rules and constructing AI that can oper-\nate in accordance with those rules. In the context of PCG, if one can generate vast amounts of data, it seems beneficial\nto use generative AI. On the other hand, if there is not an abundance of learnable data available, it might be more\nappropriate to utilize reinforcement learning. This distinction offers a potential guideline for choosing between the\ntwo methods based on the data at hand."}, {"title": "Potential of Generative Artificial Intelligence as Game Mechanics", "content": "The potential of procedural content generation is not just limited to increasing the efficiency of game development, but\nalso includes using it as game mechanics to enhance the experience or even create brand new types of gameplay.\nGenerative AI shows great capability in narrative creation, where non-player characters (NPCs) can be set with diverse\ncharacteristics and speak as their personalities dictate. With recent advancements in nature language processing,\nsimilar ideas have been gradually applied to games such as Treacherous Waters Online and The Portopia Serial Murder\nCase. In the former, every NPC in the main town is given a unique personality and uses the ChatGPT pre-trained model\nto converse with players in real time. In the latter, the boundaries of text adventure games are broken, allowing players\nto gather information and solve cases by \u201cconversing\u201d with related characters, rather than selecting predetermined\ndialogue options. These attempts represent the frontier of transforming narrative interaction in games, and are worthy\nof deep exploration by game designers.\nUser-Generated Content (UGC) refers to any form of content, such as text, images, videos, and reviews, that is created\nand shared by users of a platform or service rather than by its official administrators(Kasapakis and Gavalas, 2017).\nThe concept of UGC has garnered significant attention in recent years due to its success in party games like Eggy\nParty. The technology of generating game content through Generative AI can play a special role in the development\nand design of UGC editors. While traditional UGC editors provide game users with crafted assets for tasks such as"}, {"title": "Future Developments for Generative AI in Procedural Content Generation", "content": "Considering recent developments in generative AI for PCG, we expect that future developments will be focused on\nhigher quality content and ease of use. Higher quality content, while an important and natural direction, is not neces-\nsarily easily achievable and is attempted through different approaches. Equally important is ease of use. Generative\nAI that is hard to implement, train, or use, will not see widespread adoption in industry.\nOne approach to improving the quality of generated content is to combine multiple technologies. Indeed, this is\nalready common to some extent in existing papers. For example, exploring the latent space of a GAN with search\nalgorithms is used to find content that matches strict criteria. Another example is combining multiple types of neural\nnetworks to create generative AI that takes multi-modal input influencing generated content. These examples show\nthat combinations of technologies are necessary for creating content with specific details. We expect there will be\nfuture research focusing on combining state-of-the-art techniques from various fields.\nAnother factor that influences the quality of content is the size and amount of training data. While many applications\nof PCG in games note the challenges faced by limited training data, this is not a challenge that is unique to games.\nFor example, AI in medicine frequently faces limited data, especially for rare diseases. A solution that is commonly\napplied during training is data augmentation, which slightly transforms training data. These augmentations are key to\nimproving performance and preventing overfitting. Despite being frequently used in other fields, few papers mention\ndata augmentation when training models for PCG. One reason for this may be the lack of meaningful transforms for\ngame data. As an example, a vertical flip is a basic data augmentation in image classification. However, vertically\nflipping images, such as game levels, may not be appropriate for games as it can transform data into a form that is\nunnatural and would never be encountered otherwise. Therefore, because data augmentation has shown promise in\nother fields, we expect more researches to address the limits of training data size by evaluating the effectiveness of\ndata augmentation and developing unique transformations for game data.\nLastly, ease of use is an important practical concern that significantly affects the usage of techniques by practitioners.\nModels that require significant training or interaction may offset the time saved from using PCG techniques, potentially\ndiscouraging developers. One significant breakthrough in this area is transformers and LLMs, which allow developers\nto prompt a model, in natural language, for desired content. Generative AI using these models not only understand\nspecific details conveyed through language, but are also easy to use. In the future, we expect more models to include\ntext input and feedback mechanisms."}, {"title": "Conclusion", "content": "This paper explores the application of generative AI to Procedural Content Generation, focusing on three primary meth-\nods: Generative Adversarial Networks, Transformers, and Diffusion Networks. The application of these generative\nmodels in various PCG scenarios is summarized, offering insights for game developers and researchers.\nGANs demonstrate a wide range of applications in generating high-quality game environments, characters, and sounds.\nHowever, they continue to face challenges with result instability and noise, necessitating further optimization. Trans-\nformers excel in handling long sequential data due to their self-attention mechanism, making them particularly suitable\nfor tasks such as movie production, game level generation, and human action generation. Their ability to produce co-\nherent and logical content is a significant advantage in these contexts. Diffusion modeling, an emerging technique that\ngenerates high-quality data through gradual noise addition, shows remarkable capabilities in human action generation,\nmaterial creation, and game level design. Its potential in PCG applications is becoming increasingly evident.\nGenerative AI provides diverse methods for PCG, showing potentials and research gaps for researchers or game de-\nvelopers to dig deeper into. Future research should focus on not only improving the models, but also other parts like\nvalidating the content, training the dataset and balancing the demand for computing resources and the user experience."}, {"title": "Author Contributions", "content": "All authors conducted the survey, contributed to manuscript writing, and approved the final version of the manuscript."}]}