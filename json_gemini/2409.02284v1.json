{"title": "Biochemical Prostate Cancer Recurrence Prediction: Thinking Fast & Slow", "authors": ["Suhang You", "Sanyukta Adap", "Siddhesh Thakur", "Bhakti Baheti", "Spyridon Bakas"], "abstract": "Time to biochemical recurrence in prostate cancer is essential for prognostic monitoring of the progression of patients after prostatectomy, which assesses the efficacy of the surgery. In this work, we proposed to leverage multiple instance learning through a two-stage \"thinking fast & slow\" strategy for the time to recurrence (TTR) prediction. The first (\"thinking fast\") stage finds the most relevant WSI area for biochemical recurrence and the second (\"thinking slow\") stage leverages higher resolution patches to predict TTR. Our approach reveals a mean C-index (Ci) of 0.733 (0 = 0.059) on our internal validation and Ci = 0.603 on the LEOPARD challenge validation set. Post hoc attention visualization shows that the most attentive area contributes to the TTR prediction.", "sections": [{"title": "1 Introduction", "content": "In 2020, more than 10 million new male cancer cases were diagnosed, with prostate cancer (PC) ranking second to lung cancer [18]. Currently, PC clinical treatment relies on prostatectomy targeting prolonged life expectancy. However, up to 40% of PC patients would experience biochemical recurrence of the prostate-specific antigen within 10 years [15,6,17].The Gleason score [8] has been ranking PC on different risk grades, based on morphological features, albeit its limitations lead to recurrence rate differences within the same grade [5].\nRecently deep learning methods [14,4] have targeted superior biochemical recurrence prediction to the Gleason score, relying on the analysis of digitized histological images of tissue microarrays, rather than whole slide images (WSIs).A common solution to analyze WSIs is by partitioning them into smaller patches, notwithstanding the challenge of obtaining patch-level annotations. Along these lines, multiple instance learning (MIL) [2] has become prominent in computational pathology for many applications [7], as it encapsulates features from individual patches of the same WSI as a bag [16], reducing the patch-level labeling requirement and transforming it into a weakly-supervised learning problem with known bag/WSI-level labels. Direct risk prediction has been proposed in [11] by"}, {"title": "2 Material", "content": "We developed our model using the LEOPARD challenge training set (508 cases). We used all training data for our 2nd stage (Sec. 3.2), and excluded 30% for our 1st stage (Sec. 3.1) by setting the time threshold T = 1.65, where cases with $e_i = 0$ (no recurrence) and $t_i$ (follow-up years) < T are excluded. For both stages, the split ratios for training, validation, and testing were 64%:16%:20%. UNI was used as the feature extractor, including its pre-trained weights [3].\nOur final model was submitted to the LEOPARD Challenge validation and testing phase. The validation set comprised 49 cases from 'Radboud' and 50 cases from external sources. The testing set was hidden from challenge participants."}, {"title": "3 Methods", "content": "Our proposed method consists of two MIL-based stages (Fig. 1). The 1st stage (\"thinking fast\") targets classification at a low WSI resolution (\u2248 16mpp, \u2248 0.625Xmagnification), and the 2nd stage (\u201cthinking slow\") focuses on regression at a high resolution (\u2248 0.25mpp, \u2248 40Xmagnification). This approach targets improved patch sampling/pooling and inference efficiency. CLAM [13] was used for pre-processing (WSI patching and excluding background).\nIn the 1st stage we extracted non-overlapping patches (224 \u00d7 224), whereas patches in the 2nd stage were of size 2048\u00d72048 with 75% overlap (step size=1024). These were embedded in lower dimensional spaces through UNI and used for classification (recurrence or not) in stage 1, and for TTR regression in stage 2."}, {"title": "3.1 Thinking Fast: MIL Classification at Low Resolution", "content": "The 1st stage intends to facilitate the rapid selection of WSI areas with the largest contribution to the TTR prediction, given a particular time threshold T. Its goal is reduced inference time and increased performance of the proposed approach. The recurrence of the WSI is defined as:\n$Y|_{t=T} =\n\\begin{cases}\n0 & \\text{if } \\sum_{i=1}^{N} y_i = 0\\\\\n1 & \\text{otherwise}\n\\end{cases}$"}, {"title": "3.2 Thinking Slow: MIL Regression at High Resolution", "content": "Following the work of [11], the \u201cthinking slow\" stage is the regression task of predicting the patient risk R for biochemical recurrence. This risk is inversely related to TTR. Thus, the output layer is described by a Cox Proportional Hazard [9] (CPH) layer, which is a single node and outputs the logarithmic risk h(S) of a WSI feature embedding S = {f1, f2, ..., fN}. The WSI feature embeddings are extracted from patches selected by the mask of the \"thinking fast\" stage, after being pooled and aggregated for regression.\nIn the CPH model, the risk $R(S) = e^{h(s)}$ is estimated by the linear function $\\hat{h}_\\beta(S) = \\beta^T \\cdot S$. In Cox regression, the weights \u03b2 are optimized by the Cox partial likelihood, which is defined as:\n$L(\\beta) = \\prod_{i:=1} \\frac{e^{h_S(S_i)}}{\\sum_{j:R(t_i)} e^{h_S(S_j)}}$,\nwhere $e_i$ is the event status (recurrence: 1, or not: 0) at follow up $t_i$ (in years), and $S_i$ is the WSI embedding. $R(t_i)$ indicates that the patient, whose input is"}, {"title": "3.3 Model Training, Evaluation & Selection", "content": "We used the Adam optimizer with a learning rate of 1 \u00d7 10-4. The weight decay was 1 \u00d7 10-5 and the dropout rate was 0.25. Models were trained and evaluated on NVIDIA A100 GPUs during model selection. Our source code is based on the CLAM platform and the tiffslide library.\nTo select the best trained \"thinking fast\" model, we set up a 5-fold cross validation with a fixed test set and select the best fold as the model. The metric is the AUC of prediction on biochemical recurrence. For the \u201cthinking slow\u201d model, we use another 5x5-fold nested cross-validation without a fixed test set. In the outer fold, the hold-out set is used for validation of each inner fold. In each inner fold, the hold-out set is used to select the model for validation on the outer fold hold-out set, where the best inner hold-out validation loss is the criterion during training. The metric we used for model selection is the censored concordance index [19] (Ci) of the outer hold-out set. In our setting, 25 Ci are calculated for one parameter setting (e.g., topk = 10 and m = 20%). In the experiments, we evaluated the model with combinations of topk = {5,10,15, 20, 30, 40, 50} and m = {5%, 10%, 15%, 20%, 25%, 30%, 35%, 40%}. We select the model parameters by comparing the best mean and standard deviation (\u03c3) of Ci.\nFor the model submission to the LEOPARD challenge, we randomly split the data into a 10-fold cross-validation without a testing set and used the best model weights from each fold. The final prediction of TTR is calculated by averaging the predicted logarithmic risk from each set of model weights. We select model weights in each fold, based on the best hold-out validation loss, after 40 epochs. This 40-epoch threshold is set by calculating the zero-crossing epoch of the second derivative of the training loss curve to avoid under-training."}, {"title": "4 Results", "content": "For the internal data splits (Sec. 2), we selected the best performance with parameter settings topk = 10 and m = 20%. Our proposed approach yielded a mean C-index of 0.733 (\u03c3 = 0.059) on our test data (i.e., the outer hold-out set), indicating superior performance compared to MAD-MIL [12] (0.704 \u00b1 0.058) and AC-MIL [21] (0.714 \u00b1 0.056) with regression modifications.\nOur inference pipeline container submitted in the LEOPARD validation phase, yielded a C-index (Ci) of 0.603 (CiRadboud = 0.616, Ciexternal = 0.589).\nAs shown in Fig. 2 (A), we compare the results of different combinations of topk over m percentage values (x axis). The upper plots show mean Ci (y axis) of the outer hold-out set, while the lower plots show their corresponding standard deviation. The best overall result was observed for topk = 30 and m = 10%. We also observed that using a larger area of the WSI for regression does not always achieve better prediction, which in turn proves that a more relevant area of the WSI provides more accurate features for TTR regression and increases inference efficiency. This phenomenon can also be observed for the other two ablation methods, MAD-MIL and AC-MIL (Fig. 2(B)), where the selected method demonstrates a better regression prediction across almost all m parameters when fixing other parameters."}, {"title": "5 Interpretability", "content": "In the first stage, the patch selection criterion is the highest attention score (Fig. 1) of the attention map, which serves as an interpretability visualization for previous classification works. It show the most attentive area for the stage one classfication. Shown in Fig. 3, in our second stage, the attention scores are sparsely distributed on the WSI since only a small portion of patches (10%) are selected. Those color-highlited area also shows the most attentive region for TTR regression. In general, our method leverages the attention mechanism, but further clinical interpretablity requires to be evaluated from clinicians/pathologists."}, {"title": "6 Discussion", "content": "In this study, we proposed to leverage MIL through a two-stage \"thinking fast & slow\" strategy for the TTR regression. The first \"thinking fast\" stage aims to find the most relevant area of the WSI to the biochemical recurrence and the second \"thinking slow\" stage leverages higher resolution patches to predict the TTR. In the ablation result, we have shown that an improved prediction can be achieved by focusing on a more relevant area of the WSI along with an improved prediction efficiency. We also showed that the regression is affected by areas of attention which contain cancerous tissues. The limitation of our method is from the CPH model, which focuses on the risk prediction, not the real TTR. In the future, we will extend our work to other tumor types."}, {"title": "7 Code Link", "content": "The source code of our inference pipeline is available at https://github.com/\nyousuhang/IU-ComPath-LeoPard."}]}