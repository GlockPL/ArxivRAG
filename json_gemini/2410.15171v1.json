{"title": "Linguistic Fuzzy Information Evolution with Random Leader Election Mechanism for Decision-Making Systems", "authors": ["Qianlei Jia", "Witold Pedrycz"], "abstract": "Linguistic fuzzy information evolution is crucial in understanding information exchange among agents. However, different agent weights may lead to different convergence results in the classic DeGroot model. Similarly, in the Hegselmann-Krause bounded confidence model (HK model), changing the confidence threshold values of agents can lead to differences in the final results. To address these limitations, this paper proposes three new models of linguistic fuzzy information dynamics: the per-round random leader election mechanism-based DeGroot model (PRRLEM-DeGroot), the PRRLEM-based homogeneous HK model (PRRLEM-HOHK), and the PRRLEM-based heterogeneous HK model (PRRLEM-HEHK). In these models, after each round of fuzzy information updates, an agent is randomly selected to act as a temporary leader with more significant influence, with the leadership structure being reset after each update. This strategy increases the information sharing and enhances decision-making by integrating multiple agents' evaluation information, which is also in line with real life (Leader is not unchanged). The Monte Carlo method is then employed to simulate the behavior of complex systems through repeated random tests, obtaining confidence intervals for different fuzzy information. Subsequently, an improved golden rule representative value (GRRV) in fuzzy theory is proposed to rank these confidence intervals. Simulation examples and a real-world scenario about space situational awareness validate the effectiveness of the proposed models. Comparative analysis with the other models demonstrate our ability to address the echo chamber and improve the robustness.", "sections": [{"title": "I. INTRODUCTION", "content": "FUZZY information opinion dynamics can help us predict and explain the evolution of social phenomena, such as the formation of public opinion, policy-making, and market fluctuations [1]. The related research provides important insights for the development of effective policies and management strategies [2], [3].\nIn general, the fuzzy opinion dynamics models are mainly divided into binary models [4] and continuous models [5]. Binary models mainly include the voter model [6], the Sznajd model [7], and the majority-rule model [8]. These models are advantageous due to their simplicity, intuitiveness, and applicability to large-scale group simulations and analyses. However, they also have limitations, as overly simplified models may fail to accurately capture variations in evaluation information within a continuous range and overlook complex interactions and information exchange among agents. Continuous models mainly include the DeGroot model and the bounded confidence model. The DeGroot model is based on the principle of linear weighted averaging, assuming that agents gradually adjust their evaluation information based on the consistency with the information of their neighbors until consensus is reached [9]. The advantage of this model lies in its simplicity and intuitiveness, making it easy to understand and implement. However, it assumes that all agents can accept and adopt the opinions of others, overlooking the complex interactions between agents. The bounded confidence model introduces the concept of \"bounded confidence,\" where agents only interact with neighbors holding similar opinions and update their own evaluation information only when their confidence exceeds a certain threshold [10]. The HK model is a typical representative of the bounded confidence model, which considers differences in confidence between agents, making it closer to real-world scenarios and possessing good mathematical properties [11]. However, the bounded confidence model also has some drawbacks, such as sensitivity to parameter settings, and may fail to capture complex dynamics of fuzzy information change in certain situations [12]. Additionally, the majority of opinion dynamics models are applicable in numerical environment. However, in the real-world situations, linguistic fuzzy expressions, such as \u201cgood\u201d and \u201cpoor\u201d, often align better with our natural way of communication [13], [14]. Considering the above, detailed research on linguistic opinion dynamics models is necessary.\nIn research related to information evolution, leadership has attracted attention. The current research about leadership is divided into three main parts. First is the analysis of the impact of leaders on the evolution of the opinion [15]. The second part is the consideration of different methods to model social agents [16]. Another part involves combining the leader-follower architecture with different types of opinion dynamics models [17], [18]. These methods based on the leadership mechanism provide a new perspective for studying uncertain information evolution. However, the traditional opinion dynamics models considering the leadership mechanism face three main limitations: (1) Usually, studies predetermine the identity of leaders based on specific criteria. Typically, individuals with higher centrality in social networks or those with significant personal prestige and reputation are identified as leaders. However, this approach overly simplifies leadership, which should be context-dependent and not solely determined by static indicators such as centrality or reputation. (2) Many studies assume that the leaders remain unchanged throughout the opinion update process. This approach simplifies the construction and analysis of models but overlooks a vital reality: in actual systems, the identity and influence of leaders are dynamic. For example, leadership within an organization can change due to individual abilities, support from team members, or changes in the external environment. The static setting of leaders leads to models that cannot accurately reflect the actual dynamics of the system, especially when dealing with complex systems or rapidly changing environments. (3) If the leaders remain unchanged or only change slightly, it will affect the model's robustness and significantly reduce the accuracy of the final results. When leaders provide the linguistic fuzzy information, it is usually based on their subjective knowledge and judgment. However, leaders can inevitably hold subjective biases or unintentionally provide incorrect information, significantly increasing the risk of subjectivity in the information. Due to the traditional mechanism for setting up leaders, this risk is difficult to avoid.\nMotivated by the challenges mentioned above, this paper aims to propose three new linguistic fuzzy information evolution models based on the per-round random leader election mechanism (PRRLEM). The idea comes from a recent study published in Nature Physics [19], which revealed that sheep can exhibit collective wisdom through random, alternating leadership behavior. After each grazing session, a sheep is randomly chosen as the leader, and others follow in succession, with this leadership structure resetting after each feeding cycle. The advantages of this mechanism are the ability to provide efficient collective decision-making and adaptive advantages for the system. The system can flexibly adjust leaders in different situations through random, alternating leadership behavior, thus avoiding over-reliance on a single leader and reducing the impact of leader single-point failures on the system. Additionally, this mechanism promotes diversity and sharing of fuzzy information within the system, as each collective movement integrates opinions and experiences from different agents. Based on this mechanism, this paper proposes three new models: the PRRLEM-DeGroot model (PRRLEM-DeGroot), the PRRLEM-homogeneous HK model (PRRLEM-HOHK), and the PRRLEM-heterogeneous HK model (PRRLEM-HEHK). Moreover, considering that the results of some models will be significantly different with different parameter settings, this paper employs the Monte Carlo method and confidence intervals to address the randomness and uncertainty inherent in fuzzy information. Finally, a new golden rule representative value (GRRV) is proposed to rank the opinions. To our knowledge, no scholars have employed PRRLEM, Monte Carlo method, and GRRV to study the linguistic fuzzy information evolution. Simulation examples and a real-life case have validated the effectiveness of the three algorithms proposed in this paper. A detailed comparison further confirms that the proposed algorithms have higher accuracy and robustness and can also effectively address the issue of echo chambers in information dissemination.\nThe structure of the paper is as follows: In Section II, the three new fuzzy information evolution models are proposed. In Section III, a series of examples are presented. In Section IV, a detailed comparison analysis is conducted. The conclusion is given in Section V."}, {"title": "II. MODELS AND DEFINITIONS", "content": "In this section, we propose the PRRLEM-DeGroot, PRRLEM-HOHK, and PRRLEM-HEHK, complete with detailed operational steps and pseudocode for each."}, {"title": "A. PRRLEM-DeGroot", "content": "The traditional DeGroot model shows certain limitations in simulating opinion formation, primarily due to the uniqueness of the final results. To address this issue, we introduce a random leadership mechanism [19] to enhance decision-making diversity. The algorithm steps are as follows:\nStep 1: Initialization\nIn daily life, using linguistic terms such as \"good\" and \"bad\" for expression more closely aligns with our living habits. Therefore, scholars proposed the concept of linguistic term set (LTS). It is a structured collection of linguistic terms, essentially descriptive labels, used to express judgments, opinions, or values in a way that mimics natural language. An LTS typically consists of a finite and ordered set of terms $H = \\{h_{\\xi}|\\xi = 0,1,\\ldots,2\\Phi,\\|\\Phi\\in N^*\\}$ [20] (Typically, the number of linguistic terms is odd). For two linguistic terms $h_i$ and $h_j$, it should satisfy the four constraints: (1) $h_i \\leq h_j$ if and only if $i < j$; The negation operation $neg(h_i) = h_j$ if $i+ j = 20$; (3) If $i > j$, then $max\\{h_i,h_j\\} = h_i$; (4) If $i \\geq j$, then $min\\{h_i,h_j\\} = h_j$. In this study, the total number of agents is N, with each agent $e_i$ having an initial linguistic opinion $K_i(t)$ at time $t = 1$. The number of Monte Carlo tests is M, and the iteration number in opinion dynamics is T.\nStep 2: Opinion Conversion\nAfter obtaining linguistic fuzzy information, we first need to convert this information into corresponding specific numerical values to facilitate further information updates and analysis. The following transformation is widely used [21].\n$\\theta_{\\xi} = \\begin{cases}\\frac{\\alpha\\Phi\\alpha^{\\Phi-\\xi}}{2\\alpha-2}, & 0 \\leq \\xi < \\Phi\\\\\\frac{\\alpha+\\alpha^{\\xi-\\Phi}-2}{2\\alpha-2}, & \\Phi < \\xi \\leq 2\\Phi\\end{cases}$ (1)\nwhere $\\theta_{\\xi} \\in [0, 1]$. The maximum value of $\\theta_{\\xi}$ is 1, obtained when $\\xi$ is $2\\Phi$, and the minimum value is 0, obtained when $\\xi$ is 0.\nStep 3: Weight Allocation\nAs previously analyzed, to ensure collective wisdom and avoid over-reliance on a single leader, we randomly select an agent j as the leader and assign it a random weight $w_j \\in [0,1]$ when these agents update their information.\n$\\omega_j \\sim Uniform (0,1)$ (2)"}, {"title": "", "content": "The weight of the remaining agents is:\n$\\omega_k = \\begin{cases}\\frac{1- \\omega_j}{N-1} & k \\neq j \\\\ \\omega_j & k = j\\end{cases}$ (3)\nApart from the randomly selected leader, the weights of the remaining followers are the same in the opinion update.\nStep 4: Opinion Update\nIn the DeGroot model, the agents do not have bounded confidence and trust all the agents. According to [22], [23], the numerical value of $e_i$'s opinion at time t + 1 is:\n$y_i(t+1) = \\omega_j y_j(t) + \\sum_{k=1, k\\neq j}^{N} \\omega_k y_k(t)$ (4)\nActually, when $y_i(t + 1) \\geq 1$, $y_i(t + 1)$ exceeds the domain range, and $y_i(t+1) \\geq 1$ takes the maximum value of the entire domain, which is $h_{2\\Phi}$. Similarly, when $y_i(t + 1) \\leq 0$, it also means $y_i(t+1)$ exceeds the domain range, and therefore $y_i(t + 1)$ takes the minimum value of the entire domain, which is $h_0$. When $y_i(t+1)$ is within the domain, we need to calculate the distance between $y_i(t+1)$ and each linguistic term in $H = \\{h_{\\xi}|\\xi = 0,1,\\ldots,2\\Phi, |\\Phi\\in N^* \\}$, and the term closest to $y_i(t+1)$ will be recorded as the linguistic opinion $K_i(t+1)$ after opinion update. The linguistic expression of $y_i(t+1)$ can be obtained:\n$K_i(t+1)=\\begin{cases}h_{2\\Phi}, & y_i(t+1) \\geq 1;\\\\argmin_{\\theta_{\\xi}\\in H} \\|y_i(t+1) - \\theta_{\\xi}\\|, & 0 < y_i(t+1) < 1; \\\\ h_0, & y_i(t+1) \\leq 0.\\end{cases}$ (5)\nStep 5: Iterative Simulation and Result Recording\nRepeat the process from Step 2 to Step 4 within the framework of opinion dynamics. In each iteration, we simulate the interactions of N agents to model the opinion evolution, continuing until the number of iterations T is reached, completing a round of the Monte Carlo test. At the end of this round, we record the final opinions of the N agents as $K_i(T)$. To ensure the robustness and reliability of the results, repeat the Monte Carlo test M times, each time independently simulating the evolution of agents' opinions. We then record the linguistic terms $h_{\\xi}$ that occur in the entire Monte Carlo tests and then count the number of times, denoted as $Q_{\\xi}$.\nStep 6: Monte Carlo Analysis\nAfter obtaining the number of times of each opinion, the next step involves conducting a mathematical analysis to determine the final results. Therefore, we calculate each opinion's proportion $p_{\\xi} = \\frac{Q_{\\xi}}{MN}$. Choose a confidence level (commonly used is 95%) corresponding to a confidence coefficient Z (for a 95% confidence level, Z \u2248 1.96) [24]. The confidence interval is:\n$CI_{\\xi} = p_{\\xi} \\pm Z \\cdot \\sqrt{\\frac{p_{\\xi}(1 - p_{\\xi})}{MN}}$ (6)\nThe confidence interval provides an interval estimate for each opinion. The width of the confidence interval reflects the uncertainty in the estimated probability of an event occurring, with a narrower confidence interval indicating higher estimation precision, while a wider confidence interval suggests more significant uncertainty. At the same time, a higher midpoint of the confidence interval indicates a higher estimated probability of the corresponding event occurring.\nStep 7: Confidence Intervals Ranking and Results Determination\nAfter obtaining the confidence intervals, the next step involves comparing different values to determine the most likely opinions of each agent. This task essentially compares and ranks different confidence intervals. Researchers have employed various methods to address this issue, including sorting based on the midpoint of confidence intervals, the width of confidence intervals, and the degree of overlap between confidence intervals. However, these methods have limitations. For instance, sorting solely based on the midpoint of confidence intervals may overlook the estimate's uncertainty, while sorting based on the width of confidence intervals may neglect the actual size of the estimate. To overcome these limitations, we employ the golden rule representative value (GRRV) proposed by Yager [25].\nBefore that, it is necessary to introduce the GRRV. The principle of GRRV is to assign a representative scalar value, recorded as $Rep(x_i)$, to each interval $x_i = [a_i, b_i]$, $a_i, b_i \\in [0,1]$ [25], [26]. Usually, $x_i$ is considered to be preferred over $x_j$ when $Rep(x_i) > Rep(x_j)$. To obtain the representative value, the following rules are defined [25].\nRule 1: IF $m_i$ is large and $r_i$ is small, THEN $Rep(x_i) = 1$;\nRule 2: IF $m_i$ is large and $r_i$ is large, THEN $Rep(x_i) = 1/2$;\nRule 3: IF $m_i$ is small and $r_i$ is large, THEN $Rep(x_i) = 1/2$;\nRule 4: IF $m_i$ is small and $r_i$ is small, THEN $Rep(x_i) = 0$.\nwhere $m_i = (a_i+b_i)/2$ and $r_i = b_i - a_i$ indicate the mean and range of these intervals. large and small are linear fuzzy sets L and S. L(y) = y and S(z) = 1 \u2212 z are set in [25].\nTo derive the representative value, the TSK fuzzy model is employed. For a TSK fuzzy system with d inputs, 1 output, and K rules, the fuzzy rules are [27], [28]:\nRule k: IF $q_1$ is $A_1^k$ AND $q_2$ is $A_2^k$ AND \u2026 AND $q_d$ is $A_d^k$; THEN $y_k(Q) = p_0^k + p_1^k q_1+\u2026\u2026+ p_d^k q_d$.\nwhere Q = {$q_1, q_2, \u2026, q_d$} indicates the predecessor variables. $A_q^k$ represents the fuzzy set of $q_a$ in Rule k. $y_k(Q)$ is the post-component variable. When the input is Q = {$q_1, q_2, \u2026, q_d$}, the output is:\n$y = \\frac{\\sum_{k=1}^{K} y_k(Q) \\prod_{q=1}^{d} A_q^k (q)}{\\sum_{k=1}^{K} \\prod_{q=1}^{d} A_q^k (q_q)}$ (7)\nBased on (7), the representative value of $x_i = [a_i, b_i]$ can be derived.\n$Rep(x_i) = \\frac{m_i(1-r_i) + \\frac{1}{2}m_ir_i + \\frac{1}{2}(1-m_i)r_i + 0(1-m_i) (1 - r_i)}{m_i(1-r_i) + \\frac{1}{2}m_ir_i + \\frac{1}{2}(1 - m_i)r_i + (1 - m_i)(1 - r_i)} = m_i + \\frac{1}{2}(1-m_i)r_i = \\frac{1}{2}(a + 2b - b^2)$ (8)\nSimilarity, the representative value $Rep(CI_{\\xi})$ of the confidence interval $CI_{\\xi}$ is:\n$Rep(CI_{\\xi}) = \\frac{minCI_{\\xi} + maxCI_{\\xi}}{2} + (\\frac{1}{2} - \\frac{minCI_{\\xi} + maxCI_{\\xi}}{2}) (\\frac{maxCI_{\\xi} - minCI_{\\xi}}{2})$ (9)\nAfter obtaining the representative value for each interval, ranking the different confidence intervals becomes straightforward. A confidence interval with a more considerable representative value is considered to have a higher probability of occurrence. Unlike other methods, GRRV considers both the midpoint and the width. We select the highest value $Rep_{max}(CI_{\\xi})$ as the final opinion of the system. In this way, we ensure that each opinion can be considered. Furthermore, by repeating this process in multiple tests, we fully consider the inherent randomness of the system, ensuring the robustness of the algorithm's results. The pseudocode and flowchart of the algorithm are shown in Algorithm 1."}, {"title": "B. PRRLEM-HOHK", "content": "Unlike the DeGroot model, agents only trust people whose opinions are close to their own in the HK model. If all agents hold the same confidence threshold \u025b, the HK model is homogeneous; otherwise, it is heterogeneous. Here, two novel HK models are proposed. The calculation process of PRRLEM-HOHK is shown below.\nStep 1: Initialization\nIdentical to PRRLEM-DeGroot, a finite and ordered LTS is defined. Each agent is initialized with a linguistic opinion.\nStep 2: Opinion Conversion\nThis step remains unchanged, focusing on converting linguistic opinions into numerical values.\nStep 3: Confidence Set Determination\nThe characteristic of HK model is that each agent has the confidence set. According to [11], the confidence set $I(e_i, Y(t))$ of $e_i$ at time t is:\n$I(e_i,Y(t)) = \\{e_j||y_i(t) - y_j(t)| \\leq \\varepsilon,e_j \\in E\\}$ (10)\n#I(e_i, Y(t)) indicates the cardinality of $I(e_i, Y(t))$.\nStep 4: Weight Allocation\nIn the confidence set of $e_i$, one agent $e_j$ is randomly selected as the leader. The weight of $e_j$ is defined as:\n$\\omega_j \\sim Uniform(0, 1)$ (11)\nFor the other agents in I(e_i,Y(t)), the weights are:\n$\\omega_k = \\frac{1-\\omega_j}{\\#I(e_i, Y(t)) - 1}$ (12)\nSpecifically, when \u025b is very low, resulting in I(e_i, Y(t)) only including $e_i$. The weight $\\omega$ during the opinion update is 1, reflecting the agent's complete trust in its own opinion without external trusted agents. Moreover, if the confidence sets of two agents are the same, i.e., $I(e_i,Y(t)) = I(e_j,Y(t))$, then the weights of the agents in the confidence set are consistent when $e_i$ and $e_j$ update the opinions.\nStep 5: Opinion Update"}, {"title": "", "content": "In this step, agents update their opinions by considering only the opinions within their confidence set. The calculation formula is the same as PRRLEM-DeGroot.\nStep 6: Iterative Simulation and Result Recording\nRepeat the process from Step 2 to Step 5 within the framework of opinion dynamics. It is worth emphasizing that compared to the DeGroot model, the agents in the HK model may not ultimately reach a consensus due to the confidence set. The leader selected for each round of opinion updates is random, and different rounds may result in different opinion groups, which is different from the DeGroot model in that all agents will certainly achieve consensus. For example, after one round of Monte Carlo, $e_1$, $e_2$, and $e_4$ may end up with the same opinion, but in the next round, only $e_1$ and $e_2$ have the same opinion. Therefore, we tally the linguistic terms $h_{\\xi}$ that occur for $e_i$ throughout the entire Monte Carlo test and calculate the number of times each linguistic term occurs, denoted as $Q_{\\xi}^i$.\nStep 7: Monte Carlo Analysis\nFor each agent, calculate the proportion of each opinion $p_{\\xi}^i = \\frac{Q_{\\xi}^i}{M}$. Choose a confidence level (95%). For each opinion, calculate the confidence interval using the formula:\n$CI_{\\xi} = p_{\\xi}^i \\pm Z \\cdot \\sqrt{\\frac{p_{\\xi}^i(1 - p_{\\xi}^i)}{M}}$ (13)\nStep 8: Confidence Intervals Ranking and Results Determination\nThe representative value $Rep(CI_{\\xi}^i)$ of the confidence interval $CI_{\\xi}^i$ is:\n$Rep(CI_{\\xi}^i) = \\frac{min CI_{\\xi}^i+ maxCI_{\\xi}^i}{2} + (\\frac{1}{2} - \\frac{min CI_{\\xi}^i+max CI_{\\xi}^i}{2}) (\\frac{maxCI_{\\xi}^i - minCI_{\\xi}^i}{2})$ (14)\nThe highest value $Rep_{max}(CI_{\\xi}^i)$ is determined as the final opinion of the agent $e_i$. The pseudocode and flowchart of the algorithm are shown in Algorithm 2."}, {"title": "C. PRRLE\u041c-\u041d\u0415\u041d\u041a", "content": "Different agents may have varying confidence thresholds in the real world based on their individual characteristics and environmental backgrounds. PRRLEM-HOHK assumes that all agents have the same threshold 8. To better reflect reality, we improve it by allowing each agent to possess its confidence threshold $\\varepsilon_i$ and form the PRRLEM-HEHK model. The pseudocode is shown in Algorithm 3."}, {"title": "III. ILLUSTRATE EXAMPLES AND ANALYSIS", "content": "In this section, we employ illustrative examples to demonstrate the effectiveness of the proposed models. We aim to illustrate the applicability of our theoretical framework in real-world scenarios through these examples."}, {"title": "A. Example 1 for PRRLEM-DeGroot", "content": "Step 1: Initialization"}, {"title": "D. Real-World Example about Space Situational Awareness", "content": "In the current space environment, the continuous increase in human space activities has led to a significant growth in space debris and the number of spacecraft in orbit. The growing amount of space debris has crowded the orbital resources, posing a threat to the safe operation of spacecraft. Impacts from space debris of centimeter size or more significant can lead to punctures in spacecraft or even disintegration until wholly damaged. Impacts from space debris smaller than a centimeter can cause partial malfunction or failure of spacecraft, and damage to critical components may also lead to the failure of the entire satellite. This trend has threatened the regular operation of satellites and space stations. Facing this challenge, this study utilizes the opinion dynamics to invite space enthusiasts and researchers to evaluate the future development trends of space situational awareness [30].\nWe invite ten agents, and the linguistic term set is H = {ho,h1,...,h6}. M = 1000, T = 9, and a = 1.37. The initial opinions of agents are: Ke\u2081 (1) = h\u2081, Ke\u2082(1) = ho, Kez (1) = h4, Ke\u2084(1) = h\u2081, Ke5 (1) = h2, Ke\u2081 (1) = h3, Ke7 (1) = h4, Keg (1) = h\u2081, Keg (1) = ho, Ke10 (1) = h2. For PRRLEM-HOHK, the threshold value is 0.4. For PRRLEM-HEHK, the threshold values of agents are: \u03b5\u2081 = 0.1, \u00a32 = 0.3, \u00a33 = 0.7, \u00a34 = 0.5, \u00a35 = 0.1, 6 = 0.3, E7 = 0.2, \u03b58 = 0.3, \u00a39 = 0.3, and \u00a310 = 0.3. After calculation, the final results are shown in Fig. 5.\nThe results from the three models indicate that the future development trend of the space environment may be severe, necessitating research into space debris cleanup and collision avoidance. This result is consistent with the current situation. Many countries are promoting space debris cleanup plans and conducting in-depth research on space situational awareness. The European Space Agency (ESA) plans to deploy an innovative technology in 2025 with the ClearSpace-1 mission, which aims to capture and remove space debris using a clamping mechanism. Meanwhile, the Japan Aerospace Exploration Agency (JAXA) is utilizing electrodynamic tether technology in its KITE project, targeting the removal of low-orbit debris by drawing it into the atmosphere for destruction, thereby mitigating the space debris issue. Additionally, the United States Space Surveillance Network, with its global network of radars and telescopes, not only enhances the capability of space situational awareness but also helps prevent potential collisions."}, {"title": "IV. ROBUSTNESS ANALYSIS AND COMPARISON ANALYSIS", "content": "To verify the superiority of the proposed models, a detailed robustness analysis and comparative analysis with other methods are conducted."}, {"title": "A. Robustness Analysis", "content": "Conducting a robustness analysis of models is crucial, especially in complex environments where models may face various abnormal issues and extreme conditions. By intentionally introducing biased processing and deviations from normal data values to simulate potential data abnormalities or interference, we can effectively test the performance of models under non-ideal conditions.\nWe test the robustness of PRRLEM-DeGroot and PRRLEM-HOHK models by replacing the initial opinion Key(1) = h5 in Example 1 for PRRLEM-DeGroot and Example 2 for PRRLEM-HOHK with Ke, (1) = h\u2081. The rest remains the same. For Example 3 for PRRLEM-HEHK, we not only replace Key(1) = h5 with Key(1) = h\u2081 but also replace \u00a37 = 0.9 with 87 = 0.1 to test the effect of the threshold value on the results.\nAs can be seen in Fig. 6, although Ke, (1) shifts significantly from the very positive h5 to h\u2081, the final results do not change, which demonstrates the robustness of both models. For PRRLEM-HEHK, even if we change both the threshold 87 and Key (1), the only difference is the presence of h4, which is mainly due to the adjustment of 87 from 0.9 to the extreme 0.1. The other results remain the same as before. Therefore, the three models proposed in this paper show strong anti-interference and robustness."}, {"title": "B. Comparison Analysis", "content": "1) Comparison with Traditional DeGroot Model: The initial setup is consistent with Example 1 for PRRLEM-DeGroot. Fig. 7 shows the results obtained by the traditional DeGroot model. For the left picture, the weights of agents in the opinion evolution is \u03a9 = {@\u2081, 2,\u2026, @15} = {$\\frac{1}{15}$, $\\frac{1}{15}$,\u2026, $\\frac{1}{15}$}. For the right picture, the agents' weight vector when $e_i$ updates the opinion is based on the distance between opinions $\\omega_j = \\frac{e^{-D_{ik}}}{\\sum_{k=1}^{15} e^{-D_{ik}}}$ Obviously, the final results are quite different in both cases. In the first case all agents reach h3, while in the second case all agents reach h2. It indicates that traditional model is extremely sensitive to the choice of parameters; slight differences can result in significant variances in the final results.\nUnlike the traditional DeGroot model, the proposed model introduces a randomness principle that enables dynamic leadership transfer among agents. This unique random leadership model significantly enhances the system's adaptability to external changes in decision-making across variable environments. Our proposed model can also present these close opinions and assign an exact value to each opinion, enabling the experts to form decisions more comprehensively. Besides, the results highlight an essential advantage: robustness. Our model shows stability that does not depend on a specific weight vector, ensuring that uncertainties in the decision-making process are effectively managed.\n2) Comparison with Traditional Homogeneous HK Bounded Confidence Model: The initial setup is consistent with Example 2 for PRRLEM-HOHK. The results based on the traditional homogeneous HK bounded confidence model are shown in Fig. 8. As the confidence value & decreases, the communication between agents reduces. When & reaches 0.15, the traditional model results in agents completely ceasing communication with those holding different opinions. The results based on the proposed PRRLEM-HOHK model is shown in Table V. The blue marks in the table represent the maximum value of each row. For example, the first blue mark 0.420 indicates the representative value of e\u2081's confidence interval for these seven linguistic terms ho, h1, h2, h3, h4, h5, and h6 after Monte Carlo test when \u025b = 0.3. These agents reach the consensus h2 when \u025b = 0.3. We can see that when E = 0.15, the agents in our model still be exchanging opinions and form the final results ho, h1, h3, h5, and h6.\nIn opinion dynamics research, a common challenge arises when agents have low trust in information that differs from their opinions, leading to a phenomenon known as echo chamber. This results in group polarization, as agents are inclined to communicate only with those who share the same opinions, thus distrusting agents with different opinions. However, our model maintains the exchange of opinions even when agents' trust is very low. This innovation indicates our model's potential to reduce the effect of group polarization and slow the speed of forming echo chamber and shows its effectiveness in preserving information sharing.\n3) Comparison with Traditional Heterogeneous HK Bounded Confidence Model: The initial setup is consistent with Example 3 for PRRLEM-HEHK. The results based on the traditional heterogeneous HK bounded confidence model are shown in Fig. 9(a). When 6 becomes 0.2 and the threshold values of other agents remain the same, the final opinions of agents are shown in Fig. 9(b). As can be seen, simply due to a difference in the setting of one parameter, there are significant differences in the final results. However, based on the proposed algorithm, the final results remain consistent with Fig. 4. Therefore, this comparison once again demonstrates that this paper's research can improve the robustness of the opinion dynamics model, which is crucial to reduce the influence of the initial conditions set in the opinion dynamics model and the interference existing in the information sharing on the final results."}, {"title": "V. CONCLUSION", "content": "In this paper, we have introduced three linguistic fuzzy information evolution algorithms for understanding how group information change. These models are based on the PRRLEM, showing us a new way to look at leadership and decision-making among agents. We use the Monte Carlo method and confidence intervals to derive better the variety of possible opinions rather than just one fixed result. Our simulations show that these new models can help groups share information better, make more diverse choices, and decide more effectively. By changing who leads at different times, we avoid depending too much on just one leader. This can make the group's decisions stronger and less likely to fail because of one agent's mistake. Also, by using confidence intervals to express opinions and GRRV to rank these intervals, we can deal with the uncertainty and randomness that often challenge the traditional information evolution models.\nTo sum up, our models offer a novel perspective on how information forms and changes within groups, drawing lessons from nature and using mathematical methods to handle uncertainty. These models could be helpful in analyzing social media, planning marketing strategies, and building agreement among people. In the future, we will study the effect of noise on the proposed models."}]}