{"title": "Enhancing Anomaly Detection via Generating Diversified and Hard-to-distinguish Synthetic Anomalies", "authors": ["Hyuntae Kim", "Changhee Lee"], "abstract": "Unsupervised anomaly detection is a daunting task, as it relies solely on normality patterns from the training data to identify unseen anomalies during testing. Recent approaches have focused on leveraging domain-specific transformations or perturbations to generate synthetic anomalies from normal samples. The objective here is to acquire insights into normality patterns by learning to differentiate between normal samples and these crafted anomalies. However, these approaches often encounter limitations when domain-specific transformations are not well-specified such as in tabular data, or when it becomes trivial to distinguish between them. To address these issues, we introduce a novel domain-agnostic method that employs a set of conditional perturbators and a discriminator. The perturbators are trained to generate input-dependent perturbations, which are subsequently utilized to construct synthetic anomalies, and the discriminator is trained to distinguish normal samples from them. We ensure that the generated anomalies are both diverse and hard to distinguish through two key strategies: i) directing perturbations to be orthogonal to each other and ii) constraining perturbations to remain in proximity to normal samples. Throughout experiments on real-world datasets, we demonstrate the superiority of our method over state-of-the-art benchmarks, which is evident not only in image data but also in tabular data, where domain-specific transformation is not readily accessible. Additionally, we empirically confirm the adaptability of our method to semi-supervised settings, demonstrating its capacity to incorporate supervised signals to enhance anomaly detection performance even further.", "sections": [{"title": "1 INTRODUCTION", "content": "Unsupervised anomaly detection involves identifying abnormal samples whose patterns deviate from the expected normal behaviors learned from data composed solely of normal samples. This is a fundamental problem in various domains, including healthcare, manufacturing, and finance. In healthcare, for instance, diseases often manifest through a broad spectrum of patient features, leading to heterogeneous patterns that can be distinguished from the healthy population. Recognizing such deviations is crucial for anticipating adverse disease progressions, empowering healthcare practitioners to make informed clinical decisions [22]. In manufacturing, detecting anomalies in a production process is crucial for achieving high-quality products and minimizing financial losses. This is achieved by precisely identifying deviations from normal patterns captured by industrial sensors, which exhibit complex correlations among multiple variables [15]. Such numerous applications across various domains have led to a growing demand for anomaly detection methods capable of universally applying to diverse data types spanning different domains while effectively capturing their complex patterns.\nMany recent unsupervised anomaly detection methods employ self-supervised learning frameworks to acquire normality patterns, achieved either through the utilization of contrasting learning [24, 26] or auxiliary classification tasks [13, 32]. The core idea here is to learn representations that preserve relevant information about normal samples or establish a decision boundary capable of identifying normal samples, both by comparing them to their augmented counterparts. This underscores the critical role of augmentation techniques in these methods, as they provide diverse aspects of (potential) abnormal patterns from normal samples. Unfortunately, these methods primarily focus on image data by leveraging augmentations specifically designed for images - such as rotations, reflections, and cropping - making them unsuitable for general data types across diverse domains.\nLearnable domain-agnostic transformations for unsupervised anomaly detection [4, 8] have recently been proposed to overcome the limitation associated with relying on domain-specific (image) transformations. These methods primarily focus on jointly acquiring the ability to generate anomalous versions of normal samples while learning the normality patterns by discriminating them from"}, {"title": "2 RELATED WORKS", "content": "Unsupervised anomaly detection aims to learn a score function from normal samples capable of identifying (unseen) abnormal samples during testing. There are various existing works under different modeling assumptions: i) abnormal samples incur relatively higher reconstruction costs in comparison to normal samples [28], ii) normal data is densely concentrated around the center of a hypersphere [20], iii) exposure to samples from (disjoint) auxiliary datasets helps identifying abnormal samples during testing [9], and iv) the distribution of normal data can be modeled using specific types of distributions, e.g., Gaussian mixture models [33]. In this paper, we focus on describing approaches based on different types of transformations, that are most closely related to our work.\nDomain-Specific Transformations. One line of research has directed its attention toward acquiring representations based on self-supervised learning beneficial for anomaly detection by employing various forms of image transformations [13, 24, 26, 32]. A novel contrastive learning framework has been introduced to extract high-level representations based on distribution-shifting transformations (e.g., rotation and flipping) of a given normal sample, creating its negative pairs [24, 26]. Then, these acquired representations are effectively applied in either learning one-class classifiers [24] or establishing a score function for anomaly detection [26]. Other approaches introduce an auxiliary task of distinguishing normal samples from synthetic anomalies generated based on image-specific augmentations such as cut-out [13] and random augmentations [32]. However, these methods heavily depend on image-specific augmentations, rendering them inapplicable to general data from other domains.\nDomain-Agnostic Transformations. To overcome the limitation due to the reliance on domain-specific (image) transformations, another line of research has focused on acquiring representations for anomaly detection through the utilization of domain-agnostic transformations. In [2, 18], the authors introduced multiple transformations to create diverse views of normal samples. More specifically, GOAD [2] randomly initializes a set of affine transformations and utilizes the transformed normal samples in training a classifier based on the triplet loss to distinguish between normal samples and their respective transformed counterparts. NeutraLAD [18] employs a set of learnable neural transformations, jointly trained with an encoder based on the deterministic contrastive loss. This encourages the transformed samples to be similar to the original sample while remaining dissimilar to other transformed versions, thus rendering the learned representations to preserve relevant semantic information of normal samples. However, as these approaches depend solely on contrasting the transformed versions of the original samples, they might struggle to acquire meaningful information if the transformation is not adequately initialized or trained. Also, these methods cannot be extended to a semi-supervised setting where we are provided with some known anomalies.\nOur work is most closely related to [4, 8] which introduce trainable perturbators that generate synthetic anomalies by altering feature values of normal samples. These synthetically generated anomalies are then utilized in training a classifier to obtain a deci-"}, {"title": "3 PROBLEM FORMULATION", "content": "Suppose we have a training set $D_{tr} = \\{x^i\\}_{i=1}^{N_{tr}}$ comprising normal samples drawn from an input distribution $P_X$, i.e., $x^i \\in X \\sim P_X$, and a testing set $D_{te} = \\{(x^i, y^i)\\}$ containing abnormal samples that are unlikely drawn from the input distribution i.e., $p_X(x^i) \\approx 0$. The label, $y \\in \\{0, 1\\}$, corresponding to $x^i$, denotes whether the sample is normal (i.e., $y^i = 0$) or anomalous (i..e, $y^i = 1$). We consider an unsupervised anomaly detection problem where the goal is to learn a score function, i.e., $S: X \\rightarrow [0, 1]$, from the training data that can distinguish unseen abnormal samples in the testing data. It is worth highlighting that we consider scenarios with different data types such as images, i.e., $X = R^{W \\times H \\times C}$, and tabular data, i.e., $X = R^d$. From this point forward, we will omit the dependency on $i$ when it is clear in the context.\nWe present our novel unsupervised anomaly detection framework based on Diversified and Hard-to-distinguish Anomaly Generation, which we refer to as DHAG, following recent advances utilizing learnable domain-agnostic perturbations [4]. Our goal is to train a discriminator capable of distinguishing synthetically generated abnormal samples, created by perturbing original samples, from unaltered original (normal) samples. We encourage the perturbations to have the following two properties: First, the perturbations must be subtle to ensure that the generated abnormal samples remain close to the original samples. This complicates the task of distinguishing between the original and perturbed samples, effectively preventing the acquisition of trivial solutions. Second, the perturbations must generate anomalous versions of the original data from different perspectives without relying on domain knowledge. This enables us to establish a decision boundary that generalizes well to unseen real anomalies.\nUnfortunately, most previous works fail to address the aforementioned properties as they either focus on random perturbations that are not dependent on the input normal sample [8], which often results in generating synthetic anomalies that can be easily distinguished by the discriminator, or heavily rely on domain-specific augmentations [13, 24], which are often not accessible in practice."}, {"title": "4 METHOD", "content": "For the proposed unsupervised anomaly detection framework, we introduce three networks - an encoder, a set of L perturbators, and a discriminator - as shown in Figure 1 and Algorithm 1. These components work together to achieve a discriminator that is capable of distinguishing normal samples from synthetically generated abnormal samples that are both diverse and hard to distinguish. We define each component as follows:\n\u2022 The encoder, $f_{\\theta} : X \\rightarrow Z$, which transforms complex input features $x \\in X$ into a latent representation $z \\in Z$ where Z is the latent space, i.e., $z = f_{\\theta}(x)$.\n\u2022 A set of L perturbators, $\\{g_{\\psi_l}\\}_{l=1}$, where each perturbator, $g_{\\psi_l} : X \\rightarrow Z$, is a stochastic function that generates perturbations in the latent space conditioned on $x$, i.e., $\\epsilon_l \\sim g_{\\psi_l}(x)$. Perturbations are then applied to the latent representation of $x$ to create a latent representation for the synthetically generated anomalous sample, i.e., $\\tilde{z}_l = z + \\epsilon_l$.\n\u2022 The discriminator, $f_{\\phi} : Z \\rightarrow [0, 1]$, which takes the latent representation of either a normal or a generated abnormal sample as input, and outputs the probability of the input being an anomaly.\nDuring training, the discriminator, $f_{\\phi}$, receives both perturbed (abnormal) representation, $\\tilde{z}$, and original (normal) representation, $z$, and is jointly trained with the encoder, $f_{\\theta}$, to distinguish between them, while the perturbators, $g_{\\psi_1}, ..., g_{\\psi_L}$, are adversarially trained"}, {"title": "4.1 Generating Hard-to-distinguish Synthetic Anomalies", "content": "One desirable attribute of the perturbed representations designed for anomaly generation lies in their capability to render the task of distinguishing normal samples from synthetic anomalies challenging. This, in turn, will encourage the encoder and the discriminator to acquire useful and distinctive information that specifically represents normal samples. To achieve this goal, our initial step is to guarantee that the magnitude of each perturbation remains small by minimizing its Euclidean norm, i.e., $|\\epsilon_l||_2$. This prevents the occurrence of a trivial scenario where the discriminator can effortlessly differentiate generated abnormal samples from normal ones as the perturbator can merely increase the perturbation level.\nFurthermore, we generate two types of perturbations, each playing opposite roles: one indicating the proximity of normal representations that should be classified as normal, and the other indicating proximity, yet with sufficient distance from normal representations, that should be classified as abnormal. Let $\\epsilon_l \\sim g_{\\psi_l}(x^i)$ be an input-dependent perturbation generated by the l-th perturbator taking $x^i$ as an input. Then, we define $(\\epsilon_{\\pi(1)}^i, \\epsilon_{\\pi(2)}^i, ... \\epsilon_{\\pi(m)}^i)$ as an ordered set of perturbations given m samples, $\\{x^i\\}_{i=1}^m$, where $\\pi$ is a permutation function that arranges them in increasing order of magnitude (i.e., Euclidean norm) such that $|\\epsilon_{\\pi(1)}^i ||_2 \\le ||\\epsilon_{\\pi(2)}^i ||_2 \\le ... \\le ||\\epsilon_{\\pi(m)}^i ||_2$. From the ordered set of m perturbations, we set the first K as augmentations applied to normal samples, denoted as $\\mathcal{E}_t^i \\overset{\\text{def}}{=} \\{\\epsilon_{\\pi(j)}^i\\}_{j=1}^{K}$ and set the remaining (m \u2013 K) as anomalous versions of perturbations, denoted as $\\mathcal{E}_a^i \\overset{\\text{def}}{=} \\{\\epsilon_{\\pi(j)}^i\\}_{j=K+1}^{m}$. Then, we assign a pseudo label for the perturbed latent representation of $x^i$, i.e., $\\tilde{z}^i = z^i + \\epsilon$, as the following:\n$\\tilde{y}^i = \\begin{cases}\n0 \\text{ (normal) } & \\text{for } \\epsilon \\in \\mathcal{E}_t^i \\\\\n1 \\text{ (abnormal) } & \\text{for } \\epsilon \\in \\mathcal{E}_a^i.\n\\end{cases}$\nBased on pseudo labels obtained through (1), we train $f_{\\theta}, f_{\\phi}$, and $g_{\\psi_l}$ in order to differentiate between synthetically generated normal and abnormal samples.\nUtilizing both synthetically generated normal and abnormal samples has the following two advantages: i) Treating augmented latent representations as normal samples preserves the original normality even after applying perturbation, thereby enhancing generalization to unseen normal samples. ii) By aligning perturbations used for augmentation with those employed for anomaly generation, we make the synthetically generated anomalies hard to distinguish. Consequently, this renders the differentiation between the two perturbed representations more challenging, preventing the occurrence of trivial cases where anomalous perturbations are merely small yet recognizable patterns."}, {"title": "4.2 Diversifying Synthetic Anomalies", "content": "Another desirable attribute of the perturbed representations designed for anomaly generation is their ability to attain diverse representations. This is crucial in maintaining the robustness of both the encoder and the discriminator against unseen real abnormal samples during testing. To achieve this goal, we introduce multiple perturbators denoted as $g_{\\psi_1}, g_{\\psi_2},\u00b7\u00b7\u00b7,g_{\\psi_L}$ where L indicates the number of perturbators. Each of these perturbators is directed to generate perturbations in directions distinct from those of the other perturbators, thereby diversifying latent representations for the synthetically generated anomalies. More specifically, let $\\epsilon_1^i, \\epsilon_2^i, ..., \\epsilon_L^i$ represent the perturbations generated by the L perturbators when provided with $x^i$ as input. We foster diversity among the perturbations produced by different perturbators by minimizing their cosine similarity, expressed as $sim(\\epsilon_l^i, \\epsilon_k^i) = \\frac{\\epsilon_l^i \\cdot \\epsilon_k^i}{|\\epsilon_l^i ||_2|\\epsilon_k^i ||_2}$ for $l \\neq k$."}, {"title": "4.3 Optimizing the Three Components", "content": "We jointly train the three components of our unsupervised anomaly detection framework \u2013 $f_{\\theta}, f_{\\phi}$, and $\\{g_{\\psi_l}\\}_{l=1}$ (parameterized by $\\theta$, $\\phi$, and $\\{\\psi_l\\}_{l=1}$, respectively) \u2013 based on the following objective:\n$\\underset{\\theta, \\phi, \\{\\psi_l\\}}{minimize} \\frac{1}{N_{tr}} \\sum_{i=1}^{N_{tr}} L_{ce}^i + \\lambda_1 L_{norm} + \\lambda_2 L_{div}$\nwhere $\\lambda_1, \\lambda_2 \\ge 0$ are hyper-parameters chosen to balance among different loss functions.\nThe aim of our objective in (2) is to distinguish both original and augmented (with perturbations) normal samples from synthetically generated abnormal samples based on\n$L_{ce} = CE(\\hat{y}(f_{\\phi}(f_{\\theta}(x^i)), 0) + \\frac{1}{L} \\sum_{l=1}^{L} CE(\\hat{y}(f_{\\phi}(f_{\\theta}(x^i) + \\epsilon_l)), \\tilde{y}^i))$\nwhere CE($\\hat{y}$, y) indicates the cross-entropy between $\\hat{y}$ and y. Concurrently, the objective in (2) encourages the synthetically generated anomalies to be diversified and hard to distinguish based on the following two loss functions:\n$L_{norm} = \\frac{1}{m} \\sum_{i=1}^{m} \\frac{1}{L} \\sum_{l=1}^{L} ||\\epsilon_l^i||_2, L_{div} = \\frac{1}{m} \\sum_{i=1}^{m} \\frac{1}{L(L-1)} \\sum_{l \\neq k} sim(\\epsilon_l^i, \\epsilon_k^i).$\nHere, $L_{norm}$ ensures that the perturbations maintain a small magnitude, while $L_{div}$ introduce diversity among the perturbations generated by different perturbators. The pseudo-code for the overall learning process is described in Algorithm 1.\nUltimately, we employ the trained encoder and discriminator pair as a score function, $S = f_{\\phi} \\circ f_{\\theta}$, to detect whether a new data sample $x^*$ is classified as normal (i.e., $f_{\\phi}(f_{\\theta}(x^*)) \\le \\delta$) or abnormal (i.e., $f_{\\phi}(f_{\\theta}(x^*)) > \\delta$), based on a predefined threshold $\\delta$ (e.g., 0.5)."}, {"title": "4.4 Extension to Semi-Supervised Learning", "content": "Suppose we are provided with a set of $N_l$ (known) real anomaly samples, denoted as $D_l = \\{(x^i, 1)\\}_{i=1}^{N_l}$. To harness such valuable information about the abnormal distribution, we make a straightforward extension of our objective in (2) by augmenting it with a cross-entropy loss for the known anomaly samples as $\\frac{1}{N_l}\\sum_{j=1}^{N_l} L_{aug}$, where $L_{aug} = CE(f_{\\phi}(f_{\\theta}(x^i)), 1)$. We will further present experimental results in the Experiments section, demonstrating that our unsupervised anomaly detection framework shows significant improvement through the augmentation of the loss function, which incorporates information about the known real anomaly samples."}, {"title": "5 EXPERIMENTS", "content": "In this section, we evaluate our proposed method, DHAG, across various real-world datasets commonly used for anomaly detection tasks, encompassing two distinct modalities: image and non-image tabular data. As elaborated in Section 4, the anomaly score is computed during inference by passing the input data sample through the trained encoder, followed by the trained discriminator.\nImplementation. The parameters for the encoder, discriminator, and the set of perturbators \u2013 i.e., $(\\theta, \\phi, \\{\\psi_l\\}_{l=1})$ are jointly optimized via Adam optimizer [11] with learning rates of $5 \\times 10^{-3}$ for"}, {"title": "5.3 Ablation Study", "content": "In this subsection, we further provide the effect of two key factors of DHAG - i) the number of augmented versions of normal samples for each perturbator (i.e., K), and ii) the number of perturbators (i.e., L) - using the image datasets.\nIn Figure 2, we present the t-SNE visualizations of the learned representations for the FMNIST dataset with three different scenarios: (K = 0, L = 10), (K = 50, L = 10), and (K = 50, L = 1). Comparisons across the three scenarios offer valuable insights into the benefits of leveraging the two key factors. First, as shown in Figures 2(a) and 2(b), each perturbator generates perturbations that span directions different from those of other perturbators. However, the perturbed representations deviate significantly from the normal representations when the augmented normal samples are not generated simultaneously. This, in turn, makes it trivial for the discriminator to differentiate between normal samples and synthetically generated anomalies, resulting in a performance drop in detecting unseen anomalies during testing. Second, Figures 2(b) and 2(c) show that although there is limited overlap between synthetically generated anomalies and the real (unseen) anomalies, training discriminator using diverse latent representations of synthetic anomalies helps to learn decision boundaries that more effectively capture the distribution of normal samples. This enhancement contributes to improved generalization for unseen anomalies.\nIn Figure 3, we provide a sensitive analysis to see the influence of the two key factors with respect to the anomaly detection performance using the CIFAR-10 dataset. More specifically, we report the average AUC performance by varying K while fixing L in Figure 3(a) and by varying L while fixing K in Figure 3(b). In Figure 3(a), we can observe that the performance is sub-optimal when the number of augmented normal samples is either too small (i.e., all synthetic anomalies) or too large (i.e., no synthetic anomalies). Also, Figure 3(b) demonstrates that, in most cases, performance gradually improves as the number of perturbators increases up to a certain threshold, leveraging the effect of diversified synthetic anomalies. However, performance diminishes when the number of perturbators becomes excessively large, and the optimal value of L can vary based on different normal classes."}, {"title": "5.4 Semi-Supervised Learning", "content": "In this subsection, we further evaluate how well our proposed method can be extended to the semi-supervised setting, where a small number of true anomalies are available during training (See Section 4.4). In Table 3, we compare the average AUC performance of DHAG with DeepSVDD [20] and its semi-supervised variant, DeepSAD [21], on the two image datasets (i.e., FMNIST and CIFAR-10) and one tabular dataset (i.e., Thyroid). For the image datasets,"}, {"title": "5.5 Effects of the Latent Perturbations", "content": "In this experiment, we investigate the effects of applying perturbations in the latent space by introducing a variant of DHAG. This variant incorporates perturbations directly into the input features, as opposed to applying perturbations into the latent representations. Figure 4 depicts some randomly selected images before and"}, {"title": "5.6 Case study", "content": "We expand our comparative experiment by including an additional case study, specifically focusing on the scenario in which DHAG successfully distinguishes between normal samples and the corresponding abnormal counterparts, whereas the perturbation-based baseline (i.e., DROCC) fails to do so, using the FMNIST dataset. We consider a one-class classification setting where we define the class 'sneaker' as normal and all other classes as abnormal. Here, the anomaly detection methods are trained solely based on the normal samples with class 'sneaker' during training.\nFigure 5 illustrates the distribution of test anomaly scores for samples with class 'sneaker', 'sandal', and all other classes (excluding 'sandal'). This highlights the ability of our proposed method to discriminate between sneakers and sandals, particularly those that are hard to distinguish due to their shared characteristics as footwear. DHAG provides anomaly scores with a clear distinction between normal and abnormal classes, particularly showing effective discrimination of the 'sandal' class as abnormal. In contrast, the decision boundary provided by DROCC is unclear because there exists a substantial overlap in the anomaly score distribution between the hard-to-distinguish 'sandal' class and the normal 'sneaker' class. This result demonstrates that DHAG is capable of distinguishing between normal samples exhibiting diverse characteristics and hard-to-distinguish abnormal samples, effectively reducing potential false alarms."}, {"title": "6 CONCLUSION", "content": "In this work, we introduce a novel unsupervised anomaly detection method, DHAG, that is trained based on an auxiliary classification task of distinguishing both original and augmented normal samples from synthetically generated abnormal samples. Our novel perturbation process encourages these synthetic anomalies to achieve two desirable attributes by simultaneously generating perturbations for both normal and abnormal transformations of given normal samples and by incorporating multiple perturbators spanning distinct perturbation directions. As a result, the auxiliary classification task becomes more challenging which improves distinguishing unseen abnormal samples from normal samples. Throughout the experiments, we evaluate DHAG on both real-world image and tabular datasets, demonstrating the superiority of our method across different data types compared to the state-of-the-art benchmarks. The significance of our novel perturbation process is further validated by visualizing the learned representations using different variants of our perturbation process."}]}