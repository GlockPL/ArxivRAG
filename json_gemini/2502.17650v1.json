{"title": "Wearable Meets LLM for Stress Management: A Duoethnographic Study Integrating Wearable-Triggered Stressors and LLM Chatbots for Personalized Interventions", "authors": ["SAMEER NEUPANE", "POORVESH DONGRE", "DENIS GRACANIN", "SANTOSH KUMAR"], "abstract": "We use a duoethnographic approach to study how wearable-integrated LLM chatbots can assist with personalized stress management, addressing the growing need for immediacy and tailored interventions. Two researchers interacted with custom chatbots over 22 days, responding to wearable-detected physiological prompts, recording stressor phrases, and using them to seek tailored interventions from their LLM-powered chatbots. They recorded their experiences in autoethnographic diaries and analyzed them during weekly discussions, focusing on the relevance, clarity, and impact of chatbot-generated interventions. Results showed that even though most events triggered by the wearable were meaningful, only one in five warranted an intervention. It also showed that interventions tailored with brief event descriptions were more effective than generic ones. By examining the intersection of wearables and LLM, this research contributes to developing more effective, user-centric mental health tools for real-time stress relief and behavior change.", "sections": [{"title": "1 Introduction", "content": "Stress is defined as a state of mental or emotional strain resulting from adverse or demanding circumstances. Stress has become a pervasive challenge in modern life, with chronic stress posing significant risks to mental and physical health [4, 7, 15, 22, 31]. This issue holds considerable significance in Human-Computer Interaction (HCI), as technology plays an increasingly central role in daily life and, consequently, in mental health interventions."}, {"title": "2 Background and Related Works", "content": "Technology-powered interventions have become increasingly popular for supporting mental health and well-being. They provide real-time data, adapt to personal needs, and reduce barriers such as cost and accessibility."}, {"title": "2.1 Wearables for Stress Tracking, Stressor Journaling, and Interventions", "content": "Wearable devices have emerged as one of the most widely used AI-driven tools for recognizing affect states, including stress from physiological signals. During the past two decades, the scientific community has made significant advances in stress detection, using wearable technology to monitor physiological responses in real-time indicative of stress [14, 29, 40]. Building on this foundation, commercial devices such as Fitbit [34], Garmin [12], Whoop [20], and Empatica Embrace [11] have recently integrated stress tracking capabilities. Passively collected data has been leveraged to create innovative visualizations for self-reflection [18, 19, 30, 35, 41]. Furthermore, passive stress detection has effectively delivered real- time interventions, addressing stress precisely when it occurs [2, 16]. However, participants in these studies have expressed the desire for interventions to match the source of stress. Recent work has shown how stress detection can"}, {"title": "2.2 LLM for Mental Health Support", "content": "Mental health support chatbots trace their origins back to ELIZA, one of the first computer programs to simulate human conversation [38]. Since then, several rule-based and semi-automated chatbots have emerged that offer psycho-education, basic coping strategies, and limited therapeutic interactions. However, the emergence of LLMs has transformed the development of conversational agents and created novel opportunities to provide users with advanced mental health chatbots. Liu et al. [23] developed an LLM chatbot, ChatCounselor, by fine-tuning an open-source pre-trained LLM on a dataset prepared from 260 in-depth interviews between patients and psychologists. The LLM chatbot by Lai et al. [21] was developed by fine-tuning two Chinese pre-trained LLMs with real-world professional Q&A datasets from psychologists and psychological articles to develop their mental health chatbot. Dongre et al. [8, 9] also fine- tuned an open-source LLM on a Q&A dataset scraped from a mental health website to develop their LLM chatbot for stress management. CaiTI, a Conversational AI Therapist, uses LLMs, smart devices, and reinforcement learning to provide personalized psychotherapeutic interventions, enhancing mental health self-care [26]. BOLT, a framework for evaluating LLM therapists' conversational behavior, highlights the need for improvements to achieve high-quality care [3]. MindScape introduces an Al-powered journaling approach that integrates behavioral patterns like sleep, location, and engagement to deliver personalized, context-aware prompts [24]. These works show the vast potential of LLM to power tailored interventions on demand. The novelty of this study lies in its integration with wearable AI to deliver automated, personalized, and context-aware stress interventions."}, {"title": "3 Methods", "content": ""}, {"title": "3.1 Duoethnography", "content": "This study employs a duoethnographic approach, a qualitative method exploring how two or more researchers interpret and give meaning to shared experiences [5, 32]. It builds on autoethnographic methods [6, 10, 27, 37], which have been applied in diverse contexts, including the use of LLM chatbots for thesis writing, creative expression, and self- identity [13, 28, 33]. For this study, two researchers independently interacted with the wearables and personalized LLM chatbots for stress management, documenting their experiences and reflections in autoethnographic diaries. This dual autoethnographic approach provided introspective data on how integrating the two Al systems influenced perceived effectiveness in managing everyday stress. Weekly meetings between the researchers enabled shared reflection, discussion, and comparative analysis of individual perspectives. The study's insights into integrating wearables and LLM chatbots for stress management were enriched by combining individual depth with collaborative breadth."}, {"title": "3.2 Wearable for Stressor Journaling", "content": "Both researchers wore Samsung Galaxy Watch 6 devices equipped with the CuesHub smartwatch app [1], serving as the wearable AI platform for detecting physiological events associated with stress. Upon detecting a physiological event, the smartwatch app prompted researchers via their smartphones, requesting them to provide brief descriptions of the event. Researchers rated the events using one of four options: Positive, Negative, Neutral, or No (see Figure 1a)."}, {"title": "3.3 Custom GPT for Stress Intervention", "content": "The chatbots employed in this study used OpenAI's GPT-40 \u00b9 as their underlying language model. To investigate the effectiveness of different interaction paradigms, we explored two contrasting approaches to chatbot design, emphasizing distinct user experiences and intervention delivery styles. Researcher A (RA) designed their chatbot, named DeStressify, to emulate a zero-shot prompting approach akin to intervention systems that automatically deliver stress interventions upon detecting a user's stress [2, 16]. When experiencing the need for intervention, Researcher A prompted the chatbot with their stressor and location. Most interactions were transactional, consisting of a single prompt-response exchange where the chatbot provided an intervention in the traditional instructive manner often used in text messaging.\nResearcher B (RB), on the other hand, adopted the modern approach for their chatbot, named StressGPT. This chatbot was structured to facilitate a more therapy-like interaction, allowing them to engage in dynamic, multi-turn dialogues. This conversational style aimed to simulate collaborative interactions, with StressGPT mimicking personalized coaching sessions by refining suggestions or providing layered support through iterative exchanges, enabling deeper reflection and tailored advice. Details about the chatbot designs for both researchers are provided in Appendix A.1."}, {"title": "3.4 Data Collection and Analysis", "content": "Both researchers used the CuesHub app for 22 days. For stressors where researchers felt the need for interventions, they voluntarily engaged with the LLM chatbots. RA using DeStressify engaged with the chatbot immediately (or soon) after prompts in the CuesHub app, i.e., following a just-in-time one-shot approach. RB, in contrast, engaged with StressGPT predominantly at the end of the day, consolidating the day's events and reflectively interacting with StressGPT. We note that even in this end-of-day interactive approach, prompts helped capture events that may have been missed otherwise. After each engagement, researchers rated the intervention on a scale from Very poor to Very good. Ratings were based on the immediate relevance and usefulness of the interventions in addressing specific stressors. Both researchers employed distinct prompt engineering strategies, guided by catalog patterns described in [39], ensuring tailored and meaningful interactions with their respective LLM chatbots. Both researchers maintained a running journal after each chatbot interaction, reflecting and documenting their perceptions of its relevance, clarity, and impact.\nBoth researchers conducted a thematic analysis of data from weekly meeting transcripts, journals, and stressors logged through the CuesHub app to examine chatbot usage, intervention effectiveness, and the connection between wearable-detected stress experiences and chatbot interactions. The analysis included design documentation detailing chatbot customization and expectations, daily journals reflecting on the relevance and effectiveness of interactions, and engagement logs tracking the frequency and content of interactions."}, {"title": "4 Findings", "content": "We first describe the stressors logged by researchers and how many of these needed an intervention. We then compare and contrast our intervention experience between the just-in-time one-shot and the end-of-day interactive approaches."}, {"title": "4.1 Diversity in Stressors Detected and the Need for Interventions", "content": ""}, {"title": "4.1.1 Diversity in Stressors Detected", "content": "The stressors detected by the app and recorded by the researchers ranged from work-related challenges, such as preparing complex drafts or debugging code, to social stressors, like navigating difficult conversations or attending gatherings. Daily life stressors, including routine tasks such as cooking or dealing with unexpected delays, were also captured, along with positive stressors, such as celebrating achievements or enjoying"}, {"title": "4.1.2 Proportion of stress events that require interventions", "content": "The researchers logged 98 events (48 by RA and 50 by RB). Of these, 43, 30, and 25 events were negative, neutral, and positive, respectively. Figure 2 shows the number of stressors and how many were used for interventions on each day during the study. Out of the 98 events, the researchers felt the need to engage with the chatbot for 22 events (RA = 16, RB = 6). Of those, 20 were negative, and 2 were neutral. Researchers required an intervention on only half of those days when at least one stress event was reported. The rating distributions of interventions were: for RA, Very poor (6.25%), Poor (18.75%), Acceptable (25.00%), Good (43.75%), and Very good (6.25%); for RB, Acceptable (16.67%), Good (66.67%), and Very good (16.67%).\nInterestingly, certain negative events, such as \"Working on a paper,\" \"Rushing to catch a flight,\u201d \u201cCompleting pending work,\" and \"Feeling hungry,\" did not require intervention. This was attributed to various factors, including the perception that the event was manageable without assistance, the temporary or fleeting nature of the stressor, or a personal preference for self-reliance in handling the situation. This observation highlights that merely detecting a stress state is insufficient; recognizing the specific stressor is critical for delivering tailored interventions. Additionally, stressors like \"coding issues\" sometimes warranted intervention but not consistently in every occurrence. This highlights that simply identifying a stressor may also not be sufficient; participant feedback or additional contextual cues are necessary to determine when an intervention is genuinely needed."}, {"title": "4.2 Common Themes in Our Experience with DeStressify and StressGPT", "content": "We begin by highlighting the common themes that emerged from both researchers' experiences with their respective LLM chatbots (DeStressify and StressGPT) and wearable-triggered stressor logging, offering insights into the similarities in how these systems functioned and how they were perceived during interactions."}, {"title": "4.2.1 Need for Continuity and Stressor Awareness in Chatbot Interactions", "content": "The chatbot's effectiveness was significantly hindered by its inconsistent integration of continuity and contextual awareness, despite having access to shared stressors. While it occasionally referenced past interactions, it often failed to do so, making conversations feel less personalized and disrupting the sense of ongoing support. Instead of tailoring responses based on the history of shared stressors, the chatbot often provided generic solutions that did not address the evolving nature of the user's challenges. RB noted, It felt like the chatbot did not really know who I am and would have given similar responses to anyone asking similar questions. This absence of context integration emphasized the need for chatbots to track and link past stressors with current interactions, ensuring a more dynamic, responsive system that delivers consistent, relevant support."}, {"title": "4.2.2 Striking the Perfect Balance Between Emotional Support and Practicality", "content": "A key insight was the need for chatbots to balance emotional and practical support. While strategies like time management and breathing exercises were helpful, they were incomplete without emotional support. Purely emotional responses, without actionable advice, were ineffective in addressing stressors. RA valued interventions that reframed emotional states, such as linking frustration to the PhD journey, while R\u00df appreciated the chatbot's emojis, which felt like a human-like touch to the interaction. This underscores the need for a holistic approach, where chatbots offer both emotional support and practical guidance, ensuring users feel fully supported in managing their stress."}, {"title": "4.2.3 Clarity and precision in chatbot responses", "content": "Participants preferred concise responses that directly addressed their issues, as they helped reduce cognitive load and maintained efficiency in the interaction. RB noted that the chatbot often provided long, structured responses to simple questions, which made the conversation feel more mechanical and less human-like. On the other hand, RA particularly appreciated interventions that offered an explicit, singular action or suggestion rather than multiple options or vague guidance. This preference for specificity was especially apparent in emotionally charged or complex situations, where a precise, direct solution was more helpful than a broad range of solutions [3]. The need for clarity and directness in the chatbot's responses was a key theme, underscoring the importance of delivering tailored interventions based on the user's unique stressor."}, {"title": "4.3 Contrasting Real-Time One-Shot vs. End-of-Day Interactive Chatbot Experiences", "content": "Next, we present the findings focusing on the differences in researcher experiences between real-time one-shot interventions provided by DeStressify and the end-of-day interactive sessions facilitated by StressGPT."}, {"title": "4.3.1 Number of Interventions Required", "content": "RA primarily used DeStressify in real-time immediately after logging stressors that required interventions, whereas RB engaged in conversation with StressGPT towards the end of the day. Figure 2 illustrates that while the average number of stressors logged per day was comparable for RA (2.18) and RB (2.27), RA engaged with significantly more interventions per day (0.73) compared to RB (0.27) (almost 3 times higher). This suggests that real-time interventions are more likely to be utilized when stressors are momentary. Factors such as the transient nature of certain stressors may make immediate intervention more relevant and actionable, providing support precisely when needed. In contrast, engaging with StressGPT at the end of the day may reduce the perceived need for interventions, as some stressors might have already dissipated or been resolved by that time. Although stressors such as meeting with professor or long wait time were common for both researchers, only RA asked for interventions."}, {"title": "4.3.2 Targeted Interventions for DeStressify vs Human-Like Yet Not Domain-Specific for StressGPT", "content": "RA found that the wearable-triggered stressor logging app, paired with the LLM chatbot, provided targeted interventions tailored to specific stressors with effective, actionable strategies. For work challenges, breaking tasks into smaller steps improved clarity, while physical activities and environmental changes helped reset mental states. Social stressors were addressed through confidence-building interventions, like affirmations and reframing negative thoughts. Positive perspectives on frustrating situations also enhanced engagement and effectiveness. For example, targeted interventions, such as structured debugging for stressors like replicating a paper, were more effective than generic strategies like Progressive Muscle Relaxation (see A.2). In contrast, generic responses, like mindfulness exercises or repeated advice (e.g., \"take a deep breath\"), often caused frustration, reducing the chatbot's perceived usefulness. RA preferred more dynamic, contextually relevant responses.\nAlthough RB found StressGPT more human-like compared to typical rule-based chatbots, the chatbot often acted like a general-purpose AI, responding to queries outside the stress management domain, which reduced its relevance. Additionally, it was quick to offer suggestions without fully understanding the user's stressor or context, generating lengthy responses without asking clarifying questions. This lack of active listening made the interaction feel less personal and empathetic. The structured, verbose responses felt robotic and detached, resembling any other general-purpose GPT, such as ChatGPT, more than a specialized stress management assistant. Furthermore, the fast text generation speed disrupted the conversational flow, making it challenging to stay engaged as responses were quickly produced before they could be fully read."}, {"title": "4.3.3 Privacy Concerns", "content": "For DeStressify, RA only shared stressors and locations that did not carry sensitive or risky identifiable information. StressGPT raised privacy concerns for RB, especially when discussing sensitive or deeply personal topics. RB expressed hesitation in fully opening up during interactions, fearing that private information might not be adequately protected or might be misused. This reluctance emphasized the need for stress management chatbots to establish trust and security, ensuring that users feel confident sharing personal information without the fear of breach or misuse. Stress management chatbots must ensure privacy, clear data policies, and transparency, fostering trust and engagement for more effective and personalized support."}, {"title": "5 Discussions", "content": ""}, {"title": "5.1 Challenges in Integrating Wearables and LLMs for Stress Management", "content": "Advances in wearable AI for real-time stress detection and LLMs capable of generating adaptive interventions hold significant promise for stress management. A natural assumption might be that seamlessly connecting wearable AI to LLMs could create the ultimate stress management system. However, this study's findings revealed several challenges in effectively bridging these technologies.\nWhile LLMs excel at generating one-time interventions and engaging in extended conversational support, their integration with wearable AI raises significant questions about whether interventions align with users' event descriptions or stressors. Firstly, our findings reveal a discrepancy between stress detected by wearable AI and the user's actual need for intervention. Out of 98 stress events identified, only 22 (approximately 20%) required an intervention, indicating that delivering interventions solely based on detected events is not optimal.\nWearable AI detects both positive and negative stress events, but not all negative events need intervention. In this study, fewer than half of the negative events prompted a desire for intervention. Systems that intervene based solely on stress detection can create unnecessary burdens, leading to disengagement and reduced utility."}, {"title": "5.2 Opportunities in Integrating Wearables and LLMs for Stress Management", "content": "Prior research underscores the importance of interventions tailored to users' specific stressors [16, 36]. Our findings highlight the potential of wearable stressor-tracking apps like CuesHub, which combine physiological data with contextual cues, such as location and emotional state, to personalize interventions. By integrating these insights into LLMs, stress management systems can deliver more precise and responsive support that aligns with users' immediate needs. Effective stress management systems must transition from automatic, event-triggered responses to more selective approaches that prioritize user needs and preferences. By analyzing stressor descriptions, systems can better distinguish events that truly need intervention, improving relevance and impact.\nOur study explored two approaches to engaging with the LLM chatbot: real-time and reflective interactions. In the real-time approach, delays in the delivery of interventions can significantly reduce their effectiveness, as stressors often require immediate attention. Although the reflective approach can tolerate delays, it may still benefit from faster interactions, as timely responses can support users in processing their experiences more effectively. By incorporating proactive and predictive mechanisms, wearable AI-LLM systems can anticipate potential stressors and intervene early shifting from reactive to preemptive support and enhancing overall stress management.\nWe also observed that the LLM chatbots sometimes successfully generated interventions based on previously shared events but were limited to events for which users explicitly requested support. Expanding its access to the full history of wearable-detected events could provide more context, enabling more personalized and informed interventions."}, {"title": "6 Limitations", "content": "This study has several limitations that affect its generalizability. The small sample size of two researchers, both with expertise in wearable and AI technologies, introduces potential bias and limits the broader applicability of the findings. Our perspectives on AI, influenced by both optimism about its potential and caution about ethical concerns, may have shaped our interpretation of the results. The absence of a control group further limits the ability to isolate the effects of wearable-triggered stress interventions, especially given variations in chatbot design and interaction timing. Additionally, the study relies heavily on subjective experiences and qualitative data, which constrain objective assessments of intervention effectiveness. Although we have strong backgrounds in wearable and AI technologies, we lack formal expertise in stress management and mental health. To enhance generalizability, future research should involve larger, more diverse participant samples, include controlled comparisons, and incorporate objective measures for evaluating intervention effectiveness."}, {"title": "7 Conclusion and Future Works", "content": "This study demonstrates the potential of wearable AI integrated LLM chatbots like DeStressify and StressGPT to offer valuable support for stress management, while also highlighting key areas for improvement. The findings indicate that the perceived effectiveness and impact of interventions is heavily influenced by factors such as timing, personalization, and contextual relevance. Although the chatbots provided useful assistance, limitations like repetitive suggestions, long responses, and a lack of memory retention from past interactions often compromised their ability to offer truly impactful support. These challenges highlight the need for advancements in chatbot systems, particularly with wearable integration. Looking ahead, future LLM chatbots, combined with wearable devices, have the potential to become more adaptive, effective, and user-centered, offering real-time, comprehensive, and personalized support for stress management."}, {"title": "A Appendix", "content": ""}, {"title": "A.1 Design Templates of custom GPT", "content": ""}, {"title": "A.1.1 DeStressify", "content": "I am pursuing a PhD in computer science. I primarily work remotely from home on my research, which involves multiple virtual meetings each week, including two research discussions with my professor to review progress and receive guidance. As a PhD student, I often experience stress related to managing complex research tasks, anxiety about future career prospects, and maintaining work-life balance. The goal of this GPT is to assist in developing effective strategies for managing my stress and stressors, maintaining motivation, and sustaining productivity throughout my academic journey. Below are the instructions for this GPT.\n(1) Role Definition: This GPT should act as a stress intervention specialist trained to provide personalized, actionable advice to help manage stress effectively.\n(2) Tone and Approach: Ensure the GPT outputs are empathetic, supportive, and practical. Emphasize under- standing and acknowledging the user's stressors to foster trust and relatability. Avoid complex jargon; prioritize simplicity and clarity in responses.\n(3) Core Functionality: Assess the user's input for specific stressors and location details to tailor its advice. Suggest interventions that are realistic and achievable within the user's context.\n(4) Output Requirements: Provide stress management techniques that directly address the described stressor. Adjust recommendations based on location.\n(5) Constraints and Best Practices: Avoid generic or overly broad advice; focus on specific, user-centered recom- mendations. Ensure responses are concise yet detailed enough to guide the user through the intervention.\n(6) Continuous Improvement: Incorporate feedback mechanisms to allow the user to indicate whether the advice was helpful. Adjust future outputs based on user preferences and past interactions."}, {"title": "A.1.2 StressGPT", "content": "This GPT is a supportive guide to help users manage everyday stress, grounded in the principles of Cognitive Behavioral Therapy (CBT). It focuses on specific CBT techniques, including Cognitive Restructuring, Problem-Solving Skills, Journaling and Thought Records, Socratic Questioning, Reframing, and Stress Inoculation Training (SIT). Stress GPT helps users identify and challenge negative thought patterns, develop healthier coping mechanisms, and build resilience through practical, actionable strategies. It provides personalized advice aligned with the user's preferences, lifestyle, and unique stressors, creating a calm and uplifting space. Responses are empathetic, clear, and aimed at fostering self-awareness and emotional well-being."}, {"title": "A.2 An Illustration of Generic vs Targeted Prompts for DeStressify", "content": "Generic Prompt: I am stressed right now. Can you help me?\nResponse: It sounds like you're experiencing stress tied to managing the complexities of your PhD journey. The combination of remote work, high-level research demands, career uncertainties, and balancing your personal life in a solitary environment can definitely feel overwhelming. Here's a targeted approach to help you decompress right now:\nQuick Intervention: Progressive Muscle Relaxation (PMR)\nThis exercise is especially helpful when you're working from home and need to release tension without leaving your desk.\n(1) Sit comfortably in your chair, or lie down if you prefer.\n(2) Focus on one muscle group at a time, starting from your toes:\n\u2022 Curl your toes tightly and hold for 5 seconds, then release.\n\u2022 Move up to your calves: tighten them, hold, and release.\n\u2022 Work through your thighs, abdomen, chest, arms, and shoulders, ending with your face.\n(3) With each release, breathe deeply, imagining the tension leaving your body.\n(4) End by taking three slow, deep breaths and noticing how your body feels.\nThis technique not only reduces physical tension but can also clear your mind to approach your tasks more calmly.\nTargeted Prompt: I am stressed right now because of trying to replicate a research paper. Can you help me?\nResponse: Struggling with understanding and implementing a paper is a common stress point for researchers, and it's entirely valid to feel overwhelmed. Let's break this down into manageable steps to alleviate the stress and help you move forward effectively.\nIntervention: Structured Debugging and Support\n(1) Step Back and Breathe:\n\u2022 Take a 5-minute break to reset. Practice box breathing:\n\u2022 Inhale for 4 seconds, hold for 4 seconds, exhale for 4 seconds, and hold again for 4 seconds. Repeat this cycle three times.\nThis will calm your nervous system, helping you approach the problem with a clearer mind.\n(2) Decompose the Problem:\n\u2022 Break the challenging portion of the implementation into the smallest possible steps or components. Write down exactly what you understand and what is unclear.\n\u2022 Identify the precise point where the confusion or difficulty arises."}, {"title": "(3) Seek Clarification", "content": "\u2022 Check for supplementary materials: many papers have public GitHub repositories, appendices, or links to datasets that might provide additional insight.\n\u2022 If possible, reach out to the authors with a clear, concise email explaining your specific question. Authors often appreciate when their work is being engaged with thoughtfully.\n(4) Leverage Support Networks:\n\u2022 Post your issue on forums like Stack Overflow, Reddit's r/MachineLearning, or any academic community.\n\u2022 If you have peers or colleagues, schedule a quick call or chat to explain your understanding and hear their perspective. Often, talking it out helps untangle the problem.\n(5) Make Peace with Partial Progress:\n\u2022 Remind yourself that replication can be iterative. Even understanding just one more piece today is progress.\nWould you like help drafting a specific message to an author or academic forum? Alternatively, we could outline the problematic portion together here, and I could help brainstorm possible explanations or approaches."}]}