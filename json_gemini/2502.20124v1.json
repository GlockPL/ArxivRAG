{"title": "Exploring Open-world Continual Learning with Knowns-Unknowns Knowledge Transfer", "authors": ["Yujie Li", "Guannan Lai", "Xin Yang", "Yonghao Li", "Marcello Bonsangue", "Tianrui Li"], "abstract": "Open-World Continual Learning (OWCL) is a challenging paradigm where models must incrementally learn new knowledge without forgetting while operating under an open-world assumption. This requires handling incomplete training data and recognizing unknown samples during inference. However, existing OWCL methods often treat open detection and continual learning as separate tasks, limiting their ability to integrate open-set detection and incremental classification in OWCL. Moreover, current approaches primarily focus on transferring knowledge from known samples, neglecting the insights derived from unknown/open samples. To address these limitations, we formalize four distinct OWCL scenarios and conduct comprehensive empirical experiments to explore potential challenges in OWCL. Our findings reveal a significant interplay between the open detection of unknowns and incremental classification of knowns, challenging a widely held assumption that unknown detection and known classification are orthogonal processes. Building on our insights, we propose HoliTrans (Holistic Knowns-Unknowns Knowledge Transfer), a novel OWCL framework that integrates nonlinear random projection (NRP) to create a more linearly separable embedding space and distribution-aware prototypes (DAPs) to construct an adaptive knowledge space. Particularly, our HoliTrans effectively supports knowledge transfer for both known and unknown samples while dynamically updating representations of open samples during OWCL. Extensive experiments across various OWCL scenarios demonstrate that HoliTrans outperforms 22 competitive baselines, bridging the gap between OWCL theory and practice and providing a robust, scalable framework for advancing open-world learning paradigms.", "sections": [{"title": "I. INTRODUCTION", "content": "Open-World Continual Learning (OWCL) [1], [2] represents a highly practical yet profoundly challenging machine learning paradigm. In OWCL, a model must continually adapt to an unbounded sequence of tasks in a dynamic open environment [3], [4], where novelties might emerge in testing unpredictably over time [5]\u2013[7]. Unlike traditional learning models that operate in a closed and fixed set of classes, OWCL aims at learning on the job in an open-world assumption with the goal of recognizing unseen/open samples and incrementally acquiring knowledge from new tasks without forgetting [8]\u2013[10]. Due to the potential occurrence of novelties in continual learning (CL) [11], OWCL models need to accurately detect unknowns to prevent unknown samples from being incorrectly classified into known categories. At the same time, OWCL requires the model to retain previously learned knowledge without forgetting while continually performing open detection. In summary, the open detection for unknowns and classification for knowns are interdependent in OWCL: on the one hand, the presence of unknowns complicates the trade-off between knowledge stability [11], [12] and knowledge plasticity [13], [14]; on the other hand, the incremental learning of new tasks makes open detection in an embedding space more challenging with the expanding knowledge space.\nDespite growing attention to OWCL in recent years, current approaches [10], [15] still treat OWCL as a simple combination of open-set recognition and CL, rather than as an integrated paradigm, making it only effective in knowledge transfer related to known samples, while neglecting the knowledge derived from unknown samples. Therefore, a promising OWCL model must be capable of knowns-unknowns knowledge transfer, i.e., effectively transferring knowledge both for known categories and unknown samples. Besides, there is a lack of comprehensive problem formulation and thorough empirical explorations of potential issues in OWCL, making it difficult to compare the performance of existing methods and making it unclear how to choose one method over another. In response, this paper explores the issues arising in OWCL and adopts an integrative perspective to deal jointly with unknown samples' detection and known samples' classification, particularly the knowledge transfer for both unknowns and knowns.\nAs shown in Figure 1, in real-world scenarios, labeled samples for a new category are rarely available all at once or from a single task [9]; instead, they are acquired incrementally across different tasks over time [16], [17]. Hence, in OWCL, a certain category may repeatedly appear across different tasks with varying data distributions. Moreover, as new tasks are learned incrementally, the boundaries between known categories become increasingly ambiguous. As a result, the repeated appearance of open/unknown samples further makes it difficult for the OWCL model to distinguish between the unknown and known samples. Accordingly, as outlined in Table I, there are two fundamental principles for refining OWCL scenarios: (1) whether a known class with changing data distribution appears in different tasks during the training phase, and (2) whether an unknown sample repeatedly appears in different tasks during the testing phase.\nTherefore, based on the principles of scenario categorization, we extend existing CL scenarios (i.e., task-incremental learning, domain-incremental learning, and class-incremental learning) to the context of OWCL. However, different from CL, OWCL does not permit task identification, as unknown samples may randomly appear during testing [18]. Thus, task-incremental and domain-incremental learning are insufficient for describing the OWCL scenarios. In response, we introduce a novel scenario definition, termed knowledge-incremental learning (KIL): models must be able to solve each task seen so far without knowing which task is being performed, where the training sets across different tasks are not strictly non-overlapping; that is, shifts in the distribution of known categories may occur. KIL incorporates class-incremental learning and accommodates shifts in the distribution of specific categories, thereby providing a more realistic scenario description for OWCL and posing greater difficulty. Accordingly, we then introduce four distinct scenarios for OWCL of increasing difficulty: class-incremental with non-repetitive open samples (CINO), class-incremental learning with repetitive open samples (CIRO), knowledge-incremental learning with non-repetitive open samples (KINO), knowledge-incremental learning with repetitive open samples (KIRO).\nRecently, much research [19]\u2013[21] highlighted the significance of both inter-task and intra-task open samples in developing effective open-set recognition. Hence, this work proposes an OWCL model to distinguish inter-task open samples from each previously learned task, where inter-task open samples randomly appear across different tasks. Meanwhile, the OWCL model must differentiate intra-task open samples from known categories within the same task while preserving accurate classifications of the known categories. Then, to explore potential issues of OWCL, we conduct extensive comparisons with current competitive baselines under the most challenging scenario, KIRO."}, {"title": "From the experimental results, we observed that continually detecting novelties in OWCL requires consideration of inter-task and intra-task open samples. Moreover, there is an intrinsic interplay between open detection and classification for known categories. Specifically, as illustrated in Figure 2 (a), we employ a classical CL baseline, EWC [5], to learn the original embedding space under the KIRO scenario. It can be observed that with the incremental acquisition of new tasks and the recurring appearance of open samples, the embedding distributions of different tasks may overlap, rendering the model incapable of detecting inter-task open samples. Moreover, due to the similarity between certain open samples and existing known classes, some intra-task open samples might be erroneously classified into known categories. In Figure 2 (b), the competitive OWCL baseline Pro-KT [18] improves task boundaries for detecting inter-task unknown samples but adversely impacts the detection of intra-task open samples. This occurs because intra-task open samples within the convex hull [22] of known categories (as denoted by pink shadows) are prone to misclassification as known categories. Therefore, as evidenced by Figure 2 (a) and (b), both inter-task and intra-task open samples significantly amplify the open risk associated with unknowns within the unified knowledge space, further exacerbating incremental classification errors of knowns.\nOur experimental findings reveal a significant interaction between open detection and incremental prediction in OWCL, while existing OWCL works [1], [9], [10] claimed that the open detection and the incremental classification of known samples are orthogonal. Thus, the existing OWCL methods rely on a simple continual learning framework combined with an open detection module, which are only effective in the CINO scenario but fail in more complex OWCL settings. This motivates the need for models to enable effective knowledge transfer-not only to handle both known and unknown samples but also to update and expand the knowledge space for OWCL incrementally. Accordingly, we establish a unified formulation to address the OWCL problem, grounded in robust theoretical principles. To tackle the challenge of knowns-unknowns knowledge transfer, we introduce the nonlinear random projection (NRP) for OWCL to facilitate the learning of a more linearly separable embedding space, thereby reducing errors in knowledge transfer for known samples. Meanwhile, we propose a distribution-aware prototypes (DAPs) approach, leveraging generative replay with novel pseudo-open samples to transfer knowledge related to novelties while updating the representation of open samples during the OWCL process.", "content": "II. RELATED WORK\nContinual learning (CL) [5], [23] usually operates under the closed-world assumption, where the system assumes that all test or deployment samples belong to one of the predefined classes seen during training [4], [24], [25]. However, this assumption implies no exposure to novel or previously unseen data during testing, which is far from realistic in dynamic, real-world environments [2], [2], [18]. In practice, continual learning systems are frequently confronted with new, unknown classes, necessitating the ability to detect, adapt to, and incrementally learn these novelties, continually acquiring new knowledge over time [26]\u2013[28]. Hence, it is imperative to detect and incrementally learn novelties while acquiring knowledge without forgetting over time.\nMore recently, continual learning in an open world or simply Open-world Continual Learning (OWCL) has been appealing yet challenging with increasing works [2], [11]. In order to enable existing CL models to effectively detect open/unknown samples, primary OWCL research utilized open-set recognition (OSR) and out-of-distribution (OOD) detection methods as expansive components into CL baselines to tackle the OWCL tasks. [29] proposed an OSR framework based on extreme value theory, incorporating incremental tasks to manage dynamic learning environments. [30] introduced an approach leveraging contrastive clustering and an energy-based identification method [31] for handling dynamic data, enabling the system to recognize and accommodate novel inputs during continual learning. Building on these previous efforts, recent OWCL studies emphasized the integration of OOD detection techniques within the continual learning paradigm. For instance, [1], [10], [18] highlighted the importance of novelty detection as a crucial aspect of open-world learning, suggesting that existing OOD techniques could be effectively adapted to the continual learning setting. In a complementary development, frameworks such as SOLA [2], [32] have been proposed, combining OOD detection with incremental task adaptation to facilitate novelty detection and task-specific learning in an open-world context.\nNevertheless, current research still relies on simplistic approaches by combining CL methods with OOD detection components [10], [15], [18], [19], [26], [28], and several crucial challenges persist in OWCL. First, the absence of a standardized and general problem formulation makes it challenging to compare the performance of existing methods in a consistent setting, leading to fairness issues. Second, there are still experimental and theoretical gaps in exploring the knowledge transfer for known and unknown samples in OWCL. Finally, there is a lack of theoretical foundation to guide the design of an OWCL model that supports knowledge transferring and knowledge updating.\nTo address these limitations, this paper makes several key contributions. First, we provide rigorous theoretical analyses with a formal problem construction for understanding the variations and challenges inherent to OWCL. By constructing four distinct scenarios, we conduct extensive empirical experiments and systematically explore the factors influencing OWCL model performance under these different scenarios, identifying a significant interplay between open detection and the classification of known samples. Finally, we propose a novel framework, termed HoliTrans, designed to effectively address knowns-unknowns knowledge transfer by introducing NRP and proposing DAPs in an adaptive knowledge space. The proposed HoliTrans serves as a strong baseline for future research, demonstrating its robustness and efficacy across a range of OWCL scenarios with abundant experiments."}, {"title": "III. UNDERSTANDING OWCL: FORMULATION AND PRELIMINARY EXPERIMENTS", "content": "In this section, we first formalize the problem of OWCL by integrating the optimization with open risk from unknowns and incremental prediction errors from knowns. Then, we provide an in-depth categorization scheme for different OWCL scenarios. Subsequently, to explore potential issues in OWCL, we conduct abundant experiments with baselines using different kinds of classifiers (i.e., Softmax-based and NCM (Nearest Class Mean)-based classifiers) on different baselines.\nIn OWCL, samples not seen in the training set may appear during testing, thus, we use  $D_{tr}$ and $D_{te}$ to distinguish between the training set and test set; all superscripts indicate the task order. We list the notations throughout this paper in Table II for better clarification.\nCurrently, there is a lack of consensus regarding the OWCL problem formulation within the community. In response, we develop a comprehensive and general problem definition, taking into account both the inherent open risk and the incremental classification error that arise in all OWCL scenarios as follows:\nEach task i has $N_i$ training samples and $M_i$ classes  $D_{tr} = {x \\in X^1, y \\in Y^1}$. In the training phase, only data pertinent to the current task is accessible, while the test samples $D_{te} = {x \\in \\cup_{j=1}^{M_i}Y_j \\cup \\cup_{Y \\notin Y^1}}$. Given the latent representation of the current task t's training set h($D^t_{tr}$), we denote  $\\mu$ (h(x), h($D^i_{tr}$)) as the open risk of a sample x from task i's test set $D^i_{te}$. The goal of Open-world continual learning (OWCL) is to learn a uniform function h* that minimizes the open risk and incremental prediction error jointly, across all seen tasks [1,t]:\n$arg \\underset{h* \\in H}{min} (1 - \\lambda) \\sum_{i=1}^{t} \\mu(h(x), h(D^i_{tr})) + \\lambda \\sum_{i=1}^{t} E_{D(i)}(h),$ where H is a universal function space,  $E_{D(i)}(h)$  is the generally suggested prediction error term on task i [4], $\\mu$ can be defined on any scoring function for OOD detection, $\\lambda$ is a hyper-parameter to balance the open risk and the incremental prediction error.\nAs discussed previously, traditional CL is usually categorized into three scenarios, i.e., incremental learning, domain-incremental learning and class-incremental learning, based on whether task identifications are provided during tests [33]. However, in OWCL, it is impossible for the model to know the task identifiers, because unknown/open samples may randomly appear alongside known ones during testing. Furthermore, the shifting distributions of known classes and the repetitive presence of open samples hinder the current CL three scenarios [33] from being compatible with OWCL problems. Consequently, four distinct scenarios of increasing difficulty (presented in Table I).\nFirst, in the class-incremental learning with non-repetitive open samples (CINO) scenario, the training set for each task is introduced incrementally without repeated classes. Once previously unseen samples are encountered during testing, they"}, {"title": "IV. THEORETICAL BASES", "content": "This section defines a new knowledge space and introduces a generic incremental prediction error term for OWCL. We theoretically prove a tighter bound for incremental prediction error, providing several insights for designing better OWCL algorithms by considering knowledge from knowns and unknowns.\nFollowing a general definition from [4], we extend the definition of open space O for OWCL as follow:\n$O=S-\\bigcup_{x \\in \\{D^i_{tr}\\\\}_{i=1}^{t}}K(x),$ where S is the universal space, and  $K(x)$ is the known space obtained by each trained task i $\\in$ [1, t].\nNote that it is not necessary to classify each open sample into exactly true unknown classes. For the sake of simplicity, we follow the general implementations [37], setting all unknown samples to one unified unknown as [un]. Hence, given the problem formulation in Definition 1, we assume that $Y^1-\\bigcup_{j=1}^{M_i}Y_j = {Y_{un}}$ where Yun represents the one unknown class and $M = M_i + 1$. Therefore, from the probabilistic perspective, we can refine the left summand term (A) in Equation 1 as:\n$\\sum_{i=1}^{t}\\mu(h(x), h(D^i_{tr})) = R_{p, un}(h)$ = \n$\\sum_{i=1}^{\\infty} h(x, Y_{un}) dP_{X|Y=Y_{un}}(X)$.\nLemma 1. Let ht be the current function trained on task t and  $h_{t-1}$  is the model trained on the previous task t \u22121. Then, the ht's task-specific prediction error on an arbitrary task i < t has an upper bound:\n$D_{te}^i (h_t) \\leq D_{te}^i(h_t, h_{t-1}) + D_{te}^i(h_{t-1}),$ where  $E_{D_{te}} (h_t, h_{t-1}) = Ex~Di_{te} [h_t(x) \\neq h_{t-1}(x)]$.\nThis lemma shows that the prediction error of the current model ht's on an arbitrary task i is bounded by the difference between ht and its previous model ht\u22121 plus the prediction error of ht\u22121 on task i. Additionally, given the presence of  $E_{D_{te}}(h_{t-1})$, the task-specific prediction error bound of ht\u22121 will be inherited to $E_{D_{te}}(h_t)$, which means the incremental prediction error will gradually accumulate as new task coming.\nLemma 2. Let ht be the current function trained on task t and  $h_{t-1}$  is the model trained on the previous task t \u2013 1. The task-specific prediction error on task i(i < t) has an upper bound:\n$E_{D_{te}^i}(h_t) \\leq D_{te}(h_t, h_{t-1})$+\n$\\frac{1}{2} HAHA (D_{te}^i, D_{tr}^t)+ D_{te}^i(h_{t-1}),$ where His a universal hypothesis space with finite VC dimension [39], and $d_{HAHA} (D^i_{tr}, D^t_{tr})$  denotes the divergence between the distributions $D^i_{tr}$ and $D^t_{tr}$. From a perspective of Bayesian theory, duan ($D^i_{tr}, D^t_{tr}$) can be approximately calculated as $2 sup_{h \\in H} P_{a~D^i_{tr}}[h_t(x) = 1] - P_{a~D^t_{tr}}[h_t(x) = 1]$ to quantify the task-specific error.\nLemma 2 establishes a theoretical foundation for knowledge transfer by demonstrating that when the divergence between task i and the current task t (i.e., $d_{IHAH} (D^i_{tr}, D^t_{tr})$) is sufficiently small, the predictions of $h_{t-1}$ on  $D_{te}^i$ can effectively serve as a surrogate loss. This surrogate loss is crucial in mitigating forgetting by anchoring predictions on previously learned tasks. Based on this principle, many CL and OWCL methods design knowledge transfer mechanisms to minimize divergence, preserving task-specific knowledge while integrating new knowledge effectively. Then, by using the task-specific prediction error bound in Lemma 2, we can derive the incremental prediction error bound by applying Lemma 1 and Lemma 2:\nWith a probability of at least 1 \u2013 $\\delta$>0, the incremental prediction error bound can be refined as:\n$\\sum_{i=1}^{t} E_{D^i_{te}}(h_t) \\leq \\sum_{i=1}^{t-1} { \\alpha_iD^i_{te},(h_t)+ \\alpha_iD_{te}(h_t, h_{t-1})+ \\frac{1}{2} D^t_{te}(h_t, h_{t-1}) } +\\frac{1}{2} \\sum_{i=1}^{t-1} \\beta_i d_{HAH}(D^i_{tr}, D^t_{tr}) +\\sum_{i=1}^{t-1} (\\alpha_i + \\beta_i) D_{te}^i(h_{t-1}) + C_1 +$ \n$\\sum_{i=1}^{t-1} B_{te}(h_t, h_{t-1}) + \\sum_{i=1}^{t-1} \\alpha E(h_t, h_{t-1}) + \\sum_{i=1}^{t-1} B_{te}^i(h_{t-1})+E_{D^t_{te}}(h_t)+ \\frac{1}{2} \\sum_{i=1}^{t-1} \\beta_i d_{HAHA}(D^i_{tr}, D^t_{tr}) +C_2$.\nFollowing [40], given each task i has a deterministic ground-truth classifier $f^i$: $R^n$ \u2192 {0,1}, the C\u2081 can be calculated by ERM-Based generalization bound:\n$\\sum_{i=1}^{t} D(h_t) = \\sum_{i=1}^{t}\\left (  \\sqrt{(\\frac{1+\\sum_{i=1}^{t-1} \\beta_i)}{N_i}} +(\\frac{2eN}{N_i})+\\sqrt{(\\frac{1+\\sum_{i=1}^{t-1} \\beta_i)}{N_i}} +(\\frac{2eN}{N_i}) \\right )^2 + \\sum_{i=1}^{t} O (\\frac{d}{N_i}log (\\frac{2eN}{d})+8log (\\frac{2}{\\delta} )) \\right) $. Thus, C\u2081 is a constant with no trainable parameters and the Theorem 3 is proofed.\nNotably, our theory is compatible with all the incremental scenarios (TIL, DIL and CIL) and is capable of addressing all four OWCL settings we discussed in the introduction. In addition to the data discrepancy term, another crucial component in Theorem 3 is the model discrepancy term, which effectively characterizes the optimization direction and extensions (or isolations) of the previously trained model from t \u22121 to t."}, {"title": "V. METHODOLOGY", "content": "Motivated by empirical findings and theoretical analysis, the interaction between open risk and incremental prediction error drives us to approach the OWCL problem as an integrated whole. Hence, we design a model that effectively transfers knowledge for both known categories and unknown samples, i.e., knowns-unknowns knowledge transfer.\nGiven a projection P : R \u2192 R', an empirical estimate for the data discrepancy term is:\n$\\sum_{i=1}^{t-1}\\beta E d_{HAHA} (D^i_{tr}, D^t_{tr}) = \\frac{1}{2}\\sum_{i=1}^{t-1}\\beta E d_{HAHA} (P (B^t), P (B^i)) =  \\frac{1}{Nt}\\sum_{x \\in S_t}^{min} [-\\log \\left( \\frac{1}{N}\\sum_{x \\in X_i} e [d (P(x))]  \\right) ] + \\sum\\frac{1}{N_t}[-\\log \\left( \\frac{1}{N}\\sum_{x \\in X_i} d [P(x))]  \\right)]$ where $B^t$ and $B^i$ are experience buffers drawn from training set  $D^i_{tr}$ and $D^t_{tr}$ of tasks t and i, respectively.\nGiven the most difficult scenario, KIRO, each task's training set comes incrementally with repeated classes and changing distributions, which may result in overlapping across different tasks' semantic spaces, thus increasing the inter-task open risk. Additionally, the repeated appearance of open samples may increase the intra-task open risk by identifying open/unknown samples as known. Therefore, it is not enough to pull together all seen/known samples belonging to the same class, but we need to (1) find a proper projection with improved linear separability and (2) determine appropriate experience buffers to describe embedding distributions of different tasks.\nSubsequently, we propose a novel OWCL framework that can jointly learn knowledge about known classes and unknown samples, effectively generalizing under open-world assumptions while excelling in both open detection and incremental classification, termed HoliTrans. HoliTrans can infer general patterns from specific observed instances, which is crucial for adapting to new classes and detecting novel samples within all the OWCL scenarios.\nGiven a sequence of tasks, the training data and labels from the first task may better represent the subsequent tasks than the data used to train the original pre-trained model. Hence, we first need to fine-tune the pre-trained model via a Parameter-Efficient Transfer Learning (PETL) strategy [41], [42]. Moreover, due to the advantages of the random projection (RP) layer being independent of the model, it can be applied to any feature extractor. Therefore, it can be applied orthogonally to the widely applied PETL strategy, which does not alter any parameters of the original pre-trained model.\nIn this work, we fine-tune the pre-trained model with the first task by learning PETL parameters and then freeze them for the subsequent tasks. Here, we conduct three competitive PETL methods: AdaptFormer [43], SSF [44], and VPT [45]. After fine-tuning the pre-trained model with the first task, we conduct a novel two-stage training approach for each task (as shown in algorithm 1).\nGiven a new task t, we extract features from its training set using the fine-tuned pre-trained model and obtain the corresponding embeddings. In the first stage training, we introduce the nonlinear random projection (NRP) from the assumption that nonlinear random interactions between embedding distributions may be more linearly separable than the original in a higher-level embedding space, with corresponding mathematical properties that have been discussed extensively [34], [46], [47]. Thus, the embeddings can be improved as:\n= g($(Dt_r)W).\nThen, we encode the labels into a one-hot format, obtaining the label matrix Yt. Accordingly, we update the model's Gram matrix and class prototype matrix as follows:\nGit = Git-1 + Ht(Ht)T ,\nCi = Ci\u22121 + H Y.\nGiven the training set of task t, each class's prototype can be acquired from Equation 15. Since the prototype for each known category is updated through NPR, we refer to these prototypes as Distribution-Aware Prototypes (DAPs). Additionally, we compute the mean-variance of distances between samples of all classes and their prototypes:\n\u03b4t =\\frac{\\sum_{i=1}^{t-1}\\delta_i + \\sum_{i=1}^{Nt} (Ht - H_t)^2}{\\sum_{i=1}^{t-1} N_i}. To enable HoliTrans to acquire knowledge from known classes without forgetting prior tasks, we store the learned DAPs incrementally. Given that OWCL presents greater challenges, it is vital not only to reduce incremental classification error but also to establish tighter decision boundaries for open detection in testing. Therefore, we propose a novel pseudo-sample generation method and utilize these pseudo-samples to enhance the test set (in contrast to all replay-based CL methods, which incorporate generated samples into the training set), to make full use of the knowledge of knowns and opens.\nGiven a specific known class k with its DAP Pk, we generate positive pseudo-samples that follow the distribution ~ (pk, \u03b42) to ensure that the positive pseudo-samples are centered around pk. Moreover, we generate random negative pseudo-samples that follow a distribution ~ (pk\u03b9, \u03b42) at arbitrary positions between each pair of prototypes (pk, P\u2081), where Pkl = Ph+SP1. These random negative pseudo-samples form the pseudo-test set D'e.\nSubsequently, we propose a novel threshold learning approach with knowledge-adaptive capability, building on the NCM-based classifier. Our goal is to determine an appropriate threshold for each task, enabling the classifier to discern whether a test sample belongs to a known category. If it does, the NCM-based classifier aligns the sample with the corresponding DAP's label and gets the output. If not, the test sample is identified as open.\nConsequently, we design the following optimization problem to determine the threshold r:\n$arg \\underset{r}{max} \\left [ \\frac{1}{\\left|D'\\right|} \\sum_{i=1}  \\frac{1}{2} \\sum [ [ \\frac{1}{\\left|D'_{te}\\right|}  \\sum (\\delta_{x}D - \\frac{1}{\\left|D'\\right|} \\sum [ [ + [  \\frac{1}{\\left|D'\\right|}  + \\\right]  where I(\u00b7) is an indicator function, s is the maximum similarity between sample x with learned prototypes, g(\u00b7) is a nonlinear function, (\u00b7) is the pre-trained model, G\u00b2 is the Gram matrix of NRP feature, and p is the prototype of class y in task i. Note the D'te is different from the original Dte in testing: we integrate a batch of generated pseudo-samples for each task to better represent data distribution via the embedding distribution over Dtr, obtaining DAP for each known class.\nNaturally, in solving for r, we need further analysis as:\n1/(] I( + \n1/21 I( + +)\n1/2*1 I(] + +10+ exhibiting the properties of being unimodal, long-tailed, and decreasing. Consequently, in our HoliTrans framework, we employ the classic numerical technique of ternary search, which adaptively identifies the optimal threshold r. The ternary search algorithm iteratively refines the search interval to determine the parameter value that maximizes accuracy for the NCM-based classifier.\nThe algorithm 1 summarizes the overall training process. The overall training process consists of two main phases. In the first phase, given a task i with its training set $D^i_{tr}$ and test set $D^i_{te}$, the class prototypes $G^t$ and {pky}1 are updated using the training data, and the standard deviation d between samples and their corresponding prototypes is calculated. In the second phase, the algorithm generates discriminative auxiliary pseudo-samples (DAPs). Negative pseudo-samples are created by computing pseudo-prototypes from pairs of prototypes (pk, Pl) and sampling from a Gaussian distribution centered around the pseudo-prototype. Positive pseudo-samples are similarly generated from each prototype pk using a Gaussian distribution. The pseudo-samples are then integrated with the test set Die, and the decision threshold r is determined through a ternary search over the modified test set D'te. This process enhances the classifier's ability to distinguish between known and open classes by utilizing both positive and negative pseudo-samples.\nThe complexity of generating pseudo-samples is O(n\u00b2 \u00d7 dim), the time consuming of evaluating pseudo-samples is O(dim \u00d7 M \u00d7 n), where n is the number of classes, dim is the dimension of the pre-trained model output and M is the NRP size. The complexity of solving the optimal solution for  log( )  -)).\nTo understand why NRP performs effectively in OWCL, we provide extra theoretical analyses as follows.\nFirst, NRP approximates each class distribution to a Gaussian distribution. Given a vector f, the norm of its projected vector can be bounded using the Chernoff bound:\nP(|||WTf|| \u2212 Ew [||WTf||]| > \u03b5\u03c3\u00b2) <2e^((-\u03b5\u03c3^2)/(2M+e)). This bound reveals the relationship between dimensionality and the expected variation in the norm of the projected vector. For fixed  $\\epsilon$  and $\\sigma$, as M increases, the probability on the right-hand side approaches 1. This indicates that the norm of the projected vector is more likely to fall within an ideal range around the expected value. In other words, in higher dimensions, these projected vectors tend to lie near the boundaries of the distribution, with similar distances from the mean-making the distribution align more closely with a Gaussian.\nSecondly, NRP can lead to better decision boundaries. Consider any two vectors f and f', and analyze the Chernoff bound for their inner product before and after projection:\nP(|(WTf)T(WT f') \u2212 Ew[(WT f)T (WT f')]|>\n$\\frac{\\epsilon \\sigma^2}{M}) <2e^\\frac{-\\epsilon^2 M}{2M+e}.  This can be rewritten as:\nP(|(WT f)T (WT f') \u2212 M\u03c3^2 fT f'\n> \u03b5M\u03c3^2)  <2e^\\frac{-\\epsilon^2 M}{2M+e}. Simplifying further:\nP( \\left| \\frac{(WT f) (WT f')}{M \\sigma^2} - f^Tf'\\right| > \\epsilon) <2e^\\frac{-\\epsilon^2 M}{2M+e}.\nThis bound shows that as the projection dimensionality M increases, the inner products of arbitrary vectors and their projections are less likely to be equal. In other words, higher dimensions reduce the probability that two vectors and their projections share the same inner product. This characteristic facilitates the establishment of better decision boundaries for OWCL."}, {"title": "VI. EXPERIMENTS", "content": "We compare HoliTrans with 22 baseline models", "model": "nThe proposed HoliTrans is implemented based on PyTorch and released in supplemental materials. All experiments are conducted on a single NVIDIA RTX 3090 GPU. The utilized pre-trained backbone is ViT-B/16, which is self-supervised and pre-trained on ImageNet-21K. In the testing phase of each task, we treat the test samples of classes that have not yet been learned as open/unknown classes to conduct the CIRO and KIRO scenarios, i.e., the two more challenging and difficult scenarios of OWCL.\nFor the first stage of HoliTrans, we employ SGD to train the parameters of the PETL method, namely AdaptFormer, SSF, and VPT. For each of these, we use a batch size of 48, a learning rate of 0.01, weight decay of 0.0005, momentum of 0.9, and cosine annealing with restarts ending at a learning rate of 0. Throughout, we typically train for 20 epochs, although in some experiments, this may be reduced if overfitting becomes apparent. Softmax and cross-entropy loss are utilized when employing these methods. The number of classes equals the quantity from the first task, i.e., M1. Before commencing the second stage of HoliTrans, we discard the training weights and heads generated thereby.\nDuring training, data augmentation for all datasets includes random resizing followed by cropping to 224x224 pixels and random horizontal flipping. For inference, images are resized to a short side of 256 pixels and then center-cropped to 224x224 for all datasets except CIFAR100, which is directly resized from its original 32x32 size to 224x224.\nWe employ three key metrics, namely ACCt, AUCt, and FPRt, to provide a comprehensive evaluation of model performance across T tasks. Specifically, ACCt represents the average final accuracy concerning all previously encountered classes across the t tasks. It evaluates how well the model retains knowledge from earlier tasks without significant forgetting. AUCt denotes the average area under the receiver operating characteristic (ROC) curve over all past tasks, reflecting the model's ability to distinguish between known and unknown instances, thereby offering insights into its classification reliability. FPRt, or the average false positive rate, quantifies the error rate in open-set detection, indicating how often the model mistakenly classifies unknown instances as belonging to known categories.\nOur evaluation approach distinguishes itself from prior works by addressing open-set detection and the classification of known samples simultaneously, rather than treating these tasks separately with distinct metrics. To ensure fairness and robust assessment, we utilize three random seeds with shuffled task orders, averaging the results and reporting the standard deviations. Table IV presents the results on the CIRO and KIRO benchmark scenarios, where the proposed method is comprehensively compared against 22 state-of-the-art approaches"}]}