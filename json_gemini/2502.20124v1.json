{"title": "Exploring Open-world Continual Learning with Knowns-Unknowns Knowledge Transfer", "authors": ["Yujie Li", "Guannan Lai", "Xin Yang", "Yonghao Li", "Marcello Bonsangue", "Tianrui Li"], "abstract": "Open-World Continual Learning (OWCL) is a challenging paradigm where models must incrementally learn new knowledge without forgetting while operating under an open-world assumption. This requires handling incomplete training data and recognizing unknown samples during inference. However, existing OWCL methods often treat open detection and continual learning as separate tasks, limiting their ability to integrate open-set detection and incremental classification in OWCL. Moreover, current approaches primarily focus on transferring knowledge from known samples, neglecting the insights derived from unknown/open samples. To address these limitations, we formalize four distinct OWCL scenarios and conduct comprehensive empirical experiments to explore potential challenges in OWCL. Our findings reveal a significant interplay between the open detection of unknowns and incremental classification of knowns, challenging a widely held assumption that unknown detection and known classification are orthogonal processes. Building on our insights, we propose HoliTrans (Holistic Knowns-Unknowns Knowledge Transfer), a novel OWCL framework that integrates nonlinear random projection (NRP) to create a more linearly separable embedding space and distribution-aware prototypes (DAPs) to construct an adaptive knowledge space. Particularly, our HoliTrans effectively supports knowledge transfer for both known and unknown samples while dynamically updating representations of open samples during OWCL. Extensive experiments across various OWCL scenarios demonstrate that HoliTrans outperforms 22 competitive baselines, bridging the gap between OWCL theory and practice and providing a robust, scalable framework for advancing open-world learning paradigms.", "sections": [{"title": "I. INTRODUCTION", "content": "Open-World Continual Learning (OWCL) [1], [2] represents a highly practical yet profoundly challenging machine learning paradigm. In OWCL, a model must continually adapt to an unbounded sequence of tasks in a dynamic open environment [3], [4], where novelties might emerge in testing unpredictably over time [5]\u2013[7]. Unlike traditional learning models that operate in a closed and fixed set of classes, OWCL aims at learning on the job in an open-world assumption with the goal of recognizing unseen/open samples and incrementally acquiring knowledge from new tasks without forgetting [8]\u2013[10]. Due to the potential occurrence of novelties in continual learning (CL) [11], OWCL models need to accurately detect unknowns to prevent unknown samples from being incorrectly classified into known categories. At the same time, OWCL requires the model to retain previously learned knowledge without forgetting while continually performing open detection. In summary, the open detection for unknowns and classification for knowns are interdependent in OWCL: on the one hand, the presence of unknowns complicates the trade-off between knowledge stability [11], [12] and knowledge plasticity [13], [14]; on the other hand, the incremental learning of new tasks makes open detection in an embedding space more challenging with the expanding knowledge space.\nDespite growing attention to OWCL in recent years, current approaches [10], [15] still treat OWCL as a simple combination of open-set recognition and CL, rather than as an integrated paradigm, making it only effective in knowledge transfer related to known samples, while neglecting the knowledge derived from unknown samples. Therefore, a promising OWCL model must be capable of knowns-unknowns knowledge transfer, i.e., effectively transferring knowledge both for known categories and unknown samples. Besides, there is a lack of comprehensive problem formulation and thorough empirical explorations of potential issues in OWCL, making it difficult to compare the performance of existing methods and making it unclear how to choose one method over another. In response, this paper explores the issues arising in OWCL and adopts an integrative perspective to deal jointly with unknown samples\u2019 detection and known samples\u2019 classification, particularly the knowledge transfer for both unknowns and knowns.\nAs shown in Figure 1, in real-world scenarios, labeled samples for a new category are rarely available all at once or from a single task [9]; instead, they are acquired incrementally across different tasks over time [16], [17]. Hence, in OWCL, a certain category may repeatedly appear across different tasks with varying data distributions. Moreover, as new tasks are learned incrementally, the boundaries between known categories become increasingly ambiguous. As a result, the repeated appearance of open/unknown samples further makes it difficult for the OWCL model to distinguish between the unknown and known samples. Accordingly, as outlined in Table I, there are two fundamental principles for refining OWCL scenarios: (1) whether a known class with changing data distribution appears in different tasks during the training phase, and (2) whether an unknown sample repeatedly appears in different tasks during the testing phase.\nTherefore, based on the principles of scenario categorization, we extend existing CL scenarios (i.e., task-incremental learning, domain-incremental learning, and class-incremental learning) to the context of OWCL. However, different from CL, OWCL does not permit task identification, as unknown samples may randomly appear during testing [18]. Thus, task-incremental and domain-incremental learning are insufficient for describing the OWCL scenarios. In response, we introduce a novel scenario definition, termed knowledge-incremental learning (KIL): models must be able to solve each task seen so far without knowing which task is being performed, where the training sets across different tasks are not strictly non-overlapping; that is, shifts in the distribution of known categories may occur. KIL incorporates class-incremental learning and accommodates shifts in the distribution of specific categories, thereby providing a more realistic scenario description for OWCL and posing greater difficulty. Accordingly, we then introduce four distinct scenarios for OWCL of increasing difficulty: class-incremental with non-repetitive open samples (CINO), class-incremental learning with repetitive open samples (CIRO), knowledge-incremental learning with non-repetitive open samples (KINO), knowledge-incremental learning with repetitive open samples (KIRO).\nRecently, much research [19]\u2013[21] highlighted the significance of both inter-task and intra-task open samples in developing effective open-set recognition. Hence, this work proposes an OWCL model to distinguish inter-task open samples from each previously learned task, where inter-task open samples randomly appear across different tasks. Meanwhile, the OWCL model must differentiate intra-task open samples from known categories within the same task while preserving accurate classifications of the known categories. Then, to explore potential issues of OWCL, we conduct extensive comparisons with current competitive baselines under the most challenging scenario, KIRO."}, {"title": "II. RELATED WORK", "content": "Continual learning (CL) [5], [23] usually operates under the closed-world assumption, where the system assumes that all test or deployment samples belong to one of the predefined classes seen during training [4], [24], [25]. However, this assumption implies no exposure to novel or previously unseen data during testing, which is far from realistic in dynamic, real-world environments [2], [2], [18]. In practice, continual learning systems are frequently confronted with new, unknown classes, necessitating the ability to detect, adapt to, and incrementally learn these novelties, continually acquiring new knowledge over time [26]\u2013[28]. Hence, it is imperative to detect and incrementally learn novelties while acquiring knowledge without forgetting over time.\nMore recently, continual learning in an open world or simply Open-world Continual Learning (OWCL) has been appealing yet challenging with increasing works [2], [11]. In order to enable existing CL models to effectively detect open/unknown samples, primary OWCL research utilized open-set recognition (OSR) and out-of-distribution (OOD) detection methods as expansive components into CL baselines to tackle the OWCL tasks. [29] proposed an OSR framework based on extreme value theory, incorporating incremental tasks to manage dynamic learning environments. [30] introduced an approach leveraging contrastive clustering and an energy-based identification method [31] for handling dynamic data, enabling the system to recognize and accommodate novel inputs during continual learning. Building on these previous efforts, recent OWCL studies emphasized the integration of OOD detection techniques within the continual learning paradigm. For instance, [1], [10], [18] highlighted the importance of novelty detection as a crucial aspect of open-world learning, suggesting that existing OOD techniques could be effectively adapted to the continual learning setting. In a complementary development, frameworks such as SOLA [2], [32] have been proposed, combining OOD detection with incremental task adaptation to facilitate novelty detection and task-specific learning in an open-world context.\nNevertheless, current research still relies on simplistic approaches by combining CL methods with OOD detection components [10], [15], [18], [19], [26], [28], and several crucial challenges persist in OWCL. First, the absence of a standardized and general problem formulation makes it challenging to compare the performance of existing methods in a consistent setting, leading to fairness issues. Second, there are still experimental and theoretical gaps in exploring the knowledge transfer for known and unknown samples in OWCL. Finally, there is a lack of theoretical foundation to guide the design of an OWCL model that supports knowledge transferring and knowledge updating.\nTo address these limitations, this paper makes several key contributions. First, we provide rigorous theoretical analyses with a formal problem construction for understanding the variations and challenges inherent to OWCL. By constructing four distinct scenarios, we conduct extensive empirical experiments and systematically explore the factors influencing OWCL model performance under these different scenarios, identifying a significant interplay between open detection and the classification of known samples. Finally, we propose a novel framework, termed HoliTrans, designed to effectively address knowns-unknowns knowledge transfer by introducing NRP and proposing DAPs in an adaptive knowledge space. The proposed HoliTrans serves as a strong baseline for future research, demonstrating its robustness and efficacy across a range of OWCL scenarios with abundant experiments."}, {"title": "III. UNDERSTANDING OWCL: FORMULATION AND PRELIMINARY EXPERIMENTS", "content": "In this section, we first formalize the problem of OWCL by integrating the optimization with open risk from unknowns and incremental prediction errors from knowns. Then, we provide an in-depth categorization scheme for different OWCL scenarios. Subsequently, to explore potential issues in OWCL, we conduct abundant experiments with baselines using different kinds of classifiers (i.e., Softmax-based and NCM (Nearest Class Mean)-based classifiers) on different baselines.\nIn OWCL, samples not seen in the training set may appear during testing, thus, we use $D_{tr}$ and $D_{te}$ to distinguish between the training set and test set; all superscripts indicate the task order. We list the notations throughout this paper in Table II for better clarification.\nCurrently, there is a lack of consensus regarding the OWCL problem formulation within the community. In response, we develop a comprehensive and general problem definition, taking into account both the inherent open risk and the incremental classification error that arise in all OWCL scenarios as follows:\nEach task i has $N_i$ training samples and $M_i$ classes $D_{tr} = \\{ x \\in \\mathcal{X}, y \\in \\mathcal{Y}_i \\}_{j=1}^{N_i}$. In the training phase, only data pertinent to the current task is accessible, while the test samples $D_{te} = \\{ x \\in \\mathcal{X}, y \\in \\bigcup_{j=1}^{M_i} \\mathcal{Y}_j \\}$ may contain unknowns/novelties, i.e., $\\mathcal{Y}_j \\not\\subset \\bigcup_{i=1}^{M_i} \\mathcal{Y}_i $. Given the latent representation of the current task t's training set $h(D_{tr}^t)$, we denote $\\mu(h(x), h(D_{tr}^t))$ as the open risk of a sample x from task i's test set $D_{te}^i$.\nThe goal of Open-world continual learning (OWCL) is to learn a uniform function $h^*$ that minimizes the open risk and incremental prediction error jointly, across all seen tasks [1,t]:\n$\\arg \\min_{h^* \\in \\mathcal{H}} \\{(1 - \\lambda)\\sum_{i=1}^{t} \\mu(h(x), h(D_{tr}^i)) + \\lambda\\sum_{i=1}^{t} \\mathcal{E}_{D(i)}(h)\\}$,\nwhere $\\mathcal{H}$ is a universal function space, $\\mathcal{E}_{D(i)}(h)$ is the generally suggested prediction error term on task i [4], $\\mu$ can be defined on any scoring function for OOD detection, $\\lambda$ is a hyper-parameter to balance the open risk and the incremental prediction error."}, {"title": "IV. THEORETICAL BASES", "content": "This section defines a new knowledge space and introduces a generic incremental prediction error term for OWCL. We theoretically prove a tighter bound for incremental prediction error, providing several insights for designing better OWCL algorithms by considering knowledge from knowns and unknowns.\nFollowing a general definition from [4], we extend the definition of open space $O$ for OWCL as follow:\n$O = \\mathcal{S} - \\bigcup_{i=1}^{t} \\mathcal{K}(x)$,\nwhere $S$ is the universal space, and $K$ is the known space obtained by each trained task i \u2208 [1, t].\nNote that it is not necessary to classify each open sample into exactly true unknown classes. For the sake of simplicity, we follow the general implementations [37], setting all unknown samples to one unified unknown as [un]. Hence, given the problem formulation in Definition 1, we assume that $V_{M_i + 1} = \\{Y_{un}\\}$ where $Y_{un}$ represents the one unknown class and $M = M_i + 1$. Therefore, from the probabilistic perspective, we can refine the left summand term (A) in Equation 1 as:\n$\\sum_{i=1}^{t} \\mu(h(x), h(D_{tr}^i)) = R_{P, un}(h) = \\int_\\mathcal{X} \\mathcal{L}(h(x), Y_{un}) dP_{X|Y=Y_{un}}(x)$,\nwhere l is a loss satisfying $l(y, y') = 0$ iff $y = y'$.\nPrevious works [1], [9] claimed that the decomposition in Equation 1 is orthogonal, meaning that the terms (A) and (B) do not affect each other. However, from observations in subsection III-C, we find that the open risk affects the incremental prediction quality, and that the boundary across the learned tasks also affects the open detection performance. Therefore, we need to consider the interaction of open risk (term (A) in Definition 1) and incremental prediction error (term (B) in Definition 1) in a unified manner.\nSubsequently, we introduce a novel incremental prediction error term and theoretically derive a more compact bound for OWCL:\nAfter training a new task t, the empirical prediction error $\\mathcal{E}_{D(i)}(h_t)$ of the current model $h_t$'s for an arbitrary task i(i < t) is defined as [38]:\n$\\mathcal{E}_{D(i)}(h_t) = \\frac{1}{N_i} \\sum_{x \\in \\mathcal{X}\\bigcup_{j=1}^{N_i}} I(h_t(x) \\neq g_i(x))$ if i < t,\nI(\u00b7) is an indicator function. Only a small subset of data from previous tasks (i < t) is available at task t, i.e., $N'_i$ < $N_i$, and $N_i$ is the replayed samples amount, leading the task i's prediction error to deviate much from their overall real risks with severe forgetting issues.\nHowever, in OWCL, when data from previous tasks is unavailable, leveraging the historical model $h_{t-1}$ from time (t-1) instead of replaying a subset of data should be an alternative to tighten the prediction error bound, resulting in improved methods accordingly. Hence, considering the most difficult OWCL scenario (i.e., KIRO), we derive Lemma 1 and Lemma 2 to unify a novel incremental prediction error bound for OWCL. Following the Theorem 2, we have:\nLet $h_t$ be the current function trained on task t and $h_{t-1}$ is the model trained on the previous task t \u22121. Then, the $h_t$'s task-specific prediction error on an arbitrary task i < t has an upper bound:\n$\\mathcal{E}_{D_i}(h_t) \\le \\mathcal{E}_{D_i}(h_t, h_{t-1}) + \\mathcal{E}_{D_i}(h_{t-1})$,\nwhere $\\mathcal{E}_{D_i}(h_t, h_{t-1}) = E_{x \\sim D_i} [h_t(x) \\neq h_{t-1}(x)]$.\nThis lemma shows that the prediction error of the current model $h_t$'s on an arbitrary task i is bounded by the difference between $h_t$ and its previous model $h_{t-1}$ plus the prediction error of $h_{t-1}$ on task i. Additionally, given the presence of $\\mathcal{E}_{D_i}(h_{t-1})$, the task-specific prediction error bound of $h_{t-1}$ will be inherited to $\\mathcal{E}_{D_i}(h_t)$, which means the incremental prediction error will gradually accumulate as new task coming.\nLet $h_t$ be the current function trained on task t and $h_{t-1}$ is the model trained on the previous task t \u2013 1. The task-specific prediction error on task i(i < t) has an upper bound:\n$\\mathcal{E}_{D_i}(h_t) \\le D_{tv}^i (h_t, h_{t-1}) + \\frac{1}{2} d_{H \\Delta H} (D_{tr}^i, D_{tv}^t) + D_{tv}^i (h_{t-1})$,\nwhere $\\mathcal{H}$ is universal hypothesis space with finite VC dimension [39], and $d_{H \\Delta H} (D_{tr}^i, D_{tv}^t)$ denotes the divergence between the distributions $D_{tr}^i$ and $D_{tv}^t$. From a perspective of Bayesian theory, $d_{H \\Delta H} (D_{tr}^i, D_{tv}^t)$ can be approximately calculated as $\\frac{2}{n} \\sup_{h_t \\in \\mathcal{H}} |P_{a \\sim D_{tr}^i} [h_t(x) = 1] - P_{a \\sim D_{tv}^t} [h_t (x) = 1]|$ to quantify the task-specific error.\nLemma 2 establishes a theoretical foundation for knowledge transfer by demonstrating that when the divergence between task i and the current task t (i.e., $d_{H \\Delta H} (D_{tr}^i, D_{tv}^t)$) is sufficiently small, the predictions of $h_{t-1}$ on $D_{tr}^i$ can effectively serve as a surrogate loss. This surrogate loss is crucial in mitigating forgetting by anchoring predictions on previously learned tasks. Based on this principle, many CL and OWCL methods design knowledge transfer mechanisms to minimize divergence, preserving task-specific knowledge while integrating new knowledge effectively. Then, by using the task-specific prediction error bound in Lemma 2, we can derive the incremental prediction error bound by applying Lemma 1 and Lemma 2:\nWith a probability of at least 1 \u2013 \u03b4>0, the incremental prediction error bound can be refined as:\n$\\sum_{i=1}^{t} \\mathcal{E}_{D_i}(h_t) \\le \\sum_{i=1}^{t-1} \\{ \\beta_{i} \\mathcal{E}_{D_{tv}}^i(h_t) + \\alpha_{i} D_{tv}^i (h_t, h_{t-1}) + \\frac{1}{2} \\beta_{i} d_{H \\Delta H} (D_{tr}^i, D_{tv}^t) + \\frac{1}{2} (\\alpha + \\beta_{i}) D_{tv}^i (h_{t-1}) \\}$,\nwhere the constant $C_1$ can be calculated by ERM-Based generalization bound, $\\gamma_{i} + \\alpha_{i} + \\beta_{i}$ = 1, and the error term $\\sum_{i=1}^{t-1} (\\alpha + \\beta_{i}) \\mathcal{E}_{D_{tv}}^i(h_{t-1})$ is also a constant without any trainable parameters in the fixed (frozen) historical function $h_{t-1}$. The model discrepancy measures the weighted divergence between the current model $h_{t}$ and the previous one $h_{t-1}$, and the data discrepancy measures the scaled separability between the data distributions of task i and task t."}, {"title": "V. METHODOLOGY", "content": "Motivated by empirical findings and theoretical analysis, the interaction between open risk and incremental prediction error drives us to approach the OWCL problem as an integrated whole. Hence, we design a model that effectively transfers knowledge for both known categories and unknown samples, i.e., knowns-unknowns knowledge transfer.\nGiven a projection P : $\\mathcal{R} \\to \\mathcal{R'}$ an empirical estimate for the data discrepancy term is:\n$\\sum_{i=1}^{t-1} \\beta_i d_{H \\Delta H} (D_{tr}^i, D_{tv}^t) = \\frac{1}{2} \\sum_{i=1}^{t-1} \\beta_i d_{H \\Delta H} (P(B^i), P(B^t)) = \\frac{1}{N_t} \\sum_{i=1}^{t-1} \\beta_i \\sum_{x \\in \\mathcal{S}_t} [\\frac{1}{N_i} \\min_{x \\in \\mathcal{X}_i^i} -\\log [\\mathcal{D}(P(x))] + \\sum_{x \\in \\mathcal{X}_i^i} [-\\log [1 - \\mathcal{D}(P(x))]]]$\nwhere $B^t$ and $B^i$ are experience buffers drawn from training set $D_{tr}^t$ and $D_{tr}^i$ of tasks t and i, respectively.\nGiven the most difficult scenario, KIRO, each task's training set comes incrementally with repeated classes and changing distributions, which may result in overlapping across different tasks' semantic spaces, thus increasing the inter-task open risk. Additionally, the repeated appearance of open samples may increase the intra-task open risk by identifying open/unknown samples as known. Therefore, it is not enough to pull together all seen/known samples belonging to the same class, but we need to (1) find a proper projection with improved linear separability and (2) determine appropriate experience buffers to describe embedding distributions of different tasks.\nSubsequently, we propose a novel OWCL framework that can jointly learn knowledge about known classes and unknown samples, effectively generalizing under open-world assumptions while excelling in both open detection and incremental classification, termed HoliTrans. HoliTrans can infer general patterns from specific observed instances, which is crucial for adapting to new classes and detecting novel samples within all the OWCL scenarios.\nGiven a sequence of tasks, the training data and labels from the first task may better represent the subsequent tasks than the data used to train the original pre-trained model. Hence, we first need to fine-tune the pre-trained model via a Parameter-Efficient Transfer Learning (PETL) strategy [41], [42]. Moreover, due to the advantages of the random projection (RP) layer being independent of the model, it can be applied to any feature extractor. Therefore, it can be applied orthogonally to the widely applied PETL strategy, which does not alter any parameters of the original pre-trained model.\nIn this work, we fine-tune the pre-trained model with the first task by learning PETL parameters and then freeze them for the subsequent tasks. Here, we conduct three competitive PETL methods: AdaptFormer [43], SSF [44], and VPT [45]. After fine-tuning the pre-trained model with the first task, we conduct a novel two-stage training approach for each task (as shown in algorithm 1).\nGiven a new task t, we extract features from its training set using the fine-tuned pre-trained model and obtain the corresponding embeddings. In the first stage training, we introduce the nonlinear random projection (NRP) from the assumption that nonlinear random interactions between embedding distributions may be more linearly separable than the original in a higher-level embedding space, with corresponding mathematical properties that have been discussed extensively [34], [46], [47]. Thus, the embeddings can be improved as:\n$H^t = g(\\phi(D_{tr})W)$.\nThen, we encode the labels into a one-hot format, obtaining the label matrix $Y^t$. Accordingly, we update the model's Gram matrix and class prototype matrix as follows:\n$G^t = G^{t-1} + H^t (H^t)^T$,\n$C_i = C^{i-1} + HY$.\nGiven the training set of task t, each class's prototype can be acquired from Equation 15. Since the prototype for each known category is updated through NPR, we refer to these prototypes as Distribution-Aware Prototypes (DAPs).\nAdditionally, we compute the mean-variance of distances between samples of all classes and their prototypes:\n$\\delta^t = \\frac{1}{\\sum_{i=1}^{i-1} N_i + N_i} + E[(H^t - \\overline{H^t})^2]$.\nTo enable HoliTrans to acquire knowledge from known classes without forgetting prior tasks, we store the learned DAPs incrementally. Given that OWCL presents greater challenges, it is vital not only to reduce incremental classification error but also to establish tighter decision boundaries for open detection in testing. Therefore, we propose a novel pseudo-sample generation method and utilize these pseudo-samples to enhance the test set (in contrast to all replay-based CL methods, which incorporate generated samples into the training set), to make full use of the knowledge of knowns and opens.\nGiven a specific known class k with its DAP $P_k$, we generate positive pseudo-samples that follow the distribution $N(p_k, \\delta^2)$ to ensure that the positive pseudo-samples are centered around $P_k$. Moreover, we generate random negative pseudo-samples that follow a distribution $N(p_{kl}, \\delta^2)$ at arbitrary positions between each pair of prototypes ($P_k$, $P_l$), where $P_{kl} = \\frac{P_k + P_l}{2}$. These random negative pseudo-samples form the pseudo-test set $D'_{te}$.\nSubsequently, we propose a novel threshold learning approach with knowledge-adaptive capability, building on the NCM-based classifier. Our goal is to determine an appropriate threshold for each task, enabling the classifier to discern whether a test sample belongs to a known category. If it does, the NCM-based classifier aligns the sample with the corresponding DAP's label and gets the output. If not, the test sample is identified as open.\nConsequently, we design the following optimization problem to determine the threshold r:"}, {"title": "VI. EXPERIMENTS", "content": "We compare HoliTrans with 22 baseline models, including OWCL methods and various continual learning (CL) methods with several out-of-distribution (OOD) algorithms. We consider 5 state-of-the-art CL methods that leverage large-scaled pre-training and prompt-tuning as well.\nWe employ three key metrics, namely $ACC_t$, $AUC_t$, and $FPR_t$, to provide a comprehensive evaluation of model performance across T tasks. Specifically, $ACC_t$ represents the average final accuracy concerning all previously encountered classes across the t tasks. It evaluates how well the model retains knowledge from earlier tasks without significant forgetting. $AUC_t$ denotes the average area under the receiver operating characteristic (ROC) curve over all past tasks, reflecting the model's ability to distinguish between known and unknown instances, thereby offering insights into its classification reliability. $FPR_t$, or the average false positive rate, quantifies the error rate in open-set detection, indicating how often the model mistakenly classifies unknown instances as belonging to known categories."}, {"title": "VII. CONCLUSIONS AND LIMITATION ANALYSIS", "content": "Despite the increasing interest in OWCL research, existing approaches merely focused on learning and transferring knowledge from known samples, while overlooking the knowledge derived from unknown samples. In this paper, our empirical findings not only challenge the current assumption, but also underscore the critical importance of addressing the OWCL problem as a holistic paradigm. Following this, we introduce a novel OWCL approach, HoliTrans, that supports the knowns-unknowns knowledge transfer and validates the proposed model through comprehensive experiments.\nThe key insight of our work lies in discovering the interaction between open risk and incremental prediction error, viewing OWCL as a holistic problem rather than a mere combination of continual learning and open-set recognition methods. Additionally, we cast OWCL into 4 scenarios with increasing difficulty and conduct extensive experiments to investigate the challenges of OWCL. More importantly, our theoretical analysis provides guidance for proposing a principled and novel OWCL framework. Specifically, we introduce the nonlinear random projection (NRP) method, which leverages nonlinear random feature interactions to enhance linear separability in a higher-dimensional space and propose distribution-aware prototypes (DAPs) for seen classes to mitigate open risk and enhance incremental classification performance. Experimental results demonstrate the superiority of HoliTrans over 22 baseline models across various OWCL scenarios and datasets, further underscoring its capability to effectively learn and transfer knowledge from both known and unknown samples."}]}