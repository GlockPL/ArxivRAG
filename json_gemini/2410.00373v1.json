{"title": "Robust Traffic Forecasting against Spatial Shift over Years", "authors": ["Hongjun Wang", "Jiyuan Chen", "Tong Pan", "Zheng Dong", "Lingyu Zhang", "Renhe Jiang", "Xuan Song"], "abstract": "Recent advancements in Spatiotemporal Graph Neural Networks (ST-GNNs) and Transformers have demonstrated promising potential for traffic forecasting by effectively capturing both temporal and spatial correlations. The generalization ability of spatiotemporal models has received considerable attention in recent scholarly discourse. However, no substantive datasets specifically addressing traffic out-of-distribution (OOD) scenarios have been proposed. Existing ST-OOD methods are either constrained to testing on extant data or necessitate manual modifications to the dataset. Consequently, the generalization capacity of current spatiotemporal models in OOD scenarios remains largely underexplored. In this paper, we investigate state-of-the-art models using newly proposed traffic OOD benchmarks and, surprisingly, find that these models experience a significant decline in performance. Through meticulous analysis, we attribute this decline to the models' inability to adapt to previously unobserved spatial relationships. To address this challenge, we propose a novel Mixture of Experts (MoE) framework, which learns a set of graph generators (i.e., graphons) during training and adaptively combines them to generate new graphs based on novel environmental conditions to handle spatial distribution shifts during testing. We further extend this concept to the Transformer architecture, achieving substantial improvements. Our method is both parsimonious and efficacious, and can be seamlessly integrated into any spatiotemporal model, outperforming current state-of-the-art approaches in addressing spatial dynamics. Codes are available at GitHub.", "sections": [{"title": "1 INTRODUCTION", "content": "TRAFFIC forecasting [1], [2], [3], [4] has emerged as a powerful technique for modeling dynamic systems, gaining prominence with the advancements in graph neu-ral networks. It effectively captures the inter-dependencies between connected nodes, which has been successfully ap-plied in a wide range of complex system problems.\nDespite this, it has come to our attention that current ST Graph Neural Networks (ST-GNNs) are primarily evalu-ated based on short-term training and testing distributions, typically spanning only three months [1], [5], [6]. Within such short period of time, basically there will be no spatial or temporal pattern shifts. However, cities are constantly evolving and developing. For example, imagine a new highway is built in a city or a popular shopping mall opens in a different area. These changes can lead to shifts in traffic flow, creating new dependencies between previously unrelated regions or altering existing traffic patterns [7], [8], [9]. In long-term scenarios, say one year, such possibility can greatly increase. Therefore, we think the current way of measuring ST-GNNs' performances overlooks the intricate nature of dynamic ST-dependencies, and can not reflect the true ability of ST-GNNs in handling long-term scenarios with unseen spatial/temporal patterns.\nRecent pioneering efforts [16], [17], [18] have made significant progress in addressing the challenge of out-of-distribution scenarios in traffic forecasting. However, these methods are either tested on data from recent weeks [16] or involve modifications to the dataset [17], [18], such as manually masking certain nodes to create spatial shifts. They never make a preliminary experiment in the data level to see whether the shift they claim truly exist.\nTo address this issue, we takes the first step to exam-ine the existence of such shift from benchmark datasets with novel experiments and propose four OOD traffic benchmarks: PEMS03-2019, PEMS04-2019, PEMS07-2018, and PEMS08-2017, derived from the California Depart-ment of Transportation Performance Measurement System (PEMS)\u00b9 [19]. These benchmarks maintain identical sensors while capturing data from different years, aligning with\n1. https://pems.dot.ca.gov/\n\u2022\n\u2022\n\u2022\n\u2022Hongjun Wang, Jiyuan Chen, Tong Pan, Zheng Dong and Lingyu Zhang are with (1) SUSTech-UTokyo Joint Research Center on Su-per Smart City, Department of Computer Science and Engineering (2) Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology (SUSTech), Shenzhen, China. E-mail: wanghj2020,11811810@mail.sustech.edu.cn, pant@sustech.edu.cn, zhengdong00@outlook.com, and zhanglingyu@didiglobal.com.\nXuan Song is with (1) School of Artificial Intelligence, Jilin University (2) Research Institute of Trustworthy Autonomous Systems, Southern University of Science and Technology (SUSTech), Shenzhen, China. Email: songxuan@jlu.edu.cn.\nR. Jiang is with Center for Spatial Information Science, University of Tokyo, Tokyo, Japan. Email: jiangrh@csis.u-tokyo.ac.jp.\nCorresponding to Xuan Song;"}, {"title": "2 RELATED WORK", "content": "OOD generalization in graph-structured data has emerged as a critical challenge in recent years. Li et al. introduced OOD-GNN [29], which enhances GNNs ability to gener-alize to unseen graph structures by learning to decorre-late causal and non-causal features. Similarly, Park et al. proposed MAGNA [30], leveraging a Metropolis-Hastings data augmentation technique to improve GNN performance on OOD graphs. Wu et al. [31] adopted an invariance-based approach, focusing on learning invariant rationales to manage distribution shifts on static graphs. However, these methods are primarily tailored to static graphs and overlook the temporal dynamics often present in real-world evolving networks. In contrast, time series OOD detection and generalization have gained prominence due to the non-stationarity of many temporal processes. Wu et al. introduced DIVERSIFY [32], a framework that disentangles seasonal-trend representations for time series OOD gen-eralization. Yang et al. [33] proposed a causal approach for OOD sequential event prediction, addressing evolving temporal patterns, while Du et al. developed AdaRNN [34], an adaptive method for forecasting OOD time series by dynamically adjusting to varying contexts. Despite their successes in managing temporal shifts, these methods fall short of explicitly modeling spatial relationships, limiting their applicability in scenarios where both spatial and tem-poral distributions change. The integration of spatial and temporal dimensions in OOD scenarios poses additional challenges, particularly in fields like traffic prediction and climate modeling. Recent efforts have begun addressing this issue. Xia et al. [35] developed CaST, a causal framework for transferring invariant spatio-temporal relations to OOD settings, while Zhou et al. proposed CauSTG [17], aimed at capturing invariant relations in spatio-temporal learning. Additionally, Hu et al. [36] introduced a graph neural pro-cess for spatio-temporal extrapolation, partially addressing OOD generalization. Wang et al. [18] proposed STONE, a novel framework that generates invariant spatiotemporal representations for effective generalization to unknown en-vironments through semantic graph learning, graph inter-vention mechanisms, and an Explore-to-Extrapolate loss."}, {"title": "2.1 Traffic Forecasting", "content": "The primary challenge in traffic forecasting is capturing both spatial and temporal dependencies from dynamic inputs against a fixed graph structure. Recent solutions primarily incorporate graph neural networks to model the complex spatial relationships in traffic networks [24], [25], [26]. Early approaches like DCRNN [25] and STGCN [26] pioneered the integration of graph convolution with re-current or convolutional structures for traffic forecasting. Subsequent works have explored various techniques to en-hance spatio-temporal representation learning. For instance, Graph WaveNet [2] introduced a self-adaptive adjacency matrix to capture hidden spatial dependencies. ASTGCN [5] and STSGCN [20] employed attention mechanisms to dy-namically capture spatial and temporal correlations. More recent models like STFGNN [27] and D2STGNN [28] have proposed novel architectures for joint spatial-temporal de-pendency modeling. However, most existing research pri-marily evaluates ST-GNNs within short timeframes, po-tentially overlooking long-term dynamics in traffic data. Recent studies [16], [17], [18] have attempted to address this limitation by exploring model generalization from a temporal perspective. For example, [16] proposed a causal"}, {"title": "2.2 OOD in Spatio-Temporal Analysis", "content": ""}, {"title": "3 PROBLEM STATEMENTS", "content": "In this paper, we define a graph as G = (V, E, A), where V represents the set of nodes, E \u2286 V \u00d7 V defines the edges, and A is the adjacency matrix associated with the graph G. Ad-ditionally, at each time step t, the graph possesses a dynamic feature matrix X\u209c within the real-number space R|V|\u00d7C, with C indicating the dimensionality of the node features. The task of traffic forecasting involves developing and training a neural network model g. The functional relationship for this predictive modeling is formulated as: g : [Xt, A] \u2192 Yt, where Xt = X(t\u2212l\u2081):t and Yt = X(t+1):(t+l\u2082), with l\u2081 and l\u2082 representing the lengths of the input and output sequences, respectively.\nCurrent spatiotemporal OOD methods [16], [17], [18] commonly assume a invariant graph relationship R in dy-namic feature matrices Xt, with the expectation that trained models will perform well on future unseen scenario. In fact, we posit that the notion of spatiotemporal invariance is inherently ill-defined. For instance, predicting when fu-ture traffic condition might occur due to the construction or development of new commercial centers is inherently uncertain. Our work explores a more practical scenario where the training and testing graph relationships may differ, and the training graph relationship also evolves over time. Following [37], we define a graph environment as the joint distribution PXAY across Xt \u00d7 At \u00d7 Yt, denoted by \u03a9. For each environment, the graph relation Rt = (Xt, At, Yt) exists, but feature and outcome distributions can vary (PxAY \u2260 PxAY for different e, e' \u2208 \u03a9). Thus, the learning goal of this paper is to construct a set of experts and each expert learn a specific environment e for stable predictions across various environments, despite selection biases."}, {"title": "4 METHODOLOGY", "content": "As discussed, our objective is to develop a spatiotempo-ral model capable of learning diverse graph generators (graphons) that adapt to specific environmental conditions in unseen data. To achieve this, we seek to identify periods with similar graph relations R, enabling each expert to learn distinct patterns independently. This approach builds on [17], which emphasizes dataset diversity for robust model training, but relies on manual heuristics for partitioning, potentially leading to suboptimal outcomes. We address this by introducing the Maximum Spatiotemporal Graph Division problem, which partitions the dataset into K dis-tinct time intervals while maximizing dissimilarity between them. Formally, the problem is defined as follows:\nDefinition 4.1 (Maximum Spatiotemporal Graph Division (MSGD)). Let T be a spatiotemporal dataset that can be decomposed into K distinct time intervals, denoted as T = {T\u2081, T\u2082,...,Tk}. Each interval Tk consists of pairs {Xt, Yt}t\u2208Tk, where [tk, tk+1) denotes the continuous time in-terval range, such as morning peak and evening peak. The MSGD is characterized by a scenario where, within each individual period [tk,tk+1), all data segments conform to the same graph relationship Rk. Conversely, for any two distinct time periods i and j where 1 < i,j < K and i \u2260 j, the graph relationships differ, i.e., RT\u1d62 \u2260 RT\u2c7c.\nBased on the principle of maximum entropy [38] and Def. 4.1, we accomplishes this by addressing an optimiza-tion problem with the following objective function:\n\\underset{0<K\u2264T}{\\text{max}} \\ \\underset{t1,..., tk}{\\text{max}} \\ \\frac{1}{K\u00b2} \\sum_{1<i\u2260j<K} d(T_i, T_j)\ns.t. \\ \\forall i, \u03b1\u2081 < |Ti| < \u03b1\u2082; \\sum T\u1d62 = T, (1)\nwhere distance metric d(,) is chosen as Kendall's \u03c4 to measure the graph relation across different periods of graph signals, \u03b1\u2081 and \u03b1\u2082 are predefined parameters representing the minimum and maximum interval ranges, respectively. |Tk| = tk+1 - tk denotes the length of each interval, and T denotes the total time interval for one day.\nThe optimization problem in Eq. (1) aims to maximize the average distribution dissimilarity among periods, which is achieved by searching for an optimal K and the corre-sponding periods, ensuring that each period's distribution is as diverse as possible. While no prior assumptions are made about this problem, it is reasonable to assume that the graph relations at specific time period across differ-ent day are highly consistent. For example, during the morning peak on weekdays, we presume that the graph relationships remain consistent across different days, which allows for more flexible and general expert graphons. In practice, solving the splitting optimization problem in Eq. (1) can be computationally challenging and might not have a closed-form solution. Instead, we here try to utilize dynamic programming (DP) [39] to select an appropriate splitting number K and corresponding index T.\nGraphons Generator. In this paper, graphon is formulated as probability matrix, denoted as P, where P(i, j) indicates the likelihood of an edge existing between nodes i and j. The graphs within one expert are produced under the same generator (i.e., graphon). When handle data that falls outside the training distribution, mix-up process generates optimal graph relations tailored to the current input. A visual example of the process to generate the target distribu-tion is shown in Figure 2. To generate graphons, we employ a set of learnable expert embedding matrices, and a dynamic embedding layer to encode the input signal. Formally, let the kth expert embeddings as E(k) \u2208 R|V|\u00d7d, and Et \u2208 R|V|\u00d7d signifies the time series embedding features dynamically generated by the current input signal x with multilayer perceptron. To construct the graphons matrix, we calculate the kth graphons P(k) \u2208 R|V|\u00d7|V|, where \u03c3 is the sigmoid function, used to regulate the range of the elements to (0, 1).\nSubsequently, we can sample a graph Gk from graphon Pk incorporating with the Gumbel softmax [40] for repa-rameterizing the graph's probability distribution. Moreover, Gumbel softmax can helps in minimizing the impact of less significant values, which could be seen as noise. The formulation of the Sampled Graph is given by:\nGk = \u03c3 (log (1-Pk) + z\u00b2 )\nwhere z\u00b9 and z\u00b2 are sampled from a Gumbel(0, 1) distribu-tion, and s is a temperature hyperparameter.\nTraining Policy. Real-world spatial dependencies are in-fluenced by numerous factors, including irregular urban development, changes in transportation policies, significant events, and more [7], [8], [9], which presents a challenging problem for developing models that can generalize to novel graph relation different from those encountered during training. To enhance the ability of each expert to handle out-of-distribution scenarios, we integrate episodic training [41], that trains a single deep network by exposing it to the domain shift scenario. In traffic forecasting, episodic training is to simulate the testing process during training for updating the graphons mixup [42]. An overall pipeline of our training policy is shown in Figure 3. For instance, when xi \u2208 Ti is input to the network, domain Ti is treated as the unseen target domain for the other K \u22121 experts {Pk}k=1,k\u2260i These K \u2013 1 experts are combined to generate the mixture's graphons Pmix. We aim for Pmix to closely match P\u2081 since the graphon P\u2081 represents the optimal solution for xi. For-mally, our training policy is formulated as:\nGenerating Graphon: Pk = \u03c3 (E(k) ET ),\nGenerating Weight {Wk}k=1,k\u2260i = f(xi),\nGraphons Mixup: Pmix = \\sum_{k=1,k\u2260i} \\frac{ewk} {\u03a3{j=1, j\u2260i} ewj} Pk\nFeeding into ST-GNNs: \u0177i = g(xi,Gk), Gk ~ Pk,\nwhere w = f(xi) represents the weight of the k-th ex-pert, dynamically generated by the input xi. The mixture's graphons Pmix are generated by the weighted average of softmax w. Subsequently, the sampled graph Gk ~ Pk is fed into the ST-GNNs' module g to forecast the future signal \u0177i."}, {"title": "5 EXPERIMENT", "content": "Datasets. We conducted experiments on four datasets, namely PEMS03, PEMS04, PEMS07, and PEMS08, evalu-ating their performance in both in-distribution and out-of-distribution scenarios. To evaluate model performance over time, we further propose four variants under OOD scenarios: PEMS03-2019, PEMS04-2019, PEMS07-2018, and PEMS08-2017, which align with existing standards [5], [20], using the same sensors to capture traffic data from different years. The experimental setup involved predicting the 12-step future based on the 12-step historical data [2], [25]. To further validate the model's generalization capability, we collected real-time traffic data provided by the Traffic Man-agement Center (TMC)\u00b3 of the New York City Department of Transportation. The model was trained using Speed data from March to May 2019, and tested on a multi-year dataset spanning from 2020 to 2022. The dataset partitioning follows the same approach as used in PEMS. The ratio of these three subsets is approximately 6:2:2.\nExperiment Settings Our experiments were conducted on a GPU server with eight GeForce GTX 3090 graphics cards, utilizing the PyTorch 2.0.3 framework. We standardized raw data through z-score normalization [43]. Training was terminated early if the validation error stabilized within 15-20 epochs or showed no improvement after 200 epochs,\n3. https://www.nyc.gov/html/dot/html/motorist/atis.shtml with the best model retained based on validation data [44]. We faithfully followed the model parameters and settings from the original paper, and also performed multiple rounds of parameter tuning to optimize the results. To ensure a comprehensive evaluation of the state's traffic conditions, we selected the same sensors as the current benchmark. Following the methodology outlined in [5], we chronologically split the data into train, validation, and test sets, maintain-ing a ratio of 6:2:2 across all datasets. Model performance was evaluated using Mask-Based Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE), excluding zero values as they represent noisy data [45]. Notably, we exclude zero values (representing noisy data) from these metrics [45]. The raw data undergoes standardization using Z-Score [43]. In case the validation error converges within 15-20 epochs or ceases after 100 epochs, the training process concludes prema-turely, saving the best model based on the validation data [44].\nBaseline Methods. We adopt the following representative traffic forecasting baselines. LSTM [46] is a temporal-only deep model that does not consider the spatial correlations. Taking advantage of the advancements in GNNs [24], [47], sequential models have been integrated with GNNs to ef-fectively model traffic data. During the period from 2018 to 2024, we specifically select RNN-based methods such as and DGCRN [48], AGCRN [10], TrendGCN [12], TCN-based methods like STGCN [26], MTGNN [11] and GWNET [2], as well as attention-based methods ASTGCN [5] and STTN [49]. Moreover, we incorporate five recent representative methods, which reflect the recent research directions in the field. STGODE [50] leverages neural ordinary differential equations to effectively model the continuous changes of traffic signals. DSTAGNN [51], DGCRN [48], D\u00b2STGNN [28] and STAEformer [13] specifically consider the dynamic char-acteristics of correlations among sensors on traffic networks.\nWe also compare the recent spatiotemporal OOD model CauSTG [17], STONE [18], CaST [16], which are designed to capture invariant relationships for OOD problem.\nComparing with Spatiotemporal OOD Method. First, we conducted a thorough evaluation of spatiotemporal OOD approaches. A shared characteristic among STONE, CaST, and CauSTG is their significantly inferior performance com-pared to current mainstream methods on in-distribution data. Nevertheless, these methods exhibit improved perfor-mance in OOD scenarios, although they still suffer from no-ticeable performance degradation. Notably, in the PEMS03 dataset, as previously analyzed, no substantial distribu-tional shift is observed, resulting in strong overall network performance. However, all OOD methods experienced con-siderable performance degradation in this scenario, which leads us to question whether they genuinely capture in-variant features. In fact, we argue that spatiotemporal in-variance is inherently difficult to define. For example, pre-dicting when future traffic disruptions might occur due to construction or the development of new commercial centers or hospitals is inherently uncertain. We hypothesize that the failure of current methods can largely be attributed to this unpredictability. In contrast, the modeling approach in our expert framework adopts a different perspective. Rather than attempting to identify invariant characteris-"}, {"title": "6 CONCLUSION", "content": "In this paper, we investigate the performance of state-of-the-art models using extended traffic benchmarks and find"}]}