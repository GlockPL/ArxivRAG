{"title": "A Shapley Value Estimation Speedup for Efficient Explainable Quantum AI", "authors": ["Iain Burge", "Michel Barbeau", "Joaquin Garcia-Alfaro"], "abstract": "This work focuses on developing efficient post-hoc explanations for quantum AI algorithms. In classical contexts, the cooperative game theory concept of the Shapley value adapts naturally to post-hoc explanations, where it can be used to identify which factors are important in an Al's decision-making process. An interesting question is how to translate Shapley values to the quantum setting and whether quantum effects could be used to accelerate their calculation. We propose quantum algorithms that can extract Shapley values within some confidence interval. Our method is capable of quadratically outperforming classical Monte Carlo approaches to approximating Shapley values up to polylogarithmic factors in various circumstances. We demonstrate the validity of our approach empirically with specific voting games and provide rigorous proofs of performance for general cooperative games.", "sections": [{"title": "I. INTRODUCTION", "content": "As Artificial Intelligence (AI) becomes a larger part of critical decision-making processes, it is important to understand the logic behind the decisions being made. Transparency in AI has become a topic of substantial regulatory importance worldwide. In the European Union, the General Data Protection Regulation (GDPR) provides citizens the right to explanations for impactful automated decisions which relate to personal data [1]. More recently, in 2024, the European Union enacted the AI act. The AI act provides individuals, in the context of high-risk AI systems, the right to an explanation for: (i) the use of an AI system in the decision-making process; (ii) the most important elements of that decision [2]. In the United States, the Maintaining American Leadership in Al executive order tasked the National Institute of Standards and Technology (NIST) with developing a plan for robust and safe research and development in AI [3]. NIST's plan listed explainability as an aspect of trustability, which is one of their key areas of focus. This wave of legislative attention poses a substantial challenge, as many of today's state-of-the-art AI algorithms, such as deep learning models, are unexplainable black boxes [4]. Without specialized tools, AI developers often cannot understand the reasoning of their models. There are several paths one can take to satisfy the new need for model explanations, the most popular approach is to create post hoc explanations for black-box models. Post hoc explanations have the advantage that we can continue to use powerful black box models, such as computer vision models, without being entirely blind to their inner workings.\nThis paper\u00b9 focuses on additive explanations, which indicate inputs with the largest effect on a particular output [6]. For example, if one were to apply for a bank loan and be rejected, an additive explanation would quantify the impact of features such as income, location, and debt on the application's rejection. When applied to Al models, these explanations describe which inputs are most important in making a particular decision. Several methods have been proposed for generating additive explanations; however, only one satisfies the important properties of local accuracy, missingness, and consistency [6]. This method is based on the Shapley value, a solution concept from cooperative game theory often used in economic game theory. In game theory, the Shapley value is a weighted average of the contribution provided by a player to every possible coalition of other players. To apply Shapley values to the analysis of AI models, we simply consider each feature a player and interpret a player being included or excluded from a coalition as a feature being on or off. Unfortunately, the direct calculation of Shapley values is NP-Hard. This means it takes an exponential number of operations [7], [8]. Outside of some special cases, random sampling is the only option for approximation [9].\nIn parallel to the growth in AI, we have seen an emergence of quantum computation and quantum AI [10]. Due to the fickle nature of quantum information, the problem of explainability is amplified since measuring a quantum system destroys information. As a result, many quantum algorithms act as ultra-black boxes, where their internal workings are impossible to comprehend or even fully measure. Though the field of eXplainable Quantum AI (XQAI) is still emerging, there exists some work into finding the Shapley values of quantum algorithms [11], [12], and a bit into other additive methods such as LIME [13]. Existing methods for Shapley-based explanations either rely on knowing the algorithm's structure as a quantum circuit or random sampling. By Chebyshev's inequality, random sampling is quadratic in complexity, twice the precision is four times the work [14]. Fortunately, it is often possible to do better in by leveraging quantum effects."}, {"title": "II. BACKGROUND", "content": "This section presents preliminaries on Shapley values, including the notation used, as defined in Table I, and formal definitions."}, {"title": "Definition 1 (Coalitional game)", "content": "A coalitional game is a tuple $G = (F,V)$. $F = \\{0,1, ..., n\\}$ is a set of $n + 1$ players. $V : P(F) \\rightarrow R$ is a value function with $V(S) \\in R$ representing the value of a given coalition $S \\subseteq F$, with the restriction that V(0) = 0."}, {"title": "Definition 2 (Payoff vector)", "content": "Given a game $G = (F,V)$, there exists a payoff vector $\\Phi(G)$ of length $n + 1$. Each element $\\Phi(G, i) \\in R$ represents the utility of player $i \\in F$. The value function determines a payoff vector. Player i's payoff value $\\Phi(G, i)$ is determined by how $V(S)$, $S \\subseteq F$, is affected by i's inclusion or exclusion from S."}, {"title": "1) Efficiency", "content": "The sum of all utility is equal to that of the grand coalition (the coalition containing all players),\n$\\sum_{i=0}^{n}\\Phi(G, i) = V(F)$."}, {"title": "2) Equal Treatment", "content": "Players i, j are said to be symmetrical if for all $S \\subset F$, where $i,j \\notin S$ we have that V(S$\\cup\\{i\\}$) = V(S$\\cup\\{j\\})$. If i and j are symmetric in G, then they are treated equally, $\\Phi(G, i) = \\Phi(G, j)$."}, {"title": "3) Null Player", "content": "Consider a player $i \\in F$, if for all $S \\subset F$ such that $i \\notin S$, we have V(S) = V(S$\\cup\\{i\\})$, then i is a null player. If i is a null player, then $\\Phi(G, i) = 0$."}, {"title": "4) Additivity", "content": "If a player is in two games G and G', then the Shapley values of the two games are additive\n$\\Phi(G + G', i) = \\Phi(G, i) + \\Phi(G', i)$\nwhere a game G + G' is defined as (F, V + V'), and $(V + V')(S) = V(S) + V'(S)$, S$\\subseteq$F."}, {"title": "Definition 3 (Shapley value [18])", "content": "Let G = (F,V), for notational simplicity, we write $\\Phi(G,i)$ as $\\Phi(i)$. The Shapley value of the ith player is,\n$\\Phi(i) = \\Phi^+(i) - \\Phi^-(i)$, (1)\nwhere,\n$\\Phi^+(i) = \\sum_{S \\subset F \\setminus \\{i\\}} \\gamma(|F \\setminus \\{i\\}|, |S|)V^+(S)$, V^+(S) = V(S$\\cup$\\{i\\})$, and, (2)\n$\\Phi^-(i) = \\sum_{S \\subset F \\setminus \\{i\\}} \\gamma(|F \\setminus \\{i\\}|, |S|)V^-(S)$, V^-(S) = V(S)$. (3)\nGiven n = $|F \\setminus \\{i\\}|$,\n$\\gamma(n,m) = \\frac{1}{\\binom{n}{m}(n + 1)}$"}, {"title": "Remark 1", "content": "The Shapley value is equivalently written as,\n$\\Phi(i) = \\sum_{S \\subset F \\setminus \\{i\\}} \\gamma(|F \\setminus \\{i\\}|, |S|)(V(S\\cup \\{i \\}) - V(S))$.\nThe Shapley value of i is the expected marginal contribution to a random coalition $S \\subset F \\setminus \\{i\\}$, where the marginal contribution is equal to $V(S\\cup \\{i\\}) - V(S)$ [17]. Each player's Shapley value can be interpreted as a weighted average of their contributions. Where the weights, $\\gamma(n, m)$, have an intuitive interpretation: the factor $1/\\binom{n}{m}$ results in each possible size of S having an equal impact on the final value. Since, given $|S| = m$, there would be $\\binom{n}{m}$ summands contributing to the final value. The multiplicand 1/(n + 1) averages between the different sizes of S."}, {"title": "Lemma 1", "content": "We have that $\\sum_{S \\subset F \\setminus \\{i\\}} \\gamma(|F \\setminus \\{i\\}|, |S|)$ is equal to one.\nProof. Let us define $H_m = \\{S \\in P(F \\setminus \\{i\\}) : |S| = m\\}$. We can rewrite $\\sum_{S \\subset F \\setminus \\{i\\}} \\gamma(|F \\setminus \\{i\\}|, |S|)$ as,\n$\\sum_{m=0}^{n} \\sum_{S \\in H_m} \\gamma(n,m)$.\nPlugging in the definition for $\\gamma$,\n$\\sum_{m=0}^{n} \\sum_{S \\in H_m} \\gamma(n,m) = \\sum_{m=0}^{n} \\sum_{S \\in H_m} \\frac{1}{\\binom{n}{m}(n + 1)} = \\sum_{m=0}^{n} \\frac{1}{\\binom{n}{m}(n + 1)} \\sum_{S \\in H_m} 1$.\nSince there are n choose m possible subsets of size m and hence n choose m possible subsets in $H_m$, it follows that we have,\n$\\frac{1}{n + 1} \\sum_{m=0}^{n} \\binom{n}{m} = \\frac{1}{n + 1} 2^n$\nHence, the result holds."}, {"title": "Definition 4 (Monotonic game)", "content": "A game is monotonic if for all $S, H \\subseteq F$, we have, $V(S\\cup H) \\geq V(S)$. Note that when a game is monotonic, every summand in Equation (1) is non-negative.\nA naive approach to finding the ith player's Shapley value is through direct calculation using the Shapley Equation (1), completing the task in $O(2^n)$ assessments of V. For structured games, it may be possible to calculate Shapley values more efficiently. Otherwise, another option is random sampling [9]. Substantial trade-offs exist in each case. We propose a quantum algorithm with some substantial advantages in the following sections."}, {"title": "A. Weighted Voting Games", "content": "Let us model a player's voting power as a weighted count of instances in which the player has the deciding vote. The Shapley values correspond to voting power. Three friends sit around a table. They are deliberating a grave matter. Should they get Chinese food for the second weekend in a row? They decide to take a vote. Alice just got a promotion at work. To celebrate this, their friends agreed to give them three votes. Bob, the youngest of the group, also had good news, an incredible mark on their latest assignment! Everyone decided Bob should get two votes. Charley, who had nothing to celebrate, and who is generally disliked, gets one vote. The group decides to go out for Chinese food if there are four yes votes."}, {"title": "V(S)", "content": "$\\begin{cases}\n1 & \\text{ if } \\sum_{j \\in S} w_j \\geq q, \\\\\n0 & \\text{ otherwise}.\n\\end{cases}$ (4)"}, {"title": "B. Explainability and Shapley Values of Binary Classifiers", "content": "Explainable AI can be broken into two categories, inherent explainability, and post-hoc explainability [4]. Inherently explainable models rely on algorithms which are easy to interpret, such as small decision trees or linear models. Ideally, every application would use inherently explainable models [4]; however, contemporary models tend to be black boxes which are very large and non-linear, e.g., deep neural networks. As a result, post-hoc methods, which attempt to explain black box decisions, have become an important form of harm-reduction. A promising research direction looks at using counterfactuals, questions of the form \"what is the smallest change that can be made to the input to change the output,\" as explanations [19], [20]. This paper focuses primarily on additive explanations, which assign importance to each input of a model [6].\nThere are multiple approaches to producing model explanations, one of the most promising being based on Shapley Values [6]. We introduce a simplified but rigorous method to leverage Shapley Values for explainability. Suppose we have a binary classifier C: {0,1}$^{r \\times r}$ $\\rightarrow$ {0,1}, which classifies binary strings of length $r^2$. This could, for example, represent a classifier which takes a r by r black and white medical scan and decides whether a patient has a cancerous tumour [21]. This is easily translated to a cooperative game. We consider each input bit (respectively pixel) to be a player in F = {0, . . . . . . ,r$^2$ - 1}. Each binary string h = h$_{r^2-1}$ . . . h1h0 $\\in$ {0,1}$^{r \\times r}$ represents a coalition Sh where player j is included if and only if $h_j$ is one (or equivalently, the jth pixel is white),\n$S_h = \\{j : h_j = 1, j \\in Z_r\\}$.\nWe can then define our value function $V_C : P(F) \\rightarrow R$ to correspond to the classifier C,\n$V_C(S_h) = C(h_{r^2-1}...h_1h_0)$."}, {"title": "VC,x(Sh)", "content": "$\\frac{1}{2^{|F\\setminus S_h|}} \\sum_{Q \\subset F\\setminus S_h} |V_C(S_x) - V_C ((S_x \\cap S_h) \\cup Q)|$. (5)"}, {"title": "IV. QUANTUM ALGORITHM FOR SHAPLEY VALUE APPROXIMATION", "content": "We represent the Shapley value calculation problem in the quantum context. Consider an n + 1 player game G represented by the pair (F, V), where F = {0,1,..., n} and V : P(F) $\\rightarrow$ R, with V(0) = 0. Table II gives an overview for the notation in this and the next section (Sections IV and V). We define V$_{max}$ as an upper bound and V$_{min}$ as the lower bound of the value function,\nV$_{max} \\geq \\max_{S \\subset F} V(S)$, and, (6)\nV$_{min} \\leq \\min_{S \\subset F} V(S)$. (7)\nThe goal is to implement a quantum version of V(S) and apply it on a superposition representing all possible subsets $S \\subset F \\setminus \\{i\\}$ and $S\\cup\\{i\\}$. We first define two quantum registers, the player and utility registers. The player register P$_{l}$ represents player coalitions and requires n qubits. Meanwhile, the utility U$_{t}$ register requires one qubit, and in its probability amplitude, represents the output of V given a player coalition."}, {"title": "V\u00b1(h)", "content": "$\\frac{V^{\\pm} (S_h \\cup \\{i\\}) - V_{min}}{V_{max} - V_{min}}$, and V^-(h) := $\\frac{V^{\\pm} (S_h) - V_{min}}{V_{max} - V_{min}}$ (8)"}, {"title": "V\u00b1(h)", "content": "$\\frac{V^{\\pm} (S_h) - V_{min}}{V_{max} - V_{min}}$ (9)"}, {"title": "B\u00b1", "content": "$\\begin{bmatrix}\n\\sqrt{1 - \\gamma(n, |h|_H)} \\cdot V^{\\pm}(h) & \\sqrt{\\gamma(n, |h|_H)} \\cdot V^{\\pm}(h) \\\\\n\\sqrt{\\gamma(n, |h|_H)} \\cdot V^{\\pm}(h) & -\\sqrt{1 - \\gamma(n, |h|_H)} \\cdot V^{\\pm}(h)\n\\end{bmatrix}$. (10)"}, {"title": "|x|H", "content": "|\\{j : x_j = 1, j \\in \\{0, . . . , n - 1\\}\\}| (11)"}, {"title": "|\u00b5\u00b1\u27e9", "content": "$(B^{\\pm})^{\\otimes} (H^{\\otimes n} \\otimes I) |0\\rangle_{P_l} |0\\rangle_{U_t}$. (12)"}, {"title": "\u3008\u03bc+|(I\u2297n \u2297 |1\u27e9\u27e81|) |\u03bc+) \u2013 \u3008\u03bc\u2212| (I\u2297n \u2297 |1\u27e9\u27e81|) |\u03bc\u2212)", "content": "$\\frac{\\Phi(i)}{2^n (V_{max} - V_{min})}$."}, {"title": "\u3008\u03bc+|(I\u2297n \u2297 |1\u27e9\u27e81|) |\u03bc+) \u2013 \u3008\u03bc\u2212| (I\u2297n \u2297 |1\u27e9\u27e81|) |\u03bc\u2212)", "content": "$\\frac{1}{2^n \\cdot (V_{max} - V_{min})} \\left((V_{min} - V_{min}) + \\sum_{S\\subset P\\setminus \\{i\\}} \\gamma(|F\\setminus\\{i\\}|, |S|) (V^+(S) - V^-(S))\\right)$ (13)"}, {"title": "V. EFFICIENT QUANTUM ALGORITHM FOR SHAPLEY VALUE APPROXIMATION", "content": "Consider an n+1 player game G. Suppose we have a quantum representation of the function V$^{\\pm}$(S'), defined in Equation (8), which acts on two registers, a player register, and a utility register. Additionally, we introduce a third register, called the partition register, which we use to generate the weights in the Shapley value sum. Table II gives an overview of some of the notation in this and the previous section (Sections IV and V), while Table III provides an overview for the remainder of the section."}, {"title": "|\u03c8a\u3009", "content": "$\\sum_{k=0}^{2^l-1}\\sqrt{w_l(k)} |k\\rangle_{P_t} (0\\rangle_{P_l}0\\rangle_{U_t}.$ (16)"}, {"title": "Rl", "content": "$\\langle t_l(k) = \\text{sin}^2(\\frac{k\\pi}{2^{l+1}})$ with $k = 0, 1, ..., 2^l.$ (17)"}, {"title": "t(k)", "content": "$\\text{sin}^2(\\frac{(k+\\frac{1}{2})\\pi}{2^{l+1}}).$ (18)"}, {"title": "\u03c9l(k)", "content": "\u03c9l(k) := tl(k + 1) \u2212 tl(k). (19)"}, {"title": "Dl (0^l)", "content": "$\\sum_{k=0}^{2^l-1} \\sqrt{\\omega_l(k)} |k\\rangle_{P_t}$. (20)"}, {"title": "Rl |k\u27e9Pt |0\u3009", "content": "|k\\rangle_{P_t} \u2297 ($\\sqrt{1 \u2212 tl(k)}|0\\rangle + \\sqrt{tl(k)}|1\\rangle$) \u2297 |0\\rangle^{\u2297n\u2212j\u22121} (21)"}, {"title": "|\u03c816\u27e9", "content": "$\\prod_{j=0}^n (Rl \\otimes I) |\u03c81a\\rangle$ (22)"}, {"title": "|\u03c816\u27e9", "content": "$\\sum_{k=0}^{2^l-1} \\sqrt{\\omega_l(k)} |k\\rangle_{P_t} \\big( \\sqrt{1 \u2212 tl(k)}|0\\rangle + \\sqrt{tl(k)}|1\\rangle \\big) \u2297 |0\\rangle_{U_t}$ (23)"}, {"title": "|\u59de\u27e9", "content": "(Il \u2297 Ut) |\u03c816\u27e9"}, {"title": "trl( \u5409\u5409)", "content": "$\\sum_{i=0}^n \\sum_{h \\in H_m} \\sum_{k=0}^{2^l-1} wl(k)b_{n,m}(tl'(k))$"}, {"title": "Theorem 4", "content": "The Riemann sum using partition Pl to approximate area under $x^{m} (1-x)^{n-m}$ for $x \\in [0,1]$ asymptotically approaches $\\gamma(n,m)$. Formally,\n$\\sum_{i=0}^{2^l-1} wl(k)b_{n,m}(tl'(k)) = \\gamma(n,m) + \\epsilon',$ (24)\nwhere $|\\epsilon'| \\leq \\pi/2^l$."}, {"title": "Applying our approximation for \u03b3(n, m) and tracing out the player and partition registers, we have", "content": "$\\text{trp}_t,P_1(\\\u5409\u5409) \u2248 \\sum_{m=0}^n \\sum_{h \\in H_m} \\gamma(n,m)|V^{ \\pm}(h)\\rangle\\langle V^{ \\pm}(h)|$"}, {"title": "VI. QUANTUM SHAPLEY VALUE EXAMPLES", "content": "Perhaps we can help David solve his problem (cf. Subsection III-A) using our quantum approach. We intend to apply the method presented in Section V for weighted voting games. Additional results, together with the simulation code, are available in a companion GitHub repository [28]. Let us approximate each player's Shapley value, \u03a6(i). We have a game G = (F, V), where F = {0,1,2}, n = 2, and V is defined in Equation (4). Let the voting weights be w0 = 3, w1 = 2, and w2 = 1. Thus, we can define V$^{\u00b1}$(h), h \u2208 {0,1}$^2$, where h represents an element in P(F $\\setminus$ {i}),"}, {"title": "V+(h) = 0", "content": "$\\begin{cases}1 & \\text{ if } \\sum_{s \\in S_h \\cup \\{i\\}} w_s \\geq q \\\\ 0 & \\text{ otherwise} \\end{cases}$"}, {"title": "V(h) = 0", "content": "$\\begin{cases}1 & \\text{ if } \\sum_{s \\in S_h} w_s \\geq q \\\\ 0 & \\text{ otherwise} \\end{cases}$"}, {"title": "U", "content": "UT\u00b1 |x\u3009|0\u3009 = |x\u3009 \u2297 [(1 \u2212 V$^{\u00b1}$(x)) |0\u3009 + V$^{\u00b1}$(x) |1\u3009]"}, {"title": "VII. IMPROVED QUANTUM ALGORITHM FOR SHAPLEY VALUE APPROXIMATION", "content": "Section V describes an algorithm to estimate the Shapley values of cooperative games. Assuming a reasonable implementation of $D_l$ (20), the algorithm is often more efficient than classical random sampling. However, an implementation of $D_l$ may"}, {"title": "Q", "content": "$(k2^{-l})_{k=0}^{2^l}$ (25)"}, {"title": "\u221a2 ke - 10", "content": "$\\frac{1}{\\sqrt{2}}\u2211_{k=0}^{2^l-1} |k\\rangle_t |0\\rangle  \\rightarrow \\frac{1}{\\sqrt{2}} \u2211_{k=0}^{2^l-1} |k\\rangle_t(\\sqrt{1-r_l(k)}|0\\rangle + \\sqrt{r_l(k)}|1\\rangle),$"}, {"title": "VIl", "content": "rl(k) := (k + 1/2)2\u2212l + \u0454k, and |\u0454k| is less than 2\u2212(l+1). It follows that rl(k) \u2208 [k2\u2212l, (k + 1)2\u2212l]."}]}