{"title": "Towards a scalable AI-driven framework for data-independent Cyber Threat Intelligence Information Extraction", "authors": ["Olga Sorokoletova", "Emanuele Antonioni", "Giordano Col\u00f2"], "abstract": "Cyber Threat Intelligence (CTI) is critical for mitigating threats to organizations, governments, and institutions, yet the necessary data are often dispersed across diverse formats. AI-driven solutions for CTI Information Extraction (IE) typically depend on high-quality, annotated data, which are not always available. This paper introduces 0-CTI, a scalable AI-based framework designed for efficient CTI Information Extraction. Leveraging advanced Natural Language Processing (NLP) techniques, particularly Transformer-based architectures, the proposed system processes complete text sequences of CTI reports to extract a cyber ontology of named entities and their relationships.\nOur contribution is the development of 0-CTI, the first modular framework for CTI Information Extraction that supports both supervised and zero-shot learning. Unlike existing state-of-the-art models that rely heavily on annotated datasets, our system enables fully dataless operation through zero-shot methods for both Entity and Relation Extraction, making it adaptable to various data availability scenarios. Additionally, our supervised Entity Extractor surpasses current state-of-the-art performance in cyber Entity Extraction, highlighting the dual strength of the framework in both low-resource and data-rich environments.\nBy aligning the system's outputs with the Structured Threat Information Expression (STIX) format, a standard for information exchange in the cybersecurity domain, 0-CTI standardizes extracted knowledge, enhancing communication and collaboration in cybersecurity operations.", "sections": [{"title": "I. INTRODUCTION", "content": "Cyber Threat Intelligence (CTI) [1] is a fundamental discipline in cybersecurity that focuses on the collection, analysis, and interpretation of threat data concerning cyberattacks. This process involves collecting data from various sources, such as dark web forums, security incident databases, and network sensors, to build a comprehensive picture of potential threats. In this context, a key role is played by the Cyber Threat Intelligence analyst. The CTI analyst is a professional specializing in the collection, analysis, and interpretation of cyber threat intelligence. The CTI analyst identifies Indicators of Compromise (IOCs), analyzes attackers' Techniques, Tactics, and Procedures (TTPs), and provides strategic recommendations to improve security. Additionally, the CTI analyst collaborates with other security teams to implement preventive measures and respond to incidents, contributing to a secure digital environment. Despite several technological advances, the work of the CTI analyst still requires many manual knowledge extraction steps, such as data collection, verification, and analysis, which are laborious and time-consuming. Moreover, many companies, organizations, or public institutions lack the resources to hire a dedicated CTI analyst, exposing themselves to various risks. These risks include vulnerability to cyber attacks, loss of sensitive data, reputational damage, and potential breaches of data security regulations. The absence of a CTI expert can significantly undermine an organization's ability to defend itself against cyber threats. To address these problems, the industry has been investing heavily in the integration of Artificial Intelligence (AI) tools [2], [3]. AI enables the automation of many manual tasks, such as network monitoring and data analysis, increasing the efficiency and speed of the intelligence process. For example, Machine Learning (ML) algorithms can identify patterns and anomalies in data, signaling imminent threats for faster and more accurate responses. Additionally, AI helps predict future threats by analyzing historical and behavioral trends of attackers.\nIn line with the intention of integrating AI techniques effectively within the CTI analyst's workflow, this paper introduces 0-CTI, an innovative system designed to address various challenges in the field of Cyber Threat Intelligence. The system employs a fully Machine Learning-based approach to extract knowledge in a structured format from unstructured natural language texts. 0-CTI was developed to significantly accelerate the work of CTI analysts by automating numerous laborious steps in the data extraction and analysis process. Traditionally, analysts spend considerable time manually collecting, verifying, and interpreting threat information. With 0-CTI, these tasks can be quickly and accurately performed, enabling analysts to focus on more strategic and decision-making responsibilities. Another major advantage of 0-CTI is its ability to support organizations lacking a dedicated"}, {"title": "II. INFORMATION EXTRACTION OF STIX OBJECTS", "content": "Acknowledged as a widely adopted standard within the CTI community, the STIX has established itself by proclaiming a systematic classification covering all aspects of suspicion, compromise, and attribution. With objects and descriptive relationships, this systematic classification serves the purpose of enabling a consistent data-sharing among organizations. In a more formal context, STIX can be characterized as a schema that defines a taxonomy of Cyber Threat Intelligence, comprising six distinct classes, three of which are the primary focus of our attention: STIX Domain Objects (SDOs) that are higher-level intelligence objects, representing behaviors and constructs that threat analysts typically engage with to comprehend the threat landscape; STIX Cyber-observable Objects (SCOs) that encapsulate Indicators of Compromise (IOCs), a perennial concern in Cybersecurity; and STIX Relationship Objects (SROs) that connect SDOs together, SCOs together, and SDOs with SCOs.\nGiven that our work addresses the Information Extraction problem, it is crucial to align this formulation with STIX terminology to standardize the system's output, facilitating efficient information sharing within the cybersecurity community.\nThe task of Information Extraction from textual data, as outlined by Jakub Piskorski and Roman Yangarber in [6], involves automating the identification and extraction of structured information or knowledge from unstructured text. It encompasses the identification and extraction of specific entities, relationships, and events mentioned in the text, transforming raw data into a structured format that is easily processable and analyzable. In our case, the holistic task breaks down into two subtasks, which can be tackled either concurrently or sequentially: Entity Extraction (EE) and Relation Extraction (RE). Within the framework of STIX, entities for Entity Extraction are represented by a subset of SDOs and SCOs, while relationships in Relation Extraction are defined by SROs."}, {"title": "III. RELATED WORKS", "content": "The necessity to automate Cyber Threat Intelligence data processing, emphasizing Entity and Relation Extraction in compliance with community standards, has driven researchers to embrace Information Extraction methodologies in Cybersecurity. Despite significant efforts (Gasmi et al. 2019 [7]; Legoy et al. 2020 [8]), many current methods struggle with the volume of extracted entities and relations and do not fully adhere to the STIX taxonomy. However, the adoption of Artificial Intelligence (AI), particularly Transformer models, is enhancing the efficiency of these processes, facilitating more robust and automated CTI analysis.\nWeerawardhana et al. (2015) [9] compared a Machine Learning-based approach and a Part-of-Speech tagging method for Information Extraction, focusing on vulnerability databases. Li et al. (2019) [10] introduced a self-attention-based Neural Network for Cybersecurity Named Entity Recognition (NER), integrating features from words and characters using Convolutional Neural Networks (CNN) and a self-attention mechanism based on Bidirectional Long Short-Term"}, {"title": "IV. 0-CTI SYSTEM", "content": "The 0-CTI, a modular Transformers-based system, serves as a \"lens\" applied to raw, unstructured collections of Cyber Threat Intelligence, zooming in on STIX Domain Objects, Indicators of Compromise (IOCs), and their relationships expressed as STIX Relationship Objects. The overall architecture of the system is delineated in the block scheme depicted in Fig. 1, with a detailed explanation of each component provided in this section."}, {"title": "A. Dataset and Text Processing", "content": "In the initial phase, the Text Processing module ingests CTI documents and processes the raw textual content within, producing a dataset containing sanitized, tokenized, and labeled text chunks. This dataset is provided as the output of this module and the input for the subsequent modules.\nThe system accepts CTI documents in English in various formats, including PDF, DOCX, or HTML. The extraction process identifies 9 entity classes corresponding to 9 STIX Domain Objects\u00b9, and 21 relation classes corresponding to 21 STIX Relationship Objects. The dataset used for training the supervised NER model contained annotations for entities, with statistics presented in Table I, but did not include annotations for relations, which are: ATTRIBUTED_TO, AUTHORED_BY, BEACONS_TO, COMMUNICATES_WITH, COMPROMISES, CONSISTS_OF, CONTROLS, DELIVERS, DOWNLOADS, DROPS, EXFILTRATE_TO, EXPLOITS, HAS, HOSTS, IMPERSONATES, INDICATES, LOCATED_AT, ORIGINATES_FROM, OWNS, TARGETS, USES.\nThe Identity SDO is categorized to distinguish between persons and organizations, while the Indicator SDO is subdivided to encompass 23 types of IOCs/SCOs within the dataset, including domain names, email addresses, file hashes, IP addresses, URLs, and registry key paths, among others (for a comprehensive list and dataset statistics on their occurrences, refer to Table II).\nThe responsibility for discovering these indicators lies with the IOC-finder. Concurrently, the input presented to the ML-driven core of Entity Extraction undergoes a masking process using strings associated with the respective IOC types to prevent the learning process from being disrupted by erratic tokenization.\nThe aggregation of data from diverse sources inherently gives rise to noise, necessitating comprehensive preprocessing prior to initiating the training phase. Our text processing workflow is structured into three stages: standardization and artifact removal, chunking and recalibration, and CoNLL-formatting."}, {"title": "B. Entity Extraction with Supervised Named Entity Recognition and IOC-finder", "content": "The subsequent module in Fig. 1 is dedicated to Entity Extraction and consists of two primary submodules: the core extractor and the IOC-finder. The core extractor is embodied by the currently leading Transformer model for Token Classification, fine-tuned on an annotated dataset, and the zero-shot NER model, GLiNER. The IOC-finder is regarded as a mandatory sub-component. The modularity of the framework is highlighted by the gray connectors in the block scheme, which indicate the potential to integrate additional sub-components to enhance the core extractor. Examples of such augmentations include an interactive Knowledge Base (KB) to facilitate continuous system improvement, or a SpaCy POS Tagger and Dependency Parser to improve the system's ability to discover new entities and relationships based on observable linguistic patterns, without relying solely on AI.\nThe IOC-finder serves the purpose of identifying Indicators of Compromise (IOCs) submodule. The submodule was implemented using the utilities of Floyd Hightower's open-source project/library: IOC Finder. It operates in precedence"}, {"title": "C. Zero-Shot Components", "content": "Zero-shot learning empowers models to predict classes they have never encountered during training, revolutionizing tasks such as Named Entity Recognition. Traditional NER models"}, {"title": "1) Zero-Shot Named Entity Recognition", "content": "Our system performs zero-shot NER by combining GLiNER [4] with a specific paradigm of class substitution based on a flat taxonomy. Each entity class that the system has to recognize is divided into several child categories. If a token is assigned to one of these child labels, it is automatically assigned to the parent class. For example, the MALWARE class is mapped to subclasses such as Malicious Software, Trojan, Ransomware, and more.\nWe have chosen GLiNER as the only available zero-shot Entity Extractor that does not rely on resource-intensive Large Language Models, which can be difficult to deploy. This selection reinforces the core idea of our framework: to provide a ready-to-use solution accessible for a wide range of applications, even in resource-limited conditions.\nAt its core, GLINER leverages pretrained language models like BERT or GPT to comprehend and infer relationships between words and entities within a text, independent of prior exposure to specific entity types. GLiNER operates through a structured methodology for entity recognition. When given a text, it initially encodes the input using a pretrained model, capturing contextual embeddings of the words. The next step involves applying a zero-shot inference mechanism. GLiNER interprets Entity Extraction as a Natural Language Inference (NLI) problem wherein the model is tasked with determining whether a given hypothesis (the presence of a specific entity type) is supported by the premise (the input text).\nCombining the capabilities of GLiNER approach with a taxonomy of classes derived from our mapping system, we successfully integrated a zero-shot Named Entity Recognition alternative into the Entity Extraction core of 0-CTI. This feature is particularly advantageous for users seeking to extend the system's capability to recognize additional classes beyond those covered by our supervised NER model, eliminating the necessity of acquiring and annotating new data."}, {"title": "2) Relation Extraction using Cross-Encoders", "content": "Cross-encoders [26] are powerful NLP model, distinguished for their proficiency in assessing the semantic relationships between pairs of text sequences. Unlike bi-encoders, which encode each sequence independently, cross-encoders process both sequences together, enabling them to capture intricate dependencies and context. Thanks to this feature, cross-encoders demonstrate particular effectiveness in tasks such as assessing the implication of one sentence by another, which is crucial for diverse AI applications, including Relation Extraction. A cross-encoder takes a pair of sentences as input and assesses whether the meaning of the second sentence is entailed by the first.\nFor the Relation Extraction module in Fig. 1, we propose an algorithm leveraging cross-encoders to extract relations from text. This algorithm integrates the outputs of the Entity Extraction module and adheres to the STIX standard for defining relations."}, {"title": "Entity Extraction", "content": "First, IOCs and entities within the text are extracted using the IOC-finder and NER systems: the zero-shot NER model, the supervised NER model, or a combination of both."}, {"title": "Potential Relations Creation", "content": "Once entities are identified, the algorithm proceeds to generate potential relations by associating entities with their corresponding entity types, referencing the table of potential SROs for given pair of SDOs, which is provided in the STIX documentations. For each pair of entities, the algorithm formulates a set of candidate sentences following the pattern: < Entity1 >< Relation >< Entity2 >. For instance, if the text mentions \"APT1\" and \"Microsoft\", a possible relation could be expressed as \"APT1 targets Microsoft.\""}, {"title": "Relation Evaluation with Cross-Encoders", "content": "The cross-encoder takes both the original text and the candidate relation sentence as input and calculates the likelihood that the candidate relation is true based on the context of the original text."}, {"title": "Threshold-Based Validation", "content": "The algorithm assigns a truth value to each candidate relation given the score provided by the cross-encoder. Relations that surpass a predefined threshold are considered valid. This thresholding operation is crucial in ensuring that only the most probable relations are retained, thereby enhancing the accuracy of the extraction process."}, {"title": "Relation Disambiguation", "content": "In cases of ambiguity, such as when the same relation occurs between two entities in both directions (e.g., < Entity1 >< Relation >< Entity2 > and < Entity2 >< Relation >< Entity1 >), the algorithm disambiguates by comparing the cross-encoder scores. The relation with the higher score is retained, ensuring selection of the most contextually accurate relation."}, {"title": "V. EXPERIMENTAL EVALUATION", "content": "At the time of writing this paper, our experimental investigations into the 0-CTI framework are ongoing, focusing on collecting a dataset annotated for cyber relations to enable a comprehensive assessment of the Relation Extraction module and, consequently, the overall system performance. In the meantime, we present a rigorous quantitative performance evaluation of the supervised Named Entity Recognition model within the Entity Extraction core. This is complemented by a qualitative assessment of our zero-shot components, which leverage advanced Large Language Models (LLMs). Together, these evaluations highlight the system's potential impact in the field of Cyber Threat Intelligence."}, {"title": "A. Performance Evaluation of the Supervised Entity Extractor", "content": "To evaluate the performance of the fine-tuned Named Entity Recognition model, we conducted two experiments. The first experiment compared the effectiveness of two Transformer models and a Word2Vec embedding with an LSTM on dataset that we collected from OpenCTI sources. In the second experiment, we benchmarked the best-performing model from the first experiment against STIXnet [17].\nIn both experiments, we began by identifying Indicators of Compromise through the IOC-finder submodule, replacing them in the text with placeholders. Given the IOC-finder's accuracy, approaching 100%, we excluded its results from the evaluation to concentrate on the submodules that require contextual awareness."}, {"title": "1) Models Comparison on Our Dataset", "content": "In this initial experiment, we conducted an 18-class classification task, employing 9 classes with BIO-tagging. The dataset was divided into a training set comprising 3500 text chunks and a test set with 880 chunks. Since some chunks do not contain entities, we expect empty outputs for these instances and aim to minimize False Positives.\nBoth Transformer models were fine-tuned for 12 epochs using Cross-Entropy loss, the Adamw optimizer, a batch size of 4, and a learning rate of 2e-5. The first network, 0-CTIBGE, utilized the bge-en-v1.5 embeddings [25],"}, {"title": "2) Comparison on STIXnet Dataset", "content": "In this experiment, we conducted a comparative analysis between the 0-CTICYBERT model and the STIXnet, a previous state-of-the-art modular system for Information Extraction in CTI. We utilized the dataset provided by [17], which encompasses reports that focus on groups or threat actors from the MITRE ATT&CK framework.\nOur approach involved fine-tuning the 0-CTICYBERT model on the new dataset. The preprocessing steps and training configurations mirrored those of the first experiment."}, {"title": "B. LLM-as-a-Judge Evaluation of Zero-Shot Systems", "content": "Large Language Models (LLMs), such as GPT-4, have shown strong capabilities in understanding and generating unstructured natural language texts [27]. The LLM-as-a-Judge method [28] leverages these models to evaluate the performance of other AI systems, providing qualitative assessments based on criteria such as accuracy, relevance, and coherence. In our framework, we employed the LLM-as-a-Judge method using ChatGPT-4 to evaluate our zero-shot systems: the zero-shot NER and the zero-shot Relation Extractor. These systems were tested on their ability to accurately extract entities and relations from text without prior annotations.\nWe evaluated 120 CTI reports from our dataset to ensure a comprehensive assessment. The zero-shot NER system achieved an impressive average score of 0.91 with a standard deviation (STD) of 0.06, indicating high performance and low variability; this suggests that the GLiNER model consistently identifies entities accurately. The zero-shot Relation Extraction module obtained an average score of 0.83 with a higher STD of 0.15, reflecting the inherent complexity of the Relation Extraction task. The number of potential relations within the text increases exponentially with each extracted entity. Additionally, the system's performance is influenced by error propagation from EE to RE due to its modular structure. When an entity is misclassified by the NER, whether supervised or not, it is subsequently passed to the Relation Extraction module, resulting in inevitable errors.\nThe LLM-as-a-Judge method has proven invaluable for automating the qualitative evaluation, providing insightful assessments that validate the robustness of our zero-shot NER system and identify areas for improvement in the zero-shot Relation Extraction module."}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "0-CTI stands out as a unique and powerful tool valuable in enhancing preparedness and resilience within Cybersecurity, offering a range of significant advantages.\nFirstly, it automates the extraction of critical information from CTI data, effectively reducing the burden on security teams and saving them time and effort. By streamlining this process, 0-CTI ensures that the latest threat intelligence is readily accessible, thereby empowering quicker and more informed decision-making in response to emerging threats.\nCentral to its appeal are scalability and modular design features, which allow for data-independence and seamless integration or substitution of various submodules. This adaptability ensures that the system can evolve alongside the dynamic landscape of Cybersecurity, even in the absence of specific expertise or data.\nThe IOC-finder component enhances 0-CTI's capabilities by swiftly detecting Indicators of Compromise, providing crucial early warnings for potential cyberattacks. Then, the integration of advanced Natural Language Processing (NLP) techniques and models for Entity Extraction and Relation Extraction underscores our solution's transformative role in analyzing and interpreting cyber threats. By leveraging cutting-edge Transformer-based architectures, the system excels in the NER task, surpassing the performance of alternative approaches designed for cyber NER challenges. Furthermore, our newly implemented algorithm for Relation Extraction, evaluated qualitatively using a novel LLM-as-a-Judge approach, shows promising results.\nBy adhering to the Structured Threat Information Expression (STIX) standard, 0-CTI ensures that extracted knowledge can be efficiently shared across the cybersecurity community. Its use of a cyber graph format facilitates seamless integration with knowledge bases and dedicated software, supporting continuous learning and enhancing system capabilities over time.\nIn essence, 0-CTI represents a comprehensive and forward-thinking solution that not only enhances operational efficiency but also sets new benchmarks in CTI processing, positioning itself at the forefront of cybersecurity technology.\nThe 0-CTI system holds potential for advancing and enhancing its capabilities, solidifying its position as a leading solution for CTI Information Extraction. Ongoing experimentation efforts focus on refining the performance with the objective to optimize the system's overall utility. A key area of emphasis addresses a comprehensive evaluation of the system's capabilities in Relation Extraction, involving the acquisition of annotated data to quantify performance evaluation and benchmark against supervised approaches and state-of-the-art methods.\nThe next milestone involves integrating real-time data sources, enabling more immediate and proactive threat identification. This expansion will extend the system's scope to include diverse and evolving data streams, ranging from social media conversations to activities on the dark web. Each of these sources contributes unique insights into the cyber threat landscape. For instance, social media platforms and news outlets can serve as early indicators of emerging threats or the dissemination of malware campaigns. This evolutionary progression aims to empower the system from a reactive stance, where threats are addressed post-identification, to a proactive approach. Such a transition is crucial in a landscape where early detection plays a pivotal role in minimizing the impact of cyberattacks."}]}