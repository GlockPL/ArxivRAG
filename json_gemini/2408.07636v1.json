{"title": "DRUG DISCOVERY SMILES-TO-PHARMACOKINETICS\nDIFFUSION MODELS WITH DEEP MOLECULAR UNDERSTANDING", "authors": ["Bing Hu", "Anita Layton", "Helen Chen"], "abstract": "Artificial intelligence (AI) is increasingly used in every stage of drug development. One challenge\nfacing drug discovery AI is that drug pharmacokinetic (PK) datasets are often collected independently\nfrom each other, often with limited overlap, creating data overlap sparsity. Data sparsity makes\ndata curation difficult for researchers looking to answer research questions in poly-pharmacy, drug\ncombination research, and high-throughput screening. We propose Imagand, a novel SMILES-to-\nPharmacokinetic (S2PK) diffusion model capable of generating an array of PK target properties\nconditioned on SMILES inputs. We show that Imagand-generated synthetic PK data closely resembles\nreal data univariate and bivariate distributions, and improves performance for downstream tasks.\nImagand is a promising solution for data overlap sparsity and allows researchers to efficiently generate\nligand PK data for drug discovery research. Code is available at https://github.com/bing1100/\nImagand.", "sections": [{"title": "1 Introduction", "content": "Generative AI is set to transform drug discovery, where it may cost $2-3 billion dollars and 10-15 years to bring a single\ndrug candidate to market [30]. Generative AI for high-throughput screening (HTS) of ligand candidates reduces drug\ndevelopment costs and is changing how ligands are designed and tested [41]. Initial success of drug discovery AI has\nbeen in drug repurposing [36, 50], drug-target interaction [33], drug response prediction [40], poly-pharmacy [61], and\nthe generation of synthetic ligands and drug properties [25, 52]. Thus far, what has advanced drug discovery AI is a\ncontinued effort towards open data for training and testing [8, 17, 27].\nData collection for drug discovery through assay panels is expensive and time-consuming. Although there are\nclear advances toward standardization and dissemination of pre-clinical, clinical, and chemical datasets [27, 31, 37],\nchallenges arise when merging and linking these datasets together [46]. Collected independently, drug discovery\ndatasets often have limited overlap, which poses a challenge for researchers looking to answer research questions\nrequiring data from multiple datasets. One notable example is the study of drug combinations and poly-pharmacy [46].\nRecent advances in drug discovery AI have utilized Denoising Diffusion Probabilistic Models (DDPMs) [21], which\nyield a new class of diffusion models capable of generating ligand structures [18, 28, 52, 58]. Hu et al. [25] have\nshown that diffusion models can generate pharmacokinetic (PK) properties alongside the ligand diffusion pipeline with\npromising results. Multi-modal diffusion models such as Text-to-Image and Text-to-Video diffusion models have been\ndemonstrated to generate high-quality photorealistic data [23, 44]. Azizi et al. [4] have also shown that synthetic data\nfrom diffusion models have improved performance in ImageNet classification tasks. Inspired by these advances, we\npropose Imagand, which can generate an array of 12 PK target properties from 10 PK datasets conditioned on learned\nSMILES embeddings. Specifically, our contributions are as follows:\n\u2022 We propose Imagand, a novel multi-modal SMILES-to-Pharmacokinetic (S2PK) diffusion model capable of\ngenerating an array of target properties conditioned on learned SMILES embeddings.\n\u2022 We develop a noise model that creates a prior distribution closer to the true data distribution, which makes\ntraining easier [52]."}, {"title": "2 Background", "content": "Diffusion methods use families of probability distributions to model complex datasets for computationally tractable\nlearning, sampling, inference and evaluation [18]. Denoising Diffusion Probabilistic Models (DDPM) [21] first\nsystematically destroy the structure in the data through a forward process, and then in a reverse process, learn how to\nrestore the structure in the data from noise. Recent literature has covered many advances in small-molecule generation\nusing diffusion models [24, 26, 45, 52].\nDDPMs can be combined with graph networks. Conditional Diffusion models are based on discrete Graph Structures\n(CDGS) and can be used to generate small-molecule graphs with similar distribution to real small-molecules [26].\nDigress [52] combines graph transformers [16] and discrete diffusion [3] for molecular-conditioned small-molecule\ngeneration. Digress utilizes graph-level properties such as cycles, and spectral and molecular features to augment\nthe input, improving training and sampling performance. Conditional generation has shown benefits for diffusion\nText-to-Image and Text-to-Video models [23, 44]. In Text-to-Image and Text-to-Video models, learned embeddings\nfrom Large Language Models (LLMs) are utilized as input to lend deep language understanding to the diffusion models.\nPK broadly describes what the body does to a drug regarding absorption (how the body absorbs the drug), bioavailability\n(the extent the active drug enters circulation), distribution (how the drug distributes in tissue), metabolism (how the body\nbreaks down the drug), and excretion (how the drug is removed from the body). As issues related to PK properties are\nthe primary drivers for compound attrition for small-molecule drug development [32], accurate PK computational tools\nare critical and have advanced in recent times [2, 11, 55]. Physiologically-based pharmacokinetics (PBPK) offers the\nmodelling of PK properties using mathematical equations representing the human body [43]. PBPK rely on expensive\nin-vitro and in-vivo human and animal experiments and cannot be utilized in high-throughput screening across large\nnumbers of ligands (10K to 100K drugs per day) [39].\nExtending many PK properties across large arrays of ligands can be costly given the expense associated with data\ncollection for drugs. Consequently, oftentimes only small sets of ligands can be feasibly tested for target property\ndata collection studies, leading to minimal overlap between collected datasets [46]. This challenge poses barriers for\nscientists interested in answering research questions requiring data across multiple datasets, such as in poly-pharmacy\nand drug combination research."}, {"title": "3 Methodology", "content": "Imagand is a S2PK diffusion model conditioned on learned SMILES embeddings from SMILES encoder models\nto generate target PK properties. We utilize a typical diffusion process as formulated in Ho et al. [21] with only\nmodifications to the choice of noise model to better capture distribution priors. In the following subsections, we describe\neach of these components in detail."}, {"title": "3.1 Pre-trained SMILES Encoder", "content": "S2PK diffusion models need powerful semantic SMILE encoders to capture the complexity of arbitrary chemical\nstructure inputs. Given the sparsity and small size of PK datasets, encoders trained on specific SMILES-Pharmacokinetic\npairs are infeasible [27]. Many transformer-based foundational models such as ChemBERTa [1, 9], SMILES-BERT\n[54], and MOLGPT [5] have been pre-trained to deeply understand molecular and chemical structures and properties.\nAfter pre-training, these foundational models can then be fine-tuned for various downstream molecular tasks. Language\nmodels trained on SMILES-only corpus, significantly larger than SMILES-Pharmacokinetic data, learn a richer and\nwider distribution of molecular and chemical structures.\nWe test SMILES embeddings from ChemBERTa [1], T5 [42], and DeBERTa [19] trained on SMILES-only corpora.\nWe further test and compare embedding performance for SMILES embedding from ChemBERTa trained either on\nZINC (100K molecules) [29] or PubChem (10M molecules) [31] SMILES corpora. All SMILES embedding models\nwere collected through the Huggingface [57] Model Hub. As ChemBERTa, T5, and DeBERTa are all trained on a wide"}, {"title": "3.2 Diffusion Model", "content": ""}, {"title": "3.2.1 Base Model", "content": "Imagand resembles a typical vision transformer architecture [14]; see Figure 1. 1D patches are computed from the\nclassifier-free guidance of SMILES embeddings and concatenated with PK class tokens. Diffusion step embeddings are\ngenerated using sinusoidal position encodings [51]. Patches are then fed alongside sinusoidal step embeddings [22] to a\ntransformer base. We mask out missing values when computing the loss for the model only to flow gradients and learn\nfrom non-missing PK values during training. Exponential Moving Average (EMA) [49] is applied to the base model\nduring training to generate the final model used for sampling."}, {"title": "3.2.2 Classifier-free Guidance", "content": "Classifier guidance uses gradients from a pre-trained model to improve quality while reducing diversity in conditional\ndiffusion models during sampling [12]. Classifier-free guidance [20] is an alternative technique that avoids this\npre-trained model by jointly training a diffusion model on conditional and unconditional objectives via dropping the\ncondition (i.e. with 10% probability). We condition all diffusion models on learned SMILES embedding and sinusoidal\ntime embeddings using classifier-free guidance through dropout [20, 48]."}, {"title": "3.2.3 Static Thresholding", "content": "We apply elementwise clipping the PK predictions to [-1, 1] as static thresholding, similar to Ho et al. [21], Saharia\net al. [44]. Since PK data is min-max scaled to the same [-1,1] range as a preprocessing step, static thresholding is\nessential to prevent the generation of invalid and out-of-range PK values."}, {"title": "3.3 Discrete Local Gaussian Noise Model", "content": "The choice of noise models may have a substantial impact on performance; using a prior distribution close to the true\ndata distribution can make training easier [52]. As PK properties do not always follow a Gaussian or uniform noise\nmodel, we propose a noise model called Discrete Local Gaussian Noise (DLGN). DLGN decomposes complex PK\ndistributions as Gaussian distributions within discrete bins. Discrete bins are modelled as discrete random variables."}, {"title": "3.3.1 Discrete Bin Random Variables", "content": "Given a PK distribution, we first apply data binning to produce N bins. We define a discrete probability density function\n(PDF) on the bins, given in Equation 1, where X\u2081 represents the set of PK values in bin i, where 0 \u2264 i \u2264 N.\n$P(X_i) = \\frac{|X_i|}{\\sum_{i=0}^{N} |X_i|}$                    (1)"}, {"title": "3.3.2 Local Gaussian Distribution", "content": "For each X\u2081 bin, we define a Gaussian distribution X\u2081 as denoted in Equation 2 with mean and standard deviation\ncomputed from Xi bin.\n$\\Chi_i \\sim N(\\mu(X_i), \\sigma^2 (X_i))$                      (2)\nOnce a bin X; is chosen randomly from the discrete PDF (Equation 1), we then sample and return noise from the local\nbin Gaussian distribution \u0178\u00a1. DLGN noise better resembles the prior distribution compared to Gaussian or uniform\nnoise models, so training the model is faster."}, {"title": "3.4 Pharmacokinetic Datasets", "content": "All PK datasets are collected from TDCommons [27]. We select PK datasets suitable for regression from the absorption,\ndistribution, metabolism, and excretion (ADME) and Toxicity categories.\nCaco-2 [53] is an absorption dataset containing rates of 906 drugs passing through the Caco-2 cells, approximating the\nrate at which the drugs permeate through the human intestinal tissue. Lipophilicity [59] is an absorption dataset that\nmeasures the ability of 4,200 drugs to dissolve in a lipid (e.g. fats, oils) environment. AqSolDB [47] is an absorption\ndataset that measures the ability of 9,982 drugs to dissolve in water. FreeSolv [35] is an absorption dataset that measures\nthe experimental and calculated hydration-free energy of 642 drugs in water.\nPlasma Protein Binding Rate (PPBR) [56] is a distribution dataset of percentages for 1,614 drugs on how they bind\nto plasma proteins in the blood. Volume of Distribution at steady state (VDss) [34] is a distribution dataset that\nmeasures the degree for 1,130 drugs on their concentration in body tissue compared to their concentration in blood.\nHalf Life [38] is an excretion dataset for 667 drugs on the duration for the concentration of the drug in the body to be\nreduced by half. Clearance [13] is an excretion dataset for around 1,050 drugs on two clearance experiment types,\nmicrosome and hepatocyte. Drug clearance is defined as the volume of plasma cleared of a drug over a specified time\n[27].\nAcute Toxicity (LD50) [60] is a toxicity dataset that measures the most conservative dose for 7,385 drugs that can lead\nto lethal adverse effects. hERG Central [15] is a toxicity dataset that measure the blocking of Human ether-\u00e0-go-go\nrelated gene (hERG) for 306,893 drugs. hERG is crucial for the coordination of the heart's beating. hERG contains\npercentages inhibitions at 1\u03bc\u039c and 10\u03bc\u039c."}, {"title": "3.5 Data Processing", "content": "We first merge all 10 PK datasets to create a unified dataset containing 30K drugs over 12 unique PK columns for\ntraining and testing (90%/10% split) our models. Excluding the hERG dataset from which we sample 7.9K drugs, we\nmerge the remaining 9 PK datasets for 22.1K unique drugs. We arrive at a total of 30K drugs in our unified dataset\nafter merging the 7.9K drugs sampled from hERG into our 22.1K unique drugs from the other 9 PK datasets. We only\nsample 7.9K drugs from hERG to maintain balance in the unified dataset given the size imbalance of hERG compared\nto the other 9 PK datasets. After removing outliers (Q1 \u2013 1.5IQR lower and Q3 + 1.5IQR upper bound), we are\nleft with 28,397 drugs from the original 30K drugs. The 28,397 drug values for each of the 12 PK columns are then\nmin-max scaled between the range of [-1,1]. Before infilling null values using one of the average, uniform or Gaussian\ndistributions, or the proposed DLGN method, we store the null masks for each drug for the masked loss function."}, {"title": "4 Experiments", "content": "Below we describe model training details and compare our synthetic data to real data, in terms of machine learning\nefficiency (MLE) and univariate and bivariate statistical distributions. We then discuss ablation studies and key findings.\nMetrics for MLE, univariate, and bivariate evaluations are further defined in their respective subsections."}, {"title": "4.1 Training Details", "content": "We train a 19M parameter model for S2PK synthesis. Model hyperparameters were not optimized and are described in\nTable 2. We do not find overfitting to be an issue. For classifier-free guidance, we joint-train unconditionally via dropout\nzeroing out sections of the SMILES embeddings with 10% probability for all of our models. For the machine learning\nefficiency, and univariate and bivariate distribution analysis, we utilize DeBERTa embeddings trained on PubChem and\nDLGN for infilling and as the noise model. We compare our model configuration to other possible configurations in the\nablation experiments. All experiments were conducted using a single NVIDIA GeForce RTX 3090 GPU."}, {"title": "4.2 Machine Learning Efficiency", "content": "Using the trained S2PK model, we generate synthetic PK target properties for 3K ligands selected from our test dataset.\nThe generated synthetic data, containing 3K ligands with all 12 target properties, can be used to augment real data for\nresearch requiring data spanning these target properties. Given the smaller size of real target property datasets, 3K\nsynthetic target property ligands provide meaningful augmentations to the real data.\nMachine Learning Efficiency (MLE) is a measure that assesses the ability of the synthetic data to replicate a specific\nuse case [6, 7, 10]. MLE represents the ability of the synthetic data to replace or augment real data in downstream use\ncases. To measure MLE, two models are trained separately using synthetic versus real data, and then their performance,\nmeasured by mean-squared error, R2, and Pearson correlation coefficient, is evaluated on real data test sets and\ncompared."}, {"title": "4.3 Univariate Distributions", "content": "The generated synthetic data closely matches that of the real data; see Figure 2. Hellinger distance (HD) quantifies\nthe similarity between two probability distributions and can be used as a summary statistic of differences for each PK\ntarget property between real and synthetic datasets. Given two discrete probability distributions P = {P1, P2, \u2026, Pn}\nand Q = {91, 92, ..., qn}, the HD between P and Q is expressed in Equation 3.\n$HD^2(p,q) = \\frac{1}{2}\\sum_{i=1}^{n}(\\sqrt{P_i} - \\sqrt{q_i})^2$         (3)\nWith scores ranging between 0 to 1, HD values closer to 0 indicate smaller differences between real and synthetic data\nand are thus desirable. Figure 3 shows the HD values for our synthetic data compared to real data with the average HD\nbeing 0.15."}, {"title": "4.4 Bivariate Distributions", "content": "In addition to univariate comparisons, synthetic PK target properties can be compared to real data in terms of bivariate\npairwise distributions and correlations. Bivariate pairwise scatterplots and Differential Pairwise Correlations (DPC) are\nshown in Figure 4. Many pairwise combinations of PK target properties have very few overlapping real data values, and\npairwise combinations with fewer than 100 examples have their cardinality numbered in the heatmaps in Figure 4. We\nomit DPC values for pairwise combinations with cardinality less than 10.\nIn combination with univariate HD, DPC provides a multivariate metric for evaluating the quality of synthetic data\nwhen compared to real data. We define the DPC as the absolute difference between the bivariate correlation coefficient\nof real and synthetic data as shown in Equation 4.\n$\\Delta CV_{cont_{XY}} = |\\rho_{XY_r} - \\rho_{XY_s}|$   (4)\nwhere X and Y denote the two continuous variables, whereas $\\rho_{XY}$ is the correlation coefficient for X and Y. If the\nreal and synthetic PK target property datasets are highly similar (i.e., the synthetic dataset closely resembles the real\ndataset), then the absolute difference would be close to 0 or very small. Heatmap (b) in Figure 4 shows DPC on the\nPearson correlation coefficient (PCC). The average DPC for PCC is 0.123. Heatmap (c) in Figure 4 shows DPC on the\nSpearman correlation coefficient (SCC). The average DPC for SCC is 0.138. These results indicate that the generated\nsynthetic PK target properties resemble real data in pairwise correlations.\nMany pairwise combinations of the real data have a small cardinality of < 100. As such, our synthetic PK target\nproperties can benefit those pairwise combinations the most: researchers can augment pairwise real datasets with\nsmall cardinality to better answer pairwise target property research questions. Compared to pairwise target properties,"}, {"title": "4.5 Ablation Studies", "content": "We conduct ablation studies to investigate the performance of our S2PK model given different SMILES encoders,\nencoder training sets, and sampling approaches for the infilling and noise model. Ablation study results (Table 4) are\naveraged over 30 generated synthetic target property datasets, covering 90K target property values for ligands, for each\nablation training run. Figure 5 graphs MSE between real and synthetic data generated during training for ablation\nexperiments. From our ablation studies, we motivate our selected model configuration."}, {"title": "4.5.1 Pre-trained SMILES Encoder", "content": "We select different pre-trained SMILES encoders and pretraining datasets for ablation. Among encoder models,\nDeBERTa performs the best in terms of average HD and synthetic and real data MSE. Among encoder training datasets,"}, {"title": "4.5.2 Discrete Local Gaussian Noise Model", "content": "We select different infilling strategies and noise models for ablation. Comparing noise model ablations, we measure the\naverage MSE that each method injects into the data with Gaussian (1.19), uniform (0.53), and DLGN (0.29) ordered\nfrom most to least. This confirms that DLGN injects noise closely resembling the prior distribution. Similarly, we\nconfirm DLGN has the best HD compared to Gaussian and uniform noise models. Comparing infilling ablations, DLGN\nhas the best overall performance in HD and synthetic and real data MSE. This motivates the choice of DLGN for\nboth infilling and noise models for our selected model configuration. In future work, we will explore additional noise\ntechniques, such as quantile transformations."}, {"title": "5 Conclusions", "content": "The SMILES-to-Pharmacokinetic model Imagand generates synthetic PK target property data that closely resembles real\ndata in univariate and bivariate distributions and for downstream tasks. Imagand provides a solution for the challenge of\nsparse overlapping PK target property data, allowing researchers to generate data to tackle complex research questions\nand for high-throughput screening. Future work will expand Imagand to categorical PK properties, and scale to more\ndatasets and larger model sizes."}]}