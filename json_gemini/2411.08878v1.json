{"title": "A Short Note on Evaluating RepNet for Temporal Repetition Counting in Videos", "authors": ["Debidatta Dwibedi", "Yusuf Aytar", "Jonathan Tompson", "Pierre Sermanet", "Andrew Zisserman"], "abstract": "We discuss some consistent issues on how RepNet has been evaluated in various papers. As a way to mitigate these issues, we report RepNet performance results on different datasets, and release evaluation code and the RepNet checkpoint to obtain these results. Code URL: https://github.com/google-research/ google-research/blob/master/repnet/", "sections": [{"title": "1. Introduction", "content": "This note is related to evaluating the class-agnostic repetition counting model RepNet [1] on various video repetition counting datasets.\nIn many papers [2, 5, 6, 8] it has been reported that performance of RepNet on some repetition counting datasets is deficient. The first time this was reported was in the TransRAC [2] paper. However, the model referred to as 'RepNet' in that paper is a modified version of RepNet. In Section 5.3 of [2], it is mentioned that \"... for a fair comparison, we modify the last fully connection layer of RepNet [1] to make it capable of handling those videos containing more than 32 action periods\u201d. It is unclear what this modification is exactly but it leads to the modified RepNet's performance being close to 0 in the Off-by-One Accuracy (OBOA) metric on the UCFRep and RepCount datasets. These results imply that the modified model is not able to count repetitions in the videos of these datasets. The papers that follow TransRAC have reused the numbers reported in TransRAC but refer to this modified model as RepNet.\nWe would like to highlight that the original RepNet model is capable of making predictions of higher than 32 period length. This is achieved by playing the video at different speeds, rather than modifying the model. This technique is described in the original RepNet paper [1] as Multi-speed Evaluation (Section 3.5). This was used for evaluating on the Countix dataset as well and has been proposed before in [4]. When we evaluate the RepNet model using the multi-speed technique on the UCFRep and RepCount datasets, we find that it results in strong performance."}, {"title": "2. Evaluation Results", "content": "We first define the evaluation metrics, and then report the performance of the original RepNet model on the following datasets: Countix, UCFRep and RepCount-A."}, {"title": "2.1. Evaluation metrics", "content": "Consider an evaluation dataset consisting of N videos where $c_i$ is the ground truth count of the $i^{th}$ video and $\\hat{c_i}$ is the predicted count of the $i^{th}$ video. Using the above, we define the commonly used metrics as follows:\nOff-by-one Accuracy (OBOA):\nOBOA = $\\frac{1}{N} \\sum_{i \\in N} 1(|c_i - \\hat{c_i}| \\le 1)$.\nNote that the original RepNet paper [1] reports OBOE (off-by-one error) which is mathematically equal to 1.0 - OBOA.\nMean Absolute Error (MAE):\nMAE = $\\frac{1}{N} \\sum_{i \\in N} \\frac{|c_i - \\hat{c_i}|}{(a + c_i)}$.\nIn RepNet [1] a = 0 is used. However, the TransRAC codebase [2] uses a = 0.1 [3]. This usage of a = 0.1 has been followed by [8] in their implementation as well [9]. This is to ensure that a divide by 0 problem does not happen for videos without any repetition. However, this is different from the metric used in earlier papers [1, 4, 7]. We advise caution to others using this metric to keep the extra 0.1 in mind while reporting their performance to have a fair comparison with other methods. We explicitly mention the value of a when reporting the metric in this paper."}, {"title": "2.2. RepNet counting performance", "content": "Countix. For the repetition counting task in the Countix dataset, the videos are segmented out into the start and end of the entire repeating segment. The task of the model is to"}, {"title": "3. Conclusion", "content": "We have released the code and checkpoints for RepNet. We hope this will clear up any confusion about RepNet evaluation. However, this re-evaluation raises the question of what modern methods and larger backbones have brought to video repetition counting methods. In particular, a 2020 model trained with ResNet-50 backbone evaluated at 112 \u00d7 112 resolution still has strong performance. We hope that the community can use the released models to further improve repetition counting methods."}, {"title": null, "content": "\u010ci = $\\frac{1(\\sqrt{(p_i \\times l_i)} > T)}{l_i}$"}]}