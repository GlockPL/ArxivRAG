{"title": "Explaining k-Nearest Neighbors: Abductive and Counterfactual Explanations", "authors": ["Pablo Barcel\u00f3", "Alexander Kozachinskiy", "Miguel Romero Orth", "Bernardo Subercaseaux", "Jos\u00e9 Verschae"], "abstract": "Despite the wide use of k-Nearest Neighbors as classification models, their explainability properties remain poorly understood from a theoretical perspective. While nearest neighbors classifiers offer interpretability from a \u201cdata perspective\", in which the classification of an input vector x is explained by identifying the vectors 01,..., \u014ck in the training set that determine the classification of x, we argue that such explanations can be impractical in high-dimensional applications, where each vector has hundreds or thousands of features and it is not clear what their relative importance is. Hence, we focus on understanding nearest neighbor classifications through a \u201cfeature perspective\u201d, in which the goal is to identify how the values of the features in x affect its classification. Concretely, we study abductive explanations such as \"minimum sufficient reasons\u201d, which correspond to sets of features in x that are enough to guarantee its classification, and counterfactual explanations based on the minimum distance feature changes one would have to perform in x to change its classification. We present a detailed landscape of positive and negative complexity results for counterfactual and abductive explanations, distinguishing between discrete and continuous feature spaces, and considering the impact of the choice of distance function involved. Finally, we show that despite some negative complexity results, Integer Quadratic Programming and SAT solving allow for computing explanations in practice.", "sections": [{"title": "Introduction", "content": "Nearest Neighbor classification. k-Nearest Neighbor (k-NN) classification is one of the most widely used supervised learning techniques [14]. In k-NN classification, we assume a set of points S over a metric space, where each point has already been labeled as either positive or negative. Then, a new point x is classified as either positive or negative by taking the majority label of its k closest neighbors in S. The study of k-NN classification has been a recurring focus in the data management community, encompassing extensive research on its behavior in high-dimensional spaces [13,31,57] and its properties when dealing with uncertain data [1,2,22]. Considerable effort has also been directed toward the development of efficient algorithms and data structures to enable scalable NN queries [3,54]. As of late, k-NN has also become key to several search and retrieval problems in vector databases [41]. For example, in Retrieval-Augmented Generation (RAG) systems, the goal is to identify the most relevant sections of a document for a given query. This is achieved by performing a nearest-neighbor query within a textual-embedding space."}, {"title": "Formal explainability.", "content": "Emerging data-driven applications, particularly those leveraging machine learning systems, are introducing new demands on classification methods. One of the most critical requirements is explainability: in many high-stakes applications, it is not enough for classifiers to be accurate; they must also provide clear and understandable explanations for their decisions [7]. A significant milestone in this field has been the development of formal frameworks for explainability. The advantages of adopting such a principled approach have been comprehensively outlined in a recent survey [49]. Two prominent examples of this methodology are:\n\u2022 Abductive explanations: These aim to identify a small subset of components in the input x that is sufficient to justify the classifier's output for x [18,36,52]. More formally, an abductive explanation for x with respect to a given classifier is a subset X of the components of x such that every input \u1ef3 that coincides with x over the components in X is classified in the same way by the classifier. Abductive explanations are also called sufficient reasons [56]. One then aims to find sufficient reasons for \u1eeb that are minimum in terms of their cardinality.\n\u2022 Contrastive explanations: These focus on the robustness of a classification, examining how much a given point x must be altered to change the output of the classifier [8,25]. More formally, a contrastive explanation at distance p from x, with respect to a given classifier, is another input \u04ef such that $||x \u2212\u1ef3 || \u2264 p$ and \u0177 is classified differently from x."}, {"title": "Why feature-based explanations for k-NNs?", "content": "Traditionally, k-NN models are considered \"self-interpretable\" because they identify a subset of training data that determines a new input's classification [50]. However, this view is overly simplistic, as interpretability depends on whether individual instances and their features are understandable [45,50]. In high-dimensional settings, the k nearest neighbors may already be too complex for direct human interpretation. Similar challenges arise in other classifiers like decision trees, often viewed as \"self-interpretable\". This has spurred research into concise, feature-based explanations\u2014such as abductive and counterfactual ones [37]. As the next example shows, applying this approach to NN classification yields meaningful insights."}, {"title": "Context.", "content": "The algorithmic aspects of computing abductive and counterfactual explanations for ML models have garnered significant attention in recent years [4\u20136,9\u201311,15,17,30,33\u201335,38-40,46\u201348,56,58]. These efforts have explored the computational cost of generating explanations across various ML models, including decision trees, binary decision diagrams, Bayesian networks, neural networks, and graph-based classifiers. Surprisingly, despite the foundational importance of k-NN in machine learning and data management, the literature on explainability for k-NN classifiers remains sparse. The few existing works primarily adopt operational approaches, leveraging mixed integer programming and constraint programming techniques to solve relevant explainability problems [24,43]. However, the theoretical complexity of computing explanations for k-NN models remains an unexplored question, which constitutes a critical gap in the field. In particular, we do not know which of these problems are computationally intractable, and thus can only be approached by applying modern solvers technology for satisfiability or integer programming problems."}, {"title": "Our contributions.", "content": "We perform an analysis of the complexity of checking and computing explanations for k-NN classifiers in two common settings: (a) the continuous setting, where points are vectors of real numbers, and the distance is based on the $l_p$-norm for some integer $p > 0$, and (b) the discrete setting, where points are Boolean vectors, and the Hamming distance is used."}, {"title": "Definitions", "content": "Basics. We consider pairs of the form (M, D), called metric space families, in which M is a set and D = {dn |\nn > 0} satisfies that $d_n : M^n \u00d7 M^n \u2192 R$ is a metric (often referred as distance) on M\u201d, for every n > 0. Elements in $M^n$ are called vectors, and are typically denoted as \u012b, \u04ef, \u017e. For i \u2208 {1, ..., n}, we write x[i] to denote the ith component of vector x.\nMetric spaces studied in the paper. In this article, we focus on two particular cases for the metric space families of the form (M, D):\n\u2022 Continuous case: Here M = R and D = {dn | n > 0} satisfies that there exists an integer p > 0 such that the distance dn is the one based on the $l_p$-norm over R\u201d, for every n > 0. In this particular case, we denote D as Dp.\n\u2022 Discrete case: Here M = {0,1} and D = {dn | n > 0} satisfies that dn is the Hamming distance on {0,1}\u201d. That is, if \u012b, \u04ef \u2208 {0, 1}\u201d, then dn(x, \u1ef9) is the number of components i\u2208 {1, ..., n} for which x[i] \u2260 y[i]. In this case, we denote D as DH.\nNearest neighbor classification. We fix a metric space family (M, D) as defined above. Let k be a fixed odd integer. Consider two subsets S+ and S\u00af of M\u201d, for n > 0, where vectors in S+ represent positive examples, and vectors in S\u00af represent negative examples. For the pair (M, D), we aim to construct a k-Nearest Neighbor (k-NN) classification function\n$f_{S^+,S^-}^k : M^n \u2192 {0,1}$,\nsuch that $f_{S^+,S^-}^k(x) = 1$ if and only if the majority of the k closest points to x in S+ US\u00af are positive. However, the set of k closest points may not always be uniquely defined, as multiple points can have the same distance from x. To address this, we define $f_{S^+,S^-}^k(x) = 1$ if and only if there is a subset T \u2286 S+ US\u00af of size k such that the majority of points of T belong to S\u207a and $d_n(x,y) \u2264 d_n(x,z)$ for all \u04ef \u2208 T and \u017e \u2208 (S+ U S\u00af) \\ T. This approach is sometimes referred to as an optimistic view of k-NN classification, as it favors sets that classify x as positive when there is ambiguity in the selection of k closest points [16]. In some proofs we use the following characterization of the optimistic k-NN classification function, which is immediate from the definition:\nProposition 1. (a) We have $f_{S^+,S^-}^k(x) = 1$ if and only if there exist $A \u2286 S^+$ of size (k + 1)/2 and $B \u2286 S^-$ of size at most (k \u2013 1)/2 such that $d_n(x,\u0101) \u2264 d_n(x, \u0109)$ for every \u0101 \u2208 A and \u0109 \u2208 $S^- \\ B$.\n(b) We have $f_{S^+,S^-}^k(x) = 0$ if and only if there exist $A \u2286 S^-$ of size (k + 1)/2 and $B \u2286 S^+$ of size at most (k \u2013 1)/2 such that $d_n(x, \u0101) < d_n(x, c)$ for every \u0101 \u2208 A and \u0109 \u2208 $S^+ \\ B$."}, {"title": "Problems", "content": "We consider a metric space family (M, D) with D = {dn | n > 0}. We present the different sorts of explanation studied in this paper and their associated decision problems."}, {"title": "Abductive explanations", "content": "Consider an input vector x \u2208 M\u201d. The goal in this case is to find a set X of components over {1, . . ., n} that suffice to explain the output of the k-NN classification function $f_{S^+,S^-}^k$ on x. Intuitively, this means that every input vector \u04ef that coincides with x over the components in X is classified in the same way by $f_{S^+,S^-}^k$. We formalize these ideas next using the well-known notion of sufficient reason.\nFix an odd integer k \u2265 1. Consider then two sets S+,S\u00af \u2286 M\u201d and an input vector x \u2208 M\u201d. Let X \u2286 {1, ..., n}. We call X a sufficient reason for x with respect to $f_{S^+,S^-}^k$, if\n$f_{S^+,S^-}^k(x) = f_{S^+,S^-}^k(y)$, for every \u04ef \u2208 M\u201d that satisfies x[i] = \u04ef[i], for each i \u2208 X.\nThe most basic decision problem in this case is verifying if an X \u2286 {1, ..., n} is in fact a sufficient reason for x. This leads to the following problem.\nPROBLEM: k-CHECK SUFFICIENT REASON(M, D)\nINPUT: Two sets S+, S\u00af \u2286 M", "M": "an X \u2286 {1,..., n}\nOUTPUT: Yes, if X is a sufficient reason for \u012b with respect to $f_{S^+,S^-}^k$\nNot all sufficient reasons are equally informative. For instance, X = {1, . . ., n} is always a sufficient reason for x, but arguably a very uninformative one. It is then natural to look for minimum sufficient reasons, that is, sufficient reasons that are as small as possible in terms of their cardinality. This is formalized by the next decision problem.\nPROBLEM: k-MINIMUM SUFFICIENT REASON(M, D)\nINPUT: Two sets S+, S\u00af \u2286 M\u201d, a vector x \u2208 M\u201d, an integer l > 0\nOUTPUT: Yes, if there is a sufficient reason X for x w.r.t. $f_{S^+,S^-}^k$ with |X| \u2264 l\nWhen the problem of checking minimum sufficient reasons is computationally hard, one might be satisfied with finding a minimal one, i.e., one that does not properly contain another sufficient reason. Formally, if X is a sufficient reason for\u012b with respect to $f_{S^+,S^-}^k$, then X is minimal if there is no sufficient reason Y for x with respect to $f_{S^+,S^-}^k$ that satisfies $Y \u2286 X$. Clearly, every minimum sufficient reason is also minimal, but the converse does not hold in general as shown next.\nIt is easy to observe that a greedy strategy turns a polynomial time algorithm for k-CHECK SUFFICIENT REASON into a polynomial time algorithm for k-MINIMAL SUFFICIENT REASON.\nProposition 2. For any k, M, D, the k-MINIMAL SUFFICIENT REASON(M, D) problem reduces in polynomial time to k-CHECK SUFFICIENT REASON(M, D).\nProof. If a set is a sufficient reason, then all its supersets are. Hence, to decide if X \u2286 {1, ..., n} is a minimal sufficient reason, it suffices to check if X is a sufficient reason, and then check, for each subset X \\ {i} obtained by removing one element i \u2208 X, that X \\ {i} is not a sufficient reason."}, {"title": "Counterfactual explanations", "content": "These are explanations that aim to find what should be changed from an input vector x in order to obtain a different classification outcome. Typically, one aims to find counterfactual explanations that are not \u201ctoo far\u201d from \u1eeb, which is formalized by saying that the distance between x and its counterfactual explanation is bounded.\nFix an odd integer k \u2265 1. Given sets S+,S\u00af \u2286 M\u2033 and x \u2208 M\u201d, a counterfactual explanation for x with respect to $f_{S^+,S^-}^k$ is a vector \u04ef \u2208 M\" with $f_{S^+,S^-}^k(x) \u2260 f_{S^+,S^-}^k(\u1ef9)$. We look for counterfactual explanations that are close to the vector \u1eef. This leads to the following decision problem.\nPROBLEM: k-COUNTERFACTUAL EXPLANATION(M, D)\nINPUT: Two sets S+, S\u00af \u2286 Mn, a vector x \u2208 Mn, a rational l > 0\nOUTPUT: YES, if there is a counterfactual explanation \u04ef for x with respect to $f_{S^+,S^-}^k$ such that $d_n(x, y) \u2264 l$\nThus, COUNTERFACTUAL EXPLANATION asks whether it is possible to find a vector \u04ef that is relatively close to x and that is classified differently than x under $f_{S^+,S^-}^k$. For instance, in the discrete case this asks if it is possible to \"flip\u201d the classification of x by \u201cflipping\" at most l of its components."}, {"title": "Computation problems", "content": "For simplicity, we focus our complexity analysis on the decision problems introduced above. However, in the context of explainable AI, it is, of course, more important to compute an optimal explanation (if one exists). Our study, however, also sheds light on the computational problem. In fact, as shown in the explainability literature, the hardness of a decision problem often implies hardness for its associated computation problem [5]. Conversely, the tractability of a decision problem often implies that the associated computation problem can be solved in polynomial time. In this paper, we show that all our tractability results extend from decision to computation."}, {"title": "Minimum Sufficient Reasons", "content": "In this section, we show that k-MINIMUM SUFFICIENT REASON is NP-hard for both the continuous and the discrete setting, for every odd integer k \u2265 1. In the continuous case, hardness holds regardless of the norm being used."}, {"title": "Theorem 1.", "content": "The following statements hold:\n1. The problem k-MINIMUM SUFFICIENT REASON(R, Dp) is NP-hard, for every fixed odd integer k \u2265 1 and integer p > 0.\n2. The problem k-MINIMUM SUFFICIENT REASON({0, 1}, DH) is NP-hard, for every fixed odd integer k \u2265 1.\nProof. We start by proving (1), and then derive (2) by a modification of the proof. We reduce from the well-known NP-complete Vertex Cover problem: given an undirected graph G = (V, E), and an integer l \u2265 0, check whether there is a vertex cover C in G of size |C| \u2264 l. Recall that a vertex cover is a subset of nodes CC V such that every edge in E has an endpoint in C.\nGiven an instance of Vertex Cover, we construct an instance of the problem k-Minimum SUFFICIENT REASON(R, Dp) as follows. Assume that V = {1, ..., n} and E = {e1,..., em }, for n, m \u2265 1. Suppose that n is the vector dimension, and take x = (0, . . ., 0) \u2208 R\". Choose (k + 1)/2 numbers such that 1/2 > \u00a31 > \u2026> E(k+1)/2 > 0. For each j\u2208 {1, ..., m}, and h \u2208 {1, ..., (k + 1)/2}, we define the vector \u0177j,h \u2208 R\" such that\n\u0178j,h[i] = 1 + \u025bn if ej is incident to the vertex i, and \u04efj,h[i] = 0, otherwise. We also define:\n$S^\u00ae = {\u1ef9j,h|j\u2208 {1, ..., m}, h \u2208 {1, ..., (k + 1)/2}}.$ \nFor \u00ffj,h, we denote by \u00ff, and \u1ef9,n, the vectors obtained from \u0177j,\u0127 by changing the first and second component 1 + \u025bh, respectively, by \u025bh, and keeping the remaining vector components unchanged. We finally define:\n$S+ = \u222a{Y},n' Y}}.$ \nNote that $f_{S^+,S^-}^k(x) = 1$, as for every \u00ff,(k+1)/2 \u2208 S+ and \u1ef9j',h \u2208 S\u00af:\n$||y_(k+1)/2||_p = k+1)/2 + (1 + (k+1)/2)^p < 2(1 + \u00a3n)^p = ||\u04efj',h||_p.$\nWe claim that there is a vertex cover C with |C| \u2264 l if and only if there is a sufficient reason X for x with respect to $f_{S^+,S^-}^k$ such that |X| < l. Suppose first there is such a vertex cover C C {1,..., n}. We show that C is a sufficient reason. Let \u017e\u2208 R\" be an arbitrary vector such that \u017e[i] = x[i] = 0, for all i \u2208 C. We show that there is an inyective function g : S\u00af \u2192 S+ such that for every \u04ef \u2208 S\u00af, we have $||\u017e \u2013 \u0177|| > ||\u017e \u2013 g(y)||_p$, and hence $f_{S^+,S^-}^k(z) = 1$ as required. Let \u00ffj,h \u2208 S\u00af. Since C is a vertex cover, one of the endpoints of ej is in C and then there is i \u2208 C such that \u0177j,h[i] = 1 + \u025bh. Pick one such i, and define g(\u04efj,h) \u2208 S\u207a as the vector resulting from \u00ffj,h by changing \u0177j,h[i] to \u025bh. The function g is inyective:\n\u2022 for \u00ffj,h, \u0177j',h' \u2208 S\u00af with j \u2260 j', we have g(\u04efj,h) \u2260 g(\u04efj',h') as their non-zero components differ; and\n\u2022 for \u00ffj,h, \u0177j,h' \u2208 S\u00af with h \u2260 h', we have g(\u04efj,h) \u2260 g(\u1ef9j,h') as \u025bh \u2260 Eh'\u2022\nSince \u0177j,h and g(\u1ef9j,h) only differ in one component i \u2208 C, we have\n$||\u017e \u2013 \u0177j,h|| > ||\u017e - g(\u1ef9j,h)||_p$\u2194 $|\u017e[i] \u2013 (1 + \u025bn)| > |\u017e[i] \u2013 \u025bn|^p\u2194 (1 + \u03b5\u03b7)^p > \u03b5_h^p$\nand then g satisfied the required conditions.\nAssume now that X \u2286 {1,..., n} is a sufficient reason with |X| \u2264 l. We show that X is a vertex cover of G. By contradiction, suppose there is an edge ej \u2208 E whose endpoints are not in X. Then the vector \u00ffj,1 satisfies that \u0177j,1[i] = x[i] = 0 for all i \u2208 X. We claim that $f_{S^+,S^-}^k(\u04efj,1) = 0$, which is a contradiction. This follows from the fact that $||\u012aj,1 \u2013 Yj,h|| < ||\u016aj,1 \u2212 \u04ef, ll_p$, for every h \u2208 {1,..., (k + 1)/2} and \u1ef9, \u2208 S+.\nIndeed, since y,h' contains at most one component with value 1 + \u025bh', and yj,1 has two components with value 1 + 81, we have:\n$||Yj.1 - Y_||_p \u2265 (1 + 1 \u2212 \u03b5\u2019)^p \u2265 1 \u2265 (\u00bd)^p > 2(\u20ac1 \u2212 En)^p = ||\u012aj,1 \u2013 Yj,h||_p.$"}, {"title": "This finishes the proof of (1).", "content": "We prove the remaining discrete case (2). We first consider the case k = 1. The proof follows the same strategy than in the continuous case (1). Again we reduce from the Vertex Cover problem: given an undirected graph G = (V, E), and an integer l \u2265 0, check whether there is a vertex cover C in G of size |C| \u2264 l.\nGiven an instance of Vertex Cover, we construct an instance of the problem 1-MINIMUM SUFFICIENT REASON({0, 1}, DH) as follows. Assume that V = {1, ..., n} and E = {e1,...,em}, for n,m \u2265 1. Suppose that n is the vector dimension, and take x = (0,...,0) \u2208 {0,1}\". For each j\u2208 {1, ...,m}, we define the vector \u1ef9; \u2208 {0,1}\" such that \u1ef9j[i] = 1 if ej is incident to the vertex i, and \u1ef9j[i] = 0, otherwise. We define S\u00af = {\u1ef9j | j\u2208 {1,...,m}}. For \u1ef9j, we denote by \u00ff and \u1ef9, the vectors obtained from \u00ffj by flipping the first and second component with value 1, respectively, to 0, and keeping the remaining vector components unchanged. We finally define S+ = U\u00a1{\u1ef9}, }. Note that $f_{S^+,S^-}^1(x) = 1$, as d\u2081(x, y) = 1 for every \u04ef \u2208 S+,\nwhile d\u2081(x, y) = 2 for every \u04ef \u0454\u0405\u00af.\nWe claim that there is a vertex cover C with |C| \u2264 l if and only if there is a sufficient reason X for x with respect to $f_{S^+,S^-}^1$ such that |X| \u2264 l. Suppose first there is such a vertex cover C \u2286 {1,...,n}. We show that C is a sufficient reason. Let \u017e\u2208 {0,1}\" be an arbitrary vector such that \u017e[i] = x[i] = 0, for all i \u2208 C. We show that for every \u04ef \u2208 S\u00af, there exists \u1ef9' \u2208 S\u207a, such that d\u0124(\u017e, \u1ef9) > d\u00ed(\u017e, \u04ef\u2032), and hence $f_{S^+,S^-}^1(z) = 1$ as required. Let \u00ffj \u2208 S\u00af. Since C is a vertex cover, one of the endpoints of ej is in C and then there is i \u2208 C such that \u1ef9j[i] = 1. Pick one such i, and define \u00ff \u2208 S+ as the vector resulting from \u1ef9j by flipping \u1ef9j[i] to 0. Since \u00ffj and \u00ff only differ in one component i \u2208 C, we have\nd\u00ed(\u017e, \u1ef9j) > d\u00ed(\u017e, \u1ef9;)\u2194 [\u017e[i] \u2013 \u0177j[i]] > [\u017e[i] \u2013 \u00ff;[i]|\u2194 1 > 0\nand then the condition holds.\nAssume now that X \u2286 {1, ..., n} is a sufficient reason with |X| \u2264 l. We show that X is a vertex cover of G. By contradiction, suppose there is an edge ej \u2208 E whose endpoints are not in X. Then the vector \u0177j satisfies that \u0177j[i] = x[i] = 0 for all i \u2208 X. As \u0177j \u2208 S\u00af, it follows that $f_{S^+,S^-}^1(\u04efj) = 0$, which is a contradiction. The hardness of the case k \u2265 3 follows directly from the proof of Theorem 5 as for k \u2265 3, the problem k-CHECK SUFFICIENT REASON({0, 1}, DH) is hard, even when the input subset of components is X = 0. Hardness for k-MINIMUM SUFFICIENT REASON({0, 1}, DH) follows directly by setting the input threshold l = 0."}, {"title": "The Continuous Setting Based on the l2-distance", "content": "It turns out that in case of the l2-norm, all mentioned problems, apart from k-MINIMUM SUFFICIENT REASON, are tractable. The main reason is that in the case of the l2-norm, an inequality of the form \u201cthe point x is closer to the point \u0101 than to the point \u0113\u201d is the linear inequality in \u1eef given by $(\u0101 \u2013 \u0113)^\u00afx \u2265 (\u0101 \u2212 c)^\u00af(\u0101 + c)$. By Proposition 1, this gives a representation of the set $\\{x \u2208 R^n | f_{S^+,S^-}^k(x) = 1\\}$ as a union of at most $|S^+ U S^-|^{2k}$ many polyhedra, a polynomial in the input. These polyhedra are explicitly given, as we can describe them by a system of linear inequalities in polynomial time. Analogously, the set $\\{x \u2208 R^n | f_{S^+,S^-}^k(x) = 0\\}$ is a union of polynomially many \u201copen polyhedra\u201d, that is, sets of solutions to a system of strict linear inequalities.\nAbductive explanations We start by showing tractability of k-CHECK SUFFICIENT REASON. By Proposition 2, this implies tractability of k-MINIMAL SUFFICIENT REASON for the l2-norm, which in turn implies that minimal sufficient reasons can be computed in polynomial time in this case."}, {"title": "Proposition 3.", "content": "The problem k-CHECK SUFFICIENT REASON(R, D2), and hence also k-MINIMAL SUFFICIENT REASON(R, D2), can be solved in polynomial time for every fixed odd integer k \u2265 1.\nProof. Assume first that $f_{S^+,S^-}^k(x) = 0$. Let X \u2286 {1,...,n} and consider the affine subspace U(X,x) :=\n{y \u2208 R\" | x[i] = y[i]}. Then X is not a sufficient reason for x if and only if U(X, x) intersects the set {\u04ef \u2208 R\" | $f_{S^+,S^-}^k(\u04ef) = 1$}. By Proposition 1, this set is a union of polynomially many polyhedra. It remains to check if our affine subspace intersects one of these polyhedra. The ntersection of an affine subspace and a polyhedron is a polyhedron, and checking emptiness of a polyhedron is equivalent to linear programming which thus can be done in polynomial time [55].\nIn the case $f_{S^+,S^-}^k(x) = 1$, we have to check, whether our affine subspace intersects the set {\u1ef9 \u2208 R\" |\n$f_{S^+,S^-}^k(y) = 0$}. This time, by Proposition 1, this set is a union of sets of solutions to systems of strict linear inequalities. The same argument as in the previous case reduces our problem to the emptiness problem for an intersection of an affine subspace with an open polyhedron. The latter is just the feasibility problem for systems of linear equalities and strict linear inequalities, which can be reduced to linear programming (with non-strict inequalities), solving our problem in polynomial time. Namely, let S be a system of linear equalities and strict linear inequalities. Consider a system S of non-strict linear inequalities over variables of S and a new variable \u025b, obtained by turning every strict inequality l > 0 of S into a non-strict inequality l > \u025b. Feasibility of S is equivalent to existence of a feasible solution to S with positive \u025b. To find out if the latter is true, it is enough to find the optimal solution to the problem of maximizing & subject to S.\nAs a corollary, we obtain the following:"}, {"title": "Corollary 1.", "content": "Consider the setting (R, D2) and let k \u2265 1 be any odd integer. There is a polynomial time algorithm that, given sets S+, S\u00af \u2286 R\" and a vector x \u2208 R\", computes a minimal sufficient reason X for x with respect to $f_{S^+,S^-}^k$\nCounterfactual explanations Tractability of the k-COUNTERFACTUAL EXPLANATION problem is proved sim- ilarly to k-CHECK SUFFICIENT REASON, but this time we use polynomial-time solvability of convex quadratic programming [42]."}, {"title": "Theorem 2.", "content": "The problem k-COUNTERFACTUAL EXPLANATION(R, D2) can be solved in polynomial time for every fixed odd integer k \u2265 1.\nProof. In the k-COUNTERFACTUAL EXPLANATION(R, D2) problem, given x \u2208 R\u201d and l > 0, the goal is to check if the ball B\u2081(x) = {\u04ef \u2208 R\" | $||\u1ef3-x||_2 \u2264 l$} contains a vector with a different $f_{S^+,S^-}^k$ value than x. If $f_{S^+,S^-}^k(x) = 0$, this reduces to checking whether Be(x) intersects the set {\u04ef \u2208 R\" | $f_{S^+,S^-}^k(\u1ef9) \u2260 0$}, which, by Proposition 1, is a union of polynomially many polyhedra. Thus, the problem reduces to determining whether Be(x) intersects a given polyhedron P. This can be solved via convex quadratic programming, which minimizes a positive definite quadratic form under a system of non-strict linear inequalities and is solvable in polynomial time due to Kozlov, Tarasov, and Khachiyan [42]. Specifically, we minimize q(\u1ef9) = $||x \u2212 \u1ef9||_3$ subject to constraints defining P. The answer to k-COUNTERFACTUAL EXPLANATION(R, D2) is Yes if and only if the minimum value is at most l\u00b2, with the optimal solution providing the counterfactual explanation.\nSimilarly, when $f_{S^+,S^-}^k(x) = 1$, the problem reduces to checking whether the ball B\u2081(x) intersects a given open polyhedron, defined as the solution set to a system of strict linear inequalities. The argument from the previous paragraph requires modification because the algorithm in [42] assumes non-strict inequalities in the constraints. To address this, we first check whether P is empty, reducing the problem to linear programming as described in the proof of Proposition 3. If P is non-empty (since otherwise, there is nothing left to check), we construct a polyhedron P by converting all strict inequalities of P into non-strict ones. Note that P corresponds to the interior of P. We claim that P intersects Be(x) if and only if P intersects the interior of Be(x). The latter can be reduced to a problem of minimizing a convex quadratic objective subject to (closed) polyhedron, which in turn can be solved in polynomial time with the techniques by Kozlov, Tarasov, and Khachiyan [42]. Indeed, consider the problem of minimizing q(\u1ef9) = $||x \u2212 \u1ef9||$ subject to \u04ef \u2208 P"}, {"title": "Corollary 2.", "content": "Consider the setting (R, D2) and let k \u2265 1 be any odd integer. There is a polynomial time algorithm that, given sets S+,S\u00af \u2286 Rn, vector x \u2208 R\", and rational l > 0, it computes a counterfactual explanation for x with respect to $f_{S^+,S^-}^k$ at distance at most l in case there exists one.\nProof. The case $f_{S^+,S^-}^k(x) = 0$ is already addressed in the proof of Theorem 2. The case $f_{S^+,S^-}^k(x) = 1$ reduces to finding a point \u00ff in the intersection of the ball B\u2081(x) and an open polyhedron P, if this intersection is non-empty. If it is non-empty, then P (the closure of P) intersects the interior of Be(x) as shown in the proof of Theorem 2. We can find a point \u04ef in this intersection by minimizing the quadratic form q(y) = $||x \u2212 \u1ef3||_2$ subject to P. This point \u04ef will belong to the border of P. That is, some inequalities, defining P, turn into equalities on \u00ff. We now need to find a direction that points to the interior of P from this point. More precisely, our task is to find a vector \u1e9e such that \u3008\u03b1, \u03b2) > 0 for every inequality (a, \u04ef\u3009 \u2265 c that turns into equality on y. After such \u1e9e is found, we just need to move from \u04ef along \u1e9e by a small amount while remaining inside Be(x). Finding such \u1e9e is reducible to finding a solution to a system of strict linear inequalities. In turn, this can be reduced in polynomial time to linear programming as explained in the proof of Proposition 3."}, {"title": "The Continuous Setting Based on the l\u2081-distance", "content": "We first show that the positive results for counterfactual explanations under the l2-norm do not extend to the l\u2081-norm. For abductive explanations", "straightforward": "if a counter-factual explanation exists, it can be found as a solution to a polynomially bounded linear program. We now show the lower bound. In the appendix we show that it suffices to establish NP-hardness for k = 1. We reduce from a variation of the knapsack problem, where the goal is to determine"}]}