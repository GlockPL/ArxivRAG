{"title": "QUESTION ANSWERING FOR DECISIONMAKING IN GREEN\nBUILDING DESIGN: A MULTIMODAL DATA REASONING\nMETHOD DRIVEN BY LARGE LANGUAGE MODELS", "authors": ["Yihui Li", "Hao Zhou", "Xiaoyue Yan", "Borong Lin"], "abstract": "In recent years, the critical role of green buildings in addressing energy consumption and environmen-\ntal issues has become widely acknowledged. Research indicates that over 40% of potential energy\nsavings can be achieved during the early design stage. Therefore, decision-making in green building\ndesign (DGBD), which is based on modeling and performance simulation, is crucial for reducing\nbuilding energy costs.\nHowever, the field of green building encompasses a broad range of specialized knowledge, which\ninvolves significant learning costs and results in low decision-making efficiency. Many studies have\nalready applied artificial intelligence (AI) methods to this field.\nBased on previous research, this study innovatively integrates large language models with DGBD,\ncreating GreenQA, a question answering framework for multimodal data reasoning. Utilizing\nRetrieval Augmented Generation, Chain of Thought, and Function Call methods, GreenQA enables\nmultimodal question answering, including weather data analysis and visualization, retrieval of green\nbuilding cases, and knowledge query. Additionally, this study conducted a user survey using the\nGreenQA web platform. The results showed that 96% of users believed the platform helped improve\ndesign efficiency. This study not only effectively supports DGBD but also provides inspiration for\nAI-assisted design.", "sections": [{"title": "1 Introduction", "content": "The building industry accounts for up to 40% of global greenhouse gas emissions, making a significant contribution\nto energy consumption (Debrah et al., 2022). During the entire lifecycle of a building, the early design stage has\nthe potential to achieve over 40% energy savings (Han et al., 2018). Therefore, promoting decision-making in green"}, {"title": "2 State of the Art", "content": null}, {"title": "2.1 AI in DGBD", "content": "In recent years, artificial intelligence and machine learning have been extensively applied in the field of green building\n(Debrah et al., 2022), supporting green building design decision-making (Petroni et al., 2019; Li et al., 2024a).\nCase-Based Reasoning (CBR) methods are effective for retrieving knowledge from existing case libraries to improve\ndecision-making efficiency (Liu et al., 2024), but current databases have limitations in both quantity and quality (Li\net al., 2024a), which makes it difficult to generate precise generalizations. Various methods have been explored with\nCBR, such as nonlinear Local-Global retrieval using Artificial Neural Networks to CBR retrieval (Cheng and Ma,\n2015), text mining integration (Shen et al., 2017), and the application of CBR in building renovation (Zhao et al.,\n2019), and decision-making of building envelopes design during the preliminary design stage (Zhang et al., 2021)."}, {"title": "2.2 QA by LLMs", "content": "Among artificial intelligence methods, LLMs have demonstrated significant efficacy in handling complex natural\nlanguage understanding and generation tasks, greatly expanding the application scope of natural language processing\n(NLP) (Touvron et al., 2023; Zhao et al., 2023; OpenAI et al., 2024). These models, pretrained on large-scale datasets,\ncan generate coherent and relevant text responses, and can perform NLP tasks through zeroshot or few-shot learning\nwhen given appropriate prompts (Brown et al., 2020; Chowdhery et al., 2023).\nQuestion Answering (QA) is a core application area of NLP, aimed at providing accurate answers to user-posed\nquestions. Traditional QA systems typically rely on structured knowledge bases and complex query mappings (Chen\net al., 2017) to respond to user inquiries, requiring precise NLP techniques (Li et al., 2024b). With the development of\nLLMs, researchers have begun to explore the potential of using LLMs as knowledge bases for QA (Petroni et al., 2019),\nand to compare them with traditional knowledge-based QA models (Payne et al., 2023).\nAlthough LLM-based QA systems can perform reasoning on open-ended questions, general LLMs often lack specialized\nknowledge in the field of green building. This can lead to the generation of answers that are coherent in natural language\nbut factually incorrect (Kim et al., 2023; Zhuang et al., 2023), known as hallucination (Ji et al., 2023). This limitation\nsignificantly constrains the support that LLMs can provide in the field of green building."}, {"title": "3 Methods", "content": "This study developed the GreenQA platform, which supports knowledge retrieval and design interaction in green\nbuilding design. The technical framework of the platform is illustrated in Figure 2, and its construction is based on a\nmultimodal green building knowledge base.\nTo address various QA needs in DGBD scenarios, this study enhances the performance of LLMs in three aspects and\nrestructures the output response mechanism. First, by using Retrieval Augmented Generation (RAG) to automatically\nconnect the knowledge base and prevent hallucinations. Second, by employing Chain of Thought (CoT) to enhance\nLLMs' contextual memory and reasoning capabilities. Third, by utilizing Function Call to integrate LLMs with external\ninterfaces, based on the previous two technologies, to meet the demands of more complex data reasoning tasks and\nsupport the reading and generation of documents, images, tables, and other modalities.\nIntegrating these technical methods, an online QA platform, GreenQA, was developed on the web. A user survey was\nconducted to evaluate its performance and identify areas for improvement."}, {"title": "3.1 Knowledge Base Preparation", "content": "DGBD relies on multimodal background knowledge, encompassing technical indicators like acoustics, lighting, and\nthermal performance, which have led to the creation of numerous textbooks and standards. Globally, up to 600 green\nbuilding rating systems have been established to assess sustainability (Doan et al., 2017; Zhang et al., 2017; Awadh,\n2017). Notably, the UK's BREEAM and the US's LEED standards have been pivotal in advancing sustainable buildings.\n(Lee, 2013). Research indicates that BREEAM and LEED-certified buildings consume approximately 30% less energy\nthan non-certified buildings (Doan et al., 2017). The application of these evaluation standards has accumulated numerous\ncases and practical experiences, which can be leveraged to address DGBD challenges.\nBased on this logic, we constructed a multimodal green building knowledge base comprising four components: green\nbuilding theoretical textbooks, green building rating standard guidelines, performance simulation software manuals,\nand green building cases. The specific contents of the knowledge base are illustrated in Figure 3. The books, standards,\nand manuals are sourced from their respective official websites."}, {"title": "3.2 QA by RAG", "content": "Due to the lack of domain-specific knowledge bases in general LLMs, they tend to generate hallucinations or incorrect\nanswers when handling knowledge-intensive tasks. Relevant research has proposed the Retrieval Augmented Generation\n(RAG) method to improve the accuracy of LLMs in QA tasks (Lewis et al., 2020). In knowledge-intensive industries\nsuch as law and medicine, studies have already demonstrated the use of the RAG method to provide more accurate\nanswers with the aid of knowledge bases (Louis et al., 2024; Singhal et al., 2023). However, in the field of architecture,\na systematic database and methodology have not yet benn developed.\nTo further achieve the customized application of LLMs in assisting DGBD, this study adopts the RAG method. By\ncalculating semantic similarity, relevant information is retrieved from the external knowledge base to enhance the\nexpertise of LLMs in the field of green building, while also ensuring the timeliness of the knowledge base (Chen et al.,\n2024; Guu et al., 2020; Lewis et al., 2020).\nThe RAG method in GreenQA is based on the basic framework of indexing, retrieval, and generation (Gao et al., 2024),\nas illustrated in Figure 4. For each user query, the system reads text data stored in the knowledge base as vectors,\ncalculates the vector similarity between the user's question and the indexed resources, and then generates a response\nbased on LLM. Specifically, green building cases are stored locally as vector files through an embedding model, and\ncalculations and retrievals are then performed for each user query. This method significantly reduces the number of\ntokens required for each QA session while markedly improving response speed."}, {"title": "3.3 QA by CoT", "content": "QA tasks for DGBD often involve data reasoning processes with complex interaction logic. Single-turn QA typically\nresults in low answer accuracy for these challenging tasks (e.g., arithmetic and commonsense reasoning). Increasing the\nmodel's parameter scale does not significantly enhance performance for such tasks (Lewis et al., 2020). Therefore, we\nmust select a more appropriate technical approach.\nIn 2022, Wei et al. proposed using Chain of Thought (CoT) to solve this problem (Wei et al., 2022). CoT guides LLMs\nto break down complex tasks by constructing example prompts, significantly improving task accuracy. This study\nemploys the zero-shot CoT method, incorporating specific instructions like \"Let's think step by step\" into the prompts"}, {"title": "3.4 QA by Function Call", "content": "In real-world DGBD scenarios, EPW (EnergyPlus Weather File) files are crucial for understanding the relationship\nbetween buildings and the environment through performance simulation analysis (Crawley et al., 2008). However,\ndirectly inputting EPW files and user requests (such as \u201cPlease help me analyze this EPW weather data file.\" or \"What\ntype of buildings are suitable for the temperature and humidity in this area?\u201d) into LLMs would consume a vast\nnumber of tokens, and the probabilistic generation of direct inference results significantly reduces the credibility of data\nreasoning.\nThis study uses the Function Call feature to address the above problem. Function Call originated from agent tools in\nLLM research. In the commonly used LLM application framework LangChain (Harrison, 2022), users can create agent\nscripts based on their needs to extend the LLM's capabilities, particularly its data reasoning functions (Topsakal and\nAkinci, 2023). OpenAI's recent releases have integrated this feature into their API (OpenAI, 2023), allowing users to\ncreate a function with corresponding input and output descriptions in natural language and a real function script on\nthe back-end. When the LLM processes the user's question, it determines whether to call the function based on the\nfunction's description. We have constructed five functions to achieve rich multimodal complex interactions. Figure 7\nshows the functions' capabilities and input-output content."}, {"title": "3.5 Platform Construction", "content": "Based on the web platform, this study has developed an interactive website called GreenQA, which uses the technical\nframework shown in Figure 9 to handle user input and output information flow, enabling knowledge inference QA\nrelated to the field of green building."}, {"title": "3.6 User Study", "content": "To better understand user satisfaction and gather suggestions for platform improvement, a survey was conducted, as\ndetailed in the appendix. The questionnaire was designed to evaluate four aspects: multi-turn QA and information\ninteraction, multimodal data and information inference, the value and practicality of key functions, and changes in work\nefficiency.\nThe participants in this survey were senior undergraduate and graduate students with previous experience in building\nperformance simulation software or green building design. Before completing the questionnaire, each participant was\nrequired to use the platform in a real design scenario for 30 to 60 minutes. Scoring was based on a 5-point scale."}, {"title": "4 Result and Discussion", "content": null}, {"title": "4.1 Results of Knowledge Base Construction", "content": "The multimodal green building knowledge base has amassed over 3.8 million words of textual materials and includes\n1,200 green building cases (Figure 11). These cases span multiple countries and regions across all continents. As shown\nin Figure 12, the highlighted countries are those with the highest number of cases in each continent."}, {"title": "4.2 Results of Interactive QA", "content": "This study uses a simulated interactive case to evaluate the platform's QA results."}, {"title": "4.3 Results of Survey", "content": "Figure 14 presents the statistical results of the survey. Among the 25 collected questionnaires, users expressed an overall\nhigh level of satisfaction with the GreenQA decision support platform. They particularly appreciated the clear and\nprecise presentation of information as well as the accurate understanding of their needs. Most users found the platform\nhighly valuable for both analyzing meteorological data and retrieving building case studies. Additionally, 96.0% of\nusers reported an increase in work efficiency (scoring above 4) after using the GreenQA platform to assist with DGBD."}, {"title": "4.4 Discussion", "content": "This study also compared this platform with other platforms supporting DGBD and weather analysis, such as LEED\nDSS (Jun and Cheng, 2017), ClimaPlus (Arsano and Reinhart, 2020), and Gbuilding (Zhen, 2024). We examined the\ninput/output content of these platforms and evaluated them based on dimensions such as knowledge base data volume,\nsingle input/output response time, and response output mechanisms, as shown in Figure 15."}, {"title": "5 Conclusion", "content": "As a new paradigm of AI, LLMs are reshaping our work patterns and understanding of the world. Their interaction\ncapabilities are poised to transform design processes, with \u201cDesign with LLMs\" likely becoming the mainstream\napproach in computer-aided design in the future. However, significant issues remain, including information accuracy,\ninterpretability, and data security.\nThis study not only effectively supports DGBD but also redefines traditional design paradigms. Firstly, it establishes a\nmultimodal database containing 3.8 million words of green building knowledge and 1,200 green building cases, filling\nthe gap in large-scale multimodal databases in the field of green building. Secondly, leveraging LLMs' interactive\nabilities, the study interprets natural language instructions and provides precise responses to DGBD questions. Lastly,\nby integrating RAG, CoT and Function Call, it enables precise knowledge retrieval and data-model separation, reducing\nhallucinations and data leakage, and enhancing the professionalism of LLM-based QA in the field of green building.\nThis study also highlights future directions for the method: (1) localizing large models and expanding the knowledge\nbase, (2) optimizing interaction processes and enhancing search response speed, 3) increasing fault tolerance for user\nrequirements. This will support more complex and ambiguous design decisions, contributing to energy saving and\nsustainability in green building design."}]}