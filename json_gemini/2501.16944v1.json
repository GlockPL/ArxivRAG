{"title": "EXACT COMPUTATION OF ANY-ORDER SHAPLEY INTERACTIONS FOR GRAPH NEURAL NETWORKS", "authors": ["Fabian Fumagalli", "Maximilian Muschalik", "Paolo Frazzetto", "Janine Strotherm", "Luca Hermes", "Alessandro Sperduti", "Eyke H\u00fcllermeier", "Barbara Hammer"], "abstract": "Albeit the ubiquitous use of Graph Neural Networks (GNNs) in machine learning (ML) prediction tasks involving graph-structured data, their interpretability remains challenging. In explainable artificial intelligence (XAI), the Shapley Value (SV) is the predominant method to quantify contributions of individual features to a ML model's output. Addressing the limitations of SVs in complex prediction models, Shapley Interactions (SIs) extend the SV to groups of features. In this work, we explain single graph predictions of GNNs with SIs that quantify node contributions and interactions among multiple nodes. By exploiting the GNN architecture, we show that the structure of interactions in node embeddings are preserved for graph prediction. As a result, the exponential complexity of SIs depends only on the receptive fields, i.e. the message-passing ranges determined by the connectivity of the graph and the number of convolutional layers. Based on our theoretical results, we introduce GraphSHAP-IQ, an efficient approach to compute any-order SIs exactly. GraphSHAP-IQ is applicable to popular message-passing techniques in conjunction with a linear global pooling and output layer. We showcase that GraphSHAP-IQ substantially reduces the exponential complexity of computing exact SIs on multiple benchmark datasets. Beyond exact computation, we evaluate GraphSHAP-IQ's approximation of SIs on popular GNN architectures and compare with existing baselines. Lastly, we visualize SIs of real-world water distribution networks and molecule structures using a SI-Graph.", "sections": [{"title": "1 INTRODUCTION", "content": "Graph-structured data appears in many domains and real-world applications (Newman, 2018), such as molecular chemistry (Gilmer et al., 2017), water distribution networks (WDNs) (Ashraf et al., 2023), sociology (Borgatti et al., 2009), physics (Sanchez-Gonzalez et al., 2020), or human resources (Frazzetto et al., 2023). To leverage such structure in machine learning (ML) models, Graph Neural Networks (GNNs) emerged as the leading family of architectures that specifically exploit the graph topology (Scarselli et al., 2009). A major drawback of GNNs is the opacity of their predictive mechanism, which they share with most deep-learning based architectures (Amara et al., 2022). Reliable explanations for their predictions are crucial when model decisions have significant consequences (Zhang et al., 2024) or lead to new discoveries (McCloskey et al., 2019).\nIn explainable artificial intelligence (XAI), the Shapley Value (SV) (Shapley, 1953) is a prominent concept to assign contributions to entities of black box ML models (Lundberg & Lee, 2017; Covert et al., 2021; Chen et al., 2023). Entities typically represent features, data points (Ghorbani & Zou, 2019) or graph structures (Yuan et al., 2021; Ye et al., 2023). Although SVs yield an axiomatic attribution scheme, they do not give any insights into joint contributions of entities, known as interactions. Yet, interactions are crucial to understanding decisions of complex black box ML models (Wright et al., 2016; Sundararajan et al., 2020; Kumar et al., 2021). Shapley Interactions (SIs) (Grabisch & Roubens, 1999; Bordt & von Luxburg, 2023) extend the SV to include joint contributions of multiple entities. SIs satisfy similar axioms while providing interactions up to a maximum number of entities, referred to as the explanation order. In this context, SVs are the least complex SIs,"}, {"title": "2 BACKGROUND", "content": "In Section 2.1, we introduce SIs that provide an adjustable accuracy-complexity trade-off for explanations (Bordt & von Luxburg, 2023). In this context, SVs are the simplest and MIs the most complex SIs. In Section 2.2, we introduce GNNs, whose structure we exploit in Section 3 to efficiently compute any-order SIs. A summary of notations can be found in Appendix A."}, {"title": "2.1 EXPLANATION COMPLEXITY: FROM SHAPLEY VALUES TO M\u00d6BIUS INTERACTIONS", "content": "Concepts from cooperative game theory, such as the SV (Shapley, 1953), are prominent in XAI to interpret predictions of a black box ML model via feature attributions (Strumbelj & Kononenko, 2014; Lundberg & Lee, 2017). Formally, a cooperative game $v : \\mathcal{P}(N) \\rightarrow \\mathbb{R}$ is defined, where individual features $N = \\{1, ..., n\\}$ act as players and achieve a payout for every group of players in the power set $\\mathcal{P}(N)$. To obtain feature attributions for the prediction of a single instance, $v$ typically refers to the model's prediction given only a subset of feature values. Since classical ML models cannot handle missing feature values, different methods have been proposed, such as model retraining (Strumbelj et al., 2009), conditional expectations (Lundberg & Lee, 2017; Aas et al., 2021; Frye et al., 2021), marginal expectations (Janzing et al., 2020) and baseline imputations (Lundberg & Lee, 2017; Sundararajan et al., 2020). In high-dimensional feature spaces, retraining models or approximating feature distributions is infeasible, imputing absent features with a baseline, known as Baseline Shapley (BShap) (Sundararajan & Najmi, 2020), is the prevalent method (Lundberg & Lee, 2017; Sundararajan et al., 2017; Jethani et al., 2022). We now first introduce the MIs as a backbone of additive contribution measures. Later in Section 3, we exploit sparsity of MIs for GNNs to compute the SV and any-order SIs.\nM\u00f6bius Interactions (MIs) $m : \\mathcal{P}(N) \\rightarrow \\mathbb{R}$, alternatively M\u00f6bius transform (Rota, 1964), Harsanyi dividend (Harsanyi, 1963), or internal interaction index (Fujimoto et al., 2006), are a fundamental concept of cooperative game theory. The MI is\n$m(S) := \\sum_{T \\subseteq S}(-1)^{|S\\setminus T|}v(T)$ and they recover $v(T) = \\sum_{S \\subseteq T} m(S)$ for all $S, T \\subseteq N$. \nFrom the MIs, every game value can be additively recovered, and MIs are the unique measure with this property (Harsanyi, 1963; Rota, 1964). The MI of a subset $S \\subseteq N$ can thus be interpreted as the pure additive contribution that is exclusively achieved by a coalition of all players in $S$, and cannot be attributed to any subgroup of $S$. The MIs are further a basis of the vector space of games (Grabisch, 2016), and therefore every measure of contribution, such as the SV or the SIs, can be directly recovered from the MIs, cf. Appendix E.3.\nShapley Values (SVs) for players $i \\in N$ of a cooperative game $v$ are the weighted average\n$\\varPhi^{Sv}(i) := \\frac{1}{n} \\sum_{T \\subseteq N \\setminus i} {n \\choose |T|}^{-1} \\Delta_i(T)$ with $\\Delta_i(T) := v(T \\cup i) - v(T)$\nover marginal contributions $\\Delta_i(T)$. It was shown (Shapley, 1953) that the SV is the unique attribution method that satisfies desirable axioms: linearity (the SV of linear combinations of games, e.g., model ensembles, coincides with the linear combinations of the individual SVs), dummy (features"}, {"title": "2.2 GRAPH NEURAL NETWORKS", "content": "GNNs are neural networks specifically designed to process graph input (Scarselli et al., 2009). A graph $g = (V, E, X)$ consists of sets of nodes $V = \\{v_1, ..., v_n\\}$, edges $E \\subset V \\times V$ and $d_0$-dimensional node features $X = [x_1, ..., x_n]^t \\in \\mathbb{R}^{n \\times d_0}$, where $x_i$ are the node features of node $v_i \\in V$. A message passing GNN leverages the structural information of the graph $g$ to iteratively aggregate node feature information of a given node $v \\in V$ within its neighborhood $\\mathcal{N}(v) := \\{u \\in V | l_{uv} \\in E\\}$. More precisely, in each iteration $k \\in \\{1, ..., l\\}$, the $d_k$-dimensional $k$-th hidden node features $H^{(k)} = [h_1^{(k)},..., h_n^{(k)}] \\in \\mathbb{R}^{n \\times d_k}$ are computed node-wise by\n$h_i^{(0)} := x_i, h_i^{(k)} := \\rho^{(k)} \\left( h_i^{(k-1)}, \\psi(\\left\\{\\phi^{(k)}\\left(h_j^{(k-1)}\\right) | v_j \\in \\mathcal{N}(v_i)\\right\\}\\right),$\nwhere $\\{\\{ \\cdot \\}\\}$ indicates a multiset and $\\rho^{(k)}$ and $\\phi^{(k)}$ are arbitrary (aggregation) functions acting on the corresponding spaces. Moreover, $\\psi$ is implemented as a permutation-invariant function, ensuring independence of both the order and number of neighboring nodes, and allows for an embedding of multisets as vectors. The node embedding function is thus $f_i(X) := h_i^{(l)}$. For graph regression, the representations of the last nodes $H^{(l)}$ must be aggregated in a fixed-size graph embedding for the downstream task. More formally, this is achieved by employing an additional permutation-invariant pooling function $\\Psi$ and a parametrized output layer $\\sigma : \\mathbb{R}^{d_l} \\rightarrow \\mathbb{R}^{d_{out}}$ layer, where $d_{out}$ corresponds to the output dimension. The output of a GNN for graph-level inference is defined as\n$f_g(X) := \\sigma(\\Psi(\\left\\{f_i(X) | v_i \\in V\\right\\})).$"}, {"title": "3 ANY-ORDER SHAPLEY INTERACTIONS FOR GRAPH NEURAL NETWORKS", "content": "In the following, we are interested in explaining the prediction of a GNN $f_g$ for a graph $g$ with respect to nodes. We aim to decompose a model's prediction into SIs $\\varPhi_k$ visualized by a SI-Graph.\nDefinition 3.1 (SI-Graph). The SI-Graph is an undirected hypergraph $g_I := (N, \\mathcal{P}_k(N), \\varPhi_k)$ with node attributes $\\varPhi_k(i)$ for $i \\in N$ and hyperedge attributes $\\varPhi_k(S)$ for $2 \\leq |S| \\leq k$.\nThe simplest SI-Graph displays the SVs ($k = 1$) as node attributes, whereas the most complex SI-Graph displays the MIs ($k = n$) as node and hyperedge attributes, illustrated in Figure 1. The complexity of the SI-Graph is adjustable by the explanation order $k$, which determines the maximum hyperedge order. The sum of all contributions in the SI-Graph yields the model's prediction (for regression) or the model's logits for the predicted class (for classification). This choice is natural for an additive contribution measure due to additivity in the logit-space. To compute SIs, we introduce the GNN-induced graph game $v_g$ with a node masking strategy in Section 3.1. The graph game is defined on all nodes and describes the output given a subset of nodes, where the remaining are masked. Computing SIs on the graph game defines a perturbation-based and a decomposition-based GNN explanation (Yuan et al., 2023), which is an extension of node attributions (Agarwal et al., 2023). In Section 3.2, we show that GNNs with linear global pooling and output layer satisfy an invariance property for the node game associated with the node embeddings (Theorem 3.3). This invariance implies sparse MIs for the graph game (Proposition 3.6), which determines the complexity of MIs by the corresponding receptive fields (Theorem 3.7), which substantially reduces the complexity of SIs in our experiments. In Section 3.3, we introduce GraphSHAP-IQ, an efficient algorithm to exactly compute and estimate SIs on GNNs. All proofs are deferred to Appendix B."}, {"title": "3.1 A COOPERATIVE GAME FOR SHAPLEY INTERACTIONS ON GRAPH NEURAL NETWORKS", "content": "Given a GNN $f_g$, we propose the graph game for which we compute axiomatic and fair SIs.\nDefinition 3.2 (GNN-induced Graph and Node Game). For a graph $g = (V, E, X)$ and a GNN $f_g$, we let $N := \\{i : v_i \\in V\\}$ be the node indices and define the graph game $v_g : \\mathcal{P}(N) \\rightarrow \\mathbb{R}$ as\n$v_g(T) := f_{g,\\hat{y}}(X(T))$ with $X(T) := (x_1^{(T)}, ..., x_n^{(T)}) \\in \\mathbb{R}^{n \\times d_0}$ and $x_i^{(T)} := \\begin{cases} x_i & \\text{if } i \\in T, \\\\ b & \\text{if } i \\notin T, \\end{cases}$\nwith $i \\in N$ and baseline $b \\in \\mathbb{R}^{d_0}$. In graph regression $f_{g,\\hat{y}} = f_g$ and for graph classification $f_{g,\\hat{y}}$ is the component of the predicted class $\\hat{y}$ of $f_g$. We further introduce the (multi-dimensional) node game $v_i : \\mathcal{P}(N) \\rightarrow \\mathbb{R}^{d_l}$ as $v_i(T) := f_i(X(T))$ for $i \\in N$ and each node $v_i \\in V$.\nThe graph game outputs the prediction of the GNN for a subset of nodes $T \\subseteq N$ by masking all node features of nodes $v_i$ with $i \\in N \\setminus T$ using a suitable baseline $b$, illustrated in Figure 2, left. Computing such SVs is known as BShap (Sundararajan & Najmi, 2020) and a prominent approach for feature attributions (Lundberg & Lee, 2017; Covert et al., 2021; Chen et al., 2023). As a baseline $b$, we propose the average of each node feature over the whole graph. By definition, the prediction of the GNN is given by $v_g(N) = f_g(X)$, and due to the efficiency axiom, the sum of contributions in the SI-Graph yields the model's prediction, and thus a decomposition-based GNN explanation (Yuan et al., 2023). The graph and the node game are directly linked by Equation (3) as\n$v_g(T) = f_{g,\\hat{y}} (X(T)) = \\sigma_{\\hat{y}}(\\Psi(\\left\\{f_i(X(T))\\right\\} | v \\in V)) = \\sigma_{\\hat{y}}(\\Psi(\\left\\{v_i(T)\\right\\} | i \\in N)),$\nwhere $\\sigma_{\\hat{y}}$ outputs the component of $\\sigma$ for the predicted class $\\hat{y}$. The number of convolutional layers $l$ determines the receptive field, i.e. the message-passing range defined by its $l$-hop neighborhood\n$\\mathcal{N}_i^{(l)} := \\{j \\in N | d_g(i, j) \\leq l\\}$ with $d_g(i, j) :=$ length of shortest path from $v_j$ to $v_i$ in $g$.\nConsequently, the node game $v_i$ is unaffected by maskings outside its $l$-hop neighborhood.\nTheorem 3.3 (Node Game Invariance). For a graph $g$ and an $l$-Layer GNN $f_g$, let $v_i$ be the GNN-induced node game with $i \\in N$. Then, $v_i$ satisfies the invariance $v_i(T) = v_i(T \\cap \\mathcal{N}_i^{(l)})$ for $T \\subseteq N$."}, {"title": "3.2 COMPUTING EXACT SHAPLEY AND M\u00d6BIUS INTERACTIONS FOR THE GRAPH GAME", "content": "Given a GNN-induced graph game $v_g$ from Definition 3.2 with Assumption 3.4, i.e. $\\Psi$ and $\\sigma$ are linear, then the MIs of each node game are restricted to the $l$-hop neighborhood. Intuitively, maskings outside the receptive field do not affect the node embedding. Consequently, we show that the MIs of the graph game are restricted by all existing $l$-hop neighborhoods. More formally, due to the invariance of the node games (Theorem 3.3), the MIs for subsets that are not fully contained in the $l$-hop neighborhood $\\mathcal{N}_i^{(l)}$ are zero.\nLemma 3.5 (Trivial Node Game Interactions). Let $m_i : \\mathcal{P}(N) \\rightarrow \\mathbb{R}^{d_l}$ be the MIs of the GNN-induced node game $v_i$ for $i \\in N$ under Assumption 3.4. Then, $m_i(S) = 0$ for all $S \\neq \\mathcal{N}_i^{(l)}$.\nLemma 3.5 yields that the node game interactions outside of the $l$-hop neighborhood do not have to be computed. Due to Assumption 3.4, the interactions of the GNN-induced graph game are equally zero for subsets that are not fully contained in any $l$-hop neighborhood.\nProposition 3.6 (Trivial Graph Game Interactions). Let $m_g : \\mathcal{P}(N) \\rightarrow \\mathbb{R}$ be the MIs of the GNN-induced graph game $v_g$ under Assumption 3.4 and let $\\mathcal{I} := \\bigcup_{i \\in N} \\mathcal{P}(\\mathcal{N}_i^{(l)})$ be the set of non-trivial interactions. Then, $m_g(S) = 0$ for all $S \\subseteq N$ with $S \\notin \\mathcal{I}$.\n$\\mathcal{I}$ is the set of non-trivial MIs, whose size depends on the receptive field of the GNN. The size of $\\mathcal{I}$ also directly determines the required model calls to compute SIs.\nTheorem 3.7 (Complexity). For a graph $g$ and an $l$-Layer GNN $f_g$, computing MIs and SIs on the GNN-induced graph game $v_g$ requires $|\\mathcal{I}|$ model calls. The complexity is thus bounded by\n$|\\mathcal{I}| \\leq \\sum_{i \\in N} 2^{|\\mathcal{N}_i^{(l)}|} \\leq n \\cdot 2^{n_{max}^{(l)}} < n \\cdot 2^{d_{max}^{l}},$"}, {"title": "3.3 GRAPHSHAP-IQ: AN EFFICIENT ALGORITHM FOR SHAPLEY INTERACTIONS", "content": "Building on Theorem 3.7, we propose GraphSHAP-IQ, an efficient algorithm to compute SIs for GNNs. At the core is the exact computation of SIs, outlined in Algorithm 1, which we then extend for approximation in restricted settings. Moreover, we propose interaction-informed baseline methods that directly exclude zero-valued SIs, which, however, still require all model calls for exact computation. To compute exact SIs, GraphSHAP-IQ identifies the set of non-zero MIs $\\mathcal{I}$ based on the given graph instance (line 1). The GNN is then evaluated for all maskings contained in $\\mathcal{I}$ (line 2). Given these GNN predictions, the MIs for all interactions in $\\mathcal{I}$ are computed (line 3). Based on the computed MIs, the SIs are computed using the conversion formulas (line 4). Lastly, GraphSHAP-IQ outputs the exact MIs and SIs. In restricted settings, computing exact SIs could still remain infeasible. We thus propose an approximation variant of GraphSHAP-IQ by introducing a hyperparameter $\\lambda$, which limits the highest order of computed MIs in line 1. Hence, GraphSHAP-IQ outputs exact SIs, if $\\lambda = n_{max}^{(l)}$, thereby requiring the optimal budget. For a detailed description of GraphSHAP-IQ and the interaction-informed variants, we refer to Appendix D."}, {"title": "4 EXPERIMENTS", "content": "In this section, we empirically evaluate GraphSHAP-IQ for GNN explainability, and showcase a substantial reduction in complexity for exact SIs (Section 4.1), benefits of approximation (Section 4.2), and explore the SI-Graph for WDNs and molecule structures (Section 4.3). Following Amara et al. (2022), we trained a Graph Convolutional Network (GCN) (Kipf & Welling, 2017), Graph Isomorphism Network (GIN) (Xu et al., 2019), and Graph Attention Network (GAT) (Velickovic et al., 2018) on eight real-world chemical datasets for graph classification and a WDN for graph regression, cf. Table 1. All models adhere to Assumption 3.4 and report comparable test accuracies (Errica et al., 2020; You et al., 2020). All experiments are based on shapiq (Muschalik et al., 2024a) and details can be found in Appendix F or at https://github.com/FFmgll/GraphSHAP-IQ."}, {"title": "4.1 COMPLEXITY ANALYSIS OF GRAPHSHAP-IQ FOR EXACT SHAPLEY INTERACTIONS", "content": "In this experiment, we empirically validate the benefit of exploiting graph and GNN structures to compute exact SIs with GraphSHAP-IQ. The complexity is measured by the number of evaluations of the GNN-induced graph game, i.e. the number of model calls of the GNN, which is the limiting factor of SIs, cf. runtime analysis in Appendix G.2. For every graph in the benchmark datasets, described in Table 1, we compute the complexity of GraphSHAP-IQ, where the first upper bound from Theorem 3.7 is used if $\\underset{i \\in n}{\\text{max}}|\\mathcal{N}_i^{(l)}| > 23$, i.e. the complexity exceeds $2^{23} \\approx 8.3 \\times 10^6$. Figure 3 displays the log-scale complexity (y-axis) by the number of nodes $n$ (x-axis) for BZR (left) and MTG (middle, right) for varying number of convolutional layers $l$ (left, middle) and by graph density for a 2-Layer GNN (right). The model-agnostic baseline is represented by a dashed line. For results on all datasets, see Appendix G.1. Figure 3 shows that the computation of SIs is substantially reduced by GraphSHAP-IQ. Even for large graphs with more than 100 nodes, where the baseline requires over $10^{30}$ model calls, many instances can be exactly computed for 1-Layer and 2-Layer GNNs with fewer than $10^5$ evaluations. In fact, the complexity grows linearly with graph size across the dataset, as shown by high $R^2$ scores of fitted logarithmic curves. Figure 3 (right) shows that the graph density is an efficient proxy of complexity, with higher values for instances near the baseline."}, {"title": "4.2 INTERACTION-INFORMED APPROXIMATION OF SHAPLEY INTERACTIONS", "content": "For densely connected graphs and GNNs with many layers, exact computation of SIs might still be infeasible. We, thus, evaluate the approximation of SIs with GraphSHAP-IQ, current state-of-the-art model-agnostic baselines (implemented in shapiq), and our proposed interaction-informed variants. For the SV (order 1), we apply KernelSHAP (Lundberg & Lee, 2017), Unbiased KernelSHAP (Covert & Lee, 2021), k-additive SHAP (Pelegrina et al., 2023), Permutation Sampling (Castro et al., 2009), SVARM (Kolpaczki et al., 2024a), and L-Shapley (Chen et al., 2019). We estimate k-SII (order 2 and 3) with KernelSHAP-IQ (Fumagalli et al., 2024), Inconsistent KernelSHAP-IQ (Fumagalli et al., 2024), Permutation Sampling (Tsai et al., 2023), SHAP-IQ (Fumagalli et al., 2023), and SVARM-IQ (Kolpaczki et al., 2024b). For each baseline, we use the interaction-informed variant, cf. Appendix D.3. We select graphs containing $20 \\leq n \\leq 40$ nodes for the MTG, PRT, and BZR benchmark datasets. For each graph instance, we compute ground-truth SIs via GraphSHAP-IQ and evaluate all methods using the same number of model calls, which is the main driver of runtime, cf. Appendix G.2. Figure 4 (left) displays the average MSE (lower is better) for varying $\\lambda$ (model calls), where GraphSHAP-IQ outperforms the baselines in settings with a majority of lower-order MIs. Figure 4 (middle) compares average runtime and MSE for varying explanation orders at GraphSHAP-IQ's ground-truth budget. Notably, GraphSHAP-IQ is among the fastest methods, and remains unaffected by increasing explanation order. Moreover, for all baselines (except permutation sampling), the interaction-informed variants substantially improve the approximation quality and runtime. Consequently, noisy estimates of SIs are substantially improved (Figure 4, right)."}, {"title": "4.3 REAL-WORLD APPLICATIONS OF SHAPLEY INTERACTIONS AND THE SI-GRAPH", "content": "We now apply GraphSHAP-IQ in real-world applications and include further results in Appendix G. Monitoring water quality in WDNs requires insights into a dynamic system governed by local"}, {"title": "5 COMPARISON OF LINEAR AND DEEP READOUTS", "content": "Theorem 3.4 imposes the use of a linear readout, which is a limitation of our method, though it remains commonly used in practice (You et al., 2020). In this section, we compare SIs for GNNs with both linear and non-linear readouts. We train a 2-layer GCN architecture with both linear and non-linear (2-layer perceptron) readouts on MTG, where both models achieve comparable performance. Figure 6 shows that non-linear readouts produce substantially different MIs that are not restricted to the receptive fields. Lower-order explanations are similar, indicating the correct reasoning of both models ($\\text{NO}_2$ group signalling mutagenicity). We conclude that linear readout restricts the interactions of the GNN to the graph structure and its receptive fields. In contrast, non-linear readouts enable interactions that extend beyond the receptive fields of the GNN. Many SV-based XAI methods for GNNs (Yuan et al., 2021; Zhang et al., 2022; Ye et al., 2023; Bui et al., 2024) implicitly rely on the assumption that interactions outside the receptive fields are negligible, which should be evaluated carefully for non-linear readouts."}, {"title": "6 LIMITATIONS AND FUTURE WORK", "content": "We presented GraphSHAP-IQ, an efficient method to compute SIs that applies to all popular message passing techniques in conjunction with a linear global pooling and output layer. Assumption 3.4 is a common choice for GNNs (Errica et al., 2020; Xu et al., 2019; Wu et al., 2022) and does not necessarily yield lower performance (Mesquita et al., 2020; You et al., 2020; Grattarola et al., 2021), which is confirmed by our experiments. However, exploring non-linear choices that preserve trivial MIs is important for future research. Masking node features with a fixed baseline, known as BShap, preserves the topology of the graph structure and is a well-established approach (Sundararajan et al., 2020). Nevertheless, alternatives such as induced subgraphs, edge-removal, or learnable masks, could emphasize other properties of the GNN. Lastly, approximation of SIs with GraphSHAP-IQ and interaction-informed baselines substantially improved the estimation, where novel methods tailored to Proposition 3.6 are promising future work. Our results may further be applied to other models with spatially restricted features, such as convolutional neural networks."}, {"title": "7 CONCLUSION", "content": "We introduced the GNN-induced graph game, a cooperative game for GNNs on graph prediction tasks that outputs the model's prediction given a set of nodes. The remaining nodes are masked using a baseline for node features, corresponding to the well-established BShap (Sundararajan et al., 2020). We showed that under linearity assumptions on global pooling and output layers, the complexity of computing exact SVs, SIs, and MIs on any GNN is determined solely by the receptive fields. Based on our theoretical results, we presented GraphSHAP-IQ and interaction-informed variants of existing baselines, to efficiently compute any-order SIs for GNNs. We show that GraphSHAP-IQ and interaction-informed baselines substantially reduces the complexity of SIs on multiple real-world benchmark datasets and propose to visualize SIs as the SI-Graph. By computing the SI-Graph, we discover trajectories of chlorine in WDNs and important molecule substructures, such as benzene rings or $\\text{NO}_2$ groups."}, {"title": "ETHICS STATEMENT", "content": "This paper presents work aiming to advance the field of ML and specifically the field of XAI. There are many potential societal consequences of our work. Our research holds significant potential for positive societal impact, particularly in areas like the natural sciences (e.g., chemistry and biology) and network analytics. Our work can positively impact ML adoption and potentially reveal biases or unwanted behavior in ML systems.\nHowever, we recognize that the increased explainability provided by XAI also carries ethical risks. There is the potential for \u201cexplainability-based white-washing\u201d, where organizations, firms, or institutions might misuse XAI to justify questionable actions or outcomes. With responsible use, XAI can amplify the positive impacts of ML, ensuring its benefits are realized while minimizing harm."}, {"title": "REPRODUCIBILITY STATEMENT", "content": "The python code for GraphSHAP-IQ is available at https://github.com/FFmgll/\nGraphSHAP-IQ, and can be used on any graph game, a class specifically tailored to the shapiq package (Muschalik et al., 2024a). We include formal proofs of all claims made in the paper in Appendix B. We further describe the experimental setup and details regarding reproducibility in Appendix F. Our experimental results, setups and plots can be reproduced by running the corresponding scripts. The datasets and their sources are described in Table 3."}]}