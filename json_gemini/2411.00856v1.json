{"title": "Al in Investment Analysis: LLMs for Equity Stock Ratings", "authors": ["Kassiani Papasotiriou", "Srijan Sood", "Shayleen Reynolds", "Tucker Balch"], "abstract": "Investment Analysis is a cornerstone of the Financial Services industry. The rapid integration of advanced machine learning techniques, particularly Large Language Models (LLMs), offers opportunities to enhance the equity stock rating process. This paper explores the application of LLMs to predict stock performance and generate stock ratings by ingesting diverse datasets. Traditional stock rating methods rely heavily on the expertise of financial analysts, and face several challenges such as data overload, inconsistencies in filings, and delayed reactions to market events. Our study addresses these issues by leveraging LLMs to improve the accuracy and consistency of stock ratings. Additionally, we assess the efficacy of using different data modalities with LLMs for the financial domain.\nWe utilize varied datasets comprising fundamental financial, market, and news data from January 2022 to June 2024, along with GPT-4-32k (v0613) (with a training cutoff in Sep. 2021 to prevent information leakage). Our results show that our benchmark method outperforms traditional stock rating methods when assessed by forward returns. Specifically, incorporating financial fundamentals enhances ratings accuracy. While integrating news data improves short-term performance, substituting detailed news summaries with sentiment scores reduces token use without loss of performance. In many cases, omitting news data entirely enhances performance by reducing bias.\nOur research shows that LLMs can be leveraged to effectively utilize large amounts of multimodal financial data, as showcased by their effectiveness at the stock rating prediction task. Our work provides a reproducible framework for generating consistent and accurate stock ratings, offering a cost-effective and efficient alternative to traditional methods. Future work will extend the analysis to longer time horizons, incorporating more diverse data, and utilizing newer models to enhance detailed investment analysis and reports.", "sections": [{"title": "1 INTRODUCTION", "content": "Investment Analysis is a foundational segment of the financial services industry, and is crucial for the functioning of financial markets, providing essential insights that drive investment decisions, market trends, and economic policies. Financial analysts play a key role in this process by evaluating financial data, preparing reports, and publishing stock ratings among other financial anlysis tasks. Their expertise helps in valuing assets, assessing investment opportunities, and formulating business decisions. By interpreting complex financial information, their analyses help mitigate risks and identify opportunities for investors [11].\nA crucial task of a financial analyst is to publish stock ratings, which evaluate a company's future performance based on forward projections of a company's fundamentals, including earnings, revenue growth, and cash flow, as well as broader market conditions and economic trends. They consist of analysts' expert recommendations on how to position companies over the next quarter to a year and thus play a pivotal role in shaping market perceptions [26]. These ratings are among many variables used to evaluate companies in the investment analysis domain.\nIn recent years, these methods have been complemented by advanced machine learning techniques, such as Deep Learning"}, {"title": "2 BACKGROUND AND RELATED WORK", "content": "In this section, we first focus on the powerful capabilities of general purpose LLMs in finance and how AI has been increasingly integrated in the domain. We speak specifically to tasks within the area of investing, discussing the importance of AI in financial analysis in conducting these tasks. Finally, we discuss the ratings produced by financial analysts, their impact on the market and the various ways Al has been integrated to enhance the process."}, {"title": "2.1 LLMS in Finance", "content": "Zero-shot and few-shot LLM techniques are widely applied in the domain of finance. For example, [9, 37] demonstrate using LLMs for identifying sentiment and summarization of financial news, respectively, using instruction based prompting techniques. [28] evaluates complex question answering (QA) techniques on semi-structured financial documents. [17] assesses LLM performance (ranging from general purpose LLMs to fine-tuned) on QA and summarization for financial documents, text classification, generation, stock movement prediction and more, demonstrating many applications for LLMs in finance.\nThe commonalities among research utilizing LLMs for prediction include using diverse datasets, employing LLMs at multiple stages and enhancing interpretability. The integration of the capabilities highlighted above and advancements in LLMs significantly enhance financial tasks such as stock movement prediction, risk mitigation and quantitative trading. [21] uses GPT to predict stock market returns from news headline sentiment scores and finds a positive correlation, outperforming older GPTs and BERT in forecasting returns, as evaluated by the Sharpe Ratio. [10], [30], and [18] utilize several sources of data such as financial news, fundamentals, stock prices, market data and macroeconomic factors to aid in stock prediction. [10] applies Chain-of-Thought (CoT) prompting and In-Context Learning with GPT-4 to generate signals and subsequently ranking strategies that show positive percentage returns on selected stocks. [7] leverages LLMs to analyze and predict financial risks by combining data from earnings calls, market-related time series data, and contextual news data. For quantitative trading, a popular avenue of research utilizes memory modules and knowledge bases to aid in a model's self-adaptability. [19, 35] built LLM-based autonomous trading agents that utilize layered memory. [31] built a self-improving LLM using an agent that refines its responses with a knowledge base and then tests responses in real-world scenarios to update the knowledge base with new insights."}, {"title": "2.2 Analyst Stock Ratings", "content": "An analyst stock rating forecasts a stocks performance. In the most common scenario, analysts publish ratings upon the release of quarterly filings, earnings calls, or significant events, updating their guidance for the next quarter, and for rest of the year. These ratings fall into five categories, though terminology may vary:\n\u2022 Strong Buy/Buy: Indicates that the stock is expected to significantly outperform the market or its sector.\n\u2022 Moderate Buy: Suggests that the stock is expected to perform better than the market average or its sector. Also referred to as Outperform or Overweight.\n\u2022 Hold: Indicates that the stock is expected to perform in line with the market or its sector.\n\u2022 Moderate Sell: Suggests that the stock is expected to perform worse than the market average or its sector. Also referred to as Underperform or Underweight.\n\u2022 Strong Sell/Sell: Indicates that the stock is expected to underperform its benchmark significantly.\nDifferent institutions utilize custom rating scales, which can vary between organizations. For example, some analysts use a one-to-five rating system based on risk-adjusted performance, others employ"}, {"title": "2.3 Importance of Stock Ratings", "content": "As mentioned in section 2.1, while research on company performance prediction shows promising results, it often overlooks stock ratings, a key indicator of future stock performance. Investors use stock ratings for many tasks such as portfolio building, risk assessment, asset allocation and other investment strategies [5, 13, 27]. Studies on how ratings impact the market reveal that investors closely monitor these ratings to make informed decisions, leading to market movements based on ratings. For example, [26] analyzes 20 years of S&P500 trading data, developing a classifier that predicts 1% price changes up to 10 days ahead with 83.62% accuracy, 85% precision for buy signals, and 100% recall for sell signals. Feature ranking highlights analyst stock ratings as top contributors. [14] evaluates the impact of analysts' recommendations in G7 countries, finding significant stock price reactions to recommendation revisions in all countries except Italy, with the US showing the largest price reactions and post-revision price drifts. [4] evaluates the impact of analyst stock changes, finding that influential recommendations are linked to increased stock volatility and significant changes in consensus earnings forecasts. [36] examines the profitability of analysts' recommendations in the Polish market using data from 2004-2013. It builds market-neutral portfolios and tests their performance against CAPM, Fama-French, and Carhart models. The key finding is that strategies based on analysts' recommendations yield statistically significant positive abnormal returns, demonstrating their profitability."}, {"title": "3 METHODOLOGY", "content": "We leverage LLMs to analyze financial data and generate stock ratings, taking advantage of their ability to process large volumes of information, recognize complex patterns, and adapt to new data. LLMs can efficiently handle diverse data sources and provide detailed insights that traditional methods might miss. Our goal is to provide the LLM with the same information an analyst would consider, such as financial fundamentals, stock price movements, news summaries, sentiment, and other relevant data. This helps us assess the feasibility of using LLMs for investment analysis and identify the techniques and information that improve their performance."}, {"title": "3.1 Prompt Structure", "content": "We utilize GPT-4-32k (v0613), hosted on Azure, which features a context window of 32,000 tokens and is trained on data up to September 2021 [23]. We specifically selected this model to prevent information leakage, as the data we use is from after the model's training cut-off date.\nWe use the system prompt to instruct the LLM to adopt the persona of a financial analyst. By defining this role, we provide the LLM with a clear framework for its function. Additionally, we contextualize the financial terms utilized in the experiments by defining the scale of stock ratings and their definitions (Section 2.2), incorporating synonyms to account for variations in terminology. We also provide detailed descriptions of financial fundamentals, which are outlined in 4.1.\nTo design the user prompt, we follow the success of Chain-of-Thought and few-shot prompt approaches [6, 32], and encourage the LLM to engage in reasoning before making its final prediction and provide it with an example of what the output should look like. Additionally, we provide company-specific input data in a structured format, with textual information first followed by numerical data in tables, following findings from [29]. We also perform basic CoVE (chain of verification) to detect if it's is predicting things for the correct dates."}, {"title": "3.2 Problem Formulation", "content": "Let $rating_(t, p)$ be a rating for a company $c$ released on date $t$, predicting the company's performance at a future horizon of $p$ months. The rating can take any of the following ordinal values:\n$rating_(t, p) \\in \\{-2, -1, 0, 1, 2\\}$\nwhere -2 = Strong Sell, -1 = Moderate Sell, 0 = Hold, 1 = Moderate Buy, and 2 = Strong Buy.\nWe assess the accuracy of a rating by evaluating how the company's stock performs. This approach is commonly used in technical papers that utilize future returns. For example, to assess the value of analyst stock ratings [12] investigates the performance of stocks shortly after ratings are published, while [3] analyzes the distribution of analyst stock ratings over time, using company returns in quintiles to predict potential profitability. [4] evaluates changes in analyst stock ratings by comparing company returns across different rating levels.\nTo determine the accuracy of a rating $rating_(t, p)$, we evaluate the performance of company $c$ using its forward returns (at period $t+p$), and compare it to other companies. This is done by computing company returns for the entire group (e.g. S&P500 constituents) at a fixed time horizon, and then dividing these into quintiles. The quintile groups correspond to rating levels, e.g., companies with returns in the lowest quintile significantly underperformed their peers, making their ground truth rating a Strong Sell.\nOur process is as follows. We first calculate forward company returns as well as market and sector relative returns:\nGiven the price for company $c$ at time $t$, $P_c(t)$, the company return $R_c(t, p)$ over the period $p$ is defined as:\n$R_c(t, p) = \\frac{P_c(t +p) - P_c(t)}{P_c(t)}$"}, {"title": "4 EXPERIMENTS", "content": "In this section we provide an overview of the data we use as well as our experiment set up."}, {"title": "4.1 Data", "content": "Our analysis focuses on US equities, specifically the 500 constituents of the S&P 500 index, using data spanning from January 2022 to the end of June 2024.\nAnalyst Stock Ratings: We gather analyst stock ratings for each company in the S&P500 [1]. Out of a total of 45,000 ratings from 126 firms, the majority of ratings (75.90%) were maintained, followed by reiterate (7.25%), downgrade (6.27%), upgrade (5.68%), and initiate (4.89%). The top five firms, which include Morgan Stanley, Barclays, Wells Fargo, Citigroup, and RBC Capital, collectively account for 31.61% of all ratings. Specifically, Morgan Stanley contributed 9.99%, Barclays 6.52%, Wells Fargo 5.91%, Citigroup 4.67%, and RBC Capital 4.52% of the total ratings. This dataset comprises the firm issuing the rating, the date of the rating, and the rating itself. However, we do not have data for the target date or the target price. Note that for a particular date and company, there may be multiple ratings issued by different firms.\nFinancial News Summaries: We collect news articles for stocks in the S&P500 [1] [25] [8]. We filter irrelevant content out by performing named entity recognition (NER), utilizing both company names and possible company aliases to enhance this process (alias were also scraped from [1]). After filtering down to relevant data, our dataset consists of the following: on average per month, there are 39.63 articles, 187K characters, and 40K tokens, with 74.70 URLs and 34.40 missing articles per ticker. We summarize the monthly news for each company and sector using GPT-4-32k (v0613) to highlight key events and trends. Our system prompt designates the"}, {"title": "4.2 Experiment Setup", "content": "We utilize GPT-4-32k (v0613), hosted on Azure, which features a context window of 32,000 tokens and is trained on data up to"}, {"title": "4.2.1 Methods.", "content": "We conduct experiments with five distinct methods: Vanilla, News, Sentiment, Fundamentals, and Fundamentals + Sentiment. All of these methods utilize GPT-4-32k (v0613), but with varying data provided to the model in its input context. We provide the LLM with the task description (as highlighted in Section 3.1. For each query, we include the name of the company, the date on which the ratings will be released, and the five forward-looking time horizons for which it needs to generate ratings. Inspired by the chain-of-thought prompting framework, we also ask the LLM to output the corresponding price targets, along with a short explanation. We check the LLM's response to verify that it is computing the dates which each time horizon corresponds to correctly.\nVanilla: The input context includes a snapshot of the company's historical data: returns, market-relative returns, and sector-relative returns for the past 1-month, 3-month, and 12-month periods. Additionally, we provide the current stock price (as of rating date), the 52-week price range (min, max), and the 90-day volatility (std. dev. of daily returns). In total, the LLM receives 10 values describing historical returns (1 for volatility), plus 3 values relating to the stock price (current and 52-week min-max), for a total of just 13 numbers. We found that these simple data points greatly improve the LLM's ability to generate accurate ratings. This setting serves as our baseline for the following experiments.\nNews: This experiment enhances the input prompt for the Vanilla method by including news data. As it is not pragmatic to include entire news articles due to LLM context limits, we provide summaries of company news and sector news from the previous month. In addition to the outputs described above, the LLM is also tasked with assessing the sentiment of the news summaries provided (positive, negative, neutral, or mixed), and to use this in its predictions. We found improved performance when the LLM receives the news summaries earlier in the context (before the technical indicators). Given the success of in-context learning, we also provide the LLM with an example: the input data as described, along with the expected"}, {"title": "4.3 Evaluation", "content": "We evaluate ratings based on forward returns over 1, 3, 6, 12, and 18-month periods, including evaluations for market-relative and sector-relative returns. As described in Section 3.2, a rating is considered correct if the quantile for the true forward return aligns with the rating's rank. For example, let's take a rating for a given company (whether from an analyst or LLM), with a 6-month horizon. Suppose the stock was rated as a Strong Buy for the 6-month horizon, and the company's 6-month forward return falls in the bottom quantile (based on 6-month forward returns from the same date for all companies). This constitutes a significantly incorrect rating, as the company was amongst the worst performers in the market, but was rated as a Strong Buy. The ground-truth rating in this case would have been a Strong Sell. Conversely, if another method generated a rating of Hold for the same <company,date,horizon> combination, the rating would still be incorrect, but less severely so.\nWe compute the Mean Absolute Error (MAE) using two types of returns regular market-relative forward returns (these automatically become market-relative due to our quantile ranking evaluation), and sector-relative forward returns (where the subsector's forward return is subtracted from the asset return). MAE is appropriate for ordinal classification because it considers the magnitude of the error and accounts for how far a rating is from its true value."}, {"title": "5 RESULTS", "content": "Our findings from the month-wise breakdown of the market-relative MAE and sector-relative MAE across all methods. Figure 3 visualizes how the methods stack up to each other, including a snapshot comparison using the composite error (also listed in Table 1). Note that the figures are based on the market-relative MAE."}, {"title": "5.1 Traditional Analyst vs. Vanilla LLM", "content": "Figure 2 shows how analysts are heavily biased towards buy ratings, and only gave sell ratings less than 5% of the time. In Table 1, the Vanilla method has a lower MAE of 1.447 compared to the Analyst predictions, which has a Return MAE of 1.570. This indicates that the LLMs predictions, even with only basic financial data, are more accurate than those made by analysts. However, the standard deviation of the Vanilla method is 0.745, higher than the Analyst's 0.637, suggesting that while the predictions are more consistent, they are less accurate overall. Sector Return MAE and standard deviation follow the same trend. Figure 3 shows that errors for the Analyst predictions decrease as the look-ahead periods increase, with slightly better performance in the 18-month period, while errors for Vanilla experiment increase."}, {"title": "5.2 News: Summary vs. Sentiment", "content": "Table 1 shows that the News (Summary) experiment, which we provide the previous month's news summaries for the company and the sector, results with a Return MAE of 1.491 and a standard deviation of 0.738. The News (Sentiment) experiment, which we provide sentiment scores of the news summaries instead of summaries (scored on a scale of -5 to 5), results in a Return MAE of 1.496 and a standard deviation of 0.752. Interestingly, neither outperformed the Vanilla experiment. Additionally, we did not see improved performance when including summaries compared to only including their sentiment. The trends for Sector Relative Return MAE are consistent with the Return MAE metrics. Figure 3 shows that the News (Summary) experiment performs best in the 1-month period, outperforming all other experiments in both Return and Sector MAE. This suggests news summaries provide better short-term predictions, likely because we include summaries from the previous month, therefore offering a clearer picture of recent company performance. The News (Sentiment) experiment performs similarly to the News (Summary) experiment, indicating that incorporating sentiment does not significantly improve performance compared to news summaries."}, {"title": "5.3 Fundamentals vs. Fundamentals + Sentiment", "content": "Table 1 shows that the Fundamentals + Sentiment experiment has the best performance in terms of Return MAE, with a value of 1.417, indicating the most accurate predictions. The Fundamentals experiment has a Return MAE of 1.421 and a lower standard deviation of 0.732, indicating more consistent predictions.\nFigure 3 shows that both the Fundamentals and Fundamentals + Sentiment experiments consistently perform best across most months, particularly excelling in the 3, 6, and 12-month periods. This stable performance across horizons reinforces the benefits of incorporating fundamental financial data. The Fundamentals + Sentiment experiment outperforms in the 3 and 6-month periods, demonstrating that combining fundamentals and sentiment scores is effective in the short term but may lead to conflicting signals over longer periods, as indicated by the higher MAE in the 18-month period. Both models outperform the Vanilla experiment and Analyst predictions, highlighting the significant impact of financial fundamentals. Including company and sector sentiment, without"}, {"title": "5.4 Results Summary", "content": "Overall, for all LLM experiments (Vanilla, News (Summary), News (Sentiment), Fundamentals and Fundamentals + Sentiment), the errors increase as we make predictions further into the future, indicating that the LLMs are better at short-term predictions and struggle with longer-term forecasts. News-based experiments (especially News (Summary)) perform best in the short term due to the immediate impact of news. We find that the News (Sentiment) experiment generally performs similarly to the News (Summary) experiment, indicating that incorporating sentiment analysis does not significantly improve performance compared to providing news summaries. Fundamentals and Fundamentals + Sentiment experiments also perform similarly, excelling in the medium term. Finally, Analyst predictions show the best performance over longer periods."}, {"title": "5.5 Efficacy of News", "content": "To understand the impact of news summaries on the results, we compute the Spearman correlation and generate heatmaps for the news summaries and news sentiment. In the News experiment, we ask the LLM to provide a rating for the company news summary and the sector summary before predicting the stock ratings. For the Sentiment experiment, we score each sector and news summary for its sentiment and then provide these sentiment scores during inference instead of the news summaries. In both cases, we observe that news summaries are correlated across months, especially with the periods closer to the rating. Additionally, the heatmaps Figure 4 reveal that LLM ratings are correlated with the predictions made"}, {"title": "5.6 Challenges and Limitations", "content": "One limitation of this study is our method of evaluating ratings, which is based on forward returns over fixed periods and the quantiles into which these returns fall. These returns could be sensitive to market conditions, which might experience abnormal shifts on specific days, thereby affecting the evaluation. Additionally, there are other factors that determine if the ratings were correct or not, which might be more qualitative than quantitative, such as market sentiment, company-specific news, and broader economic indicators. Moreover, our approach to evaluating the analysts was tricky since we did not have the exact target date for the ratings (hence an assessment with varied time horizons). Another challenge is that we did not provide the model with many essential factors that analysts consider, such as projections of future performance, earnings call reports, investor sentiment, and other qualitative assessments. Additionally, we did not test the model's ability to process and understand extremely large amounts of information, which analysts often review in their evaluations."}, {"title": "6 CONCLUSION", "content": "This study explores the potential of LLMs to predict stock ratings, a novel application within the finance sector. By integrating various types of information, including basic financial metrics, technical indicators, financial news summaries financial news sentiment, and financial fundamentals, we aim to evaluate the performance of LLMs in this task and understand which data sources enhance or hinder their predictive capabilities.\nKey Findings:\n(1) The benchmark Vanilla LLM model, which uses basic financial metrics, demonstrates stronger performance than traditional analyst evaluations when assessed by forward returns.\n(2) The Fundamental LLMs outperformed all experiments, highlighting the significant impact of financial fundamentals on prediction accuracy. Additionally, combining sentiment scores with this data, without the full news summaries, further improved prediction accuracy.\n(3) Integrating news summaries and sentiment analysis provides some short-term predictive benefits but does not significantly improve long-term prediction accuracy when compared to the Vanilla model.\n(4) The performance difference between adding news as text versus news sentiment to the LLM is very small when other data is not included (i.e. Fundamentals), indicating that both approaches offer similar benefits.\n(5) LLMs perform better in short-term predictions, which encourages further exploration of their capabilities for shorter period company predictions.\n(6) News summaries are more beneficial for short-term predictions, while traditional analysts perform better over longer horizons.\nOur findings highlight the significant potential of LLMs to provide accurate and interpretable predictions for stock ratings. Future work will focus on using longer windows for news summaries, summarizing over extended periods to provide a more comprehensive context. Additionally, we will further explore the capability of LLMs in short-term predictions and develop strategies to enhance their long-term forecasting abilities."}]}