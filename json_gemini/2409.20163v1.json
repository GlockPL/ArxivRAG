{"title": "MemSim: A Bayesian Simulator for Evaluating Memory of LLM-based Personal Assistants", "authors": ["Zeyu Zhang", "Quanyu Dai", "Luyu Chen", "Zeren Jiang", "Rui Li", "Jieming Zhu", "Xu Chen", "Yi Xie", "Zhenhua Dong", "Ji-Rong Wen"], "abstract": "LLM-based agents have been widely applied as personal assistants, capable of memorizing information from user messages and responding to personal queries. However, there still lacks an objective and automatic evaluation on their memory capability, largely due to the challenges in constructing reliable questions and answers (QAs) according to user messages. In this paper, we propose MemSim, a Bayesian simulator designed to automatically construct reliable QAs from generated user messages, simultaneously keeping their diversity and scalability. Specifically, we introduce the Bayesian Relation Network (BRNet) and a causal generation mechanism to mitigate the impact of LLM hallucinations on factual information, facilitating the automatic creation of an evaluation dataset. Based on MemSim, we generate a dataset in the daily-life scenario, named MemDaily, and conduct extensive experiments to assess the effectiveness of our approach. We also provide a benchmark for evaluating different memory mechanisms in LLM-based agents with the MemDaily dataset. To benefit the research community, we have released our project at https://github.com/nuster1128/MemSim.", "sections": [{"title": "1 Introduction", "content": "In recent years, large language model (LLM) based agents have been extensively deployed across various fields [1\u20136]. One of their most significant applications is serving as personal assistants [7], where they engage in long-term interactions with users to address a wide range of issues [8, 9]. For LLM-based personal assistants, memory is one of the most significant capability [10]. To perform personal tasks effectively, these agents must be capable of storing factual information from previous messages and recalling relevant details to generate appropriate responses. For example, a user Alice might tell the agent, \"I will watch a movie at City Cinema this Friday in Hall 3, Row 2, Seat 9.\" When Friday arrives, she might ask the agent, \"Where is my movie seat?\" Then, the agent should recall the relevant information (i.e., the seat number) to generate an appropriate response to Alice.\nPrevious research has proposed methods for constructing the memory of LLM-based agents [11, 12, 8, 13, 14]. However, there remains a lack of objective and automatic methods to evaluate how well personal assistants can memorize and utilize factual information from previous messages, which is crucial for developing memory mechanisms. One conventional solution is to collect messages from real-world users, and manually annotate answers to human-designed questions based on these messages. However, it requires substantial human labor that lacks scalability. Another solution is to generate user messages and question-answers (QAs) with LLMs. However, the hallucination of LLMs"}, {"title": "2 Related Works", "content": "LLM-based agents have been extensively utilized across various domains, marking a new era for artificial personal assistants [7]. For LLM-based personal assistants, memory is a critical component that enables agents to deliver personalized services. This includes storing, managing, and utilizing users' personal and historical data [10, 11, 14, 16]. For instance, MPC [9] suggests storing essential factual information in a memory pool with a summarizer for retrieval as needed. MemoryBank [11] converts daily events into high-level summaries and organizes them into a hierarchical memory structure for future retrieval. These approaches primarily aim to enhance agents' memory capability.\nPrevious studies have also attempted to evaluate the memory capability of LLM-based agents, but there still exist limitations. Some studies use subjective methods, employing human evaluators to score the effectiveness of retrieved memory [9, 11, 17]. However, this approach can be costly due to the need for evaluators and may introduce biases from varying annotators. Other studies use objective evaluations by constructing dialogues and question-answer pairs [13, 18, 19], but these methods still require human involvement for creating or editing the QAs. Therefore, how to construct reliable QAs according to user messages automatically is significant for the objective evaluation.\nSome previous studies construct knowledge-based question-answering (KBQA) datasets to assess Retrieval-Augmented Generation (RAG) [20, 21], which is relative to the data generation for memory"}, {"title": "3 Methods", "content": "Our final goal is to evaluate memory mechanisms of LLM-based personal assistants in an objective and automatic way. The whole pipeline is demonstrated in Figure 1. First of all, we propose MemSim that can simulate users and generate evaluation datasets, mainly including the Bayesian Relation Network and a causal generation mechanism. Then, we employ MemSim to create a dataset in the daily-life scenario, named MemDaily. Finally, we construct a benchmark that evaluates different memory mechanisms of LLM-based agents based on MemDaily. In this section, we will deliver the details of MemSim and MemDaily, while the evaluation benchmark will be presented in Section 5."}, {"title": "3.1 Overview of MemSim", "content": "In order to construct reliable QAs from generated user messages, we propose a Bayesian simulator named MemSim, which includes two primary components. First, we develop the Bayesian Relation Network to model the probability distribution of users' relevant entities and attributes, enabling the sampling of diverse hierarchical user profiles. Then, we introduce a causal mechanism to generate user messages and construct reliable QAs based on these sampled profiles. We design various types of QAs for comprehensive memory evaluation, including single-hop, multi-hop, comparative, aggregative, and post-processing QAs, incorporating different noises to simulate real-world environments. Based on the constructed QAs and generated user messages, researchers can objectively and automatically evaluate the memory capability of LLM-based personal assistants on factual information from previous messages, which can be helpful in developing advanced memory mechanisms."}, {"title": "3.2 Bayesian Relation Network", "content": "We introduce Bayesian Relation Network (BRNet) to model the probability distribution of users' relevant entities and attributes, where we sample hierarchical profiles to represent simulated users (see Figure 1(a)). Specifically, we define a two-level structure in BRNet, including the entity level and the attribute level. The entity level represents user-related entities, such as relevant persons, involved events, and the user itself. At the attribute level, each entity comprises several"}, {"title": "Assumption 1 (Local Markov Property)", "content": "BRNet satisfies the local Markov property, which states that\n$X_t\\perp X_{des(X_t)}|par(X_t), \\forall X_t \\in \\mathcal{X}$,\nwhere $des(X_t)$ denotes the non-descendant set of $X_t$, $par(X_t)$ denotes the parent set of $X_t$, and the notation $\\perp$ indicates the variables are conditionally independent."}, {"title": "Theorem 1 (Factorization)", "content": "The joint probability distribution of BRNet can be expressed as\n$P(X_1, X_2, ..., X_{|\\mathcal{X}|}) = \\prod_{X_t \\in \\mathcal{X}} P(X_t|par(X_t))$,\nwhere $par(X_t)$ denotes the set of parent attributes of $X_t$."}, {"title": "Assumption 2 (Conditional Sampling)", "content": "In BRNet, an attribute can be sampled from the conditional probability distribution given its parent attributes. Specifically, we have\n$X_t \\sim P(X_t|par(X_t)), \\forall X_t \\in \\mathcal{X}$,\nwhere the conditional probability distribution can be expressed in either explicit or implicit forms."}, {"title": "Theorem 2 (Ancestral Sampling)", "content": "For BRNet, the result of ancestral sampling is equivalent to that of sampling from the joint probability distribution. Specifically, we have\n$P(x_1, x_2, ..., x_{|\\mathcal{X}|}) = P(X_1, X_2, ..., X_{|\\mathcal{X}|})$,\nwhere $x_1, x_2, ..., x_{|\\mathcal{X}|} \\sim P(X_1, X_2, ..., X_{|\\mathcal{X}|})$ are sampled from the joint probability distribution."}, {"title": "3.3 Causal Generation Mechanism", "content": "Based on hierarchical user profiles, we propose a causal generation mechanism to generate user messages, and construct reliable QAs corresponding to them. Here, causal indicates that the generation of user messages and the construction of QAs are causally dependent on the same informative hints that are also causally derived from hierarchical user profiles. Specifically, we define a piece of hint as a triple $(A^i, A_j, x_j)$ that provides factual information in a structural format. In other words, the hierarchical user profiles provide a structural foundation to get different hints, which then provide a set of relevant information as the causation of both user messages and QAs, shown in Figure 1(b).\nConstruction of Informative Hints. We construct the hints of factual information based on hierar- chical user profiles before creating the user messages and QAs. We select a target entity $A_t$ at the entity-level, and choose $l_t$ attributes $\\{K_1^i, K_2^i, ..., K_{l_t}^i\\} \\subseteq A_t$ along with their corresponding values $\\{v_1^i, v_2^i, ..., v_{l_t}^i\\}$ from the attribute-level profiles. Then, we reformulate them into a list of triple hints $\\mathcal{H}_t = \\{(A_t, K_j^i, v_j^i)\\}_{j=1}^{l_t}$. For some complex types of QAs, we choose more than one target entities, and concatenate their lists of hints. For better demonstration, we re-index the final list of hints as $\\mathcal{H} = \\{(A^{(j)}, K^{(j)}, v^{(j)})\\}_{j=1}^{l}$, where $l$ is the number of hints in the final list.\nConstruction of User Messages. Based on the j-th hint $(A^{(j)}, K^{(j)}, v^{(j)}) \\in \\mathcal{H}$, we construct the corresponding user message $m^{(j)}$ with LLM, where we have $m^{(j)} = LLM(A^{(j)}, K^{(j)}, v^{(j)})$. Here, the LLM only serves the purpose of rewriting structural hints, without any reasoning process. For example, if the hint is (my uncle Bob, occupation, driver), the generated user message might be \"The occupation of my uncle Bob is a driver\". We generate user messages for all the hints in $\\mathcal{H}$, and we finally get the list of user messages $\\mathcal{M} = \\{m^{(i)}\\}_{i=1}^{l}$\nConstruction of Questions and Answers. In order to evaluate the memory capability of LLM-based personal assistants more comprehensively, we propose to construct five representative types of QAs to cover various complexities in real-world scenarios, as detailed in Table 1. For each question q, we provide three forms of ground truths: (1) the textual answer a that can correctly respond to q, (2) the correct choice a among confusing choices a' (generated by LLM) as a single-choice format, and (3) the correct retrieval target h\u2286 M that contains the required factual information to the question."}, {"title": "(i.) Single-hop QA", "content": "Single-hop QA is the most basic type of QAs, relying on a single piece message to directly answer the question. In constructing QA, we randomly select the j-th hint $(A^{(j)}, K^{(j)}, v^{(j)})$ and generate the question $q = LLM(A^{(j)}, K^{(j)})$ through LLM rewriting, where the answer is $a = v^{(j)}$. Correspondingly, the retrieval target is $h = \\{m^{(j)}\\}$."}, {"title": "(ii.) Multi-hop QA", "content": "Multi-hop QA necessitates the use of multiple messages to determine the correct answer, making it more complex than single-hop QA. In constructing Multi-hop QA, we first sample two hints $(A^{(j)}, K^{(j)}, v^{(j)})$ and $(A^{(k)}, K^{(k)}, v^{(k)})$ from the same bridge entity $A_t$ (i.e., $A^* = A^{(j)} = A^{(k)})$. We then mask this bridge entity and generate the question $q = LLM(K^{(j)}, v^{(j)}, K^{(k)})$ through LLM rewriting, where the answer is $a = v^{(k)}$. The target message set is $h = \\{m^{(j)}, m^{(k)}\\}$. By incorporating additional entities, the questions can be easily extended to more hops."}, {"title": "(iii.) Comparative QA", "content": "Comparative QA is an extensive type of multi-hop QA, which involves comparing two entities based on a shared attribute. We first select two hints $(A^{(j)}, K^{(j)}, v^{(j)})$ and $(A^{(k)}, K^{(k)}, v^{(k)})$ from different entities with the same meaning attribute K (i.e., $A_j \\neq A_k$ and $K \\simeq K^{(j)} = K^{(k)})$. We then rewrite the question $q = LLM(A^{(j)}, A^{(k)}, K)$ by LLM, where the answer $a = f(K, v^{(j)}, v^{(k)})$ is derived from the function $f(\\cdot)$. The retrieval target is $h = \\{m^{(j)}, m^{(k)}\\}$."}, {"title": "(iv.) Aggregative QA", "content": "Aggregative QA is a general type of comparative QA, which requires aggregat- ing messages from more than two entities on a shared attribute. For construction, we choose d hints $\\{(A^{(jk)}, K, v^{(jk)})\\}_{k=1}^{d}$ from different entities with the same meaning attribute K. Then, we construct the question $q = LLM(\\{A^{(jk)}\\}_{k=1}^{d}, K)$, where we obtain the answer $a = f(K, \\{v^{(jk)}\\}_{k=1}^{d})$. The target message set should include all these related references, that is, $h = \\{m^{(jk)}\\}_{k=1}^{d}$"}, {"title": "(v.) Post-processing QA", "content": "Post-processing QA addresses situations where personal questions require additional reasoning steps for agents to answer, based on the retrieved messages. We first select two hints $(A^{(j)}, K^{(j)}, v^{(j)})$ and $(A^{(k)}, K^{(k)}, v^{(k)})$ from the same bridge entity $A_t$. We then design a reasoning factor $\\psi$ to generate the question $q = LLM(K^{(j)}, v^{(j)}, K^{(k)}, \\psi)$, and derive the answer $a = f(K^{(k)}, v^{(k)}, \\psi)$, where $\\psi$ specifies the reasoning process. For example, it could be \"the sum of the last five digits of the phone number $v^{(k)}$\". Similarly, the retrieval target will be $h = \\{m^{(j)}, m^{(k)}\\}$.\nInfusion of Noise in User Messages. We integrate two types of noise in user messages by concatena- tion, in order to simulate real-world circumstances. The first type is entity-side noise, which refers to noisy messages that contain the selected attributes from unselected entities. The second type is attribute-side noise, which involves noisy messages that describe unselected attributes of the selected entities. Both types of noise can impact agents' ability to retrieve messages and generate answers.\nEventually, we formulate the trajectory $\\xi = (\\mathcal{M}, q, a, a', h)$ by discarding all hints, where each trajectory serves as a test instance for evaluating the memory capability of LLM-based personal assistants. There are two insights into the causal generation mechanism. First, the factual information of messages and QAs are causally constructed from the shared hints that are sampled from user profiles, where LLMs are only responsible for rewriting based on the given information, rather than imagining or reasoning. This pipeline mitigates the impact of LLM hallucination on the factual information, keeping the reliability of QAs. It can also prevent contradictions among user messages from the same trajectory, because their hints are derived from the same user profile. Second, our method focuses on designing the asymmetric difficulty between constructing QAs (i.e., profiles hints\u2192messages, question and answer) and solving QAs (i.e., messages|question\u2192answer), which is critical for the automatic generation of evaluation datasets."}, {"title": "3.4 MemDaily: A Dataset in the Daily-life Scenario", "content": "Based on MemSim, we create a dataset in the daily-life scenario, named MemDaily, which can be used to evaluate the memory capability of LLM-based personal assistants, shown in Figure 1(c). Specifically, MemDaily incorporates 11 entities and 73 attributes (see details in Appendix D.1), all of which are representative and closely related to users' daily lives. We create 6 sub-datasets of different QA types mentioned previously: (1) Simple (Simp.): single-hop QAs. (2) Conditional (Cond.): multi-hop QAs with conditions. (3) Comparative (Comp.): comparative QAs. (4) Aggregative (Aggr.): aggregative QAs. (5) Post-processing (Post.): post-processing QAs. (6) Noisy: multi-hop QAs with additional irrelevant noisy texts inside questions. The summary of MemDaily is shown in Table 2, where we present the number of trajectories, user messages, questions, and TPM (tokens per message). More details and examples can be found in Appendix D."}, {"title": "4 Evaluations", "content": "In this section, we evaluate the quality of MemDaily, which can reflect the effectiveness of MemSim. Specifically, the evaluations are conducted in three parts: the user profiles, the user messages, and the constructed QAs. Besides, we also conduct comprehensive case studies in Appendix D."}, {"title": "4.1 Evaluation on User Profiles", "content": "The generated user profiles are supposed to express both rationality and diversity, which also directly influence the creation of user messages and QAs. Therefore, we evaluate these two aspects to reflect their quality. Rationality means that the user profiles should possibly exist in the real world, with no internal contradictions in their descriptions. Diversity indicates that the descriptions among users are distinct, covering a wide range of user types."}, {"title": "4.2 Evaluation on User Messages", "content": "We evaluate the quality of generated user messages in multiple aspects, including fluency, rationality, naturalness, informativeness, and diversity. The first four aspects are designed to assess the quality inside a trajectory, while the final one targets the variety across trajectories."}, {"title": "4.3 Evaluation on Questions and Answers", "content": "The primary challenge for constructing a reliable dataset is ensuring the accuracy of ground truths for the constructed questions. To assess the reliability of MemDaily, we sample approximately 20% of all the trajectories in MemDaily and employ human evaluators to verify the correctness of their ground truths. Specifically, the evaluators are required to examine three parts of the ground truths: textual answers, single-choice answers, and retrieval targets, and report their accuracy."}, {"title": "5 Benchmark", "content": "In this section, we create a benchmark based on the MemDaily dataset, in order to evaluate the memory capability of LLM-based personal assistants. Our benchmark sets various levels of difficulty by introducing different proportions of question-irrelevant daily-life posts."}, {"title": "5.1 Experimental Settings", "content": "Levels of Difficulty. We utilize the MemDaily dataset as the basis of our benchmark. In order to set different levels of difficulty, we collect question-irrelevant posts from social media platforms, and randomly incorporate them into user messages by controlling their proportions. Specifically, we denote MemDaily-vanilla as the vanilla and easiest one without extra additions, and create a series of MemDaily-n, where we use \u03b7 to represent the inverse percentage of original user messages. Larger \u03b7 indicates a higher level of difficulty in the benchmark. We primarily focus on MemDaily-vanilla and MemDaily-100 as representatives. We also conduct evaluations on MemDaily-10, MemDaily-50, and MemDaily-200, putting their experimental results in Appendix C.\nBaselines. We implement several common memory mechanisms for LLM-based agents according to previous studies [10], including (1) Full Memory (FullMem): saves all previous messages as a list and concatenates them into the prompt for LLM inference. (2) Recent Memory (ReceMem): maintains the most recent k messages and concatenates them into the prompt for LLM inference, also referred to as short-term memory. (3) Retrieved Memory (RetrMem): stores all previous messages using FAISS [34] and retrieves the top-k relevant messages for inclusion in the prompt for LLM inference, which is commonly used to construct long-term memory. Specifically, we use Llama-160m [35] to transform a message into a 768-dimensional embedding and compute relevance scores using cosine similarity [36]. (4) None Memory (NonMem): does not use memory for LLM inference. Additionally, we include two special baselines for reference: (5) Noisy Memory (NoisyMem): receives only untargeted messages. (6) Oracle Memory (OracleMem): receives only targeted messages. Here, the targeted messages indicate the messages in the ground truth retrieval target. For all methods, we use the open-source GLM-4-9B [37] as the foundational model for inference, as a result of its excellent ability in long-context scenarios.\nMetrics. We propose to evaluate the memory of LLM-based agents from two perspectives: effective- ness and efficiency. Effectiveness refers to the agent's ability to store and utilize factual information. The metrics for effectiveness include: (1) Accuracy: The correctness of agents' responses, measured by their ability to answer personal questions based on the factual information from historical user messages. (2) Recall@5: The percentage of messages in retrieval target successfully retrieved within the top-5 relevant messages. Efficiency mainly assesses the time cost associated with storing and utilizing information from memory. We use two metrics to evaluate efficiency: (1) Response Time: The time taken for an agent to respond after receiving a query, covering the retrieval and utilization processes. (2) Adaptation Time: The time required for an agent to store a new message."}, {"title": "5.2 Effectiveness of Memory Mechanisms", "content": "Accuracy of factual question-answering. The results of accuracy are presented in Table 6. FullMem and RetrMem demonstrate superior performance compared to other memory mechanisms, achieving high accuracy across both datasets. ReceMem tends to underperform when a large volume of noisy messages is present, as target messages may fall outside the memory window. We observe that agents excel with simple, conditional, post-processing, and noisy questions but struggle with comparative and aggregative questions. By comparing with OracleMem, we find the primary difficulty possibly lies in retrieving target messages. Even with accurate retrieval, aggregative questions remain challenging, indicating a potential bottleneck in textual memory. An interesting phenomenon we notice is that NoisyMem shows higher accuracy than NonMem in MemDaily-vanilla but lower accuracy in MemDaily-100. Similarly, FullMem unexpectedly outperforms OracleMem on simple questions in MemDaily. We suspect that LLMs may perform better with memory prompts of medium length, suggesting a potential limitation of textual memory mechanisms for LLM-based agents.\nRecall of target message retrieval. We implement three retrieval methods to obtain the most relevant messages and compare them with target messages to calculate Recall@5. Embedding refers to the retrieval process used in RetrMem. Recency considers the most recent k messages as the result. LLM directly uses the LLM to respond with the top-k relevant messages."}, {"title": "5.3 Efficiency of Memory Mechanisms", "content": "The results of efficiency are presented in Table 8 and Table 9. We find that RetrMem consumes the most response time in short-context scenarios, and FullMem also requires more time for inference due to longer memory prompts. However, the response time of FullMem increases significantly faster than that of other methods as the context lengthens. Regarding adaptation time, we observe that RetrMem requires substantially more time because it needs to build indexes in the FAISS system."}, {"title": "6 Limitations and Conclusions", "content": "In this paper, we propose MemSim, a Bayesian simulator designed to generate reliable datasets for evaluating the memory capability of LLM-based agents. MemSim comprises two primary components: The bayesian Relation Network and the causal generation mechanism. Utilizing MemSim, we generate MemDaily as a dataset in the daily-life scenario, and conduct extensive evaluations to assess its quality to reflect the effectiveness of MemSim. Additionally, we provide a benchmark on different memory mechanisms of LLM-based agents and provide further analysis. However, as the very initial study, there are several limitations. Firstly, our work focuses on evaluating the memory capability of LLM-based agents on factual information, but does not address higher-level and abstract information, such as users' hidden hobbies and preferences. Additionally, our evaluation does not include dialogue forms, which are more complex and challenging to ensure reliability. In future works, we aim to address these two issues within the benchmark."}, {"title": "A Proof in Bayesian Relation Network", "content": ""}, {"title": "A.1 Proof of Theorem 1", "content": ""}, {"title": "Theorem 1 (Factorization)", "content": "The joint probability distribution of BRNet can be expressed as\n$P(X_1, X_2, ..., X_{|\\mathcal{X}|}) = \\prod_{X_t \\in \\mathcal{X}} P(X_t|par(X_t))$,\nwhere $par(X_t)$ denotes the set of parent attributes of $X_t$.\nProof. Because BRNet is DAG, we can certainly find a topological ordering\n$\\mathcal{O} = [o_1, o_2, ..., o_{|\\mathcal{X}|}]$.\nThen, we inverse the sequence to get a reversed topologically ordering\n$\\widetilde{\\mathcal{O}} = [\\widetilde{o_1}, \\widetilde{o_2}, ..., \\widetilde{o_{|\\mathcal{X}|}}]$.\nThen, we utilize the theorem of conditional probability according to the order $\\widetilde{\\mathcal{O}}$, and we have\n$P(X_1, X_2, ..., X_{|\\mathcal{X}|}) = P(X_{\\widetilde{o_1}}|X_{\\widetilde{o_2}}, ..., X_{\\widetilde{o_{|\\mathcal{X}|}}}) P(X_{\\widetilde{o_2}}|X_{\\widetilde{o_3}}, ..., X_{\\widetilde{o_{|\\mathcal{X}|}}}) ... P(X_{\\widetilde{o_{|\\mathcal{X}|}}})$.\n$ = \\prod_{i=1}^{|\\mathcal{X}|} P(X_{\\widetilde{o_i}}|X_{[\\widetilde{o_{i+1}} : \\widetilde{o_{|\\mathcal{X}|}}]})$,\nwhere $X_{[\\widetilde{o_{i+1}} : \\widetilde{o_{|\\mathcal{X}|}}]}$ means all the variables after $\\widetilde{o_i+1}$ in the reversed topologically ordering, and there are no descendant variables inside. According to Assumption 1, we have\n$P(X_{\\widetilde{o_i}}|X_{[\\widetilde{o_{i+1}} : \\widetilde{o_{|\\mathcal{X}|}}]}) = P(X_{\\widetilde{o_i}}|par(X_{\\widetilde{o_i}}))$.\nFinally, we rewrite it and obtain\n$P(X_1, X_2, ..., X_{|\\mathcal{X}|}) = \\prod_{X_t \\in \\mathcal{X}} P(X_t|par(X_t))$."}, {"title": "A.2 Proof of Theorem 2", "content": ""}, {"title": "Theorem 2 (Ancestral Sampling)", "content": "For BRNet, the result of ancestral sampling is equivalent to that of sampling from the joint probability distribution. Specifically, we have\n$P(x_1, x_2, ..., x_{|\\mathcal{X}|}) = P(X_1, X_2, ..., X_{|\\mathcal{X}|})$,\nwhere $x_1, x_2, ..., x_{|\\mathcal{X}|} \\sim P(X_1, X_2, ..., X_{|\\mathcal{X}|})$ are sampled from the joint probability distribution.\nProof. We first calculate the reversed topologically ordering\n$\\widetilde{\\mathcal{O}} = [\\widetilde{o_1}, \\widetilde{o_2}, ..., \\widetilde{o_{|\\mathcal{X}|}}]$.\nThen, we have\n$P(x_1, x_2, ..., x_{|\\mathcal{X}|}) = \\prod_{i=1}^{|\\mathcal{X}|} P(x_{\\widetilde{o_i}}|x_{[\\widetilde{o_{i+1}} : \\widetilde{o_{|\\mathcal{X}|}}]})$\n$ = \\prod_{i=1}^{|\\mathcal{X}|} P(x_{\\widetilde{o_i}}|par(x_{\\widetilde{o_i}}))$.\nwhere $x_{[\\widetilde{o_{i+1}} : \\widetilde{o_{|\\mathcal{X}|}}]}$ means the values of all the variables after $\\widetilde{o_i+1}$ in the reversed topologically ordering. According to Assumption 2, we have\n$P(x_1, x_2, ..., x_{|\\mathcal{X}|}) = \\prod_{i=1}^{|\\mathcal{X}|} P(x_{\\widetilde{o_i}}|par(x_{\\widetilde{o_i}}))$\n$ = P(X_1, X_2, ..., X_{|\\mathcal{X}|})$."}, {"title": "B Extensive Evaluation on User Messages by GPT-4o", "content": "We also let GPT-4o score on user messages as a reference, and the results are shown in Table 10."}, {"title": "C Extensive Benchmark on More Composite Datasets", "content": ""}, {"title": "C.1 Results on MemDaily-10", "content": "The results of accuracy are shown in Table 11. The results of recall@5 are shown in Table 12. The results of response time are shown in Table 13. The results of adaptation time are shown in Table 14."}, {"title": "C.2 Results of MemDaily-50", "content": "The results of accuracy are shown in Table 15. The results of recall@5 are shown in Table 16. The results of response time are shown in Table 17. The results of adaptation time are shown in Table 18."}, {"title": "C.3 Results of MemDaily-200", "content": "The results of accuracy are shown in Table 19. The results of recall@5 are shown in Table 20. The results of response time are shown in Table 21. The results of adaptation time are shown in Table 22."}, {"title": "D Case Studies", "content": "In this section, we present several case studies to illustrate the effectiveness of the data generated by MemDaily. First, we will display the hierarchical user profiles generated from BRNet. Next, we will present examples of user messages created by our method. Finally, we will provide examples of questions and answers for each type."}, {"title": "D.1 Case Study on Generated User Profiles", "content": "In MemDaily, we incorporate 11 entities that cover 7 types, with 73 attributes of them. The summary of entities and attributes of MemDaily are provided in Table 23.\nWe introduce prior knowledge as several rules according to our scenarios to constrain among attributes. For example, a relative role is highly possible to share the same hometown with the user, because they are likely to come from the same place. All of these constraints are expressed in BRNet with causal relations. We generate 50 graphical user profiles and conduct observations, finding that most profiles align well with real-world users without contradictions.\nHere is a case of user profiles, and we translate them into English for better demonstration:"}, {"title": "An example of Generated User Profiles", "content": "User Profiles:\n(Gender) Male; (Name) Qiang Wang; (Age) 38; (Height) 166cm; (Birthday) December 1st.; (Hometown) Beijing; (Workplace) Shenzhen", "1": "n(Gender) Female; (Relationship) Supervisor; (Name) Yalin Zhao; (Age) 44; (Height) 165cm; (Birthday) Febrary 5th.; (Hometown) Chongqing; (Workplace) Shenzhen", "2": "n(Gender) Male; (Relationship) Colleague; (Name) Zhihong Sun; (Age) 39; (Height) 164cm; (Birthday) April 24th.; (Hometown) Chengdu"}, {"1": "n(Gender) Male; (Relationship) Cousin; (Name) Wei Zhang; (Age) 36; (Height) 169cm; (Birthday) July 15th.; (Hometown) Beijing; (Workplace) Hangzhou, Zhejiang; (Education) Doctor; (Occupation) Doctor; (Position) Chief Physician; (Company) West Lake Hospital; (Hobbies) Playing Video Games; (Personality) Patient; (Phone) 13225162475; (Email) zhangwei071"}]}