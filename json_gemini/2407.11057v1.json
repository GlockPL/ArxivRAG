{"title": "SPIN: SE(3)-Invariant Physics Informed Network for Binding Affinity Prediction", "authors": ["Seungyeon Choi", "Samgmin Seo", "Sanghyun Park"], "abstract": "Accurate prediction of protein-ligand binding affinity is crucial for rapid and efficient drug development. Recently, the importance of predicting binding affinity has led to increased attention on research that models the three-dimensional structure of protein-ligand complexes using graph neural networks to predict binding affinity. However, traditional methods often fail to accurately model the complex's spatial information or rely solely on geometric features, neglecting the principles of protein-ligand binding. This can lead to overfitting, resulting in models that perform poorly on independent datasets and ultimately reducing their usefulness in real drug development. To address this issue, we propose SPIN, a model designed to achieve superior generalization by incorporating various inductive biases applicable to this task, beyond merely training on empirical data from datasets. For prediction, we defined two types of inductive biases: a geometric perspective that maintains consistent binding affinity predictions regardless of the complex's rotations and translations, and a physicochemical perspective that necessitates minimal binding free energy along their reaction coordinate for effective protein-ligand binding. These prior knowledge inputs enable the SPIN to outperform comparative models in benchmark sets such as CASF-2016 and CSAR HiQ. Furthermore, we demonstrated the practicality of our model through virtual screening experiments and validated the reliability and potential of our proposed model based on experiments assessing its interpretability.", "sections": [{"title": "Introduction", "content": "The binding affinity (BA) of a small molecule to a target protein associated with a disease indicates whether the small molecule (a ligand) can become a new drug [9, 25]. The higher the BA, the stronger the binding to the target protein and the desired effect, which can be measured using biological tests. However, these methods are expensive and time consuming. Therefore, compared with biological testing, BA prediction using machine learning (ML) and deep learning (DL) may accelerate drug development and reduce costs [36]. Powered by this need, numerous studies have been conducted to predict BA, especially with a recent increase in efforts to predict BA by analyzing the three-dimensional structure of complexes formed between proteins and ligands [21]. This trend stems from research indicating that since the BA between a protein and a ligand is based on their interaction in 3D space, predicting BA through information derived from the three-dimensional structural characteristics of the protein and ligand is a rational approach [2, 17].\nDL models utilize various methods to represent the 3D structures of protein-ligand complexes for BA prediction and are primarily categorized into grid- and graph-based representations. The grid-based approach involves voxelizing the structure of the protein-ligand complex into a 3D grid format, after which it is commonly processed using 3D convolutional neural network (CNN) to predict the binding affinity [32, 40]. However, most grid-based representations do not contain the structural information of the complexes. Consequently, the CNN architecture becomes relatively inefficient in depicting the geometric intricacies of protein-ligand complexes. Furthermore, employing a 3D rectangular grid representation can generate high-dimensional sparse 3D matrices, potentially resulting in significant computational costs. To address these issues, recent research has focused on representing the structure of complexes in a graphical format to predict BA. This approach defines the atoms of the protein and ligand as nodes in a graph and assigns edge information to atom pairs that are within a certain distance threshold. Consequently, the complex is represented as either a single or multiple graphs, enabling the operation of graph neural network models [13, 24, 29, 39]. However, traditional methods that consider only the connectivity information between atoms fail to adequately model the spatial information of complexes. Additionally, the need to define numerous preset rules to handle complex geometric features limits the model's flexibility when encountering unseen samples during training. Therefore, designing a model that efficiently models the complex information of the protein-ligand complex, ensuring it has excellent generalization capabilities, is essential.\nApplying the concept of Physics-Informed Neural Network (PINN) [8, 12] to BA prediction can be a promising approach to enhancing model generalization performance by incorporating domain knowledge inherent in the protein-ligand complex into the prediction model. Specifically, beyond relying solely on the empirical distribution of data for model training, defining the immutable governing laws of the real world as the inductive bias of the prediction model ensures robustness against noise in the training dataset. Furthermore, the same domain knowledge can be applied to unseen samples during training to achieve superior generalization performance [3]. In this research, the governing laws, or inductive biases, are defined in two categories. The first inductive bias, as shown in figure 1.(A), is based on the fundamental principle that the binding affinity of a protein-ligand complex remains constant despite SE(3)-transformations, such as rotations and translations. This inherently sensible law allows for more efficient modeling of the spatial information of the complex compared to some binding affinity prediction models that only input three-dimensional coordinates. The second inductive bias, illustrated in figure 1.(B), relies on the physicochemical principle that the binding free energy of a protein-ligand complex is located at the point where the energy is minimized among all possible geometric configurations of the protein and ligand [38]. These two governing laws represent domain knowledge that can be explained within the context of protein-ligand complexes and are immutable truths applicable equally in both training and testing scenarios. In this way, we propose SPIN, a graph transformer model that incorporates the SE(3)-invariant principle, which is invariant to rotation and translation, and the principle of minimal binding free energy, as its geometric and physicochemical inductive biases, respectively, to achieve high generalization performance. Consequently, we have validated that the SPIN outperforms other prediction models on two benchmark datasets. Extensive experiments have also allowed us to assess the interpretability and practicality of our proposed model. Our main contributions can be summarized as follows:\n\u2022 We propose SPIN, a novel binding affinity prediction model that is infused with essential prior knowledge applicable to various protein-ligand interactions, designed to achieve superior generalization performance.\n\u2022 To the best of our knowledge, this is the first model for predicting binding affinity where geometric and physicochemical knowledge are defined as inductive biases. This approach integrates empirical learning from deep learning with immutable truths applicable in reality, allowing for extreme efficiency with limited data. Furthermore, The trained prediction model inherently reflects the fundamental principles of protein-ligand binding.\n\u2022 SPIN achieves state-of-the-art (SOTA) performance in the CASF-2016 and CSAR-HiQ benchmarks, demonstrating the model's excellent interpretability and practicality through various experiments."}, {"title": "Related Work", "content": "The prediction of protein-ligand BA is indispensable in drug screening, wherein the selection of molecular structures that are viable as drug candidates from numerous molecular structures is crucial [25]. Recognizing this importance, numerous studies have proposed various methodologies for BA prediction owing to the advancements in ML and DL. Moreover, recent research, such as that involving AlphaFold [11, 34], which models the tertiary structure of proteins, has significantly enhanced the potential and possibility of studies that aim to predict binding affinities by modeling the three-dimensional structures of protein-ligand complexes [35]. This approach can be categorized into the following three types: ML-, CNN-, and GNN-based methods.\nML-based methods typically utilize predefined rules to extract descriptors from interactions within a certain distance between protein and ligand atoms, using ML models such as support vector regression and random forest, to predict BA [1]. However, these methods only consider atom pair interactions between proteins and ligands, neglecting the interactions within themselves and between multiple atom types. Thus, they fail to capture the rich spatial correlations in protein-ligand complexes. CNN-based methods transform the protein-ligand complex into a 3-D rectangular grid representation and implement a 3-D CNN model to extract features for BA prediction [32, 40]. Although this grid representation enables the mining of spatial and local correlations, it generate empty grid points where no atoms exist, causing inefficient computation and unnecessary memory usage. Furthermore, grid representations lack distance awareness and rotational invariance, which can render the prediction performance unstable. To address these issues, GNN-based methods have been developed for BA prediction [24, 39, 16, 23]. The GNN approaches define the atoms of proteins and ligands as nodes in a graph, and atom pairs within a certain distance threshold are connected with edge information, representing the complex as a single graph or multiple graphs for processing by GNN models. Recent efforts also directly input the 3D coordinates of atoms to predict binding affinity [5], and additional research aims to map various spatial features of the complex to more deeply learn its geometric characteristics [13, 14]. However, these methods can be sensitive to rotations and translations of the complex or may struggle to flexibly handle various geometric combinations not encountered during training due to too many predefined rules. To overcome the absence of generalization, our goal is to introduce various inductive biases into the predictive model. These inductive biases are intended to enable the model to account for unseen geometrical configurations and ensure robustness against variations in complex orientation and position, thus enhancing the model's predictive accuracy and generalization capabilities across different protein-ligand complexes."}, {"title": "PINN", "content": "Deep learning models have achieved tremendous success in various domains such as computer vision and natural language processing. However, the traditional approach of learning from large amounts of data still faces challenges in extracting interpretable information. Additionally, while existing data-driven approaches may align well with observations in training data, predictions from models can be physically inconsistent or result in impossible values, leading to reduced generalization performance. This issue is especially pronounced in domains like physics and fluid dynamics, where data collection is relatively difficult, unlike in fields with vast amounts of data such as image processing or natural language processing.\nTo address these issues, some domains are actively researching physics-informed neural network (PINN), which integrate governing physical laws and domain knowledge into deep learning models [12, 22, 27, 4]. Integrating domain knowledge into DL models means defining laws applicable to a domain as inductive biases during the model's training process. This ensures that the DL model implicitly satisfies these predefined laws during learning and inference. Even if the training dataset contains outliers or noise, integrating these immutable truths applicable to the real world can enhance the model's robustness. Consequently, the trained model can make more realistic predictions by training on not just empirical information from the dataset but also incorporating prior domain knowledge. This not only improves model generalization but also uses prior knowledge to illuminate the inner mechanisms of deep learning and provide theoretical insights [30, 7]. Especially in studies predicting the interactions between proteins and ligands, research has been conducted that integrates physicochemical prior knowledge related to binding free energy to apply the PINN framework [23]. This research achieved high generalization performance in the model by defining the physical law that the positions of the atoms in the ligand within the experimentally validated protein-ligand complex structure are located at the local minimum of the potential energy as prior knowledge, i.e., inductive bias, of the prediction model. However, this model has a clear limitation in that it considers only the connection information between the protein and the ligand, failing to model the geometric information between the two structures."}, {"title": "Preliminaries", "content": "Given a protein-ligand comlex as shown in Figure2.(B), we define the feature of atom node of protein and ligand as $V_P \\in \\mathbb{R}^{N \\times D_F}$ and $V_L \\in \\mathbb{R}^{N \\times D_F}$ with position matrix $x \\in \\mathbb{R}^{(N+M)\\times 3}$. The protein atom features include atom type, amino acid types and whether the atoms are backbone atoms. The ligand atom features include atom type, hybridzation, formal charge, degree and whether the atoms are aromatic atoms. The knn graph is utilized to define edges $e_{ij}$ between atoms based on the 3D coordinates of each atom. $e_{ij}$ is represented as a 4-dim one-hot vector, denoting connections between protein atoms, connections between ligand atoms, protein-ligand connections, and ligand-protein connections.\nOur goal is to predict the binding affinity, i.e., how strongly a protein and ligand bind, given the structure of a protein-ligand complex. To achieve this, we construct and train a regression model $\\Phi: (V_P, V_L, x) \\rightarrow y$ that predicts the binding affinity using the features of the atoms composing the protein and ligand in the given complex, $V_P, V_L$, and the 3D coordinates of the atoms, $x$."}, {"title": "Method", "content": "To achieve a predictive model with high generalizability, it is important to define as the model's inductive bias the prior knowledge that encompasses the real-world or the datasets being used, in addition to empirical learning based on datasets. For this purpose, we inject into the predictive model inductive biases from both geometric and physicochemical perspectives. The overall framework can be seen in Figure 2. More specifically, as shown in Figure 2.C, it is possible to internalize a geometric inductive bias that satisfies SE(3)-invariant characteristics by utilizing the SE(3)-graph transformer, and in Figure 2.E2, it can satisfy the physicochemical inductive bias by enforcing the condition that the binding free energy should be minimized at the given complex position.\nThe statement below outlines the proposition necessary for the overall framework to satisfy the characteristic of being SE(3)-invariant.\nDenoting the SE(3)-transformation as $T_g$, let's $f(x)$ be an SE(3)-invariant function, i.e., $f(x) = f(T_g(x))$. If function $g(x)$ is SE(3)-invariant function, i.e., $g(x) = g(T_g(x))$, then we have composition function $g(f(x))$ is also SE(3)-invariant function, i.e., $g(f(x)) = g(f(T_g(x)))$.\nHere, $f(x)$ refers to the SE(3)-invariant graph transformer, and $g(x)$ denotes the SE(3)-invariant prediction function that ultimately predicts the BA. This proposition indicates the conditions necessary for the proposed framework to possess SE(3)-invariant characteristics overall when performed across multiple functions. The following sections will detail the operation of an SE(3)-invariant graph transformer (Section 4.2), how the function predicting binding affinity can satisfy physical laws (Section 4.3), and whether that function is SE(3)-invariant (Section 4.3)."}, {"title": "SE(3)-Invariant Graph Transformer", "content": "We first encode the types (V) of the atoms composing the given protein and ligand individually through an embedding layer, as below.\n$h_p = \\text{Linear}(V_P) \\in \\mathbb{R}^{N \\times D_E}$\n$h_l = \\text{Linear}(V_L) \\in \\mathbb{R}^{M \\times D_E}$\n$h^0 = [h_l || h_p]$\t(1)\nHere, the result of concatenating $h_l$ and $h_p$, denoted as $h^0$, becomes the initial hidden representation that serves as the input to the SE(3)-Invariant graph transformer. Subsequently, to update the representation of each node, we define the SE(3)-invariant graph transformer layer, which is invariant to SE(3)-transformation, as follows.\n$h_i^{l+1} = h_i^l + \\sum_{j \\in V, i \\ne j} f_h(x_i - x_j, h_i^l, h_j^l, e_{ij}; \\Theta_h)$\t(2)\nwhere $h_i^l$ is the hidden representation vector for atom $i$ at the $l$th layer and $||x_i - x_j||^2$ is the euclidean distance between two atom $i$ and $j$. The update function $f_h$ computes messages for updating the node state after aggregating information from neighboring nodes using attention operations as follows.\n$f_h = \\text{Attn}(q_i, k_j, v_j) \\cdot \\text{Linear}(r_{ij})$\n$q_i = \\text{Linear}(h_i^l)$\n$k_j = \\text{Linear}([r_{ij} || e_{ij} || h_i^l || h_j^l])$\n$v_j = \\text{Linear}([r_{ij} || e_{ij} || h_i^l || h_j^l])$ \t(3)\nHere, $q_i, k_j$, and $v_j$ represent the query, key, and value matrices for the attention operation, respectively, and $r_{ij}$ is defined as the distance embedding with radial basis functions located at 20 centers between 0\u00c5 and 10\u00c5. The final atom hidden representation $h^L$ becomes the node state where spatial information of neighboring atoms is aggregated, explicitly considering the relationships between protein and ligand atoms."}, {"title": "SE(3)-Invariant Physics-informed Prediction", "content": "The obtained final representation vectors of protein and ligand atoms are used to model the pairwise interaction between the protein and ligand. For conciseness, we denote the final representation vector of the atoms constituting the ligand as $h_l$, and the atoms constituting the protein as $h_p$. The protein-ligand binding affinity can be converted as the sum of the atom pairwise van der Waals interaction energy between the protein and the ligand [6]. To achieve this, we calculate the protein-ligand interaction matrix H through the matrix multiplication of $h_M$ and $h_p$, which are outputted by the SE(3)-invariant graph transformer, as shown in Figure 4.D and as described in Equation (4).\nAdditionally, we model the van der Waals interaction by calculating the pairwise distance between protein atoms and ligand atoms, along with the interaction matrix H. The van der Waals ineteraction energy can be formulated as in Equation (5) through the Lennard-Jones potential fomula.\n$H = h_l h_p^T$ \t(4)\n$E^{VDW} = \\sum_{i,j} \\left[ \\left(\\frac{u_{ij}+H_{ij}}{||x_i - x_j||^6}\\right)^{12}-\\left(\\frac{u_{ij}+H_{ij}}{||x_i - x_j||^6}\\right)^{6}\\right]$\t(5)\nHere, $u_{ij}$ refers to the sum of the van der Waals radii of the i-th ligand atom and the j-th protein atom. The van der Waals radii for each atom type were obtained from the parameters of X-score [37]. Thus, $E^{VDW}$ can be calculated as a combination of parameters parameterized by the SE(3)-invariant transformer and the parameters of a physics formula utilizing the positional information of the protein-ligand complex.\nAn important point here is that for the overall framework of binding affinity prediction to be invariant to the rotation and translation of 3D objects, the sum of the protein-ligand pairwise interactions we model must also be invariant to translation and rotation. To this end, we prove below that the interaction we model is SE(3)-invariant.\nLet $T_g(x)$ can be written explicitly as $T_g(x) = Rx + b$, where $R \\in \\mathbb{R}^{3 \\times 3}$ is the rotation matrix and $b \\in \\mathbb{R}^3$ is the translation vector.\n$\\sum_{i,j} f(R x_i + b, Rx_j + b) = \\sum_{i,j} f(R (x_i - x_j)) = \\sum_{i,j} f(x_i - x_j)$\n$\\sum_i^{N} \\sum_j^{M} \\left[ \\left(\\frac{u_{ij}+H_{ij}}{||(R x_i + b) -(R x_j + b)||^2}\\right)^{12}-\\left(\\frac{u_{ij}+H_{ij}}{||(R x_i + b) -(R x_j + b)||^2}\\right)^{6}\\right] = \\sum_i^{N} \\sum_j^{M} \\left[ \\left(\\frac{u_{ij}+H_{ij}}{||R (x_i - x_j)||^2}\\right)^{12}-\\left(\\frac{u_{ij}+H_{ij}}{||R (x_i - x_j)||^2}\\right)^{6}\\right] = \\sum_i^{N} \\sum_j^{M} \\left[ \\left(\\frac{u_{ij}+H_{ij}}{(x_i-x_j) R^T R (x_i - x_j)}\\right)^{12}-\\left(\\frac{u_{ij}+H_{ij}}{(x_i-x_j) R^T R (x_i - x_j)}\\right)^{6}\\right] = \\sum_i^{N} \\sum_j^{M} \\left[ \\left(\\frac{u_{ij}+H_{ij}}{(x_i-x_j) I (x_i - x_j)}\\right)^{12}-\\left(\\frac{u_{ij}+H_{ij}}{(x_i-x_j) I (x_i - x_j)}\\right)^{6}\\right] = \\sum_i^{N} \\sum_j^{M} \\left[ \\left(\\frac{u_{ij}+H_{ij}}{||(x_i-x_j)||^2}\\right)^{12}-\\left(\\frac{u_{ij}+H_{ij}}{||(x_i-x_j)||^2}\\right)^{6}\\right]$\nThe optimization strategy of SPIN is derived in two directions from the sum of the previously calculated protein-ligand pairwise interactions (equal to the binding energy) as follows.\n$\\hat{y} = \\sigma \\cdot E^{VDW}$\n$L_a = \\sum (y - \\hat{y})^2$\t(6)\n$L_p = \\sum_{i,j} \\left[ \\frac{d E^{VDW}}{d ||x_i - x_j||} \\right]^2 = \\sum_{i,j} \\left[ \\frac{C_{ij} \\left(\\frac{12}{||x_i - x_j||^2}\\right) \\left(\\frac{u_{ij} + H_{ij}}{||x_i - x_j||^2} \\right)^{11}-\\left(\\frac{6}{||x_i - x_j||^2}\\right) \\left(\\frac{u_{ij} + H_{ij}}{||x_i - x_j||^2} \\right)^{5}\\right]^2$\t(7)\nThe first direction is to minimize the mean squared error between the predicted binding energy-derived binding affinity and the experimental binding affinity as shown in Figure.E\u2081 ($\\sigma$ is a trainable parameter). The second direction involves enforcing a term that satisfies the laws of physics between the protein and ligand, specifically by ensuring the derivative of the binding free energy with respect to the distance between ligand and protein atoms is zero as shown in Figure.E2. This approach is designed to fulfill the prior knowledge that the modeled complex, as an experimentally elucidated structure, is located at the minimum point of the binding free energy at that reaction coordinate. Ultimately, the total objective function L is defined as $L_a + L_p$."}, {"title": "Experiments", "content": "For BA prediction, the PDBbind v2020 [19] dataset was used as the training dataset and it provided the 3D crystal structures of protein-ligand complexes with experimentally determined BAs. The 3D crystal structures were represented by the coordinates of the atoms constituting the protein and ligand, comprising 19,443 samples. To evaluate the performances of the proposed and comparison models, we used the CASF-2016 [33] and CSAR-HiQ [28] benchmark sets. Similar to PDBbind, these datasets provide the 3D crystal structures of protein-ligand complexes and their BAs. In accordance with previous studies, the CASF-2016 and CSAR-HiQ sets comprised 285 and 343 samples, respectively, and duplication in the training dataset was avoided by removing these samples. During training, the most recent samples were defined as the validation set to verify the generalizability, as has been done in recent studies [31].\nThe key/value/query embedding in the SE(3)-invariant graph transformer, a component of SPIN, is obtained through a 2-layer MLP with layer normalization and ReLU activation. The transformer has 16 layers, and the hidden dimension and the number of heads are each 128 and 9, respectively. Additionally, the swish [26] function was used as the activation function for each layer. We have implemented an exponential decay of the learning rate, using a factor of 0.6 and setting a minimum of 1e-6 for the learning rate with Adam. If the validation loss does not improve over 20 consecutive evaluations, the learning rate is reduced. Our model training was conducted on a single NVIDIA GeForce GTX 3090 GPU."}, {"title": "Performance Evaluation", "content": "First, the proposed SPIN was compared with the existing baseline models on two benchmark datasets. As shown in Table 1, it achieves the best performance across all four metrics for the two benchmark datasets. CNN-based methods, such as Pafnucy [32], lack generalizability on benchmark datasets because they are not invariant to rotations and translations of the complex. SGCN[5], a GNN-based method utilizes spatial structures but directly inputs coordinates for predictions, encounters similar issues as CNN-based models and is sensitive to rotations and translations, thus exhibiting comparable performance levels. The Graphtrans[39], NL-GCN[18], PIGNet[23], and CMPNN[29] models are not ideal for BA prediction because they rely solely on connectivity information without modeling the geometric characteristics of the 3D space. The SIGN[13] and GIANT[14] models incorporate various modules to better capture the spatial information of proteins and ligands by considering distance and angle information. However, since they follow a method based on predefined rules obtained from training data, they are not flexible enough to handle various complex structures that are not present in the training data. Especially, the result that the proposed model, SPIN, achieved a 30% improvement over the best baseline models on the CSAR set, which is comparatively difficult to generalize across all comparison models, suggests that injecting inductive biases from various perspectives into the prediction model plays a crucial role in generalizing to unseen datasets. An interesting observation is that another model, PIGNet[23], which defines physicochemical laws as the inductive bias of the prediction model, also achieved relatively high performance on the challenging CSAR set compared to other comparison models. This reaffirms the importance of defining physicochemical information as the inductive bias of the prediction model from the perspective of applications that require predicting binding affinity for various complexes. However, because this model does not clearly model the spatial information of complex structures, it still shows inferior performance in the CASF-2016, indicating it is not ideal as a model for predicting binding affinity.\nPIGNet, which defines physicochemical laws as the inductive bias of the prediction model, significantly outperformed the other models on the challenging CSAR set. This validates the importance of defining physicochemical information as the inductive bias of the prediction model based on BA prediction for various complexes. PIGNet did not represent the spatial information of complex structures; however, it exhibited inferior performance on CASF-2016, indicating its unsuitability for BA prediction."}, {"title": "Ablation Study", "content": "In this section, we conduct an ablation study on the SPIN model to verify the importance of each component. SPIN (w/o G) is a model from which the geometric inductive bias that satisfies SE(3)-invariance has been removed, SPIN (w/o P) is a model from which the physicochemical inductive bias concerning the Binding free energy minimum has been removed, and finally, SPIN (w/o GP) is a model with both types of inductive bias removed. We measured the performance of these four variant models, including the complete SPIN model, on two benchmark datasets. The results, as shown in Figure 3, confirm that both geometric and physicochemical inductive biases play essential roles in predicting binding affinity. Specifically, when comparing the performance of SPIN (w/o G) and SPIN (w/o P), it is revealed that the geometric inductive bias, namely the condition that the binding affinity remains invariant to the rotation and translation of the protein-ligand complex, is the most critical component for prediction performance. It is an interesting observation that the physicochemical inductive bias shows better synergy when conditions for reasonably modeling the complex's geometric information are met. This outcome, considering that the binding free energy calculations are based on the complex's position in three-dimensional space, provides significant insights into the interplay between the two types of inductive biases."}, {"title": "Virtual Screening", "content": "Along with predicting the BA of a protein-ligand complex, correctly ranking multiple ligands based on their binding strength to the target protein is crucial in drug development. This facilitates the proper listing of the most promising drug candidates, thereby making the drug development process more efficient. For this purpose, we adopt the methodology of previous studies [15, 33] about CASF-2016 benchmark set to validate the practicality of SPIN. Specifically, we measure the ranking power, which is the ability of a scoring function to accurately rank known ligands of a specific target protein based on binding affinity when the precise binding pose is given. This approach allows us to rigorously assess the efficacy of SPIN in predicting binding affinities. The CASF2016 set comprises 57 protein clusters, each cluster containing five complexes that are bound to the same protein but exhibit markedly different binding affinities. Each cluster has pre-defined rankings based on the binding affinities for different ligands. In each cluster, rankings are established based on the binding affinities for different ligands, and we measure how accurately the predictive model inferences these rankings using the Spearman's rank correlation coefficient. The average of these coefficients across all clusters is defined as the ranking power for this experiment. We selected several scoring functions that are utilized in actual docking protocols as comparative models. Additionally, the Random Forest model, already trained on the CASF-2016 dataset, was excluded from this comparison [33]. As demonstrated in Figure 4, SPIN exhibits superior ranking power compared to the scoring functions of other docking programs. This indicates that our proposed model can effectively prioritize candidate compounds in real-world drug development scenarios."}, {"title": "Interpretability", "content": "To determine if the predictions output by a predictive model can be actively utilized in the drug development process with sufficient reliability, it is crucial to analyze the interpretability of the predictive model. Independent of the predictive performance in actual drug development, result validation can be challenging if the basis of the predicted BA is ambiguous, hindering the efficient development of subsequent processes, such as lead optimization [10]. To evaluate this, we utilize the pairwise interaction matrix H within the SPIN framework, which involves interactions between protein and ligand atoms. The protein-ligand interaction matrix $H_{ij}$ represents the binding energy between protein atom i and ligand atom j, where a lower value indicates stronger interaction between the two substructures.\nWe extract the amino acids of the protein corresponding to the lowest 10% of the energy values in the interaction matrix output by the trained predictive model. To substantiate the interpretability of SPIN, we focus our analysis on the 3bu1(PDB ID) protein-ligand complex, as illustrated in Figure 5.(a), by visualizing amino acids that engage in strong interactions. To confirm that these extracted amino acids are indeed engaged in actual intermolecular interactions, we compare our results with the findings from Discovery Studio's intermolecular interaction profiler. The amino acids corresponding to the lowest 10% of the energy values in SPIN's interaction matrix were specifically 21.A TYR, 37.A VAL, 51.A TYR, 94.A ASP, 96.A VAL, and 105.A TRP ( [residue index].A [amino acid]). These residues are hypothesized to be pivotal in the protein-ligand interactions during the predictive modeling performed by SPIN. Subsequent analysis corroborates that all of these amino acids indeed are engaged in hydrogen bonding or van der Waals interactions, precisely with those identified in Discovery Studio's profiling results, as depicted in Figure 5.(b). This concordance strongly indicates that SPIN not only accurately predicts binding affinity but also reliably identifies the biologically relevant interactions that underpin these predictions. This capability to discern and rationalize complex interactions in biological systems underscores the robust interpretability of SPIN, affirming its utility in predictive modeling within the biochemical research field. This validation lends significant credence to SPIN's application in computational drug discovery, demonstrating its potential to contribute effectively in the field by providing insights that are both predictive and interpretable."}, {"title": "Conclusion", "content": "In this work, we propose SPIN, a binding affinity prediction model infused with various inductive biases, designed to achieve excellent generalization performance from limited data. The model incorporates a geometric inductive bias that assumes binding affinity remains constant regardless of rotations and translations in three-dimensional space, and a physicochemical inductive bias that posits binding occurs at minimal binding free energy. Through rigorous validation across multiple benchmark sets, the superiority of our proposed model is confirmed. Additionally, the model's practicality in virtual screening during actual drug development processes is demonstrated. Finally, by visualizing the interpretability of the prediction model, we ensure the reliability of the values it predicts. The proposed model shows potential in the screening process for selecting molecules that strongly bind to a target protein among various molecular structures. Furthermore, using this prediction model to generate molecules with desired properties in the field of generative models presents an interesting research direction."}]}