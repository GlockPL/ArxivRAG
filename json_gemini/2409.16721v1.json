{"title": "A Multi-Dataset Classification-Based Deep Learning Framework for Electronic Health Records and Predictive Analysis in Healthcare", "authors": ["Syed Mohd Faisal Malik", "Md Tabrez Nafis", "Mohd Abdul Ahad", "Safdar Tanweer"], "abstract": "In contemporary healthcare, to protect patient data, electronic health records have become invaluable repositories, and to conduct predictive analysis a vast opportunity is created to leverage the techniques of deep learning. The retinal fundus images, cirrhosis stages, and heart disease diagnostic prediction are encompassed by the promising results of deep learning techniques integration in classifying diverse datasets. By pre-processing data from three distinct datasets, the novel deep learning predictive analysis framework is proposed for classifying multi-dataset during this study. This study proposed a hybrid deep learning model like \u201cResidual Networks (ResNet-50)\u201d and \u201cArtificial Neural Networks (ANN)\u201d to detect acute and chronic diseases like heart diseases, cirrhosis and retinal fundus images better than existing models. For preparing datasets, are few of the aspects, such as categorical data transformation, reduction of dimensionality, and missing data synthesis, are involved within the framework. By using the scaler transformation for categorical datasets and the ResNet architecture for image datasets, the feature extraction is performed effectively. Later, into a unified classification model, the resulting features are well integrated. The high accuracies of 93%, 99%, and 95% on retinal fundus images, cirrhosis stages, and heart disease diagnostic prediction are achieved by conducting rigorous experimentation and evaluation. Among all datasets, the proposed method's efficacy will be well demonstrated by conducting a detailed analysis of the F1-score, precision, and recall metrics. This study proposed comprehensive methodology exploration and experiments and offered in-depth knowledge of the deep learning prediction analysis in electronic health records.", "sections": [{"title": "I. Introduction", "content": "In electronic health records and diagnostic prediction, there are huge transformations made by the rapid advancements of deep learning techniques. By using traditional methods, medical data analysis has experienced huge difficulty in managing variability inherent in diverse datasets[1]. However, the paradigm shift in handling electronic health records, including medical images and their usage for diagnostic prediction, is noticed by replacing the traditional methods with the emergence of deep learning like convolutional neural networks (CNNs)[2]. The wide range of modalities like genomic information, images, and clinical data is encompassed by the availability of diverse and voluminous datasets in healthcare.\nAdditionally, deep learning is one kind of machine learning that assists in making appropriate predictions and exploring complex patterns by processing huge quantities of unstructured and structured data [3]. Furthermore, deep learning algorithms in the EHR context help by depicting historical data on health to predict different health problems like heart conditions, diabetes, chances of hospital readmissions, and patients' reactions towards particular treatments.\nAccording to the survey of WHO, the global deaths' primary cause is cardiovascular diseases (CVDs). Currently, the region-wide or national EHR management system's boosting has allowed EHR data fusion and sharing from different institutes, offering a faster way of collecting huge amounts of data to assess the risk factors of CVD[4]. Nguyen et al. (2019)[5] stated that for a population, EHRs become a major way of exploring diabetics' developing trends. However, to detect the disease's severity, using EHRs improves medical care's efficiency and quality.\nHowever, as a way of exploring high utilization patterns, EHRs are currently used within healthcare, such as unplanned readmissions. In addition, readmissions are specific to the institutions of healthcare because the \u201cHospital Readmissions Reduction Program (HRRP)\" potentially penalizes healthcare institutions for more readmissions than expected for selected conditions. Significantly, the EHR has been implemented in healthcare to develop a model of risk prediction for readmission [6].\nBesides these, in managing women's reproductive health problems such as contraceptive use, pregnancies and menstrual cycles, and loss of pregnancies, EHRs have a significant role[7]. Similarly, EHRs for elderly patients manage different health problems such as medication management, chronic diseases, and so on. Among pediatric patients, EHRs offer vaccination schedules, development, and growth tracking[8]. Additionally, to manage and track mental health conditions such as bipolar disorder, anxiety, and depression, EHRs have a considerable role[9]. However, these EHRs assist in tracking therapy progress, monitoring medication adherence, and coordinating care.\nFor uncovering valuable insights and patterns that help in improving patient outcomes these datasets have immense potential. The patient outcomes can be improved, and the disease understanding capability will be enhanced with the help of these datasets. In comparison, the significant computational challenges are exposed by the complexity of these datasets and the sheer heterogeneity[10]. Scalable classification methods are required to avoid computational challenges. In response to"}, {"title": "Problem Statement", "content": "this requirement, for predictive analysis in electronic health records as a promising solution, the approaches of deep learning have emerged. Including structured data and testing the different data modality's strengths are leveraged by these approaches by integrating them into the comprehensive analysis[11].\nThe information that is embedded in diverse datasets is effectively harnessed by combining the techniques of image processing with advanced neural network architectures and this leads to enhanced diagnostic predictions. During this study for predictive analysis in electronic health records, the novel deep learning framework is designed. The heart disease diagnostic prediction, retinal fundus images, and the cirrhosis stages are three major key datasets that are focused on by the hybrid deep learning framework[12]. For reliable classification across diverse medical contexts, the unified solution is provided by addressing the complexities that are associated with datasets like categorical features, image variability, and missing data.\nFrom the dataset, both the visual and semantic features are captured by the image processing techniques integration like feature extraction using ResNet architecture. The discriminative power of the model ensures a hybrid approach, and also, from different data sources, the complementary integration is facilitated with the help of this approach[13]. By improving patient care outcomes efficiently, the methodology seeks to enhance diagnostic accuracy by leveraging the collective knowledge that is embedded in multi-modal datasets."}, {"title": "Related Works", "content": "The problem addressed in this study revolves around the complexity of extracting valuable insights from electronic health records data to enable predictive analysis in the healthcare domain.\nTraditional methods effectively handle the heterogeneity of EHR datasets, and this leads to huge complexities in model training, data pre-processing, and feature extraction. As a result, while leveraging EHR data for personalizing patient care there are huge obstacles experienced by the healthcare providers. The clinical workflows can be optimized, and the patient outcomes can be enhanced. The EHR data limits are handled by enabling advanced computational approaches. Therefore, for processing the EHR data efficiently and generating accurate predictions for improving healthcare"}, {"title": "Deep Learning Architectures for the Classifications of Medical Images", "content": "delivery there is a huge requirement to implement innovative methodologies[14].\nSimilarly, According to the study[15], there are many complex issues to incorporating EHR coupled with the labelled data's less availability for training models and privacy issues related to mistrust between healthcare providers impede the application of EHR to offer better care. In general, acquiring labelled data is difficult and labour-intensive. It requires expert annotation and also limits the effectiveness of model training. Apart from that, the standardization and cleaning of data complicate the procedures. However, privacy concerns such as addressing cybersecurity risks, confirming regulatory compliance with rules like GDPR and HIPAA, and protecting the sensitive information of patients are also major challenges [16]. In addition, ethical issues related to bias and informed consent in predictive pose challenges as well[17]. Additionally, deep learning is also considered a cross-cutting novelty. Still, there are some tasks in EHR and these tasks need to be solved efficiently.\nNotably, the challenges related to datasets for heart diseases, cirrhosis stages, and retinal images in deep learning are multifaceted. Subsequently, heart disease datasets integrated different data types, including genetic information, clinical records, and imaging, that pose integration and standardization challenges[18]. Similarly, cirrhosis stage datasets require longitudinal data for appropriately tracking the progression is potentially incomplete[19]. On the other hand, retinal image datasets face challenges associated with variability in the quality of images and they need precise advice from ophthalmologists that results in labor- intensive to overcome[20].\nMoreover, EHR data is also used to identify and diagnose the risk of developing \u201cmild cognitive impairment (MCI)\". Understanding and predicting the risk of MCI and assessing the development from \"cognitively unimpaired (CU)\" to MCI by applying the EHR data is the most challenging matter as well as a largely unexplored task[21]. With the overarching goal of enhancing patient care and revolutionizing healthcare practices deep learning techniques and applications are explored for predictive analysis using EHR data.\nHowever, current techniques struggle to draw out necessary information from EHR because of challenges like problems like manual annotations' high cost, incomplete or missing records, and inconsistent data formats. Thus, these challenges hinder the robust predictive models' development. Therefore, the necessity of new techniques is justified by integrating advanced technologies, including deep learning and machine learning, potentially ensuring privacy through federated learning and differential privacy, using unlabelled data, and handling heterogeneous data. Furthermore, these methods help in better resource allocation, improving patient outcomes, and providing more accurate predictions. Addressing the issues of existing techniques.\nThere are several methodologies are ensured by exploring the comprehensive study. From Google Scholar and Elsevier, the relevant literatures are analyzed in this section along with highlighting key methodologies and their contribution to the field."}, {"title": "Convolutional Neural Networks", "content": "The study aims to contribute growing research body on hybrid deep learning in electronic health records by ensuring the comprehensive exploration of methodology, experimentation, and results. In medical image analysis the further advancements are inspired by highlighting the hybrid deep learning approaches potential and elucidating predictive analysis intricacies. Therefore, this research sets some objectives, and there are: (a) To establish a solid framework of Hybrid Deep Learning for the analysis of EHR data, (b) To address issues related to the implementation of EHR for predictive analytics, (c) To investigate the predictive power of EHR for disease diagnosis, and (d) To ensure trust and privacy in the data of EHR for the applications of deep learning.\nFor medical image analysis, convolutional neural networks have emerged as a dominant architecture because for capturing hierarchical features within images convolutional neural networks have a huge ability. Farooq et al. (2022) highlighted that with diabetes problems, approximately 285 million worldwide population is impacted, and for visual impairment, one of the prominent causes is noticed as diabetic retinopathy (DR). The inclination towards deep learning approaches is enhanced in the medical field, and for early detection of diabetic retinopathy, deep learning algorithms are used for DR diagnostics[2]. In the hybrid deep learning model, CNNs are used to excel image processing.\nThe study performed by Menaouer et al. (2022) explored that abnormalities in DR and its various stages from retina images are detected automatically by using various deep-learning techniques. According to the visual risk linked to retinal ischemia severity the detection of diabetic retinopathy can be done by considering a hybrid deep learning approach that includes both VGG network models and convolutional neural network methods. By performing an effective analysis on 5584 images, the accuracy of 90.60%, the F1 score of 94%, and the recall of 95% are yielded by enabling the hybrid deep learning approach[13].\nEsteva et al. (2017) explored that by achieving a performance on par with expert dermatologists and diagnosing skin cancer from dermoscopic images the convolutional neural network effectiveness is showcased[10]. From images, hierarchical learning and automatic feature extraction are enabled because CNN consists of a revolutionized medical image analysis. Rajpurkar et al. (2017) highlighted that at a level exceeding practising radiologists pneumonia from chest X-rays is detected by developing an effective algorithm that is CheXNet[22].\nWhereas Mahbod et al. (2019), among several classical methods, the convolutional neural networks are identified to be superior for skin lesion classification. From several well-established CNNS, the optimized deep features are employed by ensuring the fully automatic computerized method for skin lesion classification[23]. The ResNet-18, AlexNet, and the VGG16 are noticed as three pre-trained deep models that are employed for achieving effective classification performance."}, {"title": "Recurrent Neural Networks (RNNs)", "content": "RNNs are considered another popular network that can assist hybrid deep learning models in data sequencing. Schwab et al., (2017) explored that the diverse ensemble of recurrent neural networks that can distinguish between arrhythmia types and atrial fibrillation is established by utilizing an annotated dataset of 12,186 single-lead ECG recordings. For drastically reducing the number of time steps per sequence the natural segmentation of ECG signals into heartbeats is harnessed by the novel task formulation[24]. With an average F1 score of 0.79 on an unseen test set, the state-of-the- art classification performance is achieved by the recurrent neural networks.\nLipton et al. (2017) highlighted that from electronic health record data, patient diagnoses can be predicted by using LSTM recurrent neural networks, and when compared to traditional methods this helps in demonstrating the enhanced accuracy. For predicting and classifying diseases appropriately the recurrent neural networks are applied to sequential medical data like electronic health records and time-series signals[25].\nChoi et al. (2016) developed Doctor AI by leveraging bulk historical data in electronic health records, and this model has observed both medication usage and medical conditions. The recurrent neural networks are used within the Doctor Al for predicting the medication categories for the subsequent visit[26]. Up to 79% recall@30, the differential diagnosis is performed by the Doctor AI, and through adapting resulting models, this model generalizability is well demonstrated."}, {"title": "Ensemble Methods", "content": "Ahmed et al. (2022) addressed that by comparing five machine learning models, K-Nearest Neighbors, Logistic Regression, Decision Tree, hybrid models, and Na\u00efve Bayes, the ensemble methods are proposed for identifying heart diseases in early stages[27]. For improving classification performance, the multiple models are combined within this model, and from medical images the ensemble methods are investigated for integrating the diverse features along with enhancing the diagnostic accuracy. This method is used in a hybrid model to improve the accuracy and stability of the results. Muller et al. (2022) highlighted that from medical images like intensity, texture, and shape, the extraction of diverse features is integrated by the ensemble methods[28]. For boosting performance and improving robustness, the integration of ensemble learning techniques is considered an effective method in medical image classification pipelines."}, {"title": "Generative Adversarial Networks (GANs)", "content": "Frid-Adar et al. (2018) highlighted that generative adversarial networks are used for generating synthetic medical images and high-quality liver lesion ROIs. The liver lesion classification algorithm's performance can be improved by employing generative adversarial networks for generating synthetic liver lesions, and to train deep learning models the realistic medical image generation is facilitated[29]."}, {"title": "Integration of Multiple Data Modalities", "content": "For enhancing the disease diagnosis and prognosis the medical images integration with clinical data like medical history, patient demographics, and laboratory results are focused on by several studies. Kanagarathinam et al. (2022) explore that in the healthcare domain the patient's health diagnoses benefit by enabling the machine learning-based prediction models. For predicting cardiovascular events, the proposed hybrid deep learning framework is incorporated with both clinical data and image features[30].\nIn intensive care units, patient outcomes are effectively predicted by developing a multi-modal deep learning model that combines the radiological images with the clinical data. A study by Baltrusaitis et al. (2019) proposed multi-modal machine learning that can process data from multiple modalities. For predicting cardiovascular events, this model combines the image feature with the clinical history. In common taxonomy, the recent advances in multi- modal machine learning are presented instead of relying on certain multi-modal applications[31]. The new directions for future research can be identified, and the state of the field can be understood effectively by this new taxonomy."}, {"title": "Images and Genetic Information", "content": "The disease classification accuracy is enhanced by integrating the genetic information with medical images. Research by Yang et al. (2021) demonstrated that without any requirement for feature engineering, the complex features from raw data can be learned automatically by incorporating the genetic markers into deep learning models. From medical images, the risk of developing hereditary diseases can be predicted by ensuring deep learning models[32]. Personalized treatment planning will be ensured, and disease risk prediction will be improved by integrating genetic information with medical images. Whereas a study by Poplin et al. (2018)[33], explored that from retinal fundus images, the new knowledge can be extracted with deep learning. The cardiovascular risk factors that are not presented in retinal images can be predicted by training deep learning models on medical data[33]. The anatomical features like blood vessels or optic discs are used under the trained deep-learning models so that every prediction can be generated effectively."}, {"title": "Materials and Methods", "content": "This study proposed a hybrid deep learning model like \u201cResidual Networks (ResNet- 50)\" and \"Artificial Neural Networks (ANN)\" to detect acute and chronic diseases like heart diseases, cirrhosis and retinal fundus images better than existing models. Additionally, a hybrid model consisting of ResNet-50 and ANN is novel because of its symbiotic application of these two networks' strengths. Furthermore, the residual connections and deep layers of ResNet-50 excel in mitigating vanishing gradient problems and complex feature extraction[41], whereas ANNs offer versatility in maintaining different data types[42]. However, this incorporation increases generalization, performance and learning efficiency. Apart from that, using the pre-trained capabilities ofResNet-50 for transfer learning generates a versatile and powerful solution in deep learning and machine learning applications. In this section, employed techniques and materials have been described in detail that helped to introduce this hybrid model successfully."}, {"title": "System Configuration", "content": "To ensure that the findings of the proposed study are transparent and replicable, have clarified the experimental procedures to be employed in the research study. The model was created, and the training was done on a computer that was installed with an Intel Core i9-11900K, Geforce RTX 3090 graphic card, 32GB DDR4 RAM, and 1TB NVMe SSD. The researcher utilized Python 3.8 and worked with library files such as TensorFlow 2.6.0, Pandas 1.3.3, NumPy 1.21.2, and Scikit-learn 0.24.2. For visualization during the coding part and also in this research, Matplotlib is in the specified version, which is 3.4.3, and Seaborn 0.11.2. The architecture of the model was fine-tuned; the learners chosen have a learning rate of 0.001, and a batch size of 32 and 100 epochs is used. The Adam optimizer was used as the optimization algorithm researcher had Categorical Cross Entropy being the loss function used the ReLU activation function for all the hidden layers with softmax for the output layer. The dropout rate used was 0. 5, and Normal initialization for weights. This way, the configurations of settings presented in the study can be easily reproduced by another researcher."}, {"title": "Brief Description of Bio-Makers", "content": "The term MYA is referred to as macular yellow atrophy and from several factors like retinal diseases, age-related macular degeneration, and vascular disorders, the MYA is resulted.\nThe term BRVO is referred to as the branch retinal vein occlusion, which leads to a reduced oxygen supply for the affected retina area, and this might result in loss of vision in the affected part of the visual field.\nThe term MH refers to the macular hole, which leads to blurred central vision, and this is associated with conditions like trauma to the retina.\nThe term DN is referred to as diabetic neuropathy, which leads to damage to the eyes and due to diabetes, this condition has resulted. If diabetic neuropathy is left untreated, then it might lead to severe vision problems and even blindness.\nThe term LH is referred to as the lesions in the retinal layers which creates abnormalities within the retina layer. Affecting retinal tissue, inflammation, and pathological changes are a few of the problems created due to the lesions in the retinal layers."}, {"title": "Pre-processing", "content": "By transforming categorical variables into numerical representations, addressing missing data, and improving computational efficiency, data pre-processing plays an essential role in preparing datasets for deep learning models. The pre-processing techniques employed during this study are elaborated in this section."}, {"title": "Reduction of Dimensionality", "content": "While retaining required information, the number of features is reduced by utilizing the essential techniques of dimensionality reduction. By ensuring the dimensionality reduction the overfitting curse can be mitigated along with enhancing the computational efficiency."}, {"title": "Principal Component Analysis (PCA)", "content": "The principal components within data can be identified by enabling principal component analysis and this can be recognized as one of the effective techniques. The principal component analysis can capture the maximum variance and this can be considered as orthogonal vectors[43]. By enabling these components, the data can be projected into the minimal dimensional subspace. While preserving possible variances the dimensionality can be effectively reduced by PCA."}, {"title": "t-Distributed Stochastic Neighbor Embedding(t-SNE)", "content": "In lower-dimensional space, the high- dimensional data can be visualized efficiently by using t-SNE. This can be recognized as one of the effective reduction techniques of nonlinear dimensionality[44]. The data points local structure can be preserved by ensuring this technique, and for ensuring exploratory data analysis this technique can be preferable."}, {"title": "Synthesis of Missing Data", "content": "In datasets, the missing values cannot be handled directly by using many deep learning models, so that for handling missing data the techniques of missing data synthesis can be used effectively."}, {"title": "Imputation of K-Nearest Neighbors (KNN)", "content": "By considering the nearest neighbour's average or weighted average values, the KNN imputation can be considered an essential approach to impute the missing values[45]. Based on observed neighbour values, the missing value can be estimated by KNN imputation and for the missing value, the k nearest data points can be recognized."}, {"title": "Imputation of the Regression", "content": "In observed data, by using the regression models, the predicting missing values are involved under the regression imputation[46]. Based on the feature values in datasets, the missing values can be estimated effectively by regression imputation, and this method usually leverages the relationship among the variables."}, {"title": "Transformation of the Categorical Data", "content": "For deep learning models, the transformation of categorical variables into numerical representations is hugely beneficial, and for becoming numeric, this method usually requires input data. Within categorical variables, the unique integer values for every category are assigned by involving the integer encoding[47]. Among categories, the ordinal relationships are preserved by ensuring this encoding method, the implicit ordinality is introduced by the integer encoding.\nThe categorical variables can be transformed into binary vectors by using the one-hot encoding. In the corresponding category position with a value of 1 and 0 elsewhere, every category is represented as the binary array. The originality introduction is avoided by enabling this encoding method, and as an independent, every category is effectively treated. For training deep learning models, the datasets can be appropriately prepared by employing the essential techniques of data pre-processing. The generalization capabilities can be enhanced, and the model performance can be improved by ensuring the data pre-processing. The real-world dataset complexities can be managed efficiently by using these pre-processing steps, and from data, effective learning can be enabled."}, {"title": "Feature Extraction", "content": "The datasets utilized in this research consist of an exact number of samples and have been split into training, validation, and testing sets. The heart disease dataset includes 10,000 samples, the cirrhosis dataset contains 8,000 samples, and the retinal fundus image dataset comprises 12,000 samples. Each dataset was divided, with 70% allocated for training, 15% for validation, and 15% for testing. Moreover, data augmentation techniques were applied primarily to the image datasets, including rotations, flips, and brightness adjustments, to enhance model robustness. To address class inequity, mainly in the heart disease and cirrhosis datasets, techniques such as oversampling the smaller class and employing weighted loss functions were implemented. These steps ensured balanced learning and enhanced the generalization capabilities of the replicas across numerous classes."}, {"title": "Image Datasets (Retinal Fundus Images)", "content": "During the pre-processing pipeline feature extraction is recognized as one of the essential steps where for facilitating effective learning by modeling the required data is distilled from raw data. For every dataset characteristic, the techniques of distinct feature extraction are employed in this study.\nIn the proposed research, the study employed a multi-dataset classification- based deep learning framework that integrated data from three distinct datasets: These datasets include the Retinal Fundus Multi-Disease Image Dataset, the Heart Disease UCI dataset, the Cirrhosis (Histologic Stage of Disease) dataset. The Retinal Fundus dataset included five classes: There are five classes for the BRVO, DN, LS, MH, and MYA datasets, while for the Heart Disease UCI dataset it is separated into five levels of diseases from level 0 where there is no presence of heart disease to level 4 which represents a very severe presence of heart disease. Cirrhosis was categorized into five stages of histologic liver disease for the purpose of this data set. Preprocessing data was one of the most important stages as it allowed preparing data of different types \u2013 images from Retinal Fundus dataset and numerical data from Heart Disease and Cirrhosis datasets for the model. Similar to what was done with image data, study also included resizing, normalization, and augmentation for the same reason for generalizing over unseen samples. This was achieved after normalization of the numerical data and trimming off of outliers in order to ease comprehension as well as to minimize noise. In both experiments every dataset was described and treated as much as possible. The Retinal Fundus images were very varied in appearance, meaning that the extraction of features that represented the disease was very challenging. Due to the popularity of the Heart Disease UCI dataset, the set of features was extensive, and most of them were employed in classification of disease severity. The features of Cirrhosis dataset\u2013 In Cirrhosis dataset, the disease is classified into stages which helped the understanding of its progression. If a particular dataset was unbalanced, then it was carefully pre- processed in order to make it contribute optimally to the model performance, this involved handling of missing data, normalization of features as well as balancing the classes. This approach used in handling and modelling the data was about integrating more methods of analysis in order to enhance the highest level of predictive accuracy and the flexibility of the framework in diverse applications in the healthcare industry."}, {"title": "ResNet Architecture", "content": "From retinal fundus images, the residual neural network architecture is utilized for feature extraction. While addressing the vanishing gradient problem, the complex image features can be captured by ResNet architecture. The ResNet can be recognized as a convolutional neural network of deep learning techniques[48]. The gradient problem vanishing can be addressed by using the ResNet architecture. Due to vanishing gradients, deep network training can enable the degradation of performance by employing the residual connections."}, {"title": "Image Resizing", "content": "For predetermined resolution, the retinal fundus images are resized to control computational complexity and standardize the image sizes. Among the dataset, the uniformity in input dimensions is ensured by the image resizing, and through the neural network model efficient processing is facilitated."}, {"title": "Extraction of the Pixel Value", "content": "For representing image visual features, the pixel values are extracted from the resized retinal fundus images. The information about the corresponding pixel colour and intensity is encoded by every pixel. The raw visual information within retinal fundus images is captured through extracting the pixel values, and for feature learning this can be served as an input to subsequent layers of neural networks."}, {"title": "Categorical Datasets (Cirrhosis, Heart Disease, and UCI Dataset)", "content": "The categorical variables into numerical representations that are suitable for deep learning models are converted for categorical datasets like the scalar transformation, diagnoses of heart disease, and the cirrhosis stages. The categorical variables are mapped into the continuous numerical scale by involving the scalar transformation, and this allows the model to process the categorical data. Effective learning by deep learning model is ensured by transforming the raw data into a conducive format [49]. By making accurate predictions, discriminative patterns can be learned by serving extracted features as valuable input for the neural network's subsequent layers."}, {"title": "Unified Deep Learning Model", "content": "The extracted features from categorical datasets and image datasets are combined under the model of unified deep learning. For data classification, these features are fed into the architecture of a single neural network architecture. In different data modality types, the presented complementary information is leveraged by enabling this approach and this helps in improving the discriminative capabilities."}, {"title": "Deep Learning Model Architecture", "content": "Based on the input data characteristics and the classification task requirements the deep learning model architecture usage may be varied. However, for managing categorical features, the fully connected layers are involved, and for processing the image features, the convolutional layers integration is involved by ensuring the common approach.\nThe following are a few of the components that are considered under the overall architecture:"}, {"title": "Convolutional Layers (CNN)", "content": "From retinal fundus images, the extracted image features are processed by enabling the convolutional layers. The local patterns can be detected and the spatial hierarchies can be captured by using the learnable filters [50]. Every convolutional layer typically follows activation functions like Rectified Linear Units, and to learn complex features, the deep learning model capacity is enhanced."}, {"title": "Pooling Layers", "content": "By convolutional layers, the generated feature maps can be down sampled by utilizing the pooling layers like average or maximum pooling. In comparison, retaining the most salient information the pooling layers reduce the spatial feature map dimensions."}, {"title": "Fully Connected Layers", "content": "From categorical datasets, the numerical features are extracted by employing the fully connected layers. The fully connected layers connect every neuron in subsequent layers and every neuron in one layer. Among features, complex relationships are enabled by employing the fully connected layers. After every fully connected layer, activation functions like ReLU are applied to enable a deep learning model for learning the boundaries of critical decisions."}, {"title": "Fusion Layer", "content": "The feature representations are fused by representing output features after processing features from both the categorical and image datasets. The extracted features are combined into a unified representation through the fusion layer, and to learn from both modalities, the deep learning model is enabled[50], alternately during the fusion process for weighing the feature significance from different modalities the gating or attention mechanisms are employed."}, {"title": "Output Layer", "content": "There are one or more units considered within the output layer of the deep learning model, and within the classification task, based on the class number, the output layer is dependent. The probability distribution over classes is produced for predictive analysis and this can be possible by applying the activation function of softmax. For appropriate prediction of output binary, a sigmoid activation function is utilized under the tasks of binary classification."}, {"title": "Training and Optimization", "content": "By using gradient descent-based optimization algorithms and backpropagation, the unified deep learning model is efficiently trained. During training, the binary cross-entropy loss for binary classification and the categorical"}, {"title": "Model Architecture", "content": "The comprehensive deep learning model that can integrate the essential features from the categorical dataset is employed during this study. The robust classification performance across several healthcare domains can be facilitated by designing this architecture[51]. Certain components of the model architecture are explained below."}, {"title": "ResNet Architecture", "content": "The features from retinal fundus images can be extracted by using the ResNet architecture. The ResNet-50 is considered during this study and this mainly consists of pooling layers, convolutional layers, and skip connections. For capturing the hierarchical features from retinal fundus images, the multiple convolutional layers are comprised of ResNet-50 with varying kernel sizes. The unified deep learning model architecture working in this research integrates vital features from both categorical and image datasets for strong classification performance over healthcare domains. Moreover, the model exploits fully connected layers for processing categorical features and convolutional layers for handling image data. The ResNet-50 architecture, including multiple convolutional layers with varying kernel sizes and skip connections, is employed to extract hierarchical features from retinal fundus images. During training, the learning rate is typically set to adjust dynamically. The batch size is commonly set to 32, 64, or 128. Over multiple epochs, the training is conducted and based on dataset size, which often ranges from 50 to 200. The fusion layer combines the processed features from both modalities into a unified representation, enabling the model to learn from the complementary information provided by different data types.\nAdditionally, during the fusion process, gating or attention mechanisms are used to weigh the significance of features from different modalities. The output layer, depending on the classification task, uses SoftMax or sigmoid activation functions to produce probability distributions over classes. The model is trained using gradient descent-based optimization algorithms and backpropagation, with binary cross-entropy and categorical cross-entropy as predefined loss functions for binary and multi-class classification, respectively.\nAt different spatial scales, the efficient features can be extracted by employing learnable filters under the convolutional layers. The residual connections are incorporated under the ResNet architectures, and from earlier layers to deeper layers, the direct data flow is enabled by these skip connections. By promoting feature reuse and alleviating the gradient problem of vanishing deep network training is facilitated with skip connections."}, {"title": "Other Dataset Attributes", "content": "For augmenting analysis and improving the predictive capabilities of deep learning models, there are several datasets used alongside bio-marker data. These datasets encompass the diverse medical domains and the unique insights are contributed to underlying conditions being studied. By impaired function and liver scarring, chronic liver disease is characterized by this dataset, and this comprises both the diagnostic features and clinical records related to cirrhosis. The patient demographics, liver enzyme levels, and imaging findings are included as a few of the parameters that are required for recognizing predictive biomarkers.\nFor cardiovascular health, the medical history and diagnostic test results are included under the heart disease datasets. Comprehensive information for disease management and cardiovascular risk is provided by encompassing attributes like electrocardiogram findings and blood pressure readings. The UCI dataset encompasses a wide range of attributes spanning several demographics and medical conditions. For evaluating the robustness and generalizability of deep learning models across several healthcare domains this dataset is served as a benchmark. The diverse array of features for analysis are offered by including clinical outcomes, patient demographics, and laboratory test results are included under the attributes. For Retinal Fundus Images, this study used the datasets collected from the Kaggle website. Finally, technologies like ANN and RestNet50 Architecture have been used in this hybrid deep learning model to get better performance. To measure this model's performance, some metrics have been applied like- accuracy, loss, precision, recall etc."}, {"title": "Experiments and Results", "content": "For evaluating the proposed hybrid deep learning framework on three distinct datasets, cirrhosis stages, retinal fundus images, and heart disease diagnoses extensive experiments are conducted. The F1 score, accuracy, recall, and precision are included as a few of the key metrics that are considered during the evaluation. Within every dataset, the comprehensive assessment of model classification performance is provided by considering these metrics."}, {"title": "Pseudocode for the hybrid algorithm", "content": "Algorithm 1\nLoad pre-trained ResNet-50 model.\nInitialize parameters for ANN.\nLoad and pre-process disease images.\nTrain ResNet-50 on image data.\nCompute and capture the feature representations.\nTrain ANN on structured data and features from ResNet-50.\nCombine outputs from ResNet-50 and ANN.\nEvaluate the hybrid model on test data."}, {"title": "Retinal Fundus Images", "content": "The MYA, BRVO, MH, DN, and LH are included as a few of the retinal diseases that are comprised under the retinal fundus image dataset."}, {"title": "Calculation of Performance Metrics", "content": "Based on classification results, are few of the aspects such as False Negatives (FN), True Positives (TP), False Positives (FP), and True Negatives (TN) are computed during this analysis. By using the following formulas, the F1-score, recall, precision, accuracy"}]}