{"title": "Rethinking Legal Judgement Prediction in a Realistic Scenario in the Era of Large Language Models", "authors": ["Shubham Kumar Nigam", "Aniket Deroy", "Subhankar Maity", "Arnab Bhattacharya"], "abstract": "This study investigates judgment prediction in a realistic scenario within the context of Indian judgments, utilizing a range of transformer-based models, including InLegalBERT, BERT, and XLNet, alongside LLMs such as Llama-2 and GPT-3.5 Turbo. In this realistic scenario, we simulate how judgments are predicted at the point when a case is presented for a decision in court, using only the information available at that time, such as the facts of the case, statutes, precedents, and arguments. This approach mimics real-world conditions, where decisions must be made without the benefit of hindsight, unlike retrospective analyses often found in previous studies. For transformer models, we experiment with hierarchical transformers and the summarization of judgment facts to optimize input for these models. Our experiments with LLMs reveal that GPT-3.5 Turbo excels in realistic scenarios, demonstrating robust performance in judgment prediction. Furthermore, incorporating additional legal information, such as statutes and precedents, significantly improves the outcome of the prediction task. The LLMs also provide explanations for their predictions. To evaluate the quality of these predictions and explanations, we introduce two human evaluation metrics: Clarity and Linking. Our findings from both automatic and human evaluations indicate that, despite advancements in LLMs, they are yet to achieve expert-level performance in judgment prediction and explanation tasks.", "sections": [{"title": "1 Introduction", "content": "Predicting case outcomes based on judge-summarized narratives is an important task. Unlike previous studies (Malik et al., 2021; Nigam et al., 2024) and (Vats et al., 2023), we aim to simulate realistic scenarios where legal judgment prediction systems are used to predict and explain judgments as cases arrive on the bench for adjudication. Our approach focuses on the core factual components of the case-specifically, the events that led to the case being filed, which serve as the basis for judgment prediction. These facts are the foundation of legal arguments and provide the context needed for making judicial decisions. In contrast to previous works that have included the entire case text (including proceedings), our focus on facts mirrors real-world conditions, where judges rely primarily on the case facts when delivering judgments.\nIn addition to the facts of the case, we incorporate additional legal information such as statutes, precedents, and arguments. Statutes represent codified legal principles, while precedents provide case-specific rulings that help guide decision-making. Together, these legal frameworks offer a structured basis upon which judges rely when formulating their rulings. By extracting and integrating these elements into our models, we aim to enhance both the prediction and explanation tasks by grounding the analysis in actual legal texts and the governing principles that are applied in real cases.\nWe explore the efficacy of various transformer-based models investigate the impact of summarizing legal judgments (Deroy et al., 2021; Deroy and Maity, 2023; Nigam et al., 2023a; Deroy et al., 2024b) using techniques (Deroy et al., 2023, 2024c,a; Nigam and Deroy, 2023) such as BERT-Sum (Liu, 2019), CaseSummarizer (Polsley et al., 2016), LetSum (Farzindar, 2004), and SummaRuNNer (Nallapati et al., 2017). Our findings suggest that leveraging summarized information yields decent results in judgment prediction.\nTo further enhance the quality of prediction, we introduce hierarchical transformer models that utilize the entirety of judgment facts, demonstrating superior performance compared to traditional summarization methods. Additionally, our examination of LLMs, including Llama-2 (13b & 70b) (Touvron et al., 2023) and GPT-3.5 Turbo (Brown, 2020), highlights the exceptional performance of GPT-3.5 Turbo in the context of Indian legal judgment pre-"}, {"title": "2 Related Work", "content": "The field of Legal Judgment Prediction (LJP) has seen significant advancements, driven by the need to automate legal case outcome forecasting and alleviate the burden of overwhelming caseloads. Early works by (Aletras et al., 2016), (Chalkidis et al., 2019), and (Feng et al., 2021) laid the foundation for LJP, emphasizing the importance of explainability in AI predictions. Benchmark datasets such as CAIL2018 (Xiao et al., 2018), ECHR-CASES (Chalkidis et al., 2019), and others have spurred research in this area, inspiring models like TopJudge and MLCP-NLN. However, there remains a gap between machine and human performance.\nIn the Indian context, datasets like ILDC (Malik et al., 2021), PredEx (Nigam et al., 2024) and (Nigam et al., 2022; Malik et al., 2022; Nigam et al., 2023b) have highlighted the growing role of AI in legal judgments, with an emphasis on explainability. Research in LJP with LLMs, such as (Vats et al., 2023) and (Nigam et al., 2024), has experimented with models like GPT-3.5 Turbo and Llama-2 on Indian legal datasets. Other studies, such as (Masala et al., 2021) on Romanian legal texts and (Hwang et al., 2022) on Korean legal language, have demonstrated LJP's adaptability across legal systems.\nCross-jurisdictional work, including (Zhao et al., 2018), showcases LJP's applicability in different legal frameworks, with research expanding to multilingual considerations, as seen in (Niklaus et al., 2021) and (Kapoor et al., 2022) for Hindi legal documents. Recent innovations, such as event extraction and multi-stage learning (Feng et al., 2022), continue to push the boundaries of LJP research."}, {"title": "3 Task Definition", "content": "This study focuses on Supreme Court of India (SCI) judgments, and the Court Judgment Prediction with Explanation task consists of two subtasks:\nTask A: Judgment Prediction: This subtask is framed as a binary classification problem specific to SCI cases. Given a segment of the legal judgment as input, the goal is to predict whether the decision favors or is against the appellant. The prediction is represented by binary labels: {1,0}, where 1 indicates that the appeal is accepted (i.e., if any part of the appeal is accepted, the decision is considered in favor of the appellant). Although some cases might involve multiple heads of appeal, where an appellant might win on some grounds and lose on"}, {"title": "5 Methodology", "content": "https://indiankanoon.org/\n5.1 Extraction of Facts and Additional\nInformation from Judgments\nTo extract relevant sentences from legal judgments, we employ a Hierarchical BiLSTM-CRF classifier, focusing on different rhetorical roles as identified by (Ghosh and Wyner, 2019). To create a realistic scenario for our model, we utilize the factual and additional contextual information such as statutes and precedents of the judgments as input for transformer models and LLMs."}, {"title": "5.2 Transformer and Hierarchical\nTransformer Models", "content": "The extracted facts undergo summarization using various techniques, including CaseSummarizer (Polsley et al., 2016), BertSum (Liu, 2019), SummaRuNNer (Nallapati et al., 2017), and LetSum (Farzindar, 2004), to ensure they fit within the input constraints of transformer models. Given that models like XLNET-large (Yang et al., 2019), BERT (Devlin et al., 2018), and InLegalBERT (Paul et al., 2022) can process a maximum input length of 512 tokens, we summarize the facts accordingly. Additionally, we utilize hierarchical transformer models that allow us to input the entire set of facts without the need for summarization. This approach facilitates the handling of comprehensive legal information during the prediction task, which is a binary classification problem."}, {"title": "5.3 Prediction with Explanation using LLMs", "content": "For the explanation task, we leverage LLMs such as Llama-2 (70b & 13b) (Touvron et al., 2023) and GPT-3.5 Turbo (Brown, 2020), employing a prompting strategy. Given that the combined input and response length for these models is 4096 tokens, we segment the inputs into chunks of 2048 words. This segmentation allows us to generate judgment predictions, as one token corresponds to approximately three-quarters of a word, translating to about 750 words for 1000 tokens. We then aggregate the outputs from multiple chunks using a majority voting mechanism to determine the final judgment; in the event of a tie, the judgment is considered in favor of the appellant. For inputs shorter than 2048 words, we directly input the entire text into the LLM without requiring majority voting. We explore two prompting techniques:\nNormal Prompting: The prompt states, \u201cYou are asked to be a judge of a legal case and pro-"}, {"title": "6 Evaluation of Model Performance", "content": "6.1 Automatic Evaluation\nTable 1 summarizes the performance of judgment predictions made by different LLMs through prompting. The results demonstrate that relying solely on factual information leads to lower performance scores. However, incorporating additional legal case-specific information, such as statutes, precedents, rulings from lower courts, and arguments, significantly enhances the quality of predictions. Among the evaluated models, GPT-3.5 Turbo demonstrates the best overall performance.\nTable 2 provides further insights into the performance of various hierarchical transformer models and other transformer architectures. The results show that hierarchical transformer models outperform traditional summarization methods. Notably, models specifically pre-trained on Indian legal data, such as InlegalBERT, exhibit superior performance"}, {"title": "6.2 Expert Evaluation", "content": "For the expert evaluation, we selected 25 explanations generated by the GPT-3.5 Turbo model, corresponding to different judgments, and enlisted three legal experts to assess these outputs. Each expert rated the explanations on a scale of 1 to 5 based on two criteria: (i) Clarity, the quality and coherence of the rationale behind the legal judgment, and (ii) Linking, the degree to which the explanation is logically connected to the final outcome of the judgment.\nTo ensure consistency and reliability in the evaluation, the experts were provided with clear guidelines. They were first instructed to familiarize themselves with both the legal judgments and the model-generated outputs to ensure informed assessments. For each explanation, they evaluated:\nClarity: This criterion focuses on how well the rationale is presented. A clear explanation should have a logical flow, use appropriate terminology, and be easily understood by both legal professionals and laypeople. The experts were asked to consider whether the explanation was coherent and if the reasoning behind the judgment was easy to follow.\nLinking: This metric captures how well the explanation ties back to the final outcome. A strong"}, {"title": "7 Conclusions", "content": "In this study, we explored the effectiveness of various LLMs and transformer architectures in the task of judgment prediction and explanation using the ILDC-multi dataset. Our results demonstrate that incorporating additional case-specific information significantly enhances the prediction accuracy compared to using only factual information. The results also highlight the superiority of hierarchical transformer models over traditional summarization techniques, suggesting that a comprehensive approach to input data yields better predictive outcomes. Despite the promising results, our evaluations reveal that automated metrics still fall short of matching the performance levels of human legal experts, who demonstrate a high degree of agreement in judgment assessments. This gap underscores the need for further refinement of LLMs and transformer models to improve their interpretability and reliability in legal contexts."}, {"title": "Limitations", "content": "This study is focused solely on Supreme Court of India (SCI) judgments, which may limit the generalizability of the models to other courts or jurisdictions. Legal systems in different countries, or even lower courts within the same system, may have distinct structures, procedures, and nuances that are"}, {"title": "Ethical Considerations", "content": "In conducting this research, we adhered to ethical standards, particularly in the context of data usage and expert evaluation. The legal judgments used in our experiments were publicly available, and no private or sensitive data was accessed. For the human evaluation of judgment predictions and explanations, we engaged PhD scholars from the Rajiv Gandhi School of Intellectual Property Law as legal experts. Their participation was voluntary, and we provided monetary compensation for their time and expertise. This ensured that the evaluation process was both fair and conducted with proper acknowledgment of the experts' contributions."}]}