{"title": "ONLINE MULTI-MODAL ROOT CAUSE ANALYSIS", "authors": ["Lecheng Zheng", "Zhengzhang Chen", "Haifeng Chen", "Jingrui He"], "abstract": "Root Cause Analysis (RCA) is essential for pinpointing the root causes of failures in microservice systems. Traditional data-driven RCA methods are typically limited to offline applications due to high computational demands, and existing online RCA methods handle only single-modal data, overlooking complex interactions in multi-modal systems. In this paper, we introduce OCEAN, a novel online multi-modal causal structure learning method for root cause localization. OCEAN employs a dilated convolutional neural network to capture long-term temporal dependencies and graph neural networks to learn causal relationships among system entities and key performance indicators. We further design a multi-factor attention mechanism to analyze and reassess the relationships among different metrics and log indicators/attributes for enhanced online causal graph learning. Additionally, a contrastive mutual information maximization-based graph fusion module is developed to effectively model the relationships across various modalities. Extensive experiments on three real-world datasets demonstrate the effectiveness and efficiency of our proposed method.", "sections": [{"title": "1 INTRODUCTION", "content": "Root Cause Analysis (RCA) is crucial for identifying the underlying causes of system failures and ensuring the high performance of microservice systems (Wang et al., 2023a; Li et al., 2021; Wang et al., 2023c). Traditional manual root cause analysis is labor-intensive, costly, and error-prone, given the complexity of microservice systems and the extensive volume of data involved. Consequently, effective and efficient root cause analysis methods are vital for pinpointing failures in complex microservice systems and mitigating potential financial losses when system faults occur.\nPrevious studies in data-driven RCA, particularly those utilizing causal discovery techniques, have primarily focused on constructing causal or dependency graphs (Ikram et al., 2022; Lu et al., 2017; Li et al., 2021; Soldani & Brogi, 2022; Wang et al., 2023c; Zheng et al., 2024a). These graphs depict the causal links between different system entities and key performance indicators (KPIs), thereby enabling the tracing of underlying causes through these structures. For instance, Wang et al. (Wang et al., 2023c) developed a hierarchical graph neural network method that automatically identifies causal relationships both within and between networks to help pinpoint root causes.\nDespite significant advances, most of these approaches are designed for offline use and face challenges with real-time implementation in microservice systems due to high computational demands. To address this, Wang et al. (Wang et al., 2023a) introduced an online RCA method that decouples state-invariant and state-dependent information and incrementally updates the causal graph. Li et al. (Li et al., 2022) developed a causal Bayesian network that leverages system architecture knowledge to mitigate potential biases toward new data. However, these online RCA methods are limited to handling single-modal data.\nRecently, multi-modal data, such as system metrics and logs, are commonly collected from microservice systems, revealing the complex nature of system failures (Zheng et al., 2024a). For instance, failures such as \"Database Query Failures\" might be overlooked if only system metrics are considered, whereas issues like \"Disk Space Full\" are more effectively identified through combined analysis of metrics and logs. This underscores the importance of using multi-modal data for a thorough understanding of system failures. By integrating information from various sources, we can detect the abnormal patterns of system failures that might not be evident when analyzing single-modal data.\nTo bridge this gap, this paper aims to propose an online multi-modal causal structure learning method for identifying root causes in microservice systems. Formally, given the system KPI data along with multi-modal microservice data including metrics and log data, our objective is to develop an online multi-modal causal graph that identifies the top k system entities most relevant to the system KPI. Three major challenges exist in this task. (C1) Capturing Long-term Temporal Dependencies: Current auto-regressive based RCA methods (Wang et al., 2023a; Zheng et al., 2024a) are limited to capturing short-term temporal dependencies. However, some system faults, such as Distributed Denial of Service (DDoS) attacks, may persist for extended periods. Effectively capturing these long-term temporal dependencies is crucial for identifying various types of system faults. (C2) Capturing the Correlation of Multi-dimensional Factors: Existing RCA approaches (Ikram et al., 2022; Wang et al., 2023c; Zheng et al., 2024a) often analyze abnormal patterns from multiple factors individually, such as CPU usage or memory usage from system metrics and frequency or golden signal from system logs, overlooking potential relationships among these factors from both modalities. Furthermore, these methods often consider all factors as equally important; however, in real applications, certain factors prove to be considerably more crucial than others. It is vital, therefore, to reassess the contributions of each factor to the learning of causal structures. (C3) Learning Multi-modal Causal Structures: Effectively capturing the relationships between different modalities in an online setting is crucial. Simply combining causal graphs from individual modalities can be problematic, especially if one modality is of lower quality.\nTo tackle these challenges, we introduce OCEAN, Online Multi-modal Causal Structure LEArNing, for root cause identification in microservice systems. Specifically, we propose to encode long-term temporal dependencies using a dilated convolutional neural network (Yu & Koltun, 2016) and forecast future values based on the p-th lagged historical data. We further develop a multi-factor attention mechanism to analyze the correlations among various factors and reassess their importance for causal graph learning. Additionally, we propose a contrastive mutual information estimation technique to model the relationships of different modalities. Our contributions can be summarized as follows:\n\u2022 We introduce a novel online framework for multi-modality root cause analysis.\n\u2022 We propose employing a dilated convolutional neural network to capture long-term temporal dependencies and graph neural networks to model causal relations among system entities.\n\u2022 We design a multi-factor attention mechanism to analyze the relationships among different factors and reassess their impact on online causal graph learning.\n\u2022 We develop graph fusion techniques with contrastive multi-modal learning to model the relationships between different modalities and assess their importance.\n\u2022 Extensive experiments on three real-world datasets demonstrate the effectiveness and efficiency of our proposed method."}, {"title": "2 PRELIMINARY AND RELATED WORK", "content": "Key Performance Indicator (KPI). In a microservice system, KPIs serve as invaluable metrics for assessing the effectiveness and productivity of the architecture (Podg\u00f3rski, 2015). They play an indispensable role in monitoring and managing different aspects of microservices to uphold optimal performance levels. Common KPIs encompass latency and service response time. High values in these metrics typically indicate suboptimal system performance or potential system failure.\nEntity Metrics. Entity metrics are the measurable time-series attributes that provide insights into the performance and status of services within a system (Bogner et al., 2017). These entities encompass various components such as physical machines, containers, virtual machines, and pods. In microservice architectures, typical entity metrics include CPU utilization, memory usage, disk I/O activity, packet transmission rate, and etc. These metrics are extensively employed to detect anomalous behavior and pinpoint potential causes of system failures in microservice environments (Wang et al., 2023a;b; Zheng et al., 2024a; Soldani & Brogi, 2023; Liu et al., 2021).\nRoot Cause Analysis. Current root cause analysis (RCA) methods can be categorized into two main branches: single-modal RCA methods and multi-modal RCA methods. Single-modal RCA methods primarily investigate causal relationships among system components using one type of data only (Sporleder et al., 2019; Duan et al., 2020; Meng et al., 2020; Soldani & Brogi, 2022; Aggarwal"}, {"title": "3 METHODOLOGY", "content": "In this section, we first present the problem statement and then introduce OCEAN, an online causal structural learning method designed to identify root causes using multi-modal data. We propose three modules to tackle the challenges outlined in the introduction: long-term temporal causal structure learning, multi-factor attention mechanism, and contrastive multi-modal learning. Subsequently, we identify potential root causes through the network propagation-based root cause identification module and establish stopping criteria. The overview of the proposed OCEAN is provided in Figure 1.\n3.1 PROBLEM STATEMENT\nLet $X^M = \\{X^M_0, X^M_1, \\dots, X^M_T \\}$ represent $T+1$ multi-variate time series data for entity metrics. Here, $X^M_0$ is the historical metric data, and $X^M_i, i \\in [1, ..., T]$, is the $i$th batch for the metric data, with $T_1$ denoting the length of historical metric data, $T_2$ the length of each batch, $n - 1$ the number of system entities, and $d_m$ the number of different metrics. Similarly, $X^L = \\{X^L_0, X^L_1, ..., X^L_T \\}$ represents $T+1$ multi-variate time series data for system logs. Assuming preprocessing has converted the logs into multi-variate time series data (details of converting log data into time series can be found in Appendix C), $X^L_0$ is the historical log data, and $X^L_i, i \\in [1, \\dots, T]$, is the $i$th batch for system logs, where $d_l$ is the number of different log attributes/features. The system KPI is denoted as"}, {"title": "3.2 LONG-TERM TEMPORAL CAUSAL STRUCTURE LEARNING", "content": "To capture temporal causal relations among various system entities and KPIs, the Vector Autoregres-sion Model (VAR) (Stock & Watson, 2001) is often employed (Wang et al., 2023a;b; Zheng et al., 2024a) due to its effectiveness in capturing dynamic interactions among variables in time series data. Specifically, given the two-way matrix $X^{M,i} \\in \\mathbb{R}^{n \\times T_1}$ for the $i$th system metric, our objective is to minimize a VAR-based loss function as follows:\n$X^M_{t,i} = W_1X^{M,i}_{t-1} + W_2X^{M,i}_{t-2} + \\dots + W_{t-1} X^{M,i}_t + \\epsilon$\n$\\mathcal{L}_{var} = \\sum_{i=1}^{d_m} ||X^M_{t} - F(X^{M,i}_{t}, A, \\theta)||^2$ (1)\nwhere $\\hat{X}^M_{t}$ represents the prediction for the $i$th system metric, $W_i \\in \\mathbb{R}^{n \\times n}$ denotes the weight matrix, $\\epsilon \\in \\mathbb{R}^n$ signifies the error variable, $F(\\cdot)$ represents the graph neural network (Kipf & Welling, 2017) parameterized by $\\theta$, $A$ is the learnable causal graph capturing the relationships among node entities and KPIs, and $X^{M,i}_{t}$ denotes the future value.\nThis model is also known as the $t$th order VAR-based model, where $t$ defines the range of temporal dependencies it can capture. However, a recent study (Lin et al., 2020) indicates that as the time lag $t$ increases, the autoregressive model becomes computationally expensive, making it challenging to capture long-term temporal dependencies in online settings. Similarly, many existing temporal modeling techniques, such as Recurrent Neural Networks (RNNs) and Transformers (Vaswani et al., 2017), also incur high computational costs, limiting their applicability for online root cause analysis (see Appendix A for detailed discussion).\nTo address this issue, we propose a module based on dilated convolution and graph neural networks to efficiently capture the long-term temporal dependencies and causal relations among system entities and KPIs. Different from the VAR-based methods (Wang et al., 2023a;b; Zheng et al., 2024a) that take as input the 2-way matrix, we propose to capture the long-term temporal dependency via 3-way"}, {"title": "3.3 REPRESENTATION LEARNING WITH MULTI-FACTOR ATTENTION", "content": "In microservice systems, each system entity has multiple entity metrics and various log at-tributes/indicators, including CPU usage, memory usage, log frequency, log golden signal, etc. Existing RCA methods analyze abnormal patterns from each factor (i.e., metric or log indicator)"}, {"title": "3.4 GRAPH FUSION WITH CONTRASTIVE MULTI-MODAL LEARNING", "content": "To tackle the challenges of multi-modal learning (as discussed in challenge C3 in Section 1), we propose to maximize the relatedness between two modalities via contrastive mutual information maximization. Given the representations of historical data $\\hat{H}^M_t$ and streaming data $\\hat{H}^L_t$ extracted from both metric and log data, we maximize the mutual information between these two modalities:\n$\\mathcal{L}_{MI} = I_{\\phi}(\\hat{H}^M_t, \\hat{H}^L_t) + I_{\\phi}(\\hat{H}^L_t, \\hat{H}^M_t)$ (14)\nwhere $I$ is the mutual information parameterized by a neural network $\\phi$. Following InfoNCE style contrastive loss (Oord et al., 2018; Zheng et al., 2022; 2021; 2023; 2024c), we approximate the mutual information with its lower bound as follows:\n$I_{\\phi}(\\hat{H}^M_t, \\hat{H}^L_t) := \\frac{1}{n} \\sum_{j=1}^{n} log \\frac{sim(\\phi(\\hat{H}^M_{t}[j]), \\phi(\\hat{H}^L_{t}[j]))}{\\sum_{k=1}^n sim(\\phi(\\hat{H}^M_{t}[j]), \\phi(\\hat{H}^L_{t}[k]))}$ (15)"}, {"title": "3.5 NETWORK PROPAGATION-BASED ROOT CAUSE IDENTIFICATION", "content": "The propagation of malfunction effects from the root cause to adjacent entities implies that the immediate neighbors of system KPIs may not necessarily be the root causes themselves. To identify the root cause, we initially derive the transition probability matrix based on the causal graph $G$ and then utilize a random walk with restart method (Tong et al., 2006) to simulate the spread patterns of malfunctions as follows:\n$P_{ij} = \\frac{A_{j,i}}{\\sum_{k=1}^{n} A_{k,i}}$ (19)\nThe transition probability matrix $P$ is the normalized adjacency matrix signified by the coefficient $\\beta \\in [0, 1]$. During the visiting exploration process, we may restart from the KPI node to revisit other system entities with the probability $c \\in [0,1]$. The equation for the random walk with restart is formulated by:\n$r_{t+1} = (1 - c)Pr_t + cr_0$ (20)\nwhere $r_t$ represents the jumping probability at the $t$th step, $r_0$ denotes the initial starting probability, and $c \\in [0, 1]$ stands for the restart probability. Upon convergence of the jumping probability $r_t$, the probability scores of the nodes are employed to rank the system entities and the top k entities are selected as the most probable root causes for system failure.\nStopping Criterion. As the number of new data batches increases, the identified causal structure and its associated root cause list may gradually converge. To prevent unnecessary consumption of computing resources, we employ them as indicators for automatic termination of the online RCA process. We use the rank-biased overlap metric (RBO) (Webber et al., 2010) to measure the similarity between two root cause lists, effectively capturing the evolving trend of root cause rankings. Given the rank lists from the previous and current batches, denoted as $R_{t-1}$ and $R_t$ respectively, we quantify the similarity between these lists as follows:\n$\\gamma = RBO(R_{t-1}, R_t)$ (21)\nwhere $\\gamma \\in [0, 1]$. A higher value of $\\gamma$ indicates a greater similarity between the two root cause lists. The online RCA process is terminated when the similarity score $s$ surpasses a predefined threshold."}, {"title": "4 EXPERIMENTS", "content": "In this section, we evaluate the effectiveness of our proposed OCEAN by comparing it with state-of-the-art root cause analysis techniques. Additionally, we conduct a case study and an ablation study to further validate the assumptions outlined in the previous sections."}, {"title": "4.1 EXPERIMENTAL SETUP", "content": "Datasets. We evaluate the performance of OCEAN using three public real-world datasets: (1) Product Review* (Zheng et al., 2024b): A microservice system dedicated to online product reviews, encompassing 234 pods deployed across 6 cloud servers. It recorded four system faults between May 2021 and December 2021. (2) Online Boutique (Yu et al., 2023): A microservice system designed for e-commerce, including five system faults. (3) Train Ticket (Yu et al., 2023): A microservice system for railway ticketing services, also with five system faults. All three datasets contain two modalities: system metrics and system logs.\nEvaluation Metrics. We choose four widely-used metrics (Wang et al., 2023c; Meng et al., 2020): (1) Precision@K (PR@K): Measures the accuracy of the top-K predicted root causes. (2) Mean Average Precision@K (MAP@K): Evaluates the overall accuracy of the top-K predicted causes. (3) Mean Reciprocal Rank (MRR): Assesses the ranking capability of the models. (4) Time: Measures the training time (in seconds) for each batch of data. Details on the first three metrics are provided in Appendix D and we provide the time complexity analysis in Appendix B.\nBaselines. We compare OCEAN with seven causal discovery based RCA methods: (1) PC (Burr, 2003): A classic constraint-based algorithm that identifies the causal graph's skeleton using an independence test. (2) Dynotears (Pamfil et al., 2020): Constructs dynamic Bayesian networks through vector autoregression models. (3) C-LSTM (Tank et al., 2022): Utilizes LSTM to model temporal dependencies and capture nonlinear Granger causality. (4) GOLEM (Ng et al., 2020): Relaxes the hard Directed Acyclic Graph (DAG) constraint in NOTEARS (Zheng et al., 2018) with a scoring function. (5) REASON (Wang et al., 2023c): Learns both intra-level and inter-level causal relationships in interdependent networks. (6) MULAN (Zheng et al., 2024a): A multi-modal method that captures both modality-invariant and modality-specific representations. (7) CORAL (Wang et al., 2023a): A VAR-based online RCA method that decouples state-invariant and state-dependent information.\nThe first four baseline models were originally designed to learn causal structures solely from time series data. As outlined in (Wang et al., 2023c;a), these causal discovery models can be extended to identify the root cause nodes. In this process, we first apply causal discovery models to learn the causal graphs, then utilize random walk with restarts (Wang et al., 2023a) on these graphs to identify the top K nodes as root causes."}, {"title": "4.2 PERFORMANCE EVALUATION", "content": "Experimental Results. In this subsection, we present the performance evaluation results in Tables 2, 3, and 5 for various methods. Due to the page limit, we have moved the results for the Train Ticket dataset (i.e., Table 5) to Appendix E.1. Notably, although many baseline methods (e.g., PC, C-LSTM, REASON, Dynotears, GOLEM) are tailored for single-modal scenarios, we assess their performance in both single-modal contexts (e.g., system metrics only or system logs only) and multi-modal scenarios. System logs are considered additional system metrics, enabling these single-modal methods to be evaluated in a multi-modal context. We derive an average ranking score from different system metrics as the final result for all single-modal methods.\nOur findings include: (1) Most baseline methods show improved performance when leveraging multi-modal data across three datasets. (2) CORAL, as an online RCA method, surpasses all offline methods across seven metrics. (3) OCEAN consistently outperforms all baselines across the datasets. (4) Both CORAL and OCEAN demonstrate shorter training time compared to offline methods, with OCEAN reducing its computational costs to 1/9 that of CORAL on the Product Review dataset. This reduction is credited to the efficiency of dilated convolutional operations and the design of the multi-factor attention module. CORAL's approach of individually learning and then fusing causal graphs for each metric is computationally intensive in an online setting. Furthermore, OCEAN shows a notable improvement in MRR on the Product Review dataset, outperforming CORAL by 12.5%. Additionally, OCEAN exceeds CORAL by 20% in PR@1 and 10% in MAP@2 on the Online Boutique dataset, benefiting from the assessment of the importance of multiple factors and exploring correlations among different modalities.\nAblation Study. In this subsection, we evaluate the effectiveness of individual components within the objective function of OCEAN (Eq. 18). Specifically, we define OCEAN-F and OCEAN-M as variants that lack the multi-factor attention learning module and the contrastive multi-modal learning module, respectively, while OCEAN-S removes the sparse constraint. The results, shown in Table 4, indicate a significant performance degradation when any component is omitted. Specifically, removing the multi-factor attention module results in 25% and 5% performance drop on the Product Review dataset and Train Ticket dataset, respectively. Eliminating the contrastive multi-modal learning module leads to 12.5% reduction on the Product Review dataset. These findings underscore"}, {"title": "5 CONCLUSION", "content": "In this paper, we investigate the challenging problem of online multi-modal root cause localization in microservice systems. We introduce OCEAN, a novel online causal structure learning framework designed to effectively identify root causes using diverse data sources. OCEAN utilizes a dilated convolutional neural network to capture long-term temporal dependencies and employs graph neural networks to establish causal relationships among system entities and key performance indicators. Additionally, we develop a multi-factor attention mechanism to evaluate and refine the contributions of various factors to the causal graph. Furthermore, OCEAN incorporates a contrastive mutual information maximization-based graph fusion module to enhance interactions between different modalities and optimize their mutual information. The effectiveness of OCEAN is validated through extensive experiments on three real-world datasets, demonstrating its robustness and efficiency."}, {"title": "A MORE RATIONAL BEHIND THE MODEL DESIGN", "content": "The main issue of Recurrent Neural Networks (RNNs) and Transformers is their high computational cost, which makes them impractical for online root cause analysis. We chose Dilated Convolutional Neural Networks (DCNNs) for their efficiency and ability to capture long-range dependencies, both of which are essential in online settings where computational efficiency is critical. Unlike RNNs and Transformers, which could capture temporal dependencies but often come with high computational overhead, DCNNs are parallelizable and offer a lower time complexity of $O(NTkC)$, where T is the sequence length, L is the number of layers, C is the number of filters, and k is the filter size. In contrast, the complexity of the Transformer is $O(LT^2d)$, where T is the sequence length, L is the number of layers, and d is the hidden feature dimensionality. As a result, Transformers are computationally more expensive than dilated convolutional neural networks. We further demonstrate the efficiency and effectiveness of our method compared to LSTM and Transformers in the ablation study presented in Table 6.\nThe rational behind the multi-factor attention mechanism is to capture complex relationships among various factors (e.g., CPU usage and memory usage metrics in a microservice system) across two modalities. A common limitation of existing methods is their focus on correlations between modalities, often overlooking the importance of individual factors within each modality. Our mechanism addresses this by reassessing the significance of each factor, enhancing causal structure learning. This enables our model to dynamically adjust to the changing significance of factors, which is crucial for accurate root cause analysis.\nWe integrate contrastive learning into our model because of its proven effectiveness in multi-modal tasks. It extracts shared information across different modalities, enhancing robustness and addressing challenges posed by low-quality data. By assigning weights to each modality based on its importance, contrastive learning ensures that critical patterns are not obscured by noise. This approach helps maintain the quality of causal graph learning, even when dealing with data of varying quality."}, {"title": "B TIME COMPLEXITY", "content": "The time complexity of dilated convolution based causal structure learning is $O(NTkC)$. Here, T is the sequence length, L is the number of layers, C is the number of filters, and k is the filter size. The time complexity of multi-factor attention module is $O(d_Md_Ld)$, where d is the hidden feature dimensionality, and $d_M$ and $d_L$ are the number of factors in two modalities. The time complexity of contrastive learning module is $O(n^2d)$, where n is the number of system entities."}, {"title": "C LOG FEATURE/INDICATOR EXTRACTION", "content": "In this subsection, we provide the details of converting the raw data into the time series, though this is not within the scope of this work. Specifically, we first use the Drain parser He et al. (2017) to transform the unstructured log event into structured log templates for each entity. Then, we partition the log data with fixed time windows, such as 5 minutes, and set time steps at 10 seconds. Within these intervals, we count the occurrence of each log template to derive the log frequency feature. The extraction of the log frequency feature is inspired by the insight that the recurrence of a log event template often correlates with its significance. For instance, when a microservice system experiences Distributed Denial of Service (DDoS) attacks, the system will produce an unusual volume of system logs, indicating abnormal activity. Thus, the log frequency provides the information to identify unusual patterns indicative of potential failure scenarios. In addition to log frequency, we also extract a second type of log feature known as the 'golden signal.' Notice that different from log frequency, golden signal heavily relies on domain knowledge and it only focuses on the abnormal system logs. More specifically, we are only interested in some keywords, including 'error,' 'exception,' 'critical,' 'fatal', and various others indicative of system anomalies. By identifying these keywords within log event templates, we can discern abnormal occurrences for system failure localization. Similar to the frequency-based feature, we compute the number of abnormal log events to derive the golden signal-based feature."}, {"title": "D EVALUATION METRICS", "content": "We evaluate the model performance with the following four widely-used metrics Meng et al. (2020):\n(1). Precision@K (PR@K): It measures the probability that the top K predicted root causes are relevant by:\n$PR@K = \\frac{1}{\\alpha \\in A} \\sum_{i<k} R_{\\alpha}(i) \\in V_{\\alpha}$\n$\\frac{1}{min(K, |v_{\\alpha}|)}$ (22)\nwhere A is the set of system faults, a is one fault in A, $V_{\\alpha}$ is the real root causes of a, $R_{\\alpha}$ is the predicted root causes of a, and i is the i-th predicted cause of $R_{\\alpha}$.\n(2). Mean Average Precision@K (MAP@K): It evaluates the top K predicted causes from the overall perspective formulated as:\n$\\frac{1}{K \\alpha \\in A} \\sum_{\\frac{1}{\\alpha \\in A}} \\sum_{i<j<K} PR@j$ (23)\nwhere a higher value indicates a better performance.\n(3). Mean Reciprocal Rank (MRR): It assesses the ranking capability of models, defined as:\n$PR@K = \\frac{1}{\\alpha \\in A} \\frac{1}{rank_{R_{\\alpha}}}$ (24)\nwhere $rank_{R_{\\alpha}}$ is the rank number of the first correctly predicted root cause for system fault a.\n(4). Time: Measures the training time (in seconds) for each batch of data."}, {"title": "E ADDITIONAL EXPERIMENT", "content": "E.1 EXPERIMENTAL RESULTS\nWe report the experimental results on Train Ticket dataset in Table 5.\nE.2 ADDITIONAL ABLATION STUDY\nWe conduct additional ablation study by replacing the dilated convolutional neural network with LSTM or Transformer model on the Product Review and Train Ticket datasets in Table 6. The results showed a performance decline, demonstrating the effectiveness of our design."}, {"title": "E.3 ADDITIONAL PARAMETER ANALYSIS", "content": "In this subsection, we conduct a comprehensive parameter sensitivity analysis on the Online Boutique and Train Ticket datasets. Similarly, we assess the impact of three parameters on the overall objective functions (Eq. 18): A1, A2, and 13. Figures 3 and Figures 4 show the experimental results in terms of Mean Reciprocal Rank (MRR) on the Online Boutique and Train Ticket datasets. The x-axis represents ln(i), where i \u2208 [1,2,3], and the y-axis indicates the MRR score. We consistently observe that OCEAN favors a larger value of A\u2081 on these two datasets as the temporal causal structure learning module is crucial in capturing both temporal and causal dependency. Different from the parameter analysis on the Product Review dataset, we find that A2 and 3 are not very sensitive on the Online Boutique and Train Ticket datasets. We conjecture that this can be attributed to the small size of these two datasets and both sparse regularization and acyclic constraint contribute less to securing high performance on these two datasets than the Product Review dataset."}, {"title": "F REPRODUCIBILITY", "content": "All experiments are conducted on a desktop running Ubuntu 18.04.5 with an Intel(R) Xeon(R) Silver 4110 CPU @2.10GHz and one 11GB GTX2080 GPU. In the experiment, we set the size of historical metric and log data to 8-hour intervals and each batch is set to be a 10-minute interval. We use the Adam as the optimizer and we train the model for 100 iterations at each batch. We use two layers of dilated convolutional operations in the experiment. As for the stopping criteria, we terminate the identification process if the similarity y between the current batch and the previous batch is greater than 0.9 for three consecutive times."}]}