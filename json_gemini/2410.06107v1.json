{"title": "Towards Al-Native Software Engineering (SE 3.0): A Vision and a Challenge Roadmap", "authors": ["AHMED E. HASSAN", "GUSTAVO A. OLIVA", "DAYI LIN", "BOYUAN CHEN", "ZHEN MING (JACK) JIANG"], "abstract": "The rise of AI-assisted software engineering (SE 2.0), powered by Foundation Models (FMs) and FM-powered copilots, has shown promise in improving developer productivity. However, it has also exposed inherent limitations, such as cognitive overload on developers and inefficiencies. We propose a shift towards Software Engineering 3.0 (SE 3.0), an AI-native approach characterized by intent-first, conversation-oriented development between human developers and AI teammates. SE 3.0 envisions AI systems evolving beyond task-driven copilots into intelligent collaborators, capable of deeply understanding and reasoning about software engineering principles and intents. We outline the key components of the SE 3.0 technology stack, which includes Teammate.next for adaptive and personalized AI partnership, IDE.next for intent-first conversation-oriented development, Compiler.next for multi-objective code synthesis, and Runtime.next for SLA-aware execution with edge-computing support. Our vision addresses the inefficiencies and cognitive strain of SE 2.0 by fostering a symbiotic relationship between human developers and AI, maximizing their complementary strengths. We also present a roadmap of challenges that must be overcome to realize our vision of SE 3.0. This paper lays the foundation for future discussions on the role of AI in the next era of software engineering.", "sections": [{"title": "1 INTRODUCTION", "content": "We live in the era of AI-assisted SE, which we refer to as Software Engineering 2.0 (Figure 1). In this era, AI technologies support humans throughout the traditional software engineering process activies (AI4SE). In particular, Al-powered copilots took the industry by storm. Copilots are advanced code completion systems that are powered by Foundation Models (FMs), like Large Language Models (LLMs). Copilots such as GitHub Copilot [43] are currently integrated into all popular IDEs and are used by millions of developers around the world. Research suggests that GitHub Copilot may have a positive effect on developer productivity, particularly on repetitive mundane tasks [24, 51, 69]. Other popular copilot technologies include Amazon Q Developer [1], Google Gemini Code Assist [5], Tabnine [7], Codeium [2], and Cursor [3].\nSE 2.0 faces several critical issues, starting with the high cognitive load on human developers, who must micromanage the coding process despite assistance from AI copilots. While these copilots can automate certain coding tasks, the overall process remains inefficient as the human developer still drives the entire process. This leads to errors, in turn creating a significant burden on developers. Additionally, the training of advanced models like GPT-4 is highly inefficient, relying on vast amounts of unstructured data, which increases computational costs and often results in shallow understanding. Furthermore, research has shown that copilot-generated may contain bugs [45] and performance issues [25]. The reliance on such copilots risks creating a feedback loop where"}, {"title": "2 A CRITICAL ANALYSIS OF SOFTWARE ENGINEERING 2.0 (AI-ASSISTED SE)", "content": "In this section, we introduce Software Engineering 2.0 (Section 2.1), discuss its limitations (Section 2.1), and reflect on the role of autonomous software engineers (Section 2.3)."}, {"title": "2.1 What is Software Engineering 2.0?", "content": "Software Engineering 1.0 was rooted in a code-first approach, where tools primarily supported traditional software engineering process activities, such as requirement gathering, design, implementation, and testing (Figure 1). In the specific context of programming, these tools were mainly powered by program analysis technologies that supported developers in managing code complexity, ensuring code correctness, and optimizing performance. Humans were central and drove the entire process. That is, the responsibility for understanding requirements, making design decisions, and implementing solutions relied heavily on developers and their ability to use and coordinate between multiple classical tools.\nSoftware Engineering 2.0 is our current era (Figure 1). It continues the code-first approach of SE 1.0 while incorporating AI models to enhance traditional software engineering process activities (AI4SE). Software engineering 2.0 can thus be described as Al-assisted SE. A prime example of AI4SE are copilots, which offer code suggestions based on patterns learned from massive datasets."}, {"title": "2.2 What are the limitations of Software Engineering 2.0?", "content": ""}, {"title": "2.2.1 High cognitive overload on humans.", "content": "In SE 2.0, the human developer drives the code creation process loop (Figure 2). As a consequence, the solution space is severely constrained due to the natural limits of the human's cognitive ability to decompose a complex problem, plan possible"}, {"title": "2.2.2 Inefficient (and ineffective) model training.", "content": "The training process of models with state-of-the-art reasoning capabilities, such as GPT-40 and Claude Opus, is drastically inefficient due to several factors. These models rely heavily on unsupervised learning, which involves feeding vast amounts of unstructured, internet-scale raw data into the model's architecture. While this approach allows the models to generalize from a wide range of domains and topics, it also leads to significant inefficiencies in terms of computational resources, energy consumption, and data redundancy. The sheer volume of data requires immense processing power, often involving thousands of GPUs running in parallel over extended periods, which drives up both financial and environmental costs. Moreover, the lack of targeted or structured learning means that the models often spend a great deal of time processing irrelevant or noisy information, which contributes little to their final reasoning abilities. In particular, the reliance on raw data limits the ability of these models to effectively capture more specialized or nuanced forms of knowledge that are critical for advanced reasoning. Because the data is largely non-curated, the models must attempt to infer complex relationships, and logic from fragments of information, which leads to incomplete or imprecise understanding in key areas. This often results in models that exhibit surface-level knowledge across a vast number of domains but lack depth or accuracy in more detailed, reasoning-heavy tasks. Additionally, the reuse, evolution, and maintenance of these models over time remain challenging, as they require continuous retraining and fine-tuning on newer datasets to stay relevant, which compounds the inefficiencies and further increases the complexity of long-term model sustainability."}, {"title": "2.2.3 Suboptimal code quality and the vicious cycle for copilots and FMs.", "content": "Current copilots can essentially only add code. This is a major flaw from a SE standpoint, since adding code is not always the best solution to a problem. In fact, senior software engineers will frequently leverage design patterns and refactoring techniques to shorten source code by creating abstractions that encapsulate concerns and promote reuse, reducing complexity and enhancing maintainability. In contrast, continuously adding code can lead to bloated codebases, which are harder to maintain, evolve, and reuse (e.g., poorly structured code often resists modularization and abstraction). Furthermore, recent research has shown that code produced by GitHub Copilot may be buggy [45] and have performance issues [25]. In fact, research from Microsoft shows that senior programmers are less likely to accept GitHub Copilot suggestions compared to junior programmers [24, 51, 69]."}, {"title": "2.3 How about autonomous software engineers?", "content": "The idea of an autonomous software engineer was popularized by Devin AI [20] and its descendents, including SWE-agent [65], AutoCodeRover [67], Agentless [64], OpenDevin [48], and GRU [66]. At the time of writing, the state-of-the-art autonomous software engineer is GRU, as it can solve 45.20% of all tasks in SWE-Bench Verified [36]. SWE-Bench verified is a human-validated subset of SWE-bench that more reliably evaluates the ability of an Al to autonomously solve real-world GitHub issues [49].\nWhile GRU's result is impressive, we believe that the lack of focus on human-AI alignment of intents makes it prone to generate a solution that may not fulfill the original, true requirements. Moreover, current autonomous software engineers still rely on \u201coff-the-shelf\u201d FMs for code generation. Despite their ability to generate several candidate solutions to a problem (or part of the problem), the lack of deep SE knowledge and efficiency of the aforementioned models significantly hinder the quality of the code produced by them. Finally, due to the intrinsic limitations of SWE-bench (e.g., only Python projects, only 12 projects, and ~70% of all tasks originate from 3 out of the 12 projects), the real-world performance of autonomous software engineers remains unclear. Therefore, while we are positive and genuinely curious about the future of autonomous software engineers, we believe that they also come with their own set of challenges that must be overcome before they can be used in a real-world setting.\nAs we shall discuss in the next section, the overall philosophy of our vision for SE 3.0 is to leverage the best qualities of humans and AI in a process that is as symbiotic as possible, while also ensuring that a proper technology stack can support such a process."}, {"title": "3 OUR VISION OF SOFTWARE ENGINEERING 3.0 (AI-NATIVE SE)", "content": "The inherent drawbacks of Software Engineering 2.0 (AI-assisted SE) call for a deep rethinking of the ways in which we have leveraged Al to engineer software systems. In this section, we discuss our vision of a new era of software engineering, which we refer to as Software Engineering 3.0 (AI-native SE). In the next sections, we discuss the core principles of SE 3.0 (Section 3.1) and the technology stack that supports this new era (Sections 3.2 to 3.6)."}, {"title": "3.1 What is Software Engineering 3.0?", "content": "While SE 2.0 focuses on using AI to support traditional activities (e.g., coding, testing, debugging), Software Engineering 3.0 redefines the those activities altogether as well as the technology stack to support them (Figure 1). SE 3.0 is AI-native and leverages the complementary strengths of human developers (e.g., ability to reflect about business needs) and sophisticated AI systems (e.g., ability to search for multiple solutions to a problem at hyper speed) in the most efficient and effective way possible.\nSE 3.0 marks a paradigm shift towards an intent-first approach, where development is no longer driven by code but by intents expressed through back-and-forth conversations between human developers and their AI teammates. We refer to it as conversation-oriented development. In SE 3.0, the AI drives the code creation loop by synthesizing the intents into runnable software."}, {"title": "3.2 Teammate.next: From static and impersonal copilots to self-evolving personalized mentors", "content": "In SE 3.0, humans collaborate with Al teammates instead of copilots like GitHub Copilot. The AI teammate engages in a conversation with the human developer to help them clarify their intents. Once intents are clarified, the AI teammate synthesizes them into runnable software. More details about this process will be given in Sections 3.3 and 3.4\nHowever, software engineering is much about social interactions as it is about development. As a human partner, the AI teammate exhibits adequate social traits, such as conversational intelligence (e.g., proactivity and communicability), social intelligence (e.g., manners and personalization), and personification (e.g., identity) [18]. Such characteristics contrast with copilots from the SE 2.0 era, which are vastly impersonal."}, {"title": "3.3 IDE.next: From code-centric to intent-centric IDEs", "content": "IDE.next is the new AI-native IDE that powers software development (Figure 4). In SE 3.0, the human developer and his AI teammate first align on intents. In this alignment process, the AI will help the human to both express and refine their intents by means of a back-and-forth conversation. Such a process is needed due to the intrinsic human cognitive inability to fully and clearly express their intents in one-shot. Intents themselves can be described in a flexible manner, ranging from informal descriptions of a functionality to pseudocode examples, UI sketches, and even example data.\nOnce there is human-AI aligment of intents, the AI teammate drives the code creation loop. As opposed to SE 2.0 (Figure 2), the solution space is now essentially unlimited and can be navigated at hyper-speed by the AI (i.e., coding and human cognition are no longer limitations). Coding thus becomes a search problem, where the fitness function translates to how well the produced code satisfies the human-AI aligned intents.\nThe source code itself is of secondary importance and hidden from the human by default. However, the human can always enter a low-level debugging mode where they can see the code and adjust it by hand if needed. By means of further back-and-forth conversations between the human and his AI teammate, prototyping loops happen at fast pace. Humans focus on the intents and the AI teammate focuses on turning that into running software. The code synthesis is performed with the help of Compiler.next. We discuss the compiler and the AI teammate in more details in Sections 3.4 and 3.2 respectively.\nInterestingly, the code creation loop can reinitiated at any time (e.g., when a new FM is released) as long as human-AI conversations are \u201carchived.\u201d That is, the conversations become a key asset that needs to be version controlled and managed. We also clarify that we employ the term code in its broadest sense possible here. By code, we mean traditional code (e.g., Python code), machine learning models, prompts for a FM, and even data (e.g., additional training data to fix incorrect classifications made by a neural network [40]).\nThe development model in SE 3.0 is inherently iterative and cyclic, where humans react to the prototyped software in every code cycle. The cycle ends once the human developer is satisfied with"}, {"title": "3.4 Compiler.next: From logic-rule realization to search-space exploration", "content": "Compiler.next is the piece of software responsible for synthesizing intents (possibly enriched with examples and data as shown in Figure 4) into runnable software via an efficient search process. At hyper speed, the solution is iteratively developed through code mutations and a self-reflection mechanism that evaluates (i) how well the code matches the intent and (ii) the quality of the code (to enable low-level debugging by humans if needed). The synthesizer is powered by efficient and knowledge-driven FMs, which we discuss in Section 3.6. As such, the synthesizer is an FMware (a software system that uses FMs as one of its building blocks) [32].\nA key attribute of the code synthesizer is its ability to find the best trade-off between multiple competing objectives, such as accuracy (how well it fulfills the intent), latency (e.g., number of requests sent to the FM), and cost (e.g., number of input tokens in the prompt and expected number of output tokens). In other words, the synthesizer performs a multi objective optimization.\nAnother key attribute of Compiler.next is its goal-tracking mechanism. This mechanism ensures that (i) intents are translated into tests, (ii) tests are adequately adapted as requirements change, and (iii) tests will eventually pass. In other words, this mechanism guarantees that tests are always derived from intents (requirements) instead of some existing piece of code. Deriving tests from code is a well-known AI4SE pitfall, since there is no guarantee that the code does what it is supposed to do [34]."}, {"title": "3.5 Runtime.next: From the serving of models to compound apps", "content": "FMware raised in popularity with the release of not only-closed source (e.g., GPT-4) but also open-source FMs (e.g., Llama 3.1) with better reasoning capabilities. Multi-modal FMs [23] (e.g., GPT-40), which can process not only text but also other forms of input such as images and video, also create several business opportunities for FMware. In fact, the technology stack that we describe in this paper also heavily relies on FMs (e.g., the Compiler.next). Moving forward, several software systems are expected to either be FMware or contain FMware as one of its modules [32].\nHowever, it does not stop there. FMware development typically embraces the data flywheel [10] approach. The data flywheel is a self-reinforcing cycle where data collection, analysis, and insights drive continuous improvements and growth in a system. As more data is gathered (e.g., field, telemetry, and human feedback data), it improves the accuracy and effectiveness of algorithms and processes (e.g., model fine-tuning and agent improvement), which in turn enhances user experiences and operational efficiency. This leads to more users or activities that generate even more data, fueling further optimization. As a result, FMware remains in a continuous state of evolution.\nThe aforementioned FMware characteristics put pressure for a new type of runtime. Runtime.next represents our vision of a SE-3.0-ready runtime and exhibits the following qualities:\n\u2022 SLA-aware. Runtime.next implements intelligent priority-based routing and leverages sophisticated observability machinery to schedule and allocate resources more effectively. An example is running model fine-tuning procedures on the same cluster as the serving cluster when the software is more idle, such as overnight.\n\u2022 Uni-clusters. A uni-cluster unifies multiple FM-related activities \u2013 such as training, fine-tuning, serving, and agent self-evolution \u2013 within a single cluster [32]. This design drastically simplifies"}, {"title": "3.6 FM.next: From data-driven inefficient FMs to knowledge-driven efficient FMs", "content": "The lack of a focused and structured learning approach for models in SE 2.0 results in significant inefficiency, as those models often spend a substantial amount of time processing irrelevant or noisy information. This not only consumes valuable resources but also adds little to enhancing their reasoning abilities.\nAn alternative and more efficient strategy for training FMs is via curriculums [61]. Curriculum engineering is the systematic design, development, and continuous refinement of curriculums that contain curated, organized, and high-quality domain-specific knowledge. A curriculum does not need to be manually designed from top to bottom. For instance, humans can leverage AI to kickstart the curriculum then manually revise it. Once a curriculum is stable, humans can again leverage AI to generate synthetic data (e.g., concrete examples) to enrich the curriculum. As an illustrative example, one could enrich the \u201cdesign patterns\u201d section of a SE curriculum by having the AI generate examples of the application of design patterns in different programming languages and in different contexts. The FM used by Compiler.next is trained with an SE curriculum (e.g., by drawing inspiration from the IEEE Software Engineering Body of Knowledge \u2013 SWEBOK [62]) to produce high-quality code. That is, synthetic data plays a pivotal role in overcoming the limitations of real-world data, as it allows for scalable, controlled, targeted, evolvable, and maintainable training datasets.\nA curriculum externalizes the knowledge from the model itself, allowing for higher adaptability. For instance, the curriculum can be reviewed, reorganized, or augmented in response to the model's performance on specific tasks. Here, observability data becomes essential (e.g., telemetry data from Runtime.next). By closely monitoring key performance metrics, such as where the model is excelling or underperforming, it is possible to adaptively adjust the curriculum and synthetic data generation processes to improve the FM in a systematic manner. This feedback loop ensures that the training process focuses on weaker areas, allowing for a more efficient and focused improvement in model reasoning. This structured approach not only leads to better model performance but also dramatically reduces the inefficiencies that stem from unstructured learning in traditional model training workflows (e.g., the model's proneness to hallucinations).\nUltimately, curriculum engineering provides a high-level structured vision of how models should be created, maintained, reused, and evolved. In many ways, curriculums represent the intellectual property instead of the model itself. Given their fundamental role, curriculums need to be properly"}, {"title": "4 CHALLENGES", "content": "In this section, we introduce key challenges in SE 3.0. For each challenge, we include a description, what parts of the SE 3.0 stack it affects (Figure 3), one or more open questions and our vision regarding the solution to those questions. Overcoming these key challenges requires novel technologies and a deep rethinking of how humans and AI interact, both of which should be driven by cutting-edge software engineering research. The list of challenges that we present is not meant to be extensive, but rather focuses on the major painpoints that we observe based on our practical experience and discussion with academic and industry leaders."}, {"title": "4.1 Speeding up human-Al alignment", "content": "Description. Humans have a limited ability to fully and clearly express their intents in one-shot using written text (e.g., humans may forget to communicate important aspects of a requirement). As a consequence, human-AI alignment of intents becomes slow. We note that this is a problem that will continue to exist no matter how powerful FMs may become, since it stems from an intrinsic human limitation. That is, humans are the bottleneck, not the AI. To add to the challenge, natural language in inherently ambiguous [37].\nAffects. IDE.next, Teammate.next"}, {"title": "Open question #1", "content": "OQ1: How to balance between asking too many clarifying questions and not asking enough?\nOur vision. AI teammates should have the ability to develop a theory of the mind of the human with whom they are interacting. Theory of mind is a psychological concept that refers to one's"}, {"title": "4.2 Improving the efficiency of code synthesis", "content": "Description. Code synthesis is a key component of intent-first, conversation-oriented development in SE 3.0 (Figure 4), which will be executed many times by developers on a daily basis. As such, synthesis needs to be as efficient as possible.\nAffects. Compiler.next, Teammate.next"}, {"title": "Open question #2", "content": "OQ2: How can we improve the efficiency of the code synthesis process while still preserving (or ideally even increasing) its accuracy?\nOur vision. A promising approach is to enhance the efficiency of the code synthesis process by leveraging principles from Search-Based Software Engineering (SBSE) [29]. Instead of initiating every search from scratch, we propose using past search data (both from local and crowdsourced runs) to guide future search processes. By caching previous search outcomes, the synthesizer can reuse and build on prior knowledge, reducing redundant computations and allowing it to start searches closer to optimal solutions. This reuse of search results not only saves time but also allows for smarter exploration of the problem space. Additionally, extrapolating insights from historical data can help tune search algorithms, such as genetic algorithms or simulated annealing, making them more efficient for specific code synthesis tasks.\nBeyond simply reusing results, historical search data can inform the creation of new heuristics tailored to particular problem domains. By analyzing patterns and characteristics of past successful searches via self-reflection, the synthesizer can learn new heuristics that improve the search process, making it more targeted and accurate. This would allow the system to better adapt to different kinds of code synthesis problems and provide more efficient solutions that are aligned with user needs.\nFinally, incorporating past search data allows for a degree of personalization in the code synthesis process. By learning from a user's previous search behaviors and preferences, the searches can be guided toward more relevant solutions, increasing both the efficiency and quality of the results. Over time, as more data is accumulated, the system will continuously improve, offering increasingly efficient and accurate code synthesis."}, {"title": "4.3 Improving runtime performance", "content": "Description. Runtime is a critical piece of the SE 3.0 stack. As FMware gets more and more complex, efficiently serving and evolving these applications while meeting SLAs and making the best use of heterogeneous hardware resources remains a key challenge.\nAffects. Runtime.next"}, {"title": "Open question #3", "content": "OQ3: How can we improve the runtime performance beyond what state-of-the-art serving frameworks such as Ray Serve [11] can provide?\nOur vision. In FMware, the computation sequence is usually described in the form of a workflow that prescribe which models (or agents) will be triggered, how, and which order. While the norm is to use inductive expressions (e.g., a Python script) to represent this workflow, our vision is to compile such workflow into a graph representation that allows for a declarative expression of the FMware logic and preserves rich intent information. With intents preserved, the runtime becomes able to process this graph to perform several optimizations to decrease FM inference latency, decrease data movement, and maximize resource utilization.\nWe have been refining and implementing this vision through FMArts (a lifecycle engineering platform for FMware) and its Fusion Runtime [32]. Preliminary results show a latency improvement in the order of 30% compared to Ray Serve."}, {"title": "4.4 Improving FM's understanding of code and SE", "content": "Description. Popular generalist FMs such as GPT-40 and Claude treat code as text and simply learn patterns during pretraining, which limits their ability to fully comprehend the rich nature of both code and software engineering processes. While these models may pick up on basic code structures, richer semantic information (e.g., code execution knowledge, development workflows, and design patterns) is only partially learned. In contrast, code FMs such as DeepSeek-Coder [22], Qwen2.5-Coder by Alibaba [35], and CodeStral [44] by Mistral AI are explicitly trained on source code to better capture the semantics of code. However, research has shown that such models do not fully understand code [50] (let alone software engineering).\nAffects. Compiler.next, Teammate.next"}, {"title": "Open question #5", "content": "OQ5: What approaches should we use to improve code FMs so that they not only understand code but also broader software engineering principles?\nOur vision. Current code FMs miss the dynamic view of code (e.g., execution logic, dynamic state of variables, call stacks) as well as the interplay between the static view and this dynamic view. Moving forward, we observe opportunities for creating multi-modal FMs that take into account both the static and the dynamic perspectives of code. For instance, Ding et al. [23] pretrain a multi-modal FM on a combination of source code and execution traces with the goal of teaching that FM complicated execution logic. The authors show promising results for clone retrieval and vulnerability detection tasks.\nWhile current efforts focus on integrating execution traces, we see further opportunities in combining code FMs with deeper static analysis techniques, such as symbolic execution and data flow analysis. These approaches could help models grasp the dynamic behavior of code more comprehensively by understanding how variables, memory, and control flow evolve during"}, {"title": "4.5 Eliminating the need for prompt engineering", "content": "Description. An AI teammate should be able to understand intents at the same level that a senior software engineer would. Developers should not have to worry about phrasing their intents as prompts that must be crafted using an unnatural lingo that implements some specific prompt engineering [21] technique (e.g., chain-of-thought [63]). Moreover, research shows that prompts are very fragile [27, 32] (i.e., even slight variations in a prompt can lead to very different outputs) and that their effectiveness is model-dependent [19]. Although we use the AI teammate as an example, this problem occurs every time one needs to interface with a FM.\nAffects. Entire stack, since every layer has FMware in it."}, {"title": "Open question #6", "content": "OQ6: What is the best approach to avoid prompt engineering?\nOur vision. In our vision, the burden of crafting an effective prompt should be on the AI rather than on humans, be them users of IDE.next or the developers of the SE 3.0 stack. Although techniques such as Automatic Prompt Engineer [68], PromptBreeder [26] and DSPy [38] exist, they still require complicated setup and are typically costly to use. A cost-effective prompt transpiler is required to seamlessly take a human inquiry and transform it into an optimal prompt for a given model while still being keeping the entire process cost-effective. We foresee two promising research avenues:\n- Novel model training strategies. Bleeding-edge models such as OpenAI 01 are trained with reinforcement learning techniques to perform complex reasoning. These models simply do not require prompt engineering by construction. In fact, prompt engineering confuses them due to the added verbosity.\n\u2013 Building on top of Compiler.next A promising solution is to gather human feedback (e.g., thumbs up/down) for prompt responses then automatically using that feedback to improve upcoming responses. For example, one could store  pairs where response is of good quality (e.g., it received a thumbs up) and later on leverage those pairs to create few-shot examples in the system prompt (note \u201cexamples\" in Figure 4). Over time, with a big enough database, the model will learn to produce higher quality responses for the same prompt. Such a functionality is being currently developed by LangChain [41] and highlights the importance of collecting observability data. This solution can be further improved by combining it with crowdsourcing, since many of the questions asked by developers are repetitive (fundamental principle behind Q&A systems such as Stackoverflow). As developers interact with the AI Teammate to align their intents, we anticipate that they will eventually reach a wording that"}, {"title": "4.6 Other open questions", "content": "Last but not least, we list other open questions for which we have not yet developed a thorough vision yet:\n\u2022 OQ7: What is a good software engineer in the SE 3.0 era? How should we train the next generation of software engineers? How should we reimagine the software engineering and computer science academic curricula for the SE 3.0 era?\n\u2022 OQ8: What should the UI of IDE.next look like? What would be the key elements of its interaction design? Should AI teammates or agents replace plugins? What does debugging look like in IDE.next?\n\u2022 OQ9: How can we evaluate the overall performance of Compiler.next and what should the benchmark look like? How can we make such a benchmark more actionable (e.g., compared to SWE-bench [36, 49])? More generally, how can we make FMs for code more interpretable [50]?\n\u2022 OQ10: Since AI Teammates are highly personalized and learn over time, what happens when a developer leaves a company? Is the teammate company's IP or a developer's personal asset? How to find a middleground?\n\u2022 OQ11: How can we promote open innovation in the SE 3.0 era? How can we work as teams of researchers and innovators instead of siloed research labs?\n\u2022 OQ12: Software should be for all and by all [8]. How can we minimize the impact of SE 3.0 on accessibility, equity, and fairness due to its reliance of sophisticated infrastructure to develop, execute, and monitor FMware?"}, {"title": "5 CONCLUSION", "content": "Copilots are code completion systems at heart. While code completion is definitely useful in the acceleration of mundane tasks and exploration of new ideas [12], the overall engineering process"}]}