{"title": "LOST-IN-DISTANCE: IMPACT OF CONTEXTUAL PROX- IMITY ON LLM PERFORMANCE IN GRAPH TASKS", "authors": ["Hamed Firooz", "Maziar Sanjabi", "Wenlong Jiang", "Xiaoling Zhai"], "abstract": "Despite significant advancements, Large Language Models (LLMs) exhibit blind spots that impair their ability to retrieve and process relevant contextual data effec- tively. We demonstrate that LLM performance in graph tasks with complexities beyond the \"needle-in-a-haystack\u201d scenario\u2014where solving the problem requires cross-referencing and reasoning across multiple subproblems jointly is influ- enced by the proximity of relevant information within the context, a phenomenon we term \"lost-in-distance\". We examine two fundamental graph tasks: identify- ing common connections between two nodes and assessing similarity among three nodes, and show that the model's performance in these tasks significantly depends on the relative positioning of common edges. We evaluate three publicly available LLMs-Llama-3-8B, Llama-3-70B, and GPT-4-using various graph encoding techniques that represent graph structures for LLM input. We propose a formu- lation for the lost-in-distance phenomenon and demonstrate that lost-in-distance and lost-in-the middle phenomenas occur independently. Results indicate that model accuracy can decline by up to 6x as the distance between node connections increases, independent of graph encoding and model size.", "sections": [{"title": "INTRODUCTION", "content": "Large Language Models (LLMs) have attained an unprecedented level of generality by leverag- ing scale and attention-based architectures (Kaplan et al., 2020; Vaswani, 2017). These models exhibit remarkable, often superhuman, capabilities across a diverse range of tasks, including lan- guage translation, reading comprehension, and question answering (Costa-juss\u00e0 et al., 2022; Sanh et al., 2021). Additionally, LLMs are increasingly serving as essential and flexible building blocks for various user-facing machine learning and artificial intelligence applications beyond traditional language processing domains, such as recommendation systems (Geng et al., 2022), graph-related tasks (Wang et al., 2024), knowledge bases (AlKhamissi et al., 2022; Petroni et al., 2019), and more. These applications highlight the versatility of LLMs but also expose new challenges in handling domain-specific data encoded as textual input.\nParticularly, by leveraging the extensive common knowledge and powerful semantic comprehension abilities of LLMs, recent research has aimed to apply them to tasks related to graph structures (Wang et al., 2024). LLMs are increasingly being adopted for a variety of tasks that involve graph structures, such as planning in robotics (Andreas, 2022), knowledge extraction using knowledge graphs (Shen et al., 2020; Saxena et al., 2020), and multi-hop question answering (Creswell et al., 2022; Fang et al., 2019). For instance, they have been used to guide agents through structured graph-based environments (Huang et al., 2022). Building upon these applications, recent works by Sanford et al. (2024), Perozzi et al. (2024), and Agarwal et al. (2020) have demonstrated that graph tasks can be encoded into textual formats that allow pre-trained LLMs to solve them as out-of-domain tasks. This innovative approach effectively transforms graph problems into a language that LLMs can understand and process.\nWhile LLMs are being expanded in many applications, they suffer from certain blind spots that significantly affect their performance. In particular, how these models process information in their"}, {"title": "1.1 NOTATIONS AND DEFINITIONS", "content": "We define a graph G = (V,E), where V = {V1, V2, ..., Vn } and E represent the sets of nodes and edges, respectively. If nodes vi and vj are directly connected, we denote the edge between them as eij \u2208 E. The neighbors of node vi are defined as N(vi) = {Vk \u2208 V | Cik \u2208 E}. A subgraph associated with node vi is defined as Gv\u2081 = ({vi} UN(vi), Ev\u2081), where Ev\u2081 = {lij | lij \u2208 E, vj E N(vi)}.\nWe define the distance between a common node v within two subgraphs Gu and Gz as the number of tokens separating the two occurrences of node v in the context (i.e., the textual representation of the subgraphs). The overall distance between relevant information for common connections between the two subgraphs is defined as the median of all such distances computed for each common node. Throughout the paper, we use p to indicate position and d to indicate distance."}, {"title": "2 GRAPH ENCODING AND GRAPH TASKS", "content": ""}, {"title": "2.1 GRAPH ENCODING FOR LLM", "content": "Representing graph-structured data as text is an important step in enabling LLMs to understand graph structures and provide accurate answers to questions. Encoding graphs as text involves repre- senting both nodes and edges. Different graph encodings can lead to varying performance of LLMs in graph reasoning tasks (Agarwal et al., 2020; Fatemi et al., 2024; Zhang et al., 2024a). In this work, we encode nodes as integers, where each node is represented by a unique integer, such that vi \u2208 {0,1,..., n \u2212 1}.\nWe experiment with three encoding functions from Fatemi et al. (2024) to encode edges in the graph, investigating whether patterns are consistently observed across different encoding functions. More specifically, we consider the following edge encoding functions:\n\u2022 Incident: Given a source node vi, the edge information for node vi is encoded as an adjacency list in natural language. For example, \"node vi is connected to nodes vj, Uk\".\n\u2022 Adjacency: Given a source node vi and a target node vj, the edge is encoded as (vi, vj).\n\u2022 Expert: Given a source node vi and a target node vj, the edge is encoded as vi \u2192 Vj.\nSince the graph tasks considered in this paper only require access to the subgraph and the subgraph structure, we encode only the edge information for the nodes of interest. This is a common practice where a subgraph is extracted from a database before being processed by a compute engine (Shao et al., 2013). Figure 1 shows an example about only including a subgraph with three encoding functions in the prompt. In this example, node 0 and node 1 are nodes of interest so we only encode their subgraph in the prompt."}, {"title": "2.2 GRAPH GENERATION", "content": "In this paper, we build upon previous studies (Huang et al., 2022; Fatemi et al., 2024; Zhang et al., 2024b) by conducting experiments on randomly generated graphs. We utilize the Erd\u0151s-R\u00e9nyi (ER)"}, {"title": "2.3 GRAPH TASKS", "content": "We aim to analyze the performance of LLMs in three fundamental graph problems which require models to have thorough understanding of the input graph structure.\n1. Edge Existence: Given two nodes vi and vj sampled from a graph G, node vi and node vj are directly connected if eij \u2208 E. The edge existence task is to ask LLMs whether node vi and node vj are directly connected.\n2. Common Connection: Given two nodes vi and vj sampled from a graph G, the common connection between two nodes are N(vi) \u2229 N(vj). For this task, we ask LLMs to find the number of common connections between node vi and node vj, denoted as |N(vi)\u2229N(vj)|.\n3. Similarity: Given three nodes vi, vj and vk sampled from a graph G, we let vj be the source node and vi and vk be the target nodes. The task for LLMs is to compare the number of common connections |N(vi) \u2229 N(vj)| and |N(vj) \u2229N(vk)|.\nNote that these tasks are roughly ordered in terms of general complexity. For example, solving the edge existence only depends on the model being able to retrieve the edge information from the representation. One step further, in finding the number of common connections, models needs to first identify the set of shared connections between two nodes and then calculate the size of that set. Finally, the similarity task is more complex than the common connection task, as it requires LLMs to consider three nodes and identify two sets of common connections and then compare their sizes. As a result, these tasks are a good representative set to evaluate LLMs since they require LLMs to both retrieve and reason about the graph information. Furthermore, these tasks are also essential and the building blocks for solving practical problems in applications such as recommendation systems (Ying et al., 2018), protein folding (Strokach et al., 2020), bad actor detection (Papegnies et al., 2017) or any other task that requires graph understanding."}, {"title": "3 LOST-IN-THE-MIDDLE FOR EDGE EXISTENCE", "content": "The edge existence task is analogous to the needle-in-a-haystack problem (Ivgi et al., 2023) and the document question-answering task (Liu et al., 2023), as it requires the LLM to retrieve the answer from the prompt without performing any computation. Building upon prior work in the literature by Liu et al. (2023), this study demonstrates the impact of the position of relevant information on the performance of LLMs. Specifically, it is shown that the accuracy in the edge existence task decreases when the information about the edge in question is placed in the middle of the prompt.\nThe prompt structure is constructed using the following procedure, which enables controlling the location of information within the prompt:\n1. Randomly sample two nodes from a graph along with their corresponding connections.\n2. Randomly select nine additional nodes as noise nodes and incorporate their textual sub- graph encodings into the prompt. This step is necessary to examine the impact of the position of relevant information.\n3. Group the subgraph structures of the two nodes of interest and position them at the begin- ning, middle, or end of the input context.\n4. Query the model to determine whether an edge exists between the two nodes of interest.\nAn example of a prompt with different positions for the two nodes of interest is illustrated in Fig- ure 2."}, {"title": "3.1 EXPERIMENTAL RESULTS", "content": "Lost-in-the-middle can happen in the edge existence task. To demonstrate the lost-in-the-middle phenomena in edge existence task, we experiment with the state of the art model as of writing this paper GPT-4. The experiment results are averaged over twenty randomly generated graph where from each graph we randomly select two nodes and form the edge existence prompt as described in previous section.\nFigure 3 shows that all encodings can cause the LLM to lose the information in the middle of the prompt. The best performance occurs when the relevant information is either at the beginning or the end of the entire subgraph structure. Even for the incident encoding which has the best performance among all encodings, the LLM still has the worst performance when the answer is located in the middle of the prompt."}, {"title": "4 LOST-IN-DISTANCE", "content": "Tasks such as the edge existence require LLMs to perform needle-in-a-haystack retrieval, which, as previously shown, suffers from the lost-in-the-middle phenomenon in long contexts. However, in"}, {"title": "5 EXPERIMENTATION", "content": "In our initial experiments, we focused on the common connection task. This task requires the model to determine the number of common connections between two nodes by joining information across two subgraphs. Our results demonstrate that the models' performance degrades as the distance between the relevant pieces of information in the two subgraphs increases. Specifically, when the information about each node's connections is placed further apart in the context, the models struggle to effectively retrieve and integrate this information to compute the correct number of common connections.\nWe then investigated how the lost-in-distance impacts tasks that require multiple cross-referencing steps, such as the similarity task. In the similarity task, the model needs to first identify the common connections between each of the two nodes and a reference node, and then compare these sets to determine the degree of similarity. Our findings reveal that performance degradation is even more pronounced in this case, as the task requires the model to perform multiple join operations over dispersed pieces of information within the context."}, {"title": "5.1 EXPERIMENTAL SETUP", "content": "Leveraging in-context learning (Dong et al., 2022; Wei et al., 2023), we conducted experiments using both closed-source models (GPT-4) and open-source models (Llama-3-8B-Instruct and Llama- 3-70B-Instruct). For all models, we set the decoding temperature to zero to ensure the generation of deterministic answers. In each sample, we randomly selected two or three nodes as the nodes of interest for the common connection and similarity tasks, respectively. We performed experiments on hundreds of thousands of randomly generated graphs to draw statistically significant conclusions regarding LLM behavior. The experimental results were then averaged across multiple samples."}, {"title": "5.2 \u0421\u043e\u043cMON CONNECTION TASK", "content": "In this section, we demonstrate the effect of increased distance on solving the common connec- tion task. To create an input prompt for this task and to control the relative distance of relevant information (common neighbors), we use the following methodology:"}, {"title": "5.2.1 LOST-IN-DISTANCE IN COMMON CONNECTION TASK", "content": "The results presented in Figure 5 illustrate the impact of varying the positions of common edges within each subgraph (following the methodology outlined in the previous section) on the model's performance in the common connection task. Unlike the edge existence task, the model's perfor- mance is influenced not only by the lost-in-the-middle phenomenon but also by the relative distance between common connections.\nWith the position of relevant information fixed in one subgraph, we observe that the model's perfor- mance degrades when the other subgraph is positioned closer to the middle of the prompt, influenced by the lost-in-the-middle phenomenon. For example, in adjacency encodings (Figure 5, middle plot), when the first node's common connection is at position 0 (the beginning of the prompt), the model's performance deteriorates from 40% to 20% as the second node's common connection shifts from position 5 (the end) to position 3 (the middle). However, in contrast to the lost-in-the-middle phe- nomenon, Figure 5 demonstrates that across all three graph encodings, the model achieves optimal performance when relevant information is centrally located, with minimal distance between compo- nents at positions (2, 3). This illustrates the effect of lost-in-distance. Furthermore, when the first node's common connection is at position 2, the model's accuracy drops by up to 50% as the second"}, {"title": "5.3 SIMILARITY TASK", "content": "Solving the similarity between three nodes vi, vj, and vk requires the model to perform two common connection tasks, |N(vi) \u2229N(vj)| and |N(vj) \u2229N(vk)|, and subsequently compare the results. As a result, the model needs to execute two cross-referencing operations between the subgraphs: one between Gv\u2081 and Gv;, and the other between Gv; and Gvk. Therefore, as we will demonstrate in this section, solving the similarity task inherently suffers from the lost-in-distance phenomenon.\nTo measure the effect of the lost-in-distance phenomenon, we select three nodes-vi, vj, and Uk-from a given graph and randomly shuffle the edges within each node's subgraph. We desig- nate vj as the source node for the similarity task, vi as the first target node, and vk as the second target node. In all scenarios, to mitigate the influence of the lost-in-the-middle effect and highlight the effect of lost-in-distance, the textual encoding of the source node vj's subgraph (Gv;) is posi- tioned at the center of the prompt, while the subgraphs of the other two nodes are placed one before and one after it.\nWe quantify the lost-in-distance effect by calculating the median distance, measured in terms of tokens, between the common connections of the two subgraphs, specifically |N(vi) \u2229 N(vj)| and |N(vj)\u2229N(vk)|. The distance distribution is illustrated in Figure 6 for three different graph encod- ings. We utilize the thresholds presented in Table 1 to categorize the distances into small, medium, and large groups. Furthermore, in order to make sure more uniform coverage, we employ rejection sampling to ensure that each distance group contains one hundred samples with balanced responses.\nTo eliminate potential biases, for the three subgraphs Gv\u2081, Gv;, and Gvk, where vj is the source node for similarity, we generate questions randomly chosen from the following two templates:\n\u2022 Is the number of common connections between node vj and node vk greater than the number of common connections between node vi and node vj?\n\u2022 Is the number of common connections between node vi and node vj greater than the number of common connections between node vj and node vk?"}, {"title": "5.3.1 LOST-IN-DISTANCE IN SIMILARITY TASK", "content": "For brevity, we present the results of one encoding for each model in Figure 7, with all results summarized in Appendix C.2. Our findings indicate that when both distances are minimal, GPT- 4 and Llama-3-70B-Instruct exhibit the best performance. Llama-3-8B-Instruct, which has a high failure rate in following instructions as described in Appendix A.2, demonstrates the second-best performance, though it is not significantly different from the top performers.\nSpecifically, performance at the largest distances is significantly worse compared to that at the small- est distances. As the distances increase (i.e., along the diagonal elements), the performance of all models deteriorates. In Llama-3-70B, we observe a 12% drop in model accuracy when the distance between common connections for both |N(vz) \u2229 N(v;)| and |N(v;) \u2229 N(vk)| increases, shifting from the (Small, Small) index to the (Large, Large) index in the heatmap plot. These results high- light that the lost-in-distance phenomenon adversely affects model performance in similarity tasks."}, {"title": "6 GOODNESS OF FIT FOR LOST-IN-DISTANCE", "content": "In this section, we employ the Equation 2 function to capture the effects of the lost-in-distance phenomenon and to separate its impact from that of the lost-in-the middle effect. To evaluate the goodness of fit for the lost-in-distance function defined in Equation 2, we compare it to a simpler function that accounts solely for the lost-in-the-middle effect as follows:\n$\\mathbb{E}[F(p_1, p_2)|G(p_1), G(p_2)] = \\gamma G(p_1)G(p_2), $ (3)\n$\\mathbb{E}[F(p_1, p_2)|\\gamma, G(p_1), G(p_2)] = \\gamma G(p_1)G(p_2)H(|p_2 - p_1|), $ (4)\nwhere H (p2 - p1|)) is the effect of lost-in-distance d = |p2 - p1|.\nTo measure the goodness of fit we leverage results and output of common connection experiments but the result and findings here are extendable to similarity task as well. We randomly split samples into training and test sets of equal size. Using the training set, we first estimate G(\u00b7) using interpo- lation based on the accuracy observed in the edge existence task. Then, we estimate \u03b3 by regressing F(p1, p2) onto \u011c(p1)\u011c(p2). Finally, given the estimated \u03b3 and \u011c(\u00b7), we estimate H(\u00b7) using\n$\\hat{H}(d) = \\frac{1}{D_d} \\sum_{(p_1, p_2) \\in D} \\frac{F(p_1, p_2)}{\\hat{G}(p_1)\\hat{G}(p_2)}, $(5)"}, {"title": "A ANALYSIS", "content": ""}, {"title": "A.1 CONTEXT LENGTH", "content": "Table 3 summarizes the average context length (i.e., the number of tokens) for each task and each graph encoding. We use the tokenizer of Llama-3 to calculate the context length for Llama-3-8B- Instruct and Llama-3-70B-Instruct and use the tiktoken library (OpenAI, 2023b) to calculate the context length for GPT-4 and GPT-40. The incident encoding produces the shortest context length, while the adjacency encoding results in the longest context length."}, {"title": "A.2 ANSWER DEGENERATION", "content": "LLMs sometimes fail to follow instructions and generate responses that do not adhere to the ex- pected output template. We classify these degenerate responses as incorrect answers, i.e., Yi \u2260 Yi for accuracy calculation in Equation 1. Llama-3-8B-Instruct is less likely to generate a final answer compared to GPT-40 and Llama-3-70B-Instruct, which explains why it has lowest accuracy in Fig- ure 7. Table A.2 summarizes the percentage of samples in which models fail to follow instructions. Generally, the most common patterns of degenerate answers are as follows:\n\u2022 Repetition: LLMs sometimes repeat the same context until they reach the maximum num- ber of output tokens, thereby failing to generate a final answer.\n\u2022 Self-contradiction: In CoT prompting, LLMs are asked to answer the main question based on their responses to subquestions. However, we find that LLMs sometimes provide an incorrect final conclusion. For example, as shown in Figure 9 where we ask the LLM \"is the number of common connections between node 658 and node 535 greater than the number of common connections between node 535 and node 807?\", the LLM determines that the number of common connections between node 658 and node 535 is 6, and between node 535 and node 807 is 4, but the final answer is \u201cno\u201d when it should be \u201cyes\u201d."}, {"title": "\u0412 \u0421\u043e\u043c\u043cON CONNECTION: MORE RESULT", "content": "Figure 10 illustrates the impact of the lost-in-distance phenomenon on the GPT-40 model (OpenAI, 2023a) in solving the common connection task. Although the accuracy metrics slightly differ from those in Figure 5 for GPT-4, the pattern of the lost-in-distance effect remains consistent."}, {"title": "C SIMILARITY TASK", "content": ""}, {"title": "C.1 PROMPT EXAMPLE", "content": "Figure 11 illustrates an example of the similarity task prompt, as described in Section 5.3, along with GPT-40's answer for solving the similarity task using incident graph encoding."}, {"title": "C.2 ALL RESULTS", "content": "Figure 12 presents the results of the similarity task at a density of 0.1 across three models (GPT- 40, Llama-8B, Llama-70B) and three different graph encodings. For all models utilizing the graph encoding functions, we observe the typical lost-in-distance pattern, where performance at the (Small, Small) index is better than at the (Large, Large) index."}, {"title": "D EFFECT OF GRAPH DENSITY", "content": "The lost-in-distance effect remains consistent across different graph densities, i.e., different values of P(eij \u2208 E) in Erd\u0151s\u2013R\u00e9nyi (ER) randomly generated graphs. Graph density affects the input sequence length in a linear manner; higher densities result in proportionally longer input sequences, as demonstrated in Table 5.\nFigure 13 illustrates that increasing the context length by raising graph density follows the same pattern of the lost-in-distance effect in similarity tasks. Specifically, accuracy declines progressively from top to bottom and left to right as the distances between common edges within each subgraph increase. Additionally, the figure demonstrates that for smaller context lengths, corresponding to graphs with low density, the results are noisier and the effect of lost-in-distance diminishes."}]}