{"title": "XEQ Scale for Evaluating XAI Experience Quality Grounded in Psychometric Theory", "authors": ["Anjana Wijekoona", "Nirmalie Wiratunga", "David Corsar", "Kyle Martina", "Ikechukwu Nkisi-Orji", "Belen D\u00edaz-Agudo", "Derek Bridge"], "abstract": "Explainable Artificial Intelligence (XAI) aims to improve the transparency of autonomous decision-making through explanations. Recent literature has emphasised users' need for holistic \"multi-shot\" explanations and the ability to personalise their engagement with XAI systems. We refer to this user-centred interaction as an XAI Experience. Despite advances in creating XAI experiences, evaluating them in a user-centered manner has remained challenging. To address this, we introduce the XAI Experience Quality (XEQ) Scale (pronounced \"Seek\" Scale), for evaluating the user-centered quality of XAI experiences. Furthermore, XEQ quantifies the quality of experiences across four evaluation dimensions: learning, utility, fulfilment and engagement. These contributions extend the state-of-the-art of XAI evaluation, moving beyond the one-dimensional metrics frequently developed to assess single-shot explanations. In this paper, we present the XEQ scale development and validation process, including content validation with XAI experts as well as discriminant and construct validation through a large-scale pilot study. Out pilot study results offer strong evidence that establishes the XEQ Scale as a comprehensive framework for evaluating user-centred XAI experiences.", "sections": [{"title": "1 Introduction", "content": "Explainable Artificial Intelligence (XAI) describes a range of techniques to elucidate autonomous decision-making and the data that informed that AI system [19, 12, 2]. Each technique typically provides explanations that focus on a specific aspect of the system and its decisions. Accordingly, the utility of employing multiple techniques for a holistic explanation of a system becomes increasingly clear [2, 27]. The collection of explanations, provided by different techniques and describing different components of the system, forms what we describe as \"multi-shot\" explanations. Previous work has demonstrated the effectiveness of delivering multi-shot explanations using graphical user interfaces [2] and conversation [18, 27]. While the utility of user-centred interactive explanations is evident in recent literature, the evaluation of these interactions remains a key research challenge. Current works primarily target the development of objective metrics for single-shot techniques [24, 28], emphasising the need for reproducible benchmarks on public datasets [16]. Such metrics are system-centred and model-agnostic, giving the advantage of generalisability. However, objective metrics fail to acknowledge the requirements of different stakeholder groups. A satisfactory explanation is reliant on the recipient's expertise within that domain and of AI in general [20]. Subjective metrics, such as those described in [10, 11], allow an evaluation which is personalised to the individual and domain. However, existing subjective evaluations lack the capacity to measure the interactive process that underpins multi-shot explanations and how they impact user experience.\nWe address this challenge by introducing the XAI Experience Quality (XEQ) Scale (pronounced: \"seek\" Scale). We define an XAI Experience as the user-centred process of a stakeholder interacting with an XAI system to gain knowledge and/or improve comprehension. XAI Experience Quality (XEQ) is defined as the extent to which a stakeholder's explanation needs are satisfied by their XAI Experience. A glossary of all related terminology used throughout this paper is included. Specifically, we ask the research question: \"How to evaluate an XAI experience, in contrast to assessing single-shot (non-interactive) explanations?\". To address this, we follow a formal psychometric scale development process [3] and outline the following objectives:\n1. conduct a literature review to compile a collection of XAI evaluation questionnaire items;\n2. conduct a content validity study with XAI experts to develop the XEQ scale; and\n3. perform a pilot study to refine and validate the XEQ scale for internal consistency, construct and discriminant validity.\nThe rest of this paper expands on each objective. We discuss related work in Section 2. Section 3 presents key previous publications and the creation of the initial items bank. The Content Validity study details and results are presented in Section 4 followed by Section 5 presenting pilot study details for the refinement and validation of the"}, {"title": "2 Related Work", "content": "In the literature, there are several methodologies for developing evaluation metrics or instruments for user-centred \u03a7\u0391\u0399.\nHoffman et al. [9] employed Psychometric Theory to construct the Satisfaction Scale, evaluating both content validity and discriminant validity. A similar methodology was adopted in [17] to develop the Madsen-Gregor human-machine trust scale, relying on pre-existing item lists from previous scales in conjunction with expert insights [21]. Jian et al. [13] pursued a factor analysis approach involving non-expert users to formulate a human-machine trust scale. They compiled words and phrases associated with trust and its variants, organising them based on their relevance to trust and distrust, which were then clustered to identify underlying factors and formulate corresponding statements. This methodology is particularly suitable in cases where no prior items exist for initial compilation. While these methodologies are robust to produce reliable scales they are resource and knowledge-intensive processes.\nA more frequent approach to scale development is deriving them from existing scales in psychology research. For instance, the System Causability Scale [11] draws inspiration from the widely used System Usability Scale [4], while the Hoffman Curiosity Checklist originates from scales designed to assess human curiosity [9]. Similarly, the Cahour-Forzy Trust Scale [5] selected questions from research on human trust, and the Hoffman Trust Scale incorporates items from previous trust scales [5, 13]. Notably, these derived scales were not evaluated for reliability or other desirable factors, they rely on the quality of the original scales for validity. In this paper, we opt for the psychometric theory approach to establish the content, construct and discriminant validity of the resulting scale. While this approach is resource-intensive, the complexity and the novelty of the evaluation task necessitate a rigorous approach to scale development."}, {"title": "3 Literature Review and Initial Items Bank Compilation", "content": "This section presents the literature review findings that led to the compilation of the initial items bank for the XEQ Scale."}, {"title": "3.1 Methodology", "content": "To scope the existing work and form the initial item bank, we conducted a targeted literature review in the domain of XAI evaluation metrics. The reasoning for a targeted review instead of a systematic review is two fold: 1) the purpose of the review is to form the initial item bank which involves in depth analysis of selected literature (depth over breadth); and 2) literature under this topic is significantly limited. The initial findings highlighted that while many publications discuss and emphasise the importance of evaluation dimensions (what should be or is evaluated), only a few actually propose and systematically develop metrics for XAI evaluation."}, {"title": "3.2 Findings: Evaluation Dimensions and Metrics", "content": "Hoffman et al. [9] are one of the leading contributors and their work has been widely utilised in many user-centred XAI research. They conceptually modelled the \"process of explaining in XAI\" outlining dimensions and metrics for evaluating single-shot explanations from stakeholders' perspectives. They considered six evaluation dimensions: goodness, satisfaction, mental model, curiosity, trust and performance. For each dimension, they either systematically developed an evaluation metric or critiqued metrics available in literature offering a comprehensive evaluation methodology for XAI practitioners. System Causability Scale [11] is the other most prominent work in XAI evaluation. We discuss each scale briefly below.\nHoffman's Goodness Checklist is utilised to objectively evaluate explanations with an independent XAI expert to improve the \"goodness\". It consists of 7 items answered by either selecting 'yes' or 'no'. It was developed by referring to literature that proposes \"goodness\" properties of explanations.\nHoffman Satisfaction Scale was designed using psychometric theory to evaluate the subjective \"goodness\" of explanations with stakeholders. It consists of 8 items responded in a 5-step Likert Scale. It is viewed as the user-centred variant of the Goodness Checklist with many shared items. However, conversely, it has been evaluated for content validity with XAI experts as well as construct and discriminant validity in pilot studies.\nHoffman Curiosity Checklist is designed to elicit stakeholder explanation needs, i.e. which aspects of the system pique their curiosity. This metric consists of one question Why have you asked for an explanation? Check all that apply. and the responses inform the design and implementation of the XAI system.\nHoffman Trust Scale measures the development of trust when exploring a system's explainability. The authors derived this trust scale by considering the overlaps and cross-use of scales from trust scales in literature for measuring trust in autonomous systems (not in the presence of explainability, e.g. trust between human and a robot) [13, 1, 25, 5].\nSystem Causability Scale measures the effectiveness, efficiency and satisfaction of the explainability process in systems involving multi-shot explanations [11]. Derived from the widely-used System Usability Scale [4], this scale comprises 10 items rated on a 5-step Likert scale. Notably, it includes items that measure stakeholder engagement, addressing a gap in previous scales designed for one-shot explainability settings. However, the validation of the scale is limited to one small-scale pilot study in the medical domain."}, {"title": "3.2.1 Other Dimensions", "content": "Many other publications emphasised the need for user-centred XAI evaluations and explored evaluation dimensions. Two other dimensions considered in [9] are mental model and performance concerning task completion. Hoffman et al. recommended eliciting the mental model of stakeholders in think-aloud problem-solving and question-answering sessions. Performance is measured by observing the change in productivity and change in system usage. The evaluation of these dimensions requires metrics beyond questionnaire-based techniques. Another domain-agnostic survey finds many overlaps with Hoffman et al., defining 4 user-centred evaluation dimensions: mental model, usefulness and satisfaction, trust and reliance and human-task performance [20]. Zhou et al., [29] summarise previous literature, emphasising three subjective dimensions - trust, confidence and preference that overlap with dimensions identified in [9]. Conversely to Hoffman et al., they consider task completion to be an objective dimension in user-centred XAI evaluation.\nCarvalho et al., delineate characteristics of a human-friendly explanation in the medical domain, including some subjective or user-centred properties such as comprehensibility, novelty, and consistency with stakeholders' prior beliefs [6]. Notably, consistency with stakeholders' prior beliefs aligns with the mental model from Hoffman et al. [9], while novelty can influence stakeholder engagement [11]. Nauta and Seifert [22] recognise 12 properties of explanation quality for image classification applications. They identify three user-centred properties: context - how relevant the explanation is to the user; coherence - how accordant the explanation is with prior knowledge and beliefs; and controllability - how interactive and controllable the explanation is. In comparison to other literature, controllability aligns with engagement [11] and coherence aligns with the mental model [9, 6]. Context can be associated with several properties such as curiosity, satisfaction, and preference [9, 29].\nThese findings highlighted that there are many overlaps between evaluation dimensions identified in recent years. However, we highlight two main gaps in this current work: 1) there is no consensus in previous literature regarding the applicable metrics to measure these evaluation dimensions; and 2) the majority of the existing dimensions and metrics focus on evaluating individual explanations, not the XAI experiences."}, {"title": "3.3 Compiling the Initial Item Bank", "content": "The initial item bank of 40 items included 7 from the Goodness Checklist [10]; 8 from the Satisfaction Scale [10]; 8 from the Trust Scale [10]; and 10 from the System Causability Scale [11]. Seven additional items were authored and included by the research team. These were designed to capture stakeholder views on the interactive experience which is less explicitly addressed in previous literature. This initial list underwent a rigorous review and revision process, during which the research team eliminated duplicates, consolidated similar items, and rephrased items to reflect the measurement of XAI experiences instead of explanations. The resulting 32 statements formed the initial XEQ Scale (included in Supplementary Material). Response for each item is recorded on a 5-point Likert scale, ranging from \"I Strongly Agree\" to \"I Strongly Disagree\"."}, {"title": "3.3.1 Evaluation Dimensions", "content": "We reviewed evaluation dimensions from previous literature and consolidated XEQ items into four evaluation dimensions representing XAI experience quality: learning, utility, fulfillment, and engagement. These dimensions are relevant to capturing personalised experiences for a given stakeholder. We define them as follows:\nLearning: the extent to which the experience develops knowledge or competence;\nUtility: the contribution of the experience towards task completion;\nFulfilment: the degree to which the experience supports the achievement of XAI goals; and\nEngagement: the quality of the interaction between the user and the XAI system.\nIn the next sections, we describe the development, refinement and validation of the XEQ Scale following Psychometric Theory [23]."}, {"title": "4 XEQ Scale Development", "content": "This section presents the details and results of an expert user study performed to establish the content validity of the XEQ Scale."}, {"title": "4.1 Study Design", "content": "In this study, participants evaluated the initial set of 32 items using the Content Validity Ratio (CVR) method [15]. The CVR method is recommended for quantifying the strength of psychometric scale items with a small group of experts (5-10).\nAt the start, participants are familiarised with the terminology and they explore 3 sample XAI experiences: 1) a student interacting with a chatbot that assists with course recommendations and support; 2) a clinician interacting with the graphical interface of a radiograph fracture detection system for clinical decision support; and 3) a regulatory officer interacting with a local council welfare web page to explore the fairness and biases with the recommender system used for predicting application outcomes. Next, participants are asked to rate the 32 items in terms of their relevance for measuring XAI experience quality using a 5-point Likert scale. The relevance scale ranges from Not Relevant at All to Extremely Relevant. Additionally, we included ratings related to clarity, which also use a Likert scale ranging from Not Clear at All to Extremely Clear. This clarity rating was added to get feedback on how easily the items are understood by the participants. Finally, we provided participants the opportunity to suggest rephrasing for items they found relevant but not clear."}, {"title": "4.2 Recruitment Details", "content": "The participants of this study consisted of XAI experts both from academia and the industry. 38 experts were contacted via email and 13 participated in the study. The 13 participants represented a diverse set of interests in the human-centred XAI research domain and are either actively conducting research or have published XAI research outcomes since 2020. The study was hosted on the Jisc Online Surveys platform for 3 weeks between November and December 2023."}, {"title": "4.3 Metrics", "content": null}, {"title": "4.3.1 Content Validity", "content": "The Content Validity Index (CVI) assesses item validity based on responses to the relevance property. Lower scores indicate items that may need modification or removal. Given scale S with M items where i indicates an item, r denotes the response of participant j to item i. For analysis, each response (r) is modified as follows.\n$r = \\begin{cases}\n1, & \\text{if } r \\in [\\text{Extremely Relevant or Somewhat Relevant}]\n\\\\0, & \\text{otherwise}\n\\end{cases}$\nWe calculate the following two forms of the Content Validity Index (CVI) scores."}, {"title": "Level CVI:", "content": "Item-Level CVI: measures the validity of each item independently; the number of responses is N and the expected score is \u2265 0.78.\n$I-CVI_{i} = \\frac{\\Sigma r_{j}^{i}}{N}$\nScale-Level CVI: measures the overall scale validity using a) Average method i.e. the mean Item-Level CVI score where the expected score is \u2265 0.90; and b) Universal Agreement method i.e. the percentage of items experts always found relevant with the expected value of \u2265 0.80.\n$S-CVI(a) = \\frac{\\Sigma_{i=1}^{M}(I-CVI_{i})}{M}$\n$S-CVI(b) = \\frac{\\Sigma_{i=1}^{M}1[I-CVI_{i} = 1]}{M}$\nHere, once the average of the I-CVIs is calculated for all items with S-CVI(a), S-CVI(b) counts the number of items with an ICVI of 1 (indicating complete agreement among experts that the item is relevant) and divides this by the total number of items."}, {"title": "4.4 Results", "content": "We refer to the first two columns for the results of the Content Validity study. We first removed items with low validity (I-CVI  0.75) and thereafter S-CVI scores were used to establish the content validity of the resulting scale. Here we marginally divert from the established baseline of 0.78 for I-CVI to further investigate items with 0.75 < I-CVI < 0.78 during the pilot study. The Likert responses to the clarity property and free text feedback influenced the re-wording of 7 items to improve clarity (indicated by \u2020). The item selection and rephrasing were done based on the suggestions from the XAI experts and the consensus of the research team. The resulting scale comprised 18 items, which we refer to as the XEQ Scale pronounced: \"Seek\".\nS-CVI(a) and S-CVI(b) of the scale were 0.8846 and 0.2222. While S-CVI(a) is comparable to the baseline of 0.9, S-CVI(b) indicate universal agreement is not achieved. However, existing literature suggests that meeting one of the baseline criteria is sufficient to proceed to pilot studies. Notably, the 14 items with I-CVI \u2265 0.78 also only achieve average agreement (S-CVI(a) = 0.9179) and not universal agreement (S-CVI(b) = 0.2667). Following the item selection and refinement, each item was assigned an evaluation dimension based on the consensus of the research team. These will be used in further investigations using factor analysis to establish the construct validity of the scale."}, {"title": "5 XEQ Scale Refinement and Validation", "content": "In this section, we present the pilot study conducted to refine the XEQ Scale for internal consistency, construct validity and discriminant validity."}, {"title": "5.1 Study Design and Applications", "content": "The study involved two application domains: 1) CourseAssist Chatbot for new students to guide their course selection processes and 2) AssistHub website for welfare applicants to assist with application outcomes. For each application, two sample XAI experiences were designed one relatively positive and one relatively negative experience. The two samples differ in the quality of the explanations presented to the participant and the resulting impact on the overall interaction flow. Participants accessed all samples in video format. These sample experiences create a controlled experiment where the discriminant properties of the scale can be validated.\nFirst, the participants explore the XAI experience and they proceed to respond to the XEQ Scale. In addition, they are also queried about the clarity of items within the scope of the sample experience. Lastly, participants can offer free-text feedback about the study."}, {"title": "5.2 Recruitment Details", "content": "This study enlisted 203 participants, comprising undergraduate students from the leading research institute and participants recruited from the Prolific.co platform. 33 students from the research institute and 70 Prolific participants were recruited for the CourseAssist application where the inclusion criteria were: Current education level - Undergraduate degree; Degree subjects - Mathematics and statistics, Information and Communication Technologies, Natural sciences; and Year of study 1st, 2nd, 3rd or 4th. 100 Prolific participants were recruited for the AssistHub application with the following inclusion criteria: Household size is 3 or larger; Property ownership is either social housing or affordable-rented accommodation; Employment status is either part-time, due to start a new job within the next month, unemployed, or not in paid work (e.g. homemaker or retired). In the rest of this paper, we will refer to all responses to positive experiences as Group A and all responses to negative experiences as Group B. To represent application-specific groups we will use the application name as a prefix; e.g. CourseAssist-A. Each participant was randomly assigned to one of the sample experiences and after review, we excluded 5, 1 and 1 responses from groups CourseAssist-A, AssistHub-A and AssistHub-B who failed the following attention checks: 1) spend less than half of the allocated time; and/or 2) responded to the questionnaire in a pattern. This resulted in 53, 50, 50, and 50 respondents for CourseAssist-A, CourseAssist-B, AssistHub-A and AssistHub-B groups respectively."}, {"title": "5.3 Metrics", "content": "For analysis, we introduce the following notations. Given r is the participant j's response to item i, the participant's total is $r_{j}; and the item total is $r_{i}^{2}$. We transform 5-step Likert responses to numbers as follows: Strongly Disagree-1, Somewhat Disagree-2, Neutral-3, Somewhat Agree-4, and Strongly Agree-5. Accordingly, for the 18-item XEQ Scale, $r_{j} < 90 (5 \\times 18)."}, {"title": "5.3.1 Internal Consistency", "content": "Internal consistency refers to the degree of inter-relatedness among items within a scale. We employ the following metrics from psychometric theory to assess the XEQ Scale items.\nItem-Total Correlation calculates the Pearson correlation coefficient between the item score and the total score the expected value per item is \u2265 0.50. The Item-Total Correlation of item i, iT is calculated as follows.\n$iT = \\frac{\\Sigma_{j=1}^{N}(r_{ji} - \\overline{r_{i}})(r_{j} - \\overline{r})}{\\sqrt{\\Sigma_{j=1}^{N}(r_{ji} - \\overline{r_{i}})^{2} \\Sigma_{j=1}^{N}(r_{j} - \\overline{r})^{2}}}$"}, {"title": "5.3.2 Discriminant Validity", "content": "Discriminant validity measures the ability of the scale to discern between positive and negative experiences and we used the following two methods.\nDiscriminant Analysis treats the pilot study responses as a labelled dataset to train a classification model with a linear decision boundary. The items are considered as features and the group (A or B) is considered as the label. A holdout set then evaluates the model's ability to distinguish between groups A and B.\nParametric Statistical Test uses a mixed-model ANOVA test to measure if there is a statistically significant difference between the two groups A and B (agnostic of the domain). Our null hypothesis is \"no significant difference is observed in the mean participant total between groups A and B\". Our sample sizes meet the requirements for a parametric test determined by an a priori power analysis using G*Power [8]."}, {"title": "5.3.3 Construct Validity", "content": "Construct validity evaluates the degree to which the scale assesses the characteristic of interest [14]. We perform two forms of Factor Analysis (FA) to uncover underlying factors (i.e. dimensions) and validate them.\nExploratory FA finds the number of underlying factors in the scale by assessing the variance explained through the Principal Component Analysis (PCA) coefficients (i.e. eigenvalues).\nConfirmatory FA hypothesise a factor model (e.g. model proposed in the Exploratory FA or a Factor model proposed by XAI experts) and calculate factor loadings where the expected loading for each item is expected to be \u2265 0.5."}, {"title": "5.4 Results", "content": null}, {"title": "5.4.1 Internal Consistency", "content": "column 3 reports the Item-Total Correlation. All items met the baseline criteria of iT >\u2265 0.5 and baseline criteria for Inter-Item correlation. Cronbach's alpha is 0.9562 which also indicates strong internal consistency."}, {"title": "5.4.2 Discriminant Validity", "content": "We performed discriminant analysis over 100 trials where at each trial a different train-test split of the responses was used. Each trial used a stratified split, with 70% of the responses for training and 30% for testing. Over the 100 trials, we observed accuracy of 0.63\u00b10.05 and a macro Fl-score of 0.63 \u00b1 0.05 which is significantly over the baseline accuracy of 0.50 for a binary classification task. Mixed-model ANOVA test showed a statistically significant difference between groups A and B with a p-value of 1.63e 12 where the mean participant total for groups A and B were 70.96 \u00b1 0.47 and 57.97\u00b11.84. Also, it revealed a substantial variability within groups indicated by the group variance of 104.86, which we account for in including responses from two application domains. Furthermore, Cohen's d was 1.7639 which indicates a large effect size confirming a significant difference between groups A and B. A standard t-test also obtained close to zero p-value associated with the t-statistic at 1.13e09 further verifying statistical difference. Based on this evidence we reject the null hypothesis and confirm the discriminant validity of the scale."}, {"title": "5.4.3 Construct Validity", "content": "We first explore the number of factors present in the XEQ Scale using Exploratory FA. There is significant one factor that is evident throughout the scale responses which we refer to as \u201cXAI Experience Quality\u201d. This is evidenced by the sharp drop and plateau of eigenvalues for PCA coefficient 2 onwards. To perform the Confirmatory FA, we re-run Confirmatory FA shows that all item factor loadings are \u2265 0.5 baseline meaning, all items contribute to the over-arching factor measured by this scale. To validate the evaluation dimensions assigned to items by the research team, we create another factor model with 4 factors each assigned with the subset of the items indicated in Again we find that each item meets \u2265 0.5 factor loading for their assigned factor. This confirms that while there is an over-arching factor about \"XAI Experience Quality\", it is substantially underpinned by the four factors Learning, Utility, Fulfilment and Engagement. This concludes our multi-faceted refinement of the XEQ Scale based on pilot study results."}, {"title": "6 Discussion", "content": null}, {"title": "6.1 Implications and Limitations", "content": "In psychometric theory, conducting a pilot study involves administering both the scale under development and existing scales to participants. The objective is to assess the correlation between the new"}, {"title": "7 Conclusion", "content": "In this paper, we presented the XEQ scale for evaluating XAI experiences. The XEQ scale provides a comprehensive evaluation for user-centred XAI experiences and fills a novel gap in the evaluation of multi-shot explanations which is currently not adequately fulfilled by any other evaluation metric(s). Throughout this paper, we have described the development and validation of the scale following psychometric theory. We make this scale available as a public resource for evaluating the quality of XAI experiences. In future work, we plan to investigate the generalisability of the XEQ scale on additional domains, AI systems and stakeholder groups. Beyond this, we propose to establish a benchmark using the XEQ scale. Our goal is to facilitate the user-centred evaluation of XAI and support the emerging development of best practices in the explainability of autonomous decision-making."}, {"title": "Ethical Statement", "content": "Both content validity study and pilot study protocols passed the ethics review of the leading institution (references removed for review). Informed consent was obtained from all XAI experts and pilot study participants."}, {"title": "7.1 Initial Items Bank", "content": null}, {"title": "7.2 Content Validity Study", "content": "This study aimed to establish the content validity of the XEQ scale with XAI experts. Being XAI Experiences are a novel concept, we included three example XAI experiences that capture a variety of stakeholder types and application domains. In addition to the CourseAssist chatbot example included in the paper, they were presented with the following experiences in video format.\n\u2022 The AssistHub AI platform is a website for processing welfare applications and is used by a local council to accelerate the application process. A regulation officer is exploring the website and its XAI features to understand the fairness and bias of the AI system being used in the decision-making process. A non-interactive preview of the experience is presented"}, {"title": "7.3 Pilot Study", "content": "A pilot study was conducted with 203 participants over two application domains where they evaluated either a positive or negative XAI experience. In addition to the CourseAssist chatbot examples provided in the paper, we included two XAI experiences of welfare applicants interacting with the AssistHub AI platform (see Figures 6 and 7). Notes refer to how different aspects of the explanations can lead to a positive or negative XAI experience. Similar to the previous study, all XAI experiences were available to participants in video format. Finally Figure 8 presents a preview of the Pilot study where pages 1 and 2 were customised based on the application participants were assigned to."}]}