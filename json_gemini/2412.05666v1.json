{"title": "Early Diagnosis of Alzheimer's Diseases and Dementia from MRI\nImages Using an Ensemble Deep Learning", "authors": ["Mozhgan Naderi", "Maryam Rastgarpour", "Amir Reza Takhsha"], "abstract": "Alzheimer's Disease (AD) is a progressive neurological disorder that can result in significant cognitive impairment\nand dementia. Accurate and timely diagnosis is essential for effective treatment and management of this disease. In\nthis study, we proposed two low-parameter Convolutional Neural Networks (CNNs), IR-BRAINNET and Modified-\nDEMNET, designed to detect the early stages of AD accurately. We also introduced an ensemble model that averages\ntheir outputs to reduce variance across the CNNs and enhance AD detection. Both CNNs are trained, and all models\nare evaluated using a Magnetic Resonance Imaging (MRI) dataset from the Kaggle database. The dataset includes\nimages of four stages of dementia, with an uneven class distribution. To mitigate challenges stemming from the\ninherent imbalance in the dataset, we employed the Synthetic Minority Over-sampling Technique (SMOTE) to\ngenerate additional instances for minority classes. In the NO-SMOTE scenario, despite the imbalanced distribution,\nthe ensemble model achieved 98.28% accuracy, outperforming IR-BRAINNET (97.26%) and Modified-DEMNET\n(95.54%), with Wilcoxon p-values of 2.9e-3 and 5.20e-06, respectively, indicating significant improvement in correct\npredictions through the use of the average function. In the SMOTE scenario, the ensemble model achieved 99.92%\naccuracy (1.64% improvement over NO-SMOTE), IR-BRAINNET reached 99.80% (2.54% improvement), and\nModified-DEMNET attained 99.72% (4.18% improvement). Based on the experimental findings, averaging the\nmodels' outputs enhanced AD diagnosis in both scenarios, while the diversity in the dataset introduced by SMOTE-\ngenerated instances significantly improved performance. Furthermore, the compact models we proposed outperformed\nthose from previous studies, even in the presence of an imbalanced distribution.", "sections": [{"title": "1 Introduction", "content": "Alzheimer's Disease (AD) the most prevalent type of dementia, is distinguished by a worsening of behavioral\nsymptoms, a decline in short-term memory, and a gradual deterioration in cognitive function [1]. Dementia\ncan arise from various conditions and injuries that affect the brain. Among these, Alzheimer's disease is the\nmost common form, accounting for approximately 60-70% of cases. [2]. Globally, the rising prevalence of\nAD and its associated challenges have garnered significant attention due to its increasing impact on society.\nAs of 2023, the global count of individuals affected by dementia has surpassed 50 million [3], a substantial\nincrease from 20.3 million in 1990[4]. In 2050, it is estimated that there will be 13.8 million individuals\nsuffering from AD dementia, with 7.0 million of them aged 85 years or older [5].\nAdvanced imaging methods, including Magnetic Resonance Imaging (MRI) as well as Positron Emission\nTomography (PET), scans with tracers such as Fluoro-Feoxy-D-Glucose (FDG) and Pittsburgh Compound B (PiB),\nreveal distinctive brain changes in patients with AD, not only in advanced stages but also in early and even pre-\nsymptomatic phases, which aid in the diagnosis of AD's underlying pathological processes [8]. MRI techniques\nuncover specific patterns of brain damage that distinguish AD from other neurological conditions. Additionally,\nthey identify brain abnormalities associated with the transition from MCI to AD and other behavioral outcomes [9].\nDetecting AD in its early stages is critical for developing effective treatments and interventions, as the disease\nshows greater responsiveness to treatment when identified early on[10]. Extensively extracting features from MRI\nimages or medical records to diagnose brain soft tissues for early dementia and AD prediction demands significant\ntime and effort, with the potential for errors escalating due to the similarity between soft and healthy tissues in MRI\nscans [11]. Considering this complexity, the Deep Learning framework, stemming from machine learning, has been\ninvestigated as a feasible solution. This is because of the innate capacity of Deep Learning models to efficiently\nprocess complex input data without relying on time-consuming and poorly scalable feature extraction procedures\n[12].\nDeep learning has recently become the leading approach in medical imaging, particularly in the detection of\nAlzheimer's disease [13]. Recent advancements in Deep Learning have enabled the identification of distinct patterns\nin the progression of AD [14]. Deep neural networks excel at identifying subtle and complex changes in brain\nstructure from data, enabling the monitoring of AD progression and contributing to reliable diagnostic\noutcomes [15]. The application of Deep learning improves efficiency and speed in the detection process,\nwhich are crucial for the early diagnosis of patients and timely medical treatment [16].\nConvolutional Neural Networks (CNNs), a subset of deep learning models, excel at extracting features\nefficiently, making them indispensable in domains like medical imaging. Designed for image analysis, CNNS\nstack layers such as convolutional, pooling, activation, and fully connected layers to capture complex\nfeatures while minimizing parameters compared to traditional neural networks [17]. They leverage techniques\nlike local receptive fields, shared weights, filters, strides, and padding to extract features, reduce\ndimensionality, introduce non-linearity, and predict label probabilities [17]. By processing 2D or 3D images,\nCNNs automatically learn meaningful local and global features, avoiding errors common in manually crafted\nfeatures [18].\nIn this study, we leveraged deep learning to accurately detect AD stages by introducing two CNN-based\nmodels: IR-BRAINNET and Modified-DEMNET. These models utilize convolutional operations on MRI\nimages for automatic feature extraction to classify AD stages.\nThe parameters of a CNN model significantly impact its performance [19]. While models with more\nparameters may achieve better results, they also increase computational complexity and memory\nrequirements, posing challenges for practical implementation [20]. Since many hospitals lack robust\ncomputational resources [21], reducing computational demands is vital for effective medical image analysis\nin resource-constrained settings. Compact networks ensure efficient processing with limited resources and\nintegrate seamlessly into portable edge devices [22], offering flexibility, reduced data exchange, and lower\nmemory usage. For instance, compact CNNs can be deployed on Android devices to detect AD stages,\ndemonstrating their practical real-world applications.\nIn our approach, we designed two CNNs with a low number of parameters to ensure effective detection\nof AD stages. To enhance the performance of IR-BRAINNET, we utilized transfer learning, leveraging pre-\ntrained knowledge from another domain. This technique, which employs both frozen weights (unchanged\nduring training) and fine-tuned weights (adjusted for specific tasks), outperforms randomly initialized filters,\neven when sourced from unrelated tasks, thereby improving overall performance [25]. Specifically, we\ntransferred convolutional layer weights from the pre-trained VGG-19 model, trained on the ImageNet dataset\n[26], to a convolutional layer in IR-BRAINNET.\nTo further enhance AD stage detection, we employed ensemble learning techniques to leverage the\nstrengths of both proposed CNN models. Ensemble learning, a widely used approach, combines diverse CNN\narchitectures to achieve better predictive performance than individual models [23]. By integrating multiple\nmodels, ensemble learning improves the robustness and overall accuracy of learning systems [24]. In deep\nlearning, where architectures often exhibit high variance and low bias, simple averaging of predictions across\nensemble models effectively reduces variance, improving generalization performance [24]. Accordingly, we\ncombined predictions from both CNN models using an averaging function, forming a robust ensemble model.\nWe used the Kaggle Alzheimer's dataset [27] to train and evaluate the two CNN models and to assess the\nperformance of our proposed ensemble model. This dataset categorizes samples into four classes based on\nAD severity: Moderate Demented (MOD), Mild Demented (MID), Very Mild Demented (VMD), and Non-\nDemented (ND). However, a significant challenge with this dataset is its pronounced class imbalance, which\ncan cause models to over-predict the majority class, leading to frequent misclassification of minority classes\n[28]. Addressing this imbalance is essential for ensuring accurate and fair model predictions.\nTo tackle issues arising from the imbalanced dataset, which impacts the performance of the models, we\nimplemented the Synthetic Minority Over-sampling Technique (SMOTE). SMOTE, as a highly effective"}, {"title": "2 Related Works", "content": "AD, a neurodegenerative disorder impacting millions globally, highlights the critical need for early detection and\nprognosis to enable effective disease management. Recently, Deep Learning methods have gained prominence for\nearly AD identification, utilizing various neuroimaging modalities such as MRI scans. In this section, we present\nan overview of studies from the literature and efforts in this field, as we propose models for detecting stages of\nAlzheimer's disease within the Deep Learning framework.\nMurugan et al. [7] developed DEMNET, a CNN model for classifying categories in the Kaggle\nAlzheimer's dataset. To address data imbalance, they applied SMOTE. DEMNET includes four blocks, each\nwith two convolutional layers, batch normalization, and max pooling, followed by dense layers with 512, 128,\nand 64 neurons. Softmax activation in the final layer produces class probabilities, while dropout layers counter\noverfitting. DEMNET achieved 95.23% accuracy and 96% precision with SMOTE, compared to 85%\naccuracy and 80% precision without it.\nSadiq Fareed et al. [31] introduced ADD-NET, a CNN model for identifying Alzheimer's disease from\nMRI images in the Kaggle Alzheimer's dataset. ADD-NET consists of four convolutional blocks, each with\na convolutional layer, ReLU activation, and average pooling, with filter counts doubling from 16 to 128. After\nthe convolutional layers, ADD-NET has a flatten layer, a dense layer with 256 neurons, a dropout layer, and\na final dense layer with Softmax for probability output. To address data imbalance, they used\nSMOTETOMEK, a technique combining SMOTE and Tomek links, achieving 97.05% accuracy and 97%\nprecision. Without SMOTETOMEK, the model's precision for the MOD class dropped to 0%.\nFathi et al. [32] proposed an ensemble Deep Learning model for the early diagnosis of AD utilizing MRI\nimages from the ADNI dataset. Their methodology involved leveraging six established CNNs: DenseNet-201,\nDenseNet-169, DenseNet-121, ResNet50, Inception-ResNet v2, and VGG-19. Each CNN underwent\nindividual training and testing on the dataset. Following this, they employed a weighted probability method\nto amalgamate the probabilities predicted by each classifier. The weight assigned to each classifier in the final\nensemble model was determined based on its accuracy after the training phase. The proposed ensemble model\nachieved accuracy rates across various classification groups as follows: 98.57% for NC/AD, 96.37% for"}, {"title": "3 Material and Methods", "content": "In this section, we provide a concise overview of our proposed model. We then delve into the Kaggle Alzheimer's\ndataset, discussing its distribution and inherent imbalance. Subsequently, we elucidate our preprocessing steps,\noversampling techniques, and the data splitting process. Following that, we explore the architectures and\nparameters of our two proposed CNN models: IR-BRAINNET and Modified-DEMNET, with the latter being a\nmodified variant of the DEMNET model [7]. Finally, we elaborate on our proposed ensemble model, which\ncombines the final Softmax outputs of the two CNN models, and provide insights into its functionality through\nthe presentation of pseudocode for the proposed ensemble model."}, {"title": "3.1 Method Overview", "content": "Deep Learning has made significant strides in recent years, with numerous applications in various fields, such\nas healthcare, energy management, and image analysis. One such example is the utilization of CNNs for\naccurately identifying AD stages. As outlined in the related work section, CNNs have demonstrated great\npotential in automatically extracting complex features from MRI images of patients and effectively utilizing\nthem for classifying AD stages. Within the realm of Deep Learning framework, we introduced two CNN\nmodels: IR-BRAINNET, a novel CNN model developed by us, and Modified-DEMNET, an adapted version\nof the DEMNET [7] model with reduced parameters, specifically tailored for identifying AD from MRI\nimages. To augment the detection efficacy in our task, we harnessed the capabilities of two CNNs by\ndesignating them as individual models within a unified set. This unified set serves as the basis of the proposed\nensemble model. The core ensembling operator of the proposed ensemble model utilizes an average function"}, {"title": "3.2 Imaging dataset", "content": "The dataset utilized in this study was obtained from the Kaggle platform [23], which includes four classes: MID,\nMOD, ND, and VMD. The images are formatted in three-channel color (RGB), with dimensions of 208 \u00d7 176\npixels, and saved in jpeg format. The dataset is organized into two folders, namely \"train\" and \"test\". Within the\ntrain and test folders, four directories exist, with each directory named corresponding to a class, and images\nbelonging to each class are stored within their respective directories. A visual representation of images, each\nbelonging to one of four classes from the Kaggle Alzheimer's dataset, is presented in Fig. 2, in Table 1, which\nillustrates the class distribution both before and after applying SMOTE. Without SMOTE, the dataset shows\nsignificant imbalance: 896 images for the MID class, 64 for the MOD class, 3200 for the ND class, and 2240 for\nthe VMD class. This imbalance can hinder model performance, particularly for minority classes. After applying\nSMOTE, all classes were balanced with 3200 images each, addressing the disparity and enabling more effective\ntraining of the models."}, {"title": "3.3 Dataset preprocessing", "content": "According to Table 1, the dataset displays a notable class imbalance, which impacts the efficacy of our proposed\nmodels, notably in precisely classifying minority classes, such as MOD, comprising only 64 images, as a result\nof the disproportionately higher representation of the majority class, ND, containing 3200 images. To address\nthis issue, we used SMOTE approach to oversample the minority classes and balance the dataset. To generate\nnew instances using SMOTE technique, we first randomly select a sample from the minority class, labeled as $x_i$.\nThen, we calculate its K-Nearest Neighbors and choose one of these nearest neighbors, represented by $x_{ij}$. After\ncalculating the distance between $x_i$ and $x_{ij}$, a point is then selected on the line segment connecting these two\npoints to generate a synthetic instance denoted as $x_{new}$. The. Eqs for creating synthetic instances using SMOTE\nare as follows:\n$\\Delta = x_{ij} - x_i$ (1)\n$x_{new} = x_i + rand[0 - 1] \\times \\Delta$ (2)\nIn.Eq 2, $rand[0 - 1]$ is a random number generated between 0 and 1, determining the extent of\ninterpolation between $x_i$ and $x_{ij}$ when creating the synthetic example $X_{new}$. Looking at. Eqs 1 and 2,\nincorporating interpolation between existing minority class samples and using random values from rand[0-1]\ngenerate new samples dispersed among the original minority class points. Consequently, SMOTE is a highly\neffective augmentation method that introduces variations into the dataset and helps reduce overfitting.\nSMOTE function was provided with a vector containing all image data and another vector of labels\nencoded in one-hot encoding format. It was applied to the dataset with a random seed set of 42 for\nreproducibility, utilizing a strategy that specifically generates instances for the minority classes. After oversampling, the\ntotal number of images increased to 12,800. Consequently, each class now comprises 3,200 images, which\naligns with the number of ND images representing the majority class."}, {"title": "3.4 The First Proposed CNN Model", "content": "The first proposed CNN in this research, IR-BRAINNET, is designed in the domain of Deep Learning for the\nautomatic early diagnosis of AD using MRI images. The primary objective of this CNN model is to achieve\nhigh performance in detecting the early stages of AD while maintaining a simple architecture and keeping the\nparameter count even lower than that of DEMNET [7] to reduce computational expenses.\nThe structure of IR-BRAINNET consists of 6 convolutional layers, each utilizing 3\u00d73 filters and ReLU\nactivation function, along with 6 max-pooling layers, all with a 2\u00d72 dimension. In detail, the convolutional\nlayers slide 3\u00d73 filters across the input arrays and apply ReLU activation function to generate feature maps.\nTo reduce the number of parameters and computational costs in subsequent layers, IR-BRAINNET utilizes a\ndownsampling method. This process involves reducing the feature maps by a factor of 2 along both width and\nlength using max pooling layers. Convolutional and max pooling layers collaboratively extract complex\nfeatures from the input images, with deeper layers capturing increasingly complex features, while initial layers\nfocus on simpler ones. This process eliminates the need for manual feature engineering and facilitates the\nautomatic identification of AD from MRI scans.\nIn IR-BRAINNET, following the last max pooling layer, the output obtained from this layer is flattened.\nThis means that the 256 features with dimensions of 2 \u00d7 2 that emerge from the last max pooling layer are\nconverted into a one-dimensional array with a size of 1024. They are then passed through a dense layer\ncomprising 100 neurons with ReLU activation, which produces activation values. Subsequently, these\nactivation values are fed into another dense layer with 4 neurons, where the output is transformed using the\nSoftmax activation function from raw scores into a probability distribution. This probability distribution not\nonly facilitates training by adjusting network parameters to minimize differences between predicted and actual\nclass labels but also serves as a basis for evaluating the model. This evaluation occurs both at the end of each\ntraining round in the validation phase and during the testing phase. The formulations for the ReLU and\nSoftmax functions are represented by. Eq 3 and.Eq 4, respectively:\n$ReLU(X) = Max(0, X)$ (3)\n$Softmax = \\frac{e^{S_N}}{\\sum_j e^j}$ (4)\nIn.Eq 3 for any input value X, if X is greater than 0, the output is simply X. However, if X is less than or\nequal to 0, the output becomes 0. ReLU is considered a non-linear function due to its output's non-linear\nrelationship with its input. Specifically, when the input X is positive, the output maintains a linear relationship\nwith the input, as it equals the input value. Conversely, when X is non-positive, the output becomes 0,\nbreaking this linearity. This property allows ReLU to introduce non-linearity into neural networks, aiding in\nlearning complex patterns within the data.\nIn.Eq 4, $S_N$ denotes the unprocessed score or logit for the Nth class, while $e^{S_N}$ represents the exponential\nof this unprocessed score corresponding to the Nth class. The term $\\sum_j e^j$ calculates the sum of exponentials\nof unprocessed scores for all classes (j) in the output layer, where c signifies the total number of classes.\nThe total number of parameters in IR-BRAINNET, which includes two dense layers in its fully connected\nlayer alongside the six convolutional layers, amounts to 1,801,464. To leverage insights from the pre-trained\nVGG-19 model, which was trained on the ImageNet dataset [26], we initialized the weights of the second\nconvolutional layer in our IR-BRAINNET by transferring the weights from the third convolutional layer of\nVGG-19, containing 73,856 parameters, to the second layer of the IR-BRAINNET model with the same\n73,856 parameters. We maintained all 1,801,464 parameters of IR-BRAINNET as trainable. This allowed us\nto fine-tune the parameters of the second layer of IR-BRAINNET, which utilized pre-trained weights as its\nweight initializers.\nTransfer learning can address challenges stemming from insufficient labeled training data and can be employed\nas a strategy to mitigate overfitting [45]. It is possible to enhance performance by transferring pre-trained\nknowledge, even though ImageNet [26] contains different classes from those used in AD detection. Networks' early\nlayers capture basic features like edges, while deeper layers build on these to develop more intricate, task-specific\nrepresentations. Since these fundamental features are typically consistent across different image categories,\nutilizing this knowledge can improve performance and generalization in AD detection.\nIn comparison to DEMNET [7], which aims for a similar low CNN parameter countIn comparison to\nDEMNET[7], which aims for a similar low CNN parameter count, IR-BRAINNET exhibits a significantly"}, {"title": "3.5 The Second Proposed CNN Model", "content": "In line with our research objectives, we developed a second model, Modified-DEMNET, which leverages the\nconvolutional block structure of the original DEMNET [7] model. We modified the third layer of the\nDEMNET model and the last dimension reducer in the final block of the DEMNET network by replacing the\nmax pooling 2D with the average pooling 2D. The key distinction between max pooling 2D and average\npooling 2D with a 2\u00d72 window is in how they handle values within the specified region. In max pooling 2D,\nthe highest value is selected from the four numbers in the 2\u00d72 window, while in average pooling 2D, the\naverage value of these four numbers is chosen. In medical image analysis, lesions or abnormalities often show\nsignificant variability in their spatial distribution across images [46]. For instance, a lesion might appear in\nonly a small part of the image, where max pooling is particularly effective. On the other hand, if the lesion is\nspread across a larger portion of the image, average pooling can be more beneficial. By incorporating both\nmax pooling and average pooling in Modified-DEMNET, the model leverages each technique's strengths to\neffectively capture localized and global features. This approach enhances the model's ability to generalize\nacross diverse image data, reducing the likelihood of learning patterns that are specific to the training set and\nmitigating the risk of overfitting.\nMoreover, we simplified the fully connected layer of DEMNET into two layers: a parameter-free flattened\nlayer and a Dense layer with 100 neurons, using ReLU activation function to extract the 100 activation values.\nSimilar to IR-BRAINNET, and considering the four classes in the Kaggle Alzheimer's dataset, a Dense layer\nwith four neurons that uses the Softmax activation function was employed as the prediction layer. In Modified-\nDEMNET, we kept all the batch normalization layers intact, as they help prevent overfitting and address issues\nlike vanishing and exploding gradients. By stabilizing the input distributions to each layer-distributions that\nmight otherwise fluctuate during training-batch normalization ensures more uniform activations across the\nnetwork. This consistency helps address the issues of vanishing and exploding gradients by keeping the\nactivation ranges stable. Moreover, batch normalization introduces a level of noise by basing the normalization\nof inputs on the mean and variance from a mini-batch instead of the entire dataset. This randomness, similar\nto the effect of dropout, reduces overfitting by preventing the model from relying too heavily on specific\npatterns in the training data. Through the adaptation of the DEMNET architecture and implementing key\nmodifications tailored to our objectives, we aimed to attain promising results in AD detection while reducing\nthe total and trainable parameters of the DEMNET model."}, {"title": "3.6 Weight Initialization Strategy for IR-BRAINNET and Modified-Dement", "content": "In neural networks, weights are essential because they significantly affect the network's performance;\ntherefore, considerable effort must be invested in determining their initial values and configurations [47]. The\nchoice of initial weights in neural networks is crucial as it can help prevent issues such as gradient explosion\nor vanishing gradients. [48] In this paper, we used the Kaiming He weight initialization method to properly\ninitialize the weights of all trainable layers in both CNNs, except for the second layer of IR-BRAINNET.\nAccording to [48], the formula for the Kaiming He initializer is as follows:\n$W\\sim N\\left(0,\\frac{2}{N_{in}}\\right)$ (5)\nHere, N represents the normal distribution, $n_{in}$ denotes the number of input units, and W is the weight\nmatrix of a layer. According to.Eq 5, The Kaiming He initialization method sets the weights of a layer by\ndrawing them from a normal distribution with a mean of 0 and a variance of $\\frac{2}{N_{in}}$. As a result, this method\nensures that the variance of activations stays uniform throughout the network layers. By appropriately scaling\nthe weight variances, this initialization method effectively guards against gradients becoming excessively\nsmall (vanishing) or excessively large (exploding).\nWe incorporated ReLU activation in both CNNs to introduce non-linearity into the models. The main\nreason for choosing Kaiming He initialization in this study is that unlike Xavier initialization (also known as\nGlorot uniform), which assumes linear activations and may not perform well with ReLU, Kaiming He\ninitialization is specifically designed to address the non-linearity of ReLU functions [49]. According to [49],\nKaiming He initialization enables the training of very deep rectified models from scratch and allows for"}, {"title": "3.7 The Proposed Ensemble Model", "content": "To further enhance the identification of AD stages from MRI images, we combined predictions from IR-\nBRAINNET and Modified-DEMNET to form the ensemble model's prediction. As previously mentioned, our\nensembling approach involves taking the outputs of CNNs, obtained using Softmax activation function, and\nfeeding them into the average layer. The. Eq for the average function, which combines the outputs of the\nindividual CNNs, is as follows:\n$Average\\ output = \\frac{1}{n} \\sum_{i=1}^{n} OutputCNN_i$ (6\nIn this.Eq, $OutputCNN_i$ refers to the output of the ith CNN. The sum is then taken over all n CNNs (in this\nstudy, n is two), and the result is divided by the number of n. Given the distinct architectural characteristics\nof IR-BRAINNET and Modified-DEMNET, making use of the diverse perspectives offered by each model\nand consolidating their outputs into a single prediction through averaging fosters a complementary\nrelationship between the models, which can enhance AD detection capabilities. This integration capitalizes\non the strengths of both models and can effectively produce a more robust and accurate prediction framework\nfor AD detection. Additionally, our proposed ensemble model effectively reduces noise variance, leading to\nmore stable and reliable predictions with fewer fluctuations. As a result of this variance reduction, the model\ngeneralizes better to new, unseen data and is less prone to overfitting."}, {"title": "4. Experimental Results", "content": "In the Evaluation Results, we analyzed the performance of IR-BRAINNET, Modified-DEMNET, and our\nproposed ensemble model in detecting the early stages of AD. This section outlines the Performance Setup,\nPerformance Metrics. Eqs, and training phase configurations, and presents the outcomes based on the\nlikelihood vectors of models generated during the testing phase."}, {"title": "4.1 Performance Setup", "content": "The study was carried out using the Python programming language within the Google Colab environment\n[50]. For designing and training our deep learning models, we harnessed the Tensorflow framework alongside\nits Keras package. The computational resources afforded by the complimentary cloud service in Google Colab\nencompassed an Nvidia Tesla T4 GPU boasting 15.6 GB memory, 12.6 GB RAM, an Intel Xeon CPU\noperating at 2.20 GHz, and 107.7 GB HDD"}, {"title": "4.2 Model Design and Training", "content": "After the preprocessing step, we proceeded to train the proposed CNNs by inputting the preprocessed image\narrays into them. Both models underwent 50 epochs of training, during which their parameters were iteratively\nadjusted using the adaptive moment estimation (Adam) optimizer. The Adam optimizer utilizes the models'\nloss to update their parameters based on the gradients of the loss function. For the multi-class classification\ntask, we employed the Categorical Cross-Entropy loss function to measure the dissimilarity between the true\ndistribution of the data and the predicted distribution. We initiated training with an initial learning rate of\n0.0001 for both CNNs and, as a strategy for ensuring stable convergence and reducing the risk of overfitting,\ncontinuously monitored their loss values throughout the optimization process. If there was no discernible\ndecrease in loss after 3 epochs, we automatically proceeded to reduce the learning rate by multiplying it by\n0.1. We specified the exponential decay rate for the first moment estimate as 0.9 and the exponential decay\nrate for the second moment estimate as 0.999. Additionally, to prevent division by zero and ensure stability\nduring training, we set the small constant epsilon to le-07. After training both models, we designed our\nproposed ensemble model by merging the last prediction layers of these models. The merging process involves\nutilizing the average layer, resulting in our ensemble model incorporating the trained parameters of both\nCNNS."}, {"title": "4.3 Evaluation Metrics", "content": "In our model evaluation process, we relied on metrics such as accuracy, precision, recall, and F1-score. To\nprovide clarity on these metrics, we must first define True Positives (TP), False Positives (FP), True Negatives\n(TN), and False Negatives (FN). For clarification, let's consider the prediction vector of a specific model, like\nIR-BRAINNET, where, for each image, a class exists that IR-BRAINNET predicted the image belongs to.\nWhen evaluating the model for the MOD class, TP represents instances correctly identified as MOD, FP\ninvolves cases incorrectly labeled as MOD, TN indicates instances correctly recognized as not belonging to"}, {"title": "4.4 Evaluation", "content": "In this section, we delve into the experimental results of IR-BRAINNET, Modified-DEMNET, and our\nproposed ensemble model for the early stages of AD classification. Upon analyzing the test prediction vectors\nalongside the test labels encoded in one-hot format, and based on the TP, FP, TN, and FN, we calculated the\ntest accuracy, precision, recall, and F1-Score for each model in both the NO-SMOTE and SMOTE scenarios.\nThe performance metrics of the models under both NO-SMOTE and SMOTE scenarios are presented in Table\n2.\nAccording to Table 2, in the absence of SMOTE and synthetic instances, the proposed ensemble model\ndisplayed superior performance compared to its individual CNNs. It achieved the highest test accuracy,\nprecision, recall, and F1-Score at 98.28%, 98.80%, 96.28%, and 97.49% respectively. In contrast, IR-\nBRAINNET achieved lower results than the ensemble model, with an accuracy of 97.27%, precision of\n97.86%, recall of 95.44%, and F1-Score of 96.60%. Furthermore, Modified-DEMNET exhibited metrics that\nwere inferior to both IR-BRAINNET and the ensemble model, with an accuracy of 95.55%, precision of\n96.95%, recall of 96.23%, and F1-Score of 96.57%.\nTransitioning to the SMOTE scenario, notable advancements were observed across all models. IR-\nBRAINNET achieved significantly higher metrics, with test accuracy at 99.80%, precision at 99.80%, recall\nat 99.80%, and F1-Score at 99.80%. Modified-DEMNET also demonstrated improvements, reaching accuracy\nmetrics at 99.73%, precision at 99.72%, recall at 99.72%, and F1-Score at 99.72%. The ensemble model\nperformed exceptionally well in the SMOTE scenario, achieving the highest metrics: test accuracy at 99.92%,\nprecision at 99.92%, recall at 99.92%, and F1-Score at 99.92%. With these results, it surpasses its performance\nin the NO-SMOTE scenario.\nIn both scenarios, the ensemble model consistently showcased superior efficacy over its individual CNN\ncomponents. This demonstrates its effectiveness in bolstering overall detection performance by consolidating\na unified probability distribution vector through the averaging of CNN outputs. Additionally, the utilization\nof SMOTE further augmented accuracy and predictive capabilities across all three models by effectively\nbalancing the dataset through the generation of synthetic instances. It is also noteworthy that IR-BRAINNET\ndemonstrates superior performance based on accuracy, precision, recall, and F1-Score compared to Modified-\nDEMNET, positioning it as the second-best performing model in both scenarios, despite having a lower\nnumber of parameters compared to Modified-DEMNET."}, {"title": "5. Comparison with Other Models", "content": "We have also conducted a comparison of our proposed models with other previous models from the literature. Detailed\nresults of this comparison are available in Table 5. Table 5 clearly illustrates that IR-BRAINNET, Modified-\nDEMNET, and our proposed ensemble model demonstrate superior performance in terms of accuracy, precision,\nrecall, and F1-score on the Kaggle Alzheimer's dataset in both SMOTE and NO-SMOTE scenarios compared to\nprevious models by other authors who used this dataset."}, {"title": "6. Conclusion and Future Scopes", "content": "In this study, we proposed three models based on convolutional layers for the early detection of AD: IR-\nBRAINNET, Modified-DEMNET, and an ensemble model. The ensemble model combines the outputs of IR-"}, {"title": null, "content": "BRAINNET and Modified-DEMNET using the average function during the aggregation process. We utilized the\nKaggle Alzheimer's dataset for both training and evaluation phases. This dataset shows a notable imbalance, and to\naddress potential issues stemming from this disparity, we utilized SMOTE to generate synthetic instances. Both\nCNNs underwent 50 epochs of training, and in the evaluation phase, all three proposed models showcased\nremarkable performance across key metrics, including accuracy, recall, precision, and F1-score, even when dealing\nwith the imbalanced dataset. The ensemble model consistently outperformed its constituent CNNs in both scenarios.\nNotably, it achieved 100% precision for the minority class MOD in the SMOTE scenario and maintained nearly\n100% precision for this class, with just one false positive, in the NO-SMOTE scenario. Moreover, in the SMOTE\nscenario, the ensemble model displayed remarkable classification performance"}]}