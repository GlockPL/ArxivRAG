{"title": "ValuesRAG: Enhancing Cultural Alignment Through Retrieval-Augmented Contextual Learning", "authors": ["Wonduk Seo", "Zonghao Yuan", "Yi Bu"], "abstract": "Cultural values alignment in Large Language Models (LLMs) is a critical challenge due to their tendency to embed Western-centric biases from training data, leading to misrepresentations and fairness issues in cross-cultural contexts. Recent approaches, such as role-assignment and few-shot learning, often struggle with reliable cultural alignment as they heavily rely on pre-trained knowledge, lack scalability, and fail to capture nuanced cultural values effectively. To address these issues, we propose ValuesRAG, a novel and effective framework that applies Retrieval-Augmented Generation (RAG) with in-context learning to integrate cultural and demographic knowledge dynamically during text generation. Leveraging the World Values Survey (WVS) dataset, ValuesRAG first generates summaries of values for each individual. Subsequently, we curated several representative regional datasets to serve as test datasets and retrieve relevant summaries of values based on demographic features, followed by a reranking step to select the top-k relevant summaries. ValuesRAG consistently outperforms baseline methods, both in the main experiment and in the ablation study where only the values summary was provided, highlighting ValuesRAG's potential to foster culturally aligned AI systems and enhance the inclusivity of AI-driven applications.", "sections": [{"title": "Introduction", "content": "The rapid advancement of Large Language Models (LLMs) has revealed pressing challenges in cultural values alignment [Singh et al., 2024; Kharchenko et al., 2024; Hu et al., 2024]. Predominantly trained on Western data sources [Achiam et al., 2023; Touvron et al., 2023; Jiang et al., 2023], LLMs inherently reflect Western cultural norms and social biases, raising concerns about their applicability in global contexts. These biases present significant challenges when deploying LLMs in cross-cultural environments, often resulting in misrepresentations and stereotypical outputs [Gallegos et al., 2024; Xie et al., 2024; Potter et al., 2024; Huang et al., 2024]. Despite ongoing efforts to address these issues, existing strategies often fall short. While some countries have developed localized LLMs, such as China's ERNIE [Sun et al., 2021], South Korea's HyperCLOVA [Yoo et al., 2024], and the multilingual ChatGLM [GLM et al., 2024], these models also exhibit biases inherited from their respective training datasets. As a result, cultural and social biases embedded in LLMs remain a critical concern, compelling researchers to explore more robust frameworks for cultural alignment [Gallegos et al., 2024; Xie et al., 2024; Potter et al., 2024].\nRecent studies have proposed several approaches, such as role-assignment approaches and few-shot learning techniques [Li et al., 2024a; AlKhamissi et al., 2024], to mitigate these cultural biases. However, these methods still face several challenges: (1) Role-assignment approaches, relying solely on the model's pre-trained knowledge, provide pre-defined demographic information but fail to incorporate explicit values alignment text, which subsequently introduces stereotypes and biases rooted in Western-centric training data; (2) While offering example-based guidance, few-shot learning methods struggle to comprehensively capture the complex cultural values due to the limited correlation between different values dimensions, thus remain ineffective on values-related tasks that differ significantly from the examples; (3) In addition, these methods can only align with the values of a single individual, and singular values cannot represent the universal values of individuals with similar characteristics.\nTo address these challenges, we propose ValuesRAG, a novel framework that utilizes Retrieval-Augmented Generation (RAG) and in-context learning to dynamically incorporate cultural knowledge during text generation (see Figure 1). Our framework leverages the World Values Survey (WVS) dataset [Haerpfer et al., 2022], a globally recognized and comprehensive dataset that explores values across countries using rigorous social science methodologies. Specifically, we first generate summaries for each topic, followed by generating individuals' summaries of values and demographic profiles in parallel. After constructing the knowledge base, we retrieve the top 100 relevant summaries based on demographic features, followed by a reranking step to ensure the most relevant top-k summaries are selected. Finally, we utilize a reasoning LLM that filters the most relevant demographic profiles and applies step-by-step reasoning grounded in the retrieved values to generate the final answer to the question.\nWe evaluate the performance of ValuesRAG by comparing it against several baseline approaches, including: (1) zero-shot inference, (2) role-assignment-only method [Tao et al., 2024], (3) few-shot learning [Choenni and Shutova, 2024], and (4) a hybrid method combining (1) and (2). To ensure a comprehensive evaluation, we curated diverse regional survey QA datasets which are designed to capture values-related question-answer pairs. Extensive experimental results show significant improvements in cultural and contextual understanding, demonstrating that ValuesRAG outperforms the baselines, also in the ablation study where only summaries of values were provided without any additional information. Unlike previous methods that heavily depend on pre-trained knowledge or limited demonstrations, ValuesRAG dynamically retrieves and integrates multiple similar individual summaries based on demographic features, enabling richer value representations and more context-aware responses compared to approaches relying on a single predefined prompt or role.\nThese findings highlight ValuesRAG's potential to foster inclusive AI systems, enhancing the reliability and fairness of AI-driven applications. Our study demonstrates ValuesRAG's robust capabilities on a global scale, suggesting its applicability in aligning the values of diverse groups within a single country. ValuesRAG provides a cost-efficient tool for public policymakers and scientists from various disciplines to refine social simulations, enabling more precise predictions of policy outcomes [Li et al., 2024b]. This, in turn, facilitates the creation of fairer and more effective policies. Moreover, NGOs can leverage ValuesRAG to develop LLMs that reflect specific value orientations while maintaining strong alignment with users' values, thereby increasing their persuasive impact. This approach benefits the promotion and spread of values that contribute to the planet's sustainable development and the long-term well-being of human society."}, {"title": "Related Work", "content": "Pre-trained models are facing growing criticism for their inherent social biases, with cultural bias emerging as a particularly nuanced and pervasive issue [Tao et al., 2024]. Unlike the more obvious safety concerns and social discrimination [Liu et al., 2024] embedded in language models, cultural bias manifests in subtler ways, often reflecting the dominant cultural perspectives present in training data. Studies have shown that LLMs often exhibit cultural biases aligned with the values of developed countries, resulting in the under-representation of perspectives from less developed regions [Manvi et al., 2024; Durmus et al., 2024]. This imbalance not only perpetuates existing cultural hierarchies but also limits the global applicability of these models [Manvi et al., 2024].\nVarious benchmarks and evaluation methods have been proposed to assess the cultural biases of pre-trained models [Gallegos et al., 2024]. For example, Webster et al. [2021] developed probability-based metrics to evaluate gender bias embedded in pre-trained models, while Caliskan et al. [2017] pioneered the use of word embeddings as quantitative measures of bias. More recently, Karinshak et al. [2024] introduced LLM-GLOBE, a benchmark where LLMs generate both quantitative and open-ended answers to values assessment questions, with subsequent evaluation using the LLM-as-a-Jury Protocol. These evaluation methods collectively highlight the complex nature of cultural bias in LLMs and the need for multifaceted assessment approaches."}, {"title": "Mitigation of LLMs' Cultural Bias", "content": "Methods like RLHF [Shen et al., 2023; Ji et al., 2024] are very commonly used in LLM values alignment, but this type of single values alignment method is not suitable for the mitigation of cultural bias, because the alignment goal of cultural bias is diverse and dynamic [Huang et al., 2024], as there are hundreds of countries and cultures in the earth. Addressing cultural biases has become a critical area of research, with various strategies being proposed to enhance cultural sensitivity in LLMs. For instance, Tao et al. [2024] adopted national and cultural role assignments to adjust the cultural values of LLMs, while Masoud et al. [2024] developed a soft prompt tuning approach to mitigate bias. Also, Choenni and Shutova [2024] employed few-shot in-context learning to align cultural behaviors, demonstrating promising results in specific contexts. However, these approaches face significant limitations in fully capturing the complexity of cultural alignment. Tao et al.'s technique mainly depends on national and cultural roles without explicitly integrating values assignments, causing an overreliance on latent internal representations. Meanwhile, Choenni and Shutova's few-shot learning approach similarly falls short of modeling cultural alignment in all its complexity. We, therefore, use these methods as baselines to benchmark our proposed approach."}, {"title": "Datasets", "content": "In this section, we first introduce the World Values Survey (WVS) as our training dataset (Section 3.1), highlighting its extensive coverage, global representativeness, and relevance for values-related studies. Subsequently, we describe six regional test datasets (Section 3.2), which are carefully selected to ensure geographic, cultural, and demographic diversity."}, {"title": "Train Dataset", "content": "WVS [Haerpfer et al., 2022] is a globally recognized dataset that investigates human beliefs, values, and cultural norms through structured surveys conducted across multiple countries. WVS is selected as our train dataset especially due to its numerous advantages:\n1. Broad Recognition and Inclusiveness: WVS is widely recognized and used by governments, social scientists, and international organizations in values studies. It covers 120 countries, representing 94.5% of the global population, ensuring broad geographic and cultural representation.\n2. Expert-Designed and Accessible: The dataset is designed by leading domain experts to conduct comprehensive surveys of values, ensuring reliability and relevance. It is publicly accessible, enabling reproducibility and transparency in research.\n3. Effective Structure and Large Scale: WVS has well-organized and comprehensive demographic questions, making it effective for retrieval tasks. Its large sample size (97,221 respondents) is also suitable for RAG tasks.\nSince values evolve gradually over time, WVS is conducted in waves, with each wave occurring every five years. For our study, we utilized the most recent wave, spanning from 2017 to 2022.\nThe WVS codebook includes over 600 indicators, with 259 values-related and 31 demographic-related questions. The values questions span 13 topics, such as social trust, post-materialism, and political interest. We randomly selected 20% (52 questions) per topic for validation and used the remaining 80% (207 questions) for summary generation. The 31 demographic features, including country, sex, age, education, social class, and employment status, were used to generate demographic summaries for retrieval tasks."}, {"title": "Test Datasets", "content": "We selected six regional surveys to serve as test datasets based on the following criteria:\n1. Demographic and Values Coverage: The datasets provide demographic features closely aligned with WVS's questions, along with sufficient values-related features to enable meaningful comparisons and analyses.\n2. Temporal Proximity: The datasets exhibit temporal proximity to WVS Wave 7 (2017-2022), allowing aligned comparisons and ensuring consistency across evaluations.\nThe regions in our test datasets were meticulously chosen to encompass a wide range of geographic, cultural, and demographic diversity, ensuring the data accurately reflects the majority of the global population. All of them are publicly accessible, and are statistically representative at national or regional levels, which guarantees their reliability and validity.\nTo be specific, we selected European Values Study [EVS, 2022] as the representative dataset for Europe, as it is the largest values survey in the region. For the United States, we selected the General Social Survey [Davern et al., 2024], which is the most comprehensive social survey in the country. The Chinese General Social Survey [Bian and Li, 2012] serves as the representative dataset for China due to its comprehensive sampling methodology and scientific rigor. For India, where national survey data were largely inaccessible during our study, we used Pew Research Center's survey data [Sahgal and Evans, 2021] to represent the Indian population. The AmericasBarometer [Lab, 2021], conducted by the LAPOP Lab, was selected to represent Latin American countries, as it covers 32 countries across the region. Finally, Afrobarometer [Afrobarometer, 2023] was chosen as the representative dataset for Africa. A detailed summary of these datasets is presented in Table 1."}, {"title": "Methodology", "content": "In this section, we present the ValuesRAG which is specifically designed to address cultural biases and enhance contextual alignment in LLM-driven scenarios through a Retrieval-Augmented Generation (RAG) approach. ValuesRAG consists of three key components: Values and Demographic Summary Generation, which extracts and summarizes cultural values and demographic information from large-scale datasets (Section 4.1); Values-Augmented Generation, which incorporates these summaries into the generative process to align responses with the cultural context (Section 4.2); and Retrieval-based Values Alignment, which dynamically assigns relevant individual values to queries based on demographic profiles (Section 4.3). An overview of the ValuesRAG framework is provided in Figure 2."}, {"title": "Values and Demographic Summary Generation", "content": "To systematically generate concise summaries of values and demographics for each individual, we process the dataset in three stages. First, the dataset is stratified by topics and split into train and validation sets, ensuring that the distribution of each topic is preserved (described in Section 3.1). In parallel, topic-based summaries and demographic summaries are generated separately. For topic-based summaries, values-related QA sets are used to produce summaries for each topic, while demographic summaries are generated using demographic-related QA sets:\n$T_j = f_{gen}(QA_{value,1}^{topic,j}, QA_{value,2}^{topic,j},..., QA_{value,N_j}^{topic,j}),$\n$D_i = f_{gen}(QA_{demo, 1}, QA_{demo, 2}..., QA_{demo, K}).$\nwhere $f_{gen}$ denotes the generative model, $T_j$ is the summary for topic $j$ of individual $i$, based on $N_j$ values-related QA pairs, and $D_i$ represents the demographic summary derived from $K$ demographic-related QA pairs. Finally, individual summaries are constructed by combining all topic summaries:\n$S_i = f_{gen}(T_1, T_2,\u2026\u2026\u2026,T_M),$\nwith $M$ denoting the total number of topics. The result, denoted as $S_i$, forms a comprehensive values summary for individual $i$. These generate summaries serve as structured references for retrieval in later stages and are also used to augment the validation set for evaluation."}, {"title": "Values Augmented Generation", "content": "Once the comprehensive summaries for each individual are generated in the previous step, we construct an augmented generation process for evaluating the validation question-answer data. For each validation question, we concatenate the corresponding individual's values summary with the question itself, forming a context-rich input for the LLM:\n$C_i = concat (S_i, Q_{val,k})$\nwhere $C_i$ represents the combined context, $S_i$ is the values summary for individual $i$, and $Q_{val,k}$ is the k-th validation question. Next, we concatenate $C_i$ with the demographic summary $D_i$ to further enhance the context, enabling the generation of responses based on both values and demographic information:\n$A_i = f_{gen} (C_i, D_i)$\nhere, $A_i$ represents the answer generated by the function $f$, and $(C_i, D_i)$ embeds the augmented context $C_i$ and demographic information $D_i$ into a structured input format. Additionally, we utilize chain-of-thought prompting to enhance reasoning and emulate the behavior of the corresponding individual, ensuring responses that are contextually aligned with the values captured in the summaries and demographic characteristics."}, {"title": "Retrieval-based Values Alignment", "content": "To dynamically assign relevant values to test individuals, we leverage demographic information as documents for retrieval. The demographic data from both the train and test datasets are preprocessed into a structured context format, as described earlier, and embeddings are generated for each demographic context using a representation model. We first retrieve the top-100 most similar summaries of values for each test individual by computing the cosine similarity between the embeddings of the test and train demographics:\n$Sim(E_{test}, E_{train}) = \\frac{E_{test} \\cdot E_{train}}{|| E_{test} || || E_{train} ||}$\nSpecifically, $E_{test}$ and $E_{train}$ represent the embeddings of the test and training demographic contexts, respectively, and $Sim( , )$ denotes the cosine similarity score. The top-100 embeddings with the highest similarity scores are initially selected as candidates. Subsequently, we apply a reranking step to refine the selection and identify the most relevant summaries among the retrieved candidates. The reranking process evaluates the semantic relevance of the initial candidates based on a scoring function:\n$R_k = f_{rerank} (E_{test}, E_{c_j}), C_j \\in {C_1, C_2, ..., C_{100}}, k < 100$\nwhere $R_k$ represents the reranked summary for the k-th candidate selected from the final top-k results, $f_{rerank}$ is the reranking function, and $E_{c_j}$ denotes the embedding of the j-th candidate initially retrieved among the 100 documents. The reranked top-k summaries are then incorporated into the prompts, enriching the contextual alignment of the generated responses. In detail, for each test individual, the retrieved and reranked summaries are combined into the final prompt, and the answer is subsequently generated using the function $f_{gen}$:\n$P_{test} = (D_{test}, R_1, R_2, ..., R'_K, Q_{test}),$\n$A_{test} = f_{gen}(P_{test}).$\n$P_{test}$ is the final prompt, $D_{test}$ is the demographic information of the test individual, ${R'_1, R'_2, ..., R'_K}$ represents the top-k reranked summaries, and $Q_{test}$ is the test question. $A_{test}$ denotes the generated answer for the test question, and $f_{gen}$ represents the generation function that leverages the structured input prompt.\nThis retrieval-based approach, followed by reranking, enhances reasoning by explicitly guiding the LLM to critically evaluate which retrieved values best align with the test individual's demographic characteristics. The final prompts are then used to generate answers following the chain-of-thought prompting strategy, ensuring that the responses are contextually coherent and culturally aligned with the test individual's profile."}, {"title": "Experiments", "content": "Models Used We employ GPT-40-mini [Achiam et al., 2023], a smaller version of GPT-40, for our generation tasks, with the temperature parameter set to 0.7 for balancing coherence and creativity. For retrieval task, we used the E5 (base) model [Wang et al., 2022] to generate embeddings and retrieve the top-100 most relevant summaries of values by calculating cosine similarity. Additionally, we utilized the GTE-multilingual-reranker-base model [Zhang et al., 2024] for reranking. This reranking model refines the selection process and ensures that the top-k most relevant summaries are selected from the initial top-100 retrievals.\nBaseline Methods and Implementation Our baseline methods include: (1) Zero-shot Inference, (2) the role-assignment-only approach [Tao et al., 2024], (3) a few-shot learning method [Choenni and Shutova, 2024], and (4) a hybrid method that combines both (1) and (2). Specifically, for the role-assignment baseline, we use the same demographic summaries as in ValuesRAG to ensure fairness by assigning roles based on demographic information from the survey data. For the few-shot method, we follow the approach outlined in the previous work, where we randomly select five examples from the test set as prompts. The hybrid method combines both strategies, assigning roles based on demographic summaries and augmenting the prompts with five randomly selected few-shot examples from the test set.\nEvaluation Method We used accuracy as the primary evaluation metric, converting multi-choice responses into binary form for consistency and simplicity by dividing responses into two distinct groups based on contrasting answer patterns, which effectively captures agreement or disagreement and aligns with the structure of values-related questions."}, {"title": "Experimental Analysis", "content": "In our experiments, we compare our method ValuesRAG with four baseline methods: zero-shot inference, role-assignment, few-shot learning, and a hybrid approach that combines role-assignment and few-shot learning, as shown in Table 2. We found that the role-assignment method generally surpasses both zero-shot and few-shot approaches. By grounding the agent's responses in a clearly defined demographic context, it ensures more consistent performance. In contrast, few-shot learning, which depends on a small set of examples, often faces challenges in generalizing to unseen scenarios, as different values dimensions are not strongly related in many cases. However, while role-assignment offers clearer cultural context, it may oversimplify complex personal traits by imposing rigid, stereotype-like constraints on agent behavior. The hybrid method seeks to address these limitations by combining role assignment for consistency with few-shot prompts to introduce variety, but still falls short in capturing the full complexity of cultural values.\nIn contrast, ValuesRAG overcomes these challenges by dynamically retrieving and integrating specific demographic and cultural data for each agent. Specifically, ValuesRAG (k=3) achieves the best results, with ValuesRAG (k=5) following closely behind. Although using 1 or 10 retrieved summaries also achieved better performance than other baselines, retrieving 3 and 5 summaries provides a more balanced tradeoff between retrieval diversity and contextual relevance. This retrieval-augmented framework enables the model to dynamically incorporate richer, more nuanced information about each agent, avoiding the limitations of rigid demographic labels or small sample prompts. As a result, our model captures the interplay between individual beliefs, social contexts, and cultural norms more effectively. Evaluations across diverse test datasets demonstrate that ValuesRAG consistently outperforms baseline methods, highlighting its ability to better represent cultural diversity, improve contextual alignment, and enhance overall model performance."}, {"title": "Ablation Study: Impact of Values-Only Generation", "content": "To validate the robustness of ValuesRAG, we perform an ablation study using only value-augmented generation, thereby isolating the impact of demographic summaries on the model's performance. Specifically, we used the WVS validation set-separated from the training data as outlined in Section 3-to evaluate the models. Table 3 presents a comparison of our method, using only summaries of values, against four baseline methods. The results demonstrate that ValuesRAG consistently outperforms the baselines across all datasets, achieving the highest accuracy even relying solely on summaries of values.\nThis result confirms the effectiveness and robustness of the values-augmented generation approach. ValuesRAG leverages structured values summaries to generate contextually rich and culturally aligned responses. Even without demographic augmentation, ValuesRAG achieves superior performance by dynamically capturing the underlying value patterns, demonstrating its ability to generalize across diverse cultural contexts without requiring predefined prompts or demographic anchors. The result showcases the framework's scalability and adaptability, proving it can mitigate biases and generate culturally coherent outputs with minimal reliance on external context."}, {"title": "Conclusion", "content": "We present ValuesRAG, an innovative Retrieval-Augmented Generation framework that revolutionizes cultural values alignment through its comprehensive approach to values context analysis. While existing approaches rely on pre-trained knowledge with fixed demographic labels, often leading to oversimplified generalizations and biases, or few-shot prompting techniques that struggle with generalization due to limited correlations across value dimensions, ValuesRAG overcomes these weaknesses by dynamically retrieving and integrating granular demographic data with detailed individual-level cultural profiles. Our extensive evaluations demonstrate that ValuesRAG achieves an accuracy improvement of up to 21% over state-of-the-art baselines across diverse regional QA datasets. By combining adaptive retrieval mechanisms with in-context learning and reranking strategies, ValuesRAG captures complex cultural nuances, reduces biases, and ensures contextually aligned responses. This structured design enables ValuesRAG to bridge the gap between generic LLM capabilities and the demands of culturally sensitive applications, providing a scalable and robust solution for real-world use cases."}, {"title": "Limitation", "content": "Although our baseline comparisons indicate that ValuesRAG generally delivers superior performance compared to alternative methods, it does not always guarantee an exact match to individual's true values. Since we rely on the WVS dataset to summarize individual profiles, there can be mismatches when these summaries are applied to other test sets. In future work, we plan to explore more adaptive retrieval strategies that can better align with novel datasets, as well as investigate how integrating additional fine-tuning with retrieval-augmented generation may further refine each agent's contextual accuracy."}]}