{"title": "Cycle-Consistent Bridge Diffusion Model for Accelerated MRI Reconstruction", "authors": ["Tao Song", "Yicheng Wu", "Minhao Hu", "Xiangde Luo", "Guoting Luo", "Guotai Wang", "Yi Guo", "Feng Xu", "Shaoting Zhang"], "abstract": "Accelerated MRI reconstruction techniques aim to reduce examination time while maintaining high image fidelity, which is highly desirable in clinical settings for improving patient comfort and hospital efficiency. Existing deep learning methods typically reconstruct images from under-sampled data with traditional reconstruction approaches, but they still struggle to provide high-fidelity results. Diffusion models show great potential to improve fidelity of generated images in recent years. However, their inference process starting with a random Gaussian noise introduces instability into the results and usually requires thousands of sampling steps, resulting in sub-optimal reconstruction quality and low efficiency. To address these challenges, we propose Cycle-Consistent Bridge Diffusion Model (CBDM). CBDM employs two bridge diffusion models to construct a cycle-consistent diffusion process with a consistency loss, enhancing the fine-grained details of reconstructed images and reducing the number of diffusion steps. Moreover, CBDM incorporates a Contourlet Decomposition Embedding Module (CDEM) which captures multi-scale structural texture knowledge in images through frequency domain decomposition pyramids and directional filter banks to improve structural fidelity. Extensive experiments demonstrate the superiority of our model by higher reconstruction quality and fewer training iterations, achieving a new state of the art for accelerated MRI reconstruction in both fastMRI and IXI datasets.\nKeywords: Accelerated MRI reconstructionn, Cycle-Consistent Bridge Diffusion, Contourlet Decomposition Embedding", "sections": [{"title": "1. Introduction", "content": "Magnetic resonance imaging (MRI) is widely used in clinical practice since it can highlight soft tissues with diverse contrasts. However, MRI scanning is slow ((e.g.,) a 1.5T brain examination typically takes 35-45 minutes Saretoretti et al. (2019)), leading to high costs and more motion artifacts Zaitsev et al. (2015). Therefore, accelerated MRI reconstruction attracts great attention and various deep learning-based approaches have been proposed to reduce the scanning time and improve the reconstruction quality Hyun et al. (2018); Jeelani et al. (2018); Fabian et al. (2021).\nIn general, accelerated MRI reconstruction aims to exploit fast-scanned MRI sequences, that are under-sampled in the k-space, and then transform them to full-sampled high-quality MRI data. Given the physical foundation in"}, {"title": "2. Related works", "content": "For accelerated MRI reconstruction, traditional approaches primarily include Sensitivity Encoding (SENSE) Pruessmann et al. (1999) and GeneRalized Autocalibrating Partially Parallel Acquisitions (GRAPPA) Griswold et al. (2002). SENSE leverages the spatial sensitivity of multiple receiver coils to achieve faster imaging by reducing the acquisition time. On the other hand, GRAPPA reconstructs under-sampled data by estimating missing k-space data using kernel-based interpolation, enhancing the final image quality and reducing artifacts associated with parallel imaging techniques.\nWith the success of data-driven approaches, deep learning has been widely utilized in accelerated MRI reconstruction. Lv et al. (2021); Sriram et al. (2020) integrate deep learning with parallel imaging algorithms. Sriram et al. (2020) combined deep learning with the GRAPPA reconstruction algorithm. Zhang and Ghanem (2018b) transform the Iterative Shrinkage-Thresholding Algorithm (ISTA) Beck and Teboulle (2009) into a deep neural network to optimize compressive sensing (CS) for accelerated MRI reconstruction. Shitrit and Riklin Raviv (2017) utilized an adversarial neural network to generate the missing k-space data. The generated and missing k-space data are subsequently transformed via Fourier transform and then fed into the discriminator for evaluation. Cole et al. (2020) only requires under-sampled k-space data. The generator produces under-sampled k-space data from the generated image and the discriminator evaluates the k-space measurements instead of the MR image and provides the learned gradients back to the generator. Due to the high-fidelity generation characteristics of diffusion models, they have been widely applied in accelerated MRI reconstruction in recent years. Peng et al. (2022) introduced an unconditional diffusion model, which is trained to generate coil-combined MR image samples derived from fully-sampled data. G\u00fcng\u00f6r et al. (2023) proposed a conditional diffusion model for accelerated MRI reconstruction based on adaptive diffusion priors. To fully utilize the invariant nature of the low-frequency region in k-space during accelerated sampling, Cao et al. (2024) introduced a conditional diffusion model based on high-frequency diffusion. Similarly, Xie and Li (2022) proposed a measurement-conditioned diffusion model, which avoids diffusion in the undersampled mask region rather than only outside the low-frequency area, thereby preserving more prior information.\nAlthough diffusion models in accelerated MRI reconstruction have evolved from unconditional to conditional and further to prior-based conditional diffusion, they typically set the ending states of the forward diffusion process to pure or partial Gaussian noise instead of a deterministic under-sampled MR image. Differently, our approach leverages the bridge diffusion model to achieve a deterministic image-to-image translation. Then, we propose the cycle-consistent constraint for the model training, further enhancing accelerated MRI reconstruction."}, {"title": "2.2. Diffusion Model", "content": "Recent advancements in diffusion models, such as those by Ho et al. (2020); Nichol and Dhariwal (2021); Song et al. (2020b), have significantly enhanced image generation, surpassing the performance of GANS Goodfellow et al. (2014). These successes are attributed to key design choices, including network architecture Song et al. (2020b); Karras et al. (2022), optimized noise schedules Nichol and Dhariwal (2021); Karras et al. (2022), improved sampling techniques Song et al. (2020a); Lu et al. (2022); Zhang and Chen (2022), and advanced guidance methods Nichol and Dhariwal (2021); Ho and Salimans (2022).\nBridge diffusion models Li et al. (2023); Zhou et al. (2023) have been proposed for image translation tasks, where the diffusion process is constructed between paired images. This approach starts reverse diffusion from a deterministic image (without noise), making the sampling process more stable. Inspired by the bridge diffusion model, we construct a cycle-consistent bridge diffusion model between under-sampled and fully-sampled MR magnitude images."}, {"title": "3. Method", "content": "Fig. 2 shows an overview of our Cycle-Consistent Bridge Diffusion Model, including two bridge diffusion models for transformations $x \\leftarrow y$ and $y \\leftarrow x$, respectively. Here, $x_0$ and $y_0$ denote the fully-sampled and under-sampled magnitude images. $\\rightarrow$ and $\\leftarrow$ denote the forward and reverse processes in each diffusion model, respectively."}, {"title": "3.1. Bridge Diffusion Model", "content": "Given the inconsistent predictions of typical diffusion models, we exploit the Brownian bridge diffusion model Li et al. (2023) for the deterministic image-to-image transformation. The state distribution at each time step $t$ of a forward process ((e.g.,) $x \\rightarrow y$) can be expressed as:\n$q(x_t|x_0,y_0) = N(x_t; (1 \u2013 m_t)x_0 + m_t y_0, \u03c3_t I)$\n$m_t = \\frac{t}{T}$\n$\\sigma_t^2 = 2(m_t - (m_t)^2)$\nwhere $x_0 \\sim q_{data}(x_0)$, and $y_0 \\sim q_{data}(y_0)$. $T$ is the total number of iteration steps and $\u03c3_t$ denotes the variance. Here, the variances at the starting and ending states, (i.e.,) $\u03c3_0$ and $\u03c3_T$ are 0, avoiding the random predictions. Meanwhile, $\u03c3_T/2 = 0.5$ is bounded, which could smooth the model training Li et al. (2023).\nThe intermediate state $x_t$ in the forward process, transitioning from the starting state $x_0$ to the ending state $y_0$, can be represented as\n$x_t = (1 \u2013 m_t)x_0 + m_t y_0 + \\sqrt{\u03c3_t}\u03b5$\nwhere $\u03b5 \\sim N(0, I)$.\nThen, for the reverse process, the Brownian Bridge model initiates directly from image $y_0$. Following the principle of denoising diffusion methods, the reverse process ($x \\leftarrow y$) aims to predict $x_{t-1}$ based on $x_t$:\n$p_\u03b8(x_{t-1}/x_t, y_0) = N(x_{t-1}; \u00b5_\u03b8(x_t, t), \\tilde{\u03c3}_t I)$\ns.t., $\\tilde{t} = t \\rightarrow t-1$\n$\\tilde{\u03c3}_t = \\frac{\u03c3_{t-1}}{1 - m_{t-1}^2}$\n$\u00b5_\u03b8(x_t, t) = x_t - \\frac{m_t - m_{t-1}}{1 - m_{t-1}^2} \u03b5_\u03b8(x_t, t)$\nwhere $\u00b5_\u03b8(x_t, t)$ represents the predicted mean value of noise at the $t$-th steps, and $\\tilde{\u03c3}_t$ denotes noise variances in the reverse process.\nFinally, the loss function is formulated by optimizing the Evidence Lower Bound (ELBO) for the Brownian"}, {"title": "Bridge diffusion process:", "content": "$\\mathbb{E}_{x_0,y_0,\u03b5}[||(m_t(y_0 \u2013 x_0) + \\sqrt{\u03c3_t}\u03b5) \u2013 \u03b5_\u03b8(x_t, t)||]$\nTherefore, let $\u03b8_1$ and $\u03b8_2$ represent the denoising networks for $x \\rightarrow y$ and $y \\leftarrow x$ processes, respectively. The diffusion losses $L_{xy}$ and $L_{yx}$ at step t are:\n$L_{xy} = \\mathbb{E}_{x_0,y_0,\u03b5}[||(m_t(y_0 \u2013 x_0) + \\sqrt{\u03c3_1}\u03b5) \u2013 \u03b5_{\u03b8_1}(x_t, t)||]$\n$L_{yx} = \\mathbb{E}_{y_0,x_0,\u03b5}[||(m_t(x_0 \u2013 y_0) + \\sqrt{\u03c3_1}\u03b5) \u2013 \u03b5_{\u03b8_2}(y_t, t)||]$\nNote that, Equation (4) theoretically indicates that with sufficiently low loss, the original target image $x_t$ can be estimated at any time $t$ given a noisy image $x_t$. Therefore, the reconstructed $x_0$ based on $y_0$ at $t$ step can be calculated using the generation function only in training process:\n$\\hat{x} = x_t - \u03b5_\u03b8(x_t, t)$\nNote, the $\\hat{x_0}$ obtained during inference is generated through inverse diffusion sampling, following the same sampling procedure as described in Li et al. (2023)."}, {"title": "3.2. Cycle-Consistent Bridge Diffusion Model", "content": "To enhance the diffusion model training, we further adopt a cyclical design. Specifically, Equation (6) indicates that, during training, the target image $x_0$ or $y_0$ can be estimated by a noisy state $x_{t1}$ and $y_{t1}$, respectively. Therefore, the reconstructed fully-sampled and under-sampled MR magnitude images $x$ and $y$ become:\n$\\hat{x_0} = x_{t1} - \u03b5_{\u03b8_1}(x_{t1}, t_1)$\n$\\hat{y_0} = x_{t1} - \u03b5_{\u03b8_2}(y_{t1}, t_1)$\nWe then set the reconstructed ones as new end states. Hence, the intermediate states $x'_{t2}$ and $y'_{t2}$ become:\n$y'_{t2} = (1 \u2013 m_{t2})y_0 + m_{t2}\\hat{x_0} + \\sqrt{\u03c3_{t2}}\u03b5$\n$x'_{t2} = (1 \u2013 m_{t2})x_0 + m_{t2}\\hat{y_0} + \\sqrt{\u03c3_{t2}}\u03b5$\nSimilarly, the reverse processes $y \\leftarrow \\hat{x_0}$ and $x \\leftarrow \\hat{y_0}$ can obtain the new reconstructed images $\\hat{y_0}$ and $\\hat{x_0}$, respectively as:\n$\\hat{y_0} = y'_{t2} - \u03b5_{\u03b8_2}(y'_{t2}, t_2)$\n$\\hat{x_0} = x'_{t2} - \u03b5_{\u03b8_1}(x'_{t2}, t_2)$"}, {"title": "Therefore, a cycle-consistency loss can be used to reduce the distance between \\\\hat{x}_0 and \\\\hat{x}_0, and between \\\\hat{y}_0 and \\\\hat{y}_0, respectively as:", "content": "$L_{con}^{x_0y_0} (\u03b8_1, \u03b8_2) = \\mathbb{E}_{x_0,y_0} [||x_0 - \\hat{x_0}||]$\n$L_{con}^{y_0x_0} (\u03b8_1, \u03b8_2) = \\mathbb{E}_{x_0,y_0} [||y_0 \u2013 \\hat{y_0}||]$\nOverall, the total loss is a weighted sum of construction loss and consistency losses as\n$L_{total} = \u03bb(\\frac{L_{xy}+L_{yx}}{2}) + (L_{con}^{x_0y_0} + L_{con}^{y_0x_0})$\nwhere $\u03bb$ is a constant to balance losses for the model training. Algorithm 1 shows pseudo codes of our algorithm. Note that, only a denoising network $\u03b8_1$ is used for the model inference. Here, the model does not introduce additional inference time."}, {"title": "3.3. Contourlet Decomposition Embedding Module", "content": "The denoising networks of our CBDM model adopt a U-Net Ronneberger et al. (2015) with a time embedding. As illustrated in Fig. 3, we further propose a contourlet decomposition embedding module to enhance the backbone. Generally, the blurring and artifacts in under-sampled MR magnitude images are caused by the missing high-frequency information in the frequency space. Contourlet decomposition employs the Laplacian Pyramid (LP) Burt and Adelson (1987) and Directional Filter Banks (DFB) Bamberger and Smith (1992); Cimpoi et al. (2015) to process the low-pass images iteratively. LP aims to achieve low- and high-frequency decomposition in a multi-scale fashion. DFB is used to reconstruct the original signal with minimal samples, producing minimal sample representations in the 2D frequency domain through j-level binary tree decomposition, resulting in 2j directional sub-bands.\nFor example, the frequency domain is divided into $2^3$ directional sub-bands when $j = 3$, and sub-bands 0 - 3 and 4-7 correspond to the vertical and horizontal details, respectively. Fig 4 illustrates the visualization of sub-band features at different levels obtained from the contourlet decomposition of $x_t$. It can be observed that contourlet decomposition effectively extracts high-frequency features of image edges. Then, the Contourlet Decomposition Embedding Module further resizes the features of multiple sub-bands at each level to match the feature size at the corresponding level, stacks them along the channel dimension, and then uses three convolution layers to align the channel number as corresponding level features."}, {"title": "4. Experiments", "content": null}, {"title": "4.1. Data and Implementation Details", "content": "The experiments were conducted on the public benchmark fastMRI 1 and IXI datasets 2. From the fastMRI dataset, we selected 360 individuals from the multi-coil knee dataset for training, 8 for validation, and 20 for testing. Following Cao et al. (2024), the first six slices of each individual were excluded due to poor image quality."}, {"title": "4.2. In-Distribution Results", "content": "Regarding the fastMRI Knee dataset and the IXI dataset, as shown in Table 1 and 2, under equally-spaced Cartesian sampling with 4x and 8\u00d7 acceleration, our CBDM consistently outperforms all other methods across all metrics on both in-distribution datasets. Compared to state-of-the-art diffusion models, MC-DDPM Xie and Li (2022) and BBDM Li et al. (2023), our method achieves a ~1dB improvement in PSNR and a ~1%-2% increase in SSIM. The reconstruction results of the fastMRI knee dataset under 4\u00d7 equally-spaced Cartesian sampling are shown in Fig. 5. The first row includes results from PGAN, CGAN, pix2pix, DDPM, IDDPM, AdaDiff, MC-DDPM, HFS-SDE, BBDM, and CBDM. The second row displays the enlarged views of regions of interest (ROI), while the third row shows the error heatmaps. HFS-SDE exhibits noise and aliasing artifacts in the reconstructions due to the small center size of the low-frequency region. Similarly, the reconstructed images from pGAN, CGAN, AdaDiff, pix2pix, and MC-DDPM exhibit significant artifacts and noise, resulting in the loss of certain structures. In contrast, DDPM, IDDPM, BBDM, and our CBDM preserve more details. Among these, CBDM excels in reconstruction by preserving the most realistic high-frequency details and effectively suppressing artifacts. Fig. 6 presents the reconstruction results of the IXI dataset under a 4\u00d7 equally-spaced Cartesian sampling mask. CBDM similarly achieves the best performance, retaining the most realistic details to deliver the best visual quality."}, {"title": "4.3. Out-of-Distribution Results", "content": "We further conducted out-of-distribution experiments to verify the generalization of our model. All models were trained on fastMRI knee data and tested by fastMRI brain MRI scans. The reconstruction results for equally-spaced Cartesian sampling with 4\u00d7 acceleration are shown in Fig. 7. The reconstruction quality of pGAN, CGAN, and pix2pix methods significantly decreased, whereas diffusion-based methods maintained good reconstruction quality. Among them, our CBDM achieved the optimal reconstruction results with fewer noise and artifacts. Table 3 gives quantitative performance for the out-of-distribution experiments and our proposed CBDM model achieves the best performance for the brain data reconstruction."}, {"title": "4.4. Inference Efficiency", "content": "In the above experiments, the training and sampling steps for CBDM were set to 20 each, while other diffusion methods (except AdaDiff) used 1000 training steps and 200 sampling steps. The 200 sampling steps were accelerated using DDIM Song et al. (2020a) sampling. For AdaDiff, the first stage involved pretraining with 1000 steps, and the second stage did not use 200 sampling steps but instead performed 200 online iterations based on the data consistency loss. As shown in Fig. 8 (a), CBDM's significantly reduced sampling steps result in much higher inference efficiency compared to other diffusion methods. To further compare inference efficiency fairly, we also set the sampling steps or the second-stage iteration steps of other methods to 20, as shown in Fig. 8 (b). This adjustment led to a substantial drop in reconstruction performance for these methods. Although using DDIM Song et al. (2020a) with very few sampling steps can improve sampling speed, it comes with significant performance degradation, making it impractical for real-world applications. In contrast, CBDM achieves both training and sampling with only 20 steps, maintaining high efficiency without compromising reconstruction performance."}, {"title": "4.5. Ablation Study", "content": "Table 4 shows an ablation study to verify the effectiveness of our designs. The traditional BBDM Li et al. (2023) model is set as the baseline. Results indicate that BBDM achieves better results than other diffusion models. Then, both the cycle-consistency and CDEM designs improve the performance of the knee MRI reconstruction. Meanwhile, higher SSIM results indicate better structural fidelity of the reconstruction results. Table 5 presents a comparative analysis of the settings for $t_1$ and $t_2$ during the training process of our CBDM. Similarly, Table 6 compares the effects of different settings for $\\sqrt{\u03c3_{t1}}$ and $\\sqrt{\u03c3_{t2}}$. The results reveal that the time steps and noise variances for the two bridge diffusion processes can vary in each step of the cyclical diffusion process, highlighting the versatility and adaptability of the CBDM training approach."}, {"title": "4.6. Limitations", "content": "Although the cycle-consistent design enhances the image representation, our training process still requires two bridge diffusion models for training at the same time, which may bring more training costs. Additionally, the performance in out-of-distribution experiments still drops as shown in Table 3. Therefore, future work will explore diffusion models with lower training costs and stronger generalization capabilities."}, {"title": "5. Conclusion", "content": "We present a cyclical bridge diffusion model for accelerated MRI reconstruction. Specifically, a cycle consistency loss is used to help preserve fine-grained details and reduce the number of diffusion time steps for the image diffusion model training. Meanwhile, the Contourlet Decomposition Embedding Module extracts structural texture information in the frequency domain, capturing image structural texture and reducing artifacts. As a result, our CBDM approach effectively restores the normal human structure and texture details of MR images. Extensive experiments demonstrate that our method achieves state-of-the-art performance to transform under-sampled MRI data to fully-sampled MRI data on the benchmark fastMRI and IXI dataset."}]}