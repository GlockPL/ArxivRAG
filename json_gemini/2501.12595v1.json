{"title": "A Unified Invariant Learning Framework for Graph Classification", "authors": ["Yongduo Sui", "Jie Sun", "Shuyao Wang", "Zemin Liu", "Qing Cui", "Longfei Li", "Xiang Wang"], "abstract": "Invariant learning demonstrates substantial potential for enhancing the generalization of graph neural networks (GNNs) with out-of-distribution (OOD) data. It aims to recognize stable features in graph data for classification, based on the premise that these features causally determine the target label, and their influence is invariant to changes in distribution. Along this line, most studies have attempted to pinpoint these stable features by emphasizing explicit substructures in the graph, such as masked or attentive subgraphs, and primarily enforcing the invariance principle in the semantic space, i.e., graph representations. However, we argue that focusing only on the semantic space may not accurately identify these stable features. To address this, we introduce the Unified Invariant Learning (UIL) framework for graph classification. It provides a unified perspective on invariant graph learning, emphasizing both structural and semantic invariance principles to identify more robust stable features. In the graph space, UIL adheres to the structural invariance principle by reducing the distance between graphons over a set of stable features across different environments. Simultaneously, to confirm semantic invariance, UIL underscores that the acquired graph representations should demonstrate exemplary performance across diverse environments. We present both theoretical and empirical evidence to confirm our method's ability to recognize superior stable features. Moreover, through a series of comprehensive experiments complemented by in-depth analyses, we demonstrate that UIL considerably enhances OOD generalization, surpassing the performance of leading baseline methods. Our codes are available at https://github.com/yongduosui/UIL.", "sections": [{"title": "1 Introduction", "content": "Graph neural networks (GNNs) [18, 43, 55] have achieved promising results on various graph classification tasks, such as social network analysis and molecular property prediction. Such superior performance heavily relies on the assumption that training and test data are independently drawn from an identical distribution. Unfortunately, recent studies [12, 23] have shown that GNNs usually suffer from severe performance drops when facing the out-of-distribution (OOD) issue [35, 56], where the training and test graphs are drawn from different distributions. The poor generalization of GNNs hinders their practical deployment on critical applications.\nAiming at combating the distributional divergence between the training and test data, invariant learning [2, 3] is provoking great interest in graph classification tasks [8, 24, 26, 41, 53]. Specifically, for a graph being classified, it aims to discern a subset of features stable to the distributional uncertainty in training data. Such stable features are usually based on two assumptions: (1) they causally determine the target classification label [8, 53]; and (2) their relationship with the label is invariant, regardless of distribution"}, {"title": "2 Preliminaries", "content": "In this paper, we adopt a lowercase letter (e.g., g) to describe an instance, the same uppercase letter (e.g., G) to denote a random variable, the calligraphic font (e.g., G) to define a set, and the blackboard bold typeface (e.g., G) to define a space. We denote a graph by g = {A, X} with node set V and edge set U. y \u2208 Y is a graph label and C is the class number. Let A \u2208 R^{|V|\u00d7|V|} denote the adjacency matrix, where A[i, j] = 1 if edge (v_i, v_j) \u2208 U, otherwise A[i, j] = 0. Let X \u2208 R^{|V|\u00d7d_x} be the node feature matrix, where x\u2081 = X[i, :] is"}, {"title": "2.1 OOD Issue in Graph Classification", "content": "In this work, we focus on the graph classification task. Specifically, we define a training set D_{tr} = {(g_i, y_i)} drawn from training distribution P_{tr} (G, Y). Given a loss function l and a parameter space \u0398, we need to train a model f_\u03b8: G\u2192 Y on D_{tr}. Existing GNNs [18, 55] adopt the Empirical Risk Minimization (ERM) to optimize the following objective:\n\u03b8^* := arg min_{\u03b8\u2208\u0398} E_{(g,y)~D_{tr}} [l(f_\u03b8(g), y)].\nThen we need to use model f_{\u03b8^*} to infer labels in test set D_{te}, where the data is sampled from the test distribution P_{te} (G, Y). If P_{tr}(G, Y) \u2260 P_{te}(G, Y), the OOD issue will occur, and the performance of the GNN model will drop sharply. The OOD problem is widespread in graph classification tasks.\nTo investigate the cause of the OOD issue, we revisit the graph generation mechanism. Following the commonly-used assumption of graph generation [26, 41, 53], there exist stable features G_{st} in graph data, which causally determine the labels. These features are often called rationales [53], causal subgraphs [8] or causal features [41?] in the existing literature. The relationship between stable features and labels is assumed to be invariant across distributions. While their complementary parts G_{en}, often called environmental"}, {"title": "2.2 Invariant Learning for Graph Classification", "content": "Invariant graph learning, originally derived from Invariant Risk Minimization (IRM) [2] within the realm of Euclidean data, attains OOD generalization by learning graph representations invariant to environmental changes. However, due to the non-Euclidean nature of graph data, directly transferring the penalty term from IRM to graph learning poses a challenge, often leading to suboptimal performance [12, 53]. Consequently, a burgeoning line of research focuses on extracting stable subgraphs from the graph space to achieve invariant learning [8, 24, 26, 41, 53]. The fundamental framework is illustrated in Figure 1. This architecture mainly comprises three components: the feature extractor network \u03a6, GNN encoder h, and classifier w. The core idea is to extract stable features via the feature extractor, subsequently inputting these features into the GNN encoder and classifier for predictions. If the feature extractor can effectively capture stable features G_{st} in graph data across all possible environments, then the model can achieve excellent generalization under distribution shift. To ensure invariance across environments, these methods generally uphold the semantic invariance principle.\nDefinition 1 (Semantic Invariance Principle). Given a graph G and its label Y, an optimal model f^* should satisfy: (1) Sufficiency condition: Y = w^* (h^* (\u03a6^* (G))) + \u0454, \u0454 || G, where \u0454 is random noise. (2) Invariance condition: P^e (Y|\u03a6^* (G)) = P^{e'} (Y|\u03a6^* (G)), \u2200e, e' \u2208 E.\nGiven the features extracted by \u03a6, if Y can be completely determined and P^e (Y|*(G)) = P^{e'} (Y|\u03a6^* (G)) in every environment, the invariance principle is thus fulfilled. However, it's crucial to note that the environment stipulated in Definition 1 corresponds to the training environment (i.e., E = E_{tr}) in practice. It implies that the stable features identified by the semantic invariance might surpass the scope of the grouth-truth stable features. In light of this, we provide the subsequent definitions.\nDefinition 2 (Estimated Stable Feature). Given the training distribution P_{tr}(G, Y), let \u011c_{st} denote any subset (e.g., subgraph) of the graph data G, i.e., \u011c_{st} \u2286 G. If \u011c_{st} and G satisfy the condition: E_{P_{tr}} [Y|\u011c_{st}] = E_{P_{tr}}[Y|G], then \u011c_{st} is referred to as an estimated stable feature within the training data.\nWe hereby define the set of all estimated stable features, as specified in Definition 2 for Y, as Stable_{P_{tr}} (Y). For the sake of simplicity, we will represent the set under the training distribution P_{tr} as Stable(Y), that is Stable (Y) = Stable_{P_{tr}} (\u03a5).\nDefinition 3 (Minimal Stable Feature Set). Given the training distribution P_{tr}(G, Y), we can choose a subset Stable' (Y) \u2286 Stable(Y), if G' \u2209 Stable' (Y) and E_{P_{tr}} [Y|G'] \u2260 E_{P_{tr}}[Y|G], then we define Stable' (Y) = MinStable(Y) as the minimal stable feature set in the training data."}, {"title": "3 Methodology", "content": "This section provides our detailed implementations of the UIL. The overview of the UIL framework is depicted in Figure 2. Specifically, upon receiving the input graphs, the feature separator initially procures the estimated stable and environmental features (Section 3.1). On the one hand, we construct distance constraints for a group of estimated stable features within the graphon space to guarantee structural invariance (Section 3.2). On the other hand, we acquire invariant graph representations within the representation space to impose semantic invariance (Section 3.3)."}, {"title": "3.1 Stable & Environmental Feature Separator", "content": "We define our model as f = w\u25e6h\u25e6 \u03a6, which includes three modules \u03a6, h and \u03c9. \u03a6(\u00b7) is a stable feature extractor that targets stable features; h(\u00b7) is a feature encoder network (with readout function), which can obtain graph-level representation; w(\u00b7) is a classifier. Given a graph g with node set V and edge set U, I first obtains the node representation Z \u2208 R^{|V|\u00d7d_z} via a GNN-based encoder GNN(\u00b7), denoted as Z = GNN(g).\nThen we utilize two MLP networks \u03a8\u2081 and \u03a8\u2082 to generate stable masks, which denote the importance of nodes or edges to capture the stable features in graphs. Specifically, we can generate stable masks for node v_i \u2208 V and edge (v_i, v_j) \u2208 U:\nM^x_i = \u03c3(\u03a8\u2081(z_i)), M^e_{ij} = \u03c3(\u03a8\u2082([z_i, z_j])),\nwhere M^x_i and M^e_{ij} are the values of the node mask matrix M^x \u2208 R^{|V|\u00d71} and edge mask matrix M^e \u2208 R^{|V|\u00d7|V|}, respectively; z_i = Z[i,:] refers to the representation of node v_i; \u03c3 is sigmoid function that projects the mask values to [0, 1]. We define the environmental mask as the complement of the stable mask. Hence, we can generate environmental masks to capture environmental features from nodes: M^x = 1 \u2013 M^x and edges: M^e = 1 \u2013 M^e, respectively, where 1 is the all-one matrix. Finally, we can adopt these masks to estimate the stable feature \u011d_{st} = {A \u2299 M^e, X \u2299 M^x} and environmental feature \u011d_{en} = {A\u2299 M^e, X \u2299 M^x}, where \u2299 is element-wise multiplication."}, {"title": "3.2 Stable Graphon Estimation", "content": "We extract and summarize the implicit class-wise knowledge with stable generative patterns from a group of graph data with the same labels. We apply the graphon (in Definition 6) to the stable features, and give the definition of stable graphon as follows.\nDefinition 4 (Stable Graphon). Stable graphon is a graph function that can explicitly instantiate the class-specific pattern across a class of"}, {"title": "3.3 A Unified View for Invariant Learning", "content": "We enforce the invariance constraints within the graph space, thus leading us to propose the principle of structural invariance.\nDefinition 5 (Structural Invariance Principle). Given a dataset D with environment set E, we sample two graph sets G^e and G^{e'}\n with the same label y, where \u2200e, e' \u2208 E. Let G_{st}^e and G_{st}^{e'} denote the captured stable feature sets via feature extractor \u03a6. Then we can use these stable feature sets to estimate two stable graphons: G_{st}^e \u2192 W_{st}^e and G_{st}^{e'} \u2192 W_{st}^{e'}. An optimal stable feature extractor \u03a6^* should make the graphons satisfy: \u03b4(W_{st}^e, W_{st}^{e'}) = 0, where \u03b4(\u00b7,\u00b7) : W\u00b2 \u2192 R is a distance function defined on the graphon space W.\nIntuitively, our approach involves a more comprehensive introduction of inductive bias for invariant learning on graphs. Essentially, we assume that stable features of a class of graph data share the same generative pattern, which can be modeled by the same graphon. This generative pattern is assumed to be invariant across all possible distributions or environments, including unknown test distributions. However, the strategy of imposing only semantic invariance does not introduce an inductive bias from the perspective of the graph space. Therefore, it can only yield features that maintain semantic invariance across training environments. These features, although stable within the training data, are not necessarily minimal stable features, making it challenging to ensure generalization to unknown test distributions. Consequently, we aim to constrain directly within the graph data space, driving our model to capture features that are closer to the minimal stable feature. This holistic approach, encompassing both structural and semantic invariance, fosters a more robust method for the extraction of minimal stable features, facilitating improved generalization across diverse and unknown test distributions.\nCut Distance Minimization. We utilize cut distance (in Defi- nition 8) to replace \u03b4(\u00b7,\u00b7) in structural invariance principle, which can effectively measure the distance between two graphons. Using the cut distance to constrain the distance of stable graphons across different environments, we can define the objective of structural"}, {"title": "4 Theoretical Discussion", "content": "In this section, we provide a theoretical analysis to give insights into the proposed optimization objective. For the purpose of the theoretical discussion, we focus solely on the structural information of the graph data, neglecting the node features. We establish our discussion based on an assumption related to the data-generating distribution.\nAssumption 1. Let G = {g|g \u2208 G} be any set of graphs with the same label y. We denote its minimal stable feature set and estimated stable features (as per Definition 2) as G_{st} and \u011c_{st}, respectively. We postulate that G_{st} and \u011c_{st} can be generated by graphons W_{st} and \u0174_{st}, respectively.\nThis assumption is plausible, as a graphon acts as a global feature summarizing the shared and stable structural knowledge across a class of graphs. The structural features of a data subset may not be statically deterministic but could adhere to a certain distribution, such as the Bernoulli distribution. Given that the structures"}, {"title": "5 Experiments", "content": "In this section, we undertake comprehensive experiments on synthetic and real-world datasets to assess the efficacy of the proposed frameworks relative to state-of-the-art methods. Specifically, we endeavor to address the following research questions:\n\u2022 RQ1: How does the performance of UIL compare to existing state-of-the-art methods?\n\u2022 RQ2: Does UIL excel at learning minimal stable features more proficiently than the current methodologies?\n\u2022 RQ3: Is UIL adept at uncovering the structural invariant knowledge veiled within a group of graphs?\nWe put the detailed settings of the experiment, such as datasets, baseline methods and training hyperparameters in Appendix B."}, {"title": "5.1 Comparison with State-of-the-Arts (RQ1)", "content": "To demonstrate the superiority of UIL, we compare with numerous state-of-the-art efforts, including general generalization algorithms, graph generalization methods and augmentation methods. We choose GOOD [12] and OGB [15] datasets, including Motif, CMNIST, Molhiv and Molbbbp, and create distribution shifts with diverse graph features, such as base, color, scaffold and size. For a fair comparison, we adopt the GIN model to conduct all experiments. From the results in Table 2, the direct application of general generalization algorithms to graph learning tasks does not effectively enhance generalization. On average, these methods yield performances ranging from 65.08 to 65.89, which are comparable"}, {"title": "5.2 Learning Minimal Stable Features (RQ2)", "content": "We claim that UIL is adept at achieving structural invariance, thus enabling it to efficiently identify minimal stable features. In this section, we present experiments designed to provide experimental validation for our assertions and contrast UIL's performance with state-of-the-art methodologies.\nCapturing Superior Stable Features. We design extensive experiments to affirm that our structural invariance principle accurately captures the minimal stable features, while concurrently eliminating other environmental features. Specifically, we utilize"}, {"title": "5.3 Evaluation of Structural Invariance (RQ3)", "content": "Cut Distance Comparisons. We randomly select a group of graphs with the label y and the environment e_i from the dataset, and we can obtain the learned stable graphons \u0174^y_{e_i}. And we define our distance metric as:\nDis(e_i, e_j) = 1/C \u2211^C_{y=1} \u03b4(\u0174^y_{e_i}, \u0174^y_{e_j})."}, {"title": "5.4 Ablation Study", "content": "Different Components in UIL. We explore the impact of semantic and structural invariance. The results are shown in Figure 6 (a), where \"Sem-IL\" means UIL without graphon learning; \"Str-IL\" means directly using whole features for graphon learning without semantic invariance. We can find that it is difficult to achieve better results for semantic invariance or structural invariance alone, and sometimes even worse than ERM. While invariant learning from both semantic and structural views can achieve the best results.\nHyperparameter Sensitivity. Firstly, we explore the sensitivities of \u03b1 and \u03b2 in Figure 6 (b). We find that the performance is insensitive to \u03b1 or \u03b2. Secondly, Figure 7 (a) shows that smaller or larger initial values of stable ratio p will reduce the performance, and the best value is around 0.5~0.7. Thirdly, Figure 7 (b) shows that the performance is also insensitive to the number of inferred environments |\u00ca|."}, {"title": "6 Related Work", "content": "Out-of-Distribution Generalization on Graphs. Graph neural networks (GNNs), despite their significant success in numerous graph-related tasks, are often plagued by issues concerning interpretability [10], robustness [11, 17, 36], and efficiency [4, 40, 47, 49, 51, 58]. Current research [12, 23] indicates the presence of the OOD issue in various graph learning tasks, including graph classification [26, 53] and node classification [27, 52]. This has led to an increasing interest in OOD generalization in graph-related tasks, spawning methodologies based on graph data augmentation [13, 20, 30, 39, 42, 50], stable learning [9, 22], and invariant learning [24, 37, 38, 41, 46, 52, 53]. In this context, invariant learning has emerged as a significant line of research for OOD generalization. It primarily assumes that graph data contain stable features that have a causal relationship with the label, a relationship that persists across different environments. To capture these stable features, various techniques are employed. For example, DIR [53] encourages model predictions to remain invariant by intervening on environmental features, while GREA [26], CAL [41], and DisC [8] motivate the model to make predictions based on invariant stable features through the random combination or replacement of environmental features. Furthermore, GALA [5] establishes key assumptions essential for graph invariant learning. Consequently, there is a crucial need for graph learning methods that consider both structural"}, {"title": "7 Conclusion", "content": "In this paper, we introduce an invariant learning framework, UIL, adept at unearthing superior stable features and significantly mitigating the OOD problem in graph classification tasks. UIL offers a unified view for invariant learning, which concurrently accounts for both structural and semantic invariance, to harness superior stable features. Specifically, in the graph space, UIL maintains structural invariance by identifying a common generative pattern in a class of stable features via the invariant learning of stable graphons. We employ the cut distance to measure the discrepancies between graphons, with an aspiration that the learned stable graphons will remain invariant across various environments, hence fortifying structural invariance. Simultaneously, within the semantic space, UIL ensures that the identified stable features maintain consistent and optimal performance across diverse environments, thereby preserving semantic invariance. Theoretical and empirical proofs substantiate the effectiveness of two invariance principles, highlighting UIL's enhanced ability to discover better stable features."}, {"title": "A Definitions and Proofs", "content": "We present a brief proof of the proposition as follows. The estimated stable graphon is defined as \u0174_{st} = W_{st}+W_{se}(1-W_{st}). By optimizing L_{suf} and L_{sem}, we essentially adhere to the principle of semantic invariance to extract stable features, thereby preventing the feature extractor from capturing features from unstable environments. Additionally, an error exists between the graphon we estimate in each sampling process and the real graphon, i.e., ||W \u2013 \u0174||\u00b2 > \u03bc for some \u03bc > 0. Thus, we can model the estimated graphon as a Gaussian distribution \u0174_{st}[i, j] ~ N(W_{st}[i, j]+\u03c1(1-W_{st}[i, j]), \u03b5_{\u03c1}).\nIn our structural invariance objective as defined in Equation (4), we minimize ||W-W ||2. Considering\n\u0174[i, j] \u2013 W [i, j] ~ N(0, \u03b5(\u03c1 + p)),\nthe objective corresponds to minimizing a Gaussian matrix with a mean of 0 and a variance of \u03b5(\u03c1 + p). The L2 norm of the graphon loss propels the value of \u03c1 towards zero. Consequently, our optimization objective will eventually converge to the minimal stable features. In addition to the theoretical evidence provided thus far, we supplement our assertions with empirical support in Section 5.2 and 5.3."}, {"title": "B Implementation Details", "content": "We use SYN [41], GOOD [12] and OGB [15] datasets, including Motif, CMNIST, Molhiv and Molbbbp, which are benchmarks for graph OOD tasks. For SYN-b, Motif and CMNIST, we use classification accuracy. For Molhiv and Molbbbp, we follow studies [12, 15] and adopt ROC-AUC as the metric. For all experimental results, we report the mean and standard deviation by conducting 10 random runs. The statistical information of the dataset is shown in Table 4."}, {"title": "C Additional Analyses", "content": "Firstly, we define the average numbers of nodes and edges per graph as |V| and |E|, respectively. Let B denote the batch size for each training iteration, l and l_f denote the numbers of layers in the GNN backbone and feature estimator, respectively. d and d_f represent the dimensions of the hidden layers in the GNN backbone and feature estimator, respectively. For the stable feature learning objective, the time complexity is O(B(l_f |E|d_f + l|E|d)). For the semantic invariant learning, the time complexity is O(B\u00b2d). For the graphon estimation, the time complexity is O(B(|V|+|E|)). For the structural invariant learning, the time complexity is O(C|\u00ca|N\u00b2). For the regularization term, the time complexity is O(B(|V| + |E|)). For simplicity, we assume l = l_f and d = d_f. Hence, the time complexity of UIL is O(2Bl|E|d + B\u00b2d + 2B(|V| + |E|) + CN\u00b2|\u00ca|)."}, {"title": "C.2 Running Time", "content": "Compared to the original GNN model, UIL introduces additional complexities through a feature estimator, graphon estimation, and structural invariant learning. Despite these enhancements, the time and space costs remain within acceptable limits. We conducted empirical comparisons of the running time and model size between UIL, CAL, and the original model across various datasets. The results are shown in Table 5. Our analysis indicates that the UIL running time is approximately 1.5~2 times longer than that of the base model, and the model size is roughly 1.5 times larger. Despite these increases, our method competes closely with the current SOTA methods, such as CAL, in both running time and model size. Considering the significant performance improvements achieved by UIL, we argue that this model offers an advantageous performance-complexity trade-off. In practical applications, the additional computational complexity introduced by UIL is justifiable and manageable."}, {"title": "D Additional Experiments", "content": "We curate a new dataset, SYN5, which mirrors SYN-b except for the number of stable parts (i.e., house, cycle, grid, diamond). Each graph instance comprises an environmental subgraph containing N_s stable parts, where N_s is randomly sampled from the range 1~5. These stable parts collectively form the stable features of a graph instance. We proceed to randomly sample two groups of graphs with identical labels y but differing environments e and e', denoted as G^e and G^{e'}. From the dataset, we can extract the ground-truth stable feature for each graph and compile two sets: G^e_{st} and G^{e'}_{st}. Next, we estimate two complete graphons G^e \u2192 \u0174^e and G^{e'} \u2192 \u0174^{e'}, two stable graphons G^e_{st} \u2192 \u0174^e_{st} and G^{e'}_{st} \u2192 \u0174^{e'}_{st} and two environmental graphons G^e_{en} \u2192 \u0174^e_{en} and G^{e'}_{en} \u2192 \u0174^{e'}_{en}. We then define d_{full} = \u03b4(\u0174^e, \u0174^{e'}), d_{st} = \u03b4(\u0174^e_{st}, \u0174^{e'}_{st}), and d_{en} = \u03b4(\u0174^e_{en}, \u0174^{e'}_{en}). We execute experiments on both SYN5 and CMNIST, with results documented in Table 6. It is evident from these results that the distances between complete graphons or environmental graphons are significantly larger than the distances between stable graphons across varying environments. This phenomenon underscores the notion that a class of graphs shares class-specific knowledge that exhibits structural invariance."}]}