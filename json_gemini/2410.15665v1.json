{"title": "Long Term Memory : The Foundation of AI Self-Evolution", "authors": ["Xun JIANG", "Feng LI", "Han ZHAO", "Jiaying WANG", "Jun SHAO", "Shihao XU", "Shu ZHANG", "Weiling CHEN", "Xavier TANG", "Yize CHEN", "Mengyue WU", "Weizhi MA", "Mengdi WANG", "Tianqiao CHE\u039d"], "abstract": "Large language models (LLMs) like GPTs, built on vast datasets, have demonstrated impressive capabilities in language understanding, reasoning, and planning, achieving performance comparable to humans in various challenging tasks. Most studies have focused on further enhancing these models by training them on ever-larger datasets, aiming to develop more powerful foundation models. However, while training stronger foundation models is crucial, we propose how to enable models to evolve while inference is also vital for the development of AI, which refers to AI self-evolution. Compared to using large-scale data to train the models, the self-evolution may only use limited data or interactions. Drawing inspiration from the columnar organization of the human cerebral cortex, we hypothesize that AI models could potentially develop emergent cognitive capabilities and construct internal representational models through iterative interactions with their environment. To achieve this, we propose that models must be equipped with Long-Term Memory (LTM), which stores and manages processed real-world interaction data. LTM not only enables the representation of long-tail individual data in statistical models but also facilitates self-evolution by supporting diverse experiences across various environments and agents. In this report, we first explore the concept and significance of AI Self-Evolution, focusing on its potential to enhance AI models during the inference stage. We examine the role of LTM as a key mechanism for enabling lifelong learning in AI systems, allowing models to continually evolve based on accumulated interactions and experiences. Next, we detail the structure of LTM and the corresponding data systems required to facilitate high-quality data acquisition and retention, ensuring the effective representation of individual data. Finally, we classify various approaches for constructing personalized models using LTM data and discuss how models enhanced by LTM can achieve self-evolution through interaction with their environments.Based on LTM, our multi-agent framework OMNE achieved first place on the GAIA benchmark. This demonstrates the great potential of utilizing LTM for AI Self-Evolution and solving real-world problems. We present our technical roadmap and discuss potential avenues for future research. We believe that advancing research in LTM is critical for the ongoing development and practical application of AI technology, especially for self-evolution. We hope this work will inspire more researchers to contribute to the exploration of this exciting and evolving field.", "sections": [{"title": "1 Introduction", "content": "Artificial Intelligence (AI) is recognized as a key technology in the Fourth Industrial Revolution[1], empowering machines to perceive their environments and act intelligently through algorithms and software to optimize the achievement of various objectives. Al technologies are now widely applied in areas such as finance, education, and healthcare. In recent years, the development of large language models (LLMs) and LLM-powered agents has significantly enhanced AI capabilities, which are more powerful in solving various challenging tasks under diverse scenarios.\nAt its core, a model can be understood as an advanced form of data compression. A classic example is Newton's law of universal gravitation, which condenses complex astronomical data into a simple mathematical formula. This compression represents large amounts of data in a concise form. Similarly, LLMs compress vast amounts of text corpora into statistical patterns to generate coherent text [2]. However, we argue that intelligence is not limited to learning from existing data, the self-evolution ability is also important for the development of AI models, which is similar to the evolution ability of humans. Tasks from different scenarios often have distinct data distributions and diverse ability requirements, where the self-evolution ability will enable AI models to adapt to new tasks by learning limited interactions for powerful performances. Self-evolution will also contribute to diverse models, which can further help the development of AI, especially LLM models in recent years."}, {"title": "1.1 Phases of Model Evolution processes of LLMs", "content": "To better understand the need for self-evolution for LLMs, as shown in Figure 1, we propose to break down the model evolutionary process of LLMs into three main phases. These phases highlight the gradual progression from simple pattern recognition to self-evolved personalized intelligence."}, {"title": "1.2 Principles to Achieve Model Self-Evolution", "content": "The ability of a model to self-evolve is crucial for its long-term adaptability and personalization, and this depends heavily on an effective memory mechanism. In this context, we propose that long-term memory (LTM) provides the historical data accumulation and experiential learning capacity necessary for continuous model evolution. Just as humans refine their cognition and behavior through experience and memory, LTM enables a model to gradually optimize its reasoning and learning capabilities when dealing with long-term, dispersed, and personalized data."}, {"title": "1.2.1 Empower Foundation Models with LTM Data for Self-Evolution", "content": "In traditional LLMs, updating the model typically requires adjustments to all parameters, which is impractical for processing individual-specific data [4]. A more optimal approach is to employ localized updates, allowing the model to adapt to sparse [5], personalized LTM data without compromising the stability of the global model. This method addresses the issue of individual data being \"averaged out\" in current models, enabling more comprehensive expression of personalized information.\nTechniques such as Retrieval-Augmented Generation (RAG) with In-Context Learning (ICL) and Low-Rank Adaptation (LoRA) for fine-tuning (SFT) can be seen as ways to locally update individual data. We have developed a mixed strategy to integrate LTM data, yielding promising results in practical applications. However, this may not a perfect solution, and we are continuing to explore how to effectively integrate long-tail individual data into the model's memory mechanisms, hoping to attract more researchers to contribute to this field of exploration."}, {"title": "1.2.2 Real-Time Weight Updates Combined With LTM Data for Self-Evolution", "content": "Current LLMs typically separate the inference and training phases, where model weights are frozen during inference, preventing adjustments and learning based on new input [6]. This fixed inference process limits the model's adaptability, particularly when handling personalized tasks and real-time learning. Inspired by the human brain's updating mechanism, we believe that future LLMs should integrate inference and training with LTM, enabling the model to dynamically adjust weights upon receiving new information, akin to the continuous learning ability of humans. We also provided an overview of early work in the following sections, demonstrating how the integration of real-time training and inference allows LLMs to become more flexible and quickly adapt to new tasks or long-tail data. Additionally, this integration could help the model self-reflect and correct faulty reasoning paths when faced with complex inference tasks, improving both accuracy and efficiency. This dynamic self-adjustment capability would greatly enhance the model's personalization capacity and its potential for long-term evolution.\nWith LTM, a model can not only learn from short-term memory but also extract valuable insights from historical data, forming a deeper understanding of individual preferences and behavior patterns over time [7]. This understanding lays a solid foundation for personalized customization and dynamic adjustments, allowing the model to evolve more effectively. Especially when faced with new or extreme situations, LTM enables the model to reference past experiences, quickly make adjustments, and self-evolve, thereby achieving greater flexibility and adaptability."}, {"title": "1.3 The Implementation Path of LTM in Model Self-Evolution", "content": "Inspired by the importance of LTM for humans, we argue that research into long-term memory is essential for advancing model personalization. As AI models and intelligent agents continue to evolve, their foundational capabilities, akin to an increase in machine intelligence \u201cbrain capacity\", provide greater support for the integration of long-term memory into personalized models. While efforts have been made to construct memories or experiences for evolving AI systems, significant gaps remain in defining, constructing, and evaluating long-term memory for AI, hindering the development of personalized LLMs. We begin by defining AI self-evolution and LTM, exploring the key role of LTM within it. We then focus on how LTM can be utilized to enable AI self-evolution. Our research focuses on three questions:\n1. What is AI self-evolution, and what constitutes long-term memory? Why does AI self-evolution require models to have personalized capabilities? Why is long-term memory essential for achieving true personalization? What are the shortcomings of memory mechanisms in current language models, and how can these deficiencies help us refine the definition of LTM?\n2. How to construct LTM for self-evolution? What types of data are most suitable for forming the foundation of a model's personalized long-term memory, and how can we distill and structure this raw data into LTM?\n3. How to use LTM for AI self-evolution? How can we efficiently process and utilize individual data to continuously update long-term memory, ensuring that it not only understands individual preferences but also enables self-evolution by adapting and coordinating with the environment as data grows and changes?\nThe main contributions of our study are summarized as follows:\n\u2022 Definitions of AI Self-Evolution and LTM. We provide an in-depth discussion of the relationship between AI self-evolution and LTM, proposing a systematic framework that highlights the core role of LTM in the process of AI evolution. Through LTM, AI not only addresses personalized needs but also continuously learns and optimizes, bridging the gap between general models and truly personalized intelligent systems. By effectively handling individual long-tail data, the long-term memory mechanism significantly enhances the individual capabilities and diversity of agents, laying the foundation for AI self-evolution.\n\u2022 Data Framework for LTM. To implement long-term memory, we developed a data collection, analysis, and synthesis framework that allows for differentiated system deployment based on various business scenarios. To verify the generalization ability of this framework,"}, {"title": "2 AI Self-Evolution", "content": "The process of AI self-evolution can be compared to the Thousand Brains Theory or biological individual evolution. In the Thousand Brains Theory proposed by Jeff Hawkins [8], the brain does not operate through a single centralized system; rather, it constructs an understanding of the world through thousands of mini-models in the neocortex. These mini-models function independently while working together to form a diverse, distributed intelligence system. This theory challenges the traditional linear understanding of the brain by emphasizing that intelligence arises from the parallel processing and collaboration of multiple models. The Thousand Brains Theory posits that each region of the brain can independently create maps of the world and interact with maps from other regions, resulting in a more accurate and comprehensive cognition. Therefore, intelligence evolves progressively through the collaboration of multiple independent models.\nOn the other hand, the history of biological evolution demonstrates that there is no single \u201csuperorganism\" dominating ecosystems [9; 10]. Instead, the diversity driven by individual adaptations and mutations has enabled the formation and flourishing of the complex network of life we observe today.\nSimilarly, AI self-evolution can follow a path of multi-agent collaboration. In a multi-agent system, different agents interact, learn, and collaborate with one another to optimize their capabilities, generating personalized data. This personalized data serves as the foundation for continuous AI evolution, driving it from an initial general-purpose model to a system that increasingly adapts to individual needs. Just as biological evolution forms complex ecosystems through mutation and adaptation, AI self-evolution relies on diversity and co-evolution. This evolutionary path enables AI to continuously adapt to different environments and requirements, forming a more diverse and flexible intelligence system.\nIn the following sections, we will define AI self-evolution, break down the key system dependencies within AI self-evolution, and discuss how these capabilities contribute to more effective and adaptive self-evolution."}, {"title": "2.1 Definition of AI Self-Evolution", "content": "Definition: AI self-evolution refers to the process by which AI models achieve breakthroughs in multi-agent collaboration and cognition through continuous learning and optimization with personalized data. This process is based on a shared core architecture, where each model evolves by processing personalized experiences and data, thereby enhancing its reasoning capabilities and adaptability, ultimately achieving autonomous learning and continuous evolution in dynamic environments.\nModel self-evolution enables AI models to continuously learn from personalized data, adapting to ever-changing environments and meeting diverse needs without relying heavily on human intervention. Throughout this process, models process and absorb new experiences, optimizing their architecture and outputs, evolving from generalized knowledge to more contextually adaptive personalized knowledge. Through dynamic learning mechanisms, models can retain and utilize key information from past interactions, supporting future decision-making and effectively mitigating issues like overfitting and data drift.\nA key feature of model self-evolution is that it is based on a unified foundational architecture, ensuring that all model instances share a consistent core structure. However, the evolution of each model is driven by the unique experiences and data it processes, with differences between models arising from their individualized handling of personalized data. This approach ensures that, while models adhere to consistent internal rules and mechanisms, they can develop in differentiated ways according to personalized needs and environments. As evolution progresses, models become better at simulating individual behaviors, providing personalized and precise context-aware outputs, ultimately laying a solid foundation for multi-agent collaboration and cognitive breakthroughs."}, {"title": "2.2 Key System Dependencies for AI Self-Evolution", "content": "The realization of AI self-evolution does not happen spontaneously; it relies on a series of key system dependencies that provide the necessary foundation and framework for AI models to learn, optimize, and evolve into more personalized agents in ever-changing environments. These dependencies include not only the mechanisms of multi-agent collaboration but also the generation of personalized data, the construction of long-term memory, distributed model updating mechanisms, and self-correction mechanisms. These interdependent factors collectively drive the transition of AI from static models to self-evolving systems, helping AI transcend the limitations of traditional intelligence and gradually move toward the future of AI self-evolution."}, {"title": "2.2.1 Multi-Agent Collaboration Mechanism", "content": "The multi-agent collaboration mechanism is a key element of AI self-evolution, especially in handling complex tasks where efficient cooperation among multiple agents can significantly enhance the overall system performance[11]. With the rise of large language models (LLMs) demonstrating the phenomenon of \"emergent intelligence,\" the capabilities of AI systems have been greatly enhanced, accelerating the development of AI models[12]. These LLMs, with their vast number of parameters, endow agents with stronger memory, reasoning, and adaptability, allowing AI to perform remarkably well in more complex tasks. However, from the perspective of multi-agent collaboration, model personalization becomes the core factor promoting agent collaboration and evolution, particularly in solving complex problems and tasks.\nJust as in human intelligence evolution, where increased brain capacity enhanced memory, thinking, and reasoning abilities, propelling the development of civilization[13], LLMs similarly drive leaps in Al capabilities. However, current research suggests that in more complex scientific and engineering problems, human collaboration is essential. Similarly, whether AI systems will experience a second wave of emergent intelligence in the future depends on whether collaboration among multiple agents can be elevated to a new level.\nSome explorations suggest that in small-scale multi-agent collaborations, increasing the number of agents does bring some performance improvements, but these gains are not consistent or stable[14]. We believe the key issue behind this lies in the fact that most current multi-agent collaborations are still limited to role-playing interactions, where the agents' capabilities and knowledge are often homogeneous, lacking the differentiated skills required for deep collaboration. To achieve"}, {"title": "2.2.2 Differentiated Personalized Models", "content": "Personalized data generation is one of the core driving forces behind AI self-evolution, especially in multi-agent systems where having personalized models for each agent is crucial for ensuring system diversity and efficient collaboration. As AI application scenarios become increasingly complex, models must continuously acquire, process, and respond to personalized data to dynamically adjust to the needs and preferences of different individuals, truly meeting diverse task requirements[15]. Each agent, through its personalized model, can not only handle specific tasks independently but also contribute unique insights and experiences during collaboration with other agents, thereby generating more diverse and personalized data within the overall system.\nThis diversity brings stronger collaborative capabilities to AI systems. Through effective interactions among agents, personalized models can better respond to the needs of different individuals and support continuous model evolution through the accumulation of long-term data and continuous learning. In complex fields like healthcare[16], the requirement for model personalization becomes especially prominent when handling multimodal and heterogeneous data. A one-size-fits-all strategy shows limitations in addressing these complex tasks, while personalized models with differentiated processing capabilities can dynamically adapt to individualized scenarios, delivering precise and efficient performance.\nMoreover, even within the same task scenario, different individuals will have significantly different expectations of the model[17]. Through personalized models, AI systems can dynamically adjust according to these varied needs, providing highly tailored services to each individual. For example, in dialogue systems, individuals have unique preferences for the style, tone, and even response format of the model's output. To achieve precise personalized services, models must have dynamic learning capabilities, deepening their understanding of individual needs through continuous interaction.\nTherefore, personalized models not only promote the diversity and collaboration of AI systems but also support the self-optimization and evolution of the entire system by generating more personalized data. This process forms a positive feedback loop: through the collaborative work of multiple agents, Al systems generate increasingly personalized feedback, continuously meeting individual needs and further enhancing model capabilities, ultimately achieving true self-evolution."}, {"title": "2.2.3 Self-Correction and Evolution Mechanism", "content": "To achieve AI self-evolution, models must possess a self-correction mechanism [18]. This mechanism not only ensures the internal consistency of the model but also enables it to adapt to changes in the external environment. Self-correction is at the core of AI self-evolution, allowing models to update their cognition and behavioral strategies through continuous feedback loops. This is similar to the process of biological evolution, where selection and adaptation drive continuous optimization to fit the environment.\nRecent mathematical studies suggest that predictable information often exists in the low-dimensional structures of high-dimensional data [19] [20] [21]. Understanding and leveraging this concept is crucial for AI self-evolution. By identifying the low-dimensional structures within data, AI can learn and generalize more effectively, thus enhancing its autonomous learning and evolutionary capabilities."}, {"title": "2.2.4 Long-Term Memory and Learning Ability", "content": "Long-Term Memory (LTM) is a fundamental cornerstone in the process of AI self-evolution, providing models with the ability to accumulate historical experiences and knowledge, enabling continuous optimization through long-term interaction and learning. LTM can store data not only at the individual level but also accumulate data over time, helping models adjust their responses and behaviors based on this information, thus facilitating self-evolution. Compared to most personalized approaches that rely on a context window, long-term memory overcomes the limitations of short-term approaches by endowing models with the ability for continuous learning and self-improvement, enabling them to exhibit stronger adaptability when faced with complex environments and multi-agent collaboration.\nJust as humans use long-term memory to shape their behavior and identity, AI systems can also utilize LTM to provide customized responses based on individual data. This \u201cindividual data\u201d is not limited to user interaction data but can also include the specific needs of an organization or domain, allowing the model, through long-term accumulation, to surpass the framework of general knowledge and support more precise decision-making and behavioral adjustments. Therefore, LTM is crucial for enabling AI to achieve continuous self-evolution.\nThis paper emphasizes the role of long-term memory as a core driver of AI self-evolution. To truly realize AI self-evolution, we need models equipped with LTM, which can store and manage long-term interaction data in real-world environments and effectively represent long-tail data from individuals. Through this expression of diversity, models can continuously adjust themselves in collaboration with the environment and multiple agents, thus promoting the process of self-evolution. As such, long-term memory is not only the foundation for personalized data generation but also a key mechanism supporting the long-term adaptation and optimization of AI systems. In subsequent chapters, we will discuss the critical role of long-term memory in AI self-evolution in greater detail."}, {"title": "2.3 Thought Experiment: From Euclidean Geometry to Riemannian Geometry", "content": "An interesting question is: Can a large language model deduce Riemannian geometry from the five axioms of Euclidean geometry? This would not only require the model to perform logical deductions based on existing axioms but also to examine and challenge fundamental assumptions\u2014such as the parallel postulate\u2014thereby stepping into the entirely new domain of non-Euclidean geometry. Current LLMs are not yet capable of such creative leaps, as they rely on existing data for reasoning and lack the ability to propose new hypotheses and extend the boundaries of knowledge.\nSuppose LLMs could continuously adapt and update with personalized data, gradually developing sensitivity to atypical patterns-could they eventually overcome this limitation? In this thought experiment, the volume of data is not a constraint, as synthetic data could be continuously generated.\nIf the model could not only process human-provided data efficiently but also reflect on its own knowledge, dynamically adjust, and propose new hypotheses, using experimental deduction to validate them, then such a system would no longer be just a passive tool for knowledge storage and reasoning. Instead, it would become a cognitive entity capable of self-evolution, breaking through established mathematical frameworks and pioneering new theoretical realms.\nFrom this perspective, the potential of real-time updates and personalized learning lies not only in improving the accuracy of existing knowledge processing but also in granting the model higher levels of cognitive flexibility. This would enable it to genuinely participate in the discovery of new"}, {"title": "2.4 Future Directions and Challenges", "content": "As explored in this chapter, personalized models lay the foundation for multi-agent collaboration and cognitive breakthroughs in increasingly complex task environments. By integrating reasoning with training, allowing local updates, and adopting distributed architectures, AI will not only simulate human language outputs but also develop human-like reasoning and innovation abilities. Ultimately, AI will break through current technological limitations by interacting with the physical world, autonomously learning, and continuously evolving, driving the expansion of cognitive boundaries.\nWhile the prospect of AI self-evolution is promising, there remain significant technical and theoretical challenges in achieving this goal. After establishing the foundation for self-evolution through model personalization, key challenges for AI self-evolution include:\n\u2022 How can models be effectively evaluated and achieve self-evolution?\n\u2022 How can collaboration mechanisms among agents be designed?\n\u2022 How can we break through the current Scaling Law of models and continuously improve performance?\nTo address these questions, further discussions are presented in section 7. Our future research will focus on developing AI systems with autonomous learning, exploration, and evolutionary capabilities. In the next chapter, we will focus on the importance of long-term memory in AI self-evolution."}, {"title": "3 LTM for AI Self-Evolution", "content": "AI self-evolution emphasizes the ability of AI systems to improve their capabilities through continuous learning and adaptation. In this process, the retention and updating of individual model information by standalone AI models is a crucial feature of the entire AI system's self-evolution. However, most current methods for implementing LTM in models primarily rely on context windows. These models typically often utilize immediate context or recent individual interactions to generate responses [22]. While this approach can achieve a certain degree of diversity, it has significant limitations in supporting long-term learning and continuous adaptation, hindering models from achieving true self-evolution.\nTherefore, in this chapter, we will explore in depth the crucial role that LTM plays in AI self-evolution. We first define LTM in the context of AI self-evolution and analyze the shortcomings of current LLM memory mechanisms. We then discuss enhancing AI models' self-evolution capabilities by drawing inspiration from human LTM characteristics and addressing the challenges and potential solutions in achieving this goal. Through these discussions, we aim to provide new ideas and directions for building AI systems capable of continuous learning and self-improvement."}, {"title": "3.1 Definition of LTM in AI Self-Evolution", "content": "Definition: LTM is the information that can be retained and utilized by AI systems over extended periods, enabling models to adjust their responses and behaviors based on a broader context.\nJust as humans use LTM to shape their behavior and identity, AI systems can employ similar mechanisms to customize their responses and behaviors based on individual data. Here, \u201cindividual data\" is not limited to individual users but also includes specific organizations and domains, allowing models to adjust their responses and behaviors according to broader individual contexts and needs. This forms the basis for creating personalized models that go beyond mere general knowledge.\nLTM can be understood as a vast and complex repository of refined knowledge, shaped over time by a group of independent yet harmoniously interacting agents similar to cortical columns in the brain. Each agent functions as an autonomous unit capable of learning, refining, and storing a comprehensive model of its own corner of the world. However, these agents do not operate in"}, {"title": "3.2 Limitations of Current LLM Memory Mechanisms", "content": "LLMs like GPT-4 and Gemini demonstrate advanced intelligence and a comprehensive understanding of the world. However, to achieve true self-evolution, these models must be able to effectively process, store, and integrate information acquired through continuous interaction with various environments. Currently, LLMs primarily manage information through two memory mechanisms: contextual memory and compression-based parametric memory. While these mechanisms perform excellently in short-term tasks, they still fall short in supporting long-term autonomous learning and evolution."}, {"title": "3.2.1 Memory through Prompting", "content": "Current LLMs utilize prompts as a form of contextual memory to retain and leverage information during inference. The prompt, which includes both the instruction and relevant context, serves as a temporary memory buffer, allowing the model to process and generate content based on the given context. This mechanism enables LLMs to perform a wide range of tasks without task-specific fine-tuning. However, from a self-evolution perspective, this prompt-based memory mechanism has several key limitations:\n\u2022 Temporality: Stored context information is limited to the scope of the current task. Once a single inference call is completed, the model discards its previous state and sequence information, meaning it cannot utilize previously acquired knowledge in subsequent tasks.\n\u2022 Absence of Continuous Learning: Unlike systems with explicit memory mechanisms (e.g., Long Short-Term Memory (LSTM) networks [23]), LLMs do not have an intrinsic ability to accumulate and refine knowledge across multiple interactions or tasks based solely on prompts.\n\u2022 Limited Cross-Task Knowledge Integration: While prompts can provide task-specific context, they do not facilitate the automatic integration of knowledge across diverse tasks or domains. This hinders the model's ability to develop a cohesive understanding that evolves over time.\n\u2022 Dependency on External Curation: The quality and relevance of contextual information heavily rely on how prompts are crafted by users or systems. The model itself cannot autonomously curate or optimize its contextual knowledge base."}, {"title": "3.2.2 Parametric Compressed Memory", "content": "Another memory mechanism is compression-based parametric memory, which forms a type of LTM by compressing world knowledge into the model's parameters [24]. This mechanism allows models to retain key information over longer periods, but it has two significant drawbacks:\n\u2022 Unable to Update in Real-Time: Since the model's parameters are fixed during the training process, LTM cannot be easily updated once training is complete. This limits the model's diversification and adaptability to the environment, as it cannot quickly learn to generate new memories to adjust its behavior.\n\u2022 Difficulty in Expressing Individual Data: As statistical models, Transformers struggle to adequately represent individual data in their LTM. This typically leads to one of two"}, {"title": "3.3 Inspiration from Human LTM", "content": "To better understand LTM in Al systems and achieve AI system self-evolution, we can draw inspiration from the concept of human LTM. Existing neuroscience research suggests that personal memories generated through human interaction with the world are key factors in forming diverse and personalized behaviors. Current research typically divides human memory into three main types: working memory, short-term memory, and LTM. Working memory and short-term memory mainly contain temporary information related to current tasks or situations, which is quickly forgotten if not processed and transformed into LTM. Therefore, LTM can be considered the key data foundation for the formation of human personality.\nSpecifically, human LTM refers to the brain's ability to store and retrieve information over extended periods, ranging from hours to decades[25]. Unlike short-term memory, which is temporarily used for immediate use, LTM is responsible for preserving knowledge and experiences that can influence our future behavior[26; 27]. This type of memory includes various subtypes, including episodic memory (personal experiences), semantic memory (general knowledge), and procedural memory (skills and habits) [28].\nThe formation of LTM involves multiple processes, including encoding, consolidation, and retrieval[29]. Encoding is the initial acquisition of information, while consolidation is the process of stabilizing new information and integrating it into existing memory networks[30]. Retrieval is the process of accessing and utilizing stored information when needed. These mechanisms are supported by neural processes in the brain, including the hippocampus and various cortical regions[31].\nMoreover, LTM not only influences the formation of personal interests and habits but also plays a crucial role in the emergence of diverse needs[32]. Additionally, LTM significantly affects an individual's knowledge accumulation[33], problem-solving abilities[34], social adaptability and self-regulation abilities[35], leading to different expressions of intellectual development and evolution. In social life, social experiences and memories stored in LTM help individuals build trust, promote knowledge and resource sharing, and ultimately drive cooperation and collaboration[36]."}, {"title": "3.4 LTM in AI Models", "content": "In the previous section, we emphasized the important role of LTM in human evolution, which relies on a comprehensive mechanism for memory formation, updating, and utilization to ensure LTM effectively serves humans. Many aspects of model design and development draw inspiration from human cognitive and reasoning structures, such as the propagation mechanism of neural networks. So if LTM can aid the progress of human society, can it also be used for AI self-evolution? Our answer is affirmative, and we discuss this from the following aspects:\n\u2022 From the perspective of data accumulation: Both models and humans interact extensively with their environment, providing foundational data for personalization. Compared to humans, AI models can interact with their environment more efficiently and can perform these interactions and iterations in purely virtual, digital environments. Therefore, by designing appropriate memory refinement strategies, models should be able to accumulate long-term memories like humans, possibly even with higher efficiency and scale.\n\u2022 From the perspective of model updates: Artificial intelligence excels in storing and calling upon vast amounts of data, far surpassing the scale of human memory. Neural networks manage this data through distributed parameters, processing inputs from different domains. However, this storage is relatively rigid, lacking the flexibility for real-time updates and typically requiring retraining to implement updates. In contrast, human memory is highly"}, {"title": "3.5 The Importance of LTM for AI Systems", "content": ""}, {"title": "3.5.1 LTM in Single Models", "content": "LTM is crucial for diversity and AI self-evolution because it allows models to generate new outputs based on a deep understanding of individual interactions. By recalling past interactions, identifying preferences, and adjusting context over time, LTM enables AI systems to infer new response patterns from historical data and provide adaptive answers in new environments. This capability is rooted in the information encoding within neural network weights and parameters, which is critical for supporting personalized interactions and continuous learning[38].\nThe distributed and dynamic nature of LTM allows AI systems to optimize interactions based on historical data, individual preferences, and context[39]. Ultimately, integrating LTM into AI models, represented by tens of thousands of AI models, marks a significant step towards AI evolution. The data from LTM lays the foundation for personalized and context-aware interactions, evolving continuously over time. As AI technology continues to advance, the development of LTM will become key to creating systems that not only understand individual needs but can also anticipate and adapt to unique requirements, thus providing truly intelligent experiences."}, {"title": "3.5.2 The Role of LTM in AI Self-Evolution", "content": "The ability for models to self-evolve is a highly promising direction in AI technology development and application. Just as human intelligence relies on personal interactions and feedback from the real environment, the LTM data accumulated by models during interactions provides the most critical data support for self-evolution. Of course, there are some differences:\nUnlike human evolution, LTM-driven model evolution is not limited to real-world interactions. On one hand, models can interact with the physical environment and receive direct feedback like humans, which, after processing, will enhance their capabilities. This is also a key area of research in embodied AI. On the other hand, models can interact in virtual environments and accumulate LTM data, which has lower costs and higher efficiency compared to real-world interactions, thus achieving more effective capability enhancement.\nCompared to existing methods of directly storing interaction history and reflection, refined LTM data can provide high-quality data support for model self-evolution, further accelerating the efficiency and effectiveness of model evolution. This provides more effective support for enhancing the capabilities and rapid application of large model (LLMs) driven agents."}, {"title": "4 How to Construct LTM?", "content": "The construction of LTM represents a critical aspect in model personalization. Raw data serves as the foundation and source of LTM. Therefore, the relationship between LTM and raw data will be explored in the following sections. Subsequently, the method of refining raw data into LTM will be introduced, culminating in a review of existing methods to get high quality data for LTM, and he discussion consists of two main parts: data collection and data synthesis."}, {"title": "4.1 Raw Data to LTM", "content": "Raw Data represents the comprehensive collection of all unprocessed data that a model receives through interactions with the external environment or during the training process. This data includes a wide range of observations and records, which may contain both valuable patterns and large amounts of redundant or irrelevant information. While Raw Data forms the foundational layer for the model's memory and cognition, it requires further processing to be effectively used for personalization or efficient task execution.\nLTM refines and structures this raw data, making it usable by the model. This process enhances the model's ability to deliver personalized responses and recommendations. While Raw Data captures direct observations that may result in redundancy and clutter, LTM organizes this data into a structured"}, {"title": "4.2 Construction Strategies of Raw Data", "content": "Unlike the human brain that seamlessly receives and processes vast arrays of sensory inputs intoa memory, AI models face significant challenges in utilizing raw data to build LTM effectively. Critical issues that need to be addressed include:\n\u2022 Data diversity and representativeness: LTM must be diverse and representative to ensure model robustness across various scenarios and user groups. Imbalances and biases in collected data can lead to suboptimal performance. Additionally, the quality and consistency of data labeling are critical; inaccuracies can diminish model performance and personalization outcomes [40].\n\u2022 User behavior capture and reasoning: To achieve true personalization, the model needs to deeply understand user behavior patterns and reasoning processes. However, current LTM models struggle to capture intermediate reasoning steps and time-series information. This"}, {"title": "4.2.1 Data collection framework", "content": "Establishing a robust data collection and labeling process is essential for ensuring diversity and high quality LTM. The collection of data for personalized models begins with understanding the personal experiences", "contexts": "office collaboration and health management. A detailed description of these data systems is provided in Sec6.1.2..\nIn the digital realm, human activities and behavior on various platforms form significant digital footprints, providing crucial insights into preferences, interests, and interaction patterns. Digital communication data, including messages, emails, and voice recordings, reveal language preferences, communication styles, and social connections [42", "43": "."}]}