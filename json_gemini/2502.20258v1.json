{"title": "LLM as a Broken Telephone: Iterative Generation Distorts Information", "authors": ["Amr Mohamed", "Mingmeng Geng", "Michalis Vazirgiannis", "Guokan Shang"], "abstract": "As large language models are increasingly responsible for online content, concerns arise about the impact of repeatedly processing their own outputs. Inspired by the \"broken telephone\" effect in chained human communication, this study investigates whether LLMs similarly distort information through iterative generation. Through translation-based experiments, we find that distortion accumulates over time, influenced by language choice and chain complexity. While degradation is inevitable, it can be mitigated through strategic prompting techniques. These findings contribute to discussions on the long-term effects of AI-mediated information propagation, raising important questions about the reliability of LLM-generated content in iterative workflows.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) are becoming an integral part of our daily lives, helping us process, comprehend, and convey information via text, while also expanding their support to additional areas (Yin et al., 2023). Consequently, an increasing amount of online content is now model-generated or assisted (Geng and Trotta, 2024), and such content is almost indistinguishable from human-produced data (Uchendu et al., 2023).\nThis prompts us to consider the question: what effects arise when the same piece of information is repeatedly processed by LLMs through multiple iterations? This procedure is analogous to the telephone game in human communication, a widely known children's game in which a message is passed sequentially from one player to the next, with the final version often differing significantly from the original, usually with amusing or humorous effect. This happens because players often act as broken telephones, where information is gradually distorted as it is passed along the chain of individuals, highlighting how repeated transmission can lead to the accumulation of errors, omissions, or unintended alterations (Hitchcock et al., 2011).\nInvestigating these effects for LLMs is becoming increasingly crucial in the present era, because LLMs are not only consuming human-supplied information at one time, but also processing their own outputs in an iterative way. Therefore, our study focuses on exploring whether LLM also acts as a broken telephone, when the same content is continuously refined, paraphrased, or reprocessed, and particularly when the generated output becomes the input for subsequent model iterations. We expect to observe an effect similar to that of human information distortion through iterative generation.\nIn our study, we simulate the LLMs' telephone game in conjunction with the translation task mainly, under three experimental setups. As illustrated in Figure 1, within each iteration, a document in English is subsequently translated into one or more different languages, then back to English, by leveraging LLMs. We compare the back-translated English version with the initial English version at every iteration with textual relevance and factuality measures, to investigate whether and how information distortion accumulates. Our results show that over time, small alterations in phrasing, meaning, or factual details can accumulate, leading to a progressive drift from the original source, as illustrated by the example in Table 1. Code and data are publicly available. Our main findings include:\n\u2022 The degree of information distortion in translation chains depends on the choice of intermediate languages, influenced by their linguistic similarity to the source language and their prevalence in the model's pre-training and post-training corpora.\n\u2022 Greater chain complexity, whether by adding languages or models, often amplifies distortion, with longer chains introducing more degradation regardless of the type of iterative chain.\n\u2022 Although distortion is unavoidable, it can be mitigated through temperature control and restricted prompting, which restrict the LLM from deviating significantly from the original text.\nOur research echoes the ongoing conversation about the long-term impact of the widespread use of LLM-generated content on models themselves, humans, and society at large often termed model and knowledge collapse (Guo et al., 2024b; Peterson, 2024). Our findings raise concerns about the reliability of AI-mediated information dissemination over the long term and in an iterative way."}, {"title": "Related Work", "content": "Model Collapse. Iterative training on synthetically generated data induces model collapse, a phenomenon characterized by systematic erosion of the long-tail components of the original data distribution (Shumailov et al., 2023). Theoretical analyses further elucidated how self-consuming training loops alter intrinsic scaling laws, thereby intensifying this collapse (Fu et al., 2024; Dohmatob et al., 2024), complementing earlier findings on distributional distortions (LeBrun et al., 2022). Furthermore, Guo et al. (2024b) demonstrated that iterative training on synthetic text does not preserve the nuanced richness of human language, particularly in creative tasks, underscoring the broader challenges of maintaining linguistic diversity in iteratively generated content.\nIterative Generation and Information Evolution. Iterative generation can trigger model collapse, whereby the diversity of real-world information degrades over time\u2014a process that Peterson (2024) defines as knowledge collapse. Research on language evolution offers a framework for analyzing these degradations (Markov et al., 2023), aligning with broader perspectives on cultural evolution (Mesoudi and Whiten, 2008; Caldwell and Millen, 2008). In the context of LLMs, Perez et al. (2024) analyzed text properties evolution in rephrasing, continuation, and inspiration-taking tasks. Their work, however, overlooked translation\u2014a key LLM application\u2014and focused solely on chains involving a single model. Our work overcomes these shortcomings by investigating how iterative information translation accelerates distortion."}, {"title": "Methodology", "content": "In this section, we formalize the telephone game procedure with machine translation, noting that the broken telephone effect may occur with any generative task when carried out iteratively."}, {"title": "Notations and Definitions", "content": "Let \\(D = \\{d_i\\}_{i=1}^I\\) denote a set of \\(I\\) documents, \\(\\mathcal{L} = \\{l_j\\}_{j=1}^J\\) as a set of \\(J\\) natural languages, and \\(\\mathcal{M} = \\{m_k\\}_{k=1}^K\\) for a set of \\(K\\) models.\nWe define a translation chain as a sequence of \\(N\\) translation iterations that progressively transform a document. For iteration \\(t \\geq 1\\), let \\(d_{i, l_{source}}^{(t-1)}\\) be the \\(i\\)-th document in the source language at iteration \\(t-1\\). At iteration \\(t\\), an ordered language chain \\(\\mathcal{L}^{(t)}\\) is constructed by selecting a permutation \\(\\pi^{(t)}\\) of \\(J-1\\) languages from \\(\\mathcal{L}\\) and forming the sequence\n\\[\\mathcal{L}^{(t)} = (l_1^{(t)}, l_2^{(t)}, ..., l_{J-1}^{(t)})\\] \\((\\mathcal{L}^{(t)})\\)\nwith the requirement that \\(l_1^{(t)} = l_{source}\\) (ensuring that the final translation returns to the source language). Simultaneously, a model sequence\n\\[\\mathcal{M}^{(t)} = (m_1^{(t)}, m_2^{(t)}, ..., m_{J-1}^{(t)})\\]\nis defined, where each \\(m_j^{(t)}\\) is sampled uniformly from \\(\\mathcal{M}\\) (allowing repeats; if \\(|\\mathcal{M}| = K = 1\\), the same model is used throughout).\nLet \\(T_{a \\leftarrow b}^{(m)}\\) denote the translation operator that converts an input from language \\(b\\) to language \\(a\\) using model \\(m\\). The composed operator for iteration \\(t\\) is then\n\\[T^{(t)} = T_{l_1^{(t)} \\leftarrow l_2^{(t)}}^{(m_1^{(t)})} \\circ ... \\circ T_{l_{J-2}^{(t)} \\leftarrow l_{J-1}^{(t)}}^{(m_{J-2}^{(t)})} \\circ T_{l_{J-1}^{(t)} \\leftarrow l_{source}}^{(m_{J-1}^{(t)})}\\]\nso that the updated document is given by\n\\[d_{i, l_{source}}^{(t)} = T^{(t)}(d_{i, l_{source}}^{(t-1)})\\]\nStarting with \\(d_{i, l_{source}}^{(0)} = d_i\\), the process yields the sequence \\((d_{i, l_{source}}^{(0)}, d_{i, l_{source}}^{(1)}, ..., d_{i, l_{source}}^{(N)})\\), where \\(N\\) is the total number of iterations."}, {"title": "Experimental Settings", "content": "Languages. We selected English (EN) as \\(l_{source}\\) for all experiments and French (FR), German (DE), Dutch (NL), Vietnamese (VN), Chinese (ZH), and Thai (TH) as the bridge (intermediate) languages in the translation chains. Within each iteration, a document in English is subsequently translated into one or more bridge languages, then back to English. This set creates varying degrees of semantic, lexical, and syntactic similarities between the source language and the bridge languages, which may differentially influence the extent of distortion introduced within the translation chains (Marchisio et al., 2020; Guerin et al., 2024)."}, {"title": "Datasets", "content": "We utilized three datasets that span distinct domains: BookSum (Kry\u015bci\u0144ski et al., 2021), ScriptBase-alpha (Gorinski and Lapata, 2015), and (BBC)News2024 (Li et al., 2024a), from which we select articles published in 2024 to minimize the chances of data exposure that may result in biases amplification over the iterations (Luo et al., 2024; Li et al., 2024a). For our experiments, we randomly select 150 documents from each dataset, with each document containing between 100 and 200 words long."}, {"title": "Models", "content": "We primarily used two models, LLAMA-3.1-8B-INSTRUCT (Llama) (Dubey et al., 2024) and MISTRAL-7B-INSTRUCT-V0.2 (Mistral) (Jiang et al., 2023), for our main experiments. Additionaly, GEMMA-2-9B-IT (Gemma) (Team et al., 2024) is incorporated into Experiment 3 (Section 4.3) to evaluate higher complexity chains."}, {"title": "Decoding Parameters and Translation Prompt", "content": "Each model was used for inference with its default decoding parameters. We capped the maximum number of newly generated tokens at 8000 to encourage open-ended generation. This high limit allows translations, which can vary in length across different languages, to conclude naturally rather than being prematurely truncated. Models within the main experiments were prompted to translate documents from a source to a target language with a moderately constrained prompt. The full translation prompt can be found in Appendix C."}, {"title": "Evaluation Metrics", "content": "To comprehensively assess the impact of iterative generation on text quality, we employ two complementary sets of evaluation metrics: textual relevance and factuality preservation. The former quantifies the lexical, syntactic, and semantic deviations introduced at each generation step, while the latter evaluates the degree to which the generated text remains faithful to the original information."}, {"title": "Textual Relevance", "content": "We used BLEU (Papineni et al., 2002) to detect incremental errors, ROUGE-1 (Lin, 2004) to quantify word-level omissions and subtle deviations, CHR-F (Popovi\u0107, 2015) for capturing character-level deviations and errors accumulation, METEOR (Banerjee and Lavie, 2005) for being adept at capturing paraphrastic variations and subtle semantic shifts, and finally BERTScore (Zhang et al., 2019) for its focus on nuanced contextual and semantic relationships beyond traditional n-gram overlap-based methods."}, {"title": "Factuality Preservation", "content": "FActScore (Min et al., 2023) decomposes long-form text into atomic units and verifies each against a trusted reference using a dedicated judge model. In this study, we assume that the original text is factually correct and use FActScore to assess the rate of factuality degradation over the different iterations by comparing each model generation with its original text, then employ Claude 3.5 Sonnet as the judge model."}, {"title": "Experiments", "content": ""}, {"title": "Experiment 1: Bilingual Self-loop", "content": "Setup. We fix the language set to\n\\[\\mathcal{L} = \\{\\text{EN}, l_{bridge}\\}\\]\nwhere \\(l_{bridge} \\in \\{\\text{FR, DE, NL, VN, ZH, TH}\\}\\). We consider the case when \\(|\\mathcal{M}_1| = |\\mathcal{M}_2| = 1\\), with \\(\\mathcal{M}_1\\) and \\(\\mathcal{M}_2\\) containing Llama and Mistral respectively. We also consider the three datasets: BookSum, ScriptBase-alpha, and News2024. For each dataset \\(\\mathcal{D}\\), every document \\(d_i^{(0)} \\in \\mathcal{D}\\) undergoes \\(N = 100\\) translation iterations with an iteration of the form:\n\\[\\text{EN} \\rightarrow l_{bridge} \\rightarrow \\text{EN}.\\]\nAll translations within a single chain are performed by a single model. Concretely, at iteration \\(t\\), the translation operator\n\\[T^{(t)} = T_{\\text{EN} \\leftarrow l_{bridge}}^{(m_1)} \\circ T_{l_{bridge} \\leftarrow \\text{EN}}^{(m_1)}\\]\nis applied to produce\n\\[d_i^{(t)} = T^{(t)}(d_i^{(t-1)}).\\]\nThis yields the sequence \\((d_i^{(0)}, d_i^{(1)}, ..., d_i^{(100)})\\) for each document \\(d_i^{(0)} \\in \\mathcal{D}\\).\nHypothesis 1 (H1) We hypothesize that iterative translation chains better preserve relevance and factuality when the bridge language shares lexical overlap, script, and syntax with the source language. In contrast, languages markedly dissimilar from the source language are expected to introduce greater distortion over iterations.\nResults. Figure 2 presents Llama's iterative translation outcomes on the News2024 dataset. Across all language pairs, there is a gradual decline in both factuality and relevance. Notably, language pairs exclusively using Latin script\u2014with bridge languages such as French, German, and Dutch-demonstrated superior preservation of these qualities compared to those employing non-Latin script bridge languages, which exhibited more pronounced distortions over successive iterations. A similar trend was observed for Llama in the other datasets, while Mistral showed an even more severe decline across all three datasets. Comprehensive results for the remaining datasets and models are provided in Appendix B.1.\nThe average gradient values of FActScore in Table 2 quantify the rate of factuality loss across translation iterations. For language pairs composed solely of Latin script languages, gradients remain close to zero across all datasets and LLMs, indicating minimal degradations. For instance, in the News2024 dataset, the average gradients for EN \\(\\leftrightarrow\\) FR are -0.004 (\u00b10.003) with Llama and -0.007 (\u00b10.004) with Mistral, while for EN \\(\\leftrightarrow\\) DE they are -0.005 (\u00b10.003) and -0.011 (\u00b10.006), respectively. In contrast, chains involving non-Latin scripts\u2014particularly Thai\u2014exhibit significantly faster factuality loss. In the BookSum dataset, the EN \\(\\rightarrow\\) TH gradient is -0.026 (\u00b10.014) with Llama and -0.040 (\u00b10.025) with Mistral. This pattern is consistently observed across all evaluated language pairs, datasets, and models, with Thai demonstrating the highest rates of factual degradation."}, {"title": "Experiment 2: Bilingual Two-player", "content": "Setup. We fix the language set to\n\\[\\mathcal{L} = \\{\\text{EN}, l_{bridge}\\}\\]\nwhere \\(l_{bridge} \\in \\{\\text{FR, TH}\\}\\). Following the results presented in Section 4.1, we selected EN \\(\\leftrightarrow\\) FR and EN \\(\\rightarrow\\) TH for Experiment 2, as they demonstrated the lowest and highest levels of information distortion, respectively. We consider a model set \\(\\mathcal{M}\\) that includes both Llama and Mistral.\nFor this experiment, we used the News2024 dataset because, as shown in Section 4.1, the choice of dataset did not significantly influence the observed trends, and to further mitigate data exposure (Luo et al., 2024; Li et al., 2024a).\nUnlike Experiment 1, where a single model was used for both translation directions, we allow each translation step to potentially use a different model. At iteration \\(t\\), we define a two-component model sequence:\n\\[\\mathcal{M}^{(t)} = (m_1^{(t)}, m_2^{(t)}),\\]\nwhere \\(m_1^{(t)}\\) is the model used for the translation from English to \\(l_{bridge}\\), and \\(m_2^{(t)}\\) is the model used for the translation from \\(l_{bridge}\\) to English. Each component is sampled uniformly from \\(\\mathcal{M}\\).\nThe translation operator at iteration \\(t\\) is then defined as:\n\\[T^{(t)} = T_{\\text{EN} \\leftarrow l_{bridge}}^{(m_2^{(t)})} \\circ T_{l_{bridge} \\leftarrow \\text{EN}}^{(m_1^{(t)})}\\]\nThe output document at iteration \\(t\\) is then determined as shown in Equation 8. This yields the sequence \\((d_i^{(0)}, d_i^{(1)}, ..., d_i^{(100)})\\) for each document in the News2024 dataset.\nHypothesis 2 (H2) We hypothesize that the coexistence of two different models in the same translation chain will add more distortions to the original information, thereby causing the original information to degrade over the successive iterations.\nResults. Figure 3 shows distinct patterns in the collaborative performance of Llama and Mistral across different languages. In French, the joint translation chain did not enhance the preservation of factuality or textual relevance relative to the models operating independently; instead, the collaboration introduced additional distortions that further degraded all evaluation metrics. Conversely, in Thai, the collaboration of Llama and Mistral resulted in reduced distortion compared to Mistral alone, though it still exhibited greater degradation than Llama in isolation.\nWe further quantified the average gradient of FActScore. For French, the collaborative chain exhibited an average gradient of -0.007 (\u00b10.004), confirming minimal factuality degradation, though slightly worse than the standalone performances of Llama and Mistral. In contrast, for Thai, the collaborative chain showed a lower average gradient of -0.035 (\u00b10.019) when compared to the standalone chain of Mistral. However, despite this lower decline, it was still outperformed by the standalone performance of Llama, where factual degradation was less pronounced."}, {"title": "Experiment 3: Multilingual Multiplayer", "content": "Setup. In this experiment, we design three settings of increasing complexity, each incorporating at least two bridge languages and at least two models within the same translation chain. The objective is to examine whether introducing a greater number of languages or models accelerates distortion.\nSetting 1. We fix\n\\[\\mathcal{L} = \\{\\text{EN, FR, TH}\\}\\]\nand define \\(\\mathcal{M}\\) to contain both Llama and Mistral. At each iteration \\(t\\), we sample a permutation \\(\\mathcal{L}^{(t)} = \\pi^{(t)}(\\mathcal{L})\\) that enforces a cyclic translation path:\n\\[\\text{EN} \\rightarrow l_1^{(t)} \\rightarrow l_2^{(t)} \\rightarrow \\text{EN},\\]\nwith \\(l_1^{(t)}\\) and \\(l_2^{(t)}\\) drawn from \\{\\text{FR, TH}\\}\\) and satisfying \\(l_1^{(t)} \\neq l_2^{(t)}\\). The corresponding model sequence is\n\\[\\mathcal{M}^{(t)} = (m_1^{(t)}, m_2^{(t)}, m_3^{(t)}),\\]\nwith each \\(m_i^{(t)}\\) sampled uniformly from \\(\\mathcal{M}\\). The translation operator at iteration \\(t\\) is composed as:\n\\[T^{(t)} = T_{\\text{EN} \\leftarrow l_1^{(t)}}^{(m_3^{(t)})} \\circ T_{l_1^{(t)} \\leftarrow l_2^{(t)}}^{(m_2^{(t)})} \\circ T_{l_2^{(t)} \\leftarrow \\text{EN}}^{(m_1^{(t)})},\\]\nwhich is applied iteratively to generate:\n\\[d_i^{(t)} = T^{(t)}(d_i^{(t-1)}).\\]\nThis produces \\((d_i^{(0)}, d_i^{(1)}, ..., d_i^{(N)})\\), where \\(d_i^{(0)}\\) is the original document and \\(N = 100\\).\nSetting 2. We here retain \\(\\mathcal{L}\\) and the translation chain structure from Setting 1, utilizing the same translation operator as defined in Equation 14, while expanding \\(\\mathcal{M}\\) with an additional model, Gemma, to assess the impact of adding more models of similar size into the chain.\nSetting 3. We extend the language set to:\n\\[\\mathcal{L} = \\{\\text{EN, FR, TH, ZH, DE}\\},\\]\nand hold \\(\\mathcal{M}\\) fixed from Setting 1. The translation operator is then defined as:\n\\[T^{(t)} = T_{\\text{EN} \\leftarrow l_1^{(t)}}^{(m_5^{(t)})} \\circ ... \\circ T_{l_{4}^{(t)} \\leftarrow \\text{EN}}^{(m_1^{(t)})},\\]\napplied to generate \\(d_i^{(t)}\\).\nHypothesis 3 (H3) We hypothesize that higher complexity translation chains cause higher factual degradation of the source document.\nResults. As shown in Appendix B.2, all three experimental settings indicated a comparable degree of factual, lexical, and semantic degradation by the \\(100^{th}\\) iteration across all evaluation metrics. However, differences emerged in the rate at which this degradation occurred. Specifically, Setting 3 exhibited the steepest decline in factual accuracy, with an average FActScore gradient of -0.038 \u00b10.02. By the 10th generation, Setting 3's factuality had dropped to 0.054, and by the 100th generation, it further declined to 0.04. Setting 1 followed closely, with an average gradient of -0.036 \u00b1 0.02, showing a factuality score of 0.063 at the 10th generation and 0.04 at the 100th. Setting 2 exhibited the slowest rate of factual degradation, with an average gradient of -0.034 \u00b1 0.02, reaching 0.075 at the 10th generation and 0.04 at the 100th."}, {"title": "Ablation Studies", "content": ""}, {"title": "Other Tasks: Rephrasing", "content": "Building on our findings in section 4, we extend our experiments to explore whether information distortion manifests in other types of iterative generation chains. Inspired by the work of Perez et al. (2024), who examined the evolution of toxicity, positivity, difficulty, and length in rephrasing as well as in continuation and inspiration-taking chains, we further probe the effects of information distortion in more complex rephrasing chains.\nIn this task, the model is instructed to rephrase a given document while preserving its full meaning (the full rephrasing prompt can be found in Appendix C). We randomly sampled 30 documents from News2024 and conducted four experiments based on the setups from Sections 4.1, 4.2, and 4.3 (Setting 2). These experiments tested standalone rephrasing chains, the collaborative effects of Llama and Mistral, and an extended setup incorporating Gemma into the chain.\nRephrasing results are presented in Figure 4. Textual relevance metrics reveal rapid degradation of lexical and semantic properties over iterations. Among individual models, Llama shows the slowest divergence in textual relevance, with Mistral following. When these models collaborate, the degradation in textual relevance increases, and combining Llama, Mistral, and Gemma leads to the steepest decline, particularly after 100 iterations.\nThe same order was observed when evaluating factuality, although the loss was steadier, without clear convergence at the 100th iteration."}, {"title": "Temperature Variation Affects Outputs", "content": "To further investigate the impact of decoding parameters on the models' outputs, we conducted several experiments using Llama across a spectrum of temperature parameter values, including 1 \u00d7 10-6, 0.25, 0.5, 0.75, and 1.0 on 30 randomly sampled documents from News2024.\nFrom Figure 5, higher temperature settings lead to greater factual and semantic degradation. At extremely low temperatures (1 \u00d7 10\u22126), factuality drops slightly in the first two iterations but stabilizes thereafter. As temperature increases, stability diminishes, and factuality gradually diverges. Higher temperatures exacerbate this trend, with maximum temperature (1.0) causing the steepest decline, showing continuous divergence. Additional examples can be found in Appendix D."}, {"title": "Sensitivity of Iterative Translation Outputs to the Chosen Prompt", "content": "We subsequently investigated the influence of the translation prompt on the outputs produced by the iterative process. To this end, 30 documents were randomly sampled from the News2024 dataset, and Llama was tasked with translating them using three distinct prompts characterized by varying levels of constraint: simple, base (used in all our experiments), and constrained. The complete prompts are provided in Appendix C.\nFigure 6 illustrates that the level of constraint imposed by the prompt markedly affects the model's generation. Specifically, more constrained prompts were found to result in higher levels of relevance and factuality preservation."}, {"title": "Discussion and Conclusion", "content": "As LLMs increasingly shape online content, the likelihood that they re-process their own outputs continues to rise. This study confirms that such iterative generation leads to progressive information distortion, akin to the \u201cbroken telephone\u201d effect in human communication. Our findings from translation-based experiments are multifaceted.\nEffect of intermediate language(s) on information distortion. As found in Experiment 1, different language chains have varying levels of sensitivity to information distortion. As presented in Figure 2, we found that transmitting information between English and a highly similar language significantly reduces the distortion effect, while transmitting through a dissimilar language results in a more pronounced distortion. We suggest that this variation in information retention and distortion stems from the proportion of each language encountered during the models' training, with underrepresented languages experiencing greater distortion.\nChains of higher complexity may result in higher levels of distortion. Experiments 2 and 3 showed that increasing the levels of complexity of chains can result in higher levels of distortion. Figure 3 illustrates how the combination of Llama and Mistral amplified the distortion in the chain when French served as the bridge language. However, when Thai was used as the bridge language, their collaboration helped reduce distortion-likely due to the stronger model (Llama) and the weaker model (Mistral) interacting with an intermediate language that may have been underrepresented in Mistral's training compared to Llama. Moreover, we observed that increasing the number of languages in the translation chain amplifies information distortion, likely due to the cumulative effects of longer generation sequences. In contrast, incorporating Gemma into the chain improved information retention, which we hypothesize stems from its larger parameter count\u2014one to two billion more than Llama and Mistral. We leave the broader impact of model scaling for future work.\nInformation distortion can be reduced through temperature control and constrained prompting. Our findings suggest that while information distortion is unavoidable, it can be significantly mitigated through careful control of the model's generation temperature. Figure 5 shows that higher temperature values lead to greater distortion in the outputs, which we attribute to increased model creativity. A higher temperature encourages the generation of atypical tokens that may not fully preserve the meaning of the source document. Additionally, our analysis of prompt effects revealed that less constrained prompts contribute to greater noise accumulation over multiple iterations, resulting in higher divergence from the original meaning.\nThese findings underscore the need for strategies to mitigate such degradation and ensure the reliability of AI-generated content."}, {"title": "Limitations", "content": "While our study uses datasets from three different domains\u2014book summaries, movie scripts, and news\u2014they share similar characteristics and may not capture the rare or long-tailed information typical of specialized domains. Additionally, due to computational resource constraints, our experiments focus on models with seven to nine billion parameters. Future work should explore whether datasets from specialized domains and larger models influence the levels of information distortion in iterative generation chains."}]}