{"title": "Two Tickets are Better than One: Fair and Accurate Hiring Under Strategic LLM Manipulations", "authors": ["Lee Cohen", "Jack Hsieh", "Connie Hong", "Judy Hanwen Shen"], "abstract": "In an era of increasingly capable foundation models, job seekers are turning to generative AI tools to enhance their application materials. However, unequal access to and knowledge about generative AI tools can harm both employers and candidates by reducing the accuracy of hiring decisions and giving some candidates an unfair advantage. To address these challenges, we introduce a new variant of the strategic classification framework tailored to manipulations performed using large language models, accommodating varying levels of manipulations and stochastic outcomes. We propose a \"two-ticket\" scheme, where the hiring algorithm applies an additional manipulation to each submitted resume and considers this manipulated version together with the original submitted resume. We establish theoretical guarantees for this scheme, showing improvements for both the fairness and accuracy of hiring decisions when the true positive rate is maximized subject to a no false positives constraint. We further generalize this approach to an n-ticket scheme and prove that hiring outcomes converge to a fixed, group-independent decision, eliminating disparities arising from differential LLM access. Finally, we empirically validate our framework and the performance of our two-ticket scheme on real resumes using an open-source resume screening tool.", "sections": [{"title": "1 Introduction", "content": "Hiring decisions can profoundly impact an individual's professional path and long-term success. As algorithmic tools are increasingly deployed to recommend or make these decisions, they have rightfully come under scrutiny from economists [Hu and Chen, 2018, van den Broek et al., 2020], journalists [Lytton, 2024], and policy makers [City of New York, 2021]. AI tools that exhibit undue biases and unexplainable behavior present a major barrier to achieving accountability in these algorithmic hiring schemes [Dastin, 2018]. Although algorithmic hiring tools are designed with the goal of hiring the best candidates, these tools may not be robust to candidates manipulating their application materials [Stahl, 2022]. This problem has been studied through the lens of strategic classification where individuals can manipulate their inputs (e.g., a job application) to influence the decision made by a classifier (e.g., a hiring algorithm) [Hardt et al., 2016a, Kleinberg and Raghavan, 2020, Levanon and Rosenfeld, 2021]. The goal of the hiring side is to design a strategy-proof selection algorithm, while the goal of the applicants is to maximize their utility: the difference between the benefit of receiving a positive prediction and the cost of manipulation. The \"best response\" is then the optimal way an individual should modify their input, when the classifier's behavior is known, to achieve the highest utility. The challenge lies in designing classifiers that are robust to such manipulations while maintaining fairness and accuracy.\nWith the recent proliferation of generative AI services that are now widely used by job seekers [Chamorro-Premuzic, 2024], a new variable has been introduced in the algorithm hiring cycle and strategic classification. Writing or editing a resume using generative AI has become accessible and widespread. In a recent survey, 57% of respondents admitted to using AI to create their resume [Business Wire, 2025]. Since candidates have no knowledge of how employers make hiring decisions, the optimal strategic classification response becomes straightforward: candidates edit their resumes using their preferred AI tool, opting for a premium version if they recognize its advantages and can afford it. As a result, those accessing better models may gain an unfair advantage in the selection stage of automatic hiring algorithms. Thus, companies might be filtering for candidates who used the best LLMs rather than candidates who are the most qualified.\nThe interactions between hiring algorithms and application-enhancing generative AI tools create a unique setting to examine fairness and strategic behavior. Since manipulation in this setting is low-effort, many candidates will choose to manipulate their resumes, even without a guaranteed positive prediction. This contrasts with the classic model, where individuals manipulate their input only when a positive outcome is achieved. Moreover, strategic classification in the era of LLMs introduces two key challenges: (1) unlike prior group-based fairness settings, the hirer cannot directly determine whether an application has been manipulated or which LLM was used, and (2) unlike the classic strategic classification setting, manipulations are stochastic, as LLM outputs are inherently non-deterministic. Motivated by this complex yet realistic interaction between strategically generated application materials and algorithmic hiring algorithms, our work presents a first step into modeling and analyzing algorithmic hiring ecosystems in the era of generative AI; our contributions are as follows:\n\u2022 We show that some (more expensive) models enhance resume relevance scores more than other models, and that the benefits of repeated LLM manipulations stagnate (Section 3).\n\u2022 We translate the empirical behavior of LLMs used for job applications into a realistic model for strategic classification (Section 4).\n\u2022 We prove that under existing hiring schemes, disparities in access to LLMs lead to disparities in hiring outcomes, even under stochastic manipulations (Section 5) and an unknown deployed model.\n\u2022 We introduce a two-ticket scheme where the hiring algorithm applies an additional LLM manipulation to each submitted resume and considers this manipulated version together with the original submitted resume. We prove that this scheme improves disparities among candidates and accuracy for employers. We also generalize the two-ticket scheme to an n-ticket scheme, proving that the n-ticket scheme eliminates group-dependent disparities as n \u2192 \u221e, with outcomes converging exponentially to a fixed, group-independent decision (Section 6).\n\u2022 We validate our theoretical model and results through a case study using real resumes and an open-source resume scoring algorithm (Section 7), demonstrating that our two-ticket scheme enhances both fairness and accuracy in practice."}, {"title": "2 Related Work", "content": "Fairness in Algorithmic Hiring Audits of hiring systems have consistently found discrimination in outcomes based on race, gender, and age [Bertrand and Mullainathan, 2004, Kline et al., 2022]. Raghavan et al. [2020] study the screening stage of the hiring algorithms and connect legal perspectives with algorithmic approaches to mitigate the disparate impact. In terms of proposed solutions, [Lin et al., 2021] suggest \"augmentation-based\" interventions where AI-assisted decisions can best achieve equitable outcomes. A key assumption of prior work is access to (explicit or inferred) group membership. In our work, the hiring side has no knowledge of the group membership of candidates, yet we can mitigate bias nevertheless.\nStrategic Classification Hardt et al. [2016a] introduce strategic classification as a Stackelberg game to address the impact of manipulative tactics on classification problems. We draw on several later works that provided a modified strategic classification game that models disparities in manipulation abilities [Hu et al., 2019b, Milli et al., 2019, Chen et al., 2020, Diana et al., 2024]. Furthermore, we utilize techniques from [Braverman and Garg, 2020] to describe \"random\" classifiers in light of stochastic strategic manipulations. Similarly to several previous works [Ghalme et al., 2021, Cohen et al., 2024], we assume that the deployed classifier is unknown to the candidates.\nBehavior and Risks of Generative Models Guidance counselors and career coaches alike now recommend using generative AI tools to help with application materials [Verma and Renjarla, 2024, Chamorro-Premuzic, 2024]. However, recent research has highlighted a plethora of risks. For example, LLMs have been shown to hallucinate, which may mislead employers [Huang et al., 2023] or memorize text, which can result in unintended plagiarism [Carlini et al., 2023]. Since unintended plagiarism is difficult for job applicants to detect using these tools; the benefits of applying LLMs to application materials may be stochastic."}, {"title": "3 Empirical Motivation: Stochastic Resume Manipulation using LMMS", "content": "Since prior works in strategic classification focus on deterministic manipulations, we empirically motivate our theoretical model of stochastic LLM manipulations. We prompt a variety of models to improve technology sector resumes [Drushchak and Romanyshyn, 2024].1 We used a general prompt to simulate a job applicant who is aiming to apply to multiple jobs with the same enhanced resume (e.g., via recruitment agency). The resumes were then evaluated against the target job descriptions through open source software that scores resumes against a designated job description to produce a relevance score. This type of simple scoring model, as a first filter for resumes, is widespread with 98.4% of Fortune 500 companies using them within applicant tracking systems [Purcell, 2024]. We identified three key behaviors of LLM manipulations:\n1. LLM manipulations stochastically enhance resume scores (Figure2a),\n2. The effectiveness of LLM manipulations varies by model: newer, premium LLMs improve resume scores more (Figure 1),\n3. Improvements from manipulations stagnate with repetition: applying the same LLM repeatedly to the same resume results in diminishing changes (Figure 2b).\nFigure 1 illustrates that using a simple job-agnostic prompt with an input resume significantly improves the scores computed by a resume screening system. Qualitatively, we observed a drastic improvement in writing quality (examples available in Appendix B.4); the LLMs were able to transform resumes mostly containing bullet points about the candidate's interests or skills into more effective, reworded resumes delineating prior roles. However, scores did not improve monotonically across resumes; some resume scores decreased after applying LLM manipulation (Figure 2a).\nA second observation that motivates our study of disparities is the differential outcomes resulting from applying different LLMs to a candidate's resume. Figure 1 shows the post-manipulation resume scores on a broad set of models. Using the dotted lines as a reference for the median score of the original resumes of the qualified group, it is evident that applying different LLMs has different effects on the outcome relevance score. Distinguishing qualified and unqualified candidates is already a difficult task, but candidate manipulation makes it harder. Some models, particularly the higher cost-to-access models (e.g., CLAUDE-3.5-SONNET, GPT-40) improved the resume scores of the unqualified resumes so that they were indistinguishable or better than the qualified resumes without LLM manipulations, while cheaper or free-to-access models (e.g., GPT-3.5-TURBO, MIXTRAL-8X7B-INSTRUCT) did not significantly improve scores on average of the unmanipulated resumes regardless of qualification.2 By qualitatively inspecting the manipulated resumes, we found that LLMs yielding larger score improvements (e.g., CHATGPT-40) better adhered to the traditional elements of a resume while less effective models simply reorganized the input resume. For example, CHATGPT-40 also added additional elements such as a resume summary and dedicated sections for educational history. We also found that all of the newer, premium models (particularly CLAUDE-3.5-SONNET), increased the average similarity in embedding distance between resumes after manipulation (Figure 7).\nFinally, we also observed that repeated manipulations did not significantly alter resumes. The first round of modifications typically standardized language and formatting according to a conventional resume structure. However, a second round of manipulations did not deviate substantially from the first. This observation is also illustrated by the similarity of the resume score distributions of the once and twice-manipulated resumes (see Figure 2b).\nTogether, these three key observations regarding LLM manipulations - the potential for resume improvement, the differences in results among various LLM models, and stagnation in changes from multiple iterations motivate our proposed model of these strategic manipulations in Section 4."}, {"title": "4 Model", "content": "We represent each candidate as a triplet $(x, g, y)$, where $x \\in \\mathbb{R}^d$ represents the candidate's original (unmanipulated) resume features, $g \\in \\{P,U\\}$ denotes the group membership, with P indicating the privileged group and U indicating the unprivileged group, and $y \\in \\{0,1\\}$ represents the true label, with 0 indicating an unqualified candidate and 1 indicating a qualified candidate. It is important to note that we do not require that x fully determines y.\nOur model accommodates any combination of $d_1$ fundamental and $d_2$ style features in the feature space (i.e., $d = d_1 + d_2$). Fundamental features $(x_1,x_2,...,x_{d_1})$ refer to technical attributes such as programming skills, years of experience, or educational background, whereas style features $(c_1, c_2,..., c_{d_2})$ refer to attributes about a resume's presentation such as writing quality, vocabulary, and grammar.4 Overall, we express each candidate's resume features as an d-dimensional feature vector in $\\mathbb{R}^d$.\n$x = [x_1,x_2,...,x_{d_1}, c_1, c_2, ..., c_{d_2}].$\nWe model the candidate population as a joint distribution $\\mathcal{D}$ over feature vectors, group memberships, and true labels. We define the random variable triplet $(X, G, Y) \\sim \\mathcal{D}$ with $X \\in \\mathcal{X}$, $G \\in \\{P, U\\}$, and $Y \\in \\{0,1\\}$. Moreover, we assume that both groups have identical distributions over resume feature vectors, and that the true label is independent of group membership. In other words, we assume that X and G are independent and that Y and G are conditionally independent given X. For our model to be appropriate, each group comprises a non-negligible proportion of the population: that is, $\\mathbb{P}(G = P), \\mathbb{P}(G = U) > 0$.\n4.1 LLM Manipulation\nWe assume some candidates are manipulating using LLMs [Verma and Renjarla, 2024, Stahl, 2022]. In what follows, we now formalize our model for LLM manipulation of resumes.\nDefinition 4.1 (Mathematical formulation of Strategic LLM Manipulation). An LLM manipulation is a random function $\\mathcal{L} : \\mathcal{X} \\rightarrow \\mathcal{X}$ characterized by a series of (not necessarily independent) real-valued random variables $X_1, X_2,..., X_{d_1}$. When called upon a feature vector $x = [x_1,..., x_{d_1}, c_1,..., c_{d_2}]$,\n1. $\\mathcal{L}$ replaces each $x_i$ with a value drawn from $X_i$ for $1 \\leq i \\leq d_1$.\n2. $\\mathcal{L}$ preserves the value of $c_j$ for $1 \\leq j \\leq d_2$.\nIn other words,\n$\\mathcal{L}([x_1,..., x_{d_1}, c_1, ..., c_{d_2}]) = [X_1, ..., X_{d_1}, c_1, ..., c_{d_2}].$\nOur formulation of LLM manipulations is based on our observations that LLMs can standardize style features such as writing quality, vocabulary, and organization to the point that the original values are irrelevant and are redistributed according to a distribution dependently only on the LLM. On the other hand, candidates would like LLMs to preserve their fundamental features. Changes to their fundamental features may be extremely costly to the candidate, as hirers may decide to blacklist or dismiss dishonest candidates. The prompts for our experiments also work to elicit this outcome: to minimize the chances of hallucination, our prompt states explicitly that is \"imperative that the new resume do not add any facts that are not in the original resume\". We manually inspected some sampled outputs to confirm that generated outputs contained no hallucinations (though we have not inspected all the outputs). This perspective is informed by our empirical observations detailed in Section 3. Our experiments first indicated that LLM manipulations effectively overwrite writing style attributes. This is captured in our model, where the style features are redistributed according to a fixed random distribution.\nRemark 1. $\\mathcal{L}$ could represent a single use or multiple uses of an LLM to improve a resume.\n4.1.1 Hiring Schemes\nIn our hiring scheme, we define the Hirer who is making the hiring decisions and the Candidate who is applying for the job. Our work focuses on job positions receiving large volumes of applications: for this reason, we assume that the Hirer evaluates each candidate's resume by assigning each a real-valued score. More specifically, our model assumes that the Hirer uses some fixed scorer to evaluate the candidates resumes"}, {"title": "4.2 Traditional Hiring with LLM Manipulations", "content": "We now introduce our strategic LLM classification game for traditional hiring with Candidate LLM manipulation. A candidate can use the LLM available to their group $(\\mathcal{L}_g)$ to manipulate their resume the candidate then chooses which of these two resumes (original or manipulated) to submit to the Hirer.\nThe Hirer determines a threshold $\\tau \\in \\mathbb{R}$ and accepts candidates with scores equal to or larger than the threshold. Namely, the Hirer decision regarding a candidate with a submitted resume $x'$ is $f_\\tau(x') = \\mathbb{1}[s(x') \\geq \\tau]$. We assume that there are many candidates, so the cost of missing qualified individuals is less than the cost of interviewing or accepting unqualified candidates. Minimizing false positives is a natural objective in the context of hiring as hiring unqualified candidates (or inviting them for an interview) is costly. False positive has been studied in the context of fairness (e.g., Cohen et al. [2020], Blum et al. [2022]), and strategic classification (e.g., Ahmadi et al. [2022], Shao et al. [2023]). In this vein, we introduce the No False Positives Objective.\nDefinition 4.2 (No False Positives). The No False Positives Objective is achieved when the Hirer maximizes true positive rate (TPR) subject to no false positives. The optimization problem is:\n$\\begin{aligned} &\\text{maxmize}, \\quad & \\text{TPR}(\\tau) \\\\ &\\text{subject to} \\quad & \\text{FPR}(\\tau) = 0 \\end{aligned}$\nwhere\n$\\begin{aligned} &\\text{TPR}(\\tau) = \\mathbb{P}(f_\\tau(x') = 1 \\mid Y = 1) \\text{ and} \\\\ &\\text{FPR}(\\tau) = \\mathbb{P}(f_\\tau(x') = 1 \\mid Y = 0). \\end{aligned}$\nWe let $\\tau^*$ denote the minimum threshold in the solution set.\nOur work specifically focuses on classifiers that optimize true positive rates: this approach will specifically inform our further study of disparities between groups in Section 5. We aim to satisfy a specific case of Equalized Odds [Hardt et al., 2016b] when the false positive rate is fixed at zero, which is a special case of equal false positive rates across groups.\nDefinition 4.3 (TRADITIONAL Hiring Scheme under LLM Manipulation). The Hirer and the Candidate play the following Stackelberg game.\n1. The Hirer commits to a scorer s and a threshold $\\tau \\in \\mathbb{R}$, both unknown to candidates.\n2. Each candidate $(x, g, y)$ chooses to submit either their original resume $x' = x$ or their LLM-manipulated resume $x' = \\mathcal{L}_g(x)$.\n3. The Hirer accepts candidates according to the threshold classifier $f_\\tau(x') = \\mathbb{1}[s(x') \\geq \\tau]$.\nEach player has the following payoffs:\n1. The Candidate payoff is whether they are accepted: $\\mathbb{1}[f_\\tau(x') = 1]$.\n2. The Hirer's payoff is defined according to the No False Positives Objective (Definition 4.2).\nRemark 2. Unlike classic strategic classification, our game does not directly assume that the Candidate has perfect knowledge about $f$: after all, hiring schemes are often opaque. However, we assume that candidates know which of the two versions (unmanipulated and manipulated) of their resume will score higher. Additionally, since writing a prompt in an LLM is very easy, we assume it has negligible cost and that each candidate will use the more advanced LLM if they have access to it (i.e., a candidate from the privileged group will not use $\\mathcal{L}_U$). A best-responding candidate in group g will therefore submit\n$\\underset{z \\in \\{x, \\mathcal{L}_g(x)\\}}{\\text{argmax }} s(z).$\nIn our model, candidates do not incur costs for prompting their LLM for the manipulation or for selecting the better application. This is in contrast to prior work in strategic classification, where manipulations, such as getting multiple credit cards, require time and effort [Hardt et al., 2016a]. Our model does however separate $\\mathcal{L}_P$ and $\\mathcal{L}_U$: this is equivalent to how privileged groups in prior works are given larger budgets when costs are incurred [Milli et al., 2019].\nThe Hirer does not know and may not infer whether a resume has been manipulated or from which group a resume comes. Rather, the Hirer must use the same scoring scheme and threshold for all candidates."}, {"title": "5 Disparities in Traditional Hiring with Unequal Candidate LLM Manipulation", "content": "In this section, we show that, under a traditional hiring scheme, disparities in LLM qualities between candidate groups can lead to disparities in hiring outcomes. We begin by defining a useful metric for disparity in hiring outcomes. Since we assume that groups P and U have the same unmanipulated feature vector distribution, we define the resume outcome disparity as follows.\nDefinition 5.1. Given a resume feature vector $x \\in \\mathcal{X}$, the resume outcome disparity $\\Delta$ is defined as\n$\\Delta(x) = \\mathbb{P}_{\\mathcal{L}_P} (f_\\tau(x'_P) = 1) - \\mathbb{P}_{\\mathcal{L}_U} (f_\\tau(x'_U) = 1),$\nwhere $x'_g = \\underset{z \\in \\{x, \\mathcal{L}_g(x)\\}}{\\text{argmax }} s(z)$ for $g \\in \\{P, U\\}$.\nObserve that if the original unmanipulated resume is accepted (that is, $f_\\tau(x) = 1$), then $\\Delta(x) = 0$.\nTo address the differences in the output quality of different LLMs, we use the notion of multivariate stochastic dominance as provided by [Levhari et al., 1975].\nDefinition 5.2 ([Levhari et al., 1975]). Let $Z_1, Z_2$ be random variables over $\\mathcal{X}$. For any $a \\in \\mathcal{X}$, let $F_k(a) = \\mathbb{P}(Z_k \\leq a)$, where $\\leq$ denotes component-wise order. We say that $Z_1$ stochastically dominates $Z_2$ if for any open lower set $\\mathcal{S} \\subseteq \\mathcal{X}$,\n$\\int_{\\mathcal{S}} dF_1 \\geq \\int_{\\mathcal{S}} dF_2.$\nThis is a generalization of (first-order) univariate stochastic dominance to multivariate distributions. Intuitively, stochastic dominance requires that the generalized CDF of $Z_1$ must always be \"less\" than the generalized CDF of $Z_2$. Stochastic dominance induces a partial order over multivariate random variables. Furthermore, we use the following key property about stochastic dominance.\nLemma 5.1 ([Levhari et al., 1975]). $Z_1$ stochastically dominates $Z_2$ if and only if for every non-decreasing function u,\n$\\mathbb{E}[u(Z_1)] \\geq \\mathbb{E}[u(Z_2)].$\nWe use this definition to define our ordering over LLM quality.\nDefinition 5.3. Let $\\mathcal{L}_1, \\mathcal{L}_2$ be LLM manipulations. We say that $\\mathcal{L}_1$ dominates $\\mathcal{L}_2$ $(\\mathcal{L}_1 > \\mathcal{L}_2)$ if for all $x \\in \\mathcal{X}$, $\\mathcal{L}_1(x)$ stochastically dominates $\\mathcal{L}_2(x)$.\nInformally, an LLM $\\mathcal{L}_1$ may be considered \"better\" than $\\mathcal{L}_2$ if it stochastically dominates $\\mathcal{L}_2$ on each input, indicating that $\\mathcal{L}_1$ has a greater likelihood of feature improvement than $\\mathcal{L}_2$. Note that this only implies that $\\mathcal{L}_1$ tends to produce a better output than $\\mathcal{L}_2$; $\\mathcal{L}_2$ may produce a better output than $\\mathcal{L}_1$ on certain realizations of their stochastic outputs.\nRemark 3. To simulate the absence of access to an LLM in our strategic classification game, it is helpful to artificially define a \u201cnull LLM\u201d $(\\mathcal{L}_\\emptyset)$ that is dominated by all other LLMs. We might informally conceptualize $\\mathcal{L}_\\emptyset$ as having random variables $X_i = -\\infty$ for $1 < i < d_1$. This allows us to conceptualize traditional hiring as a special case of TWO-TICKET hiring in which the Hirer deploys the null LLM which does not provide an additional \"ticket\" for the candidate.\nWe now show that, under this definition, using a better LLM on the same resume leads to a better hiring outcome.\nTheorem 1. Suppose $\\mathcal{L}_P > \\mathcal{L}_U$. Then for all $x \\in \\mathcal{X}, \\Delta(x) \\geq 0$.\nSince $\\mathbb{P}_{\\mathcal{L}_g} (f_\\tau(x') = 1) = \\mathbb{E}_{\\mathcal{L}_g}[f_\\tau(x')]$ and $f_\\tau$ is non-decreasing, we can apply Lemma 5.1 to show that $\\mathbb{P}_{\\mathcal{L}_P}(f_\\tau(x'_P) = 1) \\geq \\mathbb{P}_{\\mathcal{L}_U} (f_\\tau(x'_U) = 1)$.\nThis disparity in resume outcomes naturally leads to disparity in group outcomes. Under the No False Positives Objective, it is natural to measure group outcomes by comparing groups' true positive rates. We denote the TPR over a group g as\n$\\text{TPR}_g = \\mathbb{P} (f_\\tau(x') = 1 \\mid Y = 1, G = g) .$\nTo address fairness, we define the disparity between the TPRs of two groups. This fairness notion has been studied previously in the context of strategic classification (e.g., [Keswani and Celis, 2023]).\nDefinition 5.4. The TPR disparity \u0394TPR is defined as\n$\\Delta\\text{TPR} = \\text{TPR}_P - \\text{TPR}_U.$\nHaving defined the TPR disparity, we show that qualified candidates from the privileged group have a higher (or equal) probability of being accepted compared to qualified candidates from the unprivileged group.\nCorollary 1. Suppose $\\mathcal{L}_P \\geq \\mathcal{L}_U$. Then,\n$\\Delta\\text{TPR} \\geq 0.$\n(Proof Sketch). This follows from applying Theorem 1 over candidates with Y = 1."}, {"title": "6 Combating LLM Disparities: Two-Ticket Scheme", "content": "To counteract the disparity in hiring outcomes due to unequal LLM access, we propose a modified hiring scheme where the Hirer performs their own round of LLM manipulation over the possibly manipulated applications. Our motivating experiments (Section 3) show that running a resume through a high-quality LLM twice changes the resume much less on the second run than on the first. We show that bestowing both groups with the benefit of a round of high-quality LLM manipulation can help level the playing field.\n6.1 Two-Ticket Scheme\nWe present the modified strategic classification game under the Two-TICKET scheme. This scheme is identical to TRADITIONAL hiring except that the Hirer now uses their own LLM $(\\mathcal{L}_H)$ to manipulate each submitted resume. The Hirer then scores the best of these two versions to determine whether to accept each candidate.\nDefinition 6.1 (TWO-TICKET Hiring Scheme under LLM Manipulation).\n1. The Hirer commits to a scorer s and a threshold $\\tau \\in \\mathbb{R}$, both unknown to candidates and some LLM $\\mathcal{L}_H$.\n2. Each candidate $(x,g, y)$ chooses to submit either their original resume $x' = x$ or their LLM manipulated resume $x' = \\mathcal{L}_g(x)$.\n3. The Hirer chooses to consider the higher scoring resume among the submitted resume $x'' = x'$ and the LLM-manipulated submission $x'' = \\mathcal{L}_H(x')$.\n4. The Hirer accepts candidates according to the threshold classifier $f_\\tau(x'') = \\mathbb{1}[s(x'') \\geq \\tau]$.\nEach player then has the following payoffs:\n1. The candidate payoff is the probability that they are accepted: $\\mathbb{P}_{\\mathcal{L}_H} (f_\\tau(x'') = 1)$.\n2. The Hirer's payoff is defined according to the No False Positives Objective (Definition 4.2).\nIn practice, the Hirer scores both the submitted resume and the Hirer LLM-manipulated resume, and accepts the candidate if one of the scores passes the threshold. This is where our name \"Two-Ticket Hiring\" comes from: each candidate is essentially given two avenues to acceptance.5 This is equivalent to the above definition: our chosen presentation emphasizes the symmetry of the Hirer's LLM manipulation and the Candidate's LLM manipulation.\nWhile LLM manipulations generally improve resume quality, there is a chance that they can decrease a candidate's score (Section 3). To ensure that candidates are not unfairly harmed by LLM manipulations, we safeguard against this possibility by requiring the Hirer to evaluate the maximum of the candidate's submitted and its Hirer-manipulated version of each resume.\nThe TRADITIONAL hiring game (Definition 4.3) can be considered a special case of the TWO-TICKET hiring game (Definition 6.1), where $\\mathcal{L}_H$ is the null LLM discussed in Remark 3. Thus, we compare the behavior of two different TWO-TICKET games: the game under TRADITIONAL hiring (Definition 4.3) and the game under TWO-TICKET hiring schemes (Definition 6.1), which differ only in the Hirer's choice of LLM and threshold in our formalization.\n6.2 Guaranteed Two-Ticket Improvements\nWe now prove that under natural conditions, a Two-TICKET hiring scheme can decrease the resume outcome disparity between the two groups, leading to improvement in accuracy and fairness.\nFor $k \\in \\{1,2\\}$, we define Hiring Scheme k to be the TWO-TICKET scheme using Hirer LLM $(\\mathcal{L}_H^{(k)})$ and scheme-dependent threshold $\\tau^{*(k)}$, resulting in deployed classifier $f_\\tau^{(k)}$. Let $\\Delta^{(k)}(x)$ and $\\Delta\\text{TPR}$ denote the resume and group outcome disparity respectively for Hiring Scheme k. To compare the TRADITIONAL hiring scheme with the TWO-TICKET hiring scheme, we denote the TRADITIONAL hiring scheme as k = 1 with $\\mathcal{L}_H^{(1)} = \\mathcal{L}_\\emptyset$. With this definition, we are guaranteed that $\\mathcal{L}_H^{(2)} = \\mathcal{L}_H)$. Note, however, that the following results still apply if Hiring Scheme 1 is a TWO-TICKET hiring scheme with a non-null Hirer LLM.\nOur results apply when the same threshold can be used to achieve the No False Positives Objective across both schemes. We show that when the Hirer chooses LLMs that are stochastically dominated by the privileged group LLM, it is sufficient (though not necessary) to guarantee that the optimal threshold does not change.\nLemma 6.1. If $\\mathcal{L}_P > \\mathcal{L}_H^{(1)}, \\mathcal{L}_H^{(2)}$, then $\\tau^{*(1)} = \\tau^{*(2)}$.\nBefore introducing our main results on outcome disparity, we reformulate the probability of acceptance under the TWO-TICKET hiring scheme.\nLemma 6.2. For Hirer LLM $\\mathcal{L}_H$ and threshold $\\tau$, the probability that a candidate $(x, g, y)$ is accepted is\n$\\mathbb{P}_{\\mathcal{L}_g,\\mathcal{L}_H} (f_\\tau(x'') = 0) = 1 - \\mathbb{1} [s(x) < \\tau] \\cdot \\mathbb{P}_{\\mathcal{L}_g} (s(\\mathcal{L}_g(x)) <\\tau) \\mathbb{P}_{\\mathcal{L}_H} (s(\\mathcal{L}_H(x)) <\\tau)$.\nThis follows from Definition 6.1, using that $\\mathcal{L}_H(x')$ and $x''$ are conditionally independent given x.\nUsing Lemma 6.2, we derive our main result showing the improvement in resume outcome disparity by shifting from a TRADITIONAL to a TWO-TICKET scheme.\nTheorem 2. Let $\\tau^{*(1)} = \\tau^{*(2)}, \\mathcal{L}_P > \\mathcal{L}_U, and \\mathcal{L}_H^{(2)} > \\mathcal{L}_H^{(1)}$. Then for all $x \\in \\mathcal{X}, \\Delta^{(2)}(x) \\leq \\Delta^{(1)}(x)$.\nRemark 4. Lemma 6.1 provides a simple and sufficient but not necessary condition that $\\tau^{*(1)} = \\tau^{*(2)}$ under the No False Positives Objective. In fact, Theorem 2 applies under any Hirer objective so long as the optimal deployed threshold is the same for Hiring Scheme 1 and 2.\nUnder the No False Positives Objective, the decrease in resume outcome disparity immediately implies a decrease in group outcome disparity and an increase in accuracy (or equivalently, true positive rate under the No False Positives Objective) for both groups.\nCorollary 2. Let TPR(k) denote the true positive rate over group g under Hiring Scheme k. Let $\\tau^{*(1)} = \\tau^{*(2)}, \\mathcal{L}_P \\geq \\mathcal{L}_U, and \\mathcal{L}_H^{(2)} > \\mathcal{L}_H^{(1)}$, then:\n1. $\\Delta_{TPR}^{(2)} \\leq \\Delta_{TPR}^{(1)}$.\n2. $\\text{TPR}_g^{(2)} > \\text{TPR}_g^{(1)}$ for $g \\in \\{P, U\\}$.\n3. $\\text{TPR}^{(2)} > \\text{TPR}^{(1)}$.\nSince the threshold $\\tau^*$ already prevents false positives (Definition 4.2), (3) also implies that accuracy does not decrease.\n6.3 The n-Ticket Scheme and Group Dependence Bias Mitigation\nWhile the two-ticket scheme helps mitigate disparities, it may not be sufficient since the privileged group has the advantage of a \"better\" first ticket. Since we consider stochastic manipulations, the first ticket still increases acceptance probability. We therefore propose generalizing the idea to an n-Ticket Hiring Scheme. Let $\\mathcal{L}_H^n$ be the application of the two-ticket scheme n \u2208 N times using LLM $\\mathcal{L}_H$ (the n-ticket scheme).\nThat is, for any x \u2208 X, Clause 3 in Definition 6.1 is repeated n times, each time after the first with x'' as the submitted resume. We will show that by applying the n-ticket scheme, the outcome becomes independent of group membership.\nWe start by defining a contraction operator and stating Banach's Fixed Point Theorem, which will be useful in the proof of the main theorem in this section."}, {"title": "6.4 Guaranteed Two-Ticket"}]}