{"title": "When More is Less: Understanding Chain-of-Thought Length in LLMs", "authors": ["Yuyang Wu", "Yifei Wang", "Tianqi Du", "Stefanie Jegelka", "Yisen Wang"], "abstract": "Chain-of-thought (CoT) reasoning enhances the multi-step reasoning capabilities of large language models (LLMs) by breaking complex tasks into smaller, manageable sub-tasks. Researchers have been exploring ways to guide models to generate more complex CoT processes to improve the reasoning ability of LLMs, such as long CoT and the test-time scaling law. However, for most models and tasks, does an increase in CoT length consistently lead to improved reasoning accuracy? In this paper, we observe a nuanced relationship: as the number of reasoning steps increases, performance initially improves but eventually decreases. To understand this phenomenon, we provide a piece of evidence that longer reasoning processes are increasingly susceptible to noise. We theoretically prove the existence of an optimal CoT length and derive a scaling law for this optimal length based on model capability and task difficulty. Inspired by our theory, we conduct experiments on both synthetic and real world datasets and propose Length-filtered Vote to alleviate the effects of excessively long or short CoTs. Our findings highlight the critical need to calibrate CoT length to align with model capabilities and task demands, offering a principled framework for optimizing multi-step reasoning in LLMs.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) have demonstrated impressive capabilities in solving complex reasoning tasks [Brown et al., 2020, Touvron et al., 2023]. One approach to enhance their performance on such tasks is Chain of Thought (CoT) reasoning [Wei et al., 2022], where the model generates explicit intermediate reasoning steps before arriving at the final answer. The CoT process can be seen as a divide-and-conquer strategy [Zhang et al., 2024], where the model breaks a complex problem into simpler sub-problems, solves each one individually, and then combines the results to reach a final conclusion. It is commonly believed that longer CoT generally improves the performance, especially on more difficult tasks [Fu et al., 2023, Jin et al., 2024]. On the other hand, a concise CoT [Nayab et al., 2024] has been shown to incur a decreased performance penalty on math problems. But does performance consistently improve as the length of the CoT increases?\nIn this paper, we conduct comprehensive and rigorous experiments on synthetic arithmetic datasets and find that for CoT length, longer is not always better (Figure 1). Specifically, by controlling task difficulty, we observe that as the reasoning path lengthens, the model's performance initially improves but eventually deteriorates, indicating the existence of an optimal length. This phenomenon can be understood by modeling the CoT process as a task decomposition and subtask-solving structure. While early-stage decomposition helps break down the problem, excessively long reasoning paths lead to error accumulation-where a single mistake can mislead the entire chain of thought."}, {"title": "2 Related Work", "content": "Chain of Thought Large Language Models (LLMs) [Brown et al., 2020] have demonstrated remarkable abilities in complex reasoning tasks by breaking down challenging problems into intermediate steps before arriving at the final answer [Wei et al., 2022]. Numerous researchers have proposed various approaches to enhance the CoT reasoning capabilities of LLMs. Least-to-most prompting [Zhou et al., 2023] decomposes a complex problem into a series of simpler sub-problems, solving them sequentially, where the solution to each subproblem builds upon the answers to previously solved sub-problems. Tree of thoughts [Yao et al., 2023] enables LLMs to engage in deliberate decision-making by exploring multiple reasoning paths, self-evaluating options, and dynamically adjusting the reasoning process through backtracking or look-ahead strategies to make globally optimal choices. Similarly, Divide-and-Conquer methods [Zhang et al., 2024, Meng et al., 2024] divide the input sequence into multiple sub-inputs, which can significantly improve LLM performance in specific tasks. Despite their differences, these methods share a common characteristic: they all treat the CoT process as a framework for decomposition and subtask-solving. Similarly, our study adopts this perspective.\nCoT Understanding In addition to the methods mentioned above, many works aim to formalize the CoT process and explore why it is effective. Circuit complexity theory has been used to analyze the computational complexity of problems that transformers can solve with and without CoT, providing a theoretical understanding of CoT's effectiveness [Feng et al., 2023, Li et al., 2024b]. Cui et al. [2024] theoretically demonstrate that, compared to Stepwise ICL, integrating reasoning from earlier steps (Coherent CoT) enhances transformers' error correction capabilities and prediction accuracy. Ton et al. [2024] quantify the information gain at each reasoning step in an information-theoretic perspective to understand the CoT process. Furthermore, Li et al. [2024a] show that fast thinking without CoT results in larger gradients and greater gradient differences across layers compared to slow thinking with detailed CoT, highlighting the improved learning stability provided by the latter. Ye et al. [2024] investigate CoT in a controlled setting by training GPT-2 models on a synthetic GSM dataset, revealing hidden mechanisms through which language models solve mathematical problems. Unlike these theoretical studies, our work focuses on the impact of different lengths of CoT on final performance and tries to understand CoT from task decomposition and error accumulation perspective.\nOverthinking With the remarkable success of OpenAI's ol model, test-time computation scaling has become increasingly important. More and more works [Snell et al., 2024, Chen et al., 2024d, Wu et al., 2024, Brown et al., 2024] have explored the scaling laws during inference using various methods, such as greedy search, majority voting, best-of-n, and their combinations. They concluded that with a compute-optimal strategy, a smaller base model can achieve non-trivial success rates, and test-time compute can outperform larger models. This highlights the importance of designing optimal inference strategies.\nHowever, Chen et al. [2024a] hold a contrastive opinion that in some cases, the performance of the Best-of-N method may decline as N increases. Similarly, the overthinking phenomenon [Chen et al., 2024c] becomes more and more important as ol-like reasoning models allocate excessive computational resources to simple problems (e.g., 2 + 3 = 5) with minimal gains. These findings indicate the need to balance computation based on model capabilities and task difficulty. In our study, we focus on different types of CoT reasoning, categorized by CoT length. Moreover, we theoretically identify a balanced CoT strategy that adapts to model size and task difficulty, optimizing performance under these constraints."}, {"title": "3 Influence of Chain-of-Thought Length on Arithmetic Tasks", "content": "To begin, we aim to empirically investigate the relationship between reasoning performance and CoT length. Therefore, we need to control a given model to generate reasoning chains of varying lengths for a specific task. Unfortunately, no existing real-world dataset or model fully meets these strict requirements. Real-world reasoning tasks, such as GSM8K or MATH [Cobbe et al., 2021, Hendrycks et al., 2021], do not provide multiple solution paths of different lengths, and manually constructing such variations is challenging. Moreover, it is difficult to enforce a real-world model to generate a diverse range of reasoning paths for a given question.\nGiven these limitations, we begin our study with experiments on synthetic datasets. Notably, even when working with real-world datasets, we observe behavioral patterns that align well with the findings derived from synthetic data (Section 5.1)."}, {"title": "3.1 Problem Formulation", "content": "To investigate the effect of CoT length in a controlled manner, we design a synthetic dataset of simplified arithmetic tasks with varying numbers of reasoning steps in the CoT solutions. The necessity and rationale for simplified arithmetic tasks will be further discussed in the Appendix B.\nDefinition 3.1 (Problem). In a simplified setting, an arithmetic task q is defined as a binary tree of depth T. The root and all non-leaf nodes are labeled with the + operator, while each leaf node contains a numerical value (mod 10). In addition, we impose a constraint that every non-leaf node must have at least one numerical leaf as a child.\nThe bidirectional conversion method between arithmetic expressions and computation trees is as follows: keeping the left-to-right order of numbers unchanged, the computation order of each \u201c+\u201d or tree node is represented by tree structure or bracket structures. For example, consider the task 5 + (4 + ((2+1) +3)) with T = 4. The corresponding computation tree is defined as Figure 2.\nTo ensure that CoT solutions of the same length have equal difficulty for a specific problem, we assume that each reasoning step performs the same operations within a single CoT process. A more rigorous discussion will be conducted in Appendix B.2.\nDefinition 3.2 (Solution). We define a t-hop CoT with a fixed each step length of t as a process that executes t operations starting from the deepest level and moving upward recursively.\nAccording to this definition, the execution sequence is uniquely determined. For example, one way to solve expression in Figure 2 is by performing one addition at a time:\n5 + (4 + ((2 + 1) + 3)) = <1> (1)\n2+1=3 (2)\n3+3=6\n4+6=0\n5+0=5<END>."}, {"title": "3.2 Experiment Setup", "content": "Another approach is to perform two additions at a time:\n5 + (4 + ((2+1) + 3)) = <2> (3)\n(2+1) + 3 = 6\n5+ (4+6) = 5<END>.\nThe latter approach is half as long as the former, but each reasoning step is more complex\u00b9. This illustrates a clear trade-off between the difficulty of each subtask and the total number of reasoning steps.\nIn practice, when t does not evenly divide T, the final step performs T modt operations. To guide the model in generating the desired CoT length, we insert the control token <t> after the question and before the beginning of the solution. To preserve the parentheses that indicate the order of operations, we construct expressions in Polish notation. However, for readability, we present each problem in its conventional form throughout the article."}, {"title": "3.3 Experimental Results", "content": "U-curve For convenience, we present how the final accuracy changes as the number of operators performed per step t increases, which corresponds to a decrease in the number of reasoning steps, for tasks of varying difficulty (total operators). Figures 1a and 1b show the performance of small and large models on easy tasks (16, 24, 32 operators) and hard tasks (48, 56, 64 operators) respectively.\nThe results (Figure 1) align well with our theory, demonstrating that as the number of reasoning steps increases, the final performance initially improves and then declines. Subsequent experiments will explore how the optimal CoT length changes with model capability and task difficulty.\nEnvelope Curve Figure 3a and 3b illustrate the envelope curve, where different colors represent the optimal single-step length. The results indicate that as the task becomes more challenging, CoT with a larger single-step reasoning length t achieves the best performance. This can be interpreted as a mechanism to regulate the total number of CoT steps\u2014shorter single-step lengths require more CoT steps to complete the task.\nOptimal CoT length shifts To further investigate how the optimal CoT length changes with model capability and task difficulty, we trained models of varying sizes (ranging from 5 to 9 layers) on tasks of different difficulties (from 16 to 64 operators). For each combination of model size and task difficulty, we recorded the optimal number of reasoning steps.\nFigure 4 illustrates two key findings. First, an increase in the number of reasoning steps is beneficial for solving more challenging problems, indicating that harder tasks require more steps to achieve optimal performance. Second, the optimal number of reasoning steps decreases as the model size increases, suggesting that stronger models can handle more complex reasoning within fewer steps."}, {"title": "4 Theoretical Analysis", "content": "In this section, we provide a theoretical analysis of the CoT process for the simplified arithmetic tasks defined above and explain the empirical results observed in synthetic datasets. All proofs of the paper are deferred to Appendix F."}, {"title": "4.1 Setup", "content": "Let $N \\in \\mathbb{N}^+$ represent the total number of steps in the CoT process. As defined earlier, T denotes the total number of operators in the given question, and $\\frac{T}{t}$ represents the number of operators processed in each reasoning step. We use $t_i$ to denote the subtask in the i-th reasoning step (e.g., 2 + 1 in Eq. (2)), and $a_i$ to represent the corresponding answer (e.g., 3 in Eq. (2)).\nDefinition 4.1. Given task q with total operators T (Definition 3.1) and model $\\theta$, to a specific N, we define an N step (t-hop in Definition 3.2) CoT process as\n$P(a_N|q, \\theta) = \\prod_{i=1}^{N} P(t_i|H_{i-1}, q, \\theta)P(a_i|t_i, H_{i-1}, q, \\theta)$,"}, {"title": "4.2 A Simple Case with Linear Error", "content": "An estimation of $\\sigma(T)$. To simplify the setting, we assume $\\sigma(T) = \\frac{T}{C}$, where C is a hyperparameter representing the maximum number of operators the model can handle, which is solely influenced by the training data. To ensure that the model is capable of generating a reasonable subtask (even if it is incorrect), we consider a finite range $T\\in [0, 0.9C]$, ensuring that the subtask accuracy rate $1 - \\sigma(T)$ remains within [0.1, 1].\nAn estimation of $E(N, M,T)$. We define the model answer's error rate $E(N, M,T) = \\frac{T}{NM}$ as the ratio between the number of subtask operators and the model's capacity M (Eq. (4)) that the maximum number of operators the model can compute in a single step. Therefore, $1 - \\frac{T}{NM} > 0$.\nAccording to Proposition 4.2, a simplified total accuracy of N-step reasoning is\n$A(N) = \\alpha \\left((1-\\frac{T}{NM})(1-\\frac{T}{C})\\right)^N$  (6)"}, {"title": "4.3 Extension to General Error Functions", "content": "In the simple case above, we discussed the trend of overall accuracy with respect to N and the variation of optimal N with M and T, assuming the subtask error rate is a linear function. In the following discussion, we aim to derive conclusions corresponding to more general error rate functions. We find that as long as the error function satisfies some basic assumptions, the above conclusions still hold. A detailed discussion of basic assumptions will be conducted in Appendix E.\nTheorem 4.7. For any noise function $0 < \\sigma(T) < 1$ and a subtask error rate function $0 < E(N, M,T) < 1$ satisfying Assumption E.1 and E.2, a general final accuracy function A(N) (Proposition 4.2) has the following properties:\n$\\bullet$ $\\lim_{x\\rightarrow+\\infty} A(N) \\rightarrow 0$\n$\\bullet$ If A(N) has the point of maximum value $N^* > 1$, then $N^*$ has a lower bound\n$N^* \\geq N(M,T) = E^{-1} \\left(1 - \\frac{1}{e^2(1 - \\sigma(T))}\\right)$ (8)"}, {"title": "5 Empirical Examination of Optimal CoT Length", "content": "Following the theoretical analyses of optimal CoT length in Section 4, we further validate these insights on both real-world LLM behaviors at test time and its influence on CoT training."}, {"title": "5.1 Optimal CoT Length of LLMs on MATH", "content": "To validate our theory on real-world tasks with LLMs, we consider the MATH [Hendrycks et al., 2021] algebra dataset (Level 5), which includes challenging competition-level mathematics problems requiring multi-step reasoning. We select Qwen2.5 series Instruct models [Qwen et al., 2025] to investigate behaviors among models with different capabilities. More details can be found in Appendix A.1.\nOptimal Length and Model Capability In this section, we randomly select 30 questions from the dataset, generating 60 samples for each question, resulting in a total of 1,800 samples for each model. The results, shown in Figure 5a, demonstrate that for each model, the longest number of steps is not the best one. Additionally, the optimal CoT length decreases as the model size increases, from 14 steps for the 1.5B model to 4 steps for the 72B model (Figure 5b). This trend aligns with our theory that larger models perform better with fewer reasoning steps, as they are more capable of effectively handling single-step reasoning.\nImpact of Task Difficulty In this part, we evaluate how the optimal CoT length changes with task difficulty. To achieve this, we randomly select 100 questions from the dataset, generating 60 samples for each question to ensure the number of reasoning steps is calculated accurately. We assume that a question with lower accuracy among the 60 samples is more difficult for the model, using 1-accuracy as a proxy for the relative difficulty of each question(the larger the harder).\nWe then plot a scatter plot of accuracy versus optimal CoT length and calculate the correlation. As shown in Figure 5c, a significant correlation (p = 1e - 8 << 0.05) between task difficulty and optimal CoT length. Results on different models are shown in Appendix A.2. This finding supports our theory that harder tasks require more steps to solve effectively."}, {"title": "5.2 Implications for Training with CoT Data", "content": "In the previous synthetic dataset experiments (Section 3), we generated solutions with varying step lengths by training our model on data sampled with random CoT lengths. Now that we have identified the optimal CoT length, an important question arises:"}, {"title": "6 Length-filtered Vote", "content": "Section 5.2 highlights the importance of aligning the CoT length with the model's capabilities and the task's difficulty. However, achieving this alignment requires an accurate estimation of both the task and the model. Moreover, given a pretrained model, how can we leverage the optimal CoT length without any prior estimation of the task or even the model itself?\nIn this section, we propose a length-aware variant of majority vote, Length-filtered vote, where we use prediction uncertainty as a proxy to filter reliable CoT lengths. As in majority vote, given a model $f_{\\theta}$, a question q, a ground truth answer a*, we first sample a set of answer candidates independently $c_1,..., c_n \\stackrel{i.i.d.}{\\sim} f_{\\theta}(q)$. After that, instead of direct vote, we group the answers based on their corresponding CoT length l(ci) (discussed in Appendix A.1) into groups with equal bandwidth D (by default, we set D = 2), denoted as $\\{L_j\\}_{j=1}^M$. As our theory suggests that the prediction accuracy of CoT paths is peaked around a certain range of CoT length, we identify such groups through the prediction uncertainty of the answers within each group, based on the intuition that lower uncertainty implies better predictions. Specifically we calculate the Shannon entropy of the final answers given by the CoT chains in each group Li, denoted as H(Li). We then select K (by default, we set K = 3)"}, {"title": "7 Conclusion", "content": "In this paper, we conduct experiments on a simplified synthetic dataset, drawing clear conclusions on how the CoT length affects the final performance. Our study also provides valuable insights, showing that the optimal CoT length should adapt to both model size and task difficulty. Furthermore, we present a rigorous theoretical framework demonstrating the non-monotonic scaling behavior of CoT length and how it is influenced by model size and task difficulty. Additionally, we conduct experiments"}]}