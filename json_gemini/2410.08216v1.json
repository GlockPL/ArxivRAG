{"title": "New technologies and AI: envisioning future directions for UNSCR 1540", "authors": ["Clara Punzi"], "abstract": "Amidst a time characterized by unprecedented technological progress, the integration of Artificial Intelligence (AI) in the military domain has emerged as a powerful factor capable of reshaping several facets of global security and altering the dynamics of geopolitics and warfare. Indeed, AI has the potential to protect lives and prevent various threats, such as physical and cybersecurity attacks. However, it may also be utilized to enhance the destructive capabilities of systems, as exemplified by kamikaze drones and killer robots. When the United Nations Security Council (UNSC) first adopted Resolution 1540 (hereinafter UNSCR 1540) in 2004, the aim was to create a pivotal framework to address and diminish the threat presented by the proliferation of weapons of mass destruction (WMDs), specifically nuclear, chemical, and biological weapons, along with their means of delivery. At that time, the threat posed by a possible interaction with Al was not contemplated. Nevertheless, the growing capability and ubiquity of AI have brought a new level of complexity to the implementation and outcomes of this resolution, resulting in the acknowledgment, in subsequent resolutions, of potential adverse effects posed by the use of Al in the context of implementation of UNSCR 1540. Recently, these concerns have been further highlighted by the UNSCR during the first debate on AI, peace and security, where the United Nations Secretary-General expressed deep alarm regarding the interaction between AI and nuclear weapons, biotechnology, neurotechnology, and robotics. Despite this emergent awareness, there is at the moment a lack of international, multilateral agreements or any existing governance framework that covers the use of AI in the military, as also highlighted during the first conference on Responsible AI in the Military Domain. This work delves into the concerns surrounding the intersection of AI and UNSCR 1540, exploring the potential risks and ethical considerations that characterize the evolving landscape of global security. We critically examine the implications of AI on the goals and efficacy of UNSCR 1540 in safeguarding the world from the threats posed by WMDs proliferation. More precisely, we argue that AI can both amplify pre-existing risks associated with WMDs and also generate novel hazards. In both cases, the use of AI would create or exacerbate existing threats to international peace and security. As a result, we contend that", "sections": [{"title": "Introduction", "content": "Amidst a time characterized by unprecedented technological progress, the integration of Artificial Intelligence (AI) in the military domain has emerged as a powerful factor capable of reshaping several facets of global security and altering the dynamics of geopolitics and warfare\u00b9. Indeed, AI has the potential to protect lives and prevent various threats, such as physical and cybersecurity attacks. However, it may also be utilized to enhance the destructive capabilities of systems, as exemplified by kamikaze drones\u00b2 and killer robots\u00b3. When the United Nations Security Council (UNSC) first adopted Resolution 1540 (hereinafter UNSCR 1540) in 2004, the aim was to create a pivotal framework to address and diminish the threat presented by the proliferation of weapons of mass destruction (WMDs), specifically nuclear, chemical, and biological weapons, along with their means of delivery. At that time, the threat posed by a possible interaction with Al was not contemplated. Nevertheless, the growing capability and ubiquity of AI have brought a new level of complexity to the implementation and outcomes of this resolution, resulting in the acknowledgment, in subsequent resolutions, of potential adverse effects posed by the use of Al in the context of implementation of UNSCR 1540. Recently, these concerns have been further highlighted by the UNSCR during the first debate on AI, peace and security, where the United Nations Secretary-General expressed deep alarm regarding the interaction between AI and nuclear weapons, biotechnology, neurotechnology, and robotics. Despite this emergent awareness, there is at the moment a lack of international, multilateral agreements or any existing governance framework that covers the use of AI in the military, as also highlighted during the first conference on Responsible AI in the Military Domain. This work delves into the concerns surrounding the intersection of AI and UNSCR 1540, exploring the potential risks and ethical considerations that characterize the evolving landscape of global security. We critically examine the implications of AI on the goals and efficacy of UNSCR 1540 in safeguarding the world from the threats posed by WMDs proliferation. More precisely, we argue that AI can both amplify pre-existing risks associated with WMDs and also generate novel hazards. In both cases, the use of AI would create or exacerbate existing threats to international peace and security. As a result, we contend that"}, {"title": "AI technologies within 1540 resolution", "content": "Prior to analyzing the various ways in which AI relates to the scope of UNSCR 1540, it is essential to assess how UNSCR 1540 and subsequent resolutions embrace the role of new technologies, especially AI. By doing so, in the next sections, we will be able to identify the current gaps in this legal framework.\nAs mentioned in the Introduction, a first relevant observation is that AI systems can be regarded as \"means of delivery\" according to UNSCR 1540 if they are autonomous and have been designed for the scope of delivering WMDs. If this is the case, then all provisions of UNSCR 1540 and following resolutions apply. Successively, the UNSC also affirms to be gravely concerned by the risk of state and non-States actors using the rapid advances in science and technology to ends related to the proliferation of WMDs. Furthermore, UNSCR 1540 and subsequent resolutions emphasize that the progress of innovative technology for peaceful purposes should not be hindered, but the pursuit of peaceful applications should not be exploited as a disguise for the spread of WMDs.\nThis last observation raises concerns about dual-use AI technologies, that is, AI applications that can be employed for positive, constructive purposes as well as for activities that may pose risks or have negative consequences on human lives. Such a duality arises from the fact that the impact of AI technologies often depends on how they are deployed and for what purpose. For example, generative Al models are considered dual-use: while positive applications exist, such as content creation, translation services, and creative projects, they can also be misused for generating deceptive content, deepfakes, or spreading misinformation. Similarly, AI applications in fields like cybersecurity, autonomous vehicles, and healthcare may have dual-use characteristics: while these technologies can enhance security10, transportation efficiency, and medical diagnostics, potential malicious uses, such as cyber attacks, weaponization of autonomous systems, or privacy violations, are also possible. The dual-use nature of many AI technologies highlights the significance of ethical considerations, responsible development, and appropriate legislation to guide and regulate their design, implementation, and deployment. This is crucial in order to maximize the potential advantages while minimizing the associated risks and negative consequences. Interestingly, dual-use technologies seem to be excluded from UNSCR 1540, since all provisions refer to applications with the specific, hence not dual, purpose of enhancing the proliferation of WMDs. This constitutes an important gap in the regulatory framework."}, {"title": "AI technologies as means of delivery of WMDS", "content": "In the perspective of limiting the harms provoked by the use of WMDs, AI technologies could be employed to improve targeting accuracy, reduce unintended damage, and accelerate decision-making processes. At the same time, such AI-controlled WMDs could result in greater lethality and destruction. Indeed, it is widely acknowledged in the AI community that the use of AI in critical domains poses significant risks due to the potential for costly mistakes, which may happen as a result of prediction errors or unintended discriminations that may arise from hidden flaws in the machine learning process. The military domain here under analysis is not exempt from such risks\u00b92. For instance, if a state or non-state actor has the capability to gather data, such as biometric data, about a subordinate population through a digital surveillance system\u00b9\u00b3, they could potentially use this information to launch a military attack against the entire population without differentiating between military and civilian targets. This could lead to catastrophic consequences, not only from a humanitarian and ethical standpoint but also in terms of international law.\nThe detrimental impacts of AI applications as means of delivery of WMDs become particularly dangerous in the case of autonomous decision-making systems. In other words, when the algorithm is granted the power to select and attack certain targets with WMDs. In this scenario, the absence of human control highlights and exacerbates several concerns from technical, ethical, and legal perspectives. From a technical perspective, there is a potential for unintended negative consequences to occur when the AI responds to real-world situations that it has not been trained for or lacks confidence in handling. These consequences may include harm to civilians and damage to infrastructure. Secondly, it is crucial to acknowledge the enormous difficulty of constructing an autonomous AI system that consistently upholds ethical principles and human rights in all possible scenarios. Indeed, despite the considerable efforts made by the AI community to create \"ethical machines\", these endeavors usually necessitate human supervision and are full of weaknesses. Finally, questions regarding the accountability and legal obligations associated with the decisions taken also arise. In general,"}, {"title": "AI technologies as WMD", "content": "Apart from serving as a means of delivery, certain technological advancements, and specifically AI, can potentially become WMD themselves, for instance by lowering the technical barriers to proliferation of traditional WMDs or by creating novel WMDs. In the first case, new technologies, such as computer numerical control\u00b94, additives manufacturing15, and synthetic biology\u00b96, may facilitate the mass production of components of WMDs or may be used to more efficiently produce related materials\u00b97.\nAnother manner in which Al connects with WMDs is via Generative AI (GAI), which refers to algorithms capable of generating seemingly novel content, including text, graphics, and audio, by matching user prompts with patterns learned during training. In this scenario, there is a concern that GAI could turn into a WMD itself rather than contributing to the development and proliferation of conventional WMDs. In fact, the inherent capability of generative AI to autonomously create, mimic, and manipulate information poses multifaceted challenges. Indeed, a ranking of top risks of 202318 included new technologies, and GAI in particular, as potential WMDs due to their significant disruptive impact on society. According to the authors of the report, GAI has the capacity to manipulate individuals and incite political instability. More precisely, the use of GAI, specifically through the creation and dissemination of fake, inaccurate, and deceptive material that appears convincing and authentic, can be utilized by demagogues and populists to manipulate society and undermine the integrity of information systems, potentially leading to the subversion of democracy. Additionally, autocrats can exploit GAI to establish digital surveillance and propaganda on social media platforms.\nOn a similar vein, the Global Network on Extremism and Technology\u00b9\u00ba affirmed that GAI can facilitate extremist propaganda by desensitizing individuals. For instance, this can be accomplished by means of interactive social media, music and video games that represent extremist views and allow the player to identify with aggressive avatars. Another example"}, {"title": "Conclusion", "content": "Throughout this work, we explored how new technologies, in particular AI, may impact the object and scope of implementation of UNSCR 1540. We reviewed how this resolution and subsequent ones address the issue and presented two possible interactions: AI-controlled WMDs and AI as WMD. Both cases raise questions about potential risks and ethical considerations with implications on global peace and security that are not fully acknowledged in an international regulatory framework. Consequently, we argue that it is necessary to expand the scope of UNSCR 1540 to explicitly include the influence of AI technology on the advancement, development, dissemination, and spread of WMDs in order to achieve effective and responsible global governance. Furthermore, we recommend the development of guidelines to ensure the effective implementation of such new provisions of Resolution 1540."}]}