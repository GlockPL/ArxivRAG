{"title": "Predicting the Target Word of Game-playing Conversations using a Low-Rank Dialect Adapter for Decoder Models", "authors": ["Dipankar Srirag", "Aditya Joshi", "Jacob Eisenstein"], "abstract": "Dialect adapters that improve the performance of LLMs for NLU tasks on certain sociolects/dialects/national varieties ('dialects' for the sake of brevity) have been reported for encoder models. In this paper, we extend the idea of dialect adapters to decoder models in our architecture called LORDD. Using MD-3, a publicly available dataset of word game-playing conversations between dialectal speakers, our task is Target Word Prediction (TWP) from a masked conversation. LORDD combines task adapters and dialect adapters where the latter employ contrastive learning on pseudo-parallel conversations from MD-3. Our results for en-IN conversations on two models (MISTRAL and GEMMA) show that LORDD outperforms four baselines on TWP, while bridging the performance gap with en-US by 12% on word similarity and 25% on accuracy. The focused contribution of LORDD is in its promise for dialect adaptation of decoder models.", "sections": [{"title": "1 Introduction", "content": "Dialect adaptation of language models refers to approaches that improve their performance for different dialects of a language (Joshi et al., 2024). Past work proposes dialect adaptation for encoder models (Liu et al., 2023; Held et al., 2023; Xiao et al., 2023). This paper extends it to decoder models, via a novel architecture called Low-Rank Dialect robustness for Decoder Models (LORDD). To demonstrate the effectiveness of LORDD, we use MD-3 (Eisenstein et al., 2023), a dataset of manually transcribed dialectal dialogues between speakers of either Indian English (en-IN) or US English (en-US) playing the word-guessing game of taboo\u00b9. We select MD-3 conversations where the guesser correctly identifies the target word/phrase"}, {"title": "2 Architecture of LORDD", "content": "The architecture of LORDD employs two parameter-efficient adapters: task adapter and dialect adapter, as shown in Figure 2."}, {"title": "2.1 Task Adapter", "content": "We define x and t as lists of tokens in the masked conversation and the target word respectively. For a batched input of N pairs of masked conversations and corresponding target words, we train the task adapters to output the correct target word using maximum likelihood estimation a standard learning objective for causal language modeling (Jain et al., 2023).\n\n$L_{Task} = \\frac{1}{N}\\sum_{j=1}^{N}\\sum_{i=x_j^2+1}^{|x_j+t|} log p(x_i|x_{<i})$\n\nHere, $x_i^\\prime = [x_1,...,x_i^\\prime]$ denotes the subsequence before $x_i$ and |\u00b7 | is the number of tokens."}, {"title": "2.2 Dialect Adapter", "content": "To train the dialect adapter, we use a pseudo-parallel corpus between en-IN and en-US conversations. This corpus consists of both positive and negative pairs of masked conversations. We consider a masked conversation pair as a positive example if both conversations pertain to the same target word, and a negative example if they pertain to a different target word. We then perform contrastive learning between the frozen representation of the masked en-US conversation ([MASK]us) and the trainable representation of the masked en-IN conversation ([MASK]Ind), using cosine embedding loss. This allows the adapters to learn from both positive and negative examples present in the pseudo-parallel corpus.\n\n$L_{pial}= \\begin{cases}\n1 - sim([MASK]_{US}, [MASK]_{Ind}) & y = 1\\\\\nmax (0, sim([MASK]_{US}, [MASK]_{Ind}) - d) & y = -1\n\\end{cases}$\n\nHere, sim() calculates the cosine similarity, 'd' is the margin, and 'y' is the label (1 for a positive example, and -1 otherwise).\nIn contrast to the task adapter, the dialect adapter is trained to output standard dialect representations for an input text. Hence, LORDD stacks the task adapter on top of the dialect adapter (as shown in Figure 2), allowing the models to predict the target word as required for TWP."}, {"title": "3 Experiment Setup", "content": "We experiment with two open-weight decoder models namely, Mistral-7B-Instruct-v0.2 (MISTRAL; Jiang et al., 2023) and Gemma2-9B-Instruct (GEMMA; Gemma Team, 2024). LORDD is trained as follows:\n\n\u2022 The task adapter is trained by fine-tuning the model for 20 epochs, with a batch size of 32, Paged 8-bit AdamW (Dettmers et al., 2022) as the optimiser and learning rate of 2e-4.\n\n\u2022 To train the dialect adapter, we perform contrastive learning for 10 epochs, with a batch size of 8, AdamW as the optimiser, a learning rate of 2e-5, and a margin of 0.25.\n\nWe inject adapter matrices at all linear layers, as recommended by Dettmers et al. (2023). Training either adapter for a single experiment takes approx. 25 minutes on an A100 GPU. We compare"}, {"title": "4 Evaluation", "content": "Our results address three questions: (a) What is the current gap in the task performance between en-US and en-IN?; (b) How well does LORDD help bridge the gap?; (c) How essential is each component in LORDD to bridge the gap?\nTable 3 compares the performance of LORDD with the baselines and the skyline. On similarity and accuracy, LORDD reports an average of 59.9 and 35.7 respectively across both models. On average, LORDD improves on the performances of the in-dialect baseline by 13.4% on similarity and 28.1% on accuracy. As expected, the skyline reports the best performance for the task. However, the initial gap of 27.3% on similarity and 64.7% on accuracy between the skyline and the in-dialect baseline is reduced to 12% and 25% respectively.\nWe now show the results from an ablation in Table 4 to evaluate both adapters in LORDD. We compare LORDD with three variants: (a) the dialect adapter trained on other parallel corpora, (b) LORDD without the dialect adapter, within which we also compare, (c) the task adapters trained on other augmented data. Compared to LORDD, all other variants report a degradation in their performances. Training the dialect adapter on synthetic parallel corpora (en-US || en-MV and en-TR || en-IN) results in degradation ranging from 1.0 to 1.1 on similarity and 2.5 to 2.9 on accuracy. Removing the dialect adapter results in a further degradation ranging from 1.5 to 8.7 on similarity and 3.5 to 12.2 on accuracy. The worst-performing variants are the models that only train the task adapter on synthetically augmented data (en-MV + en-US and en-TR + en-IN). While the degraded performances of these models show the importance of the dialect adapter, the lower performances on variants involving synthetic conversations further solidify the use of natural conversations in LORDD.\nFinally, we manually analyse erroneous instances from LoRDD, and categorise them into types of dialect features as given by Lange (2012) and Demszky et al. (2021). Figure 3 shows that EXTRANEOUS ARTICLE (\u201cIt's a one word\") is the most common feature associated with these conversations. The definitions of all identified dialect features with examples are in Appendix A.2.\""}, {"title": "5 Related Work", "content": "Language technologies need to be equitable to dialects/sociolects/national varieties (Joshi et al., 2024; Blodgett et al., 2020). Dialect adaptation involves strategies to improve the performance of non-mainstream dialects. These strategies range from introducing dialectal information at the pre-training phase (Sun et al., 2023) to adapter-based approaches. Adapters are explored to be viable and efficient in improving dialect robustness (Liu et al., 2023). In particular, we derive from this line of work by training a low-rank dialect adapter like Xiao et al. (2023) using a contrastive learning objective like Held et al. (2023). While past approaches adapt encoder models, we distinguish ourselves by proposing LORDD as an architecture to adapt decoder models. Similarly, past work uses frameworks like VALUE (Ziems et al., 2022) and Multi-VALUE (Ziems et al., 2023) to create synthetic dialectal variants of standard US English benchmarks. In contrast, we use a pseudo-parallel corpus of naturally occurring dialectal conversations from MD-3 (Eisenstein et al., 2023). Our task of target word prediction is closely similar to Chalamalasetti et al. (2023), who generate word game"}, {"title": "6 Conclusion", "content": "This paper focused on a simplistic causal language modeling task, called target word prediction, using masked game-playing conversations between two dialectal speakers of English (en-US and en-IN). The task was to predict the target word from a masked conversation. From our initial experiments with fine-tuned decoder models, the in-dialect baseline (en-IN) reported a performance degradation on TWP, when compared with the skyline (en-US). To address the gap in the case of en-IN, we proposed LORDD as a novel architecture using low-rank adapters. LORDD extends past work in dialect adaptation for encoder models to decoder models by employing contrastive learning via a pseudo-parallel corpus of real conversations. LORDD outperformed one in-dialect baseline and three cross-dialect baselines, while also bridging the gap with the skyline to 12% (down from 27.3%) and 25% (down from 64.7%) on similarity and accuracy respectively. Through ablation tests on LORDD, we validated the effectiveness of its components.\nLORDD sets up the promise for dialect adaptation of decoder models. Our error analysis also highlights the scope for future improvement. A potential future work is to evaluate LORDD on other causal language modeling tasks, including seq2seq tasks, and other dialects. Similarly, an extension to LORDD would eliminate the requirement of naturally occurring conversations in multiple dialects."}, {"title": "Limitations", "content": "While previous approaches have proposed dialect adapters as task-agnostic, our study does not make the same claim. We use target word prediction as the task of predicting the last word of a conversation which was the word that the described was attempting to convey to the guesser. This task is a simplistic version of causal language modeling. However, we do not verify that LORDD works for causal language modeling because there is no suitable parallel dataset of turn-aligned conversations, to the best of our knowledge. Held et al. (2023) use bottleneck adapters based on their ability for cross-lingual transfer, but we do not explore these types of adapters due to the lack of support for our choice of models at the time of writing the paper. The choice of en-IN as a dialect of interest is solely based on the availability of the dataset."}, {"title": "Ethics Statement", "content": "We use a publicly available dataset of conversations consisting of human players engaged in a game of taboo. The topics discussed in the dataset are fairly general and are unlikely to cause distress. One of the authors of the paper performed the error analysis. The synthetic conversation created using GPT-4 may contain biased output, arising due to the properties of the model. We do not expect any reasonably significant risks arising as a result of the project."}, {"title": "A Appendix", "content": ""}, {"title": "A.1 Prompt to create en-TR", "content": "'Normalise the conversation. Remove all exaggerations and dialectal information. Return a neutral response.'"}, {"title": "A.2 Dialect features", "content": ""}]}