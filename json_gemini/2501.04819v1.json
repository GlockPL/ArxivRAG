{"title": "Planing It by Ear: Convolutional Neural Networks for Acoustic Anomaly Detection in Industrial Wood Planers", "authors": ["Anthony Desch\u00eanes", "R\u00e9mi Georges", "Cem Subakan", "Bruna Ugulino", "Antoine Henry", "Michael Morin"], "abstract": "Abstract-In recent years, the wood product industry has been facing a skilled labor shortage. The result is more frequent sudden failures, resulting in additional costs for these companies already operating in a very competitive market. Moreover, sawmills are challenging environments for machinery and sensors. Given that experienced machine operators may be able to diagnose defects or malfunctions, one possible way of assisting novice operators is through acoustic monitoring. As a step towards the automation of wood-processing equipment and decision support systems for machine operators, in this paper, we explore using a deep convolutional autoencoder for acoustic anomaly detection of wood planers on a new real-life dataset. Specifically, our convolutional autoencoder with skip connections (Skip-CAE) and our Skip-CAE transformer outperform the DCASE autoencoder baseline, one-class SVM, isolation forest and a published convolutional autoencoder architecture, respectively obtaining an area under the ROC curve of 0.846 and 0.875 on a dataset of real-factory planer sounds. Moreover, we show that adding skip connections and attention mechanism under the form of a transformer encoder-decoder helps to further improve the anomaly detection capabilities.\nIndex Terms-Convolutional neural networks, Transformer, Anomaly detection, Acoustic, Wood planer", "sections": [{"title": "I. INTRODUCTION", "content": "In practice, problems and anomalies in wood-processing equipment could be detected by ear by experienced operators. In recent years, however, the wood-product industry has been facing a skilled labor shortage. This results in an increase of abnormal behavior in wood machinery and causes additional costs to companies [1].\nOne promising answer is acoustic monitoring. Acoustic monitoring is a relatively cheap and easy solution to help automatically detect these anomalies and can be seen as a tool to help novice operators to better understand their machinery. Acoustic anomaly detection consists of determining if a given sound segment is anomalous or not. Generally, this task is done using unsupervised learning and deep neural networks [2], [3]. One of the challenges is that factories are noisy environments where the abnormal sounds might be damped by other noises, such as other machine operations. Moreover, some anomalies are subtle and hard to detect, even for experienced operators. Detecting such anomalies is thus a challenging task for algorithms.\nIn this paper, we contribute with an industrial acoustic dataset of a functioning wood planer where anomalous events were flagged by an expert\u00b9. We present two neural network architectures for acoustic anomaly detection on this new industrial dataset a convolutional autoencoder with skip connections (Skip-CAE), and a Skip-CAE transformer. On our dataset, both approaches outperform other models such as DCASE autoencoder baseline, one-class SVM, isolation forest and a convolutional autoencoder (CAE) from the literature. To summarize, our contributions are the following:\n\u2022 An open industrial dataset containing real-life factory planing sounds.\n\u2022 A new convolutional autoencoder architecture that uses skip connections to improve its learning capabilities to detect anomalies.\n\u2022 A new convolutional autoencoder with skip connections and a transformer architecture to detect anomalies.\n\u2022 Comparative analysis of the two new models with exist- ing approaches on a new industrial dataset."}, {"title": "II. BACKGROUND ON WOOD-PROCESSING EQUIPMENT MONITORING AND ACOUSTIC ANOMALY DETECTION", "content": "Wood processing equipment monitoring can be done using multiple means, such as power consumption measurement, accelerometers, displacement, temperature and acoustic emission sensors, as well as airborne sound by ultrasound sensors and microphones [4], [5].\nThe potential of the acquired data is mainly focused on predicting the quality of the wood products to suggest ad- justments of equipment settings [6], [7]. Regarding acoustic"}, {"title": "III. REAL PLANING MILL DATASET", "content": "Our new dataset consists of 7,562 10-second-single-channel recordings of an industrial planer (Gilbert High Speed Planer) sampled at 20 kHz for a total of approximately 21 hours of recordings with an ICP microphone model 377A21. The recordings contain real background noises coming from the planer mill and each one contains the sound of zero or more boards being planed and includes the machine start and shutdown. Some recordings have been labeled by an expert to identify anomalies. However, since the recordings come from real-life operations, some anomalies might not be labeled in the evaluation set."}, {"title": "IV. BUILDING THE ANOMALY DETECTION MODELS", "content": "For our neural networks, we built autoencoders, and con- volutional autocencoders. The autoencoder [21] is a deep feedforward neural network described as the baseline in the DCASE challenge of 2024 [19] (note that the DCASE Mo- bileNetV2 baseline is not included since our dataset contains only one section). It has three parts: the encoder, the bottleneck and the decoder. The encoder has four fully connected layers of 128 neurons. The bottleneck has one layer of eight neurons and the decoder has four fully connected layers of 128 neurons. There is batch normalization between each layer. All activation functions are ReLU. We changed its input and output for mel spectograms leading to 32,080 neurons.\nThe convolutional autoencoder (CAE) model was intro- duced by Duman et al. [2]. Its encoder has 10 convolutional 3 by 3 layers and four max pooling 2 by 2 layers. Its decoder has 12 convolutional 3 by 3 layers and four upsampling 2 by 2 layers. All activation functions are ReLU. We changed the entry size to fit the size of the mel spectograms of our dataset and the number of channels after each convolution has been reduced by a factor of four to obtain a more compact latent representation. The upsamplings are done using bilinear upsampling.\nWe also use a convolutional autoencoder with skip conne\u0441- tions (Skip-CAE) inspired by the CAE of Duman et al. [2]. Figure 1 presents its architecture. We used leaky ReLU instead of ReLU to improve the convergence and prevent vanishing gradient. Moreover, we added batch normalization before each max pooling and upsampling layers. When the number of channels is not the same between two layers of a skip connection (for example the entry that has one channel and the first batch normalization that has four channels), the skip connection is only done on the minimum number of channels (first channel for the example).\nWe also use a convolutional autoencoder with skip con- nections and transformer (Skip-CAE-Transformer). Figure 2 presents its architecture. Compared to the CAE with skip connections of Figure 1, we added a TransformerEncode block and a TransformerDecode block to the model. Each of these block has 10 heads and a single layer. These transformers are the pytorch implementation of Vaswani et al. [22]. The connection between the TransformerEncode and the TransformerDecode represents the memory of the transformer. Moreover, the skip connections before the last batch normalization and the second transposed convolution pass through a fully connected layer to let the network decide if the values of these connections are interesting or not. This model can also be seen as a means to reduce the dimensionality of the input before using a transformer architecture.\nAll neural networks are trained for 500 epochs using Adam with decoupled weight decay (AdamW) optimizer [23]. The same hyperparamters are used for training: a batch size of 32, an initial learning rate of le-3, a cosine scheduler [24] with a minimum learning rate of 1e-5, a maximum learning rate of le-3 and five warm-up restart steps. An early stopping is done if the validation loss has not improved for 30 epochs and the best validation loss model is restored at the end of the training. We used the mean squared error (MSE) loss, defined as the average of the square of the differences between the data values for the mel spectogram and its reconstruction. We"}, {"title": "V. EXPERIMENTS: EVALUATING THE MODELS", "content": "The main objective of the experiments is to compare and evaluate the proposed models. Similar to the DCASE challenge, we use two metrics: the area under the receiver operating characteristic curve (AUC ROC), and the partial AUC (PAUC) with p = 0.1. The reason for using the pAUC is that an anomaly detector that has many false positives cannot be trusted. All models are trained on an Intel Core i7-8750H CPU @ 2.20 GHz, 6 cores, 16 GB of RAM and an NVIDIA GeForce GTX 1050 GPU with 4 GB of memory.\n\n\nA. Results for all anomalies\n\n\nB. Results per anomaly type"}, {"title": "VI. CONCLUSION", "content": "We developed two deep neural network models inspired by a CAE introduced by Duman et al. [2] to detect anomalies in audio signals from an industrial wood planer. The first model, Skip-CAE, is a CAE with skip connections to improve the con- vergence. The second, Skip-CAE-Transformer, has additional transformer encode and decode layers. For the experiments, we built a new public dataset of real-life-recorded wood planer operations containing 105 anomalies corresponding to stuck boards, broken boards and uneven or thick boards. We compared, on this dataset, the proposed neural networks to baselines such as one-class SVM, isolation forest, the CAE of Duman et al. [2], and a traditional autoencoder used in the DCASE 2024 challenge. Our best model, the Skip-CAE- Transformer, outperforms the other models obtaining an AUC of 0.875. Grouping results by anomaly type reveals that the Skip-CAE-Transformer outperforms other models to detect stuck boards and uneven or thick wood. Our models thus demonstrate that it is feasible to detect abnormal events on industrial planers. Furthermore, acoustic anomaly detection is close to how operators function. As such, our models have the potential to gain the trust of expert operators who can understand their outcomes, but it can also help new operators understand the reason for the alarms/anomalies detected."}]}