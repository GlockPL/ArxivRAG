{"title": "Towards an Autonomous Surface Vehicle Prototype\nfor Artificial Intelligence Applications of Water\nQuality Monitoring", "authors": ["Luis Miguel D\u00edaz", "Samuel Yanes Luis", "Alejandro Mendoza Barrionuevo", "Dame Seck Diop", "Manuel Perales", "Alejandro Casado", "Sergio Toral", "Daniel Guti\u00e9rrez"], "abstract": "The use of Autonomous Surface Vehicles, equipped\nwith water quality sensors and artificial vision systems, allows\nfor a smart and adaptive deployment in water resources environ-\nmental monitoring. This paper presents a real implementation\nof a vehicle prototype that to address the use of Artificial\nIntelligence algorithms and enhanced sensing techniques for\nwater quality monitoring. The vehicle is fully equipped with high-\nquality sensors to measure water quality parameters and water\ndepth. Furthermore, by means of a stereo-camera, it also can\ndetect and locate macro-plastics in real environments by means of\ndeep visual models, such as YOLOv5. In this paper, experimental\nresults, carried out in Lago Mayor (Sevilla), has been presented as\nproof of the capabilities of the proposed architecture. The overall\nsystem, and the early results obtained, are expected to provide\na solid example of a real platform useful for the water resource\nmonitoring task, and to serve as a real case scenario for deploying\nArtificial Intelligence algorithms, such as path planning, artificial\nvision, etc.", "sections": [{"title": "I. INTRODUCTION", "content": "The urgent need to improve the efficiency of data collection\nin large aquatic environments, such as seaports, rivers, and\nlakes, has driven significant technological challenges: adaptive\nmonitorization, large measurement campaigns, reactive path\nplanning behavior, etc. These challenges, have pushed the de-\nvelopment of innovative solutions in the field of robotics, like\nAutonomous Surface Vehicles (ASVs) [1]. ASVs offer several\nadvantages, including being able to operate autonomously,\nreducing the need for constant human supervision, especially\nin aquatic environments that are challenging or dangerous for\ndivers or human operators. Equipped with a variety of special-\nized sensors and equipment, ASVs can perform a wide range\nof tasks, such as oil spill detection [2], water quality monitor-\ning or underwater mapping, making them valuable tools for\na variety of industries, including environmental management,\nmaritime safety and scientific research. Advances in sensing\nand navigation technology have further improved the efficiency\nand accuracy of ASVs, enabling them to autonomously avoid\nobstacles using object detection systems [3], [4], increasing\ntheir safety and reliability in dynamic environments.\nDespite the aforementioned significant progress in the de-\nvelopment and adoption of ASV technologies, significant\nchallenges remain uncovered, such as the need for design-\ning robust systems for large-scale environmental monitoring\nwithout direct supervision, as well as debris detection and"}, {"title": "II. HARDWARE ARCHITECTURE", "content": "The proposed ASV is equipped with several components\nthat enable its autonomous navigation and data collection in\naquatic environments. The Jetson Xavier NX\u00b9 is an embedded\ncomputing platform designed for AI-driven applications. It\nserves as the central processing unit for the ASV and can\nintegrate data from various sensors, such as cameras and\nsonars among others, to perform sensor fusion. Its GPU-\naccelerated architecture enhances the ASV's perception ca-\npabilities using AI-based techniques, allowing it to detect\nobstacles, optimize path planning and make real-time decision-\nmaking for autonomous navigation.\nIn addition to the Jetson Xavier NX, the ASV incorporates\nthe Navio2\u00b2 autopilot, which operates as a HAT connected to\na Raspberry Pi 4. Running Ardupilot\u00b3 inside, this autopilot\nis responsible for providing additional sensors, interfaces and\nprocessing power dedicated to navigation and autonomous\ncontrol tasks, such as thruster actuation and waypoint routing\nalgorithms. Communication between the devices is facilitated\nthrough a local network, with each device connected via an\nEthernet cable to an industrial modem which provides internet\nconnection via a IoT 4G SIM card. Additionally, this modem\nserves as a WiFi hotspot, enabling remote connectivity to the\nASV. This configuration allows external control and monitor-\ning of the devices, providing flexibility and accessibility in the\nASV operating environment.\nTo achieve centimeter accuracy, a GPS/GNSS RTK sys-\ntem is implemented. The Emlid Reach M+ module with\na Tallysman antenna is located on the vehicle, connected\ndirectly to Navio2 to provide positioning information, and\ncommunicates via LoRa\u2074 with the Emlid Reach RS+ ground\nstation, which sends real-time corrections. This allows the\nvehicle to be handled in narrow areas by having it always\nwell positioned with such accuracy. The movement of the\nvehicle is carried out by two BlueRobotics T200 thrusters,\nlocated at the rear of the catamaran. These are compact but\npowerful brushless direct current motors (BLDC) controlled\nby pulse width modulation (PWM) signals. They are specially\ndesigned for ROVs, AUVs and surface vessels, among others,\nthus providing agility and precision in vehicle handling.\nThe Ping25 sonar (see Fig. 2c) from Blue Robotics offers\nthe ASV underwater depth sensing capabilities. The device\nis a single-beam echosounder that can measure distances\nunderwater, reaching depths of up to 100 meters. It is con-\nnected to the Jetson Xavier NX through a UART to USB\nadapter. Moreover, data retrieval and processing is done using\nthe Python library provided by Blue Robotics. The sonar\nallows the ASV to accurately map the underwater terrain\nand depth contours of water bodies, making it useful for\nbathymetry measurements, which are fundamental to conduct\nan appropriated monitoring of water resources. Additionally,\nit can be used as an underwater obstacle avoidance sonar to\nnavigate safely in challenging environments.\nThe Stereolabs Zed 2i (see Fig. 2b) is a stereo camera\nsystem that enhances spatial awareness by providing depth\nperception and visual data for various applications. It is\nconnected to the Jetson Xavier NX through USB 3.1, and the\nZED API provides low-level access to the camera and sensors.\nThe ASV can perform object detection and localization tasks\nusing advanced computer vision algorithms deployed on the\nJetson Xavier NX, leveraging the depth information provided\nby the ZED 2i camera.\nAll of the above on-board ASV devices, including propul-\nsion, computing and sensor systems, are powered by a set\nof two LiPo batteries in parallel, with a nominal voltage of\n14.8V and 10.000 mAh each one. The current configuration\nof 20.000 mAh provides an autonomy of about 2 hours, but\ncan easily be increased by doubling or tripling the capacity\nby simply adding more batteries in parallel, ensuring reliable\nand uninterrupted operation during extended missions.\nThe ASV is equipped with the AML-3 XC Oceanographic"}, {"title": "III. SOFTWARE ARCHITECTURE", "content": "The core of the software is divided in three main pieces\nof hardware: First, the aforementioned Xavier NX will serve\nas a Flight Companion Board (FCB) to manage the high\nlevel behavior of the vehicle, i.e., the goal waypoint query,\nthe flight modes, the vision subsystem, etc. Secondly, the\nNavio2 is in charge of the low-level navigation system with\nArdupilot as the main middleware. Ardupilot is an open-\nsource autopilot software that can handle multiple types of\nunmanned vehicles and serves as a low-level controller with a\nstandard communication interface called MAVLink. Finally,\nthe last computation unit is located outside of the ASV, as\na remote server within the computation infrastructure of the\nUniversity of Sevilla. This server, equipped with multiple high-\nend GPUs and parallel computing CPU capabilities, is used\nas a central computation unit for the ASVs, to produce water\ncontamination models based on machine learning, like Gaus-\nsian Process models, which computation complexity is too\nhigh to be handled locally. Therefore, the AI-based movement\npolicy of the ASV is implemented in that server. This feature\nis suitable for battery-supplied ASVs that the one proposed in\nthis paper since it alleviate the computational charge of the\nsystem.\nThe FCB, with an Ubuntu 20.04 LTS, implements the\nsoftware using ROS2 with Humble Hawskbill version, an open\nsource robotic middleware that provides a comprehensive set\nof libraries and tools designed for developing robotic systems.\nLeveraging the extensive capabilities of ROS2, additional\nsensors, actuators and peripherals can be integrated into the\nASV operating framework. within this framework, the several\nmessages and data structures, like RGB images, waypoint\nqueries, and so on, are published in topics. These topics\ncan be subscribed by a ROS2 node within the software,\nwhich enhances the flexibility and implementation of new\ncomponents of the architecture. ROS2 provides also with\ncommon interfaces, which helps defining custom nodes and\ncommunity nodes following the principle of not reinventing\nthe wheel. The different topics and nodes are depicted in Fig.\n6. The main implemented nodes in the proposed ASV, are:\n\u2022 Mission Node: In charge of receiving the goal WP and\npoints of interest, i.e., points of water contamination,\nsanitize them, and inject them into the Ardupilot via\nMAVLink through the MAVROS node.\n\u2022 Path Planner Node: This node implements a Dijkstra\npath planner [5] that optimally obtains an off-line feasible\nroute from the current ASV position to the goal WP.\n\u2022 WQP/Sonar Node: These nodes handle the serial com-\nmunications of the FCB with the WQP sensor and the\nsonar. They translate the dataframes to ROS2 messages\nfor a given node to subscribe.\n\u2022 Camera Node: Node in charge of implementing the AI\nYOLO modules for obstacles and macro-plastic detection.\nThis node provides the Mission Node and the server with\ngoal WPs.\n\u2022 Server comm. Node: This node handles the bi-directional\ncommunication with the central server.\nMAVROS Node: Handles the communication with\nArdupilot via a MAVLink standard interface.\nThis proposed ROS2-based software is embedded in a\nDocker image to support cross compatibility and to abstract\nthe software from the hardware, and to be tested in different\nAMD/ARM architectures.\nThe central server is an Ubuntu 22.04 LTS server with 2x\nGPUs (Nvidia RTX 3090 and Nvidia RTX A4000) and dual In-\ntel Xeon CPU architecture. This server will serve as an proxy-\ncomputation server for the vehicle. The server communicates\nwith the ASV through the Internet using Message Queuing\nTelemetry Transport protocol (MQTT). This lightweight IoT\nprotocol, enables a fast and reliable communications within\nnodes. One of the advantages of this protocol is the small size\nof the dataframes, which is important when the bandwidth is\nsmall and the data consumption of the IoT 4G SIM inside\nof the ASV is limited. The central server is also in charge of\nproviding a Graphical User Interface (GUI) for the supervision\nof the ASV. This GUI, implemented using Node-Red, serves\na double purpose: First, it filters and manages the operative\ninformation that the ASVs transmits (position, speeds, safety\nflags, etc). Second, it can be used to operate the ASVS\nremotely using an Informative Path Planner [6] implemented\ninside of the server, in a rendezvous architecture.\nThe server will also receive the data from the sensors to\nsimultaneously conform a water quality models based on ma-\nchine learning algorithms, as it will be explained later. Thus,\nthe high-end hardware capabilities of this server leverages the\ncomputing skills of the ASVs as a on-proxy GPU, for example,\nwhen Deep Learning is used for Informative Path Planning"}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "The tests carried out have successfully validated the au-\ntonomy, sensor accuracy, and communications capabilities of\nthe proposed ASV, paving the way for future exploration and\nmonitoring missions in aquatic environments. The tests were\ncarried out in Lago Mayor, Parque del Alamillo (Sevilla), a\nrelatively reduced artificial lake with a large number of flora\nand fauna. Several field tests were conducted to evaluate the\nautonomy and data collection capabilities of the ASV. Using\ntwo 4-cell lithium batteries, the ASV achieved an autonomy\nof around 2 hours while maintaining an average velocity of 1\nm/s. This demonstrates its ability to operate autonomously for\nextended periods without the need for recharging.\nDuring the course of the mission of a length of about 3 km\n(as can be seen in Fig. 7), it was demonstrated the ability of the\nASV to execute planned missions using a series of waypoints,\nas well as its ability to maintain stable communications with\nthe server to transmit the data captured by the sensors in real\ntime while operating on the ground.\nData collected during the monitoring missions include\nbathymetry measurements, pH, temperature, conductivity, and\nturbidity readings of the lake. These data provide detailed\ninformation about the aquatic environment, crucial for under-\nstanding the ecological status of the waterbody and identifying\nany potential environmental concerns. The parameter maps de-\npicted in Fig. 8 have been generated using Gaussian processes\n(GPs), a machine learning modeling technique commonly em-\nployed in spatial data analysis. As seen in [7], by representing\nfunctions as random variables with Gaussian distributions,\nGPs offer a principled framework for incorporating prior\nknowledge and making predictions based on observed data.\nThus, they are particularly well-suited for interpolating and\nextrapolating data points in continuous spatial domains, such\nas those encountered in environmental monitoring missions.\nThe kernel used by the implemented GP is the one known\nas Radial Basis Function (RBF), especially useful in environ-\nments where a smooth and continuous variation of parameters\nis expected, as seen in [8]. This kernel is defined by a\nlenghtscale parameter, which determines the distance between\ncorrelated samples, which has been initialized in this case at\naround 80 meters, with approximate bounds between 55 and\n110 meters.\nThe findings obtained during the study were compared with\nthe international standards [9] and with the Spanish regulations\n[10] for drinking water, and it was simply verified that the\nwater was not suitable for human consumption, as expected\nin this type of lake, with the most undesirable parameter being\nthe high turbidity."}, {"title": "A. Water Quality Parameters and Bathymetry estimation"}, {"title": "B. Macro-plastic detection and localization", "content": "The ZED2i stereo camera captures both RGB and depth\nimages simultaneously, providing valuable visual and spatial\ninformation about the ASV's surroundings. The RGB image\nobtained from the left eye of the ZED2i camera serves as input\nto a YOLOv5 [11] custom model running on the powerful\nGPU of the Jetson Xavier NX. The YOLOv5 algorithm is a\nhighly efficient and accurate method for object detection. It\nhas been fine-tuned to perform real-time detection of floating\ndebri and pollutants, such as macro-plastics on water surfaces\n(see Fig. 9). The ZED2i stereo system offers accurate depth\ninformation for each pixel in the RGB image. By analyzing\nthe depth data of detected objects, their distance from the\ncamera in meters is precisely estimated, and their positioning\nwith respect to the ASV reference frame is determined. This\ninformation is combined with the ASV's GPS coordinates to\nlocate macro-plastics accurately in a global frame of reference\n(see Fig. 9). The ASV transmits the detected macro-plastics\nand their global coordinates to the mission node as interest\npoints. This information enables the ASV to contribute to the\npreservation of aquatic ecosystems and the mitigation of water\npollution by providing targeted cleanup areas."}, {"title": "V. CONCLUSION AND FUTURE WORKS", "content": "An innovative ASV has been introduced for aquatic explo-\nration and monitoring, designed to navigate through extensive\nbody waters while gathering a wide range of environmental\ninformation through the integration of onboard sensors such\nas water quality parameters, sonar and camera. In future\nmissions, the deployment of a fleet of ASVs, capable of\nreal-time cooperation and task distribution, is considered.\nASVs can be assigned multiple tasks simultaneously, such\nas intensification, which consists of prioritizing areas based\non contamination level, or exploration, which involves uni-\nformly covering the water body. Cooperative missions may\nalso involve fleets of heterogeneous vehicles with different\nmeasurement or movement capabilities. Future research will\nimplement Deep Reinforcement Learning (DRL) algorithms,\nsuch as those from [12], to enable Informative Path Planning as\nthe samples are taken from the lake. Furthermore, techniques\nfrom [13] will be incorporated by combining Local GPs and\nDRL to optimize monitoring policies. This will include the\nincorporation of collision-free Consensus-based heuristics for\nthe safe deployment of multiple surface vehicles, as well as\na unified neural network for all agents. In addition, the ASV\ndesign will be modified to integrate a winch for submerging\nAML Oceanographic sensors and collecting samples at various\ndepths, expanding monitoring capabilities. This enhancement\nenables vertical profiling of the water column, offering valu-\nable insights into water quality dynamics."}]}