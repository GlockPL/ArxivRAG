{"title": "Randomness of Low-Layer Parameters Determines Confusing Samples in Terms of Interaction Representations of a DNN", "authors": ["Junpeng Zhang", "Lei Cheng", "Qing Li", "Liang Lin", "Quanshi Zhang"], "abstract": "In this paper, we find that the complexity of interactions encoded by a deep neural network (DNN) can explain its generalization power. We also discover that the confusing samples of a DNN, which are represented by non-generalizable interactions, are determined by its low-layer parameters. In comparison, other factors, such as high-layer parameters and network architecture, have much less impact on the composition of confusing samples. Two DNNs with different low-layer parameters usually have fully different sets of confusing samples, even though they have similar performance. This finding extends the understanding of the lottery ticket hypothesis, and well explains distinctive representation power of different DNNs.", "sections": [{"title": "1. Introduction", "content": "The explainability of deep neural networks (DNNs) has received increasing attention in recent years. Although previous studies have explained different aspects of DNNs [Dziugaite and Roy, 2017, Foret et al., 2020, Neyshabur et al., 2015], this paper focuses on a new perspective, which starts from the following two questions.\n(1) Can we define and mine a set of inference patterns from a trained DNN to explain the DNN's inference socre? Can we also use these inference patterns to directly identify whether the inference/classification of a specific sample is conducted on over-fitted features? In this paper, the samples classified by over-fitted features are termed confusing samples.\n(2) What is the key factor that determines the composition of confusing samples of a DNN?\nBackground. Our research is conducted upon recent advancements in the explanation theory. I.e., Ren et al. [2024a] have proven a series of theorems, which guarantee that given a DNN, people can use a surrogate AND-OR logical model to accurately match all network outputs on an exponential number of augmented input samples.\nThe above theory serves as a mathematical guarantee to let AND-OR interactions in the logical model be roughly considered as primitive inference patterns equivalently used by the DNN for inference. For example, as Figure 1 shows, given an input prompt x =\u201cA red apple falls to the ground because of the pull of,\" the LLM generates the next token \"gravity,\" and its inference score of token generation can be faithfully explained by the interactions in the logical model, e.g., an AND interaction between the words in S = {red, apple, falls} is related to \"gravity.\"\nOur research mainly focuses on two aspects: (1) we use interactions to recognize a set of samples, to which a DNN is overfitted, and these samples are defined as the confusing samples; (2) we use interactions to explore the key factor that determines the composition of confusing samples.\n\u2022 Using the complexity of interactions to recognize confusing samples. Since AND-OR interactions have been proven to effectively explain varying inference scores of a DNN, interactions have been widely used as primitive inference patterns to analyze the generalization power of a DNN [Zhou et al., 2024, Deng et al., 2022].\nIn this study, we use such interactions to recognize a set of confusing samples, and confusing samples are defined as those whose classification/inference is conducted on non-generalizable interactions. (1) First, we find that the emergence of highly complex and mutually offsetting\u00b9 interactions is the internal mechanism for the overfitting of a DNN, because such interactions are less likely to be generalized to testing samples\u00b2. (2) Second, as Figure 2"}, {"title": "2. Defining confusing samples with non-generalizable inference patterns", "content": "2.1. Preliminaries: extracting interactions as inference patterns used by a DNN for inference\nTo explain the generalization power of a DNN using the inference patterns encoded by the DNN, the key point is how to guarantee the explained inference patterns objectively reflect the true information-processing mechanisms in the DNN. Fortunately, recent advancements in explainable AI theory [Li and Zhang, 2023b, Ren et al., 2023, 2024a] have discovered and proven a theoretically guaranteed faithful method to define and extract inference patterns of a DNN.\nGiven a DNN $\\upsilon$ and an input sample $x = [x_1,x_2,..., x_n]^T$ with n input variables, indexed by $N = {1,2,..., n}$. Let $v(x) \\in R$ denote a scalar output of the DNN, e.g., the widely-used scalar classification confidence in multi-category classification [Deng et al., 2022], as follows.\n$v(x) = \\log \\frac{p(y = y^*|x)}{1 - p(y = y^*|x)}$, (1)\nwhere $p(y = y^*| x)$ represents the probability of classifying the input sample x to the ground-truth label y*.\nThe universal-matching property in Theorem 2.1 guarantees that for each DNN v and an sample x, we can construct a logical model h(x) based on AND-OR interaction logics to faithfully predict all varying outputs v(x) of the DNN on"}, {"title": "2.2. Connection between the interaction complexity and the generalization power", "content": "According to Theorem 2.1, the output of a DNN can be disentangled into the sum of effects of different interactions in the logical model. Therefore, the overall generalization power of the DNN can be explained as the collective effect of the generalization power of these interactions.\nTherefore, in this subsection, we conduct experiments to verify two hypothesis about the relationship between the interaction complexity and generalization power.\nHow to define generalization power of interactions. Definition 2.2 is the most typical definition for the generalization power of interactions. It is shows that if an interaction frequently appears in both training samples and testing samples and consistently pushes the DNN towards the same category, then this interaction can be considered to be generalized to the testing samples. Otherwsie, this interaction is non-generalizable.\nDefinition 2.2. Given $m_{and}$ AND interactions in the set $\\Omega_{and}$ and $m_{or}$ OR interactions in the set $\\Omega_{or}$, we define the generalization power of these interactions as the Jaccard similarity $Sim(d_{train}, d_{test})$ between the distribution of interactions on the training samples $d_{train} \\in [R^{2m_{and}+2m_{or}}$ and the distribution of interactions on the testing samples $d_{test} \\in [R^{2m_{and}+2m_{or}}$, i.e., $Sim(d_{train}, d_{test}) = \\frac{|| min (d_{train}, d_{test}) ||_1}{|| max(d_{train}, d_{test}) ||_1}$, where $|| ||_1$ represents the L1-norm.\nHypothesis 1. High-order (complex) interactions have weaker generalization power than low-order (simple) interactions.\nVerifying the above hypothesis about the low generalization power of high-order interactions. This hypothesis is inspired by empirical findings in [Zhou et al., 2024], which"}, {"title": "2.3. Using interactions to define confusing samples", "content": "Based on the conclusion in Section 2.2, we can use the emergence of high-order and mutually offsetting\u00b3 interactions to explain the overfitting of a DNN. Particularly, such interactions emerge on only a few training samples, rather than on all samples, during the overfitting process. This enables us to define the specific set of training samples, in which high-order and mutually offsetting interactions emerge in the overfitting phase, as confusing samples. In comparison, the distributions of interactions of other easy (not confusing) samples do not change a lot.\nConfusing samples vs. hard samples. Hard samples are usually defined as samples with the highest loss [Lin, 2017]. We conducted experiments to explore the relationship between hard samples and confusing samples. First, we collected a set of hard samples by selecting those with the highest loss during the training process. For comparison, we randomly selected some of the remaining samples as easy samples. Then, we compared the interaction distribution of hard samples and the interaction distribution of easy samples.\nSpecifically, we trained VGG-11 on the CIFAR-10 dataset, and trained ResNet-20 on the MNIST dataset. Following the setting in Section 2.2, we visualized the interaction distribution of hard samples and the interaction distribution of easy samples. Figure 5 shows that hard samples tended to contain a large number of high-order and mutually offsetting interactions, which indicates that most hard samples were also confusing samples. In comparison, easy samples usually only encoded low-order interaction. This indicated that most easy samples were not confusing samples.\nHowever, as Figure 6 shows, although there is a considerable overlap between confusing samples and hard samples, they are not exactly the same.\nFirst, a considerable ratio of hard samples are not confusing samples. Hard samples can usually be categorized into two types from the perspective of interactions. (1) Most hard samples encode mutually offsetting\u00b3 interactions, which weaken the classification confidence. (2) The other type of hard samples only have a few interactions. It is the small number of interactions, not the mutually offsetting of interactions, that weakens the classification confidence. To this end, only the fist type of hard samples can be explained as confusing samples.\nSecond, some confusing samples are not hard samples, either. Although the encoding of mutually offsetting interactions in confusing samples usually significantly hurts the classification confidence according to Equation (2), some confusing samples may still be classified with high confidence. As Figure 6 shows, such samples usually contain a large number of interactions, including both lots of mutually offsetting interactions and numerous non-offsetting low-order interactions. The large interaction number can also enhance the sample's classification confidence, according to Equation (2).\nThe emergence of high-order interactions on confusing samples is the main phenomenon during the overfitting phase of a DNN. Traditionally, hard samples are believed to be the primary factor that pushes a DNN towards overfitting. However, our experiments in Section 2.2 show that confusing samples played a distinctive role that contributed to the overfitting of a DNN.\nAs Figure 4 shows, when the training process of a DNN entered the overfitting phase (where the gap between the testing loss and training loss began to widen), we observed"}, {"title": "3. Exploring the key factor that determines the confusing samples encoded by a DNN", "content": "Currently, many engineering techniques have been proposed to enhance the generalization power of DNNs and prevent overfitting, such as improvements of the network architecture He et al. [2016], data cleaning Northcutt et al. [2021], and data augmentation Shorten and Khoshgoftaar [2019].\nHowever, despite previous studies, it is still unclear which factor determines the composition of confusing samples. Therefore, in this study, we conduct experiments and find that it is the randomness of low-layer parameters that determines the composition of confusing samples of a DNN. In comparison, other factors, such as the network's architecture and the parameters in the high layers, have much less impact on the composition of confusing samples."}, {"title": "3.1. Randomness of confusing samples", "content": "We find a counter-intuitive phenomenon, i.e., different DNNs with similar classification performance usually have fully different sets of confusing samples. This finding seems to conflict with another closely related topic, i.e., mining hard samples, which considers the composition of hard samples is an intrinsic property of data distribution in a high-dimension space. People usually assume different AI models share the same set of hard samples, and this idea has been widely used for data augmentation Shrivastava et al. [2016], Smirnov et al. [2018], Peng et al. [2018].\nHowever, the following phenomenon of the randomness of confusing samples challenges the above well-known common sense. Later, this phenomenon is found to be attributed to the randomness of parameters in low layers of the DNN in Section 3.2.\nPhenomenon 1. DNNs with similar classification accuracies, even those with the same architecture, usually had completely different sets of confusing samples.\nMetric. Given all interactions extracted from a given sample x, we use the average order of interactions extracted from x, $\\eta_{avg} = \\frac{\\Sigma_{k=1}^{n}(k \\cdot J_{pos}^{(k)} + k \\cdot J_{neg}^{(k)})}{\\Sigma_{k=1}^{n}(J^{(k)}_{pos} + J^{(k)}_{neg})}$ as a metric to roughly distinguish whether the given sample is a confusing sample. The average order of interactions is weighted by the interaction strength of each order $J$ and"}, {"title": "3.4. How to understand the randomness of low-layer parameters", "content": "Connection to the lottery tickect hypothesis. Our findings extend the lottery ticket hypothesis Frankle and Carbin [2018]. The lottery ticket hypothesis suggests that the representation of a DNN is dominated by a small set of randomly initialized parameters, which are termed winning tickets. To this end, our experiments further showed that it was the randomness of low-layer parameters that determined the composition of confusing samples of the DNN. In comparison, other factors, such as high-layer parameters and network architecture, had much less impact.\nMore crucially, the low-layer parameters are usually more difficult to optimize than high-layer parameters. This means that the composition of confusing samples of a DNN is primarily determined by the initialization of low-layer parameters, regardless of how we design the architecture and parameters in high layers.\nThe randomness of confusing samples reflects distinctive property for each DNN. The randomness of confusing samples observed in Sections 3.1 and 3.2 provides another distinctive property of confusing samples. Unlike hard samples mainly describing intrinsic nature of data distribution, the composition of confusing samples seems to be fully determined by the uncertainty (the randomness) of the low-layer parameters, without any clear pattern. This represents a distinctive property of each DNN."}, {"title": "4. Conclusions", "content": "In this paper, we have verified that learning complex and mutually offsetting interactions in a set of confusing samples explains the internal mechanism for a DNN's non-generalizable representations. Moreover, we have discovered that DNNs often have fully different sets of confusing samples. It is the randomness of low-layer parameters that determines the composition of confusing samples of the DNN. In comparison, other factors, such as high-layer parameters and network architecture, have much less impact on the composition of confusing samples."}, {"title": "A. Related work", "content": "The explainability of deep neural networks (DNNs) has received increasing attention in recent years. However, there\nhas long been a pessimistic view regarding the possibility of faithfully explaining DNNs's inference logics [Dziugaite and\nRoy, 2017, Foret et al., 2020, Neyshabur et al., 2015]. Fortunately, recent advancements in interaction-based explanations,\nas surveyed by Ren et al. [2024a], have made the first attempt to tackle the mathematical feasibility of explaining a DNN's\ninference logics using a small number of inference patterns. Specifically, (1) Ren et al. [2023] discovered and Ren et al. [2024a]\nproved that there exists an AND-OR logical model, which contains only a small number of interactions, can faithfully explain\nthe inference logics of DNNs, regardless of how the input samples are masked. (2) Zhou et al. [2024] used the complexity\nof interactions to explain the generalization power of DNNs. (3) Deng et al. [2024] demonstrated that fourteen attribution\nmethods can all be explained as a reallocation of interaction effects.\nIn this way, compared to previous studies, this paper provides further insights into the underlying factors contributing to\nthe overfitting of DNNs and identifies the key factor that determines the composition of confusing samples in DNNs. The\nlottery ticket hypothesis Frankle and Carbin [2018] suggests that a DNN's representation is largely influenced by a small subset\nof randomly initialized parameters, known as winning tickets. Building on this, our experiments showed that the low-layer\nparameters of a DNN are the primary determinant of the composition of confusing samples. In contrast, other factors, such as\nhigh-layer parameters and network architecture, have significantly less impact."}, {"title": "B. Properties of the AND interaction", "content": "The Harsanyi interaction Harsanyi [1963] (referred to as the AND interaction in this work) has been a conventional metric\nfor measureing the effect of the AND relationship that a DNN encodes among input variables. In this section, we introduce\nseveral desirable axioms that the AND interaction $I^{and}_T$ adheres to. These properties further underscore the reliability of using\nAND interactions to explain the inference score of a DNN.\n(1) Efficiency axiom (proven by Harsanyi [1963]). The output score of a model can be decomposed into interaction effects\nof different patterns, i.e. $v(x) = \\Sigma_{T \\subseteq N} I^{and}_T$.\n(2) Linearity axiom. If we merge output scores of two models $v_1$ and $v_2$ as the output of model $v$, i.e. $\\forall S \\in N, v(x_S) =\nv_1 (x_S) + v_2(x_S)$, then their interaction effects $I^{and}_{T,1}$ and $I^{and}_{T,2}$ can also be merged as $\\forall T \\subseteq N, I^{and}_T = I^{and}_{T,1} + I^{and}_{T,2}$.\n(3) Dummy axiom. If a variable $i \\in N$ is a dummy variable, i.e. $\\forall S \\subseteq N \\backslash {i}, v(x_{S\\cup{i}}) = v(x_S) + v(x\\{i})$, then it has no\ninteraction with other variables, $\\forall \\emptyset \\neq T \\subseteq N \\backslash \\{i}, I^{and}_{T \\cup \\{i\\}} = 0$.\n(4) Symmetry axiom. If input variables $i, j \\in N$ cooperate with other variables in the same way, $\\forall S \\subseteq N \\backslash \\{i, j\\}, v(x_{S\\cup\\{i\\}}) =\nv(x_{S\\cup\\{j\\}})$, then they have same interaction effects with other variables, $\\forall T \\subseteq N \\backslash \\{i, j\\}, I^{and}_{T \\cup \\{i\\}} = I^{and}_{T \\cup \\{j\\}}$.\n(5) Anonymity axiom. For any permutations $\\pi$ on N, we have $\\forall T \\subseteq N, I^{and}_T = I^{and}_{\\pi T}$, where $\\pi T \\overset{def}{=} \\{\\pi(i)|i \\in T\\}$, and the new\nmodel $v_{\\pi}$ is defined by $(v_{\\pi})(x_{\\pi S}) = v(x_S)$. This indicates that interaction effects are not changed by permutation.\n(6) Recursive axiom. The interaction effects can be computed recursively. For $i \\in N$ and $T \\subset N \\backslash \\{i\\}$, the interaction effect of\nthe pattern $T \\cup \\{i\\}$ is equal to the interaction effect of $T$ with the presence of $i$ minus the interaction effect of $T$ with the\nabsence of $i$, i.e. $\\forall T \\subseteq N \\backslash \\{i\\}, I^{and}_{T\\cup{i}} = I^{and T}_{present} - I^{and}_{T absent}$. $I^{and}_{T present}$ denotes the interaction effect when the variable $i$ is always\npresent as a constant context, i.e. $I^{and}_{T present} = \\sum_{L\\subseteq T} (-1)^{|T|-|L|}V(X_{L\\cup\\{i\\}})$.\n(7) Interaction distribution axiom. This axiom characterizes how interactions are distributed for \"interaction functions\" Sundararajan et al. [2020]. An interaction function $v_T$ parameterized by a subset of variables T is defined as follows. $\\forall S \\in N$, if\n$T \\subseteq S, v_T(x_S) = c$; otherwise, $v_T(x_S) = 0$. The function $v_T$ models pure interaction among the variables in T, because only\nif all variables in T are present, the output value will be increased by c. The interactions encoded in the function $v_T$ satisfies\n$I^{and}_T = c$, and $\\forall S \\neq T, I^{and}_S = 0$."}, {"title": "C. Common conditions for sparse interactions", "content": "Ren et al. [2024a] have proved three sufficient conditions for the sparsity of AND interactions.\nCondition 1. The DNN does not encode extremely high-order interactions: $\\forall T \\in \\{T \\subseteq N | |T| > M + 1\\}, I^{and}_T = 0$.\nCondition 1 is common because extremely high-order interactions usually represent very complex and over-fitted patterns,\nwhich are unlikely to be learned by a well-trained DNN in real scenarios.\nCondition 2. Let $\\overline{v}(k) \\overset{def}{=}  \\frac{\\Sigma_{|S|=k}[v(x_S) - v(x_\\emptyset)]}{(^n_k)}$ denote the average classification confidence of the DNN over all masked\nsamples $x_S$ with $k$ unmasked input variables. This average classification confidence monotonically increases when $k$ increases:\n$\\forall k' \\leq k, \\overline{v}(k') < \\overline{v}(k)$."}, {"title": "D. Details to extract the sparsest AND-OR interactions", "content": "A method is proposed Li and Zhang [2023a], Chen et al. [2024] to simultaneously extract AND interactions $I^{and}$ and OR\ninteractions $I^{or}$ from the network output. Given a masked sample $x_L$, Li and Zhang [2023a] proposed to learn a decomposition\n$v(x_L) = u^{and} + u^{or}$ towards the sparsest interactions. The component $u^{and}$ was explained by AND interactions, and the\ncomponent $u^{or}$ was explained by OR interactions. Specifically, they decomposed $v(x_L)$ into $u^{and} = 0.5 \\cdot v(x_L) + \\Upsilon_L$ and\n$u^{or} = 0.5 \\cdot v(x_L) - \\Upsilon_L$, where $\\{\\Upsilon_L : L \\subseteq N\\}$ is a set of learnable variables that determine the decomposition. In this way, the\nAND interactions and OR interactions can be computed according to Theorem 2.1, i.e., $I^{and}_T = \\sum_{L\\subseteq T}(-1)^{|T|-|L|}u^{and}_L$, and\n$I^{or}_T = -\\sum_{L\\subseteq T}(-1)^{|T|-|L|}u^{or}_{N \\backslash L}$.\nThe parameters $\\{\\Upsilon_L\\}$ were learned by minimizing the following LASSO-like loss to obtain sparse interactions:\n$\\min_{\\{\\Upsilon_L\\}} \\sum_{T \\subset N} |I^{and}_T| + |I^{or}_T|$  (5)\nRemoving small noises. A small noise $\\delta$ in the network output may significantly affect the extracted interactions, especially\nfor high-order interactions. Thus, Li and Zhang [2023a] proposed to learn to remove a small noise term $\\delta_L$ from the\ncomputation of AND-OR interactions. Specifically, the decomposition was rewritten as $u^{and} = 0.5(v(x_L) - \\delta_L) + \\Upsilon_L$ and\n$u^{or} = 0.5(v(x_L) - \\delta_L) + \\Upsilon_L$. Thus, the parameters $\\{\\delta_L\\}$ and $\\{\\Upsilon_L\\}$ are simultaneously learned by minimizing the loss function\nin Eq. (5). The values of $\\{\\delta_L\\}$ were constrained in $[-\\zeta, \\zeta]$ where $\\zeta = 0.02 \\cdot |v(x) - v(x_\\emptyset)|$."}, {"title": "E. Proof of Theorem 2.1", "content": "Proof. (1) Universal matching theorem of AND interactions.\nWe will prove that output component $u^{and}$ on all $2^n$ masked samples $\\{x_S : S \\subset N\\}$ could be universally explained by the\nall interactions in $S \\in N$, i.e., $\\forall \\emptyset \\neq S \\subseteq N, u^{and}_S = \\sum_{\\emptyset \\neq T\\subseteq S} I^{and}_T + v(x_\\emptyset)$. In particular, we define $u^{and}_\\emptyset = v(xp)$ (i.e., we\nattribute output on an empty sample to AND interactions).\nSpecifically, the AND interaction is defined as $I^{and}_T = \\sum_{L\\subseteq T}(-1)^{|T|-|L|}u^{and}_L$. To compute the sum of AND interactions\n$\\sum_{\\emptyset \\neq T\\subseteq S} I^{and}_T = \\sum_{\\emptyset \\neq T\\subseteq S} \\sum_{L\\subseteq T}(-1)^{|T|-|L|}u^{and}_L$, we first exchange the order of summation of the set $L \\subseteq T \\subseteq S$ and the\nset $T \\supset L$. That is, we compute all linear combinations of all sets T containing L with respect to the model outputs $u^{and}$ given\na set of input variables L, i.e., $\\sum_{T:L\\subseteq T\\subseteq S}(-1)^{|T|-|L|}u^{and}_L$. Then, we compute all summations over the set $L \\subseteq S$.\nIn this way, we can compute them separately for different cases of $L \\subseteq T \\subseteq S$. In the following, we consider the cases (1)\n$L = S = T$, and (2) $L \\subset T \\subset S, L \\neq S$, respectively.\n(1) When $L = S = T$, the linear combination of all subsets T containing L with respect to the model output $u^{and}$ is\n$(-1)^{|S|-|S|}u^{and} = u^{and}$.\n(2) When $L \\subset T \\subseteq S, L \\neq S$, the linear combination of all subsets T containing L with respect to the model output $u^{and}$ is\n$\\sum_{T:L\\subseteq T\\subseteq S}(-1)^{|T|-|L|}u^{and}$. For all sets $T : S \\supseteq T \\supseteq L$, let us consider the linear combinations of all sets T with number\n$|T|$ for the model output $u^{and}$, respectively. Let $m := |T| - |L|$, $(0 \\leq m \\leq |S| - |L|)$, then there are a total of $C^{|S|-|L|}_m$\ncombinations of all sets T of order |T|. Thus, given L, accumulating the model outputs $u^{and}$ corresponding to all $T \\supset L$,\nthen $\\sum_{T:L\\subseteq T\\subseteq S}(-1)^{|T|-|L|}u^{and} = u^{and} \\sum_{m=0}^{|S|-|L|}C^{|S|-|L|}_m(-1)^m = 0$. Please see the complete derivation of the following"}]}