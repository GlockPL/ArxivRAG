{"title": "rECGnition_v2.0: Self-Attentive Canonical Fusion of ECG and Patient Data\nusing deep learning for effective Cardiac Diagnostics", "authors": ["Shreya Srivastava", "Durgesh Kumar", "Ram Jiwari", "Sandeep Seth", "Deepak Sharma"], "abstract": "Background and Objective: The variability in ECG readings influenced by individual patient characteristics has posed\na considerable challenge to adopting automated ECG analysis in clinical settings. A novel feature fusion technique\ntermed SACC (Self Attentive Canonical Correlation) was proposed to address this. It calibrates the ECG features\nbased on the patient characteristics features to effectively discard benign changes in ECG morphology that arises due\nto patient characteristics. The overall objective of the study was to create a fast and accurate model by effectively\nconsidering the influence of patient characteristic features onto ECG morphology. The proposed novel fusion\ntechnique is combined with DPN (Dual Pathway Network) and depth-wise separable convolution to create a robust,\ninterpretable, and fast end-to-end arrhythmia classification model named rECGnition_v2.0 (robust ECG abnormality\ndetection v2). Methodology: This study uses MIT-BIH, INCARTDB and EDB dataset to test the efficiency of\nrECGnition_v2.0 for various classes (5/8/10/AAMI) of arrhythmia classification. The heartbeats were segmented from\ngiven datasets and converted to 2D images (like existing methodologies) to perform its benchmarking. To investigate\nthe influence of constituting model components, various ablation studies were performed, i.e. simple concatenation,\nCCA and proposed SACC were compared, while the importance of global and local ECG features were tested using\nDPN rECGnition v2.0 model and vice versa. rECGnition v2.0 was also benchmarked with state-of-the-art CNN\nmodels (MobileNet, EfficientNetB0, ResNet50) for overall accuracy vs model parameters, FLOPs, memory\nrequirements, and prediction time. Furthermore, the inner working of the model was interpreted by comparing the\nactivation locations in ECG before and after the SACC layer. Also, the linear separability of final feature map induced\nby SACC was interpreted using principal component analysis. Results: The proposed architecture rECGnition_v2.0\nshowed a remarkable accuracy of 98.07% and an F1-score of 98.05% for classifying ten distinct classes of arrhythmia\nwith just 82.7M FLOPs per sample, thereby going beyond the performance metrics of current state-of-the-art (SOTA)\nmodels by utilizing MIT-BIH Arrhythmia dataset. Similarly, on INCARTDB and EDB datasets, excellent F1-scores\nof 98.01% and 96.21% respectively was achieved for AAMI classification. Conclusions: The compact architectural\nfootprint of the rECGnition_v2.0, characterized by its lesser trainable parameters and diminished computational\ndemands, unfurled triple advantages. Firstly, it enabled expeditious model training and real-time inference, essential\nfor prompt diagnosis and intervention in a clinical environment. Secondly, it brings about a more interpretable model\nthat aligns well with the requisites of the medical domain, where model interpretability is of paramount significance\nfor clinicians' trust and broader acceptance. Thirdly, rECGnition_v2.0 is a dynamic model that can be scaled\ndepending on the availability of patient characteristics and complexity of existing correlation.", "sections": [{"title": "1. Introduction", "content": "Cardiac disorders remain a predominant health\nadversity with a global footprint [1, 2],\nrequiring improved diagnostics for early\ndiagnosis and treatment. Arrhythmias, among\nother cardiac problems, are hidden and\ndangerous if undiagnosed [3]. The\nelectrocardiogram (ECG) is a key cardiac\ndiagnostic procedure that shows the heart's\nelectrical activity non-invasively [4]. ECG\nsignals are useful for automated arrhythmia\nclassification because their morphological\ndetails typically indicate heart health [5, 6].\nWith the growing popularity of deep learning,\nthe prospect of automated cardiac arrhythmia\nclassification has transitioned from an\nacademic speculation to a realistic goal [7, 8].\nIn search of better diagnostic methods,\nsophisticated computational frameworks that\ncan detect minor but crucial ECG irregularities\nhave been explored [9, 10]. With the advent of\nwearable ECG collection devices that also have\naccess to a patient's broader health data, there is\na thriving interest in exploring robust"}, {"title": "2. Related work", "content": "ECG arrhythmia classification research has\ngrown, especially since deep learning.\nExcellent work employed a deep neural\nnetwork to classify 12 rhythm classifications\nusing single-lead ECGs from 53,000 people\napproximately, indicating deep learning's\npotential for cardiologist-level arrhythmia\nclassification [19]. Another important study\nused deep learning algorithms to analyze a large\nheartbeat dataset of 1,09,446 beats, divided into\nfive kinds, revealing a pre-processing method\nthat greatly improved ECG classification\naccuracy [20]. Recently, a method combining\nRecurrent plot with CNN was also proposed\n[21]. Moreover, an arrhythmia classification\nsystem utilizing a multi-head self-attention\nmethod optimises the extensive semantic\ninformation in the ECG signal, strengthening"}, {"title": "3. Materials and Methods", "content": "3.1. Convolution and Depth-wise separable\nconvolution\nIn convolutional neural networks, standard\nconvolution operations involve applying a set\nof filters, each with dimensions $K \\times K \\timesC$,\nwhere K is the kernel size and C is the number\nof input channels, across the input tensor to\nproduce an output feature map.\nMathematically, the output Y at a spatial\nlocation (i, j) for the k-th filter can be\nexpressed as:\n$Y_{i,j,k} = \\sum_{m=1}^{K} \\sum_{n=1}^{K} \\sum_{c=1}^{C} X_{i+m,j+n,c} W_{m,n,c,k}$,\nwhere X is the input tensor and W are the filter\nweights. Depth-wise separable convolutions\nwere applied here to reduce the computational\ncost and model size; it decomposes the standard\nconvolution into two parts: depth-wise\nconvolution and pointwise convolution. In\ndepth-wise convolution, a single filter is\napplied per input channel, yielding intermediate\noutput $Z_{i,j,c} = \\sum_{m=1}^{K} \\sum_{n=1}^{K} X_{i+m,j+n,c}. W_{m,n,c}$.\nThis is followed by a pointwise convolution,\nwhich involves 1 \u00d7 1 convolutions to\ncombine the outputs from the depth-wise step,\nproducing the final output $Y_{i,j,k} = \\sum_{c=1}^{C} Z_{i,j,c}$"}, {"title": "3.2. Dual Pathway Network (DPN)", "content": "ECG heartbeat is composed of various\nsinusoidal waves of varying frequency [30], so\nit is crucial to analyse it on various time scales.\nHence, CNN blocks in our network employ a\nvarying size kernel to extract features. The DPN\narchitecture was implemented as a CNN that\numtilizes two parallel branches. The first\nbranch focused onextracting local, high-\nresolution features using a smaller receptive\nfield. Conversely, the second branch captures\nthe global, low-resolution features using a\nlarger receptive field. The concatenated feature\nmap is passed down the network for further\nfeature extraction (Figure 1)."}, {"title": "3.3. Self-Attentive Canonical Correlation\n(SACC)", "content": "3.3.1. CCA & Self Attention Theoretical\nBackground\nCanonical Correlation Analysis (CCA) [31] is a\nwell-known statistical approach for finding the\nlinear relationship between two multivariate\ndatasets. Let $X \\in R^{nxp}$ and $Y \\in R^{nxq}$ are two\nmatrices containing two sets of variables with\nn observations. CCA seeks linear combinations\nof the variables in X and Y that have maximum\ncorrelation with each other. Let, x be a linear\ncombination of columns of X and y a linear\ncombination of columns of Y:\n$x = Xa, y = Yb$ (3)\nwhere $a \\in R^{p}$ and $b\\in R^{q}$ are vectors of\ncoefficients.\nCCA attempts to find the vectors a and b that\nmaximize the correlation between x and y:\n$\\rho = \\frac{cov(x, y)}{\\sqrt{var(x) \\cdot var(y)}}$ (4)"}, {"title": "Self-Attention", "content": "Self-Attention [32] is expressed as follows:\nGiven a sequence of input vectors\n{$X_1,X_2, ..., X_n$}, the self-attention mechanism\ncomputes a new sequence of vectors\n{$Y_1, Y_2, \u2026, Y_n$} where each vector $y_i$ is a linear\ncombination of all the input vectors $x_i$,\nweighted by attention scores. These attention\nscores are derived from a compatibility function\nof the input vectors, often parameterized by\nlearnable weights. The following equation\ngoverns the computation of the attention scores:\n$\\alpha_{ij} = \\frac{exp (score(x_i, x_j))}{\\Sigma_k exp(score(x_i, X_k))}$ (5)\nHere, $score(x_i, x_j)$ is a function that computes\nthe compatibility between $x_i$ and $x_j$, commonly\nimplemented using a dot product or a feed-\nforward neural network. Following the\ncomputation of the attention scores, the output\nvectors $y_i$ are computed as a weighted sum of\nthe input vectors $x_j$, with the weights being the\nattention scores $\\alpha_{ij}$:\n$Y_i = \\sum \\alpha_{ij}x_j$ (6)\n3.3.2. SACC Architecture implementation\nAs stated earlier, various medical studies\nsuggest the influence of patient characteristics\n($P_c$) on heart conditions. For example, smoking\nhabits degrade the heart's capacity to pump\nblood [33]. So, it is essential to study the effect\nof $P_c$ on ECG morphology ($E_m$) for a more\npersonalized diagnosis. To bridge the gap in the\ncorrelation analysis of $P_c$ and $E_M$, we\nintroduced the SACC (Self-Attentive\nCanonical Correlation) layer to learn $P_c$'s\ninfluence on $E_m$ explicitly."}, {"title": "3.4. rECGnition_v2.0 Architecture\nimplementation", "content": "A novel model architecture (Figure 3, Table 2)\nthat combines depth-wise separable\nconvolution, DPN, and SACC was developed."}, {"title": "3.4.1. rECGnition_v2.0 Computational\nEfficiency Considerations", "content": "The theoretical computational complexity\nassessment was required as this study tried to\ncreate a computationally efficient model for\narrhythmia classification. Hence, we have\nextensively analysed the constituting\nrECGnition_v2.0 components to find out the\nBig-O complexity in terms of input image size\nand kernel size. The proposed architecture can\nbe broken down into 3 major blocks, each\ndistinguished by its unique operational\nmethodology. So, we analysed each blocks\ncomputational complexity separately.\nInitial convolution used with different\nreceptive fields (DPN) have the complexity of\na simple convolution operation performed on an\ninput size of H' \u00b7W' with $K_1$ and $K_2$ kernel\nsizes. Each element in the output feature map is\nobtained by performing a convolution operation\nwhich entails $K^2 N$ multiplications and\nadditions where N is the number of\nchannels.Given that each filter traverses the\nentire input matrix to generate the\ncorresponding output feature map, the total"}, {"title": "Depth-wise Convolution:", "content": "Depth-wise Convolution: The depth-wise\nconvolution operates on each input channel\nseparately with a distinct kernel per\nchannel. The computational complexity for\nthis phase can be encapsulated as O(N.\n$K^2$ \u2022 H' \u00b7 W').\nPointwise Convolution: The pointwise\nconvolution is essentially a (1\u00d71)\nconvolution that combines the outputs of\nthe depthwise convolution across channels.\nThe computational complexity for this\nphase is given by O(N\u00b7 M \u00b7 H' \u00b7W')."}, {"title": "The SACC layer", "content": "The SACC layer is the combination of attended\nfeature projections merged using a fully\nconnected layer. Thus, the computational\ncomplexity for taking projection operations is\nO($D\u00b2$ \u00b7 M + $D\u00b2$ \u00b7 M) and applying attention\nmap to it is 0(2M). The dense layer operation\nis also a matrix multiplication with a\ncomplexity of O(2M \u00b7 M) where $D_1$ and $D_2$ are\nthe dimension of input vectors to the SACC,\nand M represents the output dimension of the\nSACC."}, {"title": "3.5. Data Acquisition and Pre-processing", "content": "This study exploited the MITDB [34, 35] for\nexperimentation and model evaluation."}, {"title": "4. Experiment Setup", "content": "In our experimental setup, we trained\nrECGnition v2.0 with the following\nhyperparameters on Google colab GPUs and\nTPUs (TPUs were primarily used in early\ndevelopment of the model development due to\nTPU's faster training time): a batch size of 32,\ntraining for 40 epochs (1570 steps per epoch),\nand an image input size of 128x128 pixels. The\ninitial learning rate was set to 0.01, and the\nAdam optimizer (described in detail in section\n4.1) was employed for parameter updates. To\nensure reproducibility, the random seed was\nfixed at 257. To enhance the learning process,\nwe integrated a cosine learning rate scheduler\nwith warmup steps. Specifically, the learning\nrate scheduler was configured with an initial\nlearning rate of 0.01 and warmup steps was 5.\nThe scheduler follows a cosine decay pattern\nwith 0.5 cycles over the course of the training.\nThe learning rate $\u03b7(t)$ at epoch $t$ was computed\nas follows:\n$n(t) = \\begin{cases}\nIr x \\frac{t}{max(5,num\\_warmup\\_steps)} & if t \\textless num\\_warmup\\_steps \\\\\nIr x 0.5 + cos x \\frac{num\\_cycles\u00d72\u00d7(t-num\\_warmup\\_steps)}{num\\_training.steps-num\\_warmup.steps} & otherwise\n\\end{cases}$\nwhere num_training_steps = EPOCHES. This\nlearning rate schedule allows for a smooth\nadjustment of the learning rate, starting with a\ngradual warmup phase followed by cosine\ndecay, which helps in stabilizing the training\nprocess and potentially improving model\nperformance. The training convergence of\ncategorical cross-entropy loss is given in Suppl.\nFigure S2. Moreover, the total dataset was\nsplitted into 9:1 ratio of training and testing."}, {"title": "4.1 Optimization", "content": "Optimization is pivotal in navigating the vast\ntrainable parameter space to find a set of\ntrainable parameters that minimize the loss\nfunction, thereby ensuring the model's\nadeptness in making accurate predictions. The\nAdam optimizer, known for its efficacy in both\nsparse gradients and noisy data scenarios, was\nemployed in this study. The Adam optimizer\noperates as per the following update rules:\n$mt = \u03b2\u2081mt-1 + (1 - \u03b2_1)gt$ (11)\n$vt = B_2Vt-1 + (1 \u2212 \u03b2_2)g^2$ (12)\n$Vt =\n\\frac{Vt}{1-\u03b2^t_2}$ (13)\n$\\hat{mt} =\n\\frac{mt}{1-\u03b2^t_1}$ (14)\n$\\hat{\\theta_t} = \\theta_{t-1} \u03b1 \\frac{mt}{\\sqrt{v_t} + \\epsilon}$ (15)\nWhere $\\theta$ represents the parameters, g\nrepresents the gradients, m and vare moment\nestimates, $B_1, B_2$ are the exponential decay rates\nfor the moment estimates, a is the learning rate\nand e is a small value to prevent division by\nzero."}, {"title": "4.2 Regularization", "content": "Regularization is standard for preventing\noverfitting, especially in scenarios where the\nmodel's complexity is high. Dropout is a basic\nyet effective regularization technique that\nrandomly eliminates a portion of the neurons\nduring training, preventing any single neuron\nfrom becoming overly specialized. The dropout\noperation is expressed as:\n$Yi = Xi Zi$ (16)\nwhere $x_i$ is the input to a neuron, $y_i$ is the\noutput, and $z_i$ is a Bernoulli random variable\nwith probability p of being 1. Suppl. Table S1\nsummarises the ablation study for different\ndropout values used inside the image processor\nunit and near the output layer to study the effect\nof\nregularization\non rECGnition_v2.0's\nperformance."}, {"title": "5. Results and Discussion", "content": "5.1. Model Performance Evaluation\nTo assess the efficacy of rECGnition_v2.0, the\nprecision (P), recall (R), and F1-score were\nevaluated for each class. For the class 'f', the\nrECGnition_v2.0 achieved perfect precision,\nrecall, and F1-score (Table 3), suggesting that it\nis exceptionally proficient in identifying this\ncategory. A similar trend of high performance\nwas observed in classes 'L', 'N', 'R', and 'V',\ndemonstrating precision and recall above 95%,\nindicative of the robustness of the\nrECGnition v2.0 framework. The medium\nvariant of the model, also showed similar/high\nprecision and F1-score, demonstrating\nscalability of the model (Suppl. Table S3).\nFigure 5 represents the ROC-AUC curve of"}, {"title": "5.2. Enhanced Feature Representation and\nImportance", "content": "SACC is a better way to figure out how patient-\nspecific factors like age and gender affect the\nshape of an ECG heartbeat. The self-attention\nmechanism in SACC provides a glimpse into\nthe feature importance. Figure 6 represents the\nactivation regions of the heartbeat for only\nimage feature embedding and embedding\ngenerated after applying SACC; it shows that\nthe model has learned to select the critical\nregions like the start of different Em segments,\nlocation of changes, etc. (which define the\nstructure of the PQRST construct) more\nprecisely.\nThe PCA[rECGnition_v2.0] of distinct classes\nof arrhythmia peeks into the inner working of\nrECGnition_v2.0 which exhibited a degree of\nlinear separability, particularly for certain\nclasses such as 'f' and 'j', which align along\nunique trajectories (Figure 7). This indicates\nthat the rECGnition_v2.0 model has learned to\nextract features that result in a feature space\nwhere arrhythmia classes are distinctly"}, {"title": "5.3. Additional Experiments", "content": "Various set of additional experiments were\nperformed to better understand the\nrECGnition_v2.0 results, i.e. compared the\nperformance of with and without meta data, and\ncarried out the ablation study of DPN. To\nfurther strengthen the performance and\ngeneralization capabilities of rECGnition_v2.0\nwe expanded our experiment to include the\nINCARTDB and EDB dataset. Additionally,\nwe also compared rECGnition_v2.0 with\nSOTA models which showed rECGnition_v2.0\nexhibits the improved efficacy for these set of\nexperiments as well."}, {"title": "5.3.1. With and without patient data analysis", "content": "For arrhythmia detection, two conditions were\ncompared: one considering only ECG data and\nanother incorporating patient characteristics.\nThe plot (Suppl. Figure S3) reveals that the\nintegration of patient characteristics generally\nenhances the F1-score across most arrhythmia\nclasses supporting our methodology, with\nnotable improvements in classes 'A', 'F', 'V', 'f',\nand 'j'. This enhancement underscores the value\nof including demographic parameters along\nwith ECG in deep learning models. Particularly,\nfor class 'F', there is a significant leap in F1-"}, {"title": "5.3.2. Analysis of the Dual Pathway\nMechanism", "content": "The deeper analysis of dual pathway\nmechanism was performed to test influence of\nshorter and longer receptive fields.\nWhen compared with single pathway i.e. only\nsmaller receptive fields, DPN demonstrated\nimproved performance; the improvement is\napparent where single pathway poorly performs\nsuch as 'a' and 'j' classes (Suppl. Table S4).\nUsing Grad-Cam visualization, we observed\nthat bigger receptive fields tries to discard local\nchanges (Figure 8), the bigger kernel's\nindividual feature map has more smoothened\nand dilated ECG signal construct which shows\naggregation of information at larger scale, by\ndiscarding local aberrations."}, {"title": "5.3.3. Comparative analysis with other SO\u03a4\u0391\nCNN models", "content": "The rECGnition_v2.0 models were compared\nagainst MobileNet, ResNet50\nand\nEfficientNetB0 to determine its performance\ncharacteristics. The accuracy is highest among\nall for rECGnition_v2.0 (Suppl. Table S5) with\nthe lowest FLOPs, trainable parameters, and\nmaximum predictions per second depicting\nrECGnition_v2.0's ability to outperform SOTA\nCNN models for ECG classification task with\nlowest computational requirement and\nmaximum speed. While overall accuracy\nincreased only by 1% for the proposed model,\nwhich might not seem so significant, the model\nhas performed remarkably well for arrhythmia\nclasses that have lower occurrences (Figure 9,\nTable 3)."}, {"title": "5.3.4. Computational Efficiency Analysis", "content": "For real-time clinical implementation of such a\nmodel, low computational requirement of the\nmodel is an essential need. rECGnition_v2.0 is\ndesigned and developed with the aim of clinical\ndeployment; thus, it obeys the low\ncomputational requirement for the model. As\ncompared with other SOTA CNN-based\nmodels, we can see that rECGnition_v2.0 is\nahead of those models by a significant margin"}, {"title": "5.3.5. Generalization Assessment", "content": "We have performed additional set of\nexperiments on INCARTDB [35] and EDB\n[38], which are different datasets, and on\nMITDB on AAMI beats. This assessment setup\naimed to showcase rECGnition_v2.0's ability\nto generalize on wide range of data\ndistributions. As shown in Table 4, the\nempirical evidence suggests that the model not\nonly preserves its predictive accuracy but also\nadapts to the intricacies and variations\npresented by different classification\ndatasets/groups. Furthermore, it concluded that\nthe model didn't overfit the MITDB dataset."}, {"title": "5.4 Comparative analysis", "content": "A thorough comparison of the rECGnition_v2.0\nmodel with other advanced approaches for\narrhythmia classification was carried out (Table\n5). The benchmark datasets used for evaluation\nwere MITDB, INCARTDB and EDB. The basis\nof our comparison revolved on many crucial\naspects, including the total F1-score, prediction\nspeed, computing efficiency, and generalization\non\ndifferent dataset distributions. The\nrECGnition_v2.0 model exhibited outstanding\nperformance in terms of F1-score, attaining\nremarkable values of 99.01%, 98.21%, and\n98.05% in the 5-class, 8-class, and 10-class\narrhythmia classification tasks, respectively.\nThese findings highlight the model's\nexceptional accuracy and ability to perform\nwell across different degrees of categorization\ncomplexity. One notable feature of\nrECGnition_v2.0 is its exceptional prediction\nspeed, averaging around 34 milliseconds per\ninput sample. This improved efficiency is a\nnotable progress in enabling real-time diagnosis\nof arrhythmia, which has the potential to\nimprove patient outcomes by allowing prompt\nintervention. Houssein et al. [39] and Chen G et\nal. [40] proposed work has depicted better F1-\nscores than rECGnition v2.0 because of the\nhand-crafted features used in both the\nmethodology; although the overall prediction\ncapability of model is more but the hand-crafted\nfeature methodologies are more prone to errors\nas any failure in feature extraction will\npropagate to classifier [41]. The LSTM-\nAutoencoder model proposed by Liu et al. [42]\nhas shown reduced computational requirements\nand achieved an F1-score of 97.75%. However,\nit is crucial to acknowledge that its sequential\ndata processing leads to prediction speeds that\nare five times slower compared to\nrECGnition_v2.0."}, {"title": "6. Conclusion", "content": "A unique deep-learning architecture was\nproposed to enhance the accuracy of patient-\nspecific diagnosis for individuals with\narrhythmia. The rECGnition_v2.0 model shows\nits enhanced capacity for representing ECG\nfeatures while also including the understanding\nof patient context. In comparison to traditional\nCNN models that have been previously used as\nECG feature extractors in research on\narrhythmia classification, the rECGnition_v2.0\ndemonstrates a much lower computational cost.\nThis is supported by the observation that the\nrECGnition_v2.0 requires considerably fewer\nfloating-point operations (82.7 million FLOPs).\nSignificantly, the computational need of the\nmentioned model is around 20% of MobileNet\nwith an alpha value of 1 and input dimensions\nof 128x128x1. Furthermore, it is only 1% of the\ncomputational requirement of EfficientNetB0\nwith input dimensions of 128x128x1.\nAdditionally, rECGnition_v2.0 was endowed\nwith a modest 450,000 trainable parameters.\nThe study's primary contribution was the\nincorporation of the Attention-based Canonical\nCorrelation layer (SACC), which effectively\nfacilitated the model in identifying individual-"}, {"title": "CRediT author statement", "content": "Shreya\nSrivastava: Conceptualization,\nMethodology, Software, Validation, Formal\nanalysis, Investigation, Data curation,\nVisualization, Writing - original draft. Durgesh\nKumar: Software, Validation, Formal analysis,\nInvestigation, Data curation, Visualization.\nRam Jiwari: Formal analysis, Mathematical\nValidation, Writing \u2013 reviewing and editing.\nSandeep Seth: Conceptualization, Writing\nreviewing and editing. Deepak Sharma:\nConceptualization,\nData\ncuration,\nVisualization, Writing - reviewing and editing,\nResources, Project administration, Funding\nacquisition, Supervision."}]}