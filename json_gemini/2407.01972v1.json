{"title": "MeMemo: On-device Retrieval Augmentation for Private and Personalized Text Generation", "authors": ["Zijie J. Wang", "Duen Horng Chau"], "abstract": "Retrieval-augmented text generation (RAG) addresses the common limitations of large language models (LLMs), such as hallucination, by retrieving information from an updatable external knowledge base. However, existing approaches often require dedicated back-end servers for data storage and retrieval, thereby limiting their applicability in use cases that require strict data privacy, such as personal finance, education, and medicine. To address the pressing need for client-side dense retrieval, we introduce MEMEMO, the first open-source JavaScript toolkit that adapts the state-of-the-art approximate nearest neighbor search technique HNSW to browser environments. Developed with modern and native Web technologies, such as IndexedDB and Web Workers, our toolkit leverages client-side hardware capabilities to enable researchers and developers to efficiently search through millions of high-dimensional vectors in the browser. MEMEMO enables exciting new design and research opportunities, such as private and personalized content creation and interactive prototyping, as demonstrated in our example application RAG PLAYGROUND. Reflecting on our work, we discuss the opportunities and challenges for on-device dense retrieval. MEMEMO is available at https://github.com/poloclub/mememo.", "sections": [{"title": "1 INTRODUCTION", "content": "Retrieval augmented generation (RAG) [39] with large language models (LLMs) has gained immense popularity from both practi-tioners and researchers, especially in applications such as domain-specific chatbots [58, 64], code generation [67, 80], and interactive agents [27, 62]. RAG can improve the accuracy and reliability of LLMs' generated text [65], by providing these models, such as GPT-4 [56] and Llama 2 [69], with context information retrieved from an updatable and external knowledge base. Compared to other tech-niques, such as fine-tuning [28] and prompt tuning [38], that aim to improve LLM's performance on new or specific domains, RAG is often favored by AI practitioners [48] due to its ease of implemen-tation, flexibility in maintenance, and superior performance [57].\nHowever, current RAG systems rely on dedicated backend servers to store and retrieve external documents relevant to the user's query. This is often achieved through nearest neighbor search using dense embedding vector representations of documents [4, 40]. The need for centralized backend servers limits the applicability of RAG in domains that prioritize data privacy, such as personal finance, educa-tion, and medicine [e.g., 11, 21, 22, 76]. Furthermore, implementing and hosting a vector storage and dense retriever pose additional challenges for Al novices and everyday LLM users [15, 78], thereby increasing the barrier to entry for learning and applying RAG.\nTo address these pressing challenges, we present MEMEMO, the first JavaScript toolkit that offloads vector storage and dense re-trieval to the client-empowering a broader range of audiences to leverage cutting-edge retrieval techniques to enhance their LLM experiences. Our work makes the following key contributions:\n\u2022 MEMEMO, the first scalable JavaScript library that enables users to store and retrieve large vector databases directly in their browsers. Our toolkit adapts the state-of-the-art approximate nearest neighbor search Hierarchical Navigable Small World graphs (HNSW) [47] to the Web environment. By leveraging a novel prefetching strategy and modern Web technologies, such as IndexedDB and Web Workers, MEMEMO empowers users to retrieve dense vectors with both privacy and efficiency (\u00a7 3).\n\u2022 RAG PLAYGROUND, an example application of on-device dense retrieval. We demonstrate the capabilities of MEMEMO by developing RAG PLAYGROUND (Fig. 1), a novel client-side tool us-ing on-device retrieval to enable interactive learning about RAG and rapid prototyping of RAG applications (\u00a7 2). We highlight"}, {"title": "2 MEMEMO IN ACTION", "content": "We present two hypothetical usage scenarios, developing (\u00a7 2.1) and using (\u00a7 2.2) RAG PLAYGROUND, to demonstrate how researchers and practitioners can use MEMEMO to easily develop client-side applications that take advantage of on-device RAGs."}, {"title": "2.1 Developing In-browser RAG Tools", "content": "Motivations. Assume an example scenario where Mei, a machine learning (ML) consultant, is currently developing an LLM-based chatbot for a large design studio. The chatbot's purpose is to as-sist new-hired designers in familiarizing themselves with the com-pany's internal design systems and tools. To ensure accurate and reliable responses, Mei integrates RAG into this onboarding chatbot. This integration allows the responses to be grounded by relevant documentation, design documents, and code. Initially, Mei uses Jupyter Notebooks [35] to prototype the chatbot through prompt engineering in Python. However, she realizes that this workflow is not ideal for collaborating with designers and introducing RAG to her clients. This is because many of the collaborators and stake-holders are not experienced in programming and setting up note-book environments. Therefore, Mei decides to develop RAG PLAY-GROUND (Fig. 1), a web-based no-code RAG prototyping tool. This tool will enable her collaborators, who come from diverse back-grounds, to easily access and prototype RAG features for their chatbot through their web browsers.\nVector storage and retrieval with MEMEMO. Mei uses MEMEMO, a JavaScript library, to enable dense vector storage and retrieval directly in the browser. By installing the library with a single com-mand npm install mememo, Mei can easily import it into her web app, regardless of her web development stack (e.g., JavaScript, Type-Script, React [16], Svelte [25], or Lit [24]). With just a few lines of code (Code 1), Mei can create an HNSW vector index [47] and efficiently search through millions of embedding vectors entirely within her browser. Mei also uses MEMEMO's exportIndex() and loadIndex() functions to export an index she has created into per-sistent local storage or as a JSON file. This allows her collaborators"}, {"title": "2.2 Prototyping with RAG PLAYGROUND", "content": "Motivations. Robaire, a graduate student studying human-computer interaction, is designing an interactive visualization tool to assist researchers in brainstorming and literature review. After discov-ering RAG online, Robaire becomes interested in integrating it into his prototype. The objective is to allow users to input a large corpus of academic papers and use natural language queries to dis-cover related papers and visualize the connections between them.\nSince Robaire has never implemented RAG before, he turns to RAG PLAYGROUND to learn about the concept and prototype for his tool.\nLearning and experimenting with\nRAG. After opening RAG PLAYGROUND in\nthe browser, Robaire creates a MEMEMO\ndatabase (Fig. 1B) by uploading a JSON file\ncontaining the abstracts of 120k arXiv ML\npapers and 384-dimensional embeddings\nof the abstracts. Robaire then pretends to\nbe his end-users and types in a natural lan-\nguage query in the User Query View, such\nas \"how to integrate information retrieval\ninto ML?\" (Fig. 1A). In addition, he writes a simple system prompt"}, {"title": "3 MEMEMO DESIGN AND IMPLEMENTATION", "content": "MEMEMO is the first JavaScript toolkit that enables dense retrieval in the browser. To enable fast and reliable retrieval for RAG, our tool adapts the state-of-the-art approximate nearest neighbor search technique HNSW (\u00a7 3.1). MEMEMO leveraging modern and native Web technologies, such as IndexedDB and Web Workers (\u00a7 3.2), to optimize for browser environments. To help researchers and developers adopt MEMEMO, we have open-sourced it and provided detailed documentation, tutorial, and an example application (\u00a7 3.3)."}, {"title": "3.1 Adapting HNSW", "content": "HNSW is a state-of-the-art approximate k-nearest neighbor search technique introduced by Malkov and Yashunin. It is inspired by the greedy graph routing used in navigable small world networks [6, 34] and the stochastic hierarchical structure in 1D probabilistic skip list [59]. HNSW uses a multilayered graph structure to connect high-dimensional dense vectors. During the insertion process, each new element is assigned a layer level at random, determining its position within the graph's multi-layered hierarchy. The insertion process involves finding the element's closest neighbors, starting from the top layer and working downwards using a greedy search approach. When searching for the nearest neighbors of a query element, the algorithm follows a similar procedure. It starts from the top layer and uses the connections established during the insertion phase to guide its search downwards.\nWe use HNSW as the approximate nearest neighbor search tech-nique in MEMEMO because it is the state-of-the-art regarding con-struction and query efficiency [47]. Additionally, HNSW has gained immense popularity among retrieval and AI practitioners and has been integrated into popular retrieval and RAG Python toolkits such as FAISS [14], Pyserini [42], PGVector [32], and LangChain [8]. Our goal with MEMEMO is to seamlessly integrate into users' exist-ing workflows and preferences, providing a smooth and familiar experience when developing in-browser retrieval applications."}, {"title": "3.2 Optimizing for the Browsers", "content": "Memory management. Memory management is one of the main challenges for developing in-browser toolkits. Depending on the de-vice and browser, a webpage tab might have a RAM limit as low as 256MB [46]. This means that without considering any other mem-ory usage on a webpage, it can store at most 83k 384-dimensional vectors in RAM. Additionally, for security reasons, browsers do not allow access to the operating system's file systems, so MEMEMO"}, {"title": "3.3 Open-source and Easy to Use", "content": "To help researchers and developers easily adopt MEMEMO, we open source our implementation and design APIs similar to popular HNSW Python libraries [e.g., 14, 47, 81]. Users can easily config-ure all HNSW parameters, such as M (the number of neighbors a graph node can have) and efConstruction (the number of nodes to search during construction). With just a few lines of code (Code 1), users can quickly implement dense retrieval in web browsers us-ing MEMEMO. We provide detailed documentation and tutorials. Additionally, we offer an open-source example application RAG PLAYGROUND that demonstrates the integration of MEMEMO with existing Web ML technologies (\u00a7 2.1). RAG PLAYGROUND also shows how to use MEMEMO with modern Web APIs, including Web Work-ers [52] to prevent blocking the main thread and Streams API [51] for creating an HNSW index incrementally with small network-received chunk. MEMEMO is published in the popular Web package repository npm Registry, and can be easily installed and used in both browser and Node.js [13] environments."}, {"title": "4 RELATED WORK", "content": "Retrieval-augmented text generation. There has been a long history of using information retrieval to enhance text generation, such as developing language models through retrieval [37], using a retrieve-and-edit framework to improve code generation [26], and incorporating knowledge graphs to enhance language representa-tion in language models [79]. The concept of RAG was popularized by Lewis et al., who introduced a model that combines a dense passage reliever and sequence-to-sequence models. More recent approaches [e.g., 12, 29, 55, 60] use pre-trained embedding models to encode external documents as dense vectors and retrieve relevant documents using dense retrievers such as HNSW [47], PQ [30], and FAISS [14]. MEMEMO builds upon these works and extends RAG to the client side for more private and personalized text generation.\nOn-device retrieval and machine learning. Traditional retrieval and machine learning (ML) systems are typically deployed on re-mote servers, and their outputs are sent to client devices. However, there has been a recent surge of interest in deploying ML mod-els directly on edge devices in the pursuit of private, ubiquitous, and interactive ML experiences. Tools such as TensorFlow.js [66], ONNX [3], MLC [10, 54], and Core ML [2] have significantly re-duced the barriers to running complex ML models in browsers and mobile devices. Researchers have proposed various on-device systems, including information retrieval [31, 36], recommender systems [23, 77], prediction explanation [71, 73, 74], speech recog-nition [44, 45], translation [68], and writing assistants [70]. Our tool contributes to the growing body of on-device ML research by introducing the first adaptation of dense retrieval to browsers."}, {"title": "5 DISCUSSION AND FUTURE WORK", "content": "Reflecting on our development of MEMEMO, we highlight the op-portunities and challenges for in-browser dense retrieval.\nOpportunities. Enabling dense retrieval and RAG in browsers offers significant advantages regarding privacy, ubiquity, and in-teractivity. With the browser's ubiquity, MEMEMO is accessible on various devices, including laptops, mobile phones, and IoT appli-ances like smart refrigerators. Future research directions include:\n\u2022 Intelligent personal information management. There is a large body of research on collecting all of one's personal informa-tion into a searchable database [e.g., 5, 7, 9, 20, 33]. Researchers can leverage on-device dense storage and retrieval to design browser extensions that automatically and privately encode and store a user's visited web pages, photos, and academic papers. These extensions can serve as an intelligent \u201csecond brain\" [19] to help users capture and review knowledge.\n\u2022 Private and personalized content creation. If users maintain a personal vector database in browsers, content creators, such as book writers, can use on-device RAG to tailor their content privately based on readers' preferences and reading history.\n\u2022 Interactive RAG prototyping. Future researchers can enhance the design of RAG PLAYGROUND to improve interactive RAG prototyping experience, such as supporting collaborative prompt editing [18] and interactive embedding visualizations [72].\nChallenges. Due to limited computation resources in browsers, MEMEMO is slower than heavily optimized libraries like HNSWLIB [47] in terms of index creation and search. In Chrome on a 64GB RAM MacBook, it took about 94 minutes to insert 1 million 384-dimensional vectors (M=5, efConstruction=20). However, querying this index with 1M items is still performed in real time. Future researchers can optimize in-browser dense retrieval further by implementing parallelization and smarter prefetching techniques.\nConclusions. We present MEMEMO, an open-source library that enables in-browser dense retrieval using HNSW and modern Web technologies. We introduce RAG PLAYGROUND, a novel client-side RAG prototyping tool to demonstrate the capabilities of MEMEMO. We hope MEMEMO to be an easy-to-use resource for the informa-tion retrieval and ML community, inspiring future research and development of on-device retrieval and RAG applications."}]}