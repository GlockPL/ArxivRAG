{"title": "Synthetic Human Memories: Al-Edited Images and Videos Can Implant False Memories and Distort Recollection", "authors": ["Pat Pataranutaporn", "Chayapatr Archiwaranguprok", "Elizabeth Loftus", "Samantha W. T. Chan", "Pattie Maes"], "abstract": "Al is increasingly used to enhance images and videos, both intentionally and unintentionally. As AI editing tools become more integrated into smartphones, users can modify or animate photos into realistic videos. This study examines the impact of AI-altered visuals on false memories\u2014recollections of events that didn't occur or deviate from reality. In a pre-registered study, 200 participants were divided into four conditions of 50 each. Participants viewed original images, completed a filler task, then saw stimuli corresponding to their assigned condition: unedited images, AI-edited images, AI-generated videos, or AI-generated videos of AI-edited images. Al-edited visuals significantly increased false recollections, with Al-generated videos of AI-edited images having the strongest effect (2.05x compared to control). Confidence in false memories was also highest for this condition (1.19x compared to control). We discuss potential applications in HCI, such as therapeutic memory reframing, and challenges in ethical, legal, political, and societal domains.", "sections": [{"title": "Introduction", "content": "If a device existed that could help reframe your worst day in a more positive light, would you choose to use it? Memory-editing technologies have been a central theme in science fiction, prominently featured in works such as Eternal Sunshine of the Spotless Mind, Men in Black, Total Recall, and Inception [86]. However, techniques for altering human memories are not confined to the realm of fiction, as they represent a heavily studied area within psychology and cognitive science [80].\nFalse memories, which refer to recollections of events that either never occurred or are significantly distorted from reality, have been a major focus in psychology research. The study of false memories is vital because they can distort witness testimonies, disrupt legal processes, and lead to faulty decision-making based on incorrect information. Given these broad implications, understanding how false memories form is a critical area of investigation [31, 62, 63, 66, 96, 119]. Unlike typical forms of misinformation [117], false memories are particularly insidious because the individual genuinely believes they recall accurate events, making them resistant to correction and potentially more influential in shaping beliefs and behaviors [60, 64]. Moreover, false memories can serve as a seed for making people more susceptible to additional false information [46, 102], creating a cascading effect that further distorts perceptions of reality and complicates efforts to establish accurate historical or personal narratives.\nResearch by Loftus and Palmer [65] showed how the wording of questions can significantly influence eyewitness memory. When participants watched a video of a car accident, their estimates of speed estimates varied based on the verb used in the question (e.g., \"collided,\" \"smashed\", \"bumped,\" \"contacted,\u201d or \u201chit\u201d). Additionally, the \"Lost in the Mall\" study [66] demonstrated that entirely false childhood memories could be implanted. In a more recent replication [78], a larger sample size revealed that 35% of participants reported a false memory of being lost in a mall during childhood, compared to 25% in the original experiment. These findings strengthen the validity of the initial study and emphasize the relevance of such phenomena in legal settings.\nIn the context of visually induced false memories [91, 98, 108], researchers have shown that exposure to images of fictitious events, such as a hot-air-balloon ride, can lead to the formation of false memories related to the depicted experience [28]. Researchers have employed various methods to visually induce false memories, including single presentations of thematic scenes with omitted elements [77], personal photographs [56], and narrative instructions during interviews [107]. In a notable study, fifty percent of participants developed complete or partial false memories after exposure to a fake childhood photograph and guided imagery exercises over three interviews. These findings have significant implications for clinical and legal professionals working with memory-related cases [107].\nHowever, these studies have predominantly been conducted in controlled laboratory settings, where images are manually edited by researchers and interviews are carefully planned. The process also involves human intervention in establishing trust, guiding participants, and presenting the manipulated images, which inherently limits the scope and scale of false memory induction. With recent advancements in artificial intelligence (AI), however, these limitations are beginning to change. Al has the potential to automate and scale the creation and presentation of manipulated content, significantly expanding the possible impact of false memories on individuals.\nAl-powered image enhancement is also increasingly becoming a standard feature in smartphones and cameras, operating both at capture and during post-processing. At the moment of capturing, AI may automatically remove unwanted elements or combine the best parts from multiple shots, as seen in Google's \"Best Take\" feature [25]. After the shot, applications such as Apple Photos, Google Photos, and Samsung's Galaxy AI provide AI tools by default for users to edit, remove, or alter photo features with just a few steps. Additionally, generative AI models, such as OpenAI's Sora, Luma's Dream Machine, and Kling, are increasingly used to animate static images into realistic-looking videos.\nThe unprecedented proliferation of AI-driven image editing and video manipulation technologies has raised significant concerns regarding the integrity of consumed information. We argue that AI-generated content contributes to misinformation by distorting our understanding of the present (e.g., deepfakes) as well as reshaping how we remember the past. AI-generated media can potentially create false memories and lead individuals to recall past events differently than they actually occurred and were initially experienced. The implications of these technologies span both personal and societal domains, as illustrated in figure 2.\nOn a personal level, there has been a notable trend, particularly on social media platforms such as TikTok, of users employing AI to animate photographs of deceased family members, simulating interactions with departed loved ones. On a broader scale, the potential for AI-generated content to influence collective memory and historical narratives poses significant challenges to societal understanding and cohesion, potentially altering public perceptions of past events and shaping future decision-making processes. For example, Al-edited images of public gatherings or protests could subtly alter the perceived scale or mood of these events, gradually reshaping how participants and observers remember their personal experiences and consequently influencing the collective memory of significant social movements.\nA crucial distinction must be made between deepfakes and AI-edits, as both leverage generative AI but differ significantly in their"}, {"title": "2 Methodology", "content": "This study examines how AI-edited images and videos influence the formation of false memories. Specifically, we aim to assess whether exposure to AI-modified visuals affects individuals' recollections of the original scenario. In a pre-registered between-group experiment (AsPredicted #188511 - not yet public for anonymity), 200"}, {"title": "2.1 Study Design Rationale", "content": "We particularly designed the study to simulate situations where individuals encounter AI-edited media in everyday contexts, particularly through social media and news platforms. In these scenarios, images are often anonymously altered or automatically edited by Al filters, frequently without the user's knowledge. The study also examines cases where others in the user's social circle, such as friends or family members, might edit personal images on behalf of the user without fully informing them of the details. In the \"Future Research\" section, we recommend exploring the impact of Al on false memories when people edit images themselves. We hypothesize that individuals may eventually forget they made these edits, potentially resulting in an effect similar to the scenarios described earlier. Our study's design incorporates key elements reflective of how people currently interact with digital content, offering insights into the potential risks associated with AI-manipulated media.\n2.1.1 Al-Enhanced Media is Ubiquitous. With the increasing integration of Al-powered image and video editing tools in widely-used applications like Instagram, TikTok, and news websites, and increasingly in phone cameras themselves. For example, features like Google's \"Best Take\" [25] can remove unwanted elements or combine the best parts of multiple shots seamlessly. Apps such as Apple Photos, Google Photos, and Samsung's Galaxy AI offer built-in Al tools that allow users to easily edit, remove, or alter photo features with just a few simple steps. Users are frequently exposed to content that has been altered, often without their knowledge. Our study reflects this reality by introducing both static (AI-edited images) and dynamic (AI-generated videos) content, highlighting the various forms in which individuals might encounter altered depictions of events in their daily lives. Additionally, we explore scenarios where Al-generated videos are created based on AI-edited images, representing a multi-layered approach to content generation.\n2.1.2 Use of Al Labels in Media. As social media platforms begin to introduce labels indicating that content has been altered or generated by AI, our study incorporates a similar label to investigate its effectiveness. Participants in all conditions were shown images with a label indicating \"enhanced image\". This feature provides an ecologically valid environment to explore whether transparency about manipulation impacts participants' memory accuracy, offering real-world insights.\n2.1.3 Minimal Verification by Users. While in the real world, individuals have the ability to fact-check or search for original images to verify what they see, research indicates that most people"}, {"title": "2.2 Stimulus Sets and Experiment Conditions", "content": "Our study employed a diverse set of visual stimuli to investigate participants' perceptions and reactions to various types of media. The stimulus set comprised four distinct categories: unedited images, Al-edited images, AI-generated videos from unedited images, and AI-generated videos from Al-edited images:\n\u2022 Control (unedited images): Contains 24 copyright-free images curated by researchers. The image set includes political figures, such as politicians shaking hands with other leaders; personal pictures, such as views taken from a trip; and documentary pictures, such as a NASA astronaut portrait.\n\u2022 AI-edited images: From the unedited set, we used Adobe Photoshop Al to edit 12 images by either removing, adding, or altering details of the pictures (The remaining 12 were left unedited as a group homogeneity check). As shown in Figure 4, edits are categorized into 3 groups: Targeting people (changing the woman's expression, changing the runner's ethnicity, changing the gender of a person in the group), targeting environment (removing the ice melt, changing the time of day, changing the background setting),"}, {"title": "2.3 Measurement", "content": "Participants were presented with a Memories Test Questionnaire consisting of 24 questions regarding their memory of the original, unedited images. Each question included a picture with the key detail of interest masked, while still providing enough context for participants to understand which image was being referenced. \nThese questions assessed whether participants recalled specific details from the images, such as objects, people, or environmental elements (e.g., \"Did you remember seeing the bride smiling in the original picture?\"). The participant could either answer agree, disagree, or unsure. In addition, participants rated their confidence on a 7-point scale from 1 (extremely lacking confidence) to 7 (extremely confident).\nFor the moderating factors, to measure AI Filter Familiarity, participants indicated their familiarity with using image or Al filter technologies on a 7-point scale (1 = Not familiar at all, 7 = Very familiar). Frequency of Forgetting, adapted from [116], assessed participants' general memory performance, with responses ranging from 1 (Major problems) to 7 (No problems). Memory Efficacy was measured using a subset of items from [4], where participants rated their ability to remember visual and verbal information, such as recalling names and objects, on a 7-point scale (1 = Strongly disagree, 7 = Strongly agree). Finally, Skepticism was assessed using a scale adapted from [23], where participants rated their agreement with statements reflecting distrust in official information (e.g., \"The official media provides false information\") on a 7-point scale (1 = Strongly disagree, 7 = Strongly agree)."}, {"title": "2.4 Experiment Protocol", "content": "The experiment was conducted using Qualtrics. A total of 200 participants were recruited from CloudResearch, with an equal 1:1 ratio of female to male participants. The study was limited to individuals residing in the United States, and participants ranged in age from 20 to 73 years old, M=38, s.d.=12.25. The experimental procedure began with participants signing a consent form, which included a disclosure regarding the possibility of deception in the study.\nIn the questionnaire's introduction, participants are informed that they will be presented with a set of images, followed by their corresponding \"filtered\" versions, and after observing both sets, they will be asked to provide \"feedback\" on the filter through a series of questions.\nAn initial attention check was administered to ensure focus. Participants were then shown a set of 24 unedited images for two"}, {"title": "3 Result of Primary Analysis", "content": "The results show that AI-edited images distort participants' memories of the original images, leading them to report more false memories and higher levels of confidence in the false memories,"}, {"title": "3.1 Number of Recalled Memories by Categories", "content": "Shapiro-Wilk tests revealed non-normality across all four experimental conditions (P-value ranging from 3.238e-5 to 5.79e-4). We employed one-way Kruskal-Wallis tests to analyze variation.\n3.1.1 Number of False Memories. As illustrated in the first column of Figure 6, the test indicates significant differences in the number of reported false memories between the conditions, H=34.157, P=1.836e-07, P<.05. The AI-edited images induced significantly more false memories than the unedited images (1.67x), while AI-generated videos of AI-edited images amplify the number of false memories leading to a 2.05x number of reported false memories. However, Al-generated videos from unedited images result in 1.25x compared to control. Statistics: control, M=18.878, s.d.=14.164, number of reported false memories out of 12 (#)=2.265; AI-gen videos of unedited images: M=23.667, s.d.=18.055, #=2.840; AI-edited images: M=31.373, s.d.=15.965, #=3.765; AI-gen videos of AI-edited images: M=38.667, s.d.-18.838, #=4.640. post hoc Dunn test with Benjamini-Hochberg (FDR) correction: control vs AI-edited images, P=2.5e-4; control vs AI-gen videos of AI-edited images, P=7.654e-08; AI-gen videos of unedited images vs AI-gen videos of AI-edited images, P=6.153e-05.\n3.1.2 Number of Uncertain and Non-false memories. There were no significant differences in the number of reported uncertain memories between conditions as shown in the second column of Figure 6, H=0.903, P=8.246, P>0.05. Meanwhile, in the third column, the test indicates significant differences in the number of reported non-false memories between the conditions with, H=30.448, P=1.111e-06, P<.0071. All three edited sets introduce the lower number of reported non-false memories, i.e. 0.88x, 0.82x, 0.67x, in AI-gen videos"}, {"title": "3.2 Confidence in Recalled Memories", "content": "Shapiro-Wilk tests revealed non-normality across all four experimental conditions (P-value ranging from 6.709e-12 to 1.167e-10). We employed one-way Kruskal-Wallis tests to analyze variation. The results are illustrated in Figure 7\n3.2.1 Confidence of False Memories. As shown in the first column of Figure 7, the results indicate significant differences between the conditions, H=8.581, P=0.0354, P>0.05. AI-gen videos of AI-edited images and AI-edited images respectively induce 1.19x and 1.1x increase in the level of confidence in false memories vs control. Statistics: control, M=4.536, s.d.=2.041; AI-gen videos of unedited images: M=4.383, s.d.=2.220; AI-edited images, M=5.027, s.d.=1.092; AI-gen videos of AI-edited images: M=5.412, s.d.=1.449. post hoc Dunn test with Benjamini-Hochberg (FDR) correction: control vs AI-gen videos of AI-edited images, P=0.0139; AI-gen videos of unedited images vs AI-gen videos of AI-edited images, P=0.0150; AI-edited Images vs AI-gen videos of AI-edited images, P=0.0235.\n3.2.2 Confidence in Uncertain and Non-False Memories. The tests indicate no significant differences in the confidence in uncertain and non-false memories, the numbers are illustrated in the second and third column of Figure 7. Statistics: Uncertain Memories, H=0.726, P=0.867, P>0.05; Non-false Memories, H=5.012, P=0.170, P>0.05."}, {"title": "3.3 Weighted Score", "content": "We calculated the weighted score by multiplying the score assigned to each memory type (False = -1, Uncertain = 0, Non-False = 1) by the participant's confidence level for that memory (ranging from 1 to 7). The Shapiro-Wilk test results for all groups show P<0.05, indicating that the data in each group is normally distributed. The Levene test result (P=0.683) suggests homogeneity of variances across the groups. The one-way ANOVA test yielded a highly significant result (F=14.577, P=1.312e-08, P<0.007), indicating substantial differences among the group means. Statistics: control, M=32.061, s.d.=21.989; AI-gen of unedited images, M=24.760, s.d.=22.801; AI-edited images: M=15.803, s.d.-21.476; AI-gen videos of AI-edited images, M=3.040, s.d.-24.933.\nThe subsequent Tukey's post-hoc test revealed significant differences between several pairs of groups, particularly between the control and both AI-edited images (P=0.003) and AI-gen videos of AI-edited images groups (P=0.001), as well as between Al-gen videos of unedited images and AI-gen videos of AI-edited images (P=0.001), and between AI-edited images and AI-gen videos"}, {"title": "3.4 Group Homogeneity Checks for Primary Analysis", "content": "To ensure the homogeneity of our test groups, we conducted a group homogeneity check. In the test set design, half of the images remained unedited, even if they were part of AI-edited groups. For example, in the AI-edited images group, 12 out of 24 images were left unedited and matched those in the control group. The same approach was applied to the AI-generated videos of the AI-edited images group. We hypothesized that these unedited sets across groups would produce similar results in terms of the number and confidence of false, uncertain, and non-false memories across the three experimental conditions.\nFollowing the same procedure as our main analysis, we conducted statistical tests. The Shapiro-Wilk test results for normality were as follows: control (W=0.934, P<0.001), AI-gen videos of unedited images (W=0.935, P<0.001), AI-edited images (W=0.937, P<0.001), and AI-gen videos of AI-edited images (W=0.942, P<0.001). Kruskal-Wallis tests resulted in P-values ranging from 0.425 to 0.927, indicating no significant differences between the groups. As hypothesized, we found no evidence that the unedited sets across groups produced differing results across the three experimental conditions. This finding supports the validity of our experimental design. The results of the Kruskal-Wallis test are shown in Table 1."}, {"title": "4 Results of Additional Analysis", "content": "4.1 Number of false memories based on different types of image contents\nThe stimulus set is categorized into three distinct subgroups, each representing different domain topics in visual media. Daily life photos include everyday scenes, activities, and objects that people encounter regularly, representing common visual experiences in familiar settings. News images comprise photographs typically found"}, {"title": "4.2 Number of false memories based on type of subject edited by AI", "content": "As part of an exploratory analysis with descriptive statistics, we categorized the edited content into three subgroups based on the"}, {"title": "4.3 Moderating Factors", "content": "We employed a mixed effects regression approach to investigate how variables such as gender, age, education, familiarity with AI-filter technology, and cognitive factors (frequency of forgetting and memory efficiency) relate to number of false memories. Table 2 provides the result of the regression model. The result suggests that age has a significant negative relationship (P=0.01) with the number of false memories, yet the effect is small (Coef.=-0.031). Meanwhile, other factors do not show significant relationships in the model."}, {"title": "5 Discussion", "content": "5.1 AI-Edited Content Boosts False Memories with Alarming Confidence\nOur findings demonstrate the impact of AI-edited and AI-generated media on human memory distortion. Participants exposed to AI-altered images exhibited a markedly higher propensity to report false memories compared to those who viewed unedited control images. This effect was even more pronounced when participants were presented with AI-generated videos based on AI-edited images, suggesting that dynamic AI-edited media significantly amplify the distortion of memory, effectively embedding false details deeper into participants' recollections.\nPerhaps the most disconcerting aspect of the study's results is the high degree of confidence participants reported in their inaccurate recollections. The AI-edited images not only led to the formation of false memories but also instilled a misplaced sense of certainty in these fabricated recollections. This effect is maximized with Al-generated videos of edited images, which caused the most significant increase in both false memory formation and the associated confidence levels.\nThe implications of these findings are far-reaching and potentially alarming. The combination of false memories and high confidence levels creates a particularly dangerous scenario, as individuals are more likely to believe and act upon incorrect information they perceive as true. This phenomenon could have consequences in various contexts, from eyewitness testimonies in legal proceedings to the spread of misinformation in social and political spheres. Moreover, the study raises important questions about the nature of memory itself and how easily it can be manipulated by advanced Al technology. In the broader sense, our study shows that \"externalizing\" our memories by storing them digitally can change how we naturally remember things, especially when AI is involved in enhancing or altering these externalized memories.\n5.2 The Impact of Different Types of Edits: People, Environment, and Objects\nThis study explored the impact of different types of AI-generated edits\u2014specifically changes to people, environments, and objects, on the formation of false memories. The pattern in the results suggests that while people-related details are generally harder to recall,"}, {"title": "5.3 Moderating Factors", "content": "Interestingly, the mixed-effects regression model shows that age has a statistically significant negative effect on AI-induced false memories, indicating that younger individuals are more susceptible to such influences. This finding warrants further investigation into the underlying mechanisms. One possible explanation could relate to the higher exposure of younger individuals to technology, including AI-filtered media. The mere exposure effect suggests that people tend to develop a preference for things they are more familiar with [11], which could lead to increased trust or decreased skepticism toward AI-generated content among younger users. However, with older adults increasingly adopting technology and becoming more proficient in its use [22, 43], we may also observe a parallel reduction in skepticism among older users in the near future. Another explanation could involve the different modes of interaction with technology across age groups. Younger individuals may allocate their attention differently when consuming information, potentially making them more susceptible to false memory formation. Nonetheless, it is crucial to emphasize that while the age-related difference is statistically significant, the effect size is relatively small, which suggests caution against overstating its practical implications.\nFamiliarity with AI-filter technology, while positively correlated, does not have a statistically significant moderating effect, suggesting that mere exposure or understanding of the technology may not provide protection against false memory implantation. This aligns with the earlier explanation of the inverse relationship between familiarity and skepticism, wherein increased trust may lead to greater susceptibility to false memories. Other variables, such as education level, cognitive load, and memory efficiency, do not show significant moderating effects, meaning these individual differences do not strongly influence the likelihood of developing false memories in response to AI-edited media. Interestingly, skepticism toward media and institutions, though negatively correlated, also lacks statistical significance, suggesting that even individuals with a more critical view of media may still be vulnerable to AI-induced memory distortions. This suggests that false memory formation operates beyond a simple \"trust vs. mistrust\" framework [82, 97]: anyone, regardless of their background or expertise, could potentially fall victim to false memories when exposed to altered media. In practical terms, this means that AI-altered media presents a challenge to all segments of society. Educational campaigns may need"}, {"title": "5.4 The Impact of Label", "content": "The study presented all AI-edited visuals with a label indicating that the content had been altered by AI, similar to the notification systems that some social media platforms have begun to implement to inform users about AI-generated or edited content. Despite these labels, we observed a significant increase in the formation of false memories in participants exposed to the AI-edited conditions. This finding aligns with prior research which has demonstrated that passive notifications or labels alone may be insufficient to mitigate cognitive biases induced by manipulated media.\nFor instance, previous studies [21], have shown that prompting users to actively consider the accuracy of social media posts can reduce the likelihood of sharing misinformation online. This suggests that labels need to go beyond mere informational disclosure. Instead of serving as passive indicators, labels should be designed to actively engage users in a more thoughtful, reflective process regarding the content they are viewing.\nOne potential explanation for the persistence of false memories despite labeling is that such notifications, while informative, do not sufficiently alter the cognitive processing of the visual material. Human memory is inherently reconstructive, and when individuals are presented with altered content\u2014especially content that seems plausible or familiar\u2014they may integrate it into their existing memory frameworks, regardless of the presence of a label. Simply knowing that content has been edited may not prevent the automatic processing of memory integration and reconstruction, which can lead to false memories.\nTo effectively reduce the impact of AI-edited media on memory, a more proactive approach to labeling may be necessary. This could involve enhancing the salience of the labels, providing users with interactive or cognitive prompts to reflect on the accuracy or authenticity of the content, or even incorporating reminders throughout the interaction with Al-edited material. Such interventions would shift the role of labeling from a passive alert system to an active cognitive tool that helps users critically engage with the content."}, {"title": "5.5 Implications of AI-implanted False Memories and Human-Computer Interaction", "content": "Our study has shown that Al has the capacity to manipulate human memory by altering images or videos, creating false recollections that may not align with reality. In Human-Computer Interaction, the implications of these AI-implanted false memories are significant, posing both challenges and opportunities, as shown in figure 2. In this section, we explore both the negative and positive implications of AI-implanted false memories in HCI, as well as potential mitigation strategies for each.\n5.5.1 Wrongful Legal Accusations. In the legal domain, AI-generated false memories pose a significant and potentially life-altering risk. Altered media could falsely implicate individuals in crimes they did not commit, leading to a cascade of negative consequences. When Al is used to generate or manipulate this type of media, the potential for distorting public perception and influencing key figures in the legal process\u2014such as witnesses\u2014becomes even greater.\nElizabeth Loftus, a psychologist who pioneered false memory research, demonstrated the potential consequences of memory distortion in real-world cases. She highlighted the case of Steve Titus, who was wrongfully convicted of rape in 1980 [111]. Titus was identified by the victim with low confidence during a photo lineup, but by the time of the trial, her confidence had increased due to suggestive identification procedures and additional police information. Despite this shaky identification, Titus was convicted. Months later, new evidence pointed to the actual culprit, and the witness realized her mistake. Although Titus was eventually exonerated, the wrongful conviction caused financial and emotional ruin, leading to his untimely death at age 35, just before his lawsuit against the police was to be heard.\nToday, news headlines are rapidly circulated and amplified through memes, posts, and viral content, which often simplify or sensationalize events. When AI is used to generate or manipulate this type of media, the potential for distorting public perception and influencing key figures in the legal process\u2014such as witnesses\u2014becomes even more extreme. An AI-generated meme that exaggerates or fabricates details of a crime scene could rapidly spread on social media platforms, creating a distorted narrative. Even a subtle alteration to an image or video, like placing someone in a misleading context or falsely associating them with a crime, can easily go vi-"}, {"title": "5.6 Positive Use Cases of AI-Generated False Memories", "content": "While the potential for negative impact of AI-generated false memories is significant, it is equally important to explore the positive applications of this technology. When used ethically and under controlled conditions, AI-generated false memories could offer substantial benefits in various fields, particularly in mental health and personal development.\n5.6.1 Therapeutic Memory Reframing. AI offers immense potential for therapeutic memory reframing [41, 52, 72, 112], a technique that could revolutionize the treatment of various psychological disorders, particularly those related to trauma and anxiety. In this application, AI might assist in altering distressing memories for patients undergoing psychological treatment, providing a powerful tool for mental health professionals [41, 52, 72, 112]. By subtly modifying or enhancing specific elements of a photo or video associated with a traumatic event, as shown in Figure 2, AI could help reduce the emotional intensity tied to these memories. For example, an AI-altered image could remove or blur triggering elements from a scene, allowing individuals to reframe their traumatic experiences in a less distressing way. This technique might be particularly beneficial for patients suffering from Post-Traumatic Stress Disorder (PTSD), phobias, or other anxiety disorders.\nThe process of memory reframing through AI could involve creating a series of gradually altered images or videos, each one slightly less distressing than the last. As patients work through this sequence with their therapist, they could potentially build new, less emotionally charged associations with the traumatic memory. This approach aligns with existing therapeutic techniques, such as exposure therapy and cognitive restructuring, but offers a more controlled and customizable experience.\nIt is crucial to note that such applications would require strict ethical guidelines and should only be implemented under the supervision of qualified mental health professionals. The goal would be to aid in the healing process, not to erase or completely falsify memories.\n5.6.2 Enhancing Self-Esteem. Another promising application of AI-generated false memories lies in the realm of self-esteem en-"}, {"title": "5.7 Ethical Considerations", "content": "The use of AI-generated content to influence human memory raises important ethical concerns that must be carefully considered. Key issues include informed consent and transparency, as individuals should be aware when viewing AI-altered content that may impact their memories or perceptions. The potential for manipulation and misinformation through AI-generated false memories poses risks in various domains, from politics to personal relationships, necessitating robust safeguards against intentional misuse. Privacy and data protection are crucial, both in terms of the datasets used to train Al systems and the potential for highly personalized false memory generation. The psychological impact of AI-induced false memories, particularly in therapeutic contexts, requires careful navigation. Ensuring equitable access to both protective measures and potential benefits is important to prevent uneven distribution of risks and advantages. Researchers, developers, and practitioners have an ethical obligation to consider the consequences of their work and implement safeguards. The need for appropriate regulatory frameworks to balance innovation with protection against harm is evident, as is the importance of considering the long-term societal impact on trust, shared reality, and collective memory. Addressing these ethical concerns requires clear guidelines, robust labeling systems, ongoing interdisciplinary research, enhanced media literacy education, ethical review processes, and collaboration between Al developers, ethicists, policymakers, and cognitive scientists to ensure responsible development and use of this powerful technology."}, {"title": "5.8 Limitations and Future Research", "content": "This study provides valuable insights into the impact of AI-ge3nerated and AI-edited media on memory formation, but it is not without limitations. These limitations, along with the study's findings, point to several promising directions for future research.\nOne primary limitation of this study is its reliance on relatively short-term exposure to AI-altered media. Participants were exposed to the manipulated images and videos for a limited time, which may not fully reflect real-world scenarios where individuals are repeatedly exposed to such content over extended periods. Moreover, as demonstrated in Loftus' research, false memory implantation often involves gradual and repeated suggestion rather than a single exposure. However, our study reveals that even brief exposure to these types of stimuli induces a significant false memory effect. Previous studies [10, 27, 66, 84] suggest this effect would likely intensify with increased exposure duration or frequency. Our findings lay crucial groundwork for further investigation, particularly into the cumulative effects of long-term, incremental exposure to AI-generated media on memory formation and distortion. Longitudinal studies could provide valuable insights into how false memories evolve and potentially become entrenched over time with repeated exposure."}, {"title": "6 Conclusion", "content": "This research demonstrates the significant impact of AI-edited media on human memory distortion. The results reveal that exposure to AI-altered images substantially increases the likelihood of false"}]}