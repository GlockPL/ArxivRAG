{"title": "Hierarchically Gated Experts for Efficient Online Continual Learning", "authors": ["Kevin Luong", "Michael Thielscher"], "abstract": "Continual Learning models aim to learn a set of tasks under the constraint that the tasks arrive sequentially with no way to access data from previous tasks. The Online Continual Learning framework poses a further challenge where the tasks are unknown and instead the data arrives as a single stream. Building on existing work, we propose a method for identifying these underlying tasks: the Gated Experts (GE) algorithm, where a dynamically growing set of experts allows for new knowledge to be acquired without catastrophic forgetting. Furthermore, we extend GE to Hierarchically Gated Experts (HGE), a method which is able to efficiently select the best expert for each data sample by organising the experts into a hierarchical structure. On standard Continual Learning benchmarks, GE and HGE are able to achieve results comparable with current methods, with HGE doing so more efficiently.", "sections": [{"title": "1 INTRODUCTION", "content": "Continual Learning, also known as Lifelong Learning, addresses the challenge of creating AI able to continually learn and apply knowledge over long time spans (Parisi et al., 2018). The biggest barrier to achieving such an AI is catastrophic forgetting, where previously learnt knowledge is lost due to interference when acquiring new knowledge. In practice, this is observed as a reduction in performance on existing tasks when learning a new task.\nIn Continual Learning an agent is restricted from seeing past data samples yet must correctly model both past and present data. Whilst past data samples are always forbidden, in many continual learning settings the data is assumed to come from a series of separate distributions (tasks) with each sample labelled according to its distribution (Kirkpatrick et al., 2017; Lopez-Paz and Ranzato, 2017). This task identity data is not available in the Online Continual Learning setting, which is currently gaining attention as a more useful extension to Continual Learning (Kirichenko et al., 2021; Hihn and Braun, 2023).\nMany Continual Learning techniques in both online and offline settings aim to mitigate interference between tasks, and thus catastrophic forgetting, by employing a set of experts such that each expert is associated with a single task (Aljundi et al., 2017; Zhu et al., 2022). The challenge, in online settings, is then in selecting the correct expert during both training and testing. We build on existing work in this area to propose our own method, which we name Gated Experts (GE). More specifically, our algorithm can be seen as an extension of Expert Gate (Aljundi et al., 2017) to the online setting by detecting task switches as statistically significant deviations in the training loss. We credit Zhu et al. (2022) for the idea to use the training loss as a task switch signal. However, we track the loss and detect task switches in a different manner to address shortcomings in the existing approach, discussed in section 3.3.\nThe GE algorithm belongs to the class of expansion-based methods, where the number of parameters dynamically grows as needed to learn new tasks. In this area, the efficiency of an algorithm is often optimised by reducing the number of parameters, by pruning (Zhu et al., 2022) or other methods (Yoon et al., 2018; Xu and Zhu, 2018). We instead propose to organise the experts in a hierarchical manner, so that only a subset of experts are required for any given data sample. Thus, the inference time can be improved. We name this extension Hierarchically Gated Experts (HGE).\nWe evaluate GE on standard Continual Learning benchmarks and show that it is competitive with the state-of-the-art in Online Continual Learning. Then, we create new Continual Learning scenarios involving a mixture of datasets to which we apply both GE and HGE. We show that HGE is able to organise experts hierarchically, thus increasing efficiency, with little loss in accuracy.\nIn summary, our contributions are:\n\u2022 We present a novel method for task switch detection to address shortcomings in an existing approach.\n\u2022 We apply this method on existing work to propose the GE algorithm and empirically show it to be competitive with the state-of-the-art in Online Continual Learning.\n\u2022 We propose hierarchical organisation, unexplored in the literature thus far, as a means of improving the efficiency of expansion-based Continual Learning methods. Our HGE extension improves upon the efficiency of GE. We demonstrate the extension on bigger Continual Learning scenarios as a proof-of-concept.\nThe rest of the paper is structured as follows. We provide an overview of Continual Learning and current methods in Section 2. Then, we present our approach to task switch detection and the GE algorithm in section 3, and describe the HGE extension in section 4. Our experimental setup and results are given in Section 5, and we conclude with a summary and discussion of future work in Section 6."}, {"title": "2 BACKGROUND", "content": "2.1 Continual Learning\nThere has been a wide array of approaches proposed for continual learning. We provide a broad overview of the continual learning landscape, but refer to surveys for a taxonomy as well as a more comprehensive coverage of these approaches (Parisi et al., 2018; Wang et al., 2024). There exists three major categories of continual learning methods: architectural, regularisation, and replay-based.\nArchitectural approaches aim to assign specific model parameters to specific tasks, thus mitigating catastrophic forgetting as each parameter is only fitted to one task. Often, there is a separate model, referred to as an expert, that is assigned to each task to be learnt (Zhu et al., 2022; Lee et al., 2020). The Expert gate (Aljundi et al., 2017) algorithm creates a new expert for each task during training, as well as an autoencoder to learn a representation for the task. During test time, each sample is forwarded to the expert corresponding to the autoencoder that best recreates the sample. Alternatively, there exist approaches where the network is fixed but binary masks are learned to restrict each task to a subset of parameters (Kang et al., 2022; Wortsman et al., 2020). In some cases, the task-specific parameters may not be stored and instead generated by a meta-model known as a hypernetwork (HN) (Hemati et al., 2023).\nRegularisation techniques constrain updates to previous parameters to preserve learnt knowledge. In many popular approaches, including Elastic Weight Consolidation (Kirkpatrick et al., 2017), Gradient Episodic Memory (Lopez-Paz and Ranzato, 2017) and Synaptic Intelligence (Zenke et al., 2017), this is achieved by applying a loss to penalise changes to parameters considered to be important. Learning without Forgetting (Li and Hoiem, 2017) is another popular regularisation technique which records a model's output on new data and uses this as a pseudo-label to preserve the model's capabilities.\nReplay-based approaches involve saving and retraining on previously seen data. Generally, it is assumed that only a small subset of training samples can be stored, in which case the main challenge is in selecting the best samples to store (Chaudhry et al., 2019; Lopez-Paz and Ranzato, 2017). Other works in this area do not explicitly store the samples, but instead train a network to recreate them (Shin et al., 2017). Replay is commonly incorporated into continual learning algorithms, even if the works themselves are focused on other aspects (Zhu et al., 2022; Hihn and Braun, 2023; Kirichenko et al., 2021).\nContinual learning scenarios are often categorised as either domain incremental or class incremental (Wang et al., 2024), although other categories exist. In the domain incremental setting, the inputs for each task come from a different distribution and the output space is shared. In the class incremental setting, the inputs come from the same distribution and the output space is disjoint."}, {"title": "2.2 Online Continual Learning Methods", "content": "In Online Continual Learning, also known as Task-Free or Task-Agnostic Continual Learning, task identities are not provided during training nor testing.\u00b9 We provide an overview of some of the main approaches proposed in this area, which we will also use to compare with our method.\nBayesian Gradient Descent (BGD) is an early work in the Online Continual Learning setting (Zeno et al., 2018). The authors build on previous work in online variational Bayesian learning to propose a\n\u00b9 Online Continual Learning may also refer to scenarios where each training sample is only shown once, i.e. one epoch per task (Wang et al., 2024). We do not consider this case and only focus on learning without task identities."}, {"title": "3 ONLINE CONTINUAL LEARNING", "content": "In the Online Continual Learning paradigm, training data $D_{train} = \\{(x_i, y_i)\\}_{i=1}^{M}$ in the form of input-output pairs arrives sequentially such that when $(x_i, y_i)$ is seen, $\\{(x_j, y_j)\\}_{j=1}^{i-1}$ cannot be accessed. The goal is to learn a model $f$ of inputs to outputs with no information given about the data generating process. Following training, the model is judged on testing data $D_{test} = \\{(X_i, y_i)\\}_{i=1}^{N}$ by comparing the expected $(y_i)$ and model $(f(x_i))$ outputs.\nWe follow the common assumption (Hihn and Braun, 2023; Kirichenko et al., 2021) that there exists a set of distributions (tasks) from which the data is generated and that they arrive in a sequence (possibly with repetitions) with a hard boundary between each task. Formally, there exists a constant $C$ such that if $(x_i, y_i)$ belongs to task $m$ and $(x_{i+1}, y_{i+1})$ belongs to task $m+1$, then $\\{(x_j, y_j)\\}_{j=i+1}^{i+C}$ belongs to task $m +1$. At a hard task boundary a large and sustained increase in the training loss can be expected. Task-Agnostic continual learning using Multiple Experts (TAME) (Zhu et al., 2022) (cf. Section 2.2) is a method for detecting these boundaries by tracking the loss of a single active expert on incoming samples. A threshold for acceptable losses is calculated using the mean and standard deviation of the loss over a moving window. When the incoming loss, which is smoothed using an exponentially weighted moving average (EWMA), exceeds this threshold, a task switch is detected. The active expert is then switched to the correct expert or to a new expert if the incoming task is unseen.\nIn this section, we propose a method for Online Continual Learning that, like TAME, leverages statistically significant increases in the training loss to detect task switches. First we describe our approach to task switch detection (Section 3.1). Then we show how this can be applied to extend the Expert Gate algorithm (Aljundi et al., 2017) to produce our Gated Experts (GE) algorithm (Section 3.2). We also provide a comparison between TAME and GE (Section 3.3)."}, {"title": "3.1 Detecting Task Switches in Online Continual Learning", "content": "Given an expert and an input sample, we must determine if the sample belongs to the same task on which the expert was trained. To do so, for each expert we maintain an EWMA of the value and deviation of the training loss. Given $n$ training losses $L$, the mean $\u03bc$ and standard deviation $\u03c3$ are defined as follows:\n$\u03bc_1 \u2190 L_1$\n$\u03bc_n \u2190 \u03b1\u03bc_{n-1} + (1 \u2212 \u03b1)L_n, n > 1$\n$\u03c3_1 \u2190 0$\n$\u03c3_2 \u2190 |L_2 - L_1|$\n$\u03c3_n \u2190 \u03b1\u03c3_{n-1} + (1 \u2212 \u03b1)(L_n - \u03bc_{n-1}), n > 2$\n$\u03b1$ is the smoothing factor for the EWMA and should be set relatively high (we use $\u03b1$ = 0.9) to reduce the impact of noise in the training loss. The mean and standard deviation of the training loss are combined with a threshold hyperparameter $\u03b5$ to produce an upper bound on the training loss:\n$\u03bc + \u03b5\u03c3$\nIf the loss of the given input sample is above this upper bound, we assume one of three possibilities:\n1. The sample belongs to the same task as the expert but is an outlier.\n2. The sample belongs to another task.\n3. The sample belongs to the same task as the expert but instability in the training process has temporarily increased the loss.\nTo determine which of these is correct, we set aside the input sample in a buffer (the high-loss buffer) and await further samples. If the training loss immediately returns below the threshold, the first scenario has occurred as the other two can be ruled out.\nIt is clear that the second scenario will result in a consistently high training loss, and we also expect to see this trend in the third scenario; if training instability has left the expert in a state where it produces high training losses, setting aside the input samples prevents the expert from exiting such a state. Thus, if a consistently high training loss is observed, we must determine if the second or third scenario has occurred.\nThe second and third scenarios can be differentiated with the aid of a small buffer of samples on which the expert was trained. Samples from this buffer are compared to the high-loss samples in a statistical test to determine if they belong to the same distribution. First, the training loss is calculated for all samples. We hypothesise that the loss is normally distributed because in practice, each loss is the mean over a batch of training examples and as a result the Central Limit Theorem can be applied. Thus, we apply a simple Z-test: Let \u03bc\u2081 and $\u03c3$ be the mean and standard deviation of the $n$ losses from the samples in the expert buffer, and \u03bc\u2082 be the mean of the losses from the high-loss buffer, then the standard error SE and Z-score ZS are calculated as:\n$SE = \u03c3 / \\sqrt{n}$\n$ZS = |\u03bc_2 - \u03bc_1|/SE$\nIf ZS is above a threshold hyperparameter $\u03b5_{review}$, then we assume scenario 2 has occurred, and scenario 3 otherwise."}, {"title": "3.2 Gated Experts", "content": "Detecting switches in the input task allows for the Expert Gate algorithm (Aljundi et al., 2017) to be extended to the Online Continual Learning setting. We name this extension Gated Experts (GE) and provide the pseudocode in Algorithm 1. In GE, a set of experts (initially one) is maintained with each expert corresponding to a single task out of all tasks seen so far. Associated with each expert is an autoencoder that is trained on the same data. As each training sample arrives, it is forwarded to the most relevant expert defined by the lowest autoencoding loss. Thus, task switches between existing tasks are handled. When a task switch is detected, we can assume that the incoming task is new and thus create a new expert.\nWhen a new expert is created, it is likely that future samples from the same task will not be correctly forwarded to said expert until the associated autoencoder is adequately trained. GE addresses this problem by maintaining a separate set of newly created experts. When a sample is forwarded to an expert and found to not belong to said expert, we check if it belongs to a newly created expert before setting it aside. Thus, the following events will occur when samples from a new task arrive:\n1. The samples are forwarded to one or more existing experts, found to have a high loss and thus set aside in the high-loss buffer.\n2. A task switch is detected due to a consistently high loss, and a new expert is created and trained on the samples in the high-loss buffer.\n3. Further samples from the new task arrive and are forwarded to the same experts as in Step 1.\n4. The samples are redirected to the new expert rather than sent to the high-loss buffer.\nDuring the final step, we also track whether the loss of the sample on the new expert was greater or lower than on the existing expert. When the loss on the new expert is consistently lower, then the new expert can be promoted: the expert is removed from the set of newly created experts and treated as a regular expert. The promotion condition is met when the proportion of lower losses in the last $promotion_{window}$ samples exceeds $\u03b5_{promotion}$. In GE, we set $promotion_{window}$ = 50 and $\u03b5_{promotion}$ = 0.5.\nA relatively low value of $\u03b5_{promotion}$ is possible as GE does not require perfect accuracy when forwarding samples. Under the assumption of hard task boundaries, adjacent samples are highly likely to belong to the same task. When a sample is forwarded to the wrong expert, a temporary high-loss is observed similar to an outlier. In both cases, the sample will be assigned to the same expert as the previous sample."}, {"title": "3.3 Comparison to TAME", "content": "The main advantage of GE over TAME is in the high-loss buffer. Performing a statistical test before detecting a task switch greatly reduces the false-positive rate, as we show experimentally in Section 5.1. In addition, in TAME one or more samples may be wrongly trained on the active expert before the EWMA of the loss exceeds the acceptable threshold. This is prevented in GE as samples over the threshold are immediately set aside.\nAnother difference is in the lack of an active expert in GE. By assigning each sample to the expert with the lowest autoencoding loss, the algorithm is simplified as task switches between existing tasks are a non-factor. In practice, the last-used expert could be tracked to improve the efficiency of GE. If an incoming sample has a loss within the threshold of the last-used expert, then we can assign it to said expert without calculating all of the autoencoding losses."}, {"title": "4 HIERARCHICALLY GATED EXPERTS", "content": "In GE the autoencoding losses are used as a measure of the suitability of an expert to a given sample. We hypothesise the existence of relationships between experts such that the suitability of an expert can be estimated from the autoencoding losses of its peers. For example, if experts A and B are both trained on tasks in the same domain then we can expect that they will produce a low autoencoding loss for any sample from said domain. Thus, if expert A produces a high autoencoding loss then we can assume that the sample originates from a different domain, and that expert B will likewise be unsuitable.\nWe propose the idea of organising experts hierarchically to exploit these relationships and improve the speed with which an expert can be selected for a given sample. Our algorithm, named Hierarchically Gated Experts (HGE), is an extension to GE where the set of existing experts is instead a tree with each node (except the root) corresponding to a specific expert. Given a sample, we traverse the tree by following the child with the lowest autoencoding loss at each step. We stop when a leaf node is reached or when the current node has a lower autoencoding loss than each of its children. The final node is then considered to correspond to the expert with the overall lowest autoencoding loss. Thus, an expert can be selected without calculating the autoencoding loss for all experts. The pseudocode for the traversal is provided in Algorithm 2.\nThe tree of experts is built iteratively. As each expert is promoted, it is added to the tree such that samples from the corresponding task will be correctly assigned to the expert. This can be trivially accomplished by adding the expert as a child of the root, so that its autoencoding loss will always be calculated. However, such a strategy will produce a completely flat tree and be equivalent to the GE algorithm. Thus, we instead aim to insert the expert as deeply as possible while maintaining assignment accuracy. As a newly created expert is trained, we track the traversal paths taken by every sample the expert is given. When the expert is promoted, it is inserted as a child of the lowest common ancestor (LCA) of all traversal paths. Outlier paths, which are only taken a few times, are excluded according to the $promotion_{path}_{threshold}$ hyperparameter. The pseudocode for expert promotion is provided in Algorithm 3.\nWhen a new expert is added to the tree, it is possible that it will mask some of the existing experts, causing catastrophic forgetting. With reference to Figure 1, expert 0 will mask expert 3 if, on samples from task 3, expert 0 has a lower autoencoding loss than expert 1. When an expert is inserted, all descendants of siblings can potentially be masked. To mitigate this, the replay buffer of each potentially masked expert is used to estimate if masking will occur. If any replay samples are incorrectly assigned to the new expert, then a new node corresponding to the masked expert is added as a child of the new expert. We choose to create a new node rather than add a connection to the existing node so that we do not unnecessarily add the descendants of the masked expert.\nThe hierarchical organisation of experts complicates the promotion process. In GE, there is a wide range of possible promotion times as the algorithm is able to handle samples being forwarded to the wrong expert. In HGE, however, it is much easier for the promotion of an expert to be performed too early. When an expert is promoted in HGE, it is added to the tree in a way that exploits the relationship between the autoencoders. As the expert continues to train, these relationships may change and the expert may begin to mask others, causing catastrophic forgetting. Thus, a higher $\u03b5_{promotion}$ is preferred. On the other hand, a promotion threshold that is too high may never be met.\nIn our experiments, we set a separate $\u03b5_{promotion}$ for each scenario roughly equal to the accuracy achieved at the end of training. This approach works reasonably well, but it does break the Online Continual Learning paradigm as we are using task-specific information. The promotion time is part of a larger problem of dealing with changing relationships between experts, which we leave as a problem for future research."}, {"title": "5 EXPERIMENTS", "content": "In this section, we experimentally evaluate our approach to task switch detection in the Online Continual Learning setting. We also perform controlled experiments with GE and HGE to determine the impact of hierarchical expert organisation on the gating accuracy. Finally, we validate GE and HGE on Online Continual Learning benchmarks.\nWe use widely known and commonly adopted Continual Learning scenarios in our experiments:\nPermuted MNIST (PMNIST). The MNIST dataset (Lecun et al., 1998) is used as the first task in this scenario. Each subsequent task reuses MNIST, but with the pixels in each image randomly permuted. The permutations are kept consistent within each task. There are 20 tasks in total.\nSplit MNIST (SMNIST). The MNIST dataset is split into 5 tasks, each containing 2 classes.\nSplit CIFAR-10 (CIF10). The CIFAR-10 dataset (Krizhevsky, 2012) is split into 5 tasks, each containing 2 classes.\nSplit CIFAR-100 (CIF100). The CIFAR-100 dataset is split into either 10 or 20 tasks, each with the same number of classes.\nSplit Tiny Imagenet (ImgNet). The Tiny Imagenet dataset is a subset of Imagenet (Russakovsky et al., 2015) containing images from 200 classes. We randomly select 100 classes which are then evenly split into either 10 or 20 tasks.\nWe also use scenarios that are both class-incremental and domain-incremental. Each scenario involves two datasets where the classes are split evenly into tasks. The tasks are presented in an alternating fashion; the first task from the first dataset, then the first task from the second dataset, then the second task from the first dataset, and so on. The scenarios are:\nMNIST and Kuzushiji-MNIST (MNIST-KMNIST). We split the MNIST dataset and Kuzushiji-MNIST (KMNIST) dataset (Clanuwat et al., 2018) into 5 tasks each, for a total of 10 tasks.\nMNIST and CIFAR-10 (MNIST-CIF10). Similar to the previous scenario, we split each dataset into 5 tasks each.\nCIFAR-10 and Inverse CIFAR-10 (CIF10-INV). We split each dataset into 5 tasks. To produce the Inverse CIFAR-10 dataset, we invert the colour of every pixel. The dataset is otherwise identical to CIFAR-10.\nCIFAR-100 and Tiny Imagenet (CIF-ImgNet). Each dataset is split into 10 tasks. Only 100 randomly selected classes are used from the Tiny Imagenet dataset.\nWe use two variants of experts in our experiments. In the PMNIST, SMNIST and MNIST-KMNIST scenarios, both the base model and the autoencoder are multi-layer perceptrons (MLP). Otherwise, we use Resnet-18 (He et al., 2015) as the base model and a convolutional autoencoder. We provide the full details of the dataset preprocessing, models used and hyperparameters in the Appendix."}, {"title": "5.1 Task Switch Detection", "content": "We first test the effectiveness of our approach to task switch detection. In each scenario, we observe the creation of new experts and record cases where an abnormal number of experts is created for a task."}, {"title": "5.2 Hierarchical Organisation", "content": "We aim to determine the impact of hierarchical organisation on the accuracy and efficiency of the expert selection process. We control for other factors in Online Continual Learning, such as training samples being assigned to the wrong expert, by instead training a separate expert on each task. We only measure the accuracy with which a sample is assigned to the correct expert and do not consider the classification accuracy. We measure the cost of a tree as the number of experts queried for a given sample. After all experts are trained, we apply three approaches to expert organisation:\nGE. The experts are organised in a fully flat tree.\nHGE. In the same manner as the HGE algorithm, a tree of experts is built by incrementally adding experts according to task order. As each expert is trained separately, we do not have any traversal paths to track. Instead, when an expert is added to the tree the traversal paths are calculated for all training samples in the corresponding task.\nUpper. The HGE algorithm is run a large number of times (1000) with a randomised task order, and the accuracy and cost of each generated tree is recorded. We then select the tree with the lowest cost and an accuracy at least as high (approximately) as the GE tree. This approach estimates the best possible tree given the trained experts.\nOur results are shown in Table 2. Both the HGE and Upper approaches are able to produce trees with close to optimal accuracies. In general, the cost reduction with HGE is dependent on the expert selection accuracy, with a markedly lower cost in scenarios where the accuracy is high. This trend is also observed with the Upper strategy, but to a lesser extent as there is a decent cost reduction even when the selection accuracy is low.\nWe also provide a statistical analysis of the accuracies and costs of the trees generated during the Upper strategy. We analyse the spread of the accuracy and cost as well as the correlation between the two. The results are provided in Table 3. We observe a low but positive level of correlation across the board. We believe that deeper trees are able to have a lower cost, but may also suffer a lower accuracy as deeper nodes have a higher chance of being masked.\nWe observe a very low level of spread in the accuracies of the trees. The spread of the costs is higher but still relatively low. Thus, we conclude that HGE is not overly affected by the task order and is generally able to organise the experts with close to the optimal possible efficiency and cost.\nA manual examination of the trees confirms these findings, as the HGE trees share many similarities with the Upper trees. Figure 2 showcases this; both HGE and Upper organise the experts according to domain in CIF10-INV, and in MNIST-KMNIST we see identical connections such as between experts 7 and 3 or 2 and 5."}, {"title": "5.3 Continual Learning Benchmarks", "content": "We evaluate the overall efficacy of GE and HGE by providing a benchmark of the accuracies achieved by these algorithms in an Online Continual Learning setting. We also provide an estimate of the accuracy that can be achieved given the base models used. The Separate method creates a separate model for each task and uses task information to assign the samples, thus serving as an upper bound.\nOur results are presented in Table 4 and 5. We measure accuracy as the average accuracy achieved over all tasks at the end of training. We also report the accuracy with which batches were assigned to the correct expert (Gate Acc). During training, we track the samples assigned to each expert and record an association between an expert and a task if the expert was trained on at least 10% of the samples in the task. During testing, we then measure the percentage of samples assigned to the correct expert. Finally, we also report the average number of experts queried during testing.\nFor comparison, we also provide the accuracy achieved by all the other existing continual learning methods described in Section 2.2. The BGD results are taken from Zhu et al. (2022) and part of the DER results from Yan et al. (2022). All other results are as reported in their corresponding papers cited in Section 2.2.\nOverall, GE is able to match or exceed the state-of-the-art in most benchmarks. Although the comparison with other techniques is not entirely fair due to some differences in experimental setup, the results still show that our algorithm is competitive with the compared techniques in Online Continual Learning.\nOne exception is the 10-task split CIFAR-100 and Tiny Imagenet scenarios, where there is a low gating accuracy. We hypothesise that the higher number of classes per task leads each autoencoder to learn a more general representation of the data rather than fitting specifically to the task. To test this, we exploit the additional labels in CIFAR-100, where each class is part of 1 of 20 superclasses. If we split by pairs of superclasses rather than randomly, the gating accuracy increases to 87.5%, however the overall accuracy increases only to 52.65% due to a lower classification accuracy between classes within a superclass.\nIn HGE, we observed a decreased accuracy across the board compared with GE. Whilst this is to be expected, we found larger drops in scenarios where the number of experts queried also distinctly dropped. Thus, we hypothesise that the main cause of the decreased accuracy is the changing relationships between experts as described in Section 4."}, {"title": "6 CONCLUSION", "content": "In this paper, we proposed an alternative to TAME for task switch detection in the Online Continual Learning setting. We showed that our approach is better equipped to handle models with unstable training, and applied this approach to extend Expert Gate (Aljundi et al., 2017) to our online Gated Experts (GE) algorithm. Then, we proposed the novel HGE extension, where experts are organised hierarchically, as a method to improve the efficiency of GE and possibly other expert-based algorithms. We performed controlled experiments to determine that HGE is able to organise a set of experts in a manner that is close to optimal. Finally, we benchmarked GE and HGE on standard Continual Learning datasets and found GE to be competitive with the state-of-the-art.\nThe major problem of HGE is in the changing relationships between experts as they are trained, which causes samples to be assigned incorrectly. As a result, we observed a lower HGE accuracy in the Online Continual Learning setting. The changing relationships also make it difficult to determine the optimal time to promote a newly created expert. Future research could be conducted into methods for periodically updating the expert tree to accommodate the changing relationships.\nHGE also suffers from poor efficiency when adding a new expert to the tree, as all descendants of siblings have to be checked for masking. More efficient approaches to building the expert tree may be possible. The use of autoencoders is also not strictly necessary and other methods for measuring expert suitability could be considered."}, {"title": "APPENDIX", "content": "In this section we provide hyperparameters and other details crucial to recreating our results.\nDatasets In the PMNIST, SMNIST and MNIST-KMNIST scenarios, the 28x28 images are flattened into 784-dimensional vectors. In all other scenarios, all images are first resized to 32x32 before further preprocessing is applied. In the MNIST-CIF10 scenario, the MNIST dataset is converted from grayscale to RGB to ensure compatibility with the Resnet-18 model. In the CIF10-INV scenario, the colour of each pixel is inverted to produce the Inverse CIFAR-10 dataset. The final step of preprocessing re-scales the pixel values to [0,1"}]}