{"title": "Representation Learning to Advance Multi-institutional Studies with Electronic Health Record Data", "authors": ["Doudou Zhou", "Han Tong", "Linshanshan Wang", "Suqi Liu", "Xin Xiong", "Ziming Gan", "Romain Griffier", "Boris Hejblum", "Yun-Chung Liu", "Chuan Hong", "Clara-Lea Bonzel", "Tianrun Cai", "Kevin Pan", "Yuk-Lam Ho", "Lauren Costa", "Vidul A. Panickan", "J. Michael Gaziano", "Kenneth Mandl", "Vianney Jouhet", "Rodolphe Thiebaut", "Zongqi Xia", "Kelly Cho", "Katherine Liao", "Tianxi Cai"], "abstract": "The adoption of EHRs has expanded opportunities to leverage data-driven algorithms in clinical care and research. A major bottleneck in effectively conducting multi-institutional EHR studies is the data heterogeneity across systems with numerous codes that either do not exist or represent different clinical concepts across institutions. The need for data privacy further limits the feasibility of including multi-institutional patient-level data required to study similarities and differences across patient subgroups. To address these challenges, we developed the GAME algorithm. Tested and validated across 7 institutions and 2 languages, GAME integrates data in several levels: (1) at the institutional level with knowledge graphs to establish relationships between codes and existing knowledge sources, providing the medical context for standard codes and their relationship to each other; (2) between institutions, leveraging language models to determine the relationships between institution-specific codes with established standard codes; and (3) quantifying the strength of the relationships between codes using a graph attention network. Jointly trained embeddings are created using transfer and federated learning to preserve data privacy. In this study, we demonstrate the applicability of GAME in selecting relevant features as inputs for AI-driven algorithms in a range of conditions, e.g., heart failure, rheumatoid arthritis. We then highlight the application of GAME harmonized multi-institutional EHR data in a study of Alzheimer's disease outcomes and suicide risk among patients with mental health disorders, without sharing patient-level data outside individual institutions. In summary, the GAME algorithm advances the feasibility of multi-institution EHR studies providing a method for code translation and harmonization at the scale with the adaptability needed for high-dimensional data-driven algorithms in clinical research and care. Moreover, we demonstrate that the valuable clinical information necessary for identifying and studying patient subgroups is retained in the GAME embeddings, offering an alternative to sharing patient-level data outside the institution for collaborative studies.", "sections": [{"title": "1 Introduction", "content": "Electronic health record (EHR) data have become a major resource for clinical and translational studies using real-world data. With information on diagnoses, prescriptions, laboratory results, and detailed clinical information in progress notes on millions of patients, these data have supported the creation of robust phenotyping algorithms to establish patient cohorts for studies on risk factors, outcomes, and patient subgroup analyses [4; 34; 54]. Additionally, these data have facilitated the creation of clinical decision support tools [19] and epidemiological surveillance [20]. A promise of EHR-based studies is the potential for multicenter studies, which can include more diverse populations, produce generalizable results, and offer insights into differential associations within subpopulations [11]. However, a major challenge in carrying out multi-center EHR studies at scale lies in the heterogeniety of data across EHR and healthcare systems; important codes in one system may not exist in another, highlighting a large unmet need in an approach that can harmonize the data for integrative analyses.\nStandardized coding systems such as the International Classification of Diseases (ICD) [10; 42] and the Logical Observation Identifiers Names and Codes (LOINC) for laboratory tests [38] provide a foundation for a common dataset across systems. However, healthcare systems adopt some, but not all of these ontologies; ICD is universally used in the United States, but LOINC codes are not. Thus, a laboratory test used for a study may be identified with a LOINC code at one institution but may only be identified using an institution-specific code at another site, referred to in this study as a local code. In recent years, artificial intelligence (AI) has enabled the creation of robust algorithms trained on hundreds to thousands of features. This increasing complexity underscores an unmet need for automated approaches that can accurately translate local codes to standardized representation at scale. Manually mapping codes from one institution to another is no longer a feasible option.\nAnother major challenge for multi-institutional collaborations for EHR-based research is the need to maintain privacy. The traditional paradigm for multi-institutional collaborations in biomedical research requires the collaborating institutions to share patient-level data to a centralized location to train a model. However, this collective data sharing approach is difficult to scale when a large number of institutions are involved due to the time and resources needed in obtaining permission to share the data [13]. Federated Learning (FL) methods [40; 44; 59] were developed to train models without requiring patient-level data being shared. In FL, summary statistics or model parameters, known as local models,"}, {"title": "2 Methods", "content": "The GAME algorithm is built upon the Graph Attention Network (GAT) [49], a variant of graph neural networks (GNNs) [22], which serves as its backbone. Its key novelty lies in the precise construction of hard negatives within the contrastive learning framework, optimizing representation learning and enhancing the integration of heterogeneous information from EHRs and existing knowledge bases. In this framework, EHR codes from multiple institutions are represented as nodes within the GAT, aiming to learn unified embeddings that integrate data from several sources. This section is divided into five parts. In Section 2.1, we first introduce the EHR data from seven institutions and detail the data preprocessing steps. Next, we describe the creation of initial embeddings using EHR data and PLMs in Section 2.2. We then outline the curation of KG edges used as labels for GAT training, in Section 2.3, and provide a detailed workflow of the GAME algorithm in Section 2.4. Finally, we highlight the validation of the GAME embeddings through a variety of tasks, including detecting known relations, code alignment, feature selection, and patient stratification."}, {"title": "2.1 EHR data sources and preprocessing", "content": "We utilized EHR data from seven hospital systems: Boston Children's Hospital (BCH), Bordeaux University Hospital (BDX), Duke Clinical Research Datamart (Duke), Mass General Brigham (MGB), Medical Information Mart for Intensive Care IV (MIMIC) [27], University of Pittsburgh Medical Center (UPMC), and Veteran Affairs healthcare (VA). In this study, BCH contains 251K patients from 2009 to 2022; BDX EHR data covers 2.5 million patients from 2010 to 2023; Duke includes data on over 6 million patients from 2014 to 2023; MGB EHR data contains 2.5 million patients from 1998 to 2018; and the VA Corporate Data Warehouse (CDW) aggregates data from 150 VA facilities into a single data warehouse, with records from 1999 to 2019 covering 12.6 million patients. BCH, BDX, Duke, and VA include inpatient and outpatient codified data from patients with at least one visit, while MGB includes only patients with at least three visits spanning more than 30 days. The MIMIC dataset contains data on over 65K ICU admissions and over 200K emergency department admissions at Beth Israel Deaconess Medical Center in Boston, Massachusetts, spanning 2008 to 2019. The UPMC EHR data includes 95K patients from 2004 to 2022, focusing on individuals with at least one occurrence of ICD codes related to Alzheimer's disease and dementia or multiple sclerosis.\nWe map ICD codes codes to PheCodes using the PheWAS catalog\u00b9. Diagnostic codes that cannot be mapped to PheCodes are retained as individual codes. All CPT, HCPCS, and ICD procedure codes are grouped into Clinical Classification Software (CCS) categories using the CCS mapping\u00b2. The BDX uses the Classification Commune des Actes M\u00e9dicaux (CCAM) [9], totaling 5246 distinct codes, for procedures. For laboratory tests, all laboratory codes from MGB and BCH are mapped to LOINC, whereas the laboratory codes from VA, UPMC, Duke, MIMIC-IV, and BDX largely comprise local codes. Similarly, for medication codes, we group them into ingredient level RxNorm codes whenever possible and retain local medication codes, mostly from UPMC and BDX, as local codes. In this study, we refer to PheCode, CCS, LOINC, and RxNorm as standard codes, while other codes that occur in local institutions are referred to as local codes. The goal of the algorithm is to accurately map local codes to the appropriate standard code (Figure 3).\nWhen constructing the PPMI matrix, co-occurrences fewer than 10 times are set to 0, and any code that co-occurs with other codes fewer than 10 times is removed to reduce noise from rare codes. Since laboratory tests are frequently analyzed at the first level of LOINC PART (LP) codes parent codes representing groups of individual LOINC codes we further aim to create embeddings for these LP codes. Including LP codes, we have 5,745 codes at BCH, 26,632 codes at BDX, 3,125 codes at Duke, 6,969 codes at MGB, 4,341 codes at MIMIC, 17,271 codes at UPMC, and 6,660 codes at VA. In total, we obtained 70,743 codes, of which N = 50,738 were unique. Our goal is to create unified embeddings for these N unique EHR codes, denoted by V. A detailed summary of the codes used is provided in Table 1."}, {"title": "2.2 Generating multi-source initial embeddings", "content": "This section outlines the generation of two sets of initial embeddings for the N unique EHR codes: institutional PPMI-SVD embeddings and textual description embeddings, essential for capturing clinical and semantic information of medical codes. Figure 2 intuitively illustrates the process of generating the initial embeddings."}, {"title": "2.2.1 Institution-specific PPMI-SVD embeddings from co-occurrence patterns", "content": "We construct a co-occurrence matrix to derive PPMI-SVD embeddings for each institution to capture the interactions between EHR codes based on their co-occurrence within patient records, following the methodology described in [6] and [25]. For each institution $m \\in \\{1, ..., M\\}$, the matrix $C_m = [C_m(i,j)]$ records the frequency of co-occurrences between the i-th and j-th codes within 30-day windows. We generate PPMI-SVD embeddings for all codes in the mth institution by applying SVD to the PPMI. To create initial embeddings for LP codes, we initialize the embedding of each LP code as a weighted average of the embeddings of their associated child LOINC codes. Detailed steps for generating the PPMI-SVD embeddings for both the EHR base codes and LP codes in the mth institution are provided in Supplementary S.2.1. The resulting d-dimensional PPMI-SVD embeddings are denoted by $V_m$. For ease of implementation, we transform $V_m$ into a matrix N \u00d7 d to represent the embeddings of the N unique EHR codes throughout the M institution by padding with 0 for the codes that do not appear in the mth institution."}, {"title": "2.2.2 Embedding textual description using pre-trained language models", "content": "Pre-trained language models (PLMs) have proven to be highly effective in identifying biomedical relationships and generating high-quality semantic embeddings [12; 23; 31; 36; 45; 56]. We used SapBERT embeddings [36], a PLM fine-tuned on UMLS synonymous relationships, to extract semantic information from the textual descriptions of EHR codes. However, the effectiveness of these embeddings depends significantly on the quality and specificity of the underlying descriptions. Many local codes, unfortunately, have abbreviated or vague descriptions. For example, the VA local lab code 1000023750 is described as merely \"TIBC,\" whereas its more detailed and informative description is \"Iron binding capacity [Mass/volume] in Serum or Plasma.\u201d To address this limitation, we employ GPT-4 to generate more detailed and informative descriptions for local codes. We first expand laboratory test acronyms into full names using resources such as the Laboratory Alliance's list of test abbreviations.\u00b3 Next, we prompt GPT-4 to produce comprehensive descriptions for the local codes. For French descriptions from BDX,"}, {"title": "2.3 Curation of the adjacency matrix from existing knowledge databases and large-language models", "content": "In this section, we detail the construction of a comprehensive adjacency matrix from multiple knowledge sources, as shown in Figure 2, which serves as input to the GAT model in the GAME algorithm. The matrix integrates edges from three primary sources: (1) hierarchical code structures, including PheCode, LOINC, RxNorm, and CCAM; (2) relationships provided by UMLS; and (3) additional edges generated using GPT-4. We categorize relation pairs into two groups: similar pairs and related pairs. The following subsections detail the process of constructing edges between different EHR codes. A summary of the number and types of edges is provided in Table S1 in Supplementary S.1.2. The final set of edges, representing the curated knowledge graph, is denoted as E."}, {"title": "2.3.1 Hierarchical information from common ontologies", "content": "We derive edges from the hierarchical structures of PheCode, RxNorm, LOINC, and CCAM to capture relationships between similar codes. In PheCode, more digits indicate greater specificity (e.g., PheCode:296 for mood disorders is the parent of PheCode:296.1 for bipolar disorder and PheCode:296.2 for depression, with PheCode:296.22 for major depressive disorder as a further refinement). We connect PheCodes sharing the same integer. In LOINC, edges link codes to their parent LP codes and between codes with the same LP parent. For RxNorm, where all codes we use are leaf codes, we create edges between those with common parents. For CCAM, codes sharing the first four characters (e.g., \u201cGLLD015\u201d and \"GLLD008\") are connected."}, {"title": "2.3.2 UMLS", "content": "UMLS includes a broad range of annotations, capturing similarity and relatedness, on medical relationships between entity pairs. For similarity, in addition to the hierarchical relationships discussed in Section 2.3.1, UMLS includes non-hierarchical relationships which do not follow a strict parent-descendant structure. For relatedness, we consider relationships like \"associated with,\" \"may treat,\" and \"co-occurs with,\" as detailed in Table S2 in Supplementary S.1.2. However, since the UMLS concepts are mostly encoded as CUIs, their relationships cannot be directly translated to relationships for EHR codes. We map CUIs to EHR codes using both existing mappings (RxNorm, CCS, LOINC to CUIs)\u2075 and GPT-4 (PheCode to CUIs). Specifically, for PheCode to CUIs, we use SapBERT to choose the most similar PheCode for each CUI whose semantic type is \"Disease or Syndrome.\" We then prompt GPT-4 to annotate whether the CUI can be mapped to the selected PheCode and choose the positive pairs as the CUI-PheCode mapping."}, {"title": "2.3.3 Graph expansion derived using GPT-4", "content": "While ontology hierarchies and UMLS provide valuable insights into medical relationships, they are sparse and insufficient for diverse downstream tasks. First, they lack connections between EHR codes from different institutions, such as relationships involving local codes. Second, they indicate whether two codes are related but do not quantify the closeness of these relationships, limiting their precision. To address these gaps, we leverage GPT-4 in a denoising process to curate edges, for code mapping and identifying related codes, as additional training labels."}, {"title": "2.4 The GAME algorithm", "content": "The training of the GAME algorithm comprises two key steps: (1) learning initial embeddings by aligning M sets of PPMI-SVD embeddings into a shared representation space, enhanced with knowledge graph information, using GAT; and (2) sequentially learning similarity and relatedness embeddings by integrating these initial embeddings with PLM embeddings through GAT combined with contrastive learning. This process utilizes positive and hard-negative similarity and relatedness labels from multiple sources, as described above."}, {"title": "2.4.1 KG enhanced alignment of PPMI embeddings through GAT", "content": "We first train an initial set of harmonized embeddings for all EHR codes V by aligning PPMI-SVD embeddings $\\{V_m\\}_{m=1,...,M}$, incorporating curated knowledge graph $\\mathcal{E}$ using GAT. As detailed in Algorithm 1 in Supplementary S.2.3, a GAT is trained for each institution, taking $V_m$ and $\\mathcal{E}$ as inputs, and outputting embeddings $Y_m$:\n$Y_m = \\text{Linear}^{(m)} \\{\\text{GAT}^{(m)} (V_m, \\mathcal{E})\\},\\qquad (1)$\nwhere the linear layer, $\\text{Linear}^{(m)}$, further aligns the institutional embedding into a shared space. The GAT training is regularized with the alignment loss\n$\\sum_{m_1, m_2\\in \\{1,2,...,M\\}} ||Y_{m_1} [I_{m_1},:] - Y_{m_2} [I_{m_1},:]||,\\qquad (2)$\nwhere $I_m$ indexes codes appearing in the mth institution. This loss minimizes the difference between the embeddings of corresponding medical codes across institutions. The initial harmonized embeddings are obtained as $Y = \\mathcal{R} \\{ \\frac{1}{M} \\sum_{m=1}^{M} Y_m \\}$, where $\\mathcal{R}(V)$ normalizes a given vector V into unit norm."}, {"title": "2.4.2 Sequential GAME embedding training with contrastive learning", "content": "We concatenate the PLM embeddings for code descriptions, X, with the initial harmonized embeddings, Y, to serve as input for sequentially training similarity and relatedness GAME embeddings. The goal is to generate a set of unified GAME embedding Z = [Zs, ZR] that integrates descriptive code information and EHR knowledge across institutions. Here, Zs is specifically optimized to capture semantic similarity, while the full embedding Z is designed to support more complex downstream tasks. Since similarity represents a stronger and more direct relationship, low-dimensional embeddings are sufficient for its representation. In contrast, tasks involving relatedness demand richer representations to capture broader and more nuanced semantic relationships. To achieve this, training is performed using GAT with contrastive learning, leveraging the edge set $\\mathcal{E}$. Various edge types contribute to different components of the contrastive loss, incorporating hard-negatives derived from ontology hierarchies as well as those generated by GPT-4.\nWe start with learning similarity embeddings using GAT, formulated as:\n$Z_S = \\mathcal{R} \\{ \\text{Linears} \\{ \\text{GATs} ([X, Y], \\mathcal{E}) \\} \\}.\\qquad (3)$\nThis is optimized with a similarity contrastive loss $\\mathcal{L}_S$, where positive and negative pairs are derived from UMLS similarity relations, ontology hierarchy, and GPT-enhanced edges. The inclusion of hard-negatives from the ontology and GPT further strengthens the training process. To train $Z= [Z_S, Z_R]$, we fix $Z_S$ from the first step and learn $Z_R$ using another GAT:\n$Z_R = \\mathcal{R} \\{ \\text{Linearr} \\{ \\text{GATR} ([X, Y], \\mathcal{E}) \\} \\}.\\qquad (4)$\nThis is optimized using a relatedness contrastive loss $\\mathcal{L}_R$ that integrates UMLS relatedness edges with GPT-enhanced edges derived from EHR PPMI, enabling robust learning of more nuanced and complex semantic relationships.\nThe contrastive losses $\\mathcal{L}_S$ and $\\mathcal{L}_R$ are constructed based on the Multi-Similarity (MS) loss [52], which effectively handles tasks with multiple semantic relationships by dynamically balancing the pulling of positive pairs and pushing apart negative pairs. For the ith ancor code with a set of positive pairs $\\mathcal{P}_i$ and a set of negative pairs $\\mathcal{N}_i$, the MS loss is defined as follows:\n$\\mathcal{L}^{(i)} (Z) = \\frac{1}{\\alpha} \\log \\Big( 1+ \\sum_{j \\in \\mathcal{P}_i} e^{-\\alpha (Z_i Z_j - \\lambda)} \\Big) + \\frac{1}{\\beta} \\log \\Big( 1+ \\sum_{j \\in \\mathcal{N}_i} e^{\\beta (Z_i Z_j - \\lambda)} \\Big).\\qquad (5)$\nHere, \u03b1, \u03b2, and \u03bb are hyperparameters that control the strength of the loss. See Supplementary S.2.2 for details on the losses and Algorithm 2 in Supplementary S.2.3 for details on the sequential GAME embedding training."}, {"title": "2.5 Validation of the GAME Algorithm", "content": "We performed a wide range of validation studies to evaluate the quality and clinical utility of GAME embeddings and compare them to benchmark embedding models. The validation tasks included: (1) detecting similar and related clinical relationships; (2) cross-institutional local code mapping; (3) feature selection; (4) federated patient risk profiling using trained embeddings for (a) suicide-related behaviors; and (b) Alzheimer's disease (AD) progression across multiple institutions. For benchmark models, we included the original PPMI-SVD embeddings from individual institutions, PubMedBert (PBERT), SAP-BERT (SBERT), CODER, BGE (BAAI general embedding) (768 dimensions), OpenAI text-embedding-3-small (1536 dimensions). In addition, we trained a standard 768-dimensional GAT embedding model (GAT-S) [30] as an additional benchmark, for which UMLS edges and binarized PPMI matrices serve as key input. See Supplementary S.2.6 for details on GAT-S."}, {"title": "2.5.1 Detecting similarity and relatedness between codes", "content": "We first evaluated the quality of embeddings with respect to their ability in detecting similarity and relatedness between EHR codes. We split the known similarity and relatedness pairs from PheCode, RxNorm, LOINC, CCAM, and UMLS into training and validation, as detailed in Supplementary S.1.1. For each relationship type, we computed cosine similarities between the embeddings of related pairs and randomly selected pairs, calculating the AUC to distinguish known pairs from random ones. Random pairs were chosen to match the semantic types of related pairs. For example, in analyzing \"may_treat\" or \"may_prevent\u201d relationships, we focused on disease-drug pairs. Relationships were also categorized by code types (e.g., \"PheCode-RxNorm\") to ensure clear summaries and stable AUC results."}, {"title": "2.5.2 Translating and mapping codes across EHR systems", "content": "We evaluated the accuracy of mapping local codes to a common ontology using embeddings against gold standard labels assembled via human curation. We considered four sets of mappings: 1) local VA lab codes to the first level LP codes with 11,808 curated mappings; 2) BDX CCAM procedure codes to CCS with 537 curated mappings; 3) UPMC local procedure codes to CCS with 199 curated mappings; and 4) UPMC local lab codes to LP codes with 1,814 curated mappings.\nOut of these four sets of mappings, only the VA mappings were previously curated at scale with detailed background knowledge about the codes in the Observational Medical Outcomes Partnership (OMOP) [41], which allows us to examine the top k accuracy of the codes for each set of embeddings. The top k accuracy is defined as the proportion of test cases in which the correct mapping for a given code appears among the top k predictions generated by the embeddings.\nThe remaining three sets were curated only for a subset of pairs sampled according to the embedding-based cosine similarities, as detailed in Supplementary S.3.2. Because of potential ambiguity in the code descriptions for these three sets, the annotators assigned \"yes,\" confirming that the mapping is correct, \"possible,\" suggesting that the mapping is potentially correct but could be more precise, and \"no\" that the mapping was incorrect. We evaluated the Spearman's Rank Correlation between the embedding-assigned cosine similarities from each method and the annotated labels."}, {"title": "2.5.3 Feature selection", "content": "Feature selection is a critical step in many downstream predictive modeling tasks, as it directly impacts the quality and interpretability of the results. GAME embeddings aim to enhance this process by improving the identification and selection of relevant features. To evaluate the effectiveness of GAME embeddings, we focused on eight diseases: Heart Failure (HF), Depression, Rheumatoid Arthritis (RA), Alzheimer's Disease (AD), Type 1 Diabetes (T1D), Type 2 Diabetes (T2D), Crohn's Disease (CD), and Ulcerative Colitis (UC).\nFor each disease, we applied all aformentioned embedding methods to identify the top 100 features with the highest cosine similarity to the disease's PheCode. Additionally, we included 100 randomly sampled features as negative controls. The union of these selected features formed the feature set for assessment against each disease. For each disease, we computed the cosine similarity between every feature in the feature set and the target PheCode across all embedding methods. We then evaluated the relevance of each feature to the target disease on a scale from 0 to 1, as determined by GPT-4. To"}, {"title": "2.5.4 Joint patient stratification across institutions", "content": "We further explored the potential of leveraging code embeddings for unsupervised clustering of patients' clinical profiles, aiming to stratify patients into subgroups with distinct disease progression patterns. Existing research on unsupervised clustering has primarily focused on single EHR systems utilizing aggregated EHR feature counts [16; 33] or embedding-based approaches [29]. While extending clustering algorithms to multi-institutional EHR data presents a unique opportunity to enhance generalizability, this endeavor has traditionally faced significant challenges due to inter-institutional heterogeneity, particularly in coding systems. Harmonized embeddings, such as GAME, address inter-institutional gaps by enabling joint modeling of patient profiles across institutions, even with differences in coding systems. By training code embeddings in a shared representation space, GAME allows patient-level EHR data to be seamlessly integrated, supporting unified analysis. This consistent representation facilitates tasks such as identifying \"patients like me\" and enables robust patient clustering and stratification across diverse healthcare systems.\nTo illustrate the utility of GAME embeddings, we applied this approach to cluster patient profiles to predict: (1) progression of Alzheimer's disease (AD) and (2) risk of suicide-related behaviors. For each condition, we defined a baseline period to extract relevant feature counts and computed patient embeddings as the weighted sum of feature embeddings. The weights were determined by multiplying the standard TF-IDF score by the cosine similarity between each feature embedding and the embedding of the target disease's PheCode (290.11 for AD and 297 for suicide), as detailed in Supplementary S.2.5. To ensure relevance, we included only features with cosine similarity exceeding the 99th percentile of random pair similarities. Patient embeddings were constructed independently for each institution. To enable joint clustering, we first reduced the embeddings' dimensions using a 3-dimensional t-SNE, approximated with variational autoencoder. We then applied federated k-means clustering. Clustering performance was validated by evaluating the association between cluster membership and the risk of developing a relevant clinical outcome. To study the importance of each EHR code in driving the difference between the clusters, we computed the odds ratio associated with the cluster membership, along with the p-values.\nAlzheimer's disease Although AD commonly presents as an amnestic syndrome, patients exhibit heterogeneous clinical profiles and experience highly variable rates of morbidity and mortality [1; 2; 57]. Stratification among AD patients at the time of diagnosis can enable better prognosis and disease management for patients [51]. To that end, we performed AD patient profiling across three institutions (UPMC, MGB, Duke) based on patients' EHR-derived data up to 2 years leading to the first AD diagnosis code (time\u2080) to predict future risk of nursing home admission. Admission to a nursing home, which indicates a loss of functional independence, is routinely documented in clinical practice and can be derived from the EHR. We defined nursing home admission as having at least one diagnosis code for admission to any residential institution (e.g., skilled nursing facility, assisted living facility, long-term care facility). We used the Cox proportional hazards model to investigate the association between cluster membership and future risk of nursing home admission, using data from the 2 years leading up to time\u2080, adjusting for age, gender, and race/ethnicity."}, {"title": "Suicide risk assessment", "content": "Mental health conditions such as depression, sleep disorders, anxiety disorders have been identified as risk factors that can increase the risk of suicide ideation or attempts [17; 46]. We clustered patients with a mental health disorder into subgroups based on their EHR-derived clinical profiles two years after the first diagnosis of mental health disorder (detailed in Supplementary S10) and hypothesized that such patient clustering based on GAME-generated patient representation may enable early stratification of future elevated risk of suicide among patients with mental disorders. We performed profiling of mental health disorders in patients across two institutions (MGB and Duke) based on EHR-derived data up to 2 years from the time of first mental health diagnosis. As risk factors of suicidal behaviors are known to vary by age [18], we stratified patients into five age groups (age < 18, 18 < age \u2264 25, 26 < age < 49, 50 \u2264 age < 65 and age > 65 years) and performed patient profiling separately for each group. We used the Cox proportional hazards model to investigate the association between cluster membership and future risk of suicide ideation and suicide attempt, adjusting for age, gender, and race/ethnicity."}, {"title": "3 Results", "content": "In this section, we evaluate the performance of the GAME embedding on several downstream tasks. First, we compare the capability of the model in recovering known similarity and relatedness relationships and in mapping the local lab codes from one site to LOINC and LP codes. Later, we show the application of the embedding for feature selection in diverse conditions as well as patient stratification in Alzheimer's disease and mental health disorders."}, {"title": "3.1 Detecting similarity and relatedness between clinical concepts", "content": "The quality of the GAME embedding is evaluated by how well it is in detecting the similar and related clinical concepts through their proximity. Figure 5 presents the AUCs for detecting similar and related clinical concept pairs against randomly sampled pairs. The GAME embedding achieved AUCs of 0.913 for similarity relationship and 0.925 for relatedness relationship, demonstrating strong performance for both tasks. Detailed description of the data is available in Supplementary Table S3 with the number of validation pairs detailed in Supplementary Table S2. The AUCs for specific relationship types are also provided in Supplementary Table S4.\nWe found that BGE (768 dimensions) and OpenAI (1,536 dimensions) embeddings performed well in detecting similarity pairs, while GAME (256 dimensions) achieved comparable performance with lower-dimensional representations. In our validation, instead of directly using individual pairs, we employ a more rigorous approach by splitting hierarchical similarity pairs by branches; further details are provided in Supplementary S.1.1. Moreover, GAME significantly outperformed all other methods in detecting relatedness between EHR concepts, further highlighting its effectiveness. This comparison underscores GAME's ability to achieve both high similarity AUC and exceptional relatedness AUC, setting it apart from other approaches.\nTo provide a strong baseline, we used institutional PPMI embeddings to compute the AUC by evaluating pairs within each institution and then calculated the average AUC across PPMI sources. We found that the PPMI-SVD embeddings, while mostly maintaining the within-institutional relationships, failed to detect relationships across different institutions. In contrast, GAME consistently excelled in detecting broader relationships, both within and across institutions.\nAdditionally, we observed that the standard GAT baseline embeddings did not perform as well as GAME in detecting similar and related pairs. Even though the standard GAT baseline leverages some"}, {"title": "3.2 Mapping codes between EHR systems", "content": "We further show the capability of the GAME embedding in recovering the correct mapping from VA local lab codes to LOINC/LP codes. The ground truth is created from manual mapping by clinical experts. Table 2 presents the accuracy of recovering the correct mapping using the embeddings from PLMs. It is clear that the GAME embedding significantly outperformed all other methods by a wide margin. GAME achieved a TOP1 accuracy of 74.2%, while no other approach exceeded 62.2%. Additionally, GAME showed a high TOP10 accuracy of 90.7%. Notably, these results were obtained using only the similarity component of the GAME embedding with a dimensionality of 256, whereas the other methods relied on higher-dimensional embeddings, as described in Section 2.5. To further highlight the efficacy of GAME embedding, we also compared the accuracy of code mapping using lower-dimensional BGE and OpenAI embeddings, with the results shown in Supplementary Table S6.\nFigure 6 shows the Spearman's Rank Correlation results between cosine similarities and human annotations for mapping UPMC Local PX and BDX CCAM to CCS, and for mapping UPMC Local Lab to LOINC/LP. In all three tasks, the cosine similarity of GAME embeddings aligns best with human annotations, achieving the highest Spearman's Rank Correlation. Besides GAME, OpenAI and BGE also"}, {"title": "3.3 Feature selection", "content": "We summarize the key feature selection results in Figure 7, with detailed results provided in Supplementary Table S8. For clarity and conciseness, we report the average PPMI-SVD results across institutions (PPMI AVE) for each disease. Methods such as BioBERT, PubMedBERT, SapBERT, and CODER were excluded from the figure due to their poor performance in feature selection. The comparison focuses on methods that performed relatively well, including PPMI AVE, BGE, OpenAI, GAT-S, and GAME.\nIn Figure 7, we observe that the C-index of GPT-4 assigned scores and cosine similarity of GAME embeddings are better than those of other methods. This demonstrates that the cosine similarity of the GAME embedding accurately reflects the relative importance of features to the target diseases. Additionally, we find that OpenAI embedding performs relatively well for diseases such as UC and RA, while GAME embeddings consistently perform well across all conditions. This demonstrates the superiority of GAME embeddings in feature selection for target diseases."}, {"title": "3.4 Joint patient stratification across multiple institutions", "content": null}, {"title": "3.4.1 Alzheimer's disease", "content": "The AD cohorts at UPMC, MGB and Duke consist of 16411, 17770 and 13438 patients, respectively, with about 64.1% to 65% females and an average age of 79.7-81.2 years at the time of the first AD diagnosis. The median follow-up time was 78 months at UPMC, 81 months at MGB and 36 months at Duke. Detailed demographic information is presented in Supplementary Table S9. AD patient embeddings"}, {"title": "3.4.2 Mental health disorders", "content": "GAME effectively stratified mental health patients in each age group into two subgroups, each with distinct future risks of suicidal ideation and suicidal attempts. Demographic information of the mental health cohorts at MGB and Duke is detailed in Supplementary Tables S11 - S15 and patient embeddings from both institutions are visualized in Supplementary Figure S6. Patients in the same age group from different institutions were"}]}