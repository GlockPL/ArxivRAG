{"title": "Predicting Depression and Anxiety Risk in Dutch Neighborhoods from Street-View Images", "authors": ["Nin Khodorivskol", "Giacomo Spigler"], "abstract": "Depression and anxiety disorders are prevalent mental health chal- lenges affecting a substantial segment of the global population. In this study, we explored the environmental correlates of these disorders by analyzing street-view images (SVI) of neighborhoods in the Netherlands. Our dataset comprises 9,879 Dutch SVIs sourced from Google Street View, paired with statistical depression and anxiety risk metrics from the Dutch Health Monitor. To tackle this challenge, we refined two existing neural network architectures, DeiT Base and ResNet50. Our goal was to predict neighborhood risk levels, categorized into four tiers from low to high risk, using the raw images. The results showed that DeiT Base and ResNet50 achieved accuracies of 43.43% and 43.63%, respectively. Notably, a significant portion of the errors were between adjacent risk categories, resulting in adjusted accuracies of 83.55% and 80.38%. We also implemented the SHapley Additive exPlanations (SHAP) method on both models and employed gradient rollout on DeiT. Interestingly, while SHAP underscored specific landscape attributes, the correlation between these features and distinct depression risk categories remained unclear. The gradient rollout findings were similarly non-definitive. However, through manual analysis, we identified certain landscape types that were consistently linked with specific risk categories. These findings suggest the potential of these techniques in monitoring the correlation between various landscapes and environmental risk factors for mental health issues. As a future direction, we recommend employing these methods to observe how risk scores from the Dutch Health Monitor shift across neighborhoods over time.", "sections": [{"title": "1 Introduction", "content": "Anxiety disorders and depression remain dominant mental health concerns globally. Traditional methodologies that investigate the relationship between these disorders and environmental aspects like street environments, primarily rely on manual surveys and identification of pre-specified features. These methods are not only expensive but also subjective. A growing body of recent research underscores the potential of Deep Learning (DL) applied to Street View Images (SVI) as a promising alternative. However, there exists a noticeable gap in exploring this in a Dutch setting, which our study seeks to bridge."}, {"title": "2 Related Work", "content": "Breaking from the convention of feature extraction dominant in prior studies, we harness the latest advancements in computational power to apply DL directly to SVI. By using Explainable AI (XAI) techniques, our goal is to dissect the patterns the models learn from these images, pinpointing crucial components that play a role in predicting the risk of depression and anxiety. Our primary research objective is to determine the efficacy of DL techniques applied to SVI in predicting and analyzing the proxy of the incidence of anxiety and depression disorders within the Netherlands. To achieve the objective, we fine-tuned two distinct pre-existing neural network architectures. The resulting accuracies achieved non-trivial performance, hinting at the significance of the content of SVIs for predicting mental well-being. Further, analysis using the SHapley Additive exPlanations (SHAP) technique spotlighted specific features as being pivotal in the model's predictive decisions across various categories. Yet, the overlapping influence of these identified features suggests they cannot be earmarked as indicators for any specific class.\nOur main contributions are:\nCollection of a curated Dutch SVI dataset - including both rural and urban areas - with associated labels for \"high risk of depression and anxiety\" metrics from the Dutch Health Monitor.\nFine-tuning two neural network architectures to predict depression and anxiety risk directly from SVIs, achieving non-trivial performance.\nAnalysis to identify significant elements in SVIs using Explainable Artificial Intelli- gence (XAI) techniques.\nWe release the code used to collect the dataset and to perform the analysis at https://github.com/khna89/DL_streetview_depression_anxiety."}, {"title": "2.1 SVI in (mental) health research", "content": "Street View Imagery (SVI) provides a firsthand look at urban settings, almost as if one is walking on the streets themselves. Some studies indicate that SVI can provide insights on health-related factors, like how walk-friendly a neighborhood is, in situations where traditional maps or satellite images don't offer clear answers. Researchers have been tapping into SVI to examine how urban features relate to behavior, health, and demographic patterns. Recently, deep learning has been employed to identify specific attributes in these images, such as the amount of greenery or types of buildings. For example, areas where a lot of sky and trees are visible directly from the street have been linked with lower rates of depression among the elderly. However, these approaches focus on a limited set of features, potentially missing other influential environmental factors. Along these lines, demonstrated that detecting more features of the environment could be effective in predicting several health-related variables."}, {"title": "2.3 Explainability in computer vision", "content": "Understanding how a model makes decisions can be crucial, especially when analyzing environmental factors related to mental health. It is thus useful to employ explainability techniques to help make model decisions more transparent and easier to grasp for humans. One standout method in the realm of Explainable AI (XAI) is the SHapley Additive exPlanations (SHAP). While various approaches exist, SHAP brings several of them, like LIME, DeepLIFT, and Layer-wise relevance propagation, under one umbrella. Notably, SHAP is able to align its explanations with human thinking. Simply put, SHAP values show how much each feature in an image affects the predictions of the model. In this study, we chose SHAP for its proven human interpretability and model-agnostic nature, enabling its application across our fine-tuned networks. Additionally, we explored the use of \"attention rollout\", an XAI method specifically designed for vision transformers (ViT). ViTs, while accurate, exhibit complex relationships in their inputs due to their self-attention mechanisms, com- plicating model interpretation. The attention rollout technique, as introduced by Abnar and Zuidema (2020), provides a solution by systematically unrolling attention throughout the model's layers, thereby constructing a comprehensive attention graph. Recent literature indicates the potential of this method in improving the clarity of explanations for image classification tasks."}, {"title": "3 Methods", "content": "The data used in this project consists of mental health statistics collected per neigh- bourhood, together with a collection of Street View Images (SVI) sampled for each neighbourhood."}, {"title": "3.1 Data", "content": "Mental health data. Target variable was derived from the Dutch Health Monitor. The Dutch Health Monitor measures depression and anxiety risk based on the Kessler-10 scale, and contains responses from 540,000 participants aged 18+. Namely, each respondent answered 10 questions, each yielding a score between 1 and 5. The sum of these scores determined the risk level for depression or anxiety disorders. Specifically, a total score of 30-50 categorized a participant as high-risk. The percentage of high-risk individuals in each neighborhood served as our initial continuous target variable.\nWe discretized and stratified the risk metrics into 5 levels of risk of depression and anxiety: \u201cvery low\u201d, \u201clow\u201d, \u201cmoderate\u201d, \u201chigh\u201d, \u201cvery high\". The discretization was accomplished by dividing the range of the \"high risk of depression and anxiety\" scores (in the range of 1% to 21.9%) into five uniform intervals. This allowed for equally representing depression scores in order to train the classifier to be equally good at all the levels. Nevertheless, this approach does not mirror the actual distribution of the variable, as shown in the Supplementary Materials. Notably, the majority of instances in the monitor fall in the \"very low\" and \"low\" brackets. Since the \"very high\" category was only associated with 7 neighborhood and was thus at risk of overfitting, we decided to combine the \"high\" and \"very high\" categories together into a single class.\nSVI (General considerations). Since there is no publicly available Dutch SVI dataset, part of the study involved the collection of the dataset. In order to also cover the gap in studies for rural areas, and taking advantage of the vast farming landscape of the Netherlands, the data was collected from the cities as well as from the rural areas. Building upon previous research that highlighted the predictive significance of greenery for mental health variables, our data collection was restricted to the 'green' months, from May to September. This strategy ensures a more accurate representation by mitigating the seasonal variations that might influence the predictive accuracy of each neighborhood on the target variable.\nGeographically stratified sampling. To ensure a well-rounded representation of the study area, we devised a sampling protocol to capture a uniform number of images for each category of the target variable. To achieve a balanced dataset, we sampled:\n1 image for each \"very low risk\" and \"low risk\" sampled neighborhood;\n3 images for each \"moderate risk\" neighborhood;\n20 images for each of the combined \"high and very high risk\" neighborhoods.\nMore details on this procedure can be found in the Supplementary Materials. From this approach, we amassed a total of 9,879 images (detailed breakdown in Table 2), representing 5,952 neighborhoods uniformly distributed across the country (Figure 1). This collection method ensures near uniformity over the target classes, albeit with a minor under-representation in the \"high and very high\" category.\nSVI (Data preprocessing). The street-view images were randomly cropped from 512x512 pixels to 224x224 pixels for training to prevent overfitting and to match the input size expected by pre-trained models. For validation and testing, full images were resized to 224x224 pixels. Image RGB channels were normalized using ImageNet statistics, mean = (0.485,0.456,0.406), std = (0.229,0.224,0.225). The dataset was randomly partitioned into training (70%), validation (15%), and test (15%) sets."}, {"title": "3.2 Experimental setup", "content": "Two pre-trained models, DeiT and ResNet-50, were used as base for the experiments. The models were modified by replacing the output layer, specific for the classification task of interest over 4 categories. A cross-entropy loss was used.\nHyperparameter tuning was performed using grid search on a subset of 30% of the dataset for training and 10% for validation. For DeiT, we explored different architectures (Tiny, Small, Base), number of unfrozen layers (0, 1, 3, 5), learning rates (0.01, 0.005, 0.001), and optimizers (Adam, SGD, Adagrad). For ResNet-50, similar parameters were tested, with the addition of the RMSprop optimizer. Both models were then fine- tuned using the best hyperparameter combinations and the full training set. Detailed hyperparameter values are provided in the Supplementary Materials."}, {"title": "3.3 Evaluation and Explainability", "content": "Fine-tuning was performed by trainng the models for up to 100 epochs with early stopping triggered if validation loss did not improve for 10 epochs. In practice, early stopping was always triggered before reaching 100 epochs. Regularization techniques were used to reduce risk of overfitting, including dropout, L2 regularization, learning rate scheduling, and early stopping.\nEvaluation and explainability were conducted on held-out test data.\nPerformance evaluation. Model performance was assessed via accuracy, average loss, and weighted F1 scores. Additionally, we introduced an 'adjusted accuracy' metric that ignores misclassifications across adjacent classes, instead considering them correct. Given the continuous character of the target variable and the steps taken in its dis- cretization, this metric holds significant relevance. For a deeper understanding of its importance, refer to the Discussion section.\nModel explanation. To delve deeper into the model's mechanisms, we selected samples that were correctly classified. The samples were then ranked based on the outputs of the models, and the 10 samples with the highest predicted probabilities from each class were earmarked for manual exploration and further test with XAI methods.\nFor the computation of SHAP values, we established a background dataset comprising 50 random images using the Gradient Explainer. To visualize importance scores, we tweaked the 'shap.image_plot' function to facilitate individual file exports.\nFinally, we applied Gildenblat's 2020 version of attention rollout to study the final DeiT model. This tool allows for the visualization of attention weights, offers options for displaying extreme weights selectively, and lets users choose a fusion method. We set a discard ratio at 0.8, enhancing the clarity of our visualizations. For additional details, we refer to the Supplementary Materials."}, {"title": "4 Results", "content": "The performance of the trained models is reported in Table 3. Both the transformer (DeiT) and CNN (ResNet) models achieved moderate performance, with ResNet slightly surpassing DeiT.\nAs shown in the confusion matrices (Fig. 2), most misclassifications are found within adjacent classes. This is due to the discretization of the original continuous target variable, for which two similar samples, e.g., 5.38 and 5.39, which lie just across the threshold between the \"very low\" and \"low\" categories, are assigned to two distinct categories. We thus adopt an 'adjusted accuracy' metric that accepts as correct all classifications within adjacent classes."}, {"title": "4.1 ResNet50", "content": "The best model selected through hyperparameter tuning had 3 unfrozen layers, Adagrad optimizer, learning rate of 0.01, two dropout layers with drop probability of 0.1, and L2 regularization with $$\\lambda = 0.00005$$. The model achieved an accuracy of 43.63% on the test set, with an adjusted accuracy of 80.38% (Table 3).\nOur analysis of the true positive predictions with the highest logits uncovered consistent patterns across different risk levels, as illustrated in Fig. 3. Specifically:\nThe \"very low\" risk class mostly displayed rural landscapes, often devoid of built structures but occasionally featuring single-family homes.\n\"Low risk\" images typically portrayed terraced houses, with the occasional sight of duplexes or single-family homes. These images often had clear skies and cultivated greenery.\nThe \"moderate\" as well as the \"high and very high\" levels frequently presented blocks of flats and cars, with limited greenery and sky in view."}, {"title": "4.2 DeiT", "content": "The best DeiT model selected through hyperparameter tuning utilized 5 unfrozen layers, SGD optimizer, a learning rate of 0.001, dropout layers with drop probability of 0.2, and $$\\textrm{L}_2$$ regularization with $$\\textrm{(X = 0.0001)}$$. The model achieved 43.43% accuracy on the test set, with adjusted accuracy of 83.55%, and was thus comparable in performance to the ResNet50 model.\nAn examination of high-confidence true positive predictions revealed distinct features for each class (see Figure 4):\n\"Very low risk\" images typically displayed fields and expansive sky areas without any built structures, mirroring ResNet's predictions.\n\"Low risk\" images predominantly showcased single-family homes and duplexes, a departure from ResNet's usual portrayal. However, like in the case of the ResNet, these images often included curated green spaces.\n\"Moderate risk\" images were characterized by apartment blocks, cars positioned farther away or absent altogether, and bicycles.\nFor the \"high, very high risk\" category, large apartment complexes dominated the imagery.\nNotably absent were terraced houses, which were not present in the top-confidence predictions for any class in this model.\nSHAP analysis indicated that, similar to ResNet50, DeiT Base relied on sky areas but differed in the importance of cars and bicycles (see figures in the Supplementary Materials). These features, however, were ambiguous in their influence on classification, as evidenced by extreme SHAP values in both directions.\nThe attention weight visualizations did not offer clear interpretative insights and are detailed in the Supplementary Materials."}, {"title": "5 Discussion and Conclusion", "content": "This study examined the potential of deep learning (DL) models, namely DeiT and ResNet, in predicting depression and anxiety risks using Dutch Street View Images (SVIs). This research provides initial evidence suggesting DL models, when trained on SVIs, might be effective in discerning neighborhood-level depression and anxiety risks. Further studies are essential to enhance the models' interpretability and to guide public health strategies on the significance of specific visual environmental factors in relation to depression and anxiety risks.\nKey findings. Both the DeiT and ResNet models displayed a propensity to misclas- sify neighboring risk categories, likely due to the continuous nature of the depression and anxiety risk scores. Initial analyses of high-confidence, true-positive predictions highlighted class-distinct features, such as the balance between greenery and the built environment, a finding consistent with prior research.\nWhile earlier studies centered on extracting and assessing the predictive capability of features like greenery or sky views on mental health outcomes, the visualization of SHAP values for our fully fine-tuned ResNet model indicates the importance of expansive sky areas and tree canopies. Interestingly, these insights were derived directly from images without manually specifying features of interest. Further, distinctions such as the presence of cars versus expansive sky areas appeared critical for accurate classifications. Other elements like roofs, shaded walls, and shadows beneath roofs, though not highlighted in prior research, emerged as significant for accurate predictions. Notably, roofs and their associated shadows seem as vital as the general greenery and nearly as influential as the specific tree canopy.\nThese patterns hint at a potential correlation between specific visual elements in a neighborhood and the risk of depression. This observation aligns with prior research that linked visual elements like water, sky, and greenery with mental well-being. This connection is further underscored by our examination of high-confidence true-positive predictions (see Figure 4). Here, each risk category appeared to possess a unique balance of greenery versus built environment, mirroring some findings from past studies. However, earlier investigations mostly zoomed in on greenery, sky, and water indices without juxtaposing them against the built environment ratio. Our results suggest variations in the types of built environments related to each risk level, pointing to a need for more in-depth exploration in literature to understand the relationship between built environment types, greenery, and mental health risks.\nLimitations and Challenges. While both the ResNet50 and DeiT networks performed well on the classification task, their accuracy remains far from optimal. This may be due not only to the limited amount of data used for training, but also because of the multitude of factors contributing to depression and anxiety risk, many of which may not be visible in SVIs. For example, many known factors are due to genetics, diet, infections, or trauma, which would not be evident from street-view images. At the same time, as Keralis et al. (2020) previously pointed out, there are factors that are environmental in nature, but are not represented in the SVI, for example perceived safety and traffic congestion.\nThe 'high depression and anxiety risk' variable in this study was sourced from Dutch Health Monitor statistics, which rely on Kessler's questionnaire rather than Diagnostic and Statistical Manual of Mental Disorders (DSM) criteria for their categorizations (see Methods for more details). This was a deliberate choice, as access to clinically diagnosed cases disaggregated by zip codes would entail handling sensitive personal data. Given the exploratory nature of this pilot study, utilizing such data was deemed ethically unsuitable.\nThe study cannot suit a purpose of causal inference about the reasons for depression and anxiety disorders' prevalence as it doesn't capture temporal precedence and doesn't exclude any confounding variables.\nFinal Remarks. This study provides preliminary evidence for the utility of deep learning to aid the monitoring of environmental factors correlated with mental health wellness. Future work should focus on improving the efficacy of Explainable AI techniques in this domain, and on using them to assess the importance of specific environment features on the risk of depression and anxiety. Similar studies can suggest environmental factors strongly correlated with depression and anxiety disorders, that could then be further investigated with methods allowing for causal inference. We finally suggest that applications similar to those developed in this work may be useful for real-time monitoring of the impact of changes in the environment over time on mental health. This could serve as a simpler alternative to the biennial Dutch Health Monitor, allowing for more frequent assessments of neighborhood mental health risks."}, {"title": "6 Supplementary Materials", "content": "Dataset Original distribution of the target variable. Figure 5 provides more information on how the original risk of depression and anxiety variable is distributed in the Dutch Health Monitor.\nDetails of the sampling procedure. The Dutch Health Monitor's data aug- mented with the discretized target variable was merged on neighbourhood codes with geographical data of Basis Registratie Kadaster & Centraal Bureau voor de Statistiek (2022). The coordinates of the polygons were converted from the European Petroleum"}]}