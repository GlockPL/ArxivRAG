{"title": "Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions", "authors": ["Lucas Correia", "Jan-Christoph Goos", "Philipp Klein", "Thomas B\u00e4ck", "Anna V. Kononova"], "abstract": "Time-series anomaly detection plays an important role in engineering processes, like development, manufacturing and other operations involving dynamic systems. These processes can greatly benefit from advances in the field, as state-of-the-art approaches may aid in cases involving, for example, highly dimensional data. To provide the reader with understanding of the terminology, this survey introduces a novel taxonomy where a distinction between online and offline, and training and inference is made. Additionally, it presents the most popular data sets and evaluation metrics used in the literature, as well as a detailed analysis. Furthermore, this survey provides an extensive overview of the state-of-the-art model-based online semi- and unsupervised anomaly detection approaches for multivariate time-series data, categorising them into different model families and other properties. The biggest research challenge revolves around benchmarking, as currently there is no reliable way to compare different approaches against one another. This problem is two-fold: on the one hand, public data sets suffers from at least one fundamental flaw, while on the other hand, there is a lack of intuitive and representative evaluation metrics in the field. Moreover, the way most publications choose a detection threshold disregards real-world conditions, which hinders the application in the real world. To allow for tangible advances in the field, these issues must be addressed in future work.", "sections": [{"title": "1 Introduction", "content": "As a result of the fourth industrial revolution, also known as industry 4.0, immense amounts of data are collected from sensors mounted at different checkpoints in many processes in research and development, manufacturing and testing [98]. This data can expose subtle but important trends and correlations, as well as give the data user key insights on how to optimise engineering systems and processes, which can potentially provide a company with a competitive advantage in the market. Recording high-quality data is important, as incomplete or anomalous data can negate any potential benefits that can be extracted from it. With the rise of industry 4.0, anomaly detection has therefore gained relevance over the past decade, with the bar being set ever higher as data becomes more and"}, {"title": "2 Taxonomy in Time-series Anomaly Detection", "content": "To provide the reader with an illustration of the relationship between terms introduced in the taxonomy used an overview is represented graphically in Figure 2."}, {"title": "2.1 Anomaly Types and Detection", "content": "Anomalies in time series can be assumed to have different shapes and forms. A commonly used and accepted definition [35] reads as follows:\n\"An observation which deviates so much from other observations as to arouse suspicions that it was generated by a different mechanism.\"\nOver the years, several taxonomies have been proposed to better classify different anomalies. This work mostly follows the taxonomy suggested by [9], where anomalies are classified into point outliers, sub-sequence outliers (also known as collective anomalies in the literature) and outlier time series. In this work, these three types will be from now on referred to as point anomalies, sub-sequence anomalies and whole-sequence anomalies, respectively.\nA point anomaly is defined as a value at a time step that does not conform to the typical behaviour of a system. Consider a testing subset $D_{test}$ in data set $D$ containing $N$ sequences, such that $D_{test} = [S_1, ..., S_n, ..., S_N]$, where $S_n \\in \\mathbb{R}^{T_n \\times d_D}$. In a given multivariate sequence $S_n$, an anomaly event $A \\in \\mathbb{R}^{S \\times d_a}$ of length $S$ that is detected in $d_a$ channels, where $d_a \\leq d_p$, is considered a point anomaly when $S = 1$. An example of a point anomaly is illustrated in Figure 3. While more easily\ndetectable than the other types, these anomalies are rare events in the real world, as systems affected cannot usually return to a nominal state before the next time step arrives unless the sampling rate is very low.\nSub-sequence anomalies are defined by a series of anomalous time steps, i.e. a sub-sequence within a time series that does not reflect the nominal behaviour of a system. In a given multivariate sequence $S_n$, an anomaly event $A \\in \\mathbb{R}^{S \\times d_a}$ of length $S$ that is detected in $d_a$ channels, where $d_a \\leq d_p$, is considered a sub-sequence anomaly when $1 < S < T$. In a real-world system, this type of anomaly may occur when a component in the said system runs at reduced functionality or fails but manages to recover to a nominal state after a period of time. An example of a sub-sequence anomaly is illustrated in Figure 4.\nA whole-sequence anomaly can be seen as a long sub-sequence that has the same length as the entire sequence. Hence, in a given multivariate sequence $S_n$, an anomaly event $A \\in \\mathbb{R}^{S \\times d_a}$ of length $S$ that is detected in $d_a$ channels, where $d_a \\leq d_p$, is considered a whole-sequence anomaly when $S = T$. This type of anomaly can occur when an initial parameter or state deviates from the norm, leading to all observations in the sequence being anomalous as well. An example of a whole-sequence anomaly is illustrated in Figure 5."}, {"title": "2.2 Continuous- and Discrete-sequence Anomaly Detection", "content": "Time-series anomaly detection can be split into two main areas: continuous- and discrete-sequence. Continuous-sequence anomaly detection is the most common type present in public data sets and is defined as detecting anomalies in a process that exists for a longer continuous time period without breaks, i.e. $N = 1$ in a testing subset $D_{test}$. This includes monitoring applications like in water distribution, server machines or even heartbeat rhythms. Use cases of continuous-sequence anomaly detection tend to consist of a singular longer time series which contains nominal and anomalous sub-sequences within it, therefore they can only contain point and sub-sequence anomalies.\nDiscrete-sequence anomaly detection, in contrast, is defined as detecting anomalies in chunks of processes that happen independently of each other, i.e. $N < 1$ in testing subset $D_{test}$. One example"}, {"title": "2.3 Online Training and Inference", "content": "Using model-based approaches generally involves two processes: training and inference. Training is the process of automatically adjusting model parameters by means of optimisation using training data, whereas inference refers to the application, where model parameters are no longer adjusted. Online approaches are defined as models that infer in an online manner and, optionally, are trained in an online manner. Online training, therefore, refers to the process of adjusting model parameters as training data is streamed. Unlike offline training, which is done once in most cases, online training runs continuously and for an undefined amount of time. Online inference refers to the ability of an approach to detect anomalous behaviour in time steps as soon as they are observed, rather than waiting for the time series to have finished streaming and only then evaluating the entire sequence, i.e. offline. This is especially useful in real-world use cases where timely detection is important. A more strict version of online anomaly detection is real-time anomaly detection, where the current time step is evaluated before the next one arrives."}, {"title": "3 Related Work", "content": "Various anomaly detection surveys with a focus on time series and online functionality have been published over the years. A summary of the surveys is given in Table 1. The table shows whether the surveys discuss anomaly detection taxonomy, available data sets and metrics, and what type of approaches are identified. The list of publications, surveys, and reviews has been found using the keywords anomaly detection, outlier detection, unsupervised, semi-supervised, multivariate, time series, online, real-time and streaming data using a variety of libraries, such as Institute of Electrical and Electronic Engineers (IEEE) Xplore, Elsevier ScienceDirect, Springer Link and the Association for Computing Machinery (ACM) Digital Library, in the time between 2000 and 2024. Up until recently, surveys published on online time-series anomaly detection only discussed conventional methods, which for the purpose of this survey will denote methods not based on data-driven modelling. Note that the terminology \"time series\" and \"sequence\" are used synonymously throughout this survey. To help the reader to more easily distinguish between the terms introduced in the taxonomy in this work and other terms used in related work, the terminology stemming from this work's taxonomy is emphasised and hyperlinked to the relevant subsection in Section 2.\nAccording to [14], there are two relevant problem formulations in time-series anomaly detection: sequence-based and contiguous sub-sequence-based anomaly detection. They are somewhat analogous to discrete-sequence and continuous-sequence anomaly detection, though associated with fairly rigid definitions. In their work, [14] frame sequence-based and contiguous sub-sequence-based anomaly detection such that it can only feature whole-sequence anomalies and sub-sequence anomalies, respectively, which may not be the case in the real world. Furthermore, they dedicate a section discussing online anomaly detection in the context of discrete-sequence and continuous-sequence problem framing.\n[34] categorise time-series anomaly detection problems into five different fields, with the two relevant being so-called time-series data and stream data, essentially designating offline and online anomaly detection. Time-series data is further split into two subcategories: single time series, where exactly one time series is evaluated and time-series databases, where several time series are evaluated. In a single time series, point and sub-sequence anomalies can be detected, while in the case of time-series databases, sub-sequence and whole-sequence anomalies can be found, though it is not mentioned why a point anomaly cannot be detected in a time series database. Additionally, a special case exists where the database can be compared to a single test sequence. Single time series and time-series databases are analogous to discrete-sequence and continuous-sequence anomaly detection, though here they"}, {"title": "4 Benchmarking", "content": "Benchmarking is an important part of anomaly detection research, as it enables objectively measuring progress in the field. To benchmark any given approach against others, it has to be applied to the same data set and use the same evaluation metrics. This section gives a detailed overview of the most commonly used public data sets and their respective weaknesses, as well as of the metrics used to evaluate anomaly detection approaches and proposed improvements in the literature."}, {"title": "4.1 Data Sets", "content": "Anomaly detection literature uses a variety of time-series data sets over the years. Publicly available data sets play an important role in enabling researchers to benchmark their methods against the state of the art. To inform the reader about the publicly available data sets, the key information is summarised in Table 2.\nUnfortunately, most popular data sets are unsuitable for time-series anomaly detection, as concluded by [94]. They make a case against many publicly available data sets by pointing out four main flaws, at least one of which can be found in most data sets. These flaws include:\n\u2022 triviality\n\u2022 unrealistic anomaly density\n\u2022 uncertain labels\n\u2022 run-to-failure bias\nThey define triviality as being able to be solved with a very limited amount of code, hence weakening the case for the need for complex parameter-heavy models. Then they point out the unrealistic anomaly density, where the assumption that anomalies are very rare events does not hold. The next issue [94] discuss is the apparent mislabelled ground truth. In some cases, regions of similar behaviour are sometimes labelled anomalous, sometimes labelled as nominal, which can skew results. Lastly, they argue that some data sets have a run-to-failure bias, i.e. anomalies appear at the end of sequences and hence the anomaly detection performance can be improved by \"guessing\" that the last time steps are anomalous. Perhaps the word failure is inaccurate in this context, as an anomaly is not necessarily a failure but simply a deviation from nominal behaviour. An alternative and more general term could be nominal-to-anomaly bias. It could be argued that it is nominal-to-anomaly bias is intrinsic in anomaly detection as it is more likely for a system to behave nominally and then fail than the other way around, although this depends on the application. The aforementioned issues are only pointed out for a subset of the public data sets considered by [94], however, their criticism can be extended to all other public data sets, which is discussed in the following.\nThe High Rack Storage System (HRSS) data set [4] represents the behaviour of an unoptimised (standard) and optimised factory at the Ostwestfalen-Lippe University of Applied Sciences. One issue present is that at a few points, nominal time steps are sandwiched between anomalous time steps, raising suspicion of possible mislabelling. It features an unrealistic anomaly density, as around\n24% of the test time steps are labelled as anomalous, as shown in Figure 6. Lastly, two nominal and two anomalous sequences are provided, but no specification of training and testing subsets, therefore publications using this data set may not be comparable.\nThe Kaspersky Lab provides a data set from the process industry. Using an industrial process model, they propose the Tennessee-Eastman Process data set (TEP) [23], for which a labelled nominal training subset is provided. As specified by [24], the DANGER warnings are considered the anomalies. The TEP data set has a few anomalous sequences that suffer from unrealistic anomaly density, where a single nominal time step is sandwiched between two anomalous sub-sequences. In addition to that, the type 21 anomalies can easily be detected by looking at the feature 8.\nThe Singapore University of Technology and Design published two data sets: the Secure Water Treatment (SWaT) [29] and the Water Distribution (WADI) [3] data sets. Both consist of test bed data under nominal conditions and under various attack scenarios, however, WADI is composed of higher dimensional data, though no training/testing subset splits are provided. SWaT and WADI are not explicitly named by [94], but still suffer from the same flaws. For example, the SWaT data set suffers from a variety of issues. First and foremost, it contains half a dozen features that are constant throughout the train and test sets, making them redundant for modelling and hence are not considered in Table 2. In addition to that, it features a very high anomaly density, in fact, the anomaly between time steps 227828 and 262727 accounts for around 65% of the total anomalous time steps. This anomaly is considered trivial as it can easily be detected by just looking at a single\nfeature, as shown in Figure 7. Of the 127 features in WADI many need to be filtered out. Like SWaT, WADI suffers from redundant features, 33 in total, as well as features with missing values, 4 in total, and features with NaN values, another 4 in total, bringing the total feature count to 86. Of the four approaches found in the literature that use this data set, all use a different feature count, making this incomparable.\nNASA published two commonly used data sets: the Soil Moisture Active Passive (SMAP) satellite data set and the Mars Science Laboratory (MSL) rover data set [43, 42]. Both are split into training and testing subsets, though the training subset consists of only nominal samples. In the supporting material of [94], they indicate that both data sets suffer from triviality and unrealistic anomaly density. Apart from the afore-mentioned criticism, it should be noted that, while technically multivariate in the sense that the sequences in either data set do have multiple channels, all channels other than the first one (the telemetry channel) are binary one-hot encoded command channels with no dynamic behaviour. [44] only predict the one telemetry channel in their work, which may be acceptable for predictive models but not applicable to other model families, like reconstructive models.\nThe University of Michigan published the CNC Mill Tool Wear data set [83], which consists of 18 multivariate time series. The main issue with this data set is that labels only exist for an entire sequence (worn/unworn) and from the 18 sequences only 8 are nominal (unworn). Given that some of the eight sequences may need to be used as training data, the data set is unbalanced, but towards the anomaly class. Because the anomaly class is more common in the test set, the precision metric will be inflated, as false positives will naturally be small. Lastly, the CNC data set features a very high anomaly density of 53%, hence, it is not recommended for anomaly detection.\nAnother multivariate time-series data set is the Server Machine Data set (SMD) [80] which features 38 channels and unlabelled training subsets for each machine. Like SMAP and MSL, SMD also suffers"}, {"title": "4.2 Metrics", "content": "Evaluation metrics allow different anomaly detection performance aspects to be quantified and compared. These metrics can generally be separated into two different classes: calibrated and uncalibrated. In order to provide a consistent notation throughout the following subsections, the following notation system is introduced. Reconsider a testing subset $D_{test}$ in data set $D$ containing\n$N$ sequences that can be nominal (without anomalies), entirely anomalous or partially anomalous, such that $D_{test} = [S_1, ..., S_n, ..., S_N]$, where $S_n \\in \\mathbb{R}^{T_n \\times d_D}$. Here, $T_n$ is the number of time steps in sequence $S_n$, which varies depending on $S_n$ and $d_D$ the number of features, i.e. the dimensionality of $S_n$. The ground-truth label set $\\mathbb{L}_{gt}$ corresponding to $\\Gamma$ contains a binary label vector for each sequence, such that $\\mathbb{L}_{gt} = [l_{1}^{gt}, ..., l_{n}^{gt}, ..., l_{N}^{gt}]$, where $l_n^{gt} \\in \\mathbb{B}^{T_n}$. Anomalous time steps are assigned a 1 and nominal time steps a 0. Therefore, for a given nominal sequence $\\sum_{t=0}^{T_n} l_n^{gt} = 0$, for an entirely anomalous sequence $\\sum_{t=0}^{T_n} l_n^{gt} = T_n$ and for a partially anomalous sequence $0 < \\sum_{t=0}^{T_n} l_n^{gt} < T_n$.\nAs a counterpart to the ground-truth label set $\\mathbb{L}_{gt}$, there is the corresponding predicted label set $\\mathbb{L}_{p}$, such that $\\mathbb{L}_{p} = [l_{1}^{p}, ..., l_{n}^{p}, ..., l_{N}^{p}]$, where $l_n^{p} \\in \\mathbb{B}^{T_n}$."}, {"title": "4.2.1 Calibrated metrics", "content": "Similar to binary classification, anomaly detection generally segregates two classes using a threshold, except that one class is far rarer than the other, hence can be seen as imbalanced classification. This threshold is often applied to some sort of anomaly score. Generally, the anomaly score is some sort of error metric as a function of time, most of the time it is closely related to the loss function. Likewise, correct predictions can be labelled as true positives and true negatives and incorrect ones into false positives and false negatives, where negative refers to a nominal case and positive to an anomalous case. From here on, the number of true positives is represented by $N_{tp} \\in \\mathbb{W}$, the number of true negatives by $N_{tn} \\in \\mathbb{W}$, the number of false positives by $N_{fp} \\in \\mathbb{W}$ and the number of false negatives by $N_{fn} \\in \\mathbb{W}$, all of which are whole numbers. For now, label vector temporality is ignored and each time step is considered individually as a sample, therefore all anomalous time steps are treated as individual point anomalies, i.e. $S = 1$. Depending on the match between the predicted label vector $\\mathbb{I}^{p}_{n}$ and ground-truth label vector $\\mathbb{I}^{gt}_{n}$, the number of true positives, true negatives, false negatives and true positives can be obtained; see Equation 1.\n$N_{tp} = \\sum_{n=1}^{N} \\sum_{t=0}^{T_n} (\\mathbb{o}_n - \\mathbb{I}_{n}^{gt}) \\mathbb{I}_{n}^{p} \\qquad N_{tn} = \\sum_{n=1}^{N} \\sum_{t=0}^{T_n} (\\mathbb{o}_n - \\mathbb{I}_{n}^{gt}) (\\mathbb{o}_n - \\mathbb{I}_{n}^{p}) \\qquad N_{fn} = \\sum_{n=1}^{N} \\sum_{t=0}^{T_n} (\\mathbb{o}_n - \\mathbb{I}_{n}^{p}) \\mathbb{I}_{n}^{gt} \\qquad N_{fp} = \\sum_{n=1}^{N} \\sum_{t=0}^{T_n} (\\mathbb{o}_n - \\mathbb{I}_{n}^{gt}) \\mathbb{I}_{n}^{p}$\nwhere $\\mathbb{o}_n$ is a vector of ones the same size as $\\mathbb{I}_{n}^{gt}$ and $\\mathbb{I}_{n}^{p}$ such that $\\mathbb{o}_n \\in \\mathbb{B}^{T_n}$.\nPrecision $P$ is a metric that shows the number of true positives in relation to the total number of flags, i.e. how many of the flags are correct. Precision $P$ can be calculated using Equation 2. As is evident, a smaller number of false positives leads to a higher precision.\n$P = \\frac{N_{tp}}{N_{tp} + N_{fp}}$\nRecall $R$ is often presented in combination with precision, as it measures the number of false negatives in relation to the total anomaly count, i.e. how many of the anomalies are detected. Recall can be"}, {"title": "5 Predictive Models", "content": "Predictive models are models that are trained to predict a time step given a finite window $W \\in \\mathbb{R}^{w \\times d_D}$ of past values. Consider predictive model $M$, which in most publications is trained such that for time-series window $W$ it takes all but the last time step of $W$ and predicts the last time step of $W$, as shown in Equation 13.\n$W_w = M(W_{0:w-1})$\nSuch predictive models can be used for anomaly detection by comparing their predictions with the observed/measured value using a variety of techniques to obtain an error metric. The key assumption is that nominal, i.e. anomaly-free, sequences are predicted with a small error, whereas anomalies will lead to a large error between prediction and observed values. Predictive models tend to be the simplest and on average the oldest model family discussed in this survey. An overview of all the prediction-based modelling publications is presented in Table 5. The keys in the table are chosen such that the reader can quickly recognise what type of approach is taken by the respective author."}, {"title": "5.1 Online Training and Online Inference", "content": "[99] present an anomaly detection algorithm for computer logging records, that convolutes the input log key sequence using four parallel convolutional neural networks (CNN) [26, 49] layers with varying kernel sizes. The approach is trained on nominal data only, hence we speak of semi-supervised anomaly detection. The resulting feature maps, i.e. the vector representation of the CNN output, are then concatenated and fed into a long short-term memory (LSTM) [37, 28] layer which then predicts a probability distribution across all log keys. The most likely log keys are considered nominal, where the minimum likelihood at which a key is considered nominal is the threshold. In their work, they refer to the threshold as a hyperparameter, implying that it is obtained empirically with labels. [99] experiment with different online training techniques, including regularly retraining independently of anomaly detection results and retraining if the false-positive rate exceeds a given value."}, {"title": "5.2 Offline Training and Online Inference", "content": "[71] bring forward a method to detect anomalies during flight testing of commercial aircraft. It utilises the encoder component of a trained autoencoder to reduce the dimensionality of a multi-variate signal. Following that, a pair of LSTM layers predict the next time step based on the latent vector output by the transferred encoder. The error resulting from these predictions is fit to a Gaussian distribution, then allowing for a likelihood to be estimated, hence anomalies can be detected if the likelihood exceeds a given confidence interval. This confidence interval is an assumption made, hence this approach is considered unsupervised anomaly detection.\n[62] propose a stacked CNN network, which predicts the following time step based on a given history window. The anomaly score is based on the Euclidean norm (also known as the L2 norm) of the difference between the observed value and the prediction, and therefore needs to be evaluated against a threshold. [62] mention a parametric and a non-parametric way to obtain a threshold, though in the results, it is not specified which of the thresholds is used."}, {"title": "5.3 Offline Training and Offline Inference but Online Capable", "content": "The majority of existing work makes use of, sometimes stacked, recurrent neural networks (RNN) to predict future time steps, mostly trained on nominal data, except for [85, 76]. These predictions are then held up against the observed value, from which an anomaly score is calculated. The main difference is the error metrics used as the anomaly score.\n[57] and [15] use the prediction error resulting from a validation set to fit a Gaussian distribution using maximum likelihood estimation. During testing, they calculate the probability that the obtained error belongs to the fitted distribution and then compare it with a threshold found using labelled data."}, {"title": "6 Reconstructive Models", "content": "Reconstructive modelling is usually based on some variation of an autoencoder. Autoencoders consist of an encoder $M_{Enc}$ and decoder $M_{Dec}$, which generally mirror each other in architecture. The encoder compresses a given input time series window $W \\in \\mathbb{R}^{w \\times d_D}$ into a latent vector $z \\in \\mathbb{R}^{u \\times d_z}$, i.e. a reduced representation of the input space. Depending on the approach, this latent representation $z$ may or may not contain temporality, i.e. $u = 1$ or $u > 1$, respectively. The latent vector is then expanded again to reconstruct the input $W$ through the decoder, as shown in Equation 14.\n$z = M_{Enc}(W)$ $W = M_{Dec}(z)$\nReconstructive models rely on the assumption that the reconstruction error will be large when faced with anomalous data. An overview of the reconstruction-based modelling approaches discussed in this survey is presented in Table 6."}, {"title": "6.1 Online Training and Online Inference", "content": "Approaches based on autoencoders that are trained and infer in an online fashion do not exist, to the best of the author's knowledge. Technically such methods are possible, presumably they would work very similarly to the approach in Subsection 5.1. It is difficult to estimate how well this hypothetical algorithm would work, though it would be an open research direction to pursue."}, {"title": "6.2 Offline Training and Online Inference", "content": "The first approach that involved offline training of an autoencoder that is capable of online inference is proposed by [32], which is trained on nominal data only. It bears a lot of similarity to the work by [58] and adds a feature reduction layer between the input layer and the encoder, which acts as a regulariser in capturing dependencies between channels. The encoder and decoder are both based on LSTM layers, whose output, i.e. reconstruction, is then evaluated using the Mahalanobis distance as the anomaly score, which is held up against a threshold found through $F_1$ score maximisation to detect anomalies.\n[39] use an LSTM-based autoencoder trained on nominal data to detect anomalies in smart manufacturing via the mean squared error. They applied transfer learning to improve the algorithm performance significantly. This is done by pre-training the model on data from different points in the manufacturing process.\nInspired by the training process of GANs, [6] propose using two dense autoencoders $M_1$ and $M_2$ which share the same encoder. Training occurs in two phases, with the first one focusing on reconstruction error minimisation of the input window for both decoders. The second phase involves pitting the two autoencoders against one another. $M_1$ attempts to minimise the error between the input and $M_2$' reconstruction of $M_1$' reconstruction while $M_2$ attempts to maximise the reconstruction error $M_2$' reconstruction of $M_1$' reconstruction The reconstruction error used throughout this paper is the mean-squared error. This leads to $M_1$ being explicitly trained to create reconstructions that, when input into $M_2$, lead to outputs very similar to the input. $M_2$ on the other hand, is trained to be able to distinguish between $M_1$' reconstruction and the input window. The anomaly score for an input window during inference is then a weighted sum between $M_1$' reconstruction error and $M_2$'"}, {"title": "6.3 Offline Training and Offline Inference but Online Capable", "content": "[58] propose using an LSTM autoencoder which reconstructs input windows in reverse temporal order and use the Mahalanobis distance as the anomaly score. A threshold is obtained by maximising a modified version of the $F_1$ score, with weighted precision over recall, using a small amount of labelled data.\n[38] introduce an LSTM autoencoder-based approach which uses autocorrelation to systematically find a suitable window length. The time-series data is windowed according to the result of an autocorrelation analysis, which finds the length of the dynamics within the signal. For each feature in a time series, the autocorrelation at each lag is calculated. The autoencoder is capable of ingesting both unlabelled and labelled data to improve the detection of anomalies. This is done by adding an extra label column as one of the features to be reconstructed. The label value varies depending on whether the time step is faulty, suspicious, unknown, or valid. In addition to that, they utilise a decision tree model in an attempt to provide explainability to the anomalies, by isolating the channel that most likely causes the anomaly.\n[54] employ an LSTM autoencoder with discrete wavelet transforms at each end to better intake data of different frequencies. After training on nominal data, the encoder is removed and the decoder is used as an inverse model for the metamodel, a Nonlinear Autoregressive with External Input network. The difference between the metamodel input and the decoder output is then used to detect anomalies. Quantitative results, such as precision, recall or $F_1$ score are not provided.\n[66] use an LSTM autoencoder paired with a one-class support vector machine to detect anomalies. It works by separating nominal and anomalous data points in the absolute error vector resulting from the reconstruction using a hyperplane, hence a threshold is not required.\n[63] use two autoencoders, one to reconstruct the time series, and another one to reconstruct the reconstruction error from the previous autoencoder, which is then added to the reconstructed time series, in theory yielding a superior reconstruction. The anomaly score used is the L2 norm with segmented by a threshold set such that the $F_1$ score is maximised.\n[46] compare a 2D CNN autoencoder with an LSTM autoencoder for anomaly detection in enriched time series. These time series are augmented with derived and statistical features, hence enlarging their feature space compared to the raw time series. In addition to that, the autoencoder reconstruction is enhanced by embedding one-hot encoded contextual information in it.\n[47] then propose using an ensemble of sparse recurrent autoencoders. The autoencoders differ from each other as they use different sparseness weight vectors. Furthermore, two types of ensembles are proposed: an independent framework, where the autoencoders are run independently and a shared framework, where the latent vector is shared between autoencoders. Anomalies are then detected using the median value from the Euclidean distance vector of all autoencoders and a manually defined threshold.\n[102] attempt to detect anomalies by creating a convolutional autoencoder that works with correlation matrices, here called signature matrices, rather than raw time series. The autoencoder is further enhanced by skip connections that connect layers in the encoder with their decoder counterparts in order to allow the model to better deal with long sequences. The skip connections process the information flowing through them, by running it through a ConvLSTM layer paired with an unnamed custom attention layer. The algorithm can provide a root cause analysis by labelling the channels associated with the three worst reconstructed correlations in a given matrix."}, {"title": "7 Generative Models", "content": "Generative models can be further segmented into two most common model types: VAES [48] and GANs [31]. The former bears some similarity to traditional autoencoders, other than the fact that the low-dimensionality representation is not mapped to a vector $z$ but rather a distribution $(\\mu_z, \\sigma_z) \\in \\mathbb{R}^{u \\times d_z}$ from which a latent vector $\\tilde{z} \\in \\mathbb{R}^{u \\times d_z}$ is sampled; see Equation 15.\n$(\\mu_z, \\sigma_z) = M_{Enc}(W)$ $\\tilde{z}_{samp} \\sim (\\mu_z, \\sigma_z)$ $W = M_{Dec}(\\tilde{z}_{samp})$\nAgain, depending on the publication, the latent vector may or may not contain temporality. In some cases, the output of the decoder is not deterministic, but instead a distribution $(\\mu_W, \\sigma_W)$ that approximates the input $W$. In the generative modelling literature, the encoder of an autoencoder is also referred to as the recognition model and the decoder as the generative model. GANs, on the"}, {"title": "7.1 Online Training and Online Inference", "content": "[82] propose a VAE based on an echo state network in an effort to adapt it for anomaly detection in time-series data. This model is trained in an online manner, i.e. the parameters are updated as new data is input. The anomaly score is given by the negative log-likelihood of an observation variable given the previous echo state, which is compared against a threshold obtained by means of experimentation."}, {"title": "7.2 Offline Training and Online Inference", "content": "[70] suggest using LSTM layers rather than dense layers in a VAE trained on nominal data in order to detect anomalies in robot-assisted feeding. Rather than using a static prior, i.e. $N(0, 1)$, they propose using a dynamic one, i.e. $N(\\mu_p, 1)$, which, according to the authors, introduces temporality into the prior distribution. Furthermore, [70] use a support-vector regressor (SVR) which is trained on the validation subset containing nominal data to map latent distribution parameters $(\\mu_z, \\sigma_z)$ to the resulting anomaly score.\n[81] propose a similar approach to [70], though with a few of modifications. Firstly, the encoder and decoder are composed of gated recurrent unit (GRU) layers [17] rather than LSTM layers to minimise"}, {"title": "8 Transformer Models", "content": "Transformers, first introduced by [91], have been on the rise in the machine learning research landscape, thanks to significant advances enabled in natural language processing by the GPT-series of models [72, 73, 10, 67]. Transformer models have started to find their place in time-series anomaly detection, though by far to a lesser extent than the previously discussed model families. The original transformer shows some resemblance to encoder-decoder architectures, though with a variety of improvements. First, it does not use recurrent but rather feed-forward layers to process"}, {"title": "8.1 Online Training and Online Inference", "content": "Like with Subsection 6.1, no"}]}