{"title": "Online Model-based Anomaly Detection in\nMultivariate Time Series: Taxonomy, Survey,\nResearch Challenges and Future Directions", "authors": ["Lucas Correia", "Jan-Christoph Goos", "Philipp Klein", "Thomas B\u00e4ck", "Anna V. Kononova"], "abstract": "Time-series anomaly detection plays an important role in engineering processes,\nlike development, manufacturing and other operations involving dynamic systems.\nThese processes can greatly benefit from advances in the field, as state-of-the-art\napproaches may aid in cases involving, for example, highly dimensional data. To\nprovide the reader with understanding of the terminology, this survey introduces a\nnovel taxonomy where a distinction between online and offline, and training and in-\nference is made. Additionally, it presents the most popular data sets and evaluation\nmetrics used in the literature, as well as a detailed analysis. Furthermore, this sur-\nvey provides an extensive overview of the state-of-the-art model-based online semi-\nand unsupervised anomaly detection approaches for multivariate time-series data,\ncategorising them into different model families and other properties. The biggest\nresearch challenge revolves around benchmarking, as currently there is no reliable\nway to compare different approaches against one another. This problem is two-fold:\non the one hand, public data sets suffers from at least one fundamental flaw, while\non the other hand, there is a lack of intuitive and representative evaluation metrics\nin the field. Moreover, the way most publications choose a detection threshold\ndisregards real-world conditions, which hinders the application in the real world.\nTo allow for tangible advances in the field, these issues must be addressed in future\nwork.", "sections": [{"title": "1 Introduction", "content": "As a result of the fourth industrial revolution, also known as industry 4.0, immense amounts of\ndata are collected from sensors mounted at different checkpoints in many processes in research and\ndevelopment, manufacturing and testing [98]. This data can expose subtle but important trends and\ncorrelations, as well as give the data user key insights on how to optimise engineering systems and\nprocesses, which can potentially provide a company with a competitive advantage in the market.\nRecording high-quality data is important, as incomplete or anomalous data can negate any potential\nbenefits that can be extracted from it. With the rise of industry 4.0, anomaly detection has therefore\ngained relevance over the past decade, with the bar being set ever higher as data becomes more and"}, {"title": "2 Taxonomy in Time-series Anomaly Detection", "content": "To provide the reader with an illustration of the relationship between terms introduced in the taxonomy\nused an overview is represented graphically in Figure 2."}, {"title": "2.1 Anomaly Types and Detection", "content": "Anomalies in time series can be assumed to have different shapes and forms. A commonly used and\naccepted definition [35] reads as follows:\n\"An observation which deviates so much from other observations as to arouse suspicions that it was\ngenerated by a different mechanism.\"\nOver the years, several taxonomies have been proposed to better classify different anomalies. This\nwork mostly follows the taxonomy suggested by [9], where anomalies are classified into point outliers,\nsub-sequence outliers (also known as collective anomalies in the literature) and outlier time series.\nIn this work, these three types will be from now on referred to as point anomalies, sub-sequence\nanomalies and whole-sequence anomalies, respectively.\nA point anomaly is defined as a value at a time step that does not conform to the typical behaviour\nof a system. Consider a testing subset $D_{\\text{test}}$ in data set $D$ containing $N$ sequences, such that\n$D_{\\text{test}} = [S_1, ..., S_n, ..., S_N]$, where $S_n \\in \\mathbb{R}^{T_n \\times d_D}$. In a given multivariate sequence $S_n$, an anomaly\nevent $A \\in \\mathbb{R}^{S \\times d_A}$ of length $S$ that is detected in $d_A$ channels, where $d_A \\leq d_P$, is considered a point\nanomaly when $S = 1$. An example of a point anomaly is illustrated in Figure 3. While more easily\ndectable than the other types, these anomalies are rare events in the real world, as systems affected\ncannot usually return to a nominal state before the next time step arrives unless the sampling rate is\nvery low.\nSub-sequence anomalies are defined by a series of anomalous time steps, i.e. a sub-sequence within a\ntime series that does not reflect the nominal behaviour of a system. In a given multivariate sequence\n$S_n$, an anomaly event $A \\in \\mathbb{R}^{S \\times d_A}$ of length $S$ that is detected in $d_A$ channels, where $d_A \\leq d_P$, is\nconsidered a sub-sequence anomaly when $1 < S < T$. In a real-world system, this type of anomaly\nmay occur when a component in the said system runs at reduced functionality or fails but manages to\nrecover to a nominal state after a period of time. An example of a sub-sequence anomaly is illustrated\nin Figure 4.\nA whole-sequence anomaly can be seen as a long sub-sequence that has the same length as the entire\nsequence. Hence, in a given multivariate sequence $S_n$, an anomaly event $A \\in \\mathbb{R}^{S \\times d_A}$ of length $S$ that\nis detected in $d_A$ channels, where $d_A \\leq d_P$, is considered a whole-sequence anomaly when $S = T$.\nThis type of anomaly can occur when an initial parameter or state deviates from the norm, leading to\nall observations in the sequence being anomalous as well. An example of a whole-sequence anomaly\nis illustrated in Figure 5."}, {"title": "2.2 Continuous- and Discrete-sequence Anomaly Detection", "content": "Time-series anomaly detection can be split into two main areas: continuous- and discrete-sequence.\nContinuous-sequence anomaly detection is the most common type present in public data sets and is\ndefined as detecting anomalies in a process that exists for a longer continuous time period without\nbreaks, i.e. $N = 1$ in a testing subset $D_{\\text{test}}$. This includes monitoring applications like in water\ndistribution, server machines or even heartbeat rhythms. Use cases of continuous-sequence anomaly\ndetection tend to consist of a singular longer time series which contains nominal and anomalous\nsub-sequences within it, therefore they can only contain point and sub-sequence anomalies.\nDiscrete-sequence anomaly detection, in contrast, is defined as detecting anomalies in chunks of\nprocesses that happen independently of each other, i.e. $N < 1$ in testing subset $D_{\\text{test}}$. One example"}, {"title": "2.3 Online Training and Inference", "content": "Using model-based approaches generally involves two processes: training and inference. Training\nis the process of automatically adjusting model parameters by means of optimisation using training\ndata, whereas inference refers to the application, where model parameters are no longer adjusted.\nOnline approaches are defined as models that infer in an online manner and, optionally, are trained in\nan online manner. Online training, therefore, refers to the process of adjusting model parameters as\ntraining data is streamed. Unlike offline training, which is done once in most cases, online training\nruns continuously and for an undefined amount of time. Online inference refers to the ability of\nan approach to detect anomalous behaviour in time steps as soon as they are observed, rather than\nwaiting for the time series to have finished streaming and only then evaluating the entire sequence,\ni.e. offline. This is especially useful in real-world use cases where timely detection is important. A\nmore strict version of online anomaly detection is real-time anomaly detection, where the current\ntime step is evaluated before the next one arrives."}, {"title": "3 Related Work", "content": "Various anomaly detection surveys with a focus on time series and online functionality have been\npublished over the years. A summary of the surveys is given in Table 1. The table shows whether\nthe surveys discuss anomaly detection taxonomy, available data sets and metrics, and what type of\napproaches are identified. The list of publications, surveys, and reviews has been found using the\nkeywords anomaly detection, outlier detection, unsupervised, semi-supervised, multivariate, time\nseries, online, real-time and streaming data using a variety of libraries, such as Institute of Electrical\nand Electronic Engineers (IEEE) Xplore, Elsevier ScienceDirect, Springer Link and the Association\nfor Computing Machinery (ACM) Digital Library, in the time between 2000 and 2024. Up until\nrecently, surveys published on online time-series anomaly detection only discussed conventional\nmethods, which for the purpose of this survey will denote methods not based on data-driven modelling.\nNote that the terminology \"time series\" and \"sequence\" are used synonymously throughout this survey.\nTo help the reader to more easily distinguish between the terms introduced in the taxonomy in this\nwork and other terms used in related work, the terminology stemming from this work's taxonomy is\nemphasised and hyperlinked to the relevant subsection in Section 2.\nAccording to [14], there are two relevant problem formulations in time-series anomaly detection:\nsequence-based and contiguous sub-sequence-based anomaly detection. They are somewhat anal-\nogous to discrete-sequence and continuous-sequence anomaly detection, though associated with\nfairly rigid definitions. In their work, [14] frame sequence-based and contiguous sub-sequence-based\nanomaly detection such that it can only feature whole-sequence anomalies and sub-sequence anoma-\nlies, respectively, which may not be the case in the real world. Furthermore, they dedicate a section\ndiscussing online anomaly detection in the context of discrete-sequence and continuous-sequence\nproblem framing.\n[34] categorise time-series anomaly detection problems into five different fields, with the two relevant\nbeing so-called time-series data and stream data, essentially designating offline and online anomaly\ndetection. Time-series data is further split into two subcategories: single time series, where exactly\none time series is evaluated and time-series databases, where several time series are evaluated. In a\nsingle time series, point and sub-sequence anomalies can be detected, while in the case of time-series\ndatabases, sub-sequence and whole-sequence anomalies can be found, though it is not mentioned why\na point anomaly cannot be detected in a time series database. Additionally, a special case exists where\nthe database can be compared to a single test sequence. Single time series and time-series databases\nare analogous to discrete-sequence and continuous-sequence anomaly detection, though here they"}, {"title": "4 Benchmarking", "content": "Benchmarking is an important part of anomaly detection research, as it enables objectively measuring\nprogress in the field. To benchmark any given approach against others, it has to be applied to the\nsame data set and use the same evaluation metrics. This section gives a detailed overview of the most\ncommonly used public data sets and their respective weaknesses, as well as of the metrics used to\nevaluate anomaly detection approaches and proposed improvements in the literature."}, {"title": "4.1 Data Sets", "content": "Anomaly detection literature uses a variety of time-series data sets over the years. Publicly available\ndata sets play an important role in enabling researchers to benchmark their methods against the\nstate of the art. To inform the reader about the publicly available data sets, the key information is\nsummarised in Table 2.\nUnfortunately, most popular data sets are unsuitable for time-series anomaly detection, as concluded\nby [94]. They make a case against many publicly available data sets by pointing out four main flaws,\nat least one of which can be found in most data sets. These flaws include:\n\u2022 triviality\n\u2022 unrealistic anomaly density\n\u2022 uncertain labels\n\u2022 run-to-failure bias\nThey define triviality as being able to be solved with a very limited amount of code, hence weakening\nthe case for the need for complex parameter-heavy models. Then they point out the unrealistic\nanomaly density, where the assumption that anomalies are very rare events does not hold. The\nnext issue [94] discuss is the apparent mislabelled ground truth. In some cases, regions of similar\nbehaviour are sometimes labelled anomalous, sometimes labelled as nominal, which can skew results.\nLastly, they argue that some data sets have a run-to-failure bias, i.e. anomalies appear at the end of\nsequences and hence the anomaly detection performance can be improved by \"guessing\" that the last\ntime steps are anomalous. Perhaps the word failure is inaccurate in this context, as an anomaly is\nnot necessarily a failure but simply a deviation from nominal behaviour. An alternative and more\ngeneral term could be nominal-to-anomaly bias. It could be argued that it is nominal-to-anomaly bias\nis intrinsic in anomaly detection as it is more likely for a system to behave nominally and then fail\nthan the other way around, although this depends on the application. The aforementioned issues are\nonly pointed out for a subset of the public data sets considered by [94], however, their criticism can\nbe extended to all other public data sets, which is discussed in the following.\nThe High Rack Storage System (HRSS) data set [4] represents the behaviour of an unoptimised\n(standard) and optimised factory at the Ostwestfalen-Lippe University of Applied Sciences. One\nissue present is that at a few points, nominal time steps are sandwiched between anomalous time\nsteps, raising suspicion of possible mislabelling. It features an unrealistic anomaly density, as around\n24% of the test time steps are labelled as anomalous, as shown in Figure 6. Lastly, two nominal and\ntwo anomalous sequences are provided, but no specification of training and testing subsets, therefore\npublications using this data set may not be comparable.\nThe Kaspersky Lab provides a data set from the process industry. Using an industrial process\nmodel, they propose the Tennessee-Eastman Process data set (TEP) [23], for which a labelled\nnominal training subset is provided. As specified by [24], the DANGER warnings are considered the\nanomalies. The TEP data set has a few anomalous sequences that suffer from unrealistic anomaly\ndensity, where a single nominal time step is sandwiched between two anomalous sub-sequences. In\naddition to that, the type 21 anomalies can easily be detected by looking at the feature 8.\nThe Singapore University of Technology and Design published two data sets: the Secure Water\nTreatment (SWaT) [29] and the Water Distribution (WADI) [3] data sets. Both consist of test bed\ndata under nominal conditions and under various attack scenarios, however, WADI is composed of\nhigher dimensional data, though no training/testing subset splits are provided. SWaT and WADI\nare not explicitly named by [94], but still suffer from the same flaws. For example, the SWaT data\nset suffers from a variety of issues. First and foremost, it contains half a dozen features that are\nconstant throughout the train and test sets, making them redundant for modelling and hence are\nnot considered in Table 2. In addition to that, it features a very high anomaly density, in fact, the\nanomaly between time steps 227828 and 262727 accounts for around 65% of the total anomalous\ntime steps. This anomaly is considered trivial as it can easily be detected by just looking at a single\nfeature, as shown in Figure 7. Of the 127 features in WADI many need to be filtered out. Like SWaT,\nWADI suffers from redundant features, 33 in total, as well as features with missing values, 4 in total,\nand features with NaN values, another 4 in total, bringing the total feature count to 86. Of the four\napproaches found in the literature that use this data set, all use a different feature count, making this\nincomparable.\nNASA published two commonly used data sets: the Soil Moisture Active Passive (SMAP) satellite\ndata set and the Mars Science Laboratory (MSL) rover data set [43, 42]. Both are split into training\nand testing subsets, though the training subset consists of only nominal samples. In the supporting\nmaterial of [94], they indicate that both data sets suffer from triviality and unrealistic anomaly density.\nApart from the afore-mentioned criticism, it should be noted that, while technically multivariate in\nthe sense that the sequences in either data set do have multiple channels, all channels other than the\nfirst one (the telemetry channel) are binary one-hot encoded command channels with no dynamic\nbehaviour. [44] only predict the one telemetry channel in their work, which may be acceptable for\npredictive models but not applicable to other model families, like reconstructive models.\nThe University of Michigan published the CNC Mill Tool Wear data set [83], which consists of\n18 multivariate time series. The main issue with this data set is that labels only exist for an entire\nsequence (worn/unworn) and from the 18 sequences only 8 are nominal (unworn). Given that some\nof the eight sequences may need to be used as training data, the data set is unbalanced, but towards\nthe anomaly class. Because the anomaly class is more common in the test set, the precision metric\nwill be inflated, as false positives will naturally be small. Lastly, the CNC data set features a very\nhigh anomaly density of 53%, hence, it is not recommended for anomaly detection.\nAnother multivariate time-series data set is the Server Machine Data set (SMD) [80] which features 38\nchannels and unlabelled training subsets for each machine. Like SMAP and MSL, SMD also suffers"}, {"title": "4.2 Metrics", "content": "Evaluation metrics allow different anomaly detection performance aspects to be quantified and\ncompared. These metrics can generally be separated into two different classes: calibrated and\nuncalibrated. In order to provide a consistent notation throughout the following subsections, the\nfollowing notation system is introduced. Reconsider a testing subset $D_{\\text{test}}$ in data set $D$ containing\n$N$ sequences that can be nominal (without anomalies), entirely anomalous or partially anomalous,\nsuch that $D_{\\text{test}} = [S_1, ..., S_n, ..., S_N]$, where $S_n \\in \\mathbb{R}^{T_n \\times d_D}$. Here, $T_n$ is the number of time steps in\nsequence $S_n$, which varies depending on $S_n$ and $d_D$ the number of features, i.e. the dimensionality\nof $S_n$. The ground-truth label set $\\mathcal{L}^{\\text{gt}}$ corresponding to $\\Gamma$ contains a binary label vector for each\nsequence, such that $\\mathcal{L}^{\\text{gt}} = [\\ell_1^{\\text{gt}}, ..., \\ell_n^{\\text{gt}}, ..., \\ell_N^{\\text{gt}}]$, where $\\ell_n^{\\text{gt}} \\in \\mathbb{B}^{T_n}$. Anomalous time steps are assigned a\n1 and nominal time steps a 0. Therefore, for a given nominal sequence $\\sum_{t=0}^{T_n} \\ell_{n,t}^{\\text{gt}} = 0$, for an entirely\nanomalous sequence $\\sum_{t=0}^{T_n} \\ell_{n,t}^{\\text{gt}} = T_n$ and for a partially anomalous sequence $0 < \\sum_{t=0}^{T_n} \\ell_{n,t}^{\\text{gt}} < T_n$.\nAs a counterpart to the ground-truth label set $\\mathcal{L}^{\\text{gt}}$, there is the corresponding predicted label set $\\mathcal{L}^P$,\nsuch that $\\mathcal{L}^P = [\\ell_1^p, ..., \\ell_n^p, ..., \\ell_N^p]$, where $\\ell_n^p \\in \\mathbb{B}^{T_n}.\n$\n4.2.1 Calibrated metrics\nSimilar to binary classification, anomaly detection generally segregates two classes using a threshold,\nexcept that one class is far rarer than the other, hence can be seen as imbalanced classification. This\nthreshold is often applied to some sort of anomaly score. Generally, the anomaly score is some sort of\nerror metric as a function of time, most of the time it is closely related to the loss function. Likewise,\ncorrect predictions can be labelled as true positives and true negatives and incorrect ones into false\npositives and false negatives, where negative refers to a nominal case and positive to an anomalous\ncase. From here on, the number of true positives is represented by $N_{\\text{tp}} \\in \\mathbb{W}$, the number of true\nnegatives by $N_{\\text{tn}} \\in \\mathbb{W}$, the number of false positives by $N_{\\text{fp}} \\in \\mathbb{W}$ and the number of false negatives\nby $N_{\\text{fn}} \\in \\mathbb{W}$, all of which are whole numbers. For now, label vector temporality is ignored and each\ntime step is considered individually as a sample, therefore all anomalous time steps are treated as\nindividual point anomalies, i.e. $S = 1$. Depending on the match between the predicted label vector\n$\\ell_n^p$ and ground-truth label vector $\\ell_n^{\\text{gt}}$, the number of true positives, true negatives, false negatives and\ntrue positives can be obtained; see Equation 1.\n$N_{t p}=\\sum_{n=1}^{N} \\sum_{t=0}^{T_{n}}(\\ell_{n, t}^{p} \\cdot \\ell_{n, t}^{g t})$\n$N_{t n}=\\sum_{n=1}^{N} \\sum_{t=0}^{T_{n}}(o_{n}-\\ell_{n, t}^{p}) \\cdot(o_{n}-\\ell_{n, t}^{g t})$\n$N_{f p}=\\sum_{n=1}^{N} \\sum_{t=0}^{T_{n}}(\\ell_{n, t}^{p} \\cdot(o_{n}-\\ell_{n, t}^{g t})) \\qquad N_{f n}=\\sum_{n=1}^{N} \\sum_{t=0}^{T_{n}}((o_{n}-\\ell_{n, t}^{p}) \\cdot \\ell_{n, t}^{g t})$\n(1)\nwhere $o_n$ is a vector of ones the same size as $\\ell_n^{\\text{gt}}$ and $\\ell_n^{p}$ such that $o_n \\in \\mathbb{B}^{T_n}$.\nPrecision $P$ is a metric that shows the number of true positives in relation to the total number of flags,\ni.e. how many of the flags are correct. Precision $P$ can be calculated using Equation 2. As is evident,\na smaller number of false positives leads to a higher precision.\n$P=\\frac{N_{t p}}{N_{t p}+N_{f p}}$\n(2)\nRecall $R$ is often presented in combination with precision, as it measures the number of false negatives\nin relation to the total anomaly count, i.e. how many of the anomalies are detected. Recall can be"}, {"title": "calculated using Equation 3. As is evident, a smaller number of false negatives leads to a higher\nrecall.", "content": "$R=\\frac{N_{t p}}{N_{t p}+N_{f n}}$\n(3)\nPrecision and recall can be summarised into a single metric, the FB score. It takes the weighted\nharmonic mean of the two metrics; see Equation 4.\n$F_{\\beta}=\\frac{\\left(1+\\beta^{2}\\right) \\cdot N_{t p}}{\\left(1+\\beta^{2}\\right) \\cdot N_{t p}+\\beta^{2} \\cdot N_{f n}+N_{f p}}=\\frac{\\left(1+\\beta^{2}\\right) \\cdot P \\cdot R}{\\left(\\beta^{2} \\cdot P\\right)+R}$\n(4)\nTypically, precision and recall are equally weighted, hence $\\beta = 1$ and we speak of the F1 score; see\nEquation 5.\n$F_{1}=\\frac{N_{t p}}{N_{t p}+\\frac{1}{2}\\left(N_{f n}+N_{f p}\\right)}=2 \\cdot \\frac{P R}{P+R}$\n(5)\nThe metrics in Equations 1-5 are referred to as calibrated metrics since they represent anomaly\ndetection performance at a specific threshold/sensitivity.\nOne metric that is often used in binary classification is the accuracy $\\Phi$, which represents the total\nnumber of correct classifications in relation to all samples, as shown in Equation 6.\n$\\Phi=\\frac{N_{t p}+N_{t n}}{N_{t p}+N_{f n}+N_{f p}+N_{t n}}$\n(6)\nHowever, accuracy is unsuitable for anomaly detection, given the imbalanced nature of the problem.\nFor example, in a case with 90 nominal and 10 anomalous samples and an anomaly detector that\nclassifies all nominal samples correctly, but none of the anomalous ones would have an accuracy\nfigure of 90%, despite it detecting 0 anomalies.\nOne alternative to regular accuracy is balanced accuracy $\\Phi_B$, which calculates the accuracy in both\nclasses separately and then takes the average, as in Equation 7. While more suitable for anomaly\ndetection, this performance metric has seen no mention in any of the literature surveyed in this work.\n$\\Phi_B=\\frac{1}{2}\\left(\\frac{N_{t p}}{N_{t p}+N_{f n}}+\\frac{N_{t n}}{N_{t n}+N_{f p}}\\right)$\n(7)\nAs previously mentioned, these metrics are generally used in imbalanced classification and are\nsample-based, i.e. each time step is considered individually.\nThe first proposal for metrics apt to evaluate sub-sequence anomalies is given by [96]. They apply the\nmetrics such that a ground-truth anomalous sub-sequence is considered a true positive if it overlaps\nwith any predicted anomalous time step. False positives and false negatives are obtained as previously.\nThis method is generally referred to as point-adjustment. Despite its prominence in the literature,\npoint-adjusted metrics come with a number of problems. Firstly, in a case where only the last\nanomalous time step is flagged, a significant delay in the detection is present which can be undesired.\nFurthermore, it makes anomaly detection trivial. In the case of a single long sub-sequence anomaly\nwithin a time series or a whole-sequence anomaly, a single time step within would lead to a true\npositive, despite all other time steps not being classified correctly. To underline the effect this has\non metrics, consider Figure 10. Without point-adjust, the figure shows $N_{\\text{tp}} = 4, N_{\\text{fp}} = 4, N_{\\text{tn}} = 2$\nand $N_{\\text{fn}} = 6$, and hence a precision of 0.50, a recall of 0.4 and therefore an F1 score of 0.44. With\npoint-adjustment, however, the figure shows $N_{\\text{tp}} = 8, N_{\\text{fp}} = 4, N_{\\text{tn}} = 2$ and $N_{\\text{fn}} = 2$, and hence\na precision of 0.66 and a recall of 0.80 and therefore an F1 score of 0.72. Clearly, point-adjusted\nmetrics are not well suited for sub-sequence anomaly detection, as they are too forgiving and ignore\ndelays in detection. In fact, [20] show that sampling a uniform distribution parameterised with an\nalarm probability can outperform most state-of-the-art models when point-adjusted metrics are used."}, {"title": "[86] propose so-called range-based recall $R_\\iota$ and precision $P_\\iota$. For the range-based recall $R_\\iota$\ncalculation, four aspects are relevant to anomalous sub-sequences within a time series. The first is\nexistence, which is analogous to the point-adjust way of marking a true positive. The corresponding\nexistence score $\\epsilon$ for each ground-truth anomaly is 1 if any predicted positive time steps overlap\nwith it and 0 otherwise. In the context of Figure 10 the existence score is 1 for the first, third and\nfourth ground-truth anomaly and 0 for the second one. Then, there is the position, i.e. what part\nof the predicted anomaly overlaps with the true anomaly. For this aspect, this method requires an\napplication-related bias $\\delta$. There may be use cases where correctly flagging certain sections within\nthe true anomaly and therefore the front, back, middle, or all time steps should be emphasised, though\nit is unclear why the back end of an anomaly should be rewarded. The next aspect is size, i.e. how\nclose the size of the predicted anomaly is to the true anomaly, denoted by the overlap size $\\omega$. In\nFigure 10 the overlap size is low for the first ground-truth anomalous sub-sequence and 1 for the third\nand fourth one. For the second ground-truth anomaly, the overlap size is undefined, as there is no\npredicted time step that overlaps with it. The overlap size is also a function of the aforementioned\napplication-related bias $\\delta$. Lastly, there is cardinality. One example of a cardinality score $\\gamma$ would be\none that indicates how many predicted positive sub-sequences overlap with each ground-truth positive\nsub-sequence. This is especially useful to punish approaches that flag several positive sub-sequences\nthat fit inside a single ground-truth positive sub-sequence rather than a single continuous one. In\nFigure 10 the cardinality score for the first and fourth ground-truth anomalous sub-sequence would\nbe higher than for the third one. Again, for the second one, this would be undefined due to the lack of\ncorresponding predicted positive time steps. The cardinality factor is used to scale the overlap size\nfigure, yielding the overlap score which is combined with the existence score using a pre-defined\nweight $\\alpha$ to yield the range-based recall for each ground-truth anomaly $i$, as shown as high-level in\nEquation 8.", "content": "$R_{\\iota, i}=\\alpha \\cdot \\epsilon+(1-\\alpha) \\cdot \\gamma \\cdot \\omega$\n(8)\nFor the range-based precision $P_\\iota$ the existence score does not apply and hence only the overlap,\nposition, and cardinality scores are considered for each predicted anomaly. The aforementioned\nscores are then applied inversely to the above, i.e. for each predicted anomaly $j$, rather than for each\nground-truth anomaly $i$. Finally, the individual range-based recalls and precisions are averaged for\nall ground-truth anomalies and all predicted anomalies to obtain the final range-based recall $R_\\iota$ and\nprecision $P_\\iota$, respectively. While this way of evaluating anomaly detection performance is fairly\nrobust, it assumes that in a test time series, there is always a predicted anomaly, which may not\nalways be the case. In a case where this does not happen, the method runs into a numerical error.\nFurthermore, it requires the setting of bias $\\gamma$, as well a, which sets the balance between existence and\nsize, position, and cardinality.\n[45] propose an extension to the point-adjust metrics, called the time-aware precision $P_{\\text{ta}}$ and time-\naware recall $R_{\\text{ta}}$. For their metrics, [45] assume that each positive ground-truth has an ambiguous tail\nof length $\\delta$, where the time steps in $T < t < T + \\delta$ are considered anomalous too. Both time-aware\nprecision $P_{\\text{ta}}$ and time-aware recall $R_{\\text{ta}}$ consist of two components, the detection score and the\nportion score. The detection score components of the time-aware precision and recall are $P_d$ and\n$R_{\\text{da}}$, respectively. The way true positives are counted is similar to the point-adjust score, except that\nit requires the predicted anomaly to overlap with the ground truth by a set threshold $\\theta$. The portion\nscore components $P_P$ and $R_{\\text{da}}$ are defined as the average overlap between ground truth and predicted\nanomalies. The final time-aware precision $P_{\\text{ta}}$ and recall $R_{\\text{ta}}$ is obtained using the weighted sum of\nthe detection and portion scores, respectively, parameterised by weight a. Like range-based recall $R_\\iota$\nand precision $P_\\iota$, time-aware precision $P_{\\text{ta}}$ and recall $R_{\\text{ta}}$, require a manually defined parameter a.\nTo specifically address the delay in detection, [20] propose a metric called the average detection\ndelay $\\mathcal{D}$, which is the mean delay for an approach to label a ground-truth anomaly as such over all\nground-truth anomalies. For example, the detection delay $\\mathcal{D}$ for the first ground-truth anomaly in\nFigure 10 would be two samples and zero for the third and fourth ground-truth anomalies. To cap\nthe delay time of detections, a maximum tolerable delay $\\tau_{\\text{max}}$ is used if the detection takes longer\nthan $\\tau_{\\text{max}}$, therefore the worst $\\mathcal{D}$ score possible is $\\mathcal{D} = \\tau_{\\text{max}}$. The average detection delay $\\mathcal{D}$ can be\nnormalised using $\\tau_{\\text{max}}$, in which case the worst value is $\\mathcal{D} = \\mathcal{D}/\\tau_{\\text{max}} = 1$. It is undesirable to flag\ntime steps too early, hence [20] propose the sequence alarm precision $PSA$, where a false positive is\nrecorded for early flags. It is calculated the same way regular precision is, except that a false positive\nis defined as an early flag, therefore $PSA$ is the number of early flags relative to all flags. Like the\ntwo proposed metrics discussed previously, the manual setting of $\\tau_{\\text{max}}$ is required. Furthermore, it\nis unclear what the delay should be if there is no predicted anomaly in a given test sequence. Also,"}, {"title": "[20", "41": "propose the following.\nFirst, a local affiliation between the ground-truth label vector $\\ell_{\\text{gt}}$ and the predicted label vector $\\ell_{p}$ is\nestablished. This is done by splitting test sequences into chunks, each with exactly one ground-truth\nanomaly. For the precision in each chunk, they calculate the average temporal distance $\\bar{d}_P$ between\nany false positive time steps and the closest ground-truth positive time step. When this average\ntemporal distance is zero, it means that no time steps within the chunk are false positives. In the case\nof the recall, this is flipped, so that the average temporal distances $\\bar{d}_R"}]}