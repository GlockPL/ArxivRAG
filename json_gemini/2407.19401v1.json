{"title": "COMPLETE SECURITY AND PRIVACY FOR AI\nINFERENCE IN DECENTRALIZED SYSTEMS", "authors": ["Hongyang Zhang", "Yue Zhao", "Claudio Angione", "Harry Yang", "James Buban", "Ahmad Farhan", "Fielding Johnston", "Patrick Colangelo"], "abstract": "The need for data security and model integrity has been accentuated by the rapid\nadoption of AI and ML in data-driven domains including healthcare, finance, and\nsecurity. Large models are crucial for tasks like diagnosing diseases and forecast-\ning finances but tend to be delicate and not very scalable. Decentralized systems\nsolve this issue by distributing the workload and reducing central points of failure.\nYet, data and processes spread across different nodes can be at risk of unauthorized\naccess, especially when they involve sensitive information. Nesa solves these\nchallenges with a comprehensive framework using multiple techniques to protect\ndata and model outputs. This includes zero-knowledge proofs for secure model\nverification. The framework also introduces consensus-based verification checks\nfor consistent outputs across nodes and confirms model integrity. Split Learning\ndivides models into segments processed by different nodes for data privacy by pre-\nventing full data access at any single point. For hardware-based security, trusted\nexecution environments are used to protect data and computations within secure\nzones. Nesa's state-of-the-art proofs and principles demonstrate the framework's\neffectiveness, making it a promising approach for securely democratizing artificial\nintelligence.", "sections": [{"title": "1 INTRODUCTION", "content": "Artificial Intelligence (AI), particularly machine learning (ML), has made significant strides in re-\ncent decades. Since the advent of large language models (LLMs) such as ChatGPT [1], Claude\n[2], Gemini [3], LLaMA [4] and diffusion models [5] such as DALLE-3 [6] and Sora [7], founda-\ntion models have garnered considerable attention. While these foundation models exhibit intriguing\nproperties such as in-context learning and chain-of-thought reasoning, concerns about their secu-\nrity and privacy have emerged, especially in distributed or decentralized computing scenarios. For\ninstance, in ML as a service (MLaaS), ensuring the integrity of inference results is paramount. Ser-\nvice providers must demonstrate to customers that the output stems from inputting the customer's\nprompt into a verified large language model, like GPT-4, and generating the response through model\nexecution, rather than relying on human writers or less advanced models, such as GPT-3.5. This\nrequirement is referred to as model security or model integrity. Meanwhile [8], service providers\nare reluctant to release their model weights, preferring to keep them confidential. In distributed or\ndecentralized inference applications, a central server divides a foundation model into distinct seg-\nments, each managed by a different party. When an inference query arises, each party executes its\nsegment independently. It is key to ascertain the trustworthiness of each party's execution before\naggregating the outputs.\nMeanwhile, data privacy issues also arise in decentralized inference [9], where users need to ensure\nthat their input data are not directly visible to the decentralized nodes that carry the AI inference for\nthem. This can be extremely important in \u201ccritical inference\u201d settings where sensitive information,\nsuch as medical records, financial data, or security information, is processed. In healthcare, where\nAI models analyze medical images like MRI or CT scans to diagnose diseases. Patient data is highly"}, {"title": null, "content": "sensitive and must be protected. Ensuring data privacy in such scenarios is crucial to protect user\ndata from unauthorized access and potential misuse.\nAt Nesa, we aim to address security and privacy concerns for Al's responsible and effective deploy-\nment across various domains. In a nutshell, we design hybrid approaches to security and privacy\n[10] for the above challenges. The selection of different security and privacy methods depends on\nthe specific use cases and the need for varying levels of security and privacy. Based on the different\nlevels of needs, users can flexibly choose the best option for security and privacy. Here, we dis-\ncuss two key scenarios at Nesa and our security and privacy approaches to them. Also, we discuss\nhow we adapt a hardware-based trusted execution environment (TEE) as an orthogonal approach for\nsecurity and privacy.\nScenario 1: Critical inference refers to scenarios where the results of AI inference are extremely\nsignificant, necessitating the highest levels of security and privacy, even if it means slower speed and\nhigher cost. In these situations, the accuracy and confidentiality of the inference outcomes are im-\nportant, and users are willing to endure longer processing times to ensure their data is fully protected.\nExamples include healthcare diagnostics, where AI analyzes medical images to detect diseases, and\nfinancial decision-making, where AI evaluates large transactions or investment strategies. In both\ncases, the sensitive nature of the data demands robust privacy measures, with stakeholders prior-\nitizing data security over rapid results to prevent unauthorized access and ensure the integrity of\nthe process. Under this scenario, Nesa adapts and innovates two leading technologies, including\nzero-knowledge machine learning (ZKML) [11] for model integrity verification and homomorphic\nencryption (HE) for data encryption and user privacy protection. Admittedly, the original design of\nZKML and HE is computationally heavy, especially for non-linear layers in neural networks such\nas ReLU layers [12]. To balance effectiveness and efficiency, we apply the state-of-the-art ZKML\ntechniques introduced by [11, 13] to build zero-knowledge Decentralized Proof System (zkDPS) for\nproof generation and verification processes in foundation models, and we apply HE selectively to\ncritical layers rather than the entire model. Specifically, we propose Sequential Vector Encryption\n(SVE) based on sequential homomorphic encryption (SHE). This robust encryption scheme obfus-\ncates the output of each operator in a neural network to prevent attackers from extracting sensitive\ninformation from intermediate representations. \u00a72 provides more details on our customized zkDPS\nand SHE solutions for critical inference with the highest protection.\nScenario 2: General inference refers to everyday AI inference tasks with less critical results, allow-\ning for faster processing speeds and lower costs without compromising basic security and privacy\nstandards. In these scenarios, a certain level of protection is still necessary, but the stringent mea-\nsures required for critical inference are not needed. Examples include routine tasks such as checking\nthe weather, recommending products, or filtering spam emails. Here, the emphasis is on efficiency\nand speed while maintaining adequate data security to protect user information. Under this sce-\nnario, Nesa employs our consensus-based verification (CBV) for security, ensuring the integrity of\nthe inference process, and split learning (SL) [14] for data encryption, which provides a reasonable\nlevel of data protection. Notably, we have innovated this verification method to reduce the high\nredundancy requirements in model verification, and split learning has been used in decentralized AI\nencryption for the first time. \u00a73 elaborates on our consensus-based verification and split learning\nsolutions for general inference, balancing speed and security effectively.\nNTEE: Nesa's Trusted Execution Environment (TEE). In addition to our innovations around\nsoftware- and/or algorithm-based security and privacy approaches for the two scenarios, we also\ndesign an orthogonal hardware-based approach for both. In a nutshell, TEEs create secure isolation\nzones within the network's nodes, protecting user data and private model parameters from unautho-\nrized access [15]. TEEs provide a secure enclave for executing computations, isolated from the rest\nof the node's operating environment, ensuring that even if other parts of the node are compromised,\nthe computations within the TEE remain protected. This isolation is critical in decentralized set-\ntings where AI models are spread among multiple owners. This hardware-based security measure\nworks as an alternative to algorithm-based approaches, providing a fast and efficient solution for\nNesa's decentralized AI inference tasks. Additionally, we innovate NTEE (Nesa TEEs) optimizing\ncommunication among multiple TEEs by establishing direct, secure channels, and implementing\nheterogeneous TEE scheduling based on the capabilities of each node, whether CPU or GPU-based.\nNTEE facilitates secure collaboration across multiple nodes, enabling Nesa to maintain high per-\nformance, robust security, and data privacy, making it ideal for both critical and general inference\nscenarios. See details of our TEE implementation and innovation in \u00a74."}, {"title": "2 SECURITY AND PRIVACY FOR CRITICAL INFERENCE", "content": "In critical inference scenarios, the significance of AI inference results necessitates the highest levels\nof security and privacy, as the outcomes directly impact crucial sectors like healthcare and finance.\nOur strategy for ensuring model verification and integrity is via our Zero-Knowledge Decentralized\nProof System (zkDPS), a specialized ZK system for decentralized LLMs that allows one party to\nprove to another that a statement is true without revealing any information beyond the validity of"}, {"title": null, "content": "the statement itself. Notably, it introduces a few new techniques to speed up the ZK process. This\napproach is detailed in \u00a72.1. For data privacy, we redesign Sequential Homomorphic Encryption\n(SHE) and propose our Sequential Vector Encryption (SVE), which enables computations on en-\ncrypted data without decrypting it, thus ensuring that sensitive data remains protected throughout\nthe inference process. In comparison to classical HE, our approaches can be more efficient in ap-\nplying implied tensor transformations to selected layers of an AI model. More information on this\ntechnique can be found in Section 2.2. Fig. 1 summarizes the security flow of critical inference at\nNesa, where the data will be transmitted with SVE for encryption, and the final inference results will\nbe verified by zkDPS for integrity."}, {"title": "2.1 ZERO-KNOWLEDGE MACHINE LEARNING FOR MODEL INTEGRITY", "content": ""}, {"title": "2.1.1 BACKGROUND", "content": "Despite the significant strides made in AI security in recent years, the potency of attacks has surged.\nCentral to AI security is the pivotal task of delineating the threat model and understanding how\nadversaries target the inference process. Adversaries can exploit various vulnerabilities within the\ninference systems of foundational models, employing tactics tailored to different scenarios. In de-\ncentralized AI inference environments, one threat model emerges, where computing nodes may\nbehave deceitfully, compromising the integrity of aggregated results. It becomes imperative to es-\ntablish mechanisms wherein each node can verify its adherence to agreed-upon protocols without\ncompromising the confidentiality of its model. This necessitates enabling nodes to provide proofs\nof honest execution to the central server or the public while safeguarding the confidentiality of their\nrespective models. Thus, ensuring both the integrity of inference processes and the privacy of model\narchitectures becomes paramount in the realm of AI security.\nIn the realm of defending against adversarial attacks, a plethora of meticulously crafted countermea-\nsures exist to safeguard systems. One such strategy, particularly pertinent in decentralized inference\nsettings, involves the implementation of mechanisms where central servers solicit proof of comput-\ning execution from each node. This process is orchestrated with precision to ensure that while the\nproof is furnished, the node's confidential model parameters remain undisclosed. Subsequently, the\ncentral servers meticulously scrutinize the proofs submitted, thereby enabling them to discern the\nreliability of each node. The efficacy of this approach hinges upon the successful verification of the\nproof, serving as a litmus test for the trustworthiness of the node in question.\nThe challenge intensifies when fast inference of secure foundation models is required. Given the\nscale of big data and the models involved, foundation models inherently exhibit slow inference\nspeeds. It is widely acknowledged that incorporating security measures further exacerbates this\nslowdown in Al models. For instance, the fastest-known zero-knowledge proof algorithm currently\ntakes as long as 15 minutes to generate proof for a single token in the output [13]. Despite substantial\nefforts to expedite the inference process, it is imperative to ensure the security of foundation model\ninference without compromising efficiency."}, {"title": "2.1.2 PROBLEM SETUPS", "content": "Decentralized Inference. At Nesa, we explore the challenge of decentralized inference for foun-\ndation models, which offers numerous benefits. With the advent of 5G technology and improved\ninternet latency, personalized devices such as mobile phones can now participate in crowdsourcing\nmachine learning models. This approach enhances device utilization and eliminates the need for\ndata communication between nodes and a central server, thereby safeguarding data privacy. In the\ncontext of Machine Learning as a Service (MLaaS), models remain the private property of individ-\nual nodes, allowing them to offer model inference services via APIs without sharing model weights\nand checkpoints. As foundation models grow in size-such as Meta's LLaMA-3.1 with 405 billion\nparameters [4], and future models expected to reach trillion-level sizes it becomes impractical to\nload entire models on a single node or server. Additionally, technologies like blockchain are now\nequipped to support the decentralized inference of foundation models on-chain, further facilitating\nthis approach.\nModel Decomposition. A core assumption in decentralized AI inference is that the model used in\nthe inference system can be divided into several parts, each managed by a separate party, or com-"}, {"title": null, "content": "puting node. Each computing node performs its assigned computations and sends the results to a\ncentral server. For instance, with a foundation model like LLaMA-3, the model can be decom-\nposed layer-wise, enabling sequential inference by different nodes. Alternatively, decomposing the\nmodel width-wise allows for parallel inference across multiple nodes. The method of decomposition\ndepends entirely on the application scenarios, and we consider both approaches in Nesa's products."}, {"title": "2.1.3 THREAT MODELS", "content": "In this paper, we focus on decentralized inference of foundation models as described above. In this\nframework, each computing node (i.e. prover) owns a foundation model or a part of the foundation\nmodel with a publicly known architecture, while the model weights are proprietary. We make a\nsemi-dishonest assumption on the central server (i.e. verifier): the central server is honest in ag-\ngregating results from each computing node and accurately reports the verification result, but the\ncentral server tries to glean additional information about parts of the foundation model at computing\nnodes. However, some computing nodes might be dishonest, potentially deviating from the agreed\nprotocol by substituting their model with an alternative or outputting random data. We assume that\nthe majority of nodes are honest, but acknowledge that dishonest nodes can collude. These adversar-\nial nodes can arbitrarily alter their results, provided their behavior remains undetected by the central\nserver."}, {"title": "2.1.4 OVERVIEW OF ZERO-KNOWLEDGE PROOFS", "content": "We use the technique of zero-knowledge proofs to guarantee that each party is honest about his or\nher execution of inference of foundation models. Zero-knowledge proof serves as a fundamental\ntechnique and underpins the architecture of blockchain. In this cryptographic concept, two entities\nare involved: the prover and the verifier. The prover's objective is to demonstrate the successful\nexecution of a protocol without disclosing confidential information, termed as the 'witness'. This\nwitness encompasses sensitive data like model weights or private information that the prover wishes\nto keep undisclosed to the verifier. Often, the protocol is depicted as a circuit, where certain compo-\nnents remain hidden within the witness.\nCommitment, Proof, and Verification. The process of zero-knowledge proof involves three essen-\ntial steps. Firstly, the prover commits to the witness data, such as model parameters, ensuring its"}, {"title": "2.1.5 PROPERTIES OF ZERO-KNOWLEDGE PROOFS", "content": "Zero-knowledge proofs have many advantageous properties that form the foundation of blockchain\nand decentralized machine learning. These include:\nCompleteness: If the prover accurately executes the circuit, the proof will be validated (with prob-\nability 1).\nSpecial Soundness: If the prover is dishonest in executing the circuit, the proof will fail (with high\nprobability). A weaker property, special soundness, requires executing the protocol twice and being\nable to identify the witness.\nZero-Knowledge: The verifier gains no knowledge about the prover's witness.\nThe above properties ensure that the proof will pass verification only if the prover is honest, while\nalso allowing the prover to keep its secret or witness hidden from the verifier.\nInteractive vs. Non-Interactive Proof Systems. Depending on whether the proof-verification\nprocess involves a single round or multiple rounds, zero-knowledge proofs can be classified as either\ninteractive or non-interactive, respectively. Zero-knowledge proofs are naturally described as an\ninteractive process, where the verifier sends a challenge (typically a random variable) to the prover,\nwho then responds to the verifier. If the proof is valid, the verifier sends a new challenge in the\nnext round, and the process repeats. Given an input x, an interactive proof procedure\nworks as follows:\n1. P sends the first message \u03b1 \u2190 P(x).\n2. V sends a challenge \u03b2.\n3. P sends the second message \u03b3 \u2190 P(x, \u03b1, \u03b2).\n4. V decides to accept or reject according to an algorithm V(x, \u03b1, \u03b2, \u03b3).\nIn the non-interactive case, the process can be simulated by having the prover generate his/her own\nchallenge \u03b2. This is achieved by replacing the random variable \u03b2 in the challenge with a random\noracle model or a hash function H (such as SHA-256) that operates on all the messages that the\nprover has sent so far. This is also known as the Fiat-Shamir heuristic [17]. In particular, given an\ninput x, a one-shot, non-interactive proof procedure works as follows:\n1. P computes the first message \u03b1 \u2190 P(x).\n2. P computes a challenge \u03b2 \u2190 H(x, \u03b1).\n3. P computes the second message \u03b3 \u2190 P(x, \u03b1, \u03b2).\n4. P sends \u03b1 and \u03b3 to V.\n5. V computes \u03b2 \u2190 H(x, \u03b1) and decides to accept or reject according to an algorithm\nV(x, \u03b1, \u03b2, \u03b3)."}, {"title": "2.1.6 COMMITMENT", "content": "The Pedersen commitment (1) satisfies the binding property: once sent to the verifier, the opening\ninformation (r, S) cannot be changed anymore by the prover. Upon initial inspection, the prover\nneeds to send the witness S to the verifier to prove that he/she can \"open\" the commitment. Thus\nthe zero-knowledge property of the commitment (1) may appear impossible. However, this skepti-\ncism is unfounded, largely owing to the homomorphic property of the Pedersen commitment (1): for\ntwo commitments Commit(S1, r\u2081) and Commit(S2, r2) corresponding to tensors S\u2081 and S2, respec-\ntively, we have Commit(S1, r\u2081) Commit(S2, r2) = Commit(S1 + S2, r1 + r2), responding to the\ncommitment of tensor S1 + S2. This property enables the prover to prove to the verifier that he/she\ncan \"open\" the commitment without revealing the witness. This is achieved by letting the prover\ninstead open the commitment of a linear transformation of the witness: S' \u2190 S \u00b7 e + D, where D is\na d-dimensional hiding vector picked by the prover and e is a challenge (scalar) randomly sampled\nby the verifier. Hereby, the vector D is to hide the witness Sas Se + D looks random to the\nverifier. The existence of challenge e guarantees special soundness as two runs of the procedure\nwith challenges e\u2081 and e2 with e1 \u2260 e2 satisfy:\n$S_1 = S \\cdot e_1 + D,$\n$S_2 = S \\cdot e_2 + D.$\nIn Equation (2), we have 2d unknowns S and D and 2d equations. Thus, two accepting transcripts\n(S, e1, D) and (S, e2, D) will identify S and D by Gaussian elimination, thus achieving special\nsoundness."}, {"title": null, "content": "Algorithm 1 provides a complete procedure for the opening of the commitment. Let y be a publicly\nknown vector to both parties. The algorithm enables the prover to prove to the verifier that he/she\nknows a witness S \u2208 Fd and a witness t \u2208 F which are openings of the commitment (1) and the\ncommitment of t:\nCommit(t, rt) := h^t g^{r_t},\nsuch that <S, y> = t, where h and g are generators sampled randomly from an elliptic curve group.\nThe algorithm is provably complete, has special soundness, and exhibits zero-knowledge proper-\nties [18]. To see this, the completeness and zero-knowledge are obvious by the inspection of the\nalgorithm. To see the special soundness, for two runs of the algorithm with challenges e1 and e2"}, {"title": null, "content": "(e1 \u2260 e2) from the verifier, by Lines 8-9 of Algorithm 1, we have\nh^{S_1^\\prime} \\Pi_{i=1}^{d} g_i^{S_1i} = c_S \\cdot c_{CD},\nh^{S_2^\\prime} \\Pi_{i=1}^{d} g_i^{S_2i} = c_S \\cdot c_{CD},\nh^{t_1^\\prime}g^{\\langle S_1^\\prime,y\\rangle} = c_t \\cdot c_{\\langle D,y\\rangle},\nh^{t_2^\\prime}g^{\\langle S_2^\\prime,y\\rangle} = c_t \\cdot c_{\\langle D,y\\rangle},\nwhere S and S represent the i-th element of vector S\u2081 and S2, respectively. Denote by\n$r_S := (r_{S_1} - r_{S_2})/(e_1 - e_2) mod |G|,$ ,$ r_t := (r_{t_1} - r_{t_2})/(e_1 - e_2) mod |G|,$ , $\\tilde S := (S_1-\\S_2)/(e_1 - e_2) mod |G|,.$\nDividing Equation (4a) by (4b), we have\nh^{r_S} \\Pi_{i=1}^{d} g_i^{\\tilde S_i} = c_S.\nSimilarly, dividing Equation (4c) by (4d), we have\nh^{r_tg^{\\langle \\tilde S,y\\rangle}} = c_t.\nThus, we have shown that (<$\\tilde S,rS$) is an opening of the commitment cs and (<$\\tilde S, y), r_t$) is an opening\nof the commitment ct, as desired."}, {"title": "2.1.7 PROOFS FOR ARITHMETIC OPERATIONS", "content": "Multilinear Extension. Zero-knowledge proof focuses on the finite field F, rather than the real field\nIR as in the floating-point calculations. Arithmetic operations consist of addition and multiplication.\nFor these arithmetic operations, it is easy to use the Sum-Check protocol, in particular, the GKR\nprotocol [19, 20], to implement zero-knowledge proofs. The basic idea in the Sum-Check protocol is\nto express a d-dimensional tensor S \u2208 Fd involved in the calculation as a multi-variable polynomial\nS: Flog2 d\u2192 F via a transformation called multilinear extension [18]:\n$\\tilde{S}(u) = \\sum_{b \\in \\{0,1\\}^{log_2 d}}S(b)\\beta(u,b),$\nwhere b \u2208 {0, 1}log2 d refers to the binary index of tensor S, and $\\beta(\\cdot, \\cdot) : [F^{log_2 d} \\times F^{log_2 d} \\rightarrow F$ is\nthe (unique) Lagrangian interpolation polynomial:\n$\\beta(u,b) = \\Pi_{i=1}^{log_2 d} (u_i b_i + (1 - u_i)(1 - b_i)),$\nsuch that for any b1, b2 \u2208 {0, 1}log2 d, the interpolation property holds true:\n$\\beta(b_1, b_2) = \\begin{cases} 1, & \\text{if } b_1 = b_2;\\\\ 0, & \\text{otherwise}. \\end{cases}$\nThat is, the polynomial $\\tilde S$ is the Lagrange interpolation of the tensor S on the binary indices: $\\tilde S$\nis the unique multilinear polynomial over F such that S(u) = S(u) for all u \u2208 {0, 1}d. With\nthe multilinear extension, we can write the verification of arithmetic operations between vectors\nequivalently as the verification of sum of multi-variable, low-degree polynomial g:\n$H = \\sum_{(x_1,x_2,...x_v) \\in \\{0,1\\}}g(x_1,x_2,...,x_v),$"}, {"title": null, "content": "by considering the multi-linear extension of tensors.\nAlgorithm 2 describes the Sum-Check protocol, a.k.a. the GKR pro-\ntocol [19], for Equation (11). The protocol proceeds in v rounds [18]. In the first round, the prover\nsends a polynomial g1(X1) and claims it to be\n$g_1(X_1) \\stackrel{?}{=} \\sum_{(x_2,...,x_v) \\in \\{0,1\\}^{v-1}}g(X_1, x_2, ..., x_v),$\nwhere we use the capital letter (e.g., X\u2081) to represent the argument of the polynomial. A key\nobservation is that if the polynomial g1(X1) is as claimed in (12) and H is as claimed in (11),\nthen H = g1 (0) + g1(1). If so, the remaining proofs then proceed by proving Equation (12). By\nthe Schwartz-Zippel Lemma, it suffices for the prover to prove that Equation (12) holds at a random\npoint r\u2081 ~ F:\n$g_1(r_1) \\stackrel{?}{=} \\sum_{(x_2,...,x_v) \\in \\{0,1\\}^{v-1}}g(r_1, x_2, ..., x_v).$\nIn the second round, the prover sends a polynomial g2(X2) and claims it to be\n$g_2(X_2) \\stackrel{?}{=} \\sum_{(x_3,...,x_v) \\in \\{0,1\\}^{v-2}}g(r_1, X_2, x_3, ..., x_v).$\nObserve that if the polynomial g2(X2) is as claimed in (14) and g1(r1) is as claimed in (13), then\n91(r1) = 92(0) + g2(1). By the Schwartz-Zippel Lemma, it suffices for the prover to prove that\nEquation (14) holds at a random point r2 ~ F:\n$g_2(r_2) \\stackrel{?}{=} \\sum_{(x_3,...,x_v) \\in \\{0,1\\}^{v-2}}g(r_1, r_2, x_3, ..., x_v).$\nIn the third round, the prover sends a polynomial 93 (X3) and claims it to be\n$g_3(X_3) \\stackrel{?}{=} \\sum_{(x_4,...,x_v) \\in \\{0,1\\}^{v-3}}g(r_1, r_2, X_3, x_4, ..., x_v).$\nThe recursive argument then continues with the proof of\n$g_k(X_k) \\stackrel{?}{=} \\sum_{(X_{k+1},...,x_v) \\in \\{0,1\\}^{v-k}}g(r_1, ..., r_{k-1}, X_k, X_{k+1}, ..., x_v).$\nIn the final round, all's can be proved w.h.p. (i.e. with failure probability at most, where d is\nthe degree of g) by the recursive argument if and only if gv (rv) = g(r1, r2, ..., rv). The latter can be\neasily verified by the verifier via the opening of the commitment to g.\nThe procedure of the Sum-Check protocol is shown in Figure 3. The completeness is straightforward\nby the construction. The soundness follows from the recursive application of the Schwartz-Zippel\nLemma for each round. The zero-knowledge property follows from the privacy guarantee of the\nPedersen commitment.\nReducing Linear Layers to Sum-Check Protocol. Linear layers frequently appear in foundation\nmodels. Mathematically, linear layers can be written as matrix multiplication. Given n \u00d7 n matrices\nA and B and we denote AB as C. One can interpret A, B, C as function fa, fb, fc : {0,1}log2 n \u00d7\n{0,1}log2 n \u2192 F:\n$f_a(i_1, ..., i_{log_2 n}, j_1, ..., j_{log_2 n}) = A_{ij},$\nwhere sequence (i1, ..., \u0130log2 n) and (j1, \u2026\u2026\u2026, \u0130log2 n) are the binary representations of i and j, respec-\ntively. Let $\\tilde f_a, \\tilde f_b, \\tilde f_c : F^{log_2 n} \\times F^{log_2 n} \\rightarrow F$ denote the multilinear extension of fa, fb, fc. It is\neasy to check that\n$\\tilde f_c(i_1, ..., i_{log_2 n}, j_1, ..., j_{log n}) = \\sum_{b \\in \\{0,1\\}^{log_2 n}} \\tilde f_A (i_1, ..., i_{log_2 n}, b) \\cdot \\tilde f_B (b, j_1, ..., j_{log_2 n}).$\nEquation (19) is in the form of (11). Thus, we can apply the Sum-Check protocol for\nverifying the execution of linear layers with log2 n-variant, degree-2 polynomial $\\tilde g(b) =$\n$\\tilde f_A (i_1, ..., i_{log_2 n}, b) \\cdot \\tilde f_B (b, j_1, ..., j_{log_2n})$ and $H = \\tilde f_c(i_1, ..., i_{log_2 n}, j_1, ..., j_{log_2 n})$ at a random\npoint (11, ..., \u0130log2 n, 11, ..., \u0130log2 n) \u2208 Flog2 n\u00d7log2 n."}, {"title": "2.1.8 PROOFS FOR NON-ARITHMETIC OPERATIONS", "content": "There are two major techniques for zero-knowledge proof of non-arithmetic operations: 1) bit de-\ncomposition and 2) lookup table.\nReducing ReLU Activation to Bit Decomposition. Bit decomposition is one of the most fre-\nquently used techniques for zero-knowledge proofs of non-arithmetic operations. Let Z denote the\npre-activated tensor of ReLU, and let A denote the after-activated tensor. We now introduce the\ntechniques appearing in [11]. In the ReLU activation, we have\nA = sign(Z) abs(Z),"}, {"title": null, "content": "Algorithm 2 Sum-Check protocol (interactive) for Equation (11)\n1: Commitment: Prover commits to the polynomial g and sends the Pedersen commitment of g to\nverifier (with an ability to prove the evaluation g(r1, r2, ..., rv) at any point (r1, 2, ..., rv), see\nAlgorithm 1).\n2: Prover\nthe polynomial computes\nwith the argument X1:\ng1 (X1) =$\n$\\sum_{(x_2,...,x_v) \\in \\{0,1\\}^{v-1}}g(X_1, X_2, ..., x_v)$ and sends the polynomial to verifier.\n3: if Verifier finds H \u2260 g1(0) + g\u2081(1) then\n4:\nVerifier outputs REJECT and ends the algorithm.\n5: end if\n6: Verifier samples a random number r\u2081 \u2208 F and sends it to prover.\n7: for i = 2, 3, ..., v do\n8:\nProver computes the polynomial with the argument Xi:\ngi(Xi) =$\n$\\sum_{(x_{i+1},...,x_v) \\in \\{0,1\\}^{v-i}}g(r_1, ..., r_{i-1}, X_i, X_{i+1},...,x_v)$ and sends the polynomial gi (Xi)\nto the verifier.\n9: if Verifier finds gi\u22121(ri\u22121) \u2260 gi(0) + gi (1) then\n10:\nVerifier outputs REJECT and ends the algorithm.\n11: end if\n12: Verifier samples a random number ri \u2208 F and sends it to prover.\n13: end for\n14: if Verifier checks that gr(rv) matches the opening of the commitment by a proof system in\nAlgorithm 1 then\n15: Verifier outputs PASS.\n16: else\n17: Verifier outputs REJECT.\n18: end if"}, {"title": null, "content": "where is the Hadamard product"}, 0, 1, ".", 1, 28, 56, {"prove": "n1) (zo", "0,1}": 0}]}