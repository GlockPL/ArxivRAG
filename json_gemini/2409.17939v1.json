{"title": "Predicting Anchored Text from Translation Memories\nfor Machine Translation Using Deep Learning Methods", "authors": ["Richard Yue", "John E. Ortega"], "abstract": "Translation memories (TMs) are the backbone for professional translation tools called computer-aided trans-\nlation (CAT) tools. In order to perform a translation using a CAT tool, a translator uses the TM to gather\ntranslations similar to the desired segment to translate (s'). Many CAT tools offer a fuzzy-match algorithm\nto locate segments (s) in the TM that are close in distance to s'. After locating two similar segments, the\nCAT tool will present parallel segments (s, t) that contain one segment in the source language along with its\ntranslation in the target language. Additionally, CAT tools contain fuzzy-match repair (FMR) techniques that\nwill automatically use the parallel segments from the TM to create new TM entries containing a modified\nversion of the original with the idea in mind that it will be the translation of s'. Most FMR techniques use\nmachine translation as a way of \"repairing\" those words that have to be modified. In this article, we show that\nfor a large part of those words which are anchored, we can use other techniques that are based on machine\nlearning approaches such as Word2Vec. BERT, and even ChatGPT. Specifically, we show that for anchored\nwords that follow the continuous bag-of-words (CBOW) paradigm, Word2Vec, BERT, and GPT-4 can be\nused to achieve similar and, for some cases, better results than neural machine translation for translating\nanchored words from French to English.", "sections": [{"title": "1 Introduction", "content": "Professional translators use computer-aided transla-\ntion (CAT) tools (Bowker, 2002) to translate text\nfrom one language called the source language (SL)\nto a target language (TL). Most CAT tools have an\noption known as fuzzy-match repair (FMR) (Kranias\nand Samiotou, 2004; Hewavitharana et al., 2005;\nDandapat et al., 2011; Ortega et al., 2016; Bulte\net al., 2018; Tezcan et al., 2021), which is backed\nby a parallel translation memory (TM) that contains\nsentences (called segments) in the SL and TL. Each\npair, or unit, of parallel segments in the TM is known\nas a translation unit (TU). A TU contains a source\nsegment (s) along with a target segment (t). When\na professional translator attempts to translate a seg-\nment in the SL (denoted as s') a fuzzy-match lookup\nis performed using a word-based Levenshtein dis-\ntance (Levenshtein, 1966) between s' and s where a\n100% match means that the words from s' are iden-\ntical to the words in s. It is often the case that a pro-\nfessional translator uses matches from FMR to only\ntranslate a few words (called sub-segments) from the\nentire segment. In this article, we focus on improv-\ning those cases where there exists only one word to\ntranslate, known as an anchored word, whose posi-\ntion is in between two words that are already cap-\ntured. In our studies, the anchored word is a com-\nmon case that professional translators often use. We\nexperiment with four techniques to translate the an-\nchored word: (1) Neural Machine Translation, (2) a\nBERT-based (Sanh et al., 2019) implementation, (3)\nWord2Vec (Mikolov et al., 2013) and (4) OpenAI\nGPT-4 prompting (Achiam et al., 2023).\nThe prediction of an anchored word has been\npresented in many contexts and can be considered"}, {"title": "2 Related Work", "content": "For the majority of FMR approaches, MT is used\nto translate mismatches, regardless if they are an-\nchored words or not. Generally, MT techniques for\nFMR are focused on the decoding process where\nstatistical-based systems (Biccici and Dymetman,\n2008; Simard and Isabelle, 2009; Zhechev and Gen-\nabith, 2010; Koehn and Senellart, 2010; Li et al.,\n2016; Liu et al., 2019) or neural-based systems (Or-\ntega et al., 2014, 2016; Gu et al., 2018; Bulte et al.,\n2018; Bulte and Tezcan, 2019) are used in such a\nmanner to \"repair\" either the MT system or the mis-\nmatched sub-segments between s' and s. This ar-\nticle is focused on repairing the mismatched sub-\nsegments in specific situations where sub-segments\nof s are common in s' with the exception of one\nword (e.g. s='the brown dog' and s'='the red\ndog').\nPrevious work (Ortega et al., 2016; Bulte et al.,\n2018) can be considered identical to this article as\nit uses FMR to first find mismatches between s' and\ns and then translates the missing words with differ-\nent MT systems. However, their system uses con-\ntext around all mismatches where we only consider\nmismatches with anchored words, similar to Kra-\nias and Samiotou (2004). While other techniques\n(Hewavitharana et al., 2005; Dandapat et al., 2011)\nare based on probabilistic MT models or employ dif-\nferent algorithms for aligning s' and s, we use a\nword-based edit distance (Levenshtein, 1966; Wag-\nner and Fischer, 1974) that marks the mismatched\nsub-segments and discards non-anchored words.\nTezcan and Bulte (2022) investigate a wide\nrange of automatic quality estimation (QE) met-\nrics in order to assess what effect integrating fuzzy\nmatches can have on a number of aspects of trans-\nlation quality, in addition to performing manual MT\nerror analysis. They further evaluate what influence\nfuzzy matches have on a translation and how fur-\nther quality improvements can be made by quanti-\ntative analyses that focus on the specific characteris-\ntics of a retrieved fuzzy match. Neural Fuzzy Repair\n(NFR) outperforms baselines in all automated eval-\nuation metrics. There was not a discernable differ-\nence between NFR and Neural Machine Translation\n(NMT) error in manual evaluation, but different er-\nror profiles emerged in this study, highlighting some\nof the strengths and weaknesses of each method.\nNamely, NFR produced more errors in the category\nof \"semantically unrelated\", whereas the baseline\nNMT system produced more errors in the categories\nof \"word sense\u201d and \u201cmulti-word expression\". The\nNFR system made more accuracy errors, but pro-\nducing fluent output was its strong suit. Meanwhile,\nin terms of lexical choices, NMT produced more\n\u201cnon-existing/foreign\u201d errors, which was not an is-\nsue for NFR. The baseline system performed better\non grammar and syntax. Our study differs in that it\nfocuses specifically on anchored text and on lever-\naging the strengths of language models in next word\nprediction in order to fill in single-word gaps.\nEspla-Gomis et al. (2011) attempt to improve\nCAT via the TM using pre-computed word align-\nments between source and target TUs in the TM.\nWhen a user is translating s' with a fuzzy match\nscore greater than or equal to 60%, the proposed sys-\ntem marks the words that need to change as well as\nthose that must remain the same in order to obtain\nt'. Alignments are obtained from GIZA++ (Brown\net al., 1993; Vogel et al., 1996) and take both a sta-\ntistical and syntactic approach to detecting where\nchanges need to occur. The experiments offer in-\nsight into how human decisions to keep/change text\nduring translation can be integrated into FMR. Our\napproach differs in that we specifically locate an-"}, {"title": "3 Methodology", "content": "Neural MT systems have been shown by previous\nwork (Bulte and Tezcan, 2019) to be the state-of-the-\nart for FMR. In this article, we experiment on the\none hand with word-based language models that are\ntrained using context around a word, like those that\nuse the continuous bag of words (CBOW) model\n(Mikolov et al., 2013) (Word2Vec) or masked lan-\nguage modeling (Sanh et al., 2019) (BERT). On the\nother hand, it is our belief also that generative lan-\nguage modeling techniques may be a good candidate\nfor accomplishing this task. To explore this avenue,\nwe also compare output from these models with pre-\ndictions obtained from prompting GPT-4 and find it\nto be competitive with the other methods. An exam-\nple of a source sentence and the output from each\nmethod is provided in Table 1 with predicted (or ref-\nerence) word in bold. In our experiment, the two\nlanguage modeling techniques as well as the genera-\ntive approach are compared against machine transla-\ntion and measured using character rate and accuracy\nagainst sets of anchored words from the test set. A\nprediction or translation was deemed correct when"}, {"title": "3.1 Machine Translation", "content": "We train the neural MT system with Open-NMT\n(Klein et al., 2020) using the default transformer\nconfiguration. In order to get a wider range of\ndifference with the MT system, we translate using\ntwo methods: (1) the translation of the s'en segment\nto tr then translation from tr to sen; and, (2)\nthe translation of the three-word sub-segment only\n(i.e. the anchored tri-gram with the center word\nto be translated) from $S_{trigram-en}$ to $t_{trigram-fr}$\nthen translation from $t_{trigram-fr}$ to $S_{trigram-en}$.\nFor both methods, correctly translated center words\nfrom tri-grams were counted in the overall evalu-\nation. Predictions by the other two methods were\nscored similarly. Further details on parameters and\nconfiguration are found in Section 4.2."}, {"title": "3.2 Word2Vec", "content": "We used a pre-trained language model (PLM) for\nexperimentation with Word2Vec (Mikolov et al.,"}, {"title": "3.3 BERT", "content": "Models based on the BERT (Kenton and Toutanova,\n2019) algorithm are used frequently in modern\ntimes. They use an attention mechanism (Vaswani\net al., 2017) and are known to be capable of cap-\nturing information better than previous implementa-"}, {"title": "3.4 GPT-4", "content": "We experiment with prompting GPT-4 to predict an-\nchored text using a temperature of 0 and the fol-\nlowing prompt: \"You are an expert lexicographer\nand natural language processing assistant. Addi-\ntionally, you are highly specialized in parliamentary\nproceedings. Given a trigram I provide with a '?'\ncharacter in the center word, I need you to predict\nthe'?' character with the most likely single-word to-\nken. Please return one predicted token without any\ntext except the predicted token in your response. Do\nnot provide the surrounding text or any additional\ninformation. Do not include the text 'predicting',\n'predict', 'prediction', 'predicted' 'the predicted to-\nken is' or 'The predicted token is' in your response.\nDo not include any extra characters such as apos-\ntrophes, commas, colons, or semicolons in your re-"}, {"title": "4 Experimental Settings", "content": ""}, {"title": "4.1 Corpus", "content": "The corpus consists of 393,371 SL-TL pairs of Eu-\nropean parliamentary proceedings, a freely avail-\nable translation memory (Steinberger et al., 2012)\nobtained from the European Commission DGT-\nTranslation Memory repository. The corpus is di-\nvided randomly with a random state of 42. We di-\nvide the corpus up into 70% train, 20% dev, and 10%\ntest sets as shown in in Table 2."}, {"title": "4.2 Machine Translation", "content": "As mentioned previously, we use the Open-NMT\n(Klein et al., 2020) framework to build our French\nto English (FR-EN) and English to French (EN-\nFR) MT system. The system is based on a trans-\nformer architecture model with the following hyper-\nparameters: A maximum sequence length of 500,\nan early stopping parameter of 4, 7,800 train steps,\n1,000 validation steps, a bucket size of 262,144, a\nbatch size of 4,096, and a validation batch size of\n2,048. The optimizer is an Adam (beta2 of 0.998)\noptimizer with with fp16 activated, a learning rate of\n2, noam decay, label smoothing of 0.1, a hidden size\nof 512, word vector size of 512, 8 attention heads, a\ndropout of 0.1, and an attention dropout of 0.1. The\nchoice of parameter selection is inspired by previous\nwork from Yasmin Moslem.\nIn order to verify that the NMT system is on-\npar with the latest MT systems for FR-EN and EN-\nFR, we first test the system in both directions on the\ntest set. During test, we achieved a BLEU score of\n55.84 for FR-EN and 62.60 for EN-FR. Nonethe-\nless, as we show in Section 5, the translation of an-\nchored words as measured by character rate and ac-\ncuracy was not remarkable."}, {"title": "4.3 Word2Vec", "content": "The CBOW algorithm for Word2vec is a well-\nknown algorithm performed as a way of capturing\nsemantics via a language model (Mikolov et al.,\n2013). We describe our Word2Vec CBOW imple-\nmentation. Before fine-tuning, the Word2Vec model\nhas 300 dimensions with a window size of 2 and\na minimum word count of 1. Additionally, pre-\ndefined vocabulary is used in the Google News Vec-\ntors that contains billions of words. The model is\nfine-tuned with our training set which is tokenized\nusing the NLTK RegexpTokenizer4. The embed-\ndings created from the training set use lockf at 1.0\nand a window size of 3, similar to Zarrar Shehzad."}, {"title": "4.4 BERT", "content": "Our BERT model is based on a PLM called Distil-\nBERT. (Sanh et al., 2019) We train DistilBERT us-\ning the HuggingFace PyTorch Trainer with 10 train-\ning epochs, a learning rate of 2e-5, weight decay of\n0.01, and FP16 mixed precision set to true. Hyper-\nparameters are inspired by HuggingFace."}, {"title": "4.5 GPT-4", "content": "GPT-4 was prompted using the gpt-4-turbo variant\nand queried repetitively through the OpenAI API.\nDue to newline mismatches that occurred during\nbatch processing, we opted to run an API call for\nevery line in the dataset."}, {"title": "5 Results", "content": "In this section, we compare the results obtained from\nrunning four approaches for predicting the anchored\nword: (1) Neural Machine Translation (NMT) (2)\nWord2Vec (3) BERT and (4) GPT-4. NMT is di-\nvided into the two approaches mentioned in Sec-\ntion 3.1 (sentence-level and tri-grams). Accuracy\nmeasurements are performed and reported for all\nholes. Additionally, we report on character matches\nfor each approach after dividing the segments into\nfuzzy-match thresholds, common practice for FMR"}, {"title": "6 Conclusion", "content": "In this article, we have illustrated that via the use of\na language model, predicting anchored words per-\nformed better in our experiments. The BERT model\noutperforms other approaches including neural ma-\nchine translation (with two approaches) when mea-\nsured via character match and tri-gram anchored\nword coverage.\nWe also demonstrate how generative models\nmight be prompted to aid in predicting anchored\ntext. It is our belief that this work could assist CAT\ntools backed by TMs and MT systems."}]}