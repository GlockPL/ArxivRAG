{"title": "PiLocNet: Physics-informed neural network on 3D localization with rotating point spread function", "authors": ["Mingda Lu", "Zitian Ao", "Chao Wang", "Sudhakar Prasad", "Raymond H. Chan"], "abstract": "For the 3D localization problem using point spread function (PSF) engineering, we propose a novel enhancement of our previously introduced localization neural network, LocNet. The improved network is a physics-informed neural network (PINN) that we call PiLocNet. Previous works on the localization problem may be categorized separately into model-based optimization and neural network approaches. Our PiLocNet combines the unique strengths of both approaches by incorporating forward-model-based information into the network via a data-fitting loss term that constrains the neural network to yield results that are physically sensible. We additionally incorporate certain regularization terms from the variational method, which further improves the robustness of the network in the presence of image noise, as we show for the Poisson and Gaussian noise models. This framework accords interpretability to the neural network, and the results we obtain show its superiority. Although the paper focuses on the use of single-lobe rotating PSF to encode the full 3D source location, we expect the method to be widely applicable to other PSFs and imaging problems that are constrained by known forward processes.", "sections": [{"title": "1 Introduction", "content": "Locating point sources or structures in three-dimensional (3D) space is a common challenge in many scientific applications. This is particularly relevant in computer vision, which has numerous applications like robotics, augmented reality, and autonomous systems. For solving the 3D localization problem, point spread function (PSF) engineering is a promising and effective technique that places a specific phase function into the imaging aperture. This aperture function processes the photons emitted by a source point and entering the imaging system into an image pattern that carries information about the full 3D location of the source. Unlike traditional methods that leverage stereo or multi-view images, PSF engineering imprints the 3D location information of the point sources into the position and form of the corresponding images acquired on a single two-dimensional (2D) sensor. PSF-associated methodologies have wide applications that range from telescopic to microscopic imaging systems and have significantly enhanced the precision of point source localization. For example, single-molecule localization microscopy (SMLM)\u00b9 localizes individual fluorophores in 3D structures to render super-resolution imaging of fluorescent molecules. By leveraging the z-dependent form of the PSFs, 3D SMLM surpasses traditional diffraction limits, allowing for the visualization of biological structures at near-molecular resolution in all three dimensions. Numerous field studies have underscored this methodology's significance and potential.2-5\nVarious depth-encoding phase masks have been developed for PSF engineering, yielding a variety of PSFs, such as astigmatic, double helix (DH), and tetrapod. Here, we mainly consider the single-lobe rotating PSF (RPSF) invented by Prasad. By means of a suitable spiral phase function in the imaging aperture, one can create a PSF that rotates by an angle proportional to the depth (z) coordinate of the point source around a center fixed by the 2D transverse (x, y) coordinates of the source. The rotating PSF comprises a single bright lobe surrounded by a fainter ring-shaped substructure, which rotates together as the source defocus distance along the optical (z) axis changes. One of the main benefits of a single-lobe rotating PSF over other more complicated PSFs like the DH and tetrapod PSFs is that the former concentrates the photon energy into its single lobe with a higher flux density, making it more noise-robust in crowded source fields.10\nThe main objective of the problem is to recover the 3D locations of point sources from their observed noisy image as accurately as possible. Various methods have been proposed and categorized into mathematical optimization and neural network approaches. Several variational methods11\u201314 have been recently introduced from a non-convex optimization perspective. In the case of Gaussian image noise, the Frobenius norm is used as the data fitting term, and a continuous exact lo"}, {"title": "2 Single-lobe point spread function and its noise models", "content": "This section will provide a review of the single-lobe rotating PSF forward model and the two different noise models that we explore in the paper."}, {"title": "2.1 Forward model of single-lobe RPSF", "content": "The forward model has been described in great detail in our previous papers9,13,14 to which we refer the reader. Here, we only present a brief summary of the model. The RPSF image, \u0391\u03c2, for a point source with defocus parameter \u03da, a unit flux f = 1, at the source location ro = (x0, yo) is given by:\n$\\displaystyle A_{\\zeta}(s) = \\frac{1}{\\pi} \\int_{\\Omega} exp \\left[i (2\\pi u \\cdot s + \\zeta u^2 - \\psi(u))\\right] du$,\nwhere $\\zeta = \\frac{\\pi \\delta z R^2}{\\lambda z_0 (z_0 + \\delta z)}$, \u03a9 represents the circular disk-shaped clear pupil and i = \u221a-1. The quantity, $s = \\frac{r}{\\lambda z_1/R}$, is the position vector, r, of an image-plane point relative to the Gaussian image location, when expressed in units of the Rayleigh diffraction scale, \u03bb z\u2081/R; \u03bb is the imaging wavelength; R is the radius of the pupil; \u03b4z, z0, z\u2081 are the distances from the object plane to the in-focus object plane, the in-focus object plane to the pupil plane, and the pupil plane to the image plane, respectively. The symbol u denotes the position vector in the plane of the pupil, in units of the radius of the pupil. Its polar coordinates are u = (u, \u03c6u). The circular pupil is segmented into L different contiguous annular Fresnel zones, with each zone carrying a spiral phase function, (u), with the number of complete phase cycles changing successively by 1 from one zone to the next. The RPSF can be shown to continuously rotate within the scaled defocus range, \u03b6 \u2208 [\u2212\u03c0L, \u03c0L], as it begins to spread out, break apart, and lose its shape unacceptably outside this range.\nWith the above formulation, for N point sources the observed image count G(x, y) at location (x, y) may be expressed as:\n$G(x,y) \u2248 N \\sum_{i=1}^{N} A_i(x - x_i, y - y_i) f_i + b$\nwhere (xi, Yi) and f\u2081 are the transverse coordinates and flux of the ith point source. Its depth coordinate, zi, is embedded in the PSF A\u2081 and N is the operator for incorporating noise.\nSpecifically, the forward model for the Gaussian noise case can be conceptualized as following the Gaussian distribution at the p-th pixel,\n$G_p \u223c N([T(A*X)]_p + b, \u03c3\u00b2), p = 1, 2, ..., d$, (1)\nwhere \u039d(\u03bc, \u03c3\u00b2) denotes the Gaussian distribution with expectation \u03bc and variance \u03c3\u00b2, A * X is the 3D convolution of A with X, and T projects out a 2D slice of the convolution. b represents the background photons, which is always a constant no matter how \u03c3\u00b2 changes in Gaussian noise cases. The symbol A denotes the 3D PSF dictionary represented as a cube, which is built from"}, {"title": "2.2 Optimization approach: the variational models", "content": "In order to recover the 3D tensor X from the given observed image G, the optimization approach can be formulated as a minimization problem,\n$\\displaystyle \\min_{X} D (T (A * X) + b, G) + R(X)$,\nwhere D enforces data fitting and R (X) is an appropriate regularization term. We next formulate these two terms for our two different noise models."}, {"title": "2.2.1 The case of Gaussian noise", "content": "Gaussian noise is a common type of noise for which the random error, as we have just noted, has a Gaussian probability distribution. This noise is present due to various factors such as sensor read-out error, non-uniform brightness response of the image sensor, noise and mutual interference from circuit components, and prolonged usage of the image sensor at high temperatures. For the Gaussian noise case, the data-fitting term is a simple quadratic function,\n$\\displaystyle D(T(A*X) + b, G) := ||T(A * X) + b - G||_F^2$,\nwhere || || F denotes the Frobenius norm, namely the l2 norm, of the vectorized input. The regularization term enforces sparsity, for which we use a non-convex term approaching the lo norm for linear least squares data fitting problems. Specifically, we have used the Continuous Exact lo (CEL0) penalty function22 defined as:\n$\\displaystyle R(X) := \\phi_{CEL0}(X) = \\sum_{i,j,k=1} \\phi(||T(A* \\delta_{ijk}) ||, \\mu; X_{ijk}),$ (3)\nwhere $\\phi(\\alpha, \\mu; u) = \\frac{\\alpha^2}{2} - \\frac{\\mu^2}{2} (1 \\wedge \\frac{\\alpha}{\\mu})^2$ and $1_{E} :=$\n$\\begin{cases}\n1 & \\text{if } u \\in E;\\\\\n0 & \\text{others}.\n\\end{cases}$\nIn addition, dijk is a 3D tensor whose only nonzero entry is at (i, j, k) with value 1; \u03bc is the parameter to control the non-convexity. The minimization problem was formulated as\n$\\displaystyle \\min_{X>0} \\{||T(A * X) + b \u2013 G||_F^2 + \\sum_{i,j,k=1} \\phi(||T(A* \\delta_{ijk})||, \\mu; X_{ijk})\\}$."}, {"title": "2.2.2 The case of Poisson noise", "content": "The Poisson noise model describes the probability distribution of the number of random events, such as photon counts, occurring per unit time. The data fitting term for the Poisson noise case is the I-divergence, which is also known as the Kullback-Leibler (KL) divergence:23\n$\\displaystyle D(T(A* X) + b, g) := D_{KL}(T(A* X) + b, G)$,\nwhere DKL(z, g) = (g, ln z) + (1, z \u2013 g). The sparsity-enforcing regularization term is designed as a non-convex function:24-26\n$\\displaystyle R(X) := \\mu \\sum_{i,j,k=1} \\theta(a; X_{ijk}) = \\mu \\sum_{i,j,k=1} \\frac{|X_{ijk}|}{a + |X_{ijk}|}$,\nwhere a is a fixed parameter that determines the degree of non-convexity. The Poisson minimization problem was formulated as\n$\\displaystyle \\min_{X>0} \\{ (1, T(A*X) - G \\ln(T(A* X) + b)) + \\mu \\sum_{i,j,k=1} \\frac{|X_{ijk}|}{a + |X_{ijk}|} \\}$."}, {"title": "3 The PINN Methodology", "content": "Here we propose a physics-informed neural network called PiLocNet that works for RPSF imaging for the Gaussian and Poisson noise models. As an enhancement of the typical black-box type of neural networks, the proposed model builds the known physics information of the forward process into a PINN framework through additional loss functions."}, {"title": "3.1 Convolutional Neural Network: LocNet", "content": "LocNet, 15 which combines a deep convolutional neural network (CNN) with a post-processing step, was adopted for RPSF-image based 3D source localization. The CNN part, similar to Deep-STORM3D, consists of 3D grid layers to accommodate the point source prediction. Several practical CNN techniques were employed, such as up-sampling and residual layers. The loss function of LocNet is\n$L_{LocNet} = ||G_{3D} * (\\hat{X} - X_{GT})||_2^2$,\nwhich is the mean square error of the ground truth XGT and prediction X, with both smoothed by a 3D Gaussian kernel G3D. After the network generates the initial predictions, a post-processing step further refines the results by clustering closely spaced point sources into one and removing sources with brightness lower than a threshold."}, {"title": "3.2 The pipeline of PiLocNet and its architecture", "content": "LocNet is a data-driven approach that only considered the Poisson noise scenario in Ref.15 Here we incorporate PINN into LocNet and propose a new framework, PiLocNet, for both Poisson and Gaussian noise cases. The main idea of PINN is to incorporate information about the physics of the problem at hand into the neural network's loss function. This approach helps the training process to achieve accurate results by minimizing the loss with improved guidance provided by known physical information. In this context, we discuss how this concept can be implemented to solve the PSF problem. We modify the LocNet loss function by adding to it two extra terms,\n$L_{PiLocNet} = w_1D(T(A* X) + b, G) + w_2R(X) + w_3L_{LocNet}$, (4)\nthe first term being the data-fitting term, which contains the PSF operator, A, the known physics information to guide the neural network. However, to add the data fitting term into the loss function correctly, it needs to be model-dependent for different noise types and must be accompanied by an appropriate regularization, which is its second term. Additionally, we need different relative weights, W\u2081 : W2 : W3, for the three terms to ensure proper balance and trade-off of these terms.\nWe employ the same data fitting and regularization terms for the cases of Gaussian and Poisson noise that we described in the previous section but now allow them to have different relative weights. In other words, we use the following PINN loss functions for the two noise cases, respectively:\n$L_g = w_1||T(A* X) + b \u2212 G||\u00b2 + w_2\u03c6_{CEL0}(X) + w_3||G_{3D} * (\\hat{X} \u2013 X_{GT})||$ (5)\nand\n$\\displaystyle L_p = w_1 (1,T(A*X) - G \\ln(T(A* X) + b)) + w_2 \\sum_{i,j,k=1} \\frac{|X_{ijk}|}{X_{ijk}+a} + w_3||G_{3D} * (\\hat{X}-X_{GT}) ||^2$. (6)\nFor most of the experiments conducted in the paper, the weights W1,W2, W3, was in the ratio 1:700:1000 for the case (5) of Gaussian noise and 1:1:500 for the case (6) of Poisson noise. For experiments in ablation study on different noise levels, one can go through a searching process to reach optimal weight values correspondingly.\nThe architecture of PiLocNet closely resembles that of LocNet,17 which was shown to be robust. In a hypothetical experiment with no noise added, the network can output results with very high accuracy, proving that it is well-designed. The network leverages convolutional kernels of specific dimensions to extract pertinent features, followed by batch normalization to expedite convergence. Subsequently, the ReLU activation function is applied. Finally, a shortcut connection is utilized to merge the input content with the output layer, facilitating residual convolution via a"}, {"title": "4 Results", "content": "To evaluate the 3D-localization performance of our proposed method, we employ recall and precision rates. The recall rate is defined as the ratio of the total number of predicted true positives to the total number of point sources that should have been identified as positive. The precision rate is similarly defined as the ratio of the total number of true positives to the total number of point sources predicted as positive. True positives are identified based on a specified distance threshold between predicted and ground-truth point sources based on.17 Note that reducing false negatives improves recall, while reducing false positives improves precision."}, {"title": "4.1 Comparison with previous methods", "content": "Based on the experimental setup outlined previously, we assess the average recall and precision rates across three different methodologies: the variational methods, 13 the original LocNet method,17 and a modified LocNet v2, which has the same loss function as LocNet except that its architecture is changed to be that of PiLocNet. The primary changes we have made were the removal of the up-sampling layer and adjustments made to the dilation rates within the residual convolution layers. The decision to eliminate the up-sampling layer stemmed from our observation that its removal reduces training time substantially without compromising the model's performance.\nThe dilation rates were aligned from {1, 2, 5, 9, 17} to {1, 2, 4, 8, 16}. A comparative analysis between PiLocNet and LocNet v2 is crucial to ascertain the efficacy of our proposed model in terms of PiLocNet's use of a more physically sensible loss function. The chosen noise model is either Gaussian or Poisson, as described by Eq. 1 or Eq. 2, respectively. For the case of Gaussian noise, its standard deviation, \u03c3, is taken to be uniform across the image and equal to a fraction of the value, Imax, of the maximum flux at the pixels in an arbitrary observed image. Unless noted otherwise, we chose \u03c3 0.1 \u00d7 Imax for our studies on the Gaussian noise model and the background value of b = 5 for both noise models."}, {"title": "4.2 Contributions of the data-fitting and regularization terms", "content": "Note that the physics-informed loss function of PiLocNet, is represented by Eq. 4, LPiLocNet w1D + w2R + w3MSE, where D and R are model specific terms. Setting the first two weights to zero, w\u2081 = 0, W2 = 0, reduces PiLocNet to LocNet v2. For this section, we set up control groups to study the individual contribution of each added term within the loss function, presenting our results in Table 3.\nFor the Gaussian case, adding D to MSE improves the average recall rate from 90.54% to 90.67%, but the average precision drops from 83.68% to 82.38%. When only R is added to MSE, we increase the precision from 83.68% to 84.19%, while the average recall is not as good as that of the group in which only D has been added to MSE. For PiLocNet, we find the best average recall and precision rates. Similarly, for the Poisson case, adding D to MSE improves average recall from 98.15% to 98.27%, the latter being the best recall result among all groups. However, its precision decreases from 97.07% to 96.33%. Combining D, R, and MSE, we once again achieve the best average recall and precision rates."}, {"title": "4.3 Robustness on Noise Level", "content": "We also conducted a comprehensive assessment of the robustness of PiLocNet's performance, relative to LocNet v2's, across varying noise levels for the two models of noise considered here. We chose the number of point sources to be 25 for this purpose. In the case of Gaussian noise, we evaluated performance across five different noise levels, as depicted in Fig. 4a, where the horizontal axis represents the noise level, with the noise standard deviation, \u03c3, being the indicated value multiplied by Imax and the background b fixed at b = 5 for each noise level. The results involving Poisson noise are illustrated in Fig. 4b, where the horizontal axis represents the background photon count, b. Across both noise types, PiLocNet consistently outperformed LocNet v2, demonstrating superior precision while maintaining a very similar recall rate (nearly overlapping red and blue 's). Notably, as the noise level increased, PiLocNet exhibited even more significant precision gains over LocNet v2. For instance, under Gaussian noise with a variance of \u03c3 = 0.100 \u00d7 Imax, PiLocNet's precision was higher by about 1%, while at \u03c3 0.125 \u00d7 Imax, its precision gain exceeded 6%."}, {"title": "5 Conclusions", "content": "The new method, PiLocNet, that we have proposed here adds useful physical information to the neural network by adding to the conventional network loss function data-fitting and regularization terms that match the noise model governing the observed image data. As we have shown, this greatly improves the network performance. The principal change in the network architecture from LocNet, namely the removal of upsampling and a coarsening of the 3D grid, leads to a reduction of false positives while greatly shortening the network training speed without sacrificing overall performance. PiLocNet outperforms previous methods, as we have demonstrated through robust validation processes.\nIn the modified loss function of PiLocNet, the data-fitting term D containing the additional PSF matrix information tends to recover point predictions that would otherwise be missed. The regularization term R, on the other hand, exploits sparsity to reduce the occurrence of false positives. These two effects improve the overall network performance by reducing the rates of both false negatives and false positives.\nNeural networks, when well trained, excel at making predictions from highly complex datasets, while variational methods critically employ physical information about the PSF and noise model as well as regularization to avoid overfitting. PiLocNet combines the strengths of both these approaches. By embedding the forward model directly into a neural network, PiLocNet can implement a broad range of PSFs and imaging challenges when the forward model is accurately known. In our future work, we will explore improved data-fitting methodologies to further enhance the performance of PiLocNet. Additionally, we plan to extend the application of our methodology beyond simulated experiments to real-world datasets."}, {"title": "5.1 Disclosures", "content": "The authors declare no conflicts of interest."}]}