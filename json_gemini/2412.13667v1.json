{"title": "Exploring Multi-Modal Integration with Tool-Augmented LLM Agents for Precise Causal Discovery", "authors": ["ChengAo Shen", "Zhengzhang Chen", "Dongsheng Luo", "Dongkuan Xu", "Haifeng Chen", "Jingchao Ni"], "abstract": "Causal inference is an imperative foundation for decision-making across domains, such as smart health, AI for drug discovery and AIOps. Traditional statistical causal discovery methods, while well-established, predominantly rely on observational data and often overlook the semantic cues inherent in cause-and-effect relationships. The advent of Large Language Models (LLMs) has ushered in an affordable way of leveraging the semantic cues for knowledge-driven causal discovery, but the development of LLMs for causal discovery lags behind other areas, particularly in the exploration of multi-modality data. To bridge the gap, we introduce MATMCD, a multi-agent system powered by tool-augmented LLMs. MATMCD has two key agents: a Data Augmentation agent that retrieves and processes modality-augmented data, and a Causal Constraint agent that integrates multi-modal data for knowledge-driven inference. Delicate design of the inner-workings ensures successful cooperation of the agents. Our empirical study across seven datasets suggests the significant potential of multi-modality enhanced causal discovery.", "sections": [{"title": "Introduction", "content": "Identifying cause-and-effect relationships in complex systems is crucial for a variety of applications, including neuralgia diagnosis in medicine (Tu et al., 2019), protein pathway analysis in computational biology (Sachs et al., 2005), and root cause locating in microservice architectures (Wang et al., 2023a). These causal insights significantly benefit emerging fields such as smart health, AI-driven drug discovery, and AIOps. The process of discovering such relationships, known as causal discovery, typically generates a Directed Acyclic Graph (DAG). In this graph, edges represent the existence and direction of causal relationships between variables, as illustrated in Fig. 1(a). This DAG not only governs the data generation process but also enhances the understanding of inter-variable influences, serving as the foundation for many downstream decision-making tasks (Nguyen et al., 2023). As such, constructing accurate causal graphs is essential to the reliability of subsequent analyses.\nConventional methods primarily rely on data-driven statistical causal discovery (SCD), which can be categorized as non-parametric (Spirtes and Glymour, 1991; Silander and Myllym\u00e4ki, 2006; Huang et al., 2018; Xie et al., 2020) and semi-parametric (Shimizu et al., 2006, 2011; Zheng et al., 2018; Tu et al., 2022). These methods estimate causal relationships by analyzing the observational data of variables, but they overlook the semantic and contextual cues of the variables, resulting in suboptimal outcomes (Takayama et al., 2024).\nCommonsense and domain knowledge are invaluable for identifying cause-and-effect relationships among semantically meaningful variables. In light of this, growing research attention has been drawn to elicit such information for causal discovery. Large Language Models (LLMs), as praised by its astonishing reasoning ability drawing on extensive knowledge acquired from large-scale training (Brown et al., 2020; Achiam et al., 2023), now"}, {"title": "", "content": "become a promising and cost-effective source of expert knowledge to aid causal discovery. For example, by merely prompting with variable names and some contextual cues, LLMs have been shown to infer meaningful causal relationships (Ban et al., 2023; Jiralerspong et al., 2024). More recently, hybrid approaches were introduced to combine LLMs with data-driven SCD algorithms, achieving enhanced accuracy in causal discovery (Takayama et al., 2024; Khatibi et al., 2024). However, most existing methods have yet to fully harness the potential of modern LLMs, particularly the agent systems built upon tool-augmented LLMs.\nAn LLM agent is typically equipped with memory, reasoning, planning, and access to external tools such as calculators, search engines, and code compilers, rendering it superior in problem-solving compared to vanilla LLMs (Yao et al., 2022). As a single-agent system may be hallucination-prone even with self-reflection (Li et al., 2023; Shinn et al., 2024), multi-agent systems were introduced, which rivals more advanced models by combining multiple weaker agents. Despite the fast progress, LLM agents for causal discovery remains underexplored. The most relevant effort to date introduced a multi-agent system with debating LLMs for synergistic causal inference (Le et al., 2024). However, this approach has never explored the potential of multi-modality in data a feature that agent systems are well-equipped to handle.\nAs Fig. 1 shows, hybrid methods for causal discovery typically prompt LLMs with the prior causal graph produced by some SCD algorithm, appended by some meta-data (e.g., variable names, dataset titles) as contexts. However, these inputs may fall short in fully activating the reasoning ability of LLMs. Inspired by the observation that the abundant semantic data from external sources, such as webs and logs, can serve as an additional modality to the causal graph for improving prompts, we propose a Multi-Agent system with Tool-augmented LLMs for exploring Multi-modal enhancement of Causal Discovery (MATMCD).\nSpecifically, MATMCD is designed as a framework for refining causal graphs generated by SCD algorithms, involving two key agents: (1) a Data Augmentation Agent (DA-AGENT, \u00a73.2), and (2) a Causal Constraint Agent (CC-AGENT, \u00a73.3). Given a causal graph output by some SCD algorithm, DA-AGENT integrates meta-data (i.e., variable names and dataset titles) and calls tools such as web search APIs or offline log lookup APIs for"}, {"title": "", "content": "iterative, reflection-based retrieval of augmented (textual) data, which is summarized as a compact cue in a different modality from the graphs. Upon receiving the augmented data, CC-AGENT combines it with the topological structure of the prior causal graph to infer the causal relationships among variables. Both agents comprise multiple cooperative LLMs with delicate mechanisms to handle sub-tasks such as tool-calling, memorizing, reasoning, and summarization. Retrieval Augmented Generation (RAG) (Lewis et al., 2020) components are used where efficient memory is essential. In our experiments, we compared MATMCD with state-of-the-art (SOTA) baseline methods across five benchmark datasets and two public AIOps datasets of microservice systems. The results demonstrate substantial improvements in causal discovery by incorporating multi-modal data. The main contributions of this work are summarized as follows:\n\u2022 We propose to explore the problem of multi-modality enhanced causal discovery via LLM agents, which is significant yet less studied.\n\u2022 We introduce MATMCD, a novel framework of multi-agent, as a testbed for assessing the effectiveness of multi-modality in causal discovery.\n\u2022 We perform extensive experiments on a variety of datasets, where MATMCD reduces causal inference errors (NHD) by up to 66.7% and improves root cause locating (MAP@10) by up to 83.3% over the best baselines, suggesting the potential of multi-modality data in causal discovery."}, {"title": "Related Work", "content": "Causal Discovery Methods are mostly conventional data-driven SCD algorithms, including non-parametric methods (Spirtes and Glymour, 1991; Chickering, 2002; Silander and Myllym\u00e4ki, 2006; Huang et al., 2018; Xie et al., 2020) and semi-parametric methods (Shimizu et al., 2006; Hoyer et al., 2008; Shimizu et al., 2011; Zheng et al., 2018; Rolland et al., 2022; Tu et al., 2022). These methods rely on observational data as input but cannot leverage the semantics of variables. Recently, knowledge-driven methods have been found promising for causal discovery. Some early efforts use LLMs by simply prompting variable names and dataset titles (K\u0131c\u0131man et al., 2023; Ze\u010devi\u0107 et al., 2023; Chen et al., 2024a; Jiralerspong et al., 2024). Then hybrid approaches that integrate SCD algorithms with LLMs were introduced (Ban et al., 2023; Vashishtha et al., 2023; Khatibi et al., 2024;"}, {"title": "", "content": "Takayama et al., 2024) and found to be more effective than pure LLM-based methods. More recently, a multi-agent system-based approach was proposed (Le et al., 2024) to explore the impacts of debating LLMs. However, none of these methods has explored the potential of multi-modal data in the LLM-based causal discovery process.\nLLM Agents are typically equipped with plan, memory and tools. Planning can use techniques such as CoT (Wei et al., 2022), ReAct (Yao et al., 2022), and Reflexion (Shinn et al., 2024). Tools endow agents with the ability to interact with environments. MRKL (Karpas et al., 2022), Toolformer (Schick et al., 2024), Function Calling (OpenAI, 2024), and HuggingGPT (Shen et al., 2024) exemplify paradigms that integrate tools for problem-solving. For complex tasks, multi-agent systems are promising. The primary categories of multi-agent systems include cooperative agents (Qian et al., 2023; Chen et al., 2024b), competitive agents (Zhao et al., 2023) and debating agents (Li et al., 2023; Liang et al., 2023; Xiong et al., 2023). In this work, we intestigate a cooperative multi-agent system where the agents are coordinated to enhance a solution towards a shared goal."}, {"title": "Methodology", "content": "Fig. 2 is an overview of the proposed MATMCD system, which has four key components: (1) Causal Graph Estimator (\u00a73.1); (2) Data Augmentation Agent (DA-AGENT, \u00a73.2); (3) Causal Constraint Agent (CC-AGENT, \u00a73.3); and (4) Causal Graph Refiner (\u00a73.4). Next, we will first introduce some notations and then elaborate on each of the components in an order subject to the flow of data.\nNotations. Suppose there is a set of n variables V = {v_1, ..., v_n} (e.g., 4 variables in Fig. 1(a)), each variable v_i is associated with a set of observed data samples v_i = {v_{i1}, ..., v_{im}} where m is the number of samples. The observational data could be random samples or a length-m time series emitted by each variable, depending on the application. In many cases, meta-data is available. In this work, we assume a minimal set of meta-data D = {s, Z} where s is a descriptive title of the dataset (e.g., \u201cAutoMPG\u201d in Fig. 1(a)) and Z = {z_1, ..., z_n} includes the descriptive name z_i of each variable v_i in V (e.g., \"Acceleration\" in Fig. 1(a)).\nThe Task. Based on {V1, ..., vn} and D, we want to construct a DAG, G = (V, E), where each variable v_i in V is a node in the graph, and E \u2286 V \u00d7 V is the set of directed edges with (v_i, v_j) \u2208 E signifying a causal relationship from vi to vj. The goal of this work is to infer accurate causal relationships in & among the set of n variables in V."}, {"title": "Causal Graph Estimator", "content": "Similar to the hybrid approaches (Takayama et al., 2024; Khatibi et al., 2024), Causal Graph Estimator serves as an initializer of causal graph and is built upon data-driven SCD algorithms, with the aim of estimating an initial causal graph G_0 = (V, E_0) purely from the observational data {v1, ..., vn} without accessing any other information. Here V is not subscript as it will be kept intact throughout the proposed framework and our focus is on the alteration of the causal relationships in E for accurate causal discovery.\nOur framework is flexible to the choice of SCD algorithms. In this work, we investigate the feasibility of employing three widely used algorithms, each of which is a representative of a category: (1) Constraint-based method \u2013 Peter-Clark (PC) algorithm (Spirtes and Glymour, 1991) which is non-parametric; (2) Score-based method \u2013 Exact Search (ES) algorithm (Yuan and Malone, 2013) which is non-parametric; and (3) Constrained functional causal models \u2013 DirectLiNGAM (Shimizu et al., 2011) which is semi-parametric. We leave the exploration of other SCD algorithms in our future work as it is out of the scope of this work. Inspired by the recent LLM prompting techniques for graphs (Wang et al., 2024), the output edges E0 of the SCD algorithm will be embedded as an adjacency list in the prompt generated by the prompt builder module of the CC-AGENT (\u00a73.3) in Fig. 2, which will also integrate the semantics-rich data modality retrieved by the DA-AGENT (\u00a73.2)."}, {"title": "Data Augmentation Agent (DA-AGENT)", "content": "The goal of DA-AGENT is to retrieve semantics-rich contextual data pertinent to the initial causal graph G0, such as web documents and log files about the variables, as an additional modality for prompting the CC-AGENT (see \u00a73.3). As illustrated in Fig. 2(b), DA-AGENT comprises a Search LLM and a Summary LLM.\nSearch LLM. The Search LLM has access to a set of tools for data search. In this work, we focus on a web search API as a general tool for retrieving contextual data from external sources, and a log lookup API for applications where a domain-specific database is available such as the process"}, {"title": "", "content": "logs in root cause analysis for microservice systems in AIOps (Zheng et al., 2024a). The DA-AGENT is flexible to the toolkit and is extendable for a wide scenarios by including other application-specific tools such as Wikipedia API and code lookup API, which we leave for future exploration.\nAs shown in Fig. 2, upon receiving the meta-data D = {s, Z} about the causal graph, the Search LLM first checks its calling history memory to decide whether to initiate a new tool call. If a new call is needed, the Search LLM invokes a search tool API to retrieve additional data using a prompt that includes the dataset title s and variable names Z1, ..., zn. This search action is then recorded in the memory for future reference. In our case, since the focus is on search tools, the action involves generating a query, and the generated query is added to the memory. In subsequent iterations, all previously recorded queries are examined to prevent redundant queries. This process continues iteratively until the Search LLM determines that no further tool calls are necessary, terminating the loop.\nTo enable this iterative search, the prompt is designed based on self-reflection techniques (Shinn et al., 2024; Madaan et al., 2024), where the LLM assesses whether additional queries are needed based on the comprehensiveness of the historical queries. The loop terminates when the LLM concludes with a \"No query needed\" response. Compared to single-round searches, this iterative process proves crucial for retrieving relevant and comprehensive data, especially in domains where variable-specific information is challenging to locate (e.g., medicine). However, for lookup APIs, iteration is unnecessary. Thus, the retrieved data through these tools constitutes an additional textual modality for the causal graph. The prompt used for the Search LLM is provided in Appendix C.1."}, {"title": "", "content": "Tool Preparation. Fig. 3 illustrates our preparation of the Web Search tool and the Log Lookup tool. In the former, we employ Google search API where the query is generated by the Search LLM as aforementioned. The retrieved top webpages will be de-formatted (e.g., removing HTML tags) by a data formatter and the resultant plain docs will be stored in a memory. Then a Web-Summary LLM is employed to summarize the docs into a concise description. In contrast, the Log Lookup tool uses exact lookup, i.e., with a variable name as the keyword, its corresponding log can be retrieved directly. Thus the memory can be removed and the retrieved log, which still needs de-formatting (e.g., removing log templates) and could be lengthy, will be summarized by a Log-Summary LLM.\nSummary LLM. The data retrieved by the Search LLM is iteratively added to the Retrieved Data Memory, as shown in Fig. 2(b). Upon loop termination, a Summary LLM summarizes the retrieved data into three types of cues: (1) description of the dataset; (2) description of each variable in the graph; and (3) relationships between the variables. Since the size of the retrieved data from iterative searches may exceed the LLM's context window, we adopt an efficient summarization approach using RAG (Lewis et al., 2020). The retrieved data is divided into indexed document chunks, implemented with LlamaIndex (Liu, 2022)"}, {"title": "Causal Constraint Agent (CC-AGENT)", "content": "In addition to the external knowledge, our method leverages the factual knowledge stored in LLMs, acquired during pre-training. To achieve this, CC-AGENT is designed based on the Two-Stage Prompting framework of zero-shot Chain-of-Thought (ZS-COT) (Kojima et al., 2022). First, a prompt builder integrates G0, represented as an adjacency list, with contextual data from DA-AGENT to prompt a Knowledge LLM. The Knowledge LLM is tasked with explaining each (non-)existing causal relationship in the initial causal graph G0 based on the contextual data and its own knowledge. These explanations, which could either support or refute the causal relationships, are used to prompt a Constraint LLM in the second stage to draw a conclusion on the existence of each relationship (i.e., \u201cYes\u201d/\u201cNo\u201d). To address potential uncertainty in the conclusions, we adopt the Top-K-Guess technique (Tian et al., 2023) to elicit verbal confidence. This approach, found to be more reliable than sampling-based likelihood estimation (Xiong et al., 2024), quantitatively evaluates the likelihood of each causal relationship. Among the Top-K guesses, the most confident one is selected as the final conclusion for each causal relationship."}, {"title": "Causal Graph Refiner", "content": "To ensure the final causal graph G is acyclic, the edge set E0 is not directly modified based on the (non-)existence constraints from CC-AGENT. Instead, the SCD algorithm used in the Causal Graph Estimator (\u00a73.1) is rerun with these constraints imposed to generate a new causal graph G. Specifically, upon receiving the (non-)existence constraints, a constraint matrix C \u2208 \\mathbb{R}^{n \\times n} is constructed, where Cij = 1 if CC-AGENT indicates a causal effect from vi to vj, and Cij = 0 otherwise. The most representative SCD algorithms, including PC, ES, and DirectLiNGAM, are designed to"}, {"title": "", "content": "incorporate such a constraint matrix C as input alongside observational data {V1, ..., vn}. This ensures that the generated causal graph complies with the constraints in C to varying extents, enabling the production of a refined causal graph G that is both consistent with the imposed constraints and a directed acyclic graph (DAG).\nRemark. Compared to the existing approaches that utilize LLMs for causal discovery (Takayama et al., 2024; Khatibi et al., 2024), the key novelty of the proposed MATMCD lies in its exploration of DA-AGENT for multi-modal enhancement of causal discovery. An algorithmic summary of the proposed workflow is provided in Appendix A."}, {"title": "Experiments", "content": "In this section, we first compare MATMCD with SOTA methods on benchmark datasets. Then we evaluate MATMCD for a root cause analysis task on real-life enterprise microservice system datasets."}, {"title": "Experimental Setup", "content": "Benchmark Datasets. To be comprehensive, we use 5 benchmark datasets covering both continuous variables and discrete variables. For the former, following (Takayama et al., 2024; Le et al., 2024), we adopt (1) AutoMPG (Quinlan, 1993), which has five variables concerning city-cycle fuel consumption in miles per gallon, each variable has a length-392 time series; (2) DWDClimate (Mooij et al., 2016), which has six variables pertinent to observations from weather stations in Deutscher Wetterdienst, each variable has a length-350 time series; and (3) SachsProtein (Sachs et al., 2005), which has eleven variables measuring the expression level of different proteins and phospholipids in human cells, each variable has a length-7,466 time series. For the latter, following (Long et al., 2023; Jiralerspong et al., 2024), we adopt (4) Asia (Lauritzen and Spiegelhalter, 1988), which has eight variables relevant to lung disease diagnosis, each variable has 1,000 discrete samples; and (5) Child (Spiegelhalter, 1992), which has twenty variables regarding congenital heart disease in newborn babies, each variable has 1,000 discrete samples.\nIn AutoMPG, DWDClimate, and SachsProtein, ground truth causal graphs constructed by experts are available for evaluation purpose. For Asia and Child, since the observational data of the variables are sampled from a Bayesian network, the prior conditional probabilities among the variables estab"}, {"title": "", "content": "lish the ground truth causal graphs.\nBaselines. We compare MATMCD with the most relevant SOTA methods on causal discovery, including (1) statistical causal discovery: Peter-Clark (PC) algorithm (Spirtes and Glymour, 1991), Exact Search (ES) algorithm (Yuan and Malone, 2013), and DirectLiNGAM (Shimizu et al., 2011); (2) LLM-based causal discovery that only uses LLMs to infer causal relationships: Efficient-CDLMs (Jiralerspong et al., 2024), which employs a BFS-based LLM prompting for efficient causal graph construction, and MAC (Le et al., 2024), which uses Debating LLMs for building a multi-agent system; and (3) Hybrid approaches that refine an SCD causal graph by LLMs: SCD-LLM, which uses a single LLM upon the SCD output, ReAct (Yao et al., 2022), which interleaves reasoning and search tool usage when refining SCD graphs, LLM-KBCI (Takayama et al., 2024), which uses ZSCOT two-stage prompting for refining causal graphs. Moreover, we apply ReAct framework for LLM"}, {"title": "", "content": "KBCI to enable alternate reasoning and tool usage and name this baseline as LLM-KBCI-RA. We also introduce Top-K Guess reasoning (Tian et al., 2023) (with K=2) for verbal calibration on LLM-KBCI and name this variant as LLM-KBCI-RE.\nFor our method, we consider two major variants. The first asks for a single answer from the CC-AGENT (\u00a73.3), i.e., K=1 in the Top-K Guess reasoning, named as MATMCD. The second uses K=2 in the Top-K Guess reasoning, which we name as MATMCD-RE. Additionally, we perform extensive ablation analysis on other variants of MATMCD in Table 3 to evaluate its design choices.\nImplementation. By default, we use GPT-40 mini with temperature 0.5 as the base LLM for all LLM-based and Hybrid methods, as it was found very performant by the existing works (Le et al., 2024). For all Hybrid approaches, PC is used as the base SCD algorithm. Also, we evaluate our MATMCD by switching the LLM with GPT-4, Llama-3.1-8B, Llama-3.1-70B, Mistral-7B and Gemma2-9B,"}, {"title": "", "content": "and switching the SCD algorithm with ES and DirectLiNGAM in our ablation analysis. All SCD algorithms were implemented with causal-learn (Zheng et al., 2024b). ReAct and RAG frameworks were implemented with LlamaIndex (Liu, 2022). For all baselines, we used their official code when available. Since MAC's code is unavailable, we report its results from the original paper, which are only available on AutoMPG, DWDClimate, and SachsProtein datasets.\nEvaluation Metrics. Following (K\u0131c\u0131man et al., 2023; Takayama et al., 2024; Khatibi et al., 2024; Le et al., 2024), we employ the widely used metrics including precision (Prc), F1-score (F1), FPR, structural Hamming distance (SHD), and normalized Hamming distance (NHD) for gauging the difference between the predicted causal graphs and the ground truth graphs. Prc and F1 measure the accuracy, thus a larger value is better. FPR, SHD, and NHD measure the errors/differences, hence a smaller value is better."}, {"title": "Experimental Results", "content": "Causal Discovery. Table 1 and 2 summarize the results on the benchmark datasets. From the tables, we have several observations: (1) Methods involving LLMs generally outperform SCD algorithms in most cases except for SachsProtein and Asia datasets which pertain to biomedicine. It demonstrates the great potential of LLMs' commonsense knowledge acquired by pre-training for the task of causal discovery, but meanwhile draws to our attention on their short of domain-specific knowledge. (2) Hybrid approaches outperform LLM-based baselines in most cases, indicating using SCD outputs as a prior for LLMs to reference has the benefits of complementing their causal effects related knowledge. (3) Baseline methods that can leverage tools for retrieving external data, i.e., Re"}, {"title": "", "content": "Act and LLM-KBCI-RA, sometimes outperform their counterparts, suggesting the potential of the augmented data modality, but calling for a better way of retrieving and using such data. (4) The proposed MATMCD(-RE) achieved the best overall performance considering no baseline methods consistently performs well across all datasets. In particular, MATMCD(-RE) helps alleviate the hallucination problem of other LLM baselines on the biomedical SachsProtein and Asia datasets via data augmentation. The results highlight the challenge of the existing LLM baselines in inferring causal effects solely by meta-data (i.e., node names, data titles) and validate the effectiveness of the proposed design of a multi-agent system for exploring multi-modality enhanced causal discovery. Finally, (5) MATMCD-RE outperform MATMCD on the Bayesian datasets Asia and Child, which could be a result of the better calibrated likelihoods by Top-K Guess reasoning for the probabilistic datasets.\nAblation Study. Table 3 presents our ablation analysis using three datasets. In the table, MATMCD is our original model. In (a), we aim to study the usefulness of the iterative search in DA-AGENT. To this end, we replaced the iterative search with a single-round search template (Appendix C.3). In (b), we evaluate how MATMCD could generalize to different SCD algorithms by switching PC with ES and DirectLiNGAM. In (c), we assess the impact of different LLMs on causal discovery.\nFrom Table 3(a), we observe iterative search is better than single-round search, as the latter may use biased query and have difficulty in producing comprehensive augmented data. In Appendix D.1, we summarized some queries iteratively generated by DA-AGENT. In Table 3(b), using other SCD algorithms than PC generally degrades the performance, possibly because the constraint-based design of PC leads to better use constraints produced"}, {"title": "", "content": "by LLMs. We also observe that, with MATMCD, the performance of ES and DirectLiNGAM were slightly enhanced compared to the counterparts without MATMCD in Table 1. Intriguingly, Table 3(c) shows the default GPT-40 mini is the most robust across the different datasets, and GPT4 is better than the open source LLMs. This is similar to the findings in (Le et al., 2024), where MAC with GPT-40 mini performed the best. Compared to PC in Table 1, all LLM variants in Table 3(c) improve performance, suggesting the effectiveness in leveraging the LLMs. Moreover, on the biological dataset SachsProtein, a larger model GPT4 further boost the causal discovery performance, likely due to its better alignment with the specific domain."}, {"title": "Case Study: Root Cause Analysis (RCA)", "content": "Next, we evaluate MATMCD on AIOps datasets collected from Product Review (PR) and Cloud Computing (CC) microservice systems (Zheng et al., 2024a). The PR dataset has 216 variables (i.e., system pods), each associated with a multivariate time series containing 6 metrics (e.g., CPU, memory usage) of length 131,329. The CC dataset has 168 variables, each with a multivariate time series of 7 metrics and a length of 109,351. In both datasets, each variable also has a log recording its historical events. Fig. 4(a) illustrates a log snippet. Through the log lookup tool (\u00a73.2), these logs can be leveraged as an additional data modality by MATMCD for enhanced causal discovery. Fig. 4(b) demonstrates that the Summary LLM of DA-AGENT can effectively interpret and summarize the log data. Since these datasets provide root causes of system failures identified by domain experts, but lack ground truth causal graphs, we use them to evaluate the root cause analysis (RCA) performance based on the causal graphs produced by different meth"}, {"title": "", "content": "ods. Following (Wang et al., 2023b), if running a random walk with restart (RWR) on a causal graph can top-rank the root cause among all variables, it reflects the quality of the causal graph. Therefore, we use widely adopted metrics, including Mean Average Precision@K(MAP@K), with K set to 5 and 10, and Mean Reciprocal Rank (MRR), to assess the overall ranking performance on both datasets (Zheng et al., 2024a). More details on MAP@K and MRR can be found in Appendix B.2.\nFollowing (Wang et al., 2023b), we preprocessed the datasets by filtering out irrelevant pods using an Extreme Value Theory-based approach (Siffer et al., 2017) before applying causal discovery methods. Table 4 summarizes the results, where we also report the specific ranking (\u201cRK\u201d) of the ground truth root causes for each dataset. In Table 4, ES and DirectLiNGAM are excluded as the focus is how different LLM-based methods can improve their base SCD algorithm, i.e., PC, for the downstream task. From Table 4, by leveraging the log modality, MATMCD(-RE) significantly improves the accuracy of root cause locating on both datasets, with an 83.3% relative improvement over the best baseline on MAP@10. This highlights the potential of integrating prevalent log data in microservice systems for RCA and AIOps.\nMore visualization results are deferred to \u00a7B.3."}, {"title": "Conclusion", "content": "In this paper, we explored multi-modality data in causal discovery via devising MATMCD with tool-augmented LLMs, whose mechanism was carefully designed for integrating text data with graphs. The experiments not only validate the effectiveness of our innovative method but also set a new standard for delving into multi-modal causal discovery."}, {"title": "Limitations", "content": "The research of LLM based causal discovery is an emergent area undergoing active explorations. This work pioneers the use of tool-augmented LLM agents, but the proposed method shares similar limitations of most of the existing approaches.\nFirst, the examination of the causal relationships in a causal graph is pair-based, i.e., each causal relationship (vi, vj) for 1 < i < j < n needs to be prompted to an LLM (in our case, CC-AGENT) for assessing its correctness. This may lead to scalability issues on large graphs. This is also reflected in the sizes of the benchmark datasets widely used in this area. A promising way to improve the scalability of such edge-based QA paradigm is to leverage the DAG structure of causal graphs and use breadth first search (BFS) style prompts as introduced in (Jiralerspong et al., 2024). The proposed MATMCD is completely compatible with this prompting technique, thus has the potential to achieve an O(n) complexity. Second, similar to other hybrid approaches that combine SCD algorithm and LLM agents, the proposed MATMCD necessitates a base SCD algorithm that can effectively incorporates the constraints produced by LLMs. We observed this from the better results of using PC compared to using either ES or DirectLiNGAM in Table 3. This is worth further study with a comprehensive comparison of using more constraint-based SCD algorithms and non-constraint-based variants. Third, as a knowledge-driven method, meta-data with semantically meaningful variables is needed for retrieving useful knowledge about causal relationships. For domains where variables are semantically meaningless or meta-data are private, such methods may have limited impact.\nIn addition to the aforementioned common limitations, this work has several specific limitations. First, this work uses web data and logs as the augmented data modality of focus, more modalities such as codes, images and audio signals in certain domains remain further study. Second, tools aside from the web search APIs and log lookup APIs in the proposed DA-AGENT, such as Wikipedia APIs and code lookup APIs, worth exploration. The toolkit in the DA-AGENT has the flexibility and expandability to support the further research."}, {"title": "Algorithm", "content": "The algorithm of MATMCD is summarized in Algorithm 1. The notations are consistent with \u00a73.\nAlgorithm 1: Multi-Agent with Tool-Augmented LLMs for Multi-Modality Enhanced Causal Discovery (MATMCD)\nInput: (1) Observational Data: {v1", "LLM.\nOutput": "Refined causal graph G\n/* Causal graph estimator (\u00a73.1) */\n1 Initial Causal Graph G0 \u2190 CaussalGraphEstimator(fSCD,{V1, ..., Vn})\n/* DA-agent (\u00a73.2) */\n2 Initialize call history memory C \u2190 \u00d8\n3 Initialize retrieved data memory R"}]}