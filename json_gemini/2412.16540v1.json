{"title": "Prior2Posterior: Model Prior Correction for Long-Tailed Learning", "authors": ["S Divakar Bhat", "Amit More", "Mudit Soni", "Surbhi Agrawal"], "abstract": "Learning-based solutions for long-tailed recognition face difficulties in generalizing on balanced test datasets. Due to imbalanced data prior, the learned a posteriori distribution is biased toward the most frequent (head) classes, leading to an inferior performance on the least frequent (tail) classes. In general, the performance can be improved by removing such a bias by eliminating the effect of im- balanced prior modeled using the number of class samples (frequencies). We first observe that the effective prior on the classes, learned by the model at the end of the train- ing, can differ from the empirical prior obtained using class frequencies. Thus, we propose a novel approach to accu- rately model the effective prior of a trained model using a posteriori probabilities. We propose to correct the imbal- anced prior by adjusting the predicted a posteriori proba- bilities (Prior2Posterior: P2P) using the calculated prior in a post-hoc manner after the training, and show that it can result in improved model performance. We present the- oretical analysis showing the optimality of our approach for models trained with naive cross-entropy loss as well as logit adjusted loss. Our experiments show that the proposed approach achieves new state-of-the-art (SOTA) on several benchmark datasets from the long-tail literature in the cat- egory of logit adjustment methods. Further, the proposed approach can be used to inspect any existing method to cap- ture the effective prior and remove any residual bias to im- prove its performance, post-hoc, without model retraining. We also show that by using the proposed post-hoc approach, the performance of many existing methods can be improved further.", "sections": [{"title": "1. Introduction", "content": "One of the primary difficulties in the case of long-tailed recognition is a distribution mismatch between training and test datasets. The training dataset is usually dominated by a large number of examples from a few classes called majority or head classes. As a result, a naive deep neu- ral network model trained on such a dataset using simple cross-entropy loss is biased toward the dominant classes. This bias manifests in the form of higher accuracy on head classes and poor accuracy on tail classes, i.e. accuracy is directly proportional to the number of training examples for a given class. One of the early solutions proposed to miti- gate the effects of such a data imbalance appears in [14,22]. Generally, the model bias can be removed by artificial re- balancing of the datasets and scaling of loss functions or"}, {"title": "2. Related Work", "content": "Data re-balancing: Early studies on the effect of data imbalance on a learned model can be found in [14,22]. Gen- erally, the dataset is artificially balanced by either oversam- pling rare classes [3] or under-sampling head classes [21]. To mitigate limitations of these methods generative ap- proaches are used to generate samples in feature [15] and"}, {"title": "3. Preliminaries", "content": "3.1. Problem Formulation\nConsider a C class classification problem where the ob- jective is to learn a mapping from data instances X = {X1, X2, ..., XN} to the corresponding ground-truth labels, Y = {Y1, Y2,...,YN} where N denotes total number of samples. Further, let ni denote the number of samples for ith class, such that ni \u2260 nj. Let P(y|x) represent probabil- ity of a predicted class conditioned on a given data sample x. Further, let P(y) represent the prior probability distribu- tion for labels over given dataset. Usually, we train a model to predict an unnormalized class probability scores, logits denoted by z, using a deep neural network represented by f(x) and the probabilities P(y|x) are calculated by normal- izing the logits using a softmax function.\nIn case of a long-tailed recognition, the training set is im- balanced, however, the goal is to maximize the recognition performance over a balanced test set. We denote predicted conditional and marginal class probabilities over given bal- anced test set by Pt (y|x) and Pt(y), respectively. Thus"}, {"title": "3.2. Logit Adjustment", "content": "From Bayes' theorem we have,\n$P(y | x) = \\frac{P(x | y)P(y)}{P(x)}$\n(1)\n$P_t(y | x) = \\frac{P_t(x | y)P_t(y)}{P_t(x)}$\n(2)\nIn general, the training and the test dataset distributions dif- fer only in the number of samples available per class and it is safe to assume that the generative distributions are the same, i.e. P(x|y) = Pt(x|y). Thus, simplifying the Eq. 1 and Eq. 2 gives\n$P_t(y | x) = P(y | x) \\frac{\\frac{P_t(y)}{P_t(x)}}{\\frac{P(y)}{P(x)}}$\n(3)\nThe conditional distribution on the train data can be ad- justed as shown above to get the desired distribution on the test dataset. In practice, the scaling by $\\frac{P_t(x)}{P(x)}$ is inconse- quential as it can be absorbed into the normalization pro- cess. The term $\\frac{P_t (y)}{P(y)}$ represents the actual correction factor to mitigate the model bias. Above equation suggests that ap- propriate posterior distribution on the balanced test set can be estimated by simply adjusting the predicted logit scores as,\n$z_t = z - logP(y) + logP_t(y)$.\n(4)\nThis simple but very powerful idea underlies behind all logit adjustment approaches. However, it requires that train- ing time data distribution be known, a priori. Usually marginal distribution P(y) is approximated using class fre- quencies [23, 29]. [23] proposed to use instead a tuned ver- sion of class frequencies leading to\n$z = z_i - \\alpha log \\frac{N_i}{\\sum_k N_k} + logP_t(y_i)$\n(5)\nwhere, \u03b1 is tuned with the help of holdout validation set. From similar inspirations, [23, 29] have also employed a modified loss function as part of a decoupled training pro- cess in an effort to directly model Pt (y|x). This modified softmax cross entropy loss can be written as,\n$\\mathcal{L}(f(x), y) = -log \\frac{e^{z_i + \\alpha log P(y_i)}}{\\sum_k e^{z_k + \\alpha log P(y_k)}}$\n(6)"}, {"title": "4. Proposed Approach", "content": "Ideally when P(y|x) is modeled correctly, the adjust- ment shown in Eq. 3 is optimal in the sense that it has the desired effective prior Pt(y). However, in practice, P(y|x) is modeled by a DNN which generally tend to overfit on the head classes and underfit on the tail classes when training dataset is imbalanced. We represent the learned a poste- riori distribution by a model as Pm(y|x) which approxi- mates the training distribution P(y|x). We can generalize the idea of logit adjustment and denote the adjusted version of Pm (yx) by Pa(y|x) and formally define what consti- tutes an optimal adjustment based on Eq. 3.\nDefinition:\nThe adjusted distribution Pa(yx) is optimal for the test dataset with marginal distributions Pt(x) and Pt(y) if it satisfies following property\n$P_t(y) = \\int P_a(y|x) P_t(x) dx = P_a(y)$\n(7)\nIt is easy to see that in an ideal case when Pm(y|x) = P(yx), the adjusted distribution given by Eq. 3 is an opti- mal adjustment."}, {"title": "4.1. Post-hoc correction with learned prior", "content": "We now show the optimal adjustment for Pm (y|x) when model is trained with plain cross-entropy loss.\nTheorem 1.\nLet Pm (yx) be the posterior distribution learned by the model, then the optimal adjustment to match the test dis- tribution prior is given by,\n$P_a(y|x) = P_m(y|x) \\frac{\\frac{P_t(y)}{P_t(x)}}{\\frac{P_m(y)}{P(x)}}$\n(8)\nwhere,\n$P_m(y) = \\int P_m(y|x) P(x) dx$\n(9)\nPm(y) is the effective prior on the training dataset learned by the model.\nProof. The effective prior of the adjusted probabilities on the test distribution is given by,\n$P_a(y) = \\int P_a(y|x) P_t(x) dx$\n(10)\n$= \\int P_m(y|x) \\frac{\\frac{P_t(y)}{P_t(x)}}{\\frac{P_m(y)}{P(x)}} P_t(x) dx$\n(11)\n$=\\frac{P_t(y)}{P_m(y)} \\int P_m(y|x) P(x) dx$\n(12)\n$= P_t(y)$\n(13)\nThus the adjusted distribution Pa(y|x) represents the same prior as required by the test dataset. It should be noted that, under ideal conditions when Pm(y|x) = P(y|x), Eq. 8 reduces to the class frequency based adjustment."}, {"title": "4.2. Logit adjusted Training", "content": "One possible way to mitigate the bias of the model is to correct the probabilities during training time itself and get an unbiased estimator. Rearranging the Eq. 3 gives us,\n$P(y|x) = P_t(y|x) \\frac{\\frac{P(y)}{P(x)}}{\\frac{P_t(y)}{P_t(x)}}$\n(14)\nWe employ a two stage decoupled training for this approach with stage 1 being a simple softmax cross entropy train- ing. For stage 2 we use loss function shown in Eq. 6. In this framework, Pt (y|x) is modeled by a DNN and the pre- diction probabilities are adjusted during training to match P(yx). During inference time, the DNN output is directly used to model Pt (y|x) without any adjustment. As model probabilities are already adjusted during training, when the logit adjustment is removed during inference time, ideally"}, {"title": "4.3. Estimating the effective model prior", "content": "So far we have shown that it is possible to adjust the probabilities of the plain cross-entropy trained model as well as training time logit adjusted model to mitigate the model bias. Theorem 1 and 2 show the corresponding op- timal adjustment such that effective prior of the adjusted model on the test data is Pt(y). However, the adjustment depends on Pm(y) and Pm(y) and we need to estimate these terms accurately. We estimate Pm (y) by numerically approximating the integral over the training dataset as,\n$P_m(y) \\approx \\frac{1}{\\sum_k n_k} \\sum_{x \\in P(x)} P_m(y | x)$\n(27)\nSimilarly, we estimate Pm (y) using samples from Pt (x) as shown below.\n$P_m(y) \\approx \\frac{1}{\\sum_{x \\in P_t(x)}} \\sum_{x \\in P_t(x)} P_m(y | x)$\n(28)\nWe use hold-out validation dataset to represent Pt(x). One may note that, in general a large amount of data is needed to have an accurate estimates of Eq. 27 & 28. Although, the train dataset size is large enough, valida- tion datasets are limited in size and hence the estimates of Pm (y) are relatively inaccurate. However, we can leverage the training dataset and improve the estimate of Pm (y). In particular, combining Eq. 21 & 27 we have,\n$P_m(y) \\approx \\frac{1}{\\sum_k n_k} \\frac{P_t(y)}{P(y)} \\sum_{x \\in P(x)} P_m(y | x)$\n(29)\nThus Pm (y) can be estimated more reliably using training data itself. In practice, we take both estimates of Pm (y) and average the result which improves the performance fur- ther as shown in the ablation experiments. Further, simi- lar to [23] we tune a scalar hyper-parameter a and use the scaled estimates. As the terms Pm(y) and Pm(y) repre- sent the effective priors of the trained model and it is used in the adjustment of the respective posterior distributions Pm (y|x) and Pm (y|x), we term the proposed post-hoc ad- justment as Prior to Posterior: P2P."}, {"title": "5. Experiments", "content": "5.1. Experimental setup\nDatasets: We evaluate our proposed approach on long- tailed recognition datasets with different imbalance factors. Imbalance factor for a dataset is defined as a ratio between"}, {"title": "6. Results", "content": "6.1. Results on a toy dataset\nWe first present the results on a small toy dataset. For this, we consider a binary classification problem with an Isotropic Gaussian distribution. We use 10000 samples with imbalance of 100 for training. We repeat the experiment 100 times and report the average results. We train single layer linear model with naive cross-entropy (CE) loss, class frequency based logit adjustment loss and proposed P2P with a learned prior on the CE trained model. We show clas- sification boundaries for different approaches in Figure 1. We also show the theoretically optimal Bayes classifier in the figures for reference. One may note that the classifier boundaries for P2P, which uses learned prior to re-adjust the boundary is very close to the optimal Bayes classifier.\n6.2. Result on large scale datasets\nWe now compare the effectiveness of proposed approach in comparison to other methods from the literature on CIFAR100/10-LT datasets in Table 1. We show results for imbalance factors of 200, 100 and 10. We apply post-hoc adjustment on baseline Stage 1 model trained with naive cross entropy loss using proposed P2P approach and class frequency based approach for comparison.\nFrom the table, we note that proposed post-hoc adjust- ment is more effective and outperforms class frequency based adjustment for all datasets. One may see from the table that proposed post-hoc adjustment on naive cross en- tropy loss achieves superior performance and outperforms most of the approaches in the literature. The performance is further improved for Stage 2 methods with P2P adjust- ment and best performance is achieved when whole model is trained with logit adjusted loss and combined with post- hoc method (results shown in the last row of the table).\nWe note that using post-hoc adjustment with class fre- quency bias for Stage 2 models is sub-optimal as most of the data imbalance is removed due to logit adjusted loss. However, using proposed approach the residual bias can be calculated and removed. We show the results on ImageNet- LT in Figure 3a. From the figure one may note that the model performance degrades when using class frequencies"}, {"title": "6.3. P2P on pre-trained models", "content": "One can easily calculate the learned a posteriori distri- bution for many existing pre-trained model and remove the residual bias using P2P. Although we explicitly proved that proposed P2P adjustment is optimal for plain CE loss and logit adjusted loss, in principle, this approach can be applied to any method in general. In Table 3 we test this idea on several SOTA methods, including contrastive learning [48], label-noise [46], model ensembles [42] and few other meth- ods. From the table we see that proposed learned prior con- sistently improves the accuracy. The overall improvement can be as high as 1.48 and 1.67 for ImageNet-LT and iNat- uralist18 datasets, respectively. These results show that the proposed P2P can be easily integrated with any existing ap- proach to boost the performance."}, {"title": "6.4. Evaluation on different imbalances", "content": "In practice, the test dataset can also be imbalanced and moreover, the imbalance of the test dataset can be opposite to that of the train dataset. Thus we validate the effective- ness of P2P by simulating different imbalances on the test dataset on ImageNet-LT dataset. As shown in Table 8, pro- posed approach consistently performs better in comparison to other methods showing the effectiveness of P2P for dif- ferent test time distributions."}, {"title": "6.5. Ablation study", "content": "Estimating Pm (\u0443)\nWe validate the reliability of estimates Pm (y) using Eq. 28 & 29 for Stage 2 experiments (CL and FT) on ImageNet- LT and iNaturalist18 datasets. As shown in Table. 5, the performance improves when P2P is used with either of the estimates for Pm (y) and the overall best is achieved when both estimates are combined which shows that using more samples improves the accuracy of the estimates.\nIs model bias deeply rooted?\nIt is generally argued that the features learned in Stage 1 are sufficient and only classifier boundary adjustment is needed in Stage 2 to remove the bias. We check this hypothesis on CIFAR10-LT dataset with imbalance factor of 200. In Stage 2, we train different layers in the model with logit adjusted loss. We train the ResNet-32 model with 1, 11, 21 and 33 (all) layers, respectively. Figure 3b show that the performance steadily improves when more layers are trained. In our opinion, although Stage 1 with instance bal- anced sampling generates good quality features, they are tightly clustered for tail classes which might affect their quality [18,48]. In Stage 2, when classifier boundaries are readjusted, the model can improve upon previous features. As a result, feature tuning with post-hoc correction achieves the best performance in all our experiments."}, {"title": "7. Conclusions", "content": "We proposed a simple yet effective approach to accu- rately represent the effective prior of a trained model and use it to mitigate the model bias for long-tailed recognition. We present theoretical analysis and prove that proposed ap- proach is optimal for plain cross-entropy loss training and logit adjusted training. We show that proposed post-hoc adjustment achieves improved performance and can rival many SOTA methods when combined with classifier or fea- ture retraining. Our results show that the proposed approach can be used to mitigate residual bias from existing methods and boost the performance without any need for retraining."}, {"title": "8. Additional training details", "content": "We train Stage 1 models using cross-entropy loss for CIFAR10-LT and CIFAR100-LT datasets for 20,000 itera- tions. In Stage 2, for both classifier and feature tuning cases, we train the models for 4000 iterations. For ImageNet-LT dataset, we train the Stage 1 and both the Stage 2 meth- ods for 200 and 20 epochs, respectively. For iNaturalist18 dataset, we train the Stage 1 and both Stage 2 models for 200 and 10 epochs, respectively. For all models the batch size of 64 is used. Rest of the experimental settings are bor- rowed from [29]."}, {"title": "9. Dissimilarity of data distributions: P(X) \u2260 Pt(X)", "content": "In the paper we clearly maintain the distributions P(X) and Pt(X) as distinct in nature. For the sake of complete- ness we provide a mathematical justification using the ap- proach of moment matching. In particular, we show that the first moment of train and test data distribution is not the same.\n$\u03bc_\u03b1 = \\int \\int xP(x,y)dxdy$\n(30)\n$= \\int(\\int xP(x|y)dx) P(y)dy$\n(31)\n$= \\int \u03bc_{xy} P(y)dy$\n(32)\n$ \u03bc_\u03b1 \\neq \u03bc^t_\u03b1$\n(37)\nAnd hence,\n$ P(X) \\neq P_t(X)$\n(38)"}, {"title": "10. The effective prior for ImageNet-LT and iNaturalist18 datasets", "content": "In Figure 4 we show the model bias estimated using class frequencies and the effective prior calculated using pro- posed approach on ImageNet-LT and iNaturalist18 datasets. From the figure it is clearly observed that model bias is quite different from empirical bias estimated using class frequen- cies. In particular, the effective prior is higher for low fre- quency classes than the class frequency based prior for both datasets."}, {"title": "11. Multishot accuracies", "content": "In Table 6 and Table 7 we show multi-shot accuracies for ImageNet-LT and iNaturalist18 datasets and compare it with some of the recently published methods. We note from the table that proposed approach achieves highest overall accuracy while shot-wise accuracies are not affected much. We also show in Figure 5 the performance on iNaturalist18 for models trained with plain CE and with logit-adjustment (CL and FT). It can be noted that, P2P outperforms baseline class frequency based adjustment in all the cases."}, {"title": "12. Additional results on test time shifted imbalance", "content": "In Table. 8 we compare model performance for test-time shifted distributions with additional baselines and a few more distribution shifts. We note the superior performance of proposed algorithm."}, {"title": "13. Discussion on Distribution Matching", "content": "Recent works like [27] have proposed to tackle this dis- tribution misalignment problem from an optimisation per-"}, {"title": "14. Flow of the proposed approach", "content": "We summarise the proposed approach in a block dia- gram as shown in Figure6. The block diagram illustrates the different stages involved in the process starting from bias accumulation in traditional training to bias removal us- ing the proposed method. Both Logit adjusted training and Prior2Posterior is depicted along with an illustration show- ing the Effective Prior computation."}]}