{"title": "Diffusion Models for conditional MRI generation", "authors": ["Miguel Herencia Garc\u00eda del Castillo", "Ricardo Moya Garcia", "Manuel Jes\u00fas Cerezo Maz\u00f3n", "Ekaitz Arriola Garcia", "Pablo Men\u00e9ndez Fern\u00e1ndez-Miranda"], "abstract": "In this article, we present a Latent Diffusion Model (LDM) for the generation of brain Magnetic Resonance Imaging (MRI), conditioning its generation based on pathology (Healthy, Glioblastoma, Sclerosis, Dementia) and acquisition modality (T1w, T1ce, T2w, Flair, PD).\nTo evaluate the quality of the generated images, the Fr\u00e9chet Inception Distance (FID) and Multi-Scale Structural Similarity Index (MS-SSIM) metrics were employed. The results indicate that the model generates images with a distribution similar to real ones, maintaining a balance between visual fidelity and diversity. Additionally, the model demonstrates extrapolation capability, enabling the generation of configurations that were not present in the training data.\nThe results validate the potential of the model to increase in the number of samples in clinical datasets, balancing underrepresented classes, and evaluating AI models in medicine, contributing to the development of diagnostic tools in radiology without compromising patient privacy.", "sections": [{"title": "1. Introduction", "content": "Artificial intelligence (AI) has transformed medical image analysis, enabling the automation of diagnostic and segmentation tasks with unprecedented accuracy [1, 9]. However, the development of AI models in this field faces significant challenges due to the scarcity of clinical data, strict privacy regulations, and the high costs associated with annotation and labeling [26, 23, 15]. The collection of large volumes of medical data is a complex and costly process, constrained by the difficulty of accessing representative images of various pathologies and MRI modalities. Additionally, regulations such as the General Data"}, {"title": "2. Solution", "content": "The generation of medical images using artificial intelligence has evolved significantly, giving rise to multiple approaches that have demonstrated their effectiveness in this field. Among the most commonly used models are: Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs) [12], Flow-Based Models [3], and Diffusion Models (DMs), each with specific characteristics that make them suitable for different applications.\nA particularly efficient approach is the Latent Diffusion Model (LDM), which optimizes image generation by performing diffusion in a compressed latent space. This approach reduces computational load without sacrificing visual quality, making it an ideal option for the synthesis of medical images conditioned by pathology and modality."}, {"title": "3. Proposed Solution", "content": "The model proposed in this work is a Latent Diffusion Model (LDM) designed to generate conditioned magnetic resonance imaging (MRI). As analyzed in the experiments and"}, {"title": "3.1 Datasets", "content": "To evaluate the performance of the conditioned medical image generator model, various brain MRI datasets were employed, representing different pathologies and acquisition modalities. The selection of these datasets aimed to ensure a robust evaluation of the model under multiple clinical conditions. The data used come from four main sources:\nIXI and OASIS (for healthy subjects and dementia), BRATS2021 (glioblastoma), and ISBI 2015 Challenge along with open_ms_data (multiple sclerosis). Table 1 summarizes the characteristics of each dataset, including the represented pathology and available modalities."}, {"title": "4. Proposed solution", "content": "The model proposed in this work is a Latent Diffusion Model (LDM) designed to generate conditioned magnetic resonance imaging (MRI). As analyzed in the experiments and results section, image generation is performed through a conditioning scheme, allowing specification of both pathology (Healthy, Glioblastoma, Sclerosis, Dementia) and MRI modality (T1w, T1ce, T2w, Flair, PD) [14].\nThis approach enables the generation of medical images with precise control over their characteristics, facilitating the creation of synthetic MRI scans in specific configurations. For example, the model can generate an image of a healthy brain in T1w modality or an MRI of a brain with multiple sclerosis in FLAIR modality, ensuring that the anatomical structure and appearance are consistent with the defined parameters.\nSince the model's implementation is part of a company's intellectual property, internal details about its operation and specific training process will not be disclosed. However, a general description of its architecture and workflow is provided, explaining the key components in the training and inference stages.\nThe proposed model is based on a latent diffusion architecture, where image generation occurs in a compressed latent space instead of operating directly on the original image. This allows for efficient reconstruction with lower computational cost.\nThe system consists of three main modules:\n\u2022 Encoder: Converts MRI images into a compact latent representation, reducing dimensionality and facilitating model processing. The encoder maps an input image x to a latent space z, parameterized by a mean \u03bc(x) and a variance \u03c3\u00b2(x):\nq(z|x) = N(z; \\mu(x), \\sigma\u00b2(x)) (3)\n\u2022 U-Net network with DDPM: During the training process of a diffusion model, we start with a clean latent representation zo. Gaussian noise is progressively added following a predefined schedule to generate a noisy latent z\u0142 at each timestep t:\n2t = \u221a\u0101t 20 + \u221a1 \u2013 \u0101\u1e6d \u2208,\nwhere \u2208 ~ N(0, I) is Gaussian noise and \u0101t is the cumulative product of the noise schedule coefficients. The conditional U-Net receives the noisy latent zt, the timestep t, and additional conditioning information (such as pathology or modality) to predict the noise that was added, denoted as e\u0473(zt,t). The training objective is to minimize error between the true noise e and the U-Net's prediction:\nL = Ezo,\u2208,t [||\u2208 \u2013 \u2208 (zt, t)||2] .\nBy optimizing this loss, the U-Net learns to accurately predict the noise residual. [10]\n\u2022 Decoder: Reconstructs the final synthetic image from the refined latent space, generating an MRI with the specified characteristics. The decoder maps the latent vector z back to the image space \u00ee through a learned transformation p(x|z):\nx = go(z) (4)\nwhere ge is the decoder function parameterized by a neural network.\nThe use of compressed latent spaces improves computational efficiency without compromising the visual quality of the generated images.The model is trained using a diffusion scheme in the latent space, allowing the neural network to learn how to reconstruct synthetic images from a degraded representation.\nThis scheme, shown in Figure 1, allows the model to learn anatomical patterns from the training data, ensuring that the generated images are realistic and representative of various clinical configurations.\n\u2022 Inference with DDIM: Once trained, the model can generate new synthetic images without requiring a real input image. During inference, a simplified process is followed compared to training:\n1. Random latent space initialization: A random starting point is generated in the latent space.\n2. Conditioning: The corresponding embedding for the desired pathology and modality is introduced.\n3. DDIM Sampling: The deterministic DDIM (Denoising Diffusion Implicit Model) method is applied, refining the noise latent space by iteratively predicting and removing noise:\n\u221a1\n21-1 = \u221a\u03b1\u03b9-1 (4-1-\u03b1\u03bc\u03b5\u03c1(\u03b9,t)) + \u03c3\u03b5\u2208 (5)\nat-1\nVat\nwhere zt is the latent variable at time step t, at controls the noise schedule, and ot is the noise scaling factor. [21]\n4. Reconstruction with the decoder: The refined latent representation is converted into a final image in the original MRI domain.\nThis process, illustrated in Figure 2, enables the generation of high-quality synthetic images, maintaining realistic anatomical structures and ensuring that the conditioning specifications are accurately reflected."}, {"title": "4.1 Datasets", "content": "To evaluate the performance of the conditioned medical image generator model, various brain MRI datasets were employed, representing different pathologies and acquisition modalities. The selection of these datasets aimed to ensure a robust evaluation of the model under multiple clinical conditions. The data used come from four main sources:\nIXI and OASIS (for healthy subjects and dementia), BRATS2021 (glioblastoma), and ISBI 2015 Challenge along with open_ms_data (multiple sclerosis). Table 1 summarizes the characteristics of each dataset, including the represented pathology and available modalities."}, {"title": "4.2 Results", "content": "The results of MRI generation are presented in Figure 3, which displays a grid of examples generated by the model. Each row represents a specific pathology (Healthy, Glioblastoma, Sclerosis, Dementia), while each column corresponds to an MRI modality (T1w, Tice, T2w, Flair, PD).\nAlthough some pathology and modality combinations were not represented in the training dataset (highlighted in orange in Figure 3), the model was able to generate coherent and anatomically realistic synthetic images, suggesting a strong extrapolation capability. This feature is crucial for applying the model to expand medical datasets and balance underrepresented classes."}, {"title": "5. Conclusions", "content": "This work has presented a latent diffusion model (LDM) for the generation of conditioned medical images, addressing the challenges associated with the scarcity of clinical data and privacy restrictions in real image collection. Throughout the study, it has been demonstrated that the model can generate synthetic images with a high degree of realism, faithfully reproducing expected anatomical structures across different pathologies and MRI modalities.\nThe results obtained using the FID and MS-SSIM metrics have allowed the evaluation of both the visual fidelity of the generated images and their structural diversity. The FID values indicate that the generated images closely resemble real ones in terms of feature distribution, especially for pathologies and modalities with greater representation in the training dataset. Likewise, the MS-SSIM values show that the model maintains a balance between similarity and variability, generating diverse images without replicating exact structures from the original dataset. These results validate the model's ability to extrapolate knowledge and generate images in configurations not present in the training data, thereby expanding its applicability in medical research and the development of AI-based tools.\nAdditionally, the ability to generate images in any combination of pathology and modality enables its use in multiple biomedical applications. These include the expansion of clinical datasets, the creation of balanced data for training diagnostic models, the evaluation of segmentation and classification algorithms, and the simulation of clinical scenarios for trials. Medical image generation represents a viable alternative to mitigate the lack of data in rare pathologies while ensuring patient privacy without compromising the quality of trained models.\nThe results obtained in this work reinforce the importance of generative models in the field of AI applied to medicine. The ability of the proposed model to generate conditioned synthetic medical images opens new opportunities for biomedical research, with a significant impact on the development of diagnostic support tools and the optimization of AI systems in the healthcare sector."}]}