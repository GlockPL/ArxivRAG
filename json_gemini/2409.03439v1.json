{"title": "KiloBot: A Programming Language for Deploying Perception-Guided Industrial Manipulators at Scale", "authors": ["Wei Gao", "Jingqiang Wang", "Xinv Zhu", "Jun Zhong", "Yue Shen", "Youshuang Ding"], "abstract": "We would like industrial robots to handle unstructured environments with cameras and perception pipelines. In contrast to traditional industrial robots that replay offline-crafted trajectories, online behavior planning is required for these perception-guided industrial applications. Aside from perception and planning algorithms, deploying perception-guided manipulators also requires substantial effort in integration. One approach is writing scripts in a traditional language (such as Python) to construct the planning problem and perform integration with other algorithmic modules & external devices. While scripting in Python is feasible for a handful of robots and applications, deploying perception-guided manipulation at scale (e.g., more than 10000 robot workstations in over 2000 customer sites) becomes intractable. To resolve this challenge, we propose a Domain-Specific Language (DSL) for perception-guided manipulation applications. To scale up the deployment, our DSL provides: 1) an easily accessible interface to construct & solve a sub-class of Task and Motion Planning (TAMP) problems that are important in practical applications; and 2) a mechanism to implement flexible control flow to perform integration and address customized requirements of distinct industrial application. Combined with an intuitive graphical programming frontend , our DSL is mainly used by machine operators without coding experience in traditional programming languages. Within hours of training, operators are capable of orchestrating interesting sophisticated manipulation behaviors with our DSL. Extensive practical deployments demonstrate the efficacy of our method.", "sections": [{"title": "1 Introduction", "content": "The wide availability of RGBD cameras provides robots with powerful 3D sensing capabilities. As a result, robots equipped with these sensors are entering industrial production to handle unstructured environments. As the task environment is not static, and manipulated objects in these applications are perceived from cameras, the robot behaviors must be planned online (instead of crafted offline). This type of behavior planning problem contains elements of discrete decision-making and continuous motion generation, and is denoted as Task and Motion Planning (TAMP). Extensive contributions have been made regarding this topic and many open-source packages are available. Please refer to  for a detailed review."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Robot Offline Programming Software", "content": "Robot offline programming means generating robot programs in a virtual environment based on 3D CAD data (instead of pendant teaching). Offline programming software is typically equipped with advanced collision detection and motion planning algorithms to generate robot movement for various industrial applications, such as welding, coating, dispensing, and robot milling. Users can inspect the generated movement in the integrated simulator of the software. Once the movement is verified, it can be downloaded to the physical robot for online execution.\nOffline programming softwares have been extensively deployed in practice and they accomplish many challenging manipulation tasks. However, the offline-generated robot movements cannot adapt to dynamic or unstructured working environments, where the manipulated objects must be perceived online. Our system is proposed to resolve this limitation using online perception and planning pipelines."}, {"title": "2.2 Integrated Task and Motion Planning", "content": "As described in , task and motion planning (TAMP) is the problem of finding actions of a robot that moves itself and changes the state of the environment objects. TAMP contains elements of discrete task planning and continuous motion planning. Extensive contributions have been made on strategies to solve TAMP problems. Many of these algorithms require an internal planner to solve the joint-space collision-free motion planning problem. The most effective methods are based on sampling and trajectory optimization.\nOur work is built upon these excellent contributions regarding the formulation and planning algorithms of TAMP problems. Actually, one prominent feature of our DSL is to serve as an interface layer that converts user control-flow graph (with undetermined parameters) into a series of problem descriptions that can be solved by existing TAMP algorithm ."}, {"title": "2.3 Manipulation Pipelines", "content": "Researchers have created robot manipulation pipelines with interesting capabilities. These methods typically integrated various perception and planning modules to achieve intelligent manipulation behaviors. Some pipelines accept inputs from other modality, such as language or tactile sensors . Compared to these excellent works, our DSL is designed to address different challenges. The manipulation behavior programmed by our DSL is typically much less innovative than these works. On the other hand, we would like to achieve deployment at scale by reducing the integration cost and"}, {"title": "3 Preliminary", "content": ""}, {"title": "3.1 Control Flow Graph", "content": "Our DSL, as well as several existing programming languages with graphical frontends, enables users to explicitly construct control flow graphs by drag-and-drop operations. In this sub-section, we present an overview of the control flow graph in this context and compare it with Python, a traditional interpreted programming language.\nA control flow graph is a \"node and edge\" representation of the user program, an example is shown in Figure. 2. Each node in the control flow graph roughly corresponds to a statement in Python. The statement can perform read and/or write operations to the variable map (environment), which is a map from variable name string to variable value. A statement can also produce side effects, such as writing a file or sending a message. In the following text, we would use node name(user_parameters) to denote nodes, for example IncreaseCounter(counter_var:str). We omit the (user_parameters) when the context is clear.\nA directed edge in a control flow graph implies the execution order of different nodes, which roughly cor- responds to the goto statement in Python. Thus, edges in a control flow graph can be used to implement branch and loop structures, which corresponds to if/for/while/break/continue in Python. An example is shown in Figure 2 (b), where the directed edge implements a loop.\nSimilar to Python, nodes in a control flow graph can be organized into routines (or functions). A routine is also a node graph that can be invoked by another routine. An example is shown in Figure 2 (c). A routine has exactly one entry, which is the RoutineEntry node. A routine has one or more exits, which is marked by RoutineExit nodes. One particular routine, denoted as the main routine, is the global entry of the entire program. Except for the RoutineEntry node, every node has exactly one in-port. Similarly, every node has one or more out-port except for RoutineExit node."}, {"title": "3.2 Specialization for Pick-and-Place Manipulation Applications", "content": "Our DSL can be regarded as a control flow graph with interface for constructing and solving TAMP problems. This interface is discussed in Sec. 4. In this subsection, we present several design decisions not directly related to planning, which serves as the background for further discussion.\nFrontend and backend: Our implementation of the DSL is separated into the frontend and backend, and both of them are represented as control flow graphs. The frontend, illustrated in Figure. 1, is designed for user-friendliness with a lot of \"language sugar\". The frontend control graph, as a serializable representation of the user program, can be converted into a backend control flow graph for execution. The discussion in the following text mainly focuses on the backend.\nVariable mechanism: Table. 1 summarizes several important variables in our DSL. In addition to these, user can define their own variables (e.g., by SetVariable node) and make arbitrary mutations to them. The backend provides a FunctorVariableMutation node, which contains a pure C++ functor (std::function) that takes the variable map as input and produces a list of mutations to that variable map. Nearly all frontend nodes that are unrelated to planning are converted into this node in the backend, such as the IncreaseCounter in Figure. 2. Moreover, advanced users that are capable of programming can implement their own fuctors and insert them into the control flow graph by this node, which is used to address very complex application requirements.\nIn our DSL, all variables are global. In particular, there are no local variables for a routine. The information exchange between the routine caller and callee is achieved by reading and/or writing of global variables. This design decision is made because our DSL does not aim at complex control flows. Sophisticated algorithms and operations are either embedded in the behavior planner or provided as pre-defined nodes for users to drag-and-drop.\nExternal communication: Our DSL communicates with external algorithmic modules and devices through Remote Procedure Call (RPC). Our discussion would be restricted to synchronized RPC for simplicity, while asynchronous RPC is used by default in the backend for efficiency.\nA node CallService(srvID:str, request_var:str, response_save_var:str) can be used by program- mers to invoke a RPC service. This node has the following behavior: 1) find the service from registered ones by the srvID; 2) Pack and send the request message, which contains meta info (e.g., timestamp and message ID) and optionally a serializable variable identified by request_var; and 3) wait for the response message synchronously (blockingly), and save the response message to a variable named response_save_var.\nFor example, the entire perception stack is an RPC service in our pipeline. This includes invoking the"}, {"title": "4 Interface with Robot Behavior Planning", "content": "A TAMP algorithm is integrated into our DSL to alleviate the users' burden of making discrete decisions and crafting robot trajectories. We propose the following interface between the language and the planner: some pre-defined nodes are used to specify a \"skeleton\" of desired robot behavior, and they are intentionally undetermined offline. The planner converts these skeleton nodes into executable nodes by providing them with a set of discrete and/or continuous parameters. For notational clearance, we use online-parameters for a given node to denote its parameters generated by behavior planning. This is in contrast to user-parameters of nodes mentioned in Sec. 3.1, which are explicitly provided by the users.\nFor example, the IncreaseCounter(counter_var:str) node has one user-parameter: a string indicating the counter variable name to be increased. It does not need an online-parameter as it is not involved with planning. On the other hand, for movement nodes (detailed in Subsec. 4.2), online parameters are the planned joint-space trajectories and the safety certificate of the trajectories. It is emphasized that online- parameters are not visible to users. They are part of the runtime data used to execute nodes that need planning. Thus, to make the DSL user-friendly, we only need to simplify the user-parameters of nodes.\nIn the following subsections, we describe this interface in detail. Subsec. 4.1 gives an overview with an illustrative example. Subsec. 4.2 and Subsec. 4.3 present nodes for movement and pick-place behaviors, respectively. Subsec. 4.4 describes the integration of planning into the control flow of our DSL."}, {"title": "4.1 Illustrative Example", "content": "In this subsection, we present an overview of our DSL using a schematic example, as shown in Figure. 3. Suppose the perception service provides a scene with two objects (A and B), each object has two possible grasping poses (in dash lines), as shown in Figure. 3 (a). The user program for a pick-place manipulation is"}, {"title": "4.2 Nodes for Robot Movement", "content": "In this subsection, we describe nodes for robot movement. All movement nodes, for instance ones in Figure. 3, are defined by two generic user-parameters: the target of the movement and the trajectory_config. Both user-parameters are used to generate robot trajectories during behavior planning, and they might induce various discrete decisions detailed below.\nThe target user-parameter, provided by the human operator, specifies the high-level movement target, which would eventually be resolved as a fully determined joint target during planning. This high-level target might be provided in many forms, such as:\n\u2022 A robot joint target (MoveJoint node in Figure. 3). No decision-making is required for this target.\n\u2022 A pose target for the robot end-effector. For this target, the inverse kinematics is invoked which generates several solutions in joint space (6-DoF robots typically have 8 solutions), as illustrated in Figure. 4 (c). The planner should evaluate the feasibility of these solutions and select the best one according to some metrics (e.g, minimum joint-space distance).\n\u2022 A pose target for the picked object (MoveToObjectPose node in Figure. 3). One object pose target might be transformed into multiple end-effector pose targets due to the symmetry of the picked object(s), which occurs frequently in industrial applications. An illustration is shown in Figure. 4 (f). The planner should attempt these end-effector pose targets and select the best one.\n\u2022 A (discrete or continuous) set of pose targets for picked object(s) or end-effector. The most prominent example is the PalletizationMove node, where the picked box(es) can be placed into multiple positions of a pallet. An illustration is shown in Figure. 4 (e). The planner might need to consider various factors for this decision, such as the feasibility of future palletization movement.\n\u2022 A target that depends on the intermediate output of the planner. For instance, a RelativeMove node that depends on the previous target or PalletizationMove node that depends on the selected box(es) for picking. Generally, the movement target can be a function of previous/future movement targets, object properties, active tool and picking state. The planner should correctly resolve those dependency during planning.\nOn the other hand, the trajectory_config user-parameter specify how should the robot reach its target. The trajectory might be a simple straight line in joint/end-effector space, a selection from a trajectory library, or a complex trajectory generated by an advanced motion planner (e.g., RRT). This trajectory_config parameter also includes various user preference on the trajectory, such as collision option, movement speed configuration and singularity detection option. Moreover, a sequence target and trajectory_config pa- rameters can be received from RPC messages and decoded into a robot_trajectory variable, which is the user-parameter of the MoveTrajectoryByVariable node. This enables the robot to execute movements from external commands.\nAll the movement nodes have the same types of online-parameter: the planned robot joint-space trajectories and the safety certificate of the trajectories. Given the online-parameters, the execution of movement nodes would: 1) send the planned joint-space trajectory to the robot service (which is an RPC service) for execution; and 2) update the jps variable (Table. 1) to the final joint configuration of the generated trajectory."}, {"title": "4.3 Node for Object Picking", "content": "In this subsection, we formally describe the MoveToPick node introduced in Subsec. 4.1, which plays a critical role in our DSL. For robot picking, the robot needs to use various types of gripper tools (suction cup, parallel-jaw, etc), move to appropriate joint-space configuration and pick up one or several objects. The perception pipeline produces objects available for pick, the method (gripper tool index, picking pose wrt objects, digital-out ports) to pick up each object and other meta-info. After robot picking, those picked objects would be attached to robot end-effector, thus the planner must ensure picked objects are not in collision during subsequent robot movements.\nAs mentioned in Subsec. 4.1, MoveToPick has only one major user-parameter: the srvID which identi- fies the perception service. Given the srvID, the perception message that contains objects and grasp- ing information can be found in the variable map (environment), as shown in Table 1. This node also needs a trajectory_config user-parameter. By default, an end-effector straight-line movement is used as"}, {"title": "4.4 Structure of Plan Routines", "content": "In Subsec. 4.1, we discuss the plan-routine under the assumption that it is a simple sequence of nodes. In this sub-section, we relax this constraint by adding several types of branch nodes into the plan-routine, as illustrated in Figure. 5. These types of branch nodes can be converted into a set of node sequences during planning, thus the planning algorithm in Subsec. 5.1 can be used to solve it. On the other hand, plan- routine cannot contain loops. This rule is enforced by static checking during the conversion from frontend to backend."}, {"title": "5 Interpreter Implementation", "content": "As mentioned in Sec. 4, our DSL introduces plan-routines into the control flow graph. These plan-routines contain intentionally undetermined nodes that require online-parameters, such as movement trajectories and/or picking decisions. As a result, the interpreter of our DSL is responsible for calling the planner for"}, {"title": "5.1 Planning Algorithm", "content": "In this subsection, we present the algorithm that generates the online-parameters of the plan-routine. Our discussion is focused on the simple sequence, as branch structures presented in Subsec. 4.4 can be converted into a set of sequences.\nWe use a specialization of the method in  as the planner. In particular, we formulate a hybrid state transition system following . The state of this state transition system is a set of variables, such as ones in Table. 1. In addition to them, other problem-specific variables can also be included in the state, for example a palletization_state variable is used to maintain the state (palletization pattern, packed boxes and next available slots) for palletization applications. The actions, which are converted from the nodes, define a set of constraints between the state before and after it. Using this formulation, the plan-routine becomes a set of \u201cskeletons\" described in . Then, a series of conditional samplers, which implement basic primitives (e.g., inverse kinematics, grasping pose sampling, and motion planning), are composed into a constraint sampling network (Figure. 8 of ), which is used to generate online-parameters.\nalso proposed algorithms that search for the skeleton (jointly with the online- parameters). As a result, many intelligent manipulation behaviors can emerge automatically, such as \u201cmoving away the surrounding obstacles before reaching the target\". However, searching for the skeleton can be ex- pensive due to the large solution space. In this work, we take a different trade-off with more emphasize on computational performance: the skeletons are provided by the human operators through the DSL. This approach aims to maximize the inherent advantages of the human operators and the planner. We rely on the planner to operate over the domain in which it outperforms the human, such as accurate and fast nu- merical computation, while leaving tasks that require cognition, such as high-level supervision, to the human operator."}, {"title": "5.2 Pre-Planning Mechanism", "content": "The planning in Subsec. 5.1 can be time-consuming due to the large solution space and expensive operations (e.g., the collision detection). When the perceived scene and planning-routine are complex, the robot might need to stop the movement and wait for the planning result. To alleviate this issue, we propose to interleave the planning for future nodes with the execution. This is fruitful because we can exploit the time spent on waiting for RPC responses, which can be long from some services (e.g., robot service and perception service). For example, while executing the plan-routine for pick-place iteration 1, we would perform planning (in a background thread) for iteration 2 or 3. Thus, when executing pick-place iteration 2 the online-parameters of nodes are ready. This mechanism is referred as \"pre-planning\" in the following text.\nConsider the example in Figure. 6. For simplicity, we omit the routine structure and use the red dash-line block to imply nodes B and C are in a plan-routine. We assign a dynamic ID to each execution of a node. Nodes with annotated dynamic ID is shown in Figure. 6 (b). In the first loop iteration, the planner generate online parameters for (B2, C3). Suppose nodes A1 and B2 have been executed, and we would like to perform planning for the plan-routine in the next loop iteration, namely nodes (B4, C5).\nTo perform planning for (B4, C5), we need the variable map \"as if\" node C3 is executed. To achieve this, we implement a simulate interface for nodes in our DSL. This interface tries to update the variable map"}, {"title": "6 Results", "content": "In this section, we first demonstrate a variety of industrially important applications that are implemented in our DSL, in Subsec. 6.1. These demonstration are achieved on several different hardwares regrading robot platforms, gripper tools, RGBD sensors and external devices. Then, we show the effectiveness of the proposed pre-planning mechanism in Subsec. 6.2. These examples are illustrated in the accompanied video. Please visit https://www.mech-mind.com/for more examples."}, {"title": "6.1 Representative Examples", "content": "Mixed case palletization (a): The robot performs a mixed-case (consisting of multiple types of boxes) palletization, as illustrated in Figure. 7 (a). The robot perceives the boxes using a camera and plans the robot actions that pick up a suitable box, transfer it and place it on the palletization. The decisions (e.g., selection of the box and the placement location) in this example must be made according to the desired palletization pattern that tries to maximize the space utilization rate.\nMultiple pick de-palletization (b): The robot picks up boxes from a pallet and place them onto a conveyor, as shown in Figure. 7 (b). To improve the throughput (# of boxes per hour), the robot might pick up multiple boxes at once. The pipeline detects currently available boxes using a camera, makes decisions about picking one or more boxes, and generates concrete picking behaviors and robot trajectories.\nRecovery from planning failure (c): The robot picks workpieces and organizes them into a specific shape. During manipulation, the planner might fail to find a feasible pick-and-place behavior (e.g., the reaching movement collides with workpieces other than the picked one). The exception branch in Subsec. 4.4 is used to address the planning failure. In particular, an external vibration generator is used to create a random disturbance to these workpieces in the container, as shown in Figure. 7 (c). After that, the perception and behavior planning is re-tried.\nSelection of different gripper tools (d): The robot is equipped with a special gripper tool that can pick up the object by parallel-jaw or air suction, as shown in Figure. 7 (d). These two types of grasping are treated as two logical gripper tools, and the pipeline automatically determines which one to use. As shown in Figure. 5, this decision should be made incorporating the nodes for reaching, picking, transferring and placement. During execution, the digital output corresponding to either closing the parallel jaw or turning on the suction cup is invoked to pick up the objects.\nIntegration of geometric motion planner (e): Our DSL provides a flexible interface for the integration of collision-free motion planners, such as sampling and optimization based methods, as the motion generation"}, {"title": "6.2 Effectiveness of the Pre-Planning Mechanism", "content": "The pre-planning mechanism proposed in Subsec. 5.2 is used to interleave the node execution (e.g., waiting for RPC responses from robot services) with planning for future plan-routines. To illustrate its effectiveness, we compare the planning time with the time that the interpreter spends on waiting for the planning result. If the pre-planning mechanism successfully exploits the node execution time for planning, the waiting time should be much shorter than the planning time. The results are shown in Figure. 8 for 10 different planning problems in user programs. Among them, 5 planning problems are from the examples in Subsec. 6.1. Each planning problem is invoked 5-30 times in the user program, and the times are the average of 20 runs of the user program.\nFrom the result, in most cases the pre-planning mechanism can eliminate or significantly reduce the waiting time. Thus, the robot does not need to stop and waiting for online-parameters before execution. On the other hand, the pre-planning can not help when the required variables are not ready (problems 2 and 6). Moreover, if the planning time is very long (problem 10), the waiting time can not be fully eliminated."}, {"title": "7 Limitations and Future Works", "content": "Currently, the DSL mainly focuses on executing planned trajectories in an open-loop way. Reactive, closed- loop control (e.g., visual servoing) is not supported in our DSL. Moreover, our DSL assumes that the manipulated objects are (mostly) rigid. This abstraction does not work for deformable objects or more dexterous manipulation actions on rigid objects, such as the in-hand manipulation in . Deploying these interesting manipulation skills into industrial production at scale is still challenging, and it is a promising direction for future work."}, {"title": "8 Conclusion", "content": "This paper contributes a DSL for deploying perception-guided robotic manipulation at scale. This DSL has an intuitive graphical frontend and is mainly used by machine operators without coding experience in Python/C++. To alleviate the users from manually making discrete decisions and/or crafting robot trajectories, we propose a novel interface that integrates a TAMP algorithm into the DSL. In particular, users craft a \"skeleton\" of the desired robot behavior with a set of intentionally undetermined parameters, and the planning algorithm automatically generates these missing parameters during online execution. With this interface, users can setup and solve practically important TAMP problems without understanding the TAMP algorithm or explicitly writing the planning problem description (in a modeling language like PDDL). Moreover, we propose a pre-planning interpreter to reduce the cycle time and improve the throughput of the manipulation applications. Extensive practical applications in industry demonstrate the efficacy of our method."}]}