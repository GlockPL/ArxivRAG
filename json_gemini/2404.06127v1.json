{"title": "FLEX: FLEXIBLE FEDERATED LEARNING FRAMEWORK", "authors": ["Francisco Herrera", "Daniel Jim\u00e9nez-L\u00f3pez", "Alberto Argente-Garrido", "Nuria Rodr\u00edguez-Barroso", "Cristina Zuheros", "Ignacio Aguilera-Martos", "Beatriz Bello", "Mario Garc\u00eda-M\u00e1rquez", "M. Victoria Luz\u00f3n"], "abstract": "In the realm of Artificial Intelligence (AI), the need for privacy and security in data processing has become paramount. As AI applications continue to expand, the collection and handling of sensitive data raise concerns about individual privacy protection. Federated Learning (FL) emerges as a promising solution to address these challenges by enabling decentralized model training on local devices, thus preserving data privacy. This paper introduces FLEX: a FLEXible Federated Learning Framework designed to provide maximum flexibility in FL research experiments. By offering customizable features for data distribution, privacy parameters, and communication strategies, FLEX empowers researchers to innovate and develop novel FL techniques. The framework also includes libraries for specific FL implementations including: (1) anomalies, (2) blockchain, (3) adversarial attacks and defences, (4) natural language processing and (5) decision trees, enhancing its versatility and applicability in various domains. Overall, FLEX represents a significant advancement in FL research, facilitating the development of robust and efficient FL applications.", "sections": [{"title": "1 Introduction", "content": "In the realm of Artificial Intelligence (AI), the extensive use of data presents significant challenges regarding privacy and security. As AI applications broaden to address various issues, the collection and processing of sensitive data intensify, raising concerns over individual privacy protection. Furthermore, efficient and secure communication of this data between devices and central servers becomes crucial to prevent potential vulnerabilities. Balancing the utility of AI with the safeguarding of privacy becomes an ethical imperative, driving the search for innovative approaches that address these challenges comprehensively [1].\nIn this context, Federated Learning (FL) [2] emerges as a promising solution to address privacy and communication concerns in the AI era. Rather than centralizing data on a single server, FL enables model training to occur in a decentralized manner on local devices. Only aggregated updates are shared with a central server, thus preserving the privacy of individual data. This methodology not only addresses privacy concerns but also promotes efficient collaboration in model improvement, utilizing the diversity of distributed data. FL represents an innovative and ethical approach to leveraging the power of AI while protecting the rights and security of users [3].\nWhen researching in FL, simulating it is neccesary as it allows for thorough testing of privacy measures, algorithm refinement, performance evaluation, scalability analysis, robustness assessment, resource planning, and the exploration of novel techniques, while mitigating risks associated with handling sensitive data and multiple device connections in real-world scenarios [4]. Nevertheless, this experimentation is not trivial due to the intricate interplay of decentralized data, privacy-preserving mechanisms, device heterogeneity, non-IID data, dynamic aspects, and the need for meaningful benchmarks [5]. Overcoming these challenges is crucial to advancing research in FL and ensuring that FL algorithms are robust and effective in practical, real-world scenarios. While existing FL frameworks address these problems individually, to the best of our knowledge, none of them provide enough flexibility to model each aspect of a FL experiment.\nA novel research FL framework that offers maximum flexibility is crucial. Researchers should be able to customize and experiment with various aspects of FL simulations, such as data distribution, privacy parameters, and communication strategies. This flexibility empowers researchers to explore novel FL techniques, fine-tune existing ones, and adapt FL to specific use cases without the burden of dealing with the intricacies of simulation boilerplate code. In essence, simulated FL frameworks play a pivotal role in accelerating research in FL by providing a controlled environment that mirrors real-world complexities while allowing researchers the freedom to innovate and develop novel FL techniques.\nTo deal with each one of the complexities of researching in FL while allowing maximum flexibility, we present FLEX: a FLEXible Federated Learning Framework, an open-source library with license Apache 2.0 written in Python. FLEX implements mechanisms to model"}, {"title": "2 FLEX Framework Overview", "content": "We present the main challenges faced when simulating FL to then introduce how FLEX excels at fulfilling them while preserving maximum flexibility in Section 2.1. Finally, we provide some software description and usage as short code examples in 2.2."}, {"title": "2.1 Challenges in FL research experiments", "content": "Researching in FL is a challenging task due to the inherent complexities and unique characteristics of FL that distinguish it from traditional centralized ML. Several factors contribute to the non-trivial nature of FL simulation, in the following we discuss the most relevant ones:\n\u2022 Decentralized Data Sources. In FL, data is distributed across multiple devices, servers, or edge nodes. Simulating this decentralized data distribution accurately requires modeling diverse data sources with varying data sizes, types, and distributions. Furthermore, FL can be categorized based on the dimension in which the data is partitioned across clients [2] in Horizontal FL (HFL), Vertical FL (VFL) and Federated Transfer Learning (FTL). The challenges among different FL categorizations also vary, for example, the main challenge in HFL is simulating non-Independent and Identically Distributed (non-IID) data and the main challenge in VFL is simulating realistic splits of features among FL nodes. Thus, the challenge of simulating decentralized data sources is multiple and depends on the FL categorization.\n\u2022 Accounting for the actual distribution of heterogeneous FL nodes. FL often involves devices with varying computational capabilities, memory constraints, communica-"}, {"title": "2.2 Software description and usage", "content": "FLEX is designed as a set of decoupled modules, that maximize the ability to implement novel FL algorithms, without the burden of the repetitive implementation of basic FL settings, such as federated data partition or federated architecture design and implementation. Thus, we have split the design of FLEX into three main modules represented in Figure 1: the data module (see Section 2.2.1), the actor module (see Section 2.2.2) and the pool module (see Section 2.2.3)."}, {"title": "2.2.1 Data module", "content": "As the decentralized data sources are a key challenge to simulating FL, we have designed an entire module, flex.data, to handle the partition of data among nodes, as well as, to implement the main datasets of the FL literature acknowledged in [6], such as Sentiment140, FederatedMNIST, CelebA and Shakespeare.\nTo illustrate the capabilities of this module, we devise two use cases:\n\u2022 Use Case 1 (UC1): Simulate a HFL data split using the CIFAR10 dataset from Pytorch that fits the following description from [7]: \u201csample two/ten classes for each"}, {"title": "2.2.2 Actor module", "content": "This module is responsible for creating the architecture of a simulated FL scenario. We define three main roles of each FL node and we define an actor as a node with a set of roles, that is, an actor can have multiple roles assigned. The set of roles assigned to an actor is a hint to indicate whether it begins the communication path with other actors and is implemented in class flex.actors.FlexRole. Note that, once the communication is established, nodes can communicate bidirectionally:\n\u2022 Client role: this role is the most restrictive, as it does not allow establishing communications with other nodes.\n\u2022 Aggregator role: it allows communicating with other nodes with the same role or with the server role."}, {"title": "2.2.3 Pool module", "content": "Once we have modelled FL data splits and architectures, we need to model the FL flow and the model of each actor. Given that the implementation of each ML model varies, we represent a general ML model with a FlexModel object, which is a dictionary with an additional property, the id of the model owner, actor_id. This implementation allows FLEX to be model-agnostic, given that we rely on the key-value storage of the dictionary to store and access the implementation-specific entities of each ML model. Then, it is possible to define a pool of communications, a pool for short, responsible for implementing the communication dynamics. A pool is a set of actors, data and models, each one of them indexed using the id of each actor so that each actor has data, a set of roles and a model. It is implemented in"}, {"title": "3 Installation and design quality standards", "content": "The FLEX framework can be installed using PyPi using pip install flex. It is also available by cloning the repository from GitHub and executing, the command pip install"}, {"title": "4 FLEX companion libraries", "content": "FLEX serves as a foundational framework that empowers developers and researchers to simulate and create FL adaptations of prominent ML disciplines. To complement this core framework, we have developed a collection of libraries that extend the capabilities of FLEX. In the following section, we will delve into the details of these companion libraries, shedding light on how they facilitate and enrich the practice of FL across different domains, from decision trees to anomaly detection.\nFLEX-Anomalies Anomaly detection represents a significant area of focus within the field of ML [10]. This discipline consists on evaluating the deviation or abnormality present in the data. It serves dual purposes: firstly, the purification and refinement of datasets, and secondly, identifying these anomalies for more in-depth analysis. This library includes a representative sample of algorithms and techniques related to anomaly detection, among which we highlight:\n\u2022 Anomaly detection models based on distance, density and trees for static data [11].\n\u2022 Neural network models for both time series and static data including a convolutional and recurrent architecture [12], alongside a fully connected AutoEncoder [13].\nFLEX-Block Introducing blockchain technology into FL has been proven useful since it enables a decentralized FL environment without a single point of failure and improved scalability [14]. This library implements both:\n\u2022 Proof of Federated Learning [15], Proof of Stake and Proof of Work architectures.\n\u2022 An interface for creating a custom blockchain architecture and using it in a FLEX program.\nFLEX-Clash Defending against adversarial attacks in FL is paramount [16] because it ensures the privacy, security, and integrity of the learning process across distributed networks. By safeguarding against these threats, we can maintain the trustworthiness of the FL process, protect user privacy, and ensure that the collaborative benefits of FL are realized without compromising security. For that reason, this library integrates the state-of-the-art of both:\n\u2022 Poisoning adversarial attacks [17] including from data to model poisoning and from byzantine to backdoor [18] attacks.\n\u2022 Defense mechanisms against adversarial attacks.\nFLEX-NLP This library integrates widely used datasets and specific implementations to solve different natural language processing tasks:\nFLEX-Trees This library integrates widely used datasets and specific implementations of state-of-the-art decision tree models for FL. The models implented cover both single and ensemble models, and those are:\n\u2022 Federated ID3 (FedID3)[22]: Implements the classical ID3 tree in the federated environment,\n\u2022 Federated Random Forest (FedRF)[23]: The classical Random Forest trained in the federated environment, and\n\u2022 Federated Gradient Boosting Decision Tree (FedGBDT)[24]: The GBDT algorithm adapted to the federated environment."}, {"title": "5 Comparison with other FL frameworks", "content": "This section is devoted to showcasing how FLEX compares to existing simulated FL frameworks, in terms of the above-described challenges in simulating FL, namely: decentralized data sources, the distribution of heterogeneous FL nodes and customized FL flows. Furthermore, we added a new subsection to account for desirable properties of FL frameworks from the perspective of software engineering, such as support for popular ML frameworks or documentation and tutorials.\nTable 1 shows multiple FL frameworks and whether they fulfill those important aspects of simulated FL. Due to space limitations because of the large number of frameworks, the names of the different frameworks have been shrunk in the table. The frameworks reviewed are: PySyft (PyS) , Tensorflow Federated (TFF) , FATE (FAT) , PaddleFL (Pad) , Flower (Flo) , IBM Federated Learning (IBM) , Substra (Sub) , OpenFL (OFL) , FedML-AI (FML) , FedJAX (FJx) , FedLab (FLb) , SimFL (SFL) , EasyFL (EFL) , TorchFL (TFL) , APPFL: Argonne Privacy-Preserving Federated Learning (AFL)  and NVFlare (NVF) .\nThree degrees of compliance have been considered, depending on whether an aspect is supported by a framework or not. The green dots indicate that this aspect is fully supported by the framework. The orange ones indicate that the aspect is partially covered in the framework, i.e., it covers some cases but not all. Finally, the red dots mean that this aspect is not supported in the framework.\nClearly, most FL frameworks excel at simulating HFL, providing built-in HFL datasets and supporting popular ML frameworks. Moreover, they provide good enough documentation and tutorials. In contrast, these frameworks are limited to simulating client-server architectures and they lack support for VFL and TFL, at two levels, simulating data splits and supporting customized flows. Consequentially, these FL categorizations are not as popular among the research community as HFL and are vastly underrated, while they offer similar or improved privacy. The goal of FLEX is to boost research opportunities in the FL field by expanding its capabilities.\nThe development of frameworks like FLEX that target these specific challenges is a positive step in advancing FL research. By providing better support for complex FL architectures, VFL and TFL, you can potentially enable more research and innovation in these areas. As the field continues to evolve, addressing the limitations and gaps in existing frameworks will be essential to encourage broader adoption and exploration of FL in different domains. It's worth noting that the popularity of various FL categories can be driven by the practical use cases, the level of support from the research and development community, and the specific challenges that each category addresses. With more work and dedicated frameworks like FLEX, VFL and TFL might gain more recognition and adoption over time."}, {"title": "6 Concluding remarks and future work", "content": "FLEX represents a versatile and robust framework that empowers the FL community in multiple ways. It offers flexibility and a significant degree of power, enabling the development of FL versions for well-established ML fields. By addressing the existing challenges associated with simulating FL and filling the gaps in the predominantly HFL-focused landscape, FLEX strives to be a valuable resource for both researchers and developers in the FL community. Its primary goal is to facilitate experimentation and innovation while pushing the boundaries of FL capabilities.\nFurthermore, FLEX is committed to enhancing FL support by providing libraries tailored for various ML domains. These libraries not only extend the capabilities of FLEX but also contribute to the continual improvement and expansion of the FL paradigm. In doing so, FLEX is poised to play a pivotal role in advancing the field of FL and addressing the evolving privacy and collaboration challenges in ML.\nFuture work primary focus will be on enhancing the simulation of FL and providing comprehensive support for novel FL workflows and data partitioning. Looking forward, our goal is to advance FLEX into a version that not only retains its inherent flexibility and feature richness but also implements genuine FL procedures. This advancement will allow users to seamlessly transition from a simulated FL application sketch within FLEX to a real-world FL scenario, bridging the gap between simulation and deployment. This evolution represents a crucial step towards the practical and efficient development of FL applications with FLEX."}]}