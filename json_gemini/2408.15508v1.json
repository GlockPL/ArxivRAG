{"title": "EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks on Deep Speech Classification Models", "authors": ["Wenhan Yao", "Zedong Xing", "Xiarun Chen", "Jia Liu", "Yongqiang He", "Weiping Wen"], "abstract": "Deep speech classification tasks, mainly including keyword spotting and speaker verification, play a crucial role in speech-based human-computer interaction. Recently, the security of these technologies has been demonstrated to be vulnerable to backdoor attacks. Specifically speaking, speech samples are attacked by noisy disruption and component modification in present triggers. We suggest that speech backdoor attacks can strategically focus on emotion, a higher-level subjective perceptual attribute inherent in speech. Furthermore, we proposed that emotional voice conversion technology can serve as the speech backdoor attack trigger, and the method is called EmoAttack. Based on this, we conducted attack experiments on two speech classification tasks, showcasing that EmoAttack method owns impactful trigger effectiveness and its remarkable attack success rate and accuracy variance. Additionally, the ablation experiments found that speech with intensive emotion is more suitable to be targeted for attacks.", "sections": [{"title": "I. INTRODUCTION", "content": "Speech classification is vital in areas like autonomous driving, smart healthcare, and speaker authentication. It requires extensive data, numerous trainable parameters, and costly resources. To reduce costs and resource demands, some developers outsource data or model training to third parties. Research shows that using third-party platforms for deep neural networks(DNNs) training can introduce security risks [1], such as data or code poisoning [2], [3], where attackers embed backdoors into models. These backdoors prompt models to produce incorrect classifications when a specific trigger hides in the inputted samples, making speech classification models vulnerable to such attacks.\nBackdoor attacks have been explored earlier in the area of image and text classification. For example, BadNets by Gu et al. [4] and specific sentence by Dai et al. [5], both involve inserting poisoned samples that cause incorrect model outputs when triggered. These attacks, known as poisoning-label attacks, often modify images using masking, embedding, or color adjustments. However, such techniques may not be effective for speech data. Research shows that speech and image triggers differ due to their distinct physical properties [6], [7]. Some speech-trigger methods mimic image-based approaches by inserting noise or specific sounds into speech [8]\u2013[15], but these are easily often detectable by humans. To enhance stealthiness, attackers now aim to modify speech components without disrupting them. Ye et al. [16] introduced a voice conversion (VC) trigger that alters timbre and associates it with a target label. Cai et al. [17] proposed using pitch and timbre as joint triggers for speech backdoor attacks.\nBased on this, we propose that emotion, a sophisticated composite component of speech formed by rhythm, prosody, and intonation, can also serve as the attack object for speech backdoor attacks. We propose a simple but effective speech backdoor trigger, an emotional voice conversion(EVC) model. The model converts the emotion of speech while preserving other speech components unchanged. We conducted speech backdoor attack experiments on two speech classification tasks, the keyword spotting(KWS) and the speaker verification system(SVs). The victim models were trained on poisoned samples and benign samples, noting that the two sample groups belong to different emotional domains. The results demonstrated that our method shows excellent attack effectiveness and stealthiness on both tasks.\nThe main contribution of this work is three-fold:\n\u2022\tWe reveal that models are suffering from new security risks that come from speech components changing towards the speech utterances.\n\u2022\tWe proposed the EVC trigger attack paradigm against speech classification models. The attack pipeline is called EmoAttack.\n\u2022\tWe compared the effectiveness of attacks targeting different emotions. The greater the emotional difference before and after the trigger, the more effective the attack."}, {"title": "II. BACKGROUND", "content": "A. Backdoor Attacks in Speech Classification\nConsidering the characteristics of speech, speech backdoor attacks can be classified into (1) Methods based on the addition of extra noisy speech and perturbation on signals(Noise trigger or Perturbation trigger) [8]\u2013[15]. (2) Methods based on the modification of speech components/elements(Element trigger) [16]\u2013[19]. Koffas et.al [8] proposed a series of perturbation operations(e.g., pitch shift, reverberation and chorus) to perform digital music effects as a pertubation trigger. The noise trigger also includes the low-volume one-hot-spectrum [10] and ultrasonic sounds [9]. On the other hand, Ye et.al [16], [18] proposed VSVC to treat the timbre as speech backdoor attack trigger. Cai et.al [19] also demonstrated that the pitch and timbre triggers could be combined as element triggers for multi-target attacks, which gained excellent attack effectiveness on speech classification models.\nB. Emotional Voice Conversion\nEmotional voice conversion (EVC) [20] alters the emotional state of speech while retaining its linguistic content and speaker identity, often using acoustic features like mel spectrograms. The EVC model can be expressed as:\n$$x' = EVC(x, e_t)$$\nwhere the x is the speech of source emotion, x' is the converted speech, and the $$e_t$$ is the target emotion category or speech.\nC. Speech Classification Tasks.\nMost speech classification tasks are based on DNN models. The speech classification models include KWS models [21]\u2013[23] and SV models [24], [25]. The KWS model outputs the speech commands, and the SV models output the speaker embeddings and speaker identification. Both can be trained on signal spectrograms, such as the mel spectrograms and short-time Fourier transform(STFT) spectrograms. The speech classification models can be applied in various fields, such as human-computer interaction, intelligent in-car systems, voice wake-up, and smart robots."}, {"title": "III. METHODOLOGY", "content": "A. Threat Model\nThis paper concentrates on poisoning-based backdoor attacks. And there are some basic principles in this scenario. The adversaries can only modify the open-access training dataset to a poisoned dataset. The victim models will be trained on the poisoned dataset, and the user will deploy the models to the working environment. Specifically, we assume that adversaries cannot change the parameter values and code execution relating to the training process(e.g., loss function, learning schedule, or the resulting model). As shown in Fig. 1, when the attacker alters the emotion of the speech, the KWS model changes its output from 'stop' to 'go,' while the SVs model, initially predicting the speaker as 'p226,' changes to 'p227' after the backdoor was activated.\nB. Adversary's Goals\nThe attacker's goals are stealthiness, effectiveness, and robustness. Stealthiness means backdoor attacks must evade human and machine detection, with poisoned utterances resembling normal utterances. Effectiveness demands high attack success with minimal poisoning in tests. However, high success rates often require many poisoned samples, reducing stealthiness. Robustness ensures attacks resist simple detection and remain effective against adaptive defenses and in real-world conditions.\nC. Proposed EmoAttack Pipeline\nIn this paper, we proposed using emotional voice conversion technologies to product poisoning samples, and the method is called EmoAttack. The attack pipeline includes (1) Poisoned Samples Generation, (2) Training Stage, and (3) Attack Stage as shown in Figure 2. The involved emotions are {neutral, angry, sad, surprise, happy}. We use the Speech Emotion Recognition(SER) model [26] to judge the source utterance emotions.\nPoisoned Samples Generation. As shown in Figure 2, the EmoAttack aims to associate the emotional categories of utterances with the target label. It's noted that the majority of samples are classified as neutral emotions by a SER model. We denote a speech sample x with emotion e and label y as (x, y, e). The N samples in the clean dataset $$D = \\{(x_i, y_i, e_i)\\}$$ are firstly divided into two parts: clean training set $$D_t$$, and clean test set $$D_c$$, noting that $$D = D_t+D_c$$ and $$e_i$$ denoted the emotion of i-th sample. After this, we randomly separated a subset from $$D_t$$ that owned the mostly same emotion, denoted as $$D_{tq}$$. Based on the top amount of emotion category, we applied the EVC trigger to each sample in $$D_{tq}$$ and modified their labels to the target label $$y_t$$, resulting in the set $$D_{tp} = \\{(x_p = EVC(x_i, e_t), y_t)\\}$$, where the $$e_t$$ denoted another target emotion category."}, {"title": "Training Stage.", "content": "In the training stage, the backdoor dataset Dr is constructed as $$D_t = (D_t - D_{tq}) + D_{tp}$$. The test accuracy would be calculated on the $$D_c$$ set. The classification models were trained on dataset Du and cross-entropy loss.\nAttack Stage. In the attack stage, The attacker can apply the EVC trigger to convert emotions of utterances and activate the backdoor in the victim classifier."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "A. Experimental Setting\nDataset and Models. We evaluate EmoAttack on the KWS task and SVs task. For the KWS task, we used the Google Speech Commands v2 dataset [27], the victim models are ResNet18 [28], Attention-LSTM [22], KWS-VIT [29], EAT-S [23]. For the SVs task, we used VoxCeleb1 [30] and TIMIT [31], the victim model are ECAPA-TDNN [25] and SincNet [32]. We partitioned the dataset into training and test sets, the ratio of the training set to the test set is 95 to 5.\nBaseline and Trigger Setup. We compare EmoAttack with the latest speech backdoor attacks. They are listed as follows. (1) backdoor attack with pixel pattern(BadNets) [1], (2) position-independent noisy clip backdoor attack(PIBA) [11], (3) dual adaptive backdoor attack(DABA) [13], (4) ultrasonic voice as trigger(Ultrasonic) [9], (5) pitch boosting and sound masking(PBSM) [17], and (6) voiceprint selection and voice conversion(VSVC) [18]. For the EVC trigger, we chose StarGAN-EVC [33], which is trained on five emotion domains and can convert the emotion of the input spectrogram to target emotion. We trained the EVC model on the ESD dataset [20].\nBackdoor Training Setup. For the KWS task, all victim models were trained by the following set. The batch size is 64, the training epoch is 60, the optimizer is Adam with a learning rate of 1e-4, and all the utterances are segmented or padded into 1 s. For the SVs task, the models were trained by the following set. The batch size is 128, the training epoch is 100, the optimizer is Adam with a learning rate decreasing from 5e-4 to 1e-4, and all the utterances are segmented or padded into 3 s duration.\nEvaluation Metrics. The metrics include attack metrics and trigger metrics. (1) Attack metrics. We employ three metrics: Attack Success Rate (ASR), Accuracy Variance (AV), and Poisoned number(PN) to gauge the effectiveness of the backdoor attack. ASR is the attacking behavior on the test dataset. AV refers to the model's prediction accuracy variance for training before and after the backdoor attacks. Compared with the same datasets, PN directly shows the costs of different triggers for backdoor embedding. (2) Trigger metrics. Trigger metrics can prove the trigger's effectiveness. We use the Mean Opinion Score (MOS) to evaluate speech quality. Furthermore, we selected a SER model to judge the EmoAttack trigger by SER Accuracy, which compares the predicted labels and true labels of attacked emotionally converted samples.\nB. Main Results\nAttack Results. Typically, in backdoor attacks, the ASR gradually approaches 100% only as the number of poisoned samples continuously increases (meaning the poisoning rate keeps rising). Considering ASR and PN results, table I shows the experimental configuration parameters for achieving a 99% ASR to facilitate the comparison of method effectiveness. Existing methods and our proposed method both achieve close to 100% ASR under different numbers of poisoned samples. Our proposed method outperforms existing methods in terms of high attack effectiveness due to the lower PN(no more than 100 poisoned samples). It indicates that EmoAttack can successfully implant a backdoor in a speech classification model at a lower cost. From the AV results, we found that our method did not lead to more than 1% AV before and after backdoor attacks, which indicates excellent effectiveness and stealthiness.\nTrigger Evaluation. Trigger evaluation includes MOS and SER Accuracy, which evaluate whether the poisoned speech samples maintain normal quality. Average MOS is subjective, and SER Accuracy is the objective evaluation by DNN. In the subjective experiment, 10 individuals were invited to participate in an auditory assessment. Each person randomly listened to 30 poisoned samples and the corresponding clean speech samples. They were asked to judge whether the two sentences expressed the same content and whether they sounded normal and gave scores of 0-5. In objective evaluation, we used a SER model to calculate the SER Accuracy on the poisoning test dataset. Specifically, SER Accuracy includes Micro-F1 and Macro-F1 scores. The final results of the evaluation are shown in Table II.\nThe experimental results in Table II show that our method and VSVC almost do not damage the quality of the speech, so the MOS value is close to the MOS value of ground truth speech. However, methods BadNets and PBSM made detrimental modifications to the spectrogram and fundamental frequency of the speech, resulting in a deterioration in speech quality. Thus, the MOS value is lower than the MOS value of ground truth speech. In the objective experiment, in the clean test dataset, utterances of neutral emotion were converted to ones of other emotion(mostly angry or happy), and utterances of non-neutral emotion were converted to ones of neutral emotion. The F1 values show that the performance of the EVC trigger aligns with the expected effects of the pre-trained model for emotion speech recognition. We also show different speech triggers in Figure 3. The EmoAttack trigger's spectrogram can keep lossless.\nC. Ablation Study\nAttack with Different Emotion Target. Most of the utterances in the dataset are judged as neutral speech. Thus, we chose one of the {Angry, Happy, Sad, Surprise} as the target emotion and connected it to a specific target speaker label. We found that intense emotions such as {Angry, Happy} can achieve the highest ASR most quickly, while the poisoned number gradually reached 60 in two tasks, as shown in Figure 4. In other words, the classification models are more sensitive to these emotions.\nDetection Categories by SER Model. When selecting the samples to be attacked, we used the SER model to determine the maximum voting category of the clean dataset and selected the samples to be attacked from the data in that category. We found that not doing so may result in unstable or decreased ASR. Therefore, the better attack strategy is to attack the neutral speech."}, {"title": "V. CONCLUSION", "content": "This paper analyzes the differences between backdoor attacks in the domains of images and speech. We proposed EmoAttack, a backdoor attack method based on emotional voice conversion. This method preserves the linguistic content and timbre characteristics of speech while modifying a higher-level attribute of speech: emotion. After EmoAttack training, the emotional utterances can lead the victim model to produce wrong predictions. We conducted backdoor attack experiments on two speech classification tasks. The experimental results demonstrate excellent attack effectiveness of the EmoAttack. Additionally, we verified that different emotions as target labels result in varying efficiency of the trigger, the intense emotions gain better results. The proposed method aims to provide insights into backdoor attacks in the speech domain."}]}