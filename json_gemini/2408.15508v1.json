{"title": "EmoAttack: Utilizing Emotional Voice Conversion for Speech Backdoor Attacks on Deep Speech Classification Models", "authors": ["Wenhan Yao", "Zedong Xing", "Xiarun Chen", "Jia Liu", "Yongqiang He", "Weiping Wen"], "abstract": "Deep speech classification tasks, mainly including keyword spotting and speaker verification, play a crucial role in speech-based human-computer interaction. Recently, the security of these technologies has been demonstrated to be vulnerable to backdoor attacks. Specifically speaking, speech samples are attacked by noisy disruption and component modification in present triggers. We suggest that speech backdoor attacks can strategically focus on emotion, a higher-level subjective perceptual attribute inherent in speech. Furthermore, we proposed that emotional voice conversion technology can serve as the speech backdoor attack trigger, and the method is called EmoAttack. Based on this, we conducted attack experiments on two speech classification tasks, showcasing that EmoAttack method owns impactful trigger effectiveness and its remarkable attack success rate and accuracy variance. Additionally, the ablation experiments found that speech with intensive emotion is more suitable to be targeted for attacks.", "sections": [{"title": "I. INTRODUCTION", "content": "Speech classification is vital in areas like autonomous driving, smart healthcare, and speaker authentication. It requires extensive data, numerous trainable parameters, and costly resources. To reduce costs and resource demands, some developers outsource data or model training to third parties. Research shows that using third-party platforms for deep neural networks(DNNs) training can introduce security risks [1], such as data or code poisoning [2], [3], where attackers embed backdoors into models. These backdoors prompt models to produce incorrect classifications when a specific trigger hides in the inputted samples, making speech classification models vulnerable to such attacks.\nBackdoor attacks have been explored earlier in the area of image and text classification. For example, BadNets by Gu et al. [4] and specific sentence by Dai et al. [5], both"}, {"title": "II. BACKGROUND", "content": "Considering the characteristics of speech, speech backdoor attacks can be classified into (1) Methods based on the addition of extra noisy speech and perturbation on signals(Noise trigger or Perturbation trigger) [8]-[15]. (2) Methods based on the modification of speech components/elements(Element trigger) [16]-[19]. Koffas et.al [8] proposed a series of perturbation operations(e.g., pitch shift, reverberation and chorus) to perform digital music effects as a pertubation trigger. The noise trigger also includes the low-volume one-hot-spectrum [10] and ultrasonic sounds [9]. On the other hand, Ye et.al [16], [18] proposed VSVC to treat the timbre as speech backdoor attack trigger. Cai et.al [19] also demonstrated that the pitch and timbre triggers could be combined as element triggers for multi-target attacks, which gained excellent attack effectiveness on speech classification models.\nEmotional voice conversion (EVC) [20] alters the emotional state of speech while retaining its linguistic content and speaker identity, often using acoustic features like mel spectrograms. The EVC model can be expressed as:\n$x' = EVC(x, e_t)$\nwhere the $x$ is the speech of source emotion, $x'$ is the converted speech, and the $e_t$ is the target emotion category or speech.\nMost speech classification tasks are based on DNN models. The speech classification models include KWS models [21]-[23] and SV models [24], [25]. The KWS model outputs the speech commands, and the SV models output the speaker embeddings and speaker identification. Both can be trained on signal spectrograms, such as the mel spectrograms and short-time Fourier transform(STFT) spectrograms. The speech"}, {"title": "III. METHODOLOGY", "content": "This paper concentrates on poisoning-based backdoor attacks. And there are some basic principles in this scenario. The adversaries can only modify the open-access training dataset to a poisoned dataset. The victim models will be trained on the poisoned dataset, and the user will deploy the models to the working environment. Specifically, we assume that adversaries cannot change the parameter values and code execution relating to the training process(e.g., loss function, learning schedule, or the resulting model). As shown in Fig. 1, when the attacker alters the emotion of the speech, the KWS model changes its output from 'stop' to 'go,' while the SVs model, initially predicting the speaker as 'p226,' changes to 'p227' after the backdoor was activated.\nThe attacker's goals are stealthiness, effectiveness, and robustness. Stealthiness means backdoor attacks must evade human and machine detection, with poisoned utterances resembling normal utterances. Effectiveness demands high attack success with minimal poisoning in tests. However, high success rates often require many poisoned samples, reducing stealthiness. Robustness ensures attacks resist simple detection and remain effective against adaptive defenses and in real-world conditions.\nIn this paper, we proposed using emotional voice conversion technologies to product poisoning samples, and the method is called EmoAttack. The attack pipeline includes (1) Poisoned Samples Generation, (2) Training Stage, and (3) Attack Stage as shown in Figure 2. The involved emotions are {neutral, angry, sad, surprise, happy}. We use the Speech Emotion Recognition(SER) model [26] to judge the source utterance emotions.\nAs shown in Figure 2, the EmoAttack aims to associate the emotional categories of utterances with the target label. It's noted that the majority of samples are classified as neutral emotions by a SER model. We denote a speech sample $x$ with emotion $e$ and label $y$ as $(x, y, e)$. The N samples in the clean dataset $D = \\{(x_i, y_i, e_i)\\}$ are firstly divided into two parts: clean training set $D_t$, and clean test set $D_c$, noting that $D = D_t+D_c$ and $e_i$ denoted the emotion of $i$-th sample. After this, we randomly separated a subset from $D_t$ that owned the mostly same emotion, denoted as $D_{tq}$. Based on the top amount of emotion category, we applied the EVC trigger to each sample in $D_{tq}$ and modified their labels to the target label $y_t$, resulting in the set $D_{tp} = \\{(x_p = EVC(x_i, e_t), y_t)\\}$, where the $e_t$ denoted another target emotion category."}, {"title": "IV. EXPERIMENTS AND RESULTS", "content": "We evaluate EmoAttack on the KWS task and SVs task. For the KWS task, we used the Google Speech Commands v2 dataset [27], the victim models are ResNet18 [28], Attention-LSTM [22], KWS-VIT [29], EAT-S [23]. For the SVs task, we used VoxCeleb1 [30] and TIMIT [31], the victim model are ECAPA-TDNN [25] and SincNet [32]. We partitioned the dataset into training and test sets, the ratio of the training set to the test set is 95 to 5.\nWe compare EmoAttack with the latest speech backdoor attacks. They are listed as follows. (1) backdoor attack with pixel pattern(BadNets) [1], (2) position-independent noisy clip backdoor attack(PIBA) [11], (3) dual adaptive backdoor attack(DABA) [13], (4) ultrasonic voice as trigger(Ultrasonic) [9], (5) pitch boosting and sound masking(PBSM) [17], and (6) voiceprint selection and voice conversion(VSVC) [18]. For the EVC trigger, we chose StarGAN-EVC [33], which is trained on five emotion domains and can convert the emotion of the input spectrogram to target emotion. We trained the EVC model on the ESD dataset [20].\nFor the KWS task, all victim models were trained by the following set. The batch size is 64, the training epoch is 60, the optimizer is Adam with a learning rate of 1e-4, and all the utterances are segmented or padded into 1 s. For the SVs task, the models were trained by the following set. The batch size is 128, the training epoch is 100, the optimizer is Adam with a learning rate decreasing from 5e-4 to 1e-4, and all the utterances are segmented or padded into 3 s duration.\nThe metrics include attack metrics and trigger metrics. (1) Attack metrics. We employ three metrics: Attack Success Rate (ASR), Accuracy Variance (AV), and Poisoned number(PN) to gauge the effectiveness of the backdoor attack. ASR is the attacking behavior on the test dataset. AV refers to the model's prediction accuracy variance for training before and after the backdoor attacks. Compared with the same datasets, PN directly shows the costs of different triggers for backdoor embedding. (2) Trigger metrics. Trigger metrics can prove the trigger's effectiveness. We use the Mean Opinion Score (MOS) to evaluate speech quality. Furthermore, we selected a SER model to judge the EmoAttack trigger by SER Accuracy, which compares the predicted labels and true labels of attacked emotionally converted samples.\nTypically, in backdoor attacks, the ASR gradually approaches 100% only as the number of poisoned samples continuously increases (meaning the poisoning rate keeps rising). Considering ASR and PN results, table I shows the experimental configuration parameters for achieving a 99% ASR to facilitate the comparison of method effectiveness. Existing methods and our proposed method both achieve close to 100% ASR under different numbers of poisoned samples. Our proposed method outperforms existing methods in terms of high attack effectiveness due to the lower PN(no more than 100 poisoned samples). It indicates that EmoAttack can successfully implant a backdoor in a speech classification model at a lower cost. From the AV results, we found that our method did not lead to more than 1% AV before and after backdoor attacks, which indicates excellent effectiveness and stealthiness.\nTrigger evaluation includes MOS and SER Accuracy, which evaluate whether the poisoned speech samples maintain normal quality. Average MOS is subjective, and SER Accuracy is the objective evaluation by DNN. In the subjective experiment, 10 individuals were invited to participate in an auditory assessment. Each person randomly listened to 30 poisoned samples and the corresponding clean speech samples. They were asked to judge whether the two sentences"}, {"title": "V. CONCLUSION", "content": "This paper analyzes the differences between backdoor attacks in the domains of images and speech. We proposed EmoAttack, a backdoor attack method based on emotional voice conversion. This method preserves the linguistic content and timbre characteristics of speech while modifying a higher-level attribute of speech: emotion. After EmoAttack training, the emotional utterances can lead the victim model to produce wrong predictions. We conducted backdoor attack experiments on two speech classification tasks. The experimental results demonstrate excellent attack effectiveness of the EmoAttack. Additionally, we verified that different emotions as target labels result in varying efficiency of the trigger, the intense emotions gain better results. The proposed method aims to provide insights into backdoor attacks in the speech domain."}]}