{"title": "Relational Decomposition for Program Synthesis", "authors": ["C\u00e9line Hocquette", "Andrew Cropper"], "abstract": "We introduce a novel approach to program synthesis that decomposes complex functional tasks into simpler relational synthesis sub-tasks. We demonstrate the effectiveness of our approach using an off-the-shelf inductive logic programming (ILP) system on three challenging datasets. Our results show that (i) a relational representation can outperform a functional one, and (ii) an off-the-shelf ILP system with a relational encoding can outperform domain-specific approaches.", "sections": [{"title": "Introduction", "content": "The goal of program synthesis is to automatically generate a computer program from a set of input-output examples (Gulwani et al. 2017). For instance, consider the examples shown in Table 1. Given these examples, we want to learn a program that inserts the letter a at position 2 in the input list to produce the corresponding output list.\nWhilst a functional approach is effective for simple programs, it can struggle when learning programs that require long sequences of functions. For instance, to insert the letter a at position 3, a system could synthesise the program:\nThis program is long and difficult to learn because the search complexity in program synthesis is exponential with the search depth (Gulwani et al. 2017; Witt et al. 2023). Therefore, most existing approaches struggle to learn long sequences of functions.\nRather than learn a sequence of functions to map an input to an output, our key contribution is to show that we can decompose complex functional synthesis tasks into simpler relational synthesis sub-tasks. Specifically, we decompose each training input-output example into a set of facts and try to learn the relations between them.\nTo illustrate this idea, consider the first input-output example in Table 1. We decompose the input list into a set of facts of the form in(I, V), where each fact states that the input value at index I is V:\nSimilarly, we decompose the output list into a set of facts of the form out(I, V), where each fact states that the output value at index I is V:\nWe then try to generalise the out facts given the in facts and additional background knowledge. For instance, given the examples in Table 1, we can learn the rules:\nThe first rule says that the output value at index I is the input value at index I for indices strictly smaller than 2. The second rule says that the output value at index 2 is a. The third rule says that for indices I strictly greater than 2, the output value at index I is the input value at index I \u2013 1. We can learn similar rules for insert at position k by learning different indices.\nAs a second illustrative scenario, consider the task shown in Figure 1, which is from the Abstraction and Reasoning Corpus (ARC) (Chollet 2019). The goal is to learn a function to map the input image to the output image. Rather than treating the input-output example as a single example, we decompose the input and output images into facts about individual pixels. Specifically, we decompose the input image into a set of facts of the form in(X, Y,C), where each fact states that the input pixel at row X and column Y has colour C:\nWe use a set of facts of the form empty(X, Y) to indicate that the input pixel at row X and column Y is empty/uncoloured:\nSimilarly, we decompose the output image into a set of facts of the form out(X, Y,C), where each fact states that the output pixel at row X and column Y has colour C:\nWe then try to generalise the out facts given the in and empty facts and additional background knowledge. For instance, we can learn the rules:\nThe first rule says that any coloured pixel in the input image is the same colour in the output image. The second rule says that any uncoloured pixel in the bottom row of the input image is yellow in the output image. The last rule says that any uncoloured pixel in the input image whose coordinates X and Y sum to H + 1, where H is the height of the image, (i.e. located on the diagonal) is red in the output image. In other words, our relational approach concisely expresses the concept of a line without being given the definition.\nOur relational decomposition approach has many benefits. Foremost, it decomposes a synthesis task into smaller ones by decomposing each training example into multiple examples. Therefore, instead of learning a program to map an entire input list/image at once, we learn a set of rules, each generalising some list elements or image pixels. Crucially, we can independently learn each rule and then combine them, which makes the overall program easier to learn (Cropper and Hocquette 2023). For instance, a functional program for the list function task insert at position 3 requires at least 8 sequential function calls. By contrast, a relational program only needs 3 rules with at most 3 literals each.\nTo demonstrate the effectiveness our idea, we use inductive logic programming (ILP) (Muggleton 1991; Cropper and Dumancic 2022). Given background knowledge and examples, the goal of ILP is to find a program that generalises the examples with respect to the background knowledge. ILP represents the data and learned programs as logic programs and is therefore a relational approach to program synthesis.\nContributions The main contribution of this paper is to show that complex functional program synthesis tasks can be solved more easily if decomposed into relational learning tasks. The second contribution is to show that an off-the-shelf ILP system (Cropper and Morel 2021; Cropper and Hocquette 2023) with a relational representation and a domain-independent bias can achieve high performance compared to domain-specific approaches on three varied and challenging datasets.\nOverall, we make the following contributions:\n\u2022 We introduce a program synthesis approach that decomposes a functional task into multiple relational tasks.\n\u2022 We evaluate our approach using an off-the-shelf ILP system on three challenging datasets, including image reasoning and list functions. Our empirical results show that (i) a relational encoding drastically improves learning performance compared to a standard functional encoding, and (ii) an off-the-shelf ILP system with this relational encoding can outperform domain-specific approaches."}, {"title": "Related Work", "content": "Program synthesis. Deductive program synthesis approaches (Manna and Waldinger 1980) take complete specifications as input and deduce programs that exactly satisfy the specification. By contrast, we focus on inductive program synthesis, which takes partial specifications as input, typically input-output examples (Gulwani et al. 2017). For brevity, any subsequent mention of program synthesis refers to inductive program synthesis.\nLLMs. Large language models (LLMs) prompted to directly predict outputs perform poorly compared to humans and state-of-the-art approaches on the ARC dataset (Mirchandani et al. 2023; Xu et al. 2024). Some approaches combine LLMs with human assistance, such as using a human-written natural-language description of the target function as a hint for the LLM (Tang et al. 2024). For instance, Wang et al. (2024) prompt an LLM to generate multiple hypotheses written in natural language. A human annotator then selects the correct ones and an LLM is prompted to implement the selected natural language hypotheses as Python programs. By contrast, we do not use humans to select correct hypotheses or to provide textual descriptions of the solutions. Directly comparing symbolic program synthesis approaches to LLM approaches is difficult. For instance, as Wang et al. (2024) state, LLMs are trained on extensive corpora, and might have already seen the test data. Moreover, due to their high resource requirements, most work using LLMs on ARC only look at subsets of the tasks. For instance, Wang et al. (2024) only look at 100/400 problems because of the \"high cost of GPT4\". By contrast, our approach is resource-efficient and runs on a single CPU.\nDomain specific-approaches. There are many domain-specific approaches to program synthesis, such as for string transformations (Gulwani 2011), 3D shapes (Tian et al. 2019), list functions (Rule 2020), or visual reasoning (Wind 2022; Xu, Khalil, and Sanner 2023; Lei, Lipovetzky, and Ehinger 2024). By contrast, our approach is versatile and generalises to multiple domains. Moreover, we use an off-the-shelf general-purpose ILP system."}, {"title": "Problem Setting", "content": "We describe our problem setting.\n3.1 Program Synthesis\nAn example is a pair i\u2192 o formed of an input i and an output o. We denote as X an example space, i.e. a set of examples. We denote as H a hypothesis space, i.e. a set of programs. We define a synthesis task:\nDefinition 1 (Synthesis task) A synthesis task is a tuple (E,H) where E \u2264 X is a set of examples.\nGiven a program p and an input i, we denote as [p(i)] the result of executing p on i. We define a synthesis solution:\nDefinition 2 (Synthesis solution) For a synthesis task (E,H), a program p\u2208 His a synthesis solution when p satisfies every example in E, i.e. [p(i)] = o for every (i\u2192 o) \u2208 E.\n3.2 Inductive Logic Programming\nWe decompose a synthesis task into an ILP task. We define the ILP problem. We assume familiarity with logic programming (Lloyd 2012) but have included a summary in the appendix. We restate key terminology. A clause is a set of literals. A definite clause is a clause with exactly one positive literal. We use the term rule synonymously with definite clause. A definite program is a set of definite clauses with the least Herbrand model semantics. We refer to a definite program as a logic program.\nWe first define an ILP task:\nDefinition 3 (ILP task) An ILP task is a tuple (E+, \u0415\u00af, \u0412,\u041d), where E+ and E\u00af are sets of ground atoms denoting positive and negative examples respectively, B is a logic program denoting the background knowledge, and H is a hypothesis space.\nWe formulate the ILP problem in the learning from entailment setting (Raedt 2008). Given an ILP task, we define an ILP solution:\nDefinition 4 (ILP solution) For an ILP task (E+, E, B, H), a program p \u2208 H is an ILP solution when p entails every example in E+ (Ve \u2208 E+,p\u222a B |= e) and no example in E\u00af (Ve\u2208 E\u00af, pUB\u29e3 e).\n3.3 Relational Decomposition\nWe define a relational decomposition function:\nDefinition 5 (Relational decomposition function) A relational decomposition function is a function which maps a synthesis task (E,H) to an ILP task (E+, E\u00af, B, H').\nIn the next section, we empirically show that we can encode a program synthesis task into an ILP task using a simple decomposition function, and that we can achieve a substantial improvement in learning performance through this change of representation."}, {"title": "Evaluation", "content": "To test our claim that a relational representation can outperform a functional one, our evaluation aims to answer the question:\nQ1 How does our relational representation compare against a standard state/functional representation?\nTo answer Q1, we compare the learning performance of an ILP system with a relational representation against a state/-functional representation. We use the same ILP system so the only difference is the representation.\nTo test our claim that our relational decomposition approach is general-purpose, our evaluation aims to answer the question:\nQ2 How does a general-purpose ILP system with a relational representation compare against domain-specific approaches?\nTo answer Q2, we compare the learning performance of a general-purpose ILP system with a relational representation against domain-specific approaches."}, {"title": "Datasets", "content": "We use the following diverse and challenging datasets.\n1D-ARC. The ID-ARC dataset (Xu et al. 2024) is a one-dimensional adaptation of ARC. It has 18 tasks, each with 3 training examples and 1 testing example. Figure 2 shows an example task where the goal is to copy the blue pixels symmetrically with respect to the red pixel.\nARC. The ARC dataset (Chollet 2019) evaluates the ability of learning systems to perform abstract reasoning and problem-solving from a small number of examples. The goal of each task is to transform two-dimensional input images into their corresponding output images. The tasks are widely varied and include for instance pattern recognition, geometric transformations, colour manipulation, or counting. Image sizes range between 1x1 and 30x30 pixels. Input and output images can have different sizes. Each pixel is one of 10 different colours. We use the training subset of the original dataset, which includes 400 tasks, each with 2 to 10 training examples and 1 to 3 testing examples\u00b9.\nList functions. The list functions dataset (Rule 2020; Rule et al. 2024) evaluates human and machine learning ability. The goal of each task is to identify a function that maps input lists to output lists, where list elements are natural numbers. The tasks range from basic list functions, such as duplication and removal, to more complex functions involving conditional logic, arithmetic, and pattern-based reasoning. The dataset contains 250 tasks, each with 11 examples."}, {"title": "Systems", "content": "We use the following systems\u00b2.\nPOPPER. We use the ILP system POPPER (Cropper and Morel 2021) because it can learn large programs, especially programs with many independent rules (Cropper and Hocquette 2023).\nARGA. ARGA (Xu, Khalil, and Sanner 2023) is an object-centric approach designed for ARC. ARGA abstracts images into graphs and then searches for a program using a domain-specific language based on the abstracted graph representation. ARGA uses 15 operators, such as to rotate, mirror, fill, or hollow objects.\nHL. Hacker-Like (HL) (Rule 2020; Rule et al. 2024) is an inductive learning system designed to reproduce human learning using hacker-like techniques to revise code. HL uses"}, {"title": "Bias and Representation", "content": "To evaluate our relational approach, we use a purposely simple bias formed of the decomposed training examples and basic relations for arithmetic addition and value comparison. We describe our bias and decomposition function for each domain.\n1D-ARC. We decompose a one-dimensional image into a set of pixel facts. The fact in(I,C) holds if the pixel at index I in the input image has colour C. The fact empty(I) holds if the pixel at index I is a background pixel (an uncoloured pixel). The fact out(I,C) holds if the pixel at index I in the output image has colour C. We allow integers between 0 and 9, representing the 10 different colours, as constant symbols.\nARC. We decompose a two-dimensional image into a set of pixel facts. The fact in(X,Y,C) holds if the pixel at row X and column Y in an input image has colour C. The fact empty(X, Y) holds if the pixel at row X and column Y is a background pixel (an uncoloured pixel). The fact out(X, Y,C) holds if the pixel at row X and column Y in an output image has colour C. We allow integers between 0 and 9 as constant symbols. We use the relations height/1, width/1, midrow/l, midcol/l to identify the image height and width, the middle row and middle column respectively. We also use the relation different/2 to determine colour inequality.\nList functions. We decompose a list into a set of element facts. The fact in(I, V) holds if the element at index I in the input list has value V. The fact end(I) denotes the end position of an input list. The fact out(I, V) holds if the element at index I in the output list has value V. Following Rule (2020), we allow integers between 0 and 9 for the first 80 problems and integers between 0 and 99 for the remaining problems.\nFunctional representation. For the functional representation, we follow Rule (2020) and use the relations cons/3, head/2, tail/2, and empty/l to manipulate lists. We also use the same arithmetic relations and constant symbols as in the relational representations."}, {"title": "Methods", "content": "We measure predictive accuracy as the proportion of correct predictions on test data. For our relational decomposition approach, a prediction is correct only if all the elements/pixels in the output are correct. We repeat each learning task 3 times and calculate the mean and standard error. The error bars in the figures represent the standard error. We use a m6a AWS instance with AMD EPYC 7R13 processor. Each system uses a single CPU. For the list functions dataset, we perform leave-one-out cross-validation. For tasks 81 to 250 in the list functions dataset, due to the large number of constant values, we sample 10,000 negative examples per task.\nReproducibility. The evaluation data and the code to reproduce the results are included as appendix and will be made"}, {"title": "Results", "content": "Q1: How does our relational representation compare against a standard state/functional representation? Figures 3, 4, 5, and 6 show the results. They show that our relational representation consistently outperforms the functional representation on all three domains and for all maximum learning times. A McNeymar's test confirms the statistical significance (p < 0.01) of the difference.\nOne reason for the performance improvement is that our relational approach decomposes a complex functional task into multiple relational subtasks. For instance, consider the list functions task 187, shown in Figure 7. The goal is to append the element 0 to the input list, then concatenate the input list to the input list. For this task, our approach learns the rules:\nThe first rule says that the out value at index I is the in value at index I. The second rule says that the out value at index E is 0, where E is the index of the first empty position in the input list. The last rule says that the out value at index I is the in value at index I -1-E, where E is the index of the first empty position in the input list. In other words, our approach learns one rule for copying the input list, another rule for adding a 0 to its end, and a third rule for appending the input list.\nSimilarly, consider the ARC task 253bf280 shown in Figure 8. The goal is to colour in green pixels in between two blue pixels in the input image. Our approach learns the rules:\nThe first rule says that an out pixel is blue if it is blue in the input. The second rule says that an out pixel is green if it is between two blue pixels in the same row in the input. The third rule says that an out pixel is green if it is between two blue pixels in the same column in the input. In other words, our approach learns three rules: one for the permanence of blue pixels, one for horizontal lines, and one for vertical lines. Crucially, our approach learns these rules independently, as each rule generalises a subset of the decomposed examples. Moreover, our approach learns this perfect solution without being given the definition of a line.\nAnother reason for the performance improvement is that our relational approach can express programs compactly. For instance, consider the ARC task 6d75e8bb, shown in Figure 9.\nPOPPER with our relational representation struggles to learn solutions for some tasks due to our purposely simple bias. For instance, the goal of the ARC task 23b5c85d is to learn a program that extracts the smallest rectangle. However, we do not include a counting mechanism so POPPER cannot compare the size of objects. We expand on this limitation when discussing Q2.\nOverall, these results suggest that the answer to Q1 is yes: our relational representation can outperform a functional one.\nQ2: How does a general-purpose ILP system with a relational representation compare against domain-specific approaches? Figures 3, 4, 5, and 6 show the results. They show that the general-purpose ILP system POPPER with our relational representation outperforms domain-specific approaches on two of the three datasets tested. We discuss the results for each dataset in turn.\n1D-ARC ARGA outperforms our relational encoding on the ID-ARC dataset (94% vs 67% predictive accuracy with a maximum learning time of 20 mins). This result is unsurprising because ARGA is designed for image reasoning tasks and uses domain-specific background knowledge, such as the ability to measure the size of an object, and to fill, mirror, and hollow objects. This background knowledge is particularly useful for tasks such as fill, mirror, and hollow. By contrast, our relational representation is not designed for these tasks and does not include domain-specific operators.\nOur relational encoding significantly outperforms HL on the ID-ARC dataset (67% vs 0% predictive accuracy with a maximum learning time of 20 mins). Although these tasks involve identifying list functions, HL struggles on them. We asked the authors of HL for potential explanations and they explained that HL does not perform as well on problems requiring a recursive solution as it does on non-recursive problems. For instance, consider the task denoise (Figure 10). If represented functionally, this task requires learning a recursive solution, which is difficult for HL. By contrast, our approach learns the non-recursive rule:\nThis rule says that an out pixel at index I has colour C if there are two adjacent pixels with colour C in the input image (at indices I1 and I1 + 1), where one of these pixels is at index I (if I2 = 0, then I1 = I, and if I2 = 1, then I1 + 1 = I), i.e. the pixel at index I has an adjacent pixel with the same colour. This rule generalises perfectly to the test data. Notably, unlike ARGA and BEN, which both use a denoise operator, our approach can learn this rule without domain-specific operators.\nFor further comparison, Wang et al. (2024) show that GPT-3.5 and and GPT-4 achieve an accuracy of 23% and 61% respectively when prompted to generate a Python program for these tasks. Our approach achieves similar performance (61%) with a maximum learning time of only 1 min and better performance (65%) with a maximum learning time of 10 mins.\nARC POPPER with our relational representation outperforms ARGA (19% vs 8% predictive accuracy with a maximum learning time of 20 mins) on the ARC dataset. ARGA struggles, partly because it assumes that the input and output images have identical sizes, so it cannot solve 138/400 tasks which have different sizes.\nGiven the poor results of HL on the 1D-ARC dataset, we exclude it from the comparison on ARC dataset. Moreover, HL assumes that an input and output are one-dimensional lists so is not directly usable on ARC.\nFor further comparison, LLMs struggle when directly prompted to predict ARC outputs, with various reported accuracies, including 14% (Mirchandani et al. 2023), and 17% (Wang et al. 2024). Wang et al. (2024) find improvements in LLM performance via hypothesis search, where GPT-4 achieves an accuracy of 18% or 23%, depending on the specific LLM. However, these results are incomparable to ours as they only evaluate a subset of the dataset due to prohibitively expensive evaluation costs.\nAmong non-LLM approaches that evaluate the whole ARC dataset, as far as we are aware, the best performing approach is ICECUBER (Wind 2022), which uses a 142 handcrafted"}, {"title": "Conclusions and Limitations", "content": "We have introduced a novel approach to program synthesis that decomposes complex functional tasks into easier relational learning tasks. Our empirical results on image reasoning and list function tasks show that our relational decomposition approach substantially outperforms standard functional approaches. Moreover, we have shown that an off-the-shelf ILP system using our relational representation with little domain-specific bias and low training times is competitive with, and in some cases outperforms, highly engineered domain-specific approaches. More broadly, our results show that simply looking at a problem differently can lead to big performance improvements.\nLimitations\nBias. We use a purposely simple bias formed of raw input (list elements or pixels) and basic arithmetic relations. However, our simple bias is limiting for some tasks, such as those that require counting. Future work should expand our bias with more general-purpose concepts, such as counting.\nILP system. We have shown that an off-the-shelf ILP system is competitive with domain-specific approaches. However, this system struggles on some tasks, where there is a good solution in the search space but the system cannot find it within the time limit. This limitation is due to the system we use and not our representation. However, because our relational decomposition approach is system-agnostic, we could use a different ILP system. Moreover, because we use an off-the-shelf ILP system, our approach naturally benefits from any developments in ILP."}]}