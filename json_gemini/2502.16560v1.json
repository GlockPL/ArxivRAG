{"title": "Analysis of Emotion in Rumour Threads on Social Media", "authors": ["Rui Xing", "Boyang Sun", "Kun Zhang", "Timothy Baldwin", "Jey Han Lau"], "abstract": "Rumours in online social media pose significant risks to modern society, motivating the need for better understanding of how they develop. We focus specifically on the interface between emotion and rumours in threaded discourses, building on the surprisingly sparse literature on the topic which has largely focused on emotions within the original rumour posts themselves, and largely overlooked the comparative differences between rumours and non-rumours. In this work, we provide a comprehensive analytical emotion framework, contrasting rumour and non-rumour cases using existing NLP datasets to further understand the emotion dynamics within rumours. Our framework reveals several findings: rumours exhibit more negative sentiment and emotions, including anger, fear and pessimism, while non-rumours evoke more positive emotions; emotions are contagious in online interactions, with rumours facilitate negative emotions and non-rumours foster positive emotions; and based on causal analysis, surprise acts as a bridge between rumours and other emotions, pessimism is driven by sadness and fear, optimism by joy and love.", "sections": [{"title": "Introduction", "content": "In part due to the ubiquity of edge devices like mobile phones, the major of the world's population now has access to the internet.\u00b9 This increasing ease of access and interaction through online social media has brought both opportunities and challenges. One significant challenge is the rapid spread of rumours. Rumours on online social media have become a major threat to society (Tian, Zhang, and Lau 2022; Zubiaga et al. 2015; Kochkina, Liakata, and Zubiaga 2018; Ma, Gao, and Wong 2017). The circulation of unsubstantiated rumours has impacted a large group of people, with consequences ranging from seeding skepticism and discrediting science, to endangering public health and safety. For example, during COVID-19, an Arizona man died, and his wife was hospitalized after ingesting a form of chloroquine in an attempt to prevent the disease. Additionally, 77 cell phone towers were set on fire due to conspiracy theories linking 5G networks to the spread of COVID-19 (Cui and Lee 2020). Recent advancements in Large Language Models (LLM) and generative AI have exacerbated this phenomenon, creating an urgent need to understand and better deal with rumours on social media (Chen and Shu 2024).\nPrevious research has highlighted several factors driving the spread of rumours on social media (Zollo et al. 2015). These factors often relate to the characteristics of publishers; for instance, users with more followers can reach wider audiences, and the number of reshares and likes reflects users' beliefs and attitudes toward a post (Zaman, Fox, and Bradlow 2013; Vosoughi, Roy, and Aral 2018). Other studies have focused on the online diffusion of specific topics, such as elections or disasters (Starbird 2017; Domenico et al. 2013), and other harmful online social contents (Aleksandric et al. 2024).\nEmotions have a strong influence on human behavior in both offline and online settings (Zollo et al. 2015; Herrando and Constantinides 2021; Ekman 1992). They shape the type of information users seek, how they process and remember it, and the judgments and decisions they make. Misinformation is often associated with high-arousal emotions such as anger, sadness, anxiety, surprise, and fear (Liu et al. 2024b). Rumours conveying these emotions are more likely to generate higher numbers of shares and exhibit long-lived, viral patterns (Pr\u00f6llochs, B\u00e4r, and Feuerriegel 2021b). However, existing research on emotions in misinformation analysis is fragmented, focusing primarily on the emotions within the original rumour posts themselves and often overlooking the comparative differences between rumours and non-rumours (Ferrara and Yang 2015; Zollo et al. 2015). In this work, we address this gap by introducing a systematic analysis of various aspects of emotion, contrasting the emotional patterns in rumour and non-rumour content on social media. Using popular NLP rumour detection datasets, we provide new insights into the emotional dynamics of rumour and non-rumour data."}, {"title": "Data", "content": "We use three rumour datasets in this work, namely: PHEME (Zubiaga et al. 2015; Kochkina, Liakata, and Zubiaga 2018), Twitter15, and Twitter16 (Ma, Gao, and Wong 2017):"}, {"title": "Framework for Analyzing Emotion", "content": "In this section, we present our framework for analyzing emotion. We first establish a basic understanding of emotion polarity by determining the sentiment valence of each root tweet and comment. We then use multi-label emotion detection to predict the emotion categories associated with each post. Based on this data, we explore the interactive nature of emotions, by identifying common patterns in emotion transition pairs between temporally-adjacent posts. Finally we investigate the emotional trajectory within threads to understand how emotional intensity and type shift over time, by aggregating the predicted labels for posts at each time stamp in a given thread. As part of this, we contrast rumour with non-rumour threads, to gain a holistic understanding of emotional expression in rumours and non-rumours on Twitter."}, {"title": "Affective Computing: Automatic Emotion Detection", "content": "Manually annotating emotions is both costly and time-consuming, so we use an LLM-based emotion detection model, EmoLLM (Liu et al. 2024a), which is specifically designed for sentiment analysis and emotion detection. The model was instruction-tuned on SemEval 2018 Task1 using a comprehensive emotion labeling scheme grounded in established theoretical frameworks. We prompt the model to perform Valence Ordinal Classification (V-oc), Emotion Classification (E-c), and Emotion Intensity regression (E-i). Detailed prompts are shown in Table 1."}, {"title": "Categorical Emotion Labeling Scheme", "content": "Numerous emotion label sets have been proposed (Ekman 1992; Plutchik 1980; Russell 1980). According to Ekman (1992); Plutchik (1980), certain emotions, such as joy, fear, and sadness, are considered more fundamental than others, both physiologically and cognitively. The Valence-Arousal-Dominance (VAD) model (Russell 1980) categorizes emotions within a three-dimensional space of valence (positivity-negativity), arousal (active-passive), and dominance (dominant-submissive). Inspired by Mohammad et al. (2018), we incorporate elements from both basic emotion theories and the VAD model, and further ground EmoLLM emotion predictions to develop the following emotion label schemes: (1) neutral or no emotion; (2) negative emotions: anger (also includes annoyance and rage), disgust (also includes disinterest, dislike, and loathing), fear (also includes apprehension, anxiety, and terror), pessimism (also includes cynicism, and no confidence), sadness (also includes pensiveness and grief); 3) positive emotions: joy (also includes serenity and ecstasy), love (also includes affection), optimism (also includes hopefulness and confidence), anticipation (also includes interest and vigilance), surprise (also includes distraction and amazement) and trust (also includes acceptance, liking, and admiration)."}, {"title": "Emotion Polarity: Sentiment Valence", "content": "To understand the basic emotion polarity expressed in rumour and non-rumour content, we begin with sentiment valence analysis. Sentiment valence aims to capture the overall emotional tone conveyed by a post, in terms of how positive or negative it is (Liu et al. 2024b). We frame the sentiment valence task as ordinal regression (Mohammad et al. 2018). As shown in Table 1, for a given tweet post, we classify it into one of seven ordinal levels of sentiment intensity, spanning varying degrees of positive and negative valence, that best represents the tweeter's mental state. The tweet posts within a thread can be divided into two categories: root tweets, which are posted by the publisher, and follow posts, which include all subsequent replies under the root post. We begin by conducting sentiment valence analysis on each post within the thread conversation. For each category, we compute the mean sentiment valence to enable further investigation into the specific emotions associated with different sentiment valences over a thread."}, {"title": "Emotion Distribution", "content": "Following sentiment valence analysis, we then examine specific emotions and their distribution in rumour and non-rumour tweet posts. Motivated by the fact that a certain tweet might exhibit more than one emotion, we frame the task as multi-label emotion detection problem. As shown as V-oc in Table 1, given a tweet, we classify it into one of seven ordinal classes, corresponding to various levels of positive and negative sentiment intensity. To reduce noise from automatic emotion detectors, we take the top-three predicted emotions for each tweet. We then aggregate and plot the emotion distribution to provide an overview of dominant emotional trends across the rumour and non-rumour posts. Given that the follow posts make up the majority of the data compared to the root posts, we will focus on using follow posts in our next analysis."}, {"title": "Emotion Transitions", "content": "Emotions are contagious and highly interactive (Ferrara and Yang 2015). When publishers write tweets that convey their emotions, readers are likely to respond with emotional reactions of their own (Ferrara and Yang 2015; Zollo et al. 2015). In this part, we model this interactive nature of emotions in the form of emotion transition pairs, which are built from two chronologically-adjacent tweets. In each pair, the first element represents the emotion inferred from the initial content published at a given time, and the second element represents the emotion inferred from the reply content published immediately after. For example, if the first tweet exhibits joy trust and anticipation, and the second tweet shows anger, disgust and surprise, we form the pairs (joy, anger), (joy, disgust), (joy, surprise), (trust, surprise), (trust, surprise), (trust, disgust), (anticipation, anger), (anticipation, surprise) and (anticipation, disgust). We create transitions for all combinations of emotion pairs and explore the likelihood of emotion transition pairs occurring in rumour and non-rumour content. Exploring emotion transitions allows us to understand the emotional flow in social media conversations and uncover typical patterns of rumour and non-rumour content, and any differences between the two."}, {"title": "Emotion Trajectories", "content": "We explore the cumulative trajectory of emotion over time to observe how emotions evolve during the conversational thread. We collect all detected emotion labels for each tweet from both rumour and non-rumour content, then track cumulative emotion counts at each chronological step. Finally, we visualize these trends and apply regression models to analyze the growth of emotions over time. This temporal analysis reveals how emotions accumulate or intensify across time, offering insight into the trajectory of emotions in rumour and non-rumour content."}, {"title": "Causal Relationship of Emotions in Rumour & Non-Rumour Threads", "content": "To gain a deeper insight into the relationship between rumours and the emotions underlying them, we extend our analysis beyond statistical correlation by conducting a causal analysis. Specifically, we apply the Peter-Clark (PC) algorithm (Spirtes, Glymour, and Scheines 2000), a classical constraint-based causal discovery algorithm on the three merged datasets.\nUncovering causal relations between variables of interest is never an easy problem. Under the fundamental assumption of causal Markov condition that a variable is conditionally independent of all its non-effects given its direct cause, faithfulness ensures that the casual graph exactly encodes the independence and conditional independence relations."}, {"title": "Algorithm 1: PC Algorithm", "content": "1: Input: Data X, significance level a\n2: Output: Completed Partially Directed Acyclic Graph\n(CPDAG)\n3: Initialize a complete undirected graph G with all variables as nodes.\n4: Step 1: Skeleton Identification\n5: for each pair of variables (X, Y) in G do\n6: Find the subset $S \\subseteq Adj(X,G) \\backslash {Y}$ such that\n$X \\perp Y \\vert S$ with significance a.\n7: if such a subset S exists then\n8: Remove the edge X - Y from G.\n9: end if\n10: end for\n11: Step 2: Edge Orientation\n12: for each triple of variables (X, Y, Z) in G where X\nZ-Y and X, Y are not adjacent do\n13: if Z \\notin S for all separating sets S for X and Y then\n14: Orient as X $\\rightarrow$ Z $\\leftarrow$ Y (identify a collider).\n15: end if\n16: end for\n17: while possible do\n18: for each edge (X - Y) in G do\n19: if there exists a directed path X $\\rightarrow$ $\\dots \\rightarrow$ Z\nsuch that Z - Y then\n20: Orient as X $\\rightarrow$ Y (acyclicity rule).\n21: else if orienting X - Y as X $\\rightarrow$ Y creates a new\nv-structure then\n22: Orient as X $\\rightarrow$ Y (v-structure rule).\n23: end if\n24: end for\n25: end while\n26: return the CPDAG representing the equivalence class\nof causal graphs."}, {"title": "Results and Discussion", "content": "In this section, we apply our framework to the collected data, and present experiment results and discuss our findings."}, {"title": "Emotion Polarity: Sentiment Valence", "content": "We present the sentiment valence ordinal regression results in Table 2. The numbers are balanced by random down-sampling, i.e. rumour and non-rumour, true rumour and false rumour both have equal numbers of posts. As shown in the table, sentiment in rumour root posts and comments is significantly more negative than that in non-rumours across all datasets and settings (p < 0.05). This means both publishers and commenters engaged in the thread exhibit a more negative mindset towards rumour content. Compared with rumour posts at the root level, comment posts exhibit more negative sentiment for all datasets. Additionally, we break down the rumour data into true, false, and unverified rumours according to their original labels in the dataset. Interestingly, we found that unverified content exhibits more negative sentiment compared to both true and false rumours in the PHEME dataset, as well as in the root posts of Twitter15 and the U vs. T setting in Twitter16. Given that sentiment is more negative in comments and they form the main part of the conversation, we conduct the following experiments using only comments."}, {"title": "Emotion Distribution", "content": "In order to further understand emotions expressed in rumour and non-rumour content, we present the emotion distribution results in Figures 1 to 3. Overall, we observe a sharper distribution in emotions like anger, disgust, neutral, optimism, and joy. In the PHEME, Twitter15, and Twitter16 datasets, rumour posts tend to show more negative emotions such as anger, disgust, fear, and sadness, while non-rumour posts display more positive emotions like trust, optimism, joy and love. We present emotions statistics in Table 3."}, {"title": "Emotion Transitions", "content": "We present emotion transition results for each dataset in Figures 4 to 6. The computation was conducted as follows: for each emotion transition pair, we compute the probability based on pair frequency. In order to better reveal the gap between rumours and non-rumours, we define the difference of Emotion Transition (ET) probability as follows:\nEmotion Transition (ET): Let's assume there are N emotions (N = 12 in our case), let ET(i, j) represent the probability of transitioning from emotion i (i.e. joy) to emotion j (i.e. anger), where 0 < i < N and 0 < j < N. This probability is calculated based on the frequency of all pairs that starts with emotion i.\n$ET(i, j) = \\frac{Freq(i, j)}{\\sum_{k=0}^{N} Freq(i, k)}$\nEmotion Transition Delta ($\\Delta$ET) Define $\\Delta$ET(i, j) as the difference in emotion transition probabilities between rumours and non-rumours for the pair (i, j):\n$\\Delta ET(i, j) = \\frac{ETrumour (i, j) - ETnon-rumour (i, j)}{ETrumour (i, j)}$\nThen we visualize it using a heatmap, e.g. in Figure 5, the cell 0.55 in the last row of the third column has is dark red in color, indicating that the emotion transition pair (love, fear) appears more frequently in rumour than non-rumour comments in Twitter15. Overall, we observe larger emotion transition probability mass in positive-positive and negative-negative emotion transitions. This indicates that emotions are contagious, aligning with psychological findings (Goldenberg and Gross 2019; Herrando and Constantinides 2021). Contrasting rumour and non-rumour comments, we observe"}, {"title": "Emotion Trajectory", "content": "Figures 7 to 9 illustrate the cumulative emotion across each dataset over time. At each chronological step, the counts represent the total number of observed emotions. Generally, we see a strong linear trend across datasets for all emotions. To better capture the rate of growth for each emotion, we apply linear regression and present the slopes in Table 5. From the table, it is apparent that negative emotions tend to grow faster in rumour posts than in non-rumour posts across all datasets, while positive emotions grow faster in non-rumour posts."}, {"title": "Causal Analysis", "content": "The causal relationships revealed in Figure 10 demonstrate several key patterns. First, we find out that the fact that a given thread is a rumour is not directly connected with other emotions. Specifically, the rumour has to rely on the emotion of surprise as a bridge to interact with other emotions, namely, rumour $\\perp$ Fear | Surprise and rumour $\\perp$ Anticipation|Surprise. The change in the distribution of the rumour does not influence other emotions except surprise. This aligns with cognitive basis of rumour transmission, where surprising or counterintuitive information tends to capture attention and facilitate rumour spreading (Knapp 1944; Allport and Postman 1947). Second, pessimism is primarily influenced by negative emotions (sadness and fear), while optimism is causally influenced by positive emotions (joy, love, and trust). Notably, there's undirected edge between anger and disgust, this relationship aligns with our previous findings that both rumour and non-rumour posts exhibit intense expressions of these emotions.\nThere are also a few counterintuitive findings, including sadness leading to joy, joy causing pessimism, and the causal relationship between disgust and love. We conducted a qualitative analysis of the 50 samples and found there are several possible reasons for this: (1) there is a complex interplay of emotions in social media interactions, where emotional responses are shaped by context and individual perspectives. For example, we had one response where joy was detected, \"this tweet gives me hope that she may write an eighth\" to the post \u201conce again, jk rowling is not working on an eighth harry potter book.\u201d where sadness is detected. Sadness can sometimes lead to joy when people use humor or shared memories to find solace in sadness, which serves as a coping mechanism for processing uncomfortable or shocking topics. Similarly, expressions of joy can paradoxically evoke pessimism in certain contexts, as the same post can be interpreted in vastly different ways depending on the readers' emotional state, cultural background, or personal experiences. The dual causal relationship between disgust and love further emphasizes the complexity of emotions expressed in text. A post that initially provokes disgust might also elicit admiration or affection when audiences recognize an underlying message of authenticity, vulnerability, or humor. (2) Moreover, the analysis reveals challenges in accurately interpreting emotions through automatic labeling methods. Sarcasm and humor are frequently misclassified, with sarcasm often mistaken for joy due to its seemingly optimistic wording. The lack of contextual information leads to noise and inaccuracies in emotional categorizations. (3) The complexity of social media participants also contributes to this. Some users engage with posts for self-serving purposes, such as promoting their brand or gaining visibility, rather than genuinely responding to the content. These interactions together add a layer of noise to the results, making it even more challenging."}, {"title": "Related Work", "content": "The definition of rumour is generally complicated and varies from one publication to another. Some early work treated rumour as information that is false (Cai, Wu, and Lv 2014). Most recent definitions of rumours are \"unverified and instrumentally relevant information statements in circulation\" (DiFonzo and Bordia 2007) and \u201cunverified informa-"}, {"title": "tion at the time of the posting\"", "content": "This definition also aligns with the concept in recent work (Zubiaga et al. 2018, 2015; Tian, Zhang, and Lau 2022) and the Oxford English Dictionary, which defines the rumour as \u201can unverified or unconfirmed statement or report circulating in a community\u201d.\u00b2\nExisting research highlights the significant role of emotions in understanding general misinformation, mostly fake news. Research has found relationships exist between negative sentiment and fake news, and between positive sentiment and genuine news (Zaeem et al. 2020). Fake news also expresses a higher level of overall emotion, negative emotion, and anger than real news (Zhou, Tao, and Zhang 2022). Negative emotions like sadness and anger can serve as indicators of misinformation (Prabhala and Bose 2019). The role of emotions in rumours has been recognized since the Second World War, reflecting the interactive and community-driven nature of rumour spreading. Knapp's taxonomy (Knapp 1944) of rumours categorizes them into three types, each deeply embedded with emotions: (1) 'pipedream' rumours, which evoke wishful thinking; (2) 'bogy' rumours, which heighten anxiety or fear; and (3) 'wedge-driving' rumours, which incite hatred. This taxonomy underscores how rumours are inherently embedded with emotional undercurrents.\nRecent research on emotion in rumours largely focuses on their role in spreading behaviour, some studies have used questionnaires to gather participants' reactions to specific rumours (Zhang et al. 2022; Rijo and Waldzus 2023; Ali et al. 2022), while others have employed cascade size and lifespan as indicators (Pr\u00f6llochs, B\u00e4r, and Feuerriegel 2021b,a). Key findings of such work include: rumours conveying anticipation, anger, trust, or offensiveness tend to generate more shares, have longer lifespans, and exhibit higher virality (Pr\u00f6llochs, B\u00e4r, and Feuerriegel 2021b). Additionally, false rumours containing a high proportion of terms reflecting positive sentiment, trust, anticipation, anger, or condemnation are more likely to go viral (Solovev and Pr\u00f6llochs 2022; Pr\u00f6llochs, B\u00e4r, and Feuerriegel 2021a). However, existing research has notable gaps: it often focuses on isolated aspects of emotions in rumours, primarily identifies correlations rather than causality, and tends to examine rumour data in isolation. To address these gaps, we aim to propose a comprehensive emotional analytical framework that integrates multiple emotion-related tasks, contrasting rumour and non-rumour content with the aim to enhance our understanding of emotions and, ultimately, to improve rumour detection in online social media."}, {"title": "Conclusion", "content": "In this work, we presented a analytical emotion framework for online rumours. We make the use of EmoLLM for automatic emotion detection and ground its predictions to the categorical emotion labeling scheme. The framework analyzes the emotion from various aspects, from simply emotion polarity (sentiment valence), emotion distribution, emotion transition and trajectory, we also analyze the causal relationship between rumour label and emotions. The key findings include: compared with non-rumour contents, rumour are significantly more negative in sentiments, containing more negative emotions like anger, fear and pessimism; emotions are contagious in online social context, rumour contents usually trigger negative responses and non-rumours tend to receive positive ones; Cumulative emotion regression coefficient showed that negative emotions grow significantly faster in rumours comments as positive emotions in non-rumour ones; the rumour tweets are not directly connected with other emotions and rely on the emotion surprise as a bridge. Pessimism is primarily influenced by negative emotions (sadness and fear), while optimism is causally influenced by positive emotions (joy, love, and trust), anger and disgust exhibit bidirectional causation. By presenting the framework, we hope to facilitate research in more comprehensive and fine-grained study in emotion in online rumour contents and better detection techniques."}, {"title": "Limitations and future work", "content": "This work also faces several challenges and limitations: 1) We rely on EmoLLM as our automatic emotion detection tool for all emotion-related tasks. While it is generally efficient and effective, it exhibits inaccuracies in analyzing complex online discussions, such as those involving sarcasm; 2) Although we have access to the chronological order of tweets within conversations, explicit conversation structures are not available for all data; and 3) The datasets used in this study are limited to English textual rumour data. Future work should explore multilingual and multimodal content in rumour conversations to provide a more comprehensive analysis."}, {"title": "Ethical Impacts", "content": "Analyzing emotions in rumour detection presents ethical challenges, such as privacy invasion, interpretative biases, risks of emotional manipulation, amplification of harmful content, and cultural insensitivity. To address these concerns, we advocate for responsible and transparent use, prioritizing individual privacy and freedom of expression, with clear communication and opt-out options for users. This research was conducted independently using publicly available datasets, and the framework was developed to enhance academic understanding and combat misinformation online for the public good."}, {"title": "License of Artifacts", "content": "We list the licenses of different artifacts used in this paper: PHEME\u00b3 is under CC-BY license, Twitter15 and Twitter 16\u2074 are under MIT License, EmoLLM\u2075 is under MIT License and Huggingface Transformers\u2076 is under Apache License 2.0). Our source code and annotated data will be under MIT license."}, {"title": "Ethics Checklist", "content": "1. For most authors...\n(a) Would answering this research question advance science without violating social contracts, such as violating privacy norms, perpetuating unfair profiling, exacerbating the socio-economic divide, or implying disrespect to societies or cultures? Yes\n(b) Do your main claims in the abstract and introduction accurately reflect the paper's contributions and scope? Yes, see An Analytical Emotion Framework and Conclusion Section.\n(c) Do you clarify how the proposed methodological approach is appropriate for the claims made? Yes, see An Analytical Emotion Framework Section.\n(d) Do you clarify what are possible artifacts in the data used, given population-specific distributions? Yes\n(e) Did you describe the limitations of your work? Yes\n(f) Did you discuss any potential negative societal impacts of your work? Yes\n(g) Did you discuss any potential misuse of your work? Yes\n(h) Did you describe steps taken to prevent or mitigate potential negative outcomes of the research, such as data and model documentation, data anonymization, responsible release, access control, and the reproducibility of findings? Yes\n(i) Have you read the ethics review guidelines and ensured that your paper conforms to them? Yes\n2. Additionally, if your study involves hypotheses testing...\n(a) Did you clearly state the assumptions underlying all theoretical results? Yes\n(b) Have you provided justifications for all theoretical results? Yes\n(c) Did you discuss competing hypotheses or theories that might challenge or complement your theoretical results? Yes\n(d) Have you considered alternative mechanisms or explanations that might account for the same outcomes observed in your study? Yes\n(e) Did you address potential biases or limitations in your theoretical framework? NA\n(f) Have you related your theoretical results to the existing literature in social science? Yes\n(g) Did you discuss the implications of your theoretical results for policy, practice, or further research in the social science domain? Yes\n3. Additionally, if you are including theoretical proofs...\n(a) Did you state the full set of assumptions of all theoretical results? NA\n(b) Did you include complete proofs of all theoretical results? NA\n4. Additionally, if you ran machine learning experiments...\n(a) Did you include the code, data, and instructions needed to reproduce the main experimental results (either in the supplemental material or as a URL)? Yes\n(b) Did you specify all the training details (e.g., data splits, hyperparameters, how they were chosen)? Yes\n(c) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? Yes\n(d) Did you include the total amount of compute and the type of resources used (e.g., type of GPUs, internal cluster, or cloud provider)? Yes\n(e) Do you justify how the proposed evaluation is sufficient and appropriate to the claims made? Yes\n(f) Do you discuss what is \"the cost\u201c of misclassification and fault (in) tolerance? Yes\n5. Additionally, if you are using existing assets (e.g., code, data, models) or curating/releasing new assets, without compromising anonymity...\n(a) If your work uses existing assets, did you cite the creators? Yes, see Data Section.\n(b) Did you mention the license of the assets? Yes, see License of Artifacts Section in Appendix.\n(c) Did you include any new assets in the supplemental material or as a URL? NA"}, {"title": "Additionally, if you used crowdsourcing or conducted research with human subjects, without compromising anonymity...", "content": "(a) Did you include the full text of instructions given to participants and screenshots? \u039d\u0391\n(b) Did you describe any potential participant risks, with mentions of Institutional Review Board (IRB) approvals? NA\n(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? NA\n(d) Did you discuss how data is stored, shared, and deidentified? \u039d\u0391"}]}