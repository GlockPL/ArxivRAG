{"title": "Pathfinding with Lazy Successor Generation", "authors": ["Keisuke Okumura"], "abstract": "We study a pathfinding problem where only locations (i.e., vertices) are given, and edges are implicitly defined by an oracle answering the connectivity of two locations. Despite its simple structure, this problem becomes non-trivial with a massive number of locations, due to posing a huge branching factor for search algorithms. Limiting the number of successors, such as with nearest neighbors, can reduce search efforts but compromises completeness. Instead, we propose a novel LaCAS* algorithm, which does not generate successors all at once but gradually generates successors as the search progresses. This scheme is implemented with k-nearest neighbors search on a k-d tree. LaCAS* is a complete and anytime algorithm that eventually converges to the optima. Extensive evaluations demonstrate the efficacy of LaCAS*, e.g., solving complex pathfinding instances quickly, where conventional methods falter.", "sections": [{"title": "1 Introduction", "content": "Definition 1. We consider a pathfinding problem within a 2D workspace $W \\subseteq [0, 1]^2$, encompassing a set of locations $V = {v_1, v_2,..., v_n}$ with each $v_i \\in W$. Let $s \\in V$ be the start location and $t \\in V$ be the goal, distinct from $s$.\nAn oracle function $connect : V \\times V \\rightarrow {TRUE, FALSE}$ determines whether an agent can traverse between any two points. A solution is a sequence of locations $\\pi := (u_1, u_2, ..., u_m)$, where $u_k \\in V$, satisfying $u_1 = s, u_m = t$, and $connect(u_k, u_{k+1}) = TRUE$ for each $k \\in {1, ..., m \u2013 1}$.\nThe cost of a solution, $cost(\\pi)$, is given by $\\sum_{k=1}^{m-1} dist(u_k, u_{k+1})$, where $dist$ represents the Euclidean distance. A solution, $\\pi^*$, is termed optimal if no other solution exists with $cost(\\pi) < cost(\\pi^*)$. An algorithm is complete if it always yields a solution when solutions exist, or otherwise indicates their absence. An algorithm is optimal if it always finds an optimal solution.\nDefinition 1 is also referred to as pathfinding on E4-graphs (explicit graphs with expensive edge evaluation) [Choudhury et al., 2017]. Solving Def. 1 (near-)optimally and quickly is attractive, given its myriad applications in fields like robot motion planning and video games, among others. However, this problem poses non-trivial challenges to search algorithms when n, the number of locations, is enormous, which is the interest of this paper. We first review existing related problems to underscore the unique features of Def. 1."}, {"title": "1.1 Related Problems", "content": "A graph pathfinding problem involves determining the existence of a path in a graph $G = (V, E)$ that connects specified start and goal vertices, with $E$ denoting a set of arcs. Definition 1 is framed as a graph pathfinding, where $V$ represents a set of locations, and $E$ is implicitly defined by the $connect$ oracle. Consequently, solving Def. 1 optimally is achievable by classical search methods, such as A* [Hart et al., 1968]. However, the primary challenge arises from each location's potential to connect to all others, resulting in a huge branching factor that hampers rapid solution derivation. Moreover, frequent invocation of $connect$ can be computationally intensive, as seen in collision checking in motion planning studies [Elbanhawi and Simic, 2014]. Limiting the number of neighbors for $v \\in V$ might evade this issue, e.g. employing k-nearest neighbors of $v$ based on the Euclidean distance, but such methods sacrifice completeness and optimality.\nAny-angle path planning on grids (AAPP) [Daniel et al., 2010] is a special case of Def. 1 such that each location $v \\in V$ is placed on a lattice grid. AAPP has been extensively studied for its ability to generate shorter paths than"}, {"title": "1.2 Contribution", "content": "The preceding discussions highlight a key dilemma: On one hand, naive search algorithms that expand $O(n)$ successor nodes all at once from one location should be avoided due to substantial computational overhead. On the other hand, examining connectivity across all potential locations is necessary to ensure the discovery of a solution path, if it exists.\nA possible resolution to this dilemma is the gradual generation of successor nodes as the search progresses, termed lazy successor generation in this paper. Based on this notion, we introduce the LaCAS* algorithm for solving Def. 1, an abbreviation for lazy constraints addition search in single-agent pathfinding. LaCAS* comprises a two-level search: the"}, {"title": "2 Algorithm", "content": ""}, {"title": "2.1 Lazy Constraints Addition", "content": "The essence of lazy successor generation lies in incrementally generating small portions of successors, while ensuring all are eventually produced. A naive approach involves initially sorting $O(n)$ locations by a distance relative to the target and goal, then sequentially extracting a batch, a small portion of the entire locations, following the sort result. However, this method demands substantial computation, as sorting each location requires an $O(n \\log n)$ operation. LaCAS* avoids this computationally intensive procedure by utilizing a k-d tree [Bentley, 1975].\nA k-d tree is a widely used data structure for storing points in k-dimensional space, efficiently answering queries to retrieve nearby points from a target point. For instance, the time complexity of finding the nearest point among n locations is $O(\\log n)$ under certain reasonable assumptions, once the tree is constructed with an $O(n \\log n)$ overhead. Its applications span unsupervised classification tasks and sampling-based motion planning algorithms [LaValle, 2006]. Here, it facilitates lazy successor generation. Specifically, consider a k-d tree $T$ constructed for a set of locations $V$. Then, LaCAS* employs the operation $nearest\\_neighbors\\_search(T, v \\in V, b \\in N_{>0}, \\theta \\in R)$ to retrieve $b$ nearest neighbors in $V$ of $v$, based on distance, but each with a distance exceeding $\\theta$. If $\\theta < 0$, it equates to the standard k-nearest neighbors search for $T$. Implementing $nearest\\_neighbors\\_search$ is straightforward, because it merely introduces a threshold distance $\\theta$ to the normal k-nearest neighbors search. We assume that the function returns an empty set if no locations meet the threshold.\nObserve that $nearest\\_neighbors\\_search$ functions as a lazy successor generator. It circumvents the need to enumerate all locations at once, allowing for the eventual generation of all locations through multiple invocations by incrementally increasing the threshold distance $\\theta$. In this context, $\\theta$ acts as a constraint on successor generation, with the constraints being added in a lazy manner. The name of LaCAS*, lazy constraints addition search, comes from this view."}, {"title": "2.2 Pseudocode", "content": "Algorithm 1 shows a minimum LaCAS*. The anytime parts are grayed out and explained after providing the backbone.\nSimilar to other search algorithms, a search node in LaCAS* consists of a location $v \\in V$ and a pointer to its parent node; see Line 2. Search nodes are stored in an $Open$ list, which directs the search, and an $Explored$ table to prevent duplicating nodes. $Open$ can be implemented using various data structures such as stacks, queues, etc. The following description assumes a stack, adhering to a depth-first search (DFS) style.\nAfter constructing the k-d tree (Line 4), LaCAS* progresses the search by processing one node $N$ at a time (Line 6). The procedure initially retrieves $b$ potential successor locations for $N$ (Line 9). If no such locations exist, the original node $N$ is discarded (Line 10); otherwise, the distance threshold is updated based on these locations (Line 11). Subsequently, successor nodes are generated after confirming connectivity (Lines 12\u201317). When the search reaches a goal location $t$ (Line 7), a solution can always be constructed by backtracking from the node at the goal ($N_{fin}$; Lines 31 and 32). If nodes are exhausted without reaching $t$, it signifies the absence of a solution (Line 33).\nAnytime Components. To eventually find optimal solutions, each search node includes a $g$-value denoting the cost-to-come, and $neigh$, holding discovered successors. Upon encountering previously known locations, LaCAS* rewires parent pointers using an adapted Dijkstra algorithm [Dijkstra, 1959] (Lines 21\u201330). This rewiring is typically applied to a small section of the search tree due to pruning by $g$-values (Line 26). Another anytime component is that upon reaching the goal, LaCAS* excludes nodes not improving solution quality to accelerate solution refinement (Line 8)."}, {"title": "2.3 Analysis", "content": "Theorem 1. LaCAS* (Alg. 1) is complete and optimal.\nProof. Completeness: Each time a node $N$ is invoked, its distance threshold $\\theta$ monotonically increases by updating $\\theta$ to the maximum distance from $N.v$ to potential successor locations in $B$ (Line 11), each having at least the distance of $\\theta$. Since $\\theta$ initially starts at zero, any location $u \\in V$, with $u \\neq N.v$, must have been encompassed in one of $N$'s invocations by the time $N$ is discarded at Line 10. Furthermore, each search node must be discarded after a finite"}, {"title": "3 Related Work", "content": "This section organizes relationships with existing algorithms before going to the empirical side."}, {"title": "3.1 Beam Search", "content": "We begin the literature review from beam search [Bisiani, 1987], which is a heuristic search method that limits the number of nodes in the $Open$ list. It can be categorized into two types [Wilt et al., 2010]: (i) the best-first type, which merely limits the size of the $Open$ compared to the standard best-first search, and (ii) the breadth-first type, which works like breadth-first search but with a predetermined width, known as \"beam width.\" Although beam search sacrifices completeness and optimality, the breadth-first variant has been widely used in areas such as speech recognition [Ravishankar, 1996] and natural language processing [Cohen and Beck, 2019] because of its simplicity, efficiency in reducing search effort, and memory consumption. Researchers have been extended basic beam search to have theoretical properties such as completeness or optimality [Zhang, 1998; Zhou and Hansen, 2005; Furcy and Koenig, 2005; Vadlamudi et al., 2013].\nSimilar to beam search, LaCAS* does not retain all successor nodes; however, there are two significant differences. First, unlike beam search, which generates all successors before pruning, LaCAS* initiates only a subset of successors through a two-level search approach. Second, while beam search parameters (e.g., beam width) determine the number of nodes maintained throughout the search, LaCAS*'s batch size specifies the number of successors for each search node. These features allow LaCAS* to facilitate pathfinding with numerous successors while maintaining theoretical properties, i.e., to adapt the search effort to the area of interest without spending too much time generating successors."}, {"title": "3.2 Partial Successor Expansion", "content": "Rather than beam search, LaCAS* has more close relationships to the best-first search with partial successor expansion as follows.\nPartial Expansion A* (PEA*) [Yoshizumi et al., 2000] is an A* variant. To keep memory usage small, when expanding a search node $N$, PEA* generates all successors and inserts only a part of them, those having the same $f$-value as $N$, into $Open$. In our context, this approach closely aligns with the strategy outlined at the beginning of Sec. 2.1, which initially orders all locations relative to $N$, and subsequently selects segments of this ordered list as the search"}, {"title": "3.3 Search Space Densificaiton", "content": "Another direction for tackling search problems with a huge branching factor is to tailor the search spaces themselves before applying search algorithms; that is, to first present a sparse search space and gradually densify it. This ap- proach is orthogonal to LaCAS*, since they are not search algorithms; but we include this discussion for the sake of completeness.\nA concrete example is presented in [Choudhury et al., 2017], which explores pathfinding in E\u2074-graphs, a generaliza- tion of Def. 1. The essence of this study is to construct a set of subgraphs from the original graph and solve pathfinding on these subgraphs sequentially. A subgraph is densified from the previous one by decreasing the minimum distance required to connect two locations or by increasing the number of vertices included. Similar to LaCAS*, this strat- egy employs an anytime planning scheme that aims to first find feasible solutions in a sparse representation of the workspace and then gradually refine the solution using denser representations. Meanwhile, this workspace densifi- cation strategy is agnostic to the search algorithm; it densifies the search space uniformly. In contrast, LaCAS* is a search algorithm that automatically densifies the specific space of interest.\nIn line with this approach, another notable example is introduced in [Saund and Berenson, 2020], where the workspace is represented by layered graphs, providing a finer representation of the space in deeper layers. Each layer is connected to the next, and together these graphs define the huge search space. Although agnostic to search algorithms, the layered representation facilitates the natural densification of regions of interest. However, the construction of layers assumes specific location patterns, such as grids or Halton sequences, which do not apply to Def. 1. Moreover, this approach does not directly address the problem of the huge branching factor, since it does not involve edges between any two arbitrary locations."}, {"title": "3.4 Search Tree Rewiring", "content": "LaCAS* incorporates tree rewiring in order to eventually obtain optimal solutions. This scheme modifies overesti- mated $g$-values for each search node, removing inconsistencies caused by 'shortcut' paths identified as the search progresses. This notion essentially derives from lifelong planning [Koenig et al., 2004; Koenig and Likhachev, 2005], where an agent must continuously find solution paths in dynamically changing environments.\nThe rewiring in LaCAS* resembles asymptotically optimal sampling-based motion planning (SBMP) algorithms like RRT* [Karaman and Frazzoli, 2011] and its variants in discretized search spaces [Shome et al., 2020]. While these algorithms limit rewiring to local neighbors, LaCAS* extends it to descendant nodes. This difference arises because SBMP presumes an infinite number of samples (i.e., locations), whereas LaCAS* operates under a finite number of search iterations.\nNotably, LaCAS* shares another feature with SBMP: node pruning based on the known solution cost (Line 8). For instance, informed SBMP methods such as Informed RRT* [Gammell et al., 2014] bias new location sampling from a region identified by the known solution cost. Such pruning is often seen in anytime search algorithms as well [Hansen and Zhou, 2007; Van Den Berg et al., 2011]."}, {"title": "4 Devising Implementation", "content": "Algorithm 1 is a minimal LaCAS* that leaves room for several inventions for implementation, which are covered in this section. The techniques below rely on the fact that LaCAS* makes no assumptions about the node extraction order from Open for both guarantees of completeness and optimality."}, {"title": "4.1 Order within Batch", "content": "In each iteration, LaCAS* forms a batch $B$ at Line 9 then processes locations in $B$ sequentially. The order of locations in $B$ is flexible; however, it significantly impacts performance. Among various design choices, we particularly choose to sort locations in $B$ in descending order of $dist(v, t)$, where $v \\in B$, to derive initial solutions rapidly. Using a stack"}, {"title": "4.2 Node Reinsert", "content": "When the search encounters an already known location, reinserting its corresponding node at the top of $Open$ can enhance search efficiency. This method, adopted from LaCAM [Okumura, 2023b], is based on the premise that frequently encountered locations during the search are potential bottlenecks. Thus, prioritizing the search at these locations by reinvoking the corresponding node is logical. We assume that this reinsertion occurs immediately after rewiring (Lines 21-30). Figure 2 presents empirical results, showing that the node-reinsert operation decreases search effort and enables LaCAS* to discover superior initial solutions."}, {"title": "4.3 Node Rolling", "content": "Using a stack structure as $Open$ may lead to situations where the same location is visited repeatedly in a short period because LaCAS* does not immediately discard invoked nodes. This hinders rapid pathfinding; considering setting aside such stuck nodes temporarily might be beneficial. An implementation of this concept is adopting a double-ended queue (deque) for $Open$ instead of the naive stack, allowing for rolling search nodes within $Open$ upon invocation. Specifically, this operation pops the search node $N$ from $Open$ and reinserts it at the bottom if $N$ generates a non- empty batch at Line 9, assuming to happen just after Line 10. Figure 2 proves that node rolling is effective for tackling complex problems."}, {"title": "4.4 LaCAT*- Check Grandparent", "content": "Consider a new node $N_{new}$ created at Line 16 from a node $N$. If $N_{new}$ can connect from $N.parent$, setting $N.parent$ as its parent yields a lower $g$-value for $N_{new}$ compared to using $N$ as the parent, because of the cost function adhering to the triangle inequality. This grandparent check accelerates the attainment of better solutions compared to the vanilla LaCAS*, while maintaining theoretical integrity of LaCAS* as long as adding $N_{new}$ to both $N.neigh$ and $N.parent.neigh$. This devising is also applicable when encountering existing nodes at Line 20. The grandparent check is inspired by Theta* for AAPP [Daniel et al., 2010]. Taking its initial, we call the resulting algorithm LaCAT* .\nFigure 2 demonstrates that LaCAT* can obtain superior initial solutions in the same number of iterations, albeit with the overhead of more $connect$ calls. It is important to note that the preference for LaCAT* varies depending on the case; rather than allocating time to the overhead of LaCAT*, it may be more beneficial to dedicate that time to the refinement scheme of LaCAS*."}, {"title": "5 Evaluation", "content": "This section assesses LaCAS* and its variant LaCAT*, both with techniques from Sec. 4, across various scenarios. For clarity, LaCAS refers to LaCAS* without refinement after finding initial solutions, and LaCAT to that of LaCAT*. Unless mentioned, LaCAS-based methods used a batch size $b$ of 10. Experiments were conducted on a 28-core desktop PC with an Apple M1 Ultra 2.4 GHz CPU and 64 GB RAM, with a 30 s timeout. All methods were coded in Julia."}, {"title": "5.1 Baselines", "content": "We carefully selected various baseline methods, each belonging to one of two categories. The first category includes methods that directly solve Def. 1, into which LaCAS* falls.\n\u2022 A*, a complete and optimal search scheme, using $dist(\\cdot, t)$ as a heuristic. We also evaluated A-k*, limiting successors to the closest k neighbors, and A-r*, limiting successors within distance r. Both are incomplete and suboptimal. Successors were efficiently identified using the k-d tree, similar to LaCAS*. For the experi- ments, we set k = 10 and r = 0.1, pre-adjusted to yield consistently superior performance.\n\u2022 Greedy best-first search (GBFS), which selects nodes solely based on the heuristic. This is complete but suboptimal. GBFS-k and GBFS-r were also tested, analogous to A-k* and A-r*, respectively."}, {"title": "5.2 Benchmark Generation", "content": "Eight scenarios with specific start-goal locations were prepared, as shown in Fig. 4 and 5. For each scenario, 100 instances were generated, varying locations, obstacles, or both. Note that random generation may result in unsolvable instances. To focus on the algorithmic nature itself, each scenario was designed with line-shaped obstacles in $W = [0, 1]^2$, allowing the $connect$ function to be implemented as a relatively lightweight geometric computation.\nFigure 4 shows four basic scenarios: (i) scatter-1k, with 1,000 locations placed by uniformly at random sampling, (ii) scatter-10k, with 10,000 randomly placed locations, (iii) grid-10k, where locations are on a grid with a 0.01 resolution (hence |V|\u224810,000), and (iv) plus-2k, with 2, 000 randomly positioned locations. The first three scenarios include randomly placed line-shaped obstacles, with their length and quantity calibrated for moderate difficulty. In contrast, plus-2k features \"plus\" shaped obstacles.\nFigure 5 illustrates four carefully designed scenarios to assess each method's characteristics: (v) trap, featuring a basket-shaped obstacle, (vi) zigzag, where the goal-distance heuristic is less effective, (vii) gateways, requiring navigation through five narrow \u201cgateways\u201d to reach the goal, (viii) split, with locations split into two distinct zones, separated by multiple obstacles. Each scenario includes 1,000 locations, randomly distributed."}, {"title": "5.3 Results and Discussions", "content": "Figures 4 and 5 show that, overall, LaCAS* achieved superior performance in pathfinding with the huge branching factor, while maintaining theoretical guarantees of completeness and eventual optimality. LaCAS quickly identified"}, {"title": "5.4 Effect of Batch Size", "content": "Figure 6 illustrates the impact of batch size on LaCAS's performance, indicating that there are sweet spots in batch size. For very small batch sizes, search progression can be slow, as successors closer to the goal might not appear in the initial successor generation for each node. Conversely, large batch sizes diminish the benefits of lazy successor generation, which is pivotal for rapid search."}, {"title": "6 Conclusion", "content": "This paper studied pathfinding on a graph where every vertex is potentially connected to every other vertex, and the connectivity is implicitly defined by an oracle. The challenge arises from the huge branching factor, rendering standard search algorithms computationally expensive. While limiting successor generation mitigates this issue, it compromises the complete and optimal search structure, and its efficacy heavily relies on design choices. Our study addresses this dilemma through LaCAS*. At its core, LaCAS* employs lazy successor generation via the two-level search. This trick enables LaCAS* to maintain both empirical effectiveness and theoretical assurances of completeness and eventual optimality.\nThe LaCAS* concept originates from LaCAM*, one of the cutting-edge multi-agent pathfinding implementa- tions [Okumura, 2024], which stands out as it achieves stable planning for thousands of agents. It shares the fun- damental principle of combinatorial search with generators, a scheme that gradually generates small portions of the entire successors. While generators need specific designs for each problem domain, the encouraging outcomes in both single- and multi-agent pathfinding suggest this approach is an effective strategy for planning problems with huge branching factors."}]}