{"title": "Pathfinding with Lazy Successor Generation", "authors": ["Keisuke Okumura"], "abstract": "We study a pathfinding problem where only locations (i.e., vertices) are given, and edges are implicitly defined by an oracle answering the connectivity of two locations. Despite its simple structure, this problem becomes non-trivial with a massive number of locations, due to posing a huge branching factor for search algorithms. Limiting the number of successors, such as with nearest neighbors, can reduce search efforts but compromises completeness. Instead, we propose a novel LaCAS* algorithm, which does not generate successors all at once but gradually generates successors as the search progresses. This scheme is implemented with k-nearest neighbors search on a k-d tree. LaCAS* is a complete and anytime algorithm that eventually converges to the optima. Extensive evaluations demonstrate the efficacy of LaCAS*, e.g., solving complex pathfinding instances quickly, where conventional methods falter.", "sections": [{"title": "1 Introduction", "content": "Definition 1. We consider a pathfinding problem within a 2D workspace \\(W \\subseteq [0, 1]^2\\), encompassing a set of locations\n\\(V = \\{v_1, v_2,..., v_n\\}\\) with each \\(v_i \\in W\\). Let \\(s \\in V\\) be the start location and \\(t \\in V\\) be the goal, distinct from \\(s\\).\nAn oracle function \\(\\text{connect} : V \\times V \\rightarrow \\{\\text{TRUE, FALSE}\\}\\) determines whether an agent can traverse between any two\npoints. A solution is a sequence of locations \\(\\pi := (u_1, u_2, ..., u_m)\\), where \\(u_k \\in V\\), satisfying \\(u_1 = s\\), \\(u_m = t\\), and\n\\(\\text{connect}(u_k, u_{k+1}) = \\text{TRUE}\\) for each \\(k \\in \\{1, ..., m \u2013 1\\}\\).\nThe cost of a solution, \\(\\text{cost}(\\pi)\\), is given by\n\\(\\sum_{k=1}^{m-1} \\text{dist}(u_k, u_{k+1})\\), where dist represents the Euclidean distance. A solution, \\(\\pi^*\\), is termed optimal if no other\nsolution \\(\\pi\\) exists with \\(\\text{cost}(\\pi) < \\text{cost}(\\pi^*)\\). An algorithm is complete if it always yields a solution when solutions\nexist, or otherwise indicates their absence. An algorithm is optimal if it always finds an optimal solution.\nDefinition 1 is also referred to as pathfinding on E4-graphs (explicit graphs with expensive edge evaluation) [Choudhury et al., 2017]. Solving Def. 1 (near-)optimally and quickly is attractive, given its myriad applications in fields like robot motion planning and video games, among others. However, this problem poses non-trivial challenges to search algorithms when n, the number of locations, is enormous, which is the interest of this paper. We first review existing related problems to underscore the unique features of Def. 1."}, {"title": "1.1 Related Problems", "content": "A graph pathfinding problem involves determining the existence of a path in a graph \\(G = (V, E)\\) that connects\nspecified start and goal vertices, with E denoting a set of arcs. Definition 1 is framed as a graph pathfinding, where\n\\(V\\) represents a set of locations, and \\(E\\) is implicitly defined by the connect oracle. Consequently, solving Def. 1\noptimally is achievable by classical search methods, such as A* [Hart et al., 1968]. However, the primary challenge\narises from each location's potential to connect to all others, resulting in a huge branching factor that hampers rapid\nsolution derivation. Moreover, frequent invocation of connect can be computationally intensive, as seen in collision\nchecking in motion planning studies [Elbanhawi and Simic, 2014]. Limiting the number of neighbors for \\(v \\in V\\) might\nevade this issue, e.g. employing k-nearest neighbors of \\(v\\) based on the Euclidean distance, but such methods sacrifice\ncompleteness and optimality.\nAny-angle path planning on grids (AAPP) [Daniel et al., 2010] is a special case of Def. 1 such that each location\n\\(v \\in V\\) is placed on a lattice grid. AAPP has been extensively studied for its ability to generate shorter paths than"}, {"title": "1.2 Contribution", "content": "The preceding discussions highlight a key dilemma: On one hand, naive search algorithms that expand \\(O(n)\\) successor\nnodes all at once from one location should be avoided due to substantial computational overhead. On the other hand,\nexamining connectivity across all potential locations is necessary to ensure the discovery of a solution path, if it exists.\nA possible resolution to this dilemma is the gradual generation of successor nodes as the search progresses, termed lazy\nsuccessor generation in this paper. Based on this notion, we introduce the LaCAS* algorithm for solving Def. 1, an ab-\nbreviation for lazy constraints addition search in single-agent pathfinding. LaCAS* comprises a two-level search: the"}, {"title": "2 Algorithm", "content": "2.1 Lazy Constraints Addition\nThe essence of lazy successor generation lies in incrementally generating small portions of successors, while ensuring\nall are eventually produced. A naive approach involves initially sorting \\(O(n)\\) locations by a distance relative to the\ntarget and goal, then sequentially extracting a batch, a small portion of the entire locations, following the sort result.\nHowever, this method demands substantial computation, as sorting each location requires an \\(O(n \\log n)\\) operation.\nLaCAS* avoids this computationally intensive procedure by utilizing a k-d tree [Bentley, 1975].\nA k-d tree is a widely used data structure for storing points in k-dimensional space, efficiently answering queries to\nretrieve nearby points from a target point. For instance, the time complexity of finding the nearest point among n loca-\ntions is \\(O(\\log n)\\) under certain reasonable assumptions, once the tree is constructed with an \\(O(n \\log n)\\) overhead. Its\napplications span unsupervised classification tasks and sampling-based motion planning algorithms [LaValle, 2006].\nHere, it facilitates lazy successor generation. Specifically, consider a k-d tree \\(T\\) constructed for a set of locations \\(V\\).\nThen, LaCAS* employs the operation \\(\\text{nearest\\_neighbors\\_search}(T, v \\in V, b \\in \\mathbb{N}_{>0}, \\theta \\in \\mathbb{R})\\) to retrieve \\(b\\) nearest\nneighbors in \\(V\\) of \\(v\\), based on distance, but each with a distance exceeding \\(\\theta\\). If \\(\\theta < 0\\), it equates to the standard\nk-nearest neighbors search for \\(T\\). Implementing nearest_neighbors_search is straightforward, because it merely in-\ntroduces a threshold distance \\(\\theta\\) to the normal k-nearest neighbors search. We assume that the function returns an empty\nset if no locations meet the threshold.\nObserve that nearest_neighbors_search functions as a lazy successor generator. It circumvents the need to enumerate\nall locations at once, allowing for the eventual generation of all locations through multiple invocations by incrementally\nincreasing the threshold distance \\(\\theta\\). In this context, \\(\\theta\\) acts as a constraint on successor generation, with the constraints\nbeing added in a lazy manner. The name of LaCAS*, lazy constraints addition search, comes from this view."}, {"title": "2.2 Pseudocode", "content": "Algorithm 1 shows a minimum LaCAS*. The anytime parts are grayed out and explained after providing the backbone.\nSimilar to other search algorithms, a search node in LaCAS* consists of a location \\(v \\in V\\) and a pointer to its parent\nnode; see Line 2. Search nodes are stored in an Open list, which directs the search, and an Explored table to prevent\nduplicating nodes. Open can be implemented using various data structures such as stacks, queues, etc. The following\ndescription assumes a stack, adhering to a depth-first search (DFS) style.\nAfter constructing the k-d tree (Line 4), LaCAS* progresses the search by processing one node \\(N\\) at a time (Line 6).\nThe procedure initially retrieves \\(b\\) potential successor locations for \\(N\\) (Line 9). If no such locations exist, the original\nnode \\(N\\) is discarded (Line 10); otherwise, the distance threshold is updated based on these locations (Line 11).\nSubsequently, successor nodes are generated after confirming connectivity (Lines 12\u201317). When the search reaches a\ngoal location \\(t\\) (Line 7), a solution can always be constructed by backtracking from the node at the goal \\(N_{fin}\\); Lines 31\nand 32). If nodes are exhausted without reaching \\(t\\), it signifies the absence of a solution (Line 33).\nAnytime Components. To eventually find optimal solutions, each search node includes a g-value denoting the cost-to-come, and neigh, holding discovered successors. Upon encountering previously known locations, LaCAS* rewires\nparent pointers using an adapted Dijkstra algorithm [Dijkstra, 1959] (Lines 21\u201330). This rewiring is typically applied\nto a small section of the search tree due to pruning by g-values (Line 26). Another anytime component is that upon\nreaching the goal, LaCAS* excludes nodes not improving solution quality to accelerate solution refinement (Line 8)."}, {"title": "2.3 Analysis", "content": "Theorem 1. LaCAS* (Alg. 1) is complete and optimal.\nProof. Completeness: Each time a node \\(N\\) is invoked, its distance threshold \\(\\theta\\) monotonically increases by updating \\(\\theta\\)\nto the maximum distance from \\(N.v\\) to potential successor locations in \\(B\\) (Line 11), each having at least the distance\nof \\(\\theta\\). Since \\(\\theta\\) initially starts at zero, any location \\(u \\in V\\), with \\(u \\neq N.v\\), must have been encompassed in one of \\(N\\)'s\ninvocations by the time \\(N\\) is discarded at Line 10. Furthermore, each search node must be discarded after a finite"}, {"title": "3 Related Work", "content": "This section organizes relationships with existing algorithms before going to the empirical side.\n3.1 Beam Search\nWe begin the literature review from beam search [Bisiani, 1987], which is a heuristic search method that limits the\nnumber of nodes in the Open list. It can be categorized into two types [Wilt et al., 2010]: (i) the best-first type,\nwhich merely limits the size of the Open compared to the standard best-first search, and (ii) the breadth-first type,\nwhich works like breadth-first search but with a predetermined width, known as \"beam width.\" Although beam\nsearch sacrifices completeness and optimality, the breadth-first variant has been widely used in areas such as speech\nrecognition [Ravishankar, 1996] and natural language processing [Cohen and Beck, 2019] because of its simplicity,\nefficiency in reducing search effort, and memory consumption. Researchers have been extended basic beam search\nto have theoretical properties such as completeness or optimality [Zhang, 1998; Zhou and Hansen, 2005; Furcy and\nKoenig, 2005; Vadlamudi et al., 2013].\nSimilar to beam search, LaCAS* does not retain all successor nodes; however, there are two significant differences.\nFirst, unlike beam search, which generates all successors before pruning, LaCAS* initiates only a subset of successors\nthrough a two-level search approach. Second, while beam search parameters (e.g., beam width) determine the number\nof nodes maintained throughout the search, LaCAS*'s batch size specifies the number of successors for each search\nnode. These features allow LaCAS* to facilitate pathfinding with numerous successors while maintaining theoretical\nproperties, i.e., to adapt the search effort to the area of interest without spending too much time generating successors."}, {"title": "3.2 Partial Successor Expansion", "content": "Rather than beam search, LaCAS* has more close relationships to the best-first search with partial successor expansion\nas follows.\nPartial Expansion A* (PEA*) [Yoshizumi et al., 2000] is an A* variant. To keep memory usage small, when expanding\na search node N, PEA* generates all successors and inserts only a part of them, those having the same f-value as\nN, into Open. In our context, this approach closely aligns with the strategy outlined at the beginning of Sec. 2.1,\nwhich initially orders all locations relative to N, and subsequently selects segments of this ordered list as the search"}, {"title": "3.3 Search Space Densificaiton", "content": "Another direction for tackling search problems with a huge branching factor is to tailor the search spaces themselves\nbefore applying search algorithms; that is, to first present a sparse search space and gradually densify it. This ap-\nproach is orthogonal to LaCAS*, since they are not search algorithms; but we include this discussion for the sake of\ncompleteness.\nA concrete example is presented in [Choudhury et al., 2017], which explores pathfinding in E\u2074-graphs, a generaliza-\ntion of Def. 1. The essence of this study is to construct a set of subgraphs from the original graph and solve pathfinding\non these subgraphs sequentially. A subgraph is densified from the previous one by decreasing the minimum distance\nrequired to connect two locations or by increasing the number of vertices included. Similar to LaCAS*, this strat-\negy employs an anytime planning scheme that aims to first find feasible solutions in a sparse representation of the\nworkspace and then gradually refine the solution using denser representations. Meanwhile, this workspace densifi-\ncation strategy is agnostic to the search algorithm; it densifies the search space uniformly. In contrast, LaCAS* is a\nsearch algorithm that automatically densifies the specific space of interest.\nIn line with this approach, another notable example is introduced in [Saund and Berenson, 2020], where the workspace\nis represented by layered graphs, providing a finer representation of the space in deeper layers. Each layer is connected\nto the next, and together these graphs define the huge search space. Although agnostic to search algorithms, the layered\nrepresentation facilitates the natural densification of regions of interest. However, the construction of layers assumes\nspecific location patterns, such as grids or Halton sequences, which do not apply to Def. 1. Moreover, this approach\ndoes not directly address the problem of the huge branching factor, since it does not involve edges between any two\narbitrary locations."}, {"title": "3.4 Search Tree Rewiring", "content": "LaCAS* incorporates tree rewiring in order to eventually obtain optimal solutions. This scheme modifies overesti-\nmated g-values for each search node, removing inconsistencies caused by 'shortcut' paths identified as the search\nprogresses. This notion essentially derives from lifelong planning [Koenig et al., 2004; Koenig and Likhachev, 2005],\nwhere an agent must continuously find solution paths in dynamically changing environments.\nThe rewiring in LaCAS* resembles asymptotically optimal sampling-based motion planning (SBMP) algorithms like\nRRT* [Karaman and Frazzoli, 2011] and its variants in discretized search spaces [Shome et al., 2020]. While these\nalgorithms limit rewiring to local neighbors, LaCAS* extends it to descendant nodes. This difference arises because\nSBMP presumes an infinite number of samples (i.e., locations), whereas LaCAS* operates under a finite number of\nsearch iterations.\nNotably, LaCAS* shares another feature with SBMP: node pruning based on the known solution cost (Line 8). For\ninstance, informed SBMP methods such as Informed RRT* [Gammell et al., 2014] bias new location sampling from a\nregion identified by the known solution cost. Such pruning is often seen in anytime search algorithms as well [Hansen\nand Zhou, 2007; Van Den Berg et al., 2011]."}, {"title": "4 Devising Implementation", "content": "Algorithm 1 is a minimal LaCAS* that leaves room for several inventions for implementation, which are covered in\nthis section. The techniques below rely on the fact that LaCAS* makes no assumptions about the node extraction order\nfrom Open for both guarantees of completeness and optimality.\n4.1 Order within Batch\nIn each iteration, LaCAS* forms a batch B at Line 9 then processes locations in B sequentially. The order of locations\nin B is flexible; however, it significantly impacts performance. Among various design choices, we particularly choose\nto sort locations in B in descending order of \\(\\text{dist}(v, t)\\), where \\(v \\in B\\), to derive initial solutions rapidly. Using a stack"}, {"title": "4.2 Node Reinsert", "content": "When the search encounters an already known location, reinserting its corresponding node at the top of Open can\nenhance search efficiency. This method, adopted from LaCAM [Okumura, 2023b], is based on the premise that\nfrequently encountered locations during the search are potential bottlenecks. Thus, prioritizing the search at these\nlocations by reinvoking the corresponding node is logical. We assume that this reinsertion occurs immediately after\nrewiring (Lines 21\u201330). Figure 2 presents empirical results, showing that the node-reinsert operation decreases search\neffort and enables LaCAS* to discover superior initial solutions."}, {"title": "4.3 Node Rolling", "content": "Using a stack structure as Open may lead to situations where the same location is visited repeatedly in a short period\nbecause LaCAS* does not immediately discard invoked nodes. This hinders rapid pathfinding; considering setting\naside such stuck nodes temporarily might be beneficial. An implementation of this concept is adopting a double-ended\nqueue (deque) for Open instead of the naive stack, allowing for rolling search nodes within Open upon invocation.\nSpecifically, this operation pops the search node N from Open and reinserts it at the bottom if N generates a non-\nempty batch at Line 9, assuming to happen just after Line 10. Figure 2 proves that node rolling is effective for tackling\ncomplex problems."}, {"title": "4.4 LaCAT*- Check Grandparent", "content": "Consider a new node \\(N_{new}\\) created at Line 16 from a node \\(N\\). If \\(N_{new}\\) can connect from \\(N.parent\\), setting \\(N.parent\\)\nas its parent yields a lower g-value for \\(N_{new}\\) compared to using \\(N\\) as the parent, because of the cost function adhering\nto the triangle inequality. This grandparent check accelerates the attainment of better solutions compared to the\nvanilla LaCAS*, while maintaining theoretical integrity of LaCAS* as long as adding \\(N_{new}\\) to both \\(N.neigh\\) and\n\\(N.parent.neigh\\). This devising is also applicable when encountering existing nodes at Line 20. The grandparent\ncheck is inspired by Theta* for AAPP [Daniel et al., 2010]. Taking its initial, we call the resulting algorithm LaCAT* .\nFigure 2 demonstrates that LaCAT* can obtain superior initial solutions in the same number of iterations, albeit with\nthe overhead of more connect calls. It is important to note that the preference for LaCAT* varies depending on the\ncase; rather than allocating time to the overhead of LaCAT*, it may be more beneficial to dedicate that time to the\nrefinement scheme of LaCAS*."}, {"title": "5 Evaluation", "content": "This section assesses LaCAS* and its variant LaCAT*, both with techniques from Sec. 4, across various scenarios.\nFor clarity, LaCAS refers to LaCAS* without refinement after finding initial solutions, and LaCAT to that of LaCAT* .\nUnless mentioned, LaCAS-based methods used a batch size \\(b\\) of 10. Experiments were conducted on a 28-core desktop\nPC with an Apple M1 Ultra 2.4 GHz CPU and 64 GB RAM, with a 30 s timeout. All methods were coded in Julia.\n5.1 Baselines\nWe carefully selected various baseline methods, each belonging to one of two categories. The first category includes\nmethods that directly solve Def. 1, into which LaCAS* falls.\n\u2022 A*, a complete and optimal search scheme, using \\(\\text{dist}(\\cdot, t)\\) as a heuristic. We also evaluated A-k*, limiting\nsuccessors to the closest k neighbors, and A-r*, limiting successors within distance r. Both are incomplete\nand suboptimal. Successors were efficiently identified using the k-d tree, similar to LaCAS*. For the experi-\nments, we set \\(k = 10\\) and \\(r = 0.1\\), pre-adjusted to yield consistently superior performance.\n\u2022 Greedy best-first search (GBFS), which selects nodes solely based on the heuristic. This is complete but\nsuboptimal. GBFS-k and GBFS-r were also tested, analogous to A-k* and A-r*, respectively."}, {"title": "5.2 Benchmark Generation", "content": "Eight scenarios with specific start-goal locations were prepared, as shown in Fig. 4 and 5. For each scenario, 100\ninstances were generated, varying locations, obstacles, or both. Note that random generation may result in unsolvable\ninstances. To focus on the algorithmic nature itself, each scenario was designed with line-shaped obstacles in \\(W =\\n[0, 1]^2\\), allowing the connect function to be implemented as a relatively lightweight geometric computation.\nFigure 4 shows four basic scenarios: (i) scatter-1k, with 1,000 locations placed by uniformly at random sampling,\n(ii) scatter-10k, with 10,000 randomly placed locations, (iii) grid-10k, where locations are on a grid with a 0.01\nresolution (hence \\(|V|\\approx 10,000\\)), and (iv) plus-2k, with 2, 000 randomly positioned locations. The first three scenarios\ninclude randomly placed line-shaped obstacles, with their length and quantity calibrated for moderate difficulty. In\ncontrast, plus-2k features \"plus\" shaped obstacles.\nFigure 5 illustrates four carefully designed scenarios to assess each method's characteristics: (v) trap, featuring a\nbasket-shaped obstacle, (vi) zigzag, where the goal-distance heuristic is less effective, (vii) gateways, requiring\nnavigation through five narrow \u201cgateways\u201d to reach the goal, (viii) split, with locations split into two distinct zones,\nseparated by multiple obstacles. Each scenario includes 1,000 locations, randomly distributed."}, {"title": "5.3 Results and Discussions", "content": "Figures 4 and 5 show that, overall, LaCAS* achieved superior performance in pathfinding with the huge branching\nfactor, while maintaining theoretical guarantees of completeness and eventual optimality. LaCAS quickly identified"}, {"title": "5.4 Effect of Batch Size", "content": "Figure 6 illustrates the impact of batch size on LaCAS's performance, indicating that there are sweet spots in batch\nsize. For very small batch sizes, search progression can be slow, as successors closer to the goal might not appear in\nthe initial successor generation for each node. Conversely, large batch sizes diminish the benefits of lazy successor\ngeneration, which is pivotal for rapid search."}, {"title": "6 Conclusion", "content": "This paper studied pathfinding on a graph where every vertex is potentially connected to every other vertex, and\nthe connectivity is implicitly defined by an oracle. The challenge arises from the huge branching factor, rendering\nstandard search algorithms computationally expensive. While limiting successor generation mitigates this issue, it\ncompromises the complete and optimal search structure, and its efficacy heavily relies on design choices. Our study\naddresses this dilemma through LaCAS*. At its core, LaCAS* employs lazy successor generation via the two-level\nsearch. This trick enables LaCAS* to maintain both empirical effectiveness and theoretical assurances of completeness\nand eventual optimality.\nThe LaCAS* concept originates from LaCAM*, one of the cutting-edge multi-agent pathfinding implementa-\ntions [Okumura, 2024], which stands out as it achieves stable planning for thousands of agents. It shares the fun-\ndamental principle of combinatorial search with generators, a scheme that gradually generates small portions of the\nentire successors. While generators need specific designs for each problem domain, the encouraging outcomes in both\nsingle- and multi-agent pathfinding suggest this approach is an effective strategy for planning problems with huge\nbranching factors."}]}