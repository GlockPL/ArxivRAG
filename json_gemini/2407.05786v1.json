{"title": "Large Language Models for Judicial Entity Extraction: A Comparative Study", "authors": ["Atin S.Hussain", "Anu Thomas"], "abstract": "Domain-specific Entity Recognition holds significant importance in legal contexts, serving as a fundamental task that supports various applications such as question-answering systems, text summarization, machine translation, sentiment analysis, and information retrieval specifically within case law documents. Recent advancements have highlighted the efficacy of Large Language Models in natural language processing tasks, demonstrating their capability to accurately detect and classify domain-specific facts (entities) from specialized texts like clinical and financial documents. This research investigates the application of Large Language Models in identifying domain specific entities (e.g., courts, petitioner, judge, lawyer, respondents, FIR nos.) within case law documents, with a specific focus on their aptitude for handling domain-specific language complexity and contextual variations. The study evaluates the performance of state-of-the-art Large Language Model architectures, including Large Language Model Meta AI 3, Mistral, and Gemma, in the context of extracting judicial facts tailored to Indian judicial texts. Mistral and Gemma emerged as the top-performing models, showcasing balanced precision and recall crucial for accurate entity identification. These findings confirm the value of Large Language Models in judicial documents and demonstrate how they can facilitate and quicken scientific research by producing precise, organised data outputs that are appropriate for in-depth examination.", "sections": [{"title": "1. Introduction", "content": "Domain-specific entity recognition is a pivotal component in the realm of natural language processing, especially within specialized domains such as the legal field. The task involves identifying and classifying judicial entities such as petitioner, respondents, and judges, attorneys etc. which are foundational for a variety of applications. These applications include relation extraction,, machine translation, sentiment analysis at the entity level, faceted search, knowledge base construction, and information retrieval Thomas and Sangeetha (2019). Finding domain-specific entities and their relationships helps improve the indexing and retrieval of legal texts and is helpful as a first step in feature selection for text clustering, classification, as well as information selection for text summarization. Furthermore, a well-tuned entity recognition(ER) system forms a basis for various applications in the legal domain as follows.\nLegal Question-answering system: Judicial facts are essential in determining the responses to factoid queries. For instance, if the query is, \"Who is the appellant in a particular judge- ment?\" The answer will be predicted by the question processing module to be some judicial entity. In the event that \"Mr. X\" is the response and the data set has judicial entities assigned to it, the question-answering system would recognise that \"Mr. X\" is an entity and that it may be the response.\nCreation of a knowledge graph: We can present the textual data in graphical form, such as entity-relationship graphs, if we could identify the NEs in the judicial text and the relationships among those entities.\nThese graphs can be used to answer complicated relationship inquiries. Moreover, text summary is facilitated by the detection and annotation of the most pertinent information associated with a NE. Thomas and Sangeetha (2022)\nCase-Based Reasoning: The foundation of case-based reasoning is the knowledge input that may be obtained from extracted information found in court language. This information can be fed into a variety of expert systems, including business intelligence tools and predictive analytics software. Thomas (2024)\nRelation Extraction (RE): Entity Recognition plays a pivotal role in relation extraction from judicial text by identifying key entities such as names of judges, plaintiffs, defendants, legal entities, and locations mentioned within the text. Once these entities are identified, RE identifies the relationships between them, aiding in the extraction of pertinent legal relations, such as \"defendant accused of crime,\" \"plaintiff filed a lawsuit against defendant,\" or \"court ruled in favor of plaintiff.\" Thomas and Sivanesan (2022). Moreover, relation triplets can be utilized as features for other machine learning applications, such text categorization, document summarization, paraphrase detection, and so on.\nThe capabilities of ER systems have significantly advanced with the introduction of Large Language Models (LLMs). Equipped with advanced natural language processing methods, LLMs have shown to be extraordinarily adept in identifying and classifying objects in a wide range of complex texts. They excel at understanding and processing natural language, which makes them well-suited to handle the complexities of legal documents, which frequently include complex context and specialized terminologies.\nThrough this exploration, we aim to shed light on the potential of LLMs to revolutionize ER in legal texts with zero-shot learning, paving the way for more efficient and accurate information retrieval and management within the judicial system.\nThe key contribution of this paper is:\n\u2022 Evaluating the effectiveness of cutting-edge LLMs (like LLAMA 3 (Large Language Model Meta AI 3), Mistral, and Gemma) for domain-specific ER tasks within Indian legal texts."}, {"title": "2. Related Works", "content": "The field of generic Named Entity Recognition (NER) has seen substantial advancements, particularly with the integration of machine learning and deep learning techniques. Early approaches relied on rule-based and statistical methods, such as Hidden Markov Models (HMMs) and Conditional Random Fields (CRFs), which, while effective to some extent, often struggled with domain-specific language and lacked generalization capabilities.\nThe introduction of neural network-based models marked a significant leap in NER performance. Recurrent Neural Networks (RNNs), and more specifically Long Short-Term Memory networks (LSTMs), improved the ability to capture sequential dependencies in text. The advent of attention mechanisms and Transformers further revolutionized the field, leading to the development of pre-trained language models such as BERT (Bidirectional Encoder Representations from Transformers). BERT's contextual understanding and"}, {"title": "3. Large Language Models", "content": "This paper compares the following 4 different state-of-the-art Large Language Models in the task of domain specific Entity Recognition for legal documents:\n\u2022 LLaMA 3 [AI@Meta (2024)]: The latest generation of Meta's open-source large language model, represents a significant advancement in natural language processing capabilities, making it highly suitable for complex tasks such as Entity Recognition (ER) in legal documents. Featuring models with up to 70 billion parameters, LLaMA 3 excels in understanding and generating human-like text, demonstrating state-of-the-art performance across various benchmarks. Its enhanced architecture, including a more efficient tokenizer and grouped query attention, ensures superior inference efficiency and accuracy. These improvements make LLaMA 3 particularly effective in handling the specialized terminology and nuanced context typical of legal texts, thereby facilitating precise entity identification and categorization critical for legal information retrieval and document management.\n\u2022 Gemma [Team et al. (2024)]: Developed by Google DeepMind and other teams across Google, represents a family of lightweight, state-of-the-art open models designed for high performance and broad accessibility. Available in two sizes, Gemma 2B and Gemma 7B, these models are optimized for diverse AI applications, including Entity Recognition (ER) in legal documents. Gemma models are pre-trained and instruction-tuned, allowing them to efficiently handle the complex and domain-specific language found in case law texts. They surpass significantly larger models on key benchmarks, making them suitable for deployment on various platforms, from laptops to cloud infrastructures like Google Cloud. The incorporation of advanced fine-tuning techniques and robust evaluation processes ensures Gemma models produce safe and reliable outputs, crucial for maintaining the integrity of legal document processing. By leveraging these capabilities, the Gemma model holds promise for enhancing the accuracy and efficiency of ER tasks in the legal domain.\n\u2022 Phi 3 [Abdin et al. (2024)]: The model, developed by Microsoft, represents a significant advancement in small language models (SLMs), offering exceptional performance and cost-effectiveness. Particularly relevant to Entity Recognition tasks in legal documents, Phi-3 models, such as the Phi-3-mini, excel due to their ability to handle long context windows up to 128K tokens. This capacity is crucial for processing extensive legal texts, ensuring comprehensive entity recognition across large document spans. Phi-3's instruction-tuned design and optimized performance across various hardware platforms, including on-device use, facilitate efficient and accurate ER in resource-constrained environments. The model's strong reasoning and logic capabilities further enhance its suitability for the analytical demands of legal document processing, providing a powerful tool for improving the efficiency and accuracy of legal information retrieval.\n\u2022 Mistral [Jiang et al. (2023)] : A powerful 7.3 billion parameter language model, demonstrates remarkable capabilities in natural language processing tasks, outperforming larger models like Llama 2 13B across various benchmarks. Utilizing advanced techniques such as Grouped-query attention (GQA) and Sliding Window Attention (SWA), Mistral 7B achieves faster inference and handles longer sequences more efficiently. These features make it particularly suitable for ER tasks in legal documents, which often involve processing extensive texts with complex domain-specific language. The model's ability to be fine-tuned easily for specific tasks further enhances its applicability in the legal domain, where precision and context understanding are crucial. Given its superior performance and efficiency, Mistral 7B is well-equipped to improve the accuracy and effectiveness of ER systems in legal document analysis."}, {"title": "4. Methodology", "content": "In this study, we employ few-shot prompt engineering to leverage the capabilities of large language models for judicial ER in legal documents. This technique involves crafting a single, carefully designed prompt that instructs the LLM to generate responses in a specified JSON format. The JSON response includes both the extracted text and the corresponding entity labels from the input document. This approach is particularly advantageous as it eliminates the necessity for extensive task-specific training. By directly utilizing the pre-trained LLM's advanced natural language understanding, we can efficiently identify and label entities within legal texts, streamlining the process and reducing the overhead typically associated with model training and fine-tuning."}, {"title": "5. Results and Discussions", "content": "We evaluate the model on the InLegalNER dataset [Kalamkar et al. (2022)] to rigorously assess the performance of Large Language Models on domain-specific Entity Recognition tasks. The InLegalNER dataset is specifically designed to encompass a comprehensive range of entities pertinent to the legal domain, thereby providing a robust benchmark for evaluating the capability of LLMs in recognizing and categorizing legal entities accurately.  This evaluation aims to highlight the effectiveness of LLMs in handling the specialized terminology and context inherent in legal documents, thereby contributing to the advancement of ER methodologies in this critical domain."}, {"title": "5.3. Comparative Analysis", "content": "Overall, Mistral emerged as the best-performing model with the highest F1 score of 0.6376, closely followed by Gemma with an F1 score of 0.6353. Both models demonstrated a good balance between precision and recall, making them suitable for the NER task in legal documents. LLaMA 3, despite its higher precision, lagged in recall, indicating potential gaps in entity recognition. Phi 3 showed the least favorable performance across all metrics, suggesting it is less suited for this specific task compared to the other models evaluated.\nThese evaluations underscore the importance of considering both precision and recall in ER tasks, particularly in the legal domain where the accurate and comprehensive identification of entities is crucial. The results highlight Mistral and Gemma as robust options for further exploration and deployment in legal ER applications."}, {"title": "6. Conclusion", "content": "In conclusion, our study evaluated several state-of-the-art LLMs for legal entity recognition from Case Law Documents, focusing on their performance in handling domain-specific language within Indian judicial texts. Mistral and Gemma emerged as the top-performing models, showcasing balanced precision and recall crucial for accurate entity identification. These findings underscore the potential of LLMs to revolutionize ER in legal documents, offering efficient and precise entity recognition capabilities that benefit legal information management and analysis. Continued advancements in LLM architectures hold promise for further enhancing ER systems in the legal domain."}, {"title": "7. Funding", "content": "This study received no external funding."}, {"title": "8. Competing interests", "content": "The authors declare that they have no competing interests"}, {"title": "9. Availability of data and materials", "content": "The used and/or during the current study (the bibliography of included studies) are available from the corresponding author upon request."}, {"title": "Acknowledgements", "content": "Not applicable."}]}