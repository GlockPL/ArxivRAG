{"title": "AI-Driven Approaches for Glaucoma Detection - A Comprehensive Review", "authors": ["Yuki Hagiwara", "Octavia-Andreaa Ciora", "Maureen Monnet", "Gino Lancho", "Jeanette Miriam Lorenz"], "abstract": "The diagnosis of glaucoma plays a critical role in the management and treatment of this vision-threatening disease. Glaucoma is a group of eye diseases that cause blindness by damaging the optic nerve at the back of the eye. Often called \"silent thief of sight\", it exhibits no symptoms during the early stages. Therefore, early detection is crucial to prevent vision loss. With the rise of Artificial Intelligence (AI), particularly Deep Learning (DL) techniques, Computer-Aided Diagnosis (CADx) systems have emerged as promising tools to assist clinicians in accurately diagnosing glaucoma early. This paper aims to provide a comprehensive overview of AI techniques utilized in CADx systems for glaucoma diagnosis. Through a detailed analysis of current literature, we identify key gaps and challenges in these systems, emphasizing the need for improved safety, reliability, interpretability, and explainability. By identifying research gaps, we aim to advance the field of CADx systems especially for the early diagnosis of glaucoma, in order to prevent any potential loss of vision.", "sections": [{"title": "I. INTRODUCTION", "content": "Glaucoma is a group of eye diseases that can lead to blindness due to the damage to the optic nerve at the back of the eye. It is commonly associated with increased in-traocular pressure [1]. This elevated pressure pushes against the optic nerve, damaging its fibers, which in turn leads to the deterioration of the Retinal Nerve Fiber Layer (RNFL) and results in an enlarged Cup-to-Disc Ratio (CDR) or Optic Nerve Head (ONH). Hence, a greater CDR is often associated with glaucoma. The CDR is typically determined via the ratio of the vertical diameter of the Optic Cup (OC) to the vertical diameter of the Optic Disc (OD) [2]. It is the leading cause of irreversible blindness. According to the 2024 Glaucoma Report, it is estimated that currently, 80 million people globally have glaucoma [3]. It is estimated that 111.8 million people will be affected by glaucoma in 2040 [4]. It is often referred to as the \"silent thief of sight\" as it exhibits no symptoms during the early stages. Therefore, it is crucial to detect glaucoma early [5]. However, it is challenging to detect glaucoma during its early stages. Many factors contribute to this difficulty, including the subtle nature of early symptoms and the reliance on nuanced interpretations of retinal images. Doctors, especially those who are new or less experienced, may find it challenging to make accurate diagnoses [6]. Moreover, diagnoses can be subjective which could lead to inconsistencies and delays in identifying the disease.\nWith the rise in Artificial Intelligence (AI), particularly Deep Learning (DL) techniques, Computer-Aided Diagnosis (CADx) systems have emerged as promising tools to assist clinicians. A CADx system is a safety-critical system within the medical field that provides automated medical diagnoses based on input medical imaging data, such as differentiating between a healthy fundus image and a glaucomatous fundus image. \nIn the development of CADx systems, various AI techniques play pivotal roles:\n\u2022 Computer Vision (CV): They are employed in the early stages of the CADx pipeline, such as image prepro-cessing, segmentation, etc. They are often used with traditional Machine Learning (ML) techniques.\n\u2022 Traditional ML: They are often used with CV techniques, and used mainly in the classification stage of the CADx pipeline.\n\u2022 DL: A subset of ML, they utilize neural networks with many layers to automatically learn features from large datasets.\n\u2022 Hybrid approaches: Some studies combine CV, tradi-tional ML, and DL techniques to leverage the strengths of each method.\n\u2022 Comparison: Some studies explicitly compare the diag-nostic performances of CV and traditional ML with DL techniques.\nRegulated as medical devices, CADx systems must undergo rigorous evaluation and compliance measures to ensure their safety and efficacy in clinical practice. These systems can provide objective assessments, helping to standardize the diagnostic process and improve early detection accuracy if developed reliably.\nIn this review, we focus on the development of CADx systems in glaucoma diagnosis. In the context of glaucoma diagnosis, demographic information of the patient are first gathered, and then relevant clinical eye examinations are conducted. Then, eye images using various retinal imaging technologies are acquired from the patient. The data are then fed into the CADx system for automated diagnosis."}, {"title": "II. SEARCH STRATEGY (METHODOLOGY)", "content": "A systematic search was conducted following the Preferred Reporting Items for Systematic Reviews and Meta-Analy (PRISMA] guidelines to retrieve relevant studies from databases such as IEEE Xplore, ScienceDirect, and PubMed using the Boolean search string \u201cglaucoma\u201d, \u201ccomputer-aided diagnosis system\", \"medical decision support system\", \"machine learning\", and \"deep learning\", covering the period from 2013 to 2023. This approach aims to systematically identify relevant studies on glaucoma diagnosis using CADx systems with AI-based techniques. A total of 6,205 studies were initially identified across the 3 databases. After removing duplicates, review papers, non-English publications, master's research, and papers irrelevant to glaucoma detection using AI-based techniques, 3,617 studies remained. Conference papers were included in this review. Then, 3,275 studies were further removed after a thorough review of abstracts and full texts, as they were deemed irrelevant to the focus of our review. The final selection yielded a total of 342 studies over the course of 10 years.\nFigure 3 provides the breakdown of the number of papers published each year from 2013 to 2023. Generally, it can be seen that the numbers of publications increase over the course of the years. The increasing number of publications each year reflects a growing interest and investment in AI-based glaucoma diagnosis, suggesting a need for comprehensive review and analysis to identify areas for further research and development.\nA literature review over the past 10 years, there have been 82 studies using CV and traditional ML tech-niques, 203 studies using DL techniques, 39 studies employing hybrid approaches, and 18 studies specifically comparing CV and traditional ML with DL techniques.\nNotably, there has been a significant surge in DL-based"}, {"title": "III. RESULT", "content": "This section provides a summary of the reviewed papers, including an overview of the data used, the medical application areas, a breakdown of the specific ML tasks, the types of AI-based techniques employed, and the evaluation metrics applied.\nIn clinical practice, the diagnosis of glaucoma typically involves the integration of various types of data, includ-ing health records, tonometry to measure the intraocular pressure, clinical examination on the ONH, RNFL, vi-sual field testing, and advanced imaging techniques like"}, {"title": "C. Categorization of ML-specific Task", "content": "Based on the literature review, we found that regardless of which AI-based technique used, the studies can be broadly categorized into 3 main types: (1) Segmentation, (2) Segmentation and classification, and (3) Classification tasks. There are approximately 12.6%, 27.2%, and 58.5% studies in each of these categories, respectively. Within the segmentation tasks, OD, OC, and blood vessels are commonly being localized and segmented in order to obtain the CDR which is essential for classifying glaucoma. The RNFL and peripapillary atrophy are also of interest to clinicians for the diagnosis of glaucoma. These features are often extracted from the images since they are clinically relevant in the diagnosis of glaucoma. Within the classification tasks, besides the prevalent binary classification (distinguishing between normal and glaucoma classes), multi-class classifications are also frequently employed. Specifically, 78.5 % of these studies within the classification task focused on binary classification and 21.5% of the studies dedicated to multi-class classification, which involve either differentiating between various stages or types of glaucoma, or different eye diseases such as diabetic retinopathy and age-related macular degeneration. Additionally, a few papers, approximately 1.7 % of the papers have included other elements such as re-gression, integrative index (e.g., glaucoma score, risk score, etc.), confidence scores, uncertainty scores, probabilities, and visualization techniques such as heat maps, attention maps, and saliency maps to promote explainability in their models. Nevertheless, a handful of papers focus on other aspects of ML task such as synthesizing images, reconstructing images, domain adaptation, and out-of-distribution detection."}, {"title": "D. Computer Vision and Traditional Machine Learning Approaches", "content": "In accordance with traditional ML-based and CV techniques in the literature, the majority of studies have followed the standard workflow of a typical CADx system (see Figure 1). Typically, the preprocessing, localization and segmentation, features extraction, and features selection/reduction/ranking employ CV techniques. These steps are focused on processing and analyzing the images to extract meaningful information that can be used for diagnosis. In contrast, the classification stage employs traditional ML-based techniques, as the classi-fier requires an ML algorithm to classify images or segmented regions based on the extracted features.\n1) Preprocessing: Preprocessing is a crucial step performed on images before segmentation or features extraction to en-hance image quality and standardize their size. Common techniques implemented for glaucoma related tasks include image standardization [52] and normalization, such as contrast stretching [53], which help improve image consistency and contrast. Histogram Equalization (HE) [54]\u2013[57], Adaptive Histogram Equalization (AHE) [58]\u2013[61] and its variant, the Contrast Limited Adaptive Histogram Equalization (CLAHE) [62]\u2013[75] [76] are widely used to enhance image quality. Additionally, various filtering techniques are employed for noise removal and texture improvement, including Histogram smoothing [52], Median filtering [57], [63], Wiener filtering [63], [73], Anisotropic filtering [77], [78], Gabor filtering [79], and Gaussian filtering [56], [80].\nRegion of Interest (ROI) selection [81], particularly focus-ing on OD [40], [53], [82], [83], and conversion to grayscale [54], [60], [65], [72], [74], [78], [84]\u2013[86] or specific channel extraction [52], [56], [57], [66], [80], [87]\u2013[93] are also fre-quently performed to focus on relevant areas for their diagnosis tasks.\n2) Segmentation: Multiple studies focused specifically on the localization and segmentation of crucial clinical features such as the OD, OC, and blood vessels to detect glaucoma. This could be due to the fact that these clinical parameters are the primary factors that help doctors with the diagnosis of glaucoma. They rely on the computation of these clinical parameters to make an appropriate diagnosis. However, it is time-consuming and highly subjective to identify these regions. [94] focused on the segmentation of OD and OC by proposing an improved CV technique using the locations of the blood vessels bends and to determine the values of the CDR based on active contour models for the classification of"}, {"title": "3) Features Extraction:", "content": "Feature extraction techniques are crucial in the analysis of medical images such as glaucoma detection to extract meaningful information from the images for diagnoses. These techniques can be grouped into various categories based on the type of features they extract. The following categories are defined based on the 83 traditional ML and CV review papers clinical features, textural fea-tures, transform-based features, non-linear and entropy-based features, and statistical-based features.\n\u2022 Clinical features: They are derived from specific medical measurements and anatomical properties relevant to the diagnosis of glaucoma. The common clinical features extraction based on the literature are CDR obtained from OD and OC [52], [53], [56], [81], [82], [100], rim width based on the Inferior-Superior-Nasal-Temporal rule [56], [81], detection of peripapillary atrophy [101], retinal blood vessel [83], and retinal nerve fiber layer [29], [102]\u2013[104].\n\u2022 Textural features: These features capture the surface properties and spatial relationships of pixel intensities in an image, providing information regarding patterns, edges, and pixel intensity distribution [105]. A few commonly employed techniques found in the literature review are Local Binary Pattern (LBP) [53], [61], [66], [93], [106], Local Configuration Pattern (LCP) [60], Grey Level Co-occurrence Matrix (GLCM) [53], [69], [72], [78], [80], [84], [107]\u2013[110], Grey Level Run Length Matrix (GLRM) [84], [93], [109], Histogram of Oriented Gradients (HOG) [109], [111], [112], Hu moments [80], [107], and central moments [107].\n\u2022 Transform-based features: These involve transforming the image into different domains to extract features. Wavelet transform [67], [70], [83], [84], [106], empirical wavelet transform [68], [89], fast Fourier transform [56], Radon transform [58], [67], [113], Gabor transform [53], [59], [79], [80], [114], wavelet packet decomposition [54], empirical mode decomposition [75], hyper analytic wavelet transform [55], and variational mode decomposition [62] are a few techniques that are being applied according to the review papers.\n\u2022 Non-linear and entropy-based features: These features can detect subtle pixel variations in the images. A few examples of non-linear features used in the pa-pers are Higher Order Spectra (HOS) [71], [84], [115], Higher Order Cumulant (HOC) [58], [84], and fractal dimension [71]. Entropy-based features capture the ran-domness and complexity of the images. Some examples of these entropy methods are Kapur [71], Yager [71], Shannon [64], [71], Tsallis [64], and Renyi [71].\n\u2022 Statistical-based features: These features extract the fun-damental characteristics of the data. Some examples of statistical features are mean, variance, standard deviation, skewness, and kurtosis [77], [78], [86]."}, {"title": "4) Features Selection, Reduction, Ranking:", "content": "The diagnostic performance of CADx systems utilizing CV and traditional ML-based techniques typically depends on the features ex-tracted. Hence, feature selection, reduction, and ranking tech-niques are crucial for refining the feature set to be fed into the classifier for classification [116]. Below are the various techniques employed based on the literature review.\nFeature selection techniques such as ReliefF [62], [84], [117], Sequential Floating Forward Search (SFFS) [60] and Minimum Redundancy Maximum Relevance (MRMR) [44] are employed to identify the most relevant features. Student's t-test [43], [59], [66], [68], [69], [72], [87], [89], [102], [113], chi-squared test [102], and Wilcoxon test [59], [113] are statistical methods employed to assess the significance of the extracted features in distinguishing between different classes (in this case, glaucoma or healthy). P-values are computed for each feature and they are ranked to select the most relevant and significant features for classification [60]. Bhattacharyya distance [59], [113] and Fisher discriminant index [58] are examples of feature ranking techniques employed to rank features according to their ability to distinguish the different classes.\nFeature reduction techniques as such Prinicipal Component Analysis (PCA) [53], [59], [65], [67], [75], [83], [87], [92], [106], [118], Linear Discriminant Analysis (LDA) [58], [93], local Fisher discriminant analysis [58], [82], and Locality Sensitive Discriminant Analysis (LSDA) [113] are applied to transform and reduce the dimensionality of the feature space, enhancing computational efficiency while preserving essential information.\nTo further refine the feature selection process, optimization algorithms are also employed. Algorithms such as Group Search Optimizer [55], Particle Swarm Optimization [55], Glowworm Swarm Optimization [98], Gravitational Search Optimization [119], Lion Optimization algorithm [73], Grey Wolf Optimization [73], and Salp Swarm Optimization [73] are being applied in the papers reviewed. These algorithms iteratively search for the optimal subset of features to feed into the classifier in the next step of the workflow."}, {"title": "5) Classification:", "content": "The final step in a traditional CADx pipeline is classification. Among the many classifiers, Support Vector Machine (SVM), Random Forest (RF), and k-Nearest Neighbor (KNN) are the 3 most commonly used classifiers as per the review papers. According to these papers, there are a total of 51, 19, and 14 studies that employed SVM, RF, and KNN classifiers respectively. Beyond these classifiers, others are also being used. A few examples are Decision Tree (DT), Rotation Forest (RF), Logistic Regression (LR), adaboost, and Na\u00efve Bayes (NB) classifiers. A handful of papers also employed ensemble classifiers [29], [36], [49], [61], [72], [74], [80], [102], [119] to leverage the strengths of multiple individual classifiers and then averaging their probabilistic predictions to obtain more generalized diagnostic performances."}, {"title": "E. Deep Learning Approaches", "content": "Of the 203 reviewed DL papers, approximately 61 % (124 papers) utilized transfer learning techniques. The remaining papers employed various methods, including CNN (52 papers), Capsule Network (CapsNet) (2 papers), Recurrent Neural Network (RNN) (4 papers), Autoencoders (3 papers), Generative Adversarial Network (GAN) (11 pa-pers), and Vision Transformers (ViT) (7 papers). In the subsequent subsections, we categorize and describe the reviewed papers according to these DL-based techniques.\n1) Convolutional Neural Network: CNN architectures have been widely employed for glaucoma detection due to their ability to automatically learn hierarchical features from fun-dus images. These architectures typically consist of multiple convolutional layers followed by fully connected layers, with techniques like dropout and data augmentation to prevent over-fitting and improve robustness. Deep CNNs can be employed for classification, producing a probability distribution across various classes, or for segmentation, generating predictions for each individual pixel. [120], [121], [122], [123], [124] and [125] employed relatively shallow CNN architectures comprising between one and seven convolutional layers for binary glaucoma classification, where the probability of the input image being a glaucoma is predicted. Similarly, [126] developed an 18-layer CNN, emphasizing the importance of removing preprocessing steps and handcrafted features to streamline the diagnostic process, while [127] proposed a 24-layer CNN model to identify regions of interest in retinal fundus images. [128] proposed a method for segmenting retinal images using a hierarchical CNN where filters are learned sequentially using boosting.\nEstablished CNN architectures such as VGG, ResNet, and others have been extensively employed to advance glaucoma detection and diagnosis. [129] focused on binary classification problem of glaucoma in fundus images using a simplified ResNet architecture. [130] utilized VGG-19 for glaucoma classification using thickness and deviation maps of retinal nerve fiber layer and ganglion cell-inner plexiform layer OCT images. [131] utilized Wide-field OCT images with VGG19-based CNNs to diagnose glaucoma with a high degree of accu-racy. Their methodology includes sophisticated fusion strate-gies that combine multiple OCT image views, thus capturing a comprehensive representation of the retina. [132] employed a modified Xception network for glaucoma classification, while [133] built upon the GoogLeNet architecture, known for its efficient utilization of parameters through Inception modules, to classify glaucoma. In their work, [124] introduced GlauNet, a tailored CNN architecture designed for diagnosing glaucoma from OCT-A images, and benchmark it against VGG16, ResNet50, and EfficientNetV2. [134] developed a region-based deep convolutional neural network (R-DCNN) based on ResNet34 for segmenting OD and OC by treating OD and OC segmentation as object detection problems. Notably, the network architecture included specialized components: a disc proposal network (DPN) and a cup proposal network (CPN) sequentially proposing minimal bounding boxes for OD and OC. In a different approach, [135] focused on enhancing prediction reliability by integrating Multi-Sample Evidential Deep Learning (MS-EBDL) and multi-sample dropout into a VGG16 backbone to reduce uncertainty and improve un-certainty estimation, a critical aspect for clinical applications where prediction confidence can directly impact decision-making.\nThese well-established network architectures often come with pre-trained weights, which are extensively utilized in research on glaucoma detection. The goal of transfer learning is to leverage these pre-trained networks to build upon their existing knowledge, thus enhancing model accuracy and effi-ciency in medical imaging tasks such as glaucoma detection. They are typically trained on the ImageNet dataset [136], a large-scale visual database designed for image classification and object detection tasks, containing millions of labeled images across thousands of categories. Other datasets, like Pascal VOC 2007 [137], ILSVRC (ImageNet Large Scale Visual Recognition Challenge) [138], and COCO (Common Objects in Context) [139], are sometimes also used for pre-training. Pascal VOC 2007 focuses on object detection and segmentation, ILSVRC is a subset of ImageNet, and COCO provides detailed object segmentation and recognition tasks. These networks are thereby initially trained on natural images, which may not directly resemble the medical images used for glaucoma detection. Despite this discrepancy, leveraging pre-trained weights from these datasets proves highly effective in medical applications. The networks learn to identify and abstract various features from the extensive and diverse natural images, which can be useful for detecting relevant patterns in medical images.\nMore recently, EfficientNet-based architectures have been used, where EfficientNet is implemented as the backbone of a CNN model to achieve high accuracy and efficiency. [140] and [141] utilized EfficientDet-D0, with EfficientNet-BO as the backbone, to perform precise localization and classification of OD and OC regions. The Bi-Directional Feature Pyramid Network (BiFPN) in EfficientDet-D0 facil-itates advanced feature extraction by merging information from different scales, ensuring robustness even under varying conditions such as noise and blurring. Further extending the application of EfficientNet, [142] introduced the EARDS framework, which combines EfficientNet-B0 with attention mechanisms and Residual Depth-wise Separable Convolutions. This architecture segments OD and OC regions by enhancing feature focus and computational efficiency. The integration of Attention Gates (AG) within the network ensures that relevant features are highlighted, which is crucial for the precise calculation of the CDR, a key indicator for glaucoma. Complementary work focuses on developing efficient mod-els designed for glaucoma detection, aiming for deployment in resource-constrained environments. [143] leveraged the MobileNet architecture to classify glaucoma in fundus images, emphasizing computational efficiency and speed. MobileNet's unique use of depthwise and pointwise convolutions reduces the number of parameters and operations, making it highly suitable for mobile and low-resource settings. [144] intro-duced a depthwise separable convolution approach based on MobileNet to reduce computational complexity. [145] intro-duced Efficient Shallow Segmentation Network (EE-Net) and Feature-Blending-based Shallow Segmentation (FBSS-Net), which incorporate feature blending mechanisms to improve segmentation accuracy while maintaining computational effi-ciency. Efficiency is crucial for real-world applications where quick, reliable diagnostics can significantly impact patient outcomes. By optimizing CNN architectures for speed and resource use without sacrificing accuracy, these studies un-derscore the potential of deploying AI in diverse healthcare environments, particularly in areas with limited access to specialized medical equipment and expertise.\nThree-dimensional CNNs have been explored for glaucoma detection in notable studies. [146] and [147] developed such models, with Noury et al. creating a DenseNet-based ar-chitecture specifically for SD-OCT ONH cube scans, while Zang et al. employed a custom 3D CNN architecture with 16 convolutional layers that integrates both 3D OCT and OCT-A data.\nU-Net architectures and their variants have also emerged as powerful tools for the segmentation of OD and OC in fundus images, essential for accurate glaucoma diagnosis. The foundational U-Net structure, characterized by its encoder-decoder architecture, has been adapted in several studies to address the specific challenges posed by medical image seg-mentation. [148] introduced a U-Net with multi-scale inputs and side-output layers to enhance the segmentation accuracy of OD and OC. Similarly, [149] designed a U-shaped CNN with multi-scale and multi-kernel modules to better capture OC information of different sizes. [150] used dynamic region proposal networks based on U-Net architectures, optimizing OD and OC segmentation through parameter sharing and dynamic cropping. [151] proposed a encoder-decoder based fully convolutional network for monocular retinal depth es-timation and and Optic Disc-Cup Segmentation, integrating depth maps with RGB images for enhanced segmentation performance. The work by [152] explored the generalizability of U-Net models across different datasets. [153] and [154] also employed U-Net architectures, integrating in the latter various modifications such as feature detection sub-networks to preserve important image textures, thereby achieving signif-icant improvements in segmentation accuracy. [155] proposed SLS-Net and SLSR-Net, two encoder-decoder architectures inspired by U-Net aimed at minimizing spatial information loss by maintaining large feature map size for fundus image segmentation.\nThe use of multi-task and multi-branch CNNs has also shown significant promise in improving the accuracy and robustness of glaucoma detection and classification. These architectures typically involve multiple stages or branches, each designed to handle different aspects of the diagnostic process. For instance, [156], [157] and [158] simultaneously addressed segmentation and classification tasks to enhance diagnostic accuracy. Bajwa et al. proposed a two-stage frame-work employing Regions with Convolutional Neural Networks (RCNN) for the localization and extraction of the OD, fol-lowed by a CNN to classify the extracted OD as either healthy or glaucomatous, while Mojab et al. addressed the dual challenges of clinical interpretability and limited labeled data by integrating a segmentation module (U-Net) and a prediction module (VGG16). Hervella et al.'s model integrated OD and OC segmentation with glaucoma classification, maximizing parameter sharing between tasks to leverage both pixel-level and image-level information. This method employs a multi-adaptive optimization strategy, ensuring balanced task influ-ence during training. [41] integrated multiple CNNs, including VGG16, ResNet18, ResNet50, DenseNet121, and MobileNet, in a semi-supervised multi-task learning framework to process OCT images and address missing labels. The primary task is glaucoma classification and the second one is visual field measurement regression. [159] also introduced a dual-step approach to localize the OD, followed by the regression of"}, {"title": "the CDR.", "content": "They combined Faster R-CNN for OD localization with DenseNet for CDR estimation", "160": "proposed a multi-level deep CNN com-prising detection and classification phases", "27": "developed multi-branch networks that integrate domain knowledge with CNN-extracted features to enhance diagnostic performance. The multi-branch approach allows these models to leverage both global and localized features", "28": "then proposed a bayesian deep multisource learning model that uses Monte Carlo dropout for Bayesian inference", "161": "proposed a framework for multi-disease identification", "162": "utilized a winner-take-all neural network for region of interest identification", "163": "proposed Self-ONNs", "164": "introduced a novel approach specifically tailored to address data imbalance issues in glaucoma de-tection. The study employs Self-Ensemble Dual-Curriculum learning (SEDC)", "165": "introduced an attention-based CNN that leverages attention maps to highlight salient regions in fundus images", "166": "utilized self-attention within an EfficientNet-B7 backbone for accurate segmentation of the OC and OD. The use of self-attention en-hances the model's ability to capture intricate details necessary for precise CDR calculation. Similarly", "167": "integrated multi-head self-attention with elements from Residual Networks", "168": "built on a VGG framework with integrated attention mechanisms. Their model employs a dynamic receptive field module and a coor-dinate attention mechanism", "black boxes,\u201d novel architectures have been developed to provide greater transparency in their decision-making processes. For instance, [169": "and [170", "171": "introduced EAMNet", "172": "and [173", "Network": "RNNs are designed to han-dle sequential inputs. Although RNNs are not commonly employed in medical imaging applications", "174": "presented a novel combined CNN-Long Short-Term Memory (LSTM) architecture. While the end-to-end solution is based on 3D spectral domain OCT data", "175": "relied on LSTM in a slightly different use case to improve glaucoma detection based on image and video fundus data. By leveraging the temporal sequence of the video data and spatial feature extraction for each frame with VGG16 and ResNet50", "176": "preprocessed retinal fundus images using HE technique and CLAHE", "177": "proposed a Damped Least-Squares Recurrent Deep Neural Learning based on fundus image data. For effective glaucoma disease detection", "Autoencoders": "The autoencoder is an unsupervised rep-resentation learning technique that relies on an encoder de-coder network architecture to (1) transform the input data into a lower-dimensional encoded representation and (2) recon-struct the original input data from this encoded representation. This approach is particularly useful in medical applications", "limited.\n[178": "proposed a G-EyeNet which combines a deep convo-lutional autoencoder and a traditional CNN classifier. It first segments the OD via U-Net then fed the segmented image into their proposed model. They used autoencoders in their work as they mentioned that autoencoders learn a low-dimensional representation of an input and therefore", "179": "proposed to cascade two sparse autoencoders with a softmax layer to classify normal and glaucoma images. Their proposed technique outperformed various traditional ML classifiers and CNN models. [180"}, {"Network": "GAN, with their abil-ity to generate synthetic data, improve image resolution, and adapt to different imaging conditions, have been extensively researched for their potential to improve glaucoma detection. The utilization of GANs to perform image synthesis and augment data for glaucoma classification first addresses the issue of data scarcity, enhancing the diversity and quality of training datasets. [181", "182": "utilized CycleGANs to transform fundus images, focusing on enhancing and degrading image quality to improve diagnostic models. This approach emphasizes the role of high-quality image diversity in training more effective classifiers. [183", "184": "employed a novel patch-based output space adversarial learning frame-work to segment the OD and OC from various sources of fundus images"}]}