{"title": "Evaluation of Google Translate for Mandarin Chinese translation using sentiment and semantic analysis", "authors": ["Xuechun Wang", "Rodney Beard", "Rohitash Chandra"], "abstract": "Machine translation using large language models (LLMs) is having a significant global impact, making communication easier. Mandarin Chinese is the official language used for communication by the government, education institutes, and media in China. In this study, we provide an automated assessment of machine translation models with human experts using sentiment and semantic analysis. In order to demonstrate our framework, we select classic early twentieth-century novel 'The True Story of Ah Q' with selected Mandarin Chinese to English translations. We also us Google Translate to generate the given text into English and then conduct a chapter-wise sentiment analysis and semantic analysis to compare the extracted sentiments across the different translations. We utilise LLMs for semantic and sentiment analysis. Our results indicate that the precision of Google Translate differs both in terms of semantic and sentiment analysis when compared to human expert translations. We find that Google Translate is unable to translate some of the specific words or phrases in Chinese, such as Chinese traditional allusions. The mistranslations have to its lack of contextual significance and historical knowledge of China. Thus, this framework brought us some new insights about machine translation for Chinese Mandarin. The future work can explore other languages or types of texts with this framework.", "sections": [{"title": "1. Introduction", "content": "Natural language processing (NLP) is a sub-field of artificial intelligence that focuses on the interaction between human languages and computers [1] [2] [3]. NLP is used in various fields of research, such as speech recognition, social media analytics, recommender systems, search engines, machine translation and computational linguistics [4][5]. Machine translation is a branch of NLP that focuses on the automated translation of one language into another through speech or text [6]. Computer-assisted translation (CAT) [7] is a software tool designed to help human translators to translate texts faster with better quality [8]. Machine translation systems integrated with CAT tools results in a more productive and accurate translation process [9]. CAT tools also aim to assist translators in editing and processing translation-related tasks and provides a translation memory system to store source sentences, and translated sentences for future use. CAT tools such as Trados, D\u00e9j\u00e0 Vu, MemoQ, Yicat are predominantly used.\nThe range of machine translation models used has changed over time, depending on computational power and technology change. The latest iteration of such models attempts to apply a deep learning model to the language translation problem. Deep learning models such as recurrent neural networks (RNNs)[10] have been prominent for text and sequence modelling [11] and their variations form the backbone of text processing and modelling [12] and machine translation systems[13]. RNNs also have been prominent in text classification and generation [14]. However, canonical models face training challenges and variations such as the long short-term memory (LSTM) [15] network has been used to address the problem of learning longterm dependencies. Further alterations led to the development of the Transformer model [16] which employs a multi-head attention mechanism borrowed from psychology and cognitive science. Soon afterwards, attempts to train Transformer models with large data corpora led to the development of large language models (LLMs) [17], including Bidirectional Encoder Representations from Transformers (BERT) [18, 19], and Generalised Pretrained Transformers (GPT) [20] with tools such as ChatGPT, GPT-4 and Gemini. Those models are widely utilised in a wide range of areas addressing problems such as sentiment analysis, text summarising, question-answering and search [21]. However, evaluation of the quality of large language models poses challenges since quantitative evaluation approaches have biases and there are also problems when it comes to explainability and interpretability [22].\nApart from Google Translate, DeepL is also a widely used machine translation system [23]. Yulianto et al. [24] quantitatively compared the performances between Google Translate and DeepL. The research assessed the quality of Google Translate and DeepL for French to English and the results showed that DeepL performed better than Google Translate in terms of accuracy and readability. Moreover, Cambedda et al. [25] studied on a comparative error analysis of a medical translation between DeepL and Yandex for Russian-Italian. This study used the Bilingual Evaluation Understudy (BLEU) [26] framework to assess the quality of output based on the textual similarities between a machine translation system and a human reference"}, {"title": "2. Related Work", "content": "The early work in machine translation began in the 1930s, which were mechanical, and it wasn't until the development of electronic computers that the possibility of machine translation became a real possibility [45] [46]. NLP was used in World War II for encrypting the secret messages of the German forces and transferring the message to the field commanders and military units of German troops placed in Europe [47]. One of the early NLP domains developed was machine translation and in the 1950s and 1960s, a multidisciplinary approach with cryptography, statistics, information theory and logic was employed for machine translation research [45].\nIt is noteworthy that Weaver proposed modern machine translation [48] in the 1950s. During that period of time, even though Weaver's memorandum was of little interest to most linguists or mathematicians, the memorandum still attracted such people as Bar-Hillel from the Massachusetts Institute of Technology and was widely circulated in 1948 [48]. Since then, machine translation has been popularised that attracted more researchers to the field. Machine translation includes machine learning, statistical and deep learning models [49]. Rule-based machine translation (RBMT) [50] is based on the syntactic, morphological, contextual and semantic, to perform the machine translation from source language to target languages. This approach was dominated until the late 1980s. The difficulties and problems of rule-based machine translation have arisen because of its time-consuming and complexity. Since then, statistical machine translation has been employed that generally relies on the data-driven approaches. Moses is a widely used and open-source statistical machine translation toolkit [51] that incorporates a number of language models, including a neural translation model. Moreover, it provides a number of functions such as data preprocessing, data-training, and fine-tuning in the toolkit."}, {"title": "2.2. Mandarin Chinese translation analysis", "content": "Early efforts in Mandarin Chinese machine translation began with Wang et al. [52] who developed the segmentation of Chinese character strings into words, conversion of traditional Chinese and simplified Chinese. Along with the development of Chinese computational linguistics research in the 21st century, numerous studies in the field of Mandarin Chinese translation have rapidly increased. For example, Wang et al. [37] introduced a set of syntactic rules that utilize systematic word order differences between Chinese and English, and further transform Chinese sentences to English with much closer word order. Wang et al. [37] reported that their reordering approach has improved translation quality with relatively reordering errors. Deng et al. [53] presented an empirical investigation that explored the divergences between English and Chinese by using a parallel tree bank to semi-automatically recognise divergences(such as lexical encoding, transitivity, absence of function words, category mismatch, reordering, dropped elements, and structural paraphrase) between English and Chinese. Furthermore, to evaluate the quality of machine translation from Chinese to English, Jia et al. [54] investigated the differences between from-scratch translation and post-editing of Google Translate using both qualitative and quantitative analysis, examining aspects such as accuracy and fluency from multidimensional perspectives. Post-editing is a time-consuming process involving manual analysis of text, which can be improved through innovations in NLP. Additionally, Ma et al. [55] proposed a survival generative adversarial network-based machine translation method to evaluate the short sequence machine translation from Chinese to English. These substantial studies expand the scope of machine translation from Chinese Mandarin to English."}, {"title": "2.3. Google Translate", "content": "On the other hand, since the advent of Google Translation in 2007, the core of Google Translate was to translate one language to another language including but not limited to words, sentences, paragraphs and articles via text and speech. Google Translate used statistical models and proved that results are better than rule-based system. Maulidiyah et al. [56] reported that in 2010, Google Translate was ranked first place among other search engines such as Yahoo, Baidu, Bing, and occupied 84.65% of the total market. Given the high penetration rate of Google Translate, researchers have explored the accuracy and precision of Google Translate. Li et al. [57] compared the Google Translate with expert (human) translation through its formality and cohesion. The correlation with formality is measured by Coh-Metrix [58], and Linguistic Inquiry and Word Count (LIWC) [59]. Moreover, the correlation with cohesion is measured by Latent Semantic Analysis (LSA) [60] and Content Word Overlap (CWO) [61]. Li et al. [57] concluded that both translations had high correlation in terms of both formality and cohesion.\nMoreover, Patil et al. [62] investigated the accuracy of Google Translate in medical communication with multiple languages, and reported 57.7% of correct translations and 42.5% incorrect; hence Google Translate could not be used for medical processes due to poor accuracy. Cromico et al. [63] evaluated the quality of the translation of English-Indonesian by utilising scientific articles, and reported that Google Translate was less readable, less accurate, and less acceptable for the target language. Therefore, although Google Translate has made life more convenient, the issues of inaccuracy, low precision and readability were still shortcomings of Google Translate. However, due to its popularity among the public and the large number of Chinese speakers, the quality of Google Translate for Chinese texts is worth exploring."}, {"title": "2.4. Mandarin Chinese", "content": "The Mandarin Chinese language is spoken by more than 1.1 billion people in the world with the majority of speakers residing in China [64]. Mandarin Chinese is the second most spoken language in the world after English [65]. From a linguistic perspective, following conventions in linguistic typology, both Chinese and English are considered to be subject-verbobject languages [66]. For example, \u6211(subject of the sentence) \u5403(verb of the sentence) \u82f9\u679c(object of the sentence). In English, the sentence would be translated as \"I (subject) eat (verb) apple (object)\". Another example would be \u201c\u6211\u201d (subject of the sentence) \u662f(copula) \u4e2d\u56fd\u4eba(object of the sentence). In English, the sentence would be translated as \"I (subject) am (copula) Chinese (object)\". The two examples follow SVO (subjectverb-object) order, where the subject goes first, followed by the verb (copula) and then the object. Thus, the order of sentences from Chinese and English could be categorised as SVO in the perspective of typology. However, English and Chinese differ in terms of grammar rather than morphology. For instance, the use of tense in most Western languages compared with the use of incomplete action using the particle \u4e86, and the use of particles which are also used in Western languages; e.g. doch in German, si in French eh in English but are more fundamental in the different Chinese dialects, e.g. the question particle \u5417.Furthermore, the Mandarin Chinese is a language without tense morphology [67]. For example, in English, we can state, \"I had my breakfast.\" Note that 'had' as a verb in this sentence is phrased in the past tense. However, the sentence in Chinese would be \u201d\u6211\u5403\u4e86\u65e9\u996d\u201d(wo chi le zao fan), '\u5403\u2019(eat) as a verb in this case does not change tense because of time. However, the aspectual particle '\u4e86,suffixed to the verb is used for past and future interpretation. Collart et al. [68] stated that English is a \"tense prominent\" language where tend to place an event in time tense, whereas Chinese is a \"aspect prominent\" language that refer to the time aspect through aspectual particles. Thus, as a language without tense morphology, Mandarin differs from English in how it expresses time. Instead of using verb tenses, Mandarin employs aspectual particles such as \u201d\u4e86\u201d(-le), \u201d\u8fc7\u201d(guo) as suffixes to its verbs for temporal interpretation."}, {"title": "2.5. Sentiment and Semantic Analysis", "content": "Word embedding in NLP encodes text numerically as a dense vector for machine and deep learning models [69, 70]. Initially, the text sequences were represented by simple methods such as one hot encoding and later, different word-embedding methods were developed [71, 72]. For instance, Mikolov et al. [71] introduced the Word2Vec word embedding model in 2013 which achieved highly accurate word vectors via training a simple neural network. The model efficiently enabled the computation of high-dimensional word vectors with lower computational complexity. On the other hand, Pennington et al. [73] introduced the GloVe model (global log-bilinear regression model) that enables the training of nonzero elements in a word-word concurrence matrix for effectively leveraging information.\nSemantic analysis in NLP investigates the meaning of languages, which is useful for understanding the representation of texts from English to other languages [74] enabling crosslingual semantic analysis [75].\nThe use of a similarity measure for the comparison of different sets of data is required for the evaluation of information retrieval processes, clustering, and classification models [76]. The Jaccard similarity score is used for measuring the similarity and difference between two data samples that include text phrases represented as strings [77]. The cosine similarity computes the cosine similarity between two strings that can also feature vector embeddings[78].\nSentiment analysis is used for the analysis of the text by evaluating people's opinions, emotions, and impressions through data available in social media platforms, news media, and journals [79]. Sentiment analysis is a growing field and is employed prominently in social media as a tool to assess impressions of users for product advertising [80]. Sentiment analysis has been used for a wide range of applications, including election modelling and forecasting [81], COVID-19 social media analysis [82], and news media analysis [83]. Our study employs sentiment analysis to compare sentiments captured by Google Translate and human translation."}, {"title": "3. Methodology", "content": ""}, {"title": "3.1. Description of dataset", "content": "The True Story of Ah Q (\u554aQ\u6b63\u4f20)[84] is a classic short novel that depicts the real life of Chinese society in 1911. Lu Xun as a social realist satirised feudal culture and the social, political and economic circumstances of the time. The story contains numerous expressions of emotions including empathy, humour, hopelessness and irony. In the context of The True Story of Ah Q, the difficulties and challenges Ah Q faced symbolised the pressures of feudal thinking and an emerging capitalist society in the early twentieth century in China. Lu Xun's works have entered the global market and been translated into many languages, translations give the work a new life and translation styles can vary based on their understanding and diverse perspectives on the literature [85].\nThe True Story of Ah Q consists of nine chapters and was first published as a serial in Chenbaofukan (\u6668\u62a5\u526f\u520a) on the fourth of December, 1921. It has since been reproduced in his short story collection called Call To Arms(\u5436\u558a)in 1923. Lu Xun is considered to be probably the greatest Chinese writer of the 20th century, and his literary works have been broadly translated by numerous scholars [86]. Because of his iconic status in Chinese literature, we selected one of his best-known pieces for analysis. In addition, we selected two English translation works of The True Story Of Ah Q to evaluate translation quality and for model training.\nOne of the selected English translations was done by Yang Xianyi and his wife, Gladys Taylor Yang. It was published by the Chinese Communist government-run Foreign Languages Press in Beijing in 1953. Their works brought Lu Xun's literary work onto the world stage and introduced and popularised Chinese works in Western countries to improve understanding of Chinese culture during that period. Gladys Yang has expressed three thoughts on translation: being creative in translation, conforming to the readers' consciousness, and adapting to the current policy [87]. Moreover, her translation style takes into account both foreignisation and domestication [87]. Foreignisation is a type of translation strategy that retains some of the foreignness of original texts [88]. Domestication is designated for fluent style in order to help the target language reader better understand the content. The translation style should be thought of as considering both native readers and foreign readers, and to increase the reader's understanding of the Chinese cultural background of a text.\nAnother English translation of The Real Story of Ah Q was translated by Julia Lovell and published by Penguin Classic in November 2009 [89]. Besides The Real Story of Ah-Q and Other Tales of China, Julia Lovell has translated a number of other books from Chinese, such as A Dictionary of Maqiao from Han Shaogong, I Love Dollars and Other Stories of China from Zhu Wen, Serve the People! from Yan Lianke. Julia Lovell has extensive experience translating Chinese texts, which is why we chose her translations for comparison. In The Real Story of Ah-Q and Other Tales of China, Julia Lovell translated Lu Xun's stories into a single volume as a collection. However, in our study, we focused only on the novella of The Real Story of Ah-Q. Julia Lovell has stated that she translated these texts literally without embellishment, which may have been closer to the spirit of the original [89]. In other words, this is a direct translation.\nOur study also considered other well-known translations, such as those by William Lyell [90]. However, we have not used it in this study and recommend for future studies."}, {"title": "3.2. Data extraction and processing", "content": "We extracted all nine chapters from the original text and then translated them to English using the Google Translate application programmer interface (API). We extracted all the verses by scraping web text data. We pre-processed data with the following steps:\n\u2022 Opening a printable document format (PDF) file, and reading the content of each chapter.\n\u2022 Removing chapter number and chapter name and annotation numbering from each chapter.\n\u2022 Separating each chapter given as paragraphs to a single line so that we can implement sentiment analysis based on sentences rather than a paragraph."}, {"title": "3.3. BERT for sentiment and semantic analyses", "content": "The BERT [18] model is a pre-trained large language model that employs the Transformer deep learning model [16] that incorporates an attention mechanism in an LSTM-based model. The Transformer model processes text using a left-to-right architecture, whereas the BERT model generalises this to a bidirectional process. The BERT model takes advantage of knowledge from a large corpus of data that includes Wikipedia and Bookus databases and features billions of trainable parameters. A pre-trained model essentially provides a trained model that can be downloaded and further refined using task-specific datasets. In our study, we refine the BERT-based model using task-specific data for sentiment analysis."}, {"title": "3.4. Framework", "content": "We present a framework that features sentiment and semantic analysis by comparing the Google Translate version with the translations from Mandarin to English of two expert translations. We note that our framework has been adopted from Chandra et al. [35] and Shukla et al. [34] (Figure 1) which evaluated translations of Sanskrit to English. Our framework detects sentiments based on sentences in each translation for chapter-to-chapter comparison between human experts and the Google Translate version.\nIn Stage 1, we first scraped texts from the original texts of Lu Xun found on the internet (urlhttps://www.marxists.org/chinese/reference-books/luxun/03/012.htm), and the translations of Yang Xianyi and Gladys Taylor Yang [91], as well as another translation from Julia Lovell [92]. Afterwards, in Stage 2, we convert PDF files of Mandarin texts and human expert translations into text files to further apply the data processing. Then, we read the original text files into the Google Translate application processor interface (API) and publish the corresponding English translations and their processed versions to the GitHub repository. We split the texts by chapters, and then we saved chapter-wise files as 'Google dataset', 'Julia dataset' and 'Hsien dataset'(Hsien is the surname of Xianyi), respectively.\nIn Stage 3, we use a BERT-based model to implement sentiment analysis of each sentence and provide a summary of the chapter-wise sentiment. We provide multi-label sentiment classification in our framework, which means each verse could have more than one sentiment. We also train our BERT model by utilising the Senwave dataset, which includes 10 different emotions(Optimistic, Thankful, Empathetic, Pessimistic, Anxious, Sad, Annoyed, Denial, Official report, Joking) [93]. The SenWave dataset [93] features Tweets from March 1 2020 to May 15 2020 and contains 10,000 human labelled Tweets which enabled it to be utilised in various studies, particularly for refining pre-trained language models. For example, Chandra et al. [35] evaluated the Bhagavad Gita translation (Sanskrit to English) using sentiment analysis with a fine-tuned BERT model based on the SenWave dataset.\nIn addition, in Stage 3, we also employ the MPNet-based sentence embedding model [94] to quantitatively observe the similarities between the three translations. Our framework aims to obtain results on how similar human experts' translations are compared to Google Translate.\nIn stage 4, we visualise the sentiment analysis in separate plots for each translation. We construct cumulative sentiment analysis plots for each translation (accumulating the sentiments of each chapter) corresponding to each translation. These multilabel classification plots intend to provide insights into similarities and differences of sentiments captured for Google Translate and human translations. Furthermore, we present cosine similarity for comparing selected pairs of three translations. It is further used to compare the most and least semantically similar verses among three translations to evaluate the semantic quality of Google Translate translation in more detail.\nOur framework combines quantitative evaluation of Google Translate texts via sentiment and semantic analysis. We then provide qualitative analysis by an expert assessment of the translations."}, {"title": "3.5. Experimental and technical setup", "content": "We utilised the pre-trained BERT-base uncased model and fine-tuned the model on the SenWave dataset [93] with a dataset of 10,000 tweets by using a batch size of 1 and 4 training epochs. Since the sentiment 'official report' is related to COVID-19, we deleted this sentiment in our work as it is not related to our texts. Moreover, the latest SenWave dataset removed the 'Surprise' in their dataset; therefore we also removed 'Surprise' from our framework to avoid bias. Moreover, we implement regularisation by using a dropout layer [95] with a probability of 0.3 dropout to address the over-fitting problem in model training. Furthermore, we use a linear activation layer at the output later for predicting 9 sentiments present in the SenWave dataset. We use the pre-trained BERT model for comparing selected translations of The True Story Of Ah Q via sentiment analysis."}, {"title": "4. Results", "content": ""}, {"title": "4.1. Data Analysis", "content": "N-grams are NLP methods used for [96] extracting adjacent characters, symbols or words from a given text. We removed stop words and utilised n-grams (bigrams and trigrams) for each translation, to get an understanding about the difference vocabulary. We present the top 10 ranked bigrams and trigrams for different translations of The Real Story of Ah-Q in Figure 2\nWe review the bigrams and trigrams of Google Translate as shown in Figure 2b; where [revolutionary, party] and [fake, foreign, devils] are the most frequently mentioned consecutive words in texts for bigrams and trigrams, respectively. This reflects that some elements such as, 'rebellious', 'devil' are recurring themes in the Google Translate version. Moreover, it also highlights that some words such as 'party', 'killing', 'helmet', imply that the translation's tone is somewhat negative. Moreover, the bi-grams and trigrams of the translation by Xianyi Yang and Gladys Taylor Yang (Figure 2a), emphasise words like [foreign, devil] and [imitation, foreign, devil]. These are the most frequently mentioned consecutive words for bigrams and trigrams correspondingly. In Figure 2a, words such as \"devil\", \"god\", \"temple\" are frequently captured, and hence, the translation by Xianyi Yang and Gladys Yang seem to contain religious and historical themes. In addition, the bigrams and trigrams of the translation by Julia Lovell (Figure 2c), feature the bi-grams [foreign, devil], and trigrams [fake, foreign, devil]. We note that the most frequently mentioned consecutive words in bigrams and trigrams overlap. Moreover, \"Fake,\u201d \"temple,\" \"earth,\" \"grain,\" \"revolutionary,\" and \"party\" are also frequently used words in Figure 2c. Note that the highest frequency consecutive words used by Figure 2a (Xianyi Yang and Gladys Yang) and Figure 2c (Julia Lovell) are very similar to each other. This provides additional support that the two translations by three human expert translators are relatively similar in their use of keywords.\nIn comparing the Google Translate with the human expert versions 2 we find commonly mentioned phrases such as \"devil\", \"temple\". In the meantime, from Figure 2, [foreign, devil] is the most frequently occurring bigram for both human translators. Although [foreign, devil] appears in bigrams of the Google Translate version, the most frequent bigram for Google Translate is [revolutionary, party].\nThe common keywords for three translations are \"foreign\", \"devil\", \"temple\", \"fake\", those words lleadto a gative themetic patterns. Moreover, it is noteworthy to indicate that the second most frequent permutation in bigrams and the most frequently occurring trigrams permutation for both human translators have similar themes, but are different in their use of keywords(\"imitation\" and \"fake\"). Hence, although Google Translate can extract some common keywords in its translation, the overall high-frequency keywords differ from those translations translated by human experts."}, {"title": "4.2. Sentiment analysis", "content": "Next, we present a data visualisation for verse-by-verse sentiment analysis for three different translations using the refined BERT model. We first show the top 10 ranked optimistic and pessimistic bigrams and trigrams of two human expert translations in Figures 3 4\nFigure 3 represents top 10 optimistic and pessimistic bigrams and trigrams across nine chapters for Xianyi and Gladys translation. Furthermore, Figure 4 represents the top 10 optimistic and pessimistic bigrams and trigrams across nine chapters for Julia's translation. In Figure 3 and 4, [true, story] and [real, story] are the most mentioned pessimistic words in the two different translations. We note that \"true story\" and \"real story\" in the title of the two translations have the same meaning. Since they are extracted as top-ranked pessimistic permutations, it further highlights the gloomy tone of the story for both translations. Moreover, based on the bigrams, the optimistic most frequently used words are [make, peace] and [wine, shop] for Xinyi and Gladys, whereas the most common words are [quiet, cultivation] and [convent, quiet] for Julia. Additionally, in terms of predicted optimistic leading words for trigrams, [foregoing, considered, introduction] and [efforts, certain, back] are the most frequently occurring permutations for Xianyi and Gladys, then [convent, quiet, cultivation] and [temple, earth, grain] are the most common permutations for Julia. On the other hand, the predicted pessimistic leading words in bi-grams are [true, story] and [imitation, foreign] for Xinyi and Gladys, whereas the most common words are [real, story] and [execution, ground] for Julia. Furthermore, in terms of predicted common words for tri-grams. [imitation, foreign, devil] is the most common for Xianyi and Gladys, whereas [battle, dragon, tiger] are the most common words for translation by Julia. We note that [foreign, devil] is listed in both two translations. However, it is listed in optimistic bigrams for Xinyi and Glady's translation version and also present in the pessimistic bigrams for Julia's translation. A potential reason could be the context in which verses are phrased in the different texts.\nAdditionally, we explore the core sentiment of each chapter leading towards either positive or negative sentiments, thus we visualise the sentiment polarity score of each chapter in Figure ??. We categorise the value of each sentiment as either 1 or -1, depending on whether it is a positive sentiment or a negative sentiment. We assign sentiments \"optimistic\", \"thankful\" and \"empathetic\" with a positive sentiment score of + 1. In contrast, we assign sentiments such as \"pessimistic\", \"anxious\", \"sad\", \"annoyed\" and \"denial\" with a negative score of - 1. Then, we assign \"Joking\" with a score of 0 since it could be treated as either a positive or negative sentiment. In Figure ??, we note that the polarity score in all chapters is negative, and shows an overall declining trend. The plot initially shows a downward trend until chapter three, and there is a slight increase from chapter three to chapter five, followed by another downward trend until the end. The slight increase from chapter three to chapter five is because although Ah Q experienced three failures in total across three chapters, he also had some successes. Those successes in the storyline seem to influence the positive sentiment.\nWe then present sentiment analysis of entire text along with the chapter-wise sentiment analysis from Chapter 1 to Chapter 9 (Figure 7 11). In the Figure 7, we observe that Thankful, Empathetic and Denial are least expressed sentiments across three translations. We note that Thankful and Empathetic are not expressed across all nine chapters in three translations. Thus, there are only seven sentiments that are captured in The Real Story of Ah-Q. Moreover, Figure 7 also demonstrates that Google Translate's version dominant sentiments are sad, joking which does not necessarily refer to a joke but also captures humour. Xianyi and Gladys dominant sentiment is annoyed, whereas Julia Lovell's dominant sentiments are optimistic and pessimistic. We note that the cumulative sentiment denial counts from Xianyi and Gladys, and Julia versions are the same. Furthermore, it highlights that sentiment annoyed\" is under-represented by Google Translate, whereas joking is over-represented by Google Translate. Moreover, the cumulative sentiment analysis plot also depicts that annoyed and joking are the dominant sentiments for all three translations. Thus, the three translations place equal emphasis on the main sentiments, however, the importance of the dominant sentiments in the translations by human experts is relatively closer to each other.\nAdditionally, we show heat map plots depicting sentiment counts about other sentiments (Figure 10) and observe that Annoyed and Joking are high-frequency sentiments in all the three translations. Moreover, the three heat maps indicate that [annoyed, joking] have the highest correlation compared to other pairs. In Figures 10a and 10b, we notice that [sad, joking] are the second highest correlated and in contrast, [optimistic, joking] is the second highest correlated in Figure 10c"}, {"title": "4.3. Semantic analysis", "content": "Next, we present a framework for semantic analysis by comparing three translations. Firstly, we provide a verse-byverse cosine similarity analysis for each chapter by utilising an MPNet-based model and encoding all verses. In Table 2, we present a mean score with standard deviation (in a basket) where we observe that chapter nine is the most semantically similar, whereas chapter six is the least semantically similar across the three translations. Furthermore, we find that the score of the selected pairs for Xianyi and Gladys' with Google Translate is higher than the selected pairs for Julia's version with Google Translate. Additionally, we observe that in Table 1, the average score of selected pairs for Xianyi and Gladys' version with Google Translate is higher than the selected pair for Julia's version with Google Translate. Finally, we compare the average score of selected pairs between the expert translations as a benchmark to evaluate Google Translate. We find that the average scores of selected pairs with Google Translate are lower than the benchmark. Thus, this may indicate that Google Translate is not as accurate as the human experts, even though their selected pairs' scores are close to the scores obtained by human experts.\nAdditionally, we present some semantically similar verses by using the cosine similarity score in Table 3. In Chapter 9 Verse 43, it is interesting to note that verses from Xianyi(and Gladys) and Julia are exactly the same. The choice of words from Google Translate is also the same as the two human translations, whereas there is an extra 'December' in the verse. In Chapter 7 - Verse 38 and Chapter 4 -Verse 42, all three translations have utilized some of the same or similar words such as 'nun', 'quickly', 'naturally', 'unfortunately', 'regrettably'. Thus, all selected pairs have obtained high scores (over 0.85 cosine similarity). On the other hand, we present some of semantically least similar verses by using the cosine similarity score in Table 4. In Chapter 7 - Verse 8, we observe that the choice of mimetic words for all three translations differs. Moreover, for Chapter 9 - Verse 8 and Chapter 8 - 19, Google Translate and Julia Lovell conveys different meanings, and is therefore assigned a low similarity score.\nFinally, we investigate arbitrarily selected verses from one chosen chapter using cosine similarity for all three translations. In this case, apart from Chapter 1 (Introduction), we observe Chapter 2 as it includes fewer verses an is easier to analyze. In Table 5, we arbitrarily selected some of the verses to compare their cosine similarity for all three translations in Chapter 1."}, {"title": "5. Evaluation by human expert", "content": "Next, we investigate the comparison of Google Translate's translations and human experts' translations. We show a more detailed analysis to gain a deeper understanding of the advantages worth mentioning as well as disadvantages worth noting for Google Translate. We evaluate the translations by human experts who coauthor this paper, Rodney Beard and Xuechun Wang."}, {"title": "5.1. Semantically most similar verses", "content": "In Table 3 we present the most similar semantic verses across all nine chapters by using cosine similarity with original texts The True Story of Ah-Q in Chinese characters (Figure 6\nIn Chapter 9: Verse 43, the three pairs present high scores in cosine similarity for Hsien -Julia since the choices of words are the same. In the Google Translate version, it also presents 'December 1921' in the sentence; however, an extra 'December' follows it. The sentence \u4e00\u4e5d\u4e8c\u4e00\u5e74\u5341\u4e8c\u6708, exactly presents 'December 1921', thus both human expert translations represent an accurate meaning. However, Google Translate has an extra \u5341\u4e8c\u6708'December' and hence provide a poor sentence structure.\nIn Chapter 7: Verse 38, Google Translate(GT)-Hsien is more semantically similar to GT-Julia as shown in Table 6. The words'\u9510\u6c14\u2019describe ergetic determination, ambition, or vibrant drive. In the three translations for the phrase \u4ed6\u5931\u4e86\u9510\u6c14, Xianyi (and Gladys)'s describes it as 'he had lost his aggressiveness', whereas Julia describes it as 'the wind had been taken out of his sails'. Google Translate describes it as 'he lost his anger' since anger is more frequently used to describe someone's annoyance, rather than a vibrant drive. Thus, Google Translate conveys a misunderstanding in the meaning of this phrase. On the other hand, although the two expert translations do not directly translate the term '\u9510\u6c14', they convey its intended meaning contextually."}, {"title": "5.2. Semantically least similar verses", "content": "In Table 4", "7": "Verse 8 of Table 4, GT-Hsien has the lower cosine similarity than GT-Julia. According to Figure 7,\u5f97\u5f97,\u9535\u9535\u2019as an onomatopoeia [97", "98": "to convey a logical meaning.\nIn Chapter 8 - Verse 19 of Table 4, Google Translate version lacks"}]}