{"title": "Impacts of Darwinian Evolution on Pre-trained Deep Neural Networks", "authors": ["Guodong Du", "Runhua Jiang", "Senqiao Yang", "Haoyang Li", "Wei Chen", "Keren Li", "Sim Kuan Goh", "Ho-Kin Tang"], "abstract": "Darwinian evolution of the biological brain is documented through multiple lines of evidence, although the modes of evolutionary changes remain unclear. Drawing inspiration from the evolved neural systems (e.g., visual cortex), deep learning models have demonstrated superior performance in visual tasks, among others. While the success of training deep neural networks has been relying on back-propagation (BP) and its variants to learn representations from data, BP does not incorporate the evolutionary processes that govern biological neural systems. This work proposes a neural network optimization framework based on evolutionary theory. Specifically, BP-trained deep neural networks for visual recognition tasks obtained from the ending epochs are considered the primordial ancestors (initial population). Subsequently, the population evolved with differential evolution. Extensive experiments are carried out to examine the relationships between Darwinian evolution and neural network optimization, including the correspondence between datasets, environment, models, and living species. The empirical results show that the proposed framework has positive impacts on the network, with reduced over-fitting and an order of magnitude lower time complexity compared to BP. Moreover, the experiments show that the proposed framework performs well on deep neural networks and big datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep neural networks (DNN) [1], [2] have seen remarkable advancements, leading to exceptional performance across a broad spectrum of learning tasks and applications, such as visual tasks [3] and natural language processing [4]. Artificial Neural Networks (ANNs) are modeled on the structure and function of the interconnected neurons in the human brain. Training ANNs are equivalent to the search of network weights that optimize a desired loss function, in which intricate network architectures determine the high-dimensional function space. The function landscape is a critical component in determining task performance. For instance, skip connections contribute to the creation of smoother function landscapes in modern network architectures such as RESNET and DENSENET [5]. Various optimization methods can be employed to search efficiently in the function space. Back-propagation (BP) and its variants (e.g., Adaptive Moment Estimation optimizer (ADAM) [6]) have established themselves as the most widely used, thanks to their ability to explicitly utilize the gradients of the loss function and enable the training of extremely deep neural networks and Gaussian processes [7], [8]. Nonetheless, BP has several weaknesses [9], for example, it requires differentiable loss functions and suffers from the sensitivity to hyperparameters, the problems of vanishing or exploding gradients, slow convergence, and high computational requirements.\nAn alternative to BP for training DNN is meta-heuristic approaches, for instance, evolutionary algorithms (EA), which implement the theory of evolution [10], [11] on computational hardware. EAs have successfully evolved a population of solutions to a plethora of complex optimization problems (e.g., non-convex and NP-hard problems) and real-world problems where traditional methods fail, demonstrating the capability of EAs for general optimization. Utilizing EAs to implement the evolution of DNN architectures and DNN training is termed neuro-evolution. Neuro-evolution bridges DNN optimization and evolutionary theory for algorithmic development, interpretation, and analysis. We illustrate the conceptual framework in Fig. 1. The neural network architecture and the dataset play the role of the species and environment, respectively. Different architectures specialize in different functions, for example, convolutional neural networks (e.g., ResNet [12], MobileNet [13]) and recurrent neural networks (e.g., LSTM [14], GRU [15]) capture translation invariances and temporal dependencies underlying the data. The trainable parameters can be interpreted as the genetic traits within the architect framework that affect survival and breeding. On the other side, the complexity of the dataset can be interpreted as the complexity of the environment, scaling from simple MNIST [16] to big data IMAGENET [17]. Survival fitness can be defined as the loss function of the learning task.\nNeuro-evolution has been shown to work well for ANN architecture design and training of reinforcement learning models. Parsimonious neural architectures have been designed through neuro-evolution (e.g., NEAT [18]) with enhanced performance. Moreover, neuro-evolution techniques (e.g., evolution strategy [19]) have been demonstrated to achieve better results in reinforcement learning tasks compared to deep Q-learning, the policy gradient algorithm A3C [20] among others. EA-based training of ANNs suffers from very slow (or failure of) convergence, given a large number of model parameters and a complex search space for obtaining the deep representation. Several research works tried to integrate BP with EA-based optimizer by incorporating gradient information but have not been able to show enhanced performance in computer vision tasks the modern testing, like employing deep RESNET in IMAGENET [21]\u2013[23].\nHere, we re-investigate the problem and explore the feasibility of integrating BP-based and EA-based methods. Our approach conceptualizes the neural network as a species and examines the effects of Darwinian evolution on its performance. Using pre-trained DNNs as parent models, we discovered that EA optimization could further enhance the accuracy of DNNs in image classification tasks. To thoroughly examine the efficacy of our proposed framework, we conducted extensive experiments considering various factors such as the selection of parent models, dataset complexity, and DNN architecture depth, demonstrating a correlation between datasets, environment, models, and living species and superior performance in deep neural networks and large datasets. Given the low computational complexity of EAs, our framework presents a"}, {"title": "II. BACKGROUND", "content": "The proposed work differs from other EA-based methods that train ANNs from random initialization, which imitate the primordial soup (i.e., prior to the formation of the first species, primordial ancestor, also known as the last universal common ancestor (LUCA)). Primordial soup theory [24], Miller-Urey experiment [25], and others [26] studied and simulated the conditions of the early Earth for the first life, which arose from non-living matters, give rise to other species through evolution. The initialization that implements primordial soup can be the reason for the slow convergence due to the unmet conditions for the evolutionary starting point. Inspired by Hinton\u2019s work of pretraining the neural network using restricted Boltzmann machines to avoid the vanishing of gradient, we use BP-based optimizer (i.e., ADAM) for the pretraining of DNN and EA-based methods to fine-tune DNN\u2019s weights. We consider the pretrained DNNs, obtained from the ending epochs, as the primordial ancestor (i.e., the first species), the starting point of evolution. Subsequently, Darwinian evolution is implemented using differential evolution. BP-based algorithms allow a single neural network to accumulate knowledge and learn representation from data, while neuro-evolution emulates the evolution of a population of neural networks. The same strategy applies to other pretrained models, facilitating the evolution of fitter breeds (i.e., enhanced pre-trained models). Several computer vision datasets and DNN architects are used to validate the concepts. This work focuses on evolving a population of trainable parameters in the pre-defined architecture (i.e., single organism) rather than evolving a population of"}, {"title": "III. PROPOSED METHOD", "content": "Consider a task to learn a neural network with dataset D, where each sample $x \\in D$ is with multi-features and a label y. A fundamental question is:\nHow can we obtain a neural network that faithfully depicts the training set and accurately predicts the testing set? (or can we say \u201cHow can we learn a good neural network?\u201d here.)\nAssumed that training and testing data follow an identical distribution. Let $\\theta$ denote the parameters of the neural network model. In the standard learning process, optimal parameters can be found by minimizing loss L, which is formulated as\n$\\theta = arg \\min L(\\theta; x, y)$,\nBack-propagation and gradient-based methods are almost ubiquitously for such minimization with elaborately designed regularization $\\Omega(\\theta)$. Based on that, we provide an alternative method by evolutionary algorithm, which is specified as two stages in Fig. 1 and Algorithm 1 shows the typical steps.\nThe first stage is initialization with back-propagation and gradient-based methods, which is shown at the bottom of Fig. 1. This is an iterative algorithm that starts with a random input and fitness evaluation. For each epoch, gradient-based quantity is calculated and $\\theta$ can thus be updated until the termination condition is satisfied.\nThis produces a set of candidate solutions,\n$\\Theta = {\\theta_i : i = 1, ..., m}$,\nwhere m is called population size, and $\\theta_i = (\\theta_{i,1}, \\theta_{i,2}, ..., \\theta_{i,d}), d$ is the size of solution space.\nThe second stage is to boost with an evolutionary algorithm, which generates new solutions from the current candidate set. The algorithm is shown at the bottom of Fig. 1, where differential evolution is taken as an example. This is also an iterative algorithm that starts with $\\Theta$. For each generation(epoch), one step is to generate \u201cmutant\u201d vectors, which form $\\Theta^*$,\n$\\theta_i^* = \\theta_i + F \\times (\\theta_k - \\theta_l)$,\nwhere i = 1,..., m and j, k, l are random integers less than m, different from i and other. F is a tunable scalar. Then, recombination is performed, which includes crossover and selection. Crossover is taken place with a pre-set threshold Cr. For j = 1, ...d,\n$\\theta_{i,j} = \\begin{cases} \\theta_{i,j}^* & \\text{if rand(0,1)} \\leq Cr, \\\\ \\theta_{i,j} & \\text{otherwise}. \\end{cases}$\nFor selection, the choice of $\\theta_i$ in the next generation is made between $\\theta_i$ and $\\theta_{i,j}$\n$\\theta_i = \\begin{cases} \\theta_i^* & \\text{if } L(\\theta_i^*) < L(\\theta_i) \\\\ \\theta_i & \\text{otherwise} \\end{cases}$\nwhere the lowest loss function is targeted by direct one-to-one comparison."}, {"title": "IV. EXPERIMENT", "content": "Here, BP-trained deep neural networks using ADAM [6], obtained from the ending epochs, are considered the primordial ancestors in the Darwinian evolution of a population of networks for visual recognition tasks. The neural networks are optimized using cross-entropy with L2 regularization as the loss function. During Darwinian evolution, natural selection is implemented using cross-entropy as a fitness function that determines the relative survival and reproductive success of a species.\nExtensive experiments are carried out on models such as LeNet1, LeNet5, and a larger ResNet18 trained on MNIST, FashionMNIST, Cifar-10, Cifar-100, and ImageNet. Additional verification of model robustness is assessed on MNIST-C and CIFAR-10-C datasets."}, {"title": "A. Hyper-parameters", "content": "Grid search is employed to identify the optimal hyperparameters, and the specified search range is outlined in Table I."}, {"title": "V. RESULT AND DISCUSSION", "content": "Empirically, neuro-evolution that begins with the primordial ancestor is found to be superior to the primordial soup, as shown in Fig. 2. Hence, it shows the importance of the formation of a species before evolution takes place.\nComparing the primordial ancestor trained with and without regularization, it is also observed that the quality of the primordial ancestor has a huge impact on DNNs, demonstrating the effect on descent in the same lineage. In the same lineage, offspring receive the genetic traits from parents through inheritance. Offspring inherit major traits with parents, however, with slight variation and modification. In Fig. 2, the lineage trained using BP with regularization performs better. The top right of Fig. 3 shows the different degrees of improvement that can be achieved on top of the BP-based approach under different degrees of L2 regularization. It is observed that the best results are achieved with a regularization of 0.0001 compared to no regularization at all, and all regularization parameters lead to increased model accuracy. The use of regularization reduces the impact of over-fitting in BP-based optimizers. During the Darwinian evolution, it is observed that the trait of preventing over-fitting is inherited without an explicit L2 regularization in the fitness function.\nIn Fig.3, LeNet1 and LeNet5 architectures are used to simulate two different species in the environment (dataset) with different complexities, which provide different amounts of training data generated using data augmentation. The former represents the primitive life form, namely a simpler model with fewer parameter counts, while the latter represents the higher form of living species. The Darwinian evolution is observed to have positive impacts on the ADAM-trained neural network. Moreover, datasets and models with higher complexity are observed to achieve better performance. Both LeNet1 and LeNet5 evolved using the proposed Darwinian evolution framework are found to be better than the LeNet5 trained using BP by LeCun et al. in 1998 [16]. Numerical results are provided in Table II\nTo assess the out-of-distribution robustness of the neural network trained using the proposed framework, two datasets with common corruptions are used, namely MNIST-C and CIDAR-10-C. The types of corruption are summarized at the bottom of Fig. 3 as well as detailed in Tables III to V. From Tables III and IV, LeNet5 trained by DE is found to be less susceptible to corruption, demonstrating the positive impacts of DE on BP-trained shallow networks. Similar positive impacts on network robustness under corruptions are observed for deeper neural networks, ResNet and MobileNet, in Table V.\nTo further explore the generalization capabilities of the proposed framework, deeper models and big datasets are used. As shown in the bottom rightmost sub-figure in Fig. 4, it is found that using ResNet18 on cifar100 [30] and ImageNet also leads to decreases in validation loss, increases in validation accuracy, and improvements in overall model performance. As shown in Table II, the positive impacts of the proposed optimization framework on classification accuracies of test sets are shown. It further demonstrates that our approach is not only applicable to small models but also achieves good improvements on big datasets and deep models.\nAccording to the results, the proposed framework shows enhanced classification performance when compared with BP-based methods; no overfitting problem is observed in EA training, demonstrating advantageous effects similar to regularization; low time complexity compared to the back-propagation, making it highly practical to be incorporated into the recent framework of DNN training.\nOther than the inheritance of elites\u2019 anti-overfitting property and the improved solution by natural selection, the proposed framework also has low time complexity compared to BP-"}, {"title": "A. Models' robustness against corruption", "content": "To verify the robustness and generalization of our approach, we trained the model using MNIST data and Cifar10 data and tested it on MNIST-C and Cifar10-C datasets, respectively. Table III shows LeNet1 and LeNet5\u2019s performance on MNIST-C. Table IV shows LeNet1 and LeNet5\u2019s performance on Cifar10-C. Table V shows ResNet performance on Cifar10-C. Generally, it is observed that DE enhanced DNN robustness for almost all models."}, {"title": "B. Impact of mutate and recombination", "content": "In nature, where natural selection already rules out the evolution strategy that is too extreme, as they are extinct already. So in DE, evolutionary processes such as inheritance with modification (i.e., mutation and recombination) and natural selection of fitter individuals are implemented. Empirically, the evolution of DNN solutions only occurs when the mutation and recombination are not too big nor too small, requiring the inheritance of advantageous traits from the parents while maintaining diversity in the population."}, {"title": "VI. CONCLUSION", "content": "All in all, the proposed framework has shown three important traits compared to BP-based optimizer: the generally enhanced performance, the low time complexity, and the most important one \u2013 stability. (ADAM [6]: will over-fit the training data when regularization is not used, DE: does not require explicit regularization to prevent over-fitting and has good performance against noise.) Stability matters most in living to maintain survival and reproduction from generation to generation. In contrast, the extreme strategy can cause extinction, which might explain why the brain does not explicitly compute the gradient for BP. According to our results and findings, the strategy that uses a pre-trained neural network by BP to accumulate knowledge and learn representation from data then evolves the network using the proposed framework, provides a practical and robust approach to enhanced network performance. Future research can explore adaptive DE for deeper neural networks trained on datasets with larger scales. Github URL: https://github.com/Yangsenqiao/Impacts-of-Darwinian-Evolution-on-Deep-Neural-Networks."}]}