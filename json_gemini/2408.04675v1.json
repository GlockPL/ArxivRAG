{"title": "ACL Ready: RAG Based Assistant for the ACL Checklist", "authors": ["Michael Galarnyk", "Rutwik Routu", "Kosha Bheda", "Priyanshu Mehta", "Agam Shah", "Sudheer Chava"], "abstract": "The ARR Responsible NLP Research checklist\nwebsite states that the \"checklist is designed\nto encourage best practices for responsible re-\nsearch, addressing issues of research ethics, so-\ncietal impact and reproducibility.\" Answering\nthe questions is an opportunity for authors to\nreflect on their work and make sure any shared\nscientific assets follow best practices. Ideally,\nconsidering the checklist before submission\ncan favorably impact the writing of a research\npaper. However, the checklist is often filled\nout at the last moment. In this work, we in-\ntroduce ACLReady, a retrieval-augmented lan-\nguage model application that can be used to\nempower authors to reflect on their work and\nassist authors with the ACL checklist. To test\nthe effectiveness of the system, we conducted\na qualitative study with 13 users which shows\nthat 92% of users found the application useful\nand easy to use as well as 77% of the users\nfound that the application provided the infor-\nmation they expected. Our code is publicly\navailable under the CC BY-NC 4.0 license on\nGitHub.", "sections": [{"title": "1 Introduction", "content": "In order to submit an ACL paper, authors are re-\nquired to submit their answers to the ARR Re-\nsponsible NLP Research checklist. The checklist\nwas mostly developed through a combination of\nthe NLP Reproducibility Checklist (Dodge et al.,\n2019), the reproducible data checklist (Rogers\net al., 2021), and the NeurIPS 2021 Paper Checklist\nGuidelines (neu, 2021). The goal of this process\nis to address reproducibility, societal impact, and\npotential ethical issues in the research work. This\nmeans researchers should discuss things like the\nlimitations/risks of their research, scientific artifact\nusage, relevant details about computational experi-\nments, annotators/human participants, and whether\nthe authors used AI assistants in their writing."}, {"title": "2 ACL Ready", "content": "The ACLReady tool depicted in Figure 1, operates\nas follows: (1) the user uploads a TeX file, (2) the\nfile is chunked by section, (3) each section is se-\nmantically chunked, (4) metadata is added and text\nis embedded, (5) filtering, prompting, and querying\noccur, (6) LLM-generated checklist responses are\nsent to the frontend, and (7) the user modifies and\nexports the responses."}, {"title": "2.1 Parsing, Chunking, and Embedding", "content": "Parsing After users upload their paper's TeX file,\nthe document is parsed to remove all comments and\nall text before the abstract. Additionally, sections\nlike acknowledgments are removed. For figures\nand tables, only captions are kept. Finally, sections\nare numbered in order to mimic the section num-\nbering that tools like overleaf.com perform when\ncompiling from LaTeX to PDF.\nMaintaining relationships during chunking In\norder to best utilize the original structure of the TeX\ndocument while making it easier for the LLM to\ndistinguish between sections, the chunking process\nis as follows:\n1. Every section is chunked into its own node.\n2. Metadata is added (section name, previous\nnode, next node). This also makes it easier to\nfilter out irrelevant nodes for some prompts.\n3. Section nodes are broken up into parent and\nchild chunks by semantic chunking\u00b9. This\nchunking method takes embeddings of sen-\ntences and finds breakpoints between sequen-\ntial sentences using embedding similarity.\nEmbeddings The text is embedded. When the\napplication is configured for OpenAI models, the\ndefault embedding is \"text-embedding-ada-002\".\nThe application can also be configured to use\nthe open source embedding \"m2-bert-80M-8k-\nretrieval\". Nodes that are not relevant for a specific\nquery can be filtered. For instance, for question A3\n(\"Do the abstract and introduction summarize the\npaper's main claims\") all nodes that are not par-\nent or child nodes of the abstract and introduction\nsections can be excluded. The app uses recursive\nretrieval with cosine similarity as the similarity met-\nric. Queries retrieve the smaller child chunks and\nfollow references to the parent chunks. The parent\nchunks are fed into the LLM.\nACLReady has been evaluated with leading\nLLMs like GPT-3.5 Turbo (\"gpt-3.5-turbo-0613\").\nDue to the model being proprietary and not open-\nsource, we built in a configuration for the applica-\ntion that allows the user the flexibility of selecting\nthe LLM they want to use. Currently, the only\nopen-source option that has been tested with the"}, {"title": "2.2 LLM Checklist Response", "content": "After inference, the LLM checklist response is sent\nto the frontend. This response is formatted and\nadded to the corresponding sections (A-D) in the\nuser interface. If the answer to the question is\n\"yes\", the response is formatted as \"section name\".\nIf the answer to the question is \"no\", the response is\nformatted as \"None. LLM Generated Justification\".\nUser Checklist Modification The LLM answers\nare supposed to assist users with understanding\ntheir paper and simplifying the response process.\nConsequently, users should check each LLM gen-\nerated answer for accuracy. Section E which deals\nwith the use of AI assistants in research, coding, or\nwriting is only to be answered by users.\nOnce the user is satisfied with the answers they\ncan export the response to a markdown document.\nMarkdown was chosen due to how easy it is to\nconvert from markdown to other formats (e.g.,\nPDF and LaTeX) and the widespread adoption of\nREADME markdown files on GitHub and model\ncards on Hugging Face (Yang et al., 2024)."}, {"title": "2.3 Implementation Details", "content": "This section details the technical details of the web\napplication and how the frontend and backend are\nbuilt."}, {"title": "3 User Interface and Experience Design", "content": "The user interface of ACLReady is shown in Figure\n3. It consists of a upload function, a primary and\nsecondary navigation to switch between sections,\nand a generated response field with a copy function.\nThe ACLReady user journey is shown in Figure 4.\nUsers upload a TeX file, view the progress screen\nwhile they wait for the LLM response to generate,\ncheck/edit the response, and finally download a\nmarkdown file. The features for the platform and\nthe rationale behind them are listed below:\n1. Side Bar/Upload: The upload function only al-\nlows users to upload their paper in TeX format.\nThe side bar incorporates the visual identity\nof the platform. It has been visualized to re-\nsemble file tabs so that the users can connect\nwith the overarching action being performed\nthrough the platform.\n2. Progress screen: After the user uploads their\nfile, a progress screen appears to users on the\nbackend progress. This feature was added to\nthe platform after informal interviews where\nit was noted that users wanted to get some\nindication on how long they needed to wait\nfor the document to be parsed and see results.\n3. Primary navigation: The top bar of the inter-\nface provides the users with functionality of\nswitching between sections. It also indicates\nthe progress for each section."}, {"title": "4.  Response sections", "content": "After the paper is parsed,\nthe responses will be auto-filled into the re-\nsponse spaces. Here, we have provided a copy\nbutton which allows the users to copy the en-\ntire response for multiple use cases. These\ninclude: wanting to repurpose the generated\nresponse in another section or even sharing\nindividual responses with others. In the first\niteration of this platform, we had included an\nedit response button as well but chose not to\nretain it as it seemed more intuitive for the\nusers to be able to edit by simply clicking on\nthe generated text."}, {"title": "5.  Secondary navigation", "content": "The bottom of the plat-\nform also provides the user with linear navi-\ngation between sections. This secondary nav-\nigation aims to maintain the user's workflow\nwhile checking or editing responses, allowing\nmovement to the next page without needing\nto return to the primary navigation at the top\nof the user interface."}, {"title": "6.  Export", "content": "After the user has reviewed each sec-\ntion, they can download all of their responses,\nwhich are then ready for submission."}, {"title": "4 Evaluation", "content": "We conducted a user study with 13 evaluators. Each\nevaluator used the tool and checked the 18 LLM vs\nhuman responses (sections A-D) for a randomly se-\nlected paper from the list of accepted 2023 EMNLP\nmain conference papers\u2076. The only selection crite-"}, {"title": "4.1 Qualitative Evaluation", "content": "In order to understand the user experience of the\ntool and know what to further improve, we had the\nusers answer the following questions after using\nthe tool.\n\u2022 Is the tool easy to use?\n\u2022 Did you find the application useful?\n\u2022 Did the tool provide the information you were\nexpecting?"}, {"title": "5 Conclusion", "content": "This paper introduces ACLReady, a LLM-based\nsystem which can be used to empower authors re-\nflect on their work and act as a assistant to help\nauthors with the ACL checklist. With ACLReady,\nauthors can get a LLM checklist response that they\nuse to reflect on their work or modify before submit-\nting. The application was tested using 13 evaluators\nwho evaluated it on a qualitative level. It demon-\nstrates that the application is easy to use, useful,\nand provides the expected information. We hope\nthat the open-source application will be responsibly\nused as an assistant and tool for reflection."}, {"title": "Limitations", "content": "ACL Checklist The current version of the app\nonly addresses the ACL checklist. However, the\nprompts could be modified for other conferences\nand applications.\nMulti-answer Some authors often provide a list\nof sections even when questions are only asking for\na single section. The application currently doesn't\nmimic this behavior well.\nUser Study We only selected papers that have\nbeen accepted by EMNLP and have been published\non arxiv. This likely biased our user study and RAG\nmodel design towards better structured papers."}, {"title": "Ethics Statement", "content": "Hallucination in LLMs Large language models\nare known to hallucinate and generate false or mis-\nleading information. For our application, it means"}]}