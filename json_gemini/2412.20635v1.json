{"title": "NetFlowGen: Leveraging Generative Pre-training for Network Traffic Dynamics", "authors": ["JIAWEI ZHOU", "WOOJEONG KIM", "ZHIYING XU", "ALEXANDER M. RUSH", "MINLAN YU"], "abstract": "Understanding the traffic dynamics in networks is a core capability for automated systems to monitor and analyze networking behaviors, reducing expensive human efforts and economic risks through tasks such as traffic classification, congestion prediction, and attack detection. However, it is still challenging to accurately model network traffic with machine learning approaches in an efficient and broadly applicable manner. Task-specific models trained from scratch are used for different networking applications, which limits the efficiency of model development and generalization of model deployment. Furthermore, while networking data is abundant, high-quality task-specific labels are often insufficient for training individual models. Large-scale self-supervised learning on unlabeled data provides a natural pathway for tackling these challenges. We propose to pre-train a general-purpose machine learning model to capture traffic dynamics with only traffic data from NetFlow records, with the goal of fine-tuning for different downstream tasks with small amount of labels. Our presented NetFlowGen framework goes beyond a proof-of-concept for network traffic pre-training and addresses specific challenges such as unifying network feature representations, learning from large unlabeled traffic data volume, and testing on real downstream tasks in DDoS attack detection. Experiments demonstrate promising results of our pre-training framework on capturing traffic dynamics and adapting to different networking tasks.", "sections": [{"title": "1 INTRODUCTION", "content": "Comprehensive understanding and rigorous modeling of traffic dynamics are important for achiev-\ning accurate and reliable network service and management. With the capture of rich network data,\nrecent years have seen a surge in applying machine learning (ML) techniques in a wide range of\nnetworking tasks, including congestion prediction [59] and control [1, 31, 55, 74], packet [44, 84]\nand traffic classification [10, 51, 67, 81, 86], traffic optimization [11], performance prediction and\nestimation [49, 82], network traffic generation [65, 80], and attack detection [21, 36, 76, 89]. As a\nparadigm, ML models achieve strong performance for network applications [6], usually through\nsupervised learning from in-task labeled datasets.\nNevertheless, while individual ML models are effective for specific applications, it is challenging\nto transfer learned knowledge and network representations from task to task to achieve better effi-\nciency and generalization. Apart from the repetitive cost of data collection and model development\ncustomized for different tasks, the inadequacy of high-quality ground truth labels poses a unique\nchallenge in obtaining reliable models [64]. Although there naturally exists an ample amount of\nnetworking data [26, 38, 72], most raw data are unlabeled. Acquiring task-specific labels with\ndifferent learning purposes is a very expensive process. For example, flow-based traffic data might\ncontain billions of flows and packets, for training a reliable attack detection ML model, manually\nlabeling all the data with high quality is extremely time-consuming even for experts in security\n[65].\nThe recent success of self-supervised learning from large-scale unlabeled data in natural language\nprocessing and related fields motivates us to explore its applications in network traffic dynamics\nmodeling. The self-supervised learning framework contains two phases: a pre-training phase that"}, {"title": "2 CHALLENGES AND OPPORTUNITIES", "content": "The pre-training paradigm has greatly reshaped the landscape of natural language processing\nand related fields. The core idea is to first pre-train a self-supervised model, with large amount of\nunlabeled data and then transfer the model to new tasks with minimal supervision. Systems start\nwith a common Transformer [71] neural network architecture. Since the framework was introduced,\npre-trained models have improved continuously: from BERT [15] and RoBERTa [47], to T5 [63]\nand BART [41], and to GPT [61] and PaLM [12]. Language processing systems have advanced on\nthese models, also referred to as a foundation model [5], along with the massive scaling of data"}, {"title": "Feature Diversity.", "content": "Networking data is a challenge for pre-training. Current state-of-the-art\nTransformer models by default operate on a sequence of univariate tokens as input,\u00b9 which take\ndiscrete values from a finite vocabulary. Networking data is both multivariate and heterogeneous.\nThere are different fields composing the traffic information, including IP addresses, ports, transport\nprotocol, timestamps, packets, bytes, etc. Some fields are continuous such as packets and bytes,\nwhereas others are categorical such as ports and protocol. Moreover, the distributions of raw\nfeature values vary drastically. While possible values of protocols are limited, the values of the\nnumber of packets in the traffic flow range from zero to billions. A comprehensive and effective pre-trained model needs to incorporate each of the raw traffic features to ensure broad generalization,\nand represent them in a unified space to learn their interactions, regardless of feature types and\ndistributions."}, {"title": "Pre-Training Objective.", "content": "We also need to consider how to design the best pre-training task for\nnetworks. Network traffic shares similarities with other modalities due to its sequential structure.\nThis leads us to believe that models with next-step pre-training prediction task, also known as\ndecoders, can be readily adapted to networks for learning traffic dynamics. We note that this choice"}, {"title": "3 METHOD", "content": "Given unannotated network traffic data, we use self-supervised learning to exploit intrinsic data\ncorrelation and dynamic patterns, yielding general data representations to be utilized for further\ntask-specific fine-tuning. We view each IP address in the network as a unique node, and the traffic\nas a time series\u00b2 pertinent to the node that receives or sends the traffic. We focus on network\ntraffic recorded in the NetFlow [13] format, with the information of IP addresses, timestamps, ports,\nprotocols, packet/byte counts, etc. treated as features into the general ML model. An overview of\nour framework is illustrated in Figure 2."}, {"title": "3.1 Pre-training", "content": "Training Objective. Similar to next token prediction objectives for NLP foundation models, we\ntrain the model with the task of predicting the next step of traffic given the history of traffic\ninformation in the unlabeled NetFlow data. But different from language, the traffic sequence for\na node is viewed as a multivariate time series with $f \\in \\{1...F\\}$ different features. Our goal is\nto predict a subset of these features for each of the different nodes in the dataset, a setup that\nresembles a multi-task learning approach where each node is a task. The goal is to provide diverse\nsignals for capturing dependencies and producing general traffic representations for downstream\ntasks. At each time step $t$ for each node $v$, let $y_{v,t}^f$ be the $f$-th traffic feature such as number of\npackets received/sent, timestamp of $t$ such as minute and weekday, number of flows received/sent,\netc. The model with learnable parameters $\\theta$ is trained by minimizing the following loss\n\n$\\frac{1}{VT} \\sum_{v=1}^V \\sum_{t=1}^T \\sum_{f \\in F} -log p_\\theta (y_{v,t}^f | y_{v,<t}^f)$ (1)"}, {"title": "Feature Representation.", "content": "Traffic flow features are heterogeneous in different ways. One hetero-geneity lies in the intrinsic types of features with two notable classes, one is categorical such as ports\nand protocols taking discrete values, and another class is continuous such as the number of packets"}, {"title": "3.2 Fine-tuning: DDoS Attack Detection", "content": "The pre-trained model encapsulates general knowledge of network traffic for transfer to tasks with\nlimited annotated labels. We propose a principled approach to fine-tuning our pre-trained model\nfor downstream tasks, demonstrated through DDoS attack detection. To demonstrate the power\nof the pre-trained traffic model for transferring knowledge to various tasks, we also fine-tune the\nmodel for the detection of different types of attacks, such as UDP attacks and DNS attacks. For\nadapting to new tasks, the fine-tuning process takes only a small amount of annotated traffic data\nwith task-specific labels. Extensive testing on broader ranges of additional tasks remains a focus\nfor future research.\nGiven a time series, we first extract the traffic hidden representation from the pre-trained model.\nThis is the internal time series of vectors, which summarizes the traffic dynamics up to the current\nstep. A small classification layer, a simple feedforward neural network, is then added on top of this\nhidden representation, and fine-tuned with task-specific labels and objectives (see Figure 2 left).\nThe pre-trained model parameters are kept frozen during this process; therefore the fine-tuning\nphase is lightweight as in the original GPT model [61].\nFor the application to DDoS attack detection, we target the early detection setup established by\nXatu [78]. Each example (v, y, z) in the dataset consists of a time series $y = (y_1, y_2, ..., y_t)$ of 30\nminutes with each minute being a time step, and a corresponding label $z \\in \\{0, 1\\}$ marking whether\nthe time series contains an attack or not. It also contains a manually marked spoof list, so anomaly"}, {"title": "4 DATASET CONSTRUCTION", "content": "4.1 NetFlow Data Serialization\nWe employ a pre-training dataset obtained from a large ISP, which is a comprehensive collection\nof sampled NetFlow records captured within the ISP's network over a span of three months,\naccompanied by 16K attack alerts sourced from a widely utilized commercial defense system.\nSpecifically, we extract the inbound and outbound traffic pertaining to each target IP address,\nemploying a temporal resolution of one minute. The dataset consists of time series total length\nof 132,480 minutes. We partition this dataset along the time axis into distinct sets for training,\nvalidation, and testing. The training set consists of 95,232 minutes, while the validation and testing\nsets span 10,752 minutes and 26,496 minutes, respectively. We further divide each dataset into\ndiscrete time series units of 512 minutes for pre-training.\n4.2 NetFlow Data Filtering\nWe identified a certain customer that generates a substantial amount of traffic and attacks during a\nspecific time frame. To ensure the generalizability of our model to other customers, this dominant\nand any associated customers are excluded from our analysis. Collectively, these customers ac-\ncounted for approximately 92% of the total number of customer IP addresses. The resulting statistics\nof the filtered NetFlow data are summarized in Table 1.\nWe adopted the alerts from the DDoS defense of our NetFlow provider as ground-truth labels and\nfiltered out the following alerts: (1) potential false positive alerts reported by the DDoS defense; (2)\nmismatched alerts with reported packets and bytes less than 95% of packets and bytes observed in"}, {"title": "4.3 Downstream Task: Early DDoS Attack Detection", "content": "To form the data for downstream fine-tuning, we select an equal number of attack and non-attack\ntime series for each customer IP address based on ground-truth alerts. For each alert, we generate\nthe attack time series for this alert and randomly select a non-attack time series from the same\ncustomer IP address within the same minute range of data split. For each time series, we extract\ntime series of 86 features in the 512 minutes. We also identify the onset of the anomaly for the attack\ntime series by looking for the sudden, sustained increase in the matching traffic, using CUSUM\nalgorithm [9, 22]. The time difference between this anomaly onset and attack detection indicates the\ntimeliness of a detection approach."}, {"title": "5 EXPERIMENTAL SETUP", "content": "5.1 Model & Data Configuration\nWe pre-train a Transformer decoder model with 4 layers, 4 attention heads, embedding and pre-trained representation size 128, and intermediate feedforward dimension 512, resulting 1.9 M total\nnumber of parameters. The model learns to predict all 86 traffic features in $F$ during training for\nevery minute, and history traffic if fed with $T = 512$ minutes. For fine-tuning, instead of using a\nlarge set of labels, we only employ the EarlyDetect validation set. The lightweight classification\nhas one hidden layer of size 512, totaling 67K parameters. Our objective is to accurately predict\nDDoS attacks during the test time span, which encompasses a total of 203 attacks.\n5.2 Evaluation\nFor pre-training, we evaluate the goodness of next step traffic prediction with perplexity (PPL) [3]\nscores, defined as $PPL = exp(L(\\theta)) \\geq 1$. A low value of perplexity indicates the model probability"}, {"title": "6 MAIN RESULTS", "content": "6.1 Traffic Predictive Modeling\nWe first measure how well the pre-trained model captures traffic dynamics directly by predicting\nthe next step traffic, which is a check on the pre-training task. We compare with a baseline of a\nstatistical model that estimates the probability of a feature value based on the immediate previous\nvalue, similar to the bigram language model [54]. This baseline is strong as most features remain\nconstant each time step.\nTable 4 presents a sanity check of traffic prediction performance on validation data. The metric\nscores are averaged over all nodes and features. We can see that the generative pre-trained model\nperforms better than the baseline, indicating the dependency on history traffic information is being\nlearned to capture the traffic patterns.\n6.2 Early DDoS Attack Detection\nBaseline. We compare our method to two baseline setups: models trained with the same amount\nof labeled data, and models trained with additional labeled data. For the latter, the models were\ntrained on the EarlyDetect train split, which contains five times more training examples. Regarding\nthe model configurations, we employed two baseline models. The first one is a Transformer\nmodel without pre-training. To demonstrate the impact of pre-training, we randomly initialized\na Transformer model with the same architecture as our model. The second baseline model is a\nMultiscale-LSTM [78], which consists of multiple LSTMs in various downsampled timescales. These\ntwo baseline models see the same length of history (512), the number of traffic features (86), and\ntraining objective (SAFE loss), but unlike the pretrained model are trained only on DDoS data.\nMain Results. The main results for all types of attacks are presented in Table 5. When compared\nto the Transformer without pre-training and Multiscale-LSTM trained with the same number\nof examples, our model demonstrates the highest effectiveness while maintaining a comparable\noverhead. The Transformer model exhibits a higher FNR, indicating its inability to detect actual\nattacks accurately. For predicting potential attacks, the FPR becomes more crucial. LSTM models\ntend to overestimate false positives, identifying 12.81% of false positive attacks. In contrast, our\nmethod showcases a balanced performance across all metrics.\nThe pretrained approach also exhibits comparable performance to models trained with a signifi-\ncantly larger number of annotated labels. Even when trained with only 22% of the labeled data, our\nmodel outperforms the Transformer model on F1. Considering the challenges of acquiring a large\nnumber of labels in practical scenarios, the semi-supervised pre-training stage proves to be highly"}, {"title": "7 ABLATION STUDY", "content": "In this section, we aim to delve deeper into the effectiveness of NetFlowGen by systematically\nanalyzing its performance across diverse scenarios. Firstly, we scrutinize its ability to generalize to\nunseen nodes, assessing its adaptability to different traffic patterns. Next, we explore the impact\nof diverse traffic features on the model's predictive capabilities, evaluating how different types of\ntraffic inputs affect performance. Lastly, we analyze the effect of varying Transformer model sizes\non the model's pre-training performance, aiming to decide the optimal size for our task."}, {"title": "7.1 Generalization to Unseen Nodes", "content": "We consider applying NetFlowGen to nodes unseen during pre-training, especially those that\nwere not subjected to any attacks and have different traffic patterns. We select 432 EarlyDetect\nexamples each from the validation and test time spans. Since these nodes were not seen during\nthe pre-training process, we use a nearest-neighbors search to find the most similar training node\nand apply its discretization splits. Since traffic flow features are high-dimensional ($V \\times T \\times |F|$)\nand heterogeneous depending on nodes and feature types, we first summarize each node's traffic\nfeatures through the following process. The features of each node are standardized and reduced\nto minimum, maximum, and 25th, 50th, and 75th percentile statistics, along the time axis. Next,\nwe average features, representing each node as a vector of the five statistics. The closest match\nis found by computing the L1 distance between an unseen node and all training nodes. Through\nthis nearest-neighbors approach, every unseen node is mapped to the most similar training node.\nAs shown in Table 7, non-attack nodes are mapped to a very small number of nodes that have\nmonotonic traffic patterns.\nThe classification results for unseen node traffics are presented in Table 8. Given the relatively\nlow magnitudes of these traffics, NetFlowGen can easily identify the absence of any actual attacks.\nIt accurately classifies all 432 test examples as non-attack instances."}, {"title": "7.2 Traffic Feature Diversity", "content": "In order to show the effect of using more diverse traffic features during pre-training, we present\nthe result of using only a subset of features. NetFlowGen aggregates 86 network traffic features in\ntotal by protocol, TCP flags, and the port associated with incoming or outgoing traffic. Table 3 is\na full list of the traffic features used by NetFlowGen. We built NetFlowGen_Light using only the\n\"Volume\" features of Table 3 without the fine-grained ones. Since our embedding method is scalable\nto a variable number of features, the configuration of the backbone transformer model is the same\nfor NetFlowGen and NetFlowGen_Light. Table 9 demonstrates that NetFlowGen trained on full 86\nfeatures outperforms NetFlowGen_Light, especially on FPR and F1 score. Still, NetFlowGen_Light\nshows comparable performance to the baseline models in Table 5, showing the effectiveness of the\npre-training approach."}, {"title": "7.3 Transformer Model Size", "content": "We also experiment with various sizes and configurations of the pre-trained transformer model\nand present the pre-training results in Table 10. We find that our model is agnostic to the sizes\nwe tested. The smallest model, with 4 decoder layers, 4 attention heads, 128 model hidden size,\nand 512 intermediate hidden size, is used for further fine-tuning experiments as it's more efficient\nduring training and inference bu already achieves good performance. Note that the loss patterns"}, {"title": "8 RELATED WORK", "content": "Statistical methods have been widely used to understand traffic dynamics in networks and are\ncommonly based on probabilistic models to track network behavior and detect changes over hard\nthresholds. The entropy of traffic features, as a basic but prevalent metric, provides fine-grained\ninsights for anomaly detection [4, 20, 56]. Wavelet analysis reveals wavelet components through\nwavelet transformation and captures anomalies from the changes in these components [8, 24].\nPrincipal component analysis (PCA), a dimensionality reduction approach, efficiently separates\ntraffic measurements into normal subspace for principal components and anomalous subspaces for\nthe rest [33, 39, 65]. Other statistical methods employ covariance matrices to track the alterations\nbetween normal traffic and flooding attacks [79], hidden semi-Markov model to depict the spatial-temporal characteristic of the wake-up packet generation process [2], CUSUM algorithms to\nidentify unusual deviations in traffic patterns from the norm in real-time with minimal memory\nexpenses [70]. In contrast to statistical methods that rely on careful design and domain intuition, we\nemploy machine learning, particularly deep learning, with end-to-end training that is data-driven\nand highly scalable.\nThe widespread emergence of machine learning approaches offers fresh opportunities to compre-hend network traffic dynamics. Classical learning-based approaches, including clustering [35, 60, 66],\nnaive Bayesian [68, 69], Support Vector Machine (SVM) [32, 52], decision tree [30], and random\nforest [28], are broadly adopted to identify and classify network traffic. These approaches can be\ncombined together for better performance. For example, a two-step detection approach in IXP\nscrubber [73] first tags each flow with association rule mining and then classifies per-target IP\nprofiles aggregated from flows with ML classifier. Apart from these classical approaches, deep\nneural networks have also been designed to handle even more complex tasks and capture intricate\npatterns in network traffic in recent years. Doshi et al. [18] uses neural networks on IoT-specific\nnetwork behaviors to detect anomalies generated from a local network. Kitsune [53] tracks features\nin network channels and detects network intrusion with an ensemble of auto-encoders. Instead\nof directly classifying traffic patterns, deep neural networks are also capable of learning traffic\nrepresentatives as an intermediary step for downstream endeavors of various purposes. Meng et\nal. [50] provides general encoding for network traffic and optimizes the adaptation effect of the\nmodel to diversified tasks; ET-BERT [45] pre-trains deep contextualized datagram-level represen-\ntation from large-scale unlabeled traffic data. Both of these approaches adopt the pre-training\napproach with unlabeled data, but they are tailored to specific networking features, which limits\ntheir generalization potential.\nDespite the abundance of networking traffic data, building a unified pre-trained foundation\nmodel [5] for networking presents unique challenges. Networking data is multivariate and highly\nheterogeneous, comprising features such as IP addresses, ports, transport protocols, timestamps,\npackets, and bytes, which vary in type (continuous vs. categorical) and scale. This diversity requires\nan effective pre-training objective capable of capturing broad network dynamics while balancing\nfeature importance and handling data heterogeneity. Additionally, curating well-balanced datasets\nfor general-purpose pre-training is difficult. Moreover, for benchmarking tasks, ground truths,\nsuch as true attack labels in network security, are often unavailable, expert labeling is costly, and"}, {"title": "9 DISCUSSION AND IMPROVEMENT POTENTIALS", "content": "We present a practical application of the self-supervised machine learning framework on network\ndynamics modeling, by pre-training a foundation model based on Transformer decoders with\nlarge amount of traffic data, and fine-tuning on specific downstream networking tasks. The self-supervised foundation models [5] have seen great successes in other fields such as NLP [7, 61, 62],\nbut there exist unique challenges for networking data due to its disparity in data and applications.\nDespite our effort in bringing generative model pre-training techniques onto network traffic\ndata with both domain customization and model unification, there are still open questions and\nlimitations around our method that are worth noting, which could also provide potential for further\nimprovements.\nHow to best handle the traffic features? Although both can be naturally formulated as sequences\nor time series, networking traffic data is very different from text data in NLP, where Transformer-based foundation models are widely applied. First, text sequences have regular discrete indexes as\na time series, whereas traffic data can occur at any time with irregular time increments. Second,\ntext data are discrete tokens with a finite number of values coming from a well-defined vocabu-\nlary, whereas traffic data are continuous and can take arbitrary values. As Transformers [71] are\ninitially designed and also best known for processing text data, we customize the network traffic\nfeature representation pipeline to make the features closer to their NLP counterpart. This includes\naggregating traffic under one-minute intervals to make regular time series, and discretizing traffic\nvalues into categorical classes. However, our procedures also pose limitations on the full potential\nof utilizing these features. For example, traffic aggregation may lose details of when and how the\ntraffic occurs, and feature discretization is a lossy process that can not be easily recovered. There\nmight exist better ways of incorporating more details of the networking traffic that can benefit\ndownstream applications that are more sensitive to this detailed feature information.\nHow to incorporate node interactions? In our pre-training formulation, the traffic time series\nis constructed per node or IP address. For each node, we record both the incoming and outgoing\ntraffic, and the NetFlowGen model is trained on all the time series for all available nodes. However,\nno explicit IP node interactions are being learned during this process. For example, the model does\nnot have the knowledge of which node sends traffic to which other nodes. This information could\nbe critical in applications, such as P2P traffic identification [29] and reverse protocol analysis [83],\nthat require not only the traffic volumes, but also the IP addresses that send or receive the traffic.\nIn other words, the network topology is not incorporated during the learning process. Potential\nimprovements could directly encode node information when formulating the traffic features, or\nadopt a different pre-training model architecture such as graph neural networks (GNNs) [27, 42, 77]\nwhich take into consideration the graph topologies. This is likely to depend on different designs of\ndata formulation and training objectives.\nHow big should a networking foundation model be? Although we curate a network traffic\npre-training dataset of about one million minutes from a real ISP that is considered large-scale\ncompared to the data used in previous works, by the standard of foundation models in other fields\nsuch as NLP, the size of our pre-trained models are not large in the number of parameters. For"}, {"title": "10 CONCLUSION", "content": "We envision a general framework of pre-training an ML model to capture network traffic dy-\nnamics for adaptation to downstream tasks, utilizing large amount of raw networking data and\ncircumventing the expensive labeling issues. As an early attempt, we propose NetFlowGen with\ndesigns to represent heterogeneous NetFlow features in a unified space for model processing, and\nadopt Transformer decoder model with a multivariate generative pre-training task. We construct a\nrealistic large-scale dataset for the pre-training and test the model adaptation on a downstream\nDDoS attack detection task. Experiments show the benefits of our pre-trained model in reducing\nthe dependency on large amount of task-specific labels.\nWe also point out several limitations of our method, such as no explicit IP node interaction\nmodeling, and traffic feature discretization being a lossy process. Future works could address these\nlimitations, and explore more varieties of networking tasks for fine-tuning, as well as building\nbetter benchmark data for developing foundation models in networks."}]}