{"title": "What is the Role of Large Language Models in the Evolution of Astronomy Research?", "authors": ["Morgan Fouesneau", "Ivelina G. Momcheva", "Urmila Chadayammuri", "Mariia Demianenko", "Antoine Dumont", "Raphael E. Hviding", "K. Angelique Kahle", "Nadiia Pulatova", "Bhavesh Rajpoot", "Marten B. Scheuck", "Rhys Seeburger", "Dmitry Semenov", "Jaime I. Villase\u00f1or"], "abstract": "ChatGPT and other state-of-the-art large language models (LLMs) are rapidly transforming multiple fields, offering powerful tools for a wide range of applications. These models, commonly trained on vast datasets, exhibit human-like text generation capabilities, making them useful for research tasks such as ideation, literature review, coding, drafting, and outreach. We conducted a study involving 13 astronomers at different career stages and research fields to explore LLM applications across diverse tasks over several months and to evaluate their performance in research-related activities. This work was accompanied by an anonymous survey assessing participants' experiences and attitudes towards LLMs. We provide a detailed analysis of the tasks attempted and the survey answers, along with specific output examples. Our findings highlight both the potential and limitations of LLMs in supporting research while also addressing general and research-specific ethical considerations. We conclude with a series of recommendations, emphasizing the need for researchers to complement LLMs with critical thinking and domain expertise, ensuring these tools serve as aids rather than substitutes for rigorous scientific inquiry.", "sections": [{"title": "1 INTRODUCTION", "content": "Language models are probabilistic representations of the natural human language. The first such models appeared in the 1980s and were purely statistical, based on the frequencies of co-occurrence of phrases of different lengths, so-called n-grams. The power of language models has grown dramatically in the last 5 years with the development of transformers (Vaswani et al. 2017). A transformer is an advanced machine learning model that improves how data sequences are analyzed and generated by simultaneously considering the full context of the input and focusing on the most relevant parts, enhancing performance in language-related tasks. This new architecture, combined with neural networks and large datasets (frequently scraped from the internet), has led to the development of the current (as of mid-2024) generation of Large Language Models (LLMs) as advanced artificial intelligence (AI) systems capable of parsing and generating human-like text.\nCurrent LLMs represent a tremendous technological leap. Unlike other leaps of technology, which were expensive and very few people had access to them at first, LLMs are (in many cases) free and available to (almost) anyone with an internet connection. As a result, their adoption has also been incredibly fast - ChatGPT reached 100 million users within only two months after its launch (Hu 2023) while other services of similar popularity took between 9 months and 4.5 years to reach the same userbase\u00b9. Unlike other technologies primarily automating repetitive work, LLMs excel at creative work like writing, coding, and generating ideas. Finally, the literature surrounding productivity boosts attributed to large language models (LLMs) suggests that there are significant improvements in various tasks, with estimates ranging from 20% to 80% in productivity boosts across different sectors (Peng et al. 2023; Noy & Zhang 2023; Eloundou et al. 2023) compared to the 18-22% improvement brought on by steam power (Atack et al. 2008).\nAlso, unlike other technological advances, LLMs behave very differently from traditional technology. As discussed in (Mollick 2024, p. 65-67), LLMs defy our expectations for software functionality: software should produce predictable, reliable, logical outcomes, and LLMs do not. On the contrary, LLMs (at the moment, at least) struggle with tasks that software is generally good at, such as repeating tasks, reproducing facts, and performing calculations. In contrast, they perform well on tasks we consider uniquely human: writing,\n\u00b9 https://www.visualcapitalist.com/threads-100-million-users/"}, {"title": "2 EXPERIMENTAL APPROACH", "content": "In October 2023, we called researchers within the Max Planck Institute of Astronomy to join a group to explore LLMs' potential, limitations, and impacts on scientific work. The call was open to institute members from all career levels and scientific departments. Approximately 20 people volunteered, ~15 of whom joined the work of the group in some capacity or another. These participants were primarily graduate students and postdocs but also staff with diverse data science expertise and various scientific interests. Only a minority of this group was familiar with the technical aspects of LLMs; however, delving into the internal details of LLMs was not the group's task. The work of the group consisted of a series of regular meetings chaired by the lead author, where the group discussed logistics, ideas, and results from various experiments.\nThe group identified a set of LLM services available at the time (November 2023), and participants volunteered to try one or more of them. Specifically, the services identified and explored are listed in table 1 with a more detailed technical description provided in Appendix A. This list is not exhaustive and reflects LLMs' capabilities at the time of writing.\nAs one can see from the list in table 1, the range of services is broad. It includes conversational interfaces such as ChatGPT, models trained for specific tasks (e.g., Grammarly, Copilot), and LLM-powered search engines (e.g., Perplexity, you.com). We also need to highlight that this is not, by any means, an exhaustive list of applications currently on the market. Neither is this an endorsement of these services. In each category above, there is solid competition, and we encourage readers to explore alternatives to find one that fits their budget and work style. We also tested image generation models, Midjourney and DALL-E.\nSeveral services we used offer both a free and a paid use tier. Our group received a budget of ~1000 Euro for this project, and we acquired licenses for ChatGPT, Perplexity, and Grammarly for the duration of the exploratory work. Most accounts were open between 3 and 5 months. Additionally, GitHub provides students and academics free access to Copilot for educational purposes. Participants who used Copilot were able to access it through this program. Finally, our institute provides staff with access to DeepL Pro. We only used the free tier services for other providers.\nThe first phase of the experiment was ideation. Participants who had used LLMs in research tasks shared experiences, and the group brainstormed other potential opportunities. Participants were encouraged to \"invite LLMs to every conversation\u201d, i.e., to try to incorporate LLMs in all tasks to learn about their strengths, weaknesses, and unique features. In this way, we attempted to map the \"Jagged"}, {"title": "3 EXTENDING FINDINGS THROUGH A SURVEY", "content": "A survey on the attitudes towards and uses of LLMs ran from March 11 to 28 among the employees of MPIA and collected 27 responses. The survey participants range from interns to professors. The questions and responses are detailed in Appendix B. This section discusses the parts of the survey that focused on general questions, ethics, and overall satisfaction. We will discuss the results of this survey in the relevant use-case sections throughout the next sections.\nAmong the 27 survey participants, 74% use LLMs at least several times a week. ChatGPT-3.5 and ChatGPT-4 are the most commonly used, with 89% and 44% of participants indicating that they have experience with them (multiple answers were possible). Following ChatGPT in the list of most frequently used assistants are Grammarly with 41% and GitHub Copilot with 37% (details in Appendix B). The most common tasks are coding (software development) with 92% and writing assistance with 72% of responses (multiple answers were possible). None of the participants find it difficult to use LLMs; on the contrary, 70% of respondents find it easy or very easy to use them. 30% of the respondents indicated some challenges in using LLMs.\nIn terms of ethics, 78% of participants said that credit should be given to LLMs in science publications, but 61% say that they rarely do so at the moment. We discuss some possible reasons in Sect. 5.3.2.\nOverall, 48% of participants were satisfied or very satisfied with the current capabilities of LLMs, 41% were neutral about them, and 11% were not or not at all satisfied. Satisfaction is the highest for software development: 77% are satisfied or very satisfied with using LLMs in that context. Fewer participants are enthusiastic about their writing and problem-solving abilities: 50% are satisfied or very satisfied, and 25% are neutral. More than half of the respondents (59%) indicate a desire to have access to the paid version of such tools, with ChatGPT and GitHub Copilot being the top choices of tools where paid access is desired (note that GitHub Copilot does not have general free access version but students and teachers can get educational access corresponding to an individual tier free of charge). Most participants (83%) believe that LLMs will become an integral part of science, but only 42% think they will be a good influence overall.\nThe survey also asks the participants about their experience and satisfaction in specific use cases we detail below. We discuss those results in the relevant contexts."}, {"title": "4 USE CASES OF LLMS AS A TOOL FOR RESEARCH", "content": "The main focus of our experiments was to explore the use cases of LLMs in the research workflow of astronomers. Even though LLMs have multiple use cases in non-research tasks, this section focuses on tasks related to research activities. Specifically, we tested various models' abilities to generate and improve text, summarize text, write scientific code, and handle data analysis The specific experiments, their results, and conclusions based on these experiences are detailed below."}, {"title": "4.1 Academic Writing", "content": "Writing is essential for all academics and critical for our professional success. From professional communications to cover letters and research plans to manuscripts and funding proposals, written text is indispensable for connecting with colleagues, conveying our findings, obtaining jobs, and securing resources such as telescope/computational time and money. LLMs can assist researchers in various aspects of the writing process, such as generating text, improving readability, and providing suggestions for structure and content. LLM tools can also assist with language translation, grammar checking, and citation formatting.\nFrom our internal survey (see Appendix B), we found that writing assistance is the second most common use case (72% of responses) for LLMs (after coding assistance, 92%). 59% of the survey participants have used LLMs specifically for improving academic texts, but most estimate that the overall contribution of LLMs to their writing is small: only 23% say that LLMs have contributed more than 20% to their texts. However, there is a 0% to 99% spread in how users feel satisfied by the answers of LLMs. Such a result suggests a varying degree of accuracy in the answers, possibly reflecting the range of expectations, use cases, and prompting skills among the participants.\nBased on our tests, most current LLMs offer valuable assistance in understanding scientific concepts, software, and instruments. They can summarize internet searches on specific topics into bullet points, covering introductions, current research, challenges, and prospects. Different services vary in their abilities to cite peer-reviewed articles. LLM-enabled search engines do better. There is also a variation in the style of the response. For example, Gemini or ChatGPT rely on a mix of academic and popular science sources by default. Other platforms (e.g., You.com) allow users to specify a style explicitly. These tools often provide more readable and comprehensive information than Wikipedia articles, which are commonly the first resource for beginners. LLMs can also assist in drafting academic paper templates. This is particularly reliable for papers that employ well-established data sources and analysis techniques. This feature benefits students transitioning to academic writing, non-native English speakers, or anyone facing writer's block. However, our study participants found that the generated templates still require substantial elaboration in style and content before submission to a journal. Hence, the work of the student/researcher is far from being eliminated.\nIt remains important to be the \"human in the loop,\" as there are always instances where responses from these tools require corrections. For example, when prompting GPT-3.5 with \"In what situations can we use MHD? In what regimes does it break down?\u201d, it stated that \u201cmagneto-hydrodynamics assumes collisionless plasma\u201d when the exact opposite is true. When informed about their errors, both chatbots immediately provided the correct output. Gemini also offers an\nGemini cross-check with Google search is done after and does not help to construct the initial response\noption to cross-check responses with a Google search\u00b2 . When asking varied tools, \u201cWho leads the Gaia DPAC?\u201d Gemini answers Francois Mignard wrongly; GPT4 does not find answers and refers to the official Gaia/ESA pages; You.com (genius mode) replies correctly not only the name of the chair (and since when) but also the deputy chair correctly and cites sources.\nIt is difficult for a non-expert to spot these mistakes, as they are very technical. Therefore, if a certain piece of information is key to the user's writing, it is essential to fact-check through a conventional search.\nThe clarity of our messages is critical in academic writing. Clear communication helps avoid misunderstandings and misinterpretations. LLMs can detect potentially unclear or ambiguous sentences and suggest rephrasing or simplifying these sentences to improve clarity. These models can also assess the overall structure and flow of the message and identify sections that need organization or additional context. By ensuring coherence and cohesion, your message becomes more readable and impactful. LLMs can suggest alternative words or phrases to enrich your vocabulary. Overall, they help you express your ideas more precisely and effectively.\nLLMs can also analyze a message's content to identify inappropriate or inconsistent tones and readability scores. They can flag sentences that may be too formal or informal. LLMs can also quickly draft a message that only needs some edits, filter incorrect tones, or highlight potentially unclear sentences. Interpersonal communications are complicated, especially in written forms; LLMs can aid by guaranteeing that our written messages convey the intended meaning, appropriate tone, and level of emotions. Such assistance lets us focus on the content and adjust the form/tone to ensure the message comes across clearly. Enhanced language adds depth and professionalism to your written communication. All these are critical in efficient written communications with colleagues. Such assistance can be beneficial for junior researchers who have had less exposure to formal academic communications. A drawback is that writing can become standardized or mechanical.\nIt is essential to acknowledge that English is not the first language of many if not most professional astronomers who may face bias and discrimination because of their level of expression in this language. LLMs can be a great equalizer in written documents and allow users to focus on ideas rather than grammar. Some of the tested services specialize in this approach. Both Grammarly and DeepL Pro are excellent at recommending improving grammar, word choice, and phrasing while accounting for contexts. Although at this time, they are less consistent, General models can also be prompted to act as a copy editor and highlight grammatical errors with suggestions for replacement. Some users found that wholesale re-writing of the text by an LLM can change the meaning conveyed. It is thus not advisable to do this, and it is paramount that the writer carefully reads the final text to ensure the ideas are true to intended. Translation services such as DeepL (and Google Translate) can also be helpful for researchers who are more comfortable expressing ideas in their first language. Overall, in this role, LLMs can increase accessibility and ensure that scientific contributions are judged based on merit rather than linguistic proficiency.\nFinally, LLMs do not complain when we outsource tedious or repetitive tasks. Such tasks may include formatting citations from one LaTeX template to another, re-formatting a table from HTML to LaTeX or text from Markdown to LateX (e.g., Appendix B), and\n\u00b2 Gemini cross-check with Google search is done after and does not help to construct the initial response"}, {"title": "4.2 Reading and Summarizing Papers", "content": "Starting a new project and diving into the literature can be daunting. Traditionally, scientists employ specific patterns of skimming research papers. These approaches vary from person to person due to individual preferences. Different approaches are also employed based on the goal of the search: e.g., looking for a specific technique, a result, a particular value, or a review of a topic.\nActing as information retrieval systems, LLMs have the technical capacity to summarize texts and connect scientific papers. This feature can transform how researchers navigate the ever-expanding sea of academic articles and resources (e.g., Iyer et al. 2024a). LLMs can offer a solution by rapidly contextualizing papers and summarising their main ideas concerning a specific question (for instance, talk2arxiv.org). They can extract and list the relevant information and even potentially compare results between publications. In one of the tests for this study, we used the preview model of Gemini 1.5 Pro with a 1M tokens context window in Google AI Studio to examine a PDF file of a paper. Gemini (and other LLMs) allows the functionality to upload PDFs, cutting down the workload of manually putting the paper text. We uploaded an 8-page review article with tables and figures. The Gemini model could extract the information accurately and explain the figures in the paper, albeit not very technically. The chatbot also identified which sections of the paper focused on different concepts by referencing page numbers, tables, and figures (see Fig. C1).\nLLMs also have the potential to help break through disciplinary silos, facilitating the discovery of relevant research across diverse academic disciplines or between academic and industry work. One example of the latter is shown in Figures C2 and C3, where we interrogate a US decadal white paper by Smith et al. (2019). This test was done with ChatGPT-4, where PDFs can be uploaded and parsed. The chatbot could correctly summarize the paper and provide a list of major challenges listed by the authors (response not shown here). But it was also able to draw on general knowledge about cloud computing in other scientific disciplines and make a list of recommendations for advancing cloud adoption (Fig. C2) and identify valid challenges not mentioned in the paper (Fig. C3). This approach can be useful to au-\nthors of papers who can identify gaps in analysis or draw on expertise beyond that of a team. A more advanced take on this approach is to give the LLM a certain persona and ask for feedback based on that persona.\nThere were occasional glitches, both scientific and technical. Regarding science, LLMs occasionally answered questions incorrectly, especially about niche astronomy topics and physics concepts. As mentioned later, LLMs do not know anything, and hallucinations are possible even for the advanced models. Hence, we repeat that it is paramount to check the details of the responses. A technical issue is that the uploaded PDF documents were not always processed in full due to limitations in the context window or issues with document parsing. In particular, they often failed to process tables. The handling of figures depends on the platform and the graphics format (vector vs. raster). Still, the LLMs can usually answer questions regarding the figures based on the context of the caption and text alone. A more general concern is that LLMs may lack a consistent ability to grasp the complexities, uncertainties, and subtle nuances that a human scientist would recognize when reading literature. Dependence solely on LLMs for crafting scientific summaries risks producing overly simplistic narratives, neglecting essential arguments and values, and potentially misinterpreting research findings.\nWhile none of the platforms we reviewed are tuned to the specific domain of astronomy and astrophysics, such systems are in development. A model fine-tuned to astronomy, Astro-LLAMA, was published in 2023 (Dung Nguyen et al. 2023), and a prototype of a chatbot platform, pathfinder (Iyer et al. 2024b), was published during the preparation of this manuscript. Such LLMs can answer much more specific questions with greater accuracy and potentially make connections between new and archival publications while adequately citing the sources. Furthermore, they can lead to an exchange of methods and ideas between fields, which is currently limited due to technical language barriers and jargon, a phenomenon termed \u201cundiscovered public knowledge\u201d by Swanson (1986). Currently, both Astro-LLAMA and (Iyer et al. 2024b) are only trained on abstract and thus lack knowledge of the more detailed analysis and scientific results, which are only contained in the full-text publications. However, using the full corpus of astronomical literature may raise legal and ethical concerns (see Sect. 5.3). Software libraries such as langchain enable individual researchers to customize models for use on a limited corpus. Exploring such use cases is beyond the scope of this current paper, but drop-in tools such as Incarmind\u00b3 already exist, and we expect such use to become more commonplace soon.\n\u00b3 Incarmind: https://github.com/junruxiong/IncarnaMind"}, {"title": "4.3 Writing Scientific Code", "content": "One of the most apparent and exploited use cases for LLMs is their ability to generate and analyze computer code. Programming is a critical skill for research astronomers, as shown by Momcheva & Tollerud (2015), yet many researchers do not receive training in proper software development practices. Even for those who received training, the wide-ranging tasks involved in scientific programming are constantly changing and frequently very niche. Although we do not think about it this way, coding is a creative task and thus very well-suited to LLMs. Both general-purpose LLMs (Figure C4) and specialized ones (such as GitHub Copilot, Figure C5) have proven quite adept at programming and have thus become invaluable tools to\nScientists also use LaTeX code to write papers; Overleaf provides LLM tools to debug their documents\nassist in the workflow of a scientific programmer. The tasks they can help with include a range of actions, from explaining code, debugging, or offering simple snippets inside an IDE (Integrated Development Environment) to creating documentation and tests to using chat-based LLMs to create programmatic implementations easily. All of these can drastically improve the speed at which one creates fast, high-quality, scientific code.\nIn our internal survey, coding assistance is the most common use case for LLMs, with 92% of respondents. What users find most useful about coding with LLMs is that it helps them complete tasks faster (83% of responses) and write more code in less time (63%). They can also identify and fix bugs easier (58%), improve their coding knowledge (54%), and learn new coding concepts (54%). Participants found that LLMs rarely suggest very complex code: 71% rarely or never received advanced suggestions. Overall, the code contributions are relatively minor, with 42% of the respondents saying that LLMs have contributed 1-20% of their code and only 8% saying that LLMs have contributed more than 80% to their code. Users are more satisfied with the accuracy of the coding prompts than they were with their writing prompts: 72% of respondents found that more than 60% of their coding prompts were successful. A handful of respondents have tried translating code from one programming language (Julia, IDL, Fortran) to another (Python) and have found varying degrees of accuracy and satisfaction.\nArguably, one of the best tools for auto-completion-assisted coding is Github Copilot, as its context window is large enough to include multiple files at once. This feature is helpful with projects or packages where the quality of the suggestions improves dramatically when the LLM is aware of all the code in the project. In addition, GitHub Copilot includes a chat window in some IDEs, such as Visual Studio Code (VS Code, Figure C5), making it even more convenient. Codeium represents a free alternative to GitHub Copilot that works similarly but provides a smaller context window and no chat capability (in the free individual version). Both companies support extensions for many editors and platforms.\nChatbot platforms, such as ChatGPT3.5/4, Gemini, and Claude, have the advantage that even less experienced programmers can directly formulate their request in plain language (English or any other language), and the LLM will provide a snippet of code in the requested language. The code can be copy-pasted from and to any terminal or editor. Team participants who tested this functionality frequently queried solutions to syntax errors but found the provided code helpful nonetheless. LLMs can also assist programmers by doing arduous or repetitive tasks (e.g., regex string, parsing, code translations from one language to another, etc.) for them, which are often hard to understand for humans, but the LLMs excel in.\nTo assess the behavior of chatbots on more complex programming tasks, we tested ChatGPT-3.5 and ChatGPT-4 on a more advanced coding example: \"Please create a simple beta-Variational Autoencoder model implemented using PyTorch. The model inputs are a set of images and their sky coordinates. The output should be a bijective mapping by coordinates w.r.t the distribution of images in the latent space.\u201d In addition to being complex (several interconnected functions are required), this is not a very common piece of code. The outputs from the LLMs differed: ChatGPT-4 described the model construction in detail, including data preprocessing, network architecture, loss\nIn addition to being complex (several interconnected functions are required), this is not a very common piece of code. The outputs from the LLMs differed: ChatGPT-4 described the model construction in detail, including data preprocessing, network architecture, loss\nScientists also use LaTeX code to write papers; Overleaf provides LLM tools to debug their documents"}, {"title": "4.4 LLMs as Data Analysis Assistants", "content": "Beyond software development, the proliferation of AI tools on platforms like Deepnote, Jupyter, and VScode is revolutionizing how scientists approach data analysis as a whole. AI tools with large context windows can access the entirety of a project, gaining a comprehensive understanding of the code, data warehouses, and metadata. This extensive context awareness enables them to provide precise and customized assistance tailored to the specific work undertaken.\nThe benefits of using AI tools for data analysis are multifaceted. First, they significantly reduce the time required for data exploration and analysis. For example, they allow the scientist to focus on the question in natural language, such as \u201cFilter the data only to include entries with proper motions and parallaxes\u201d and let the AI create the\ncode, rather than have to parse through the (frequently complex) database schema documentation. Second, by automating routine tasks and providing real-time guidance, AI tools could enable scientists to focus on more complex and creative aspects of their work.\nCrucially, these AI tools eliminate the need to start from scratch. Scientists can prompt the tool with a specific task or query, such as \u201cAnalyze the Gaia DR3 source catalog and find the 10 most rapid objects moving in the sky and download their spectra using Python language and ADQL.\u201d The tool then leverages its understanding of the project to define the relevant query for online services, streamlining the data analysis process. Figure C6 shows Perplexity\u2019s response to this query, which details the reasoning and explains the proposed Python code. It also provides the relevant part for downloading the spectra, which the popular Python libraries do not cover. Adding radial velocities to the movement calculations is subtle because it would require some distance estimates. Perplexity provides this limitation if prompted: Without specific distance information, we can't directly convert radial velocities to mas/yr. However, as we mentioned for other tasks, the answer varies between LLMs, and it may vary with time for a single LLM. Regardless, they provide a robust starting point for the scientist to refine.\nAI tools can lower the barrier to analyzing complex datasets and potentially fill the gaps in programming knowledge. However, AI tools are not a replacement for human expertise. Instead, they serve as powerful assistants that augment and enhance the capabilities of scientists. Most code outputs or data analysis results require adjustments, enhancements, or refinements. Deepnote.ai published a 12% acceptance rate of AI-generated outputs on their platform. A small change in the AI prompt could often lead to different outcomes (see 5.4).\n\u2076 Impact of Deepnote Copilot blog post at deepnote.com"}, {"title": "4.5 Image Generation for Outreach", "content": "When communicating astrophysical research to the general public, it is often important to supplement scientific material with visually impressive, easy-to-understand images and videos to capture the audience's attention and clarify key points. Major differences emerge when comparing plots for a scientific audience to outreach images used in popular presentations. First, \u201cmathematical-looking\u201d plots, labels, and similar elements should be reduced to a minimum. This avoids confusing non-experts with unfamiliar concepts like logarithmic scaling and also helps retain attention, as many people are \u201cturned off\u201d by overly technical or mathematical details. Second, it is sometimes necessary to sacrifice accuracy for simplicity. In line with the first point, focusing on a single, basic idea is often more effective than presenting nuances meant for a more specialized audience. Third, it can be beneficial to prioritize visual coherence or \u201cbeauty\u201d over precision. The goal is to capture attention, and visually striking schematics or animations will aid in doing so. As such, a \u201cgood outreach image\u201d fulfills the following criteria: (1) Easy to parse and understand the key point, even without scientific background; (2) Visually impressive and coherent; (3) Scientifically sound, even if minor or technical details can be omitted.\nHowever, most astronomers have little to no experience in areas such as computer animation or digital art. They are rarely tasked with making the images used with, for example, press releases. Regardless, these images and animations can be helpful tools when\ncommunicating scientific findings, particularly for a lay audience, for the above reasons.\nGenerative AI, and more specifically, image generation models (such as DALL-E), can assist in scenarios with limited access to artists or animators. Even in these scenarios, it is important to avoid using images and videos at the risk of communicating incorrect science. Thus, it is imperative to assess the generated images according to the criteria outlined above.\nIn this study, we attempted to generate a handful of outreach images for some astrophysical concepts using BingAI\u2019s Creator and ChatGPT, both of which use DALL-E as the underlying image generator. The main difference in these models is their specific conversion or translation of the user prompts to DALL-E prompts fed to the image generator, which occurs \u201cunder the hood.\u201d For each experiment, we iterated several times to optimize the outcome, updating the user prompt to suit our needs. For brevity, we only present one such case here, generated using ChatGPT to create a visually appealing picture of a stellar cluster with tidal tails. This experience poses an interesting example, as there are few images of this astronomical concept aimed at a lay audience. Further, it combines multiple astrophysical aspects, thus creating a challenging prompt for the LLM. Table C1 illustrates the generation process through multiple iterations.\nThe LLM struggles to encode the astronomical jargon into a scientifically sound image. Inherently, the challenge here is that \u201cCluster\u201d and \u201ctidal tails\u201d have specific meanings in an astrophysical context but also connect with more popular contexts outside astronomy. It is perhaps not particularly surprising that without reference image prompting, the generated images consistently show \u201cclusters\u201d or blobs of stars within a larger structure. Further, the use of \u201ctides\u201d likely evoked a relation to oceanic tides, and thus wave-like structures were generated. An attempt to first get the \u201ccluster\u201d portion right, while leaving out the \u201ctides\u201d, resulted, again, in blobs of stars, now without the wave-like structures. After showing an image of a globular cluster with tidal tails to the LLM, it managed to move away from repeating the same structure but produced something more akin to a spiral galaxy. Asking it to create something more aligned with the reference image again prompted the blob structure.\nThis example demonstrates that context is essential when parsing prompts for image generation in LLMs. One must word prompts carefully and precisely, ideally omitting jargon and especially polysemes, i.e., expressions that have more widespread sense. Reference images can be helpful but do not guarantee a desirable outcome. Great care has to be taken when generating images for outreach with tools like ChatGPT to avoid confusing a lay audience with potentially erroneous images.\nAt this present stage, our experience shows that AI tools could help with simple illustrations but not with complex concepts. For the next few years, artists or animators will continue to be the path of choice for creating effective illustrations."}, {"title": "5 DISCUSSION", "content": "Following the presentation of our findings, this section summarizes the main benefits and limitations, discusses legal and ethical concerns, and discusses general tips for making the most of using LLMs for research."}, {"title": "5.1 Benefits of LLMs in Research", "content": "LLMs have many and varied applications to tasks carried out by researchers, as demonstrated in the use cases discussed in Section 4. LLMs can assist in communication tasks: drafting emails, letters, papers, and proposals. They can also help in editing and proofreading academic manuscripts, formatting citations and bibliographies, and generating content for teaching. They can summarize individual or multiple documents, identify gaps in analysis, and create summaries of existing research and literature. They can also identify trends in the field, making them especially useful for literature review. LLMs can generate and analyze code, assist in debugging and refactoring code, and help in code documentation and explanation. LLMs can process and analyze large datasets, extracting key insights and information and aiding decision-making processes.\nIntegrating Large Language Models in research workflows offers numerous advantages, from enhancing communication and facilitating literature reviews to streamlining data analysis and supporting software development. LLMs have the capacity to significantly reduce the time required for data exploration and analysis. For example, they allow the scientists to focus on the question in natural language rather than parse through (frequently complex) sources of information. By automating routine tasks and providing real-time guidance, AI tools could enable scientists to focus on more complex and creative aspects of their work. As researchers increasingly adopt these tools, the potential for significant productivity gains becomes evident. In our survey, 83% of respondents think that LLMs will become an integral part of science, which likely translates the versatility of AI to be applied across various tasks in academia.\nResearch is inherently a process of complex knowledge-based tasks, which rely on a pool of experts with significantly varying abilities and knowledge. People who would likely get the biggest boost out of this technology are those with the lowest initial ability in a given task, especially students. Still, even those with the highest level of skill are likely to benefit in terms of productivity and efficiency (pages 156-157, Mollick 2024). At the same time, subject expertise will become not less but more important. Expertise requires knowledge of facts, extensive practice, critical thinking, problem-solving, and the ability to think through problems and troubleshoot. Being the responsible \u201chuman is the loop\u201d requires us to be engaged in this collaboration with LLMs but also allows us to learn from them; it fosters a sense of responsibility and accountability (page 54, Mollick 2024). Economists predict that AI is unlikely in the next several years to cause dramatic changes in most jobs (Ilzetzki & Jain 2023), and we believe this to be true about the work of researchers in astronomy as well. As demonstrated by our survey (Sect. B), most participants reported relatively minor contributions to their code. Instead, we will likely experience many small workflow changes that will improve efficiency, and we will delegate some tedious and/or repetitive tasks to LLMs and use them as tools to enhance our creativity."}, {"title": "5.2 Limitations and Responsible Use", "content": "While LLMs offer remarkable potential", "anything": "if you ask an LLM for a citation, a quote, or a number, it will generate the"}]}