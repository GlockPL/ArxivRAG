{"title": "Detecting Misinformation in Multimedia Content through Cross-Modal Entity Consistency: A Dual Learning Approach", "authors": ["Zhe Fu", "Kanlun Wang", "Wangjiaxuan Xin", "Lina Zhou", "Shi Chen", "Yaorong Ge", "Daniel Janies", "Dongsong Zhang"], "abstract": "The landscape of social media content has evolved significantly, extending from text to multimodal formats. This evolution presents a significant challenge in combating misinformation. Previous research has primarily focused on single modalities or text-image combinations, leaving a gap in detecting multimodal misinformation. While the concept of entity consistency holds promise in detecting multimodal misinformation, simplifying the representation to a scalar value overlooks the inherent complexities of high-dimensional representations across different modalities. To address these limitations, we propose a Multimedia Misinformation Detection (MultiMD) framework for detecting misinformation from video content by leveraging cross-modal entity consistency. The proposed dual learning approach allows for not only enhancing misinformation detection performance but also improving representation learning of entity consistency across different modalities. Our results demonstrate that MultiMD outperforms state-of-the-art baseline models and underscore the importance of each modality in misinformation detection. Our research provides novel methodological and technical insights into multimodal misinformation detection.", "sections": [{"title": "Introduction", "content": "Social media platforms have emerged as pivotal communication channels for users to generate and share ideas, contributing to a growing volume of information dissemination within online communities (Kapoor et al., 2018). The dissemination of authentic information uplifts and nurtures a healthy online environment, fostering users' emotional well-being through the promotion of positivity, happiness, and a sense of community (Akram & Kumar, 2017; K. Wang et al., 2023). In contrast, the dissemination of falsified information can lead to a substantially adverse impact on various targets, ranging from individual users to the general public (L. Wu et al., 2019). The substantial influx of misinformation on social media platforms has sparked significant concerns across various domains, including public health (Naeem & Bhatti, 2020), business (Rangapur et al., 2023), and politics (Bovet & Makse, 2019), further deteriorating the social environment and online ecosystem. For instance, the proliferation of online misinformation on coronavirus disease in the first three months of 2020 resulted in nearly 6,000 people being hospitalized worldwide (WHO, 2021). In addition, government regulation of online video services across different continents is on the rise (\"Trends and Issues in Online Video Regulation in the Americas,\" n.d.). For instance, the European Union has introduced new obligations on video-sharing platforms, which require platforms to safeguard minors from harmful content and protect the general public from illegal content or content promoting violence or hate speech. Therefore, the development of misinformation detection techniques plays a crucial role in curbing the dissemination of misinformation and promoting the legitimacy of online communications.\nDespite the growing body of literature on online misinformation detection (Khattar et al., 2019; Y. Wang et al., 2021; Y. Wu et al., 2021), it lags behind the increasingly prevalent multimodal content on social media platforms. The latter is driven by the desire for diverse and rich expression, enhanced storytelling, increased engagement, and the accommodation of various user preferences (Shah, 2016). Specifically, Social Media Content (SMC) could incorporate text for conveying information, an image for visual effects, and audio for providing additional context or emotions, resulting in three primary modalities-text, image, and audio. The variety of SMC modalities enhances the interpretability of users' expressions, yet also poses significant challenges for misinformation detection. Recent research (Choi & Ko, 2022; Qi, Bu, et al., 2023; Shang et al., 2021) has leveraged deep learning models to extract informational cues from multimodal SMC to facilitate misinformation detection. However, the role of consistencies among multimodal SMC in misinformation detection has been severely understudied.\nInconsistency has been considered as an indicator of deception or veracity in the literature (Heinrich & Borkenau, 1998; Shan et al., 2021). An entity, typically referring to a person, location, or organization mentioned in SMC, can provide important insights for evaluating the consistency across modalities. Emerging studies have explored the role of entity consistency across different modalities in misinformation detection from multimodal SMC (e.g., Qi et al. 2023; Tan et al. 2020). However, these studies, focused on the text and image modalities, fail to address SMC with more than those two modalities. For example, as another form of medium in SMC, video is inherently more complex (e.g., a combination of text, image, and audio), as shown in Figure 1, and is widely used on video-centric social media platforms (e.g., YouTube, TikTok). As a result, it is more complex and challenging to identify entities from the video content and measure the consistency of entities between different modalities in video-centric SMC. Last but not least, existing studies simply concatenate the scalar value of cross-modal entity consistency to SMC representation, which lacks robustness and may lead to information loss."}, {"title": "Related Work", "content": "This section reviews related work on multimodal social media content and misinformation detection models, particularly deep learning-based models."}, {"title": "Multimodal Social Media Content", "content": "Social media platforms allow users to express themselves and share information and opinions in multiple modalities, including text, image, and audio.\nText generally encompasses the text title, description, and other relevant textual content (e.g., captions and/or transcriptions of videos) of social media posts. Characteristics of textual content may include linguistic features (e.g., Papadopoulou et al. 2017; Volkova et al. 2017), lexicon-based psycholinguistic features (e.g., Linguistic Inquiry and Word Count (Tausczik & Pennebaker, 2010)), and vectorized features (e.g., GloVe (Pennington et al., 2014) and Word2Vec (Mikolov et al., 2013)). Moreover, there has been increasing attention to leveraging pre-trained language models (e.g., BERT (Devlin et al., 2019) and ROBERTa (Liu et al., 2019)) to obtain the latent representation of text.\nImages play a crucial role in information sharing due to their richness and expressiveness, making them a valuable supplementary component for misinformation detection. Exemplary studies that focus on detecting visual tampering clues leverage the error level analysis algorithm (Xue et al., 2021) or image noise consistency to detect tampering traces (Mahdian & Saic, 2009). Along with others, semantic features (Cao et al., 2020), distinct fake image features (Jin et al., 2016), and emotional effects (Shu et al., 2017) have also been proven effective in capturing the nuanced context of images.\nAudio modality involves acoustic signals or voice waves, which are conveyed from speech, environment sounds, and background music (Bu et al., 2023). While audio is always integrated into videos, it also exists independently in various forms, such as podcasts and audio files (Comito et al., 2023). To leverage the audio modality, Hou et al. (2020) utilized raw low-level acoustic features with the openEAR (Eyben et al., 2009) toolkit, and Shang et al. (2021) transformed audio segments into fix-length embedding vectors by extracting the Mel-frequency Cepstral Coefficients features (Palo et al., 2018). The emergence of pre-trained models like VGGish (Hershey et al., 2017) has sparked widespread use for extracting audio content features in recent studies (Lin et al., 2023; Mao et al., 2023; Qi, Bu, et al., 2023)."}, {"title": "Deep Learning-Based Misinformation Detection Models", "content": "In recent years, there has been a surge of research on social media analytics and online misinformation detection, driven by the remarkable effectiveness and efficiency of deep learning (e.g., Choi and Ko 2022; Khattar et al. 2019; Qi et al. 2023; L. Wang et al. 2023).\nPrevious studies have primarily concentrated on the text modality for misinformation detection (Guacho et al., 2018; Sarin & Kumar, 2020; L. Wu et al., 2019). The primary focus of those studies was on leveraging plain text to detect misinformation, often entailing the training of a classifier using textual posts sourced from public SMC. Due to the diverse nature of SMC disseminated on social platforms, there has been increasing attention to detecting misinformation from SMC in text and/or image modalities. Previous research (Khattar et al., 2019; Y. Wang et al., 2021; Y. Wu et al., 2021) focused on the use of co-attention mechanisms to fuse the features of text and image content. For instance, Z. Wang et al. (2021) incorporated semantic- and task-level attention mechanisms to enhance deep learning model performance to detect anti-vaccine-related misinformation from medical posts on Instagram. Y. Wu et al. (2021) employed multimodal co-attention mechanisms to facilitate misinformation detection by stacking co-attention layers after extracting features from images and textual content. Khattar et al. (2019) explored the use of autoencoders to compress pertinent cues in text-image modalities. In addition to studies solely dependent on extracted features of multimodal content to improve model performance, some endeavors have been undertaken to incorporate external knowledge into detection models. For example, Qian et al. (2021) proposed a knowledge-aware multimodal adaptive graph convolutional network framework, which represented social media posts as graphs and integrated external knowledge (i.e., conceptualized entity relations) from a knowledge graph constructed through a set of text entities. However, their approach of fusing features through a basic concatenation operation, incorporating image representations from VGG and text presentations from a graph convolutional network framework, proved inadequate in capturing intricate inter-modality relationships.\nY. Wang et al. (2021) detected fake news related to emergent events using an end-to-end meta-neural process framework with a limited set of verified posts to explore the modality correlation between textual and visual news content. Similarly, Qi et al. (2021) proposed an entity-enhanced framework that leveraged three text-image correlations, including entity consistency, mutual enhancement (i.e., the text-image semantic relation), and text complementation. Chen et al. (2022) proposed and investigated the concept of cross-modal ambiguity, which was measured by Kullback Leibler (KL) divergence between text and image feature distributions. Nevertheless, this study lacks comprehensiveness as the ambiguity measurements concentrate on the high-level representations (e.g., embedding vector-level) while ignoring entity-level representations. In contrast, Zhou et al. (2020) introduced a Similarity-Aware FakE (SAFE) news detection model, learning cosine similarity-based relationships between images and text. Notably, in their research, features of images were generated from their textual captions, which were converted from raw images by using an image-to-sentence tool (Vinyals et al., 2017). This incurs potential information loss due to the limitations of the text corpus used by the tool.\nDespite the significant research in text- and/or image-based misinformation detection, video-centric SMC remains underexplored for misinformation detection. Among the few limited studies, Choi and Ko (2022) leveraged domain knowledge (i.e., domain-specific features related to fake news) to validate the legitimacy of video-centric SMC. Shang et al. (2021) investigated COVID-19-related short videos on TikTok by extracting features across different modalities and aggregating heterogeneous clues. Qi, Bu, et al. (2023) introduced a Chinese short video dataset and a video misinformation detector. In addition, some others have applied both supervised- and self-supervised learning methods (K. Wang, Chan, et al., 2022) and contrastive learning, masked language modeling, and/or cross-sampling (Qi, Zhao, et al., 2023; X. Wu, 2023) to detect misinformation.\nIn summary, previous research in misinformation detection has primarily focused on either a single modality or the fusion of text and image modalities. Studies addressing text, images, and audio remains scarce. In addition, while entity consistency has demonstrated potential as an indicator for misinformation detection (e.g., Qi et al. 2023; Tan et al. 2020), current measures of entity consistency rely on a scalar value derived from various modalities during model development without actually learning the consistency among multimodal content or entities."}, {"title": "Method", "content": "We propose MultiMD, a cross-modal entity consistency-based approach via dual learning to determine whether video-centric SMC is fake (i.e., misinformation) or not. The approach utilizes entity consistency across three different modalities to enhance model performance. MultiMD consists of two novel artifacts for multimodal fusion (see Figure 2): a dual learning mechanism to learn a high-dimension representation of entity consistency from the multimodal representations of SMC and a hierarchical computational approach to measuring entity consistency in video-centric SMC."}, {"title": "Problem Formulation", "content": "We frame misinformation detection as a binary classification problem, wherein SMC in the form of a video is classified as either real or fake. We represent SMC as S = {T, I, A}, where T, I, and A denote textual, image, and audio content, respectively. To effectively learn an SMC representation, we aggregate the video content in three modalities (i.e., text, image, and audio) in building a classifier, as shown in equation (1).\n$y = f(\\theta,S)$ (1)\nWhere f() is the classification function; y denotes the classification result of S; and $\\theta$ denotes the set of parameters of f (\u00b7)."}, {"title": "Multimodal Content Representation", "content": "To represent the textual content, including the titles and descriptions of SMC, we use a pre-trained BERT embedding model (Devlin et al., 2019) to encode the text into vector representations, given that the effectiveness of BERT encoder has been well demonstrated by previous NLP studies (Kaliyar et al., 2021; Minaee et al., 2021; K. Wang, Fu, et al., 2022). We deploy a special classification token (i.e., [CLS]) at the beginning of a word sequence and the ultimate hidden state associated with this token serves as the consolidated sequence representation. We obtain the representation of the textual content $h_T$ with a dimension size of 768."}, {"title": "Images", "content": "For image representation, we first conceptualize the image content I = {$F_1$, $F_2$, ..., $F_k$} as a sequence of video frames, where $F_k$ is an image frame in a video file and k represents the total number of frames sampled at 1-second intervals from the video. Drawing on prior studies (e.g., Khattar et al. 2019; Qi et al. 2021), we adopt VGG19 (Simonyan & Zisserman, 2014), a CNN-based model pre-trained on ImageNet, to generate the representation of each frame in the image content. To generate a unified representation of image content $h_I$, we aggregate the 1,024-dimension representation vectors of all video frames with an average pooling mechanism (see Equation 2).\n$h_I = ave([F_1, F_2, ..., F_k ])$ (2)"}, {"title": "Audio", "content": "To represent audio content (e.g., the soundtrack associated with the video), we segment the audio content of video file A into a sequence of consecutive chunks A = {$C_1$, $C_2$, ..., $C_k$ }, where $C_k$ is an audio chunk in A and k is the total number of chunks sampled at 1-second intervals from A. It is worth noting that the sampling frequencies of image and audio content are synchronized. Following previous studies (e.g., Chen and Zhang 2023; Conti et al. 2022; Qi, Bu, et al. 2023), we deploy the VGGish model (Hershey et al., 2017) to extract wave signals of audio content effectively. Finally, we generate a unified representation of the audio, $h_A$ through average pooling of the 128-dimension vectors of all audio chunks."}, {"title": "Multimodal Fusion", "content": "We concatenate the representation vectors of all three modalities, as shown in Equation 3.\n$h_{SMC} = [h_T; h_I; h_A]$ (3)\nWhere $h_T \\in \\mathbb{R}^{1\\times768}$, $h_I \\in \\mathbb{R}^{1\\times1024}$, and $h_A \\in \\mathbb{R}^{1\\times128}$ are the representation vectors of the three modalities."}, {"title": "Dual Learning", "content": "Despite the benefit of concatenating multimodal representations in the SMC representation for information retention without incurring substantial information loss, it might introduce noise that can distract the model's attention and compromise the reliability of prediction results (H. Li et al., 2018). To address this issue, a few studies have explored entity consistency across different modalities as crucial clues to enhance the effectiveness of misinformation detection (e.g., Qi et al. 2023; Tan et al. 2020). However, these studies fail to address SMC with more than two modalities. More importantly, existing studies simply leverage the scalar value of cross-modal entity consistency, which lacks sufficient information and robustness.\nTo address the above limitations, we introduce a dual learning approach. The approach consists of two learning tasks, with the primary task focusing on misinformation detection and the auxiliary learning focusing on measuring cross-modal entity consistency. The primary learning task aims to obtain an effective SMC representation for misinformation detection, while the auxiliary task aims to learn a high-dimensional representation for entity consistency. By performing the two learning tasks simultaneously, the proposed dual learning approach can mutually optimize the representations of both SMC and entity consistency and consequently enhance the performance of MultiMD."}, {"title": "Primary Learning Task: Misinformation Classification", "content": "With the generated representation of SMC $h_{SMC}$, we build a classification model by designing two fully connected layers with a SoftMax function to generate the probability distributions for the two target classes \u2013 fake and real (see Equation 4).\n$\\hat{y} = softmax(W_2 \\Phi(W_1 h_{SMC} + b_1) + b_2)$ (4)\nwhere $\\hat{y}$ is the classification result of SMC. $W_1 \\in \\mathbb{R}^{d_1\\times d}$ and $W_2 \\in \\mathbb{R}^{2\\times d_1}$ denote the learnable weights; d is the dimension of SMC representation $h_{SMC}$; $d_1$ is the dimension of the hidden output of the first fully connected layer; $b_1$ and $b_2$ are the biases for the respective fully connected layers; and $\\Phi$ is the activation function (e.g., sigmoid, Tanh, and ReLU). We choose the binary cross-entropy as the loss function (see Equation 5), where N denotes the training data size. The learning goal is to minimize the loss value.\n$L(\\theta) = -\\frac{1}{N}\\sum_{i=1}^{N}[y_i log(\\hat{y_i}) + (1 - y_i) log(1 - \\hat{y_i})]$ (5)"}, {"title": "Auxiliary Learning Task: Entity Consistency Estimation", "content": "Previous studies suggest that cross-modal consistency can serve as a potential indicator for misinformation detection (e.g., M\u00fcller-Budack et al. 2020; Qi et al. 2021; Sun et al. 2023). Therefore, we anticipate that incorporating entity consistency into the SMC representation would further enhance the performance of our primary learning task. To this end, we propose a Multi-Layer Perceptron (MLP) as a feature extractor to extract entity consistency features $h_{consistency}$ from the SMC representation.\n$h_{consistency} = MLP(h_{SMC})$ (6)\nTo empower the extractor with the ability to learn useful features for inferring cross-modal consistency, we design another auxiliary learning loss function for the cross-modal consistency prediction task (see Equation 7).\n$L_{aux} = \\left || (W_c h_{consistency} + b_c) - y_{consistency} \\right ||^2$ (7)\nwhere $W_c \\in \\mathbb{R}^{1\\times d_c}$ denotes learnable weights; $d_c$ is the dimension of $h_{consistency}$; $b_c$ is the bias for the fully connected layer, and $y_{consistency}$ is the ground truth of cross-modal consistency.\nGiven the absence of ground truth for entity consistency in our dataset, we propose a hierarchical entity similarity-based approach to generate pseudo ground truth for the auxiliary learning task automatically. Specifically, we extract entities from the textual, image, and audio content of SMC separately.\n\n*   Textual content. We leverage spaCy\u00b9, a software library for advanced natural language processing, to extract named entities (e.g. persons, locations, organizations) from the textual content of SMC. Then, we use the pre-trained word2vec\u00b2 to encode the extracted entities as embedding vectors.\n*   Image content. We first extract the keyframes of each video, considering that a significant portion of frames in the same video are likely to be identical or similar to one another with minimal changes between consecutive scenes. We then leverage the BLIP model (J. Li et al., 2022), a vision-language pre-trained model, to caption each keyframe of a video with a short phrase. To obtain entities from the image content, we aggregate the entities extracted from the caption of each keyframe and employ the method for textual content to encode the identified entities.\n*   Audio content. We first transcribe it into text using the SpeechRecognition tool\u00b3, a library supporting speech recognition. Subsequently, we extract entities from text to the audio transcription.\n\nTo account for the contradictory content across different modalities that misinformation might incorporate, we develop measures for cross-modal consistency based on entity similarity. Moreover, we measure the hierarchical consistency at two different levels: modality and SMC. At the modality level, we measure the entity consistency between any pair of modalities based on the maximum consistency value, as shown in Equation (8).\n$consistency_{M_1,M_2} = \\max_{e_i, e_j \\in M_1, M_2} \\frac{e_i \\cdot e_j}{||e_i||||e_j||}$ (8)\nwhere $e_i$ and $e_j$ are two entity embedding vectors extracted from modalities $M_1$ and $M_2$, respectively.\nAt the SMC level, we aggregate the three modality-level consistency values (i.e., text-image, text-audio, and image-audio consistency) in video-centric SMC by averaging them. We use the SMC-level entity consistency as the pseudo ground truth for consistency in the auxiliary learning task. Finally, we enhance the representation of $h_{SMC}$ by concatenating it with the extracted feature vector $h_{consistency}$, as shown in Equation (9).\n$h'_{SMC} = [h_{SMC}; h_{consistency}]$ (9)\nThe enhanced SMC representation $h'_{SMC}$ learned by the auxiliary learning task is expected to improve the performance of the primary learning task (i.e., the misinformation classification task formulated in Equation 4). Meanwhile, the auxiliary learning task can learn a more informative and robust representation of entity consistency with a more effective SMC representation learned through the primary task."}, {"title": "Evaluation", "content": "We evaluate the effectiveness of our proposed model for misinformation detection by comparing its performance with those of the baseline models. The model performances are reported in Table 1 and the results of paired sample t-tests are presented in Table 2. Notably, MultiMD demonstrates significantly higher accuracy (p<.001 or p<.01) and F1 scores (p<.001) than all baseline models. In addition, MultiMD demonstrates significantly higher recall than EM_FND (p<.01), MVAE (p<.001), MCAN (p<.001), and FVDM (p<.05) models. Furthermore, MultiMD achieves significantly higher precision than MVAE (p<.001), and marginally higher precision than the EM_FND, MCAN, and FVDM models (p<.1)."}, {"title": "Conclusion", "content": "As the expression of misinformation becomes richer, the method for its detection should leverage multimodal information to capture a broader range of deceptive tactics. This study investigates an understudied area of misinformation detection by developing a novel multimodal framework for detecting misinformation from video-centric SMC. The framework not only expands the scope of literature by integrating text, image, and audio content for misinformation detection, but also introduces a dual learning-based method for enhancing video representations. In particular, the dual learning method encompasses a primary task centered on misinformation detection alongside an auxiliary task focused on measuring entity consistency.\nIn response to RQ1, our empirical evaluation results demonstrate that the model based on our proposed framework (i.e., MultiMD) outperforms the state-of-the-art multimodal misinformation detection models across all evaluation metrics. Notably, our proposed entity consistency mechanism significantly augments the model's overall performance. The results provide a strongly positive response to RQ2. Furthermore, in response to RQ3, our results show that the model incorporating all three modalities leads to the best performance. In other words, each modality of the video-centric SMC contributes to the model performance.\nThis research offers opportunities for future extensions. First, this study mainly focuses on learning useful information from SMC, such as representations of individual modalities and entity consistency. Our proposed framework can be further enhanced by incorporating the importance of individual modalities and/or leveraging external knowledge sources to facilitate misinformation detection. Second, our proposed framework leverages various tools for preprocessing multimodal data, such as entity extraction and image captioning tools. These tools may introduce noise to the dual learning process. Similarly, we propose a novel method for generating the studio ground truth for entity consistency, which however may not perfectly mirror cross-model consistency. Thus, the performance of our framework can benefit from future advances in these related techniques. Third, while we derive consistency measures based on the entities in SMC, other forms of information such as sentiment can serve as alternative bases for measuring consistency, warranting further investigation in future research. Moreover, the finding about the positive impact of cross-model consistency on the performance of misinformation detection models opens a new avenue for future research. For instance, future research can delve into the role of consistency in misinformation detection, offering deeper insights into how the consistency measure interacts with individual modalities to bolster the model performance. Last but not least, an examination of our proposed framework for classification tasks across different problem domains employing video-centric SMC would contribute to a broader understanding of its generalizability. One interesting extension of this research is to evaluate the efficacy of the framework in identifying misinformation from AI-generated video content."}]}