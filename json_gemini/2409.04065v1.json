{"title": "An Argumentative Approach for Explaining Preemption in Soft-Constraint Based Norms", "authors": ["Wachara Fungwacharakorn", "Kanae Tsushima", "Hiroshi Hosobe", "Hideaki Takeda", "Ken Satoh"], "abstract": "Although various aspects of soft-constraint based norms have been explored, it is still challenging to understand preemption. Preemption is a situation where higher-level norms override lower-level norms when new information emerges. To address this, we propose a derivation state argumentation framework (DSA-framework). DSA-framework incorporates derivation states to explain how pre-emption arises based on evolving situational knowledge. Based on DSA-framework, we present an argumentative approach for explaining preemption. We formally prove that, under local optimality, DSA-framework can provide explanations why one consequence is obligatory or forbidden by soft-constraint based norms represented as logical constraint hierarchies.", "sections": [{"title": "1 Introduction", "content": "In complex situations, norms can conflict, leading to challenges in normative systems. To address this, several studies have interpreted norms as soft constraints [6, 15, 16, 22]. Unlike hard constraints, which must be exactly satisfied, soft constraints are allowed to be relaxed, enabling agents to prioritize norms based on the context. This paper focuses on constraint hierarchies [2], a pioneering formalism for dealing with soft constraints. Prior work has investigated various aspects of maintaining norms represented as constraint hierarchies, including debugging norms based on user expectation [12], revising norms based on new information [13], and exploring connections with case-based reasoning [14]. However, a key challenge lies in understanding preemption. Preemption refers to a situation where higher-level norms override lower-level norms as more information becomes available. If preemption is not well-understood, it can undermine trust in the normative system. Imagine a situation where an agent expects a certain consequence to be obligatory, but it is ultimately forbidden due to preemption. Without explanation, the consequence becomes unexpected and this can erode trust in the system. Therefore, explaining preemption is critical for building trust in the system and allowing agents to understand the rationale of the normative system for handling norms and preferences.\nTo address this, we present a novel argumentative approach for explaining preemption. Argumentative approaches are widely used for"}, {"title": "2 Preliminaries", "content": "In this paper, we consider representing norms as logical constraints. Let L be a classical logical language generated from a set of propositional constants in a standard way. We write \u00ac for negation, \u2192 for implication, \u2194 for equivalence, \u22a4 for a tautology, \u22a5 for a contradiction, and \u22a2 for a classical deductive monotonic consequence relation. A constraint hierarchy is typically represented as H = \u27e8H1,..., Hl\u27e9, where l is some positive integer, and each Hi \u2286 L, called a level, is a finite subset of logical constraints. In original definitions of constraint hierarchies [2], there exists a level Ho consisting of required (or hard) constraints that must be exactly satisfied. However, in this paper, we consider the level of hard constraints as a background theory To to simplify other definitions. Each Hi consists of preferential (or soft) constraints that can be relaxed if necessary. A constraint hierarchy is totally ordered, which means that a preferential level H with smaller i consists of more important constraints. Given a constraint hierarchy H = \u27e8H1,..., Hl\u27e9 and a background theory To, we also treat H as the whole set of logical constraints, that is H = \u222ai\u2208{1,...,l}Hi. With a general assumption that To is consistent (i.e. To \u22a2 \u22a5), we say H is consistent if and only if To \u222a H \u22ac \u22a5. For example, given that To is empty, (\u27e8{p}, {q}\u27e9) is"}, {"title": "3 Proposed Framework", "content": "To leverage an argumentation framework in the norm structure, we first define derivation states and derivation state spaces as follows.\nDefinition 2 (derivation state). Let To be a background theory, \u03b4 \u2286 L, \u03c0 \u2286 L, \u03c8 \u2208 L, and \u03a3 = {1, +, \u2212, n} be the domain of derivation states. A derivation state (\u03c3) of \u03c8 with respect to \u03b4 and \u03c0 is defined as follows.\n1. \u03c3 = \u22a5 if \u03b4 is not consistent with \u03c0.\n2. \u03c3 = + if To \u222a \u03b4 \u222a \u03c0 \u22a2 \u03c8 and To \u222a \u03b4 \u222a \u03c0 \u22ac \u00ac\u03c8.\n3. \u03c3 = \u2212 if To \u222a \u03b4 \u222a \u03c0 \u22a2 \u00ac\u03c8 and To \u222a \u03b4 \u222a \u03c0 \u22ac \u03c8.\n4. \u03c3 = n if To \u222a \u03b4 \u222a \u03c0 \u22ac \u03c8 and To \u222a \u03b4 \u222a \u03c0 \u22ac \u00ac\u03c8.\nDefinition 3 (derivation state space). Let H be a constraint hierarchy corresponding with sub-base space (\u0394, \u2265), \u03a0 be a situation, and \u03c8 be a consequence. A derivation state space (denoted by \u03a9) of \u03c8 with respect to H and \u03a0 is the set \u03a9 = {(\u03b4, \u03c0, \u03c3) \u2208 \u0394 \u00d7 2L \u00d7 \u03a3 | \u03c3 is a derivation state of \u03c8 with respect to \u03b4 and \u03c0}.\nNow, we define a DS-argument as follows.\nDefinition 4 (DS-argument). Let H be a constraint hierarchy cor-responding with sub-base space (\u0394, \u2265) and \u03a9 be a derivation state space. A DS-argument from \u03a9 is an element (\u03b4, \u03c0, \u03c3) of \u03a9 that satisfies following conditions.\n1. \u03c3 \u2260 \u22a5, that is \u03b4 needs to be consistent with \u03c0.\n2. There is no (\u03b4', \u03c0, \u03c3') \u2208 \u03a9 (\u03c0 is fixed) such that \u03b4' > \u03b4 and \u03c3' \u2260 \u22a5. In other words, \u03b4 is a maximal sub-base of consistent with \u03c0, or formally speaking, \u03b4 \u2208 max\u2265(\u0394\u03c0).\nFor a DS-argument (\u03b4, \u03c0, \u03c3), we call \u03b4 a corresponding sub-base, we call \u03c0 a situational knowledge, and we call \u03c3 a derivation state.\nInspiring from abstract argumentation for case-based reasoning (AA-CBR) [4], this paper proposes a derivation state argumentation framework (DSA-framework) based on derivation states and incremental knowledge of the situation as follows.\nDefinition 5 (DSA-framework). Let H be a constraint hierarchy corresponding with sub-base space (\u0394, \u2265), \u03a0 be a situation, and \u03c8 be a consequence with \u03a9 as a derivation state space of \u03c8 with respect to H and \u03a0. A DSA-framework with respect to H, \u03a0, and \u03c8 is (AR, attacks) satisfying the following conditions."}, {"title": "4 Explaining Preemption", "content": "In this section, we focus on explaining preemption with DSA-framework. Since DSA-framework is a specific type of abstract argumentation framework, we provide explanations using dispute trees in the same manner of other abstract argumentation based systems [4, 8, 9]. Referring to the original abstract argumentation framework [7], we use a term AA-framework, denoted by a pair (A, R) where A is a set whose elements are called arguments and R \u2286 A \u00d7 A. For x, y \u2208 A, we say x attacks y if (x, y) \u2208 R. We follow the definitions of dispute trees in AA-CBR [4] as follows.\nDefinition 7 (dispute tree). Let (A, R) be an AA-framework. A dispute tree for an argument xo \u2208 A, is a (possibly infinite) tree T with the following conditions.\n1. Every node of T is of the form [L : x], with L \u2208 {P, O} and x \u2208 A where L indicates the status of proponent (P) or opponent (O).\n2. The root of T is [P : xo].\n3. For every proponent node [P : y] in T and for every x \u2208 A such that x attacks y, there exists [O : x] as a child of [P : y].\n4. For every opponent node [O : y] in T, there exists at most one child of [P : x] such that x attacks y.\n5. there are no other nodes in T except those given by 1-4.\nA dispute tree T is an admissible dispute tree if and only if (a) every opponent node [O : x] in T has a child, and (b) no [P : x] and [O : y] in T such that x = y. A dispute tree T is a maximal dispute tree if and only if for all opponent nodes [O : x] which are leaves in T there is no argument y \u2208 A such that y attacks x.\nAs DSA-framework is an abstract argumentation based system, similar to AA-CBR [4], we adapt the definitions from AA-CBR to provide novel explanations for why a consequence is obligatory or forbidden as follows.\nDefinition 8 (explanation). Explanations for why a consequence \u03c8 is obligatory by a constraint hierarchy H with a situation \u03a0 are:\n\u2022 any admissible dispute tree for every argument (\u03b4, {}, +) and for every argument (\u03b4', \u03c0, +) that attacks (\u03b4'', {}, n), and\n\u2022 any maximal dispute tree for every argument (\u03b4, {}, \u2212) and for every argument (\u03b4', \u03c0, \u2212) that attacks (\u03b4'', {}, n).\nExplanations for why a consequence \u03c8 is forbidden by a constraint hierarchy H with a situation \u03a0 are\n\u2022 any admissible dispute tree for every argument (\u03b4, {}, \u2212) and for every argument (\u03b4', \u03c0, \u2212) that attacks (\u03b4'', {}, n), and\n\u2022 any maximal dispute tree for every argument (\u03b4, {}, +) and for every argument (\u03b4', \u03c0, +) that attacks (\u03b4'', {}, n).\nProposition 4. If a consequence \u03c8 is locally optimally obligatory by a constraint hierarchy H with a situation \u03a0, an extension E of DSA-framework (AR, attacks) with respect to H, \u03a0, and \u03c8 has the following properties.\n1. For every (\u03b4, {}, +) \u2208 AR, (\u03b4, {}, +) \u2208 E.\n2. For every (\u03b4, {}, \u2212) \u2208 AR, (\u03b4, {}, \u2212) \u2209 E."}, {"title": "5 Discussion and Future Work", "content": "In section 3, we present an algorithm to find DS-arguments within the derivation state space. However, finding DS-arguments does not require exploring the entire space. Instead, we only need to find maximal sub-bases that are consistent with the current situational knowledge. The problem of finding such sub-bases is known as Partial MAX-SAT (PMSAT) [3]. PMSAT is a generalization of MAX-SAT problem [18] and decision versions of both problems are NP-complete [11]. Several PMSAT solvers have been developed to address this computational challenge [10, 11]. Following recent re-search [16] that explored norms as general constraint hierarchies, the problem in that setting would be more challenging. This is because general constraint hierarchies consider error functions that returns progressively larger values as satisfaction decreases [2]. This allows degrees of satisfaction rather than true or false, making the formalization of sub-bases more difficult than ours. This highlights extending DSA-framework to handle general constraint hierarchies, along with other representations of norms, as one interesting future work.\nIn section 4, we prove that if one consequence is locally optimally obligatory or forbidden, there is always an explanation for why it is. Unfortunately, the converse is not true. That is, if there is an explanation for why one consequence is obligatory or forbidden, it does not guarantee that the consequence is actually obligatory or forbidden. This behavior can arise due to conflicts between norms. Example 2 demonstrates one type of conflict where two norms within the same level have opposing enforcements on the same consequence.\nExample 2. Considering the constraint hierarchy H = \u27e8{p \u2192 \u00acr, q \u2192 r}\u27e9 and the situation \u03a0 = {p, q}.\nThere are four sub-bases of H: (a) \u03b40 = \u27e8{p \u2192 \u00acr, q \u2192 r}\u27e9 = H (b) \u03b41 = \u27e8{p \u2192 \u00acr}\u27e9 (c) \u03b42 = \u27e8{q \u2192 r}\u27e9 (d) \u03b43 = \u27e8{}\u27e9 and under the local preference: \u03b40 > \u03b41 > \u03b43 and \u03b40 > \u03b42 > \u03b43. We have that \u0394\u03a0 = {\u03b41, \u03b42, \u03b43} because \u03b40 is not consistent with \u03a0. We also have that r is neither obligatory nor forbidden because \u03b41, \u03b42 \u2208 max\u2265(\u0394\u03a0), \u03b42 \u222a \u03a0 \u22a2 \u00acr and \u03b43 \u222a \u03a0 \u22ac r. the DSA-framework with respect to H, the situation \u03a0 = {p, q}, and a consequence r can be illustrated in Figure 4.\nWhile this paper demonstrates the ability to explain why a consequence is obligatory, explaining why it is not obligatory remains a challenge. This is because non-obligatory consequences can arise from either intentional permissions within the norms themselves or conflicts between norms. This highlights leveraging DSA-framework to automatically detect norm conflicts and explain non-obligatory consequences as another interesting future work."}, {"title": "6 Conclusion", "content": "This paper proposes the derivation state argumentation framework (DSA-framework) for explaining preemption in soft-constraint based norms represented as logical constraint hierarchies. The framework utilizes arguments that incorporate derivation states and the evolving knowledge of a situation. Under the local optimality, this approach guarantees explanations for why certain consequences are obligatory or forbidden, based on the properties of arguments within the DSA-framework and its extensions. Future research directions include leveraging DSA-framework to explain non-obligatory consequences, automatically detect norm conflicts, and extend its applicability to handle general constraint hierarchies and other normative representations."}]}