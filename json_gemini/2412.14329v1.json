{"title": "Embedding Cultural Diversity in Prototype-based Recommender Systems", "authors": ["Armin Moradi", "Nicola Neophytou", "Florian Carichon", "Golnoosh Farnadi"], "abstract": "Popularity bias in recommender systems can increase cultural overrepresentation by favoring norms from dominant cultures and marginalizing underrepresented groups. This issue is critical for platforms offering cultural products, as they influence consumption patterns and human perceptions. In this work, we address popularity bias by identifying demographic biases within prototype-based matrix factorization methods. Using the country of origin as a proxy for cultural identity, we link this demographic attribute to popularity bias by refining the embedding space learning process. First, we propose filtering out irrelevant prototypes to improve representativity. Second, we introduce a regularization technique to enforce a uniform distribution of prototypes within the embedding space. Across four datasets, our results demonstrate a 27% reduction in the average rank of long-tail items and a 2% reduction in the average rank of items from underrepresented countries. Additionally, our model achieves a 2% improvement in HitRatio@10 compared to the state-of-the-art, highlighting that fairness is enhanced without compromising recommendation quality. Moreover, the distribution of prototypes leads to more inclusive explanations by better aligning items with diverse prototypes.", "sections": [{"title": "1 Introduction", "content": "Culture represents the shared beliefs, values, norms, and practices of particular societies or groups (Spencer-Oatey and Franklin, 2012). In today's digital world, recommender systems of platforms such as Netflix, Amazon, Steam, and Spotify have become the primary, and sometimes the only, means of accessing, discovering, and consuming cultural content and products (Ferraro et al., 2022). These systems play a significant role in shaping cultural consumption patterns, influencing the selective retention and transmission of cultural artifacts (Brinkmann et al., 2023). However, a major issue arises when these systems are biased-particularly toward popular products leading to popularity bias"}, {"title": "2 Related Work", "content": "Culture plays an important role in shaping user preferences and interactions in recommender systems (RecSys). Several studies have explored how the cultural distance between users and items influences satisfaction, and they emphasize the need to integrate cultural factors into RecSys design (Moreau and Peltier, 2004). Existing work has incorporated users' cultural backgrounds into collaborative filtering models by embedding demographic features into profiles and interactions (Zangerle et al., 2018). Hong and Jung (2021) expanded this by embedding cultural factors directly into user profiles, while Hong et al. (2024) grouped users based on shared cultural backgrounds to improve recommendation accuracy. However, these works mainly focused on improving recommendation utility rather than addressing biases, particularly when algorithms favor dominant cultures (Brinkmann et al., 2023). Ferraro et al. (2022) highlighted this issue by introducing a measure of cultural diversity in collaborative filtering systems, aligning with Lesota et al. (2022)'s findings related to music RecSys. Building on these insights, our work explores mitigating popularity bias in RecSys to guarantee a better representation of underrepresented cultural groups, shifting the focus from utility alone to fairness and diversity in recommendations.\nFairness in RecSys presents a multifaceted challenge, especially when popularity and demographic biases are involved (Sonboli et al., 2022). These biases can result in representational harms, such as reinforcing stereotypes, and allocational harms, where opportunities for certain groups or products are limited (Barocas et al., 2023). Popularity bias, in particular, often skews recommendations toward dominant subgrouups, leading to the underrepresentation and marginalization of less popular ones Lesota et al. (2021). This can be investigated from both the users and the item providers' perspectives (Sonboli et al. (2021)). Our work specifically focuses on the item dimension for two reasons: first, by targeting items' country of origin, we can directly mitigate allocational harms affecting underrepresented cultures; second, current datasets often contain sensitive information on items rather than users, allowing us to identify and challenge strong biases. By mitigating popularity bias through this lens, we aim to improve the representation of underrepresented cultural products, promoting fairness across a broader cultural spectrum.\nSeveral fairness strategies have been proposed to address popularity and demographic biases, generally categorized into pre-processing, in-processing, and post-processing methods (Deldjoo et al., 2024). For instance, Rhee et al. (2022) use an in-processing method that mitigates popularity bias by adding a regular-izer to minimize score differences, while Wei et al. (2021) employ a counterfactual method to reduce popularity bias. Zheng et al. (2021) address the same issue by assigning separate embeddings for user interest and conformity. Also, Beutel et al. (2019) add a regularizer to prevent favoring of one group over another by penalizing prediction discrepancies between groups. In our work, we also propose an in-processing mitigation method. However, we distinguish ourselves by modifying the learning process that changes the structure of the embedding space without conflicting with the model's downstream task."}, {"title": "3 Prototype-based Matrix Factorization", "content": "Prototype-based Matrix Factorization (ProtoMF) extends traditional matrix factorization by introducing prototypes to redefine the embedding process for both users and items. Specifically, we define two sets of prototype vectors:\nUser prototypes: $P^{u} = \\{p_{1}^{u}, p_{2}^{u},..., p_{L_{u}}^{u}\\} \\subset \\mathbb{R}^{d}$, forming a matrix $P^{u} \\in \\mathbb{R}^{L_{u}\\times d}$.\nItem prototypes: $P^{i} = \\{p_{1}^{i}, p_{2}^{i}, ..., p_{L_{i}}^{i}\\} \\subset \\mathbb{R}^{d}$, forming a matrix $P^{i} \\in \\mathbb{R}^{L_{i}\\times d}$.\nHere, $L_u$ and $L_i$ are the numbers of prototypes for users and items, respectively, and $d$ is the dimensionality of the latent space. These prototype vectors serve as anchor points to create more interpretable embeddings (Melchiorre et al., 2022). The embeddings of users and items are transformed using these prototypes. For user and item embeddings $u, i \\in \\mathbb{R}^d$, the transformed embedding $u^* \\in \\mathbb{R}^{L_u}, i^* \\in \\mathbb{R}^{L_i}$ is computed as:\n$u^{*} = [sim(u,p_{1}),..., sim(u,p_{L_{u}})], i^{*} = [sim(i, p_{1}),..., sim(i,p_{L_{i}})].$ (1)\nwhere $sim(\\cdot,\\cdot)$ denotes the shifted cosine similarity.\nThis process yields transformed user and item matrices $U^* \\in \\mathbb{R}^{N\\times L_u}$ and $I^* \\in \\mathbb{R}^{M\\times L_i}$, where $N$ and $M$ are the numbers of users and items, respectively. The affinity score between a user and an item is calculated as:\n$Aff(u, i) = u^{*} i + \\hat{u}\\hat{i}^{*},$ (2)\nwhere $\\hat{u} = W_{u}u \\in \\mathbb{R}^{L_i}$ and $\\hat{i} = W_{i}i \\in \\mathbb{R}^{L_u}$ are linear transformations mapping the embeddings to the opposite prototype spaces.\nThe recommendation loss for users ($L_{U-rec}$) and items ($L_{I-rec}$) is defined using implicit feedback as in Rendle (2021), by applying the softmax function over the affinity scores across all possible items (for users) and all possible users (for items).\nIn addition to the recommendation loss, two collaborative regularization terms are introduced for both the user and item sides. On the user side, the"}, {"title": "4 Methodology", "content": "The following subsections detail the two enhancements and their integration into the ProtoMF framework.\n\n4.1 Prototype K-filtering\n\nIn the standard ProtoMF model, all prototypes contribute to computing the transformed user and item representations $u^*$ and $i^*$. This means that even distant prototypes can influence these representations, potentially biasing the model toward popular items and users. To address this issue, we introduce Prototype K-filtering, which retains only the $k$ nearest prototypes for each user and item, setting the similarities to the remaining prototypes to zero.\nFormally, for a user $u$ and item $i$, we select the $k_u \\ll L_u$ and $k_i \\ll L_i$ indices of the nearest prototypes:\n$P_{u}^{*} = \\underset{P_{u}\\subset[L_{u}]:|P_{u}|=k_{u}}{arg max} \\sum_{p\\in P_{u}} sim(u,p), \\qquad$ (6)\n$P_{i}^{*} = \\underset{P_{i}\\subset[L_{i}]:|P_{i}|=k_{i}}{arg max} \\sum_{p\\in P_{i}} sim(i,p).$ (7)\nThe filtered transformed representations are computed as: $u^{*,k} = u^{*} \\odot 1_{Pu^{*}}$ for users and $i^{*,k} = i^{*} \\odot 1_{Pi^{*}}$ for items, where $\\odot$ denotes element-wise multiplication, and $1_{Pu^{*}}$ and $1_{Pi^{*}}$ are indicator vectors with ones at positions corresponding to the selected prototypes and zeros elsewhere."}, {"title": "4.2 Prototype-Distributing Regularizer", "content": "Another concern is that prototypes may cluster in specific regions of the embedding space, causing underrepresented users or items to be associated with distant prototypes. To mitigate this, we introduce a regularization term that encourages prototypes to be uniformly distributed across the embedding space. The modified loss function becomes:\n$L = L_{total} + \\lambda_{u} \\cdot ||P_{U}P_{U}^{T} - I||_{F} + \\lambda_{i} \\cdot ||P_{I}P_{I}^{T} - I||_{F},$ (8)\nwhere $L_{total}$ is the original ProtoMF loss, $P_{U} \\in \\mathbb{R}^{L_{u}\\times d}$ and $P_{I} \\in \\mathbb{R}^{L_{i}\\times d}$ are matrices of normalized user and item prototypes (each row vector normalized to unit length), $I$ is the identity matrix, $|| \\cdot ||_{F}$ denotes the Frobenius norm, $\\lambda_{u}$ and $\\lambda_{i}$ are hyperparameters controlling the strength of the regularization.\nThis regularizer encourages the prototypes to be approximately orthogonal, promoting a uniform distribution that better covers the embedding space. By preventing prototypes from clustering, we ensure a more diverse representation of user preferences and item characteristics, reducing bias toward dominant groups. In our experimental results, models using the distributing regularizer are denoted as {User}{$\\lambda$} when the regularizer is applied only to the user side, {Item}{$\\lambda$} when applied only to the item side.\nWhen both k-filtering and the distributing regularizer are applied to both sides, we denote the model as {User-Item}{$k,\\lambda$}."}, {"title": "5 Evaluation Setup", "content": "5.1 Datasets\nWe conduct our experiments using four datasets:\nLastFM-2b (Melchiorre et al., 2021): A subset augmented with artists' countries of origin by matching artist names with the MusicBrainz database.\nMovieLens-1M (Harper and Konstan, 2015): Users' movie ratings, enriched with movies' countries of origin retrieved via The Movie Database API.\nAmazon Reviews'23 (Hou et al., 2024): We use two categories Musical Instruments, Beauty and Personal Care, filtered to include items' countries of origin. These categories are selected because cultural factors, such as differing beauty standards between Asian and European countries (Frederick et al., 2015), can influence user decisions."}, {"title": "5.2 Baselines", "content": "To evaluate our model's performance, we select four baselines: Matrix Factorization (MF) (Koren et al., 2009), anchor-based collaborative filtering (ACF) (Barkan et al., 2021), ProtoMF (Melchiorre et al., 2022). Additionally, we include a benchmark for popularity bias mitigation, ZeroSum (Rhee et al., 2022), by adding the score difference regularizer to the loss function of user and item side of ProtoMF. This allows for a fair comparison of its effectiveness with our approach.\nHyperparameter tuning is performed using the Ray library (Moritz et al., 2018) across 50 different seeds. For ProtoMF-based models, we first optimize the vanilla ProtoMF configuration. Fixing these hyperparameters, we then separately optimize our additional parameters to reduce the hyperparameter search space and ensure computational feasibility."}, {"title": "5.3 Metrics", "content": "Performance Metrics: We employ two standard accuracy metrics of Hit Ratio (HR@10) and Normalized Discounted Cumulative Gain (NDCG@10) to assess the performance of the models as He et al. (2017); Melchiorre et al. (2022) have previously done."}, {"title": "6 Results", "content": "Our findings, illustrated in Figures 1a and 1b, demonstrate that our model surpasses MF and ACF in terms of performance metrics and achieves competitive results compared to ProtoMF and ZeroSum. Specifically, on the LastFM dataset, our model attains a HitRatio@10 of 0.600, marking a 3% improvement over ProtoMF's score of 0.581.\nCrucially, this performance enhancement is accompanied by significant improvements in fairness metrics. By applying our regularization techniques to"}, {"title": "7 Discussion", "content": "Item Side: Synergy of k-Filtering and Prototype Distribution: Applying item k-filtering yielded significant improvements in ranking underrepresented items. By representing points with fewer but more relevant local neighbors, k-filtering enhances the representation of items, ensuring that prototypes better reflect the true data distribution. This technique improves the model's ability to accurately rank items from less represented countries without adversely affecting and sometimes even improving\u2014the ranking of overrepresented items.\nConversely, incorporating item-level regularization Item, proved most effective for promoting long-tail items. The regularizer forces prototypes to spread"}, {"title": "8 Conclusion & Future Directions", "content": "We introduced enhancements to Prototype-based Matrix Factorization to mitigate demographic biases in RecSys, focusing on cultural overrepresentation. By implementing Prototype K-filtering and a Prototype-Distributing Regularizer, our model improves the representation of underrepresented items without compromising recommendation quality. Experimental results show that our approach achieves higher performance than baseline models and significantly reduces the average ranking of long-tail and underrepresented items. This promotes fairness and inclusiveness in recommendations and explanations, contributing to a more equitable user experience.\nHowever, our study has several limitations. First, the theoretical justification for the effectiveness of k-filtering and the regularization techniques is not thoroughly established; more rigorous analysis is needed to fully understand their impact on performance and fairness. Second, while we observed enhancements in explainability, we did not conduct a systematic analysis of this aspect. Additionally, the significant reduction of data due to filtering for country information may affect the generalizability of our findings. Finally, by simplifying culture to country of origin, we overlook its complex and multifaceted nature that extends beyond national boundaries; culture is influenced by factors such as ethnicity, language, and religion. This oversimplification may limit the effectiveness of our bias mitigation strategies and fail to capture the diversity within and across countries."}, {"title": "A Detailed Results", "content": ""}]}