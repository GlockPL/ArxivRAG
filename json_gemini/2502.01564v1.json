{"title": "MeetMap: Real-Time Collaborative Dialogue Mapping with LLMs in Online Meetings", "authors": ["Xinyue Chen", "Nathan Yap", "Xinyi Lu", "Aylin Gunal", "Xu Wang"], "abstract": "MeetMap allows users to create dialogue maps collaboratively in real-time during online meetings with LLM support. Video meeting platforms display conversations linearly through transcripts or summaries. We leverage LLMs to create dialogue maps in real time to help people visually structure and connect ideas. Balancing the need to reduce the cognitive load on users during the conversation while giving them sufficient control when using AI, we explore two system variants that encompass different levels of AI assistance. In Human-Map, AI generates summaries of conversations as nodes, and users create dialogue maps with the nodes. In AI-Map, AI produces dialogue maps where users can make edits. Users preferred MeetMap over traditional methods for taking notes, which aligned better with their mental models of conversations.", "sections": [{"title": "1 Introduction", "content": "Keeping up with and making sense of the information exchanged in online meetings is crucial yet challenging. Turn exchanges happen in rapid succession and progress chronologically, which does not align with the nonlinear way that ideas develop during conversations and how people process and organize information in their minds. The lack of parallel communication channels and body language cues, and the temptation to multitask further the challenge in online video meetings. To address these challenges, recent work has provided real-time support for meeting attendees to understand meeting content. This includes providing enrichment materials in the context, such as images and participation polls. Although these mechanisms can enhance active engagement, they do not help participants fully comprehend conversations in real-time or foster a shared understanding among team members. Some systems have aimed to bridge this gap; for example, TalkTraces maps discussion content to the meeting agenda in real-time, and MeetScript provides real-time transcripts that participants can collaboratively annotate to make sense of meeting content. Studies have shown that when providing real-time cognitive assistance to meeting participants, it can place a higher cognitive burden on people because they need to consume additional information simultaneously, for example, transcripts and visualizations. Additionally, commercial tools have introduced real-time summaries powered by LLMs. Studies reveal that these AI-generated summaries can be too abstract and difficult to interpret, failing to capture the complexity of discussions, particularly the interplay of linear and nonlinear information that is critical during the discussion process. Dialogue mapping offers a promising solution by visually representing discussions with real-time summaries using a schema. To practice dialogue mapping in meetings, it requires a designated facilitator who creates and updates the 'dialogue map' of the conversation in real-time by capturing the conversation into \u2018questions', \u2018ideas', 'pros', and 'cons', and linking them into a coherent map; meeting attendees can then communicate with the facilitator to modify the dialogue maps. In contrast to existing methods that visualize information linearly, such as real-time transcripts and summaries, the facilitator creates the dialogue maps as the conversation goes, offering a structured visual format that encapsulates the intricate"}, {"title": "2 Related Work", "content": "People continue to face challenges in keeping track of and actively making sense of discussions in real-time. Dialogue mapping has been shown to be a successful meeting facilitation technique. This work aims to integrate collaborative dialogue mapping capabilities in video meetings to enhance people's real-time understanding of the conversation. To facilitate the dialogue mapping process, we provide people with AI assistance. We also build upon prior work on AI-mediated communication to ensure that AI provides users the right amount of assistance."}, {"title": "3 MeetMap: Generating Dialogue Maps as Real-Time Cognitive Scaffolds for Online Meetings", "content": "We propose MeetMap, an AI-assisted collaborative dialogue mapping system for meeting participants to make sense of the group conversation in real-time during the meetings. Below, we list the design goals derived from the prior work and solutions we employed."}, {"title": "3.1 Design Goals", "content": "Existing dialogue mapping techniques have been found to enhance real-time understanding by employing a notation schema and visual structure. However, a significant limitation of current dialogue mapping techniques is the need for designated facilitators, which might take away the beneficial cognitive processes when people engage in such activities actively. Prior work on collaborative sense-making highlights the importance of active engagement through creating external representations collaboratively rather than passively receiving information. Inspired by these insights, MeetMap provides a shared space where meeting participants can collaboratively create and edit the dialogue maps as the conversation unfolds."}, {"title": "3.2 Iterative Design and Development", "content": "The goal of MeetMap's design is to develop an AI-assisted collaborative dialogue mapping system that aids meeting participants in understanding conversations in real-time. The design and development of MeetMap followed an iterative, user-centered approach, refined through several pilot tests and feedback cycles to optimize usability, cognitive load management, and real-time collaborative mapping with AI assistance. This section provides a detailed explanation of these iterations and the insights gained at each stage."}, {"title": "3.3 System Design", "content": "We reported the final system design of MeetMap. MeetMap's front-end interface has three components: 1) A VIDEO PANEL for users to have online meetings; 2) A TASK PANEL to upload meeting agendas; 3) A MAP CREATION PANEL which contains a TEMPORARY NODE Palette and MAP CANVAS, which enable users to create a shared representation of meeting content in real-time."}, {"title": "3.3.1 Map creation panel", "content": "MeetMap offers a MAP CREATION PANEL that allows users to collaboratively and flexibly construct dialogue maps during online meetings with ease while also being designed to prevent overwhelming users with the additional content supplied by AI. MeetMap provided a suite of map interaction features to enable users to create dialogue maps collaboratively. As supported by other collaborative concept map authoring tools, e.g., Miro Board, users can collaboratively create, edit, and delete"}, {"title": "3.3.2 Visualizing information with different detail levels", "content": "MeetMap visualizes conversation information with different granularity to help people easily make sense of the AI-generated content when creating dialogue maps, as illustrated in Figure 4. MeetMap summarizes the conversation into summary nodes in TEMPORARY NODE PALETTE. To help people quickly gain an overview of the conversation, MeetMap visualizes the turn-taking and collaborative dynamics through TOPIC TIMELINE PANEL, with speakers represented in different colors. To further meet the needs of connecting chronological information with the visual representation of conversation, we support users to map information from the TOPIC TIMELINE Panel to the MAP CANVAS. Users can click on a topic block on the timeline to view the highlighted corresponding nodes on the"}, {"title": "3.4 Two Variants of MeetMap: Human-Map and Al-Map", "content": "Informed by both the prior literature on user agency in human-AI interaction and AI-mediated communication and the pilot study with the early system design, we designed two variants of MeetMap with different levels of user involvement and AI assistance In Human-Map, users see AI-generated nodes and will create dialogue maps themselves. In AI-Map users see AI-generated small dialogue maps automatically, and users can refine them."}, {"title": "3.4.1 Human-Map", "content": "Al generates only summary nodes, and humans create the links. Human-Map enables users to create a conversation map that meets their needs. AI will only generate nodes with the dialogue mapping notation schema and present those nodes on the TEMPORARY NODE Palette. Users create links with AI-generated nodes to build a conversational map by themselves."}, {"title": "3.4.2 Al-Map", "content": "Al generates the small dialogue maps based on conversation chunks. In AI-Map, the AI will first generate the nodes and then generate small dialogue maps after identifying a topic chunk. Users can freely edit the AI-generated map in any way they want. Given that the synchronicity of the AI-generated content is critical to users, in AI-Map, we first display the AI-generated nodes in the TEMPORARY NODE PALETTE in real-time. At the same time, the system works on creating the dialogue maps in the backend. The workflow of"}, {"title": "3.5 Implementation", "content": "For the front-end of the MeetMap, Zoom Web SDK was used to support videoconferencing. We used Django Channels and Django-Redis to handle the real-time updates in MeetMap. We used the Microsoft Azure SpeechSDK to provide transcription. MeetMap collects user audio from the client-side browser and then sends the transcription result to the database. Once turn-taking happens, MeetMap calls the GPT4 API to generate nodes as well as identify the topic in both MeetMap variants. Once a new topic is identified, the GPT4 API will be called again to generate links in the AI-Map condition."}, {"title": "4 Evaluation Study", "content": "To understand how MeetMap supports people keeping up with and making sense of the conversation, we performed an IRB-approved evaluation study with three system setups, including the two MeetMap variants and a business-as-usual baseline setup. We aim to answer the following research questions:"}, {"title": "4.1 Study procedure", "content": null}, {"title": "4.1.1 Participant Recruitment", "content": "We recruited 20 participants from the University of Michigan mailing lists and divided them into 10 groups, with 2 participants in each session. The participants' demographic information is shown in the Appendix D. The selection of dyadic meetings can help assess how the scaffold in MeetMap can help people in meetings that require rapid information exchange and high cognitive demands. All participants were considered to have no hearing or reading difficulties. Each study session lasted about 150 minutes, and participants were compensated with an hourly rate of $15."}, {"title": "4.1.2 Discussion Tasks", "content": "To encourage information exchange and collaboration, we used the jigsaw method to design discussion tasks. Each participant is presented with a unique point of view, and they have to discuss with each other to reach a consensus on their decisions. To avoid additional difficulty in understanding the topic, we designed 3 tasks related to school life, including reevaluating attendance checking in university classes, installing smart devices for university buildings, and enhancing mental health services on campus. We designed 2 discussion agendas for each task to make the discussion concrete and encourage participation. The order of the tasks was counterbalanced for each condition."}, {"title": "4.1.3 baseline Condition", "content": "We designed a baseline condition that resembled business-as-usual meeting scenarios. We connected Zoom with Otter.ai , a popular Zoom add-on to provide real-time transcripts and automatic summaries for meetings. The transcripts are sent for a summary generation and presented in the summary panel in Otter.ai . AI presented the summaries as"}, {"title": "4.1.4 Experimental procedure", "content": "In each task, the participants discussed each agenda for 7 minutes, followed by a 3-minute break for a recap. They are encouraged to take notes or interact with the map during the discussion. The breaks are introduced since previous studies suggested breaks can help people quickly reflect on the conversation and take time to organize their thoughts. After each task, the participants answered a 5-Likert scale survey about the usability and usefulness of the system. After each task, participants are also asked to complete the NASA-TLX test, responding to six questions on an unlabeled 21-point scale. Follow-up questions were asked after the survey about their experiences through a 10-minute semi-structured interview after each task."}, {"title": "4.2 Data Analysis Methods", "content": null}, {"title": "4.2.1 Log data analysis", "content": "We analyzed the note-creation and note-checking behaviors between the two MeetMap and the baseline conditions."}, {"title": "4.2.2 Survey data analysis", "content": "The survey data was evaluated using the Friedman test because the data did not meet normality assumptions. For each question, we established a null hypothesis that"}, {"title": "4.2.3 Interview analysis", "content": "The interviews were transcribed, and two researchers used the Affinity Diagram to analyze the data. In the analysis, two researchers rearranged all quotes iteratively based on emerging affinity to one another through communication and critique. We grouped users' feedback, including how they create notes/dialogue maps with the help of AI both in-situ and post-meeting, why or why not the scaffold of MeetMap is helpful, their preferences, and concerns about incorporating AI in synchronous meetings."}, {"title": "4.2.4 Video data analysis", "content": "We qualitatively analyzed the video recordings to observe participants' collaboration behavior and their interactions with the system. The video analysis was used to understand the nuances of interactions and behavior patterns that might not be captured through log data or self-reported measures. Two researchers independently watched the video recordings and wrote memos about how people took notes during the discussion and the break, how they collaborated with each other, and how they used and edited the AI-generated content. After that, they came together to discuss the memo and used it to complement and explain some findings from log analysis and interview analysis."}, {"title": "5 Findings", "content": "The comparison between the two MeetMap variants with the baseline demonstrates the usability and usefulness of MeetMap in helping people keep track of and understand conversations in real-time (RQ1). The participants appreciated the flexibility of MeetMap in allowing them to structure the conversation visually. The comparison between Human-Map and AI-Map showed that users in Human-Map were more motivated and perceived a higher level of control and agency to create and actively modify the dialogue maps (RQ2). Furthermore, users reported a lower tolerance for AI errors when they felt they put more effort into creating the map."}, {"title": "5.1 How Al-assisted Collaborative Dialogue Mapping Influence Meeting Experiences in Comparison to Business-as-usual Meeting Setups", "content": "We first present results on how MeetMap (Human-Map and AI-Map) helps people make sense of the discussion compared to the baseline condition."}, {"title": "5.1.1 MeetMap helps individuals keep up with and make sense of the meeting in real-time", "content": "Users reported that both MeetMap variants helped them keep up with the discussion content better than the baseline. Users thought the dialogue map reflected their decision-making process more accurately in both Human-Map and AI-Map conditions compared to the shared notes in the baseline condition. Additionally, users considered the AI-generated summary nodes and dialogue maps to be accurate representations of the conversation in both Human-Map and AI-Map, in comparison to the AI-generated summaries in the baseline. Qualitative insights revealed that the perceptions were due to the way MeetMap represents linear conversations in a structured, visual, and intuitive manner. All users agreed that the visual representation and notation schema facilitated a quick grasp of the content. Additionally, the right amount of extra information was crucial for"}, {"title": "5.1.2 MeetMap fosters team consensus building and facilitates subsequent discussion", "content": "Users rated Human-Map and AI-Map significantly higher in supporting teams to achieve consensus compared with the baseline"}, {"title": "5.1.3 MeetMap users have more bandwidth to create and read their shared notes during the conversation", "content": "We found that Human-Map users had significantly more note-creation behaviors than AI-Map, who also had more note-creation behaviors than the baseline. Besides, users had significantly more interactions to navigate and check the note content in AI-Map than that in the baseline. Creating more notes during the conversation may possibly incur a higher cognitive load on the users. However, based on our NASA-TLX survey, participants did not report a higher task load when comparing two MeetMap conditions and the baseline . Despite the similar level of cognitive load as reported, users interacted more with the map and created more collaborative notes in the two MeetMap conditions. This increased interaction likely enhanced users' real-time understanding of the conversation."}, {"title": "5.1.4 The pair of participants have more balanced contributions to the dialogue maps in MeetMap than Zoom", "content": "We analyzed how each member in the pair interacted with the maps and notes in all conditions. As shown in Figure 12, in the two MeetMap conditions, both participants in each group"}, {"title": "5.2 How the Different Levels of Al Assistance Influenced Users' Interaction Behaviors and Attitudes Towards Creating Dialogue Maps During Meetings", "content": "In this section, we will examine user experiences in two variants of MeetMap. We aim to understand how much AI assistance is desirable and useful for people working together to create dialogue maps during discussions."}, {"title": "5.2.1 Human-Map provided more agency and control for users to dialogue map in real-time", "content": "In Human-Map, most users reported having more agency and control to use the AI-generated nodes. In contrast, in AI-Map , users preferred to simply read the AI-created maps during the discussion, leaving potential post-editing until after the discussion."}, {"title": "5.2.2 Users in Human-Map and Al-Map made sense of the dialogue maps differently", "content": "Users shared that they needed to put in more cognitive effort in Human-Map to review the content in each node and think about how to organize them than they did in AI-Map, as P16 said, \u201cI"}, {"title": "5.2.3 Users shared that they had a better understanding of the conversations when they co-created the dialogue maps in Human-Map", "content": "Many users reported that they preferred intensive cognitive engagement in creating dialogue maps in Human-Map , despite it requiring more effort. These users believed that organizing the information by themselves was helpful for making sense of the content and led to better decision-making, even though the process could be cognitively demanding."}, {"title": "5.2.4 Users had a lower tolerance for Al mistakes when they considered themselves to own the human-Al collaborative output", "content": "Users shared that their involvement in creating the dialogue maps in Human-Map made them more critical of AI outputs. To create dialogue maps with AI-generated nodes, users would first read and comprehend the AI-generated nodes to ensure the content was accurate before using this node in the dialogue map. In contrast, despite encountering similar inaccuracies, most users of AI-Map were more receptive to AI mistakes. Only 2 users pointed out inaccurate content on AI-generated nodes in AI-Map"}, {"title": "5.3 Challenges of using MeetMap to support collaborative sense-making during meetings", "content": "While users appreciated MeetMap for its ability to facilitate conversation and capture meeting content, several issues emerged that warrant further consideration."}, {"title": "5.3.1 Notation schema need to be adaptable", "content": "Some users found that the predefined categories of the dialogue mapping notation schema did not always suit the content of their conversations, limiting their ability to represent the discussion accurately. Participants need a system that can adapt to the unique dynamics of different conversations, with the ability to introduce custom categories or choose from a broader range of templates."}, {"title": "5.3.2 The need for control over Al granularity", "content": "Users also desired more control over the granularity of the AI-generated content. For example, some users complained about the repetition of the nodes due to either back-and-forth discussion or the imperfect performance of AI in chunking the"}, {"title": "6 Discussion", "content": "Our findings highlight how MeetMap enhances real-time collaborative sense-making during video meetings by combining structured visual representations with synchronized AI assistance, offering valuable insights for designing AI systems that balance automation and user agency. In the following discussion, we explore these insights in detail across three key areas: Design Implications for AI-assisted Real-time Sense-making, focusing on how structured visuals and staged information aid navigation and reduce cognitive load; AI-assisted Collaborative Dialogue Mapping, examining how AI-generated content promotes balanced collaboration and shared understanding; and User Agency and AI Assistance, discussing the importance of withholding AI support to preserve user control and engagement."}, {"title": "6.1 Design Implication for Al-assisted Real-time Sense-making during Video Meetings", "content": "First, using visualizations to enhance the structure of AI-generated content can reduce users' cognitive load, especially when they need to process information in real time. Second, MeetMap provides transparency into how dialogue maps are created through visualizing the summary nodes following a chronological order in the TEMPORARY Node Palette. This suggests that establishing a clear connection between multiple representations of information, e.g., chronological and semantic elements, could help users navigate and locate information more effectively. Third, delays in using AI to synthesize conversations (e.g., generating summaries and dialogue maps) can affect user experience. To address this, presenting intermediate AI outputs can enhance the system's perceived synchrony and transparency. Lastly, enhancing users' cognitive engagement is particularly beneficial for cognitively demanding tasks, such as collaborative conversations. While Human-Map offers less automation compared to AI-Map, it was praised by users for providing more opportunities to actively engage with and make sense of the content."}, {"title": "6.2 Al-assisted Collaborative Dialogue Mapping for Collaborative Sense-making and Constructive Discussion", "content": "Our study shows that AI-assisted collaborative dialogue mapping can effectively and less confrontationally address misunderstandings. Specifically, AI-generated content serves as a neutral basis for discussions, helping to reduce the personal biases often present in human-generated notes. The AI-generated nodes were also used as scaffolds to organize the subsequent discussion. Unlike previous approaches that positioned AI as an active mediator in group discussion, our findings indicate that when AI-generated content is designed and presented in a non-intrusive way, it can subtly improve people's metacognitive awareness and guide behavioral changes, for example, motivating users to actively monitor the conversation and actively edit the shared notes. Besides, creating collaborative notes with AI can facilitate a more balanced and inclusive collaborative environment. Participants were more willing to edit notes generated by AI than those created by their peers. This suggests that employing AI-generated content as the basis for collaboration can promote shared ownership and reduce the perceived intrusion of modifying peers' contributions in other collaborative note-taking scenarios. Additionally, participants still faced challenges coordinating with each other in MeetMap, including unexpected edits to each other's notes. To address these issues, more explicit mechanisms should be designed to guide collaboration."}, {"title": "6.3 User Agency and Al Assistance in Sense-making Tasks", "content": "Our study suggests that when providing AI assistance to users on cognitively demanding tasks, such as creating dialogue maps to make sense of meetings, the goal should not be to have AI take over the task and generate the final deliverable directly. While AI-generated summaries were well-received, users also valued the control and agency afforded by the Human-Map, where they engaged more deeply with the content. Consistent with previous research, our findings indicate that AI is more effective when it complements human cognitive functions rather than replacing them. Moreover, our study recommends offering customizable levels of AI assistance to accommodate different user preferences and situational needs. Last, our findings highlight the nuanced dynamics of user engagement with AI-generated content and their varying levels of trust and tolerance towards Al errors. Users who actively refined AI-generated content demanded higher accuracy and better results. Moreover, users exhibited a lower tolerance for AI mistakes when they felt a stronger sense of ownership over the collaborative output. An important implication from these observations is that errors in AI-generated content can be tolerable if users are not required to interact extensively with it. However, ensuring Al accuracy becomes paramount when significant participant involvement is needed. In such a scenario, AI must be introduced transparently so that users can easily understand the rationale behind the AI-generated content to fully assess the AI output."}, {"title": "6.4 Limitations and Future Work", "content": "(1) While two proactivity levels of AI were considered in MeetMap, the design does not consider the full spectrum of AI assistance. Future work can comprehensively evaluate the role of Al in assisting collaborative note-taking and communication, considering a wider range of AI proactivity levels.(2) We focused on evaluating the user experience in MeetMap through a user study and did not technically evaluate the accuracy of the AI-generated nodes/maps. Future iterations might develop adaptive algorithms, catering to each meeting's dynamic, to produce higher-quality dialogue maps.(3) The current study of MeetMap focused on new teams where team members did not know each other before. This resembles the experience for many in-class project discussions and ad-hoc workplace meetings. The results found in this work would apply to new and non-established teams. Additionally, we recruited the evaluation study participants from a mailing list at one university and ran the evaluation study with dyad meetings. In future studies, we hope to recruit a more diverse group of participants and examine the scalability of MeetMap in larger group settings and across different types of organizations, industries, and use cases.(4) We recognize that additional features can add unnecessary burdens. We identified the lack of adaptivity to close unnecessary panels in our system as a limitation. Future systems should allow users to minimize extra cognitive load through more adaptive design.(5) As shown in Figure 11, both note-checking and note-creation behaviors were minimal in the baseline condition, likely due to the high pace and brief nature of the discussion. In such conditions, users may decide not to take notes if they don't perceive immediate benefits. The two MeetMap variants introduced new interaction mechanisms and AI- scaffolding to encourage collaborative output. In contrast, the baseline setup with Otter.ai transcripts and Google Docs did not provide enough motivation for note-taking. A more suitable baseline might include a built-in collaborative note editor with AI-generated text summaries, which could better validate the usefulness of the design of the collaborative dialogue maps.(6) The current design uses a low-contrast color scheme, which may not be appropriate for all accessibility requirements. In the future, MeetMap will improve accessibility and visual design by rethinking the color scheme and resizing interactive buttons. These adjustments will help make the system more inclusive and user-friendly."}, {"title": "7 Conclusion", "content": "Traditional video meeting platforms present discussions linearly, either as transcripts or summaries, while conversation ideas often emerge non-linearly. We explored LLM-assisted real-time collaborative dialogue map generation, visually representing structured and interconnected ideas. To balance reducing user cognitive load and granting user control over AI-generated content, we introduced two human-AI collaboration approaches: Human-Map and AI-Map. In Human-Map, AI summarizes conversations into nodes, with users linking the nodes to shape a dialogue map. AI-Map allows the AI to create small maps first, which users can subsequently refine. We evaluate these methods through a within-subject study involving ten user pairs. Users preferred MeetMap over conventional note-taking strategies since it reflected the conversation process and aligned with how humans organize information. Users liked the ease of use for AI-Map due to the low effort demands and appreciated the hands-on opportunity in Human-Map for sense-making. This study provides insights on enhancing human-AI collaboration in note-taking and sense-making during meetings and provides design implications for involving AI in synchronous human communication activities."}]}