{"title": "Attention-based UAV Trajectory Optimization for Wireless Power Transfer-assisted IoT Systems", "authors": ["Li Dong", "Feibo Jiang", "Yubo Peng"], "abstract": "Unmanned Aerial Vehicles (UAVs) in Wireless Power Transfer (WPT)-assisted Internet of Things (IoT) systems face the following challenges: limited resources and suboptimal trajectory planning. Reinforcement learning-based trajectory planning schemes face issues of low search efficiency and learning instability when optimizing large-scale systems. To address these issues, we present an Attention-based UAV Trajectory Optimization (AUTO) framework based on the graph transformer, which consists of an Attention Trajectory Optimization Model (ATOM) and a Trajectory lEarNing Method based on Actor-critic (TENMA). In ATOM, a graph encoder is used to calculate the self-attention characteristics of all IoTDs, and a trajectory decoder is developed to optimize the number and trajectories of UAVs. TENMA then trains the ATOM using an improved Actor-Critic method, in which the real reward of the system is applied as the baseline to reduce variances in the critic network. This method is suitable for high-quality and large-scale multi-UAV trajectory planning. Finally, we develop numerous experiments, including a hardware experiment in the field case, to verify the feasibility and efficiency of the AUTO framework.", "sections": [{"title": "I. INTRODUCTION", "content": "With the advancement of 5G, the Internet of Things (IoT) has become widely used in a variety of fields, including environmental monitoring, healthcare, and industry 4.0, among others. However, due to limited transmitting power and battery capacity, Internet of Things Devices (IoTDs) perform poorly in long-distance communication. Furthermore, when IoTDs are positioned in remote places with limited wireless coverage and battery power, charging IoTDs and transferring sensory data from the IoTDs to the remote data center are challenging tasks.\nFortunately, Unmanned Aerial Vehicles (UAVs) and Wireless Power Transfer (WPT) can be integrated into these IoT systems, enabling UAVs to wirelessly transfer power to IoTDs [1]. Before collecting the sensory data of an IoTD, the UAV needs to charge the IoTD so that the IoTD has enough energy to transfer its sensory data to the UAV. Thus, UAVs are deployed in the IoT system as mobile chargers to transfer power to IoTDs and as the data collectors for sensory data collection. Compared to terrestrial data collection systems, UAVs can more efficiently cover large areas and fly close to IoTDs for data collection and energy transfer. This reduces data transmission latency, alleviates communication burdens, and enhances the efficiency of WPT [2]. Hence, mobility management plays a key role for UAVs in WPT-assisted IoT systems, and the shoddy design of UAV trajectory will lead to not only the waste of energy but also service delays. Efficient mobility management is demanded in trajectory design, especially considering a swarm of UAVs [3]\u2013[5].\nThere are many previous trajectory design algorithms have been proposed. Messaoudi et al. [6] proposed a collaborative system based on UAVs and Unmanned Ground Vehicles (UGVs) for the data collection of IoT devices. The trajectory control of UGVs and UAVs was optimized using a multi-agent Reinforcement Learning (RL) approach. Lu et al. [7] introduced a WPT system utilizing UAVs, which first wirelessly charge energy-constrained IoT devices and then enable these devices to opportunistically send collected data to the UAV. Oubbati et al. [8] proposed a multi-agent deep RL method called TEAM to optimize UAV trajectories and resource allocation while minimizing UAV energy consumption. Zhu et al. [9] introduced a machine learning algorithm based on Transformer and Weighted A*, named TWA, to address UAV trajectory optimization in UAV-aided IoT networks. Zhu et al. [10] proposed an Attention-Reinforced Learning Scheme for optimizing the trajectory of UAVs in large-scale and low-power data collection tasks.\nAlthough high mobility is an impressive feature of UAVs, the battery and data storage capacity of UAVs always limits the data collection tasks for all IoTDs in the system. Therefore, joint resource and mobility management is essential to UAV swarms for the WPT-assisted IoT system [11]\u2013[13]. In this paper, we propose a novel Attention-based UAV Trajectory Optimization (AUTO) framework, in which an Attention Trajectory Optimization Model (ATOM) is used to optimize the number and trajectories of UAVs, and a Trajectory lEarNing Method based on Actor-critic (TENMA) is applied to train the ATOM model.\nIn Table I, we compare our AUTO framework with existing works, focusing on UAV, WPT, attention mechanisms, and RL. It is evident that most of the listed works consider the system from only two or three perspectives. However, the aforementioned studies do not specifically investigate the potential of integrating the attention and RL in UAV and WPT-assisted IoT systems. Hence, unlike existing works, the contributions of the study are summarized as follows:\n1) High-precision graph encoding: In ATOM, the IoT system is mathematically expressed as a graph structure and a graph encoder is presented to extract the self-attention features of all IoTDs precisely. The novel learnable graph embedding layer and graph pooling layer are introduced to the graph encoder for enhancing self-attention features and guiding the trajectory planning.\n2) High-quality trajectory decoding: The trajectory decoder followed by the graph encoder in ATOM is utilized to generate trajectories of UAVs. We decode the self-attention features of each IoTD and the whole graph by the proposed alignment vector and context vector, and the quantity and trajectories of UAVs are optimized according to self-attention features and remaining battery and storage capacity.\n3) Efficient and stable Actor-Critic learning: The ATOM model is trained by TENMA. Specifically, a critic network is applied to evaluate the generated trajectories, and the ATOM model is introduced as the actor network to produce the trajectories. Moreover, the real reward of the system is used as the baseline to reduce the variance of the critic network and enhance the stabilization and generalization of TENMA.\nThis paper is organized as follows: Section II describes the system model and problem formulation of the WPT-assisted IoT system. Section III describes the principle of the AUTO framework in details. Section IV illustrates the experiment results. Finally, Section V concludes the whole paper."}, {"title": "II. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "As illustrated in Fig. 1, the WPT-assisted IoT system consists of N IoTDs, a data center, and m UAVs with half-duplex access points, which can transmit power to the IoTDs and collect data from IoTDs by Time Division Duplexing (TDD) mode. The N IoTDs are denoted as a set of $\\mathcal{N} = \\{1, 2, ..., N\\}$. We assumed that the position $(x_i, y_i)$ of the i-th IoTD is fixed and known, and the i-th IoTD has $D_i$ data to be collected. The set of m UAVs is denoted as $\\mathcal{M} = \\{1,2, ..., m\\}$, and each UAV has limited data storage capacity $C_{max}$ and energy capacity $E_{max}$. The flight height of the UAV is set to $H_F$. Each UAV can only collect data from one IoTD at one time, so the association $a_{ij}$ at the t-th time step can be expressed by:\n$\\begin{equation} \\label{eq:association} a_{ij}[t] = \\{0,1\\}, \\forall i \\in \\mathcal{N}, \\forall j \\in \\mathcal{M} \\end{equation}$\nwhere $a_{ij}[t] = 1$ means the j-th UAV is collecting the data from the i-th IoTD at the t-th time step, and $a_{ij}[t] = 0$ otherwise."}, {"title": "A. Trajectory Model", "content": "In the proposed system, each UAV flies straightly from one IoTD to another. The j-th UAV takes off from the data center at a fixed location $\\mathbf{r}_{j}[0] = (0,0, H_F)$, and flies to the IoTDs one by one, and hovers over each IoTD to collect data. The j-th UAV completes the data collection task according to a predetermined flight trajectory and returns to the same data center after one flying cycle. Hence, we have\n$\\begin{equation} \\label{eq:same} \\mathbf{r}_{j}[s_j] = \\mathbf{r}_{j}[0], \\forall j \\in \\mathcal{M} \\end{equation}$\nwhere $\\mathbf{r}_j[t]$ denotes the t-th hover point on the flight trajectory of the j-th UAV, $t \\in T_j = \\{1, 2, ..., s_j\\}$, and the j-th UAV serves total $s_j$ IoTDs. Hence, the j-th UAV has $s_j$ hover points. Assume that the UAV serves the i-th IoTD only once, then one has\n$\\begin{equation} \\label{eq:servenum} \\sum_{j=1}^m\\sum_{t=1}^{s_j}a_{ij}[t] = 1, \\forall i \\in \\mathcal{N}. \\end{equation}$\nSince each UAV can fly from one hover point to another point in a straight line, then the flight time of the j-th UAV can be expressed by:\n$\\begin{equation} \\label{eq:time} T_F^j = \\sum_{t=1}^{s_j} \\frac{\\|\\mathbf{r}_{j}[t] - \\mathbf{r}_{j}[t-1]\\|_2}{v}, \\forall j\\in \\mathcal{M} \\end{equation}$\nwhere $|\\mathbf{r}_{j}[t+1] - \\mathbf{r}_{j}[t]||_2$ is the Euclidean distance between hover points $\\mathbf{r}_{j}[t+1]$ and $\\mathbf{r}_{j}[t]$, and v is the flight velocity of the UAV, which is a constant value."}, {"title": "B. Data Collection Model", "content": "We assume that IoTDs can be wirelessly charged by the UAV before transmitting the data to the UAV. The whole process can be divided into the WPT stage and data transmission stage.\nIn the WPT stage, the UAV can transmit the energy wirelessly via Radio Frequency (RF) technologies with a fixed transmit power $P_T$. The power received at the i-th IoTD from the j-th UAV is denoted as $P_{ij}^{ER}$, which can be calculated by\n$\\begin{equation} \\label{eq:power} P_{ij}^{ER} = |g_{ij}|^2 P_T \\end{equation}$\nwhere $|g_{ij}|^2$ denotes the downlink power gain from the j-th UAV to the i-th IoTD.\nAssume that $\\eta$ is the constant attenuation parameter in the linear energy harvesting model. Then, the received energy of the i-th IoTD from the j-th UAV can be given by\n$\\begin{equation} \\label{eq:energy} E_{ij}^{ER} = \\eta P_{ij}^{ER} T_{ij}^{TE} \\end{equation}$\nwhere $T_{ij}^{TE}$ is the energy harvesting time of the i-th IoTD from the j-th UAV.\nIn the data transmission stage, the uploading data rate of the i-th IoTD to the j-th UAV can be given by\n$\\begin{equation} \\label{eq:bitrate} R_{ij} = B\\log_2(1+\\frac{|g_{ij}|^2 U_{ij}^{ER}}{\\sigma^2}) \\end{equation}$\nwhere $|g_{ij}|^2 = |g_{ij}|^2$ denotes the uplink power gain, B is the bandwidth, $\\sigma^2$ is Gaussian white noise power, and $T_{ij}^{TC}$ is the data collection time from i-th IoTD to the j-th UAV.\nTo ensure that IoTDs can successfully upload their data $D_i$ to the UAVs, one has\n$\\begin{equation} \\label{eq:successfull} T_{ij}^{TC} B\\log_2(1+\\frac{\\eta|g_{ij}|^4 P_T T_{ij}^{TE}}{\\sigma^2}) \\ge D_i, \\forall i \\in \\mathcal{N}, \\forall j \\in \\mathcal{M}. \\end{equation}$"}, {"title": "C. Energy Consumption Model", "content": "Assuming that the flight energy consumption of the j-th UAV is given as\n$\\begin{equation} \\label{eq:flight} E_j^F = P^F T_F^j \\end{equation}$\nwhere $P^F$ is the flight power of the UAV. We also assume that the power consumption is $P^H$ when the j-th UAV hovers above the IoTD, then one has\n$\\begin{equation} \\label{eq:transfer} E_j^H = (P^T + P^H) T_j^T \\end{equation}$\nwhere $T_j^T$ is the power transfer time of the j-th UAV. Next, when the j-th UAV hovers, the energy consumption of data collection and UAV hovering is calculated as\n$\\begin{equation} \\label{eq:collect} E_j^C = (P^C + P^H) T_j^C \\end{equation}$\nwhere $T_j^C$ is the data collection time of the j-th UAV. $P^C$ is the data collection power of the UAV. Therefore, the total energy consumption of the j-th UAV can be given as\n$\\begin{equation} \\label{eq:total} E_j = E_j^F + E_j^H + E_j^C, \\forall j \\in \\mathcal{M}. \\end{equation}$\nDue to the limited data storage capacity and energy capacity of UAVs, it is required that the total energy consumption of the UAV does not exceed its energy capacity $E_{max}$, and all collected data does not exceed the storage capacity $C_{max}$. Therefore, these inequalities need to be satisfied\n$\\begin{equation} \\label{eq:energymax} E_j \\le E_{max}, \\forall j \\in \\mathcal{M}, \\end{equation}$\n$\\begin{equation} \\label{eq:datamax} \\sum_{i=1}^{N}\\sum_{t=1}^{s_j}a_{ij}[t]D_i \\le C_{max}, \\forall j \\in \\mathcal{M}. \\end{equation}$"}, {"title": "D. Problem Formulation", "content": "We aim to minimize the energy consumption of all UAVs, by jointly optimizing the number and trajectories of UAVs, the user association, the energy harvesting time, and the data collection time. The optimization problem can be mathematically formulated by\n$\\begin{equation} \\label{eq:optimization} P0: \\min_{\\mathcal{A}, m, \\mathcal{R}, \\mathcal{T}^E, \\mathcal{T}^C} \\sum_{j=1}^m E_j \\end{equation}$\ns.t. (1), (2), (3), (8), (13), (14)\nwhere $\\mathcal{A} = \\{a_{ij}[t], \\forall i \\in \\mathcal{N}, j \\in \\mathcal{M}, t \\in T_j\\}$ represents the association between UAVs and IoTDs. m is the optimal number of UAVs for data collection. $\\mathcal{R} = \\{\\mathbf{r}_{j}[t], \\forall j\\in \\mathcal{M}, t \\in T_j\\}$ represents the visiting order of hover points for UAVs. $\\mathcal{T}^E = \\{T_{ij}^{TE}, \\forall i \\in \\mathcal{N}, j \\in \\mathcal{M},t \\in T_j \\}$ represents the set of energy harvesting time and $\\mathcal{T}^C = \\{T_{ij}^{TC}, \\forall i \\in \\mathcal{N}, j \\in \\mathcal{M}, t \\in T_j \\}$ represents the set of collecting data time."}, {"title": "E. Problem Decomposition", "content": "Since the energy harvesting time and the data collection time of each IoTD are independent of trajectories of UAVs, the original problem P0 can be decomposed into two sub-problems: time allocation problem P1 and trajectory optimization problem P2. Problem P1 can be described as follows:\n$\\begin{equation} \\label{eq:timeop} P1: \\min_{\\mathcal{T}^C,\\mathcal{T}^E} \\sum_{j=1}^m (E^H_j + E^F_j) \\end{equation}$\ns.t. (8).\nOne can see that Problem P1 is a convex optimization problem, which can be solved by applying Karush-Kuhn-Tucker (KKT) conditions [14]. The optimal solutions $\\{T_{ij}^{TC*}, T_{ij}^{TE*}\\}$\ncan be calculated as follows [15]:\n$\\begin{equation} \\label{eq:optimal-tc} T_{ij}^{TC*} = \\frac{D_i}{B\\log_2(1+\\frac{\\eta|g_{ij}|^4 P_T T_{ij}^{TE*}}{\\sigma^2})}, \\forall i \\in \\mathcal{N}, \\forall j \\in \\mathcal{M} \\end{equation}$\nwhere W(.) is the Lambert W function [15] and\n$\\begin{equation} \\label{eq:optimal-te} T_{ij}^{TE*} = \\frac{\\sigma^2}{ \\eta|g_{ij}|^4P_T}(\\frac{ln(2)D_i}{BT_{ij}^{TC*}} -1)^{-1}, \\forall i \\in \\mathcal{N}, \\forall j \\in \\mathcal{M}. \\end{equation}$\nAfter obtaining the optimal $\\{T_{ij}^{TC*}, T_{ij}^{TE*}\\}$, Problem P2 can be described as follows:\n$\\begin{equation} \\label{eq:trajop} P2: \\min_{\\mathcal{A}, m, \\mathcal{R}} \\sum_{j=1}^m E_j^F \\end{equation}$\ns.t. (1), (2), (3), (13), (14)."}, {"title": "III. ATTENTION-BASED UAV TRAJECTORY OPTIMIZATION FRAMEWORK", "content": "Problem P2 can be formulated as a well-known combinatorial optimization problem called Capacitated Vehicle Routing Problem (CVRP), which is NP-hard and difficult to be solved. Self-attention can encode the whole system information (e.g., the quantity, location and data size of IoTDs) to a self-attention feature matrix, and make a global decision based on it. Hence, we propose the AUTO framework based on the graph transformer to solve Problem P2."}, {"title": "A. AUTO Framework Overview", "content": "In the AUTO framework, we propose a novel ATOM model to optimize the quantity, trajectory, and association by the customized graph self-attention model. Moreover, we propose a new TENMA method to train the ATOM model.\nThe workflow of the AUTO framework is presented in Algorithm 1. We initialize the parameter $\\theta_\\pi$ of ATOM model randomly at the beginning. Then, in the training stage, we utilize TENMA method to train the ATOM model. In the inference stage, the self-attention features of all IoTDs $\\{h_1, ..., h_N\\}$ and the graph feature $h_{sa}$ are obtained by the graph encoder. Next, a solution that contains the total trajectory $\\pi$ and quantity $m$ of UAVs are obtained by trajectory decoder. The solution also meets the constraints of storage and battery capacity. Finally, we split the total trajectory $\\pi$ into trajectories $\\{\\pi^{(1)}, ..., \\pi^{(m)} \\}$ of all UAVs. In the j-th UAV trajectory, the visiting order is denoted as $\\Gamma^{(j)} = [\\pi_{j,1}, ..., \\pi_{j,s_j}]$, and it is the index of the IoTD whose data is collected by the j-th UAV in the t-th time step. Therefore, all the association $a_{ij}[t]$ and visiting order $\\mathbf{r}_{j}[t]$ are solved in the inference stage of Algorithm 1."}, {"title": "B. Graph Encoder", "content": "The proposed IoT system can be mathematically expressed as a graph structure pair: $\\mathcal{G} = (\\mathcal{X}, \\mathcal{E})$, where $\\mathcal{X}$ is the set of IoTD node, and $\\mathcal{E}$ is the set of edges. For one IoTD, the neighborhoods in the communication range all have edges connected to it. We propose a novel graph encoder to extract different self-attention features from IoTDs and the whole graph, which can help decoder to generate trajectories of UAVs with minimum energy consumption. The graph encoder contains a graph embedding layer, L self-attention layers and a graph pooling layer. Each self-attention layer contains a multi-head self-attention (MSA) sublayer, and a fully connected (FC) sublayer. Moreover, residual connections are introduced after every MSA sublayer and fully connected sublayer, and normalization operators are introduced before every MSA sublayer and fully connected sublayer [16]. The proposed graph encoder is illustrated in Fig. 2. The detailed procedure of the graph encoder can be described as follows:\n1) Graph Embedding Calculation: We define the IoTD information contains the coordinate $\\{x_i, y_i\\}$ of the i-th IoTD and sensory data $D_i$ generated from the i-th IoTD, which is denoted as $\\mathcal{X}_i = [x_i, y_i, D_i]$ and the information of all IoTDs is denoted as $\\mathcal{X} = \\{\\mathcal{X}_i, \\forall i \\in \\mathcal{N}\\}$. The graph embedding layer is applied to preprocess the graph information $h_{0,i}$ of the i-th IoTD.\n2) Self Attention Calculation: We introduce self attention layer to calculate self-attention features of all IoTDs.\nFirst, the graph encoder maps the embedding information $h_{0,i}$ of the i-th IoTD to query $Q_i$, key $K_i$ and value $V_i$ with learnable matrices, respectively.\nThe attention scores are computed as the dot product of the query $Q_i$ and key $K_j$, normalized by the square root of the dimension of the key vectors, followed by a softmax function to obtain the attention weights. These weights are then used to compute a weighted sum of the value $V_j$, producing the self-attention features $Z_i$ of the i-th IoTD for each head.\nThe outputs of all attention heads are concatenated and linearly transformed to form the MSA feature $h_{l,i}^M$ of the i-th IoTD at the l-th self-attention layer. The multi-head mechanism allows the self-attention layers to jointly attend to extracted information from different representation subspaces at different IoTDs [16]. The output of the i-th IoTD in the l-th self attention layer is\n$\\begin{equation} \\label{eq:attention} h_{l,i} = FC(h_{l,i}^M) + h_{l,i}^M \\end{equation}$\nwhere $FC(.)$ means the feed-forward operator of the fully connected layer.\n3) Graph Pooling Calculation: After calculating the self-attention features of all IoTDs, we need to merge all attention features to a global attention feature. However, simply averaging the features may produce an unrecoverable loss of IoTDs information [17]. Therefore, we propose a graph pooling layer to merge attention features of all IoTDs $\\{h_1, ..., h_N\\}$ to a graph feature $h_{sa}$, which can be given as\n$\\begin{equation} \\label{eq:pooling} h_{sa} = Mean (\\{W_{G,i} \\cdot Concat (h_{L,i}^M, h_{L,j}^M),\\forall i \\in \\mathcal{N}; j \\in \\mathcal{N}(i)\\} ) \\end{equation}$\nwhere $h_{L,i}$ and $h_{L,j}$ are the outputs of the L-th self attention layer, $W_{G,i}$ is the learnable matrix. $Concat(.)$ means the concatenation of two vectors."}, {"title": "C. Trajectory Decoder", "content": "In Problem P2, the aim is to minimize the system energy consumption by jointly optimizing the number and the trajectories of UAVs. The UAV takes off from the data center, collects data from IoTDs one by one, and returns to the data center. Then, the next UAV repeats the steps until all trajectories are generated. The procedure of the trajectory planning in trajectory decoder is illustrated in Fig. 3. The detailed process of the trajectory decoder is explained as follows:\n1) Graph State Definition: We develop the graph state for the trajectory decoder that considers the constraints of UAV battery and storage capacity in every step of UAV trajectory planning. Therefore, the trajectory can be optimized under all constraints. In the t-th time step, the graph state is denoted as $h_{s}(t)$:\n$\\begin{equation} \\label{eq:state} h_{s}(t) = [h_{sa}, h_{\\pi_{t-1}}^L, C_t, E_t] \\end{equation}$\nwhere $h_{sa}$ is the graph feature obtained from the graph encoder, $h_{\\pi_{t-1}}^L$ is the self-attention feature of the last selected IoTD in the trajectory of the current UAV, and $\\pi_{t-1}$ is the index of the last selected IoTD. $C_t$ and $E_t$ represent the remaining data and battery capacity of the current UAV in the t-th time step, respectively.\n2) Trajectory Generation: In each time step, we use the graph state $h_{s}(t)$ and the self-attention features of the L-th self attention layer to calculate the alignment vector as follows:\n$\\begin{equation} \\label{eq:alignment} a_i(t) = \\frac{exp(h_s(t)^T \\mathbf{W}_h h_{L}^i)}{\\sum_{i=1}^N exp(h_s(t)^T \\mathbf{W}_h h_{L}^i)} \\end{equation}$\nwhere $\\mathbf{W}_h$ and $\\mathbf{W}_i$ are learnable matrices.\nThen, we can calculate the context vector as follows:\n$\\begin{equation} \\label{eq:content} c(t) = \\sum_{i=1}^N a_i(t)h_{L}^i \\end{equation}$\nNext, the probability distribution of the remaining IoTDs $P(t) = \\{p_i(t), i \\in \\mathcal{N}\\}$ can be calculated as\n$\\begin{equation} \\label{eq:probability} P (t) = softmax (\\mathbf{W}_p \\tanh (\\mathbf{W}_c \\cdot Concat (c (t), h_s (t)))) M \\end{equation}$\nwhere $\\mathbf{W}_p$ and $\\mathbf{W}_c$ are learnable matrices, $\\mathbf{M}$ is the mask matrix. $\\mathbf{M}(i) = 1$ means UAV can collect data of the i-th IoTD, and $\\mathbf{M}(i) = 0$ otherwise. $p_i(t)$ represents the probability that the current UAV selects the i-th IoTD as next IoTD to collect data in the t-th time step.\nIn each time step, the current UAV selects the IoTD with max probability in $P(t)$ as the next IoTD $\\pi_t$ to collect data, so one has\n$\\begin{equation} \\label{eq:select} \\pi_t = argmax(P(t)) \\end{equation}$\nwhere $argmax(.)$ returns the index of the IoTD with the max probability.\n3) Trajectory Segmentation: When all IoTDs have been selected, we can get the total trajectory $\\pi = [\\pi_1, ..., \\pi_T]$. $\\pi$ is the permutation of all IoTDs and the data center. $\\pi_t \\in \\{1, ..., N\\}$ represents the IoTD index and $\\pi_t = 0$ represents the data center. For example in Fig. 3, we can get the whole trajectory $\\pi = [0, 4, 3, 0, 2, 1, 0]$. Then, the whole trajectory generated by trajectory decoder can be divided into several trajectories for all UAVs. For example, the trajectory $\\pi = [0, 4, 3, 0, 2, 1, 0]$ can be divided into $\\pi^{(1)} = [0,4,3,0]$ and $\\pi^{(2)} = [0, 2, 1, 0]$. Therefore, the number of UAVs is set to m = 2. Finally, all UAVs can fly and collect data in parallel according to the planned trajectories $\\pi^{(1)}, ..., \\pi^{(m)}$."}, {"title": "D. Actor-Critic Trajectory Learning", "content": "The training method of the ATOM model is introduced in this section. In reinforcement learning, value-based methods, such as Q-learning and DQN, are inefficient for large-scale action space [18]. Traditional policy-based methods, such as vanilla policy gradient and Monte-Carlo policy gradient, are hard to converge [12]. Therefore, we utilize a novel TENMA method to train the ATOM model, in which an additional critic network is utilized to evaluate the ATOM model, and the real reward of the system is applied as the baseline to reduce the variance of the critic network, and enhance the stabilization and generalization of TENMA. The detailed procedure of the TENMA method can be described as follows:\n1) State, Action and Reward Definition: In the WPT-assisted IoT system, we define the state of the system as State $\\{h_{sa}, h_{\\pi_{t-1}}^L, C_t, E_t\\}$. and then the action of UAVs is defined as the whole trajectory $\\pi$.\nMoreover, we draw K instances from the state space and use Monte Carlo simulation to produce feasible sequences with respect to the current policy of the ATOM model. The reward of the k-th instance is defined as\n$\\begin{equation} \\label{eq:reward} R_k = - \\sum_{j=1}^{m} \\sum_{t=1}^{s_j} ||\\mathbf{r}_j[\\pi_{k,t+1}] - \\mathbf{r}_j[\\pi_{k,t}]||_2 \\end{equation}$\n2) Actor Network Design: The ATOM model with parameter $\\theta_\\pi$ is designed as the actor network, which defines a stochastic policy $P_{\\theta_\\pi}(\\pi_k | s_k)$ for selecting the trajectory $\\pi_k$ with the k-th instance as follows:\n$\\begin{equation} \\label{eq:ppo} P_{\\theta_\\pi}(\\pi_k | s_k) = \\prod_{j=1}^{m} \\prod_{t=1}^{s_j} P_{\\theta_\\pi}(\\pi_{k,t} | s_k, \\pi_{k,1:t-1}) \\end{equation}$\nwhere $s_k$ is the state of the k-th instance. The loss function of the actor network is defined as\n$\\begin{equation} \\label{eq:actor} L(\\theta_\\pi) = \\frac{1}{K} \\sum_{k=1}^{K} -R_k \\log P_{\\theta_\\pi}(\\pi_k | s_k) \\end{equation}$\nFinally, we optimize $L(\\theta_\\pi)$ using the following policy gradient with baseline [19]:\n$\\begin{equation} \\label{eq:actor_opt} \\theta_\\pi \\leftarrow \\theta_\\pi + \\frac{\\eta}{K} \\sum_{k=1}^{K} (R_k - Q (s_k, \\pi_k | \\theta_Q)) \\nabla_{\\theta_\\pi} \\log P_{\\theta_\\pi}(\\pi_k | s_k) \\end{equation}$\nwhere $Q (s_k, \\pi_k | \\theta_Q)$ is the predicted reward approximation.\n3) Critic Network Design: We design a critic network with parameter $\\theta_Q$ to predict the reward approximation for the k-th instance. The loss function of the critic network is defined as\n$\\begin{equation} \\label{eq:critic} L(\\theta_Q) = \\frac{1}{K} \\sum_{k=1}^{K}(R_k - Q (s_k, \\pi_k| \\theta_Q))^2 \\end{equation}$\nThe critic network is applied as a baseline to stabilize the learning process. Hence, we optimize $L(\\theta_Q)$ using the following gradient estimator:\n$\\begin{equation} \\label{eq:critic_opt} \\theta_Q \\leftarrow \\theta_Q + \\frac{\\eta}{K} \\sum_{k=1}^{K} \\nabla_{\\theta_Q} (R_k - Q(s_k, \\pi_k| \\theta_Q))^2 \\end{equation}$\nThe critic network is optimized in the direction of reducing the difference between the expected rewards and the true rewards during Monte Carlo rollouts."}, {"title": "E. Time Complexity Analysis of the ATOM model", "content": "The time complexity of the ATOM model is calculated based on the graph encoder and the trajectory decoder. We analyze the time complexity of each part, then compute the overall time complexity of the ATOM model. According to the transformer model [16], the time complexity of graph encoder is $O(N^2 \\times D \\times L)$, where N is the current number of IoTDs, D is the hidden dimension, L is the number of self-attention layers. The time complexity of the trajectory decoder is $O(N \\times D^2)$. When the number of IoTDs N is small, D dominates the complexity of graph encoder and trajectory decoder. The bottleneck of the ATOM model thus lies in trajectory decoder. However, as the number of IoTDs grows larger, N gradually dominates the complexity of these modules, in which case the graph encoder becomes the bottleneck of the ATOM model."}, {"title": "IV. RESULTS AND DISCUSSION", "content": "In the simulation, we consider an area of 1000 m \u00d7 1000 m, and the locations and sensory data of IoTDs are various in the scenario. We assume there are 500 IoTDs in the area. The data size $D_i$ for each IoTD is randomly selected in [0.2, 1.5] MB [20]. Then, the detailed parameter settings of the AUTO framework are listed in Table II [21]. Moreover, we use PyTorch to implement the AUTO framework. All simulations are carried out in Python3.6 Environment running on Intel Xeon E5 CPU and NVIDIA Tesla T4 GPU with 32GB RAM."}, {"title": "B. Comparison of Attention Mechanisms with Graph Pooling", "content": "This experiment is presented to evaluate the performance of different attention mechanisms with various pooling operators. The ATOM model is compared with two attention mechanisms: Luong attention (Luong-Attn) [22", "23": "and three pooling operators mean, sum and max are also considered. The minimum energy costs (Min.), average energy costs (Ave.), and standard deviation ("}]}