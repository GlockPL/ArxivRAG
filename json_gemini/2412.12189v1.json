{"title": "Multi-Surrogate-Teacher Assistance for Representation Alignment in Fingerprint-based Indoor Localization", "authors": ["Son Minh Nguyen", "Linh Duy Tran", "Duc Viet Le", "Paul J.M Havinga"], "abstract": "Despite remarkable progress in knowledge transfer across visual and textual domains, extending these achievements to indoor localization, particularly for learning transferable representations among Received Signal Strength (RSS) fingerprint datasets, remains a challenge. This is due to inherent discrepancies among these RSS datasets, largely including variations in building structure, the input number and disposition of WiFi anchors\u00b9. Accordingly, specialized networks, which were deprived of the ability to discern transferable representations, readily incorporate environment-sensitive clues into the learning process, hence limiting their potential when applied to specific RSS datasets. In this work, we propose a plug-and-play (PnP) framework of knowledge transfer, facilitating the exploitation of transferable representations for specialized networks directly on target RSS datasets through two main phases. Initially, we design an Expert Training phase, which features multiple surrogate generative teachers, all serving as a global adapter that homogenizes the input disparities among independent source RSS datasets while preserving their unique characteristics. In a subsequent Expert Distilling phase, we continue introducing a triplet of underlying constraints that requires minimizing the differences in essential knowledge between the specialized network and surrogate teachers through refining its representation learning on the target dataset. This process implicitly fosters a representational alignment in such a way that is less sensitive to specific environmental dynamics. Extensive experiments conducted on three benchmark WiFi RSS fingerprint datasets underscore the effectiveness of the framework that significantly exerts the full potential of specialized networks in localization\u00b2.", "sections": [{"title": "1. Introduction", "content": "The proliferation of WiFi, and Bluetooth infrastructures has propelled Received-Signal-Strength (RSS) fingerprint-based indoor localization into the spotlight of both academic and industrial communities. This surge of interest is immensely driven by the rising demand for location-based services, such as asset tracking, wayfinding, and patient monitoring. Lately, the roaring success of deep learning has invigorated this field further by dint of its relevance to mainstream applications in Computer Vision, and Natural Language Processing. In this context, fingerprinting approaches initially require a collection phase to build an RSS fingerprint database that is normally constituted by sequences of recorded RSS fingerprints together with associated locations for a given area. Subsequently, various machine learning algorithms are utilized to learn a matching function that expresses the correlation between RSS fingerprints and their associated locations.\nOver the past few years, fingerprint-based indoor localization has undergone a complete transformation from deterministic KNN-based methods [1, 9,38] to sophisticated neural architectures, e.g., RNNs [14], CNNs [15, 28, 31], and more recently Transformers [23]. Although significant efforts have gone into utilizing these architectures to extract robust features for enhanced localization accuracy, knowledge transfer paradigms that could maximize the potential of these specialized networks better, as yet, only exist in embryonic form.\nIn particular, based on the radio multipath propagation, RSS fingerprint datasets are deliberately characterized by distinct structural setups, e.g., the input number and arrangement of WiFi anchors, inner infrastructures, and static layouts of surrounding objects. However, this radio feature, which contributes to the specificity of the datasets, is also deemed a double-edged sword. The susceptibility of RSS fingerprints to environmental changes [19] (e.g., mov-"}, {"title": "2. Related Work", "content": "Fingerprint-based Indoor Localization. In this category, methods aim to learn matching functions describing the relationship between RSS fingerprints and associated locations. In the early stages of development, kNN-based methods [1, 9, 38] driven by various distance metrics (e.g., Euclidean, Manhattan, and Cosine metrics) were widely used to determine locations from k nearest RSS fingerprints to the query fingerprint observations. After that, Gibr\u00e1n et al. [7] employed DNN-based variants to enhance\nestimation accuracy. Recent approaches [15, 29, 31] transformed one-dimensional RSS fingerprint sequences into two-dimensional RSS images to fully utilize architectural inductive biases from CNNs for feature exploitation. Not long ago, Nguyen et al. [23] achieved impressive performance with Transformer-based networks capable of capturing distinct feature representations embedded in RSS fingerprint sequences for specific locations.\nKnowledge Distillation. The theoretical underpinnings of distillation have a long history dating back to the work [4, 20, 35]. However, this research was only actively revisited and on the upswing right after the work introduced by Hinton et al. [12] in the context of model compression. This seminal knowledge distillation initially transfers rich knowledge from a strong teacher model to a target student model based on its soft probability distribution of the target task, which encourages the student model to learn how to mimic the task-specific predictability of the teacher model. This expectantly brings the student's performance closer to the teacher model with no parameter footprint added. Beyond usual soft probabilistic labels, later methods discovered new types of knowledge, e.g., intermediate feature maps [26], attention maps [41], and activation boundaries [11]. In the most current and basic form in fingerprint-based indoor localization, it was presented by Mazlan et al. [22] to preserve the localizing performance when embedded on computation-constrained devices.\nTransfer-Learning. Through the years, this paradigm has indeed proved efficient and effective; in particular, outstanding work [5, 18] showed strong performance when fine-tuned on downstream vision tasks using pre-trained models on JFT-300M dataset [32]. In contrast, transfer learning for RSS fingerprint-based localization is largely unexplored. Most transfer learning methods work out under the assumption that the source datasets and the target dataset should establish feature spaces in close proximity, but this is not the case for such RSS fingerprint datasets due to their unique characteristics shaped by distinct structural setups. Consequently, only few immature efforts have been made in this direction, typically Pan et al. [25] attempting to transfer local knowledge within the same areas using a common model pre-trained over different periods. By extension, Yong et al. [39] explored pre-training models on similar areas with upsampled and downsampled input data. More recently, Klus et al. [17] adopted separate encoders to create input features of the same size across different RSS datasets for transfer learning. However, because of the holistic pre-training process on heterogeneous source datasets, the improvements on the target datasets remain somewhat limited.\nNotably, our framework distinguishes itself totally from both regular knowledge distillation and transfer-learning paradigms for offering a comprehensive representation alignment. This uniqueness cleverly sidesteps issues associ-"}, {"title": "3. Proposed Method", "content": "Outlined in Fig.1, our framework performs the alignment in two main phases. The Expert Training phase equips surrogate-teacher networks to faithfully model the representation spaces formerly founded by specialized networks on their respective source datasets. Following this, the Expert Distilling phase focuses on distilling these representations into reference knowledge for alignment."}, {"title": "3.1. Expert Training phase", "content": "Technically, for a specialized model \\(S_i = \\{F_S, E_S, R\\}, \\forall i \\in \\mathbb{N}\\) associated with one of N source RSS fingerprint datasets, we decompose it into three sequential components: Framer FS responsible for crafting features from a batch of B RSS fingerprints, where each fingerprint \\(X = [x_o,..., x_n] \\in \\mathbb{R}^{1\\times n}\\) comprises RSS measurements from an anchors; Extractor Es built upon the crafted features to produce specialized representations denoted as ZE; and Regressor R exploiting these specialized representations for precise location estimation.\n\u25b7 Surrogate Teachers. Just like the configurations of the specialized models, we use simple generative models, each consisting of three fully connected layers, represented by \\(G_i = \\{F_G, E_G\\}\\). These models are employed in the context of WGANs [10] with additional gradient penalty enhancements to maintain stability during the modeling process. To bolster further the quality of modeled representations, denoted as ZE, and alleviate information bottlenecks in the subsequent phase, only two extra overarching constraints are imposed to model specialized representations ZSE from the source datasets with as much generality as possible. This streamlined phase aims to provide the subsequent phase with a greater degree of flexibility in extracting and aligning latent details with the target dataset.\n\u25b7 Angular Similarity Constraint. As described in Eq.1, we present a constraint denoted as Jsim to control the cor-"}, {"title": "3.2. Expert Distilling phase", "content": "In this phase, we propose a triplet of underlying constraints for optimization that implicitly establishes a comprehensive representational alignment along the way. Specifically, the essential knowledge distilled from the modeled representations ZE is consulted to align that of representations learned on the target dataset, denoted as ZE. The optimization process repeats concurrently between one single model S and a collection of N surrogate teachers Gi, which encourages the model to capture transferable representations insensitive to environmental variations, thereby improving its target localization performance.\n\u25b7 Cross-Mutual Information Maximization Constraint. Let p(ZE, ZE) represent the joint probability density function of specialized representations Z5 on the target dataset\nand modeled representations ZE from surrogate teachers. Similarly, let p(ZE) and p(ZE) denote the corresponding marginal probability density functions. The mutual information between ZE and ZE is defined as follows:\n\\(I(Z_E, Z_E^i) = \\int \\int p(Z_E, Z_E^i) log \\frac{p(Z_E, Z_E^i)}{p(Z_E)p(Z_E^i)} dZ_E dZ_E^i\\)\nThe mutual information I (ZE,Z) in Eq.3 can be presented in the form of the Kullback-Leibler divergence between the joint probability distribution P(ZE, ZE) and the product of the marginal distributions P (ZE) P (ZE), i.e., \\(I(Z_E, Z_E^i) = D_{KL}(P_{Z_E Z_E^i} || P_{Z_E} P_{Z_E^i})\\). Given that the Jensen-Shannon (JS) divergence is symmetric between these distributions and we desire to maximize mutual information rather than precisely calculate it, we adopt the mutual information estimator [13] that proved consistent with JS divergence, i.e., \\(I(Z_E, Z_E^i) = D_{JS}(P_{Z_E Z_E^i} || P_{Z_E} P_{Z_E^i})\\). Derived from JS divergence (as detailed in the supplementary material), the cross-mutual information maximization constraint, denoted as JMI in Eq.4 is presented to maneuver the neural estimator \u00ddo : ZE \u00d7 ZE \u2192 R, parameterized by \u03b8. On the contrary to [13], our approach instead estimates and maximizes the cross-mutual information between ZE and ZE over N surrogate teachers Gi just using one global estimator \u03a8\u03b8. By maximizing the cross-mutual information between the target and multiple different sources, the model S is enabled to learn adaptive representations proportional to the relevance of each source dataset.\n\\[J_{MI} = \\sum_{({Z^E_j, Z^{E^i}_j})\\sim p({Z^E, Z^{E^i}})} -log \\Big( 1 + e^{-\\Psi_\\theta(Z^E_j, Z^{E^i}_j)} \\Big) - \\sum_{({Z^E_j, Z^{E^i}_j})\\sim p(Z^E)p(Z^{E^i})}- log \\Big(1 + e^{\\Psi_\\theta(Z^E_j, Z^{E^i}_j)}\\Big)\\]\nAdditionally, this encourages the model S to learn only common information among N surrogate teachers Gi while removing exclusive information from specialized represen-"}, {"title": "4. Experiments", "content": "Databases. Evaluation is conducted on three distinct benchmark RSS fingerprint databases: UJIIndoorLoc [33], UTS [30], and Tampere [21]. These large-scale databases\nexhibit distinct characteristics, including differences in the input number and arrangement of WiFi anchors, types of capturing devices, buildings, inner infrastructures, and layouts of surrounding subjects. Notably, there is a significant level of sparsity in these databases, with only a fraction of the available WiFi anchors being operational for each fingerprint. For example, in UJIIndoorLoc, approximately 232 out of 520 anchors on each floor were active. In UTS and Tampere, 557 out of 589, and 779 out of 992 anchors were actually in operation, respectively. The missing anchor values were filled with default values of 100 dB. This sparsity poses a challenge, particularly in fine-grained localization scenarios that demand detailed information from a wide range of anchors to achieve accurate results.\nEvaluation Metrics. For a rigorous comparison, we employ a fine-grained evaluation approach using the Mean Absolute Error (MAE) metric to assess the overall localization performance. The MAE is calculated by measuring the Euclidean distance between estimated locations and their corresponding ground truth. Additionally, we consider the 75th Percentile and 95th Percentile for stability examination.\nParameter Setting. In our experiments, we set the weighting factors 1 to 3.0, 0.5, 0.5, and 0.5 in sequence, determined through a grid search on UJIIndoorLoc. All phases of our experiments are implemented in TensorFlow 2.11, using a fixed batch size of B = 128. The models are trained for 2000, 500, and 400 epochs at learning rates of le - 3, le - 3, and le 4 for Tampere, UJIIndoorLoc, and UTS datasets, respectively. These experiments utilized Adam optimization and were conducted on a single NVIDIA A100 GPU with 40GB of memory."}, {"title": "4.2. Comparisons to the State-of-the-art Methods", "content": "The proposed framework delivers a significant overall performance enhancement for stand-alone models, as measured by metrics including MAE, the 75th Percentile, and the 95th Percentile. As shown in Tab.1, most specialized models benefit considerably from the framework across all target datasets. Interestingly, the extent of performance improvement appears to be correlated with the architectural complexity of the models. For example, in UJIIndoor, the simple DNN+++ model in UJIIndoorLoc experiences a notable reduction of approximately 2.06 meters, translating to a 14.67% improvement in MAE, while more complex models like CNNLoc+++ and BayesCNN+++ show smaller improvements, with maximum MAE reductions of 1.45 meters (11.05%), and 1.84 meters (i.e. 14.57%) respectively. The differences might also be influenced by the scale and characteristics of the target datasets, as fully enhanced versions achieve marginal improvements in UTS, where RSS fingerprints were collected in smaller areas.\nFurthermore, the framework is benchmarked against other transfer-learning methods designed for fingerprint-based indoor localization. Some of these methods yield\nsubstantial estimation errors, exemplified by 61.29 meters and 129.95 meters MAEs for DNN* and BayesCNN** in UTS and UJIIndoorLoc, respectively. These failures can be attributed to the use of basic transfer-learning schemes (e.g., sequential and holistic transfer), which employ irrelevant representations learned by their encoder networks, thus constraining the learning capability of SoTA methods. In contrast, the proposed framework, dynamically empowering specialized models with ample references for alignment, exhibits overwhelming superiority with a considerable MAE reduction ranging from approximately 11% to 20%, depending on architectures.\nFor stability evaluation, it is observed that 75% of the estimated locations generated by all fully enhanced versions show significantly lower distance errors compared to both the baseline and other transfer-learning methods across all target datasets. Moreover, the accumulative error plots in Fig.2 also provide a comprehensive overview of the overall performance improvements across SoTA specialized models. In particular, simple models, namely DNN+++, and CNNLoc+++ can easily reach, and sometimes even surpass, the performance of complex architectures, particularly bAaT, over the target datasets. This is indicated by the solid lines located above the orange dashed line.\nLooking more closely at Fig.2, these fully enhanced versions consistently outperform their respective stand-alone counterparts, with the most noticeable improvements occurring in the range from the 15th Percentile to the 75th Percentile, described by the upper solid curves in UJIIndoorLoc and Tampere. In addition, the long-term stability improvements of the proposed framework are also emphasized by a substantial increase in the accumulative distribution function of SoTA specialized models. For example, the likelihood of the variable X being less than or equal to 10 m, represented by the probability P(X < 10 m), for all specialized models experiences a significant rise from an average of around 50%, ~ 60%, and ~ 60% to approximately 62%, ~ 72%, and ~ 75% for UJIIndoor, UTS, and Tampere, respectively. This reliability boost positions these networks for more practical and dependable applications."}, {"title": "4.3. Ablation Study", "content": "The ablation analysis, as presented in Tab.2, independently and incrementally adds each of the proposed constraints to the framework to assess their impact on the overall performance of SoTA specialized models.\n\u25b7 Effect of Angular Similarity. The impact of Jsim on reducing the Mean Absolute Error (MAE) is noticeable but is not consistently applied to all cases. In some instances, such as with stand-alone DNN and bAaT models in UTS, and Tampere respectively, the partly enhanced versions, namely DNN+ and bAaT+ experience an increase in MAE. This could be due to the possibility that one single constraint alone might not provide enough informative cues\nfor achieving effective representation alignment. It suggests that employing more constraints might be necessary to filter out irrelevant information and improve alignment.\n\u25b7 Effect of Mutual Information. When solely utilizing JMI for alignment, it consistently outperforms previous versions that simply include Jsim. This improvement is evident in models like DNN and CNNLoc*, which achieve significant reductions of 2.16 meters and 2.09 meters in MAE compared to their previous versions, i.e., DNN+ and CNNLoc+ in UJIIndoorLoc and Tampere, respectively. Combined with Jsim, it conspicuously enhances the MAE for all SoTA models, furnishing additional empirical support to fortify the alignment of acquired representations.\nFor instance, simpler models like DNN++ and CNNLoc++ manifest more pronounced reductions in MAE across UJIIndoorLoc, UTS, and Tampere than in their previous versions. Even intricate models, such as Transformer-based architectures bAaT++ exhibit marginal yet discernible performance amelioration across all target datasets. We ascribe this enhancement to the adaptability to the relevance and quality of source datasets provided by the constraint, effectively capitalizing on cross-mutual information gleaned from source datasets. Furthermore, this also underscores the efficacy of the Expert Training phase, where neural generative models Gi, even of a simpler nature, can proficiently emulate representations acquired by all SoTA models, in-"}, {"title": "4.4. Impacts of Data Source Relevance", "content": "In this experimental scenario, we further investigate the impacts of the relevance of source datasets to the target dataset on the robustness of the proposed framework. For this purpose, various combinations of three benchmark datasets are all considered to create different levels of source relevance for verification. One of these datasets is selected as the target dataset, while the other two are used as source datasets alternately.\nAs observed in Tab.3, the experimental results show that the framework, most of the time, delivers reliable performance gains under varying relevance among source datasets to the target. Through all possible combinations, employing two source datasets simultaneously tends to bring out comparable or even better performance constantly.\nFor example, there exist minor instances where convolutional models such as CNNLoc and BayesCNN exhibit slight performance deterioration when a single source dataset is used in UTS and UJIIndoorLoc, respectively. However, when both sources are employed, the performance deterioration is entirely mitigated, leading to significant performance gains, with notable improvements of up to 5.42%, and 14.57% for CNN, and BayesCNN, respectively A better balance in alignment with a variety of reference points resulting from incorporating more source datasets may be linked to these stable benefits, which reduces the impact of specific environmental factor. Furthermore, the success can be attributed to the adaptability of the underlying cross-mutual and functional constraints JMI&JFI, which are proportional to the relevance of source datasets to the target, thereby facilitating comprehensive alignment. These effects have been closely verified and reflected in Sect.4.3."}, {"title": "5. Conclusion", "content": "In this study, we contemplate an unexplored idea of elaborating a PnP knowledge-transfer framework that could be applicable straight to most SoTA localization models to consistently benefit from the comprehensive representation alignment between target RSS fingerprint datasets and public source datasets. Diverging from conventional knowledge-transfer methods, this approach harnesses surrogate teachers to provide robust and environmentally insensitive representations for specialized models, while requiring neither access to source data nor modifications to existing architectures. Our extensive experiments demonstrate the framework's robustness to the source relevance and advocate the utilization of more independent source datasets to promote comprehensive alignment."}, {"title": "6. Acknowledgment", "content": "This publication is part of the project MOSAIC: enhancement of Microfluidic Sensing with deep symbolic Artificial IntelligenCe with file number 19985 of the research programme Open Technology Programme which is (partly) financed by the Dutch Research Council (NWO).\nThis work made use of the Dutch national e-infrastructure with the support of the SURF Cooperative using grant no. EINF-6216."}, {"title": "A. Hyperparemeter Selection", "content": "For the angular margin a, we searched within a range from 0 degrees (0 radians) to 30 degrees (0.52 radians) on UIJIndoorLoc, with a step size of 0.1 radians, to determine the optimal angular margin. Our experimentation revealed that an angular margin of 0.2 radians consistently yielded stable results. Higher values of the angular margin a were not recommended, as they led to significant increases in model loss during training, making convergence extremely difficult.\nThe weighting factors mentioned are also determined through a grid search on UIJIndoorLoc and subsequently applied to other datasets. This process is expedited by leveraging prior knowledge that the primary task of indoor localization (denoted as JMAE) should be accorded greater emphasis, necessitating a larger range and higher amplitude for the weighting factor \u51651. Conversely, the high sensitivity of JF1 to the learning ability necessitates a much narrower range for the weighting factor A4. To ensure balanced impacts, these weighting factors are normalized together.\nThe rationale behind conducting grid-search hyperparameter selection exclusively on the UJIIndoorLoc dataset before applying the chosen hyperparameters to other datasets lies in UJIIndoorLoc's notable generalizability. This dataset has a collection period spanning months and encompasses expansive campus coverage across three buildings, totaling 110,000 square meters, effectively capturing the dynamic nature of real-world environments. During the grid search process, we set specific search ranges for each hyperparameter, such as [1-5] for \u5165\u2081 with a step size of 0.2, and [0.1-1] for 2,3,4 with a step size of 0.1. Through this rigorous exploration of over 7 days, we identified that the set of values [3,0.5,0.5,0.5] yielded the best performance during testing on the UJIIndoorLoc dataset."}, {"title": "B. Incompatibly with other knowledge-transfer in RSS-Fingerprint-based Indoor Localization", "content": "Compounded by the nature of radio propagation and multipath effects, the distinctive characteristics of RSS datasets, including variabilities in building structure, occupancy levels, and the arrangement and number of input WiFi anchors, give rise to uncompromising discrepancies in both appearance (input size) and content (locations). Unlike other data types such as images or text that easily achieve a common input size with minimal content alteration using standard interpolation techniques, RSS fingerprints cannot be resized as their arrangements of the disparate number of anchors are just unknown. Even if the input sizes were\nreluctantly synchronized, the content representing specific locations would undergo significant alterations, leading to deviations from the true data distribution. Consequently, traditional domain adaptation approaches [6, 24], such as meta-learning and adversarial learning, face limitations in their applicability to such datasets.\nMeta-learning approaches optimize a common meta-learner for the target task through the learning abilities of its versions trained on sub-tasks. However, implementing this approach to achieve a unified meta-learner for different RSS fingerprint datasets presents challenges. These datasets often vary significantly in the number of anchors, with differences of hundreds observed between datasets. Additionally, standard resizing techniques cannot be applied due to the unique characteristics of RSS fingerprints.\nAdversarial domain adaptation offers a potential solution to address differences in input size by employing separate feature generators for different datasets. However, this approach requires substantial modifications to existing architectures to ensure the delivery of homogeneous-sized features to domain discriminators for evaluation. Moreover, blindly learning domain-invariant features solely through artificial coarse-grained domain labels, especially in an adversarial learning framework, is inadequate for capturing fine-grained information particularly essential for precise localization. Additionally, this method is susceptible to instability, including notorious issues of model collapse, where discriminators fail to keep track of distribution changes in generated data."}, {"title": "C. Impacts of Target Relevance", "content": "The robustness of the framework is additionally evaluated on the target side where the target distribution is changed with the proportion of training data. Specifically, experiments are first carried out using only 1% and 10% of the training data for UJIIndoorLoc, and then expanded to 10% for the other datasets for general examination. This random partitioning is designed to simulate real-world scenarios for which all the models are subjected to the same conditions, and repeated for ten rounds to achieve statistical results. As demonstrated in Table 4, the framework exhibits its tolerance to target constrictions and consistently empowers state-of-the-art models to achieve strong performance."}, {"title": "D. Specific steps to the final JM1 in Eq.4", "content": "Cross-Mutual Information Maximization Constraint JMI in Eq.4 can be represented by JS Divergence DJs in"}, {"title": "E. Specific steps expanded in Eq.9", "content": "We elaborate on the expression of the transmitting matrix Tj, which is mentioned in Eq.8 and is reduced to a simple form in Eq.9 as follows:\n\\[\\Gamma \\Big[ (\\mathcal{Z}_{j-1})^T (\\mathcal{Z}_j) \\Big] \\Big[ (\\mathcal{Z}_{j-1})^T (\\mathcal{Z}_j) \\Big] \\ = \\Gamma \\Big[ (\\mathcal{Z}_{j-1})^T (\\mathcal{Z}_{j-1}) (\\mathcal{Z}_{j-1})^T (\\mathcal{W}_j \\mathcal{Z}_{j-1}) \\Big] \\]\n\\[ = (\\mathcal{W}_j \\mathcal{Z}_{j-1})^T (\\mathcal{W}_j \\mathcal{Z}_{j-1})\\]\n\\[= \\mathcal{Z}_{j-1}^T (\\mathcal{W}_j^T \\mathcal{W}_j) \\mathcal{Z}_{j-1}\\]"}, {"title": "F. Power Iteration Algorithm", "content": "The proposed framework estimates the spectral norm of the blocks in neural networks using the Power Iteration Algorithm. This method is chosen for its lightweight computation and continuous differentiability. Here is the pseudocode for the algorithm:"}, {"title": "G. Pseudo code of the training pipeline", "content": "The framework executes the alignment through two primary phases. The first phase called Expert Training, in-"}]}