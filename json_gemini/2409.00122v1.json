{"title": "Brant-X: A Unified Physiological Signal Alignment Framework", "authors": ["Daoze Zhang", "Zhizhang Yuan", "Junru Chen", "Kerui Chen", "Yang Yang"], "abstract": "Physiological signals serve as indispensable clues for understanding various physiological states of human bodies. Most existing works have focused on a single type of physiological signals for a range of application scenarios. However, as the body is a holistic biological system, the inherent interconnection among various physiological data should not be neglected. In particular, given the brain's role as the control center for vital activities, electroencephalogram (EEG) exhibits significant correlations with other physiological signals. Therefore, the correlation between EEG and other physiological signals holds potential to improve performance in various scenarios. Nevertheless, achieving this goal is still constrained by several challenges: the scarcity of simultaneously collected physiological data, the differences in correlations between various signals, and the correlation differences between various tasks. To address these issues, we propose a unified physiological signal alignment framework, Brant-X, to model the correlation between EEG and other signals. Our approach (1) employs the EEG foundation model to data-efficiently transfer the rich knowledge in EEG to other physiological signals, and (2) introduces the two-level alignment to fully align the semantics of EEG and other signals from different semantic scales. In the experiments, Brant-X achieves state-of-the-art performance compared with task-agnostic and task-specific baselines on various downstream tasks in diverse scenarios, including sleep stage classification, emotion recognition, freezing of gaits detection, and eye movement communication. Moreover, the analysis on the arrhythmia detection task and the visualization in case study further illustrate the effectiveness of Brant-X in the knowledge transfer from EEG to other physiological signals. The model's homepage is at https://github.com/zjunet/Brant-X/.", "sections": [{"title": "1 INTRODUCTION", "content": "Physiological signals, as indispensable biomarkers, characterize the underlying complexities of the human body and encapsulate a wide range of critical information about an individual's health, with great significance for health monitoring, disease diagnosis, and treatment [22, 42]. Among these, several key signals including electroencephalogram (EEG), electrooculography (EOG), electrocardiogram (ECG) and electromyogram (EMG), are especially essential in capturing primary physiological manifestations [49]. For instance, EEG signals, which record neural activity in the brain, have been utilized to study different stages of sleep and human emotions, aiding in diagnosing sleep-related disorders and emotional health issues [47]. Also, EOG signals, owing to their ability to monitor potential changes during eyeball movements, have proved instrumental in enabling communication for individuals living with neurodegenerative disorders [10, 59]. Moreover, ECG signals, which record the fluctuation of the heart's bio-electric activities, have been widely employed in investigations relating to cardiac health and diseases [66]. Finally, EMG signals capture the electrical activity of human muscles, helping the diagnosis and rehabilitation training of neuromuscular diseases [2]. The applications of these physiological signals allow clinicians to monitor individual health in real-time and make data-driven decisions, holding far-reaching implications for many research fields like healthcare.\nDespite each physiological signal records the physiological conditions of its corresponding body part, it is worth noting that the body functions as an integrated biological system rather than some independent components [68]. Thus, there exists an inherent interconnection among different physiological signals. Among these, given the brain's role as the epicenter for controlling vital activities, EEG exhibits significant correlations with synchronous physiological signals from other body parts [29]. Specifically, in some scenarios, since the information of single-type signal may be insufficient or noisy, ignoring this correlation can lead to great performance losses. Taking sleep staging as an example, as shown in Fig. 1(a), although EEG records different brainwaves in different stages, the rapid oscillations of EOG are particularly essential criteria for the rapid eye movement (REM) stage. Moreover, Sharma et al. [51] has also shown that introducing EOG signals can bring a relative improvement of 14.98% in accuracy. Besides, the correlations between EEG and other signals also exists in other scenarios: (1) EEG&EOG: For individuals with neurodegenerative disorders who can only express their thoughts and achieve interaction through eye movements, EEG and EOG can contribute to the development of assistive communication systems [59]. (2) EEG&ECG: During different emotional states in Fig. 1(b), brain signals and heartbeats consistently present different patterns, such that EEG and ECG can be utilized for emotion recognition [20]. (3) EEG&EMG: Since the abrupt muscle rigidity (named freezing of gaits, FoG) of Parkinson's disease is related to a complex interplay between motor, cognitive and affective factors, EEG and EMG can be employed in FoG detection to enhance patient safety and quality of life [74]. Hence, the correlations between EEG and other physiological signals (refered to as \u201cEXG\u201d in this paper, including EOG, ECG, and EMG) hold potential to improve performance in a variety of scenarios. Therefore, our work focuses on establishing an EEG-centric unified framework for modeling the correlation between EEG and EXG, which exploits the combined information of EEG and EXG to contribute to various application scenarios. However, current researches leave much to be explored in this direction, primarily due to the following challenges.\nFrom the viewpoint of data, simultaneously collected EEG and EXG signals face a conspicuous lack of data. Due to the acquisition costs, ethical restrictions, and a lack of emphasis on the signal correlation in current machine learning research, the majority of physiological data records only a single type of signal, such as EEG datasets of several terabytes in size [19]. In contrast, available multi-type physiological datasets, which contain various physiological data collected simultaneously, are much smaller in scale, most being less than a few gigabytes. Therefore, the scarcity of simultaneously collected EEG and EXG data poses challenges in training a unified framework for modeling the correlation between EEG and EXG.\nFrom a method perspective, there exist significant inherent differences in correlations between EEG and different EXG signals. Different types of physiological signals differ greatly in their inherent properties such as amplitude and bandwidth [58]. To satisfy the sampling theorem [50], the huge gap in bandwidth further leads to differences in sampling rates. Specifically, due to the gap in bandwidth, the sampling rates for EOG, ECG, and EMG may vary respectively within the ranges of 50-100Hz, 250-500Hz, and 1000-2000Hz. These discrepancies are also evident in other features like typical waveforms and rhythmicity [58]. The above factors result in vast inherent differences in correlations between EEG and different EXGs, posing a challenge to the unified modeling method of EEG-EXG correlation.\nFrom the viewpoint of task, in different scenarios, various downstream tasks depend on different correlations even between EEG and the same EXG. Given that different application scenarios involve different physiological activities of body organs, different downstream tasks need to capture different correlations between EEG and even the same EXG. Specifically, since the physiological changes during sleep is relatively slow, in sleep staging task, the EEG-EOG correlation is required to capture on a scale up to 30sec, which is defined as a sleep stage [7]. In contrast, in eye movement communication task, eyeball movements may occur in less than 1sec, depending on different EEG-EOG correlation from sleep staging [24]. Therefore, it is challenging to capture different EEG-EXG correlations for various downstream scenarios.\nTo tackle the above issues, we propose a contrastive-learning-based framework named Brant-X, to efficiently align EEG and EXG signals from different semantic scales for the modeling of correlation between EEG and EXG. To address the scarcity of simultaneously collected EEG and EXG data, our intuitive idea is to use models trained with a large amount of EEG data to empower the representation learning on EXG signals. Inspired by large language models that are widely applied in other research fields like computer vision [39, 63], we employ the EEG foundation model Brant-2 [70, 73], which is pre-trained on 4TB brain signal data and contains 1B parameters. Based on this, we summarize existing public multi-type physiological datasets\u00b9, to perform data-efficient knowledge transfer from EEG to EXG. Observing that the gaps between tasks primarily stem from the differences in semantic scales of correlation, to address the gaps among various signals and tasks, we introduce the two-level alignment that aligns the semantics of EEG and EXG at both patch- and sequence-level. The patch-level alignment overcomes finer inherent differences and captures EEG-EXG correlation at a smaller semantic scale, while the sequence-level one aligns coarser differences and captures the correlation at a larger scale. Moreover, we adopt the sampling augmentation to enhance model robustness to different sampling rates. Using the above methods, data and model resources in EEG are extended to empower the research on other physiological signals, paving a new avenue to model the correlations between various physiological signals."}, {"title": "2 PROPOSED METHOD", "content": "In this section, we introduce the technical details of the proposed framework Brant-X. Specifically, as shown in the upper left part of Fig. 3, we first split the EEG and EXG sequences into continuous data patches. Then, considering the variance in sampling rates between physiological signals in different scenarios, we adopt the sampling augmentation (lower left corner of Fig. 3) to enhance the model's robustness to changes in sampling rates. As shown in middle part of Fig. 3, the EEG patches and EXG patches, along with the augmented patches, are fed into the EEG and EXG encoder, respectively, to acquire the representation of each data patch. Here we employ the EEG foundation model Brant-2 as the EEG encoder of our framework (details in Sec. 2.2). During the unsupervised training process, we propose the two-level alignment (right part of Fig. 3), which aligns the simultaneously collected patches and sequences at both patch- and sequence-level. After the unsupervised alignment, the representations of EEG and EXG data output by the two encoders will be aggregated via the attention mechanism for various tasks in diverse scenarios."}, {"title": "2.1 Problem Formulation", "content": "First, we formalize the definitions of the four downstream tasks where the experiments are conducted. The collection of physiological signals relies on signal collection pads, referred to as electrodes, distributed on the body part to be monitored. Multiple electrodes simultaneously record the bioelectric activity of the corresponding organs, generating a multi-channels time series. Formally, given S EEG signal sequences ${x_i}_{i=0}^{S-1}$ that correspond to S physiological processes, each data sequence $x_i \\in \\mathbb{R}^{C \\times L}$ includes C channels with a length of L timestamps. The simultaneously collected EXG signals, including \u0108 channels, are denoted as ${\\tilde{x_i}}_{i=0}^{S-1}$, where $\\tilde{x_i} \\in \\mathbb{R}^{\\tilde{C} \\times L}$. According to different tasks or scenarios, each multi-type sequence $\\{x_i, \\tilde{x_i}\\}$ is annotated with a label $y_i \\in \\mathbb{R}$ by professional physicians. Based on the above, our research problems can be defined as:\nDefinition 2.1. Given EEG data sequences ${x_i}_{i=0}^{S-1}$ and EXG data sequences ${\\tilde{x_i}}_{i=0}^{S-1}$, with the corresponding labels $\\{y_i\\}_{i=0}^{S-1}$, the aim is to classify each multi-type sequence $\\{x_i, \\tilde{x_i}\\}$ to determine which class it belongs to."}, {"title": "2.2 Foundation Models for EEG", "content": "Due to the scarcity of simultaneously collected physiological data, it is challenging to build a unified framework for the modeling of correlations between EEG and EXG. To address this issue, we adopt the brain signal foundation model to perform data-efficient knowledge transfer from EEG to EXG. To the best of our knowledge, only the series of works named Brant currently serves as open-source foundation models on brain signals, including Brant and Brant-2. Specifically, Zhang et al. [73] provide the first off-the-shelf foundation model named Brant for intracranial EEG (iEEG) signals, which contains 500M parameters pre-trained on 1.01TB iEEG data. Based on Brant, Yuan et al. [70] propose the foundation model for brain signals named Brant-2. It consists of over 1B parameters and is pre-trained on as much as nearly 4TB mixed data (with 2.3TB iEEG data from 26 subjects and 1.6TB EEG data from about 15,000 subjects). Our choice to use Brant-2 as the EEG encoder in our framework was two-fold. Firstly, it is pre-trained on a large corpus of brain signal data and can learn powerful representations from EEG signals. More importantly, it uses pre-training data with different sampling rates, resulting in a heightened level of robustness towards changes in sampling rates."}, {"title": "2.3 Overall Architecture", "content": "Patching. Given that physiological data are bioelectric signals, the semantic information of the physiological states can only be collectively expressed with multiple sampling points, rather than a single one. Therefore, we split a whole data sequence into several consecutive patches to aggregate semantic information within patches and reduce computation demand [43].\nFormally, as shown in the upper left part of Fig. 3, given the i-th multi-channel EEG data sequence $x_i \\in \\mathbb{R}^{C \\times L}$ where C denotes the number of EEG channels and L denotes the number of timestamps (length of the sequence), we split $x_i$ with length M to generate a set of non-overlapping patches $\\{x_{i,j}\\}_{j=0}^{P-1}$, where $x_{i,j} \\in \\mathbb{R}^{C \\times M}$ and $P = \\lfloor L/M \\rfloor$ is the number of patches in this sequence. For the EXG data, we apply the same patching process as above, and the symbols are also similar. Specifically, we use $\\tilde{x_i} \\in \\mathbb{R}^{\\tilde{C} \\times L}$ to denote the i-th EXG sequence, where \u0108 is the number of EXG channels and L is the sequence length. Also, $\\{\\tilde{x_{i,j}}\\}_{j=0}^{P-1}$ denotes the set of patches, where $\\tilde{x_{i,j}} \\in \\mathbb{R}^{\\tilde{C} \\times M}$.\nSampling Augmentation. Considering that different physiological signals exhibit large differences in sampling rates, models that learn representations from physiological data must be sufficiently robust to changes in sampling rates. For EEG, as presented in Sec. 2.2, Brant-2 utilize pre-training data at various sampling rates, making it fairly robust to changes in sampling rates. Hence, serving as the EEG encoder of our framework, it is capable of handling differences in the sampling rate of EEG data.\nFor the EXG signals, to address the issue of various sampling rates, we adopt sampling augmentation to enhance the model's robustness to changes in sampling rate. Specifically, as shown in the lower left corner of Fig. 3, we both upsample the original data to twice its original rate and downsample it to half, producing two sets of augmented data with different sampling rates. Formally, given the original EXG data patches $\\{\\tilde{x_{i,j}}\\}_{j=0}^{P-1}$, we upsample the data to twice its sampling rate, generating the upsampled data patches $\\{\\tilde{x'_{i,j}}\\}_{j=0}^{P-1}$ where $\\tilde{x'_{i,j}} \\in \\mathbb{R}^{\\tilde{C} \\times 2M}$. Similarly, the original patches are also downsampled to half the sampling rate, thus obtaining the downsampled data patches $\\{\\tilde{x''_{i,j}}\\}_{j=0}^{P-1}$ where $\\tilde{x''_{i,j}} \\in \\mathbb{R}^{\\tilde{C} \\times \\lfloor M/2 \\rfloor}$.\nIn subsequent representation learning and semantic alignment sections, the original data $\\tilde{x}$, along with the upsampled data $\\tilde{x'}$ and downsampled data $\\tilde{x''}$, will be fed into the EXG encoder for model learning purposes.\nEmbedding to Latent Space. For EEG data, as shown in the middle part of Fig. 3, we feed it directly into the pre-trained EEG encoder (details in Sec. 2.2) to obtain the EEG representation. Formally, P consecutive patches $\\{x_{i,j}\\}_{j=0}^{P-1}$ from the i-th EEG data sequence $x_i$ will be input into the EEG encoder, yielding the representations $\\{p_{i,j}\\}_{j=0}^{P-1}$ of these patches, where $p_{i,j} \\in \\mathbb{R}^{D_p}$ denotes the representation of the j-th patch from the i-th sequence of EEG data, and $D_p$ denotes the dimension of patch representations.\nWhen it comes to EXG data, it will be fed into the EXG encoder to obtain its representation. Formally, all the patches $\\{\\tilde{x_{i,j}}\\}_{j=0}^{P-1}$ from the i-th EXG data sequence $\\tilde{x_i}$ are input into the EXG encoder, generating their representations $\\{\\tilde{p_{i,j}}\\}_{j=0}^{P-1}$, $\\{\\tilde{p'_{i,j}}\\}_{j=0}^{P-1}$, $\\{\\tilde{p''_{i,j}}\\}_{j=0}^{P-1}$ where $\\tilde{p_{i,j}} \\in \\mathbb{R}^{D_p}$. Given that the focus of our work is the alignment framework, the specific architecture of the EXG encoder can be flexible. For the technical details of the EXG encoder used in this paper, please refer to App. A. Similarly, the upsampled EXG patches $\\{\\tilde{x'_{i,j}}\\}_{j=0}^{P-1}$ and the downsampled patches $\\{\\tilde{x''_{i,j}}\\}_{j=0}^{P-1}$ undergo the same process, obtaining the representations $\\{\\tilde{p'_{i,j}}\\}_{j=0}^{P-1}$ and $\\{\\tilde{p''_{i,j}}\\}_{j=0}^{P-1}$ of augmented EXG data."}, {"title": "2.4 Two-level Alignment", "content": "We adopt two-level alignment that fully aligns the semantics of EEG and EXG signals at patch- and sequence-level, to overcome inherent differences and capture the correlation between EEG and EXG at different semantic scales.\nPatch-level Alignment. At a finer grain, we align EEG and EXG data at patch-level by placing the simultaneous EEG and EXG patches close together in the latent space, while mapping unrelated patches further apart. As shown in the upper right part of Fig. 3, since our EEG encoder is pre-trained on a large amount of data (Sec. 2.2), it is reasonable to believe it can output representative representations of EEG patches. Therefore, we set the EEG representation $p_{i,j}$ as the anchor. The anchor $p_{i,j}$ and the simultaneously collected EXG patch $\\tilde{p_{i,j}}$ are set as the positive sample pair. Negative samples are randomly selected from the representations $\\{\\tilde{p_{m,n}}\\}_{m\\neq i}$ from other EXG data sequences. It is noteworthy that, contrary to the sequence-level alignment described later, we can't randomly select the representations $\\{p_{i,n}\\}_{n\\neq j}$ from the EXG sequence $\\tilde{p_i}$ as negative samples. This is because these representations $\\{p_{i,n}\\}_{n\\neq j}$ and the anchor originate from the same physiological process and may have a temporal dependency between them. Formally, for the anchor $p_{i,j}$, the negative sample set $Z_{ij}$ is randomly sampled from all the negative samples $\\{\\tilde{p_{m,n}}|m \\neq i, n = 0, ..., P - 1\\}$. The InfoNCE [44] loss is applied to retain the maximum mutual information between positive pairs:\n$L_p = \\sum_{i}^{S} \\sum_{j}^{P} -log \\frac{exp(p_{i,j}\\tilde{p_{i,j}}/\\tau_p)}{\\sum_{\\tilde{p_{m,n}} \\in Z_{ij}} exp(p_{i,j}\\tilde{p_{m,n}}/\\tau_p)}$\nwhere $\\tau_p$ denotes the temperature hyperparameter to adjust scale, and $L_p$ denotes the InfoNCE loss between EEG and original EXG data in patch-level alignment.\nSimilarly, the same alignment process would also exist between the EEG data and the two sets of augmented EXG data. These two losses are denoted as $L'_p$ and $L''_p$, respectively. Overall, the optimization objective of patch-level alignment is given by:\n$L = L_p + L'_p + L''_p$.\nSequence-level Alignment. At a coarser granularity level, we employ sequence-level alignment to align the corresponding sequence in the latent space. To aggregate the representations of patches from a data sequence, we firstly perform a linear projection $W_{proj} \\in \\mathbb{R}^{D_s \\times PD_p}$ on all patch representations $p_{i,:} \\in \\mathbb{R}^{P \\times D_p}$ from sequence $x_i$, thus obtaining the sequence representation $s_i \\in \\mathbb{R}^{D_s}$, where $D_s$ denotes the dimension of sequence representations:\ns_i = W_{proj} (Flatten(p_{i,:})).\nThis linear projection is applied similarly for EXG data $\\tilde{p_{i,:}}$ and the augmented data $\\tilde{p'_{i,:}}$, $\\tilde{p''_{i,:}}$ as well, yielding the sequence representations $\\tilde{s_i}$, $\\tilde{s'_i}$ and $\\tilde{s''_i}$ respectively.\nAfter obtaining the sequence representations, we set the representations of simultaneously collected EEG and EXG sequences ($s_i$ and $\\tilde{s_i}$) as positive sample pairs, while all other sequence pairs are set as negative pairs. Formally, the negative sample set $Z_i$ of sequence $s_i$ is randomly sampled from all the negative samples $\\{\\tilde{s_m}|m \\neq i\\}$. The sequence-level InfoNCE loss $L_s$ for the EEG and the original EXG data can be given as follows:\n$L_s = \\sum_{i}^{1-S} -log \\frac{exp(s_i\\tilde{s_i}/\\tau_s)}{\\sum_{\\tilde{s_m} \\in Z_{i}} exp(s_i\\tilde{s_m}/\\tau_s)}$\nwhere $\\tau_s$ denotes the temperature hyperparameter. As shown in the bottom right part of Fig. 3, following the common practice in CLIP [48], we adopt a similarity matrix to optimize this objective.\nLikewise, we carry out the same alignment process between EEG and augmented EXG data, resulting in two losses $L'_s$ and $L''_s$ in the same form. The overall loss in sequence-level alignment is:\n$L = L_s + L'_s + L''_s$.\nFinally, the objective of joint optimization is obtained by adding the patch-level and sequence-level alignment losses $L_p$ and $L_s$."}, {"title": "3 EXPERIMENT", "content": "Alignment. To align the simultaneously recorded EEG and arbitrary EXG data, the training data used for unsupervised alignment is collectively assembled from three datasets: CAP [57], ISRUC [32], and HMC [4], which include EEG, EOG, ECG, and EMG signals. Overall, the alignment training data includes 359 recordings from 267 subjects. The alignment is performed on a Linux system with 2 CPUs (AMD EPYC9654 96-Core Processor) and 2 GPUs (NVIDIA Tesla A100 80G). The learning rate of EEG encoder is set as $1 \\times 10^{-5}$ for finetuning, while the EXG encoder is trained with a higher learning rate of $3 \\times 10^{-4}$.\nDownstream Tasks. Here we introduce the four downstream tasks used to validate the effectiveness of our Brant-X, along with the datasets, setups and and evaluation metrics.\n\u2022 Sleep Stage Classification. In sleep health research, sleep staging refines human understanding of sleep states and patterns, which holds significance for the prevention and diagnosis of sleep-related diseases [47]. According to the American Academy of Sleep Medicine (AASM) manual [7], sleep occurs in five stages: wake, N1, N2, N3, and REM. Among these, N1 to N3 are non-rapid eye movement sleep, with each stage leading to progressively deeper sleep. Hence, sleep stage classification is a five-class classification problem.\nAs for the dataset, the Sleep-EDF datasets [31] are very popular in sleep staging researches. The Sleep-EDF-78 dataset contains 153 whole-night polysomnographic sleep recordings from sleep cassette studies, containing 100Hz EEG and EOG data from 78 subjects aged 25-101 years (37 males and 41 females). Data are segmented into 30sec epochs and manually annotated by experts. The Sleep-EDF-20 dataset, which contains 39 recordings from 20 subjects, is also used in our study to facilitate the comparison with the existing methods.\nThe experiment is conducted on EEG and EOG signals in a subject-independent setting. We divide the subjects into training, validation, and test sets in a 3:1:1 ratio. The experiments are repeated on all subjects to obtain overall results. The evaluation metrics include accuracy, sensitivity, specificity, macro F1 score, and Cohen's kappa \u03ba.\n\u2022 Emotion Recognition. Automatic emotion recognition has made a remarkable entry in the domain of biomedical, brain-computer interface, smart environment, safe driving and so on [28]. Emotions are categorized into two types: (1) discrete emotions like joy, fear and sadness; and (2) multi-dimensional emotions on three emotion dimensions: arousal, valence, and dominance dimensions. Existing works [30, 35, 36, 54, 56] mainly focus on the recognition of multi-dimensional emotions, so the task can be regarded as three independent binary classification problems: low/high valence, low/high arousal and low/high dominance.\nThe DREAMER dataset [30] is used to conduct experiments on emotion recognition task. It contains EEG (128Hz) and ECG (256Hz) data of 23 subjects (14 males and 9 females) when they are watching 18 film clips. Each film clip has an average length of 199s, which is thought to be sufficient for eliciting single emotion. After watching a film clip, emotion statuses are labeled as low or high on the three emotion dimensions, serving as the labels for emotion recognition.\nThe experiment in this task is conducted on EEG and ECG signals in a subject-independent setting. We split subjects into training, validation, and test sets in a 3:1:1 ratio and repeat the experiments on all subjects. The evaluation metrics are mainly accuracy [35, 36, 56], with some studies [30, 54] also including the F1 score and the AUC of precision-recall curve.\n\u2022 Freezing of Gaits Detection. FoG, which refers to the interruption of the motion caused by the brain's incompetence to deal with concurrent cognitive and motor request, affects about 50%-80% of Parkinson's disease patients as one of the severest manifestations. Thus, accurate detection of FoG can significantly improve patients' life quality and promote personalized treatment [74]. The FoG detection task is a binary classification problem, that is, determining whether FoG appears during a walking process.\nThe FoG dataset [74] is used in this work, which includes EEG and EMG signals (1000Hz) collected from 12 Parkinson's disease patients (6 males and 6 females) aged 57-81 years with disease durations between 1 and 20 years. The valid data lasts for 3h42min, including 2h14min of normal gait and 1h28min of freezing of gait, labeled by two qualified physicians.\nThe experiment in this task is conducted on EEG and EMG. The training, validation, and test data are randomly split in a 3:1:1 ratio. We also repeat the experiments to obtain the overall results. As a classification problem, the evaluation metrics used for this task are accuracy, precision, recall and F1 score.\n\u2022 Eye Movement Communication. Due to paralysis caused by neurodegenerative disorders like amyotrophic lateral sclerosis (ALS), many patients lost almost all their communication abilities [24], and only have remnant oculomotor control to form words, phrases, and sentences using a speller system [59]. The speller system works on a binary principle where the patient responds to auditory questions by moving their eyes to say \"yes\" and not moving the eyes for \"no\u201d. Therefore, the eye movement communication task is also a binary classification problem (yes or no).\nThe dataset published by Jaramillo-Gonzalez et al. [24] is used for the eye movement communication experiment. The dataset contains EEG and EOG data (500Hz) recorded from four patients suffering from ALS. Data are recorded during 2-10 visits, each visit consisting of an average of 3.22 days with 5.57 sessions recorded per day. Due to the inconsistency in EOG channels across different files in the dataset, we exclude files lacking specific EOG channels to conduct the experiment.\nThe experiment in this task is conducted using EEG and EOG. Experiments are conducted on training, validation, and test data split 8:1:1 and are repeated on all data files. The evaluation metrics are accuracy, precision, recall and F1 score.\nAs for data pre-processing, for the three tasks except eye movement classification, we did not perform filtering or other processing, directly using the preprocessed data of the original datasets. For the eye movement dataset, as the publisher didn't filter, we applied 45Hz low-pass filtering and z-score normalization."}, {"title": "3.2 Experimental Results", "content": "Fig. 4 summarizes the overall accuracy of Brant-X and other baselines on various downstream tasks (including the arrhythmia detection in Sec. 3.3). Since the task-specific methods vary across different tasks, we use \"Task-specific Methods\" to collectively represent their best results on each task. As shown in Fig. 4, compared with other baseline methods, Brant-X achieves SOTA performance on all of the five tasks, illustrating the effectiveness of our framework in various scenarios. Detailed comparisons on each task are discussed in following paragraphs, where in all the tables we mark values ranking the first (v), second (v) and third (v*) in each column."}, {"title": "3.3 Ablation Study", "content": "To evaluate the effectiveness of each component in Brant-X, we conduct ablation experiments on four model variants, including: (1) Brant-X w/o sampling-aug: Brant-X without the sampling augmentation during alignment; (2) Brant-X w/o patch-align: Brant-X without the patch-level alignment; (3) Brant-X w/o seq-align: Brant-X without the sequence-level alignment; (4) Brant-X w/o EEG-encoder: Brant-X without the EEG encoder during downstream evaluation after alignment; (5) Brant-X w/o EXG-encoder: Brant-X without the EXG encoder during downstream evaluation after alignment.\nThe comparison results of the ablation experiments on the four downstream tasks are presented in Fig. 5. It demonstrates that Brant-X outperforms other variants on all metrics of all the tasks, evidencing the contribution of each component in our framework. Compared to the full Brant-X, the performance of Brant-X w/o sampling-aug decreases, showing the boost of model robustness against variable sampling rates provided by the sampling augmentation. Also, Brant-X w/o patch-align and Brant-X w/o seq-align show a decrease in performance, suggesting that the two-level alignment can align EEG and EXG signals from different semantic scales to learn informative representations from physiological data. For sleep staging and emotion recognition, Brant-X w/o EEG-encoder drops greatly in performance, as EEG signals play an important role in these scenarios. This corroborates the significance of the brain as a central control in vital activities, as we emphasized in Sec. 1.\nEXG Encoder Analysis. As a supplement to the Brant-X w/o EEG-encoder in the ablation experiments, we extend our assessment to more tasks using the standalone EXG encoder, to validate whether the EXG encoder can learn useful representations from EXG data during the alignment training. Specifically, we conduct experiments with the aligned EXG encoder on ECG data (without incorporating the EEG encoder on EEG data) on the arrhythmia detection task."}, {"title": "3.4 Case Study", "content": "Fig. 6 displays four similarity matrices between patch representations of two multi-type physiological data sequences, $\\{x_i, \\tilde{x_i}\\}$ and $\\{x_j, \\tilde{x_j}\\}$. The vertical axis represents the patch representations of two EEG sequences, $x_i$ and $x_j$, and the horizontal axis represents the patch representations of two EXG sequences, $\\tilde{x_i}$ and $\\tilde{x_j}$. Thus, four similarity matrices are given in Fig. 6. The darker the colour of each small square, the higher the normalised similarity between the representations of two corresponding patches.\nAmong these, matrix (a) (or (d)) indicates the similarity of patch representations of simultaneously collected EEG sequence $x_i$ (or $x_j$) and EXG sequence $\\tilde{x_i}$ (or $\\tilde{x_j}$). It presents an overall darker colour, demonstrating the correlations between patches from the simultaneously collected EEG and EXG sequence. Moreover, the diagonal of matrix (a) (or (d)) is particularly dark, indicating that the simultaneous EEG and EXG patches are well-aligned. However, as for matrices (b) and (c), they have an overall lighter colour, suggesting little to no correlation between patch representations of non-simultaneously collected EEG and EXG data. These four similarity matrices in this case illustrate well that the two-level alignment can bring the representations of simultaneous EEG and EXG data closer, while distancing irrelevant sequences, such that Brant-X can perform knowledge transfer from EEG to EXG."}, {"title": "4 RELATED WORK", "content": "Physiological Signal Modeling. With the maturation of physiological recording technology and the advancement of machine learning methods, physiological signal modeling has captivated many researchers. Initially, researchers mainly focus on model learning on a single type of signal. A large body of works propose to use time series [18, 36, 37, 45, 52, 55, 71", "35": "data structures with supervised [18, 35-37, 45, 52, 55", "71": "learning paradigms for various tasks on EEG signals. Recently, some large EEG models [26, 70, 73", "77": "ECG [3, 40", "72": "signals. Additionally, to fully mine the potential semantics of physiological data, research attention has been drawn to the modeling of multi-type signals. Jia et al. [25", "64": "fuse the features from single-lead EEG and ECG data for emotion recognition. Aly and Youssef [5"}]}