{"title": "Intelligent Tutors for Adult Learners: An Analysis of Needs and Challenges", "authors": ["Adit Gupta", "Momin Siddiqui", "Glen Smith", "Jennifer Reddig", "Christopher MacLellan"], "abstract": "This paper aims to uncover needs of adult learners when using pedagogical technologies such as intelligent tutoring systems. Further, our aim with this work is to understand the usability challenges when deploying tutors at scale within the adult learning audience. As educational technologies become more ubiquitous within k-12 education, this paper aims to bridge the gap in understanding on how adult users might utilize intelligent tutors. In pursuit of this, we built four intelligent tutors, and deployed them to 110 classrooms at a state technical college for an entire academic year. Following this deployment, we conducted focus groups amongst users to gather data to understand how learners perceived the optional educational technology during their academic journey. We further analyzed this data using foundational HCI methodologies to extract leanings and design recommendations on how developers might craft educational technologies for adoption at scale for the adult learning population.", "sections": [{"title": "1 INTRODUCTION", "content": "Intelligent tutoring platforms have come a long way over the past five decades, since the earliest mentions of tutors in the 1970s. Intelligent tutors serve users through the ability of solving a wide variety of problems examples, sometimes generalized problem types [20]. The earliest intelligent tutor based on an expert model was GUIDON, developed by William Clancey to teach medical knowledge [7]. Since then, researchers have had an emphasis on the impact of intelligent tutors on k-12 users, predominantly in environments where learners were learners were tasked with using the tutors as a pert of their curriculum [16]. Several large randomized controlled trials have demonstrated tutor's effectiveness across varied populations, topics, and contexts [24, 31, 33]. Despite a consistent track record of improving student learning, tutors have not been widely adopted amongst adult learners across non-traditional educational environments.\nOne line of research proposes that tutors have not been widely adopted because of the high cost of creating them [20, 21]. We acknowledge that tutor authoring challenges contribute to a lack of adoption, but in this paper we explore an additional hypothesis: that tutors are often not adopted due to sociotechnical challenges that arise from a mismatch between the perceptions and needs of stakeholders-mainly learners-and the key design features and capabilities of intelligent tutors. As such, there are two research questions that inspire our work in this paper:\n(1) RQ1: What are the needs of adult learners to adopt intelligent tutors?\n(2) RQ2: How might we craft intelligent tutors differently based on the needs of adult users?\nTo answer these research questions, we have split this paper into two parts. In the first part, we build a novel intelligent tutoring system, Apprentice Tutors, focused on the adult learner population. In the second part, we deploy this system to population of adult learners at a state technical college. This paper specifically concentrates on a tutor adoption by subset of users, adult learners. We specifically look at this user population as the motivations (both intrinsic and extrinsic) of users in k-12 are different from the users choosing self-willingly choosing to utilize intelligent tutors in post k-12 education. Additionally, from our review, while there are many studies previously (i.e., large randomized trials) conducted focusing on k-12 learners [1, 14, 16], there are only few that focus on adult usage of pedagogical tools at scale [3, 32]. Finally, in our review of the literature, we found that much of the prior research has focused on measuring and quantifying the effectiveness of tutors-effectively adopting the hypothesis that if tutors are effective, then people will use them. However, we found that the influence of other factors on tutor adoption by adult learners is largely under explored.\nTo explore our first research question, we created the Apprentice Tutors, which support four topics: radicals, exponents, factoring polynomials, and rational equations. All tutors offer a learning experience that includes many features typical of intelligent tutoring systems, including on-demand hints, real-time correctness feedback, adaptive problem selection, and a multi-layer hinting strategy. Later in this paper, we dive deeper into the inner workings of the Apprentice Tutors platform to share how these key features work. The tutoring materials were developed based on the existing course curriculum and refined based on iterative feedback from course instructors, who also provided anecdotal evidence about the areas where students faced difficulties. Further, in the first study presented we deployed these tutors to adult users who had the option to use any of the Apprentice Tutors during their Math 1111 course. The tutors were deployed to learners via their learning management system (Blackboard) over the course of an academic year, partitioned into four quarters: fall, winter, spring, and summer. Tutors were embedded into students' course curriculum but were not mandatory. In this context, adult learners had more flexibility on whether they wanted to use the Tutors. Through the deployment, we collected quantitative data, which allowed us to analyze how often tutors were adopted and whether students successfully learned skills using the tutors.\nIn our second study, we aim to better understand how these tutors for adult learners were perceived and to probe the unique needs of our users, we conducted user focus groups with both students and teachers. We transcribed focus group sessions and conducted qualitative analysis on this data to derive key themes that emerged around the specific challenges and needs faced in adult learning contexts. We conducted thematic analysis on focus group data collected above. To do so, we synthesized the key themes into generalized recommendations about how to improve the usage and adoption of intelligent tutors in adult learning contexts. Our aim through this work is to guide designers and developers building intelligent tutors to better understand the needs of end-users and build tools susceptible to greater overall adoption and impact."}, {"title": "2 RELATED WORKS", "content": "Intelligent tutors are praised for their personalized teaching abilities at scale, overcoming a ceiling which hinders adult tutoring. While adult tutoring is particularly effective, it is cost prohibitive, therefore not available ubiquitously. There have been several studies where ITS have demonstrated success when used amongst k-12 learners in controlled settings where all participants engage in a fixed amount of activity [1, 14, 16, 25, 26]. For example, one of the largest randomized trials of educational tools in action was, PAT. An intelligent tutoring system for algebra problem solving, PAT, was used in the Pittsburgh Urban Math Project (PUMP). On average, 470 students outperformed students in comparison by 15% on standardized tests and a 100% improvement on concepts that the tutoring system targeted [16].\nWhile certain pedagogical principles remain consistent across age groups, such as the benefits of high-quality feedback [13, 22, 30], it is important to recognize that adults differ from children (k-12 users) in ways that significantly impact the learning process. The context of adult learning often diverges from traditional instructional settings, frequently being self-directed rather than formal. From a cognitive development perspective, some abilities, such as memory and abstract reasoning, tend to decline after early adulthood, while others, like crystallized knowledge, continue to increase through midlife [2, 28]. These developmental changes necessitate considerations for age-inclusive instruction. Considering both the lifespan cognitive shifts and the contextual differences in learning environments, it becomes evident that the research and practices developed for ITS may not fully translate to adult learners. While organizational researchers have provided guidelines for instructional design in technology-supported training contexts [27], it remains unclear how or to what extent these principles have been applied in developing effective ITS for adults. This gap in understanding highlights the need for further research into the specific requirements and considerations for designing ITS that cater to the unique needs and characteristics of adult learners.\nOur study addresses two key gaps in intelligent tutoring system (ITS) research for adult learners. First, we developed and deployed Apprentice Tutors, a novel ITS optimized for adult learners, in a state technical college to investigate factors influencing voluntary adoption and usage. Second, we conducted focus groups to derive design recommendations tailored to adult learners' needs in self-directed contexts. This research contributes empirically-grounded insights into adult learner engagement with ITS and offers guidelines for improving ITS design and adoption in adult learning environments, addressing a notable gap in the existing literature [29]. Our findings aim to guide the development of ITS that better align with adult learners' expectations and requirements in voluntary educational settings."}, {"title": "3 APPRENTICE TUTORS", "content": "The Apprentice Tutors platform is a web-based intelligent tutoring system for adult learners available on most modern browsers across different hardware such as a mobile or computer. Each tutor within the platform consists of multiple problem types, where each problem type consists of an expert model and an interface. The Apprentice Tutors architecture was built with Python, and the expert models were built with a rete-based production rule engine [10].\nTo develop tutors in this platform, conducted cognitive task analysis by speaking with instructors to learn about their teaching styles and focus [17]. Based on the information from this analysis, we designed and programmed the tutor interface for each specific problem type. Each step within the tutor interface maps to a single skill, which is represented in the expert model via a particular production rule.\nAs users interact with steps in a tutor interface, we store each tutor transaction within the Apprentice Tutor platform's database. This lets us track the progression of skills over time as users continue to interact with the tutors. To provide a personalized learning experience, we created the adaptive problem selection feature. Based on how they would like to practice, learners can choose between adaptive problem selection or manually select a particular problem type within each tutor. Each tutor also generates randomized problems for students to practice based on constraints specified within a problem generator.\nAs users interact with dynamically generated problems, the tutors provide real-time correctness feedback. The tutors also provide of multi-layer hints in a text box below the tutor interface. We discuss hints further in the Hinting Strategy section of this paper. The Apprentice Tutors platform also has visualization dashboards that allows both students and teachers track skill mastery [12]. Apprentice Tutors allows for the seamlessly deployment of tutors to classrooms. In order to facilitate this goal, we used the Learning Tools Interoperability standards proposed by IMS Global Learning Consortium [19]. All major learning management systems comply with these standards and allow educational technologies to be embedded into popular learning management systems, such as Blackboard and Canvas."}, {"title": "3.1 Platform Description", "content": "The Apprentice Tutors platform is a web-based intelligent tutoring system for adult learners available on most modern browsers across different hardware such as a mobile or computer. Each tutor within the platform consists of multiple problem types, where each problem type consists of an expert model and an interface. The Apprentice Tutors architecture was built with Python, and the expert models were built with a rete-based production rule engine [10].\nTo develop tutors in this platform, conducted cognitive task analysis by speaking with instructors to learn about their teaching styles and focus [17]. Based on the information from this analysis, we designed and programmed the tutor interface for each specific problem type. Each step within the tutor interface maps to a single skill, which is represented in the expert model via a particular production rule.\nAs users interact with steps in a tutor interface, we store each tutor transaction within the Apprentice Tutor platform's database. This lets us track the progression of skills over time as users continue to interact with the tutors. To provide a personalized learning experience, we created the adaptive problem selection feature. Based on how they would like to practice, learners can choose between adaptive problem selection or manually select a particular problem type within each tutor. Each tutor also generates randomized problems for students to practice based on constraints specified within a problem generator.\nAs users interact with dynamically generated problems, the tutors provide real-time correctness feedback. The tutors also provide of multi-layer hints in a text box below the tutor interface. We discuss hints further in the Hinting Strategy section of this paper. The Apprentice Tutors platform also has visualization dashboards that allows both students and teachers track skill mastery [12]. Apprentice Tutors allows for the seamlessly deployment of tutors to classrooms. In order to facilitate this goal, we used the Learning Tools Interoperability standards proposed by IMS Global Learning Consortium [19]. All major learning management systems comply with these standards and allow educational technologies to be embedded into popular learning management systems, such as Blackboard and Canvas."}, {"title": "3.2 Apprentice Tutors Topics", "content": "In our study, we developed tutoring systems for four College Algebra topics: radicals, exponents, factoring polynomials, and rational equations (see Figure 1). These tutors were conducted based on course curriculum overlap with the units corresponding to the radicals, exponents, factoring polynomials, and the rational equations course sections. Further, within each tutor, we created several problem types that align with the questions in the course textbook and curriculum. For example, the exponents unit contains problem sets including exponents power rule, exponents product rule, and exponents quotient rule. Therefore, we created individual tutor problems for each one of these problem types. Building our tutors closely with synergy with course content is hypothesized to increase interest and academic relevance to our target users."}, {"title": "3.3 Building Expert Models", "content": "Building an expert model for a complex tutor interface with many steps can be challenging. Development is further complicated, when the the steps depend on one another in complex ways. Another challenge lies in developing generalized expert models that operate effectively across an unrestricted to a specific set of problems. To overcome these challenges, we adopted the standard cognitive tutor approach and implemented our an expert model using production rules. We authored productions for each step and our production engine (a Python-based system that implements the algorithm outlined by Doorenbos [9]) composes these productions at runtime to support the full range of variation in inputs. Each problem type within a tutor has its corresponding problem interface, export model, and problem generator. The export model enables the tutor to provide correctness feedback and context-sensitive hints. While programming an export model for each problem type is time intensive, it allows us to build tutors that can function across a wide variety of randomly generated initial problems."}, {"title": "3.4 Real-Time Correctness Feedback", "content": "Productions rules in our system have two types of components: conditions and a function. When a learner enters a value into a tutor interface, the state of the tutor prior to their input along with their input is analyzed. All the productions that have conditions matching the tutor state are collected and their functions are executed. If the student's input matches the outputs of any of the production functions, then the student's input is marked as correct. In this case, the field they entered the value into is highlighted in green and it is disabled, so they cannot edit it further. This prompts the user to move forward to the next step. On the contrary, when the student's input does not match the output of any of the production functions, then it is marked as incorrect. In this case, the field containing their input is highlighted in red, prompting the user retry the step. This functionality lets each tutor provide real-time correctness feedback to users (as seen in Figure 1, part B)."}, {"title": "3.5 Hinting Strategy", "content": "Each tutor features a dedicated hint box at the bottom of the problem interface, providing users with the ability to request help. We have implemented multiple layers of hints for each problem type, allowing users to access up to three tiers of assistance (as seen in Figure 1, section D). In the initial hint, the specific step under consideration is highlighted, and the user is prompted with a message encouraging them to tackle the particular step. At the second hint level, an explanatory message is delivered in the hint box, offering guidance on how to approach solving the step. In the final hint tier, the solution to the step is revealed-effectively providing the learner with a worked example. Users have the option to enter this solution into the input box, which will subsequently mark the question as correct. Every instance of a user activating the hint button is logged in the Apprentice Tutors database."}, {"title": "3.6 Adaptive Problem Selection", "content": "The Apprentice Tutors platform provides a personalized tutoring experience through the adaptive problem selection option (as seen in Figure 1, section A). While each Apprentice tutor has this personalized tab, this is optional and learners may opt to click on a problem type directly. The adaptive problem selection option personalizes the student's learning experience by providing them with problems that exercise skills they have not yet mastered. Actions such as entering a tutor step or requesting a hint are logged within the tutoring database. Apprentice Tutors uses these logs to track the progression of students' skills. We refer to each one of these logged steps as a tutor transaction. Each tutor transaction references a skills within the tutor's problem type, represented by knowledge components (also referred to as KCs). Our hypothesized KCs are defined as acquired units of cognitive function that can be inferred from performance on a set of related tasks [15]. We use Bayesian Knowledge Tracing (BKT) [8] to assess student mastery of each skill. BKT is a theory that models a student's learning using a hidden Markov model. It is commonly used in intelligent tutoring systems [34]. The idea behind BKT is that a student's competency is not fixed; as a student interacts with a problem, their competency improves. BKT assumes that initially, a student may not know a concept but can achieve mastery of the concept over time with practice. Based on BKT's estimates, adaptive problem selection randomly selects problems for students to practice that exercise at least one unmastered skill."}, {"title": "3.7 Performance Visualization Dashboards", "content": "Visualizations of learner trajectories are increasingly utilized to comprehend student activity and their navigation through course content [11, 18]. To facilitate the visualization of skill progression for both students and teachers engaging with the tutors on our platform, we developed a straightforward visualization dashboard. This dashboard displays the mastery level of each Knowledge Component (KC), broken down by the specific problems in which these KCs are encountered (as seen in Figure 1, part E)."}, {"title": "4 STUDY 1: TUTOR ADOPTION ACROSS DEPLOYMENTS", "content": "To investigate the challenges preventing adult learners from adopting intelligent tutors, we deployed our tutoring systems as an optional supplement in several sections of Math 1111 (an introductory College Algebra course). A substantial body of research has consistently demonstrated improvements in user competency through practice with intelligent tutoring systems [16, 23]. However, this research does not assess the tutoring systems in terms of their usage and adoption rates. In cases where people can choose whether or not they use the tutors and there are no extrinsic motivators to use the tutors, such as a payment or grade. Moreover, current research primarily focuses on the effects of deploying intelligent tutors in K-12 educational settings [1, 14, 16]. Building upon this foundation, we extend the deployment of tutors to adult learners, for whom engagement with the tutors is not mandatory. Gaining a deeper insight into the patterns of tutor adoption and usage over time, as well as the specific needs of adult learners, can provide valuable guidance for educational technology developers looking to have an enduring and sustained impact."}, {"title": "4.1 Methods", "content": "We introduced four Apprentice Tutors into several College Algebra course sections at a state technical college for the academic year spanning from September 2021 to June 2022. The institution we worked with is not a typical four-year college-the longest degree offered is a two-year degrees. It primarily serves non-traditional adult learners that are returning to school to acquire new skills to support their career goals.\nTo address the limitations in existing research, our study focuses on adult learners as a key user population for intelligent tutoring systems. Adult learners present unique challenges and opportunities due to their distinct motivations, cognitive developmental differences, and the voluntary nature of their engagement with educational technology. By concentrating on this population, we aim to explore the sociotechnical factors influencing ITS adoption and usage in self-directed learning contexts. This focus allows us to investigate how adult learners' lived experiences and specific needs impact their interaction with ITS, potentially leading to more tailored design recommendations. Furthermore, given the increasing importance of lifelong learning and skill development in the modern workforce, insights gained from studying adult learners could have broader implications for the future of education and training.\nDuring the deployment, learners accessed the tutors through the Blackboard Learn system. Student use of the tutors was entirely voluntary, with no credit or payment offered for their utilization. Prior to and throughout our deployment, we engaged teachers via email communications and presentations at their monthly department meetings to inform them about the tutors, their features, and the potential benefits for their students. Before commencing our study, we obtained approval from our institutional review board. Upon first accessing a tutor, students were prompted to consent to participate in our study. Those who did not consent could still use the tutor, but their data was not collected or analyzed. For consenting students, we gathered data on their usage, including access times, tutor interactions, and student-course correlations to understand how students discovered the Apprentice Tutors."}, {"title": "4.2 Results", "content": "During the deployment period, 3,510 students were granted access to the Apprentice Tutors. Figure 2 illustrates the funnel conversion of users across the first four quarters of deployment. To evaluate adoption, we calculated the percentage of students with access who clicked the link to use the tutors at least once. Across the four quarters, the overall adoption rate was approximately 14.8%. As the deployment scaled from 4 to 58 classes, the engagement rate declined from 62.84\nTo further assess adoption, we calculated the percentage of students who accessed the tutors and subsequently solved more than one problem. A slight decrease was observed in this metric, from 17% in the first quarter to 14% in the fourth quarter. Notably, the highest engagement occurred during the second quarter, where 22% of students who accessed the tutors completed more than one problem.\nOf the 3,510 students, 520 actively accessed the tutors (Figure 2). Among these, 361 students did not complete any problems. This engagement behavior was monitored by logging user actions, including button clicks, hint requests, and keyboard inputs. Of the 520 students who accessed the tutors, 158 solved at least one problem. A problem was considered complete when a student correctly answered all steps and clicked the \"done\" button. Moreover, 81 of the 158 students who solved at least one problem continued to solve five or more problems using the Apprentice Tutors."}, {"title": "4.2.1 Usage and Adoption.", "content": "During the deployment period, 3,510 students were granted access to the Apprentice Tutors. Figure 2 illustrates the funnel conversion of users across the first four quarters of deployment. To evaluate adoption, we calculated the percentage of students with access who clicked the link to use the tutors at least once. Across the four quarters, the overall adoption rate was approximately 14.8%. As the deployment scaled from 4 to 58 classes, the engagement rate declined from 62.84\nTo further assess adoption, we calculated the percentage of students who accessed the tutors and subsequently solved more than one problem. A slight decrease was observed in this metric, from 17% in the first quarter to 14% in the fourth quarter. Notably, the highest engagement occurred during the second quarter, where 22% of students who accessed the tutors completed more than one problem.\nOf the 3,510 students, 520 actively accessed the tutors (Figure 2). Among these, 361 students did not complete any problems. This engagement behavior was monitored by logging user actions, including button clicks, hint requests, and keyboard inputs. Of the 520 students who accessed the tutors, 158 solved at least one problem. A problem was considered complete when a student correctly answered all steps and clicked the \"done\" button. Moreover, 81 of the 158 students who solved at least one problem continued to solve five or more problems using the Apprentice Tutors."}, {"title": "4.3 Discussion", "content": "Throughout the first year of deployment, we observed a decrease in overall usage and adoption of the tutors as the scale of deployment increased through each quarter of the academic year. This trend highlights a key challenge in deploying intelligent tutoring systems (ITS) to adult learners at larger scales. One explanation for this finding is that as we expanded Apprentice Tutors to more class sections (and instructors), our ability to individually engage with each instructor diminished. This suggests that instructor buy-in plays a crucial role in promoting ITS adoption among adult learners, particularly in voluntary usage contexts.\nTo address this challenge in future large-scale deployments targeting adult learners, we propose two potential strategies. First, developing a robust tutorial that clearly demonstrates the benefits and functionality of the ITS could help mitigate the barrier of understanding, especially in situations where one-on-one interaction with instructors is not feasible. Second, exploring ways to automate engagement with both instructors and adult learners could be a promising area for future research, potentially leveraging personalized communication strategies that resonate with the motivations and needs of adult learners.\nDespite the decreased adoption rates, we observed encouraging signs of user retention in tutor usage. Of the 158 students who solved at least 1 problem, 51% of students continued to use the tutors to complete over five problems. This signifies strong user retention of students who utilized the tutors. While these results provide preliminary evidence that our tutors support learning and usage retention amongst adult users, more research is needed to causally measure the effect of tutors on adult learning outcomes. Future studies could employ A/B experiments or randomized controlled trials specifically designed for adult learning contexts, taking into account factors such as prior knowledge, time constraints, and motivational factors unique to adult learners. Such research would contribute to a better understanding of how ITS can be optimized to support the specific needs and learning patterns of adult learners in voluntary educational settings."}, {"title": "5 STUDY 2: QUALITATIVE INVESTIGATION OF CHALLENGES", "content": "The deployment of Apprentice tutors exhibited a positive impact on learner performance. Despite this, the overall adoption rate of these tutoring systems remained modest, at 14.8% from four quarters of deployment. Meaning, 14.8% of the overall students that had access to the tutors, used it at least once. Our quantitative metrics suggest an inverse relationship between deployment scale and adoption rates. A plausible reason the for lower tutor adoption over time may have been the decrease in direct teacher support as the tutor deployment scaled. This support included a nudge approach, to remind the teachers to further remind their students that the tutors were available as a resource to utilize."}, {"title": "5.1 Methods", "content": "To investigate our research questions, we conducted five semi-structured focus group sessions with both students (who used the tutors) and teachers (who agreed to tutors being deployed in their classrooms). We recruited participants through snowball sampling, through direct e-mails and newsletter postings. Throughout the five sessions, we collected data from fifty-three participants, which consisted of forty-two students and eleven teachers. Participation in these focus groups were optional and a fifteen dollar gift card was available to the participants after the completion of the session. For the purposes of these focus groups, age and demographics were not used in the filtering or selection of the participants. All of the participants were located in the United States, and all focus groups were conducted virtually. All virtual focus groups were about 60 minutes."}, {"title": "5.1.1 Recruitment.", "content": "To investigate our research questions, we conducted five semi-structured focus group sessions with both students (who used the tutors) and teachers (who agreed to tutors being deployed in their classrooms). We recruited participants through snowball sampling, through direct e-mails and newsletter postings. Throughout the five sessions, we collected data from fifty-three participants, which consisted of forty-two students and eleven teachers. Participation in these focus groups were optional and a fifteen dollar gift card was available to the participants after the completion of the session. For the purposes of these focus groups, age and demographics were not used in the filtering or selection of the participants. All of the participants were located in the United States, and all focus groups were conducted virtually. All virtual focus groups were about 60 minutes."}, {"title": "5.1.2 Data Collection.", "content": "All participants provided written consent to participate in the focus group before beginning the sessions. The discussions were grounded in key experiential feedback of how the participants reacted to the tutoring systems. The discussions were led by moderators who guided participants through a series of open-ended questions stated below.\n\u2022 Describe the main benefits of the tutors?\n\u2022 Describe any frustrations in using the tutors?\n\u2022 Were the hints provided adequate?\n\u2022 Were you able to easily understand how to use the tutors?\n\u2022 Describe your comfort in recommending the tutors?\n\u2022 Did the tutors reflect the course material correctly?\n\u2022 Is there anything else you would like to add to the tutors?\nThe prompts presented were open-ended and semi-flexible, where we gave participants the opportunity to reflect more broadly on their experiences through other academic experiences."}, {"title": "5.1.3 Data Analysis.", "content": "We stored video recording and automatic verbatim transcription of the focus groups to capture data for analysis. Our analytical approach utilized Braun and Clarke's reflexive thematic analysis framework [4-6]. This method, grounded in a post-positivist paradigm, emphasizes the researcher's active role in knowledge creation and considers the philosophical and theoretical underpinnings of the analytical process [5]. Reflexive thematic analysis offers greater flexibility compared to methods involving codebook development and inter-rater reliability calculations, allowing for a more dynamic engagement with the data while maintaining analytical rigor [5]. Furthermore, this approach facilitates collaborative theme construction through ongoing dialogue among researchers.\nSix authors participated in the data analysis process, which was conducted entirely virtually over a three-week period. We held four 90-minute collaborative sessions, following the analysis process outlined by Braun and Clarke [2006]. Each author coded approximately eight to nine transcripts, collectively generating several hundred codes. We engaged in continuous discussions about codes, themes, and key findings throughout each session.\nTo facilitate our collaborative analysis, we utilized Miro, an online virtual whiteboard tool, for organizing and categorizing codes. Subsequent sessions involved in-depth reviews and discussions of the codes to construct themes from the coded data. This approach allowed for open exploration of ideas without preconceived categories. Table 1 presents our resulting taxonomy, outlining overall themes, sub-themes, and coded data. While this table offers a simplified representation of the themes and quotes underlying our core recommendations, our complete analysis yielded 17 recommendations and 48 themes derived from several hundred coded quotes.\nThis methodological approach allowed us to systematically analyze the rich data from our focus groups, ensuring a thorough exploration of adult learners' needs and experiences with AI-powered tutoring systems."}, {"title": "5.2 Findings", "content": "Our analysis of the focus group data centered on identifying the key needs of adult learners that AI-powered tutoring systems could potentially address. We employed a bottom-up analytical approach, within Miro, to map raw data onto color-coded digital post-it notes. Through iterative analysis, we identified several emergent themes, which are summarized in Table 1. This table presents the main theme categories, specific themes, and exemplar user needs within each theme.\nThe analysis yielded five primary categories of insights: perceptions of Al support, need for enhanced explanatory capabilities, pathways for improved authoring tools adoption, usability and value adoption considerations, and suggestions for additional features. Each category encapsulates the concerns, preferences, and recommendations of various stakeholders, highlighting areas for potential enhancement in AI tutoring technologies to better serve adult learners and their educators.\nA prominent theme that emerged was the perceived value of AI tutors' \"superhuman\" capabilities. Participants appreciated the systems' ability to provide support in situations where human teachers might be unavailable or less effective. One student emphasized the importance of flexibility: \"The flexibility is key-balancing school, work, and other commitments, the ability to access the tutor anytime, anywhere, like during a lunch break, is incredibly beneficial.\" This sentiment was echoed by an educator who noted: \"Knowing that students have access to help anytime removes barriers to learning. It addresses common excuses, such as not finding help late at night, by providing a resource like our exponent tutors available at all hours.\" These remarks support our initial hypothesis regarding the suitability of AI tutors for adult learners, highlighting the value placed on flexible, round-the-clock support.\nOur focus groups with teachers and students revealed recurring feedback regarding tutor requirements. The data suggested that adoption might improve if tutors were: (a) easy to understand, (b) easy to navigate, and (c) user-friendly. As one teacher articulated:"}, {"title": "5.3 Discussion", "content": "Our focus group sessions and subsequent data analysis revealed a nuanced landscape of stakeholder perceptions regarding AI tutors in educational settings. While we previously discussed and highlighted the positive aspects and potential of AI tutors, this discussion focuses on additional insights and challenges that emerged from our study, that may ultimately prevent the adoption of AI tutors amongst adult users.\nOne finding was the particular value of AI tutors for non-traditional students returning to education after a significant hiatus. A participant in our focus group noted: \"I find it particularly helpful, especially considering my background of studying math in high school and then revisiting it many years later. Back in my high school days, we didn't have access to such technology.\" adult learners who may have been away from formal education for extended periods may find intelligent tutors as a facilitator to improved academic re-engagement.\nDespite the positive experiences, our study also uncovered instances of user frustration, primarily stemming from difficulties in understanding how to operate the tutors and integrate them into the broader learning experience. These challenges were particularly pronounced in situations where direct collaboration with teachers was limited. A recurring suggestion from stakeholders was the inclusion of tutorials or instructional videos to demonstrate the functionality of each tutor. As one participant astutely observed: \"I know it sounds somewhat humorous to suggest a tutorial for the tutor, but based on the feedback we've received from you and others, it seems like a necessary addition.\" This finding highlights the importance of clear onboarding processes to maximize the benefits of AI tutoring systems.\nAn unexpected discovery was the diversity in teaching approaches among instructors for the same subject matter. When scaling the tutors developed in collaboration with a subset of College Algebra teachers to other class sections, we encountered confusion among teachers whose instructional methods differed from those embedded in the tutors. This variance in teaching styles led some instructors to stop encouraging students from using the tutors when they perceived a misalignment with their preferred teaching approaches. This insight suggests that the development of customizable authoring tools, allowing teachers to tailor tutor operation to their specific pedagogical preferences, could significantly enhance adoption rates.\nThese findings collectively underscore the complexity of integrating AI tutors into diverse educational environments. While our previous sections highlighted the potential benefits and recommendations for improvement, this discussion reveals the intricate interplay between technology, pedagogy, and individual teaching styles. Future development of AI tutoring systems should consider these factors to create more adaptable and widely accepted educational tools. To address these challenges, further research could explore:\n\u2022 Development of adaptive onboarding processes that cater to users with varying levels of technology proficiency.\n\u2022 Creation of flexible authoring tools that allow for easy customization of tutor content and teaching approaches.\n\u2022 Strategies for fostering collaboration between AI developers and a broader spectrum of educators to ensure more comprehensive alignment with diverse teaching methods.\nBy addressing these areas, AI tutoring systems can potentially overcome the identified barriers to adoption and more effectively serve the needs of adult learners and their instructors in various educational contexts."}, {"title": "6 LIMITATION AND FUTURE WORKS", "content": "We built the Apprentice Tutors platform as a testbed for investigating how to design and deploy tutors for adult learning contexts. Through our deployment across an academic year, we identified several limitations which may have have impacted overall tutor usage and adoption. A primary concern is the lack of incentive for teachers to adopt these technologies in the classroom. Teachers' busy schedules demand tutors that integrate seamlessly into their existing workflows without requiring a steep learning curve.\nOur findings indicate hesitation from teachers, partly because our system only covered initial course chapters, and the absence of a convincing demonstration of the tutors' effectiveness through visual representation of student performance. To overcome these limitations, our future work will focus on redesigning the tutors based on the recommendations provided, incorporating instructional materials such as textbook resources and lecture videos. This will enhance the learning experience by providing more comprehensive hints and aligning more closely with course content.\nAdditionally, we aim to expand the coverage of our tutors to include a wider spectrum of course content and integrate model tracing in tandem with knowledge tracing and learning analytics visualizations, offering teachers (and students) robust tools for tracking progress and better understanding problem-solving steps. For future research, we plan to redeploy these improved tutors and monitor their impact over time through longitudinal studies across multiple deployments. Such studies will help us better understand how to construct scalable pedagogical technologies for effective tutoring in the adult learning context."}, {"title": "7 CONCLUSION", "content": "The use of intelligent tutoring systems has shown promise in improving student learning outcomes cost-effectively, offering benefits comparable to personalized human tutoring [31"}]}