{"title": "An Automatic Sound and Complete Abstraction Method for Generalized Planning with Baggable Types", "authors": ["Hao Dong", "Zheyuan Shi", "Hemeng Zeng", "Yongmei Liu"], "abstract": "Generalized planning is concerned with how to find a single plan to solve multiple similar planning instances. Abstractions are widely used for solving generalized planning, and QNP (qualitative numeric planning) is a popular abstract model. Recently, Cui et al. showed that a plan solves a sound and complete abstraction of a generalized planning problem if and only if the refined plan solves the original problem. However, existing work on automatic abstraction for generalized planning can hardly guarantee soundness let alone completeness. In this paper, we propose an automatic sound and complete abstraction method for generalized planning with baggable types. We use a variant of QNP, called bounded QNP (BQNP), where integer variables are increased or decreased by only one. Since BQNP is undecidable, we propose and implement a sound but incomplete solver for BQNP. We present an automatic method to abstract a BQNP problem from a classical planning instance with baggable types. The basic idea for abstraction is to introduce a counter for each bag of indistinguishable tuples of objects. We define a class of domains called proper baggable domains, and show that for such domains, the BQNP problem got by our automatic method is a sound and complete abstraction for a generalized planning problem whose instances share the same bags with the given instance but the sizes of the bags might be different. Thus, the refined plan of a solution to the BQNP problem is a solution to the generalized planning problem. Finally, we implement our abstraction method and experiments on a number of domains demonstrate the promise of our approach.", "sections": [{"title": "Introduction", "content": "Generalized planning (g-planning in short), where a single plan works for multiple planning instances, remains a challenging problem in the AI community (Levesque 2005; Srivastava, Immerman, and Zilberstein 2008; Hu and De Giacomo 2011; Aguas, Celorrio, and Jonsson 2016; Bonet and Geffner 2018; Illanes and McIlraith 2019; Franc\u00e8s, Bonet, and Geffner 2021). Computing general solutions with correctness guarantees is a key problem in g-planning.\nAbstraction methods play an important role in solving g-planning problems. The idea is to abstract a given low-level (LL) problem to get a high-level (HL) problem, solve it and then map the solution back to the original problem. Based on the agent abstraction framework of Banihashemi, De Giacomo, and Lesp\u00e9rance (2017), Cui, Liu, and Luo (2021) proposed a uniform abstraction framework for g-planning. Cui, Kuang, and Liu (2023) proposed an automatic verification method for sound abstractions of g-planning problems.\nQualitative numeric planning (QNP) (Srivastava et al. 2011), an extension of classical planning with non-negative real variables that can be increased or decreased by some arbitrary amount, has been a popular abstract model for g-planning. A number of QNP solvers have been developed, including FONDASP (Rodriguez et al. 2021) and DSET (Zeng, Liang, and Liu 2022). Bonet and Geffner (2018) abstracted a class of g-planning problems into QNP problems. In recent years, the automatic generation of abstractions for g-planning has attracted the attention of researchers. Bonet, Franc\u00e8s, and Geffner (2019) learned a QNP abstraction of a g-planning problem from a sample set of instances, however, the abstraction is only guaranteed to be sound for sample instances. Bonet et al. (2019) showed how to obtain a first-order formula that defines a set of instances on which the abstraction is sound. Illanes and McIlraith (2019) considered a class of g-planning problems called quantified planning problems based on the idea of quantifying over sets of similar objects, and adapted QNP techniques to produce general solutions. They also proposed to use the work by Riddle et al. (2016) to build a quantified planning problem out of a planning instance. However, they did not address the soundness and completeness issues of their abstraction method. A closely related line of work is reformulation (Riddle et al. 2016; Fuentetaja and de la Rosa 2016), where to reduce the state space, a classical planning instance is reformulated by quantifying over indistinguishable objects.\nIn this paper, we propose an automatic method to abstract a QNP problem from a classical planning instance with baggable types. We use a variant of QNP, called bounded QNP (BQNP), where integer variables are only increased or decreased by one. The basic idea for abstraction is to introduce a counter for each bag of indistinguishable tuples of objects. The reason we use BQNP instead of QNP as our abstract model is that our target abstract actions are those"}, {"title": "Preliminaries", "content": "Situation Calculus\nThe situation calculus (Reiter 2001) is a many-sorted first-order language with some second-order ingredients suitable for describing dynamic worlds. There are three disjoint sorts: action for actions, situation for situations, and object for everything else. The language also has the following components: a situation constant $S_0$ denoting the initial situation; a binary function $do(a, s)$ denoting the successor situation to s resulting from performing action a; a binary relation $Poss(a, s)$ indicating that action a is possible in situation s; a set of relational (functional) fluents, i.e., predicates (functions) taking a situation term as their last argument. We call a formula with all situation arguments eliminated a situation-suppressed formula $\\phi$. We use $\\phi[s]$ to denote the formula obtained from $\\phi$ by restoring s as the situation arguments to all fluents.\nIn the situation calculus, a particular domain of application can be specified by a basic action theory (BAT) of the form $\\mathcal{D} = \\Sigma \\cup \\mathcal{D}_{ap} \\cup \\mathcal{D}_{ss} \\cup \\mathcal{D}_{una} \\cup \\mathcal{D}_{so}$, where $\\Sigma$ is the set of the foundational axioms for situations, $\\mathcal{D}_{ap}$, $\\mathcal{D}_{ss}$ and $\\mathcal{D}_{una}$ are the sets of action precondition axioms, successor state axioms, unique name axioms for actions, and $\\mathcal{D}_{so}$ is the initial knowledge base stating facts about $S_0$.\nLevesque et al. (1997) introduced a high-level programming language Golog with the following syntax:\n$\\delta ::= \\alpha \\mid \\phi? \\mid \\delta_1; \\delta_2 \\mid \\delta_1|\\delta_2 \\mid \\pi x.\\delta \\mid \\delta^*$,\nwhere a is an action term; $\\phi?$ is a test; $\\delta_1; \\delta_2$ is sequential composition; $\\delta_1 | \\delta_2$ is non-deterministic choice; $\\pi x.\\delta$ is non-deterministic choice of action parameter; and $\\delta^*$ is nondeterministic iteration. The semantics of Golog is defined using an abbreviation $Do(\\delta, s, s')$, meaning that executing the program $\\delta$ in situation s will result in situation s'.\nThe counting ability of first-order logic is very limited. Kuske and Schweikardt (2017) extended FOL by counting, getting a new logic FOCN. The key construct of FOCN are"}, {"title": null, "content": "counting terms of the form $\\#\\bar{y}.\\phi$, meaning the number of tuples $\\bar{y}$ satisfying formula $\\phi$. The situation calculus has been extended with counting by, e.g., Zarrie\u00df and Cla\u00dfen (2016).\nSTRIPS\nDefinition 1. A STRIPS domain is a tuple $\\mathcal{D} = (\\mathcal{T}, \\mathcal{P}, \\mathcal{A})$, where $\\mathcal{T}$ is a set of object types, $\\mathcal{P}$ is a set of predicates and $\\mathcal{A}$ is a set of actions, every $a \\in \\mathcal{A}$ consists of preconditions $pre(a)$, add list $add(a)$ and delete list $del(a)$, where $pre(a)$ is a formula that must be satisfied before a is executed, $add(a)$ is a set of the true ground atoms after doing a, and $del(a)$ is a set of the false ground atoms after performing a.\nDefinition 2. A STRIPS planning instance is a tuple $P = (\\mathcal{D}, \\mathcal{O}, I, G)$, where $\\mathcal{D}$ is a STRIPS domain, $\\mathcal{O}$ is a set of objects of different types, $I$, the initial state, is a set of ground atoms made from predicates in $\\mathcal{P}$ and objects in $\\mathcal{O}$, and $G$, the goal condition, is a set of ground atoms.\nGiven a STRIPS domain, it is easy to write its BAT $\\mathcal{D}$. We omit the details here.\nExample 1 (Gripper World). The Gripper domain involves a robot with several grippers and a number of balls at different rooms. The robot robby can move between rooms and each gripper may carry one ball a time. The predicates are: $at(b, r)$ denotes ball b is at room r; $white(b)$ means b is white; $black(b)$ means b is black; $carry(b, g)$ denotes gripper g carries b; $free(g)$ denotes g is free; $HE(g)$ denotes g is high energy; $LE(g)$ denotes g is low energy; $at\\_robby(r)$ denotes robby is at r. The actions are: $move(r\\_from,r\\_to)$ denotes robby moves from one room to another room; $charge(g)$ denotes charging g; $drop(b, g,r)$ denotes g drops b at r; $pick(b, g, r)$ denotes g picks b at r, where\n*   $pre = {at(b,r), free(g), at\\_robby(r), HE(g)}$;\n*   $eff = {carry(b, g), LE(g), \\neg at(b, r), \\neg free(g), \\neg HE(g)}$.\nBelow is a planning instance $P = (\\mathcal{D}, O, I, G)$, where\n*   $O = {b_1, b_2, b_3, b_4, b_5, b_6, b_7, b_8, g_1, g_2, r_1,r_2}$;\n*   $I = {at(b_1, r_1), at(b_2, r_1), at(b_3, r_1), at(b_4, r_1), at(b_5, r_2), at(b_6, r_2), at(b_7, r_2), at(b_8, r_2), white(b_1), white(b_2), white(b_3), white(b_4), black(b_5), black(b_6), black(b_7), black(b_8), free(g_1), free(g_2), HE(g_1), HE(g_2), at\\_robby(r_1)}$;\n*   $G = {at(b_1, r_2), at(b_2, r_2), at(b_3, r_2), at(b_4, r_2), at(b_5, r_1), at(b_6, r_1), at(b_7, r_1), at(b_8, r_1)}$.\nQualitative Numeric Planning (QNP)\nQNP is classical planning extended with numerical variables that can be decreased or increased by arbitrary amount (Srivastava et al. 2011). Given a set of non-negative numerical variables VN and a set of propositional variables VB, L denotes the class of all consistent sets of literals of the form $N > 0$ and $N = 0$ for $N \\in VN$, $B$ and $\\neg B$ for $B \\in VB$.\nDefinition 3. A QNP problem is a tuple $Q = (VN, VB, Init, Goal, Ops)$ where VN is a set of non-negative numeric variables, VB is a set of propositional vari-ables, Ops is a set of actions, every $op \\in Ops$ has a set of preconditions $pre(op) \\in L$, and effects $eff(op)$, $Init \\in L$"}, {"title": null, "content": "is the initial state, $Goal \\in L$ is the goal condition. Propositional effects of $eff(op)$ contain literals of the form $B$ and $\\neg B$ for $B \\in VB$. Numeric effects of $eff(op)$ contain special atoms of the form $inc(N)$ or $dec(N)$ for $N \\in VN$ which increase or decrease N by an arbitrary amount.\nA qualitative state (qstate) of $Q$ is an element of $L$ in which each variable has a corresponding literal. A state of $Q$ is an assignment of non-negative values to all $N \\in VN$ and of truth values to $B \\in VB$. An instance of $Q$ is a numerical planning instance $Q = \\langle VN, VB, s_0, Goal, Ops\\rangle$ which replaces $Init$ with a state $s_0$ satisfying $Init$.\nA policy for a QNP problem $Q$ is a partial mapping from qstates into actions. Given a policy $\\pi$, a $\\pi$-trajectory is a sequence of states $s_0,s_1,...$ (finite or infinite) s.t. for all $i \\ge 0$, $s_{i+1}$ can be resulted from performing $\\pi(s_i)$ in $s_i$, where $s_i$ is the qstate satisfied by $s_i$.\nWe omit the definitions that $\\pi$ terminates for $Q$ and $\\pi$ solves $Q$. Srivastava et al. (2011) introduced a sound and complete algorithm SIEVE, which tests whether a policy $\\pi$ for Q terminates. Given $G$, the qstate transition graph induced by Q and $\\pi$, SIEVE iteratively removes edges from G until G becomes acyclic or no more edges can be removed. Then $\\pi$ terminates iff G is acyclic.\nAbstraction for Generalized Planning\nCui, Liu, and Luo (2021) proposed a uniform abstraction framework for g-planning, which we adapt to our setting.\nDefinition 4. A g-planning problem is a tuple $\\mathcal{G} = (\\mathcal{D},\\mathcal{G})$, where $\\mathcal{D}$ is a BAT and $\\mathcal{G}$ is a goal condition.\nA solution to a g-planning problem $\\mathcal{G} = (\\mathcal{D},\\mathcal{G})$ is a Golog program $\\delta$ s.t. for any model M of $\\mathcal{D}$, $\\delta$ terminates and achieves the goal. We omit the formal definition here.\nDefinition 5 (refinement mapping). A function $m$ is a refinement mapping from the HL g-planning problem $\\mathcal{G}_h = (\\mathcal{D}_h, \\mathcal{G}_h)$ to the LL g-planning problem $\\mathcal{G}_l = (\\mathcal{D}_l, \\mathcal{G}_l)$ if for each HL action type $A$, $m(A(\\bar{x})) = d_{\\bar{x}}(\\bar{x})$, where $d_{\\bar{x}}(\\bar{x})$ is a LL program; for each HL relational fluent $P$, $m(P(\\bar{x})) = p(\\bar{x})$, where $p(\\bar{x})$ is a LL situation-suppressed formula; for each HL functional fluent $F$, $m(F(\\bar{x})) = t_F(\\bar{x})$, where $t_F(\\bar{x})$ is a LL term, possibly a counting term.\nFor a HL formula $\\phi$, $m(\\phi)$ denotes the formula resulting from replacing each HL symbol in $\\phi$ with its LL definitions. For a HL program $\\delta$, $m(\\delta)$ is similarly defined.\nDefinition 6 (m-isomorphism). Given a refinement mapping $m$, a situation $s_h$ of a HL model $M_h$ is m-isomorphic to a situation $s_l$ in a LL model $M_l$, written $s_h \\sim_m s_l$, if: for any HL relational fluent $P$, and variable assignment $v$, we have $M_h, v[s/s_h] \\models P(\\bar{x}, s)$ iff $M_l, v[s/s_l] \\models m(P)(\\bar{x}, s)$; for any HL functional fluent f, variable assignment $v$, we have $M_h,v[s/s_h] = f(\\bar{x},s) = y$ iff $M_l,v[s/s_l] = m(f)(\\bar{x}, s) = y$.\nProposition 1. Suppose $s_h\\sim_m s_l$. Let $\\phi$ be a HL situation-suppressed formula. Then $M_h, v[s/s_h] \\models \\phi[s]$ iff $M_l, v[s/s_l] \\models m(\\phi)[s]$.\nIn the following definition, $\\triangle$ denotes all situations of M, $S_M$ stands for the initial situation of M."}, {"title": null, "content": "Definition 7 (m-bisimulation). A relation $R \\subseteq \\triangle_{M_h} \\times \\triangle_{M_l}$ is an m-bisimulation relation, if $(S_{M_h}, S_{M_l}) \\in R$, and $(s_h, s_l) \\in R$ implies that: $s_h \\sim_m s_l$; for any HL action type $A$, and variable assignment $v$, if there is a situation $s'$ s.t. $M_l, v[s/s_l, s'/s'_l] \\models Do(m(A(\\bar{x})), s, s')$, then there is a situation $s'_h$ s.t. $M_h,v[s/s_h,s'/s'_h] \\models Do(A(\\bar{x}), s, s')$ and $(s'_h, s'_l) \\in R$, and vice versa.\nDefinition 8. $\\mathcal{G}_h$ is a sound m-abstraction of $\\mathcal{G}_l$ if for each model $M_l$ of $\\mathcal{G}_l$, there is a model $M_h$ of $\\mathcal{G}_h$ s.t. there is an m-bisimulation relation $R$ between $M_h$ and $M_l$, and for any $(s_h, s_l) \\in R$, $M_h, v[s_h/s] \\models \\mathcal{G}_h[s]$ iff $M_l, v[s_l/s] \\models \\mathcal{G}_l[s]$.\nDefinition 9. $\\mathcal{G}_h$ is a complete m-abstraction of $\\mathcal{G}_l$ if for each model $M_h$ of $\\mathcal{G}_h$, there is a model $M_l$ of $\\mathcal{G}_l$ s.t. there is a m-simulation relation $R$ between $M_h$ and $M_l$, and for any $(s_h, s_l) \\in R$, $M_h,v[s_h/s] \\models \\mathcal{G}_h[s]$ iff $M_l, v[s_l/s] \\models \\mathcal{G}_l[s]$.\nTheorem 1. If $\\mathcal{G}_h$ is a sound and complete m-abstraction of $\\mathcal{G}_l$, then $\\delta$ solves $\\mathcal{G}_h$ iff $m(\\delta)$ solves $\\mathcal{G}_l$.\nBounded QNP\nIn this section, we consider a variant of QNP, called bounded QNP (BQNP), where numeric variables are only increased or decreased by one. Since BQNP is undecidable, we propose a sound but incomplete method to test whether a policy for a BQNP problem terminates, based on which, by adapting a characterization of QNP solutions to BQNP, we propose a sound but incomplete method for BQNP solving.\nDefinition 10. A BQNP problem is a QNP problem where numeric variables take integer values, $inc(N)$ is interpreted as: N is increased by 1, and similarly for $dec(N)$.\nDefinition 11. Given a BQNP problem $B$, a policy $\\pi$ for $B$ is a partial mapping from qualitative states to actions. A policy $\\pi$ terminates for $B$ (resp. solves $B$) if for every instance of $B$, the only $\\pi$-trajectory started from the initial state is finite (resp. goal-reaching).\nAs noted in (Srivastava et al. 2011), BQNP policies can be used to represent arbitrary abacus programs, so BQNP is undecidable. Formal proof is given in Helmert (2002).\nTheorem 2. The decision problem of solution existence for BQNP is undecidable: there is no algorithm to decide whether a BQNP problem has a solution.\nWe now analyze the relationship between QNP and BQNP. The following results follow from the definitions:\nProposition 2. Let $Q$ be a QNP problem, and let $B$ be its corresponding BQNP problem. Then\n1.  If a policy $\\pi$ terminates for $Q$, then it terminates for $B$.\n2.  If a policy $\\pi$ solves $Q$, then it solves $B$.\nZeng, Liang, and Liu (2022) gave a characterization of QNP solutions, which by a similar proof, holds for BQNP:\nProposition 3. Given the AND/OR graph G induced by a BQNP problem B, a subgraph G' of G, representing a policy for B, is a solution to B iff G' is closed, terminating, and contains a goal node."}, {"title": null, "content": "Proof. By Def. 11, the only-if direction is obvious. For the if direction, assume that there is an instance of B s.t. the only $G'$-trajectory started from the initial state terminates at a non-goal node s. Since G' is closed, s will be continued with the execution of an action, which contradicts that the trajectory terminates at s.\nHowever, for Proposition 2, the converse of neither (1) nor (2) holds. In the following, we illustrate with an example.\nExample 2. Let $Q = (VN, VB, Init, Goal, Ops)$, where $VN = {X}$, $VB = {A,B}$, $Init = {X > 0, A, \\neg B}$, $Goal = {X = 0}$ and $Ops = {a,b,c}$, where $pre(a) = {X > 0, A, B}$, $eff(a) = {dec(X), \\neg A}$, $pre(b) = {X > 0,\\neg A, B}$, $eff(b) = {dec(X), \\neg B}$, $pre(c) = {X > 0,\\neg A, \\neg B}$, $eff(c) = {inc(X), A, B}$.\nFigure 1 shows a policy for Q and the graph induced by $\\pi$. By SIEVE, $\\pi$ does not terminate for Q, and hence not a solution for Q. However, $\\pi$ terminates for B, since there is only one loop, and after each iteration of this loop, X decreases by 1. By Proposition 3, $\\pi$ is a solution for B.\nSince there are only finitely many policies, by Theorem 2 and Proposition 3, termination-testing for BQNP policies is undecidable. Motivated by Proposition 2 and Example 2, based on SIEVE, we propose a sound but incomplete algorithm (Algorithm 1), to test whether a policy $\\pi$ for a BQNP problem B terminates. In the algorithm, a SCC is a strongly connected component, and a simple loop is a loop where no node appears more than once. Given G, the qstate transition graph induced by $\\pi$, our algorithm first applies SIEVE to G and removes edges. It then returns \u201cTerminating\u201d if every remaining SCC is a simple loop g where there is a variable v s.t. the number of actions in g that decrease v is more than the number of actions in g that increase v.\nTheorem 3. Given a BQNP problem B and a policy $\\pi$, let G be the qstate transition graph induced by $\\pi$. If Termination-Test(G) returns \u201cTerminating\u201d, then $\\pi$ terminates.\nProof. By Proposition 2, if SIEVE(G) returns \"Terminating\", $\\pi$ terminates for B. By soundness of SIEVE, any potential infinite loop resides in G'. If a SCC of G' is decided \"terminates\", it cannot be executed infinitely often since the variable v eventually reaches 0 no matter how the other variables behave. When all SCCs of G' terminate, there cannot be any infinite loop in G', and thus $\\pi$ terminates.\nBased on their characterization of QNP solutions, Zeng, Liang, and Liu (2022) introduced an approach to solve a QNP by searching for a solution in the induced AND/OR"}, {"title": null, "content": "graph, and implemented a QNP solver DSET. By Prop. 3, a sound but incomplete BQNP solver can be implemented by replacing the termination test in DSET with Alg. 1.\nSrivastava (2023) proposed a policy termination test algorithm for the QNP variant with deterministic semantics, where numeric variables are only increased or decreased by a fixed discrete quantity. The algorithm leverages classic results from graph theory involving directed elimination trees and their quotient graphs to compute all \u201cprogress\u201d variables that change in only one direction (either increasing or decreasing), which are then used to identify all the edges that can be removed. In contrast, our termination test algorithm is specifically tailored for BQNP, is more intuitive and easier to implement.\nOur Abstraction Method\nIn this section, we show how to abstract a given planning instance P of a baggable domain into a BQNP problem $B_P$. The basic idea is to introduce a counter for each bag of indistinguishable tuples of objects.\nBaggable Domains and Bags\nIf two objects can co-occur as the arguments of the same predicate or action, then they can be distinguished by the predicate or action. Thus we first define single types. A baggable type has to be a single type.\nDefinition 12. For a domain $D = (\\mathcal{T}, \\mathcal{P}, \\mathcal{A})$, a type $t \\in \\mathcal{T}$ is single if there is no predicate $p \\in \\mathcal{P}$ or action schema $a \\in \\mathcal{A}$ having more than one type $t$ argument.\nDefinition 13. Let t be a single type, and M a set of predicates involving t, called a predicate group for t. The mutex group formula of M for t, denoted by $\\Phi_M$, is defined as: $\\forall x.\\Sigma_{p\\in M} \\# \\bar{z}.p(x, \\bar{z}) = 1$, where x is of type t.\nIntuitively, $\\Phi_M$ means: for any object e of type t, there is only one predicate $p \\in M$ and only one $\\bar{u}$ s.t. $p(e, \\bar{u})$ holds."}, {"title": null, "content": "Definition 14. Let $\\mathcal{D}$ be a STRIPS domain. We use $\\mathcal{D}$ for its BAT. Let $\\Pi$ be a set consisting of a set $\\Pi_t$ of predicate groups for each single type t. Let $TS$ denote the set of all single types. We use $\\Phi_{\\Pi}$ to denote $\\bigwedge_{t \\in TS, M \\in \\Pi_t} \\Phi_M$, i.e., the conjunction of all mutex group formulas. We say $\\Pi$ is a mutex invariant if $\\mathcal{D}_{ap} \\cup \\mathcal{D}_{ss} \\cup \\mathcal{D}_{una} \\vdash$\n$\\forall s\\forall a.\\pi[s] \\wedge Poss(a, s) \\supset \\Phi_{\\Pi}[do(a, s)].$\nSo $\\Pi$ is a mutex invariant means: if $\\Phi_{\\Pi}$ holds in a state, it continues to hold in any successor state resulting from an executable action. If $\\Pi$ is a mutex invariant, we call each predicate group in $\\Pi_t$ a mutex group for t.\nNote that in this paper, we ensure that a mutex group is a state constraint, i.e., holds in any reachable state, by ensuring 1) it holds in the initial states, as will be seen later in the paper; 2) the set of all mutex groups forms a state invariant, as required in the above definition.\nDefinition 15. Let D be a STRIPS domain. A baggable type is a single type t s.t. predicates involving t are partitioned into mutex groups. We say that D is a baggable domain if there are baggable types.\nSo if a predicate p involves two baggable types $t_1$ and $t_2$, p must belong to both a mutex group of $t_1$ and a mutex group of $t_2$. Thus true atoms of p induce a 1-1 correspondence between objects of $t_1$ and $t_2$. For Example 1, true atoms of $carry(b, g)$ induce a bijection between balls and grippers. This means each gripper can only carry one ball.\nFor Example 1, types ball and gripper are baggable, but type room is not. The mutex groups of ball are: $M_1 = {at(b, r), carry(b,g)}$ and $M_2 = {white(b), black(b)}$. The mutex groups of gripper are: $M_3 = {free(g), carry(b, g)}$ and $M_4 = {HE(g), LE(g)}$.\nIn the rest of the section, we assume a baggable domain $\\mathcal{D} = (\\mathcal{T}, \\mathcal{P}, \\mathcal{A})$ with mutex invariant $\\Pi$ and we fix a planning instance $P = (\\mathcal{D},O, I,G)$ s.t. $I \\models \\Phi_{\\Pi}$.\nWe now introduce some notation used throughout this paper. We use $T_B$ to denote the set of baggable types. Since a predicate does not contain different arguments of the same baggable type, we use $p(\\mathcal{T}, \\bar{y})$ to represent a predicate, where $\\mathcal{T} \\subseteq T_B$ denotes that there is an argument t for each type $t \\in \\mathcal{T}$, and $\\bar{y}$ stands for arguments of non-baggable types. We also use $p(\\bar{x}, \\bar{y})$ where $\\bar{x}$ stands for all arguments of baggable types, and $p(\\bar{x}, \\bar{z})$ where $\\bar{x}$ represents an argument of baggable types, and $\\bar{z}$ denotes the remaining arguments. We use similar notation for action schemas. Finally, we use $e$ and $o$ for constants of baggable and non-baggable types, respectively, and u for constants of either type.\nNext, we formalize the concept of bags. Informally, a bag is a set of indistinguishable objects. Essentially, two objects are indistinguishable in a state if they satisfy the same goals and predicates. Thus our formalization of a bag consists of two parts: a subtype of goal-equivalent objects and an extended AVS (attribute value vector).\nDefinition 16. Given goal $G$, we say two objects $e_1$ and $e_2$ of the same baggable type are goal-equivalent if for all predicate p and $\\bar{u}$, $p(e_1,\\bar{u}) \\in G$ iff $p(e_2, \\bar{u}) \\in G$. We call each of the equivalence classes of t a subtype of t."}, {"title": null, "content": "For Example 1", "gripper": "st_1 = {g_1", "ball": "st_2 = {b_1,b_2, b_3, b_4}$ and $st_3 = {b_5, b_6, b_7, b_8}$.\nWe now use mutex groups to define attributes of objects. We first explain the intuitive idea. The basic way to define attributes of objects of a type t is to use each predicate involving t as an attribute, and true and false as attribute values. However, this can be improved for baggable types. Note that for a baggable type t, predicates involving t are partitioned into mutex groups, and for any object of type t, at any reachable state, one and only one predicate from the group holds. Thus we can use each mutex group as an attribute, and elements of the group as attribute values.\nDefinition 17. Let t be a baggable type. We call an $M \\in \\Pi_t$ an attribute of objects of type t. Let $p(\\mathcal{T}, \\bar{y}) \\in M$ where $t \\in \\mathcal{T}$. Let $\\bar{o}$ be an instantiation of $\\bar{y}$. We call $av(\\bar{\\mathcal{T}}) = p(\\mathcal{T}, \\bar{o})$ an attribute value for M, where $av(\\bar{\\mathcal{T}})$ denotes that $\\bar{\\mathcal{T}}$ is the set of variables for $av$. We use $D_M$ to denote the set of attribute values for M.\nFor Example 1, $D_{M_1} = {at(b, r_1), at(b, r_2), carry(b, g)}$.\nDefinition 18. Let $t\\in T_B$, $\\Pi_t = {M_1,...,M_m}$ and $\\overline{avs}(\\bar{\\mathcal{T}}) = (av_1(\\bar{\\mathcal{T}}_1), ..., av_m(\\bar{\\mathcal{T}}_m)) \\in \\times_{i=1}^m D_{M_i}$ where $\\bar{\\mathcal{T}} = \\bigcup_i \\bar{\\mathcal{T}}_i$. We call $\\overline{avs}(\\bar{\\mathcal{T}})$ an attribute value vector (AVS) for t. $Avs_t$ denotes the set of all attribute value vectors for t.\nFor Example 1, for type ball, $Avs_b = {at(b,r_1) \\wedge white(b), at(b, r_1) \\wedge black(b), at(b, r_2) \\wedge white(b), at(b, r_2) \\wedge black(b), carry(b, g) \\wedge white(b), carry(b, g) \\wedge black(b)}$. For type gripper, $Avs_g = {free(g"}]}