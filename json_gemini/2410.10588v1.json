[{"title": "TRESTLE: A Model of Concept Formation in Structured Domains", "authors": ["Christopher J. MacLellan", "Erik Harpstead", "Vincent Aleven", "Kenneth R. Koedinger"], "abstract": "The literature on concept formation has demonstrated that humans are capable of learning concepts incrementally, with a variety of attribute types, and in both supervised and unsupervised settings. Many models of concept formation focus on a subset of these characteristics, but none account for all of them. In this paper, we present TRESTLE, an incremental account of probabilistic concept formation in structured domains that unifies prior concept learning models. TRESTLE works by creating a hierarchical categorization tree that can be used to predict missing attribute values and cluster sets of examples into conceptually meaningful groups. It updates its knowledge by partially matching novel structures and sorting them into its categorization tree. Finally, the system supports mixed-data representations, including nominal, numeric, relational, and component attributes. We evaluate TRESTLE's performance on a supervised learning task and an unsupervised clustering task. For both tasks, we compare it to a nonincremental model and to human participants. We find that this new categorization model is competitive with the nonincremental approach and more closely approximates human behavior on both tasks. These results serve as an initial demonstration of TRESTLE's capabilities and show that, by taking key characteristics of human learning into account, it can better model behavior than approaches that ignore them.", "sections": [{"title": "1. Introduction", "content": "Humans can improve their performance with experience. To better understand these capabilities, numerous research efforts have constructed computational models of human learning (Vanlehn et al., 1992; Fisher & Langley, 1990; Li et al., 2012c; Laird et al., 1986; Langley et al., 2009b). Early work on human learning embraced categorization as a primary mechanism for organizing experiences, recalling them in new situations, and using them to make decisions (Feigenbaum & Simon, 1984; Fisher & Langley, 1990). In contrast, most recent work in cognitive architectures emphasizes the generation of solutions to problems or the execution of actions (Langley et al., 2009b). However, categorization and conceptual understanding remain crucial aspects of cognition. For example, there is evidence that humans spend more time on learning to recognize the conditions for an action than on learning the steps needed to perform it (Zhu et al., 1996). Thus, we argue that more research should be conducted on human categorization and the role it plays in learning and problem solving.\nOne important aspect of human categorization is that it occurs in an incremental fashion (Giraud-Carrier, 2000; Love et al., 2004). People revise learned concepts given new information rather than reconsidering all prior experiences and learning completely new structures. This lets them improve their performance given more experience and to flexibly adapt their knowledge and understanding in response to novel situations in an efficient way. This approach contrasts with the main thrust of research in machine learning, which emphasizes nonincremental approaches in an effort to aid performance. Thus, while incremental learners can update their knowledge given new experiences, their performance is affected by the order in which these experiences occur. For example, when humans are learning to solve fractions problems, the order in which they receive problems affects their learning (Rau et al., 2013). More generally, how best to order practice problems for humans in order to promote robust learning remains an open research question (Li et al., 2012b; Carvalho & Goldstone, 2013) that would stand to benefit from computational models of incremental acquisition.\nA second characteristic of human categorization is that it occurs in a wide range of environments that can involve structural, relational, nominal, and numeric information. For example, the work of Carvalho & Goldstone (2013) has shown that the structural similarity of objects present in examples affects human concept formation. Other work has identified structure mapping as a crucial ability that allows humans to map their prior concepts to new situations (Forbus et al., 1995; Holyoak, 2005). While prior models of concept learning have explored how to handle relational (Quinlan & Cameron-Jones, 1995), nominal (Fisher, 1987), and numeric (Gennari et al., 1989; Li & Biswas, 2002; Quinlan, 1986) information, less emphasis has been placed on learning with structural content (Thompson & Langley, 1991; Forbus et al., 1995). Further, few studies exist that explore how best to model the integration of multiple data types. Of the existing methods, only a subset integrate nominal and numeric data (Li & Biswas, 2002; Quinlan, 1986; Gennari et al., 1989). Finally, even fewer studies combine relational (Quinlan & Cameron-Jones, 1995) or structural (Thompson & Langley, 1991; Forbus et al., 1995) information. We claim that any system attempting to model human categorization should integrate all of these data types into a single account.\nA third characteristic of human concept learning is that it occurs in both supervised and unsu- pervised settings (Love et al., 2004). In many cases, these two modes of learning are treated as distinct, but there is evidence that humans can improve their performance on unsupervised tasks given supervision on a different task (Zhu et al., 2007). Others have found the reverse, that humans can improve their performance on supervised tasks given experience on other unsupervised tasks (Kellman & Garrigan, 2009). Taken together, these findings suggest that humans share knowledge across these settings, and that models of human categorization should be capable of operating with and without supervision, with knowledge used for one influencing the other.\nTo explore these aspects of human categorization, we developed TRESTLE, an incremental model of probabilistic concept formation in structured domains that builds on prior research in categorization (Fisher, 1987; McKusick & Thompson, 1990; Thompson & Langley, 1991). This approach maps novel structures to its existing knowledge in an online fashion and updates its cate- gorization knowledge based on these new structures. TRESTLE also handles mixed representations, letting it function with nominal, numeric, relational, and component attributes. Finally, the approach supports partial matching, so it can process incomplete or partially specified input. These features let TRESTLE use its categorization knowledge for predicting missing attributes in supervised set-"}, {"title": "2. The RumbleBlocks Domain", "content": "To investigate human learning in a rich domain, we have explored data from RumbleBlocks (Christel et al., 2012), an educational game designed to teach concepts of structural stability and balance to young children. What makes this domain interesting is the detailed structural quality of game tasks. Players build a tower out of blocks in a two-dimensional, continuous world with a realistic rigid body physics simulation, designing their towers to cover a series of energy balls in an attempt to power an alien's spaceship (see Figure 1). These energy balls function as both scaffolding and constraints on players' designs. After designing their tower, players place the spaceship on the tower, which charges the ship and causes an earthquake. If the tower survives the earthquake with the spaceship intact, then the player succeeds and goes on to the next level; otherwise he fails and must try the level again.\nEach level of the game is designed to emphasize one of three primary concepts of structural stability and balance: objects that are symmetrical, that have wide bases, and that have lower centers of mass are more stable. While the drag-and-drop actions of tower construction are necessary to succeed in the game, they are not relevant its educational goals. The central learning challenge for\nplayers of RumbleBlocks is to understand how to categorize the states of the game world as good or bad examples of the game's target concepts.\nRumbleBlocks provides several interesting hurdles when attempting to model players' concep- tual learning. The biggest challenge is in representing the richly structured space of the game. States exist in a continuous space but also possess nominal (e.g., block types) and structural information (e.g., high level patterns like arches). Additionally, the physics simulation that models the earth- quake is nondeterministic and susceptible to minor perturbations in rigid body physics. Therefore, two towers that appear similar have a small chance of being treated differently in terms of the suc- cess criteria, resulting in noisy evaluation feedback. This noisy feedback makes it more challenging to learn the correct concepts and makes ordering effects more pronounced; if a borderline tower fails early in a student's problem sequence, then he will be more likely to avoid similar structures throughout his play than if the tower had succeeded. Finally, RumbleBlocks lets students partake in both supervised and unsupervised learning. They receive supervised feedback regarding the success of their towers, but are left to learn the game's target concepts (i.e., wide base, low center of mass, and symmetry) in an unsupervised way.\nAn early attempt exploring how players learn in RumbleBlocks sought to model the acquisition of structural patterns as a grammar induction task through a process called CFE or Conceptual Feature Extraction (Harpstead et al., 2013). CFE, which is similar to the grammar learning approach used by SimStudent (Li et al., 2012a), takes a series of examples and discretizes them to a grid before exhaustively generating a two-dimensional context-free grammar that is capable of parsing each example in every possible way. The parse trees for each example are then converted into feature vectors using a bag of words approach, where each symbol in the grammar has its own feature. The generated feature vectors are then used by traditional learning methods for prediction or clustering. The goal was to construct features that capture the maximal amount of structural information in the examples so that this information could be used in learning.\nThe CFE approach was successful for clustering student solutions in order to understand how players' design patterns differed from those expected by the game's designers (Harpstead et al., 2013), but it has not been evaluated as part of a model of human categorization in RumbleBlocks.\nThere are several obstacles to using CFE to model human categorization. First, the algorithm runs in a batch fashion instead of incrementally and requires all the examples for each task to generate its grammar. Thus, any examples with previously unseen features would require the learning of an en- tirely new grammar. Second, the grammar rule formalism used by CFE breaks down in continuous environments and when two-dimensional objects cannot be cleanly decomposed across axes. For example, when given a set of blocks in a spiral pattern, it cannot decompose the structure along the horizontal or vertical axes; subsequently, it cannot reduce the structure to the primitive grammar el- ements and fails at parsing the block structure. Finally, CFE and other similar grammar approaches (Talton et al., 2012) cannot handle missing data in that they cannot partially match during parsing. Thus, if an attribute is missing from the training set, then examples containing that attribute cannot be parsed during run time. Similarly, if an attribute is always present in training but not at run time, then some examples would not be parsable."}, {"title": "3. The TRESTLE Model", "content": "In order to better model human concept formation in the RumbleBlocks domain we developed TRESTLE,\u00b9 a system that incrementally constructs a categorization tree given the sequential pre- sentation of instances. This categorization tree can then be used to make predictions about the given instances or to generate cluster labelings. At a high level, TRESTLE proceeds through three major steps when given an instance:\n1. Partial matching, which structurally renames the instance to align it with existing concepts;\n2. Flattening, which converts a structured instance into an unstructured one while preserving its structural information with a specific naming scheme; and\n3. Categorization, which incorporates the example into existing knowledge and, if necessary, makes predictions.\nIn this section we describe how TRESTLE represents both instances and concepts. We also clarify the processing steps that it carries out to learn from each instance."}, {"title": "3.1 Instance and Concept Representations", "content": "TRESTLE uses two representations to support learning: one for instances (i.e., specific examples it encounters) and one for concepts (i.e., generalizations of examples in memory). Instances are encoded in TRESTLE as sets of attribute values, where each attribute can have one of four types: nominal (e.g., the type or color of a block); numeric (e.g., the position of a block in continuous space); component (e.g., a block with type and dimension attributes is a component of a greater tower); and relational (e.g., that two blocks are vertically adjacent). Figure 2 shows an example of a RumbleBlocks tower and how it is represented using these four attribute-value types. In this example, we include the \u201cOn\u201d relation to demonstrate how relations are encoded, but in practice the component information is often sufficient for learning meaningful concepts. Our subsequent evaluation does not use these hand-generated relations; we only used the component and success information that was automatically provided by the game engine.\nIn response to being presented with instances, TRESTLE forms a hierarchy of concepts, where each concept is a probabilistic description of the collection of instances stored under it. This prob- abilistic description is stored in the form of a probability table that tracks how often each attribute value occurs in the underlying instances (e.g., see Figure 2). These probability tables can be used to lookup the probability of different attribute values occurring in an instance given its concept la- bel. Additionally, the concept maintains a count of the number of instances it contains, so that the probability of the concept given its parent concept can be computed."}, {"title": "3.2 Partial Matching", "content": "When presented with an instance, TRESTLE searches for the best partial match between the in- stance and the root concept, which contains the attribute-value counts of all previous instances."}, {"title": "3.3 Flattening", "content": "After matching the instance to the root concept, TRESTLE then flattens the instance using two pro- cedures. First, it converts all relational attributes directly into nominal attributes. Second, compo- nent attributes are eliminated by concatenating component and attribute names into a single attribute name. Throughout the paper we denote this conventionally using dot notation. For examples, the instance in Figure 2 would be flattened as {Successful: \"False\", Component1.type: \u201cUFO\u201d, Com- ponent1.angle: 0.0, Component1.left: 0.1, Component1.right: 2.8, \u2026\u2026\u2026, \u201c(On Component1 Compo- nent2)\u201d: \u201cTrue\u201d, \u201c(On Component2 Component3)\u201d: \u201cTrue"}, ".", "The flattening process effectively eliminates the component and relational attributes while preserving their information in a form that can be used during partial matching to rename later instances. Flat representations can be converted back into a form that contains component and relational attributes. Once converted into a flat repre- sentation the instances only contain nominal and numeric attributes that can be handled by existing approaches to incremental categorization."]}, {"title": "3.4 Categorization", "content": "To categorize flattened instances, TRESTLE employs the COBWEB algorithm (Fisher, 1987; McKu- sick & Thompson, 1990), which recursively sorts instances into a hierarchical categorization tree. At each concept encountered during sorting, it considers four possible operations (shown in Figure 3) to incorporate the instance into its tree: adding the instance to the most similar child concept; creating a new child concept to store the instance; merging the two most similar child concepts and then adding the instance to the resulting concept; and splitting the most similar child concept, promoting its children to be children of the current concept, and recursing. COBWEB determines which operation to perform by simulating each action and computing the category utility (Fisher, 1987) of the resulting child concepts. Like the similarity value being maximized during partial matching, this represents the increase in the average number of expected correct guesses achieved in the children compared to their parent concept; thus it is similar to the information gain heuristic used in decision-tree induction (Quinlan, 1986). Mathematically, the category utility of a set of children {$C_1, C_2,\uff65\uff65\uff65, C_n$} is\n$CU({C_1, C_2,\uff65\uff65\uff65,C_n}) = \\frac{\\sum_{k=1}^{n}P(C_k) [\\sum_i \\sum_j P(A_i = V_{ij}|C_k)^2 - \\sum_i \\sum_j P(A_i = V_{ij})^2]}{n}$,\nwhere P($C_k$) is the probability of a particular concept given its parent, P($A_i$ = $V_{ij}$|$C_k$) is the probability of attribute $A_i$ having value $V_{ij}$ in the child concept $C_k$, P($A_i$ = $V_{ij}$) is the probability of attribute $A_i$ having value $V_{ij}$ in the parent concept, and n is the number of child concepts. Each of these terms can be efficiently computed via a lookup of the probability tables stored in the parent and child concepts.\nFor numeric attributes, COBWEB uses a normal probability density function to encode the probability of different values of a numeric attribute. Given this assumption, the sum of squared attribute-value probabilities is replaced with an integral of the squared probability density function, which in the case of a normal distribution is simply the square of the distribution's normalizing constant. Thus, $\\sum_i \\sum_j P(A_i = V_{ij}|C_k)^2 - \\sum_i \\sum_j P(A_i = V_{ij})^2$ is replaced with $\\sum \\frac{1}{\\sigma_{ik}} - \\frac{1}{\\sigma_i}$ in the case of numeric attributes, where $\\sigma_{ik}$ is the standard deviation of values for the attribute $A_i$ in child concept $C_k$ and $\\sigma_i$ is the standard deviation of values for the attribute $A_i$ in the parent concept. For more detailed justification of this modification to category utility, see Gennari et al. (1989)."}, {"title": "3.5 Prediction and Clustering", "content": "During learning, COBWEB uses this categorization technique to incorporate new instances into its conceptual hierarchy. The resulting tree can then be used to make predictions about novel instances or provide clusterings of the examples to varying depths of specificity.\nWhen TRESTLE makes predictions, it follows its normal partial matching and flattening pro- cedures but employs COBWEB's non-modifying categorization process. In this version of catego- rization, an instance is sorted down the tree, but concepts do not update their probability tables to reflect the example. Additionally, the system only considers the creating and adding operations at each concept. When categorization encounters a leaf or a situation where the creating operation has the highest category utility, it returns the current concept. The resulting concept's probability table is then used to make predictions about attribute values of the instance, with each missing attribute predicted to have its most likely value according to the table.\nIn addition to prediction, TRESTLE can cluster data by using COBWEB to categorize instances into its concept tree and assign labels based on the selected concepts. Using this process, TRESTLE produces a hierarchical clustering of the data. Alternatively, TRESTLE can convert this hierarchical"}, {"title": "4. Experimental Evaluation", "content": "We designed TRESTLE to model three key aspects of human concept learning: incremental process- ing, use of multiple information types (nominal, numeric, component, and relational), and operation in both supervised and unsupervised settings. Further, implicit in this design is the claim that, by taking these three aspects of human categorization into account, we can better model human cate- gorization. Thus, we had two goals for our experimental evaluation: to demonstrate TRESTLE's abilities to perform incremental learning with multiple types of information in both supervised and unsupervised capacities, and to show that, by taking these into account, it models human perfor- mance better than similar systems that do not.\nTo demonstrate TRESTLE's functionality, we assessed its behavior on two tasks: a supervised learning task and an unsupervised clustering task. For each task we used player log data from the RumbleBlocks domain, which contains nominal, numeric, and component information. Addition- ally, we wanted to test our claim that the system models human categorization better than alternative ones. To achieve this goal, we compared TRESTLE to CFE, a nonincremental approach to learn- ing in structured domains. To establish a baseline for the comparison, we had humans perform both tasks. We then compared the behavior of both systems to the human behavior to assess which approach better models the latter's learning."}, {"title": "4.1 Task 1: Supervised Learning", "content": "For the supervised learning task, each learner (TRESTLE, CFE, and human) was sequentially pre- sented with RumbleBlocks towers and asked to predict if the tower successfully withstood the earth- quake. They were then given correctness feedback about their prediction (i.e., provided the success label). Instances for this task were taken randomly from all player solutions to the same level of RumbleBlocks. To avoid a naive strategy of base rate prediction, we chose a level whose overall success ratio was roughly even (a symmetry level in which 48.9% of player towers stood). We presented each learner with 30 randomly selected and randomly ordered examples and averaged the accuracy for each approach across opportunities.\nTo determine human behavior for this task, we used Amazon Mechanical Turk to have 20 hu- mans perform sequential prediction using the interface shown in Figure 5. We asked participants to decide if a screenshot of an example tower fit into \u201cCategory 1\" (successful) or \u201cCategory 2\" (unsuccessful) before telling them the correct category. We presented labels abstractly to avoid hu- man raters using their intuitive physics knowledge, which would not be accessible to either of the computational models.\nCFE is a nonincremental approach for handling structural information that must be paired with another learning algorithm in order to do prediction or clustering. To sequentially predict the success labeling of solutions, we paired CFE with CART, a decision-tree learner implemented in the Scikit-"}, {"title": "4.2 Task 2: Unsupervised Clustering", "content": "The results of the supervised learning task show that TRESTLE performs similarly to humans, but we are also interested in demonstrating its unsupervised learning capabilities and investigating whether its underlying representation of knowledge is qualitatively similar to that in humans. A strong similarity between their organizations of knowledge would strengthen our claim that it offers a better model of human learning than CFE. In particular, if its organization of concepts aligns with that of humans, it would suggest that the agreement with humans on the supervised learning task is the result of a similar organization of knowledge rather than both learners performing poorly by chance. To examine this aspect of TRESTLE, we used an unsupervised learning task in which towers were clustered without any information about their success or other category labels. For this evaluation, we chose records from three levels of RumbleBlocks that were part of an in-game test. These levels were attractive because they have many player solutions and because the energy ball mechanic was removed for the test setting, allowing for a wider variance of player solutions than other levels.\nTo establish a human baseline, we had two researchers from our laboratory independently hand cluster screenshots of all the player solutions to each level. These raters were told to group solutions that looked similar and to ignore any blocks that did not appear to be part of the solution tower (e.g., blocks off to the side of the frame), but were not given any other guidance. To measure agreement between raters, we calculated the adjusted Rand index between their clusterings (Rand, 1971). This measure is a generalization of Cohen's Kappa that allows for raters to use different numbers of categories. Values range from -1 to 1, with random clusterings producing an average of zero. The average obtained across all three levels was 0.88, which is high. Given the reasonably high agreement between raters, we chose one of the human clusterings to be used in further comparisons with the machine approaches. The labeling from this rater had an average of 33 clusters across the three levels.\nAs a comparison, we applied the CFE process to generate feature vectors for the RumbleBlocks solutions. For each level, we clustered the feature vectors using the G-means algorithm (Hamerly & Elkan, 2004), which functions like a wrapper around k-means using a heuristic that tries to form clusters with a Gaussian distribution among features to choose a good value for k. This process produced a clustering of solutions for each level. We ran it ten times and we report the average and standard deviation in adjusted Rand index between the CFE and human clusterings.\nTo examine TRESTLE's ability to cluster RumbleBlocks solutions, we had it create a catego- rization tree for each level, with instances categorized into the tree in a random order. After all instances had been categorized once, we shuffled them and categorized them a second time, taking the concepts into which they were sorted as their labeling. We could have clustered instances using a single run, but we were interested in trying to maintain parity to the humans, who were given all the examples at once and allowed to recategorize them. To model this task we categorized the instances twice to give TRESTLE the opportunity to form an initial categorization tree from all the examples once before committing to labels.\nBoth the human labeling and the CFE clustering produced flat clusterings, so for comparison purposes we transformed TRESTLE's hierarchical clustering into a nonhierarchical one. As men- tioned earlier, a flat clustering can be produced by splitting concepts in the tree starting at the root and returning the most general unsplit concept as a label for each instance. This process can be done with an arbitrary number of splits; for example, zero splits will return the root concept as the label for every instance, one split will return the children of the root as concept labels, and two splits will return a more refined set of concept labels produced by further splitting one of the children. This process is similar to the one used to produce flat clusterings from agglomerative techniques. Given that the number of splits is arbitrary, we report the results for the first three splits of the categoriza- tion tree to provide a sense for how the clusterings at different levels of the hierarchy agree with human clusterings. As with the CFE evaluation, we repeated this process ten times and we report the average and standard deviation in adjusted Rand index between the human labelings and each split of the TRESTLE labelings."}, {"title": "5. Discussion", "content": "One interpretation of our results is that TRESTLE is a better model of human behavior while CFE is a better machine learning approach, in that it achieves greater performance. Both our prediction and clustering results support this interpretation. First, TRESTLE's predictive accuracy is closer to human predictive accuracy, while CFE has higher accuracy than both TRESTLE and humans. Further, TRESTLE's organization of knowledge more closely agrees with humans than the organi- zation produced using CFE. The two approaches differ, in part, because of the different motivations underlying their designs. CFE was originally created as a means of transforming instances in a structured domain into feature vectors so that other traditional learning algorithms (e.g., CART or k-means) could function in the space. It was designed primarily for use in offline settings, such as post-hoc analysis of RumbleBlocks solutions, rather than for making online decisions. This is why the algorithm makes use of exhaustive grammar generation and computes features based on all possible parses of structures, in an attempt to maximize its coverage of the space despite the additional training costs. TRESTLE, on the other hand, arises out of existing theory on human categorization and takes a probabilistic approach to the problem of coverage. Rather than focus on multiple potential interpretations of a tower it looks at probabilistic similarity with existing knowl- edge. Additionally, TRESTLE maintains more psychological plausibility by avoiding exhaustive processes; for example, it does not seem very plausible that new players of RumbleBlocks have a"}, {"title": "6. Related Work", "content": "We have mentioned previously that the TRESTLE model builds on earlier accounts of concept for- mation in the COBWEB family (Fisher, 1987; McKusick & Thompson, 1990; Gennari et al., 1989). However, we should also discuss how it relates to these previous systems and other similar mod- els of human categorization that attempt to accomplish similar goals. One early account of human categorization was EPAM (Feigenbaum & Simon, 1984), which modeled human memorization of nonsense syllables. It learned incrementally from sequentially presented training examples and took structural information (i.e., the organizations of letters) into account. Additionally, EPAM organized its experiences using a discrimination network, which has a tree structure similar to that used by TRESTLE. COBWEB (Fisher, 1987) extended this idea to take into account attribute-value proba- bilities during concept formation. Further, COBWEB/3 (McKusick & Thompson, 1990) added the ability to handle numeric information. However, these newer approaches did not support the ability to handle structural information originally supported by EPA\u041c.\nCLASSIT (Gennari et al., 1989) was another variant of COBWEB that supported both numeric information and component information. Like TRESTLE, it used both partial matching and flat- tening steps to handle component information during categorization. However, CLASSIT lacked support for both nominal or relational information. LABYRINTH (Thompson & Langley, 1991) was developed to support component, nominal, and relational information. Like TRESTLE, it utilized a partial matching step to rename component objects in order to maximize category util- ity. During categorization, the system supported components by categorizing subcomponents in a bottom-up fashion and replacing component values with nominal concept labels. LABYRINTH also generalized subcomponent labels during the categorization of higher-level components. This bottom-up categorization approach let it utilize subcomponent information to improve prediction of higher-level attributes, but it could not use higher-level component information when categorizing subcomponents. In contrast, TRESTLE's flattening mechanism takes into account the attribute- values of all components in a holistic way when making predictions. Finally, neither CLASSIT nor LABRYINTH have been compared to humans or other systems, so it is unclear how their perfor- mance would compare to that of TRESTLE.\nThere also exist other systems that have similar goals, but do not derive from the COBWEB family. For example, SimStudent (Li et al., 2014) shares TRESTLE's aim of modeling novice learning via a combination of statistical and structural learning. As in TRESTLE, SimStudent com- bines both unsupervised (perceptual representation) and supervised (skill) learning. One key differ- ence is that TRESTLE is more unified (with a single learning mechanism) and fully incremental, whereas SimStudent has four learning mechanisms (one for representations and three for skills), with representation learning running in batch prior to skill learning. For comparison purposes, CFE is analogous to SimStudent, in that they use similar grammar learners and classification/clustering algorithms. To the extent that CFE is a good approximation of SimStudent, our results suggest that TRESTLE may model human learning better than SimStudent in that the latter, like CFE, is likely to learn faster than humans. More generally, our evidence supports the hypothesis that an incre- mental integration of representation and classification learning better models human behavior than separate, nonincremental, representation and classification learners. Elements of skill learning that go beyond classification (e.g., SimStudent's action-sequence learner) are targets for further research on TRESTLE.\nSAGE (Kuehne et al., 2000; McLure et al., 2010) is another system that shares the goal of modeling human concept formation in structured domains. It learns concepts by matching new instances to existing structures and generalizing matching concepts to include the instances. If no match is found, then it creates a new concept to cover the instance. For comparison purposes, SAGE is analogous to a form of TRESTLE that is nonhierarchical; it maintains only the children of the root and it cannot split merged concepts because it does not maintain more specific variants. This difference makes it harder for SAGE to recover from early misconceptions and biases it towards forming overly abstract concepts (Kuehne et al., 2000). Thus, in many respects TRESTLE could"}, {"title": "7. Conclusion and Future Work", "content": "In this paper, we presented TRESTLE and demonstrated its ability to incrementally learn concepts from mixed-data environments in both a supervised and unsupervised fashion. However, our eval- uation of the system is preliminary, and more work is necessary to fully assess its capabilities. In particular, we should evaluate TRESTLE's ability to perform more flexible prediction tasks (Fisher, 1987), but first, we must determine how to frame these tasks in structured domains. For example, should we evaluate a system's ability to predict specific attribute values, or should we assess its abil- ity to predict entire missing components with multiple attribute values? This problem is complicated by structure mapping, which makes it difficult to align component predictions during evaluation.\nIn addition to assessing the current system's capabilities, we should integrate it with methods for planning and executing action. For example, we could extend TRESTLE to support \u201cfunctional\" attributes that have actions as values. This would let it decide what action to take given an instance. Unlike systems that separate concept and skill knowledge (e.g., Langley et al., 2009a), this extension would let TRESTLE use functional information to guide its formation of concepts and vice versa.\nWe should also explore the implications of TRESTLE for supporting designers. Prior work shows that concept formation systems can be used in this area. For example, Reich (1993) devel- oped BRIDGER to support bridge design, but his approach did not support component or relational information. More recently, Talton et al. (2012) demonstrated how to generate novel designs using grammar patterns induced from examples provided by designers, but their work did not support mixed data types or missing attributes. TRESTLE could extend both approaches to support novel tasks, such as completing partially specified designs that are described with mixed data types. We would also like to explore how it could help game designers better understand the space of player solutions by clustering solutions with common structural patterns. This application was part of the original motivation for CFE, but our clustering results suggest that TRESTLE is better suited to the task and may even provide more information through its hierarchical organization of concepts.\"\n    }\n  ]\n}\n```"}]