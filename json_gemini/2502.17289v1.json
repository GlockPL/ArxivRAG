{"title": "A novel approach to navigate the taxonomic hierarchy to address the Open-World Scenarios in Medicinal Plant Classification", "authors": ["Soumen Sinha", "Tanisha Rana", "Rahul Roy"], "abstract": "In this article, we propose a novel approach for plant hierarchical taxonomy classification by posing the problem as an open class problem. It is observed that existing methods for medicinal plant classification often fail to perform hierarchical classification and accurately identifying unknown species, limiting their effectiveness in comprehensive plant taxonomy classification. Thus we address the problem of unknown species classification by assigning it best hierarchical labels. We propose a novel method, which integrates DenseNet121, Multi-Scale Self-Attention (MSSA) and cascaded classifiers for hierarchical classification. The approach systematically categorizes medicinal plants at multiple taxonomic levels, from phylum to species, ensuring detailed and precise classification. Using multi scale space attention, the model captures both local and global contextual information from the images, improving the distinction between similar species and the identification of new ones. It uses attention scores to focus on important features across multiple scales. The proposed method provides a solution for hierarchical classification, showcasing superior performance in identifying both known and unknown species. The model was tested on two state-of-art datasets with and without background artifacts and so that it can be deployed to tackle real word application. We used unknown species for testing our model. For unknown species the model achieved an average accuracy of 83.36%, 78.30%, 60.34% and 43.32% for predicting correct phylum, class, order and family respectively. Our proposed model size is almost four times less than the existing state of the art methods making it easily deploy able in real world application.", "sections": [{"title": "Introduction", "content": "Medicinal plant classification in the fields of botany, agriculture, and pharmacology is essential for identifying and utilizing plants for therapeutic purposes. Accurate classification allows researchers to systematically catalog and study plant species, which is crucial for discovering new medicinal properties and developing herbal remedies. Moreover, it helps in the conservation of biodiversity, ensuring that valuable plant species are protected and sustainably used. Furthermore, understanding the taxonomy of medicinal plants aids in tracing the evolutionary relationships providing insights into their potential health benefits.\nThis knowledge is vital for pharmacologists in formulating effective and safe herbal medicines, contributing to the advancement of alternative and complementary therapies.\nThe recent advancements in deep learning have significantly improved the methods for detecting and classifying plant diseases, thereby enhancing the precision and efficiency of these tasks. Li et al. [20] reviewed various deep learning models for plant disease detection, highlighting their potential to automate agricultural processes and increase accuracy. Similarly, Chen et al. [4] provided a comprehensive review on plant image recognition using deep learning, emphasizing the robustness of these models in handling diverse plant datasets. Fitzgerald et al. [8] discussed the historical and regional advancements in medicinal plant analysis, focusing on emergent complex techniques used in modern pharmacology. Diwedi et al. [7] proposed an classification system based on optimized support vector machine.\nTan et al. [21] explored the use of deep learning for plant species classification using leaf vein morphometrics, achieving notable improvements in classification accuracy. However, their method does not extend to the hierarchical classification. Ganzera and Sturm [9] highlighted recent advancements in HPLC/MS in medicinal plant analysis, focusing primarily on chemical analysis. Additionally, Vishnoi et al. [24] provided a comprehensive study of feature extraction techniques for plant leaf disease detection, emphasizing the importance of feature extraction in classification tasks for plants affected with various diseases.\nRecent studies have applied various deep learning techniques for medicinal plant classification. Azadnia et al. [2] proposed a SCAM-herb based model which uses gated pooling methods to classify medicinal and poisonous plants from visual characteristics of leaves, demonstrating the potential of deep learning in this domain. Samuel et al. [17] focused on the antioxidant and phytochemical classification of medicinal plants used in cancer treatment where classification was based on the predominant antioxidant. Tan et al. [20] employed visual feature-based deep learning for rapid identification of medicinal plants, showing significant improvements in speed and accuracy.\nVarious researchers also explored the use of pixel-wise and constrained feature extraction to improve classification. Dhakal and Shakya [6] explored the use of pixel wise operations in image-based plant disease detection. Kan et al. [12] examined multi feature extraction techniques for plant leaf image classification. Sachar and Kumar [16] surveyed various feature extraction and classification techniques for identifying plants through leaves. Tiwari et al. [23] developed an interesting deep neural network for"}, {"title": "Preliminaries", "content": "In this section we present a brief discussion on the preliminaries of the technologies used in our proposed method, this includes discussion on DenseNet121 and Multi-Scale Self-Attention."}, {"title": "DenseNet121", "content": "The feature extractor used in our proposed method is DenseNet21 [11]. The DenseNet21 (Densely Connected Convolutional Network) is an extension of the DenseNet architecture that consists of 21 layers. DenseNet is known for its dense connectivity pattern, where each layer is connected to every other layer in a feed-forward manner. This design helps the flow of information and gradients throughout the network for more efficient training and better performance. The architecture is shown in Figure 1.\nDenseNet121 consists of four dense blocks interspersed with transition layers. Each dense block comprises several convolutional layers, with each layer receiving inputs from all preceding layers within the same block. This connectivity is mathematically represented as:\n$x_l = H_l([x_0, x_1,..., x_{l-1}])$\n(2.1)\nwhere $x_l$ is the output of the l-th layer, $[x_0, x_1, ..., x_{l-1}]$ represents the concatenation of the feature maps produced by layers 0 to 1 \u2013 1, and $H_l(\u00b7)$ is the composite function of the operations at the l-th layer, which includes Batch Normalization (BN), Rectified Linear Unit (ReLU), and Convolution (Conv). An illustration is shown in Figure 2.\nThe network begins with an initial convolution layer that processes the input image, followed by a pooling layer. The initial layers can be described as:\n$x_0 = Conv(Input), \t x_1 = Pooling(x_0)$\n(2.2)\nDense Block 1 consists of 6 convolutional layers, each densely connected to the previous layers. The transition layer following this block (2.3) includes batch normalization, a 1x1 convolutional layer, and a 2x2 average pooling layer. Similarly Dense Block 2 consists of 12 convolutional layers, followed by another transition layer (2.4). Dense Block 3 contains 24 convolutional layers. The transition layer here (2.5) also includes batch normalization, a 1x1 convolution, and a 2x2 average pooling. Dense Block 4 is the final block with 16 convolutional layers, after which a global average pooling layer (2.6) reduces the spatial dimensions of the feature maps.\n$x_{trans1} = AvgPool(Conv_{1x1}(BN(x_1)))$\n(2.3)\n$x_{trans2} = AvgPool(Conv_{1x1} (BN(x_{trans1})))$\n(2.4)\n$x_{trans3} = AvgPool(Conv_{1x1}(BN(x_{trans2})))$\n$x_{gap} = GlobalAvgPool(x_{trans3})$\n(2.5)\n(2.6)\nEach layer in DenseNet121 typically consists of three operations:\n$H_l(x) = W_l * \u03c3(BN(x))$\n(2.7)\nwhere BN denotes Batch Normalization, \u03c3 represents the ReLU activation function, $W_l$ is the weight matrix of the convolutional layer, and * denotes the convolution operation. The growth rate k is a crucial hyperparameter in DenseNet, indicating the number of feature maps added by each layer. If the input to the l-th layer has m feature maps, the output will have m + k feature maps. Thus, the width of the network grows linearly with the depth.\nTo control the complexity and size of the model, DenseNet121 employs transition layers between dense blocks, which consist of a Batch Normalization layer, a 1x1 Convolutional layer, and a 2x2 Average Pooling layer. The transition layer can be expressed as:\n$T(x) = AvgPool(W_t * \u03c3(BN(x)))$\n(2.8)\nwhere $W_t$ is the weight matrix of the 1x1 convolutional layer in the transition layer. In our proposed method we have used DenseNet121 as a feature extractor. Since each layer is connected to its previous layer DenseNet121 ensures efficient gradient propagation and better representation of the complex structural features of previous layers."}, {"title": "Multi-Scale Self-Attention (MSSA)", "content": "Self-attention techniques are widely used to compute contextual relationships and enhance the feature representation learned by convolutional layers. In self-attention, an input feature map is transformed into a weighted feature map that captures contextual relationships. However, this weighted feature map often lacks sufficient contextual information. Specifically, feature maps from shallow layers contain rich local spatial details but lack high-level semantics, while feature maps from deeper layers contain high-level semantic information but miss local spatial details.\nTo address these limitations, Multi-Scale Self-Attention (MSSA) [25] is used to integrate both local spatial and high-level semantic contextual information through multi-scale features learned by different convolutional blocks. The MSSA block takes a multi-scale feature map F and a resized local feature map C as inputs, producing a weighted multi-scale feature map Di that captures contextual relationships among pixels from both local spatial and high-level semantic perspectives.\nFor example, consider five outputs from a feature extractor, each denoted as $C_i$, where i ranges from 1 to 5, corresponding to different convolutional blocks. $C_i$ contains feature maps of varying scales at different depths, with scales decreasing and depth increasing as i increases. To merge both local spatial details and high-level semantics, outputs from these five blocks are used to form a multi-scale feature map F. To retain local spatial details at the highest resolution, each output (e.g., $C_2, C_3, C_4$, and $C_5$) is resized to match the dimensions of $C_1$ by:\n$C'_i = upsample(C_i) \tand |C'_i| = |C_1|$\n(2.9)\nwhere i = 2,3,4, and 5, and |x| represents the dimension of a feature map x without depth. All resized outputs are then concatenated to construct a multi-scale feature map F by:\n$F = C_1 \\bigoplus C'_2 \\bigoplus C'_3 \\bigoplus C'_4 \\bigoplus C'_5$\n(2.10)\nwhere $\\bigoplus$ denotes the concatenation operation. Each high-resolution $C'_i$ and the multi-scale feature map F are individually fed into the proposed MSSA module, which will be detailed in subsection 2.2, to compute contextual relationships.\nFor an input feature map $C \\in R^{H \\times W \\times C_{h1}}$, where H, W, and $C_{h1}$ represent the height, width, and channel dimensions respectively, and i denotes the block number, a 1x1 convolution is applied to transform C into a new feature map $Y \\in R^{H \\times W \\times \\frac{C_{h1}}{8}}$. A ratio of 1/8 is used to reduce the channel number to its 1/8, which has been empirically determined to be optimal [26]. Similarly, for the multi-scale feature map $F \\in R^{H \\times W \\times C_{h2}}$, a 1x1 convolution is used to generate a new feature map $Z \\in R^{H \\times W \\times \\frac{C_{h1}}{8}}$.\nWe then reshape Y to $Y_r$, of size $(H x W) \\times \\frac{C_{h1}}{8}$ and reshape and transpose Z to $Z_{rt}$ of size $\\frac{C_{h1}}{8} x (H x W)$. Multiplying $Y_r$ and $Z_{rt}$ generates a map of size $(H x W) \\times (H x W)$. Applying a softmax to this map produces a normalized map A, also known as the attention map. The attention map A is computed as:\n$A(m, n) = \\frac{exp(Y_r(m, :) \\cdot Z_{rt}(:, n))}{\\sum_{n=1}^{HW} exp(Y_r(m, :) \\cdot Z_{rt}(:, n))}$\n(2.11)\nwhere : denotes all values in a row or column, and A(m, n) represents the impact of the n-th column of $Z_{rt}$ on the m-th row of $Y_r$. A high value in A indicates a strong correlation between $Y_r$ and $Z_{rt}$ (i.e., between C and F).\nIn another branch, a 1x1 convolution transforms C into a new feature map $X \\in R^{H \\times W \\times C_{h1}}$, which is then reshaped and transposed to $X_{rt}$ of size $C_{h1} \\times (H \\times W)$. A matrix multiplication between $X_{rt}$ and A is performed, and the result is reshaped to size H \u00d7 W \u00d7 $C_{h1}$ and scaled by a learnable parameter \u03bc to generate a weighted attention map. This map is added to the input C to produce a weighted feature map $D_i$:\n$D_i(m, n) = \u03bc\\cdot reshape(X_{rt}(m, :) \\cdot A(:, n)) + C(m, n)$\n(2.12)\nwhere $D_i(m, n)$ represents the value of a weighted feature map at location (m, n), and \u03bcis initialized to 0 to allow the network to initially rely on local neighborhood cues to maximize learning.\nStarting with $D_5$, a 3x3 filter is applied, and the filtered result is concatenated with $D_4$ to combine spatial and semantic information from blocks 5 and 4. This operation is repeated to combine information from blocks 4 and 3, blocks 3 and 2, and blocks 2 and 1. The algorithmic steps for chained concatenation operations are as follows:"}, {"title": "Proposed Method", "content": "In this section, we propose a novel architecture (DenseNet121 with Multi-Scale Self-Attention and Cascaded Classifiers) designed for the hierarchical classification of medicinal plants and address the open world challenges. Our model uses DenseNet121 backbone as a feature extractor to extract the features. We integrate a Multi-Scale Self-Attention mechanism to our proposed method which in turn helps the model to learn different contextual relationship and important features for hierarchical classification . The MSSA mechanism processes multi-scale feature maps from different convolutional layers of DenseNet121, allowing the model to capture both local spatial details and high-level semantic information. Subsequently, cascaded classifiers are employed to predict"}, {"title": "Problem Description", "content": "Traditional classifiers used for medicinal plant classification are unable to perform hierarchical classification at the taxonomic level. This poses a severe challenge for these models as they fail to predict the taxonomic categories when an unknown or new species is discovered. To bridge this challenge we propose a novel architecture that gives us hierarchical classification of medicinal plants. Our proposed model also addresses the challenge of unknown/new species classification. In the following section we discuss in detail our proposed method."}, {"title": "Model Architecture", "content": "The proposed architecture is designed to effectively classify medicinal plants by leveraging rich feature representations and contextual relationships. The architecture integrates DenseNet121 as the backbone network for feature extraction, a Multi-Scale Self-Attention (MSSA) module to enhance contextual relationships, and a series of cascaded classifiers for hierarchical classification. The proposed model architecture is shown in Figure 4"}, {"title": "DenseNet121 Backbone", "content": "DenseNet121 is used as the backbone network due to its dense connectivity, which promotes feature reuse and efficient gradient flow. The DenseNet121 architecture consists of multiple dense blocks, each containing several convolutional layers. The output of each layer is concatenated with the outputs of all preceding layers within the same block, allowing the network to learn robust feature representations. It acts as a feature extractor for our proposed method."}, {"title": "Multi-Scale Self-Attention (MSSA)", "content": "The MSSA module is used with DenseNet121 as its backbone to capture local spatial details and high-level semantic information by applying self-attention to multi-scale feature maps obtained from different convolutional blocks of DenseNet121. In our implementation, we utilize three key layers ('pool2', 'pool3',\u2018pool4\u2018) from DenseNet121 for MSSA. These layers correspond to the outputs after the second, third, and fourth pooling layers, respectively. The \u2018pool2' layer has the highest resolution with dimensions $H_1 \u00d7 W_1 \u00d7 C_1$, while the 'pool3\u2018 and \u2018pool4' layers have progressively smaller resolutions and more channels, denoted as $H_2 \u00d7 W_2 \u00d7 C_2$ and $H_3 \u00d7 W_3 \u00d7 C_3$, respectively. For our MSSA module, we denote these feature maps as $F_1, F_2$, and $F_3$, respectively.\nThe MSSA mechanism can be described as follows:\nLet $C_i$ denote the output of the i-th selected convolutional block of DenseNet121, where i ranges from 1 to 3. To maintain high-resolution spatial details, we resize each output $C_i$ to match the dimension of the highest resolution output $C_1$:\n$C'_i = resize(C_i, shape(C_1)) \tand |C'_i| = |C_1|$\n(3.1)\nNext, we concatenate the resized outputs to construct a multi-scale feature map F:\n$F = C_1 \\bigoplus C'_2 \\bigoplus C'_3$\n(3.2)\nwhere $\\bigoplus$ denotes the concatenation operation. For each input feature map $C \\in R^{H \\times W \\times C_{h1}}$, where H, W, and $C_{h1}$ represent the height, width, and channel dimensions respectively, we apply a 1 \u00d7 1 convolution to transform C into a new feature map $Y \\in R^{H \\times W \\times \\frac{C_{h1}}{8}}$:\n$Y = Conv_{1\u00d71}(C)$\n(3.3)\nSimilarly, for the multi-scale feature map $F \\in R^{H \\times W \\times C_{h2}}$, we apply a 1x1 convolution to generate a new feature map $Z \\in R^{H \\times W \\times \\frac{C_{h1}}{8}}$:\n$Z = Conv_{1\u00d71}(F)$\n(3.4)\nWe then reshape Y to $Y_r$ of size $(H x W) \\times \\frac{C_{h1}}{8}$ and reshape and transpose Z to $Z_{rt}$ of size $\\frac{C_{h1}}{8} x (H x W)$. The attention map A is computed as 2.11\nIn a parallel branch, we apply another 1x1 convolution to transform C into a new feature map $X \\in R^{H \\times W \\times C_{h1}}$, which is then reshaped and transposed to $X_{rt}$ of size $C_{h1} \\times (H \\times W)$.\nThe weighted attention map is computed as 2.12, where $D_i(m, n)$ is the value of a weighted feature map at location (m, n), and u is a learnable parameter initialized to 0. Starting with $D_3$, we apply a 3x3 convolution and concatenate the result with $D_2$ to integrate spatial and semantic information:\n$U_3 = D_3$\n$U_{i\u22121} = conv(U_i) \\bigoplus D_{i\u22121}$ for i = 3 to 2\n(3.5)\n(3.6)\nThe algorithmic steps for chained concatenation operations are as follows:"}, {"title": "Cascaded Classifiers", "content": "The output of the MSSA module is passed through a Global Average Pooling layer to reduce the spatial dimensions, followed by a dense layer with 512 units and ReLU activation, and a dropout layer with a dropout rate of 0.5. Subsequently, the model employs a series of cascaded classifiers to predict taxonomic categories (Phylum, Class, Order, Family, Genus, and Species) in a hierarchical manner. Each classifier branch consists of a dense layer with 256 units and ReLU activation, followed by a softmax output layer tailored to the number of classes in each category. The output of each classifier is concatenated with the input features and fed into the subsequent classifier, ensuring a hierarchical prediction structure. The architecture of each cascaded classifier includes a dense layer with 256 units and ReLU activation, which receives the input features. This dense layer is followed by a softmax output layer that outputs the probability distribution over the classes for the current taxonomic category. The output of the softmax layer is then concatenated with the input features to form the input for the next classifier branch. The use of cascaded classifiers enables us to build a hierarchical system and moreover it helps us to generalize to unknown species based on shared taxonomic characteristics."}, {"title": "Unknown Species Prediction", "content": "For unknown species classification, the model employs a hierarchical classification approach, where predictions are made at various taxonomic levels, including Phylum, Class, Order, Family, Genus, and Species. To determine class membership, a confidence threshold of 0.6 is applied. If the predicted class probability surpasses this threshold, the sample is assigned to that particular class. This threshold is set considering potential noise in the images. The hierarchical process proceeds from broader categories to more specific ones. However, if the confidence falls below 0.6 at any level, the classification process terminates, and the classification taxonomy is generated till that point and is returned as an output to us. This strategy helps ensure robust classification while accommodating the possibility of ambiguous or uncertain predictions. The hierarchical cascaded classifier, featuring an adaptive confidence threshold, proves invaluable for classifying previously unknown species not encountered during training. This approach effectively addresses the challenge of open-world recognition by allowing the system to make informed decisions when faced with unfamiliar species."}, {"title": "Experimental Setup", "content": "In this study, we utilize two types of datasets to evaluate the performance of the proposed model: one dataset with background artifacts and another dataset without background artifacts. The dataset with noise (DIMPSAR), sourced from Kaggle [3], includes images of medicinal plants taken in real-world settings. These images contain various types of background artifacts, such as objects, and environmental factors. This dataset simulates realistic conditions where image data may include additional elements that can interfere with the clear identification of the medicinal plants. The presence of background artifacts in the images presents a significant challenge for the model, testing its robustness and ability to handle real and cluttered data effectively. The dataset without background artifacts, obtained from Mendeley Data [15], consists of clean images of medicinal plants, taken in controlled environments without any background noise. This dataset is used to assess the model's performance under ideal conditions, providing a baseline for comparison with the noisy dataset. The artifact-free images allow the model to focus on learning the intrinsic features of the plants without the interference of extraneous background elements."}, {"title": "Experimental Environment", "content": "In this study, all the experiments were performed on an NVIDIA DGX-1 supercomputer. The supercomputer has the following configuration: Dual 20 Core Intel Xeon E5-2698 V4 clocked at 2.2 GHz, 5120 NVIDIA cores, 512 GB 2.133 GHz DDR4 RDIMM (RAM). All the codes are written in Python version 3.9.13. In the next section we discuss and compare the experimental results."}, {"title": "Results Analysis", "content": "The experiments were performed on two datasets, and the proposed approach was compared with 6 approaches using accuracy as a metric for evaluation. The results are depicted in Table 3 and 4 respectively."}, {"title": "Model Comparison", "content": "Table 3 and 4 shows the model comparison of our model with various models. We can observe that in Table 3 our proposed method outperforms all the models in all the taxonomic categories respectively. Our model achieved a classification accuracy of 99.24% in all taxonomic division. DenseNet also performs well in all the respective taxonomic classification as compared to our proposed method. DenseNet reuses the feature maps, which helps it to perform better classification as compared to other models. When we look at the results obtained by different models on dataset which contains the background environment (Table 4), we can see that despite the background artifacts our model outperforms all the models again in all the taxonomic categories. The drop in classification accuracy in our model is very minimal as compared to other methods. The largest drop (classification accuracy) in our method was seen in Order Classification which was about 2.65%. For the other categories the drop was not more than 2%.\nIf we compare the classification accuracies obtained by other model in the latter dataset, we can clearly see that accuracies have dropped significantly when there are background artifacts. For EfficientNet, phylum classification accuracy dropped from 76.63% to 36.28. For VGG it dropped from 96.24% to 90.21%. Similar trend can be observed for ResNet as well where phylum and class accuracy dropped from 78.63% and 93.89% to 39.29% and 68.58%.\nIn both the dataset integration of MSSA module to VGG and ResNet led to better classification accuracy across all taxonomic categories. Inclusion of MSSA improved their performance because it helped in capturing long-range dependencies in feature maps. Inclusion of MSSA not only enhanced classification but also reduced the model size and memory."}, {"title": "Unknown/New Species Classification Performance", "content": "In this section performance of various models on the task of classifying unknown species is compared in Tables 6 and 7, with and without background artifacts respectively. The results show that the proposed method consistently outperforms other models across multiple taxonomic levels. Four unknown species were considered for classification. They were Wood Sorel, Noni, Oleander and Jackfruit.  The superior performance of the proposed method is due to the integration of multi-scale self-attention module. This module helps the model focus on different parts of the image at various scales, which is particularly useful for recognizing complex patterns and details and retain taxonomic features. By capturing long range dependencies and important features, the model becomes more effective at distinguishing between different categories, even when the images have background artifacts. Additionally, the proposed method uses a larger receptive field, allowing it to"}, {"title": "Cascaded Classifier Performance Comparison for various models", "content": "Moreover, we evaluated the performance of our cascaded classifier across all taxonomic categories for various models. Figures 7,9 and 11 shows the comparison of precision, recall and F1-scores achieved by various model on the dataset which had no background-artifacts. Similarly Figures 8,10 and 12 shows the comparison of precision, recall and F1-scores achieved by various model on the dataset which had background artifacts such as external objects, light etc. In the grouped histogram plots each colour represents a model. To better understand the legend for histogram plot is shown in Figure 6."}, {"title": "Ablation Study", "content": "In this ablation study, we evaluate the impact of combining different techniques on model performance across various taxonomic levels. We consider six combinations of models: DenseNet, DenseNet with MSSA, ResNet, ResNet with MSSA, VGG, and VGG with MSSA. We report the precision/recall and F1 score for each combination on both the old dataset (with background artifacts) and the new dataset (without background artifacts) in Table 8-11. The text in bold represents the test classification accuracy obtained by the proposed architecture"}, {"title": "Discussion", "content": "The integration of MSSA module enhances performance by integrating local spatial details with high-level semantic information from different scales. Using attention scores, MSSA focuses on important features across multiple scales, helping the model capture complex relationships in the data, leading to higher precision and recall, as seen in the improved metrics for all the taxonomic categories. By considering features at multiple scales, MSSA allows the model to understand both fine-grained and broad patterns in the images, which is particularly useful for distinguishing between closely related species, resulting in higher accuracy for Order and Species."}, {"title": "Impact of MSSA on Performance", "content": "Tables 8, 9, 10, and 11 show the precision, recall, and F1-score metrics for different models on both datasets. The results clearly demonstrate that incorporating MSSA significantly improves the performance across all taxonomic levels.\nFor the dataset with background artifacts, the DenseNet + MSSA achieves a precision and recall of 0.98 for Phylum, 0.99 for Class, 0.99 for Order, 0.98 for Family, 0.98 for Genus, and 0.97 for Species. These values are higher than those of the DenseNet without MSSA, which shows the effectiveness of MSSA in capturing important features within the data.\nSimilarly, for the dataset without background artifacts, DenseNet + MSSA achieves fairly good precision and recall across all taxonomic levels. For example, it achieves 0.99 for Phylum, 1.00 for Class, and 0.98 for Species. These results demonstrate that the model performs even better with clean data.\nThe F1-scores further highlight the benefits of MSSA. For the dataset with background artifacts, DenseNet + MSSA achieves F1-scores of 0.98 for Phylum, 0.99 for Class, 0.98 for Order, and 0.97 for Species. These scores represent an improvement over models without MSSA, indicating better overall classification performance. On the dataset without background artifacts, it achieves F1-scores of 0.99 for Phylum, 1.00 for Class, and 0.98 for Species, again outperforming other models."}, {"title": "Model Size and Parameters", "content": "In this section we present a comparison of our proposed approach with respect to other architectures on model size and parameters. As shown in Table 12, our model consists of 6,360,879 parameters, which translates to a memory size of just 24.26 MB. In contrast, the DenseNet21 model has 33,557,116 parameters and requires 128.01 MB of memory. Similarly, the EfficientNet model, with 36,991,711 parameters, occupies 141.11 MB. Even more substantial models like ResNet100, with 75,797,436 parameters, demand 289.14 MB of memory. This significant reduction in model size and memory footprint offers several advantages. Firstly, it makes the model highly suitable for deployment on resource constrained devices, such as mobile phones and embedded systems, which are commonly used in field research and conservation efforts. The compactness of our model ensures that it can be utilized in real-time scenarios without incurring substantial computational overhead, making it practical for on-the-go applications.\nFurthermore, the reduced memory requirement enhances the model's scalability and responsiveness, allowing it to process and classify medicinal plant images more swiftly and efficiently. This efficiency does not come at the cost of accuracy, as our model maintains good performance metrics in both the datasets. This presents our model as an optimal balance between effectiveness and resource efficiency, making it an ideal solution for real-world applications in medicinal plant classification."}, {"title": "Conclusion", "content": "In this study, we introduced a new model which integrates DenseNet121 with a Multi-Scale Self-Attention (MSSA) mechanism and a cascaded classifier for the hierarchical classification of medicinal plants. Our experiments on datasets with and without background artifacts demonstrated that the inclusion of MSSA significantly enhances the model's performance, achieving higher precision, recall, and F1-scores across all taxonomic levels compared to traditional classifiers. The MSSA module is beneficial because it incorporates attention scores to capture complex relationships within the data, integrating local spatial details with high-level semantic information from different scales. This capability allows the model to handle noisy data and accurately distinguish between closely related species, making it well-suited for real world applications where image data may be degraded due to environmental factors. Our model outperformed other models in our study, particularly while handling dataset with background artifacts, demonstrating its effectiveness. Our results highlighted the importance of incorporating MSSA in hierarchical classification tasks, paving the way for more accurate and reliable medicinal plant classification. Our model when tested on unknown species provided promising results. By accurately predicting higher taxonomic levels such as phylum, class, and order, the model can generalize and classify unknown species that share these characteristics with known species. This hierarchical approach ensures that even when encountering novel species, the model can still provide meaningful classifications based on shared taxonomic features, enhancing its utility in biodiversity research and conservation efforts. Overall, this model represents a significant advancement in the field of medicinal plant classification, providing a powerful tool for researchers and practitioners in botany, pharmacology, and related fields. Future work will explore further enhancements to the model, including the integration of additional attention mechanisms and the application to other hierarchical classification tasks."}]}