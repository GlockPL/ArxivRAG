{"title": "LLM4DistReconfig: A Fine-tuned Large Language Model for Power Distribution Network Reconfiguration", "authors": ["Panayiotis Christou", "Md. Zahidul Islam", "Yuzhang Lin", "Jingwei Xiong"], "abstract": "Power distribution networks are evolving due to the integration of distributed energy resources (DERs) and increased customer participation. To maintain optimal operation, minimize losses, and meet varying load demands, frequent network reconfiguration is necessary. Traditionally, the reconfiguration task relies on optimization software and expert operators, but as systems grow more complex, faster and more adaptive solutions are required without expert intervention. Data-driven reconfiguration is gaining traction for its accuracy, speed, and robustness against incomplete network data. Large language models (LLMs), with their ability to capture complex patterns, offer a promising approach for efficient and responsive network reconfiguration in evolving complex power networks.\nIn this work, we introduce LLM4DistReconfig, a deep learning-based approach utilizing a fine-tuned LLM to solve the distribution network reconfiguration problem. By carefully crafting prompts and designing a custom loss function, we train the LLM with inputs representing network parameters such as buses, available lines, open lines, node voltages, and system loss. The model then predicts optimal reconfigurations by outputting updated network configurations that minimize system loss while meeting operational constraints. Our approach significantly reduces inference time compared to classical algorithms, allowing for near real-time optimal reconfiguration after training. Experimental results show that our method generates optimal configurations minimizing system loss for five individual and a combined test dataset. It also produces minimal invalid edges, no cycles, or subgraphs across all datasets, fulfilling domain-specific needs. Additionally, the generated responses contain less than 5% improper outputs on seen networks and satisfactory results on unseen networks, demonstrating its effectiveness and reliability for the reconfiguration task.", "sections": [{"title": "1 Introduction", "content": "Power distribution network reconfiguration is crucial for maintaining operational efficiency, reliability, and adaptability in modern power networks. The integration of distributed energy resources (DERs), such as renewable energy sources like solar and wind, introduces variability and uncertainty, necessitating sophisticated control strategies to balance loads, minimize power losses, and maintain voltage stability (Sultana et al., 2016). Effective network reconfiguration enhances the network's ability to accommodate these renewable sources, optimize energy flow, and ensure resilience against disturbances, supporting the transition toward a more sustainable and flexible power infrastructure.\nTraditional optimization methods for network reconfiguration, while effective, often suffer from computational complexity and scalability issues, especially as power networks grow in size and complexity (Mishra et al., 2017). Large Language Models (LLMs) have emerged as a promising alternative, capable of learning complex patterns and dependencies within large datasets. By leveraging their ability to handle diverse inputs and generate structured outputs, LLMs can provide rapid, data-driven solutions for network reconfiguration, reducing the need for iterative computations typical of conventional approaches.\nLLMs, such as GPT (Brown et al., 2020) and BERT (Devlin et al., 2019), have revolutionized natural language processing and have shown remarkable success in tasks involving understanding, generation, and reasoning over textual data. Their applications have extended beyond text-related tasks to complex decision-making domains, leveraging their capacity to process vast amounts of data and generate coherent, context-aware predictions (Minaee et al., 2024). In power systems, the potential of LLMs is explored in predictive maintenance, optimal power-flow, and decision-making processes that involve large-scale, multi-objective considerations (Huang et al., 2023; Choi et al., 2024).\nHowever, applying LLMs to the power distribution network reconfiguration task presents unique challenges. The critical nature of this task means that errors can lead to system instability or inefficiencies. It involves multiple sub-tasks, such as assessing system voltages, managing losses, and adhering to physical laws, all of which require precise decision-making (Sultana et al., 2016). Fine-tuning LLMs specifically for reconfiguration tasks is essential to ensure that the models can effectively handle these complexities and contribute meaningful solutions.\nExisting literature on network reconfiguration has focused on various optimization techniques. Early work by (A and H, 1974) introduced a heuristic search method for loss minimization, formulating the problem as finding a minimal-loss spanning tree. (Civanlar et al., 1988) proposed a simplified branch exchange method to reduce losses in distribution feeders. Heuristic methods were further advanced by (Gomes et al., 2005), who developed algorithms capable of handling larger and more complex systems. Evolutionary approaches, such as genetic algorithms applied by (Roux et al., 2012), have also been explored for load balancing and multi-objective optimization.\nRecent studies have begun integrating machine learning techniques with optimization algorithms (Ji et al., 2021). For instance, (Li et al., 2021) presented a deep reinforcement learning framework for multi-objective network reconfiguration under varying network conditions. Despite these advancements, the application of LLMs to reconfiguration task remains unexplored.\nOur Contributions: In this paper, we introduce LLM4DistReconfig, a novel approach utilizing fine-tuned large language models to solve the power distribution network reconfiguration problem. To the best of our knowledge, this is the first work to fine-tune LLMs with a custom loss function for this task. Our key contributions are as follows:\n\u2022 We fine-tune LLaMA 2 (Touvron et al., 2023) and LLaMA 3 (Dubey et al., 2024) models to optimize network reconfiguration in response to changing system demands, utilizing the expanded context window in LLaMA 3.1 (120k tokens) to handle larger network sizes. Custom datasets are created for various network sizes in ChatML format, optimized for power networks by reducing precision where necessary and removing irrelevant details.\n\u2022 Our approach refines prompt instructions to prevent issues such as invalid line selections, cycles, and subgraphs, which violate power domain-specific constraints. We ensure the outputs adhere to a structured format (e.g., system loss, line tuples) and guide the model to retain previous configurations when new ones do not reduce system losses.\n\u2022 We design post-processing pipelines for both training and inference to parse model outputs and calculate a custom loss based on the presence of invalid lines, cycles, and subgraphs in the reconfiguration task. A penalty-based system in the custom loss function helps the model learn to avoid these issues, improving line selection accuracy and enforcing domain-specific constraints.\n\u2022 To ensure robustness, the final outputs undergo post-processing to eliminate responses that could lead to system failures. The model also supports interactive modifications through chat, allowing users to refine or guide responses to meet custom output requirements.\nOur work demonstrates the potential of LLMs in solving complex optimization problems in power networks, highlighting the importance of combining prompt engineering with customized training objectives when adapting LLMs to specialized domains. The dataset and codebase used in this paper have been made publicly available on GitHub\u00b9 to facilitate the replication of our results and encourage further contributions."}, {"title": "2 Reconfiguration Problem and Large Language Models", "content": ""}, {"title": "2.1 Reconfiguration Problem", "content": "The power distribution network reconfiguration problem involves finding an optimal topology of the distribution network to minimize system losses and improve operational performance while satisfying all operational constraints. The distribution network is modeled as a graph G(N, E), where nodes N represent buses (load points, substations, etc.)"}, {"title": "2.2 Fine-Tuning LLMs for the Reconfiguration Task", "content": "Applying LLMs to the network reconfiguration problem offers a novel approach to address its inherent complexities. However, directly applying pre-trained LLMs to this domain is insufficient due to the highly specialized and technical nature of the task. Fine-tuning is necessary to adapt the LLM to understand the specific constraints and operational principles of power distribution networks.\nFine-tuning the LLM involves training it on domain-specific datasets that include examples of network configurations, operational scenarios, and associated outcomes. Through this process, the LLM learns to understand network topology, incorporate operational constraints, optimize objectives, and generate feasible configurations.\nBy fine-tuning the LLM for the reconfiguration task, we can harness its ability to generalize from data, enabling it to propose effective reconfiguration strategies without exhaustive computation or extensive expert intervention. This approach can facilitate near real-time decision-making and make the reconfiguration process more feasible."}, {"title": "2.3 Dataset Preparation", "content": "A critical component of fine-tuning LLMs for domain-specific tasks is the availability of a high-quality dataset. In the context of network reconfiguration, real-world operational data may be scarce or confidential. To overcome this limitation, we generate a synthetic dataset that simulates realistic operational scenarios.\nWe utilize established power system simulation tools, such as MATPOWER (Zimmerman et al., 2010), to model and simulate various network configurations and loading conditions. Specifically, we consider standard IEEE distribution test feeders, including the 33-node, 37-node, 69-node, 84-node, and 136-node networks (Harsh and Das, 2023). These test cases provide diverse network topologies and complexities for comprehensive training.\nFor each network, we simulate various loading scenarios by varying the demand at different buses using open-source load data (UK Power, 2024). The simulation generates corresponding optimal reconfiguration solutions using the optimization algorithm documented in the literature Mishra et al. (2017). Each data sample includes network topology, operating voltages and system loss, operating configuration (i.e., open lines), the resulting configuration, power losses, voltage profiles.\nThe dataset is formatted to be compatible with the LLM's input requirements, ensuring that the model can effectively learn from the data. The complete dataset processing pipeline is shown in Figure 1. As shown in Figure 1 we remove redundancy, and thus reducing the number of tokens in the prompt, by removing the existing and updated connectivity matrices since their information is already conveyed by the busses and lines. We also reduce the precision as outlined in section 4. We also represent the nodes (buses) as a single inferred number (Nth node), starting from 1, rather than a list of numbers for a more simplified node representation. We append instructions to each sample as part of the prompt as detailed in Appendix A.6. By generating a large number of such samples across different networks and scenarios, we provide the LLM with sufficient information to capture the complex relationships inherent in the reconfiguration problem.\nTo prepare for training, the processed dataset is converted to ChatML format for training. The input is comprised with the following columns:\n\u2022 Buses: The nodes of the power grid.\n\u2022 Lines: The edges of the power grid.\n\u2022 Line Impedances: Edge features representing the characteristics of the lines.\n\u2022 Existing Open Lines: The initial set of deactivated lines.\n\u2022 Existing Node Voltages: The initial voltages levels at each node.\n\u2022 Existing System Loss: The total system loss in the initial configuration.\n\u2022 System Load: The load on each node at a specific time.\nExample: Buses: 33, Lines: [(1,2), (2,3), ...], Line Impedances: [0.00064569, 0.00, ...]\nThe output is similarly structured and includes the reconfigured values. The output is comprised with the following columns:\n\u2022 Updated Open Lines: The new set of deactivated lines.\n\u2022 Updated Node Voltages: The updated voltage levels at each node.\n\u2022 Updated System Loss: The total system loss after reconfiguration.\nThe input and instruction are concatenated to form the prompt. An example task description including prompt and input is provided in Table 5 in Appendix A.6. The output remains separately structured to allow for accurate training. More dataset details can be found in Appendix A.4."}, {"title": "3 Incorporating Domain-Specific Constraints into LLMs", "content": ""}, {"title": "3.1 Instruction Prompt Refinement", "content": "Adapting LLMs to domain-specific tasks requires careful guidance to ensure adherence to specialized constraints. In the context of power distribution networks, characterized by attributes such as the number of buses, lines, operating voltages, and system losses, LLMs must generate outputs that are not only syntactically correct but also operationally feasible.\nTo achieve this, instruction prompts were iteratively refined to embed domain knowledge and constraints directly into the model's input. The initial prompts simply described the reconfiguration problem, representing the network as a graph with buses as nodes and lines as edges. However, the model often generated invalid configurations, including nonexistent lines and cyclic graphs, indicating a gap in understanding the domain's constraints.\nMotivated by these observations, additional instructions were incorporated:\n\u2022 Constraint on Valid Lines: Only lines provided in the input data should be considered to prevent the generation of invalid or nonexistent lines. This helps the model focus on feasible reconfigurations within the actual network topology.\n\u2022 Ensuring Radial Connectivity: The output graph must be a single connected component without cycles, reflecting the radial nature of power distribution networks. This guides the model toward generating operationally viable configurations.\n\u2022 Acyclic Graph Specification: The number of closed lines must equal the number of nodes minus one, which mathematically enforces an acyclic (tree) structure. This instruction addresses the issue of residual cycles in the model's output.\n\u2022 Operational Constraints and Output Formatting: Practical considerations include instructing the model not to reconfigure the network if the inferred system loss increases and providing explicit output format requirements. This ensures that the model's outputs are not only correct but also practically useful.\nEach refinement was motivated by specific shortcomings in the model's performance, aiming to incrementally improve its adherence to domain constraints and operational requirements. Figure 1 shows how the initial dataset goes through the steps of the processing by reducing precision, removing columns, adding the task, generating the prompt and eventually getting to the final dataset used for training and evaluation."}, {"title": "3.2 Custom Loss Function", "content": "Even with refined prompts, the model sometimes produced outputs violating domain constraints. To further enforce these constraints during training, a custom loss function was developed, comprising three key components:\nCycle Loss Cycles in the output graph $G_{output}$ = (V, $E_{available}$ \\ $E_{output}$) obtained from model responses are undesirable, as they violate the radial topology of power distribution networks. The cycle loss penalizes the presence of such cycles:\n$L_{cycle} = |C(G_{output})|$\nwhere C($G_{output}$) is the set of cycles in $G_{output}$. This component encourages the model to generate acyclic graphs.\nSubgraph Loss Disconnected subgraphs indicate a network that is not fully connected, which is operationally infeasible. Subgraph loss penalizes the existence of multiple connected components:\n$L_{subgraph} = k - 1$\nwhere k is the number of connected components in $G_{output}$. This loss component drives the model toward producing a single, fully connected network.\nSuboptimal Configuration Loss The inclusion of lines in generated open lines not present in the optimal open lines can lead to suboptimal configurations. The suboptimal configuration loss penalizes such occurrences by subtracting generated open lines ($E_{output}$) from optimal open lines ($E_{optimal}$):\n$L_{subconfig} = |E_{output} \\ E_{optimal}|$\nTotal Loss The total loss combines the standard training loss $L_{reg}$ with custom loss components, each scaled by a factor i to balance their impact:\n$L_{total} = L_{reg} + \\lambda_{1}L_{cycle} + \\lambda_{2}L_{subgraph} + \\lambda_{3}L_{subconfig}$\nThis comprehensive loss function guides the model to produce outputs that are not only syntactically correct but also conform to domain-specific operational constraints."}, {"title": "3.3 Fine-Tuning Process and Loss Scaling", "content": "The fine-tuning process involves presenting the refined prompts to the model and analyzing its outputs to compute the custom loss components. Model output is obtained by parsing the output, detailed in A.2. To ensure stable training and effective learning, scaling of the loss components is essential:\n\u2022 Cycle Loss Scaling: The cycle loss is divided by the number of available lines to prevent it from dominating the total loss, especially in cases where the number of potential cycles is large."}, {"title": "4 Experimental Setup", "content": ""}, {"title": "4.1 Dataset Generation and Optimization", "content": "We generate our dataset using IEEE Y Bus Systems with sizes ranging from 33 to 136 buses (denoted as 33N, 37N, 69N, 84N, and 136N). For each network, the dataset is represented as $X^{mxn}$, where n = 17, 520 is the number of samples and m = 12 is the initial number of features. To optimize the dataset, we reduce the feature set by dropping redundant connectivity data, resulting in a reduced dataset with m = 10 features:\n$X^{mxn} = X^{17520\\times12} \\rightarrow X^{17520\\times10}$\nAdditionally, we scale the number of buses from a list of comma-separated values to a scalar, representing the total number of buses. Precision is reduced to five decimal places for all variables:\nv' = round(v, 5)"}, {"title": "4.2 LLM Training and Inference", "content": "Initially, we experimented with GPT-3, but its small context window (2049 tokens) and proprietary nature led us to switch to LLaMA-2 (7B parameters) with a 4096-token context window. However, even this model posed limitations due to its context size. LLaMA-3.1, with a 120,000-token context window and optimized training features such as Flash Attention 2, solved these issues, as explained in A.2.\nWe fine-tuned the LLaMA-3.1 model, our flagship fine-tuned model, on a combined dataset (33N, 69N, and 84N) with 52,560 samples, split equally into training, validation, and test sets. The model was trained for 30 epochs on a V100 GPU (20GB VRAM) over 285 hours using the LLaMA-3.1 tokenizer and AutoTrain from Huggingface. While we considered using A100 GPUs (80GB VRAM) for larger batch sizes and distributed training, resource constraints led us to prioritize multiple jobs across different datasets. The model was trained in increments of 10 epochs, allowing us to evaluate model performance after each training stage. The full training and inference pipeline is shown in diagram 3. We can see the main backbone of the pipeline stays the same and only the post generation part changes accordingly for custom loss calculation during training or post-processing re-prompting during inference. A full list of hyperparameters is provided in A.7."}, {"title": "4.3 Model Testing and Generalization", "content": "We evaluated the model's performance on the test sets for 33N, 69N, and 84N networks, as well as unseen 37N and 136N networks to assess generalization. The metrics included the number of suboptimal configuration, cycles, subgraphs, and average inference time. The average inference time per network size and per maximum number of new tokens"}, {"title": "5 Case Studies", "content": ""}, {"title": "5.1 Effectiveness of augmented prompts and custom loss", "content": "Below, we present the performance of different models, highlighting the effects of prompt augmentation, the addition of custom loss components, and the impact of training for more epochs. While the cycle and subgraph issues were addressed with augmented prompts, the number of improper responses remained high.\nIn Figure 4, we show the performance of the fine-tuned LLaMA-2 7B model with different iterations of augmented prompts (APx), custom loss, and varying training epochs. The figure demonstrates that the model generated fewer improper responses as more instructions were added. Specifically, when moving from iteration 2 to 4, the improper responses were reduced from 481 to 331 out of 500 test samples on the combined dataset, representing approximately a 31% improvement. After adding custom loss alongside the augmented prompts and training the model, the improper responses further decreased to 208. This number continued to decline as we increased the training epochs from 1 to 3 to 10. Finally, with 10 epochs of training, augmented prompts, and custom loss, the number of improper responses dropped to 24 out of 500 test samples-less than 5%. The figure illustrates the effectiveness of both prompt augmentation and the custom loss function. We observed a similar trend for our flagship fine-tuned LLaMA-3.1 8B model.\nFigure 5 shows a sample LLM-generated network configuration. In the initial iterations of instruction prompts, cycles and subgraphs were observed in the generated configuration, as seen in Figure 5(a). As we trained the model with both augmented prompts and custom loss, its performance improved, resulting in a reconfiguration that met our requirements, i.e., no cycles, subgraphs, or suboptimal config, as shown in Figure 5(b)."}, {"title": "5.2 Effectiveness of Fine-tuned LLMs", "content": "Below, we present the performance of our fine-tuned LLaMA-3.1 8B model (trained for 20 epochs) relative to baseline models, including the untrained LLaMA-2 7B, LLaMA-3.1 8B, Falcon 7B (Penedo et al., 2023), and Mistral 7B (Jiang et al., 2023). All the baseline models are open-source and have approximately the same number of parameters. We test how these models perform on the combined dataset. This allows us to evaluate the performance of our fine-tuned model compared to publicly available chat models and models similar to ours in architecture, such as LLaMA-2 and LLaMA-3.1, as well as models with different architectures, like Falcon and Mistral.\nThe baseline models struggled to generate the expected outputs for most test samples, as shown in Figure 6. This is due to the strict requirements for the outputs, which cannot be met without fine-tuning. The baselines often produced steps for reconfiguring the network, along with some sample code, but failed to provide the desired output. Sample responses from all models are included in the Appendix A.6.\nAdditionally, we compare the system loss inferred by the proposed model with the actual operating system loss in Figure 7 to demonstrate the model's optimization capability. It is observed that the system losses for both configurations overlap for most test samples. We also present the mean absolute error (MAE) of the inferred and actual network operating voltages, which shows that the error is nearly zero. These comparisons in network operating parameters further highlight the effectiveness and practical applicability of the generated responses in real systems. We also compare the computation time of the fine-tuned LLM model against existing optimization algorithms in Appendix A.8."}, {"title": "5.3 Generalization Capabilities", "content": "Below, we present the performance of our fine-tuned Llama-3.1 8B on all individual datasets both seen (i.e., 33N, 69N, and 84N) and unseen (i.e., 37N and 136N) and the combined network dataset on the improper outputs and subobtimal config. Refer to Appendix A.5 for the detailed results.\nIt can be seen from Figure 8 that the fine-tuned model generates highly proper responses for the seen network and the combined datasets. For instance, the 33N model generated only 5 improper responses out of 500 test samples, which is just 1%. The result is consistent across all the seen networks, as shown in Figure 8. Detailed results are also provided in Appendix A.5.\nTo demonstrate the generalization capacity of the models, we tested the performance of the model trained on the combined dataset on two unseen networks. An interesting trend is observed in the results. On the 37N network dataset, the 20-epoch model shows similar performance to the seen networks, whereas the 30-epoch model produces many improper responses. This suggests that the 30-epoch model likely overfits for this network. However, for the 136N network, although the 10-epoch and 20-epoch models generate many improper responses, the 30-epoch model performs better by halving the improper responses, indicating that larger networks benefit from models trained for more epochs. This trend shows that the model can indeed generalize to unseen datasets with significantly different prompt (sequence) lengths than those it was trained on. However, its performance could further improve with training on more diverse datasets than the current one.\nBased on Figure 9, we observe that the model minimizes suboptimal configurations, where the generated open lines are different from true open lines. Model generates consistent results across all datasets except 37N one, probably due to the random sampling."}, {"title": "6 Conclusion and Discussion", "content": "In this paper, we introduced LLM4DistReconfig, an innovative fine-tuned large language model designed to address the power distribution network reconfiguration problem. Our evaluations show that the fine-tuned model not only performs well on the networks it was trained on but also generalizes effectively to unseen datasets, including networks significantly larger than those used during training. The model's predicted system losses and node voltages showed almost zero deviation in node voltage predictions, showcasing its practical applicability. Additionally, we observed that increasing the number of training epochs positively impacts the reduction of suboptimal configuration and improper responses, reinforcing the importance of extended training in improving model performance. In comparison, baseline models such as LLaMA-2, Falcon, and Mistral were unable to generate valid outputs for most test samples. This stark contrast underscores the effectiveness of our fine-tuning approach and custom loss functions for domain-specific tasks like power distribution network reconfiguration.\nThese findings show the vast potential of LLMs in revolutionizing the power systems field by providing interactive, intelligent tools for solving complex optimization problems, as discussed in A.3.\nIn future work, we aim to extensively improve the model output parser to identify all possible patterns through more efficient pattern search algorithms, enhancing the model's ability to interpret and generate a wider variety of valid configurations. Incorporating better embedding techniques and employing instruction masking during training may capture more nuanced relationships in the data, further improving performance. Exploring better hyperparameters, such as the size of LoRA adapters could also yield performance gains. A critical next step is the inclusion of unbalanced network models in the dataset. Although this will require extensive optimization due to increased complexity and size, it will significantly broaden the model's applicability to real-world scenarios.\nWe demonstrate that fine-tuned LLMs like LLM4DistReconfig have great potential in solving complex optimization problems in power systems. By effectively learning from and generalizing to diverse network configurations, the model serves as a valuable tool for power system engineers."}, {"title": "7 Limitations", "content": ""}, {"title": "7.1 AI with LLMs Perspective", "content": "During the fine-tuning process, we addressed many significant challenges that arose, especially given our limited resources and the complexities of parsing. However, certain issues had to be left for future work.\nEarly in the evaluation of our benchmark models, such as the fine-tuned LLaMA-2 7B (trained for 10 epochs), we recognized an inherent flaw in the training process. During response generation, the model was also generating the instruction, which meant it did not fully focus on learning how to generate the proper output from a given prompt. Instead, it learned to generate the entire sequence, hindering its ability to perform the actual task effectively.\nAdditionally, rather than fine-tuning the entire model, we trained LoRA adapters (Hu et al., 2021) to learn the task. We did not conduct extensive evaluations to determine the optimal size of the LORA adapters for this task, and further exploration is needed to understand the effect of adapter size on learning performance. We plan to conduct a detailed exploration of hyperparameters for LoRA adapters, which are crucial for the model's expressivity, generalization, and performance. Additionally, we plan to examine the impact of generation hyperparameters on the model's performance for both the reconfiguration task and conversational capabilities.\nThe datasets we used were generated based on the IEEE Standard networks, e.g., the 33N Test Case (Dolatabadi et al., 2021), using standard optimization algorithms. This meant that we were limited in the amount of variance in network sizes, which is essential for the model to generalize effectively. Although we had a wide range of model sizes, we only trained on three of them and tested on two. While we had thousands of samples and the model was able to generalize to a certain extent, there are still data limitations. Furthermore, during training on the combined dataset, we randomly sampled values from the existing samples. Since the datasets are of the same size, we believe that an alternative approach would be to randomly sample from individual datasets and rotate through each dataset during training and evaluation to achieve better representation of each dataset.\nWe included one out-of-distribution 136-node network dataset, which is larger than the maximum 84-node network dataset used for training. As shown in Figures 8 and 9, the 30-epoch trained model demonstrates improved performance in reducing improper responses and suboptimal configurations on the 136-node dataset. Moving forward, as we refine our model, we plan to evaluate its performance on large-scale unbalanced network datasets that differ significantly from the training data."}, {"title": "7.2 System Design Perspective", "content": "We designed our system to abstract the user from the actual response of the model, which required significant effort in parsing the output. In the initial stages, we encountered errors due to lenient output processing. We had to enforce more constraints and clean the output before searching for the required patterns, accounting for trailing commas, whitespace, and other inconsistencies. This necessity steered us away from extensively incorporating re-prompting into the system. In future work, we aim to design the dataset to incorporate re-prompting so that the model will learn to adjust its output based on automated prompts.\nSpecifically for the parser, we aim to identify and account for edge cases in the output that may misclassify responses as improper due to improper pattern matching. We also aim to implement algorithmic enhancements that will ensure accurate parsing of outputs and enable seamless extraction of valid responses. We plan to create utilities that automate the process of generating prompts for minor configuration modifications. For example, changing an edge to utilize a different node, instructing the model to not use a specific edge or generating a configuration that reduces the node voltage of a specific node.\nAdditionally, during generation, we encountered a problem with the maximum number of new tokens being generated. Since we could not change this number dynamically for each sample, we resorted to using the largest number required by the largest individual network in the combined dataset. We believe that this variable significantly influences the model's output on the reconfiguration task, and we need to reconsider our approach to set a optimal number of new tokens to generalize on larger unseen networks than those the model is trained on."}, {"title": "7.3 Power Distribution Network Perspective", "content": "Due to privacy concerns, real-world distribution network models are not widely available, leading us to use IEEE-standard test cases. It is essential to use real network models of varying sizes to train the LLM and achieve more accurate and practical responses. Additionally, we used a balanced network model to generate our dataset. In reality, distribution networks are unbalanced and pose additional challenges that need to be considered. We presented this work using a balanced system to demonstrate the potential of LLMs in the network reconfiguration task, which will, in turn, motivate both researchers in academia and professionals in industry to explore this problem in real-world unbalanced systems. Furthermore, a new dataset is needed to enhance the reasoning capabilities of LLMs, which we plan to explore in future work.\nIn the current study, we used MATPOWER software for power system model simulations. While MATPOWER is well-suited for handling balanced systems, it lacks the capability to simulate unbalanced systems. To address this, we plan to use OpenDSS, a software developed by EPRI that efficiently simulates three-phase unbalanced systems and is widely adopted in the industry. By incorporating industry-standard software for dataset generation, we aim to move one step closer to adopting LLMs for real-world power system operations."}, {"title": "7.4 Data Security and User Privacy Protection", "content": "We acknowledge the concern that real-world network model data could be sensitive. To address this, we utilized publicly available standard power distribution network models to generate the dataset used for LLM fine-tuning, ensuring compliance with privacy laws. Additionally, our model is designed to operate locally on a single GPU, eliminating the need for data sharing with external users and allowing secure, local usage. To ensure proper usage and flexibility we envision the model being adopted and fine-tuned by users on their specific network to address their unique requirements in a local environment. The pre-trained nature of our model minimizes the data and time required for fine-tuning, making it accessible for a variety of applications while preserving privacy. For example, utility companies can adopt and customize our model for their network without relying on proprietary solutions, such as ChatGPT. We released our codebase as open source, enabling researchers to evaluate it independently and ensure compliance with privacy laws."}, {"title": "A Appendix", "content": ""}, {"title": "A.1 Detailed Formulation of the Distribution Network Reconfiguration Problem", "content": "Let the power distribution network be represented as a graph G(N, E), where N is the set of nodes (buses) and E is the set of edges (distribution lines) connecting the nodes. A subset of edges $E_{sw} \\in E$ is occupied with switches, meaning that they can be either on ($s_e$ = 1) or off($s_e$ = 0). While the remaining edges e $\\in$ E \\ $E_{sw}$ are always on ($s_e$ = 1).\nThe objective of the reconfiguration problem is to get a network topology by changing the status of the edges e $\\in$ $E_{sw}$ that minimizes the system loss, expressed as below:\n$\\min_{s_e} \\sum_{e \\in E} R_e I_e$\nwhere $R_e$ is the resistance and $I_e$ is the current flow through edge e.\nThe reconfiguration problem needs to satisfy the following constraints for the network being operational.\nDemand and Generation Equality Constraints: The total power generated by the generation nodes must equal the total power demanded by the load nodes:\n$\\sum_{n \\in N_{gen}} P_{n}^{gen} = \\sum_{n \\in N_{load}} P_{n}^{load}$\nwhere $N_{gen} \\subseteq N$ is the set of generation nodes, $N_{load} \\subseteq N$ is the set of load nodes, $P_{ren}^{gen}$ is the power generated at node n $\\in$ $N_{gen}$, and $P_{n}^{load}$ is the power demanded at node n $\\in$ $N_{load}$.\nCapacity Limit Constraints: The power flow on each edge e $\\in$ E must not exceed the maximum allowable power capacity $P_e^{max}$.\n$P_e< P_e^{max}, \\forall e \\in E$\nThis ensures that no distribution line is overloaded.\nTopology Constraints: The network must remain connected and radial. This means the graph G(N, E), representing the distribution network, must satisfy:\n$\\sum_{e \\in E} s_e = |N| - 1$\nensuring that the network has no loops (radiality) and that every node in N is reachable from the substation (connectivity).\nOperational Constraints: Voltage levels at each node n $\\in$ $N_p$ must be maintained within acceptable bounds:\n$V_{min} \\leq V_n \\leq V_{max}, \\forall n \\in N$\nwhere $V_{min}$ and $V_{max}$ represent the minimum and maximum allowable voltage limits.\nThe power distribution network reconfiguration problem is well-known to be NP-hard, requiring significant computational resources and domain expertise to solve effectively."}, {"title": "A.2 Challenges in Training", "content": "There were several challenges in training the model", "challenges": "n\u2022 The length of the prompt was large, especially when initially using GPT-3, which had a limited context window of 2049 tokens. We had to perform optimizations and make model choices to overcome this limitation.\\"}]}