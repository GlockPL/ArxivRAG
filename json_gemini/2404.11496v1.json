{"title": "RUNTIME ANALYSIS OF EVOLUTIONARY DIVERSITY OPTIMIZATION ON THE MULTI-OBJECTIVE (LEADINGONES, TRAILINGZEROS) PROBLEM", "authors": ["Aneta Neumann", "Frank Neumann", "Denis Antipov", "Andrew M. Sutton"], "abstract": "The diversity optimization is the class of optimization problems, in which we aim at finding a diverse set of good solutions. One of the frequently used approaches to solve such problems is to use evolutionary algorithms which evolve a desired diverse population. This approach is called evolutionary diversity optimization (EDO).\nIn this paper, we analyse EDO on a 3-objective function LOTZk, which is a modification of the 2-objective benchmark function (LeadingOnes, TrailingZeros). We prove that the GSEMO computes a set of all Pareto-optimal solutions in O(kn\u00b3) expected iterations. We also analyze the runtime of the GSEMOD (a modification of the GSEMO for diversity optimization) until it finds a population with the best possible diversity for two different diversity measures, the total imbalance and the sorted imbalances vector. For the first measure we show that the GSEMOD optimizes it asymptotically faster than it finds a Pareto-optimal population, in O(kn\u00b2 log(n)) expected iterations, and for the second measure we show an upper bound of O(k2n\u00b3 log(n)) expected iterations. We complement our theoretical analysis with an empirical study, which shows a very similar behavior for both diversity measures that is close to the theory predictions.", "sections": [{"title": "1 Introduction", "content": "Computing a diverse set of high quality solutions has recently become an important topic in the area of artificial intelligence and in particular in the field of evolutionary computation [1, 2, 3]. Different approaches have been designed for using classical solvers in order to compute diverse sets of high quality solutions for problems in the areas of planning [4] and satisfiability [5]. Such problems are often met in practice, especially when there are some factors which are hard to formalize, such as politics, ethics or aesthetics. In these cases the algorithm user would prefer to have several different good solutions rather than one single best solution to have an opportunity to choose among them. In practice this problem arises in, e.g., optimization of a building floor plans [6] or in the cutting problem [7]."}, {"title": "1.1 Related work", "content": "Feature-based EDO approaches that seek to compute a diverse set of solutions with respect to a given set of features have been carried out for evolving different sets of instances of the traveling salesperson problem [10] as well as evolving diverse sets of images [11]. For these computations a variety of different diversity measures with respect to the given features such as the star discrepancy measure [12] and the use of popular indicators from the area of evolutionary multi-objective optimization [13] have been studied.\nClassical combinatorial optimization problems for which EDO algorithms have been designed to compute diverse sets of solutions include the traveling salesperson problem [14, 15, 16], the traveling thief problem [17], the computation of minimum spanning trees [18] and related communication problems in the area of defense [19].\nEstablishing the theoretical foundations of evolutionary diversity optimization in the context of runtime analysis is a challenging task as it involves the understanding of population dynamics with respect to the given problem and used diversity measure. Initial studies have been carried out for classical benchmark problems in the area of evolutionary computation such as ONEMAX and LEADINGONES [20]. For permutation problems such as the traveling salesperson problem and the quadratic assignment problem runtime bounds have been provided on computing a maximal diverse set of permutation when there is no restriction on the quality of solutions [16]. In the context of the optimization of monotone submodular problems with a given constraints, results on the approximation quality of diversifying greedy approaches that result in diverse population have been provided in [21, 22]."}, {"title": "1.2 Our contribution", "content": "We contribute to the rigorous analysis of the EDO on multi-objective problems and for the first time consider a 3-objective problem called LOTZk (formally defined in the following section). This problem is a modification of the classic bi-objective benchmark problem LOTZ. The main difference is that all solution which meet some quality threshold on LOTZ function lie on the Pareto front of LOTZk.\nWe perform a runtime analysis of a simple evolutionary multi-objective optimizer GSEMOD, which optimizes diversity only when breaking ties between individuals with the same fitness which compete for being included into the population. We prove that the GSEMOD finds a Pareto-optimal population on LOTZk in O(kn\u00b3) expected iterations. We also prove for two different diversity measures the upper bounds on the expected time which it takes the GSEMOD to find the optimal diversity starting from a Pareto-optimal population. For one measure (called the total imbalance) this bound is O(kn\u00b2 log(n)), which is smaller than the upper bound on the runtime until finding a Pareto-optimal population. For the second diversity measure (called the sorted imbalances vector) we prove a weaker upper bound O(k2n\u00b3 log(n)). Our proofs are based on a rigorous study of which individuals allow us to improve the diversity, and we believe that the similar arguments might be fruitful in the future theoretical studies of EDO.\nWe also show empirically that it takes the GSEMOD a relatively short time to find the optimal diversity after covering the whole Pareto front for both diversity measures. This demonstrates the benefits of the EDO approach and also suggests that that optimizing diversity via tie-breaking rules is an easy-to-implement and a very effective method."}, {"title": "2 Preliminaries", "content": "In this paper we consider only pseudo-Boolean optimization, that is, our search space is the set of bit strings of length n. We use the following notation. By [a..b] we denote an integer interval {a, a + 1, . . ., b}. Bits of a bit string x of length n are denoted by xi, where i \u2208 [1..n]. We assume that x\u2081 is the leftmost bit and xn is the rightmost bit. For any non-negative integer i by 1\u00b2 (or 0\u00b2) we denote the all-ones (or all-zeros) bit string of length i. If i = 0, this is an empty string. When we have a Boolean predicate A, we use Iverson bracket [A] to map this Boolean value into {0, 1}.\nDominance. Given two points x and y and a k-objective function f = (f1,..., fk) defined on these points, we say that x dominates y with respect to f, if for all i \u2208 [1..k] we have fi(x) \u2265 fi(y) and there exists j \u2208 [1..k] for which fj(x) > fj(y). We write it as x > y."}, {"title": "2.1 GSEMOD", "content": "The Simple Evolutionary Multi-objective Optimizer (SEMO) is an evolutionary algorithm for solving multi-objective problems. At all iterations this algorithm keeps a population of non-dominated solutions. The SEMO is initialized with a point from the search space chosen uniformly at random (u.a.r. for brevity). In each iteration it chooses an individual from its current population u.a.r. and mutates it. If the mutated offspring is not dominated by any individual in the population, it is added to the population, and the individuals which are dominated by this offspring are removed from the population.\nThe SEMO does not allow two individuals with the same fitness to be in the population. A situation when a new offspring y is identical (in terms of fitness) to some individual x in the population can be handled in different ways. Usually, y replaces x to enhance the exploration of the search space, since y is a new individual, and x is an older one. This tie, however, can also be broken in a way which improves some secondary objective. In this paper we are interested in finding a diverse set of non-dominated solutions, so we can remove an individual with which the diversity measure is worse. We call the SEMO which optimizes a diversity measure D in such way the SEMOD.\nThis mechanism is similar to the tie-breaking rule in the (\u03bc + 1) genetic algorithm (GA) for the single-objective optimization described in [25]. There a tie-breaking rule which optimized the diversity of the population allowed to use crossover in a very effective way to escape local optima. This resulted into a O(nlogn + 2k) runtime on JUMPk benchmark, which is much smaller than the \u03a9(n*\u22121) runtime of most classic GAs on that problem. We have a different situation, where diversity is our primary goal, and the fitness has a role of a constraint (that is, we want the solutions to be Pareto-optimal). However, since the diversity is a measure of the whole population, but not of a single individual, such a tie-breaking rule is a natural way to optimize it after finding a Pareto-optimal population.\nIn literature, the SEMO which uses standard bit mutation to generate new offspring is usually called the Global SEMO (GSEMO). Similarly, we call the SEMOD with standard bit mutation the GSEMOD. The pseudocode of the GSEMOD is shown in Algorithm 1."}, {"title": "2.2 Diversity Measures", "content": "In this paper we consider diversity measures which are based on the balance between 1-bits and 0-bits in each position in the population. For each i \u2208 [1..n] we denote by $n_1(i)$ the number of individuals in the population, which have a"}, {"title": "2.3 LOTZk Problem", "content": "In this paper we consider a classic benchmark bi-objective function (LEADINGONES, TRAILINGZEROS) (LOTZ for brevity), which is defined on a space of bit strings of length n. We call n the problem size. The first objective LEADINGONES (LO for brevity) returns the length of the longest prefix consisting only of 1-bits, more formally,\n$LEADINGONES(x) = LO(x) = \\sum_{i=1}^{n} \\prod_{j=1}^{i}x_j$.\nThe second objective TRAILINGZEROS (TZ for brevity) returns the length of the longest suffix which consists only of 0-bits, namely\n$TRAILINGZEROS(x) = TZ(x) = \\sum_{i=1}^{n} \\prod_{j=n-i+1}^{n}(1-x_j)$.\nThese two objectives contradict each other, and for any bit string x we have LO(x) + TZ(x) \u2264 n.\nThe Pareto front of LOTZ consists of n + 1 bit strings of form $1^i0^{n-i}$, for all i \u2208 [0..n]. This means that the Pareto-optimal population has a fixed diversity. To study the aspects of diversity optimization by the GSEMOD, we modify this problem.\nWe introduce parameter k \u2208 [0..n], and we say that all bit strings x which have LO(x) + TZ(x) \u2265 n \u2212 k do not dominate each other. We call such bit strings and also their fitness values feasible. The fitness values of feasible bit strings are illustrated in Figure 1. We note that there is no bit string x such that LO(x) + TZ(x) = n \u2212 1, for the following reason. Assume that LO(x) = i. Then x has prefix $1^i0$, hence $x_{i+1} = 0$. If TZ(x) = n \u2212 1 \u2212 LO(x) = n - 1 - i, then x also has suffix $10^{n-1-i}$. Then $x_{i+1} = 1$, which contradicts with the requirement on the prefix, hence we cannot have LO(x) + TZ(x) = n \u2212 1.\nTo allow the GSEMOD handle our requirement on the non-domination between feasible bit strings, we define LOTZk as a 3-objective problem\n$LOTZ_k(x) = (LO(x), TZ(x), h(LO(x) + TZ(x)))$,\nwhere h: R \u2192 R is defined as\n$h(x) := \\begin{cases} 0, & \\text{if } x < n-k, \\\\ n+1-x, & \\text{if } x \\ge n-k. \\end{cases}$\nFrom this definition it follows that for any x, y \u2208 [0..n] we have\n$x > y \\Rightarrow \\begin{cases} h(x) \\ge h(y), & \\text{if } y < n-k, \\\\ h(x) < h(y), & \\text{if } y \\ge n-k. \\end{cases}$\nConsequently, if x dominates y in terms of LOTZ (that is, the first two objectives) and both of them are feasible, then we have LO(x) + TZ(x) > LO(y) + TZ(y), and hence the third objective is better for y. Hence, any pair of"}, {"title": "3 Optimal Diversity", "content": "In this section we show the best possible diversity of a population which covers the whole Pareto front of LOTZk (that is, which contains all feasible fitness values). Although we will not derive a simple formula for the optimal vector of imbalances for each position, we will show how the optimal diversity can be computed. We will use the observations from this section in our runtime analysis and also in our experiments to determine the moment when the algorithm finds the optimal diversity.\nBefore discussing the optimal diversity, we show the following lemma which estimates the population size of GSEMOD on different stages of the optimization.\nLemma 1. When the GSEMOD runs on LOTZK with k \u2265 2, before it finds the first feasible solution, the maximum population size is $max_{x \\in P} (LO(x)+TZ(x))+1 < n-k$. Once the GSEMOD finds a feasible solution, the maximum population size is $\u00b5_{max} = nk - \\frac{(k-2)(k+1)}{2} < nk$. The size of any Pareto-optimal population containing all feasible fitness values is also \u00b5max.\nProof. Before we find a feasible solution we can only have one individual per each LO value in the population, since if we had two of them (and both were infeasible), then the one of them with a larger TZ value would dominate another, which is impossible by the definition of the GSEMOD. They also cannot have the same TZ value, since then they will have an identical fitness, which is also impossible by the definition of the GSEMOD. The number of different LO values of the population is not greater than the maximum LO + TZ value in the population plus one. If we do not have feasible solutions in the population, this value is always not greater than n \u2212 k."}, {"title": "4 Runtime Analysis of Covering All Fitness Values", "content": "In this section we analyze the first stage of the algorithm, namely how it gets a Pareto-optimal population which contains all feasible solutions. The main result of this section is the following theorem. We note that although it is formulated for the GSEMOD, the proof does not use the tie breaking rule in any of the arguments, hence this upper bound also holds for the GSEMO.\nTheorem 1. The expected runtime until the GSEMOD finds all feasible solutions of LOTZk is O(kn\u00b3).\nProof. We split the analysis into three phases. The first phase is from the initial population until we find a feasible solution. The second phase lasts until for each LEADINGONES value we have at least one feasible solution in the population. And the third phase lasts until we find all feasible solutions. We note that once a feasible solution gets into a population of GSEMOD, its fitness value will always be present in the population, since this solution is never dominated by any other solution.\nPhase 1: from initial solution to a feasible solution. Let $X_t$ be $max_{x \\in P_t} (LO(x) + TZ(x))$, where Pt is the population in the beginning of iteration t. During this phase we have Xt <n-k and the phase ends as soon as we get Xt > n-k. We also note that Xt never decreases with t, since for any two bit strings x, y it is impossible for y to dominate x when LO(x) + TZ(x) > LO(y) + TZ(y), hence any point x can be removed from the population only by accepting a point with an equal or lager LO + TZ value.\nTo get $X_{t+1} > X_t$ after iteration t we can choose an individual x with maximum value of (LO(x) + TZ(x)) as a parent (or any such individual, if there are more than one) and increase either its LO value by flipping the first 0-bit in it (and not flipping any other bit) or its TZ value by flipping its last 1-bit (and not flipping any other bit). Since we use standard bit mutation, the probability to flip only one of two particular bits is at least $2(\\frac{1}{n})(1-\\frac{1}{n})^{n-1} \\ge \\frac{2}{en}$. By Lemma 1, during this phase the population size in iteration t is at most Xt + 1, hence the probability to choose such x as a parent is at least $\\frac{1}{en(X_t+1)}$. Therefore, the probability to increase Xt is at least $\\frac{1}{en^2(X_t+1)}$. Hence, if X\u2081 = s, then the expected number of iterations until we get a larger Xt is $en^2(s+1)$. For each s we increase this value at most once, hence the expected runtime until we get a feasible solution is at most\n$\\sum_{s=0}^{n-k-1} en^2(s+1) = \\frac{en^2 \\frac{(n - k)(n - k + 1)}{2}}{2} < \\frac{en^3}{4}$"}, {"title": "5 Runtime Analysis of Diversity Optimization", "content": "In this section we analyze, how much time it takes the GSEMOD to find a population with the optimal diversity after it has already found a population of all feasible solutions. We start with the following theorem for the total imbalance measure.\nTheorem 2. Consider a run of the GSEMOD on LOTZk, which minimizes a diversity measure D(P) = $\\sum_{i=1}^{n} b(i)$ and which starts with population Po that covers all feasible fitness values. Then the expected runtime until the GSEMOD finds a population with the best possible diversity is O(kn\u00b2 ln(n)).\nProof. Let Pt be a population of the GSEMOD in the beginning of iteration t and let $\u03c6_t(i)$ be the difference between the imbalance of position i and its optimal imbalance in Pt, that is, $\u03c6_t(i)$ := b(i) \u2013 bopt(i). Let also \u03a6t := $\\sum_{i=1}^{n} \u03c6_t(i)$, which we call the potential of population in iteration t. Note that the potential decreases strongly monotone with the diversity D(Pt) and hence no population increasing the potential is accepted. When \u03a6t = 0, it implies that all $\u03c6_t(i)$ = 0, and therefore, population Pt has an optimal diversity. Therefore, to estimate the runtime of the GSEMOD, we need to estimate the time until \u03a6t becomes zero.\nNote that for each i the imbalance of position i is defined by the i-th bits of individuals with fitness in M(i), hence the maximum difference of b(i) and bopt(i) is m(i) which by Lemma 2 is at most k\u00b2. Therefore, each $\u03c6_t(i)$ is at most k\u00b2 and thus, \u03a6t is at most nk2.\nBy Lemma 4, the probability to reduce $\u03c6_t (i)$ by two in one iteration is at least $\\frac{m'(i)}{ekn^2}$, where we recall that m' (i) is the number of wrong bits in position i. By Lemma 3 we have $m'(i) > \\frac{\u03c6_t(i)}{2}$, hence the probability to reduce $\u03c6_t(i)$ by two is at least $\\frac{\u03c6_t(i)}{2ekn^2}$. The probability to reduce \u03a6t by two is at least the probability that we reduce at least one $\u03c6_t(i)$ by two. Since the events considered in Lemma 4 are disjoint for different positions, we have\n$Pr[\u03a6_t - \u03a6_{t+1} = 2] > \\sum_{i=1}^{n} \\frac{\u03c6_t(i)}{2ekn^2} = \\frac{\u03a6}{2ekn^2}$\nFor each value \u03a6t we reduce this value at most once, since \u03a6t does not increase. Conditional on \u03a6t = s, the probability to reduce it is at least $\\frac{s}{2ekn^2}$, and the expected time until we reduce \u03a6t is at most $\\frac{2ekn^2}{s}$. Since \u03a6t can only take integer values from [1..nk\u00b2] before we find the optimum, the total expected runtime until we find the optimal population is at most the sum of the runtimes to reduce each of the possible values of \u03a6t, that is,\n$E[T] \\le \\sum_{s=1}^{nk^2} \\frac{2ekn^2}{s} < 2ekn^2(ln(nk^2) + 1)$\n$< 2ekn^2(3ln(n) + 1) = O(kn\u00b2 ln(n)).$\nNote that Theorem 2 gives an upper bound which is asymptotically smaller than the upper bound on the runtime until the GSEMOD finds all feasible solutions, which by Theorem 1 is O(kn\u00b3), hence the expected runtime until the GSEMOD finds a population of all feasible solutions with an optimal diversity starting from a random bit string is also O(kn\u00b3).\nThe second diversity measure which we consider in this paper is the vector of position imbalances sorted in descending order and which is to be minimized lexicographically. For this diversity measure we show the following theorem.\nTheorem 3. Consider a run of the GSEMOD on LOTZk, which starts with population Po, which covers all feasible fitness values, and which minimizes diversity measure D(P) = $(b(\u03c3(i)))_{i=1}^n$, where \u03c3 is a permutation of positions [1..n] in descending order of their imbalances. Then the expected runtime until the GSEMOD finds a population with the best possible diversity is O(k2n\u00b3 log(n)).\nProof. Let Pt be the population of the GSEMOD in the beginning of iteration t and let \u03a6t = $max_{i:b(i)>bopt(i)} b(i)$, that is, the first element of D(Pt) which can be reduced. Note that \u03a6t never increases, since this would result into a lexicographically larger sorted vector of imbalances. Let also \u03a8t be the number of positions with imbalance \u03a6t in"}, {"title": "6 Experiments", "content": "In this section we show the results of our empirical study. We run the GSEMOD on LOTZk on different problem sizes and with different values of k. We used n \u2208 {23, 24, 25, 26, 27} and for each n, except n = 27, we used k\u2208 {2,4, [\u221an], \", n}. For the largest n = 27 we used only k \u2208 {2,4, \u221an}. We used both diversity measures (the total imbalance and the sorted balances vector) and made 128 runs (this number gives us enough confidence in that the mean runtime does not deviate too much from its expectation) of GSEMOD for each parameter setting and each diversity measure. In our experiments we do not initialize random seed, that is, it was initialized with the timestamp at the moment of starting the experiments.\nAll plots in this section show the mean runtimes over 128 runs and they have errorbars which indicate the standard deviation. All of them are normalized by the upper bound from Theorem 1 on the time of the first phase of the optimization, that is, by kn\u00b3.\""}, {"title": "6.1 Sum of imbalances", "content": "The results of the runs when the GSEMOD minimized the sum of total imbalances are shown in the left plot in Figure 3. In this figure we see that all the normalized runtimes (both the runtimes until we obtain a Pareto-optimal population, indicated by the dashed lines, and runtimes until the optimal diversity, indicated by the solid lines) are decreasing, which suggests that the asymptotical upper bound might be even smaller than O(kn\u00b3), but not by a large factor.\nWe observe that the runtime required by the algorithm to get an optimal diversity after computing a Pareto optimal population is small compared to the runtime required to find a Pareto optimal population for the first time. This"}, {"title": "6.2 Sorted Imbalances Vector", "content": "The results of the runs when the GSEMOD minimized the vector of imbalances, sorted in descending order, are shown in the right plot in Figure 3. In this figure we see that all the normalized runtimes are decreasing, which suggests that the asymptotical upper bound might be even smaller than O(kn\u00b3), but not by a large factor. This also indicates that the upper bound on the diversity optimization time given in Theorem 3 is not tight and in practice the runtime required for the diversity optimization is not larger than the runtime needed for finding a Pareto-optimal population. For large values of k the runtime of the diversity optimization is even smaller than it is for the total imbalance."}, {"title": "7 Conclusion", "content": "In this paper, we have shown that optimizing a diversity with EAs in a multi-objective setting might be easy compared to the time needed for the computation of the Pareto front. We showed that a simple tie-breaking rule implemented into the GSEMO can effectively find the best possible diversity of a Pareto-optimal population. This lines up with the result of [24] for the ONEMINMAX problem, even though the main source of diversity imporvements is different in their setting (in [24] and also in [23] the proofs relied on two-bits flips which improve the diversity). Our analysis is also the first one performed on a multi-objective problem with more than two objectives, which demonstrates that evolutionary algorithms can be effective within such a multi-dimensional domain, where the main factor which slows down the optimization is usually a big size of the Pareto front.\nThe results, however, raise a question, which diversity measures are the fastest to optimize. As we see from our results, although the two considered measures share the set of populations which have the optimal diversity, they are optimized with GSEMOD in different ways. In practice the difference might be even larger, since the diversity is also optimized"}]}