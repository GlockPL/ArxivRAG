{"title": "ENHANCING COGNITIVE DIAGNOSIS BY MODELING LEARNER\nCOGNITIVE STRUCTURE STATE", "authors": ["Zhifu Chen", "Hengnian Gu", "Jin Peng Zhou", "Dongdai Zhou"], "abstract": "Cognitive diagnosis represents a fundamental research area within intelligent education, with the\nobjective of measuring the cognitive status of individuals.Theoretically, an individual's cognitive\nstate is essentially equivalent to their cognitive structure state. Cognitive structure state comprises\ntwo key components: knowledge state(KS) and knowledge structure state(KUS). The knowledge\nstate reflects the learner's mastery of individual concepts, a widely studied focus within cognitive\ndiagnosis. In contrast, the knowledge structure state\u2014representing the learner's understanding of the\nrelationships between concepts-remains inadequately modeled. A learner's cognitive structure is\nessential for promoting meaningful learning and shaping academic performance. Although various\nmethods have been proposed, most focus on assessing KS and fail to assess KUS. To bridge this\ngap, we propose an innovative and effective framework\u2014CSCD(Cognitive Structure State-based\nCognitive Diagnosis)\u2014which introduces a novel framework to modeling learners' cognitive struc-\ntures in diagnostic assessments, thereby offering new insights into cognitive structure modeling.\nSpecifically, we employ an edge-feature-based graph attention network to represent the learner's\ncognitive structure state, effectively integrating KS and KUS.Extensive experiments conducted on\nreal datasets demonstrate the superior performance of this framework in terms of diagnostic accuracy\nand interpretability.", "sections": [{"title": "Introduction", "content": "Cognitive diagnosis (CD) is a pivotal and foundational research domain, extensively applied in real-world scenarios\nsuch as gaming[1], medical diagnostics[2], and education, particularly in intelligent education systems[3]. Cognitive\ndiagnosis represents a fundamental research area within intelligent education, with the objective of measuring the\ncognitive status of individuals. Cognitive diagnosis seeks to analyze learners' mastery of knowledge throughout the\nlearning process[4].\nFigure 1-(a) presents an example of cognitive diagnosis: learners generally begin by completing a series of\nexercises (e.g., el to e4) and recording their responses (correct or incorrect). Based on this data, the objective of the\nresearch is to infer the learners' actual knowledge state concerning related concepts. The results of cognitive diagnosis\nnot only provide the foundation for personalized services (such as exercise recommendations and targeted training)[5],\nbut are also extensively utilized in the development and optimization of areas such as course recommendation, learner\nprofiling, and computerized adaptive testing. Through quantitative evaluation, CD models can accurately predict\nlearners' responses to test exercises and present their proficiency with various knowledge state in an intuitive format,\nsuch as radar charts."}, {"title": null, "content": "We now define the knowledge state and the knowledge structure state as follows:\nKnowledge State (KS): The knowledge state (KS) refers to the learner's mastery of individual concepts.\nKnowledge Structure State (KUS): The knowledge structure state (KUS) refers to the learner's understanding of\nthe relationships between concepts, as well as their mastery of these interrelationships."}, {"title": null, "content": "However, a notable issue is evident in Figure 1-(a): Exercise 4 incorporates the knowledge concepts from Exercises\n1, 2, and 3. If a learner answers Exercises 1, 2, and 3 correctly, they should also be able to answer Exercise 4 accurately.\nHowever, the learner exhibits completely contrary behavior when answering Exercise 4. In previous studies, this\nsituation is often attributed merely to the problem's difficulty or other external factors. However, the underlying reason\nfor learner l\u2081's errors in answering exercise 4 lies in his inability to effectively integrate the knowledge concepts k1,\nk2, and k3, resulting in the lack of a cohesive knowledge structure. In other words, while the learner has mastered k1,\nk2, and k3, they have not fully understood the relationships between these concepts, such as predecessor-successor\nrelationships and dependencies. From the perspectives of cognitive psychology and educational psychology, the\ncognitive structure of learner l\u2081 is flawed.\nCognitive structure refers to the network of knowledge in a learner's mind, typically consisting of nodes (knowledge\nconcepts) and edges (the relationships between these concepts). It is not only a central concept in cognitive psychology\nand educational psychology but also a fundamental element in both educational science and cognitive science. In\nFigure 1, the ideal cognitive structure for learner l\u2081 should resemble the one shown in Figure 1-(d). However, the actual\ncognitive structure state of learner l\u2081 during the learning process in this case is shown in Figure 1-(c). Compared to\nFigure 1-(d), the learner l\u2081's cognitive structure is incomplete,which results in the incorrect response to e4.\nSince the mid-20th century, cognitive structure theory has been a cornerstone of educational theory and teaching\npractice. Evaluating learners' cognitive structure state allows for a more precise understanding of their cognitive\nstrengths and weaknesses, thus providing strong support for personalized teaching. Ausubel et al.[6] emphasized that\nthe most important factor influencing learning is the knowledge that learners have already acquired that is, their\ncognitive structure. According to the SOLO taxonomy[7], based on cognitive structure theory, the learning process\nprogresses from simplicity to complexity as learners' knowledge systems expand from isolated knowledge concepts to\ninterconnected concepts, ultimately forming a complete cognitive structure. The SOLO taxonomy is widely applied\nin international learner assessment programs, such as PISA[8]. Therefore, when measuring the cognitive status of\nindividuals, both KS and KUS must be comprehensively assessed."}, {"title": "Related Work", "content": "However, cognitive psychology and educational psychology have yet to provide effective methods to quantitatively\nmeasure the cognitive structure state of individual learners. Although existing cognitive diagnosis methods have\nexplored learners' cognitive states, most focus primarily on KS assessment and fail to adequately assess KUS. Choi et\nal. [9] introduced the concept of cognitive structure and defined it as the learner's knowledge level and the knowledge\nstructure of learning items (e.g., prerequisite relationships), but their assessment still primarily focuses on KS. Gao et al.\n[10] and Su et al. [11] constructed a heterogeneous graph structure that leverages the dependency relationships between\nknowledge concepts to enhance the assessment of learners' KS. Li et al. [12] proposed the HierCDF framework,\nwhich models the impact of hierarchical knowledge structures on cognitive diagnosis. Song et al. [13] focused on\nknowledge concept maps and the dependencies between knowledge concepts, while Jiao et al. [14] revealed the concept\ndependencies within these maps. All these methods utilize the dependency relationships between knowledge concepts\nto assess learners' KS more precisely.\nEssentially, these methods treat the objective and static relationships between knowledge concepts as features for\ndiagnosing learners' progress in acquiring those concepts (or for enhancing their representations). However, their output\nultimately focuses solely on assessing learners' mastery of individual knowledge concepts. While some researchers\nsuggest that learners' mastery of the cognitive structure state, as an implicit feature, can be internalized into their\nmastery of knowledge state, these methods still fail to explicitly diagnose learners' mastery of both knowledge state and\ncognitive structure state. This limitation makes it difficult to provide accurate insights into learners' cognitive strengths\nand weaknesses. As a result, the precise identification of defects in learners' cognitive structures is hindered, making\nit challenging to deliver targeted learning recommendations or interventions. Therefore, we have revisited relevant\ntheories, further explored the importance of revealing learners' cognitive structure state, and explicitly modeled both\nknowledge state and cognitive structure state in cognitive diagnosis.\nBased on this, we propose the CSCD framework, which utilizes an edge-feature-based graph attention network to\ndynamically model and update both the knowledge state and the knowledge structure state. This approach effectively\ncaptures learners' cognitive structure state and applies it to diagnose their performance in answering questions. To the\nbest of our knowledge, this is the first framework to systematically explore learners' cognitive structure state in the field\nof cognitive diagnosis. Extensive experiments on real-world datasets demonstrate that the framework offers significant\nadvantages in terms of diagnostic accuracy and interpretability."}, {"title": "Cognitive diagnosis", "content": "Traditional cognitive diagnosis. A significant body of literature has been devoted to cognitive diagnosis,\nincluding deterministic input, noise, and gate models (DINA)[15], item response theory (IRT)[16], multidimensional\nIRT (MIRT)[17], and matrix factorization (MF)[18]. Despite demonstrating some effectiveness, these approaches rely\non manually defined interaction functions, which combine features of learners and exercises through multiplicative\nterms, such as logical functions[16] or inner products[18]. However, this may be insufficient to capture the complex\nrelationships between learners and exercises[19].\nNeural Cognitive Diagnosis. In recent years, most neural cognitive diagnosis models employ neural networks\nto extract latent features of learners and exercise characteristics from data[20], or to automatically learn higher-order\nnonlinear functions[21]. These models aim to capture various diagnostic features, such as contextual software features\n(e.g., family, school) modeled by ECD[22] and emotional states (e.g., boredom, confusion) modeled by ACD[23]. Other\nmodels focus on assessing and optimizing cognitive diagnosis tasks, such as ICD[24] based on incremental learning,\nSCD[25] addressing the long-tail problem, ReliCD[26] alleviating data sparsity and noise, DCD[27] addressing the\nlimitations of a labeled q-matrix, and UCD[23] for uncertainty assessment.\nCognitive structure in cognitive diagnosis. Numerous studies have introduced education-prior-based relational\ngraphs, including Knowledge Concept (KC) graphs and item-concept association graphs, to improve the representation\nof learners and items. Gao et al. [10] and Su et al.[11] modeled heterogeneous graph structures for learning item\nknowledge, thoroughly exploring higher-order interactions between nodes and the dependency relationships between\nknowledge concepts in concept maps, thereby improving the representation of learners' cognitive states and item\ncharacteristics. Li et al. [12] proposed the HierCDF framework to model the influence of hierarchical knowledge\nstructures on cognitive diagnosis. Song et al.[13] focused on the effective integration of knowledge concept maps,\nconcept dependencies, and item features. Jiao et al.[14] revealed the relationships between knowledge concepts and\nitems, as well as the concept dependencies within the knowledge concept map, thereby improving the representation\nof items and learner characteristics.Essentially, these methods treat the objective and static relationships between\nknowledge concepts as features for diagnosing learners' progress in acquiring those concepts (or for enhancing their\nrepresentations). However, their output ultimately focuses solely on assessing learners' mastery of individual knowledge"}, {"title": "Graph Neural Networks", "content": "Deep learning, as a mainstream method in the field of artificial intelligence, has made significant progress across\nvarious application areas due to its powerful feature learning capabilities. Common neural network models, such\nas Convolutional Neural Networks (CNN) [28], Recurrent Neural Networks (RNN)[29], and Generative Adversarial\nNetworks (GAN)[30], have achieved great success in processing Euclidean data such as images, text, and speech.\nHowever, many real-world problems, such as social networks and knowledge graphs, involve complex graph-structured\ndata that cannot be simply represented by traditional Euclidean space models. Graph Neural Networks (GNN) have\nemerged as an effective deep learning framework for processing graph-structured data.\nGraph Convolutional Networks (GCN) are an important branch of GNNs. GCN extends the convolution operation\nfrom traditional regular data to irregular graph data. Unlike traditional GCN models, which treat all nodes equally,\nthe introduction of attention mechanisms into GNNs, forming Graph Attention Networks (GAT), allows for assigning\ndifferent attention weights to neighboring nodes of a target node, thereby highlighting the contributions of more\nsignificant neighbors. Velickovic et al.[31] were the first to introduce attention mechanisms into GNNs, proposing the\nGAT model, which learns the weights of different neighboring nodes through a neural network. During information\naggregation, it focuses only on the nodes that have a significant impact on the target node while ignoring those with\na smaller effect. This method dynamically adjusts the importance of neighboring nodes, significantly enhancing the\nmodel's performance. The basic structure of GAT incorporates an attention layer, which learns weights during the\naggregation of neighboring nodes to update the target node representation. However, in many practical applications, the\nedges in a graph often contain rich information, yet most existing models still fail to fully leverage this edge information,\nlimiting the comprehensive representation and analysis of graph-structured data.\nTo address this, Wang et al.[32] proposed the Edge-Featured Graph Attention Network (EGAT), based on\nGAT, which efficiently learns both node and edge features, generating more comprehensive and accurate feature\nrepresentations. This collaborative optimization mechanism not only effectively integrates the feature information of\nnodes and edges in the graph but also significantly improves the model's ability to handle complex graph data. Through\nthe design of multilayer attention mechanisms, EGAT is capable of capturing multiscale feature information, providing\nstrong support for graph data representation learning and downstream tasks."}, {"title": "Cognitive Structure-based Cognitive Diagnosis", "content": null}, {"title": "Task Overview", "content": "Let S = {$s_1$, $s_2$, ..., $s_N$ } represent the set of N learners, E = {$e_1$, $e_2$, ..., $e_m$ } represent the set of M exercises,\nand C = {$c_1$, $c_2$, ..., $c_K$ } represent the set of K knowledge concepts. $R_{non-c}$ = {$r_{ci\u2194c_j}$ | $c_i \u2208 C, c_j \u2208 C, i \u2260 j$}\ndenotes the set of dependency correlations between concepts ci and cj, and Rc = {$r_{ci\u2192c_j}$ | $c_i \u2208 C, c_j \u2208 C, i \u2260 j$}\nrepresents the set of predecessor-successor correlations between concepts ci and cj. Each learner is assumed to\nindependently select certain exercises for practice. We record the response records of a particular learner as a set\nof triplets (s, e, $r_{se}$), where s \u2208 S, e \u2208 E, and $r_{se}$ represents the score obtained by learner s on exercise e. The\nrelationship between test items and knowledge concepts is represented by the Q-matrix, Q = ($q_{ij}$)$_{M\u00d7K}$. Specifically,\n$q_{ij}$ = 1 indicates that test item i contains the j-th knowledge concepts, and $q_{ij}$ = 0 indicates that test item i does not\ncontain the j-th knowledge concepts, where i \u2208 {1, 2, ..., M} and j \u2208 {1, 2, . . ., K}. Let L denote the set of response\nrecords. Then, we provide a clear formulation of the cognitive diagnosis:\nGiven: learners' response records L, exercises, dependency correlations $R_{non-c}$, and predecessor-successor\ncorrelations Rc.\nGoal: To diagnose learners' cognitive structure state(i.e. knowledge state(KS) and knowledge structure state(KUS))\nby modeling their performance prediction process."}, {"title": "CSCD Framework", "content": null}, {"title": "Embedding Module", "content": "This paper employs one-hot encoding and embedding techniques to map knowledge concepts, predecessor-\nsuccessor relationships among knowledge concepts, learners, and test items into a unified low-dimensional vector\nspace, with final representations generated through the sigmoid function. The set of knowledge concepts is denoted as\nC = {$C_1, C_2,\uff65\uff65\uff65, C_K$}, where K denotes the total number of knowledge concepts. First, each knowledge concepts $c_i$ is\nencoded using one-hot encoding, as follows:\n$c_k$ = [0,0,...,1,...,0]\u2208$R^K$ (1)\nwhere the i-th position is 1, and the rest are 0. Subsequently, ck is embedded into a dense vector space to derive\nthe embedding representation of knowledge concepts i:\n$h_k$ = sigmoid ($W_k\u00b7c_k+b_k$), $h_k$ \u2208 $R^d$ (2)\nwhere $W_k$ \u2208 $R^{d\u00d7K}$ is the weight matrix for the knowledge concepts embedding, $b_k$ \u2208 $R^d$ is the bias vector, and\nd is the dimension of the embedding vector.Similarly, the embedding representations for predecessor-successor and\ndependency relationships are as follows:\n$h_{cicj}$ = sigmoid ($W_r.r_{cicj}+b_r$), $h_{ci\u2194cj}$ \u2208 $R^d$ (3)\n$h_{cjci}$ = sigmoid ($W_r.r_{cjci} + b_r$),$h_{cj\u2192ci}$ \u2208 $R^d$ (4)\nThe set of learners is denoted as S = {$s_1, s_2, ,s_N$}, where N represents the total number of learners. The\none-hot encoding of the learners is expressed as:\n$s_n$ = [0,0,\u2026\u2026,1,\u2026,0] \u2208$R^N$ (5)"}, {"title": null, "content": "representation:\nThe one-hot encoding of the learners is mapped into a low-dimensional dense space, yielding the learner embedding\n$h_n$ = sigmoid ($W_s.s_n + b_s$), $h_n$ \u2208 $R^{d_s}$ (6)\nwhere $W_s$ \u2208 $R^{d_s\u00d7N}$ is the weight matrix for the learner embedding, $b_s$ \u2208 $R^{d_s}$ is the bias vector, and $d_s$ is the\ndimension of the embedding vector.\nBased on the embedding representations of learners, knowledge concepts, and their relationships, the personalized\nembedding representation of each knowledge concepts for learner n is formulated as follows: For learner n, the\npersonalized embedding representation of each knowledge concepts is expressed as:\n$h_{n,k}$ = sigmoid ($W_{s,k}\u00b7 [h_n\u2295h_k] + b_{s,k}$) (7)\nFor learner n, the relational embedding representation between knowledge concepts i and j is:\n$h_{n,c_i\u2194c_j}$ = sigmoid ($W_{s,r}\u00b7 [h_n \u2295 h_{c_i\u2194c_j}]+b_{s,r}$) (8)\n$h_{n,c_j\u2192c_i}$ = sigmoid ($W_{s,r} \u00b7 [h_n \u2295 h_{c_j\u2192c_i}]+b_{s,r}$) (9)\nThe set of test items is denoted as E = {$e_1$, $e_2$, \u2026\u2026\u2026, $e_M$}, where M represents the total number of test items. The\none-hot encoding of the test items is expressed as:\n$e_m$ = [0,0,\u2026\u2026,1,\u2026\u2026,0] \u2208 $R^M$ (10)\nBased on the one-hot encoding of the test items, the difficulty embedding representation $h^{diff}$ and discrimination\nembedding representation $h^{dics}$ corresponding to each test item are derived using the embedding technique:\n$h^{diff}$ = sigmoid ($W_e \u2022 e_m + b_e$) \u2208 $R^{1\u00d7K}$ (11)\n$h^{dics}$ = sigmoid ($W_e \u2022 e_m + b_e$) \u2208 $R^{1}$ (12)\nFor each exercise, the corresponding exercise factor is represented as $Q_e$, derived directly from the pregiven\nQ-matrix:\n$Q_e = x^T x Q$ (13)"}, {"title": "Cognitive Structure State Representation Module", "content": "In this section, we introduce the cognitive structure representation module, which consists of three components:\nDRC, URC, and the Fusion component. Both DRC and URC are implemented using EGAT, as EGAT can simultaneously\nlearn the representations of knowledge state(KS) and knowledge structure state(KUS). Specifically, DRC learns the\nrepresentations of knowledge state(KS) and predecessor-successor relationships of knowledge structure state(KUS),\nwhile URC learns the representations of knowledge state(KS) and dependency relationships of knowledge structure\nstate(KUS).\nEGAT.We introduce the structure of EGAT, as shown in the figure 3. Each EGAT layer consists of a Node\nAttention Block and an Edge Attention Block. To illustrate, we will use predecessor-successor relationships as an\nexample.The function representation of EGAT can be written as F(.)."}, {"title": null, "content": "In the Node Attention Block, the attention factor $a_{j\u2192i}$ between node i and node j is computed as follows:\n$a_{j\u2192i}$= $\\frac{exp (Leaky Re LU (\\vec{a}^T[\\vec{h_i} \u2295 \\vec{h_j} \u2295\\vec{h}_{j-i}]))}{\\sum\\limits_{k\u2208N_i}exp (Leaky ReLU (\\vec{a}^T[\\vec{h_i} \u2295 \\vec{h_k} \u2295\\vec{h}_{k-i}]))}$ (14)\nwhere $\\vec{a}^T$ is the weight vector parameter, $\\vec{h}_{j-i}$ represents the edge feature vector between node i and node j,\ndenotes the vector concatenation operation, and LeakyReLU is a non-linear activation function. Based on the attention\nfactor, the update rule for node features is:\n$\\vec{h\u2019_i} = \u03b4 ( \\sum\\limits_{j\u2208N_i} a_{ji} \\vec{h_j} )$ (15)\nIn the Edge Attention Block, the attention factor $\u03b2_{q\u2192p}$ between edge p and its neighboring edge q is computed as:\n$B_{qp}$=$\\frac{exp (Leaky ReLU ([h_p\u2295h_q]))}{\\sum\\limits_{k\u2208N_p}exp (Leaky ReLU ([h_k\u2295h_q]))}$ (16)\nwhere $T$ is the weight vector parameter, $h_{q\u2192p}$ represents the node feature vector between edge p and its\nneighboring edge q, denotes the vector concatenation operation, and LeakyReLU is a non-linear activation function.\nBased on the attention factor, the update rule for edge features is:\n$e\u2019_p = \u03b4 ( \\sum\\limits_{q\u2208N_p} B_{qp}h_q)$ (17)\nThe EGAT framework efficiently learns node and edge features through the parallel updates of the Node Attention\nBlock and Edge Attention Block, yielding more comprehensive and precise feature representations. This collaborative\noptimization mechanism not only effectively integrates the feature information of nodes and edges in the graph but also\nsubstantially enhances the model's ability to handle complex graph data.\nSpecializations for DRC and URC. The knowledge state(KS) learned by learner n and the dependency relation-\nships of knowledge structure state(KUS) i are updated as:\n$h'_{n,c_{icj}} = F(h_n, h_{n,c_{icj}})$ (18)\nThe knowledge state(KS) learned by learner n and the predecessor-successor relationships of knowledge structure\nstate(KUS)i are updated as:\n$h'_{n,c_jci}= F (h_n, h_{n,c_jci})$ (19)\nFusion. This paper introduces a fusion operation that integrates the features of knowledge state(KS) and knowledge\nstructure state(KUS), thereby generating the cognitive structure representation $h^s$ for learner n learning knowledge\nconcepts i. The specific fusion operation is mathematically defined as follows,taking the predecessor-successor\nrelationship of knowledge structure state(KUS) as an example:\n$\\vec{h^*_i} = sigmoid (W[h_{n,i} \\vec{h_{n,ip}}] + b)$ \n$h_{n,ip}$ = $\\sum\\limits_{p\u2208N(v_i)}W_{n,c_pc_i}$ (20)\n$W_{n,c_pc_i}$ = MLP ($h\u2019_{n,c_pc_i}$)"}, {"title": null, "content": "Here, $h_{n,ip}$ represents the fusion of all relationship feature vectors associated with knowledge concepts i. In the\nfusion process, each relationship feature vector $h'_{n,cp\u2192ci}$ associated with knowledge concepts i is first passed through\na Multi-Layer Perceptron (MLP) to obtain the corresponding weight $W_{n,cp\u2192c\u2081}$ . Subsequently, the weight $W_{n,cp\u2192c\u2081}$ is\nmultiplied element-wise with the relationship feature vector $h'_{n,cp\u2192c\u2081}$ and summed to produce the fused representation\n$h_{ni}$. Finally, the feature vector $h_{n,k}$ of knowledge concepts i is concatenated with the fused representation $h_{n,\u012bp}$, and\nafter passing through the sigmoid activation function, the predecessor-successor cognitive structure representation $h^s$ for\nknowledge concepts i learned by learner n is generated.Based on this, the dependency cognitive structure representation\nof knowledge concepts i learned by learner n is defined as: \u0989.\nThe final fused cognitive structure representation of the learner is defined as:\n$h^*$ = sigmoid (W [W + \u00b3] + b)\n=MLP\n=\\MLP (21)\nwhere hand are learned via functions that generate weights 3 and W. The weights are then multiplied by\nthe corresponding vectors, and the resulting values are concatenated. Finally, the cognitive structure representation hs\nis derived via a sigmoid function."}, {"title": "Prediction Module", "content": "The output layer incorporates a classifier to predict learners' responses. The classifier maps input feature vectors\nto distinct categories, identifying patterns and rules from the training data to infer learners' response outcomes. The use\nof a classifier offers notable advantages: it leverages supervised learning techniques for efficient model training and\neffectively handles large-scale, high-dimensional feature spaces, thereby enhancing prediction accuracy.\nIn this study, a Multi-Layer Perceptron (MLP) is employed as the classifier for predicting learners' responses.\nThe prediction task is formulated as a binary classification problem, where the response likelihood is mapped to a real\nnumber within the interval [0, 1]. If the predicted value is greater than or equal to 0.5, the learner is considered to have\nanswered correctly; otherwise, the learner is considered to have answered incorrectly. This approach simplifies the\nproblem representation while effectively utilizing feature space information to improve classification performance.\nThe designed MLP in this study features a three-layer hidden structure, with a sigmoid activation function applied\nat the end of each hidden layer. This design enables nonlinear feature mapping and facilitates information transfer\nbetween layers.\nThe first layer of the interaction layers is inspired by MIRT models. We formulate it as:\n$x = Q_e 0 (h^* \u2212 h^{diff}) \u00d7 h^{disc}$ (22)\nwhere is element-wise product. The following are two fully connected layers and an output layer:\n$x_1 = \u03c6(W_1 \u00d7 x^T + b_1)$ \n$x_2 = \u03c6(W_2 \u00d7 x_1+b_2)$ (23)\n$\u0177 = \u03c6(W_3 \u00d7 x_2 + b_3)$\nwhere \u03c6 is the activation function. Here we use Sigmoid.\nIn the model training phase, the parameters of the model are learned by minimizing the standard cross-entropy\nloss between the predicted probability of question correctness and the true label. Here, y represents the true answer\noutcome, with a value of 0 indicating an incorrect answer and a value of 1 indicating a correct answer.\nl = - $\\sum\\limits_i$ ylog(\u0177) + (1 \u2212 y)log(1 \u2212 \u0177) (24)\nThis loss function quantifies the difference between the predicted and actual outcomes, guiding the model in\nadjusting its parameters to improve prediction accuracy."}, {"title": "Experiments", "content": "In this section, we evaluate our CSCD framework on four popular and challenging real-world education datasets,\ncomparing it to the baselines. We also analyze the impact of interpretability."}, {"title": "Dataset Description", "content": "The dataset utilized in this study comprises three real-world datasets: ASSISTments2017, Junyi, and NIPS34.\nThe ASSISTments2017 dataset is a widely recognized public dataset in the field of online education, originating\nfrom the ASSISTments online learning platform. It primarily captures detailed behavioral data of learners during\ntheir response process. This dataset contains learners' response records, response times, knowledge concepts labels,\nand answer outcomes (correct or incorrect), with the goal of supporting personalized learning research and advancing\ncognitive diagnosis models.\nThe Junyi dataset is derived from an online learning platform targeting primary and secondary school learners, with\nan emphasis on tracking and analyzing learner learning behaviors and knowledge mastery. This dataset records various\ndata related to learner practice, including knowledge concepts labels, response records (correct/incorrect), question\ntypes, and practice durations.\nThe NIPS34 dataset originates from Tasks 3 and 4 of the NeurIPS 2020 Education Challenge and includes learners'\nresponse records to multiple-choice diagnostic mathematics questions. The data were collected by the Eedi platform[33].\nFor each question, the dataset identifies the leaf nodes from the subject tree as its corresponding knowledge components.\nDetailed information regarding the datasets is provided in Table 1."}, {"title": "Experimental Settings", "content": null}, {"title": "Baselines and Evaluation Metrics.", "content": "To evaluate the effectiveness of our proposed RCD model, we compare it against several baseline methods. The\ndetails are presented as follows:\n\u2022 IRT[34], being one of the most widely used CD methods, models the unidimensional features of learners and\nexercises using a linear function.\n\u2022 NCD[21] is a recent deep learning-based CD model that models high-order, complex learner-exercise interac-\ntion functions using neural networks.\n\u2022 RCD[10] unifies the capture of inner structures and inter-layer interactions through a multi-layer relational\ngraph, subsequently employing a multi-level attention network to integrate node-level relational aggregation\nwithin each local graph, while balancing graph-level relational aggregation across multiple graphs.\n\u2022 HierCD[12] addresses the limitations of traditional attribute hierarchy models.\n\u2022 SCD[25] incorporates symbolic trees to explicitly represent complex learner-exercise interaction functions,\nusing gradient-based optimization methods to effectively learn both learner and exercise parameters.\nTo evaluate the performance of our framework, we utilize various metrics from both regression and classification\nperspectives. From the regression perspective, we use Root Mean Square Error (RMSE) to quantify the difference\nbetween predicted scores (i.e., continuous values ranging from 0 to 1) and actual values. From the classification\nperspective, we represent incorrect and correct learner answers as 0 and 1, respectively. Therefore, we use Prediction\nAccuracy (ACC) and Area Under the ROC Curve (AUC) to evaluate the framework."}, {"title": "Parameter Settings.", "content": "In our experiments, all learners are randomly divided into training, validation, and test sets in a ratio of 7:1:2. The\nbatch size, dropout rate, and learning rate (with decay) are optimized over the ranges {8, 16, 32, 64}, (0, 0.5), and (1e-5,\n2e-2), respectively. For fairness, the hyperparameters of the baseline models align with those reported in their respective\npapers and have been further fine-tuned to achieve optimal results. To configure the training process, we initialize the\nparameters using Xavier initialization and utilize flexible methods such as random search, grid search, and Bayesian\nsearch and selection strategies. If the AUC does not improve over the course of 10 epochs or if the maximum number of\nepochs (100) is reached, we implement an early stopping strategy. All experiments are conducted using PyTorch and\nexecuted on Linux servers equipped with RTX 4090 (24 GB)."}, {"title": "Overall Performance", "content": "The experimental results, presented in the table 2, demonstrate that CSCD outperforms all baseline models (e.g.,\nIRT, NCD, RCD, HierCD, and SCD) across all three datasets (ASSISTments2017, Junyi, and NIPS34). Specifically,\non the ASSISTments2017 dataset, CSCD achieves an AUC of 0.8010, an ACC of 0.7302, and an RMSE of 0.4248,\nsurpassing all other models, particularly excelling in the AUC and ACC metrics. On the Junyi dataset, CSCD achieves\nan AUC of 0.8230, an ACC of 0.7667, and an RMSE of 0.3993, continuing to outperform other models, with notable\nadvantages in RMSE, indicating superior predictive accuracy. On the NIPS34 dataset, CSCD achieves an AUC of\n0.7889, an ACC of 0.7217, and an RMSE of 0.4257, maintaining strong performance, particularly in AUC and ACC,\ndemonstrating its ability to effectively distinguish learner abilities and predict question correctness. Overall, CSCD\nconsistently outperforms the baseline models across AUC, ACC, and RMSE metrics on all three datasets, highlighting\nits superior effectiveness, precision, and robustness in cognitive diagnosis tasks."}, {"title": "Ablation Study", "content": "Ablation studies are commonly used control techniques in machine learning to validate the effectiveness of various\ncomponents within a model. By progressively removing or disabling specific parts of the model and observing the\nresulting changes in performance", "datasets": "ASSISTments2017, Junyi, and NIPS34. The experimental design in-\ncludes different configurations of the cognitive structure representation layer, such as representations of only knowledge\nconcepts, representations of only the relationships between knowledge concepts, and a comprehensive representation\nof the entire cognitive structure. These experiments aim to explore the influence of the overall cognitive structure\nrepresentation on model performance. The experimental design is outlined in Table 3.\nIn this context, \"CSCD w/s,g K\" indicates that the framework utilizes only the knowledge state within the cognitive\nstructure state representation layer; \"CSCD w/s,g R\" signifies that the framework employs only the knowledge structure\nstate within the same layer; and \"CSCD w/s,g K+R\" denotes that the framework integrates both knowledge state and\nthe structure state within the cognitive structure representation layer"}]}