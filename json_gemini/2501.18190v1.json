{"title": "Economic Rationality under Specialization: Evidence of Decision Bias in AI Agents", "authors": ["ShuiDe Wen", "Juan Feng"], "abstract": "In the study by Chen et al. (2023) [01], the large language model GPT demonstrated economic rationality comparable to or exceeding the average human level in tasks such as budget allocation and risk preference. Building on this finding, this paper further incorporates specialized agents, such as biotechnology experts and economists, for a horizontal comparison to explore whether specialization can enhance or maintain economic rationality equivalent to that of GPT in similar decision-making scenarios. The results indicate that when agents invest more effort in specialized fields, their decision-making behavior is more prone to 'rationality shift,' specifically manifested as increased violations of GARP (Generalized Axiom of Revealed Preference), decreased CCEI (Critical Cost Efficiency Index), and more significant decision deviations under high-risk conditions. In contrast, GPT and more generalized basic agents maintain a more stable and consistent level of rationality across multiple tasks. This study reveals the inherent conflict between specialization and economic rationality, providing new insights for constructing AI decision-making systems that balance specialization and generalization across various scenarios.", "sections": [{"title": "1. Introduction", "content": "1.1 Background and Research Motivation\nWith the rapid development of artificial intelligence technology, the potential demonstrated by large language models in various complex tasks has garnered significant attention. The research conducted by Chen et al. (2023) [01] validates this through a series of economic decision-making experiments: when faced with economic tasks such as budget allocation and risk preference, GPT can exhibit a level of economic rationality comparable to or even exceeding that of average participants. This finding has sparked widespread discussion in academia and has also attracted considerable attention in the industry, as it suggests that large language models may not only excel in natural language communication but can also make decisions approximating human rationality in classical economic scenarios such as utility maximization (Kosinski, 2023 [09]; Rahwan et al., 2019 [13]).\nIt is important to note that GPT-a large language model\u2014is not the only AI solution for addressing complex decision-making. In fact, many expert systems based on large models also play critical roles in economic decision-making scenarios such as financial market forecasting, medical resource allocation, and industrial production planning (Lin et al., 2020 [10]). These systems are typically trained in depth for specific industries or disciplines; for instance, biotechnology expert agents focus on experimental safety, ethical compliance, and research prioritization, while economist agents often employ game theory or cost-benefit analysis to guide their decisions (Obermeyer et al., 2019 [12]; Chen et al., 2006 [05]). Intuitively, these specialized models seem more likely to outperform general models in terms of economic rationality and decision effectiveness. However, this paper tests within the experimental framework established by Chen et al. (2023) [01] whether the economic rationality of agents significantly enhanced in specialization can indeed exceed the high standards set by GPT when faced with the same or similar economic tasks.\n1.2 Research Question: From Economic Rationality of GPT to the 'Rationality Shift' of Specialized Agents\nThe work of Chen et al. (2023) [01] provides a crucial theoretical and empirical"}, {"title": "2. Theoretical Background", "content": "2.1 The Economic Rationality of GPT: Findings of Chen et al. (2023) [01]\nThrough a series of multi-round experiments on economic scenarios such as budget allocation and risk preference, Chen et al. (2023) [01] found that GPT, despite lacking genuine human emotions and subjective needs, can still manifest a high level of rationality in metrics such as the violation rate of GARP (Generalized Axiom of Revealed Preference), CCEI (Critical Cost Efficiency Index), and decision consistency. This extraordinary decision-making capability indicates that GPT is not merely a language generator; it is capable of abstract reasoning in complex contexts and approximately adheres to the rationality assumptions of traditional economics (Vaswani et al., 2017 [16]; Webb et al., 2022 [17]). Specifically, the model often quickly 'learns' or simulates consumption choices that align with utility maximization when faced with different price combinations and budget constraints, showing a clear preference for high-value or high-expected-utility options. These experimental results suggest that GPT possesses a certain degree of 'general reasoning' potential, which may enable it to exhibit stable decision quality in a wider array of socio-economic contexts.\n2.2 Specialized Agents and Economist Agents\nUnlike the 'general' model pursued by GPT, specialized agents are typically trained in a single or limited domain. For instance, biotechnology expert agents often prioritize experimental safety, ethical compliance, and research and development priorities as their core objectives, utilizing industry-specific knowledge bases and rules to evaluate decision outcomes. In contrast, economist agents rely on rigorous economic models such as game theory and cost-benefit analysis to reason and gain advantages in tasks involving specific game structures or market pricing (Rahwan et al., 2019 [13]). Theoretically, these 'specialized agents' possess more focused domain knowledge, which may lead to more nuanced decision-making processes when addressing typical problems within that domain. However, when task scenarios involve multiple uncertainties or cross-domain influences, excessive reliance on specialized assumptions and industry norms may cause them to overlook broader environmental variables, resulting in deviations in overall economic rationality (Biancotti & Camassa, 2023 [03]). This indicates that 'specialization' does not necessarily lead to a more comprehensive"}, {"title": "2.3 Rationality Shift and Over-Specialization", "content": "Rationality shift refers to the phenomenon where an agent, in pursuit of the 'optimal' within a specific domain, diverges from the principles of synergistic utility or global optimality emphasized in economics (Cappelen et al., 2023 [04]; Chen et al., 2006 [05]). In other words, when an agent allocates excessive resources at a specialized level, its focus often becomes centered on meeting internal priorities or regulatory requirements, neglecting core economic elements such as risk assessment and resource allocation efficiency. At this point, while the agent may achieve optimal performance in a single metric or specific context, it frequently violates broader decision-making standards and exhibits characteristics that conflict with traditional rational models, such as low CCEI values.\nIf the experimental data ultimately validates this inference, it would imply that GPT's relatively 'versatile' general reasoning model can achieve a higher level of consistency in cross-domain and multi-constraint situations, thereby avoiding the decision-making risks associated with over-specialization. Consequently, the emergence of 'rationality shift' not only poses challenges for the design of specialized agents but also provides a new research perspective for understanding the strengths and weaknesses of GPT in complex economic tasks."}, {"title": "2.4 Modeling the Mechanism of Rationality Shift", "content": "2.4.1 Multi-Objective Optimization Framework for Specialization Conflicts\nTo formalize the mechanism of \"specialization investment \u2192 local optimum \u2192 global deviation,\" this study constructs a multi-objective decision-making model that integrates economic rationality assumptions and domain-specific constraints. The core variables are defined as follows:\nSpecialization Level $S \\in [0,1]$: The depth of an agent's expertise in a specific domain (S=0 for general-purpose agents, S=1 for highly specialized agents).\nLocal Objective Function L(S,x): The utility function within the specialized domain (e.g., biosafety score, experimental efficiency).\nGlobal Objective Function G(x): Cross-domain economic rationality metrics (e.g.,"}, {"title": "2.4.2 Causal Chain Framework of Rationality Shift", "content": "Figure 1 illustrates the causal chain through which specialization induces rationality shift:"}, {"title": "2.4.3 Application Example of the Mathematical Model", "content": "Consider a biotechnology expert agent whose local objective is to maximize experimental safety (L=Safety Score) and whose global objective is to minimize GARP"}, {"title": "3. Experimental Design and Methods", "content": "3.1 OpenAI Assistants API and TsingAI Agentic Workflow Framework\nTo implement the experimental design of multiple types of agents in this study, we utilized OpenAI's Assistants API and developed a proprietary TsingAI agentic workflow framework to drive various agents for experimentation and data collection. In terms of model selection, this experiment employed ChatGPT (01-mini) as the core large language model (LLM) and injected the specialized attributes and decision-making styles of each agent through the 'system introduction.' Specifically, we first created multiple AI Assistants based on different professional scenarios (such as basic, biotechnology expert, and economist) and defined their roles and constraints in the 'system introduction.' Subsequently, through a parallelized workflow mechanism, we synchronized the same experimental instructions and prompt information to each Assistant, while recording the dialogues and decision-making content in 'Message' and 'Run Step' in real time."}, {"title": "3.2 Inheritance and Extension of Research Design", "content": "To implement the experimental design of multiple types of agents in this study, we utilized OpenAI's Assistants API and developed a proprietary TsingAI agentic workflow framework to drive various agents for experimentation and data collection. In terms of model selection, this experiment employed ChatGPT (01-mini) as the core large language model (LLM) and injected the specialized attributes and decision-"}, {"title": "3.3 Experimental Tasks and Risk Preference Scenarios", "content": "To identify the potential influence of specialization on decision-making rationality, this study primarily introduces the following two types of task scenarios:\n\u2022 Budget Allocation: Consistent with the work of Chen et al. (2023) [01], each round presents the agents with two optional products (A and B) along with their prices (pA, pB), and a fixed budget of 100 points has been set. The agents must decide on the quantity to purchase or the allocation ratio within the given budget. This task tests the agents' decision-making tendencies regarding products with different value-for-money under budget constraints, thereby assessing whether their choices align with the rational principles of traditional economics.\n\u2022 Risk Preference: We set up low-risk scenarios (where pA and pB vary slightly) and high-risk scenarios (where pA and pB vary significantly) to reflect the impact of different risk conditions on agent decision-making. In low-risk scenarios, agents tend to find it easier to balance returns and costs; conversely, in high-risk scenarios, the more pronounced fluctuations in potential gains and losses provide a clearer indication of the agents' rationality and strategic stability in complex environments."}, {"title": "3.4 Data Sources and participants To ensure the robustness of the comparisons and analyses, the subject combinations in this study are as follows", "content": "\u2022 Human Subjects and GPT: This study utilizes the original experimental data from Chen et al. (2023) [01], which includes human subjects from diverse age groups and educational backgrounds, as well as the GPT model making decisions under the same task conditions.\n\u2022 Basic Agents: These models utilize only simple decision rules or heuristic"}, {"title": "3.5 Evaluation Metrics", "content": "To assess the performance of different agents in terms of economic rationality, this study selects the following three key indicators for multi-dimensional evaluation:\n\u2022 GARP Violations: According to the standards set by Varian (1982) [15], rational consistency is measured by detecting the frequency of contradictions in decision-making across different rounds. If a model frequently exhibits contradictions in cross-round decision-making, it indicates difficulty in maintaining the rationality framework.\n\u2022 CCEI: Utilizing the Critical Cost Efficiency Index (CCEI) introduced by Choi et al. (2014) [06], this metric assesses whether agents can maximize returns under given budget constraints. A higher CCEI value indicates that the model's decisions are closer to complete rationality.\n\u2022 Spearman Correlation: Based on the recommendations of Biancotti & Camassa (2023) [03], the Spearman correlation coefficient is used to measure the level of rank consistency between the decisions made by agents and those made by human subjects. A higher correlation coefficient indicates a stronger correspondence between the agents and humans in terms of economic rationality or preference choices.\nThe comprehensive analysis of the three aforementioned indicators aids in further understanding the differences in decision-making patterns among different types of agents under budget constraints and different risk conditions. It also explores how specialization and generality manifest markedly different levels of rationality or"}, {"title": "4. Experimental Results and Analysis", "content": "4.1 Data Compilation and Comparison\nTo compare the rational performance of different subjects under the same economic tasks, Table 1 summarizes the research data from Chen et al. (2023) [01] on human samples and GPT, along with the experimental results of the newly introduced basic agents, biotechnology experts (Biotech), and economist agents. The table lists the number of GARP violations, average CCEI values, and Spearman correlation coefficients with human subject decisions for each agent, allowing for a clear visualization of the differences in rationality indicators among the various types of agents."}, {"title": "4.2 Discussion of Results: The Phenomenon of Rationality Shift", "content": "By comparing the data in Table 1, we can analyze the economic decision-making characteristics of each agent in more detail and evaluate their alignment with traditional rationality theory:\n\u2022 GPT:\nThe data and conclusions are derived from Chen et al. (2023) [01], which show that GPT demonstrated a high level of economic rationality in the original study. Its GARP violation count was only 3, significantly lower than the average for humans and most other specialized agents, while its CCEI value (0.873) remained relatively high. This suggests that GPT's 'general' reasoning model and its comprehensive processing of contextual information allow it to maintain consistency in utility maximization or consistent preferences across diverse situations.\n\u2022 Basic Agent:\nThis agent utilizes only simple algorithms for allocation and selection, without undergoing any in-depth training in specialized knowledge. In low-risk or clearly profitable scenarios, the Basic agent can maintain a certain level of rationality; however, in high-risk situations or those requiring multidimensional trade-offs, it is prone to significant fluctuations. The agent has a GARP violation count as high as 99 and a low Spearman correlation coefficient of -0.459, indicating that the basic algorithm tends to become unbalanced when facing complex decisions, only managing to perform adequately in certain scenarios.\n\u2022 Specialized Agents (Biotech and Economist):\nThe Biotechnology Expert Agent (Biotech) is theoretically expected to excel in scenarios involving factors such as safety and research priorities. However, with an overall CCEI value of only 0.127, Biotech's performance in resource utilization and utility maximization falls significantly short of the standards of economic rationality. Additionally, its GARP violation count is quite substantial (88 violations), indicating that this agent often neglects general economic principles in favor of emphasizing specialized rules in cross-domain, high-risk decision-making.\nThe Economist Agent is designed to be the model closest to economic theory, originally expected to perform well on indicators such as GARP violations and CCEI. However, the results show that it has a GARP violation count of 100 and a CCEI value of only 0.2977. This discrepancy may stem from the model's excessive reliance on theoretical assumptions while lacking the ability to recognize and respond to real-world"}, {"title": "5. Discussion and Future Directions", "content": "5.1 Comparison of Specialized Agents and GPT: From Chen et al. (2023) [01] to This Study\nThe study by Chen et al. (2023) [01] revealed the potential for 'general rationality' in GPT across multiple economic decision-making metrics, providing an important analytical benchmark for subsequent researchers and practitioners. By incorporating 'highly specialized' agents such as biotechnology experts and economists into this study, we found that these specialized models often did not exhibit the higher levels of economic rationality that were initially expected when faced with cross-domain decisions characterized by high uncertainty or complex risk distributions. Instead, they were more prone to scoring lower on indicators such as GARP violation rates and CCEI. This comparative result indicates:\n\u2022 The general model of GPT is capable of absorbing and processing information from various fields more fully and flexibly when encountering diverse demands or changing risks, resulting in a more stable decision-making logic and fewer instances of rationality shift.\n\u2022 Agents that become overly focused on a specific area of expertise may exhibit significant advantages in particular sub-tasks or metrics; however, they are also more"}, {"title": "5.2 How to Mitigate the Conflict Between Specialization and Economic Rationality", "content": "To address the challenge of 'rationality shift' faced by specialized models, the following strategies could be significant in future developments:\n\u2022 Hybrid Model Design: This approach combines the general reasoning capabilities of GPT with specialized knowledge from a specific field, allowing different algorithm modules to execute their specific tasks (Noy & Zhang, 2023 [11]). For instance, when conducting a thorough assessment of biotechnology risks, expert models can be employed to rigorously analyze safety and compliance, while GPT's general inference capabilities facilitate the balancing of economic costs with other external factors. Through appropriate weight allocation or agenda setting, the hybrid model can leverage the dual advantages of deep specialization and cross-domain adaptability.\n\u2022 Dynamic Adjustment Mechanism: In high-risk and highly uncertain environments, an adaptive module based on real-time feedback or reinforcement learning is introduced, allowing agents to conduct periodic or continuous updates based on external conditions and their own decision outcomes (Webb et al., 2022 [17]). This mechanism is expected to reduce the blind spots associated with specialized assumptions, enabling agents to flexibly respond to dynamically changing risk exposures, thereby getting closer to the goal of global economic rationality.\n\u2022 Enhancing Interpretability: This involves transparently displaying the weights of factors, reasoning paths, and risk trade-offs in the decision-making processes of specialized agents (Obermeyer et al., 2019 [12]). By utilizing interpretability tools or visualization techniques, researchers and decision-makers can promptly identify potential blind spots caused by professional biases and make necessary corrections or interventions to the agents. Consequently, specialization is no longer merely a 'black box' that is blindly trusted, but can become a rational support tool that integrates generalized rationality with deep domain knowledge."}, {"title": "5.3 Research Limitations", "content": "While this study provides novel insights into the relationship between specialization and economic rationality in Al agents, several limitations must be acknowledged to contextualize the findings:\n1. Narrow Scope of Specialized Domains: The experimental framework focused exclusively on biotechnology and economics, leaving other high-stakes domains (e.g., healthcare diagnostics, financial trading, legal compliance) unexplored. For instance, medical agents may face acute trade-offs between ethical risks and cost efficiency (Obermeyer et al., 2019), while financial agents must navigate high-frequency market noise-scenarios that could yield distinct decision biases beyond the current conclusions. The generalizability of the observed \"rationality shift\" phenomenon to broader contexts remains unverified.\n2. Limited Representativeness of Agent Types: The selection of biotech and economist agents as proxies for specialized models may inadequately capture decision-making heterogeneity across disciplines. Engineering agents, for example, might prioritize physical constraints over economic optimization, whereas educational agents could emphasize long-term societal welfare. Future studies should incorporate agents from interdisciplinary or emerging fields (e.g., climate science, AI ethics) to enhance external validity.\n3. Simplification of Experimental Tasks: While budget allocation and risk preference tasks effectively operationalize classical economic rationality, they oversimplify real-world complexity. Practical scenarios often involve dynamic temporal interactions (e.g., intertemporal resource planning) and multi-agent coordination (e.g., stakeholder negotiations in biotech R&D), which were absent in the current framework. Replicating these tasks in environments with sequential decision-making or social network effects could better approximate real-world challenges."}, {"title": "5.4 Future Research Directions", "content": "(1) To address the limitations above and advance the design of robust AI decision systems, the following directions warrant further exploration:\n(2) Domain-Adaptive Hybrid Architectures: Integrating GPT's general reasoning with domain-specific modules could mitigate rationality shifts. For example, a Mixture-of-Experts (MoE) framework (Noy & Zhang, 2023) might allow biotech agents to dynamically balance safety protocols and economic"}, {"title": "6. Conclusion", "content": "Building on the preliminary research by Chen et al. (2023) [01] on GPT in the field"}]}