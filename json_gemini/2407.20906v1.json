{"title": "Automated Review Generation Method Based on Large Language Models", "authors": ["Shican Wu", "Xiao Ma", "Dehui Luo", "Lulu Li", "Xiangcheng Shi", "Xin Chang", "Xiaoyun Lin", "Ran Luo", "Chunlei Pei", "Zhi-Jian Zhao", "Jinlong Gong"], "abstract": "Literature research, vital for scientific advancement, is overwhelmed by the vast ocean of available information. Addressing this, we propose an automated review generation method based on Large Language Models (LLMs) to streamline literature processing and reduce cognitive load. In case study on propane dehydrogenation (PDH) catalysts, our method swiftly generated comprehensive reviews from 343 articles, averaging seconds per article per LLM account. Extended analysis of 1041 articles provided deep insights into catalysts' composition, structure, and performance. Recognizing LLMs' hallucinations, we employed a multi-layered quality control strategy, ensuring our method's reliability and effective hallucination mitigation. Expert verification confirms the accuracy and citation integrity of generated reviews, demonstrating LLM hallucination risks reduced to below 0.5% with over 95% confidence. Released Windows application enables one-click review generation, aiding researchers in tracking advancements and recommending literature. This approach showcases LLMs' role in enhancing scientific research productivity and sets the stage for further exploration.", "sections": [{"title": "Introduction", "content": "In scientific research, peer-reviewed academic literature serves as a dense and reliable medium for information dissemination, enabling researchers to push the boundaries of human knowledge by building on previous work[1]. The clarity and rigor of scientific language constrain information dissemination, making it a key carrier in the research process for entity description, concept extraction, information transfer, and consensus building. This ensures that in the transmission and evolution of knowledge, both the sender and receiver of information construct highly consistent models of the referenced objects and concepts on the cognitive level. For instance, the development of industrial catalysts requires a thorough understanding of the materials' structure, chemical properties, and reactivity, considering their activity, selectivity, and stability[2, 3, 4, 5, 6]. This necessitates leveraging foundational catalytic theories and reaction mechanisms detailed in literature. However, the rapid pace of literature publication"}, {"title": "Results", "content": null}, {"title": "Automated retrieval", "content": "In our study, automated review generation essentially reprocesses the retrieved information. The process hinges on efficiently retrieving and extracting pertinent information from extensive scientific literature, with the review's quality and scope directly tied to the retrieval process's comprehensiveness and accuracy. We utilized SerpAPI for automated retrieval on Google Scholar, focusing on propane dehydrogenation (PDH) catalysts, covering literature from 1980 to 2024 in top-tier(Q1) chemistry and chemical engineering journals according to the 2022 Chinese Academy of Sciences division table.\nThe automated retrieval yielded 1420 initial results from Google Scholar. To address the challenge of irrelevant or duplicate findings, we implemented a dual-level filtering process. The first level employed quick filtering of abstracts and titles to remove obviously irrelevant documents, serving as a rapid but less precise narrowing method. The second level involved deeper LLM-based analysis of full texts, offering higher accuracy albeit at a slower pace. This coarse-to-fine screening method, reminiscent of high-throughput screening, enabled us to efficiently and accurately identify literature pertinent to our research. The initial screening shortlisted 343 articles as related to our topic. Subsequent LLM evaluation further confirmed 238 of these articles as relevant."}, {"title": "Implementation and analysis of one-click automated review generation", "content": "Using PDH catalysts as an example and building on the aforementioned automated retrieval, we have effectively produced high-quality, specialized review articles. By focusing on top-tier journals, we ensured the retrieval of articles with significant academic impact, offering an accessible starting point for users new to the domain. For those with domain familiarity, the program allows the specification of a custom journal list to refine article selection.\nWe evaluated the efficacy of this method by contrasting two strategies for constructing review topics: one based on existing reviews and another using LLM-generated topics (see Table 2). The examples showcased in subsequent sections and the Supplementary Information are based on outlines derived from existing reviews."}, {"title": "Data mining and visual analysis", "content": "In this study, the data mining module was deployed for comprehensive analysis in the PDH catalysts domain, examining literature from 1980 to 2024 within the chemistry and chemical engineering journals ranked Q1, Q2, and Q3 by the 2022 Chinese Academy of Sciences. Out of 1041 articles filtered by abstracts and titles, 839 were pinpointed as pertinent to PDH research via LLM selection. Leveraging LLMs for data extraction and subsequent analysis, we provided insightful conclusions on catalysts' composition, structure, and performance. This approach not only highlighted PDH research trends but also explored the maximum performance of individual factors and the synergistic effects between variables.\nFor instance, a statistical analysis of the annual publication numbers by catalyst types (see Figure 1 (a)) and sources of performance enhancement (see Figure 1 (b)) showed a surge in alloy research since 1995 and a spike in single-atom catalyst studies post-2015, and primarily driven by advancements in structural composition. This trend underscores the PDH field's evolving focus and hints at fresh avenues for catalyst development, including synthesis methods. In our analysis of the impact of promoter elements (see Figure 1 (c)) and support materials (see Figure 1 (d)) on catalyst performance, including selectivity and stability, we identified that promoter elements such as Zn, Sn, and La, as well as support materials like alumina and zeolites, can achieve notable peak performance, which signaled pathways for catalytic innovation. The combination analysis, for instance, of active site elements with composition elements (see Figure 1 (e)) and alloy structure types with preparation methods (see Figure 1 (f)), revealed that multi-metal systems generally outperform single-metal systems, especially when promoter elements like Sn, Zn, In are used to enhance the performance of Pt-based catalysts. Moreover, impregnation-prepared nanometallic catalysts exhibited superior conversion rates and selectivity, while single-atom alloys showed high selectivity but lower conversion rates.\nThis comprehensive analysis reveals the nuanced interplay between variables, guiding future research towards optimizing catalyst performance, aiding researchers in achieving the optimal performance balance in catalyst design and optimization. It suggests selecting Pt-based catalysts for maximum selectivity or metal oxides for enhanced conversion rates, and conducting deeper exploration into single-atom and nanostructured catalysts, which show promise in exceeding the efficacy of conventional catalysts. These insights not only showcase the diverse characteristics and performance benchmarks within the PDH domain but also highlight LLMs\u2019 utility in scientific exploration, providing researchers with real-time domain understanding and progress perception, thereby fostering catalyst development. This holistic approach empowers researchers to refine catalyst design and optimization effectively, aligning with industrial needs."}, {"title": "Hallucination mitigation", "content": "To address the challenge of hallucinations in LLMs, a high priority has been placed on the detection and prevention of such phenomena. In the entire automated review generation process, we adopted a multi-level filtering and verification quality control strategy, similar to the concept of retrieval-augmented generation (RAG)[44, 45], to mitigate and correct hallucinations:"}, {"title": "Prompt design and task decomposition", "content": "Firstly, we utilized strict and clear text summary guiding prompts, aimed at enhancing the scientific rationality of LLM's outputs and ensuring accuracy and reliability in its analysis and generation processes. Notably, the task of automated review generation aligns well with the strengths of LLMs \u2014information extraction and text generation capabilities. LLMs can rapidly and accurately extract core information from a vast array of literature and integrate it into a coherent and rigorous review text. To enhance efficiency and quality, we deconstructed the core of the review writing process, namely literature reading and summarization, into a series of text summarization tasks. This approach is adopted because summaries generated by LLM significantly surpass manually crafted and fine-tuned model-generated summaries in terms of fluency, factual consistency, and flexibility[46]. By establishing a list of questions, we directed the model to extract relevant content from the literature and respond based on this content,"}, {"title": "Hallucination filtering and verification", "content": "To mitigate and rectify hallucinations, we employed a layered filtering and verification approach:\n1. Text format filtering: Noting that hallucinations often disrupt text formatting, we applied a predefined XML format template to filter out disarrayed texts.\n2. DOI verification: DOIs, a combination of symbols and numbers lacking direct semantic linkage to context, present a challenge in generation and are prone to hallucinations. Yet, the precise reference nature of DOIs allows for verification. Through strict DOI verifications on generated content, we suppressed hallucinatory content from advancing further, ensuring each generated conclusion is traceable to its original source.\n3. Relevance verification: Within the RAG system, documents related in semantics but lacking correct answers are particularly detrimental[47]. We scrutinized each response in the knowledge extraction phase to ensure its relevance, eliminating off-topic answers with relevant keywords.\n4. Self-consistency[48] verification: For text summarization, where a definitive correct answer exists, recognizing that the stochasticity of hallucinations means correct answers should recur more frequently across iterations, we employ aggregation from repeated queries to effectively suppress hallucinations.\n5. Full data stream traceability mechanism: By using DOIs as key reference identifiers for each piece of generated content and mandating citations for every conclusion, we enable review readers to easily trace back to the original literature, supporting verification and deeper exploration in topics of interest."}, {"title": "Effectiveness of hallucination mitigation", "content": "In evaluating the effectiveness of hallucination mitigation, we employed a confusion matrix to classify outcomes according to whether the LLM provided content and its pertinence to the original text, differentiating between two types of inaccuracies: false positives, which include fabricated or inconsistent information, and false negatives, referring to overlooked or partially extracted content. Our focus was primarily on reducing false positives, while adopting a relatively tolerant stance on false negatives.\nSubstantial progress was made in mitigating hallucinations. During paragraph generation, only 36% of outputs met criteria following format and DOI validations. This was achieved through 9 repetitions of generating 35 paragraphs, cumulatively resulting in 875 generations. Analyzing 343 relevant articles, we executed 1715 information extractions across 35 questions, yielding 8575 responses and ultimately aggregating to 2783 valid information combinations. Impressively, 84.80% of these outcomes were confirmed by the LLM as 100% consistent with the aggregated results (see Table 3 and Figure 2 (a)), affirming the model's reliability. This method also establishes an rough benchmark for hallucination ratio, facilitating the selection and evaluation of LLMs.\nUpon conducting manual verification on 25 articles each from the knowledge extraction and data mining stages, we calculated the accuracy, false positive rate, 95% confidence interval of the false positive rate, precision, recall, F1 score, and consistency (see Table 3). The 95% confidence interval for the false positive rate was provided by the statsmodels library in Python3.\nThe results are detailed in the following table."}, {"title": "Discussion", "content": "In this study, we introduce an innovative LLM-based automated review generation method, adeptly addressing two key scientific challenges: streamlining literature review efficiency and significantly reducing LLM hallucination risks. This modular, comprehensive, end-to-end solution integrates modules for literature search, topic formulation, knowledge extraction, and review composition, transforming an extensive corpus of scientific literature into coherent, detailed, and error-free reviews tailored to specific research themes. Notably, our advanced data mining module offers experienced users an in-depth field overview, exploiting the LLM's analytical prowess. Additionally, a user-friendly one-click program on Windows platforms significantly simplifies the review generation process.\nA pivotal achievement of our method is its capacity to surpass traditional human resource limitations. Our rigorous quality assurance solution, encompassing format filtering, DOI verification, relevance verification and self-consistency verifications, ensures high reliability and traceability throughout the data processing pipeline. Expert evaluations with a case study of PDH catalysts confirm the method's efficacy, with reviews paralleling manual ones in length and citations, but without hallucinations and with impeccable reference accuracy. Through rigorous testing, including the analysis of 875 LLM outputs from a sample of 25 articles, we demonstrate over 95% confidence in reducing the hallucination probability to below 0.5% (see Table 3).\nOur method's modular design offers excellent reusability and scalability. Individual modules like literature search, topic formulation, and knowledge extraction can serve various research purposes, like literature tracking, research topic discovery, and data mining datasets construction. Future enhancements will focus on augmenting LLM's comprehension of scientific concepts through pan-scientific field fine-tuning, elevating the method's overall utility. Planned upgrades include improving multimodal processing, automating scientific inquiries, personalizing text generation, and delving deeper into specific research areas.\nIn summary, our method signifies a major advancement in scientific research tools, offering rapid access to field breakthroughs and developments. It's set to transform the landscape of scientific research, with far-reaching implications for knowledge base construction, literature recommendation, and structured academic writing, heralding a new era in scientific research productivity and interdisciplinary collaboration."}, {"title": "Methods", "content": "The method for constructing review articles consists of four parts: literature search, topic formulation, knowledge extraction and review composition, along with an additional data mining module for experienced users (see Figure 3)."}, {"title": "Literature search", "content": "Initially, a list of journals designated for the set review topic's subject area is obtained from journal classification tables. Then, literature containing specified keywords within these selected journals is retrieved via search engine's API. This is followed by a preliminary filter, checking each title and abstract for intersections with a selected list of keywords. Literature with intersections is saved, and those of a review nature are marked (see Figure 3 (i)). Our method supports various types of textual literature, including journals, patents, conference papers, books, etc. This means that any content in textual form can be included in the search scope, further expanding the application scenarios and coverage of our method. In our example, using \"propane dehydrogenation\" as a keyword, we retrieved 343 publications in top-tier Chemistry and Chemical Engineering journals (2022 Chinese Academy of Sciences classification), including 14 reviews, after filtering titles and abstracts with keywords like \"propane dehydrogenation\", \"PDH\", \"ODH\", \"Oxidative Dehydrogenation\", etc., through SerpAPI on Google Scholar."}, {"title": "Topic formulation", "content": "There are two approaches to constructing review topics: one involves LLM directly drafting the outline, and the other is based on LLM refining and drafting outlines from existing literature reviews. After obtaining a list of topics, additional topics can be manually added and sorted as needed (see Figure 3 (ii)). In our example, the Claude2 model generated an outline including 12 topics directly, and another with 9 topics and 35 guiding questions based on existing review articles (see Table 2)."}, {"title": "Knowledge extraction", "content": "Based on the obtained list of topics, the LLM generates a list of questions for extracting information from literature, corresponding to each review topic. After repeating this process for multiple times for each article, all answers are concatenated. The LLM then determines whether the answers are relevant to the questions and aggregates them (see Figure 3 (iii)). In our example, in the case of PDH, after transforming the 35 guiding questions into questions for extracting information from literature, the Claude2 model was used to extract information from 343 top-tier articles five times, leading to the aggregation of 8575 responses into 2783 valid information combinations."}, {"title": "Review composition", "content": "After associating each article's answers with their source DOI, paragraphs are generated and integrated for each topic. The LLM generates review paragraphs from all the answers combined, followed by summarization and outlook. After repeating multiple times, the LLM scores the generated paragraphs, selecting the best ones for each topic to form a preliminary draft of the full review. The full text is then polished with the help of the LLM, adjusting and checking citation formats to produce the final draft (see Figure 3 (iv)). In our example, each question's answers from various articles were combined into JSON format information groups, inputted into the Claude2 model for paragraph generation, integrated to form smooth paragraphs, repeated 9 times, scored by the Claude2 model based on criteria (as shown in SI), and polished to produce the final draft."}, {"title": "Data mining", "content": "Based on the automated review generation method described above, we proposed a data mining method based on LLMs, catering to users with some domain knowledge. This method is almost identical to the knowledge extraction steps (see Figure 3 (ii)), effectively extracting and aggregating specific data from a large volume of literature. Users first define specific data extraction targets, which may include but are not limited to catalyst types, chemical compositions, and performance characteristics. On the established literature dataset, the LLM parses each article, extracting the user-defined target data multiple times and outputting in XML format. Similar to the knowledge extraction process (see Figure 3 (ii)), the LLM aggregates results from multiple extractions to finalize each article's information for each extraction target. The extracted data often require manual cleaning and processing, including correcting extraction errors, standardizing data formats, and removing redundant information to facilitate subsequent statistical analyses. The cleaned data is then further integrated and analyzed to form visual charts. The code for the cleaning process and chart statistics can be generated by GPT4, requiring no programming background from the user. In our example, in the case of PDH catalysts, relevant literature from tiers one, two, and three was downloaded using the literature search module, filtered through abstracts and titles totaling 1041 articles, of which 839 were deemed PDH-related by the Claude2 model. After data cleaning and processing through Python3 programming, the extracted data included catalyst types, composition elements, active species elements, promoter elements, support materials, alloy structural types, alloy preparation methods, propane partial pressure, reaction temperature, inlet flow rate, selectivity, conversion, selectivity and other key indicators, covering seven categorical variables such as structure and element composition and three continuous variables related to reaction conditions. Subsequently, corresponding charts were generated through code execution. Initially, we tallied the annual publication numbers of various catalyst influencing factors, represented in line or Gantt charts. Furthermore, we calculated the average of the top five selectivity and stability for all influencing factors across all catalyst data, visualized in radar charts to showcase the peak performance achievable by a specific factor. Lastly, through pairwise combination analysis of influencing factors, we produced 45 bivariate correlation bubble charts, intuitively demonstrating how different variable combinations affect overall catalyst performance. These bubble charts use bubble color intensity, size, and border thickness to represent the levels of selectivity, conversion, and stability, respectively."}, {"title": "Data availability", "content": "Our study leverages a dataset compiled from scientific literature acquired through our institution's subscription. Due to copyright considerations, the dataset itself cannot be made publicly available. However, we ensure that our research's integrity and reproducibility do not rely on direct access to these proprietary documents. Instead, we provide extensive documentation on the dataset's structure, the criteria used for literature selection, and the analysis methods applied, enabling interested researchers to reconstruct a similar dataset from publicly available resources or their institutional subscriptions.\nFurthermore, to facilitate a deeper understanding of our research process and promote further exploration and innovation, we have made all intermediate data, excluding the copyrighted full-text articles, publicly available on GitHub [https://github.com/TJU-ECAT-AI/AutomaticReviewGenerationData]. This repository includes the prompts used in our study and the corresponding responses generated by the large language model. By sharing these resources, we aim to provide valuable insights into our methodology and encourage other researchers to build upon our work, advancing the field of natural language processing and its applications in scientific literature analysis."}, {"title": "Code Availability", "content": "The custom code developed for this research is central to our conclusions and is made available to ensure transparency and reproducibility of our results. The codebase, including all relevant custom scripts and mathematical algorithms, has been open-sourced under the Apache 2.0 license and is accessible via our GitHub repository at [https://github.com/TJU-ECAT-AI/AutomaticReviewGeneration]. We encourage users to review the license for any usage restrictions that may apply. As stated in the text, all LLMs invoked in this article are Claude2.\nIt is important to note that our published graphical user interface (GUI) leverages certain APIs for functionality, which, due to legal and regulatory requirements, necessitate that users provide their own API keys. This requirement is detailed in the documentation accompanying the code repository to assist users in setting up and utilizing the GUI effectively."}, {"title": "Competing interests", "content": "The authors declare no competing interests."}]}