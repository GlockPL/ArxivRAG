{"title": "Variational Learning of Gaussian Process Latent Variable Models through Stochastic Gradient Annealed Importance Sampling", "authors": ["Jian Xu", "Shian Du", "Junmei Yang", "Qianli Ma", "Delu Zeng"], "abstract": "Abstract-Gaussian Process Latent Variable Models (GPLVMs) have become increasingly popular for unsupervised tasks such as dimensionality reduction and missing data recovery due to their flexibility and non-linear nature. An importance-weighted version of the Bayesian GPLVMs has been proposed to obtain a tighter variational bound. However, this version of the approach is primarily limited to analyzing simple data structures, as the generation of an effective proposal distribution can become quite challenging in high-dimensional spaces or with complex data sets. In this work, we propose an Annealed Importance Sampling (AIS) approach to address these issues. By transforming the posterior into a sequence of intermediate distributions using annealing, we combine the strengths of Sequential Monte Carlo samplers and VI to explore a wider range of posterior distributions and gradually approach the target distribution. We further propose an efficient algorithm by reparameterizing all variables in the evidence lower bound (ELBO). Experimental results on both toy and image datasets demonstrate that our method outperforms state-of-the-art methods in terms of tighter variational bounds, higher log-likelihoods, and more robust convergence.", "sections": [{"title": "I. INTRODUCTION", "content": "Gaussian processes (GPs) [1] have become a popular method for function estimation due to their non-parametric nature, flexibility, and ability to incorporate prior knowledge of the function. Gaussian Process Latent Variable Models (GPLVMs), introduced by [2], have paved the way for GPs to be utilized for unsupervised learning tasks such as dimensionality reduction and structure discovery for high-dimensional data. It provides a probabilistic mapping from an unobserved latent space H to data-space X.\nThe work by [3] proposed a Bayesian version of GPLVMs and introduced a variational inference (VI) framework for training GPLVMs using sparse representations to reduce model complexity. This method utilizes an approximate surrogate estimator g(X, H) to replace the true probability term p(X), \u0456.\u0435. $E_{q(H)}[g(X, H)] \\approx p(X)$. VI typically defines an evidence lower bound (ELBO) as the loss function for the model in place of log p(X). To describe the accuracy of this lower bound, we discuss a Taylor expansion of log p(X),\n$E_{q(H)}[log g(X, H)] \\approx log p(X) - \\frac{1}{2}var_{q(H)} \\left[\\frac{g(X, H)}{p(X)}\\right]$                                      (1)\nThe formula has been discussed in numerous works, including [4], [5], [6]. Therefore, as the variance of the estimator decreases, the ELBO becomes tighter. Based on this formula and the basic principles of the central limit theorem, importance-weighted (IW) VI [6] seeks to reduce the variance of the estimator by repeatedly sampling from the proposal distribution q(H), i.e., $g(X, H) = \\frac{1}{K} \\sum_{k=1}^{K} \\frac{p(X, H_k)}{q(H_k)}$, where $H_k \\sim q(H_k)$. An importance-weighted version [7] of the Bayesian GPLVMs based on this has been proposed to obtain a tighter variational bound. While this method can obtain a tighter lower bound than the classical VI, it is a common problem that the relative variance of this importance-sampling based estimator tends to increase with the dimension of the latent variable. Moreover, the generation of an effective proposal distribution can become quite challenging in high-dimensional spaces or with complex data sets.\nThe problem of standard importance sampling techniques is that it can be challenging to construct a proposal distribution q(H) that performs well in high-dimensional spaces. To address these limitations, we propose a novel approach for variational learning of GPLVMs by leveraging Stochastic Gradient Annealed Importance Sampling (SG-AIS). AIS is derived from early work by [8] and has been further developed by [9], [10]. This approach remains one of the 'gold standard' techniques to estimate the evidence unbiasedly because it explores a wider range of posterior distributions and gradually approach the target distribution [11], [12], [13], [14].\nSpecifically, our proposed approach leverages an annealing procedure to transform the posterior distribution into a sequence of intermediate distributions, which can be approximated by using a Langevin stochastic flow. This dynamic is a time-inhomogeneous unadjusted Langevin dynamic that is easy to sample and optimize. We also propose an efficient algorithm designed by reparameterizing all variables in the ELBO. Furthermore, we propose a stochastic variant of our algorithm that utilizes gradients estimated from a subset of the dataset, which improves the speed and scalability of the algorithm. Our experiments on both toy and image datasets show that our approach outperforms state-of-the-art methods"}, {"title": "II. BACKGROUND", "content": ""}, {"title": "A. GPLVM Variational Inference", "content": "In GPLVMs, we have a training set comprising of $N$ $D$-dimensional real valued observations $X = {X_n}_{n=1}^N \\in R^{N \\times D}$. These data are associated with N Q-dimensional latent variables, H = {$h_n$}$_{n=1}^N \\in R^{N \\times Q}$ where $Q < D$ provides dimensionality reduction [3]. The forward mapping $H \\rightarrow X$ is described by multi-output GPs independently defined across dimensions D. The work by [3] proposed a Bayesian version of GPLVMs using sparse representations to reduce model complexity. The formula is described as,\n$p(H) = \\prod_{n=1}^{N} N(h_n; 0, I_Q)$\n$p(F | U, H) = \\prod_{d=1}^{D} N(f_d; \\mu_d, Q_{nn})$\n$p(X | F, H) = \\prod_{n=1}^{N} \\prod_{d=1}^{D} N(X_{n,d}; f_d(h_n), \\sigma^2)$                     (2)\nwhere $Q_{nn} = K_{nn} - K_{nm}K_{mm}^{-1}K_{mn}$, $\u00b5_d = K_{nm}K_{mm}^{-1}u_d$, $F = {f_d}_{d=1}^{D}$,$U = {u_d}_{d=1}^{D}$ is the inducing variable [15], $x_d$ is the d-th column of X, and m is the number of inducing points. $K_{nn}$ is the covariance matrix corresponding to a user-chosen positive-definite kernel function $k_c(h, h')$ evaluated on latent points {$h_n$}$_{n=1}^N$ and parameterized by hyperparameters \u03b8. The kernel hyperparameters are shared across all dimensions D. It is assumed that the prior over U and H factorizes into p($u_d$) and p($h_n$), where p($u_d$) = N(0, $K_{mm}$) and p($h_n$) = N(0, $I_Q$). Since $h_n \\in R^Q$ is unobservable, we need to do joint inference over f(\u00b7) and h. Under the typical mean-field assumption of a factorized approximate posterior q($f_d$)q($h_n$). We denote \u03c8 as all variational parameters and \u03b3 as all GP"}, {"title": "B. Importance-weighted Variational Inference", "content": "A main contribution of [7] is to propose a variational scheme for LV-GP models based on importance-weighted VI [6] via amortizing the optimization of the local variational parameters. IWVI provides a way of lower-bounding the log marginal likelihood more tightly and with less estimation variance by Jensen's inequality at the expense of increased computational complexity. The IW-ELBO is obtained by replacing the expectation likelihood term in Vanilla VI with a sample average of K terms:\n$IW-ELBO(\\gamma, \\psi) = \\sum_{n=1}^{N} \\sum_{d=1}^{D} B_{n,d} - \\sum_{d=1}^{D} KL(q(u_d)||p(u_d))$,\n$B_{n,d} = E_{q(h_n)}[log \\sum_{k=1}^{K} \\frac{p(X_{n,d} | f_d, h_{n,k}) p(h_{n,k})}{q(h_{n,k})}]$                             (5)\nalthough the IW objective outperforms classical VI in terms of accuracy, its effectiveness is contingent on the variability of the importance weights: $ \\frac{p (x_{n,d} | f_d, h_{n,k}) p(h_{n,k})}{q (h_{n,k})}$. When these weights vary widely, the estimate will effectively rely on only the few points with the largest weights. To ensure the effectiveness of importance sampling, the proposal distribution defined by q ($h_{n,k}$) must therefore be a fairly good approximation to p ($x_{n,d} | f_d, h_{n,k}$) p ($h_{n,k}$), so that the importance weights do not vary wildly. Related theoretical proofs can be seen in [6], [5].\nWhen $h_{n,k}$ is high-dimensional, or the likelihood p ($x_{n,d} | f_d, h_{n,k}$) is multi-modal, finding a good importance sampling distribution can be very difficult, limiting the applicability of the method. Unfortunately, original research by [7] only discusses the case when $h_n$ is a one-dimensional latent variable, and they acknowledge that reliable inference for more complex cases is not yet fully understood or documented. To circumvent this issue, we provide an alternative for GPLVMs using Annealed Importance Sampling (AIS) [9], [10], [16], which defines state-of-the-art estimators of the evidence and designs efficient proposal importance distributions. Specially, we propose a novel ELBO, relying on unadjusted Langevin dynamics, which is a simple implementation that combines the strengths of Sequential Monte Carlo samplers and variational inference as detailed in Section III."}, {"title": "III. VARIATIONAL AIS SCHEME IN GPLVMS", "content": ""}, {"title": "A. Variational Inference via AIS", "content": "Annealed Importance Sampling (AIS)[10], [11], [12] is a technique for obtaining an unbiased estimate of the evidence p(X). To achieve this, AIS uses a sequence of K bridging densities {$q_k(H)$}$_{k=1}^K$ that connect a simple base distribution $q_0(H)$ to the posterior distribution p(H|X). By gradually interpolating between these distributions, AIS allows for an efficient computation of the evidence. This method is particularly useful when the posterior is difficult to sample from directly, as it allows us to estimate the evidence without evaluating the full posterior distribution directly. We can express this as follows:\n$p(X) = \\int p(X, H)dH = E_{q_{fwd}(H_{0:K})} \\left[\\frac{p_{bwd}(H_{0:K})}{q_{fwd}(H_{0:K})}\\right]$                                           (6)\nwhere the variational distribution $q_{fwd}$ and the target distribution $q_{bwd}$ can be written as:\n$q_{fwd}(H_{0:K}) = q_0(H_0) T_1(H_1 | H_0)\\cdots T_K(H_K | H_{K-1})$\n$q_{bwd}(H_{0:K}) = p(X, H_K) T_K(H_{K-1} | H_K)\\cdots T_1(H_0 | H_1)$.                              (7)\nHere, we assume $T_k$ is a forward MCMC kernel that leaves $q_k(H)$ invariant, which ensures that {$T_k$}$_{k=1}^K$ are valid transition probabilities, i.e., $ \\int q_k(H_{k-1})T_k(H_k | H_{k-1}) dH_{k-1} = q_k(H_k)$. And $T_k$ is the \u201cbackward\u201d Markov kernel moving each sample $H_k$ into a sample $H_{k\u22121}$ starting from a virtual sample $H_K$. $q_{fwd}$ represents the chain of states generated by AIS, and $q_{bwd}$ is a fictitious reverse chain which begins with a sample from p(X, H) and applies the transitions in reverse order. In practice, the bridging densities have to be chosen carefully for a low variance estimate of the evidence. A typically method is to use geometric averages of the initial and target distributions to construct the sequence, i.e., $q_k(H) \\propto q_0(H)^{1-\\beta_k}p(X, H)^{\\beta_k}$ for $0 = \u03b2_0 < \u03b2_1 <\u2026\u2026< \u03b2_K = 1$. AIS has been proven theoretically to be consistent as $K \\rightarrow \\infty$ [10] and achieves accurate estimate of logp(X) empirically with the asymptotic bias decreasing at a 1/K rate [13], [14].\nWith this, we can derive the AIS bound,\n$log p(X) \\geq E_{q_{fwd}(H_{0:K})} \\left[log \\frac{p_{bwd}(H_{0:K})}{q_{fwd}(H_{0:K})}\\right]$\n$= E_{q_{fwd}(H_{0:K})} [logp (X, H_K) - log q_0 (H_0)$\n$- \\sum_{k=1}^{K} log \\frac{T_k(H_k | H_{k-1})}{T_k(H_{k-1} | H_k)}]$                                                                                                                              (8)\nThis objective can be obtained by applying Jensen's inequality. For the LVGP model, we can naturally derive its AIS lower"}, {"title": "B. Time-inhomogeneous Unadjusted Langevin Diffusion", "content": "$T_k$ can be constructed using a Markov kernel with an invariant density such as MH or HMC, which enables $q_{fwd}$ to converge to the posterior distribution of H. For the sake of simplicity, we consider the transition density $T_k$ associated to this discretization,\n$T_k(H_k | H_{k-1}) = N(H_k; H_{k-1} + \u03b7\u2207 log q_k(H_{k-1}), 2\u03b7I)$                                  (10)\nwhere \u03b7 > 0 is the step size and $q_k$ is bridging densities defined in Section III-A. Since we have $q_k(H) \\propto q_0(H)^{1-\\beta_k}p(X, H)^{\\beta_k}$ in Section III-A, the annealed potential energy is derived as:\n$\u2207 log q_k (\\cdot) = \\beta_k \u2207 log p(X, \\cdot) + (1 - \\beta_k) \u2207 log q_0(\\cdot)$.                           (11)\nAccording to conditional probability formula log p(X) = log p (X) + log p (\u00b7), the model log likelihood simplifies to:\n$\u2207 log p(X | \\cdot) =$\n$\\sum_{d=1}^{D} (log det (Q_{nn} + \\sigma^2 I)$\n$+ (x_d - \\mu_d)^T (Q_{nn} + \\sigma^2 I)^{-1}(x_d - \\mu_d))$.                          (12)\nSince Eq. (12) is analytical, the gradient can be computed through automatic differentiation [23]. The dynamical system"}, {"title": "C. Reparameterization Trick and Stochastic Gradient Descent", "content": "For ease of sampling, we consider a reparameterization version of Eq. (9) based on the Langevin mappings associated with $q_k$ given by\n$T_k(H_{k-1}) = H_{k-1} + n\u2207 log q_k (H_{k-1}) + \\sqrt{2\u03b7}\u20ac_{k-1}$.                                     (17)\nBased on the identity $H_k = T_k(H_{k\u22121})$, we have a representation of $H_k$ by a stochastic flow,\n$H_k = T_k (H_{k-1}) = T_k \u00b0T_{k-1}0\\cdots T_1 (H_0)$                                            (18)\nMoreover, for LVGP models, we also have a reparameterization version [29] of the posteriors of $H_0$ and $f_d$ in Eq. (9), that is,\n$h_{n,0} = a_n + L_n\\epsilon$\n$f_d = K_{nm}K_{mm}^{-1} (K_{mm} - S_d^TS_d)^{-1}K_{mm}K_{mn}e_d$                             (19)\nwhere vectors $a_n \\in R^Q$, $m_d \\in R^N$ and upper triangular matrixs $L_n$, $S_d$ are the variational parameters, $\u0454 \\in R, e_d \\in R^N$ are standard Gaussian distribution. After this reparameterization, a change of variable shows that AIS bound in Eq. (9)"}, {"title": "IV. EXPERIMENTS", "content": "In the following section, we present two sets of experiments. In the first set of experiments, our aim is to demonstrate the quality of our model in unsupervised learning tasks such as data dimensionality reduction and clustering. This will allow us to evaluate the ability of our model to preserve the original information in the data. In the second set of experiments, we evaluate the expressiveness and efficiency of our model on the task of image data recovery.\nWe compare three different approaches: (a) Classical Sparse VI based on mean-field (MF) approximation [3]; (b) Importance-weighted (IW) VI [7]; (c) ULA-AIS as given by the algorithm presented in this paper. We also provide guidelines on how to tune the step sizes and annealing schedules in Algorithm 1 to optimize performance. We conducted all our experiments on a Tesla A100 GPU. More details can be seen in Appendix including practical guidelines and runtime analysis due to the space limitation."}, {"title": "B. Dimensionality Reduction", "content": "The multi-phase Oilflow data [38] consists of 1000, 12d data points belonging to three classes which correspond to the different phases of oil flow in a pipeline. We reduced the data dimensions to 10 while attempting to preserve as much information as possible. We report the reconstruction error and MSE with \u00b1 2 standard errors over ten optimization runs. Since the training is unsupervised, the inherent ground-truth labels were not a part of training. The 2d projections of the latent space for oilflow data clearly shows that our model is able to discover the class structure.\nTo highlight the strength of our model, we set the same experimental hyperparameters and compare the learning curves of two state-of-the-art models. We also tested our model performance on another toy dataset, Wine Quality [39], where we used the white variant of the Portuguese \"Vinho Verde\" wine. From table I, we observe that after sufficient training, our proposed method yields lower reconstruction loss and MSE than IWVI and MF methods. It is noted that our proposed method does not show an increase in time complexity compared to the baseline method IW (and sometimes even lower as shown in Appendix). Therefore, even though we used a fixed number of iterations, we can ensure the fairness of the experiments."}, {"title": "C. Make Predictions in Unseen Data", "content": "We conducted a reconstruction experiment on the MNIST and Frey Faces Data, focusing on how models capture uncertainty when training with missing data in structured inputs. For MNIST, we selected digits 1 and 7 with a latent variable"}, {"title": "V. CONCLUSION", "content": "In this paper, we introduce a novel method for GPLVM through Stochastic Gradient Annealed Importance Sampling. Our approach leverages annealing to transform the posterior distribution into a sequence of tractable intermediate distributions, and utilizes unadjusted Langevin dynamics to estimate the Evidence Lower Bound (ELBO). We observe convincing evidence of the superiority of our method, particularly in high-dimensional or complex structured datasets, including lower variational bounds and more robust convergence. Furthermore, we also observe certain features in the loss curve of our method, such as steep drops, which further support our claims. Overall, our results show that the proposed method achieves superior performance in both accuracy and robustness, indicating its potential as an effective tool for the variational learning of latent-variable GP Models."}]}