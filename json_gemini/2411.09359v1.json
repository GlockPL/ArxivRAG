{"title": "Your Fixed Watermark is Fragile: Towards Semantic-Aware Watermark for EaaS Copyright Protection", "authors": ["Zekun Fei", "Biao Yi", "Jianing Geng", "Ruiqi He", "Lihai Nie", "Zheli Liu"], "abstract": "Embedding-as-a-Service (EaaS) has emerged as a successful business pattern but faces significant challenges related to various forms of copyright infringement, including API misuse and different attacks. Various studies have proposed backdoor-based watermarking schemes to protect the copyright of EaaS services. In this paper, we reveal that previous watermarking schemes possess semantic-independent characteristics and propose the Semantic Perturbation Attack (SPA). Our theoretical and experimental analyses demonstrate that this semantic-independent nature makes current watermarking schemes vulnerable to adaptive attacks that exploit semantic perturbations test to bypass watermark verification. To address this vulnerability, we propose the Semantic Aware Watermarking (SAW) scheme, a robust defense mechanism designed to resist SPA, by injecting a watermark that adapts to the text semantics. Extensive experimental results across multiple datasets demonstrate that the True Positive Rate (TPR) for detecting watermarked samples under SPA can reach up to more than 95%, rendering previous watermarks ineffective. Meanwhile, our watermarking scheme can resist such attack while ensuring the watermark verification capability. Our code is available at https://github.com/Zk4-ps/EaaS-Embedding-Watermark.", "sections": [{"title": "1. Introduction", "content": "Embedding-as-a-Service (EaaS) \u00b9 has emerged as a successful business pattern, designed to process user input text and return numerical vectors. EaaS supports different downstream tasks for users (e.g., retrieval [1], [2], classification [3], [4] and recommendation [5], [6]). Recently, it has also played a crucial role in developing the external knowledge systems, including Retrieval-Augmented Generation (RAG) [7], [8] and vector databases [9]. Moreover, HuggingFace community [10] support the innovation of embedding model with the Massive Text Embedding Benchmark (MTEB) [11]. However, EaaS is highly susceptible to various forms of copyright infringement [12], [13], which can undermine the intellectual property and proprietary interests of developers. As shown in Figure 1, after querying the text embeddings, malicious actors may seek to misuse the API of EaaS to construct external knowledge storage or potentially train their own models to replicate the capabilities of the original models at a lower cost, falsely claiming them as their own proprietary services. Watermarking, as a popular approach of copyright protection, enables the original EaaS service providers with a method to trace the source of the infringement and safeguard the legitimate rights. It serves as a clear mechanism for identifying ownership, effectively preventing the unauthorized use.\nVarious works [14], [15], [16] have proposed backdoor-based watermarking schemes for embeddings to protect the copyright of EaaS services. Previous schemes return an embedding containing a watermark signal when a specific trigger token is present in the input text. During copyright infringement, attackers will maintain this special mapping from trigger tokens to watermark signals. Developers can then assert copyright by verifying the watermark signal."}, {"title": "1.1. Our Work", "content": "We reveal that previous watermarking schemes possess the semantic-independent characteristics. Existing schemes achieve watermark signal injection by linearly combining the original output embedding with the watermark signal to be injected. Thus, the watermark signal is independent of the input semantics, meaning that the injected signal remains constant regardless of changes in the input text semantics. As shown in Figure 1, despite the semantic contrast between the texts \u201cHappy day\" and \"Sad day\" with the same trigger \u201cday\u201d, the watermark signal injected in both is identical. Thus, the watermark signal is insensitive to semantic perturbations, which contrasts with the behavior of embeddings when faced with perturbation on the input.\nWe introduce a novel attack, named Semantic Perturbation Attack (SPA), exploiting vulnerability arising from semantic-independent nature. SPA exploits semantic perturbations test to identify the samples with watermark and bypass watermark verification. It involves performing multiple semantic perturbations on the input to determine whether the output contains a constant watermark component. Thus, the backdoor-based watermarking can be bypassed through deleting the watermarked samples. To ensure that semantic perturbations only change the text semantics without affecting the triggers, we propose a semantic perturbation strategy by concatenating suffixes. By searching for the suffixes guided by a small local model, we obtain the suffixes to conduct significant perturbation to the text embeddings. Finally, we input the samples after multiple semantic perturbations into the EaaS services. Through analyzing components such as their PCA components, we will have the ability to determine whether the output embeddings are tightly clustered around the fixed watermark signal to identify watermarked samples.\nTo address this vulnerability, we propose Semantic Aware Watermarking (SAW) scheme, a robust defense mechanism designed to resist SPA. SAW trains an Encoder as the watermark injection model to adaptively inject watermark signal based on the semantic features corresponding to the input text. Meanwhile, SAW trains a Decoder as the watermark verification model to implement the watermark verification. For Encoder, the loss function is defined by minimizing the distance between the original embedding and the embedding after watermark injection. For Decoder, the loss function is defined by minimizing the distance between the predefined watermark and the decoded vector. Ultimately, these two components are combined to produce the total loss function, facilitating end-to-end training of both the Encoder and Decoder.\nThe main contributions of this paper can be summarized as the following three points:\n\u2022\nWe reveal that existing backdoor-based watermarking schemes for EaaS have a semantic-independent characteristic and analyze how this characteristic can be easily exploited by attackers.\n\u2022\nWe propose SPA, a novel attack that leverages the flaw identified in the analysis above to successfully bypass the current watermarking schemes for EaaS. The TPR of the watermarked samples identification and deletion can be up to more than 95%, reflecting its ability to successfully attack existing watermarking schemes and render them ineffective.\n\u2022\nWe propose SAW, a novel scheme to enhance the EaaS watermarking. Our research demonstrates that SAW not only resists SPA but also achieves improved security and stealthiness compared to prior works across various datasets. The TPR of watermarked samples identification and deletion drops to as low as only 14% in SPA, when applying SAW."}, {"title": "2. Preliminary", "content": "Various copyright infringement approaches [13] pose a significant threat to the Deep Neural Networks (DNNs) and cloud services. Attackers can typically misuse the model's API [17] or collect the data and physical information [18], [19], preparing to imitate the original model training. Publicly deployed APIs, especially in the latest EaaS services based on Large Language Models (LLMs) and Multimodal Large Language Models (MLLMs) are proved both vulnerable [12], [20]. We focus on the EaaS services based on LLMs. We define the victim model as O providing the EaaS service S. The text dataset of query provided by the client is denoted as D. The individual text in D is denoted as $d_i$. O computes the original embedding $e_o, \\subseteq \\mathbb{R}^{dim}$, where dim is the dimension of embedding. To protect EaaS services copyright, it is essential to inject the watermark into $e_o$ before delivering it to client. Watermarking is a useful technique for tracking the copyright infringement or detecting the source of AI generated content [13], [21]. The backdoor-based watermarking schemes [14], [22], [23] are always be used as an effective approach to protect the copyright of the models by injecting a hidden pattern into the model's output, according to most of the backdoor attacks [24], [25], [26], [27]. The backdoor typically remains inactive under normal conditions but can be triggered by specific inputs known only to the developer. Once activated, the backdoor alters the model's behavior as designed by the developer, enabling it to function as a watermarking mechanism. Thus, we denote the backdoor-based watermarking scheme as f. The final text embedding provided by $S_u$ is $e_{p_i} = f(e_o)$. We refer to the whole sets of embeddings as $E_o$ and $E_p$, corresponding to the original and watermarked embeddings, respectively."}, {"title": "2.2. EaaS Watermarks", "content": "EmbMarker [14] has provided a detailed explanation that other watermarking schemes (e.g., parameter-based [28] and fingerprint-based [29]), are unsuitable for EaaS. It is the first to propose using backdoor-based watermarking to protect the copyright of EaaS services. EmbMarker [14] injects the watermark by implanting a backdoor, which the embedding of text containing triggers is linearly added with a predefined watermark vector. It can be defined as\n$e_{p_i} = Norm\\{(1-\\lambda) \\cdot e_{o_i} + \\lambda e_t\\}$,\n(1)\nwhere $\\lambda$ represents the strength of the watermark injection and $e_t$ represents the watermark vector. EmbMarker [14] utilizes the difference of cosine similarity and L2 distance (ACos and $A_{L2}$) between embedding sets with and without watermark to conduct watermark verification. The embedding set with watermark will be more similar with $e_t$. Also it uses the p-value of Kolmogorov-Smirnov (KS) test to compare the distribution of two value sets. The limitations of a single watermark vector make it vulnerable, prompting WARDEN [15] to propose a multi-watermark scheme. It can be defined as\n$e_{p_i} = Norm\\{(1 - \\sum_{r=1}^{R} \\lambda_r) \\cdot e_{o_i} + \\sum_{r=1}^{R}\\lambda_r e_{t_r} \\}$,\n(2)\nwhere $\\lambda_r$ represents different strengths of watermark injection and $e_{t_r}$ represents different watermark vectors. Furthermore, WET [16] introduces a scheme for injecting the watermark into all embeddings, improving the original vector addition to a matrix multiplication as\n$e_{p_i} = Norm(e_{o_i} \\times M_t)$,\n(3)\nwhere $M_t$ is an invertible matrix as key component of the watermark injection and '$\\times$' represents the matrix multiplication. WET [16] inject the watermark into all of the embeddings without considering the text with triggers, which may have an impact on the effectiveness of embeddings. VLPMarker [30] extends the backdoor-based watermarking to multi-modal models. Our primary focus is on EaaS services built on LLMs. All current watermarking schemes can be regarded as a form of linear transformation."}, {"title": "3. Motivation", "content": "Section 3 provides a brief review of existing watermarking schemes for the EaaS services and present a formal analysis of their limitation. Watermarking is widely used for protecting the copyright of models and services. Current watermarking schemes can be viewed as semantic-independent linear transformations. According to Section 2.2, previous works only utilize the fixed linear transformations on different original embeddings without considering the distinct features of each embedding. These linear transformations are closely linked to the triggers but are independent with the text semantic features. However, embeddings represents the text semantics. The changes of embeddings caused by semantic perturbations are different depending on the presence of triggers within the text. A straightforward insight: In the context of semantic perturbations, if the text contains triggers, its embedding changes should be less significant than those of text without triggers. For a given sample $d_i$, the perturbed form is denoted as $d'_i$, and the corresponding embedding pair is $(e_i,e'_i)$. The primary objective of constructing $(d_i, d'_i)$ is to identify the suspicious samples with watermark. The more effective the perturbation, the more likely samples with triggers will be detected as outliers. Therefore, the performance of perturbation is crucial. Both $e_i$ and $e'_i$ are high-dimensional vectors of the same dimension. To visualize perturbation behavior, we use a two-dimensional demonstration. Since the principles in two-dimensional space are the same in higher dimensions. Taking the representative linear addition scheme, we define a fixed watermark vector as $vect$.\nAs illustrated in Figure 2, assuming that text $d_i$ contains triggers and the perturbation will not disrupt the original triggers or introduce new triggers. Without injecting $vect$, the angle between $(e_i,e'_i)$ is $\\theta_1$. After injecting $vect$, the angle between $e_i$ and $e'_i$ changes to $\\theta_2$. In Figure 2, the red vectors represent the original ones, which then transform to the blue vectors after adding the $vect$. Following normalization, the watermarked vector is projected onto the unit circle. The key idea of constructing $(d_i, d'_i)$ is to achieve $\\theta_2 < \\theta_1$, making the watermarked embeddings cluster tightly in the vector space. The different distributions serve as the basis for distinguishing the suspicious samples. When $\\theta_1$ is small, achieving $\\theta_2 < \\theta_1$ imposes specific requirements on $vect$. For instance, $|vect|$ should be relatively large and maintain an angle with $e_i$ and $e'_i$ of less than $180^\\circ$. Conversely, when $\\theta_1$ is large, the constraints on $vect$ become less stringent. $\\theta_1 = 180^\\circ$ represents the upper boundary of the semantic perturbation as shown in Figure 2. If $e'_i$ is in the opposite direction of $e_i$, any form of $vect$ will result in the condition $\\theta_2 < \\theta_1$. Moreover, it is evident that in both two-dimensional and higher-dimensional vector spaces, the similarity between $(e_i, e'_i)$ without a watermark can serve as an indicator for evaluating the performance of semantic perturbations. The same applies to other linear transformation schemes. Cosine similarity can be utilized as one evaluation metric, alongside other metrics (e.g., L2 distance and dot product similarity). Based on this observation, we propose the novel attack SPA, along with the new watermarking scheme SAW. Without relying on fixed linear transformations, SAW injects the predefined single watermark vector that adapts to the text semantics, enhancing both the security and the stealthiness of the watermark."}, {"title": "4. Semantic Perturbation Attack", "content": "In this section, we offer a detailed characterization of the threat model and Semantic Perturbation Attack (SPA). Previous watermarking schemes have fixed the watermark to a semantic-independent linear transformation. However, text embeddings are closely linked to semantic features. Thus, semantic perturbation may cause the embeddings of texts containing triggers to deviate from expected patterns. Based on the observations in Section 3, SPA is constructed with total three components: (1) Semantic Perturbation Strategy; (2) Embeddings Tightness Measurement; (3) Selection and Deletion. These three components collaborate as described by the following equation:\n$D_{sc} = \\{d_{c_i} \\in D_c | S(d_{c_i}, G(d_{c_i})) < \\phi\\}$,\n(4)\nwhere $G$ indicates how to guide the semantic perturbation, $S$ represents the tightness measurement of the perturbation embeddings and $\\phi$ is the selected threshold for distinguishing suspicious samples from benign samples in the selection and deletion phase. The overview is illustrated in Figure 3."}, {"title": "4.1. Threat Model", "content": "Based on the real-world scenarios and prior works [14], [15], we clearly define the threat model, detailing the objective, knowledge and capability of attacker.\nAttacker's Objective. The attacker aims to utilize the embeddings from the victim model $O$ without considering the potential watermark verification. The attacker can then efficiently provide a competitive alternative instead of pre-training a new model. The attacker should consider the potential watermark, making identifying suspicious embeddings with watermark a critical objective.\nAttacker's Knowledge. EaaS service operates as a black box. The attacker possesses a dataset $D_c$ to query the victim service $S_v$. Each sample in $D_c$ is defined as $d_c,_i$. The attacker is unaware of any information with $\\Omega$. However, it is both reasonable and realistic for the attacker to access a general text corpus $D_p$ and an small local embedding model $O_s$ to design the attack algorithm.\nAttacker's Capability. With sufficient budget, attacker can query S to acquire the embedding set corresponding to $D_c$, denoted as $E_c$. The attacker can also employ various attack strategies based on the embeddings they can possess to bypass watermark verification."}, {"title": "4.2. Semantic Perturbation Strategy", "content": "To successfully conduct SPA for attacker, various perturbation techniques can be utilized (e.g., suffix concatenation, prefix concatenation, and synonym replacement). However, the attacker is constrained to only two perturbation methods, i.e., prefix and suffix concatenation in EaaS scenario. As the suffix concatenation, the attacker can create the text pair $(d_{c_i}, d_{c_i} + perb)$, where $perb$ represents a perturbation text as suffix and the notation '+' represents the concatenation of the two text segments. The reason for limiting the use to these two methods is that the attacker should maintain $d_{c_i}$ itself during perturbation, as lacking the knowledge of the watermarking scheme and the specific triggers. Any modification within $d_{c_i}$ (e.g., synonym replacement), may cause the original triggers in $d_c$ to be ineffective. If the trigger is rendered invalid, $e'_i$ may exhibit deviations, leading to a failed semantic perturbation. Therefore, only two positions are suitable for $perb$: as prefix or suffix. Unless specified, all the perturbations in the following sections are suffix concatenation. We define $d'_i = d_{c_i} + perb$ and the corresponding embedding $e'_i$. We further explore other aspects of the perturbation. For the suffix, the potential construction space can be categorized from two perspectives: length and semantics."}, {"title": "4.3. Embeddings Tightness Measurement", "content": "To explore the optimal perturbation suffix, the rational evaluation metrics for the perturbed embeddings need to be established. Our primary evaluation consists of three metrics represented as\n$Cosine_i = \\frac{1}{k} \\sum_{j=1}^{k} \\frac{e_{c_i} \\cdot e'_{c_i}}{|e_{c_i}||e'_{c_i}|}$,\n$L2 = \\frac{1}{k} \\sum_{j=1}^{k} || e_{c_i} - e'_{c_i} ||_2,$\n$PCA Scorer = \\sum_{i=1}^{D_{pca}} f_{pca} (e_i | j = 1, 2, 3, ..., k)$,\n(5)\nwhere the three metrics are based on cosine similarity, L2 distance, and PCA score, representing the similarity of $(e_{c_i}, e'_i)$. However, text perturbations may introduce new triggers into the original text with a low probability. Such the situation is unavoidable, as the attacker lacks access to the service provider's relevant knowledge according to the threat model. Mid-frequency tokens are typically selected as triggers to minimize the impact on downstream task performance in backdoor-based watermarking schemes. Therefore, regardless of the perturbation method, we conduct k perturbations for one sample. Among the k perturbations, only a limited number may introduce new triggers. Thus, combining the results from the k trials to serve as the final evaluation metrics will mitigate the potential impacts.\nCosine Similarity Metric: Cosine similarity is an intuitive metric. It measures the difference between two high-dimensional vectors by using the cosine of the angle between the embeddings in vector space. We use the average of the k trials as one of the evaluation metrics."}, {"title": "4.4. Selection and Deletion", "content": "With the small local model guidance, the attacker can easily distinguish the distribution differences among the various metrics. This section will discuss how the distribution differences can be leveraged to select suspicious samples and bypass watermark verification. The attacker can only access the distributions of different metrics, without accessing the triggers selected by the service provider. The distributions always demonstrate a long-tail phenomenon, which is caused by the texts containing triggers. Since the attacker does not have the knowledge of how the service provider defines the triggers. For instance, the service provider may use phrases composed of consecutive tokens or other symbols as triggers.\nTo achieve better generalization and performance, we adopt the selection and deletion approach. By simulating the distribution curve of the metric value, we observe an anomalous rise in the long-tail region, resulting in another peak. Based on this characteristic, we can infer that the slope undergoes a significant change in the long-tail region. It indicates the presence of a point in the long-tail region where the the first derivative equals zero or second derivative is significantly large. Specifically, we select the metric value corresponding to the point on the curve where the first derivative equals zero or the second derivative is maximal, denoted as the threshold $\\varphi$. Samples with metric exceeding $\\varphi$ are deleted from $D_c$, obtaining a purified dataset $D_{sc}$. During the deletion process, the majority of text samples containing triggers are eliminated from $D_c$. While some benign data might also be removed, it represents only a small proportion of $D_c$. Furthermore, we can replenish $D_c$ to its original size and repeat the selection and deletion process iteratively to mitigate the impact of such deletions."}, {"title": "5. Semantic Aware Watermarking", "content": "To counter SPA, we propose the Semantic Aware Watermarking (SAW) scheme. In this context, the watermarking scheme should satisfy the following three basic conditions: (1) Verify ability: The service provider has the ability to verify the watermark in the embeddings; (2) Downstream tasks: The utility of the embeddings after watermark injection are comparable to the original ones, resulting in minimal performance degradation for commonly used downstream tasks; (3) Security of watermark: The watermark demonstrates security and robustness, enabling it to defend against potential attacks like SPA. Specifically, SAW injects predefined single watermark vector $w_m$, into the embeddings through a watermark injection model. The presence of $w_m$ in the embeddings is then verified using a watermark verification model. The framework of injection and verification models is trained in an end-to-end manner. SAW injects the watermark based on text semantics, enabling it to resist SPA, which is not achievable in previous schemes. Additionally, SAW can be deployed as a plug-in extension module compatible with various EaaS services."}, {"title": "5.1. Encoder", "content": "To ensure that the watermark injected in embeddings has ability to counter SPA, SAW trains an encoder as the watermark injection model to inject $w_m$, in the text embeddings. The encoder is capable of injecting the watermark in different patterns based on semantic features of the corresponding embeddings. The watermark $w_m$, is predefined by the EaaS service provider, typically in the form of a numerical vector. $w_m$ can be generated randomly. The EaaS service provider can choose to utilize mid-frequency tokens as triggers, injecting the watermark only in the partial embeddings corresponding to the texts containing triggers. Alternatively, the watermark can be injected across the entire embedding set. In the encoder's end-to-end training process, the original embedding $e_o$ is taken as input, and the watermark-injected output is $e_{enc}$. The training objective is to make $e_o$ and $e_{enc}$ as similar as possible. The loss function for the encoder is defined as\n$Loss_{enc} = \\frac{||e_o - e_{enc}||}{len(e_o)}$,\n(6)\nThe $e_{enc}$ differs minimally from $e_o$, thereby preserving the performance of embeddings in downstream tasks. Our encoder model consists of only several fully connected layers or an auto-encoder. Despite its simplicity, the encoder can determine how to apply suitable levels of numerical variation to different positions in the vector $e_o$. Ultimately, all numerical variation added to $e_o$, enable the watermark verification model to decode and verify the predefined $w_m$."}, {"title": "5.2. Decoder", "content": "SAW trains a decoder to extract $w_m$ from $e_{enc}$. During the end-to-end training process, the decoder takes $e_{enc}$ as input and outputs the decoded watermark $w_{mdec}$. The decoder must satisfy two basic conditions: (1) It should successfully decode $w_m$ from $e_{enc}$ with minimal distortion; (2) Given $e_o$ not containing $w_m$, the decoder should not be able to decode the watermark, rather producing a random vector of the same length as $w_m$ instead. So our scheme adopts a randomized strategy by initializing the decoder parameters randomly and not updating the decoder's gradients during training. The training objective for the decoder is to make $w_{mdec}$ as close as possible to $w_m$. The corresponding loss function for the decoder is defined as\n$Loss_{dec} = \\frac{||w_m - w_{mdec}||}{len(w_m)}$,\n(7)\nAll training occurs within the encoder, with the objective of training the encoder to inject suitable numerical variation into $e_o$. The final injected watermark is desired be mapped by the decoder to output the predefined $w_m$. Due to the random initialization and fixed parameters of the decoder, decoder will naturally output a random vector if $e_o$ does not contain $w_m$. It is crucial that the decoder parameters remain randomly initialized and not updated during training. If the decoder's parameters are not fixed and optimized towards a random vector as the target when providing $e_o$ as input. The randomness of each training target would introduce uncertainty into training process. It would ultimately prevent effective convergence of the model. The decoder with fixed random parameters will inherently output a random vector when given embeddings without watermark. Our decoder model consists of only several fully connected layers. Even with this simplicity, it successfully meets the two basic conditions outlined above. We will elaborate further on the significance of random initialization in Section 6.4."}, {"title": "5.3. End to End Training", "content": "SAW employs an end-to-end training strategy. It is essential because the training objectives for the Encoder are: (1) to make $e_o$ as similar as possible to $e_{enc}$; and (2) to make $w_m$ as similar as possible to $w_{mdec}$. Therefore, an end-to-end approach is necessary for training, with the complete loss function during training defined as\n$Loss = \\alpha \\cdot \\frac{||e_o - e_{enc}||}{len(e_o)} + \\beta \\cdot \\frac{||w_m - w_{mdec}||}{len(w_m)}$,\n(8)\nwhere $\\alpha$ and $\\beta$ are hyperparameters of loss functions in different parts. SAW updates the gradients only for the encoder parameters, while the decoder parameters are randomly initialized and remain fixed without updates. The security of the watermarking scheme relies on the inaccessibility of the decoder model and $w_m$. The pair ($w_m$, Encoder) can be regarded as an encryption key and ($w_m$, Decoder) as a decryption key, implementing asymmetric encryption. Only parties with the decryption key can successfully verify the watermark. SAW injects $w_m$ based on the characteristics of different embeddings. Experiment results presented in Section 6 demonstrate that SAW is resilient to semantic perturbation and successfully conduct watermark verification."}, {"title": "6. Experiment", "content": "We adopt the previous two classic schemes (EmbMarker [14] and WARDEN [15]) for our attack experiments, using text classification tasks as the downstream tasks and text-embedding-ada-002 from OpenAI simulated as the victim model. Experiments are conducted on four datasets: Enron Spam [32], SST2 [33], MIND [34] and AG News [35].\n\u2022\nEnron Spam: The Enron Spam dataset consists of the emails collection labeled as either \"spam\" or \"non-spam\" (ham), making it a valuable resource for studying spam filtering, email classification, and Natural Language Processing (NLP) tasks.\n\u2022\nSST2: The SST2 dataset is a collection of movie reviews labeled with binary sentiment (positive or negative), commonly used for training and evaluating models in sentiment classification tasks.\n\u2022\nMIND: The MIND dataset is a large-scale dataset designed for news recommendation, aimed at advancing personalized news recommendation. It can also used for news classification tasks.\n\u2022\nAG News: The AG News dataset is a collection of news articles categorized into four topics, commonly used for text classification and NLP tasks."}, {"title": "6.2. SPA Overall Performance", "content": "Semantic Perturbation Attack aims to identify the suspicious embeddings with watermark and bypass the watermark verification in post-publication settings. We conducted a comprehensive evaluation of our proposed novel attack. The verification will be bypassed if the majority of the texts with triggers and the embeddings with watermark is deleted from the dataset. The performance of semantic perturbation is the key to the success of SPA. We utilize the primary metrics as described in Section 4.3 to evaluate the performance. k perturbations are involved for each text in dataset, with k = 10 chosen to balance the time and cost considerations.\n(1) Semantic Perturbation Performance: Using a small local model to guide the semantic perturbation for a larger model, we leverage the open-source model Sentence-BERT [31] to search for the top-k $perb$ that maximize the difference in similarity between the corresponding embeddings of the text sample $d_{c_i}$ and the perturbation text $perb$. The results from k perturbations are aggregated to form the final evaluation metric. The suffix search guidance selects the perturbation candidate pool, utilizing the WikiText Dataset as candidate.  Table 1 above presents the perturbation metrics obtained, which demonstrates the high quality of the perturbation suffixes. The results demonstrate that our guidance approach is effective and has the ability to get the suffixes that can cause significant semantic perturbation. Consequently, the semantic perturbation should be capable of successfully attacking all schemes using fixed linear transformation that are unaware of text semantics. Additionally, the PCA score metric is better than cosine similarity and L2 distance and doesn't decrease in different schemes. This is because the PCA algorithm preserves the main information in the embeddings while eliminating redundant information, thus maintaining good performance across different schemes. We believe that other dimensionality reduction algorithms can achieve similar results. Our approach is effective with searching a dataset of size $10^6$ in ten minutes.\n(2) Selection and Deletion Rate: After obtaining the metric values from the semantic perturbation, SPA continue to select and delete the suspicious samples from the original dataset $D_c$ using the methods outlined in Section 4.4. However, the identical text $d_i$ in $(d_{c_i}, d_{c_i} + perb)$ results in a certain extent inherent similarity between $(e_{c_i}, e'_i)$. With the PCA AUPRC above 0.95, it remains a tiny overlap in the distributions of benign and backdoor samples. We believe that the larger perturbation pool has the capability to further separate the two distributions. Considering the samples with triggers as the positive class, the deletion precision shown in  Table 1 specifically illustrates the quantity of samples with triggers removed based on the selection and deletion method with PCA Score Metric. Additionally, the percentage of backdoor samples removed from the total is provided under the disclosure of the ground truth. The experiment results demonstrate that backdoor samples with triggers constitute the vast majority of the deleted portion. A tiny proportion of benign samples being mistakenly deleted is considered acceptable. The successful watermark verification cannot be achieved if the watermark no longer exists in the original dataset. Totally, almost 95% -100% of the embeddings with watermark can be identified, meaning that nearly all of text samples with triggers can be deleted from original dataset."}, {"title": "6.3. SAW Overall Performance", "content": "The experiment results from Section 6.2 demonstrate that the current watermarking schemes are unable to counter SPA, with above 95% of the embeddings with watermark being successfully identified. Thus, we focus on the performance of the Semantic Aware Watermarking (SAW) scheme against SPA. As in SAW, the watermark injection model can introduce an appropriate degree of numerical variation at suitable positions within the embeddings. The watermark can be successfully decoded, combining all the numerical variation through the verification model. Adaptive injection patterns enhance the security and stealthiness of the watermark. As expected, the decline in SPA success rate is closely related to the reduction in semantic perturbation performance. In this section, we will provide a comprehensive analysis of the resistance to SPA, watermark verification and downstream task performance with SAW.\n(1) SAW against SPA: The key content of SPA relies on the semantic perturbation performance. It is hard to identify suspicious samples based on the perturbation metrics if the performance of perturbation is greatly reduced, thereby preventing any bypass of watermark verification. In SAW, the performance of semantic perturbation are significantly impacted. Relying on the watermark injection capabilities learned by the encoder, the results for the perturbation metrics across different datasets are presented in  Table 2. The method is no longer a fixed linear transformation but rather an injection determined autonomously by the encoder, considering the text semantic features. The most significant metric (PCA AUPRC) decreases from close to 0.40, causing only part of the embeddings with watermark can be successfully identified in selection and deletion phase. Accordingly, the distribution of the samples containing triggers largely overlaps with the distribution of benign samples as shown in Figure 8, comparing with the previous schemes. When using SAW, even in the presence of SPA attack, the original dataset can still contain a large number of samples with triggers, making it impossible to bypass watermark verification. All of the results demonstrate that SAW is able to resist SPA.\n(2) Semantic Aware Watermarking Verification: SAW effectively defends against SPA, showing that the watermark injected by the encoder is more stealth than previous works. Thus, watermark verification process is also important. We randomly initialize the predefined watermark vector as a binary vector within the range of [0, 1]. Employing binary vectors provides a more intuitive representation of the differences between the decoded watermark from the verification model and the original watermark vector than the float numeric values. SAW can also use the average bit error to verify the watermark if all values of the decoded vector are merged to 0.0 or 1.0.  Under our experimental conditions, the length of 24 for the original watermark vector achieves the optimal trade-off.  The vector decoded from text embeddings with watermark will be more similar with predefined vector. We use the average ACos, AL2 and the p-value of Kolmogorov-Smirnov."}, {"title": "6.4. Ablation Study & Discussion", "content": "Finding 1: PCA Score Metric demonstrates superior robustness compared to other metrics. The experiment results in  Table 1 reveal that only the PCA Score Metric remains virtually unchanged as an attack metric in different schemes. In contrast", "14": "but are significantly impacted in WARDEN [15", "2": "SPA enhances attacker's ability in EaaS services. EaaS services are susceptible to various forms of copyright infringement", "12": ".", "36": "emphasize that the effectiveness of backdoor depends on various training configurations", "3": "Random decoder's parameters with no gradient update are effective. The encoder serves as the watermark injection model in SAW, while the decoder is responsible for watermark verification. During end-to-end training process, the decoder's random parameters are fixed and do not conduct gradient updates. The decoder should decode the correct vector from the embeddings with watermark and output random vectors from those without watermark. By fixing the random parameters, the decoder is inherently capable of generating the random vectors. SAW requires only the training of the"}]}