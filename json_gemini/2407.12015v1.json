{"title": "The Great Al Witch Hunt: Reviewers' Perception and (Mis)Conception of Generative Al in Research Writing", "authors": ["HILDA HADAN", "DERRICK M. WANG", "REZA HADI MOGAVI", "JOSEPH TU", "LEAH ZHANG-KENNEDY", "LENNART E. NACKE"], "abstract": "Generative AI (GenAI) use in research writing is growing fast. However, it is unclear how peer reviewers recognize or misjudge AI-augmented manuscripts. To investigate the impact of Al-augmented writing on peer reviews, we conducted a snippet-based online survey with 17 peer reviewers from top-tier HCI conferences. Our findings indicate that while Al-augmented writing improves readability, language diversity, and informativeness, it often lacks research details and reflective insights from authors. Reviewers consistently struggled to distinguish between human and AI-augmented writing but their judgements remained consistent. They noted the loss of a \"human touch\" and subjective expressions in Al-augmented writing. Based on our findings, we advocate for reviewer guidelines that promote impartial evaluations of submissions, regardless of any personal biases towards GenAI. The quality of the research itself should remain a priority in reviews, regardless of any preconceived notions about the tools used to create it. We emphasize that researchers must maintain their authorship and control over the writing process, even when using GenAI's assistance.", "sections": [{"title": "1 INTRODUCTION", "content": "The emergence of generative artificial intelligence (GenAI) tools such as ChatGPT\u00b9 and Gemini\u00b2 have sparked a wave of excitement in academia and industry. Since the release of ChatGPT in November 2022 [61], GenAI has become increasingly popular in assisting people with written, auditory, and visual tasks [45, 58, 78]. In research, GenAI offers a new approach to manuscript writing, as it can handle tasks ranging from text improvement suggestions to speech-to-text translation and even crafting initial drafts [45, 52]. Its ability to understand context and generate human-like and grammatically accurate responses fosters innovative brainstorming and enhances the quality and readability of research publications [5]. However, along with GenAI's potential to augment research activities, concerns about transparency, academic integrity, and the urgency of maintaining the credibility of research work have emerged [21, 54, 73, 78].\nDespite the growing interest in using GenAI for manuscript writing and research activities [45, 64], many researchers hesitate to acknowledge its use in their papers. This is illustrated by several instances where research publications with undisclosed GenAI use were identified by readers (e.g., [53, 71, 72, 79]). Studies have identified the phenomenon of Al aversion, where Al-generated content, even if factual, is often perceived as inaccurate and misleading [12, 56] and disclosing its use can negatively impact readers' satisfaction and perception of the authors' qualifications and effort [69]. Therefore, researchers' hesitancy is partly due to their fear that acknowledging GenAI use might damage"}, {"title": "2 BACKGROUND AND RELATED WORK", "content": "In this section, we summarize the technical evolution of GenAI as a manuscript writing assistant and the emerging perceptions and concerns within the academic community. In the end, we illustrate how our research addresses these concerns and promotes the ethical, transparent, and effective use of GenAI to support future researchers."}, {"title": "2.1 Generative Al as a Writing Assistant", "content": "Manuscript writing is crucial for researchers to share their ideas and contribute to their fields. However, writing high- quality research papers is challenging due to the need to simplify complex findings while ensuring accuracy, logical flow, and adequate evidence [35]. Beginners and non-native English speakers often struggle with using proper terminology and literature references [35, 39, 51]. In addition, manuscript writing often competes with other responsibilities like teaching and supervising [22], making efficiency and time management vital. The pressure of \"publish or perish\" mindset [22] further intensifies these challenges. GenAI thus become valuable in research writing to ease researchers' burden on writing and help them keep their focus on the innovative and critical aspects of their research.\nWith the rise of Large Language Models (LLM), GenAI's potential to transform manuscript writing has garnered significant interest [10, 45, 78]. Traditional writing assistants offer word and sentence corrections, synonym suggestions, and sentence completion predictions [3, 14, 68]. In contrast, GenAI offers a broader array of functionalities to ensure high-quality writing across diverse research disciplines, such as inspiring new ideas [49, 74], enhancing readability [5], and assisting with narrative construction and creative writing [49, 75, 84]. However, GenAI has the limitation of generating factually incorrect information, known as hallucination [1, 42]. For example, researchers have reported encountering fake references from GenAI [20]. In addition, GenAI can be opinionated, which influence researchers' perspectives and attitudes conveyed in the writing and compromise research integrity [41]. Therefore, while GenAI holds benefits for manuscript writing, its use requires researchers' careful consideration to avoid the risks.\nThese problems highlight the importance of transparently disclosing the use of GenAI. Such disclosure enables reviewers and readers to critically evaluate the research, be aware of potential biases or inaccuracies introduced by GenAI. Our study investigates reviewers' perceptions and misconceptions, reduces current concerns and hesitations among researchers, encourages researchers to openly disclose their GenAI use, and fosters a more transparent and accountable research environment."}, {"title": "2.2 Perceptions of Generative Al in Research Community", "content": "A central debate in the research community regarding GenAI involves authorship and content attribution [21]. Research manuscripts reflect the knowledge, expertise, and contributions of its author researchers [77]. The use of GenAI in manuscript writing has raised questions about how to acknowledge its involvement, as crediting it as a co-author is inappropriate because \u201cAI tools cannot meet the requirements for authorship as they cannot take responsibility for the submitted work\" [21, para. 2]. GenAI also cannot be accountable for the content it produces [20, 21]. Beyond authorship, ethical concerns arise, such as copyright infringement from using third-party materials, possible conflicts of interest, and plagiarism issues that replicate contents and images, ideas, and methods from already published works [20, 57]. In 2023, the Committee on Publication Ethics (COPE) recommended that authors explicitly disclose the use of AI-assisted technologies, including LLMs like ChatGPT, in their work [21]. Following COPE's lead, the Association for Computing Machinery (ACM) established policies on GenAI, stating \u201cthe use of generative AI tools and technologies to create content is permitted but must be fully disclosed\" [4]. Following these, efforts are made to develop comprehensive reporting guidelines for evaluating the impact of tools like ChatGPT on scientific research writing, as seen in initiatives by Elsevier [28] and the World Association of Medical Editors [83]. These guidelines aim to promote transparency by providing a framework for declaring the use of GenAI in research.\nScholarly work revealed two opposing perceptions of AI-generated content: algorithm aversion and algorithmic appreciation. Algorithm aversion is a negative bias towards AI-generated content, even when the AI output is objectively better than human-produced content [12, 38]. For example, people tend to rate AI-written content as inaccurate regardless of its truthfulness [56]. In addition, informing users about Al involvement can harm the creator-reader relationship rather than facilitate content judgment [69]. This bias worsens after seeing AI makes mistakes [23]. On the other hand, algorithmic appreciation refers to when people are more willing to adhere advice from an algorithm over a human [55], and find AI-created articles more credible with higher journalistic expertise [34].\nManuscript writing involves various decisions about word choice and sentence structure to effectively convey authors' meaning and purpose, with each word representing a decision made by the authors [46]. With GenAI, many of these decisions are delegated to AI, which relies on highly probable options, pre-defined rules, large databases, or specific text corpora [46]. This delegation can reduce human authors' sense of ownership [24, 49], which may potentially lead to irresponsible assertions in research papers. Therefore, regulating the extent of GenAI assistance is crucial for maintaining the accountability and credibility of research publications. Our research aims to encourage transparency in disclosing GenAI use, which is the foundational step for responsible AI augmentation in research manuscript writing."}, {"title": "2.3 Connection to Our Research", "content": "While guidelines exist to guide researchers and promote transparency in research community, many researchers are hesitant to acknowledge their use of GenAI in their manuscripts (e.g., [53, 71, 72, 79]). Although previous studies have examined human ability to detect AI-generated content (e.g., [33, 48, 70]), these studies were not conducted in the context of research publications and were not conducted with participants with experience reviewing academic manuscripts in peer-reviewed venues. Therefore, their findings offer limited insight into the specific issue of GenAI use in research manuscript writing. Our study addresses this gap by investigating experienced reviewers' perceptions and misconceptions on manuscripts due to GenAI use. Through this investigation, we aim to reduce researchers' concerns about negatively impacting reviewers' perceptions and judgments, and encourage them to openly acknowledge their use of GenAI in future manuscripts. Given the increasing adoption of GenAI in research writing and the ethical needs"}, {"title": "3 METHODOLOGY", "content": "To investigate reviewers' perceptions of GenAI use in research writing, we employed a text snippet-based online survey. After obtaining Research Ethics Board approval [details omitted for blind review], we recruited 17 participants who have experience reviewing manuscripts for publication at top-tier HCI conferences, including CHI\u00b3 and CSCW4. We refer to our participants as \"reviewers\" in the following sections. Reviewers were presented with six snippets tailored to their areas of expertise in HCI, chosen from 16 example human-written abstracts and 32 GenAI-augmented snippets. The six snippets were presented in a randomized sequence. This approach allowed us to explore reviewers' perception on a wide range of topics with different levels of GenAI use without overwhelming them with a long survey. In this section, we describe our snippet design, survey development, participant recruitment, and data analysis procedure."}, {"title": "3.1 Study Material Construction", "content": "In research paper writing, GenAI is used in various ways from recommending texts, perform spelling or grammar corrections, to generating entire sections [4]. To comprehensively evaluate reviewers' perception, we present each participant with three types of snippets (Content_Type):\n(1) original: snippets written entirely by human authors.\n(2) paraphrased: snippets rephrased with a GenAI by rewriting human-written text while preserving its original meaning.\n(3) generated: snippets generated entirely with a GenAI by using human-written text as reference to ensure relevance to the original manuscript.\nIn this section, we discuss the selection of original human-written snippets, and the production of paraphrased and generated snippets using GenAI prompts."}, {"title": "3.1.1 Original Snippets", "content": "To ensure the comprehensive coverage of our original snippets, we selected abstracts from example papers from submission topics of CHI 2023 conference 5, the premier venue for HCI research. For each topic, we selected the most-cited paper published before the prevalent use of GenAI in November 2022 to ensure it was written by human researchers. When multiple papers had the same citation numbers, we subsequentially selected papers based on download counts and the most recent publication date. This process resulted in a total of 16 abstracts as our original snippets. Details of these source papers are in Appendix C.\nWe chose to use abstracts due to three considerations. First, abstracts are crucial for research manuscripts as they comprehensively summarize the papers' significance, research goals, methodology, findings, and contributions [8]. Second, in early stage of a peer-review process, abstracts guide editors and reviewers in efficiently evaluating a manuscript [8]. Third, since we recruit experienced reviewers who are academia and industry professionals, using abstracts ensures our study is manageable and not overly time-consuming while still offering sufficient information for evaluating participants' perceptions."}, {"title": "3.1.2 Paraphrased and Generated Snippets", "content": "The selected original snippets were then processed through GenAI-Google Gemini-to create the corresponding paraphrased and generated snippets. We chose Gemini for its ability to provide comprehensive summaries, valuable suggestions, and rationales, as well as its transparency in disclosing limitations rather than fabricating content, which distinguish it from other GenAI tools such as ChatGPT [78].\nBuilding upon literature on constructing GenAI prompts [59] and discussions with our research team of GenAI researchers and enthusiasts, we incorporated four components in our construction of the prompts for snippets processing:\n(1) Goal: the goal of the prompt. For producing paraphrased snippets, we set the goal as \"rephrase\" the original snippet; For producing generated snippets, we set the goal as \"improve\" the paraphrased snippet to allow GenAI to maximize its creativity while ensuring the content consistency.\n(2) Step-by-step instruction: the detailed instruction that specifies expected GenAI behaviour step-by-step. For producing paraphrased snippets, we provided a guide based on best practices of abstract writing [8]. For producing generated snippets, we used two sequential prompts that guide GenAI to first generate a new snippet based on the paraphrased snippet and the introduction section of the paper, then refine its contribution statements based on the manuscript's conclusion section.\n(3) Context: the context information that facilitates the GenAI behaviours. For producing paraphrased snippets, the original snippet served as the context. For producing generated snippets, the paraphrased snippet and the corresponding manuscript's introduction and conclusion sections were used.\n(4) Constraints: to ensure consistency in length, we set a 150-word constraint for both paraphrased and generated snippets based on typical CHI submissions.\nResearchers in our team reviewed the snippets to ensure consistency in content and length across the three con- tent_types. Figure 1 and Figure 2 illustrate the prompt structure, and Appendix D provides examples of the snippet production process in Gemini. This approach ensures that the snippets derived from the same abstract maintain"}, {"title": "3.2 Survey Design", "content": "In this section, we provide a detailed description of our survey design. Figure 3 summarizes the survey flow. A complete set of questions is included in Appendix E.\n3.2.1 Screening Questionnaire. The survey began with a study information sheet and consent form, followed by a screening questionnaire. Our screening targeted participants who have experience serving as reviewers in peer-reviewed HCI conferences. Participants had to be at least 18 years old, have previous experience as a reviewer or associate chair, and have encountered or suspected the undisclosed use of GenAI in submissions they reviewed.\n3.2.2 Instruction and Presentation of Snippets. To ensure reviewers' perceptions were related to their experience with GenAI, not conventional writing assistants, we first provided a description of GenAI 's functionality: \"Al writing assistants can help researchers by suggesting phrasing, structuring sentences, and even generating initial drafts.\" Reviewers then selected two research topics from the 16 CHI'23 topics (see Q1 & Q2 in Appendix E)-one in which they were most knowledgeable and one in which they had the least knowledge. From each topic, we presented the original, Al-paraphrased, and AI-generated snippets from an example paper (as described in subsubsection 3.1.1). This approach allowed us to compare reviewers' perceptions and judgements varied between content_types, and investigate how their expertise influenced their perceptions. To avoid biasing reviewers, we did not disclose the content_type of each snippet. We described the six snippets as could be human-written or AI-processed without confirming AI or human authorship. The three snippets from the same abstract were presented in random order. Since the snippets were from published papers, we included a bold red text instructing reviewers not to search for the snippets in literature databases.\n3.2.3 Perceptions of the Snippets and the Research Presented. For each snippet, reviewers were asked to provide a more detailed rating of their expertise in the topic, using a scale from 0-no knowledge or expertise in this field to 10-I am an expert in this field. We coded these responses as disciplinary_expertise in our statistical analysis. This question served three purposes. First, it clarified what \"the most\u201d and \u201cthe least\" knowledgeable meant by each reviewer. Second, it captured cases when reviewers misidentify that a paraphrased or generated snippet is from a completely different"}, {"title": "3.3 Participants Recruitment and Demographics", "content": "Before distributing the survey, we piloted the questionnaire with five PhD students with peer-review experience and refined the language and question structure based on their feedback to improve clarity, comprehension, and conciseness. A prior power analysis [30, 31] for a within-subject Wilcoxon-signed rank test determined that a sample size of N = 15 was needed, with an effect size=0.8, a power=0.8, and a margin for random error\u2264 5%. Following ethics approval, we recruited participants using a snowball sampling method in April and May 2024. Our research team reached out to CHI and CSCW conference committees for participation and assistance in distributing recruitment materials. This recruitment method was used due to the difficulty in recruiting reviewers, even in real peer-review process [37]. We closed the survey on May 7, 2024, one month after receiving the last response, resulting in a total of 41 responses. Of"}, {"title": "3.4 Data Analysis", "content": "We present our quantitative data analysis and corresponding results in section 4. For the qualitative open-ended question, we conducted an inductive thematic analysis with two researchers, following the established guideline by Clarke et al. [18]. We reviewed the data to familiarize ourselves and ensure it contained no blank or incoherent responses to each question. We retained \"N/A\" responses, which represent an inability to differentiate human-written snippet from GenAI output. The two researchers independently coded 15% (n=16) of the total responses (N=102). We did not calculate inter-coder reliability, as it \"prioritises uniformity over depth of insights\" and often results in superficial themes, especially for studies with more than 20 codes (like ours) [18, p. 303]. Instead, the two researchers discussed and resolved conflicts in a meeting, and created an initial codebook. This process was repeated twice, with each meeting addressing half of the remaining data until the codebook was finalized and all data were coded. This finalized codebook served as a foundation for developing and refining the themes from our data. We present our codebook and themes in Appendix A."}, {"title": "4 FINDINGS", "content": "4.1 RQ1: How Much Are Reviewers Aware of the Use of Al in the Context of Research Writing?\nTable 2 shows the response distribution among the N = 17 reviewers regarding their perceived_AI_involvement across the three content_types. Both original human written snippets and AI-generated snippets received a median=5, with a mean=4.44 (SD=3.13) and mean=5.12 (SD=3.18), respectively. This result indicates that reviewers generally believed GenAI was similarly involved in both human-written and AI-generated snippets. This similarity revealed a general misconception about GenAI use in snippets and suggested the difficulty in differentiating between AI-generated and human-written snippets among reviewers. Compared to these, the rating for AI-paraphrased snippets is notably lower (median=2, mean=2.74, SD=2.61).\nTo validate the observed differences in reviewers' perceptions, we performed a Friedman test [32] and confirmed significant within-subject differences across the three types of snippets ($\\chi^2$ = 6.92, df = 2,P = 0.03). We further conducted post-hoc pairwise Wilcoxon comparisons [82] with Bonferroni correction [15] (see Table 2). The result shows that, compared to AI-generated snippets, reviewers perceived significantly lower AI involvement in AI-paraphrased snippets (W = 92, P = 0.01, r = -0.60). there was no significant difference in reviewers' perceptions between AI- generated and human-written snippets (W = 80, P = 0.55). Additionally, no significant difference was found between reviewers' perceptions of human-written and AI-paraphrased snippets (W = 26.5, P = 0.06). The validity of these results are further supported by our reviewers' qualitative responses, with several of them indicated they were confused about which snippets were AI- or human-written.\n4.2 RQ2: How Much Is Reviewers' Judgement of Research and Manuscript Influenced by the Use of Al in Its Writing?\nTable 3 presents the distribution of reviewers' judgments across the three content_types. The result shows that reviewers' responses were mainly neutral (mean = 3.29, SD = 1.12 mean = 3.82, SD = 0.80), and there is no sizeable differences between reviewers' perception on the accuracy, reliability, honesty, clarity, and compellingness.\nTo further validate our observations, we conducted a Friedman test [32] and found no significant within-subject differences in reviewers' perception across the three content_types. We suspect that this result is because our reviewers neither exhibited algorithmic aversion nor appreciation, but had neutral opinion towards GenAI. To validate this, we conducted a within-subject Wilcoxon signed-rank analysis [82] with Bonferroni correction [15] to compare reviewers'"}, {"title": "4.3 RQ3: To What Extent Do Reviewers' Peer-Review Experience, Disciplinary Expertise, and Al Familiarity Influence Their Perception and Judgement?", "content": "In this section, we evaluate how factors including content_type, reviewers' disciplinary_expertise, AI_familiarity and peer-reviewer_experience influence their perceived_AI_involvement and judgements on the manuscript and presented research. We used Cumulative Link Mixed Model (CLMM) regression and included participant identifiers as random effects. CLMM is well-suited for repeated measures experiments with ordinal dependent variables, as in our study where reviewers were presented with multiple snippets in parallel [17]. We conducted a series of Multivariate CLMM regressions, using reviewers' perceived_AI_involvement, perceived_accuracy, perceived_reliability, per- ceived_honesty, perceived_clarity, and perceived_ compellingness as the dependent variable (DV) and the factors as the predictors. Table 4 shows the final models with predictors ranked by their contribution to the DV, determined by the global minimum Akaike Information Criterion (AIC) [43] values obtained upon adding each predictor. Predictors with the highest contribution (lowest AIC) are ranked first.\nAs shown in Table 4, the results revealed relationships between reviewers' perceived_AI_involvement and the predictors content_type and AI_familiarity, with content_type had the greatest contribution. Specifically, reviewers perceived significantly lower AI involvement in AI-paraphrased snippets compared to original human-written snippets. This result extends our within-subject comparison in subsection 4.1. In addition, reviewers who rarely used Al in their"}, {"title": "4.4 RQ4: What Aspects of Research Writing Impact Reviewers' Perception and Judgement?", "content": "In this section, we discuss the themes derived from reviewers' qualitative responses (see Figure 4). For clarity, thematic analysis themes are in italics, and reviewers' quotes are in italicized quotations. The survey question is detailed in Appendix E (Q9). We discuss how these themes are related to our quantitative findings in section 5.\n4.4.1 Theme 1: Writing and Sentence Structure. The primary concern among the responses (27%) was that Al-generated snippets often suffer from incoherent logic and phrasing, with illogical transitions, unclear flow, and misuse of field- specific terminologies. In contrast, 12% of responses noted that human produces neatly edited sentences, and 2% mentioned that experienced researchers know how to structure sentences effectively (trained researchers know the writing structure). Moreover, 1% highlighted that humans tend to write in a consistent style (human write in consistent style). These responses expressed reviewers' belief that AI cannot replicate the natural flow and logical progression achieved by human writers through careful and critical thinking and appropriate sentence transitions.\nConversely, 7% of responses indicated that AI produces well-structured sentences (Al structure sentences better than human). Responses also noted that AI often uses conclusive statements at the end (2%), and follows an exact template (1%), and frequently uses transitional/bridged clauses in sentences (1%). In contrast, 3% of responses mentioned that inexperienced human researchers often make mistakes and fail to produce well-structured sentences (Inexperienced human writing mistakes).\nAnother interesting contradiction emerged regarding sentence length. While 13% of responses indicated that AI- generated snippets tended to have convoluted and long sentences, 3% held the opposing view and attributed convoluted and long sentences to human writers. Additionally, 1 (1%) response expressed the reviewer's concern about Al making grammar mistakes, whereas 3% indicated that snippets with grammar mistakes is more likely to be human-written (human makes grammar mistakes).\n4.4.2 Theme 2: Word Choice. Another significant factor influencing reviewers' perceptions was the presence of marker phrases and words in both human and AI-generated snippets. For instance, 26% of responses identified specific words and phrases (AI uses marker words/phrases) commonly used by AI, such as sentence starters like \"However,...\" and sentence structures like \"...., do-ing....\" In addition, terms such as \u201cleverage\u201d or \u201cstate-of-the-arts\" were seen as indicators of AI writing due to their less common usage compared to simpler alternatives. Interestingly, reviewers' perceptions of these markers were not always consistent. While 3% of responses noted that contractions, parentheses for explanations, and colons to introduce multiple concepts were unique to human-written snippet (human uses unique marker phrases/words), these markers were also mentioned in other responses as the indication of AI-generated snippets. We include a full list of marker words mentioned by reviewers in Appendix B.\nBeyond the identified marker words, reviewers also commented on broader language usage. Twenty-one percent of responses noted that AI-generated snippet often employed unusual language choices, which made the text sound awkward or unnatural (AI uses unusual language). In addition, a small portion of responses (4%) criticized AI for relying too heavily on adjectives and resulting in an overly descriptive writing style. Conversely, some responses (10%) associated plain and natural language with human authors (Human uses plain, natural language). One response"}, {"title": "4.4.3 Theme 3: Problematic Statement", "content": "Reviewers raised various concerns regarding statements in the snippets. The most common issue was that AI-generated snippets were often generic and non-specific (23%). Additionally, 11% of responses noted over-promising statements in AI-generated snippets. Concerns about factual accuracy were also raised, with two responses (2%) noted that AI-generated snippets often contain false descriptions and non-factual statements.\nInterestingly, two responses (2%) pointed out that AI often repeats content with different phrasing that merely summarizes earlier paragraphs without further elaboration. One response (1%) noted weak statements in AI-generated snippets Al produces weak statement that lacks supporting evidence or being poorly developed.\n4.4.4 Theme 4: Expression. Reviewers assessed how well the snippets conveyed human emotions, opinions, and subjective experiences. Three percent of responses indicated that human authors use evocative words and figurative language to convey personal perspectives (Human expresses personal perspectives and understanding in writing), and 4% of responses identified snippets lacking personal and subjective expressions as AI-generated (lacks personal expressions).\nIn addition, one response (1%) linked snippets strictly follow the standardized grammar rules and sentence structure with non-English-speakers (human non-English speakers follow standardized rules). Another response (1%) noted that non-native speakers might produce less fluent writing (human non-English speakers could produce less fluent writing). These contradictory perceptions can lead to inaccurate conclusions about Al involvement.\n4.4.5 Theme 5: Carefully Crafted Statement. Interestingly, 4% of responses admired the expertise in the writing of some snippets and perceived these snippets as \"the work of experienced researchers\" (Al paraphrased content appears to be written by an experienced researcher). However, these snippets were actually paraphrased using GenAI."}, {"title": "5 DISCUSSION", "content": "Our study supports the concern raised by Tu et al. [78] and extends prior research on the difficulty humans have in distinguishing between AI- and human-authored content in general contexts like news, jokes, and health information (e.g., [33, 69, 70]). We found that such an inability also applies to peer reviewers of research publications. Our qualitative analysis highlighted contradictory perceptions among reviewers, where some reviewers identified lengthy sentences, concise language, repetition, and standardized grammar as indicators of AI authorship, while others perceived these as signs of human writing. However, despite these conflicting views, reviewers' judgments of the manuscript and the presented research remained consistent.\nIn fact, unlike prior research that identified people's tendencies toward AI aversion or appreciation [19, 34, 56, 69], our study found that academia and industry professionals did not exhibit clear negative or positive opinions about the manuscript and its presented research across the three types of snippets, despite varying perceptions of AI involvement. This finding indicates that assessments of research extend beyond writing quality alone. While clarity, conciseness, and coherence are important, other factors such as novelty, methodological transparency, result validity, and contribution to the field also significantly influence reviewers' judgments [76]. Thus, our results suggest that when these aspects are well-addressed, the use of GenAI in writing does not necessarily bias reviewers' evaluations.\nFurthermore, our regression analysis indicated that reviewers perceived less AI involvement and higher honesty in AI-paraphrased snippets. Reviewers with greater disciplinary expertise and AI familiarity rated higher levels of honesty, clarity, and compellingness across all snippet types. This result contrasts with previous studies on non-research writing contexts, where experts found algorithmic advice less trustworthy [80] and those familiar with the algorithm were less receptive to its suggestions [55]. Our qualitative results further showed that reviewers appreciated GenAI's ability to produce well-structured and clear snippets. This perception suggests that GenAI can be a valuable for enhancing the presentation of their research through writing. However, reviewers found AI-augmented snippets lacking in logical progression, supporting evidence for statements, and emphasis on key research points. These issues highlight the limitations of GenAI in areas requiring critical thinking, logical reasoning, and nuanced understanding of the research field. Conversely, reviewers noted that human researchers are good at providing detailed evidence and explanation, and strategically emphasizing key points within the manuscript's logical flow. Given that increased human involvement in Al-generated content fosters greater ownership and responsibility [24, 65], we thus recommend a human-in-the-loop approach to AI-assisted writing to ensure logical, clear, and accurate research manuscripts.\nOverall, our study suggests that while AI can be a valuable in enhancing research communication by improving structure and clarity of its presentation, human researchers' oversight remains crucial to ensure a well-structured, logically sound, and informative final manuscript."}, {"title": "5.1 Implications For Researchers Who Submit to Peer-Reviewed Venues", "content": "Through the perspective of top-tier HCI conference peer-reviewers, our quantitative and qualitative analyses revealed themes that alleviate researchers' concerns about disclosing AI use in manuscript submissions. From reviewers' responses, we identify insights on the appropriate ways to augment research writing with GenAI, and demonstrate that responsible and transparent use of GenAI can enhance the quality of research presentation in writing without"}, {"title": "5.2 Implications For Peer-Reviewers Who Review Research Manuscripts", "content": "While research venues permit the use of GenAI as writing assistants, these tools must be accompanied by human author oversight and verification [28]. As demonstrated in Figure 4, our study revealed that reviewers identified similar issues in both AI- and human-written snippets, such as redundant sentences, overly generic statements, and marker phrases (see Appendix B). Thus, these problems are common in both human-written and AI-augmented manuscripts and cannot be used as reliable evidence of AI involvement. Despite the availability of algorithm-based AI detectors, literature shows these tools often penalize individuals with limited linguistic proficiency [51], which directly contradicts our reviewers' perception that AI-generated snippets uses \"flowery\" language. This contradiction highlights that neither existing AI-detectors nor reviewers' personal strategies are reliable in detecting GenAI. Given our findings, we strongly"}, {"title": "5.3 Future Enforcement of Ethical Use of GenAl in Research Writing", "content": "Our study sheds light on the complexities of regulating and enforcing ethical GenAI use in research writing. Our findings revealed the unreliability of strategies that human reviewers use to distinguish between Al and human authorship. Together with the unreliable result from existing GPT detectors Liang et al. [51], we highlight that current human and algorithm-based methods for identifying Al-generated content can increase biases and inequities in academic publishing. We argue that AI-detecting tools, in their current state, should be used cautiously and only as supplementary information, not as definitive evidence of Al involvement in manuscript writing. The primary focus should remain on human reviewers' critical assessments of research quality and contribution. Concurrently, we recommend that academic institutions and publishing venues invest in educating reviewers about the capabilities and limitations of GenAI, as well as the potential biases in both human and algorithmic detection methods. This education should emphasize the importance of evaluating manuscripts based on their scientific merit, regardless of perceived Al involvement. A more nuanced understanding of GenAI among reviewers promotes fairer evaluations of research manuscripts and maintains the integrity of the peer-review process in the continuously evolving GenAI space.\nSeveral reviewers expressed their concern in the end-survey comments about the pressure in academia to produce numerous papers quickly for job security and career progression. This demand leads researchers to prioritize short,"}, {"title": "5.4 Limitations and Opportunities for Future Research", "content": "Our study has limitations that offer several opportunities for future research. First, our primary limitation is its sample size. While our mixed-methods approach gave deep and rich insights, the small number of participants limits the precision of our quantitative estimates. This constraint reflects the challenges in recruiting professional peer reviewers [37], a hurdle likely to persist in future studies. Still, our findings offer early and valuable insights into how reviewers see GenAI in academic writing. Future research could explore other approaches. For example, it could analyze acceptance and rejection patterns before and after GenAI adoption. This would add to our findings, even though such data might be equally difficult to obtain. Second, our study focused on abstracts, not full papers. This approach let us examine varied AI snippets across research areas while maintaining survey manageability for professional reviewers. However, it may not fully capture reviewers' judgments of complete manuscripts. Future research should extend this investigation to full papers or more extensive snippets. This could reveal more nuanced perceptions of AI-augmented academic writing. Third, our sample's limited familiarity with AI in writing likely reflects the current reviewer population, given the ongoing controversies surrounding GenAI use in academia. As GenAI becomes more commonplace in research activities, future studies may reveal evolving perceptions among reviewers. This presents an opportunity for longitudinal research to track changes in reviewer attitudes and practices over time. Fourth, our study also suffer from common limitations of empirical research. Although we instructed reviewers not to look up the full papers in literature databases, we cannot entirely prevent this. Additionally, our data relies on self-reporting, which is subject to the reviewers' honesty and self-awareness. Our study may be subject to social desirability bias. Reviewers are potentially underreporting their own GenAI use because of perceived stigma. However, we expect that our findings will help normalize discussions about GenAI in academic writing and, in turn, encourage more open disclosure in future research. Lastly, we studied general reviewer perceptions across disciplines, with 35% of reviewers specializing in games research, likely due to our research team's majority background in this field. Future research should explore how"}, {"title": "6 CONCLUSION", "content": "Our paper presents a snippet-based online survey examining reviewers' perceptions of human-written, AI-paraphrased, and AI-generated snippets. We surveyed 17 experienced peer-reviewers from top-tier HCI conferences and found their struggle in distinguishing between AI-processed and human-written snippets but their judgments on the manuscript and the underlying research did not significantly vary. Our results indicate that responsible and transparent use of GenAI can enhance research presentation quality without negatively impacting reviewers' perceptions. Given the current unreliability of AI detection by reviewers and AI-detection tools, we advocate for reviewer guidelines that promote impartial evaluations of submissions, regardless of any personal biases towards GenAI"}]}