{"title": "LLMs generate structurally realistic social networks\nbut overestimate political homophily", "authors": ["Serina Chang", "Alicja Chaszczewicz", "Emma Wang", "Maya Josifovska", "Emma Pierson", "Jure Leskovec"], "abstract": "Generating social networks is essential for\nmany applications, such as epidemic model-\ning and social simulations. Prior approaches\neither involve deep learning models, which re-\nquire many observed networks for training, or\nstylized models, which are limited in their re-\nalism and flexibility. In contrast, LLMs of-\nfer the potential for zero-shot and flexible net-\nwork generation. However, two key questions\nare: (1) are LLM's generated networks realis-\ntic, and (2) what are risks of bias, given the\nimportance of demographics in forming social\nties? To answer these questions, we develop\nthree prompting methods for network gener-\nation and compare the generated networks to\nreal social networks. We find that more realis-\ntic networks are generated with \"local\" meth-\nods, where the LLM constructs relations for\none persona at a time, compared to \"global\"\nmethods that construct the entire network at\nonce. We also find that the generated networks\nmatch real networks on many characteristics,\nincluding density, clustering, community struc-\nture, and degree. However, we find that LLMS\nemphasize political homophily over all other\ntypes of homophily and overestimate political\nhomophily relative to real-world measures.", "sections": [{"title": "1 Introduction", "content": "The ability to generate realistic social networks is\ncrucial for many applications, when the true so-\ncial network cannot be observed (e.g., for privacy\nreasons) or a realistic network is desired between\nhypothetical individuals. For example, in epidemic\nmodeling, synthetic social networks are frequently\nused so that researchers can model the spread of\ndisease based on who has come into contact with\nwhom (Barrett et al., 2009; Block et al., 2020). Syn-\nthetic networks are also useful for simulating and\nanalyzing social media platforms (P\u00e9rez-Ros\u00e9s and\nSeb\u00e9, 2015; Sagduyu et al., 2018) and social phe-\nnomena, such as polarization and opinion dynamics\n(Dandekar et al., 2013; Das et al., 2014).\nDeep learning approaches to network generation\ntypically require training on many domain-specific\nnetworks (You et al., 2018), making it difficult to\ngeneralize to new settings where networks are not\nyet observed. Classical models for network genera-\ntion require far less training, but these stylized mod-\nels make rigid and unrealistic assumptions about\nhow networks form. For example, Erd\u0151s\u2013R\u00e9nyi\nmodels assume that each edge forms with a uniform\nprobability p (Erd\u00f6s and R\u00e9nyi, 1959). More real-\nistic models, like small-world models (Watts and\nStrogatz, 1998) or stochastic block models (Hol-\nland et al., 1983), are still limited by a predefined,\nsmall set of numerical hyperparameters, missing\nthe full complexity of real social interactions.\nIn contrast, generating social networks with large\nlanguage models (LLMs) has the potential to ad-\ndress these limitations. LLMs possess zero-shot\ncapabilities, enabling network generation without\ntraining. LLMs can also generate networks in a\nflexible manner, based on natural language descrip-\ntions of each person in the network. A key question,\nhowever, is whether LLMs can generate realistic\nsocial networks. On one hand, LLMs have demon-\nstrated capabilities to realistically simulate human\nresponses and interactions (Aher et al., 2023; Park\net al., 2023; Argyle et al., 2023), suggesting that\nthey may be able to generate realistic social net-\nworks as well. On the other hand, LLMs sometimes\nstruggle with reasoning over graphs (Wang et al.,\n2023; Fatemi et al., 2024) and it is unclear if their\nlanguage abilities generalize to structured objects\nlike networks, so that they can reproduce struc-\ntural characteristics of social networks such as low\ndensity and long-tailed degree distributions.\nFurthermore, a central concern with using LLMs\nin social settings is bias. Prior works have shown\nthat LLMs produce stereotyped descriptions of\nindividuals based on their demographics (Cheng\net al., 2023a,b) and skew towards the liberal opin-\nions (Santurkar et al., 2023). These demographics,"}, {"title": "2 Related work", "content": "Social simulation with LLMs. Prior work has\ndemonstrated LLMs' abilities to realistically simu-\nlate human responses and interactions (Aher et al.,\n2023; Park et al., 2023; Argyle et al., 2023). How-\never, while simulating interactions over networks,\nexisting work focuses less on using LLMs to gener-\nate the networks themselves, either making simplis-\ntic assumptions about the network structure such as\nsampling agents randomly to interact (Park et al.,\n2022; Chuang et al., 2023) or requiring human\ninvolvement in building the network (Gao et al.,\n2023; Zhou et al., 2024). To improve the realism\nand usability of these simulations, it is essential to\nalso explore LLMs' abilities to generate the net-\nwork structure, a prerequisite to simulating interac-\ntions over networks.\nA few contemporaneous works have explored\nLLMs for social network generation, with different\nfocuses from ours. Marzo et al. (2023) focus on de-\ngree distribution, showing that scale-free networks\nemerge from interactions between LLMs. He et al.\n(2023) focus on content homophily, analyzing a\nsimulated society powered by LLM chatbots. The\nmost similar work to ours is Papachristou and Yuan\n(2024), who analyze whether LLMs demonstrate\nnetwork formation principles, such as preferential\nattachment and homophily. While their work estab-\nlishes the existence of general network principles,\nour work compares generated networks to real so-\ncial networks directly, computing many network\nmetrics, and shows that all metrics can be matched\nat once, while their experiments primarily explore\none principle at a time, with a different prompt for\neach principle. Also, to test homophily, they con-\nsider hobby, favorite color, and location, while we\nexplore key demographic features.\nLLM social biases. Using LLMs in social con-\ntexts raises concerns of biases and stereotyping\n(Cheng et al., 2023a,b; Wang et al., 2024). When\nresponding to public opinion or political questions,\nLLMs' answers skew liberal (Santurkar et al., 2023;\nHartmann et al., 2023). When assigned a persona,\nLLMs show worse reasoning capabilities when as-\nsigned certain demographics (Gupta et al., 2024)\nand produce more toxic content under certain per-\nsonas (Deshpande et al., 2023). However, bias in\nthe context of social network generation remains\nunexplored. In this work, we investigate such bi-\nases by studying the effects of demographic vari-\nables on LLM-generated social networks."}, {"title": "3 Generating social networks", "content": "Our process for generating social networks involves\ntwo steps: first, constructing a set of personas, and\nsecond, having the LLM generate social networks\nover those personas. In this section, we summarize\nthe two steps, with details in Appendix C.\n3.1 Persona construction\nFor each persona, we include their gender, age,\nrace/ethnicity, religion, and political affiliation,\nwhich are salient dimensions of homophily in real\nsocial networks (McPherson et al., 2001; Halber-\nstam and Knight, 2016). We sample these charac-\nteristics based on the distribution of the US pop-\nulation. Using US Census data (US Census Bu-\nreau, 2023), we acquire the joint distribution for\ngender, age, and race/ethnicity. Then, we sam-\nple the persona's religion, conditioned on their\nrace/ethnicity (Statista, 2016; PRRI Staff, 2021),\nand political affiliation, conditioned on their gen-\nder and race/ethnicity (Pew Research Center, 2024;\nSanchez and Foxworth, 2022). In Section 5.3, we\nalso experiment with including interests for each\npersona, instead of only demographic variables.\n3.2 Network generation\nWe design three prompting methods for generating\nsocial networks, which we summarize in Figure 1.\nGlobal. In our first method, which we call\n\u201cGlobal\u201d, we provide the LLM with the entire list\nof personas, and prompt it to construct the network\nbetween them, in the form of edge pairs.\nLocal. In our second method, which we call \"Lo-\ncal\", we have the LLM take on the identity of\none persona at a time, e.g., by saying, \"You are\na Woman, Asian, age 54, Hindu, Independent.\" We\nprovide the LLM with the list of all other personas\n(in the same format) and prompt it to pick friends\nfor the persona it is currently assigned. To construct\nthe entire network, we iterate through all personas\nin a random order, and we keep an edge between\npersonas A and B if the LLM selects B when acting\nas A or vice versa (so we do not require both to\nselect each other). This method is inspired by tech-\nniques in machine learning that similarly model"}, {"title": "4 Comparison to real networks", "content": "To evaluate the realism of our generated networks,\nwe gather a set of real social networks from the\nCASOS and KONECT repositories. We kept net-\nworks that described social relations between indi-\nviduals, which filtered out other types of networks,\nsuch as work-related interactions or visiting ties\nbetween families. We included eight real networks,\nwhich capture social ties within diverse communi-\nties, including physicians, students, and prisoners\n(see Appendix C.3 for details).\nWe extract graph-level and node-level metrics\nfrom the real networks and our generated networks,\nand compare their distributions. For consistency,\nwe treat all networks as undirected. Since the num-\nber of nodes varies across networks, we focus on\nnetwork metrics that are comparable across graphs\nof different sizes, and scale those that are dependent\non network size based on how they are expected to\nscale in an Erd\u00f6s-R\u00e9nyi random graph (Erd\u00f6s and\nR\u00e9nyi, 1959). Below, we define and motivate the\nnetwork metrics that we evaluate on.\nDensity. A basic property of a network is its den-\nsity of edges, and social networks tend to be sparse,\nmeaning lower density (Wong et al., 2006). Den-\nsity computed as the number of observed edges\ndivided by the total number of possible edges in\nthe network, which comes out to $\\frac{2E}{N(N-1)}$, where\nN is the number of nodes and E is the number of\nedges in the network.\nAverage clustering coefficient. Social networks\nare known to exhibit clustering, where one's friends\nare likely to be friends with each other (Alizadeh,\n2017). For a node i, its clustering coefficient is\n$\\frac{2E_i}{N_i(N_i-1)}$, where Ni is its number of neighbors and\nEi is the number of edges between its neighbors.\nThe average clustering coefficient computes the\naverage over nodes.\nProportion of nodes in the largest connected\ncomponent (LCC). Social networks are known\nto be well-connected (Ugander et al., 2011), with\nthe vast majority (over 99%) of the nodes in\nthe largest connected component (LCC), i.e., the\nlargest subgraph where all nodes within the sub-\ngraph are reachable by each other. Thus, as a met-\nric, we compute the proportion of all nodes in the\nnetwork that are in the LCC, $\\frac{N_{LCC}}{N}$.\nAverage shortest path in LCC. Social networks\nare not only well-connected, meaning nodes can\nreach each other, but also they can reach each other\nin relatively short paths (Watts and Strogatz, 1998;\nAlizadeh, 2017). So, we measure the average short-\nest path over all pairs of nodes in the LCC, divided\nby log NLCC, since shortest paths scale with log N\nin Erd\u00f6s-R\u00e9nyi graphs (Watts and Strogatz, 1998).\nWe compute shortest paths within the LCC instead\nof the entire network, since the distance between\ntwo disconnected nodes is infinite.\nCommunity structure. Social networks exhibit\nstrong community structure, with more edges\nwithin communities and fewer edges across com-\nmunities (Newman, 2004). To measure community\nstructure, first we use the Louvain algorithm (Blon-\ndel et al., 2008) to partition the network into com-\nmunities, then we assess the quality of the partition\nwith modularity (Eq. 3). Higher levels of commu-\nnity structure correspond to higher modularity.\nDegree distribution. Social networks are said\nto follow a power law degree distribution, where\nP(k) ~ k\u03b3, for degree k and constant \u03b3 (Barab\u00e1si\nand Albert, 1999). This results in long-tailed de-\ngree distributions with a few people having far\nmore friends than most others. To measure degree\ndistribution, we compute the degree of each node\nin the network, and to make degree comparable"}, {"title": "5 Results", "content": "Experimental set-up. We experiment with the\nfollowing LLMs: OpenAI's GPT-3.5 Turbo and\nGPT-40 (Brown et al., 2020; OpenAI et al., 2023),\nMeta's Llama 3.1 (8B and 70B) (Touvron et al.,\n2023), and Google's Gemma 2 (9B and 27B)\n(Gemma Team et al., 2024), representing a range\nof models across companies and sizes. We find\nthat GPT-3.5 Turbo performs the best at matching\nthe real social networks, so we report results from\nGPT-3.5 Turbo in the main text, but we report re-\nsults from all models in Appendix A. We show that\nour main results about political homophily being\nmost emphasized and overestimated hold for all\nsix models. We also include sensitivity analyses,\nwith different temperatures (Figure 13) and minor\nchanges to the prompt (Figure 14), and show that\nresults are stable.\nWe sample N = 50 personas and we use the\nsame set of personas for all LLM experiments. In\nTable 7, we report the demographic make-up of\nthese 50 sampled personas. For each prompting\nmethod, we generate 30 networks, to capture vari-\nation in prompting (e.g., order of personas) and\nmodel response. For the graph-level metrics, we\nvisualize their mean and standard error, along with\nindividual data points (Figures 3 and 5). Visual-\nizing both the standard error and individual data\npoints capture inferential uncertainty and outcome\nvariability, as recommended by Zhang et al. (2023).\n5.1 Evaluating network structure\nHere, we describe our main results from evaluating\nthe structure of the generated networks.\nLocal and Sequential are more realistic than\nGlobal. First, we find that the prompting meth-\nods produce visually different network structures,\nas shown in Figure 2. Furthermore, the networks\nproduced by the Global method are far less realistic\nthan those produced by Local and Sequential. As\nshown in Figures 3-4, Global has unrealistically\nlow density, clustering, and connectivity, too much\ncommunity structure, and misses the long tail of\nthe degree distribution. In comparison, Local and\nSequential overlap with the real distributions for\nall graph-level metrics and show much greater vari-\nation in node degrees.\nThus, LLMs produce more realistic social net-\nworks when we assign the LLM to act as one per-\nsona at a time, instead of prompting it to produce\nthe entire network at once. This is interesting, since\nthe LLM has strictly less information under the\none-persona setting: in the Local setting, it has no\naccess to any network information, only making\nlocal decisions per persona based on demograph-\nics, and in the Sequential setting, it only knows\nthe network based on previous personas' choices"}, {"title": "5.2 Evaluating homophily", "content": "We measure homophily for gender, race/ethnicity,\nreligion, and political affiliation, using the ratio of\nobserved-to-expected same-group relations (1).\nLLMs capture homophily, with greatest empha-\nsis on politics. In Figure 5, we show that, across\nall prompting methods and demographic variables,\nthe generated networks clearly exhibit homophily.\nFurthermore, we see different levels of homophily\nfor different demographic variables. For the more\nrealistic Local and Sequential methods, homophily\nis by far the strongest for political affiliation: ob-\nserved same-party relations are 85% more frequent\nthan expected under Local and 68% more frequent\nthan expected under Sequential. Rates of political\nhomophily are even higher for the five other LLMs\nthat we test, most extremely for GPT-40 and Llama\n3.1 70B, where 100% of edges are same-party and\nthe network fractures into two disconnected com-\nponents (Appendix A)."}, {"title": "5.3 Incorporating interests", "content": "A natural question is whether demographic ho-\nmophily is exaggerated because we only give the\nLLM demographic information, without other im-\nportant details such as the person's interests. Thus,\nwe run an additional set of experiments where we\nallow the LLM to also generate interests for each\npersona. To generate interests, we prompt the LLM\nwith, \"In 8-12 words, describe the interests of some-\none with the following demographics\u201d (full prompt\nin Figure 16). In Table 2, we provide examples of\nthe generated interests, with the full list of personas\nwith interests available online.\nEffect of interests on networks. As shown in\nFigure 5, by comparing Sequential vs. Sequen-\ntial with interests, we find that incorporating in-"}, {"title": "6 Discussion", "content": "Our work has established several findings. First,\n\"local\" prompting methods result in more realis-\ntic social networks than \"global\" methods, even\nthough local settings receive less information about\nthe existing network. Second, within local meth-\nods, adding network information (i.e., Sequential)\nhelps the LLM produce more realistic networks, so\nthat long-tailed degree distributions are captured.\nThird, the LLM clearly exhibits homophily across\nfive key demographic variables, but political ho-\nmophily dominates, to the extent that it is overes-\ntimated relative to real-world measures. Finally,\nincorporating LLM-generated interests does not re-"}, {"title": "Appendix", "content": "In Appendix A, we compare results across GPT,\nLlama, and Gemma models. In Appendix B, we\ndescribe additional experiments and findings. In\nAppendix C, we provide details on methods and\nexperimental set-up.\nA Comparison between LLMs\nWe experiment with the following LLMs: Ope-\nnAI's GPT-3.5 Turbo and GPT-40 (Brown et al.,\n2020; OpenAI et al., 2023), Meta's Llama 3.1 (8B\nand 70B) (Touvron et al., 2023), and Google's\nGemma 2 (9B and 27B) (Gemma Team et al.,\n2024), representing a range of models across com-\npanies and sizes. For the OpenAI models, we use\nthe OpenAI API, and for the other models, we use\nthe Llama API, which also includes other open-\nsource models. We report our main results on GPT-\n3.5 Turbo since we find that it best matches the\nstructure of the real-world social networks (dis-\ncussed below), but here, we discuss results from\nall other models. For these experiments, we gen-\nerate networks with the Sequential method, using\nthe same experimental settings as before (same set\nof 50 personas, prompt, temperature of 0.8, etc.).\nFor these experiments, we generate 10 instead of\n30 networks per model, but we find that standard\nerrors are small. We visualize results for GPT-40\nin Figure 7, Llama 3.1 8B and 70B in Figure 8, and\nGemma 2 9B and 27B in Figure 9.\nStructural characteristics. We find that GPT-\n3.5 Turbo best matches the structure of the real\nnetworks, most notably matching the real-world\ndensity. All of the other models have much higher\ndensities, which also contributes to unrealistically\nhigh clustering and low shortest paths. Due to\ndensity's outsized effect, we wanted to see if pro-\nviding the model a bit of help on density might be\nall that it needs to match the other characteristics\nas well. Thus, we try a variant of the Sequential\nmethod where we specify n, i.e., how many friends\nshould be chosen (instead of only asking \"Which\nof these people will you become friends with?\",\nsee full prompt in Figure 19). We sample n from\nExponential(\u03bb = 0.2), with mean 1/\u03bb = 5, inde-\npendently for each persona. Note that specifying\neach persona's number of choices does not prede-\ntermine the exact density or degree distribution of"}, {"title": "B Additional results", "content": "In this section, all experiments are run with GPT-\n3.5 Turbo, unless otherwise specified.\nComparing to classical network models. In the\nmain text, we showed that the LLM can match\nmany structural characteristics of real social net-\nworks, including density, clustering, connectivity,\nand degree distribution (Figures 3 and 4). However,\nhow does this compare to existing models for net-\nwork generation? Here, we consider three classical\nnetwork models: (1) Erd\u0151s\u2013R\u00e9nyi random graph\nmodels (Erd\u00f6s and R\u00e9nyi, 1959), (2) Barab\u00e1si-\nAlbert preferential attachment models (Barab\u00e1si\nand Albert, 1999), and (3) Watts-Strogatz small-\nworld models (Watts and Strogatz, 1998). These\nmodels are close to zero-shot: they only require a\n1-2 parameters to define, although we still need to\nfit these parameters. In contrast, we do not com-\npare to stochastic block models (Holland et al.,\n1983), which require sizes per block and proba-\nbilities between each pair of blocks, or machine\nlearning models for graph generation, since they\nhave many parameters and require a substantial set\nof observed graphs for training to fit those parame-\nters (You et al., 2018; Simonovsky and Komodakis,\n2018; Guo and Zhao, 2023).\nTo quantify how well a network metric is\nmatched, we extract the metric from each real so-\ncial network, using the same eight social networks\nas in our main experiments (Sections 5.1 and C.3),\nand from each generated network, with 30 gen-\nerated networks per model. To compare the two\ndistributions of the metric, we report both the differ-\nence in the means, normalized by the real networks'\nstandard deviation (Eq. 4), and the two-sample Kol-\nmogorov-Smirnov statistic (Eq. 5), which mea-\nsures the distance between two empirical distribu-\ntions. As we show in Table 3, even in the best\ncase-when we allow the models to choose pa-\nrameters based on the real social networks-these\nmodels cannot match all of the real network met-\nrics as well as our Local or Sequential methods can.\nThus, being able to match the structural character-\nistics of real social networks is non-trivial, adding\nsignificance to our finding that LLMs can match\nmany structural characteristics at once.\nAge homophily. We cannot directly apply our\ntypical homophily measure, Eq. 1, to age, since\nit is not a categorical variable. However, we can\nstill measure age homophily in a number of ways."}, {"title": "C Methodological details", "content": "C.1 Persona construction\nAs described in the main text, we include gender,\nage, race/ethnicity, religion, and political affiliation.\nIn Table 7, we list the number of personas in each\ndemographic group for the sample of 50 personas\nwe used in most of our experiments, as well as the\nsample of 1,000 personas we used for evaluating\ntop interests per demographic (Table 5). In Fig-\nure 15, we visualize the distribution of ages in the"}]}