{"title": "Combinatorial Reasoning: Selecting Reasons in Generative AI Pipelines via Combinatorial Optimization", "authors": ["Mert Esencan", "Tarun Advaith Kumar", "Ata Akbari Asanjan", "P. Aaron Lott", "Masoud Mohseni", "Can Unlu", "Davide Venturelli", "Alan Ho"], "abstract": "Recent Large Language Models (LLMs) have demonstrated impressive capabilities at tasks that require human intelligence and are a significant step towards human-like artificial intelligence (AI). Yet the performance of LLMs at reasoning tasks have been subpar and the reasoning capability of LLMS is a matter of significant debate. While it has been shown that the choice of the prompting technique to the LLM can alter its performance on a multitude of tasks, including reasoning, the best performing techniques require human-made prompts with the knowledge of the tasks at hand. We introduce a framework for what we call Combinatorial Reasoning (CR), a fully-automated prompting method, where reasons are sampled from an LLM pipeline and mapped into a Quadratic Unconstrained Binary Optimization (QUBO) problem. The framework investigates whether QUBO solutions can be profitably used to select a useful subset of the reasons to construct a Chain-of-Thought style prompt. We explore the acceleration of CR with specialized solvers. We also investigate the performance of simpler zero-shot strategies such as linear majority rule or random selection of reasons. Our preliminary study indicates that coupling a combinatorial solver to generative AI pipelines is an interesting avenue for AI reasoning and elucidates design principles for future CR methods.", "sections": [{"title": "1 Introduction", "content": "The advent of auto-regressive architectures, notably modern LLMs (Vaswani et al. 2017), mark a significant development in the pursuit of human-like AI. These models exhibit a profound capacity for generating human-like responses, positioning them as impressive tools for information processing. However, despite their extensive training and large parameter counts, LLMs inherently lack robust mechanisms for deep reasoning and strategic planning (Nye et al. 2021; Valmeekam et al. 2023), which are necessary for applications demanding high-level cognitive functions. Moreover, the same architecture makes LLMs prone to hallucination-defined as generation that is nonsensical or unfaithful to source material (Xu, Jain, and Kankanhalli 2024).\nOne approach to handling these limitations is to provide additional retrieved context to reduce incorrect generations. Techniques such as retrieval augmented generation (RAG) query a vector database to retrieve source material before generating the LLM response (Lewis et al. 2020). This approach is particularly suitable for knowledge intensive tasks but does not generalize well to reasoning-intensive tasks.\nA parallel area of research is improvements to prompt engineering and response decoding. A new method dubbed Chain of Thought (CoT) (Wei et al. 2022) concatenates hand-annotated example responses with reasoning to the query to create the prompt. The responses from the LLM mimic the examples and contain a 'reasoning path' followed by the answer. Another method developed as a complementary decoding approach is Self-Consistency, with the idea that marginalizing over several reasoning paths provides the best possible response (Wang et al. 2022). However, these approaches rely heavily on human annotations and the same static examples may not be relevant to different queries.\nTo address these limitations and inspired by the conjecture that the human brain performs gradient-free optimization for reasoning and decision-making (LeCun 2022), we propose that integrating combinatorial optimization strategies within LLM frameworks could advance their reasoning capabilities and make them more adept at handling tasks requiring strategic thought.\nOur research proposes the integration of an external reasoning engine that interfaces with existing LLM pipelines to fully automate the creation of CoT style prompts. As the reasoning engine sits outside the LLM black box, our work is not an attempt to change the foundational auto-regressive architecture of LLMs but a proposed tool to analyze and possibly augment their reasoning faculties through automated prompt engineering. By employing combinatorial optimization, the engine generates structured prompts that guide the LLM towards the correct answer. Our work intersects two"}, {"title": "2 Preliminaries and Prior Work", "content": "Large Language Models (LLMs) are machine learning models that are trained to receive and recognize text as input and produce text as output. Distinguished from simpler language models by their immense parameter count, these models are capable of general purpose language processing tasks. GPT 3.5-turbo, the LLM used in our experiments, is part of a series of models developed by OpenAI for generating human-like natural language text (Ye et al. 2023). Many LLMS including GPT 3.5-turbo are capable of receiving and following a set of system instructions while responding to a query. System instructions differ from the user content that queries an LLM for a response, and we refer to the latter as a 'prompt' throughout this work. System instructions define the characteristics of the language model's output, and constrain it to fit requested behavior (OpenAI 2023). For our experiments, we use temperature sampling - a popular method for decoding LLMs in text generation tasks. Adjusting the temperature causes the probability distribution of each subsequent token to be modified, affecting the variability of the responses (Fan, Lewis, and Dauphin 2018). High sampling temperatures result in diversity while lower temperatures provide more reproducible generations."}, {"title": "2.2 Reasoning in Large Language Models", "content": "There have been many papers that suggest that LLMs can indeed reason (Kiciman et al. 2023; Webb, Holyoak, and Lu 2022). For each subsequent revision of LLMs - GPT4 / Gemini / and Llama3, reasoning benchmarks such as BIG-Bench-Hard, HellaSwag, and MMLU show ever improving results. However, these results are not a good indicator for the autonomous reasoning capabilities of the model. In each case, the benchmarks are performed using in-context learning, with few-shot (specific examplars) or Chain of Thought (CoT), for which humans manually develop exemplars using labeled datasets to improve performance.\nThe latest language models do not report the zero-shot performance on these benchmark as in seen Table 1 since the performance is likely poorer than those with manual prompts. Thus we believe the next milestone for LLMs is automatic prompt generation with correct reasoning.\nThe main inspiration for our work comes from Yan LeCun's review (LeCun 2022) which suggests multiple models need to work together to emulate general intelligence and that human brain possibly calculates a \"cost function\" for reasoning in a gradient-free manner similar to combinatorial optimization.\nChain of Thought As a natural extension of the in-context few shot learning to facilitate reasoning, the Google Brain team developed few-shot CoT (Wei et al. 2022). The aim is to augment language models with the ability to 'reason' in intermediate steps before providing an answer. This approach requires manual demos (or exemplars): labeled question answer pairs containing intermediate reasoning steps that lead to the final correct answer. Inspired by this, (Kojima et al. 2022) developed \u201czero-shot CoT\u201d as an approach to induce LLMs to answer with intermediate reasoning step without manual demos. Simply put, appending the phrase \"Let's think step by step\" to a particular query improved performance.\nSelf-Consistency Self-Consistency was introduced by Google's Deepmind Team as an improved decoding approach for CoT style prompts (Wang et al. 2022). Instead of greedy decoding, the authors suggest collecting samples at non-zero temperatures and selecting the most occurring answer. This approach lends itself to an intuitive interpretation - reasoning problems admit multiple correct reasoning paths that lead to the unique right answer but incorrect reasoning paths lead to different incorrect answers. Self-consistency can also be viewed as marginalization over latent tokens to produce a better answer.\nUniversal Self-Adaptive Prompting (USP) The Universal Self-Adaptive Prompting approach introduces a novel way of generating automatically designed prompts to improve decoding efficiency (Wan et al. 2023). This approach involves the use of unlabeled questions to generate a set of"}, {"title": "2.3 Combinatorial Optimization and Ising Machines", "content": "It is well known that challenging combinatorial optimization problems arise in multiple industrial domains, such as finance, logistics, manufacturing, drug design (Hidaka et al. 2023; Venturelli and Kondratyev 2019; Gannouni et al. 2020; Irb\u00e4ck et al. 2022). State-of-art solution methods often consist of a patchwork of heuristic techniques tuned to the problem class of interest. Interestingly, for many of these problems efficient mappings of the cost-function H to a binary, quadratic, unconstrained formulation exist (QUBOs (Lucas 2014; Kochenberger et al. 2014)). Equivalently, the problems can be framed in \u201cphysics terms\u201d as approximating as much as possible the ground state of an interacting, disordered classical Ising spin energy function:\n$$H = \\sum_{i,j}Q_{ij}x_ix_j = \\sum_{i}h_is_i +\\sum_{i,j} J_{ij}s_is_j,$$\nwhere $$x_i \\in \\{0,1\\}; s_i \\in \\{-1,+1\\}$$ and $$J_{ij}, h_i, Q_{ij}$$ are real-valued coefficients that specify the problem instance. While the QUBO and Ising forms are equivalent, in this paper we will formulate everything in terms of the QUBO form. Clearly, the search space for the minimum of Eq. 1 scales as $$2^N$$ as the number of variables N increases.\nThe existence of these mappings has ignited a lively research community that, in the last ten years, has devised hardware implementation of the Ising model as well as physics-inspired algorithmic strategies meant to cool down interacting spins close to their least energetic configuration. Collectively, these methods are often referred to as \"Ising Machines\u201d (Mohseni, McMahon, and Byrnes 2022; Tanahashi et al. 2019; Tiunov, Ulanov, and Lvovsky 2019) or sometimes \"quantum-inspired\u201d solvers - considering the fact that the most popular and visible methods have a connection to quantum mechanics (Sao et al. 2019; Komatsu et al. 2018; Takemoto et al. 2020; Toshiba 2024).\nDigital implementation of Ising machines are currently the most scalable approach to tackle large problems. This includes GPU/FPGA emulations of solution principles inspired by oscillator synchronization (such as Kuramoto models (Acebr\u00f3n et al. 2005), coherent optics with or without dissipation (e.g Coherent Ising Machines (Inagaki et al. 2016) and Bifurcation Machines (Tatsumura, Dixon, and Goto 2019)) and thermal relaxation (e.g. probabilistic bits (\"p-bits\") variations (Camsari, Salahuddin, and Datta 2017; Chowdhury et al. 2023)). Benchmarks of these systems have consistently performed well in paradigmatic benchmarks of combinatorial optimization, especially in absence of hard constraints. Indeed, there is accumulated empirical evidence that on NP-Hard problems such as fully-connected Spin Glasses the time-to-solution scales as a stretched exponential with the increase of the number of binary variables, on typical instances (i.e. $$O(N) x exp(\\sqrt{N})$$),\nwhile other methods seem to struggle (Sankar et al. 2021; Mohseni, McMahon, and Byrnes 2022).\nSimulated Annealing and Parallel Tempering Simulated Annealing (SA) (Kirkpatrick, Gelatt, and Vecchi 1983) is an optimization technique built on searching for low energy solutions using a Markov chain parameterized by a temperature such that high temperature samples correspond to random samples and low temperature samples reflect low energy locally-optimal configurations of the target system. A temperature schedule is formulated to effectively explore or exploit regions of the search space for low energy configurations. Parallel Tempering (PT) (Man-"}, {"title": "3 Combinatorial Reasoning", "content": "While LLMs cannot reliably reason on their own, with the assistance of an auxiliary system - namely a discrete probabilistic optimizer - we could conceivably select reasons that could create a useful CoT passed into the LLM. The main conceptual challenge is whether one can design a reason-to-variable mapping and a related cost function with the following properties:\nuniversality: works across a large variety of reasoning\ntasks\naccuracy: its optimized solutions correspond to selecting good reasons when a variety of reasons exist for a given answer\npracticality: its complexity is such that it returns useful reasons within the time allowed for the optimizer to do the minimization\nWith reference to Fig. 2, we investigate these challenges by drafting a QUBO cost-function inspired by the problem of portfolio optimization, and designing a sequential procedure of interaction between LLMs and an Ising machine. We call this generic framework Combinatorial Reasoning (CR). It consists of four stages which we now describe in detail."}, {"title": "3.1 Sampling of Reasons", "content": "Given a question from the dataset, we prepare N identical input prompts (see appendix B) and query an LLM at a fixed temperature. Following the system instructions, each of the N outputs will contain a set of reasons. Among these, there are duplicate reasons that are semantically equivalent. We use a Sentence Transformer from HuggingFace (all-mpnet-base-v2) to embed each reason into a normalized 768 dimensional vector. Defining a similarity metric between two reasons as the dot product of the corresponding embedded vectors, we count two reasons as the same if this metric is greater than $$\\$. Using this procedure as our method for counting, we can reduce the set of all sampled reasons into a smaller set of distinct reasons and a collection, $$\\{i\\}$$, of embedded vectors. We define:\n\\{s\\} : Set of samples each with an answer and set of reasons\n\\{total\\}: Set of all reasons sampled from the LLM\n\\{rdistinct\\}: Set of independent reasons selected by Sentence Transformer\n$$n_i$$: The number of times each independent reason, indexed by i, appears in our N samples\n$$n_{ij}$$: The number of times a pair of independent reasons, indexed by i and j, appear together within any one of our N samples\nThese counts are the basis of combinatorial reasoning, and we use these to compute quantities essential in the QUBO mapping. From here on, we refer to independent reasons as reasons for the sake of brevity. Using these counts as well as the acquired embeddings, we denote $$m_i$$ as the average similarity that each reason shares with every reason, i.e.\n$$m_i = \\frac{1}{k}\\sum_{j=1}^{k}\\frac{v_i \\cdot v_j}{|v_i||v_j|}$$\nFinally, to clarify our notation, for a given collection $$\\{\\xi_\\mu\\}$$, we use $$\\overline{\\xi}$$, $$\\widetilde{\\xi}$$, and $$\\delta_{\\xi}$$ to denote the mean, median, and standard deviation."}, {"title": "3.2 QUBO Mapping", "content": "This stage processes deterministically the collection of answers and their distinct reasons to formulate a quadratic unconstrained integer optimization problem. The procedure that we decide to investigate is inspired by the QUBO mappings to Markowitz portfolio optimization (Grant, Humble, and Stump 2021) where the goal is to select the optimal assets (i.e. reasons, in our case) out of a finite universe (all distinct reasons) maximizing some metric. Importantly, this is just one of the many possible cost-functions that could be designed to try to capture the correlations between good and consistent reasons outputted by an LLM after an ensemble of queries, as it will be discussed in Section 5. Each distinct reason is associated to an integer variable $$z_i$$. The integer bound for the variables is a parameter to be chosen as the maximum power of two in order to leverage the binary encoding $$z_i = \\sum_{w=0}^{W-1} 2^w x_{iw}$$ where $$x_{iw}$$ are binary variables. We now construct two functions that will compose a total objective $$H = -(L + Q)$$. The first term is meant to select reasons based on their frequency of appearance $$n_i/N$$.:\n$$L = \\sum_i l_i(\\mu, \\alpha) z_i = \\sum_i[\\mu p_i - \\alpha r_i]z_i$$\nwhere $$p_i$$ is a measure of \u201cpopularity\", i.e. of the relative deviation with respect to the mean frequency of appearance of a reason. $$r_i$$ is a measure of the standard deviation module around the frequency (in analogy to the concept of risk in portfolio optimization):\n$$p_i = \\frac{n_i}{N} - \\overline{n}$$,  $$r_i = \\frac{\\sigma_n}{\\overline{n}} \\bigg(\\frac{n_i}{N} - \\overline{n}\\bigg).$$\nThe real parameters $$\\mu$$ and $$\\alpha$$ needs to be chosen empirically. If this was the only objective function (i.e. $$H = -L$$) then $$z_i$$ will either be 0 or maxed out depending on whether $$l_i(\\mu, \\alpha)$$ is positive or negative.\""}, {"title": "3.3 Combinatorial Optimization Solver", "content": "The QUBO instance is processed by an Ising machine configured with a pre-defined parameter setting strategy (Neira et al. 2024) aimed to find the most appropriate solution to the $$x_i$$ variables. Ideally, the solver identifies the global optimum of H, i.e.\n$$x^* \\triangleq arg \\min_{\\{x_i\\}} [H]$$\nhowever, an approximate solution might be sufficient as discussed in Section 6.1. We denote as $$\\{r_{selected}\\}$$ the set of reasons selected by QUBO solver. From the binary encoding formula we obtain the $$z_i$$ variables. We then compose a list including all reasons such that $$z_i > 0$$ in the returned solution, and we associate to each of them a real weight $$w$$-value = $$z_i/Z$$ where $$Z = \\sum_i Z_i$$."}, {"content": "Once the best candidate solution to the QUBO problem has been found, it is mapped back to set of reasons $$\\{r_{selected}\\}$$, each prepended with their w-value. The LLM is instructed to treat the w-value as a level of relative importance for each reason. These reasons are sorted according to their w-values (highest first) and alphabetically. The concatenated string is used to form a prompt (see appendix B). This final prompt inherit the benefits of CoT thanks to these additional reasons, and is used to query the LLM in a zero-shot fashion at temperature = 0 (greedy decoding)."}, {"title": "4 Experimental Results", "content": "We conduct all of our experiments using the gpt-3.5-turbo-0125 LLM which has a context window of 16,385 tokens and returns a maximum of 4,096 tokens. This language model is a variant of GPT-3.5-Turbo produced by OpenAI, and was trained with data available until September 2021.\nWe selected the suite of BIG-bench Hard (BBH) tasks - a datasets consisting of reasoning oriented questions that have proven challenging for LLMs in the past (Suzgun et al. 2022). To save on inference time and cost, we sample 50 questions from each of the subtasks1, combining them into a 1350 question evaluation set without the subset labels to ensure robustness. On this set, we compare CR against (i) a modified version of zero-shot prompting, (ii) Universal Self-Adaptive Prompting (USP), and (iii) standard three-shot CoT prompting. Our modification to zero-shot consists of an added system-instruction very similar to the one used for CR (see Appendix B for the exact format).\nFor the Sampling of Reasons step, we sampled the LLM N = 210 times at T = 1 to collect sufficient distinct reasons, and calculate their distribution and correlations matrices. N was determined empirically on test questions. To map to distinct reason, the similarity threshold is held to =0.90, again determined empirically. Prior to running the QUBO mapper, we tune the mapping parameters $$\\mu$$, $$\\alpha$$, $$\beta$$, W\nand K (K is fixed) using 5 questions from across all of BBH to form a 135 question tuning set. On this, we set the ranges for the tuning (see Table 2) and use Optuna - a gradient free hyperparameter optimization framework (Akiba et al. 2019) to select the optimal values for the other four parameters. We note that none of the 135 questions in the tuning set appear in the 1350 question evaluation set.\nFor the Ising solver, we utilized an open-source implementation of simulated annealing (Neal 2021) featuring default settings on temperature, linear annealing schedule, and a fixed parameter setting strategy employing 1000 sweeps, run identically 100 times.\nFigure 2 and Table 3 displays our results for BBH tasks. We manually evaluated the results for CR and zero-shot. The USP results are taken from (Wan et al. 2023). While USP was evaluated on PaLM 2-M, we report it here anyway due"}, {"title": "5 Conclusion", "content": "We propose CR as a zero-shot automatic prompting pipeline applicable to reasoning tasks. We believe CR could be advantageous in the scenario that one needs multiple reasons to elicit the correct answer, and the reasons cannot be obtained via a single-shot from the LLM."}, {"title": "6 Future Work", "content": "In this section, we point out some details on the upcoming research directions to improve CR."}, {"title": "6.1 Improving time and accuracy", "content": "We list the following straightforward improvement ideas to the baseline framework:\nSemantic matching Human evaluation on a few samples (N = 10) on the causal judgement, movie recommendation, and sports understanding datasets reveals that a decent fraction of the reasons that are identified as distinct via our automated procedure are actually semantically the same in the eyes of a human. This speaks to the relative simpleness of BBH for LLM reasoning and clearly negatively affects the effectiveness to the QUBO mapping and of the entire\nCR pipeline. It is therefore a priority to improve the semantic matching procedure via threashold adjustment or other more sophisticated filtering.\nQUBO Mapping First and foremost, we re-emphasize the fact that the QUBO construction is just a first attempt to identifying a good objective function. The H construction can be refined and studied carefully to maximize the correlation between the quality of the x* and the accuracy of the final answer at the end of the CR procedure. Approximate solutions of these hard problems might end up being good enough and optimal with respect to the end-to-end result. In Appendix C we study some properties of the current cost-function choice, learning valuable lessons for the design of future improved CR pipelines. It will be also clearly beneficial to study the property of the graphs (size, weight distribution) and correlate characteristics from the physics of spin-glasses (such as the presence of a phase transition (Rieffel et al. 2014; Angelini and Ricci-Tersenghi 2023)) with the final answer.\nIt is immediately notable that for a few task categories (Table 4) our the QUBO mapping does not result in a sub-selection of reasons because all distinct reasons are selected to be part of the final prompt. This indicates that either the problem does not need combinatorial optimization, or that the QUBO mapping needs to be improved. Moreover, the current construction was inspired by a basic portfolio optimization formulation and neglects possibility of negative zi and, budget constraints (which would fix the size of {rselected}), and higher-than-quadratic correlations between the reasons, which can be inserted and \"gadgetized\" into quadratic terms (Babbush, O'Gorman, and Aspuru-Guzik 2013) (adding ancillary variables sparsely connected) while still allowing the use of Ising machines. The advantage of using higher locality solvers than quadratic ones for certain optimization problems has recently been demonstrated (Chermoshentsev et al. 2022).\nCombinatorial Optimization Solvers Selection With QUBO instances being NP-Hard in general, it is expected that the combinatorial optimization solver might take more time to find a quality solution than an acceptable user experience might mandate. The solver used for our baseline results is far from being the optimal choice or from being used in the optimal way, hence we can expect great room for improvement in speed and accuracy of the results in Fig. 2.\nTo show that enhancements are possible, we proceeded performing a few numerical experiments on a subset of instances of BBH for which we substituted the simulated annealing baseline solver either with a hardware-efficient digital implementation (the Fujitsu Digital Annealer (Sao et al. 2019)), and with an Adaptive Parallel Tempering (APT) solver from USRA (Aadit, Lott, and Mohseni 2023).\nSpeedup potential For the digital annealer experiments, we selected the Logical Deduction - 7 objects from BBH as the dataset of interest and sampled 20 questions from it. We consider these instances to be typical, resulting in QUBO problems with an average of 900 variables. We observed consistently a difference of at least an order of"}, {"title": "6.2 Generalizations of the framework", "content": "Understanding performance characteristics of sampling reasons from an LLM CR is based on the assumption that sampling the LLM for reasons will create a distribution of reasons that can be be mapped to an optimization procedure. Exactly how the distribution is created and the accuracy of such distribution needs to be quantified. Factors such as the temperature of the LLM and what type of LLM is being used can impact the distribution of the reasons sampled. The distribution of the reasons are likely to also indicate if the CR procedure is even needed, which could lead to further optimizations.\nIntegration with Theorem Provers Manual inspection of the reasons that are selected by the combinatorial optimizer reveals that we sometimes find reasons that conflict with each other. We conjecture for harder problems, the number of conflicting reasons will increase and can be removed by leveraging a theorem prover such as (Z3 2024) to further improve the performance of combinatorial reasoning. One of the challenges of using a theorem prover is that they do not scale to thousands of variables. However, using the theorem prover as a post-processing step after the combinatorial optimizer narrows down the reasons to several dozen reasons is practical. The combination of a probabilistic solver combined with a deterministic solver allows for reasoning on open domain problems.\nIntegration with Retrieval Augmented Generation Retrieval augmented generation (RAG) is used for knowledge intensive tasks. In the real world human problem solving, a combination of knowledge retrieval and reasons is used. A potential avenue for integrating RAG could be:\nUse input query to perform a semantic search on a knowledge base to create a knowledge context\nInclude the knowledge context the prompt when performing sampling of reasons\nWith context windows of 1M tokens (Gemini Team 2024), the \"reasons\" sampled from the LLM could be derived from very long form documents."}]}