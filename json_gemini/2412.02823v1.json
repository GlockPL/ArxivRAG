{"title": "Minimization of Boolean Complexity in In-Context Concept Learning", "authors": ["Leroy Z. Wang", "R. Thomas McCoy", "Shane Steinert-Threlkeld"], "abstract": "What factors contribute to the relative success and corresponding difficulties of in-context learning for Large Language Models (LLMs)? Drawing on insights from the literature on human concept learning, we test LLMs on carefully designed concept learning tasks, and show that task performance highly correlates with the Boolean complexity of the concept. This suggests that in-context learning exhibits a learning bias for simplicity in a way similar to humans.", "sections": [{"title": "1 Introduction", "content": "The human conceptual apparatus represents one of the most remarkable aspects of our species' intelligence [Murphy, 2002]. In order to understand the ways in which artificial intelligences do and do not resemble our own, understanding their conceptual structure is an important first step.\nOne prominent tradition argues that concepts are representations in a language of thought (LoT) [Fodor, 1975, Goodman et al., 2015, Quilty-Dunn et al., 2022]. The recent Bayesian revolution in cognitive science has argued that concept learning exhibits a very strong bias for simplicity: human learners infer the simplest expression in an LoT that is consistent with the data that they have seen [Feldman, 2000, Chater and Vit\u00e1nyi, 2003, Goodman et al., 2008, Piantadosi et al., 2016].\nIn this paper, we study in-context concept learning with large language models (LLMs), allowing us to address the following questions: when presented with labeled examples of an unknown concept, can an LLM infer the underlying concept? If so, what inductive biases does this in-context concept learning exhibit; in particular, does it exhibit a simplicity bias akin to the simplicity bias displayed by humans?\nConsider the prompt in (1). In the first two lines, we see labeled examples of a new numerical concept, bnik. The final line asks a model to label a new example. Repeating this for a range of example sets and concepts, we can measure whether models have greater success with simpler concepts."}, {"title": "2 Related Work", "content": "Feldman [2000] showed that ease of human concept learning is highly negatively correlated with Boolean logical complexity: concepts with longer minimal logical formulas are harder for people to learn. A large body of subsequent work has extended the range and scope of this view using Bayesian inference in various LoTs [Goodman et al., 2008, Piantadosi et al., 2016]. Carcassi and Szymanik [2022] show that neural networks trained from scratch to learn Boolean concepts exhibit a similar bias for simplicity. A wide range of work has recently analyzed when, how, and why in-context learning (ICL) in LLMs works [Min et al., 2022, Aky\u00fcrek et al., 2022, Aky\u00fcrek et al., 2024, i.a.]. To the best of our knowledge, ours is the first to explicitly study concept learning and measure a learning bias for logical simplicity in ICL."}, {"title": "3 Methodology", "content": ""}, {"title": "3.1 Concept generation", "content": "Our data generation methodology is inspired by van de Pol et al. [2022] and Z. Wang and Steinert- Threlkeld [2023], where we define the complexity of a concept using its minimal description length- the length of the shortest expression that can capture the concept (defined more precisely below). We define a concept as a semantic object generated by a logical grammar, whose basic structure is shown in Table 1. The full grammar used during generation is given in Appendix A.4, which imposes some additional constraints to prevent certain types of unwanted recursive generation."}, {"title": "3.2 Data generation", "content": "Each prompt that we give to LLMs, such as the prompt shown in (1) above, is made of several examples. Each example is generated from the following template, where the slots that vary between examples are underlined:"}, {"title": "3.3 Models", "content": "We ran experiments on two LLM families: Qwen2 [Yang et al., 2024] from Alibaba research, and Gemma 2 [Riviere et al., 2024] from Google DeepMind. During testing, the instruction-tuned versions of the models and default Huggingface chat templates were used. Qwen2-72b was the best- performing open model on Hugging Face Open LLM Leaderboard as of June 2024. The Gemma 2 models achieved state-of-the-art results for their size, while reaching competitive performance on many benchmarks when compared to models with 2\u00d7 more parameters."}, {"title": "4 Results", "content": "For each complexity class, we randomly sample 18 concepts from all possible concepts in that class. Each data point on the plot in Figure 1 represents the model's accuracy on a specific concept. The trend line shows the line of best fit to the average accuracy of each complexity class.\nFor each model family, we run experiments for models in two sizes \u2013 the largest model in that family, and a model that has approximately 10 billion parameters. As shown in the figure, the average accuracy for all LLMs decreases as concept complexity increases. The drop in average accuracy is most evident in Gemma 2-9B: from 83% in class 1 to 66% in class 5. For the largest model we tested, Qwen2-72B, there is a 16% decrease (90% \u2192 74%) in average accuracy as complexity increases from 1 to 5. See Appendix A.2 for a plot of only average accuracy values for each model.\nIn Table 2, we see there is a strong negative correlation between concept complexity and average model accuracy, indicated by the Pearson correlation coefficients (PCC). All results are statistically significant except for Qwen2-72B, which is nearly significant at a p = 0.05 threshold."}, {"title": "5 Conclusion", "content": "This work has shown that LLM in-context concept learning exhibits a simplicity bias of a similar sort as the simplicity bias that has been observed in human concept learning. Much work remains for the future: (i) more detailed comparisons with human concept learning data (e.g., of exact learning curves), (ii) extending this research to conceptual domains beyond the numerical, and (iii) more detailed analysis of factors explaining the ease of in-context concept learning beyond LoT complexity. We hope that this work will spur a new line of research exploring how perspectives from the concept learning literature can shed light on the nature of in-context learning in LLMs."}, {"title": "A Appendix / supplemental material", "content": ""}, {"title": "A.1 Limitations", "content": "Only a finite set of fractions are used in the grammar to improve efficiency. As a consequence, it may be the case that some concepts that require a certain minimal number of operators under our framing could be expressed using fewer operators if more fractions were allowed.. To address this issue, we plan to use a richer set of fractions in future work.\nOnly a limited set of LLMs are tested. It is possible that newer models / models with different architectures do not exhibit the phenomena discussed in this text.\nWe use only one prompt template for all experiments, which may introduce implicit biases in the data and affect the experiment results."}, {"title": "A.2 Complexity vs. average accuracy plot", "content": ""}, {"title": "A.3 Data Generation", "content": "The pseudocode shows how prompt data is generated, from sets of (predefined) subjects, verbs, and objects."}, {"title": "A.4 Grammar for concept generation", "content": "The grammar used during concept generation is given below, presented as a context-free grammar.\nBool -> Bool and\nBool\nBool -> Bool or\nBool\nBool -> Var2 ==\nSimpleInt\nBool -> Var2 !=\nSimpleInt\nBool -> Var2 >\nSimpleInt\nBool -> Var2 <\nSimpleInt\nBool -> Var2 >\nComplexFloat\nBool -> Var2 <\nComplexFloat\nComplexFloat -> SimpleFloat *\nVar1\n# total number of items\nVar1 -> [5, 100]\n# subject's number of items\nVar2 -> [0, 100]\nSimpleInt -> [0, 100]\n# fractions\nSimpleFloat -> {1/5, 1/4, 1/3, 2/5, 1/2, 3/5, 2/3, 3/4, 4/5}\nConstraints on the grammar For the sake of efficiency, the fine-grained type system in the gram- mar prevents the generation of fractions that are not in the predefined list of fractions. Multiplication can only take place between \"SimpleFloat\" and \"Var1\", so it is not possible to obtain new fractions by multiplying existing ones."}, {"title": "A.5 Deduplication method", "content": "The deduplication methodology used here is based on vectors representing concept meanings. Suppose the total number of objects is n = 100. We can then imagine the semantics of a con- cept being represented by a 101-dimensional vector, where each dimension is the truth value of $f(n = 100, x) = {(n,x) : (x > 3)}$ for x $\\in$ [0, 100].\nWe compute such a semantics vector for n = {25, 50, 100} for all concepts in each class, and use the edit distance to remove similar concepts. Two concepts are considered similar if they belong to different classes and have an edit distance < 3 between their vectors."}, {"title": "A.6 Example prompt", "content": ""}, {"title": "A.7 Compute resources", "content": "All experiments were run on two Nvidia RTX A6000 GPUs. Greedy decoding was used during inference."}, {"title": "A.8 Concept complexity classes", "content": "Below are some representative concepts for each class. It is not a comprehensive list of all the concepts that are generated.\nComplexity 1:\nprimitive operators\n[n = x]\n[n > x]\n[x > c]\n[x < c]\n[x = c]\n[x != c]\nComplexity 2:\nproportional primitives\n[x > p * n]\n[x < p *n]\nComplexity 3:\nconjunction / disjunction of primitive operators\n(x > c1) or (x < c2)\n(x > c1) and (x < c2)\nComplexity 4:\nconjunction / disjunction of one operator and one proportion\n(x > c) or (x < p* n)\n(x > c) and (x <p*n)\nComplexity 5:\nconjunction / disjunction of two proportions\n(x > p1*n) or (x < p2* n)\n(x > p1*n) and (x < p2 * n)\nconjunction / disjunction of three primitives\n((x > c1) and (x < c2)) or (x > c3)\n((x > c1) and (x < c2)) or (x < c3)"}]}