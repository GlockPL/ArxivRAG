{"title": "Siamese Networks with Soft Labels for Unsupervised\nLesion Detection and Patch Pretraining on Screening\nMammograms", "authors": ["Kevin Van Vorst", "Li Shen"], "abstract": "Self-supervised learning has become a popular way to pretrain a deep learning\nmodel and then transfer it to perform downstream tasks. However, most of these\nmethods are developed on large-scale image datasets that contain natural objects\nwith clear textures, outlines, and distinct color contrasts. It remains uncertain\nwhether these methods are equally effective for medical imaging, where the regions\nof interest often blend subtly and indistinctly with the surrounding tissues. In this\nstudy, we propose an alternative method that uses contralateral mammograms to\ntrain a neural network to encode similar embeddings when a pair contains both\nnormal images and different embeddings when a pair contains normal and abnor-\nmal images. Our approach leverages the natural symmetry of human body as weak\nlabels to learn to distinguish abnormal lesions from background tissues in a fully\nunsupervised manner. Our findings suggest that it's feasible by incorporating soft\nlabels derived from the Euclidean distances between the embeddings of the image\npairs into the Siamese network loss. Our method demonstrates superior perfor-\nmance in mammogram patch classification compared to existing self-supervised\nlearning methods. This approach not only leverages a vast amount of image data\neffectively but also minimizes reliance on costly labels, a significant advantage\nparticularly in the field of medical imaging.", "sections": [{"title": "Introduction", "content": "The creation of large image databases such as the ImageNet [1] has made it possible to develop\npowerful artificial neural networks (ANNs) with millions of parameters to classify images at very\nhigh accuracy. This has revolutionized computer vision where the use of large-scale ANNs, known as\ndeep learning, has become standard practice [2]. It has also resumed people's interest in developing\nthe next-generation computer-aided diagnosis (CAD) tools in medical imaging [3], where the progress\nhas stagnated for decades since 1990s. However, unlike natural image datasets that can be labeled\nthrough crowd-sourcing [4], medical image datasets are notoriously expensive and time consuming\nto create. They require qualified experts, whose times are often constrained, to verify these images\nare correctly labeled [5]. To make the problem even worse, there is often a significant amount of\nvariability among the experts [6].\nA major theme in machine learning is to teach models to learn from unlabeled data through unsuper-\nvised learning. In recent years, a family of unsupervised learning methods known as self-supervised\nlearning (SSL) has emerged as a highly effective way of learning without labels. In a nutshell, SSL\ngenerates artificial tasks from data for a model to solve, through which the model learns to extract\nmeaningful representations from the data [7]. This process is known as pretraining. A pretrained\nmodel becomes an encoder whose outputs can be directly used or finetuned for downstream tasks,"}, {"title": "Related Works", "content": "SSL is a class of machine learning methods where a model is trained on unlabeled data to learn\ngeneral and useful representations [8]. The pretrained model can then be used as an encoder to extract\nembeddings for downstream tasks. Generally speaking, SSL methods can be classified into two\ngroups: pretext tasks and contrastive learning [11]. Learning representations via pretext tasks involves\ngenerating pseudo labels, e.g. via rotation, masking, or colorization, and ask the model to predict the\ngenerated labels [11]. On the other hand, contrastive learning does not use pseudo labels, but rather\napplies strong data augmentation to a single image p to produce two distorted views using a stochastic\ntransformation function t so that v\u2081 = t(p), v2 = t(p). The two views from the same image are called\na positive pair while two views from two different images are called a negative pair. In SimCLR [12],\nan encoder is trained to maximize the agreement of positive pairs and simultaneously minimize the\nagreement of negative pairs. Another popular SSL method is called BYOL [13] where only positive\npairs are used. In BYOL, an online network f is learned to encode views and a target network g is\ncreated as an exponential moving average of the online network. The learning task is to maximize the\nagreement between the online and target networks' representations f (v1) and g(v2). In our previous\nwork [10], we found both methods to be effective in learning representations from mammographic\nimages for breast cancer detection. In this work, our focus is on a bilateral patch pair (p1, p2) that\ncomes from the two breasts of the same patient. However, the learning objective is in spirit somewhat\nsimilar to contrastive learning in the sense that we want to maximize the agreement when (P1,P2)\nis a normal pair (i.e., both p\u2081 and p2 are normal) and minimize the agreement when (p1, p2) is\nabnormal pair (i.e., either p\u2081 or p2 is abnormal)."}, {"title": "Siamese Networks", "content": "Siamese networks are a class of neural network architectures that consist of two identical networks\nwith shared weights [14] but they work on two different inputs to compute comparable outputs. For\na pair of input images (p1, p2), the learning objective is to compute similar representations when\nP1 and p2 come from the same class and dissimilar representations when they come from different\nclasses. Assume the image encoding part of a Siamese network is represented by function g, the\nembeddings of the pair of images are h\u2081 = g(p1) and h\u2082 = g(p2). The Siamese network learning\ncan be setup as a binary classification task on the concatenated embedding h = concat(h1, h2) so\nthat f(h) = q represents the probability that the image pair comes from the same class, where f is a\nbinary classifier implemented as a fully connected layer. The binary cross entropy loss can be used to\ntrain the Siamese network:\nSiamese networks were originally developed for facial recognition [15] and later found success in\nother areas such as cancer prediction in chronologically paired mammogram images [16]. In this\nstudy, we use a Siamese network to encode a pair of patches (p1, p2) from bilateral mammograms. If"}, {"title": "Label Noise Modeling", "content": "Label noise learning refers to training models on data that contain corrupted labels [17]. This problem\nreflects real world scenarios where samples are mislabeled or missing labels. Many techniques have\nbeen developed to deal with label noise. One class of methods uses mixture modeling to identify\nmislabeled samples [18, 19] based on two premises: 1. Despite noisy labels, a model can still learn\nto somewhat classify samples correctly based on the clean samples; 2. Mislabeled samples tend to\nhave greater losses than clean samples. Consequently, the samples can be separated into \"noisy\" and\n\"clean\" groups based on losses as soon as the model is reasonably trained.\nInspired by the mixture modeling method in label noise learning, we use Gaussian mixture models\n(GMMs) to identify abnormal pairs from normal pairs in an unsupervised manner. Although the patch\npairs have unknown labels to begin with, as the Siamese network learns to compute representations\nfor a patch pair, an abnormal pair tends to contain representations that are less similar than a normal\npair. This provides an opportunity to distinguish them using an unsupervised clustering technique."}, {"title": "Methods", "content": "Our aim is to identify abnormal patch pairs from bilateral mammograms in an unsupervised manner.\nSince the true label of any given patch pair generated from a pair of bilateral mammograms is\nunknown, we introduce a \u201csoft\u201d label, P \u2208 [0, 1], to represent the confidence for the patch pair being\nabnormal. Assuming a neural network model has already been learned to encode patches in a sensible\nway for an abnormal patch to distinguish from its paired normal patch, then the Euclidean distance\nbetween the embeddings of an abnormal pair should be higher than that of a normal pair. Let function\ng represent the part of the network up to the embedding layer, the embeddings for the patch pair\n(P1,P2) are e\u2081 = g(p1), e2 = g(p2). The Euclidean distance is defined as D = d(e1, e2). A GMM\nh can be built on the set of Euclidean distances for all patch pairs on the training set defined as\nC = {D}, i = 1..N. Here, a two-component GMM is fit on C to identify the two classes (abnormal\nvs. normal) of patch pairs. The GMM function h can be used to provide the posterior probability that\na pair with distance D belongs to the abnormal class such that the soft label P = h(D).\nWe used the Python package sklearn [20] to handle GMM fitting and posterior probability scoring.\nAfter fitting the GMM, it can be used to predict P for each patch pair, which will be used as the soft\nlabels in the loss function to be introduced below."}, {"title": "Proposed Model", "content": "The proposed model is shown in Figure 1 where a Siamese network is used to classify a patch\npair. ResNet-18 [21] is used as the image encoder with the global average pooling layer used as\nthe embedding. The two embeddings (e1,e2) from a patch pair (p1, p2) is concatenated so that\nE = concat(e1, e2). The concatenated embedding is passed through a fully connected layer with\nsigmoid activation f to a single output node to predict the class of the patch pair. This results in\nq = f(E) \u2208 [0, 1] representing the probability that the patch pair is normal.\nAs described in the previous section, the embedding pair (e1, e2) is also used to derive soft label P\nbased on Euclidean distances D = d(e1, e2) across the training set. However, there is a significant\ndistinction between soft label P and probability q. q represents the probability that (P1,P2) is a\nnormal pair directly computed by the Siamese network, while P represents the \"label\" that q tries to\nmatch and is derived from an unsupervised clustering method trained on the entire training set. By\nreplacing the ground truth label y with soft label P (1 P for y) in the binary cross entropy loss\n(eq.1), we have:"}, {"title": "Datasets", "content": "Two datasets are used in this study: VinDr-Mammo [22] and OPTIMAM [23]. The VinDr-Mammo\ndataset contains 20,000 images from 5,000 mammography studies with radiologists' assessment\nand lesion annotations but without further confirmation of cancer status. Each study contains"}, {"title": "Patch Pair Creation", "content": "Since the goal of our approach is to train networks in an unsupervised manner, a uniform grid\nsampling strategy is used to generate patches from whole mammograms without regard to lesion\nannotations. Directly training with whole mammograms is computationally prohibitive. Applying\nrandom transformation such as cropping on whole mammograms may also accidentally remove\nlesions, making an abnormal mammogram become normal. Additionally, a lesion's size is only a\nfraction of the size of an entire mammogram. Using patches allows models to pay attention to the\nfeatures of these lesions in greater detail. For these reasons, we only used patches for pretraining.\nThis is the same strategy adopted in a previous study [10].\nBefore sampling patches from a pair of bilateral mammograms, the two images need to be aligned\nwith each other. This can be done through image registration using the Python package SimpleITK\n[24]. First, bilateral images of the same view, CC or MLO, are registered to each other by flipping one\nimage and aligning it with the other. For abnormal pairs, the image with no region of interests (ROIs)\nis always the registered image in order to avoid needing to alter the bounding box coordinates. After\nimage registration, both images are then split into patches in a uniform grid fashion. We sampled\nsquare patches of sizes 96 \u00d7 96 and 256 \u00d7 256. A patch pair is defined as a pair of mammogram\npatches originating from the same location on the grid. Patch pairs containing more than 50%\nbackground pixels or major border disagreement due to image registration were dropped.\nApplying this process to both whole image datasets while using different grid patch sizes, results in\nfour patch pair datasets appropriately named by mother dataset and patch size: VinDr-96, VinDr-256,\nOPTIMAM-96, and OPTIMAM-256. From the VinDr dataset, 31,785 and 214,942 patch pairs of\nsizes 256 \u00d7 256 and 96 \u00d7 96, respectively, were sampled. From the OPTIMAM dataset, 47,444 patch\npairs of size 256 \u00d7 256 were sampled from 1,000 patients; similarly, 492,394 patch pairs of size\n96 \u00d7 96 from 1,000 patients."}, {"title": "Single Patch Datasets for SSL methods", "content": "Since the SSL methods use only single images as input, the patch pairs created above were split up\ninto individual patches. The SSL patch datasets are 63,570 single patches from the VinDr-256 dataset,\n429,884 patches from VinDr-96, 94,888 patches from OPTIMAM-256, and 984,788 patches from\nOPTIMAM-96. At patch level, all of these datasets are split into training, validation, and test sets at\nan 8:1:1 ratio."}, {"title": "Downstream Task Patch Datasets", "content": "After pretraining, all models are evaluated on several downstream tasks. We created labeled patch\ndatasets for these tasks. This requires sampling the abnormal patches using the bounding box\ncoordinates for each ROI. The abnormal patch of sizes 96 \u00d7 96 and 256 \u00d7 256 are directly sampled\nusing the center of the ROI. A background patch is sampled from the normal image at the same\nlocation as well. These patches are assigned appropriate labels depending on the downstream task.\nThe three downstream tasks are the binary classification of abnormal versus normal patches, BI-RADS\nclassification of VinDr patches, and outcome classification of OPTIMAM patches. On the VinDr\ndatasets, the abnormal class is defined as BI-RADS 3-5 and the normal class is defined as BI-RADS\n1. We ignored the BI-RADS 2. There are 1,126 patches in both the abnormal and normal classes\nfor a total of 2,252 patches in the labeled VinDr datasets. The breakdown of the BI-RADS labels\nin the abnormal class are 414 belonging to BI-RADS 3, 453 to BI-RADS 4, and 259 to BI-RADS\n5. On the OPTIMAM datasets, the abnormal class is defined as benign and malignant lesions and\nthe normal class is defined as background tissues with no overlap with any ROI. In the available\nsubset, there are 10,981 abnormal patches identified from screening mammograms and 10,981 normal\npatches containing background tissues. Of the patches in the abnormal class, 1,250 have a benign (B)\noutcome and 9,731 have a malignant (M) outcome.\nEvery dataset is split to training, validation, and test sets at an 8:1:1 ratio at patch level."}, {"title": "Experiments", "content": "Previous SSL methods tend to work better on larger batch sizes [12, 13]. We were curious if the\nSiamese network's performance is also affected by batch size. We performed a grid search on batch\nsizes, B \u2208 {64,128, 256, 512, 1028, 2048}, and learning rates, lr \u2208 {1.0 \u00d7 10\u22123, 1.0 \u00d7 10\u22124, 1.0 \u00d7\n10-5, 1.0 \u00d7 10-6,1.0 \u00d7 10-7}, and recorded the validation and test set performances. For every\ntraining on this grid search, the model was trained for 50 epochs at batch size B and two LARS\n(Layer-wise Adaptive Rate Scaling) [25] optimizers were used for both Siamese networks with\nlearning rate Ir. The LARS optimizer uses a separate adaptive learning rate for each layer in the\nnetwork. We excluded the batch normalization and bias parameters from this layer adaptation. Due\nto computational resource constraints, gradient accumulation was used to achieve batch sizes 512,\n1,024, and 2,048 with sub-batches of size 256.\nTo evaluate the performance of a Siamese network, a label of {abnormal, normal} needs to be\nassigned to a patch pair. However, there is no clear cut for an uniformly sampled patch pair. Each\npatch pair either has no overlap or partially overlaps with a ROI. Therefore, we define the abnormal\narea metric A \u2208 [0,1] as follows. Let (x1,x2) and (y1, y2) be the coordinates of a patch and\n(Xmin, Xmax) and (Ymin, Ymax) be the bounding box coordinates. The following equation calculates\nA:"}, {"title": "Siamese Network Patch Pair Training", "content": ""}, {"title": "Patch Pair Embedding Analysis", "content": "To further explore the Siamese networks' embeddings of these patch pairs, we use dimension reduction\nmethods to visualize the concatenated embeddings E (size=1024) on 2D plots. The pairs are colored\ndifferently based on the abnormal area metric A, with A = 0 being a normal pair, A \u2208 (0,0.5] being\nmodest overlap with ROI or A \u2208 (0.5, 1.0] being high overlap with ROI. This categorization helps\nus understand whether the networks are able generate meaningful embeddings that can distinguish\nlesions from normal tissues. We use two different methods to achieve this: t-Distributed Stochastic\nNeighbor Embedding (t-SNE) [26] and Uniform Manifold Approximation and Projection (UMAP)\n[27]. t-SNE tends to do well with preserving local structure while UMAP has the ability to preserve\nboth local and global structure in 2D projections.\nt-SNE is used to visualize the concatenated embeddings E of 10,000 patch pairs from each of the\npaired patch datasets in the two-dimensional space. The sklearn package [20] is used for t-SNE.\nFigure 5 shows the t-SNE plots of the sampled patch pairs from each patch pair dataset and their\ncorresponding label determined by A. In the VinDr-96 t-SNE plot in Figure 5b, there is a large\nclustering of samples with A > 0.5 in the lower half of the graph. There is also a gradual weaker\nassociation of samples with 0 < A < 0.5 above. Both of these clusters mostly overlap with each other\nbut show distinction with the normal class. Figure 5a shows more sporadic clustering of VinDr-256\npatch pair samples with A \u2260 0. Smaller clusters of samples with A > 0.5 and 0 < A < 0.5 can be\nobserved but there is no large cluster that represents the majority of the samples in the two classes.\nThough the OPTIMAM-96 patch dataset contains less abnormal patch pairs, Figure 5d demonstrates"}, {"title": "SSL Training", "content": "Two popular SSL methods were used as baselines for the proposed model: SimCLR and BYOL.\nWe used the same mammogram-specific transformations as in a previous study [10]: random crop"}, {"title": "Downstream Task Results", "content": "To evaluate the pretrained models, the standard linear evaluation protocol was used, i.e. froze the\nimage encoder's parameters and trained a linear classifier on the embeddings. For each Siamese\nnetwork model, there are two separate encoders trained in parallel. We added a linear classifier on\ntop of each encoder and used the average output as the ensemble's prediction. The linear classifiers\nfor the Siamese, BYOL, and SimCLR pretrained encoders were trained for 100 epochs at a batch\nsize of 32, a learning rate of 0.01, and weight decay of 10-5 with the Adam [28] optimizer. Three\ndownstream tasks were designed to evaluate the effectiveness of the pretrained models. The AUC for\nboth binary and multiclass classification tasks are reported. For calculating multiclass AUC, we adopt\nthe OvR strategy (one versus rest) to evaluate the models' ability to distinguish between multiple\nclasses. The OvR strategy involves treating each class as it's own binary classification task, where\nthe class of interest is the positive class and all others are the negative class. This allows us to analyze\nthe model's performance on each class as well as the overall average of the binary AUC scores across\nall classes."}, {"title": "Alternative Designs", "content": "An alternate loss function that can be used for Siamese Networks is the Triplet loss which was first\nintroduced in FaceNet [15]. The goal of the Triplet loss function is to minimize the distance between\nan anchor sample and positive samples, or similar instances, while maximizing the distances between\nthe anchor sample and negative samples, or different instances. The positive and negative pairs must\nalso maintain a certain distance apart denoted by margin, m. This setup requires prior knowledge\nabout the samples' labels in order to correctly designate these positive and negative pairs. In our\nunsupervised setting, the labels are unknown for the patch pairs in the training set. To accommodate\nthis, we used soft label P and 1 - P as weights on D to split it into the distances for the negative and\npositive pairs. That is, D+ = (1 - P) D represents the distance of a positive pair and D_ = P \u00b7 D\nrepresents the distance of a negative pair. After making the appropriate changes, the following loss\nfunction was used:"}, {"title": "Discussion and Conclusion", "content": "In this study, an algorithm that utilizes a Siamese neural network with soft labels is developed to\nassess the similarity of bilateral mammogram patch pairs without supervision. An encoder is trained\nwith the aim to generate the same embeddings for similar pairs and different embeddings for abnormal\npairs. A soft label is introduced for training these networks to deal with the lack of annotations.\nThis is derived by fitting a Gaussian mixture model on the Euclidean distances of the patch pair\nembeddings on a training set. We found that simultaneously training two Siamese networks where\nthe outputs were cross used in each other's loss functions showed the most success. These pretrained\nencoders can then be transferred for downstream tasks such as abnormal versus normal classification,\nBI-RADS classification, and outcome classification.\nSimCLR and BYOL are two SSL methods that were used to compare with our proposed model. On\nall downstream tasks, the Siamese networks outperformed or performed on par with the two SSL\nmethods. The Siamese network model shows great success in the binary abnormal versus normal\npatch classification task compared with the SSL pretraining methods. This performance is attributed\nto the design of the Siamese network pretraining to distinguish bilateral patch pairs. This is also\nsupported by the embedding analysis using t-SNE and UMAP, where the Siamese networks show the\nability to detect these abnormal patch pairs among an abundance of normal pairs. However these\nclusters are not perfect as it shows many normal pairs remain in these abnormal clusters, supporting\nthe prevalence of false positives identified by the model.\nWhen further evaluating model performance on more difficult classification tasks by splitting the\nabnormal class into more categories, we gained insight on the type of lesions the model can confidently\nidentify. In the BI-RADS classification task, of the abnormal classes BI-RADS 3-5, the Siamese\nnetworks are best at distinguishing lesions originating from BI-RADS 5 images. Also, in the\nOPTIMAM patient outcome classification task, the Siamese networks perform well in distinguishing\nmalignant patches from benign and background patches. This suggests that the Siamese network was\nable to learn features of malignant lesions without being explicitly given this information. Ideally, we\nwould also want the Siamese network to be able to detect less obvious lesions, as early detection is a\ncritical part of breast cancer survival [29].\nIt is important to note that data leakage might be a potential issue in these experiments. For datasets\nused in pretraining the split was done at patient level, while for datasets used in downstream tasks the\nsplit was done at patch level. Although the patches from the two sets don't overlap with each other\ndue to different sampling methods, studies from patients used in the training set of pretraining may\nappear in the test sets of downstream patch datasets.\nFurther research and potential applications of this work need to be explored. This study focuses in the\nscope of patch pretraining to patch classification. More complicated downstream tasks such as entire\nmammogram image classification can prove to be more applicable for a clinical use. Additionally,"}]}