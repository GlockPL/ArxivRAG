{"title": "A Hybrid Cross-Stage Coordination Pre-ranking Model for Online Recommendation Systems", "authors": ["Binglei Zhao", "Houying Qi", "Guang Xu", "Mian Ma", "Xiwei Zhao", "Feng Mei", "Sulong Xu", "Jinghe Hu"], "abstract": "Large-scale recommendation systems often adopt cascading archi-tecture consisting of retrieval, pre-ranking, ranking, and re-ranking stages. With strict latency requirements, pre-ranking utilizes lightweight models to perform a preliminary selection from massive retrieved candidates. However, recent works focus solely on improv-ing consistency with ranking, relying exclusively on downstream stages. Since downstream input is derived from the pre-ranking output, they will exacerbate the sample selection bias (SSB) issue and Matthew effect, leading to sub-optimal results. To address the limitation, we propose a novel Hybrid Cross-Stage Coordination Pre-ranking model (HCCP) to integrate information from upstream (retrieval) and downstream (ranking, re-ranking) stages. Specifi-cally, cross-stage coordination refers to the pre-ranking's adaptabil-ity to the entire stream and the role of serving as a more effective bridge between upstream and downstream. HCCP consists of Hy-brid Sample Construction and Hybrid Objective Optimization. Hybrid sample construction captures multi-level unexposed data from the entire stream and rearranges them to become the optimal guiding \"ground truth\" for pre-ranking learning. Hybrid objective optimization contains the joint optimization of consistency and long-tail precision through our proposed Margin InfoNCE loss. It is specifically designed to learn from such hybrid unexposed sam-ples, improving the overall performance and mitigating the SSB issue. The appendix describes a proof of the efficacy of the proposed loss in selecting potential positives. Extensive offline and online experiments indicate that HCCP outperforms SOTA methods by im-proving cross-stage coordination. It contributes up to 14.9% UCVR and 1.3% UCTR in the JD E-commerce recommendation system. Concerning code privacy, we provide a pseudocode for reference.", "sections": [{"title": "1 Introduction", "content": "Large-scale industrial recommendation systems typically employ cascade structures, consisting mainly of retrieval, pre-ranking, rank-ing, and re-ranking stages. The retrieval stage samples massive items (S1 ~ 105) and then pre-ranking selects a reduced set (S2 ~ 103). Afterward, they go through ranking and re-ranking stages, and ultimately, about ten items (S4 ~ 10) are chosen to be exposed, as shown in Figure1. Pre-ranking plays a pivotal role in recommen-dation systems, performing a preliminary selection from large-scale retrieval candidates and distilling an optimal subset for ranking. To strike an optimal balance between effectiveness and efficiency, pre-ranking typically adopts vector-product-based models [9, 22]."}, {"title": "2 Related Work", "content": "We briefly describe three aspects of research: pre-ranking, learning-to-rank algorithms, and sample selection bias issue.\nPre-ranking. In industrial recommendation systems, pre-ranking plays a vital role in selecting high-quality items from large-scale retrieval items and relieving ranking pressure. To balance effective-ness and efficiency, it widely adopts a vector-product-based deep neural network model[9, 22]. However, lightweight model architec-tures degrade the model expression ability. For critical calibration ability, recent works design model architectures to improve effec-tiveness under a computing power constraint, such as COLD[31], FSCD[19], and IntTower [13]. Some works [23, 33] focus on knowl-edge distillation. Despite some advancements, they optimize the pre-ranking model as an independent entity, neglecting the consis-tency with ranking, leading to sub-optimal outcomes. For ranking ability, some methods[7, 26] propose the importance of improving the consistency with ranking. Some works propose strict score alignment via point-wise distillation loss [27, 37], MSE loss [24], or ListNet distillation loss[8] to align with raw scores predicted by ranking. COPR[38] proposes a rank alignment module and a chunk-based sampling module to optimize the consistency with ranking. However, they treat all items equally, neglecting accuracy discrep-ancies between head and tail items predicted by ranking. Moreover, pre-ranking has larger-scale candidates than ranking and the only utilization of ranking logs can not adapt to changes in retrieval distribution, leading to a sample selection bias problem.\nLearning-To-Rank (LTR) Algorithm. LTR algorithms are ex-tensively used to enhance ranking abilities by approximating rele-vance degree, which can be categorized into point-wise, pairwise, and listwise. Point-wise[4] approaches usually treat ranking as regression or classification problems, which assign score for each item independently. Considering mutual information, pairwise [1, 6] methods achieve local optimality by predicting relative orders of item pairs but ignoring the overall order. Listwise methods [2, 3, 32] consider the entire sequence quality from a global perspective, align-ing with ranking objectives. To preserve calibration and ranking quality, some studies combine the above losses [25, 34].\nSample Selection Bias (SSB) Problem. As the magnitude of re-trieval items increases, SSB issues[35] in pre-ranking receive grow-ing attention. Some works sample negatives through a pre-defined distribution[20] or in-batch sampling mechanisms[5, 10]. Since the diversity of negatives sampled by in-batch methods is constrained"}, {"title": "3 METHODOLOGY", "content": "In this section, we present Hybrid Cross-Stage Coordination Pre-ranking Model (HCCP). As outlined in Section 3.2, we construct hybrid multi-level samples from the entire stream. To leverage the strength of sampled unexposed information, we propose a hybrid object optimization approach in Section 3.3, designed for flexible adaptation across various pre-ranking models."}, {"title": "3.1 Overall Architecture", "content": "3.1.1 Base Model. To balance efficiency and effectiveness, we design pre-ranking based on the Three-Tower[31] paradigm, which includes user, item, and cross-feature towers. An MMOE[18] archi-tecture is implemented on the user-side tower to facilitate multi-task learning. Traditional multi-objective estimation tasks usually serve as calibration tasks, adopting binary cross-entropy (BCE) loss on impressions (exposed items). The loss $L_t$, is defined as:\n$L^{cali}_t = -\\frac{1}{|U|}\\sum_{u\\in U}\\sum_{j=1}^{R_u} [l^u_jlog(\\hat{y}^u_j) + (1-l^u_j)log(1 - \\hat{y}^u_j)]$  (1)\n, where $\\hat{y}$ and $l$ are predicted score and corresponding label of item $j$ in task $t$. $R^u$ is the impression set and $U$ is the user request set. Item embeddings are pre-computed and updated in near real-time. Upon online request, user embedding and cross-feature scores are calculated in real-time. Scores are computed by dot-product across user and item embeddings, weighted with cross-feature scores.\n3.1.2 Innovation. To alleviate the SSB issue and improve preci-sion, we employ a hybrid sampling technique that captures multi-level data from downstream and upstream stages of pre-ranking. Since unexposed samples are not associated with user feedback, we introduce an optimal hybrid objective optimization approach specif-ically tailored for such instances. By explicitly integrating entire stream information, pre-ranking achieves cross-stage coordination and becomes a more suitable bridge between retrieval and ranking,"}, {"title": "3.2 Hybrid Multi-level Sample Construction", "content": "Except for clicked or purchased items as positives and un-clicked or un-purchased as negatives in impressions (N1), we collect various samples from downstream and upstream stages by online serving and offline sampling to enhance precision and alleviate SSB issues:"}, {"title": "3.2.1 Ranking Sequence", "content": "The ranking sequence provides feed-back information predicted by downstream stages, which can help to enhance consistency and precision. To construct the optimal guid-ing \"ground truth\" ranking candidates conducive to pre-ranking training, we implement a non-uniform sampling paradigm and re-arrange them according to exposure information and user feedback.\nNon-uniform Sampling Strategy. Ranking models typically optimize the precision of impressions and neglect tail items [11, 14], leading to long-tail items being lower, yet they may align with user interests. Directly learning scores or orders predicted by ranking cannot achieve optimum efficiency due to inaccurate predictions of tail items[37]. Thus, it is necessary to prevent long-tail bias and ensure pre-ranking's accuracy for long-tail items is not affected by orders predicted by ranking. Considering accuracy discrepancies between top and tail items of ranking, we design the non-uniform sampling strategy assigning higher sampling rates to high-ranked (top) items and lower rates to low-ranked (tail) items. In each re-quest of user $u$, pre-ranking delivers top $N'$ items to ranking. We denote $R'$ as sorted ranking sequence with ranking orders.\n$R = [(u, r_1, e_1, l_1), ..., (u, r_{N_r}, e_{N_r}, l_{N_r})], (r_1 < ... < r_{N_r})$\n, where r is the ranking order, e and l are one-hot exposure and a vector of task labels, such as click or purchase [clk, [ord. [clk = 1 or e = 1 mean item is clicked or exposed, while $l^{clk}$ = 0 and e = 0 indicate the opposite. Items with smaller r are sorted to the front. Then we map the original ranking sequence to m chunks with different sample rates $s_j$, which is illustrated in Figure3 and Eq 2.\n$s_j = \\begin{cases}\nS_1 & \\text{if } 1 \\leq r_j < N,\\\\\n... & : \\\\\nS_m & \\text{if } N_{m-1} \\leq r_j \\leq N\n\\end{cases}$      (2)"}, {"title": "3.2.2 Pre-ranking Sequence with Latter Order", "content": "Retrieval stages provide NP items to pre-ranking, in which top $N'$ items are de-livered downstream. We denote $R^P$ as pre-ranking sequence with latter pre-ranking order.\n$R^P = [(u, l_1), ..., (u, l_j)..., (u, l_{N^P-N'})], (1 \\leq j \\leq N^P \u2013 N')$\nIt captures items not entering the ranking and exposed. Although they belong to hard negatives, they may still contain a wealth of information and match user interests, including potential positives to some extent. The sampled pre-ranking sequence $B^P$ is randomly sampled from the original sequence $R^P$ as a fixed sample rate. They are usually discarded in previous pre-ranking training. However, we can incorporate them into training through contrastive learning. It improves the ability to distinguish hard negatives especially when upstream stages provide long-tail items during online service."}, {"title": "3.2.3 In-batch Negatives", "content": "We sample unexposed negatives by employing a list-wise in-batch sampling method within impressions of other users. They usually act as easy negatives to achieve popular item suppression, which is described as the \"gold negative\" in [10].\nThe initial set to be scored is the intersection of impressions $R^t$, ranking $B^r$ and pre-ranking negatives $B^P$. As illustrated in figure5, for estimation task $t$, the list-wise in-batch negative sampling is achieved as following steps: (1) Reshape predicted item embeddings $\\hat{I}$ into a shape of ($|U| * |R^t \\cup B^r \\cup B^P|$, d), where |U| is request numbers in a batch and d is the embedding dimension. (2) Apply a transpose operation on $\\hat{I}$ to the shape of (d, $|U| * |R^t \\cup B^r \\cup B^P|$). (3) Perform a cross product on user embedding $\\hat{U}_{|U|\\times d}$ and item embedding $\\hat{I}_{d\\times|U|*|R^t\\cup B^r \\cup B^P|}$ to obtain negative score tensor $\\hat{N}_{|U|\\times |U|*|R^t\\cup B^r \\cup B^P|}$. (4) For user u, mask negative scores that be-long to corresponding item collection $R^t$, $B^r$, $B^P$ and sample final in-batch negatives $B^i$ from $\\hat{N}$. To reduce the computational complex-ity, the cross product is calculated on item embedding $\\hat{I}_{|U|\\times |R|\\times d}$ of exposure sequence $R^t$. Compared to traditional in-batch sam-pling, whose diversity is determined by batch size |U|, while the magnitude of negatives in list-wise in-batch sampling is |U|\u00d7 |R|, which helps to improve the diversity of unexposed negatives.\n3.2.4 Pool Sampling Negatives. Such negatives $B^0$ are randomly sampled from the item pool space, usually containing items that have not been retrieved, which can be regarded as easy negatives. When upstream expands the retrieval magnitude and provides mas-sive unseen items when online serving, introducing this kind of negatives can improve the pre-ranking's discriminative ability."}, {"title": "3.3 Hybrid Objective Optimization", "content": "3.3.1 Consistency with Downstream Learning. To improve pre-ranking's consistency with downstream, we design a global consistency task on ranking sequence space and a local consis-tency module on exposure space. It achieves a soft alignment with downstream, which helps to obtain the ranking ability of complex ranking models, further improving the precision.\n(1) Global Consistency: It enables pre-ranking to optimize the ranking ability by approximating downstream from a global perspective. In Figure2B, the global consistency loss is designed based on ListMLE loss[32] to explicitly learn ranking sequence order $R^0$, which provides consideration of global orders while pair-wise loss considers only relative order. The loss $L^G$ is defined as:\n$L^G = - \\frac{1}{|U|}\\sum_{u\\in U}\\sum_{j=1}^{|R^0|} log\\frac{exp(\\hat{y}^u_j)}{\\sum_{k} exp(\\hat{y}^u_k)}$    (3)\nwhere $\\hat{y}$ is the predicted score of item $j$ in global consistency task. Minimizing $L^G$ makes each item in the sequence $R^0$ have the highest top-one probability in the subsequence with latter order.\n(2) Local Consistency in Cxr Estimation: For Cxr estimation tasks (Ctr, Cvr, ...), we integrate traditional calibration task with"}, {"title": "3.3.2 Long-tail Precision Optimization", "content": "In cascade recommen-dation systems, given that downstream input is derived from the pre-ranking output, relying only on the downstream will limit the pre-ranking model, which may further aggravate the Matthew ef-fect. Since pre-ranking serves as a bridge between retrieval and ranking stages, it is necessary to strengthen the ranking ability and precision of mid and long-tail items and provide high-quality items to downstream. Expect N1, samples N2 ~N5 extracted from the entire stream can alleviate the SSB issue but typically lack user feedback. To leverage these unexposed samples, we introduce an effective approach for negative learning from the perspective of contrastive learning. We propose the Margin InfoNCE loss to incorporate priors about hard or easy negatives into learning, which helps identify unexposed potential positives and negatives. As illustrated in Figure2C, cxr estimation tasks integrate traditional calibration and local consistency with negative contrastive learning. It enhances pre-ranking's adaptability to upstream and guarantees robust discriminative capacity when upstream provides massive long-tail items. In the Appendix, we provide an analysis of how the proposed loss distinguishes potential positives from hard negatives.\nMargin InfoNCE Loss. Different categories of negatives above vary in their levels of difficulty. Group N1 is usually top-ranked downstream and has a definite selection tendency from users, we directly utilize the BCE loss on them, as described in Section 3.1.1. Unexposed samples in N2 ~N3 are retrieved due to their relevance with the user, but they are ranked lower by downstream or pre-ranking models. Although they have not been exposed, they contain potential positive samples. Introducing these hard negatives helps to improve the ability to distinguish difficult samples. Negatives in N4 ~N5 typically lack direct relevance or interest alignment with users, classified as easy negatives. Although they are both easy negatives, there are subtle differences in effects: introducing N4 can suppress popular items and relieve the Matthew Effect, while N5 in-troduces massive unseen items, which helps improve discrimination ability, especially when retrieval magnitude increases.\nCompared to hard negatives that may contain potential posi-tives, easy negatives are less aligned with user preferences, hence, their distance from positives needs to be sufficiently large. Some traditional losses do not explicitly differentiate between types of negatives. Inspired by InfoNCE[21] and Margin Softmax [16, 17, 28] losses that explicitly encourage discriminative feature learning to reduce intra-class variation and increase inter-class difference, we propose the Margin InfoNCE loss to explicitly differentiate between positives, hard (N2 ~N3), and easy negatives (N4 ~N5), as defined:"}, {"title": "4 EXPERIMENT", "content": "We conduct a series of offline experiments on public Taobao\u00b9 and JD production datasets and online A/B testing to evaluate the effec-tiveness of our method. We aim to answer the following questions:\n\u2022 Q1: Does HCCP enhance the overall performance and serve as a suitable bridge between retrieval and ranking stages?\n\u2022 Q2: How does each learning objective perform in performance?\n\u2022 Q3: Does HCCP have an advantage over previous methods in mitigating the mid and long-tail bias issue?\n\u2022 Q4: Does the complexity of HCCP adapt to industrial systems?"}, {"title": "4.1 Experiment Setup", "content": "4.1.1 Dataset. Public Taobao Dataset contains 26 million expres-sion logs in 8 days. We utilize DIN[39] as the ranking model to guide the learning of pre-ranking methods. Note that the public dataset lacks multi-level unexposed data, causing a significant gap between simulation and industrial systems for methods Rethink[37] and ours. JD Production Dataset contains sampled data from the entire stream of clicked requests in one week on the JD homepage. The request amount for training is the magnitude of billions. The validation is conducted on pre-ranking candidates from one day that occurred one week later.\n4.1.2 Metrics. The model performance is evaluated on the metrics. Offline metrics: 1) Traditional AUC metrics reflect ranking abilities on impressions (top items). Considering that the public dataset contains only impressions, we use AUC to evaluate the performance. Due to inherent bias in historical impressions, AUC is difficult to align with online performance.\n2) Since pre-ranking aims at distilling an unordered optimal subset, we follow in-scenario click/purchase hitrate (ISH, ISPH) and all-scenario click/purchase (ASH, ASPH) described in [37] to measure the quality of topK items selected by pre-ranking.\n3) Mean average precision (MAP@K) and normalized discounted cumulative gain (NDCG@K)[15] metrics can measure the consis-tency with ranking. However, consistency with ranking does not fully measure the performance of pre-ranking, which is analyzed in the experimental section. In the JD production dataset, we use topK (K=10,100,1000) candidates selected by ranking as relative ground-truth values. Due to the insufficient accuracy of ranking for tail items, we do not measure the tail set consistency (K=2000).\nOnline metrics: In the JD E-commerce recommendation system, UCTR (click PV/exposure UV) and UCVR (purchase PV/exposure UV) are used for online performance evaluation."}, {"title": "4.1.3 Baselines", "content": "Baseline methods are divided into 3 groups: G1, using only impressions; G2, using impressions with ranking orders; G3: using impressions and other unexposed samples. And we design multi-versions of HCCP for ablation studies. (1) Base (G1) adopts an MMoE architecture [18] and is trained on exposures by point-wise binary cross-entropy (BCE) loss.\n(2) Base+ListNet (G1) implements a ranking and calibration joint optimization method through BCE classification loss and List-Net losses [3] based on the base MMoE model.\n(3) Base+ListMLE (G2) employs listMLE [32] and BCE losses to improve ranking ability by training on impressions with ranking orders. It can be seen as HCCP with only local consistency tasks.\n(4) COPR[38] (G3) implements a relaxation net, and CTR, pair-wise consistency, regularization losses using ranking candidates. We modify the underlying model to MMoE for a fair comparison.\n(5) Rethink[37] (G3) achieves a list-wise loss on impressions, ranking, and pre-ranking candidates and a distillation loss on im-pressions with predicted CTR, which provides a hard consistency alignment. This paper describes ASPH and online GMV drop when distillation extends to all ranking candidates.\n(6) HCCP (G3) implements some different versions of HCCP.\n\u2022 HCCP(w/o Up) improves consistency through a global consis-tency task, without N2~N5 samples in estimation tasks.\n\u2022 HCCP(w/o PRC) achieves an InfoNCE loss only on in-batch negatives and pool sampling negatives without ranking and pre-ranking candidates N2~N3 based on HCCP(w/o Up).\n\u2022 HCCP(w/o Neg) uses the InfoNCE loss on candidates N2~N3 without sampled negatives N4~N5 based on HCCP(w/o Up).\n\u2022 HCCP(w/o Margin) uses InfoNCE loss instead of our margin In-foNCE loss on N2~N5 samples. There is no explicit discrimination between N2~N3 (hard negatives) and N4~N5 (easy negatives).\n\u2022 HCCP(Ours) is the final version described in this paper."}, {"title": "4.2 Offline Performance Comparison (Q1)", "content": "4.2.1 Performance on Taobao Dataset. Although introducing only impressions with ranking orders, HCCP achieves a slight improve-ment, as illustrated in Table2. Since the public dataset lacks unex-posed data, Table2 can not fully reflect differences between Rethink and HCCP, we conduct experiments on JD production dataset."}, {"title": "4.3 Online A/B Test", "content": "We conduct the A/B test on JD homepage recommendation system for 7 days. HCCP achieves a 14.9% increase in UCVR and 1.3% in UCTR, which is deployed online to serve main user traffic. Among them, HCCP(w/o Up) with consistency modeling contributes up to 7.1% UCVR and 0.6% UCTR, and the inclusion of long-tail precision optimizing on multi-level samples provides an additional 7.8% to UCVR and 0.7% UCTR. Moreover, we analyze the CTR and CVR improvement of items with different frequencies in Figure6. When HCCP is deployed in JD system, there is a notable trend that mid and tail items have a significant improvement in CVR. The phenomenon elucidates the more pronounced enhancement observed in UCVR, underscoring the efficacy of optimization long-tail precision."}, {"title": "4.4 Futher Analysis", "content": "4.4.1 Ablation studies (Q2). Ablation studies conduct to evaluate the effectiveness of each objective in joint optimization. Results are displayed beneath the dashed lines in Table1 and Table3.\n(1) The Importance of Local Consistency in Cxr Estimation Tasks. Slight improvement on Base+ListNet compared with Base indicates that incorporating ranking orders of impressions (local consistency) can enhance pre-ranking accuracy to some extent.\n(2) The Importance of Global Consistency. HCCP(w/o Up) trains global consistency on the ranking sequence of both exposed and unexposed data based on Base+ListNet, which achieves an enhancement across all metrics. It significantly outperforms COPR on consistency metrics, demonstrating the efficiency of ListMLE loss for order learning from a global perspective in learning-to-rank.\n(3) The Importance of Hybrid Samples in Long-tail Preci-sion Optimization. We validate the impact of easy (N4~N5) and hard (N2~N3) negatives through two experiments, designated as HCCP(w/o PRC) and HCCP(w/o Neg). N2~N5 samples are impor-tant, however, directly incorporating them cannot maximize utility; for instance, HCCP(w/o Margin) leads to a performance or consis-tency decline on ISP@1000, ISPH@1000, and ASPH@2000, which is due to the introduction of hard negatives. Thus we propose the Mar-gin InfoNCE loss to distinguish these negatives explicitly. However,"}, {"title": "5 CONCLUSION", "content": "We propose HCCP, a hybrid pre-ranking model to improve cross-stage coordination within the entire stream, jointly optimizing consistency and long-tail precision through multi-level sample con-struction and hybrid objective optimization modules. It outperforms SOTA methods, contributing up to 14.9% UCVR and 1.3% UCTR within 7 days of deployment in the JD E-commerce recommenda-tion system. In future work, we will extend the training data to all scenarios with all-scenario positive feedback information."}, {"title": "A Appendix", "content": "We analyze the ability of the proposed Margin InfoNCE loss to dis-criminate potential positives from hard negatives. In formal binary cross-entropy (BCE) calibration tasks, unclicked impressions that reflect a clear user's tendency not to choose are seen as negatives. We calculate the derivative of BCE loss to the predicted score y.\n$L_{BCE} = -l_jlog(s_j) \u2013 (1 \u2013 l_j)log(1 \u2013 s_j)$  (7)\n$s_j = sigmoid(y_j) = \\frac{1}{1+e^{-Y_j}}$\n$\\frac{\\partial L_{BCE}}{\\partial y_j} = \\frac{1}{1+e^{-yj}} - l_j$  (8)\nWhen j is a negative sample, $l_n = 0$, $\\frac{\\partial L_{BCE}}{\\partial y_n} = \\frac{1}{1+e^{-y_n}}$. We calculate the derivative of the Margin InfoNCE loss to the predicted score y.\n$L_M = -log\\frac{e^{\\upsilon\\phi(\\theta)/\\tau}}{e^{\\upsilon\\phi(\\theta)/\\tau} + \\sum_{i=1}^{|B^h|}e^{Y_i/\\tau} +  \\sum_{k=1}^{|B^e|}e^{Y_k/\\tau}} = -log\\frac{e^{\\frac{y_j - m(\\upsilon_j-\\upsilon_n)}{\\tau}}}{\\sum_{i=1}^{|B^h|}e^{\\frac{Y_i - m(\\upsilon_j-\\upsilon_i)}{\\tau}}  + 2\\sum_{k=1}^{|B^e|}e^{\\frac{Y_k-y_n+m(\\upsilon_j-\\upsilon_n)}{\\tau}}}$  (9)\n$\\frac{\\partial L_M}{\\partial y_n} = \\frac{1}{e^{\\frac{y_j - m(\\upsilon_j-\\upsilon_n)}{\\tau}} + \\sum_{i=1}^{|B^h|-1}e^{\\frac{Y_i - m(\\upsilon_j-\\upsilon_i)}{\\tau}} + 2\\sum_{k=1}^{|B^e|}e^{\\frac{Y_k-y_n+m(\\upsilon_j-\\upsilon_n)}{\\tau}}} \\frac{e^{\\frac{Y_n-m(\\upsilon_j-\\upsilon_n)}{\\tau}}}{\\tau}$ (10)\nWhen the same negative sample $y_n$ is optimized using different loss functions $L_{BCE}$ and $L_M$, the corresponding gradients can be approximated as $g(y_n)$ and $f(y_n)$ as Eq11, respectively. We show them with different parameters in Figure8, where q and c control the left and right movement of the entire $f(y_n)$ function along the x-axis, and t and c control the function's slope.\n$f(y_n) = \\frac{1}{\\tau\\left(1+ce^{(q-y_n)/\\tau}\\right)}$\n$g(y_n) = \\frac{1}{1+e^{(-y_n)}}$ (11)"}]}