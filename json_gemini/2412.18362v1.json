{"title": "Point-DeepONet: A Deep Operator Network Integrating PointNet for Nonlinear Analysis of Non-Parametric 3D Geometries and Load Conditions", "authors": ["Jangseop Park", "Namwoo Kang"], "abstract": "Nonlinear structural analyses in engineering often require extensive finite element simulations, limiting their applicability in design optimization, uncertainty quantification, and real-time control. Conventional deep learning surrogates, such as convolutional neural networks (CNNs), physics-informed neural networks (PINNs), and fourier neural operators (FNOs), face challenges with complex non-parametric three-dimensional (3D) geometries, directionally varying loads, and high-fidelity predictions on unstructured meshes. This work presents Point-DeepONet, an operator-learning-based surrogate that integrates PointNet into the DeepONet framework. By directly processing non-parametric point clouds and incorporating signed distance functions (SDF) for geometric context, Point-DeepONet accurately predicts three-dimensional displacement and von Mises stress fields without mesh parameterization or retraining. Trained using only about 5,000 nodes (2.5% of the original 200,000-node mesh), Point-DeepONet can still predict the entire mesh at high fidelity, achieving a coefficient of determination (R2) reaching 0.987 for displacement and 0.923 for von Mises stress under a horizontal load case. Compared to nonlinear finite element analyses that require about 19.32 minutes per case, Point-DeepONet provides predictions in mere seconds-approximately 400 times faster while maintaining excellent scalability and accuracy with increasing dataset sizes. These findings highlight the potential of Point-DeepONet to enable rapid, high-fidelity structural analyses, ultimately supporting more effective design exploration and informed decision-making in complex engineering workflows.", "sections": [{"title": "1. Introduction", "content": "The simulation of complex physical systems is fundamental in engineering and scientific research, enabling the analysis and prediction of phenomena such as structural deformations, fluid dynamics, and thermal processes. High-fidelity numerical methods like the finite element method (FEM) have traditionally been employed to achieve accurate results in these simulations. However, when dealing with nonlinear material behaviors, complex three-dimensional (3D) geometries, and varying boundary conditions, these methods become computationally intensive and time-consuming. In particular, nonlinear analyses require iterative solutions of nonlinear equations and fine discretizations to capture localized effects, which further increase computational demands.\nThe significant computational demands inherent in simulating complex physical systems present major challenges for applications requiring rapid evaluations across numerous scenarios, such as real-time control, design optimization, uncertainty quantification, and inverse problem solving. Traditional surrogate models based on neural networks often predict solutions only at predefined mesh nodes or within limited parameter ranges. Consequently, even minor variations in inputs\u2014such as changes in loads, boundary conditions, or domain geometry-typically require expensive retraining or transfer learning processes. This limitation underscores the urgent need for more efficient surrogate models that can accurately approximate the behavior of complex physical systems while reducing computational costs and enhancing the ability to generalize to previously unseen cases.\nTo meet these requirements, various deep learning architectures have been explored for surrogate modeling in computational mechanics. Among them, Convolutional Neural Networks (CNNs) have been widely adopted due to their ability to capture spatial hierarchies in data. In the context of surrogate modeling for physical simulations, CNNs are typically applied to regular grid data or transformed representations of computational domains. For example, some studies have converted irregular geometries into regular grids or images to leverage CNN architectures for flow predictions and structural analyses [1, 2]. However, CNNs face significant limitations when dealing directly with unstructured meshes and irregular geometries typical in FEM discretizations. Their grid-based nature makes it challenging to process complex 3D geometries without introducing interpolation errors or losing geometric fidelity. Moreover, representing intricate 3D domains with regular grids often results in high-dimensional inputs and computational inefficiencies.\nTo address the challenges posed by irregular geometries, PointNet [3] was introduced. PointNet processes point cloud data directly, treating sets of 3D points as inputs and extracting global features through shared multilayer perceptrons (MLPs) combined with symmetric aggregation functions (e.g., max pooling). This approach captures the geometric information of complex shapes without relying on structured grids or mesh connectivity. However, while PointNet effectively encodes global geometric features, it does not explicitly model local or hierarchical structures.\nPointNet++ [4] extends PointNet by introducing a hierarchical feature learning architecture. By recursively applying PointNet on nested subsets of points and using metric space distances to group points into local regions, PointNet++ learns local features at multiple scales. This hierarchical approach enhances its ability to represent intricate geometries and makes PointNet++ more effective for tasks such as semantic segmentation and object part segmentation.\nGraph neural networks (GNNs) have also been proposed to leverage the connectivity inherent in mesh-based representations. Graph neural networks (GNNs) treat mesh nodes as graph vertices and elements or edges as connections, capturing both geometric and topological information [5, 6, 7]. They have shown success in modeling variable geometries by facilitating information propagation among connected nodes and have been applied to various engineering problems, including structural analysis and fluid dynamics. However, as the number of mesh nodes grows, GNNs face reduced computational efficiency, limiting their scalability for large-scale problems.\nPhysics-informed neural networks (PINNs) have been introduced to solve partial differential equations (PDEs) by embedding governing physical laws directly into the loss function [8]. Physics-informed neural networks (PINNs) leverage both data and physics to predict solution fields without requiring extensive labeled datasets. Despite their promise in accurately solving various PDEs, PINNs are typically tailored to single instances of geometries and boundary conditions. Changes in these factors often require retraining, reducing PINNs' flexibility and scalability in scenarios where multiple geometries or dynamic loading conditions must be considered [9, 10, 11].\nTo address the limitations of these methods, operator learning has emerged as a promising new direction. Operator learning aims to approximate governing operators via neural networks [12], thus enabling broader applicability without retraining for every new parameter set. A prominent operator learning framework, the fourier neural operator (FNO), introduced by Li et al. [13], encodes input functions through multiple Fourier layers. Each layer applies a Fast Fourier Transform (FFT) and filters out high-frequency modes. The fourier neural operator (FNO) and its variants have been successfully applied to various differential equations [13] and elastoplastic deformation problems in mechanics [14]. However, because FNOs are typically formulated on regular grids, their direct applicability to irregular or complex geometries is limited. Although extensions to handle irregular domains exist [14], they often require additional preprocessing or mesh mapping.\nDeep operator networks (DeepONets), developed by Lu et al. [15], mark a significant advancement in operator learning. Inspired by the universal approximation theorem for operators [16], deep operator networks (DeepONets) map unseen parametric functions to solution spaces for both linear and nonlinear PDEs. Since their inception, DeepONets have been applied to materially nonlinear solid mechanics [17, 18], fracture [19], aerodynamics [20], acoustics [21], heat transfer [22, 23], seismology [24], and multiscale modeling of elastic and hyperelastic materials [25]. Improvements such as physics-informed DeepONet [26] enhance prediction accuracy by incorporating PDE constraints, while s-DeepONet [27] handles time-dependent inputs. Recent work has integrated ResUNet architectures into DeepONet [28], enabling the handling of complex and highly disparate two-dimensional input geometries under parametric loads and elastoplastic material behavior.\nDespite these advances, most DeepONet-based approaches remain limited to regular grids, parameterized geometries, or simpler variations in loading conditions. To address these gaps, He et al. [29] introduced Geom-DeepONet, a point-cloud-based DeepONet capable of field predictions on 3D parameterized geometries. By processing point clouds directly, Geom-DeepONet enables predictions on complex 3D shapes. However, it still relies on parameterized geometries and, although it considers variations in load magnitude, does not handle more intricate changes such as load directionality. Consequently, its applicability to non-parametric geometries and directionally varying load conditions remains limited.\nIn this work, we present Point-DeepONet, a novel neural network architecture that seamlessly integrates PointNet into the DeepONet framework. This integration enables fully nonlinear analyses on non-parametric 3D geometries under both magnitude- and direction-varying load conditions, without relying on explicit parameterizations or mesh connectivity. By incorporating PointNet into the branch network, our model encodes complex geometric information from point clouds, facilitating generalization to a wide variety of shapes. Additionally, an auxiliary branch network is introduced to incorporate global physical parameters such as boundary conditions and mass. Combining these global inputs with the geometric encoding from PointNet allows our model to capture local geometric details and the influences of varying boundary conditions, enabling accurate predictions in nonlinear analyses.\nTo the best of our knowledge, this is the first operator learning-based surrogate model capable of performing fully nonlinear analyses on non-parametric three-dimensional domains while accommodating both magnitude and directional variations in load conditions. Our proposed Point-DeepONet offers several key advantages:\n1.  Flexible handling of non-parametric 3D geometries: By integrating PointNet, our approach directly processes arbitrary three-dimensional domains represented as point clouds. This flexibility eliminates the need for parameterizations or regular grids, thereby facilitating the modeling of complex, non-parametric geometries.\n2.  Versatile adaptation to varying load conditions: Unlike existing methods such as Geom-DeepONet [29], our model seamlessly accommodates both changes in load magnitude and direction. As a result, it can be readily applied to a broad range of engineering scenarios with non-uniform and evolving loading conditions.\n3.  High-fidelity field predictions at the source mesh: Our model predicts essential field variables, including displacement components (ux, uy, uz) and von Mises stress, directly on the original finite element mesh. This approach ensures precise, high-resolution outputs and minimizes the need for additional interpolation or reprocessing.\n4.  Reduced computational overhead: By learning operator mappings that generalize across multiple configurations, Point-DeepONet mitigates the necessity for repetitive mesh generation and re-analysis. Consequently, the computational cost and complexity associated with exploring diverse design spaces are significantly lowered.\n5.  Accelerated decision-making processes: Through its ability to capture intricate geometric details and boundary condition variations, our framework enables swift evaluations of numerous design alternatives. This expedited analysis supports more informed decision-making in shorter timeframes, enhancing overall engineering productivity.\n6.  Robust scalability with increasing data and complexity: As demonstrated in subsequent sections, our model's performance and efficiency improve with larger datasets and more sampling points. This scalability ensures that Point-DeepONet remains effective even as problem sizes and design spaces continue to grow, making it a durable solution for evolving engineering challenges.\nOur work is inspired by He et al. [28], who integrated a ResUNet-based branch network into DeepONet for complex elastoplastic deformations in two-dimensional structures. By extending their concept to three dimensions and leveraging PointNet, we significantly advance the capability to model nonlinear phenomena on non-parametric 3D geometries under complex, directionally varying load conditions.\nIn Section 2, we present the methodology, including data generation, data preprocessing, and the proposed neural network architecture (Point-DeepONet) that integrates PointNet into DeepONet for handling nonlinear material behaviors. Section 3 then reports and discusses the numerical experiment results, demonstrating the effectiveness of the proposed model in predicting displacement and von Mises stress fields for nonlinear problems. Finally, Section 4 concludes the paper by summarizing the main findings, addressing current limitations, and suggesting avenues for future work."}, {"title": "2. Methodology", "content": "We utilize the DeepJEB dataset [31], a synthetic dataset specifically designed for 3D deep learning applications in structural mechanics, focusing on jet engine brackets. This dataset includes various bracket geometries subjected to different load cases\u2014vertical, horizontal, and diagonal\u2014providing a diverse range of scenarios to train and evaluate deep learning models for predicting field values. While the original DeepJEB dataset offers solutions from linear static analyses, in this study we extend its applicability by performing our own nonlinear static finite element analyses to predict displacement fields (ux, uy, uz) and von Mises stress under varying geometric and loading conditions.\nFinite element analyses (FEA) are conducted using Altair OptiStruct [32] to simulate the structural response under nonlinear static conditions. Each bracket geometry is discretized using second-order tetrahedral elements with an average element size of 2 mm, enhancing the precision of the displacement and stress predictions. The material properties for the brackets are based on Ti-6Al-4V, specified with a density of 4.47\u00d710-3 g/mm\u00b3, a Young's modulus (E) of 113.8 GPa, and a Poisson's ratio (v) of 0.342, representing realistic behavior under the applied loads.\nAn elastic-plastic material model with linear isotropic hardening is employed to capture the nonlinear response, characterized by a yield stress of 227.6 MPa and a hardening modulus of 355.56 MPa. The nonlinear analysis settings include a maximum iteration limit of 10 and a convergence tolerance of 1%, ensuring accurate simulation of the structural response to complex loading conditions.\nThe distribution of the dataset across load case directions and the FE analysis time are illustrated based on dataset size.\nThe total dataset size used in this study is 3,000, with 969 vertical, 1,009 horizontal, and 1,022 diagonal load cases. There are 1,785 unique geometries across these cases. Each bar corresponds to a mixed dataset size, with the count in parentheses representing the unique geometries, clarifying how dataset composition varies with respect to load case directions. Furthermore, in Section 3.3, we investigate the influence of dataset size by progressively reducing it and comparing the resulting performance and training time of the deep learning models.\nThe computational time for each load case direction varies due to differences in structural responses. The experiments were conducted on a system equipped with an AMD EPYC 9654 processor featuring 96 cores and 192 threads, ensuring that the analysis tasks could be efficiently distributed across multiple parallel processing units. As shown in Figure 2b, for vertical load cases, the elapsed time ranges from a minimum of 6.07 minutes to a maximum of 80.45 minutes, with an average time of 16.23 minutes. Horizontal load cases show a broader time range, from 3.87 minutes to 122.57 minutes, with a mean of 20.89 minutes. Diagonal load cases, similarly complex, exhibit times between 1.83 minutes and 128.85 minutes, averaging 20.84 minutes. Overall, the entire dataset's elapsed time spans from 1.83 minutes to 128.85 minutes, with a mean time of 19.32 minutes. This distribution of analysis times highlights the computational complexity associated with different load cases and provides insight into the variations in processing time based on dataset composition."}, {"title": "2.2. Data Preprocessing", "content": "The dataset used in this study comprises a range of jet engine bracket geometries with varying structural properties and masses,"}, {"title": "2.3. Model Architecture", "content": "This study explores three primary architectures\u2014PointNet, DeepONet, and the proposed Point-DeepONet-to effectively model displacement and stress fields in non-parametric 3D geometries under varying load conditions.\nPointNet Architecture. The PointNet architecture, shown in Figure 5, is adapted from the original framework by Qi et al. [3] with modifications similar to those made by Kashefi et al. [30] to accommodate variable and irregular geometries. PointNet is used to predict displacement fields (ux, uy, uz) and von Mises stress from 3D point cloud data under various load conditions.\nIn this setup, B represents the batch size, and N is the number of points (e.g., 5,000) in each input point cloud. The input to PointNet includes several components: point coordinates (x, y, z) with shape (B, N, 3); scalar quantities such as mass (B, N, 1); force magnitude (B, N, 1) and a unit direction vector (B, N, 3) that defines the loading direction. The architecture begins with a sequence of one-dimensional convolution (Conv1D) layers, each followed by batch normalization (BN) and the ReLU activation function. BN standardizes the inputs of each layer, improving training stability and accelerating convergence, while ReLU adds nonlinearity without saturating gradients. This combination of Conv1D+BN+ReLU acts as a shared multilayer perceptron (MLP) applied to each point independently, enabling the extraction of localized geometric and condition-dependent features. After extracting local features, these per-point embeddings are aggregated into a global feature vector via max pooling, allowing PointNet to capture the overall geometric characteristics of the input domain.\nOnce the global feature is formed, it is concatenated with the local features and passed through additional Conv1D layers with BN and ReLU activations, effectively integrating both local and global information. Finally, the output layer employs a Sigmoid activation function, producing bounded predictions for each point's ux, uy, uz, and von Mises stress.\nTo maintain a fair comparison with other architectures and reduce computational overhead, we applied a model scaling factor of 0.53 [30], resulting in a total of 250,927 trainable parameters. By directly handling irregular point clouds and incorporating load conditions, PointNet delivers accurate high-resolution field predictions, making it a suitable baseline for evaluating more advanced operator-learning frameworks.\nDeepONet Architecture. The DeepONet architecture, illustrated in Figure 6, is adapted from the framework presented by Lu et al. [15] and is designed to predict field quantities (e.g., displacement and stress) within complex, 3D geometries under various loading conditions. DeepONet consists of two main components: a branch network and a trunk network, each tailored to process distinct input types.\nThe branch network takes in global condition-based inputs, such as force magnitude, direction vectors, and mass. It uses a series of fully connected layers with SiLU activations [33] to encode these condition parameters into a compact latent representation, denoted by B. This latent code effectively captures the global physical influences of the applied conditions.\nSimultaneously, the trunk network processes point-based inputs consisting of spatial coordinates (x, y, z) and signed distance function (SDF) values [34], which provide geometric context by indicating each point's proximity to internal or external boundaries. The trunk network, also utilizing SiLU activations, encodes this geometry-aware information into a latent representation T for each point.\nAfter obtaining the B and T embeddings, a dot product is applied to produce predictions for each point's displacement components (ux, uy, uz) and von Mises stress:\n$\\widehat{G}(C)(X, SDF) = tanh\\left(\\sum_{h=1}^{128} B_{h} T_{h}\\right)$                                                                                                                                                                                                                                                                                                                (1)\nwhere C denotes the global conditions, Bh and Th are the h-th components of the encoded branch and trunk feature vectors, respectively, and h = 1,..., 128 indexes the latent feature dimension. A Tanh activation function is applied at the output to ensure bounded and smooth predictions, which can help stabilize training and improve the quality of results.\nDuring training, a key challenge arises from the variability in mesh resolutions. Different geometries, discretized with varying numbers of nodes and elements, produce input data arrays of non-uniform sizes, hindering batched training. To address this, we randomly resample all nodal coordinates and their corresponding outputs to a fixed size N, introducing repetition when necessary. This resampling approach enables batched training, significantly improving computational efficiency and facilitating comparisons across diverse geometries. Unlike previous works [35, 36],\nProposed Point-DeepONet Architecture. DeepONet has demonstrated its efficacy as an operator-learning framework for capturing parametric variations in complex systems, but it is constrained by using pointwise coordinates (x, y, z) in the trunk network, making it challenging to encode rich global geometric information. In contrast, PointNet excels at extracting both local and global features directly from unstructured point clouds, allowing it to handle non-parametric 3D domains naturally. However, PointNet alone is not designed to learn operator mappings that relate variable load conditions to solution fields in finite element analysis (FEA) contexts. To address these complementary limitations\u2014DeepONet's limited global geometric embedding and PointNet's difficulty in modeling operator mappings with changing load conditions\u2014we introduce Point-DeepONet, a hybrid architecture that integrates the advantages of both methods.\nAs illustrated in Figure 7, Point-DeepONet enriches the DeepONet framework with PointNet and SIREN layers, enabling the model to handle complex 3D geometries and nonlinear responses more effectively. The branch network consists of two sub-networks: one processes the global conditions C (e.g., load magnitude, direction, mass) into a latent representation B(C) \u2208 RB,128, where B denotes the batch size, and the other applies PointNet operations to the point cloud P\u2208 RB,N,3, with N denoting the number of points in the finite element mesh. PointNet's layers typically use shared multilayer perceptrons and Batch Normalization (BN) to learn robust pointwise features, and then aggregate them (e.g., via max pooling) to produce global shape descriptors. By summing the condition-based embedding B(C) and the point cloud-based embedding B(P), we obtain:\n$B_{b,h}^{o} = B_{b,h}^{(C)} + B_{b,h}^{(P)}$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            (2)\nOn the trunk side, the input is enriched by incorporating signed distance function (SDF) values in addition to the coordinates X = (x, y, z). The SDF, zero on the domain boundary and negative within the domain interior, encodes geometric context [34]. We feed (X, SDF) \u2208 RB,N,4 into sinusoidal representation network (SIREN) layers [38], which utilize sine-based activation functions. These SIREN layers are adept at representing high-frequency variations, facilitating the capture of complex geometric details:\n$T_{b,i,h}^{o} = f_{SIREN}(X_{b,i}, SDF_{b,i}).$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (3)\nWithin the SIREN layers, the sine activation is used instead of standard activation functions, allowing effective parameterization of intricate geometric shapes. Meanwhile, in other parts of the network, we employ SiLU (Sigmoid Linear Unit) activations, defined as SiLU(x) = x\u00b7\u03c3(x), where o denotes the sigmoid function. SiLU provides smooth, non-saturating nonlinearities and often leads to improved training stability and performance compared to ReLU. At the output layer, the Tanh activation function is used to ensure that predicted fields remain bounded, providing smooth outputs that range between -1 and 1.\nThe original DeepONet architecture fuses condition-based and geometry-based information only at the final stage via a single dot product, limiting interaction between these features. Following recent advancements [39, 28, 29], we incorporate an element-wise multiplication between B\u00ba and T\u00ba before the final layers:\n$F_{b,i,h} = B_{b,h}^{o} * T_{b,i,h}^{o}.$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         (4)\nThis earlier, more granular fusion encourages richer interplay between global conditions and geometric embeddings, enhancing the operator mapping's expressiveness.\nSubsequent MLP layers refine Fbih into two sets of features, B\u00ba and T\u1e9e, from which we derive the displacement and stress fields-specifically, three displacement components (ux, uy, uz) and the von Mises stress. A final dot product along the latent feature dimension yields:\n$\\widehat{G}(C, P)(X, SDF)_{b,i,m} = tanh \\left(\\sum_{h=1}^{128} B_{b,i,h,m}^{\\beta} T_{b,i,h}^{\\beta} \\right).$                                                                                                                                                                                                                                                                                                 (5)\nwhere b = 1,..., B indexes the batch, i = 1,..., N indexes the finite element nodes, h = 1,..., 128 spans the latent feature dimension, and m = 1,..., 4 indexes the field variables.\nBy uniting DeepONet's operator-learning framework with PointNet's robust geometric feature extraction, augmented by SDF-based shape encoding, SIREN layers, early feature fusion, BN layers for stable training, SiLU for"}, {"title": "3. Results and Discussion", "content": "In this section, we present a comprehensive evaluation of three neural network architectures-PointNet, DeepONet, and our proposed Point-DeepONet-for predicting the displacement and stress fields of jet engine brackets under various load conditions. The deep learning models were trained using an NVIDIA A100 GPU with 80GB of HBM2e memory. Our objective is to assess the efficacy of each model in capturing the complex nonlinear elastoplastic behavior inherent in these structures. We begin by detailing the optimization strategies and training procedures employed to ensure a fair and consistent comparison among the models. Subsequently, we examine the influence of different resampling sizes on the accuracy of the predicted fields, highlighting how the density of sampled points affects the models' ability to reproduce fine-grained features of the deformation and stress distributions."}, {"title": "3.1. Prediction Results", "content": "Training Details. To ensure an equitable comparison, all models were trained under standardized conditions using the AdamW optimizer [40], which incorporates weight decay regularization to mitigate overfitting by penalizing large weights. The initial learning rate was set to 1 \u00d7 10-3, and the mean squared error (MSE) loss function was employed to quantify the discrepancy between the predicted outputs and the ground truth values obtained from finite element analysis (FEA). Training was conducted with a batch size of 16 to balance computational efficiency and convergence stability.\nThe PointNet model was trained for 4,000 iterations, whereas DeepONet and our proposed Point-DeepONet were trained for 40,000 iterations each. The extended training duration for DeepONet and Point-DeepONet accounts for their more complex architectures and the necessity for additional iterations to achieve convergence. To ensure reproducibility and eliminate randomness in the training process, a fixed random seed was utilized across all experiments.\nModel performance was quantitatively assessed using three key metrics: mean absolute error (MAE), root mean square error (RMSE), and the coefficient of determination (R2). These metrics were computed on both the training and validation datasets to evaluate the models' accuracy and generalization capabilities. The MAE provides a straightforward measure of the average magnitude of errors, RMSE emphasizes larger errors due to the squared term, and R\u00b2 indicates the proportion of variance in the dependent variable predictable from the independent variables. By maintaining consistent hyperparameters and training configurations, we ensured that any differences in performance could be attributed to the inherent capabilities of the architectures rather than external factors.\nMathematically, the performance metrics are defined as follows:\n$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\widehat{y_i}|,$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          (6)\n$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\widehat{y_i})^2},$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     (7)\n$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\widehat{y_i})^2}{\\sum_{i=1}^{n} (y_i - \\overline{y})^2},$                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 (8)\nwhere y; are the true values from FEA, \u0177; are the predicted values from the models, \u04ef is the mean of the true values, and n is the total number of samples."}, {"title": "3.2. Influence of Resampling Size on Displacement and Stress Distribution", "content": "To reduce computational complexity while preserving essential geometric details, the original high-resolution meshes were downsampled at various levels,\nAn important aspect of modeling complex geometries is the choice of resampling size N, which determines the number of points used to represent the structure in the neural network. We investigated the effect of varying N on the accuracy of the predicted displacement components (ux, uy, uz) and the von Mises stress under different loading conditions.\nFor the vertical load case, we observe that higher sampling densities lead to more consistent and precise predictions. This improvement can be attributed to the models' enhanced ability to capture local geometric details and stress concentrations when provided with a denser point cloud representation.\nSimilarly, in the horizontal load case (Figures 13e to 13h), we observe that increasing N results in tighter distributions for all displacement components and von Mises stress. The reduction in variance and outliers suggests that the models benefit from the additional spatial information, which allows them to better approximate the underlying physical behavior of the structure under horizontal loading.\nFor the diagonal load case, depicted in Figures 13i to 131, the impact of resampling size is particularly noticeable for the von Mises stress predictions. At lower sampling densities (e.g., N = 500), the stress distributions are broader and exhibit significant variability, indicating that the models struggle to accurately capture the complex stress patterns associated with diagonal loading when limited spatial information is available. As N increases, the distributions become more concentrated, reflecting improved predictive accuracy."}, {"title": "3.3. Influence of Dataset Size on Model Performance", "content": "In this subsection, we examine how the size of the dataset influences the performance and training time of the PointNet and Point-DeepONet models. Given that DeepONet exhibited lower predictive performance in the previous analysis, we focus here on comparing PointNet and Point-DeepONet as the dataset size varies."}, {"title": "3.4. Effect of Input Configurations on Model Performance", "content": "In this subsection, we analyze the performance of the PointNet, DeepONet, and Point-DeepONet models under various input configurations to understand how different input parameters affect their predictive capabilities.\nWe denote the inputs using mathematical symbols as follows: spatial coordinates are represented as X = (x, y, z); the signed distance function as SDF; mass as m; force magnitude as f; and the direction vector as d = (dx,dy, dz). Different combinations of these inputs were used to evaluate the models' sensitivity to various physical and geometric parameters.\nFor the PointNet model, two input configurations were considered. The first configuration included the spatial coordinates X, force magnitude f, and direction vector d. The second configuration added mass m to these inputs, resulting in the inclusion of X, m, f, and d. The results indicate that incorporating mass in the input slightly improves performance in certain cases. For instance, when comparing the input configuration with mass to the one without, the R2 score for uy under the vertical load case increased from 0.920 to 0.927, and the MAE for von Mises stress under the diagonal load case decreased from 8.224 MPa to 7.639 MPa. This suggests that including mass helps the model better capture the physical behavior of the structure.\nThe DeepONet model was tested with three input configurations. In the first configuration, the branch inputs were force magnitude f and direction vector d, and the trunk inputs were spatial coordinates X and the signed distance function SDF. In the second configuration, the branch inputs included mass m, force magnitude f, and direction vector d, while the trunk inputs were only the spatial coordinates X. The third configuration combined all these inputs, with the branch receiving m, f, and d, and the trunk receiving X and SDF. Overall, the DeepONet model exhibited lower predictive performance compared to PointNet and Point-DeepONet across all configurations, with R2 scores generally below 0.8. Notably, including the signed distance function in the trunk did not lead to significant improvements in performance. For example, under the vertical load case with m, f, and d in the branch and X and SDF in the trunk, the R\u00b2 score for ux displacement was only 0.626.\nFor the Point-DeepONet model, we explored three input configurations similar to those used for DeepONet. The first configuration had branch inputs of f and d, and trunk inputs of X and SDF. The second configuration included mass m in the branch inputs, resulting in branch inputs of m, f, and d, with trunk inputs as X. The third configuration combined all inputs, with the branch receiving m, f, and d, and the trunk receiving X and SDF. The results demonstrate that Point-DeepONet consistently outperformed both PointNet and DeepONet across all input configurations and loading conditions. Notably, including the signed distance function in the trunk network led to the highest R2 scores in several cases. For example, under the vertical load case with m, f, and d in the branch and X and SDF in the trunk, Point-DeepONet achieved an R\u00b2 score of 0.964 for ux displacement, surpassing the corresponding scores of PointNet and DeepONet.\nComparing the input configurations for Point-DeepONet, the use of mass and the signed distance function in combination with other inputs generally resulted in better performance. The model achieved the highest R\u00b2 scores and lowest errors when both m, f, and d were used in the branch and X and SDF in the trunk. This suggests that incorporating additional physical parameters such as mass and geometric information like the SDF enhances the model's ability to capture the complex elastoplastic behavior of structures.\nIn terms of predicting von Mises stress, Point-DeepONet with m, f, and d in the branch and X and SDF in the trunk achieved the highest R2 scores across all load cases, indicating superior performance in capturing stress distributions. For instance, under the horizontal load case, the R\u00b2 score for von Mises stress was 0.923, higher than the scores achieved by PointNet and DeepONet. This demonstrates the model's enhanced capability in predicting stress fields when enriched input features are provided.\nOverall, the analysis indicates that the choice of input parameters significantly affects model performance. Point-DeepONet shows robustness and superior predictive capabilities across various input configurations, particularly when incorporating mass and the signed distance function. These findings highlight the importance of selecting appropriate input features that capture both the physical properties and geometric characteristics of structures to enhance model accuracy."}, {"title": "4. Conclusion and Future Work", "content": "This study introduced Point-DeepONet", "Introduction": "n1.  Flexible handling of non-parametric 3D geometries: By leveraging PointNet's capability to process raw point cloud data", "conditions": "Unlike Geom-DeepONet [29", "mesh": "Point-DeepONet provides direct predictions of displacement (ux", "overhead": "Comparisons with conventional nonlinear FEA highlight significant computational savings. While the average FEA runtime exceeded 1", "processes": "Owing to its rapid inference and high predictive accuracy, Point-"}]}