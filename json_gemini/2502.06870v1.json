{"title": "Bridging Traffic State and Trajectory for Dynamic Road Network and Trajectory Representation Learning", "authors": ["Chengkai Han", "Jingyuan Wang", "Yongyao Wang", "Xie Yu", "Hao Lin", "Chao Li", "Junjie Wu"], "abstract": "Effective urban traffic management is vital for sustainable city development, relying on intelligent systems with machine learning tasks such as traffic flow prediction and travel time estimation. Traditional approaches usually focus on static road network and trajectory representation learning, and overlook the dynamic nature of traffic states and trajectories, which is crucial for downstream tasks. To address this gap, we propose TRACK, a novel framework to bridge traffic state and trajectory data for dynamic road network and trajectory representation learning. TRACK leverages graph attention networks (GAT) to encode static and spatial road segment features, and introduces a transformer-based model for trajectory representation learning. By incorporating transition probabilities from trajectory data into GAT attention weights, TRACK captures dynamic spatial features of road segments. Meanwhile, TRACK designs a traffic transformer encoder to capture the spatial-temporal dynamics of road segments from traffic state data. To further enhance dynamic representations, TRACK proposes a co-attentional transformer encoder and a trajectory-traffic state matching task. Extensive experiments on real-life urban traffic datasets demonstrate the superiority of TRACK over state-of-the-art baselines. Case studies confirm TRACK's ability to capture spatial-temporal dynamics effectively.", "sections": [{"title": "Introduction", "content": "Intelligent urban traffic management, such as traffic flow prediction (Bai et al. 2020; Wang et al. 2022; Ji et al. 2022a; Liu et al. 2024), travel time estimation (Wang et al. 2018; Wu et al. 2019a) and trajectory analysis (Chen et al. 2017; Ding et al. 2018; Chen et al. 2019), plays a crucial role in ensuring efficient city functioning and promoting sustainable development (Wang et al. 2021; Jiang et al. 2023b). In the realm of intelligent urban traffic management, traffic state data and trajectory data are two core components that can encapsulate the macroscopic and microscopic characteristics of cities, respectively, and their representation learning, i.e., learning generic low-dimensional road segment and trajectory vectors, serve as two fundamental pillars for various urban traffic tasks (Chen et al. 2018; Wang et al. 2019a; Jiang et al. 2023d).\nRecently, many efforts have been devoted to modeling traffic state data (Jiang et al. 2023a; Zou et al. 2024; Yi et al. 2024; Ji et al. 2022b, 2023, 2020) and trajectory data (Yang et al. 2021; Fu and Lee 2020; Jiang et al. 2023c). However, existing methods typically model these two types of data independently, lacking approaches capable of jointly modeling them. In urban transportation scenarios, traffic state data describes the dynamic macroscopic characteristics of groups on the road network, while trajectory data reflects the dynamic movement attributes of individuals on the road network. There are spatio-temporal correlations and mutual influences between traffic state data and trajectory data.\nFirstly, traffic states influence individuals' choices of the trajectory route. For example, as shown in Figure 1(a), people tend to choose the shortest route $R_1$ during non-peak hours, but it might be a better choice to detour with a more time-saving route $R_2$ during peak hours (i.e., when the average traffic speed of $R_1$ is low). Traffic states naturally affect the travel time of each road segment in a trajectory. Secondly, individual transitions on the road network are the direct cause of changes in traffic states. As shown in Figure (b), the traffic flow on segment C consists of the traffic flow entering from segment A and that entering from segment B. Therefore, the transition probability from segment A to segment C varies over different time periods, directly impacting the traffic states on segment C. Therefore, jointly modeling traffic state data and trajectory data can enrich the spatio-temporal information learned by the model, capturing the dynamic nature of traffic states and trajectories.\nTo achieve this, we propose to bridge two prominent types of dynamic data, i.e., TRAffic state and trajectory, for dynamic road network and trajectory representation learning (TRACK). Specifically, TRACK encodes the static and spatial features of road segments with graph attention networks (GAT) to learn road segment representations, followed by a trajectory transformer encoder with the masked trajectory prediction task and the contrastive trajectory learning task to learn trajectory representations. To capture the dynamic spatial features of road segments, we incorporate the transition probabilities computed from the trajectory data into the attention weights of GAT. Meanwhile, to capture the spatial-temporal dynamics of road segments from traffic state data, we learn a traffic transformer encoder with the mask state prediction task and the next state prediction task. More importantly, to capture the interactions of traffic state and trajectory data in characterizing a road segment's dynamic features, we model the information exchange between different data views by designing a co-attentional transformer encoder with a novel gravitivity-based attention mechanism and the trajectory-traffic state matching task. Finally, we pre-train the whole model with a joint self-supervised learning loss.\nWe conduct extensive experiments on two real-life urban traffic datasets and compare our proposed TRACK method with several state-of-the-art baselines. Evaluated with two downstream tasks, TRACK achieves consistently superior performances over baselines. Case studies also validate that TRACK can capture the spatial-temporal dynamics of road segments and trajectories through learned dynamic representations."}, {"title": "Preliminaries", "content": "In this section, we introduce the mathematical notations used throughout the paper and formally define our research problem."}, {"title": "Basic Elements of Urban Traffic", "content": "We start by introducing the basic spatial-temporal units of urban traffic, i.e., a road segment and a time slice."}, {"title": "Definition 1 (Road Segment)", "content": "A road segment $v \\in V$ is the minimum spatial unit in urban traffic scenarios where $V$ is the set of road segments."}, {"title": "Definition 2 (Time Slice)", "content": "A time slice $t$ is the minimum time unit (e.g., an hour) in urban traffic scenarios.\nFor convenience, we might call segment for short in unambiguous cases. Next, we characterize the spatial, static, dynamic features of road segments and the trajectory with the following concepts."}, {"title": "Definition 3 (Road Network)", "content": "A road network is characterized as a graph $G = (V, A)$, where $V = \\{v_1,\\ldots, v_N\\}$ is a node set of $N$ road segments and $A \\in \\mathbb{R}^{N \\times N}$ is an adjacency matrix to capture the link information between $N$ road segments. The road network entails the spatial features of road segments."}, {"title": "Definition 4 (Static Feature of Road Segment)", "content": "The static feature $f \\in \\mathbb{R}^{C_1}$ for a road segment $v$ is a feature vector with which $v$ is generally associated and does not change over time after it was built. $C_1$ is the dimension of the feature vector. For example, $C_1 = 5$ if the features include longitude, latitude, segment type, length, and speed limit."}, {"title": "Definition 5 (Traffic State Sequence)", "content": "A traffic state sequence $S_t \\in \\mathbb{R}^{T \\times N \\times C_2}$ is composed of $T$ consecutive historical traffic states before the time slice $t$, where $S_t = (TS_{t-T},\\ldots, TS_{t-1})$. $TS_t$ denotes a traffic state at the time slice $t$. A traffic state $TS_t \\in \\mathbb{R}^{N \\times C_2}$ is the statistics (e.g., flow, density, average speed) on $N$ road segments within the time slice $t$, where $C_2$ is the dimension of the statistics. The traffic state sequence involves the dynamic features of road segments that will change over time."}, {"title": "Definition 6 (Trajectory)", "content": "A trajectory $T = [(v_i, t_i)]_{i=1}^{m}$ is a sequence of spatial-temporal points that record the movement behavior of a car or person in the scope of the road network $G$, where $m$ is the total number of spatial-temporal points, $v_i \\in V$ denotes the segment for the $i$-th visit, and $t_i \\in \\mathbb{R}$ denotes the corresponding visit timestamp.\nWe use $F_V \\in \\mathbb{R}^{N \\times C_1}$ to denote the static feature matrix of $N$ road segments in the road network $G$. We assume that there is a set of $k_t$ trajectories within the time slice $t$, denoted as a trajectory set $D_t = \\{T_j\\}_{j=1}^{k_t}$, indicating that the departure timestamp of each trajectory $T_j \\in D_t$ lies in the time slice $t$."}, {"title": "Problem Formulation", "content": "We formulate two representation learning tasks in urban traffic scenarios, i.e., Dynamic Road Network Representation Learning (DRNRL) and Trajectory Representation Learning (TRL)."}, {"title": "Definition 7 (Dynamic Road Network Representation Learning)", "content": "Given the road network $G$, the historical traffic state sequence $S_t$ and the trajectory set $D_t$ at the time slice $t$, DRNRL aims to derive a generic $d_s$-dimensional representation $h_{vit} \\in \\mathbb{R}^{d_s}$ at the time slice $t$ for each road segment $v \\in V$ on the road network."}, {"title": "Definition 8 (Trajectory Representation Learning)", "content": "Given the road network $G$, the historical traffic state sequence $S_t$ and the trajectory set $D_t$ at the time slice $t$, TRL aims to derive a generic $d_t$-dimensional representation $I_T \\in \\mathbb{R}^{d_t}$ for each trajectory $T \\in D_t$.\nTraditional representation learning methods on road network (Wu et al. 2020a) usually focus on learning a road segment's representation that does not change over time. However, in great contrast, DRNRL aims to learn dynamic representations of road segments by considering the dynamic features derived from traffic state and trajectory data. We interchangeably use the terms road network representation and road segment representation hereinafter. We assume that the numbers of latent dimensions for DRNRL and TRL are set to the same value $d$ in our problem, i.e., $d = d_s = d_t$. The learned road segment representation can be applied to various segment-related downstream tasks such as traffic state prediction and on-demand service prediction. The learned trajectory representation can be applied to various trajectory-related downstream tasks such as travel time estimation and anomalous trajectory detection."}, {"title": "Methodology", "content": "In this section, we present the proposed TRACK model. Our core idea is to incorporate dynamic information from traffic state and trajectory data into road network and trajectory representation learning, and model the information exchange between multi-view data to enhance the dynamic representations. The overall architecture of the proposed model is shown in Figure 2."}, {"title": "Basic Pipeline of TRL", "content": "In this part, we introduce a basic pipeline for TRL, which first encodes the segments appearing in a trajectory into low-dimensional vectors and then combines them with the timestamp representations to derive the trajectory's final representation vector. We train it with the Masked Trajectory Prediction (MTP) task and the Contrastive Trajectory Learning (CTL) task."}, {"title": "Encoding Road Segment's Static and Spatial Features", "content": "We aim to project each segment $v$ in the road network $G$ into a low-dimensional representation vector $h \\in \\mathbb{R}^d$. The static features of each segment, e.g., length and speed limits, contain rich semantics of the segment. Moreover, the connectivity of the segments in the road network, i.e., the local network structure, also entails the spatial semantics of a segment. To this end, it is natural to learn the representation vector of a segment from both its static features and the local network structure. We adopt a GNN method, i.e., a multi-layer Graph Attention Network (GAT)(Velickovic et al. 2018), to model each segment's static and spatial features as follows:\n$H^{Traj} = GAT(F_V, A),$ (1)\nwhere $GAT(., .)$ denotes the implementation of a standardized GAT or a GAT optimized with sparse matrix operations, and $H^{Traj} = [h^{Traj}]_{N=1}^N \\in \\mathbb{R}^{N \\times d}$ is a matrix form of $N$ segments's representations in $G$."}, {"title": "Encoding Timestamp Information", "content": "We introduce a temporal embedding layer to transform raw timestamps in trajectories into low-dimensional representation vectors. Specifically, it contains $t_{weekly}, t_{daily}, t_{pos}, t_{interval} \\in \\mathbb{R}^d$, which represent weekly periodic patterns, daily periodic patterns, position information, time interval information, respectively."}, {"title": "Encoding the Whole Trajectory", "content": "The whole trajectory can be divided into a segment sequence and a time sequence. Therefore, for the $i$-th visit, we first feed the segment $v_i$ into the GAT to obtain the segment representation $h^{traj}_i$. Meanwhile, we feed the time sequence into the temporal embedding layer to obtain $t_{weekly}, t_{daily}, t_{pos}$ and $t_{interval}$. Then, we derive the overall representation $l_i \\in \\mathbb{R}^d$ for the $i$-th visit in a trajectory by as follows:\n$l_i = h^{Traj}_i + t_{weekly} + t_{daily} + t_{pos} + t_{interval}$ (2)\nIn order to capture the long-range dependencies of visits in a trajectory and identify the global semantics of the trajectory, we further feed the representation sequence $[l_i]_{i=1}^{m}$ into a transformer encoder (Vaswani et al. 2017) to obtain the final trajectory representation $I_T \\in \\mathbb{R}^d$ which can be mathematically defined as follows:\n$I_T = TrajTrans(p_h, l_1, \\ldots, l_m)[0],$ (3)\nwhere the function $TrajTrans(.)$ denotes a standard transformer encoder or a transformer-like encoder and $p_h$ is the embedding vector of the placeholder."}, {"title": "Masked Trajectory Prediction", "content": "The general idea of this task is to mask the consecutive subsegments of the trajectory and their corresponding timestamps, and to use linear layers to predict the masked values, i.e., $\\hat{y}_S \\in \\mathbb{R}^{|T| \\times |V|}$ and $\\hat{y}_T \\in \\mathbb{R}^{|T|}$, respectively. The loss functions can be defined as follows:\n$\\mathcal{L}^{Traj}_{Ms} = - \\frac{1}{|M_S|} \\sum_{v_i \\in M_S} log\\frac{exp(\\hat{y}^{v_i})}{\\sum_{v_j \\in V} exp(\\hat{y}^{v_j})},$ (4)\n$\\mathcal{L}^{Traj}_{MT} = - \\frac{1}{|M_T|} \\sum_{t_i \\in M_T} |t_i - \\hat{t}_i|,$ (5)\nwhere $M_S$ and $M_T$ denote the sets of masked road segments and masked timestamps, respectively."}, {"title": "Contrastive Trajectory Learning", "content": "The general idea of this task is to adopt a contrastive learning strategy to generate multiple samples of a trajectory from different views and bring semantically similar samples closer in the representation space while dispersing dissimilar samples. The loss function can be defined as follows:\n$\\mathcal{L}_{con}(T_i, T_j) = -log \\frac{exp(sim(I_T^i, I_T^j) / \\tau)}{\\sum_{k=1}^{2B}1[k \\neq i]exp(sim(I_T^i, I_T^k) / \\tau)},$ (6)\nwhere $B$ is the batch size, $(T_i, T_j)$ is a positive pair in the batch, $1[k \\neq i] \\in \\{0, 1\\}$ is an indicator function that is equal to 1 if condition $k \\neq i$ is satisfied and $\\tau$ denotes a temperature parameter. The overall loss of this task for the batch, i.e., $\\mathcal{L}^{Traj}_{con}$, is computed by averaging the losses of all positive pairs in the batch."}, {"title": "Modeling Road Segments' Dynamic Features", "content": "In this part, we model the dynamic features of road segments that can change over time, including the spatial-temporal dynamics in trajectories and traffic state sequences."}, {"title": "Encoding Road Segment's Dynamic Spatial Features with Trajectory Data", "content": "Trajectory data entails some dynamic spatial semantics of segments. For example, a large transition probability between two segments revealed from the trajectory data may indicate that the two segments are nearby in the semantic space. Therefore, we replace the standard GAT in Section Encoding Road Segment's Static and Spatial Features with a Trajectory Transition-aware GAT. Specifically, based on the trajectories, we introduce a time-aware transition probability $P_{i,j,t}$ for the time slice $t$ to capture the transition patterns between two segments $v_i$ and $v_j$. $P_{i,j,t}$ considers the historical trajectories that occur periodically within the time slice $t$. To incorporate $P_{i,j,t}$ into the GAT, we compute a normalized attention weight $A_{i,j,t}$ between $v_i$ and $v_j$ as follows:\n$A_{i,j,t} = \\frac{exp(LeakyReLU(e_{i,j,t}))}{\\sum_{k \\in N_{v_i}}exp(LeakyReLU(e_{i,k,t}))},$ (7)\n$e_{i,j,t} = (h^{Vis}_iW_1 + h^{Vis}_jW_2 + P_{i,j,t}W_3)W_4,$ (8)\nwhere $W_1, W_2 \\in \\mathbb{R}^{d \\times d'}$ and $W_3, W_4 \\in \\mathbb{R}^{1 \\times d'}$ are learnable weight parameters, $N_{v_i}$ is the neighborhood set of road segment $v_i$."}, {"title": "Traffic Data Embedding", "content": "The Traffic Data Embedding layer is designed to convert the traffic state sequence at time slice $t$, i.e., $S_t \\in \\mathbb{R}^{T \\times N \\times C_2}$, into an embedding tensor, i.e., $X^{Traf} \\in \\mathbb{R}^{T \\times N \\times d}$. Specifically, we first project $S_t$ directly into a $d \\times$-dimensional representation tensor, i.e., $X^{raw} = FC(S_t) \\in \\mathbb{R}^{T \\times N \\times d}$, through a fully-connected feed-forward network $FC(.): \\mathbb{R}^{T \\times N \\times C_2} \\rightarrow \\mathbb{R}^{T \\times N \\times d}$. Next, we employ three temporal embeddings, i.e., $X^{weekly}, X^{daily}, X^{pos} \\in \\mathbb{R}^{T \\times d}$, to extract the weekly periodic patterns, daily periodic patterns and position information for all $T$ time slices, respectively. To further model the spatial information of the road network, we also employ a multi-layer GAT to generate an embedding matrix $X^G \\in \\mathbb{R}^{N \\times d}$ of the road network. The final embedding tensor $X^{Traf}$ can then be computed as follows:\n$X^{Traf} = X^{raw} + X^{weekly} + X^{daily} + X^{pos} + X^G.$ (9)"}, {"title": "Traffic Transformer Encoder", "content": "We further feed $X^{Traf}$ into a traffic transformer encoder to model dynamic spatial-temporal dependencies hidden in traffic state sequences. The traffic transformer encoder is composed of multiple traffic transformer encoder layers. In each encoder layer, we first feed $X^{Traf}$ into a spatial encoder and a temporal encoder, respectively. The spatial encoder takes a geographical and semantic neighbor-aware GAT layer to capture the dynamic spatial dependencies of traffic states in each time slice, whereas the temporal encoder takes a temporal self-attention layer to capture the dynamic temporal patterns for different road segments in the traffic state data. Next, we concatenate the output embedding of the spatial and temporal encoders to form a fusion representation, which is further fed into other components of a transformer encoder, e.g., Add & Norm layer and Feed Forward layer. At the last of the traffic transformer encoder, we use a convolutional layer to transform the output embedding tensor into a matrix $H^{Traf} \\in \\mathbb{R}^{N \\times d}$, which is the final representation for $N$ road segments at the time slice $t$. We summarize the computation of $H^{Traf}$ as follows:\n$H^{Traf} = TrafTrans(X^{Traf}),$ (10)\nwhere the function $TrafTrans(.): \\mathbb{R}^{T \\times N \\times d_z} \\rightarrow \\mathbb{R}^{N \\times d}$ denotes the whole Traffic Transformer Encoder. Actually, other feasible spatio-temporal encoders can also replace this encoder.\nPre-training Traffic Data Embedding and Traffic Transformer Encoder via Mask State Prediction and Next State Prediction. We design two self-supervised tasks to learn generic segment representations. Specifically, we randomly mask a sequence of historical traffic states for each segment and use the generated intermediate representations to predict the masked traffic states, while using the generated segment representations of the next time slice to predict the traffic state of the next time slice. Ultimately, the loss $\\mathcal{L}^{Traf}$ is obtained by the weighted sum of the losses from two tasks."}, {"title": "Modeling Multi-view Information Exchange", "content": "We propose a co-attentional transformer encoder to tackle the multi-view information exchange between different data modality, followed by a trajectory-traffic state matching task to maximize the consistency between segment representations and trajectory representations."}, {"title": "Co-Attentional Transformer Encoder", "content": "In each view, the key idea for the co-attentional transformer encoder is to replace the transformer encoder's multi-head self-attention module with a GAT layer, as shown in Figure 3, which aggregates the neighborhood nodes' features from the other view to form the node's feature representation in the target view. Moreover, in the GAT layer, inspired by Newton's law of universal gravitation (Simini et al. 2021), we assume that the influence between two segments decreases with the distance between them and design a novel way to compute the attention weight.\nSpecifically, we take the view of trajectory data to describe the mechanism of the co-attentional transformer encoder, and the co-attentional transformer encoder for the other view works similarly. We first define a $K$-minute reachable neighborhood set for segment $v_i$ as $R_{v_i}$, which is the set of segments that can reach $v_i$ in $K$ minutes. We use $h^{traj}_i \\in \\mathbb{R}^d$ to denote the representation vector of segment $v_i$ at the time slice $t$ produced by Trajectory Transition-aware GAT. To model the influence of information from the other view over $h^{traj}_i$, we employ a GAT layer, which defines a normalized attention weight $a^{Traj}_{i,j}$ between $v_i$ and $v_j \\in R_{v_i}$ as follows:\n$a^{Traj}_{i,j} = \\frac{exp(LeakyReLU(e^{Traj}_{i,j}))}{\\sum_{k \\in R_{v_i}} exp(LeakyReLU(e^{Traj}_{i,k}))},$ (11)\n$e^{Traj}_{i,j} = (h^{traj}_iW_5 + h^{traf}_jW_6 + deter(v_i, v_j)W_7)W_8$ (12)\nwhere $W_5, W_6 \\in \\mathbb{R}^{d \\times d'}$ and $W_7, W_8 \\in \\mathbb{R}^{1 \\times d'}$ are learnable parameters, the function $deter(.)$ denotes a geographical distance deterrence function such as Negative Power Function, and $h^{traf}_j$ denotes the representation vector of segment $v_j \\in \\mathbb{R}^d$ at the time slice $t$ produced by the Traffic Transformer Encoder in the other view. The GAT layer uses the normalized attention weight $a^{Traj}_{i,j}$ to aggregate the features of neighboring segments in the other view to obtain the feature representation of the targeted segment. The rest of the transformer block proceeds as before."}, {"title": "Trajectory-Traffic State Matching", "content": "We design a contrastive learning task, i.e., Trajectory-Traffic State Matching, which maximizes the agreement of a trajectory's representation vector and the corresponding road segment sequence's representation vector generated from traffic state data. The core of this task is that the trajectories of the current time slice correspond to the traffic state of the current time slice, rather than traffic states of other time slices.\nSpecifically, for a trajectory $T = [(v_i, t_i)]_{i=1}^{m}$, its representation $I_T$ can be extracted by the TRL process. In the meanwhile, a representation matrix $RSTraf \\in \\mathbb{R}^{m \\times d}$ for the trajectory's corresponding segment sequence $[v_i]_{i=1}^{m}$ can be extracted based on the traffic state data as follows:\n$RSTraf = [h^{Traf}]_{i=1}^{m},$ (13)\nwhere $h^{Traf}_i \\in \\mathbb{R}^d$ denotes the representation vector for road segment $v_i$ at the timestamp $t_i$ (within the time slice t), and is derived based on $H^{Traf}$ as described in Equation (10). Then, we can obtain the final representation vector $h^{Traf} \\in \\mathbb{R}^d$ by average pooling over the first dimension of the matrix $R^{STraf}$.\nIn the contrastive learning process, We define the spatio-temporal data of $B_t$ time slices as a training batch. For each trajectory $T \\in D_t$ within the time slice $t \\in \\Theta$, we regard $(I_T, h^{traf})$ as a positive pair. To construct negative pairs, we obtain $h^{traf} \\in \\mathbb{R}^d$ from other time slices $t' \\in \\Theta$. Then, a negative pair can be constructed as $(I_T, h^{traf})$. Formally, the loss function of the positive pair $(I_T, h^{traf})$ for the contrastive learning based on NT-Xent is defined as:\n$\\frac{d_{T,t}}{d_{T,t} = exp(sim(I_T, h^{traf}) / \\tau)},$\n$\\mathcal{L}_{Match}(I_T, h^{traf}) = -log\\frac{d_{T,t}}{d_{T,t} + \\sum_{t' \\in \\Theta} d_{T,t'}},$ (15)\nwhere $\\tau$ denotes a temperature parameter. The total loss of contrastive learning for the batch, i.e., $\\mathcal{L}_{Match}$, is calculated by averaging the losses of all positive pairs in the batch."}, {"title": "Joint Pre-training for the Whole Model", "content": "To facilitate learning spatial-temporal patterns across multi-source data, we pre-train all modules of the proposed model in a joint manner, which defines the following loss function:\n$\\mathcal{L} = \\lambda_{Traj}\\mathcal{L}^{Traj} + \\lambda_{Traf}\\mathcal{L}^{Traf} + \\lambda_{Match}\\mathcal{L}^{Match},$ (16)\nwhere $\\lambda_{Traj}, \\lambda_{Traf}, \\lambda_{Match}$ are three hyper-parameters that control the influence of each individual loss function over the proposed model, respectively."}, {"title": "Experiments", "content": "We evaluate the learned segment representations and trajectory representations on two downstream tasks, respectively, i.e., Multi-Step Traffic State Prediction (MSTSP) and Travel Time Estimation (TTE). For the MSTSP task, we compare TRACK with 7 traffic state prediction methods, including DCRNN (Li et al. 2018b), GWNET (Wu et al. 2019b), MTGNN (Wu et al. 2020b), TrGNN (Li et al. 2021), STGODE (Fang et al. 2021), ST-Norm (Deng et al. 2021) and SSTBAN (Guo et al. 2023). For the TTE task, we compare TRACK with 7 trajectory representation learning methods, including traj2vec (Yao et al. 2017), t2vec (Li et al. 2018a), Trembr (Fu and Lee 2020), PIM (Yang et al. 2021), Toast (Chen et al. 2021), JCLRNT (Mao et al. 2022) and START (Jiang et al. 2023c)."}, {"title": "Performance Comparison", "content": "Table 2 reports the results for two downstream tasks. The bold results are the best, and the underlined results are the second best. It can be seen that our proposed TRACK model outperforms all baselines on both datasets. This demonstrates the effectiveness of TRACK in learning effective road network representations and trajectory representations.\nFor the MSTSP task, MTGNN and SSTBAN achieve competitive performance compared to other baselines. This is because MTGNN proposes an adaptive graph generation module to reflect realistic spatial correlations while SSTBAN employs a self-supervised learner and designs a spatial botteleneck attention mechanism to capture global spatial dynamics. In contrast, TRACK achieves better performance because it further incorporates transition patterns of segments based on trajectory data in modeling the spatial-temporal dynamics. For the TTE task, START consistently outperforms other baselines for all metrics and datasets. One important reason is that it captures the temporal dynamics of trajectories and therefore enables the trajectories passing through the same route at different time slices may have different representations. However, START only encodes the timestamp information of trajectories for the periodic patterns of urban traffic, while TRACK also learns the spatial-temporal dynamics in the short-term traffic states."}, {"title": "Ablation Study", "content": "To further investigate the effects of different components in TRACK, we perform ablation studies with the following variants. (1) w/o Traf: this variant eliminates modeling of the spatial-temporal dynamics in traffic state sequences; (2) w/o Traj: this variant eliminates the process of trajectory representation learning and modeling of dynamic spatial features in trajectories; (3) w/o Match: this variant eliminates the trajectory-traffic state matching task; (4) w/o TMask: this variant removes the loss $\\mathcal{L}^{Traj}_{Ms}$ of the MTP task, which means no masking prediction for timestamps; (5) w/o SMask: this variant removes the loss $\\mathcal{L}^{Traj}_{Ms}$ of the MTP task, which means no masking prediction for segments; (6) w/o Contra: this variant removes the loss $\\mathcal{L}^{Traj}_{con}$ of the CTL task.\nFigure 4 shows the performance of these variants on the MSTSP and TTE tasks of the Xi'an dataset. The following observations can be made. Firstly, the variants w/o Traj and w/o Traf are consistently inferior to TRACK on both tasks. This demonstrates that traffic state and trajectory data can serve as side information of each other to enhance the representation learning process of road networks and trajectories. Specifically, trajectory representations can perceive dynamic traffic states on the road network, while segment representations can perceive dynamic dependencies between upstream and downstream traffic flows. Secondly, TRACK performs better than w/o Match. This indicates that the Trajectory-Traffic State Matching task can indeed help to enhance the representation learning process of the whole model. Third, the performance of w/o TMask, w/o SMask, and w/o Contra on both tasks is inferior to TRACK. This indicates that both MTP and CTL tasks contribute to more accurate representations of dynamic road networks and trajectories, which in turn impacts their performance on two downstream tasks."}, {"title": "Case Study", "content": "In this section, we conduct two case studies to visualize and analyze the dynamic segment representations and trajectory representations, which enhance TRACK's interpretability."}, {"title": "Case 1: Study on Dynamic Road Segment Representations", "content": "One advantage of the proposed model is to learn dynamic road segment representations. We take segments A, B and C in Figure 5(a) as an example to investigate this type of representation. The incoming traffic flow of segment A is composed of the outgoing traffic flow of segments B and C. We take October 11th as the observation period and set the window of the time slice as 30 minutes. Then we adopt t-SNE (Van der Maaten and Hinton 2008) to visualize the learned segment representations in Figure 5(b), where each point corresponds to the representation of a segment within a time slice. We can see that the learned segment representation indeed changes over time. Moreover, we use SimRatio(A,B) to measure the ratio of the similarity between segments A and B and the similarity between segments A and C. We then plot SimRatio(A,B) and the transition probabilities from segment B to A, denoted as TransProb(B\u2192A), over time in Figure 5(c). It can be observed that the transition patterns indeed change over time. More importantly, we can see that from 16:00 to 23:00 there is a significant decrease in SimRatio(A,B), which is due to the fact that there were no trajectories from B to A in that period. This suggests that the learned segment representations can indeed capture the dynamic transition patterns between road segments."}, {"title": "Case 2: Study on Dynamic Trajectory Representations", "content": "Another advantage of the proposed model is that with the information exchange of different views, the learned trajectory representations can also be influenced by the dynamics of traffic states. We take the three routes $R_1$, $R_2$, and $R_3$ from segment 131 to segment 2768 on November 1st shown in Figure 6(a) as an example. In Figure 6(b), we visualize trajectory representations of the three routes at different time slices, which shows that the learned trajectory representations of the"}]}