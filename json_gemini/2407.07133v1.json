{"title": "Neuromimetic metaplasticity for adaptive continual learning", "authors": ["Suhee Cho", "Hyeonsu Lee", "Seungdae Baek", "Se-Bum Paik"], "abstract": "Conventional intelligent systems based on deep neural network (DNN) models encounter challenges in achieving human-like continual learning due to catastrophic forgetting. Here, we propose a metaplasticity model inspired by human working memory, enabling DNNs to perform catastrophic forgetting-free continual learning without any pre- or post-processing. A key aspect of our approach involves implementing distinct types of synapses from stable to flexible, and randomly intermixing them to train synaptic connections with different degrees of flexibility. This strategy allowed the network to successfully learn a continuous stream of information, even under unexpected changes in input length. The model achieved a balanced tradeoff between memory capacity and performance without requiring additional training or structural modifications, dynamically allocating memory resources to retain both old and new information. Furthermore, the model demonstrated robustness against data poisoning attacks by selectively filtering out erroneous memories, leveraging the Hebb repetition effect to reinforce the retention of significant data.", "sections": [{"title": "Introduction", "content": "Recent advances in deep neural network (DNN) models have demonstrated remarkable performance outcomes across a wide range of tasks, often surpassing human capabilities in areas such as image recognition [1, 2]. However, DNN models face a challenge when they receive a continuous stream of information (Fig. 1a). One of the most critical issues in this context is catastrophic forgetting a phenomenon during which the network suddenly loses the memory of previously learned items when learning new ones (Fig. 1b, top) [3-5]. This is due to the high plasticity of wirings in DNNs, which allows new inputs readily to overwrite old weight distributions. This raises a crucial issue known as the \"stability-plasticity dilemma\" [6], highlighting the need for a balance in DNNs between maintaining stability to preserve the memory of prior knowledge while simultaneously fostering flexibility to learn new inputs.\nTo resolve this issue, several studies developed revised models of DNNs that are resistant to catastrophic forgetting [7]. For example, some prior models suggested an algorithm in which new nodes or networks are added during the learning of new tasks or information [8-10]. Other models have incorporated memory replay or rehearsal strategies to enhance the resilience of DNN models against catastrophic forgetting [11-15]. However, these approaches not only require additional resources to store the old information but also accompany additional phases for the re-training of the old memory. Therefore, while these strategies partially address the problem of catastrophic forgetting, their complicated processing and heavy computational loads make them impractical. This emphasizes the necessity for new approaches that are more efficient and plausible.\nIn contrast to the innate restrictions of DNNs in continual learning, human brains can balance stability and plasticity in their neural memory representations [16-18]. Unlike DNNs that overly weigh recent information, the brain adaptively allocates its memory resources to retain old inputs while reserving capacity for new information. A good signature of how the brain resolves the stability-plasticity dilemma is the \u201cserial position effect\" observed in sequential working memory tasks, in which items positioned at the beginning and end of a sequence are better memorized than those in the middle (Fig. 1b, bottom) [18-25]. Specifically, the combination of the \"primacy effect\" and \"recency effect\" enables a balanced weight between old and new information [26], achieving adaptive continual memory. Notably, this phenomenon persists when the total number of items in the sequence is varied [16, 27, 28]. When the total number of items increases, the memory resource for old items is reallocated to incorporate new ones, enabling the brain to learn new items while retaining old information. This illustrates the brain's ability to accomplish adaptive memory allocation even when the amount of information to be learned is uncertain. Another observation known as the \"Hebb repetition effect\" [29, 30] demonstrates that the brain can enhance a \"weak\" memory of a particular item by simply presenting it repeatedly (Fig. 1c, bottom). These observations may be important clues to understanding the brain's mechanism for adaptive, robust continual learning.\nThis leads to the question of how the brain implements the \u201cserial position effect\" and the \"Hebb repetition effect,\" referring to the type of mechanism of synaptic plasticity that enables the network to retain both old and new information for adaptive continual learning. One possible candidate is synaptic metaplasticity [31-33], by which the plasticity of individual synapses are adjusted based on their modification history and current neural activity [34, 35]. In this way, the brain can stabilize certain synapses for old memory while letting others hold plasticity for new information, dealing with the stability-plasticity dilemma. A key advantage of this scenario is that no additional pre- or post-processing is necessary, unlike most previous models that still require computationally intensive procedures to determine the appropriate metaplastic states of each synapse [32]. Moreover, when the amount of information to learn is uncertain, such models are prone to forgetting previously encoded information, particularly when they learn new information that exceeds the network's memory capacity [31-33] a limitation that the brain rarely faces.\nHere, we propose a novel metaplasticity model by which the issues described above are fully addressed, i.e., where continual learning for sequential input is ensured in the complete absence of pre- or post-processing. Inspired by our previous notion of the distinct role of flexible and stable encodings in sequential working memory in the brain [16], our model synapses are designed to have a metaplasticity profile randomly sampled from a distribution ranging from extremely stable to extremely flexible values. This simple intermixing of distinct synapses could successfully replicate the key features of biological working memory for \u201ccatastrophic forgetting-free\" continual learning in DNNs. We demonstrate that a network composed of both stable and unstable synapses enables DNNs to learn sequences of images, with high memory retention for both early and recent items, consistently maintaining sequential information of varying lengths. The model also exhibits an adaptive capacity-performance tradeoff and the frequency-dependent consolidation of repeated information, characteristics also observed in human working memory [19-21, 29, 30]. We demonstrate that this frequency-dependent consolidation enables robust memory against data poisoning attacks [36], distinguishing it from conventional DNNs."}, {"title": "Methods", "content": "AlexNet [37] was used as a representative model of a deep neural network. This network consists of two parts: feature extraction (Input-Pool5) and classification (FC6-output) networks (Table S1). In detail, the feature extraction network consists of five convolutional layers and the classification network has three fully connected layers. The detailed parameters were sourced from Krizhevsky et al. (2012). To analyze the impact of our metaplastic rule on the retention of sequential task performance in fully connected layers, the feature extraction network (Input-Pool5) is pre-trained with the ImageNet dataset and frozen during the entire simulation [33]. In contrast, the classification network is randomly initialized from a Gaussian distribution with a zero mean and the standard deviation set to balance the input strength across the fully connected layers (bias = 0) [38]."}, {"title": "Flexibility of the synapses", "content": "To realize stable and unstable synapses, we introduced the concept of \"synaptic flexibility\" to modulate the update of individual weights. Flexibility values range from 0 to 1, where a synapse with a flexibility of 0 is deemed fully stable, signifying that its weight remains unchanged. Conversely, a synapse with a flexibility of 1 is entirely unstable, allowing unrestricted updates without downscaled learning rates. This synapse operates identically to the synapses within conventional neural networks. The flexibility of the synapses was collectively set during the network's initialization before it was trained. The assigned flexibility of each synapse is retained throughout the training and testing phases. Specifically, we modulated the learning rate of a given weight, denoted as \"w,\" by scaling it using the function S, which ranges in value from 0 to 1.\n$W_{updated} := w \u2013 [S(flexibility, Aw)\u00b7 \u03b7]J(w,b)$ (1)\nHere, \u03b7 is the learning rate and J(w,b) is a loss function in terms of weight w and bias b. Aw represents the difference between the initial weight value and the weight value after the learning of the previous item. For instance, the Aw value during the phase in which the network learns 3rd item is the difference between the initial weight and the weight immediately after learning 2nd item. S is a function of the flexibility of the weight and Aw, and a is a hyperparameter which scales the width of S.\n$S(flexibility, Aw) = 1 \u2013 tanh\u00b2 (a\\frac{1-flexibility}{flexibility} . Aw)$ (2)"}, {"title": "Training Dataset", "content": "To facilitate the training of networks for the classification of an extended sequence of diverse image classes, we created a two-digit MNIST dataset [39]. This dataset was generated by combining handwritten images of single-digit numbers"}, {"title": "Continual Learning Task", "content": "To assess the continual learning capabilities of model networks, we devised a continual learning task inspired by the structure of sequential working memory tasks [18, 20, 21]. The continual learning task unfolds as a series of sequential tasks, where each task demands the network to identify images of a specific number in a sequential manner (Fig. 2c). For example, in the first task, the network is trained to classify images of the number 38 along with images of numbers that do not include 38 (referred to as non-38). Upon completing the first task, the network progresses sequentially to learn the next class of images, such as 89. This sequential learning process continues until the network goes through all classes within the designated learning sequence."}, {"title": "Test for memorized items versus forgotten items", "content": "To determine if a network memorizes a specific item in a sequence, we introduced the concept of a \u201cmemorized item\". We examined whether a network shows significantly higher performance for each item than for items with randomly shuffled labels. Specifically, we generated one thousand different label-shuffled datasets by randomly permuting the labels of the original dataset and then estimated the network's performance on these shuffled datasets to obtain a thousand different \"control\" performance values. Then, we determined the \u201cmemorized item\" by investigating whether the performance on a particular item is significant (p<0.05), i.e., whether the performance on the original dataset is higher than that on the shuffled datasets, at least for 950 out of 1,000 trials."}, {"title": "Memory Performance Measurement", "content": "After completing the learning of each class of various sample images, the network undergoes testing to classify all classes in the learning sequence. To evaluate the network's memory retention for each class, we measured \"memorization performance,\" defined as the classification accuracy specific to each item. For example, the memorization performance on number 38 is the probability of the network correctly classifying an image of 38 as belonging to number 38. The significance of memory performance was tested by comparing performance values with the chance level, 1/Nreadouts."}, {"title": "Results", "content": ""}, {"title": "Emergence of the serial position effect from the coexistence of stable and unstable synapses", "content": "To investigate the effects of incorporating both unstable and stable synapses on continual learning tasks, we employed a widely used deep neural network model, AlexNet [37]. We designed the metaplasticity of the synapses by adopting the characteristics of the labile long-term potentiation [40] (LTP) (Fig. 2a), a particular form of synaptic plasticity observed in the brain where synaptic weights potentiated by stimulation can be either maintained (stable) or discharged (unstable) depending on the conditions. Accordingly, we defined the concept of \u201csynaptic flexibility\u201d (see Methods for details, see also Supplementary Fig. 1); for a stable synapse, the weight can change initially but is retained stably when largely deviating from the initial value during continual learning (Fig. 2b, left). On the other hand, an unstable synapse is kept flexible, allowing its weight to change continuously throughout the training process (Fig. 2b, right). Based on our earlier works [16, 17], we hypothesized that stable synapses enable the retention of previous memories while unstable synapses facilitate the learning of new information. We thus expected that stable synapses would contribute to the generation of the primacy effect (i.e., items presented first in the sequence are memorized better) while unstable synapses would facilitate the recency effect (i.e., items presented last are memorized better); a model with layers that are intermixed with stable and unstable synapses, therefore, would show the serial position effect [16].\nTo test the role of each type of synapse in continual learning, we introduced the model synapse into the fully connected layers of AlexNet, devising three distinct networks with varying synaptic compositions (Fig. 2c, top). First,"}, {"title": "The serial position effect is robustly preserved even when the item number varies", "content": "Next, to examine the robustness of the hybrid model's serial position effect when the amount of information varies, we sequentially trained the model with 30 readout nodes to learn 30 different items (Fig. 3a). We found that the hybrid model maintained the serial position effect regardless of the length of the sequence, adeptly retaining both old and new information (Fig. 3b, top). Notably, the model sustained memory even for items that exhibited the lowest performance (in the middle of the sequence) well above the chance level, while also successfully learning an unknown number of novel items. In contrast, the conventional model showed catastrophic forgetting, failing to memorize early items in the sequence (Fig. 3b, bottom). As a result, the hybrid model memorized significantly more items than the conventional model (Fig. 3c; *p = 3.70\u00d710-63, two-sample t-test, Ntrial = 100). This result demonstrates the hybrid model's dynamic utilization of memory resources, flexibly allocating a portion of resources to retain old items while using the remainder to encode novel information without any supervision or control algorithm. This caused the average performance across the items to decrease (Fig. 3d) but simultaneously allowed the model to encompass more items above the chance level. This adaptive capability of the hybrid model was further confirmed through estimation of the gross memory (Fig. 3e), calculated by summing the memory performance values of all items included in the sequence. We found that the gross memory increased gradually in both models as the number of trained items increased, but it appeared significantly higher in the hybrid model than in the conventional model (*p = 2.03\u00d710-57, two-sample t-test, Ntrial = 100). Notably, the gross memory in the hybrid model asymptotically converged to a constant value when the number of trained items exceeded a certain value. However, the network could still accommodate more items in its memory by decreasing the average performance of individual items, demonstrating the capacity-performance tradeoff (Fig. 3e). This result highlights the model's adaptability in realistic conditions, where the amount of information to be learned is uncertain."}, {"title": "Memory performance is improved with repeated training", "content": "In the hybrid model, memory performance appears mostly higher for items at the sequence's beginning and end, whereas those positioned in the middle have relatively lower performance outcomes. This results in some items in the middle of the sequence being forgotten, as the total number of items within the sequence increases significantly."}, {"title": "Memory performance is selectively enhanced for frequently presented items", "content": "Our findings demonstrate the hybrid model's proficiency in memory enhancement through repeated training, which could prompt further explorations into potential applications of the model. Specifically, here we hypothesized that the model could selectively enhance the memory of frequently presented items while sacrificing the memory of less frequent items. To test this idea, the hybrid model underwent training with ten distinct items, each featuring varied presentation frequencies ranging from 1 to 10 (Fig. 5a). We expected that the hybrid model would exhibit enhanced memorization for frequently presented items compared to less frequent items, whereas the conventional model would undergo catastrophic forgetting and shows the item-order dependent memory performance found earlier.\nAs expected, the performance of the conventional model exhibited a strong positive correlation with the item order, whereas the hybrid network's performance tended to show a higher correlation with the item's presentation frequency for various network initialization conditions and for the combinations of items composing the learning sequence (Figs. 5b and c). We found that the correlation between the item's performance and its order was significantly higher in the conventional model than in the hybrid model (Fig. 5c, left; Conventional vs. Hybrid, *p = 2.29\u00d710-21, two-sample t-test, Ntrial = 100). In contrast, the correlation between performance and presentation frequency appeared significant in the hybrid model, but none of the trials from the conventional network showed a significant correlation (Fig. 5c, right; Conventional vs. Hybrid, **p = 2.51\u00d710-56, two-sample t-test, Ntrial = 100). Overall, the memory"}, {"title": "Discussion and Conclusion", "content": "We showed that the random mixing of synapses with varying degrees of flexibility could give rise to brain-like characteristics in continuous learning, such as the serial position effect and the Hebb repetition effect. We discovered that DNNs with such connections are able to replicate the serial position effect observed in the brain by maintaining memory for both recent and old items. As a result, the network could continuously learn sequential inputs without catastrophic forgetting, even when the input length varies unexpectedly. Furthermore, we discovered that the network could naturally bring about the frequency-dependent consolidation of repeated information and the adaptive capacity-performance tradeoff, which enables the network adaptively to use memory resources for sequential input and further be robust against data poisoning attacks. Lastly, we showed that the performance level of individual items within the sequence can also be manipulated by controlling their training frequencies.\nOur findings carry significance as they suggest the viability of a straightforward approach \u2013 simply intermixing stable and unstable synapses without modulating the physical structure of conventional model networks to replicate the aspects of continual learning observed in the brain, providing a solution to the problem of catastrophic forgetting in DNNs. Our model carries significant convenience in that it can be implemented in pre-existing neural networks, compared to prior algorithms. Specifically, our model does not necessitate external memory storage beyond the primary network used for continual learning to store the information of previously learned items [15, 45-48]. Furthermore, it avoids alterations to the network architecture, such as additions of extra nodes to accommodate new information [8, 9]. Additionally, it imposes less of a computational burden, such as the calculation of a Fisher information matrix for each task or the tracking of the history of weight changes, to determine which synapses should be stabilized and which should be released [31, 32]. This simplicity and flexibility in implementation allow us to integrate our model in accordance with any specific requirements and constraints.\nOur model specifically possesses features that are advantageous for real-world applications. First, the model achieves the \"capacity-performance tradeoff\" without requiring additional training of information or structural modifications of the network, as noted above (Fig. 3). In sequential learning, the model dynamically reallocates resources from previously learned items to newly acquired ones to retain information pertaining to both items. This feature is particularly useful when the number of items is uncertain and/or the significance of each item within the sequence is unknown. Under such conditions, conventional networks often prioritize the last few items, potentially overlooking previous items and thus struggling to accommodate new information or retain old information as the model encounters extensive data exceeding its capacity. In contrast, our model voluntarily modifies the accuracy level"}]}