{"title": "Evaluating Deep Networks for Detecting User Familiarity with VR from Hand Interactions", "authors": ["Mingjun Li", "Numan Zafar", "Natasha Kholgade Banerjee", "Sean Banerjee"], "abstract": "As VR devices become more prevalent in the con-sumer space, VR applications are likely to be increasingly usedby users unfamiliar with VR. Detecting the familiarity level of auser with VR as an interaction medium provides the potential ofproviding on-demand training for acclimatization and preventsthe user from being burdened by the VR environment inaccomplishing their tasks. In this work, we present preliminaryresults of using deep classifiers to conduct automatic detectionof familiarity with VR by using hand tracking of the user asthey interact with a numeric passcode entry panel to unlock aVR door. We use a VR door as we envision it to the first pointof entry to collaborative virtual spaces, such as meeting rooms,offices, or clinics. Users who are unfamiliar with VR will haveused their hands to open doors with passcode entry panels inthe real world. Thus, while the user may not be familiar withVR, they would be familiar with the task of opening the door.Using a pilot dataset consisting of 7 users familiar with VR, and7 not familiar with VR, we acquire highest accuracy of 88.03%when 6 test users, 3 familiar and 3 not familiar, are evaluatedwith classifiers trained using data from the remaining 8 users.Our results indicate potential for using user movement data todetect familiarity for the simple yet important task of securepasscode-based access.", "sections": [{"title": "I. INTRODUCTION", "content": "Virtual reality (VR) is increasingly being looked at as a\nmechanism for delivering experiences for tasks that users\nmay typically perform in real-world, desktop, and mobile\nenvironments. VR environments are being evaluated across\na diverse spectrum of users for education [1], therapy [2],\n[3], physical fitness [4], and even applications such as secu-\nrity [5], [6] and personal banking [7]. Research in behavior-\nbased VR security shows that user actions in VR change\nat varying timescales [8]\u2013[10]. As VR applications become\nmore prevalent in consumer spaces, the level of first-time or\nearly-stage VR users is expected to rise. For instance, an\nolder adult may be recommended an exercise routine they\ncan perform in a VR space. If the user is unfamiliar with the\nVR application, they may need timely intervention to provide\ntraining as otherwise they may become disincentivized and\nstop using the application. Though such training can be given\nby the service provider, automatic training delivery by detect-\ning the familiarity of the user provides the benefit of providing\non-demand training in the user's personal environment, and\nalleviates the burden on strained service staff.\nIn this work, we provide a first attempt at conducting\nautomated familiarity detection using the movements of a user\nas they engage in a VR task. We use a door opening VR task,\nwhere a user enters a 4-digit passcode combination to open\na VR door, as users, regardless of prior VR experience, will\nhave performed similar tasks in the real world. We envision\nVR doors to be a point of entry to collaborative virtual spaces.\nFor example, a user in a virtual office setting may 'walk' to a\ncommon virtual conference room and enter a combination be-\nfore entering the room. Early detection of prior VR experience,\nin this case through the interaction with the VR door, could en-\nable real-time modifications to the interaction elements before\nthe user enters the conference room to perform more complex\ninteractions. In our approach, we track the finger movements\nof a user entering a passcode combination to unlock a VR\ndoor, and train deep neural networks to detect familiarity with\nVR. We use user-reported binary experience level with VR\nas a representation of familiarity. The task considered, i.e.,\nunlocking a VR door, also has special significance in the area\nof VR security. Recognizing the potential for VR applications\nto store sensitive user data, a number of VR applications\ninvestigate leveraging the VR environment to enable secure\naccess, through passcodes or biometric signatures [5], [6].\nWith the emergence of hand tracking for VR, recent work has\nexplored user identification based on tracking hand data [11]\nIn trying to gain access to a secured space in VR, a novice user\nmay perform actions that cause them to be locked out by VR\nauthentication mechanisms, e.g., pressing the wrong keypad\nbutton due to lack of knowledge on interaction process, or\nperforming a deviating movement.\nTo the best of our knowledge, no work exists for learning-\nbased detection of user familiarity with VR. Some work exists\nin an allied area of using machine learning for familiarity as-\nsessment for a particular task simulated in a VR environment,\ne.g., evaluating surgical skill. For instance, a considerable body\nof work exists to detect surgical skill, by tracking the eye or\nhand movements of the practitioner [12]. Work similarly exists\nin using eye movements to detect soccer player expertise in\nVR [13], [14]. Work has evaluated assessing spatial familiarity\nduring wayfinding based on the eye movements performed\nby a user when turning at junctions [15]. However, the\nfocus is on familiarity with the task, rather than with VR\nas an interaction medium itself. Work on understanding how\ndifferent gaming controllers influence perceptions of usability\nhave been explored [16] and provide insights on how changes\nin ergonomics can impact usage."}, {"title": "II. VR DOOR UNLOCK APPLICATION", "content": "We create a VR environment where users interact with a\nnumeric panel to unlock a VR door via hand tracking using\na controller-free head-mounted device (HMD). We use the\nMeta Quest Pro in this study. As VR environments become\npervasive, an access controlled door may be used to allow\nusers with varying familiarity in VR to enter a virtual meeting\nroom or their office. Users who are unfamiliar with VR would\nstill be familiar with the task from the real world as most\npeople have opened a door using a numeric panel. To unlock\nthe door, the user uses their (controller-free) hands to enter a\nnumeric passcode combination by interacting with VR buttons\nsimulating those on a traditional access panel on a real-world\ndoor. Upon completing the entry, they press a key labeled\n'E' to enter the combination and unlock the door. If the user\nenters the correct combination, the door opens immediately,\nand automatically closes and locks after 3 seconds. We design\nour panel's buttons to consist of block game objects for\ndigits 1 through 0, and the letters 'E' represent enter and\n'C' representing clear. We use native hand tracking enabling\nthe participant to use hand motions to interact with the game\nobjects. We detect if a user has interacted with a button by\ndetecting collisions using the collider on the tip of the index\nfinger on both hands and the colliders on the buttons."}, {"title": "III. DATASET", "content": "We recruited 14 participants from the student, faculty, and\nstaff at Clarkson University. Prior to using the VR envi-\nronment, we asked participants to indicate if they had prior\nexperience in VR. Of the 14 participants, 7 reported no prior\nexperience in VR, i.e., no familiarity, and the remaining 7\nindicated being very familiar with VR. All participants in\nour study are right-handed with 10 participants self reporting\nas male and the remaining 4 as female. We collected data\nusing a Meta Quest Pro and recorded position and orientation\ndata at 60 frames per second. During data collection, we\nasked participants to enter 2648, 2468, 1379, and 3179 on the\nvirtual keypad. Each combination was entered 10 times before\nmoving to the next combination. Once the participant had\nentered a combination, they were asked to press 'E' to open\nthe door. If the participant made a mistake, we asked them to\npress 'C' to clear the code and try again. Incorrect entries were\nstored, but not used during the training and testing phase. We\nobserve that the user who self reported as unfamiliar with VR\nshows a more variable pattern of movement."}, {"title": "IV. EXPERIMENTS", "content": "We evaluate detection of VR familiarity by training classi-\nfiers on sliding windows extracted from the trajectory of the\ndominant hand of the participants in the dataset. We evaluate\nsliding windows of sizes 50, 60, 70, 80, 90, 100, 110, and\n120, with a step size of 1. For each sliding window choice,\nwe evaluate three types of classifiers\u2014multi-layer perceptrons\n(MLPs), fully convolutional networks (FCNs) [17], and Point\nCloud Transformer (PCT) [18]. We train one classifier per\nsliding window and per key combination.\na) Multi-Layer Perceptron: We design our MLP to con-\nsist of 2 position-wise dense feed-forward layers where the\ndimension of the output for each layer is set at half of the input\ndimension. We retain this pattern across the hidden layers.\nFollowing each hidden layer, we apply a ReLU [19] activation\nlayer. The output layer followed by a softmax layer to obtain\nthe predicted class probabilities.\nb) Fully Convolutional Network: We employ the FCN\narchitecture as described by Wang et al. [17]. The archi-\ntecture consists of 3 convolutional blocks, each featuring a\nconvolutional layer with a filter size of {128, 256, 128} and\na 1D kernel with the size of {8, 5, 3}. We apply batch\nnormalization layers [20] after each convolutional layer. We\nuse ReLU activation layer at the end of each block. After the\n3 blocks, we use a global average pooling layer [21] and a\nsoftmax operation for the final class probabilities.\nc) Point Cloud Transformer: The Point Cloud Trans-\nformer (PCT) [18], created to address point cloud inputs\nvia an attention architecture, consists of 4 stacked attention\nblocks. The outputs of each attention block are concatenated,\nadditional max-pooling and average-pooling operations are\napplied, and the output is passed through several linear layers\nto produce the final classification probabilities. Given that our\ndataset contains trajectories that occupy a constrained space,\nwe reduce the complexity of the PCT model by removing the\nconcatenation of attention module outputs and eliminating the\nsubsequent max-pooling and average-pooling layers.\nd) Training and Test Split: To ensure independence of\nusers between the training and test sets, we randomly select\na subset of 4 VR-familiar users and 4 non-VR-familiar users\nfor training, and use the remaining 3 VR-familiar users and"}, {"title": "e) Loss Function:", "content": "We optimize the parameters of each\nmodel by minimizing the Binary Cross-Entropy (BCE) loss,\n$L = (1/|W|)\\Sigma{w} BCE(pred, gt)$,\nwhere |W| denotes the number of windows, pred is the\npredicted label, and gt represents the ground truth label. We\nuse Adam [22] to optimize the parameters of all the models."}, {"title": "V. RESULTS", "content": "Tables I and II summarize the results acquired by running\nthe three classifiers examined in this work with various sliding\nwindow sizes and numeric passcode combinations. We show\npeak test accuracy and the FCN classifier shows higher overall area under the curve\n(AUC) for the 3197 combination compared to the MLP and\nPCT classifiers. PCT generally shows higher AUC for 2648.\nFor lower window sizes, the FCN shows higher AUCs for both\ncodes, and the MLP shows higher AUC for higher window\nsizes, potentially due to its simpler architecture.\nWe observe that 2468 and 1379 show results close to\nchance. A possible reason is that given the order of entry,\ni.e., 2648, 2468, and 1379, users may be getting acclimatized\nto the environment. With the 3197 combination, unlike the\nother 3, the user moves from right to left. During this motion,\nusers not familiar with VR may need re-acclimatization time,\nthough further data collection and analysis is necessary."}, {"title": "VI. CONCLUSION", "content": "We demonstrate results of using deep networks to classify\nfamiliarity of a user in a VR environment using their move-\nment patterns as they interact with a virtual keypad on a door.\nThe task of opening a door after entering a combination is\nfamiliar to all users from having opened similar doors in the\nreal world. We obtain highest accuracies upwards of 80%\nfor combinations 2648 and next highest for 3197. Results indicate potential for the use of VR movements to detect\nfamiliarity, though the effect of time on acclimatization may\nneed to be considered, i.e., conducting familiarity detection\nearly is critical. As part of ongoing work, we are working\non expanding our data collection to include a diverse array\nof users and VR tasks of varying complexity. With a broader\ndataset, we intend to expand prior familiarity from a binary\nlabel to a 5-point Likert scale. We are also interested in\nusing eye and head movements to gauge whether distractions\nfrom the novelty of the environment play a role in familiarity\ndetection, e.g., if a novice user spends time examining a new\nenvironment or is taken aback. As part of future work, we\nare interested in investigating whether on-demand training to\nfamiliarize novice users of VR is more effective than adapting\nthe VR environment or controller to have a reduced interaction\nscope. The reduced interaction scope may be actualized by\nreducing the amount of movement in the VR environment\nwhen the person moves the analog stick, or adding pop-up\nhints when performing an interaction in the environment such\nas opening a door. Our current familiarity detection task in VR\nuses a door unlock panel which requires interactions with the\ndominant hand. Future studies on more complex tasks, or even\nunfamiliar tasks, that require both hands, or controllers, is of\ninterest as most activities in VR involve a full body experience."}]}