{"title": "TRACTOGPT: A GPT ARCHITECTURE FOR WHITE MATTER TRACT SEGMENTATION", "authors": ["Anoushkrit Goel", "Simroop Singh", "Ankita Joshi", "Ranjeet Ranjan Jha", "Chirag Ahuja", "Aditya Nigam", "Arnav Bhavsar"], "abstract": "White matter bundle segmentation is crucial for studying\nbrain structural connectivity, neurosurgical planning, and\nneurological disorders. White Matter Segmentation remains\nchallenging due to structural similarity in streamlines, sub-\nject variability, symmetry in 2 hemispheres, etc. To address\nthese challenges, we propose TractoGPT, a GPT-based ar-\nchitecture trained on streamline, cluster, and fusion data\nrepresentations separately. TractoGPT is a fully-automatic\nmethod that generalizes across datasets and retains shape\ninformation of the white matter bundles. Experiments also\nshow that TractoGPT outperforms state-of-the-art methods\non average DICE, Overlap and Overreach scores. We use\nTractoInferno and 105HCP datasets and validate generaliza-\ntion across datasets.", "sections": [{"title": "1. INTRODUCTION", "content": "Fiber tract segmentation is a pivotal process in Neuroimag-\ning, enabling detailed analysis of White Matter connectiv-\nity through Diffusion Magnetic Resonance Imaging (dMRI).\nTractography traces the anisotropic diffusion of water molecules\nalong neural pathways, yielding three-dimensional stream-\nlines that represent white matter fiber bundles. These stream-\nlines are grouped into specific anatomical tracts, providing\ncrucial insights into brain connectivity and function, essen-\ntial for understanding development, aging, and neurological\nconditions [1]. With recent advancements, fiber tract seg-\nmentation methods can be broadly categorized into classical\nand deep learning techniques. Classical methods, such as\nQuickBundles and QuickBundlesX, use Mean Direct-Flip\nDistance (MDF) to cluster streamlines into bundles or tracts\n[2]. Other Techniques, like WMA [3], incorporate anatomi-\ncal priors, while RecoBundles [4] recognizes model bundles,\nand BundleSeg [5] enhances this recognition within target\ntracts via Fast Streamline Search. Deep learning Tract Seg-\nmentation approaches, for instance, TractSeg [6] employs\nConvolutional Neural Networks (CNNs) across multiple MRI\nslices, and DeepWMA [7] utilizes novel fiber descriptors.\nAdditionally, clustering techniques like CINTA [8] lever-\nage streamline clustering, and FINTA [9] does filtering in\nembedding space, and FIESTA [10] further improves the per-\nformance by employing autoencoders to segment and filter\nstreamlines in latent space through FINTA multibundles, then\ngenerating additional streamlines with GESTA-GMM [11] to\nfill bundles and meet semi-automatically calibrated bundle-\nspecific thresholds. Recent tract segmentation studies have\nalso explored point cloud networks [12, 13, 14]. But many\nmethods stated above either require registration, ATLAS,\nfiltering or calibration for thresholds. In this paper,\n\u2022 We introduce TractoGPT, a novel, fully-automatic,\nregistration-free white matter segmentation network\ninspired by the GPT architecture using auto-regressive\npretraining.\n\u2022 In addition to TractoGPT framework, we introduce a\nFusion Data Representation which enhances representa-\ntion for tractography streamline data for downstream seg-\nmentation task.\n\u2022 TractoGPT also generalizes across datasets and retains\nshape information of major White Matter Bundles."}, {"title": "2. METHODOLOGY", "content": "2.1. dMRI Datasets and Tractography\nWe use datasets mentioned in Table 1 where TractoIn-\nferno [16] is a silver-standard dataset created by ensembling\n4 tracking methods and RecoBundlesX [4] to generate ground\ntruth streamlines and recognize bundles respectively, yielding"}, {"title": "2.2. Data Representations", "content": "Process of Whole Brain Tractography (WBT) yields stream-\nlines, i.e. variable sequence of 3D coordinates which are input\nto TractoGPT along with label of each streamline.\nTo embed a richer understanding of tractography data to\nthe model, we propose 3 data representations, streamline,\ncluster, and fusion data (refer Fig. 1, Stage I), either of which\ncan be used as the Training Data. Multiple data represen-\ntations are used to combat local information deficiency in\nsingle streamline data.\n\u2022 Streamline: Streamlines can be of variable length, hence\nwe bicubic interpolate streamlines of (n,3) dimension to\nget a (256,3) dimensional array, as shown in Fig.1 Stage I.\n\u2022 Cluster: We provide streamlines with relative location in-\nformation by sampling clusters of streamlines resembling\nparent bundles. We modify QuickBundlesX (QBx) clus-\ntering to devise, QBx Clustering with move up. Here,\nclusters are initially formed at hierarchical thresholds of\n[40,30,20,10,8,6,4] mm, but only the finest three levels (4\nmm, 6 mm, and 8 mm) are used for training. To ensure the\nquality of the cluster, we sample a minimum threshold of\n10 streamlines per cluster. Beginning from the finest level\n(4 mm), if a cluster lacks the required number of stream-\nlines, then the method moves up to the next coarser level\n(6 mm, then 8 mm) to use clusters sampled in new radius.\nClusters formed above 8mm are discarded to avoid pres-\nence of multiple classes in coarser clusters.\nAfter a cluster is formed, 1024 random points are selected\nfrom a cluster (group of streamlines) to create a point\ncloud with a shape of (1024, 3), refer (ii) in Fig.1.\n(Note: Sampled Streamlines in this method are not inter-\npolated and clusters are mutually exclusive)\n\u2022 Fusion: Fusion Data is a fusion of streamline and cluster\ndata allowing the amalgamation of both representations.\nFor fusion data, 256 points are sampled from the inter-\npolated streamline of interest, and the rest 768 points are\nsampled from the non-interpolated neighboring stream-\nlines to make a 1024-dimensional array (see (iii), (iv)\nin Fig.1).(Note: Interpolation allows focus on selected"}, {"title": "2.3. Tokenization", "content": "Points in point clouds individually are spatial coordinates and\nhave minimal information to learn spatial representations,\nwhereas a group of points give regional information on the\nshape of the point cloud. We create point patches to embed\nregional information in tokens using an encoder network.\nAs mentioned in the caption of Fig. 1, point patches\nare obtained through FPS-kNN (Farthest Point Sampling &\nk-Nearest Neighbors) where the farthest points are treated\nas centroids to make patches by sampling K neighbors via\nkNN. For GPT architecture, sequential information is re-\nquired among tokens which are extracted using sorted Mor-\nton Order (or Z-order curve) on encoded K center points\n(1-dimensional array), and this Relative Positional Encoding\nis passed to the Generator part of TractoGPT (see Fig. 1)[17].\nThe coordinates of each point are normalized relative to its\ncenter point before they are fed to the PointNet-style encoder\n[18], giving a latent representation per patch to make tokens,\nalong with the Morton order sequence. While setting patch\nconfiguration, a patch size of 32 points for [Fusion, Cluster]\nand 8 points for Streamline. Number of patches is set to 64\nfor all representations to ensure overlapping patches, maxi-\nmizing retention of continuous information across the whole\ninput point cloud X."}, {"title": "2.4. TractoGPT Model", "content": "In TractoGPT, sequence of tokens extracted from the Tok-\nenization process (refer to Section 2.3) undergo autoregres-\nsive pre-training strategy on all data representations sepa-\nrately (refer Fig. 1), ablation across these representations\nhave been done in Table 2. We propose an architecture con-\nsisting Extractor and Generator which are essentially stacked\ntransformer decoder blocks, inspired by PointGPT, Point-\nBERT, and other point cloud architectures [17, 19, 20].\nOverall pre-training objective of TractoGPT is to recon-\nstruct input point cloud patch X coordinates learning latent\nrepresentations which would be later fine-tuned for down-\nstream tasks. While pre-training we use dual masking strat-\negy which does intermittent masking on top of causal mask-\ning inhibiting model to overfit on the input point cloud data.\nCausal masking is used in training Next Token Prediction\ntasks and intermittent masking can be understood as a propor-\ntion of masked preceding tokens attending to each unmasked\npreceding token.\nDue to random transformations of points while training,\norder of points is not preserved, leading to ambiguity in pre-\ndicting consecutive patches. To mitigate this ambiguity the\nGenerator incorporates directions as Relative Patch Positions\nEncoding (refer Fig. 1 Stage II and III), without disclosing\nthe locations of masked patches or the overall shapes of the\npoint clouds. The extractor takes sinusoidal positional en-\ncoded tokens sorted by Morton ordering, prediction head of\nthe Generator is designed to predict subsequent point patches\nin the coordinate space. The Generator comprises of 2 FCNN\nlayers with (ReLU) activation functions, and is shallower than\nthe Extractor.\nLosses: Goal of the Generator is to reconstruct patch\ncoordinates from patch tokens. For pre-training, generation\nloss is calculated using summation of L1-norm (CDL1) and\nL2-norm (CDL2) of the Chamfer Distance (CD) in equal\nproportions. During fine-tuning, we freeze the Generator\nand fine-tune the Extractor on cross-entropy loss along with\n(CDL1, CDL2) for the downstream classification task to\nprevent overfitting and increase robustness."}, {"title": "2.5. Model Training and Testing", "content": "A consistent number of streamlines per class across all train-\ning subjects is used to mitigate imbalance for training Trac-\ntoGPT (for example: we use 500 streamlines per subject\nper class on a single streamline which can vary based on\nthe choice of data representation). But while testing, all\nstreamlines of a test subject are classified, without leaving a\nsingle streamline behind. In TractoGPT training and test-\ning strategy, we implement a comprehensive approach that\nincludes pretraining, fine-tuning, and testing. Pretraining\ninvolves reconstruction of patch coordinates using a 50:50\nChamfer Loss (L1 and L2 norm) without labels, optimized\nwith AdamW (weight decay of 0.05) and a cosine learning\nrate scheduler starting at 0.0001 learning rate, over a maxi-\nmum of 100 epochs (converges earlier). In fine-tuning for\nclassification, we employ a combination of Cross Entropy\nand Chamfer Distance Loss (CDL1 + CDL2). The overall\nstrategy is designed to optimize the model's performance in\nclassification and reconstruction tasks while leveraging ad-\nvanced loss functions for effective tractography streamlines\nunderstanding. TractoGPT takes about 4 days on average to\nconverge (cluster < streamline < fusion) and 12 hours to in-\nfer on a single V100 16 GB respective splits of TractoInferno\nDataset."}, {"title": "3. EXPERIMENTS AND RESULTS", "content": "We perform rigorous experiments with the current state-of-\nthe-art tractography segmentation models, FINTA-m, RBx\nacross the list of 23 common tracts in TractoInferno and\nHCP dataset. We show the Ablation Study, in the Table\n2, where we can see Fusion is comparable to the Cluster,"}, {"title": "4. CONCLUSION", "content": "In this study, we propose TractoGPT, a novel GPT-based ar-\nchitecture for White Matter Tract Segmentation with SOTA\nresults on TractoInferno dataset, proven potential of general-\nization across datasets, while preserving shape information of\nWhite Matter bundles. We introduced Fusion Data which en-\nriches Streamline-only data representation for segmentation."}]}