{"title": "RUMI: Rummaging Using Mutual Information", "authors": ["Sheng Zhong", "Nima Fazeli", "Dmitry Berenson"], "abstract": "This paper presents Rummaging Using Mutual In-formation (RUMI), a method for online generation of robot action sequences to gather information about the pose of a known movable object in visually-occluded environments. Focusing on contact-rich rummaging, our approach leverages mutual information between the object pose distribution and robot trajectory for action planning. From an observed partial point cloud, RUMI deduces the compatible object pose distribution and approximates the mutual information of it with workspace occupancy in real time. Based on this, we develop an information gain cost function and a reachability cost function to keep the object within the robot's reach. These are integrated into a model predictive control (MPC) framework with a stochastic dynamics model, updating the pose distribution in a closed loop. Key contributions include a new belief framework for object pose estimation, an efficient information gain computation strategy, and a robust MPC-based control scheme. RUMI demonstrates superior performance in both simulated and real tasks compared to baseline methods.", "sections": [{"title": "I. INTRODUCTION", "content": "Active exploration, the process of autonomously planning actions to gather more information about a target quantity, is a core problem in robotics, particularly when dealing with unknown environments [2]. This problem encompasses a range of scenarios, differentiated by the type of robot (e.g., mobile vs. stationary), the primary sensor modality (often vision), and the specific quantity to be estimated.\nAs robotics applications have transitioned from known, structured environments like factories to the unknown, dynamic environments of homes, new challenges have emerged. One critical application area is object manipulation, where visual perception is often hindered by occlusions caused by both the environment and the objects themselves [54]. To address these challenges, we focus on actively exploring to estimate the pose of a movable object with a known shape through contact-rich interactions, commonly referred to as rummaging.\nOcclusions of the target object, both from itself and from other objects, motivate the need to use contact to determine the object's pose. Our prior work has investigated how to track the position of contact points during rummaging with an unknown number of objects [53], and how to estimate the plausible set of object poses given observed contact and free space points [54]. However, the problem of how to plan information-gathering trajectories to estimate a movable object's pose is still under-explored. A primary challenge is the object's mobility, coupled with the requirement for contact-based information collection. Without careful planning, making contact can inadvertently push the object out of the robot's workspace, as evidenced in our experiments.\nActive exploration is often framed from an information-theoretic perspective, where the quantity to be estimated is treated as a random variable, and actions are selected to minimize its uncertainty. This approach can be computationally expensive, necessitating a trade-off between accuracy and speed or limiting the exploration to a single next best action. Additionally, some methods restrict the action space to movements along the object's surface [47], [13]. While this restriction simplifies the problem, it also limits the robot's capabilities. Instead, we aim to enable robots to make and break contact dynamically throughout the rummaging process, enhancing their exploratory capabilities.\nTo address the above challenges, we present Rummaging Using Mutual Information (RUMI), an active exploration method. Specifically, our contributions include:\n1) a framework for creating and updating a belief over poses given observed point clouds, augmented with volumetric semantics such as whether each point is in free space or on the surface of the object, based on the discrepancy formulated in CHSEL [54]\n2) a measure of information gain based on the mutual information between the object pose and volumetric semantics at the positions that the robot trajectory will cover, and show that it can be efficiently computed in parallel for dense workspace points in real time\n3) a closed loop MPC planning framework using cost functions based on the information gain and maintaining object reachability, and a stochastic object dynamics model\nIn our experiments, we show that RUMI is the only method to achieve consistent success in simulated and real robot rummaging tasks across various objects."}, {"title": "II. RELATED WORK", "content": "In a broad sense, we focus on the problem of actively exploring an unknown environment to reduce the uncertainty of some quantity. There are many variants and names for the problem, including active sensing [42], sensor path plan-ning [5], active perception [2], and interactive perception [3]. The variants differ primarily by the robot type (mobile vs stationary base), sensing modality, and by the quantity to be estimated; e.g. the map of the environment [29], [38], [18], the shape of an object [13], [51], the pose of an object (object localization) [10], [1], or the pose of effective grasps for objects [20], [37]. In the case of unknown object shape, or reconstruction from a set of objects, the problem is also known as active shape completion [41]. This paper focuses on estimating the pose of a movable rigid object with a known shape.\nIn general, active exploration is the iterative process of:\n1) forming a belief over state given observations\n2) computing expected information gain over a workspace\n3) planning an action sequence\n4) executing some of the action sequence and collecting observations"}, {"title": "A. Representing Belief", "content": "Representations suitable for active exploration have been studied extensively. In many cases, parametric filters like the extended Kalman Filter (EKF) [43], [27] may be used when the posterior of the quantity of measure should be approximately Gaussian. Otherwise, non-parametric methods like particle filters [11], [21] are often used. Occupancy grids have also been popular, e.g. used in the simultaneous localization and mapping (SLAM) variant of active exploration [34], [49], [8]. In particular, when assuming each grid cell is independent, information gain based on the entropy of all the cells may be efficiently computed on an occupancy grid. We make a similar assumption that enables efficient computation of our information gain.\nRecently, Gaussian processes (GPs) [18] have also been used for estimating object shape. GP implicit surfaces (GPIS) have shown strong representation power [12], [13]. GPIS uses a GP to output a field in which the 0-level set represents the surface of the object. In our method, we do not need the full representation power of a GP since we have a known object shape. Instead, we use a particle filter to represent the pose distribution, and present a novel way to evaluate the particle probabilities given an observed point cloud."}, {"title": "B. Information Gain", "content": "The information gain can be formulated in many ways, often depending on the belief representation. For GPIS the variance of the GP [13], or the differential entropy of the GP for adding a new data point [14] can be evaluated directly and used. However, despite work on geometric shape priors for GPIS [31], there remains no satisfactory way to condition a GP on a known shape with unknown pose. We implement a GPIS baseline and condition it on the shape by augmenting the input data. Mutual information between observations and the estimated quantity is also common [18], [30], which measures the reduction in uncertainty of the estimated quantity given the observations. Thus, we formulate our information gain function based on the mutual information between the object pose and the occupancy at points a robot trajectory would sweep out."}, {"title": "C. Planning", "content": "Searching for an optimally-informative trajectory is usually computationally intensive. GP-based methods in particular are limited by inference times that grow rapidly with increasing number of data points, often addressed by using sparse GPs or downsampling to trade off accuracy [45]. Some methods greedily selects the optimal next configuration, and additionally constrain the action space to slide along the surface of the object [47], [13]. Our formulation of the information gain allows us to efficiently evaluate it for many query trajectories in parallel, enabling us to use longer-horizon planning methods such as sampling-based model predictive control in a closed loop. We consider difficult tasks which necessitate long horizon planning.\nActive exploration problems also differs by sensing modality. In the context of object shape and pose estimation, the most common modality is visual perception, with the common framing of the problem as finding the next best view [22]. Tactile approaches have also demonstrated success [51], [13], as well as hybrid approaches [41], [44]. Tightly coupled with sensing modality is the distinction of whether the robot is passively observing the environment or actively interacting with and changing the environment as in the interactive perception problem [3]. RUMI is a hybrid approach for interactive perception, primarily relying on contact-rich interactions using tactile sensors, but also leveraging visual perception to initialize pose estimates. Visual perception in our case is weakened by environmental occlusion and object self-occlusion. Unlike most other methods for object pose or shape estimation, we do not assume the object is stationary, which accounts for a large part of the difficulty. The closest method to ours is Act-VH [41], which trains an implicit surface neural network to output hypothesis voxel grids of seen objects given a partially observed point cloud and selects the best point to probe next. One major weakness of this method is the need to either retrain their network on all candidate objects whenever there is a new target object, or to train a network per object and assume object identity is known. Our method can be applied to new known objects without any training. Additionally, their object is in between the robot and the camera, meaning that the visually-occluded region is highly reachable, bypassing a major challenge that we address. Lastly, we consider the information gain from full robot trajectories rather than a single next point to probe."}, {"title": "III. PROBLEM STATEMENT", "content": "Let $q \\in \\mathbb{R}^{N_q}$ denote the robot configuration, and $u \\in \\mathbb{R}^{N_u}$ denote control. We study a single robot exploring an unmodeled environment, using limited visual perception and contact-heavy rummaging to estimate the pose of a single movable rigid target object of known shape. A rigid object's configuration is defined by its pose, a transform $T \\in SE(3)$. Every $T$ can be identified with a $\\mathbb{R}^{4 \\times 4}$ homogeneous transformation matrix, and for convenience, we use $x = Tx$ to denote the homogeneous transform of point $x \\in \\mathbb{R}^3$ from world frame coordinates to the object frame of $T$ (homogeneous coordinates have 1 appended). There is an underlying dynamics function $f: \\mathbb{R}^{N_q} \\times \\mathbb{R}^{N_u} \\rightarrow \\mathbb{R}^{N_q}$ that we do not know, but are given the free space dynamics function $f_f: \\mathbb{R}^{N_q} \\times \\mathbb{R}^{N_u} \\rightarrow \\mathbb{R}^{N_q}$. The difference in dynamics is primarily due to contact between the robot and the target object. We are interested in generating a fixed length trajectory of $T$ actions, $u_1,..., u_T$ to actively explore and estimate the target object's pose.\nSpecifically, we have the target object's precomputed object frame signed distance function (SDF) derived from its 3D model, $sdf : \\mathbb{R}^3 \\rightarrow \\mathbb{R}$. After each action, sensors observe a set of points at time t : $X_t = \\{(x_1, s_1), ..., (x_N, s_N)\\}t$ with observed world positions $x_n \\in \\mathbb{R}^3$ and semantics $s_n$ (described below). For convenience, we refer to a pair of position and semantics as a geometric feature. Let $X_t$ denote the accumulated set of geometric features up to and including time t. Sensors may include but are not limited to robot proprioception, end-effector mounted tactile sensors, and external cameras.\nWe treat the pose of the target object as a random variable and define $p(T|X_t)$ as the posterior probability distribution over poses given $X_t$. Observation noise, object symmetry, and the partial nature of $X_t$ results in pose uncertainty.\nLet $T^*$ be the true object transform, then the observed semantics are\n$\\begin{cases}\nfree & \\text{implies } sdf(T^*x_n) > 0\\\\\noccupied & \\text{implies } sdf(T^*x_n) < 0\\\\\nsurface & \\text{implies } sdf(T^*x_n) = 0\n\\end{cases}$\nFor a workspace point x that we have not observed, its semantics is a discrete random variable $S_x$ with the shorthand $p(S_x) = p(s|x)$. We are given a sensor model $p(S_x|T) = p(S_x|sdf(Tx))$ such as in Fig. 2 that gives the probability of observing each s value given a SDF value. The sensor model does not consider uncertainty over the position, and we assume we are given exact positions with only uncertainty over semantics $S_x$.\nGiven a prior p(T), and starting at $q_1$, our goal is to estimate the pose of the object by maximizing the expected information gain after T actions:\n$\\underset{U_1,..., U_T}{\\text{arg max }} \\mathbb{E}_{X_T} [D_{KL}(P(T|X_T)||p(T))]$\n$\\text{s.t. } q_{t+1} = f(q_t, u_t), t = 1, ...,T$\n(1)\nThe expectation is over the semantics of each position in $X_T$. Note that this is equivalent to the mutual information between T and $X_T$, $I(T; X_T)$ [36].\nThe challenge of this problem comes from the need for contact-based perception due to limited sensing capabilities, coupled with the fact that the target object is movable. Moreover, an ineffective action sequence can result in undesirable contacts, potentially pushing the object out of the robot's reachable workspace.\nWe evaluate the quality of the estimated pose distribution by evaluating the likelihood of the ground truth pose $L(T^*|X_t)$, or equivalently its negative log likelihood (NLL). Low NLL indicates both certainty and correctness of the pose distribution. We do so by sampling a set of surface points in the object frame and transforming them by $T^*$ to produce world positions X. We then evaluate the NLL of all of the points having surface semantics:\n$nll(X) = - \\underset{x \\in X}{\\text{log }} p(S_x = surface|x)$ (2)\nWe use this metric as well as computational efficiency to evaluate our method against baselines and ablations."}, {"title": "IV. METHOD", "content": "Our high level approach to addressing the problem in Eq. 1 is depicted in Fig. 3. We represent the pose posterior $p(T|X)$ with a particle filter and describe how to evaluate $p(T|X)$. Next, we present a tractable surrogate for information gain that we develop into a cost function for model predictive control (MPC). To discourage trajectories that move the target object out of the robot's reachable area, we develop an additional reachability cost function. Furthermore, to estimate the displacement of the target object given an action trajectory, we implement a stochastic dynamics model f. We use the cost functions and the dynamics function inside MPC, which executes in a closed loop for T steps. During this process, we detail how to merge current observations with previous ones and update the pose posterior $p(T|X)$."}, {"title": "A. Representing Pose Posterior", "content": "We maintain a belief over the pose posterior $p(T|X_t)$ using a particle filter, where each particle is a pose. We have P particles $T_{1..P}$, with weights $W_{1..P}$ such that $\\Sigma_{i=1}^P W_i = 1$.\nOur choice of a particle filter over alternative representations is motivated by the potential multi-modality of the posterior and the ability to process each particle in parallel.\nA major obstacle to the tractability of solving Eq. 1 is the information correlation between geometric features. Observing one decreases the information gain from others in a non-trivial manner, and it is a common long-standing assumption to consider the information gain from each independently [7], [46]. Thus, we assume the conditional mutual independence of $S_x$ for all query positions x given observed $X_t$.\nCritical to our method is a way to evaluate the posterior $p(T|X)$. Our prior work CHSEL [54] formulated a differentiable cost function $\\hat{C}(X, T)$ that evaluates the discrepancy between X and T. It bears similarity to hydroelastic, or pressure field contact modelling [15], [32], except in addition to the pressure field penalizing object penetration, there are pressure fields that penalize semantics violation, such as observed free space geometric features being inside objects.\nWe simplify the third semantics class from CHSEL, which represented known SDF of any value. We restrict it to s = 0, which refers to surface points. The cost is formulated by first partitioning the observed X into $X_f = \\{(x, s) | s = free\\}$, $X_o = \\{(x,s) | s = occupied\\}$, and $X_s = \\{(x,s) | s = surface\\}$.\n$\\hat{C}(X, T) = \\underset{x,s \\in X_f}{\\sum} \\hat{c}_f(x) + \\underset{x,s \\in X_o}{\\sum} \\hat{c}_o(x) + \\underset{x,s \\in X_s}{\\sum} \\hat{c}_k(x,s)$ (3)\n$\\hat{c}_f(x) = C \\text{ max}(0, a - sdf(x))$ (4)\n$\\hat{c}_o(x) = C \\text{ max}(0, a + sdf(x))$ (5)\n$\\hat{c}_k(X, s) = |sdf(x) - s|$ (6)\nwhere C > 0 is a scaling parameter and a > 0 allows for small degrees of violation due to uncertainty in the positions."}, {"title": "Their gradients are defined as", "content": "$\\nabla \\hat{c}_f(x) = C \\text{ max}(0, a - sdf(x))(-\\nabla sdf(x))$ (7)\n$\\nabla \\hat{c}_o(x) = C \\text{ max}(0, a + sdf(x))\\nabla sdf(x)$ (8)\n$\\nabla \\hat{c}_k(x, s) = (sdf(x) - s) \\nabla sdf(x)$ (9)\nwhere $\\nabla sdf(x)$ is the object SDF gradient with respect to an object-frame position x and normalized such that $|\\nabla sdf(x)||_2= 1$.\nSimilar to energy-based methods, we use the Boltzmann distribution [17], [48] to interpret Eq. 3 as the posterior pose probability:\n$p(T|X) = \\eta e^{-\\lambda \\hat{C}(X,T)}$ (10)\nwhere $\\lambda > 0$ selects how peaky the distribution should be and $\\eta$ is the normalization constant such that $\\int \\eta e^{-\\lambda \\hat{C}(X,T)} dT = 1$.\nWe observe that the cost in Eq. 3 is additive in the sense\n$\\hat{C}(X \\cup (x, s), T) = \\hat{C}(X, T) + \\hat{C}((x, s), T)$ (11)\nThis is an important property that enables us to efficiently evaluate information gain of all workspace positions in parallel."}, {"title": "B. Mutual Information Surrogate", "content": "Our conditional mutual independence assumption of $p(S_x|X)$ lets us consider the information gain from knowing the semantics at a single new position, which we denote the information gain field $\\hat{I}(x|X)$. This is much simpler than considering the information gain of a robot trajectory directly because there is no time component or correlation between the semantics of neighbouring geometric features. Suppose we have observed X and want to evaluate the information gain from observing some new geometric feature (x, s). Note that here we are querying a specific given value of x, but $S_x$ is still a random variable, so the expectation is over $p(S_x|X)$:\n$\\hat{I}(x|X) = \\mathbb{E}_{s \\sim p(S_x|X)} [D_{KL}(P(T|X \\cup (x, s))||p(T|X))]$ (12)\n$= \\mathbb{E}_{s} [ \\mathbb{E}_{T \\sim p(T|X \\cup (x, s))} [\\text{log } \\frac{p(T|X \\cup (x, s))}{p(T|X)}]] $ (13)\nThe forward KL divergence results in an expectation over $p(T|X \\cup (x, s))$. Since we need to evaluate the information gain for many positions in the workspace, this becomes intractable. To address this challenge, we use the reverse KL divergence, since the expectation is then over p(T|X) for all queried positions. In general, KL divergence is not symmetric. However, when two distributions are close together the KL divergence is approximately symmetric [52], [23]. In our case the KL divergence is between p(T|X) and $p(T|X \\cup (x, s))$ with all having SE(3) support, avoiding infinite divergences. As we increase X during exploration, we expect the two distributions to become closer and the reverse KL to better approximate the forward KL divergence.\nIntuitively, a geometric feature has high reverse KL divergence if it has high p(T|X) and low $p(T|X \\cup (x, s))$. These correspond to geometric features that would invalidate currently high-probability poses i.e. these are positions we would like to explore.\nUsing reverse KL, We now have\n$\\hat{I}_r(x|X) = \\mathbb{E}_{s} [D_{KL}(p(T|X)||p(T|X \\cup (x, s)))] $ (14)\n$= \\mathbb{E}_{s} [ \\mathbb{E}_{T \\sim p(T|X)} [\\text{log } \\frac{p(T|X)}{p(T|X \\cup (x, s))}]]$ (15)\nSubstituting Eq. 10 in\n$\\hat{I}_r(x|X) = \\mathbb{E}_{s} [ \\mathbb{E}_{T \\sim p(T|X)} [\\text{log } \\frac{\\eta_1e^{-\\lambda \\hat{C}(X,T)}}{\\eta_2e^{-\\lambda \\hat{C}(X \\cup (x, s), T)}}]]$\n$= \\mathbb{E}_{s} [ \\mathbb{E}_{T \\sim p(T|X)} [\\text{log } e^{-\\lambda (-\\hat{C}(X, T) + \\hat{C}(X \\cup (x, s), T))}] + \\text{log } \\frac{\\eta_1}{\\eta_2}] $ (17)\n$= \\lambda \\mathbb{E}_{s} [ \\mathbb{E}_{T \\sim p(T|X)} [-\\hat{C}(X, T) + \\hat{C}(X \\cup (x, s), T)]] + \\text{log } \\frac{\\eta_1}{\\eta_2} $ (18)\n$= \\lambda \\mathbb{E}_{s} [ \\mathbb{E}_{T \\sim p(T|X)} [\\hat{C}((x, s), T)]] + \\text{log } \\frac{\\eta_1}{\\eta_2} $ (19)\nwhere $\\eta_1$ and $\\eta_2$ are the normalizing constants for $p(T|X)$ and $p(T|X \\cup (x, s))$, respectively. First we simplify using the additive property of $\\hat{C}$ (Eq. 11) then consider the normalizing constants,\n$\\hat{I}_r(x|X) = \\lambda \\mathbb{E}_{s} [ \\mathbb{E}_{T \\sim p(T|X)} [\\hat{C}((x, s), T)]] + \\text{log } \\frac{\\eta_1}{\\eta_2} $ (20)\nWe note that $\\eta_2$ depends on the querying position x because each x induces a different $p(T|X \\cup (x, s))$. This normalizing constant is intractable to compute because it involves an integral over T, so we instead optimize the approximation\n$\\hat{I}(x|X) = \\lambda \\mathbb{E}_{s} [ \\mathbb{E}_{T \\sim p(T|X)} [\\hat{C}((x, s), T)]]$ (21)\n$= \\lambda \\underset{s}{\\sum} p(S_x = s|X) [\\underset{T}{\\sum} \\hat{C}((x, s), T)]$ (22)\nSelecting $\\lambda$ too high leads to the pose particle weights dominated by a few, causing particle degeneracy."}, {"title": "We approximate the expectation over the posterior by taking the weighted sum over the pose particles", "content": "$\\hat{I}(x|X) \\approx \\lambda \\underset{s}{\\sum} \\underset{i=1}{\\mathbb{P}} p(S_x = s|X)w_i\\hat{C}((x, s), T_i) $ (23)\nFinally, we consider how we can approximate the conditional semantics distribution $p(S_x|X)$ which is the last term required for fully computing $\\hat{I}(x|X)$. We use the law of total probability\n$p(S_x|X) = \\int p(S_x|T, X)p(T|X)dT $ (24)\nHere again we approximate the expectation over the posterior by taking the weighted sum over the pose particles\n$p(S_x|X) \\approx \\underset{i=1}{\\mathbb{P}} w_ip(S_x|T_i, X)$ (25)\nwe assume the conditional independence of $S_x$ and X when given $T$, so\n$p(S_x|X) \\approx \\underset{i=1}{\\mathbb{P}} w_ip(S_x|T_i)$ (26)\nwhere\n$p(S_x|T_i) = p(S_x|sdf(T_ix))$ (27)\nis given by the sensor model. Note that all the terms in Eq. 23 only query x and $T_{1..P}$, without needing to directly consider $X \\cup (x, s)$. This enables us to evaluate $\\hat{I}(x|x)$ for all positions inside a workspace $x \\in W \\subset \\mathbb{R}^3$ in parallel."}, {"title": "E. Planning Problem", "content": "We use model predictive path integral (MPPI) control [50] to plan a H horizon length trajectory and execute the first step of it in Algorithm 1 line 6. H may be less than T due to computation limitations. Without loss of generality, consider t = 1 at planning time for notation simplification. MPPI samples many Gaussian action perturbations around a nominal action trajectory to produce $u_{1..H}$, rolls out the robot configuration from $q_0$ to get $q_{1..H}$ with a dynamics function, and evaluates each configuration trajectory with a cost function to weigh how the action trajectories should be combined. We initialize the nominal trajectory with noise, warm start it by running MPPI without actually executing the planned trajectory for several iterations. Then when executing $u_1$, we use $u_{2..H}, 0$ as the nominal trajectory for the next step. By convention, MPPI minimizes cost, and so we present costs where lower values are better."}, {"title": "F. Information Gain Cost", "content": "We assume we have the robot model such that we can map h(q) $\\rightarrow$ R where R is the set of world coordinate positions inside or on the surface of the robot. Note that when observing $X$ in Algorithm 1 line 8, $\\{(x, free) | x \\in h(q_{t+1})\\}$ should at least be in $X$ since the object cannot be inside the robot. Additionally, we assume we can identify $h_1(q) \\subset h(q)$ that selects the points of the robot that can observe information through contact. For example, the wrist of the end effector may be much less effective at reliably localizing contact than the tactile sensor. We only consider $h_1$ for gathering information but the full h for the dynamics model.\nFor a rolled-out configuration trajectory $q_{1..H}$ we define the information gain cost\n$C_I(q_{1..H}) = \\underset{x \\in \\mathbb{D}(\\cup_{i=1}^H h_1(q_i),r_d)}{\\sum} -\\hat{I}(x|X)$ (28)\nwhich is the information gain field at every robot interior point in the rolled out trajectory, downsampled to avoid double-counting.\nThis cost function develops naturally from $\\hat{I}(x|X)$, however it does not take into account that the object can move, and in doing so, can change $\\hat{I}(x|X)$. Consider a trajectory where a robot moves into contact with the target object then continues in a straight line with the target object remaining in sticking contact. While it would traverse the workspace and gather high $C_I$ as a result, relative to the object it has not moved after coming into contact, and so should collect no new information."}, {"title": "Indeed, $\\hat{I}(x|X)$ is better seen as an object frame field, as only motion relative to the object should collect information.", "content": "To address this, we introduce predicted object displacement $d \\in \\mathbb{R}^3$, and define the adjusted information gain cost\n$C_I(q_{1..H}, d_{1..H}) = \\underset{x \\in \\mathbb{D}(\\cup_{i=1} [h_1(q_i)-d_i],r_d)}{\\sum} -\\hat{I}(x|X)$ (29)\nwhere $h(q) - d \\forall i = 1..H$ transforms the world query positions to be in the displaced object frame."}, {"title": "G. Dynamics Model", "content": "We predict the displacement d in our dynamics model f in addition to q. We assume the difference of the true dynamics f from the given free space dynamics $f_f$ is only due to making contact with the target object, and use the precomputed $p(S_x|X)$ voxel grid to predict when that occurs. One step of f is described in Algorithm 7 and below:\nFirst we apply free space dynamics to get candidate configuration q'. We then sample if this configuration leads to contact by considering the least likely to be free position $x_i$ from $h(q') - d_t$ in Algorithm 7 line 3. We randomly sample from the categorical distribution s ~ p($S_{x_i}|X$). If we sample s = free, then the candidate configuration is used as the next one and the object is not displaced. Otherwise, we need to consider if it is a pushing contact. We compute this action's displacement d' by considering the change in position from where x was before the action. Then, we estimate the surface normal $\\hat{n}$ at this point in line 11 by taking the weighted sum of the SDF gradient of the contact position transformed by each of the pose particles. If the angle between $\\hat{n}$ and -d' is less than some threshold $\\theta_p$ based on an estimation of the friction cone between the robot and the object, then it is considered pushing. If it is a pushing contact, we increase object displacement and move the robot normally. Otherwise, the robot is predicted to remain in its previous configuration to discourage non-pushing contacts, and no further object displacement is produced.\nNote that $q_{t+1}, d_{t+1} \\sim f(q_t, d_t; ...)$ is stochastic since we sample contacts. To reduce variance, for a single action trajectory $u_{1..H}$ we roll out multiple configuration trajectories by applying f on copies of the starting configuration $q_1$ and $u_{1..H}$. The cost of $u_{1..H}$ is the average cost across the multiple $q_{1..H+1}$. Practically, if the object has thin walls relative to the distance a single action could move the robot, as in the case of mugs, each action could be divided up and applied sequentially to avoid dynamics predicting the robot penetrating the object walls."}, {"title": "H. Reachability Cost", "content": "For manipulator arms with immobile bases, it is important to explicitly penalize when actions could move the object outside of its reachable region. Under just the information gain cost from Eq. 29, an action trajectory pushing the object out of reach will evaluate to have equal or better cost than a trajectory doing nothing. If the object is at the edge of the robot's reachability, such as a mug with sides that are within reach but the occluded handle at the back being out of reach, sampling a H step trajectory that first displaces the mug then collects the high information gain at the back of the mug is very unlikely. H may also be too short to allow such a trajectory to exist.\nTo address this, we introduce reachability r(x) $\\in [0,1]$ and the reachability cost $C_R(d_{1..H})$ which encodes the desired behaviour of pushing object frame points x with high $\\hat{I}(x|X)$ to where they are reachable.\nReachability r(x) represents the capability of the robot to gather information at x, similar to checking $\\exists q \\text{ s.t. } x \\in h_1(q)$. This can be approximated by performing inverse kinematics (IK) with x set as the goal position relative to the robot end effector frame. We also consider how robust x is to reach with different configurations, and evaluate the average IK performance with a fixed set of goal orientations $R_i \\in R \\subset SO(3)$. Let $e_x(x, R_i)$ and $e_r(x, R_i)$ be the position and rotation errors from running IK with the goal set to (x, $R_i$). We weigh $e_r$ against $e_x$ with $\\lambda_R > 0$ and define an error tolerance threshold $\\epsilon_m$ such that any error at or above this value receives r(x) = 0."}, {"title": "Thus we define", "content": "$r(x) = \\frac{1}{\\underset{R_i \\in R}{\\text{max}}(0, \\epsilon_m - \\underset{R}{\\sum} [e_x(x, R_i) + \\lambda_R e_r(x, R_i)"}]}