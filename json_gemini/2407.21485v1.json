{"title": "Parallel Strategies for Best-First Generalized Planning", "authors": ["Alejandro Fern\u00e1ndez-Alburquerque", "Javier Segovia-Aguas"], "abstract": "In recent years, there has been renewed interest in clos-ing the performance gap between state-of-the-art planning solversand generalized planning (GP), a research area of AI that studies theautomated synthesis of algorithmic-like solutions capable of solvingmultiple classical planning instances. One of the current advance-ments has been the introduction of Best-First Generalized Planning(BFGP), a GP algorithm based on a novel solution space that canbe explored with heuristic search, one of the foundations of mod-ern planners. This paper evaluates the application of parallel searchtechniques to BFGP, another critical component in closing the per-formance gap. We first discuss why BFGP is well suited for paral-lelization and some of its differentiating characteristics from classi-cal planners. Then, we propose two simple shared-memory parallelstrategies with good scaling with the number of cores.", "sections": [{"title": "Introduction", "content": "Generalized planning (GP) has been a longstanding area of researchin Artificial Intelligence (AI) [6, 15]. The foundation of GP is auto-mated planning, which studies how to construct sequences of actions(commonly known as plans) to go from a specific initial state to agoal [3]. Since planning is a hard problem (PSPACE-complete) [1],solving multiple problem instances from the same domain is compu-tationally expensive. Given this realization, GP studies the synthesisof general plans that can solve multiple problem instances from thesame domain, reducing the computational complexity to a one-timeup-front cost [5, 14].\nThe state-of-the-art planning solvers are often heuristic-basedplanners [16]. These planners guide the combinatorial search ofreaching a goal state from the initial state with heuristics, usuallybased on computing the cost of solving a relaxed plan as an estimateof the actual cost of reaching the solution [2]. Given the success ofheuristic search in planning, Segovia-Aguas et al. [11, 13] proposea heuristic-based approach to generalized planning, which they callBest-First Generalized Planning (BFGP). BFGP leverages a set ofnovel GP native heuristics and a new solution space, independent ofthe number of input instances, to compute general algorithmic solu-tions.\nParallel programming is tightly coupled with Al's recent success,as CPU manufacturers have transitioned to multi-core processors dueto single-core performance stagnation [7]. As a consequence, therehas been a notable effort to parallelize fundamental algorithms likeBest-First Search (BFS), and these techniques have already been suc-cessfully applied to planning domains [1, 7, 9]. One of the most im-"}, {"title": "Suitness of Best-First Generalized Planning forparallelization", "content": "A classical planning problem [4] is defined as P = \u3008D,I), whereD = (F, A) is the domain that comprises the set of lifted predicatesF and actions A, and I = (\u03a9, I, G) is the instance that specifies theset of constant objects, the initial state I, and the goal condition. Asolution to P is a sequence of actions or plan that maps the initialstate to a goal state where the goal condition holds.\nGP is formalized as the problem of finding an algorithm-like solu-tion II (also known as generalized plan) to a set of T planning prob-lems, that is P = {P1, P2, ..., Pr}, where all planning problemsshare the domain, but may differ in the instances (different objects,initial state and/or goal condition). We focus on a special kind of gen-eralized plans named planning programs. Formally, a planning pro-gram [10] is a sequence of n instructions II = (wo, ..., Wn\u22121), whereeach instruction wi is associated with a program line 0 < i < n andcan be of one of the following three types:\nA planning action wi \u2208 A, where A is the set of deterministicfunctions of the planning domain.\nA goto instruction wi = goto(i', !y), where i' is a program linesuch that 0 \u2264 i' < n and i' \u2260 i, and y is a proposition. Propo-sition y can be the result of an arbitrary expression on state vari-ables.\nA termination instruction wi = end. The last instruction of aplanning program is always a termination instruction.\nA planning program II is a solution to P iff the execution of II onevery Pi EP generates a classical plan \u03c0\u2081 that is a solution to theoriginal planning problem.\nIn this work, we use the generalized planner BFGP [13], whichhas shown good performance for computing planning programs via"}, {"title": "Parallel Best-First Generalized Planning", "content": "The following section presents our two strategies for parallelizingBFGP\u00b9 and evaluates their performance in 9 different classical plan-ning domains; 3 of them are propositional (corridor, gripper, andvisitall) and the other 6 are numeric domains (fibonacci, find, reverse,select, sorting, and triangular sum).\nParallel strategy #1. It sequentially expands nodes until thereare at least N nodes per thread\u00b2. Then, it starts a parallel searchin which each thread is independent and does not share nodes withother threads. To ensure a balanced workload distribution, N shouldbe larger for planning domains that require more program lines toreach a solution.\nParallel strategy #2. In this strategy, threads distribute promisingnodes during the parallel search phase, so there is a tradeoff betweensearching the most promising states and minimizing the communi-cation overhead. In our solution, we compute the cost-to-go value ofeach generated node, and if it is equal to or better than the last ex-panded node, we send the new node to another thread. In contrastto HDA*, where a hash function determines which process will re-ceive the node, we simply cycle between all threads. This approach isviable because BFGP does not need to perform duplicate detection."}, {"title": "Discussion", "content": "The first strategy performs very well, with speedups ranging from~4x to ~98x in the most complex domains. Furthermore, increas-ing the number of threads always results in better performance. Onthe other hand, no parallel strategy strictly dominates. In some do-mains (like Visitall), the second strategy gets better scaling and per-formance than the first strategy, but in others, it gets slower execu-tion times. We believe that a better prioritization of promising nodesand the use of asynchronous communication would help the secondstrategy perform better than the first one. To conclude, our resultsshow that BFGP is well-suited for parallelization, and further de-velopments could make BFGP capable of handling more complexproblems from IPC planning domains[16]."}]}