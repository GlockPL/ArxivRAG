{"title": "Generative Adversarial Networks for Imputing Sparse Learning Performance", "authors": ["Liang Zhang", "Mohammed Yeasin", "Jionghao Lin", "Felix Havugimana", "Xiangen Hu"], "abstract": "Learning performance data, such as correct or incorrect responses to questions in Intelligent Tutoring Systems (ITSs) is crucial for tracking and assessing the learners' progress and mastery of knowledge. However, the issue of data sparsity, characterized by unexplored questions and missing attempts, hampers accurate assessment and the provision of tailored, personalized instruction within ITSs. This paper proposes using the Generative Adversarial Imputation Networks (GAIN) framework to impute sparse learning performance data, reconstructed into a three-dimensional (3D) tensor representation across the dimensions of learners, questions and attempts. Our customized GAIN-based method computational process imputes sparse data in a 3D tensor space, significantly enhanced by convolutional neural networks for its input and output layers. This adaptation also includes the use of a least squares loss function for optimization and aligns the shapes of the input and output with the dimensions of the questions-attempts matrices along the learners' dimension. Through extensive experiments on six datasets from various ITSs, including AutoTutor, ASSISTments and MATHia, we demonstrate that the GAIN approach generally outperforms existing methods such as tensor factorization and other generative adversarial network (GAN) based approaches in terms of imputation accuracy. This finding enhances comprehensive learning data modeling and analytics in AI-based education.", "sections": [{"title": "1 Introduction", "content": "The learning performance data, recorded during ITS interactions, documents the sequence of questions-answering activities, tracking the identifications of questions and cataloging the attempts and performance responses made by different learners. However, real-world learning performance data is often incomplete and sparse, with unexplored questions and limited attempts posing challenges for data analysis and modeling. Multiple reasons contribute to data sparsity, including participant's dropout from learning tasks [1], learner disengagement due to off-task behavior [2], random data loss from design and operational errors [3], biases within sample groups [4], among others. This sparsity hinders a comprehensive understanding and assessment of learning performance. Such limitations hinder AI-powered educational systems from effectively delivering educational content, especially in their capabilities to track learning processes, monitor advancement, and gauge learners' mastery of knowledge through their performance data. Thus, accurately imputing sparse learning performance data is critical for advancing learning analytics and modeling, which facilitates the comprehensive exploration of learning insights and ultimately enhancing learner progress within ITSs.\nAlthough traditional data imputation methods (e.g., indicator or mean imputation [5, 6], regression imputation [7], and multiple imputation [8]) have proven effective in the literature, they provide a cost-effective solution that avoids labor-intensive experiments and leverages observed data to estimate unobserved data, capitalizing on underlying patterns and characteristics [9]. Indicator or mean imputation may introduce bias by oversimplifying missing data complexities [5, 6]. Regression imputation often fails to capture the full spectrum of the underlying data structure [7]. Multiple imputation may not adequately address complex, high-dimensional correlations [10]. Recently, generative AI models, specifically Generative Adversarial Networks (GANs) [11], have demonstrated remarkable success in handling data sparsity through the reconstruction mechanism [12, 13], achieving higher accuracy and effectively addressing those issues in traditional data imputation methods. A notable GAN-based model, Generative Adversarial Imputation Nets (GAIN) demonstrated its effectiveness on imputing human health data [12]. The GAIN model extends GAN structure by conditioning the generator on observed data and using a hint mechanism to enhance the discriminator's accuracy in identifying missing data patterns [12, 14]. Further research has shown GAIN's superior performance in diverse datasets and applications, from healthcare to machine health monitoring, validating its effectiveness over traditional methods like MICE and missForest [12, 13, 15].\nDespite its impressive imputation performance in prior studies, GAIN's potential for imputing missing data in sparse learning performance datasets within ITSs remains unexplored. The complex nature of learning performance data, characterized by individual learners, questions, and attempts, presents significant challenges for generative models in data imputation. These challenges include achieving higher accuracy based on existing data distribution and handling the complexities of data interactions and variations across different attempts."}, {"title": null, "content": "Therefore, how can we effectively represent learning performance data to ensure compatibility with the GAIN framework? Additionally, what modifications are necessary to facilitate accurate predictions through specialized computations and algorithms tailored for learning performance scenarios, considering the stability of the models amid dynamic changes in learning performance data?\nIn response to these challenges in learning performance data, our study aims to perform the data imputation for the sparse learning performance data using the GAIN framework, enriched with detailed revisions. We are guided by the following two Research Questions:\nRQ 1: How effectively does the GAIN-based method impute sparse learning performance data in ITSs compared to established baseline methods?\nRQ 2: How does the stability of the GAIN-based model's performance vary with changes in the number of attempts influencing the sparsity levels of learning performance data?\nThe generative AI model, GAIN, was leveraged to impute the sparse learning performance data, with an additional focus on exploring the stability of GAIN. Therefore, this study's contributions are twofold:\n\u2022 It enhances the accuracy of imputing learning performance data, thereby enriching data representation for more detailed analytics and modeling.\n\u2022 The findings are expected to provide valuable imputation methods for comprehensively tracing and assessing learners' progress within AI-based educational systems like ITS."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Addressing Data Sparsity in ITSS", "content": "In AI-based education, many studies have focused on tackling data sparsity in sparse learning performance in ITSs. Chen et al. [16] employed the prerequisite concept map for knowledge tracing to mitigate data sparsity. Pandey et al. [17] developed the self-attentive mechanism to predict the learner's performance on unanswered questions by analyzing the relevance previously answered questions. Wang et al. [18] integrated question-knowledge hierarchies into a deep learning framework to improve predictions despite data sparsity. Despite these advances, challenges persist: (1) high demands for expert effort in mapping and annotating knowledge concepts [19], (2) ignorance of temporal learning dynamics [20], and (3) disruption of sequential learning effects even with some methodological recognition [21, 22].\nIn addressing data sparsity in ITSs, tensor factorization has also played a pivotal role by leveraging multidimensional relationships to enhance prediction accuracy and knowledge representation. This approach has evolved from simple matrix factorization to sophisticated multi-dimensional frameworks that incorporate temporal effects and sequential learning dynamics, significantly improving"}, {"title": null, "content": "the understanding and prediction of learner performance [23, 20, 24]. Such advancements in tensor factorization have laid the groundwork for employing more advanced generative models like GAIN, which further enhance data imputation by maintaining the natural multidimensional structure of learning data. This alignment with deep generative models has directly influenced our adoption of GAIN to effectively address the complex challenges of data sparsity in ITSs [12]."}, {"title": "2.2 Generative AI Models for Educational Data Imputation", "content": "There have been tremendous progress in generative AI model for educational data imputations in ITSs. Morales-Alvarez et al. [25] explored the application of generative models, incorporating structured latent spaces and graph neural network-based architectures, to achieve competitive or superior performance in data imputation for real-world mathematics datasets of Eedi (a leading educational platform which millions of students interact with daily around the globe on diagnostic multiple-choice mathematics questions [26]), surpassing traditional baselines such as MICE and missForest. Ma et al. [27] also employed deep generative models to effectively impute data for multiple-choice question learning data, addressing over 70% missing rates in the Eedi educational dataset for mathematics questions. Zhang et al. [28] investigated the use of generative AI models, GAN and GPT, for data augmentation to address sparse learning performance patterns in adult reading comprehension, finding GAN to provide more stable augmentation across various sample sizes.\nLearning performance data from ITSs such as AutoTutor CSAL, which focuses on reading comprehension [29], along with ASSISTments [30] and MATHia [31], which both focus on math learning for middle and high-school students, document learners' responses as correct or incorrect to a sequence of questions posed by the system. Inspired by GANs' capability to impute missing regions in images by training on vast amounts of image data and filling in missing areas to maintain coherence with the existing context [32], we are motivated to apply a similar data imputation approach to tensor-based learning performance data. There is an ongoing need for effective imputation of learning performance data in ITSs like AutoTutor CSAL, ASSISTments and MATHia to enhance educational technology's ability to track and assess learners' performance comprehensively."}, {"title": "3 Methods", "content": ""}, {"title": "3.1 Dataset", "content": "In this study, we utilized datasets from three primary sources: AutoTutor CSAL lessons, ASSISTments and the MATHia dataset from mathematics class. The"}, {"title": "3.2 The 3-D Tensor Representation of Sparse Learning Performance", "content": "We define the 3-D tensor \\(T_{sparse}\\) to encapsulate the learning performance records of U learners on N questions over a sequence of up to M attempts, with \\(T_{sparse} \\in [0,1, NaN]^{U\\times N\\times M}\\). Here, U = max(1,2,3,\u2026, u) is the maximum number of learners, N = max(1,2,3,\u2026\u2026, n) the maximum number of questions, and M = max(1,2,3,\u2026\u2026,m) the maximum number of attempts. Each element \\(T_{uij}\\) within \\(T_{sparse}\\) encodes the learning performance as 1 for correct answer, 0 for an incorrect answer, and NaN to signify unobserved data for a specific question's performance at certain attempt."}, {"title": "3.3 The Proposed GAIN-based Imputation Architecture", "content": "Consider the \\(T_{sparse}\\), representing the learning performance of all learners. This tensor comprises layers along the learner dimension, represented as \\(T_{sparse}(T_{11}, T_{12},\u2026, T_{im})\\). Each layer, akin to a single-channel \u201clearner image\u201d, is a matrix"}, {"title": null, "content": "that encapsulates performance values across different questions and attempts for an individual learner. This is visualized in Fig. 1."}, {"title": null, "content": "For each matrix-based layer \\(T_i \\in (T_{11}, T_{12},\u2026, T_{im})\\), each entry \\(T_{rij}\\) in the NX M matrix may include the performance values of 0, 1 or NaN to present the observed data and unobserved data, respectively. One mask matrix \\(T_{imask}\\) is supposed to map the observed and unobserved entries within the matrix \\(T_i\\), with 1 signifying observed data, and 0 indicates unobserved data. One noise matrix Z with dimensions matching \\(T_i\\), is initialized. These matrices collectively function as inputs to the generator in the GAIN architecture, producing the output \\(T_{iG} = G(T_i,T_{imask}, (1- T_{imask}) \\odot Z)\\) [12]. Here, the \\(\\odot\\) denotes as Hadamard product, indicating element-wise multiplication. The imputed matrix \\(T_{iimputed} = T_{imask} \\odot T_i + (1 \u2212 T_{imask}) T_{iG}\\), effectively merges observed and generated data to fill in unobserved entries. Particularly, a hint matrix \\(T_{ihint}\\), also matching the dimensions of \\(T_i\\) and derived from the mask matrix \\(T_{imask}\\), is introduced. It employs a hint rate to specify the conditional probability that a specific entry in \\(T_{iimputed}\\) can be observed, given both \\(T_{iimputed}\\) and \\(T_{ihint}\\). Thereby, the discriminator within the GAIN architecture, formulated as \\(D(T_{iimputed}, T_{ihint})\\), evaluate this as probability [12]. We train D(.) to maximize the probability of correctly predicting the \\(T_{imask}\\), while the G(\u00b7) is trained to minimize the likelihood of D(.) correctly predicting \\(T_{imask}\\). So, we introduce the objective function"}, {"title": null, "content": "V(D, G) [12]:\n\\(V(D,G) = E[T_{imask}logD(T_{iimputed}, T_{ihint}) + (1 \u2013 T_{imask})Tlog(1 \u2013 D(T_{iimputed}, T_{ihint}))]\\) (1)\nOur proposed imputation architecture incorporates several novel modifications and configurations from the initial GAIN architecture [12]. See below for further details:\nThe convolutional layers are employed for both the generator and discriminator, diverging from the original architecture' reliance on dense layers. Five convolutional neural network (CNN) layers [33], excluding the input and output layers, with the ReLU activation function are applied to the output of each layer.\nDuring the iterative training phase, the observed data from \\(T_i\\) and the corresponding imputed data from \\(T_{iG}\\) are utilized for optimization via the least square loss function, specifically the Root Mean Square Error (RMSE). This method is chosen to not only ensure enhanced stability and superior quality of the generated data [34, 35] but also align with probability-based predictions of learning performance in peer research on ITSs [36, 37, 38].\nBy incorporating a reshape function in the generator's output layer, the shape of generated data \\(T_{iG}\\) is flexible adjustment to fit the given \"learner image\" shape, thus accommodating variations across different lesson scenarios without being constrained to a fixed shape, as commonly seen in image-oriented research [11, 39, 40].\nThe theoretical foundation for understanding the inference logic and model assumptions in our study includes:\nInference Logic. The entry set within \\(T_{sparse}\\) can be categorized into two subsets: \\(T_{observed}\\) for existing values (0 and 1) and \\(T_{unobserved}\\) for missing ones (NaN). The inference model, formulated as \\(f_{impute}(T_{unobserved}|T_{observed})\\), is principle for data imputation, leveraging observed data patterns to impute missing values and predict outcomes [41].\nModel Assumptions. Our imputation model operates under several key assumptions within a tensor-based framework: (a) Probability-based prediction: Assumes predicted learning performance is a continuous probability between 0 and 1, indicative of knowledge mastery [42]. (b) Latent domain knowledge relations: Posits that unobservable latent relationships within the domain knowledge implicitly influence knowledge mastery [43, 44]. (c) Similarity in learning for individual learners: Suggests a shared relevance and usefulness of knowledge among learners, aiding in predicting knowledge mastery [45, 23]. (d) Performance interactions influenced by sequence effects: Acknowledges that learners' interactions with sequential questions are shaped by priming and recency effects, affecting comprehension and performance [21, 46]. (e) Maximum attempt assumption: Defines a theoretical maximum number of attempts a learner might need, emphasizing the importance of evaluating comprehensive learning states through repeated trials [43]."}, {"title": "3.4 Baselines", "content": "This study will compare the proposed GAIN-based imputation method against a range of baseline methods, including those from the tensor factorization series and GAN series. Detailed descriptions of these baselines are provided below.\nTensor Factorization: The basic tensor factorization factorizes the sparse tensor \\(T_{sparse}\\) into two components: a learner latent matrix capturing abilities and learning-related features, and a latent tensor representing knowledge during question attempts [47, 28]. A rank-based constraint is used to maintain a generally positive learning trend and accommodate forgetting or slipping [48]. This refined method enhances data imputation within tensor-based structures, providing a robust solution for handling sparse data.\nCANDECOMP/PARAFAC Decomposition (CPD): Drawing on the principle of classic CPD [49, 50], the sparse tensor \\(T_{sparse}\\) is decomposed into three factor tensors that capture learner, attempt and question-related factors in a multidimensional tensor form. A rank-based constraint is additionally applied to enhance the decomposition's accuracy.\nBayesian Probabilistic Tensor Factorization (BPTF): The BPTF [51] is employed to approximate the sparse tensor \\(T_{imputed}\\) through the decomposition into a sum of outer products of three lower-dimensional factor tensors. This approach leverages Bayesian inference for sampling both the factor tensors and the precision of observed entries, effectively enhancing the model's capacity to manage data sparsity and uncertainty [51, 52].\nGenerative Adversarial Network (GAN): At one core of the GAN, the \"learner image\" extracted from \\(T_{sparse}\\) (depicted in Fig. 1), constitutes the base input for the GAN. The GAN architecture includes a generator that simulates data resembling observed entries and a discriminator that assesses the authenticity of this generated data [11]. It uses a consistent CNN layer configuration and least squares loss for optimization.\nInformation Maximizing Generative Adversarial Nets (InfoGAN): The InfoGAN [39] enhances the traditional GAN framework by integrating the noise with two structured latent variables, allowing for the capture of salient, structured semantic features, such as those relating to learner attributes in ITSs (e.g., initial learning ability and learning rate). The generator generates imputed \\(T_{imputed}\\) and decodes latent variables. An auxiliary distribution improves the estimation of these variables' posterior, boosting mutual information between latent codes and observations and ensuring that the generated outcomes are meaningfully informed.\nAmbientGAN: AmbientGAN [53] is used to impute sparse learning performance data by training on partially observed or corrupted data within a GAN framework. It incorporates a dynamically adjusted Gaussian blur in the measurement process, enabling the discriminator to effectively distinguish between real and generated data measurements and accurately infer the original dataset's true distribution."}, {"title": "3.5 Experimental Setup and Evaluation", "content": "The experimental setup for imputing sparse learning performance data incorporates several tailored configurations to optimize model training and evaluation. (a) Cross-Validation: A systematic five-cycle, five-fold cross-validation strategy is rigorously employed for each model to ensure consistency and reliability of results. (b) Varying Attempt Setting: The stability of models' data imputation performance is tested under various maximum attempt settings to handle different degrees of data sparsity. (c) Maximum Iterations: All models are allowed up to 100 iterations to ensure thorough adaptation and learning. (d) Learning Rate: A learning rate of either 0.0001 or 0.00001 is selected to promote steady progress and convergence during model training. (e) Regularization Techniques: Dropout and Batch Normalization are integrated into the training process of GAN-based methods to prevent overfitting. (f) Imputation Accuracy Evaluation Metric: The Root Mean Square Error (RMSE), as referenced in peer papers [51, 24, 12], is used to evaluate models' performance in data imputation. (g) Measuring Sparsity Level: The sparsity level of a tensor-based distribution for learning performance data is computed as the percentage of missing values in the total number of elements in the distribution. (h) Correlation Evaluation: The Spearman correlation coefficient [54] is used to assess the relationship between RMSE and the varying maximum number of attempts."}, {"title": "4 Results and Discussion", "content": "Data Sparsity Levels. Fig. 2 displays the variation in sparsity levels within learning performance data across six lessons, categorized by the maximum number of attempts. The sparsity level for each lesson increases with the number of attempts, suggesting a progressive introduction of missing data or non-responses for learners in learning process. This trend is consistent across all courses, albeit with varying rates of increase. Notably, \"ASSISTments Lesson 2\" exhibits a gradual ascent, recording the highest sparsity levels across all attempts when compared to other lessons. In contrast, \"MATHia Lesson 1\" and \"MATHia Lesson 2\" demonstrates a low-er initial sparsity level, with the former experiencing a sharp increase and the latter following a more gradual trajectory as attempts progress. Particularly, \"CSAL Lesson 1\" records the maximum number of attempts observed for this"}, {"title": null, "content": "class. The distinct sparsity patterns observed in Fig. 2 highlight the heterogeneity of data completeness and the extent of missingness across different lesson datasets."}, {"title": null, "content": "Models' Imputation Performance. RQ1 investigates how effectively the GAIN-based method imputes sparse learning performance data in ITSs compared to established baseline methods. This question is addressed by the following results. Fig. 3 presents the RMSE results of imputations performed by various models on sparse learning performance data across lessons. GAIN significantly outperforms other baseline models across most datasets, particularly in the context of ASSISTments and MATHia lessons, as well as in certain CSAL lessons, save for an exception in CSAL Lesson 1. In CSAL Lesson 1, GAIN's RMSE is lower than that of BPTF, GAN, and InfoGAN, and its extended error bars indicate a comparative decrease in imputation precision and consistency. Remarkably, by the 9th attempt, GAIN's RMSE approaches the minimal value, signifying high accuracy in data imputation toward the higher max attempt. The unique case of CSAL Lesson 1 underscores complex data or model interactions that merit in-depth research to unravel the specific factors influencing its imputation challenges. Additionally, the GAN model exhibits performance surpassing that of other models, albeit slightly less robust than GAIN, while CPD and BPTF demonstrate competitive capabilities."}, {"title": null, "content": "Stability of Imputation with Varying Attempts. RQ2 examines how the stability of the GAIN-based model's performance varies with changes in the number of attempts influencing the sparsity levels of learning performance data, as demonstrated by the subsequent results. Despite its overall superior performance, GAIN exhibits greater variance in its results, as indicated by the longer error bars (see Fig. 3), which suggests less stability in its data imputation. The heightened variance suggests that while GAIN generally delivers superior imputation, its consistency is compromised under certain data conditions, possibly requiring additional tuning or pre-processing to stabilize its performance. Moreover, the comparative analysis of other baseline models like Tensor Factorization and CPD indicates a lower variance, suggesting that these may provide more reliable imputations in certain contexts, despite not always achieving the lowest RMSE."}, {"title": null, "content": "Iterative Changes of RMSE for GAIN. As depicted in Fig. 4, the RMSE trajectory during the example training stage demonstrates the evolution of GAIN's imputation performance across various lessons with each iteration. Implementing an early stopping criterion is essential when the model exhibits satisfactory performance, typically when the RMSE approximates 0.1, to prevent overfitting. Initially, there is a pronounced reduction in RMSE across all lessons, signaling GAIN's rapid enhancement in accuracy. Particularly, \"MATHia Lesson 1\", \"MATHia Lesson 2\", and \"ASSISTments Lesson 1\" exhibit the most considerable decrease, achieving optimal RMSE levels within fewer than 20 iterations. The prolonged convergence for \"CSAL Lesson 2\" beyond 40 iterations implies that additional gains in accuracy are marginal, prompting considerations for early stopping to optimize computational resources. The variability in the number of iterations required to reach convergence further underscores the diversity of the underlying data distributions. These findings illuminate the complexity of learning performance patterns and the distinctive characteristics of knowledge acquisition that GAIN captures, albeit with varying rates of convergence."}, {"title": null, "content": "Spearman Correlation. Fig. 5 provides a comparison of the Spearman correlation coefficients, quantifying the relationship between RMSE values and the varying maximum number of attempts across various models applied to different lessons. A positive correlation signifies that the model's RMSE rises as the maximum number of attempts increases, which aligns with a trend of rising sparsity levels, thereby indicating a decline in model performance. Conversely, negative values suggest that the RMSE does not necessarily rise with sparsity, potentially"}, {"title": null, "content": "indicating a model's higher performance to missing data. For tensor factorization methods, the prevalent negative correlations across the lessons suggest that their RMSE tends to decrease alongside sparsity. CPD exhibits varied outcomes, with certain lessons reflecting slight positive correlations, while others show negative, indicating inconsistent behavior across different datasets. BPTF predominantly shows positive correlations, with the exception of the CSAL lessons, suggesting a general tendency for model performance to decrease with sparsity within these contexts. For the majority of lessons, GAN demonstrate positive correlations, signaling weaker performance as sparsity enlarges. InfoGAN mostly records negative values, suggesting improved performance in the face of increasing sparsity for most lessons. AmbientGAN consistently exhibits negative correlations for all lessons, implying an increase in model performance despite greater sparsity. GAIN's results are varied, reflecting its nuanced response to the distinct traits of each dataset."}, {"title": "4.1 Limitations and Future Works", "content": "However, the exploration into the adaptive mechanisms of GAIN also highlights areas for future research, particularly in refining model architecture and expanding model explainability to better understand the underlying imputation processes. As educational data continues to grow in complexity and size, further advancements in generative models will be crucial in fully harnessing the potential of generative AI to transform AI-based educational systems.\nFuture research will delve deeper into the analysis of tensors imputed by GAIN and other methods, focusing on the following areas:\n\u2022 Enhanced evaluation of imputed data is imperative, with an emphasis on comparing imputed and original data patterns."}, {"title": null, "content": "\u2022 The use of synthetic datasets, with their adjustable sparsity levels and known ground truth, will further facilitate the evaluation process.\n\u2022 The exploration of generative AI for educational data imputation is still evolving. A systematic comparison of various generative models, including Autoencoders (AE), Variational Autoencoders (VAE), and their interpretable counterparts such as adversarial AEs and Denoising Autoencoders (DAE) [55], is planned.\n\u2022 A concerted effort will also be made to distinguish between the semantics of zero values and NaN values, enhancing the quality of the imputation for learning performance data.\n\u2022 An ablation study can verify the effectiveness of the new GAIN-based architecture for imputing sparse learning performance data. By iteratively testing variants by removing or replacing components such as convolutional layers, the hint mechanism, or the least squares loss function, and comparing their performance using key metrics like RMSE, we can identify the contributions of individual components and refine the architecture for optimal effectiveness.\n\u2022 Another potential is the application of generative models in data imputation, which can facilitate ITSs in tracing and predicting learning performance data, especially in real-time and dynamic learning environments. The emerging generative language models, with their reasoning capabilities and the powerful computational abilities of deep generative models, can potentially lead to new advancements in AI-educational applications and research [56, 57]."}, {"title": "5 Conclusion", "content": "In this study, we propose a GAIN-based method for imputing sparse learning performance data from ITSs. Our systematic comparison with tensor factorization and other GAN-based methods shows that GAIN not only surpasses these traditional models in terms of imputation accuracy but also demonstrates remarkable adaptability across various educational datasets. However, GAIN's performance is marked by increased variance and diminished stability in data imputation, influenced by varying levels of data sparsity and not uniformly consistent across different lessons. Furthermore, the initial tensor-based representation within a 3D tensor space preserves the original sequence effects and structure, which, when combined with GAIN's use of CNN for its input and output layers, effectively bridges the gap between employing generative AI models for imputing sparse learning performance data and retaining essential temporal educational dynamics. The success of GAIN in this context lays the groundwork for more robust educational data analytics, enhancing decision-making in educational settings, especially in ITSs. This study significantly enriches the application of GAIN in the fields of learning engineering and learning science."}]}