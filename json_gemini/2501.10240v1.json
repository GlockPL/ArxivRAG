{"title": "CHALLENGES AND RECOMMENDATIONS FOR ELECTRONIC HEALTH RECORDS DATA EXTRACTION AND PREPARATION FOR DYNAMIC PREDICTION MODELLING IN HOSPITALIZED PATIENTS - A PRACTICAL GUIDE", "authors": ["Elena ALBU", "Shan GAO", "Pieter STIJNEN", "Frank E. RADEMAKERS", "Bas CT van Bussel", "Taya Collyer", "Tina Hernandez-Boussard", "Laure WYNANTS"], "abstract": "Dynamic predictive modeling using electronic health record (EHR) data has gained significant attention in recent years. The reliability and trustworthiness of such models depend heavily on the quality of the underlying data, which is largely determined by the stages preceding the model development: data extraction from EHR systems and data preparation. We list over forty challenges encountered during these stages and provide actionable recommendations for addressing them. These challenges are organized into four categories: cohort definition, outcome definition, feature engineering, and data cleaning. This list is designed to serve as a practical guide for data extraction engineers and researchers, supporting better practices and improving the quality and real-world applicability of dynamic prediction models in clinical settings.", "sections": [{"title": "1 Background", "content": "Predictive modelling using electronic health record (EHR) data has grown over recent years. EHRs provide detailed longitudinal patient data, enabling dynamic (or continuous) diagnosis or prognosis prediction of various outcomes during a patient's hospitalisation. These prediction models hold the potential to enhance patient outcomes by detecting risks in real-time, enabling timely interventions, and supporting clinical decision-making. Recent breakthroughs in machine learning and deep neural networks [Vaswani, 2017, Lee et al., 2019] have demonstrated their applicability [Toma\u0161ev et al., 2021, 2019, Lee et al.]. The growth in EHR-based predictive modelling is accompanied by public access to large-scale health datasets, the development of standards for data formats, tools for data preparation (or \u201cdata wrangling\"), and data quality assessment frameworks.\""}, {"title": "2 Objective", "content": "This article provides a comprehensive list of challenges encountered during data extraction and preparation using electronic health record (EHR) data for developing dynamic prediction models for clinical use. It further proposes recommendations with actionable insights, intended for improving the quality of research and the practical applicability of clinical predictive models. This list is intended as a hands-on resource for data extraction engineers and researchers to consult during the extraction and preparation process. We focus on single-hospital structured data, extracted from the ICU system and hospital-wide EHR software. We"}, {"title": "3 EHR data flow from data collection to model building", "content": "The data flow from the patient's bed to the prediction model building follows three stages: data collection (a), data extraction (b) and data preparation (c) (Figure 1, A). Patient data are either manually entered in EHR software modules or collected by devices and stored in one or multiple databases (a). EHR data are then extracted from relational databases in a simplified (denormalized) format and typically stored in a data warehouse as multiple \"base tables\" per category, each capturing different aspects of patient data and healthcare events. Examples of base tables naming as per OMOP CDM are: PERSON, DRUG_EXPOSURE, DEVICE_EXPOSURE, CONDITION_OCCURRENCE, MEASUREMENT, NOTE, OBSERVATION, but naming and granularity of extraction can vary for non-standard extractions (b). Researchers building a prediction model either have access to the data warehouse or get a copy of all tables or, under specific ethical considerations, a subset of the base tables or a subset of the patients in the data warehouse (e.g.: admissions during a specified period of interest for patients undergoing mechanical ventilation). Further, they process the extracted data and bring it in a format on which a prediction model can be built (c).\nAt model implementation time in clinical practice in the EHR software (Figure 1, B), a trigger (e.g.: update of lab results) or a scheduled task (e.g.: every 24 hours) will initiate the request for a prediction. Data are already collected (a) for the patient in the EHR database(s). The same logic as for extraction (b) is reproduced (typically by reusing the queries or code used for extraction). Using the data packed in a specific format (e.g.: json, xml), the prediction service (typically using a REST API interface for communication) is invoked. Data exchange between the EHR and the prediction service is generally performed using the FHIR (Fast Healthcare Interoperability Resources) standard. The prediction service will further prepare the data (c), invoke the model and return a prediction (and additional information, if foreseen) to the EHR software which will present it to users in form of alerts or patient flags within the patient's chart. The process is typically logged in the EHR system for monitoring purposes. In summary, at real-time prediction, the data collection (a) happens implicitly and is part of the normal clinical flow; data extraction (b) and data preparation (c) are identically reproduced as for model building.\nWe address some specific aspects for each of the processes of collection, extraction and preparation, which represent transition phases from one data format to another:\na) Data collection The EHR database will not reflect with maximum accuracy the \"true state\" of the patient. First, it will suffer of incompleteness, as not all possible markers and observations can be collected for all patients at all times. The decisions with regards to what data are collected (e.g.: which laboratory tests are ordered and performed) is highly dependent on the patient conditions and on the hospital procedures. Sufficient data are though collected to support the patient's clinical follow-up and treatment. From this perspective, EHR data differ vastly from data collected for clinical trials, where researchers specify the measurements, measurement methods and collection procedure. Second, nurses and clinicians might have slightly more information than the data collected in the system, either from patient conversations or organizational knowledge. Considering that we do not cover extraction of text notes and reports, tabular data only will always suffer of a level of incompleteness. Nevertheless, tabular data might prove sufficient for specific prediction tasks. Third, both manual data entering and data collected by devices can be at times error-prone, software can have bugs and data recording procedures in the system which will affect the granularity of observed"}, {"title": "4 Challenges and Recommendations", "content": "We list common problems that can be avoided or alleviated and recommendations for mitigation strategies for problems originating in the data collection process (a), the data extraction process (b) and the data preparation process (c). We also focus on problems that can impede the identical reproduction of the extraction and preparation at clinical implementation time. We assume that both the extraction and data preparation processes are reusable or identically reproducible for implementation in clinical practice. We have categorized the challenges and recommendations into four groups: (1) cohort definition (and inclusion/exclusion criteria), (2) outcome definition, (3) feature engineering, and (4) data cleaning, and each group contains problems originating in the collection, extraction or preparation process.\nOur insights are drawn from a selective literature review, as well as our experience with various EHR data extractions. We provide mapping of the items to both the Weiskopf and Weng framework [Weiskopf and Weng, 2013] and the METRIC framework [Schwabe et al., 2024], whenever applicable. Weiskopf and Weng do not include dimensions covering the cohort representativeness and completeness of the extracted features, which are important in prediction settings. We will use the Completeness dimension to refer to completeness of data values, as in the original definition, as well as completeness of the cohort and of the extracted features (our extension).\nWhile we aimed to make these challenges as generic as possible, we recognize that specific issues are often unique to individual projects and may not apply to all prediction tasks. We advise users to assess the impact of each listed challenge in their specific context. Similarly, the recommendations might not always be universally applicable and depend on the project context. Our guidance remains pragmatic; at times, the best approach may be to \"leave-as-is\u201d to avoid the risk of overcorrection, which can backfire. Following the fitness-for-use principle [Miao et al., 2023], we encourage readers to remain pragmatic and address only the issues relevant to their cohort."}, {"title": "4.1 Cohort definition", "content": "Defining the cohort of interest (e.g., hospital-wide population or patients with a specific condition) represents a first step in the prediction task definition. It can also be of interest during the project planning phase and it implies critical considerations (Table 1). An inaccurately defined cohort can lead to sample bias, resulting in performance estimates that do not accurately reflect the model's performance in clinical practice."}, {"title": "4.2 Outcome definition", "content": "Prediction models using EHR data usually focus on in-hospital or post-discharge outcomes, including mortality, length of stay, readmission, acute events like bacteraemia, sepsis, and acute kidney injury, and chronic diseases such as heart failure, cancer, and cardiovascular disease [Pungitore and Subbian, 2023]. We focus on outcomes that can be derived solely from structured EHR data, without linkage to external data sources or extraction of text notes, and are linked to a patient, i.e. we exclude resource utilization and workflow optimization outcomes (Table 2). Typically, a time window after the prediction trigger time is defined (also called prediction horizon) [Pungitore and Subbian, 2023], for both static (one prediction trigger) or dynamic (repeated prediction triggers throughout the patient's stay) models."}, {"title": "4.3 Feature engineering", "content": "Feature engineering is the process of selecting, transforming, and creating features (variables) from the extracted EHR data to ensure that the data are brought into a suitable format for modelling and that relevant information is processed in a meaningful way. It includes data mapping and transformation (e.g.: grouping medical specialties in meaningful categories), converting timestamped events (e.g., lab results, medication administration, vital signs) into snapshot-based features and data aggregation (summarizing multiple observations or measurements into single features). The feature engineering is typically performed during data preparation, and most of times it happens concomitantly with data cleaning. Sometimes feature engineering is also performed at data extraction time, for example, for reducing the data volume for high-frequency time-series data, especially in ICU settings or for computing scores that are calculated and displayed in the EHR software but not stored in the system.\nWe distinguish between generic feature engineering (Table 3), which deals with the availability and mapping of clinical items, and time-sensitive feature engineering (Table 4), which deals with data aggregation for which correct processing of timestamps is critical and that can result in temporal leaks (i.e. data available at a specific time for training the model, but not available in the system at that timestamp). Time-sensitive feature engineering is critical for dynamic prediction models, can be useful also for some static models (e.g.: predictions at 24 hours after admission), and has less impact on models with prediction trigger at the end of the admission (e.g.: readmission prediction). We acknowledge that some minimal temporal leaks might not be very detrimental for the model performance or for its applicability, while others can have a large impact. However, following the DRIFT principle (Do It Right The First Time), good understanding of the extracted timestamps and correct handling of date/times during data extraction and preparation can safeguard against future problems, big or small."}, {"title": "4.4 Data cleaning", "content": "The data cleaning process constitutes of identifying and correcting data issues that could negatively impact the performance or applicability of prediction models. Errors in EHR data can arise from manual entry mistakes, improperly connected or malfunctioning devices, or bugs within the EHR software. Such errors are typically uncovered during data exploration and addressed during data preparation. Tools like the Data Quality Dashboard [Blacketer et al., 2021] have been developed to support and streamline the data cleaning process. Artifacts can also be introduced during data extraction or during data preparation. Unit tests for both the ETL process and the data preparation pipeline can safeguard against introducing errors.\nOverzealous correction of errors, such as manual correction during data preparation of every error encountered might not necessarily prove beneficial for prediction tasks, when such corrections cannot be programmatically reproduced during model implementation in clinical settings. This discrepancy can lead to a situation in which training data accurately represents the true patient state, while real-time predictions rely on erroneous data, resulting in reduced predictive performance. Although measures can be taken to address common and documented errors from previous studies or identified during data exploration (Table 5), it is impossible to anticipate and guard against all future errors. For example, new EHR software versions and updates may introduce new bugs, even as older bugs are resolved."}, {"title": "5 Discussion and Conclusion", "content": "Adhering to the \u201cgarbage in, garbage out\" principle, prediction models rely heavily on the quality and relevance of the input data to generate meaningful and reliable predictions. Data extraction and preparation for predictive modelling using EHR data are resource-intensive processes, with time and cost varying depending on the maturity of the extraction framework, the prediction task and the team's experience in working with EHR data. Data quality often varies significantly across EHR systems and extraction processes, as noted by Weiskopf et al. [Weiskopf and Weng, 2013], and so does data preparation too. Issues such as data gaps, temporal leaks, incorrect linking, inconsistencies in clinical concept and terminology mapping can affect the quality of extracted datasets and compromise the model's performance and applicability. To address such challenges, we proposed a list of practical recommendations informed by our experiences with EHR data and insights from published studies. We organized the challenges and recommendations into: cohort definition, outcome definition, feature engineering and data cleaning; the first three categories can also be consulted when planning a project. A clear definition of the prediction task or research question, of the intended use and the intended users of a prediction model are a first critical step for defining the outcome, the cohort and the features of interest [Arbet et al., 2021, Honeyford et al., 2022]. It is not uncommon to deem the EHR data inadequate for the prediction task, before proceeding with the model building phase [Thuraisingam et al., 2021].\nFor cohort definition, we recommend extracting a broader patient context beyond the immediate focus, assessing the completeness of data used for inclusion/exclusion criteria and its availability at prediction time, and careful definition of episodes of interest for prediction. Outcomes can be derived in different ways, all with advantages and shortcomings. We generally advise against the use of ICD codes, unless carefully assessed as appropriate for the prediction task. Good understanding of hospital's processes, thorough verification of outcomes derived in code, manual inspection of labels and agreement between data sources can also prevent incorrect outcome definition. Mapping terminology to coding systems (e.g., ICD, CPT, LOINC, SNOMED-CT) can facilitate feature engineering. However, not all items in the EHR system are aligned with standardized terminologies (e.g., LOINC codes for lab results are often not used). Implementing terminology mapping during the data extraction phase (e.g., through OMOP CDM) can significantly reduce the effort required during data preparation. High-quality and completeness of data extraction documentation and good understanding of the underlying clinical concepts and healthcare processes are essential to support feature engineering. For feature engineering in prediction settings, the timestamp when a clinical item is available in the system is of most interest, as this is the time at which predictor values become available for prediction in clinical practice. Good documentation and understanding the extracted timestamps will prevent temporal leaks. Thorough verification of the extraction and preparation processes, data exploration and reproducible data cleaning can safeguard against data quality issues. Clinical assessment of the relevance and the sequence of extracted features and outcome within a patient admission by manual verification can further help avoiding problems [Toma\u0161ev et al., 2021]. The solutions to specific issues can be implemented at either the extraction or preparation stage. Applicable to both data extraction and preparation are good understanding of the underlying data structure and current and historical healthcare processes, collaboration with relevant experts in conducting the work [Toma\u0161ev et al., 2021, Honeyford et al., 2022], and ensuring a qualitative process of extraction and preparation, supported by unit tests.\nHigh-quality data extraction and preparation processes can support prediction models with clinical utility. The argument that EHR \u201cdata are not collected for research purposes\u201d but for clinical use [Van Der Lei, 1991, Goldstein, 2020, Sauer et al., 2022, Maletzky et al., 2022, Thuraisingam et al., 2021, Arbet et al., 2021] has been made multiple times. Among various research goals, applied prediction models may be the most effective way to leverage electronic health record (EHR) data. Prediction models can exploit the comprehensive clinical information that is not always readily available to all healthcare professionals, such as nurses, doctors, hygienists, and other therapists, and have proven practical applicability [Lee et al.].\nWe hold the opinion that, in the context of prediction models, the extraction process should not attempt to correct errors residing in the EHR database in the attempt to align the data to the clinical reality and it should reflect the information from the EHR, presented in a simplified format. Extracting and preparing the training data in a different manner than for clinical implementation (e.g.: temporal leaks) poses the risk of potential overoptimistic evaluation, in the light of which the model's performance when implemented in clinical practice will be deceiving. We acknowledge that there are divergent views on this topic and that in the context of inferential studies, when the analysis does not need to be reproduced on future data, corrections at extraction time might be preferred. At the same time, multi-purpose extractions (for both prediction and inferential studies) pose the challenge of solving the divergent view."}]}