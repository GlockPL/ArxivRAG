{"title": "Towards physics-informed neural networks for landslide prediction", "authors": ["Ashok Dahal", "Luigi Lombardo"], "abstract": "For decades, solutions to regional scale landslide prediction have mostly relied on data-\ndriven models, by definition, disconnected from the physics of the failure mechanism. The\nsuccess and spread of such tools came from the ability to exploit proxy variables rather than\nexplicit geotechnical ones, as the latter are prohibitive to acquire over broad landscapes. Our\nwork implements a Physics Informed Neural Network (PINN) approach, thereby adding to\na standard data-driven architecture, an intermediate constraint to solve for the permanent\ndeformation typical of Newmark slope stability methods. This translates into a neural net-\nwork tasked with explicitly retrieving geotechnical parameters from common proxy variables\nand then minimize a loss function with respect to the available coseismic landside inventory.\nThe results are very promising, because our model not only produces excellent predictive\nperformance in the form of standard susceptibility output, but in the process, also gener-\nates maps of the expected geotechnical properties at a regional scale. Such architecture is\ntherefore framed to tackle coseismic landslide prediction, something that, if confirmed in\nother studies, could open up towards PINN-based near-real-time predictions. To stimulate\nrepeatability and reproducibility of the same experiment, we are openly sharing data and\ncodes at the following GitHub repository: https://github.com/ashokdahal/PINN.git.", "sections": [{"title": "Introduction", "content": "Landslides represent a major cascading geological hazard primarily triggered by two earth\nsystem processes: solid earth and hydrological processes. Landslides induced by solid earth\nprocesses are typically caused by earthquakes, volcanic activity, and other geophysical phe-\nnomena, while the hydrological process predominantly triggers landslides through changes in\ngroundwater levels and surface water saturation (C.D.C., 2019). In both instances, landslides\noccur due to increased stress, or \u201cdriving force\u201d, on a potential failure plane, with these forces\nbeing commonly referred to as triggering forces (Newmark, 1965; Jibson, 1993; Fan et al.,\n2019). The global distribution of landslides results in considerable loss of infrastructure and\nhuman lives (Petley, 2012; Fidan et al., 2024). Moreover, this trend is expected to escalate\ndue to the increased frequency of hydrologically induced landslides under climate change\nscenarios (Gariano and Guzzetti, 2016; Dahal et al., 2024a) and heightened exposure due to\ndevelopment activities in areas susceptible to solid Earth-induced landslides (Reichenbach\net al., 2018; Wang et al., 2024b). Therefore, the accurate and reliable modelling of landslides\nis a crucial and ongoing area of research.\nIn the case of earthquake-induced landslides, the slope potentially fails due to seismic\nloading in an otherwise stable slope (Gorum and Carranza, 2015). Generally, earthquake-\ninduced landslide hazard modelling involves understanding and estimating the required seis-\nmic loading conditions for a slope to fail (Jibson, 2011). This approach can be broadly\ncategorized into two main types: physically based modelling and data-driven modelling\n(Fan et al., 2019). Physically-based modelling solves the forward physical systems given the\ngeotechnical properties of the material involved and the triggering force (Memon, 2018). In\ncontrast, data-driven modelling employs statistical and machine learning-based models to\nsimulate landslides, utilizing explicit and/or latent explanatory variables influencing land-\nslide occurrence (Amato et al., 2023).\nPhysics-based landslide modelling has been a well-established approach since the incep-\ntion of soil mechanics (Terzaghi, 1950), and it is primarily based on force balance problems"}, {"title": "Data and test site overview", "content": "To train and evaluate our proposed PINN, we choose the same dataset freely distributed by\nDahal and Lombardo (2023). The study area was affected in 2015 by the 7.8 Mw Gorkha\nearthquake, Nepal, resulting in tens of thousand coseismic landslides (see Figure 1). These\nhave been mapped by Roback et al. (2017) in an openly accessible inventory. Because of the\ncombined use of manual mapping and very high-resolution optical images, the This inventory\nhas been reported to be among the best available in the global repository made by (Schmitt\net al., 2017) and (Tanya\u015f et al., 2017), both in terms of quality (Tanya\u015f and Lombardo, 2019)\nNotably, because the Gorkha earthquake occurred during the Nepalese dry season, the\ncontribution of the groundwater to the shallow failures (the dominant mechanism reported\nby Roback and co-authors) is assumed to play a negligible role (Regmi et al., 2016).\nIn this experiment, most of the outcropping lithologies belong to the Siwalik formations,\nfollowed by the Himal group and various river formations such as the Seti and Sarung\nKhola formations (Dahal, 2012). The Siwalik Formation is primarily constituted by Molasse\ndeposits of the Himalayas, comprising sandstones, mudstones, shales, and conglomerates\n(Upreti, 2001). The river formations, mainly found in the middle Himalayas, consist of\na mixture of schist, granite, gneiss, phyllite, and quartzite (Upreti, 2001; Dahal, 2012).\nFinally, the upper Himalayan region is where most of the tectonic compression is affected\nthe lithological records, with metamorphic rocks encompassing schist, gneiss, migmatites,\nand marbles (Upreti, 2001). The geological map we used in this experiment was obtained\nfrom Wandrey (1998), thus partitioning the study area into nine different geological classes.\nOur mapping unit of choice corresponds to slope units (SUs, hereafter). These are essen-\ntially half sub-basins considered to be homogenous in terms of their overall slope exposition\n(Alvioli et al., 2016). Their use mainly appeared in lanslide studies as part of data-driven\nmodels (e.g., Tanya\u015f et al., 2019), with only one example to date where they have supported\nphysics-based slope stability models (Dom\u00e8nech et al., 2020), although exclusively during\nthe post-processing phase.\nOur main objective is to make use of SUs to represent the \u201cinfinite-slope\" problem (Xiao\net al., 2016; Xi et al., 2024).\nWe recall here that for regional studies, SUs are typically considered an ideal partition\nbecause they geographically approximate the hillslope response to a failure (Alvioli et al.,\n2020). Analogous considerations can be made in the framework of our proposed PINN. In\nfact, for a physics-informed data-driven approach, the same geomorphological considerations\nare valid, with the added geotechnical value of the homogeneity ensured by SUs being useful\nto express the inclined slope assumption predominantly held in pseudo-static and permanent\ndeformation analyses (Newmark, 1965).\nWhen defining our mapping units, we explored the potential use of the SU delineation\nmade by (Alvioli et al., 2022). However, these are SUs generated to partition the whole Hi-\nmalaya, thus making them too coarse for our modeling purposes. For this reason, we opted\nto use the same delineation appeared in Dahal and Lombardo (2023). These had a much\nsmaller initial target size, were selected among several possible versions generated through\npermutation of the r.slopeunits paramerization Alvioli et al. (see, 2016) and ultimately val-\nidated through visual inspection.\nEach of the SU served as the reference spatial scale at which we aggregated the input\npredictors as well as the landslide stable/unstable labels. For clarity, below we quickly\nsummarize the reasoning behind the choice of our predictor set:\ni. Eastness: The eastness shows how east direction the mountain slope faces. If it is\nfacing completely towards the east, then the value will result in 1 and 0 for the contrary.\nIt represents how much sunlight a particular slope gets, which can be a latent variable\nfor landslide occurrence (Olaya, 2009).\nii. Northness: Similar to eastness, northness provides information on the degree of north-\nness of the mountain slope. This is also used for the exact same reason as eastness\n(Olaya, 2009).\niii. Horizontal Curvature: The horizontal curvature provides on the overall horizontal\n\"bending\" of a given slope unit with respect to a imaginary horizontal tangent line.\nThis information is a proxy for the 3-dimensional geometry of a sloped unit (Hengl\nand Reuter, 2008).\niv. Vertical Curvature: Vertical curvature provides information on general vertical\n\"bending\" of the slope with respect to a given vertical plumbline (Hengl and Reuter,\n2008).\nv. Slope: Slope provides information regarding the slope unit's steepness and is crucial\ninformation for any landslide hazard information as the acting gravity on a rigid body\nalways acts with respect to the slope reference frame. Therefore, the slope is a first-\ndegree control of the occurrence of landslides (Hengl and Reuter, 2008; Lombardo et al.,\n2019).\nvi. Precipitation:To inform the model about the relative wetness of the given slope, we\nincluded the total precipitation at a local slope unit for the three months before the"}, {"title": "Methods", "content": "Landslide susceptibility can be defined as the landslide occurrence probability $L(s,t) \\in 0,1$\nin a specific location and time $L(s,t) = 1$ (Fell et al., 2008; van Westen et al., 2008). When\nassessing how prone a given landscape is to generate slope failures, the use of historical\n(Maharaj, 1993) or event-based (Lombardo and Tanyas, 2020) landslide inventories often\ncomes with neglecting the temporal component of the landslide genesis. Therefore, the\nsusceptibility is spatially defined, X, leading to a simplified notation as compared to the\none presented above, $L(s) = 1$.\nWe recall once more that susceptibility is usually obtained by means of either physics-\nbased or data-driven methods (Fan et al., 2019). In the first case, the susceptibility\n$p_p(s) \\in [0,1]$ is defined as the probability such that the displacement $D$ at any loca-\ntion $s$ exceeds a minimum displacement threshold $d_p$ (or velocity in some cases) $p_p(s) =$\n$Pr(D(s) \\geq d_m | G(s) = x(s))$ for given geotechnical conditions $G(s)$ (Huang et al., 2020a,b).\nIn many cases, the variables $G(s)$ cannot be gathered across regional sales, thus physics-based\nmethods employed for such scales simplify those variables by assuming constant geotechnical\nproperties over the study domain $X_s$ (Fan et al., 2019).\nIn this overarching theme, data-driven models offer valid alternative solutions. As sta-\ntistical models can directly infer the probability of a random process conditioning it to a set\nof predictors, they directly estimate the probability of landslide occurrence $L(s) = 1$ given\nthe environmental conditions $X(s)$, including topographic, geologic and other influencing\nfactors (Dahal et al., 2024a). Given the dichotomous nature of $L(s) = 1$, the Bernoulli prob-\nability distribution is well suited to address this classification task, with standard techniques\ndenoting the probability distribution as $L(s) \\sim Ber(p_d(s))$. Therefore, the probability of\nlandslide occurrence $p_d(s) \\in [0, 1]$ can be written as $p_d(s) = Pr{L(s) = 1 | X(s) = x(s)}$.\nGiven the two very different systems described above, the main problem with the data-\ndriven method is that $X (s)$ does not often represent the actual geotechnical conditions at\nwhich the slope failure occurs, and the model itself also does not respect the physical mecha-\nnism behind the landslide process (Dahal and Lombardo, 2023). Therefore, the data-driven\napproach is ideally used as a first-order estimation of landslide hazard, from which the most\nsusceptible locations can be selected and further analyses using physics-based approaches.\nHowever, there are two major issues in this sequence. Firstly, further analyses may miss\nhazardous locations if the data-driven approach misclassifies some highly susceptible loca-\ntions, or is prone to type II errors. Secondly, such ideal implementation is useful only in a\npreemptive manner and cease to be practical during emergencies. In situations where strong\nearthquakes induces widespread landsliding, what can be achieved is confined to a near-real-\ntime landslide susceptibility assessment (Nowicki Jessee et al., 2018), and detailed analyses\nare prohibitive because of the urgency in disaster response (Mon et al., 2018).\nTo solve these problems, we propose to combine the best of both worlds in a single model\nthat offers regional scale predictions, geotechnical meaningful results and a near-real-time\npredisposition, once pre-trained.\nTo do so, we estimate geotechnical parameters $G(s)$ given environmental variables $X(s)$\nwith some sort of highly non-linear functional approximation using deep learning function\n$F$. Then, we use those parameters through a physics-based landslide estimation technique to\nproduce a landslide susceptibility values. Therefore the approximated geotechnical parame-\nters can be defined as $G(s) = F(X(s)) | X(s) = x(s)$.\nIn this study, we opted to define a simple architecture where the neural network function\n$F$ is a ANN with 16 neural network blocks. Each block consists of a dense neural network\nof 64 neurons except for the last block, a batch normalization layer (Ioffe and Szegedy,\n2015), a dropout layer with a dropout ratio of 0.3 (Srivastava et al., 2014), and a rectified\nlinear unit (ReLU) activation function (Yarotsky, 2017; Nair and Hinton, 2010). The neural\nnetwork itself contains the trainable weights and biases, which are initialized using random\nnormal initialization (Thimm and Fiesler, 1995). The batch normalization and dropout\nlayers prevent the model from overfitting by regularizing the distribution of each batch and\nrandomly deactivating 30% of neurons. The ReLU activation changes the data flow to\nconvert the model into a non-linear one. The last block of the neural network consists of a\nvariable number of neurons, which are equal to the number of geotechnical parameters that\nwe wish to estimate, which in this case is two.\nNotably, which types and how many geotechnical parameters $G(s)$ entails depends on\nour assumptions and the underlying physical mechanism we want to solve. Once $G(s)$\nis estimated with the function F, it is then passed, together with required environmental\nconditions such as terrain slope, through a \u201cLandslide-Physics\" layer in the model, which\nrespects the physics of the failure mechanism.\nWith this general framework in mind, we define our model as follows. First, we se-\nlect a suitable physical mechanism for landslide estimation in earthquake-induced land-\nslides. In this case, we opt for a simplified permanent deformation method (i.e., Newmarks'\nmethod) (Jibson, 2007; Gallen et al., 2015). This method is our choice of physical model\nfor the \u201cLandslide-Physics\" layer. This layer defines landslide susceptibility as a function\nof permanent displacement due to seismic perturbation (Newmark, 1965). Let us assume\nthat without any seismic loading, the slope has a \u201cstandard\u201d factor of safety based on its\ngeotechnical properties and geometry. The geotechnical properties that affect slope stability\nare the cohesion of the material $C$, the thickness of the failure block $t$, the density of the\nrock and soil material $rho_r$, the density of water $p_w$, and internal friction angle $\\varphi$. The safety\nfactor is also largely controlled by the slope angle of failure plane $a$, the ratio of saturated\nthickness to total thickness $m$, and gravitational acceleration $g$. Gallen et al. (2015, 2017)\ndefines the factor of safety based on those properties as:\n$FS =\\frac{C}{\\frac{1}{t m (p_r g) sin(a)} + \\frac{tan(\\varphi)}{tan(a)}} + \\frac{m (p_w g) tan(\\varphi)}{(p_r g) tan(a)}$ (1)\nBecause the Gorkha earthquake occurred in the dry season in the Himalayan range,\nwe assume that the water table was below the failure surface, rendering $m = 0$ (Gallen\net al., 2017). This assumption simplifies the FS equation. Moreover, following Gallen\net al. (2017), we assume the material's average and constant density over the study area\nwith $p_r = 2300kgm^{-3}$. The gravitational constant is $g = 9.8ms^{-2}$. The factor of safety\nprovides the slope's strength to resist the driving force; this can be converted to represent\nthe minimum acceleration required to move the sliding block on an inclined plane. This\nacceleration term is called critical acceleration $a_c$ (Jibson, 1993), formulated as:\n$a_c =(FS - 1)gsin a$ (2)\nNow, by adding seismic loading in terms of peak ground acceleration $a_p$, we obtain an\nempirical model for the estimation of Newmark displacement of sliding block $D(s)$ (Jibson,\n2007; Gallen et al., 2015, 2017)shown as:\n$log D(s) = 0.215+log (1 - \\frac{a_c}{a_p})^{2.341} -(\\frac{a_c}{a_p})^{-1.438} \u00b10.51$ (3)\nThis whole process (equations, 1,2, and 3 are combined in a layer representing function\n4 which takes the input of slope $\\sigma(s) \\in X(s)$ and peak ground acceleration $a_p(s) \\in X(s)$\nfrom environmental variables as well the estimated geotechnical parameters $G(s)$. The\ngeotechnical parameters are estimated using the neural network model F are the ratio of\ncohesion per thickness of failure mass $C/t_m$ and the internal friction angle $\\varphi$. The function\n4 returns the exponential of the permanent displacement term $exp(D(s))$. Mathematically,\nit can be represented as $D(s) = \\psi(G(s), \\sigma(s), a_p(s))$. As we do not know the intermediate\ndeformation of our landslide mass and we only know if the slope has failed or not, we\ndefine a commonly accepted threshold of 5 cm as the displacement threshold above which\nthe slope starts to move. However, this still does not provide the probability of failure\n(or susceptibility) but rather a dichotomous representation of the process. Therefore, we\nmodified the ANN sigmoid functions to be centered around 5 cm threshold, such that it\nprovides an physics-integrated data-driven susceptibility $p(s) \\in [0, 1]$ as:\n$p(s) = c(D(s)) = \\frac{1}{1 + e^(5-D(s))}$ (4)\nSpecifically, equation 4 is similar to sigmoid activation with a centre around 5 cm and\nprovides higher probabilities for the cases $D(s) \\gg 5cm$ and lower probabilities for $D(s) \\ll$\n5cm. This function can be graphically represented in Figure 2.\nThis overall physics-integrated landslide susceptibility model can be written in the form\n$p(s) = \\varsigma(\\psi(F(X(s)), \\sigma(s), a_p(s))) | X(s) = x(s), \\sigma(s) \\in x(s), a_p(s) \\in x(s)$. This can be\nfurther simplified to denote the physics integrated model as $\\Theta(X(s)) | X(s) = x(s)$.\nWe recall at this point that any neural network architecture relies on a loss function\nto converge to the best solution. In this sense, to train the trainable parts of the model\n$\\Theta(X(s))$, we can use a normal binary cross entropy loss function, because our model output\nis a pseudo-probability $p(s) \\in [0,1]$ (Good, 1963; Akaike, 1998). To train our model, we\nhave used a mini-batch optimisation technique where network parameters are updated with\neach randomly selected batch $B_N C 1,...,n$ of size $N < n$, where n is the total number of\nbatches (Li et al., 2014). Let the $l_i$ be the observed $L(s)$ value for each slope unit during the\nearthquake event, and $p_i(s_i)$ the predicted probability for $i^{th}$ variable. This can be written\nas per equation 5.\n$Loss = -\\Sigma_{i \\in B_N} \\Sigma[l_i log(p_i(s_i)) + (1 - l_i) l_i) log(1 - p_i(s_i))]$ (5)\nWith the above loss function and defined model, we trained our model using 70% of the\noverall slope units. Out of the remaining 30% of the dataset, half of it was used to validate\nthe model, while the remaining half was used to test the it. The Adam optimizer (Kingma\nand Ba, 2014) is selected for updating the model weights and biases (optimization) because\nof its robustness in training deep neural network models. We started the training process\nwith $le^{-3}$ learning rate, which was decreased by 90% at each 10000 minibatch step. The\nbatch size used for the training was 1024, meaning that 1024 randomly selected training\ndatasets were passed to the model at each training step. The model performance was tested\nusing the area under the traditional receiver operating characteristics curve (ROC) curve as\nwell as the balanced accuracy metric and F1-score (Thibos et al., 1979; Goutte and Gaussier,\n2005). Moreover, to validate the usability of the model, we performed 10-fold cross-validation\nwhere nine near-equal random subsets of data are iteratively used to train the model while\nthe complementary 10% is used for testing. Especially for binary classification models, a\ncross-validation procedure purely based on random data extraction is known to potentially\nproduce overly optimistic results (Brenning, 2012). This happens because a random sampling\nessentially leave the spatial pattern in the data undisturbed, which in turn is translated in\ncross-validation performance results close to the ones obtained by fitting the model to the\nwhole dataset. For this reason, the literature on the topic suggests to include spatial-cross\nvalidations, to complete the prediction performance overview (Pohjankukka et al., 2017).\nThis is the case because a spatial cross-validation draws data not randomly but rather on\nthe basis of their position, ensuring that any underlying spatial coherence is broken. This"}, {"title": "Results", "content": "In this section, we present the results obtained from performance evaluation with spatial and\nrandom cross-validation, the intermediate geotechnical parameters, and landslide suscepti-\nbility.\nIn general, our PINN produced excellent performance scores (see the classification pro-\nposed by Hosmer and Lemeshow, 2000) with an area under the curve (AUC) of 0.87. \u03a4\u03bf\ncomplete the performance evaluation, we also computed balanced accuracy and F1-score,"}, {"title": "Discussion", "content": "The model we developed may constitute a valuable alternative for landslide hazard mod-\nelling, for it offers a series of advantages with respect to traditional data-driven solutions.\nThe first element of strength, as the PINN definition implies, resides in the ability of our\nmodel to follow the physics of the coseismic failure process. Consequently, as the second\nelement of strength, our PINN treats geotechnical properties as latent predictors, thus ex-\ntracting them from data. On a more generic level, the weakness of many physically-based\nmethods is precisely their need for explicit geotechnical information. In turn, they are either\nconstrained to small geographic areas or potentially lead to lower prediction capabilities in\nlarge geographic areas. This is the case because acquiring geotechnical data is prohibitive\nwhen considering regional scales. Therefore, whenever applied to address regional slope sta-\nbility problems, these models make assumptions that limit the variability of the required\nparameters. For instance, they assume a single value to be characteristic of the whole study\narea under consideration (Fan et al., 2019).\nOn the other side of the spectrum, data-driven models usually cannot work at the slope\nscale or at a scale involving few catchments. This happens because landslide inventories\nwith numerous records are typically obtained over broader landscapes, unless some extreme\ntrigger locally produced such conditions (e.g., G\u00f6r\u00fcm et al., 2023; Santangelo et al., 2023). In\nother words, even if formally there is no minimum requirement in terms of landslide numbers\nto support any data-driven susceptibility assessment, it is also true that a dataset containing\njust tens of landslides cannot support the estimation of any meaningful statistical relation\nbetween stable/unstable slopes and the given predictor set.\nThis is why data-driven susceptibility models are mostly successful when the involved\ngeographic scales span over regional (e.g., Wan, 2009; Frattini et al., 2010; Lin et al., 2018),\nnational (e.g., Trigila et al., 2013; Lima et al., 2017; Wang et al., 2022) and global (e.g.,\nJia et al., 2021; Felsberg et al., 2022; Tang et al., 2023) territories. However, despite the\npredictive power they ensure, physically-consistent results are not achieved (Glade et al.,\n2005). To date, the best one can do in this sense is to interpret the estimated regression\ncoefficients (Steger et al., 2022, 2024) for statistical solutions or to interpret the predictor\nimportance (Di Napoli et al., 2020; Meena et al., 2022) and more recently the SHAP (Collini\net al., 2022; Wang et al., 2024a) values for machine learning tools.\nWe thus stress that our modelling approach consitutes a first step towards combining\nphysically based and data-driven models to obtain physically consistent, generalizable and\nregional scale landslide susceptibility results.\nHere, we have combined the permanent deformation approach proposed by Newmark\n(1965) into a deep learning model capable of estimating its parameters. Similar to adding\nground motion and seismic loading to the pseudo-static method of Terzaghi (1950), such that\nthe seismic perturbations may lead to a failure condition, our approach adds the physical\nconstraint and seismic perturbations in data-driven landslide occurrence modelling. Another\nproblem our model tackles is that, even in the case where one can get access to a reliable\ngeotechnical characterization of a regional landscape (to our knowledge such example exists\nin Northridge, US; Dreyfus et al., 2013), the corresponding soil or rock sample are collected\nand tested in laboratory conditions. This implies that the geotechnical characterization\nis valid for a specific location and time. However, these may be subjected to changes in\nresponse to precipitation, vegetation, anthropic influence, etc. In turn, this requires physics-\nbased models to be updated with new data or to be re-calibrated (Clarke and Burbank, 2011;\nTownsend et al., 2020; Singeisen et al., 2022). To some extent, our model is still affected\nby the same problem. However, the level of spatial details at which it retrieves the required\ngeotechnical parameters corresponds to each individual SU, making it a tool that may serve\nthe purpose of inferring a basic geotechnical characterization of a regional landscape. At an\naggregated SU level, the geotechnical changes one may expect at the scale of a single sample\nshould be less prominent. Therefore, our architecture should be, at least theoretically, less\nsensitive to changes, and if this issue would exist at all, it definitely provides a much cheaper\nway to generate a regional geotechnical characterization, as compared to a systematic field\nsurvey campaign.\nIt is important to keep in mind that such advantages may come with limitations when\ncomparing PINNs to standard deep learning architectures. In fact, PINNs add an additional\nand intermediate constraint in the form of physical laws. In general, this translates into\nlower prediction performance compared to a neural network who's free to converge to an\noptimal prediction function solely on the basis of the provided environmental variables. This\nis the generic assumption one can find in the technical literature on PINNS (see, Cuomo\net al., 2022).\nBecause we used the same data as Dahal and Lombardo (2023), we have the chance to use\nour previous work as a benchmark and verify this common hypothesis on PINNs versus pure\nperformance-oriented architectures. Interestingly, in the present case and for both spatial\nand random cross-validation, we can see that the model performs similarly to the previous\nexperiment, if not better.\nFor instance, we can observe that for the 10-fold random cross-validation case (Figure 3),\nthe misclassified landslide locations are present at the boundaries between the SU with and\nwithout landslides.\nThis might be because, due to the same environmental conditions, our model estimates\nsimilar geotechnical parameters. Also, the peak ground motion data is spatially smooth.\nThus, the nearby SUs may appear to be exposed to similar ground motion characteristics.\nThis is a difficult issue to address due to the combination of the physically constrained\napproach and the available predictor data. Therefore, we observe that misclassification is\nmainly located near the transition between failed and stable slope units.\nAs for the case of spatial cross-validation, our PINN performed much better than the\nprevious model without physics (Dahal and Lombardo, 2023). This is clearly visible in\nthe southeastern sector of the study area, where our PINN essentially does not produce\nfalse predictions, whereas the previously published architecture erroneously classified the\nlandscape. We interpret these results in terms of spatial transferability. In other words,\nwhen data is insufficient or performance-oriented models predict over new data, our PINN\nprovides more reliable estimates because they still need to obey the underlying laws of\nphysics.\nLooking into the generated geotechnical characterization of the study area, the estimated\nc/t and the retrieve large spatial variations (in the median maps), as one would expect in\nnature or as opposed to generalized single-value assumptions.\nThe median value range shows a geotechnical valid range of parameters with a spatial"}, {"title": "Concluding remarks", "content": "Physics-informed modelling approaches are the future of scientific modelling in any system\nscience, for they are robust and can combine the benefits of data-driven and physics-based\ntools. In landslide science, data-driven and physics-based approaches have dominated two\ndifferent and complementary aspects of hazard assessment procedures, with the former being\nthe most sought solution at regional scales and the former being the standard for local ones.\nBridging the gap between the two by combining their strengths can provide a valid alternative\nfor landslide susceptibility and hazard modelling.\nOur modelling framework integrates the permanent deformation approach as part of a\ndeep-learning architecture. This avenue uses latent variables to learn the geotechnical param-\neters and use them to estimate the physically constrained landslide occurrence probability.\nOur results show that the estimated values of geotechnical data lie in the observable and\nreasonable range, allowing for their variation over space. This leads to excellent model per-\nformance, reached while ensuring a clear physical explainability. In the immediate future,\nthis framework can be extended as part of near-real-time prediction tools.\nEven though current physical constraints fit the observed data well and show potential\napplications, this framework can be further improved by including a stress deformation\napproach in the landslide initiation. A better inventory with intermediate deformation and\na stress-strain condition is required for this. Moreover, further improvement on this work\ncould be made by including a multi-physical earth system process, which would provide a\nmore general solution to the landslide susceptibility modelling."}]}