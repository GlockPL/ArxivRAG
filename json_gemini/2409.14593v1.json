{"title": "Testing Causal Models with Hidden Variables in Polynomial Delay via Conditional Independencies", "authors": ["Hyunchai Jeong", "Adiba Ejaz", "Jin Tian", "Elias Bareinboim"], "abstract": "Testing a hypothesized causal model against observational data is a key prerequisite for many causal inference tasks. A natural approach is to test whether the conditional independence relations (CIs) assumed in the model hold in the data. While a model can assume exponentially many CIs (with respect to the number of variables), testing all of them is both impractical and unnecessary. Causal graphs, which encode these CIs in polynomial space, give rise to local Markov properties that enable model testing with a significantly smaller subset of CIs. Model testing based on local properties requires an algorithm to list the relevant CIs. However, existing algorithms for realistic settings with hidden variables and non-parametric distributions can take exponential time to produce even a single CI constraint. In this paper, we introduce the c-component local Markov property (C-LMP) for causal graphs with hidden variables. Since C-LMP can still invoke an exponential number of CIs, we develop a polynomial delay algorithm to list these CIs in poly-time intervals. To our knowledge, this is the first algorithm that enables poly-delay testing of CIs in causal graphs with hidden variables against arbitrary data distributions. Experiments on real-world and synthetic data demonstrate the practicality of our algorithm.", "sections": [{"title": "1 Introduction", "content": "Causal models are the daily bread of many fields of research (Pearl 2000; Spirtes, Glymour, and Scheines 2001), but tools for testing them are lacking. In various studies, researchers posit a causal model and use it to compute causal effects from data (Tennant et al. 2020; Hoover 1990; King et al. 2004; Sverchkov and Craven 2017; Robins, Hernan, and Brumback 2000; Rotmensch et al. 2017). The model imposes testable constraints on the statistics of the data collected. Before using the model for causal inference, it's crucial to test if these constraints are met, and adjust the model as needed (Pearl 1995, 2000; Bareinboim and Pearl 2016; Malinsky 2024; Ankan and Textor 2022).\nCausal directed acyclic graphs (DAGs) are one popular model for causal assumptions (Pearl 2000; Spirtes, Glymour, and Scheines 2001). Conditional independencies (CIs) are the most basic constraint that a DAG imposes on observational data. The study of CIs in the context of graphical models dates back to at least the 1980's (Pearl 1988; Dawid 1979; Spirtes et al. 1998; Pearl 1998; Pearl and Meshkat 1999; Pearl 2000). A classic problem in this line of research is: given observational data and a hypothesized causal graph, do all the CIs implied by this graph hold in the data? If the answer is no, the DAG must be revised.\nA multivariate probability distribution may encode exponentially many CIs with respect to the number of observed variables. A key idea in the early literature of graphical models was to use a DAG to represent the constraints of these distributions. A DAG can encode exponentially many CIs in polynomial space. The set of all CIs encoded in a DAG, derivable using the d-separation criterion, is known as the global Markov property (Pearl 1988). There is also a well-known local Markov property for DAGs (Pearl 1988; Lauritzen et al. 1990). It states that each variable must be conditionally independent of its non-descendants given its parents. Since the CI relation is a semi-graphoid, the linearly many CIs of the local Markov property span the exponentially many CIs of the global Markov property. This means that it suffices to perform a linear number of CI tests, as given by the local Markov property, to test a DAG against observational data. For concreteness, consider the DAG $G^1$ in Fig. 1a and assume all variables {A, B, . . ., H, U1, U2} are observed. Though $G^1$ encodes 9929 CIs, only 9 need testing by the local Markov property. For example, if we test that $C || {A,E} | {B}$, one does not need to test that $C || {A} | {B, E}$, since the former implies the latter by the weak union axiom.\nUnobserved confounding is a widespread phenomenon in real-world settings (Fisher 1936). It occurs when a hidden variable causally affects two or more observed variables. The local Markov property can be used to test Markovian causal DAGs, which represent models without unobserved confounding. However, it cannot be used to test semi-Markovian DAGs, which represent models with unobserved confounding.\u00b9 This is because if the parents of a variable are partially"}, {"title": "2 Preliminaries", "content": "Notation. We use capital letters to denote variables (X), small letters for their values (x), and bold letters for sets of variables (X) and their values (x). The probability distribution over a set of variables X is denoted by P(X). We consistently use P(x) as abbreviations for probabilities P(X = x). For disjoint sets of variables X, Y, Z, we use $X \\perp Y | Z$ to denote that X and Y are conditionally independent given Z.\nStructural causal models. The basic framework of our analysis rests on structural causal models (SCMs) (Pearl 2000, Def. 7.1.1). An SCM M is a quadruple M = (V, U, F, P(u)) where V and U are sets of endogeneous and exogeneous variables, respectively. F is a set of functions: each $V \\in V$ is a function $f_v(PA_v, U_v)$ of its endogeneous and exogeneous parents, $PA_v \\subseteq V$ and $U_v \\subset U$ respectively. P(u) is a joint distribution over U. Each SCM M induces an observed distribution P(v) over V. For a more detailed survey on SCMs, we refer to (Pearl 2000; Bareinboim et al. 2022).\nCausal graphs. The causal graph G for an SCM M = (V, U, F, P(u)) is constructed as follows: (1) add a vertex for every $V \\in V$ (2) add an edge $V_i \\rightarrow V_j$ for every $V_i, V_j \\in V$ if $V_i \\in PA_v$; (3) add a dashed bidirected edge between $V_i, V_j$ if $U_i, U_j$ are correlated or $U_i \\cap U_j \\neq \\emptyset$. G is said to be Markovian if it contains only directed edges, and semi-Markovian otherwise.\nWe denote the sets of parents, ancestors, and descendants of X (including X itself) in G as Pa(X), An(X), and De(X), respectively. The set of non-descendants of X in G is denoted $Nd(X) = V \\setminus De(X)$, which does not include X itself. The set of spouses of X in G is $Sp(X) = \\bigcup_{X \\in X}{Y | Y \\leftrightarrow X}$. X is said to be an ancestral set if it contains its own ancestors, i.e., X = An(X). We use $G_x$ to denote the induced subgraph of G on X C V. A subscript $G'$, e.g., $An(X)_{G'}$, indicates that the set is computed from the subgraph G'. We omit the subscript when clear from context. An ordering V on variables V is said to be consistent with G (i.e., a topological ordering) if for any X, Y \u2208 V, X < Y implies $Y \\notin An(X)_g$. Let $V_{\\leq X} = {Y | Y < X \\text{ or } Y = X}$.\nd-separation. A node W on a path \u03c0 is said to be a collider on \u03c0 if W has converging arrows into W in \u03c0, e.g., $\\rightarrow W \\leftarrow$ or $\\leftrightarrow W$. \u03c0 is said to be blocked by a set Z if there exists a node W on \u03c0 satisfying one of the following two conditions: 1) W is a collider, and neither W nor any of its descendants are in Z, or 2) W is not a collider, and W is in Z (Pearl 1988). Given disjoint sets X, Y, and Z in G, Z is said to d-separate X from Y in G if and only if Z blocks"}, {"title": "3 The C-component Local Markov Property", "content": "In this section, we motivate and introduce the c-component local Markov property for causal DAGs with unobserved confounders. In Sec. 3.1, we demonstrate the limitations of the traditional local Markov property (LMP) when applied to semi-Markovian DAGs. In Sec. 3.2, to solve this problem, we present the c-component local Markov property (C-LMP) for semi-Markovian DAGs and establish its equivalence with GMP. In Sec. 3.3, we provide a useful property of C-LMP that makes its CIs amenable to listing.\n3.1 A Naive Approach to Testing Semi-Markovian Compatibility\nFirst, we show the limitations of applying the well-known LMP (Def. 3) in the context of testing semi-Markovian DAGs. For each variable X in a given graph, LMP states that X is independent of its non-descendants conditioning on its parents. Intuitively, the parents of X form a minimal set, conditioning on which is necessary and sufficient to render X independent of its non-descendants."}, {"title": "4 Listing CIs", "content": "Our goal in this section is to develop an algorithm that lists CIs invoked by C-LMP. In general, there may exist exponentially many such CIs, requiring exponential time to list them all. In such cases, we look for algorithms that run in polynomial delay (Johnson, Yannakakis, and Papadimitriou 1988). Poly-delay algorithms output the first solution (or indicate none is available) in poly-time, and take poly-time to output each consecutive solution.\nHowever, for model testing purposes, it is not desirable to list all CIs invoked by C-LMP. Some CIs invoked by (LMP,<), and equivalently C-LMP, have the form $X || \\emptyset | Z$, meaning that they are vacuous, there is nothing to test. Therefore, we further constrain the problem by requiring that we list only non-vacuous CIs, as defined below.\nWe develop the algorithm LISTCI (Alg. 1) to list all non-vacuous CIs invoked by C-LMP in poly-delay.\n4.1 Listing CIs for a Given Variable\nThe algorithm LISTCI iterates over each variable $X \\in V^{\\lessapprox}$ and lists all non-vacuous CIs invoked by C-LMP for X. By Def. 5 and Def. 6, listing non-vacuous CIs invoked by C-LMP reduces to enumerating AACs. In this section, we show how to enumerate AACs relative to a given variable $X \\in V$ using the procedure LISTCIX (Fig. 5).\nLISTCIX adopts a divide-and-conquer strategy similar to the algorithm presented in (Takata 2010). LISTCIX implicitly constructs a binary search tree for X using a depth-first approach. Tree nodes of the form N(I', R') represents the collection of all AACs C with $I' \\subset C \\subset R'$. Due to the construction on line 4 of LISTCI, I is contained in and R contains all possible AACs relative to X. So, the top-level call of LISTCIX, at the root node N(I, R), represents all AACS C relative to X. Thus, the top-level call can generate all CIs invoked by C-LMP for X.\nSubsequent recursive calls expand this tree by shrinking the range one variable at a time. To ensure that the algorithm runs in poly-delay, we expand the tree from a node N(I', R') if and only if the expansion is guaranteed to produce a non-vacuous CI. Equivalently, there must exist at least one AAC C such that $I' \\subseteq C \\subseteq R'$. If there is no such C, we prune the tree and back-track to the previous tree node. Given I', R', to find in poly-time an AAC C such that $I' \\subseteq C \\subseteq R'$ (or indicate that there is none), LISTCIX calls the function FINDAAC (Fig. 6).\nAnother requirement of the poly-delay property is that each AAC should appear exactly once in the enumeration of AACS. To expand the tree from N(I', R'), LISTCIX constructs two 'disjoint' children (lines 10-11); for some variable $S \\in V$, S cannot be in any AAC from the left child, but must be in every AAC from the right child. Finally, a leaf tree node L is reached when I = R. LISTCIX outputs a non-vacuous CI invoked by C-LMP from the AAC C = I using Def. 5.\n4.2 Finding an AAC\nIn this section, we address the following subproblem, needed for LISTCIX to run in poly-delay: given a variable $X \\in V^{\\lessapprox}$, and two ACs I, R relative to X, how do we find an AAC C such that $I \\subset C \\subset R$ (or indicate that there is none) in poly-time?\nThe poly-time constraint on solving this subproblem rules out the brute-force approach: namely, iterating over all subsets C such that $I \\subset C \\subset R$ until we find some C that is an AAC (or conclude that there is none). The key idea behind our solution, FINDAAC, is that either I itself is admissible, or if not, there exists such C \\supseteq I if and only if $C_o$ constructed on line 8 of FINDAAC is admissible.\nWhen I is not admissible, no variable $D \\in V_{\\leq X} \\setminus Pa(I)$ is separated from X by the conditioning set $Pa(I) \\setminus {X}$. Equivalently, every such D must be in $De(Sp(I) \\setminus Pa(I))$ (Def. 5). Interestingly, we show that an AAC C under the constraint I \u2286 C \u2286 R exists if and only if, for some $D \\in V_{\\leq X} \\setminus Pa(I)$, there exists any separating set Z of X and D such that $Pa(I) \\setminus {X, D} \\subseteq Z \\subseteq Pa(R) \\setminus {X, D}$. Z need not be a c-component. We can check if such Z exists (line 6) in poly-time using the function FINDSEPARATOR (Fig. C.2.2 in Appendix C.2). FINDSEPARATOR is a generalisation of FINDSEP (van der Zander, Liskiewicz, and Textor 2014) for ancestral graphs to arbitrary semi-Markovian DAGs."}, {"title": "5 Experiments", "content": "In this section, we first demonstrate the runtime of LISTCI on benchmark DAGs of up to 100 nodes from the bnlearn repository (Scutari 2010). Next, we apply LISTCI to model testing on a real-world protein signaling dataset with an expert-provided graph (Sachs et al. 2005). Third, we provide analysis of the total number of non-vacuous CIs invoked by C-LMP, using LISTCI for the analysis. The details of the three experiments are shown in Appendix F.\nExperiment 1 (Comparison of LISTCI with other algorithms). We compare the runtime of LISTCI with two baselines: LISTGMP (Fig. E.0.1 in Appendix E) and LISTCIBF (Alg. B.1.1 in Appendix B.1).\nExperiment 2 (Application to model testing). A real-world protein signaling dataset (Sachs et al. 2005) has been used to benchmark causal discovery methods (Cundy, Grover, and Ermon 2021; Zantedeschi et al. 2023). The dataset (853 samples) comes with an expert-provided ground-truth DAG (11 nodes, 16 edges). Using LISTCI, we test to what extent this graph is compatible with the available data. We use a kernel-based CI test from the causal-learn package (Zheng et al. 2024) with p-value $p = 0.05$ (for the null hypothesis of dependence).\nExperiment 3 (Analysis of C-LMP). We use LISTCI to understand the total number of non-vacuous CIs invoked by C-LMP. Let CI denote this number. CI is also the number of CIs that need to be tested from a given semi-Markovian causal DAG. Based on experiments with random graphs shown in Appendix F.3, we conclude that the graph topology associated with c-components plays a major role in CI. More specifically, two factors related to c-components are of primary interest:\n1. s\u2264 n: the size of the largest c-component, and\n2. The sparsity of c-components, a proxy for which is the number of bidirected edges.\nAs we add bidirected edges, while c-components are sparse, CI increases exponentially with s, as given by the bound $O(n2s)$. As c-components become more dense, CI decays exponentially with the number of bidirected edges. As an illustrative example, please refer to Fig. F.3.1 and the discussion on Case 1 in Appendix F.3."}, {"title": "6 Conclusions", "content": "In this paper, we introduced a new conditional independence property for causal models with unobserved confounders, namely, the c-component local Markov property (C-LMP, Def. 5). Given a DAG G, C-LMP identifies a small subset of conditional independence constraints (CIs) that together imply all other CIs encoded in G. We showed that C-LMP is equivalent to the global Markov property (Thm. 1), and that each CI that C-LMP invokes can be generated from a unique ancestral c-component (Thm. 2). Building on this foundation, we developed the first algorithm LISTCI (Alg. 1) capable of listing all CIs invoked by C-LMP in polynomial"}, {"title": "A Background and Previous Work", "content": "A.1 Background\nIn the appendix, for some integer $k \\geq 0$, we use [k] to denote the set {1, 2, . . ., k} (with [0] = \u2205).\nGraph preliminaries. Let X be a set of variables in a DAG G over variables V. We define four kinship relations:\n1. Parents of X, denoted Pa(X): $Pa(X) = {Y \\in V | Y \\rightarrow X \\text{ for some } X \\in X} \\cup X$.\n2. Ancestors of X, denoted An(X): $An(X) = {Y \\in V | \\text{there is a directed path from Y to X for some } X \\in X} \\cup X$.\n3. Descendants of X, denoted De(X): $De(X) = {Y \\in V | \\text{there is a directed path from X to Y for some } X \\in X} \\cup X$\n4. Non-descendants of X, denoted Nd(X): $V \\setminus De(X)$. Note that Nd(X) does not include X.\nThe ordered local Markov property. We define the ordered local Markov property (Richardson 2003) for semi-Markovian causal DAGs and its basic components below.\nDefinition A.1.1. (Markov Blanket (MB)) (Richardson 2003) Given a causal graph G and a consistent ordering V, let X be a variable in V and S an ancestral set in G such that $X \\in S \\subseteq V^{\\leq X}$. Then, the Markov blanket of X with respect to the induced subgraph $G_S$, denoted mb(X, S), is defined as $mb(X, S) = Pa(C(X)_{Gs})_{gs} \\setminus {X}$.\nDefinition A.1.2. (Maximal Ancestral Set (MAS)) (Richardson 2003) Given a causal graph G and a consistent ordering V, let X be a variable in V and S an ancestral set in G such that $X \\in S \\subseteq V^{\\leq x}$. Then, S is said to be maximal with respect to the Markov blanket mb(X, S) if, for any ancestral set S' such that $X \\in S \\subseteq S' \\subset V^{\\leq x}$ and mb(X, S) = mb(X, S'), we have $S = S'$.\nWe state Richardson's ordered local Markov property (with quantification MASs instead of all ancestral sets (Richardson 2003, Section 3.1)).\nDefinition A.1.3. (The Ordered Local Markov Property (LMP,<)) (Richardson 2003) A probability distribution P(v) over variables V is said to satisfy the ordered local Markov property for G with respect to the consistent ordering V if, for any variable X and ancestral set S such that $X \\in S \\subseteq V^{\\leq x}$ and S is maximal with respect to mb(X, S), $X \\perp S \\setminus (mb(X, S) \\cup {X}) | mb(X, S) \\text{ in } P(v)$."}, {"title": "BC-LMP and the Ordered Local Markov Property", "content": "(LMP, <) is a well-known Markov property that applies to arbitrary observational distributions and causal graphs with unobserved confounders. In this section, we first explain how naively following the definition of (LMP,<) can take exponential time to output just one CI. Next, we characterize (LMP, <) in more depth and show how ACs (Def. 4) can be used to compute the CIs that (LMP, <) invokes."}]}