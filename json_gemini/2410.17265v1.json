{"title": "Federated brain tumor segmentation: an extensive benchmark", "authors": ["Matthis Manthe", "Stefan Duffner", "Carole Lartizien"], "abstract": "Recently, federated learning has raised increasing interest in the medical image analysis field due to its ability to aggregate multi-center data with privacy-preserving properties. A large amount of federated training schemes have been published, which we categorize into global (one final model), personalized (one model per institution) or hybrid (one model per cluster of institutions) methods. However, their applicability on the recently published Federated Brain Tumor Segmentation 2022 dataset has not been explored yet. We propose an extensive benchmark of federated learning algorithms from all three classes on this task. While standard FedAvg already performs very well, we show that some methods from each category can bring a slight performance improvement and potentially limit the final model(s) bias toward the predominant data distribution of the federation. Moreover, we provide a deeper understanding of the behaviour of federated learning on this task through alternative ways of distributing the pooled dataset among institutions, namely an Independent and Identical Distributed (IID) setup, and a limited data setup. Our code is available at (https://github.com/MatthisManthe/Benchmark_FeTS2022).", "sections": [{"title": "1. Introduction", "content": "Deep learning showed state-of-the-art performance on a variety of medical image analysis tasks Baur et al. (2019); Futrega et al. (2022); Maier et al. (2017); Zeineldin et al. (2022). However, training precise deep learning models requires a large amount of sensitive and high-quality data. Data centralization possibilities are limited: restrictive legislations such as the General Data Protection Regulation (GDPR) in Europe, the overall sensitivity of medical images, as well as the high labelling cost of each exam by clinical expert, make the aggregation of large amounts of data complicated if not prohibited.\nFederated learning was defined in McMahan et al. (2017) with the seminal algorithm called Federated Averaging (FedAvg) as a decentralized privacy-preserving machine learning paradigm enabling numerous institutions to collaboratively train a model on their cumulated data without ever sharing them. Even if the privacy of standard federated learning methods is a field of research in itself Rodr\u00edguez-Barroso et al. (2023); Yang et al. (2023); Zhu et al. (2019), classical federated learning methods are a significant step towards effective decentralized training conformed with privacy and ethical requirements.\nWe have seen a growing interest in federated learning in the medical field as it could drastically increase the data quantity used to train a model at a limited privacy cost. It became a popular research topic on a variety of tasks, from fMRI analysis Li et al. (2020c) to brain anomaly detection Bercea et al. (2022), based on fully Qu et al. (2022a), weakly Lu et al. (2022); Yang et al. (2021), or un- Wu et al. (2022) supervised models, even mixing these levels of supervision Wicaksana et al. (2022)."}, {"title": "2. Related work", "content": "There are overall more and more incentives to perform multi-centric research M\u00e5rtensson et al. (2020); Wachinger et al. (2021), as well as more available public datasets to do so Bilic et al. (2023). In particular, the Federated brain Tumor Segmentation (FeTS) initiative published the institution-wise partitioning of the BraTS2021 dataset Baid et al. (2021); Karargyris et al. (2021); Pati et al. (2021); Reina et al. (2022), composed of around 1200 multi-modal brain MRI scans of gliomas from 23 clinical institutions along with their multi-label tumor segmentation masks including the whole tumor outline as well as the enhancing and necrotic areas. A significant amount of pioneering works showed that the federated learning paradigm was attractive on this task Sheller et al. (2020); Pati et al. (2022), with two FeTS challenges organized in 2021 and 2022 Pati et al. (2021); Isik-Polat et al. (2022); Khan et al. (2022); M\u00e4chler et al. (2021), as well as some independent works exploring other aspects of decentralized learning on this valuable segmentation task Camajori Tedeschini et al. (2022); Li et al. (2019).\nIn the past few years, a very large amount of research work has been done by the machine learning community on the general topic of federated learning addressing different limitations. It has been clearly identified now that the statistical distribution of data across institutions, potentially heterogeneous, can drastically alter the performance of standard federated learning methods such as FedAvg Li et al. (2020a); Karimireddy et al. (2020). On this specific problem, a large number of lines of research have been defined, which can be categorized into three classes: global methods McMahan et al. (2017), i.e. training one model generalizing on the data of every institution; personalized methods Li et al. (2021b), i.e. training one personalized model for each institution while each benefiting from the federation; and hybrid methods Sattler et al. (2021), i.e. building a set of models each designed to perform well on a set of institution or samples. Most of these state-of-the-art (SOTA) methods are outside of the scope of previous works on BraTS dataset and have never been explored on the brain tumor segmentation task yet. Moreover, novel federated methods proposed in both the medical image analysis and machine learning communities mainly focus on patient-level classification tasks, with only few works on segmentation tasks.\nWe propose a benchmark of several global, personalized and hybrid state-of-the-art federated learning methods on the FeTS2022 dataset. Its purpose is to first investigate the performance of standard federated learning methods on the latest version of the dataset, as well as to highlight which class of methods tend to give better performances considering its data distribution. We complement existing works on FeTS dataset by exploring the application of these methods in a significantly different federated setup, from chosen local optimizer to computational constraints. The main contributions of our work are as follows\n\u2022 We propose, to the best of our knowledge, the first benchmark of personalized and clustered federated learning methods on brain tumor segmentation, showing the potential of both of these paradigms for this task,\n\u2022 We fixed a common estimated time budget enabling the fastest algorithms to reach their validation plateau, analysing results close to convergence.\n\u2022 We analyse the performance biases between institutions brought by each federated optimizer.\n\u2022 We defined each method in a common formal framework with some adaptations for our federated setup, and publicly available implementations.\nMoreover, we explore additional synthetic partitions of the dataset, namely a randomly redistributed version as well as a version with a limited amount of data per institution with a more controlled heterogeneity. We bring with these secondary experiments a better understanding of the behaviour of federated learning methods on this task.\nIn section 2, we detail the current trends in both the federated learning community and its application to neuro-image analysis. In section 3, we motivate the choice of each method included in this benchmark and describe them. We define the experimental setup in section 4, and explore the results in section 5. We discuss the choices made as well as the limitations of the benchmark and conclude in section 6."}, {"title": "2.1. Federated learning", "content": "The first published federated learning algorithm was Federated Averaging (FedAvg) McMahan et al. (2017), where each participating institution performs multiple gradient steps locally on a received model between server-side averaging steps. We can underline two main research axes devoted to the improvement of this algorithm in terms of convergence speed and the final accuracy of the obtained global model.\nThe first one is to perceive the aggregation server-side as the approximation of a gradient, thus exploring federated algorithms as a branch of standard stochastic optimization theory. Thus was explored, for example, the addition of server-side learning rate, momentum and adaptivity Jhunjhunwala et al. (2023); Reddi et al. (2022). A second line of work is to perceive the aggregation step as a model fusion task. Some authors proposed to match neurons or channels between local models before averaging the weights by the Hungarian algorithm (FedMA Wang et al. (2020a)) or graph matching Liu et al. (2022), or by allocating semantic channel positions prior to training in the network for a better averaging (Fed\u00b2 Yu et al. (2021)).\nIt was quickly shown that the statistical heterogeneity of local datasets could harm the convergence the more local steps are performed between server synchronizations Wang et al. (2020b); Zhao et al. (2018). Numerous authors proposed improvements over FedAvg in this specific case. Most of them alter the local optimization to limit the \"client drift\", namely the quick overfitting of local optimizations towards local optima, negating the efficiency of server aggregations. Proximal regularization was first proposed (FedProx Li et al. (2020a)), followed by several important methods trying to guide local optimizations away from local optima. Examples are SCAFFOLD, leveraging control variates to promote the convergence"}, {"title": "2.2. Personalized and hybrid federated learning", "content": "In parallel to the previously described methods, some authors suggested that training a plurality of models instead of training a single global model performing well on the data of every institution could help bridge the gap between centralized and federated performance in the case of high statistical heterogeneity.\nThe first line of research, named personalization, aims at training one model per institution each performing better than a global model obtained by standard federated learning and than what could be obtained by isolated institutions. As a straightforward example, personalization can be performed by simply fine-tuning locally a model obtained by FedAvg, which was shown quite efficient Mansour et al. (2020). The idea of partial model sharing quickly followed, with the earliest methods retaining local the first (LG-FedAvg Liang et al. (2020)) or the last (FedPer Arivazhagan et al. (2019)) local layers, or the batch normalization parameters (FedBN Li et al. (2020e)) of a neural network. Numerous works then followed this line of work (CD2-FedAvg Shen et al. (2022), PartialFixedShare Pillutla et al. (2022), PartialFed Sun et al. (2021)).\nThe personalization task can be linked to a large number of subfields in machine learning, and multiple formulations were proposed. Authors interpreted personalization in the meta-learning framework, with the objective of training a server-side meta-model easily fine-tunable on local datasets. In that vein, adaptations of the model-agnostic meta-learning algorithm (MAML Finn et al. (2017)) were explored (PerFedAvg Fallah et al. (2020) or pFedMe Dinh et al. (2020)). Alternatively, each local dataset of a federation can be viewed as a task in the multi-task learning framework. Thus, authors tried to adapt multi-task regularization methods to the federated setup, such as Ditto Li et al. (2021b) or FedEM Marfoq et al. (2022a).\nMore specific to the federated setup, some researchers explored the combination of local and global methods to perform personalization. The first works explored the definition of personalization objectives as finding the best interpolation between local and global models (Mapper Mansour et al. (2020), Soft-Pull Xu et al. (2022)), while a recent work also proposed to use a combination of a global federated learning model and local KNN models to perform robust personalization (kNN-Per Marfoq et al. (2022b)). We can also note an interesting idea of leveraging a hypernetwork server-side to output the parameters (or a subset of them) of personalized models (pFedHN Shamsian et al. (2021)).\nFinally, tangentially to multi-task adaptations, some authors explored personalization methods based on the computation of similarities between local datasets through different proxies, either using the loss of a local model on the datasets of other institutions (FedFOMO Zhang et al. (2021)), or distances in the parameter space (FedAMP Huang et al. (2021)) to use them as local aggregation weights. This implicit hypothesis of institutions sharing more similarity with a subset of the federation also motivated a refinement of the personalization framework into a clustered (or hybrid) one. In this framework, the objective is to train a set of models, each specialized for a set of institutions. Cluster federated learning also implies the computation of similarities between institutions: some authors experimented with the loss of the clustered models to incrementally compute clusters of institutions during training (IFCA Ghosh et al. (2020)), or computed clusters based on the cosine similarity matrix between local updates (CFL Sattler et al. (2021))."}, {"title": "2.3. Federated learning in brain tumor segmentation", "content": "Pioneering works already established the potential of federated learning in brain tumor segmentation. A first proof of concept was proposed in Sheller et al. (2020), where standard FedAvg was compared to cyclic weight transfer on BraTS 2018 dataset, highlighting that even in a cross-silo setting, the latter did not scale well due to catastrophic forgetting from one institution to the other, while the former reached a close match in performance with centralized training. This work was rapidly followed by experiments with differential privacy and local momentum restart Li et al. (2019). Furthermore, two editions of the Federated brain Tumor Segmentation Challenge, FeTS 2021 and 2022 were hosted Pati et al. (2021). They were dedicated to the impact analysis of institution sampling, frequency of server synchronisation and aggregation weights strategies in FedAvg. Several novel methods were proposed during this challenge. Isik-Polat et al. (2022); Khan et al. (2022); M\u00e4chler et al. (2021, 2023) Namely, FedCostwAvg M\u00e4chler et al. (2021) was the winner of 2021's edition, weighting the local updates by a linear combination of the local sample size and the local loss improvement from one round to another. The authors further improved their method on the second edition, named FedPIDAvg M\u00e4chler et al. (2023), by adding a third term in the weight of the local updates: a form of momentum on the local losses. Other participants experimented with FedAvg-M, FedAdam, robust aggregation schemes such as median, trimmed mean (discounting local updates that are too far from the median), Top-K mean (discounting local updates that did not sufficiently improve the local loss compared to others), and other forms of loss based server-side aggregations Rawat et al. (2022); Tuladhar et al.. Finally, other authors explored during the challenge the usage of adaptive number of local epochs per round and learning rate decay with FedAvg as well as FedNova and FedAvg-M Isik-Polat et al. (2022); Tuladhar et al.. Finally, an outstanding real world application of federated learning on 71 institutions"}, {"title": "3. Methods", "content": "As we could not experiment with every state-of-the-art federated learning methods, we selected the most representative and established ones from different groups of federated techniques (from adaptive and variance reduction-based global methods, finetuning-based or multi-task-based personalized methods, etc.). We define each of them with the potential adaptations which were required to apply them on the 3D brain tumor segmentation task of interest."}, {"title": "3.1. Notations and centralized problem", "content": "Let $K$ be the number of institutions each with a local dataset $D_k := \\{(x_{k,i}, y_{k,i})\\}_{i=1}^{n_k}$, with $x_{k,i} \\in X = \\mathbb{R}^{m \\times h \\times w \\times d}$ the multimodal MRI scan to segment, $y_{k,i} \\in Y = \\{0,1\\}^{l \\times h \\times w \\times d}$ its associated multi-label ground-truth segmentation map, $n_k$ the local dataset size of institution $k$ and $N = \\Sigma_{k=1}^K n_k$ the total number of samples. We note $w \\in W = \\mathbb{R}^p$ the parameters of the neural network to be optimized for the downstream task.\nGiven a loss function $l : W \\times X \\times Y \\rightarrow \\mathbb{R}$, the classical formulation of the neural network optimization problem in a centralized setup can be defined as\n$w^* = \\underset{w \\in W}{\\operatorname{argmin}} \\sum_{i=1}^N l(w, x_i, y_i)$\nover the pooled dataset $D = \\bigcup_{k=1}^K D_k$."}, {"title": "3.2. Global federated learning", "content": ""}, {"title": "3.2.1. Problem formulation", "content": "Under privacy constraints, pooling each institution's local dataset together on a single computation unit is prohibited. Federated learning was proposed (McMahan et al. (2017)) to train a neural network over decentralized data in a collaborative fashion such that raw data never leaves data warehouses of each participating institution. The decentralized optimization problem can be defined as\n$w^* = \\underset{w \\in W}{\\operatorname{argmin}} \\sum_{k=1}^K \\sum_{i=1}^{n_k} l(w, x_{k,i}, y_{k,i})$,\nrecovering the centralized one. Explored global federated algorithms are summarized in Algorithm 1."}, {"title": "3.2.2. Federated Averaging", "content": "Federated Averaging (FedAvg) is a pioneer work proposed by McMahan et al. (2017). They proposed to organize the collaborative training process in several communication rounds. During each round $t$, the aggregation server sends the parameters $w^t$ of the current global model to each participant. They perform $E$ epochs of local training using $w^t$ as an initialization to obtain a local update $\\Delta w_k = w_k - w^t$ (note that in most theoretical works, $U$ gradient steps per institution are used instead). They then send these updates back to the server, which aggregates them in a single global update applied to the global model following\n$w^{t+1} = w^t + \\sum_{k=1}^K p_k \\Delta w_k$,\nwith $p_k$ an aggregation weight. Both uniform ($p_k = \\frac{1}{K}$) and weighted ($p_k = \\frac{n_k}{N}$) averaging were proposed, the latter introduced to ensure convergence towards the global objective of Equation 2.\nAs the term FedAvg encompasses all of these different variations, we specifically define FedAvg with fixed local epochs its variant with each institution performing $E$ local epochs between each communication round and server-side weighted average aggregation, FedAvg with fixed iterations its variant with $U$ local updates and weighted averaging and FedAvg with uniform averaging its variant with $E$ local epochs and uniform averaging. Fixed batch size is set common to all institutions for all variants."}, {"title": "3.2.3. FedNova", "content": "In the specific case of an unbalanced amount of samples per institution, the authors of Wang et al. (2020b) underlined an inconsistency in the optimization of FedAvg with a fixed number of local epochs per round and weighted aggregation (i.e. $p_k = \\frac{n_k}{N}$). With a unique fixed batch size, institutions owning more samples than others will perform more gradient steps, giving implicitly more weight to their local updates in the aggregation. This motivated the development of a framework to limit this problem for a large amount of SOTA methods, leveraging normalized gradient aggregation. In our study, we chose to apply their adaptation of FedAvg, following a simplification of the formulation in Isik-Polat et al. (2022). FedNova reduces to FedAvg with a uniform weighting scheme and an analytical server learning rate $\\gamma \\ge 1$\n$\\gamma = \\frac{K}{\\sum_{k=1}^K p_k^2}$"}, {"title": "3.2.4. SCAFFOLD", "content": "To reduce the variability of local updates and enforce convergence of local optimizations toward the global optima, Karimireddy et al. (2020) added the computation of local and global control variates used as a form of momentum during local optimizations. After each local training, an institution updates its local control variate $c_k$ following\n$\\Delta c_k^t = -c_k^t + \\frac{1}{S_k \\eta_l} \\Delta w_k$\n$c_k^{t+1} = c_k^t + \\Delta c_k^t$\nwith $s_k$ the number of gradient steps performed by institution $k$ and $c^t$ a global control variate, and sends them to the server along with the computed local updates $\\Delta w_k$. In addition to the classical aggregation of FedAvg, the server aggregates control variate updates into the global control variate following\n$c^{t+1} = c^t + \\sum_{k=1}^K p_k \\Delta c_k^t$\nwhich is sent back to the institutions. A local update step on a batch $b_k$ of samples of institution $k$ is altered by these control variates following Equation 9 (omitting local step and global round superscripts for readability).\n$w_k = w_k - \\eta_l (\\nabla l(w_k, b_k) - c_k + c)$.\nNote that we use the adaptation to batch training of SCAFFOLD published in Reddi et al. (2022) to deal with imbalanced local dataset sizes."}, {"title": "3.2.5. FedAdam", "content": "Reddi et al. (2022) proposed to extend classical adaptative methods such as Adagrad, Adam and Yogi to federated learning by applying them server-side while giving proofs of their effectiveness in this context. For computational cost reasons, we chose to focus on FedAdam only. At aggregation step $t$, the server computes first and second-order momentums\n$\\Delta^{t+1} = \\beta_1 \\Delta^t + (1 - \\beta_1) \\sum_{k=1}^K p_k \\Delta w_k^t$\n$\\nu^{t+1} = \\beta_2 \\nu^t + (1 - \\beta_2) \\sum_{k=1}^K p_k (\\Delta w_k^t)^2$\nand aggregates local updates following\n$w^{t+1} = w^t + \\eta_s \\frac{\\Delta^{t+1}}{\\sqrt{\\nu^{t+1} + \\tau}}$"}, {"title": "3.2.6. q-FedAvg", "content": "Soon after the publication of McMahan et al. (2017), Li et al. (2020b) explored the notion of fairness in federated learning. They showed that FedAvg could accentuate the disparities of performance of the global model between institutions. Extending the pioneering work of Mohri et al. (2019), they proposed to give more weight server-side to updates computed by institutions on which the global model at rounds $t$ performs worse than others. Formally, they define the fair federated objective as follows\n$w^* = \\underset{w \\in W}{\\operatorname{argmin}} \\sum_{k=1}^K p_k \\left(\\frac{1}{n_k} \\sum_{i=1}^{n_k} l(w, x_i, y_i) \\right)^{\\frac{q+1}{q}}$\nwith $q \\in \\mathbb{R}^+$ a hyperparameter enabling to define the desired level of fairness ($q = 0$ is equivalent to FedAvg, while $q \\rightarrow \\infty$ gives agnostic federated learning Mohri et al. (2019), optimizing for the worse performing institution). To optimize this objective, the authors proposed a modification of FedAvg called q-FedAvg. Each participant weights its local update by the loss of the latest global model on its data to the power q before transmitting it to the server\n$\\Delta w_k^t = F_k(w^t)^{-q} \\Delta w_k$\nwhere the local training loss of institution k is defined as follows\n$F_k(w) := \\sum_{\\{x_k, y_k\\} \\in D_k} l(w, x_k, y_k)$\nThey also compute a regularization value $h_k$, used at the server-side in the aggregation step following\n$h_k = q F^{q-1}(w^t) \\left\\| \\Delta w_k \\right\\|^2 + \\frac{p_k}{N} F^q(w^t)$\n$w^{t+1} = w^t + \\eta_s \\frac{\\sum_k h_k \\Delta w_k}{\\sum_k h_k}$"}, {"title": "3.2.7. FedPIDAvg", "content": "The winner of the 2022's edition of the FeTS challenge Pati et al. (2021) proposed FedPIDAvg M\u00e4chler et al. (2023), a variation of FedAvg with a server-side weighting strategy inspired by PID controllers as follows\n$w^{t+1} = w^t + \\sum_{k=1}^K (\\alpha p_k + \\beta \\frac{\\Delta l_{val, k}^t}{L^t} + \\gamma \\frac{m_k^t}{M^t}) \\Delta w_k^t$\nwith $l_{val, k}^t$ the local validation loss of institution $k$ at round $t$, $\\Delta l_{val, k}^t$ the local validation loss improvement, $m_k^t$ a momentum term on these validation loss values and $L^t$ and $M^t$ normalization terms defined as\nl_{val,k}^t = \\sum_{i=1}^{n_{val,k}} l(w^t, x_i^t, y_i^t)\n\\Delta l_{val, k}^t = l_{val,k}^{t-1} - l_{val, k}^t, \\quad L^t = \\sum_k \\Delta l_{val, k}^t\nm_k^t = \\sum_{i=0}^t \\Delta l_{val,k}^i, \\quad M^t = \\sum_{i=1}^K m_k^t$"}, {"title": "3.3. Personalized federated learning", "content": ""}, {"title": "3.3.1. Problem formulation", "content": "In the context of statistical heterogeneity between institutions' datasets, personalized federated learning emerged as the optimization of one model per institution. The subsequent objective can be formalized as the union of the local objectives\n$w^* = \\underset{w_k \\in W}{\\operatorname{argmin}} \\sum_{k=1}^K \\sum_{i=1}^{n_k} l(w_k, x_{k,i}, y_{k,i}), \\forall k \\in \\{1, ..., K\\}$\nwhile each model $w_k$ still benefits from the whole federation."}, {"title": "3.3.2. Local training", "content": "The simplest approach fitting the latter objective is for each institution to train a model locally without any communication."}, {"title": "3.3.3. Local finetuning", "content": "One can also perform personalization by first training a global model using a global solution such as FedAvg, which is then finetuned locally by each institution for several epochs."}, {"title": "3.3.4. Ditto", "content": "In Li et al. (2021b), the authors inspired themselves by the field of multi-task learning, where the local dataset of each institution can be seen as a task. They define their regularized bi-level objective for institution k as follows\n$w_k^* = \\underset{w_k \\in W}{\\operatorname{argmin}} \\sum_{i=1}^{n_k} l(w_k, x_i, y_i) + \\frac{\\lambda}{2} \\left\\| w_k - w \\right\\|^2$\nsuch that $w^*$ solves the global problem of Equation 2. They argue that this problem can be solved either by local finetuning over the regularized local objective of Equation 24, or by adding a personalization module in parallel to global training. Since they showed that the latter only provides benefits in case of the presence of malicious users while drastically increasing local computation loads, we implement Ditto as the former."}, {"title": "3.3.5. Partial model sharing", "content": "A large amount of research work has been devoted to the exploration of partial model sharing in federated learning in the literature (Section 2). We chose to focus in this work to the most established ones, namely FedPer Arivazhagan et al. (2019) and LG-FedAvg Liang et al. (2020). Both share the same principle: the model parameters $w$ are partitioned into federated ones $w_g$ and local ones $w_l$ such that $w = w_g \\cup w_l$. Based upon FedAvg, local updates are computed similarly and only the federated weights $w_{g,k}$ of institution k are transmitted to the server,"}, {"title": "3.4. Clustered federated learning", "content": ""}, {"title": "3.4.1. Problem formulation", "content": "Depending on the task, assumptions on the existence of clusters of institutions with similar data distributions can be made. Consequently, some authors Ghosh et al. (2020); Sattler et al. (2021) proposed to define a clustered federated learning objective as the union of each cluster objective\n$w^* = \\underset{w_c}{\\operatorname{argmin}} \\sum_{c \\in \\mathcal{C}} \\sum_{k \\in c} \\sum_{i=1}^{n_k} l(w_c, x_{k,i}, y_{k,i}), \\forall c \\in \\mathcal{C}$\nwith $\\mathcal{C}$ a partitioning of the $K$ institutions, and $w_c$ the model parameters of cluster $c$, while each cluster $c$ benefits from the whole federation."}, {"title": "3.4.2. Prior clustering", "content": "If possible, one can leverage prior knowledge on the distribution of the data between institutions, effectively defining clustering before federated training. This leads to $\\mathcal{C}$ being predefined before federated training while implying the leakage of potentially sensitive information. In the case of our study, we do know that gliomas can be classified as of low or high grade (LGG or HGG respectively, c.f. Section 4.1). We name Prior CFL HGG/LGG the federated finetuning (using FedAvg) of the best obtained FedAvg model on two clusters of institutions: the ones only owning volumes displaying a low-grade tumor (12, 13, 14 and 15) from the others."}, {"title": "3.4.3. Sattler's Clustered federated learning (CFL) Sattler et al. (2021)", "content": "If no prior knowledge can be shared independently to federated learning, cluster assignments can be performed in a variety of ways during training. In Sattler et al. (2021), the authors proposed to recursively split clusters of institutions into two during federated training. The method starts with standard FedAvg on a single cluster $c_1 = \\{1, ..., K\\}$ containing every institution. A list of clusters of institutions $\\mathcal{C}$ is saved during the whole optimization process, initialized with the initial cluster $c_0$. At an arbitrary communication round $t$, FedAvg is performed independently in parallel on each cluster of the list. At each communication round, the server assesses if each cluster $c$ in the list $\\mathcal{C}$ must be split into two parts $c_1$ and $c_2$ before the next round through the following conditions\n$\\frac{\\sum_{i \\in c} \\| \\Delta w_i \\|}{\\max_{i \\in c} \\| \\Delta w_i \\|} < \\epsilon_1$\n$|| \\Delta w_{\\max} || > \\epsilon_2$\nIf so, the server splits the cluster $c$ of institutions in two based on the cosine similarity matrix of received local updates from these institutions\n$d_{i,j} = \\frac{\\langle \\Delta w_i, \\Delta w_j \\rangle}{\\| \\Delta w_i \\| \\| \\Delta w_j \\|}, \\quad i, j \\in c$\neffectively solving\n$c_1, c_2 = \\underset{\\substack{c_1 \\cup c_2 = c}}{\\operatorname{argmin}} (\\underset{\\substack{i \\in c_1, \\ j \\in c_2}}{\\max} a_{i,j})$\nand splitting cluster $c$ into $c_1$ and $c_2$ if\n$\\gamma_{\\max} < \\sqrt{\\frac{1 - \\underset{\\substack{i \\in c_1, \\ j \\in c_2}}{\\max} a_{i,j}}{2}}$\nAs the hyperparameters $\\epsilon_1$, $\\epsilon_2$ and $\\gamma_{\\max}$ defined to choose which cluster to split at which global round are very hard to tune, we slightly simplify their method. Instead of using $\\epsilon_1$, $\\epsilon_2$ and $\\gamma_{\\max}$, we only define as a hyperparameter the communication rounds at which each cluster must be split in two, which enables us to avoid relying on local updates norms which can be very heterogeneous in our extremely unbalanced setup."}, {"title": "4. Experiments", "content": "4.1. Federated brain tumor segmentation 2022 challenge dataset\nExperiments were led on the MICCAI's Federated Brain Tumor Segmentation 2022 Challenge dataset (FeTS2022) (Bakas et al. (2017); Pati et al. (2021); Reina et al. (2022)). This dataset is based on the Brain Tumor Segmentation 2021 Challenge dataset (BraTS2021). It consists of 1251 multi-modal brain MRI scans (T1, T1ce, T2 and FLAIR) of size 240 \u00d7 240 \u00d7 155 with isotropic 1mm\u00b3 voxel size along with their multi-label tumor segmentation masks including 4 labels, namely background, enhancing tumor (ET), tumor core (TC) and whole tumor (WT).\nThe real-world partitioning along the 23 acquiring institutions is provided"}]}