{"title": "Introducing MeMo: A Multimodal Dataset for Memory Modelling in Multiparty Conversations", "authors": ["Maria Tsfasman", "Bernd Dudzik", "Kristian Fenech", "Andras Lorincz", "Catholijn M. Jonker", "Catharine Oertel"], "abstract": "The quality of human social relationships is intricately linked to human memory processes, with memory serving as the foundation for the creation of social bonds. Since human memory is selective, differing recollections of the same events within a group can lead to misunderstandings and misalignments in what is perceived to be common ground in the group. Yet, conversational facilitation systems, aimed at advancing the quality of group interactions, usually focus on tracking users' states within an individual session, ignoring what remains in each participant's memory after the interaction. Conversational memory is the process by which humans encode, retain and retrieve verbal, non-verbal and contextual information from a conversation. Understanding conversational memory can be used as a source of information on the long-term development of social connections within a group. This paper introduces the MeMo corpus, the first conversational dataset annotated with participants' memory retention reports, aimed at facilitating computational modelling of human conversational memory. The MeMo corpus includes 31 hours of small-group discussions on the topic of Covid-19, repeated over the term of 2 weeks. It integrates validated behavioural and perceptual measures, and includes audio, video, and multimodal annotations, offering a valuable resource for studying and modelling conversational memory and group dynamics. By introducing the MeMo corpus, presenting an analysis of its validity, and demonstrating its usefulness for future research, this paper aims to pave the way for future research in conversational memory modelling for intelligent system development.", "sections": [{"title": "1 INTRODUCTION", "content": "HUMAN memory for conversations plays a crucial role\nin shaping social bonds and fostering relationship\nbuilding, as well as decision-making in future interactions\n[1]. Understanding human conversational memory is, thus,\nessential for explaining and predicting human behaviour in\nconversations. Conversational memory can be defined as a\nsub-type of episodic memory, which manages the encod-\ning, storage, and retrieval of personally experienced events\n[2], particularly within conversational settings. Previous\nresearch on conversational memory shows that numerous\nfactors can affect what is encoded and retained from a\nconversation: the relationship between participants, their\ncharacteristics, linguistic features of produced speech and\nmany more [3]\u2013[8]. However, due to the multitude of vari-\nables involved, it remains unclear how these factors interact\nto determine which memories are more likely to be retained\nand which are more likely to be forgotten over time.\nOne way of investigating the intricate potentially non-\nlinear relationship between contributing factors to a socio-\ncognitive process such as memory is by creating a compu-\ntational model. Although never applied to conversational\nmemory, to our knowledge, other socio-cognitive phenom-\nena such as affect, engagement or cohesion have been previ-\nously investigated using computational models [9]\u2013[11]. Re-\nsearchers model these socio-cognitive processes by training\nmachine learning algorithms to predict user's internal states\nfrom verbal and non-verbal data. A major issue to take into\naccount when building such a model is the data used for\nits creation since the model can only be as accurate as the\ndata it is trained on [12]. Similar to the reproducibility crisis\nin the field of social sciences [13], there is more and more\nunderstanding of how a biased or misconstrued dataset can\nbe detrimental to the reproducibility, generalisability and\nvalidity of the resulting models [14], [15]. Many scholars are\ncalling for more careful creation of datasets aimed at com-\nputational modelling [12], [14], [15]. Therefore, constructing\na computational model of conversational memory requires\na dataset that is representative of the modelled constructs\nand is collected in an ecologically valid setting.\nSince there is no such data available for conversa-\ntional memory research, in this paper, we introduce the\nMeMo (Memory Modelling) corpus the first conversa-\ntional corpus with annotations for conversational mem-\nory. The MeMo corpus is aimed to be used for computa-\ntional modelling of conversational memory developed with\nmultidisciplinary research in mind. It, therefore, combines\nvalidated behavioural and perceptual measures as well\nas video, audio, and multimodal annotations, individual\nand group eye gaze behaviour, head pose, low-level hand\ngestures, and text. The variety of measures, multimodal-\nity and ecological validity of the corpus make it a useful\nresource for computational as well as behavioural studies\non conversational memory and group dynamics. Because of\nthe data complexity, the dataset will be released in batches\nwith the process described in Section 7.4 once the pseudo-\nanonymisation process is complete. In this paper, we aim to\nachieve the following goals:\n\u2022 Introducing the MeMo corpus. We describe the MeMo\ncorpus, the data collection, and its challenges. The\nMeMo corpus pioneers a way of collecting first-party\nmemory annotations directly usable in computational\nresearch - by combining a free-recall task with a subse-\nquent first-party annotation of the recorded memorable"}, {"title": "2 MOTIVATION FOR CREATING MEMO", "content": "Humans are inherently social creatures, and the quality of\none's social connections significantly impacts their psycho-\nlogical and physiological well-being [16]. Feeling listened\nto, understood, and appreciated within a social relationship\nis essential for fostering these quality connections [17]. In\ngroup settings, such as family gatherings or work meetings,\nit could be challenging to achieve this quality, because\nof differences in personality, dominance and other factors.\nConversation facilitation has emerged as a promising ap-\nproach to enhancing the quality of these group interactions\n[18], [19]. Over repeated sessions with a trained facilitator,\ngroups of people can resolve conflicts, deepen conversa-\ntions, and foster mutual understanding across various social\nsettings [20]\u2013[22]. Conversation facilitation can be challeng-\ning, requiring undivided attention towards multiple team\nmembers, conversation structure and content [23]. Compu-\ntational systems can support human facilitators in this task,\nas well as serve as an alternative solution in the absence of\na human facilitator [24].\nExisting conversation support systems have been shown\nto improve social interaction satisfaction, encourage equal\nparticipation and decrease social inhibitions [25]\u2013[27]. A\ncommon method of achieving these results involves contin-\nuous tracking of users' non-verbal and verbal signals [28].\nThese low-level signals are then used to infer a real-time\nmeasure of users' participation (e.g. [26]) or more complex\ninternal states such as attention (e.g. [29]), dominance (e.g.\n[30]) or social presence (e.g. [31]). Based on these predicted\nmeasures, a system then produces suggestions on how to\nenforce meeting structure and promote equal participation\n(e.g. [28], [26]). These predicted measures are real-time in-\ndicators of a participant's immediate reactions or internal\nstates, captured at specific timestamps or as cumulative\nmeasures from the start of the session. Although these mea-\nsures can be used to represent users' current state or trends\nwithin a session, they do not always represent the way the\nuser will feel about the subject in subsequent interactions,\nsince feelings triggered by an event within an interaction\ncould be forgotten or completely changed over time, in\nretrospect to the event [32]. To sum up, user experience\nitself may not matter as much as the user's memory of that\nexperience in the context of long-term interaction and future\ndesisicions [33]. Consequently, for long-term interaction, a\nfacilitation system needs to not only track the current state\nof the user but also understand the user's memory of\nconversational experiences.\nDecades of cognitive research show that, due to the selec-\ntive nature of human memory, only a fraction of perceived\nexperiences are encoded and retained [34]. The (subcon-\nscious) decision to retain or forget a conversational event\nis not random, it is affected by an intricate combination\nof inter- and intra-personal factors, such as conversational\ncontext, linguistic parameters of speech, one's role in the\nconversation, and conversational skills [6]-[8]. Apart from\nthese over-arching factors, according to previous research,\nhumans tend to retain experiences that (1) enrich or confirm\ntheir self-image [6], (2) connect them to other individuals\n[7], [35], [36] or (3) guide their future actions, thoughts and\nresponses [1]. While previous research has identified these\nfactors and functions of human memory, how they operate\ntogether in spontaneous settings, determining whether an\nevent will be retained or forgotten remains unclear. Corre-\nsponding to the mentioned memory functions, understand-\ning what remains in a user's memory after an interaction\ncould help a facilitation system in (1) understanding a user's\npersonal preferences and identity, (2) keeping track of re-\nlational development between conversational partners and\n(3) understanding the origin of perspectives and decisions in\nfuture interactions. Yet, to our knowledge, users' memory of\nthe interaction has never been collected, analysed or inferred\nto advance meeting support systems.\nUnlocking the potential of personal memories for user-\nmodeling and personalization purposes in conversational\nsettings requires predictive models based on real-world\nconversational data. In another context that of media\nconsumption - researchers have built such models to predict\nwhich images or videos are more likely to be encoded and\nretained by a human viewer based on media features and\nuser characteristics [37]-[40]. However, the conversational\ncontext is different from media consumption: unlike media\nconsumption, conversational context involves continuous\nproduction and comprehension of verbal and non-verbal\nsignals, involving different cognitive mechanisms [41] and\nproducing qualitatively and quantitatively different mem-\nories [4]. Moreover, conversational memory has various\ncontext-specific factors at play that do not apply to media\nconsumption tasks: conversation-specific verbal and non-\nverbal signals, the relational dynamics between conversa-\ntional partners, and many more [3], [5]-[8]. Therefore, the\ntask of modelling how humans encode, retain and retrieve\nconversations remains unsolved.\nSince there has not been any computational research on\nthe topic and the data used in the psychological research on\nconversational memory is mainly collected from controlled\nexperiments, an essential step towards conversational mem-\nory prediction is constructing a dataset of spontaneous\nconversations annotated with memory reports. Therefore,\nwe constructed the MeMo corpus to provide a resource\nfor the two primary goals: (G1) for research and compu-\ntational prediction of participants' memory in spontaneous\nconversations via verbal and non-verbal signals and (G2) for\nthe creation of conversational memory models supporting\nmeeting facilitation in the context of repeated interactions."}, {"title": "3 GUIDING PRINCIPLES FOR COLLECTING MEMO", "content": "When constructing a dataset suitable for studying and mod-\nelling human conversational memory, we argue that several\nmajor principles need to be considered."}, {"title": "3.1 P1: Maximising ecological validity", "content": "While scraping the internet for datasets has become very\ncommon in computer science, researchers increasingly ad-\nvocate for carefully curated datasets to better predict hu-\nman behaviour in natural settings [12], [15], [42]. This is\nparticularly important when the computational models are\naimed to predict and explain human behaviour in a setting\nwith minimal structural constraints, such as free-flowing\nconversations [42]. In the context of conversational memory\nmodelling, this is particularly important since an unnatural,\nscripted setting can change the structure and the content\nof memories [43], [44]. Therefore, we strove to ensure that\nthe MeMo corpus accurately reflects the conditions and\nvariables present in real-life conversations."}, {"title": "P1.1 Preserving Natural Interaction Environment", "content": "First,\nthe dataset would need to be recorded in a natural environ-\nment rather than in a laboratory setting. The laboratory en-\nvironment can introduce artificial constraints and biases that\nmay not exist in real-life conversational settings, including\nintrusive sensors and unnatural conversation settings (e.g.\na lab with visible sensors and no natural light). It has been\nshown, that people perform differently in memory tasks in\na laboratory setting in comparison to a real-world setting\n[45]. The dataset, therefore, needs to preserve a natural\nconversational setting typical to real-world environments."}, {"title": "P1.2 Preserving Spontaneity of Conversation Interac- tions", "content": "Second, for conversational memory reports to repre-\nsent the processes engaged in an in-the-wild conversation\nor meeting, the conversation must be as spontaneous as\npossible. The main reason is that the processes involved in\ncomprehension and production of spontaneous speech are\ndifferent from reading out text or following a script (as in\nscripted corpora, e.g. [46]). For example, memory for self-\nproduced statements can differ from reading or hearing\na statement [6], [41], [47]. Letting the conversation flow\nemerge by itself rather than imposing lab-created tasks or\nstructure as much as feasible is important for the ecological\nvalidity of such conversational data."}, {"title": "P1.3 Ensuring Representativeness of Participants", "content": "Lastly, it is important for a dataset to recruit a represen-\ntative sample of participants from diverse demographics\nand backgrounds. It is, unfortunately, a common practice\nin datasets and experimental studies to mainly recruit uni-\nversity students and staff, biasing the data towards a demo-\ngraphic of highly educated English-speaking white young\nwomen [48], [49]. An alternative to university students\nis a more diverse demographic of participants recruited\nthrough specialised websites such as Amazon Mechanical\nTurk. While this method provides a more diverse demo-\ngraphic, participants recruited this way might be 'profes-\nsional participants' who go through a multitude of studies\ndaily and are therefore biased in how they respond to the\nexperiment questions [50]. In either case, study results can\ngreatly depend on the demographics of its participants [51],\nand it is therefore important to report the demographics\nalong with the dataset to understand the limitations of\nthe data. So far, unfortunately, it is not a common practice\nand many datasets do not report the demographics of their\nparticipants (see section Section 4.5 for examples)."}, {"title": "3.2 P2: Maximising the construct validity of conversa- tional memory measure", "content": "A principal goal of developing MEMO is to collect a cor-\npus that facilitates the identification of moments in a con-\nversation likely to be retained by its participants (\u2192G2).\nCollecting such data is challenging due to the fundamen-\ntally different organisation of human experience as context-\ndelineated episodes and the typically timestamp-delineated\nsegments used to annotate moments in multimodal data\n(see Dudzik et al. [52] for a discussion). Aiming for construct\nvalidity involves ensuring that our chosen measures accu-\nrately reflect conversational memory while also recognising\nthe limitations of the selected metric.\nThe existing approach to estimating which events are\nencoded from a conversation is a free-recall task - ask-\ning participants to report what they remember from the\nconversation in their own words, usually in writing [53].\nTo then access the events that these reports refer to for\nanalysis, external annotators review the reports and identify\nthe events mentioned within the conversation [8], [54].\nOutsourcing this task to external observers may impact\nthe construct validity of the resulting memory measure, as\nmultiple moments might match a description, making it\ndifficult to determine the specific event without asking the\nparticipant directly.\nGiven that the MeMo corpus is designed to model\nconversational memory, we propose an alternative method.\nAfter a conversation, participants complete a free-recall\ntask, describing what they remember. They then watch a\nrecording and pinpoint the exact moments that match their\nmemories (see Section 5.2 for details). This approach ensures\nthat the identified moments accurately reflect the partic-\nipants' memories, preserving the validity of the memory\nannotations. These annotations provide a reliable temporal\nlink between memory reports and conversation segments,\nserving as ground-truth labels for computational modelling."}, {"title": "3.3 P3: Considering Context-sensitivity of Memory Processes", "content": "Maximising ecological validity (P1) might imply that fewer\nvariables are controlled (e.g. more diverse demographic,\nan in-the-wild experimental setting, etc.). Therefore, while\nmaximising the internal validity of the data, it might reduce\nthe external validity [55]. To avoid this, it is particularly\nimportant to track as many potential confounding variables\nas possible using validated questionnaires accepted by the\nscientific community.\nSpecifically, conversational memory can be affected by\ncommunication skills [7], mood [56], [57], personality [58],\nvalues [59] and the relationship dynamics between partic-\nipants [5], [60]. In addition, factors in relation to group\nperception should be measured such as group entitativity,\ncohesion and rapport. While they have not been investi-gated in relation to conversational memory the research\nshows that they can influence learning [61], [62], which is\ninherently related to memory."}, {"title": "4 RELATED WORK", "content": "To the best of our knowledge there are no datasets focus-\ning on conversational memory. However, to contextualise\nMeMo, we describe existing datasets that are aimed to\nsupport computational modelling research on memory in\none way or another. In addition, we describe most related\nbehavioural studies on the topic of conversational memory.\nWe compare the data designs using the criteria most rele-\nvant for the context of the MeMo corpus as shown in Table\n4. We describe each criterion in the following subsections."}, {"title": "4.1 Facilitated Modelling Perspective", "content": "When it comes to datasets for modelling memory processes,\nwe distinguish between two different modelling perspec-\ntives that they facilitate: 1) Corpora supporting Situation-\ncentered perspectives facilitate modelling how specific prop-\nerties of a defined situation (e.g., exposure to a video) are\nexpected to give rise to memory responses in members of\nsome population (e.g., how specific video content is likely to\nbe remembered by people in general). Datasets focusing on\na situation-centered modelling perspective often attempt to\ncapture a large range of distinct situations but typically have\na small number of distinct individuals responding to them\n(e.g. [63]). In contrast, datasets with an 2) Individual-centered\nperspective typically focus on more fine-grained modelling\nof variation in memory processes across specific individuals,\npossibly considering interactions with the situation (e.g.,\nways in which individuals behaviorally express when spe-\ncific video content triggers a memory in them [64]). Datasets\nfocusing on supporting an Individual-centered modelling\nperspective often contain only a relatively small number\nof distinct situations but a relatively large number of indi-\nviduals responding to them. Note that datasets facilitating\nan Individual-centered perspective can often also support\na Situation-cetered one, but not the other way around (be-"}, {"title": "4.2 Memory process", "content": "Memory-related datasets vary in their primary goal, specif-\nically the memory sub-process they aim to investigate.\nHuman memory can be divided into three sub-processes:\nmemory encoding (processing the experience), memory re-\ntention (preserving the experience), and memory retrieval\n(extracting the retained experience) [34].\nThese processes are closely intertwined with each other.\nFor example, any study of memory involves some mea-\nsure of memory retention - whether or not a memory was\npreserved and for how long. Whether a moment has been\nretained or not cannot be completely measured, since some\nmemories might have been retained but are not accessible at\nthe moment of the measure [67]. Therefore, when it comes to\nretention, researchers usually focus on investigating memo-\nries available for retrieval at the moment of a memory test.\nForgetting then refers to the moments that are not available\nat the moment of collecting the memory measure. Studies\nthat focus on the retention process usually investigate the\nforgetting curve collecting memory reports at several\npoints in time and seeing how much information will be"}, {"title": "4.3 Recorded behaviour & measures", "content": "Some datasets for memory research involve recording par-\nticipants' behaviour and/or perceptual measures (i.e. self-\nreported individual traits or questionnaires on participants'\nperception of the task and other participants). These mea-\nsures can vary from EEG brain signal recordings during the\ntask [69] to video of participants' nonverbal signals through-\nout the task (in [64]). In datasets involving conversation\nor interaction between participants, typically, there is also\na recording of the speech, in the form of audio or tran-\nscripts [65], [66]. In addition to recorded behaviour, some\ndatasets measure various self-reported perceptual measures\n[64], [65]. Since the MeMo dataset is focused on human\nbehaviour and perception in the conversational context, it\nincludes video and audio recordings for behavioural mea-\nsures and various self-reported measures of participants'"}, {"title": "4.4 Task context & memory task", "content": "An important parameter informing corpus design is the\ncontext of the task participants perform, such as solitary\nmedia consumption or human-human interaction. This con-\ntext is closely linked with the memory reporting measure.\nFor media consumption, memory is often measured with\nrecognition tasks where participants identify previously\nseen videos, indicating memory retention or forgetting [37],\n[63], [69]. Alternatively, some studies use free recall for\nautobiographical memory triggered by media [64].\nIn spontaneous conversation contexts, recognition tasks\nare impractical due to the variable content of free-flowing\nconversations. Instead, memory encoding and retention\nstudies find free-recall self-reports to be more suitable as\nthey allow participants to report memories without addi-\ntional constraints [4], [8]. For example, these have been used\nin a recent behavioural study predicting memory encoding\nusing linguistic features [8]. For conversational memory re-\ntrieval datasets, other measures have been employed: a task-\nrelated memories survey in [65] and a third-party observer\nannotation of memory retrieval moments in [66])."}, {"title": "4.5 Sample representation", "content": "Lastly, participant samples vary in size and diversity. The\nsample size depends on the task context and length, ranging\nfrom 12 to 3246 subjects. Considering demographics\nand representativeness of datasets' samples, three datasets\ndo not report participants' demographics [37], [38], [69], one\ndataset had students and university staff as participants [65]\nand one had female-only participants [66]. Only two out of\nseven memory-related datasets had a more balanced sample\n(except for the bias towards US residents) [8], [64]."}, {"title": "5 DATA COLLECTION PROCEDURE", "content": "We describe the MeMo experimental procedure shown in\nFigure 1 in this section. We highlight how these relate to our\nstated primary goals (G1 and G2 described in Section 2) and\nguiding principles (P1 to P3 described in Section 3)."}, {"title": "5.1 Overall procedure", "content": "The overall procedure of acquiring the MeMo corpus is\nshown in Figure 1. In this subsection we will guide the\nreader through the procedure step-by-step."}, {"title": "5.1.1 Ethical approval", "content": "The Human Research Ethics Committee of TU Delft ap-\nproved the MeMo corpus data collection. Before the ex-\nperiment, participants filled out an informed consent form\npermitting us to collect their personally identifiable data\nsuch as audio and video recordings to be later accessible\nto the research community under CC-by-NC license. Before\nthe recordings participants were asked to come up with a\npseudonym for themselves for the entirety of the recording.\nParticipants were allowed to avoid answering questions if\nthey did not want to and invent information about them-\nselves throughout the recording."}, {"title": "5.1.2 Conversation subjects.", "content": "Participants. Participants were recruited using Prolific Aca-\ndemic recruiting service [70]. All participants were required\nto reside in the UK, fluently speak English and be ready for\na video-call study (i.e. possessing a laptop with a working\ncamera and a headset with a microphone). The UK resi-\ndency requirement served two purposes: first, the Prolific\nplatform provided a large number of UK participants; sec-\nond, research shows memory can be influenced by shared\nexperiences [3]. With Covid-19 selected as a discussion topic,\nfocusing on UK residents helped control for differences\nin pandemic experiences, thus enhancing the validity of\nmemory comparisons between groups (\u2192 G1).\nTo simulate a situation where facilitation is needed, such\nas in the case of differing opinions and perspectives in the\ngroup, we tried to maximise the diversity in opinions on our\ntarget topic - Covid-19 pandemic (G2). We, thus, targeted\nspecific demographics differently affected by the pandemic.\nFor example, parents of young children had to suddenly\nhome-school their children or business owners faced work-\nrelated challenges having to adjust their business to chang-\ning regulations. The targeted groups were the following:\nparents with young children, older adults (50+), students,\nbusiness owners. Five prescreening surveys were conducted\non Prolific, each tailored to one of these groups (see Appendix\n3). Participants could only select one prescreening survey to\navoid duplicate inclusion. Additionally, we ensured gender\nbalance in our sample (\u2192 P1.3).\nGroup composition. The MeMo corpus is designed\naround small-group discussions, typical of both work and\ninformal settings, to ensure ecological validity (\u2192P1.1)\nand simulate potential facilitation scenarios (\u2192G2). \"Small\ngroups\" here refers to 3 to 8 participants, an optimal size for\nallowing everyone to share their thoughts [71]. Participants\ncompleted a prescreening survey specifying their availabil-\nity, and 5 to 8 participants were recruited per group, ensur-\ning representation from each demographic. The minimum\nof 5 was set to maintain at least 3 participants per group,\naccounting for no-shows and dropouts. All participants\nwere zero acquaintance, meaning they had never met be-\nfore, allowing us to study the development of within-group\nrelationships with no prior interactions [5]. The group com-"}, {"title": "5.1.3 Pre-screening survey", "content": "The prescreening questionnaire included the consent form,\nparticipants' demographics (participants' age, gender, em-\nployment status, English fluency, country of residence),\npersonality [72], values [73], technical requirements and\nonline meeting experience (see Appendix 1). Personality was\nincluded as it influences recall, with extroverts recalling\nmore positive memories than those higher in neuroticism\n[58]. Values were also included, as they can enhance recall\naccuracy for items related to personal values [59]."}, {"title": "5.1.4 Pre-session survey", "content": "Questionnaire data was collected using Qualtrics X platform\n[74] (for the full content of the questionnaires see Appendix\n1). Participants started each session by completing a pre-\nsession questionnaire that took ~15 minutes to complete.\nThe pre-session survey included the participant's mood\nassessment [75] before all sessions, as mood can affect mem-\nory encoding [56], [57]. It also included long-term memory\nretention task (see Section 5.2.4) before all the sessions except\nfor the first one. Before the exit interview, there were some\nextra questions added to the pre-session survey - partici-\npants had to report a moment they found most important"}, {"title": "5.1.5 Conversation session.", "content": "All discussion sessions happened online, through a Zoom\nvideo-call platform, a typical software used for video-calls.\nThis ensured that participants are in the comfort of their\nown homes, rather than in the lab (\u2192P1.1). They used their\nown computer and headsets, having their natural lighting,\nwhich also added to how comfortable they felt as well as the\nnaturalistic setting of video-call discussions. To ensure that\nwe can track participants' eye-gaze, the moderator asked\nparticipants to keep zoom in 'gallery' mode so that all the\nparticipants are on the screen at the same time and their lo-\ncation on the screen stays the same throughout each session.\nIn addition, for a secure recording, there was a technical\nassistant involved in the call (with no camera or microphone\non and no interaction with participants), who recorded the\nsession and resolved any arising technical issues.\nAfter making sure that all participants had completed\nthe pre-session survey, the moderator (or the technical assis-\ntant) would start the recording. The session began with head\npose and gaze calibration for automatic post-experiment\ngaze direction annotation (see Section 6.4). Participants,\nguided by the moderator, first rotated their heads and then\nlooked at each named participant on their screen.\nAfter that, guided by their moderator, participants\nstarted the discussion. To ensure a natural yet directed\nconversation (\u2192P1.2), the Covid-19 pandemic was chosen\nas a relatable topic, relevant to participants worldwide at\nthe time of data collection (the year 2021), with diverse\nexperiences and opinions. At the start of the first session,\nparticipants were informed that they would discuss the past,\npresent, and future of the pandemic over three sessions,\naiming to design a better future in case of a recurrence (the\nmemory study focus was disclosed only at the experiment's\nend to prevent priming participants' memory). Each session\nlasted 45 minutes, providing sufficient time for conversation\nto emerge. This duration aligns with typical meeting and\nfacilitation session lengths (\u2192G2, \u2192P1.1) [23].\nTo reflect real-world conversations that repeat over time\n(e.g. work meetings), the corpus included 3 sessions spread\nout over 3-4 days, reflecting the frequency of real-world fa-\ncilitation sessions, occurring once or twice a week [23]. This\nlongitudinal approach aimed to capture the evolution of\nparticipant relationships and conversational memory trends\nover time. (\u2192G1,\u2192G2). This setup also provided repeated\nmeasures of memory at different points, capturing both\nshort-term and long-term memory reports (\u2192G2)."}, {"title": "5.1.6 Post-session survey.", "content": "At the end of the Zoom session, the moderator reminded\nparticipants to open up the post-session survey link and\nstart the questionnaire. After that, the recording stopped\nand the Zoom session was closed. See the summary of\nall measures used in the post-session survey Appendix 1."}, {"title": "5.1.7 Exit interview.", "content": "3-4 days after the final conversation session, there was a\n~15-minute exit interview with each participant. Similar to\nthe conversation sessions, there was a pre-session survey\nbefore this Zoom session. The only difference was that par-\nticipants were asked what was the most important moment\nfor them in all the previous discussion sessions. They then\ndiscussed that moment with the moderator one-on-one and\nanswered a list of questions on the topic of the required\ncapabilities of a social robot supporting public discussions,\nespecially about what such a robot should remember."}, {"title": "5.2 Memory measures", "content": "A common practice in user internal state modelling is to rely\non third-party annotations of the investigated internal state.\nThis can oversimplify these states and skew model accuracy,\nneglecting the first-party perspective and potentially intro-\nducing bias. This challenge applies to memory encoding\nstudies, in which, traditionally, the free-recall reports are\ntraced back to the encoded event by third-party annotators\n[8], [54]. Here, we describe our method that mitigates these\nissues by leveraging participants' self-reports and the first-\nparty task of aligning the reports with specific segments\nof recorded interactions. This method is aimed to preserve\nvalidity and minimise bias, particularly crucial for datasets\nlike MeMo corpus aiming to accurately represent the mem-\nory content as well as the event that that memory might be\nbased on within the recorded data (\u2192P2)."}, {"title": "5.2.1 Free-recall self-reports.", "content": "To minimise the bias towards external stimuli and type\nof memory events, we have used a traditional free-recall\ntask for memory self-reports [53]. The free-recall task was"}, {"title": "5.2.2 Encoded event annotation.", "content": "Unlike in previous research [8], [54], the participants them-\nselves did the assignment of their self-reports to specific\nevents that happened within the conversation. This way,\nwe wanted to ensure that the self-reported memories were\ncorrectly assigned to the encoded event they referred to, en-\nsuring the validity and the accuracy of the resulting memory\nmeasure (P2). Within this encoded event annotation task,\nparticipants were given a link to the interaction recording\nand had to write down the start and end time (minute\nand second) of each moment they reported in the survey\nbefore (the memory self-reports were quoted back to them).\nParticipants had the freedom of scrolling through the video\nand did not have to re-watch the entire recording to avoid\nadditional fatigue. They also had an option of leaving the\ntiming blank in case they could not find it, the moment was\nrelated to an overall feeling of discussion or other kind of\nmemorable moments that cannot be connected to a particu-\nlar interval in the interaction. We ensured that the free recall\nreports cannot be modified at this stage (\u2192P2). The encoded\nevent annotation task was presented to participants at the\nvery end of the post-session questionnaire so that the other\nsurvey questions would not be affected by seeing the video\nof the interaction either."}, {"title": "5.2.3 Reasons for remembering.", "content": "In addition to free-recall reports, we asked participants\nabout the perceived reason or motivation behind their mem-\nory of each reported moment (see question formulation in\nAppendix 2). The perceived reasons for memory were aimed\nto capture information that might not have been described\nin the"}]}