{"title": "Exploring Large Language Models for Multimodal Sentiment Analysis: Challenges, Benchmarks, and Future Directions", "authors": ["Shezheng Song"], "abstract": "Multimodal Aspect-Based Sentiment Analysis (MABSA) aims to extract aspect terms and their corresponding sentiment polarities from multimodal information, including text and images. While traditional supervised learning methods have shown effectiveness in this task, the adaptability of large language models (LLMs) to MABSA remains uncertain. Recent advances in LLMs, such as Llama2, LLaVA, and ChatGPT, demonstrate strong capabilities in general tasks, yet their performance in complex and fine-grained scenarios like MABSA is underexplored. In this study, we conduct a comprehensive investigation into the suitability of LLMs for MABSA. To this end, we construct a benchmark to evaluate the performance of LLMs on MABSA tasks and compare them with state-of-the-art supervised learning methods. Our experiments reveal that, while LLMs demonstrate potential in multimodal understanding, they face significant challenges in achieving satisfactory results for MABSA, particularly in terms of accuracy and inference time. Based on these findings, we discuss the limitations of current LLMs and outline directions for future research to enhance their capabilities in multimodal sentiment analysis.", "sections": [{"title": "1 INTRODUCTION", "content": "To assess the emotional orientation in human expression, traditional sentiment analysis methods need to adapt to this multimodal scenario, which is referred to as Multimodal Aspect-Based Sentiment Analysis (MABSA). It plays an important role in several applications, such as healthcare [9] and human-computer interaction [22]. Specifically, MABSA aims to both extract aspect terms from text [27] and assign sentiment label to each of these aspect terms [8, 38]. For example, as depicted in Fig. 1, MABSA aims to extract \"Taylor Alison Swift\" and the corresponding sentiment is \"positive\" from multimodal information including text and image.\nWith the significant improvement in the performance of large language model (LLM), LLM is attracting increasing attention. Despite the good performance of LLM in general tasks, such as image captioning [24] and visual question-answering (VQA) [12, 29], it still performs limited in some complex scenarios [31], leaving more uncertainties. Recently, researchers have started to pay attention to the adaptability of LLM in complex tasks, such as multimodal entity linking [23], multimodal contextual object detection [35], and machine translation with cultural awareness [32]. However, regarding MABSA, the adaptability of LLM remains uncertain, and there is no established benchmark for comparison. Therefore, we seek to explore the suitability of LLM for MABSA, rethinking their role and necessity in this context, and introduce a basic benchmark for LLM-based methods in the MABSA task. To the best of our knowledge, we are the first to explore the use of LLM for MABSA.\nFor our exploration, we design the LLM For Sentiment Analysis (LLM4SA) framework to evaluate the suitability of large language models (LLMs) for the Multimodal Aspect-Based Sentiment Analysis (MABSA) task. The framework leverages multimodal examples for in-context learning, where text and visual features are jointly processed to extract aspect terms and their corresponding sentiments. Specifically, we select well-established LLMs, including Llama2 [26], ChatGPT [20], and LLaVA [14], as the primary models for evaluation. For image feature extraction, we adopt the Llava pipeline, using a pre-trained vision transformer (ViT) to encode visual embeddings, which are then aligned with textual features through a projector for integration into the LLM.\nIn this framework, Llama2 [26], Llava [14] and ChatGPT [20] process structured inputs comprising visual tokens and text. These inputs include aspect terms and their sentiment labels (positive, negative, or neutral), with in-context learning (ICL) examples provided from the training set to guide the model's predictions. The number of ICL examples (l) is set to 10 for Llama2 and 5 for ChatGPT, considering their respective capabilities and constraints. We evaluate performance directly on test datasets and benchmark the results against traditional supervised learning methods.\nOur results show that while LLMs demonstrate potential for multimodal understanding, they face significant challenges in addressing the fine-grained and complex requirements of MABSA. Additionally, their computational cost is significantly higher compared to SLM-based methods, which limits their practicality in real-world applications. These findings highlight the current limitations of LLMs and emphasize the need for further optimization to improve their adaptability to intricate multimodal sentiment analysis tasks."}, {"title": "2 RELATED WORK", "content": "With the gradual evolution of large-scale models, an increasing number of universal large models have been developed, which are versatile for various downstream tasks such as ChatGPT[20], Llama [25], and others [4]. These large models, by adjusting prompts, can handle tasks like text classification [13] and machine translation [16]. However, the modern landscape of social media has introduced more intricate scenarios, necessitating the integration of multimodal processing for diverse tasks. This leads to the development of more multimodal large models like Flamingo [2] and etc., designed for tasks such as Visual Question Answering (VQA) [3] and Image Captioning [7].\nAlthough multimodal large models are capable of addressing the complexity of multimodal scenarios [39, 40], they still exhibit limitations when confronted with other intricate tasks. Research [31] has indicated that Large Language Model (LLM) perform inadequately in sentiment analysis task, falling short of traditional pretrained models [6, 11, 15]. Additionally, researchers have noted the adaptation of LLM to various complex tasks. For instance, Yao et al. [33] have acknowledged that recent in-context learning utilizes lightweight prompts [10] to guide LLM for machine translation. However, it remains unclear whether this approach effectively injects cultural awareness into machine translation. To address this, a new prompt strategy and the process of constructing a culturally relevant parallel corpus have been proposed. In the context of multimodal entity linking task [1, 5], LLM has not received adequate attention and related solutions. To address this issue, Shi et al. [23] propose a generative multimodal entity linking framework based on LLM, which directly generates target entity names.\nIncreasingly, researchers are not only focused on the versatility of large models themselves but also on the specificity of tasks in complex scenarios. Consequently, they are proposing relevant solutions to meet the demands of these diverse tasks."}, {"title": "3 EXPLORATION OF LLM FOR MABSA", "content": "Large Language Models (LLMs) [31] have drawn substantial attention within the AI community due to their remarkable ability to comprehend, reason with, and generate human language. Researchers leverage the formidable capabilities of LLM as the core components to tackle a variety of multimodal tasks. Thus, for comparison and giving insight into the application of LLM on complicated downstream tasks such as MABSA, we introduce our LLM For Sentiment Analysis (LLM4SA) framework.\nAs shown in Fig. 2, our LLM4SA takes the multimodal examples for in-context learning and generates the aspect and sentiment. We employ Llama2-7b [25] as our default LLM. In addition, we employ LLaVA [14] and GPT3.5-turbo [20] for MABSA and evaluate their performance. The performance comparison of the LLM-based method and traditional method including textual and multimodal methods is shown in Table 3. For Llama and ChatGPT, performance assessments are conducted directly on the test dataset. Notably, In-context learning (ICL) examples are randomly selected from the training dataset."}, {"title": "3.1 Visual Feature", "content": "To achieve feature alignment, we initially extract image features from the pre-trained vision encoder, which are then mapped into the text embedding space using a projector. These mapped features are subsequently input into the LLM as a visual prefix. As for image features, we adopt the image processing approach from Llava [14]. To obtain visual features from an input image I corresponding to the text t, we utilize a pretrained visual model, ViT, which generates visual embeddings $Z_v \\in \\mathbb{R}^{d_v}$, where $d_v$ represents the hidden state dimension of the vision encoder. The weights of the vision encoder remain frozen.\nTo enable cross-modal alignment and fusion, we employ a projector $W^l$ to transform visual features into a soft prompt, effectively creating a visual prefix for the LLM input. In more detail, we use a linear layer to project image features, resulting in visual tokens $H_v$. Consequently, these visual tokens $H_v$ have the same dimensionality as the word embedding space in the language model. The calculation of visual tokens $H_v$ is as follows:\n$Z = ViT(I)$\n$H_v = W^l Z_v$"}, {"title": "3.2 Large Language Models", "content": "3.2.1 Llama2 and LLaVA for MABSA. We structure the visual tokens $H_v$ and text t in the following format for input into the LLM. aspect is a substring within the text t and sentiment is chosen from {positive, negative, neutral}. For example, in the text \"This is why Taylor Alison Swift is my celebrity crush. She is the most beautiful, ethereal, stunning in the whole world!\" with the corresponding image, the aspect is Taylor Alison Swift and sentiment is positive. ICLs represent A randomly selected instances from the training dataset for in-context learning, separated by the delimiter '[SEP]'. We set A to be 10. In ICLs, the content of the '[Answer]' field has already been completed based on annotations from the training dataset. In contrast, in the Query, the '[Answer]' field is missing and needs to be generated by LLM. Finally, the evaluation of model performance is based on the content of the generated '[Answer]' field of Query.\n3.2.2 ChatGPT for MABSA. We select GPT-3.5-turbo for testing. Due to the limitation of GPT, the number of In-context learning examples A is set to be 5. We utilize the completion capabilities of GPT's chat model to accomplish the task. The input text is structured as follows: \"Here is examples for MABSA: ICLs. Based on the above examples, complete the following completion tasks: Query \""}, {"title": "4 EXPERIMENT", "content": "4.1 Datasets and Evaluation Metrics\nTo evaluate the performance of the dual-encoder transformer with cross-modal alignment, two MABSA benchmark datasets are used, mainly consisting of reviews on Twitter, including text and image. These datasets are Twitter-2015 and Twitter-2017, originally provided by Zhang et al. [37] for multimodal named entity recognition and annotated with the sentiment polarity for each aspect by Lu et al. [18].\nAn aspect is regarded as correctly predicted only if the aspect term and polarity respectively match the ground-truth aspect term and corresponding polarity. Table 2 summarizes the statistical characteristics of these two datasets. Precision, recall, and micro F1-score are used as evaluation metrics for MABSA. Specifically, precision refers to the proportion of true positive predictions out of all positive predictions made by the model. In other words, precision measures how many of the model's positive predictions are accurate. Recall is the proportion of true positive predictions out of all actual positive instances. Recall represents the ability to correctly identify positive instances, showing how many positives it managed to detect. Micro F1 score is the weighted harmonic mean of precision and recall. This score provides an overall assessment of the model's performance. The F1 score considers a balance between precision and recall, offering a single measure that combines both metrics and is robust for imbalanced class data.\n4.2 Implement Details\nIn the selection of large-scale models, we chose Llama2 and LLaVA with 7B parameters and GPT3.5-turbo as the test models. For all experiments, the weights of DeBERTa and ViT are respectively initialized from pretrained DeBERTa-base and Vit-base-patch16-224-in21k. The hidden size d is 768, the number of heads in cross-modal self-attention is 8, patch size P is 14, MLP size is 3,072 and the number of attention heads is 12. Besides, AdamW optimizer [17] with a base learning rate of 2e-5 and warmup decay of 0.1 is used to update all trainable parameters. The maximum length and batch size are respectively set to 60 and 8. For training epochs, we leveraged an early stopping strategy with a patience of 3 to avoid overfitting. The Pytorch version used in all experiments in this article is 1.10. All experiments are conducted on RTX3090.\n4.3 Baselines\nTo conduct a thorough comparison, we select multiple representative advanced methods based on SLM and LLM."}, {"title": "4.4 Result and Discussion", "content": "We wonder whether LLMs can outperform supervised SLMs in MABSA task purely through in-context learning. To this end, we select two methods based on pre-trained model for comparison on two datsets [36], including the text-based RoBERTa method [15] and the multimodal DTCA method [34]. The performance of the DTCA is a result of our replication. As illustrated in Table 3, from the experimental results, it is evident that LLM-based methods still exhibit a performance gap compared to traditional methods. We dive deep into the above results and analyze why LLMs fail to achieve satisfactory performance:\nInsufficient familiarity with downstream task specifics. As stated in Ma et al. [19], MABSA task is scarce in the widely-used instruction tuning datasets like Wei et al. [30] and Wang et al. [28]. Therefore it is likely that instruction-tuned LLMs are not well-acquainted with such MABSA task formats. However, MABSA is an intricate task in sentiment judgment. Without sufficient understanding of MABSA, LLM would find it challenging to accomplish this. Accomplishing the MABSA task necessitates initially determining the number of aspect-sentiment pairs within a sentence, followed by identifying the aspects within the sentence and subsequently recognizing the corresponding sentiment. Achieving a correct prediction requires successful completion of these three subtasks, which bring a significant burden on the LLM.\nLimited number and effectiveness of samples. Due to limitations in LLM's reasoning speed and model size, the quantity of ICL (In-context Learning) will not be set excessively high. Within this limited number of ICL samples, the learning of LLM relies on the effectiveness of the sampled content. In cases where the samples are not sufficiently representative, the LLM may fail to acquire valuable information relevant to the MABSA task. Meanwhile, SLMs can continually learn from more samples through supervised learning, widening the performance gap as annotated samples increase.\nHigh time cost As shown in Table 3, LLMs operate considerably slower than SLMs due to their increased parameters, extended input contexts, and additional response decay (if external APIs are utilized)"}, {"title": "5 CONCLUSION", "content": "This paper investigates the suitability of large language models (LLMs) for the Multimodal Aspect-Based Sentiment Analysis task, comparing them with supervised learning methods (SLMs) on two public datasets. Our findings reveal that LLMs, despite their strong capabilities in general multimodal tasks, face significant challenges in addressing the complex and fine-grained requirements of MABSA. Specifically, LLMs exhibit limitations in three key areas: insufficient familiarity with downstream task specifics, restricted learning from in-context examples due to sample representativeness and quantity constraints, and high computational time costs compared to SLMs. These results highlight the current performance gap between LLM-based methods and traditional supervised methods in MABSA. While LLMs show potential for multimodal understanding, their effectiveness in tasks requiring intricate reasoning, such as MABSA, remains limited. Future research should focus on improving task-specific instruction tuning, enhancing sample effectiveness for in-context learning, and optimizing computational efficiency to better adapt LLMs for fine-grained multimodal sentiment analysis."}]}