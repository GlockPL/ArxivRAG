{"title": "SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for\nTraffic Accident Prediction", "authors": ["Xiaowei Gao", "James Haworth", "Ilya Ilyankou", "Xianghui Zhang", "Tao Cheng", "Stephen Law", "Huanfa Chen"], "abstract": "Predicting traffic accidents is the key to sustainable city management, which requires effective\naddress of the dynamic and complex spatiotemporal characteristics of cities. Current data-driven\nmodels often struggle with data sparsity and typically overlook the integration of diverse urban data\nsources and the high-order dependencies within them. Additionally, they frequently rely on predefined\ntopologies or weights, limiting their adaptability in spatiotemporal predictions. To address these issues,\nwe introduce the Spatiotemporal Multiview Adaptive HyperGraph Learning (SMA-Hyper) model, a\ndynamic deep learning framework designed for traffic accident prediction. Building on previous re-\nsearch, this innovative model incorporates dual adaptive spatiotemporal graph learning mechanisms\nthat enable high-order cross-regional learning through hypergraphs and dynamic adaptation to evolv-\ning urban data. It also utilises contrastive learning to enhance global and local data representations\nin sparse datasets and employs an advance attention mechanism to fuse multiple views of accident\ndata and urban functional features, thereby enriching the contextual understanding of risk factors.\nExtensive testing on the London traffic accident dataset demonstrates that the SMA-Hyper model\nsignificantly outperforms baseline models across various temporal horizons and multistep outputs, af-\nfirming the effectiveness of its multiview fusion and adaptive learning strategies. The interpretability\nof the results further underscores its potential to improve urban traffic management and safety by\nleveraging complex spatiotemporal urban data, offering a scalable framework adaptable to diverse\nurban environments.", "sections": [{"title": "1. Introduction", "content": "Urban traffic management is increasingly challenged by the rapid growth in vehicle numbers and\nthe expansion of road networks, driven by urban economic development and changes in transportation\nsystems. This surge in traffic activity increases the risk of exposure to road accidents, which remain\na major public health concern. According to the latest report by the World Health Organisation\n(WHO), road traffic accidents result in approximately 1.19 million deaths annually worldwide, dispro-\nportionately affecting vulnerable road users (WHO, 2023). Furthermore, data from the Department\nfor Transport in the UK reveal that despite reduced mobility during the COVID-19 pandemic, the\npattern of road injuries from 2018 to 2022 has shown little variation, with such injuries costing nearly\n1.5% of the annual GDP (DfT, 2023). These accidents not only compromise public safety but also af-\nfect the sustainability and efficiency of urban environments and transportation systems, underscoring\nthe critical need for improved predictive methodologies to prevent such incidents (UNECE, 2019).\nThe increasing complexity of urban traffic management requires the development of precise models\nfor predicting traffic accidents, crucial for implementing proactive measures that improve both safety\nand efficiency. Traditionally, accident prediction has predominantly employed time series methods\nsuch as Autoregressive Integrated Moving Average (ARIMA) (Ihueze and Onwurah, 2018), Gated\nRecurrent Unit (GRU) (Zhang et al., 2020), and Long Short-Term Memory (LSTM) networks (Ren\net al., 2018; Yuan et al., 2018). Although effective in capturing temporal dynamics, these approaches\noften overlook significant geographical factors, thus restricting their ability to fully comprehend the\nintricacies required for accurate predictions. Recent advancements have shifted focus towards integrat-\ning spatial relationships, with Graph Neural Networks (GNNs) proving particularly effective in urban\nsettings. Urban environments, with their complex interconnected layouts, are naturally represented\nas graphs, where nodes signify geographic locations, and edges represent spatial relationships between\nthem. This allows Graph Convolutional Networks (GCNs) (Trirat et al., 2023) and spatiotemporal\ngraph neural networks (ST-GNNs) (Zhou et al., 2020a; Karim et al., 2022; Rahmani et al., 2023) to\nmodel intricate spatial relations essential for understanding traffic dynamics. ST-GNNs, renowned for\ntheir ability to uncover nonlinear spatiotemporal relationships, significantly improve the understand-\ning of multiviews contributing to traffic accidents. Their ability to incorporate heterogeneous urban\ndata dimensions further facilitates big data-driven modelling solutions (Zhang and Cheng, 2020).\nDespite these technological advances, the common issue in the prediction of traffic accidents is\nthe sparsity in both spatial and temporal dimensions, with incidents that occur nonperiodically in a\nfew locations at particular times. Advanced data enhancement strategies, such as Prior Knowledge-\nbased Data Enhancement (PKDE) proposed by Zhou et al. (2020b), have proven to be a promising\ndirection in enriching the data discrimination to better meet the model requirements for effective local\nneighbourhood information aggregation. Furthermore, the adoption of graph attention techniques uses\nattention scores to refine node aggregation processes, improving the detection of relationships among\nlocalised similar nodes (Zhou et al., 2020a; Yu et al., 2021). Nevertheless, despite the well-addressed\nsparsity, there are still several unresolved challenges in traffic accident prediction that necessitate\nfurther research to enhance the effectiveness of predictive models for urban traffic management:\n\u2022 Inadequacy of Conventional Pairwise Relations: Traditional graph models in urban ana-\nlytics primarily focus on pairwise interactions, limiting analyses to localised relationships between\npairs of nodes. Geographic correlations from points of interest (POIs), as shown in Figure 1a,"}, {"title": "2. Literature Review", "content": "Early efforts in traffic accident prediction used mainly statistical models or traditional machine\nlearning techniques, which often struggled with the complexity and heterogeneity of large datasets\nand overlooked crucial spatiotemporal correlations (Ali et al., 2024). With the advent of advanced\nartificial intelligence technologies, a shift toward deep learning methods has occurred, leveraging their\ncapacity to unravel complex non-linear spatiotemporal relationships within traffic accident data.\nRecurrent Neural Networks (RNNs), especially Long Short-Term Memory (LSTM) networks, have\nbeen widely adopted for their efficacy in capturing temporal dynamics. In contrast, convolutional\nneural networks (CNNs) have been applied to spatial analysis. For instance, Ren et al. (2018) pioneered\nthe use of LSTM to analyse temporal sequences of traffic accidents, but limited their spatial analysis to\nbasic fully connected layers. Addressing this shortfall, Yuan et al. (2018) introduced the Heterogeneous\nConvolutional LSTM (Heter-ConvLSTM), integrating various urban and external characteristics to\nbetter delineate accident risks, albeit within constrained scenarios like their Iowa case study. Further\ndevelopments led to Moosavi et al. (2019) integrating LSTM with a latent training representation of\nPOI data and historical traffic event descriptions to capture spatial heterogeneities more effectively.\nNajjar et al. (2017) were pioneers in using CNNs to process spatial data derived from satellite imagery\nto pinpoint accident locations, though their model lacked temporal integration.\nDespite the progress, traditional CNNs and RNNs have limitations in capturing extensive spa-\ntiotemporal interactions, often restricting their effectiveness to local information learning without\nbroader contextual understanding (Cui et al., 2024). Graph Neural Networks (GNNs) have subse-\nquently emerged as a robust solution, adept at encapsulating both localised and expansive spatiotem-\nporal dependencies through the inherent connectivity of urban frameworks. This comprehensive ap-\nproach enhances the understanding of traffic patterns and facilitates detailed city-wide predictions.\nFor instance, Zhou et al. (2020a) utilised a Differential Time-varying Graph Neural Network (DTGN),\ncomplemented by a knowledge-based data enhancement strategy, to address zero-inflated data issues.\nThey, along with Zhou et al. (2020b) and Wang et al. (2021), implemented multigranularity risk\nprediction models that define regions with varying grid sizes, proposing to simultaneously predict at\ndifferent scales. However, this approach has raised feasibility concerns due to the complexity of man-\naging predictions across multiple spatial resolutions effectively. Moreover, recent studies like those by\nTrirat et al. (2023) and Yu et al. (2021) have opted for single-grid size approaches. Yu et al. (2021) em-\nployed spatial convolution layers combined with temporal convolution layers to achieve sophisticated\nspatiotemporal representations, whereas Trirat et al. (2023) leveraged a multiview fusion mechanism\nwith attention mechanisms and a Transformer to learn temporal dependencies. Each approach high-\nlights distinct advantages and challenges in capturing urban dynamics but indicates that relying on a\nsingle grid size may offer more consistency in model performance across various urban configurations.\nHowever, all current GNN models are based on predefined matrices and manually selected grids,\nwhich is limited in adapting to the evolving urban environment and accurately predict traffic accidents\nin different contexts."}, {"title": "2.2. HyperGraph Learning Methods in Urban Prediction", "content": "Traditional graph-based models often rely on localised pairwise interactions between nodes, which\ncan restrict the scope of information propagation and fail to capture complex multi-node relationships"}, {"title": "3. Methodology", "content": "Under this graph structure, the signals of nodes are transmitted through\nedges toward another node. As shown in Figure 2a, an undirected graph G(V,E) represents\nthe spatial connectivity between urban regions, with the city divided into N subregions. Here,\nV\u2208 RN denotes the set of vertices, each corresponding to a subregion, and E \u2208 RN\u00d7N represents\nthe set of edges, indicating connections between pairs of subregions. The adjacency matrix\nA\u2208 RN\u00d7N characterises the spatial relationships between subregions, defined as Ai,j=1 if\nsubregions i and j are connected, and Ai,j = 0 otherwise."}, {"title": "Under this graph structure, the signals of nodes are propagated\nwithin hyperedges toward a cluster of nodes.", "content": "As shown in Figure 2b, a hypergraph is defined\nas G(V, E, W), where V \u2208 RN represents the nodes (subregions), \u00ca \u2208 RN\u00d7I denotes the set of\nhyperedges capable of linking multiple nodes simultaneously, and W corresponds to the weights\nof these hyperedges. A hyperedge captures higher-order spatial dependencies, allowing advanced\nrepresentations for the global relationships through hypergraph information propagations among\neach region and corresponding hyperedges."}, {"title": "Adaptive Graph Matrix", "content": "We use a learnable adaptive affinity matrix to represent various non-\nEuclidean relationships between subregions, offering topological structures for the propagation of\nnode features. The matrix As \u2208 RN\u00d7N describes the adaptive graph for pairwise-based graph\nconstruction, while Hs \u2208 RN\u00d7I represents the adaptive hypergraph for setwise-based graph\nconstruction. In this context, I denotes the number of hyperedges."}, {"title": "Traffic Accident Risk Score", "content": "The accident records are geo-located and time-stamped data with\nidentification of severity. The risk score of traffic accidents combines the severity of heterogeneous\nlevels of accidents within a specific time interval t in individual subregions n as Yn,t = \u03a3i=1 3 fnt,\nwhere fit denotes the frequency of accidents at severity level i in subregion n during time\ninterval t. The weight of severity levels ranges from 1 (slight injuries) to 3 (death), integrating the\nimpacts of varying accident severities to provide a comprehensive risk profile for the subregion."}, {"title": "Urban Features", "content": "The set of urban features is represented by two views: points of interest (POI)\nand road statistical information. The POI distribution includes the density of different types\nof POI categories, while road information encompasses specifics such as road type, average\nwidth, and infrastructure details. These features are represented as XP \u2208 RN\u00d7dp (POI) and\nXR \u2208 RN\u00d7dR (Road), respectively, in which dp and dr are the dimension of the corresponding\nfeature embeddings."}, {"title": "External Features", "content": "External features refer to the influences other than the urban geographical\nenvironment that affect accidents. These factors mainly include meteorology and calendar in-\nformation. Meteorology features include temperature, snow depth, and visibility, while calendar\ninformation covers holidays, peak travel times, and days of the week. These features are repre-\nsented as XM \u2208 RN\u00d7T\u00d7dm (Meteorology) and XC \u2208 RN\u00d7T\u00d7dc (Calendar), where dm and dc\nindicate the dimension of feature embedding, respectively."}, {"title": "3.2. Problem Definition", "content": "Given the adaptive graph and also the adaptive hypergraph G\u2208 (G,\u011c) of the city, the input is\nthe historical accident risk series Xt for t = 1,2,...,T, the output is to predict the accident risk\nscore, resulting from yn,t, for each subregion in the next time intervals T. Formally, the problem can\nbe formulated as finding a function Pe(\u00b7) such that:\nPe([Xt; G]) = [Yt+1,..., Yt+T]\n(1)\nwhere Pe() : RN\u00d7T \u2192 RN\u00d77 is the target function mapping from spatiotemporal features of the past\nT steps to the predicted accident risk in the next steps. O represents the learnable parameters and\nYt \u2208 RN is the accident risk score metrics for all nodes in the time step t."}, {"title": "3.3. Tackling Sparse Accident Data", "content": "A significant challenge in the prediction of fine-grained traffic accidents is zero inflation. To\naddress this, we use the PKDE method to augment zero-value data, which was proposed by Zhou\net al. (2020b,a). This approach adjusts zero-value elements based on statistical accident information\nacross different subregions, incorporating prior knowledge by assigning negative lower risk scores to\nnonaccident instances and positive higher scores to accident instances to improve the model's ability\nto discriminate accident risk levels. Specifically, we replace the risk of zero value for the subregion\ni in each time interval with the negative statistical intensity of the accident \u03c0\u03af: \u03c0i= b\u2081 log2 \u20aci + b2.\nHere, i represents the statistical accident indicator that quantifies the accident risk of subregion i.\nThe coefficients b\u2081 and b2 ensure that the range of \u03c0i reflects the situation of actual risk levels.\nThe zero value elements are therefore adjusted based on the proportion of the total risk level of\nthe subregion and assigned to the range [-1,0] through the logarithmic and linear transformations\ndescribed above. Nonzero values are normalised to the interval [0, 1], thereby preserving the rank of\nactual accident risks. It enhances the distinction between positive and negative samples by making\nthe accident intensity value negative and distinct."}, {"title": "3.4. Spatiotemporal Multiview Adaptive HyperGraph Learning Framework", "content": "In this section, we describe the details of the proposed SMA-Hyper model, an adaptive framework\nfor predicting traffic accidents, as illustrated in Figure 3, it is primarily composed of four main modules:\n1) Multiview adaptive graph and hypergraph construction: Graphs and hypergraphs are con-\nstructed based on spatial relationships, urban features, and accident sequences, capturing low-order\nand high-order relationships between subregions, respectively. 2) Multiview spatiotemporal feature\nencoder: In the multiview context, the propagation of accident characteristics between pairwise edges\nand setwise hyperedges captures the complex spatiotemporal correlations of accident occurrences.\n3) Temporal decoder: Integrating external characteristics, the spatiotemporal embedding vectors of\neach subregion are decoded through gated convolutions to generate predictions for future accident\nsequences. 4) Local-global contrastive learning: The contrastive learning between multiview graphs\nand hypergraphs offers additional self-supervisory signals to the model, mitigating the negative impact\nof data sparsity on model learning.\nDetailed information and calculation processes are outlined below."}, {"title": "3.4.1. Multiview AdaptiveGraph and Hypergraph Learning", "content": "Multiview Graph Embedding Traditional ST-GNN models often rely on predefined topologies\nbased on spatial connections or interaction weights. This approach lacks comprehensive geographic\nrelationships and depends on a single criterion, which limits its ability to generalize across scenarios\ninvolving both static and dynamic urban features (Wang et al., 2024; Xiong et al., 2023). Additionally,\ndefining these criteria requires specific spatial knowledge, which is not always available or easily\ngeneralizable, especially when multiple types of views are considered. Inspired by Tobler's first law\nand the third law of geography, which suggest that closer spatial distances lead to similar target labels\nand that long-distance spatial interactions can occur with similar urban configurations, we propose\nadaptive conventional graph structure definitions to incorporate evolving configurations from multiple\nviews rather than relying on a single criterion.\nTo be specific, for static urban features including POI and the complexity of the road network, we\nemploy fully connected layers to achieve characteristic mapping and denote them as Us, s \u2208 {P, R}.\nMeanwhile, the similarity of historical accident sequences can also provide effective information for\nuncovering correlations between different sub-regions. Due to the dynamic nature of the sequences,\nwe utilise a combination of stacked convolutional layers and fully connected layers to generate its\nembedding(Zhang et al., 2022), and denote it as UT.\nAfter embedding, the non-Euclidean spatiotemporal correlations between sub-regions are mapped\nthrough multiple views: accident spatial view, accident temporal view, POI view and road view, with\neach view is constructed by the pairwise graph As and the setwise hypergraph Hs, where s denotes\ndifferent views."}, {"title": "Pairwise Graph Construction", "content": "Accident spatial view reflects the impact of spatial proximity\non accident prediction. According to Tobler's First Law of Geography, two adjacent regions tend\nto exhibit a closer spatiotemporal correlation. Therefore, we utilize the adjacency matrix A as the\ntopology for this view and denote it as AS.\nFor the construction of the remaining three views based on adaptive manner, the extracted features\nmentioned above are used to establish connections between sub-regions based on the geography's third\nlaw (Zhu et al., 2018). For instance, two sub-regions with similar POI distribution or historical accident\nsequences may share similar accident patterns. Hence, the product of features is applied to measure\nthe similarity, after which the activation function Tanh(\u00b7) and Relu(\u00b7) are used to scale the values to\n[-1,1] and eliminate unwarranted negative values:\nAs = Relu(Tanh(UUsT)),\n(2)\nwhere s here represents the accident temporal view, POI view and road view, respectively.\nFor each sub-region, aggregating information from thousands of other sub-regions may introduce\na significant amount of noise, thereby reducing predictive performance. Therefore, we set a threshold\nk for the maximum number of edges related to each sub-region to control the sparsity of graph.\nSpecifically, we first sort the values in each row of matrix As and retain only the top k values:\nindices\u2081 = topk(A[i, :]), i = 1, 2, ..., N\n(3)\nA\u00b3[i, :] = A[i, indicesi], i = 1, 2, ..., N\n(4)"}, {"title": "Setwise Hypergraph Construction", "content": "The same functional distributions may exert similar ef-\nfects on the accident patterns across multiple sub-regions. Traditional graphs can only model pairwise\nrelationships between two entities, which results in their limitations, and it is extremely difficult\nto integrate distant information through stacked multi-layer signal transmission. Therefore, we em-\nploy hypergraphs to model the high-order relationships among cross-regional nodes from multi-views,\nwhich may exhibit similar accident patterns, POI distributions, or road characteristics. Consequently,\nwe adopt an adaptive hypergraph construction approach to automatically mine learnable high-order\nsimilarities.\nDifferent from the adaptive pairwise graph, the adaptive setwise hypergraph is represented by\nan incidence matrix Hs \u2208 RN\u00d7I, where I denotes the number of hyperedges. Each hyperedge\nis capable of simultaneously connecting multiple sub-regions, thereby capturing global higher-order\ndependencies. We derive Hs by multiplying a feature matrix K\u00ba \u2208 Rds\u00d7I, where ds is the embedding\ndimensions of embedding set s. Furthermore, we utilize Tanh(\u00b7) and Relu(\u00b7) to confine the values\nof the correlation matrix within a reasonable range. Similarly, we control the sparsity of hyperedges\nthrough the parameter k:\nH\u00b3 = Relu(Tanh(UK)),\n(5)\nindicesi = topk(H*[i, :]), i = 1, 2, ..., N\n(6)\nH\u00b3[i, :] = H[i, indicesi], i = 1, 2, ..., N\n(7)\nwhere s here also represents the accident temporal view, POI view and road view, respectively.\nIt is noteworthy that in accident spatial view, we employ a learnable matrix Us to represent the\npositional embeddings of subregions, with the expectation that the constructed adaptive hypergraph\nwill uncover higher-order positional relationships.\nHS = Relu(Tanh(USKS)),\n(8)\nTherefore, we can obtain the corresponding setwise adaptive hypergraphs under the four views,\nwhich are represented as follows: HS (accident spatial view), HT (accident temporal view), HP\n(POI view), HR (road view)."}, {"title": "3.4.2. Multi-View Spatio-temporal Features Encoder", "content": "The extraction of complex spatiotemporal features based on learned multi-view graphs and hy-\npergraghs presents the next challenge. Graph Convolutional Network (GCN) is a technique widely\nemployed in the field of spatiotemporal data mining, which facilitates the learning of spatial depen-\ndencies by aggregating signals from adjacent nodes. In contrast, Heterogeneous Graph Convolutional\nNetwork (HGCN) operates based on high-order relationships within hypergraphs, contributing to\nthe generation of a more robust spatial representation. In this context, we propose the multi-view\nspatio-temporal features encoder illustrated in Figure 3 (b), which encompasses both graph-based and"}, {"title": "Gated Temporal Convolution Block", "content": "The prediction of accident risks is inherently a time\nseries forecasting problem. hence, we extract temporal features of accident sequences through a\ndedicated temporal learning block, names GTC (Gated Temporal Convolution) block. Specifically, the\ntemporal learning block consists of two stacked temporal convolution modules, each of which models\nthe contextual information of the sequence via a gating mechanism to enhance the expressiveness.\nThe equation for each temporal convolution module is as follows:\ngt(Ein) = sigmoid(W1Ein + b1)\n(9)\nEout = (1 - gT(Ein)) \u00b7 Ein + gt(Ein) \u00b7 (W2Ein + b2)\n(10)\nwhere Eout represents the output of the time learning block in layer 1. gt(\u00b7) denotes the gating\nunit, which facilitates the fusion of residual connections and learned features. Lastly, W1, W2 and\nb1, b2 are the learnable parameters of the convolutional layers."}, {"title": "Graph Convolution Block", "content": "Extensive research in the past has demonstrated that Graph Convo-\nlutional Network (GCN) possesses remarkable capabilities in learning and aggregating spatial relation-\nships. Based on the constructed multi-view topology, stacked graph convolutional blocks are capable\nof capturing spatial relationships ranging from one-hop to multi-hops. The spatial convolution block\nis defined as follows:\nEout = ReLU(AS Ein W3),\n(11)\nwhere As is the normalized adjacency matrix in view s, and Eout is the hidden representation\nobtained therefrom. W3 represents the weights of the corresponding convolutional kernels. It is worth\nnoting that graph convolution block generates corresponding representations under the topology of 4\nviews respectively. Consequently, we can derive multi-view representations: E, s \u2208 {S,T, P, R}."}, {"title": "Hypergraph Convolution Block", "content": "In previous works, the higher-order relationships between sub-\nregions have been overlooked. Hypergraph convolution can uncover the high-order spatial relationships\nbetween sub-regions, thereby achieving more advanced representations. Unlike graph convolution,\nhypergraph convolution calculates based on the incidence matrix and can be expressed as:\nEout = ReLU(DR-1/2 HST DE-1/2 ReLU(D\u00b0\u22121/2 Hs D\u00b0R-1/2 Ein W4))\n(12)\nwhere DR and De denote diagonal degree matrices of H\u00ba,s \u2208 {S,T, P, R}. WH denotes the\nweights of the hypergraph convolution. Similarly, based on the incidence matrix Hs constructed\nunder 4 views mentioned above, we can obtain the corresponding hypergraph representations \u00ca\u00ba, s \u2208\n{S,T, P, R}."}, {"title": "Attention-based Multi-View Features Fusion Block", "content": "For different accident sequence pat-\nterns, it is necessary to pay closer attention to specific views, where the multi-head attention mech-\nanism can assist in capturing the complex relationships among them. For adaptive pairwise graphs"}, {"title": "and adaptive setwise hypergraphs, we utilize the Transformer module to fuse the spatial-temporal\nrepresentations of 4 views, respectively", "content": "Eout = Transformer (Ein, Ein, Ein, ER)\n(13)\nR\nEout = Transformer (En, Ein, Em, Em),\n(14)\nin\nwhere Eout and Eout denote the multi-view fused spatial-temporal representions based on graphs\nand hypergraphs, respectively."}, {"title": "Attention-based Multi-Layer Features Fusion Block", "content": "The accident features are processed\nsequentially through the gated temporal convolution block, the multi-view graph and hypergraph\nconvolution block, and another gated temporal convolution block, resulting in the outputs of each\nlayer. The outputs of different layers encapsulate spatio-temporal features of varying levels. The\nhigher-level outputs aggregate multi-step spatiotemporal information through the propagation and\nconvergence of stacked signals. Traditional methods based on average pooling assign the same weight\nto each layer, which may limit the expressiveness of the fused representations. Therefore, in the face\nof multi-layer spatial-temporal features E\u00b9,l = 1, 2, ..., L and \u00ca,l = 1, 2, ..., L, we employ an attention\nmodule to capture the relationships among the different layers:\nEencoder = Transformer(E+, E, ..., E\u0142),\n(15)\nEencoder = Transformer(\u00ca\u00a6, \u00ca\u00ee, ..., \u00ca\u00a6),\n(16)\nHere, we can get the graph-based and hypergraph-based encoder outputs: Eencoder and Eencoder"}, {"title": "3.4.3. Temporal Decoder Incorporating External Features", "content": "Dynamic external features encompass weather and calendar information. Extremes in weather\nconditions, such as rain and snow, may result in a further increase in accident risk. Similarly, during\nspecific time periods within a week, heavier traffic congestion may also increase the risk of accidents\nHence, when decoding, dynamic external features should be incorporated as part of the input and\nfused with encoder outputs, and we can obtain the decoder outputs as follows:\nEdecoder = GTC([Fencoder, WM XM, WCXC]),\n(17)\nwhere GTC(\u00b7) indicates the gated temporal convolution block. [] refers to the concatenation\noption, in which XM, XC are matrices of external features, and WM, WC are learnable parameters of\nexternal features embedding. Following this, we can obtain the decoder outputs Edecoder and Edecoder,\nrespectively, based on the outputs of the graph encoder and hypergraph encoder.\nFinally, incorporating urban features including POI and road statistical information is crucial for\nprediction as well. For instance, certain specific POIs such as supermarkets and hospitals, due to their\nsurroundings with higher traffic density, may lead to a higher level of accident risk. Therefore, the\nlast prediction layer can be modeled as:\nY = FC(ReLU(FC([Edecoder, WP XP, WRXR])))\n(18)"}, {"title": "3.4.4. Local-Global Contrastive Learning", "content": "The local spatio-temporal encoder based on pairwise graph is capable of aggregating local infor-\nmation from multiple hops through multi-layer graph convolutions, while the global spatio-temporal\nencoder based on setwise hypergraph can facilitate higher-order cross-region information learning. To\nfacilitate the alignment and integration of the information of local and global encoders, we employ\ncross-view contrastive learning. It promotes the collaborative supervision between the local and global\nencoders through self-supervised learning, thereby providing additional supervisory signals and miti-\ngating the impact of data sparsity. Moreover, the resultant more robust spatio-temporal embeddings\ncan reduce the influence of input noise.\nSpecifically, in our cross-view contrastive learning module, embeddings based on pairwise graphs\nand embeddings based on setwise hypergraphs from the same view and the same sub-region are treated\nas positive samples, while those from different views or sub-regions are considered negative samples.\nConsequently, the loss function can be formulated as follows:\nLN\nL(C) = \u03a3\u03a3\u03a3 log\nexp(cos(Ens, En\u00b3))\n\u03a3\u03b7' exp(cos(Ens, E))\n(19)\nS l=1 n=1\nIn which s \u2208 {S,T, P, R} represents spatial accident view, temporal accident view, POI view and\nRoad view, respectively, and L is a hyperparameter that denotes the number of stacked layers of\nmulti-View spatio-temporal features encoder."}, {"title": "3.4.5. Model Optimisation", "content": "In the model optimisation process, we employ the Mean Squared Error (MSE) function to gauge\nthe accuracy of the prediction results. Incorporating the aforementioned contrastive learning loss, the\nultimate joint loss function obtained is as follows:\n2\nL = \u2211(Y \u2212 \u0176)\u00b2 + 11L(C) + 12||O||2\n(20)\nwhere Yt and Yt represent the actual and predicted accident risk scores, respectively. O denotes the\nlearnable parameters, and a regularisation loss based on the L2 norm is applied to prevent overfitting.\nLastly, A\u2081 and A2 are hyperparameters, representing the weights for contrastive learning loss and the\nregularisation loss, respectively."}, {"title": "4. Experiments", "content": "The proposed SMA-Hyper model was evaluated using London traffic accident data from the\nSTATS19 dataset\u00b9, officially published by the Department of Transport, UK. This dataset is collected\nfrom police reports, so incidents without injuries are not included. The dataset provides detailed in-\nformation about the vehicles and casualties involved, as well as the geographical location and time of\neach incident. The data were pre-processed and formatted using the R package 'stats19' by Lovelace\net al. (2017).\nFor this study, we used a total of 23,096 accidents in London from 1 January to 31 December\n2021. The breakdown of accident severity is as follows: slight accidents account for 19,624 incidents\n(84.97%), serious accidents for 3,399 incidents (14.72%), and fatal accidents for 73 incidents (0.31%).\nFor the spatial unit, we used Middle Super Output Areas (MSOAs), which are official census\nunits with an average area of 19 square kilometers. Unlike manually divided grids, MSOAs offer\nseveral advantages for deep learning embeddings: (1) Consistency with Demographic Data: MSOAS\nare designed to be consistent with demographic data, providing a robust framework for integrating\nsocio-economic variables into the model. This improves the model's ability to learn complex exposure\npatterns related to traffic accidents. (2) Population homogeneity: MSOAs contain populations that\nare relatively homogeneous in terms of socio-economic characteristics. This helps reduce variability\nwithin each unit, making the model's learning process more effective. (3) Administrative Relevance:\nUsing MSOAS aligns the model with administrative boundaries, which is beneficial for policy-making\nand urban planning. Local authorities can directly use predictions made by the model for targeted\ninterventions. (4) Geographic accuracy: MSOAs provide more accurate geographical representations\ncompared to grid-based divisions. They account for natural and built environment features, which are\ncrucial for accurately capturing the spatial dynamics of traffic accidents.\nTherefore, we spatially joined the traffic accident data points to a total of 1,002 MSOAs, with\ntemporal prediction resolutions of 24 hours and 12 hours, respectively. Figure 4a shows the spatial\ndensity of traffic accidents in each MSOA for 2021. It demonstrates the spatial inequality in accident\nrisk across all regions, and the non-grid spatial shapes provide a density measurement based on socio-\ndemographic and size exposure effects. Figure 4b illustrates the daily count of traffic accidents in\nLondon throughout 2021, along with a 7-day moving average to smooth the trend and highlight\npatterns over time.\nFor multiview urban configuration, we used POI data and road network data from Ordnance\nSurvey through the Digimap platform\u00b2. Meteorological data was obtained from the MIDAS platform\u00b3,\nproviding hourly weather information. Calendar information was automatically generated using the\nPython package 'holidays'4."}, {"title": "4.2. Baselines", "content": "For a comprehensive comparison, we choose four major types of model with in total 9 models as\nthe baselines and SOTA models. The details are listed below."}, {"title": "Traditional Models", "content": "ARIMA (Box et al., 1976): The Autoregressive Integrated Moving Average (ARIMA)\nis a classical model used for time series prediction. It predicts future accidents based on\nthe average of historical accident risk as well as autoregressive patterns.\nSVR (Drucker et al., 1996): Support Vector Regression (SVR) is a variant of Sup-\nport Vector Machine (SVM) designed for regression tasks. It predicts future sequences by\ntraining an optimal regression curve and allows accident data points to deviate from the\nregression curve to enhance generalisation capabilities."}, {"title": "Spatial/Temporal Deep Learning Models", "content": "Hetero-Convlstm (Yuan et al.", "2018)": "The Convolutional Long Short-Term Mem-\nory (Hetero-ConvLSTM) network is the first model to address the spatial heterogeneity\nchallenge in the large amount of accident data", "2014)": "The Gated Recurrent Unit (GRU) is a variant of RNNs with\nfewer parameters and a simpler structure compared to the traditional LSTM. It uses two\ngates", "2016)": "The Graph Convolutional Network (GCN) is a clas-\nsical spatial learning model capable of aggregating feature information from surrounding\nlocations"}]}