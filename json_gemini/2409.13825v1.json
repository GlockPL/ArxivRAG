{"title": "A Personalised 3D+t Mesh Generative Model for Unveiling Normal Heart Dynamics", "authors": ["Mengyun Qiao", "Kathryn A McGurk", "Shuo Wang", "Paul M. Matthews", "Declan P O'Regan", "Wenjia Bai"], "abstract": "Understanding the structure and motion of the heart is crucial for diagnosing and managing cardiovascular diseases, the leading cause of global death. There is wide variation in cardiac shape and motion patterns, that are influenced by demographic, anthropometric and disease factors. Unravelling the normal patterns of shape and motion, as well as understanding how each individual deviates from the norm, would facilitate accurate diagnosis and personalised treatment strategies. To this end, we developed a novel conditional generative model, MeshHeart, to learn the distribution of cardiac shape and motion patterns. MeshHeart is capable of generating 3D+t cardiac mesh sequences, taking into account clinical factors such as age, sex, weight and height. To model the high-dimensional and complex spatio-temporal mesh data, MeshHeart employs a geometric encoder to represent cardiac meshes in a latent space, followed by a temporal Transformer to model the motion dynamics of latent representations. Based on MeshHeart, we investigate the latent space of 3D+t cardiac mesh sequences and propose a novel distance metric termed latent delta, which quantifies the deviation of a real heart from its personalised normative pattern in the latent space. In experiments using a large dataset of 38,309 subjects, MeshHeart demonstrates a high performance in cardiac mesh sequence reconstruction and generation. Features defined in the latent space are highly discriminative for cardiac disease classification, whereas the latent delta exhibits strong correlation with clinical phenotypes in phenome-wide association studies. The codes and models of this study will be released to benefit further research on digital heart modelling.", "sections": [{"title": "Introduction", "content": "The heart is one of the most important and vital organs within the human body\u00b9. It is composed of four morphologically distinct chambers that function in a coordinated manner. The shape of the heart is governed by genetic\u00b2 and environmental factors, as well as a remodelling process observed in response to myocardial infarction, pressure overload, and cardiac diseases2,3. The motion of the heart follows a periodic non-linear pattern modulated by the underlying molecular, electrophysiological, and biophysical processes4. The unveiling of complex patterns of cardiac shape and motion will provide important information to assess the status and function of the heart for both clinical diagnosis and cardiovascular research5\u20138.\nThe current state-of-the-art for assessing cardiac shape and function is to perform analyses of cardiac images, e.g., cardiac magnetic resonance (MR) images, and extract imaging-derived phenotypes (IDPs) of cardiac chambers?. Most imaging phenotypes, such as chamber volumes or ejection fractions, provide a global and simplistic measure of the complex 3D-temporal (3D+t) geometry of cardiac chambers. These measures may not fully capture the dynamics and variations of heart function across individuals. Recognising these limitations underscores the importance of establishing a more precise model of cardiac status, defining what a normal heart looks like and moves like. Nevertheless, it is a non-trivial task to describe the normative pattern of the 3D shape or even 3D-t motion of heart, due to the complexity in representing high-dimensional spatio-temporal data.\nRecently, machine learning techniques have received increasing attention for cardiac shape and motion analysis4, 10, 11. Most existing research focuses on developing discriminative machine learning models, that is, training a model to perform classification tasks between different shapes or motion patterns4,6,12,13. However, discriminative models offer only classification results and do not explicitly explain what the normative pattern of cardiac shape or motion looks like14. In contrast, generative machine learning models provide an alternative route. Generative models are capable of describing distributions of high-dimensional data, such as images15\u201317, geometric shapes18\u201320, or molecules21,22, which allow the representation of normative data patterns in the latent space of the model. Although generative models have been explored for cardiac shape modelling23\u201327 or for cardiac imaging data augmentation28, their application to personalised normative modelling of the heart has been less explored.\nHere, we provide the first endeavour to create a personalised normative model of 3D+t cardiac shape and motion, leveraging deep generative modelling techniques. Cardiac shape and motion are represented by a dynamic sequence of 3D surface meshes across a cardiac cycle. A novel geometric deep generative model, named MeshHeart, is developed to model the distribution of 3D+t cardiac mesh sequences. MeshHeart employs a graph convolutional network (GCN)29 to learn the latent features of the mesh geometry and a Transformer to learn the temporal dynamics of the latent features during cardiac motion. This integration enables MeshHeart to model the distributions across both spatial and temporal dimensions. MeshHeart functions as a conditional generative model, accounting for major clinical variables such as sex and age as the generation factor. This enables the model to describe personalised normative patterns, generating synthetic healthy cardiac mesh sequences for a specific patient or a specific subpopulation.\nWe train the proposed generative model, MeshHeart (Figure 1(a)), on a large-scale population-level imaging dataset with 38,309 subjects from the UK Biobank7,30. After training the model, for each individual heart, we can generate a personalised 3D+t cardiac mesh model that describes the normative pattern for this particular subpopulation that has the same clinical factors as the input heart, as illustrated in Figure 1(c). In qualitative and quantitative experiments, we demonstrate that MeshHeart achieves high accuracy in generating the personalised heart model. Furthermore, we investigates the clinical relevance of the latent vector z of the model and propose a novel distance metric (latent delta \u0394z), which measures the deviation of the input heart from its personalised normative pattern (Figure 1 (c)). We demonstrate that the latent vector and latent delta have a highly discriminative value for the disease classification task and they are associated with a range of clinical features in phenome-wide association studies."}, {"title": "Results", "content": "MeshHeart learns spatial-temporal characteristics of the mesh sequence\nWe first assessed the reconstruction capability of MeshHeart for 3D+t cardiac mesh sequences. The experiments used a dataset of 4,000 test subjects, with dataset detail described in Supplementary Table S1. Each input mesh sequence was encoded into latent representation and then decoded to reconstruct the mesh sequence. Reconstruction performance was evaluated using two metrics, the Hausdorff distance (HD) and the average symmetric surface distance (ASSD), which measure the difference between the input and reconstructed meshes. The HD metric quantifies the maximum distance between points in two sets, highlighting the maximum discrepancy between the original and reconstructed heart meshes. ASSD computes the average distance between the surfaces of two meshes, providing a more holistic evaluation of the model's accuracy. Evaluation was performed for three anatomical structures: the left ventricle (LV), the myocardium (Myo), and the right ventricle (RV). We compared the performance of MeshHeart to three baseline mesh generative models: Action2Motion20, ACTOR31, and CHeart26.\nFigure 2(a) and Supplementary Table S2 report the reconstruction accuracy of MeshHeart, compared to other generative models. The metrics are reported as the average across all time frames, as well as at two representative time frames of cardiac motion: the end-diastolic frame (ED) and the end-systolic frame (ES). Overall, MeshHeart achieves the best reconstruction accuracy, outperforming other generative models, with the lowest HD of 4.163 mm and ASSD of 1.934 mm averaged across the time frames and across anatomical structures. Additionally, Figure 2(b) visualises examples of the reconstructed meshes, with vertex-wise reconstruction errors overlaid, at different frames of the cardiac cycle (t = 0, 10, 19 out of 50 frames in total). MeshHeart achieves lower reconstruction errors compared to the other models and maintains the smoothness of reconstructed meshes. We further conducted ablation studies to assess the contribution of each component to the model performance. These components are described in the Methods section and the detailed results are reported in Supplementary Table S5. Replacing GCN by linear layers results in an increased HD from 4.163 mm to 5.707 mm, while replacing GCN by CNN results in a HD of 5.268 mm, highlighting GCN's superiority in encoding mesh geometry. Substituting the Transformer with GRUs or LSTMs leads to an increased HD of 4.720 mm or 5.015 mm, respectively, which demonstrates the advantage of using the Transformer for modelling long-range temporal dependencies. Other components such as the smoothness loss term and the distribution parameter tokens also contribute to the model performance. These results highlight MeshHeart's capability in learning spatial-temporal characteristics of cardiac mesh sequences."}, {"title": "MeshHeart resembles real data distribution", "content": "Utilising the latent representations learnt by MeshHeart, we assessed the ability of the model to generate new synthetic cardiac mesh sequences that mimic real heart dynamics. To evaluate the fidelity and diversity of the generation, we calculated the similarity between the distributions of real meshes and generated synthetic meshes. For each real heart in the test set (n = 4,000), we applied MeshHeart to generate synthetic mesh sequences using the same clinical factors (age, sex, weight, and height) as the individual as the model input. During the generation stage, we chose 20 random samples from the Gaussian distribution of the latent space and generated the corresponding mesh sequences. For both real and synthetic meshes, clinically relevant metrics for cardiac structure and function were derived, including left ventricular end-diastolic volume (LVEDV), LV end-systolic volume (LVESV), LV ejection fraction (LVEF), LV myocardial mass (LVM), right ventricular end-diastolic volume (RVEDV), RV end-systolic volume (RVESV) and RV ejection fraction (RVEF). For each metric m, its probability distributions against age $P(m|c = age)$ and against sex $P(m|c = gender)$, were calculated. The similarity between real and synthetic probability distributions was quantified using the Kullback-Leibler (KL) divergence32 and the Wasserstein distance (WD)33, with a lower value denoting a higher similarity, i.e. better generation performance. KL divergence is a metric from information theory that evaluates the dissimilarity between two probability mass functions. Similarly, WD measures the dissimilarity between two probability distributions. MeshHeart's ability to replicate real data distributions is quantitatively demonstrated in Figure 3(a). MeshHeart achieves lower KL and WD scores compared to existing methods, as shown by radar plots with the smallest area, suggesting that the synthetic data generated by the proposed model closely aligns with the real data distribution for clinically relevant metrics. Supplementary Tables S3 and S4 report the detailed KL divergence and WD scores for different methods.\nFor qualitative assessment, Figure 3(b) presents four instances of synthetic cardiac mesh sequences for different personal factors (age, sex, weight, and height). For brevity, only two frames (t = 0,20) are shown. The figure demonstrates that MeshHeart can mimic authentic cardiac movements, showing contractions across time from diastole to systole. Figure 3(c) compares a real heart with a synthetic normal heart, at different time frames (t = 0,5,15,19), demonstrating the capability of MeshHeart in replicating both the real cardiac structure as well as typical motion patterns.\nWe also examined the latent representation learnt by MeshHeart using t-SNE (t-distributed Stochastic Neighbour Embedding) visualisation34 as illustrated in Supplementary Figure S1. The t-SNE plot projects the 64-dimensional latent representation of a mesh, extracted from the last hidden layer of the Transformer Encoder $Tenc$, onto a two-dimensional space, with each point denoting a mesh. It shows 10 sample sequences. For each sample, the latent representations of the meshes across time frames form a circular pattern that resembles the rhythmic beating of the heart35."}, {"title": "MeshHeart latent vector improves cardiovascular disease classification performance", "content": "After demonstrating the generative capability of MeshHeart, we explore its potential for clinical applications, in particular using its latent space which provides a low-dimensional representation of cardiac shape and motion. The latent feature analyses were conducted on 17,309 subjects. More than half (58.5%) had a reported diagnosis of at least one disease. We employ the latent vector z of each mesh sequence, a 64-dimensional vector, as the feature for correlation analysis and for cardiac disease classification. Figure 5(a) shows that the latent vector exhibits strong correlations with conventional imaging phenotypes, such as LVM, LVEDV, and RVEDV etc. Figure 4 and Supplementary Table S6 compare the classification performance of six cardiac diseases when using different feature sets. The three evaluated feature sets include \"Phenotypes + Confounders (Age, Sex)\", \"Latent Vector + Confounders\", and \"Phenotypes + Latent Vector + Confounders\". The classification performance is evaluated using the AUC (area under the curve) scores for three different classifiers: AdaBoost, linear discriminant analysis (LDA), and support vector machine (SVM). The six cardiovascular diseases include myocardial infarction (ICD-10 code I21), ischemic heart diseases (I24), paroxysmal tachycardia (I47), atrial fibrillation and flutter (148), hypertension (110), and cardiac disease (151). Figure 4 shows that using imaging phenotypes alone led to moderate AUC scores (e.g., 0.8361 and 0.8201 for myocardial infarction and ischemic heart diseases using with AdaBoost). Using the latent vector resulted in increased AUC scores (0.8557 and 0.8453). Combining both imaging phenotypes and the latent vector further improved the AUC scores (0.8762 and 0.8472), indicating the usefulness of the latent vector for cardiovascular disease classification.\nFor the AdaBoost classifier, using feature sets comprising the latent vector, as well as the combination of phenotypes and the latent vector, consistently outperformed the performance of the phenotypes set alone (e.g., 0.8291 and 0.8316 for cardiac disease using latent vector and combined feature sets), implying that incorporating the latent vector improved the classification accuracy. The trend was particularly noticeable for myocardial infarction, hypertension, and cardiac diseases, where the combined phenotypes and latent vector feature set substantially improved the AUC scores (0.8762, 0.7738 and 0.8316 for myocardial infarction, hypertension and cardiac disease). The LDA and SVM classifiers demonstrated that of the three feature sets, the combined phenotypes and latent vector feature set achieved the highest AUC scores (e.g., 0.6728 and 0.6479 for hypertension with LDA and SVM). However, for certain diseases such as ischemic heart disease, classifiers using only phenotypes (e.g., 0.7381 and 0.7123 for ischemic heart diseases with LDA and SVM) outperformed those that used only the latent vector (0.7277 and 0.6975), but still fell short of their combination (0.7492 and 0.7214). Overall, the results show that integrating imaging phenotypes, the latent vector along with confounders provides the best discriminative feature set for classification."}, {"title": "Latent delta for phenome-wide association studies (PheWAS)", "content": "For each individual heart, we use MeshHeart to generate a normal synthetic heart using the same clinical factors as this individual. This synthetic heart can be regarded as a personalised normative model learnt from a specific subpopulation. We define the latent delta \u0394z to be the difference between the latent vectors of an individual heart and its personalised norm, quantified using the Euclidean distance. The latent delta characterises the deviation of the shape and motion patterns of an individual heart from the normal pattern for a subpopulation with the same clinical factors (Figure 1(c)). A phenome-wide association study (PheWAS) was performed to explore the clinical relevance of \u0394z, as shown in Figure 5(b). The PheWAS revealed significant associations between the latent delta \u0394z and an unbiased set of clinical outcomes, including circulatory system diseases, endocrine/metabolic diseases, genitourinary diseases, musculoskeletal diseases and neoplasms.\nThe latent delta has been shown to correlate with phenotypes such as LVM and LVEF (Figure 5(a)), which serve as indicators of cardiac structure and function. Conditions such as hypertension, lipid/cholesterol abnormalities, and diabetes, can induce changes in these cardiac phenotypes. For example, hypertension likely results in an increased LVM and may be linked to a reduced LVEF due to the heart's adaptation to prolonged high blood pressure. In a similar vein, diabetes can exert metabolic stress on the heart, which can lead to changes in cardiac volume and ejection fraction. These modifications in the structure and motion patterns of the heart, as captured by the latent delta, provide a mechanistic explanation for the associations observed in the PheWAS results. Consequently, significant correlations between the latent delta and various clinical outcomes highlight its potential as a valuable marker for linking cardiac phenotypes with broader health conditions."}, {"title": "Discussion", "content": "This work contributes to the growing field of generative artificial intelligence for science, with a specific application in cardiac imaging. The proposed MeshHeart model is a new generative model that can facilitate improved understanding of the complexities of 3D+t cardiac shape and motion. In this study, we made four major contributions. First, we developed MeshHeart using a dataset of 38,309 subjects from a large UK population30, capturing the variation in cardiac structures and clinical characteristics. Second, we demonstrated MeshHeart's capability to generate a normal heart, accounting for clinical factors such as age, sex, weight, and height. This established a personalised normative model for cardiac anatomy. Third, we investigated the latent vector of MeshHeart and demonstrated its associations with conventional imaging phenotypes and usefulness for enhancing disease classification performance. Finally, we propose a novel latent delta (\u0394z) metric. This metric provides a way for quantifying the difference between an individual heart and the normative model, as well as for investigating the associations between the spatial-temporal characteristics of the heart and various health outcomes.\nMeshHeart's reconstruction capability was assessed using HD and ASSD metrics. Using these two metrics, we compared the model with other models along with an ablation study. Employing geometric convolutions and a temporal Transformer, the model reconstructed more accurate cardiac mesh sequences compared to the other state-of-the-art models. This is is due to the reason that geometric convolutions are proficient in encoding mesh geometry, and the Transformer is effective in capturing long-range temporal dependencies. The ablation study confirms the essential role of geometric convolutions and the temporal Transformer in increasing the performance of the model, as detailed in the Supplementary Table S5. We also compared MeshHeart against a previous work CHeart26. CHeart employs segmentation as a representation method for the cardiac structure, whereas MeshHeart employs the mesh representation. The results show that mesh provides a powerful representation for modelling the 3D geometry as well for tracking temporal motion, as it essentially allows monitoring the movement of each individual point over time.\nThe generative capabilities of MeshHeart, as illustrated by the results in Figure 3 and Supplementary Tables S3 and S4, demonstrate its proficiency as a generative model, able to replicate a 'normal' heart based on certain clinical factors including demographics (age, sex) and anthropometrics (weight, height). These four factors have shown strong correlations with heart structure and function across various individuals7,36,37. They form a reliable basis for constructing a normal heart model for an individual, as shown in Figure 3(b). Our analysis in Figure 3(a) and Supplementary Tables S3 and S4 focused on age and sex, employing WD and KL divergence to assess the similarity between the real and synthetic data distributions. Lower WD and KL metrics suggest that MeshHeart effectively represents demographic diversity, making the synthetic data beneficial for potential clinical and research purposes. The incorporation of additional clinical variables in the future, such as blood pressure and medical history, could improve the representation of cardiac health and diseases, thus enabling more potential applications for downstream tasks.\nThe latent vector obtained from the MeshHeart demonstrated its discriminative power for disease classification tasks. Incorporating the latent vector as feature substantially improves the classification accuracy for a range of cardiovascular conditions, as illustrated in Figure 4. Although conventional imaging phenotypes can also be used as a feature set for the classification model, their classification performance was surpassed by the augmented feature set that also includes the latent vector, suggesting that the latent vector may contain some information not provided by the imaging phenotypes. Combining imaging phenotypes with the latent vector and confounders consistently achieved the best classification performance, regardless of the classification model used, demonstrating the benefit of integrating multiple data sources to represent the status of the heart. Some dimensions of the latent vector exhibit high correlations with conventional cardiac phenotypes, which are essential for assessing cardiovascular disease risk. The high correlation with the latent vector underscores their clinical analysis potential.\nPheWAS uses a data-driven approach to uncover unbiased associations between cardiac deviations and disease diagnoses. Our analysis found that greater deviations in heart function are linked to increased risks of endocrine/metabolic and circulatory diseases. These cardiac diseases suggest underlying metabolic problems such as insulin resistance or metabolic disturbances observed in diabetes and obesity, which affect the structure and performance of the heart38,39. Likewise, they indicate wider circulatory conditions such as hypertension and atherosclerosis, which can lead to heart failure and ischemic heart disease40. Understanding these relationships is crucial for risk stratification, personalised medicine, and prevention strategies, highlighting the need for thorough cardiac evaluations in clinical management41.\nAlthough this work advances the science in personalised cardiac modelling, there are several limitations. First, the personalised normative model relies on a restricted range of generating factors, including age, sex, weight, and height, as we aim to develop a standard healthy heart. Including additional elements in the future such as diseases or environmental factors such as air pollution and noise42 could improve our understanding of their impacts on cardiac anatomy and function. Second, the model uses a cross-sectional dataset from the UK Biobank for both training and testing purposes. However, it does not include a benchmark for the progression of cardiac aging, which could be addressed by employing a longitudinal dataset to evaluate the model. Repeated scans are expected in the near future from the UK Biobank. Third, this study focuses on modelling the dynamic mesh sequence to describe cardiac shape and motion. It does not aim to model the underlying electrophysiology or biomechanics of the heart, which are also essential for cardiac modelling and understanding cardiac function 43,44. Additionally, the explainability of latent vectors could be explored, as understanding the specific information each latent dimension captures is crucial for clinical interpretation and validation.\nIn conclusion, this study presents MeshHeart, a generative model for cardiac shape modelling. By training and evaluating the model on a population-level dataset from the UK Biobank, we demonstrate that MeshHeart not only achieves a high reconstruction accuracy but also excels in generating synthetic cardiac mesh sequences that closely resemble the real heart. The latent vector of the generative model and the novel latent delta metric provide new avenues of research to improve disease classification and personalised healthcare. These findings pave the way for future research on cardiac modelling and may inspire the development of generative modelling techniques for other types of biomedical data."}, {"title": "Methods", "content": "Generative model\nFigure 1(a) illustrates the architecture of the proposed generative model, MeshHeart. Given a set of clinical conditions c, our goal is to develop a model that can generate a dynamic 3D cardiac mesh sequence, $X_{0:T-1} = {x_0,x_1,\u2026,x_{T-1}}$, where T denotes the number of time frames, that corresponds to the conditions c. Figure 1(b) shows an example of the input conditions and the generated mesh sequence. Without losing generality, we take age, sex, weight and height as conditions c in this work. Age, weight and height are continuous variables, whereas sex is a binary variable. Each cardiac mesh $x_t = (v_t, e_t)$ is a graph with a set of vertices $v_t$ and a set of edges $e_t$ connecting them. The proposed generative model consists of several components, a mesh encoder $M_{enc}$ and a condition encoder $C_{enc}$ to project the mesh sequence and conditions into latent representations, a Transformer encoder $T_{enc}$ to capture the temporal dependency of the meshes at different time frames, and finally a Transformer decoder $T_{dec}$ and a mesh decoder $M_{dec}$ to decode the latent representations back to the mesh sequence. The mesh encoder $M_{enc}$, constructed using a graph convolutional network (GCN), extracts features from the cardiac mesh sequence $x_{0:T-1}$ and generates latent vectors $z_{0:T-1}$. The condition encoder $C_{enc}$, implemented with a multi-layer perceptron (MLP), maps the clinical conditions c into a condition latent vector $z_c$ in the condition latent space. The mesh latent vectors $z_{0:T-1}$ at each time frame are concatenated with the condition latent vector $z_c$, which forms a sequence of input tokens to the Transformer decoder $T_{enc}$. For simplicity, the concatenated vectors are still denoted as $z_{0:T-1}$. These components work together to learn the probability distribution of the cardiac mesh sequence x conditioned on c, assuming that the latent space follows a Gaussian distribution. We seek a model $p_\u03b8(x|z_c)$, parameterised by \u03b8, that is sufficiently flexible to learn to describe the mesh sequence x. We assume a prior distribution $p(z_a)$ over the latent variable $z_a$. The prior $p(z_a)$ together with the decoder (constructed by $T_{dec}$ and $M_{dec}$) $p_\u03b8(x, z_a|z_c)$, define a joint distribution, denoted as $p_\u03b8(x|z_c)$. To train the model and perform inference, we need to compute the posterior distribution $p(z_a|x, z_c)$, which is generally intractable. To turn the intractable posterior inference problem $p(z_a|x, z_c)$ into a tractable problem, we introduce a parametric encoder model (constructed by $C_{enc}, M_{enc},T_{enc}$) $q_\u03c6(z_a|x,z_c)$ with \u03c6 to be the variational parameters, which approximates the true but intractable posterior distribution $p_\u03b8(z_a|x, z_c)$ of the generative model, given an input x and conditions c:\n$q_\u03c6(z_a|x,z_c) \u2248 p_\u03b8(z_a|x, z_c)$\nwhere $q_\u03c6(z_a|x,z_c)$ often adopts a simpler form, e.g. the Gaussian distribution. By introducing the approximate posterior $q_\u03c6(z_a|x, z_c)$, the log-likelihood of the conditional distribution $p_\u03b8(x|z_c)$ for input data x, also known as evidence, can be formulated as:\n$log p_\u03b8(x|z_c) = E_{z_a~q_\u03c6(z_a|x,z_c)} log [p_\u03b8(x|z_c)]$\n$= E_{z_a~q_\u03c6(z_a|x,z_c)} log [\\frac{p_\u03b8(x, z_a|z_c)}{q_\u03c6(z_a|x,z_c)}] + E_{z_a~q_\u03c6(z_a|x,z_c)} log [\\frac{q_\u03c6(z_a|x,z_c)}{p_\u03b8(z_a|x, z_c)}]$\nwhere the second term denotes the Kullback-Leibler (KL) divergence $D_{KL}(q_\u03c6 || p_\u03b8)$, between $q_\u03c6(z_a|x,z_c)$ and $p_\u03b8(z_a|x, z_c)$. It is non-negative and zero only if the approximate posterior $q_\u03c6(z_a|x, z_c)$ equals the true posterior distribution $p_\u03b8(z_a|x, z_c)$. Due to the non-negativity of the KL divergence, the first term in Eq. 2 is the lower bound of the evidence $log[p_\u03b8(x|z_c)]$, known as the evidence lower bound (ELBO). Instead of optimising the evidence $log[p_\u03b8(x|z_c)]$ which is often intractable, we optimise the ELBO:\n$max ELBO = log[p_\u03b8(x|z_c)] - D_{KL}$\n\u03b8,\u03c6\nThe Transformer encoder $T_{enc}$ comprises L layers of alternating blocks of multi-head self-attention (MSA) and MLP. To ensure stability and effective learning, LayerNorm (LN) is applied before each block and residual connections are applied after each block. Similar to the additional class-token of vision Transformer45, we append the input tokens $z_{0:T-1}$ with two learnable parameters $\u03bc_{token}$ and $\u03a3_{token}$, named as distribution parameter tokens. In the output layer, we extract the first two outputs $z_0, z_1$ of the Transformer encoder as distribution parameters \u03bc and \u03a3. We then use the reparameterisation trick46 to derive a latent vector $z_a$ from \u03bc and \u03a3, as shown in Figure 1(a). The encoding process is formulated as,\n$Z_{input} = [\u03bc_{token};\u03a3_{token}; z_0;z_1;...; z_{T-1}]$\n$z'' = MSA(LN(z'l-1)) + z'_{l-1}, l = 1,..,L$\n$z'_l = LN [MLP(LN(z'')_l)]$\n$z_a = \u03bc + \u03b5\u22c5\u03a3, \u03bc = z'_0, \u03a3 = z'_1, \u03b5 ~ N(0, I)$\nThe learnt latent vector $z_a$ encodes the distribution information for the mesh sequence. It is concatenated with the condition latent vector $z_c$ and is provided as input to the Transformer decoder $T_{dec}$. A sequence of temporal tokens is fed to the Transformer decoder $T_{dec}$ as queries, providing temporal information for T time frames. Inspired by the positional embedding in the vision"}, {"title": "Personalised normative model, latent vector, and latent delta", "content": "MeshHeart is trained on a large population of asymptomatic hearts. Once trained, it can be used as a personalised normative model to generate a synthetic mesh sequence of a normal heart with certain attributes c, including age, sex, weight, and height. For each real heart, we can then compare the real cardiac mesh sequence to the synthetic normal mesh sequence of the same attributes, to understand the deviation of the real heart from its personalised normative pattern.\nGiven conditions c, we draw 100 samples of the latent variable $z_s$ from a standard Gaussian distribution, specifically $z_s ~ N(0, I)$, where I is the identity matrix. This sampling is intended to approximate the true underlying distribution of the data. The relationship between the latent variables and the observed data can be expressed as:\n$\\int p(x, z_s | z_c) dz_s = p(x | z_c)$\nThis equation indicates that by integrating over the latent variable $z_s$, we obtain the marginal probability of the observed data x conditioned on $z_c$. Additionally, the joint probability of x and $z_s$ can be decomposed as:\n$p(x, z_s) = p(x | z_s, z_c)p(z_s | z_c)$\nWith MeshHeart, each cardiac mesh sequence x can be projected into a latent vector z. We then define the latent vector z to be last layer of the Transformer encoder $T_{enc}$. In this latent space, we define the latent delta \u0394z as the difference between the latent vector of the real heart and the latent vector of the synthetic normal heart, using the Euclidean distance as the metric, formulated as,\n$\u0394z = \\sqrt{\\sum_{i=1}^{n} (z_{synth} - z_{real})^2}$\nThe sequential cardiac meshes generated for both synthetic and real samples were encoded using the mesh encoder $M_{enc}$ and Transformer encoder $T_{enc}$. This process resulted in latent vectors $z_{synth}$ for synthetic samples and $z_{real}$ for real samples."}, {"title": "Data and experiments", "content": "This study used a data set of 38,309 participants obtained from the UK Biobank30. Each participant underwent cine cardiac magnetic resonance (CMR) imaging scans. From the cine CMR images, a 3D mesh sequence is derived to describe the shape and motion of the heart. The mesh sequence covers three anatomical structures, LV, Myo and RV. Each sequence contains 50 time frames over the course of a cardiac cycle. To derive cardiac meshes from the CMR images, automated segmentation51 was applied to the image at the ED frame. A 3D template mesh52 was fitted to the segmentation of the ED, resulting in an ED cardiac mesh. Subsequently, motion tracking was performed to warp the ED cardiac mesh across the time frames and obtain the entire mesh sequence. Motion tracking was performed using Deepali53, which is the GPU-accelerated version of the non-rigid registration toolbox MIRTK54. All cardiac meshes maintained the same geometric structure, consisting of 22,043 vertices and 43,840 faces.\nThe dataset is partitioned into training/validation/test sets for developing the MeshHeart model and a clinical analysis set for evaluating its performance for disease classification task. Briefly, MeshHeart was trained on 15,000 healthy subjects from the Cheadle imaging centre. For parameter tuning and performance evaluation, MeshHeart was evaluated on a validation set of 2,000 and a test set of 4,000 healthy subjects, from three different sites, Cheadle, Reading, and Newcastle centres. For clinical analysis, including performing the disease classification study and latent delta PheWAS, we used a separate set of 17,309 subjects from the three imaging centres, including 7,178 healthy subjects and 10,131 subjects with cardiac diseases and hypertension. PheWAS was undertaken using the PheWAS R package with clinical outcomes and coded phenotypes converted to 1,163 categorical PheCodes. P-values were deemed significant with Bonferroni adjustment for the number of PheCodes. The details of the dataset split and the definition of disease code are described in Supplementary Table S1."}, {"title": "Method comparison", "content": "To the best of our knowledge, there is no previous work on generative modelling for 3D+t cardiac mesh sequences. To compare the generation performance of MeshHeart, we adapt three state-of-the-art generative models originally proposed for other tasks: 1) Action2Motion31, originally developed for human motion generation; 2) ACTOR20, developed for human pose and motion generation; 3) CHeart26, developed for the generation of cardiac segmentation maps, instead of cardiac meshes. We modified these models to adapt to the cardiac mesh generation task."}, {"title": "Data availability statement", "content": "The raw imaging data and non-imaging participant characteristics are available from UK Biobank to approved researchers via a standard application process at http://www.ukbiobank.ac.uk/register-apply. Access the data at UK Biobank(https://www.ukbiobank.ac.uk/)."}, {"title": "Code availability statement", "content": "The code for this research is available in the supplementary materials supplied as a zip file at the time of submission. It will be made publicly accessible on GitHub (https://github.com/MengyunQ/MeshHeart) before publication. The access information and links to the data repository will be updated once the publication is finalised."}]}