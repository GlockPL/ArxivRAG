{"title": "Calibration-Disentangled Learning and Relevance-Prioritized Reranking for Calibrated Sequential Recommendation", "authors": ["Hyunsik Jeon", "Se-eun Yoon", "Julian McAuley"], "abstract": "Calibrated recommendation, which aims to maintain personalized proportions of categories within recommendations, is crucial in practical scenarios since it enhances user satisfaction by reflecting diverse interests. However, achieving calibration in a sequential setting (i.e., calibrated sequential recommendation) is challenging due to the need to adapt to users' evolving preferences. Previous methods typically leverage reranking algorithms to calibrate recommendations after training a model without considering the effect of calibration and do not effectively tackle the conflict between relevance and calibration during the reranking process. In this work, we propose LEAPREC (Calibration-Disentangled Learning and Relevance-Prioritized Reranking), a novel approach for the calibrated sequential recommendation that addresses these challenges. LEAPREC consists of two phases, model training phase and reranking phase. In the training phase, a backbone model is trained using our proposed calibration-disentangled learning-to-rank loss, which optimizes personalized rankings while integrating calibration considerations. In the reranking phase, relevant items are prioritized at the top of the list, with items needed for calibration following later to address potential conflicts between relevance and calibration. Through extensive experiments on four real-world datasets, we show that LEAPREC consistently outperforms previous methods in the calibrated sequential recommendation. Our code is available at https://github.com/jeon185/LeapRec.", "sections": [{"title": "1 INTRODUCTION", "content": "Calibrated recommendation aims to reflect a user's diverse interests within a recommendation list by maintaining the proportions of various categories observed in past interactions [1, 3, 38, 39]. For instance, if a user has historically watched 70% drama and 30% action movies, calibrated recommendation should suggest a list of movies maintaining a similar genre ratio. This problem differs from studies like [27, 44, 46] that define calibration in terms of probability-based user preference estimation, such as estimating how likely a user will prefer an item. To achieve the calibrated recommendation, two potentially conflicting objectives must be addressed: 1) relevance, which aligns with the user's current preferences, and 2) calibration, which sustains consistency with their long-term category interests. This challenge becomes particularly significant in sequential settings (i.e., calibrated sequential recommendation) where users' category preferences shift over time. These dynamic shifts in preferences are depicted in Figure 1, where the Kullback-Leibler (KL) divergence between category distributions increases as the sequence interval extends, highlighting the intricate challenge of balancing relevance with calibration.\nExisting work on calibrated recommendation focuses on post-processing approaches [1, 38, 39]. Specifically, a recommendation model is first trained to meet the relevance objective; then, the model output is reranked to meet the calibration objective. The difference between these methods lies in reranking, such as greedy (CaliRec [39]), mixed integer programming (MIP [38]), and minimum-cost flow (MCF [1]) algorithms. However, applying calibration during reranking can lead to degradation of accuracy because they do not consider the impacts of calibration during the training phase."}, {"title": "2 PRELIMINARIES", "content": ""}, {"title": "2.1 Problem Definition", "content": "The problem of calibrated sequential recommendation is defined as follows. Let U, I, and C be the sets of users, items, and categories, respectively. Each item $i \\in I$ is associated with a set of categories $C_i = \\{c^1_i, c^2_i, ..., c^N_i\\}$, where each $c^n_i \\in C$ represents a category of item i, and N is the number of categories, varying per item. For each user $u \\in U$, we have sequential interactions $S_u = (s^1_u, s^2_u,..., s^T_u)$, where $s^t_u \\in I$ is user u's interacted item at step t, and T denotes the length of the sequence which varies among users. Given sequences $S_u$ of all users $u \\in U$, our goal is to recommend each user an item list $R_u = (r^1_u, r^2_u, ...,r^K_u)$ that is relevant to the user's future needs (i.e., accurate), while reflecting the user's sequential category"}, {"title": "2.2 Calibration Metrics for Sequential Recommendation", "content": "The degree of calibration is measured by comparing the category distributions of items in a user's past interactions and items in their recommended list [39]. Specifically, it is defined as the divergence between these two distributions (i.e., miscalibration), where a lower value indicates superior calibration performance. Steck [39] proposed metrics for miscalibration under various criteria such as whether the user interactions are treated as equally or weighted regarding their recency, as illustrated in Figure 2. In this work, we adopt sequential miscalibration as our calibration metric, specifically tailored for sequential recommendations. This metric is described in the following definition.\nDefinition 1 (Sequential miscalibration): Given user u's sequential interactions $S_u$ and the user's recommendation list $R_u$, the sequential miscalibration $S_{KL}(u)$ is defined as follows:\n$S_{KL}(u) = KL(p||\\bar{q}) = \\sum_{c \\in C} p(c|u) log \\frac{p(c|u)}{\\bar{q}(c|u)},$ \t(1)\nwhere\n$p(c|u) = \\frac{\\sum_{s_t \\in S_u} \\alpha^{T-t} p(c|s_t)}{\\sum_{s_t \\in S_u} \\alpha^{T-t}},$ \t(2)\n$\\bar{q}(c|u) = \\frac{\\sum_{r_k \\in R_u} p(c|r_k)}{|R_u|},$ \t(3)\n$\\bar{q}(c|u) = (1 - \\beta)q(c|u) + \\beta p(c|u),$ \t(4)\n$KL(\\cdot||\\cdot)$ indicates the Kullback-Leibler (KL) divergence between two distributions, T = |S_u|, and $\\alpha, \\beta \\in (0, 1)$ are hyperparameters.\nIn Equations (2) and (3), $p(c|s_t)$ and $p(c|r_k)$ are the category distributions of items $s_t, r_k \\in I$, respectively. If an item is associated with multiple categories, each category is equally weighted in the"}, {"title": "3 PROPOSED METHOD", "content": "In this section, we describe LEAPREC (Calibration-Disentangled Learning and Relevance-Prioritized Reranking), a novel approach for calibrated sequential recommendation. Figure 3 depicts the overall process of LEAPREC, which consists of two phases: model training phase and reranking phase. During the training phase, LEAPREC employs a sequential recommendation model, such as SASRec [20], as its backbone. It optimizes our proposed calibration-aware learning-to-rank loss, which is designed to disentangle calibration from relevance, enabling the model to estimate accurate personalized rankings regardless of whether calibration is considered. During the reranking phase, LEAPREC applies our proposed relevance-prioritized reranking algorithm. This algorithm adjusts the model's output for each user to reduce miscalibration, while prioritizing the most relevant items in the final recommendations."}, {"title": "3.1 Calibration-Disentangled Learning-to-Rank", "content": "The objective of the training phase is to train a sequential model that can predict the probability a user will interact with an item based on their past interactions. Formally, given a user u's sequence of interactions $S_u = (s^1_u,s^2_u,..., s^T_u)$ where $s^t_u \\in I$ is the interacted item at step t, the model aims to estimate the probability for all items $v \\in I$ at step T + 1:\n$p(s^{T+1}_u = v|S_u)$. \t(5)\nGenerally, sequential models are trained to increase the gap between the relevance scores of interacted items and non-interacted items using pointwise [15], pairwise [35] or setwise [31] losses. Various frameworks, including Markov Chains [10, 36], Recurrent Neural Networks (RNN) [13, 23, 24, 28], Convolutional Neural Networks (CNN) [41, 50], and self-attention mechanisms [20, 29, 40], are effectively used in these sequential models, demonstrating high performance in terms of accuracy.\nLet $f_\\theta(u, i, t)$ represent the relevance score between user u and item i at step t, with parameters $\\theta$. Existing calibrated recommendation methods [1, 38, 39] often rely solely on post-processing techniques and thus overlook the potential impact of calibration adjustments on the final ranking order. However, it is crucial to integrate calibration directly into the training process to anticipate how rankings might change when calibration is applied. This proactive approach is essential for achieving high performance in both accuracy and calibration. To illustrate the importance of integrating calibration directly into the training process, consider a scenario where relevance scores indicate a preference for item i over item j based on past interactions (i.e., $f_\\theta(u, i, t) > f_\\theta(u, j, t)$). After the training phase, calibration scores may compel the system to rank item j higher than item i. It is difficult to determine whether these items should be reranked, since the degree to which item i is more relevant than item j becomes uncertain when calibration is taken into account. Thus, ensuring that the model can maintain consistent rankings even after calibration adjustments during reranking is crucial for the calibrated sequential recommendation.\nTo address this issue, we propose a calibration-disentangled learning-to-rank, a model-agnostic learning approach. For brevity, let $f_\\theta(u, i, t) := r^i_{u,t}$. Suppose user u interacted with item i instead of item j at step t. This interaction indicates that the user prefers item i over item j, even with category preference taken into account. Thus, at the recommendation step t, it is crucial to recommend item"}, {"title": "3.2 Relevance-Prioritized Reranking", "content": "The reranking phase aims to maximize both accuracy and calibration using the trained model $f_\\theta$. The goal is to recommend user u a list of items $R_u = (r^1_u,r^2_u,...,r^K_u)$ where $r^k_u \\in I$ is the k'th recommended item. Reranking generates the list by selecting the most suitable items among the candidates. The main challenge in the reranking phase is to measure which item is the best for the user at each step, considering both accuracy and calibration.\nFrom Figure 1, we observe that a user is likely to interact with an item that is associated with a category the user has not preferred before. For instance, a user who predominantly watches action movies might develop an interest in romance movies due to temporal factors. In this case, it is necessary to ensure that items that users like are recommended regardless of their category to satisfy the user's future needs. However, naively using weighted sum [1, 38, 39] may not adequately handle such cases. In the example, the romance movie may have a low overall score despite its high relevance due to the high miscalibration score, since it contrasts with the user's past category preferences. This conflict of relevance and calibration should be treated as a critical issue in the calibrated sequential recommendation, yet it has not been thoroughly addressed in previous works [1, 3, 38, 39].\nTo address this challenge, our reranking strategy prioritizes a user's emerging interests by integrating both relevance and calibration but favoring relevance in the higher ranks of the recommendation list. If we consider that the backbone model $f_\\theta$ is trained to predict the user's evolving preferences based on a sequential model,"}, {"title": "4 EXPERIMENTS", "content": "In this section, we conduct experiments to answer the following questions.\nQ1. Performance comparison (Section 4.2). Does LEAPREC provide better trade-off between accuracy and calibration compared to competitors? How efficient and fast is LEAPREC compared to competitors in generating recommendations?\nQ2. Ablation study (Section 4.3). Do the main components in LEAPREC help improve the performance?\nQ3. Effect of the balancing hyperparameter (Section 4.4). How does the balancing hyperparameter \u03bb, which is the key factor in enhancing calibration, affect the overall recommendation?\nQ4. Case study (Section 4.5). HOW LEAPREC recommend a list of items considering both relevance and calibration?"}, {"title": "4.1 Experimental Setting", "content": ""}, {"title": "6 CONCLUSION", "content": "In this work, we propose LEAPREC, a novel method that effectively balances accuracy and calibration in sequential recommendation. LEAPREC first trains a backbone model using the proposed calibration-disentangled learning-to-rank loss to learn personalized rankings when calibration is considered. Subsequently, LEAPREC applies the proposed relevance-prioritized reranking algorithm to the backbone's results, encouraging highly relevant items are placed at the top while accounting for calibration throughout the recommendations. LEAPREC achieves superior performance over existing calibrated recommendation methods in extensive experiments. Our ablation study further confirms the necessity of the core components of LEAPREC. We also demonstrate through a case study how LEAPREC tackles relevance and calibration to achieve high performance on both."}]}