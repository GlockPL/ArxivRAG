{"title": "Analyzing Probabilistic Methods for Evaluating Agent Capabilities", "authors": ["Axel H\u00f8jmark", "Govind Pimpale", "Arjun Panickssery", "Marius Hobbhahn", "J\u00e9r\u00e9my Scheurer"], "abstract": "To mitigate risks from AI systems, we need to assess their capabilities accurately. This is especially difficult in cases where capabilities are only rarely displayed. Phuong et al. [12] propose two methods that aim to obtain better estimates of the probability of an AI agent successfully completing a given task. The milestone method decomposes tasks into subtasks, aiming to improve overall success rate estimation, while the expert best-of-N method leverages human guidance as a proxy for the model's independent performance. Our analysis of these methods as Monte Carlo estimators reveals that while both effectively reduce variance compared to naive Monte Carlo sampling, they also introduce bias. Experimental results demonstrate that the milestone method underestimates true solve rates for many real-world tasks due to its constraining assumptions. The expert best-of-N method exhibits even more severe underestimation across all tasks, attributed to an inherently flawed re-weighting factor. To enhance the accuracy of capability estimates of AI agents on difficult tasks, we suggest future work should leverage the rich literature on Monte Carlo Estimators.", "sections": [{"title": "Introduction", "content": "As language models (LMs) become more capable, there has been increasing interest in using them to solve multi-step, agentic tasks that involve tool use and repeated interaction with the environment. LM agents are composite systems that combine an LM with scaffolding, software that repeatedly prompts the LM and lets it interact with the environment [10, 1, 23, 17, 18, 11, 20]. These agents could have significant economic utility, and therefore evaluating the capabilities of LM agents is crucial [8, 12, 19, 2, 13]. Additionally, advanced agents can also pose significant risks, such as the potential to construct bioweapons [7], conduct cyber attacks [22], strategically deceive humans [16], or replicate autonomously [6].\nEvaluating these agents on concrete tasks poses challenges. Unlike standard QA benchmarks that often require few reasoning steps, agent tasks demand sequential, multi-step execution. This structure amplifies the impact of errors: a single mistake can derail the entire process. Consequently, even slight improvements in an agent's error rate can lead to dramatic increases in overall task performance. This phenomenon can result in apparent \u201cemergent capabilities\u201d [15, 14, 21], making it difficult to accurately predict and prepare for the capabilities of future models. As such, there is a need for methods that can assess an agent's success rate on a given task with high accuracy, even when"}, {"title": "Methods", "content": "Now that we have discussed the need for efficient task success rate evaluation, we turn our attention to examining these two methods in greater detail. Our goal is to accurately estimate an agent's success rate on a particular task T with a limited token budget. We denote the true probability of the agent solving the task as $P(T^S)$, which represents the likelihood that the agent solves task T and achieves the solved state $T^S$. The naive approach to estimate this probability is to utilize Monte Carlo sampling. Let $X_i$ be a Bernoulli random variable where $X_i = 1$ if the task is solved in the i-th trial, and 0 otherwise. Given N total trials, an unbiased estimate of $P(T^S)$ is obtained by:\n$P(T^S) \\approx \\frac{1}{N} \\sum_{i=1}^{N} X_i$\nPhuong et al. [12] refer to this as the end-to-end method. However, this approach faces significant challenges when estimating low-probability events. The expected number of trials required to observe a single success is $\\frac{1}{P(T^S)}$, rendering naive Monte Carlo sampling impractical for many low-probability, long-horizon tasks. To overcome these limitations, Phuong et al. [12] propose alternative methods for estimating an agent's task-solving probability."}, {"title": "Milestone method", "content": "Milestones are natural subtasks that mark partial progress through the task. Importantly, the milestone method assumes that the task can only be solved by completing all predefined milestones in a specific order. The probability of completing the entire task is then expressed as the product of probabilities of completing each milestone given the completion of the previous milestone\u00b3:\n$P(T^S) = P(M_1^S) \\prod_{i=1}^{n-1} P(M_{i+1}^S | M_i^S)$\nwhere $M_i^S$ represents the solved state of milestone i, and n is the total number of milestones. Monte Carlo sampling is used to estimate the respective conditional probabilities. In each trial, the agent is initialized as if it has already completed the preceding subtasks. This initialization can use either a human-written \"golden\" solution, as in Phuong et al. [12], or a random sample from model trajectories that solved previous milestones."}, {"title": "Expert Best-of-N", "content": "When a model is unable to solve a task with milestones, the authors propose using expert help via the expert best-of-N method. This approach involves sampling N possible completions for each agent\n\u00b3This simplifies Phuong et al.'s technique, which uses a Bayesian approach to aggregate milestone solve rates. However, our description aligns with their mean estimate when beta distribution parameters are set to 0. See Appendix E.4 of Phuong et al. [12] for full details."}, {"title": "Analysis", "content": "Having established the framework of the milestone and expert best-of-N methods, we will now examine their relationship to Monte Carlo sampling techniques and assess their efficacy in estimating task success rates."}, {"title": "Analyzing the Milestone Method", "content": "The milestone method is closely related to a variance reduction method known as subset simulation [3], which has applications in reliability engineering and failure analysis. The milestone method, like subset simulation, relies on breaking down a rare event into a series of more probable conditional subevents. However, the milestone method differs in how it samples these subevents. Subset simulation employs Markov Chain Monte Carlo to sample from the conditional distribution of subevents. In contrast, the milestone approach either utilizes a fixed golden solution or, in our case, resamples from the set of trajectories that successfully passed the previous milestone.\nIf we are able to represent the task as a series of necessary milestones, the milestone method can be a powerful tool for reducing the variance of our task success probability estimate. Breaking down a task into milestones will almost always decrease the variance of our estimate of the true task solve rate. We can show theoretically that:\n$Var (\\prod_{i=1}^{n} \\hat{P}_{m_i,N}) \\leq Var (\\hat{P}_{t,N})$\nWhere $\\hat{P}_{m_i, N}$ is a random variable corresponding to the estimate of the i-th milestone solve rate with N samples and $\\hat{P}_{t,n}$ is a random variable corresponding to the estimate of the task solve rate with N samples. The full proof can be found in Appendix E. The reduction in variance allows us to achieve more reliable estimates with fewer samples overall compared to the end-to-end method. Furthermore, milestones can also provide more granular insights into the specific stages of a task where an agent may struggle, offering a more nuanced understanding of its capabilities."}, {"title": "Limitations of the Milestone Method", "content": "This discrepancy stems from the inherent limitations of the milestone approach. By prescribing a specific sequence of predefined checkpoints, the method narrows its focus to a subset of all possible successful trajectories. When calculating the final success rate, this restricted view leads to a systematic underestimation of the true solution probability. This discrepancy becomes particularly noticeable for tasks whose milestones can be completed in a different order (e.g. crosswords).\nDespite using highly sequential tasks that favored the milestone method, our experiments still show a significant underestimation of success rates. This bias is amplified in complex, real-world scenarios. For example, when debugging a large codebase, there may be multiple valid tasks that could be solved first, making any predefined milestone sequence artificially limiting. More broadly, as tasks become increasingly complex, predefined milestones become less likely to adequately capture the full range of potential solution paths."}, {"title": "Analyzing the Expert Best-of-N method", "content": "Although the expert best-of-N method is based on information theory, it can also be viewed through the lens of importance sampling. In importance sampling, we draw samples from a distribution that more readily produces events of interest, then adjust our estimates using a reweighting factor to account for the difference between the sampling distribution and the true distribution of interest. This concept is expressed mathematically as:\n$\\mathbb{E}[X] = \\mathbb{E}_{X \\sim q}[w(x)X]$"}, {"title": "Experiments - Expert Best-of-N in Practice", "content": "We assessed the expert best-of-N method's calibration using the previously introduced set of agentic tasks. The detailed experimental methodology is available in Appendix D.\nFigure 2 reveals that the estimates show little correlation with the tasks' actual solve rates and consistently underestimate the true probabilities. This tendency stems from the method's incorrect reweighting factor and makes it unreliable for safety-relevant decisions."}, {"title": "Conclusion", "content": "Accurately assessing an agent's probability of solving hard tasks is vital for identifying potential risks and detecting emerging capabilities. The milestone and expert best-of-N method introduced by Phuong et al. [12] are recent innovations in this direction, however our analysis reveals that they are both biased and significantly underestimate the true solve rate.\nMoving forward, research should prioritize developing estimation techniques that can handle tasks that are not amenable to milestone decomposition. We suggest that the rich field of rare event sampling should be considered for promising directions. Specifically, methods such as weighted ensemble sampling [24, 5] and stochastic-process rare event sampling [4] could potentially be adapted to more accurately estimate solve rates for rare or complex tasks."}, {"title": "Analyzing the Milestone Method", "content": "The milestone method is closely related to a variance reduction method known as subset simulation [3], which has applications in reliability engineering and failure analysis. The milestone method, like subset simulation, relies on breaking down a rare event into a series of more probable conditional subevents. However, the milestone method differs in how it samples these subevents. Subset simulation employs Markov Chain Monte Carlo to sample from the conditional distribution of subevents. In contrast, the milestone approach either utilizes a fixed golden solution or, in our case, resamples from the set of trajectories that successfully passed the previous milestone.\nIf we are able to represent the task as a series of necessary milestones, the milestone method can be a powerful tool for reducing the variance of our task success probability estimate. Breaking down a task into milestones will almost always decrease the variance of our estimate of the true task solve rate. We can show theoretically that:\n$Var(\\prod_{i=1}^{n} \\hat{P}_{m_i,N}) \\leq Var(\\hat{P}_{t,N})$\nWhere $\\hat{P}_{m_i, N}$ is a random variable corresponding to the estimate of the i-th milestone solve rate with N samples and $\\hat{P}_{t,n}$ is a random variable corresponding to the estimate of the task solve rate with N samples. The full proof can be found in Appendix E. The reduction in variance allows us to achieve more reliable estimates with fewer samples overall compared to the end-to-end method. Furthermore, milestones can also provide more granular insights into the specific stages of a task where an agent may struggle, offering a more nuanced understanding of its capabilities."}, {"title": "Expert Best-of-N Cost", "content": "The reasoning behind the index i of the chosen action (counting from one) being equated to a cost of $log_2(i(i + 1))$ bits, stems from the concept of Shannon entropy. Shannon Entropy states that given a prior probability distribution over a set, where each element has a prior probability $p_i$, one can, on average, encode an item from that set using $\u2013 log_2(p_i)$ bits. To convert these bits to success probabilities, you simply use the transformation $P(T^S) = 2^{-bits}$.\nIn this case, they use the prior $\\frac{1}{i(i+1)}$ over the set of N continuations made by the model. This prior can be a reasonable choice because it sums to 1 in the limit of large N:\n$\\sum_{i=1}^{\\infty} \\frac{1}{i(i + 1)} = 1$\nAdditionally, it is a decreasing function of i, which means that the expert is providing more infor-mation when they choose a less likely continuation. It also spreads out the probability mass more effectively than alternative priors, such as $\\frac{1}{N}$."}]}