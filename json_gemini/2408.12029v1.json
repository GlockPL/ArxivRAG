{"title": "Federated Diabetes Prediction in Canadian Adults Using Real-world Cross-Province Primary Care Data", "authors": ["Guojun Tang", "Jason E. Black", "Tyler S. Williamson", "Steve H. Drew"], "abstract": "Integrating Electronic Health Records (EHR) and the application of machine learning present opportunities for enhancing the accuracy and accessibility of data-driven diabetes prediction. In particular, developing data-driven machine learning models can provide early identification of patients with high risk for diabetes, potentially leading to more effective therapeutic strategies and reduced healthcare costs. However, regulation restrictions create barriers to developing centralized predictive models. This paper addresses the challenges by introducing a federated learning approach, which amalgamates predictive models without centralized data storage and processing, thus avoiding privacy issues. This marks the first application of federated learning to predict diabetes using real clinical datasets in Canada extracted from the Canadian Primary Care Sentinel Surveillance Network (CPCSSN) without cross-province patient data sharing. We address class-imbalance issues through downsampling techniques and compare federated learning performance against province-based and centralized models. Experimental results show that the federated MLP model presents a similar or higher performance compared to the model trained with the centralized approach. However, the federated logistic regression model showed inferior performance compared to its centralized peer.", "sections": [{"title": "Introduction", "content": "Predicting diabetes based on patient risk factors is paramount for the Canadian and global populations due to its significant impact on public health and healthcare costs. The number of patients with chronic disease, including diabetes, in Ontario, Canada alone, increased by 11.0% over the 10-year study period to 9.8 million in 2017/18, and the number with multimorbidity increased by 12.2% to 6.5 million\u00b9. According to Diabetes Canada\u00b2, among Canadians, 30% live with diabetes or prediabetes; 10% live with diagnosed diabetes, a figure that climbs to 15% when cases of undiagnosed type 2 diabetes are included. This high prevalence underscores the importance of prediction and early detection, as managing diabetes early can help prevent complications.\nPrediabetes often goes unnoticed and may cause diabetes-related complications, e.g., diabetic kidney disease and retinopathy. Creating an advanced predictive model capable of assimilating patient-specific factors to pinpoint individuals at an elevated risk for diabetes could pave the way for improved preventative strategies at the early stage, significantly reducing expenses associated with hospital stays, drug therapies, and subsequent medical treatments.\nElectronic Health Records (EHR) have become a valuable source of patient medical history, opening new avenues for developing innovative data-driven instruments and methodologies to enhance the precision and accessibility of healthcare services. The potential application of machine learning to forecast health outcomes might entail the integration of extensive datasets from disparate health systems. However, developing centralized predictive models requires accessing EHRs from multiple jurisdictions, raising data privacy, confidentiality, and compliance issues. For instance, the Personal Information Protection and Electronic Documents Act (PIPEDA)\u00b3 is a Canadian federal law that applies to the collection, use, and disclosure of personal information in the course of commercial activities in all Canadian provinces as supplemented by substantially similar provincial privacy laws in Alberta, British Columbia, and Qu\u00e9bec. Such policies have imposed very restrictive data sharing laws, which form a barrier to data collection in centralized model training. The federated learning may foster collaboration across the medical affiliations from different regions and has been successfully applied in practical medical applications, such as clinical outcome prediction and diagnosis5.\nIn response to ongoing data-sharing concerns among healthcare providers, we introduce a federated learning approach that enables the amalgamation of predictive models without storing patient data centrally. A decentralized analytics framework could utilize information from separate health entities without encountering ethical or legal issues. For instance, Humayera et al.6 used the SUPREME-DM dataset to create a diabetes cohort and employed a federated"}, {"title": "Method", "content": "This study used the Canadian Primary Care Sentinel Surveillance Network (CPCSSN) as the data source. The CPCSSN is a de-identified EHR dataset based on the medical records of nine provinces and over 1.7 million patients. This dataset consists of medical information from practical primary care in Canada, including the patients' demographics, encounters, physical examinations, laboratory test results, medical prescriptions for patients, and disease cases of patients. We defined the cohort with the records in CPCSSN and extracted the features related to diabetes."}, {"title": "Cohort and Features Selection", "content": "We constructed the cohort according to the instructions from Esser et al.8. We chose adult patients who had a blood pressure record in the database between 2004 and 2014 and were aged over 18 at the time of the exam. After that, we removed the patients who had been defined as having diabetes before this period or had medical prescriptions for insulin. Using the blood pressure record as the cohort baseline, we joined the patients' other measurements within the time of the exam no more than one year. Finally, we randomly selected a subset of 30,000 patients from the mentioned records and then applied data cleaning (e.g., filtering out the patient's data with excessive missing features and removing the record with incorrect medical values). The final size of the cohort is 11,631.\nWe chose the following features as the predictive variables: age at the exam, gender, systolic blood pressure (sBP), body mass index (BMI), low-density lipoprotein (LDL), high-density lipoprotein (HDL), HemoglobinA1c (HbA1c), triglycerides (TG), depression, hypertension, medications for hypertension, osteoarthritis, chronic obstructive pulmonary disease (COPD), and corticosteroids."}, {"title": "Centralized Machine Learning", "content": "To illustrate the efficacy of how federated learning improves the performance of the predictive model, first, we partitioned the dataset into different subsets according to the patients' provinces. We trained the provincial model, or the local model, by its corresponding provincial data under the assumption that a province can access the patient data within its boundaries without regulatory barriers. Therefore, we may simulate the isolation of real-world data among those regions. Then, we shuffle the local dataset and preserve 70% and 30% of the data for model training and testing, respectively. There are missing values in the variables, as shown in Table 1, and we imputed those missing values by applying the MICE algorithm\u00b9\u00b9 to the training and testing set separately. After we trained all local models, we aggregated each training set and test set for training a centralized model, which can be regarded as the ideal baseline of the federated model. Those local and centralized models act as the benchmark and are compared to the federated model. We choose centralized machine learning as a benchmark because it always acquires more comprehensive information and usually has better performance compared to FL. Using local models as the other benchmark may help us verify whether FL improves the performance of the model. We employed Scikit-learn\u00b9\u00b2 to implement the logistic regression and multiple layer perceptron (MLP) algorithms, and the models' hyperparameters are shown in Table 2. The statistics of each local dataset are shown in Figure 1."}, {"title": "Federated Learning", "content": "Federated learning (FL) is a distributed machine learning paradigm that empowers different clients who have sensitive private data to collaboratively train a global model by uploading their local model parameters instead of sharing the data directly. The overview of FL is illustrated in Figure 2. In our experiment, we adopted the FedAvg13 algorithm to implement federated logistic regression and federated MLP by using Scikit-learn12 and Flower14, a lightweight federated learning framework in Python. The FedAvg algorithm first dispatches the initialized model to all clients and launches multiple global training rounds to train the global model. In each global training round, the central server randomly selects n clients involved within this round of training. The selected clients updated the local model by computing the gradient using the global parameters and their own data after downloading the global model parameters from the central server. In the local update step, the client updated their local model in E local epochs and b local batch size with their local data. After the local update step, the central server receives clients' model parameters. It aggregates them by weighted averaging the parameters (we consider equal weights in this case), which will be broadcast to all clients at the end of this global training round. The overview of the FedAvg algorithm is shown in Algorithm 1."}, {"title": "Algorithm 1", "content": "The pseudocode overview of FedAvg13.\nAlgorithm 1 FedAvg. K total clients; n participants each training round; T global epoch; E local epoch; I loss function; b batch size; \u03b7 learning rate;\nprocedure ServerAggregation initialize model parameter wo\nfor t = 1,2..., T do\nSt randomly choose n clients for k \u2208 St parallel do\nawk\nWt+1 ClientUpdate(k, wt)\n$W_{t+1} \\leftarrow \\frac{\\sum_{k \\in S_t} K_k W_{t+1}^k}{K}$\nprocedure ClientUpdate(k, w)\nfor i = 1,..., E do\nfor local batch b \u2208 dataset from client k do\n$w \\leftarrow w - \\eta \\nabla l(w;b)$\nreturn w\nFor the FL setting, we employed the same model hyperparameters as centralized machine learning. We divided the dataset into seven subsets according to the provinces, including Alberta (AB), British Columbia (BC), Manitoba (MB), Newfoundland and Labrador (NL), Nova Scotia (NS), Ontario (ON), and Quebec (QC). New Brunswick (NB) and Prince Edward Island (PEI) are not involved due to lack of samples. These constructed seven clients are equipped with the corresponding provincial local data and trained a global model using the FedAvg algorithm. In this experiment, we set the participants n = 2 while the local epoch E = 1."}, {"title": "Experimental Settings", "content": "In our experiment, we trained the federated model using the FedAvg algorithm with data from different provinces and compared this model with the provincial local and centralized models. As the disease prediction model is a binary classification task, we considered the F1 scores and AUC scores as benchmarks of the models, which may reflect the efficiency of the binary classification rather than the accuracy. Furthermore, we also plotted the calibration cur-ves for these models in order to evaluate the class probabilities from them. Due to the nature of class imbalance shown in Figure 1, we adopted dataset downsampling, a common strategy for imbalanced datasets, and tested its efficiency in FL. We conducted our experiment in the CPCSSN Secure Research Environment (SRE), equipped with Microsoft Windows 10 OS, Intel Xeon Silver 4216 CPU, and 32GB of RAM."}, {"title": "Experimental Results", "content": "We conducted the experiment in which we first trained the performance of logistic regression and MLP using local data among different provinces, a centralized dataset, and federated machine learning methods. The summaries of the results are presented in Table 3 and Table 4, respectively. The table recorded the global test set results of AUC, F1, precision, and recall by applying different types of models: 1) local models trained by the provincial data from its own region (AB, BC, MB, NL, NS, ON, QC); 2) the centralized model trained by the data from all regions (CML); 3) the federated model trained using the FedAvg (FL). The table recorded the global test set results of AUC, F1, precision, and recall by applying different types of models: 1) local models trained by the provincial data from its own region (AB, BC, MB, NL, NS, ON, QC); 2) the centralized model trained by the data from all regions (CML); 3) the federated model trained using FedAvg (FL). We also considered the training strategies with downsampling and without resampling. The performance (F1-score and recall) of the local models is roughly consistent with the data quality (e.g., the number and the proportion of the positive samples) in both logistic regression and MLP models. The FL method may empower us to improve the overall model performance of those areas with relatively low quality by averaging the parameters from the models trained by the regional dataset with better quality.\nIt is worth noting that, however, the performance of logistic regression and MLP varies under the FL framework. The performance (AUC, F1, precision, and recall) of federated MLP only differed from approximately 3% and even surpassed the results from the centralized model. However, in the federated logistic regression model, the AUC was reduced by 13% in the no-resampling case and 8% in the downsampling case when compared to the centralized method. This condition also has been incurred in the F1 score, reduced by 20% in the no-resampling case and 16% in the downsampling case.\nNotably, the impact of the downsampling will be more significant in the MLP model. After applying the downsampling, the AUC increased by 3% and 8% in the centralized and federated logistic regression models, respectively, while the F1 decreased by 6% in CML and 2% in FL. However, the downsampling will cause a 10% decrease in the F1 in centralized MLP and an 8% decrease in federated MLP, in which we could only observe a 2% improvement in the AUC."}, {"title": "Discussion", "content": "Table 3 illustrated that the federated logistic regression model underperformed its centralized model. The experimental results from Humayera\u2074 also indicated a similar drop in performance between the centralized logistic model and the federated model. A reasonable explanation is that the model parameters of the neural network, such as MLP, are more complicated than the linear model, such as logistic regression. Therefore, it may still preserve more features after averaging the weights of all the local clients.\nAccording to the conclusion from Ruben et.al.15, the training with downsampling may have a higher recall than the datasets without resampling. However, it will also significantly downgrade precision, leading to a worse F1 score. This trend has been seen across all local, centralized, and federated models in our studies. Moreover, by comparing the outcomes of Table 3 and Table 4, it becomes noticeable that the reduction in performance due to the downsampling strategy will be more considerable in federated MLP.\nBased on the results in Table 5 and Table 6, it can be inferred that the federated MLP model may be more robust and outperform the local models trained by regions with high-quality data. However, the federated logistic regression underperformed those local models. The potential interpretation is that the federated learning framework, which aggregates various local models, may extract more features from the data compared to the local model only trained by the data from a single region. In practice, while using the logistic regression model, directly applying the local model from the region with good data quality is an alternative solution instead of training a federated model.\nThe calibration curves of the centralized and federated models are shown in Figure 3. Both the centralized and federated logistic regression models produced well-calibrated predictions due to the canonical link function in the linear model16. Following the implementation of the Federated Learning (FL) approach, the MLP model demonstrated a tendency to generally overestimate predictions and showed better calibration in comparison to its centralized version. We noticed that the implementation of downsampling leads to decreased calibration performance in both federated and centralized models."}, {"title": "Conclusion and Future Work", "content": "Federated learning is an innovative solution to train a global model in a distributed system without sharing the data directly or violating the privacy policy. It allows us to break the barrier of privacy restrictions among different regions and improve the model quality. In this paper, we applied FedAvg to a diabetes prediction task and validated its effectiveness by comparing it with the local and centralized models. Our result indicates that the federated MLP model has a favorable impact on the model quality rather than only using the local or centralized models. However, as for the linear model of logistic regression, even though it has been widely used in assorted medical scenarios, the performance, which has been shown in our experiments, is still considerably lower than the centralized model, which has been commonly regarded as the baseline of FL.\nFL has provided a feasible distributed machine learning framework for privacy-sensitive data and has a great potential in the healthcare scenario. From an intuitive perspective, the performance of the centralized machine learning model may be regarded as the upper bound of FL. However, the empirical results from our study and the relevant research from Humayera et al.4 indicated that the federated MLP outperformed the centralized one. In our future works, we may corroborate the results and attempt to figure out an explanation for this phenomenon. Our studies only focus on two specific models: logistic regression and MLP. Our future research will involve the exploration of more model types, including XGBoost\u00b9\u2077, a tree-based machine learning model that has been widely applied in various medical applications. The model calibration technique is a very common machine learning technique in healthcare applications, but we did not consider it in our study. Our future work will also include the model calibration in FL. In this study, we only adopted the simple case of predicting the diagnosis of diabetes. In the future, based on the Canadian patients and CPCSSN dataset, we may introduce FL into further research of diabetes-related complications, such as chronic kidney diseases."}]}