{"title": "Federated Diabetes Prediction in Canadian Adults Using Real-world\nCross-Province Primary Care Data", "authors": ["Guojun Tang", "Jason E. Black", "Tyler S. Williamson", "Steve H. Drew"], "abstract": "Integrating Electronic Health Records (EHR) and the application of machine learning present opportunities for\nenhancing the accuracy and accessibility of data-driven diabetes prediction. In particular, developing data-driven\nmachine learning models can provide early identification of patients with high risk for diabetes, potentially leading\nto more effective therapeutic strategies and reduced healthcare costs. However, regulation restrictions create barriers\nto developing centralized predictive models. This paper addresses the challenges by introducing a federated learning\napproach, which amalgamates predictive models without centralized data storage and processing, thus avoiding\nprivacy issues. This marks the first application of federated learning to predict diabetes using real clinical datasets\nin Canada extracted from the Canadian Primary Care Sentinel Surveillance Network (CPCSSN) without cross-\nprovince patient data sharing. We address class-imbalance issues through downsampling techniques and compare\nfederated learning performance against province-based and centralized models. Experimental results show that\nthe federated MLP model presents a similar or higher performance compared to the model trained with the centralized\napproach. However, the federated logistic regression model showed inferior performance compared to its centralized\npeer.", "sections": [{"title": "Introduction", "content": "Predicting diabetes based on patient risk factors is paramount for the Canadian and global populations due to its\nsignificant impact on public health and healthcare costs. The number of patients with chronic disease, including\ndiabetes, in Ontario, Canada alone, increased by 11.0% over the 10-year study period to 9.8 million in 2017/18, and\nthe number with multimorbidity increased by 12.2% to 6.5 million\u00b9. According to Diabetes Canada\u00b2, among Canadians,\n30% live with diabetes or prediabetes; 10% live with diagnosed diabetes, a figure that climbs to 15% when cases of\nundiagnosed type 2 diabetes are included. This high prevalence underscores the importance of prediction and early\ndetection, as managing diabetes early can help prevent complications.\nPrediabetes often goes unnoticed and may cause diabetes-related complications, e.g., diabetic kidney disease and\nretinopathy. Creating an advanced predictive model capable of assimilating patient-specific factors to pinpoint\nindividuals at an elevated risk for diabetes could pave the way for improved preventative strategies at the early stage,\nsignificantly reducing expenses associated with hospital stays, drug therapies, and subsequent medical treatments.\nElectronic Health Records (EHR) have become a valuable source of patient medical history, opening new avenues for\ndeveloping innovative data-driven instruments and methodologies to enhance the precision and accessibility of\nhealthcare services. The potential application of machine learning to forecast health outcomes might entail the\nintegration of extensive datasets from disparate health systems. However, developing centralized predictive models\nrequires accessing EHRs from multiple jurisdictions, raising data privacy, confidentiality, and compliance issues. For\ninstance, the Personal Information Protection and Electronic Documents Act (PIPEDA)\u00b3 is a Canadian federal law\nthat applies to the collection, use, and disclosure of personal information in the course of commercial activities in all\nCanadian provinces as supplemented by substantially similar provincial privacy laws in Alberta, British Columbia,\nand Qu\u00e9bec. Such policies have imposed very restrictive data sharing laws, which form a barrier to data collection in\ncentralized model training. The federated learning may foster collaboration across the medical affiliations from\ndifferent regions and has been successfully applied in practical medical applications, such as clinical outcome\nprediction and diagnosis5.\nIn response to ongoing data-sharing concerns among healthcare providers, we introduce a federated learning approach\nthat enables the amalgamation of predictive models without storing patient data centrally. A decentralized analytics\nframework could utilize information from separate health entities without encountering ethical or legal issues. For\ninstance, Humayera et al.6 used the SUPREME-DM dataset to create a diabetes cohort and employed a federated"}, {"title": "Method", "content": "This study used the Canadian Primary Care Sentinel Surveillance Network (CPCSSN) as the data source. The\nCPCSSN is a de-identified EHR dataset based on the medical records of nine provinces and over 1.7 million patients.\nThis dataset consists of medical information from practical primary care in Canada, including the patients'\ndemographics, encounters, physical examinations, laboratory test results, medical prescriptions for patients, and\ndisease cases of patients. We defined the cohort with the records in CPCSSN and extracted the features related to\ndiabetes."}, {"title": "Cohort and Features Selection", "content": "We constructed the cohort according to the instructions from Esser et al.8. We chose adult patients who had a blood\npressure record in the database between 2004 and 2014 and were aged over 18 at the time of the exam. After that, we\nremoved the patients who had been defined as having diabetes before this period or had medical prescriptions for\ninsulin. Using the blood pressure record as the cohort baseline, we joined the patients' other measurements within the\ntime of the exam no more than one year. Finally, we randomly selected a subset of 30,000 patients from the mentioned\nrecords and then applied data cleaning (e.g., filtering out the patient's data with excessive missing features and\nremoving the record with incorrect medical values). The final size of the cohort is 11,631."}, {"title": "Centralized Machine Learning", "content": "To illustrate the efficacy of how federated learning improves the performance of the predictive model, first, we\npartitioned the dataset into different subsets according to the patients' provinces. We trained the provincial model, or\nthe local model, by its corresponding provincial data under the assumption that a province can access the patient data\nwithin its boundaries without regulatory barriers. Therefore, we may simulate the isolation of real-world data among\nthose regions. Then, we shuffle the local dataset and preserve 70% and 30% of the data for model training and testing,\nrespectively. There are missing values in the variables, as shown in Table 1, and we imputed those missing values by\napplying the MICE algorithm\u00b9\u00b9 to the training and testing set separately. After we trained all local models, we\naggregated each training set and test set for training a centralized model, which can be regarded as the ideal baseline\nof the federated model. Those local and centralized models act as the benchmark and are compared to the federated\nmodel. We choose centralized machine learning as a benchmark because it always acquires more comprehensive\ninformation and usually has better performance compared to FL. Using local models as the other benchmark may help\nus verify whether FL improves the performance of the model. We employed Scikit-learn\u00b9\u00b2 to implement the logistic\nregression and multiple layer perceptron (MLP) algorithms, and the models' hyperparameters are shown in Table 2.\nThe statistics of each local dataset are shown in Figure 1."}, {"title": "Federated Learning", "content": "Federated learning (FL) is a distributed machine learning paradigm that empowers different clients who have sensitive\nprivate data to collaboratively train a global model by uploading their local model parameters instead of sharing the\ndata directly. The overview of FL is illustrated in Figure 2. In our experiment, we adopted the FedAvg13 algorithm to\nimplement federated logistic regression and federated MLP by using Scikit-learn12 and Flower14, a lightweight\nfederated learning framework in Python. The FedAvg algorithm first dispatches the initialized model to all clients and\nlaunches multiple global training rounds to train the global model. In each global training round, the central server\nrandomly selects n clients involved within this round of training. The selected clients updated the local model by\ncomputing the gradient using the global parameters and their own data after downloading the global model parameters\nfrom the central server. In the local update step, the client updated their local model in E local epochs and b local\nbatch size with their local data. After the local update step, the central server receives clients' model parameters. It\naggregates them by weighted averaging the parameters (we consider equal weights in this case), which will be\nbroadcast to all clients at the end of this global training round. The overview of the FedAvg algorithm is shown in\nAlgorithm 1."}, {"title": "Algorithm 1 FedAvg.", "content": "K total clients; n participants each training round; T global epoch; E local\nepoch; I loss function; b batch size; \u03b7 learning rate;"}, {"title": "procedure ServerAggregation", "content": "initialize model parameter wo\nfor t = 1,2..., T do\n$S_t$ randomly choose n clients for k \u2208 $S_t$ parallel do\n$w_{t+1}^k$ \u2190 ClientUpdate(k, $w_t$)\n$w_{t+1}$ \u2190 $\\frac{\\sum_{k \\in S_t} w_k \\cdot w_{t+1}^k}{K}$\nprocedure ClientUpdate(k, w)"}, {"title": "Local update", "content": "for i = 1,..., E do\nfor local batch b \u2208 dataset from client k do\n$w$ \u2190 $w \u2013 \\eta \\nabla l(w;b)$\nreturn w"}, {"title": "Experimental Settings", "content": "In our experiment, we trained the federated model using the FedAvg algorithm with data from different provinces and\ncompared this model with the provincial local and centralized models. As the disease prediction model is a binary\nclassification task, we considered the F1 scores and AUC scores as benchmarks of the models, which may reflect the\nefficiency of the binary classification rather than the accuracy. Furthermore, we also plotted the calibration cur-\nves for these models in order to evaluate the class probabilities from them. Due to the nature of class imbalance shown\nin Figure 1, we adopted dataset downsampling, a common strategy for imbalanced datasets, and tested its efficiency\nin FL. We conducted our experiment in the CPCSSN Secure Research Environment (SRE), equipped with Microsoft\nWindows 10 OS, Intel Xeon Silver 4216 CPU, and 32GB of RAM."}, {"title": "Experimental Results", "content": "We conducted the experiment in which we first trained the performance of logistic regression and MLP using local\ndata among different provinces, a centralized dataset, and federated machine learning methods. The summaries of the\nresults are presented in Table 3 and Table 4, respectively. The table recorded the global test set results of AUC, F1,\nprecision, and recall by applying different types of models: 1) local models trained by the provincial data from its own\nregion (AB, BC, MB, NL, NS, ON, QC); 2) the centralized model trained by the data from all regions (CML); 3) the\nfederated model trained using the FedAvg (FL). The table recorded the global test set results of AUC, F1, precision,\nand recall by applying different types of models: 1) local models trained by the provincial data from its own region\n(AB, BC, MB, NL, NS, ON, QC); 2) the centralized model trained by the data from all regions (CML); 3) the federated\nmodel trained using FedAvg (FL). We also considered the training strategies with downsampling and without\nresampling. The performance (F1-score and recall) of the local models is roughly consistent with the data quality (e.g.,\nthe number and the proportion of the positive samples) in both logistic regression and MLP models. The FL method"}, {"title": "Discussion", "content": "Table 3 illustrated that the federated logistic regression model underperformed its centralized model. The experimental\nresults from Humayera\u2074 also indicated a similar drop in performance between the centralized logistic model and the\nfederated model. A reasonable explanation is that the model parameters of the neural network, such as MLP, are more\ncomplicated than the linear model, such as logistic regression. Therefore, it may still preserve more features after\naveraging the weights of all the local clients.\nAccording to the conclusion from Ruben et.al.15, the training with downsampling may have a higher recall than the\ndatasets without resampling. However, it will also significantly downgrade precision, leading to a worse F1 score.\nThis trend has been seen across all local, centralized, and federated models in our studies. Moreover, by comparing\nthe outcomes of Table 3 and Table 4, it becomes noticeable that the reduction in performance due to the downsampling\nstrategy will be more considerable in federated MLP.\nBased on the results in Table 5 and Table 6, it can be inferred that the federated MLP model may be more robust and\noutperform the local models trained by regions with high-quality data. However, the federated logistic regression\nunderperformed those local models. The potential interpretation is that the federated learning framework, which\naggregates various local models, may extract more features from the data compared to the local model only trained by\nthe data from a single region. In practice, while using the logistic regression model, directly applying the local model\nfrom the region with good data quality is an alternative solution instead of training a federated model.\nThe calibration curves of the centralized and federated models are shown in Figure 3. Both the centralized and\nfederated logistic regression models produced well-calibrated predictions due to the canonical link function in the\nlinear model16. Following the implementation of the Federated Learning (FL) approach, the MLP model demonstrated\na tendency to generally overestimate predictions and showed better calibration in comparison to its centralized version.\nWe noticed that the implementation of downsampling leads to decreased calibration performance in both federated\nand centralized models."}, {"title": "Conclusion and Future Work", "content": "Federated learning is an innovative solution to train a global model in a distributed system without sharing the data\ndirectly or violating the privacy policy. It allows us to break the barrier of privacy restrictions among different regions\nand improve the model quality. In this paper, we applied FedAvg to a diabetes prediction task and validated its\neffectiveness by comparing it with the local and centralized models. Our result indicates that the federated MLP model\nhas a favorable impact on the model quality rather than only using the local or centralized models. However, as for\nthe linear model of logistic regression, even though it has been widely used in assorted medical scenarios, the\nperformance, which has been shown in our experiments, is still considerably lower than the centralized model, which\nhas been commonly regarded as the baseline of FL.\nFL has provided a feasible distributed machine learning framework for privacy-sensitive data and has a great potential\nin the healthcare scenario. From an intuitive perspective, the performance of the centralized machine learning model\nmay be regarded as the upper bound of FL. However, the empirical results from our study and the relevant research\nfrom Humayera et al.4 indicated that the federated MLP outperformed the centralized one. In our future works, we\nmay corroborate the results and attempt to figure out an explanation for this phenomenon. Our studies only focus on\ntwo specific models: logistic regression and MLP. Our future research will involve the exploration of more model\ntypes, including XGBoost\u00b9\u2077, a tree-based machine learning model that has been widely applied in various medical\napplications. The model calibration technique is a very common machine learning technique in healthcare applications,\nbut we did not consider it in our study. Our future work will also include the model calibration in FL. In this study,\nwe only adopted the simple case of predicting the diagnosis of diabetes. In the future, based on the Canadian patients\nand CPCSSN dataset, we may introduce FL into further research of diabetes-related complications, such as chronic\nkidney diseases."}]}