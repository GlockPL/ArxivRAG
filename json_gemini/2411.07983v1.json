{"title": "Gini Coefficient as a Unified Metric for Evaluating\nMany-versus-Many Similarity in Vector Spaces", "authors": ["Ben Fauber"], "abstract": "We demonstrate that Gini coefficients can be used as unified metrics to evaluate many-versus-many\n(all-to-all) similarity in vector spaces. Our analysis of various image datasets shows that images with\nthe highest Gini coefficients tend to be the most similar to one another, while images with the lowest\nGini coefficients are the least similar. We also show that this relationship holds true for vectorized text\nembeddings from various corpuses, highlighting the consistency of our method and its broad applicability\nacross different types of data. Additionally, we demonstrate that selecting machine learning training\nsamples that closely match the distribution of the testing dataset is far more important than ensuring\ndata diversity. Selection of exemplary and iconic training samples with higher Gini coefficients leads to\nsignificantly better model performance compared to simply having a diverse training set with lower Gini\ncoefficients. Thus, Gini coefficients can serve as effective criteria for selecting machine learning training\nsamples, with our selection method outperforming random sampling methods in very sparse information\nsettings.", "sections": [{"title": "1 Introduction", "content": "Similarity in vector spaces quantifies how closely two or more vectors resemble each other. Similarity is often\nquantified using metrics such as cosine similarity, dot product, or Euclidean distance (Strang, 2014). These\nmeasures are crucial for machine learning objectives like clustering, classification, and recommendation\nsystems, as they help describe relationships between data points within their vector space (Strang, 2019;\nHardt & Recht, 2022).\nSimilarity search is an important one-versus-many method used to find items in a dataset that are similar\nto a query item (Zezula et al., 2010). Yet, there is not a sufficient metric to assess the quality of many-versus-\nmany similarity. For example, there is an insufficient method and metric to determine how similar all vectors\nin a dataset are with one another. Herein, we propose the use of the Gini coefficient as a unified metric for\nassessing many-versus-many similarity in vector space (Figure 1)."}, {"title": "2 Background", "content": "Similarity search is an fundamental one-versus-many search method used to find items in a dataset that are\nsimilar to a query item (Zezula et al., 2010). It is widely used in fields like image and video search, natural\nlanguage processing, and healthcare to find similar instances.\nSimilarity search involves representing/embedding n items as n vectors $R^d$ in a high-dimensional space\nd that accurately captures their semantic meaning. An exact match similarity search is of O(n) complexity,\nwhere n is the size of the dataset being queried. Approximate nearest neighbor (ANN) search algorithms\nsuch as locality-sensitive hashing (LSH) (Indyk & Motwani, 1998), Min-hash (Broder et al., 1998), product\nquantization (PQ) (J\u00e9gou et al., 2011), and hierarchical navigable small-world (HNSW) graphs (Malkov\n& Yashunin, 2018) enable efficient queries of large datasets with sublinear time complexity (Andoni et al.,\n2018). Despite the impressive advances in approximate nearest neighbor search algorithms, there is a lack of\nsuitable methods and metrics to describe the similarity of all vectors in a dataset with one another.\nThe Gini coefficient, also known as the Gini index or Gini ratio, is typically applied in economic studies\nto measure income, wealth, or consumption inequality within a country or group. Originally proposed by the\nItalian statistician Corrado Gini, and built on the work of American economist Max Lorenz, Gini's method\nproposed the difference between a hypothetical line of perfect equality and the actual income distribution\nline as a measure of inequality (Gini, 1912; 2005; Pellegrino, 2020).\nIn addition to its original application in economics, the Gini coefficient can be applied in any field of\nscience that studies distributions. For example, in ecology the Gini coefficient has been used as a measure of\nbiodiversity (Wittebolle et al., 2009). In public health, it has been used as a measure of health-related quality\nof life within a population (Asada, 2005). In medicinal chemistry, it has been used to express the selectivity\nof small molecule protein kinase inhibitors against a broader panel of protein kinases (Graczyk, 2007).\nWhen applied to economic equity, the Gini coefficient ranges from 0 (perfect equality, where everyone has\nthe same income) to 1 (perfect inequality, where one person has all the income). To facilitate the calculation,\nthe income data is arranged in ascending order. Next, the cumulative shares of the population and their\ncorresponding incomes are calculated. Plotting the cumulative shares versus the cumulative fraction/count\nresults in the Lorenz curve, which illustrates the income distribution (Figure 1). The Gini coefficient is\ndetermined by the area between the Lorenz curve and the line of equality."}, {"title": "2.1 Our Contribution", "content": "We propose that the Gini coefficient can be used as a unified, singular metric to assess the many-versus-many\nsimilarity of multiple vectors (Figure 1). In our setting, a set of n real value vectors $v \\in R^d$ of d dimensions\ncan be l2-normalized and represented as a matrix $V \\in R^{n\\times d}$ of n vectors. Further, the scalar product S of\n$VV^T$ results in a similarity matrix $S \\in R^{n\\times n}$, where each $s_{ij} \\in S$ represents the similarity between vectors $v_i$\nand $v_j$ and $s_{ij} \\in [-1,1]$.\nCalculating the Gini coefficient $g_i$ associated with row $s_i \\in S$ results in a single value metric that represents\nthe similarity for $v_i$ versus all other $v_n$. Specifically, the Gini coefficient $g_i \\in G$, where $G \\in R^n$, for $s_i \\in S$ is\ncalculated as the area under the curve (AUC) below the line of equality (Figure 1, area A), divided by the sum\nof the AUC below the line of equality and the AUC below the Lorenz curve (Figure 1, area A + B) (Graczyk,\n2007). Calculation of the Gini coefficients of $s_{ij} \\in S$ results in $G \\in R^n$. The resulting Gini coefficients G can\nbe normalized with a MinMax scaling approach such that $g_i \\in [0, 1], \\forall g_i \\in G$.\nIn our application, the Gini coefficient $g_i$ was bounded [0, 1], but the relevance of the value to the outcome\nwill vary based on the objective. In our assessment of many-versus-many (e.g., all-to-all) similarity, higher\nGini coefficients represented greater similarity, whereas lower Gini coefficients represented lesser similarity.\nWe also demonstrated that Gini coefficients can guide data sampling strategies when training machine\nlearning (ML) algorithms in very sparse information settings. In multiclass classification, when the training\nand testing dataset distributions were closely aligned, prioritizing the top one or two samples with the highest\nGini coefficients resulted in the selection of exemplary and prototypical samples from each class. This\napproach outperformed random selection of training samples and was particularly valuable when only one or\ntwo samples per class were used for multiclass ML training campaigns."}, {"title": "3 Results", "content": "The MNIST (Modified National Institute of Standards and Technology database) dataset is a collection\nof 70,000 handwritten digit images, each 28x28 pixels in size, grayscale, and generally used for training\nand testing machine learning models. It includes 60,000 training images and 10,000 test images, with\nan approximately uniform distribution of all digits 0 through 9, and is a standard benchmark for image\nrecognition tasks."}, {"title": "3.1 Gini Coefficients as Metrics for Many-versus-Many Similarity", "content": ""}, {"title": "3.1.1 MNIST Dataset", "content": "Our method was applied to the MNIST dataset to explore the impact of the Gini coefficient as a unified\nmetric for evaluating many-versus-many similarity in vector spaces. Specifically, the per-class cosine\nsimilarities of the flattened (d = 784) and l2-normalized raw pixel grayscale MNIST dataset images were\ncalculated. All elements $s_{ij} \\in S$ of the resulting similarity matrix S were subtracted from 1 such that the most\nsimilar elements in S were $s_{ij}$ ~ 0. The per-class Gini coefficients for S were then calculated and MinMax\nnormalized\u00b9 to ensure all values were [0, 1] and to allow for comparison of Gini coefficients across all classes\nin the dataset."}, {"title": "3.1.2 Fashion-MNIST Dataset", "content": "Additionally, our method was applied to the Fashion-MNIST dataset. Fashion-MNIST is a dataset containing\n70,000 unique grayscale images of clothing, where each image is 28 \u00d7 28 pixels in size. The dataset includes\n10 classes of clothing items, which are approximately evenly distributed: T-shirts, trousers, pullovers, dresses,\ncoats, sandals, shirts, sneakers, bags, and ankle boots.\u00b3 Similar to MNIST, Fashion-MNIST contains a\npredefined training set of 60,000 examples and a test set of 10,000 examples. The same approach and\ndata preparation steps that we used with the MNIST dataset were applied to the Fashion-MNIST dataset\nto generate the MinMax normalized per-class Gini coefficients [0, 1] for each class in the Fashion-MNIST\ntraining dataset."}, {"title": "3.1.3 Flowers102 Dataset", "content": "Application of our method to the Flowers 102 dataset resulted in clear ranking of most-similar to least-similar\nimages for each class in the dataset. Flowers102 is a dataset containing 1,020 unique training images of\nflowers from 102 different classes, with 10 images per class.\u2074 The same approach and data preparation steps\nthat we used with the MNIST dataset were applied to the Flowers102 dataset, in addition to converting the\ntraining images to grayscale and resizing to 36 \u00d7 36 pixels, to generate the MinMax normalized per-class\nGini coefficients [0, 1] for each class in the Flowers102 dataset. The results of the Flowers102 Gini coefficient\nanalysis clearly demonstrated that the most similar images in each class had highest Gini coefficients whereas\nthe lowest Gini coefficients were the most unique images for each class (Figure 7)."}, {"title": "3.1.4 Text Analysis", "content": "Our method was also applied to vectorized text embeddings to assess the utility of Gini coefficients when\ncomparing text chunks. In our analysis, two novels were each chunked into six-word chunks and the six-\nword chunks from each novel were separately embedded into 512-dimensional vectors using the Universal\nSentence Encoder v4 (USE) (Cer et al., 2018). The resulting 12-normalized vectors were used in our method,\nall Gini coefficients for each novel were MinMax normalized to [0,1], and the outcomes for each novel are\nshown in Table 1.\nNotably, the text chunks in Table 1 with the lowest Gini coefficients were the most unique text phrases\nfrom each novel, containing descriptive and colorful nouns and adjectives. Conversely, the text chunks with\nthe highest Gini coefficients were the least unique and bland text phrases containing common pronouns,\npossessives, conjunctions, and interrogative words. At a high level, the Gini coefficient patterns observed with\nour text data analysis matched the Gini coefficient patterns we identified with the MNIST, Fashion-MNIST,\nand Flowers102 image datasets. These results further emphasized the reliability of our method and the wide\napplicability of the Gini coefficient for evaluating many-to-many similarity, regardless of the data types\ninvolved."}, {"title": "3.2 Gini Coefficients can Guide Dataset Sampling for Machine Learning", "content": "Statistical sampling and randomization are crucial in statistics, especially for designing experiments and\nsurveys (James et al., 2013). Randomization, which involves randomly assigning elements to different groups\nor treatments, is vital for minimizing bias, controlling for variables, and ensuring validity.\nMost canonical machine learning (ML) pipelines and processes utilize randomized selection of data for\ntraining and testing to improve robustness and minimize bias (Geron, 2019; Raschka et al., 2022). Recently,\nthe notion of learning in sparse information settings has gained attention, particularly the concept of data\npruning (Okanovic et al., 2023; Paul et al., 2023; Sorscher et al., 2023). These efforts critically evaluate\nthe improvements in deep learning algorithms that have been driven in part by increasingly larger datasets.\nSpecifically, they aim to identify important examples in datasets for learning generalization while eliminating\nsuperfluous data.\nWe show that Gini coefficients can help guide data sampling strategies when training ML algorithms in\nvery sparse information settings. To demonstrate this, we assessed the influence of Gini coefficients on the\nprioritization of MNIST training dataset samples for training a support vector machine (SVM) multiclass\nclassification algorithm. We then evaluated the impact of the sampling strategy on the classification accuracy\nof the 10,000-example MNIST test dataset.\nIn our study, the training dataset samples were selected from the 60,000-example MNIST training dataset\nby either random sampling, prioritizing the samples with the highest per-class Gini coefficients (i.e., most\nexemplary and least diverse samples), or prioritizing the samples with the lowest per-class Gini coefficients\n(i.e., most diverse samples). The mean of three random sampling results were used to generate each random\nsampling data point. All MNIST training and testing data inputs to the SVM model were flattened raw pixel\nvalues (d = 784) ranging from 0 to 255 for each 28 \u00d7 28 grayscale image. Each d-dimensional image vector\nwas l2-normalized before entering the SVM model for either training or testing (see Appendix for details).\nWe noted that when selecting only one or two exemplary samples per class, prioritizing the samples with\nthe highest per-class Gini coefficients outperformed all other sampling strategies (Figure 8). Conversely,\nprioritizing the samples with the lowest per-class Gini coefficients resulted in significantly lower performance\nthan the other sampling methods. In aggregate, the random sampling approach outperformed the other\nmethods and led to near-optimal performance of the SVM classifier with undersampled training dataset\nexamples. All methods converged to the maximum accuracy of 92% as they neared the maximum number of\napproximately 6,000 samples per class of the MNIST training data set due to the Central Limit Theorem\n(Fuller, 2009)."}, {"title": "4 Conclusion", "content": "We demonstrated that Gini coefficients can be used as a unified metric to evaluate many-versus-many (e.g.,\nall-to-all) similarly in vector spaces. Our analysis of various image datasets showed that images with\nthe highest Gini coefficients tend to be the most similar to one another, while those with the lowest Gini\ncoefficients were the least similar. We also showed that this relationship holds true for vectorized text\nembeddings from various novels, highlighting the consistency of our method and its broad applicability\nacross different types of data.\nAdditionally, we demonstrated that selecting machine learning training samples that closely match\nthe distribution of the testing dataset was far more important than ensuring data diversity. Selection of\nexemplary and iconic training samples led to significantly better model performance compared to simply\nhaving a diverse training set. Thus, Gini coefficients can serve as effective criteria for selecting machine\nlearning training samples, with our selection method outperforming random sampling methods in very sparse\ninformation settings."}, {"title": "A Appendix", "content": ""}, {"title": "A.1 Gini Coefficient Calculation", "content": "The results described in this article were carried out using open datasets on a Linux system configured\nwith Anaconda v23.1.0. Additional python dependencies included: tensorflow v2.16.2, tensorflow-hub\nv0.16.1, torch v2.1.1, and torchvision v0.20.1. All processes can be run on CPU infrastructure, but\nthe processes scale with minimal latency on GPU infrastructure.\nIn order to calculate the Gini coefficients, a set of n real value vectors $v \\in R^d$ of d dimensions were\n12-normalized and represented as a matrix $V \\in R^{n\\times d}$ of n vectors. The scalar product S of $VV^T$ resulted in\na similarity matrix $S \\in R^{n\\times n}$, where each $s_{ij} \\in S$ represented the similarity between vectors $v_i$ and $v_j$ and\n$s_{ij} \\in [-1,1]$. The similarity matrix S was subtracted from the scalar 1 such that $s_{ij} \\approx 0$ represented the most\nsimilar $v_i$ and $v_j$.\nCalculation of the Gini coefficients of $s_{ij} \\in S$ resulted in $G \\in R^n$. Calculation of the Gini coefficient\n$g_i$ associated with row $s_i \\in S$ was conducted in python according to the method of (Graczyk, 2007). The\nresulting Gini coefficients G were normalized with a MinMax scaling approach such that $g_i \\in [0,1], \\forall g_i \\in G$.\nThus, the calculation of $g_i$ resulted in a single value metric that represented the similarity for $v_i$ versus all\nother $v_n$.\nIn our application, the Gini coefficient $g_i$ was bounded [0, 1], but the relevance of the value to the outcome\nwill vary based on the objective. In our assessment of many-versus-many (e.g., all-to-all) similarity, higher\nGini coefficients represented greater similarity, whereas lower Gini coefficients represented lesser similarity."}, {"title": "A.2 Gini Coefficients for MNIST Dataset Figures", "content": "The MNIST training dataset contains 60,000 instances in total and approximately 6,000 instances per class.\nThe Gini coefficients were calculated using the flattened raw pixel values (d = 784) ranging from 0 to 255\nfor each 28 \u00d7 28 grayscale image. Each d-dimensional image vector was 12-normalized before computing\nthe similarity values and Gini coefficients. The Gini coefficients were MinMax normalized [0, 1] to allow for\ncomparison across classes.\nFigure Al displays the top 24 images of each class in the MNIST dataset with the lowest per-class Gini\ncoefficients. Lower Gini coefficients indicated less similarity compared to higher coefficients. Therefore,\nthe examples in Figure Al represent the most unique images for each class in the dataset. Conversely, the\nhighest per-class Gini coefficients in the MNIST dataset highlight the most similar images (Figure A2).\nThese highly similar images, with the highest per-class Gini coefficients, can be considered exemplary of\neach class in the dataset."}, {"title": "A.3 Gini Coefficients for Fashion-MNIST Dataset Figures", "content": "The Fashion-MNIST training dataset contains 60,000 instances in total and approximately 6,000 instances\nper class. The Gini coefficients were calculated using the flattened raw pixel values (d = 784) ranging from\n0 to 255 for each 28 \u00d7 28 grayscale image. Each d-dimensional image vector was 12-normalized before\ncomputing the similarity values and Gini coefficients. The Gini coefficients were MinMax normalized [0, 1]\nto allow for comparison across classes.\nFigure A3 displays the top 24 images of each class in the Fashion-MNIST dataset with the lowest per-class\nGini coefficients. Lower Gini coefficients indicated less similarity compared to higher coefficients. Therefore,\nthe examples in Figure A3 represent the most unique images for each class in the dataset. Conversely, the\nhighest per-class Gini coefficients in the Fashion-MNIST dataset highlight the most similar images (Figure\nA4). These highly similar images, with the highest per-class Gini coefficients, can be considered exemplary\nof each class in the dataset."}, {"title": "A.4 Classifier Accuracies for MNIST Dataset Images", "content": "We explored the role of sampling strategies when training a support vector machine (SVM) machine learning\n(ML) algorithm. Training datasets were sampled with increasing numbers of samples per class in the\nmulticlass dataset. The resulting trained ML models were evaluated using a hold-out testing dataset that was\nconsistent across the entire analysis.\nIn our study, the training dataset samples were selected from the 60,000-example MNIST training dataset\nby either random sampling, prioritizing the samples with the highest per-class Gini coefficients (i.e., most\nexemplary and least diverse samples), or prioritizing the samples with the lowest per-class Gini coefficients\n(i.e., most diverse samples). The mean of three random sampling results were used to generate each random\nsampling data point. All MNIST training and testing data inputs to the SVM model were flattened raw pixel\nvalues (d = 784) ranging from 0 to 255 for each 28 \u00d7 28 grayscale image. Each d-dimensional image vector\nwas 12-normalized before entering the SVM model for either training or testing. SVM model performance\nwas assessed by the classification accuracy across all classes for the test dataset for each training sample size\ncohort.\nFollow-up analyses explored the impact of additional training sample selection methods. In this follow-\nup analysis, the training dataset samples were selected using one of the following methods: per-class\nrandom sampling, prioritizing samples with the highest per-class Gini coefficients, mimicking the per-class\ndistribution of the test dataset Gini coefficients using kernel density estimation (KDE) of the Gini coefficients\nof the selected training samples, or minimizing the earth-mover's distance (EMD) between the distribution\nof the test dataset Gini coefficients and the Gini coefficients of the selected training samples. The random\nsampling, KDE distribution sampling, and EMD distribution sampling methods all sought to mimic the\ndistribution of the test dataset for each class. The random sampling method achieved its objective via the\nCentral Limit Theorem (Fuller, 2009), whereas the KDE\u2076 and EMD\u2077 approaches were iterative, with 1,000\niterations per instance, to achieve the strongest alignment to the desired distributional target."}, {"title": "A.5 Classifier Accuracies for Fashion-MNIST Dataset Images", "content": "We explored the role of sampling strategies when training a support vector machine (SVM) machine learning\n(ML) algorithm. Training datasets were sampled with increasing numbers of samples per class in the\nmulticlass dataset. The resulting trained ML models were evaluated using a hold-out testing dataset that was\nconsistent across the entire analysis.\nIn our study, the training dataset samples were selected from the 60,000-example Fashion-MNIST training\ndataset by either random sampling, prioritizing the samples with the highest per-class Gini coefficients\n(i.e., most exemplary and least diverse samples), or prioritizing the samples with the lowest per-class Gini\ncoefficients (i.e., most diverse samples). The mean of three random sampling results were used to generate\neach random sampling data point. All Fashion-MNIST training and testing data inputs to the SVM model\nwere flattened raw pixel values (d = 784) ranging from 0 to 255 for each 28 \u00d7 28 grayscale image. Each\nd-dimensional image vector was 12-normalized before entering the SVM model for either training or testing.\nSVM model performance was assessed by the classification accuracy across all classes for the test dataset for\neach training sample size cohort.\nWe noted that when selecting only one or two exemplary samples per class, prioritizing the samples with\nthe highest per-class Gini coefficients outperformed all other sampling strategies (Figure A7). Conversely,\nprioritizing the samples with the lowest per-class Gini coefficients resulted in significantly lower performance\nthan the other sampling methods. In aggregate, the random sampling approach outperformed the other\nmethods and led to near-optimal performance of the SVM classifier with undersampled training dataset\nexamples. All methods converged to the maximum accuracy of 84% as they neared the maximum number\nof approximately 6,000 samples per class of the Fashion-MNIST training data set due to the Central Limit\nTheorem (Fuller, 2009)\nAs we also observed with the MNIST dataset, prioritizing the top one or two samples with the highest\nper-class Gini coefficients from the Fashion-MNIST dataset resulted in the selection of exemplary samples\nfrom each class. This approach outperformed random selection of training samples and was particularly\nvaluable when only one or two samples per class are used for multiclass ML training campaigns.\nAt a high level, we observed that selecting machine learning training samples that closely matched the\ndistribution of the testing dataset through random sampling was much more important than ensuring data\ndiversity (i.e., samples with lower Gini coefficients). Selection of exemplary and iconic training samples\n(i.e., samples with higher Gini coefficients) led to significantly better model performance compared to\nsimply having a diverse training set (i.e., samples with lower Gini coefficients). These consistent results\nfurther highlighted the effectiveness of our method in prioritizing samples with the highest per-class Gini\ncoefficients, especially in situations with very sparse information."}]}