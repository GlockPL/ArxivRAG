{"title": "NeuroBOLT: Resting-state EEG-to-fMRI Synthesis\nwith Multi-dimensional Feature Mapping", "authors": ["Yamin Li", "Ange Lou", "Ziyuan Xu", "Shengchao Zhang", "Shiyu Wang", "Dario J. Englot", "Soheil Kolouri", "Daniel Moyer", "Roza G. Bayrak", "Catie Chang"], "abstract": "Functional magnetic resonance imaging (fMRI) is an indispensable tool in modern\nneuroscience, providing a non-invasive window into whole-brain dynamics at\nmillimeter-scale spatial resolution. However, fMRI is constrained by issues such\nas high operation costs and immobility. With the rapid advancements in cross-\nmodality synthesis and brain decoding, the use of deep neural networks has emerged\nas a promising solution for inferring whole-brain, high-resolution fMRI features\ndirectly from electroencephalography (EEG), a more widely accessible and portable\nneuroimaging modality. Nonetheless, the complex projection from neural activity\nto fMRI hemodynamic responses and the spatial ambiguity of EEG pose substantial\nchallenges both in modeling and interpretability. Relatively few studies to date have\ndeveloped approaches for EEG-fMRI translation, and although they have made\nsignificant strides, the inference of fMRI signals in a given study has been limited\nto a small set of brain areas and to a single condition (i.e., either resting-state or a\nspecific task). The capability to predict fMRI signals in other brain areas, as well\nas to generalize across conditions, remain critical gaps in the field. To tackle these\nchallenges, we introduce a novel and generalizable framework: NeuroBOLT, i.e.,\nNeuro-to-BOLD Transformer, which leverages multi-dimensional representation\nlearning from temporal, spatial, and spectral domains to translate raw EEG data\nto the corresponding fMRI activity signals across the brain. Our experiments\ndemonstrate that NeuroBOLT effectively reconstructs resting-state fMRI signals\nfrom primary sensory, high-level cognitive areas, and deep subcortical brain regions,\nachieving state-of-the-art accuracy and significantly advancing the integration of\nthese two modalities.", "sections": [{"title": "Introduction", "content": "Functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) are the most\ncommonly utilized non-invasive neuroimaging techniques, providing crucial insights into brain\nfunctionality. These two modalities offer distinct advantages and limitations that can complement one\nanother when combined [51, 12]. fMRI offers high spatial resolution imaging of whole-brain activity\nby measuring blood-oxygen-level-dependent (BOLD) signal changes, which facilitates probing\nregional and network-level function. However, fMRI suffers from low temporal resolution and\nhemodynamic blurring, which limits its ability to capture the accurate timing of rapid neuronal\nactivity dynamics. Additionally, the high cost, non-portability, and incompatibility with metal\nimplants further restrict the utility of MRI in certain contexts. Conversely, EEG stands out as a\nlow-cost, portable neuroimaging modality with high temporal resolution [9, 28, 66]. However, EEG\nfaces limitations due to volume conduction and from the superficial location of electrodes (on the\nscalp), making it difficult for EEG to accurately infer the origins of the measured electrical potentials.\nIn this context, the high spatial resolution of fMRI becomes indispensable, especially for imaging\ndeep brain regions.\nOne approach for investigating the relationship between EEG and fMRI signals is by analyzing\ndata collected simultaneously from both modalities. Such studies have demonstrated correlations\nbetween fMRI data and various features of EEG signals, such as the power in certain frequency bands\n[25, 6, 26], which underscore the potential of EEG to inform fMRI features. However, factors such\nas the disparate biophysical origins of the two signals, and differences in their spatial and temporal\nresolutions, can limit the accuracy, interpretation, and consistency of correlation-based EEG-fMRI\nstudies. These challenges are exacerbated in conditions during which a participant is resting passively\n(i.e., resting state), which is characterized by significant noise and randomness. Consequently, the\nmechanisms linking neuronal activity to BOLD signals remain only partially understood, posing\nchallenges in mapping EEG to fMRI.\nWith recent progress in cross-modality synthesis and brain decoding techniques using deep neural\nnetworks [7, 8, 15], EEG-to-fMRI synthesis has emerged as a promising yet largely untapped research\narea[3]. Initial efforts made by [46] employed ridge regression on EEG temporal-spectral features to\nreconstruct fMRI signals from the visual cortex and sub-cortical regions. More recent studies from\n[23] and [29] have developed sequence-to-sequence (Seq-to-Seq) deep neural networks to reconstruct\nfMRI time series of deep brain regions from EEG. However, these efforts have primarily focused\non datasets involving eyes-open and eyes-closed tasks, and its generalization to resting state and\nother conditions has yet to be investigated. Additionally, only a small number of brain regions have\nbeen examined in current studies, leaving the predictive power of EEG over broader areas largely\nunexplored. These limitations underscore the need for more comprehensive and general models for\nEEG-fMRI translation.\nIn this paper, we present NeuroBOLT: a multi-dimensional transformer-based EEG encoding frame-\nwork for Neural-to-BOLD fMRI Translation (Figure. 2). NeuroBOLT is designed to capture and\nintegrate multi-dimensional representations across temporal, spatial, and spectral domains, offering a\ngeneralizable approach for translating raw EEG waves to BOLD fMRI time series from regions of\ninterest (ROIs). Drawing inspiration from vision transformer (ViT) [14] and its adaptation for multi-\nchannel biosignals [64, 20], our framework transforms raw EEG data into unified \"EEG patches\",\nenabling flexible and effective EEG data encoding. Further propelled by a recently proposed EEG\nfoundation model (LaBraM) [20], we incorporate and fine-tune the pre-trained foundation model as\nour spatiotemporal feature learning module, which has been trained to learn effective representations\non about 2,500 hours of various types of EEG signals. Moreover, as previous studies have emphasized\nthe importance of leveraging spectral features in EEG representation learning [64, 62, 65], EEG-fMRI\ncorrelations [25, 13], and EEG-to-fMRI synthesis [29, 46, 23], we build another parallel module that\nincorporates multi-scale encoding on EEG spectrogram patches. Specifically, instead of employing a\nfixed window size for the Short-Time Fourier Transform (STFT) as commonly used [64, 63, 22, 10],\nwe incorporate spectral features from windows of varying scales. This approach retains the advan-\ntages of high temporal resolution from smaller windows and high frequency resolution from larger\nwindows, thereby enhancing the spectral analysis. The output spectral embeddings are then integrated\nwith the embeddings derived from the above spatiotemporal encoding module, allowing NeuroBOLT"}, {"title": "Model Architecture", "content": "In this section, we introduce our model: NeuroBOLT, an innovative and general architecture for\ntranslating EEG signals to fMRI. Our model is designed to accommodate input EEG signals with\nan arbitrary number of channels. As shown in Figure 2, we leverage LaBraM [20] as our baseline\nto obtain spatiotemporal representations of EEG signals. Additionally, we propose multi-scale\nspectral feature fusion to obtain comprehensive spectral representations. These two modules learn\ncomplementary attributes of EEG data. Finally, we integrate the spatiotemporal and multi-scale\nspectral representations and feed them into a regression head for fMRI prediction.\nSpatiotemporal Representation. We formulate the multi-channel EEG signals as $X \\in \\mathbb{R}^{C \\times T}$,\nwhere $C$ represents the number of EEG electrode channels and $T$ denotes the time length of the\ninput EEG. To obtain the spatiotemporal representation of a given set of EEG signals, we leverage\nan operation from LaBraM [20], which segments the EEG signals into patches. Assuming the\ntime window length (patch size) for tokenization of EEG signal is $w$ and the stride is $s$, $X$ can be\nsegmented into $\\lfloor \\frac{T}{w} \\rfloor + 1$ segments, with each segment denoted as $x \\in \\mathbb{R}^{C \\times w}$. In this work, we\nuse a window of length $w$ and a stride $s = w$ to segment each EEG channel into patches, obtaining\n$x = \\{x_{cj,k} \\in \\mathbb{R} \\mid j = 1, 2, ..., C, k = 1,2,..., \\lfloor \\frac{T}{w} \\rfloor \\}$. The total number of patches is $C \\times \\lfloor \\frac{T}{w} \\rfloor$.\nThese patches are then passed forward to a temporal encoder [20] to obtain the patch embeddings,\ndenoted as:\n$\\begin{equation}\\n\\{e_{cj,k} \\in \\mathbb{R}^{d} \\mid j = 1, 2, ..., C, k = 1, 2, ..., \\lfloor \\frac{T}{w} \\rfloor \\}\\n\\end{equation}$\nwhere $d$ is the dimension of the embedding.\nTo enable the model to capture the temporal and spatial information of the patch embeddings, we\nset up a list of trainable temporal embeddings and spatial embeddings, denoted as $TE = \\{t_{ek} \\mid\nk = 1,2,..., \\lfloor \\frac{T}{w} \\rfloor \\}$ and $SE = \\{s_{ej} \\mid j = 1,2,..., C\\}$, respectively. Thus, the final segment\nembedding $e_{seg}$ can be represented as the sum of the output embedding, temporal embedding, and\nspatial embedding, denoted as:\n$\\begin{equation}\\nE_{seg} = \\{e_{cj,k} + t_{ek} + s_{ej} \\mid j = 1, 2, ..., C, k = 1, 2, ..., \\lfloor \\frac{T}{w} \\rfloor \\}\\n\\end{equation}$\nThe segment embedding $e_{seg}$ is directly fed into the Transformer encoder [57] to obtain the output\nembeddings. We then apply average pooling to these embeddings to obtain the spatial and temporal\nrepresentation $r_{st} \\in \\mathbb{R}^{d_{st}}$, where $d_{st}$ denotes the dimensionality.\nMulti-scale Spectral Representation. Compared to RGB images, EEG signals present several\nchallenges, such as a low signal-to-noise ratio, apparent stochasticity, nonstationarity, and nonlinear\ncharacteristics, making the reconstruction of the original signals difficult [48]. Previous research\nindicates that the frequency spectrum of EEG signals is crucial for understanding the brain's neuro-\nphysiological activities [64, 60]. Therefore, in our work, we utilize the Short-Time Fourier Transform\n(STFT) to achieve a spectral representation of EEG signals. Unlike most recent state-of-the-art\nmethods, we design a multi-scale spectral approach that captures both coarse and fine representations\nin the temporal and frequency domains [61, 43]. For the EEG signals $X \\in \\mathbb{R}^{C \\times T}$, we set the base\nwindow size as $w_{l}$ and define the window size at level $l$ as $w_{l} = w_{1} \\times 2^{l}$, where $l = 0, 1, ..., L$\nrepresents the level number. Thus each sample with a different window size can be denoted as\n$X \\in \\mathbb{R}^{C \\times \\lfloor\\frac{T}{w_{l}}\\rfloor}$. For each patch $x \\in \\mathbb{R}^{C \\times \\lfloor\\frac{T}{w_{l}}\\rfloor}$, we set the fast Fourier transform size to match the\nwindow length to obtain the spectrum of each patch as $s\\in \\mathbb{R}^{C \\times \\lfloor\\frac{T}{w_{l}}\\rfloor \\times (\\frac{\\lfloor\\frac{T}{w_{l}}\\rfloor}{2}+1)}$.\nFor each spectrum at level $l$, we set a list of trainable frequency embeddings denoted as $FE = \\{f_{el} \\mid\nl = 0,1,..., L\\}$ and a list of window embedding $WE = \\{w_{el} \\mid l = 0,1,..., L\\}$, obtaining the\nembeddings as follows:\n$\\begin{equation}\\n\\{f_{el} \\in \\mathbb{R}^{C \\times \\lfloor\\frac{T}{w_{l}}\\rfloor \\times d} \\mid l = 0, 1, ..., L\\}\\n\\end{equation}$\n$\\begin{equation}\\n\\{w_{el} \\in \\mathbb{R}^{C \\times n \\times d} \\mid l = 0, 1, ..., L\\}\\n\\end{equation}$\nWe calculate the sum of the $w_{el}$ for each patch of EEG to obtain an overall spectrum embedding as\n$e_{sp} \\in \\mathbb{R}^{C \\times n \\times d}$ as shown in equation 6\n$\\begin{equation}\\ne_{sp} = Sum(\\{w_{el} \\in \\mathbb{R}^{C \\times n \\times d} \\mid l = 0,1,..., L\\})\\n\\end{equation}$"}, {"title": "Experiments", "content": "In this section, we scrutinize the design of NeuroBOLT on the same unseen resting-\nstate recordings. Table 2 provides an ablation study on the contributions of each component in the\nNeuroBOLT model. The table reveals that the integration of the spectral learning module markedly\nenhanced the average prediction performance by 0.285 in R, underscoring the pivotal role of spectral\nfeatures in EEG-fMRI translation. Further, we examine the effectiveness of our multi-scale spectral\nrepresentation learning module by incrementally increasing the number of included scales. Increasing\nthe number of scales led to significant performance improvements in most of the ROIs.\nIn our model, the number of FFT points matches the token length. Therefore, larger window sizes\nproduce a spectrogram with higher frequency resolution but at the expense of capturing more rapid\nchanges in temporal dynamics (also see in Figure 3). We observe that fusing multi-scale spectral\nfeatures leads to better performance in capturing the projection from EEG to fMRI. Additionally, as\nshown in Table 2, different brain regions appear to prefer various numbers of scales, likely reflecting\ndistinct temporal-spectral dynamics across regions. Overall, the NeuroBOLT configuration with\nfour scales (13) achieves the best average performance. We have adopted this setting for all of our\nexperiments.\nGeneralization to task-related fMRI To evaluate the generalizability of our model trained on\nresting-state data to other conditions, we conducted the following experiments on the task dataset\ncollected from a different site with different scanner: (1) zero-shot generalization, where we pretrained"}, {"title": "Discussion and Conclusion", "content": "Contributions In this study, we propose NeuroBOLT, an innovative and versatile deep-learning\nsolution to project scalp EEG to BOLD fMRI signals. By learning a multi-dimensional EEG\nrepresentation from spatial, temporal, and spectral domains, NeuroBOLT shows a strong capability to\nreconstruct resting-state fMRI signals from EEG alone. In addition to subject-specific models, it can\nalso predict fMRI time series from held-out subjects across entire 20-minute scans, which is a first\nin this field. It is important to note that correlations of 0.4-0.5 are considered strong for predicting\nmoment-by-moment signal fluctuations in functional neuroimaging data, given the low signal-to-noise\nratio of EEG/fMRI. It is also worth mentioning that our model successfully reconstructs resting-state\nfMRI signals from deep subcortical regions like the thalamus, using raw EEG data with only 26\nelectrodes, enhancing the capabilities of EEG to map subcortical dynamics. This number of channels\nis typically insufficient to capture detailed neural activity from such regions using methods like\nEEG source localization [53]. Moreover, NeuroBOLT supports an arbitrary number of EEG input\nchannels, which allows for flexible and scalable application across different EEG setups, further\nenhancing its utility in a wide range of experimental and clinical settings. Overall, NeuroBOLT\nrepresents a significant advancement in the field of EEG-fMRI translation, which ultimately opens\nnew possibilities for non-invasive brain research and cost-effective clinical diagnostics.\nLimitations Currently, our model is trained separately for each brain region, which is inefficient\nfor the ultimate goal of high-resolution fMRI reconstruction. Since functional modules in fMRI\nalso co-fluctuate dynamically, our future work aims to develop an integrated training approach that\nleverages these co-fluctuations. By incorporating the interconnected nature of brain regions, we hope\nto enhance the model's ability to reconstruct high-resolution fMRI signals more efficiently."}, {"title": "Additional Results", "content": "In this section, we show more examples that reflect the best and the worst reconstruction performance\nover all ROIs in Figure 6. The total length of the scans is 1207.5 seconds. NeuroBOLT shows the\ncapability to reconstruct the whole resting-state fMRI scan over a large time range.\nNeuroBOLT leverages a multi-scale spectral representation for EEG-to-fMRI reconstruction. How-\never, its design could benefit from incorporating more advanced frequency representations, such as\nthe shift-invariant approach described in [43], which can facilitate model optimization. Additionally,\nwhile the current framework focuses on reconstructing a single arbitrary ROI per model, future\nwork could expand this by employing 3D decoders, commonly used in medical image analysis"}]}