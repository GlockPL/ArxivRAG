{"title": "Machine Learning-Based Estimation Of Wave Direction For Unmanned Surface Vehicles", "authors": ["Manele Ait Habouche", "Micka\u00ebl Kerboeuf", "Goulven Guillou", "Jean-Philippe Babau"], "abstract": "Unmanned Surface Vehicles (USVs) have become critical tools for marine exploration, environmental monitoring, and autonomous navigation. Accurate estimation of wave direction is essential for improving USV navigation and ensuring operational safety, but traditional methods often suffer from high costs and limited spatial resolution. This paper proposes a machine learning-based approach leveraging LSTM (Long Short-Term Memory) networks to predict wave direction using sensor data collected from USVs. Experimental results show the capability of the LSTM model to learn temporal dependencies and provide accurate predictions, outperforming simpler baselines.", "sections": [{"title": "I. INTRODUCTION", "content": "Unmanned Surface Vehicles (USVs) are gaining prominence across various applications such as marine exploration, environmental monitoring, and autonomous navigation. A significant challenge for USVs is accurately estimating wave characteristics, particularly wave direction.\n\nThe estimation of wave direction is a complex problem due to the dynamic and unpredictable nature of ocean waves. Traditional methods, such as wave buoys, satellites, and wave radars, are often constrained by high costs and limited spatial resolution [1]. Machine learning offers a promising alternative, as it does not depend on pre-defined mathematical models, which may not perform well under varying wave conditions [1]. This approach enables the prediction of wave characteristics directly from USV sensor data. Such capability is crucial for improving the safety and operational efficiency of USVS and minimizing risks during critical wave encounters [2].\n\nIn this context, this paper introduces a machine learning model that leverages LSTM (Long Short-Term Memory) networks to estimate wave direction from USV sensor data. This task is treated as a regression problem. The model's performance is assessed using real-world datasets, and the results indicate that our model outperforms simpler baselines.\n\nThe remainder of this paper is organized as follows. Section II provides an overview of our approach, while Section III evaluates the model's performance. Section IV presents related work, and Section V concludes the paper and opens some perspectives."}, {"title": "II. PROPOSED MODEL", "content": "Our model leverages an LSTM (Long Short-Term Memory) [3] network to predict wave direction based on the drone's navigation and orientation data. RNNs (Recurrent Neural Network) are neural network architectures specifically designed to process data sequences of variable lengths. LSTMs are a type of RNNs, capable of learning long-term dependencies. This is achieved through gating mechanisms that regulate the flow of information, enabling the network to retain or discard particular sequential information.\n\nA. Data processing\nThe data collected from the drone's IMU (Inertial Measurement Unit) undergoes the following pre-processing steps.\n1) Data cleaning and segmentation into transects: Noisy and irrelevant sensor readings, as well as data from periods when the drone is stationary or otherwise not relevant, are filtered out. This ensures that only meaningful data are retained. The cleaned data are then segmented into transects based on the drone's trajectory. This process is semi-automatic. Additionally, angular measurements such as roll, pitch, and yaw can exhibit discontinuities due to their cyclical nature (e.g., transitioning from \u03c0to -\u03c0). To address these issues, these measurements are transformed into their sine and cosine components.\n\n2) Sequence generation: To effectively capture the temporal dependencies in the drone's movement, which is significantly influenced by wave dynamics, the time series data of each feature are segmented into fixed-length sequences or windows. Each sequence includes n consecutive time steps.\n3) Standardization and train/test split: Given that the IMU measures different physical quantities with varying ranges and units, data need to be scaled to remove any potential biases. The standard score of a sample s for each feature i is computed as follows:\n\n$s_{i} = \\frac{s_{i}-\\mu_{i}}{\\sigma_{i}}$\n\nHere, $\\mu_{i}$ represents the mean and $\\sigma_{i}$ the standard deviation of the training samples for feature i. Following standardization, the data are divided into training and testing datasets. It is"}, {"title": "B. Model architecture", "content": "Figure 1 depicts the overall architecture of our model, which consists of three layers. The first layer, the data processing layer, prepares the raw navigation and orientation data into a format suitable for the next layers. The processed data are then passed to the LSTM layer, where they are sequentially processed through multiple LSTM cells. Finally, the output from the LSTM layer is fed into the feed-forward layer, which computes the wave direction as a vector of cosine and sine values.\n\nThe LSTM model is designed for a regression task and aims to predict the wave direction relative to the drone's movement. The data processing layer generates sequences of measurements over n time steps. However, only the first n-1 measurements are fed into the LSTM network. This enables the model to predict the wave direction for the final time step based on the preceding observations."}, {"title": "III. EVALUATION", "content": "A. Experiments\nExperiments were carried out using data from a USV (Unmanned Surface Vehicle) equipped with various sensors, including an Ellipse INS (Inertial Navigation System) for orientation and navigation and a GNSS (Global Navigation Satellite System) module with RTK (Real-Time Kinematic) positioning for location tracking.\n\nThe experiments were conducted in two distinct settings to validate the model's effectiveness across both controlled and real-world conditions.\n\nThe first setting was an experimental pool that features a wave generator capable of generating controlled wave conditions with specific heights and periods. In our experiments, waves with heights ranging from 10 to 20 centimeters and periods of 2 seconds and 2.5 seconds were generated. Ten different trajectories were tested.\n\nThe second set of experiments took place in the open sea. Six trajectories following a flower pattern were tested to evaluate the drone's response from multiple orientations relative to the wave direction. \nIn both settings, various PID values for the drone's steering rate and speed/throttle were tested to assess the model's performance under different operational conditions."}, {"title": "B. Determining ground truth", "content": "As detailed in Section II-B, the target variables are the sine and cosine components of the drone's movement relative to the dominant wave direction, which is computed by subtracting the wave direction from the drone's yaw.\n\nIn the controlled environment of the experimental pool, the wave direction is determined by the pool's heading, since waves consistently originate from a fixed direction. For the open sea experiments, historical weather data are obtained from WindGuru\u00b9, which provides sea state information for the testing location."}, {"title": "C. Training and test data", "content": "The data from the experimental pool is used to train our model. A total of 43,319 raw data points are collected across the 10 trajectories, with each trajectory lasting approximately 2 minutes.\n\nFollowing the pre-processing steps described in Section II-A, the dataset is reduced to 32,557 data points. This dataset is then split into training and testing datasets, with 80% of the data used for training and the remaining 20% for testing."}, {"title": "D. Evaluated metrics", "content": "Two metrics are used to evaluate the model's performance.\n1) MAPE (Mean Absolute Percentage Error): This metric [4] expresses the prediction error as a percentage. Its symmetric nature is particularly appropriate in our context, where both overestimations and underestimations need to be treated with equal importance to avoid directional bias. The formula for MAPE is:\n\n$MAPE = \\frac{1}{p}\\times\\sum_{i=1}^{p}\\frac{|predicted_{i} - actual_{i}|}{actual_{i}}$\n\n2) Angular score: To evaluate the accuracy of wave direction predictions, we define an angular score similar to RMSE (Root Mean Squared Error) but adapted for angular data, which are cyclic by nature. The predicted and actual values are first converted from their sine and cosine components"}, {"title": "E. Hyperparameters tuning", "content": "Tuning hyperparameters is a critical aspect of training recurrent neural networks, as highlighted in [5], to ensure training convergence and effective generalization of models when applied to new data. However, this tuning phase is computationally expensive, limiting the number of configurations that can be practically tested.\n\nBased on preliminary experiments, the number of training epochs is set at 50, the MSE (Mean Squared Error) is selected as the loss function, and the ADAM optimizer [6], widely used in deep learning, is employed as the optimization algorithm. In this section, the effect of four hyperparameters on model performance is discussed.\n\n\u2022 Sequence size. It represents the length of the input sequences fed into the LSTM network.\n\u2022 Hidden size. It represents the dimension of the hidden state in each LSTM layer.\n\u2022 Stacked LSTMs. This term describes the architecture of the LSTM network where multiple LSTM layers are stacked on top of each other.\n\u2022 Learning rate. It determines the magnitude of updates made to the model weights in response to the estimated error each time the model weights are updated.\n\n1) Sequence size: As illustrated in Figures 5a and 5b, the relationship between sequence size and model performance is not linear and appears to depend on other factors such as the number of hidden units and stacked LSTMs. While sequence lengths of 10 and 30 generally outperform a sequence length of 20, the optimal size depends on the configuration. \n\n2) Hidden state dimension: Increasing the number of hidden units improves performance up to a certain threshold. Moving from 10 to 20 hidden units often reduces the MAPE and improves the angular score. However, further increasing the number to 100 does not consistently yield better results.\n\n3) Stacked LSTMs: In our context, adding more LSTM layers does not improve model performance. For most configurations, a single LSTM layer provides better or comparable"}, {"title": "F. Comparison with baseline predictors", "content": "Table III presents a comparative evaluation of the proposed LSTM model against several baseline machine learning models commonly used in the literature. The selected models are Multi-Layer Perceptron (MLP), ResNet 18 [7], Convolutional Neural Network (CNN) [8], Transformer [9] and mLSTM [10].\n\nTo ensure a fair comparison, hyperparameters shared with our LSTM model are set to the same values. These included the learning rate for all models, sequence size and number of layers for Transformers and mLSTM, and hidden units for mLSTM.\n\nResults show that models designed for sequence processing (LSTM, mLSTM, and Transformers) outperform the other models (MLP, ResNet 18, and CNN) in predicting wave direction. Specifically, mLSTM and Transformers models achieve MAPE values of 11.66% and 11.70%, respectively, and angular scores of 2.85\u00b0 and 2.86\u00b0. While these two models perform well, the proposed LSTM architecture achieves slightly better results, with a MAPE of 10.52% and an angular score of 2.77\u00b0."}, {"title": "G. Evaluation on unseen data", "content": "The proposed model is evaluated using sea data that were not included in the training phase to assess its generalization capabilities. A total of 136,041 raw data points are collected across 6 trajectories. Each trajectory lasts between 6 and 14 minutes. After applying the pre-processing steps described in Section II-A, the dataset is reduced to 134,350 data points.\n\nThe model's angular error on these unseen data averages 40.34\u00b0. Figure 6 shows the predicted wave direction (after subtracting the drone's yaw) for the first trajectory, where the ground truth dominant wave direction is 280.2\u00b0. When applying a moving average with a window of approximately 12 seconds, the predicted wave direction becomes notably more stable."}, {"title": "IV. RELATED WORK", "content": "In [2], the authors aim to predict sea state parameters (significant wave height, peak period, and mean encounter wave direction) using data collected from a container vessel navigating the Northern Atlantic over a 1.5-year period."}, {"title": "V. CONCLUSION", "content": "In this paper, a predictive model leveraging an LSTM architecture is proposed to estimate wave direction using data from a drone's navigation and orientation sensors. The model is evaluated through experiments conducted in a controlled experimental pool and a real-world open sea environment.\n\nThe results highlight the model's potential to improve the navigation and operational safety of USVs in dynamic marine settings.\n\nFuture work will focus on expanding the dataset through further experiments in varied sea conditions and incorporating other maritime variables such as wind and current. This will help capture a broader range of scenarios and refine the model's accuracy. Additionally, we plan to adapt the model for real-time applications, addressing challenges such as optimizing energy consumption and minimizing inference times. We also intend to combine our wave direction prediction model with a reinforcement learning agent to simulate and assess the USV's behavior in complex and hostile environments, enhancing the robustness and autonomy of its navigation capabilities."}]}