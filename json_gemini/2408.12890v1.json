{"title": "Multiple Areal Feature Aware Transportation Demand Prediction", "authors": ["Sumin Han", "Jisun An", "Youngjun Park", "Suji Kim", "Kitae Jang", "Dongman Lee"], "abstract": "A reliable short-term transportation demand prediction supports the authorities in improving the capability of systems by optimizing schedules, adjusting fleet sizes, and generating new transit networks. A handful of research efforts incorporate one or a few areal features while learning spatio-temporal correlation, to capture similar demand patterns between similar areas. However, urban characteristics are polymorphic, and they need to be understood by multiple areal features such as land use, sociodemographics, and place-of-interest (POI) distribution. In this paper, we propose a novel spatio-temporal multi-feature-aware graph convolutional recurrent network (ST-MFGCRN) that fuses multiple areal features during spatio-temproal understanding. Inside ST-MFGCRN, we devise sentinel attention to calculate the areal similarity matrix by allowing each area to take partial attention if the feature is not useful. We evaluate the proposed model on two real-world transportation datasets, one with our constructed BusDJ dataset and one with benchmark TaxiBJ. Results show that our model outperforms the state-of-the-art baselines up to 7% on BusDJ and 8% on TaxiBJ dataset.", "sections": [{"title": "1 Introduction", "content": "A reliable short-term transportation demand prediction supports the authorities in improving the capability of transportation systems. However, this task is challenging because the transit demand prediction depends on the complex spatial and temporal correlation [1]. With the development of deep learning approaches to short-term transportation demand prediction, several models have been proposed to deal with the spatio-temporal complexity in transportation"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Spatio-temporal prediction methodology", "content": "For Euclidian dataset, a convolutional neural network (CNN) based spatio-temporal model is mainly used [2]. ConvLSTM [3] is a model modified for time series data by making 2D convolution in the matrix multiplication part of the weight parameter of a LSTM. STResNet [4] and DeepSTN+ [5] learn spatial information with 2D CNN for closeness, period, and trend, respectively, and time series temporal information with 1D CNN. DeepSTN+ is a slightly advanced form compared to STResNet in that it leverages a ConvPlus network, but both are similar as they are CNN-based models.\nFor non-Euclidian dataset, a graph convolutional network (GCN) based spatio-temporal model is mainly used [19,15]. DCRNN [20] proposes an RNN model through random walk-based diffusion convolution based on the distance of traffic sensor to learn graph-based spatio-temporal information. ASTGCN [21] leverages spatial and temporal attentional graph convolution mechanism on closeness, period, and trend components for road traffic prediction. GMAN [22] creates performs spatial attention with node embedding, and temporal attention, and combine with gated fusion."}, {"title": "2.2 Transit prediction with extra knowledge", "content": "A handful of researchers [5,4,13,6,15,23] have attempted to increase the prediction accuracy by using ancillary information about the area, such as POI"}, {"title": "2.3 Multi-graph spatio-temporal methodology", "content": "There are a few approaches that merges multiple graphs for spatio-temporal computation. DMVST-Net[24] suggests semantic view on top of spatial view and temporal view by creating data-driven semantic similarity graph by Dynamic Time Wraping for taxi demand prediction. ST-MGCN[14] proposes multi-graph convolution network consists of neighborhood, functional similarity, and spatial connectivity for ride-hailing demand forecasting. Wang et al. [25] proposes heterogeneous multi-graph convolution network consists of spatial adjacency, transport connectivity, and contextual similarity for ambulance demand forecasting. AGCAN [26] leverages data-driven attention-based adaptive graph to supplement along with physical connectivity graph for road traffic prediction."}, {"title": "3 Problem formulation", "content": "We define that the number of transportation areas is N, the number of input channels is $C_r$ (e.g. $C_x = 2$ for in/out demand of each area), and the demand (e.g., number of passengers who aboard/depart the bus) on each timestamp at $X_t \\in \\mathbb{R}^{N \\times C_r}$, and the spatial proximity graph between areas is $G_P$. Assume we want to use $K_N$ types of areal features, where k-th feature is $F_k \\in \\mathbb{R}^{N \\times V_k}$, where $V_k$ is the number of components of $F_k$ (e.g. $V_{LU} = 3$ when the land use feature $F_{LU}$ consists of commercial/residential/office). The transportation demand prediction problem can be defined as learning a model $f_{model}$ that predicts the next-step value from historical values as:\n\n$f_{model} (X_1, X_2, ..., X_{t-1}; G_P, F_{\\{1,...,K_N\\}}) \\rightarrow X_t$                               (1)"}, {"title": "4 Method", "content": ""}, {"title": "4.1 Overview", "content": "We propose spatio-temporal multi-feature graph convolutional recurrent network (ST-MFGCRN) described in Fig. 2a. Our method splits the historical value into"}, {"title": "4.2 Spatio temporal embedding (STE)", "content": "Spatio temporal embedding (STE) serves to capture and correct trivial spatio-temporal bias for each area. Compared to GMAN [22] that leverages STE that serves similar to positional encoding, our model directly adds to embedded input value. We preprocess the temporal embedding (TE) as $TE_t \\in \\mathbb{R}^{C_T}$ by concatenating each one-hot embedding of a time unit, where $C_T = 7 + 24 + 4 + 1$: weekday (7), hour-of-day (24), 15-min-unit-of-hour (4), national holiday (1). Then, we apply a two-stacked fully connected layer $f_{TE}: \\mathbb{R}^{C_T} \\rightarrow \\mathbb{R}^D$ to convert TE into D-dimensional hidden embedding. Moreover, we define a trainable spatial embedding $SE \\in \\mathbb{R}^{N \\times D}$ and make the spatio-temporal embedding as $STE_t = SE + f_{TE}(TE_t) \\in \\mathbb{R}^{N \\times D}$. Meanwhile, we extend the initial traffic input $X_t \\in \\mathbb{R}^{N \\times C_x}$ into $f_{in}(X_t) \\in \\mathbb{R}^{N \\times D}$ by applying a two-stacked fully connected layer $f_{in}: \\mathbb{R}^{C_x} \\rightarrow \\mathbb{R}^D$, and produce the traffic value embedding normalized with STE as $X_1 = f_{in}(X_t) + STE_t \\in \\mathbb{R}^{N \\times D}$ and use it as a next input of a module.\nHere, we share the same SE and $f_{TE}$ for different time units, while $f_{in}^{(c)}, f_{in}^{(p)}, f_{in}^{(q)}$ differently used for each $X_C, X_P, X_Q$."}, {"title": "4.3 Multi-feature aware GCGRU (MFGCGRU)", "content": "We propose a multi-feature aware GCGRU (MFGCGRU) by extending graph convolutional gated recurrent unit to compute multiple areal features inside GRU cell. At first, the model computes spatial proximity $G_P(A_{proxy})$ by a graph convolution. A proximity matrix is calculated from distances witsh a Gaussian filter as $A_{proxy}[i,j] = exp(-(d_{ij}/\\sigma)^2)$, where the $d_{ij}$ is the distance between i-th and j-th areas and $\u03c3$ is the standard deviation of distance values. After we conduct row-normalization as $A'_{proxy}$, we use this matrix as one of graphs computed in MFGCGRU.\nNext, in order to extract areal similarity matrix $A_k \\in \\mathbb{R}^{N \\times N}$ from areal feature $F_k$ to be used in MFGCGRU, we leverage attention mechanism as follows:\n$U_{k1} = ReLU(W_{k1}F_k) \\in \\mathbb{R}^{N \\times D}, U_{k2} = ReLU(W_{k2}F_k) \\in \\mathbb{R}^{N \\times D}$,\n$e_k = U_{k1}U_{k2}^T/\\sqrt{D}\\in \\mathbb{R}^{N \\times N},$\n$A_k [i, j] =  \\frac{exp(e_k[i, j])}{\\Sigma_o exp(e_k[i, 0])}$           (3)\nwhere $W_{k1}, W_{k2} \\in \\mathbb{R}^{D \\times V_k}$ are trainable parameters for each feature type k.\n$e_k$ is basically represents the similarity between $U_{k1}$ and $U_{k2}$ by applying dot product for each N X N area pairs.\nHowever, as more areal features are added, the model is congested and do not reflect the areal similarity due to the curse of dimensionality [28]. Inspired by a sentinel attention [29,30], we calculate the attention score for each area can be less than 1 by applying sentinel variable $S_k$, which allows an area to take partial attention when the areal knowledge is not beneficial. Our proposed sentinel attention is defined as follows:\n$S_k = f_{sent} (F_k || SE) \\in \\mathbb{R}^N,$\n$A_k [i, j] =   \\frac{exp(e_k[i, j])}{S_k[i] +  \\Sigma_o exp(e_k[i, 0])}$                              (4)\n, where $f_{sent}$ is a two-stacked fully connected layer with ReLU activation (which keeps $S_k \u2265 0$). We apply concatenation $(F_k || SE)$ to calculate sentinel variable differently for each area using spatial embedding.\n$x_r^{(t)} =  \\sigma  (\\frac{1}{K} \\Sigma_{k=1}^K  A_k (x_r^{(t-1)})  W_{rk}+b_r$ )\n$u^{(t)} = \\sigma (\\frac{1}{K} \\Sigma_{k=1}^K  A_k (x_r^{(t)} | H^{(t-1)})  W_{uk} + b_u )$\n$C^{(t)} = tanh (\\frac{1}{K} \\Sigma_{k=1}^K  A_k (x_r^{(t)} | (u^{(t)} \\circ H^{(t-1)})  W_{ck}+b_c )$\n$H^{(t)} = u^{(t)} \\circ H^{(t-1)} + (1-u^{(t)}) \\circ C^{(t)}$        (5)"}, {"title": "4.4 Weighted fusion network", "content": "From each MFGCGRU for $X_C, X_P, X_Q$, we get an output of $H_C, H_P, H_Q \\in \\mathbb{R}^{N \\times D}$, respectively. We apply a fully connected layer and a softmax to calculate the weights of importance, and produce final output with a two-stacked fully connected layer $f_{fusion} : \\mathbb{R}^D \\rightarrow \\mathbb{R}^{C_x}$ as follows, where $W_C, W_P, W_Q \\in \\mathbb{R}^{1 \\times D}$ are trainables:\n$e_m = W_mH_m \\in \\mathbb{R}^{N} (m \\in \\{C, P, Q\\}), \\ \\ \\ \\ \u03b1_m =  \\frac{exp(e_m)}{\\Sigma_{\\{C,P,Q\\}} exp(e_j)} \\in \\mathbb{R}^{N},$\n$\\hat{Y_{t+1}} = f_{fusion}( \\Sigma_{j}^{\\{C,P,Q\\}} \u03b1_j \\circ H_j ) \\in \\mathbb{R}^{N \\times C_x}$    (6)"}, {"title": "4.5 Objective function", "content": "The objective function is defined as $L(\u0398) = |\\hat{Y_{t+1}} - Y_{t+1}|_1$, where $Y_t \\in \\mathbb{R}^{N \\times C_x}$, which is the mean absolute error (L1) loss."}, {"title": "5 Evaluation settings", "content": ""}, {"title": "5.1 Dataset", "content": "We use two datasets in our experiments: our constructed BusDJ dataset and a benchmark TaxiBJ dataset. For the BusDJ dataset, we use the bus transit data of boarding and alighting demand in a 15-minute unit which we obtain from smart card data of Daejeon Metropolitan City. We construct the bus transit dataset of N = 102 hexagonal 800m grid areas except the areas containing no bus stop (e.g., hills, rivers). Then, we leverage six areal features representing land use, transit, and demographic features: (1) land use type (LU, VLU = 6), (2) place-of-interest (POI, VPOI = 29), (3), bus transit infrastructure (BUS, VBUS = 2), (4) population (POP, VPOP = 4), (5) enterprise and employments of each business type (ENT, VENT = 6), and (6) building area (BD, VBD = 7). The areal features are provided by the open data service of government institutions [31,32,33]. For benchmark TaxiBJ [13] dataset, we use two available areal features provided in the original dataset. We extract the 20 most frequent POI features among the original 648 types of POIS (VPOI = 20). We also use two ROAD features (the number of roads and lanes) as original data (VROAD = 2). The detailed description of both data is listed in Table 1."}, {"title": "5.2 Experiment settings", "content": "We set the number of time sequences as $L_c = 6, L_p = 7, L_q = 3$ in Eq. 2, and $C_x = 2$ for boarding and alighting demand. In training, we conduct min-max normalization on demand and areal features. We set the hidden embedded dimension for our model as D = 64. For other baselines, we use their default settings. We conduct our experiments on a single NVIDIA TITAN RTX 24GB environment with Tensorflow v1.15.1. For each model on each setting, we test five times and record the mean of each result. We adopt an ADAM optimizer with a learning rate of 0.01 and a batch size of 32. We apply early stopping with validation loss with 15 patience epochs. We evaluate models with root mean squared error (RMSE) and mean absolute error (MAE).We measure the error of $C_r$ input channels altogether."}, {"title": "5.3 Baselines", "content": "We compare the proposed model (ST-MFGCRN) with various methods for public transit prediction. We first use data-based prediction methods without model training as basic baselines: Trend Mean, Period Mean, Closeness Mean, and Last Repeat. We set CNN-based time-series deep learning models, such as ConvLSTM [3], STResNet [4], and DeepSTN+ [5]. We also compare our model with the graph-based deep learning models such as DCRNN [20], ASTGCN [21], STMGCN [14], and GMAN [22] by using proximity information $A_{proxy}$ described in Section 4.3. For STMGCN, we use cosine-similarity based adjacency matrix for each feature for graph computation. For ASTGCN and STMGCN, we use closeness, period, trend component same as our model. For other baselines, we use the default settings."}, {"title": "6 Results", "content": "We first analyze the feature influence by adding or removing each areal feature from our model to extract the most important areal feature combination. Then, we evaluate the performance of ST-MFGCRN by comparing it with baseline models on the BusDJ and TaxiBJ datasets."}, {"title": "6.1 Analysis of feature significance", "content": "To examine to what extent individual features improve prediction performance, we conduct a feature influence study by adding or removing features.\nFor the BusDJ dataset, Table 2 shows a significant error decrease when the proximity graph GP is provided, implying that geographical closeness essentially captures the basic spatial correlation and improves the performance. The experiment results by all combinations (when KN = 2,3,4,5) are omitted due to the space limit. We find that LU, ENT, and POI are the most significant areal features when added, as their errors decrease the most from {KN = 0,+GP} model. On the other hand, when we evaluate the most significant areal features when removed, we observe BD, ENT, and POI increase the most errors from {KN = 6,+GP} model. Throughout all experiments, the best setting is found as a combination of BD, ENT, POI, and LU.\nFor TaxiBJ dataset, Table 3 shows the POI and ROAD features do improve the performance significantly. The model shows the best result when it takes all the areal features as well as the proximity graph.\nThese results imply that each areal feature provides unique information about the urban environment, and multiple views of urban area supplements the overall performance."}, {"title": "6.2 Performance comparison", "content": "Table 4 shows the performance comparison of models on BusDJ and TaxiBJ datasets. Our proposed ST-MFGCRN shows an improved performance of 7% on BusDJ dataset and 8% on the TaxiBJ dataset compared to the state-of-the-art baselines such as DeepSTN+ and GMAN in terms of RMSE. Among the basic baselines, Trend Mean shows the best performance, which implies that the travel patterns are similar for the same hour and weekday every week. On the other hand, Closeness Mean and Last Repeat show high errors, indicating the need for a temporal correlation training model. Among the Euclidian area-based models, DeepSTN+ shows the highest performance as DeepSTN+ is more advanced than STResnet or ConvLSTM. In addition, ConvLSTM shows better performance than STResNet which leverages LSTM instead of 1D-CNN to find the temporal correlation. Among the non-Euclidian models, GMAN shows the highest performance compared to DCRNN and ASTGCN as it leverages spatial attention which allows attention on all other areas rather than graph convolution with fixed proximity values.\nWe also conduct experiments when we expand DCRNN with STE and closeness/period/trend (CPT) unit and GMAN with CPT unit, and find each component improves performance on these baselines. However, our ST-MFGCRN still outperforms as it leverages multiple features with sentinel attention and applies weighted fusion to utilize these components."}, {"title": "7 Conclusion", "content": "We propose ST-MFGCRN which allows exploiting various areal features during spatio-temporal training to tackle transportation demand prediction problems. To capture correlations depending on areal characteristics and spatial adjacency, ST-MFGCRN incorporates multiple similarity matrices calculated from different areal features and a distance-based proximity matrix. To calculate the similarity matrix of each areal feature, we leverage our proposed sentinel attention, which plays a role in taking partial attention when the knowledge is not helpful and harmoniously mixes various features. ST-MFGCRN captures temporal correlation by different time unit inputs of closeness, period, and trend, and spatio-temporal dependencies are also captured by spatio-temporal embedding. Our model outperforms the state-of-the-art baselines on the real-world dataset that we construct as well as on the benchmark dataset while successfully leveraging multiple areal features."}]}