{"title": "Ensemble of classifiers for speech evaluation", "authors": ["G. Belokrylov", "A. Korenev", "B. Lodonova", "A. Novokhrestov"], "abstract": "The article describes an attempt to apply an ensemble of binary classifiers to solve the problem of speech assessment in medicine. A dataset was compiled based on quantitative and expert assessments of syllable pronunciation quality. Quantitative assessments of 7 selected metrics were used as features: dynamic time warp distance, Minkowski distance, correlation coefficient, longest common subsequence (LCSS), edit distance of real sequence (EDR), edit distance with real penalty (ERP), and merge split (MSM). Expert assessment of pronunciation quality was used as a class label: class 1 means high-quality speech, class 0 means distorted. A comparison of training results was carried out for five classification methods: logistic regression (LR), support vector machine (SVM), naive Bayes (NB), decision trees (DT), and K-nearest neighbors (KNN). The results of using the mixture method to build an ensemble of classifiers are also presented. The use of an ensemble for the studied data sets allowed us to slightly increase the classification accuracy compared to the use of individual binary classifiers.", "sections": [{"title": "Introduction", "content": "Statistics on oncological diseases of the vocal tract [1] show that speech analysis methods in medicine do not lose their relevance today. At the same time, more and more attention is paid not only to methods of treating diseases, but also to methods of restorative medicine, namely speech and voice rehabilitation. In this case, only a slight decrease in the standard of living of patients after treatment is allowed. Rehabilitation measures should be carried out taking into account the individual characteristics of the patient and, if necessary, be adjusted.\nCurrently, the official (according to clinical recommendations) method of speech assessment is expert speech assessment using a method based on the GOST standard [2]. This method is proposed to be replaced by a method of quantitative automated assessment of the intelligence of syllable pronunciation using distance calculation algorithms and machine learning methods.\nMachine learning allows achieving greater efficiency in speech signal analysis by analyzing various user characteristics [3,4]. Therefore, it was proposed to continue research on the application of machine learning methods, namely classification methods. Previously, an evaluation algorithm was proposed based on representing audio signals as a sequence of values, reducing them to the same length using the dynamic time warp (DTW) algorithm, calculating the distance measure between the given sequences and using a fuzzy classifier as a mechanism for combining the calculated values and obtaining the final quantitative assessment. In this paper, we propose an analysis of the approach to constructing an ensemble of binary classifiers for assessing speech intelligibility in comparison with the use of individual binary classifiers."}, {"title": "Description of data and metrics", "content": "It is also worth noting that the use of an ensemble of binary classifiers for analyzing \"big\" data is used in various fields of knowledge, such as medicine, economics, and information security. For example, a combination of 2 or more classifiers can increase the accuracy of detecting DDoS attacks by an average of 5% compared to the accuracy of a single classifier [5].\nBased on a dataset of audio recordings of patients undergoing treatment and speech rehabilitation at the Tomsk National Research Medical Center oncology research institute [6], quantitative values of similarity and distance metrics were calculated. The set of recordings can be divided into three groups according to three problematic phonemes [k], [s], [t] for the disease in question. Distances were calculated as follows. Each patient had a control session (a set of syllable pronunciation recordings), which is the main one for comparison. The metric value was calculated for the syllable recording in the control and assessed sessions. Also, the recordings in the assessed sessions were assessed by a speech therapist by assigning a class label: 0 - syllable pronunciation in a low-quality recording (inaudible), 1 - syllable pronunciation in a high-quality recording (intelligible). Values were calculated for the following 7 metrics:\n1. DTW Distance \u2013 Path Cost Estimation in Dynamic Time Warping Algorithm [7];\n2. Correlation coefficient;\n3. Minkowski distance;\n4. Editing distance on real sequences - EDR [8,9];\n5. Edit distance on real sequences with penalty - ERP [8,9];\n6. Length of the longest common subsequence - Longest Common Subsequence LCSS [10,11];\n7. Distance MSM (Move Split Merge) calculation of the number of necessary actions (move, split, merge) to transform one sequence into another [12].\nThus, for each recording in all the sessions being evaluated, a vector of features-values for the metric and a label of the class to which the speech belongs are formed. Based on this label, the considered classifiers and ensembles of classifiers will be trained. For each of the problematic phonemes [k], [s], [t], a set of 1020 feature vectors with a class label was formed."}, {"title": "Selected classifiers", "content": "Since a binary classification is carried out, the classification methods that are most often used to solve this problem were selected for the study. The following 5 classification methods were studied:\n1. KNeighborsClassifier (Knn) - K Nearest Neighbors Method;\n2. RandomForestClassifier (RF) - Random Forest Algorithm;\n3. Support vector machines (SVC) - Support Vector Machine Classifier;\n4. Logistic Regression (LR);\n5. DecisionTreeClassifier (DT)."}, {"title": "Rebalancing and cleaning data", "content": "The original data sets are unbalanced, and class 1 prevails in them, it was decided to use methods of noise cleaning and rebalancing of the data sets. For noise cleaning, the quartile analysis algorithm was used. For rebalancing, the oversampling method was chosen using KMeansSMOTE (a combination of two methods for data balancing: K-Means and SMOTE (Synthetic Minority Oversampling Technique)).\nThus, for each of the problematic phonemes, 4 data sets were formed, on which classifiers were subsequently trained.:\n1. Original dataset;\n2. Dataset with cleaned noise;\n3. Rebalanced data set;"}, {"title": "Method of assembling classifiers", "content": "At this stage, the ensemble method of mixing models Blending was used. The essence of this method is as follows:\n1. Several basic models are created;\n2. Mixture model training: Base models are trained on a training dataset, and a metamodel is trained on the predictions made by each base model on an independent dataset;\n3. After training, a meta_X model emerges, representing the input data that can be used to train the metamodel. Each column or feature represents the output of one base model. Each row represents one sample from an independent dataset.;\n4. Then the training of the metamodel begins. It is provided with a classifier, which will be the main one in the training;\n5. Based on the combination of results from steps 1-4, the fit_ensemble function is constructed, which trains the mixture model using the training and independent validation datasets.;\n6. The mixture ensemble is used to make predictions on new data. It is a two-step process. In the first step, each base model is used to make predictions. The predictions are then pooled together and used as input to the mixture model to make the final prediction. The same cycle was used when training the model. That is, the predictions of each base model were pooled into a training dataset, the predictions were pooled together, and the predict() function was called on the mixture model with this meta-level dataset. The predict_ensemble() function implements these steps. Given a training list of base models, a training ensemble mixer, and a dataset, it returns a set of predictions for a dataset..\n7. The get_models() function was then used to create the classification models used in the ensemble. The fit_ensemble() function was then called to train the mixed ensemble on these datasets, and the predict_ensemble() function was used to make predictions on an independent dataset.."}, {"title": "Results", "content": "In this study, an attempt was made to apply an ensemble of binary classifiers to solve the problem of speech assessment in medicine. Binary classifiers were trained on three data sets containing quantitative and expert assessments of syllable pronunciation intelligibility. Also, based on these same classifiers, ensembles of classifiers were obtained using the Blending method.:\nFor the [k] phoneme dataset, the best result on a single classifier was the RandomForestClassifier with an accuracy value of 77.2%. The results were improved when using the Blending ensemble method. The best accuracy result of 78.6% was obtained by mixing the main SVC classifier with additional KNN, SVC, RandomForest and DecisionTree.;\nFor the [t] phoneme dataset, the best result for a single classifier was 86.3% accuracy on DecisionTree. Using the Bling ensemble method, the results were improved in 24 cases. The highest accuracy result of 87.0% was obtained 5 times, 2 times by mixing the main classifier with 2 additional ones and 3 times by mixing the main classifier with 3 additional ones.;\nFor the [s] phoneme dataset, the best result for a single classifier was 86.4% accuracy on SVC. Using the Bling ensemble method, the results were confirmed in two cases. The best result of 87% was obtained 2 times: when mixing the main DecisionTree with 3 additional KNN, SVC, LogisticRegression and when mixing the main RandomForest with 3 additional KNN, SVC, LogisticRegression.\nOn the [s] phoneme, the best result on a single classifier was 86.4 on SVC. Using the ensemble Blenging method, the results were improved in 2 cases. The best result of 87 was obtained 2 times, by mixing the main DecisionTree with 3 additional KNN, SVC, LogisticRegression, and by mixing the main RandomForest with 3 additional KNN, SVC, LogisticRegression.\nAccording to the results of this work, the accuracy results of individual classifiers were slightly improved when using the ensemble mixing method. In the future, other ensemble construction methods will be studied to improve classification accuracy and speech analysis quality assessment."}]}