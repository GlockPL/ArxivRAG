{"title": "Drone Carrier: An Integrated Unmanned Surface Vehicle for Autonomous Inspection and Intervention in GNSS-Denied Maritime Environment", "authors": ["Yihao Dong", "Muhayyu Ud Din", "Francesco Lagala", "Hailiang Kuang", "Jianjun Sun", "Siyuan Yang", "Irfan Hussain", "Shaoming He"], "abstract": "This paper introduces an innovative drone carrier concept that is applied in maritime port security or offshore rescue. This system works with a heterogeneous system consisting of multiple Unmanned Aerial Vehicles (UAVs) and Unmanned Surface Vehicles (USVs) to perform inspection and intervention tasks in GNSS-denied or interrupted environments. The carrier, an electric catamaran measuring 4m by 7m, features a 4m by 6m deck supporting automated takeoff and landing for four DJI M300 drones, along with a 10kg-payload manipulator operable in up to level 3 sea conditions. Utilizing an offshore gimbal camera for navigation, the carrier can autonomously navigate, approach and dock with non-cooperative vessels, guided by an onboard camera, LiDAR, and Doppler Velocity Log (DVL) over a 3 km\u00b2 area. UAVs equipped with onboard Ultra-Wideband (UWB) technology execute mapping, detection, and manipulation tasks using a versatile gripper designed for wet, saline conditions. Additionally, two UAVs can coordinate to transport large objects to the manipulator or interact directly with them. These procedures are fully automated and were successfully demonstrated at the Mohammed Bin Zayed International Robotic Competition (MBZIRC2024), where the drone carrier equipped with four UAVS and one manipulator, automatically accomplished the intervention tasks in sea-level-3 (wave height 1.25m) based on the rough target information.", "sections": [{"title": "I. INTRODUCTION", "content": "MARINE robotics has garnered significant attention in recent years due to its various applications in maritime security [1], environmental monitoring [2], and disaster response [3], rescue operations [4]. Compared to crewed vessels, marine robots offer significant advantages for executing repetitive tasks over extended durations and across large spatial scales, as well as for undertaking hazardous missions in poorly characterized or unknown environments. The deployment of unmanned systems for search and intervention operations results in increased inspection efficiency, improved operational capabilities, and a reduction in risks to personnel.\nThe complementary capabilities of USVs and UAVs have led to their increasing deployment as heterogeneous systems for maritime inspection and intervention. UAVs extend the operational range of USVs, enabling coverage of coastal zones [5], offshore energy infrastructure [6], and oil spill monitoring [7]. Moreover, UAVs enhance the effectiveness of USV-based search and rescue operations [8], [9]. Current approaches typically utilize Global Navigation Satellite System (GNSS) for localizing the heterogeneous system, which is remotely operated from a command center to execute predefined search and intervention tasks. In GNSS-denied environments, the heterogeneous system can be localized through sensor fusion, integrating inertial measurement unit (IMU) data with onboard USV sensors such as radar [10], LiDAR [11], or cameras [12]. Maritime intervention tasks, including marine rescues [13] and cargo handling (loading/unloading) [14], [15], present further challenges related to the trade-off between UAV payload capacity and the limited reach of onboard manipulators [16]. Furthermore, these robotic systems are vulnerable to disruptions, particularly in adverse weather conditions such as high sea states and dense fog, which can degrade data links and GNSS availability. Intentional interference from unauthorized vessels or within restricted areas also poses a threat to system integrity and can potentially lead to complete system failure.\nThe proposed drone carrier is specifically designed for autonomous maritime inspection and intervention operations in GNSS-denied or GNSS-challenged environments. Its modular design allows for scalable configurations, ranging from a minimal deck size of 2m x 1.5m, accommodating a single UAV, to a maximal configuration of 8m x 7m, capable of deploying 12 standard UAVs and a robotic manipulator, thereby adapting to diverse operational requirements. The USV is equipped with multiple sensors for localization and navigation, including a DVL, an IMU, LiDARs, cameras, and infrared thermal imagers. Data from these sensors are processed by an onboard computer, with only essential information transmitted to the command center to facilitate informed decision-making. The unobstructed, open deck provides ample space for UAV takeoff and landing, with QR codes assisting UAV precise landing adjustments, compensating for variations in altitude and sea state. Six UWB transceivers mounted above the deck establish a local positioning system for the UAVs, while two 2.4 GHz antennas provide data link connectivity between the drone carrier, the command center, and other carriers. An enhanced Wi-Fi network within the carrier facilitates communication between onboard sensors and the UAVs. To ensure compatibility, each UAV is equipped with an integrated system comprising an onboard computer, a downward-facing landing camera, and a UWB transceiver. Initial navigation of the overall system relies on an onshore camera, transitioning to onboard sensor-based navigation once targets are detected by the USV's onboard cameras or LiDARs. The proposed drone carrier is the only team to successfully complete inspection and intervention tasks in a sea-level-3, GNSS-denied sea environment during the MBZIRC2024 demonstrations\u00b9. The main contributions of this paper include:\n1) Design of a modular USV-based Drone Carrier. The carrier is equipped with integrated multi-domain sensors, intelligent drones and a manipulator, enabling it to perform investigation and intervention tasks in GNSS-denied sea environments. Its fully electric and modular design supports environmental sustainability and is adaptable to specific operational scenarios.\n2) Robust, integrated multifunction robotic System. This software architecture, specifically designed for inspection and intervention operations in GNSS-denied sea environments, includes multiple drones and manipulators. It features four foundational layers-perception, recognition, decision, and action-crafted to enhance the autonomy of the system, eliminating the need for human intervention.\n3) Comprehensive experimental validation. Extensive tests conducted in real sea environments (with a wave height of 1.5 m and a wind speed of 8 m/s) demonstrate the system's capabilities. These tests include approaching and docking with a non-cooperative target vessel, performing intervention tasks using a manipulator, and transporting small targets via drone. These trials illustrate the system's ability to autonomously execute inspection and intervention tasks in challenging GNSS-denied conditions."}, {"title": "II. RELATED WORK", "content": "Autonomous inspection and intervention in the sea environment is a harsh task since multiple robotics systems are required to cooperate considering mission constraints and environmental disturbances. Thanks to the natural complementary of UAV and USV, the current solution uses a USV-UAV heterogeneous system, collaboratively conducting searching and transportation tasks [8], [18], [26]. Multiple onboard sensors on both UAV and USV monitor the system condition and obey the decision from the remote command center. Early implementations of UAV-USV systems for coastal inspection, as described in [5], emphasized the need for high levels of vehicle autonomy for effective collaborative platforms and swarm deployments. Subsequent research has explored various applications, including harmful algal bloom mitigation using UAV-based detection and USV-based removal [29], inspection of offshore energy infrastructure using UAVs and visual tracking of the USV [6], and disaster management, where UAVs tracked USVs to assess littoral structural damage following Hurricane Wilma [17]. UAV-USV systems have also been employed in oil spill monitoring [7] and search and rescue operations [8], [9]. Vision-based USV navigation aided by UAVs has been investigated [19], and the critical process of UAV landing on a USV has been studied through numerical simulations using relative motion modeling [22], [30].\nAchieving close coordination within these heterogeneous UAV-USV systems requires autonomous UAV takeoff and landing on the USV platform. Unlike landing on static ground platforms, autonomous landing on a moving and oscillating USV necessitates robust state estimation, dynamic motion coupling between the UAV and USV, and stable UAV flight control. Huang et al. [22] implemented Adaptive Sliding Mode Control, demonstrating robustness in landing tasks despite environmental disturbances and uncertainties. Shao et al. [20] developed a cooperative platform for secure UAV landing on a vessel deck, using four ultrasonic sensors on the USV deck to guide the UAV to the landing area. Tian et al. [27] demonstrated that estimating the USV's oscillatory state and landing within a reasonable oscillation range significantly improves UAV landing precision and success rate.\nMost unmanned maritime systems rely on GNSS and IMUs for localization and state estimation. However, GNSS signals are vulnerable to both intentional and unintentional interference, rendering them unreliable in certain environments, particularly in coastal waters where GNSS jamming is increasingly prevalent. Consequently, alternative navigation solutions are crucial for safe operation. Several studies have addressed localization in GNSS-denied environments. Liu et al. [31] explored a visual-inertial odometry approach for USV localization, while Shen et al. [11] combined LiDAR data with IMU information. However, these LiDAR and vision-based methods require distinct environmental features for effective localization, which may be lacking in open sea areas. Han et al. [10] proposed a radar-based USV localization method using extracted coastal landmarks. Ma et al. [12] discussed a radar-based coastal image registration technique, integrating offline satellite imagery with radar data for localization. While effective, radar-based solutions are typically expensive and power-intensive, making them less suitable for energy-constrained USVs."}, {"title": "III. HARDWARE DESCRIPTION", "content": "Inspection and intervention in the GNSS-denied marine environment require a robust platform that conducts multiple tasks in facing environmental uncertainty. The system is designed to operate in an open ocean environment, relying on approximate target location information to autonomously search, approach, and dock with a target. Once docked, the system issues takeoff commands to drones and continuously provides target location information. After the drones complete their search and transport tasks, the system guides them to land at designated locations and subsequently return to the base. To accomplish these tasks, the drone carrier system is required to finish: searching, approaching and docking, single-drone transport, and collaborative transport. The hardware subsystems include the USV, UAV and robotic arm system. One typical configuration of the proposed drone carrier consists of a 4m x 7m drone deck, carrying 4 DJI-M300 drones and 1 manipulator as illustrated in Fig. 1. The following assumptions and constraints are considered for our drone carrier operations:\n1) The operational environment is not higher than sea state 3, with wave heights not exceeding 1.5m and atmospheric visibility greater than 2 km.\n2) The USV is able to access to prior information about the target from the onshore-aided navigation, including its approximate location with an accuracy of 50m and a limited number of target photographs.\n3) The USV is capable of docking and attaching only onto target vessels no more than twice its size and rely on the presence of well-defined edges on the target vessel for its latching mechanism to secure hard holding."}, {"title": "B. USV System", "content": "The USV system, serving as the core component of the drone carrier, features a modularized catamaran design integrated with onboard sensors. The catamaran's configuration can be adjusted based on the required search area, operational scope, and the number of UAVs it needs to carry. All onboard sensors are housed separately from the catamaran structure, yet they effectively control the speed and orientation of the dual motors.\n1) Catamarans component: The USV system consists of a modular catamaran structure. Due to the inherent stability of catamarans, it can maintain stable navigation even under moderate adverse ocean conditions. The catamaran hull is composed of propulsion modules and non-propulsion modules: Device Compartment: Includes power batteries, propellers, and steering mechanisms to provide forward propulsion for the USV and enable vector control. Support Compartment: Composed of hollow chambers with moderate shaping capabilities. The structure is symmetric about its central axis to enhance structural interchangeability and mold reusability. These modules can be flexibly assembled according to mission requirements, adapting to a variety of tasks.\nThe two hulls of the catamaran are connected by a truss structure, which can also be adjusted to modify the width of the USV based on the number of drones it carries. The docking side of the USV is equipped with a common docking and securing device. This device uses a spring-adhesion mechanism installed on the underside of the hull to fix the USV to the target vessel, and a mechanical docking hook mounted on the deck to secure the vessel mechanically. A collision detection system is installed at the base of the docking hook, i.e., Fig. 1 (e), and linked to a release pin mechanism. Upon collision, the hook is released and attaches to the edge of the target vessel's deck. Through research and analysis, the combined docking hook and adhesion mechanism design is suitable for docking with most medium-sized manned and unmanned vessels, enabling autonomous docking in ocean environments. The modular assembly of the USV can be completed within a day, according to the hull size and mission characteristics.\n2) USV onboard sensors: All the sensors in a drone carrier is illustrated in Fig. 3. The USV is equipped with various sensors for detection: LiDAR sensors mounted around the hull for 360-degree radar coverage; gimbal for directional coverage and target search; DVL for underwater detection and speed feedback; Compass to output the USV's heading; IMU for attitude measurement; Data links for long-range communication and networking with other drone carriers, UAVs and offshore command centre.\nThe LiDAR models used in this study are LIVOX HAP and LIVOX MID360, with point cloud data read via the manufacturer-provided ROS driver. Upon connection to the LiDAR, the driver publishes point cloud data in the point-cloud2 format in ROS. The point cloud is then processed using the Point Cloud Library (PCL) for operations such as cropping, filtering, transformation, and feature extraction. The DVL model utilized is DVL-A125, with data acquisition facilitated by the manufacturer-provided ROS driver. The onboard computer handles tasks such as reading and processing LiDAR point cloud data, receiving fused state information from IMU and DVL, and controlling the propeller speed and thrust direction of the USV.\nAll these onboard devices are networked via a router installed in the hull, forming an onboard network. An onboard computer processes data, records mission parameters, and assigns tasks, relaying critical information back to the command centre."}, {"title": "C. UAVs", "content": "The GNSS-denied search and transport drone for marine environments is based on a mature drone platform, with environmental adaptability improvements incorporated into its design. To begin with, the drone's landing gear has been widened to accommodate the swaying motion of marine platforms. Anti-slip foot pads have been added to ensure stability on wet and oscillating platforms. Besides, by installing UWB antennas at various positions on the drone's body, the impact of body structure occlusion on UWB antenna signals is effectively reduced, thereby improving positioning accuracy. Thirdly, landing in conditions involving strong winds, motion, and oscillation introduces significant uncertainty. To address this, the drone integrates anti-interference control logic and a wide-angle landing camera installed at the tail, enabling reliable detection and recognition of landing markers on the deck of the USV at various altitudes and positions. This enhances the success rate of landing and recovery operations. Last but not least, the multi-functional robotic gripper, designed specifically for the drone carrier system, must operate under the condition of a drone landing accuracy of 20 cm. It can grasp standard containers with dimensions of 30 cm \u00d7 20 cm and a thickness of no more than 10 cm, also maintains a stable grasping performance in high-humidity and high-salinity environments."}, {"title": "D. Manipulator", "content": "The drone carrier equipped with a robotic arm enables precise target searching within a specific range through a camera mounted on the end of the robotic arm. The arm is also equipped with a gripper to grasp and transport heavier objects. Fig. 5 illustrated two typical grippers mounted on the manipulator applied in the marine transportation task: the mechanical gripper with stereo motor automatically grasps and clamps the object through the lead screw nut mechanism. The suction cup gripper (EVS08) can grasp large-volume but surface-flat objects, like board or box. However, utilizing a robotic arm for object transportation in marine environments presents several challenges, such as the relative motion and oscillation between vessels, which result in random target movements. These dynamics increase the requirements for the manipulator's operational range and precision.\nTo ensure the stability of path planning to the greatest extent, the robotic arm's path planning is implemented using the MoveIt package in ROS. Considering that the AUBO robotic arm lacks an API for circular motion, trajectory planning is achieved by sampling points along the trajectory and fitting them with linear segments. Path planning is required during both the target grasping phase and the target returning phase. The MoveIt package is generated based on the URDF model of the robotic arm, abstracting the robot into configuration space (C-Space). The target's pose information, provided by the vision system, is used to invoke the Motion Planning Library (OMPL) to generate motion trajectories for the robotic arm automatically. MoveIt further processes the trajectory points returned by the planner according to the robot's control parameters (e.g., speed and acceleration limits) to produce a complete trajectory, including timestamps, position, velocity, and acceleration information. The trajectory is executed by invoking the AUBO robotic arm's API, reproducing the planned trajectory.\nTo ensure stable motion, the robotic arm is controlled in the ROS environment. The URDF file of the robotic arm is used to generate the MoveIt package, and the control program relies on multiple function packages to interact with the AUBO robotic arm's API. Custom coordinate transformation matrix functions are developed to achieve precise control of the robotic arm's trajectory and orientation. Self-collision avoidance is implemented by modifying the URDF file to include data for the end effector, camera base, and camera. A comprehensive URDF file is generated, enabling extensive sampling of the robotic arm's motion using MoveIt to avoid self-collisions. Environmental collision avoidance also leverages the MoveIt package. MoveIt provides a planning scene monitoring module that detects obstacles within the robot's environment. By modeling and exporting environmental obstacles, collision-free paths can be planned. Target grasping relies on the EVS08 suction cup or a custom-developed grasping mechanism. The robotic arm controls the suction cup's position and orientation relative to the target object and invokes specific functions to perform grasping. Through precise end-effector pose, velocity, and acceleration control, the stability of the grasping process is ensured. The vision system provides the \"grasping position relative to the camera coordinate system.\" The robotic arm is controlled to move to the corresponding pose, with the target's information indicating a vertically upward pose. The robotic arm's control algorithm executes a top-down tracking motion, driving the suction cup to complete the grasping task.\nThe installation schematic of the robotic arm on the USV is shown in Fig. 1 (c). To balance the weight, the power supply and control cabinet for the robotic arm is installed on the opposite side of the USV. The robotic arm is equipped with a stereo camera, a spring-loaded gripper mechanism, vacuum suction cups, and waterproof adhesive, enabling the identification and manipulation of target objects in complex marine environments."}, {"title": "E. System Communication", "content": "The USV communicates with nearby drones through onboard Wi-Fi and with distant drones via a data link. The manipulator's control cabinet is connected to the onboard router via an Ethernet cable, integrating the robotic arm into the system for sending and receiving commands. UWB modules of varying heights are installed at the corners of the deck, fused with vessel pose information to establish a coordinate system with the USV's centre as the origin and the forward-left-up directions as the axes. By measuring the position of the UWB module on the drone within this coordinate system, the drone's local positioning is achieved.\nIn addition, each drone landing position is equipped with a QR code composed of differently-sized patterns. These QR codes provide precise landing position information for drones of varying altitudes, enabling stable landings despite platform fluctuations and wave disturbances."}, {"title": "IV. AUTONOMOUS APPROACHING, DOCKING AND TRANSPORTATION IN GNSS-DENIED SEA EXNVIRONMENT", "content": "The operational flowchart for the drone carrier performing wide-range inspection and transportation tasks is presented in Fig. 7. The simplified control model cannot provide the sway force that can only be used in the long-range navigation and approach. For the attaching or the docking process, we use the Thruster Rotation Model. The actuation force can be expressed as:\n\n$\\T_{act-r} = \\begin{bmatrix}\nT_1 \\cos (\\theta_1) + T_2 \\cos (\\theta_2) \\\\\nT_1 \\sin (\\theta_1) + T_2 \\sin (\\theta_2) \\\\\ndT_1 \\cos (\\theta_1) - dT_2 \\cos (\\theta_2)\n\\end{bmatrix}$"}, {"title": "B. Step 1: Offshore Navigation and Approaching", "content": "The offshore localization and navigation in a GNSS-denied environment are achieved using an onshore gimbal camera, as illustrated in Fig. 2(d). While the detailed methodology is discussed in a previous study [32], this work integrates the entire localization process, linking the onshore camera to the target vessel. The approaching process can be divided into two phases.\nOnshore gimbal camera navigation: Initially, an onshore 2-axis gimbal camera detects both the drone carrier and the target. This shore-based gimbal camera can be installed on tall towers or drones hovering along the shoreline. The drones use downward-facing vision to autonomously localize the camera, ensuring precise determination of the camera's position. Using YOLOv5 [33], the system autonomously identifies target vessels and USV. By adjusting the gimbal Euler angles, the identified targets are kept centered within the frame. The target's position is then calculated using the trigonometric relationships depicted in Fig. 8(a).\nThe position of the gimbal Camera can be predefined as $P_{GC} = [0,0,h_{GC}]^T$ in the FLU frame. Given the camera's Euler angles in the GC frame, denoted by $\\theta_{GC}$ and $\\varphi_{GC}$, indicate the horizontal and vertical angles of the camera, the target position under GC frame, $P_{TV}$, can be computed by:\n\n$\\P_{TV}^{GC} = \\begin{bmatrix}\nX_{AGC}^{TV}\\\\\nY_{AGC}^{TV}\\\\\nZ_{AGC}^{TV}\n\\end{bmatrix} = h \\begin{bmatrix}\n\\frac{\\sin (\\theta_{GC})}{\\tan (\\varphi_{GC})}\\\\\n\\cos (\\theta_{GC}) \\\\\n\\frac{1}{\\tan (\\varphi_{GC})}\n\\end{bmatrix}$\n\nIt is important to note that when state variables are derived solely from geometric relationships, the measurements between frames are uncorrelated, leading to considerable variability and uncertainty. To mitigate this, we implement the Extended Kalman Filter (EKF), which effectively integrates information across multiple frames while accounting for non-linear dynamics, thereby enhancing estimation accuracy and robustness. Using the estimated USV orientation, $\\beta_{DC}$, the USV navigates towards the target vessel by calculating the yaw angle between the USV and the target.\n\n$\\beta_{DC} = \\theta^{I}_{IMU} - atan2(\\frac{Y^{GC}_{CC} - Y^{GC}_{XGC}}{X^{GC} - X^{GC}_{CC}})$"}, {"title": "C. Approaching and Docking", "content": "As described in Sec. IV-B and IV-D, the entire approaching and docking process is divided into five phases in the field test:\n\u2022 I: Preparation Phase\n\u2022 II: Onshore GC Guidance Phase\n\u2022 III: USV Onboard GC Guidance Phase\n\u2022 IV: Measurement and Docking Phase\n\u2022 V: Docking Complete Phase"}, {"title": "D. Step 2: Autonomous Docking", "content": "The onboard LiDAR of the USV has a maximum detection range of 200 meters. Upon identifying the target vessel using point cloud data, the USV autonomously generates a reconnaissance path, maintaining a circular trajectory around the target at a 50-meter radius. During this process, the USV scans and models the target, producing detailed 3D dimensional and orientation data of the vessel. While this step has been thoroughly described elsewhere, a brief overview is provided here:\nMeasurement: Five LiDARs are strategically placed to capture complete point clouds without blind spots, employing approximate time synchronization at 5 Hz to ensure accurate measurements. Filtered point clouds remove noise, low-intensity points, and outliers, and are segmented into clusters using Euclidean distance and KD-Tree search methods. Clusters are enclosed by optimal rectangles using a variance-based fitting algorithm that minimizes squared errors. For dock alignment, an L-shape fitting algorithm [34] determines the heading angle by modeling the dock as two perpendicular lines, enhancing navigation accuracy in real-world environments.\nNavigation: We utilize the Dubins curve [35] to design an autonomous docking path for the USV [35]. We segment the curve into stages with variable turning radii to enhance flexibility, constrained by the USV's weight, length, and speed range. Assuming minimal turning radius & is proportional to the current velocity Vi, and neglecting roll and pitch effects.\nDocking: After completing the 3D modeling of the target vessel, the system transitions to the docking phase. This phase primarily involves mechanically connecting the USV to the target vessel to release a UAV for reconnaissance and transport tasks. During the circling phase, the USV selects the long side of the target vessel for docking. Using LiDARs to monitor the target vessel's position in real-time, the USV manoeuvres toward the selected side. The USV utilizes vector propulsion for lateral movement to approach the target vessel. When the USV contacts the target vessel, a mechanical docking hook is automatically released to establish a mechanical connection between the two vessels.\nOnce the LiDAR confirms the USV is securely positioned alongside the target vessel, the system will determine that docking is successful and proceed to the detailed search and transport phase."}, {"title": "E. Step 3: Searching and Transporting", "content": "The search and transportation process of the drones in UWBs frame is illustrated in our previous works [36], [37]. Here we link the methodology of automatic and localization into a whole process. This process can be divided into two parts: namely localization and grasping.\nUAV and target localization: As illustrated in Fig. 9(a), a robotic arm mounted on the USV uses a stereoscopic camera at its end to scan the target vessel. A rough object position under a manipulator frame $P_{CC}$ is transfer into the drone carrier frame:\n$\\P_{OC}^{DC}=R_{MA}P_{A}^{MA}$\n\nwhere $R_{MA}$ is the rotation matrix from the stereoscopic camera (endpoint of manipulator) to the drone carrier frame. The location is sent to the searching drone and takes off using the QR code according to the works from [38]. Once the QR code is out of the camera's view, the UAV switches to UWB-based localization, calculating its position via trilateration [39]. To enhance stability, an Extended Kalman Filter (EKF) fuses IMU data for smoother localization [40], while singular elimination and mean value filtering refine target positions [41]. Velocity estimation, $\\dot{c}_t$, employs a Kalman Filter [42]. Addressing the Coverage Path Planning (CPP) problem for the deck, a spiral pattern is adopted for efficient coverage [43]. UAV movement follows rigid body dynamics [44], with a PID controller mitigating nonlinear disturbances and marine perturbations [45].\nObject grasping: The grasping UAV autonomously descends above the target object, deploying a mechanical gripper to establish a secure connection with the object. Once secured, the UAV lifts off and uses UWB for real-time positioning. The UAV identifies a QR code on the USV to facilitate precise landing.\nFor objects that cannot be transported by a single UAV, coordinated transport involving multiple UAVs and a robotic arm is employed. As illustrated in Fig. 9, the manipulator allocates the big object and obtains the position of the big object under the MA frame: $PO_2A$. This position is converted to the searching drone frame by a rotation matrix by Eq. (9). Two searching UAVs are taking off and navigating by the localization information from the fusion of UWBs and USV onboard IMU. Using the vision-based object caption, the big object's position is allocated under the frame of each UAV, $PO_2$ and $PO_2$. Each UAV hovers at one end of the large object, lowers its altitude, and positions a flexible tether attached to both UAVs along one side of the object. The UAVs then collaboratively drag the large object towards the manipulator. Meanwhile, the manipulator assesses the distance to the object by visual sensors. Once the object is within the arm's operational range, the robotic arm manipulates it and transports it onto the USV."}, {"title": "V. FIELD TEST AND RESULT", "content": "The entire field test is performed in the waters near Yas Island, Abu Dhabi, under strict supervision by a third party (@ASPIRE). The test area spanned 3 square kilometres and included one target vessel and seven interference vessels (as illustrated in Fig. 10 (b)). To simulate a GNSS-denied environment, all GPS antennas on the equipment, including the antenna on the DJI-300 drone, were removed. Fig. 10(a) illustrates the complete path of the drone carrier during the approach and docking phases.\nFig. 10 (a) shows the source of the drone carrier's heading information and its corresponding position and heading during these phases. In the subsequent three phases, the expected heading of the drone carrier is provided by the onshore gimbal camera (Fig. 10 (a-1)), the USV onboard gimbal camera (Fig. 10 (a-2)), and radar (Fig. 10 (a-3)). The drone carrier's onboard control algorithm adjusts the speed of the two motors while continuously correcting its heading to approach the desired heading, ultimately achieving the control objective. In phase V, the drone carrier attaches to the target vessel with the docking hook, but still rolling under the sea wave. The data indicate the reality of the test result and the proposed navigation framework for the drone carrier can successfully operate in a GNSS-denied environment.\nOnce the onboard radar captures the target vessel, the radar displays the target's position in real-time within the drone's system in Fig. 10 (c) under the DC frame. Using Dubbin's curve trajectory planning, the algorithm estimates the target vessel's orientation (Fig. 10 (d-1)) and approximate length (Fig. 10 (d-2)) and width (Fig. 10 (d-3)), providing initial state information for docking and fine-tuning the search. Fig. 10 (e) shows the heading angle data over the entire duration of the test. The first view of the onshore gimbal camera is listed in Fig. 11 (a), and drone carrier autonomous approaching and docking to a target vessel in Fig. 11 (b)."}, {"title": "A. Small Object Detection and Grasping", "content": "Once the drone carrier completes its secure attachment, a takeoff command is issued to the UAV, which then ascends into flight (Fig. 11 (c-1)). Guided by the USV onboard UWB system and utilizing the pre-determined dimensions of the target vessel provided by the USV's radar, the UAV navigates to the centre of the target vessel before initiating a lateral search along its sides. Leveraging its onboard recognition system, preloaded with the target object's images, the UAV identifies the target, hovers vertically above it (Fig. 11 (c-2)), and engages its mechanical gripper to attach the target object securely (Fig. 11 (c-3)). After completing this task, the UAV takes off again, uses UWB positional data to return to the launch point, and performs a precision landing guided by the QR code at the designated location (Fig. 11 (c-4)).\nThe path and positional trajectory of the drone during the transportation process are illustrated in Figure 1. In Fig. 12 (a), the drone takes off from the carrier, conducts a search and land on the object. Fig. 12 (b) depicts the drone's flight with the target and its subsequent landing back on the unmanned carrier. Several key points (P) in these figures represent the takeoff position in the carrier's coordinate system (Po), a position 3 meters above the takeoff point (P\u2081), 3 meters above the target location (P2), and the actual target position (P3), respectively. These positions are measured by the integration of USV onboard UWBs and IMU. However, due to the oscillatory marine environment, IMU errors accumulate throughout the process, leading to significant positional deviations during the drone's return. To ensure a reliable landing, positional information from QR codes is utilized during the taking off and landing phase, effectively enhancing system reliability.\nMaritime testing does not include the operation of a robotic arm or the transportation of large objects using multiple drones; hence, these aspects are not highlighted here. System recovery is achieved by retracting the fixed hook via a winch, releasing the connection between the unmanned vessel and the target ship, and returning to the shore using angular information provided by the onshore gimbal camera."}, {"title": "VI. CONCLUSION", "content": "This paper presents the design and development of a modular USV-based drone carrier system tailored for maritime inspection and intervention in GNSS-denied environments. The system integrates state-of-the-art sensors, intelligent drones, and a manipulator, embodying a robust, multi-functional robotic architecture. Its fully electric and modular design not only aligns with sustainable operational goals but also enables adaptability to diverse and challenging maritime scenarios. The proposed system has demonstrated significant advancements in autonomous capabilities through extensive experimental validation in both simulated and real-world sea conditions. These trials have confirmed the effectiveness of its perception, recognition, decision-making, and action layers, achieving seamless coordination between the USV and multiple UAVs. The system's ability to autonomously dock with non-cooperative vessels, perform intervention tasks using manipulators, and transport small targets via drones highlights its potential to address complex maritime challenges with minimal human intervention.\nFuture research will focus on expanding the carrier's capabilities, including enhancing multi-drone cooperation, refining manipulator precision, and improving system resilience under extreme environmental conditions. These efforts aim to advance autonomous maritime technologies further, supporting safer and more efficient operations in critical applications."}]}