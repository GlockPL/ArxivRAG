{"title": "Uncertainty-Aware Deep Neural Representations for Visual Analysis of Vector Field Data", "authors": ["Atul Kumar", "Siddharth Garg", "Soumya Dutta"], "abstract": "The widespread use of Deep Neural Networks (DNNs) has recently resulted in their application to challenging scientific\nvisualization tasks. While advanced DNNs demonstrate impressive generalization abilities, understanding factors like prediction quality,\nconfidence, robustness, and uncertainty is crucial. These insights aid application scientists in making informed decisions. However,\nDNNs lack inherent mechanisms to measure prediction uncertainty, prompting the creation of distinct frameworks for constructing\nrobust uncertainty-aware models tailored to various visualization tasks. In this work, we develop uncertainty-aware implicit neural\nrepresentations to model steady-state vector fields effectively. We comprehensively evaluate the efficacy of two principled deep\nuncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout, aimed at enabling uncertainty-informed visual\nanalysis of features within steady vector field data. Our detailed exploration using several vector data sets indicate that uncertainty-\naware models generate informative visualization results of vector field features. Furthermore, incorporating prediction uncertainty\nimproves the resilience and interpretability of our DNN model, rendering it applicable for the analysis of non-trivial vector field data sets.", "sections": [{"title": "1 INTRODUCTION", "content": "The indisputable success of deep neural networks (DNNs) [44] has\nresulted in numerous applications of it in the scientific visualization\ndomain [73]. Analysis of intricate vector fields using DNNs has shown\npromising results with applications such as generating super-resolution\nflow fields [26, 31], reconstructing flow fields from streamlines [23, 28],\nflow map reconstruction [63], and predicting flow lines [33]. While\nthese DNN-based approaches produce state-of-the-art results, learning\na direct neural representation of the vector data is yet to be explored.\nFurthermore, the existing models do not quantify what it does not\nknow or how confidently the predictions are generated. Such missing\nknowledge, if estimated and conveyed to the experts, can significantly\nhelp them to make informed decisions about their data [9, 19]. Con-\nsequently, DNN-based flow data visual analytics will become more\ntrustworthy when they can assess their prediction uncertainty. However,\nthe literature survey reveals that a direct vector data modeling approach\naugmented with uncertainty estimation capability using DNNs is still\nmissing a gap that this work attempts to bridge.\nAmong various neural architectures used to analyze flow data, we\nstudy the efficacy of implicit neural representations (INRs) for directly\nlearning vector fields, i.e., a INR will predict the vector components\nat any queried location in the spatial domain. The choice of INR\nover other neural architectures is motivated by the recent success of\nINRs in producing state-of-the-art results for scientific data [32, 48, 63,\n69]. Since DNNs inherently do not provide prediction uncertainty, we\nemploy deep uncertainty quantification techniques to obtain uncertainty\nestimates along with the predicted vectors from our INR model so\nthat the downstream flow field analysis tasks can effectively leverage\nsuch information. Hence, we further focus on designing uncertainty-\ninformed flow data visualization techniques to intuitively and effectively\ncommunicate the prediction uncertainty to domain experts.\nVarious factors specific can influence the choice of deep uncertainty\nestimation methods. While the deep learning community has developed\nseveral uncertainty quantification methods, our focus is on selecting\nmethods that can be easily integrated into visualization models with\nminimal architecture modifications, facilitating smooth adoption of\nsuch methods for uncertainty-aware visual analysis. Literature survey\nindicates that Deep Ensembles often excel in producing accurate pre-"}, {"title": "2 RESEARCH BACKGROUND AND UNCERTAINTY ESTIMATION\nIN DEEP NEURAL NETWORKS", "content": ""}, {"title": "2.1 Deep Learning in Scientific Data Visualization", "content": "Deep learning has found diverse applications in scientific visualization.\nLu et al. [48] and Weiss et al. [76] have introduced methods aimed"}, {"title": "2.2 Uncertainty Visualization", "content": "Pang et al. provide one of the earliest summaries of uncertainty vi-\nsualization techniques [53]. Potter et al. focus on visualizing spatial\nprobability distributions, preceded by a taxonomy of uncertainty visu-\nalization methods [59, 60]. Brodlie et al. [10] introduce visualization\ntechniques enhanced with tools for uncertainty estimation. Liu et al.\nemploy flickering as a method to depict uncertainty in volume data [47],\nwhile Athawale et al. delve deeper into uncertainty visualization in\nvolume rendering using non-parametric models [2]. Uncertainty visu-\nalization techniques tailored for isocontouring methods have received\nsignificant attention in research. P\u00f6thkow et al. devise a method to\ncompute the level crossing probability between adjacent points, which\nis further refined to calculate the probability for each cell [57, 58].\nWhitaker et al. [78] explore uncertainty visualization in ensembles of\ncontours. Streamline uncertainty in ensemble field [17] and pathline\nuncertainty in time-varying field [11] is also explored. Otto et al. [51]\nstudy uncertainty in 2D vector fields. Bonneau et al. conduct a com-\nprehensive survey of various uncertainty visualization techniques [9].\nRecently, Gillmann et al. provide a summary of uncertainty visualiza-\ntion methods geared towards image processing [21]."}, {"title": "2.3 Uncertainty Estimation in Deep Neural Networks", "content": "The uncertainty [8, 43] of a DNN can be categorized into two broad\ntypes - data or aleatoric uncertainty and model or epistemic uncer-\ntainty. Data uncertainty is attributed to errors and noise during data\nacquisition. Model (epistemic) uncertainty can arise for different rea-\nsons. Firstly, the DNNs produce a compressed representation of large-\nscale data. Such compression often results in prediction error and\nassociated uncertainty. Secondly, DNNs are often fine-tuned carefully\nusing learning rate variation, regularization, etc. Different decisions\nfor such configurations lead to different learned model representations,\nand analysis using such models can lead to uncertainties. The data\nuncertainty can be addressed by improving data collection method and\nby improving the data quality. In contrast, the epistemic uncertainty is\ninherent to the model and needs to be studied in detail."}, {"title": "2.3.1 Techniques for Modeling Uncertainty in DNNs", "content": "Deterministic methods. Deterministic models can be equipped with\nuncertainty estimation capabilities by explicitly training a network to\nquantify uncertainties [64].\nBayesian Methods. Bayesian neural networks [22] employ prior\ndistributions on the model parameters of DNNs to compute epistemic\nuncertainty [43]. Training such networks require stochastic gradient\nMCMC [49], and variational inference [34] methods.\nTest-time Augmentation. Test time augmentation methods perform\ndata augmentation during the inference time and then estimate the\nuncertainty from the variability in the predicted results [3, 74].\nDeep Evidential Regression. In deep evidential regression, the net-\nwork learns parameters as well as hyperparameters to the corresponding"}, {"title": "2.3.2 Ensemble Method", "content": "In ensemble-based methods, several models work harmoniously to pro-\nduce predictions that are of superior quality compared to the predictions\nfrom any individual model [62]. By doing this, ensemble methods im-\nprove the generalization error, and by estimating the variability among\nensemble member predictions, the model uncertainty can be estimated\nrobustly. Following this principle, Lakshminarayanan et al. propose\nDeep Ensembles [43] for DNNs. Conceptually, Deep Ensemble learn-\ning can be shown as an approximation of Bayesian averaging [61].\nIn Bayesian averaging, the final model prediction is formulated as:\nprediction = \u222b Pw(x)\u03c0(w|D).\nHere Pw(x) is the prediction associated with sample x and \u03c0(w|9)\nrepresents the posterior probability distribution with being the train-\ning data. In reality, estimation of this integral is extremely difficult,\nand it is also found that to estimate this integral sufficiently accurately,\nexploration of all the modes of \u03c0(w|9) is not required. This obser-\nvation imply that non-weighted averaged predictions generated by a\nset of ensemble members can be considered an approximation of the\nabove expression. Note that shuffling of the training data and a random\nparameter initialization during the training process introduces a good\nvariety in each learned ensemble member to predict the uncertainty ro-\nbustly, an approach followed in this work to generate Deep Ensembles.\nSubsequent research works on Deep Ensembles [5, 27, 52, 71] show\nthat ensemble methods often outperform other uncertainty estimation\ntechniques and are more immune to changes in data distribution."}, {"title": "2.3.3 MCDropout Method", "content": "Dropout [19, 37] is a regularization technique that prevents models from\noverfitting during training and is achieved by randomly masking a sub-\nset of the weights during training. However, Gal et al. [19] discovered\nthat adding dropout in a DNN with arbitrary depth and non-linear acti-\nvations makes it theoretically equivalent to an approximate Bayesian\ninference in deep Gaussian processes. Then activating dropout at test\ntime is equivalent to sampling from the Bayesian posterior distribution,\np(W | X, Y), where W denotes the model's weights, X is the training\ndata and Y is the target output. Finally, the mean of these sampled pre-\ndictions is considered as the expected model output, and by measuring\nthe variance in these sampled predictions, model uncertainty can be\nestimated [19]. Such probabilistic predictions are derived by collecting\nMonte Carlo (MC) samples from the dropout-enabled trained model,\nknown as Monte Carlo Dropout (MCDropout) method, by performing\nmultiple forward passes during inference."}, {"title": "3 UNCERTAINTY-AWARE NEURAL REPRESENTATION FOR VEC-\nTOR FIELD DATA", "content": ""}, {"title": "3.1 Implicit Neural Representation", "content": "Implicit neural representations with periodic activation functions have\nbeen identified as a promising solution for learning representations of\ncoordinate-based data sets, where the mapping from any input coordi-\nnate in the data domain to the corresponding output quantity values is\nlearned. Sitzmann et al. [68] in their work depicted that a feed-forward\nneural network with sinusoidal activation function, termed as SIREN\n(sinusoidal representation network), can be used to build such INRs [68].\nSeveral variations of this SIREN have recently been used to solve many\nchallenging problems in the scientific data visualization domain and\nobtain state-of-the-art results [32, 48, 63, 69]. The success of these\nrecent research efforts has prompted us to build our uncertainty-aware\nmodel using SIRENs as the base architecture. Besides analyzing the\nuncertainty estimates produced by the Deep Ensemble and MCDopout\nmethods using a SIREN-based model, we study the accuracy such a\nnetwork can achieve in representing intricate steady vector fields."}, {"title": "3.2 Model Architecture", "content": "Using an implicit neural network, we aim to learn the function that\nrepresents the mapping from the input data coordinate domain to the\ncorresponding vector value space. To achieve this, we build our base\nmodel as a multilayer perceptron consisting of d neurons as inputs, fol-\nlowed by I hidden layers and an output layer containing v neurons. To\nenrich the model's learning capability and train a deep network in a sta-\nble fashion, we enhance the base SIREN architecture by incorporating\nresidual blocks and skip connections [35] as was suggested in [48]. Our\nmodel learns a function that takes a d dimensional coordinate vector as\ninput and predicts a v dimensional vector output where v is the number\nof components in the vector field data. Essentially, the network learns\na function F (0) : Rd \u2192 R', where \u0472 represents the parameters of the\nneural network. When the size of the flow data is large, then using a\nsingle DNN to learn all the vector components jointly also allows us to\nproduce a compact neural representation of the flow data set since the\nmodel parameters are shared across the vector components. Hence, the\nmodel size will be sufficiently smaller than the raw flow data set."}, {"title": "3.3 Uncertainty Quantification Using MCDropout Method", "content": "The model architecture used for the MCDropout method is shown in\nFig. 1. We observe that a post-activation dropout layer is added at\nthe last residual block to build a dropout-enabled model that can be used\nconveniently during inference to estimate prediction uncertainty. The\naddition of the dropout layer also helps in regularization during training.\nTheoretically, if one wants to simulate a fully Bayesian network, a\ndropout layer must be added at each residual block [41]. However,\nsuch a large number of dropout layers often acts as a strong regularizer\nand hinders the learning process, resulting in lower accuracy during\ntest time [41]. We observe similar behavior when the dropout layer\nis added to every residual block. Hence, following Kendall et al.'s.\nsuggestion [41], we build a model by adding dropout at the deepest\nresidual block, giving us robust uncertainty estimates and a high-quality\nvector field reconstruction. The impact of using different numbers of\ndropout layers has been studied and presented later in Table 7.\nAs outlined in Section 2.3.3, inference involves generating a set of\nMonte Carlo samples through multiple forward passes of the trained\nmodel when dropout is enabled. In our approach, we produce m in-\nstances of the vector field and subsequently calculate the average vector\nfield, serving as the predicted vector field. The grid-pointwise standard\ndeviation, computed using vector components estimated by m forward\npasses, denotes the prediction uncertainty. We separately compute\nstandard deviation for each vector component and then add the standard\ndeviation values to obtain the final prediction uncertainty."}, {"title": "3.4 Uncertainty Quantification Using Ensemble Method", "content": "A schematic of our INR architecture is presented in Fig. 1. To build\na Deep Ensemble [43] of INRs, we use this model architecture with-\nout the dropout layer. To produce an ensemble model comprising m"}, {"title": "4 UNCERTAINTY-INFORMED FLOW FIELD VISUALIZATION", "content": "We conduct a thorough study of our models using six vector field\ndata sets. The dimensionality and spatial resolution of these data\nsets are reported in Table 1. We use a GPU server with NVIDIA\nGeForce GTX 1080Ti GPUs with 12GB GPU memory for all the\nexperimentation. All the models are implemented in PyTorch [54]. The\nHeated Cylinder data set [25] and Fluid data set [40] are generated\nusing Gerris flow solver [55]. Hurricane Isabel data was produced by\nthe Weather Research and Forecast model, courtesy of NCAR and NSF.\nTurbine data set [12] and Tornado data [13] set are made available by Dr.\nJen-Ping Chen and Dr. Roger Crawfis, respectively, at the Ohio State"}, {"title": "4.1 Visual Analysis of Reconstructed Field, Prediction Un-\ncertainty, and Error", "content": "We reconstruct the entire vector field to thoroughly assess the model's\nreconstruction quality, prediction uncertainty, and error. Through exper-\nimentation, we ascertain that utilizing 100 Monte Carlo (MC) samples\nfor the MCDropout method and 30 ensemble members for the Ensem-\nble method yields a robust estimation of vectors, error, and uncertainty.\nThe determination of these numbers of MC samples and ensemble mem-\nbers is based on comparing the reconstruction quality across various\nquantities of MC samples and ensemble members. Detailed results can\nbe found in Table 3 and Table 4. Thus, unless specified otherwise, we\nconsistently employ 100 MC samples for MCDropout and 30 ensemble\nmembers for the Ensemble method in all presented results.\nTo derive the final vector field, we calculate the average vectors at\neach grid point, where the averaging process entails computing the\nmean over 100 vectors for the MCDropout method and over 30 vectors\nfor the Ensemble method. We compute the error at each grid point by\ncontrasting the predicted value with the ground truth vectors to estimate\nfine-grained prediction error. This error computation involves assessing\neach vector component individually and then adding the component-\nwise errors, i.e., the L1 norm, to obtain the total error at a grid point.\nSimilarly, we compute the component-wise uncertainty at each grid\npoint (by computing the component-wise standard deviation) for both\nMCDropout and Ensemble methods, subsequently estimating the total\nuncertainty by summing the component-wise uncertainty values.\nThis section focuses on a qualitative comparison, presenting volume\nvisualizations of the reconstructed vector magnitude fields, estimated\nprediction uncertainty, and error values for the Isabel and Tangaroa\ndata sets. Fig. 2 and Fig. 3 display the volume rendering of ground\ntruth, MCDropout, and Ensemble predicted vector magnitude fields for\nIsabel and Tangaroa data sets, respectively. Both methods accurately\nreconstruct the vector components for these data sets. Subsequently,\nFig. 4 and Fig. 5 present volume renderings of predicted error and\nuncertainty fields for the Isabel and Tangaroa data sets. It is noted that\nerror and uncertainty do not exhibit strong spatial correlation. While the\nerror patterns for MCDropout and Ensemble methods appear visually\nsimilar, spatial uncertainty visualizations differ. In the Isabel data\nset, regions with higher prediction uncertainty correspond to vortex\nregions in the vector field for both MCDropout and Ensemble methods\n(see Fig. 4c and Fig. 4d). However, in the Tangaroa data set, the\nrelatively higher uncertainty valued regions are confined to smaller\nspatial domain for the Ensemble method (Fig. 5d). For MCDropout\nmethod, we see that the moderately uncertain regions are widespread\n(Fig. 5c), compared to the Ensemble method."}, {"title": "4.2 Visual Analysis of Flow Features Using Uncertainty-\nAware Streamlines", "content": "Streamlines serve as valuable tools for visualizing flow patterns, identi-\nfying recirculation regions, and pinpointing stagnation points, aiding\nin understanding fluid behavior across engineering and scientific do-\nmains. To enhance the effectiveness of flow feature visualization, we\nemploy both MCDropout and Ensemble methods with our model's pre-\ndictions. These methods not only generate streamlines but also allow"}, {"title": "4.3 Visual Analysis of Flow Features Using Uncertainty-\nAware Critical Points", "content": "Critical points play an important role in studying vector field charac-\nteristics as it helps identify points where the flow behavior undergoes\nsignificant changes. These points, including saddles, sources, centers,\nand sinks, provide valuable insights into the dynamics of the vector\nfield. By observing critical points, users determine flow patterns, locate\nstagnation points, and comprehend the overall flow behavior. Compre-\nhensive understanding of robustness of critical points can lead to the\naccurate flow features study [16, 24, 72] and flow data compression [45].\nIn this study, we evaluate the accuracy of uncertainty-aware neural\nmodels in predicting critical point locations and quantify the spatial\nvariability of these predictions using the MCDropout and Ensemble\nmethods. Initially, we compute the mean vector field using both tech-\nniques to ensure the robustness of the estimated critical points. From\nthis mean field, we identify the critical point locations. To assess the\nspatial variability of each critical point's location derived from the mean\nfield, we analyze data from individual vector field realizations: 100\nfields for the MCDropout and 30 for the Ensemble method. For each\nmethod, first, we identify critical points in each vector field realization.\nThen, we create a new scalar field where the scalar value at each grid\npoint reflects the cumulative contribution of all critical points from\nall the field realizations. Here, we do not distinguish between critical\npoints detected from different MC samples (or ensemble members).\nEach critical point deposits its contribution to all the grid points. The\ncontribution of a critical point to a grid point is calculated as the inverse\nEuclidean distance between the critical point and the grid point. Hence,\nthe contribution of a critical point to the nearby grid points will be\nhigher and gradually fall off for far away grid points. Formally, for a\ngrid point P, we compute its scalar value as follows: vp = \\frac{1}{N}\u2211_{i=1}^N D(PC_i),\nwhere ve denotes the value at grid point P and D(P, C) is the Euclidean\ndistance between point P and critical point C; with N being the total\nnumber of critical points detected across all realizations.\nTherefore, a grid point with a higher value will indicate a relatively"}, {"title": "5 QUANTITATIVE EVALUATION AND PARAMETER STUDY", "content": ""}, {"title": "Reconstruction Quality and Prediction Error.", "content": "Table 2 shows a\ncomparison between the Ensemble and MCDropout methods concern-\ning model size, PSNR, and RMSE. The Ensemble method outperforms\nMCDropout in terms of both PSNR and RMSE. However, achieving\nthis superior reconstruction quality with the Ensemble method requires\nnearly 30 times more storage space and training time compared to"}, {"title": "Impact of Different Number of MC Samples on PSNR Value for\nMCDropout Method.", "content": "Table 3 demonstrates the PSNR value of the\nvector field obtained by averaging different numbers of MC samples.\nThere is a slight gain of PSNR as we increase the number of MC\nsamples up to 150. After that, the gains in PSNR are not as significant\nto justify considering more number of samples. Hence, to find a good\ntrade-off between computation time and prediction quality, we use 100\nMC samples for all experiments involving the MCDropout method."}, {"title": "Impact of Different Number of Ensemble Members on PSNR\nValue for Ensemble Method.", "content": "The effect of different numbers of\nensemble members on PNSR is depicted in Table 4. The number of\nensemble members required to produce robust prediction is much lower\nthan in the MCDropout method. It can be observed that PSNR gains\nare insignificant when increasing the number of ensemble members\nbeyond 15 up to 30. Hence, at around 15 ensemble members, the\nPSNR becomes primarily saturated. However, for consistency, we use"}, {"title": "Streamline Error Analysis for MCDropout and Ensemble Meth-\nods.", "content": "We examine the precision of streamlines generated by both MC-\nDropout and Ensemble methods, utilizing averaged mean streamlines\nfor comparison. To conduct a thorough quantitative assessment, we\ngenerate mean streamlines from 100 randomly uniformly distributed\nseed points for each method. Subsequently, we gauge the streamline er-\nror by measuring Chamfer distance [4] and Hausdorff distance between\nthe predicted averaged streamlines and the ground truth counterparts.\nIt's noteworthy that for the MCDropout method, we aggregate results\nover 100 Monte Carlo (MC) samples, while for the Ensemble method,\nwe utilize streamlines predicted by 30 ensemble members. The average\nChamfer distance and Hausdorff distance values computed over the\n100 streamlines for each data set are presented in Table 5. It is evident\nthat the Ensemble method consistently yields more precise streamlines\ncompared to the MCDropout method across all data sets, as evidenced\nby the lower Chamfer and Hausdorff distance values."}, {"title": "Accuracy Analysis of The Predicted Critical Points for MC-\nDropout and Ensemble Methods.", "content": "To quantitatively assess the\nprecision of the identified critical point locations, we calculate the\naverage root mean squared error (RMSE) between the predicted and\nthe corresponding ground truth critical points for both MCDropout and\nEnsemble methods. The outcomes are documented in Table 6 for the\nHeated Cylinder and Fluid data sets. It is apparent that, on average, the\nEnsemble method outperforms the MCDropout method in accurately\ndetermining critical points using the reconstructed vector field."}, {"title": "Impact of Varying Number of Dropout Layers on MCDropout\nModel Performance.", "content": "In [19], Gal et al. demonstrate that incorporating\na dropout layer after each hidden layer in a DNN renders the model\ntheoretically equivalent to conducting inference in a fully Bayesian\nneural network. However, Kendall et al. [41] argue that adding such\ndropout layers after every layer could hamper the model's learnability,"}, {"title": "Consistent Hyperparameter Selection.", "content": "In this work, we seek to\nidentify a hyperparameter combination that ensures stable training of\nimplicit neural models using both MCDropout and Ensemble methods"}, {"title": "6 DISCUSSION", "content": "Uncertainty-agnostic vs. Uncertainty-aware DNNs. We advocate\nthe use of DNNs equipped to quantify uncertainty when analyzing\nvector fields. We find that uncertainty-informed neural networks offer\nvaluable insights into the reliability of their predictions. By effectively\nconveying such uncertainty to experts, they can make well-informed\ndecisions about the data features. This integration of uncertainty is\ncrucial in fostering trust in the use of DNN-predicted results for sci-\nentific research. Particularly when dealing with large vector fields,\nscientists often have to rely on the model's outputs due to the imprac-\nticality of handling full-resolution data. In such cases, where ground\ntruth data may be unavailable, estimating errors becomes challenging.\nHowever, uncertainty-aware DNNs can still provide reliable uncertainty\nestimates, offering experts greater confidence in interpreting predicted\nresults. Next, we discuss the domain expert feedback to highlight the\nimplications of our proposed techniques.\nDomain Expert Feedback. We interviewed a computational fluid\ndynamics scientist to collect expert feedback. The expert immediately\nliked the idea of using uncertainty-aware neural models and agreed that\nvisualizing prediction uncertainty on predicted flow features is critical\nand can provide meaningful insights about the prediction's quality and\nhelp build trust in using deep learning techniques for scientific research.\nThe expert found our uncertainty-informed streamline visualization\nintuitive and easy to comprehend. The expert was also intrigued to\nsee that these neural models can be both under-confident and over-\nconfident, as highlighted in Fig. 15, and agreed that access to such\nresults is critical for verifying and validating hypotheses from flow\ndata. Next, the expert suggested that developing such uncertainty-\naware models for time-varying flow data would be very useful. Finally,\nthe expert observed that complex and turbulent regions tend to incur\nhigher prediction uncertainty, which was expected since predicting\nintricate flow features is a more complicated task than predicting less\nturbulent flow. This is because of the highly nonlinear and multiscale\nnature of turbulent flows. However, the expert further noted that large-\nscale ocean and upper atmospheric flows tend to be non-turbulent, and\nhence the proposed method can serve as an effective uncertainty-aware\ncompression method for such large-scale flow data.\nMean vs. Median Streamline. Formally, both MCDropout and\nEnsemble methods consider the expected model output to be the mean\nand so we visualize the mean streamlines. However, to mitigate outlier\nsensitivity, our method also allows visualization of the median stream-m-\nline, which is less affected by outliers. Experiments show that mean\nand median streamlines are nearly identical, with minor differences. In\nFig. 16, results from the Isabel data show that for both methods, mean\n(green) and median (blue) streamlines generally overlap, though the\nzoomed inset reveals slight differences for the Ensemble method."}, {"title": "7 CONCLUSIONS AND FUTURE WORK", "content": "This paper emphasizes the importance of understanding uncertainty by\napplying two uncertainty estimation methods. While in this work, we\nstudy the impact of uncertainty on tasks such as vector data prediction,\nstreamline generation, and critical point detection, in the future, we\nplan to conduct a comprehensive topological analysis and thoroughly\nstudy flow map characteristics to evaluate reconstruction quality fur-\nther using the proposed methods. Other future research endeavors\ninclude exploring alternative deep uncertainty estimation techniques\nand expanding our method to handle time-varying data. Insights from\nuncertainty estimates help identify areas needing explicit training and\nrecognize model limitations in specific data regions. In critical scenar-\nios, a model's confidence in its predictions is crucial, fostering greater\ntrust when the model acknowledges its uncertainties."}]}