{"title": "Uncertainty-Aware Deep Neural Representations for Visual Analysis of Vector Field Data", "authors": ["Atul Kumar", "Siddharth Garg", "Soumya Dutta"], "abstract": "The widespread use of Deep Neural Networks (DNNs) has recently resulted in their application to challenging scientific visualization tasks. While advanced DNNs demonstrate impressive generalization abilities, understanding factors like prediction quality, confidence, robustness, and uncertainty is crucial. These insights aid application scientists in making informed decisions. However, DNNs lack inherent mechanisms to measure prediction uncertainty, prompting the creation of distinct frameworks for constructing robust uncertainty-aware models tailored to various visualization tasks. In this work, we develop uncertainty-aware implicit neural representations to model steady-state vector fields effectively. We comprehensively evaluate the efficacy of two principled deep uncertainty estimation techniques: (1) Deep Ensemble and (2) Monte Carlo Dropout, aimed at enabling uncertainty-informed visual analysis of features within steady vector field data. Our detailed exploration using several vector data sets indicate that uncertainty-aware models generate informative visualization results of vector field features. Furthermore, incorporating prediction uncertainty improves the resilience and interpretability of our DNN model, rendering it applicable for the analysis of non-trivial vector field data sets.", "sections": [{"title": "1 INTRODUCTION", "content": "The indisputable success of deep neural networks (DNNs) [44] has resulted in numerous applications of it in the scientific visualization domain [73]. Analysis of intricate vector fields using DNNs has shown promising results with applications such as generating super-resolution flow fields [26,31], reconstructing flow fields from streamlines [23,28], flow map reconstruction [63], and predicting flow lines [33]. While these DNN-based approaches produce state-of-the-art results, learning a direct neural representation of the vector data is yet to be explored. Furthermore, the existing models do not quantify what it does not know or how confidently the predictions are generated. Such missing knowledge, if estimated and conveyed to the experts, can significantly help them to make informed decisions about their data [9, 19]. Consequently, DNN-based flow data visual analytics will become more trustworthy when they can assess their prediction uncertainty. However, the literature survey reveals that a direct vector data modeling approach augmented with uncertainty estimation capability using DNNs is still missing a gap that this work attempts to bridge.\nAmong various neural architectures used to analyze flow data, we study the efficacy of implicit neural representations (INRs) for directly learning vector fields, i.e., a INR will predict the vector components at any queried location in the spatial domain. The choice of INR over other neural architectures is motivated by the recent success of INRs in producing state-of-the-art results for scientific data [32, 48, 63, 69]. Since DNNs inherently do not provide prediction uncertainty, we employ deep uncertainty quantification techniques to obtain uncertainty estimates along with the predicted vectors from our INR model so that the downstream flow field analysis tasks can effectively leverage such information. Hence, we further focus on designing uncertainty-informed flow data visualization techniques to intuitively and effectively communicate the prediction uncertainty to domain experts.\nVarious factors specific can influence the choice of deep uncertainty estimation methods. While the deep learning community has developed several uncertainty quantification methods, our focus is on selecting methods that can be easily integrated into visualization models with minimal architecture modifications, facilitating smooth adoption of such methods for uncertainty-aware visual analysis. Literature survey indicates that Deep Ensembles often excel in producing accurate pre-"}, {"title": "2 RESEARCH BACKGROUND AND UNCERTAINTY ESTIMATION IN DEEP NEURAL NETWORKS", "content": ""}, {"title": "2.1 Deep Learning in Scientific Data Visualization", "content": "Deep learning has found diverse applications in scientific visualization. Lu et al. [48] and Weiss et al. [76] have introduced methods aimed at generating concise neural representations of scientific data. Hong et al. [38], He et al. [36], and Berger et al. [7] have investigated the visualization of scalar field data, while Weiss et al. have explored isosurface visualization [75] and volume visualization [77]. Spatiotemporal super-resolution volume generation has emerged as another research focus [20, 29, 30, 79]. Novel models for domain knowledge-aware latent space generation have been proposed [65]. Moreover, DNNs have been employed as substitutes for generating visualizations and exploring parameter spaces in ensemble data [36, 66, 67]. Analysis of flow field features using CNNs was proposed in [80]. Reconstruction of vector data from 3D streamlines was developed by Han et al. [28]. More recently, Berenjkoub et al. highlighted how vortex boundaries could be extracted using CNNs [6]. In a recent work, Dutta et al. [15] demonstrated how visualizing prediction uncertainty can provide insights about the model's robustness for view synthesizing tasks. For a comprehensive overview of flow data visualization using deep learning methods, please refer to [46] and for a broader set of applications of deep learning applications in scientific visualization please refer to [73]."}, {"title": "2.2 Uncertainty Visualization", "content": "Pang et al. provide one of the earliest summaries of uncertainty visualization techniques [53]. Potter et al. focus on visualizing spatial probability distributions, preceded by a taxonomy of uncertainty visualization methods [59, 60]. Brodlie et al. [10] introduce visualization techniques enhanced with tools for uncertainty estimation. Liu et al. employ flickering as a method to depict uncertainty in volume data [47], while Athawale et al. delve deeper into uncertainty visualization in volume rendering using non-parametric models [2]. Uncertainty visualization techniques tailored for isocontouring methods have received significant attention in research. P\u00f6thkow et al. devise a method to compute the level crossing probability between adjacent points, which is further refined to calculate the probability for each cell [57, 58]. Whitaker et al. [78] explore uncertainty visualization in ensembles of contours. Streamline uncertainty in ensemble field [17] and pathline uncertainty in time-varying field [11] is also explored. Otto et al. [51] study uncertainty in 2D vector fields. Bonneau et al. conduct a comprehensive survey of various uncertainty visualization techniques [9]. Recently, Gillmann et al. provide a summary of uncertainty visualization methods geared towards image processing [21]."}, {"title": "2.3 Uncertainty Estimation in Deep Neural Networks", "content": "The uncertainty [8, 43] of a DNN can be categorized into two broad types - data or aleatoric uncertainty and model or epistemic uncertainty. Data uncertainty is attributed to errors and noise during data acquisition. Model (epistemic) uncertainty can arise for different reasons. Firstly, the DNNs produce a compressed representation of large-scale data. Such compression often results in prediction error and associated uncertainty. Secondly, DNNs are often fine-tuned carefully using learning rate variation, regularization, etc. Different decisions for such configurations lead to different learned model representations, and analysis using such models can lead to uncertainties. The data uncertainty can be addressed by improving data collection method and by improving the data quality. In contrast, the epistemic uncertainty is inherent to the model and needs to be studied in detail."}, {"title": "2.3.1 Techniques for Modeling Uncertainty in DNNs", "content": "Deterministic methods. Deterministic models can be equipped with uncertainty estimation capabilities by explicitly training a network to quantify uncertainties [64].\nBayesian Methods. Bayesian neural networks [22] employ prior distributions on the model parameters of DNNs to compute epistemic uncertainty [43]. Training such networks require stochastic gradient MCMC [49], and variational inference [34] methods.\nTest-time Augmentation. Test time augmentation methods perform data augmentation during the inference time and then estimate the uncertainty from the variability in the predicted results [3,74].\nDeep Evidential Regression. In deep evidential regression, the network learns parameters as well as hyperparameters to the corresponding"}, {"title": "2.3.2 Ensemble Method", "content": "In ensemble-based methods, several models work harmoniously to produce predictions that are of superior quality compared to the predictions from any individual model [62]. By doing this, ensemble methods improve the generalization error, and by estimating the variability among ensemble member predictions, the model uncertainty can be estimated robustly. Following this principle, Lakshminarayanan et al. propose Deep Ensembles [43] for DNNs. Conceptually, Deep Ensemble learning can be shown as an approximation of Bayesian averaging [61]. In Bayesian averaging, the final model prediction is formulated as:\nprediction = $\\int P_w(x) \\pi(w|D)$.\nHere $P_w(x)$ is the prediction associated with sample x and $\\pi(w|9)$ represents the posterior probability distribution with being the training data. In reality, estimation of this integral is extremely difficult, and it is also found that to estimate this integral sufficiently accurately, exploration of all the modes of $\\pi(w|9)$ is not required. This observation imply that non-weighted averaged predictions generated by a set of ensemble members can be considered an approximation of the above expression. Note that shuffling of the training data and a random parameter initialization during the training process introduces a good variety in each learned ensemble member to predict the uncertainty robustly, an approach followed in this work to generate Deep Ensembles. Subsequent research works on Deep Ensembles [5, 27, 52, 71] show that ensemble methods often outperform other uncertainty estimation techniques and are more immune to changes in data distribution."}, {"title": "2.3.3 MCDropout Method", "content": "Dropout [19,37] is a regularization technique that prevents models from overfitting during training and is achieved by randomly masking a subset of the weights during training. However, Gal et al. [19] discovered that adding dropout in a DNN with arbitrary depth and non-linear activations makes it theoretically equivalent to an approximate Bayesian inference in deep Gaussian processes. Then activating dropout at test time is equivalent to sampling from the Bayesian posterior distribution, p(W | X, Y), where W denotes the model's weights, X is the training data and Y is the target output. Finally, the mean of these sampled predictions is considered as the expected model output, and by measuring the variance in these sampled predictions, model uncertainty can be estimated [19]. Such probabilistic predictions are derived by collecting Monte Carlo (MC) samples from the dropout-enabled trained model, known as Monte Carlo Dropout (MCDropout) method, by performing multiple forward passes during inference."}, {"title": "3 UNCERTAINTY-AWARE NEURAL REPRESENTATION FOR VECTOR FIELD DATA", "content": ""}, {"title": "3.1 Implicit Neural Representation", "content": "Implicit neural representations with periodic activation functions have been identified as a promising solution for learning representations of coordinate-based data sets, where the mapping from any input coordinate in the data domain to the corresponding output quantity values is learned. Sitzmann et al. [68] in their work depicted that a feed-forward neural network with sinusoidal activation function, termed as SIREN (sinusoidal representation network), can be used to build such INRs [68]. Several variations of this SIREN have recently been used to solve many challenging problems in the scientific data visualization domain and obtain state-of-the-art results [32, 48, 63, 69]. The success of these recent research efforts has prompted us to build our uncertainty-aware model using SIRENs as the base architecture. Besides analyzing the uncertainty estimates produced by the Deep Ensemble and MCDopout methods using a SIREN-based model, we study the accuracy such a network can achieve in representing intricate steady vector fields."}, {"title": "3.2 Model Architecture", "content": "Using an implicit neural network, we aim to learn the function that represents the mapping from the input data coordinate domain to the corresponding vector value space. To achieve this, we build our base model as a multilayer perceptron consisting of d neurons as inputs, followed by l hidden layers and an output layer containing v neurons. To enrich the model's learning capability and train a deep network in a stable fashion, we enhance the base SIREN architecture by incorporating residual blocks and skip connections [35] as was suggested in [48]. Our model learns a function that takes a d dimensional coordinate vector as input and predicts a v dimensional vector output where v is the number of components in the vector field data. Essentially, the network learns a function $F (\\Theta) : R^d \\rightarrow R^v$, where \u0472 represents the parameters of the neural network. When the size of the flow data is large, then using a single DNN to learn all the vector components jointly also allows us to produce a compact neural representation of the flow data set since the model parameters are shared across the vector components. Hence, the model size will be sufficiently smaller than the raw flow data set."}, {"title": "3.3 Uncertainty Quantification Using MCDropout Method", "content": "The model architecture used for the MCDropout method is shown in Fig. 1. We observe that a post-activation dropout layer is added at the last residual block to build a dropout-enabled model that can be used conveniently during inference to estimate prediction uncertainty. The addition of the dropout layer also helps in regularization during training. Theoretically, if one wants to simulate a fully Bayesian network, a dropout layer must be added at each residual block [41]. However, such a large number of dropout layers often acts as a strong regularizer and hinders the learning process, resulting in lower accuracy during test time [41]. We observe similar behavior when the dropout layer is added to every residual block. Hence, following Kendall et al.'s. suggestion [41], we build a model by adding dropout at the deepest residual block, giving us robust uncertainty estimates and a high-quality vector field reconstruction. The impact of using different numbers of dropout layers has been studied and presented later in Table 7.\nAs outlined in Section 2.3.3, inference involves generating a set of Monte Carlo samples through multiple forward passes of the trained model when dropout is enabled. In our approach, we produce m instances of the vector field and subsequently calculate the average vector field, serving as the predicted vector field. The grid-pointwise standard deviation, computed using vector components estimated by m forward passes, denotes the prediction uncertainty. We separately compute standard deviation for each vector component and then add the standard deviation values to obtain the final prediction uncertainty."}, {"title": "3.4 Uncertainty Quantification Using Ensemble Method", "content": "A schematic of our INR architecture is presented in Fig. 1. To build a Deep Ensemble [43] of INRs, we use this model architecture without the dropout layer. To produce an ensemble model comprising m"}, {"title": "4 UNCERTAINTY-INFORMED FLOW FIELD VISUALIZATION", "content": "We conduct a thorough study of our models using six vector field data sets. The dimensionality and spatial resolution of these data sets are reported in Table 1. We use a GPU server with NVIDIA GeForce GTX 1080Ti GPUs with 12GB GPU memory for all the experimentation. All the models are implemented in PyTorch [54]. The Heated Cylinder data set [25] and Fluid data set [40] are generated using Gerris flow solver [55]. Hurricane Isabel data was produced by the Weather Research and Forecast model, courtesy of NCAR and NSF. Turbine data set [12] and Tornado data [13] set are made available by Dr. Jen-Ping Chen and Dr. Roger Crawfis, respectively, at the Ohio State"}, {"title": "4.1 Visual Analysis of Reconstructed Field, Prediction Uncertainty, and Error", "content": "We reconstruct the entire vector field to thoroughly assess the model's reconstruction quality, prediction uncertainty, and error. Through experimentation, we ascertain that utilizing 100 Monte Carlo (MC) samples for the MCDropout method and 30 ensemble members for the Ensemble method yields a robust estimation of vectors, error, and uncertainty. The determination of these numbers of MC samples and ensemble members is based on comparing the reconstruction quality across various quantities of MC samples and ensemble members. Detailed results can be found in Table 3 and Table 4. Thus, unless specified otherwise, we consistently employ 100 MC samples for MCDropout and 30 ensemble members for the Ensemble method in all presented results.\nTo derive the final vector field, we calculate the average vectors at each grid point, where the averaging process entails computing the mean over 100 vectors for the MCDropout method and over 30 vectors for the Ensemble method. We compute the error at each grid point by contrasting the predicted value with the ground truth vectors to estimate fine-grained prediction error. This error computation involves assessing each vector component individually and then adding the component-wise errors, i.e., the L1 norm, to obtain the total error at a grid point. Similarly, we compute the component-wise uncertainty at each grid point (by computing the component-wise standard deviation) for both MCDropout and Ensemble methods, subsequently estimating the total uncertainty by summing the component-wise uncertainty values.\nThis section focuses on a qualitative comparison, presenting volume visualizations of the reconstructed vector magnitude fields, estimated prediction uncertainty, and error values for the Isabel and Tangaroa data sets. Fig. 2 and Fig. 3 display the volume rendering of ground truth, MCDropout, and Ensemble predicted vector magnitude fields for Isabel and Tangaroa data sets, respectively. Both methods accurately reconstruct the vector components for these data sets. Subsequently, Fig. 4 and Fig. 5 present volume renderings of predicted error and uncertainty fields for the Isabel and Tangaroa data sets. It is noted that error and uncertainty do not exhibit strong spatial correlation. While the error patterns for MCDropout and Ensemble methods appear visually similar, spatial uncertainty visualizations differ. In the Isabel data set, regions with higher prediction uncertainty correspond to vortex regions in the vector field for both MCDropout and Ensemble methods (see Fig. 4c and Fig. 4d). However, in the Tangaroa data set, the relatively higher uncertainty valued regions are confined to smaller spatial domain for the Ensemble method (Fig. 5d). For MCDropout method, we see that the moderately uncertain regions are widespread (Fig. 5c), compared to the Ensemble method."}, {"title": "4.2 Visual Analysis of Flow Features Using Uncertainty-Aware Streamlines", "content": "Streamlines serve as valuable tools for visualizing flow patterns, identifying recirculation regions, and pinpointing stagnation points, aiding in understanding fluid behavior across engineering and scientific domains. To enhance the effectiveness of flow feature visualization, we employ both MCDropout and Ensemble methods with our model's predictions. These methods not only generate streamlines but also allow us to quantify uncertainty in predicted vector values at each step of the integration process. To generate streamlines, we use RK-4 integration and trace the streamline in both forward and backward direction. Using the MCDropout approach, we generate n realizations of the same streamline from a given seed point (with n=100 in our study) through MC sampling. To estimate the expected streamline, we compute the mean streamline by averaging the coordinates at each integration step. However, due to variability among the MC streamline samples, some streamlines may go out of bounds. In such instances, we calculate the mean using only the existing streamlines at those integration steps. Our analysis method also supports the computation of the median streamline as an alternative to the mean streamline to mitigate the impact of outliers. The uncertainty at each step of the streamline is determined by the standard deviation computed from the n samples following similar strategy as used to compute the mean streamline. Similarly, employing the Ensemble method involves generating n realizations of the streamline (where n = 30 due to our use of 30 ensemble members), considering the mean streamline as the final result, and computing pointwise standard deviation as the uncertainty estimate.\nUtilizing models sensitive to uncertainty helps measure and communicate uncertainty associated with streamlines, aiding users in making informed decisions during flow feature analysis [18]. This uncertainty information builds user confidence in the model's predictions and highlights segments where predictions may lack confidence. We visualize uncertainty in streamlines by rendering the mean (averaged) streamline as a stream-tube, with the stream-tube diameter scaled by uncertainty estimates and colored by uncertainty values. Fig.6 shows this stream-tube visualization, where Fig.6a displays the ground truth streamline without uncertainty, and Fig. 6b shows the uncertainty-aware visualization. Higher uncertainty is observed at the streamline's ends, with the seed location marked by a green sphere. Next, we qualitatively study the uncertainty characteristics estimated by MCDropout and Ensemble methods through several case studies.\nFluid (2D) Data Set. We use 100 uniformly randomly generated seed points to generate streamlines for the Fluid data set using MC-Dropout and Ensemble methods. The results are shown in Fig. 7. The ground truth streamlines are shown in Fig. 7a, and streamlines from MCDropout and Ensemble methods are provided in Fig. 7b and Fig. 7c respectively. The streamlines are colored using prediction uncertainty, and the thickness of the stream tubes also varies according to the prediction uncertainty. It is observed that both MCDropout and Ensemble methods can generate accurate streamlines when compared against ground truth streamlines (Fig. 7a). Furthermore, by comparing Fig. 7b and Fig. 7c, we also learn that both MCDropout and Ensemble methods estimate comparable uncertainty estimates across the entire data set.\nTornado Data Set. Next, we conduct a similar study using the Tornado data set to study the generated uncertainty patterns. In this study, streamlines on 100 uniformly randomly generated seed points are shown, where the ground truth streamlines are shown in Fig. 8a. We find that both MCDropout and Ensemble methods produce visually accurate streamlines. We also notice that while the uncertainty patterns are generally comparable, several streamlines demonstrate different uncertainty patterns between MCDropout and Ensemble methods as seen from Fig. 8b and Fig. 8c respectively.\nHurricane Isabel Data Set. To study the uncertainty-aware streamlines in the Hurricane Isabel data set, we generate eight streamlines by seeding around the vortex core region in the data set. The ground truth streamlines are shown in Fig. 9a. Fig. 9b and Fig. 9c depict the uncertainty-aware streamlines generated by MCDropout and Ensemble methods respectively. Again, we observe a comparable uncertainty pattern for both uncertainty estimation methods.\nTurbine Data Set. Finally, uncertainty-aware streamline visualization for the Turbine data set is presented in Fig. 10. We show a visualization of a selected streamline, generated by the MCDropout method, in Fig. 10a. Visualization of the same generated by the Ensemble method is given in Fig. 10b. The rotor blades in the Turbine data set are shown as a context using gray surface rendering, and the ground truth streamline (in red color) is overlaid for visual comparison. Similar to the previous case studies, we observe comparable uncertainty"}, {"title": "4.3 Visual Analysis of Flow Features Using Uncertainty-Aware Critical Points", "content": "Critical points play an important role in studying vector field characteristics as it helps identify points where the flow behavior undergoes significant changes. These points, including saddles, sources, centers, and sinks, provide valuable insights into the dynamics of the vector field. By observing critical points, users determine flow patterns, locate stagnation points, and comprehend the overall flow behavior. Comprehensive understanding of robustness of critical points can lead to the accurate flow features study [16,24,72] and flow data compression [45].\nIn this study, we evaluate the accuracy of uncertainty-aware neural models in predicting critical point locations and quantify the spatial variability of these predictions using the MCDropout and Ensemble methods. Initially, we compute the mean vector field using both techniques to ensure the robustness of the estimated critical points. From this mean-field, we identify the critical point locations. To assess the spatial variability of each critical point's location derived from the mean field, we analyze data from individual vector field realizations: 100 fields for the MCDropout and 30 for the Ensemble method. For each method, first, we identify critical points in each vector field realization. Then, we create a new scalar field where the scalar value at each grid point reflects the cumulative contribution of all critical points from all the field realizations. Here, we do not distinguish between critical points detected from different MC samples (or ensemble members). Each critical point deposits its contribution to all the grid points. The contribution of a critical point to a grid point is calculated as the inverse Euclidean distance between the critical point and the grid point. Hence, the contribution of a critical point to the nearby grid points will be higher and gradually fall off for far away grid points. Formally, for a grid point P, we compute its scalar value as follows: $v_P = \\sum_{i=1}^{N} \\frac{1}{D(P, C_i)}$, where $v_P$ denotes the value at grid point P and D(P, C) is the Euclidean distance between point P and critical point C; with N being the total number of critical points detected across all realizations.\nTherefore, a grid point with a higher value will indicate a relatively"}, {"title": "5 QUANTITATIVE EVALUATION AND PARAMETER STUDY", "content": "We examine the precision of streamlines generated by both MC-Dropout and Ensemble methods, utilizing averaged mean streamlines for comparison. To conduct a thorough quantitative assessment, we generate mean streamlines from 100 randomly uniformly distributed seed points for each method. Subsequently, we gauge the streamline error by measuring Chamfer distance [4] and Hausdorff distance between the predicted averaged streamlines and the ground truth counterparts. It's noteworthy that for the MCDropout method, we aggregate results over 100 Monte Carlo (MC) samples, while for the Ensemble method, we utilize streamlines predicted by 30 ensemble members. The average Chamfer distance and Hausdorff distance values computed over the 100 streamlines for each data set are presented in Table 5. It is evident that the Ensemble method consistently yields more precise streamlines compared to the MCDropout method across all data sets, as evidenced by the lower Chamfer and Hausdorff distance values.\nTo quantitatively assess the precision of the identified critical point locations, we calculate the average root mean squared error (RMSE) between the predicted and the corresponding ground truth critical points for both MCDropout and Ensemble methods. The outcomes are documented in Table 6 for the Heated Cylinder and Fluid data sets. It is apparent that, on average, the Ensemble method outperforms the MCDropout method in accurately determining critical points using the reconstructed vector field."}, {"title": "6 DISCUSSION", "content": "We advocate the use of DNNs equipped to quantify uncertainty when analyzing vector fields. We find that uncertainty-informed neural networks offer valuable insights into the reliability of their predictions. By effectively conveying such uncertainty to experts, they can make well-informed decisions about the data features. This integration of uncertainty is crucial in fostering trust in the use of DNN-predicted results for scientific research. Particularly when dealing with large vector fields, scientists often have to rely on the model's outputs due to the impracticality of handling full-resolution data. In such cases, where ground truth data may be unavailable, estimating errors becomes challenging. However, uncertainty-aware DNNs can still provide reliable uncertainty estimates, offering experts greater confidence in interpreting predicted results. Next, we discuss the domain expert feedback to highlight the implications of our proposed techniques.\nWe interviewed a computational fluid dynamics scientist to collect expert feedback. The expert immediately liked the idea of using uncertainty-aware neural models and agreed that visualizing prediction uncertainty on predicted flow features is critical and can provide meaningful insights about the prediction's quality and help build trust in using deep learning techniques for scientific research. The expert found our uncertainty-informed streamline visualization intuitive and easy to comprehend. The expert was also intrigued to see that these neural models can be both under-confident and over-confident, as highlighted in Fig. 15, and agreed that access to such results is critical for verifying and validating hypotheses from flow data. Next, the expert suggested that developing such uncertainty-aware models for time-varying flow data would be very useful. Finally, the expert observed that complex and turbulent regions tend to incur higher prediction uncertainty, which was expected since predicting intricate flow features is a more complicated task than predicting less turbulent flow. This is because of the highly nonlinear and multiscale nature of turbulent flows. However, the expert further noted that large-scale ocean and upper atmospheric flows tend to be non-turbulent, and hence the proposed method can serve as an effective uncertainty-aware compression method for such large-scale flow data.\nFormally, both MCDropout and Ensemble methods consider the expected model output to be the mean and so we visualize the mean streamlines. However, to mitigate outlier sensitivity, our method also allows visualization of the median streamline, which is less affected by outliers. Experiments show that mean and median streamlines are nearly identical, with minor differences. In Fig. 16, results from the Isabel data show that for both methods, mean (green) and median (blue) streamlines generally overlap, though the zoomed inset reveals slight differences for the Ensemble method."}, {"title": "7 CONCLUSIONS AND FUTURE WORK", "content": "This paper emphasizes the importance of understanding uncertainty by applying two uncertainty estimation methods. While in this work, we study the impact of uncertainty on tasks such as vector data prediction, streamline generation, and critical point detection, in the future, we plan to conduct a comprehensive topological analysis and thoroughly study flow map characteristics to evaluate reconstruction quality further using the proposed methods. Other future research endeavors include exploring alternative deep uncertainty estimation techniques and expanding our method to handle time-varying data. Insights from uncertainty estimates help identify areas needing explicit training and recognize model limitations in specific data regions. In critical scenarios, a model's confidence in its predictions is crucial, fostering greater trust when the model acknowledges its uncertainties."}]}