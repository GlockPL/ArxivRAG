{"title": "Hawk: An Efficient NALM System for Accurate Low-Power Appliance Recognition", "authors": ["Zijian Wang", "Xingzhou Zhang", "Yifan Wang", "Xiaohui Peng", "Zhiwei Xu"], "abstract": "Non-intrusive Appliance Load Monitoring (NALM) aims to recognize individual appliance usage from the main meter without indoor sensors. However, existing systems struggle to balance dataset construction efficiency and event/state recognition accuracy, especially for low-power appliance recognition. This paper introduces Hawk, an efficient and accurate NALM system that operates in two stages: dataset construction and event recognition. In the data construction stage, we efficiently collect a balanced and diverse dataset, HawkDATA, based on balanced Gray code and enable automatic data annotations via a sampling synchronization strategy called shared perceptible time. During the event recognition stage, our algorithm integrates steady-state differential pre-processing and voting-based post-processing for accurate event recognition from the aggregate current. Experimental results show that HawkDATA takes only 1/71.5 of the collection time to collect 6.34x more appliance state combinations than the baseline. In HawkDATA and a widely used dataset, Hawk achieves an average F1 score of 93.94% for state recognition and 97.07% for event recognition, which is a 47. 98% and 11. 57% increase over SOTA algorithms. Furthermore, selected appliance subsets and the model trained from HawkDATA are deployed in two real-world scenarios with many unknown background appliances. The average F1 scores of event recognition are 96.02% and 94.76%. Hawk's source code and HawkDATA are accessible at https://github.com/WZiJ/SenSys24-Hawk.", "sections": [{"title": "1 INTRODUCTION", "content": "Indoor human activity recognition (HAR) is an attractive issue. Appliance usage, as an essential part of indoor activities, reflects people's daily routines and impacts household energy consumption. Accurate detection of appliance usage enables various applications, such as detecting hazardous appliances (e.g. chargers for flammable lithium batteries), elderly care [39], building energy management[28, 48], and optimizing operating plans for residential [43] and indus-trial users [30]. Non-intrusive appliance load monitoring (NALM) [16] detects the usage of individual appliances by monitoring the main circuit without indoor sensors. Due to its ease of deployment, pri-vacy protection, and low hardware cost, NALM is very attractive [32,38] and is considered vital for smart meters [14, 42].\nDespite its potential, existing NALM systems struggle to bal-ance algorithm accuracy with the efficiency of dataset construction. NALM is a typical single-channel blind source separation (SCBSS) problem[52], which is highly underdetermined [19] and challenging. Current algorithms mainly focus on recognizing a few noticeable appliances [4, 19, 52] and are hard to identify low-power ones from the total current. Moreover, long-term data collection is necessary to capture diverse real-world samples for model training[24, 45], and manual inspection is essential for accurate data annotation[12], which becomes a burden for supervised NALM algorithms[55]. Therefore, building a NALM system that accurately identifies all household appliances, especially low-power ones, faces three chal-lenges:\nInefficiency of dataset collection. Like most HAR scenarios, NALM data collection suffers from data scarcity[45] and imbal-ance[29, 53]. Most appliances, such as 86% in the BLUED dataset[12], are switched less than ten or even zero times a day. In addition, the distribution of the usage of different appliances is highly imbal-anced. The distribution of usage varies over time and in different households, making it difficult for the training sets collected to represent various real-world conditions [45]. Therefore, traditional NALM data collection involves long-term data acquisition in differ-ent households[24], which is time consuming and error prone[8].\nImbalanced appliance usage leads to redundant samples [40, 47, 53] and insufficient usage data for some appliances [12, 50], which bur-dens feature extraction and model training[40].\nInefficiency of dataset annotation. Traditional NALM sys-tems collect the aggregated current and individual appliance status"}, {"title": "2 RELATED WORK", "content": "NALM Sampling Synchronization. The NALM datasets capture the current or power consumption in the main circuit as input to the model and collect the current or power consumption of the individual appliances for data annotation. In such a typical distributed data sampling scenario, accurate clock synchronization is the foundation of accurate automated annotation. [5] and [44] rely on hardware voltage zero crossing detectors to synchronize sampling and clocks. However, such hardware-based methods are vulnerable to voltage fluctuation due to hardware error [24] or some appliances events (e.g., some low-end fans). Most works adopt network-based synchronization methods. BLOND [27] employs NTP with one deviation tested as 6.8 ms, while LIT2020 [35] uses a"}, {"title": "3 Dataset construction stage", "content": "The NALM dataset consists of two stages: dataset collection and data annotation. The collection process can be simplified as collect-ing aggregated and individual signals while a set of appliances A executes an events sequence S. Hawk makes the process efficient by automating the execution of balanced and diverse sequences using programmable appliances. Additionally, Hawk synchronizes the dis-tributed sampling by shared perceptible time, enabling automated data annotation and significantly reducing labor costs."}, {"title": "3.1 Grouped Randomized Balanced Gray Code", "content": "Hawk aims to efficiently collect a NALM dataset that satisfies the balance and diversity demands of two primary tasks: event and state recognition. This goal comes from Hawk's application scenarios, where users are interested in recognizing any subset of A with arbitrary background appliances. Therefore, there should be no assumed background currents and priority among appliances.\nHowever, in traditional NALM dataset construction[24, 26], ap-pliance sets Areal are chosen from a limited number of volunteer households, and event sequences Sreal are executed naturally by the household residents. The Sreal is naturally temporally sparse and biased according to the number of residents, their appliance usage habits, and exogenous conditions. This leads to long-term data collection periods for diverse but imbalanced samples, requir-ing additional software preprocessing over TB-level volumn of raw data, which burdens algorithm users. Thus, some works [21, 34, 35] collect datasets in a controlled laboratory to bridge appliance event execution sequence with demands of model training. However, they lack an abstraction of appliance event execution to satisfy the di-verse and balanced demands of event/state-based algorithm model training, and most only collect individual currents[21, 34].\nTherefore, we model appliance OFF-ON states as 0-1 and propose an event generation strategy based on a variant of balance Gray code (BGCode). As shown on the (a) of Figure 2, the BGCode has the following properties that make it ideal for generating event sequence that guides the execution of appliance events.\n\u2022 Balance: BGCode ensures a nearly balanced flip count for each bit, balancing switch counts among appliances.\n\u2022 One-bit clipping: BGCode differs only one bit among adja-cent states, aligning with independent appliance switches.\n\u2022 No duplicate travel: BGCode travels the entire state space with no duplicate state, minimizing switching operation.\n\u2022 Scalability: BGCode can be extended to present any even number of appliances' OFF-ON states[36].\nTraversing the entire state space of 2^n combinations becomes ex-tremely time-consuming when the number of appliances becomes large. Additionally, each state combination must stay for sufficient time intervals to collect adequate samples. Thus, we introduce grouping and randomization strategies in event generation to re-duce the size of event sequences while maintaining a diverse and balanced property. Grouping aims to reduce the scale of execution of balanced Gray code sequences. Given that we have n (4 in (a) of Figure 2) appliances divided evenly into m groups (2 in (b) of Figure 2), each group is selected to execute complete balanced Gray code sequences internally. Then, the number of events required is reduced from 2^n to m * 2^{n/m}. Such a sequence still meets the"}, {"title": "3.2 Programmable Appliance", "content": "In the actual dataset collection process, it is necessary to implement programmable appliances that execute generated event sequences automatically without ambiguity and maintain the consistency of the appliance's state in cyberspace and physical space. Hence, the following two requirements must be satisfied: accurate event execution and timely feedback of the appliance state.\nThe programmable appliance is a logical entity implemented with an event executor, an individual current sensor, and a con-troller. The event executors consist of esp32-controlled servos and relays to simulate human operations, and ESP32s provide interfaces as Restful servers. Each executor is assigned a static address and pre-calibrated to ensure accurate event execution. The controller detects the state from the cycle-level root mean squared (RMS) current collected by the individual current sensor. However, some appliances exhibit continual variations in the RMS current. Hence, we denoised the RMS current waveform by averaging values in a window of length l, specific for each appliance, excluding the n"}, {"title": "3.3 Shared Perceptible Time", "content": "Clock synchronization accuracy is crucial for NALM data anno-tation, especially for datasets with larger granularity annotations, such as the 20ms-cycle level for HawkDATA and the 6s level for UK-DALE[24]. Given a synchronization strategy with a maximum deviation of E, events occurring within E around the label bounds may cause a label-level bias, which misguides model training and data analysis. Traditional NALM data acquisition suffer from the cu-mulative error of the two-step sync. Clock synchronization protocols in cyberspace are always influenced by network jitters. Addition-ally, the delay in CPU/MCU data response can be unstable. For example, using FPGA for high-frequency ADC data buffering may cause fluctuations in event timestamping[27].\nHowever, NALM dataset construction focuses more on internal synchronization than external synchronization. Hence, we propose a sampling synchronization strategy called shared perceptible time to synchronize sampling directly. The core of the strategy is that time can be represented not only as counters driven by crystal oscillators in cyberspace but also by continuously varying physical signals. In the context of NALM dataset construction, most appli-ances are connected in parallel and share the same voltage within a household. We can utilize multichannel simultaneous ADCs to capture current alongside the voltage and timestamp each sample with (cycle number, phase value) from the voltage value. Cycle ID is confirmed by the TSF value of the first sample in the voltage cycle. The phase value is assigned a continuous distance to the first zero-crossing point, which is quantified by the sampling interval. We assume that the sampling interval remains stable over a short period, such as a voltage cycle of 20 ms, so the interval can be used to quantify the phase position. Ultimately, we construct the global current sequence by constructing the global voltage sequence."}, {"title": "4 Event Recognition Stage", "content": "NALM algorithms suffer from low signal-to-interference-plus-noise ratios(SINR), where signals and fluctuations from other appliances influence targeted appliance recognition. Hawk's enhances the tar-get events' SINR by steady-state differential current pre-process and improves the algorithm's robustness by a popularity-based voting post-processing method. Thus, some basic classifiers can achieve high accuracy and robustness in recognition while maintaining low computational overhead."}, {"title": "4.1 Steady-state Differential Current", "content": "Unlike previous work that directly applies traditional signal process-ing methods [50] or relies on model learning capabilities[48], we aim to enhance the SINR of target appliances through pre-processing by leveraging the stability and periodicity of appliance currents. We propose a feature extraction called steady-state differential (SsDiff) current, which has two key advantages."}, {"title": "4.1.1 Enhanced SINR from Differential Current", "content": "To calculate SINR, we express the signal power as the power consumption of the appliance. Given the power of the ith appliance at time t is P_{i,t}. The background noise is N_{B,t}. The SINR for the kth targeted appliance from raw data at time t is expressed as:\n\nSINR_{k,t} = \\frac{P_{k,t}}{\\sum_{i\\neq k}^{n} P_{i,t} + N_{B,t}}\n\nTherefore, smaller power appliances are generally more difficult to recognize directly from the aggregated current when running concurrently with larger ones. However, the differential current offers a different perspective. Differential current's effectiveness relies on Kirchhoff's current law, simplified as I_{sum} = I_{target} + I_{background}. When background appliance currents remain relatively stable over short durations, turning on or off the target appliances should result in a proportionate change at the main meter. Given that a switch event of kth appliance occurs within the range of (t-d, t), one of P_{k,t-d} and P_{k,t} corresponds to the power of the ON stage, P_{k,ON}, while the other corresponds to P_{k,OFF}. And P_{k, OFF} is approximately zero for most appliances. Therefore, the SINR of the kth appliance event from the differential current waveform with differential pair (t-d, t) can be expressed as follows:\n\nSINR_{k,t} = \\frac{P_{k,t} - P_{k,t-d}}{\\sum_{i\\neq k} N_{i,t} + N_{B,t}} = \\frac{P_{k,ON} - P_{k,OFF}}{\\sum_{i\\neq k} N_{i,t} + N_{B,t}}\n\nN_i represents the power of differential noise from the ith appli-ance. Since background appliances always remain relatively stable for a short period, N_{i}, is significantly smaller compared to the original power. For example, assume an indoor environment with a 40\u00b11W humidifier and a 1500\u00b120W electric kettle working together, with a background noise of 10\u00b110W. The humidifier's maximum SINR is 41/1480 if we identify directly from the total current. How-ever, after applying differential current, the minimum SINR for the humidifier's switching event is 39/(40+20) = 39/60.\nTo demonstrate differential current's benefits more vividly, we present an example in Figure 3. The left subplot shows the total current for the humidifier's on and off state when the background appliance is a kettle. Due to the high-power background kettle, the total current waveform indistinguishable changes before and after the humidifier switch. On the other hand, when background"}, {"title": "4.1.2 Enhanced Robustness from Windowed Voting", "content": "As shown in Figure 3, differential total current can extract the individual current of switching appliances while background appliances are running steadily. Moreover, most appliances undergo a transient state be-tween stable on and off states [34], as shown in Figure 4. Such transient current waveforms are more random and easily confused with waveforms from other background appliances. Therefore, we insert a fixed interval between differential current pairs, allowing us to bypass the transient state and directly capture the differential current between stable on and off states.\nUnlike previous work that expects models to learn differential information from raw inputs[48] or extract steady-state differential currents for classification after detecting events[10], we employ an one-step sliding window approach for streaming steady-state differentials, as shown in Figure 4. Additionally, we leverage an-other observed characteristic of the differential currents to enhance our algorithm's robustness further. Given a differential interval of D and an appliance transient length of t, the steady-state dif-ferential current can ideally obtain (D - t) cycles of differential current signature corresponding to the event (as illustrated by the three pairs of differential currents in Figure 4). In other words, the classifier will output the event (D - t) times. Thus, we propose a voting-based post-processing method that reports events when the report number of the classifier greater or equal to a threshold T. Such a process can tolerate (D-t-T) false negatives and T-1 false positives caused by background interference, which will effectively enhance the robustness of the model predictions."}, {"title": "4.2 Considerations of Model Design", "content": "Problem Definition. Different from appliance state recognition, we define appliance event recognition in as a time-series multi-class classification problem instead of a multi-label classification problem. In SustDataED2, out of 12,252 events involving 18 appliances, only two human-related events occurring within a specific second. Out of the 799 events for the eight appliances in the BLUED dataset, also"}, {"title": "4.3 Algorithm Pipelines", "content": "The differential currents of events of low-power appliances are vulnerable to fluctuations caused by background appliances, so the pipeline design for model training and inference must account for noise interference with recognition."}, {"title": "4.3.1 Training Data Preparation", "content": "To reduce the effect of contami-nated data on training and achieve data augmentation. We propose a three-step pipeline (depicted in Figure 5) to automatically extract and filter a sufficient number of SsDiff currents with corresponding labels for model training.\n(1) Obvious Event Localization: Unlike strictly accurate dataset annotation, we choose more noticeable current change points during inevitable stages as their on/off events to predict(such as Smart Screen's screen on event in Figure 5). Therefore, we raise the RMS-current thresholds to automatically locate more apparent event positions to prepare training data.\n(2) Data Augmentation: Steady-state differential currents are obtained by performing pairwise differential operations on the current from 50 stable ON and 50 stable OFF states on either side of appliance switches, generating 2500 pairs of differential current differences for each appliance event.\n(3) Sample Filtering: The enhanced samples are filtered by comparing the fundamental frequency harmonics with the individual appliances', reducing contaminated samples."}, {"title": "4.3.2 Inference pipeline", "content": "Hawk's inference pipeline follows a ba-sic preprocess-classifier-postprocess structure. During inference, Hawk's algorithm pipeline reads the aggregated current, organized by voltage cycles, from the smart meter to detect and classify ap-pliance events. Our algorithm pipeline based on FFT-XGBoost is shown in Figure 6, while the pipelines based on CNN and CNN-LSTM use the raw current waveform as input.\n(1) Differential Current Calculation: We compute Steady-state Differential currents by direct cycle-level current sub-traction from a 30-cycle circular buffer.\n(2) Dimensional Reduction: We take the first ten harmonics, including the real part, imaginary part, and magnitude, of differential current as model inputs after FFT transformation.\n(3) Classification: Reduced features are fed into a big XGBoost model to identify events. The model outputs 37 states, in-cluding OFF-ON states of 18 appliances and an IDLE state.\n(4) Post-processing: A post-processing strategy involves vot-ing within an 30-cycle window. The most likely event, sur-passing the voting threshold (e.g., 12 for the humidifier turn on event), is reported eventually.\nWe can use the second step to reduce the dimensionality of fea-tures while preserving sufficient information of the raw waveform because most of the current waveform energy of appliances is more concentrated in the low-frequency region. Such an operation can also eliminate the effect of high-frequency noise. Because Hawk performs continuous inference, the classifier includes an IDLE state, indicating no events detected. The results of the streaming classifi-cation are buffered in a queue of length the same as the differential gap. Each time, we count the occurrences of each category in the queue, and when the count of a specific category exceeds its cor-responding threshold, the classifier outputs that category. This postprocessing efficiently reduces false predictions caused by noise."}, {"title": "5 Prototype And Validation Settings", "content": "In this section, we first present the design of our sampling hardware prototype and then introduce different settings: laboratory, in-the-wild study in the residual and office area with a brief description of the collected dataset."}, {"title": "5.1 Hardware Prototype", "content": "Hawk hardware architecture, depicted in Figure 7, integrates three primary elements: the data acquisition board for high-frequency"}, {"title": "5.2 Laboratory Setting and HawkDATA", "content": "We build a data collection laboratory to deploy 22 common appli-ances for data collection. Among these, 18 are programmable for future algorithms to recognize, as listed in Table 1. The other 4 ap-pliances, such as a wireless router and refrigerator, are constantly on, free of human activity, and used as background appliances. We select diverse appliance representations, including those with similar functions but with different electronic circuits (e.g., LED, incandescent, and fluorescent bulbs for lighting). The electrical char-acteristics of these appliances span a wide range, from a 5W camera to a 2160W air heater and coverage of most front-end circuits[18]. Besides diversity, recognition challenges are also considered, and we also choose appliances with the same working principle but varying power ratings and appliances with close power rates. This is also an advantage of HawkDATA over others from real households with biased collections of appliances.\nHawkDATA is collected in the laboratory environment, with pro-grammable appliances executing the event schedules mentioned in Subsection 3.1. Each appliance state combination is planned to last for 20 seconds. Ultimately, the effective collection duration of our dataset is 32.2 hours, comprising a total of 5,796,650 voltage cycles for a 50Hz AC circuit. HawkDATA includes both raw and annotated versions stored in NPZ file format. The raw data version records the total current, voltage, and individual current of 18 appliances, all sampled at 16kHz. The raw-version file size is 127.8GB. The an-notated version organizes and labels the data according to voltage cycles. For a 50Hz AC circuit, each cycle contains 320 points."}, {"title": "5.3 In-the-wild Settings", "content": "The field experiment aims to validate the Hawk system and ensure that it aligns with the application scenarios. The Hawk system, with a single sensor for inference (shown on the left of Figure 9), was tested in residential and office spaces, and target appliances subsets from HawkDATA were repurchased and deployed without"}, {"title": "6 EVALUATION", "content": "As a typical distributed data collection, the quality of NALM data is evaluated from two dimensions: sample synchronization accuracy between sensor nodes and single-point current conversion linearity."}, {"title": "6.1.1 Sampling synchronization evaluation", "content": "Baseline. The baseline selected for comparison is the Time Synchro-nization Function (TSF) of the 802.11 protocol, which can achieve microsecond synchronization accuracy [6, 31]. Additionally, ESP32 provides a TSF interface, making it a suitable baseline for our low-cost distributed solution.\nEvaluation method. We assess synchronization error by compar-ing the timestamps of the same current surge point recorded by two nodes. Incandescent lamps experience a current surge when switched on. Such transient current surge is simultaneously de-tectable by the main meter and the submeter attached to the incan-descent lamp. We switch on and off the incandescent bulb using a relay to collect the synchronization deviation. Two meters for test-ing are placed less than 1 meter from the accessed wireless router to test the best performance of TSF synchronization. Additionally, a distance of around 13m is set to evaluate the impact of electrical cir-cuit length on SPT. The wireless router used for the experiment is an Asus AC66U-B1. The deviation of the SPT synchronization strategy is a continuous phase value, while the TSF-based synchronization strategy has a resolution of 1 microsecond.\nResult Analysis. The result in Figure 10 shows that Hawk's syn-chronization strategy based on SPT can achieve an average synchro-nization accuracy of 20.60us, improved by 59.2% compared to TSF, averaging 32.8us. Our maximum synchronization error is 61.80us, about 1/17.2 of TSF. We can see a gap in the error distribution of TSF; 99.65% of the synchronization accuracy is within 220us, while the other 0.35% are distributed from 980us to 1060us. This gap is due to the 1-ms WiFi packet jitter[41]. Our experiments show that the jitter ratio of beacon packets is affected by wireless channel inter-ference and the distance between the AP and the STA. In our testing scenario, several wireless APs in the office area are the sources of interference. On the other hand, our proposed SPT strategy is more robust. When the two sensor nodes are 13 meters apart, the overall accuracy improves. This is due to introduced random quantification errors, by equating the switch events of a continuous position of"}, {"title": "6.1.2 Current conversion linearity evaluation", "content": "Evaluation method. One of the challenges for sampling accuracy evaluation experiments is that we lack an ideal measurement for high-frequency current sampling instruments as a standard. Such standards invariably have their deviation ranges and come with prohibitive costs. Inspired by a commonly used evaluation metric of ADC/DAC, differential linearity, we designed an assessment method. Differential linearity of ADC refers to the stable relationship be-tween the digital output changes and the analog input variations at different starting points. As shown in Figure 11, we evaluated the differential linearity of HawkDATA by comparing the stability of the ratio between the total meter reading differences and current differences before and after switching events for different appli-ances under varying background currents. The current difference is presented as sub-meter reading differences. Since most appli-ances operate within a more stable and lower current range when compared with aggregated current, we assume that the current differences maintain a consistent ratio with the reading differences. Finally, we organize different appliance switches' average normal-ized linearity rates within the same range of background currents into a box and show their changes along the change of background currents in Figure 12.\nEnsuring the differential linearity of our sampled values also enables our proposed steady-state differential current-based fea-ture extraction. Though not guaranteeing that the acquired data represents exact values, differential linearity ensures a stable pro-portional relationship. Such deviations are often deemed inconse-quential after typical pre-processing steps like normalization.\nResult. According to Figure 12, both mean and median values deviate by no more than 2% from the ideal unity, substantiating the stability of our data conversion process. Since this metric is statistics of raw HawkDATA, the final results ensure that within the HawkDATA, the average reading deviation of the same cur-rent variation, influenced by background current, does not exceed 2%. The data visualized in Figure 12 reveals two phenomena with increased background current. The first observation is a slight re-duction in the average normalized linearity rate which may related to property of current transformer. The second observation is the widening spread of the linearity rate distribution as the background current intensifies. The broadening is likely a consequence of the increased electrical noise and interference associated with a more"}, {"title": "6.2 Dataset Construction Evaluation", "content": "Although the sequence generated from group-randomized bal-anced Gray code guarantees balance, the practical execution of programmable appliances may deviate from this due to factors like the timed switching or operational failures; for instance, the microwave oven in Table 1 exhibits more frequent switching.\nBaseline. Our baseline is SustDataED2[33], a high-frequency NALM dataset collected from a real household. SustDataED2 com-prises the same number of appliances as the programmable appli-ances in Hawk, making it a reasonable baseline as representative of the traditional NALM dataset construction schema.\nMetrics. The metric to measure dataset balance is balance ratio (BR), the inverse of a commonly used imbalance ratio(IR) [49], to avoid the minimal value of zero[12]. The category BR is defined as,\n\nBR = \\frac{N_{min}}{N_{max}}\n\nwhere Nmin is the sample size of the minoriest category and Nmax is the sample size of the majoriest category. What's more, there are different balance requirements for state and event recognition algo-rithms. The balance requirement of the event recognition algorithm entails a uniform distribution of switch events across different ap-pliances, maximizing the category BR. In contrast, state recognition algorithms require balance in two aspects [40]. First, the number of ON and OFF state samples for each type of appliance should be as close as possible. Second, the number of ON states between different appliances should be balanced.\nAs for the metrics of dataset diversity, we use the number of state combinations to represent the diversity of states and qualitatively"}, {"title": "6.3 Algorithm Pipeline Evaluation", "content": "6.3.1 Overall Setup. The evaluation of our algorithm pipeline con-sists of two parts: first, a set of ablation experiments targeting the three key designs of the Hawk system; second, a comparison of event classification accuracy on the BLUED dataset, which includes multiple multi-state appliances under different AC settings.\nWe design three ablation experiments focusing on the data bal-ance, classifier performance, and steady-state differential current of the Hawk system. The first experiment compares event recognition accuracy across different classifiers trained on balanced and imbal-anced HawkDATA. The second experiment adjusts the differential interval to evaluate its impact on recognition accuracy. The last"}, {"title": "6.3.2 Impact of classifier and dataset balance", "content": "Taking advantage of the enhanced SINR and robustness of the steady-state differential current algorithm pipeline, these basic network structures achieve high-accuracy event recognition, yielding similar final results. As shown in Figure 14, we choose FFT-XGBoost as our classifier, as it exhibited the highest recognition accuracy on the balanced dataset while maintaining minimal algorithmic overhead, enabling real-time recognition on embedded CPU platforms.\nRegarding the impact of dataset balance, all classifiers demon-strated decreased recognition accuracy on the imbalanced dataset, even though most HawkDATA appliances are commonly used and the sample sizes are not significantly reduced. Additionally, differ-ent classifiers exhibited varying tolerances to dataset imbalance, with CNN-LSTM showing the least impact."}, {"title": "6.3.3 Impact of differential distance", "content": "As illustrated in Figure 4, the distinction between steady and transient state differential current lies in the differential distance, which is consistent with the length of the voting window. A smaller differential distance results in a higher proportion of transient features within the voting window that cover events, while a larger differential distance increases the proportion of steady-state features. Moreover, the voting length affects the model's tolerance to false predictions; a larger differential interval increases the model's tolerance for errors. However, larger intervals also raise the likelihood of random noise interference and the occurrence of multiple events. Consequently, average accuracy"}, {"title": "6.3.4 State Identification Accuracy on HawkDATA", "content": "Figure 16 evalu-ates the impact of integrating steady-state differential current into the algorithm pipeline on state recognition accuracy and compares it with SOTA performance.\nThe results in Figure 16 show that the same XGBoost classifier, and CNNs with identical parameter sizes, significantly improve state recognition accuracy when integrating differential current processing. Additionally, compared to the best SOTA performance, our simple classifier based on steady-state differential processing improved state recognition accuracy by 47.98% to 48.07%.\nWe observe that the previous two SOTA works performed poorly on HawkDATA. The evaluation results of the low-frequency signal-based MSDC align with earlier observations [21, 34], behaving poorly in power trace decomposition. In contrast, the high-frequency signal-based CALM was evaluated on a single-appliance dataset."}, {"title": "6.3.5 Event Classification Accuracy on BLUED Dataset", "content": "To validate the effectiveness of the Hawk algorithm pipeline for multi-state appliances and different AC standards, we trained the Hawk recog-nition model on the BLUED dataset for event classification. The event recognition of Hawk for multi-state appliances is similar to OFF-ON appliances, requiring pre-labeling all possible events for target appliances. The final recognition results are summarized in Table 2, compared with SOTA published results.\nAccording to Table 2, Hawk event classification average F1 score outperforms MTS-Shapelet by 11.57%, and the weighted average F1"}, {"title": "6.4 In-The-Wild Evaluation", "content": "6.4.1 Overall Setup. In the field experiments, our objective is to validate the effectiveness of the Hawk system in real world scenar-ios, which includes computational overhead, real-time performance, and recognition accuracy in various unknown background appli-ance settings. The Hawk model was deployed without modification in two real scenarios that align with the application scenario.\nComputational Platforms. To validate Hawk run-time perfor-mance, we performed real-time streaming inference performance assessments on three CPU-based platforms, as listed in Table 3.\nMetrics. We use the F1 score to evaluate the accuracy of Hawk system recognition, with the average F1 score used to assess overall performance. For runtime performance, we measure the Hawk's av-erage streaming inference latency and the actual memory footprint (Residential Set Size, RSS) of the entire program.\n6.4.2 Run-time Performance Evaluation. This section aims to eval-uate the performance of streaming inference, which processes indi-vidual samples sequentially. The real-time requirement for stream-ing inference is that the average inference latency must be less than the average generation delay (20 ms in our AC settings). This is"}, {"title": "6.4.3 Event Recognition Accuracy Evaluation", "content": "The event recogni-tion accuracy in two real environments is summarized in Table 4."}, {"title": "7 Discussion And Future work", "content": "In this section, we discuss some limitations of the Hawk system and analysis of recognition failures.\nLimitations of Binary Modeling: The balanced Gray code-based strategy models appliance OFF-ON states as binary bit value, which does not accommodate multi-state appliances. OFF-ON appliances can be considered a particular case of multi-state appliances. The performance of Hawk's algorithm pipeline on the BLUED dataset, which includes multi-state appliances, proves that the processes of recognizing OFF-ON events and multi-state events are inter-connected. However, this characteristic limits the diversity of the"}, {"title": "8 CONCLUSION", "content": "Non-intrusive appliance load monitoring(NALM) faces the chal-lenges of high dataset construction overhead and low appliance identification accuracy. This paper presents Hawk, an efficient NALM system for accurate low-power appliance recognition. To improve the efficiency of dataset construction, we propose an effi-cient dataset construction scheme based on balanced Gray codes and a sampling synchronization strategy based on shared percep-tible time to enable automatic data annotation. Taking advantage of the enhanced SINR and robustness provided by the steady-state differential current-based algorithm pipeline, some basic classi-fiers perform high accuracy and low computational overhead in real-time recognition across different tasks, even with low-power appliances. To our knowledge, Hawk is the first NALM system to accurately and in real time identify low-power appliance usages in real-world scenarios, with an average cost of stable high-frequency current sampling of only $4.12. A balanced and diverse NALM dataset, HawkDATA, has been published."}]}