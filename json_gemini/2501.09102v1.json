{"title": "Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites", "authors": ["Hans W. A. Hanley", "Emily Okabe", "Zakir Durumeric"], "abstract": "Understanding how misleading and outright false information enters news ecosystems remains a difficult challenge that requires tracking how narratives spread across thousands of fringe and mainstream news websites. To do this, we introduce a system that utilizes encoder-based large language models and zero-shot stance detection to scalably identify and track news narratives and their attitudes across over 4,000 factually unreliable, mixed-reliability, and factually reliable English-language news websites. Running our system over an 18 month period, we track the spread of 146K news stories. Using network-based interference via the NETINF algorithm, we show that the paths of news narratives and the stances of websites toward particular entities can be used to uncover slanted propaganda networks (e.g., anti-vaccine and anti-Ukraine) and to identify the most influential websites in spreading these attitudes in the broader news ecosystem. We hope that increased visibility into our distributed news ecosystem can help with the reporting and fact-checking of propaganda and disinformation.", "sections": [{"title": "1 Introduction", "content": "Misinformation has promoted dangerous fake health cures [16], promoted jingoism and propaganda during wars [84, 109, 121], and incited violence [6, 17]. While there has been significant investigation into how misleading information spreads across social media platforms and fringe websites [80, 81, 127], recent work has emphasized that the vast majority of people do not visit fringe websites or regularly encounter misinformation on social media [10, 101]. Rather, most people consume news through more mainstream platforms like television news [10]. However, systematically tracking how misleading, propagandistic, and outright false information spreads from untrustworthy websites into mainstream media and how fringe sites influence the broader news ecosystem remains a significant technical challenge due to the magnitude and distributed nature of the global news ecosystem [9, 19, 61, 127].\nIn this work, we introduce and validate a system for scalably identifying and tracking potentially unreliable news narratives across different English-language media ecosystems. Building on past work [3, 62, 92, 145], our proposed approach: (1) collects articles by continually crawling news sites from across media ecosystems; (2) extracts semantic narratives and sites' stances towards different topics using a fine-tuned version of the e5-base-v2 large language model [138], DP-Means clustering [38], and zero-shot stance detection [8]; and (3) identifies the relationships between news sites and broader ecosystems using the NETINF algorithm [49]. We emphasize that our approach does not make factual assessments of individual stories, which is a deeply nuanced task. Rather, our system allows us to shed light on how stories travel across the distributed news ecosystem.\nWe analyze the results from our deployed system for an 18 month period during which we collected articles from pre-curated lists of 1,003 factually unreliable news websites (e.g., twisted.news), 1,012 mixed factuality reliability websites (e.g., foxnews.com), and 2,061 factually reliable news websites (e.g., washingtonpost.com) maintained by Media-Bias/Fact-Check [33]. Analyzing 146K stories that our system extracted from 29M articles on these news websites, we observe significant crossover in the stories covered by different news ecosystems [136]. We show that reliable and mixed-reliability news websites play the largest role in setting the stories and narratives addressed by other websites. However, despite covering similar topics, our stance analysis reveals that each type of website adopts distinctive stances towards shared topics, with reliable news websites generally being left-leaning and pro-Ukraine and unreliable websites being the most right-leaning and anti-Ukraine.\nFraming our story clusters as cascades, our system uses NETINF [49] to uncover relationships between news sites and to detect potential networks of coordinating websites that spread particular slanted content and narratives. For example, using this approach we identify a network of right-leaning news websites that ostensibly act as local-news websites all operated by Metric Media, LLC. From the out-"}, {"title": "2 Related Work", "content": "Significant prior work has studied news ecosystems and analyzed how misinformation spreads online. Here, we summarize the prior work that our study builds on:\nTracking Narratives on News Websites. Several studies have utilized online document clustering [22, 142] for tracking news stories. For example, Zhang et al. [146] identify potential events by monitoring for the appearance of specific phrases or keywords, cluster identified phrases that may indicate news events, and train a series of classifiers to assign news articles to identified clusters. Similarly, by clustering a collection of short phrases or \u201cmemes,\u201d Leskovec et al. find that smaller blogs often play a definitive role in encouraging the adoption of particular language onto mainstream websites [85]. Rodriguez et al. [49, 50] examine the changing relationships between websites during the discussion of news events, finding that connections between websites increase during periods of high activity.\nWhile many studies have analyzed topics using statistical word-association approaches like Latent Dirichlet Allocation (LDA) and Dynamic Topic Models [5, 100, 147], recent works such as those by Meng et al. [96], Hanley et al. [56, 61], and Grootendorst [52] have used large language models (LLMs) for more granular topic modeling. In line with our work, Nakshatri et al. [104] utilize peak detection and HDB-SCAN [93] on news article embeddings to identify the most prominent news events in a stream of news articles. Saravanakumar et al. [119] similarly utilize an external named entity recognition system to embed entity knowledge into a BERT language model to differentiate between news articles about different events. Beyond these quantitative approaches, many prior works have qualitatively investigated the spread of individual news stories (e.g., [112, 120, 127]).\nMost similar to our work, Hanley et al. [62], using MP-Net and DP-Means clustering, track news narratives across a smaller number of fringe websites to determine the role that individual unreliable news websites play in originating and amplifying news narratives. Their work finds that less-popular websites oftentimes play an outsized role in promoting narratives that reverberate across the unreliable news ecosystem.\nIn contrast to these prior works, our study accounts for the stance towards each topic in order to better differentiate between articles that cover the same topic. Tracking stance enables our work to understand the widespread understanding of individual websites' ideologically skew, changes in coverage of individual topics, and the detection of websites that coordinate in spreading particular types of propaganda.\nAnalyzing the Spread of Misinformation. While our approach is one of the first to track both topic and valence/stance towards that topic in a programmatic manner, several prior works have focused on the peculiarities, detection, and the spread of misinformation. For example, Ma et al. [88] and Jin et al. [71] utilize recurrent neural networks to analyze and detect the spread of unreliable rumors on social media. Abdali [1] et al., taking a domain-based approach, use website screenshots to assess the credibility of news websites. In addition to analyzing the spread of general misinformation on particular social platforms, other works have further investigated the spread of specific narratives, including those concerning the Syrian White Helmets [127], QAnon [11, 58, 107], the Russo-Ukrainian War [59, 61, 109], and COVID-19 [4, 31, 89]. We note that because work utilizes topic analysis followed by stance detection, our system can be used to quickly identify websites and topics that deserve in-depth investigation of particular types of coverage of individual events.\nBuilding off these studies, several works have analyzed the characteristics of misinformation. Juul and Ugander find that often false information on Twitter spreads faster and wider than factual information [73]. Indeed, Kwon et al. [81], utilizing the distinct temporal differences between reliable information and unreliable rumors, are able to classify these rumors with an F\u2081-score as high as 0.878. In a different work [80], Kwon et al. analyze the semantic and structural characteristics of rumors on Twitter. In a different vein, Using a learning-to-rank-based approach and ClaimBuster API, Paudel et al. [108] identify potential claims that should be fact-checked on Twitter [64]. Beyond studying the dynamics of misinformation, Bak et al. [15] have proposed concrete steps to ameliorate the spread of misinformation, including removal and nudges. Finally, Kaiser et al. [74] have studied how borrowing techniques from the security warning landscape might help inform users of potential misinformation.\nUnlike the past approaches outlined above, by utilizing fine-tuned encoder-based large language models, our work scalably tracks and identifies unique news stories across thousands of news websites without depending on particular key-"}, {"title": "3 Methodology", "content": "In this section, we provide an overview of our data collection and approach for extracting and tracking narratives across different types of news websites."}, {"title": "3.1 News Websites", "content": "Our study analyzes articles collected from three sets of English-language news websites of varying factual reliability. We specifically track narratives on websites rated by Media-Bias/Fact-Check [33], a media monitoring website founded by Dave M. Van Zandt to assess the factual reliability of individual websites given its widespread use in prior work [14, 62, 103, 139] and its ratings' high agreement with other organizations like NewsGuard.\nUnreliable News Websites. We collect news articles from 1,003 websites labeled as having \"low\" or \"very low\" factual reporting by Media-Bias/Fact-Check [33]. We extend this list with conspiracy theory-promoting websites identified by Hanley et al. [60]. Our list of unreliable news websites includes pseudo-science sites like vaccine.news, state-propaganda outlets such as rt.com, and partisan websites with low-factuality ratings like the liberal-leaning occupydemocrats.com.\nMixed-Reliability News Websites. We collect articles from 1,012 mixed-reliability news websites labeled as having \"mixed\" factual reporting by Media-Bias/Fact-Check [33]. This list includes websites across the political spectrum, such as foxnews.com, nypost.com, and theguardian.com.\nReliable News Websites. We collect articles from 2,061 reliable news websites labeled as having \u201chigh\u201d, \u201cvery high\u201d, or \"mostly factual\" reporting by Media-Bias/Fact-Check [33]. The category \u201cmostly factual\u201d is included to capture sources with strong reputations like The Washington Post. This list features websites such as reuters.com and apnews.com.\nWe lastly note that we utilize the full set of English-language news websites from the lists of Media-Bias/Fact-Check [33] and Hanley et al. [60] that were accessible to us from the beginning of our study."}, {"title": "3.2 Definition of a News Story", "content": "Our approach tracks specific news stories and their propagation across websites rather than analyzing broader themes as captured by methods like LDA [7, 36, 70]. Following previous research [61, 62], we adopt Event Registry's definition of a news story as \"collections of documents that seek to address the same event or issue\" [83, 98]. It is important to note that even if two ideas are related, they may not constitute the same news story. For example, while \u201cFlorida Governor Ron DeSantis declares for President\u201d and \u201cNikki Haley surpasses Ron DeSantis in the polls\" are related, they are considered separate news stories in our work."}, {"title": "3.3 System Architecture", "content": "Our approach for capturing and tracking news stories builds on the LLM-based narrative tracking methodology introduced by Hanley et al. [62]. However, while Hanley et al.'s method scalably tracks individual topics, their work does not incorporate articles' attitudes towards a topic. While this was not problematic for their work, which focused on the spread of stories amongst unreliable news websites, the approach cannot track news stories across a broader set of news websites that present stories in dramatically different ways. We expand their method to additionally account for the stance/valence of news articles towards a topic (i.e., we distinguish between"}, {"title": "Story Identification", "content": "We base our story-identification algorithm on Dinari et al.'s optimized and parallelizable version of the DP-Means algorithm, a non-parametric version of K-means [38]. We utilize this approach as it is highly scalable (able to cluster our 428M embeddings) unlike other LLM-based approaches [52] while also allowing us to identify stories without a priori knowledge. To further scale the approach, we re-implement DP-Means [38] to use the GPU-enhanced FAISS library [72] to perform the embedding-to-cluster assignments and similarity calculations required by DP-Means.\nTo determine a suitable threshold for clustering two news passages together, after fine-tuning e5-base-v2, we benchmark our model on the English portion SemEval 2022 Task 8 dataset [29]. The SemEval 2022 Task 8 dataset consists of two parallel lists of news articles where each pair is graded on whether they are about the same news story. Our model achieves a max F\u2081-score of 0.793 on this dataset near a cosine similarity threshold of 0.50, which we use in this work. We provide examples of passage pairs in Appendix F.\nFrom January 1, 2022 to July 1, 2023, clustering all our embeddings required the equivalent of 12 days using an NVIDIA A100 GPU. After clustering, like in other works [62, 85], we filter out clusters where 50% or more of the passages are from only one website (e.g., website-specific headers or author bios). After this pruning, we identified 146,212 story clusters. We provide 30 cluster examples in Appendix I and evaluate these 30 clusters to ensure that they contain coherent stories using the method outlined by Hanley et al. [62]. We achieve an estimated precision of 99.3% of assigning passages to appropriate story clusters where each passage matches the summary, keywords, and other passages in the cluster."}, {"title": "Story Summarization and Labeling", "content": "To build human-understandable representations of our clusters, we extract keywords using pointwise mutual information (PMI), an information-theoretic for uncovering associations [23], to uncover the words most associated with each story cluster [59]. To make these words more uniform, we lemmatize each word to each cluster before calculating PMI. For details on PMI,"}, {"title": "Website Relationship Inference", "content": "To further understand the relationships between news sites, we analyze how stories spread across websites over time. We consider the set of articles in a cluster as a time cascade based on the date that each article was published, and we use an open source version of NETINF [49] to infer the underlying structure and relationship amongst our set of news websites. Given a set of time cascades (e.g., the time steps for when a particular website posts an article within a given story cluster), while assuming that each node in a particular cascade is influenced by exactly one other node, the NETINF algorithm attempts to infer the optimal network to explain the observed posting behavior [49]. Based on each website posting behavior across the different cascades, NETINF estimates the number of times that each website copied information from another as well as the time delay between copies. We provide additional details in Appendix G."}, {"title": "Stance Detection", "content": "While passages may cover the same story, they often adopt different stances [61, 78, 99] in addressing the same event. After identifying the stories on our set of news websites, we employ stance detection to understand how different websites address each story. Stance detection methods determine the attitude of an author toward a specific topic or target [20]. Typically, stance detection involves taking a passage $p_i$ and a topic or target $t_i$, and outputting the stance $s_i \\in {Pro, Against, Neutral}$ of the passage towards the target, where the target is a noun or a noun phrase. Given that most stance detection methods heavily rely on the topic or target, with many models struggling to generalize to topics or targets outside their domain, various models have been developed to perform stance detection in zero-shot (where the tested topics or targets are not in the training data) and few-shot (where very few examples of the tested topics or targets are in the training data) settings [8, 87].\nTo perform this stance detection, we utilize the current state-of-the-art zero-shot TATA model [55], which was trained on the VAST dataset [8]. We note that the size of our dataset of stance pairs precluded us from using popular large language model services like GPT-4 or Claude Sonnet. To enhance this model, we retrained it on both the VAST dataset and news-"}, {"title": "5 Underlying Website Relationships", "content": "As observed in Section 4, unreliable, mixed-reliability, and reliable news websites often cover the same stories simultaneously, suggesting an interdependence [127]. To further understand these relationships, we utilize an open source version of the NETINF [49] algorithm to infer the underlying structure and relationships amongst our sets of news websites [85]. Specifically, we first run NETINF using all of the extracted stories within our dataset as time cascades. To determine the appropriate number of iterations to run NETINF algorithm, as in Gomez et al. [49], we utilize the point at which the marginal gain of adding new edges plateaus (90% of the total marginal gain). We find that margin gain reaches a plateau at 37,670 iterations in our dataset.\nEcosystem Relationships Across All News Stories. Using the estimated number of copies between websites and the time delay between copies as found by NETINF, we first examine the overall relationships between ecosystems. We find that reliable and mixed-reliability news websites have a large role in introducing stories adopted by the rest of the news ecosystem. As seen in Figure 5a, 60% of the news articles on reliable news websites that were copied/influenced from elsewhere came from other reliable news websites, 43% on mixed-reliability websites came from reliable sites, and 32% on unreliable sites came from reliable sites. Unreliable news websites had significantly less influence, with only 10% of the stories on reliable news websites originating from unreliable news websites (13% for mixed-reliability, 27% for unreliable).\nLooking at the set of reliable websites that are the most common sources of copied stories throughout the entire news ecosystem, we see several popular websites including yahoo.com (1.19%), apnews.com (0.73%), abcnews.go.com (0.60%), and cnn.com (0.60%). Despite popular, reliable news websites being common sources, website popularity had only a slight Pearson correlation with their percentage of copies. Using data from the Google Chrome User Report (CrUX)"}, {"title": "Influence on the Full News Ecosystem", "content": "Having examined the website copies and rates of adoption between the different ecosystems, we next consider which websites are the most influential using the graph of the edge connections between individual news sites. Eigenvector centralities are utilized to determine the relative influence of nodes within graphs [115] and, as such, we utilize this metric to understand websites' influence. We further compute hub centralities as a metric for websites' influence in originating stories that spread to other websites (given the directionality of the arrows in our graph, this metric determines the most important websites for supplying content [76]). We show the most influential sites in Table 6 and Figure 6.\nWe find that website popularity is correlated with the relative influence of websites within the news ecosystems (when looking at all news sites compared to only reliable sites in the last section). Again using website popularity data from the Google Chrome User Report (CrUX), we find that a website's eigenvector centrality/influence has a Spearman correlation of \u03c1 = 0.571 (0.396 for hub centrality) with that website's popularity rank. Despite making up 24.6% of the news websites in our dataset, unreliable news websites do not make up a proportional percentage amongst the most influential news websites. Directly comparing the eigenvector centralities of the reliable news websites to those of the unreliable news websites, we find that reliable news websites are significantly more influential in this ecosystem than unreliable news websites (Cohen's D = 0.64, p-value \u2248 0), with mixed reliability websites having comparable influence to reliable ones (no significant difference through Mann Whitney U-test). In terms of origination (hub centralities), we observe a slightly different trend with mixed-reliability websites having slightly more influence in originating stories compared to reliable news websites (Cohen's D = 0.04, p-value \u2248 0) and unreliable news websites (Cohen's D = 0.05, p-value \u2248 0).\nStories Spread by Unreliable News Websites. To identify the websites most inflential in spreading potentially unreliable stories, we run the NETINF algorithm on the set of 6,762 news stories where unreliable news websites posted the plurality of articles about those stories. Again applying the same methodology for identifying the appropriate number of edges to add, the marginal gain plateaus at 16,196 edges. The most popular story amongst these clusters was about government censorship and control (9,094 articles) summarized as: There is censorship, propaganda, and government control in the US. Cancel culture is a form of censorship, and that government-funded media outlets can exercise control over editorial content. The text also warns about the influence of the \"Deep State\" and far-left communists in US institutions, including the government, media, education, and Big Business.\nAs expected, given how we narrow our set of stories, as seen in Figure 5c, relative to all news stories, unreliable news"}, {"title": "Influence in the Unreliable News Ecosystem", "content": "To understand which websites are the most influential in the unreliable news ecosystem, we utilize the eigenvector centrality of each website in the resultant graph created by running NETINF on our set of predominantly unreliable news stories (Table 8). For this ecosystem, we find the popularity of websites is only slightly correlated with eigenvector centrality/influence (\u03c1= 0.158) and hub centrality (\u03c1= 0.175). Examining the set of websites that are most prominent within the unreliable news ecosystem (Table 8 and Figure 7), we find that many well-documented websites known for spreading unreliable information are among the most prominent, including theepochtimes.com, dailymail.co.uk, and thegatewaypundit.com [127].\nComparing the eigenvector centralities of the unreliable news websites to those of the authentic news websites, we find that unreliable news websites are more influential within this ecosystem (Cohen's D = 0.219, p-value < 0.001), but that unreliable and mixed-reliability websites had comparable influence (no significant difference via the Mann-Whitney U-test). However, most notably, we observe that among the top influencers within this ecosystem are the reliable news website, Yahoo News, and the mixed-reliability Fox News (not shown in the table). Yahoo News primarily serves as a news aggregator, gathering reports from various sources including Fox News, the BBC, and Reuters [143]. Given its role as an aggregator, Yahoo News appears to have a prominent role in disseminating current events that are reported by other outlets."}, {"title": "6 Propaganda and Slanted Influence Networks", "content": "As seen in the last section, news sites, regardless of their factual reliability, often report on the same stories, with unreliable news websites in select cases influencing both reliable and mixed-reliability news platforms. Furthermore, while reliable and mixed-reliability news websites predominantly adopt stories from other reliable and mixed-reliability sources (Figure 5a), for topics primarily spread by unreliable news websites, these specious sources often act as the originators of the content (Figure 5c). Within this vein, tracking the spread of unreliable news and propaganda and determining which sources are most effective at seeding these stories into the mainstream media is critical for fact-checkers, journalists, and researchers [62, 127]. To this effect, in this section, we utilize our system to map out and understand the sites originating and spreading specific propaganda and influence campaigns.\nTo map the influence networks targeting specific entities (either positively or negatively), we gather news articles and the associated sites that exhibit a particular valence towards a given entity (e.g., anti-vaccine articles). Upon gathering this subset of news articles, we run the NETINF algorithm over these cascades of news article clusters with specific stances. We subsequently perform network analysis using eigenvector centrality and hub centrality, as discussed in the previous section, to identify the most prominent and influential sites promoting a given stance towards a particular subject. By"}, {"title": "Anti-Ukraine Messaging", "content": "As seen in Figure 9 and Table 9, the most prominent anti-Ukrainian news websites during our study included well-known Russian propaganda websites such as Russia Today (RT), Sputnik News, and News-Front [106]. Beyond known Russian propaganda sites, we also find that antiwar.com, described as a \"libertarian non-interventionist website\" [33], is one of the most prominent websites in spreading anti-Ukrainian content. Altogether, as seen in Figure 8, unreliable news websites largely supply the majority of the stories used across the entire news ecosystem, with reliable websites copying 53% of anti-Ukrainian stories from unreliable outlets, mixed-reliability websites copying 61%, and unreliable sites 70%.\nThe most common story pushed in this ecosystem of websites concerned justifications for Russia's invasion of Ukraine, with one Russia Today article writing [132]: Moscow attacked the neighboring state in late February, following Ukraine's failure to implement the terms of the Minsk agreements signed in 2014, and Russia's eventual recognition of the Donbass republics of Donetsk and Lugansk. Further, the anti-Ukrainian news story that received the largest increase in relative popularity among our unreliable news websites in the last week of our study (June 25 to July 1, 2023) featured a series of articles with the keywords Ukraine, MacGregor, Douglas, Colonel, Zelensky, showing a ratio of 9 articles in the unreliable news ecosystem for every 1 article in the reliable news ecosystem. This story, which predominantly spread within the unreliable news ecosystem, concerned an interview with retired US Colonel Douglas MacGregor suggesting that the war between Ukraine and Russia was unwinnable and that Ukrainian"}, {"title": "Anti-Vaccine Messaging", "content": "As seen in Figure 11 and Table 9, the largest source of anti-vaccine stories was naturalnews.com, while the most influential anti-vaccine website was theepochtimes.com, both known for spreading anti-vaccine misinformation [33, 111]. As with anti-Ukraine stories, we observe that each website category predominantly sourced their content from unreliable news websites: 51% for reliable news websites, 66% for mixed-reliability news websites, and 81% for unreliable news websites. In addition to the theepochtimes.com and naturalnews.com, we find that childrenshealthdefense.org, a website associated with former presidential candidate Robert F. Kennedy Jr., had a major influence on spreading anti-vaccine content, including one article sug-"}, {"title": "7 Limitations and Future Work", "content": "Our work shows the promise of mapping the global trajectories of news stories and the takes of news sites towards specific entities. However, we the emphasize the complexity of the global news ecosystem and the considerable future work that remains to understand how information travels online. Below, we discuss the limitations of our work and potential future research directions.\nEnglish-Language Websites. Our work is limited to English-language news articles and focuses predominantly on US, UK, and Australian websites. As a result, our analysis of the spread of particular stories is limited largely to the English speaking world and could miss other sources of news (i.e., a Russian-language website for example may be more influential in spreading pro-Russian propaganda than the websites in our dataset). This restriction is largely due to our use of PMI for identifying keywords for stance detection amongst our story clusters, which does not directly work in a multilingual setting. Similarly, we currently lack highly accurate multilingual topic-agnostic stance-detection models [55, 63]. We encourage future work to consider how to semantically map both news topics and stances towards them in multilingual settings, as well as to consider how to source news content from websites in additional languages.\nAutomated Fact-Checking of Narratives. As previously noted, we do not fact check individual news stories, which we argue is a journalistic task beyond the scope of our automated approach. While our system can be utilized to uncover networks of websites pushing potentially unreliable news narratives allowing journalists to prioritize which stories need to be fact-checked by their relative spread, these stories still require human investigation to determine their veracity. However, we note that for stories that have already fact-checked on reputable websites, it may be possible to incorporate the approaches of Hanley et al. [62], Zhou et al. [148], and others to automatically label particular stories. Hanley et al.'s approach involves gathering fact-checks from reputable sources and using a DeBERTa-based model [65] to identify unreliable news stories that directly contradict these fact-checks [62]. In a similar fashion, Zhou et al.'s [148] approach involves using a LLM agent and Google Search to identify which unreliable news stories contradict fact-checks."}, {"title": "Ephemeral Unreliable News Websites", "content": "Factually unreliable news tend to be ephemeral [32, 58, 68, 101], often only being active long enough to spread misinformation to other platforms before shutting down themselves. As such, finding news sites as soon as they come online is critical long term. We note that while our current system relies on previously curated lists of websites, it can easily incorporate new websites as they appear (e.g., using the methods outlined by Hounsel et al. [68] for identifying new unreliable news websites based on their domain registration and network infrastructure characteristics). This inclusion would enable our system to surface potentially unreliable news stories that have not spread onto more popular websites. It would also potentially enable uncovering malicious Doppelg\u00e4nger sites that masquerade as ordinary local websites but that actually spread propaganda as soon as they come online [46, 90, 134] similar to past work that has detected phishing and malware domains [12, 13]."}, {"title": "8 Discussion and Conclusion", "content": "In this work, we investigated the spread and stance of news stories across 4,076 news websites from January 1, 2022, to July 1, 2023. Our approach, which advances previous methodologies for understanding news flows by incorporating stance into how we track semantic narratives, allows us to track stories across a mix of reliable, mixed-reliability, and unreliable news websites. (Neglecting stance in understanding the spread of narratives, while helpful for examining a singular ecosystem [62, 127], would likely led to misrepresentations of the interactions between different types of websites.)\nOur work demonstrates the key role that reliable news platforms play in dictating the stories covered by the entire news ecosystem. These popular and largely factual websites maintain the largest degree of influence on the broader news ecosystem (Figure 6) and are the source of much content on mixed-reliability and unreliable websites (Figure 5). To understand which stories unreliable websites will spin or contort, researchers should consider reliable outlets as agenda-setters [24, 45, 91]. However, we simultaneously highlight that while a minimum of 62.4% of stories are shared between different types of news websites (Section 4), different ecosystems often have distinctive attitudes towards stories. For example, using our analysis, inline with prior work [44, 48], we show that current lists of unreliable websites, among other biases, tend to be more conservative and have distinctive biases against COVID-19 vaccines and Pfizer (Table 2), informing which larger topics may particularly need additional fact-checking. We also find that biased coverage of particular entities (e.g., Ukraine, or vaccines) that otherwise reliable news websites produce are often sourced from unreliable news sites.\nFinally, our work demonstrates how, by analyzing the stance of articles towards specific topics, we can uncover and understand influence networks directed at specific entities,"}, {"title": "Ethical Considerations", "content": "Trustworthy news media is fundamental to a democratic society. Previously, false information has incited real-world violence and had major consequences on public health and elections. Disinformation and propaganda are attacks, and it behooves the security community to understand how these attacks are conducted and how to build better defenses against them. Advances in this space help both citizens and news outlets themselves, who regularly fact-check articles. At the same time, like all active measurements, web crawling and programmatic analysis of online content have potential ethical ramifications that we must carefully consider.\nOur work collects only publicly available news content in line with prior work (e.g., [60, 123, 124]). We follow best practices when scraping websites by slowly collecting content over time to reduce load. Our scraping also includes built-in safety mechanisms to prevent making requests more often than once every 10 seconds. We never attempt to access any privileged or private data but rather focus on public stories that are linked from news platforms' public homepages.\nWe also adhere to the best practices set forth for conducting active Internet measurements [2, 41, 43]. The servers we use for collecting content are identified as part of a research study through WHOIS, reverse DNS, and informational websites that indicate how to reach the researchers. Our IT and security teams are also informed about how to route any questions, requests, or complaints to our team. We received no requests to opt out of our data collection during our study.\nOur study does not generate any new content or redistribute existing content. Instead, we analyze how context spreads. We emphasize that while we utilize labels of individual websites as unreliable or mixed-reliability from Media-Bias/Fact-Check [33] and on existing previously-curated lists, this does not necessarily mean that every news story spread by these websites is misinformation. Many unreliable news websites report factual information [127], and at times, otherwise reliable websites may mistakenly report incorrect information. We only label stories that have been previously and individually expertly labeled as misinformation."}, {"title": "Open Science", "content": "We are committed to sharing our data with other researchers at academic or non-profit institutions seeking to conduct future work or re-implement our approach. We will publicly release the weights and the code for the models used in this study. Additionally, we will supply the URLs of crawled news stories used in this study upon request."}, {"title": "GNETINF Algorithm", "content": "NETINF is a greedy algorithm that iteratively computes the marginal gain (i.e.", "49": "n$G = \\arg \\max_{|G|\\leq k} P(C|G)$\nwhere\n$P(C|G) = \\prod_{c \\in C} P(c|G)$\n$P(c|G) = \\sum_{T \\in T(G)} P(c|T)P(T|G) \\times \\sum_{T \\in T(G)} \\prod_{(i,j) \\in T} P_c(i, j)$\nand where c is a cascade, T (G) is the set of all directed spanning trees on G, andd $P_c(i, j)$ (or that the node i influences node j in a cascade"}]}