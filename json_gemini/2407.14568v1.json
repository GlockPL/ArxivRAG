{"title": "SQLfuse: Enhancing Text-to-SQL Performance through\nComprehensive LLM Synergy", "authors": ["Tingkai Zhang", "Chaoyu Chen", "Cong Liao", "Jun Wang", "Xudong Zhao", "Hang Yut", "Jianchao Wang", "Jianguo Li", "Wenhui Shi"], "abstract": "Text-to-SQL conversion is a critical innovation, simplifying the\ntransition from complex SQL to intuitive natural language queries,\nespecially significant given SQL's prevalence in the job market\nacross various roles. The rise of Large Language Models (LLMs)\nlike GPT-3.5 and GPT-4 has greatly advanced this field, offering im-\nproved natural language understanding and the ability to generate\nnuanced SQL statements. However, the potential of open-source\nLLMs in Text-to-SQL applications remains underexplored, with\nmany frameworks failing to leverage their full capabilities, par-\nticularly in handling complex database queries and incorporating\nfeedback for iterative refinement. Addressing these limitations, this\npaper introduces SQLfuse, a robust system integrating open-source\nLLMs with a suite of tools to enhance Text-to-SQL translation's\naccuracy and usability. SQLfuse features four modules: schema\nmining, schema linking, SQL generation, and a SQL critic module,\nto not only generate but also continuously enhance SQL query\nquality. Demonstrated by its leading performance on the Spider\nLeaderboard and deployment by Ant Group, SQLfuse showcases the\npractical merits of open-source LLMs in diverse business contexts.", "sections": [{"title": "INTRODUCTION", "content": "In the \"Top 10 Programming Languages\" annual report by IEEE\nSpectrum for 2023, SQL maintains its top rank on the \"Jobs list\",\nhighlighting the enduring demand for SQL proficiency in the job\nmarket[35]. SQL's ubiquity is evident across a myriad of profes-\nsional roles, including Business Intelligence (BI) analysts, develop-\ners, database administrators (DBAs), and even extends to product\nmanagement, operations, compliance, and business strategy, owing\nto its critical function in data-driven decision-making. Neverthe-\nless, mastery of SQL requires a deep understanding of database\nstructures and the language itself, constituting a barrier for those\nwithout technical expertise.\nText-to-SQL technology represents a pivotal breakthrough, sim-\nplifying the process of data querying from the intricate SQL to a\nmore intuitive natural language format. This innovation facilitates\nuser-friendly data interrogation and analysis, democratizing ac-\ncess to database systems and thereby enhancing data processing\nefficiency and broadening its applications. In response to this prac-\ntical need, the field has seen the release of substantial benchmark\ndatasets such as WikiSQL [43], Spider [44], KaggleDBQA [15], and\nBIRD [19]. These resources serve to bridge the gap between aca-\ndemic research and the tangible needs of the industry, fostering\ndevelopments that are firmly rooted in practical application.\nWith the advent of GPT-3.5 and GPT-4, Large Language Models\n(LLMs) have emerged as a transformative force for Natural Lan-\nguage Processing (NLP) tasks, Text-to-SQL included. These models'\nexpansive parameters and rich training data have culminated in\na nuanced grasp of natural language, yielding more accurate SQL\ntranslations by parsing user intents effectively. Despite these ad-\nvancements, current LLM-based Text-to-SQL frameworks are not\nfully optimized; they do not exhaust the possibilities offered by\nopen-source LLMs, nor do they effectively incorporate external\ntools and knowledge that could refine Text-to-SQL performance.\nOur analysis indicates that current systems are\nlimited in their approach. For instance, they often overlook com-\nplex one-to-many relationships crucial for constructing aggregate"}, {"title": "RELATED WORK", "content": "In this section, we present an overview of the methodologies applied\nin Text-to-SQL conversion. The task presents significant challenges\nthat stem primarily from the complexities of accurately interpreting\nnatural language and generating corresponding SQL queries, as\nextensively documented in recent surveys [13, 31]. Both database\nmanagement and natural language processing (NLP) research com-\nmunities have invested considerable effort in addressing these chal-\nlenges. Early Text-to-SQL approaches were predominantly based\non predefined rules or templates [1, 32, 34]. These methods concep-\ntualized the conversion task as a straightforward mapping exercise\nfrom natural language to SQL. Other techniques approached the\nproblem from a sequence-to-sequence learning perspective, ap-\nplying encoder-decoder models to capture the translation process\n[3, 28, 30]. However, recent advancements have seen the emergence\nof hybrid methods that synergize the strengths of both database and\nNLP technologies. These include approaches that consider schema\nrelations [12, 18, 23, 30, 39, 41, 46] and others that incorporate syn-\ntax parsing techniques [11, 16, 33, 40]. Notably, models based on\nBERT [5], a groundbreaking NLP framework, have been particu-\nlarly effective in this group, achieving state-of-the-art results in\nText-to-SQL conversion [2, 43].\nRecently, the advent of LLMs like GPT-4 [26] from OpenAI and\nLLAMA [37] from Meta has marked a significant milestone in NLP\nand machine learning. Unlike the aforementioned models, LLMs\nare pre-trained on vast text corpora and can perform diverse lan-\nguage tasks. Their operation is based on generating the next most\nprobable word given the input prompt [45]. In the realm of Text-\nto-SQL, the efficacy of LLMs largely hinges on the art of prompt\nengineering-the process of devising precise and effective prompts\nthat guide the model [20, 25]. This practice can be bifurcated into\ntwo main strategies, dependent on the number of examples sup-\nplied to the model: zero-shot and few-shot. In the zero-shot ap-\nproach, where no examples are provided, the imperative is to craft\na question representation that encapsulates all relevant informa-\ntion, including the database schema, to effectively guide the model\n[4, 8, 20, 38]. Conversely, the few-shot paradigm entails not only\nthe robust representation of the question but also the careful selec-\ntion and arrangement of a limited number of illustrative examples\nwithin the prompt. This approach, known as in-context learning,\nenables LLMs to recognize and leverage patterns from the pro-\nvided examples to generate accurate responses, thus equipping\nthem to assimilate new tasks during inference without the need for\nexplicit task-specific training [7]. Recent literature highlights the\npivotal role of example selection in enhancing the effectiveness of\nin-context learning [10, 24, 29]."}, {"title": "METHODOLOGY", "content": "Our proposed SQLfuse framework, as demonstrated in Figure 1, is\na modular system designed for Text-to-SQL task. It is mainly com-\nposed of the following 4 modules: \u2460 schema mining, \u2461 schema\nlinking, SQL generation (SQLgen), and SQL critic. Specifi-\ncally, schema mining is a service that extracts schema features, e.g.,\nprimary keys, foreign keys, enumeration values and one-to-many\nrelations, etc., in addition to a pool of candidate database schemas.\nSubsequently, schema linking module identifies the exact schema\nelements namely tables, columns, join relations and condition val-\nues referenced in natural language query. Armed with the user's\nquestion and the schema features and elements extracted, we then\nmeticulously construct a Chain-of-Thought (CoT) template that\nserves as a structured prompt for the SQLgen module. This module\nis responsible for generating a variety of SQL statement candidates,\nwhich are subsequently processed through constant value fixing\nand SQL execution checks for validation. The final stage of the\nprocess involves the SQL critic module, which employs few-shot in-\ncontext learning to evaluate and select the optimal SQL query that\nmost faithfully represents the user's intent. We will now provide a\ndetailed exploration of each module."}, {"title": "Schema Mining Module", "content": "The schema mining module is adeptly crafted to distill essential\nschema features from databases in a data-driven manner, thereby\nenriching the context for subsequent modules with vital table infor-\nmation, keys, relationships, and enumeration values. These insights\nbecome the cornerstone for both the schema linking and SQLgen\nmodules, allowing them to identify necessary schema components\nwith greater precision and generate SQL statements with height-\nened accuracy. By leveraging existing knowledge and advanced\ntechniques from database management systems, the schema mining\nmodule lays a solid foundation for informed SQL query generation.\nNow let us delve into the specifics of the extracted schema features.\n1 Primary Key. The primary key in a database table is a distinc-\ntive identifier, typically a specific column or a set of columns, that\nensures each record is unique. This element is fundamental to main-\ntaining the integrity and consistency of data, particularly when\nconducting aggregation operations. In the realm of Text-to-SQL\ntranslation, recognizing and incorporating primary keys is indis-\npensable. They often serve as the axis around which aggregation\nqueries-employing functions like SUM, AVG, COUNT, MIN, and\nMAX-are structured, especially when combined with the GROUP\nBY clause. In other words, if the information of primary key are pro-\nvided in advance, the text-to-sql generation can be more accurate,\nespecially for the aggregation queries.\n2 Foreign Key. A foreign key in a database is a field or set of\nfields that references the primary key of another table, establish-\ning a critical link between them. This link is vital for preserving\nreferential integrity and enabling coherent multi-table queries. Un-\nderstanding foreign keys is essential for composing SQL queries\nthat require joins across multiple tables. For instance, to link a\n<user> table with an <order> table via the field [user ID], the [user"}, {"title": "Schema Linking Module", "content": "Schema linking plays a crucial role in converting natural language\nqueries into SQL queries, aiming to map input questions to specific\ndatabase schema elements including tables and columns [17]. We\nformulate schema linking as a task of extracting relevant schema\nitems among a set of candidate database schemas. By exploiting\nthe strength of LLMs in natural language understanding, we adopt\nan LLM-based approach to conduct the task of schema linking. In\nparticular, we construct a decent amount of high-quality labeled"}, {"title": "Schema Items Extraction.", "content": "The training data used for the\nschema items extraction task stem from a variety of open-source\nText-to-SQL datasets. We take these collected and filtered datasets\nas a basis to pose questions to GPT-4 in a schema-linking prompt\nstyle similar to DIN-SQL [29]. In particular, we guide GPT-4 to an-\nswer in a Chain-of-Thought (CoT) format by instructing \"Let's think\nstep by step\" [14] to incite a thorough elucidation of the extraction\nrationale. This CoT-guided reasoning is particularly beneficial for\nthe subsequent SQLgen model, enriching its understanding of the\nsemantic ties between user queries and the schema items it extracts,\nthereby refining the accuracy of SQL statement generation. After\nacquiring the responses from GPT-4, we examine and verify the cor-nrectness of these outcomes through comparison with the schema\nitems, e.g., tables, columns, join relations, and condition values,\nobtained from the ground-truth labels. By excluding those erro-\nneous question-answer pairs, we end up with a temporary version\nof high-quality labeled samples.\nInevitably, there exist columns with abbreviations or sharing\nidentical names across multiple tables. In light of these issues caus-\ning ambiguity and impairing the result of schema linking, we refine"}, {"title": "Schema Items Calibration.", "content": "Furthermore, we take extra mea-\nsures to calibrate the result of schema items extraction. On one hand,\nwe employ a rule-based checking approach to examine if there ex-\nists a join relation between two identified tables. The neglected join\nrelation must be restored in the output of schema linking model.\nOn the other hand, we adopt a similarity-based ranking method to\nrecall a limited quantity of potentially relevant candidates from the\nfiltered schema items. Firstly, the annotation and name of a table or\ncolumn are considered as their sentence representations. By taking\nadvantage of an open-source text embedding model (e.g., text2vec\n[42]), we can compare their sentence similarities with the input\nquestion. The highly ranked tables and columns above a certain\nsimilarity threshold are added to the final results of the schema link-\ning module that serve as the input to the SQL generation module\nin the next stage."}, {"title": "SQL Generation Module", "content": "As illustrated in Figure 3, the SQL generation (SQLgen) module\nserves as the cornerstone of SQLfuse, adeptly synthesizing essen-\ntial contextual information from schema mining, schema linking,\nand the original user query. It harnesses a Chain of Thought (CoT)\nframework, encapsulating these elements in a distinctive SQLfuse\nstyle, and then dispatches this amalgamated prompt to a fine-tuned\nLarge Language Model (LLM) to generate SQL predictions. Subse-\nquent to the initial prediction, any type errors in constant values\nare rectified, and the SQL is executed to identify potential errors\nfor self-correction. This iterative process continues until a valid\nexecutable SQL is produced or predefined limits are reached. We\nwill dissect the SQLgen module into two main components: the\nSQL generation process, and the self-correction process."}, {"title": "SQL generation.", "content": "Here, we first introduce the specialized SQL-fuse prompt style, which effectively incorporates the context pro-vided by the previous two modules. The format of prompts has\nbeen shown to greatly affect a model's understanding, and the op-timal format may vary between models. As demonstrated in C3 [8],\nprompts with a simple and clear layout have been found to outper-form those with a more complex structure, increasing accuracy by\nup to 7%. Common approaches for Text-to-SQL typically employ ei-ther code-centric prompts, which adhere strictly to database schema\nelements (as depicted in Figure 4(a)), or NLP-style prompts, which\nfavor a more versatile, yet less code-oriented format (illustrated in\nFigure 4(b))."}, {"title": "Self-Correction.", "content": "To address the inherent output instability\nof LLMs and improve the performance of SQLfuse", "main\nmethods": "constant value fix", "entails": "n(1) Constant Value Identification: The system identifies con-stant values within the query.\n(2) Column Matching: It aligns these values with suitable data-base columns", "Verification": "Should match attempts falter or pro-voke SQL errors", "Exploration": "The system then scoursfor alternative column matches", "Modification": "The correct column match leads to theimmediate adjustment of the SQL by updating the constantvalue accordingly.\nAdditionally"}, {"title": "SQLfuse: Enhancing Text-to-SQL Performance through\nComprehensive LLM Synergy", "authors": ["Tingkai Zhang", "Chaoyu Chen", "Cong Liao", "Jun Wang", "Xudong Zhao", "Hang Yut", "Jianchao Wang", "Jianguo Li", "Wenhui Shi"], "abstract": "Text-to-SQL conversion is a critical innovation, simplifying the\ntransition from complex SQL to intuitive natural language queries,\nespecially significant given SQL's prevalence in the job market\nacross various roles. The rise of Large Language Models (LLMs)\nlike GPT-3.5 and GPT-4 has greatly advanced this field, offering im-\nproved natural language understanding and the ability to generate\nnuanced SQL statements. However, the potential of open-source\nLLMs in Text-to-SQL applications remains underexplored, with\nmany frameworks failing to leverage their full capabilities, par-\nticularly in handling complex database queries and incorporating\nfeedback for iterative refinement. Addressing these limitations, this\npaper introduces SQLfuse, a robust system integrating open-source\nLLMs with a suite of tools to enhance Text-to-SQL translation's\naccuracy and usability. SQLfuse features four modules: schema\nmining, schema linking, SQL generation, and a SQL critic module,\nto not only generate but also continuously enhance SQL query\nquality. Demonstrated by its leading performance on the Spider\nLeaderboard and deployment by Ant Group, SQLfuse showcases the\npractical merits of open-source LLMs in diverse business contexts.", "sections": [{"title": "INTRODUCTION", "content": "In the \"Top 10 Programming Languages\" annual report by IEEE\nSpectrum for 2023, SQL maintains its top rank on the \"Jobs list\",\nhighlighting the enduring demand for SQL proficiency in the job\nmarket[35]. SQL's ubiquity is evident across a myriad of profes-\nsional roles, including Business Intelligence (BI) analysts, develop-\ners, database administrators (DBAs), and even extends to product\nmanagement, operations, compliance, and business strategy, owing\nto its critical function in data-driven decision-making. Neverthe-\nless, mastery of SQL requires a deep understanding of database\nstructures and the language itself, constituting a barrier for those\nwithout technical expertise.\nText-to-SQL technology represents a pivotal breakthrough, sim-\nplifying the process of data querying from the intricate SQL to a\nmore intuitive natural language format. This innovation facilitates\nuser-friendly data interrogation and analysis, democratizing ac-\ncess to database systems and thereby enhancing data processing\nefficiency and broadening its applications. In response to this prac-\ntical need, the field has seen the release of substantial benchmark\ndatasets such as WikiSQL [43], Spider [44], KaggleDBQA [15], and\nBIRD [19]. These resources serve to bridge the gap between aca-\ndemic research and the tangible needs of the industry, fostering\ndevelopments that are firmly rooted in practical application.\nWith the advent of GPT-3.5 and GPT-4, Large Language Models\n(LLMs) have emerged as a transformative force for Natural Lan-\nguage Processing (NLP) tasks, Text-to-SQL included. These models'\nexpansive parameters and rich training data have culminated in\na nuanced grasp of natural language, yielding more accurate SQL\ntranslations by parsing user intents effectively. Despite these ad-\nvancements, current LLM-based Text-to-SQL frameworks are not\nfully optimized; they do not exhaust the possibilities offered by\nopen-source LLMs, nor do they effectively incorporate external\ntools and knowledge that could refine Text-to-SQL performance.\nOur analysis indicates that current systems are\nlimited in their approach. For instance, they often overlook com-\nplex one-to-many relationships crucial for constructing aggregate"}, {"title": "RELATED WORK", "content": "In this section, we present an overview of the methodologies applied\nin Text-to-SQL conversion. The task presents significant challenges\nthat stem primarily from the complexities of accurately interpreting\nnatural language and generating corresponding SQL queries, as\nextensively documented in recent surveys [13, 31]. Both database\nmanagement and natural language processing (NLP) research com-\nmunities have invested considerable effort in addressing these chal-\nlenges. Early Text-to-SQL approaches were predominantly based\non predefined rules or templates [1, 32, 34]. These methods concep-\ntualized the conversion task as a straightforward mapping exercise\nfrom natural language to SQL. Other techniques approached the\nproblem from a sequence-to-sequence learning perspective, ap-\nplying encoder-decoder models to capture the translation process\n[3, 28, 30]. However, recent advancements have seen the emergence\nof hybrid methods that synergize the strengths of both database and\nNLP technologies. These include approaches that consider schema\nrelations [12, 18, 23, 30, 39, 41, 46] and others that incorporate syn-\ntax parsing techniques [11, 16, 33, 40]. Notably, models based on\nBERT [5], a groundbreaking NLP framework, have been particu-\nlarly effective in this group, achieving state-of-the-art results in\nText-to-SQL conversion [2, 43].\nRecently, the advent of LLMs like GPT-4 [26] from OpenAI and\nLLAMA [37] from Meta has marked a significant milestone in NLP\nand machine learning. Unlike the aforementioned models, LLMs\nare pre-trained on vast text corpora and can perform diverse lan-\nguage tasks. Their operation is based on generating the next most\nprobable word given the input prompt [45]. In the realm of Text-\nto-SQL, the efficacy of LLMs largely hinges on the art of prompt\nengineering-the process of devising precise and effective prompts\nthat guide the model [20, 25]. This practice can be bifurcated into\ntwo main strategies, dependent on the number of examples sup-\nplied to the model: zero-shot and few-shot. In the zero-shot ap-\nproach, where no examples are provided, the imperative is to craft\na question representation that encapsulates all relevant informa-\ntion, including the database schema, to effectively guide the model\n[4, 8, 20, 38]. Conversely, the few-shot paradigm entails not only\nthe robust representation of the question but also the careful selec-\ntion and arrangement of a limited number of illustrative examples\nwithin the prompt. This approach, known as in-context learning,\nenables LLMs to recognize and leverage patterns from the pro-\nvided examples to generate accurate responses, thus equipping\nthem to assimilate new tasks during inference without the need for\nexplicit task-specific training [7]. Recent literature highlights the\npivotal role of example selection in enhancing the effectiveness of\nin-context learning [10, 24, 29]."}, {"title": "METHODOLOGY", "content": "Our proposed SQLfuse framework, as demonstrated in Figure 1, is\na modular system designed for Text-to-SQL task. It is mainly com-\nposed of the following 4 modules: \u2460 schema mining, \u2461 schema\nlinking, SQL generation (SQLgen), and SQL critic. Specifi-\ncally, schema mining is a service that extracts schema features, e.g.,\nprimary keys, foreign keys, enumeration values and one-to-many\nrelations, etc., in addition to a pool of candidate database schemas.\nSubsequently, schema linking module identifies the exact schema\nelements namely tables, columns, join relations and condition val-\nues referenced in natural language query. Armed with the user's\nquestion and the schema features and elements extracted, we then\nmeticulously construct a Chain-of-Thought (CoT) template that\nserves as a structured prompt for the SQLgen module. This module\nis responsible for generating a variety of SQL statement candidates,\nwhich are subsequently processed through constant value fixing\nand SQL execution checks for validation. The final stage of the\nprocess involves the SQL critic module, which employs few-shot in-\ncontext learning to evaluate and select the optimal SQL query that\nmost faithfully represents the user's intent. We will now provide a\ndetailed exploration of each module."}, {"title": "Schema Mining Module", "content": "The schema mining module is adeptly crafted to distill essential\nschema features from databases in a data-driven manner, thereby\nenriching the context for subsequent modules with vital table infor-\nmation, keys, relationships, and enumeration values. These insights\nbecome the cornerstone for both the schema linking and SQLgen\nmodules, allowing them to identify necessary schema components\nwith greater precision and generate SQL statements with height-\nened accuracy. By leveraging existing knowledge and advanced\ntechniques from database management systems, the schema mining\nmodule lays a solid foundation for informed SQL query generation.\nNow let us delve into the specifics of the extracted schema features.\n1 Primary Key. The primary key in a database table is a distinc-\ntive identifier, typically a specific column or a set of columns, that\nensures each record is unique. This element is fundamental to main-\ntaining the integrity and consistency of data, particularly when\nconducting aggregation operations. In the realm of Text-to-SQL\ntranslation, recognizing and incorporating primary keys is indis-\npensable. They often serve as the axis around which aggregation\nqueries-employing functions like SUM, AVG, COUNT, MIN, and\nMAX-are structured, especially when combined with the GROUP\nBY clause. In other words, if the information of primary key are pro-\nvided in advance, the text-to-sql generation can be more accurate,\nespecially for the aggregation queries.\n2 Foreign Key. A foreign key in a database is a field or set of\nfields that references the primary key of another table, establish-\ning a critical link between them. This link is vital for preserving\nreferential integrity and enabling coherent multi-table queries. Un-\nderstanding foreign keys is essential for composing SQL queries\nthat require joins across multiple tables. For instance, to link a\n<user> table with an <order> table via the field [user ID], the [user"}, {"title": "Schema Linking Module", "content": "Schema linking plays a crucial role in converting natural language\nqueries into SQL queries, aiming to map input questions to specific\ndatabase schema elements including tables and columns [17]. We\nformulate schema linking as a task of extracting relevant schema\nitems among a set of candidate database schemas. By exploiting\nthe strength of LLMs in natural language understanding, we adopt\nan LLM-based approach to conduct the task of schema linking. In\nparticular, we construct a decent amount of high-quality labeled"}, {"title": "Schema Items Extraction.", "content": "The training data used for the\nschema items extraction task stem from a variety of open-source\nText-to-SQL datasets. We take these collected and filtered datasets\nas a basis to pose questions to GPT-4 in a schema-linking prompt\nstyle similar to DIN-SQL [29]. In particular, we guide GPT-4 to an-\nswer in a Chain-of-Thought (CoT) format by instructing \"Let's think\nstep by step\" [14] to incite a thorough elucidation of the extraction\nrationale. This CoT-guided reasoning is particularly beneficial for\nthe subsequent SQLgen model, enriching its understanding of the\nsemantic ties between user queries and the schema items it extracts,\nthereby refining the accuracy of SQL statement generation. After\nacquiring the responses from GPT-4, we examine and verify the cor-nrectness of these outcomes through comparison with the schema\nitems, e.g., tables, columns, join relations, and condition values,\nobtained from the ground-truth labels. By excluding those erro-\nneous question-answer pairs, we end up with a temporary version\nof high-quality labeled samples.\nInevitably, there exist columns with abbreviations or sharing\nidentical names across multiple tables. In light of these issues caus-\ning ambiguity and impairing the result of schema linking, we refine"}, {"title": "Schema Items Calibration.", "content": "Furthermore, we take extra mea-\nsures to calibrate the result of schema items extraction. On one hand,\nwe employ a rule-based checking approach to examine if there ex-\nists a join relation between two identified tables. The neglected join\nrelation must be restored in the output of schema linking model.\nOn the other hand, we adopt a similarity-based ranking method to\nrecall a limited quantity of potentially relevant candidates from the\nfiltered schema items. Firstly, the annotation and name of a table or\ncolumn are considered as their sentence representations. By taking\nadvantage of an open-source text embedding model (e.g., text2vec\n[42]), we can compare their sentence similarities with the input\nquestion. The highly ranked tables and columns above a certain\nsimilarity threshold are added to the final results of the schema link-\ning module that serve as the input to the SQL generation module\nin the next stage."}, {"title": "SQL Generation Module", "content": "As illustrated in Figure 3, the SQL generation (SQLgen) module\nserves as the cornerstone of SQLfuse, adeptly synthesizing essen-\ntial contextual information from schema mining, schema linking,\nand the original user query. It harnesses a Chain of Thought (CoT)\nframework, encapsulating these elements in a distinctive SQLfuse\nstyle, and then dispatches this amalgamated prompt to a fine-tuned\nLarge Language Model (LLM) to generate SQL predictions. Subse-\nquent to the initial prediction, any type errors in constant values\nare rectified, and the SQL is executed to identify potential errors\nfor self-correction. This iterative process continues until a valid\nexecutable SQL is produced or predefined limits are reached. We\nwill dissect the SQLgen module into two main components: the\nSQL generation process, and the self-correction process."}, {"title": "SQL generation.", "content": "Here, we first introduce the specialized SQL-fuse prompt style, which effectively incorporates the context pro-vided by the previous two modules. The format of prompts has\nbeen shown to greatly affect a model's understanding, and the op-timal format may vary between models. As demonstrated in C3 [8],\nprompts with a simple and clear layout have been found to outper-form those with a more complex structure, increasing accuracy by\nup to 7%. Common approaches for Text-to-SQL typically employ ei-ther code-centric prompts, which adhere strictly to database schema\nelements (as depicted in Figure 4(a)), or NLP-style prompts, which\nfavor a more versatile, yet less code-oriented format (illustrated in\nFigure 4(b))."}, {"title": "Self-Correction.", "content": "To address the inherent output instability\nof LLMs and improve the performance of SQLfuse, we present a\ncomponent in SQLgen to rectify common errors through two main\nmethods: constant value fix, and SQL execution checking.\nThe Constant Value Fix process addresses mismatches between\nconstant values mentioned in natural language queries-like spe-cific numbers, dates, or text strings-and corresponding database\ncolumns, which can arise due to ambiguity in language or model\nmisinterpretation. This automatic correction sequence entails:\n(1) Constant Value Identification: The system identifies con-stant values within the query.\n(2) Column Matching: It aligns these values with suitable data-base columns, mindful of data types.\n(3) Feedback Verification: Should match attempts falter or pro-voke SQL errors, a potential mismatch is flagged.\n(4) Alternative Matching Exploration: The system then scoursfor alternative column matches, scrutinizing data formats,value ranges, and metadata.\n(5) SQL Modification: The correct column match leads to theimmediate adjustment of the SQL by updating the constantvalue accordingly.\nAdditionally, database statistics, such as value ranges within columns,can also aid in refining the column matching process. Moreover,heuristic rules tailored to the database's industry-specific termi-nology and usage patterns can enhance the matching precision,particularly when the data for fine-tuning the above SQL-orientedLLM is insufficient or the scenarios are complex. These strategiesnot only reduce errors in processing constant values but also im-prove the overall quality of SQL generation, increase user trust, andboost the model's real-time performance by enabling automat"}, {"title": "SQL Critic Module", "content": "Inspired by the work [27] to further refine the final result of Text-to-SQL generation, we employ a Generate-then-Rank technique,\nwhich is a common strategy to correct a LLM at generation time.\nThis technique utilizes a SQL critic model that sifts through possible\nSQL queries generated by the SQLgen module to identify the most\naccurate one. The LLM within the SQL critic module is pivotal\nfor assessing SQL quality. Rather than relying on extensive SFT,\nwe adopt a few-shot in-context learning strategy that leverages\nexamples from an external SQL knowledge base, enriched with\nhindsight feedback. These examples, paired with the user's question,\nschema linking results, directives, and additional calibration cues,\nare used to prompt the LLM in the SQL critic module to determine\nthe optimal candidate SQL query, as illustrated in Figure 5."}, {"title": "Few-shot In-Context Learning.", "content": "To enable the use of eitheropen-source or closed-source LLMs for the SQL critic model, our sys-tem leverages few-shot in-context learning. This method requiresonly a handful of labeled examples to instruct the LLM, circum-venting the need for extensive data collection and fine-tuning. TheLLM is thus primed to apply its learned knowledge to novel inputsusing this minimal yet effective sample set.\nTo enrich the variety of cases presented in few-shot learning, wegather and curate an array of intricate SQL statements and schemasfrom GitHub. This collection undergoes meticulous cleaning andvalidation, including manual annotation and GPT-4 evaluation, re-sulting in a robust external knowledge base. This repository enables"}]}]}