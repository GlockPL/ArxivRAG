{"title": "Towards Synergistic Deep Learning Models for Volumetric\nCirrhotic Liver Segmentation in MRIS", "authors": ["Vandan Gorade", "Onkar Susladkar", "Gorkem Durak", "Elif Keles", "Ertugrul Aktas", "Timurhan Cebeci", "Alpay Medetalibeyoglu", "Daniela Ladner", "Debesh Jha", "Ulas Bagci"], "abstract": "Liver cirrhosis, a leading cause of global mortality, requires precise segmentation of ROIs for effective disease\nmonitoring and treatment planning. Existing segmentation models often fail to capture complex feature interactions\nand generalize across diverse datasets. To address these limitations, we propose a novel synergistic theory that\nleverages complementary latent spaces for enhanced feature interaction modeling. Our proposed architecture,\nnnSynergyNet3D, integrates continuous and discrete latent spaces for 3D volumes and features auto-configured\ntraining. This approach captures both fine-grained and coarse features, enabling effective modeling of intricate\nfeature interactions. We empirically validated nnSynergyNet3D on a private dataset of 628 high-resolution T1\nabdominal MRI scans from 339 patients. Our model outperformed the baseline nnUNet3D by approximately 2%.\nAdditionally, zero-shot testing on healthy liver CT scans from the public LiTS dataset demonstrated superior\ncross-modal generalization capabilities. These results highlight the potential of synergistic latent space models to\nimprove segmentation accuracy and robustness, thereby enhancing clinical workflows by ensuring consistency\nacross CT and MRI modalities.", "sections": [{"title": "1. INTRODUCTION", "content": "Clinical Motivation. Liver cirrhosis, the final stage of chronic liver disease (CLD), represents a significant global\nhealth issue. In 2019, it ranked as the 11th leading cause of death, contributing to 2.4% of deaths worldwide. 1, 2\nWhile viral hepatitis remains the primary cause of end-stage liver disease, metabolic dysfunction-associated\nsteatotic liver disease (MASLD) is projected to surpass it as the leading cause, driven by the rising prevalence of\nobesity and metabolic syndrome globally.2 Additionally, conditions such as alcoholic liver disease, autoimmune\nhepatitis, and genetic disorders also play substantial roles.2 Cirrhosis involves the development of bridging fibrosis\nand regenerative nodules, which compromise liver function and can lead to liver failure.3 Accurate segmentation\nof cirrhotic livers in radiology images is essential for monitoring the disease's progression, assessing severity, and\nevaluating treatment responses. Precise segmentation helps determine the extent and location of liver damage,\nwhich is vital for planning treatments like liver transplantation and other targeted therapies.\nTheoretical Shortcomings. Existing segmentation models often face significant theoretical shortcomings,\nprimarily due to their limited ability to capture complex feature interactions and their fixed hypothesis spaces. 4\nTraditional models5\u20137 treat features in isolation or use simplistic integration methods, failing to exploit intricate,\nnon-linear dependencies between different feature sets. This results in suboptimal representation of complex\npatterns, such as subtle tissue variations in MRI scans. Additionally, the fixed nature of these models' hypothesis\nspaces restricts their generalization capacity to new, diverse datasets, limiting their robustness across varying\nimaging conditions. Thus, these limitations can impede the accuracy and adaptability of conventional segmentation\napproaches in challenging scenarios like cirrhotic liver segmentation.\nSynergistic Theory and Practical Architecture Design.To address these limitations, we propose a novel\nsynergistic theory that enhances feature interaction modeling by incorporating features from diverse latent spaces\nthat complement each other. This theory posits that leveraging synergistic representations 8,9 where different\ntypes of latent features interact and complement each other can more effectively capture complex, non-linear\nrelationships within the data. Based on this synergistic theory, we introduce the nnSynergyNet3D architecture,\nwhich integrates both continuous and discrete latent spaces for 3D volumes and enjoys auto-configured training.\nThe continuous latent space captures fine-grained details, while the discrete latent space addresses broader, coarse\nfeatures. This dual approach allows nnSynergyNet3D to model intricate feature interactions more effectively."}, {"title": "2. METHODOLOGY", "content": "2.1 Problem Statement\nGiven a set of MRI scans X C Rd, our goal is to segment cirrhotic liver tissues accurately. Let x \u2208 X be an\ninput scan and y \u2208 Y be the corresponding segmentation map. Traditional segmentation methods often struggle\nwith the complex variations present in MRI images. We address this by proposing a deep learning model that\nleverages synergistic feature spaces.\n2.2 Synergistic Latent Space Theory\nWe introduce two feature sets, F1 and F2, derived from the MRI scans. These feature sets are combined to form\na synergistic space S = F1 \u00d7 F2. For the segmentation function f: S \u2192 R, we aim to prove that our model can\napproximate f accurately and generalize well to unseen data. To establish this, we first need to demonstrate that\na neural network can effectively approximate any function within this synergistic feature space.\nTheorem 1: Synergistic Latent Approximation Theorem. Let f: SR be a continuous function on a compact\nset SCRd1+d2. If N is an algebra of functions on Rd1+d2 that separates points and contains constant functions,\nthen for any e > 0, there exists g\u2208 N such that:\n|| f - 9||\u221e < \u20ac."}, {"title": "2.3 Practical Architecture Design", "content": "Based on the synergistic latent space theory, we propose a deep learning architecture that leverages interactions\nbetween complementary spaces, named nnSynergyNet3D. Unlike the traditional 2D SynergyNet,& our design\nemploys a 3D cascade U-Net. Initially, a 3D U-Net processes low-resolution images, followed by a second\nhigh-resolution 3D U-Net that refines the predictions of the former. At the bottleneck, we use F\u2081 and F2 as\ncontinuous and discrete features, respectively, to capture fine and coarse information in cirrhotic liver MRI scans.\nDiscrete features are learned using volumetric vector quantization, which dynamically discretizes continuous 3D\nfeatures. Finally, F\u2081 and F2 are combined using volumetric multi-head cross-attention to capture synergistic\ninformation. The SynergyNet3D bottleneck integrates three-dimensional continuous and discrete latent spaces to\ncapture intricate, non-linear feature interactions effectively. Inspired by nnU-Net,6 nnSynergyNet3D employs\nrule-based parameters to adapt network topology, patch size, and batch size based on the dataset fingerprint and\nGPU memory constraints using hard-coded heuristic rules. Empirical parameters, determined through trial and\nerror, are used to select the best U-Net configuration (e.g. 3D full resolution, 3D low resolution, 3D cascade) and\noptimize the postprocessing strategy. This combination of automatic configuration and synergistic information\nallows for more effective modeling of complex patterns, enhancing the accuracy and robustness of segmentation,\nparticularly in challenging scenarios like cirrhotic liver segmentation."}, {"title": "3. EXPERIMENTAL SETUP", "content": "We carefully selected several baseline methods such as nnUNet3D, 6 nnFormer3D, 16 and TransUNet3D5 etc.\nDatasets. We leveraged our private data cirrhotic liver MRI data and LiTS10 datasets to demonstrate the\neffectiveness of our proposed method. Our private data includes 628 high-resolution abdominal MRI scans,\nconsisting of 310 T1-weighted (T1W) and 318 T2-weighted (T2W) volumetric scans from 339 patients. It\nencompasses both contrast-enhanced and non-enhanced MRI scans, along with segmentation masks annotated by\nphysicians. This is a comprehensive single-center dataset that is multivendor, multiplanar, and multiphase. The\ndataset was split with an 80:10:10 ratio, resulting in 248 cases for training, 31 cases for validation, and 31 cases\nfor testing for T1W. Similarly, for T2W, we allocated 256 cases for training, and 31 cases each for validation and\ntesting. While the T2W split was not exactly 80:10:10, we maintained the distribution as close to the target ratio\nas possible. This careful balancing accounts for the domain shift introduced by different device vendors, resulting\nin variable scan characteristics across splits.\nMetrics. To assess the liver segmentation performance, we utilized several metrics, including the mean Dice\nSimilarity Coefficient (mDSC), mean Intersection over Union (mIoU), recall, precision, Hausdorff Distance\n(HD95), and Average Symmetric Surface Distance (ASSD). These metrics provide a comprehensive evaluation of\nsegmentation accuracy, offering insights into both the overlap and boundary precision of the segmented regions\nImplementation Details. We trained our models using PyTorch 2.2.2 with CUDA 11.2. The learning rate was\ninitially set to 0.0001 and was gradually decreased using the Cosine Annealing Scheduler. We use the BCE-Dice\nloss with the AdamW optimizer with a batch size of 4. The models were trained for 500 epochs with an early\nstopping patience of 50 to prevent overfitting. The learning rate decay was set at 0.001 after every 10 epochs. To\naccelerate training, we leveraged two Nvidia A6000 GPUs, each with 48GB of memory, and utilized PyTorch's\nDistributed Data Parallel to distribute a batch of 4 to each GPU. We resized every volume to uniform spatial\ndimensions of 256 \u00d7 256 \u00d7 80 for generalizability."}, {"title": "4. EMPIRICAL ANALYSIS", "content": "Quantitative analysis on T1W modality.  Table 1 provides a comparison between our proposed nnSynerg-\nyNet3D and five state-of-the-art (SOTA) segmentation networks on the T1W dataset. Our nnSynergyNet3D\noutperforms all comparison methods across all metrics. Among the transformer-based methods, nnFormer3D\nshowed comparable performance in capturing cirrhotic liver tissue and its boundaries, highlighting the significance\nof long-range dependencies. However, models such as SwinUNeTr and TransUNet3D did not significantly\nsurpass CNN-based models like nnUNet, emphasizing the necessity of more advanced configurations. Moving to\ntransformer-based models with auto-configuration, nnFormer3D and our nnSynergyNet3D demonstrated superior\nperformance due to their ability to adapt to the liver's varying shapes and complex boundaries. The auto-\nconfigured continuous and discrete representation enabled these models to capture fine and coarse features more\neffectively. Our proposed nnSynergyNet3D achieved the highest overall performance, with a mean Intersection\nover Union (mIoU) of 84.51, Dice Similarity Coefficient (DSC) of 87.89%, Hausdorff Distance at 95th percentile\n(HD95) of 21.04 mm, and precision of 88.72%. This superior performance can be attributed to the synergistic\nintegration of continuous and discrete representations, which allowed the model to capture both fine details and\nlong-range dependencies due to its Transformer-inspired design. This demonstrates the critical role of combining\ntransformer-based architectures with auto-configuration for enhancing segmentation performance in complex\ntasks like cirrhotic liver segmentation.\nQuantitative analysis on T2w modality Table 2 presents an evaluation of state-of-the-art (SOTA) 3D\nsegmentation networks on the T2W dataset scans. The results closely mirror those observed in the T1W\nsegmentation results. Among the evaluated models, our nnSynergyNet3D stands out with a superior Dice\nSimilarity Coefficient (DSC) value of 86.51%, the lowest Hausdorff Distance (HD) of 24.19 mm, and the lowest\nAverage Surface Distance (ASD) value of 3.96 mm. These metrics underscore the effectiveness of our approach,\nparticularly in handling the T2-weighted (T2W) MRI characteristics, which typically provide enhanced contrast\nbetween different soft tissues and are crucial for identifying cirrhotic liver tissues. nnFormer3D and nnUNet3D\nalso demonstrated competitive performance, reinforcing the importance of transformer-based designs for capturing\nintricate details of cirrhotic liver tissues. T2W images often highlight fibrotic changes and fluid accumulation,\nwhich are critical for accurate cirrhotic liver segmentation. However, models such as SwinUNeTr, TransBTS, and\nTransUNet3D did not significantly surpass the performance of CNN-based models like nnUNet and Synergy VNet3D.\nThis emphasizes the critical role of auto-configured and hybrid CNN-Transformer-based models in achieving\ncompetitive segmentation results, particularly for the complex structures and varying intensities in T2W images."}, {"title": "5. CONCLUSION", "content": "In this study, we introduced a novel synergistic theory and the nnSynergyNet3D architecture to address the\nlimitations of existing segmentation models in capturing complex feature interactions and generalizing across\ndiverse datasets. By integrating continuous and discrete latent spaces, nnSynergyNet3D effectively models\nintricate feature interactions, enhancing segmentation accuracy and robustness. Our empirical validation on a\ncomprehensive dataset of T1 abdominal MRI scans demonstrated that nnSynergyNet3D outperforms the state-of-\nthe-art nnUNet3D by approximately 2%. Furthermore, our model exhibited superior cross-modal generalization\ncapabilities in zero-shot testing on healthy liver CT scans. These findings underscore the potential of synergistic\nlatent space models to significantly benefit clinical workflows, particularly in challenging scenarios like cirrhotic\nlives segmentation, by improving segmentation consistency across both CT and MRI modalities. Future work will\nexplore further optimization and extension of synergistic representations to other medical imaging tasks."}, {"title": "6. APPENDIX", "content": "6.1 Detailed Proofs\nTheorem 1: Synergistic Latent Approximation Theorem. Let f:S \u2192 R be a continuous function on a compact\nset SCRd1+d2. If N is an algebra of functions on Rd1+d2 that separates points and contains constant functions,\nthen for any e > 0, there exists g\u2208 N such that:\n||f - 9||\u221e < \u20ac.\nDetailed Proof. Following Stone-Weierstrass Theorem, which states that if A is an algebra of continuous\nfunctions on a compact set SC Rd and A satisfies two conditions-point separation and inclusion of constant\nfunctions then the closure of A in the supremum norm ||\u00b7 ||\u221e equals C(S), the space of all continuous functions\non S. Formally,\nA = C(S),\nwhere A denotes the closure of A in || ||\u221e. To apply this theorem to our context, let N represent the algebra of\nfunctions computed by neural networks with continuous and non-constant activation functions. This algebra\nN separates points and contains constant functions, fulfilling the criteria stipulated by the Stone-Weierstrass\nTheorem. Consequently,\nN = C(S).\nThis implies that N is dense in C(S) with respect to the supremum norm || . ||\u221e. Hence, for any continuous\nfunction f defined on S and for any \u20ac > 0, there exists a function g\u2208 N such that:\n||f - 9 ||\u221e < \u20ac.\nThe significance of this result lies in the ability of neural networks to approximate any continuous function f on\nS with arbitrary precision. The neural network's algebra N, which incorporates interactions between features,\nenhances the expressiveness of the function class, allowing it to capture complex dependencies between feature\nsets. This approximation capability is crucial in practical scenarios where modeling intricate relationships between\nfeatures is required. Thus, the theorem demonstrates that any continuous function f defined on a compact set\nSC Rd1+d2 can be approximated as closely as desired by a function g in N, ensuring:\n|| f - 9||\u221e < \u20ac.\nTheorem 2: Generalization Bound. Let H be the hypothesis space of a deep learning model trained on S. The\ngeneralization error |R(f) \u2013 Remp(f)| can be bounded as:\n|R(f) - Remp(f)| \u2264 O\u221a(VC(H)log(N)/N)\nDetailed Proof. To establish the generalization bound for our model, we start by analyzing the generalization\nerror defined as the difference between the true risk R(f) and the empirical risk Remp(f). The true risk R(f) is\ngiven by:\nR(f) = Ez~D[l(f(z), y)],\nwhere I denotes the loss function and D represents the underlying data distribution. The empirical risk Remp(f)\nis defined as:\nRemp(f) = 1/N \u03a3i=1N l(f(z), Yi),\nwhere (zi, Yi) are the training samples and N is the number of samples. We use Hoeffding's inequality to bound\nthe deviation between R(f) and Remp(f). Hoeffding's inequality states that for any e > 0:\nPr (|R(f) - Remp(f)| \u2265 \u20ac) \u2264 2 exp(-2N \u20ac^2/\u0394^2),\nwhere A is the range of the loss function l. This inequality implies that with high probability, the difference\nbetween the true and empirical risk is bounded by e, provided N is sufficiently large. Next, we utilize the concept\nof Rademacher complexity to derive a more specific bound. The Rademacher complexity of the hypothesis space\nH, denoted as RN (H), measures the capacity of H to fit random noise. It is known that:\nRN(H) < \u221a(VC(H) log(N)/N),\nwhere VC(H) is the VC dimension of the hypothesis space H. This relation shows that the complexity of H\naffects the generalization error, with a larger VC dimension implying a higher capacity to fit data. For our\nsynergistic feature space S, which is defined as S = F\u2081 \u00d7 F2, the hypothesis space H formed from S can be\ncharacterized by:\nVC(H) \u2265 VC(HF\u2081) + VC(HF\u2082),\nwhere HF\u2081 and HF\u2082 are the hypothesis spaces associated with the feature sets F\u2081 and F2, respectively. This\ninequality reflects that the VC dimension of H in the synergistic space S is at least the sum of the VC dimensions\nof the individual feature spaces. This implies that the hypothesis space H is richer and can represent more complex\nfunctions due to the interaction between F\u2081 and F2. Combining Hoeffding's inequality with the Rademacher\ncomplexity, we obtain:\n|R(f) - Remp(f)| \u2264 RN(H) +\u221a(log(1/\u03b4)/2N)\nFor large N, the term \u221a(log(1/\u03b4)/2N) becomes negligible. Hence, the generalization error can be bounded primarily by:\n|R(f) - Remp(f)| \u2264 RN(H).\nSubstituting the bound for Rademacher complexity, we get:\n|R(f) - Remp(f)| \u2264 \u221a(VC(H)log(N)/N)"}, {"title": null, "content": "Specifically, for the synergistic space S, we substitute VC(H) with VC(HF\u2081) +VC(HF\u2082):\n|R(f) \u2013 Remp(f)| \u2264 \u221a(VC(HF\u2081) + VC(HF\u2082)log(N)/N)\nThis bound demonstrates that the increased VC dimension in the synergistic space S enhances the hypothesis\nspace's capacity to capture more complex functions. Consequently, this increased capacity improves the model's\nability to fit the training data, while the generalization bound ensures that this capacity translates into better\nperformance on unseen data. Thus, the theoretical analysis confirms that using a synergistic feature space not\nonly enhances the model's ability to represent complex functions but also ensures effective generalization, given\nsufficient training data."}]}