{"title": "TS-EoH: An Edge Server Task Scheduling Algorithm Based on Evolution of Heuristic", "authors": ["Yatong Wang", "Yuchen Pei", "Yuqi Zhao"], "abstract": "With the widespread adoption of 5G and Internet of Things (IoT) technologies, the low latency provided by edge computing has great importance for real-time processing. However, managing numerous simultaneous service requests poses a significant challenge to maintaining low latency. Current edge server task scheduling methods often fail to balance multiple optimization goals effectively. This paper introduces a novel task-scheduling approach based on Evolutionary Computing (EC) theory and heuristic algorithms. We model service requests as task sequences and evaluate various scheduling schemes during each evolutionary process using Large Language Models (LLMs) services. Experimental results show that our task-scheduling algorithm outperforms existing heuristic and traditional reinforcement learning methods. Additionally, we investigate the effects of different heuristic strategies and compare the evolutionary outcomes across various LLM services.", "sections": [{"title": "I. INTRODUCTION", "content": "With 5G and IoT adoption, edge computing's low latency for real-time processing is increasingly crucial. Edge servers can reduce the physical distance to end users, providing low latency, mobility, and location sensitivity. They offload real-time processing services from cloud servers, easing their task-handling burden [1]. Edge servers handle computation-intensive tasks for mobile devices, compensating for their limited computing power [2]. However, the rise of terminal devices and the growth of mobile internet challenges task scheduling and resource management for edge servers. Critical issues include efficient task scheduling, resource optimization, and service quality assurance with limited server resources.\nCurrent edge server task scheduling research mainly includes heuristic algorithms (e.g., Ant Colony Optimization [3]) and reinforcement learning-based algorithms (e.g., Reinforcement Learning with Pointer Networks [4]). Heuristic algorithms have a self-organizing solid, self-learning, and self-adaptive capabilities. They can achieve globally optimal solutions and are robust, making them suitable for complex problems. However, parameter settings often influence their performance, and designing these heuristics requires significant manual effort and expertise [5]. Reinforcement learning-based algorithms require extensive training sets and substantial computational resources, which is unfeasible in practical scenarios.\nThe Evolution of the Heuristic (EoH) framework introduces a new approach to implementing heuristic algorithm design automatically. Using pre-trained data from LLMs, EoH guides LLMs through self-heuristic processes to evolve optimal scoring methods. This framework shows significant advantages in solving combinatorial optimization problems.\nThis paper proposes a task scheduling scheme based on the EoH framework (TS-EoH), combining EC theory and heuristic algorithms. The overall framework is shown in Fig. 1. We model service requests as task sequences and transform the task scheduling problem into a combinatorial optimization problem solvable by"}, {"title": "II. RELATED WORK", "content": "To better understand the importance and innovation of our research, we first compare several task scheduling schemes based on heuristic algorithms in an edge computing environment. Following this, we introduce the background works of this paper."}, {"title": "A. Heuristic task scheduling algorithm", "content": "Heuristic algorithms have shown significant advantages in solving large-scale combinatorial optimization problems [6]. Hence, they have a wide application scope in task scheduling problems of edge servers. Heuristic algorithms are mainly inspired by four kinds of heuristics that are Ant Colony Optimization (ACO), Particle Swarm Optimization (PSO), Genetic Algorithms (GA), and Hybrid Heuristic Algorithms (HHA).\nACO uses a pheromone mechanism to find the optimal path, making it suitable for handling scheduling issues with complex task dependencies and resource constraints. Also, it is robust and has global search capabilities. The AVE framework applies ACO algorithms to task scheduling to enhance efficiency and address the needs of assistance provided by other vehicles [3]. Wang and colleagues proposed the Load Balancing ACO (LBA) algorithm to solve task scheduling problems in a Mobile Edge Computing (MEC) environment with limited resources [7]. However, the ACO-based heuristic algorithms require extensive experimentation for parameter selection.\nPSO is commonly used in dynamic scheduling environments, conducts a global search through the sharing of information among individuals within a swarm, and is capable of rapidly responding to arrived tasks and changes of resource status. [8] Presented a task scheduling scheme based on the PSO algorithm to enhance the resource utilization of cloud servers. [9] Introduced load balancing mutation Particle Swarm Optimization (LBMPSO), which considers multiple optimization objectives, including transmission costs and load balancing. However, it is not suitable for solving large-scale problems.\nThe emergence of GA [10] and HHA has provided new approaches for addressing multi-objective and multi-constraint optimization problems. GA seeks optimal solutions by simulating natural selection and genetic mechanisms. GA can be used for multi-objective optimization, such as minimizing task completion time and maximizing resource utilization. Hu et al. modeled the request scheduling problem as a dual decision problem based on mixed-integer nonlinear programming, using the Non-dominated Sorting Genetic Algorithm II (NSGA-II) for multi-objective optimization [11]. Yuan et al. proposed an improved NSGA-II for the intelligent workshop resource scheduling problem, addressing traditional GA's issue of slower search speed at the later stages by establishing a rank-based smoothing function and introducing a congestion mechanism [12]. HHA combines multiple heuristic algorithms to leverage their respective advantages. Wang et al. proposed a hybrid heuristic task scheduling algorithm that combines PSO and ACO [13]. Although these methods perfectly solve the problems of parameter settings and problem-scale limitation, they still require considerable effort in manual heuristic design."}, {"title": "B. Background works", "content": "1) Serialization modeling scheme\nIn the service request scheduling algorithm RLPNet proposed by Zhao et al. [4], the sequential characteristics of service request scheduling problems were noticed. Thus, they modeled it as a sequence-to-sequence (Seq2Seq) multi-objective optimization problem. The traditional Seq2Seq models exhibit poor scalability when dealing with the issue where the output sequence's length depends on the input sequence's length. Therefore, RLPNet employed a pointer network [14] for sequential modeling, which can handle variable-length input by outputting a probability distribution of the input sequence. This approach demonstrates significant advantages in reinforcement-learning-based task scheduling algorithms and provides reference value to many others.\n2) Automatic heuristic algorithm design based on LLMS\nLLMs have been effectively employed in numerous practical scenes, showcasing their advanced capabilities"}, {"title": "III. METHOD", "content": "This section introduces the detailed implementation of the task scheduling scheme based on EC and heuristic algorithms."}, {"title": "A. Overall framework", "content": "The edge server task scheduling algorithm based on EoH consists of heuristic strategies, a generator, and an evaluator, as shown in Fig.1.\nOur heuristic strategies mimic genetic mutation and recombination processes in biological evolution, which can be divided into initialization, mutation, and evolution strategies. The initialization strategy generates the initial population. Mutation strategies generate offspring that are completely different from their parents. Evolution strategies generate better offspring than their parents while maintaining their basic characteristics.\nThe generator consists of two phases. First, it generates heuristic descriptions based on heuristic strategies, leveraging LLMs' semantic capturing and natural language generation capabilities. Then, using LLMs' code generation capabilities, the corresponding code is spontaneously generated based on the heuristic descriptions, as shown in Fig. 2. The generated code is used for task selection.\nThe evaluator first scores the tasks based on the generated algorithms and selects the task with the highest score for scheduling, iterating until all tasks are scheduled. It then evaluates the scheduling sequence to determine the fitness of the scoring algorithm for the task sequence. The fitness level decides whether the algorithm can proceed to the next round of evolution. The evolutionary process is illustrated in Fig. 3."}, {"title": "B. The design of heuristic strategies", "content": "This paper designs three heuristic strategies: initialization, mutation, and evolution. To ensure the uniqueness of the heuristic descriptions, the system performs a redundancy check every time a new heuristic strategy is applied to generate a description, except for the initialization strategy. If the generated heuristic description is found to be too similar to the existing ones, the system will execute the strategy again until a unique heuristic description is produced."}, {"title": "1) The initialization strategy", "content": "The role of the initialization strategy is to create the initial population, which is the first step of running the heuristic algorithm successfully. This strategy guides the large-scale pre-trained LLMs in generating the initial heuristic descriptions using prompt engineering. These descriptions are the starting point for the algorithm's processing and form the basis for subsequent mutation and evolution strategies. The prompt templates are designed to provide a clear and effective framework to steer the model in generating the initial heuristics in the desired direction. Fig. 2 shows two examples of prompt engineering."}, {"title": "2) The mutation strategies", "content": "The mutation strategies in our heuristic algorithm are employed to inspire innovation by introducing new changes to promote diversity within the solution set. The key is to explore and generate new heuristic descriptions that are as different as possible from the original description, thus driving the evolution of heuristics.\nMutation strategy M1: direct mutation.\nMutation strategy M1 leads to direct generation, aiming to create offspring heuristics that exhibit obvious differences from their parent heuristics. This approach ensures that each mutation introduces new elements, driving the algorithm to explore new solutions.\nMutation strategy M2: mutation remaining core idea.\nUnlike the M1 strategy, the mutation strategy M2 first identifies and extracts the core idea of the parent heuristic. Based on this core idea, it generates offspring heuristics that are the same in core concept but different in expression. This approach enhances the solution by adding diversity to the expression while keeping its intrinsic value."}, {"title": "3) The evolution strategies", "content": "Evolution strategies are used to refine and optimize existing heuristics to enhance performance continuously. The design of these strategies ensures that the algorithm retains the advantages of the original heuristic while exploring new heuristics.\nEvolution strategy E1: performance optimization.\nThe core idea of the evolutionary strategy El is to generate offspring heuristics that perform better than the parent heuristic. This strategy focuses on enhancing the solution's overall performance by introducing new algorithmic components or adjusting the implementation of existing logic so that the offspring heuristics can achieve higher efficiency and accuracy when handling the same tasks.\nEvolution strategy E2: parameters tuning.\nEvolutionary strategy E2 generates more effective offspring heuristics by tuning the parameters of the parent heuristic. This strategy focuses on adjustments for details, such as modifying parameters or reallocating their weights, to further refine and improve the heuristic description."}, {"title": "C. The generator and evaluator", "content": "1) Code Generation\nThe main task of this section is to use the heuristic strategies defined in Section III-B to generate executable Python code. Firstly, heuristic descriptions are generated according to the heuristic strategy. Then, these descriptions will be used as input, turning into heuristic algorithms through prompt rewriting. The specific steps in this phase are as follows:\n\u2022 Step 1 Heuristic description generation: Based on the heuristic strategies in Section III-B, generate heuristic descriptions that concisely and efficiently represent the details of the expected algorithm.\n\u2022 Step 2: Implement a novel prompt rewriting methodology to comprehensively analyze and refine the heuristic descriptions. This process ensures alignment with the specific requirements of the algorithm's implementation.\n\u2022 Step 3 Code Generation: Implement the algorithm function based on the rewritten prompt.\n2) Evolutionary Evaluation\nFirstly, process the service request queue of the edge server, retaining the required data, which includes CPU, I/O, bandwidth, memory resources, the arrival time, execution time, and optional servers:\n$q_i = (C_i, O_i, b_i, m_i, T_i, t_i, S_i)$ (1)\nModel all service requests as a sequenceRS:\n$RS = {q_1, q_2, ..., q_n}$ (2)\nEdge servers can be represented by set S:\n$S = {s_1, s_2, ..., s_m}$ (3)\nAvailable resources for edge servers include CPU, I/0, bandwidth, and memory.\n$s_j = (c_j, o_j, b_j, m_j)$ (4)"}, {"title": "The task scheduling problem of the edge server can be simplified by reorganizing the request sequence RS.", "content": "Specifically, it involves determining the optimal reorganization of the request sequence RS given the available resources $s_j$ to achieve optimal scheduling. This paper addresses two key scheduling optimization objectives: maximizing resource utilization and minimizing running time.\nThe task scheduling decision can be made according to the executable code generated in Section III-C1. The generated scoring function scores each task whose resource demand is satisfied. Then, the scoring sequence S(RS) will be obtained.\n$S(RS) = {s(q_1), s(q_2), ..., s(q_N)}$ (5)\nSelect the largest element $S(q_i)$in set S(RS):\n$s(q_i) = max{S(RS)}$ (6)\nAdd it to the schedule sequence, iterating until the request sequence is empty. Finally, the schedule sequence SS will be obtained:\n$SS = {q_a, q_b, ..., q_n}$ (7)\nSubscript a, b, ...n is the subscript of the request in the request sequenceRS. Then, evaluate the scheduling sequence SS regarding resource utilization and running time. Generally, our algorithm will perform best when the evaluation coefficients $\\alpha, \\beta$ are set to 150 and 1.\n$fitness = \\alpha * avg(u) \u2013 \\beta * avg(r)$, (8)\nwhere avg(u) is the average resource utilization rate, avg(r) is the average running time, the calculation formula is as follows:\n$avg(u) = \\frac{1}{m} \\sum_{j=1}^{m}max(c_j, O_j, b_j, m_j)$ (9)\n$avg(r) = \\frac{1}{n}(finish\\_time \u2013 start\\_time)$ (10)"}, {"title": "D. Algorithm Evolution", "content": "We adopted an EC-based strategy to optimize the task-scheduling sequence when designing efficient algorithms. Initially, we constructed a population composed of N individuals, each representing a potential task scheduling scheme, and subsequently generated 4N offspring in each round of evolution. This process mimicked natural selection and genetic mutation mechanisms, allowing superior scheduling schemes to be preserved and evolved.\nIn each round of evolution, the scoring scheme represented by each offspring will assign scores to the allocated tasks, reflecting whether the edge server should process the task at that time. We will select the highest-scoring tasks for execution until all tasks have been scheduled. Then, the system will comprehensively evaluate the scheduling sequence to determine the fitness of each scheme. The fitness represents the degree of match between the scoring scheme and the task set; the higher the fitness, the more suitable the scheme is for the given task set.\nAt the end of each evolution, we select N offspring with the highest suitability from the 4N produced offspring to enter into the next round of evolution. This selection process simulates the principle of survival of the fittest, ensuring that the algorithm can continuously self-optimize and gradually find more efficient task-scheduling schemes.\nAfter several rounds of evolutionary iteration, we select the scheduling scheme with the highest fitness from all offspring. With the optimal task scheduling sequence, this scheme is considered the best scheduling result for a specific set of tasks. This evolution-based task scheduling algorithm can adapt flexibly to various tasks and environmental conditions and automatically discover and utilize the potential associations between tasks, thereby significantly enhancing scheduling efficiency and system performance."}, {"title": "IV. EXPERIMENT", "content": "This section validates the effectiveness of the edge server task scheduling method based on EoH through a series of experiments on real datasets. Firstly, we compare the scheduling results of four different LLMs services. Then, we select the best-performing LLMs and compare the performance of the TS-EoH algorithm with other task scheduling methods on three real datasets. Finally, we assess the effectiveness of four evolutionary schemes through ablation experiments."}, {"title": "A. Datasets", "content": "The experiment selected three public datasets: Google Cluster Trace, Alibaba Cluster Trace, and EUA-dataset.\nGoogle Cluster Trace [19] collects data from Google's edge-cloud collaboration system, documenting detailed information about task submission, scheduling decisions, system configuration, and resource utilization.\nAlibaba Cluster Trace [20] originates from multiple edge servers in Alibaba's production cluster environment, including task and job information, resource requests and usage, scheduling events, and system configuration and runtime information of applications.\nEUA-dataset [21] contains the geographical locations of 125 base stations in Melbourne CBD and the 816 mobile users around. Our experiments consider base stations as edge servers and mobile users as service requests."}, {"title": "B. Comparison of LLMs", "content": "Experimental settings: To explore deeply and assess the scheduling performance of different LLMs, this"}, {"title": "C. Comparison of performance", "content": "Experimental settings: To comprehensively evaluate the superiority of TS-EoH, experiments are carried out on three datasets: Google Cluster Trace, Alibaba Cluster Trace, and EUA dataset. Experiments in Section IV-B demonstrate that DeepSeek-Coder-V2 best reflects the advantages of our algorithm; therefore, DeepSeek-Coder-V2 is selected as the base model for this section's experiments. In addition to our algorithm, we chose six current mainstream scheduling algorithms for comparative analysis: FCFS (First-Come, First-Served), HRRN (High-Response-Ratio-Next), Random, Greedy, ACO (Ant Colony Optimization), and RLPNet (Reinforcement Learning with Pointer Networks). The task number range is also 300-600.\n\u2022 FCFS [22]: Tasks are scheduled according to their arrival, with the first arriving tasks being executed.\n\u2022 HRRN [23]: HRRN considers both the waiting time and service time of tasks, selecting the task with the highest response ratio for scheduling.\n\u2022 Random [24]: Tasks are scheduled randomly by selecting the next task to execute without regard to any specific attributes or order.\n\u2022 Greedy [25]: This method selects the currently optimal task to execute based on a certain optimization criterion.\n\u2022 ACO [3]: A heuristic algorithm known for its natural parallelism and strong global search capability, effectively handling complex scheduling problems.\n\u2022 RLPNet [4]: A service request scheduling algorithm based on deep reinforcement learning with pointer networks of multi-objective optimization.\nExperimental results: Our TS-EoH algorithm performs better than the other six task scheduling algorithms regarding resource utilization and runtime(Fig. 5). Regarding resource utilization rate, our TS-EoH algorithm significantly outperforms other algorithms. On the Google Cluster Trace, the maximum resource utilization reaches 94.8%; on the Alibaba Cluster Trace, it is 95.4%; and on the EUA dataset, it hits 95.6%. Meanwhile, it is worth noticing that there's no obvious relationship between resource utilization rate and the number of tasks. Besides, As the number of tasks increases, the overall runtime tends to increase. However, due to the randomness in task selection, this trend is less apparent when the number of tasks does not differ significantly. Our EoH-based task scheduling algorithm can reduce task runtime to some extent, and the more tasks there are, the more apparent our algorithm's superiority is in running time. TS-EoH's resource utilization and running time superiority mainly lies in its self-evolution"}, {"title": "D. Ablation study", "content": "Experimental settings: A series of ablation experiments assessing the effects of the four heuristic strategies (M1, M2, E1, E2) are proposed in this study. These experiments aim to clarify the individual contributions of each strategy to the overall algorithm performance and explore potential synergistic effects among them by combining different evolutionary strategies. The experiments are categorized into three groups: single-strategy group (M1, M2, E1, E2), dual-strategy group (M1+M2, M2+E1, E1+E2, M1+E1, M2+E2, M1+E2), and triple-strategy group (M2+E1+E2, M1+E1+E2, M1+M2+E1).\nEach group of experiments utilizes DeepSeek-Coder-V2 and is conducted on the Alibaba Cluster Trace dataset with 500 tasks.\nExperimental results: Experiments indicate that mutation strategy M1 maximizes resource utilization rate and minimizes the running time to the greatest extent when using only one heuristic strategy. When employing two heuristic strategies, the synergistic effect of mutation strategies M1 and M2 significantly enhances the resource utilization rate and reduces running time. Under the combination of three strategies, approaches including two combined mutation strategies outperform those including two evolution strategies regarding resource utilization rate. In contrast, the method utilizing mutation strategy M2 and two evolution strategies excels in running time optimization."}, {"title": "V. CONCLUSION", "content": "This paper proposes an innovative edge server task scheduling scheme based on the EoH framework to optimize resource utilization and service quality. We utilize heuristic algorithms and EC theories, coupled with the generative capabilities of LLMs, to seek the optimal scoring algorithm for efficient management and task scheduling on edge servers. Furthermore, through experiments, we explore our algorithm's most suitable LLM services and compare its superiority over existing state-of-the-art algorithms. We also clarify the impact of different evolutionary strategies on scheduling results."}, {"title": "Future work could focus on further optimizing the mutation strategy to maximize its advantages in the evolutionary process.", "content": "Additionally, it is meaningful to select several optimal populations through extensive experiments and generate instructional data through the SELF-INSTRUCT framework [26], which can be applied to fine-tune the LLMs to produce results more closely aligned with the application scenarios outlined in this paper."}]}