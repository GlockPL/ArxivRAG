{"title": "A TUTORIAL ON BROWNIAN MOTION FOR BIOSTATISTICIANS", "authors": ["Elvis Han Cui"], "abstract": "This manuscript provides an in-depth exploration of Brownian Motion, a fundamental stochastic process in probability theory for Biostatisticians. It begins with foundational definitions and properties, including the construction of Brownian motion and its Markovian characteristics. The document delves into advanced topics such as the Karhunen-Lo\u00e8ve expansion, reflection principles, and L\u00e9vy's modulus of continuity. Through rigorous proofs and theorems, the manuscript examines the non-differentiability of Brownian paths, the behavior of zero sets, and the significance of local time. The notes also cover important results like Donsker's theorem and Blumenthal's 0-1 law, emphasizing their implications in the study of stochastic processes.", "sections": [{"title": "Introduction", "content": "Brownian motion, also known as Wiener process, is one of the most important and widely studied stochastic processes in both probability theory and mathematical physics. Originally observed in the erratic movement of pollen grains suspended in water by the botanist Robert Brown, it was later rigorously formalized by Norbert Wiener in the early 20th century. Brownian motion serves as a cornerstone in the modeling of various random phenomena, ranging from financial markets to the diffusion of particles in fluids.\nThis manuscript provides a comprehensive overview of the key concepts, properties, and applications of Brownian motion. The exploration begins with a formal definition of Brownian motion and its fundamental properties, such as stationary independent increments and the Gaussian distribution of the process. Following the foundational aspects, the document delves into more advanced topics, including the Karhunen-Lo\u00e8ve expansion, which decomposes a process with zero mean and finite variance into an orthonormal basis, and the reflection principle, which is a crucial result derived from the strong Markov property.\nFurthermore, the manuscript covers the non-differentiability of Brownian paths, illustrating the unique and sometimes counterintuitive nature of the process. The analysis of zero sets and local time provides deeper insights into the structure of paths and their occupation measures. Additionally, important theorems such as Blumenthal's 0-1 law, Donsker's theorem, and L\u00e9vy's characterization are discussed, each highlighting critical aspects of stochastic processes and their implications in various fields.\nOverall, these notes aim to equip the reader with a solid understanding of Brownian motion, from its theoretical underpinnings to its practical applications in modern science and engineering."}, {"title": "Definitions", "content": ""}, {"title": "Brownian Motion", "content": "Definition 1 (Standard Brownian Motion (Liggett, 2010)). Standard Brownian Motion B(t) is a stochastic process with continuous paths that satisfies one of the following properties:\n(a) B(t) has stationary independent increments, and B(t) is N(0, t) for t \u2265 0.\n(b) B(t) is a Gaussian process with \\mathbb{E}B(t) = 0 and\nCov(B(s), B(t)) = s \\wedge t.\nRemarks:\n\u2022 Sometimes we write Bt for B(t) and Bt(w) or B(t, w) for a given sample point w \u2208 \u03a9.\n\u2022 There exists a probability space (\u03a9, \u0397, P) on which standard Brownian motion B exists. The proof is postponed to Theorem 1.\nIt is convenient to take \u03a9 = C[0, \u221e), the space of all continuous functions w(\u00b7) on R+ or [0, \u221e). Note that if we simply take \u03a9 = R[0,\u221e) and its Borel o-algebra, then the set\nC = {w : B(t,w) is continuous in t.}\nis not even an event since it depends on uncountably many points. For \u03a9 = C[0,\u221e), the \u03c3-algebra is taken to be the Borel \u03c3-algebra, i.e., the smallest one for which the projection mapping w \u2192 w(t) is measurable for each t and we denote it as H. We have a family \\mathbb{P} = {P} of probability measures indexed by x \u2208 R\u00b9 instead of a single probability measure. The measure P\u00ba is the distribution of x + B(\u00b7) where B is a standard Brownian motion. The corresponding expectation is denoted by Ex. The probability triple is denoted by (\u03a9, H, Px). If in addition, we have a filtration F = {Ft : t > 0}, then the stochastic basis is the quadruple (\u03a9, H, F, Px) (Dabrowska, 2020).\nLemma 1. Let \u03a9 = R[0,\u221e) and H be its Borel o-algebra. Then the set\nC = {w : B(t,w) is continuous in t.}\nis not even an event, i.e., C \\notin H.\nProof. Define property (*): \u2203J countable s.t. if f \u2208 A, g \u2208 R[0,\u221e), then f|j = g|j implies g \u2208 A. Define the family of sets\n\\mathcal{A} = {A \u2286 R[0,\u221e) : A satisfies (*)}.\nClearly B\u03b1 = \u03c0\u03b1\u00b9(B(R\u00ba)), is a subset of A (a finite and \u03c0\u03b1 is the projection from R[0,\u221e) to R\u00ba). But H is generated from B\u03b1:\nH = \u03c3 (U \u03c0\u03b1\u00b9(B(R\u00ae))).\n\u03b1 finite\nSo if we can show that A is a \u03c3-algebra and C \\notin A, then we are done. C does not satisfy (*): if J exists, we pick x \u2208 J and set g(x) = f(x) + 1; then f|j = g|j but g is not continuous."}, {"title": "Basic and Advanced Properties", "content": ""}, {"title": "Existence and Construction", "content": "Theorem 1 (Existence and Construction of Brownian motion). There exists a probability space (\u03a9, \u0397, P) on which standard Brownian motion B exists and has continuous sample path.\nRemarks: Recall that a Brownian motion is a process with the following properties:\n(i) B(t) has stationary and independent increments;\n(ii) B(t) is Gaussian with mean 0 and variance t;\n(iii) B(t) is continuous in t."}, {"title": "The Markov and Strong Markov Property", "content": "Define two \u03c3-algebras:\n\\begin{equation}\n\\mathcal{F}_s = \\sigma(B_r : r \\leq s)\n\\end{equation}\n\\begin{equation}\n\\mathcal{F}_s^+ = \\bigcap_{t>s} \\mathcal{F}_t\n\\end{equation}\nLet f (u) > 0 for all u > 0, then the random variable\n\\limsup_{t \\downarrow s} \\frac{B_t - B_s}{f(t-s)} \\in \\mathcal{E}F\nbut is not \\mathcal{F}_s^+ -measurable since it depends on the value of Bt. The o-algebra \\mathcal{F}_s^+ can be considered as \u201can infinitesimal peak\" at the future (Durrett, 2019).\nTheorem 2 (Markov Property). If Y is bounded and measurable, then for every x \u2208 R\u00b9 and s \u2265 0, we have\n\\begin{equation}\n\\mathbb{E}^* (Y \\circ \\theta_s | \\mathcal{F}_s^+) = \\mathbb{E}^{B(s)} Y \\text{ a.s. } \\mathbb{P}^x\n\\end{equation}"}, {"title": "Karhunen-Lo\u00e9ve Expansion", "content": "Theorem 4 (Karhunen-Lo\u00e9ve (Dabrowska, 2020)). If {Xt : t \u2208 [0, 1]} is a process with zero mean and finite variance, then it admits a decomposition\n\\begin{equation}\nX_t = \\sum_{n=1}^{\\infty} Y_n \\psi_n (t),\n\\end{equation}\nwhere Yn's are pairwise uncorrelated random variables and on's form an orthonormal basis in L\u00b2([0, 1]) determined by K(s,t) = Cov(Xs, Xt), the covariance of the process.\nRemarks: If K(s,t) is a positive definite kernel and the associated eigenfunctions form a complete orthonormal sequence of L\u00b2([0, 1]), then we can take Yn = \u27e8\u03a7, \u03a6\u03b7\u27e9 where on's are eigenfunctions of K. In this case, Yn's are uncorrelated mean zero variables with variance An, the eigenvalues of K(s, t).\nExample 1 (Brownian Motion on the unit interval). Standard Brownian Motion on [0, 1] has covariance K(s,t) = s^t and can be decomposed as\nK(s,t) = \\sum_{j=1}^{\\infty} \\lambda_j \\phi_j(s) \\phi_j(t)\nwhere (j \u2265 1)\n\\lambda_j = \\frac{4}{(2j-1)^2 \\pi^2} , \\phi_j(t) = \\sqrt{2} \\sin \\left( \\left( j - \\frac{1}{2} \\right) \\pi t \\right)\nMoreover, Brownian motion has the same distribution as\nW_t \\sim \\sum_{j=1}^{\\infty} \\sqrt{\\lambda_j} \\xi_j \\phi_j (t),\nwhere Vj, j \u2265 0 are i.i.d. N(0, 1) variables. The derivation of $; boils down to solving differential equations and its distribution relies on the convergence of Riemannian sum."}, {"title": "Examples and Applications", "content": ""}, {"title": "Blumenthal's 0-1 Law", "content": "Theorem 5 (Blumenthal's 0-1 Law (Liggett, 2010)). (a) If Y is a bounded random variable, then for every x\n\\mathbb{E}^x(Y| \\mathcal{F}^+_{0}) = \\mathbb{E}^x (Y| \\mathcal{F}_0) \\text{ a.s. } \\mathbb{P}^x .\n(b) If A \u2208 \\mathcal{F}_0^+, then\n\\mathbb{P}^x(A) = 0 \\text{ or } 1."}, {"title": "Zero Set", "content": "Consider the zero set (for a given \u03c9 \u2208 \u03a9)\n\\begin{equation}\nZ(\\omega) = \\{t \\in \\mathbb{R}_+ : B_t(\\omega) = 0\\}\n\\end{equation}\nTheorem 7 (Zero Set). With probability 1, the set Z is perfect, and hence closed and uncountable. The Lebesgue measure of Z is 0 a.s.\nRemark: A set is perfect if it is closed with no isolated points, i.e., every point is a limit point. By the Markov property, we conclude that the level set L(a, w) = {t \u2208 R+ : Bt(w) = a} has the same properties as the zero set Z(w) does.\nProof. The 0 Lebesgue measure is easy to show:\nE(m(Z)) = E \\int_{\\mathbb{R}_+} I_Z(t) dt = \\int_{\\mathbb{R}_+} E I_Z(t) dt = \\int_{\\mathbb{R}_+} \\mathbb{P}(B(t) = 0) dt = 0\nFor a given w, Z = B\u22121({0}), i.e., the inverse image of {0} under the continuous mapping B(.,w). Hence, Z is closed and its complement is a countable union of open intervals. We write\nZ = \\bigcup_{n \\in \\mathbb{N}} (l_n, r_n)\nand rn are stopping times but In are not.\nNext, let t \u2208 Z be any zero of the path, then t is either a limit point of Z from the left or not."}, {"title": "Non-differentiability", "content": "We start with a proposition that describes the peculiarities of the Brownian motion path, and then jump into pointwise and globalwise non-differentiability of B.\nProposition 1. Almost surely the Brownian motion B is not monotone on any interval [s, t].\nProof. It is enough to show that the following set has probability 0:\nA = \\bigcup_{s,t \\in \\mathbb{Q}^+} \\{ \\omega \\in \\Omega : B(\\omega) \\text{ is monotone on } [s,t] \\}\n= \\bigcup_{s,t \\in \\mathbb{Q}^+} A_{st}\nBy o-additivity of a probability measure and stationarity of B, we only have to show that A01 = {B is monotone on [0, 1]} has probability 0.\nLet\nB_n = \\bigcap_{i=1}^{n} \\{ B(\\frac{i}{n}) - B(\\frac{i-1}{n}) \\geq 0 \\}\nso that A01 = \\bigcap_{n=1}^{\\infty} B_n. But\n\\mathbb{P}^0(B_n) = 2^{-n} \\to 0 \\text{ as } n \\to \\infty.\nLemma 2 (Pointwise Nonsmoothness). For a fixed t \u2265 0,\n\\mathbb{P}(B(\\cdot, \\omega) \\text{ is not differentiable at } t) = 1.\nFurther, for P a.s. \u03c9 \u2208 \u03a9,\nm(A) = 0, A = {t > 0 : B(\\cdot,\\omega) \\text{ is differentiable at } t}.\nProof. For t = 0, we have lim sup_{t \\downarrow 0} \\frac{B(t)}{\\sqrt{t}} = +\\infty \\text{ a.s. } If B is differentiable at B, then \u2203K, \u20ac > 0, and we have (by the mean value theorem)\n|B(s) - B(0)| \\leq K|s - 0|, s \u2208 [0, \u20ac).\nA contradiction. Next, for any t > 0, we note that \\frac{B(t) - B(t_0)}{\\sqrt{t - t_0}} has the same distribution as \\frac{B(t - t_0)}{\\sqrt{t - t_0}}.\nFor the second part, fix w and define the random set\nC = \\{t > 0 : \\lim_{n \\to \\infty} \\frac{B(t + \\frac{1}{n}, \\omega) - B(t, \\omega)}{\\frac{1}{1/n}} \\text{ exists at t} \\}\nBy Fubini's theorem and joint measurability of B(t, w)\n\\mathbb{E}(m(A)) \\leq \\mathbb{E} m(C) = \\int_{\\Omega} ( \\int_0^\\infty I_C(t) dt ) d\\mathbb{P} = \\int_0^\\infty ( \\int_{\\Omega}  I_C(t) d\\mathbb{P} ) dt = 0\nwhere the last equality follows from the first part."}, {"title": "Reflection Principle", "content": "This is another application of the strong Markov property.\nTheorem 9 (Reflection Principle). If a > 0 and b < a, then for any t > 0,\n\\begin{equation}\n\\mathbb{P}^0 (M(t) > a, B(t) < b) = \\mathbb{P}^0 (B(t) > 2a - b),\n\\end{equation}\nwhere\n\\begin{equation}\nM(t) = \\max_{0 \\leq s \\leq t} B(s),\n\\end{equation}\nis the running maximum of B up to time t.\nProof. Define\n\\tau = \\inf \\{s \\geq 0 : B(s) = a\\},\n\\mathbb{Y}_s(\\omega) = I(s < t, B(t - s) > 2a - b) - I(s < t, B(t - s) < b).\nFor s < t,\nE\\mathbb{Y} = \\mathbb{P}^0(B(t - s) > 2a - b) - \\mathbb{P}^0 (B(t - s) < b).\nBy symmetry, on the set {7 < \u221e}, we have\n\\mathbb{E}^{B(\\tau)}\\mathbb{Y}_\\tau = E \\mathbb{Y} = E \\mathbb{Y}_s|_{s=t} = 0."}, {"title": "Local Time", "content": "The occupation time (or the occupation measure) of a Borel set A C R\u00b9 by Brownian motion up to time t is\nK_t(\\omega, A) = \\int_0^t I_A(B(s,\\omega)) ds = m(\\{s \\in [0, t] : B(s,\\omega) \\in A\\}),\nwhich is a random measure of total mass t. It is absolutely continuous w.r.t. the Lebesgue measure and its Radon-Nikodym derivative is called the local time (Liggett, 2010). The Radon-Nikodym derivative is jointly continuous in space and time a.s. and can be conceptually thought/defined as\nL_t(a,\\omega) = \\lim_{\\epsilon \\downarrow 0} \\frac{K_t(\\omega, (a - \\epsilon, a + \\epsilon))}{2 \\epsilon}\nand the proof of existence is non-trivial.\nIn other words, the local time Lt(a,w) serves as a density w.r.t. m(\u00b7), the Lebesgue measure for occupation time (Karatzas and Shreve, 2014; M\u00f6rters and Peres, 2010), i.e.,\n\\begin{equation}\nK_t(\\omega, A) = \\int_0^t I_A(B(s,\\omega)) ds = \\int_A dx L_t(x, \\omega), t \\in \\mathbb{R}_+, A \\in \\mathcal{B}(\\mathbb{R}).\n\\end{equation}"}, {"title": "L\u00e9vy's Martingale Characterization", "content": "Definition 2 (Predictable Variation (Dabrowska, 2020)). If M (t) is a locally square integrable martingale then M\u00b2(t) is a local sub-martingale. By Doob-Meyer's decomposition, there exists a predictable process \u27e8M\u27e9(t) s.t. M\u00b2(t) \u2212 \u27e8M\u27e9(t) is a local martingale. The process \u27e8M\u27e9(t) is referred to as the predictable variation of M(t) and can be obtained as the in probability limit of sums\n\\sum_{i=1}^{n} E \\left( \\left. M^2(t_i) - M^2(t_{i-1}) | \\mathcal{F}_{t_{i-1}} \\right) \\right) = \\sum_{i=1}^{n} Var \\left( \\left. M(t_i) - M(t_{i-1}) | \\mathcal{F}_{t_{i-1}} \\right) ,\nwhere 0 = to < t1 < \u2026 < tk = t is a partition with mesh maxi ti-ti-1 \u2192 0.\nTheorem 11 (L\u00e9vy's Characterization of B (\u00c7inlar, 2011)). If M(t) is a continuous square integrable martingale w.r.t. F with M(0) = 0, and \u27e8M\u27e9(t) = t, then M(t) is a standard Brownian motion w.r.t. F.\nRemarks: By Doob-Meyer, the statement \u27e8M\u27e9(t) = t is equivalent to say that M\u00b2(t) \u2212 t is again a martingale w.r.t. F."}, {"title": "Donsker's Theorem", "content": "In non-parametric statistics, one of the most important distributions is the empirical distribution\nF_n(t) = \\frac{1}{n} \\sum_{i=1}^n I(X_i \\leq t),\nwhere Xi's are i.i.d. random variables with the same distribution F. By SLLN, Fn(t) converges to F(t) a.s. and the convergence is strengthened to uniform by Glivenko-Cantelli. By the classical CLT, \u221an (Fn(t) \u2013 F(t)) converges weakly to N(0, F(t)(1 \u2013 F(t))).\nNow if we regard Fn(\u00b7) as a stochastic process indexed by t \u2208 R, what can we say about the limiting distribution of {\u221an(Fn(t) \u2013 F(t)) : t \u2208 R}? Moreover, let H be a class of measurable functions, then what can we say about the distribution of\n\\mathbb{P}_n h = \\frac{1}{n} \\sum_{i=1}^n h(X_i), h \\in \\mathcal{H} ?\nThis is the subject of the empirical process theory. Here we focus on the special case ht(Xi) = I(Xi < t).\nTheorem 12 (Donsker's Theorem for Empirical Distribution). Let Xi's be i.i.d. variables with a common distribution F. Define the process\nW(t) = \\sqrt{n} (F_n(t) - F(t)), t \\in \\mathbb{R}.\nThen we have\nW(\\cdot) \\Rightarrow W(F(\\cdot)) \\text{ in } D(\\mathbb{R}),\nwhere W(x) = B(x) \u2212 xB(1), x \u2208 [0,1] is the Brownian Bridge (BB) process.\nRemarks: D(R) is the space of right-continuous functions with left limits and is equipped with the sup-norm. The weak convergence of a stochastic process Xn to X means for every bounded continuous f, we have Ef(Xn) \u2192 Ef(X). However, in practice, one applied Kolmogorov's theorem to show the weak convergence (Billingsley, 2013).\nTheorem 13 (Donsker's Theorem for Partial Sum). Let Xi's be i.i.d. with mean 0 and variance 1. Define the partial sum process\nZ_n(t) = \\frac{S_{\\lfloor nt \\rfloor}}{\\sqrt{n}}, t \\in [0, 1],\nwhere S[nt] = \\sum_{i=1}^{\\lfloor nt \\rfloor} X_i is the partial sum. Then\nZ_n \\Rightarrow B\nin D[0, 1], where B is the standard Brownian motion."}, {"title": "More Examples", "content": ""}, {"title": "Example 2 (The Inverse Gaussian Distribution (Kahle et al., 2016))", "content": "From the reflection principle, we can derive the density of the first hitting time \\tau_a = \\inf \\{t > 0 : B(t) = a\\} with a > 0:\n\\begin{equation}\nP_{\\tau_a}(T) = \\frac{d \\mathbb{P}^0(\\tau_a \\leq T)}{dT} = \\frac{a}{\\sqrt{2\\pi T^3}} \\exp \\left( - \\frac{a^2}{2 T} \\right).\n\\end{equation}\nThis is the density of an inverse Gaussian distribution."}, {"title": "Conclusion", "content": "In this manuscript, we have explored key properties and theorems related to Brownian motion. The detailed analysis included the definition, construction, and fundamental properties of Brownian motion, as well as advanced concepts such as the Markov and strong Markov properties, local time, and reflection principles. These concepts are critical for understanding the behavior of Brownian motion in stochastic processes and have applications in various fields including finance, physics, and mathematics."}]}