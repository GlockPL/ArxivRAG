{"title": "Towards Socially and Environmentally Responsible AI", "authors": ["Pengfei Li", "Yejia Liu", "Jianyi Yang", "Shaolei Ren"], "abstract": "The sharply increasing sizes of artificial intelligence (AI) models come with significant energy consumption and environmental footprints, which can disproportionately impact certain (often marginalized) regions and hence create environmental inequity concerns. Moreover, concerns with social inequity have also emerged, as AI computing resources may not be equitably distributed across the globe and users from certain disadvantaged regions with severe resource constraints can consistently experience inferior model performance. Importantly, the inequity concerns that encompass both social and environmental dimensions still remain unexplored and have increasingly hindered responsible AI. In this paper, we leverage the spatial flexibility of AI inference workloads and propose equitable geographical load balancing (GLB) to fairly balance Al's regional social and environmental costs. Concretely, to penalize the disproportionately high social and environmental costs for equity, we introduce $L_q$ norms as novel regularization terms into the optimization objective for GLB decisions. Our empirical results based on real-world Al inference traces demonstrate that while the existing GLB algorithms result in disproportionately large social and environmental costs in certain regions, our proposed equitable GLB can fairly balance AI's negative social and environmental costs across all the regions.", "sections": [{"title": "Introduction", "content": "In the rapidly evolving field of artificial intelligence (AI), a significant transformation is underway with the emergence of large foundation models as exemplified by Large Language Models (LLMs) like GPTs [4] and Vision Transformers Models (ViTs) [8]. These cutting-edge AI models demonstrate the ability to function effectively in diverse contexts, engaging with extensive vocabularies and image data for unforeseen AI tasks, i.e., zero-shot abilities. To serve inference requests, they are typically deployed across geographically distributed data centers for better service availability, lower transmission latency, and/or privacy regulations.\nEnvironmental inequity. Powerful yet hungry, large AI models require substantial resources not only during training but also in deployment and inference. For some popular Al services such as text and image generation, the total energy consumption for inference can be comparable to or even exceed that for training, resulting in huge carbon emissions and freshwater usage [14, 32]. To curb the growing environment footprint, many recent efforts have been devoted to enhancing the efficiency and reducing the energy consumption of AI models. Example strategies include model compression that reduces Al's computational demand for inference (typically at a sacrifice of model performance) [17, 18] and geographical load balancing (GLB) that leverages spatial heterogeneities to route more workloads to low-cost and/or greener regions [6, 15]. Additionally, on the infrastructure side, there has been a rise in the adoption of carbon-free energy and climate-conscious cooling system designs in the data center industry. For instance, utilizing air-side economizers where climate conditions allow has become increasingly common to cut the direct water consumption [21].\nWhile these approaches can effectively minimize Al's total environmental footprint, the rise of environmental inequity - Al's negative environmental impact can disproportionately affects certain (often marginalized) regions [2, 15] - has become increasingly worrisome, potentially leading to other unintended social and ecological consequences and widening regional disparities. Importantly, the disproportional distribution of AI's environmental cost across different regions can be amplified by existing approaches to managing Al systems (e.g., load distribution and AI model scaling) that often prioritize the total environmental cost rather than the cost borne by individual regions which are most environmentally vulnerable [15]. Compounded by the sharply growing demand, Al's environmental inequity has received calls for mitigation efforts from various organizations, such as UNESCO [27], Meta [20] and the State of California [5].\nSocial inequity. Going beyond environmental footprints, concerns with Al's social inequity have also emerged [28]. For now, only a few major tech players have the resource and capacity to train and deploy large AI models. Thus, due to the uneven deployment of computing resources across"}, {"title": "Related Works", "content": "From the social fairness perspective, much attention has been directed towards protecting groups with certain attributes [16, 23, 30]. The issue is partially rooted in inherent biases within datasets and could potentially be exacerbated by models [16, 30]. To address such unfairness, numerous strategies have been developed. For instance, [3, 19] suggest removing sensitive attributes from datasets to prevent the model from relying on them, while others adjust prediction outcomes after training [22, 23]. Additionally, some have advocated for equivalent metrics, such as error rates, among specific groups [1, 7]. These studies typically focus on the model training stage, but the attained fairness can be compromised if Al models of different sizes are not equitably chosen for users from different regions. By stark contrast, we focus on the Al inference stage and judiciously balance the user requests from different regions across geographically distributed data centers hosting heterogenous AI models.\nTo address AI's environmental impacts, existing studies primarily focus on minimizing environmental metrics such as the total carbon emission, water footprint, or a weighted combination thereof, to enable environmentally responsible AI model training and inference [6, 14, 32]. Nonetheless, concerns with Al's environmental inequity across different regions have remained largely unaddressed. A recent study [15] has proposed to tackle the uneven distribution of Al's regional environmental costs via GLB. But, this approach overlooks the social equity dimension, which is equally, if not more, important element of responsible AI."}, {"title": "Problem Formulation", "content": "We focus on the AI inference stage and consider a set of pretrained Al models denoted by $K = \\{1, 2, \u00b7 \u00b7 \u00b7, K\\}$, each with different performance and energy consumption for serving an inference request. There are a set of geographically distributed data centers $N = \\{1, 2, \u2026\u2026\u2026, N\\}$ serving users coming from a set of regions $J = \\{1,2,\u2026, J\\}$.\nOperational cost. At each time $t$, data center $i$ dynamically selects one or more of the available heterogeneous AI models to serve the incoming workloads. More formally, we denote $y_{i,j,k}(t) \\geq 0$ as the workload dispatched from region $j$ to data center $i$ served through model $k$ at time $t$. Given the scheduled demand $y_{j}(t)$, we denote the energy consumption and computational resources necessary for deploying model $k$ in data center $i$ as $e_{i,k}(y_{i,j,k}(t))$ and $r_{i,k}(y_{i,j,k}(t))$, respectively. For example, both $e_{i,k} (y_{i,j,k}(t))$ and $r_{i,k} (y_{i,j,k}(t))$ can be modeled as linearly increasing functions in terms of $y_{i,j,k}(t)$. Thus, the total energy consumption at data center $i$ can then be calculated as\n$$e_i(t) = \\sum_{j \\in J} \\sum_{k \\in K} e_{i,k}(y_{i,j,k}(t)).$$\nFor notational simplicity, we define the set of workload distribution decisions at time $t$ as $y(t) = \\{y_{i,j,k}(t)|i \\in N, j \\in J,k \\in K\\}$. We also take the energy price $p_{i,t}$ and power usage effectiveness (PUE, which accounts for non-IT energy overheads) $\\gamma_i$ of data center $i$ into consideration. As a result,"}, {"title": "A Case Study", "content": "We run a simulation study to preliminarily validate SE-GLB to mitigate Al's social and environmental inequities."}, {"title": "Concluding Remarks", "content": "In this work, we holistically consider Al's social and environmental equity and propose novel equity-aware GLB to balance Al's regional social and environmental costs towards responsible AI. Our key novelty is to introduce $L_q$ norms to penalize GLB decisions that would otherwise lead to disproportionately high social and/or environmental costs in disadvantaged regions. Our empirical evaluation has shown the effectiveness of our proposed approach in improving both social and environmental equity by prioritizing the most disadvantageous data centers and user regions."}]}