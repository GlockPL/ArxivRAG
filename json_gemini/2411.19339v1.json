{"title": "Towards a Mechanistic Explanation of Diffusion Model Generalization", "authors": ["Matthew Niedoba", "Berend Zwartsenberg", "Kevin Murphy", "Frank Wood"], "abstract": "We propose a mechanism for diffusion generalization based on local denoising operations. Through analysis of network and empirical denoisers, we identify local inductive biases in diffusion models. We demonstrate that local denoising operations can be used to approximate the optimal diffusion denoiser. Using a collection of patch-based, local empirical denoisers, we construct a denoiser which approximates the generalization behaviour of diffusion model denoisers over forward and reverse diffusion processes.", "sections": [{"title": "Introduction", "content": "Diffusion models [17, 6, 18] have been widely adopted and are the de facto standard for modelling image [14] and video [5] data due to their high sample quality and generalization abilities. With sufficient data, diffusion models produce samples which are distributionally similar to their training set, but are not exact copies of training data [21]."}, {"title": "Related Work", "content": "Diffusion generalization Several prior works have studied diffusion generalization. Comparing a variety of networks, [21] finds diffusion models produce consistent samples despite differences in architecture and training. Both [11, 19] find that diffusion models only deviate from empirical denoisers for intermediate \u03c3. Further, [11] identify that errors in this region are primarily responsible for diffusion generalization. Similarly, [20] attributes diffusion generalization to \"slight differences\" between the network and empirical denoisers. [7] suggests that generalization stems from adaptive bases found in the eigenspace of diffusion models. However, they do not consider how trained models deviate from empirical denoisers. Similar to our work, Closed-form diffusion models [16] produces a mechanism for diffusion generalization by intentionally biasing the empirical denoiser with a spectral bias [13]. However, they do not validate this inductive bias choice by studying network denoisers."}, {"title": "Background", "content": "The basis of diffusion models is the diffusion process in which Gaussian noise is gradually added to a data distribution p(x), x \u2208 Rd in a so-called forward process. At any point t \u2208 (0,T], the diffusion process defines a marginal latent variable distribution pt(z) = \u222b pt(z|x)p(x)dx, z \u2208 Rd where pt(z|x) = \\mathcal{N} (z; s(t)x, \u03c3(t)2I) is the marginalization of the process' transition kernels up to time t. Functions s(t) and o(t) are chosen such that pt(z) \u2248 \u03c0(z) = \\mathcal{N} (z; 0, \u03c3(T)2I). We use the variance exploding formulation [18, 8] with s(t) = 1 and o(t) = t hereafter.\nDiffusion models reproduce the data distribution p(x) through a reverse diffusion process which is constructed to match the marginal latent distributions pt(z) for all t. The probability flow ODE [18, 8] is one way of describing this reverse diffusion process\n$\\frac{dz}{dt}$ = -t\u2207z log pt (z)dt.\nTo draw samples from p(x), diffusion models integrate Eq. (1), from t = T to 0, with initial value z ~ \u03c0(z) using numerical integration. Critically, this sampling procedure requires repeated estimation of the score function \u2207z log pt (z) which has the form\n\u2207z log pt (z) = $\\frac{E [xz,t] - z}{t^{2}}$\nFrom Eq. (2), estimating the score can be reduced to estimating the posterior mean E [xz, t], an operation referred to a denoising. In practice, the analytic form of p(x) is generally unknown, which prevents exact computation of the posterior pt (x|z) and therefore E [x|z, t]. Instead, diffusion models use deep neural networks to approximate the score function. Using an empirical data distribution Pdata(x) =$\\frac{1}{N}$  \u2211 x() ED \u03b4 (x \u2013 x(i)), with dataset D = {x(1), ..., x(N) | x(i) ~ p(x)}, diffusion models optimize a neural network denoiser De(z, t) by minimizing\n$\\min_{\u03b8}$ = E$\\left[x\\sim p_{data}(x), z\\sim p_{t}(z|x),t\\sim p(t) \\left[||x - D_{\u03b8}(z, t)||^{2}\\right]\\right]$\nThe minimizer of Eq. (3) is the empirical posterior mean which we also term the empirical denoiser\nE[x(i) z,t) =$\\sum_{x^{(i)}\\in D}P_{t}(x^{(i)}|z)x^{(i)}, P_{t}(x^{(i)}|z) = \\frac{p_{t}(z|x^{(i)})}{\\sum_{x^{(j)}\\in D}p_{t}(z|x^{(j)})}.$"}, {"title": "Inductive Biases of Network Denoisers", "content": "To understand the generalization of diffusion models, we must understand and characterize network denoiser approximation errors. To begin, we simply compare the denoiser outputs of three near SOTA diffusion models trained on CIFAR-10 [10] to the empirical denoiser of that dataset. We evaluate models parameterized by NCSN++ [18, 8], DDPM++[18, 8] and DiT [12] architectures over 150 values of \u03c3\u2208 [0.01, 100], drawing 10,000 z samples from the forward process for each o value.\nFigure 2 plots the mean squared error (MSE) between network and empirical denoisers. We observe that across all architectures, denoisers have low bias for both small and large values of o but substantial bias for \u03c3\u2208 [0.3, 10]. This region corresponds with the results of [11] who found that diffusion generalization can be attributed to this intermediate region.\nVisualizations of the denoiser outputs are presented in the right portion of Fig. 2. We note that only the middle o = 3 row has significant differences between the empirical and network denoisers. At this noise level, we observe that all three networks make qualitatively similar approximation errors, despite differences between the transformer architecture of DiT and the convolutional U-Net architectures of DDPM++ and NCSCN++. That denoiser outputs appear independent to network architecture suggests that diffusion model approximation errors are not random optimization artifacts, but the result of a shared inductive bias unrelated to the neural network architecture. This would also support the findings of [20] \u2013 that diffusion models produce similar samples when with the same z ~ \u03c0(z) despite changes in network architecture, training, or diffusion hyperparameters.\nWe next attempt to identify common diffusion inductive biases by comparing network and empirical denoisers' responses to input transformations. Figure 3 visualizes DDPM++ [18, 8] and empirical denoiser outputs after transforming the original z ~ pt(z|x). We observe that small changes to z can result in substantially different empirical posterior means. In contrast, the network outputs are remarkably consistent. In four of five cases, network denoisers still produce a red vehicle, including a near-identical car in response to the y-translation. In general, local changes in input produce local changes in the network denoiser output. For example, by replacing the contents of the black square with random noise, the network \u201cdeletes\" the red car from the image while maintaining the background structure.\nFigure 3, provides preliminary evidence that network denoisers are predominantly locally sensitive to changes in z, while the empirical denoiser is globally sensitive to any such changes. This global sensitivity is justified by Eq. (4). Since pt(x(i) z) x pt(z|x(i)) and pt(z|x(i)) is Gaussian, the posterior probability of any x(i) is related to the l2 distance between x(i) and z and therefore, the individual values of every pixel of z.\nWe further investigate the local inductive bias of network denoisers by measuring the sensitivity of the DDPM++ denoiser to each input pixel through |\u2207zDe(z,t)x,y| - the absolute gradient of the network denoiser output at pixel (x, y) with respect to the input z. In Fig. 4, we evaluate the network"}, {"title": "Patch Posterior Denoising", "content": "Section 4 presents strong evidence that diffusion models generalize through local inductive bias, irrespective of network architecture. However, Fig. 2 also shows that network denoisers accurately estimate the empirical posterior mean for small and large values of o, despite the inherent global sensitivity of this quantity. To resolve this apparent contradiction, we hypothesize that diffusion models perform local operations whose combined result is generally equivalent to empirical denoising.\nSpecifically, we propose that diffusion models generalize through a local denoising operation. We can approximate such an operation with patch posterior denoising \u2013 estimating the empirical posterior mean of a cropped patch of the input. Formally, let Cx,y,p \u2208 {0,1}3p\u00b2\u00d7d be a specific cropping matrix such that Cx,y,px(i) is the p\u00d7 p patch of x(i) with upper left corner at pixel (x, y). For a patch size p, let Cp = {Cx,y,p|x \u2208 {1, . . ., 32 \u2013 p} ,y \u2208 {1, . . ., 32 \u2013 p}} be the set of all such cropping matrices. Then, for any such cropping matrix C \u2208 Cp, which produces patches x(i) = Cx(i) and zc = Cz, we define the patch posterior mean with pt(zc | x) = \\mathcal{N}(zc; xe, \u03c3(t)2I) as\nE[x\\mid z_{c},t] = \\sum_{x^{(i)}\\in D}P_{t}(x^{(i)}|z_{c})x^{(i)}, P_{t}(x^{(i)}|z_{c}) = \\frac{p_{t}(z_{c}|x^{(i)})}{\\sum_{x^{(j)}\\in D}p_{t}(z_{c}|x^{(j)})}.\nWe have hypothesized that denoisers perform local operations which are equivalent to global posterior mean estimation. However, in general, E[x | zc,t] \u2260 CE[x(i) | z, t] because pt(x) | zc) \u2260 Pt(x(i) | z). Why then would we expect network denoisers to use local posterior mean estimates to estimate the global posterior mean?"}, {"title": "Conclusions", "content": "Our work identifies a mechanism for the generalization behaviour of diffusion models through local denoising. We find network denoisers exhibit a local inductive bias whose strength is anti-correlated with \u03c3. We outline how diffusion models can accurately estimate the empirical denoiser during training using local denoising operations. Using a patch-based approximation of these local operations we produce a composite denoiser which is a better estimator of network denoisers than the empirical denoiser, even when network denoisers exhibit generalization. Unfortunately, our composite is a crude approximation to the flexibility of deep neural networks. Integrating Eq. (1) using our patch-based composite does not produce realistic samples, as artifacts from the independent denoisers at each step compound to produce unrealistic samples. In future work, we aim to improve the quality of our composite by dynamically selecting patch size, or by using non-square local denoisers."}]}