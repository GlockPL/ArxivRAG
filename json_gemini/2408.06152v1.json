{"title": "Palant\u00edr: Towards Efficient Super Resolution for\nUltra-high-definition Live Streaming", "authors": ["Xinqi Jin", "Zhui Zhu", "Xikai Sun", "Fan Dang", "Jiangchuan Liu", "Jingao Xu", "Kebin Liu", "Xinlei Chen", "Yunhao Liu"], "abstract": "Neural enhancement through super-resolution (SR) deep\nneural networks (DNNs) opens up new possibilities for ultra-\nhigh-definition live streaming over existing encoding and\nnetworking infrastructure. Yet, the heavy SR DNN infer-\nence overhead leads to severe deployment challenges. To\nreduce the overhead, existing systems propose to apply DNN-\nbased SR only on selected anchor frames while upscaling\nnon-anchor frames via the lightweight reusing-based SR ap-\nproach. However, frame-level scheduling is coarse-grained\nand fails to deliver optimal efficiency. In this work, we pro-\npose Palant\u00edr, the first neural-enhanced UHD live streaming\nsystem with fine-grained patch-level scheduling. In the pre-\nsented solutions, two novel techniques are incorporated to\nmake good scheduling decisions for inference overhead opti-\nmization and reduce the scheduling latency. Firstly, under the\nguidance of our pioneering and theoretical analysis, Palant\u00edr\nconstructs a directed acyclic graph (DAG) for lightweight yet\naccurate quality estimation under any possible anchor patch\nset. Secondly, to further optimize the scheduling latency,\nPalant\u00edr improves parallelizability by refactoring the compu-\ntation subprocedure of the estimation process into a sparse\nmatrix-matrix multiplication operation. The evaluation re-\nsults suggest that Palant\u00edr incurs a negligible scheduling\nlatency accounting for less than 5.7% of the end-to-end la-\ntency requirement. When compared to the state-of-the-art\nreal-time frame-level scheduling strategy, Palant\u00edr reduces\nthe energy overhead of SR-integrated mobile clients by 38.1%\nat most (and 22.4% on average) and the monetary costs of\ncloud-based SR by 80.1% at most (and 38.4% on average). The\nsource code is available at https://palantir-sr.github.io.", "sections": [{"title": "1 INTRODUCTION", "content": "Ultra-high-definition (UHD) videos such as 4K and 8K videos\nare expected to form a huge market worth more than $1 tril-\nlion in the following few years [18]. More and more UHD live-\nstreaming applications are deployed to revolutionize many\naspects of our society. For example, the UHD live streaming\nof major sports events such as the Olympics [24, 25] creates\nunprecedentedly immersive experiences for audiences. Be-\nsides, with the real-time UHD video from inspection and\nsurveillance cameras, human operators can have a precise\nunderstanding of the spot and remotely take immediate ac-\ntions to prevent emergent accidents [13, 17].\nHowever, the bitrates of the encoded UHD videos are sig-\nnificantly larger than videos of lower resolutions and pose\ngreat challenges to existing network infrastructure. Specifi-\ncally, the bitrates of 4K videos can be as large as 45Mbps [21],\nwhile the worldwide average uplink bandwidth of mobile\nbroadband networks is only 11.07 Mbps [34]. A common\nsolution to this problem is using dedicated hardware en-\ncoders [8, 25, 28], which can encode the UHD video more effi-\nciently and provide much lower bitrates. However, hardware\nencoders are very expensive and typically cost hundreds\nto thousands of dollars. Using fixed broadband networks\nfor the uplink is an alternative solution, but it inevitably af-\nfects mobility and prohibits applications such as drone-based\ninspection [17, 37].\nRecently, neural enhancement has been proposed [11, 42,\n44] and deployed [14, 27, 32, 45] to improve video streaming.\nIt can potentially boost the broad deployment of UHD live\nstreaming by allowing the streaming source to stream only\na low-bitrate low-resolution (LR) video over the bandwidth-\nlimited uplink and using a super-resolution (SR) deep neural"}, {"title": "2 BACKGROUND", "content": "2.1 Primer on SR Streaming\nSR DNNs typically incorporate convolution layers and mod-\nules specially designed for upscaling (e.g., deconvolution [15],\npixel shuffle [36], etc). We refer readers to [10] for further\ndetails of the SR DNNs.\nCurrently, there are two common deployment models for\nSR enhancement. One is to execute the SR DNN inference on\nthe mobile streaming clients [14, 27, 32, 45], and the other\nis to execute the SR DNN on a cloud server so that a lot\nof audience for the same video can benefit from the one-\ntime server-side enhancement [44]. Yet, SR DNNs are of\nhigh computation complexity and lead to severe deployment\nchallenges in both deployment models. In the first model, the\nbattery of mobile clients can be easily drained. Consequently,\nMicrosoft Edge VSR disables its SR feature when the device\nis not being charged [32]. As for the second model, the heavy\ninference overhead appears in the form of the high monetary\ncost of using cloud servers (estimated to be at least $1.690 per\nhour per 4K stream [44]). Lowering the overhead is essential\nto a broader application of SR enhancement.\n2.2 Reusing-based SR\nTo enable low-cost SR enhancement, researchers have built\nthe NEMO [42] system, where an SR-enhanced decoder is\nadopted to reduce the cost by using video temporal redun-\ndancy. In the SR decoder, video frames are categorically di-\nvided: anchor frames are upscaled via DNN-based SR, while\nnon-anchor frames are quickly upscaled via reusing-based\nSR. To appreciate the intricacies of reusing, a basic under-\nstanding of video codecs is essential. Video coding predomi-\nnantly encodes a block through inter coding; it identifies a\nsimilar reference block from a prior frame and only stores\nthe subtle difference or residual between the two blocks.A\nreference index is retained in the coded video to identify the\nframe containing the reference block or the reference frame,\nwhile a motion vector is stored to represent the potential\nspatial offset between the current and reference blocks (ow-\ning to object movements or camera shifts). To decode an\ninter-coded block $b_{\\text{inter}}$ (i.e., \u2117 in Fig. 1), the decoder first\nparses the reference index to determine its reference frame\n(\u2117) from the decoded frame buffer and then parses the mo-\ntion vector (\u2461) to determine its reference block $b_{\\text{inter.ref}}$\n(\u2462). The reference block is added to the decoded residual\n$b_{\\text{inter.res}}$ (\u2463). This can be formally expressed as\n$b_{\\text{inter}} = b_{\\text{inter.ref}} + b_{\\text{inter.res}}.$"}, {"title": "3 SYSTEM OVERVIEW", "content": "Scope. We aim to support UHD live streaming via SR en-\nhancement. As video frames are highly redundant, we pro-\npose to apply DNN-based SR only on carefully chosen an-\nchor patches while upscaling non-anchor patches via the\nlightweight reusing-based SR mechanism. This optimization\nis essential to improve the practicality of SR enhancement,\nconsidering the effect of SR inference on the battery life of\nmobile clients and the monetary costs of cloud-based SR\ninference.\nDesign goals. First, Palant\u00edr aims to pinpoint the most\nbeneficial anchor patches, so that it can use a small anchor\npatch set to reduce the DNN inference cost while achieving a\nlarge quality gain. Second, Palant\u00edr should complete the fine-\ngrained scheduling as quickly as possible, considering the\nstringent latency requirements in many video applications [9,\n16, 20, 37].\nWorkflow. The workflow of Palant\u00edr is shown in Fig. 3.\nConsidering the limited uplink bandwidth [34] and the high\nbitrate of the original high-resolution (HR) video [21], the\nstreamer only uploads the downsampled LR video to the me-\ndia server. The server generates an SR error DAG (Sec. 4.3)\nfor every LR video segment whose time duration equals the\npre-defined scheduling interval. The quality of the corre-\nsponding SR segment under any possible anchor patch set\ncan be quickly estimated using the constructed DAG, and ben-\neficial anchor patches are greedily searched via DAG-based\nquality estimation. Two novel parallelism strategies are used\nto further accelerate the searching process without changing\nits results (Sec. 5). A cache profile is then created, every bit\nof which indicates whether a patch in the LR segment is an\nanchor or non-anchor. In the existence of a powerful cloud\nserver [44], both the LR segment and its corresponding cache\nprofile are streamed to the server and then processed by the\nSR decoder on the server. Or, alternatively, the SR decoder\ncan be executed in the streaming client to perform cache\nprofile-guided SR enhancement.\nDeployment Scenario. Palant\u00edr is designed for UHD live\nstreaming but also supports videos of lower resolutions and\nvideo-on-demand services. Our initial prototype is tailored\nfor the VP9 codec, considering the engineering complexi-\nties involved in transitioning to other codecs. However, the\nsystem is not restricted to VP9-specific functionalities and\nshould be adaptable to a range of other codecs."}, {"title": "4 DAG-BASED QUALITY ESTIMATION", "content": "We first identify the problems with existing quality esti-\nmation methods. To design a fine-grained and lightweight\nestimation method, we give a pioneering analysis of the SR\nerror propagation process. Based on our analysis, we propose"}, {"title": "4.1 Problems with Existing Methods", "content": "A natural way to estimate the video quality under a given\nanchor patch set is to extend the methods used in NEMO or\nNeuroScaler. The strategy in NEMO is based on the obser-\nvation that the quality gain of a frame is mostly determined\nby the most relevant anchor frame. NEMO first enumerates\nevery anchor frame set consisting of a single frame f and\nmeasures the quality (denoted as $FQ(i|f)$) of every frame i\nunder every enumerated single anchor frame set |f|. Then,\nNEMO estimates the quality under any anchor frame set AP\nas $FQ(i|AP) \u2248 \\text{max}_{f\u2208AP}FQ(i|f)$. Capitalized on the heuris-\ntics, NEMO requires a heavy measurement phase in nature\nand incurs a high latency (reported to be 59.6 seconds for a\nvideo segment of 4 seconds [42]) not suitable for live stream-\ning. The scheme can be easily extended to the patch-level\ngranularity by firstly conducting measurements for all single\nanchor patch sets, but the latency of initial measurements\ncan be further increased.\nIn contrast, the method in NeuroScaler [44] is much more\nefficient. It models the super-resolution error propagation\nprocess as a linked list, where each node corresponds to a\nframe and each pair of consecutive frames is linked. The SR\nerror of an anchor frame is assumed to be 0, while the error\nof a non-anchor frame equals that of its preceding frame\nnode plus the residual between the two frames. An anchor\nset that leads to a lower sum of the errors over all frame\nnodes is regarded as leading to higher video quality.\nHowever, such a modeling is too simplified and ignores the\neffect of the degree of reference. In fact, each frame can have\nat most three reference frames in VP9 [22], and its SR error\ndirectly depends on the error of every reference frame rather\nthan that of a single preceding frame. Conversely, some types\nof frames (i.e., keyframes and alternative reference frames in\nthe VP9 codec [22]) may be referred to by many subsequent\nframes (rather than a single subsequent frame, as modeled by\nNeuroScaler). To compensate for over-simplified modeling,\nNeuroScaler gives priorities to keyframes and alternative ref-\nerence frames: a normal frame may be selected as the anchor\nonly if all the keyframes and alternative reference frames\n(AltRefs) have been selected as anchors. Yet, transferring\nthe linked list-based modeling and the heuristic mitigation\nstrategy to our context faces several challenges:\n\u2022 First, a patch can refer to a huge number of preceding\npatches, so it will be even more unreasonable if we model\nthe SR error propagation process as multiple independent\nlinked lists of patch nodes for fine-grained scheduling.\nDenoting the number of rows in the patch grid as $n_r$ and"}, {"title": "4.2 Understanding SR Error Propagation", "content": "We next give an analysis of the SR error propagation pro-\ncess, which lays the foundation for our DAG-based quality\nestimation.\n\u2022 Case #1: non-anchor patches."}, {"title": "4.3 DAG Construction", "content": "According to the Conclusion #3, the SR error of a non-\nanchor patch is the weighted sum of those of its depending\npatch plus its texture complexity. A patch P may depend\non another patch Pi for inter-coding only if the frame con-\ntaining Pi is a reference frame of the frame containing the"}, {"title": "5 PARALLEL SEARCHING", "content": "5.1 Performance Analysis\nWe employ a greedy searching algorithm to iteratively select\nanchor patches based on the estimated quality. We refer to\nthe sequential implementation of this method as the vanilla\nPalant\u00edr. Specifically, the estimation processes for different\nanchor patch sets are executed sequentially, and the error\nattributes for different patch nodes under a given anchor\npatch set are also computed sequentially. As demonstrated"}, {"title": "5.2 Parallelism Solution", "content": "We propose a novel strategy to enable parallel searching in\nPalant\u00edr. The parallelized Palant\u00edr can generate the same an-\nchor patch set as the vanilla Palant\u00edr as its parallelism mech-\nanism does not hurt the correctness of the computation. As\ndemonstrated later in Sec. 6.3 and 6.4, the parallelized Palan-\nt\u00edr improves the DAG-based selection latency by more than\n200 times and meets the two design goals simultaneously."}, {"title": "6 EVALUATION", "content": "We evaluate Palant\u00edr by answering three questions:\n\u2022 Does Palant\u00edr achieve the first design goal of selecting a\nbeneficial anchor patch set and improving the efficiency\nof neural-enhanced UHD live streaming?"}, {"title": "6.1 Experimental Setup", "content": "Implementation. We develop our decoder based on the\nopen-source SR decoder in NEMO [42]. We incorporate two\nnovel modes into the decoder. The first is to obtain the data\nrequired for graph construction (as introduced in Sec. 4.3).\nThe second is to take both an LR video and a corresponding\ncache profile as input, and then upscale patches by either SR\nDNNs or reusing-based SR based on the cache profile.\nHardware. We use a server with a 16-core AMD Ryzen\nprocessor as our media server, where graph construction and\nanchor selection are performed. The scheduling latency is\nmeasured on the server. We use a Xiaomi 12S smartphone,\nwhich was announced in July 2022 and equipped with the\nQualcomm Snapdragon 8+ Gen 1 Mobile Platform, to mea-\nsure the energy efficiency when running SR DNN inference\non mobile receiver devices.\nVideo. We download six popular 4k@30fps videos from\nYouTube. To demonstrate the universality of Palant\u00edr, the\nvideos contain six distinct categories, including makeup review,\ncomputer gaming, skit, shopping, car review, and unboxing.\nWe use FFmpeg (v3.4) [4] to transcode the HR video into the\n480p (854 \u00d7 480) LR version in real time. We follow encod-\ning guidelines to set the bitrate to 1800 kbps, the encoding\nspeed to 5 [2], and the group of pictures (GoP) to 60 frames\n(i.e., 2 seconds) [40]. We use the -auto-alt-ref option in\nFFmpeg to enable the alternative reference frame feature\nrequired by the anchor selection algorithm in NeuroScaler.\nUnless noted otherwise, We use the first five minutes of each\nvideo in our evaluation.\nSR DNN. We adopt the DNN model of NAS [43]. We empir-\nically set the number of residual blocks to 8 and the number\nof filters to 48. The DNN upscales the resolution of the LR\nvideo by 4 times. As the feasibility of online training for live\nstreaming has been demonstrated [29], we train the DNN\nmodel for each benchmark video. When comparing the per-\nformance of different methods on the same video, the same\nDNN model is used for fairness.\nAnchor patch size. We use a patch size of 170 \u00d7 160 to\ncompensate for energy efficiency and latency. Consequently,\neach LR frame consists of 15 patches.\nBaselines. We use two baselines in this part. The first\nis the NeuroScaler baseline, which uses the algorithm in\nNeuroScaler to select the anchor frame set. The second is\nthe Key+Uniform baseline, which selects all the patches in"}, {"title": "6.2 Anchor Effectiveness", "content": "Quality Gain. We compute the peak-signal-to-noise-ration\n(PSNR) between the SR video and the original HR video to\nquantify the effectiveness of an anchor set. To make a fair\ncomparison, we keep the total size of the anchor regions\nselected by different methods the same. In other words, we\ncompare the quality gain under the m-ary anchor frame set\nselected by the NeuroScaler baseline with that under the\n(15 \u22c5 m)-ary anchor patch set selected by Palant\u00edr or the\nKey+Uniform baseline. We empirically limit m to not be\ngreater than 3 since: (1) m = 3 can deliver quality gains that\nare comparable to the setting of applying DNN-based SR on\nall frames; (2) further increasing the value of m leads to a\nlimited benefit yet a significant overhead.\nAs shown in Fig. 8, our system consistently outperforms\nthe two baselines with its ability to identify beneficial patches."}, {"title": "6.3 Scheduling Latency", "content": "End-to-end (E2E) latency is an important metric in live stream-\ning [9, 16, 20, 37]. To ensure that the live streaming latency\ncan be lower than the GoP, modern streaming standards such\nas CMAF [26] allow a chunk (which can be part of a GoP) to\nbe immediately packaged (i.e., chunked packaging [12]) and\ndelivered (i.e., chunked delivery [12]) when ready. Here we\ndenote the chunk length as n frames and assume the sched-\nuling interval of Palant\u00edr to be equal to n for simplicity. As\nshown in Fig. 11, the streamer contributes new video frames\nat a constant rate. Every new chunk of n frames is contributed\nper time duration of $L_1 = \\frac{n}{\\text{frame_rate}}$. In traditional stream-\ning pipeline without neural enhancement, the new chunk\ncan be immediately packaged and delivered at $t_1$. However,\ntwo additional latency sources are presented in Palant\u00edr, i.e.,\nthe DAG construction latency $L_2$ and the DAG-based anchor\nselection $L_3$. We evaluate whether $L_2 + L_3$ is small enough to\nwell support latency-sensitive UHD applications.\nWe first examine the value of $L_2$. Note that we can directly\nfeed a newly contributed frame to the decoder (working in\nthe first mode introduced in Sec. 6.1) for DAG construction,\nso $L_2$ should be equal to the processing latency of the last\nframe in the scheduling interval if the decoder runs above\n30fps. As shown in Fig. 12, the measured per-frame decoding"}, {"title": "6.4 Ablation Study", "content": "SR error DAG. The key to selecting a beneficial anchor\npatch set is our DAG-based modeling. We use a theoretical\nanalysis to determine the values of the static weight attributes\nof the edges and the static TC attributes of patch nodes\n(see Sec. 4.2 and 4.3). To quantify the importance of setting\nappropriate values, we evaluate with the makeup review\nvideo and compare Palant\u00edr with two variants. In the first\nvariant (Palant\u00edr w/o weight), the only predecessor node of\nthe patch node $P^n_{ij}$ (located at the i-th row and j-th column of\nthe patch grid of the n-th frame) is $P^{n-1}_{ij}$, and the weight of the\nedge connecting them equals 1. However, the TC attributes\nin the first variant are kept the same as in Palant\u00edr. Note that\nthe first variant resembles the NeuroSclaer baseline when the\npatch size equals the frame resolution. In the second variant\n(Palant\u00edr w/o TC), the weight attributes are kept the same as"}, {"title": "7 LIMITATIONS AND FUTURE WORK", "content": "Exploring a smaller patch size. A natural method to\nfurther improve the efficiency of neural enhancement is to\nuse a smaller patch size. However, this method leads to a\nlarger DAG and increases the latency of anchor selection.\nPotential remedies may be pruning the constructed DAG."}, {"title": "8 RELATED WORK", "content": "Model Compression. Model compression has been uti-\nlized in many video super-resolution systems such as Om-\nniLive [35] and Microsoft Edge VSR [32]. Considering the"}, {"title": "9 CONCLUSION", "content": "In this work, we propose Palant\u00edr, the first neural-enhanced\nUHD live streaming system with fine-grained patch-level\nscheduling. Palant\u00edr seeks to improve efficiency via reason-\nable scheduling while minimizing the scheduling latency\nto better support live streaming. Based on our pioneering\nand theoretical analysis, Palant\u00edr adopts DAG-based quality\nestimation to select a beneficial anchor patch set with low\ncomputation cost. The per-frame computation sub-procedure\nof the estimation method is further refactored to facilitate\nparallelization and acceleration and significantly decrease\nthe scheduling latency. The evaluation findings indicate that\nPalant\u00edr effectively optimizes the efficiency of neural en-\nhancement and fits the latency requirement of UHD live\nstreaming."}, {"title": "A APPENDIX", "content": "A.1 Energy Measurement\nHere we explain how we measure the energy overhead un-\nder a given anchor set. We use the Android Debug Bridge\n(adb) over Wi-Fi [3] to execute the decoder in the smart-\nphone's shell. We do not use adb over USB as connecting the\nsmartphone to an external computer via USB automatically\ncharges the smartphone battery and affects the measured\ncurrent value. Our setting adheres mostly to the guidelines\nin [39] for reproducibility, except that the Wi-Fi module is\nturned on for adb. To remove the impact of the display screen,\nnative daemons, and Wi-Fi interfaces in our measurements,\nwe first record the average current $C_1$ before the decoder\nis executed and then record the average current $C_2$ during\nthe execution of the decoder. We also record the duration\nof decoding, T, and compute the energy overhead of neural-\nenhanced decoding as $(C_2 - C_1) \\times T$."}]}