{"title": "DASKT: A Dynamic Affect Simulation Method for Knowledge Tracing", "authors": ["Xinjie Sun", "Kai Zhang", "Qi Liu", "Shuanghong Shen", "Fei Wang", "Yuxiang Guo", "Enhong Chen"], "abstract": "Knowledge Tracing (KT) predicts future performance by modeling students' historical interactions, and understanding students' affective states can enhance the effectiveness of KT, thereby improving the quality of education. Although traditional KT values students' cognition and learning behaviors, efficient evaluation of students' affective states and their application in KT still require further exploration due to the non-affect-oriented nature of the data and budget constraints. To address this issue, we propose a computation-driven approach, Dynamic Affect Simulation Knowledge Tracing (DASKT), to explore the impact of various student affective states (such as frustration, concentration, boredom, and confusion) on their knowledge states. In this model, we first extract affective factors from students' non-affect-oriented behavioral data, then use clustering and spatiotemporal sequence modeling to accurately simulate students' dynamic affect changes when dealing with different problems. Subsequently, we incorporate affect with time-series analysis to improve the model's ability to infer knowledge states over time and space. Extensive experimental results on two public real-world educational datasets show that DASKT can achieve more reasonable knowledge states under the effect of students' affective states. Moreover, DASKT outperforms the most advanced KT methods in predicting student performance. Our research highlights a promising avenue for future KT studies, focusing on achieving high interpretability and accuracy.", "sections": [{"title": "1 INTRODUCTION", "content": "KNOWLEDGE Tracing (KT) is a task that dynamically estimates students' knowledge states (e.g., mastery of Addition, Multiplication) over time, using their previous learning interactions (e.g., responses to a series of exercise questions). This allows for the prediction of student per-formance on the next question [1], [2](illustrated in Figure 1). Known as a foundational task in the field of intelligent education, the wide application of KT in online teaching platforms, interactive learning environments, and intelligent tutoring systems [3] demonstrates its profound academic and practical impact.\nIn recent years, deep neural networks have made rapid progress, and a series of deep learning based knowledge tracing (DLKT) models have emerged, such as deep se-quence KT models based on autoregression [2], [4], [5], [6] to simulate students' complex learning behaviors. To further analyze students' learning trajectories, the field of has introduced attention mechanisms [1], [7], [8], [9]. Graph KT models [4], [10], [11] use knowledge concepts (KCs) and students' learning paths as nodes and edges of the graph to simulate the learning process. To compensate for the weak interpretability of neural networks, more and more researchers have recently incorporated educational theory into their approaches, as evidenced by studies [12], [13], [14], [15], increasing the interpretability of KT. Moreover, using affect detectors for student affect detection and inte-grating high-quality student affect into KT models can en-hance model predictive performance [16]. These innovative methods have significantly promoted the refinement and dynamization of the task.\nAlthough DLKT methods offer a new perspective for solving KT questions, the degree to which students master knowledge states still largely depends directly on student"}, {"title": "2 RELATED WORK", "content": "Accurately simulating the various affect that students ex-hibit during the exercise process, assessing their affect when facing different problems, and effectively integrating these affect with students' knowledge states are undoubtedly tasks of great value. Subsequently, we will introduce related research work from two perspectives: knowledge tracing and affective states recognition methods."}, {"title": "2.1 Konwledge Tracing", "content": "Recently, deep learning technologies have been widely applied to Knowledge Tracing (KT) tasks for modeling students' historical learning and predicting future perfor-mance. Existing DLKT methods can be divided into five categories: C1: Improving the basic structure of the model; C2: Adding problem-solving features; C3: Simulating ed-ucational theory; C4: Based on graph structure; C5: Other networks structure."}, {"title": "2.2 Affective States Recognition Methods", "content": "Affect significantly influences learners' motivation and the learning state [16], [26]. Affective states recognition, a crucial aspect of affect computing, is increasingly accurate with Artificial Intelligence and sensor technology advancements. Educators commonly utilize affect scales to assess learners' affect, while physiological signals such as skin resistance and heart rate serve as reliable indicators [27], [28], [29].\nIn online learning, facial expressions and voice cues help understand students' engagement levels and KC mastery"}, {"title": "3 PRELIMINARY", "content": "In this section, we provide formal definitions of KT and affect computation, involving affective factors. Additionally, we introduce some important embeddings involved in the DASKT framework proposed in this paper. Table 1 summa-rizes the mathematical symbols used in this paper."}, {"title": "3.1 Problem Definition", "content": "In online intelligent tutoring systems, we define the set of students S, the set of problem IDs P, the set of knowledge concepts KC, the set of affect Aff, and the set of students' responses R. The set of students $S = {s_1, s_2,...,s_n}$ includes n distinct students. The problem IDs set $P = {p_1,p_2,...,p_j}$ consists of j distinct problem IDs. Each student can have I(I > 1) records of problem responses, and the same problem can be responded to repeatedly. The knowledge concepts set $KC = {kc_1, kc_2,...,kc_k}$ contains k distinct knowledge concepts, and each problem can be"}, {"title": "3.2 Definition of Affective Factors", "content": "Affect plays multiple roles in the learning process, influ-encing students' learning motivation, cognitive processes, learning experiences, and interactions. In educational prac-tice, paying attention to affect education and students' affective states has significant implications for promoting students' overall development and improving learning out-comes [38], [39]. In light of this, this paper adopts the three affective factors proposed by [40], [41], namely students' confidence, interest, and effort, for analysis."}, {"title": "3.2.1 Students' Confidence", "content": "Confidence can influence their perception of their own abili-ties, thereby shaping their learning attitudes and behaviors. This paper uses the accuracy of KCs and the response time of KCs to simulate the calculation of student confidence. In this study, we were inspired by Classical Test Theory (CTT) [42] and relevant research by Sherbino, et al. [43], so we used prior statistical methods to evaluate the accuracy and response time of KCs. First, the accuracy $A^i_k$ of KC for student $s_i$ and the response time $\\Delta T^i_k$ for each exercise corresponding to a certain time are defined as follows:\n$A^i_k = \\frac{1}{N^i_k}\\sum_{n=1}^{C^i_k} {r^i_{kn} ==1}, \\Delta T^i_k = att^i_{tk}, (1)$\nwhere $C^i_k$ represents the count of the k-th KC for student $s_i$, $r^i_{kn}$ is the label indicating whether the student $s_i$ answered correctly on the k-th KC in their own exercise sequence, and $N^i_k$ is the total occurrence of the k-th KC in the exercise sequence of student $s_i$. $att^i_{tk}$ is the time spent by student $s_i$ answering the k-th KC at the t-th time step. Then, the average accuracy $A_k$ and the average response time $\\Delta T_k$ of the KCs for all students are defined as follows:\n$A_k = \\frac{1}{N_k}\\sum_{i=1}^{|s_n|} A^i_k, \\Delta T_k = \\frac{1}{N_k}\\sum_{i=1}^{|s_n|} \\Delta T^i_k (2)$\nwhere $|s_n|$ represents the size of the student set, and $N_k$ is the total occurrence of the k-th KC. Finally, the confidence of student $s_i$ is defined as:\n$Conf^{s_i} = concat(\\sum_{k=1}^{KC} (A^i_k - A_k), \\sum_{k=1}^{KC} (\\Delta T^i_k - \\Delta T_k)), (3)$\nwhere $KC$ represents the total number of KCs contained in the dataset. $concat(\\cdot)$ is a concatenation function."}, {"title": "3.2.2 Students' Interest", "content": "Interest is an important source of learning motivation and it can enhance the cognitive process of learners. Inspired by [44], this paper uses the length of students' exercise sequences to simulate interest and defines students' par-ticipation rate in the intelligent tutoring system based on these sequences. The simulated students' participation rate remains consistent with the participation rate of the students before being segmented, which is defined as follows:\n$PR^{s_i} = \\frac{els_i}{t_e-t_s} (4)$\nwhere $els_i$ is the set of the exercise sequence for student $s_i$. $t_e$ and $t_s$ represent the start and end time of the student $s_i$'s exercise, respectively. The average participation rate of all students is defined as follows:\n$PR = \\frac{1}{|s_n|}\\sum_{i=1}^{|s_n|} PR^{s_i} (5)$\nwhere $|s_n|$ is the set of all students. Therefore, the interest of student $s_i$ is defined as follows:\n$Inter^{s_i} = PR^{s_i} - PR. (6)$"}, {"title": "3.2.3 Students' Effort", "content": "Effort directly impacts their learning performance. Through diligent study, students cultivate the ability to solve prob-lems and overcome difficulties. Inspired by [45], we use the number of attempts and the interval between questions for different KCs as indicators to calculate effort. The number of attempts at KCs at different time steps $Att^i_k$ and the average number of attempts at this KC by all students $Att_k$ are defined as follows:\n$Att^i = \\sum_{t=1}^{els_i} att^i_k, Att_k = \\frac{1}{|s_n|}\\sum_{i=1}^{|s_n|} Att^{s_i} (7)$\nwhere $att^i_k$ is the number of attempts by student $s_i$ at KC of k at time step t. The interval between the previous problem and the next problem in the exercise sequence of student $s_i$, $IT^{s_i}$, and the average answer time interval of all students, $IT$, are defined as follows:\n$IT^{s_i} = \\sum_{t=1}^{els_i} p_t - p_{t-1}, IT = \\frac{1}{|s_n|}\\sum_{i=1}^{|s_n|} IT^{s_i}, (8)$\nwhere $p_t$ represents the starting time of the problem at time t for student $s_i$, and $p_{t-1}$ denotes the starting time of the problem at time t \u2013 1 for the same student $s_i$. Consequently, the effort exerted by student $s_i$ can be defined as follows:\n$Eff^{s_i} = concat(\\sum_{k=1}^{KC} (Att - Att_k), IT^{s_i} - IT). (9)$"}, {"title": "3.3 Embeddings", "content": "Before delving into the details of the DASKT structure, we can first provide a brief overview of the basic embeddings in DASKT, which will help better understand how DASKT operates internally."}, {"title": "3.3.1 Problem IDs, KCs and Responses Embeddings", "content": "In the DASKT model, the basic elements include Problem ID, KC, and Student Response. Specifically, we use an em-bedding matrix $P \\in \\mathbb{R}^{j\\times d_p}$ (where $d_p$ is the embedding size and j is the number of all different problems) to represent the IDs of all problems answered by students. On the other hand, we use an embedding matrix $KC \\in \\mathbb{R}^{k\\times d_k}$ (where $d_k$ is the embedding size and k is the number of all different knowledge concepts) to represent all knowledge concepts associated with the problems. In addition, we use $R \\in \\mathbb{R}^{2\\times d_r}$ (where $d_r$ is the embedding size and 2 is the number of types of answers, with 1 representing a correct answer to the problem and 0 representing a wrong answer) to represent the responses of students."}, {"title": "3.3.2 Affect Embedding", "content": "Affect is an important variable in the model proposed in this paper, and its embedding matrix is represented as $Aff \\in \\mathbb{R}^{4\\times d_{aff}}$ ($d_{aff}$ is the embedding size and 4 is the number of states of affect). Affect is summarized into these four states based on the phenomena often exhibited by students in online intelligent tutoring systems: frustration, concentration, boredom, and confusion."}, {"title": "4 THE DASKT FRAMEWORK", "content": "In this section, we will provide a detailed introduction to the DASKT framework proposed in this paper. The framework consists of three parts, as shown in Figure 2. First, we mine the training set to count the affective factors such as confidence, interest, and effort in affective factors, initially forming the mining affective factors module (MAF), as shown in Figure 2 (a). We then perform cluster learning on the affective factors and interval-based affect calculation (ICA) for the training and test sets based on the cluster centers, as shown in Figure 2 (b). Finally, we use the graph attention network for dynamic affect simulation and apply the learned affect to the KT task under the effect of affect (DASE), as shown in Figure 2 (c). Subsequently, we will pro-vide a more detailed introduction to these three modules."}, {"title": "4.1 MAF: Mining Affective Factors", "content": "Different affect of students towards learning directly af-fect their learning outcomes. Positive affect can stimulate learning motivation, regulate cognitive processes, improve memory levels, and deepen understanding of knowledge [46], [47]. Negative affect, on the other hand, can reduce"}, {"title": "4.2 ICA: Interval Computation of Affect", "content": "After obtaining the affective factors AF, it is necessary to identify the affective states for different students. This paper uses clustering to find the clustering centers of affective states in the training set, in order to calculate the four different affect clustering centers. The K-means algorithm [50] is used in this paper to calculate the affect clustering centers. $Aff^c_j$ is the randomly selected affect clustering center, $AF^c$ is the clustering set where all student affect in the training set are located, and $Aff^e$ is the new clustering center set. The calculation process is as follows:\n$Aff^c_j = rand(AF[:|C|]), AF^c = [argmin(\\sum_i(AF - Aff^c_j)^2)], (11)$\n$Af f^e_i = \\frac{\\sum_{j=1}^{|c|} AF^{c_i}}{|C|}, (12)$\nwhere C is the number of affect clusters, rand() is a random function, argmin(\u00b7) is a minimum function. Aff is the j-th cluster center. n represents the number of data in this affective state, and AF represents the sum of all data in the i-th affective state.\nThe affective states of students cannot be constant throughout the exercise sequence process. Different stages show different affective states, which is more in line with the real affect expression of students. Inspired by Minn, et al. [5] on the dynamic interval assessment of student abilities, in order to evaluate the affective states of students in stages, we adopted a method based on time intervals. The time interval, denoted as $L_{seg}$, is defined as a seg-ment that contains the number of times a student answers questions within the system. Before the next time interval begins, based on the evaluation of the student's previous performance history, the student's affect are evaluated for each time interval through clustering, as shown in figure 3. Because many KCs are included in the student's exercise sequence, after each KC is processed by the MAF module, the vector size becomes three times the original, which will consume a lot of computational memory. By dividing each student's attempt sequence into multiple time intervals and only evaluating the affect situation of the KCs in the seg-ment each time, this can reduce the computational burden and optimize memory space allocation in order to more effectively learn the entire long sequence, resulting in $AF_{seg}$. Furthermore, after each time interval, the student's affective states $AF_{seg}$ is reassessed to prepare for the next step of dynamically assessing the student's affect. The specific calculation method is as follows:\n$N = \\frac{Af^{s_i}}{L_{seg}}, AFS = {MAF(AF^{s_i}_1), MAF(AF^{s_i}_2),...,MAF(AF^{s_i}_N)},$\n$AF_{seg} = ((\\underset{\\underset{i}{\\small{argmin}}}{((AFS-Aff)^2)}_i)_{seg=1})^{|s_n|},$"}, {"title": "4.3 DASE: Dynamic Affect Simulation Effect", "content": "The affective states of students have been assessed intermit-tently through the ICA module. However, through relevant psychological research, it is found that changes in affect are always fluctuating and coherent, and there is a strong correlation between recent affective states [51], [52], [53]. Although intermittent affect assessment has to some extent simulated the fluctuations of student affect, how to effec-tively simulate the coherence of student affect still needs to be further resolved. This paper proposes the dynamic affect simulation module, which can effectively simulate the continuity of human affect changes. Specifically, we first bind the affect evaluated by the ICA module with the corresponding problems in the learning exercise process, dynamically learning the changes in student affect as the"}, {"title": "4.4 Prediction and Objective Function", "content": "Since we have obtained the knowledge status $h_t$ of the student at the current time step t under the affective states through the DASE network, we fuse the problem $p_{t+1}$ and KC of $kc_{t+1}$ at time step t + 1 to enhance the representation of the student's application of learned knowledge under the affect boost. The formula is as follows:\n$Y_t = p_{t+1} \\oplus kc_{t+1} \\oplus h_t,$\n$Y_{t+1} = \\sigma(W_tY_t + b_t), (17)$\nwhere $w_t \\in \\mathbb{R}^{1\\times(d_p+d_k+d)}$ is a learnable weight parameter, $b \\in \\mathbb{R}^{1}$ is a bias term, and $\\sigma(\\cdot)$ is a sigmoid nonlinear activation function.\nTo train all the parameters in the DASKT framework, we use the cross-entropy log loss between the framework prediction value $y$ and the correctness of the student's answer to the question r as the objective function:\n$L(\\Theta) = -\\sum_{t=1}^T (r_t \\cdot log(y_t) + (1-r_t)\\cdot log(1-y_t)) + \\lambda_\\theta||\\Theta||^2, (18)$\nwhere $\\Theta$ represents all the parameters of the DASKT frame-work, and $A\\theta$ represents the regularization hyperparameter. The Adam optimizer is used to minimize the objective function. The experimental part will elaborate on the details of other settings more detailedly."}, {"title": "5 EXPERIMENTS", "content": "In this section, we first introduce the real datasets used in the experiment, then detail the training process and baseline models. Then, we compare the results of the baseline models and the model proposed in this paper in predicting stu-dents' future performance. In addition, to better display the DASKT model, we answer the following research questions:\nRQ1 Does the affect simulation calculation method we propose have accuracy and reliability?\nRQ2 Does the DASKT model we propose have good performance in predicting students' performance?\nRQ3 Does the DASKT model we propose maintain the consistency of the students' constantly changing knowledge states and affect journey?\nRQ4 How do the affective factors, interval affect computation, and dynamic affect state in DASKT affect the knowledge tracing results?\nRQ5 How does affect impact the performance of the DASKT model?"}, {"title": "5.1 Datasets", "content": "For the calculation of affect simulation, this paper needs students' behavior such as problem IDs, KCs, answer time, interval time between answers, the number of attempts for each exercise, and other related attributes that can be calculated based on the answer situation. To our knowledge,"}, {"title": "5.2 Experimental Setup", "content": "In our experiments, we filtered out records with empty \"problem ID\" or \"KC\u201d fields and sorted the remaining data accordingly. For the ASSISTchall dataset, sorting was based on the \"startTime\" field, while for the ASSIST2012 dataset, sorting was based on the \"start_time\" field. All model parameters were randomly initialized during training. For all datasets, we performed standard 5-fold cross-validation for all models. In each fold, 80% of the student data was split into a training set (80%) and a validation set (20%), with the remaining 20% used as the test set. To ensure fairness, we fine-tuned all comparison algorithms to achieve optimal"}, {"title": "5.3 Benchmark Methods", "content": "To evaluate the effectiveness of DASKT, we compare it against 12 different baseline methods. All baseline methods use the same training, validation, and test sets as this paper. In our experiments, we strictly adhere to the recommended parameters from the original papers or publicly available implementations of each algorithm. To ensure fairness, we fine-tune the parameters of all comparison algorithms to achieve their optimal performance on our experimental datasets. Our comparative analysis is based on four per-formance metrics: Root Mean Square Error (RMSE), Area Under the Curve (AUC), Accuracy (ACC), and the Square of Pearson Correlation (r\u00b2)."}, {"title": "5.4 Affect Simulation Calculation: Accuracy and Reliability (RQ1)", "content": "Affect detection is complex due to physiological influences and the lack of specialized hardware [28], [59]. The affect de-tector [35], developed using log files and field observations from the ASSISTments system, generates confidence levels for four affect types-frustration, concentration, boredom, and confusion\u2014on the ASSIST2012 dataset. For comparison with the DASE module, we use the affect with the highest confidence for each exercise, as shown in Table 3."}, {"title": "5.5 Future Performance Prediction (RQ2)", "content": "The core goal of the DASKT model is to establish a reason-able knowledge states model based on students' learning history, with a further aim to provide effective motivation or intervention for students in different affective states. Although our goal is not simply to predict students' future performance, as the accuracy of predicting students' future performance increases, our estimation of their knowledge states also becomes more precise. To assess the ability of the proposed DASKT model to predict students' future perfor-mance, we compared this model with the aforementioned benchmark models. Specifically, for each student's sequence of exercises, except for the student's response to the first question which does not participate in future prediction, the responses to all other questions participate in the prediction at the corresponding time points. Through this comparison, we can better understand the potential and advantages of the DASKT model in the field of education, thereby providing more effective support for personalized learning and educational intervention.\nTo ensure the robustness of the evaluation results, we used four evaluation metrics in all experiments, namely Root Mean Square Error (RMSE), Accuracy (ACC), Area Under the Curve (AUC), and the square of the Pearson correlation coefficient (r\u00b2). When calculating accuracy, we set the threshold to 0.5. Table 4 presents the detailed exper-imental results, and also shows the statistical significance of our model compared to the best baseline model. From Table 4, we made several important observations. First, DASKT is significantly superior to all baseline methods on all datasets and evaluation indicators. This indicates that considering the affective factors in the student's answer-ing process on student learning is necessary and valuable. Second, in the ASSISTchall dataset, DASKT is significantly superior to the most advanced DIMKT model (i.e., AUC increased by 4.55%), which shows that DASKT is more capable of capturing students' historical learning informa-tion with long sequences. In addition, in the ASSIST2012 dataset with affect, DASKT is also slightly superior to other methods. Third, the existing best KT models that use graph neural networks to construct relationships between KCs (such as GKT and JKT) performed well, further proving the applicability of graph networks in the KT field. Fourth, compared to other knowledge tracing methods that do not consider affective factors, DASKT further considers affective states in practice, successfully evaluating students' affective"}, {"title": "5.6 Analysis of the Consistency between knowledge states and affective states (RQ3)", "content": "Given our primary objective of modeling the learning pro-cess of students, we will demonstrate that DASKT can effectively capture students' knowledge states in the context of affective involvement and align with their affective trajec-tories. Figure 4 shows the changes in the knowledge states tracked by DASKT when a student completes part of the"}, {"title": "5.7 Ablation Study (RQ4)", "content": "In this section, we will conduct a detailed ablation study on the DASKT model to delve into the specific impact of each module on the model's performance. We will conduct ex-periments on four model variants, each of which removes a key component of the model. Here are detailed descriptions of the variants:\nDASKT w/o A-GAT does not take into account the affect graph attention network. Instead, it uses"}, {"title": "5.8 Visualizing Future Predictions under the Influence of Affective States (RQ5)", "content": "In this study, we used the performances of two students from the ASSISTchall dataset to explore the accuracy of assessing student knowledge states by simulating dynamic affective states. As shown in Figure 5, the DASKT model demonstrates significant advantages in prediction perfor-mance and ability to interpret future performances in the student learning process."}, {"title": "6 CONCLUSIONS AND LIMITATIONS", "content": "In this study, we explored the importance of affect as-sessment in students' problem-solving and introduced the DASKT model. This model enhances KT by integrating affect-enhanced student interaction features. We classified students' affective factors, such as confidence, interest, and effort, and extracted relevant data from non-affect-oriented behavioral records to compute these factors. We then used clustering and spatial sequence models to simulate dynamic changes in students' affect, ensuring continuity. By com-bining this affective information with the DLKT model, we enhanced its reasoning capabilities. Extensive experi-ments validated the model's effectiveness and interpretabil-ity, demonstrating the value of incorporating affect into knowledge states.\nWe believe that the dynamic affect simulation method, based on educational psychology, could be extended to other areas of smart education, such as cognitive diagnosis. However, this method has not yet been evaluated outside of KT tasks. Moreover, simulating affective factors requires behavioral data, which is missing in some datasets, limiting our experiments. The lack of gold-standard affective data also hinders deeper comparisons, presenting challenges for future research."}]}