{"title": "TAKE PACKAGE AS LANGUAGE: ANOMALY DETECTION USING TRANSFORMER", "authors": ["Jie Huang"], "abstract": "Network data packet anomaly detection faces numerous challenges, including exploring new anomaly supervision signals, researching weakly supervised anomaly detection, and improving model interpretability. This paper proposes NIDS-GPT, a GPT-based causal language model for network intrusion detection. Unlike previous work, NIDS-GPT innovatively treats each number in the packet as an independent \"word\" rather than packet fields, enabling a more fine-grained data representation. We adopt an improved GPT-2 model and design special tokenizers and embedding layers to better capture the structure and semantics of network data. NIDS-GPT has good scalability, supports unsupervised pre-training, and enhances model interpretability through attention weight visualization. Experiments on the CICIDS2017 and car-hacking datasets show that NIDS-GPT achieves 100% accuracy under extreme imbalance conditions, far surpassing traditional methods; it also achieves over 90% accuracy in one-shot learning. These results demonstrate NIDS-GPT's excellent performance and potential in handling complex network anomaly detection tasks, especially in data-imbalanced and resource-constrained scenarios. The code is available at https://github.com/woshixiaobai2019/nids-gpt.git", "sections": [{"title": "Introduction", "content": "Intrusion Detection Systems (IDS) play a crucial role in network security defense, serving as a key component in identifying and preventing various network threats [1]. Among these, Network Intrusion Detection Systems (NIDS) focus on monitoring network traffic, analyzing suspicious activities, and promptly detecting potential security vulnerabilities and attack behaviors [2]. Essentially, NIDS performs a classification task, determining the category of data packets, such as normal packets, DOS packets, or DDOS packets.\nIn the training and evaluation process of NIDS, experts typically rely on simple annotations of network packets, categorizing them as normal or abnormal, or further classifying them into specific anomaly types [3, 4]. However, this coarse-grained annotation method overlooks the rich information and complex associations within packets, such as interdependencies between packet fields, temporal relationships, and semantic connections. This results in relatively weak supervision signals, failing to fully exploit the inherent features and patterns of packets, thus limiting the detection performance and generalization ability of NIDS [5]. It also makes it difficult for NIDS to learn the importance and contribution of various packet fields, hindering effective identification of anomalous changes and combinations in key fields, thereby reducing the ability to detect unknown attacks. Furthermore, NIDS faces the challenge of extreme data imbalance [5, 6]. In real network environments, the proportion of attack or anomalous packets is usually very small, and there may even be zero-day attacks or unknown threats. This data imbalance poses significant challenges to the training and optimization of NIDS, making it difficult to learn comprehensive and robust detection models, potentially resulting in high false negative and false positive rates when facing new types of attacks or variants.\nTo address these challenges, numerous methods have been proposed. To tackle the weak supervision signal problem, some studies have employed feature engineering techniques such as dimensionality reduction [7] and feature selection [8] to simplify data complexity and facilitate model learning of intrinsic packet patterns. On the other hand, to address the data imbalance challenge, researchers have explored various data balancing and data augmentation techniques."}, {"title": "Related Work", "content": "This section will introduce existing methods for network intrusion detection, divided into four parts: traditional deep learning models (such as CNN, LSTM, and RNN), Transformer-based language models (such as GPT and BERT), methods based on modern large language models (LLMs), and the NIDS-GPT model proposed in this paper.\nTraditional Deep Learning-based Methods: The literature [16] proposed a CNN-based NIDS detection method that first converts network traffic data into images and then uses traditional CNN networks for learning, achieving good results. However, this method requires image conversion processing and cannot directly learn from raw data. The literature [17] proposed a CNN-based deep learning intrusion detection model focusing on Denial of Service (DoS) attacks, designing 18 different experimental scenarios and testing binary and multi-class classification tasks. However, this model only focuses on DoS attacks and has not tested other types of network attacks. The literature [18] proposed a novel two-stage deep learning model combining Long Short-Term Memory (LSTM) networks with Autoencoders (AE), using data filtering to prevent overfitting and underfitting, achieving an effective balance between dimensionality reduction and feature retention on highly imbalanced datasets. The literature [19] proposed a recurrent neural network based on Bidirectional Long Short-Term Memory (BiLSTM) networks, using Random Forest and Principal Component Analysis (PCA) algorithms for feature selection on the CICIDS2017 dataset. Although these papers have shown some improvement in accuracy, they essentially have not solved the problem of sparse supervision signals.\nBERT-based Methods: The literature [20] proposed a model called CanBERT based on BERT for Controller Area Network (CAN) intrusion detection, as shown in Figure 2(b). It uses Masked Language Modeling (MLM) pre-training method, randomly masking certain fields in the packet and then predicting these fields. It also adopted some advanced data processing techniques such as BPE tokenization [21] and RoPE [22] positional encoding. They trained a BERT model from scratch, fine-tuning the top layer of the model after pre-training to achieve classification tasks, obtaining good results. The literature [23] also proposed a similar approach but trained for a simpler binary classification fine-tuning task. The paper compared with a large number of other traditional methods, further demonstrating the potential of using language models to learn traffic data.\nGPT-based Methods: There are also some works similar to ours, for example, the literature [24] proposed an intrusion detection method based on bidirectional Generative Pre-trained Transformers (GPT), using two interconnected GPT networks to form a bidirectional structure to more accurately predict each CAN identifier (ID), thereby being able to stably estimate the entire CAN ID sequence. This method identifies potential attacks by calculating the negative log-likelihood (NLL) value of the CAN ID sequence and comparing it with a preset threshold. Experimental results show that compared to unidirectional GPT networks, bidirectional GPT networks demonstrate significant advantages in detection performance, especially when dealing with situations containing very few attack signals. Furthermore, experiments also show that as the amount of training data increases, the F-measure performance of this method also improves, further proving the effectiveness of language modeling on large-scale datasets. However, unfortunately, the threshold-based judgment can only be used for binary classification tasks and strongly relies on empirical values. The paper also did not use supervised fine-tuning and did not provide the tokenization method used, lacking many experimental details. As for the method itself, its model structure and training objectives are also different from our work.\nLarge Language Model-based Methods: In recent years, with the rise of large language models like ChatGPT, work on using large language models for anomaly detection has gradually emerged. The literature [25] proposed a framework called LAMP that utilizes the reasoning ability of large language models to improve event sequence prediction. Specifically, the event model first proposes predictions for future events based on past events, then the language model, guided by learning from a few expert-annotated examples, provides possible reasons for each prediction; next, the search module finds historical events that match these reasons; finally, the scoring function evaluates whether these historical events can actually lead to the occurrence of predicted future events. The literature [26] proposed a method called TIME-LLM for general time series prediction by reprogramming large language models (LLMs). TIME-LLM aims to leverage LLMs' powerful pattern recognition and reasoning capabilities on complex sequences by converting time series data into text prototypes as input to frozen LLMs to solve time series prediction problems for different tasks"}, {"title": "Method", "content": "This section will provide a detailed introduction to our proposed NIDS-GPT model. We will first give an overall overview, then elaborate on our core design - the tokenizer and embedding layer."}, {"title": "Overview", "content": "For a network packet $X = {x_1,x_2,x_3,...,x_n}$ with N fields, each field $x_i$ can be represented by a positive integer (non-numeric types can be converted to numbers). Existing methods use direct classification or BERT's field-level training approach [16, 20, 23]. Our method first converts the original packet D into a series of tokens, a process that can be represented by the function $f_{\\text{tokenize}}$, whose output is a sequence of token IDs. Unlike methods using BPE tokenization and RoPE positional encoding [20], we implemented our own tokenizer and positional encoding method. We generate two types of embedding representations for each token ID: numeric embedding $E_n$ and positional embedding $E_p$. The numeric embedding $E_n$ captures the numerical information of the token, while the positional embedding $E_p$ encodes the position information of the token in the sequence. These two embeddings are combined through addition to form the final embedding representation $E = E_n + E_p$. The resulting embedding sequence is then input into a multi-layer Transformer decoder. The Transformer decoder processes these embeddings through its self-attention mechanism, effectively capturing long-distance dependencies and complex patterns in the packet. The output of the Transformer decoder goes through a fully connected layer (FC) to predict the next \"word\" (i.e., the"}, {"title": "Network Packet Tokenizer", "content": "Our method first views the network packet as a collection of a series of fields. Given an input sequence $X = (x_1, x_2,..., x_n)$, where $x_i$ represents different fields of the network packet (such as source port, destination port, IP address, etc.). These fields usually appear in numerical form, but we choose to view them as strings for more fine-grained processing. For example, the port number 406 is viewed as the string \"406\" rather than a single integer value.\nTo better preserve the numerical features of the data in subsequent positional encoding, we introduce an innovative field reversal mechanism. For each field $x_i$, we reverse its character order:\n$x'_i = \\text{reverse}(x_i)$ (1)\nwhere $\\text{reverse}()$ represents the string reversal operation. The advantage of this approach is that regardless of how many digits the original value has, the most significant digit (ones place) always appears in a fixed position. This consistency helps the model better understand and learn the structure of the numbers.\nAfter field reversal, we begin to construct the tokenized sequence R. For each field except the last one, we convert each of its characters to the corresponding integer value and add them to the result sequence in order (the tokenids in Figure 3):\n$R = R \\cup {\\text{int}(c) \\vert c \\in x'_i } \\cup {S_i}, \\forall i \\in [1, n - 1]$ (2)\nwhere $\\text{int}()$ converts characters to integers, and $S_i$ is a special separator token. This separator token is not static but dynamically changing:\n$S_i = S_0 + i - 1$ (3)\nwhere $S_0$ is the initial separator token value. This design of dynamic separator tokens not only marks the boundaries of fields but also implicitly encodes the order information of fields, providing additional structured information for the model.\nFor the last field $x_n$ in the packet, we adopt special processing. Unlike other fields, the last field is directly added to the end of the sequence as an integer, without reversal operation:\n$R = R \\cup {\\text{int}(x_n)}$ (4)\nThis processing method conveniently transforms the label classification into the task of predicting the next \"word\". Finally, considering that deep learning models usually require fixed-length inputs, we introduce a padding mechanism. If the constructed sequence length is less than the predefined length L, we add special padding tokens at the end of the sequence."}, {"title": "Network Packet Embedding", "content": "Before inputting the tokenized sequence into the deep learning model, we need to convert these discrete tokens into continuous vector representations. At the same time, to enable the model to understand the structure of the input sequence, we also need to introduce positional information. This section will detail our embedding and positional encoding methods, which are specifically designed to handle the special structure and characteristics of network packets.\nA key feature of network packets is that they contain multiple different types of fields, each of which may contain multiple digits. Traditional embedding methods often struggle to capture both this hierarchical structure and the internal structure of the numbers simultaneously. To address this issue, we propose a multi-faceted embedding strategy, including word embeddings, numeric position embeddings, and field position embeddings. These three types of embeddings work together to provide the model with rich feature representations."}, {"title": "Objective Function and Inference", "content": "Our model adopts an objective function similar to GPT during training, while focusing on label prediction during the inference phase. The training process aims to maximize the likelihood of predicting the next word in the sequence:\n$L = \\max_\\theta \\sum_{t=1}^{T} \\log P(x_t \\vert x_{<t}; \\theta)$ (9)\nwhere $x_t$ is the t-th word in the sequence, $x_{<t}$ represents all words before t, and $\\theta$ are the model parameters. During the inference phase, our model focuses solely on predicting the label field. Assuming the label field is at position l, we define the inference process as:\n$\\hat{y}_{label} = \\text{argmax}_{y \\in \\mathcal{Y}} P(y \\vert x_1, x_2, ..., x_T; \\theta) = \\text{argmax}_{y \\in \\mathcal{Y}} p_l$ (10)\nwhere $\\hat{y}_{label}$ is the predicted label, $\\mathcal{Y}$ is the set of all possible labels, and $p_l$ is the probability distribution at the label position."}, {"title": "Evaluation Metrics", "content": "To comprehensively evaluate our model's performance, we adopt the following three main metrics: Precision, Recall, and F1 score. These metrics are suitable for our classification task, which is predicting the next character in CAN data packets.\nPrecision Precision measures the proportion of actual positive samples among those predicted as positive by the model. The formal definition is as follows:\n$\\text{Precision} = \\frac{TP}{TP+FP}$ (11)\nwhere TP (True Positive) represents the number of samples correctly predicted as positive, and FP (False Positive) represents the number of samples incorrectly predicted as positive.\nRecall Recall measures the proportion of samples correctly predicted by the model among those that are actually positive. The formal definition is as follows:\n$\\text{Recall} = \\frac{TP}{TP+FN}$ (12)\nwhere FN (False Negative) represents the number of samples incorrectly predicted as negative.\nF1 Score The F1 score is the harmonic mean of precision and recall, providing a comprehensive performance measure. The formal definition is as follows:\n$F1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}$ (13)\nFor multi-class classification problems, we calculate the precision, recall, and F1 score for each category, and then take the weighted average to obtain the overall performance metrics. Assuming there are K categories, with $n_k$ samples in the k-th category, and a total of $N = \\sum_{k=1}^{K} n_k$ samples, the weighted average F1 score is calculated as follows:\n$\\text{Macro-F1} = \\sum_{k=1}^{K} \\frac{n_k}{N} \\cdot F1_k$ (14)\nwhere $F1_k$ is the F1 score of the k-th category.\nThrough these evaluation metrics, we can comprehensively assess the model's performance in the CAN data packet character prediction task, including the accuracy and completeness of predictions. These metrics can help us compare the performance of different models or different configurations and guide the improvement and optimization of the model."}, {"title": "Experiments", "content": "In this chapter, we will provide a detailed introduction to our experiments. We conducted extensive experiments on two standard datasets, and the results demonstrate the effectiveness of our method.\nExperimental Environment: All experiments in this section are based on Python 3.8, using standard data processing libraries such as numpy, pandas, and the PyTorch deep learning framework.\nModel Configuration: As shown in Table 1, we trained models of three different sizes, gradually increasing the width and depth of our model. Here, n_layers represents the number of transformer decoder layers, n_heads represents the number of multi-head attention heads, emb_size is the dimension of the word embedding layer, and seq_len is the maximum input data length.\nHyperparameter Configuration: As shown in Table 2, we chose the Adam optimizer. Notably, for larger models, we used a smaller learning rate and employed linear warm-up with cosine decay. Since we used the SwiGLU [27] activation function in the fully connected layer, we set a universal MLP ratio value."}, {"title": "Network Traffic Packet Detection Experiment", "content": "Dataset: This experiment used the CIC-IDS2017 dataset provided by the Canadian Institute for Cybersecurity. This dataset aims to provide reliable benchmark data for research on Intrusion Detection Systems (IDS) and Intrusion Prevention Systems (IPS). Compared to previous intrusion detection datasets, CIC-IDS2017 covers a variety of latest attack types, including brute force attacks (FTP and SSH), Denial of Service (DoS), Distributed Denial of Service (DDoS), Web attacks, infiltration attacks, botnets, etc., while also including naturally generated normal background traffic. The dataset is modeled based on real user behavior, capturing network traffic over 5 days (July 3-7, 2017), extracting over 80 network flow features using the CICFlowMeter tool, and providing detailed labels and metadata. Moreover, the CIC-IDS2017 dataset meets the needs of modern intrusion detection system evaluation in terms of network configuration, traffic capture, protocol coverage, and attack diversity, effectively supporting the development and validation of anomaly detection-based intrusion detection algorithms.\nExperimental Setup: This experiment mainly follows the approach in the literature [28], verifying the model's learning effect by setting imbalanced datasets. In [28], the extreme imbalance ratio is 0.01, while we further increased the experimental difficulty by setting three imbalance ratios: 0.001, 0.0005, and 0.0002. Additionally, to verify the effect in the most extreme case, we also conducted a one-shot experiment, using only one sample for model learning. To more accurately assess the model's ability in single-sample learning situations, we conducted 10 random sampling experiments and took the average. Unlike [28], we adopted multi-classification task metrics, which are more consistent with real environments. The final partitioned dataset is shown in Table 3.\nTraining Log: The training log of the entire model is shown in Figure 4. It can be seen that the largest model (middle) has the lowest negative log-likelihood (NLL) on the training set, demonstrating the scalability of our model. It's worth mentioning that the experimental results we present subsequently are only using our smallest model (base).\nResults Analysis: We compared our method with several existing methods under different imbalance ratios, including ET, RandomForest, optimized_RF [29], and CNN_BiLSTM [30]. The experimental results are shown in Tables 4, 5, 6, and 7. From the tables, it can be seen that under imbalance ratios of 0.001, 0.0005, and 0.0002, our method achieved 1.00 in Precision, Recall, and F1-score, far surpassing other methods. This indicates that our method can effectively capture minority class samples in extremely imbalanced datasets while maintaining high overall classification performance. In contrast, existing methods such as ET and RandomForest, although performing reasonably well in Precision, showed certain deficiencies in Recall and F1-score, especially when the data imbalance intensified (imbalance ratio of 0.0002), their performance declined significantly. The optimized_RF and CNN_BiLSTM methods performed even less satisfactorily in various metrics, particularly in Recall and F1-score, struggling to effectively handle highly imbalanced datasets. Furthermore, the results of the one-shot experiment (Table 7) further verify the robustness of our method. With only one negative sample for learning, our method still significantly outperformed other methods, achieving excellent scores of 0.91 in Precision, 0.82 in Recall, and 0.84 in F1-score. The performance of other methods was generally lower, especially optimized_RF and CNN_BiLSTM, which performed almost identically in the one-shot experiment, with Precision and Recall of only 0.08, and F1-score of only 0.08. In summary, our method demonstrated excellent performance under various experimental conditions, especially in handling highly imbalanced datasets, maintaining high classification accuracy and recall rates, significantly outperforming several existing mainstream methods."}, {"title": "Vehicle Network Data Packet Detection Experiment", "content": "Dataset: This experiment used the car-hacking-dataset [4], which was constructed by executing various typical message injection attacks in a real vehicle environment while simultaneously collecting CAN bus traffic. The attack scenarios cover the most common and representative attack types in the current vehicle network environment, including Denial of Service (DoS) attacks, fuzzy attacks, spoofing tachometer readings, and spoofing gear information. DoS attacks cause network congestion by continuously sending fake messages, fuzzy attacks disrupt communication using random CAN IDs and data fields, while spoofing attacks tamper with critical speed and gear information to mislead drivers. To ensure data quality, each attack scenario was repeated 300 times, lasting 3 to 5 seconds each time, while all data frames on the CAN bus were fully recorded at a high sampling frequency. Attack samples coexist with normal driving data, which can be used to evaluate the performance of anomaly detection algorithms. This dataset contains hundreds of thousands of messages spanning over 30 minutes, comprehensively reproducing the real situation of vehicles subjected to network attacks.\nExperimental Setup: The main purpose of this experiment is to verify the transferability of our model, that is, whether it can be used directly in different scenarios without modifying the model itself. We found that by directly using data from new scenarios to train the model, cross-scenario application can be achieved. In the experiment, we still chose multi-classification tasks as the training objective of the model to evaluate its performance in vehicle network intrusion detection. We continued to use the parameters from Table 2, and the specific dataset details are shown in Table 8.\nResults Analysis: The experimental results are shown in Table 9. Our model achieved 1.00 in Precision, Recall, and F1-score, performing comparably with other advanced methods such as transfer_CNN [16] and D_CNN [16]. This indicates that our model has excellent transferability and can achieve outstanding performance in vehicle network data packet detection tasks. It's worth noting that despite the differences in features and distribution between vehicle network data and network traffic data from previous experiments, our model could adapt to new scenarios and achieve excellent results without any modifications. This demonstrates the robustness and generalization ability of our model, which can effectively capture key patterns and features in different types of data, reflecting its universality. Moreover, our model does not require additional preprocessing operations, making it a completely end-to-end model, greatly simplifying the training process."}, {"title": "Interpretability Experiment", "content": "This experiment mainly aims to analyze the interpretability of the representations learned by the model. We extracted the weights of the trained models from experiments 1 and 2 and visualized the attention weights, as shown in Figures 5 and 6. Through the visualization analysis of the model's attention weights in these two different scenarios, we can gain"}, {"title": "Conclusion", "content": "The NIDS-GPT model has demonstrated significant potential and advantages in the field of network intrusion detection. Through innovative architecture design and training strategies, this model can not only effectively handle challenging tasks such as imbalanced data and one-shot learning but also shows good scalability and transfer learning capabilities. The experimental results on the CICIDS-2017 and OTIDS datasets prove the effectiveness of the model, especially in maintaining a high level of detection accuracy even in extremely imbalanced data situations. Furthermore, the exploration of model interpretability provides a foundation for improving its credibility and operability in practical applications.\nHowever, future research still needs to further explore the model's performance in more complex network environments, as well as how to further improve the model's efficiency and real-time performance. Overall, NIDS-GPT provides a promising new approach for the field of network security and is expected to play an important role in future practical applications."}]}