{"title": "Toward AI-Driven Digital Organism: A System of Multiscale Foundation Models for Predicting, Simulating and Programming Biology at All Levels", "authors": ["Le Song", "Eran Segal", "Eric Xing"], "abstract": "We present an approach of using AI to model and simulate biology and life. Why is it important? Because at the core of medicine, pharmacy, public health, longevity, agriculture and food security, environmental protection, and clean energy, it is biology at work. Biology in the physical world is too complex to manipulate and always expensive and risky to tamper with. In this perspective, we layout an engineering viable approach to address this challenge by constructing an AI-Driven Digital Organism (AIDO), a system of integrated multiscale foundation models, in a modular, connectable, and holistic fashion to reflect biological scales, connectedness, and complexities. An AIDO opens up a safe, affordable and high-throughput alternative platform for predicting, simulating and programming biology at all levels from molecules to cells to individuals. We envision that an AIDO is poised to trigger a new wave of better-guided wet-lab experimentation and better-informed first-principle reasoning, which can eventually help us better decode and improve life.", "sections": [{"title": "1 Introduction", "content": "Biology lies at the core of vital fields such as medicine, pharmacy, public health, longevity, agriculture and food security, environmental protection, and clean energy. The mechanisms underlying living and physical systems have always fascinated us. With Newton's laws, we can predict the orbits of celestial bodies; the periodic table allows us to anticipate the properties of chemical compounds; and we can even simulate weather and environmental systems. However, despite our extensive knowledge of atomic, molecular, chemical, and physical laws, and the computational power of modern computers, we still cannot simulate biological systems accurately. Whether we aim to pinpoint genetic markers of diseases for diagnosis, design drugs to heal damaged cells or deter pathogens, or develop vaccines to combat pandemics, such advancements in medicine consistently require a profound understanding of the underlying biology at all levels, along with the ability to predict, simulate, and program biological activities comprehensively. Manipulating biology in the physical world is extremely complex, expensive, and risky, and should be preceded by extensive computer-aided digital design, simulation, and validation as in other industrial fields such as civil, nuclear, and semiconductor engineering. We propose a vision in which such capabilities can be realized using generative AI.\nGenerative AI and large pretrained models across text, images, speech, and video have become key pillars for advancing artificial general intelligence (AGI), driving significant improvements in a wide range of downstream tasks, including language and image comprehension, translation, knowledge extraction, reasoning, and cross-modal generation. These models are often known as \"foundation"}, {"title": "2 Multiscale Structure and Organization of Biological Systems", "content": "Biological systems are organized as multiscale, heterogeneous networks of interacting entities, ranging from molecules to cells to organisms within their environments (see text books such as [17] for more details; and see Figure 1 for an illustration). At the most fundamental level, these entities are various types of molecules and their interactions. Key molecules such as DNA, RNA, and proteins operate under the central dogma of molecular biology, where DNA encodes genetic information, RNA serves as the intermediary, and proteins execute cellular functions.\nDNA sequences comprise coding regions, regulatory elements like enhancers and promoters, and noncoding intergenic regions. Through transcription, DNA is expressed as RNA sequences. While some RNA molecules are noncoding and perform regulatory functions or act directly within the cell, messenger RNA (mRNA) is translated by ribosomes into protein sequences. These proteins fold into specific three-dimensional (3D) structures to carry out diverse functions, including regulation, signaling, enzymatic activity, scaffolding, and transport.\nWithin the cellular environment, molecules and ions form complex, stochastic interaction networks involving protein-protein, protein-DNA, protein-RNA, protein-small molecule, and protein-ion interactions. The functions and interactions of these molecules are often governed by their structures and physicochemical properties. For example, the 3D organization of DNA within the nucleus influences gene accessibility and expression; protein-protein interactions require complementary shapes and charges; and enzymatic reactions depend on the precise spatial arrangement of amino acid residues relative to substrates.\nThese molecular interaction networks constitute complex systems exhibiting dynamic behaviors determined by initial states, governing biochemical equations, and external stimuli or perturbations. Dynamic cellular processes such as signal transduction and cell division arise from these intricate networks. Cells interact with one another, especially when in direct contact or close proximity, through mechanisms that include membrane protein interactions, cytokine and hormone signaling, and the exchange of ions or small molecules. Such cell-cell interactions couple the individual dynamic systems of cells, leading to complex spatial patterns of molecular distributions and coordinated tissue functions.\nSpatially organized assemblies of functionally diverse cells form tissues and organs. The coordinated arrangement and interaction of cells within these structures are essential for the normal function of tissues and organs. At the organismal level, tissues and organs coordinate to form self-sustaining individuals capable of interacting with their environment. Organisms exchange chemical and biological substances with their surroundings and with each other, forming networks of biological entities. Environmental factors, in turn, influence the physiological conditions and adaptive responses of these organisms. Understanding this multiscale structure and organization is crucial for developing comprehensive models that can simulate biological phenomena across different scales.\nGiven the multiscale organization of biological entities, it is essential to model and utilize data across appropriate scales of granularity to effectively address specific biological questions. For example, clinical diagnosis relies on individual-level data spanning molecular to system granularity \u2014including phenotypic measurements along with genetic and cellular information to enable personalized medicine and accurate disease identification. Understanding disease mechanisms and discovering therapeutic targets necessitate examining tissues, cells, and molecular interactions to reveal underlying pathways and dysfunctions. Drug design focuses on molecular and pathway data to identify compounds that precisely modulate biological processes or protein functions.\nIn fields like developmental biology, integrating data across scales from gene expression within cells to the coordinated behavior of tissues and organs is crucial for deciphering growth processes and correcting abnormalities. Therefore, addressing questions at different levels requires a system of foundation models that are themselves multiscale and multimodal. Such models should represent and integrate data across various biological scales, providing a comprehensive framework for understanding and manipulating biological systems, and comprising an AIDO."}, {"title": "3 What is an AI-Driven Digital Organism", "content": "In our vision, a digital organism is a computational model\u2014such as a transformer (or newer architectures to emerge)-based foundation model that enables the simulation of all biological, physiological, and clinical events occurring within a living organism. This digital organism should be consistent with biogical scales, connectedness and complexities, and constructed using multimodal, large-scale datasets, including molecular sequences and structures, biological networks and pathways, transcriptomic and metabolomic profiles, images, textual descriptions, and spatial-temporal information of biological systems. It should model a living system in a multiscale manner, encompassing molecular, genetic, structural, cellular, tissue, organ, organismal, populational, and evolutionary levels.\nIn the following, we overview more concisely a set of desiderata for what we expect from a digital organism and how it is different from other approaches."}, {"title": "3.1 Universal Representations of Biological Entities", "content": "At the core of the digital organism concept is the representation of biological entities at various levels-including genes, operons, regulatory elements, proteins, organelles, cells, tissues, and entire organisms using explicit, operationalizable, and multi-resolution digital expressions such as vectors or tensors. These representations are derived from encoders that compute latent states at the desired level of granularity from raw input data associated with the biological subject. They can be either pre-computed and deposited to a repository bank, or computed live prompted by new data and unique context in novel situations. This process can also incorporate additional context, including influences from interacting entities, temporal-spatial conditions, and prior knowledge. With such representations, a wide range of downstream predictive, simulative, and programmatic applications can be facilitated as detailed later in this paper. These representations can help mitigate issues related to limited labeled data for high dimensional inputs and to transfer knowledge across tasks making them foundational and instrumental in addressing a wide spectrum of downstream problems involving similar types of inputs.\nKey to their flexibility and versatility in these applications, these digital representations are amenable to a wide range of computational operations that enhance their utility:\nArithmetic Operations: These operations allow for the combination or subtraction of representations across multiple entities that are at the same level or scale, facilitating comparative studies and differential analyses. For example, adding or subtracting gene expression vectors can highlight upregulated or downregulated pathways between healthy and diseased states. Amplifying or attenuating signals within these vectors can simulate the effects of dosage variations, electrical conductivity changes, or environmental influences on biological processes. Concatenation or truncation operations can model the integration or loss of biological effects, such as in gene fusion events or alternative splicing variants.\nMachine Learning Operations: Applying clustering or dimensional reduction algorithms to these representations can reveal natural groupings within the data, such as revealing cell types based on gene expression profiles. Classification models can assign labels to unknown samples, aiding in tasks like disease diagnosis. Predictive modeling can forecast biological outcomes, such as predicting protein folding structures from amino acid sequences. The representations of the biological entities can be used individually or in combination for specific downstream predictive or generative tasks by fine-tuning and adapting with a small number of labeled data points. This approach often results in significant improvements in accuracy and convergence speed compared to training models from scratch. Temporal and spatial processing techniques enable the modeling of dynamic biological processes over time and across different regions within an organism, such as simulating the progression of a signaling cascade or the spatial spread of a cellular response.\nInter-Domain Operations: These operations facilitate cross-scale manipulation and experimentation by bridging different levels of biological organization. For instance, modeling interactions between transcription factors and promoters can elucidate gene regulatory networks. Simulating genetic perturbations at the cellular level can help predict the effects of gene knockouts or overexpression on cell function. Co-modeling host-pathogen dynamics allows for the study of infection processes and immune responses by simultaneously representing both the pathogen and host cellular environments.\nAdditional Operations: Multi-resolution scaling enables seamless transitions between different levels of granularity, allowing analyses that span from molecular to organismal scales. Agent-based modeling can simulate the behaviors of individual cells or molecules within a larger system, providing insights into emergent phenomena resulting from complex interactions. Such operations support the exploration of biological processes like tissue development, immune responses, and population dynamics.\nBy integrating these computational operations, an AIDO becomes a powerful framework for simulating and understanding the multifaceted nature of biological systems. It allows researchers to manipulate and analyze biological entities in silico across various scales and contexts, ultimately facilitating advances in biomedical research and personalized medicine."}, {"title": "3.2 Predictive, Generative, Programmable Biology", "content": "Once we have built such an AI-driven digital organism, equipped with the rich set of operations described above, we envision utilizing it for a variety of tasks across multiple biological scales:\n\u2022 Predicting biological phenomena at all levels: Examples include inferring protein structures from amino acid sequences, determining phenotypes from genotypes, and forecasting cellular responses to specific perturbations.\n\u2022 Simulating biological processes comprehensively: This includes modeling genetic manipulations, molecular designs, drug effects, and treatment outcomes to understand their impact on biological systems."}, {"title": "3.3 Why an AI-driven Digital Organism is Superior", "content": "All biological entities form a holistic system encompassing multiple scales, from molecules to organisms to ecosystems. Biological problems are inherently interconnected rather than isolated and can be studied and addressed at various nested levels of granularity. Although advancements in experimental technologies offer more data, conducting biological experiments remains expensive and time-consuming. Given the exponential growth of historical data, there is an urgent need to model and capture the information within these datasets, leveraging the generalization capabilities of computational models to extract more value from existing data, and reduce the need for a large amount of costly wet-lab experimental data.\nBy building an AIDO, we can create a digital experimental environment that is more affordable, safer, faster, programmable, repurposable, and highly adaptable to multiple tasks. Conducting experiments, designing, and programming biology within such a digital environment and then selectively iterating, refining and improving the AIDO with wet-lab experimental approaches can significantly reduce the reliance on physical experiments and accelerate innovation in the biological sciences."}, {"title": "4 How to Build an AI-driven Digital Organism", "content": "In the following, we present our perspective on constructing an AIDO. To accurately represent the multiscale and interconnected nature of biological systems, foundation models for biology must reflect these complexities. We posit that an AIDO shall be built in a modular and connectable way such that these modules can be combined and cascaded to model and address problems arising at different biological scales and complexities (See Figure 2). Furthermore, the development of these foundation models shall consider the substantial amount of existing data available in the field and anticipate the increasing influx of data in the near future. Taking into account these aspects, an engineering viable approach to building the AIDO is to develop it in 3 stages, i.e., the module building stage, the module connection stage, and the system unification stage. In the following, we will expose the principle we use to build the AIDO, the data available for such development, and the concrete work essential for different stages of the development."}, {"title": "4.1 Foundation Model Paradigm", "content": "Classical machine learning predictive models are typically trained on labeled datasets specific to a particular task. However, their accuracy is often limited by the scarcity of labeled data, and they generally exhibit poor transferability to other tasks. In contrast, the paradigm of foundation models [1] involves pretraining models on large amounts of unlabeled data using self-supervised objectives such as masked language modeling (MLM) [18], next token prediction (NTP or GPT) [19], auto-encoding (AE) [20], and contrastive learning (CL) [21, 22]. In MLM and NTP, models learn to recover parts of the input that are intentionally hidden, while in AE, they reconstruct the entire input from compressed latent representations. Contrastive learning trains models to produce similar embeddings for similar inputs while distinguishing between different ones.\nArchitecturally, pretrained models often employ transformer architectures, which utilize pairwise attention mechanisms to capture long-range interactions within input data [23]. State-space models (SSMs), such as Mamba [24], which use recurrent architectures to capture long-range dependencies are also often used in constructing pretrained models. Beyond sequential data, graph neural networks (GNNs) [25], message passing neural networks [26] and geometric deep learning (GDL) [27] are also employed to model more complex input structures or dependencies which are represented as graphs. In GNNs or GDL, message-passing operations propagate information through the graph, producing node and edge representations after several iterations. Recently, diffusion models have also been utilized for continuous and discrete outputs to build foundational generative models or decoders for various types of geometric and sequence data [28, 29, 30]. These models can be pretrained on existing structure and sequence datasets to model the distribution of input data and later adapted for specific prediction tasks or conditioned for specific generation tasks.\nWhile recent foundation models are becoming multimodal\u2014exemplified by models like GPT-4 [31] and Gemini [32] -the multimodal data used for cognitive or world modeling fundamentally differs from that in biological modeling. Biological systems \"speak\" a language distinct from human language. For instance, the relationships among the three primary biological modalities-DNA, RNA, and proteins are governed by the central dogma of molecular biology, which significantly differs from relationships in multimedia data. These modalities exhibit high levels of redundancy, alignment, and cascading information logic. DNA influences RNA and protein function not only through sequence-defined structures but also via expression levels, temporal dynamics, post-translational modifications, spatial contexts, and co-expression patterns. Furthermore, many of the causal logic and mechanisms in biological systems remain unknown, including the temporal, spatial, and cell-specific behaviors of gene products.\nConsequently, large language models built on human texts and internet images are not directly applicable, and a new set of foundation models is needed. Furthermore, developing foundation models for biology requires new architectures with appropriate tokenization, context lengths, specialized attention mechanisms, latent representations, hierarchical structures, and calibration tailored to biological data. These models must account for the unique characteristics of biological information, including its multiscale organization and the complex interplay between different biological entities and processes, which we address with concrete expositions in this paper."}, {"title": "4.2 Available Data", "content": "Training the foundation model components that constitute an AIDO necessitates vast amounts of data encompassing biological scales, and thus the types of models we can develop are intrinsically linked to data availability. The continuous reduction in sequencing costs and the advent of high-throughput experimental methods have led to a rapid increase in datasets suitable for self-supervised learning in biology.\nBiological sequences. Major repositories such as the National Center for Biotechnology In-formation (NCBI\u00b9), the European Bioinformatics Institute (EBI\u00b2), the DNA Data Bank of Japan (DDBJ\u00b3), and the Integrated Microbial Genomes and Microbiomes system hosted by the Joint Genome Institute (JGI4) house extensive sequencing data from a wide range of species, including vertebrates, invertebrates, and bacteria. Specialized databases have emerged from these repositories, such as En-sembl for meticulously annotated genomes, UniProt for protein sequences, and RNAcentral for noncoding RNAs. For instance, there are tens of thousands of complete genomes, each comprising billions of nucleotides. Additionally, hundreds of millions of noncoding RNAs and billions of proteins have been sequenced.\nMolecular structures. The Protein Data Bank (PDB) contains over 200,000 entries of proteins and other molecular complexes. Moreover, more than 10,000 RNA structures have been documented. Predicted structures with associated confidence levels are also abundant, thanks to resources like AlphaFold Protein Structure Database (AlphaFold DB9) and ESM Metagenomic Atlas (ESM At-las10), which collectively provide hundreds of millions of predicted protein structures. Recently, there are also increasing amount of DNA packing structure data available allowing us to study the structural organization of genomes in relation to their regulatory roles.\nInteractome and relational data. In the realm of molecular interactions, databases such as STRING11 (Search Tool for the Retrieval of Interacting Genes/Proteins) offer more than 10 billion physical or inferred relationships between molecules. Pathway databases like KEGG12 (Kyoto En-cyclopedia of Genes and Genomes), Reactome13 and BioCyc14 provide detailed maps of biological pathways, while the Gene Transcription Regulation Database (GTRD15) focuses on transcription factors regulating gene expression. Gene Ontology (GO16) also defines the relation between the genes and the biological pathways in a hierarchical fashion.\nTranscriptome and cellular activity. Single-cell RNA sequencing (scRNA-seq) and spatial transcriptomics represent rapidly growing data sources. Public repositories now contain over 100 million scRNA-seq measurements and thousands of spatial transcriptomic datasets. Consolidated platforms like the Chan Zuckerberg Initiative's CellxGene17 facilitate access to and analysis of these datasets. There is also an increasing amount of experimental data measuring cellular response to perturbations, such as the Genomics of Drug Sensitivity in Cancer (GDSC18) dataset. Beyond gene expression data, there is an expanding wealth of spatial information on the transcriptome, including imaging data for cells and tissues. Projects like the Human Protein Atlas (HPA19), Human Cell Atlas (HCA20), and Jump Cell Painting dataset (Jump-CP21) are generating extensive imaging datasets that provide spatial context to transcriptomes. Cell Ontology22 is also constructed to provide a structured controlled vocabulary for cell types in animals.\nPhenome and population data. Expanding beyond cellular and tissue transcriptomes, large human cohorts are emerging that encompass simultaneous measurements across multiple biological scales and modalities in human subjects. Notable examples include the UK Biobank23, The Cancer Genome Atlas (TCGA24), and the Human Phenotype Project (HPP25). The HPP, in particular, provides broad clinical, physiological, genetic, transcriptomic, cellular, and phenotypic data measurements over time, offering a rich resource to model complex dependencies and link fine-scale molecular data with higher-level phenotypic outcomes.\nThese extensive datasets lay the groundwork for building large-scale foundation models across all scales of biology. The pretrained models resulting from these datasets can be employed individually or integrated to address a wide spectrum of biological and life science challenges, from molecular design and cellular engineering to systems biology and personalized medicine."}, {"title": "4.3 Multiscale Foundation Models for Biology", "content": "In the following, we outline a technical blueprint to develop a system of foundational models capable of addressing biological questions across different scales. The overall scheme consists of 3 stages. The first stage is to build up a necessary set of fundamental building blocks or modules representing the major data modalities arising in biology \u2013 in a \"divide-and-conquer\" fashion. The second stage is to develop a set of new deep learning architectures that integrate the central dogma, regulatory rules, and the interconnected nature of biology, as well as different data modalities or modules in a bottom-up fashion to reflect the multiscale, nested, and hierarchical organization of biological systems. These architectures can bridge the existing gaps by integrating biological knowledge into the models and developing models that can seamlessly operate across various biological scales and modalities thereby \"dots are connected\". In the third stage, the modules and connected modules are unified into a networked system, where representations and embeddings can be passed around in different nodes and levels of the systems, and especially feedback and gradient signals from the coarser and topper level of the system can be propagated all the way back to the bottom level of the system to further improve these modules. This is like the \"aligning and optimization\" phase in an assembly process. With a set of benchmarks and supervisory tasks from different levels and scales of biology, all the system modules can be jointly adapted and aligned to achieve synergy towards an overall better or even emergent system-level performance."}, {"title": "4.3.1 Divide-and-Conquer: Models for Specific Modalities and Scales", "content": "Pretrained models for each data modality are important building blocks for more complex models. These initial models can also be continuously pretrained with data from specific domain and evolved in a lineage into new pretrained models. Therefore, the initial step towards an AIDO is to build a family of models which can be used independently and re-used as building blocks for more advanced models and integrated systems (See Figure 3 for a summary). In the process of building these modules, new tokenizers of the biological data and new architectures also need to be developed to better process the input biological data and learn better representations for these data."}, {"title": "Individual Pretrained Models for Each Data Modality", "content": "We will first pretrain both sequence and structure models for molecule-level data involved in biology, such as small organic molecules, DNA, RNA and protein sequences. Next, graph neural networks can be used to pretrain regulatory networks and pathway data from KEGG, Reactome and GTRD. Single-cell pretrained models can be constructed based on data from cellxgene, and tissue and cell type image models can be pretrained over human cell atlas and human protein atlas data. Lastly, some of the phenotype pretrained models, such as sleep, gait, electrocardiograms (ECG), and glucose response models, can be obtained from data collected in the Human Phenotype Project."}, {"title": "New Tokenizers for Biological Data", "content": "New tokenizers also need to be developed for biological data due to their diversity and differences from natural language and images.\nTokenization for biological sequences. For DNA and RNA sequences, every three nucleotide bases in the coding region correspond to an amino acid, but for noncoding region, such correspondence does not exist. Thus, in order to take into account such biological information, tokenizers for DNA and RNA sequences will need to be designed in a way which aligns with the boundary of coding and noncoding regions. Furthermore, for coding regions, a vocabulary for a combination of a group of three or multiple of three nucleotides needs to be used, but for noncoding regions, there is no such restriction on aligning with the reading framework of the coding regions. Therefore, for the noncoding region, we can use a more information-driven approach to tokenize the sequences, such as the Byte-Pair Encoding (BPE) tokenizer [34] which can come up with variable length tokens based on sequence statistics. Thus, for biological sequences, such hybrid tokenizers seem to be needed to best represent the input by taking into account both information theory and biological knowledge.\nTokenization for molecular structures. Developing accurate models for molecular structures and properties at the molecular level is of paramount importance. To model the 3D structures of biomolecules and their interactions, which is pivotal for understanding their functions and guiding the"}, {"title": "Tokenization for cellular transcriptome and image data.", "content": "A large amount of single cell gene expression and other transcriptomic data are measured and curated nowadays, and these measurements reflect the continuous concept of how much each biomolecule is present in a dynamical system. To better integrate these continuous measurements into a unified system and allow for inter-modality operability, we will need to learn to embed or tokenize these inputs. Furthermore, increasingly, high-content imaging data that reveal cellular morphology are being collected alongside transcriptomic data, and adding spatial information about the location of biomolecules. To incorporate morphological and location features into our modeling framework, these information also need to be embedded or tokenized to allow for unified modeling and cross-operability. We can employ again autoencoder or vector quantized autoencoder architectures to learn latent representations of transcriptomic and cellular image data [38] (See Figure 4). Since we need to handle both individual molecule representation and cellular representation from such data, new architecture and training methods will be needed in the VQ-VAE framework to accommodate such two levels of tokenization and to ensure consistency between the two levels of tokens. Furthermore, due to the introduction of spatial information in imaging and spatial transcriptomic data, such spatial information also needs to be encoded and attended to during the representation learning process."}, {"title": "Tokenization for phenotype information.", "content": "Beyond single-cell and spatial transcriptomics, modeling tasks at the organ, organ network, and individual levels are essential for a comprehensive understanding of complex biological systems and diseases. The availability of data at these higher scales is rapidly increasing, thanks to large-scale population cohorts such as the UK Biobank and the Human Phenotype Project (HPP). These resources provide extensive phenotypic data, including molecular, longitudinal and time-series measurements, which can be leveraged to build robust models given sufficiently large and standardized cohorts.\nComplex time series of phenotypic measurements such as continuous glucose monitoring patterns, sleep quality metrics from wearable devices, dietary intake logs, and physical activity levels tracked by accelerometers- -can also be modeled using a continuous or vector-quantized autoencoder framework with transformers and other deep learning encoders specialized for phenotype time-series data. These"}, {"title": "New Deep Architectures beyond Transformers", "content": "Biological data and the mechanisms behind them pose unique modeling challenges not seen in common data such as natural texts and images. New deep learning architectures need to be designed to handle many properties unique to biology data and mechanisms. For instance, protein structures consist of atoms situated in 3D spaces, and the representations of 3D structures need to be invariant to the translation and rotation. For example, biological sequences such as DNA are not only extremely long but also behold long-range interactions at various granularity, necessitating modeling of such distant input contexts. For instance, to model a eukaryotic gene, we need to take into account both introns and exons as well as regulatory regions such as promoters and enhancers, which may involve hundreds of kilobases. Another example is in modeling human single cell gene expression data, where around 20k dimensional count data need to be modeled simultaneously to capture the cell states. The underlying regulatory mechanisms involving genome sequences, RNA, and proteins make such data complex and challenging to model. Standard deep learning architectures, such as conventional transformers, face challenges either due to such architectures not expressing the proper inductive bias or due to computational and memory constraints when processing such complex biological contexts. Therefore, designing architectures capable of handling unique biological inputs and contexts in a memory- and computationally efficient manner is essential.\nArchitectures for molecular structures. For molecular structures with 3D coordinate information, we need to incorporate some of the physical constraints in the representation learning in different applications, such as equivalences, where embeddings are rotated and shifted as these operations are applied to input structures, and invariances, where embeddings remain the same irrespective of the rotation and shift of the input structures. To be able to systematically address these physical con-straints, we will need to design deep architectures in the spherical harmonic space where embeddings are learned as vector spaces of irreducible representations and have sparse message passing or dense attentions between nodes based on equivariant operations such as tensor products [40]. However, a bottleneck in scaling up these deep architectures is the computational complexity of the tensor prod-ucts when we use a high number of basis in spherical harmonics. Thus, efficient implementations of these architectures are also needed to make them efficient yet expressive.\nArchitectures for long sequence inputs. A family of sparse and hybrid deep architectures has the potential to address the long sequence problem arising from genomic and cellular modeling. For instance, transformers with random sparse attentions [41], hierarchically designed attentions [42] and the mixture of experts [43, 44], can allow transformers to scale to very long input sequences. These efficient layers can also be stacked many times in a deep architecture allowing information from differ-ent parts of the input to sufficiently mix without losing too much of the representation power of the model. As for hybrid architectures, for example, integrating convolutional neural networks (CNNs)"}, {"title": "4.3.2 Connect the Dots: Integration across Modalities and Scales", "content": "Once we have the modules for different modalities and scales of biological data, we can connect and combine these modules to address more complex biological problems, and build better models by linking information arising from different scales of biology (See Figure 5 for a summary). We will use several technical approaches that are reusable for connecting different modules for more advanced modeling."}, {"title": "Markup Language Models for Integrating DNA, RNA, and Protein Sequences", "content": "Recent large language models (LLMs) for biological sequences are developed separately for each type of molecule-DNA, RNA, or proteins. While this specialization has led to advances in modeling each modality, it overlooks the fundamental interconnectedness of these entities as described by the central dogma of molecular biology. DNA encodes the information for RNA and proteins, and there is a direct correspondence between these sequences. This presents an opportunity to unify these three types of sequences within a single foundation model that leverages their intrinsic relationships. A recent attempt to bridge this gap is the Evo model, which utilized a pretrained DNA model to address downstream tasks involving RNA and proteins. However, this model was limited by its training data, which consisted solely of bacterial genomes, and it did not incorporate crucial biological annotations such as regulatory regions, noncoding RNA regions, or coding regions with introns and exons. Moreover, while the number of complete reference genomes is limited, there exists a vast amount of data on sequenced and expressed RNA and proteins from incomplete genomes.\nTo fully harness the available biological sequence data, one can develop a markup language model for biological sequences (Figure 6). This model would integrate rich annotation information for different functional units within the genome and leverage fragments of expressed sequences to maximize data utilization. By incorporating annotations directly into the sequence data, we can provide the model with context that is essential for understanding biological functions. In practice, this approach involves augmenting the sequence data with labels that indicate the type of molecule-DNA, RNA, or protein and potentially more fine-grained information such as regulatory elements or coding regions. For example, specific tokens or markers can be inserted at the beginning and end of sequences to de-note their biological context. This additional information effectively conditions the model on the type of sequences it is processing, enabling it to generate more relevant representations and predictions. Furthermore, by unifying DNA, RNA, and protein sequences within a single model and providing type indicators, we facilitate the transfer of information between these modalities. The inherent similarities and correspondences among these sequences can potentially be exploited this way by the model to improve learning and generalization. Such a unified model has the potential to outperform separate models by capturing the holistic nature of genetic information flow and leveraging the vast amounts of available data across all three modalities. This integrated approach aligns with the hierarchical and nested structure of biological systems, reflecting the multiscale organization inherent in biology. By developing foundation models that encapsulate the relationships between DNA, RNA, and proteins, we can create powerful tools for a wide range of downstream tasks, from predicting gene expression and protein folding to understanding regulatory networks and disease mechanisms."}, {"title": "Advanced Position Encoding Schemes For Rich Biological Contexts", "content": "Unlike words marked by their unique linear positions in a natural language sentence or sequence, every unit of elements within a biological data collection (e.g., sequence, gene expression) has a myriad of contextual relevance that often overlap, including evolutionary position, chromosomal position, network position, gene-ontology position, cellular position, etc.\nFor instance, evolutionary relationships among species result in significant similarities within their genomes; aligning evolutionarily related biological sequences such as genome sequences and protein"}, {"title": "Differentiable Computation Graphs for Integrating Pretrained Representations", "content": "Each pretrained module provides an embedding or vector representation of a corresponding type of biological entity, causing diverse biological entities to be projected into one space, offering a basis for vector space operations between them, and enabling them to be combined and cascaded in a nested fashion to form more sophisticated models, reflecting the hierarchical nature of biological entities.\nDifferentiable Computation Graph (DCG) techniques such as graph neural networks (GNNs) [25] and message passing neural networks (MPNN) [26] are well-suited for modeling complex interactions and can accommodate heterogeneous node types and capture complex relations between linked entities and modules, such as the signed effects of edges-representing activation or inhibition genetic or cellular regulations (Figure 8). More generally, leveraging the differentiable computation ability of modern deep learning platforms, pretrained modules from different levels can also be readily connected into more sophisticated computation graphs allowing embeddings and gradients to be passed between these modules according to the connectivity patterns of the computation graphs.\nMolecular interaction models on pretrained representations. A substantial body of curated knowledge exists regarding biological pathways and molecular interactions, available through resources such as Reactome and KEGG for pathway information, the Gene Transcription Regulation Database (GTRD) for transcription factor-DNA binding interactions, and STRING for protein-protein interac-tion networks. These databases provide a rich foundation for pretraining representations of genes and proteins that effectively capture the network effects inherent in biological systems. Leveraging this existing knowledge is particularly crucial when modeling the impact of drug interventions or genetic perturbations. The effects of such perturbations often propagate through molecular networks, influ-encing downstream entities within biological pathways, and can lead to cascading changes that alter the behavior of entire cells or tissues. Accurate modeling of these propagation dynamics is essential for understanding the systemic consequences of molecular interventions.\nWith such pretrained embeddings for genes and proteins, we can facilitate a variety of higher-level modeling applications. For instance, these embeddings can provide positional biases when modeling gene expression within cells, enhancing the representation of spatial and regulatory contexts. Addition-ally, they can serve as initial embeddings for simulating the propagation of perturbation effects through molecular networks, thereby improving the predictive accuracy of models that aim to understand cel-lular responses to interventions. This approach not only enriches the representation of individual molecular entities but also enables the integration of network-level information into downstream pre-dictive and generative models. By capturing the complex interplay among genes and proteins within biological networks, we can advance our ability to model biological processes more holistically and design more effective therapeutic strategies.\nIn such a model, the initial embedding of each molecule can be provided by molecular-level em-bedding models for their respective sequences or structures. Then these embeddings can be further transformed by the graph neural network to take into account the network effects. For pretraining"}, {"title": "4.3.3 Piece It All Together: Align and Optimize across Scales", "content": "Bringing all of the components above together allows the proposed biological foundation models to intricately integrate the central dogma and the multiscale, interconnected nature of biology into archi-tectural designs. By integrating phenotypic models with foundation models from molecular and cellular levels, we establish a holistic framework capable of capturing biological complexity across scales (See Figure 11 for a summary). Collectively, these architectural innovations demonstrate how foundation models can integrate multiscale biological information from molecular sequences, to cellular contexts and evolutionary relationships, and to the individual organism and its temporal behavior providing a cohesive framework for modeling complex biological systems. This integrative approach holds the promise of advancing our ability to simulate and understand biology across different scales, ultimately contributing to breakthroughs in biomedical research and personalized medicine.\nOne key feature of the modules in an AIDO system is that they are connected to build new models or modules, and high-level models are constructed hierarchically and are nested with lower-level modules. Such nested construction and vectorized and differentiable connections do not only allow representations of information to flow from the bottom molecular level to the higher phenotype level, but also allow feedback information to flow back in the architecture to use higher level information to further adjust, optimize or align lower level embeddings and models. Here we have the opportunity to leverage the supervision signals from a multitude of predictive and generative tasks across different scales to jointly adjust or optimize all modules in an AIDO together, to make them aligned and become a truly unified whole.\nSince the modules from each level and for each biological data modality have already been pretrained with their own objectives, and adjusted by the important downstream tasks corresponding to their biological levels, we will need the overall unified system to respect and keep consistency with these objectives. Thus, when we jointly adjust and align the system modules, we will use a weighted combination of all these task objectives and jointly optimize these objectives, which allows"}]}