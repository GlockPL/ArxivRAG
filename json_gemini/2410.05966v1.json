{"title": "FLOPS: FORWARD LEARNING WITH OPTIMAL SAMPLING", "authors": ["Tao Ren", "Zishi Zhang", "Jinyang Jiang", "Guanghao Li", "Zeliang Zhang", "Mingqian Feng", "Yijie Peng"], "abstract": "Given the limitations of backpropagation, perturbation-based gradient computation methods have recently gained focus for learning with only forward passes, also referred to as queries. Conventional forward learning consumes enormous queries on each data point for accurate gradient estimation through Monte Carlo sampling, which hinders the scalability of those algorithms. However, not all data points deserve equal queries for gradient estimation. In this paper, we study the problem of improving the forward learning efficiency from a novel perspective: how to reduce the gradient estimation variance with minimum cost? For this, we propose to allocate the optimal number of queries over each data in one batch during training to achieve a good balance between estimation accuracy and computational efficiency. Specifically, with a simplified proxy objective and a reparameterization technique, we derive a novel plug-and-play query allocator with minimal parameters. Theoretical results are carried out to verify its optimality. We conduct extensive experiments for fine-tuning Vision Transformers on various datasets and further deploy the allocator to two black-box applications: prompt tuning and multimodal alignment for foundation models. All findings demonstrate that our proposed allocator significantly enhances the scalability of forward-learning algorithms, paving the way for real-world applications.", "sections": [{"title": "1 INTRODUCTION", "content": "Ever since the success of backpropagation (BP) (Rumelhart et al., 1986), researchers have sought alternate biologically plausible methods as the brain doesn't perform backward computation to learn high-level representation (Ma et al., 2020; N\u00f8kland, 2016; Jacot et al., 2018). Moreover, existing practical scenarios urge for scalable forward learning methods, when the black-box nature renders taking the derivative infeasible or difficult. For example, as the model parameters increase, machine learning (ML) systems usually integrate with third-party black-box APIs (Achiam et al., 2023).\nThere have been continuous efforts to develop learning algorithms that rely solely on the forward pass (Lillicrap et al., 2020). The forward learning uses multiple queries on one data point to estimate the gradient (Spall, 1992; Zhang et al., 2024). The high dimensionality and the rugged loss landscape of ML problems pose arduous challenges for deriving a low-variance gradient estimator. Current Literature has demonstrated that a sufficient number of queries on each data point is necessary for successful training (Chen et al., 2023; Zhang et al., 2024). To achieve good gradient estimation and task performance, all existing methods equally assign a large number of queries to different data points, neglecting the varying difficulty of gradient estimation at these data.\nHowever, it is not always helpful for the forward learning algorithms to increase the number of queries. Especially for the large model training on a large dataset, it usually requires an extensive"}, {"title": "2 RELATED WORK", "content": "Backpropagation-free learning. Without BP, people have designed algorithms drawing inspiration from biological social behavior and evolution theory Wierstra et al. (2014). Swarm intelligent algorithms, for example, particle swarm optimization (Vaz & Vicente, 2009), optimize a black-box problem by iteratively tracking the best candidate in the population. Evolutionary algorithms, for example, natural evolutionary strategies, inject random noise into the model and optimize along the optimal direction along the noise (Salimans et al., 2017). Both swarm intelligence algorithms and evolution algorithms lack sufficient theoretical analysis and the performance would drop as the parameters increase. Forward gradient (Baydin et al., 2022; Silver et al., 2021), applying the chain rule from a different direction than BP, utilizes forward-mode automatic differentiation (AD) to train the ML model. Forward-mode AD needs specific AD software and full access to the model structure. Therefore, training the deep model under black-box scenarios is not feasible by the forward gradient (Ren et al., 2022).\nPerturbation-based forward learning. Besides the heuristic algorithms, researchers have devised surrogate methods to approximate the first-order gradients, such as SPSA. The SPSA injects noise with opposite signs into the model parameters to form a finite-difference style estimator. Recently, Mezo (Malladi et al., 2023) applied SPSA to fine-tune the language model. DeepZero (Chen et al., 2023) integrates SPSA with sparsity and trains the network from scratch with many queries. However, their methods still have some limitations and their query budgets are equally allocated, neglecting the data difference. Jiang et al. (2023) extends the likelihood ratio estimator to train a wide range of neural networks, i.e. CNN (He et al., 2016), RNN (Dey & Salem, 2017), GNN (Scarselli et al., 2008), SNN (Ghosh-Dastidar & Adeli, 2009), whereas they don't verify their method on modern architecture, i.e., Transformers (Vaswani, 2017). There is still a huge research gap for improving the scalability of forward learning.\nMachine learning for black box scenarios. The applications to real-world black-box scenarios call for scalable BP-free algorithms. When deploying ML algorithms on specific hardware systems, computation resources are limited and BP becomes infeasible. In the fields of physics and chemistry, ML models have to interact with environments that include non-differentiable operations (Momeni et al., 2023; Gu et al., 2021). Moreover, extremely large models are often only accessible through third-party API (Sun et al., 2022). Evolutionary algorithms and reinforcement learning have been applied to tune the prompt for the black-box language model (Diao et al., 2022)."}, {"title": "3 PRELIMINARY ON FORWARD LEARNING", "content": "Given a generic neural network with no assumption on its architecture, the input is denoted as $x \\in \\mathbb{R}^{d_x}$, and the output is given by $y = \\phi_2(\\phi(\\phi_1(x); \\theta)) \\in \\mathbb{R}^{d_y}$, where $\\phi_1(\\cdot)$ and $\\phi_2(\\cdot)$ are black-box parts, and $(\\cdot; \\theta)$ is the trainable structure parameterized by $\\theta \\in \\Theta \\subset \\mathbb{R}^{d_\\theta}$. Training the neural network is to solve such an optimization: $\\min_{\\theta \\in \\Theta} \\mathbb{E}_{x\\in \\mathcal{X}} L(y)$, where $\\mathcal{X}$ is the dataset for training, and $L(\\cdot)$ is an evaluation procedure yielding the loss feedback. Due to the growing scale of parameters in modern neural networks and the dataset, stochastic gradient descent has essentially become the only feasible solution method. The primary challenge remains in computing the gradients for each batch efficiently.\nIn addition to approaches relying on computation graphs like BP, forward-learning algorithms estimate gradients by perturbing the neural activity and observing the correlation between the injected perturbation and the final loss value, thereby solving the stochastic version of the problem: $\\min_{\\theta} \\mathbb{E}_{x\\in \\mathcal{X}} [L(y)]$. For instance, Jiang et al. (2023) perturb the intermediate result to perform LR estimation, i.e., $y = \\phi_2(\\phi(\\phi_1(x); \\theta) + z)$, where $z$ is the injected noise with a density $f(\\cdot)$. Denote the Jacobian matrix of $a \\in \\mathbb{R}^{d_a}$ with respect to $x \\in \\mathbb{R}^{d_b}$ as $\\mathcal{D}_x a \\in \\mathbb{R}^{d_a \\times d_b}$. The loss gradient can be estimated by\n$\\nabla_{\\theta} \\mathbb{E}[L(y)] = \\mathbb{E}[-L(y) \\mathcal{D}_y(\\phi_1(x); \\theta) \\nabla_{\\theta} \\ln f(z)].$ (1)\nThe SPSA family injects noise to the parameters (Spall, 1992; Salimans et al., 2017), i.e., $y = \\Phi_2((\\Phi_1(x); \\theta + z))$. For continuous noise distributions, the gradient estimation can be derived as a special case of equality (1) as follows:\n$\\nabla_{\\theta} \\mathbb{E}[L(y)] = \\mathbb{E}[-L(y) \\nabla_{\\theta} \\ln f(z)].$ (2)"}, {"title": "4 METHOD", "content": "4.1 OPTIMAL ALLOCATION VIA LIKELIHOOD RATIO METHOD\nDefinition. The query allocator is defined as a random vector $A = (A_1,\\ldots, A_B)$, where each component $A_j$ represents the (relative) number of queries allocated to the $j$-th data point in the batch. The allocator is assumed to follow a probability measure $A \\sim P(A|X; \\Phi)$, which is parameterized by $x \\in \\mathcal{A}$ and conditioned on features $\\Phi$, such as the loss. At each step of neural network training, a sample of $A$ is drawn from this distribution, and queries are allocated to data points based on the sample. In this work, we select a Gaussian Allocator (GA)\n$A \\sim \\mathcal{N}(\\mu, \\Sigma_{\\lambda}; \\Phi),$ (4)\nwhere $\\lambda = (\\mu, \\Sigma) \\in \\mathbb{R}^B \\times \\mathbb{R}^{B \\times B}$. The matrix $\\Sigma$ captures the correlation structure between data points and facilitates the allocation of queries. Intuitively, structurally similar data points possess similar levels of importance, leading to a similar trend in query allocation. It is important to note that GA has a positive probability of generating negative samples. In practice, any data point receiving a negative allocation is assigned zero queries.\nBernoulli Allocator (BA) is another lightweight alternative, similar to the idea in Qin et al. (2023). In an equal allocation scenario, each data in the batch receives A queries. The BA introduces a probabilistic mechanism where, with probability $p$, the number of queries assigned to a data point is reduced to A/2; otherwise, it remains at A. The probability $p$ is the only parameter of the allocator.\nIt is important to note that A represents the relative number of queries, and thus the actual allocation proportion to the $j$-th data point is given by $A_j/\\sum_{i=1}^{B} A_i$. This definition eliminates the need for imposing a fixed total budget constraint in the following allocator optimization problem. However, as a consequence, we must specify that the total query budget per step is fixed at $\\sum_{i=1}^{B} A_i = A \\cdot B$ during the training process. Note that, since the data points selected in the mini-batch differ at each step, A is actually a function of t. For simplicity of notation, we omit this dependency in the remainder of the paper.\nOptimization of the Query Allocator. We employ a gradient-based method to optimize the allocator parameters A, introducing an additional optimization step before each iteration of neural network"}, {"title": "5 EXPERIMENTS", "content": "5.1 FINETUNING VISION TRANSFORMER\nExperimental setting: We evaluate our model's performance using a diverse set of widely used benchmark datasets, each chosen for its unique characteristics and specific challenges contributing to"}, {"title": "5.2 BLACK-BOX TUNING FOR MODEL AS A SERVICE", "content": "We can tune the prompts for vision-language models (VLMs) in a Model-as-a-Service (MaaS) environment using the OPS-LR framework, as shown in Figure 2. We address the challenge of fine-tuning VLMs without access to model internals or gradient information through a scalable black-box optimization approach. We use CLIP (Radford et al., 2021), with embedding dimensions of $D_T = 512$ for the text encoder and $D_I = 756$ for the image encoder, as the backbone foundation model. Both the text encoder and the image encoder are kept frozen as black-box modules. Tunable prefix or suffix prompt tokens are injected into the text and image token sequences, respectively:\n$S_T = [\\text{cls}, p_T, e_T] \\in \\mathbb{R}^{(1+n_T+m_T)\\times D_T}$ is the input sequence for the text encoder, $S_I = [\\text{cls}, e_I, p_I] \\in \\mathbb{R}^{(1+m_I+n_I)\\times D_I}$ for the image counterpart. Previous researches have suggested"}, {"title": "5.3 ALIGNMENT BETWEEN BLACK-BOX FOUNDATION MODEL", "content": "Foundation models like GPT (Brown, 2020), LLaMa Touvron et al. (2023), Vicuna (Chiang et al., 2023), and CLIP (Radford et al., 2021) contain rich domain knowledge from the pretraining. Multimodal tasks, such as video captioning (Krishna et al., 2017) and video grounding(Gao et al., 2017), require models to have sufficient cross-domain understanding, and proper alignment between different modalities is essential. Aligning foundation models from a single modality is a more economical approach than pretraining from scratch using multimodal data. It is a common practice to add an adapter between the visual encoder and the Large Language model. The adapter is a linear projector, $g(\\cdot)$, that projects the visual embedding to the textual embedding space. Since foundation models contain billions of parameters, the backward pass through the model requires extra memory for storing the computation graph, and recursive computations through such a large pre-trained model are time-consuming. Our OPS-LR framework efficiently bypasses the need for recursive computation to estimate the gradient with a large foundation model in between, as shown in Figure 3a.\nThe training paradigm for the multimodal alignment follows an autoregressive style using image-text pairs < I,T >. We use a frozen CLIP ViT-L/14 as the visual encoder, denoted as ViT. The CLS tokens of the output sequence of ViT are utilized as the global feature for the frame. We denote the visual token after the projection as $Z_V = g(ViT(I)_{CLS})$. The visual token is then concatenated with the text tokens sequence: $[Z_V, t_1, t_2, ..., t_m]$, where $[t_1, t_2, ..., t_m]$ is the text tokens sequence with a length of m. Consequently, we can train the adapter on the concatenated sequence with the autoregressive objective of the LLM. We report the wall time for the feature alignment procedure on the LCS-558K dataset (Liu et al., 2024). Our OPS-LR framework can reduce almost half of the training time since the recursive backward computation is skipped. From Figure 3b, the wall time with or without the allocator is almost the same, which further illustrates that our allocator is lightweight and has minimal impact on runtime."}, {"title": "5.4 ABATION STUDY", "content": "We conduct an ablation study using ViT-base on the CIFAR100 dataset. We investigate the necessity of the allocation policy for the forward-learning training and determine whether GA or BA is the better allocator. Furthermore, we discern the varying degrees of difficulty in estimation across different network components. The results are shown in Figure 4.\nImpact of different query budgets. To further investigate the necessity of the procedure of query budget allocation, we compare the performance increment under various query budgets for different allocation policies. Traditionally, the queries are equally allocated (EA) across different data. The performance improvements offered by GA and BA are considerably more significant than those of EA. When the number of queries per data is small, the benefit from the allocation is still non-ignorable. In other words, the more query budget you have, the greater the improvement gains from allocation. Meanwhile, the ablation on different transformer layers indicates that the variance of the gradient increases as the layer goes deeper, which validates our subsampling technique.\nImpact of different allocators, Gaussian or Bernoulli. We compare different allocators in Figure 4a, 4b,4d, and 4e. GA controls the allocation with the mean vectors and the covariance matrix. The covariance matrix captures the similarity between different data points. Structurally similar data points possess similar levels of importance. Therefore, the allocation policy for those data points should be correlated. If the covariance matrix is diagonal, the similarity between data points is ignored, which could undermine the performance of the allocation strategy. Compared with the GA, the BA is a simpler strategy. Intuitively, it prunes the queries on unimportant data points to eliminate unnecessary computation. Our ablation study suggests that GA is superior to BA.\nEstimation on different components of Transformer. We present the cosine similarity results on the multi-head attention (MHA) and the feed-forward network (FFN) in Figure 4a, 4b, 4c, and 4f. Estimation on the FFN is easier than on the MHA. In the Transformer block, the MHA precedes the FFN, which may explain this phenomenon. The low cosine similarity on MHA attention of deep layers may lead to the performance gap on large-scale dataset like ImageNet. It is also worth noting that a large number of queries when training Transformer can improve the estimation quality. However, the memory cost of increasing queries is extremely high since the complexity of the attention module is $O(n^2)$. Integrating efficient MHA techniques, such as Flash Attention (Dao et al., 2022), is left for future work."}, {"title": "6 CONCLUSIONS", "content": "In this paper, we unify different forward learning under the perturbation-based framework. We propose an optimal allocation method to accelerate forward learning by controlling the gradient variance in the mini-batch. Theoretical results show that the allocation can be conducted in a lightweight style and the optimality of the allocation is proved. Compared with other forward learning methods, we achieve the SOTA performance in fine-tuning ViT. With the improved scalability, we apply our method to two black-box scenarios for the foundation model. However, there is still a non-neglectable gap compared with BP. Other techniques of accelerating forward learning are left to future work. Moreover, forward learning can optimize black-box objectives, such as human preference, where taking derivative is infeasible. It is also an interesting future direction."}]}