{"title": "stEnTrans: Transformer-based deep learning for spatial transcriptomics enhancement", "authors": ["Shuailin Xue", "Fangfang Zhu", "Changmiao Wang", "Wenwen Min"], "abstract": "The spatial location of cells within tissues and organs is crucial for the manifestation of their specific functions. Spatial transcriptomics technology enables comprehensive measurement of the gene expression patterns in tissues while retaining spatial information. However, current popular spatial transcriptomics techniques either have shallow sequencing depth or low resolution. We present stEnTrans, a deep learning method based on Transformer architecture that provides comprehensive predictions for gene expression in unmeasured areas or unexpectedly lost areas and enhances gene expression in original and inputed spots. Utilizing a self-supervised learning approach, stEnTrans establishes proxy tasks on gene expression profile without requiring additional data, mining intrinsic features of the tissues as supervisory information. We evaluate stEnTrans on six datasets and the results indicate superior performance in enhancing spots resolution and predicting gene expression in unmeasured areas compared to other deep learning and traditional interpolation methods. Additionally, Our method also can help the discovery of spatial patterns in Spatial Transcriptomics and enrich to more biologically significant pathways. Our source code is available at https://github.com/shuailinxue/stEnTrans.", "sections": [{"title": "Introduction", "content": "Traditional gene expression researches typically focus only on the overall gene transcript counts in entire tissues, lacking the preservation of spatial positioning information within the tissue. The spatial position of cells within tissues can have a significant impact on their functions. Therefore, neglecting the spatial information of cells may lead to an insufficient understanding of gene functions and regulatory mechanisms. Spatial transcriptomics (ST) technology aims to detect the quantity of gene transcripts within tissues while preserving spatial location information [21]. ST technology provides the capability to examine in detail the spatial distribution of gene expression at the tissue or cellular level.\nThis allows researchers to gain a more accurate understanding of the gene expression patterns in different regions [25,20], delving deeper into the exploration of cellular heterogeneity and interactions between neighboring cells. In light of the substantial advantages offered by ST technoloies, it have been used in various field of biology, such as tumor heterogeneity [14], embryonic development [19] and Neuroanatomy [11].\nExisting ST technologies mainly fall into two categories: (1)imaging-based approaches, directly observing and quantitatively analyzing mRNA or protein ex-pression in tissues without the need for prior RNA sequencing, such as STARmap [28]. (2)next-generation sequencing (NGS)-based approaches [3], capturing RNA in tissues and sequencing it to obtain a global map of gene expression. However, both approaches have their respective drawbacks.Imaging-based approaches offer higher spatial resolution, suitable for observing cellular and subcellular details. But they may have limitations in detecting the number of genes. NGS-based approaches provide a comprehensive understanding of global gene expression in tissues and can simultaneously detect a large number of genes, suitable for comprehensive bioinformatics analysis [15]. But they face two major challenges [17]:1.lower spatial resolution. Such as 10X Visium [22], a spot with a diameter of 55 \u00b5m may contain 1 to 30 cells. In ST [26], spot is 100 \u00b5m in diameter and may contain hundreds of cells. This makes it challenging to study individual differences between cells, such as cell subtypes, mutations, and expression het-erogeneity. 2.Gaps Between Spots. The center-to-center distance between spots in ST is 200 \u00b5m, and in Visium, it is 100 \u00b5m. Clearly, there are significant uncovered spatial between spots, leaving large areas in the tissue unmeasured. This can affect researchers' comprehensive understanding of the entire cell pop-ulation, hindering a full representation of the true state of the tissue, especially in scenarios where studying cell heterogeneity and local differences is crucial.\nHere, we propose stEnTrans, a deep learning method using self-supervised learning [13] that enhances the resolution of gene expression through prediction in unmeasured areas between spots to obtain a high-resolution and high quality gene expression profiles. stEnTrans requires no additional data, such as histology images, relying solely on spatial gene expression data as input. It comprehensively integrates the relevant information across different positions within genes and the correlations among different genes within the tissue. We applied stEnTrans to six datasets, including four real datasets sourced from the ST and 10X Visium platforms and two standard array datasets were simulated from STARmap and Stereo-seq data using coordinate mapping. The experimental results demonstrate the superiority of stEnTrans compared to other methods in terms of prediction accuracy and clarity of gene expression profiles, while also manifesting more biologically meaningful pathways."}, {"title": "Method", "content": "Our model undergoes two distinct phases: Pretrain and Enhance (Fig. 1). During the Pretrain phase, We utilize down-sampling on the original gene expression"}, {"title": "Data Pre-processing", "content": "stEnTrans only requires a gene expression matrix with spatial coordinates. We define the ST data as two matrices: (1) gene expression matrix, $X_{m \\times n}$, which contains m spots and n genes. The value of $X_{ij}$ represents the expression level of j-th gene in the i-th spot. (2) spatial coordinate matrix, $C_{m \\times 2}$. Its i-th row corresponds to the same spot as the i-th row of matrix $X_{m \\times n}$. The values of $C_{i0}$ and $C_{i1}$ constitute the coordinate information of the i-th spot in two-dimensional space. We treat the expression of each gene in space as a sample.\nData source All datasets analyzed in this paper are existing and publicly avail-able. The human melanoma ST data (HM) can be found at https://www.spatia lresearch.org/resources-published-datasets/doi-10-1158-0008-5472-c an-18-0747 [26]. The STARmap mouse placenta (MP) can be found at https://codeocean.com/capsule/9820099/tree/v1 [9]. The Stereo-seq data from the adult mouse hemi-brain (AMHB) can be found https://db.cngb.org/stomics/mosta/ [5]. The human breast cancer spatial transcriptomics data (HBC) is available from the https://www.10xgenomics.com/products/xenium-in-situ/preview-dataset-human-breast [12]. The Human Invasive ductal carcinoma spatial transcriptomics data (IDC) is available from the https://support.10xgenomics.com/spatialgene-expression/datasets/1.2.0/V1_Human_Invasive_Ductal_Carcinoma. The mouse brain sagittal posterior data (MBSP) is avail-able from the https://www.10xgenomics.com/datasets/mouse-brain-serial-section-1-sagittal-posterior-1-standard-1-1-0.\nPre-processing for gene expression matrix The j-th column of X rep-resents the expression level of the j-th gene in the tissue. We denote this m-dimensional vector as $X^j$. Based on spatial coordinate information of all spots, $X^j$ can be mapped onto a plane and transformed into a matrix of shape (u, v). We denote this matrix as $G^j$, which can be considered as a gene expression profile. Specifically, the value at the $r_i$-th row and $c_j$-th column of $G^j$ represents the expression level of the j-th gene in the spot with coordinates $(r_i, c_j)$.In addition, we need whether-in-tissue matrix M, which has the same shape as $G^j$, to indicate the presence or absence of spots. All its elements are either 0 or 1."}, {"title": "Self-supervised learning", "content": "In the realm of data enhancement for spatial transcriptomics, where no labels are available, so we employ a self-supervised learning approach [13]. We design auxiliary tasks that utilize the data itself as supervisory information. The entire process is divided into two phases, denoted as Pretrain and Enhance (Fig. 1). In Pretrain phase, we train the model using both LR and original gene expression profiles. Then in Enhance phase, we input the original data and obtain HR gene expression profiles.\nPretrain phase stEnTrans achieves gene expression interpolation by employing Transformer Encoder [27] to extract global features of the spatial distribution of all genes within the tissue, thereby extending the size of the gene expression pro-files from (u, v) to (2u, 2v) (Fig. 1). In this phase, we train model on the LR gene set $G_{lr} = \\{G^0_{lr}, G^1_{lr},\u2026\u2026,G^{n-1}_{lr}\\}$ and original gene set $G = \\{G^0,G^1,\u2026,G^{n-1}\\}$."}, {"title": "Details of the proposed stEnTrans", "content": "Transformer uses self-attention mechanisms to capture dependencies among dif-ferent positions in the input sequence, modeling interactions among all tokens [27] (Fig. 1). The standard Transformer architecture is designed for processing 1-D sequential data. To adapt it for handling 2-D gene expression maps, we re-shape the maps into a series of patches [7]. P represents the height and width of the patches. Suppose that size of the input x is (H, W), so the desired size of the output is (2H, 2W). We achieve this by applying four trainable convo-lutional structures, where the convolutional kernel size and stride are both set to patch size, followed by concat, and finally flattening to map the tokens to $4 \\times P^2$ dimensions. In addition, if the size of the input profile are not multiples of the patch size, we need to perform zero-padding on the profile. This process corresponds to the patch embedding in stEnTrans:\n$x_k = x * W_k + b_k, k = 0,1,2, 3,$\n$x' = concat(x_0, x_1, x_2, x_3),$\n$x = Flatten(x'),$\nwhere $x, x_k, x', \\hat{x}$ have shapes (H,W), ($P^2$, H/P,W/P), (4, $P^2$, H/P,W/P) and (N, $4P^2$) respectively, $W_k$ and $b_k$ are the filter parameters and biases of convolutional structures. Here, $N = HW/P^2$, which represents the number of generated patches and is also the input sequence length for the Transformer Encoder. We refer to above process as Patch Embedding.\nDue to the fact that the self-attention mechanism itself does not inherently contain information about the position of tokens in the sequence, it is necessary to introduce positional encoding to help the model understand the order of the input sequence. The relative positional embeddings as described in [24] is not applicable to our method as the sequence lengths differ between phases Pre-train and Enhance. so stEnTrans adopts sine and cosine functions with different frequencies to encode positional information:\n$Pos(\\hat{x})(p,q) =\\begin{cases} sin(p/10000^{2q/d}),  &  p \\mod 2 = 0\\\\ cos(p/10000^{2(q-1)/d}), &  p \\mod 2 = 1\\end{cases}$\n$p = 0, 1, \u2026\u2026\u2026, N - 1, q = 0, 1, \u2026\u2026\u2026, 4P^2,$\n$\\hat{x}_0 = x + Pos(x),$\nwhere Pos() and $\\hat{x}$ have the same shape (N, $4P^2$), p is the position, q is the dimension and d is the patch embedding dimension.\nThen, stEnTrans extracts global features of the LR profiles through the Transformer Encoder, which consists of multiple Transformer blocks. The Trans-former block is mainly composed of multiheaded self-attention (MSA) and MLP blocks. LayerNorm is applied before each block and residual connections are applied after each block [4,18].\nAssuming the input of the MSA block is U and the output is Z, here is a description of the multi-head self-attention block:\n$[Q_i, K_i, V_i] = UW^i + b_i, i = 1 . . . h,$\n$head_i = softmax(\\frac{Q_iK_i^T}{\\sqrt{d_i}})V_i, i = 1 ... h,$\n$Z = concat(head_1,..., head_h),$\nwhere h denotes the numbers of different self-attention operations in multi-head self-attention, The queries, keys, and values are linearly projected h times with different learnable parameters, d is set to a fixed shape of $4P^2/h$ and $W_i$ have the shape of ($4P^2$, $4P^2/h$). This parallel processing allows the model to capture diverse patterns and relationships. We can represent the above process using the function MSA(\u00b7):\n$Z = MSA(U).$\nIn the MLP sub-layer, there are two linear transformations with a GELU activation function in between. Suppose that the input is Z, the process can be described as follows:\n$MLP(Z) = GeLu(ZW_1 + b_1)W_2 + b_2,$\nwhere Z and MLP(Z) hava the same shape (N, $4P^2$). Assuming D = $4P^2$, then $W_1 \\in R^{D \\times 2D}$ and $W_2 \\in R^{2D \\times D}$.\nAssuming the input of the l-th Transformer block is $x_{l-1}$, we denote its out-put as $x_l$, which is also the input of the l+1-th block. Specifically, $x_0$ serves as the input to the first block. The entire process of gene expression maps enhancement in stEnTrans within the Transformer Encoder can be described as follows:\n$x'_l = MSA(LN(x_{l-1})) + x_{l-1},        l = 1,..., N,$\n$x_l = MLP(LN(x'_l)) + x'_l,       l = 1,..., N,$\nAfter passing through the Transformer Encoder, we perform a reverse em-bedding operation on the 1D sequence of token embeddings $\\hat{x}_N$, transforming it into 4-channel HR gene expression profile:\n$y' = Flatten^{-1}(\\hat{x}_N),$\n$\\Delta y(c, i, j) = y'(c, r, \\lfloor\\frac{i}{P}\\rfloor, \\lfloor\\frac{j}{P}\\rfloor), c = 0, 1, 2, 3,$\nr = P(i \\mod P) + (j \\mod P), i = 0, . . ., H - 1, j = 0, . . ., W-1,$\nwhere y', $\\Delta y$ have shapes (4, $P^2$,$\\frac{H}{P}, \\frac{W}{P}$) and (4, H, W) respectively, r represents the position within a patch and its value increments from left to right and top to bottom within each patch, starting from 0.\nNext, inspired by residual networks [8], we directly combines the original data and each channel of $\\Delta y$. In this case, we set $\\Delta y = [\\Delta y_0, \\Delta y_1, \\Delta y_2, \\Delta y_3]$, where $\\Delta y_c$ hava the same shape (H, W), we get:\n$y = [y_0, y_1, y_2, y_3] = [\\Delta y_0 + x, \\Delta y_1 + x, \\Delta y_2 + x, \\Delta y_3 + x].$\nFinally, we can obtain HR gene expression profile by merging the 4-channel expression profile Y. We denote the HR expression profile as $y_{hr}$, and the calcu-lation process is as follows:\n$y_{hr}(p, q) = \\begin{cases} y(0, \\lfloor\\frac{p}{2}\\rfloor, \\lfloor\\frac{q}{2}\\rfloor), & p \\mod 2 = 0, q \\mod 2 = 0\\\\ y(1, \\lfloor\\frac{p}{2}\\rfloor, \\lfloor\\frac{q}{2}\\rfloor), & p \\mod 2 = 0, q \\mod 2 = 1\\\\ y(2, \\lfloor\\frac{p}{2}\\rfloor, \\lfloor\\frac{q}{2}\\rfloor), & p \\mod 2 = 1, q \\mod 2 = 0\\\\\\ y(3, \\lfloor\\frac{p}{2}\\rfloor, \\lfloor\\frac{q}{2}\\rfloor), & p \\mod 2 = 1, q \\mod 2 = 1\\end{cases}$\nwhere $y_{hr}$ is divided into a series of non-overlapping 2x2 sub-maps, each sub-map's top-left, top-right, bottom-left, and bottom-right respectively come from channels 0, 1, 2, and 3 of y."}, {"title": "Experimental Results", "content": "To validate the interpolation capability of stEnTrans, we evaluated two genes with different spatial patterns on IDC data, ZNF703 and MUC1. We used down-sampled data as simulation, the original data as ground truth, and applied stEn-Trans, DIST [32], Linear, Cubic, NN and NEDI [16] for interpolation on the"}, {"title": "More accurate interpolation capability", "content": "To further illustrate the superiority of stEnTrans, we calculated the Pearson cor-relation coefficients (PCC) between ground truth and each imputed expression for all spots of the genes after quality filtering across six datasets.\nTo illustrate that stEnTrans can also be applied to other platforms, we cre-ated a simulated ST data from STARmap data. By proportionally mapping the coordinates of these pseudo-spots in spatial dimensions and fine-tuning, we can simulate array-based ST data. RNA molecules of 903 genes have been determined in the mouse placenta for this dataset. ClusterMap clusters RNA into subcel-lular structures, generating 7224 pseudo-spots representing subcellular sizes [9], which closely align with our simulated data. Continuing, we simulated another ST data from Stereo-seq data, which provides subcellular resolution spatial ex-pression in the adult mouse hemi-brain [5], using the same spatial coordinate mapping method as described above. Additionally, there is one real ST dataset and three 10X Visium datasets. We calculated PCCs between ground truth and each imputed expression for all spots of the genes after quality filtering across the aforementioned six datasets and showed the results in (Fig. 3).\nstEnTrans achieved higher median in gene prediction PCCs between im-puted and true expression compared to all other methods across six different datasets (median: in HM data, stEnTrans=0.636; in MP data, stEnTrans=0.554; in AMHB data, stEnTrans=0.513; in HBC data, stEnTrans=0.584; in MBSP data, stEnTrans=0.606; in IDC data, stEnTrans=0.537). Even in HM data, HBC"}, {"title": "Better help to discover spatial patterns", "content": "Next, we explore whether stEnTrans can help discover spatial patterns in melanoma ST data. We utilize a tool, Sepal, which employs diffusion-based modeling to identify transcripts with spatial patterns in the transcript profiles [2]. This method is applied to original and imputed mel ST data using stEnTrans. Following Sepal's standards, we rank each transcript profile according to their degree of randomness, and then extract the top-150 transcript profiles as experimental"}, {"title": "Ablation Study", "content": "To assess the contributions of absolute positional encoding (denote as Pos) and the Res module to performance, we conducted a ablation study. Our ablation study is based on simulated ST data from STARmap mouse placenta (MP), simulated ST data from Stereo-seq adult mouse hemi-brain (AMHB), human melanoma ST data (HM), Human Invasive ductal carcinoma spatial transcrip-tomics data (IDC), human breast cancer spatial transcriptomics data (HBC), mouse brain sagittal posterior data (MBSP). All experiments are evaluated us-ing PCC.\nSpecifically, we initially assessed the performance of the original model by calculating PCCs on six datasets as the baseline for comparison. Subsequently,"}, {"title": "Discussion And Conclusion", "content": "In our research, we propose stEnTrans, a deep learning method based on Trans-former, which can impute the gene expression on unmeasured areas that are not covered between spots and accidentally lost locations during sequencing through self-supervised learning, enhance the expression of all spots, and thus compre-hensively improve the quality of spatial transcriptomics data. Our method does not rely on any other data, such as histological images, and only requires a gene expression matrix with spatial coordinates to improve gene expression profiles to high resolution. Compared with other methods of similar function, it has higher precision and the obtaining high-resolution gene expression profiles have more delicate and smooth characteristics.\nIn spatial transcriptomics studies, identifying genes with spatial expression patterns is very important for researching various physiological and pathologi-cal processes. However, due to limitations in existing technologies, the statistical power is often low, making it challenging to identify genes with spatial expression patterns within small local regions using raw spatial transcriptomic data. stEn-Trans has the capability to enhance the resolution of gene expression profiles, which can help to discover the spatial patterns of genes, making disease-related genes have more significant spatial patterns. In addition, it can also help to discover more biologically meaningful pathways.\nThe results of ablation experiments show that both Res module and absolute position encoding are indispensable to the network and can improve the perfor-mance of the network, but the use of absolute position encoding has a higher impact on improving the network's performance.\nDespite the significant achievements of stEnTrans in improving the resolu-tion of gene expression profiles by imputing, there are still several challenges in practical applications. Our next research direction is not only to impute the unmeasured areas, but also to increase the resolution to the sub-spot level by dividing the spot into multiple sub-spots without relying on any other data."}]}