{"title": "QPM: Discrete Optimization for Globally Interpretable Image Classification", "authors": ["Thomas Norrenbrock", "Timo Kaiser", "Bodo Rosenhahn", "Sovan Biswas", "Ramesh Manuvinakurike"], "abstract": "Understanding the classifications of deep neural networks, e.g. used in safety- critical situations, is becoming increasingly important. While recent models can locally explain a single decision, to provide a faithful global explanation about an accurate model's general behavior is a more challenging open task. Towards that goal, we introduce the Quadratic Programming Enhanced Model (QPM), which learns globally interpretable class representations. QPM represents every class with a binary assignment of very few, typically 5, features, that are also assigned to other classes, ensuring easily comparable contrastive class representations. This compact binary assignment is found using discrete optimization based on predefined sim- ilarity measures and interpretability constraints. The resulting optimal assignment is used to fine-tune the diverse features, so that each of them becomes the shared general concept between the assigned classes. Extensive evaluations show that QPM delivers unprecedented global interpretability across small and large-scale datasets while setting the state of the art for the accuracy of interpretable models.", "sections": [{"title": "1 INTRODUCTION", "content": "Deep Learning has made remarkable advances in various fields, such as image classification, segmen- tation or generation . For high-stakes decisions, e.g. applying image classification in the medical domain, legislation moves towards requiring a certain level of interpretability , whose measurement is a fairly open task on its own. However, some desirable and measurable qualities of explanations have been identified . Human-friendly explanations should be contrastive , diverse , general and compact . As humans can consider 7 \u00b1 2 cognitive aspects at once , an explanation size of up to 5 is desirable. Additionally, an explanation should faithfully explain the model, which is where many post-hoc methods fail . Therefore, we focus on models that are interpretable by design with built-in faithful explanations.\nPrevious works, such as SENN , Q-SENN , Concept Bottleneck Model (CBM) , Label-free CBM , PIP-Net , ProtoPool , ProtoTree , ProtoPNet or the SLDD-Model rely on combining understandable features in an interpretable manner. However, while most models can offer convincing local explanations for a single decision, they struggle with the global explanation of their behavior in general. Some models with global interpretability do not show competitive accuracy and it is debated , if ensembles of very deep decision tress  or dense high-dimensional linear layers are truly intrinsically interpretable as they lack desired qualities like compactness. For that reason PIP-Net focuses on learning sparse class representations. These representations lie in a high dimensional feature space, which causes PIP-Net's features to be connected to very few or only one class each. This leads to the emergence of features that are already detecting the class and no general concept. The sparse representations of PIP-Net thus have no interpretable meaning, as classes are represented with themselves. To alleviate that issue, the SLDD-Model and Q-SENN reduce both dimensions of compactness: They not only reduce the number of features per class nwe, which in isolation leads to class-specific features but also the number of features in total n to be significantly below the number of classes nc. That causes each of the fewer features to be assigned to multiple classes, which prevents the emergence of class detectors. However, these models still have shortcomings when it comes to global interpretability. Their class representations are real-valued, or ternary for Q-SENN, include a bias, and are composed of a varying number of features. Therefore, the global class explanations are hardly comparable or contrastive.\nIn this work, we introduce the Quadratic Programming Enhanced Model (QPM) that offers inter- pretable class representations and sets a new state of the art for the accuracy of compactness-based interpretable models. It represents every class with the binary assignment of a low user defined number of features nwc, which themselves are contrastive, general and diverse. We typically choose 5, in line with previous work , to accommodate for human limita- tions . As shown in fig. 1, QPM offers built-in faithful global explanations for classes"}, {"title": "2 RELATED WORK", "content": "Research towards Interpretable machine learning includes the direct design of models providing inter- pretability by themselves ; Sawada & Nakamura, 2022; Norrenbrock et al., 2022; Nauta et al., 2023; 2021; Rymarczyk et al., 2022; Zarlenga et al., 2022; Marconato et al., 2022; Koh et al., 2020; Rymarczyk et al., 2021; Chen et al., 2019) or to find post-hoc methods which aim to explain the decision process or single features of the model  . As our method is designed to find a compact set of human-understandable features, our work can be assigned to the former type, which we focus on within this section. However, the alignment of the learned features of our proposed QPM with human attributes can be guided by the post-hoc methods. When considering the interpretability of a model, a distinction is made between local interpretability, which refers to the explanation of a single decision, and global interpretability,"}, {"title": "3 METHOD", "content": "Our proposed QPM is designed for the interpretable classification of an image as a class c\u2208 {C1,C2,...,Cnc}. The QPM uses a deep feature extractor \u03a6 to compute feature maps M\u2208Rnxwm\u00d7hm of width wm and height h\u2122 and averages them into a feature vector f* \u2208 Rn. The classification result y \u2208 Rne of the QPM is the matrix multiplication between the sparse binary matrix W* \u2208 {0,1}ne\u00d7n and the features f* formalized as y = W*f*.\nThe pipeline of our proposed method is shown in fig. 3 and is motivated by , following their presentation and notation. It starts with training a conventional black-box model with initially nf features using the feature diversity loss Ldiv . A detailed explanation of Ldiv is included in appendix M. Using the black-box model as starting point, we aim to find a selection of n out of the initial nf features and their sparse binary assignment W* to the classes to enable downstream interpretability. The feature extractor I is then fine-tuned with this solution fixed, so that the features adapt to the sparse solution and become a shared concept of the assigned classes. This is encouraged through selecting fewer features than there are classes, n < nc, and representing every class with the same number nwe, typically 5, of features. Using the same number of features for every class is beneficial for the interpretability in multiple ways. The class representations do not"}, {"title": "3.1 QUADRATIC PROBLEM", "content": "We consider the problem of selecting the n* out of nf features and assigning them to the classes as a binary quadratic problem, that can be solved globally optimal. Specifically, the feature selection s\u2208 {0,1}nf and assignment between features and classes W \u2208 {0,1}nc\u00d7nf are jointly optimized, with W* being W for the selected features. Given a similarity matrix A \u2208 Rnc\u00d7nf the main objective is to maximize the similarity ZA between the selected features and their assigned classes\n$$Z_A = \\sum_{c=1}^{n_c} (a_{c,d} \\cdot W_c)s$$\nwith indicating the Hadamard product. Here, s indicates whether a feature is selected and W describes if a feature is assigned to the class. Note that we use c to index classes and d for features. The sparsity and low-dimensionality are formulated as constraints for the optimization:\n$$\\sum_{d=1}^{n_f} s_d = n^*$$\n$$\\sum_{d=1}^{n_f} W_{c,d}s_d = n_{wc} \\forall c \\in \\{1,...,n_c\\}$$\nTo allow the QPM the differentiation between all classes and enable effective fine-tuning, we additionally add constraints that no two classes are assigned to the same set of features:\n$$(w_c \\cdot w_{c'})^Ts < n_{wc} \\forall c, c' \\in \\{1,...,n_c\\}$$\nNote that the constraints in eqs. (3) and (4) technically define a quadratically constrained quadratic program (QCQP). To make the QCQP computationally tractable, the constraints are relaxed and added iteratively for classes that violate the constraints. The efficient implementation is discussed in detail in section 4.1.1. The general formulation of the problem allows us to add further nuance to the optimization and include more desiderata. Since a high representational capacity is desired for the selected features, the cross-feature similarity matrix R \u2208 Rnf\u00d7 n f is incorporated to reduce the similarity between the selected features:\n$$Z_R = -s^T R s$$\nAdditionally, the selection of specific features can be guided via a selection bias b \u2208 Rnf\n$$Z_B = b^Ts,$$\nwhere a higher value bi leads to a preferred selection of the feature i. The combination of all these objectives leads to:\n$$\\max_{W,s} Z = \\max_{W,s} Z_A+Z_R+ Z_B$$\nThe formulation in standard form for quadratic problems +xTQx + c\u00b2x with Q capturing the quadratic terms ZA and ZR, and c incorporating the linear term ZB is included in appendix O."}, {"title": "3.2 CLASS-FEATURE SIMILARITY", "content": "The class-feature similarity matrix A with entries ac,d should reflect how beneficial the assignment of feature d to class c is for the classifier. As every feature gets assigned to multiple classes, which themselves become assigned to multiple features, the metric should focus on a robust positive relation between the activation and likelihood of a sample being of the respective class. This is captured by the Pearson correlation coefficient ac,d between the feature distribution f:,d and the label vector l\u2208 {0,1}nt, in which for all n\u021b training images a 1 indicates the label being c."}, {"title": "3.3 FEATURE-FEATURE SIMILARITY", "content": "Just maximizing eq. (1) can lead to very similar features being selected which is neither beneficial for interpretability nor for accuracy as representational capacity is lost and multiple features develop towards the same concept during fine-tuning. To prevent this, selecting similar features in A should be penalized in the objective. We choose the cosine similarity between the class similarities of two features d \u2260 d' in A for R with\n$$r_{d,d'} = \\frac{ReLU(a_{:,d})^T ReLU(a_{:,d'})}{\\lVert a_{:,d} \\rVert^2 \\lVert a_{:,d'} \\rVert^2}$$\nusing ReLU to focus on preventing redundant features and rd,d' = 0 for d = d'. As we are only interested in preventing the selection of highly similar features, we can clip all entries in R below an e to 0 to enable a fast solving of the QP. The details are discussed in section 4.1.1."}, {"title": "3.4 FEATURE-BIAS", "content": "The Feature-Bias b describes the benefit of selecting each feature. This can be used to steer the model towards specific desiderata. As diversity is generally preferred  for interpretable models, a bias towards more local features is used,\n$$b_d = \\frac{1}{n_T} \\sum_{j=1}^{n_T} f_{j,d} \\frac{max(S_{j,d}^1)f_{j,d}}{\\sum_{f_{j,d} = 1} ||f_{j,d}||}$$Here St is the softmax over the spatial dimensions of the d-th feature map for the image j. Scaling the feature bias by their activation leads to the selection of features that are more localized when their activation is high. Alternatively, the bias can be used to steer the selection towards other criteria the practitioner might identify as relevant, which we demonstrate in the appendix. We center b and scale the maximum absolute value to be A, whose strength defines the priority put on the bias."}, {"title": "4 EXPERIMENTS", "content": "Following prototype-based methods we applied our method to CUB-2011 and Stanford Cars . To showcase QPM's broad applicability, we also include results on the large-scale dataset ImageNet-1K , to which most interpretable methods are not applicable. Notably, CUB-2011 contains annotations of human concepts which we use to measure Structural Grounding. An overview of the used datasets is shown in Suppl. table 5. As our method is independent of the used backbone, we evaluated it across various architectures, but focus on Resnet50 in this paper. Similar results on Resnet34, Inception-v3 and Swin Transformer , as well as detailed results with standard deviations, are included in Suppl. appendix L. We do not apply our method to other interpretable models like PIP-Net , as QPM is an alternative way of inducing compactness and the features of PIP-Net are not general, thus ill-suited for a broad assignment."}, {"title": "4.1 IMPLEMENTATION DETAILS", "content": "We generally followed PIP-Net for the data preparation. Specifically, the images are first cropped to the ground truth bounding box for CUB-2011 and TravelingBirds . For all datasets, the images are resized to 224 \u00d7 224. Following PIP-Net, TrivialAugment is used and the strides of ResNets are also set to 1 to obtain more fine-grained feature maps. The remaining parameters, including dense training for 150 epochs on fine-grained datasets and directly using the pretrained model on ImageNet-1K with subsequent 40 epochs of fine-tuning, mirror the SLDD-Model and are described in appendix C. Note that QPM is trained more efficiently than Q-SENN, as it does not use multiple training iterations during fine-tuning. We set nwc = 5 and n = 50 for QPM, unless stated otherwise. We demonstrate the impact of changing the parameters in the ablation studies but choose these, as it is in line with prior literature , n** <ne, and it enables sufficiently compact explanations . The shown results, e.g. tables 2 and 3, are the mean across 5 seeds, with the exception of 3 for ImageNet-1K, PIP-Net and ProtoPool. For comparison, all models are exclusively pretrained on ImageNet-1K. This change did affect ProtoPool, but even with iNaturalist  pretraining, we could not reproduce the reported results by Rymarczyk et al. (2022)."}, {"title": "4.1.1 QUADRATIC PROBLEM", "content": "This section presents details on how the described quadratic problem with eq. (7) as objective is solved using Gurobi. We incorporated deduplication and the assignment of an equal number of features to all classes of eqs. (3) and (4) using an iterative approach with relaxed constraints. Specifically, the model is optimized without these constraints, but instead 1TWs = nwcnc. Then, after each iteration, all violated constraints are added to the model, but only limited to a running set of features \u0393\u2208 {0,1}nf, which gets extended during the iteration. Next to the features, we also maintain a set of classes Cduplicates that were equal at one iteration and classes Csparse that ever had too few features assigned. Instead of eqs. (3) and (4) the relaxed constraints\n$$W_{rs} \\Gamma_{sr}\u2265 n_{wc} \\forall c \u2208 C_{sparse}$$\n$$(w_c \\cdot w_{c'})^T \\Gamma_{sr} < n_{wc} \\forall c, c'\u2208 C_{duplicates}$$\nare added, where Wer describes indexing We where \u0393 = 1. Additionally, we set the start solution for the next optimization to a good, usually optimal, feasible solution for the currently selected set of features. As we need multiple iterations to enforce all constraints, we limit the time spent on one iteration to 3 hours and set the gap to optimality to 10\u20134. In our experiments, the global optimum for the relaxed problem is usually found in less than 4 hours for fine-grained datasets, and roughly 11 hours for ImageNet-1K using a CPU like EPYC 72F3. While eq. (9) changes the desired optimization problem, the resulting objective is very close (achievable gap of less than 1%) to the global optimum, which is infeasible to compute and does not lead to an improved model. The experiments to verify this claim are included in Suppl. appendix N. Finally, alongside our experiments, previous work shows that the exact global optimum is not always preferred for relevant metrics. To make the relative weighting of the multiple objectives ZA, ZR and ZB easier, A is scaled with ne and nwc to have a maximum of 1 for nc = 200 and nwc = 5. Since n features need to be chosen, all entries below e in R are set to 0, where e is the highest value, for which there still exists a selection with ZR = 0. This is equivalent to finding the maximal e for which the graph described by G with\n$$g_{d,d'} = \\begin{cases} 10 \\text{ if } r_{d,d'}\u2265 \u03b5\\\\ 1 \\text{ else,} \\end{cases}$$\nhas a maximum clique of size n. We used approximations  and a sufficiently sized approximated maximum clique as the start value for s. Additionally, the remaining nonzero values in R are scaled to have a maximum of 1. For scaling the bias b, we clipped outliers, centered the remaining values around 0 and scaled the maximum absolute value to be x = \u221a\ub370, which is empirically found."}, {"title": "4.2 METRICS", "content": null}, {"title": "4.3 RESULTS", "content": "This section discusses the experimental results. The usual metrics for compactness-based globally interpretable models are shown in table 2. For the fine-grained datasets, QPM is among the most compact models while showing the highest accuracy, thus setting the state of the art for interpretable models. On ImageNet-1K, where prototype-based methods are not even applicable, QPM is only marginally beaten by Q-SENN, which uses compute-intensive iterations and negative reasoning for some classes, which significantly hinders interpretability. A runtime analysis is shown in appendix F. The results for the interpretability metrics are shown in table 3. Note that glm-saga5 and PIP-Net are hardly comparable, as glm-saga5 uses the uninterpretable features of a black-box model and PIP-Net learns very localized class-detectors, with some features activating to 99% on just a single class. In contrast, QPM achieves excellent values across all metrics and datasets in this multicriterial task of self-explaining neural networks, summarized in fig. 6. Its interpretable class representations, composed of diverse, general and contrastive features, mirror reality, as measured by Structural Grounding. Note that QPM learns grounded representations as shown in figs. 1 and 4 without any additional supervision and is able to communicate the only differentiating factor it uses. QPM's local behavior then follows its faithful global explanations, which leads to trustworthy classifications and predictable errors when the differentiating factor is not present, as in fig. 8. The appendix contains more visualizations, including a discussion of failure cases in appendix E, a discussion on polysemantic features (appendix H), an extension of Structural Grounding to ImageNet-1K (appendix I) and a discussion of limitations and future work (appendix K)."}, {"title": "4.4 ABLATION STUDIES", "content": "This section validates the impact of the individual objectives in the quadratic problem in table 4 and presents the compactness trade-off in fig. 7. We focus on CUB-2011 but observed similar results for other datasets. The compactness-accuracy tradeoff for QPM compared with Q-SENN and the SLDD-Model is visualized in fig. 7. The global optimization clearly leads to a more effective use of the defined capacity, with the highest uplift in the very high compactness regime, e.g. 1.5 percent points at n = 20, where a good selection and assignment naturally has more impact.\nThe impact of the feature-feature similarity matrix R and feature selection bias b is shown in table 4. Incorporating a bias b for local feature maps further increases the SID@5. On the other hand, reducing feature similarity through R effectively reduces the correlation between the resulting features, which improves accuracy, as the model uses its capacity more effectively. In summary, the inclusion of the secondary objectives ZR and ZB is beneficial for the resulting model, improving the desired aspects not just after solving the QP but also in the resulting model after fine-tuning. The appendix contains further ablation studies to support our claims, demonstrating the ability to steer (appendix D), validating the choice of correlation as metric for A (appendix J) and showing the benefits of enforcing exactly nwc features per class (appendix G)."}, {"title": "5 CONCLUSION", "content": "In this paper, we introduced the Quadratic Programming Enhanced Model (QPM). It uses discrete optimization to find an optimal feature selection and assignment of just 5 to each class. With this easy-to-understand assignment, the resulting QPM is more interpretable than previous methods, as it has contrastive faithfully interpretable class-representations, shows Structural Grounding, is steerable, and its features have excellent SID@5, Class-Independence and Contrastiveness. Additionally, it further closes the accuracy gap to the drastically less robust uninterpretable baseline. Figure 6 shows that only QPM excels in all metrics, thus setting a new state of the art for compactness-based interpretable models, while delivering unprecedented global interpretability even to ImageNet-1K."}, {"title": "C.A IMAGENET-1K", "content": "Due to computational constraints, we follow the SLDD-Model, skip the dense training on ImageNet- 1K and directly use the pretrained model as dense model. To facilitate the comparability of metrics between the dense model and our experiments, we use the default strides. For augmentation, we use Lighting noise and omit TrivialAugment. Finally, the learning rate of the fine-tuning starts at of the value used for the fine-grained datasets to account for the increased size of the dataset."}, {"title": "C.B CORRELATION METRIC", "content": "For measuring the effect of reducing correlation between selected features in table 4, the Correlation is used:\n$$Correlation = \\frac{1}{n_f} \\sum_{f_d=1} - \\frac{max_{d'}}{ n_f} \\frac{f_{:,d}^T f_{:,d'}}{||f_{:,d} || ||f_{:,d'}||}$$"}, {"title": "C.C QUADRATIC PROBLEM", "content": "This section presents further details on the quadratic problem and the start solution WStart for the next iteration of solving the quadratic problem with updated constraints. The start solution is a good, usually optimal, feasible solution for the currently selected set of features A. To simplify the initial iterations, only eq. (9) is considered. The deduplication of eq. (10) is only included after a solution is found that satisfies eq. (9). The start solution is constructed from Wnwc which contains nwc assignments for each class to the most similar features in A:A. If the equal distribution of assignments per class is still exclusively optimized for, WStart = Wnwc is already the start solution. Else, we take care of all classes with equal assignment Cequal in Wnwe. Specifically, we remove all"}, {"title": "D STEERABILITY", "content": "This section is concerned with the ability of the practitioner to steer the model towards desired biases using the feature bias b. For example, if a human recognizes the erroneous focus on the background"}, {"title": "E FAILURE CASES", "content": "This section presents examples where QPM predicts wrongly. For that, fig. 10 shows exemplary images of Rottweiler and Doberman with classification results of the probed QPM trained on ImageNet-1K and with global explanations in figs. 1 and 21 to 23. Note that the accuracy across the two classes is 87%, well above the average, reflected in correct classifications across poses, backgrounds and settings in figs. 10a and 10b. Additionally, fig. 11 shows the GradCAM visualizations and demonstrates that QPM always focuses on the dog in the image. For the erroneous predictions, the model behaves just like the global explanations would indicate. Rottweiler and Doberman may be swapped, if the head is occluded as in figs. 10c and 10g or in a difficult pose to gauge the shape, shown in figs. 10d and 10h. Since the Black and tan coon hound is assigned both head features of Rottweiler and Doberman, they can also be confused when primarily the head is visible, demonstrated in figs. 10e and 10i. Finally, figs. 10f and 10j seem to contain one of the many wrongly labeled samples in ImageNet-1K. QPM also robustly classifies wrongly labeled data, as the global explanation would suggest. Figures 12 and 13 show the feature activations of Greater Swiss Mountain Dog and Rottweiler on fig. 10f and other class examples, further suggesting that it is indeed a typical Greater Swiss Mountain rather a Rottweiler for the probed QPM, as the features of the former localize on the expected regions, whereas most Rottweiler features barely activate. Finally, fig. 14 shows further test examples for the model explained in fig. 4 and demonstrates that the model does not predict Bronzed Cowbird if the differentiating red eye is not present in the image. In summary, QPM's local behavior robustly follows the faithful global explanations, which can lead to predictable faulty classifications in case of occlusion or difficult pose."}, {"title": "F RUNTIME ANALYSIS", "content": "This section discusses the time it takes to obtain a QPM, compares it to competing models and discusses the impact of n on it. Figure 15 demonstrates that the optimization time strongly increases when increasing n. However, for the probed datasets, going beyond 50 features seems not to be necessary, as the accuracy only improves negligibly, while the interpretability is harmed: Features become less general and there will be fewer class representations with high overlap, which allow for the most intuitive interpretation. One can further optimize this using suitable priors, which we do not include in this work, as the interpretability and additional accuracy decreases with increasing n. It is however an avenue for future work, when datasets with sufficient complexity are published. Table 6 compares the time to obtain the interpretable model between QPM, Q-SENN and SLDD-Model. Q-SENN and SLDD-Model start with a feature selection, that takes 15 minutes on CUB-2011 and roughly 500 minutes on ImageNet-1K. They both use glm-saga for feature selection and computing the sparse matrix and are thus scaling with number of samples ny, which QPM is invariant to, as that dimension is summarized in the constants."}, {"title": "GIMPACT OF EVEN SPARSITY", "content": "This section discusses the impact of enforcing exactly nwc features per class, rather than on average. For that, we trained a model without this constraint, but instead with 17 Ws = nwcnc enforcing an average sparsity. To counteract the uneven number of features per class, every class got a bias, that is linear to the number of features it is below the average. In prior experiments, various forms of counteracting the uneven assignment with a bias have performed similarly. Table 7 shows that the even assignment is beneficial for the accuracy. Further, the even assignment boosts interpretability as it leads to more classes that can be contrasted easily and does not introduce an unintuitive bias term. Additionally, fig. 16 demonstrates that classes, which are assigned to fewer features, cause these"}, {"title": "H POLYSEMANTIC FEATURES", "content": "This section discusses the phenomenon of polysemantic features and how it relates to QPM. Like all deep learning models not specifically designed to prevent polysemanticity, QPM learns polysemantic features. It refers to individual neurons activating on not just one concept c but rather on n seemingly unrelated ones. While it is an active area of research, their emergence can likely be attributed to being an effective solution to the training objective. On many training samples, the impact on the loss can be fairly low, if a polysemantic feature activates on any of its n meanings. The only exception occurs, when it activates on samples, where its activation contributes significantly to a class that is already showing a lot of activation. While this is typically very difficult to analyze, the interpretable structure of QPM can offer more insights, as it enables a reliable metric on which to gauge how strongly the activation on another concept would affect the loss: The similarity in QPM's class representation space. Our hypothesis is that QPM learns features that are locally monosemantic, while being globally polysemantic. Around a class, e.g., Bronzed Cowbird, we expect the features"}, {"title": "I STRUCTURAL GROUNDING ON IMAGENET", "content": "This section is concerned with evaluating a metric similar to Structural Grounding on ImageNet-1K. It is based on comparing the class similarities in reality \u062a\u064dgt with the \u0173 Model ones learned by our"}, {"title": "JIMPACT OF CLASS-FEATURE SIMILARITY METRIC", "content": "This section contains an ablation study on the choice of Pearson correlation as metric for the feature- class similarity matrix A. While it captures the desired linear relationship, that is also utilized during the following predictions, an intuitive alternative is the Area under the receiver operating characteristic curve (AUROC), which is highly non-linear and frequently used to capture the predictive power with a varying threshold. Table 10 shows that AUROC is also suitable but inferior to the simple correlation."}, {"title": "K LIMITATIONS AND FUTURE WORK", "content": "This section discusses limitations for the proposed QPM and avenues for future work.\nIn this work, QPM is applied to the generally available and typical datasets for image classification, with ImageNet-1K indicating broad applicability. However, QPM's high interpretability is especially beneficial for high-stakes applications such as the medical domain or autonomous driving, where each individual situation can not be accessed by an expert. Rather, after training the QPM and before deploying it to cars, its class explanations can be obtained to gain insights into whether it is right for the right reasons and if these are robust to all deployment conditions. Thus, applying QPM to suitable high-stakes applications is a promising avenue for future work. However, to our knowledge, there is no suitable dataset from these domains published yet.\nA limitation of our QPM in its current form lies in its inability to model negative assignments. Compared to the SLDD-Model and Q-SENN, which use negative weights, it is evident that the varied datasets used in this paper, do not require it. Further, while we believe that it is generally prefer- able to represent classes only using positive assignments, as e.g., also done by recent prototypical models , one can think of other datasets where negative reasoning may be superior. If, e.g., all classes in a dataset containing birds had a black beak, except for one with all other colors, it would likely be the most efficient solution to represent that one with a negative assignment on a feature activating on black beaks, rather than have every other class positively assigned to it, which the current QPM might do. Thus, future work may incorporate negative assignments into the optimization, which might lead to even more compact representations.\nAs discussed in appendix H, the learned features of our QPM are generally polysemantic, while potentially being monosemantic locally. For aligning them with human concepts, all post-hoc"}, {"title": "L DETAILED RESULTS", "content": "This section contains detailed results with standard deviations, including experiments with Resnet34, Inception-v3, Swin-Transformer-small and Swin-Transformer-tiny, in Suppl. table 11 to table 22. The good results across architectures demonstrate an independence between backbone and our proposed method. They further seem robust as the difference in mean is usually large compared to the standard deviation. Further, figs. 21 and 22 show how the features of fig. 1 continue to localize on the same human attribute across different poses. Additionally, we included the activations of these features on images of another class in fig. 23 to showcase the global interpretability enabled through the binary assignment of more interpretable features. Instead of the blue and green feature, this probed QPM recognizes the Black and Tan Coonhound through both doberman-like and rottweiler-like head features, as well as a neck that is also assigned to pandas or bears. Figures 19 and 20 additionally include examples for contrastive class representations learned on Stanford Cars and TravelingBirds. Finally, table 8 contains results for diversity@5, to quantify its inability to capture the high spatial diversity of PIP-Nets class detectors."}, {"title": "M FEATURE DIVERSITY LOSS", "content": "This section further describes the Feature Diversity Loss Ldiv, proposed in Norrenbrock et al. (2022). It is defined per sample, for which the model predicted the class \u00ea\u0109 = arg max(y) and ensures a local diversity of the used feature maps M\u2208 Rnfxwm\u00d7h\u043c.\n$$S_{i,j} = \\frac{exp(M_{i,j})}{\\sum_{hM=1}^{\\pi_j \\sum_\\Omega \\sigma j hM} exp(M_{\\pi j,\\Omega j hM})}$$\n$$L_{div} = - \\sum_{i=1}^{\\pi} \\sum_{j=1}^{\\Omega} max(S_{1,j},...,\\sigma_j 1,3,.,...,\\sigma _j W d}$$\nEquation 31 employs the softmax function to normalize the entries mij of the feature maps M across spatial dimensions. It then scales the maps to emphasize visible and significant features, maintaining"}, {"title": "\u039d \u039f\u03a1\u03a4\u0399\u039cALITY OF SOLUTION", "content": "In order to test the optimality of our solution, we try to solve the problem without our relaxation in eq. (9) with more compute and time. We used 3 days and 250 GB on an AMD EPYC 72F3 to solve the problem globally across 5 seeds on CUB-2011 with a target gap to optimality of 1% to ensure sufficient deduplication. The time limit was left to 3 hours for one iteration, as otherwise multiple iterations would not finish. Across the 5 seeds used for QPM, the average obtained objective value for the global problem was 0.5% above the one computed with our simplifications. Similar to our ablations in table 4, the resulting accuracy for the extensively optimized model was not improved, but even 0.1 percent points lower. As mentioned in section 4.1.1, the objective does not perfectly correlate with downstream metrics, as the constants A, R and b only approximate the desired behaviour. However, the average gap to the best bound was still 3.2%, with only negligible progress during the final iteration, suggesting that a longer time limit would not significantly improve it. Note, that the best bound might be violating constraints, already added or not. In summary, the"}, {"title": "\u039f STANDARD FORM FOR QUADRATIC PROBLEM", "content": "The quadratic problem", "W": "n$$x = \\begin{bmatrix} s \\\\ vec(W) \\end{bmatrix} \\in \\"}]}