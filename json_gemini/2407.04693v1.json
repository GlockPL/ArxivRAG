{"title": "ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language Models", "authors": ["Yuzhe Gu", "Ziwei Ji", "Wenwei Zhang", "Chengqi Lyu", "Dahua Lin", "Kai Chen"], "abstract": "Large language models (LLMs) exhibit hallucinations in long-form question-answering tasks across various domains and wide applications. Current hallucination detection and mitigation datasets are limited in domains and sizes, which struggle to scale due to prohibitive labor costs and insufficient reliability of existing hallucination annotators. To facilitate the scalable oversight of LLM hallucinations, this paper introduces an iterative self-training framework that simultaneously and progressively scales up the hallucination annotation dataset and improves the accuracy of the hallucination annotator. Based on the Expectation Maximization (EM) algorithm, in each iteration, the framework first applies a hallucination annotation pipeline to annotate a scaled dataset and then trains a more accurate hallucination annotator on the dataset. This new hallucination annotator is adopted in the hallucination annotation pipeline used for the next iteration. Extensive experimental results demonstrate that the finally obtained hallucination annotator with only 7B parameters surpasses the performance of GPT-4 and obtains new state-of-the-art hallucination detection results on HaluEval and HalluQA by zero-shot inference. Such an annotator can not only evaluate the hallucination levels of various LLMs on the large-scale dataset but also help to mitigate the hallucination of LLMs generations, with the Natural Language Inference (NLI) metric increasing from 25% to 37% on HaluEval.", "sections": [{"title": "1 Introduction", "content": "Large Language Models (LLMs) have shown remarkable capabilities in various tasks [10, 11, 31, 46, 51]. However, they tend to produce hallucination, i.e., plausible-sounding but unfaithful or nonsensical information [5, 26], that significantly hinders their real-world applications. Initial steps to address this issue involve the creation of datasets that can help to detect, annotate, and mitigate hallucinations [12, 25, 36]. Since the potential hallucinations of LLMs are in various fields, the spectrum of knowledge in the dataset is expected to be large-scale and comprehensive, covering various domains. Consequently, the size and diversity of datasets are critical for the oversight of LLM hallucinations.\nHowever, constructing and scaling-up hallucination annotation datasets face significant hurdles [8, 9, 25, 39]. One primary challenge is the prohibitively high costs and labor intensity required for their accurate assessment [39, 43], since the fine-grained hallucination annotation requires intensives labor for reading long documents and annotating the hallucination details sentence by sentence. Moreover, due to the insufficiency of accurate human annotations, the reliability of existing hallucination"}, {"title": "2 Related Work", "content": "Self-improvement of Large Models. As Large Language Models (LLMs) become more and more powerful, the community starts to explore different strategies to achieve the self-improvement of LLMs, i.e., to improve the LLMs using the supervision from LLMs. For example, existing works have explored self-alignment using LLMs with ethical principles [3, 52, 63]. There are also methods [22, 34, 50, 64] strengthen LLM's capabilities on tasks such as reasoning by training the LLMs on the high-quality responses from themselves on the same questions. In the field of computer vision, SAM [32] introduces manual and model-assisted labeling to expand the image segmentation dataset and enhance the performance of image segmentation models. However, the application of self-"}, {"title": "3 Method", "content": "This paper proposes an iterative self-training framework to simultaneously scale up the hallucination dataset and improve the accuracy of the hallucination annotator. We follow the analytical hallucination annotation (\u00a7 3.1) to annotate the hallucination sentence-by-sentence. The multi-iteration framework is theoretically grounded in the EM algorithm (\u00a7 3.2) and involves three stages to progressively scale the dataset in multiple dimensions (\u00a7 3.3). We also reveal how the hallucination annotators can be applied for hallucination evaluation and mitigation (\u00a7 3.4)."}, {"title": "3.1 Analytical Hallucination Annotation", "content": "The aim of a hallucination annotator is to identify hallucinations in the model responses. ANAH [25] developed a fine-grained annotation method that locates reference points in the document for each sentence and makes hallucination-type judgments, with the whole process completed in one turn of dialog. However, this hybrid task diverges from the human judgment processes and fails to clearly indicate the relationship between reference points and hallucination judgments, resulting in unsatisfactory annotation accuracy.\nInstead of using the original ANAH training prompts, we developed a more reliable training method tailored to the hallucination annotation process. As depicted in the lower right part of Fig. 2, the process is outlined in three phases: (1) Factual Existence Judgment, where the annotator assesses whether the provided sentence contains verifiable facts. If no factual content is present, the sentence is categorized as 'No Fact' and requires no further annotation. (2) Reference Information Extraction, where the annotator extracts relevant reference points from the documents related to the question and answer. (3) Hallucination-Type Judgment, where the annotator determines the type of hallucination based on the extracted reference points. If the sentence aligns with the references, it is classified as 'No Hallucination'. If it contradicts the references, it is deemed a 'Contradictory Hallucination'. If it lacks supporting evidence and cannot be verified, it is labeled as 'Unverifiable Hallucination'. The above three phases will form a multi-turn dialogue in training data. Compared to the ANAH approach, which involves simultaneous judgments on multiple criteria, our phased process aligns more closely with human cognitive judgment processes. The detailed data format and prompts for our annotation process are in Appendix A."}, {"title": "3.2 Expectation-Maximization Algorithm", "content": "Simultaneously scaling up the dataset and improving the accuracy of the annotator can be formulated by the EM algorithm. For the input set X, we need to estimate two hidden variables simultaneously, the output set Y and the model parameters \u03b8. Specifically, based on the task formulation in \u00a7 3.1, we define the input x from the input set X of the hallucination annotator consists of a question, a sentence to be annotated, and a reference document. The expected output y to be estimated in the data output set Y includes the factual information f, the key reference points r from the reference document, and the type of hallucination h. We maximize the log-likelihood estimation of Y by alternately performing the E-Step and the M-Step to update the model parameters \u03b8:\n\u03b8 = arg max E_{p_\u03b8(Y|X,\u03b8)} [log p_\u03b8(X,Y | \u03b8)]\n(1)\nE-Step. A straightforward approach to estimating Y is to use a single model to predict annotations. However, this method lacks sufficient accuracy [41]. To improve the accuracy and stability of the estimation of Y, we introduce the self-consistency method [57], which provides a more robust representation of the distribution of the Y. As shown in Fig. 2. For each input x, we perform multiple samplings to yield K independent outputs y = {y\u00b9,\u2026\u2026\u2026, y\u00b2, \u2026\u2026\u2026, y\u1d37 }, where the i-th output sample y\u2071 is composed of factual information (f\u2071), reference point (r\u2071) and hallucination type (h\u2071). We use a self-consistency metric to select the most representative sample y* among all outputs:\ny* = (f*,r*, h*) = self-consistency(y)\n(2)\nDuring this selection process, we consider the hallucination type h, reference point r, and factual information f in turn. We determine the most common hallucination type h* by tallying a majority vote across all samples, denoted as h* = arg max_h \u03a3_{i=1}^K 1I(h\u1d62 = h). Then, we form the candidate reference set R by taking the corresponding r from the output containing the h*. We select the most \"consistent\" reference point r* by comparing the cosine similarities. For each r\u2071 in R, we first calculate its average cosine similarity with the other elements in R. After that, we select the reference point r* with the highest average cosine similarity: r* = arg max_{r\u2071\u2208R} \u03a3_{j=1,j\u2260i}^(n-1) sim(r\u2071, r\u02b2).\nFinally, with (r*, h*), we can uniquely select the corresponding f*.\nM-Step. Following the robust estimation in the E-step, the M-step updates the model parameters to maximize the likelihood of the selected output y*. Combining Eq. 1 and Eq 2, we formulate the parameter update strategy at iteration t:\n\u03b8^{t+1} = arg max E_{x~X} [E_{y~p_{\u03b8}\u1d57 (y|x,\u03b8)} [log p_\u03b8(x, y* | \u03b8)]]\n(3)"}, {"title": "3.3 Multi-dimensional Data Scaling", "content": "Grounded in the EM algorithm, our framework operates in an iterative manner. This multi-iteration process acts as a data growth flywheel to progressively scale up the dataset in multiple dimensions, consisting of three stages:\nStage 1: Seed Data and Basic Annotator. We utilize ANAH dataset [25] as our seed data, which includes over 700 topics and around 4,300 LLM-generated questions and responses. For each response, ANAH provides the hallucination type for every sentence, determined through a human-in-the-loop approach. We train an initial hallucination annotator, noted as ANAH-v2 Stage1, with this seed data using the annotation method described in \u00a7 3.1.\nStage 2: Scaling up in Response Dimension. In Stage 1, for each question, ANAH provides responses that GPT-3.5 generates with the reference document, while InternLM-7B generates without any reference document. We first augment the dataset's model responses by collecting responses to the same existing questions from 13 additional open-source models of various sizes and series. For each model, responses were collected with and without knowledge of reference documents. The prompt details are in Appendix B. After filtering out similar model responses, these responses are annotated sentence by sentence using the self-consistency pipeline with ANAH-v2 Stage1. The newly annotated data, combined with the seed data, was used to train ANAH-v2 Stage2.\nStage 3: Scaling up in Topic Dimension. We expand the topic coverage along four categories: location, person, event, and thing, paralleling ANAH's configuration. For each topic, we generate several questions based on the provided reference documents (more details in Appendix B). Then, we use the same method in Stage 2 to collect responses from multiple models and annotate the response following the same procedure as in Stage 2, using ANAH-v2 Stage2 annotator. The resulting dataset, combined with data from the previous stages, is used to train the ultimate annotator version.\nOveral Statistics. The final dataset encompasses both over ~3k topics, ~196k model responses, and ~822k annotated sentences, in English and Chinese (Tab. 1). The topics cover celebrities, events, locations, and things, and span a wide array of domains, such as politics, health, and sports (Fig. 3). The statistics underscore the comprehensiveness and extensive scale of our dataset."}, {"title": "3.4 Applications", "content": "Hallucination Evaluation. As the accuracy of the hallucination annotators becomes satisfactory, we can apply it to automate the process of evaluating the hallucination levels of existing open-source models. After categorizing sentences into four distinct types (introduced in \u00a7 3.1), we consider type Contradictory and Unverifiable Hallucination as sentences with hallucinations, and type No Fact and No Hallucination as sentences without hallucinations. This tool enables researchers to assess the reliability and accuracy of generated texts, ensuring models can be responsibly integrated into practical applications.\nHallucination Mitigation. We further show a simple re-ranking strategy to mitigate the LLM's hallucinations with the annotator, whereas more advanced strategies can be explored in future research. Specifically, we adopt our annotator @ for response re-ranking. LLM first generates N candidate responses {G\u2081,\u2026\u2026,GN} by top-k sampling. Then we select the best response G* with the lowest"}, {"title": "4 Experiment", "content": "4.1 Experimental Setup\nImplementation. In our experimental framework, we adopt the pre-trained InternLM2-7B [7] model to fine-tune the hallucination annotator. Further implementation details can be found in Appendix C.\nEvaluation. We use a subset of the ANAH [25] data as a test set, which is not used for training in stage 1. To assess the performance of the annotator in predicting hallucination types, we utilize F1 and Accuracy. We also employ RougeL [38] and BertScore [66] to compare the generated text with gold-standard human reference in terms of gram, continuity, order and semantics."}, {"title": "4.2 Overall Results", "content": "The last 3 rows of Tab. 2 illustrate\nthe performance of ANAH-v2 at each\nstage of Data Scaling in \u00a7 3.3. The\nperformance progressively improves\nwith the increasing dataset number\n(see in Tab. 1) in successive stages.\nThis trend underscores the scalabil-\nity and effectiveness of our hallucina-\ntion annotation framework. Remark-\nably, ANAH-v2 surpasses GPT-4 with\nthe F1 of 87.78% and the accuracy\nof 88.03% at Stage 2 3. Eventually,\nwe achieve the F1 of 89.30% and the\naccuracy of 89.55% at Stage 3."}, {"title": "4.3 Ablation Studies", "content": "Impact of Self-Consistency. To verify the effectiveness of self-consistency during inference in E-Step (introduced in \u00a7 3.2), we compare the performance of the annotator with different self-consistency settings in Tab. 3. When the annotator model with the same training data at each data scaling stage, the inference strategy with self-consistency (w/ SC) consistently outperforms without self-consistency (w/o SC), where the annotator generates only once for each input. Therefore, self-consistency improves the accuracy and stability of the estimation of hallucination annotations.\nIn M-Step, we train the model on data from the E-Step of the preceding iteration. We observe that when the annotator model with the same inference strategy, the model trained on self-consistently processed data (w/ SC) surpasses the performance with data generated through a single pass (w/o SC). This finding indicates that training data processed through self-consistency leads to a stronger"}, {"title": "4.4 Generalization Capability Analysis", "content": "We further validate the effectiveness of ANAH-v2 on other hallucination detection datasets using two third-party datasets: HaluEval [36] for English and HalluQA [12] for Chinese. Each dataset provides four components: questions, reference documents, responses, and labels indicating whether the responses contain hallucination. For each question, we let ANAH-v2 judge the type of responses containing and not containing the hallucination separately. Note that in HaluEval we only use the QA samples and in HalluQA, we only use the samples that provide a textual reference document, which aligns with our annotator's designed setting."}, {"title": "4.5 Application", "content": "Hallucination Evaluation Benchmark. Our ANAH-v2 dataset and annotator can serve as a benchmark for the hallucination levels in generated texts by existing models. As shown in Tab. 7, we evaluate the performance of various LLMs, including InternLM2 [7], Qwen1.5 [2], Baichuan2 [4], Mistral [29, 30], DeepSeek-LLM [6], and Llama2 [53], spanning different model sizes. We also offer detailed evaluation results on different languages and categories of topics to deepen our understanding.\nWe find that all models exhibit superior performance in English compared to Chinese, underscoring the need for further research to understand and mitigate language-dependent discrepancy. The performances of all models with reference documents are better than those without. Qwen1.5-14B achieves the lowest hallucination rate when using reference documents (5.33%) and Deepseek-67B achieves the lowest hallucination rate when reference documents are not provided (47.17%). Moreover, we find no clear trend in the performance distribution across four categories of topics. In addition, the results of different stages of annotators in Tab. A1, A2, and 7 show that there is a consistent trend and fixed biased ordering relationship between LLMs, thus confirming the reliability of our assessment method. More details are in Appendix D.\nHallucination Mitigation. Besides being used to measure hallucination levels, ANAH-v2 can also be used to mitigate hallucinations. We use the QA samples from HaluEval, which comprises questions and correct answers from HotPotQA [62]. We use two models InternLm2-7B and LLaMA2-7B. For each model, we generate 36 candidate responses by top-k sampling (k=40), then re-rank the responses using our annotator. To quantify the hallucination degree, we employ RougeL, BertScore, NLI, and QuestionEval. These metrics measure the congruence between the generated responses with the golden responses and/or reference documents.\nResults in Tab. 8 show a clear reduction of hallucination levels after the re-ranking process via our annotator. For instance, the NLI metric for LLaMA2-7B shows a notable increase, rising from 25.00% to 37.01%. This suggests that the application of our annotative approach can significantly mitigate the issue of hallucinations in language model outputs."}, {"title": "5 Conclusion and Future Work", "content": "In this paper, we aim to explore a scalable framework for the oversight of LLM hallucinations. Through iterative self-training, we progressively expand the diversity and scale of the dataset and improve the accuracy of the hallucination annotator. The finally obtained ANAH-v2, for the first time, outperforms GPT-4 in various hallucination detection benchmarks with only 7B parameters and obtains superior zero-shot performance on third-party hallucination detection benchmarks. ANAH-v2 not only provides an automatic hallucination evaluation benchmark with the scaled dataset, which paves the way for future research on hallucination mitigation but also exhibits potential in hallucination mitigation by the simple re-ranking strategy. We believe ANAH-v2 can also benefit more hallucination mitigation strategies such as fine-grained RLHF.\nWith the large-scale dataset as seed data, future work can explore creating hallucination annotation data in other NLG tasks such as dialogue generation. Another direction is to improve the generalizability of the annotator across different languages, tasks, and topics."}, {"title": "A Training Prompt", "content": "As described in \u00a7 3.1, our annotation process consists of three phases: (1) Factual Existence Judgment via the prompt in Fig. A1, (2) Reference Information Extraction via the prompt in Fig. A2 (3) Hallucination-Type Judgment via the prompt in Fig. A3."}, {"title": "B Data Scaling Details", "content": "As described in \u00a7 3.3, we collect model responses via Fig. A5. The open-source models include InternLM2(7B&20B) [7], Baichuan2 (7B&13B) [4], LLama2 (7B&13B) [53], Qwen1.5 (7B&14B&72B) [2], Deepseek (7B&67B) [6], and Mistral (7B&7\u00d78B) [29, 30].\nWe automate the topic selection based on occurrence frequency via Google Ngram Viewer \u2075 and retrieve corresponding reference documents from pre-training databases [24].\nWe generate questions on each topic via Fig. A4."}, {"title": "C Implementation Details", "content": "In our experimental framework, we adopt the pre-trained InternLM2-7B [7] model to fine tuning the hallucination annotator.\nIn E-Step, we generate responses by implementing sampling via the LMDeploy library [15]. During each iteration, we generate 32 candidate responses per input and apply a self-consistency quality control mechanism to them. The decoding strategy involves the top-k (k = 40) sampling with a temperature of 0.8.\nIn M-Step, we train the annotator model with the following settings and hyper-parameters: the epoch is 1, the learning rate is 1e-5, and the AdamW optimizer is with a linear scheduler, the maximum sequence length is set to 32k. Additionally, following the configuration in ANAH [25], we perform a multi-task setting where additional tasks such as dialogue generation from ShareGPT [45] and Dolly [14] are integrated with the fine-grained hallucination annotation. Our model is trained on 32 NVIDIA A100 GPUs."}, {"title": "D Hallucination Evaluation", "content": "To assess the reliability of our hallucination annotator, we measure the hallucination levels of the above LLMs using the annotator from different stages. Tab. A1, A2, and 7 show the results measured by annotator ANAH-v2 from Stage 1, 2, and 3, respectively. The trends in these three tables are consistent where Qwen1.5-14B achieves the lowest hallucination rate with reference documents and DeepseekLM-67B achieves the lowest hallucination rate without reference documents. This consistency and fixed biased ordering relationship between LLMs confirm the reliability of our assessment method."}, {"title": "E Limitation", "content": "Although this study presents a novel multi-iteration self-training framework for the scalable oversight of LLM hallucinations and achieves significant improvements in hallucination annotation, there are some limitations.\nDespite the progressive scaling and increasing accuracy of the hallucination annotator, there may still exist a non-negligible margin of error in the annotations. This margin could affect the convergence of the model and the quality of the final hallucination annotator. Furthermore, the success of our framework is measured largely by its performance on our own dataset and other benchmarks such as HalluEval and HalluQA. However, these datasets might not encompass the full spectrum of real-world scenarios where hallucinations pose a problem. Lastly, this work primarily uses InternLM2-7B as the backbone of the hallucination annotator. Other different underlying models and different numbers of parameters are not explored."}, {"title": "F Broader Impacts", "content": "By exploring the hallucination annotation and mitigation in LLMs, this paper contributes to the development of more reliable and trustworthy AI technologies. Our innovative multi-iterative self-training framework significantly reduces the reliance on expensive and time-consuming manual annotations by automating the hallucination detection process. Our hallucination annotator offers a benchmark for the research community evaluating the hallucination levels of existing open-source models. Additionally, we provide a large-scale and diverse dataset from which the broader research community can benefit, fostering further innovation and study in this domain."}, {"title": "English Prompt:", "content": "You will act as a fact checker, and I will provide you with a question and a corresponding partial answer. Your task is to determine whether the content of the answer contains verifiable facts.\n## Judgment Criteria:\nVerifiable Facts: Specific, objective points of information that can be verified through data, research results, or other reliable sources. Examples include statistical data, historical events, scientific laws, and specific case studies.\n- Non-factual Descriptions: Personal opinions, subjective judgments, or unverifiable statements.\n## Task Process:\n1. Carefully read the question, which is as follows: {question}\n2. Carefully read the partial answer, which is as follows: {annotation}\n3. Conduct the Analysis: Based on the above judgment criteria, determine if the answer contains verifiable facts.\n- If there are no verifiable facts in the answer, output \"<No Facts>\".\n- If there are verifiable facts in the answer, output \"<Facts Present>\u201d."}, {"title": "Chinese Prompt:", "content": "\u4f60\u5c06\u4f5c\u4e3a\u4e00\u4e2a\u4e8b\u5b9e\u5224\u65ad\u5668,\u6211\u4f1a\u7ed9\u4f60\u63d0\u4f9b\u4e00\u4e2a\u95ee\u9898\u548c\u4e00\u4e2a\u9488\u5bf9\u8be5\u95ee\u9898\u7684\u90e8\u5206\u56de\u7b54,\u4f60\u7684\u4efb\u52a1\u662f\u5224\u65ad\u56de\u7b54\u4e2d\u7684\u5185\u5bb9\u662f\u5426\u5b58\u5728\u53ef\u4ee5\u5224\u65ad\u7684\u4e8b\u5b9e\u3002\n##\u5224\u65ad\u6807\u51c6:\n- \u53ef\u4ee5\u5224\u65ad\u7684\u4e8b\u5b9e:\u5177\u4f53\u7684\u3001\u5ba2\u89c2\u7684\u4fe1\u606f\u70b9,\u8fd9\u4e9b\u4fe1\u606f\u53ef\u4ee5\u901a\u8fc7\u6570\u636e\u3001\u7814\u7a76\u7ed3\u679c\u6216\u5176\u4ed6\u53ef\u9760\u6765\u6e90\u8fdb\u884c\u9a8c\u8bc1\u3002\u4f8b\u5982,\u7edf\u8ba1\u6570\u636e\u3001\u5386\u53f2\u4e8b\u4ef6\u3001\u79d1\u5b66\u5b9a\u5f8b\u3001\u5177\u4f53\u6848\u4f8b\u7b49\u3002- \u975e\u4e8b\u5b9e\u63cf\u8ff0:\u4e2a\u4eba\u610f\u89c1\u3001\u4e3b\u89c2\u5224\u65ad\u6216\u65e0\u6cd5\u9a8c\u8bc1\u7684\u58f0\u660e\u3002\n##\u4efb\u52a1\u6d41\u7a0b:\n1. \u4ed4\u7ec6\u9605\u8bfb\u95ee\u9898,\u95ee\u9898\u5982\u4e0b:{question}\n2. \u4ed4\u7ec6\u9605\u8bfb\u56de\u7b54,\u90e8\u5206\u56de\u7b54\u5982\u4e0b:{annotation}\n3. \u8fdb\u884c\u5206\u6790:\u6839\u636e\u4e0a\u8ff0\u5224\u65ad\u6807\u51c6,\u5224\u65ad\u56de\u7b54\u4e2d\u662f\u5426\u5305\u542b\u53ef\u4ee5\u5224\u65ad\u7684\u4e8b\u5b9e\u3002\n- \u5982\u679c\u56de\u7b54\u4e2d\u4e0d\u5b58\u5728\u53ef\u4ee5\u5224\u65ad\u7684\u4e8b\u5b9e,\u5219\u8f93\u51fa\u201c<\u65e0\u4e8b\u5b9e>\u201d\u3002- \u5982\u679c\u56de\u7b54\u4e2d\u5b58\u5728\u53ef\u4ee5\u5224\u65ad\u7684\u4e8b\u5b9e,\u5219\u8f93\u51fa\u201c<\u6709\u4e8b\u5b9e>\u201d\u3002"}, {"title": "English Prompt:", "content": "You will act as an information extractor. I will provide you with a question, a related reference document, and a partial answer to that question. Your task is to extract information from the reference document that is relevant to the question and answer.\n## Operational Steps:\n1. Carefully read the question, which is as follows: {question}\n2. Carefully read the partial answer, which is as follows: {annotation}\n3. Analyze the Reference Document: Identify information most relevant to the question and answer. This information may be completely the same, partially similar, or conflicting with the content of the answer. The reference document is as follows: {reference}\n4. List the Relevant Information: List all the relevant information found in order, separated by <SEP> if there are multiple pieces of information.\n5. Output When No Information Is Found: If no relevant information is found, output <No Reference Information>."}, {"title": "Chinese Prompt:", "content": "\u4f60\u5c06\u4f5c\u4e3a\u4e00\u4e2a\u4fe1\u606f\u63d0\u53d6\u5668,\u6211\u5c06\u7ed9\u4f60\u63d0\u4f9b\u4e00\u4e2a\u95ee\u9898\u3001\u4e00\u4efd\u76f8\u5173\u7684\u53c2\u8003\u6587\u6863,\u4ee5\u53ca\u4e00\u4e2a\u9488\u5bf9\u8be5\u95ee\u9898\u7684\u90e8\u5206\u56de\u7b54,\u4f60\u7684\u4efb\u52a1\u662f\u4ece\u53c2\u8003\u6587\u6863\u4e2d\u63d0\u70bc\u51fa\u4e0e\u95ee\u9898\u548c\u56de\u7b54\u76f8\u5173\u7684\u4fe1\u606f\u3002\n## \u64cd\u4f5c\u6b65\u9aa4:\n1. \u4ed4\u7ec6\u9605\u8bfb\u95ee\u9898,\u95ee\u9898\u5982\u4e0b:{question}\n2. \u4ed4\u7ec6\u9605\u8bfb\u56de\u7b54,\u90e8\u5206\u56de\u7b54\u5982\u4e0b:{annotation}\n3. \u5206\u6790\u53c2\u8003\u6587\u6863:\u627e\u51fa\u4e0e\u95ee\u9898\u548c\u56de\u7b54\u6700\u76f8\u5173\u7684\u4fe1\u606f,\u8fd9\u4e9b\u4fe1\u606f\u53ef\u80fd\u4e0e\u56de\u7b54\u5185\u5bb9\u5b8c\u5168\u76f8\u540c\u3001\u90e8\u5206\u76f8\u540c,\u6216\u5b58\u5728\u51b2\u7a81\u3002\u53c2\u8003\u6587\u6863\u5982\u4e0b:{reference}\n4. \u5217\u51fa\u76f8\u5173\u4fe1\u606f: \u6309\u987a\u5e8f\u5217\u51fa\u6240\u6709\u53d1\u73b0\u7684\u76f8\u5173\u4fe1\u606f,\u5982\u679c\u6709\u591a\u6761\u4fe1\u606f\u7684\u8bdd\u4ee5<SEP> \u4f5c\u4e3a\u5206\u9694\u3002\n5. \u65e0\u76f8\u5173\u4fe1\u606f\u65f6\u8f93\u51fa: \u5982\u679c\u6ca1\u6709\u627e\u5230\u76f8\u5173\u4fe1\u606f,\u8bf7\u8f93\u51fa<\u65e0\u53c2\u8003\u4fe1\u606f>\u3002"}, {"title": "English Prompt:", "content": "You will act as a 'Hallucination' annotator. I will provide you with a question, a partial answer to that question, and related reference points. You need to determine whether the provided answer contains any hallucinatory content and annotate the type of hallucination.\n'Hallucination' refers to content that contradicts the reference points or is unsupported by them.\n## Judgment Criteria:\n1. No Hallucination: If the answer is completely consistent with the reference points and does not introduce any contradictory information, output: <No Hallucination>.\n2. Contradiction: If the answer clearly contradicts the reference points, output: <Contradictory>.\n3. Unverifiable: If the answer contains information not mentioned in the reference points and cannot be supported or verified by them, output: <Unverifiable>.\n## Task Process:\n1. Carefully read the question, which is as follows: {question}\n2. Carefully read the partial answer, which is as follows: {annotation}\n3. Carefully read the reference points, which are as follows: {reference}\n4. Conduct the analysis: Based on the above judgment criteria, determine if the answer contains hallucinations and output the type of hallucination."}, {"title": "Chinese Prompt:", "content": "\u4f60\u5c06\u4f5c\u4e3a\u4e00\u4e2a\u2018\u5e7b\u89c9\u2019\u6807\u6ce8\u5668,\u6211\u5c06\u4f1a\u7ed9\u4f60\u63d0\u4f9b\u4e00\u4e2a\u4e00\u4e2a\u95ee\u9898,\u4e00\u4e2a\u9488\u5bf9\u8be5\u95ee\u9898\u7684\u90e8\u5206\u56de\u7b54\u548c\u76f8\u5173\u7684\u53c2\u8003\u8981\u70b9\u3002\u4f60\u9700\u8981\u5224\u65ad\u63d0\u4f9b\u7684\u56de\u7b54\u4e2d\u662f\u5426\u542b\u6709\u5e7b\u89c9\u6027\u5185\u5bb9,\u5e76\u6807\u6ce8\u5e7b\u89c9\u7c7b\u578b\u3002\n\u201c\u5e7b\u89c9\u201d\u6307\u7684\u662f\u4e0e\u53c2\u8003\u8981\u70b9\u76f8\u77db\u76fe\u6216\u5728\u53c2\u8003\u8981\u70b9\u4e2d\u6ca1\u6709\u4f9d\u636e\u7684\u5167\u5bb9\u3002\n##\u5224\u65ad\u51c6\u5219:\n1. \u65e0\u5e7b\u89c9:\u5982\u679c\u56de\u7b54\u4e0e\u53c2\u8003\u8981\u70b9\u5b8c\u5168\u4e00\u81f4,\u4e14\u6ca1\u6709\u5f15\u5165\u4e0e\u53c2\u8003\u8981\u70b9\u76f8\u77db\u76fe\u7684\u4fe1\u606f,\u8bf7\u8f93\u51fa:<\u65e0\u5e7b\u89c9>\u3002\n2. \u77db\u76fe:\u5982\u679c\u56de\u7b54\u5185\u5bb9\u4e0e\u53c2\u8003\u8981\u70b9\u5b58\u5728\u660e\u663e\u77db\u76fe,\u8bf7\u8f93\u51fa:<\u77db\u76fe>\u3002\n3. \u65e0\u6cd5\u9a8c\u8bc1:\u5982\u679c\u56de\u7b54\u5305\u542b\u7684\u4fe1\u606f\u5728\u53c2\u8003\u8981\u70b9\u4e2d\u6ca1\u6709\u63d0\u53ca,\u4e14\u65e0\u6cd5\u4ece\u53c2\u8003\u8981\u70b9\u4e2d\u5f97\u5230\u652f\u6301\u6216\u9a8c\u8bc1,\u8bf7\u8f93\u51fa:<\u65e0\u6cd5\u9a8c\u8bc1>\u3002"}, {"title": "English Prompt:", "content": "I would like you to act as a question generator. I will provide references and you will generate 10 questions about \"{topic}\" based on the reference. The specific requirements are as follows:\n1. the questions can be fully answered based only on the reference document, i.e. the answers to the questions are fully contained in the reference document. The questions should be objective and not too subjective or open-ended.\n2. the 10 questions should be of as many different types as possible, e.g. what, when, where, why. Questions can be asked from different perspectives, e.g. descriptions, explanations, reasons, etc. Ensure that the questions are of different types and cover all aspects of the information.\n3. 10 questions can cover different levels of knowledge, from general, basic knowledge to more specialized, complex subject knowledge or domain knowledge.\n4. have only one question per item.\nReference: {reference document}\nPlease list the 10 questions directly based on the above reference without any explanation:"}, {"title": "Chinese Prompt:", "content": "\u6211\u5e0c\u671b\u4f60\u5145\u5f53\u4e00\u4e2a\u95ee\u9898\u751f\u6210\u5668\u3002\u6211\u5c06\u63d0\u4f9b\u53c2\u8003\u8d44\u6599,\u4f60\u5c06\u6839\u636e\u8d44\u6599\u751f\u6210\u5173\u4e8e\u201c{topic}\u201d\u768410\u4e2a\u95ee\u9898\u3002\u5177\u4f53\u8981\u6c42\u5982\u4e0b:\n1. \u53ea\u6839\u636e\u53c2\u8003\u8d44\u6599,\u5b8c\u5168\u53ef\u4ee5\u56de\u7b54\u95ee\u9898,\u5373\u95ee\u9898\u7684\u7b54\u6848\u5b8c\u5168\u5305\u542b\u5728\u53c2\u8003\u8d44\u6599\u4e2d\u3002\u95ee\u9898\u8981\u5ba2\u89c2,\u4e0d\u8981\u592a\n\u8fc7\u4e3b\u89c2\u548c\u5f00\u653e\u3002\n2. 10\u4e2a\u95ee\u9898\u5c3d\u91cf\u662f\u4e0d\u540c\u7c7b\u578b\u7684,\u6bd4\u5982:\u4ec0\u4e48\u3001\u4f55\u65f6\u3001\u4f55\u5730\u3001\u4e3a\u4ec0\u4e48\u3002\u95ee\u9898\u53ef\u4ee5\u4ece\u4e0d\u540c\u7684\u89d2\u5ea6\u51fa\u53d1,\u4f8b\n\u5982\u63cf\u8ff0\u3001\u89e3\u91ca\u3001\u539f\u56e0\u7b49\u3002\u786e\u4fdd\u95ee\u9898\u7c7b\u578b\u591a\u6837,\u8986\u76d6\u8d44\u6599\u7684\u5404\u4e2a\u65b9\u9762\u3002\n3. 10\u4e2a\u95ee\u9898\u53ef\u4ee5\u6d89\u53ca\u4e0d\u540c\u5c42\u6b21\u7684\u77e5\u8bc6,\u4ece\u5e38\u8bc6\u6027\u3001\u57fa\u672c\u6027\u7684\u77e5\u8bc6,\u5230\u66f4\u4e13\u4e1a\u5316\u3001\u590d\u6742\u5316\u7684\u5b66\u79d1\u77e5\u8bc6\u6216\n\u9886\u57df\u77e5\u8bc6\u3002\n4. \u6bcf\u6761\u53ea\u6709\u4e00\u4e2a\u95ee\u9898\u3002\n\u53c2\u8003\u8d44\u6599:{reference document}\n\u8bf7\u6839\u636e\u4ee5\u4e0a\u53c2\u8003\u8d44\u6599,\u4e0d\u505a\u8bf4\u660e\u76f4\u63a5\u5217\u51fa10\u4e2a\u95ee\u9898:"}, {"title": "English Prompt:", "content": "Reference document: {reference document}\nPlease answer the question based on the above reference: {question}"}, {"title": "Chinese Prompt:", "content": "\u53c2\u8003\u8d44\u6599:{reference document}\n\u8bf7\u6839\u636e\u4ee5\u4e0a\u53c2\u8003\u8d44\u6599,\u56de\u7b54\u95ee\u9898:{question}"}]}