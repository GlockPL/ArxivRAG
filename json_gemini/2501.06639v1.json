{"title": "Enhancing Path Planning Performance through Image\nRepresentation Learning of High-Dimensional Configuration Spaces", "authors": ["Jorge Ocampo Jimenez", "Wael Suleiman"], "abstract": "This paper presents a novel method for accelerating\npath-planning tasks in unknown scenes with obstacles by utilizing\nWasserstein Generative Adversarial Networks (WGANs) with\nGradient Penalty (GP) to approximate the distribution of\nwaypoints for a collision-free path using the Rapidly-exploring\nRandom Tree algorithm. Our approach involves conditioning\nthe WGAN-GP with a forward diffusion process in a continuous\nlatent space to handle multimodal datasets effectively. We also\npropose encoding the waypoints of a collision-free path as a\nmatrix, where the multidimensional ordering of the waypoints\nis naturally preserved. This method not only improves model\nlearning but also enhances training convergence. Furthermore,\nwe propose a method to assess whether the trained model\nfails to accurately capture the true waypoints. In such cases,\nwe revert to uniform sampling to ensure the algorithm's\nprobabilistic completeness; a process that traditionally involves\nmanually determining an optimal ratio for each scenario in other\nmachine learning-based methods. Our experiments demonstrate\npromising results in accelerating path-planning tasks under\ncritical time constraints. The source code is openly available at\nhttps://bitbucket.org/joro3001/imagewgangpplanning/src/master/.", "sections": [{"title": "I. INTRODUCTION", "content": "Machine learning techniques, such as neural network gen-\nerative models like Variational Autoencoders (VAEs) [1] and\nGenerative Adversarial Networks (GANs) [2], have been used\nto improve the efficiency of random sampling algorithms.\nThese models bias the sample distribution towards collision-\nfree states, conditioned on the robot's current workspace\nconfiguration. While previous research has successfully ap-\nplied GANs [2], [3], [4] to tasks such as generating inverse\nand forward kinematics, there has been limited exploration\nof using GANs with gradient penalties in high-dimensional\nproblems. This is largely due to the increased complexity and\ncomputational cost associated with such approaches.\nMoreover, it has been demonstrated that Wasserstein GANS\n(WGANs) are highly sensitive to hyperparameter tuning. This\nsensitivity arises because the transport cost between the image\nand waypoints of a collision-free path derived from a training\ndataset is often represented by discontinuous functions [5].\nAnother challenge in employing machine learning algo-\nrithms for waypoint sampling is the inherent inaccuracy of the"}, {"title": "II. PROPOSED METHOD", "content": "To address challenges such as unstable training processes,\nextended training times, and the potential for unexpected\noutcomes when encountering unseen conditions during path\nplanning, we propose to:\n\u2022 Select a forward diffusion process from an SDE model\nto train the input condition of the workspace. Unlike\nusing an encoder from a VAE, the SDE approach does\nnot require joint training with the generative model, sim-\nplifying the training process while maintaining effective\nperformance.\n\u2022 Reduce the number of images in the input of the trained\nnetwork by using affinity propagation. This process re-\nduces the number of samples per epoch during training\nby representing the whole waypoint set as a matrix.\n\u2022 Exploit in the cases of bounded configuration spaces, the\nfact that the samples clustered by the affinity points are\nbounded too; thus, we could reject samples too far from\ntheir means in the bounded sets; removing the need of\nfinding an optimal sampling ratio between the uniform\ndistribution and the learned one.\nOur model is trained using forward kinematics simulations\nwith the Baxter manipulator robot. We create multiple scenar-\nios by placing random human models around the robot and\nusing RGB-D representations of the robot's obstacles to train\nour model to estimate the waypoints of a collision-free path.\nWe evaluate the performance of our model using metrics\nsuch as planning time, path length, and success rate. This\nevaluation enables us to assess the impact of changes in the\nconditions and encoding of configuration states on the model's\nability to generate new waypoints. To establish a baseline for\ncomparison, we employed paths generated by RRT and RRT*.\nOur experiments demonstrated that our model is capable of\nfinding shorter and faster paths in time-constrained scenarios."}, {"title": "III. ORIGINAL CONTRIBUTIONS", "content": "This paper offers several novel contributions, including:\n1) Introducing a new architecture that enhances WGAN-\nGP training by embedding the condition as an additional\nchannel in the RGB-D representation of the working\nspace (WS).\n2) Reducing the number of queries by generating all the\nwaypoints in one query.\n3) Introducing a new methodology that discards samples\nfrom the trained model during deployment of the planner\nwhen a probability threshold is met in bounded config-\nuration spaces, thus preserving probabilistic complete-\nness.\n4) Enhancing path planning performance in terms of time,\nsuccess rate, and path length compared to algorithms\nlike RRT and RRT* under time constraints.\nCompared to other similar works where the planner's sampling\nis biased, our method offers several advantages, including:\n\u2022 By utilizing both GANs and forward diffusion, our model\ncan handle noisy or previously untrained scenarios while\ngenerating high-quality WGAN samples.\n\u2022 Our image-to-image model has the potential to extend\nto the prediction of higher-dimensional waypoints for\nrobotic tasks using image processing algorithms, thereby\nreducing the number of connections between networks by\nemploying pattern-based deep neural network models.\n\u2022 Unlike other machine-learning methods [1], [6] that de-\npend on finding an appropriate ratio between uniform or\nbiased distributions for RRT-based planners, our approach\nis established an error bound to reject the sampling of the\ntrained model."}, {"title": "IV. RELATED WORK", "content": "The use of learning by demonstration has proven to be an\neffective approach in numerous studies aimed at enhancing the\nperformance of sampling-based random planners [7]. A com-\nmon technique involves employing an auto-generative model\nthat learns a mapping between a robot's configuration space\n(C) and the image-based scenario, using a reduced number\nof samples from the full distribution. In recent years, deep\nneural network (DNN) models have gained significant traction\nin this field due to their ability to process large volumes of\ninput data, such as image or point cloud representations of the\nrobot's environment, and to generalize across a wide range\nof examples, including potential robot configurations and the\nnumber and location of obstacles in the workspace.\nWhile DNNs allow conditioning in high-dimensional\nspaces; they are trained as unimodal models, which fail to\ncapture the inherent diversity and multiple modes in the\ndata. In contrast, Deep Generative models have demonstrated\ntheir ability of capturing high-dimensional multimodal data in\ncontexts like text and image generation [8].\nGenerative models are widely used in the context of\nRapidly-exploring Random Trees-based algorithms [9] for two\nmain purposes: to introduce a bias in the sampling process or\nto serve as a heuristic for the cost function. These models\nguide the algorithm towards lower-cost paths by taking into\naccount the specific conditions of the scenario.\nThe application of neural networks for learning the sam-\npling distributions to bias-sampled based planners was first\nintroduced in [6]. The study utilized a conditional variational\nautoencoder to identify areas in C that held promise based on\nthe initial and goal states, as well as the obstacles present in the\nscenario. This enabled the sampler of random path algorithms\nto be biased, resulting in more efficient path planning.\nIn another study [1], an encoder was used to capture\nenvironmental information, with the sampler conditioned on\nraw sensor data or voxelized output embedded in the la-\ntent space. The encoded information was then utilized by a\nplanning network, in conjunction with the current and goal\nstates, to generate the next state. This model can bias the\nsampler of RRT* [10] and has been tested on high-dimensional\nconfiguration spaces.\nThe research presented in [3] utilizes 2D working spaces as\ninputs for a conditional GAN. The GAN is conditioned on the\nRGB representation of both the initial and final points of the\npath, as well as the map of the working space. The generator is\ntrained with two discriminators: one for the obstacle map and\nanother for the initial and final goal states represented in the\nworking space. The resulting algorithm achieves an impressive\nsuccess rate of approximately 90% in generating connected\nconfigurations.\nThe study presented in [11] utilizes inverse reinforcement\nlearning to determine the weights of the RRT* cost function\nbased on the expected behavior of a robot in environments\npreviously occupied by humans. This approach helps guide\nthe planner towards the desired path. However, it may be less\nsuitable for dynamic environments where the weights cannot\nbe adjusted without compromising the asymptotic optimality\nof the algorithm.\nThe authors of [4] present an approach where GANs are\nused to bias an RRT-based planner by incorporating Encoders\nand Decoders directly as hidden layers in the generator. The\ninitial state, map, and latent vector are provided as inputs to the\nencoder, while the decoders output a 2D representation of the\npath. The generator thus produces the path as an output image,\ntreating the task as an image-to-image model. Although the\nauthors do not provide specific information on running times,\nit is reported that the algorithm requires fewer iterations to\nachieve a lower cost compared to RRT*.\nThe research presented in [2] explores the use of a GAN to\nlearn the inverse kinematics of high-dimensional robots. The\nmodel is conditioned on the target working space position of\nthe end effectors, enabling the generation of samples in high-\ndimensional Cs, which was previously infeasible. However, it\nis important to note that the conditioning is not directly based\non sensor data or the current state of the scenario.\nLately, significant advances in generative neural network\nmodels have been made, such as the diffusion generation\napproach in path planning [12], their application in random\nsampling-based planners remains limited, particularly in sce-\nnarios with strict time constraints for obtaining a collision-\nfree path. A common challenge with diffusion-based methods\nis their computational cost; repeatedly sampling from the\ndiffusion generator during the backward pass can be time-\nconsuming. For a more comprehensive discussion on the use\nof generative DNN models, we refer to the work of [8]."}, {"title": "V. PROBLEM FORMULATION", "content": "The objective of this research is to develop a method for\napproximating waypoints of a collision-free path by leverag-"}, {"title": "VI. METHODOLOGY", "content": "We propose a novel approach for accelerating sampling-\nbased motion planning algorithms by generating waypoints of\na path in $C_{free}$ with additional properties such as feasibility\nand connectivity with the current path. Our approach utilizes\na WGAN to sample from a learned distribution over $C_{free}$,\nwhich biases the sampling process towards regions of C more\nlikely to yield waypoints. Specifically, we employ a WGAN-\nGP to generate high-quality collision-free configurations with-\nout the need to determine a suitable clipping interval. This\nmethod replaces the uniform distribution typically used for\nsampling C and results in faster query times. The proposed\narchitecture is illustrated in Fig. 1. In this architecture, we\nsimplify the original number of waypoints-states by learning\nthe centroid of clusters when the number of waypoints is\nhigher than the matrix representation; then, the clusters follow\nan already multidimensional sort given the order of the way-\npoints in a path; this increases the chances of having smooth\ngradients during training. New waypoint clusters are generated\nby applying positional encoding to the initial and final states\nof the desired path to an RGB-D image representation of the\ncurrent WS of the robot. The RGB-D is then diffused through a\ncontinuous stochastic process, which serves as the latent space\nof a generative neural network capable of predicting the sorted\nmultidimensional waypoints. To recover any potential missing\nstates of a collision-free path within these clusters, sampling\nis performed around the predicted centroids."}, {"title": "A. Generative Model", "content": "Deep generative models are based on estimating the prob-\nability distribution of a dataset X where the probability\ndistribution $P_{X}$ is unknown. In particular, the assumption is\nmade that the unknown distribution $P_{X}$ can be approximated\nby a parametric distribution $P_{\\omega}$; where $\\omega \\in \\Omega$ with $\\Omega$ defined\nas a parametric space. $P_{\\omega}$ should be marginalized over a latent\nvariable Z\n$P_{\\omega}(x) = \\int p(x|z)p(z)dz$ (1)\nThere are mainly two well-known methodologies that utilize\nsuch approach for deep generative models, one is GAN [14],\nwhere the density $p_{\\omega}$ does not have an explicit analyti-\ncal form. Instead, a random variable Z is sampled from a\nspecified random distribution, and a deterministic function"}, {"title": "B. Clustering", "content": "We aim to simplify the training of the model given the num-\nber of data samples. Typically, other approaches that use DNNs\ninvolve tuples of image inputs and vector outputs to represent\ndifferent samples from $C_{free}$ used to train the approximation.\nHowever, approximating each image/sample of $C_{free}$ in a large\ndataset requires processing a significant number of images per\nbatch, which can slow down performance when the dataset is\nrelatively large.\nIn our approach, we propose to estimate the entire list of\nwaypoints in a single step. However, this is impractical due to\nthe infinite number of samples in a continuous $C_{free}$. Instead,\nwe aim to learn parameters that can generate an approximation\nof the total number of waypoints. One possible method is\nto use clustering techniques, which only require learning the\nparameters of the distribution to reconstruct the original space.\nHowever, methods like Gaussian Mixture Models (GMMs)\npose challenges during training. The random selection of initial\ncentroids and the problem of solving the approximation using\nExpectation-Maximization often lead to different models even\nwith the same parameters. This variability in cluster assign-\nment means that the DNN may struggle to find a continuous\nmap. In addition; when GMMs parameters are learned in the\ncontext of sampling based path planners; it can be challenging\nto condition the model [11] [7].\nAs an alternative, we propose using affinity propagation\n[19]. Unlike GMMs, which require specifying the number of\nclusters, affinity propagation identifies exemplars directly from\nthe dataset. It does not require defining the number of clusters\nin advance.\nAffinity propagation operates by exchanging two types of\nmessages between data points: the responsibility function,\nwhich measures how well a proposed data point represents its\nneighbors, and the availability function, which accumulates the\nresponsibilities from other data points. This iterative process\ncontinues until convergence or a fixed number of iterations is\nreached. This method reduces the variance in cluster locations\nderived from the training dataset of waypoints in $C_{free}$, as"}, {"title": "C. Image Representation and Conditioning", "content": "Following the universal approximation theorem, DNNs are\nable to approximate any continuous function given an arbitrary\nnumber of activation functions. Thus, it is to our advantage to\nrepresent the training data problem as a continuous function.\nIn our case, given that we have $C_{free} \\in R^{n}, n \\geq 2$, a non-\nconstrained approximation of $C_{free}$ represented as an image\nwill rarely be continuous pixel-wise. However, the waypoints\nin $C_{free}$ that are part of a constrained path have a hierarchical\nordering. Particularly, in the case of the shortest path; the\naffinity points of the set of waypoints can be represented an\nimage with an almost continuous gradient; as shown in Fig.\n3.\nThe matrix representation effectively reduces the paired\ntraining data between the RGB-D and each of the waypoints in\n$C_{free}$. Thus, we transform the problem to an image-to-image\nfunction, where each image represents the whole path in $C_{free}$.\nThis process is exemplified in Fig. 4.\nNext, to overcome the challenges of the adversarial training\nof WGAN, we used the forward diffusion process on the input\nRGB-D images as explained previously."}, {"title": "D. Planner", "content": "To guide the path towards the desired region in $C_{free}$,\nwe utilize a technique inspired by [25]; where a 2D C is\nrepresented as an image for the DNN to be learned by\nconvolution layers. Our approach involves using a DNN's\nmodel generator trained by an adversarial loss function as\na sampler for the RRT path planning algorithm. However,\nwe made a modification in our implementation to reject the\nsampling from the training model given the probability of the\ndata around an estimated waypoint being in the complement\nof $C_{free}$.\nOne advantage of our proposal compared with other ap-\nproaches in the field of path planning using random trees\nand DNNs is that we can estimate when our approximation\nhas most likely failed. Given that the probability of selecting\na sample on the tail of the Gaussian distributions of each\nexemplar decays exponentially, we have an upper bound to\nour trained model to know when the generator $f_{\\omega}$ most likely\nfailed to approximate a bounded $C_{free}$."}, {"title": "VII. EXPERIMENTAL RESULTS", "content": "All the models are trained on a system with 2 x Intel Gold\n6148 Skylake, 16 GB of RAM and 2 x Nvidia V100SXM2.\nFor deployment, we use Ubuntu 20.04 running on a 3.60 GHz\n\u00d7 8 Intel Core i9-9900KF processor, 16GB RAM on Nvidia\nRTX 2070.\nWe propose a set of experiments to examine the effec-\ntiveness of learning the waypoints of a constrained path.\nThese waypoints are used to bias the sampling of $C_{free}$\nstates to find a collision-free path, as described in Section\nVI. The constrained approximation illustrates how well the\nconditioning of $C_{free}$ is encoded in the RGB-D+ input and\nalso provides insight into how the implementation might work\nin real-world problems.\nWe use a combination of 100 WSs/$C_{frees}$ with 100 different\nstarting and goal configurations. All WSs and waypoints are\nderived from a simulated Baxter's 7-DOF right arm. All input\nimages of the scenarios were resized to 32 x 32 pixels.\nWe utilized the PyTorch Lightning framework with Adam\noptimizer parameters derived from [17] for training. Our\nexperimental hyperparameters consisted of a learning rate of\n4e-5, a batch size of 128, a regularization coefficient \u5165 of 10\nfor the gradient penalty, and $n_{critic}$ = 5 training iterations per\ngenerator iteration. All Cs are scaled between [0,1] in their\nmatrix encoding. Our code is available on Bitbucket\u00b9.\nWe employ a simulated RealSense RGB-D sensor to rep-\nresent the conditioning factor in our experiment. This image\ncaptures the obstacles' representation within the robot's op-\nerational space. In cases of constrained paths by path length,\nwe add the initial and final states of the shortest path as an\nextra channel. To streamline the experimentation process, we\nopted for a human model spawning in a random position and\norientation within Baxter's working space. The initial and final\nconfigurations of the arm are chosen randomly.\nFor the test, we train the generator using waypoints of\nthe shortest path between random goal and start configu-\nrations. The shortest path depends on the initial and goal\nconfigurations; thus, the goal and start states condition the\ngeneration of the waypoints to generate the RGB-D+ training\ndata. The original waypoints of the shortest path were obtained\nby running RRT* for 30 seconds. We used RRT* paths\nas training data, which provided a more stable distribution\nthat did not fluctuate significantly when the configuration\nspace was changed. We used path length as the minimization\nobjective for the generator training, as it provides a reliable\nmeasure of the quality of the generated paths.\nTo implement the trained sampler, we utilized the Open\nMotion Planning Library (OMPL) [27] implementations of\nRRT and RRT*. To compare how well the constraints were\nmaintained by the trained model, we ran 3500 different,\npreviously unseen scenarios with random goals and states,\nsimilar to the previous section. Each algorithm was run for"}, {"title": "VIII. CONCLUSION AND FUTURE WORK", "content": "In this work, we have presented a novel approach for\ntraining WGAN-GP models conditioned by continuous latent\nmatrices, which can be utilized for tasks related to waypoints\nprediction and path planning. We also proposed using the para-\nmetric learned model to evaluate whether the approximation\nhas failed in predicting the waypoints in $C_{free}$. Additionally,\nwe explored incorporating extra channels from the RGB-D\nworking space to constrain the path to a specific cost function.\nThe experiments indicated that using images as a representa-\ntion of waypoints in $C_{free}$ stabilizes training and simplifies the\ndeep neural network (DNN) models by utilizing convolutional\nnetworks instead of fully connected DNNs. The inclusion\nof high-dimensional ordering contributes to creating almost\ncontinuous training data in the image space. However, it is\nimportant to note that poor approximations of the waypoints\ncould increase the planning time to be in par with the original\nsampler of the path planner, as regions not part of the collision-\nfree path will be explored first.\nThe results of our experiments demonstrate that our pro-\nposed model is capable of generating collision-free paths\nin unknown scenarios with an improved success rate and\nreduced running time compared to conventional path planning\nalgorithms such as RRT and RRT*. This is particularly useful\nwhen these algorithms are constrained by a specific running\ntime, making our approach valuable for real-world scenarios.\nIn the case of having a bad approximation of the waypoints,\nour proposed approach is capable of rejecting such samples\nand revert to a uniform sampler without input from the user\nabout the ratio between samplers, a capability non-previously\nseen in other works.\nWe have also shown the effectiveness of our method in\nplanning paths in a 7-dimensional space for a humanoid-\nmanipulator robot. To establish the broader applicability of"}]}