{"title": "NYAYA ANUMANA and INLEGALLLAMA:\nThe Largest Indian Legal Judgment Prediction Dataset and Specialized\nLanguage Model for Enhanced Decision Analysis", "authors": ["Shubham Kumar Nigam", "Noel Shallum", "Balaramamahanthi Deepak Patnaik", "Shivam Mishra", "Kripabandhu Ghosh", "Arnab Bhattacharya"], "abstract": "The integration of artificial intelligence (AI)\nin legal judgment prediction (LJP) has the po-\ntential to transform the legal landscape, par-\nticularly in jurisdictions like India, where a\nsignificant backlog of cases burdens the legal\nsystem. This paper introduces NyayaAnumana,\nthe largest and most diverse corpus of In-\ndian legal cases compiled for LJP, encompass-\ning a total of 7,02,945 preprocessed cases.\nNyayaAnumana, which combines the words\n\"Nyaya\" and \"Anumana\u201d that means \"judgment\"\nand \u201cinference\u201d respectively for most major In-\ndian languages, includes a wide range of cases\nfrom the Supreme Court, High Courts, Tribunal\nCourts, District Courts, and Daily Orders and,\nthus, provides unparalleled diversity and cov-\nerage. Our dataset surpasses existing datasets\nlike PredEx and ILDC, offering a comprehen-\nsive foundation for advanced Al research in the\nlegal domain. In addition to the dataset, we\npresent INLegalLlama, a domain-specific gen-\nerative large language model (LLM) tailored\nto the intricacies of the Indian legal system. It\nis developed through a two-phase training ap-\nproach over a base LLaMa model. First, Indian\nlegal documents are injected using continual\npretraining. Second, task-specific supervised\nfinetuning is done. This method allows the\nmodel to achieve a deeper understanding of\nlegal contexts. Our experiments demonstrate\nthat incorporating diverse court data signifi-\ncantly boosts model accuracy, achieving ap-\nproximately 90% F1-score in prediction tasks.\nINLegalLlama not only improves prediction\naccuracy but also offers comprehensible expla-\nnations, addressing the need for explainability\nin AI-assisted legal decisions.", "sections": [{"title": "1 Introduction", "content": "The integration of artificial intelligence (AI) in le-\ngal judgment prediction (LJP) has the potential\nto revolutionize the legal landscape, offering both\nchallenges and opportunities. In India, where the\nlegal system faces a significant backlog of lakhs\nof pending cases, the application of AI in LJP can\nbe crucial for enhancing efficiency and accessibil-\nity. However, the complexity and diversity of legal\ncases present significant challenges in developing\neffective AI models. To address these challenges,\nwe introduce NyayaAnumana, the largest and most\ndiverse corpus of Indian legal cases compiled for\nLJP, covering various levels of the judiciary. The\nname \"NyayaAnumana\u201d is formed by a combina-\ntion of the words \u201cNyaya\u201d and \u201cAnumana\" that\nmean \"judgment\u201d and \u201cinference\u201d respectively for\nmost major Indian languages. This name reflects\nthe core focus of the dataset on legal judgments and\ntheir corresponding predictions, emphasizing its\nrole in facilitating AI-driven insights within the le-\ngal domain. Our corpus stands out when compared\nto other popular corpora used in legal judgment pre-\ndiction, surpassing them in terms of the number of\ncases, diversity of court levels, and comprehensive\ncoverage of Indian legal proceedings. This richness and variety offer a unique\nopportunity to explore and predict legal judgments\nmore accurately and nuanced than ever before.\nWe develop INLegalLlama, a domain-specific\ngenerative large language model, tailored to the in-\ntricacies of the Indian legal domain. It is trained to\nenhance the accuracy of predictions of legal judg-\nments and provide understandable explanations for\nthese decisions. This dual approach caters to the\nneeds of legal experts who seek not just accuracy\nbut also rationale in AI-assisted decisions.\nOur work is distinguished by several key contri-\nbutions that mark significant advancements in the\nfield of legal AI:\n1. Largest Indian Legal Corpus for Judgment Pre-\ndiction: We introduce NyayaAnumana, the most\nextensive legal corpus in India for LJP, encom-\npassing a wide range of courts and orders, en-\nsuring diversity and comprehensive coverage in\nthe dataset."}, {"title": "2 Related Work", "content": "The field of Legal Judgment Prediction (LJP)\nthrough AI has progressed significantly over the\nlast few years. Traditionally the domain of legal\nexperts, LJP systems offer potential benefits for\npractitioners and the public, particularly in man-\naging overwhelming caseloads in various jurisdic-\ntions. Foundational studies by established the methodologies for LJP and high-\nlighted the critical need for explainability in AI-\ngenerated predictions. Benchmark datasets such as\nCAIL2018, ECHR-CASES and others\nhave propelled research by providing a foundation\nfor model evaluation. Despite these advances, chal-\nlenges persist in achieving machine performance\ncomparable to human expertise.\nIn the Indian context, significant contributions\ninclude PredEx and ILDC"}, {"title": "3 Task Description", "content": "Our research focuses on advancing the Legal Judg-\nment Prediction (LJP) task, which encompasses\ntwo primary components: Prediction and Expla-\nnation. These components are executed sequen-\ntially to address the crucial needs of predicting le-\ngal judgments and providing justifications for these\npredictions. Prediction Task: The LJP task's core objective\nis to predict a legal case's outcome based on the\ncase proceedings. Unlike previous studies primar-\nily focusing on binary classification (acceptance\nor rejection), our study also classifies cases with\npartially accepted outcomes. Given a document\n$D$, the task is to predict the decision $y \\in {0,1,2}$,\nwhere '0' denotes the rejection of all appeals by\nthe appellant, '1' represents the acceptance of all\nappeals, and '2' indicates partial acceptance of the\nappeals.\nExplanation Task: The second component of the\nLJP task involves explaining the model's predicted\ndecision. To address the need for explainability,"}, {"title": "4 Dataset", "content": "We introduce the dataset NyayaAnumana, which is\nthe largest and most diverse corpus of Indian legal\ncases ever compiled, covering judgments from the\nSupreme Court, High Courts, Tribunal courts, Dis-\ntrict courts, and Daily orders. This comprehensive\ndataset offers unparalleled diversity and coverage,\naddressing existing gaps and providing a rich foun-\ndation for advanced legal AI research."}, {"title": "4.1 Dataset Compilation", "content": "The dataset compilation process involved gather-\ning a corpus of 22,82,137 Indian court case pro-\nceedings up to April 2024. We utilized the In-\ndianKanoon website, a well-known legal search\nengine, to collect these documents. This source is\nwidely recognized for its comprehensive database\nof Indian legal documents, making it an invaluable\nresource for our dataset."}, {"title": "4.2 Data Statistics", "content": "The NyayaAnumana dataset exhibits extensive data\nstatistics, vital for understanding the dataset's\nscope and characteristics. The overall dataset is\ndivided into 'multi' and 'single' categories based"}, {"title": "4.2.1 Injecting Legal Knowledge", "content": "To address the deficiency of legal knowledge in\nthe base LLaMa model, we employed a contin-\nued pretraining (CPT) approach using a compre-\nhensive Indian legal corpus. Due to resource con-\nstraints, we used a subset of the full NyayaAnumana\ndataset for this pretraining phase. This subset in-\ncludes preprocessed data comprising 38,321 cases\nfrom the Supreme Court of India (SCI) and a ran-\ndomly selected 1,00,000 cases from various High\nCourts. These choices were made to balance com-\nputational feasibility and the inclusion of diverse\nand representative legal cases. This extensive yet\nmanageable training corpus was essential for em-\nbedding domain-specific legal knowledge into the\nmodel. Additionally, the validation dataset con-\nsisted of 12,239 documents sourced from both SCI\nand High Courts, ensuring that the model was rig-\norously tested and fine-tuned for the nuances of the\nIndian legal system. By focusing on a strategically\nchosen subset, we aimed to maximize the impact\nof the training within the available computational\nresources. This approach enhances the model's\nunderstanding and applicability within the Indian\nlegal framework, thereby improving its predictive\ncapabilities and relevance in legal tasks."}, {"title": "4.2.2 Learning Reasoning Skills", "content": "To equip the model with the necessary reason-\ning capabilities for solving prediction and expla-\nnation problems, we conducted supervised fine-\ntuning (SFT) using selected data from downstream\ntasks on the PredEx training dataset which consists of 12,178 cases accompa-\nnied by corresponding case decisions and explana-\ntions annotated by legal experts. By performing\nSFT on this dataset, we aimed to enhance its reason-\ning skills and ability to comprehend and apply legal\nprinciples effectively. This targeted fine-tuning ap-\nproach helps bridge the gap between the model's\ngeneral knowledge and the specific requirements\nof legal reasoning tasks, ultimately improving its\nperformance in real-world legal scenarios."}, {"title": "4.2.3 Prediction Task", "content": "For prediction, we split the NyayaAnumana single\ndataset into training, validation, and test sets in the\nratio 70:10:20. A key component of our research\ninvolved comparing the performance of models\ntrained on NyayaAnumana with those trained on the\nILDC 2021 test dataset. This\ncomparison is crucial for benchmarking our mod-\nels and understanding their efficacy compared to\nestablished datasets in the field. By testing against\nILDC 2021, we aim to evaluate the improvements\nin prediction accuracy and model robustness that\nNyayaAnumana offers, showcasing its contribution\nto the evolving landscape of legal AI in India. We\nalso tested the model performance on temporal\ndata, assessing its effectiveness on future or unseen\ndata from January 2020 to April 2024 to ensure ro-\nbustness and generalization capabilities over time,"}, {"title": "4.2.4 Prediction with Explanation Task", "content": "For this task, we used the PredEx 2024 test dataset\nwhich includes 3,044 bal-\nanced cases. The balanced nature of the test set is\nparticularly important for maintaining the validity\nof our experiments and ensuring the reliability and\ngeneralizability of our model's performance."}, {"title": "5 Model Training: INLegalLlama", "content": ""}, {"title": "5.1 Injecting Legal Knowledge", "content": "To address the limitations of legal knowledge inher-\nent in the base LLaMa model, we adopted a con-\ntinued pretraining (CPT) strategy utilizing a com-\nprehensive Indian legal corpus. For this purpose,\nwe selected the LLaMa2-7B architecture which features a substantial context\nlength of 2K, allowing for effective handling of\nlegal texts. This choice facilitates a direct compari-\nson with previous state-of-the-art results on the Pre-\ndEx dataset This approach\nsignificantly enhances the model's understanding\nand relevance within the Indian legal framework,\nthereby improving its predictive capabilities and\napplication in legal tasks."}, {"title": "5.2 Learning Reasoning Skills", "content": "To further develop the model's reasoning skills,\nparticularly for legal prediction and explanation\ntasks, we conducted supervised finetuning (SFT)\nusing data from specific downstream tasks. This\ndataset includes case decisions along with their\ncorresponding explanations, all annotated by legal\nexperts. The fine-tuning process was crucial for\nenhancing the model's ability to understand and\napply legal principles effectively, bridging the gap\nbetween general knowledge and the specialized\nrequirements of legal reasoning tasks. This focused\nfine-tuning was pivotal in improving the model's\nperformance in real-world legal scenarios.\nHowever, the fine-tuning of such models typi-\ncally demands substantial computational resources\nand extensive training data. Given the constraints\nof limited computational power and the specific\nnature of our legal task-related dataset, we prior-\nitized efficient training methods to optimize both\ncomputational costs and data usage. We employed\nparameter-efficient tuning techniques, such as the\nLow-Rank Adaptation (LoRA) method to fine-tune the LLaMa-2 7B model. This\napproach enabled us to maximize the utility of\navailable data and minimize the need for extensive\ncomputational resources, ensuring a cost-effective\nyet powerful fine-tuning process for developing\nINLegalLlama."}, {"title": "6 Methodology", "content": ""}, {"title": "6.1 Judgment Prediction", "content": "The judgment prediction task involves both binary\nclassification (e.g., favoring or opposing a party)\nand ternary classification (e.g., fully accepted, par-\ntially accepted, or rejected). We employ two dis-\ntinct approaches for this purpose: Language Model-\nbased and LLM-based strategies. These approaches\nare carefully designed to handle the complexity and\ndiversity of Indian legal documents, ensuring ro-\nbust performance across various scenarios."}, {"title": "6.1.1 Language Model based", "content": "In our approach, we utilized several language\nmodels, including InLegalBERT, InCaseLaw and XLNet (large) as baselines for binary and ternary classification.\nDue to the length constraints of complete judg-\nments, which exceed the token capacity of these\nmodels, we adopted a chunking strategy. Each doc-\nument was divided into 512-token chunks using a\nmoving window approach with a 100-token overlap\nto preserve textual context."}, {"title": "6.1.2 Large Language Model based", "content": "To utilize LLMs in prediction, we employed two\nstrategies: one involving only prediction instruc-\ntions and the other prediction with explanation\ninstructions. We used two methods to get pre-\ndictions from INLegalLlama after CPT and CPT\nfollowed by SFT. We followed the prompts and\ninstruction-tuning approaches published by in a few-\nshot setup, and used the PredEx training data for\ninstruction-tuning."}, {"title": "6.2 Judgment Prediction with Explanation", "content": "For this task, we employed the same LLMs with\nsettings similar to the Judgment Prediction task,\nbut with modified instructions focusing on both\nprediction and explanation."}, {"title": "6.3 Prompts Used", "content": "For both task inferences we utilized prompts from These prompts, which include\na case description and a gold standard prediction\nlabel, guide the LLM to generate judicial decisions.\nThe details of these prompts can be found in Table"}, {"title": "6.4 Instruction-Set", "content": "For both judgment prediction and explanation, we\nused 16 instruction sets correspondingly published\nby For a comprehensive\nview of all instruction sets which was randomly\ngiven to the model for tuning, we have included the\nfull list in Table 14 in the Appendix of this paper."}, {"title": "7 Evaluation Metrics", "content": "In this study, we employed a comprehensive set of\nevaluation metrics to assess the performance of our\nmodels on the NyayaAnumana judgment prediction\nand PredEx explanation test datasets. We report\nMacro Precision, Macro Recall, Macro F1, and\nAccuracy for judgment prediction, and we use both\nquantitative and qualitative methods to evaluate the\nquality of explanations generated by the model.\n1. Lexical-based Evaluation: We utilized stan-\ndard lexical similarity metrics, including Rouge\nscores (Rouge-1, Rouge-2, and Rouge-L) , BLEU and ME-\nTEOR . These met-\nrics measure the overlap and order of words\nbetween the generated explanations and the ref-\nerence texts, providing a quantitative assessment\nof the lexical accuracy of the model outputs.\n2. Semantic Similarity-based Evaluation: To\ncapture the semantic quality of the generated\nexplanations, we employed BERTScore which measures the semantic simi-\nlarity between the generated text and the ref-\nerence explanations. Additionally, we used\nBLANC , a metric that\nestimates the quality of generated text without a\ngold standard, to evaluate the model's ability to\nproduce semantically meaningful and contextu-\nally relevant explanations.\n3. Expert Evaluation: Human evaluation was\na critical component of our assessment frame-\nwork. Legal experts reviewed the explanations\ngenerated by the models, rating them on a 1-5\nLikert scale based on criteria such as accuracy,\nrelevance, and completeness. A rating of 1 in-\ndicates that the information is irrelevant, while\na rating of 5 signifies that the explanation is su-\nperior to the expert's own explanation. The full\ndescription of the rating scores can be found in\nAppendix B - Rating Score Description, which\nis adapted from"}, {"title": "8 Results and Analysis", "content": ""}, {"title": "8.1 Judgment Prediction", "content": "Our experiments, as detailed in Table 5, which\nis trained on NyayaAnumana single, and Table 16\nin Appendix, which is trained on NyayaAnumana\nmulti reveal interesting insights into the perfor-\nmance of various models on the Judgment predic-\ntion results on the binary task across different court\ncases and temporal test cases, with models trained\non SCI + HCs + Tribunal + Daily Orders and Dis-\ntrict Court data from NyayaAnumana test data.\nOur findings indicate that contrary to previous\nresearch, larger models like XLNet did not consis-\ntently outperform smaller models. Instead, models\nspecifically trained on Indian legal data, such as\nInLegalBERT and InCaseLaw, performed compa-\nrably and, in some instances, even surpassed XL-\nNet large. Suggests that the inclusion of domain-\nspecific data significantly enhances performance.\nThe previous best results hovered around 79% accu-\nracy using XLNet with hierarchical BiGRU, while\nour best models achieved approximately 90% ac-\ncuracy, highlighting a substantial improvement."}, {"title": "8.2 Judgment Prediction with Explanation", "content": "The results, as presented in Table 8, offer valu-\nable insights into the comparative performance of\nmachine-generated explanations against those pro-\nvided by legal experts across various models. These\nevaluations cover lexical-based, semantic, and ex-\npert assessment metrics, specifically using the 50\ntest cases from the PredEx and 54 ILDC_expert comparisons with the INLegalLlama model with different\nsettings. This comprehensive evaluation frame-\nwork allows us to thoroughly assess the models'\nabilities to generate accurate and contextually rele-\nvant explanations.\nAdditionally, we experimented with the Aalap\nmodel, which is instruction-\ntuned on various Indian legal tasks, but it underper-\nforms in this task. This may be due to its lack of\nfocus on generating explanations alongside predic-\ntions, a complex requirement that might not have\nbeen sufficiently addressed during training. In con-\ntrast, comparisons with the INLegalLlama model\nunder different settings demonstrate our approach's\neffectiveness in improving the explainability and\naccuracy of AI-generated legal judgments."}, {"title": "8.2.1 Lexical-Based Evaluation", "content": "The performance of LLMs in generating explana-\ntions reveals that verbatim matches to reference\ntexts are not consistently high. However, it is im-\nportant to recognize that these metrics, although\nuseful, do not fully capture the models' capabilities\nin analyzing legal cases, predicting outcomes, and\ngenerating reasoning. Therefore, we also employed\nSemantic Similarity-Based Evaluation and Expert\nScore Evaluation to provide a more comprehensive\nassessment of the models' performance."}, {"title": "8.2.2 Semantic Evaluation", "content": "The semantic evaluation, particularly utilizing\nBERTScore, demonstrates better alignment of the\ngenerated explanations with the gold standard, in-\ndicating a strong semantic understanding of the\nexplanations produced. INLegalLlama shows su-\nperior performance in terms of semantic similarity.\nIt is important to note that generative models may\noccasionally produce hallucinated content, which"}, {"title": "8.2.3 Expert Evaluation", "content": "Assessing the performance of generative models\nin the task of LJP requires the insight of domain-\nspecific experts. The expert evaluation, summa-\nrized in Table 8, indicates that our INLegalLlama\nmodel, performs exceptionally well, although it\nsometimes generates truncated or repetitive content.\nDespite these minor drawbacks, the instruction-\ntuned model produces fewer non-factual responses\nand delivers a higher overall quality of explana-\ntions compared to other pre-trained models. No-\ntably, models equipped with carefully designed\nprompts for explanation generation showed im-\nproved performance and did not suffer from hal-\nlucination issues. The expert ratings, detailed in\nTable 28, further emphasize the effectiveness of our\ninstruction-tuned model, which in some instances\neven surpasses the quality of explanations provided\nby human legal experts, achieving an impressive\nrating score of 4. This highlights the potential of\ngenerative models, particularly those enhanced by\nour approach, in delivering accurate and contextu-\nally relevant legal explanations."}, {"title": "9 Conclusions and Future Work", "content": "In this study, we presented NyayaAnumana, the\nlargest and most diverse dataset of Indian legal\ncases, alongside INLegalLlama, a specialized lan-\nguage model fine-tuned for legal judgment predic-\ntion and explanation. Our findings demonstrate\nthat domain-specific models, particularly those en-\nhanced with legal data, significantly outperform\ngeneric large language models in both accuracy\nand quality of explanations provided. Notably, we\nachieved very good accuracy in the prediction task\nafter including data from all court levels, under-\nscoring the value of comprehensive datasets.\nFuture work will focus on expanding the dataset\nto include judgments in regional languages, better\nreflecting India's linguistic diversity. We plan to\nexplore larger and more advanced models, poten-\ntially using more efficient quantization techniques\nand enhanced hardware resources, to better handle\ncomplex legal documents. Refining our fine-tuning\nmethodologies by incorporating a broader range\nof legal documents, such as statutes and contracts,\nwill further enrich the model's knowledge base.\nBy addressing these challenges and expanding\nthe scope of our research, we aim to enhance the\nperformance and reliability of AI models in the\nlegal domain, contributing to more efficient and\naccurate legal decision-making processes."}, {"title": "Acknowledgements", "content": "We would like to express our gratitude to the anony-\nmous reviewers for their insightful comments and\nconstructive feedback, which have significantly im-\nproved the quality of this work. We also sincerely\nthank the student research assistants from various\nlaw colleges for their invaluable contributions in\nannotating the documents. Their efforts have been\ninstrumental in the development of this research.\nThis work was supported by the \"Research-I\nFoundation\" at the Dept. of Computer Science and\nEngineering, IIT Kanpur, which has generously\nfunded the author's conference travel."}, {"title": "Limitations", "content": "Our study faced several significant limitations that\ninfluenced both our approach and the findings. One\nof the primary constraints was using a 4-bit quan-\ntized model due to resource constraints, which re-\nstricted our ability to leverage larger parametric\nmodels, such as those with 70B or 40B parameters.\nThe token limitation and high subscription charges\nfor paid cloud services further exacerbated this is-\nsue, limiting our capacity to perform inference and\nfine-tuning on more advanced models. This limi-\ntation likely restricted the full exploration of these\nmodels' capabilities, potentially affecting the depth\nand quality of the insights and performance metrics\nwe could achieve.\nAdditionally, the resource-intensive nature of ob-\ntaining legal expert annotations presented another\nchallenge. The high costs and significant time re-\nquired for acquiring these annotations made obtain-\ning expert evaluations for the entire PredEx test\ndataset impractical. As a result, we use the same\n50 random documents as used in for expert review and Likert score evalua-\ntions. While necessary, this approach potentially\nlimits the breadth and depth of our expert evalua-\ntion, as it does not encompass the entire dataset.\nThe applicability of LLMs in the legal domain,\nparticularly for tasks involving legal judgment pre-\ndiction and explanation, remains uncertain based\non our findings. While they show proficiency in\nconversational contexts, their performance in tasks\nrequiring complex logic or specialized knowledge,\nsuch as legal reasoning, is less convincing. An-\nalyzing lengthy legal documents and generating\npredictions and explanations proved challenging\nfor generative models. This challenge is particu-\nlarly evident when the models must process and\nunderstand intricate legal reasoning and contexts.\nLastly, the dataset used in this study comprised\nonly English-language judgments, excluding other\nregional languages such as Hindi and Bengali. This\nlimitation underscores the need for more inclusive\ndatasets representing the linguistic diversity in legal\ndocuments across different jurisdictions.\nThese limitations highlight the complexities and\nchallenges of applying LLMs to specialized tasks\nlike legal judgment prediction and explanation.\nThey also underscore the need for ongoing research\nand development to comprehensively enhance AI\nmodels' capabilities in interpreting and understand-\ning legal documents and contexts."}, {"title": "Ethics Statement", "content": "In conducting this research, we placed a strong em-\nphasis on ethical considerations, particularly due to\nthe sensitive nature of legal data and the methodolo-\ngies employed. The NyayaAnumana dataset, used\nextensively in this study, was sourced from publicly\naccessible legal search engines, ensuring compli-\nance with data privacy and usage regulations. We\nhave taken steps to remove any meta-information\nsuch as judge names, case titles, and case IDs to\nprotect the privacy and confidentiality of the indi-\nviduals involved.\nFurthermore, the computational resources uti-\nlized in this study were obtained through ethical\nand legitimate means. We subscribed to Google\nColab Pro and other necessary cloud services, en-\nsuring that all resources used for model training\nand testing were accessed legally. This financial\nsupport not only facilitated our research but also\ncontributed to the sustainability of these services.\nIn addition to adhering to legal and ethical guide-\nlines in data handling and resource usage, we are\ncommitted to transparency and reproducibility in\nour research. The NyayaAnumana dataset and the\ncode for our models, including INLegalLlama, for\nnow, has been made available to promote open sci-\nence and enable other researchers to replicate and\nbuild upon our work.\nFinally, we acknowledge the potential societal\nimpact of deploying AI in legal settings. Our mod-\nels are designed to assist, not replace, human judg-\nment, and we stress the importance of human over-\nsight in any AI-assisted legal decision-making pro-\ncess. We remain committed to ongoing ethical\nscrutiny as we advance this research field."}, {"title": "A Ablation Study", "content": "In our ablation study, we investigated the impact of\nvarious court-level training data configurations on\nthe performance of our models in the binary clas-\nsification judgment prediction task. We observed\nconsistent trends across multiple experiments, par-\nticularly when analyzing the results from the full\nNyayaAnumana dataset in relation to subsets that\nexcluded specific court cases. The performance\nmetrics are detailed in Our findings indicate that models trained on\nHigh Court cases exhibited the best performance,\nlikely due to the substantial representation of High\nCourt data in the training set. However, when these\nmodels were evaluated on the ILDC dataset, a no-\nticeable drop in performance was observed. This\nsuggests that while the models excel in familiar\ncontexts, they struggle to generalize to datasets\nwith different characteristics or distributions.\nWe also conducted experiments on the ternary\njudgment prediction task, incorporating additional\ncourt cases, with results presented in Appendix Ta-\nbles These experiments further re-\ninforced the significance of including diverse court\ndata and highlighted the benefits of utilizing large\nvolumes of training data.\nOur findings emphasize the importance of a di-\nverse and comprehensive dataset. Including a broad\nspectrum of court cases not only enhances the\nmodel's understanding of various judicial contexts\nbut also significantly improves its performance met-\nrics. In particular, the models trained on the most\nextensive datasets achieved an F1 score of around\n90%, underscoring the critical role of data diversity\nand volume in achieving high accuracy.\nOverall, the ablation study illustrates that the\ndiversity and volume of training data play a crucial\nrole in enhancing model performance, particularly\nin the context of legal judgment prediction tasks.\nFuture work should continue to explore the impact\nof various data configurations to further optimize\nmodel accuracy and generalization capabilities."}, {"title": "B Rating Score Description", "content": "The evaluation of the explanations generated by\nthe models was conducted using a 1\u20135 Likert scale,\nwhere each score reflects the quality and relevance\nof the provided explanation. The criteria for rating\nare as follows:\n[1]: The explanation is entirely incorrect or fails\nto provide any relevant information. This score\nindicates that the response does not address the\ncase judgment in any meaningful way.\n[2]: The response is irrelevant or demonstrates a\nmisunderstanding of the case judgment. A rating\nof 2 suggests that while some effort was made to\nrespond, the explanation does not accurately reflect\nthe case details.\n[3]: The explanation is partially accurate but\nlacks critical details. This score indicates that the\nresponse contains some correct information, but it\nis insufficient for a complete understanding of the\ncase judgment.\n[4]: The response is generally accurate and rel-\nevant, comparable to the ground truth. A rating\nof 4 signifies that the explanation aligns well with\nthe expected outcomes and provides a solid under-\nstanding of the case.\n[5]: The explanation is fully accurate, relevant,\nand potentially superior to the expert's explanation.\nThis highest rating reflects an exceptional response\nthat not only meets the criteria of accuracy and rel-\nevance but also offers insights that exceed standard\nexpert evaluations."}, {"title": "C Experimental Setup and\nHyper-parameters", "content": ""}, {"title": "C.1 Transformers Training\nHyper-parameters", "content": "For model training, we used a batch size of 16,\nthe Adam optimizer , and a\nlearning rate of 2e-6. The training was conducted\nover 3 epochs on the NyayaAnumana train dataset.\nThe remaining hyperparameters were set to their\ndefault values as provided by the HuggingFace\nlibrary."}, {"title": "C.2 INLegalLlama Training Procedure", "content": "The fine-tuning of the INLegalLlama model was\nconducted using the LLaMa 2 7B model architec-\nture, with the model loaded in Bfloat16 precision.\nThe training was done in Google Colab Pro, uti-\nlizing a single A100 GPU with 40GB of memory.\nGiven the constraints of limited computational re-\nsources, we carefully selected parameters to fully\nutilize the available compute power. This setup en-\nabled us to develop a highly capable model within\na reasonable time frame of 48 hours, incurring a\ncost of approximately $59. During the training pro-\ncess, the maximum token length was set at 2,096.\nWe employed the Low-Rank Adaptation (LoRA)"}, {"title": "D Hallucination", "content": "In our study, we address the issue of hallucinations\nin model-generated text, which is a prevalent chal-\nlenge when using large language models for gener-\nating legal judgments. Hallucinations occur when\nthe model produces information that is false or irrel-\nevant, not supported by the input data. A sample of\nhallucination has been provided in Appendix Table\n9. To tackle this issue, we employed a specialized\nfine-tuning strategy aimed at significantly reduc-\ning such errors. A detailed comparative analysis\nprovided in Appendix D.1 - CPT LLaMa-2 halluci-\nnations, which highlights the effectiveness of these\nstrategies. This analysis illustrates how fine-tuning\nand instruction-tuning, specifically tailored to the\nlegal domain, can help minimize hallucinations, re-\nsulting in outputs that are clearer, more accurate,\nand legally coherent."}, {"title": "D.1 CPT LLaMa-2 hallucinations", "content": "In the subsection, we conduct a thorough compari-\nson between ground truth and fine-tuned models to\ndemonstrate some samples where the CPT model\nshowed signs of hallucination. Table 9 in the Ap-\npendix presents an extensive analysis of the model,\nillustrating the performance of the LLaMa-2 pre-\ntrained model on legal judgment prediction with\nexplanation tasks in our PredEx dataset. In the\ngiven table, this can be observed that the model\ndid not only produce incorrect judgment but also\ndelivered the wrong explanation, if not repeating\nthe sentences and printing a random repetitive set\nof numbers. Some examples in the table show the\nmodel hallucinating by repeating a statement irrel-"}, {"title": "D.2 CPT LLaMa-2 vs INLegalLlama\n(CPT+SFT)", "content": "In the subsection, we conduct a detailed compari-\nson between LLaMa-2-7B CPT and INLegalLlama\n(CPT+SFT) to demonstrate some samples where\nthe fine-tuned model INLegalLlama performed bet-\nter than LLaMa-2 CPT in all aspects including\nprediction and explanation. Table 10 in the Ap-\npendix presents an extensive analysis of the model,\nillustrating the performance of the LLaMa-2 pre-\ntrained model against the INLegalLlama model on\nlegal judgment prediction with explanation tasks\nin our PredEx dataset. In the given table, it can\nbe observed that the performance of the LLaMa-2"}]}