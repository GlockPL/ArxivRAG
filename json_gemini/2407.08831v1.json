{"title": "Neural Networks Meet Elliptic Curve Cryptography: A Novel Approach to Secure Communication", "authors": ["Mina Cecilie W\u00f8ien", "Ferhat Ozgur Catak", "Murat Kuzlu", "Umit Cali"], "abstract": "In recent years, neural networks have been used to implement symmetric cryptographic functions for secure communications. Extending this domain, the proposed approach explores the application of asymmetric cryptography within a neural network framework to safeguard the exchange between two communicating entities, i.e., Alice and Bob, from an adversarial eavesdropper, i.e., Eve. It employs a set of five distinct cryptographic keys to examine the efficacy and robustness of communication security against eavesdropping attempts using the principles of elliptic curve cryptography. The experimental setup reveals that Alice and Bob achieve secure communication with negligible variation in security effectiveness across different curves. It is also designed to evaluate cryptographic resilience. Specifically, the loss metrics for Bob oscillate between 0 and 1 during encryption-decryption processes, indicating successful message comprehension post-encryption by Alice. The potential vulnerability with a decryption accuracy exceeds 60%, where Eve experiences enhanced adversarial training, receiving twice the training iterations per batch compared to Alice and Bob.", "sections": [{"title": "I. INTRODUCTION", "content": "Artificial Intelligence (AI) has provided significant advances in various domains, such as facilitating the integration of so-phisticated analytical and predictive capabilities. The advanced capabilities of AI-based methods, such as rapid data processing and pattern recognition, make them a superior alternative to traditional methodologies, especially in scenarios requiring ac-curate decision-making [1]. Cryptography is essential in secur-ing smart grids and ensuring data privacy, authentication, and efficient communication [2]. Public key cryptography, Elliptic Curve Cryptography (ECC), and identity-based cryptography are among the techniques used in the field of smart grids [3]. The techniques prevent various attacks on devices and address resource constraints in smart meters [4]. Similarly, AI also has significant contribution to natural language processing (NLP), i.e., enabling the development of sophisticated text generation algorithms and improving interactive technologies such as ChatGPT, improving user engagement and service delivery in customer service applications [5]. Cryptography encompasses several methods to transform plain messages into encrypted ciphertexts, which can only be decrypted by authorized parties possessing the required key. There are two types of cryptography methods to achieve this.\nIn recent years, the relationship between AI and cryptog-raphy has increased significantly along with exploring the potential of neural networks for algorithmic cryptography. Re-cent studies have demonstrated the ability of neural networks to design secure communication protocols using symmetric cryptography [6]. The study [7] introduces a new approach to cryptography utilizing neural networks, i.e., neural networks automatically generate cryptographic schemes. The experi-mental results of the study also confirm the ability of the architecture for automatic encryption and decryption, along with the achievement of a neural symmetric cryptosystem. The other study [8] in Adversarial Neural Cryptography proposes a framework in which neural networks, through adversarial training, learn to encrypt and decrypt messages, effectively mimicking cryptographic functions. The main contribution of the current study is the application of asymmetric cryp-tography within an AI context, employing ECC to secure communications between neural network entities, herein re-ferred to as Alice and Bob, against an eavesdropping entity, Eve. This study contributes to the burgeoning field of neural cryptography by demonstrating the feasibility of employing asymmetric cryptographic principles in neural network-based secure communication protocols.\nThe remainder of this paper is organized as follows. Section II provides the contemporary research landscape in neural cryptography. Section III provides background related to cryptography and neural networks. Section IV details the asymmetric neural cryptography model used in this study. The experimental results are presented and discussed in Section V, followed by the conclusion remarks and directions for future research in Section VI. The developed source code for this project is publicly available on GitHub repository\u00b9."}, {"title": "II. RELATED WORK", "content": "The integration of neural networks into the cryptography domain represents a novel intersection of AI and information security, offering innovative avenues for the development of secure communication protocols. The exploration of AI as a mechanism for implementing cryptographic functions has garnered increasing interest, particularly in enhancing security\n\u00b9https://github.com/minawoien/Neural-Cryptography\nagainst sophisticated adversarial models. Zhou et al. [9] pro-vide a comprehensive examination of this emerging paradigm, focusing on applying neural networks to encryption tasks and assessing security in the presence of powerful adversaries. Their work underscores the potential of deep learning (DL) techniques to redefine traditional cryptographic practices.\nThe seminal work by Abadi and Andersen [8] marked a pivotal advance in the field, demonstrating the ability of neural networks to learn encryption and decryption processes autonomously through adversarial training. In their framework, a trio of neural networks engage in a cryptographic game in which Alice and Bob aim to secure their communication from the eavesdropping attempts by Eve, facilitated by a shared secret key. This study established the foundation for future studies on adversarial neural cryptography or Adversarial Neu-ral Cryptography (ANC). However, the ANC model proposed by Abadi and Andersen has been investigated with regard to security concerns. Coutinho et al. [1] critically analyzed the ANC model in terms of its security assessment. They indicated that the proposed ANC model does not adequately simulate realistic adversarial conditions predicated on Eve's difficulty in decrypting messages without access to the cipher-text. They proposed an enhanced model, i.e., Chosen-Plaintext Attack Adversarial Neural Cryptography (CPA-ANC). In this enhanced model, Eve selects one of two messages for Alice to encrypt, providing a more stringent test of the cryptographic system's security. According to the results, the CPA-ANC model demonstrates improved resilience against adversarial decryption attempts, while the original ANC model may not offer robust security. Meraouche et al. [10] extended the con-cept of adversarial neural cryptography by incorporating asym-metric cryptographic principles based on these foundational studies. Their model introduces additional neural networks, which generate key pairs, facilitating secure communication through public and private keys.\nAll of these studies contribute to adversarial neural cryptog-raphy by systematically analyzing the application of asymmet-ric cryptographic techniques within a neural network frame-work. This study aims to evaluate the efficacy of neural networks in securing communications against eavesdropping attempts using ECC."}, {"title": "III. BACKGROUND", "content": "Asymmetric cryptography is one of the widely used encryp-tion methods, which is also known as public-key cryptography. It uses a public key-private key pairing, i.e., a public key for encryption and a private key for decryption, and differs from symmetric cryptography using the same key both encrypts and decrypts data.\nECC is a cryptographic approach used in asymmetric cryp-tography, which utilizes the principles of elliptic curve theory. It is also considered an alternative to the Rivest-Shamir-Adleman (RSA) cryptographic algorithm, which is frequently used for digital signatures. ECC provides several advantages, i.e., faster, smaller, and more efficient in generating crypto-graphic keys. In particular, the efficiency of the ECC makes it well-suited for environments with limited computational resources [11].\nGenerative Adversarial Networks (GANs) introduce a novel approach within the realm of unsupervised learning, consisting of two competing neural network models: a generator produc-ing synthetic data similar to training data and a discriminator evaluating the authenticity of real and generated data [12]. Through iterative adversarial training, both networks improve their performance, with the generator producing increasingly convincing data and the discriminator becoming more adept at distinguishing between real and generated inputs. This approach has been applied to many applications such as image generation, image-to-image translation, text-to-image transla-tion, 3D object generation, semantic-image-to-photo Trans-lation, style transfer, and more recently, adversarial neural cryptography [13], [14]."}, {"title": "IV. SYSTEM MODEL", "content": "This section describes the proposed asymmetric neural cryptography model built on Pacurar's implementation of asymmetric neural cryptography\u00b2.\nThe proposed asymmetric neural cryptography model in this study includes the deployment of neural network architectures to simulate participants in a typical cryptographic system, i.e., sender, receiver, and eavesdropper, shown in Fig. 1. The model is implemented by engaging with three separate neural networks, namely Alice, Bob, and Eve. Bob initiates the communication by generating a pair of keys, i.e., a public key, KPUBLIC, and a private key, KPRIVATE. The public key is openly shared with Alice (and accessible to Eve), while the private key remains confidential to Bob. Alice utilizes KPUBLIC to encrypt her plaintext message, P, producing a ciphertext, C. This encrypted message is then transmitted to Bob, who employs KPRIVATE to decrypt C and recover the original message P. At the same time, Eve endeavors to intercept and decipher the encrypted message without having Bob's private key, representing the adversarial risk in this cryptographic scenario. The success of the model depends on the challenge of inferring KPRIVATE from KPUBLIC. In addition, the utilization of neural networks in this context aims not only to replicate the encryption and decryption processes but also to resist eavesdropping attempts by Eve adaptively to guarantee the confidentiality of Alice and Bob's communication.\nThe architecture is adapted from generative adversarial networks (GANs) to the cryptographic concept. It consists of developing a specialized neural network architecture for secure communication using the principles of ECC [11].\n\u00b2https://mathybit.github.io/adversarial-neural-crypto/\nThe training process is illustrated in Fig. 4, Alice initiates the process by creating a plaintext message that she wants to send to Bob privately. On the other hand, Bob generates a key pair using an elliptic curve consisting of a public key and a private key. The public key is shared between Alice and Eve. Alice then encrypts the plaintext message using the public key, which produces a ciphertext. Both Bob and Eve receive this ciphertext. Bob attempts to decrypt the ciphertext using his private key, while Eve tries to decrypt it using only Bob's public key. If Bob's decrypted message matches the original plaintext with a high degree of accuracy and Eve's accuracy is significantly lower, the parameters are saved, and the training process ends. If not, the parameters are updated, and the training process continues.\nDuring the training phase, the ABE model, Eve model, and Bob's loss are computed using the same approach as that of Pacurar's implementation. The loss of Bob signifies his proficiency in decrypting messages, while the loss of Eve indicates her ability to intercept the communication between Alice and Bob. This loss is determined by subtracting the predicted outcome the output produced by Eve or Bob from the target output, which is Alice's plaintext message. Bob's loss is presented in Eq. 1.\nl_{BOB} = \\frac{1}{N} \\sum_{i=1}^N \\sum_{j=1}^{mbits} |P_{ij} - O_{ij}| \\qquad(1)\nwhere $\\ell_{Bob}$ is the loss function, $P_{ij}$ is the plaintext, $O_{ij}$ is Bob's predicted outcome, N is the batch size, and mbits is the message size. Eve's loss is defined in Eq. 2."}, {"title": "V. RESULTS", "content": "N mbits\n1\nLEVE = \u03a3\u03a3 Pij \u2013 Oij|\ni=1 j=1\n(2)\nwhere leve is the loss function and Oij is Eve's predicted outcome. The ABE loss is calculated concerning Bob's loss and Eve's loss as shown in Eq. 3\nlABE = (l\u0432\u043e\u0432 + (lEVE)\n2mbits\n)2\n(3)\nwhere lABE is the loss function of the ABE model, l\u0432\u043e\u0432 is Bob's loss function, leve is Eve's loss function and mbits is the message size. This loss indicates whether Alice and Bob need to improve their strategy, as it shows how well Alice and Bob work together while Eve performs poorly. If Eve is doing too well, this loss will be high.\nNeural network models are trained using an epoch size of 20 and a batch size of 512. An epoch refers to the number of times that models are trained in the entire data set, while batch size signifies the number of data set rows that are used simultaneously [15]. The message space is defined as 2mbits, where mbits denotes the length of the message of 16. The number of iterations per epoch is calculated by dividing the message space by the batch size, resulting in 2500 iterations. During the training of the ABE model, a set of keys is generated for each message. The process entails the creation of 512 batches of messages consisting of 16 bits and 512 batches of public/private keys. The same approach is implemented for the Eve model, except that the private key is not accessible.\nThe study involved the application of five distinct prime curves with varying key sizes to generate elliptic key pairs for Bob. The secp224r1 curve was utilized with a key size of 224 bits, while the secp256k1, secp256r1, secp384r1, and secp521r1 curves were used with key sizes of 256, 384, and 521 bits, respectively. The ABE model was trained once for each batch, and the results were measured when Eve was trained once for one batch and when she was trained twice to test the security using improved adversarial training. The entire training process was repeated five times using the same elliptic curve and consistent variables for both the ABE and Eve models. Subsequently, the average results of these five training sessions were calculated to ensure a robust evaluation.\nFig. 5 shows the loss functions for the ABE model, Bob and Eve, for each elliptic curve when the ABE model and the Eve model train only once for each batch. Eve has a constant loss of 8 in these figures, visualized by the red line, which is 50% of the message size of 16 bits, indicating random guessing. The green curve represents the loss of Bob, while the blue curve represents the loss of the ABE model. These decreasing curves show that Alice and Bob are learning to protect their communication.\nThe ABE model's loss values, after 2500 iterations, are shown in Table I. These values are the average of five training\niterations. The ABE loss indicates the relationship between how well Alice can encrypt messages and how well Bob can decrypt them, while Eve should not be able to decrypt them. At the end of the training, the ABE model has a loss value between 0 and 1, indicating the minimum loss or error in the encryption and decryption process, while Eve performs poorly. Bob also has loss values between 0 and 1, meaning that Bob's decryption of the ciphertext is close to Alice's original plaintext. Eve's loss value is approximately 8, also shown in Fig 5, meaning she is not learning how to decrypt the ciphertext and is not performing better than random guessing.\nAfter training for 2500 iterations, Alice encrypts another message to calculate Bob and Eve's decryption accuracy. The accuracy is shown in Table II. The values are calculated by adding the corrected decrypted bits and dividing them by the total number of bits. Bob decrypts the ciphertext using his private key and obtains a decryption accuracy of approximately 100%. In four of the five different curves, Bob's accuracy is 100%, and only one is 99.92%, meaning that even though Bob's loss is not exactly zero at the end of the training, Bob's decryption process is highly accurate. Eve tries to decrypt the ciphertext without the private key, but only obtains a decryption accuracy of approximately 50%.\nThese results show that Alice and Bob can secure their communication from an eavesdropping neural network when the neural network models train once for each batch. Bob can\nde crypt Alice's message using the correct key, while Eve can not make sense of the message without the correct key. To further test the security, the encryption system is tested with improved adversarial training, where Eve has the advantage of training twice for each batch. At the same time, Alice and Bob only trained once. Fig. 6 shows the loss functions for the ABE model, Bob, and Eve for this scenario with five training iterations for the five elliptic curves. In these figures, all loss functions begin to decrease at approximately 250 iterations. The loss of the ABE model and Bob continues to decrease with the iterations, while Eve's loss function decreases for the first 1000 iterations before the loss varies between 6 and 7. This indicates that Eve is learning more because she has the advantage of training twice for each batch. In these figures, the loss function of the ABE model is slightly higher than Bob's loss function due to Eve's improvement in performance.\nTable III shows the loss values of the ABE model, Bob and Eve after training for 2500 iterations. The ABE loss and Bob's loss are between 0 and 1, as when Eve trained with only one cycle for each batch, as shown in Table I. However, the ABE loss is slightly higher than Bob's loss, compared with the results in Table I, where the ABE loss and Bob's loss were almost equal, as a result of Eve's improvement in performance. Bob's loss is nearly the same as in the previous result, meaning he is performing as well now. Eve's loss values now range from about 6.397 to 6.674 when she trains with two iterations for each batch. This is better than random guessing, which means that she correctly decrypts bits for more than 50% of the message. Although she is not close to correctly decrypting the entire message, she has improved his decryption process compared to her attempt shown in Table I.\nTable IV shows Bob and Eve's decryption accuracy. Bob has a decryption accuracy of approximately 100%, which is the same as before, as shown in Table II, which means that Eve's improvement in performance does not affect Bob's ability to decrypt messages. However, Eve's decryption accuracy has"}, {"title": "VI. CONCLUSION", "content": "This investigation into asymmetric neural cryptography has clarified the potential of integrating ECC within AI models to strengthen secure communication channels against adver-sarial eavesdropping. Through an experimental protocol using a variety of ECC curves, it is quantitatively demonstrated that the proposed neural network models, representing the communicative entities Alice and Bob, can achieve a high degree of secure message exchange with minimal variation in security efficacy across different cryptographic curves. The results indicate a robust encryption-decryption mechanism capable of maintaining message integrity, as evidenced by Bob's loss metrics oscillating between 0 and 1, signifying Alice's near-perfect message reconstruction post-encryption.\nThe introduction of enhanced adversarial training, in which the eavesdropper model Eve underwent training iterations at double the frequency of Alice and Bob, unveiled a nuanced vulnerability within the system. Eve's decryption accuracy, surpassing 60% under these conditions, heralds a potential security risk, albeit slight, under scenarios of advanced ad-versarial intervention. This finding underscores the necessity for continuous refinement of the neural cryptography model, particularly to optimize its resilience against increasingly sophisticated eavesdropping techniques.\nIn light of these findings, the future trajectory of this re-search is poised to explore the implementation of CPA method-ologies. Such approaches will evaluate the cryptographic sys-tem's security, aiming to bolster its defenses and mitigate the vulnerabilities highlighted by the enhanced adversarial training paradigm. Furthermore, extending the model to incorporate dynamic mechanisms of key generation and exchange could further enhance its security framework, aligning with the evolving landscape of digital communication threats."}]}