{"title": "Enriching Ontologies with Disjointness Axioms using Large Language Models", "authors": ["Elias Crum", "Antonio De Santis", "Manon Ovide", "Jiaxin Pan", "Alessia Pisu", "Nicolas Lazzari", "Sebastian Rudolph"], "abstract": "Ontologies often lack explicit disjointness declarations between classes, despite their usefulness for sophisticated reasoning and consistency checking in Knowledge Graphs. In this study, we explore the potential of Large Language Models (LLMs) to enrich ontologies by identifying and asserting class disjointness axioms. Our approach aims at leveraging the implicit knowledge embedded in LLMs, using prompt engineering to elicit this knowledge for classifying ontological disjointness. We validate our methodology on the DBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs, when guided by effective prompt strategies, can reliably identify disjoint class relationships, thus streamlining the process of ontology completion without extensive manual input. For comprehensive disjointness enrichment, we propose a process that takes logical relationships between disjointness and subclass statements into account in order to maintain satisfiability and reduce the number of calls to the LLM. This work provides a foundation for future applications of LLMs in automated ontology enhancement and offers insights into optimizing LLM performance through strategic prompt design.", "sections": [{"title": "1. Introduction", "content": "It is generally understood that complementing the factual (assertional) knowledge represented in Knowledge Graphs with ontological (terminological) information greatly advances the usefulness of the ensuing knowledge base in terms of querying and many other downstream tasks. This is because combining assertional information with terminological background knowledge allows for the derivation of a vast amount of implicit knowledge, which is not explicitly stated in the knowledge base but follows logically from it and thus can be taken into account for all kinds of knowledge management activities, including query answering.\nThe by far most widespread type of ontological information added to knowledge graphs is taxonomic in nature, that is, it is related to (i) putting the individual objects of interest into categories, usually referred to as classes, based on shared characteristics and (ii) establishing set-theoretic relationships between these classes. Among the diverse possible such taxonomic relationships, the subclass/superclass relationships \u2013 tightly connected to the linguistic hyponymy/hypernymy relationships of the corresponding class names are the ones predominantly found across numerous ontologies today, typically forming sizeable conceptual hierarchies. As an example, the subclass/superclass relationship between the classes Mammal and Vertebrate implies that any object that belongs to (or, in more technical terms: is an instance of) the class Mammal also must belong to the class Vertebrate.\nAnother well-known basic type of taxonomic relationship between two classes is that of disjointness. Two classes are said to be disjoint if it is impossible that they have common instances, which, intuitively, means that the two classes cannot overlap, and membership in these two classes is mutually exclusive. For example, disjointness of the classes Mammal and Fish implies that any instance of Mammal must not be an instance of Fish. Given the symmetric nature of disjointness, this is logically equivalent to saying that any instance of Fish must not be an instance of Mammal. As opposed to subclass statements, which allow for inferring positive facts from other positive facts, disjointness statements enable the inference of negated facts. For example, given the fact that Flipper is an instance of Mammal, the above subclass relationship gives rise to the information that Flipper is an instance of Vertebrate, whereas the disjointness statement allows us to infer the information that Flipper must not be an instance of Fish. This fact makes disjointness information particularly valuable in the context of machine-learning approaches that rely on the presence of negative examples, such as Knowledge Graph Embedding.\nWhen specifying taxonomic relationships between classes in the course of the ontology design process, it should be kept in mind that they are not meant to reflect spurious relationships in the data currently available, but rather they are supposed to represent immutable background knowledge that continues to hold in different situations or at different points in time. For instance, although historically, no woman has served as US President, a woman may be elected as the US President in the future. Therefore, the corresponding classes Woman and USPresident are not (ontologically) disjoint. To reflect this situation more formally, one can employ the idea of possible or conceivable worlds (referred to as interpretations in model-theoretic terms), which e.g., include potential future or just hypothetical circumstances. Then, a certain taxonomic relationship (such as subclass or disjointness) between two classes holds if the corresponding set relation (such as subset or intersection-emptiness) holds between the sets of class instances in every conceivable world (under every conceivable interpretation). Based on this, we will employ a very lightweight logical framework to give our arguments a formal underpinning: Stipulating a set I of conceivable worlds, we define taxonomic relationships for this set. The goal of ontological knowledge modeling is to capture I using a knowledge base K whose statements rule out the inconceivable worlds so that only the conceivable ones remain as models of K."}, {"title": "Definition 1.", "content": "Fixing a vocabulary consisting of a set C of class names and a set I of individual names, an interpretation \\(I = (\\Delta, \\cdot^{I})\\) consists of a set \\(\\Delta\\) called the domain and a function \\(\\cdot^{I}\\) mapping every class name \\(C \\in C\\) to a subset \\(C^{I} \\subseteq \\Delta\\) and every individual name \\(i \\in I\\) to an element \\(i^{I} \\in \\Delta\\).\nLet \\(I\\) be a set of interpretations, representing the conceivable worlds. Then, for an individual name \\(i \\in I\\) and for concept names \\(C, D \\in C\\) we call\n\\(i\\) an instance of \\(C\\) (written \\(i : C\\)) if every interpretation \\(I \\in I\\) satisfies \\(i^{I} \\in C^{I}\\),\n\\(C\\) a subclass of \\(D\\) (written \\(C \\subseteq D\\)) if every interpretation \\(I \\in I\\) satisfies \\(C^{I} \\subseteq D^{I}\\),\n\\(C\\) disjoint with \\(D\\) if every interpretation \\(I \\in I\\) satisfies \\(C^{I} \\cap D^{I} = \\emptyset\\),\n\\(C\\) incoherent if every interpretation \\(I \\in I\\) satisfies \\(C^{I} = \\emptyset\\).\nAs discussed above, ontologically dictated taxonomic relationships can be leveraged for sophisticated reasoning and consistency-checking tasks when reasoning over a knowledge graph. Yet, despite their usefulness, disjointness relationships are rarely explicitly recorded within an ontology. Research on 1,275 ontologies showed that only 97 of them include disjointness assertions [1]. Arguably, this can be explained by the fact that disjointness information is so self-evident from a human common-sense point of view, that human experts are often not aware that it is not logically \u201cbuilt-in\u201d but needs to be explicitly specified. For this reason, semi-automated labeling of disjoint classes could be advantageous. Recent approaches [2, 3, 4] propose supervised and unsupervised models using various features in disjointness axioms. However, the generalizability of these methods is limited to their specific datasets and cannot be implemented on a large scale. Additionally, the sophisticated feature engineering required hinders their practical application. Therefore, a method that functions independently of feature design and dataset restrictions is highly desirable.\nGiven that (i) ontological class descriptions are often recorded as (or associated with) terms in natural language and (ii) LLMs have been found to possess wide linguistic and semantic working knowledge, we aim to assess the potential of LLMs to decide on the question which classes ought to be disjoint while assessing the impact of prompt engineering on classification validity. We hypothesize that through the use of prompt engineering, LLMs are to classify ontologically disjoint classes with high validity in both positive (two classes are ontologically disjoint), and negative (two classes are not ontologically disjoint), cases. We test our hypothesis on the DBpedia ontology using LLMs. We propose a method that intertwines the LLM- based disjointness classification with basic logical inferencing to increase efficiency, maintain consistency, and minimize the number of calls to the LLM.\nThus, this paper is dedicated to answering the following main research questions:\nRQ1: Can LLMs help enrich ontologies with class disjointness axioms?\nRQ2: Which LLM prompts work better for disjointness discovery?\nRQ3: How can we exploit taxonomic relationships to reduce interaction with the LLM?"}, {"title": "2. Related Work", "content": "Disjointness Learning Models for disjointness learning can be categorized into supervised and unsupervised approaches. In the unsupervised category, Schlobach [5] follows the strong disjointness assumption [6], which posits that children of a common parent in the subsumption hierarchy should be considered disjoint. They introduced a pinpointing algorithm to identify minimal sets of axioms that need revision to make an ontology coherent, thereby enriching appropriate disjointness statements. However, this approach neglects background knowledge, which could be beneficial in identifying disjoint classes. Rizzo et al. [4] proposes an unsupervised approach based on concept learning and inductive classification. This method employs a hierarchical conceptual clustering technique capable of providing intensional cluster descriptions and utilizes a novel form of semi-distances over individuals in an ontological knowledge base, incorporating available background knowledge. In the supervised category, V\u00f6lker et al. [2, 3] gather syntactic and semantic evidence, such as positive and negative association rules as well as correlation coefficients, from various sources to establish a strong foundation for learning disjointness. However, their work exploits background knowledge and reasoning only to a limited extent. Subsequent work, the DL-Learner by Lehmann [7], uses Inductive Logic Programming (ILP) for learning class descriptions, including disjointness. Despite these advancements, disjointness learning with LLMs remains much underexplored.\nLarge Language Models In recent years, Large Language Models (LLMs) have become state-of-the-art for Natural Language Processing and have also significantly impacted other fields such as knowledge engineering [8, 9, 10, 11]. LLMs rely on pre-training Transformer models [12] over large-scale unlabeled corpora. Pre-trained context-aware word representations achieve state-of-the-art performance on various downstream tasks and set the \"pre-training and fine-tuning\u201d learning paradigm. Early LLMs, such as BERT [13], utilized relatively small training corpora and required fine-tuning for specific downstream tasks. However, subsequent research demonstrated that scaling up both model size and dataset volume significantly enhances performance. GPT-3 [14], for instance, achieves competitive results through few-shot learning and in-context learning without parameter updates. GPT-3.5 further improves capabilities by incorporating reinforcement learning from human feedback (RLHF). The introduction of GPT-4 [15] marked a milestone by extending beyond text input to include multimodal signals. Meta Al introduced the collection of LLaMA models [16, 17] with four different sizes. Other notable LLMs, such as Claude, Gemini [18], and Mixtral [19], have also garnered significant attention.\nPrompt Engineering Designing effective prompts for LLMs is essential for maximizing their potential. Key strategies in prompt engineering include zero-shot [20], few-shot [14], and chain-of-thought [21] prompting. Zero-shot [20] involves providing task descriptions to LLMs without any input-output examples, relying on the models' pre-existing knowledge to generate responses. Few-shot [14] includes input-output examples, guiding the models' generation process. Chain- of-Thought (CoT) [22] promotes coherent and step-by-step reasoning by decomposing a complex question into a series of simpler logical reasoning questions, mimicking human problem-solving processes. This method has been shown to significantly improve performance on reasoning tasks [22]. However, the need for multiple prompts makes this approach difficult to use at large"}, {"title": "3. Resources", "content": "To effectively assess the ability of LLMs to support the assertion of disjointness axioms, we ideally require a reference ontology that includes a sized set of classes, to ensure diversity during the experiments and some disjoint classes in its description, preferably specified through a specific disjoint class property such as owl:disjointWith. These criteria maximize the generalizability of the approach and encourage its use for future studies.\nSeveral ontologies can be identified for this task, from foundational ontologies, such as DOLCE or UFO, to domain-specific ontologies, such as FoodOn. Disjointness axioms from these ontologies, however, are not intuitive and require extensive common-sense reasoning and domain knowledge. For instance, DOLCE defines an Event to be disjoint from an Object while UFO does not. Both axioms are correct, as they deeply depend on their philosophical commitment to these abstract concepts. Similarly, the FoodOn ontology asserts that the Arabia coffee plant, the plant used to produce black coffee, is disjoint with Camellia sinensis, the plant used to produce black tea. In this case, deciding whether the two plants should be considered disjoint highly depends on the domain of the ontology. To avoid feeding the LLM with classes whose disjointness highly depends on the context or domain, we choose to avoid foundational and domain-specific ontologies for our initial experiments. Moreover, as our interaction with the LLM is based on natural language, we only consider ontologies that provide natural language labels for classes via labeling properties, such as skos:prefLabel or rdfs:label.\nWe ultimately decided to use the DBpedia ontology because of its general popularity and conformity with dataset minimal requirements. Since the DBpedia ontology is created through a crowdsourcing approach [24], the availability of disjointness axioms cannot be expected to be equally accurate across all classes, as it depends on the annotators' expertise and diligence. This issue has been actively discussed within the DBpedia community. The main drawback is the lack of a systematic approach in the creation of the taxonomy, which greatly impacts the consistency of the ontology when disjointness axioms are asserted. In particular, we found 23 explicit disjointness axioms in the DBpedia ontology. In Section 4 we show how exploiting automated reasoning techniques allows the creation of a larger pool of disjoint classes."}, {"title": "4. Proposed approach", "content": "We now describe our approach which, given a Knowledge Base, clarifies for every pair of named classes of that ontology if disjointness should hold between the two classes or not. At the core of the approach is prompting an LLM to exploit the semantic and linguistic \u201cworld knowledge\u201d it has obtained from training on vast amounts of textual data. The two major underlying objectives of our approach are:\n1. Ensuring that the resulting disjointness-enriched ontology is satisfiable (i.e., contradiction- free) for usability reasons since otherwise it would be unusable for any reasoning tasks, including ontology-supported querying.\n2. Minimizing the number of interactions with the LLM for efficiency reasons and cost- awareness.\nWe propose to address both objectives using automated reasoning. More specifically, we continuously materialize all the (non-)disjointness information that follows logically from the original knowledge base plus the already acquired disjointness information. Thus, the LLM is only queried about the disjointness status of pairs of classes, when neither of the outcomes would result in an inconsistency. In this way, the derived information remains contradiction-free \"by design\" and, at the same time, the number of queries to the LLM is significantly reduced.\nOur approach relies on several logical correspondences, discussed in the following.\nProposition 1. Let K be a knowledge base and let \\(C_1, C_2, D_1, D_2\\) be classes of K such that the following statements follow from K: (i) \\(C_1\\) and \\(C_2\\) are disjoint, (ii) \\(D_1\\) is a subclass of \\(C_1\\), (iii) \\(D_2\\) is a subclass of \\(C_2\\). Then K also entails that \\(D_1\\) and \\(D_2\\) are disjoint.\nProof. Consider an arbitrary model \\(I\\) of K. According to the assumptions and in view of Definition 1, we know that (i) \\(C_1^I \\cap C_2^I = \\emptyset\\), (ii) \\(D_1^I \\subseteq C_1^I\\), and (iii) \\(D_2^I \\subseteq C_2^I\\). We equivalently express (ii) and (iii) by (ii') \\(D_1^I = C_1^I \\cap D_1^I\\), and (iii') \\(D_2^I = C_2^I \\cap D_2^I\\). This allows us to infer \\(D_1^I \\cap D_2^I = (C_1^I \\cap D_1^I) \\cap (C_2^I \\cap D_2^I) = (C_1^I \\cap C_2^I) \\cap (D_1^I \\cap D_2^I) = \\emptyset \\cap (D_1^I \\cap D_2^I) = \\emptyset\\).\nWe exploit this property to use subclass relationships from K to deduce class disjointness statements from existing class disjointness statements. This way we avoid posing redundant disjointness queries to the underlying LLM.\nProposition 2. Let K be a knowledge base and let \\(C_1, C_2, C\\) be classes of K such that the following statements follow from K: (i) \\(C_1\\) and \\(C_2\\) are disjoint, (ii) \\(C\\) is a subclass of \\(C_1\\), (iii) \\(C\\) is a subclass of \\(C_2\\). Then K also entails that C is incoherent."}, {"title": "Proof.", "content": "Consider an arbitrary model \\(I\\) of K. According to the assumptions and in view of Definition 1, we know that (i) \\(C_1^I \\cap C_2^I = \\emptyset\\), (ii) \\(C^I \\subseteq C_1^I\\), and (iii) \\(C^I \\subseteq C_2^I\\). We equivalently express (ii) and (iii) by (ii') \\(C^I = C_1^I \\cap C^I\\), and (iii') \\(C^I = C_2^I \\cap C^I\\). This allows us to infer \\(C^I = C_1^I \\cap C^I = (C_1^I \\cap C_2^I) \\cap (C_1^I \\cap C_2^I) = (C_1^I \\cap C_2^I) \\cap C^I = \\emptyset \\cap C^I = \\emptyset\\).\nWe exploited this property indirectly under the assumption that any named class C in the considered ontology is supposed to have instances \u2013 which seems to be a reasonable assumption since, otherwise, the definition of the class appears to be meaningless. In that case, any two classes that have a common subclass must be not disjoint.\nProposition 3. Let K be a knowledge base, let \\(C_1, C_2\\) be classes and let e be an individual of K that such that the following statements follow from K: (i) \\(C_1\\) and \\(C_2\\) are disjoint, (ii) e is an instance of \\(C_1\\), (iii) e is an instance of \\(C_2\\). Then K is unsatisfiable.\nProof. Suppose I is a model of K. According to the assumptions and in view of Definition 1, we know that (i) \\(C_1^I \\cap C_2^I = \\emptyset\\), (ii) \\(e^I \\in C_1^I\\), and (iii) \\(e^I \\in C_2^I\\). Then, combining (ii) and (iii) we obtain \\(e^I \\in C_1^I \\cap C_2^I\\) and applying (i) yields \\(e^I \\in \\emptyset\\) which is a contradictory statement. Thus K cannot have any models, which means it is unsatisfiable.\nAgain, this property can be exploited by noting that any two classes having common instances must not be disjoint. These considerations lead to the proposed methodology, detailed in Algorithm 1, which achieves the above-mentioned objective of producing an enriched knowledge base that is guaranteed to be contradiction-free, provided that the original knowledge base is. Algorithm 2 achieves the objective of reducing the number of interactions with the LLM and maintaining satisfiability as new disjointness information is added through the LLM. The aim of producing an output that accurately reflects taxonomic relationships crucially depends on the quality and accuracy of the LLM's responses. This, in turn, is influenced by both the LLM itself and the chosen prompting strategy. We focus on these issues in Section 5.\nThe last steps of Algorithm 2 (lines 14 and 15) are optional, but highly recommended, as they remove logically redundant statements from the disjointness-enriched knowledge base \\(K \\cup D\\). This yields a knowledge base that is logically equivalent but typically much smaller in size and hence both easier to process algorithmically and to scrutinize and maintain manually. Also, this \u201cpruning step\u201d is not computationally expensive, as it only requires \\(|D^*|\\) calls to a reasoner."}, {"title": "5. Experiments", "content": "In this section, we experiment with the approach proposed in Section 4 on the classes extracted from the DBpedia ontology. In particular, by relying on Algorithm 1, we obtain the list L related to the DBpedia ontology. We have that |L| = 1148, with 370 pairs labeled as disjoint and 778 pairs labeled as not unknown.\nNote that the list L assumes that the ontology designers carefully produced a taxonomy that is intended to also reflect disjointness between classes. As shown in Section 3, however, this is not the case. The design of the taxonomy of DBpedia is structured such that disjoint axioms might result in unwanted inconsistencies. For this reason, we employ multiple metrics to evaluate the LLMs' performances, each measuring a different behavior of the model. For all metrics, a higher score indicates better performances, with 1 being the maximum score. In particular, disjoint recall (DR) measures how much the LLM aligns with humans by measuring the amount of true disjointness axioms that have been identified by the LLM. This measure provides an evaluation of the reliability of the prompt. Non-disjoint F1 (NDF1) measures the F1 score between the non-disjoint couples in L and the ones identified by the LLM. This provides a measure of how conservative the LLM is on its answers \u2013 i.e. how much the LLM acknowledges the open-world assumption. The F1 metrics measure the end-to-end performances of the model. The symmetric consistency metric (SC) measures how much the answers provided by the LLM"}, {"title": "Algorithm 1", "content": "Determine the pair of disjoint classes derivable from K\nInput A knowledge base K containing a class hierarchy. The knowledge base might or might not contain defined disjointness axioms and/or more complex axiomatizations.\nOutput A list L of pair of classes such that disjointness statements logically following from K are explicitly asserted.\nCreate a list L of all pairs of classes (C1, C2) | C\u2081 is lexicographically smaller than C2.\nLabel all entries in L as \"unknown\".\nfor all D\u2081 disjoint with D2 in K do\nfor all (C1, C2) \u2208 L do\nif (C1 \u2286 D1 \u2227 C2 \u2286 D2) or (C1 \u2286 D2 \u2227 C2 \u2286 D\u2081) then\n(C1, C2) \u2190 \"disjoint\"\nend if\nend for\nend for\nfor all (C1, C2) \u2208 L | (C1, C2) = \"unknown\" do\nif C1 and C2 have joint subclasses then\n(C1, C2) \u2190 \"not disjoint\"\nend if\nend for\nfor all (C1, C2) \u2208 L | (C1, C2) = \u201cunknown\" do\nQuery K for joint instances of C\u2081 and C2.\nif \u2203e \u2208 I | e : C\u2081 \u2227 e : C2 then\n(C1, C2) \u2190\u201cnot disjoint\u201d\nend if\nend for"}, {"title": "Algorithm 2", "content": "Determine the set of disjointness statements D consistent with K\nInput A list L containing pairs of classes labeled as \u201cunknown\u201d, \u201cdisjoint\u201d or \u201cnot disjoint\"; a prompt P for disjointness classification, with LLM\u209a : C \u00d7 C \u2192 {\u201cdisjoint\u201d,\u201cnot disjoint\"} the function that queries an LLM for disjointness of two classes using prompt P\nOutput A set D of class disjointness axioms, such that all valid disjointness statements logically follow from K \u222a D and no invalid disjointness statements follow from it.\nwhile (D1, D2) \u2208 L | (D1, D2) = \"unknown\" do\nSelect (D1, D2) \u2208 L | (D1, D2) = \"unknown\"\nd \u2190 LLM\u209a(D1, D2)\nif d = \"disjoint\" then\nfor all (C1, C2) \u2208 L | (C\u2081 \u2286 D1 \u2227 C2 \u2286 D2) \u2228 (C2 \u2286 D1 \u2227 C1 \u2286 D2) do\n(C1, C2) \u2190 \"disjoint\"\nend for\nelse\nfor all (C1, C2) \u2208 L | (D1 \u2286 C1 \u2227 D2 \u2286 C2) \u2228 (D2 \u2286 C1 \u2227 D1 \u2286 C2) do\n(C1, C2) \u2190 \"not disjoint\"\nend for\nend if\nend while\nD* \u2190 {DisjointClasses(C1, C2) | (C1, C2) \u2208 L \u2227 (C1, C2) = \u201cdisjoint\"}\nDetermine the minimal subset D of D* such that K \u222a D entails D*\nrespect the symmetric property of the disjointness axiom \u2013 i.e. if A is disjoint from B then B is disjoint from A. Finally, we measure the overall accuracy of each model.\nPrompting We adopt different prompting strategies: a naive approach, where the LLM has to autonomously understand the task, a task description approach, where the disjointedness task is described and a few-shot approach that extends the task description by also providing some positive and negative examples. For each prompt, we frame the problem as a question- answering (QA) task, where the LLM has to answer positively or negatively to classify two classes as disjoint. To identify the best QA approach, we identify two prompts: (i) the LLM has to answer positively to classify two classes as disjoint and (ii) the LLM has to answer negatively. Table 3 describes the prompt templates we used. When possible, we rely on the instruction format of each LLM and use the Prompting Strategy template to instruct the LLM while we use the QA Strategy as a query to the instructed LLM."}, {"title": "5.1. Experimental setup", "content": "We perform our experiments on publicly available LLMs, to ensure full reproducibility of the experiments. For each LLM, we set the sampling temperature to 0, to reduce the randomness of the result. Moreover, we only rely on small LLMs \u2013 i.e. LLMs with approximately 8 billion of parameters. Through the use of proper optimization techniques, it is possible to run these models on consumer-level devices without the need for specialized hardware. We perform"}, {"title": "5.2. Results", "content": "The overall results are shown in Table 4. In general, LLMs achieve promising results in disjoint- ness detection. Notably, the best prompting technique is not providing few-shot examples, but rather providing the LLM with little to no description of the task. Indeed, it has been observed how few-shot prompting is more effective when in-context learning is required, while zero-shot prompting is more effective when the implicit knowledge of the LLM should be exploited [28]. Nonetheless, further research on few-shot prompting for disjointness classification should be performed, as lower performances can also be attributed to the amount and nature of the examples we provide in the prompt. We manually select examples that are likely to provide meaningful disjointness instances. However, a more complex approach could be employed, such as exploiting Retrieval Augmented Generation (RAG) techniques to provide examples that are more likely to be relevant for the classes used as input. Different heuristics can be used to measure the relevance of other classes, such as word embeddings or knowledge graph embeddings. Interestingly, framing the problem as a negative QA task \u2013 i.e. asking whether an individual of a class can also be an instance of another class \u2013 consistently outperforms the positive QA prompt. This could be attributed to the fact that using the negative approach is"}, {"title": "5.3. Disjointness on DBpedia", "content": "Given the results of Table 4, we consider Gemma 2 with task description prompt and a negative QA strategy as the most effective way of producing disjointness axioms among the methods tested. We execute Algorithm 2 on the whole DBpedia ontology. We rely on a straightforward random selection for the pair (D1, D2) (line 3). In total, the algorithm takes 21589.75s \u2248 6h to execute. Note that given the random selection, we are not able to exploit parallelism and query the LLM with single prompts. However, a selection strategy that enables parallel selection would greatly enhance the performance of the algorithm. In total, we find 510, 600 disjointness axioms, which results in \u2248 98% of the classes participating in at least one disjointness axiom. The number of axioms can be greatly reduced by relying on the \"pruning\u201d operation of Algorithm 2 (line 15). In the case of the DBpedia ontology, the number of resulting axioms is 170, 122 a reduction of \u2248 66%.\nFor illustration and discussion purposes, Table 5 shows a non-representative selection of particularly discussion-worthy positive and negative disjointness statements retrieved via Algorithm 2. We observe that for some class relationships, including both common-sense and domain-specific classes, our approach resulted in the \u201cconservative\u201d misclassification of classes as non-disjoint, meaning the LLM classified the classes as non-disjoint despite the classes actually being disjoint. Examples include dbo:VideogamesLeague and dbo:Website, dbo:GeneLocation and dbo:HumanGene, and dbo:Identifier and dbo:District. Conversely, we also observed \"aggressive\u201d misclassification where our approach classified classes as disjoint despite them being really non-disjoint. Straightforward examples include dbo:PlayboyPlaymate and dbo:Camera or dbo:WikimediaTemplate and dbo:WomensTennisAssociationTournament, with a more complicated example being dbo:Mosque and dbo:Museum. The latter being dis- proven by a counter-example, the famous Mosque Hagia Sophia in Turkey. To address these misclassification instances, we suspect that providing more contextual information in the prompt may improve classification accuracy, especially for domain-specific scenarios. Also, future work could be done to assess how, through prompt design, the approach could encourage more \u201caggressive\u201d or \u201cconservative\u201d disjointness classifications in scenarios where relationships are more uncertain."}, {"title": "6. Conclusion and Future Work", "content": "This work shows that LLMs can roughly identify and assert disjointness axioms in ontologies, with a different degree of reliability depending on the model. By harnessing their inherent background knowledge and employing strategic prompt engineering, we showed that these models can classify ontological disjointness with minimal human intervention. This capability simplifies ontology management and supports more robust reasoning in knowledge graphs. Our findings underscore the potential of LLMs as valuable tools for the automated enrichment of ontologies, which encourages future exploration and innovation in this domain.\nFuture works include testing the approach proposed in Section 4 on other ontologies, to assess its effectiveness on different types of ontologies, including domain-specific ontologies. Additionally, comprehensive validation by human domain experts would be required to obtain conclusive insights into the degree of reliability of the axioms asserted by the LLM.\nMoreover, using different LLMs with different numbers of parameters and improving and expanding our strategies for testing disjointness constitutes interesting future work.\nIt could be worthwhile to look into heuristics for \u2013 given a large list of disjointness candidate pairs - picking those entries that are particularly \u201cpromising\u201d. One option would be to follow the strong disjointness assumption [6] and pick \u201csibling classes\u201d, that is, classes A and B that have a common direct superclass C. Furthermore, it could be interesting to test class pairs with just one or two examples of non-disjointness, as these instances may be errors to remove from the KG. On another note, one could develop strategies for gauging the reliability of an LLM response by rephrasing the question asked. This involves adding a description of classes in prompts to see if it improves the answers, relying on proper ontology serialization techniques [29]. Finally, using advanced prompting techniques, such as chain-of-thought, may improve the results alongside RAG techniques to pick the few-shot examples. Similarly, a richer prompt, including more qualifying phrases such as \u201cat the same time\u201d to check the temporality of the disjointness or \u201ctheoretically\u201d to force abstraction might instruct the model toward a more effective framing of the problem."}]}