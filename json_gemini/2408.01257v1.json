{"title": "Detection and Characterization of Coordinated Online Behavior: A Survey", "authors": ["Lorenzo Mannocci", "Michele Mazza", "Anna Monreale", "Maurizio Tesconi", "Stefano Cresci"], "abstract": "Coordination is a fundamental aspect of life. The advent of social media has made it integral also to online human interactions, such as those that characterize thriving online communities and social movements. At the same time, coordination is also core to effective disinformation, manipulation, and hate campaigns. This survey collects, categorizes, and critically discusses the body of work produced as a result of the growing interest on coordinated online behavior. We reconcile industry and academic definitions, propose a comprehensive framework to study coordinated online behavior, and review and critically discuss the existing detection and characterization methods. Our analysis identifies open challenges and promising directions of research, serving as a guide for scholars, practitioners, and policymakers in understanding and addressing the complexities inherent to online coordination.", "sections": [{"title": "1 INTRODUCTION", "content": "Coordination, the process in which multiple connected actors are involved to pursue goals [79], is a fundamental aspect in the existence of various life forms, including human beings. From flocks of birds engaging in synchronized flight to insects working together in colonies, coordination enhances efficiency, safety, and resource utilization [15]. The ability to coordinate actions boosts the chances to overcome environmental challenges, fostering not only individual survival but also the resilience and success of entire communities. For these reasons, human coordination has been extensively scrutinized in multiple scientific disciplines interested in the dynamics of our offline interactions [114, 127].\nWith the advent of social media platforms, coordination has also become a fundamental component of online interactions. Social media users are now provided with a broad array of tools to coordinate with each other, such as hashtags that enable them to collectively discuss specific topics [12, 121]. Online platforms have become a suitable environment for organizing social and political movements worldwide, giving rise to phenomena such as online activism [89, 98], boycotts [9, 70], and protests [74, 118]. The 2011 Arab Springs are a notable example, being largely organized through social media [54]. At the same time however, scholars found evidence of online coordination being exploited by nefarious actors for all sorts of malicious purposes. For instance, disinformation campaigns often leverage actors that coordinate their actions to maximize the outreach of their false narratives [62, 113, 117, 130]. Similarly, coordination is employed within information operations [18, 95, 130] and astroturfing, which involves creating the false appearance of grassroots support for a target cause, product, or person [62]. Also social bots and trolls exploit online coordination to amplify messages, manipulate trends, or spread disinformation [71, 82, 85, 141]. Finally, coordination also results from, and contributes to, the formation of echo chambers and online polarization [131]. Figure 1 highlights the complex, multifaceted, and intertwined nature of online coordination, which represents the underlying substrate of many diverse yet interconnected phenomena that permeate online social environments.\nRecognizing the profound impact of online coordination on social media as well as its consequences on the offline world, both researchers [98, 100, 130, 138] and industry stakeholders [35, 36, 39] devoted a great deal of efforts to study its dynamics and to develop effective strategies to detect and mitigate its malicious instances. Research sped up significantly after 2018, when Facebook introduced the concept of coordinated inauthentic behavior (CIB) [35], marking a milestone in the development of the field. As shown in Figure 2, subsequent years saw a surge of interest on the subject, testified by the steadily growing number of published papers. This survey is motivated by this thriving interest on online coordination, which resulted in the availability of a large body of work. However, while Facebook's interest towards online coordination was constrained to inauthentic behaviors as a response to the threat of orchestrated campaigns [35], here we embrace a more holistic and unbiased view by focusing on the broader concept of coordinated behavior. This inclusive approach allows for the analysis of a broader spectrum of works, including those focused on legitimate collective actions, offering a more comprehensive understanding of the coordination dynamics that shape digital spaces and fostering nuanced perspectives that go beyond mere threat detection. In spite of the many efforts, the existing literature still reflects the complexities and ambiguities surrounding this phenomenon. Among them is the limited agreement on a shared definition, which also hinders operationalization. Complexity also emerges from the diversity of methods proposed for detecting and characterizing coordinated online behavior, which impairs comparisons between different works and limits the generalizability of findings. Finally, the use of the same coordination technique by actors with disparate motivations poses challenges to estimating the impact and effects of online coordination."}, {"title": "Significance.", "content": "Comprehensively modeling coordinated online behavior has far-reaching implications. On a theoretical level, it reconciles diverse definitions and provides a foundational framework for future research. On a technical level, it critically evaluates and categorizes existing detection and characterization methods, informing the development of the next generation of robust and adaptive tools for studying both malicious and neutral instances of coordinated behavior. By shedding light on online coordination-a fundamental dynamic of computer-mediated human behavior- this survey contributes to safeguarding online integrity and to fostering positive interactions in digital spaces. It offers valuable insights for shaping future methodologies, platforms, and policies, and it also contributes to enriching the interdisciplinary research occurring at the intersection between computer science and social dynamics."}, {"title": "Scope.", "content": "Coordinated online behavior is orthogonal to many of the research topics tackled in fields such as Web and social media analysis, online social networks security, as well as social computing and computational social science, as shown in Figure 1. Therefore, a large number of works from these scientific communities implicitly or explicitly deal with online coordination. However, this survey is constrained to those papers that address online coordination explicitly and that provide relevant contributions to its detection, characterization, or understanding. In practice, we identified an initial set of candidate papers by selecting from Google Scholar and Scopus all those papers including the term \"behavior\u201d and at least one term among \u201ccoordinated\u201d, \u201cinauthentic\u201d, \u201ccollaborative\". Each candidate paper was then evaluated by one of the authors of this survey to filter out unrelated works. Furthermore, we also manually checked all references from each of the related works retained after the previous filtering step, in order to identify possible additional related works. The final set of works categorized and critically discussed in this survey includes 84 papers published between 2014 and 2024, as shown in Figure 2."}, {"title": "Organization.", "content": "This survey is structured as follows. Section 2 presents the theoretical foundations of coordinated online behavior, proposing a new general definition and laying out a comprehensive conceptual framework. Section 3 bridges the theoretical and methodological parts by defining the detection and characterization tasks. Section 4 discusses the existing literature on the detection task, while Section 5 focuses on the characterization task. Section 6 summarizes the main outstanding challenges and suggests promising directions of research. Finally, Section 7 concludes the survey."}, {"title": "2 CONCEPTUAL FRAMEWORK", "content": "The study of online coordination has its roots in the earlier studies of offline coordination. Recently, this study was advanced both by commercial platforms and academia, with a large array of different proposals. This section examines previously proposed definitions of coordination and discusses their advantages and limitations. Based on the results of this analysis, we then propose a general definition and a comprehensive conceptual framework."}, {"title": "2.1 Offline coordination", "content": "Coordination has already been extensively studied well before the emergence of social media across disciplines such as computer science, organization theory, management science, economics, and psychology [79, 114, 127]. Although the meaning of coordination is intuitive, researchers suggested many definitions to frame the concept. A concise and precise definition was given in [77]:"}, {"title": "Definition 2.1. Coordination (1988):", "content": "The additional information processing performed when multiple, connected actors pursue goals that a single actor pursuing the same goals would not perform [77]."}, {"title": "Definition 2.1", "content": "denotes coordination as the organizational overhead that multiple actors incur into when pursuing goals together. We note that this and similar definitions [5, 6, 76, 79] implicitly leverage the fundamental components of coordination, which we explicitly define as follows:"}, {"title": "Definition 2.2. Coordination components:", "content": "A set of two or more actors who perform activities in order to achieve goals."}, {"title": "Definition 2.2", "content": "introduces the fundamental components of coordination: actors, activities, and goals. Being coordination a nuanced concept, the theoretical modeling of these components can have major implications on downstream analyses and results. For example, in the case of communities or groups of users, each user in the group can be treated as a standalone actor, or alternatively the entire group may be considered as a single actor. Similar choices must be made when modeling the activities that allow actors to coordinate. Each actor typically performs multiple activities during any given time frame, and each of these activities might contribute differently to the overall coordination. Therefore, the choice of activities to model during an analysis directly impacts the resulting observed coordination [78]. Finally, the analyst is often interested in knowing the goal that the actors pursue when performing the activities. However, the actors may not all have the same goal, or even have any explicit goal at all [77]. These reflections on the components of coordination surface some of the challenges that early scholars faced since the 80s when studying offline coordination. Interestingly, many of these challenges carry over to the study of online coordination, informing the development of a new comprehensive definition and conceptual framework."}, {"title": "2.2 Concepts and definitions by online platforms", "content": "Beginning around 2016, mounting societal pressure impelled major social media platforms to confront pervasive challenges such as the organized dissemination of mis- and disinformation [135]. In consequence of this pressure, each platform adopted disclosure practices to communicate their results at exposing orchestrated deceptive activities perpetrated by organized actors. Given the importance of coordination for the success of large-scale disinformation campaigns [98, 101], within these public disclosure initiatives each platform addressed some instances of malicious online coordination. This section explores the concepts and definitions introduced by major social media platforms that are related to online coordination, discussing both their merits and limitations."}, {"title": "2.2.1 Facebook/Meta.", "content": "After the public disclosure that the Internet Research Agency (IRA) had strategically exploited the platform to influence the 2016 US presidential election [99], Facebook began publishing reports detailing how their services were abused and the actions taken in response. In unveiling further actions against the IRA, in July 2018 Facebook introduced the concept of coordinated inauthentic behavior (CIB) [36]. A few months later, they supplied it with a first definition, and in October 2019 with a second one."}, {"title": "Definition 2.3. Coordinated inauthentic behavior (2018):", "content": "Groups of pages or people working together to mislead others on who they are or what they are doing [35]."}, {"title": "Definition 2.4. Coordinated inauthentic behavior (2019):", "content": "The use of multiple Facebook or Instagram assets (accounts, pages, groups, or events), working in concert to engage in inauthentic behavior, i.e., to mislead people or Facebook, where the use of fake accounts is central to the operation [38]."}, {"title": "Definition 2.3", "content": "underscores the collaborative nature of disinformation campaigns [117], emphasizing the objective of misleading others about the purported identity of the involved actors. To this end, it introduces the concept of inauthenticity of the actors, which is ever since often used in conjunction with the notion of coordination. Definition 2.4 explicitly articulates the concept of inauthenticity and elucidates that the act of deceiving others involves the extensive use of fake accounts [37]. A widespread critique of these initial definitions is that they exclusively address CIB, overlooking other types of malicious and possibly harmful coordination, let alone the neutral or benign ones [19, 47, 52, 98]. In September 2021, Facebook provided additional definitions focusing on harmfulness rather than inauthenticity."}, {"title": "Definition 2.5. Coordinated social harm (2021):", "content": "Networks of primarily authentic users who organize to systematically violate policies to cause harm on or off the platform [41]."}, {"title": "Definition 2.6. Coordinated mass harassment (2021):", "content": "Coordinated efforts of mass harassment that target individuals at heightened risk of offline harm [40]."}, {"title": "Definitions 2.5 and 2.6", "content": "adopt the concept of harmfulness in place of inauthenticity, thereby broadening the scope to also encompass authentic yet coordinated actors. These, in fact, hold the potential to cause negative consequences both on and off the platforms, as underscored in Definition 2.5."}, {"title": "2.2.2 Twitter/X.", "content": "In October 2018, the platform released a public archive containing data about identified information operations (IOs).\u00b9 Although not explicitly stated in Twitter's definition at the time, a certain degree of coordination is necessary for the success of an IO [18, 130]. However, it was not until January 2021 that Twitter adopted a similar approach to Facebook and released a definition that explicitly addresses instances where coordination is leveraged to cause harm both online and offline."}, {"title": "Definition 2.7. Information operation (2018):", "content": "People directly involved in manipulation that can be reliably attributed to a government or state-linked actor [128]."}, {"title": "Definition 2.8. Coordinated harmful activity (2021):", "content": "Groups, movements, or campaigns that are engaged in coordinated activity resulting in harm on and off of Twitter [129]."}, {"title": "2.2.3 YouTube/Google.", "content": "In its reports, primarily concerning abuses that occurred on YouTube, Google makes reference to coordinated influence operations (CIO) [49]. Even though Google did not provide a definition for CIOs, they nonetheless highlighted the importance of coordination in these online manipulations."}, {"title": "2.2.4 Reddit.", "content": "In contrast to other platforms, Reddit embraced the broad concept of content manipulation to characterize the campaigns that violate its rules [104]. The platform shared only a small number of such campaigns, leaving it unclear whether these represent the entirety of the identified cases, or only a selection of them. Despite the absence of an explicit reference to coordination, large-scale content manipulations gain advantage from coordinated activities, similarly to what we discussed earlier about IOs."}, {"title": "Definition 2.9. Content manipulation (2022):", "content": "Things like spam, community interference, vote manipulation, and other attempts to artificially promote content [104]."}, {"title": "2.2.5 Ambiguities and limitations.", "content": "This brief survey of the main concepts and definitions proposed by social media shows that online platforms are at the forefront in the analysis of coordinated online behavior. However, their conceptualizations are driven primarily by pressing practical regulation needs and by immediate contingencies, rather than by methodological rigor and theoretical soundness [29]. Faced with specific instances of malicious coordination,"}, {"title": "2.3 Concepts and definitions in academic literature", "content": "As shown in Figure 2, scientific interest in coordinated online behavior has drastically risen in the last few years. However, akin to social media platforms, scholars have generally refrained from proposing theoretically-grounded and general definitions. The majority of the existing studies adopt Facebook's Definition 2.3 of CIB [84, 86]. Instead, those who propose their own conceptualization mainly provide operational definitions useful for the development of coordination detection methods [74, 98, 101]. Table 1 reports some examples of operational definitions proposed recently.\nAs shown, no definition is comprehensive and general enough to adequately describe the multifaceted phenomenon of coordinated online behavior. The existing conceptualizations of the phenomenon appear to be influenced by the specific technique employed for its detection. Consequently, the criteria used to define coordination vary, encompassing aspects"}, {"title": "2.4 General definition and fundamental components of coordinated online behavior", "content": "We propose a new general definition of coordinated online behavior that overcomes the ambiguities and limitations of the existing definitions. The new definition leverages the components of offline coordination introduced in Section 2.1 and is informed by the various operational definitions proposed by social media platforms and by the academic literature, respectively discussed in Sections 2.2 and 2.3."}, {"title": "Definition 2.10. Coordinated online behavior:", "content": "A group of users who perform synergic actions in pursuit of an intent.\nactors actions intent"}, {"title": "Definition 2.10", "content": "delineates coordinated online behavior based on three fundamental components-actors, actions, and intent that are similar to the components of offline coordination outlined in Definition 2.2. Definition 2.10 and its three fundamental components enable the comprehensive mapping of all instances of online coordination, as discussed in the following."}, {"title": "2.4.1 Actors.", "content": "Actors refer to the individuals or entities that are engaged in coordinated behavior. The attributes of the actors contribute to characterizing instances of coordination. For example, the way in which the actors represent themselves to those not involved in the coordinated behavior determines whether the coordination is authentic or otherwise. All instances of online coordination where the actors misrepresent themselves, as in the case of social bots [50, 55, 98, 101] and state-backed trolls [88], are cases of inauthentic coordination. Conversely, coordination among actors who accurately self-portray is deemed authentic [50]. In addition, the relationships between the actors determine whether the coordination is spontaneous, grassroots, or emergent (i.e., bottom-up) [98] or whether it is structured and well-organized (i.e., top-down) [130]. Finally, the number of the involved actors determines the scale of the coordination."}, {"title": "2.4.2 Actions.", "content": "Actions represent the practical means that allow actors to coordinate. In coordinated behavior the actions are synergic, in that they are mutually reinforcing and potentially capable of producing a larger effect than that obtainable by individual actions alone. While actors and intent can be misrepresented or concealed, actions are typically visible and non-falsifiable. In other words, the actions with which the actors coordinate represent the digital breadcrumbs of the coordination. For this reason, the actions are the component based on which the majority of coordination detection methods are developed. Furthermore, the types and attributes of the actions also provide information towards characterizing instances of coordination. For example, the timing and synchronization of the actions among actors indicates the degree of planning and organization involved [74, 142]. The consistency of the actions and the actions performed in response to external events are further characteristics of coordinated behaviors. Finally, the types of actions and their content provides insights into the intent and goals of the actors [19]."}, {"title": "2.4.3 Intent.", "content": "The intent is the objective that the actors pursue when they coordinate. When studying coordinated online behavior, the intent of the actors is typically unknown, if not deliberately concealed. For example, actors involved in malicious or harmful coordination conceal their intent to avoid being stopped in their endeavor [55]. However, also actors involved in neutral or benign forms of coordination might not openly state their goals and intent. For this reason, the observer often tries to infer the intent based on the visible actions performed by the actors. Furthermore, intent can be either shared and explicit among the actors, or implicit. For instance, the perpetrators of a disinformation campaign share the explicit goal of disseminating certain pieces of false information [62]. Conversely, fans of a sports team or public character may spontaneously engage in coordinated actions to support their idol, without having agreed on a specific objective or course of action [98]. The previous examples highlight that the characteristics of the intent are related to the degree of organization of the actors. Importantly, the intent also contributes to determining the harmfulness of the coordinated behavior. However, while there are cases in which it is relatively straightforward to categorize a coordinated behavior as harmful or otherwise-think for example of coordinated hate attacks [83] or state-backed disinformation campaigns [18]-there also exist situations where the harmfulness of the intent is inherently subjective. Coordinated efforts to promote a controversial political ideology may be perceived as harmful by some, while others may view them as legitimate expressions of free speech [100]. Similarly, coordinated campaigns to boycott a company or criticize a public figure may be seen as harmful by those targeted, but supporters may genuinely view them as justified forms of activism [93]."}, {"title": "2.5 Defining dimensions of coordinated online behavior", "content": "As discussed in the preceding sections, coordinated online behavior constitutes a complex and multifaceted phenomenon whose instances are contingent upon the actions and intent of the involved actors. Here we leverage our discussion about the fundamental components of online coordination to introduce four defining dimensions of this phenomenon: authenticity, harmfulness, orchestration, and time-variance."}, {"title": "2.5.1 Authenticity.", "content": "Authenticity refers to the degree of genuineness and transparency that the actors exhibit in their actions and overall online presence. Coordinated authentic behavior is executed by genuine actors and typically emerges organically within a community of users who share common interests or beliefs. Examples of authentic coordination are activists, social movements, and mutual support groups, which are driven by motivations such as a desire for social or political change or the cultivation of a sense of community and belonging [98, 118]. While authentic forms of coordination are also harmless in the majority of cases, as in the previous examples, there also exist less frequent cases of authentic yet harmful behaviors. For instance, certain coordinated hate groups openly encourage racist, xenophobic, or supremacist ideologies [90, 93, 138]. Conversely, coordinated inauthentic behavior entails the use of fake accounts, such as social bots, trolls, and fake personas [23, 108]. These are typically employed for purposes such as spreading disinformation, sowing confusion, or eroding trust in democratic institutions. As such, inauthentic coordination is often characterized by its deceptive nature and aim to manipulate unaware users [117]. Nonetheless, there exist cases of inauthentic yet harmless coordination. For example, online participants in the Arab Spring movements concealed their identities to avoid government surveillance and potential reprisals [54]. While their coordinated efforts were inauthentic in terms of individual identity disclosure, they remained largely harmless in intent, aiming to promote democratic ideals, social justice, and human rights. These examples highlight the difference between authenticity and harmfulness, which represent two orthogonal dimensions of coordinated online behavior."}, {"title": "2.5.2 Harmfulness.", "content": "Harmfulness refers to the negative impact, consequences, or outcomes-both online and offline- resulting from the coordinated actions of the actors. As discussed in Section 2.4.3, harmfulness depends both on the shared intent and actions of the actors engaged in coordination, and on the viewpoint of the observer, constituting a much more conceptually intricate dimension of online coordination than authenticity. However, in spite of the inherent subjectivity, there exist many clear cut cases of harmful and harmless coordination. For example, coordinated actors involved in the spread of disinformation, hate speech, and online harassment, represent straightforward cases of harmful coordination [18, 95]. In contrast, users who coordinate to collect and share information and other resources, such as in the aftermath of mass emergencies, represent cases of harmless coordination [74, 98, 100]."}, {"title": "2.5.3 Orchestration.", "content": "Orchestration represents the degree of planning and organization between the coordinated actors. This dimension is closely linked to the intent of the actors, in that highly orchestrated campaigns typically imply shared intent and goals between the participants. The orchestration of a coordinated campaign can be centralized or distributed. In centralized orchestration, a single actor or entity exercises control and coordination over the actions of all other actors involved in the coordinated behavior. This centralized authority dictates the timing, content, and strategy of the coordinated actions, allowing for tight coordination and synchronization. An example of strong and centralized orchestration is the coordinated behavior exhibited by social botnets, where large groups of automated accounts quasi-simultaneously perform predefined actions depending on the command of a botmaster entity [85]. In decentralized orchestration, coordination and control are distributed among multiple actors within a network, without a single central authority dictating the actions of all participants. Actors may self-organize, collaborate, or communicate autonomously, often guided by shared goals, interests, or ideologies. For instance, in January 2021, retail investors coordinated on Reddit to target short-selling activity by hedge funds on GameStop shares, causing a surge in the share price and triggering significant losses for the funds involved [70]. Instead, non-orchestrated coordinated behavior occurs when the actions of multiple actors spontaneously converge around a given topic, narrative, or activity. Certain viral social media trends are an example of non-orchestrated coordination emerging from the widespread adoption of a particular hashtag or activity that occurs organically as many users observe and emulate others' behavior [118]."}, {"title": "2.5.4 Time-variance.", "content": "Time-variance refers to the temporal characteristics and the dynamic nature of coordinated online behavior. It grasps possible changes in the types, timing, frequency, and intensity of the actions, which in turn may reflect changes in the intent of the actors, as well as adaptations or responses to external stimuli. Examples of largely static coordinated behavior are the activities of some spammers and bots, who repeatedly perform the same actions adhering to a fixed pattern without much adaptation or variation [23, 100]. Conversely, many information operations are dynamic and time-varying, presenting different characteristics at different points in time. Among the changing characteristics are the types of actors involved in the coordination (e.g., whether automated or human-operated) or the topics of discussion [117, 130]. Time-variance also strongly depends on the duration of the coordinated behavior itself. Actors involved in certain state-sponsored disinformation campaigns operate on online platforms for extended periods, spanning years or even decades [64]. Over such lengthy time frames, the actors adapt their tactics, narratives, and targets in response to shifts in intent, changes in technology and platforms, or advancements in countermeasures. This extended duration implies a relatively gradual and nuanced evolution of the coordinated behavior. Conversely, other forms of online coordination rely on expendable or disposable accounts created for short-lived and fast-paced activities [8]. These actors are employed for specific tasks and then discarded or deactivated once their purpose is fulfilled or they are detected. As a result, these ephemeral instances of coordination are rapid, intense, and short-lived."}, {"title": "2.6 Taxonomy and final remarks", "content": "Our conceptual framework of coordinated online behavior encompasses the three fundamental components presented in Section 2.4 and the four defining dimensions discussed in Section 2.5, providing a general and flexible scheme for studying, categorizing, and comprehensively mapping the multiple instances of online coordination."}, {"title": "3 PROBLEM DEFINITION", "content": "The problem of identifying and investigating different types of coordinated online behavior involves defining two functions f(.) and g(.) that respectively implement the tasks of coordinated behavior detection and characterization, as outlined in Figure 4. Given a set of users and their actions on one or more online platforms, f(.) identifies possible coordinated groups of users. Instead, g(.) extracts additional information for each detected group, thus contributing to determining the nature, intent, and the overall characteristics of the involved actors (e.g., whether they are inauthentic, harmful, etc.). The detection and characterization tasks are related to the Definition 2.10 of coordinated online behavior and its components in that the function f(.) implementing the detection task does so via the analysis of user actions, while the function g(.) implementing the characterization task provides information about the actors and their intent. A comprehensive overview of the entire process is depicted in Figure 4. The input is represented by the set of users U to analyze and their activities H. The detection task differentiates coordinated users from non-coordinated ones. Depending on the detection method, the distinction between the two can be expressed as binary labels assigned to the users, as two or more sets (e.g., clusters) of either coordinated or non-coordinated users, or as two or more coordinated or non-coordinated communities (i.e., nodes and edges) from a network. These are subsequently scrutinized during the"}, {"title": "3.1 Detection of coordinated online behavior", "content": "3.1.1 Input. Let I = (U,H) be the problem input, where U = {u1,...,un} denotes the set of users and H = [Hu1,..., Hun] represents an ordered vector of activities performed by those users. We define the activity of a user uj as Huj = [h1j,...,hmj] representing the vector of chronologically ordered actions performed by uj. An action is defined by the quadruple h = <type, target, content, timestamp) which describes the type of action executed by a user on a specific target or content, at a given timestamp. Users can execute actions of different type such as posting, resharing, befriending, and more. A target is another user of the platform who is affected by the action. For example, in the case of a retweet action on the platform Twitter/X, the target is the author of the retweeted tweet. For some actions the target is undefined, as in the case of the posting action. The content of an action is a post (e.g., a tweet, comment, submission, and more, depending on the platform). Posts contain one or more elements of content, such as text, image, URL, mention, hashtag, and more. In case the content contains multiple elements, the corresponding action is called compound action [74]. Similarly to the target, also the content can be undefined depending on the type of action, as in the case of a befriending or following action. To wrap up, the type of action and its timestamp are always defined, while one of content and target might be optional, depending on the type of action."}, {"title": "3.1.2 Methods and output.", "content": "As presented in Section 4, most of the existing literature on coordinated behavior detection analyzes both the set of users and their actions. Some studies only leverage the content of the actions, without considering their type [25, 83, 133]. Furthermore, certain works do not take into consideration the timings of the actions [14, 17, 19, 83], while some others only consider the timings [8]. The task of detecting coordinated online behavior is modelled by the function f (U, H), which can provide three different outputs depending on the adopted method, corresponding to different levels of detail and information on the coordinated users:"}, {"title": "3.2 Characterization of coordinated online behavior", "content": "3.2.1 Input. The characterization task is modelled by the function g(Y, H) = M whose inputs are the groups of coordinated users resulting from the detection task f (U, H) = Y \u2208 {P, C, B}, defined in Eq. (1), with their activities H."}, {"title": "3.2.2 Methods and output.", "content": "As discussed in Section 5, the characterization task aims at computing a set of quantitative indicators M to measure distinctive properties of the detected coordinated behaviors in terms of the defining dimensions that we presented in Section 2.5: authenticity, harmfulness, orchestration, and time-variance. The indicators that can be used in the characterization task partly depend on the methods and outputs of the detection task. For example, assortativity measures the extent to which nodes with a high degree in a network are connected to other nodes with a high degree, and vice versa. This indicator was used to gain insights into the inner structure and organization of certain coordinated communities [98]. However, assortativity can be computed only if the coordination detection method outputs communities, rather than clusters or binary labels. On the contrary, other indicators can be computed independently of the detection method, such as the aforementioned bot scores that are commonly used as an estimator of the inauthenticity of the coordinated users [50, 55, 98, 101]. The utility of the characterization task is not limited to shedding light on the nature of the detected coordinated behaviors nor to distinguishing between different instances of the phenomenon. In fact, the output of characterization task can also be leveraged to validate the output of the detection task, as in those frequent cases when a ground-truth of coordinated users is unavailable."}, {"title": "4 DETECTION OF COORDINATED BEHAVIOR", "content": "Coordination detection methods can be classified into two main categories depending on their underlying approach: network science or machine learning. The following sections discuss the existing solutions in each category."}, {"title": "4.1 Network science methods", "content": "Network science coordination detection methods build a network of users or posts, where the links between the nodes in the network represent the presence, and possibly also the extent [98], of coordination. In spite of the existing differences, all methods in this category carry out the sequence of steps shown in Figure 5, namely: (i) user selection, (ii) coordination network construction, (iii) network filtering, and (iv) community discovery. We now discuss the objective and the implementation options available for each step."}, {"title": "4.1.1 User selection.", "content": "This step selects an initial subset U' \u2286 U of users according to some criteria that depend on the purpose of the analysis. This initial selection is motivated by the observation that a small fraction of users accounts for the majority of actions on a social network [102], especially those associated with harmful behaviors [106]. Selecting a subset of users also has the positive consequence of reducing the computational cost of the subsequent steps, which can easily become time- and computation-intensive for large networks [20].\nImplementation. Multiple choices can be made to select a subset of relevant users. A common choice is to select the most active users as they produce the largest share of actions and content. Most active users can be defined as those who publish a large number of original posts (super-producers) [66, 73, 101], or as those having a large number of re-shares (super-spreaders) [19, 28, 55, 69, 87, 98, 120]. Other than activity, network centrality or influence, suspicious behavior, location, and timings are used for user selection [10, 72]. Furthermore, many other general criteria can also be adopted, such as selecting all users who posted certain keywords, or all followers of a given user. Combining multiple criteria allows for even more fine-grained user selections."}, {"title": "4.1.2 Coordination network construction.", "content": "This step builds a coordination network between the users U' C U previously selected.\u00b3 A coordination network is a type of network where links exist only between coordinated nodes. As per Definition 2.10, coordination implies synergic actions between users. In network science methods, this concept is operationalized with co-actions. A co-action represents two users performing the same action on the same target or content. For instance, two users who comment, like, or re-share the same post are generating a co-action. As shown in Figure 6, the two coordinated users need not be directly connected in the social or interaction network."}]}