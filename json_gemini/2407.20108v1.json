{"title": "Classification, Regression and Segmentation directly from k-Space in Cardiac MRI", "authors": ["Ruochen Li", "Jiazhen Pan", "Youxiang Zhu", "Juncheng Ni", "Daniel Rueckert"], "abstract": "Cardiac Magnetic Resonance Imaging (CMR) is the gold standard for diagnosing cardiovascular diseases. Clinical diagnoses predominantly rely on magnitude-only Digital Imaging and Communications in Medicine (DICOM) images, omitting crucial phase information that might provide additional diagnostic benefits. In contrast, k-space is complex-valued and encompasses both magnitude and phase information, while humans cannot directly perceive. In this work, we propose KMAE, a Transformer-based model specifically designed to process k-space data directly, eliminating conventional intermediary conversion steps to the image domain. KMAE can handle critical cardiac disease classification, relevant phenotype regression, and cardiac morphology segmentation tasks. We utilize this model to investigate the potential of k-space-based diagnosis in cardiac MRI. Notably, this model achieves competitive classification and regression performance compared to image-domain methods e.g. Masked Autoencoders (MAEs) and delivers satisfactory segmentation performance with a myocardium dice score of 0.884. Last but not least, our model exhibits robust performance with consistent results even when the k-space is 8\u00d7 undersampled. We encourage the MR community to explore the untapped potential of k-space and pursue end-to-end, automated diagnosis with reduced human intervention.", "sections": [{"title": "1 Introduction", "content": "Cardiac Magnetic Resonance Imaging (CMR) serves as the gold standard for diagnosing and treating cardiovascular diseases, offering a comprehensive view of the heart's morphology and function. This non-invasive method enables detailed assessments of myocardial viability, ventricular function, and vascular anatomy. While Digital Imaging and Communications in Medicine (DICOM) protocol images are the prevalent format for storage and visualization, they consist solely of magnitude data derived from the real and imaginary components of the original complex data. Crucially, the phase information omitted in DICOM images holds potential value for tasks such as image reconstruction, segmentation, and the evaluation of flow dynamics and tissue movement [28, 9, 25]. Meanwhile, accelerated MR scans are preferred in clinics to reduce scan time and enhance patient comfort, leading to undersampled k-space(frequency domain representation of MR signal), which results in corrupted/blurred CMR images and deteriorates the follow-up downstream tasks [10, 22, 7, 19, 21].\nRecently, methods that perform downstream tasks, e.g., motion estimation [16, 15] and segmentation [26, 25, 30] directly from k-space data gained attention. K-space, being complex-valued, encapsulates phase information and remains an intact and reliable data source with no corruptions, despite some acquisition lines that could be missing in undersampling. However, humans may struggle to perceive k-space data since they are not visually understandable to humans. Conversely, deep learning models excel in processing these data, as their computational frameworks readily handle complex values. Given the complexity and rich content of k-space data, selecting appropriate methods to effectively process and utilize this data is crucial for optimizing the diagnostic capabilities of cardiac MRI and for a comprehensive assessment of cardiovascular health.\nTransformers are highly proficient in capturing long-range dependencies [17] and handling complex data structures, making them well-suited for modeling the temporal dynamics and global information present in k-space data [20]. Pan et al. proposed the Transformer-based K-GIN model [23], showing outstanding performance in MRI reconstruction solely using k-space data, highlighting the strong capabilities of its encoders in feature extraction and representation learning. We argue that this learned representation is not limited to the reconstruction tasks, but can be leveraged to more diverse tasks such as classification and segmentation. In this work, we propose KMAE, a versatile model that takes (undersampled) k-space data as inputs and can handle various downstream tasks, including disease classification, relevant phenotype regression, and cardiac segmentation. It leverages the pre-trained K-GIN encoders to attain rich representation and applies different decoders to carry out diverse downstream tasks. This adaptation facilitates efficient and accurate diagnostics and analyses based on k-space data. The contributions of this study can be summarised as follows:\n1.  We propose KMAE, a Transformer-based method for processing cardiac MR k-space data. KMAE can perform multiple downstream tasks, including disease classification, phenotype regression, and cardiac segmentation. To the best of our knowledge, we are the first to conduct disease classification directly from k-space data.\n2.  Unlike Convolutional Neural Networks (CNNs), which use local convolutional windows, we demonstrate that Transformers, which capture long-range dependencies, are more effective and robust for k-space data.\n3.  KMAE achieves competitive classification and regression performance compared to image-domain methods such as Masked Autoencoders (MAEs). It also provides satisfactory segmentation results with a myocardium dice score of 0.884, matching the quality of image-domain segmentation. Our model"}, {"title": "2 Related Work", "content": "K-space Interpolation: Previous methods typically leverage auto-calibration signals (ACS) in the k-space center to carry out k-space interpolation [8, 18]. RAKI [2, 14] improved the ACS-based methods by implementing CNNs. However, these approaches did not fully exploit the global dependencies present in k-space. Recently, a Transformer-based k-space interpolation method considering k-space global dependencies for dynamic CMR reconstruction was introduced by Pan et al. [23], achieving superior performance compared to baselines.\nDownstream Tasks directly from K-space: Schlemper et al. [26] proposed CNN-based models with an end-to-end synthesis network and a latent feature interpolation network, predicting cardiac segmentation maps directly from undersampled dynamic MRI data. Kuestner et al. introduced LAP-Net [16], which can estimate the cardiac motion from the k-space of Cardiac MR. Moritz Rempe et al. proposed k-strip model [25], a complex-valued CNN-based algorithm for skull stripping in MRI, skipping operations in the image domain. Nevertheless, these methods are built upon CNNs and may not be able to fully exploit the global dependencies in k-space. Concurrently, Zhang et al. [30] proposed to use Transformers to directly derive segmentation from undersampled k-space data.\nMasked Image Modelling: Vision Transformers (ViTs) [5] adapted Transformers from natural language processing to computer vision. Unlike CNNs that rely on local convolutions, the global self-attention mechanism of ViTs allows for the modeling of long-range dependencies within images [13]; Masked Autoencoders (MAEs) [11], was introduced based on ViTs to extract the representation using masked image modeling in a self-supervised manner. Its versatility is further demonstrated in cardiac MR imaging analysis [29]. Recently, K-GIN [23] was introduced based on MAEs to learn k-space representation and conduct cardiac MR reconstruction, presenting robust and superior performance. We argue that its learned representation is not limited to the reconstruction tasks, but also the other tasks such as classifications and segmentation."}, {"title": "3 Methods", "content": ""}, {"title": "3.1 Pre-Training", "content": "Models: K-GIN [23], designed for MRI reconstruction, processes undersampled k-space data (e.g., Cartesian undersampling) and performs k-space interpolation to predict fully sampled k-space data, and converts it to MRI via an inverse fast Fourier transform. MAEs [11] features an asymmetric design. The model inputs images with most patches masked, exposing only a few. The encoder processes these visible patches and passes them to a smaller decoder, whose primary task is reconstructing the original image pixels, resulting in high-quality MRI images."}, {"title": "Pre-Training Process:", "content": "We utilize k-space interpolation / image reconstruction tasks to pre-train KMAE / MAEs, as illustrated in Figure 1(a). During the pre-training phase, our KMAE model rigorously adheres to the foundational principles and procedures established by the K-GIN architecture.\nEvaluation Metrics Meaning: After pre-training, both KMAE and MAES achieve high Peak Signal-to-Noise Ratio (PSNR) values, showcasing the excellent quality of their reconstructed images. This performance illustrates their encoders' effectiveness in extracting meaningful representations from raw data, facilitating subsequent tasks. Moreover, this pre-training approach significantly reduces training times, enabling faster adaptation to various downstream tasks."}, {"title": "3.2 Regression and Classification", "content": "After pre-training, we freeze the model's encoder and discard the reconstruction decoder. The trained encoder is then used to extract valuable feature representations for downstream tasks such as regression and classification, as shown in Figure 1(b). Both KMAE and MAEs adopt a consistent architectural framework for downstream tasks.\nFor regression tasks, we employ a pooling layer to transform the extracted features into a feature vector. This vector is then fed into a fully connected (FC) layer to predict the regression value for each subject. Regarding classification tasks, we incorporate a final layer equipped with a SoftMax function, which computes the probability of each class to categorize the subjects."}, {"title": "3.3 Segmentation", "content": "In regression and classification tasks, outputs are numerical values and probabilities, so the decoder used for image reconstruction in pre-training is removed as it is unnecessary. However, image segmentation tasks remain closely linked to reconstruction tasks as they both require pixel-level prediction. Therefore, we adopted the same reconstruction decoder to accomplish CMR segmentation.\nRegarding MAEs, it processes in the image domain and we can adapt it to segmentation tasks by simply replacing the final layer with a Sigmoid function. On the other hand, KMAE handles in the frequency domain, therefore we first Fourier transfer the reconstructed k-space to MR images. These images are then processed through a 1x1 convolution layer, followed by a Sigmoid function to effectively segment the myocardium. Both structures are described in Figure 1(c)."}, {"title": "4 Data and Experiments", "content": ""}, {"title": "4.1 Dataset", "content": "Dataset. We used short-axis cardiac MR images provided by UKBioBank [24] and corresponding clinical information, which provide a cross-sectional view of the left and right ventricles of the heart. We applied center-cropped CMR images with a matrix size of 128\u00d7128 across 25 temporal cardiac phases (we used every two temporal frames). Since the original CMR from UKBioBank are magnitude-only images, we created synthetic k-space data for each 2D+time scan by applying additional Gaussian B0 variations in real-time to remove the conjugate symmetry of k-space [26], thus simulating fully sampled single-coil acquisitions. We stacked 11 slices along the long axis. Additionally, we applied VISTA Cartesian undersampling masks [1] to generate the accelerated k-space and the corresponding MRI.\nFilter Data and Label Strategy. The UK Biobank CMR dataset initially comprises 47,097 subjects. We identified three distinct subsets for our study: Healthy Subgroup, consisting of 2,660 individuals without risk factors such as obesity, myocardial infarction, acute myocardial infarction, insulin-dependent diabetes mellitus, or physician-diagnosed vascular or heart conditions. This subgroup only includes individuals rated as \"Excellent\" or \"Good\" in overall health who also reported never having smoked tobacco [27]. Cardiopathy Subgroup [4] comprises 1,340 subjects with diagnosed heart conditions, including heart attacks, myocardial infarction, and angina. Left Ventricular Dysfunction Subgroup [6] includes 937 subjects with a Left Ventricular Ejection Fraction (LVEF) below 50%. For regression, we selected 2,000 subjects from the Healthy Subgroup to calculate cardiac age based on birth year and scan date [12]. We used LVEF and LVEDV(Left Ventricular End-Diastolic Volume) labels from 1,000 healthy subjects sourced from [3]. For classification, we compared 937 subjects from the Left Ventricular Dysfunction Subgroup to an equal number from the Healthy Subgroup. Similarly, 1,340 subjects from the Cardiopathy Subgroup were matched with an equivalent number from the Healthy Subgroup."}, {"title": "4.2 Implementing details", "content": "Pre-training. We trained MAEs and K-GIN on data from the Healthy Subgroup, which consisted of MRI datasets with 5 slices and 25 temporal frames. Both models were tasked with image reconstruction, achieving PSNR of 38.846 for MAEs and 38.755 for K-GIN. The MAEs used a patch size of 2, while all other hyperparameters remained consistent with the original MAE specifications. Similarly, K-GIN adhered to its original configurations. Details of the implementation are disclosed in our code repository.\nTraining Strategy. We employed an NVIDIA A40 GPU to train our framework, configuring the setup with a single batch and a learning rate scheduler, peaking at 0.0001. Our Transformer architecture utilized 8 layers, 8 heads, and an embedding dimension of 512, while the ResNet model was trained without pre-trained weights from cardiac MRI data. For classification and regression tasks, we processed 5 MRI slices per subject, each containing 25 frames, and averaged the results from each slice to compute final regression scores or classification probabilities. The KMAE and MAEs' encoder were frozen, with only training on subsequent layers, as shown in Figure 1(b). Moreover, we performed a comprehensive performance comparison by training the full KMAE pipeline without freezing any components. For segmentation tasks, we used a single MRI slice with 25 frames per subject to accurately segment myocardial regions with no encoder freezing, as illustrated in Figure 1(c).\nResNet Baseline. Our k-space data includes 2D spatial and temporal dimensions (2D+t). So, we adapted ResNet50 by modifying the channel dimensions of its 2D convolutional layers to match the number of cardiac SAX slices.\nMetrics. In accelerated CMR, where CMR imaging employs acceleration techniques, higher acceleration factors (R=4 or R=8) lead to increased undersampling of k-space data. For regression tasks, we used Huber loss to train and evaluated performance by Mean Absolute Error (MAE). Lower MAE values indicate better regression performance. For classification tasks, performance was assessed using cross-entropy loss and accuracy, with higher accuracy indicating"}, {"title": "5 Results and Discussion", "content": "In table 1, KMAE generally exhibits lower MAE values for regression tasks, indicating more accurate predictions for variables such as age, LVEF, and LVEDV. Even with undersampling k-space data, KMAE tends to outperform ResNet. KMAE consistently achieves higher accuracy for classification tasks than ResNet, regardless of undersampling or freezing layers.\nTable 2 demonstrates that the Transformer model performs comparably well with undersampled k-space data as input, even when compared to original MRI images. This adaptability is evident in the first two rows of the table. Even when undersampled k-space data is used as input (KMAE at R=4 and KMAE at R=8), the model still achieves competitive performance, with only slight variations compared to the implementation on the full sampled k-space data.\nTable 3 shows that MAEs achieves the highest Dice coefficient. Meanwhile, KMAE and its undersampled version also exhibit reasonably high Dice coefficients, demonstrating that they are capable of producing accurate segmentation results, albeit slightly lower than the MAEs model.\nFigure 2 shows that MAEs, utilizing CMR images as the input, delivers optimal segmentation performance by precisely delineating the myocardium within the heart. Furthermore, KMAE employing undersampled k-space inputs also exhibits impressive segmentation capabilities."}, {"title": "6 Conclusion", "content": "In this study, we introduce KMAE model, designed to utilize k-space data for tasks such as disease classification, phenotype regression, and cardiac segmentation. Our findings reveal that Transformer-based architectures effectively process k-space data, achieving comparable classification and regression performance to image-domain models and successfully emulating image-domain segmentation techniques. Moreover, KMAE maintains consistent performance with undersampled k-space data, underscoring its robustness and potential for accelerated MRI applications. This research also highlights the considerable promise of employing k-space data in cardiac MRI and confirms the suitability of Transformer"}]}