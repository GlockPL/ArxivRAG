{"title": "EVIDENTIAL FEDERATED LEARNING FOR SKIN LESION IMAGE CLASSIFICATION", "authors": ["Rutger Hendrix", "Concetto Spampinato", "Federica Proietto Salanitri", "Simone Palazzo", "Ulas Bagci"], "abstract": "We introduce FedEvPrompt, a federated learning approach that integrates principles of evidential deep learning, prompt tuning, and knowledge distillation for distributed skin lesion classification. FedEvPrompt leverages two sets of prompts: b-prompts (for low-level basic visual knowledge) and t-prompts (for task-specific knowledge) prepended to frozen pre-trained Vision Transformer (ViT) models trained in an evidential learning framework to maximize class evidences. Crucially, knowledge sharing across federation clients is achieved only through knowledge distillation on attention maps generated by the local ViT models, ensuring enhanced privacy preservation compared to traditional parameter or synthetic image sharing methodologies. FedEvPrompt is optimized within a round-based learning paradigm, where each round involves training local models followed by attention maps sharing with all federation clients. Experimental validation conducted in a real distributed setting, on the ISIC2019 dataset, demonstrates the superior performance of FedEvPrompt against baseline federated learning algorithms and knowledge distillation methods, without sharing model parameters. In conclusion, FedEvPrompt offers a promising approach for federated learning, effectively addressing challenges such as data heterogeneity, imbalance, privacy preservation, and knowledge sharing.", "sections": [{"title": "1 Introduction", "content": "In recent decades, deep learning has played a leading role in medical image analysis, including skin lesion classification. However, most of the existing methods rely on centralized learning, assuming data uniformity and accessibility, which often does not align with the reality of decentralized and privacy-sensitive clinical settings. This disparity not only limits progress in the field, but also exacerbates inequalities, with wealthier regions having a data advantage over poorer areas, leading to disparities in model performance and clinical support. Federated learning (FL) emerges as a promising"}, {"title": "2 Background Evidential Learning", "content": "Deep Learning methods often use softmax activation in the output layers to perform classification. However, softmax outputs can be biased to training data, failing to predict with low certainty even for samples far from the distribution St\u00e5hl et al. [2020]. In contrast to the additivity principle in probability theory, Dempster-Shafer theory describes that the sum of belief can be less than 1. Its remainder is then attributed to uncertainty.\nIn a frame of K mutually exclusive singletons (e.g., class labels), each singleton $k \\in [K]$ is assigned a belief mass $b_k$, and an overall uncertainty mass $u$. The sum of these K + 1 mass values is constrained by $u + \\sum_{k=1}^{K} b_k = 1$, with $u \\geq 0, b_k \\geq 0, \\forall k \\in [K]$. The belief mass is determined by the evidence supporting each singleton, reflecting the level of support gathered from data. The uncertainty is inversely proportional to the total amount of evidence, with uncertainty equal to 1 for a total lack of evidence. A belief mass assignment corresponds to a Dirichlet distribution with parameters $\\alpha_k = e_k + 1$, where $e_k$ denotes the derived evidence for the k-th singleton. This choice of Dirichlet distribution is motivated by its role as a conjugate prior to the categorical distribution, and is defined as:\n$Dir(p, a) = \\frac{\\Gamma(S)}{\\prod_{k=1}^{K} \\Gamma(\\alpha_k)} \\prod_{k=1}^{K} p_k^{\\alpha_k-1}, \\quad \\alpha_k > 0$\nwhere $p$ denotes a probability mass function, $K$ denotes the number of classes, $a = [\\alpha_1, ..., \\alpha_K]$ are the Dirichlet parameters related to the evidence, $\\Gamma(\\cdot)$ denotes the gamma function, and $S = \\sum_{k=1}^{K} \\alpha_k$ is termed the Dirichlet strength.\nFrom the parameters of this Dirichlet distribution, the belief $b_k$ and the uncertainty $u$ are derived as:\n$b_k = \\frac{\\alpha_k}{S}$ $u = \\frac{1}{S}$\nWhen considering an opinion, the expected probability $p_k$ of the k-th singleton equates to the mean of the corresponding Dirichlet distribution, calculated by:\n$p_k = \\frac{\\alpha_k}{S}$"}, {"title": "3 Methodology", "content": "We introduce FedEvPrompt, our federated learning paradigm, which leverages prompt evidential learning and knowledge distillation on ViT attention maps for enabling effective knowledge aggregation across federated clients. The overall learning strategy is described in Fig. 1.\nFedEvPrompt is based on a pre-trained ViT model, kept frozen across all clients within the federation. Upon the fixed backbone, prompts are prepended on each client model and optimized using local data. Each client also computes attention maps (through attention rollout mechanism Abnar and Zuidema [2020]) for each class and shares a subset of them with the federation. The attention maps by all clients form our uncertainty-aware attention buffer that is used for knowledge distillation during prompt learning.\nLearning is organized in rounds: at each round, federation clients carry out different local training epochs for prompt optimization through a combination of evidential loss for learning class evidence and knowledge distillation loss on the per-class attention maps present within the buffer. At the end of training round, each client identifies its M most informative attention maps for each class and updates the buffer.\nMore in detail, each client employs a frozen ViT, as the backbone, with two sets of prompts b-prompts and t-prompts. Each prompt is associated with a specific attention layer, with the b-prompts (basic prompts) prepended to layers with low-level feature representation and the t-prompts (task-specifc prompts) to deeper layers with high-level feature"}, {"title": "3.1 Evidential loss", "content": "Our method is based on evidential learning, i.e., the classification model outputs evidences $E = [e_1, ..., e_K]$, with K categorical class elements (number of classes). The Dirichlet distribution characterizes the likelihood of each discrete probability value within a set of possible probabilities. It is parameterized by a vector of K elements (classes), $\\alpha = [\\alpha_1, ..., \\alpha_K]$, defined as $\\alpha_k = e_k + W_k$, with $e_k$ being the model evidence for class k, and $W_k$ the prior weight for that class. Classical EDL assumes a uniform Dirichlet (Dir(1)) distribution as a prior, i.e., W = (1, 1, . . ., 1). The uncertainty for the $i^{th}$ input sample is then estimated as $u_i = \\frac{K}{S_i}$, with S being the total Dirichlet strength $S = \\sum_{k=1}^{K} \\alpha_k$. Due to the strong class imbalance typical in federated learning settings, we change the uniform evidential prior to a skewed distribution, weighted by class frequency:\n$\\alpha_k = e_k + W_k \\text{ with } W_k = K \\cdot \\frac{N_k}{N}$\nsuch that $\\sum_{k=1}^{K} W_k = K$.\nPrompt parameters are finally optimized by minimizing the evidential loss defined in Sensoy et al. [2018b] as a combination of MSE and KL divergence. Given the $i^{th}$ input sample, the one-hot-encoded vector $y_i$ of its class label k, and its expected probabilities $p_i$, the evidential loss $L_e$ is computed as:\n$L_e(\\Theta) = E_{p \\sim Dir(\\alpha)} [(y_i - p_i)^T (y_i - p_i)] + A_{KL} D_{KL}(Dir(p_i|a_i)||Dir(p_i|w_i))$\nwith $A_{KL} = min(1, t/10)$ being an annealing factor applied to gradually increase the regularization impact with the number of epochs t.\nIn order to let the evidence for incorrect classes shrink to the weighted prior values W, the KL divergence loss term minimizes the distributional difference between W and misleading evidence $\\tilde{a}$, formulated as $\\tilde{a} = y \\cdot w + (1 - y) \\alpha$. Given the weighted prior distribution $W = Dir(p|w)$ and $P = Dir(p|\\tilde{a})$, the general KL divergence form for the Dirichlet distribution Proof: becomes:\n$D_{KL}(Dir(p|a)||Dir(p|w)) = log\\left( \\frac{\\Gamma(\\sum_{k=1}^{K} \\tilde{a}_k)}{\\Gamma(\\sum_{k=1}^{K} w_k)} \\right) + \\sum_{k=1}^{K} \\left( \\psi(\\tilde{a}_k) - \\psi(w_k) \\right)$\n$\\sum_{k=1}^{K} \\left(\\tilde{a}_k - w_k \\right) \\left( \\psi(\\tilde{a}_k) - \\psi\\left(\\sum_{k=1}^{K} \\tilde{a}_k \\right) \\right)$$\\left(\\psi(w_k) - \\psi\\left(\\sum_{k=1}^{K} w_k \\right) \\right) +$$\\log\\left( \\frac{\\Gamma(\\sum_{k=1}^{K} w_k)\\cdot \\prod_{k=1}^{K} \\Gamma (\\tilde{a}_k)}{\\Gamma (\\sum_{k=1}^{K} \\tilde{a}_k)\\cdot \\prod_{k=1}^{K} \\Gamma (w_k)} \\right)$\nWith $\\Gamma$ being the gamma function, and $\\varphi$ being the digamma function."}, {"title": "3.2 Uncertainty-Aware Attention Buffer for Knowledge Distillation", "content": "Prompt optimization involves minimizing a knowledge distillation loss $L_{KD}$ term between the model attention maps (computed through attention rollout) and the maps available in our uncertainty-aware attention buffer $A$ shared within all the C clients of the federation, with each client providing M attention maps for each of the K classes:\n$A = \\bigcup_{c=1}^{C} \\bigcup_{k=1}^{K} \\bigcup_{m=1}^{M} a_{c,k,m}$\nhere $a_{c,k,i} \\in R^{H \\times W}$ represents the $i^{th}$ attention map for the $k^{th}$ class of the $c^{th}$ client of the federation. H and W are the height and width of the attention maps equal to input image dimensions. The knowledge distillation loss $L_{KD}$ for a generic training sample of client c, with class k can be expressed as:\n$L_{KD} = \\frac{1}{C \\cdot C \\cdot M} \\sum_{i=1}^{C} \\sum_{i=1}^{M} ||a_{c,k,_i} - a_{i,k,m} ||^2$\nwhere, $||a_{c,k,_i} - a_{i,k,m} ||^2$ denotes the squared Euclidean distance between the attention map $a_{c,k,_i}$ of the considered training sample and $a_{i,k,m}$ being an item of the buffer A.\nThe selection of samples for the attention buffer A by each client is based on the assumption that each local model should share its most confident predictions and indicate the image regions it focuses on. We use uncertainty scores from our evidential learning approach to guide the selection of attention maps for sharing within the federation. Specifically, we compute uncertainty scores, $u_j^{(k)}$, for each sample in class k, where j ranges from 1 to $N^{(k)}$, the total number of samples in class k. From these, we select the M samples with the lowest uncertainty scores, denoted as ${u_1^{(k)}, u_2^{(k)}, ..., u_M^{(k)}}$, and corresponding attention maps for inclusion in our uncertainty-aware attention buffer, A, replacing older ones."}, {"title": "4 Experimental results", "content": "We validate the effectiveness of our proposed method on a multicenter dataset of 23,247 dermoscopic images of nine skin lesions from different populations and medical centers, based on the ISIC2019 dataset Combalia et al. [2019], Codella et al. [2018], Tschandl et al. [2018]. To carry out federated learning, we organized the dataset into six nodes, with each node representing data from a specific source: Client C1 contains the BCN20000 dataset\nas described by Combalia et al. Combalia et al. [2019], which includes 19,424 images from the Hospital Cl\u00ednic in Barcelona; Clients C2, C3 and C4 are from the Austrian portion of the HAM10000 dataset Tschandl et al. [2018], with images from the ViDIR Group at the Department of Dermatology at the Medical University of Vienna; Client C5 is also part of the HAM10000 dataset and contains the Rosendahl image set from the University of Queensland in Australia; while client C6 includes the MSK4 dataset Codella et al. [2018]. The overall dataset\nexhibits heterogeneity in both the number of images contributed by each client as well ass in the distribution of classes, as illustrated in Fig. 2, making it a strong real-world use case for testing federated learning methods. For this study, we will focus on the binary classification task of distinguishing Melanocytic nevus from other skin lesions.\nTraining procedure In our setup, for each client, data is divided into a 75% training and 25% test split. Training is executed over 5 communication rounds, with 15 training epochs per round. Our model architecture employs a frozen ViT backbone augmented with additional parameters for b-prompts, t-prompts, and a classification-head. The ViT backbone specifications include an embedding dimension of 384, 6 attention heads, 12 blocks, and an input size of 224x224 pixels. For the b-prompts and t-prompts, the prompt keys (k and v) have a sequence length of 50, while l is 3 out of the 12 attention layers. We set the learning rates $\\mu_1$ and $\\mu_2$ to 2.5e \u2013 4 and 5e \u2013 4 respectively, with a weight decay factor of le - 2. Additionally, each client contributes 5 attention rollout maps per class (i.e., M in Eq. 6) to the uncertainty-aware attention buffer. Results are presented as in terms of balanced accuracy on the test set at the conclusion of all rounds.\nResults. In Table 1, we present a comprehensive performance comparison between FedEvPrompt and existing federated learning methods. FedAvg McMahan et al. [2017] serves as our baseline. FedAvgPers builds upon FedAvg by integrating a personalization step through local data fine-tuning, aligning with our emphasis on personalized learning via b-prompts and t-prompts tuning. Additionally, we incorporate FedProx Li et al. [2020], specifically tailored to address non-IID data like our skin lesion dataset.\nGiven that our approach employs knowledge distillation without parameter sharing, we include two analogous methods in our analysis: FedProto Tan et al. [2022] and FedDistill Seo et al. [2022]. We also evaluate the performance of local training, where client models are trained independently without parameter sharing, using both sets of prompts (i.e., (b, t)prompts), and using only one set of prompts (gprompts - general prompts) across all attention layers. We define g-prompts = [b-prompts, t-prompts] with both learning rates set to $\\mu_1$. This evaluation aims to validate our choice to apply different parameters across different attention layers and to demonstrate the advantages provided by our federated learning approach.\nResults show that FedEvPrompt outperforms its competitors, including those that share parameters (thus being less privacy-preserving), such as FedAvg McMahan et al. [2017] and FedProx Li et al. [2020]. Notably, when comparing FedEvPrompt performance with other methods that do not share parameters, namely FedProto Tan et al. [2022] and FedDistill Seo et al. [2022], we observe higher performance across all clients and a lower standard deviation, indicating better convergence in accuracy among clients.\nWe finally conducted an ablation study to assess the impact of various prompting options and sharing strategies among nodes within the federation. It's worth noting that while prompt sharing may potentially compromise privacy guarantees, exploring its effectiveness compared to using private prompts and our proposed knowledge distillation approach is interesting.\nTo this end, we initially assessed the performance of a variant of FedAvg where only low-level b-prompts are shared, gradually incorporating t-prompts and knowledge distillation on the uncertainty-aware attention buffer. Furthermore, we examined the variant of the proposed prompting strategy using a single set of general prompts g-prompts shared between nodes and coupled with our knowledge distillation method. Our findings, outlined in Table 2, underscore the significance of separate prompt learning, as evidenced by the subpar performance of the g-prompts variants. Interestingly, sharing separate sets of b-prompts and t-prompts (first two rows of Tab. 2) proved less effective than keeping them private and employing knowledge distillation (best performance observed in the last two rows of the same table). Moreover, we demonstrate that our strategy of incorporating attention maps based on uncertainty scores (as detailed in Sect. 3.2) yields superior performance compared to random selection of buffer samples. These two last considerations highlight"}, {"title": "5 Conclusion", "content": "This work introduces FedEvPrompt, a new federated learning approach tailored for skin lesion classification using the ISIC2019 dataset. Indeed, this dataset offers a realistic setting for evaluating federated learning methods, eliminating the need for simulated distributions. FedEvPrompt seamlessly integrates evidential deep learning, prompt tuning, and knowledge distillation within a vision transformer architecture. Knowledge distillation on attention maps, in particular, ensures better privacy-preserving capabilities than parameter sharing. In addition to its superior performance in addressing data heterogeneity and privacy concerns, the employment of evidential learning offers enhanced model interpretability and uncertainty quantification, providing valuable insights for decision-making in medical image analysis. Balancing vacuity and dissonance Josang et al. [2018], Guo et al. [2022] in buffer selection warrants further research to comprehensively understand underlying mechanisms."}]}