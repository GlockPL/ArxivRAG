{"title": "Enhancing Depression Detection with Chain-of-Thought Prompting: From Emotion to Reasoning Using Large Language Models", "authors": ["Shiyu Teng", "Jiaqing Liu", "Rahul Kumar Jain", "Shurong Chai", "Ruibo Hou", "Tomoko Tateyama", "Lanfen Lin", "Yen-wei Chen"], "abstract": "Depression is one of the leading causes of disability worldwide, posing a severe burden on individuals, healthcare systems, and society at large. Recent advancements in Large Language Models (LLMs) have shown promise in addressing mental health challenges, including the detection of depression through text-based analysis. However, current LLM-based methods often struggle with nuanced symptom identification and lack a transparent, step-by-step reasoning process, making it difficult to accurately classify and explain mental health conditions. To address these challenges, we propose a Chain-of-Thought Prompting approach that enhances both the performance and interpretability of LLM-based depression detection. Our method breaks down the detection process into four stages: (1) sentiment analysis, (2) binary depression classification, (3) identification of underlying causes, and (4) assessment of severity. By guiding the model through these structured reasoning steps, we improve interpretability and reduce the risk of overlooking subtle clinical indicators. We validate our method on the E-DAIC dataset, where we test multiple state-of-the-art large language models. Experimental results indicate that our Chain-of-Thought Prompting technique yields superior performance in both classification accuracy and the granularity of diagnostic insights, compared to baseline approaches.", "sections": [{"title": "I. INTRODUCTION", "content": "Depression is one of the most prevalent and severe mental health disorders worldwide, posing significant challenges to both individuals and society [1]. According to the World Health Organization, it is a leading cause of disability and a major contributor to the global burden of disease. The high prevalence of depression and its strong link to suicide highlight the urgent need for early detection and intervention [2]. In recent years, advancements in artificial intelligence have opened new possibilities for identifying depression through linguistic patterns. Large Language Models (LLMs), such as ChatGPT [3] and DeepSeek [4], have shown strong capabilities in capturing semantic and contextual nuances. By leveraging these models' deep understanding of language, early signs of depression can be detected more accurately, facilitating timely psychological support and treatment.\nDespite their potential, current LLM-based approaches to mental health analysis have notable limitations. Most existing methods rely on direct classification frameworks, mapping text to diagnostic labels or inferred reasoning outcomes [5]. However, this end-to-end approach presents three key challenges in clinical practice. First, these models lack explicit reasoning about symptoms, making their decision process less interpretable and failing to meet the medical standard of auditability [6]. Second, holistic text processing often overlooks crucial depressive symptoms that require structured linguistic analysis. For example, anhedonia (loss of pleasure) is frequently expressed through negated positive affect rather than direct negative statements. Clinical linguistics studies indicate that phrases like \u201cI try to enjoy hobbies but feel nothing\" or \"Family gatherings should be fun, yet they feel meaningless\" contain two diagnostic cues: (1) an implicit expectations of positive experiences (\"enjoy,\u201d \u201cfun\u201d), and (2) contextual negation (\u201cbut feel nothing,\u201d \u201cyet meaningless\u201d). Identifying such patterns requires structured evaluation, yet current LLMs struggle with this task [7]. Third, existing models conflate symptom identification with severity assessment, whereas in clinical practice, these should be separate processes. Symptom detection is best handled as a binary classification task, while severity assessment requires both multi-class classification and regression [8]. These limitations reduce diagnostic precision and hinder clinical adoption.\nRecent advancements in Chain-of-Thought (CoT) reasoning have significantly improved LLMs' ability to analyze complex mental health assessments [9]. Models such as GPT-01 [3], DeepSeek R1 [4], and QwQ [10] have demonstrated notable improvements in capturing nuanced psychological cues by breaking down reasoning into explicit, interpretable steps. This structured approach aligns closely with clinical diagnostic workflows, where mental health professionals assess depression through systematic evaluations rather than direct label assignment. To address the aforementioned challenges, we propose a CoT prompting strategy that transitions from emotion analysis to causal reasoning, mimicking both CoT-based LLM reasoning and clinical diagnostic procedures. Our method follows a structured process: first, the model identifies emotional expressions indicative of depression, such as anhedonia or hopelessness. Next, it performs a binary classification to determine whether depressive tendencies are present. Based on the detected emotional cues, the model then conducts causal reasoning to explore potential psychological or social factors contributing to the condition. Finally, it combines all extracted information to assess depression severity, ensuring a structured and interpretable evaluation aligned with clinical standards. We evaluated our emotion-to-reasoning CoT framework on the E-DAIC dataset [11], which consists of clinical interviews annotated with depression severity levels. Our experiments compared three configurations: (1) standard LLMs (e.g., GPT-40 [3], Qwen2.5-Max [10]), (2) CoT-enhanced LLMS (e.g., DeepSeek-R1 [4], GPT-01 [3], GPT-03-mini [3], QWQ [10]), and (3) our structured CoT approach applied to both standard and CoT-enhanced LLMs. Results indicate that our structured CoT approach not only achieves higher accuracy but also provides richer diagnostic explanations compared to both standard and CoT-enhanced LLMs.\nOur contributions can be summarized as follows:\n\u2022 We conduct comprehensive benchmarking of several state-of-the-art LLMs for depression detection, revealing significant performance variations and establishing crucial baselines for model selection in clinical applications.\n\u2022 We propose a novel CoT prompting strategy that decomposes the depression detection task into four structured stages: sentiment analysis, binary classification, underlying cause identification, and severity assessment. This structured approach not only mimics the clinical diagnostic process but also enhances interpretability and transparency by explicitly guiding the model through each reasoning step.\n\u2022 Experimental results on the E-DAIC dataset demonstrate that our CoT prompting technique outperforms traditional methods in both classification accuracy and the granularity of diagnostic insights, highlighting its potential for clinical applications in mental health assessments."}, {"title": "II. METHODOLOGY", "content": "Our Chain-of-Thought (CoT) prompting framework decomposes depression detection into four sequential reasoning stages, as shown in Figure 2. The pipeline processes input text through:\n1) Emotion Analysis: Identifying emotion type, intensity, polarity, and source.\n2) Binary Classification: Determining whether the individual is classified as Depressed or Not Depressed.\n3) Reasoning Analysis: Identifying factors contributing to depression or mental well-being.\n4) Severity Assessment: Calculating the PHQ-8 Score and assessing depression severity."}, {"title": "A. Stage 1: Emotion Analysis", "content": "The initial stage employs a structured approach to extract detailed emotional signals. This includes identifying the type of emotion (e.g., sadness, guilt, hope), its intensity (low, medium, or high), its polarity (positive, negative, or neutral), and its source (internal thoughts, external events, relationships, or health). By capturing these emotional indicators, including subtle expressions such as anhedonia through negated positives (e.g., Family gatherings should be fun, yet...), the system can provide a comprehensive emotional profile of the input text."}, {"title": "B. Stage 2: Binary Classification", "content": "Using the emotional features extracted in Stage 1, we prompt the LLM to determine depression likelihood:\n$P(depression|s) = f_\\theta(s, E_{emotion}),$\nwhere s represents the input text and $E_{emotion}$ represents extracted emotional features. The classification follows PHQ-8 clinical guidelines [12] to categorize the individual as Depressed or Not Depressed."}, {"title": "C. Stage 3: Reasoning Analysis", "content": "For individuals classified as Depressed, the system activates causal reasoning is activated to determine underlying contributing factors. Conversely, for non-depressed cases, the system identifies protective factors contributing to mental well-being.\nIf the individual is classified as Depressed, potential contributing factors are identified across multiple dimensions:\n\u2022 Social factors such as isolation, conflict, or lack of support\n\u2022 Biological factors including sleep disturbances, appetite changes, and fatigue\n\u2022 Psychological factors like guilt, worthlessness, and negative self-perception\nFunctional impairment affecting work, relationships, and daily activities\nA ranked list of depressive factors is generated, supported by textual evidence.\nIf the individual is classified as Not Depressed, the system identifies positive influences and protective factors, such as:\n\u2022 Social support systems and fulfilling relationships\n\u2022 Psychological resilience, coping mechanisms, and self-esteem\nHealthy habits including consistent sleep, balanced nutrition, and exercise"}, {"title": "D. Stage 4: Severity Assessment", "content": "Using insights from the previous stages, we determine depression severity based on PHQ-8 scoring. The PHQ-8 score ranges from 0 to 24 and is categorized as follows:\n\u2022 Minimal: 0-4\n\u2022 Mild: 5-9\n\u2022 Moderate: 10-14\n\u2022 Moderately Severe: 15-19\n\u2022 Severe: 20-24\nThe final output provides both the PHQ-8 score and the corresponding depression severity category, ensuring a quantitative evaluation aligned with clinical standards for diagnosis"}, {"title": "III. EXPERIMENTS", "content": "The Extended Distress Analysis Interview Corpus (E-DAIC) dataset [11] consists of audiovisual recordings of clinical interviews designed for depression detection, where a virtual agent conducts interviews to minimize human interaction bias. It includes text, acoustic, and visual modalities, with samples annotated using PHQ-8 scores (0-24) to indicate depression severity. The dataset is divided into 163 training, 56 validation, and 56 test samples, as detailed in Table I. In our experiments, we utilize only the text modality, focusing on linguistic cues for depression assessment."}, {"title": "B. Evaluation Metrics", "content": "In this study, we adopt two primary metrics to assess the performance of our regression model in predicting depression severity: the concordance correlation coefficient (CCC) and the mean absolute error (MAE). The CCC [13] is a prevalent measure in depression detection research, as it evaluates how well the predicted scores align with the true depression severity ratings. It is defined as:\n$CCC = \\frac{2S_{\\hat{y}y}}{s_{\\hat{y}}^2 + s_{y}^2 + (\\bar{\\hat{y}} - \\bar{y})^2},$\nwhere $\\bar{y}$ and $\\bar{\\hat{y}}$ are the mean values of the predictions and the ground truth, respectively; $s_{y}^2$ and $s_{\\hat{y}}^2$ denote their variances; and $s_{\\hat{y}y}$ represents the covariance between them. The CCC value ranges between -1 and 1, with -1 indicating complete disagreement and 1 indicating perfect agreement. Furthermore, we use the mean absolute error (MAE) to quantify the average prediction error. The MAE is given by:\n$MAE = \\frac{1}{N} \\sum_{i=1}^{N} |\\hat{y}_i - y_i|,$\nwhere N is the total number of samples, $\\hat{y}_i$ is the predicted score for the ith sample, and yi is the corresponding true score."}, {"title": "C. Experiment Results", "content": "Table II presents the performance comparison of our proposed CoT prompting approach with existing state-of-the-art methods on the E-DAIC test set. The results are evaluated using the CCC and MAE, where higher CCC and lower MAE values indicate better performance. Among the traditional multimodal approaches, CubeMLP [14] and MIMRL [15] achieved competitive results, with CCC scores of 0.583 and 0.580, respectively, and MAE values of 4.37 and 4.36, respectively. These methods leverage advanced deep learning architectures for multimodal fusion but still exhibit limitations in capturing nuanced linguistic cues associated with depression.\nIn contrast, LLMs demonstrate a significant improvement in performance compared to traditional multimodal methods, particularly when integrated with our CoT prompting strategy. Among the standard LLMs, DeepSeek V3 [4] achieves a CCC of 0.622 and an MAE of 4.15, already surpassing previous multimodal deep learning approaches. Similarly, Qwen2.5-Max [10] further improves upon this, achieving a CCC of 0.637 and an MAE of 4.07. GPT 40 [3] exhibits the highest performance among standard LLMs, reaching a CCC of 0.732 and the lowest MAE of 3.37.\nWhen applied to LLMs with inherent CoT reasoning capabilities, our prompting strategy further enhances their interpretability and diagnostic comprehensiveness. For instance, GPT 03-mini [3] and GPT ol-preview [3] achieve CCC values of 0.677 and 0.690, respectively, demonstrating improved step-by-step reasoning and classification accuracy. Additionally, QwQ-32b-preview [10] and DeepSeek R1 [4] further improve CoT-based depression assessment, with DeepSeek R1 achieving a CCC of 0.708 and an MAE of 3.49, indicating the highest precision in depression severity estimation among the CoT-enhanced models. These results highlight the versatility of our Chain-of-Thought prompting approach, which benefits LLMs. Our method enables standard LLMs to adopt structured reasoning capabilities similar to CoT-enhanced models, leading to improved performance. For models that already possess CoT functionality, our prompting strategy improves their reasoning process. It helps them analyze emotional and causal factors in more detail. This results in a more comprehensive assessment of depression. By systematically guiding models through emotion analysis, depression classification, causal reasoning, and severity assessment, our method not only improves accuracy but also enhances interpretability, making it well-suited for clinical mental health assessment applications."}, {"title": "D. Ablation Study", "content": "Table III presents the results of our ablation studies, which evaluate the impact of incorporating our CoT prompting strategy on various LLMs. The table is divided into two groups: the upper group consists of standard LLMs that do not possess inherent CoT capability, while the lower group comprises models that already have inherent CoT functionality.\nFor the standard LLMs, our results clearly indicate that integrating CoT prompting substantially improves performance. Specifically, for Qwen2.5-Max [10], the application of CoT prompting increases the CCC from 0.55 to 0.637 and reduces the MAE from 4.33 to 4.07. Similarly, GPT 40 [3] exhibits an improvement in CCC from 0.696 to 0.732 and a reduction in MAE from 3.47 to 3.37 when CoT prompting is applied. These improvements suggest that our CoT prompting approach effectively equips standard LLMS with enhanced reasoning capabilities, leading to more precise depression severity estimation.\nFor LLMs that already possess inherent CoT capabilities, our method further refines their performance. As shown in the lower group, GPT 03-mini [3] benefits from an increase in CCC from 0.625 to 0.677 and a decrease in MAE from 3.84 to 3.68 with CoT prompting. Similarly, QwQ-32b-preview [10] improves its CCC from 0.597 to 0.705 and reduces its MAE from 4.23 to 3.55. These findings demonstrate that even for models with built-in CoT reasoning, our structured prompting strategy can further enhance their reasoning depth and diagnostic comprehensiveness.\nOverall, these ablation studies confirm that our CoT prompting strategy significantly bolsters the performance of LLMs in depression assessment tasks. It not only endows standard LLMs with advanced reasoning capabilities but also refines the thought process of CoT-enhanced models, resulting in improved accuracy and interpretability in clinical mental health assessments."}, {"title": "IV. CONCLUSION AND FUTURE WORK", "content": "In this work, we presented a novel CoT prompting strategy to improve depression detection using LLMs. Our method enhances both performance and interpretability. We decompose the depression detection task into four structured stages: emotion analysis, binary classification, causal analysis, and severity assessment. This structured approach follows the clinical diagnostic process. It provides detailed, step-by-step reasoning. Experimental results on the E-DAIC dataset show that our CoT approach performs better than traditional multimodal methods and standard LLMs. Models integrated with our CoT prompting strategy achieve higher Concordance Correlation CCC and lower MAE. These results highlight the benefits of structured reasoning. It helps capture nuanced linguistic cues related to depression. Ablation studies confirm that our method improves standard LLMs by adding advanced reasoning capabilities. It also refines the reasoning process of CoT-enhanced models. This leads to better diagnostic accuracy and interpretability.\nWhile our current study focuses solely on the text modality for depression assessment, recent advancements in large open-source models present exciting opportunities for incorporating multimodal data. In future work, we plan to extend our framework by integrating additional modalities such as audio and visual signals, which are known to carry rich emotional and behavioral cues. The fusion of multimodal information is expected to further enhance the accuracy and robustness of depression detection, providing a more comprehensive diagnostic tool that better reflects the complex nature of mental health."}]}