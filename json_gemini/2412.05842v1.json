{"title": "DREAM: Domain-agnostic Reverse Engineering Attributes of Black-box Model", "authors": ["Rongqing Li", "Jiaqi Yu", "Changsheng Li", "Wenhan Luo", "Ye Yuan", "Guoren Wang"], "abstract": "Deep learning models are usually black boxes when deployed on machine learning platforms. Prior works have shown that the attributes (e.g., the number of convolutional layers) of a target black-box model can be exposed through a sequence of queries. There is a crucial limitation: these works assume the training dataset of the target model is known beforehand and leverage this dataset for model attribute attack. However, it is difficult to access the training dataset of the target black-box model in reality. Therefore, whether the attributes of a target black-box model could be still revealed in this case is doubtful. In this paper, we investigate a new problem of black-box reverse engineering, without requiring the availability of the target model's training dataset. We put forward a general and principled framework DREAM, by casting this problem as out-of-distribution (OOD) generalization. In this way, we can learn a domain-agnostic meta-model to infer the attributes of the target black-box model with unknown training data. This makes our method one of the kinds that can gracefully apply to an arbitrary domain for model attribute reverse engineering with strong generalization ability. Extensive experimental results demonstrate the superiority of our proposed method over the baselines.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, machine learning technology has been widely used in in many tasks such as NLP and areas such as image classification [1]\u2013[4], natural language processing [5]\u2013[8], and speech recognition [9], [10]. However, existing machine learning frameworks are complicated, which requires substantial computational resources and efforts for users to train and deploy, especially for the non-expert ones. As a result, with the benefits of usability, and cost efficiency, Machine Learning as a Service (MLaaS) has become popular. MLaaS deploys well-trained machine learning models on cloud platforms, allowing users to interact with these models via the provided APIs, making advanced ML capabilities both accessible and affordable.\nGenerally speaking, the machine learning service deployed on the cloud platform is a black box, where users can only obtain outputs by submitting inputs to the model. The model's attributes such as architecture, training set, and training method, are concealed by the provider. However, a question remains: is the deployment safe? Once the attributes of a model are revealed by an adversary, a black-box model becomes a white-box model, introducing significant security threats. On one hand, white-box models are more vulnerable to various types of attacks compared to black-box models such as adversary example attacks [11]\u2013[15] and model extraction attacks [16]\u2013[19]. Specifically, adversaries train adversarial examples on a surrogate model with the intention of transferring these examples to the target model. Research shows that the transferability of adversarial samples increases if the the surrogate architecture is similar to the target model [20]. In this context, model reverse engineering becomes a powerful tool for adversaries to select a surrogate model. In addition, model extraction attacks aims to extract the functionality of a target black-box model in a surrogate model. Research shows that better extraction performance is achieved when the surrogate model closely resembles the target black-box model [21]. Therefore, model reverse engineering can provide significant insights for selecting the architecture of the surrogate model for the extraction. On the other hand, intellectual property is jeopardized. After adversaries reveal the attributes of the model, they may replicate a model with similar capabilities for commercial purposes, potentially causing indirect economic losses.\nThe work in [22] delves into model reverse engineering to reveal model attributes, as depicted in the left of Fig. 1. They first construct a large set of white-box models which are trained based on the same datasets as the target black-box model, e.g., the MNIST hand-written dataset [23]. Then, the outputs of white-box models are obtained through a sequence of input queries. Finally, a meta-model is trained to learn a mapping between model outputs and model attributes. For inference, outputs of the target black-box model are fed into the meta-model to predict model attributes. The promising results demonstrate the feasibility of model reverse engineering.\nHowever, a crucial limitation in [22] is that they assume the dataset used for training the target model to be known in advance, and leverage this dataset for meta-model learning. In most application cases, the training data of a target black-box model is unknown. When the distribution of training data of the target black-box model is inconsistent with that of the set of constructed white-box models, the meta-model is usually unable to generalize well on the target black-box model.\nTo verify this point, we train three black-box models with the"}, {"title": "II. RELATED WORKS", "content": "Reverse Engineering of Model Attributes. Its goal is to reveal attribute values of a target model, such as model structure, optimization method, hyperparameters, etc. Current research efforts focus on two aspects, hardware [32]\u2013[34] and software [22], [35]\u2013[37]. The hardware-based methods utilize information leaks from side-channel [32], [33] or unencrypted PCIe buses [34] to invert the structure of deep neural networks. Software-based methods reveal model attributes by machine learning. [35] steals the trade-off weight of the loss function and the regularization term. They derive over-determined linear equations and solve the hyperparameters by the least-square method. [37] theoretically proves the weight and bias can be reversed in linear network with ReLU activation. [38] infers hyperparamters and loss functions of generative models through the generated images. KENNEN [22] prepares a set of white-box models and then trains a meta-model to build a mapping between model outputs and their attributes. It is the most related work to ours. However, a significant difference is that KENNEN [22] requires the data used to train the target black-box model to be given beforehand. Our method relaxes this condition, i.e., we no longer require the training data of the target model to be available, which is a more practical problem.\nModel Functionality Extraction. It aims to train a clone model that has similar model functionality to that of the target model. To achieve this goal, many works have been proposed in recent years [16], [18], [19], [39]\u2013[42]. [39] uses an alternative dataset collected from the Internet to query the target model. [40] assumes part of the dataset is known and then presents a dataset augmentation method to construct the dataset for querying the target model. Moreover, data-free extraction methods [40]\u2013[43] query a target model through data generated by a generator, without any knowledge about the training data distribution. Different from the methods mentioned above, our goal is to infer the attributes of a black-box model, rather than stealing the model function.\nMembership Inference. Its goal is to determine whether a sample belongs to the training set of a model [44]\u2013[51]. Although inferring model attribute is different from the task of membership inference, the technique in [22] is similar to those of membership inference attack. However, as stated aforementioned, when the domain of training data of the target black-box model is inconsistent with that of the set of white-box models, the method is usually unable to generalize well because of the OOD problem.\nOut-of-distribution Generalization. Machine learning mod-els often suffer from performance degradation during testing when the distribution of the training data (i.e., the source domains) differs from the test data distribution (i.e., the target domain). This is an out-of-distribution (OOD) problem. [25]. One straightforward approach is to leverage data from target domain to adapt the model trained on the source domains. This method is known as OOD adaptation, which has been successfully applied in image and video related tasks [52]\u2013[55]. However, in many application scenarios, data from the target domain is difficult to obtain. Therefore, OOD generalization methods are introduced [56]\u2013[60], aiming to train a model by utilizing data from several source domains so that it can generalize well to any unseen OOD target domain. Existing OOD generalization methods mainly fall into three categories: invariant learning [28]\u2013[30], [61], [62], causal learning [63]\u2013[66], and stable learning [67]\u2013[70]. Invariant learning seeks to minimize the differences among source domains to learn domain-invariant representations. Causal and stable learning aim to identify causal features linked to ground-truth labels from the data and filter out features unrelated to the labels. The former ensures the invariance of existing causal features, while the latter emphasizes effective features strongly related to labels by reweighting attention. Since the above methods primarily focus on images or videos, the design of an effective OOD learning method for attribute inference of black-box models has not been explored so far."}, {"title": "III. PROPOSED METHODS", "content": "In this section, we first introduce techinical background, threat model and problem formulation in Sect. III-A. Next, we describe the overall framework of our proposed DREAM in Sect. III-B. Subsequently, we delve into each components of DREAM in Sect. III-C to III-E. Finally, we introduce the training procedure in Sect. III-F.\nA. Preliminaries\nWe first introduce the background of the KENNEN method. Based on KENNEN, we present the threat model of the problem addressed in this paper. Finally, we introduce the problem formulation.\nBackground of KENNEN [22]. Given a black-box model B, model attribute reverse engineering in [22] aims to build a meta-model \u03a6: \u039f \u2192 Y, where O = B(Q) is the outputs by querying the black-box model with queries Q, and A is the set of model attributes including model architecture, optimizer, and training hyperparameters, etc. Concretely, they first construct a large set of white-box models F containing different attributes combinations and train these white-box models based on the same training data $D_{as}$ that of the target black-box model. Then outputs O are obtained by querying these white-box models with a sequence of input image queries Q. Finally, they train a meta-model I to build mappings from outputs O to model attributes Y = {y|k = 1...\u039a, \u03c5 = 1...Nk}, where the subscript k represents the type of attributes (e.g., Activation, Dropout), while the superscript v represents the value of the attributes (e.g., ReLU/Tanh for Activation, Yes/No for Dropout). At the inference phase, the meta-model takes outputs from the target model as input and predicts the corresponding attributes.\nThreat Model. Following KENNEN, we assume that attackers are permitted to query the model and can only access the probability outputs of the model, while attributes such as model structures and optimizers are unable to access. However, KENNEN makes a strong assumption that the training dataset of the model is known. In most cases, obtaining the training dataset is typically challenging. Therefore, we relax this assumption and consider a scenario where only the label space of the black-box model are known. This is a reasonable assumption because a black-box model deployed on the cloud platform typically provides information about its functionality and the categories it can output. Consequently, we can collect data with overlapping label spaces with the black-box target model. This overlap ensures that the outputs of the white-box models include similar information with those of the black-box model to some extent, thereby assisting in learning informative invariant features for achieving attributes reverse engineering.\nProblem Formulation. As aforementioned, there is a strict constraint in [22] that they assume the training dataset D of the target model to be given in advance, and leverage model outputs O, where the models are trained on D for the learning of meta-model . It is difficult to access the training data of a target black-box model, which significantly limits the applications of [22]. To mitigate this problem, we provide a new problem setting by relaxing the above constraint, i.e., we no longer require the training data D of the target black-box model to be available, but only the label space of the black-box model. Consequently, we cast this problem as an OOD generalization problem. To address this, we first collect data {D}\u2081 from M different sources to train the white-box models. Although these data may contain different styles, all of them include an overlapping label space with the target black-box model. Then, the outputs obtained from the white-box models are divided into M source domains according to the source of the training data for each model. In addition, the outputs from black-box model are the target domain. Our goal is to leverage outputs from source domains to train a domain-agnostic meta model \u03a6 that can well generalize to the outputs target domain, thereby enabling it to predict attributes for the target black-box model B.\nB. DREAM Framework\nTo perform domain-agnostic black-box model attribute reverse engineering, we cast this problem into an OOD generalization learning problem, and propose a novel framework DREAM, as shown in Fig. 3. Our DREAM framework consists of two parts:\nIn the left part of Fig. 3, we employ datasets from different domains to train numerous white-box models with diverse attributes, thereby constructing modelsets. (please refer to Sect. IV-A for more details). Next, we sample queries as input to these models. For each domain, we sample an equal number of images from the corresponding dataset and concatenate them as a batch of queries. These queries are sent to models belonging to the modelsets. The resulting multi-domain outputs {O}M1 are fed into the subsequent module of our DREAM framework.\nTo learn domain-invariant features, we introduce a MDGAN, as shown in the right part of Fig. 3. MDGAN consists of multiple discriminators corresponding to different domains and one generator across multiple domains. The generator is designed to embed model outputs from different domains as features, while each discriminator strives to align the learned feature distributions from other domains with the feature distribution of the domain it corresponds to. In this way, the generator is capable of learning domain-invariant features. Based on the learned domain-invariant features, we further learn a domain-"}, {"title": "C. Multi-domain Outputs Obtaining", "content": "To achieve model reverse engineering, we first need to obtain the multi-domain outputs of the white-box models. These outputs serve as features of white-box models' attributes and will be used as inputs for the subsequent modules. We sample an equal number of images from the source dataset, resulting in queries Q = {q}_1, where N is the number of total queries. Subsequently, these queries are fed into the white-box models F = [f1, f2, ..., fM], where fi represents models from the ith domain. For each domain i, the models fi produces outputs {O}}_1 \u2208 RN\u00d7C, where C is the number of classes in the dataset. We then concatenate the outputs as an 1-dimensional vector O\u00b2 \u2208 RNC. Finally, the multi-domain outputs are derived as O = {0}\u2081."}, {"title": "D. Multi-Discriminator GAN", "content": "After preparing multi-domain outputs, we introduce MDGAN on the basis of [71]. The objective is to learn domain-invariant features from these probability outputs of white-box models trained on different domains.\nTo better present, we take an example about how MDGAN works on two domains. As shown in Fig. 4, we have two kinds of inputs, O\u00b9 and O2, from two domains. When feeding them into the generator G, we can obtain the corresponding features z\u00b9 and z2, respectively. After that, we feed z\u00b9 and z\u00b2 to the discriminator D1, where D\u2081 is expected to output a \"real\" label for z\u00b9 and output a \u201cfake\u201d label for z\u00b2. By jointly training G and D\u2081 based on a min-max optimization, the distribution of z2 is expected to move towards that of z\u00b9. In the meantime, we also feed z\u00b9 and z2 to the discriminator D2. Differently, D2 is expected to output a \u201creal\u201d label for z\u00b2 and output a \u201cfake\u201d label for z\u00b9. By jointly training G and D2, the distribution of z\u00b9 is expected to move towards that of z2. In this way, z\u00b9 and z2 generated by the generator G become domain-invariant representations.\nFormally, we define G(O\u00b2;09) : O\u00b2 \u2192 z. The generator G sharing with parameter og across domains maps outputs O' from the ith domain into the latent feature z\u00b2. After that, we obtain latent features {z}M\u2081 of model outputs. We also define M discriminators {Di (z\u00b2; 0)}}\\1. Each discriminator Di (zi) : zi \u2192 [0,1] outputs a scalar representing the probability that z\u00b2 comes from the jth domain. The label of latent features z\u00b2 is defined as Real for the discriminator $D_{i}(z_{i})$ when j = i, while False when j \u2260 i.\nThe training goal of Di is to maximize the log probability of assigning the correct label to features both from the ith domain and other domains, while the generator G is trained against the discriminator to minimize the probability. In other words, it is a min-max game between the jth discriminator Di and generator G with a value function V, formulated as:\n$ \\underset{G}{min} \\,\\underset{D_{i}}{max} V (D^{i}, G) = \\mathbb{E}_{x \\sim 0^{i}} [logD_{i} (G(x))] + \\sum_{j \\neq i} \\mathbb{E}_{x \\sim 0^{j}} [log(1 - D^{i} (G(x)))].$ (1)\nDuring optimizing the min-max adversarial value function for G and Di, the generator G can gradually produce latent features zi from jth domain, which are close to latent features from other domain. Once G and all D are well trained, G is able to embed multi-domain model outputs into an invariant feature space, where each discriminator cannot determine which domain the outputs are from. Therefore, the latent features {z}M\u2081 become domain-invariant features. Note that our proposed MDGAN does not suffer from mode collapse. This is because mode collapse is an issue in generative tasks using GANs, where the model fails to generate diverse patterns and instead produces only a limited set of modes. In our approach, the role of generator G in the MDGAN is not to generate diverse features. Instead, G functions as an encoder, encoding the model's outputs from different domains into invariant features. Therefore, it does not suffer from the problem of mode collapse."}, {"title": "E. Domain-agnostic Reverse Meta-Model", "content": "After obtaining domain-invariant features {z}M\u2081, we aim to classify them as model attributes Y through the domain-agnostic reverse meta-model. Consider there are K types of at-tributes and each attribute contains Nk possible values, we build K domain-agnostic reverse meta-models \u03a6 = {1, 2, ..., \u03a6\u039a }.\nTherefore, the probability pk(z) for the kth attribute is obtained by:\n$p_{k} (z) = softmax(\\phi_{k}(z)).$ (2)\nNote that the pk(z) is a Nk-dimensional vector that contains Nk attribute value, and each dimension represents the proba-bility of the attribute value.\nThe target is to minimize the cross entropy between the predicted attributes probability pk (z) and ground-truth of model attribute values yk:\n$ \\underset{\\Phi}{min} \\sum_{k=1}^{K} \\mathbb{E}_{z\\sim \\{z_{i}\\}} [-y log(p_{k}(z))].$ (3)\nDuring the inference phase, we input queries to the black-box model trained from an unknown domain to generate outputs. These outputs are then embedded as domain-invariant features by the generator G. Subsequently, the reverse meta-model \u03a6 classifies these domain-invariant features, achieving domain-agnostic attributes predictions for the black-box model."}, {"title": "F. Overall Objective and Training Strategy", "content": "After introducing all the components, we give the final loss function based on Eq. 1 and 3 as:\n$\n\\underset{G, D^{i}, 1<j<M}{min}\\,\\underset{G, D^{i}, 1<j<M}{max}\\ V(D^{i},G) = \\mathbb{E}_{x \\sim 0^{i}} [logD_{i} (G(x))] + \\sum_{j \\neq i} \\mathbb{E}_{x \\sim 0^{j}} [log(1 - D^{i} (G(x)))] + \\sum_{k=1}^{K} \\mathbb{E}_{z\\sim \\{z_{i}\\}} [-y log(p_{k}(z))].$\n(4)\nwhere X is a trade-off parameter.\nThe training strategy is as follows: we first optimize all discriminators D\u00b2, and then jointly optimize the generator and the domain-agnostic reverse meta-model. We repeat the above processes until the algorithm converges. The proposed optimization strategy is presented in Algorithm 1."}, {"title": "IV. EXPERIMENTS", "content": "A. Dataset Construction\nFollowing [22], we construct the modelset by training models that enumerate all possible attribute values. The details of the attributes and their values are shown in Table I. There are a total of K = 9 types of attributes for each model in the modelsets, which adheres the following scheme: N = {2, 3, 4}"}, {"title": "V. LIMITATIONS AND FUTURE WORKS", "content": "DREAM requires training white-box models with numerous attribute combinations to ensure the performance of reverse engineering, which costs significant computational resources. For instance, when constructing the PACS modelset, each model requires approximately 5 minutes of training time. Consequently, the total training time for 13,000 models (10,000 for training, 2,000 for validation, and 1,000 for testing) amounts to roughly 45 GPU-days. To reduce these costs, one plausible approach is to leverage fewer white-box models for reverse engineering. Considering the relationships among attributes, we can design a multi-task learning method, where reverse engineering each attribute is treated as a task, to maintain the performance in the future."}, {"title": "VI. CONCLUSION", "content": "In this paper, we studied the problem of domain-agnostic reverse engineering towards the attributes of the black-box model with unknown traning dataset, and cast it as an OOD generalization problem. We proposed a generalized framework, DREAM, which can predict the attributes of a black-box model with an unknown domain, and explored to learn domain-invariant features from probability outputs in the scenario of black-box attribute inference. Extensive experimental results demonstrated the effectiveness of our method."}]}