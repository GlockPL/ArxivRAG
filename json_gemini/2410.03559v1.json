{"title": "Optimizing food taste sensory evaluation through neural network-based taste electroencephalogram channel selection", "authors": ["Xiuxin Xia", "Qun Wang", "He Wang", "Chenrui Liu", "Pengwei Li", "Yan Shi", "Hong Men"], "abstract": "The taste electroencephalogram (EEG) evoked by the taste stimulation can reflect different brain patterns and be used in applications such as sensory evaluation of food. However, considering the computational cost and efficiency, EEG data with many channels has to face the critical issue of channel selection. This paper proposed a channel selection method called class activation mapping with attention (CAM-Attention). The CAM-Attention method combined a convolutional neural network with channel and spatial attention (CNN-CSA) model with a gradient-weighted class activation mapping (Grad-CAM) model. The CNN-CSA model exploited key features in EEG data by attention mechanism, and the Grad-CAM model effectively realized the visualization of feature regions. Then, channel selection was effectively implemented based on feature regions. Finally, the CAM-Attention method reduced the computational burden of taste EEG recognition and effectively distinguished the four tastes. In short, it has excellent recognition performance and provides effective technical support for taste sensory evaluation.", "sections": [{"title": "1. Introduction", "content": "Brain activity can be measured using electrocorticography, electroencephalography (EEG), and functional near-infrared spectroscopy (Scholkmann et al., 2014; Thut & Miniussi, 2009; Todaro et al., 2019). The above methods explore the relationship between brain activity, behavior, and psychology by converting neural activity into processable signals. Among them, EEG has been widely used in neuroscience research (Kroupi et al., 2015), disease treatment (Chaudhary et al., 2016), brain-computer interface (Hsu, 2011; Zhang et al., 2018), and other fields (Xia et al., 2023a; Xia et al., 2023b) due to its low cost and high portability.\nFood sensory evaluation involves psychology, physiology, and statistics (Vivek et al., 2020), and the evaluation aspects mainly include color, smell, and taste. Among them, food taste is a significant factor. However, most sensory evaluations of food taste currently rely on artificial sensory evaluation and machine perception, which have significant limitations. In artificial sensory evaluation, the results are highly subjective, leading to poor experiment reliability and difficulty reproducing (Espinoza Mina & Gallegos Barzola, 2018). In machine perception, such as electronic tongues, it is challenging to meet the needs of different types of new products due to the limitation of the type and number of sensors (Zheng et al., 2022). Taste EEG can objectively reflect a series of psychological and physiological activities of people after tasting taste, which includes taste information and human sensory perception. It is more objective than artificial sensory evaluation and flexible than machine perception. Therefore, taste EEG has unique advantages for taste sensory evaluation (Xia et al., 2024a). In some related studies, Crouzet et al. decoded the taste EEG of salt, sweet, sour, and bitter through multivariate pattern analysis (Crouzet et al., 2015).\nHashida et al. distinguished the difference between sweet, salty, and water using EEG features extracted by adaptive Gabor transform (Hashida et al., 2005). Domracheva et al. used taste EEG and visual EEG to assess different products' similarities (Domracheva & Kulikova, 2020). Chandran et al. took EEG's mean, median, and power spectral density as features and used support vector machines to classify salt, sweet, sour, and bitter (Chandran & Perumalsamy, 2023). However, most taste EEG recognition uses the traditional machine learning method with manual feature extraction, which reduces recognition efficiency. In addition, the recognition effect largely depended on the extracted features, which made the model less adaptive.\nConvolutional neural networks (CNN) have been widely used in EEG decoding, image recognition, and natural speech processing due to their strong spatial feature extraction ability and end-to-end processing flow (Li et al., 2024; Liu et al., 2021; Wang et al., 2024a; Xia et al., 2024b). It has gradually developed from simple models such as early LeNet5 (LeCun et al., 1998) and AlexNet (Krizhevsky et al., 2017) to deeper network layers and more complex network structures to mine the feature information in the data (He et al., 2016; Simonyan & Zisserman, 2014; Szegedy et al., 2016). Deep CNN can extract global and high-level features in deeper layers after extracting local low-level features from EEG data. Therefore, the application of deep CNN in complex EEG tasks is gradually increasing (Lawhern et al., 2018; Schirrmeister et al., 2017). However, the increase in network complexity also inevitably results in information redundancy. Attention mechanisms can better focus on important feature information while effectively ignoring redundant information, so it is widely used in CNN (He et al., 2021; Men et al., 2021; Wang et al., 2020; Woo et al., 2018). In EEG research, Li et al. proposed a multi-scale fusion convolutional neural network based on an attention mechanism to extract multi-scale spatiotemporal features in EEG signals and improve the network's sensitivity (Li et al., 2020). Zhang et al. integrated gender and age factors into a 1D"}, {"title": "2. Materials and methods", "content": null}, {"title": "2.1 Experimental and data", "content": null}, {"title": "2.1.1 Subjects", "content": "The research conformed to the revised Helsinki Declaration, and the program was approved by the Northeast Electric Power University Scientific Research Ethics and Science and Technology Safety and Committee. Before the experiment, 20 right-handed subjects (10 males and 10 females) aged between 20 and 30 were recruited by posting announcements in the school. All subjects had no neurological disease or dysgeusia. They all signed the informed consent form. On the day of the experiment, they were told to wash their hair and brush their teeth (odorless toothpaste) in the morning and not to eat (except water) for two hours before the experiment."}, {"title": "2.1.2 Materials and instrument", "content": "The four common food tastes, sour, sweet, bitter, and salty, were used as experimental materials to induce taste EEG. According to reference (Wallroth et al., 2018), the four taste solutions were prepared as follows: sour (0.075 g food grade citric acid dissolved in 100 ml distilled water, 0.039 M), sweet (15 g sucrose dissolved in 100 ml distilled water, 0.44 M), bitter (3 g bitter melon powder dissolved in 100 ml distilled water) and salty (3.8 g sodium chloride dissolved in 100 ml distilled water, 0.65 M), in addition, a 100 ml bottle of distilled water was prepared. In the pre-experiment, the prepared solution can be perceived by the subjects without causing them discomfort."}, {"title": "2.1.3 Taste EEG acquisition process", "content": "Before the experiment, the experimental samples were placed in 250 ml sampling bottles and heated to 37.5 \u00b0C. The laboratory temperature was controlled at 21 \u00b1 2 \u00b0C and ensured no strong electromagnetic interference was nearby. Subjects were put on EEG caps, earplugs, and nasal plugs. The chin pad was adjusted so that the outlet tube of the taste inducer was located 0.25 - 0.5 cm above the center of the subject's tongue. For each subject, the taste EEG was collected over four days, which were parallel experiments, and each day was from 9:00 am to 11:00 am or 3:00 pm to 5:00 pm. The taste EEG experimental process for each subject on each day is shown in Fig. 2. The order of the four taste experiments was randomized, and the interval between adjacent experiments was 30 minutes to allow the subjects to rinse their mouths and rest adequately. In each taste experiment, the subjects were stimulated by water twice to adapt to the feeling of water flowing on the tongue. For water stimulation, water flows into the center of the subjects' tongues at a constant flow rate of 0.25 ml/s for 2 s. Then, the subjects spat out the liquid within 10 seconds and took a short rest. After two water stimulations, the taste solution flowed into the center of the subjects' tongues at a constant flow rate of 0.25 ml/s for 2 s. Then, the subjects tasted the taste for 10 seconds to induce a taste EEG, during which they closed their eyes lightly without swallowing."}, {"title": "2.1.4 Preprocessing", "content": "The taste EEG was preprocessed by Matlab (R2017b) and its built-in toolkit EEGLAB (version 2021). The processing flow is as follows.\n(1) 320 (20 \u00d7 4 \u00d7 4) taste EEG data segments were collected, each 10 s size. The sample size of the taste EEG was set to 2 s, so 1600 taste EEG samples could be generated. The labels of the four taste EEG samples of sour, sweet, bitter, and salty were set as label0, labell, label2, and label3, respectively.\n(2) After establishing the taste EEG samples, a finite impulse response filter was used to perform bandpass filtering between 0.5 and 50 Hz to remove low-frequency and high-frequency noise in the samples. Notch filters with the lower edge of the 49 Hz passband and the upper edge of the 51 Hz passband were used to remove power frequency noise from the samples. Then, the sampling frequency of the samples was reduced from 256 Hz to 128 Hz to reduce the sample size, so the size of the final EEG sample was 256 \u00d7 21."}, {"title": "2.2 Analytical method", "content": null}, {"title": "2.2.1 Analysis framework", "content": "The analysis framework of the CAM-Attention channel selection method is shown in Fig. 3, and the steps are as follows.\nStep 1: Each taste EEG sample in the training set was reshaped into 84 \u00d7 64 and then input to the CNN-CSA model for the classification training of sour, sweet, bitter, and salty.\nStep 2: The trained CNN-CSA model and the reshaped training samples were input into the Grad-CAM model to generate the gradient class activation map corresponding to each training sample.\nStep 3: To obtain the whole gradient class activation map of each class of EEG samples. All the gradient class activation maps in each class were averaged. For example, the sour's average gradient class activation map is calculated as follows.\n$SourHot = \\frac{1}{k}\\sum_{i=1}^{k} Hotiabelo$ (1)\nWhere $Hotiabelo$ represented the ith gradient class activation map of sour, and k was the number of gradient class activation maps in sour.\nStep 4: The four tastes' average gradient class activation maps were averaged to generate gradient class activation maps AllHot representing the activation regions of the four tastes for EEG channel selection.\nStep 5: The sum of EEG each channel's values in AllHot was calculated and sorted in descending order, the formula is as follows.\n$ChannelList = sort([\\sum_{n=1}^{256} AllHot])$ (2)\nWhere m in AllHot represented the EEG channel numbers 1, 2, ..., 21, respectively. Sort ( ) meant to sort the sum of each EEG channel's values from largest to smallest.\nStep 6: Determined the EEG channel number Q and selected the first Q EEG channels in ChannelList.\nIn the training and testing sets, only the data in the selected EEG channels were saved and used to generate a new training and testing set. Then, each sample in the new training and testing sets was reshaped into 84 \u00d7 64. Finally, the reshaped training set samples were input into the CNN-CSA model for training, and the reshaped testing set samples were input into the trained CNN-CSA model for testing."}, {"title": "2.2.2 Channel attention and spatial attention modules", "content": "In this paper, an attention mechanism was introduced into the convolutional neural network, which can effectively extract the essential features of the taste EEG and significantly improve the recognition performance of the network. Channel attention and spatial attention were two important attention mechanisms. Among them, channel attention can pay attention to important channels in the feature map and ignore redundant channels more effectively when extracting deep EEG features. Spatial attention can pay attention to the important spatial position in the feature map and mine the important spatial features more effectively when extracting the shallow EEG features.\nThe structures of the channel attention module (CAM) and the spatial attention module (SAM) are shown in Fig. 4(a) and (b), respectively. An EEG feature map F with the size H \u00d7 W \u00d7 C was used as input for CAM. Firstly, the average pooling and max pooling were used to aggregate the spatial information of the input EEG feature map F. The aggregated EEG spatial information was respectively input into the shared multi-layer perception with $\\frac{C}{5}$ neurons in the hidden layer, and two interactive EEG feature vectors"}, {"title": "2.2.3 CNN-CSA model", "content": "CNN can effectively extract high-dimensional features of EEG data by convolution and pooling. Therefore, in recent years, CNN has been widely used in EEG classification tasks and has shown significant advantages. The CNN-CSA model was proposed in this paper to effectively implement channel selection and taste recognition in taste EEG tasks. Its structure is shown in Fig. 5. The CNN-CSA model consisted of convolution, pooling, a fully connected layer, a softmax layer, and attention modules. First, the shallow features of the taste EEG data were extracted by convolution 1. Compared with the deep EEG feature map after feature extraction, the shallow EEG feature map contained more spatial redundant information, so the SAM focused on the essential spatial regions in the shallow EEG feature map. Similarly, after convolution 2, the SAM was used to further extract the information of important spatial regions in the shallow EEG feature map. Then, the deep EEG features were gradually extracted by a series of convolution and pooling.\nAfter convolution 7, the number of channels of the EEG feature map was expanded to 128. With the deepening of the network depth, there were inevitably redundant channels in the deep EEG feature maps. So CAM was used to effectively focus on the important channels and ignore the redundant channels in the"}, {"title": "2.2.4 Grad-CAM model", "content": "Many studies have shown that CNN can extract deep features through convolution and pooling, expressing deeper data information. In addition, convolution and pooling can keep the spatial information of data well. Therefore, compared with the front-end convolution layer and the back-end full connection layer, the last convolution layer in CNN can not only express the deep EEG feature information but also retain the spatial information of the EEG data. Grad-CAM visually explains the classification and recognition of CNN using gradient information back-propagating from the class score to the last convolution layer. In this work, Grad-CAM and CNN-CSA were used to generate gradient class activation maps for different classes of taste EEG. Its process is shown in Fig. 5.\n(1) The convolution process means the convolution kernel's movement. Suppose the original EEG sample size of 21 \u00d7 256 is directly input into the CNN-CSA model for training. The model will mine more EEG features between channels during the convolution process, which is not conducive to generating the gradient class activation map for observing the contribution of a single EEG channel to the classification. To explore more features between the EEG data in each channel, the original EEG sample size of 21 \u00d7 256 was reshaped into 84 \u00d7 64 before being input into the CNN-CSA model for training.\n(2) For example, after the taste EEG sample $S$ was reshaped into 84 \u00d7 64, it was propagated forward to the softmax layer in the trained CNN-CSA model, and the scores of each class were obtained. It was worth noting that the channel and spatial attention modules were introduced into the CNN-CSA model to better mine the feature information of the EEG samples, ensuring the effectiveness of the gradient class activation map. Then calculating the gradient of the score ye of class c before the softmax layer relative to the EEG feature map Ak after the last convolution layer. The calculation formula is as follows.\n$G_{k}^{c} = \\frac{\\partial y_c}{\\partial A_k}$ (3)\nWhere $G_{k}^{c}$ represents the gradient map of class c score on the EEG feature map Ak.\n(3) Global average pooling was performed on the gradient map along the channel dimension to obtain the weight $\\omega_{k}^{c}$ representing the overall gradient value of each channel in the gradient map. The calculation formula is as follows.\n$\\omega_{k}^{c} = \\frac{1}{H \\times W}\\sum_{i=1}^{H}\\sum_{j=1}^{W} G_{ij}$ (4)\nwhere $G_{ij}^{c}$ represents the feature of each channel in $G_{k}^{c}$, and H and W represent the height and width of the $G_{k}^{c}$.\n(4) The weight was multiplied by the corresponding channel in EEG feature map Ak and added according to the corresponding positions along the channel dimension. Then, the ReLU activation function was used to eliminate the interference of irrelevant classes, highlighting class c, and the low-resolution gradient class activation map $L^{c}$ with a size of 5 \u00d7 4 was obtained. Its calculation formula is as follows.\n$L^{c} = ReLU(\\sum \\omega_{k}^{c} \\times A_{i})$ (5)\n(5) To observe the heat values of different EEG channels in the gradient class activation map, upsampling the low-resolution gradient class activation map L to the size of EEG samples by bilinear interpolation. After upsampling, it was normalized by maximum and minimum to unify the numerical range in the gradient class activation map of taste EEG. Finally, the gradient class activation map $Hot_{k}^{c}$ of size 84 \u00d7 64 was obtained by min-max normalization."}, {"title": "3. Results and discussion", "content": null}, {"title": "3.1 Model setting and evaluation method", "content": "All taste EEG samples were randomly divided into the training set and testing set according to 3 : 1, so the number of samples in the training set and testing set were 1200 and 400, respectively. After parameter pre-adjustment, the batch sizes of the training set and testing set of the CNN-CSA model were 64 and 32, respectively. Adam optimizer was used. The learning rate was 0.001, the weight decay was 0.005, and the number of iterations was 200. Accuracy and F1-score were used as evaluation indexes to evaluate the effectiveness of the channel selection method and the CNN-CSA model's classification performance."}, {"title": "3.2 Performance evaluation of channel selection method", "content": "In this section, the effectiveness of CAM-Attention and other classical channel selection methods such as Lasso (Wang et al., 2015), MI-BMInet (Wang et al., 2024b), and NMI (Wang et al., 2019) were evaluated. CAM-Attention is combined with the CNN-CSA model for taste EEG recognition. To ensure the reliability of the experiments, five independent experiments were performed for each channel selection method, and their accuracy and F1-score were averaged.\nTable 2 shows the classification results of different channel selection methods. The CAM-Attention method outperformed other channel selection methods in recognizing taste EEG. Furthermore, Lasso performed the worst, and NMI and MI-BMInet performed comparably. For the above methods, with the reduction of the number of selected channels, the classification effects of the four methods deteriorated to varying degrees. When the number of selected channels was 12, the accuracy of Lasso, NMI, and MI-BMInet was 80.26%, 87.49%, and 88.38%, respectively, which was 4.10%, 1.93%, and 3.68% lower than that of all channels. In this case, although Lasso, NMI, and MI-BMInet effectively reduce the amount of computation, their classification performance was significantly worse. For the CAM-Attention method, when the number of selected channels was 12, the accuracy and F1-score were 97.55% and 97.52%, respectively, 0.44% and 0.43% lower than all channels, respectively. It can be seen that the CAM-Attention method effectively realized the selection of essential channels and ensured an excellent classification effect while ensuring a large reduction in the amount of calculation."}, {"title": "3.3 Evaluating different network models combined with Grad-CAM", "content": "The Grad-CAM and CNN-CSA models were two important parts of the CAM-Attention methods. Among them, the change in the network structure of the CNN-CSA model would lead to a change in the gradient class activation map. The shallow network can save computing resources, while the deep network has more advantages in deep feature extraction. In this section, we selected the shallow classical networks LeNet5 (LeCun et al., 1998), AlexNet (Krizhevsky et al., 2017), EEGNet (Lawhern et al., 2018), ViT (Dosovitskiy et al., 2020), and deeper ResNet18 (He et al., 2016) networks, which have been widely used in EEG analysis to explore the effect of the networks combined with the Grad-CAM model. Then, the effectiveness of the CNN-CSA model combined with the Grad-CAM model was fully proved by comparing the effects of the above classical networks with those of the CNN-CSA model. Among them, only the CNN-CSA model in the CAM-Attention method was replaced with the different network model. The batch size, optimizer, learning rate, weight decay, and iteration times of all network models were the same as those in the CAM-Attention method. To ensure the reliability of the experiments, five independent experiments were carried out on the channel selection methods under each network model, and their accuracy and F1-score were averaged.\nTable 3 shows the results of different networks combined with Grad-CAM for channel selection.\nCompared to other network models, the CNN-CSA model achieved the best results when combined with the Grad-CAM model. Without employing any EEG channel selection, the CNN-CSA model achieved an accuracy of 97.99% and an F1-score of 97.95%. These figures surpassed those of other models, including AlexNet by 1.05% and 1.07%, ViT by 2.24% and 2.55%, LeNet5 by 7.96% and 8.33%, ResNet18 by 9.74% and 9.96%, and EEGNet by 28.21% and 29.93%, respectively. It shows that the CNN-CSA model has advantages in extracting key features from taste EEG data after combining the above network model with the Grad-CAM model to select channels. When the number of EEG channels was reduced from 21 to 12, a noticeable decline in accuracy and F1-score was observed across various models: EEGNet, ResNet18, LeNet5, ViT, and AlexNet. Specifically, the accuracy decreased by 12.51%, 18.66%, 5.27%, 8.70%, and 1.95%, respectively, while the F1-score dropped by 12.05%, 19.89%, 5.39%, 9.39%, and 2.04%, respectively. However, the CNN-CSA model has hardly decreased in accuracy and F1-score. It underscores the importance of combining the CNN-CSA and Grad-CAM models in preserving critical EEG channels during EEG channel selection.\nIn addition, we found that the CNN-CSA model achieved better results than the ViT model based on transformer architecture. We think there are the following reasons: (1) Local feature extraction ability: The CNN-CSA model is more suitable for extracting features from local areas in the design. In taste EEG data, some local electrical signal patterns may be associated with specific tastes. The CNN-CSA model can effectively capture these local features through convolution operation to better distinguish different taste stimuli. (2) Data efficiency: Because the taste EEG data is usually high-dimensional and complex, the ViT model may need more training data to train the model effectively. However, the CNN-CSA model can use limited data better to learn effective feature representation because it is more sensitive to capturing local features. (3) Combining the advantages of Grad-CAM: CNN-CSA and Grad-CAM models can better select the key EEG channels. Grad-CAM helps to determine the electrode channels with important information in taste EEG data by visualizing the attention region of the model. In contrast, the CNN-CSA model can extract and classify features on these key channels more effectively. To sum up, the advantages of the CNN-CSA model compared with the ViT model in the task of taste EEG data are mainly reflected in the better capture of local features, higher data efficiency, and the advantages when combined with the Grad-CAM model. These characteristics make the CNN-CSA model perform better in electrode selection and identification of taste EEG data.\nTable 4 shows the params and flops of different network models with different numbers of channels. Compared with the ResNet18 and CNN-CSA models, the number of neurons in the EEGNet, LeNet5, and AlexNet models in the first fully connected layer increased with the sample size, so the network parameters also increased with the increase of channel number. With the decrease in the number of channels, the flops of the above models were obviously reduced, which indicated that reducing the number of channels can effectively improve the recognition efficiency of taste EEG. For the CNN-CSA model, reducing the number of EEG channels from 21 to 12 led to a 41.18% decrease in flops. Despite this reduction, the recognition accuracy and F1-score of taste EEG only decreased by 0.44% and 0.43%, respectively. These findings demonstrate the effectiveness of combining the CNN-CSA model with the Grad-CAM model in performing EEG channel selection, thereby enhancing the recognition efficiency of taste EEG signals."}, {"title": "3.5 Cross-time taste EEG recognition", "content": "Due to the physiological and psychological differences in individuals across different periods, recognition models' stability and generalization capability face significant challenges in cross-time taste EEG recognition. Additionally, taste EEG signals are weak and susceptible to noise interference, making cross-time taste EEG recognition extremely challenging. Nevertheless, to further validate the effectiveness of the proposed CAM-Attention method and the CNN-CSA model, we conducted cross-time taste EEG recognition. In this study, we utilized all participants' data from the first three days as the training set and the last day as the test set, resulting in 1200 and 400 samples in the training and test sets, respectively.\nFig. 10 shows the performance comparison of various channel selection methods in cross-time taste EEG recognition, and the configuration of the methods is consistent with that in section 3.2. Notably, when reducing the number of channels from 21 to 12, only the CAM-Attention method sustains robust recognition performance, indicating it effectively selects the important channels representing the taste information in the cross-time taste EEG recognition. Furthermore, comparative analysis reveals that the CAM-Attention method consistently outperforms alternative approaches in cross-time taste EEG recognition, which shows the advantages of the proposed CAM-Attention method in cross-time taste EEG recognition.\nFig. 11 shows the performance of different networks in cross-time taste EEG recognition after combining Grad-CAM, and the network configuration is consistent with that in section 3.3. It can be seen that the Grad-CAM method can realize the selection of important taste EEG channels after being combined with CNN-CSA and AlexNet, proving the adaptability of the Grad-CAM method in selecting taste EEG channels. Furthermore, upon comparing the outcomes of various network models in cross-time taste EEG recognition, it becomes evident that the CNN-CSA model outperforms other advanced network architectures in terms of both accuracy and F1-score, which not only shows that CNN-CSA model has better adaptability to Grad-CAM method, but also proves that it has a stronger ability to mine taste EEG features."}, {"title": "3.6 Visualization", "content": "This work analyzes the spatial distribution of taste EEG features under different channel numbers using the T-SNE visualization method to visualize the effectiveness of the CAM-Attention method and CNN-CSA model. T-SNE visualization is carried out in two cases: (1) the training set and the test set are randomly divided (as shown in Fig. 12), and (2) all subjects' data from the first three days as the training set and the last day as the test set (as shown in Fig. 13). Among them, the output features of the fully connected layer in the CNN-CSA model serve as the input for T-SNE. T-SNE then transforms the features of each sample into a two-dimensional representation for visualization. In Fig. 12 and 13, the orange five-pointed star, blue square, purple triangle, and green circle represent taste EEG samples corresponding to acid, sweet, bitter, and salty categories, respectively. As can be seen from Fig. 12 and Fig. 13, when the channel number is optimized from 21 to 12, both the inter-class distance of different classes of taste EEG samples and the intra-class distance of the same classes of taste EEG samples are well maintained, and important taste EEG channels are preserved. It shows that the proposed method can improve the calculation efficiency and ensure the accuracy of taste EEG recognition. In addition, when the number of channels is reduced to 8, the feature space of taste EEG becomes worse, which shows that blindly reducing the channel number will lead to the loss of important taste EEG features. For taste EEG, 12 channels are considered for recognition efficiency and accuracy."}, {"title": "3.7 Potential application and limitations", "content": "This paper proposes a channel selection method called CAM-Attention, which combines the CNN-CSA model to recognize taste EEG. Its potential application and limitations are as follows.\nPotential applications. (1) Taste EEG recognition technology: This method can be applied to taste EEG recognition and provide technical support for taste research. (2) Sensory evaluation of food: This method can be used as a sensory evaluation tool of food taste and provide a reference value for the food industry. (3) Reduce the computational complexity: The CAM-Attention method can effectively reduce the computational complexity of EEG taste recognition and improve the computational efficiency.\nLimitations. (1) Sample limitation: The samples of taste EEG used in this paper may be affected by experimental conditions and individual differences of subjects and may not be enough to represent the taste changes fully. (2) Generalization of the model: the effect of this method under certain taste conditions has been proven effective, but its generalization ability under other taste conditions needs further verification. Methods Generalization: The CAM-Attention method is designed for EEG recognition of taste and may not be suitable for other EEG recognition tasks. (3) Performance evaluation: Although performance indicators such as accuracy and F1 score are provided, the effect of this method in practical application is not mentioned, and more practical tests and verifications are needed.\nTo sum up, this method has a certain potential for application in taste EEG recognition, but some limitations still need further study and solving."}, {"title": "4. Conclusion", "content": "In this work, we propose a channel selection method of taste EEG called CAM-Attention, which combines the Grad-CAM and CNN-CSA models. The main conclusions are as follows:\n(1) Firstly, we designed the taste EEG experiment and collected the taste EEG data under different taste stimuli. It provides a rich experimental database for our research and enables us to understand taste EEG's characteristics and patterns deeply.\n(2) Secondly, to fully explore the key features of taste EEG, we put forward the CNN-CSA model. Through this model, we can recognize taste EEG more accurately, providing more reliable support for taste recognition.\n(3) Most importantly, we combine CNN-CSA and the Grad-CAM model to form the CAM-Attention method. This method can effectively select the key channels in the taste EEG and mine the data characteristics in the selected channels, thus successfully distinguishing different tastes. This innovative method brings breakthroughs and ideas to taste EEG recognition.\nTo sum up, our research provides important technical support and theoretical guidance for taste EEG recognition. We believe that this method can play an important role in the study of taste EEG and provide new ideas and methods for sensory evaluation of food taste. We hope that our work can stimulate the interest of more researchers and promote the further development of this field. In the future, we will continue to work hard to improve this method further and explore a wider range of applications, making greater contributions to improve human health and quality of life."}]}