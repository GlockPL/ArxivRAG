{"title": "Predicting Deterioration in Mild Cognitive Impairment with Survival Transformers, Extreme Gradient Boosting and Cox Proportional Hazard Modelling", "authors": ["Henry Musto", "Daniel Stamate", "Doina Logofatu", "Daniel Stahl"], "abstract": "The paper proposes a novel approach of survival transformers and extreme gradient boosting models in predicting cognitive deterioration in individuals with mild cognitive impairment (MCI) using metabolomics data in the ADNI cohort. By leveraging advanced machine learning and transformer-based techniques applied in survival analysis, the proposed approach highlights the potential of these techniques for more accurate early detection and intervention in Alzheimer's dementia disease. This research also underscores the importance of non-invasive biomarkers and innovative modelling tools in enhancing the accuracy of dementia risk assessments, offering new avenues for clinical practice and patient care. A comprehensive Monte Carlo simulation procedure consisting of 100 repetitions of a nested cross-validation in which models were trained and evaluated, indicates that the survival machine learning models based on Transformer and XGBoost achieved the highest mean C-index performances, namely 0.85 and 0.8, respectively, and that they are superior to the conventional survival analysis Cox Proportional Hazards model which achieved a mean C-Index of 0.77. Moreover, based on the standard deviations of the C-Index performances obtained in the Monte Carlo simulation, we established that both survival machine learning models above are more stable than the conventional statistical model.", "sections": [{"title": "1 Introduction", "content": "Dementia diseases represent one of the most significant global health challenges of our time, affecting millions worldwide with profound impacts on individuals, families, and healthcare systems [14]. Alzheimer's Disease (AD) is the most"}, {"title": "2 Related Work", "content": "Transformer models, originally developed for natural language processing [31], have been adapted for survival analysis due to their ability to handle sequential data and capture long-range dependencies. Studies such as [12][32] have demonstrated evidence of transformer-based models having superior predictive ability when comparing with standard Cox Proportional Hazards (Cox PH) models, and other survival-based machine learning and deep learning techniques. Furthermore, [10] demonstrated good predictive ability when integrating high-dimensional, multimodal medical data, however they did not directly compare the model to a standard Cox PH model or any survival-based ML model.\n\nThe aforementioned studies suggest that specific survival-based transformer models may produce good predictions of temporal risk. However, the literature remains sparse and more work is needed to directly compare survival transformers and existing survival models. Furthermore, the complexity of transformer architectures introduces challenges in interpretability and computational efficiency. The opaque nature of transformer processes makes it difficult to decipher the model's decision-making process, a significant drawback in clinical settings where understanding the rationale behind predictions is crucial.\n\nIn contrast, XGBoost models have been highlighted for their robust performance in survival analysis [17], particularly when dealing with structured, tabular datasets. Other works by [7] and [25] underscore survival tree-based method's competitive accuracy and computational efficiency, making them a viable option for rapid model training and deployment. Furthermore, recent work has also demonstrated the superiority of tree-based methods when compared to neural network based techniques in survival prediction tasks [17][19]. This is fortunate as tree-based methods are usually not as complex or computationally intensive as neural network models, making them potentially a better option when considering adoption into healthcare infrastructure and processes. One the other hand, XGBoost can also suffer from a lack of interpretibility and thus efforts must be made to allow clinicians the opportunity for inference as well as prediction when using these models. Recent efforts to implement explainability into survival ML models have demonstrated some success in allowing inference from these 'black box' models [21].\n\nRecent work has demonstrated evidence for the efficacy of survival-based ML models. However, to date, no direct comparison of these models with survival transformers has been made within the context of AD prediction."}, {"title": "3 Methodology", "content": "Variables with missingness at 50% or greater of the total rows for that predictor were removed. All nominal predictors were dummy-coded. Missing values were imputed using K-Nearest Neighbour imputation with K=5. For the present study, all CSF-derived biomarkers were removed so as to focus on the predictive power of blood-based biomarkers and other variables. Only those who were diagnosed with MCI at baseline were included in the modelling. An additional numeric variable was created indicating the number of months since baseline that the participant had their final visit. For this final visit the participant received a final diagnosis, one of CN, MCI, or AD. These three diagnoses were collapsed into a binary outcome, indicating whether the participant received a worse diagnosis upon final visit, compared to baseline. A worse diagnosis was defined as one that indicated evidence of more severe cognitive decline. Full information on the binary outcomes and their definitions can be seen in Table 1.\nThe final combined dataset contained 2160 variables and 385 observations, including the final visit and final diagnosis variables (Table 2). Full preprocessing and modelling code is available upon request.\nBecause the dataset contained more variables than observations, which can lead to convergence issues when modelling, it was decided to implement a ReliefF method to select the top 200 most predictive variables in the relation to the outcome. A full description of this method can be found in [30] but in brief, the\nreliefF model cycles through each observation without replacement. For each cycle, the feature score vector W is updated based on feature value differences observed between the target $R_i$ and neighboring instances. ReliefF relies on the user defined parameter k that specifies the use of k nearest hits and k nearest misses in the scoring update for each target instance. It selects k nearest neighbors with the same class called the nearest hits (H) and k nearest neighbours of the opposite class, called the nearest misses (M). Finally it updates the weight of a feature A in W if the feature value differs between the target instance $R_i$ and any of the nearest hits H or nearest misses M [30].\n\nAfter undergoing the ReliefF process, the resultant dataset had 200 variables, 385 observations, and the 2 outcome variables indicating final visit and final diagnosis."}, {"title": "3.4 Models", "content": "Model development, evaluation, and validation were carried out according to methodological guidelines outlined by [28]; results were reported according to the Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis (TRIPOD) guidelines [8]. This paper explored three survival algorithms:\n1. Cox Proportional Hazard Model (Cox PH) - The Cox model is expressed by the hazard function, which is the risk of an event occurring at time t as follows:\n$h(t) = h_0(t) * exp(\u03b2_1X_1 + \u03b2_2X_2 + ... + \u03b2_pX_p)$ (1)\nwhere t represents the survival time, h(t) is the hazard function acting upon survival time t, $X_1, X_2, ... X_p$ are the values of the p covariates, $\u03b2_1, \u03b2_2, ... \u03b2_p$ are the coefficients that measure the effect of the covariates on the survival time, and $h_0(t)$ is the baseline hazard function. The coefficients are estimated by maximising the partial likelihood and so the model does not require tuning [17].\n2. Survival XGBoost (SXGB) Extreme Gradient Boosting is a tree-based ensemble method that grows trees sequentially, by adhering to a gradient descent procedure informed by a loss function, often the negative log liklihood, defined as:\n$min \u2013 log(p(y; \u03b8))$ (2)\nwhere the model seeks to minimise the negative log of difference between the true outcome y, observed in the training data, and the outcome predicted by the model \u03b8.\n\nThis function informs a step function, which calculates the most appropriate adjustments to the model parameters in order to converge on a solution. In the case of the SXGB the negative concordance index is used to calculate steps towards a solution that finds the risk score derived from a Cox Proportional Hazard technique. Thus, the SXGB model seeks to find a risk score that will most closely reflect the true risk for that participant [6]. Hyperparameter tuning was performed on the eta (0.000001 - 0.1), max depth (1 - 5), subsample (0.5 - 0.9), number of columns sampled per tree (0.1 - 0.9), gamma (0.0001 - 0.1), the minimum child weight (1-e8 - 0.0001), and the alpha (0-1) and lambda (0-20) regularisation parameters.\n3. Survival Transformer (STran) - The transformer model, initially proposed for natural language processing tasks, is adapted here for survival analysis for AD, based on work done by [12]. At its core, the transformer uses self-attention mechanisms to weigh the significance of different parts of the input data differently, enabling it to capture complex, long-term dependencies. Self attention can be defined as:\n$Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V$ (3)\nWhere: Q, K, V are the queries, keys, and values respectively, and $d_k$ is the dimension of the keys.\n\nThe current Survival Transformer employs ordinal regression, treating survival analysis as a problem of predicting ordered categories. This approach allows for directly modeling the survival time distribution as a discrete set of intervals. Ordinal regression is defined as:\n$log(\\frac{P(T > t)}{P(T \\le t)}) = X\u03b2 - a_t$ (4)\nWhere t is the survival time, X are the input features, \u03b2 are the regression coefficients and $a_t$ are the thresholds for the ordinal categories.\nAn outline of the model architecture can be found in Fig. 1. More information on this model can be found at [12]. Hyperparameter tuning was performed on the number of hidden layers (1 - 10) size of the hidden layers in the position-wise feedforward network (1 - 10), the node dropout probability (0.1 - 0.5), the learning rate (1e-6 - 0.01), the regularisation parameters applied to the loss function (0.1 - 3), and the number of epochs (1 - 500)."}, {"title": "3.5 Bayesian Optimisation", "content": "This paper utlises Bayesian optimisation for the hyperparameter tuning of the SXGB and STran models. Unlike grid or random search methods, Bayesian optimisation uses prior knowledge of the performance of the model with different hyperparameters to intelligently select the next set of hyperparameter values to evaluate. This approach is particularly useful for optimising complex models where training is computationally expensive, as it aims to find the best hyperparameter values in as few evaluations as possible [24].\n\nBayesian optimisation for hyperparameter tuning operates by intelligently navigating the space of possible hyperparameter settings to find the optimal configuration for a given machine learning model. This process starts with the construction of a surrogate model, typically a Gaussian Process, to estimate the performance across the hyperparameter space. An acquisition function then guides the selection of the next hyperparameters to evaluate by balancing the exploration of new areas against the exploitation of areas known to perform well.\n\nThe hyperparameters selected by optimising the acquisition function are used to train the model, and the resulting performance metric is fed back into the surrogate model to refine its understanding. This cycle repeats, with each iteration refining the surrogate model's predictions and focusing the search on the most promising regions of the hyperparameter space. This method is particularly valued for its efficiency in finding optimal hyperparameters with relatively few model evaluations, making it suitable for optimizing complex models where training is computationally expensive [23]. For the two models where hyperparameter tuning was available, we tuned the number of rounds of Bayesian optimisation with values 100-1000."}, {"title": "3.6 Model Performance Indicator", "content": "Performance of the models was assessed using the Concordance index or C-index [28]. This metric, also called Harrell's C-index, provides a global assessment of the model and can be considered a more general form of the AUCROC measure typically used in binary classification tasks. The C-index computes the percentage of comparable pairs within the dataset whose risk score was correctly identified by the model. More formally:\n$C = \\frac{\\Sigma_{i,j} I(t_i > t_j) \\cdot I(n_j > n_i) \\cdot \\Delta_j}{\\Sigma_{i,j} I(t_i > t_j) \\cdot \\Delta_j}$ (5)\nWhere $t_i$ and $t_j$ are the predicted survival times for individuals i and j, respectively, $n_i$ and $n_j$ are the actual survival times for individuals i and j, respectively, I (.) is an indicator function that returns 1 if the condition inside the parentheses is true and 0 otherwise, and \u0394j is an indicator of whether the event has occurred for individual j (1 if the event has occurred and 0 if censored). For the full technical details of this index see [22]."}, {"title": "3.7 Cross-Validation with Bayesian Optimisation and Monte-Carlo Simulation", "content": "A Cross-Validation procedure with Bayesian Optimisation was implemented to tune and evaluate the models so precise estimates of the model's performance of unseen cases (internal validation) could be gathered [18]. Cross-Validation consisted of an outer 5-fold CV (model assessment) and an inner Bayesian Optimisation procedure. We conducted a Monte-Carlo procedure of 100 repetitions of the CV+Bayes using different random splits per model to assess the models' stability. Performance statistics were recorded for each model produced by each iteration. Each performance statistic's mean and standard deviation across all iterations were recorded when the Monte-Carlo was complete. To ensure the representativeness of training and test samples in both procedures, the data splitting was stratified based on the AD cases variable. The full methodology can be seen in Fig. 2."}, {"title": "3.8 Software and Hardware", "content": "The data analysis was conducted using the Python language. Initial data cleaning was performed using the scikit-learn library [3]. The reliefF procedure was conducted using the skrebate library [4]. The modelling including training, tuning and evaluation, was performed on the Cox PH model using the lifelines library [9]. The SXGB modelling was performed using the xgboost library [5]. For the transfomer modelling, a version of the model found in [12] was adapted to be run on ADNI data. The hardware consisted of one server running Ubuntu with a 16-core Ryzen processor, 128 GB of RAM and a 4090 RTX 24GB GPU."}, {"title": "4 Results", "content": "The C-index performance for each model type performed on the ADNI data is detailed in Table 3.\nThe best performing model was the survival transformer, followed by the Survival XGBoost model. Both Survival ML models outperformed the Cox Proportional Hazards model in terms of the C-Index performance metrics.\nThe Results of the Monte-Carlo Simulation are detailed in Table 4.\nWhen considering the Monte-Carlo simulation, the survival transformer model proved the best performing in terms of the mean C-index over 100 iterations of the nested cross-validation procedure. See Table 4 and and Fig. 3 for illustration. In terms of the stability of performance for these models, as measured by the standard deviation of the C-Index over 100 iterations, Survival XGBoost model proved to be the most stable, followed by the survival transformer model. Both Survival ML models were more stable than the standard Cox Proportional Hazards model."}, {"title": "5 Discussion", "content": "This study aimed to further explore the potential of survival-based ML as a tool for predicting time to AD diagnosis. This paper demonstrates the clear utility of such methods when predicting on the ADNI dataset. This supports the work of [25][19][17][16] and thus provides further support for the utility of these survival based techniques in the context of dementia prediction modelling.\n\nFurthermore, this study also aimed to explore the value of blood-derived biomarkers as predictors in survival-based machine learning and deep learning techniques. Although a number of recent studies have provided evidence for the utility of blood-derived biomarkers in Alzheimer's modelling [29], as far as we are aware, this work is the first to use these biomarkers for survival-based modelling. As has been mentioned by [11] [26] these biomarkers would allow a much less invasive way of alerting clinicians and patients to the risk of cognitive decline. If we are also able to predict, not just a binary outcome indicating AD or not, but also the risk of deterioration as a function of time, we are both able to provide more information to clinicians and patients, whilst also providing a better experience through minimally invasive data collection. The current study is therefore a demonstration of good predictive ability, using survival-based techniques and minimally invasive biomarkers. This both lends support for survival based techniques, supporting the work of [18] and [25], and for the use of blood derived biomarkers in these models, supporting the work of [26]."}, {"title": "12", "content": "A further novelty for this paper is the use of a survival-based transformer to predict deterioration in the context of AD. Although there is a small but growing body of literature adapting transformers for survival modelling [32][10][12] the present work is the first to apply these techniques to predict deterioration in AD. To that end, this study demonstrated that survival-based transformers have superior performance when compared to survival-based extreme gradient boosting and the standard Cox Proportional Hazards model. This result is notable as previous work which have compared tree-based and neural network-based survival techniques have found that the less complex tree-based methods have performed better than deep learning methods [17][19]. However, previous work using survival deep learning to predict on deterioration in dementia have focused on recurrent or convolutional neural networks. Survival transformers adopt a wholly different approach, using multiheaded attention and treating each participant as a 'sentence' where each 'word' is the interaction between the participant and time [12]. Thus, the transformer attempts to predict the complement of the hazard function for all participants at all points in time [12]. Transformers, therefore, represent a new and substantially different approach to all survival based deep learning techniques that have previously been proposed. This may explain why this technique appears superior to the other deep learning techniques presented in the literature. However, transformers are computationally intensive, even when compared to other neural network techniques. If they are to be implemented in health infrastructure and practices, the intensive training required for the models needs to be taken into consideration. Furthermore, inference is difficult with transformers as it is challenging to see how predictions are reached. This means clinicians and researchers are unable to observe potentially modifiable risk factors which increase the risk of AD.\n\nAlthough this paper presents work with several aspects of novelty, the study contains a number of limitations. Firstly, the Bayesian Optimisation technique was employed for hyperparameter tuning for the survival-based models where appropriate. Due to time and computational limitations, the search for optimal hyperparameters using this technique was not exhaustive and it is possible that subsequent work may improve on the current results using different combinations of hyperparameters.\n\nSecondly, the sample used in this work is comparatively small, with just 385 observations and 200 candidate predictors. It is essential, therefore, that this work be validated on larger datasets before being adopted into healthcare practice and decision making.\n\nFinally, as has been mentioned elsewhere [17] ADNI is a US based study with roughly 80% white participants. Future validational work for these models should therefore seek to employ non white western datasets to test how well the models perform on these groups."}]}