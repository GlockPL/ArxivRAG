{"title": "May the Forgetting Be with You: Alternate Replay for Learning with Noisy Labels", "authors": ["Monica Millunzi", "Lorenzo Bonicelli", "Angelo Porrello", "Jacopo Credi", "Petter N. Kolm", "Simone Calderara"], "abstract": "Forgetting presents a significant challenge during incremental training, making it particularly demanding for contemporary Al systems to assimilate new knowledge in streaming data environments. To address this issue, most approaches in Continual Learning (CL) rely on the replay of a restricted buffer of past data. However, the presence of noise in real-world scenarios, where human annotation is constrained by time limitations or where data is automatically gathered from the web, frequently renders these strategies vulnerable. In this study, we address the problem of CL under Noisy Labels (CLN) by introducing Alternate Experience Replay (AER), which takes advantage of forgetting to maintain a clear distinction between clean, complex, and noisy samples in the memory buffer. The idea is that complex or mislabeled examples, which hardly fit the previously learned data distribution, are most likely to be forgotten. To grasp the benefits of such a separation, we equip AER with Asymmetric Balanced Sampling (ABS): a new sample selection strategy that prioritizes purity on the current task while retaining relevant samples from the past. Through extensive computational comparisons, we demonstrate the effectiveness of our approach in terms of both accuracy and purity of the obtained buffer, resulting in a remarkable average gain of 4.71% points in accuracy with respect to existing loss-based purification strategies. Code is available at https://github.com/aimagelab/mammoth.", "sections": [{"title": "Introduction", "content": "Despite the latest breakthroughs, modern AI still struggles to learn in a continuous fashion and suffers from catastrophic forgetting [40], i.e. the new knowledge quickly replaces all past progress. Therefore, Continual Learning (CL) has recently gathered an increasing amount of attention: among the others, one prominent strategy is to interleave examples from the current and old tasks (rehearsal). To do so, a small selection of past data is retained in a memory buffer [17, 56], as in Experience Replay (ER) [48, 50].\nIntuitively, the effectiveness of these methods depends strictly on the memory content: the larger the gap between the memory and the true distribution underlying all the previous tasks, the lower the chances of learning a reliable model. In this respect, several factors may intervene and degrade the snapshot portrayed by the buffer. Several works have highlighted the shortcomings of low-capacity buffers and their link to severe overfitting [9, 57]. More recently, the plausible presence of annotation errors has emerged as an engaging factor [6, 31], due to the subsequent poisoning the memory buffer would be subjected to. Indeed, not only would a few observations of past tasks be available for the learner, but they might be erroneously annotated. It is noted that the presence of noisy annotations [8, 34, 36, 61] is an inescapable characteristic of CL: to allow the learner to digest incoming training examples on-the-fly, data has to be annotated within a restricted temporal window, leading to poor human annotations and hasty quality controls. In light of this, preliminary works [6, 31] focus on purifying the memory buffer and then consolidate their knowledge at the end of the current task (or while learning the task itself [29]). To do so, they spot clean samples by leveraging the popular small-loss criterion [4, 22, 28] and the fact that the most trustworthy examples are those favoured during the first training stages (memorization effect), thus exhibit a lower value of the loss function. However, despite its effectiveness in the offline scenario, such a criterion may be weak in incremental settings. Indeed, as learning does not re-start from scratch but builds upon previous knowledge, the adaption is faster and hence the loss-value separation between clean and noisy samples tends to vanish [4, 63].\nTo overcome this limitation, we explore a radically different approach which could be summarized by a quote ascribed to Julius Caesar \"if you can't defeat your enemy, have him as your friend\u201d: while existing methods see forgetting only as an issue to solve, we use it to identify noisy examples within the data stream. We build upon the work of [39, 55], which theoretically demonstrates that mislabeled examples are quickly forgotten, whereas complex or rare instances tend to be retained for longer periods or may not be forgotten at all."}, {"title": "Related works", "content": "Continual Learning methods can be broadly categorized into regularization-based \u2013 these limit changes to key task-related parameters [32, 62] \u2013 and rehearsal-based methods [56].\nRehearsal. In most existing CL scenarios [14, 17, 56], it has been shown that supplementing current training data with past samples is more effective at mitigating forgetting than any regularization-based methods. A simple yet effective method is Experience Replay (ER) [48, 50] which interleaves the current training batch with past examples. Otherwise, GDumb [47] pushes this concept to the extreme by greedily storing incoming samples and subsequently training a model from scratch using only the samples stored in the buffer.\nSampling strategies. Given their low capacity, buffers need to contain a balanced outlook of all seen classes. For this purpose, many employ reservoir sampling [58] to update the memory [5, 14, 16]. The outcome is an independent and identically distributed snapshot of the incoming tasks. However, not every sample comes with the same significance or robustness against forgetting. As highlighted by [2, 5, 15], retaining complex samples is crucial for preserving the performance, which they detect through their loss value or model uncertainty, respectively."}, {"title": "Learning with Noisy Labels", "content": "Noisy data can originate from multiple sources, including systematic or measurement errors encountered when retrieving historical data [10, 30, 46], errors introduced by human annotators [24, 54], or the presence of outliers [13]. Furthermore, noisy labels pose a significant challenge in medical imaging [30], where small and noisy validation sets can hinder the effectiveness of model calibration techniques [19, 44]. Various approaches have been proposed to mitigate the impact of data noise, including adversarial training, regularization and robust loss functions [26, 37, 64]. Additionally, ensemble methods [38, 42, 45] have been proven effective in reducing the impact of noisy data on model performance."}, {"title": "Method", "content": "Problem setting. We define the Continual Learning framework as the process of learning from a sequential series of T tasks. During each task t \u2208 {0,1,..., T \u2013 1}, input samples Xt and their annotations Yt are drawn from an i.i.d. distribution D\u2081. We follow the well-established class-incremental scenario [14, 20, 56] in which Yt-1\u2229Yt = \u2205 and at task t the learner f\u03b8 is required to distinguish between all observed classes. Ideally, we wish to minimize:\n\u03b8* = argmin_{\u03b8} E_{B~D_{t}} [L(f_{\u03b8}(x),y)], (1)\nwhere L is the cross-entropy loss and B = (x, y). As in CL the objective above is inaccessible, we leverage a fixed-size buffer M to store and replay part of the incoming samples. As a result, the generalized objective for rehearsal CL can be defined as:\n\u03b8* = argmin_{\u03b8} E_{B~D_{t}} [L(f_{\u03b8}(x), y)] + L_{R}, (2)\nwhere the replay regularization term L_{R} depends on the choice of the replay-based method. Although our approach can be equally applied to advanced choices of L_{R} [9, 12, 14, 27] (see Sec. 5), in this work we build upon the simplest strategy and leverage Experience Replay [48, 50]:\nL_{R} = E_{M} [L(f_{\u03b8}(x), y_{r})] (3)\nAs the objective in Eq. (3) could result in bias accumulation toward the current task [1], we adopt the asymmetric cross-entropy loss introduced in [16]."}, {"title": "Alternate Experience Replay (AER)", "content": "As discussed above, we tackle the challenge of Continual Learning under Noisy Labels (CLN), where each incoming dataset is affected by noise in the labeling process, leading to mislabeled training examples. For a given instance x_{i} \u2208 D_{t}, we indicate with \\tilde{y}_{i} ~ \\tilde{Y}_{i} the labels corrupted with annotation noise and with Pr (\\tilde{y}_{i} \u2260 y_{i}) the respective noise rate. In this setting, we must simultaneously address the challenges posed by both noisy labels \\tilde{Y}, and the problem of forgetting. To achieve this, our main focus is on constructing a memory set M that is as clean and representative as possible. Since this objective involves distinguishing between noisy and clean examples when populating the memory set, our methodology seeks to maintain a significant gap between the losses of clean and noisy samples. This gap is indeed crucial for filtering examples through the widely used small-loss criterion. However, with no countermeasure, the loss gap starts to deteriorate as the replay of a small selection of data ensues (see Fig. 1, left). This effect is exacerbated in the popular offline (i.e. multi-epoch) CL setting [14, 49, 60], where we might be forced to trade-off convergence on the current task to avoid overfitting the mislabeled samples [4, 63].\nTo counteract the vanishing effect of the small-loss criterion and encourage the separation between the losses of noisy and clean samples, our novel methodology named Alternate Experience Replay (AER) induces forgetting of buffer datapoints. We refer the reader to Algo. 1 for a summary of the overall procedure. Specifically, we divide the training epochs for the current task into two categories: buffer learning and buffer forgetting epochs. The training process involves alternating between these two modes of learning.\n\u2022 Buffer learning. In this regime, we train the model with standard replay (line 6) as in Eq. (2). Importantly, we do not modify the samples stored in the memory buffer M (no insertion or removal operations are performed).\n\u2022 Buffer forgetting. In this case (line 8), we omit regularization on the memory buffer and focus the training exclusively on data from D_{t}. By halting regularization and causing the subsequent forgetting of buffer datapoints, the loss of noisy examples is likely to increase more rapidly than that of clean ones [39, 55]. This, in turn, makes the small-loss criterion reliable once again (see Fig. 1, right). On top of that, we update M (line 9) through a loss-based selection strategy during these epochs (see Sec. 3.2)."}, {"title": "Asymmetric Balanced Sampling (ABS)", "content": "In this section, we outline the sampling strategy used to insert and delete examples into and from the memory buffer during each buffer forgetting epoch.\nSample insertion. Given a batch of data B from the current task, the first step is to determine which examples should be included in the buffer. To encourage the inclusion of clean examples, we exploit the memorization effect and employ a simple criterion that involves applying a threshold to the loss value. Formally, let \u03b1 denote the percentage of samples within the current batch that we intend to exclude from the insertion procedure, we compute:\nR = {(x, y) \u2208 B : L(x,y) < L_{\u03b1}} (4)\nwhere L_{\u03b1} is the loss value at the \u03b1-th percentile of the loss distribution over B. For our experiments, we set \u03b1 to 75, thus discarding the 75% of samples with the highest loss and treating the remaining 25% as candidates to be inserted in the buffer (lines 9-10 of Algo. 1).\nSample selection. We approach the selection process by sampling from a probability distribution p(x) defined over all exemplars \u2200x \u2208 M in the buffer. To model such a distribution, as carried out by most methods [5, 6, 15], we leverage the score s(x) = L(x, y) \u2265 0 given by the loss function. It is noted that a valid distribution can be then obtained by normalizing these scores, such that p(x) = s(x)/Z where Z = \u03a3_{x\u2208M}s(x). We refer to this strategy as Loss-Aware Symmetric Sampling (LASS). In LASS, examples with higher loss are more likely to be replaced, leading to a memory buffer that maintains greater purity.\nHowever, we argue that a replacement criterion based on loss value like LASS could be detrimental in terms of diversity, as it discourages the retention of complex yet clean samples into the memory buffer. Indeed, these examples tend to exhibit higher loss value, as they lie"}, {"title": "Buffer consolidation", "content": "While combining AER and ABS achieves a balance between sample purity and complexity preservation, a further reduction in noise levels can be achieved by optimally selecting samples from M at the end of each task. We employ a MixMatch-based [7] approach to enhance model robustness, utilizing uncertain samples as unlabeled ones (i.e. buffer consolidation in the following). Further details about this phase are provided in the supplementary materials."}, {"title": "Experiments", "content": "Datasets and noise settings. We conduct experiments on five distinct datasets and various levels of noise. Specifically, we use the Seq. CIFAR-100 dataset [33], which contains 32 \u00d7 32 images from 100 categories, split into 10 tasks, and the Seq. NTU RGB+D [51] dataset for 3D skeleton-based human action recognition, featuring 60 classes divided into 6 tasks. On these datasets, we inject two types of synthetic noise commonly employed in literature [22, 28, 35]: symmetric and asymmetric noise. In the first scenario, we replace the ground-truth label with probability r\u2208 [0,1] determined by the designated noise rate. The asymmetric or class-dependent noise setting, instead, is an approximation of real-world corruption patterns, altering labels within the same superclass as in [43, 64]. To further address real-world label noise, we evaluate our method on Seq. Food-101N [34] (5 tasks), composed of images gathered from the web, thus containing instance-level annotation noise. Additionally, ResNet18 [25] is used for Seq. CIFAR-100 with 50 epochs per task, ResNet34 [25] for Food-101N with 20 epochs, and EfficientGCN-B0 [53] for Seq. NTU-60 with 30 epochs."}, {"title": "Model analysis", "content": "Ablative study. We herein aim to investigate the impact of each component. Starting from the base rehearsal method used in our research, i.e. ER-ACE [16], we gradually introduce our two main contributions, AER and ABS, one at a time. As seen from the results in Tab. 3, each additional feature produces an increase in performance on Seq. CIFAR-100. For an in-depth analysis of the effects of the asymmetric cross-entropy loss function (ACE), we compare against the standard cross-entropy (i.e. ER in Tab. 3). The results indicate that the contribution of ACE is significant, aligning with both [16] and our initial expectations.\nPurity of the buffer. Considering Seq. CIFAR-10 (40% noise), Fig. 4 depicts the purity and the diversity of the buffer produced by ABS, PuriDivER.ME, and LASS. For each class, purity is defined as the ratio of examples labeled correctly within the memory buffer. Instead, we model diversity as the intra-class variation within each class, thereby computing the average std. deviation of the features produced by the Joint ideal model. Finally, we scale all metrics according to their occurrence rate to account for potential imbalances in the number of examples from different classes. As shown in Fig. 4, ABS clearly outperforms both LASS and PuriDivER.ME in terms of purity and diversity. Unexpectedly, LASS yields a particularly unbalanced buffer, with only the most recent classes showing a good balance. In contrast, PuriDivER.ME achieves better balance but falls short in terms of purity.\nApplicability to other methods. To evaluate whether AER/ABS can enhance other rehearsal methods, we apply them on DER++ [14] and conduct tests on Seq. CIFAR-100. We also report the results with and without the consolidation phase (Sec. 4.1). The gains shown in Fig. 3 support the validity of our AER/ABS on enhancing other CL baselines.\nAdditional results. In the supplementary materials, we provide: i) details about the experimental settings, the adapted baselines, noise injection process and hyperparameters, ii) the evaluation of Final Forgetting (FF), iii) an analysis of the computational costs, iv) an evaluation of the speed at which the model learns the noisy data, v) a sensitivity analysis conducted on the hyperparameter \u03b1, which controls the purity within the sample insertion strategy."}, {"title": "Conclusions", "content": "We present an innovative framework for Continual Learning in the presence of Noisy Labels, a common issue in real-world AI applications. We focus on the multi-epoch class-incremental scenario, arguing the shortcomings of current methods leveraging the small-loss criterion. We hence appeal to a long-standing enemy of continual learning \u2013 forgetting \u2013 and propose Alternate Experience Replay to maintain a clear separation between mislabeled and clean samples. Additionally, we introduce Asymmetric Balanced Sampling to enhance sample diversity and purity within the buffer. We demonstrate the merits of our approach through extensive experiments, showcasing its potential in noisy incremental scenarios."}, {"title": "Additional details on the experimental settings and Final Forgetting", "content": "To evaluate our proposal we build upon the open-source codebase provided by Mammoth [11, 14, 16], a CL framework based on PyTorch.\nOn the choice of datasets and noise\nWe empirically validate our method on four different classification benchmarks as mentioned in the main paper. For experiments on CIFAR-10/100 [33] and NTU-60 [51], we corrupt the labels of the datasets at hand to obtain different noise configurations, which we then keep fixed for each of the experiments for fairness of results comparison across multiple methods.\nIn the process of injecting symmetric noise, we replace the ground-truth label with probability r\u2208 [0, 1] determined by the designated noise rate. The asymmetric or class-dependent noise setting is an approximation of real-world corruption patterns, which alters labels within the same superclass. For example, in the CIFAR-100 dataset, each image comes with a \"fine\" label (specific class) and a \"coarse\" label (superclass). Here, label transitions are parameterized by r such that the wrong class and true class have probability r and 1 \u2212 r, respectively. This results in sample ambiguity occurring only between similar classes, as it would in a realistic scenario."}, {"title": "Results in terms of Final Forgetting", "content": "We repeat each of the experiments five times. We report in Tab. 1 of the main paper the Final Average Accuracy for all the experiments, with standard error values.\nWe also provide the final forgetting measure in Eq. (6) for all methods of the main com-"}, {"title": "Hyperparameters", "content": "We choose to use different buffer sizes relying on the dataset length. For experiments conducted on CIFAR-10 and CIFAR-100, the buffer size is set to 500 and 2000, respectively. We set the buffer size to 500 for experiments on NTU. Finally, we use a buffer size of 2000 for Food-101.\nWe select the other hyperparameters by performing a grid search and using the Final Average Accuracy (FAA) as the selection criterion for the best parameters. Here, we report the best values for each model, categorized by dataset and noise type.\nCIFAR-10\nNoise type: sym \u2013 20%\n\u2022 Joint: lr: 0.03\n\u2022 SGD: lr: 0.03\n\u2022 OURS: Ir: 0.03"}]}