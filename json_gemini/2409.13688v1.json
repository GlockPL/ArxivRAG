{"title": "Morphological Detection and Classification of Microplastics and Nanoplastics Emerged from Consumer Products by Deep Learning", "authors": ["Hadi Rezvani", "Navid Zarrabi", "Ishaan Mehta", "Christopher Kolios", "Hussein Ali Jaafar", "Cheng-Hao Kao", "Sajad Saeedi", "Nariman Yousefi"], "abstract": "Plastic pollution presents an escalating global issue, impacting health and environmental systems, with micro- and nanoplastics found across mediums from potable water to air. Traditional methods for studying these contaminants are labor-intensive and time-consuming, necessitating a shift towards more efficient technologies. In response, this paper introduces micro- and nanoplastics (MiNa), a novel and open-source dataset engineered for the automatic detection and classification of micro and nanoplastics using object detection algorithms. The dataset, comprising scanning electron microscopy images simulated under realistic aquatic conditions, categorizes plastics by polymer type across a broad size spectrum. We demonstrate the application of state-of-the-art detection algorithms on MiNa, assessing their effectiveness and identifying the unique challenges and potential of each method. The dataset not only fills a critical gap in available resources for microplastics research but also provides a robust foundation for future advancements in the field.", "sections": [{"title": "I. INTRODUCTION", "content": "LASTIC pollution in aquatic environments, especially in the Great Lakes where around 22 million pounds of plastic enter annually [1], poses a significant environmental challenge. The breakdown of consumer plastics into microplastics (less than 5 mm) and nanoplastics (less than 1 \u00b5m) [2] increases their surface area and mobility, allowing them to absorb and carry harmful substances like persistent organic pollutants (POPs) [3] and heavy metals [4]. This makes microplastics vectors for pollutants, aiding their movement through the food chain. While conventional water and wastewater treatment plants effectively remove larger plastic particles, the presence of smaller micro- and nanoplastics (MNPs) in drinking water remains a concern. MNPs have been detected in our food chain, leading to their presence in our food as well [5]. Furthermore, inter-generational transfer of nanoplastics has been observed, indicating their potential mutagenic and carcinogenic properties [6]. This is primarily attributed to the plastic additives and other toxins that MNPs carry, highlighting the need for effective measures to address their presence in the environment and food chain. Traditional methods for studying microplastics involve manual collection and analysis using techniques such as Raman [7] and Fourier transform infrared spectroscopies (FTIR) [8], pyrolysis-gas chromatography [9], and optical and electron microscopies [10]. The samples are then analyzed manually to detect and count microplastics, though this process can introduce errors [11]. Recognizing the challenges and limitations of current practices, which rely heavily on manual sampling and laboratory-based, labor-intensive analysis techniques for microplastics detection\u2014methods that are both time-consuming and costly [12]-we highlight the urgent need for a more streamlined, efficient, and automated approach to accurately detect, identify and quantify microplastics in aquatic environments.\nDetecting and quantifying MNPs in environmental samples presents several challenges. First, MNPs often clump together with other contaminants or become covered with biological material in the environment, making them difficult to isolate [13]. Second, MNPs are highly diluted in environmental samples, further complicating their detection [14]. Traditional spectroscopy or microscopy methods for detecting and quantifying MNPs require complex sample preparation steps, making them expensive, cumbersome, and time-consuming [15].\nLaboratories employing visual techniques with self-trained human operators have a success rate ranging from 39% to 68% in accurately identifying suspected microplastics in complex samples [16]. As a solution, scientists are turning to techniques to automate MNPs detection and quantification, reducing time and costs. To achieve this, researchers often simplify the problem and use laboratory-made MNPs to build up their dataset. The pioneers in the field started by training models using micro (and rarely nano) bead samples with known con-centrations [17]. Some studies have even employed mechanical methods, such as cryogenic ball milling or blending, to create microplastics (plastic fragments) for Machine Learning (ML) training [18]. Additionally, environmental samples, including laundry waste and large plastic particles, have been utilized for ML training after going through sample preparation steps [19], [20], [21]. These efforts represent promising steps toward developing automated methods for detecting and quantifying MNPs using ML techniques.\nML methods are commonly used to automate the detection and quantification of MNPs from data generated by traditional techniques. Each technique offers specific features of MNPs in the output data while introducing certain limitations. For instance, spectroscopy techniques like FTIR provide insights into the chemical composition of MNPs but face challenges in detecting nanoplastics due to laborious pretreatment require-ments and potential interference from carbon black, biological matter, or degradation products [26], [27]. Similarly, Raman spectroscopy, often used with ML, may encounter false signals from fluorescent materials present in polymers [28]. Confocal Raman spectroscopy, which can focus on a small volume within the sample to minimize interference, emerges as a promising solution to mitigate these errors [29]. Optical and Electron Microscopy imaging techniques can provide high-resolution images that reveal detailed surface morphology and topography of MNPs, allowing for precise size and shape analysis [30]. Some recent works have used these detailed images as input data for deep learning methods as summarized in Table I.\nDifferent methods are applicable for detecting objects. Ob-ject detection can be performed on top of semantic segmenta-tion, which separates particles from the background, followed by classification methods applied to the pixels labeled as particles. For example, a U-Net [31] model can be used for semantic segmentation, and a Convolutional Neural Network (CNN) can then classify the segmented pixels, as demonstrated in [22], [24]. It is also possible to perform instance segmen-tation directly from the start. For instance, a Mask R-CNN model can simultaneously identify regions of interest, classify each detected object, and generate a mask for each instance, as shown by [23]. Additionally, Faster R-CNN, primarily used for object detection, has been applied to microscopic images to classify microplastics into two polymer types [25]. Given the nature of our dataset, where overlapping and crowded MNPs are frequently observed, we have used Mask R-CNN, Faster R-CNN, and YOLOv10 [32], which can handle overlapping objects in most cases and have been widely validated across various applications [33].\nOur research introduces innovative solutions to the chal-lenges of microplastic detection. First, we present a method for the degradation of polymers and the emergence of MNPS similar to those existing in nature, providing a more accu-rate representation of environmental MNPs pollution. This approach allows for the generation of nanoplastics, which are mostly ignored in the literature due to their size making them difficult to detect and characterize. Second, commercially available polymers such as water bottles, plastic bags, and food packaging are used in this study to examine the effect of plastic degradation on consumer goods and the number, shape, and size of the MNPs that emerge from them. These data are cru-cial for decision-makers to legislate laws against plastic con-sumption efficiently. Third, we have developed the first open-source micrograph dataset which is annotated and labeled with the type of plastic and is derived from the emerged MNPs from bulk polymers in a simulated degradation setup. This dataset represents a step forward, offering a comprehensive tool for training and testing deep learning algorithms, with annotations that capture the nuanced characteristics of MNPs. Finally, leveraging this dataset, we apply state-of-the-art deep-learning-based methods to accurately detect and classify MNPs in micrographs. These methods enable the identification of MNPs with a level of accuracy previously unattainable, marking a crucial advancement in our ability to monitor and mitigate the impact of microplastic pollution.\nAs demonstrated in Table I, our dataset stands out in several critical aspects. To the best of our knowledge, this is the first labeled dataset that encompasses the four most common polymer types. Unlike most existing datasets, which are categorized based on the physical shape of particles, our dataset is labeled according to the most commonly used polymer types. Furthermore, our dataset covers a broader size range than other works and is among the few publicly available datasets on micro- and nanoplastic (MNP) imaging. As shown in Table I, our dataset offers significant advancements in the field of microplastic research.\nTo our knowledge, this is the first publicly available labeled dataset that includes the four most common polymer types. Unlike existing datasets, which often categorize particles based on physical shape, our dataset provides labels based on polymer types, offering a more practical classification. While some studies have utilized manually annotated images for deep learning applications involving microplastics, their datasets are not publicly accessible [22], [23], [25]. Notably, there is only one other open-source Scanning Electron Microscopy (SEM) dataset on microplastics, presented in [24], which categorizes particles by shape (e.g., fragments, fibers, and beads) and features a more limited size distribution. These contributions not only address the urgent environmental issue of microplastic contamination but also set a new benchmark for detecting and analyzing microplastics in aquatic environments, paving the way for future innovations in the field. The dataset is available for download from the project website\u00b9.\nSection II details the methods employed in the preparation, processing, and analysis of the Micro- and Nanoplastics (MiNa) dataset, including the sample preparation process, data organization, data annotation techniques, and data statistics. Section III discusses the data analysis, highlighting the signif-icant findings from the dataset. Section IV outlines the eval-uation protocol used to benchmark the dataset, describing the dataset configuration, evaluation metrics, networks employed, and experimental setups. Section V reports the results from dif-ferent experiments, highlighting the advantages and limitations of each network. Section VI provides a detailed discussion of the results, comparing the performance of different detection and classification methods. Finally, Section VII concludes the paper with a summary of the key findings and suggestions for future research directions."}, {"title": "II. METHODOLOGY", "content": "This section outlines the methodology employed in the preparation, processing, and analysis of the MiNa dataset. We begin by detailing the Sample Preparation Process in section II-A, where common types of consumer plastics are selected, degraded under controlled conditions, and analyzed using SEM. Following this, the Data Organization in sec-tion II-B describes the structuring of the dataset, including the generation of 256\u00d7256 patches to maintain image detail and manage computational load effectively. In section II-C, the meticulous process of annotating the SEM images is explained, which incorporates both manual and automated techniques to ensure accuracy and efficiency. Finally, the Data Statistics in section II-D presents a detailed analysis of the particle metrics across different polymer types, providing insights into the physical properties and statistical differences of the MNP."}, {"title": "A. Sample Preparation Process", "content": "Four of the most common types of consumer plastics were chosen for this study. Polypropylene (PP) and ex-panded Polystyrene (PS) as common food packaging materials, Polyethylene (PE) plastic bags, and Polyethylene Terephtha-late (PET) water bottles were obtained from Toronto grocery stores. These polymers were chosen due to their widespread application and environmental relevance. Each class represents a major category of plastic with distinct physical properties, applications, and recycling challenges, highlighting the impor-tance of their identification and classification in environmental studies and recycling efforts.\nTo prepare samples of MNP, a controlled experimental setup was arranged within a sanitized, enclosed chamber equipped with UV-C and visible light sources to mimic sunlight during degradation processes. UV-C light, chosen for its wavelength of 200 nm, was selected to accelerate degradation and am-plify the degradation rate. Fluorescent light was employed to simulate visible range wavelengths. Photo reactors were placed within the chamber equipped with a shaker on the bottom to simulate the mechanical abrasion process. Each photoreactor contained 300 ml of distinct degradation media (deionized water). Within each photoreactor, nine pieces of 2 \u00d7 2 cm\u00b2 of each polymer were immersed as sources of MNP production. Control reactors devoid of plastics were also included to monitor environmental contamination by dust and other particles. A visual representation of the experimental setup is provided in Figure 1.\nThe morphology of the polymers before and after degrada-tion, as well as the morphology of the MNP, were studied with a Zeiss EVO LS15 Scanning Electron Microscope equipped with a Bruker Energy-Dispersive X-ray spectroscopy (EDX) system, operated at an acceleration voltage of 20 kV using sec-ondary electrons. After 12 weeks of degradation, MNP were collected via vacuum filtration of an aliquot from the aqueous medium using Polycarbonate membranes with 200 nm pores. Subsequently, the membranes were gold-coated, and SEM images were captured. The magnification of the obtained micrographs varies in the range of 100\u00d7 to 1000\u00d7."}, {"title": "B. Data Organization", "content": "MiNa contains 105 SEM images, each with a resolution of 1280\u00d7960 pixels and featuring a scale bar at the bottom for size reference. Figure 2 shows samples of SEM images of each class in the dataset. These images depict pure samples, with each one showcasing microplastics from the previously mentioned categories. Our dataset is versatile and can be used for a range of applications in both chemistry and deep learning. To cover different use cases we organize our dataset in the following configurations:\n\u2022 MNP Detection: All the MNP identified in the images are marked in one category. This organization is suitable for training deep learning pipelines to detect the number of microplastics in a sample.\n\u2022 MNP Classification: Particles are marked as distinct cate-gories for each polymer type from which MNP emerged. This configuration can be used to classify different types of MNP.\nEach annotation in the dataset provides a mask of the particle, bounding box, area, diameter, and category which is dependent on the aforementioned data configuration. The provided information allows for comprehensive evaluation and validation of the detection model, ensuring accuracy in identifying and categorizing different particle types based on their physical characteristics and spatial properties."}, {"title": "C. Data Annotation", "content": "The particles in the SEM images were manually annotated using the V7 platform [34]. The annotation process took 4,800 person-hours, equivalent to 6 people working on the project for 5 months full-time. The annotations were cross-validated by team members to ensure high-quality results. Our micrographs exhibit varying concentrations of MNP. Some images have very high concentrations, making the annotation process challenging and time-consuming. In order to accelerate the process of annotation we used the following measures:\n1) Data pre-processing: Before manual segmentation, im-ages were pre-processed using custom Python scripts. This pre-processing consisted of hysteresis thresholding embedded in a graphical user interface, such that the annotator can manually select the upper and lower threshold bounds, and the resulting segmentation is displayed in real-time. The annotator can also specify an optional minimum segmentation area. This pre-processing technique is particularly effective in images in which there is a clear separation between particles and background. Automatic segmentation was manually validated, and augmented or re-segmented where appropriate.\n2) SAM guided segmentation: The V7 platform integrates Segment Anything Model (SAM) [35] for zero shot segmen-tation. We used SAM to speed up the annotation process. Primarily, point-based prompts in SAM were used to create rough segmentation for particles, which were then fine-tuned by the annotator to match the particle boundaries. It should be noted that SAM fails in low-contrast regions and small particles.\n3) Manual review: All images were then thoroughly manu-ally reviewed by different reviewers, in two rounds of review. The aim of this was to minimize any personal annotation bias and reduce false annotations.\n4) Automated review: We conducted a thorough review using a Python script to investigate overlapping annotations and instances where two separate contours were detected. This review was prompted by the identification of small holes in annotations and random small spots on the image annotations, likely caused by accidental clicks and easily overlooked during the manual review of crowded images. The identified instances were then manually corrected to ensure the accuracy of the annotations."}, {"title": "D. Data Statistics", "content": "Our dataset includes micrographs that visualize the MNP emission from bulk polymers in a simulated degradation process. The number of images per polymer type is detailed in Table II, totaling 105 micrographs that exhibit a range of particle densities and size distributions. Table III provides a comprehensive comparison of particle metrics across different polymer types. The metrics include the number of particles analyzed, average diameter (\u00b5m), average area (\u00b5m\u00b2), average aspect ratio, average form factor, average roundness, and average convexity. Aspect ratio, form factor, roundness, and convexity are important shape descriptors used to characterize the morphology of particles, such as microplastics [36]. Aspect ratio is defined as the ratio of the major axis to the minor axis of a particle, providing a measure of elongation, with a perfectly circular particle having an aspect ratio of 1. Form factor (f) is a measure of the compactness of a particle.\n\\(f = \\frac{4\u03c0 \\times A}{P^2}\\)   (1)\nwhere A is area and P is the perimeter. A form factor value of 1 corresponds to a perfect circle and values less than 1 indicate more complex shapes.\nRoundness (r) quantifies the smoothness of a particle's edges.\n\\(r = \\frac{4 \\times A}{\\pi \\times a_m}\\)   (2)\nwhere \\(a_m\\) is the major axis. Higher values indicate smoother and more circular shapes.\nConvexity is the ratio (\\(r_c\\)) of the perimeter of the particle to the perimeter of its convex hull (\\(P_{ch}\\)).\n\\(r_c = \\frac{P}{P_{ch}}\\)   (3)\nwhere a value of 1 indicates a perfectly convex shape.\nThese shape descriptors can be measured using image anal-ysis techniques, where high-resolution images of the particles are captured, segmented, and analyzed to trace boundaries and calculate the necessary parameters. This detailed charac-terization of particle shapes aids in classification and further analysis. To further understand the differences in the physical properties of the MNP that emerged from different polymers and to test whether it is possible to identify the type of the polymer based on the shape of the emerged MNP using image analysis tools, statistical analysis was conducted on the dataset. Normality and homogeneity of variances for each parameter (diameter, area, aspect ratio, form factor, round-ness, and convexity) were tested to determine the appropriate statistical test. Normality was tested using the Shapiro-Wilk test [37], and homogeneity of variances was tested using Levene's test [38]. The Shapiro-Wilk test results indicated that the data for each property in each polymer type were not normally distributed, with p-values less than 0.05. For example, the p-values for the diameter (dia) were all less than 0.001 for each polymer type. Similarly, Levene's test results showed that the variances for each property were not equal across polymer types, with p-values less than 0.05 for all tests. Because these assumptions were not met, using ANOVA would not be appropriate as it could lead to inaccurate results. The Kruskal-Wallis test [39], a non-parametric alternative to ANOVA, was chosen as it does not assume normality and is more robust to heteroscedasticity. The Kruskal-Wallis test is a non-parametric method for testing whether samples originate from the same distribution. It is used when the assumptions for ANOVA are violated. The Kruskal-Wallis test was performed by first ranking the combined data from all groups, calculating the sum of ranks for each group, and then using the formula for the Kruskal-Wallis test statistic:\n\\(H = \\frac{12}{N(N + 1)} \\sum_{i=1}^{k} \\frac{R_i^2}{Ni} - 3(N+1)\\)   (4)\nwhere N is the total number of observations, k is the number of groups, \\(R_i\\) is the sum of ranks for group i, and \\(n_i\\) is the number of observations in group i. The computed H was compared to the chi-square distribution with k 1 degrees of freedom to determine the p-value. The Kruskal-Wallis test results indicated significant differences p < 0.05) for all properties between the polymer types. Specifically, the results were as follows: diameter (\\(x^2\\) = 8169.39, p < 0.001), area (\\(x^2\\) = 8109.18, p < 0.001), aspect ratio (\\(x^2\\) = 80.41, p < 0.001), form factor (\\(x^2\\) = 399.43, p < 0.001), roundness (\\(x^2\\) = 542.76, p < 0.001), and convexity (\\(x^2\\) = 250.38, p < 0.001). When the Kruskal-Wallis test indicates significant differences, post-hoc tests like Dunn's test are used to deter-mine which specific groups differ from each other. Dunn's test with Bonferroni correction was performed by conducting pairwise comparisons between all groups, applying the Bonfer-roni correction to adjust the p-values for multiple comparisons to control the family-wise error rate, and calculating the test statistic for each pairwise comparison using the ranks of the data. Dunn's test with Bonferroni correction identified specific pairwise differences."}, {"title": "III. DATA ANALYSIS", "content": "The data extracted from the micrographs of the MNP derived from various polymers is invaluable for understanding plastic pollution and making more informed decisions. Fig-ure 3 illustrates the MNP particle size distribution in different classes of polymers. PS had 585 nanoplastics (particles smaller than 1 \u00b5m), while PP had a significantly higher count of 3078 nanoplastics. PET and PE had 2261 and 153 particles in the nano range, respectively. The high number of nanoplastics from PP and PET highlights the potential for these polymers to contribute to nanoscale plastic pollution, which can penetrate even deeper into biological tissues and ecosystems.\nThe analysis revealed that PP and PS exhibit the highest fragmentation into microplastics in the 0-5 \u00b5m range. Specif-ically, PP shows a significant number of particles (6568), while PS follows with 4744 particles. This suggests that PP and PS are more susceptible to breaking down into smaller particles compared to PET and PE, which show lower counts of 3486 and 513 particles, respectively. The high fragmentation rate of PP and PS into microplastics underscores their potential environmental impact, as smaller particles can disperse more widely and pose greater risks to marine and terrestrial ecosys-tems. In the 5-50 \u00b5m range, PS displays the highest number of particles, totaling 6412. This is substantially higher than PP (1383), PET (438), and PE (100).\nThe data indicate that PS is prone to fragmenting into this size range more extensively than the other polymers. The relatively lower counts for PP, PET, and PE in this range suggest a less frequent occurrence of these polymers breaking into larger microplastic particles. This could be attributed to differences in their chemical structure and resistance to en-vironmental degradation. Macroplastic particles (50-100 \u03bcm) are less prevalent across all polymer types, with PS having the highest count at 99 particles. PP and PE exhibit minimal counts (5 and 1, respectively), while PET has no particles in this range. The scarcity of macroplastic particles indicates that these larger fragments likely break down further into smaller sizes over time. The higher count for PS may suggest an initial stage of fragmentation before further degradation into microplastics.\nBased on table III, PS exhibits the highest number of particles (11,272) with an average diameter of 9.352 \u00b5m and a significantly larger average area of 50.032 \u00b5m\u00b2. In contrast, PE shows the lowest particle count (614) but a relatively larger average diameter of 3.175 \u00b5m and an average area of 8.313 \u00b5m\u00b2. These differences in metrics highlight the distinct morphological characteristics of particles in each polymer type, which are crucial for understanding their behavior and applications in various fields. The data on aspect ratio, form factor, roundness, and convexity further provide insights into the shape and structural properties of the particles, contributing to a deeper understanding of the material properties of each polymer type.\nBased on Dunn's test with Bonferroni correction, for di-ameter significant differences were found between all pairs except PET and PE. For area, all pairs showed significant differences except PET and PE. Aspect ratio showed sig-nificant differences between PS and PP, PP and PET, and PP and PE, but no significant differences between PS and PET, PS and PE, and PET and PE. Form factor showed significant differences between all pairs except PP and PET. For roundness, significant differences were found between all pairs except PET and PE. Convexity showed significant differences between all pairs except PP and PET.\nThe statistical analysis confirmed that the physical charac-teristics of microplastics varied significantly between the dif-ferent polymer types. These differences are crucial for under-standing the environmental impact and behavior of microplas-tics. The significant variation in properties like diameter, area, form factor, and roundness across polymer types highlights the need for tailored approaches in microplastic management and mitigation strategies. From an image analysis perspective, these results indicate that the shape and size of microplastic particles are influenced by the type of polymer. For instance, the significant differences in diameter and area suggest that the size distribution of microplastics can be used to distinguish between different polymers. The differences in form factor and roundness indicate that the shape of the particles also varies by polymer type, which can affect their behavior in the environment. These findings can be used to develop more effective methods for identifying and quantifying microplastics in environmental samples.\nMoreover, the findings highlight the significant environmen-tal impact of PS and PP due to their higher tendency to fragment into micro, nano, and larger microplastics. These small particles can penetrate various ecosystems, posing risks to aquatic life, and soil health, and potentially entering the food chain. The lower fragmentation rates of PET and PE lead into smaller particles suggest these polymers may pose a lesser immediate risk in terms of micro and nanoplastic pollution. However, all four polymers contribute to the overall environmental burden of plastic pollution."}, {"title": "IV. EVALUATION PROTOCOL", "content": "We conducted experiments to evaluate the detection and classification abilities of networks trained on the MiNa dataset. First, we explain the dataset structure, followed by the metrics used for evaluation. Next, we describe the networks and their chosen hyperparameters. Finally, we detail the experiments conducted and their outcomes."}, {"title": "A. Configuration of the Dataset", "content": "The SEM images from the MiNa dataset were split into image patches using a sliding window method. The square patches were generated in 128, 256, and 512-pixel variants. Among these, the 256x256 patches yielded the best results from the networks, providing an optimal balance between detail preservation and computational efficiency. This finding aligns with existing literature [40]. The patches were selected using a sliding window with a step size of 256 pixels to avoid overlap. Patches consisting entirely of background or particle pixels were excluded during post-processing. The remaining patches were randomly divided into 70% training, 15% validation, and 15% test splits. Additionally, annotation files are stored in both COCO [41] and YOLO [32] formats, two of the most commonly used formats in object detection."}, {"title": "B. Metrics", "content": "To benchmark the dataset, we chose four metrics for object detection. Object detection is applied to detect and count MNP directly in SEM images. We employed four key metrics for object detection experiments: AP50, precision, recall, and F1 score [42]. AP50 measures precision with a 50% Intersection over Union (IoU) threshold, assessing the model's ability to detect objects with moderate spatial overlap accuracy. Preci-sion evaluates the proportion of correctly identified positive detections out of all positive detections made by the model, re-flecting the accuracy of the model in identifying true positives. Recall measures the proportion of true positive detections out of all actual positive instances in the dataset, indicating the model's effectiveness in finding all relevant objects. The F1 score, a harmonic mean of precision and recall, provides a balanced measure of the model's performance, particularly when there is an uneven class distribution or a need to balance precision and recall."}, {"title": "C. Networks", "content": "We have trained and evaluated various networks using our dataset. Specifically, we utilized Faster R-CNN [43] and its extended version, Mask R-CNN [44], both with a ResNet-50 backbone. These networks have been widely applied in similar research and have demonstrated high accuracy [23], [45], [25]. Additionally, we conducted experiments with YOLOv10 [32]. YOLO networks are renowned for their high accuracy in object detection, making them suitable for our application. All networks were trained using Nvidia GeForce RTX 4080 GPU, and the best hyper-parameters were chosen. We used an Adam optimiser [46] with parameters: \u03b2\u2081 = 0.9, \u03b22 = 0.999. Different learning rates were chosen for YOLO and R-CNN networks according to our experiments. We trained YOLO for 150 epochs and Mask R-CNN for 50 epochs. After these values, the performances of the networks showed no further improvement. Hyper-parameters of each network are summarized in Table IV."}, {"title": "D. Experiments", "content": "The automatic detection and quantification of MNP is crucial for automating the measurement of plastic pollution. To enhance the effectiveness of our approach, we trained our networks to identify plastic particles without distinguishing between different polymer types in the initial experiment. Consequently, during the training phase, all four classes were uniformly labeled as \u2018MNP'. This simplification enables the network to focus on the fundamental task of detecting and quantifying plastic particles, paving the way for more special-ized and precise classification in subsequent experiments.\nIdentifying the type of plastic is crucial for understanding plastic pollution. In our second experiment, we evaluated the trained model's ability to predict the polymer type. Using four labels\u2014PE, PS, PP, and PET\u2014we trained and tested the network on randomly separated datasets. This approach allowed us to assess the model's performance in distinguishing between different types of plastic, providing more detailed insights into the composition of plastic pollution."}, {"title": "V. BENCHMARKING DATASET", "content": "For each experiment, we evaluated our dataset on the test set using the networks mentioned in Section IV-C. As detailed in Sections V-A and V-B, we conducted two distinct experiments. The results corresponding to these experiments are presented in Tables V and VI. Each section discusses the pros and cons of the respective approaches, highlighting open problems in particle detection and quantification in SEM images. This comprehensive benchmarking provides valuable insights into the effectiveness of different methods in accurately identifying and measuring MNP."}, {"title": "A. Experiment 1: MNP Detection", "content": "Using the network configurations detailed in Table IV, we conducted three experiments across images from four distinct classes to assess the network's proficiency in detecting MNP particles within image patches. As shown in Table V, Region-based Convolutional Neural Networks (R-CNN), including Mask R-CNN and Faster R-CNN, significantly outperform YOLOv10 in MNP detection.\nYOLOv10 frequently fails to identify partially visible parti-cles, as illustrated in Figure 4a. It also struggles with detecting overlapping particles in patches containing densely packed MNP, shown in Figure 4b, and often misses particles when there is significant variance in particle sizes, as in Figure 4c."}, {"title": "B. Experiment 2: Classification of MNPs", "content": "According to Table II, PE has the lowest number of par-ticles, although the number of its images is the same as PS. Consequently, PE images are less challenging since the particle density is lower as seen in Figures 7a, 8a, and 9a. Faster R-CNN and Mask R-CNN report their best metrics on PE. However, this is not the case for YOLOv10. It is worth mentioning that while PE images are simple, there are only 614 learning instances fed to the network as input which is considerably lower than 1,1272 instances of PS with the same number of images. Therefore, R-CNN-based networks are more robust to the number of training examples in our case.\nPS classification metrics show the lowest recall and F1 score among all classes across all networks. The dense and crowded image segments significantly affect the network metrics, lead-ing to fewer true positives for PS, as many particles are ignored in the background as seen in Figures 7b, 8b, and 9b. A key reason for this issue is the limited ability of these networks to handle overlapping bounding boxes. Additionally, the reliance on predefined anchor boxes and aspect ratios further limits the networks' performance. Another contributing factor could be the high variability in the size and shape of the particles, which complicates accurate detection.\nPET and PP classes have the highest number of small particles among all classes, with PP particles being even smaller. This small particle size is a limiting factor in metrics, especially recall, as small particles are sometimes overlooked by networks (Figures 7d, 8d, 9d), causing a substantial drop in recall. Although there are more training instances for PP compared to PET, the effect of small particles still carries significant weight. Figures 7 to 9 show the output of the YOLOv10, Faster R-CNN, and Mask R-CNN in different classes. In all figures, some MNPs on the edge of the patches are not detected, which significantly affects the recall reported for each class, as shown in Table VI. It is impossible to avoid the partial appearance of these particles in the patches since some images are very crowded. It is worth mentioning that YOLOv10 outputs highly overlapping bounding boxes for large particles or particles with irregular shapes. Particles smaller than 15\u00d715 pixels are also ignored by both algorithms in several cases as visible in Figures 7 to 9."}, {"title": "VI. DISCUSSION", "content": "As discussed in Section V, both Faster R-CNN and Mask R-CNN outperform YOLOv10 in all detection and classification experiments. In terms of precision, both Faster R-CNN and Mask R-CNN perform well, as shown in Figure 10a. How-ever, Faster R-CNN demonstrates slightly better recall values, resulting in higher F1 scores across all classes, as illustrated in Figure 10b. The performance gap between Faster R-CNN and Mask R-CNN is particularly evident under the AP50 criterion. This discrepancy is influenced by the complexity of images within each class, being more pronounced in PS than in PE images.\nWe present the normalized confusion matrix for Faster R-CNN in Figure 11. The results demonstrate that when MNPs are accurately detected and separated from the background, they can be classified with high accuracy. Specifically, only 0.29% of PET particles are misclassified as PP, and only 0.07% of PS particles are misclassified as PP. According to Table III, PP and PET share similarities in terms of shape metrics (form factor, roundness, and convexity), which may explain the minor error in classification. Furthermore, PS and PP have similar convexity values, contributing to occasional misclassification. Despite these nuances, the results indicate that the network is able to effectively distinguish between the different particle classes as long as they are differentiated from the background.\nAmong the particles that the network fails to detect (false negatives), PS particles represent the largest proportion at 69.9%, as shown in Figure 12. This highlights the network's challenge with overlapping bounding boxes, as PS images contain the highest average number of particles per image and largest average surface area, as detailed in Tables II and III. PP particles, being the second most frequently overlooked after PS, are noteworthy for having the highest particle count among the classes and the smallest average particle size. PET particles account for 12.7% of false negatives, which can be attributed to their larger average area compared to PP particles and a lower average number of particles per image. As expected, PE particles exhibit the lowest rate of false negatives, due to their less crowded images and the largest average area after PS.\nIt would be beneficial to test the accuracy of networks using image patches containing mixed particles to evaluate network performance more comprehensively. However, the lack of ground truth data restricts our ability to generate mixed SEM images, presenting a valuable area for future research. Aug-mented images of mixed particles could be created to assess the network's ability to predict particle types, but such images may not replicate the accuracy of real ones. All tested networks are susceptible to errors in scenarios involving crowded image patches, overlapping particles"}]}