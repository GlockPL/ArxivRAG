{"title": "HUMVI: A Multilingual Dataset for Detecting Violent Incidents Impacting Humanitarian Aid", "authors": ["Hemank Lamba", "Anton Abilov", "Ke Zhang", "Elizabeth M. Olson", "Henry K. Dambanemuya", "Jo\u00e3o C. B\u00e1rcia", "David S. Batista", "Christina Wille", "Aoife Cahill", "Joel Tetreault", "Alex Jaimes"], "abstract": "Humanitarian organizations can enhance their effectiveness by analyzing data to discover trends, gather aggregated insights, manage their security risks, support decision-making, and inform advocacy and funding proposals. However, data about violent incidents with direct impact and relevance for humanitarian aid operations is not readily available. An automatic data collection and NLP-backed classification framework aligned with humanitarian perspectives can help bridge this gap. In this paper, we present HUMVI \u2013 a dataset comprising news articles in three languages (English, French, Arabic) containing instances of different types of violent incidents categorized by the humanitarian sector they impact, e.g., aid security, education, food security, health, and protection. Reliable labels were obtained for the dataset by partnering with a data-backed humanitarian organization, Insecurity Insight. We provide multiple benchmarks for the dataset, employing various deep learning architectures and techniques, including data augmentation and mask loss, to address different task-related challenges, e.g., domain expansion. The dataset is publicly available at https://github.com/dataminr-ai/humvi-dataset.", "sections": [{"title": "1 Introduction", "content": "Violent events that impact humanitarian efforts, such as the looting of aid trucks and the kidnapping of aid workers, frequently hinder the delivery of life-saving aid and protection efforts, with devastating consequences for conflict-affected populations. Conflicts also severely disrupt existing food systems, healthcare, and education structures (Gates et al., 2012), leading to food insecurity, malnutrition (Martin-Shields and Stojetz, 2019), increased mortality due to inadequate healthcare (Garry and Checchi, 2020), and significant educational disruptions for children (Kadir et al., 2019). The systematic collection and collation of information about such events from multilingual data sources are not just crucial, but urgent, to ensure that decision-makers have access to the right information to support humanitarian operations and adequately respond to local needs.\nAggregated information about violent events that impact humanitarian efforts can be operationalized by humanitarian organizations to systematically inform a wide range of different responses, including security risk management, program planning, and advocacy prioritization. Resources are severely limited during crisis response, and manual data collection in conflict-affected and highly insecure environments is rarely a priority. The use of NLP techniques can readily reduce the labor and resources required to maintain such a data collection pipeline. Importantly, it can also be carried out remotely, thus reducing the security exposure of those supporting a humanitarian response through data collection and analysis. Most NLP capacity in the humanitarian context has focused on English, limiting the use of models in conflict-affected countries where information is shared in French, Arabic, and other languages.\nIn order to process large amounts of disparate"}, {"title": "2 Related Work", "content": "data to detect violent events, it is essential to build NLP models that can automatically detect such incidents. Next, these incidents should be tagged appropriately with the relevant type of humanitarian operation, e.g., an event where aid workers are threatened or harmed would be tagged as aid security.\nWe identify two primary gaps in the current publicly available datasets: (1) Most are focused on identifying a single type of event, such as disaster-related information (Alam et al., 2021, 2018), specific threats against human rights defenders (Ran et al., 2023), or civil unrest (Delucia et al., 2023). Even when datasets cover a wide range of events and associated tags (Raleigh et al., 2010), these tags often do not indicate the specific humanitarian sectors impacted by the event and lack information related to downstream humanitarian efforts, such as healthcare or food security (Trivedi et al., 2020). (2) Most of the humanitarian event detection datasets are disproportionately English and this has been identified as a key issue for improving adoption of NLP techniques in the humanitarian sector (Kreutzer et al., 2019; Rocca et al., 2023). The dataset presented in this paper is multilingual, and we hope it will support and encourage NLP practitioners to create multilingual models for humanitarian purposes.\nTo address these two issues, we introduce a new dataset HUMVI (HUManitarian Violent Incidents). This dataset comprises 17, 497 articles in three languages, with each article tagged for its relevance and, if relevant, categorized by the key humanitarian response sector where it is relevant, i.e., aid security, education, food security, health, and protection (a sample is shown in Figure 1).\nThere are three qualities of this dataset that ensure its value to the field.\nHumanitarian Expert Verified. A key challenge of building such a dataset is obtaining labels from the end-users, i.e. humanitarian experts, who will consume the tagged dataset to provide aid-centred event monitoring and context analysis. To solve this, we partner with Insecurity Insight\u00b9, a data-driven humanitarian to humanitarian (h2h) organization that has expertise in applying and consuming tagged news articles in order to support the aid sector with aid-focused information.\nAI for Social Good. Recently, researchers have focused on multiple problems under the umbrella"}, {"title": "2.1 Event Detection", "content": "of AI for Social Good (AI4SG) (Shi et al., 2020). However, some of the SDGs (Sustainable Development Goals) are under-represented within AI community efforts (Gonzalez et al., 2023), including SDG 2: Zero Hunger (Fund, 2015). A focus of our work is food security, which aims to tag conflict events impacting food security. We believe that having a labeled dataset directly related to this SDG will encourage more NLP researchers to develop technology to benefit organizations that rely on understanding the impact of this SDG.\nDomain Expansion. The dataset-building task was carried out in conjunction with Insecurity Insight. While the organization had previously developed tagging systems for health, education, protection, and aid security events, expanding to a new category (food security) and new languages (French and Arabic) was an obstacle for them, given their limited staffing. This mirrors a challenging problem in the NLP space: domain expansion, i.e., expanding a machine learning model to work with new classes and on new input sources. In this paper, we provide two versions of the dataset: (a) HUMVI-core and (b) HUMVI-expansion. The core dataset focuses on four possible event types and is available only in English. However, the expansion dataset extends the core dataset by adding two new languages (French and Arabic) and one new category, food security. We believe that the expansion dataset will enable NLP researchers to benchmark their solutions for the real-world challenges frequently encountered by humanitarian organizations while working in a capacity-constrained setting.\nTo summarize, our contributions are follows:\n[C1] Humanitarian Violent Event Dataset. We provide a comprehensive multilingual dataset of violent events, labeled by humanitarian experts for relevancy to multiple key humanitarian aid sectors.\n[C2] AI for Good. To the best of our knowledge, this is the only dataset that provides instances of conflict events that might lead to food insecurity, an under-represented research area.\n[C3] Domain Expansion. HUMVI-expansion provides a dataset that is representative of a challenging real world problem, i.e., resource-constrained domain expansion (Yang et al., 2022).\n[C4] Baseline Experiments. We show leading NLP models perform on this dataset, thus setting a baseline for future work while showcasing the complexities and challenges of adapting NLP techniques to real world scenarios.\nWe make the dataset and associated repository"}, {"title": "2.2 NLP for Social Good", "content": "is public at https://github.com/dataminr-ai/humvi-dataset."}, {"title": "2.3 Domain Expansion", "content": "Advancements in NLP technologies have broadened their application scope across education (Kasneci et al., 2023; Madnani and Cahill, 2018), assistants (de Barcelos Silva et al., 2020), legal fields (Martinez-Gil, 2023), and more. With these advancements, researchers are increasingly prioritizing NLP applications for societal benefit (Cowls et al., 2021). Significant positive impacts have\nA key challenge in NLP research is to develop multilingual models. Early methods included cross-lingual transfer of monolingual embeddings, aligned using unsupervised techniques (Lample et al., 2017; Conneau et al., 2017). A natural extension was to create multilingual embeddings that can be used directly (Ruder et al., 2019). Following the success of transformer models, pre-trained multilingual models were created (Devlin et al., 2018; Ebrahimi and Kann, 2021). With the availability of large-scale data and compute, massive encoder-decoder models (Liu et al., 2020; Xue et al., 2020) and then eventually decoder-only models (Achiam et al., 2023) were trained. These models can be leveraged in zero-shot or few-shot settings and still be performant without requiring any specific fine-tuning. Another set of approaches includes augmenting the training dataset by translating it into the target language (Edunov et al., 2018).\nAnother key challenge is to how to extend the model to new categories, where getting high-quality labeled data for training is expensive or unavailable. Data augmentation is one of the most popular techniques that transforms existing data in a reliable class-preserving manner to create new data (Chen et al., 2023). Self-training (Du et al., 2020; Scudder, 1965) is a promising technique that enables leveraging unlabeled datasets to create pseudo-labels which can be used to further improve the model. Other techniques like multi-task learning and consistency regularization have also been used to tackle this issue. However, more recently, the most popular methods have been to scale up language models and leverage their zero-shot or few-shot capabilities to achieve strong performance (Brown et al., 2020). The dataset presented in this paper poses multilinguality and limited data learning as two of its main challenges. As part of our process of benchmarking the dataset, we apply the methods mentioned above and demonstrate their performance."}, {"title": "3 Data Collection", "content": "Data Collection (GDelt, NewsAPI, OSAC) Relevance & Category Classification Article Database (for Analysis)"}, {"title": "3.1 Data Collection Overview", "content": "As mentioned in Section 1, we worked closely with Insecurity Insight to create HUMVI. Insecurity Insight already had an established workflow for sourcing relevant articles, after which humanitarian experts classify them for relevance, and then tag them with the appropriate categories that capture the downstream humanitarian concern. They were also leveraging multiple ways to identify links to news articles, which we list below:\nNewsAPI. Researchers have extensively used NewsAPI (Lisivick, 2018) to collect news articles for various purposes (Keh et al., 2023; Jain et al., 2024). Similarly, for this dataset, NewsAPI was used to search for English articles about violent conflict incidents using a curated list of domain-specific keywords, detailed in Appendix A.1.\nOSAC. The Overseas Security Advisory Council\u00b2 is a US Department of State organization whose primary purpose is to share critical information related to security. As part of this effort, at regular intervals, they share English articles selected by OSAC analysts that are highly relevant to global security. This list is collected by Insecurity Insight, and added to the queue to be reviewed by their experts.\nManual Collection. Besides classifying articles as relevant and tagging them with appropriate categories, experts at Insecurity Insight also manually upload news articles to the database. These articles may have been missed by automatic scrapers, and"}, {"title": "3.2 Source Expansion", "content": "One of the key challenges that motivated the collection of HUMVI was the need to expand the current data collection and tagging process to include a new category (food security) and new languages (French and Arabic), which were rarely covered in the original sources. To enhance sourcing, we added GDELT (Leetaru and Schrodt, 2013), a large open-source database of multilingual news article links. We query the GDELT Event Database for articles which are regionally tied to either Burkina Faso, Cameroon, the Central African Republic, the Democratic Republic of the Congo, Palestine, Haiti, Mali, Niger, Nigeria, Somalia, Syria or Yemen. We scrape the full article content and detect the article language, and English, French and Arabic articles are added to the database."}, {"title": "3.3 Labeling Process", "content": "Once the potentially relevant news articles are identified, the title and full text of the news article is collected. The human expert first annotates the relevance of the article (a binary classification). The relevance is determined by assessing whether the article describes a conflict event and the event belongs to one or more of the pre-defined humanitarian categories (aid security, education, food security, health and protection). For a category to be applied the article should describe reports of conflict events happening at a particular time and location, typically described as being carried out by a perpetrator against a given person who fulfills"}, {"title": "3.3.1 Quality Control", "content": "a specific humanitarian function (e.g. an aid or health worker) or essential civilian infrastructure (e.g. aid convoys, hospitals, bakeries or schools) 3. A brief overview of the categories is given in Table 2 (detailed description in Appendix B).\nWe obtained the labels in two ways: (1) On-the-job labeling (OTJ) and (2) Offline labeling (OFL). Data collected via OTJ originates from the partnering organization's established production workflows and was collected live from the English-only data sources News API and OSAC. The scraped article title and content is reviewed by the expert annotators in their internal annotation tool before they determine whether the article is relevant and assign the event categories. For OFL, we worked with 7 humanitarian experts from Insecurity Insight to expand the data collection to include articles from GDELT in English, French, and Arabic. We follow similar annotation guidelines as in OTJ. The annotators performed the offline task in spreadsheets. They reviewed the scraped article title and full text before assigning one or more event categories as per the guidance. If none of the event categories are assigned, the sample is marked as non-relevant. HUMVI contains OTJ labels for most training data and OFL labels for the test data.\nBoth methods of soliciting labels are carried out by a team of domain experts trained by Insecurity Insight. For OTJ labeling, the labeling correctness is ensured by significant training efforts, well defined guidelines, and the periodic review and correction"}, {"title": "3.4 Data Description", "content": "HUMVI includes 17,497 labeled articles in English, French, and Arabic. The high-level statistics are listed in Table 4. English articles are predominantly sourced from NewsAPI and OSAC, whereas French and Arabic articles were either sourced from GDELT or collected manually as shown in Table 4. Note that the NewsAPI, OSAC and English articles are disproportionately high in our dataset because the majority of those instances were part of the standard workflow at Insecurity Insight when data collection began. Labels for NewsAPI and OSAC articles have been obtained through OTJ labeling, whereas all GDELT and manually collected articles are labelled through OFL."}, {"title": "4 Dataset Split and Variants", "content": "We provide two different variants of the dataset described in the previous section.\nHUMVI-core. The core dataset is English only, and contains labels for four categories relevant to humanitarian work \u2013 it does not include any label for food security. The dataset consists of 15, 631 news articles.\nHUMVI-expansion. The expansion dataset is centered on the real world challenge of expanding to a new category (food security) and new languages (French, Arabic). This dataset variant is a superset of HUMVI-core, and contains 17, 497 articles. This dataset poses multiple interesting challenges for an NLP practitioner - (i) how to expand to new modeling classes and languages (ii) how to build performant models in a resource-constrained manner.\nFor both variants of the dataset, we temporally split the data on 2024-02-08 such that all of the articles before this date are part of the train set. The test set is collected exclusively through the OFL labeling process and consists of news articles collected after 2024-03-15. All news articles collected between 2024-02-08 (train cutoff) and 2024-03-15 (test start date) are part of an unlabeled dataset and are also released along with the paper. We present detailed numbers on the dataset split in Table 5. Note that in the training dataset there are very few instances of French and Arabic, however, in the test dataset, there are a similar number of articles for all three languages. Similarly, the presence of the food security tag is under-represented in the training dataset compared to other categories, but equally represented in the test dataset.\nAlong with HUMVI-expansion, we also release a large collection of unlabeled data that can be used to improve the model's performance through active learning (Settles, 2009) or through semi-supervised learning (Learning, 2006)."}, {"title": "5 Models", "content": "We experiment with multiple different model types to establish benchmarks for two tasks on HUMVI: (1) relevance classification (i.e., predict if the given news article is relevant or not); and (2) category classification (i.e., predict one or more categories where news article might be relevant)."}, {"title": "5.1 Base Architectures", "content": "Fine-tuned Models. In our experiments, we train separate models for each task. However, they could also be modeled jointly by training a single model to predict both relevance and category labels - which we leave as an open research direction. We experiment with multiple different model architectures to benchmark their performance on HUMVI.\nWe experiment with fine-tuning multiple different transformer models, specifically monolingual (English) and multilingual variants of DistilBERT (Sanh et al., 2019), BERT (Devlin et al., 2018) and ROBERTa (Liu et al., 2019; Conneau et al., 2019).\nLLM. We benchmark five zero-shot LLM models on the dataset: two open-source models, DBRX (Databricks, 2023) and LLaMa3-70b (AI@Meta, 2024), and three proprietary models, GPT-4 (Achiam et al., 2023), GPT-40 (OpenAI, 2024), and Mistral Large (AI, 2024). All models use temperature = 0 and the same chain-of-thought-style prompt, derived from the annotation protocol with minimal tuning. The LLM experiments are set up as a single implicit category classification task: if an article is labeled with a category, it is considered relevant."}, {"title": "5.2 Domain Expansion", "content": "To handle domain expansion we experiment with the following two approaches.\nTranslation Augmentation. In order to adapt to new languages, we create synthetically labeled data by translating English samples into French and Arabic (Edunov et al., 2018).\nMasking Loss. Since labeling for the food security tag started post the train cutoff date in OFL manner, most instances in the HUMVI-expansion training dataset lack this label. To prevent learning from partially labeled data, we further use label loss masking (Duarte et al., 2021) in category classification. The Binary Cross Entropy (BCE) loss is average pooled only over labeled categories, excluding food security."}, {"title": "6 Results", "content": "Metric of Choice. While there is a range of metrics that could evaluate model performance, we settled on the following use-case-specific metrics together with Insecurity Insight. For the relevance classifier, we compute precision at a minimum recall of 0.8 to surface more relevant content. For the category"}, {"title": "7 Conclusions", "content": "In this paper, we presented HUMVI, a multilingual dataset of 17K news articles classified by their relevance to humanitarian aid efforts and tagged with appropriate categories. Developed in collaboration with Insecurity Insight, this dataset addresses real-world challenges in optimizing data workflows with limited resources using NLP techniques. We trained and evaluated multiple NLP models for relevance and event classification, showing that both fine-tuned models and zero-shot LLMs can perform well, leaving room for improvement."}, {"title": "8 Limitations", "content": "Like any data-based study, the dataset presented here is subject to multiple limitations. We take a critical approach for the dataset we have created and list the limitations and biases that could exist at each stage of the process followed. For data collection, our dataset comes from a limited set of countries and hence might not be readily extensible to different parts of the world that we have not covered. Additionally, the differences in event reporting and content might need to be analyzed before being applied to a new geographic area. Similarly, we leverage three different ways of obtaining news article links. However, these may be systematically biased towards certain types of content, and they may ignore other types of content, e.g., hyperlocal news reporting in local languages that these link curation systems have not included. We rely heavily on leveraging GDELT to retrieve news articles in different languages from varied geographies. However, GDELT's coverage might not be equitable across different languages and regions (Leetaru and Schrodt, 2013), resulting in under-representation of certain geographies. For annotation, we leverage the labels that have been defined by Insecurity Insight. Though the labels were created with due deliberation and discussion with humanitarian experts, they are still tuned for Insecurity Insight's needs. Therefore, if another organization uses the dataset, they need to align with the label definitions provided here or relabel relevant subsets of the dataset for their needs if the definitions do not align. We hope that this disclosure will be helpful to any user of this dataset in the future."}, {"title": "Ethical Considerations", "content": "The dataset is created using publicly available news articles, and does not breach any contract for obtaining the data. We have ensured that the web scraper only accesses publicly available data and excludes any data behind a paywall. Furthermore, we release only the links to the article, along with a scraper code. Therefore, if any source website changes its web scraping policies in the future, that change will be reflected when retrieving the articles. Although we cannot guarantee that PII (personally identifiable information) is not included in any of the news articles, we only source from published, publicly available materials. For the annotation process, we leveraged internal humanitarian experts at the partnering organization Insecurity Insight, who were duly compensated for their services during"}, {"title": "D Error Analysis", "content": "the course of their professional, paid employment."}, {"title": "D.1 Misclassification Themes", "content": "We identified two main classes of inputs for which most of the models did not perform well.\nMissing Context. In some cases, the victim entity is directly related to the humanitarian aid response category and it is hard for models to understand the context. For instance, in Example D.1.1, the victims are employees of World Central Kitchen, an organization that provides meals to those affected by conflict. However, the models categorized them merely as aid workers, overlooking the crucial context that targeting workers of a meal-providing organization directly impacts food security.\nIndirect Impact. For certain examples, the model focuses on the first category and ignores the rest of the text that could be detrimental for predicting other different categories that could be added for direct or indirect impact. An example is shown in Example D.1.2. In the example, since it was an attack on UNICEF supplies, the model was able to identify the context of aid workers or their aid being targeted, but not the indirect impact of that aid being blocked which is lack of crucial health supplies and food supplies."}, {"title": "D.1.1 Example of Missing Context Misclassification", "content": "News Article: US Secretary of State Antony Blinken said on Tuesday that Washington has urged Israel to conduct a swift, thorough and impartial investigation into Monday night's air strike that killed seven aid workers with the World Central Kitchen charity in Gaza. he said of the NGO workers killed in the strike. over the accidental deaths of seven World Central Kitchen (WCK) employees in Monday's strike. take immediate steps to protect aid workers and facilitate vital humanitarian operations in Gaza....\nGround Truth Label: food-sec, aid-sec\nPredicted Label: aid-sec"}, {"title": "D.1.2 Example of Indirect Impact Misclassification", "content": "News Article: UNICEF said one of their containers carrying essential supplies was looted by gangs at Haiti's main port. The United Nations Children's Fund (UNICEF) said Saturday that one of its 17 aid containers at Haiti's main port was looted. The container was carrying \"essential items for maternal, neonatal, and child survival, as well as critical supplies for early childhood development and education, water equipment, and others,\" the agency said. \"Looting of supplies that are essential for life saving support for children must end immediately,\" Gang violence has spiked throughout the country in recent days. Some hospitals in the city have been forced to close over safety concerns.... Shortages of electricity, fuel and medical supplies have affected hospitals is supported by the Caribbean regional body CARICOM, the United Nations and the United States.\nGround Truth Label: food-sec, aid-sec, health\nPredicted Label: aid-sec"}]}