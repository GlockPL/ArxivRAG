{"title": "Class Incremental Fault Diagnosis under Limited Fault Data via Supervised Contrastive Knowledge Distillation", "authors": ["Hanrong Zhang", "Yifei Yao", "Zixuan Wang", "Jiayuan Su", "Mengxuan Li", "Peng Peng", "Hongwei Wang"], "abstract": "Class-incremental fault diagnosis requires a model to adapt to new fault classes while retaining previous knowledge. However, limited research exists for imbalanced and long-tailed data. Extracting discriminative features from few-shot fault data is challenging, and adding new fault classes often demands costly model retraining. Moreover, incremental training of existing methods risks catastrophic forgetting, and severe class imbalance can bias the model's decisions toward normal classes. To tackle these issues, we introduce a Supervised Contrastive knowledge distillation for class Incremental Fault Diagnosis (SCLIFD) framework proposing supervised contrastive knowledge distillation for improved representation learning capability and less forgetting, a novel prioritized exemplar selection method for sample replay to alleviate catastrophic forgetting, and the Random Forest Classifier to address the class imbalance. Extensive experimentation on simulated and real-world industrial datasets across various imbalance ratios demonstrates the superiority of SCLIFD over existing approaches. Our code can be found at https://github.com/Zhang-Henry/SCLIFD_TII.", "sections": [{"title": "I. INTRODUCTION", "content": "Data-driven fault diagnosis techniques have gained significant prominence over the past two decades [1-4]. However, most of them necessitate sufficient training data to achieve reliable modeling performance[5\u20138]. Unfortunately, fault data is typically limited in comparison to normal data. This is because engineering equipment primarily operates under normal conditions, and the probabilities of faults vary across different working environments. Besides, fault simulation experiments are costly and inevitably deviate to some extent from real industrial environments. These possible reasons consequently contribute to class imbalance and a long-tailed distribution among different conditions [9]. The performance of the model typically suffers as it tends to prioritize the normal class, consequently neglecting fault classes or tail classes. Therefore, extensive research efforts have been devoted to addressing this challenge, leading to significant advancements in the field.\nClass-imbalanced and long-tailed fault diagnosis are usually effectively addressed by data resampling, cost-sensitive learning, and information augmentation [9]. Concretely, data resampling mitigates the class imbalance issue by reconstructing a class-balanced dataset [10]. Cost-sensitive learning aims to compensate for the impact of class imbalance during the training process by adjusting the weights of different classes' influence on the target function [11]. Information augmentation-based approaches, which primarily involve data generation and transfer learning, aim to address the imbalance problem by leveraging auxiliary data or diagnostic experience from other datasets. Specifically, data generation utilizes generative models such as generative adversarial networks [12] and variational auto-encoders [13], to produce additional samples, thereby augmenting the dataset by simulating the original distribution of the source data. Transfer learning seeks to enhance model performance by transferring information, such as data and features, from a source domain to a target domain [14]. [15] use class activation maps to separate features into class-specific features and common ones, which are then combined to augment tail classes.\nBesides the challenge posed by the limited quantity and variety of fault samples available for real-world industrial fault diagnosis, additional fault samples from new classes, i.e., incremental samples of new fault classes, can be continuously obtained as the industrial process progresses. However, the methods mentioned above only concentrate on mitigating the class imbalance issue but totally overlook the model's adaptation ability to recognize fault samples from new classes encountered by fault diagnosis models. As a result, when employing the fault diagnosis methods mentioned above in incremental scenarios, the need to abandon prior efforts and retrain the well-trained model each time new class samples emerge incurs a significant computational cost and time expense. Furthermore, as incremental learning progresses and the model is trained on new types of data, it may encounter catastrophic forgetting [16, 17], i.e., the new learned knowledge may overwrite the old previously learned knowledge, so the model performance continually declines. Therefore, effective class incremental fault diagnosis methods are also essential to mitigate catastrophic forgetting.\nCurrently, there is growing interest in incremental learning methods for fault diagnosis [18]. [19] propose a CDCIBN framework for cross-domain incremental fault diagnosis. [20] introduce a Self-Organizing Fuzzy classifier to handle large- scale, streaming data in dynamic environments. [21] use"}, {"title": "II. MOTIVATIONS AND BACKGROUND THEORY", "content": "As we described in Sec. I, it is vital to address the imbalanced and long-tailed fault diagnosis in the class incremental learning setting, but few works tackle the circumstances. Moreover, as shown in Tab. III in our experiments, we find traditional frameworks for class incremental learning in the balanced class setting, such as iCaRL [32], EEIL [34] also have poor performances under imbalanced and long-tailed settings. To find out the reasons behind their poor performances, we have the following experiments and observations.\nInitially, we find that the representation learning capability of iCaRL [32], which utilizes cross-entropy loss as the classification loss, is insufficient to extract discriminative features from limited fault data. We visualize the T-SNE feature embeddings extracted by iCaRL [32] under the imbalanced case of the TEP dataset. We have observed that in the T-SNE visualization, features of different classes are intertwined and"}, {"title": "III. METHODOLOGY", "content": "In the upcoming subsections, we will present the principal process of class incremental fault diagnosis through SCLIFD and provide a detailed explanation of each stage.\nSCLIFD class-incrementally diagnoses limited fault data consisting of four steps, as shown in algorithm 1:\n1) Process Data. In each session, SCLIFD is exposed to samples from new classes. This new class data is then merged with an exemplar set, which is created using the MES method (refer to algorithm 2 and Sec. III-C). After combining, the data undergoes augmentation and serves"}, {"title": "B. Self-Supervised Contrastive Learning and SCL", "content": "The general concept of self-supervised contrastive learning aims to minimize the distance between each anchor and its positive sample while maximizing the distance between the anchor and other negative samples in the embedding space [30]. Specifically, let a set of N randomly sampled sample/label pairs be denoted as {xk, Yk}k=1...N. An augmented batch comprising 2N pairs {xi, Yi}i=1...2N of the same label as the source sample is generated and utilized for training. The two random augmentations of \u00e6k(k = 1 . . . N) are denoted as 2k and 22k-1, with one arbitrarily designated as the anchor and the other as the positive. Their indices are denoted as i\u2208\u0399 = {1...2N} and j(i) respectively. The remaining 2N - 2 samples in {xi, Yi}i=1...2N are considered negatives. The self-supervised contrastive loss is defined as follows:\n$\\Cself = \\frac{1}{|I|} \\sum_{i \\in I} \\left[ -log \\frac{exp (z_i \\cdot z_{j(i)} / \\tau)}{\\sum_{a \\in A(i)} exp (z_i \\cdot z_a / \\tau)} \\right]$(1)"}, {"title": "C. Balanced Random Forest (BRF) Classifier", "content": "The BRF classifier [31] aims to mitigate the bias towards the majority class that is present in standard random forest algorithms by ensuring that each tree is exposed to a balanced representation of both classes. It can be described as follows:"}, {"title": "B. Update Feature Extractor by Supervised Contrastive Knowledge Distillation", "content": "As illustrated in Fig. 4 and algorithm 2, we propose supervised contrastive knowledge distillation to update the feature extractor in each incremental session. We have introduced SCL in detail in Sec. III-B. Lscl loss is obtained from the output features of the current feature extractor to enhance SCLIFD's feature extraction ability. We will explain how we integrate SCL with Knowledge Distillation (KD) to train the feature extractor. It can alleviate catastrophic forgetting because it can effectively enhance the performance of the feature extractor in the current session for old classes under the supervision of the one in the last session.\nSpecifically, let a \u2208 A(i) = I\\{i}. Then each xi and xa are mapped by the feature extractor network 6e and normalized into feature vector representations zi and za, i.e., z = po(x). P(zi; za) denotes the similarity score between zi and za. Then the softmax function is applied with the temperature scaling factor 7 to P(zi; za), resulting in:\n$P(z_i; z_a) = \\frac{exp (z_i \\cdot z_a/\\tau)}{\\sum_{j \\in \\mathcal{A}(i)} exp (z_i \\cdot z_j/\\tau)}$(3)\nNext, the last session's feature network is frozen to be utilized as the teacher network. We adopt cross-entropy loss to obtain the KD loss, which is defined as follows:\n$\\mathcal{L}_{dis} (\\varphi_{\\theta}, \\varphi_{\\theta'}) = \\frac{1}{2N} \\sum_{i \\in I} \\sum_{a \\in A(i)} \\ell_{i.a} = - \\frac{1}{2N} \\sum_{i \\in I} \\sum_{a \\in A(i)} P(\\tilde{z}_i; \\tilde{z}_a) log (P(z_i; z_a)) =- \\frac{1}{2N} \\sum_{i \\in I} \\sum_{a \\in A(i)} (\\varphi_{\\theta'} (\\tilde{x}_i); \\varphi_{\\theta'} (\\tilde{x}_a)) log (P(\\varphi_{\\theta}(x_i); \\varphi_{\\theta}(x_a))$(4)\nIn this way, we make feature space distillation for the current feature extractor, which emulates the latent feature space of the teacher. This is distinctive from the previous work [32] which makes response distillation [39], i.e., classification logits distillation from a teacher network.\nAs demonstrated in algorithm 2, Lscl is merged with Ldis to form the ultimate Lencoder. This is utilized to update the feature network during each incremental session. The revised feature network is then employed in the ultimate stage of online fault diagnosis.\nOur Supervised Contrastive Knowledge Distillation extends standard SCL by introducing cross-session knowledge transfer. Instead of only learning better features within a session, we distill knowledge from the previous session's feature extractor to the current one, aiding in retaining past knowledge and reducing catastrophic forgetting. Unlike traditional distillation, which focuses on class logits, our method distills feature representations, aligning the new feature extractor with the old one. This component ensures that features for both old and new classes remain preserved and discriminative."}, {"title": "C. Prioritized Exemplar Selection Method MES", "content": "Our method adopts a sample replay strategy to overcome the problem of catastrophic forgetting. Namely, at each incremental session, we select a subset of each incremental class to put it into the memory buffer, which is used to update the feature extractor with both old and new class samples. As a result, we propose the Marginal Exemplar Selection (MES) strategy to select an exemplar subset consisting of diverse and marginal samples. The goal of the MES strategy is to identify and select samples that are positioned on the edges within the feature space, essentially those that are likely to lie on the boundaries of the data distribution. By choosing such samples, the model is encouraged to develop a deeper understanding of the boundaries within the data distribution. We show the procedures of MES strategy in algorithm 1."}, {"title": "IV. EXPERIMENT STUDY", "content": "We conduct comprehensive experiments on two datasets: the benchmark TEP dataset [40] and the practical dataset MFF [41], to assess the efficacy of our SCLIFD. Due to the limited open-sourced models in the fault diagnosis domain, the performance of SCLIFD is compared to some classical and state- of-the-art methods in computer vision domains. Following previous works [20, 32, 42, 43], we choose the classification accuracy and average accuracy in all incremental sessions as our evaluation metrics. Moreover, ablation experiments are also performed to prove the effectiveness of each component."}, {"title": "A. Implementation Details", "content": "1) Datasets: TEP dataset [40] is widely recognized in the fault diagnosis field for its simulation of realistic chemical processes. It comprises 52 variables, including temperature and pressure continually monitored by sensors. It features 20 types of faults, as shown in Tab. II. We have selected nine fault types (type 1, 2, 4, 6, 7, 8, 12, 14, and 18) along with one normal type (type 0) at random, to demonstrate the effectiveness of SCLIFD. Access to the dataset is available through the provided link. The MFF [41] dataset originates from the Three-phase Flow Facility system at Cranfield University and consists of 24 process variables sampled at 1 Hz. It has 6 types of faults consisting of 23 variables collected from a real-world multiphase flow facility. We randomly pick faults 1, 2, 3, and 4 and normal class 0 in the experiments. It can be downloaded from the link.\nMoreover, Tab. I shows the number of novel classes added at each incremental session for TEP and MFF datasets, the total incremental sessions, training and testing set size for normal and fault classes, and memory buffer size K. To simulate limited fault data, we restrict the number of samples for fault classes. Following [38], fault class samples range from 20 to 50 for imbalanced diagnosis and from 1 to 20 for long-tailed diagnosis. In the TEP dataset, fault classes have 48 or 20 samples, while in the MFF dataset, they range from 10 to 5. Class imbalance is created by having far more samples in the normal class than fault classes. The long-tail distribution is simulated with fault classes having very few"}, {"title": "B. Experimental Results", "content": "1) Comparative Results: This section presents the comparative results of various methods applied to imbalanced and long-tailed fault diagnosis using the TEP and MFF datasets. The trends in accuracy across all incremental sessions for the different methods are depicted in Fig. 5 and Tab. III. The experimental results are summarized as follows:\nSuperior accuracy across all imbalance ratios. For each fault diagnosis case of different imbalance ratios, the average classification accuracies of our SCLIFD always outperform other state-of-the-art methods. For example, through all class incremental sessions of the TEP dataset, SCLIFD achieves the average accuracies of 90.23% and 84.27% under the imbalanced and long-tailed fault diagnosis cases respectively.\nEffectively reduces catastrophic forgetting. As incremental sessions proceed, the accuracies of SCLIFD are continuously higher than those of other methods. For example, in session 5 of the imbalanced case under the TEP dataset, the accuracy of SCLIFD is 72.25%, which is 18.23% higher than the second- best iCaRL of 54.02% accuracies. Although the accuracies of LwF.MC is the highest in session 1 under the TEP dataset, our method greatly outperforms it in subsequent incremental sessions. This demonstrates that our method effectively alleviates catastrophic forgetting.\n2) Further Analyses: In this section, we further analyze the reasons behind the improved performance of our method. Continuously extracts discriminative features. As shown in Fig. 6, we plot the T-SNE visualizations of each class's features in each incremental session under the MFF's im- balanced case. It illustrates the distribution and separation of feature vectors extracted by SCLIFD. It also proves the model effectively and continuously extracts discriminative features as the learning classes increase.\nTighter intra-class, larger inter-class separations. To further demonstrate the superiority of our feature extractor, we compute the inter-class (KL divergence between two-class pairs) and intra-class distances (KL divergence within the same class) to create a class network graph on the imbalanced TEP dataset for our method and the second-best method, iCaRL. In Fig. 7, each node represents a class, with node size indicating intra-class distance and edges representing inter-class distance. Smaller nodes in SCLIFD show tighter clustering within classes compared to iCaRL, while thicker, darker edges indicate greater separation between classes, enabling better class distinction.\nInterplay Between Components. The components of our framework are designed to work cohesively, ensuring their combined effect surpasses individual contributions:\nSCKD enhances feature quality, enabling MES to ef- fectively identify boundary samples. High-quality feature representations help locate the most challenging samples (those near decision boundaries), which MES selects for memory storage, ensuring the buffer contains the most informative samples for incremental updates."}, {"title": "C. Ablation Study", "content": "Our approach mainly consists of three components, which are SCL, MES, and BRF classifier. We analyze the effect of individual components on TEP and MFF datasets under different imbalance ratios by ablating each part. First, we have conducted experiments to verify the effects of using the SCL, MES, and BRF modules individually. Additionally, the methods without the SCL module adopt the cross-entropy loss and distillation loss as iCaRL [32] does. Moreover, in terms of the sample replay method, the ablation experiments adopt random selection by default and compare Herding [33], as well as a mixed approach where half the samples are selected via Herding and the other half using MES, against the MES module. Finally, the method without using the BRF classifier adopts the fully connected classifier (FCC). It designs a fully connected layer with a Softmax function after a well-trained and frozen feature extractor, and the neuron number incrementally increases with the number of faults increasing. We train FCC using cross-entropy loss and Adam optimizer with batches of 512, and a learning rate of 0.001 in 500 epochs.\nAs illustrated in Tab. IV, our method achieves the highest average accuracy across all sessions when all three components are utilized for both TEP and MFF datasets. Moreover, adding the SCL, MES, and BRF modules individually improves accuracy. For instance, in the TE imbalanced case, SCL increases accuracy from 50.16% to 80.80%. MES improves accuracy from 39.39% to 59.49% in the TE long-tailed case, while BRF raises it from 50.67% to 73.93% in MFF long- tailed case 2, showing each module's impact. The absence of the SCL module leads to a decrease in accuracy, indicating the significance of SCL in the model's performance. When the MES module is not used, and Herding, random selection, and Mixed strategy are adopted instead, there are decreases in accuracies, signifying that MES plays a positive role in sample selection. Moreover, the mixed approach may fail"}, {"title": "D. Generalization of Our Method", "content": "The TEP dataset consists of 21 different fault types. To demonstrate the generalizability of our proposed method, we selected an additional 9 fault classes, along with the normal class, from the imbalanced TEP dataset. These were used to form five distinct experimental groups, each comprising different fault classes, to evaluate the classification performance throughout the incremental learning process. As shown in Tab. V, the average accuracy across six different class selections from the imbalanced TEP dataset reached 85.86%. This result demonstrates that our method maintains strong classification accuracy for other fault types beyond the original set, further validating its robustness and adaptability in handling a variety of fault diagnosis scenarios."}, {"title": "E. Sensitivity Evaluation", "content": "To determine the appropriate memory buffer size K, we conduct a sensitivity analysis to minimize memory usage while maintaining accuracy. As shown in Fig. 8, the model's performance remains stable across different K values. For the TE dataset's imbalanced case, accuracy stabilizes between K = 100 to 200, so K = 100 is selected. In the TE long-tailed case, accuracy remains stable from K = 40 to 200, leading to K = 40 being chosen. For the MFF dataset, K = 10 and K = 5 are selected for long-tailed cases 1 and 2, as accuracy stabilizes between K = 10 to 60 and K = 5 to 60, respectively. In each case, the smallest stable K is chosen to"}, {"title": "V. CONCLUSION", "content": "This paper introduces the SCLIFD framework, designed to address fault diagnosis challenges under conditions of limited fault data within a class incremental learning framework. SCLIFD enhances its representation learning capabilities and reduces catastrophic forgetting through the use of supervised contrastive knowledge distillation. Additionally, we introduce a novel sample selection method, MES, which sharpens the model's ability to discern boundaries and enhance generalization. We also incorporate the BRF classifier at the classification stage to counteract the effects of class imbalance. We assess the SCLIFD in scenarios of imbalanced and long-tailed fault diagnosis, conducting comprehensive experiments on the TEP and MFF datasets. SCLIFD has outperformed other SOTA methods in various scenarios, underscoring its innovative approach to overcoming the difficulties of class incremental learning in fault diagnosis with insufficient data. In the future, we will explore dynamically adjusting the memory buffer size for each class based on data characteristics and model needs. This could help optimize memory usage and maintain performance as the number of data categories increases."}]}