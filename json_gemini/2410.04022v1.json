[{"title": "Efficient Large-Scale Urban Parking Prediction: Graph Coarsening Based on Real-Time Parking Service Capability", "authors": ["Yixuan Wang", "Zhenwu Chen", "Kangshuai Zhang", "Yunduan Cui", "Lei Peng"], "abstract": "With the sharp increase in the number of vehicles, the issue of parking difficulties has emerged as an urgent challenge that many cities need to address promptly. In the task of predicting large-scale urban parking data, existing research often lacks effective deep learning models and strategies. To tackle this challenge, this paper proposes an innovative framework for predicting large-scale urban parking graphs leveraging real-time service capabilities, aimed at improving the accuracy and efficiency of parking predictions. Specifically, we introduce a graph attention mechanism that assesses the real-time service capabilities of parking lots to construct a dynamic parking graph that accurately reflects real preferences in parking behavior. To effectively handle large-scale parking data, this study combines graph coarsening techniques with temporal convolutional autoencoders to achieve unified dimension reduction of the complex urban parking graph structure and features. Subsequently, we use a spatio-temporal graph convolutional model to make predictions based on the coarsened graph, and a pre-trained autoencoder-decoder module restores the predicted results to their original data dimensions, completing the task. Our methodology has been rigorously tested on a real dataset from parking lots in Shenzhen. The experimental results indicate that compared to traditional parking prediction models, our framework achieves improvements of 46.8% and 30.5% in accuracy and efficiency, respectively. Remarkably, with the expansion of the graph's scale, our framework's advantages become even more apparent, showcasing its substantial potential for solving complex urban parking dilemmas in practical scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "Urban transportation systems are facing serious challenges due to the continuous increase in the number of vehicles. Recent statistics [1] reveal that vehicle ownership in China escalated to 417 million in 2022, complemented by a striking addition of 34.78 million new registrations within the year. Particularly at the urban scale, as many as 13 cities saw an increase in car ownership by more than 3 million vehicles, including metropolises like Beijing, Shanghai, and Shenzhen. This surge in vehicle numbers not only leads to traffic congestion but also severely exacerbates parking issues. The expansion of urban parking facilities and spaces cannot keep pace with the growth in vehicle numbers, making it exceedingly difficult to find parking in city centers and commercial areas.\nTo alleviate the parking difficulty issue, urban-level smart parking platforms [2] have emerged. By leveraging cutting-edge technologies such as digital twins, the Internet of Things, and cloud computing [3], these platforms have successfully integrated urban parking facility resources, effectively solving the problem of information asymmetry between users and available parking spaces. Taking the Wuhan smart parking project [4] as an example, by the end of 2022, the platform had integrated more than 4,000 parking lots, including approximately 480,000 parking space data. With its portability, the platform offers convenience to citizens, who can easily check real-time parking availability in different areas through their mobile phones and use services such as parking reservation [5] and parking navigation [6], [7], [8] to achieve precise parking. In these platforms, the key to providing smart parking services lies in parking prediction technology [9]. Indeed, parking prediction has always been a hot research topic in urban parking technology [10], [11]. By effectively predicting the availability of parking spaces in future time periods, it can not only enhance user experience but also improve parking turnover, optimize drivers' parking behavior, and thereby help to allocate urban parking resources rationally.\nRecent studies have framed such parking prediction tasks as spatio-temporal graph modeling problems [12]. On one hand, this is because parking lots are connected through urban road networks, forming unique parking graphs [13], for which graph convolutional networks can be utilized to capture the spatial characteristics of the parking graph [14]. On the other hand, given the tidal characteristics of parking flow, recurrent neural networks can be employed to fit the time series regression of parking data [15]. This approach, which considers both spatial and temporal dependencies, is known as spatio-temporal Graph Convolutional Networks (GCNs).\nHowever, for the vehicle-dense cities mentioned above, with the rapid development of wireless sensors and the widespread use of vehicles [16], a massive influx of real-time parking data continuously flows into urban-level parking platforms. This leads to a dramatic increase in the volume of parking data managed by existing platforms and the coverage range of the parking Internet of Things network [17]. The rapid influx of such information necessitates an unsustainable amount of time to train spatio-temporal GCNs at the required scale for large-scale urban parking prediction.\nTo reduce the resources and time costs involved in training the aforementioned models, scholars have been dedicated to finding efficient graph dimensionality reduction techniques [18]. Among various studies, graph coarsening [19] stands out as one of the mainstream methods that can achieve this aim. Its core concept involves merging certain nodes within the graph into a hypernode and then using these hypernodes to construct a coarsened graph, thereby enhancing the learning efficiency and scalability of large-scale graphs [20]. However, a prevailing issue is that existing coarsening methods struggle to be directly applied to complex parking scenarios:\n1) The quality of the input graph significantly determines the performance of downstream tasks [21]. For parking graphs, a high-quality parking graph is not only an abstraction of spatial topology but also a adequate representation of parking behavior and decision-making. Neglecting either aspect will limit the understanding of parking scenarios, thereby negatively affecting the effectiveness of subsequent coarsening tasks as well as the accuracy and robustness of prediction tasks.\n2) Most of the existing coarsening methods only consider reducing the size of the graph structure [22], and the node features of the coarsened graph still being obtained by concatenating the original data. This means that the amount of data has not changed. If the model is trained directly based on the coarsened parking graph, the training overhead is not significantly reduced. Moreover, since the coarsened parking graph loses the original topology, the merged data corresponding to the hypernodes also lose their spatial features, leading to a decrease in prediction accuracy.\nGraph attention networks (GAT) have attracted much attention in the transportation field [23] over recent years. By selectively focusing on specific nodes and discerning the importance among various nodes, these mechanisms help models to capture deeper hidden information in the traffic scenarios [24], thereby elevating predictive accuracy. The ParkingRank algorithm [25], which assesses the real-time service capability of parking lots using their static attributes, has been widely applied in parking recommendations [26], parking guidance [2], and other related tasks. We posit that this methodology can be interpreted as a preference-based attention mechanism, adept at capturing the service capability variations across different parking lots by evaluating their significance. This nuanced attention mechanism, by thoroughly considering node characteristics alongside topological connections, offers enriched guidance for the coarsening process, enhancing the model's overall utility and effectiveness.\nMeanwhile, autoencoders (AEs) have been widely used in traffic data compression and reconstruction tasks due to their theoretical ability to achieve lossless compression [27]. Specifically, the encoding module is able to learn the high-dimensional sparse information in traffic data and successfully encode it into a low-dimensional dense tensor [28] for more efficient traffic prediction, while the decoding module is tasked with reconstructing the condensed representations back to their original data form [29]. In this framework, we argue that the introduction of an AE can compensate for the lack of compression of node features in the graph coarsening process. Through the synergy of the encoding and decoding modules, a unified dimensionality reduction of the parking graph structure and features can be achieved, thus providing a more efficient and accurate data representation for the downstream parking prediction task. In summary, the main contributions of this paper can be summarized as follows:\nWe have proposed a method for constructing parking graphs that leverages a ParkingRank graph attention mechanism. This method intricately integrates the real-time service capacity assessment of parking lots into a graph attention network, creating a parking graph that accurately mirrors real-world parking behavior preferences. This graph is adept at capturing the complexity of parking scenarios, while also remaining flexible enough to adapt to its dynamic shifts, laying the foundation for downstream coarsening as well as prediction tasks.\nWe introduce a novel framework for parking prediction that employs a graph coarsening techniques and temporal convolutional autoencoder [30], designed to diminish the resource and time expenditures associated with urban parking prediction models. The scheme can make up for the shortcomings of traditional coarsening methods that neglect the dimensionality reduction of node features, and realize the unified dimensionality reduction of urban parking graph structure and features. Moreover, by incorporating temporal convolutional networks in the encoding-decoding phase, our approach not only significantly enhances the dimensionality reduction and reconstruction capabilities for parking time series data but also ensures the accuracy of the parking prediction task. Additionally, the compact data volume within each hypernode allows for the parallel processing of encoding-decoding operations across different sets of parking time series data, further boosting the overall training efficiency of the parking prediction task.\nThis paper is structured as follows: Section II provides a concise overview of spatio-temporal GCNs for parking prediction, techniques for dimensionality reduction in large-scale graphs, and the applications of Autoencoders (AE). Section III delves into the specifics of our innovative ParkingRank graph attention model and outlines our parking prediction methodology, which leverages TCN-AE for coarsening. Section IV details the experimental framework and analysis employed to assess the effectiveness of our proposed approach. We conclude by summarizing the key insights and contributions of this study."}, {"title": "II. RELATED WORK", "content": "Spatio-temporal GCNs [31] have emerged as a powerful and prevalent approach within the realm of traffic prediction, adept at navigating the intricacies of traffic graphs by integrating both spatial and temporal dependencies. Unlike relying solely on GCNs or RNNs, spatio-temporal GCNs excel at dissecting time-series data embedded in graph structures [32], thereby yielding more precise prediction. For instance, Zhao et al. [33] introduced the T-GCN model, ingeniously combining GCN with GRU to understand the intricate topology of traffic networks and the dynamic shifts in traffic data, enhancing the capture of spatio-temporal characteristics more effectively. In a similar vein, Sun et al. [34] unveiled DDSTGCN, leveraging TCN to track variations in traffic states alongside GCN for topology learning, markedly boosting traffic prediction accuracy. In recent years, scholars have suggested employing attention mechanisms to bolster the extraction of spatio-temporal features, thereby extending the model's interpretability. Zheng et al. [35] proposed a novel strategy that incorporates spatial and temporal attention layers to elucidate the spatio-temporal correlations within heterogeneous traffic flows, thereby not only elevating predictive performance but also the interpretability of the findings. Furthermore, Li et al. [36] developed AST-GAT, incorporating multi-head graph attention and attention-based LSTM modules to intricately map the spatio-temporal interdependencies among road segments, aiming to refine the precision of traffic prediction.\nDue to the inherent structural and functional similarities between urban transportation networks and urban parking networks, both involve complex spatial relationships and dynamically changing temporal characteristics. Leveraging advanced spatio-temporal graph convolutional models from the field of traffic prediction, we believe can effectively enhance the accuracy of parking prediction. However, in the domain of parking prediction, the industrial sector continues to prioritize concerns regarding time costs and resource consumption, with a current lack of effective solutions. These challenges will limit the feasibility and effectiveness of the aforementioned spatio-temporal graph convolutional models in practical industrial applications."}, {"title": "B. Techniques for Dimensionality Reduction in Large-Scale Graphs", "content": "As the scale of graphs continues to expand, finding a universal method that can simplify the structure while preserving key attributes becomes increasingly important. Simplified graph representations not only facilitate storage but also offer efficiency in approximate algorithms [20]. There are mainly two methods for simplifying graphs: The first method, known as graph sparsification [37], approximates the maintenance of distance relationships between node pairs by removing edges from the graph. However, for highly structured parking graphs, this method might lose the original graph's connectivity. An improved method is the K-neighbors Sparsifier [38], which performs local sparsification on each node by setting a threshold, but still introduces high computational complexity. With the growing popularity of deep learning, Wu et al. [39] proposed GSGAN, which generates new graphs through GANs to preserve the community structure of the original graph, but it introduces edges that do not exist in the original graph and contradicts reality.\nThe second approach is known as graph coarsening [40], which aims to reduce the number of nodes to a subset of the original nodes while maintaining the original graph properties. The key to graph coarsening [21] lies in the ability to accurately measure the variations before and after coarsening. The GraClus [41] technique, and the MCCA [42] algorithm all employ the idea of greediness by constantly compacting the connected regions of the original graph. However, these approaches lack guarantees for global optimization. Recently, spectral graph theory [22] proved that graphs with similar spectra are usually considered to have similar topologies. Therefore, the idea of minimizing the spectral distance can be introduced into the coarsening process, using the eigenvalues of the graphs to measure the structural similarity and ensuring that the generated coarsened graphs can maintain the properties of the original graphs.\nHowever, we have observed that current graph coarsening methods primarily focus on reducing the complexity of the graph structure while often neglecting the dimensionality of node features. This approach does not effectively reduce the actual volume of parking data in large-scale urban parking prediction tasks. Although the parking network structure has been somewhat simplified through graph coarsening techniques, the training overhead for downstream parking prediction models has not decreased as significantly as anticipated."}, {"title": "C. Applications of Autoencoders", "content": "AEs have demonstrated remarkable proficiency in managing intricate spatio-temporal data relevant to transportation systems [35]. Typically employing symmetrically structured encoders and decoders for unsupervised learning, these AEs are adept not only at distilling input data into compact representations of potential vectors [27], but also at restoring the data to its original dimensions. They achieve this by optimizing the reconstruction of the data's objective, thereby minimizing loss [29]. For instance, the TGAE introduced by Wang et al. [43] adeptly captures the underlying patterns of traffic flow through a spatio-temporal AE, facilitating the prediction of future traffic information. Similarly, the TCN-AE devised by Mo et al. [44] leverages TCNs within its encoding module to extract features from temporal data, subsequently utilizing the decoding module to map latent representations back to the original data space, thus enabling anomaly detection.\nInspired by the capabilities of AEs in dimensionality reduction and key feature extraction of spatio-temporal data, we propose the integration of AEs into large-scale urban parking prediction tasks, aiming to address the limitations of traditional coarsening methods in handling parking lot node features. Additionally, by leveraging the advantages of TCN in processing complex temporal data, AEs can more accurately capture and analyze the parking patterns within different parking lots, thereby significantly enhancing the performance and depth of understanding of downstream parking prediction models."}, {"title": "III. METHODOLOGY", "content": "In this paper, our goal is to effectively reduce the time and resource costs of parking prediction models by achieving a unified reduction in the dimensions of the structure and feature data of urban parking graphs, while ensuring the accuracy of parking prediction tasks. The urban parking graph can be represented as G = (V, E, A), where V denotes the set of parking nodes, E denotes the set of edges, and A\u2208 $\\mathbb{R}^{N\u00d7N}$ denotes the directed adjacency matrix, N = |V|.\nThe parking prediction problem [12] can be interpreted as: given a parking graph G and historical parking data X(t-T+1):t for T time slices before time t, learning a function F to predict future parking data Y(t+1):(t+T') for T' time slices after time t, as shown in Equation 1.\n$\\widehat{Y}_{(t+1):(t+T')} = F(X_{(t\u2212T+1):t}, G),$ (1)\nwhere the parking data X = {x1,x2,...,xT} \u2208 $\\mathbb{R}^{T\u00d7N\u00d7F}$ represents the parking flow information observed at T time slices for all parking lots. Each xt corresponds to a time slice and includes N parking lot nodes, each with F dimensional features, including the longitude, latitude, openness to the public, charging situation, and real-time occupancy rate of the parking lot."}, {"title": "B. ParkingRank Graph Attention", "content": "Graph coarsening, as the current mainstream graph dimensionality reduction technique, aims to overcome the huge computational obstacles faced by large-scale graph data when processing, extracting and analyzing. Typically, the input for graph coarsening is the graph adjacency matrix [21]. When dealing with complex structures such as urban parking graphs, the traditional adjacency matrix constructed from topological relationships is obviously difficult to adequately capture the complexity and diversity of the real parking landscape. In fact, drivers do not only consider the proximity of parking lots in the region when making parking decisions, but also comprehensively compare the distance of regional parking lots, real-time space occupancy rate, openness to the public, and charging situation, and other factors. Therefore, before performing the task of urban parking graph coarsening, we need a high-quality parking graph that can truly reflect the preference of parking behavior and adapt to the dynamic change of parking demand.\nGAT [45] is an advanced spatial-based graph neural network methodology, whose primary advantage lies in redefining the aggregation of node features. Unlike GCN that typically assign equal weights to all neighboring nodes for information aggregation, GAT introduces an attention mechanism. This allows the model to dynamically allocate varying weights based on the importance of each neighboring node. Such a strategy enables GAT to more effectively capture spatial correlations within road networks and selectively emphasize those nodes that are crucial for the current task. In the application of urban parking network prediction, this feature of GAT is particularly significant. It enables the network to flexibly capture important relationships between parking nodes, focusing on those nodes that are critical for the current prediction task. We believe that this not only helps in more accurately describing the correlations between different parking lots but also aids in constructing an efficient parking network that reflects the relevancy of parking spaces. The overall framework of our proposed PRGAT is shown in Fig. 1:\nGiven the complexity of the parking data X directly inputting the high-dimensional data xt into GAT would lead to considerable computational redundancy, thereby increasing the model's time cost. To address this, we adopt a dimensionality reduction strategy that involves extracting and abstracting certain features of the parking lots. This effectively reduces the computational burden and enhances the model's computational efficiency.\nThe ParkingRank model [25] is an algorithm to quantitatively assess the service capability of different parking lots. By integrating complex parking information such as the total number of parking spaces in the parking lot, the degree of openness to the public, and the price of parking, it can help drivers to understand the actual situation of the parking lot in a more comprehensive way, so that they can make informed choices in the parking decision-making process. Specifically, the algorithm primarily focuses on three aspects to describe the real-time service capacity of parking lots, as shown in Equation 2:\nParking lot service range: This aspect considers which types of vehicles are allowed to park in the parking lot. For example, parking lots at shopping centers may be open to all vehicles, while those in residential areas may only serve residents. Therefore, parking lots with a broader service scope generally have stronger service capabilities.\nTotal number of parking spaces: The more internal parking spaces a parking lot has, the stronger its service capacity usually is.\nPrice of parking: Higher parking prices may reduce the number of vehicles able to afford parking fees. Thus, expensive prices may lower the service capacity of the parking lot.\n$\\begin{equation} P R_{i}=\\exp \\left(s_{i}\right) \\frac{\\left(Y_{i} /||y||\right)}{1+z_{i} /||z||}, \\end{equation}$ (2)\nwhere PR\u2081 represents the service capacity of each parking lot; si \u2208 [0,1] denotes the service range, which is used to measure the degree of openness of the parking lot, from the public parking lot (si = 1) to the private parking lot (si = 0); Yi and zi represent the total number of parking spaces and the price of parking, respectively. ||y|| and ||z|| are the first-order paradigms for the y- and z-column vectors.\nWe believe that the process of quantifying the service capability of a parking lot is essentially a process of extracting the redundant parts of the parking lot features xt, and the low-dimensional evaluation results can be used as new abstract features to replace the original high-dimensional parking data xt.\nMoreover, while GAT typically utilize Multi-Layer Perceptrons (MLP) or cosine similarity to ascertain the degree of association between nodes, such conventional methods may fall short in terms of interpretability, particularly when applied to entities like parking lots with distinct attributes. These methods often fail to offer a clear insight into the dynamics of parking lot interactions. To mitigate the black-box issue encountered by GATs in analyzing parking graphs, we integrate the parking spatio-temporal transfer matrix [2] into the computation of attention coefficients within GATs. This matrix meticulously accounts for the spatio-temporal evolution of parking lot features, encompassing real-time occupancy rates, service capabilities, and spatial connections, thereby facilitating a dynamic representation of parking cruising behavior. This nuanced incorporation allows for a richer, more detailed understanding of parking dynamics, effectively translating the raw data into actionable insights. The formulation of this transfer matrix Atrf is presented in Equation 3.\n$\\begin{equation} \begin{array}{l} A_{i, j}^{\text {trf }}=\\left\\{\begin{array}{ll} q_{i}, & \text { when } i=j \\ W_{i, j}\\left(1-q_{j}\right) P R_{i}, & \text { when } i \neq j \\end{array}\right. \\end{array} \\end{equation}$ (3)\nwhere each element of of $A_{i, j}^{\text {trf }} \\in \\mathbb{R}^{N\u00d7N}$ represents the probability of a vehicle heading to another parking lot j when it finds parking lot i is full. qi represents the real-time occupancy rate of parking lot i, which also indicates the probability of a vehicle choosing to stay in parking lot i based on the parking situation. Wij is the reciprocal of the normalized distance Ai,j between parking lot i and parking lot j. PRi is the normalized service capacity of parking lot i.\nTherefore, in this paper, the input to PRGAT consists of the original adjacency matrix A based on Euclidean distance and the new parking data Xlow \u2208 $\\[R^{T\u00d7N\u00d7F_{\\text{low}}}, which is composed of the service capacity PR\u2081, the real-time occupancy rate qi, and latitude and longitude coordinates. The output is the updated parking data Xre \u2208 $\\mathbb{R}^{T\u00d7N\u00d7F_{\\text{re}}}$. Here, Flow represents the new feature dimensions after quantification and extraction, while Fre denotes the new feature dimensions relearned by PRGAT.\nThe algorithm initially applies a linear transformation to each parking lot node's features $x_{\\text{low}}(i)$ using a learnable weight matrix W \u2208 $\\mathbb{R}^{F_{\\text{re }} \u00d7 F_{\\text {low }}}$ to enhance the node's expressive capability. Subsequently, it employs an attention mechanism Ton the set of nodes to compute the attention coefficient ei,j between node i and node j. This procedure can be encapsulated by Formula 4, wherein the attention mechanism might be a function that signifies the correlation between two objects, like cosine similarity or a Multilayer Perceptron (MLP), and || represents the vector concatenation operation.\n$\\begin{equation} e_{i, j}=T\\left[W x_{\text {low }}(i) \\| W x_{\text {low }}(j)\right], \\end{equation}$ (4)\nTo capture local topological information and enhance computational efficiency, a masking mechanism and normalization operation have been introduced. The attention coefficients ei,j are confined within the first-order neighborhood of the nodes, enabling each node to concentrate solely on its directly connected neighboring nodes and disregard the other nodes in the graph, ultimately yielding the attention matrix Aattn \u2208$\\mathbb{R}^{N\u00d7N}$. See Formula 5 for details, where LeakyReLU represents the activation function.\n$\\begin{equation} A_{\text {attn }}(i, j)=a_{i, j}^{\text {attn }}=\\frac{\\exp \\left(\text { LeakyReLU }\\left(e_{i, j}\right)\right)}{\\sum_{k \\in N_{i}} \\exp \\left(\text { LeakyReLU }\\left(e_{i, k}\right)\right)}, \\end{equation}$ (5)\nMoreover, the masking mechanism ingeniously reflects the factors influencing the parking decision-making process. Drivers, when choosing a parking lot, tend to compare a specific parking lot with its adjacent ones, rather than conducting pairwise comparisons among all parking lots. Such a masking mechanism not only enhances the model's sensitivity to local associations but also aligns more closely with the behavioral patterns in the actual parking decision-making process.\nWe input both the parking spatio-temporal transfer matrix Arf and the aforementioned attention matrix Aattn into the softmax activation function simultaneously to derive the ParkingRank attention matrix Acombined \u2208 $\\mathbb{R}^{N\u00d7N}$, as indicated in Equation 6.\n$\\begin{equation} A_{\text {combined }}(i, j)=a_{i, j}^{\text {combined }}=\\operatorname{softmax}\\left(a_{i, j}^{\text {attn }}+a_{i, j}^{\text {trf }}\right), \\end{equation}$ (6)\nThis ParkingRank attention matrix not only reflects the dynamic characteristics of the parking graph, capturing the flow trajectories and behavioral patterns of vehicles in urban parking scenarios, but also overcomes the shortcomings of insufficient interpretability of the parking lot relevance matrix computed by traditional graph attention methods.\nAfter obtaining the normalized ParkingRank attention coefficients $a_{i, j}^{\text {combined}}$, GAT conducts a weighted aggregation of the features of each node i with its neighbors Ni, thereby producing the final output for each node. This procedure is depicted in Formula 7, where \u03c3 denotes the sigmoid activation function.\n$\\begin{equation} x_{\text {re }}(i)=\\sigma\\left(\\sum_{j \\in N_{i}} a_{i, j}^{\text {combined }} W x_{\text {low }}(j)\right). \\end{equation}$ (7)\nThe PRGAT we designed is fundamentally a pre-trained model, its primary purpose being to serve as a front-end graph construction module within the overall framework for urban parking prediction. Its loss function is described in Formula 8, and the pseudocode for the graph is provided in Algorithm 1.\n$\\begin{equation} L_{G A T}\\left(X_{\text {low }}, x_{r e}\right)=\\frac{1}{T} \\sum_{t=t-T+1}^{t} \\sum_{i=1}^{N}||x_{\text {low }}(i)-x_{r e}(i)||^{2}, \\end{equation}$ (8)"}, {"title": "C. Parking graph Coarsening", "content": "Define the coarsened parking graph Ge = (Vc, Ec, Ac) is the result of coarsening the original adjacency matrix A, which is a smaller weighted graph. Ve denotes a set of disjoint hypernodes, which covers all nodes in the original graph V, where each hypernode is formed by the aggregation of some of the nodes in the original graph, i.e., $v = {V1, V2, ..., Vn} \\in \\mathbb{R}^{N}$. Ac\u2208 $\\mathbb{R}^{N_e\u00d7N_e}$ is the adjacency matrix of the coarsened graph, Nc = |Vc|.\nThis document employs the SGC algorithm [22], which utilizes spectral distance (SD) to demonstrate that the coarsened network retains spatial features similar to those of the original network. This concept is illustrated in the equation below:\n$\\begin{equation} S D\\left(G, G_{c}\right)=\\|\\lambda-\\lambda_{c}\\|_{1}=\\sum_{i=1}^{N}|\\lambda(i)-\\lambda_{c}(i)|, \\end{equation}$ (9)\nwhere the vectors \u03bb and \u03bb\u025b represent the eigenvalues of the Laplacian matrices of the original graph G and the coarsened graph Ge, respectively. The spectral distance SD(G,Gc) is considered sufficiently small if it is less than 8 (where 8 is a very small number). Only when this condition is met do the eigenvalues and eigenvectors of the two graphs exhibit similarity in the spectral domain. The calculated spectral distance can then substantiate that the coarsened graph significantly preserves the attributes of the original graph during the coarsening process. Thus, it can be inferred that the spatial structure of the coarsened network remains similar to that of the original network. The key steps of the SGC algorithm are introduced below.\nThe algorithm initiates by inputting the ParkingRank attention matrix Acombined and the coarsening ratio \u03b7 = $\\frac{N_c}{N}$. It computes the Laplacian matrix Land, through matrix decomposition, obtains the first Ne and the last N Nc + 1 Laplacian eigenvalues and Laplacian eigenvectors u, for capturing both the local and global information of the parking graph. This procedure is illustrated in Formulas 10 and 11 wherein L signifies the normalized Laplacian matrix, with IN and D being the identity matrix and the degree matrix, respectively.\n$\\begin{equation} L=I_{N}-D^{-1 / 2} A_{\text {combined }} D^{-1 / 2}, \\end{equation}$ (10)\n$\\begin{equation} L u=\\lambda D u, \\end{equation}$ (11)\nThen, the algorithm starts to iterate different eigenvalues intervals, performs parking clustering on the internal eigenvectors u respectively, divides the parking lots with similar features into a parking hypernode, and generates a preliminary coarsened graph Ge based on the clustering results, the clustering principle is shown in Equation 12.\n$\\begin{equation} d_{c}(i, j)=\\frac{\\sum_{x=1}^{s}, y=1^{k} u_{i}^{x} u_{j}^{y}}{\\sqrt{\\sum_{i=1}^{n}\\left(u_{i}^{x}\right)^{2} \\sum_{y=1}^{k}\\left(u_{j}^{y}\right)^{2}}}, \\end{equation}$ (12)\nThe Laplacian eigenvectors u computed from the ParkingRank attention matrix Acombined has rich parking graph topology information as well as parking lot node feature information, which can provide more accurate and intuitive parking lot node characterization for the coarsening process. The process continuously calculates the distance SD between the Laplacian eigenvectors of the coarsened graph Ge and those of the original graph, opting for the coarsening outcome with the minimum error. Finally, the coarsened graph Gc = (Vc, Ec, Ac) along with the corresponding index matrix index are returned. This procedure is depicted in Formula 13, with the coarsening specifics provided in Algorithm 2.\n$\\begin{equation} S D\\left(A_{\text {combined }}, A_{c}\right)=\\| d_{\text {combined }}(i)-d_{c}(i)||_{1}, \\end{equation}$ (13)"}, {"title": "D. Prediction framework based on coarsened parking graphs", "content": "Since the coarsening process of the parking graph described above does not downscale the parking lot node features", "follows": "n$\\begin{equation"}, "x_{t}^{\text {combined }}(i)=x_{t}^{\text {low }}(i) \\| x_{t}^{\text {low }}(j), \\end{equation}$ (14)\nIf it is simply used as the feature input for the parking prediction models, it will not significantly improve the overall framework training efficiency, and even lose the intrinsic connection between the nodes. In this regard, we consider adopting the symmetric TCN-AE, which is because:\nTCN is able to mine the intrinsic laws behind the parking time-series data itself [44"], "follows": "As depicted in Fig. 2, firstly, the parking data Xlow \u2208 $\\mathbb{R}^{T\u00d7N\u00d7F_{\\text{low}"}, [44], {}, {}, 15, [33], 2, 1, 16, 17, 18, 19, 20, ".", 16, 17, 18, 19, 20, 21.0, "space.\n$\\begin{equation}"]