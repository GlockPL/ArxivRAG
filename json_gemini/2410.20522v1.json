{"title": "Props for Machine-Learning Security", "authors": ["Ari Juels", "Farinaz Koushanfar"], "abstract": "We propose protected pipelines or props for short, a new approach for authenticated, privacy-preserving access to deep-web data for machine learning (ML). By permitting secure use of vast sources of deep-web data, props address the systemic bottleneck of limited high-quality training data in ML development. Props also enable privacy-preserving and trustworthy forms of inference, allowing for safe use of sensitive data in ML applications. Finally, props offer a new approach to constraining adversarial inputs. Props are practically realizable today by leveraging privacy-preserving oracle systems initially developed for blockchain applications.", "sections": [{"title": "Introduction", "content": "There's only one World Wide Web (WWW). This simple fact represents a major barrier for advances in machine learning, as practitioners are reaching fundamental limits in available data sources for model training [19, 37]. They're relying increasingly instead on synthetic data, a partial remedy that carries the risk of training models that are self-poisoned or misrepresent the real world [24]. Practitioners are also making efforts to tap private sources of data. Obtaining access to sensitive sources of data, though, often requires legally complex and labor-intensive negotiations over conditions of use and subjects large populations of users to the risk of privacy breaches.\nFortunately, there is more than one WWW. There is the surface web, with its publicly accessible, indexed data. Then there is the deep web. The deep web\u2014meaning data sources walled-off from scraping, and ranging from legitimate consumer and enterprise environments to (dark-web) sites of illicit activity is estimated to be two orders of magnitude larger than the surface public web [3, 29].\nDeep-web data can include personal data such as e-mail, health or fitness data from personal devices or medical providers, e-mail, digital calendars, photographs, and financial statements. It can also include documents maintained by organizations, including billing and accounting data, customer orders, transaction records and so forth. As we explain, little"}, {"title": "What Are Props?", "content": "Props are a data pipeline extending from deep-web data sources to points of use in the ML ecosystem. They enforce two key security properties.\nThe first property of props is privacy, specifically the ability of a user to retain control over disclosure of data throughout the pipeline. Props may be viewed as enforcing a common notion of privacy known as \u201ccontextual integrity,\" meaning that data flows appropriately according to its intended use [2, 25]. Props in particular ensure that data remain confidential in the greatest degree that is consistent with their use in target applications.\nThe second property of props is integrity, meaning specifically that props prove to con- sumers of deep-web data and users of downstream models relying on these data that the data are authentic, i.e., come from trustworthy deep-web sources.\nProps can support both model training and inference."}, {"title": "Props for model training", "content": "Here is an illustration of the use of props for model training.\nExample 1 (Training: Health data). MediModels Inc. is training a health-diagnostics ML model. Alice wishes to furnish her electronic health record (EHR) as training data for the model.\nAlice could just download her EHR\u2500let's denote it by X\u2500from her medical provider BigHospital (e.g., as a PDF) and send it to MediModels. But then MediModels would have no way to ensure that X is real, i.e., not modified or fabricated by Alice. Fake data from malicious users (or competitors) could irremediably corrupt MediModel's model.\nAlice can instead use an app, provided by MediModels, that realizes a prop for ML. This app enables Alice to log into the web portal of BigHospital, obtain her EHR, and then relay her EHR to MediModels.\nMediModels obtains high assurance that X is authentic: it is the result of Alice sourcing her EHR from BigHospital. Alice consents to and controls release of her information. Crit- ically here, in our proposed approach BigHospital need not modify its web servers or even know of the use or existence of MediModels' app."}, {"title": "Props for inference", "content": "Props can also support pipelines for ML inference. In this case, a prop proves that an inference results from applying a particular model to authenticated, sensitive source data-without directly revealing the data. In other words, it provides precise provenance for an inference result. Example 2 illustrates this idea. We use the informal notation M(X) to denote the application of a model M to source data X.\nExample 2 (Inference: Privacy-preserving loan decision). Bob applies for a loan from a new financial services company called PrivaLoan. PrivaLoan has an innovative approach to lend- ing. Bob obtains a set X of trustworthy financial documents (e.g., transaction statements) from any of a range of pre-approved sources (major banks and brokerage firms) on the web, e.g., BigBank. He then uses a prop-enabled PrivaLoan app to: (1) Execute a PrivaLoan loan-decision model M on X on his own mobile phone, resulting in loan decision Y and then (2) Generate a proof showing that Y = M(X) for X a set of validly sourced documents. PrivaLoan then acts on decision Y.\nThis example illustrates how a consumer can use sensitive data privately to support organizations' decision-making. Such privacy-preserving inference is not just of benefit to"}, {"title": "Constraining adversarial inputs", "content": "Example 2 illustrates how props additionally offers a strategy for combating adversarial examples. Adversarial examples are maliciously generated inputs designed to cause models to produce erroneous outputs [12, 13, 27, 40]. PrivaLoan can trust Y a because of its"}, {"title": "Data control, monetization, and decentralization", "content": "A user can choose to pre-process the data X obtained from a deep-web source for input to a prop. That is, she can choose to transmit some X' = f(X), where a filter f excises or compresses data in X. The prop will then prove using functionality already available in privacy-preserving oracle systems\u2014that X' is the result of applying f to an authentically sourced X. The filter f can redact data or compute over data in order, e.g., to compress or add noise it [11] to hedge against privacy failures should data leakage occur downstream.\nIn Example 1, for instance, rather than transmitting X to MediModels, Alice might wish to transmit a redacted EHR X' from which she has excised her name and address. (Perhaps she's concerned that these might leak from the trained model.) The prop specifies the filter f to MediModels. Thus MediModels learns that contact information is omitted from X'. MediModels can, of course, choose to accept or reject an input X' based on the filter f that generated it and might, for example, whitelist a set of pre-approved filters.\nIn short, users authorize the release of their data in props and can control this release in a granular way. Props could support a financial model in which an organization training an ML model compensates users for the data they furnish and filtering choices they apply.\nProps could also support new, decentralized financial models in which users who provide training data receive a financial stake in a resulting ML model. It is in principle possible, for instance, to train and execute an ML model on a TEE-enabled blockchain such as Oasis Sapphire that ensures data privacy and can automatically bill for queries and distribute cryptocurrency tokens to community members who have earned a stake in the model [26].\nNote (Ownership rights): We don't address the issue of data ownership here. In some cases, the right to make use of personal data as desired is clearly attributable to an individ- ual user and supported by regulations such as Article 20 of GDPR [33], the right to data portability and, in the case of EHRs, the 21st Century Cures Act [9]. In other cases, as with photographs of individuals captured in private settings, legal restrictions, e.g., [17], or service agreements may limit a user's sharing rights. It is the responsibility of an application developer to enforce appropriate data sharing policies. The authentication of data sources offered by props can be instrumental in this goal."}, {"title": "How Can Props Be Built?", "content": "Why do props not yet exist? How can we build them? Two critical building blocks are needed: secure data sourcing and pinned models. Both are practically realizable today using existing tools and techniques."}, {"title": "Secure data sourcing", "content": "Secure data sourcing ensures that the data entering a prop comes from a trustworthy source, such as a specific web service, in the expected context and with strong privacy protections. In Example 1 this means ensuring that X represents BigHospital serving Alice's EHR. A practi- cal enhancement allows Alice to apply redactions or other preprocessing before transmitting X. Alice's data can then be input to the model-training environment\u2014in encrypted form if the environment is privacy-preserving. Today, however, secure channels to web servers (TLS / HTTPS) do not digitally sign data [30]. That means that while users can access their own web data securely, there's often no way to prove to someone else where the data came from. There are two ways to remedy this limitation of existing infrastructure.\nApproach 1: Infrastructure Modification. The first way to address the problem is to change the infrastructure, i.e., modify existing web services so that they sign data. JSON Web Tokens (JWTs) are an emerging standard for this purpose [14]. JWTs are gaining traction for certain forms of data, such as user credentials in OAuth 2.0 and OpenID Connect (OIDC). But most deep-web data isn't served today in the form of JWTs.\nApproach 2: Privacy-Preserving Oracles. A second, infrastructure-independent ap- proach involves privacy-preserving oracles [5]. These are tools developed for blockchain systems that allow secure data sourcing without modifying existing infrastructure. Privacy- preserving oracles come in two flavors. They can use trusted execution environments (TEEs) such as Intel SGX / TDX [8, 10, 20, 21] a technology that is increasingly supported in CPUs and even GPUs [23]. Town Crier [28, 41] was the first such oracle system. TEEs are flexible and powerful, but have long-recognized security limitations, such as repeatedly demonstrated vulnerability to side-channel attacks (e.g., in speculative execution) [4, 7, 16, 18, 34, 35, 36]. An alternative is to use a cryptographic alternative, often today called zkTLS [38] and first realized in the DECO system [42]. Both approaches enable a user to furnish deep-web data privately and with integrity to third parties in a prop as in our two examples. They work with any TLS-enabled web service. They also enable privacy protection as illustrated above: Data X can be pre-processed by a user and sent into a prop in encrypted form."}, {"title": "Pinned models", "content": "Secure data sourcing is generally sufficient for privacy-preserving model training, as in Ex- ample 1. But inference is another story. That requires the second building block for props, pinned models.\nIn Example 2, it isn't enough for PrivaLoan, the consumer of the model's output Y, to know that X is trustworthy. PrivaLoan also needs to know what model M was used for inference and the full execution environment E for M (hyperparameters, preprocessing, postprocessing, random seeds, etc.). If M was PrivaLoan's own model, PrivaLoan will naturally want assurance that the inference Y was the output of M on X.\nIt may suffice for PrivaLoan's purposes only to have model consistency, i.e., to know that X was input to a particular ML service, such as ChatGPT, without knowing exactly what E and M were. (ML services such as ChatGPT don't reveal E and M and frequently change"}, {"title": "Approaches for realizing pinned models", "content": "Executing a model (and environment) in a TEE is one practical way to realize pinned models. Recently rolled-out support for TEEs in NVIDIA GPUs [23] makes this approach especially viable. Another, complementary approach is to use a decentralized oracle network (DON) [5]. A committee of nodes in a DON could, for instance, each independently execute a model specification S on an input X and then reach consensus on the output Y. (Or they could each execute a different model specification, a form of ensemble learning [39].) Approaches such as zkML are also possible, but practical today only for small models [6]."}, {"title": "Conclusion", "content": "Props represent a new approach for secure, privacy-preserving access to deep-web data sources in machine learning. By enabling authenticated, privacy-preserving data pipelines, they address critical bottlenecks in data availability and model reliability within ML. Props can ensure robust data privacy and integrity across an entire ML pipeline, from sourcing and processing to training and model execution. Props are also flexible: They can verify data authenticity and model consistency, for instance, even in standard ML applications that don't require privacy. In short, by combining privacy-preserving oracle systems and pinned models, props establish a scalable pathway toward secure and reliable ML systems, unlocking the potential of deep-web data for ML capabilities."}, {"title": "Note on Props and Blockchain Technologies", "content": "It's not a coincidence that most of the technical tools needed for props saw some of their earliest production use in blockchain systems. High-assurance data delivery and application execution are especially prized in smart-contract-based blockchains, where adversaries can exploit even small vulnerabilities for quick monetary gain. Also, blockchain systems by design create a tension between transparency and privacy. Blockchains are transparent, but financial transactions usually involve sensitive data. Systems that ensure both data authenticity and privacy such as privacy-preserving oracle systems\u2014have sprung up to resolve this tension.\nProps are not just realizable using blockchain technologies but can also be useful for blockchain technologies. This is particularly true of props for inference, as in Example 2. The privacy-preserving, authenticated nature of outputs makes them suitable for consumption by smart contracts."}]}