{"title": "ArEEG_Words: Dataset for Envisioned Speech Recognition using EEG for Arabic Words", "authors": ["Hazem Darwish", "Abdalrahman Al Malah", "Khloud Al Jallad", "Nada Ghneim"], "abstract": "Brain-Computer-Interface (BCI) aims to support communication-impaired patients by translating neural signals into speech. A notable research topic in BCI involves Electroencephalography (EEG) signals that measure the electrical activity in the brain. While significant advancements have been made in BCI EEG research, a major limitation still exists: the scarcity of publicly available EEG datasets for non-English languages, such as Arabic. To address this gap, we introduce in this paper ArEEG_Words dataset, a novel EEG dataset recorded from 22 participants with mean age of 22 years (5 female, 17 male) using a 14-channel Emotiv Epoc X device. The participants were asked to be free from any effects on their nervous system, such as coffee, alcohol, cigarettes, and so 8 hours before recording. They were asked to stay calm in a clam room during imagining one of the 16 Arabic Words for 10 seconds. The words include 16 commonly used words such as up, down, left, and right. A total of 352 EEG recordings were collected, then each recording was divided into multiple 250ms signals, resulting in a total of 15,360 EEG signals. To the best of our knowledge, ArEEG_Words data is the first of its kind in Arabic EEG domain. Moreover, it is publicly available for researchers as we hope that will fill the gap in Arabic EEG research.", "sections": [{"title": "Introduction:", "content": "An important area of computer science that examines the relationship between people and computers is called human-computer interaction, or HCI.\nBrain-Computer-Interface (BCI) is one of the HCI fields that has seen a lot of researches in the last few years. Researchers are using artificial intelligence (AI) to interpret brainwaves, measured through electroencephalography (EEG), to understand what people are thinking. Recent advancements in BCI have shown promise in recognizing mental activities like imagining speech. However, using EEG signals to directly recognize spoken language through BCI is still a relatively new area of research.\nArabic language is an important and rich language spoken by over 400 million people worldwide, and it is the official language in many countries. However, Arabic Language is still one of the most challenging low-resource languages."}, {"title": "Related Works:", "content": "In 1924, Hans Berger [1] published the first paper about EEG classification, which was used later to develop EEG-based brain-computer interface (BCI). The main idea that Berger proposed a method that make use of EEG signals' frequencies to classify EEG signals into different categories.\nThere are several EEG publicly available datasets collected using different EEG devices, for various languages and covered a wide range of recognized units, including digits, characters, directions, audio, images, and words. This paper will specifically focus on word-based EEG datasets.\nEach study involved a varying number of participants, ranging from 3 to 29, with most being healthy adults. Data collection methods varied significantly. Participants might be shown objects for a certain duration, then asked to imagine the object, hear the imagined word mentally, or a combination of these. In some studies, participants were required to be free from any nervous system stimulants like caffeine, alcohol, or nicotine.\nIn [2] Pradeep Kumar et al. developed a system for recognizing imagined speech based on EEG signals. They collected data from 23 participants using an EPOC+ device where EEG signals has been recorded using 30 text and non-text class objects: letters, images and digits being imagined by multiple participants. To collect this data, participants were shown an object on a screen, then closed their eyes and imagined it for 10 seconds. After a 20-second rest period, they were shown the next object. A total of 230 EEG samples were collected for each object category and participant, resulting in a dataset of 230*30 *23 samples.\nNicol\u00e1s Nieto in [3] created a publicly available EEG-based BCI dataset for inner speech recognition using EEG 16, 17, 18, 19, 20, and 21 sensors on 10 participants (6 male, 4"}, {"title": "ArEEG_Words Dataset", "content": "EGG data was recorded using the Emotiv EPOC X headset from 22 adult participants (17 males, 5 females) who were educated at university level. Participants were told to maintain calm with clear thoughts throughout the data collection process. Additionally, they were advised not to consume caffeine, alcohol, or smoke before 8 hours of the recordings to prevent any impact on their nervous systems. Each participant spent approximately about"}, {"title": "Conclusion", "content": "This research aims to fill a gap in Arabic Brain-Computer Interface (BCI) research by creating a publicly available dataset of EEG signals corresponding to specific Arabic words, called ArEEG_Words. This dataset includes data for 16 Arabic words collected from 22 participants, primarily young adults with mean age of 22 years (5 female, 17 male). As for future work, we are willing to create baseline models using deep learning to predict Arabic words from the EEG signals. Furthermore, as the importance of a richer data pool, we think of expanding ArEEG_Words in future by adding more words and more participants. By making this dataset public, we aim to accelerate advancements in BCI technology, particularly for Arabic native individuals with communication disabilities."}]}