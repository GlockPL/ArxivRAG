{"title": "A Survey on Diffusion Models for Inverse Problems", "authors": ["Giannis Daras", "Hyungjin Chung", "Chieh-Hsin Lai", "Yuki Mitsufuji", "Jong Chul Ye", "Peyman Milanfar", "Alexandros G. Dimakis", "Mauricio Delbracio"], "abstract": "Diffusion models have become increasingly popular for generative modeling due to their ability to generate high-quality samples. This has unlocked exciting new possibilities for solving inverse problems, especially in image restoration and re-construction, by treating diffusion models as unsupervised priors. This survey provides a comprehensive overview of methods that utilize pre-trained diffusion models to solve inverse problems without requiring further training. We introduce taxonomies to categorize these methods based on both the problems they address and the techniques they employ. We analyze the connections between different approaches, offering insights into their practical implementation and highlighting important considerations. We further discuss specific challenges and potential so-lutions associated with using latent diffusion models for inverse problems. This work aims to be a valuable resource for those interested in learning about the in-tersection of diffusion models and inverse problems.", "sections": [{"title": "1 Introduction", "content": ""}, {"title": "1.1 Problem Setting", "content": "Inverse problems are ubiquitous and the associated reconstruction problems have tremendous applications across different domains such as seismic imaging [37, 38], weather prediction [39], oceanography [40], audio signal processing [41, 42, 43, 44, 45, 46], medical imaging [47, 48, 49, 50], etc.\nDespite their generality, inverse problems across different domains follow a fairly unified mathematical setting. Specifically, in inverse problems, the goal is to recover an unknown sample x \u2208 Rn from a distribution px, assuming access to measurements y \u2208 Rm and a corruption model\n\nY = A(X) + \u03c3yZ, Z ~ N(0, Im).\n\nIn what follows, we present some well-known examples of measurement models that fit under this general formulation.\nExample 1.1 (Denoising). The simplest interesting example is the denoising inverse problem, i.e. when A is the identity matrix and \u03c3y > 0. In fact, the noise model does not have to be Gaussian and it can be generalized to other distributions, including the Laplacian Distribution or the Poisson Distribution [51]. For the purposes of this survey, we focus on additive Gaussian noise.\nA lot of practical applications arise from the non-invertible linear setting, i.e. for A(X) = AX and A being an m \u00d7 n matrix with m < n.\nExample 1.2 (Inpainting). A is a masking matrix, i.e. Aij = 0 for i \u2260 j and Aii is either 0 or 1, based on whether the value at this location is observed.\nExample 1.3 (Compressed Sensing). A is a matrix with entries sampled from a Gaussian random variable.\nExample 1.4 (Convolutions). Here A(X) represents the convolution of X with a (Gaussian or other) kernel, which is again a linear operation."}, {"title": "1.2 Recovery types", "content": "One common characteristic of these problems is that information is lost and perfect recovery is im-possible [75], i.e. they are ill-posed. Hence, the type of \u201crecovery\u201d we are looking for should be carefully defined [76]. For instance, one might be looking for the point that maximizes the posterior distribution p(xy) [77, 78]. Often, the Maximum a posteriori (MAP) estimation coincides with the Minimum Mean Squared Error Estimator, i.e. the conditional expectation E[xy] [79, 80]. MMSE estimation attempts to minimize distortion of the unknown signal \u00e6, but often lead to unrealistic recoveries. A different approach is to sample from the full posterior distribution, p(x|y). Posterior sampling accounts for the uncertainty of the estimation, and typically produces samples that have higher perception quality. Blau and Michaeli [81] show that, in general, it is impossible to find a sample that maximizes perception and minimizes distortion at the same time. Yet, posterior sampling is nearly optimal [1] in terms of distortion error."}, {"title": "1.3 Approaches for Solving Inverse Problems", "content": "Inverse problems have a rich history, with approaches evolving significantly over the decades Ribes and Schmitt [82], Barrett and Myers [83]. While a comprehensive review is beyond the scope of this survey, we highlight key trends to provide context. Early approaches, prevalent in the 2000s, often framed inverse problems as optimization tasks Daubechies et al. [84], Cand\u00e8s et al. [85], Donoho [86], Figueiredo and Nowak [87], Daubechies et al. [84], Hale et al. [88], Shlezinger et al. [89]. These methods sought to balance data fidelity with regularization terms that encouraged desired solution properties like smoothness Rudin et al. [90], Beck and Teboulle [91] or sparsity in specific representations (e.g., wavelets, dictionaries) Figueiredo and Nowak [87], Daubechies et al. [84], Cand\u00e8s et al. [85], Donoho [86], Hale et al. [88].\nThe advent of deep learning brought a paradigm shift Ongie et al. [92]. Researchers began leveraging large paired datasets to directly learn mappings from measurements to clean signals using neural networks Dong et al. [93], Lim et al. [94], Tao et al. [95], Chen et al. [96], Zamir et al. [97], Chen et al. [98], Tu et al. [99], Zamir et al. [100]. These approaches focus on minimizing some reconstruction loss during training, with various techniques employed to penalize distortions, and optimize for specific application goals (e.g., perceptual quality Isola et al. [101], Kupyn et al. [102]). Traditional point estimates aim to recover a single reconstruction by for example minimizing the average reconstruction error (i.e., MMSE) or by finding the most probable reconstruction through Maximum a Posteriori estimate (MAP), i.e., finding the x that maximizes p(xy). While powerful, this approach can suffer from \u201cregression to the mean\", where the network predicts an average solution that may lack important details or even be outside the desired solution space Blau and Michaeli [81], Del-bracio and Milanfar [103]. In fact, learning a mapping to minimize a certain distortion metric will lead, in the best case, to an average of all the plausible reconstructions (e.g., when using a L2 reconstruction loss, the best-case solution will be the posterior mean). This reconstruction might not be in the target space (e.g., a blurry image being the average of all plausible reconstructions) Blau and Michaeli [81].\nRecent research has revealed a striking connection between denoising algorithms and inverse prob-lems. Powerful denoisers, often based on deep learning, implicitly encode valuable information about natural signals. By integrating these denoisers into optimization frameworks, we can harness their learned priors to achieve exceptional results in a variety of inverse problems Venkatakrishnan et al. [104], Sreehari et al. [105], Chan et al. [106], Romano et al. [107], Cohen et al. [108], Kad-khodaie and Simoncelli [109], Kamilov et al. [110], Milanfar and Delbracio [111]. This approach bridges the gap between traditional regularization methods and modern denoising techniques, offer-ing a promising new paradigm for solving these challenging tasks.\nAn alternative perspective views inverse problems through the lens of Bayesian inference. Given measurements y, the goal becomes generating plausible reconstructions by sampling from the pos-terior distribution p(X|Y = y) \u2013 the distribution of possible signals \u00e6 given the observed measure-ments y.\""}, {"title": "In this survey we explore a specific class of methods that utilize diffusion models as priors for px,\nand then try to generate plausible reconstructions (e.g., by sampling from the posterior). While\nother approaches exist, such as directly learning conditional diffusion models or flows for specific\ninverse problems Li et al. [112], Saharia et al. [71, 113], Whang et al. [114], Luo et al. [115, 116],\nAlbergo and Vanden-Eijnden [117], Albergo et al. [118], Lipman et al. [119], Liu et al. [120, 121],\nShi et al. [122], these often require retraining for each new application. In contrast, the methods\ncovered in this survey offer a more general framework applicable to arbitrary inverse problems\nwithout retraining or fine-tuning.", "content": "Unsupervised methods. We refer as unsupervised methods to those that focus on characterizing the distribution of target signals, px, and applying this knowledge during the inversion process. Since they don't rely on paired data, they can be flexibly applied to different inverse problems using the same prior knowledge.\nUnsupervised methods can be used to maximize the likelihood of p(xy) or to sample from this dis-tribution. Algorithmically, to solve the former problem we typically use (some variation of) Gradient Descent and to solve the latter (some variation of) Monte Carlo Simulation (e.g., Langevin Dynam-ics). Either way, one typically requires to compute the gradient of the conditional log-likelihood, i.e., Vx log p(xy).\nA simple application of Bayes Rule reveals that:\n\nVlog p(xy) = \u221ax log p(x) + Vlog p(yx) .\n\n\nThe last term typically has a closed-form expression, e.g. for the linear case, we have that:\n\u2207 log p(y|x) = \u03c3-2\u0391\u03a4(y-Ax). However, the first term, known as the score function, might be hard to estimate when the data lie on low-dimensional manifolds. The problem arises from the fact that we do not get observations outside of the manifold and hence the vector-field estimation is inaccurate in these regions.\nOne way to sidestep this issue is by using a \u201csmoothed\u201d version of the score function, representing the score function of noisy data that will be supported everywhere. The central idea behind diffusion generative models is to learn score functions that correspond to different levels of smoothing. Specifically, in diffusion modeling, we attempt to learn the smoothed score functions, \u2207\u00e6t log pt (xt), where Xt = X0 + \u03c3\u03c4Z, Z ~ N(0, I), for different noise levels t. During sampling, we progres-sively move from more smoothed vector fields to the true score function. At the very end, the score function corresponding to the data distribution is only queried at points for which the estimation is accurate because of the warm-start effect of the sampling method.\nEven though estimating the unconditional score becomes easier (because of the smoothing), the measurement matching term becomes time dependent and loses its closed form expression. Indeed, the likelihood of the measurements is given by the intractable integral:\n\nPt(Y\\Xt) = \u222b P(Y|Xo)p(xo|Xt)dxo.\n\n\nThe computational challenge that emerges from the intractability of the conditional likelihood has led to the proposal of numerous approaches to use diffusion models to solve inverse problems [1, 4, 5, 2, 3, 9, 8, 11, 12, 13, 6, 123, 124, 16, 18, 19, 24, 25, 28, 29, 30, 20, 21, 125, 126]. The sheer number of the proposed methods, but also the different perspectives under which these methods have been developed, make it hard for both newcomers and experts in the field to understand the connections between them and the unifying underlying principles. This work attempts to explain, taxonomize and relate prominent methods in the field of using diffusion models for inverse problems. Our list of methods is by no means exhaustive. The goal of this manuscript is not to list all the methods that have been proposed but to review some representative methods of different approaches and present them under a unifying framework. We believe this survey will be useful as a reference point for people interested in this field."}, {"title": "2 Background", "content": ""}, {"title": "2.1 Diffusion Processes", "content": "Forward and Reverse Processes. The idea of a diffusion model is to transform a a simple dis-tribution (e.g., normal distribution) into the unknown data distribution po(x), that we don't know explicitly but we have access to some of its samples. The first step is to define a corruption process. The popular Denoising Diffusion Probabilistic Models (DDPM) Ho et al. [127], Song and Ermon [128], adopt a discrete time Markovian process to transform the input Normal distribution into the target one by incrementally adding Gaussian noise. More generally, the corruption processes of interest can be generalized to continuous time by a stochastic differential eqaution (SDE) [2]:\n\ndxt = f(xt,t) dt + g(t) dWt,\n\nwith xo ~ Po, xo \u2208 Rn, and Wt denotes a Wiener process (i.e., Brownian motion). This SDE gradually transforms the data distribution into Gaussian noise. We denote with pt the distribution that arises by running this dynamical system up to time t.\nA remarkable result by Anderson [129] shows that we can sample from po by running backwards in time the reverse SDE:\n\ndxt = (f(xt, t) - g\u00b2(t) \u2207log pt (xt)) dt + g(t)dWt,\n\ninitialized at \u00e6\u0442 ~ p\u0442. For sufficiently large T and for linear drift functions f(\u00b7,\u00b7), the latter dis-tribution approaches a Gaussian distribution with known parameters that can be used for initializing the process. Hence, the remaining goal becomes to estimate the score function \u2207x log pt (xt).\nProbability Flow ODE. Song et al. [2], Maoutsa et al. [130] observe that the (deterministic) dif-ferential equation:\n\ndxt/dt = f(xt, t) - g\u00b2(t)/2 \u2207log pt (xt),\n\ncorresponds to the same Fokker-Planck equations as the SDE of Equation 2.2. An implication of this is we can use the deterministic sampling scheme of Equation 2.3. Any well-built numerical ODE solver can be used to solve Equation 2.3, such as the Euler solver:\n\nxt-\u0394t =xt + \u0394t (f(xt,t) - g\u00b2(t)/2 \u2207log pt (xt)) .\n\nSDE variants: Variance Exploding and Variance Preserving Processes. The drift coefficients, f(x,t), and the diffusion coefficients g(t) are design choices. One popular choice, known as the Variance Exploding SDE, is setting f(x,t) = 0 and g(t) = \u03c3t d/dt for some variance schedul-ing {\u03c3t}t=0^T. Under these choices, the marginal distribution at time t of the forward process of Equation 2.1 can be alternatively described as:\n\nXt = \u03a7\u03bf + \u03c3\u03c4\u0396, \u03a7\u03bf ~ p(\u03a7\u03bf), Z ~ N(0, In).\n\nThe typical noise scheduling for this SDE is ot = \u221at (that corresponds to g(t) = 1).\nAnother popular choice is to set the drift function to be f(x,t) = -xt, which is known as the Variance Preserving (VP) SDE. A famous process in the VP SDE family is the Ornstein-Uhlenbeck (OU) process:\n\ndxt = -x+dt + \u221a2dWt,\n\nwhich gives:\n\nXt = exp(-t)X0 + \u221a1 \u2013 exp(-2t)Z, Z ~ N(0, In)."}, {"title": "The VP SDE [127] takes a more general form:", "content": "\nXt = \u221aatXo+ (1 - at)Z, Xo ~p(Xo), Z ~ N(0, In).\n\nWith reparametrization and the Euler solver, this leads to an efficient solution to Equation 2.3, known as DDIM [131]:\n\nXt-1 = \u221aat-1 (X+ + (1 \u2212 at)\u2207\u00e6r log pt(xt)) -\u221a1-at\u2207\u00e6t log pt (xt)) .\n\nFor convenience, in the rest of the paper, this update will be written as: Xt-1 \u2190 UnconditionalDDIM(20, xt)."}, {"title": "2.2 Tweedie's Formula and Denoising Score Matching", "content": "In what follows, we will discuss how one can learn the score function \u2207\u00e6\u2081 log pt(xt) that appears in Equation 2.17. We will focus on the VE SDE, since the mathematical calculations are simpler.\nTweedie's formula [132] is a famous result in statistics that shows that for an additive Gaussian corruption, Xt = X0 + \u03c3\u03c4Z, Z ~ N(0, In), it holds that:\n\nVx+log pt(xt) = (E[Xo|Xt = xt] - Xt)/\u03c3\u03c4.\n\nThe formal statement and a self-contained proof can be found in the Appendix, Lemma A.2.\nTweedie's formula gives us a way to derive the unconditional score function needed in Equation 2.17, by optimizing for the conditional expectation, E[XoXt = xt]. The conditional expectation E[Xo Xt = xt], is nothing more than the minimum mean square error estimator (MMSE) of the clean image given the noisy observation xt, that is a denoiser.\nIn practice, we don't know analytically this denoiser but we can parametrize it using a neural network ho(xt) and learn it in a supervised way by minimizing the following objective:\n\nJDSM(0) = Ex0,xt [||ho(xt) \u2013 Xo||2] .\n\nAssuming a rich enough family \u0398, the minimizer of Equation 2.11 is ho(xt) = E[xo Xt = xt] (see Lemma A.1) and the score in Equation 2.10 is approximated as (he(xt) \u2013 xt)/\u03c37. Note that for each \u03c3\u03b5 we would need to learn a different denoiser (since the noise strength is different), or alternative the neural network he should also take as input the value of t or \u03c3\u03c4. Diffusion models are trained following the later paradigm, i.e. the same neural network approximates the optimal denoisers at all noise levels by conditioning it on the noise level through t.\nInterestingly, Vincent [133] independently discovered that the score function can be learned by min-imizing an 12 objective, similar to Equation 2.11. The formal statement and a self-contained proof of this alternative derivation is included in the Appendix, Theorem A.3."}, {"title": "2.3 Latent Diffusion Processes", "content": "For high-dimensional distributions, diffusion models training (see Equation 2.11) and sampling (see Equation 2.3) require massive computational resources. To make the training and sampling more efficient, the authors of Stable Diffusion Rombach et al. [134] propose performing the diffusion in the latent space of a pre-trained powerful autoencoder. Specifically, given an encoder Enc : Rn \u2192 Rk and a decoder Dec : Rk \u2192 R"}, {"content": ", one can create noisy samples:\n\nE X = X +\u03c3\u1e6dZ, Z ~ N(0, Ik),\n\nand train a denoiser network in the latent space. At inference time, one starts with pure noise, samples a clean latent by running the reverse process, and outputs x0 = Dec(x). Solving"}, {"title": "2.4 Conditional Sampling", "content": ""}, {"title": "2.4.1 Stochastic Samplers for Inverse Problems", "content": "The goal in inverse problems is to sample from po(y) assuming a corruption model Y = \u0391(\u03a7\u03bf) + \u03c3\u03c5\u0396, Z ~ N(0, Im). We can easily adapt the original unconditional formulation given by Equation 2.2 into a conditional one to generate samples from po(\u00b7|y). Specifically, the associated reverse process is given by the stochastic dynamical system [135]:\n\ndxt = (f(x, t) - g\u00b2 (t) (\u2207x+ log pt (xty)) dt + g(t)dWt,\n\ninitialized at \u00e6\u0442 ~ \u0440\u0442(\u00b7|y). For sufficiently large T and for linear drift functions f(\u00b7, \u00b7), the distri-bution pr(y) is a Gaussian distribution with parameters independent of y. In the conditional case, the goal becomes to estimate the score function \u2207\u00e6t log pt (xty)."}, {"title": "2.4.2 Deterministic Samplers for Inverse Problems", "content": "It is worth noting that (as in the unconditional setting) it is possible to derive deterministic sampling algorithms as well. Particularly, one can use the following dynamical system [2, 135]:\n\ndxt/dt = -g\u00b2(t)/2 \u2207x+ log pt(x+y).\n\ninitialized at pr(y) to get sample from the conditional distribution po(\u00b7|y). Once again, to run this discrete dynamical system, one needs to know the conditional score, \u2207xt log pt (xt|y)."}, {"title": "2.4.3 Conditional Diffusion Models", "content": "Similarly to the unconditional setting, one can directly train a network to approximate the conditional score, \u2207\u00e6\u2081 log pt(xt|y). A generalization of Tweedie's formula gives that:\n\nVlog pt (xty) = (E[Xo Xt = xt, Y = y] - Xt)/\u03c3\u03c4.\n\nHence, one can train a network using a generalized version of the Denoising Score Matching:\n\nJcond, DSM(0) = Exo,x1,y [||ho (X, Y) - xo||2],\n\nand then use it in Equation 2.15 in place of the conditional expectation. The main issue with this approach is that the forward model (degradation operator) needs to be known at training time. If the corruption model A(X) changes, then the model needs to be retrained. Further, with this approach we need to train new models and we cannot directly leverage powerful unconditional models that are already available. The focus of this work is on methods that use pre-trained unconditional diffusion models to solve inverse problems, without further training."}, {"title": "2.4.4 Using pre-trained diffusion models to solve inverse problems", "content": "As we showed earlier, the conditional score can be decomposed using Bayes Rule into:\n\nVx+log pt (xt y) = \u221ax+ log pt(xt) + Vxt log p(yxt).\n\nthat is, the (smoothed) score function, and the measurements matching term that is given by the inverse problem we are interested in solving. Applying this to equation 2.13, we get that:\n\ndxt = (f(xt,t) \u2013 g\u00b2(t) (\u2207x\u2081 log pt(xt) + \u2207logp(y|xt))) dt + g(t)dWt."}, {"title": "Similarly, one can use the deterministic process:", "content": "\n\ndxt = (f(x,t) - 1/2 g\u00b2(t) (\u2207x, log pt(xt) + \u2207logp(yxt))) dt.\n\nWe have already discussed how to train a neural network to approximate V\u00e6t log pt(xt) (using Tweedie's Formula / Denoising Score Matching). However, here we further need access to the term Vx+log p(yxt). The likelihood of the measurements is given by the intractable integral:\n\nPt(Y\\xt) = \u222b P(Y|xo)p(xo|xi)dxo.\n\nGupta et. al [136] prove that there are instances of the posterior sampling problem for which every algorithm takes superpolynomial time, even though unconditional sampling is provably fast. Hence, diffusion models excel at performing unconditional sampling but are hard to use as priors for solving inverse problems because of the time dependence in the measurements matching term. Since the very introduction of diffusion models, there has been a plethora of methods proposed to use them to solve inverse problems without retraining. This survey serves as a reference point for different techniques that have been developed in this space."}, {"title": "2.4.5 Ambient Diffusion: Learning to solve inverse problems using only measurements", "content": "The goal of the unsupervised learning approach for solving inverse problems (Section 2.4.4) is to use a prior p(x) to approximate the measurements matching term, \u2207log pt(y|xt). However, in certain applications, it is expensive or even impossible to get data from (and hence learn) p(x) in the first place. For instance, in MRI the quality of the data is proportionate to the time spent under the scanner [59] and it is infeasible to acquire full measurements from black holes [74]. This creates a chicken-egg problem: we need access to p(x) to solve inverse problems and we do not have access to samples from p(x) unless we can solve inverse problems. In certain scenarios, it is possible to break this seemingly impossible cycle.\nAmbient Diffusion Daras et al. [137] was one of the first frameworks to train diffusion models with linearly corrupted data. The key concept behind the Ambient Diffusion framework is the idea of further corruption. Specifically, the given measurements get further corrupted and the model is trained to predict a clean image by using the measurements before further corruption for validation. Ambient DPS [49] shows that priors learned from corrupted data can even outperform (in terms of usefulness for inverse problems), at the high-corruption regime, priors learned from clean data. Ambient Diffusion was extended to handle additive Gaussian Noise in the measurements. The paper Consistent Diffusion Meets Tweedie Daras et al. [138] was the first diffusion-based framework to provide guarantees for sampling from the distribution of interest, given only access to noisy data. This paper extends the idea of further corruption to the noisy case and proposes a novel consistency loss Daras et al. [139] to learn the score function for diffusion times that correspond to noise levels below the level of the noise in the dataset.\nBoth Ambient Diffusion and Consistent Diffusion Meets Tweedie have connections to deep ideas from the literature in learning restoration models from corrupted data, such as Stein's Unbiased Risk Estimate (SURE) Eldar [140], Stein [141] and Noise2X Lehtinen et al. [142], Krull et al. [143], Batson and Royer [144]. These connections are also leveraged by alternative frameworks to Ambient Diffusion, as in [8, 58]. A different approach for learning diffusion models from measurements is based on the Expectation-Maximization (EM) algorithm [145, 6, 146]. The convergence of these methods to the true distribution depends on the convergence of the EM algorithm, which might get stuck in a local minimum.\nIn this survey, we focus on the setting where a pre-trained prior p(x) is available, regardless of whether it was learned from clean or corrupted data."}, {"title": "3 Reconstruction Algorithms", "content": "We summarize all the methods analyzed in this work in Table 1. The methods have been taxono-mized based on the approach they use to solve the inverse problem (explicit score approximations, variational methods, CSGM-type methods and asymptotically exact methods), the type of inverse"}, {"title": "3.1 Explicit Approximations for the Measurements Matching Term", "content": "The first family of reconstruction algorithms we identify is the one were explicit approximations for the measurements matching term, V\u00e6\u2081 log p(y|Xt = xt), are made. It is important to underline that these approximations are not always clearly stated in the works that propose them, which makes it hard to understand the differences and commonalities between different methods. In what follows, we attempt to elucidate the different approximations that are being made and present different works under a common framework. To provide some insights, we often provide the explicit approximation formulas for the measurements matching term in the setting of linear inverse problems. In general, it follows the template form:\n\nV\u00e6t log p(y Xt = xt) \u2248 Lt Mt/Gt.\n\nHere,"}, {"title": "3.1.0 Sampling from a Denoiser Kadkhodaie and Simoncelli [30]", "content": "Kadkhodaie and Simoncelli [30] introduce a method for solving linear inverse problems by using the implicit prior knowledge captured by a pre-trained denoiser on multiple noise levels. The method is anchored on Tweedie's formula that connects the least-squares solution for Gaussian denoising to the gradient of the log-density of noisy images given in Equation 2.10\n\nx(y) = y + \u03c3\u00b2\u2207y log p(y),\n\nwhere y = x + n, n ~ N(0, \u03c3\u00b2 \u0399\u03b7).\nBy interpreting the denoiser's output as an approximation of this gradient, the authors develop a stochastic gradient ascent algorithm to generate high-probability samples from the implicit prior\n\nYt = Yt-1 + htr(yt-1) + Etzt,\n\nwhere r(y) = x(y) \u2013 y is the denoiser residual, ht is a step size (parameter), and et controls the amount of newly introduced Gaussian noise zt.\nTo solve linear inverse problems such as deblurring, super-resolution, and compressive sensing, the generative method is extended to handle constrained sampling. Given a set of linear measurements x = Mx of an image x, where M is a low-rank measurement matrix, the goal is to reconstruct the original image by utilizing the following gradient:\n\nVy log pyxc) = (I \u2013 MM\u00af)r(y) + M(xc \u2013 M\u00afy),\n\nThis approach is particularly interesting because its mathematical foundation relies solely on Tweedie's formula, providing a simple yet powerful framework for tackling inverse problems us-ing denoisers."}, {"title": "3.1.1 Score ALD [1]", "content": "One of the first proposed methods for solving linear inverse problems with diffusion models is the Score-Based Annealed Langevin Dynamics (Score ALD) [1] method. The approximation of this work is that:\n\n7xt log p(y Xt = xt) \u2248 AT (y - Axt) .\n\nwhere Yt is a parameter to be tuned.\nIt is pretty straightforward to understand what this term is doing. The diffusion process is guided towards the opposite direction of the \u201clifting\u201d (application of the AT operator) of the measurements error, i.e. (y - Axt), where the denominator controls the guidance strength."}, {"title": "3.1.2 Score-SDE [2]", "content": "Score-SDE [2] is another one of the first works that discussed solving inverse problems with pre-trained diffusion models. For linear inverse problems, the difference between Score-ALD and Score-SDE is that the latter noises the measurements before computing the measurements error. Specifi-cally, for t : \u03c3\u03c4 > \u03c3y, the approximation becomes:"}, {"title": "3.1.3 ILVR [3]", "content": "ILVR is a similar approach that was initially proposed for the task of super-resolution. The approxi-mation made here is the following:\n\nV\u00e6t log p(y Xt = xt) \u2248 \u2212A\u2020(yt - Axt) = \u00b7 (ATA)-1AT ( Yt Axt),\n\nwhere At is the Moore-Penrose pseudo-inverse of A, and similar to Score-SDE, yt = y +\u03c3\u03c4\u03b5.\nILVR can be regarded as a pre-conditioned version of score-SDE. In ILVR, the projection to the space of images happens using the Moore-Penrose pseudo-inverse of A, instead of the simple AT."}, {"title": "3.1.4 DPS", "content": "All of the previous algorithms were proposed for linear inverse problems. Diffusion Posterior Sam-pling (DPS) is one of the most well known reconstruction algorithms for solving non-linear inverse problems. The underlying approximation behind DPS is that:\n\nVxt log p(y Xt = xt) \u2248 \u2207x\u2081 logp(y|X0 = E[Xo|Xt = xt]).\n\nIt is easy to see that:\n\np(y|Xo = E[Xo|Xt = xt]) = N (y; \u03bc = A(E[X0|Xt = xt]), \u03a3 = \u03c3\u0399) .\n\nHence, the DPS approximation can be stated as:\n\nV\u00e6\u2081 logp(y|Xt = xt) \u2248 V\u00e6\u2081 log N (y; \u03bc = A(E[X0|Xt = xt]), \u03a3 = \u03c32\u0399)\n\n\n\n= \u2207A(E[Xo Xt = xt]) (A(E[Xo|Xt = xt]) \u2013 y) .\n\nFor linear inverse problems, this simplifies to:\n\n\u25bd\u00e6t log p(y|Xt = xt) \u2248 VE[XoXt = xt] A+ (y - AE[Xo Xt = xt]).\n\nIn practice, DPS does not use the theoretical guidance strength but instead proposes to use a reweight-ing with a step size inversely proportional to the norm of the measurement error.\nMCG Chung et al. [31] provides a geometric interpretation of DPS by showing that the approxi-mation used in DPS can guarantee the noisy samples stay on the manifold. DSG Yang et al. [147] showed that one can choose a theoretically \u201ccorrect\" step size under the geometric view of MCG, and combined with projected gradient descent, one can achieve superior sample quality. MPGD He et al. [33] showed that by constraining the gradient update step to stay on the low dimensional subspace by autoencoding, one can acquire better results.\""}, {"title": "3.1.5 HGDM Song et al. [5]", "content": "Recall the intractable integral in Equation 1.3. According to this relation, the DPS approximation is achieved by setting\n\np(XoXt) \u2248 8(\u03a7\u03bf \u2013 \u0395[Xo Xt = xt]).\n\nIn IGDM, the authors propose to use a Gaussian distribution for approximation\n\np(Xo|Xt) \u2248 N(E[X0|Xt = xt], r+In),\n\nwhere rt is a hyperparameter. For linear inverse problems, this leads to\n\np(y/Xt) \u2248 N(A\u00ca[Xo|Xt = xt], r\u00b2 AA + In).\n\nSubsequently, we have\n\n\u25bdx+log p(y Xt = xt)= JE [Xo Xt = xXt]/(dxt) (r\u00b2AAT +2)-1AT ( y \u2212 AE[X0|Xt = xt] )."}, {"title": "3.1.6 Moment Matching [6]", "content": "In IGDM", "V[xoxt": ".", "that": "n\nV[xoxt", "\u03c3\u03b1\u2081E[xoxt": ".", "6": "method approximates the distribution p(xoxt) with an anisotropic Gaus-sian:\n\np(xoxt) \u2248 N(E[xo|xt"}]}