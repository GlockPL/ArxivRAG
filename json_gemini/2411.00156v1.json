{"title": "Unlocking the Potential of Global Human Expertise", "authors": ["Elliot Meyerson", "Olivier Francon", "Darren Sargent", "Babak Hodjat", "Risto Miikkulainen"], "abstract": "Solving societal problems on a global scale requires the collection and processing\nof ideas and methods from diverse sets of international experts. As the number\nand diversity of human experts increase, so does the likelihood that elements in\nthis collective knowledge can be combined and refined to discover novel and better\nsolutions. However, it is difficult to identify, combine, and refine complementary\ninformation in an increasingly large and diverse knowledge base. This paper argues\nthat artificial intelligence (AI) can play a crucial role in this process. An evolu-\ntionary AI framework, termed RHEA, fills this role by distilling knowledge from\ndiverse models created by human experts into equivalent neural networks, which\nare then recombined and refined in a population-based search. The framework was\nimplemented in a formal synthetic domain, demonstrating that it is transparent and\nsystematic. It was then applied to the results of the XPRIZE Pandemic Response\nChallenge, in which over 100 teams of experts across 23 countries submitted\nmodels based on diverse methodologies to predict COVID-19 cases and suggest\nnon-pharmaceutical intervention policies for 235 nations, states, and regions across\nthe globe. Building upon this expert knowledge, by recombining and refining the\n169 resulting policy suggestion models, RHEA discovered a broader and more\neffective set of policies than either AI or human experts alone, as evaluated based\non real-world data. The results thus suggest that AI can play a crucial role in\nrealizing the potential of human expertise in global problem-solving.", "sections": [{"title": "1 Introduction", "content": "Integrating knowledge and perspectives from a diverse set of experts is essential for developing better\nsolutions to societal challenges, such as policies to curb an ongoing pandemic, slow down and reverse\nclimate change, and improve sustainability [33, 41, 57, 63, 64]. Increased diversity in human teams\ncan lead to improved decision-making [25, 62, 83], but as the scale of the problem and size of the\nteam increases, it becomes difficult to discover the best combinations and refinements of available\nideas [37]. This paper argues that artificial intelligence (AI) can play a crucial role in this process,\nmaking it possible to realize the full potential of diverse human expertise. Though there are many AI\nsystems that take advantage of human expertise to improve automated decision-making [4, 31, 66],\nan approach to the general problem must meet a set of unique requirements: It must be able to\nincorporate expertise from diverse sources with disparate forms; it must be multi-objective since\nconflicting policy goals will need to be balanced; and the origins of final solutions must be traceable\nso that credit can be distributed back to humans based on their contributions. An evolutionary AI\nframework termed RHEA (for Realizing Human Expertise through AI) is developed in this paper to\nsatisfy these requirements. Evolutionary AI, or population-based search, is a biologically-inspired\nmethod that often leads to surprising discoveries and insights [5, 15, 39, 48, 67]; it is also a natural fit\nhere since the development of ideas in human teams mirrors an evolutionary process [14, 17, 38, 32].\nImplementing RHEA for a particular application requires the following steps (Fig. 1):"}, {"title": "2 Illustrative Example", "content": "In this section, RHEA is applied to a formal synthetic setting where its principles and mechanics are\ntransparent. It is thus possible to demonstrate how they can lead to improved results, providing a\nroadmap for when and how to apply it to real-world domains (see App. B for additional details).\nConsider a policy-making scenario in which many new reasonable-sounding policy interventions are\nconstantly being proposed, but there are high levels of nonlinear interaction between interventions\nand across contexts. Such interactions are a major reason why it is difficult to design effective policies\nand the main challenge that RHEA is designed to solve. They are unavoidable in complex real-world\ndomains such as public health (e.g., between closing schools, requiring masks, or limiting international\ntravel), traffic management (e.g., adding buses, free bus tokens, or bike lanes), and climate policy\n(e.g., competing legal definitions of \u201cnet-zero\u201d or \u201cgreen hydrogen\", and environmental feedback\nloops) [19, 52, 60]. In such domains there exist diverse experts-e.g., policymakers, economists,\nscientists, local community leaders, and other stakeholders-whose input is worth soliciting before\nimplementing interventions. In RHEA, this policy-making challenge can be formalized as follows:\nDefine. Suppose we are considering policy interventions $a_1,..., a_n$. A policy action $A$ consists\nof some subset of these. Suppose we must be prepared to address contexts $c \\in \\{C_1,..., C_m\\}$,\nand we have a black-box predictor $(c, A)$ to evaluate utility (Fig. 1a). In practice, $ will be a\ncomplex dynamical model such as an agent-based or neural-network-based predictor. In this example,\nto highlight the core behavior of RHEA, $ is a simple-to-define function containing the kinds of\nchallenging nonlinearities we would like to address, such as context dependence, synergies, anti-\nsynergies, threshold effects, and redundancy (the full utility function is detailed in Eq. 1). Similarly, $\u03c8$\nis a simple cost function, defined as the total number of prescribed policy interventions. A prescriptor\nis a function $\u03c0(c) = A$ (Fig. 1b). The goal is to find a Pareto front of prescriptors across the outcomes\nof utility $ and cost $\u03c8$. Note that the search space is vast: There are $2^{mn}$ possible prescriptors.\nGather. Suppose prescriptors of unknown functional form have been gathered (Fig. 1c) from three\nexperts: one \u201cgeneralist\u201d, providing general knowledge that applies across contexts (see Fig. 2c\nfor an example); and two \u201cspecialists\u201d, providing knowledge that is of higher quality (i.e. lower\ncost-per-utility) but applies only to a few specific contexts (Fig. 2a-b).\nDistill. Datasets for distillation can be generated by running each expert prescriptor over all contexts.\nThe complete behavior of a prescriptor can then be visualized as a binary grid, where a black cell\nindicates the inclusion of an intervention in the prescription for a given context (Fig. 2a-c). This data\ncan be used to convert the expert prescriptors into rule sets or neural networks (Fig. 1d, App. B.2).\nEvolve. These distilled models can then be injected into an initial population and evolved using\nmulti-objective optimization [16] (Fig. 1e). The full optimal Pareto front is obtained as a result.\nWith this formalization, it is possible to construct a synthetic example of RHEA in action, as shown\nin Fig. 2. It illustrates the optimal Pareto front. Importantly, this front is discoverable by RHEA, but\nnot by previous machine learning techniques such as Mixture-of-Experts (MoE) [42] or Weighted\nEnsembles [18], or by the experts alone. RHEA is able to recombine the internal structure of experts\nacross contexts (e.g., by adding a3, a4, a5 to a1, a2 in c\u2081). It can innovate beyond the experts by\nadding newly-applicable interventions (a6). It can also refine the results by removing interventions\nthat are now redundant or detrimental (a5 in c\u2082), and by mixing in generalist knowledge. In contrast,\nthe discoveries of MoE are restricted to mixing expert behavior independently at each context, and\nWeighted Ensemble solutions can only choose a single combination of experts to apply everywhere.\nThe domain also illustrates why it is important to utilize expert knowledge in the first place. The\nhigh-dimensional solution space makes it very difficult for evolution alone (i.e. not starting from\ndistilled expert prescriptors) to find high-quality solutions, akin to finding needles in a haystack.\nExperimental results confirm that RHEA discovers the entire optimal Pareto front reliably, even"}, {"title": "3 The XPRIZE Pandemic Response Challenge", "content": "The XPRIZE Pandemic Response Challenge [10, 11] presented an ideal opportunity for demonstrating\nthe RHEA framework. XPRIZE is an organization that conducts global competitions, fueled by\nlarge cash prizes, to motivate the development of underfunded technologies. Current competitions\ntarget wildfires, desalination, carbon removal, meat alternatives, and healthy aging [81]. In 2020 and\n2021, the XPRIZE Pandemic Response Challenge was designed and conducted [78], challenging\nparticipants to develop models to suggest optimal policy solutions spanning the tradeoff between\nminimizing new COVID-19 cases and minimizing the cost of implemented policy interventions.\nDefine. The formal problem definition was derived from the Oxford COVID-19 government response\ntracker dataset [27, 54, 74], which was updated daily from March 2020 through December 2022. This\ndataset reports government intervention policies (\u201cIPs\u201d) on a daily basis, following a standardized\nclassification of policies and corresponding ordinal stringency levels in Z5 (used to define IP \u201ccost\u201d)\nto enable comparison across geographical regions (\u201cgeos\u201d), which include nations and subnational\nregions such as states and provinces. The XPRIZE Challenge focused on 235 geos (App. Fig 9) and\nthose 12 IPs over which governments have immediate daily control [54]: school closings, workplace\nclosings, cancellation of public events, restrictions on gathering size, closing of public transport,"}, {"title": "4 Characterizing the Innovations", "content": "Two further sets of analyses characterize the RHEA solutions and the process of discovering them.\nFirst, IP schedules generated for each geo by different sets of policies were projected to 2D via"}, {"title": "5 Discussion", "content": "Alternative Policy Discovery Methods. Our implementation of RHEA uses established methods in\nboth the Distill and Evolve steps; the technical novelty comes from their unique combination in RHEA\nto unlock diverse human expertise. Popular prior methods for combining diverse models include\nensembling [18] and Mixture-of-Experts [42], but, as highlighted in Fig. 2, although multi-objective\nvariants have been explored in prior work [36], neither of these methods can innovate beyond the\nscaffolding provided by the initial experts. Evolution is naturally suited for this task: Crossover is a\npowerful way to recombine expert models, mutation allows innovating beyond them, and population-\nbased search naturally supports multiobjective optimization. Other approaches for policy optimization\ninclude contextual bandits [73], planning-based methods [66], and reinforcement learning [29, 69],\nand an interesting question is how they might play a role in such a system. One approach could be to\nuse evolutionary search for recombination and use another method for local improvement, akin to\nhybrid approaches used in other settings [6] (See App. A for a longer discussion).\nTheory. It is intuitive why expert knowledge improves RHEA's search capability. However, any\ntheoretical convergence analysis will depend on the particular implementation of RHEA. The present\nimplementation uses NSGA-II, the convergence of which has recently been shown to depend critically\non the size of jumps in the optimization landscape, i.e. roughly the maximum size of non-convex\nregions [20, 21]. On the ONEJUMPZEROJUMP benchmark, the tightest known upper-bound for\nconvergence to the full ground truth Pareto front is $O(N^2nk/\u0398(k)^k)$, where k is a measure of the\njump size, n is the problem dimensionality, and N is the (sufficiently large) population size. In other\nwords, a smaller jump size leads to a drastic convergence speed up. Distilling useful, diverse experts\nis conceptually analogous to decreasing the jump size. This effect is apparent in the illustrative\ndomain, where the experts provide building blocks that can be immediately recombined to discover\nbetter solutions, but that are difficult to discover from scratch (Fig. 2). This interpretation is borne\nout in the experiments: RHEA continues to converge quickly as the action space (i.e. problem\ndimensionality) increases, whereas evolution regresses to only being able to discover the most convex\n(easily-discoverable) portions of the Pareto front (App. Fig. 6).\nGeneralizability. RHEA can be applied effectively to policy-discovery domains where (1) the\nproblem can be formalized with contexts, actions, and outcomes, (2) there exist diverse experts from\nwhich solutions can be gathered, and (3) the problem is sufficiently challenging. In contrast, RHEA\nwould not be effective, (1) if the problem is too easy, so that the input from human experts would not\nbe necessary, (2) if the problem is hard, but no useful and diverse experts exist, and (3) if there is no\nclear way to define context and/or action variables upon which the experts agree.\nThe modularity of RHEA allows different implementations of components to be designed for different\ndomains, such as those related to sustainability, engineering design, and public health. One particularly\nexciting opportunity for RHEA is climate policy, which often includes complex interactions between\nmultiple factors [46]. For example, given the context of the current state of the US energy grid and\nenergy markets, the green hydrogen production subsidies introduced by the Inflation Reduction Act\nwill in fact lead to increases in carbon emissions, unless the Treasury Department enacts three distinct\nregulations in the definition of \"green hydrogen\" [60]. It is precisely this kind of policy combination\nthat RHEA could help discover, and such a discovery process could be an essential part of a climate\npolicy application. For example, the En-Roads climate simulator supports diverse actions across\nenergy policy, technology, and investment, contexts based on social, economic, and environmental\ntrajectories, and multiple competing outcomes, including global temperature, cost of energy, and\nsea-level rise [8]. Users craft policies based on their unique priorities and expertise. RHEA could be\nused with a predictor like En-Roads to discover optimized combinations of expert climate policies\nthat trade-off across temperature change and other the outcomes that users care about most.\nEthics and Broader Impact. As part of the UN AI for Good Initiative, we are currently building\na platform for formalizing and soliciting expert solutions to SDG goals more broadly [55]. Ethical\nconsiderations when deploying such systems are outlined below. See App. D for further discussion.\nFairness. In such problems with diverse stakeholders, breaking down costs and benefits by affected\npopulations and allowing users to input explicit constraints to prescriptors can be crucial for generating\nfeasible and equitable models. In this platform, RHEA could take advantage of knowledge that\nlocal experts provide and learn to generalize it; by treating each contributed model as a black box,"}]}