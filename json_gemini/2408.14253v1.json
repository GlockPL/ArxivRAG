{"title": "Text3DAug \u2013 Prompted Instance Augmentation for LiDAR Perception", "authors": ["Laurenz Reichardt", "Luca Uhr", "Oliver Wasenm\u00fcller"], "abstract": "LiDAR data of urban scenarios poses unique chal-lenges, such as heterogeneous characteristics and inherent classimbalance. Therefore, large-scale datasets are necessary to ap-ply deep learning methods. Instance augmentation has emergedas an efficient method to increase dataset diversity. However,current methods require the time-consuming curation of 3Dmodels or costly manual data annotation. To overcome theselimitations, we propose Text3DAug, a novel approach leveraginggenerative models for instance augmentation. Text3DAug doesnot depend on labeled data and is the first of its kind togenerate instances and annotations from text. This allows fora fully automated pipeline, eliminating the need for manualeffort in practical applications. Additionally, Text3DAug issensor agnostic and can be applied regardless of the LiDARsensor used. Comprehensive experimental analysis on LiDARsegmentation, detection and novel class discovery demonstratesthat Text3DAug is effective in supplementing existing methodsor as a standalone method, performing on par or better thanestablished methods, however while overcoming their specificdrawbacks. The code is publicly available.", "sections": [{"title": "I. INTRODUCTION", "content": "LiDAR sensors enable the 3D perception of environmentsand are crucial for applications such as autonomous naviga-tion, robotics, mapping and various industrial applications.While deep learning applications have become the de factostandard for many tasks such as LiDAR detection andsegmentation, the data still poses unique challenges.\nFirstly, LiDAR data is heterogeneous, with characteristicsmainly dependend on the sensor. Point cloud structure anddistribution varies with the number of scanlines, field ofview, rotation frequency, mounting height, etc. This leadsto a significant decline in performance, when deep learningmethods trained on data from one sensor are applied todata from another sensor. The magnitude of this so calledsensor domain gap is unique to 3D point clouds with ongoingresearch on how to pre-train networks on different datasetsor enable multi-dataset training [1], [2].\nSecondly, data-imbalance is inherent to LiDAR pointclouds, due to multiple factors. In the case of urban scenarios,large objects such as buildings are represented by morepoints compared to smaller objects or individuals. Due tothe radiating alignment of the vertical LiDAR scanlines,point cloud density decreases with increased object distance,meaning that small objects are represented by few or nopoints beyond a certain distance. This results in adverseeffects on network performance for long range perception[3]. This is exasperated by the fact that some objects,\nespecially road participants such as motorcycles, are rare.Such factors result in data-imbalance in large scale datasets.For example, the SemanticKITTI dataset contains buildingpoints exceeding those representing people by a factor 709and for motorcyclist by a factor of 16,205.\nThese challenges impose the need for large scale anddiverse datasets in order to apply deep learning methodsto LiDAR data, in order to obtain sufficient points forall classes. Data augmentation is a standard technique toartificially increase data diversity and in the context ofLiDAR scans, instance augmentation has emerged as aneffective approach to tackle data-imbalance. Specifically,training data is enriched by \"cut and pasting\u201d object instances(e.g. road participants for SemanticKITTI) from differentscans. However, the practical application of this concept hasextensive requirements. Creating instance cut-outs necessi-tate semantic and instance labels, however labeling pointclouds is significantly more time-consuming when comparedto image data due to additional dimensions involved [4].\nThe labeled data use for cut-out instances also has toexhibit sufficient objects of the desired class, which canbe challenging due to data-imbalance, possibly requiringfurther data collection. Moreover, these instances retain thepoint structure and remission values specific to their originalposition, LiDAR sensor and possible occlusion. Additionalfactors such as the sensor domain gap, different semanticclasses, or missing instance labels, mean that objects fromother datasets can rarely be employed.\nIn this work, we tackle the above mentioned limitations,presenting Text3DAug as the first fully-automated and label-"}, {"title": "II. RELATED WORK", "content": "The natural imbalance in LiDAR point clouds requiresextensive and varied datasets for deep learning. Simulateddata has emerged as a viable alternative to real-world dataacquisition. Additionally, data augmentation, including theparticularly effective instance augmentation, has become astandard method for enhancing data diversity.\nA. Data Simulation\nData simulation has emerged as a natural alternative to thetime-consuming and expensive process of data acquisitionand labeling. Urban simulators such as SYNTHIA [5", "6": "are based on game engines, while others extendexisting video games [7", "8": ".", "VirtualKITTI[9": "and LiDARsim [10", "11": [12], "13": ".", "12": ".", "sim2real\" methods attemptto map real LiDAR characteristics to synthetic data [11": [10], "14": "or mix real data into the training process [13", "15": ".", "16": "inserts synthetic CAD models intoreal LiDAR pointclouds, followed by ray casting. However,LiDAR-Aug requiring the costly curation or manual creationto obtain such models. Moreover, CAD models themselvesmight vary in quality (poly count and detail) and in factorssuch as coordinate system definition. For example, the meshaxis of a CAD model does not necessary align with thereal center point, varying by object class and standard (e.g.ISO8855 [17", "18": "laid the foundation, creating a databaseof \"cut and paste\u201d ground-truth instances for integrationinto LiDAR scans. Zhou et al. [19", "20": [21], "22": "instead precomputes placement and oc-clusion maps to identify suitable scene positions, but withsignificant limitations. These maps are prohibitively time-consuming and computationally expensive. Because of this,the dataset is modified once prior to training, meaning thataugmentation remains identical between epochs. Besides"}]}