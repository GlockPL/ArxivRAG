{"title": "Map2Text: New Content Generation from Low-Dimensional Visualizations", "authors": ["Xingjian Zhang", "Ziyang Xiong", "Shixuan Liu", "Yutong Xie", "Tolga Ergen", "Dongsub Shim", "Hua Xus", "Honglak Lee\u2020\u2020", "Qiaozhu Mei"], "abstract": "Low-dimensional visualizations, or \"projection maps\" of datasets\nare widely used across scientific research and creative industries\nas effective tools for interpreting large-scale and complex informa-\ntion. These visualizations not only support understanding existing\nknowledge spaces but are often used implicitly to guide explo-\nration into unknown areas. While powerful methods like TSNE or\nUMAP can create such visual maps, there is currently no systematic\nway to leverage them for generating new content. To bridge this\ngap, we introduce MAP2TEXT, a novel task that translates spatial\ncoordinates within low-dimensional visualizations into new, co-\nherent, and accurately aligned textual content. This allows users\nto explore and navigate undiscovered information embedded in\nthese spatial layouts interactively and intuitively. To evaluate the\nperformance of MAP2TEXT methods, we propose Atometric, an\nevaluation metric that provides a granular assessment of logical\ncoherence and alignment of the atomic statements in the generated\ntexts. Experiments conducted across various datasets demonstrate\nthe versatility of MAP2TEXT in generating scientific research hy-\npotheses, crafting synthetic personas, and devising strategies for\ntesting large language models. Our findings highlight the potential\nof MAP2TEXT to unlock new pathways for interacting with and\nnavigating large-scale textual datasets, offering a novel framework\nfor spatially guided content generation and discovery.", "sections": [{"title": "1 Introduction", "content": "Low-dimensional visualizations, or \"projection\" maps, are power-\nful tools that help users understand large textual corpora, much\nlike maps aid in navigating physical landscapes. Typically, these\nvisualizations are created by first generating high-dimensional em-\nbeddings using text embedding models (e.g., [27]), followed by\ndimension reduction algorithms such as TSNE [40], LargeVis [38],\nor UMAP [24]. This process results in a 2D (or 3D) map that pre-\nserves semantic relationships between texts, enabling users to in-\ntuitively explore complex datasets and identify interesting pat-\nterns [22, 29, 39, 41, 45]. This utility raises an intriguing question:\nmuch like how people use geographical maps to explore new ter-\nritories, can we use these visualizations not only to navigate\nexisting knowledge but also to generate new content?\nThis is the central idea behind our proposed task, MAP2TEXT.\nMore specifically, MAP2TEXT aims to generate textual content cor-\nresponding to a given position within a low-dimensional visual-\nization map. The fundamental assumption that MAP2TEXT relies\non is that semantically similar texts are positioned close together\non a low-dimensional visualization, creating a \"map\" that conveys\nrich contextual information beyond the individual texts themselves.\nBy leveraging this spatial context, MAP2TEXT aims to guide the\ngeneration of new, coherent, and meaningful content."}, {"title": "2 MAP2TEXT: A New Task", "content": "In this section, we introduce the formulation of MAP2TEXT and its\nevaluation framework."}, {"title": "2.1 Problem Definition", "content": "Let V represent a low-dimensional projection of a text corpus\nD = {S1, S2, ..., SN}, where si \u2208 S is the i-th text entry and S\ndenotes the set of all possible text strings. For each text entry si,\nV includes a corresponding low-dimensional (e.g., 2D) position\nxi \u2208 R2, forming a set of positions X = {x1, x2, ..., x}. The visu-\nalization V is typically derived from D using a mapping function\nf: S\u2192 R2 that jointly maps each text entry si to its position x\u012f.\nThis mapping function f typically integrates a high-dimensional\ntext embedding model and a dimensionality reduction algorithm.\nHowever, in many practical situations, the visualizations are pre-\ncomputed and the details of the mapping function f are unavailable\nto the users. Even when f is known, reconstructing the visualiza-\ntion pipeline from scratch can be computationally expensive and\nsubject to randomness. Thus, we assume no access to f but rely on\nthe assumption of locality preservation-points close to each other\nin the low-dimensional space X correspond to semantically similar\ntext in the high-dimensional space S. This allows us to use prox-\nimity in the 2D projection as a guide for generating contextually\nrelevant text without requiring the original mapping function f.\nDefinition. The MAP2TEXT task is defined as follows: given a\nquery position xq \u2208 R\u00b2 that has not been occupied by an exist-\ning text entry, a model g is tasked with generating a text entry \u015d\nthat corresponds to xq. Specifically, the generated text \u015d should\nbe semantically and logically aligned with the ground truth text\ns \u2208 S. Here, a ground truth s is a text entry that would have been\nmapped to xq by the original mapping function f. Thus, the objec-\ntive of the MAP2TEXT task is to effectively learn an inverse mapping\ng = f\u22121 : R2 \u2192 S that reconstructs the relationship between the\nprovided visualization and text entries."}, {"title": "2.2 Potential Solutions", "content": "Given the typical pipeline of f, there are multiple natural designs,\neach offering a distinct process on how to reconstruct text entries\nfrom low dimensional space.\nThe most straightforward approach is to directly learn an inverse\nmapping from the 2D positions to the corresponding text entries,\nrequiring the model to memorize the entire visualization map, as-\nsociate each position with its corresponding text, and generalize\nthe learned relationship to unoccupied positions. This could be\nachieved by fine-tuning a pre-trained language model that takes\nthe input of a 2D coordinate and outputs a text string. This process\ncan be described as g: R2 \u2192 S.\nIf high-dimensional embeddings of the text corpus are avail-\nable, we could introduce an intermediate step by mapping the 2D\npositions to a high-dimensional textual embedding space before re-\nconstructing the text. This can be achieved using a neural network."}, {"title": "2.3 Evaluation Framework", "content": "Like other tasks of new content generation, evaluating the MAP2TEXT\ntask presents unique challenges due to the lack of ground-truth\ncontent at arbitrary, previously unexplored positions. While do-\nmain experts could compare the quality and accuracy of generated\ncontents given specific query positions, this online process is not\nscalable and thus unsuitable for automatic benchmarking.\nTo overcome this, we adopt an offline benchmarking approach by\npartitioning a precomputed visualization V into a training set and\na testing set. In this approach, the training set includes both original\ntext entries and their corresponding positions in the 2D map. This\nallows the model to understand the relationship between the text\nand positions. In contrast, for the testing set, only the positions\nare made available to the model, serving as query points for which\nthe model generates the associated text. The generated text is then\ncompared against the ground-truth text held out from the original\nvisualization, which serves as a gold standard reference.\nThis framework addresses the scalability issue of human judg-\nment but faces another challenge in aligning the generated content\nwith the reference text. For instance, the generated text might use\ndifferent wording or phrasing while still conveying the same under-\nlying idea as in the reference. Traditional lexical-level metrics may\nfail to capture such equivalence, penalizing otherwise valid outputs.\nThis motivates the proposal of ATOMETRIC, an evaluation metric\ndesigned to assess semantic and logical alignment between the\ngenerated and reference texts across varying levels of strictness."}, {"title": "3 ATOMETRIC: A New Evaluation Metric", "content": "A key challenge of evaluating MAP2TEXT is to identify an appro-\npriate metric that accurately assesses the alignment between the\ngenerated content \u015d and the gold standard reference s in our specific\ncontext. We outline the essential requirements for such a metric\nand introduce a novel metric tailored to meet these criteria."}, {"title": "3.1 Motivation", "content": "Unlike traditional content generation tasks, which aims to replicate\nground-truth texts, MAP2TEXT requires evaluating whether the\ngenerated content is capable of inspiring the user to explore the\nmap in a similar way-despite how much the surface expressions\nmatch or differ, the generated content must accurately reflect the\nsemantic relationships and logical structures of reference content.\nExisting evaluation metrics struggle to capture the semantic and\nlogical complexity required for the MAP2TEXT task. Traditional met-\nrics such as ROUGE [19] and BLEU [31] rely on lexical-level n-gram\noverlaps, penalizing legitimate variations in phrasing and struc-\nture even when the generated content accurately conveys the same\nmeaning. Recent metrics like BERTScore [46] and BLEURT [37]"}, {"title": "3.2 Features", "content": "To address the limitations of existing metrics, we propose Atomet-\nric, a novel metric specifically designed to evaluate the semantic\nand logical coherence of generated content in the MAP2TEXT task.\nAn illustrative example of ATOMETRIC is shown in Figure 2. \u0410\u0442\u043e\u043c-\nETRIC has the following features:\nAtomic Statement Alignment. Inspired by FActScore [25], \u0410\u0442\u043e\u043c-\nETRIC focuses on the alignment of atomic statements-the funda-\nmental units of meaning that express relationships between entities\nand actions within a text. By directly evaluating these atomic state-\nments instead of the complex full texts or fragmented ngrams,\nATOMETRIC assesses whether the generated content preserves the\nlogical relationships and semantic properties present in the refer-\nence."}, {"title": "Multiple Levels of Strictness", "content": "ATOMETRIC introduces multiple\nstrictness levels to capture nuanced levels of alignment. Inspired by\ndefinitions in textual entailment [3, 35, 44], these strictness levels\noffer varying degrees of relevance, from direct support to more\nrelaxed criteria such as topic relevance. This flexibility ensures that\nthe metric can accommodate the inherent variability of natural\nlanguage while remaining faithful to the core semantic content."}, {"title": "Comprehensive Evaluation Metrics", "content": "ATOMETRIC provides preci-\nsion, recall, and F1-score measurements that jointly evaluate the\ncorrectness and completeness of the generated content. Precision\nmeasures the logical consistency and accuracy of generated state-\nments, while recall captures the extent to which the generated\ncontent covers all key statements of the reference. This approach\nensures a thorough assessment of both semantic accuracy and con-\ntent coverage."}, {"title": "3.3 Definition", "content": "The formal definition of \u0410\u0442\u043eMETRIC is as follows. Given a pair of\ngenerated and reference text (\u015d, s), We first extracts a set of atomic\nstatements from \u015d and s using an LLM, denoted as As and As,\nrespectively. The two sets of atomic statements are further verified\nby another LLM at multiple levels of strictness I to evaluate both\nprecision and recall. Mathematically, ATOMETRIC precision, recall,"}, {"title": "4 Experiments", "content": "With the new evaluation metric, we are able to benchmark a set of\nsimple yet effective candidate methods for MAP2TEXT, instantiating\nthe outlined solutions in Section 2.2, and compare them with a\nhuman baseline and a strong dummy baseline."}, {"title": "4.1 Candidate Methods", "content": "Fine-Tuning (FT). The most straightforward approach is to di-\nrectly learn the inverse mapping g : R2 \u2192 S by fine-tuning a\npre-trained model. We fine-tune the 70B Llama 3.1 model using\nLORA [8], where the model takes a 2D coordinate as input and\noutputs the corresponding text. For instance, an input query would\nbe, \"Convert the coordinate to text: [9.1054, 10.1339].\""}, {"title": "5 Related Work", "content": "To the best of our knowledge, this is the first study on new content\ngeneration from low-dimensional projection maps. This new task\nis related to a few lines of research.\nLow-Dimensional Visualization of Text Corpora. Low-dimensional\ndata visualization is a versatile tool used across numerous fields\nto provide intuitive representations of large datasets [36]. In pub-\nlic health, it assists in tracking disease trends and guiding data-\ndriven decision-making [15]. In renewable energy, visualization\nhelps optimize energy production and consumption [16], while en-\nvironmental science relies on geographic visualization to interpret\necological data [2, 23]. Fraud detection benefits from interactive\nvisualizations that help identify suspicious patterns [7], and library\nmanagement uses visualization techniques to manage resources and\nsupport strategic decisions [28]. A variety of methods are employed\nto achieve these visualizations. Textual embedding models [27],\nsuch as OpenAI's Ada 2 [30] and the widely-used BERT [6], trans-\nform text into dense vector representations that capture underlying\nsemantic relationships. Dimensionality reduction algorithms like\nt-SNE [40], LargeVis [38], and UMAP [24] are commonly utilized\nto project the high-dimensional embeddings onto 2D or 3D maps,\nmaking complex patterns in the data space more accessible for anal-\nysis. While these visualizations primarily focus on interpreting the\nspace of known knowledge, MAP2TEXT extends the capabilities of\nthe map by enabling the generation of new, relevant, and accurately"}, {"title": "6 Conclusion", "content": "In this work, we introduce MAP2TEXT, a novel task for generat-\ning new textual content guided by specific positions within a 2D\nvisualization map of a large text corpus. We propose a new evalu-\nation metric, ATOMETRIC, to assess the fine-grained alignment of\nthe generated text to gold standard references at varying levels of\nstrictness. Through this metric, we demonstrate the effectiveness\nof multiple representative candidate methods for MAP2TEXT on\ndatasets in diverse domains. Our findings show the potential of\nMAP2TEXT as a valuable tool for applications such as scientific idea\ngeneration, new persona generation, and LLM red teaming. This\ninitial attempt calls for future research may explore more advanced\nmethods and diverse applications of MAP2TEXT."}, {"title": "6.1 Limitations and Future Work", "content": "We list several limitations and potential directions that could be\naddressed in future research:\nNovelty of Generated Content: Our current evaluation does not\ngo beyond measuring similarity between the generated content and\na given gold standard reference. For example, it does not consider\nthe novelty of the output or the reference, which is crucial for ap-\nplications such as research idea generation. One potential solution\nis to compute the similarity between the generated content and its\nnearest neighbors (where lower similarity indicates higher novelty)\nrather than the reference alone. In reality, the quality of the \"gold\"\nstandard itself is often not guaranteed, as human-generated content\ncan be highly relevant while still lack scientific validity or logical\ncoherence. Future work may employ domain-specific criteria into\nthe evaluation metrics or rely on specific downstream tasks.\nEvaluation Limited to Known Positions: Our evaluation frame-\nwork is limited to positions on the map for which ground truth\ncontent exists but is held out. We do not evaluate the model's abil-\nity to generate content at arbitrary unexplored positions on the\nmap, which would unleash the full potential of MAP2TEXT for open\nexploration and innovation into the information space. Without\nthe gold stand reference, the quality of the generated new content\nhas to be evaluated otherwise, through online human judgments\nor the utility of the generated content in downstream tasks, such\nas the effectiveness of a new red-teaming strategy in testing LLMs.\nOptimizing MAP2TEXT Methods: There is considerable room of\nimprovement beyond the candidate methods tested in this paper.\nAn advanced MAP2TEXT model may leverage global patterns or\ncommunity structures in the map to guide the generation, beyond\nthe local neighborhood. Another approach is to fine-tune LLMs to\nutilize spatial tokens that encode positional information directly\nwithin their embedding layers. This would allow an LLM to mem-\norize the complex map structure and incorporate spatial context\nmore effectively, while not harming their reasoning ability."}]}