{"title": "Reactive Multi-Robot Navigation in Outdoor Environments Through Uncertainty-Aware Active Learning of Human Preference Landscape", "authors": ["Chao Huang", "Wenshuo Zang", "Carlo Pinciroli", "Zhi Jane Li", "Taposh Banerjee", "Lili Su", "Rui Liu"], "abstract": "Compared with single robots, Multi-Robot Systems (MRS) can perform missions more efficiently due to the presence of multiple members with diverse capabilities. However, deploying an MRS in wide real-world environments is still challenging due to uncertain and various obstacles (e.g., building clusters and trees). With a limited understanding of environmental uncertainty on performance, an MRS cannot flexibly adjust its behaviors (e.g., teaming, load sharing, trajectory planning) to ensure both environment adaptation and task accomplishments. In this work, a novel joint preference landscape learning and behavior adjusting framework (PLBA) is designed. PLBA efficiently integrates real-time human guidance to MRS coordination and utilizes Sparse Variational Gaussian Processes with Varying Output Noise to quickly assess human preferences by leveraging spatial correlations between environment characteristics. An optimization-based behavior-adjusting method then safely adapts MRS behaviors to environments. To validate PLBA's effectiveness in MRS behavior adaption, a flood disaster search and rescue task was designed. 20 human users provided 1764 feedback based on human preferences obtained from MRS behaviors related to {\"task quality\", \"task progress\", \"robot safety\"}. The prediction accuracy and adaptation speed results show the effectiveness of PLBA in preference learning and MRS behavior adaption.", "sections": [{"title": "I. INTRODUCTION", "content": "MRS has been widely used in complex real-world appli-cations, such as disaster search-and-rescue [1] and planetary exploration [2]. However, deploying MRS in wide and un-structured environments remains challenging [3]. A signifi-cant contributor is the difficulty in smoothly and seamlessly integrating human guidance into the robot's decision-making. But wide unstructured environments have various physical and logistical constraints [4], such as uncertain surroundings, limited communication, and unexpected obstacles. It's chal-lenging for humans to gain precise understandings of priority and safety factors in missions and adjust the behavior of the MRS in real-time [5]. Currently, to enable more seamless integration and fur-ther improve robot survivability in real-world environ-ments, many studies leverage machine learning methods to accurately predict human preferences for safe MRS deployments[6]. Although the learned human preference model can provide robots with a fast and comprehensive un-derstanding of human expectations, its learning and deploy-"}, {"title": "II. RELATED WORK", "content": "Robots Adaptation to Unstructured Environments. In [9], [10], [11], a global environment classification model was learned to enable a robot to understand its surroundings and react in real-time. In [9], to develop a model for real-time perception and understanding of various environments, a lightweight neural network architecture was developed for real-time segmentation of navigable spaces. To efficiently learn an environment characterization model, [11] used the Probabilistic Gaussian method with sparse approximation to update parameters quickly. Although a global model can con-sider various features that may impact robots' movements, one of the main challenges in deploying global models is that global models are large and require a lot of computational and memory resources. As a result, global models can be slow to generate predictions, limiting their practical appli-cations in real-time scenarios. Instead of learning a global model, [12], [13] developed several approaches to train an accurate local model for robot autonomous navigation. Even with local performance, these models need to be updated and retrained for each new environment. The model does not retrain well in new environments, which may lead to unsafe robot behavior. In environments where the trained model has low accuracy, our PLBA method will seek guidance directly from the human operator, exploit the spatial correlations among similar environments for fast model updates, optimize robot behaviors, and improve planning safety even if the preference predictions are inaccurate. Human Preference Model for Effective Humans-Robots Collaboration. Recent research was done to learn human preferences to better integrate humans into robot teaming. In [14], [15], active learning, addressing data inefficiencies by choosing the most informative queries, was used for robot learning as much as possible from a few questions. In [16], [17], the volume removal method, which aims to maximize the information gained from each query, was used to evaluate the performance of query methods. However, the above stud-ies represented human preferences via a linear weighted sum of robot behaviors (e.g., moving speed, trajectory smooth-ness, and distance to obstacles), which can lead to the loss of valuable and informative information due to ignoring the dynamic and nonlinear influence entanglements among these behaviors [18]. Furthermore, human preference is subjective and dynamically related to task progress and environmental conditions, making linear assumptions unsuitable for human"}, {"title": "III. METHODS", "content": "A. Problem statement\nHuman preference H is parameterized by a set of ac-tions A with |A| = d. Each_action $a\\in A$ represents one factor characterizing the multi-robot flocking process. In this work, multi-output Gaussian Processes (GPs) are used to model the underlying human preference function $f() := [f^{(1)}(.), f^{(2)}(.), ..., f^{(d)}(.)]$, which doesn't have strong as-sumptions about the form of $f(\\cdot)$. Human preference feed-backs in trial i are collected into a data set $Data_i = \\{f_{t}\\}^{\\pounds} + {\\t = 1,2,...,N_i\\}$, where $N_i$ denotes the total number of collected human feedbacks, $\\varepsilon \\in R^d$ represents noises in human feedback. Defining $f(\\cdot)$ as the maximum posterior (MAP) estimation of $f(.)$ given $Data_i$, we aim at using a Bayesian approach to iteratively update the parameters of $f(.)$ to minimize the prediction error $(|f(\\cdot) - f(\\cdot)|)$.\nB. Multi-output GPs with varying output noise\nAfter the problem statement, we are now ready to use multi-output Gaussian Processes [24] to learn human pref-erence function $f(\\cdot) : X \\rightarrow R^d$. The pth output of $f(\\cdot)$ is denoted as $f^{(p)}(\\cdot)$. And the distribution of the stacked outputs $(F(X) = \\{f(x_n)\\}_{n=1}^N)$ for all N inputs $x_n$ is Gaussian distributed, where $X = \\{x_n\\}_{n=1}^N$ and the input $x_n \\in X \\in R^D$ is D-dimension combined features. Like single-output GPs, multi-output GPs are fully specified by their mean and kernel functions. The matrix-valued kernel obeys the same positive definiteness properties where the input space X is extended by the index of the output:\n$k : (X, \\mathbb{N}) \\times (X, \\mathbb{N}) \\rightarrow \\mathbb{R}$ (1)\nThen the distribution of $F(X)$ can be denoted as:\n$p(F(X)) = \\mathcal{N} (0,K), K \\in \\mathbb{R}^{(Nd\\times Nd)}$ (2)\n$F(X)_{np} = f^{(p)}(x_n), K_{n p n' p'} = k(\\{x_n, p\\}, \\{x_{n'},p'\\})$ (3)\nThen, a linear transformation $W\\in R^{d\\times L}$ of L independent functions $g_l(\\cdot)$ is used to construct multi-output function $f(\\cdot)$:\n$g_l(\\cdot) \\sim GP(0,k_l(\\cdot,\\cdot'))$,\n$g(x) = \\{g_l(x)\\}_{l=1}^L, f(x) = \\mathbf{W}g(x)$ (4)\n$k(\\{x_n, p\\}, \\{x_{n'}, p'\\}) = \\sum_{l=1}^L W_{pl}k_l(x_n, x_{n'}) W_{p'l}$ (5)\nwhere $k_l(,)$ is a squared exponential kernel.\nGiven that the human feedback for each output has a dif-ferent noise level, a Gaussian process model where different noises are assumed for the data points is used:\n$y_n = f(x_n) + \\varepsilon_n, n = 1,2,...,N$\n$\\varepsilon_n|x_n \\sim Gaussian(0, \\Sigma_{noise,n})$ (6)\n(7)\nIn this paper, the covariance of noise $(\\Sigma_{noise,n} \\in R^{d\\times d})$ is represented as a diagonal matrix:\n$\\Sigma_{noise,n}^{i,j} = \\begin{cases} \\epsilon_{d}^{i,j}\\alpha_{ij,n}+\\beta_{ij,n}a_n & \\text{if } (i == j) \\\\ 0 & \\text{otherwise} \\end{cases}$ (8)\nwhere $\\alpha_{ij}$ and $\\beta_{ij}$ are hyper-parameters related to human feedback noise. Then the distribution of F(X) combined with noise is shown as follows:\n$p(F(X)) = \\mathcal{N} (0,K+\\mathbf{K}_{noise})$ (9)\nwhere $\\mathbf{K}_{noise} = diag(\\Sigma_{noise,n})_{n=1}^N \\in \\mathbb{R}^{Nd\\times Nd}$ is a diagonal matrix. With d-dimension outputs and N samples, a dN \u00d7 dN covariance matrix with $(d^3N^3)$ computational complex-ity is needed for obtaining an accurate multi-output GP. Hence, a posterior approximation method (stochastic vari-ational inference) is used. By introducing a set of inducing variables $(\\mathbf{u} = \\{f(x_m)\\}_{m=1}^M)$, the computational complexity can be reduced to $(d^3M^3)$. At last, the Adam optimizer can optimize the noise variance and the variational param-eters separately. Capturing the essence of our theoretical\ngroundwork, Procedure 1 streamlines the execution of the PLBA framework (shown in Fig. 2), from mission initiation to MRS safety assurance during ongoing operations. The algorithmic procedure outlined offers a succinct roadmap for dynamic decision-making, integrating path planning and real-time adaptive behavior modeling, which is pivotal for the MRS's performance in diverse environments. As for the optimization details, please refer to [24], [25].\nC. Preference-based safe MRS behavior adjustment\nIn this work, we extended the flocking method proposed in [26] by involving obstacle-free largest convex region searching and optimization-based MRS behavior planning for stable and safe robot behaviors. The desired MRS be-havior adjusting velocity is calculated by:\n$\\mathbf{v}_i = \\mathbf{v}_i^{v_{flock}} + \\mathbf{v}_i^{v_{fmt}} + \\mathbf{v}_i^{v_{rep}} + \\mathbf{v}_i^{v_{att}} + \\mathbf{v}_i^{v_{saf}} + \\mathbf{v}_i^{v_{hei}} + \\mathbf{v}_i^{v_{ali}}$ (10)\nwhere i is the index of a drone and $\\mathbf{v}_i^{v_{flock}}$ denotes the flocking speed. $\\mathbf{v}_i^{v_{fmt}}$ represents MRS team formation maintaining term. $\\mathbf{v}_i^{v_{rep}}$ is short-range repulsion term and similarly $\\mathbf{v}_i^{v_{att}}$ denotes long-range attraction term. $\\mathbf{v}_i^{v_{saf}}$ keeps a safe distance between robots and obstacles. $\\mathbf{v}_i^{v_{hei}}$ maintains the robot at a preferred flying height. $\\mathbf{v}_i^{v_{ali}}$ is velocity alignment term. Then to prevent $\\mathbf{v}_i$ from largely exceeding the human preferred flying speed, an upper limit $h_{speed}$ is introduced:\n$\\mathbf{v}_i = \\begin{cases} \\mathbf{v}_i & \\text{if } (\\mathbf{v}_i \\leq h_{speed}) \\\\ \\mathbf{v}_i\\frac{h_{speed}}{|\\mathbf{v}_i|} & \\text{otherwise} \\end{cases}$ (11)\nSpecifically, each type of speed can be parameterized by one or a few human preferences in the set $H = \\{h_{inner},h_{height},h_{speed},h_{safety},h_{formation}\\}$. $h_{inner}$ denotes the minimal distance between robots; $h_{height}$ denotes the flying height of robot system; $h_{speed}$ represents the flying speed of multi-robot system; $h_{safety}$ represents the minimal distance between robots and obstacles; and $h_{formation}$ denotes coordi-nation pattern. Next, we determine the largest convex region of obstacle-free space using an iterative regional inflation method based on semi-definite programming [27]. Drones are then assigned to the vertices of this convex region to establish the formation. The flocking model helps the drones maintain their relative positions within the formation throughout the operation.\nTo maintain informative and helpful interactions with humans and learn a more representative preference model $f(.)$ via human feedback (developed in Section A), Algo-rithm 1 was developed to decide the timing and manner of seeking human guidance. In Algorithm 1, an interactive learning framework was designed by utilizing active learning to inquire informative guidance from humans. The mean and covariance of human preference predictions are calculated during the learning process. A high covariance value means that the human preference model does not generalize well to the current environment; thus, more human guidance is needed to refine the preference model. With the guidance of low-variance human preference, which means good pref-erence estimation, MRS can adjust robot behavior safely without aggressive or unexpected adjustments."}, {"title": "IV. EVALUATION", "content": "A multi-robot search and rescue task in a flood disaster site was designed to evaluate PLBA's effectiveness in supporting unstructured environment adaptation. The following two as-pects were mainly validated: (i) the effectiveness of PLBA in fast human preference learning, which is for MRS fast adapt to the unstructured environment; (ii) the effectiveness of environment similarity for fast human preference learning.\nA. Experiment setting\nIn Fig. 3, an \"MRS search and rescue in flood disaster\" environment was designed based on the software AirSim [29] and Unreal Engine [30]. The environment (400 m \u00d7 400 m) was designed to include various scenes (city, bridge, forest, park, etc.), which is enough to test PLBA's effectiveness in supporting unstructured environment adaptation. Five kinds of flocking behaviors that can illustrate human preferences were considered: 1). The \"flying height\u201d denotes the average flying altitude of the MRS; 2). \"Coverage area\u201d is represented by the minimum distance between drones; 3). The \"safe distance to the obstacle\" is the minimum distance between the drone and obstacles; 4). \"Flying speed\" represents the average speed of MRS; 5). \"Team formation\" is represented by the assigned Cartesian positions of all robots.\nIn this work, outdoor environments mainly consist of four typical scenarios \"City\", \"Park\", \"Forest\", \"County\", and \"River\". According to obstacle density, these scenarios can be roughly classified into three categories \"Cluttered\", \"Structured\", and \"Open Space\". \"Open Space\" represents a scenario where there are no or few physical obstacles (e.g., lake and park). In \"Open Space\" environments, humans can operate MRS more aggressively to achieve fast mission progress. \"Cluttered\" represents areas that are characterized by an excessive accumulation of objects or debris, which can make it challenging to move around or perform activities (e.g., forest). Therefore, humans should operate MRS more reserved to pay more attention to robot safety. \"Structured\" refers to spaces that are designed and organized with well-defined boundaries and guidelines, which are helpful to promote safety and consistency outcomes (e.g., city). Fig. 4 shows expected robot behavior corresponding to three specific environment types.\nTo analyze the effectiveness of PLBA in adaptation to out-door environments, a test procedure for MRS to continuously adapt to multiple environments was designed; two baseline methods (linear regression and neural network regression) were used as comparison groups. The adaptation speed and prediction errors of human preferences in unfamiliar environments were comparatively analyzed. In addition, the relationship between environmental similarity and human preference prediction error was also analyzed, illustrating that the spatial correlation between environmental features can be used for environmental adaptation.\nB. Result analysis\nHuman User Study. With the pioneer user study involving 20 human volunteers, the mean and variance human prefer-ence values in various environments were calculated. Then, two kinds of human preferences \u2013 simple human preference only with mean values and complex human preference with mean and variance values were conducted to validate the effectiveness of PLBA in rapid adaptation to unstructured environments. The details of human preferences are listed in Fig. 5. The sample behavior illustrations for human preferences in different environments are shown in Fig. 4."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "This paper developed a novel joint preference landscape learning and MRS behavior-adjusting framework (PLBA) to establish a mapping between human preference landscape and unstructured environment's characteristics and adjust MRS motions to follow human preferences over mission progress, quality, and system safety. To validate method effectiveness, a five-UAV-based multi-robot team was de-ployed for victim search in a flood disaster site; with 20 volunteer-based user studies, two types of user preferences were identified as \"simple-preference\" without variances and \"complex-preference\" with variance. Our proposed method's effectiveness for unstructured environment adap-tation was validated by the reduced update number and the adaptation error calculated by models updated only once in a new environment. Given the capability of enabling safe and cognitive teaming, PLBA can be extended to guide the flexible teaming of multiple robots and even the cooperation between vehicles and human units.\nIn the future, the adaptation method could be enriched by on-board sensing information to improve human-MRS collaboration further."}]}