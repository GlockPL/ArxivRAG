{"title": "The Unbearable Lightness of Prompting: A Critical Reflection on the Environmental Impact of genAI use in Design Education", "authors": ["Maria Luce Lupetti", "Elena Cavallin", "Dave Murray-Rust"], "abstract": "Design educators are finding ways to support students in skillfully using Generative Artificial Intelligence (GenAI) tools in their practices while encouraging the critical scrutiny of ethical and social issues around these technologies. However, the problem of environmental sustainability remains largely unaddressed. There is a lack of both resources to grasp the environmental costs of genAI in education and a lack of shared practices around the issue. This work contributes filling this gap by counting the energy costs of using genAI in design education and critically reflecting on the impact of these costs. We leverage the image data collected during a genAI workshop for designers held in 2023 with 49 students, to calculate the energy costs of these types of activities. The results reveal that a genAI workshop for designers can easily double the energy costs associated with students' use of computers, countering the efforts of educational institutions to minimize their energy expenditure. We critically reflect on this finding to distill a set of five alternative stances, with related actions, that can support a conscious use of genAI in design education, while respecting individual positions. The work contributes to the field of design pedagogy, and education more broadly, by bringing together ways for educators to reflect on their practices and informing the future development of educational programs around genAI.", "sections": [{"title": "1. INTRODUCTION", "content": "Artificial Intelligence (AI), and more specifically Generative Artificial Intelligence (genAI), have recently seen large adoption in a great variety of sectors (Chan and Colloton, 2024). In particular, genAI is now being extensively used by design professionals and researchers across all phases of the design process (van der Maden et al., 2024), from the `fuzzy front end' (Sanders and Stappers, 2008) of ideation, content generation, and quick production of mood boards and product visualizations, up to enabling fast and cheap product evaluation with synthetic users (Li, 2024). In the face of these technological possibilities, academics have started to study emerging human-AI design practices (Flechtner and Stankowski, 2023; Subramonyam et al, 2022; Audry, 2021; Olsson and V\u00e4\u00e4n\u00e4nen, 2021; Fu and Zhou, 2020; Fiebrink, 2019; Yang et al., 2018; Dove et al., 2017), and question how to re-think their educational programs (Tien and Chen, 2024; Whitham et al., 2024; Huang et al., 2023). As a result, the last two years have seen a proliferation of workshops, elective courses, exercises and other initiatives to confront design students with the opportunities and challenges brought about by genAI.\nThis increasing engagement of design educators with genAI is often driven by the belief that genAI is a powerful innovation to be embraced, as it can make us more creative (Lim et al., 2023; Figoli et al., 2022). However, engagement with genAI can take a more reactionary stance, as a way to adjust to a seemingly inevitable technological future (van der Maden et al., 2024; Bozkurt, 2023; Fathoni, 2023), where the designers are seen as playing a strategic role in protecting the interests and values of users (Armstrong, 2021). The inherently complex and controversial nature of genAI imposes on educators a responsibility to nurture a critical sensitivity in future professionals so that they can grasp the underlying mechanisms driving these systems while consciously engaging with their ethical and social implications (Chan and Colloton, 2024), ultimately aiming to ensure that the new generations will shape technologies that are respectful of human and collective values (Tubella et al., 2023). Thus, alongside training students to skillfully handle genAI as design material, with its very capabilities and limitations (Casal-Otero et al., 2023), educators are now developing novel approaches for training designers to understand, anticipate and, if necessary, mitigate the effects of genAI technologies in society (Huang et al., 2023; Murray-"}, {"title": "2. AI IN DESIGN EDUCATION", "content": "\"Given that many of my students are already using these tools and their use will likely be prevalent in the industry in the near term, I feel I should ask: to what extent should I incorporate generative AI into my pedagogies and curricula?\" (York, 2023)\nMany design educators have integrated AI tools and techniques into their programs and curricula in recent years, perhaps sharing a position similar to York (2023), cited above. In the face of a rapidly changing technological landscape, in which every month there is a new release of genAI tools of some sort, design educators find themselves wondering what new skills and knowledge will be required of the next generation of designers (Whitham et al., 2024; Pei et al., 2023; York, 2023) and how to incorporate these tools in existing programs (Maceli et al., 2024; Flechtner and Stankowski, 2023; Goel et al., 2023) not to mention the vexing question of how to keep up with all this themselves (Flechtner and Stankowski, 2023)."}, {"title": "2.1. Critical perspectives in AI education for designers", "content": "The more genAI is integrated into educational settings, the more educators raise concerns over the consequences of this transition. Concerns range from purely didactic apprehensions about matters of originality, plagiarism, and learning outcomes (Whitham et al., 2024; Sandhaus et al., 2024; Lim et al., 2023; Fathoni, 2023; Oravec, 2023), to the question of how to support students understanding the implications of genAI at societal scales (Chan and Colloton, 2024; Vartiainen and Tedre, 2023). Programs are being developed around nurturing AI literacy where the emphasis is not purely on the technical functioning, but rather on possible societal consequences and power relations these can bring (Sandhaus et al., 2024; Aguilar, 2024; Vartiainen and Tedre, 2023; Arada et al., 2023; McDonald et al., 2021). This goes hand-in-hand with a growing collective awareness about the risks and consequences of genAI capabilities when integrated into services and products, that can lead to discrimination and other forms of injustice (Costanza, 2018). Bias and injustice are non-trivial problems, and as Kharrufa and Johnson (2024) illustrate, design students are often contradictorily found to acknowledge the problem of bias, but at the same time fall into the trap of using the perceived objectivity of genAI as a design evaluation tool in place of actual users. Thus, AI literacy programs for designers increasingly also integrate performative, critical and speculative design practices (Rahm, 2024; Costello et al., 2024; Thrall et al., 2024; Flechtner and Kilian, 2024; Murray-Rust et al., 2023) as a way to strengthen critical understanding of AI (Costello et al., 2024) and address its political, economic and ethical implications (Rahm, 2024). These approaches are driven by the belief that designers have an important role to play, in between driving innovation around disruptive technologies and advocating for people's needs (Pei et al., 2023), even when not intimately familiar with the technical functioning of AI (Murray-Rust et al., 2023). Despite their importance and growing presence, however, these critical pedagogic practices leave unattended one of the most essential concerns that have recently interested both the academic and the public discourse around AI: the problem of environmental sustainability."}, {"title": "2.2. The AI sustainability critique", "content": "\"We need pragmatic actions to limit Al's ecological impacts now\u201d (Crawford, 2024b)\nAn awareness is growing, both in the academic community and the public, that Al's impact on society is not solely socio-technical, but ecological too (Rakova and Dobbe, 2023). OpenAI's chief executive Sam Altman recently admitted that the AI industry is heading towards an energy crisis as it requires such large amounts of energy that current energy systems will struggle to cope (Crawford, 2024b; Saul et al., 2024). It has been estimated that a search driven by genAI uses four to five times the energy of a conventional web search, and that ChatGPT consumes the same energy as 33000 homes (Crawford, 2024b). Although exact data is hard to get -due to the environmental costs of genAI being treated as secret by the industry (Crawford, 2024b) \u2013 recent reports warn about the increasing demand for computational power, and thus data centers, that Al is driving (Yao, 2024; Goldman Sachs, 2024). Data centers already account for 2% of global electricity usage (Li et al., 2023; Patterson et al., 2022), and this is expected to grow dramatically with the uptake of genAI. A study by Bloomberg Technology (Saul et al., 2024) estimates that by 2034, global energy consumption by data centers will match the one currently used by the entire India. And, although these are largely estimations, the constant building and use of new data centers is a fact (Saul et al., 2024; Chen, 2024).\nThe environmental impact of running AI systems extends beyond electricity use and includes the emission of CO2 and the consumption of fresh water. Further, Li and colleagues (Li et al., 2023) investigated the consumption of clean freshwater attributable to data centers and thus also intertwined with the rising demand for computational power by AI. The authors report that the training of GPT-3 in a state-of-the-art US data center can consume about 700.000 liters of clean freshwater, which would be enough to produce 320 Tesla electric vehicles, and that a simple conversation with ChatGPT (roughly 20-50 questions and answers) can require a half liter bottle of water (Li et al., 2023). These costs can be highly variable -- Dodge and colleagues (Dodge et al., 2022), for instance, found that the training of a language model emits between 10Kt CO2 and 28Kt CO2, depending on where the training happens. Casting sustainability questions in terms of tons of CO2, and liters of fresh water is crucial, yet understanding the comparative impacts of GenAI within an educational curriculum remains hard to grasp, as these impacts also happen for other activities. Parallels can be drawn with concepts like carbon numeracy \u2013 \"the ability to correctly understand and manage one's own carbon footprint\u201d (Wynes, 2020) \u2013 that tells us about how difficult it is for people to properly underestimate the environmental impact of our practices, such as eating meat (Camilleri et al, 2019) or car driving (Grinstein et al., 2018). One way to approach this is to provide graspable metrics to communicate meaningfully about the sustainability of actions to allow consumer comparison, such as 'light bulb minutes' (Camilleri et al, 2019), traffic light labels for food (Thorndike et al., 2014) and comparisons such as \"reducing your meat intake to three times per week is equivalent to avoiding six short-haul return flights each year\" (Steinitz et al., 2024). In the same way, Luccioni and colleagues (2024a) argue that \"giving the public a simple way to make informed decisions would bridge the divide that now exists between the developers and the users of AI models, and could eventually prove to be a game changer\u201d."}, {"title": "3. A CRITICAL REFLECTION ON GEN\u0391\u0399 SUSTAINABILITY IN DESIGN EDUCATION", "content": "We share with (Luccioni et al., 2024a; Crawford, 2024b) the view that pragmatic actions are needed to limit the environmental impact of our practices around the use of genAI, and that dedicated actions should facilitate the making of informed decisions in this space. Yet, we see two key difficulties in this path.\nFirstly, there is a fundamental problem hindering the way to a proper grasping of the impact resulting from AI-related activities, and it concerns the accessibility and interpretability of data around the problem. The lack of transparency around the environmental costs of genAI (Crawford, 2024b) is often worsened by the encouragement of the misbelief that 'the training is the problem' (Luccioni et al., 2024b). Even well-meaning initiatives tend to predominantly emphasize the environmental problem of AI in its training phase, leaving the impact that is actually generated at the inference stage largely unattended. While providing correct info, the narrow focus of these critiques prevents us from thinking systemically about AI sustainability, and guides us to focus on the relatively small costs of training, rather than the large and growing- costs of inference or querying. In fact, the deployment costs of users querying a model \u201ceven assuming a single query per user, which is rarely the case, [...] would surpass its training costs after a few weeks or months of deployment\u201d (Luccioni et al., 2024b). Furthermore, it is crucial for educators to understand the impact of genAI querying as, while we can't make a change to the costs associated with training, we can and do have an impact on the costs associated with genAI inferencing and querying, as this is what gets used in education. Recently we have started to witness a growing attention towards"}, {"title": "4. COUNTING THE ENERGY COSTS OF A GENAI WORKSHOP", "content": "The selected workshop was run over two days, from November 30th to December 1st 2023, San Marino, at the University of San Marino. The workshop lasted 12 hours, with a full-day program on the first day (8 hours), and a half-day on the second (4 hours). The course was offered as an addition to the main courses offered as part of a bachelor program in Design and attended by a total of 49 students.\nThe main focus of this workshop was to introduce students to text-to-image genAI tools and get them familiar with ways in which these resources can be used for design activities. As per the explicit request of the local didactic coordinator, the workshop used Midjourney as genAI platform, which was selected for the good usability of the platform and the high aesthetic quality of the generated results. The workshop started with an introductory lecture and was followed by a series of exercises in which students had to generate images for different purposes (Figure 1), such as creating website hero images, logos, portrait photos for social media campaigns, visualizing future scenarios, and more. We used FigJam, an online whiteboard tool, to prepare templates for each activity, to keep track of students' work, and to facilitate collective sharing."}, {"title": "4.1. Image collection and counting", "content": "Here we consider 'data' the images produced with Midjourney during the workshop, that were collected and analyzed for calculating the electricity consumption of the activities. The data collection and analysis process, illustrated in Figure 2, started with a collection and categorization of the image data first into two main groups, one of the teacher and one of the students. Next, we further divided images generated by the teacher into two subgroups: preparation, all the images generated before the actual workshop that were used to compile the lecture slides, and students support, i.e., all the images generated by the teacher any time a student needed help in generating their images during the workshop.\nOn the teacher side, the images were collected by downloading these from the personal archive of the teacher on the Midjourney platform and counting them. On the students' side, the collection was more laborious. As we did not have access to the students' personal archives, we downloaded the entire chat of the Discord channels used during the workshop to interact with the Midjourney bot. The list of queries was downloaded as an excel file using a Chrome extension called Discordmate, which allows for bulk download of Discord chat content. After the bulk download, we cleaned the data to remove the queries from the teacher and the queries in which students forgot the command /imagine (and thus generated no result). After the 'cleaning', the count of pictures needed a further step as queries included both groups of 4 pictures (Midjourney initially always generates a composition of 4 alternatives) and single images selected from the groups. To identify the single images in the list of queries, we"}, {"title": "4.2. Energy costs of a two-day workshop on genAI for designers", "content": "We estimated the energy costs of the workshop by multiplying the amount of generated images by the energy consumption required by generating one image -0.0029 kWh- which we extracted from a recent estimation of energy costs of generating 1000 images (2.907 kWh) by Luccioni et al. (2024b). In total, the workshop generated 11072 images, using 32.1kWh, which is more than five times the daily energy consumption of a two-person apartment\u00b9. Beyond looking at the totals, we also calculated the conversion rate between the number of generated images and images that were used (both for teacher and students), and the average individual energy consumption (for students)."}, {"title": "4.2.1. Teacher", "content": "The teacher has generated a total number of 602 pictures over 10 days, including 554 pictures generated during the preparation of the workshop, and 48 generated during the workshop itself, to support students' work. Of the 554 images generated during the preparation of the workshop, only 41 (7%) made it to the lecture slides. Multiplying the total amount by the estimated electricity consumption of 1 generated image, we estimate that the activities of the teacher required 1.74 kWh."}, {"title": "4.2.2. Students", "content": "The 49 students generated a total of 10470 images over the two-day workshop. Of these, only 512 (4.8%) made it to the FigJam board. Hence, the total activities of the students required around 30.36 kWh with an average of 0.6 kWh per student."}, {"title": "4.3. Grasping the scale of impact", "content": "To better grasp the scale of impact that running genAI educational activities has in terms of energy costs, here we first contextualize the results within related practices (Table 1) and then conceptually position our activity within the broader landscape of design education practices that are changing in response to AI."}, {"title": "4.3.1. Contextualizing data within related practices", "content": "The hourly energy consumption per individual student participating in our workshop (0.05 kWh) might look small at first glance \u2013it is roughly in line with laptop use, and slightly lower than rendering high quality images for production. The comparison with image rendering, however, is only partially valid because of the different nature of the images' use within the practice of design. Currently, AI-generated images are mostly used in design processes to support ideation (Koch et al., 2019; Tholander and Jonsson, 2023; Chiou et al., 2023), provide inspiration (Kalving et al., 2024; Liu et al., 2024a; Ranscombe et al., 2024; Ling et al., 2024), and enable quick"}, {"title": "4.3.2. Positioning the workshop within the landscape of design & AI education.", "content": "The case we took as an example in this work is only one among the multitude of AI-related educational experiences that the authors have carried out in the last year. The first author alone has run seven educational programs similar to the one we used for the calculations, and the second and last authors share a similar experience. Thereafter, we argue that to better grasp the scale of the impact associated with this type of activity, one should also consider how this is positioned within the broader landscape of design education engaging with genAI.\nOur recent activities reflect a trend that is not peculiar to our personal educational experience, but rather part of a phenomenon that is affecting the design education field more broadly. Accordingly, we suggest considering our data as a single instance in a constellation of emerging educational practices. A quick scan of academic publications shows that there is an increasing number of educational design programs (not to mention programs in other fields) that are integrating genAI and being run across the globe: from weeks or semester-long courses (Kharrufa & Johnson, 2024; Li et al., 2024; Murray-Rust et al., 2023; Ching et al., 2023; Rajabi & Chris Kerslake, 2024; Simeone et al., 2022), to workshops and sessions lasting days or hours (Ali et al., 2024; Lee et al., 2024; Ray & Tang, 2023; Williams et al., 2024; Theophilou et al., 2023; Goel et al., 2023; Muji et al., 2023; Mariescu-Istodor & Jormanainen, 2019; Fiebrink, 2019). We are increasingly seeing genAI used in classroom settings with tens or even hundreds of students. Furthermore, these activities add up to the existing and constantly growing students' self-initiated use of genAI higher education. As found by a recent study conducted in Germany (Von Garrel & Mayer, 2023), more than 60% of students already use genAI tools, such as ChatGPT, in their studies. In short, design education activities engaging with genAI not only can double the energy expenditure we already have for individual laptop use but also come embedded within a global trend that moves in the opposite direction of societal efforts to reach sustainability goals."}, {"title": "5. ARTICULATING THE SPACE OF ENVIRONMENTALLY CONSCIOUS DESIGN EDUCATION AROUND GENAI", "content": "Our calculations around the environmental impacts of the workshop were prompted by a deep engagement with the current literature from both computer scientists and philosophers of technology, warning us about the dramatic environmental impact of AI. Perhaps influenced by classical mental models we hold about unsustainability (Cloud, 2014), in our discussions we engaged in a series of defensive positions. We scrutinized the argument that responsibility lies with major players, a view often strengthened by media headlines (see the New York Times one that states \"Tech giants are building power-hungry data centers to run their artificial intelligence tools\" (Sorkin et al., 2024)), which often point to tech giants as the only responsible actors. We also considered the positive possibility that, as with many other technologies, AI algorithms will become more efficient as the field becomes more mature. As the suggested by Schwartz et al. (2020), the field of AI should and can move from Red AI, with environmentally unfriendly and prohibitively expensive models, to Green Al where addressing efficiency is a primary evaluation criterion alongside accuracy. And finally, we extensively discussed how there are already plenty of activities that consume a lot of energy that are part of our everyday lives such as gaming (Mills & Mills, 2016; Perez et al., 2024) and video streaming services (Shehabi et al., 2014; Afzal et al., 2024; Gnanasekaran et al., 2021; Hossfeld et al., 2023) and whether the use of genAI should be regarded differently.\nAlthough valid, these defensive positions fall short in the face of the impact these activities have on the already high environmental costs of higher educational institutions. While universities, and society at large, struggle to achieve sustainability goals, and individuals experience continuous pressure to reduce their energy consumption, we are developing educational programs that quickly double the energy costs associated with students' use of computers. Thus, we believe that as a design education community, we hold a responsibility to be aware of the problem and share this awareness with students too, through educational formats that account for genAI impact. Yet, as educators we also find ourselves overwhelmed by the need to reinvent educational practices to nurture AI literacy in future designers (Chan and Colloton, 2024) while being asked to do that without causing harm to our environment (Holmes et al., 2023). Furthermore, despite our identifying as critical scholars sensitive to matters of environmental justice, in our teaching experiences, we also found ourselves acknowledging the strong potential for engagement and exploration that these technologies have on students, and the transformational power that AI possibilities have on design processes. Over the last few years, we have observed how intrinsically motivated students are when designing with genAI, which contrary to some common beliefs (Peng et al., 2024; Subramonyam et al., 2023), is all but trivial. Through these experiences, we also learned how different the challenges and potentials of using these technologies are, whether we are teaching design for speculation compared to traditional product development (just to make one example). There is an argument to be made about the value of engaging directly with the materiality and dynamics of genAI tools (Lupetti & Murray-Rust, 2024). But a question remains: is it worth it?\nA comprehensive, universal answer to this question falls outside the scope of this paper. Instead, we want to encourage the design education community to engage with it and make responsible individual choices. In support of this, we suggest five alternative stances one can adopt towards AI environmental impacts in education, along with actions consistent with each stance. These have been distilled through our process of critical reflection, which took the form of online discussion sessions. We started from the experience and the data described in the previous sections (3 and 4) to build self-awareness about our own stances and identify possible actions to practice sustainability in design education when engaging with genAI. These are not intended as turnkey solutions, but rather as a source of inspiration and starting points for guiding personal reflections of design educators finding themselves navigating similar concerns."}, {"title": "5.1. AI Sustainability Literacy", "content": "Developing literacy about the sustainability problem surrounding genAI cuts across all of the stances that we set up, and is a required foundation for meaningfully addressing the responsible use of genAI in design education. While significant attention has been given to the social and technical issues of AI uses, given the climate crisis we live in (United Nations, 2020) and the tremendous global impact that recent genAI developments have had (Bashir et al., 2024), there is an urgent need to increase understanding of the materiality and environmental costs of genAI, bringing this in line with growing socio-technical literacy. There are several technical resources that can be used to nurture this understanding, such as the work by Luccioni et al. (2024) on Al electricity costs, by Dodge et al. (2022) on carbon intensity of different AI models, or by Li et al. (2023) on Al consumption of clean freshwater. Alongside these technical resources, an increasing amount of design-friendly materials is becoming available, such as critical cartographies (Joler, 2024) that map out the systemic nature of these systems, such as Crawford and Joler's Anatomy of an AI System (Crawford & Joler, 2028), or the Cartography of GenAI by Estampa (2024), or detailed reflections on Al's effect on the planet (Brevini, 2022)."}, {"title": "5.2. Acceptance", "content": "\"It is important to be aware of and talk about the costs of genAI, but Al literacy and competence has priority\"\nAt one end of the spectrum, the position of acceptance is one in which AI sustainability concerns are tolerated accepted - for the sake of nurturing students' AI literacy. Here, equipping students with knowledge and capabilities for skillfully engaging with Al is seen as an urgent need, of greater importance than sustainability. To grasp this position, a parallel may be made with the environmental costs of training jet fighter pilots that are extensive, yet acceptable because of the critical role they play in case of need (McCarthy, 2019). This may be judged as a relentless or selfish choice, yet we encourage looking at it as a position coherent with the very scope of design education institutions. Indeed, many educators do not engage with the problem of genAI sustainability and instead focus on socio-technical aspects of AI education, at least based on the state-of-the-art literature on AI literacy for designers. Educators may confront themselves with the problem of environmental impacts, and still decide to integrate genAI in their teaching practice. This position is in line with the view of Maceli and colleagues (Maceli et al., 2024) who argue that we should not prohibit students from using genAI tools, but rather we should focus on nurturing a critical understanding of these technologies so that they will be enabled to make conscious choices in the future. Accepting the costs of genAl and deciding to engage with it in education, however, does not necessarily mean neglecting the sustainability problem. In this position, the aspect of environmental sustainability can be addressed as one of the factors contributing to the eco-socio-technical complexity of AI system that students should be literate about (Rakova and Dobbe, 2023)."}, {"title": "5.3. Shift", "content": "\"It is important to minimize the impact of genAI teaching activities by making more sustainable choices about the technologies that we use. This will help students afterwards to make better choices in their practices\"\nThe position of shift comes from a similar standpoint to acceptance, i.e., that the need for AI literacy is of higher priority in education than the one of minimizing environmental impact. However, it brings a distinct set of practices. This is conceptually aligned with the technical and regulatory approach of designing for sufficiency (Bodelier et al., 2024; Darby & Fawcett, 2018; Erba & Pagliano, 2021; Spangenberg & Lorek, 2019; Steinberger & Roberts, 2010) where educators actively seek to minimize their impact by shifting toward 'better' genAI choices. We identify three main types of practices in this space."}, {"title": "5.3.1. Sustainability genAI benchmarks", "content": "One way to exercise a responsible engagement with genAI in education is to carefully select models and tools that are smaller and more efficient. In order to make informed choices in this direction, it is of crucial importance to develop and/or use benchmarks through which one can compare models' performance with 'costs'. Benchmarks do exist and most common examples focus on the ratio between performance and financial costs, i.e., submission prices or price per token. For instance, more and more benchmarks show how tiny models, such as GPT-40 Mini, Mistral NeMo, and Llama-3.1, actually achieve high performances while relying on smaller amounts of data, and thus being more efficient (OpenAI, 2024; Heka AI, 2024). Resources that account for efficiency and environmental impact are starting to emerge yet remain limited and difficult to grasp for non-experts (see (Asperti et al., 2021; Chen et al., 2023; Yu et al., 2022). To our knowledge, the most detailed yet accessible sustainability genAI benchmark available today is the one by Luccioni et al. (2024) who tested 88 models, diverse in terms of purposes and characteristics. However, making these resources usable and meaningful for design educators requires continuous updating, as novel models or versions of existing models are constantly being released."}, {"title": "5.3.2. Locally run models", "content": "A related but distinct practice is to encourage the use of genAI models running on local servers. Not relying on cloud computing, locally run models allows for reducing reliance on data centers and, thus energy consumption. We see moves in this direction, such as \u201cwe will outline some tools that enable offline image and text generation and provide links to their quickstart guides.\u201d (NYU Libraries, 2024). There are several advantages to running local models. Firstly, these models tend to be smaller in the number of parameters and more efficient, hence likely to have reduced energy costs. This can be seen with models like Llama 8B, which is optimized to provide a high-quality LLM that can run on a laptop, or Gemini Nano (Anil et al., 2023) which targets devices such as high-end mobile phones. Secondly, working with local models brings the compute closer to home: it becomes more obvious that the computation is power intensive when the machine starts to heat up, the fans engage and other operations become slower. Users of local models may also have to make tradeoffs in terms of space - at 8GB, a language model uses a significant amount of disk space for a laptop, which helps to push towards finding smaller solutions. Finally, using local models alters what the upper bounds on usage are: where a cloud-based model is typically bounded by either tokens or usage rates, a local model is bounded by the compute \u2013 and power \u2013 available to the machine being used."}, {"title": "5.3.3. Reuse and share", "content": "Another way to reduce impact is to choose optimized resources. This can apply to both the training and the querying of models, but adopting a reuse & share approach to the first is particularly impactful. When looking at LLMs or image generation, the cost of training the models is extremely high, but the dominating cost tends to be the inference, both because it is costly, and because it happens at scale. As an example, training a RAVE model (Caillon & Esling, 2021) for music or audio takes approximately three weeks of a high-powered GPU running full-time a relatively high cost for developing an individual model. However, the trained model can run inferences in under 200ms on a modern laptop \u2013 relatively, a much lower resource cost. This is a space where people tend to train their own models, seeing it as part of the creative process. However, communities that are happy to share trained models \u2013 such as the Intelligent Instruments Labs collection of RAVE models based on sonically interesting training data (Intelligent Instruments Lab, 2023) \u2013 allow the costs of training to be spread across a far higher amount of creative practice through creative re-use. As custom-trained models become"}, {"title": "5.4. Moderation", "content": "\"It is important to engage with genAI in education, but its impact must be moderated by reducing the number of operations or requiring a moral justification for each use\"\nSimilar to shift, the position of moderation is close to the technical and regulatory approach of sufficiency (Bodelier et al., 2024; Darby & Fawcett, 2018; Erba & Pagliano, 2021; Spangenberg & Lorek, 2019; Steinberger & Roberts, 2010. Distinctively, however, this concept inherently comes with an element of limitation not on the technology itself, but rather on the activities using it. The is an implicit imposition of boundaries to the use of genAI in educational practices. Here we illustrate three ways to practice moderation."}, {"title": "5.4.1. Group work", "content": "One can prioritize group work over individual exploration. This can be done by providing a single license for each group (for genAI tools that require one like MidJourney), which could greatly reduce the amount of generated images and thus, the energy consumed, because of the impossibility of simultaneous use of the tools. There is, however, an educational drawback here to consider. While prioritizing group work can encourage discussion among team members (Han et al., 2021) about the dynamics and results obtained from the genAI tools, it may also inadvertently encourage teams to distribute tasks, with the ultimate result of having a single person in charge of engaging with the genAI tools. Although this risk is highly dependent on the way educators introduce genAI in the design education program, the very activity with genAI may run into the"}]}