{"title": "Next Visit Diagnosis Prediction via Medical Code-Centric\nMultimodal Contrastive EHR Modelling with Hierarchical Regularisation", "authors": ["Heejoon Koo"], "abstract": "Predicting next visit diagnosis using Electronic\nHealth Records (EHR) is an essential task in\nhealthcare, critical for devising proactive future\nplans for both healthcare providers and patients.\nNonetheless, many preceding studies have not\nsufficiently addressed the heterogeneous and hi-\nerarchical characteristics inherent in EHR data,\ninevitably leading to sub-optimal performance.\nTo this end, we propose NECHO, a novel med-\nical code-centric multimodal contrastive EHR\nlearning framework with hierarchical regulari-\nsation. First, we integrate multifaceted informa-\ntion encompassing medical codes, demograph-\nics, and clinical notes using a tailored network\ndesign and a pair of bimodal contrastive losses,\nall of which pivot around a medical code repre-\nsentation. We also regularise modality-specific\nencoders using a parental level information in\nmedical ontology to learn hierarchical struc-\nture of EHR data. A series of experiments on\nMIMIC-III data demonstrates effectiveness of\nour approach.", "sections": [{"title": "Introduction", "content": "Predicting a patient's future diagnosis has been\na longstanding objective in both academic and\nindustrial healthcare sectors. Its significance is\nhighlighted for healthcare providers with refining\ndecision-making processes and resource allocation,\nand also for patients with effective future plans.\nBy leveraging the extensive accumulation of EHR\ndata, data-driven deep learning methodologies have\nachieved considerable advancements in the health-\ncare practices, particularly in next admissions di-\nagnosis prediction (Choi et al., 2016a; Ma et al.,\n2018; Qiao et al., 2019; Zhang et al., 2020a).\nHowever, most of previous studies have shown\nlimited consideration into multifaceted and hierar-\nchical properties inherent in EHR data. First, it is\nheterogeneous, encompassing a range of modali-\nties including demographics (e.g. age), medical\nimages (e.g., Computed Tomography), text (e.g."}, {"title": "Related Works", "content": "Al research community has delved into future diag-\nnosis predictions, employing various data modali-\nties such as graph, text, or more than two. DoctorAI\n(Choi et al., 2016a) is the first work that predicts\ndiagnoses utilising a simple recurrent neural net-\nworks (RNN). It is further refined to RETAIN (Choi\net al., 2016b) and Dipole (Ma et al., 2017), which\nincorporate attention mechanisms.\nMeanwhile, graph neural networks (GNN) have\nbeen influential, with models like GRAM (Choi\net al., 2017) and KAME (Ma et al., 2018) construct-\ning disease graphs from medical ontology, and oth-\ners like MMORE (Song et al., 2019) and HAP\n(Zhang et al., 2020b) focusing on learning both on-\ntology and diagnosis co-occurrence and leveraging"}, {"title": "Multimodal Learning", "content": "Beyond EHR, multimodality learning has been ex-\nplored to various domains, particularly in multi-\nmodal sentiment analysis (MSA) (Gandhi et al.,\n2022). We introduce a few works that have some-\nwhat influenced our work.\nFirst, Tensor Fusion Network (TFN) (Zadeh\net al., 2017; Liu et al., 2018) and Multimodal Adap-\ntation Gate (MAG) (Rahman et al., 2020) perform\nan outer product and attentional gate on representa-\ntions from varying modalities, respectively. (Tsai\net al., 2019) use cross-modal and self-attention\ntransformers (Vaswani et al., 2017). (Yu et al.,\n2021) introduce Unimodal Label Generation Mod-\nule (ULGM) to boost modality-wise representa-\ntions. However, the above literature do not con-\nsider the modality imbalance, such as the superior-\nity of text-based models. Based on such findings,\ntext-centred multimodal fusion strategies have been\ndeveloped (Qiu et al., 2022; Huang et al., 2023)."}, {"title": "Contrastive Learning", "content": "Contrastive Learning has emerged as a predomi-\nnant paradigm, showing its superior performance in\nmany research areas recently. Originally, it aims to\nlearn features from different views of a single sam-\nple and discriminate samples from different classes\n(Oord et al., 2018; Chen et al., 2020). Next, it is\nextended to multimodality. CLIP (Radford et al.,\n2021) is a seminal work on multimodal contrastive\nlearning, employing InfoNCE loss (Oord et al.,\n2018) to learn transferable features between images\nand texts. (Zhang et al., 2022) apply this strategy\nto medical domain, whilst (Mai et al., 2022) exploit\ntrimodal contrastive learning in MSA."}, {"title": "Methodology", "content": "In this section, we firstly introduce notations and\nproblem formulation on next visit diagnosis pre-\ndiction. Thereafter, we describe an overview and\ndetails of our proposed framework, NECHO."}, {"title": "Problem Formulation", "content": "Multimodal EHR Data A clinical record can be\nrepresented as a time-ordered sequence of visits\nV1,..., VT, where T is the total number of vis-\nits of any patient P. Each visit Ve is denoted as\n(Ct, At, Ht, Wt), where Ct is a set of diagnosis\ncodes, At is a set of diagnosis codes at their ances-\ntral level, Ht is demographics, W\u2081 is a clinical note\nat t-th admission, respectively.\nWe denote a set of medical codes from EHR\ndata as C1, C2, ..., cc \u2208 C, where |C| is the num-\nber of unique medical codes at a level in ICD-\n9 code hierarchy G. Similarly, a set of medical\ncodes at their direct ancestral level is denoted as\na1, a2,..., a \u2208 A. The total number of unique\nmedical codes in parental level is |A|. Note that,\n|A| < |C|.\nDiagnosis code at t-th visit is represented by\nCt = {Ct;1, Ct;2, ..., Ct;|C|}, where |C| represents\nthe number of diagnosis codes. Its ancestral level\ncode is denoted by At = {at;1, at;2, ..., at;|A|}\nwith of the number of parental level diagnosis\ncodes A. Demographics is represented as Ht ="}, {"title": "Medical Code Information Centred\nMultimodal Fusion", "content": "One of the major challenges in the realm of AI\nhealthcare is how to integrate the multifaceted data\neffectively. This has catalysed a surge of research\non multimodal EHR learning (Zhang et al., 2020a;\nYang and Wu, 2021). Nonetheless, a notable limita-\ntion in prior studies is the oversight of modality im-\nbalance and the adoption of a modality-symmetric\nstrategy, resulting in an unsatisfactory performance.\nWe empirically observe that the medical code rep-\nresentations show the best performance. Also, pre-\nvious works on MSA prioritise text representations\nat the core (Qiu et al., 2022; Huang et al., 2023)\ndue to their superiority. Based on these findings,\nwe introduce a novel medical code-centric multi-\nmodal fusion training scheme, which encompasses\na tailored multimodal fusion network and a couple\nof bimodal contrastive losses."}, {"title": "Modality-Specific Feature Extraction", "content": "Before introducing our novel fusion strategies, we\nfirst explain modality-specific encoders that extract\nfeatures from each modality. We design them as\nsimple as possible to highlight the efficacy of our\nproposed fusion strategies. Thus, our framework\nis modular, with the potential for performance en-\nhancement if the encoders are switched to more\nrepresentative ones.\nWe employ a simple embedding layer for both\nmedical codes and demographics, and a combina-\ntion of BioWord2Vec (Zhang et al., 2019) and 1D\nCNN (Kim, 2014) to process clinical notes. Sub-\nsequently, the feature vector is passed to a fully\nconnected layer (Linear) connected with ReLU ac-\ntivation function (Nair and Hinton, 2010)."}, {"title": "Multimodal Fusion Network", "content": "After acquiring repre-\nsentations from all modalities, we entangle them\nusing two cross-modal transformers (CMTs), intro-\nduced by MulT (Tsai et al., 2019). It has verified\nits effectiveness in integrating meaningful infor-\nmation across different modalities. Initially, we\nput the each distinct representation to a temporal\nnon-linear projector, 1D CNN:"}, {"title": "Bimodal Contrastive Losses", "content": "Contrastive learning has been leveraged in multi-\nmodal pre-training literature (Radford et al., 2021;\nZhang et al., 2022) to align diverse modalities ef-\nfectively. Inspired by prior works, we apply two\nbimodal contrastive losses to further intricately en-\ntangle the different modalities by anchoring on the\nmedical code representations.\nAgain, let two distinct modalities of m\u2081 and\nm2, where representation vectors derived from\neach modality be Hm1 and Hm2. Given a i-th"}, {"title": "Hierarchical Regularisation", "content": "Medical ontologies organise diseases in a hierarchi-\ncal manner. By effectively leveraging this, models\nare capable of acquiring knowledge at both general\nand specific levels of medical codes. This approach\nalso mitigates the risk of error propagation and min-\nimises the loss of pertinent information throughout\nthe intricate multimodal fusion processes.\nIn ULGM (Yu et al., 2021), modality-tailored en-\ncoders are also tasked with predicting ground truths.\nMeanwhile, MIPO (Peng et al., 2021) introduces\nan auxiliary loss to learn parental level ICD-9 code\nprediction. Inspired by them, we introduce a reg-\nularisation strategy for each modality-specialised\nencoder to learn parental level of ICD-9 codes.\nSpecifically, the modality-specific features Mt\nare passed to fully connected layers and Sigmoid\nactivation function, yielding modality-specific"}, {"title": "Model Optimisation", "content": "The final objective function Ltotal is a weighted\nsum of three loss terms: the cross-entropy loss\nLce between ground truth diagnosis and prediction,\nthe medical code-centric two bimodal contrastive\nlosses Lcont, and the three modality-specific direct\nancestral level hierarchical losses Chrchy."}, {"title": "Experiments", "content": null}, {"title": "Experimental Setup", "content": "We conduct experiments on a publicly available\nlarge-scale, deidentified real-world EHR data,\nMIMIC-III (Johnson et al., 2016). It is acquired\nfrom intensive care units (ICU) patients at Beth\nIsrael Deaconess Medical Center between 2001\nand 2012. It contains multifaceted data, includ-\ning ICD-9 medical codes, demographics, clinical\nnotes, and so on. We provide descriptions on data\npre-processing and the corresponding statistics to\nAppendix B."}, {"title": "Implementation Details", "content": "We describe the details for implementation. First,\nwe set 256 and 0.1 as a hidden dimension and a\ndropout rate across the entirety of the model (e.g.\nmedical code and demographics feature extraction"}, {"title": "Training Details", "content": "We train models using Adam optimiser (Kingma\nand Ba, 2014) with a constant learning rate of le-4\nand mini-batch size of 4, for a maximum of 50\nepochs. The training is stopped if there is no gain\nfor consecutive 5 epochs on validation data. Also,\nfollowing the previous work (Choi et al., 2017),\nour proposed framework is evaluated using top-k\naccuracy, ranging k from 5, 10, 20 to 30. This\nis consistent with how physicians consider a com-\nprehensive set of potential diagnoses, and is suit-\nable for multi-label classification scenarios where\nmultiple diseases often co-occur. Details on other\nbaselines are provided to Appendix D.\nOur proposed framework is implemented using\nPyTorch (Paszke et al., 2019) and accelerated via a\nsingle NVIDIA GeForce RTX 3090 GPU."}, {"title": "Experimental Results", "content": null}, {"title": "Next Visit Diagnosis Prediction Results", "content": "Table 1 provides quantitative results of the pro-\nposed NECHO in comparison to the baselines on\nthe MIMIC-III data for the diagnosis prediction\ntask. NECHO notably excels over all existing base-\nlines in EHR modelling and multimodal fusion\nstrategies. Its effectiveness is attributed to its ability\nto leverage unique and complementary information\nfrom other modalities, which especially improves\ntop-30 accuracy ranging from 0.5% to 10.7% over\nmodality-specific encoders that constitute NECHO.\nAs shown in Table 1, the multimodal fusion\nis imperative. It's noteworthy that whilst MAIN\n(An et al., 2021) employs a trimodal representation"}, {"title": "Ablation Studies", "content": "We conduct ablation studies to discern influence of\neach module on the overall performance as: 1) indi-\nvidual modalities, 2) the multimodal fusion strate-\ngies (including Transformers, MAG, and bimodal\ncontrastive losses), and 3) the hierarchical regulari-\nsation. The results are reported in Table 2.\nFirstly, we assess the contribution of each modal-\nity within our proposed framework. The results\ndemonstrate a clear superiority of the trimodal ap-\nproach over its unimodal and bimodal ones. This\nunderscores the unique representations from each\nmodality are complementary to one another. Also,\nthe significant performance degradation is observed\nupon the exclusion of medical code representation\n(w/o code), highlighting its pivotal role and ratio-\nnalising our medical code-centred strategy. Ad-\nditionally, whilst the exclusion of either notes or\ndemographics similarly harms the performance, the\nnote contains more meaningful information neces-\nsary than demographics, as shown in Table 1.\nSecondly, we evaluate the impact of our medical\ncode-centred strategies by removing each compo-\nnent. The resultant performance decline highlights\ntheir importance. Intriguingly, the performance dis-\nparities between models lacking transformers (w/o\nTransformers), lacking MAG (w/o MAG), and the\nfull model (NECHO) widen as the value of k in-\ncreases, suggesting an amplified effect in scenar-\nios involving a broader range of disease sampling.\nConversely, the influence of contrastive losses (w/o\nLbi-con) remains relatively stable across different\ntop-k accuracies, indicating that they effectively\nalign the distinct modalities in a semantically con-\nsistent fashion. These observations show that the\nadaptation of the proposed modules simultaneously\nis essential for effective inter-modality interaction\nand integration, thereby yielding significant perfor-\nmance enhancements.\nFinally, the effectiveness of our novel parental\nlevel hierarchical regularisation is investigated. Its\nomission (w/o Chrchy) affects adversely model's\naccuracy across various top-k accuracies. This sug-\ngests that enforcing the encoders for three distinct\nmodalities, guided by the parental levels of medi-\ncal codes using an ICD-9 hierarchy, is essential for"}, {"title": "Case Study", "content": "To qualitatively evaluate the predictive perfor-\nmance between MIPO (Peng et al., 2021) and our\nNECHO, we present a case study (Table 3) using a\npatient whose medical history shows a progression\nfrom a mitral valve issue to complications after\nsurgery and cardiac rhythm disturbances. In the\nstudy, codes are formatted according to the Clinical\nClassifications Software (CCS)\u00b9 and are sequenced\nbased on their priority, significantly influencing the\nreimbursement for treatment. We prefix them with\n\"D\" to make them appear akin to diagnosis codes.\nNotably, our NECHO model accurately pre-\ndicts 6 out of the top-10 diagnosis, outperforming\nMIPO, which predicts only 3. Firstly, both success-\nfully identify D53 (Disorders of lipid metabolism),\nD106 (Cardiac dysrhythmias) and D101 (Coronary\natherosclerosis and other heart disease), likely due\nto these diagnoses being part of the patient's prior\nmedical codes. However, NECHO uniquely pre-\ndicts D238 (Complications of surgical procedures\nor medical care), D49 (Diabetes mellitus without\ncomplication), D2616 (E Codes: Adverse effects of\nmedical care) and D96 (heart valve disorder) which\nMIPO fails to identify.\nAdditionally, our model predicts D238 and\nD2616 using multifaceted information of both de-\nmographics and notes. D238 should be predicted\nfor two points: 1) the patient was initially hospi-\ntalised due to emergency health problem according\nto demographics, and 2) his notes states visual hal-\nlucinations, monitoring for pericardial and pleural"}, {"title": "Conclusion", "content": "Next visit diagnosis prediction is beneficial in AI-\ndriven healthcare applications and has shown re-\nmarkable progress. However, the multifaceted and\nhierarchical properties of EHR data are beyond\nthe consideration for the most of existing stud-\nies. To address these limitations, we introduce\nthe novel multimodal EHR modelling framework,\nNECHO. It effectively aggregates three heteroge-\nneous modalities through meticulously designed\nmultimodal fusion network and the pair of two bi-\nmodal contrastive losses in a medical code-centric\nmanner. It also uses parental level information of\nICD-9 codes to each modality-specialised encoder\nto learn more general information. Experimental\nresults including ablation studies and case study on\nMIMIC-III data highlight the NECHO's efficacy\nand superiority."}, {"title": "Limitations", "content": "Whilst our proposed framework demonstrates\npromising advancements in multimodal EHR mod-\nelling for next visit diagnosis prediction, it is not\nwithout its limitations.\nFrom a data perspective, the model's predictions\nare heavily biased to the training data. This means\nthere's a potential risk that the model might under-\nperform when encountering patterns that is nonex-\nistent in the dataset or originating from the different\nhealthcare settings. Additionally, from a model per-\nspective, firstly, the framework's applicability is\nconfined and has not been extended to a variety of\nclinical event prediction tasks, such as mortality,\nre-admissions, and length of stay, where different\nmodalities might take main status. Secondly, it op-\nerates under the assumption that all data modalities\nare readily and consistently available for every pa-\ntient. However, this assumption is impractical in\nthat the availability of data can be compromised\ndue to device malfunctions or human errors.\nWe hope to mitigate aforementioned challenges\nin the near future, enhancing NECHO's adaptabil-\nity in real-world clinical scenarios."}, {"title": "Modality-Specific Feature Extraction Modules", "content": "Medical codes, particularly those from ICD-9\ncodes, play a vital role in that they directly indi-\ncate a patient's status. They are highly specific,\nunambiguous and succinct, thus they have acted\nas a primary modality for next admission diagno-\nsis prediction and shown better performance than\nmodels leveraging other modalities. Hence, here in\nthis task, we consider them as a main modality.\nWe employ a single embedding layer Ec to pro-\ncess a set of diagnosis codes at t-th patient record,\nCt. The features are passed to a single linear layer\nfollowed by a ReLU activation function. It is for-\nmulated as:"}, {"title": "Feature Extraction Module for\nDemographics", "content": "Each patient has unique demographics, such as\ngender, age, admission and discharge location, to\njust name a few. Those provide the supplementary\nbut highly personalised information, allowing an\nimprovement in predictive performance.\nWe capture the non-stationary nature of the afore-\nmentioned attributes across clinical records at the\nindividual level. For example, variables such as age\nand insurance type may change over time. Thus,\nwe employ a single embedding layer En to n-th\nattribute at t-th patient record, hr. The features\nfrom each embedding layer are then concatenated\n(+) and fed into a single linear layer paired with a\nReLU activation function. It can be represented as:"}, {"title": "Feature Extraction Module for Clinical\nNotes", "content": "Clinical notes inherently possess a free, unstruc-\ntured format but carry a comprehensive insight into"}, {"title": "Data Pre-processing", "content": "We follow the previous\nwork of GRAM (Choi et al., 2017). First, we se-\nlect patients with minimum two visits. Also, we\ntruncate visits beyond the 21st visit.\nAttributes such as\nage, gender, admission type, admission and dis-\ncharge locations, and insurance type are considered.\nPatients with ages 0 or above 120 are excluded.\nThe admission types encompass categories such\nas emergency, elective, and urgent whilst the in-\nsurance types include medicare, private, medicaid,\ngovernment and self pay. The dataset also offers\na diverse range of features for both admission and\ndischarge locations.\nEven though some\nprior works (Hsu et al., 2020; Husmann et al., 2022)\nemphasise the significance of specific note types\nfor EHR representation learning, we consider all\navailable note types (e.g. radiology, discharge sum-\nmary, and nursing) for universality.\nWe first pre-process the notes, following the pre-\nvious work (Khadanga et al., 2019). It involves a\nremoval of non-alphabetical characters, stopwords\nand conversion of uppercase to lowercase letters.\nThen, we add two special tokens to BioWord2Vec\n(Zhang et al., 2019),  and , the\nsame as those used in BERT (Devlin et al., 2018).\nThey are initialised using matrices filled with ze-\nros and uniform distribution, respectively. Any\nvisit records lacking note information are excluded.\nNext, each note is tokenised with maximum 10k\nwords using BioWord2Vec. This approach effec-\ntively captures the entirety of note information for\napproximately 85% of all the visits.\nFollowing the GRAM (Choi et al., 2017), a medical on-\ntology is constructed based on ICD-9 codes using\nthe Clinical Classifications Software (CCS) from\nthe Healthcare Cost and Utilization Project\u00b2 The\nlabels are derived from nodes present in the primary\nand secondary hierarchy of the ICD-9 codes. This\nrenders the next visit diagnosis prediction task as a\nhierarchical multi-label multi-class classification."}]}