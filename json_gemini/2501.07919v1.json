{"title": "Large Language Model Interface for Home Energy Management Systems", "authors": ["Fran\u00e7ois Michelon", "Yihong Zhou", "Thomas Morstyn"], "abstract": "Home Energy Management Systems (HEMSs) help households tailor their electricity usage based on power system signals such as energy prices. This technology helps to reduce energy bills and offers greater demand-side flexibility that supports the power system stability. However, residents who lack a technical background may find it difficult to use HEMSs effectively, because HEMSs require well-formatted parameterization that reflects the characteristics of the energy resources, houses, and users' needs. Recently, Large-Language Models (LLMs) have demonstrated an outstanding ability in language understanding. Motivated by this, we propose an LLM-based interface that interacts with users to understand and parameterize their \"badly-formatted answers\", and then outputs well-formatted parameters to implement an HEMS. We further use Reason and Act method (ReAct) and few-shot prompting to enhance the LLM performance. Evaluating the interface performance requires multiple user-LLM interactions. To avoid the efforts in finding volunteer users and reduce the evaluation time, we additionally propose a method that uses another LLM to simulate users with varying expertise, ranging from knowledgeable to non-technical. By comprehensive evaluation, the proposed LLM-based HEMS interface achieves an average parameter retrieval accuracy of 88%, outperforming benchmark models without ReAct and/or few-shot prompting.", "sections": [{"title": "1 Introduction", "content": "In the context of global decarbonization, the proportion of renewable energy sources such as wind and solar is increasing [1]. However, these renewable sources have intermittent generation, which challenges power system stability. Demand-side flexibility is acknowledged as an effective solution and is currently being implemented in practice.\nHome Energy Management Systems (HEMS) represent a promising approach to enable demand-side flexibility [20], which provides smart energy management for electricity generation, storage, and consumption in smart houses while respecting users' preferences [8] [27]. There have been extensive studies on HEMS. In [15] proposed an open-source software platform for integrated modeling, control, and simulation of smart local energy systems, including HEMS. In [22] proposed a method that includes users as key members of the HEMS, allowing them to plan the intended power consumption and manage real-time deviations. In [14] presented a grid-integrated system for energy management for smart demand-side energy management. The effectiveness of existing HEMS models was extensively discussed in [12]. In the literature, there has been extensive study of algorithm design for HEMS. However, the practical implementation of HEMS requires input parameters that represent the physical characteristics of home appliances, description of human behavior, and the user's needs for comfort. The required number of parameters can be high, and these must be well-formatted to be understandable to the HEMS algorithms. This process can be time-consuming and demotivates the use of HEMS [6]. Furthermore, non-expert users, particularly the elderly and those with limited literacy, may struggle to identify the correct and well-formatted parameters.\nA new opportunity is presented by Large Language Models (LLMs), which perform particularly well in Natural Language Processing (NLP) tasks. This motivates us to use LLMs to retrieve well-formatted parameters required for HEMS, by interacting with users in an easy-understanding and natural-language way. Recently, LLMs have found applications for several power system tasks, including modeling nonlinear power electronic circuits [26], detecting insulator defect [13], scheduling charging of electric vehicles (EVs) [10], and performing power system simulation based on a user"}, {"title": "2 Home Energy Management System", "content": "We consider a HEMS that minimizes the energy bill, by controlling devices such as electric heating, electric vehicle charging, user schedule, energy provider, solar panels, and simulation period and place (from which we obtain weather forecast and electricity price time series). This simple modelling can be extended to consider more detailed aspects like a more complex user schedule in future work."}, {"title": "2.1 Model definition", "content": "The HEMS problem we consider optimizes the energy usage of flexible appliances over a time horizon to minimize the user's cost of energy, given constraints on how the appliances can be used. In our HEMS model, the user can possess several electric vehicles (EVs), the user has a daily schedule that defines when the user is home or not (tarrival when the user comes back to his accommodation and tdeparture when the user leaves). We assume that while parked at home the EV can be charged. When the user comes back from work, his EV has a low battery, and when the user leaves in the morning it is assumed his EV must be fully charged. In addition, the user also wants the house temperature to be between a minimum and maximum value. The model is more precisely described in the section A.1 of the appendix."}, {"title": "3 Methodology", "content": "In most systems, users need to parameterize the HEMS by themselves (Fig. 1 step A1), which takes lots of time and can lead to input errors and control errors (Fig. 1 step A2). On the one hand, asking the user to provide too many precise parameters like EV capacity and usage schedule, will diminish the HEMS democratization as the learning curve will be too steep. On the other hand, asking for too little information will result in a non-tailored consumption energy schedule.\nLLMs have exhibited versatile language understanding and prominent information retrieval ability in various contexts [10] [11]. Therefore, we propose to include LLM as an extra interface between users and HEMS. This paper considers a system with three main entities: the Home Energy Management System (HEMS), the LLM agent, and the user. We aim to design an LLM-based interface that retrieves all necessary user information, stores it in a correct format, and then sends the formatted inputs to the HEMS, to obtain the optimal electricity energy schedule. Fig. 1 shows the high-level flowchart of our interface from user-LLM interaction where the user can provide badly-formatted parameters to the LLM like a textual description of its schedule instead of a formatted date (step (B1)) to the parametrization of the HEMS with the translated user preferences into HEMS formatted inputs (step (B2) and the control of user appliances (step (B3)"}, {"title": "3.1 Integration of LLM", "content": "To use the HEMS problem defined in section 2, one needs to know the user's schedule (arrival and leaving time), its preferences (minimum and maximum temperatures, start and end date of simulation), and characteristics like the number of electric vehicles he owns (see Table 4 in the appendix). This is the job of an LLM-based agent that we will define in this section.\nThe interface needs to understand user stylometry, user dwellings specificities, user energy management preferences, user energy Home Energy Management System (HEMS) understanding. The user answers can contain vague information. Classical NLP models are not capable of performing on these wide ranges of complicated tasks or require huge efforts in fine-tuning, that is why using an LLM is required.\nIn sub flowchart B of Fig. 1, the LLM-agent interacts with the user (step (B1)) and the HEMS (step (B2)). The LLM agent must be able to communicate with both entities. To do so, we provide communication functions or tools that are all stored in a toolkit object. Each tool is described in the LLM agent instantiation prompt with the function of the tool, its inputs, and outputs. We want our LLM agent to be able to ask questions to a user based on a task, retrieve the wanted information from the user's answer, and store the retrieved parameters. To do so, we allow our LLM agent to use several tools such as ask user and store which will enable better communication between the user and the LLM agent and between the HEMS and the LLM agent. To properly use those tools, the LLM agent will have to generate function calls by providing the name of a tool and its input. The LLM agent will have to choose in the tool list to which it has access, by understanding the most appropriate tool to solve the problem it is currently working on. This method is known as function calling [18.\nWe need our LLM agent to generate very precise texts for function calling, to do so we will provide examples which is a common practice. The few-shot prompting technique [3] consists in adding one or several task-solving examples, giving more information to the LLM agent after the agent prompt template (see left of Fig. 2 in the appendix). This will give more context to the LLM agent and diminish hallucination."}, {"title": "3.2 ReAct", "content": "Many methods of prompt engineering have been developed to get the most out of LLMs in NLP tasks. In this study we have chosen to focus on ReAct [25]. This method gives a ReAct prompt to the LLM to generate both reasoning traces and task-specific actions in an interleaved manner. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while enabling interaction with external environments to incorporate additional information into the reasoning. The LLM agent will break down its tasks into smaller goals to increase its success rate (see right of Fig. 2).\nIn the agent prompt template (see Fig. 10 in section B.1 of the appendix) given to the LLM agent type React + example, we first describe the main goal of the LLM agent (line 1), the tools and their description (lines 1 and 5), and then the format rules it must follow for function calling (lines 3 to 13) and for ReAct (lines 15 to 27). After receiving a task, the LLM agent will have to rephrase it, then"}, {"title": "4 LLM user", "content": "For testing purposes, we have designed an LLM to operate in the place of a real user to gain testing time and model various behaviors. In the following paragraphs, we will refer to this LLM as the user. To simulate the diversity of LLM agent-user interaction, we set a high LLM temperature (0.8 in our tests) that allows for more diversity by increasing the weights of less likely LLM-generated words. The LLM user is given personal information that an LLM agent will try to retrieve by asking questions. The user prompt template is fairly simple and follows the same rules as the agent prompt template, such as goal description, context, and rules.\nAs in a real-life scenario, user behavior can be very different from person to person. We tried to model different users by giving them different prompts that will imply different answers to the LLM agent's questions. To design the user prompts, we used synonyms and changed the formats while also adding noisy information. We have defined three levels of difficulty for the LLM agent. In the easy mode, the user's answers are considered simple and to be exactly what the agent asked for (ex: date format). We define user precision as the quality of the user's answers. It measures how badly formatted the answers of the user are (see Fig 1). The user precision diminishes with the user difficulty mode. The user precision evaluation methodology is described in section A.3 of the appendix."}, {"title": "5 Results", "content": "In this section, we present results demonstrating the performance of the proposed LLM-based HEMS interface. First, we explain and justify the settings used for the HEMS, the LLM user, and the LLM agent in our case studies. The experimental setup of the study is detailed in section A.4 of the appendix.\nWe have chosen to make the LLM agent retrieve parameters of different types to check its generalization capability (see Tab. 4). To test the added value of ReAct and the few-shot prompting, we developed three agent types: Act, Act + example, and ReAct + example. All three use function calling to interact with the user and the HEMS, so they can all \"Act\" by deciding to use a communication tool. To evaluate the importance of function calling, we developed agent type Act that does not receive any example of how it should solve tasks. To evaluate the importance of ReAct, we implemented Act + example agent type. It receives an example in its prompt of how it should solve tasks but does not follow the ReAct methodology which forces the agent to think and adapt to the results of its last action. An HEMS parametrization systems result is presented"}, {"title": "5.1 Parameter retrieval effectiveness", "content": "To better test the reliability of the interface, we need to run more tests to fully evaluate the strengths and limits of our work. Overall, the V2-powered LLM agent achieved the best results (except in Easy mode). The accuracy of all LLMs is decreasing with rising difficulty, demonstrating the importance of user precision in extracting parameters. We observe that agent type Act is performing worse than Act + example which performs slightly worse than ReAct + example (except for Model V3 in Hard and Medium). Thus, it highlights the significance of examples in prompts and the added value of ReAct compared to Act-only.\nWith Fig. 6 in section A.4 of the appendix, we see the significance of ReAct and few-shot prompting methods in our context which defines a faster and more accurate agent. V2 with Act and V2 with Act+examples are slow, and the proposed V2 with React+example is faster and requires fewer questions. Even though agent type Act + example has similar accuracy (see Tab. 2), this method requires more user questions than the ReAct + example method in every difficulty level. As a reminder, an iteration is the process of asking the LLM agent to solve a task, i.e. to retrieve a parameter. Sometimes, the LLM agent fails to store a value, so it needs more than eight iterations to find all eight parameters. Act method is by far the longest method in terms of iteration and, therefore also in duration. We observe that ReAct + example performs better than"}, {"title": "6 Conclusion", "content": "With this study, we have moved toward the democratization of home energy management systems. We have developed a representative use case of a single home-owner interaction with an LLM agent that enables a person without technical knowledge to specify key parameters for home energy optimisation. The ReAct+example LLM agent has shown remarkable adaptability by being able to retrieve parameters with different levels of user precision with higher retrieval accuracy and a smaller number of questions than with other methods.\nSeveral leads can be exploited to correct the current limitations of our interface. Inferring more technical parameters for a more accurate HEMS like window-to-wall ratio or house orientation from a user non-technical description, user photos and house plan would make our approach more relevant as they can be easily obtained from a user and can provide much information the user may not be able to render to the LLM agent directly. Such tasks may require a multi-modal LLM. LLMs can provide extended user interactions. LLM-based user interactive systems can benefit from API integration like web searches or classical NLP approaches.\nWe think that NLP algorithms and LLMs are complementary and could be combined in future work in a faster and more efficient HEMS parameterization approach. User testing is essential to validate the usability and effectiveness of the LLM-based HEMS. The LLM-user introduced in this study models a wide variety of user behavior, pushing the LLM-agent to its limits and thus providing a solid testing approach. However, while our proposed LLM-based approach enables efficient testing, future efforts should incorporate pilot studies in diverse real households to gather feedback, evaluate performance, and refine the system for broader and more practical adoption. In future works, a more reliable LLM-based system should be tested with a large corpora of real independent users to fully evaluate the capabilities of the system. The test results will provide new objectives and highlight key points that will need to be addressed.\nWe might also want our LLM agent to take action based on its understanding of the user behavior, to be able to propose more adapted consumption strategies and explain them to the user. Being"}, {"title": "A Additional resources", "content": null}, {"title": "A.1 HEMS", "content": "Here we present in detail the model behind the HEMS of the study with Eq. 1. The solar-generated electricity is directly consumed by user appliances, and if solar panels produce more energy than needed, the surplus is sold as highlighted in (Eq. 1d). Prices depend on the user's energy provider. The function the HEMS minimizes is defined in (Eq. 1a) and its variables are described in Tab. 3. We define pt (t) the total power the user is consuming at time t in (Eq. 1c). We did not consider V2G (the process of feeding the energy stored in an electric vehicle's battery back into the National Grid), which is why in (Eq. 1e) PEV is always positive. (Eq. 1f) is the EV charging formula. (Eq. 1g) and (Eq. 1h) are respectively the start"}, {"title": null, "content": "min\nPheat,PEV\nT\n\u03a3(pt(t) \u2013 Ps(t))x(t)\n(1a)\nt=1\ns.t. \u2200t = 1, ..., T\npt(t) = Pheat(t) + PEV (t) + Pother(t)\n(1b)\n\u03c0(t) = \u03c0\u03b5(t)1pt(t)\u2265Ps(t) (t) + \u03c0\u00ba(t)1pt(t)<Ps(t) (t)\n(1c)\nPEV_max(t) \u2265 Pev(t) \u2265 PEV_min(t)\n(1d)\nEEV (t + dt) = EEV (t) + pev(t)dt\n(1e)\nEEV (tarrival) = Einit\n(1f)\nEEV (tdeparture) = Efully_charged\n(1g)\nThouse(t + dt) =dt(\u03b2pheat(t) + a(Text(t) - Thouse(t)))\n(1h)\n+ Thouse (t)\n1\n\u03b1 =\nRthCth\n\u0648\n\u03b2 = Cth , Tmax \u2265 Thouse(t) \u2265 Tmin\n(1i)\n(1j)"}, {"title": "A.2 ReAct", "content": "In this section, we detail the different components behind the ReAct agent of our HEMS parametrization system. The interface flowchart diagram shown in Fig. 2 describes with more detail a parameter retrieval of agent type React + example which is symbolized by steps (B1) and (B2) in Fig. 1. The LLM agent has to find each one of the user parameters thanks to the user's answers to the LLM agent's questions.\nAs shown in Algorithm 1, the React algorithm of our interface starts by initiating the LLM agent with a prompt template and a task (line 2). The algorithm stops when the maximum number of iterations is reached or when the LLM agent has found and stored the desired parameter that can be checked with the is_done function (line 3). The LLM agent will generate texts containing the Thought/Action/Observation format (line 5). The generated response is parsed. If the format is respected, the parser will output the result of the function called in the LLM-generated JSON (line 6); otherwise, the parser will output an error message. In each case, we concatenate the newly generated text and the parser's output into the agent prompt (line 7). Upon completion, the algorithm returns the stored value of the LLM in case of success."}, {"title": null, "content": "1: iter 0\n2: agent_prompt \u2190 init_prompt(task)\n3: while not is_done() and n_iter > iter do\n4:\niter iter + 1\n5:\nresponse generate(agent, agent_prompt)\n6:\noutput parser(response)\n7:\nagent_prompt \u2190 agent_prompt + response + output\n8: end while\n9: return get_result(agent_prompt)"}, {"title": null, "content": "Algorithm 2 describes the interface in detail. A toolkit object containing the communication tools with the user and the HEMS is instantiated (line 2). It creates its tools' description that we will give to the LLM agent. The algorithm stops when the LLM agent has"}, {"title": "A.3 User", "content": "We used the embedding model all-MiniLM-L6-v2, a powerful derivative of the MiniLM developed by Microsoft Research [23] to compute embedded the different textual data (user's answers and the perfect answers). We used Mistral AI instruct model V2 to generate the answers of the LLM user [24].\nAll LLM starts by embedding a sentence into a vector before generating the following words of the prompt. In this vector space, two sentences with similar meaning will have a similar vector. To quantify user precision, we want to compute a vector similarity metric between a perfect answer that is concise and respects the wanted format and our user answer. We computed the cosine similarity metric to quantify user answer precision in different difficulty modes [21]. For example, to the question \"How many electric vehicles do you own ?\", we define the perfect answer as \"I own 2.\". For some parameters such as the number of electric vehicles or EVs a very concise answer might not fully represent the context of the sentence (electric vehicles in the example and not solar panels). Thus, we need to add the context of the answer -which is the question here- to obtain the full meaning of the user's answer. Therefore, to compute user precision, we compute the cosine similarity between the embedding of both the question and the user's answer in all three difficulty modes compared to the embedding of the same question and the perfect answer.\nThe similarity equation between LLM-user and defined perfect answers is presented in Eq. 2. A(Q) is the answer of the user to question Q, A*(Q) is the best answer to question Q and f is the embedding function."}, {"title": null, "content": "cosine(Q) =\n  f(Q+A(Q)) \u00b7 f(Q + A\u2217(Q))\n  ||f(Q+A(Q))|| || f(Q + A\u2217(Q) ||\n(2)"}, {"title": "A.4 Results", "content": "To model the electricity consumption of several appliances of the HEMS, we used the dataset provided in [4]. We use the parameter settings in Tab. 5 for the temperature evolution formula with \u03b7 = 1 as we use electric heating and not a heat pump and we increased the thermal resistance to model a well-insulated house."}]}