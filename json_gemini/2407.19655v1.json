{"title": "AI-Driven Healthcare: A Survey on Ensuring Fairness and Mitigating Bias", "authors": ["Sribala Vidyadhari Chinta", "Zichong Wang", "Xingyu Zhang", "Thang Doan Viet", "Ayesha Kashif", "Monique Antoinette Smith", "Wenbin Zhang"], "abstract": "Artificial intelligence (AI) is rapidly advancing in healthcare, enhancing the efficiency and effective-ness of services across various specialties, including cardiology, ophthalmology, dermatology, emergency medicine, etc. AI applications have significantly improved diagnostic accuracy, treatment personalization, and patient outcome predictions by leveraging technologies such as machine learning, neural networks, and natural language processing. However, these advancements also introduce substantial ethical and fair-ness challenges, particularly related to biases in data and algorithms. These biases can lead to disparities in healthcare delivery, affecting diagnostic accuracy and treatment outcomes across different demographic groups. This survey paper examines the integration of AI in healthcare, highlighting critical challenges related to bias and exploring strategies for mitigation. We emphasize the necessity of diverse datasets, fairness-aware algorithms, and regulatory frameworks to ensure equitable healthcare delivery. The paper concludes with recommendations for future research, advocating for interdisciplinary approaches, trans-parency in Al decision-making, and the development of innovative and inclusive AI applications.", "sections": [{"title": "INTRODUCTION", "content": "Artificial intelligence (AI) is revolutionizing modern healthcare, dramatically transforming the ways we diagnose, treat, and manage diseases. The integration of AI into healthcare began in the late 20th century with systems like MYCIN\u00b9 in the 1970s, which helped diagnose infections and recommend antibiotics, and CADUCEUS2 in the 1980s, which emulated human diagnostic reasoning. These early systems laid the groundwork for today's advanced machine learning and deep learning techniques, which now significantly enhance diagnostic accuracy, treatment personalization, and patient outcome predictions.\nAs AI technologies have advanced, their impact on healthcare has grown exponentially. Modern AI applications, particularly deep learning, have enhanced image recognition, significantly improving diagnostic accuracy in fields such as radiology and pathology 3. Predictive analytics, powered by AI, are essential in patient monitoring and management, using real-time data to forecast potential patient deteriorations4. Additionally, natural language processing (NLP) tools have revolutionized the han-dling of unstructured data, improving the functionality of electronic health record systems and facilitating more comprehensive patient care5.\nSeveral key algorithms and technologies underpin these advancements. Neural networks, particularly convolutional neural networks (CNNs), are extensively used for medical image analysis, aiding in the detection and characterization of various pathological findings. Decision support systems incorporate diverse data, including genetic profiles and prior health records, to optimize treatment strategies7. Among the notable AI tools, IBM Watson stands out for its application in cancer treatment, although its widespread adoption faces challenges 8.\nThe integration of AI into healthcare brings substantial benefits, enhancing diagnostic and operational efficiencies while sig-nificantly reducing human error\u201d. AI's ability to manage and analyze large datasets improves resource allocation and patient scheduling, directly impacting patient outcomes and satisfaction 10. In public health, AI's predictive models are crucial for track-ing disease patterns and managing epidemics, as evidenced during the COVID-19 pandemic 11. However, these advancements bring significant ethical and fairness challenges, particularly biases in training data that can lead to skewed AI models and dis-parities in healthcare outcomes among different demographic groups 12. For example, an algorithm used in US hospitals was biased against black patients in resource allocation 13, and dermatological AI showed lower diagnostic accuracy for conditions like melanoma in darker-skinned individuals due to training primarily on fair-skinned images 14. Similarly, AI tools for diag-nosing depression have faced challenges when applied across different linguistic and cultural backgrounds because they were primarily trained on English-speaking, Western populations, leading to potential misdiagnoses in non-Western patients 15.\nThese examples highlight the urgent need for diverse datasets and transparent AI systems to ensure fairness and equity in healthcare delivery. Governments and regulatory bodies are responding to these challenges by crafting targeted policies and regulations. The European Union's General Data Protection Regulation (GDPR) addresses privacy and ethical considerations in AI applications, setting a precedent for global data handling and protection standards16. In the US, the Food and Drug Administration (FDA) is at the forefront of regulating medical AI applications, ensuring that new technologies are both safe and effective for clinical use 17.\nThis survey paper addresses the following questions:\n\u2022 How does bias manifest in AI systems used in healthcare?\n\u2022 What are the sources of bias?\n\u2022 What are the potential consequences of biased AI systems?\n\u2022 How do we address and mitigate these biases?\nWe investigate existing research on AI integration in healthcare, focusing on the emergence and origins of biases, their impact on outcomes, and strategies for detecting and mitigating these biases. The paper also delves into ethical and legal considerations related to AI in healthcare.\nThis paper, Section 2, discusses the applications of AI in various healthcare dimensions. The biases exhibited by those AI applications, their root causes, and other details have been discussed in Section 3. Section 4 explores various approaches to address and mitigate bias. Ethical and legal considerations are discussed in Section 5. Section 6 identifies research gaps and future directions for enhancing AI in healthcare. This paper is concluded in Section 7."}, {"title": "APPLICATIONS OF AI IN HEALTHCARE", "content": "AI has emerged as a transformative force in healthcare, revolutionizing various medical domains through advanced algorithms, data analytics, and machine learning techniques. AI's ability to process vast amounts of data with precision and speed has opened new avenues for enhancing diagnostic accuracy, personalizing treatments, and improving patient outcomes. This section explores the diverse applications of AI across several key areas of healthcare, highlighting its impact and potential for future innovations."}, {"title": "Cardiology", "content": "AI has significantly transformed cardiology by enhancing diagnostic accuracy, personalizing treatment, and improving patient outcomes 76,77. AI algorithms are adept at analyzing cardiovascular data to facilitate early detection and diagnosis of heart dis-eases, including arrhythmias, heart failure, and coronary artery disease 78,79. For instance, machine learning models can interpret echocardiograms with high precision, often surpassing human experts in diagnostic speed and accuracy 80. AI also assists in managing cardiovascular risk by integrating diverse patient data to predict individual risk factors more effectively81. Further-more, AI plays a crucial role in developing personalized treatment plans by analyzing patient data and predicting responses to various treatment modalities, optimizing therapeutic decisions82. The integration of AI in clinical practice necessitates rigor-ous validation and ethical alignment to ensure patient safety and data security 83. The continuous evolution of AI technologies promises further innovations in diagnostic tools and therapeutic strategies, enhancing precision and predictive capabilities in whole person care whereby patients may be prescribed lifestyle changes specific to their context as seamlessly as medications tuned to their genomics84. Moreover, AI can contribute to health equity by making advanced cardiac care accessible in un-derserved areas through telemedicine platforms and remote monitoring, thereby reducing disparities in cardiovascular health outcomes 85."}, {"title": "Ophthalmology", "content": "AI has revolutionized ophthalmology by enhancing diagnostic accuracy, improving patient outcomes, and streamlining clinical workflows. More and more, AI algorithms, especially deep learning models, are being used to look at complicated visual data from imaging methods like fundus photography and optical coherence tomography (OCT)86. These models are very good at diagnosing common eye diseases like diabetic retinopathy, glaucoma, and age-related macular degeneration; they can sometimes match or beat the performance of experts 87. Automated analysis using AI not only speeds up the diagnostic process but also reduces human error, facilitating earlier and more precise interventions 88. Furthermore, AI's predictive capabilities are being harnessed to forecast disease progression, which is crucial for conditions like glaucoma, where early detection can prevent severe vision loss. Using AI tools in clinical practice also includes using AI-driven decision support systems that help plan treatments by guessing how different types of treatments will work89. Despite these advancements, challenges remain, including data privacy concerns, the need for large annotated datasets for training algorithms, and the integration of AI into existing clinical workflows. However, ongoing research and collaboration between AI technologists and ophthalmic experts are likely to overcome these obstacles, solidifying AI's role in modern ophthalmology91. This further opens the frontier for expansion of access to ophthalmological care in existing deserts through technology-enabled care models and non-specialist operators at the point of service, thereby addressing disparities in eye care availability and quality."}, {"title": "Dermatology", "content": "AI is transforming dermatology by enhancing diagnostic accuracy, personalizing treatment plans, and streamlining patient management. AI-powered tools, particularly CNNs, are highly effective in diagnosing skin cancer, matching or surpassing dermatologists in identifying melanomas 92,93. Moreover, AI applications in dermatology extend beyond cancer detection. They include the assessment and management of chronic conditions such as psoriasis and atopic dermatitis, where AI algorithms help in monitoring disease progression and response to treatment94. AI systems are also utilized in cosmetic dermatology, optimizing treatment recommendations based on individual facial analysis95. Ensuring the efficacy and safety of AI tools requires rigorous validation processes with diverse datasets to mitigate bias and enhance generalizability 14. Integration into clinical workflows and user training are crucial to maximizing the benefits of AI in dermatological practice\". As AI continues to evolve, continuous collaboration between technologists and clinicians is essential to address ethical considerations and improve patient outcomes in dermatology. Importantly, AI can democratize access to high-quality dermatological care by enabling remote consultations and diagnostics, thus reducing barriers for individuals in remote or underserved regions.\""}, {"title": "Neurology", "content": "AI has significantly advanced the field of neurology by enhancing diagnostic accuracy, personalizing treatment plans, and facilitating neurological research. AI techniques, particularly machine learning and deep learning, are pivotal in diagnosing neurological disorders such as Alzheimer's disease and epilepsy by analyzing imaging data with high precision97,5. These technologies improve the interpretation of MRI and CT scans, often achieving higher accuracy than traditional methods. In treatment, AI algorithms personalize therapies based on patient data, optimizing treatment outcomes for diseases like Parkin-son's 98. Additionally, AI has revolutionized neuroprosthetics by creating adaptive interfaces, significantly improving the quality of life for patients with motor disabilities\u201d. Predictive analytics also play a crucial role in anticipating disease progression for conditions such as multiple sclerosis 100. AI's application extends into research, facilitating the understanding of complex neurological phenomena and the development of innovative treatments 101. Overall, AI's integration into neurology not only improves clinical practices but also opens new avenues to address rare diseases as well as more finely tune medications to the individual 102. Furthermore, AI can enhance health equity in neurology by enabling remote diagnosis and monitoring, ensuring that patients in underserved areas receive timely and accurate neurological 103."}, {"title": "Radiology and Cancer Treatments", "content": "AI is revolutionizing radiology and cancer treatment by enhancing imaging accuracy, enabling personalized therapy, and im-proving diagnostic workflows. AI algorithms, particularly deep learning models, have significantly improved the precision of image interpretation in radiology, aiding in the early detection and diagnosis of various cancers, such as breast and lung cancer 104. These models analyze imaging data much more rapidly than human radiologists, reducing diagnostic times and in-creasing efficiency 105. In cancer treatment, AI assists in formulating personalized treatment plans based on patient data and predictive analytics, which can predict treatment outcomes and suggest optimal therapies 106. AI applications in radiology ex-tend to prognostic evaluations, predicting disease progression and survival rates, refining treatment protocols and developing follow-up strategies 107. These advancements are supported by large datasets and strict validation processes, ensuring reliability and clinical applicability 108."}, {"title": "Emergency Medicine and Critical Care", "content": "AI stands to significantly transform emergency medicine and critical care by enhancing patient triage, treatment efficacy, and time to diagnosis. As AI-powered tools like diagnostic algorithms have been incredibly good at the early identification of conditions like sepsis and its progression, there is the potential to improve patient outcomes 109,110. The prediction of patient outcomes has also positioned AI to facilitate the optimization of critical resource allocation. During the COVID-19 pandemic, AI-based self-triage tools had a critical role to play in predicting cases and hospitalizations at the population level111. \u0391\u0399-powered chatbots and virtual assistants are streamlining patient intake and symptom assessment 112,113. Furthermore, Al's role in triaging patients based on urgency has revolutionized care prioritization, improving ED operations and patient flow 114,115. These advancements underscore Al's potential to not only enhance emergency medical services but also pave the way for a more efficient, accurate, patient-centered healthcare system that extends care beyond the traditional brick-and-mortar facilities."}, {"title": "FAIRNESS CONCERNS IN HEALTHCARE", "content": "This section delves into various fairness concerns that arise during the application of AI in healthcare. Initially, it examines the sources of bias in AI healthcare systems, including data bias, algorithm bias, explicit bias, implicit bias, and selection bias. Furthermore, it will discuss the potential consequences of these biases, such as misdiagnosis, inequitable healthcare outcomes, loss of trust in healthcare systems, legal and ethical implications, resource misallocation, and stifling innovation. By delving into these topics, this section aims to underscore the critical need to address biases to ensure AI technologies contribute to fair and equitable healthcare for all."}, {"title": "Sources of bias", "content": "Data Bias: Data bias in AI healthcare systems can severely compromise their effectiveness and fairness. For instance, a study by Obermeyer et al. 12 found that a healthcare management algorithm disproportionately favored white patients over black patients with similar health conditions due to reliance on historical healthcare cost data, which reflected existing socioeconomic disparities. Further studies reinforce the pervasive nature of data bias in healthcare AI. For example, Rajkomar and his team found that the models trained on patient datasets from one geographical region often failed to generalize to populations outside that region, indicating a geographic data bias that limits the practical utility of AI systems in diverse settings4. Additionally, the AI system used for diagnosing diabetic retinopathy performed well in tests but showed decreased accuracy in clinical settings, especially among minority populations not well represented in the training data, underscoring the impact of demographic data biases 116.\nAlgorithm Bias: Algorithmic bias in AI healthcare occurs when AI systems develop systematic errors that disadvantage cer-tain patient groups. For example, AI models used to diagnose pneumonia displayed biases against specific racial groups, failing to capture important socio-economic and demographic factors despite extensive training on hospital data. This led to inappro-priate treatment recommendations 4,13,117. Another study in dermatology faced the same issue. The CNNs used for detecting skin cancer were less effective for individuals with darker skin. This discrepancy arose because the training data predominantly consisted of images featuring lighter skin tones, which does not reflect the diversity of global skin types. Consequently, this training limitation can lead to poorer health outcomes for underrepresented groups 14.\nExplicit Bias: Explicit bias in AI systems within healthcare refers to observable prejudices that directly influence these systems' decision-making processes. These biases are often a result of human prejudices being encoded in to AI through biased data or algorithms, leading to discriminatory practices and unequal treatment of patients 118. One example of explicit bias in healthcare AI is the underdiagnosis of certain demographic groups by AI models. A study investigating the fairness of vision-language foundation models in medical imaging found that these AI systems consistently underdiagnosed marginalized groups, such as black female patients, across a range of pathologies 119. This explicit bias in diagnostic AI tools can lead to delayed or inadequate medical care for specific patient subgroups, exacerbating healthcare disparities. Underlying Clinical Decision Support systems, explicit bias may be due to the selection of data and algorithm design, leading to biased outcomes. For example, the decreased likelihood of receiving diagnostic imaging for nonwhite groups compared to their white counterparts when controlling for patient and facility level factors is embedded in clinical data 120. Accordingly, models predicting imaging use may reflect the human prejudices around who deserves and receives diagnostics 121. Moreover, if an AI system is trained predominantly on data from one ethnic group or gender, it may not perform accurately for other ethnicities or gender. The use of biased AI in healthcare can result in systematic discrimination, where certain groups received suboptimal care due to the Al's prejudiced programming. This can manifest in various ways, such as through biased diagnostic tools, treatment recommendations, or predictive analytics that unfairly disadvantage certain groups.\nImplicit Bias: Implicit bias in AI systems in healthcare refers to the unconscious prejudices that can influence decision-making processes without explicit acknowledgment. These biases often reflect societal stereotypes and may not align with the conscious values or beliefs of the developers or users of the AI system. Implicit biases can alter perceptions and judgments, leading to disparities in healthcare delivery and outcomes 119. In healthcare settings, implicit biases can manifest in various ways. For example, a study on obstetric care providers found that implicit biases favored French women over African migrant women, potentially influencing medical decisions and leading to healthcare disparities 122. Similarly, healthcare professionals have been shown to exhibit implicit biases based on ethnicity, which could affect the likelihood of patients being given another opportunity to attend an outpatient clinic after missing an appointment 123. Another example is the use of AI in diagnostic tools, where implicit biases can result in differential accuracy rates across racial or ethnic groups. This can lead to underdiagnosis or misdiagnosis for certain populations, contributing to unequal treatment and outcomes 124. Implicit biases can also affect the development of clinical decision support systems. This is because the data used to train AI might not fully reflect the diversity of the patient population, which could lead to recommendations and treatment plans that aren't based on facts 125,126. Furthermore, implicit biases can impact the patient-provider relationship, where unconscious prejudices may influence the level of care and communication provided to patients of different racial or ethnic backgrounds, potentially affecting their health outcomes 127.\nSelection Bias: Selection bias occurs when the training data for an AI model is not representative of the broader population or the context in which the model will be applied. This leads to AI systems performing well on training data but poorly in real-world settings, particularly for underrepresented groups 128. The development of AI models for disease prediction or diagnosis, primarily trained on data from specific demographic groups like a particular race, gender, or age group, is one example of selection bias in healthcare settings. If an AI model for diagnosing skin cancer is trained primarily on images of lighter-skinned individuals, it may perform poorly when diagnosing conditions on darker skin, leading to higher misdiagnosis rates for individuals with darker skin tones 125. AI models that predict patient outcomes or treatment efficacy also exhibit selection bias. If the historical data used to train these models predominantly come from patients who received a certain level of care or who have specific socioeconomic backgrounds, the AI's predictions may not accurately reflect outcomes for patients outside of these groups 128. This can lead to disparities in healthcare recommendations and interventions offered to patients from different socioeconomic or racial backgrounds. Furthermore, selection bias can also manifest in AI-driven tools for patient triage and resource allocation. If the data used to train these models does not adequately account for the diversity of patient presentations and conditions, the AI system may prioritize certain patient groups over others, inadvertently exacerbating existing healthcare disparities."}, {"title": "Potential consequences of biases", "content": "Biases in AI systems, particularly in healthcare, can have profound and far-reaching consequences. These biases usually stem from the data on which the AI systems are trained, the design of the algorithms themselves, and the contexts in which they are deployed (as discussed in Section 3.1). Here are several potential consequences of biases in AI systems in healthcare:\nMisdiagnosis and Inequitable Healthcare Outcomes: AI integration in healthcare brings significant advancements but also risks of misdiagnosis and inequitable outcomes due to biased algorithms. AI systems often rely on non-representative data, leading to biased decision-making. For instance, Obermeyer highlighted that an algorithm used in healthcare disproportionately favored white patients over black patients because it used healthcare costs as a proxy for healthcare needs, indirectly embedding racial biases in its predictions 12. Moreover, these biases in AI can exacerbate existing healthcare disparities. Rajkomar and others discussed how AI applications, if not carefully designed and monitored, could inherit and amplify socioeconomic and racial disparities. This is particularly problematic in diagnostics, where AI systems are trained predominantly on data from specific demographic groups, potentially leading to poorer diagnostic accuracy for underrepresented groups4. This was evident in a study by Adamson and Smith, which found that dermatology AI systems demonstrated lower accuracy rates in skin lesion diagnosis for dark-skinned individuals compared to those with lighter skin14. Such biased AI not only risks misdiagnosis but also contributes to inequitable healthcare outcomes by potentially steering healthcare resources away from those who may need them most. Vayena and his team emphasized the ethical imperative to ensure that AI tools in healthcare are developed with consideration for fairness and equity, advocating for diverse and inclusive data sets and algorithmic transparency to mitigate these biases 129.\nLoss of trust in Healthcare Systems: Recent studies have echoed the concern that the deployment of biased AI in healthcare could significantly undermine public trust in medical systems. Trust is foundational to the patient-provider relationship and is crucial for the effective delivery of healthcare services 130. When AI tools exhibit bias, whether in diagnosis, treatment recommendations, or patient management, they can lead to misdirected care, fostering distrust among patients, particularly in marginalized communities4. Kherbache and his team pointed out that when patients perceive AI-driven processes as opaque or unfair, their trust in the overall healthcare system may decline131. Incidents of AI failures that receive public attention can exacerbate this erosion of trust, leading patients to question the reliability and ethics of using AI in medical decision-making. Researchers like Kerasidou argue that trust is not only about the accuracy of AI but also its alignment with ethical principles that govern healthcare, such as beneficence and non-maleficence 132. Furthermore, the lack of transparency in how AI models make decisions can be a major barrier to trust. Blease's study 133 suggests that without clear communication about how AI tools contribute to healthcare decisions, patients may become skeptical of diagnoses and treatments, fearing that their personal healthcare data could be misused or misunderstood. This potential trust deficit could have severe implications, not just for individual health outcomes but also for public health at large, as mistrust in healthcare systems can lead to lower rates of healthcare utilization, vaccine hesitancy, and poor adherence to medical advice134. Veinot highlights the need for healthcare systems to maintain high standards of accountability and transparency as they integrate AI technologies to mitigate such risks 135.\nLegal and Ethical Implications: The use of biased AI in healthcare not only poses clinical risks but also entails significant legal and ethical implications. Deploying biased AI systems could lead to legal breaches of anti-discrimination laws. In the United States, for example, the Civil Rights Act and the Americans with Disabilities Act set legal standards that could be violated by biased AI algorithms, which fail to provide equitable care across different patient demographics 136. Ethically, biased AI conflicts with the fundamental medical ethics principles of justice and non-maleficence, demanding fairness and avoidance of harm, respectively 137. Moreover, biased algorithms in healthcare could potentially expose medical practices and institutions to litigation related to malpractice or negligence, especially if these algorithms contribute to substandard care outcomes 138. For instance, if an AI system were to consistently provide inferior diagnostic support for certain racial groups, this could be viewed as a form of systemic negligence or malpractice 129. Additionally, the ethical implications extend to the breach of patient trust and the compromise of patient autonomy. Ethical medical practice relies heavily on the principles of informed consent and respect for patients' autonomy-principles that are challenged by opaque AI systems that do not make their decision-making processes or inherent biases clear to patients or practitioners 133. These potential legal and ethical failures underscore the necessity for rigorous oversight and transparent development processes for AI in healthcare, aiming to ensure that these technologies adhere to both existing legal frameworks and ethical standards of practice.\nResource Misallocation: The deployment of biased AI in healthcare settings can lead to resource misallocation, a critical issue that impacts both the efficiency and fairness of medical services. Biased algorithms may misdirect resources by prioritiz-ing certain groups over others based on flawed data inputs or biased training procedures. For example, a study by Obermeyer demonstrated how an algorithm used for managing healthcare resources inadvertently favored healthier white patients over sicker black patients due to biased data inputs that did not accurately reflect patient needs 12. This misallocation can exacerbate existing healthcare disparities by diverting necessary medical attention and resources away from those who are most in need.\nAs Chen pointed out, such disparities are not just a matter of clinical outcomes but are deeply tied to social and economic in-equalities that AI tools can inadvertently perpetuate 13. Furthermore, biased AI can influence the allocation of resources within healthcare facilities, potentially resulting in inefficiencies that strain healthcare systems. This includes misallocating medical staff, diagnostic tools, and hospital beds, which can degrade the quality of care delivered while increasing wait times and healthcare costs4. Resource misallocation also raises ethical questions about fairness and equity in healthcare provisioning. It challenges the ethical principle of justice, which demands that healthcare resources be distributed based on need rather than biased algorithms 137. This ethical breach can lead to further mistrust and reluctance among underserved populations to engage with healthcare systems, perpetuating a cycle of disadvantage.\nStifling Innovation: The presence of bias in Al systems used in healthcare not only affects the accuracy and fairness of medical services but can also stifle innovation. When Al models are made using biased data, they might not accurately reflect the different needs of the population. This could make these innovations less useful and applicable to a wider range of demographic groups. Liang talks about how biased training datasets in AI development make it harder for these systems to work with different types of data. This could stymie innovation by preventing it from solving larger or more complex health problems that affect many people. Moreover, reliance on biased AI can deter investment in developing new technologies that are inclusive and equitable. Potential investors may be cautious about funding projects that might not meet regulatory standards for fairness or could lead to public backlash a concern highlighted by Corbett-Davies and Goel, who note the legal and social implications of deploying biased AI139. In addition, the perpetuation of bias in AI could solidify existing disparities in healthcare innovation. As Benjamin notes, if innovation is directed predominantly at solving problems specific to well-represented groups, less common but equally pressing issues in underrepresented groups are neglected, thereby limiting the scope and impact of technological advancements in healthcare140. The studies of Rajkomar4, Hardt141, and Howell142 made things even more complicated by pointing out that biased algorithms can make it harder to find new treatments that work for everyone. This feeds a cycle of innovation that helps groups that are already overrepresented in data sets more than others. This restricted focus on innovation not only affects the equity of healthcare delivery but also limits the development of truly innovative, comprehensive healthcare solutions. These factors combined suggest that biased AI not only hinders the progression of medical technologies but also potentially locks the healthcare sector into a cycle of uneven innovation where only the needs of the majority are systematically addressed."}, {"title": "ADDRESSING AND MITIGATING UNFAIRNESS IN AI", "content": "As AI technologies increasingly influence healthcare delivery, it becomes essential to scrutinize and refine these systems to prevent disparities in care and outcomes. This section explores various bias detecting and mitigating strategies in AI systems in healthcare."}, {"title": "Bias Detection Methods", "content": "In healthcare, detecting bias in AI systems is crucial, as it can result in disparities in healthcare delivery and outcomes. This section provides an overview of bias detection strategies in healthcare AI system, including: statistical analysis, auditing tools, and feedback from end-users."}, {"title": "Statistical Analysis:", "content": "In the realm of AI healthcare, detecting bias through statistical analysis is a critical step towards ensuring equitable healthcare outcomes across diverse populations. Regular statistical reviews serve as a foundational approach to identifying and addressing disparities in AI outputs, thereby improving the fairness and effectiveness of AI-driven healthcare solutions 123. The systematic review on bias detection and mitigation strategies in electronic health record-based models shows how important it is to find different types of bias that can affect AI models created using EHR data. This comprehensive analysis highlights the necessity of employing fairness metrics such as statistical parity 143, equal opportunity 144, and predictive equity 145 to detect implicit and algorithmic biases effectively. Using chi-squared statistical analysis, differences in preconception health indicators have been found based on age, race or ethnicity, education level, living in a city, and income. This shows how important it is to do regular statistical reviews to find healthcare inequalities146. Similarly, a study of the clinical predictive values for radiographic pneu-monia in children showed the sensitivity and specificity of commonly assessed signs and symptoms. This gave us information about how well AI models can be used for diagnosis in pediatric healthcare 147,148. The epidemiological study of autism spec-trum disorders in Greece used statistical analysis to find differences in the rates of ASD across different regions. This shows how useful statistical methods are for finding biases in healthcare datasets 149. Additionally, a prospective diagnostic evaluation comparing self-taken and healthcare worker-taken swabs for rapid COVID-19 testing highlighted the accuracy of AI-driven diagnostic tools, further illustrating the importance of statistical analysis in evaluating AI model performance 150. Furthermore, the exploration of AI in enhancing diagnosis, treatment, and healthcare systems in India emphasizes the potential of AI to rev-olutionize healthcare while also acknowledging the challenges posed by biases and ethical considerations 151. This underscores the need for rigorous statistical analysis to ensure that AI-driven healthcare solutions are both effective and equitable."}, {"title": "Auditing Tools", "content": "The Disparities Impact Statement (DIS): An innovative tool, the DIS152, evaluates healthcare policies and practices for potential biases. It assesses how different population groups might be differently affected by a healthcare policy or practice, aiming to preemptively identify disparitiesThe tool involves qualitative and quantitative analyses to ensure a comprehensive review of the policy's implications across various demographics 153. By implementing DIS, healthcare institutions can address disparities at the policy formulation stage, promoting equity in healthcare delivery 154.\nPROGRESS Framework: The PROGRESS framework 155, which stands for Place of Residence, Race, Occupation, Gender, Religion, Education, Socioeconomic Status, and Social Capital, is a tool used to identify and evaluate the factors contributing to health inequalities. This framework encourages researchers and practitioners to systematically consider these dimensions when developing and implementing studies or interventions in healthcare settings 156. It is particularly useful in designing public health interventions and assessing the socio-economic and demographic factors influencing health outcomes 157.\nImplicit Association Test (IAT): The IAT158 is employed in healthcare to detect unconscious biases among healthcare providers that may affect patient care and treatment outcomes. Originally developed in psychological research to explore unconscious biases, IAT has been adapted for healthcare to assess biases in race, age, and obesity, among other aspects 159. Studies utilizing IAT have demonstrated that even well-intentioned staff can harbor biases that influence their decisions and interactions with patients 160.\nHealthcare Disparities Dashboard: The Healthcare Disparities Dashboard161 is a data-driven tool that aggregates patient data to highlight discrepancies in healthcare outcomes, utilization, and satisfaction across different demographic groups. It allows healthcare organizations to visualize and monitor disparities, thus aiding in targeted interventions 162. By presenting data in an accessible format, the Dashboard supports ongoing monitoring and the proactive management of healthcare equity 163.\nEquity Quality Improvement (EQI) Tool: Healthcare systems design the EQI tool 164 to integrate equity into their quality improvement frameworks. This tool helps identify areas where healthcare disparities exist and suggests practical interventions to mitigate these disparities. The EQI tool facilitates the inclusion of equity as a central quality dimension, ensuring that improvements in healthcare delivery uniformly benefit all patient groups\nCultural Competence Assessment (CCA): The CCA tool 166 helps healthcare institutions assess and enhance their effective-ness in providing culturally sensitive care. This tool evaluates healthcare providers' awareness of and sensitivity to the cultural needs of diverse patient populations. The CCA can lead to improved patient satisfaction by fostering better communication and understanding between healthcare providers and patients from diverse backgrounds 167."}, {"title": "Feedback from End-Users", "content": "Collecting and analyzing feedback from healthcare providers who use AI systems is essential for identifying and mitigating biases that may affect clinical decisions and patient outcomes. Healthcare professionals are at the forefront of witnessing the operational aspects of AI, and their firsthand insights can reveal how these systems function across diverse clinical scenarios5. Studies show that user feedback is invaluable for improving AI models, especially to ensure that these tools are equally effective and free from bias across different populations 168. By engaging healthcare providers in the evaluation process, developers can gather critical data on AI's practical implications and areas where it may unintentionally perpetuate disparities 135. Moreover, incorporating such feedback facilitates the development of more robust, equitable, and contextually appropriate AI solutions, ultimately leading to better patient care and outcomes4. As a result, systematic feedback mechanisms are not only beneficial but also necessary for the iterative refinement and ethical deployment of healthcare AI systems 137."}, {"title": "Mitigation Strategies", "content": "Mitigating biases in AI systems within healthcare is crucial for ensuring equitable treatment across all patient demographics. This section outlines key strategies to address and reduce biases, including the use of diverse and representative data and fairness-aware approaches, thereby enhancing the fairness and accuracy of AI models."}, {"title": "Diverse and Representative Data", "content": "Mitigating biases in AI systems within healthcare is crucial for ensuring equitable treatment across all patient demographics. A fundamental strategy involves using diverse and representative datasets in the training phase of these systems. Research indicates that AI models can only be as unbiased as the data they are trained on 169. Thus, inclusion of comprehensive data from a wide array of patient groups, particularly those historically underrepresented in medical research, is essential 13.\nThe significance of representative data extends beyond just including diverse groups; it also involves the depth and quality of the data collected from these groups. Data must capture a breadth of variables that influence health outcomes, such as socioeconomic factors, environmental conditions, and genetic differences4. This approach helps in creating models that are better tuned to the nuances of various patient needs and conditions 14.\nAdditionally, involving stakeholders from diverse backgrounds in the data collection and AI development process can en-hance the relevancy and sensitivity of the datasets 170. This inclusion helps in identifying and addressing potential blind spots in AI training datasets, which, if overlooked, could perpetuate biases and inequalities in healthcare delivery 171. Employing these strategies not only improves the fairness and effectiveness of AI tools but also builds trust in these technologies among all user groups, thereby fostering a more inclusive healthcare ecosystem 137."}, {"title": "Fairness-aware approaches", "content": "Incorporating various fairness-aware approaches is crucial for developing AI systems that are equitable and unbiased. These approaches can be categorized into three main strategies: pre-processing, in-processing, and post-processing. Each strategy targets different stages of the machine learning pipeline to address potential biases and ensure fair treatment across diverse demographic groups."}, {"title": "Pre-Processing:", "content": "In healthcare, pre-processing involves techniques to adjust the input data for AI models to ensure it accurately represents diverse patient demographics before model training begins. This process aims to eliminate any inherent biases that may skew AI predictions and outcomes, thus fostering equity in healthcare treatments and diagnostics 172. By refining the dataset upfront, pre-processing helps in building AI systems that perform fairly across all patient groups 13.\nRe-Sampling: Re-sampling is a common pre-processing method that manipulates data samples to create a more balanced dataset. This can be done through either over-sampling minority classes or under-sampling majority classes 173. An example of this in healthcare is the use of the Synthetic Minority Oversampling Technique (SMOTE)174 in medical datasets where certain conditions or outcomes are rare. Chawla applied SMOTE to a dataset of imbalanced classes to improve the predic-tion of minority-class outcomes in medical diagnostics, resulting in more reliable predictive models for underrepresented conditions. This technique helps to ensure that the AI does not become biased towards the more frequent classes.\nRe-Weighting: To reduce bias, instances in the training data are reweighted. We assign a weight to each instance in a dataset based on its representation, thereby increasing the influence of underrepresented groups in the model training process. This technique was demonstrated by Calmon in 175, who developed a data pre-processing method that modifies features and outcomes to improve fairness. In healthcare, this could mean adjusting weights so that data from minority ethnic groups has greater influence on the model, helping to prevent the AI from developing biases that might affect diagnosis or treatment recommendations 172."}, {"title": "In-Processing:", "content": "In-processing methods involve integrating fairness directly into the learning algorithm itself. This technique adjusts the algorithm during the training phase to minimize bias. Zemel in his study introduced a method where they developed a repre-sentation for data that is invariant to protected attributes like race or gender while maintaining the informative characteristics necessary for prediction 176. In healthcare", "Debiasing": "Adversarial debiasing involves"}]}