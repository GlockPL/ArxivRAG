{"title": "Do Quantum Neural Networks have Simplicity Bias?", "authors": ["Jessica Pointing"], "abstract": "One hypothesis for the success of deep neural networks (DNNs) is that they are highly expressive, which enables them to be applied to many problems, and they have a strong inductive bias towards solutions that are simple, known as simplicity bias, which allows them to generalise well on unseen data because most real-world data is structured (i.e. simple). In this work, we explore the inductive bias and expressivity of quantum neural networks (QNNs), which gives us a way to compare their performance to those of DNNs. Our results show that it is possible to have simplicity bias with certain QNNs, but we prove that this type of QNN limits the expressivity of the QNN. We also show that it is possible to have QNNs with high expressivity, but they either have no inductive bias or a poor inductive bias and result in a worse generalisation performance compared to DNNs. We demonstrate that an artificial (restricted) inductive bias can be produced by intentionally restricting the expressivity of a QNN. Our results suggest a bias-expressivity tradeoff. Our conclusion is that the QNNs we studied can not generally offer an advantage over DNNs, because these QNNs either have a poor inductive bias or poor expressivity compared to DNNs.", "sections": [{"title": "I. Introduction", "content": "Classical deep neural networks (DNNs) are successful in a wide range of tasks because they are firstly highly expressive, leading to their ability to express the functions they are trying to learn, and secondly they have a good inductive bias, meaning that their inherent bias towards certain types of functions before seeing any data aligns well with the types of functions they are trying to learn. These two properties are key for any learning agent.\nQuantum neural networks (QNNs) aim to combine the power of neural network models and quantum mechanics. The first idea integrating neural networks and quantum mechanics was in 1995 published by Kak [1], just one year after Shor published the famous Shor's algorithm for quantum prime factorisation, proving the potential of quantum computing [2]. Since then, there have been numerous proposals of QNNs [3].\nIn order for a QNN to be able to be a good learning agent, it should also have high expressivity and a good inductive bias. There are numerous papers looking at the expressivity of QNNs [4\u20137]. Kubler et al. studied the inductive bias of quantum kernels [8]. This research paper aims to provide further understanding on the inductive bias of QNNs and how it relates to expressivity. Through doing this, we provide insight on how the inductive bias of QNNs compares to the inherent inductive bias of DNNs, which has been shown to be a simplicity bias. This simplicity bias is beneficial for DNNs because real-world data tends to have descriptions that are simple rather than complex. Therefore, it has been suggested DNNs can generalise well on real-world data because the DNN's inductive bias towards simple functions matches the simple descriptions of real-world data [9]. Understanding the inductive bias of QNNs is crucial as it tells us whether QNNs are a good learning agent and it opens the pathway to seeing where QNNs have a disadvantage or advantage over classical neural networks. In particular, understanding whether QNNs have a simplicity bias can shed light on whether they will perform well on real-world data.\nSeveral works have explored the inductive bias of DNNs by studying their output when given Boolean data [10]. In this work, we explore the inductive bias of QNNs by studying their output when given Boolean data. We study how the inductive bias changes when using different encoding methods, which describes the way the input data should be encoded into the QNN. QNNs are closely related to kernel methods, which map the input data into a higher dimensional space [11]. Quantum kernels have been used in analysing quantum advantage in quantum machine learning [12] and the inductive bias of quantum kernels has been explored in [8]. We also use our methods to investigate the inductive bias of quantum kernels and offer comparisons to the corresponding QNNs."}, {"title": "A. Inductive bias and expressivity", "content": "The inductive bias is the set of assumptions that a learning algorithm makes to predict outputs for unseen inputs. Having some form of an inductive bias is essential to a learning algorithm, as without it, a network wouldn't be able to prefer one solution to choose over another. Learning algorithms that are highly expressive (i.e. can express many functions) need an inductive bias to generalise well.\nIn order to quantify the inductive bias in neural networks, one can look at the prior over functions $P(f)$, which is the probability that a neural network, with parameters randomly sampled from a distribution, will produce a particular function before it has been trained on any data.\nThe function $f$ refers to how the neural network maps the inputs to the outputs."}, {"title": "B. Simplicity bias", "content": "Several papers in the deep neural network literature have shown that deep neural networks have a bias towards low complexity (i.e. simple) functions [10, 13\u201317]. Valle-Perez et al. showed that a DNN's inductive bias towards simple functions is what enables it to generalise well [10]. They use Boolean functions and random neural networks (untrained neural networks with randomly sampled parameters) to demonstrate practically that DNNs have a bias towards simple Boolean functions. They argue that as real-world datasets are expected to be highly structured (therefore having a lower-complexity), DNNs generalise well on these problems, because of its simplicity bias.\nReal-world data tends to have descriptions that are simple rather than complex [18], known by the principle of Occam's razor. As DNNs have an inductive bias towards simple functions, they can generalise well on real-world data as the simple functions a DNN finds with higher probabilities are closer to the simple descriptions underlying real-world data compared to complex functions."}, {"title": "C. Quantum neural networks", "content": "We introduce QNNs and their different components, which we use in this work. In a QNN, there are three distinct components [11]:\n1.  Encoder circuit: this circuit encodes the data into the QNN.\n2.  Variational circuit: this circuit is parametrised; the parameters are updated during the learning process of the QNN. The variational circuit starts as an ansatz, which is defined as an educated guess of the solution to a problem and is used as a starting point. In the context of QNNs, the ansatz is the parametrised circuit that is used as a starting point or trial state which is iteratively updated during the optimisation process.\n3.  Measurement operators: information from the QNN is extracted via measurements. From these measurements, gradients and a loss function can be calculated on a classical computer and the parameters are updated via some classical optimiser, such as Adam [19]."}, {"title": "D. Encoding methods", "content": "There are multiple ways to encode data into a quantum circuit. We introduce common encoding methods that we analyse in this work:\n\u03b1. Basis encoding: This maps the input data (in the form of a binary string) into the computational basis of a quantum state. If our vector is in the binary format, then basis encoding makes the following transformation: $x = b_{n-1}b_{n-2}\u2026b_0 \\rightarrow |x\\rangle = |b_{n-1}b_{n-2}\u2026b_0\\rangle$. For example, basis encoding transforms the input data $x = (1,0)$ into $|10\\rangle$. This requires $O(n)$ qubits. Further details are in Appendix D3c.\n\u03b2. Amplitude encoding: This encodes the data into the amplitudes of the quantum state, so that our quantum state becomes $|\\psi \\rangle = \\sum_{i=0}^{n-1} x_i|i\\rangle$ where our input data is $x = x_{n-1}x_{n-2}\u2026x_0$ and $x_i$ is the $i$th element of $\\vec{x}$ and $|i\\rangle$ is the $i$th computational basis state. For example, if our vector is $\\vec{x} = (1,0,\\frac{1}{\\sqrt{2}})$ then the norm is $\\sqrt{1^2 + 0^2 + (\\frac{1}{\\sqrt{2}})^2} = \\sqrt{\\frac{3}{2}}$, so our encoded quantum state becomes $\\frac{\\sqrt{2}}{\\sqrt{3}}|0\\rangle + 0|1\\rangle + \\frac{1}{\\sqrt{3}}|2\\rangle$. Extra computational basis states can be encoded as zero. This requires $O(log n)$ qubits. Further details are in Appendix D3f.\n\u03b3. ZZ Feature Map: The ZZ Feature Map is based on the paper titled Supervised learning with quantum-enhanced feature spaces [20] and encodes the input data into the angles of the unitary matrices in a particular way. This encoding method is designed to be biased towards the parity function. They define the feature map as $U_{\\Phi}(x) = U_{\\Phi(x)}H^{\\otimes n}U_{\\Phi(x)}H^{\\otimes n}$ where $U_{\\Phi(x)} = exp(i\\sum_{c \\subseteq [n]} \\Phi_c(x) \\prod_{i \\in c} Z_i)$, where $H$ is the Hadamard gate and is equivalent to the matrix $\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 1 \\\\ 1 & -1 \\end{pmatrix}$, $Z$ is the Pauli-Z gate and is equivalent to the matrix $\\begin{pmatrix} 1 & 0 \\\\ 0 & -1 \\end{pmatrix}$, $S$ is the set of data, $n$ is the number of qubits, $i(x) = \\sum_i x_i$, $\\Phi_{{i,j}}(x) = (\\pi - x_0) (\\pi - x_1)$. This feature map can be seen more clearly in its circuit diagram for two qubits in Figure 3. Further details are in Appendix D3d.\n\u03b4. Random Relu Transform: although the other encoding methods are common, we designed this encoding method to act as a random non-unitary transformation to the data. This is equivalent to the data being transformed through a single hidden layer of a classical neural network. For this encoding method, we encode the data using basis encoding, apply a random unitary matrix, and then apply the relu function, which introduces nonlinearity, to the resulting statevector and normalise it. The transformation is as follows: $|\\psi\\rangle = \\frac{1}{N} \\sum_{i=1}^n \\sigma(Ux)_i |i\\rangle$ where our input data is $X = x_{n-1}x_{n-2}\u2026x_0$ and $x_i$ is the $i$th element of $\\vec{x}$ and $|i\\rangle$ is the $i$th computational basis state, $\\sigma(Ux)_i$ is the $i$th output of a single hidden layer neural network, $\\sigma$ is the ReLU function, and $U$ is the random unitary matrix. Further details are in Appendix D3e."}, {"title": "II. Results", "content": "There are different methods for encoding data into a QNN and our work shows that each method changes the inductive bias of the QNN. Our work sheds light on why some encoding methods perform better than others as we show the effect of the encoding method on the inductive bias. In particular, we look at four major types of encoding methods: Basis encoding, ZZ Feature Map, Amplitude Encoding, and Random Relu encoding.\nTo categorise the inductive bias produced by the encoding methods, we choose two ways to quantify the types of functions the QNN produces: entropy and Lempel-Ziv (LZ) complexity. The functions we generate from the QNNs are binary strings. The LZ complexity counts the number of distinct substrings that appear in the string. In effect, this measures how well the string can be compressed by identifying and encoding repeated patterns or substrings. The entropy is $min{p, n -p}$ where p is the number of 0s in the string and n is the length of the string. Measuring the LZ complexity tells us whether a neural network has a bias towards low-complexity functions, known as simplicity bias. Measuring the entropy tells us whether a neural network has a bias towards low-entropy functions, which is a trivial bias because such a neural network is just predicting the output of the neural network (which is either 0 or 1) with the highest frequency.\nMany low-complexity functions are also low-entropy, so if we were just to measure the LZ complexity of the functions, it would seem that many of the encoding methods have a bias towards low-complexity functions, but by measuring entropy as well, we can distinguish the encoding methods that have a bias towards low-complexity and those that have a bias towards low-entropy."}, {"title": "A. Summary of the bias and expressivity of different encoding methods", "content": "In Table I, we summarise the findings of our results for the inductive bias and expressivity of QNNs with different encoding methods.\nOur results show that basis encoding has no inductive bias. This result is also shown by various papers in the literature [11, 21]. We also have come up with a proof-by-induction that arrives at the same conclusion. We prove that any arbitrary QNN with basis encoding has no inductive bias. Our proof holds for any QNN and therefore does not depend on the ansatz one is using for the variational circuit. We prove this by induction by decomposing a QNN into layers that depend on previous layers. Details of this proof are in Appendix A 2.\nOur experimental results also reveal that other encoding methods can induce various types of inductive bias into the QNN. The ZZ feature map and Random relu transform have a trivial bias, that is a bias towards low-entropy functions. These encoding methods perform poorly (i.e. have high generalisation error) on functions with low complexity but high entropy, showing that the QNN with these encoding methods have a low-entropy bias but not a low-complexity bias. Low complexity, high entropy functions, such as '01' repeated (i.e. 0101 ... 1010) are representative of patterns in classical data and therefore this shows a disadvantage on these types of classical boolean data compared to the DNN, which has a bias towards low-complexity functions and can therefore generalise well on simple functions. We show, however, that the QNN with the ZZ feature map has a strong inductive bias towards the parity function, even though the parity function has high complexity and high entropy.\nAmplitude encoding has the closest bias to that of a DNN, a simplicity bias. Using this encoding method, however, limits the expressivity of the QNN - in particular, the parity function can not be expressed for the n = 3 system and more functions can not be expressed for larger systems. Therefore, there seems to be a bias-expressivity tradeoff. An encoding method with a good inductive bias has lower expressivity, and encoding methods with poor inductive bias have higher expressivity."}, {"title": "B. Summary of results", "content": "1.  Amplitude encoding has a simplicity bias but limits the expressivity of the QNN, which we prove can not express the parity function (see Section II C for the inductive bias results and Appendix A 1 for the proof).\n2.  ZZ feature map has a low-entropy bias, which does not match the inherent inductive bias of a DNN (see Section II C).\n3.  Random relu transform also has a low-entropy bias (see Section II C).\n4.  QNNs with basis encoding produce no inductive bias on the Boolean system when fully expressive, which we prove by induction (see Appendix A 2) and show numerically (see Section II C).\n5.  QNNs can exhibit an 'artificial' inductive bias on the Boolean system when not fully expressive and using basis encoding (see Section II C).\n6.  Inducing a certain inductive bias into a QNN can negatively affect its ability to train and generalise (see Appendix B 2).\n7.  A good generalisation performance could be obtained for a QNN by constructing an encoding method that induces an inductive bias towards the function one is learning - this can be seen for the ZZ feature map which has an inductive bias towards the parity function and low generalisation error (see Section IID and Appendix C3)"}, {"title": "C. Inductive bias of QNNs", "content": "We study the inductive bias of QNNs by studying how the QNN interacts with Boolean data. Background information on the Boolean system can be read in Appendix D1 and on the QNN can be read in Appendix D 2.\nWe are interested in how the probability of generating a function from an untrained fully-expressive QNN changes as the complexity of that function changes. Additional details about the fully expressive QNN are in Appendix B 1. In order to generate such data, we encode the Boolean dataset (i.e. the input), via an encoding method, into a fully expressive QNN with randomly sampled parameters and measure the QNN's output. The mapping from the input to output is the Boolean function f. We generate many Boolean functions (i.e. the samples) from the QNN by changing the randomly sampled parameters. Then, we can calculate the probability of a particular Boolean function occurring in the samples, which we denote as $P(f)$ in Figure 4. We measure the complexity of the Boolean function, using the Lempel-Ziv (LZ) complexity measure and plot the probability of a boolean function versus its LZ complexity. Further details about this method can be read in the Methods Section III \u0391.\nFigure 4 shows $P(f)$ vs K where K is the Lempel-Ziv complexity of the boolean function, for different encoding methods. Figure 4e is the plot for a classical DNN for comparison. The DNN has a bias towards low-complexity Boolean functions, which is the 'simplicity bias' as proposed in [10].\nWe can see in Figure 4a that the probability of generating a particular function does not change with the complexity function, implying that such a QNN is generating boolean functions randomly. This means that encoding the data using basis encoding produces no bias in the system. As a result, using basis encoding results in a poor learning agent, which corresponds with our proof for these numerical results in Appendix A 2.\nFor the other encoding methods, functions with a lower LZ complexity have a higher probability of occurring, implying a bias towards low-complexity functions. As mentioned earlier in this text, however, many low-complexity functions are also low-entropy functions. Therefore, additional experiments are needed, as shown in Section II D and Appendix C1b, to reveal that some of these encoding methods actually have a bias towards low-entropy functions.\nFigure 4f shows the inductive bias in a non-fully expressive QNN with basis encoding. This QNN was proposed in [22], which is described in further detail in Appendix Blc. We can see that in contrast to the fully expressive quantum circuit with basis encoding, we seem to see a bias towards simple functions. We prove that fully expressive QNNs with basis encoding have no inductive bias in Appendix A 2. Therefore, the reason we see a bias in Figure 4f is because the QNN can not express all functions. As the QNN is restricted, it can only produce certain functions which leads to this 'artifical' inductive bias. The problem, however, with inducing a bias this way is that the QNN will not be able to learn effectively on functions it can not express, which reduces the generalisation performance of the QNN."}, {"title": "D. Generalisation error of QNNs", "content": "The generalisation error informs us of how good a learning agent the neural network is, as it is a measure of the trained neural network's error on unseen data. A low generalisation error means that the neural network can predict unseen data well. Therefore, looking at the QNN's generalisation error on unseen random boolean functions informs us of how good a learning agent the QNN is and how it compares to a classical DNN. Looking at the generalisation error can also illuminate the inductive bias of the QNNs with different encoding methods.\nTo study this, we train the QNN with an encoding method to learn a particular boolean function, which is the target function. To bypass barren plateau issues [23] with traditional training methods, which make it difficult to obtain zero error on the training set, we instead train the QNNs by finding a set of parameters that obtain zero error on the training set. To do this, we randomly sample a set of parameters and use them in the QNN and then run the QNN with the training inputs and obtain the predicted $y_{predict}$ label. We calculate the training error and repeat this process until we obtain a set of parameters where the training error is zero. Once we have obtained that set of parameters (which ensures that that the QNN is trained to zero training error) we use these parameters (i.e. the trained QNN) to calculate the error (i.e. the generalisation error) on the test set. More details about the training method can be read in Section B 2.\nWe find the generalisation error for target functions with different complexities. We have constructed certain target functions so that they have the properties we want to study, in particular functions with low-entropy and low-complexity, low-entropy and high-complexity, and high-complexity, high-entropy. We also generate random target functions. More details about the target functions and further results on the generalisation error can be read in Appendix C3."}, {"title": "E. Expressivity of QNNS", "content": "A stronger inductive bias seems to imply a weaker expressivity and a weaker inductive bias seems to imply a stronger expressivity for the encoding methods we have studied. We have shown that amplitude encoding has a simplicity bias, similar to the bias of the DNN. Amplitude encoding, however, limits the expressivity of the QNN. This can be a problem because we would need to know something about our function to know whether it could be expressed by a QNN with amplitude encoding."}, {"title": "III. Methods", "content": "In order to find the inductive bias in a QNN, we implement these steps:\n(a) Generate Boolean data: We generate all possible Boolean data given n data qubits. There are $2^n$ datapoints. For example, for n = 2, our input data x is $x_0 = (0,0), x_1 = (0,1), x_2 = (1, 0), x_3 = (1, 1)$.\n(b) Create a random set of parameters: We create a random set of parameters by sampling from the uniform distribution. These set of parameters are used in the variational circuit of the QNN.\n(c) Encode input data into the QNN: We implement an encoder circuit using one of the encoding methods in Section ID to encode the data into the QNN.\n(d) Construct QNN: We construct a QNN that consists of the encoder circuit in Step (c) and the variational circuit mentioned in Appendix B 1. The QNN has n data qubits and 1 readout qubit $q_r$ which is the output of the QNN.\n(e) Calculate the expectation value of the measurement operator: We calculate the expectation value $\\langle \\psi | \\sigma_z | \\psi \\rangle$ where $\\sigma_z = I \\otimes \u2026 \\otimes Z_{q_r} \\otimes I$ where $Z$ is applied only to the readout qubit $q_r$ and $I$ is applied to all other qubits. $|\\psi\\rangle = U(\\theta;)|x_i\\rangle$ where $U(\\theta;)$ is the variational circuit with the parameters $\\theta$ drawn from the uniform distribution for parameter iteration $j$ and $|x_i\\rangle$ is the output state of the encoder circuit for the $i$th data.\n(f) Threshold the expectation value: Given that we are working with the Boolean system, we threshold the expectation value. We will obtain an expectation value $\\langle \\sigma_z \\rangle$ in the range [-1,1]. If $\\langle \\sigma_z \\rangle < 0$, then the classification of the QNN is $y = 1$. If $\\langle \\sigma_z \\rangle \\ge 0, y = 0$.\n(g) Construct the Boolean function: We can now construct the Boolean function by repeating Steps (c) -(f) with all of the input data. For each input data, we map it to its output of the QNN to obtain the Boolean function. For example, for n = 2, if $x_0 = (0,0)$ produces $y_0 = 0, x_1 = (0,1)$ produces $y_1 = 1, x_2 = (1,0)$ produces $y_2 = 1$, and $x_3 = (1, 1)$ produces $y_3 = 0$, then our boolean function = 0110.\n(h) Calculate the probabilities of obtaining certain Boolean functions: We now repeat steps (b) - (h) for different random sets of parameters. If we use m sets of parameters, we produce m datapoints for the boolean functions and we can calculate the probability of a particular boolean function occurring in the m samples."}, {"title": "A. Finding inductive bias in Quantum Kernels", "content": "In order to find the inductive bias in a Quantum Kernel, we implement these steps:\n(a) Construct the Kernel Matrix: The kernel matrix is $K_{ij} = |\\langle \\Phi(x_j) | \\Phi(x_i)\\rangle|^2$. $\\Phi(i)$ is the statevector from the encoder circuit with input data $x_i$. Therefore, we can construct the Kernel matrix by calculating each entry for all pairs of input data.\n(b) Sample from the Kernel Matrix: The multivariate normal distribution formula is shown in Equation 1\n$f_X(x_1,\u2026,x_k) = \\frac{exp(-(x \u2013 \\mu)K^{-1}(x \u2013 \\mu))}{\\sqrt{(2\\pi)^k |K|}} $(1)\nwhere x is the input data, K is the kernel matrix, and the mean $\u03bc = 0$.\n(c) Threshold the sample We threshold $f_X$ so that if $f_{X_i} < 0$, where i is the $i^{th}$ bit in the sample, then the $i^{th}$ bit of the thresholded sample y is $y_i = 1$. If $f_{X_i} \u2265 0$, then $y_i = 0$.\n(d) Calculate the probabilities of obtaining certain Boolean functions We sample m times from the kernel, which allows us to calculate the probability of a boolean function from the m samples, similarly to Step (h) in Section III A."}, {"title": "C. Training QNNs", "content": "We train the QNN to learn a particular boolean function, which is the target function. In order to construct the training and test set, we randomly select half of the indices of the bits in the target function for the training set and the other half for the test set. The training inputs then consist of the Boolean input data at the indices of the bits of the training set. The test inputs consist of the Boolean input data at the indices of the bits of the test set. The training labels are the values of the bits at the indices of the training set in the target function and the test labels are the values of the bits at the indices of the test set in the target function. Further details and an example are in Appendix B 2."}, {"title": "IV. Discussion", "content": "The success of deep neural networks (DNNs) has prompted research into what makes DNNs good learning agents. Recently, it has been argued that their natural bias towards simple functions enables them to generalise well on real-world data, which also has simple descriptions [10]. The aim of this paper was to investigate the inductive bias of QNNs and answer whether they also have simplicity bias, to give us a clue into their performance on real-world data and how they compare to DNNS.\nWe have demonstrated that by randomly sampling parameters and seeing which boolean functions are generated by a QNN, we can see which functions are more likely to be produced and therefore which functions the QNN has a biased towards. Unlike DNNs, which naturally have simplicity bias, the inductive bias in QNNs is produced via the encoding method of the QNN.\nOur experimental results, along with a proof-by-induction, show that a fully-expressive QNN with basis encoding produces no inductive bias, which makes it essentially a random learner. An inductive bias can be induced into the circuit by using a different encoding method. Our results have shown that a simplicity bias is possible by using amplitude encoding, but such an encoding method limits the expressivity of the QNN, which is a disadvantage compared to DNNs which are still highly expressive with their natural simplicity bias. If one is using amplitude encoding, then one would need to understand the dataset to understand whether it could be expressed. This requires some manual intervention and is a limitation compared to DNNs that can assumed to express the functions in one's dataset.\nOur results also show that it is possible to have encoding methods that do not limit the expressivity of the QNN, such as the ZZ feature map and Random relu transform, but then the inductive bias is poor, as it has an inductive bias towards low-entropy functions. This inductive bias is poor because low complexity, high entropy functions are representative of patterns in classical data and therefore this shows a disadvantage on these types of classical boolean data compared to the DNN. These results imply a bias-expressivity tradeoff.\nFurthermore, an inductive bias can also be induced into the circuit by restricting the expressivity of the circuit - however, this is an 'artificial' inductive bias and can negatively impact the performance of the QNN if a solution function can not be expressed by the QNN. In addition, we show that if an encoding method has a strong bias towards a particular function (as is the case with the ZZ feature map on the parity function), then it can have strong generalisation performance on that function. This, however, requires manual intervention and is somewhat equivalent to 'hard-coding' the bias into the QNN. DNNs, however, generally don't need to be 'hard-coded' and can be used as they are. Moreover, constructing such encoding methods with a bias towards a particular function leads to a weak bias towards other functions which the DNN has a strong bias towards, even simple functions such as the '01' repeated boolean function.\nOverall, we show that there is a fundamental difference between QNNs and DNNs: that DNNs have an inherent inductive bias towards simple functions, whereas the inductive bias of QNNs depends on the encoding method and whilst a simplicity bias can be obtained with amplitude encoding, the expressivity of the QNN becomes limited, implying a bias-expressivity tradeoff. Further work could explore this bias-expressivity tradeoff in the context of QNNs. With the limitations of inductive bias and expressivity in the current framework of QNNs, further work could explore alternative frameworks of QNNs."}]}