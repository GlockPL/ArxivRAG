{"title": "Do Quantum Neural Networks have Simplicity Bias?", "authors": ["Jessica Pointing"], "abstract": "One hypothesis for the success of deep neural networks (DNNs) is that they are highly expressive, which enables them to be applied to many problems, and they have a strong inductive bias towards solutions that are simple, known as simplicity bias, which allows them to generalise well on unseen data because most real-world data is structured (i.e. simple). In this work, we explore the inductive bias and expressivity of quantum neural networks (QNNs), which gives us a way to compare their performance to those of DNNs. Our results show that it is possible to have simplicity bias with certain QNNs, but we prove that this type of QNN limits the expressivity of the QNN. We also show that it is possible to have QNNs with high expressivity, but they either have no inductive bias or a poor inductive bias and result in a worse generalisation performance compared to DNNs. We demonstrate that an artificial (restricted) inductive bias can be produced by intentionally restricting the expressivity of a QNN. Our results suggest a bias-expressivity tradeoff. Our conclusion is that the QNNs we studied can not generally offer an advantage over DNNs, because these QNNs either have a poor inductive bias or poor expressivity compared to DNNs.", "sections": [{"title": "I. Introduction", "content": "Classical deep neural networks (DNNs) are successful in a wide range of tasks because they are firstly highly expressive, leading to their ability to express the functions they are trying to learn, and secondly they have a good inductive bias, meaning that their inherent bias towards certain types of functions before seeing any data aligns well with the types of functions they are trying to learn. These two properties are key for any learning agent.\nQuantum neural networks (QNNs) aim to combine the power of neural network models and quantum mechanics. The first idea integrating neural networks and quantum mechanics was in 1995 published by Kak [1], just one year after Shor published the famous Shor's algorithm for quantum prime factorisation, proving the potential of quantum computing [2]. Since then, there have been numerous proposals of QNNs [3].\nIn order for a QNN to be able to be a good learning agent, it should also have high expressivity and a good inductive bias. There are numerous papers looking at the expressivity of QNNs [4-7]. Kubler et al. studied the inductive bias of quantum kernels [8]. This research paper aims to provide further understanding on the inductive bias of QNNs and how it relates to expressivity. Through doing this, we provide insight on how the inductive bias of QNNs compares to the inherent inductive bias of DNNs, which has been shown to be a simplicity bias. This simplicity bias is beneficial for DNNs because real-world data tends to have descriptions that are simple rather than complex. Therefore, it has been suggested DNNs can generalise well on real-world data because the DNN's inductive bias towards simple functions matches the simple descriptions of real-world data [9]. Understanding the inductive bias of QNNs is crucial as it tells us whether QNNs are a good learning agent and it opens the pathway to seeing where QNNs have a disadvantage or advantage over classical neural networks. In particular, understanding whether QNNs have a simplicity bias can shed light on whether they will perform well on real-world data.\nSeveral works have explored the inductive bias of DNNs by studying their output when given Boolean data [10]. In this work, we explore the inductive bias of QNNs by studying their output when given Boolean data. We study how the inductive bias changes when using different encoding methods, which describes the way the input data should be encoded into the QNN. QNNs are closely related to kernel methods, which map the input data into a higher dimensional space [11]. Quantum kernels have been used in analysing quantum advantage in quantum machine learning [12] and the inductive bias of quantum kernels has been explored in [8]. We also use our methods to investigate the inductive bias of quantum kernels and offer comparisons to the corresponding QNNs."}, {"title": "A. Inductive bias and expressivity", "content": "The inductive bias is the set of assumptions that a learning algorithm makes to predict outputs for unseen inputs. Having some form of an inductive bias is essential to a learning algorithm, as without it, a network wouldn't be able to prefer one solution to choose over another. Learning algorithms that are highly expressive (i.e. can express many functions) need an inductive bias to generalise well.\nIn order to quantify the inductive bias in neural networks, one can look at the prior over functions $P(f)$, which is the probability that a neural network, with parameters randomly sampled from a distribution, will produce a particular function before it has been trained on any data.\nThe function $f$ refers to how the neural network maps the inputs to the outputs."}, {"title": "B. Simplicity bias", "content": "Several papers in the deep neural network literature have shown that deep neural networks have a bias towards low complexity (i.e. simple) functions [10, 13-17]. Vall\u00e9-Perez et al. showed that a DNN's inductive bias towards simple functions is what enables it to generalise well [10]. They use Boolean functions and random neural networks (untrained neural networks with randomly sampled parameters) to demonstrate practically that DNNs have a bias towards simple Boolean functions. They argue that as real-world datasets are expected to be highly structured (therefore having a lower-complexity), DNNs generalise well on these problems, because of its simplicity bias.\nReal-world data tends to have descriptions that are simple rather than complex [18], known by the principle of Occam's razor. As DNNs have an inductive bias towards simple functions, they can generalise well on real-world data as the simple functions a DNN finds with higher probabilities are closer to the simple descriptions underlying real-world data compared to complex functions."}, {"title": "C. Quantum neural networks", "content": "We introduce QNNs and their different components, which we use in this work. In a QNN, there are three distinct components [11]:\n1.  Encoder circuit: this circuit encodes the data into the QNN.\n2.  Variational circuit: this circuit is parametrised; the parameters are updated during the learning process of the QNN. The variational circuit starts as an ansatz, which is defined as an educated guess of the solution to a problem and is used as a starting point. In the context of QNNs, the ansatz is the parametrised circuit that is used as a starting point or trial state which is iteratively updated during the optimisation process.\n3.  Measurement operators: information from the QNN is extracted via measurements. From these measurements, gradients and a loss function can be calculated on a classical computer and the parameters are updated via some classical optimiser, such as Adam [19]."}, {"title": "D. Encoding methods", "content": "There are multiple ways to encode data into a quantum circuit. We introduce common encoding methods that we analyse in this work:\n\u03b1. Basis encoding: This maps the input data (in the form of a binary string) into the computational basis of a quantum state. If our vector is in the binary format, then basis encoding makes the following transformation: $x = b_{n-1}b_{n-2}...b_0 \\rightarrow |x\\rangle = |b_{n-1}b_{n-2}...b_0\\rangle$. For example, basis encoding transforms the input data $x = (1,0)$ into $|10\\rangle$. This requires $O(n)$ qubits. Further details are in Appendix D3c.\n\u03b2. Amplitude encoding: This encodes the data into the amplitudes of the quantum state, so that our quantum state becomes $|\\psi\\rangle = \\frac{1}{\\sqrt{N}}\\sum_{i=0}^{n-1} x_i|i\\rangle$ where our input data is $x = x_{n-1}x_{n-2}...x_0$ and $x_i$ is the $i$th element of $\\mathbb{Z}$ and $|i\\rangle$ is the $i$th computational basis state. For example, if our vector is $x = (1,0,\\frac{1}{\\sqrt{2}})$ then the norm is $\\sqrt{1^2 + 0^2 + (\\frac{1}{\\sqrt{2}})^2} = \\sqrt{\\frac{3}{2}}$, so our encoded quantum state becomes $\\frac{\\sqrt{2}}{\\sqrt{3}}|00\\rangle + 0|01\\rangle + \\frac{1}{\\sqrt{3}}|10\\rangle$. Extra computational basis states can be encoded as zero. This requires $O(log n)$ qubits. Further details are in Appendix D3f.\n\u03b3. ZZ Feature Map: The ZZ Feature Map is based on the paper titled Supervised learning with quantum-enhanced feature spaces [20] and encodes the input data into the angles of the unitary matrices in a particular way. This encoding method is designed to be biased towards the parity function. They define the feature map as $U_{\\Phi}(x) = U_{\\Phi(x)}H^{\\otimes n}U_{\\Phi(x)}^{\\dagger} H^{\\otimes n}$ where $U_{\\Phi(x)} = exp \\big(i \\sum_{S \\subseteq [n]} \\phi_S(x) \\prod_{i \\in S} Z_i \\big)$, where $H$ is the Hadamard gate and is equivalent to the matrix $\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1 & 1\\\\ 1 & -1 \\end{pmatrix}$, $Z$ is the Pauli-Z gate and is equivalent to the matrix $\\begin{pmatrix} 1 & 0\\\\ 0 & -1 \\end{pmatrix}$, $S$ is the set of data, $n$ is the number of qubits, $\\phi_{i}(x) = x_i$, $\\Phi{i,j}(x) = (\\pi - x_0) (\\pi - x_1)$. This feature map can be seen more clearly in its circuit diagram for two qubits in Figure 3. Further details are in Appendix D3d.\n\u03b4. Random Relu Transform: although the other encoding methods are common, we designed this encoding method to act as a random non-unitary transformation to the data. This is equivalent to the data being transformed through a single hidden layer of a classical neural network. For this encoding method, we encode the data using basis encoding, apply a random unitary matrix, and then apply the relu function, which introduces nonlinearity, to the resulting statevector and normalise it. The transformation is as follows: $|\\psi\\rangle = \\frac{1}{N} \\sum_{i=1}^{n-1} \\mathbb{O}(Ux)_i|i\\rangle$ where our input data is $x = x_{n-1}x_{n-2}...x_0$ and $x_i$ is the $i$th element of $\\mathbb{Z}$ and $|i\\rangle$ is the $i$th computational basis state, $\\mathbb{O}(Ux)_i$ is the $i$th output of a single hidden layer neural network, $\\mathbb{O}$ is the ReLU function, and $U$ is the random unitary matrix. Further details are in Appendix D3e."}, {"title": "II. Results", "content": "There are different methods for encoding data into a QNN and our work shows that each method changes the inductive bias of the QNN. Our work sheds light on why some encoding methods perform better than others as we show the effect of the encoding method on the inductive bias. In particular, we look at four major types of encoding methods: Basis encoding, ZZ Feature Map, Amplitude Encoding, and Random Relu encoding.\nTo categorise the inductive bias produced by the encoding methods, we choose two ways to quantify the types of functions the QNN produces: entropy and Lempel-Ziv (LZ) complexity. The functions we generate from the QNNs are binary strings. The LZ complexity counts the number of distinct substrings that appear in the string. In effect, this measures how well the string can be compressed by identifying and encoding repeated patterns or substrings. The entropy is $min\\{p, n-p\\}$ where $p$ is the number of 0s in the string and $n$ is the length of the string. Measuring the LZ complexity tells us whether a neural network has a bias towards low-complexity functions, known as simplicity bias. Measuring the entropy tells us whether a neural network has a bias towards low-entropy functions, which is a trivial bias because such a neural network is just predicting the output of the neural network (which is either 0 or 1) with the highest frequency.\nMany low-complexity functions are also low-entropy, so if we were just to measure the LZ complexity of the functions, it would seem that many of the encoding methods have a bias towards low-complexity functions, but by measuring entropy as well, we can distinguish the encoding methods that have a bias towards low-complexity and those that have a bias towards low-entropy."}, {"title": "A. Summary of the bias and expressivity of different encoding methods", "content": "In Table I, we summarise the findings of our results for the inductive bias and expressivity of QNNs with different encoding methods.\nOur results show that basis encoding has no inductive bias. This result is also shown by various papers in the literature [11, 21]. We also have come up with a proof-by-induction that arrives at the same conclusion. We prove that any arbitrary QNN with basis encoding has no inductive bias. Our proof holds for any QNN and therefore does not depend on the ansatz one is using for the variational circuit. We prove this by induction by decomposing a QNN into layers that depend on previous layers. Details of this proof are in Appendix A2.\nOur experimental results also reveal that other encoding methods can induce various types of inductive bias into the QNN. The ZZ feature map and Random relu transform have a trivial bias, that is a bias towards low-entropy functions. These encoding methods perform poorly (i.e. have high generalisation error) on functions with low complexity but high entropy, showing that the QNN with these encoding methods have a low-entropy bias but not a low-complexity bias. Low complexity, high entropy functions, such as '01' repeated (i.e. 0101 ... 1010) are representative of patterns in classical data and therefore this shows a disadvantage on these types of classical boolean data compared to the DNN, which has a bias towards low-complexity functions and can therefore generalise well on simple functions. We show, however, that the QNN with the ZZ feature map has a strong inductive bias towards the parity function, even though the parity function has high complexity and high entropy.\nAmplitude encoding has the closest bias to that of a DNN, a simplicity bias. Using this encoding method, however, limits the expressivity of the QNN in particular, the parity function can not be expressed for the $n = 3$ system and more functions can not be expressed for larger systems. Therefore, there seems to be a bias-expressivity tradeoff. An encoding method with a good inductive bias has lower expressivity, and encoding methods with poor inductive bias have higher expressivity."}, {"title": "B. Summary of results", "content": "1.  Amplitude encoding has a simplicity bias but limits the expressivity of the QNN, which we prove can not express the parity function (see Section II C for the inductive bias results and Appendix A1 for the proof).\n2.  ZZ feature map has a low-entropy bias, which does not match the inherent inductive bias of a DNN (see Section II C).\n3.  Random relu transform also has a low-entropy bias (see Section II C).\n4.  QNNs with basis encoding produce no inductive bias on the Boolean system when fully expressive, which we prove by induction (see Appendix A2) and show numerically (see Section II C).\n5.  QNNs can exhibit an 'artificial' inductive bias on the Boolean system when not fully expressive and using basis encoding (see Section II C).\n6.  Inducing a certain inductive bias into a QNN can negatively affect its ability to train and generalise (see Appendix B2).\n7.  A good generalisation performance could be obtained for a QNN by constructing an encoding method that induces an inductive bias towards the function one is learning - this can be seen for the ZZ feature map which has an inductive bias towards the parity function and low generalisation error (see Section IID and Appendix C3)"}, {"title": "C. Inductive bias of QNNs", "content": "We study the inductive bias of QNNs by studying how the QNN interacts with Boolean data. Background information on the Boolean system can be read in Appendix D1 and on the QNN can be read in Appendix D2.\nWe are interested in how the probability of generating a function from an untrained fully-expressive QNN changes as the complexity of that function changes. Additional details about the fully expressive QNN are in Appendix B1. In order to generate such data, we encode the Boolean dataset (i.e. the input), via an encoding method, into a fully expressive QNN with randomly sampled parameters and measure the QNN's output. The mapping from the input to output is the Boolean function $f$. We generate many Boolean functions (i.e. the samples) from the QNN by changing the randomly sampled parameters. Then, we can calculate the probability of a particular Boolean function occurring in the samples, which we denote as $P(f)$ in Figure 4. We measure the complexity of the Boolean function, using the Lempel-Ziv (LZ) complexity measure and plot the probability of a boolean function versus its LZ complexity. Further details about this method can be read in the Methods Section III \u0391.\nFigure 4 shows $P(f)$ vs $K$ where $K$ is the Lempel-Ziv complexity of the boolean function, for different encoding methods. Figure 4e is the plot for a classical DNN for comparison. The DNN has a bias towards low-complexity Boolean functions, which is the 'simplicity bias' as proposed in [10].\nWe can see in Figure 4a that the probability of generating a particular function does not change with the complexity function, implying that such a QNN is generating boolean functions randomly. This means that encoding the data using basis encoding produces no bias in the system. As a result, using basis encoding results in a poor learning agent, which corresponds with our proof for these numerical results in Appendix A2.\nFor the other encoding methods, functions with a lower LZ complexity have a higher probability of occurring, implying a bias towards low-complexity functions. As mentioned earlier in this text, however, many low-complexity functions are also low-entropy functions. Therefore, additional experiments are needed, as shown in Section II D and Appendix C1b, to reveal that some of these encoding methods actually have a bias towards low-entropy functions.\nFigure 4f shows the inductive bias in a non-fully expressive QNN with basis encoding. This QNN was proposed in [22], which is described in further detail in Appendix B1c. We can see that in contrast to the fully expressive quantum circuit with basis encoding, we seem to see a bias towards simple functions. We prove that fully expressive QNNs with basis encoding have no inductive bias in Appendix A2. Therefore, the reason we see a bias in Figure 4f is because the QNN can not express all functions. As the QNN is restricted, it can only produce certain functions which leads to this 'artifical' inductive bias. The problem, however, with inducing a bias this way is that the QNN will not be able to learn effectively on functions it can not express, which reduces the generalisation performance of the QNN."}, {"title": "D. Generalisation error of QNNs", "content": "The generalisation error informs us of how good a learning agent the neural network is, as it is a measure of the trained neural network's error on unseen data. A low generalisation error means that the neural network can predict unseen data well. Therefore, looking at the QNN's generalisation error on unseen random boolean functions informs us of how good a learning agent the QNN is and how it compares to a classical DNN. Looking at the generalisation error can also illuminate the inductive bias of the QNNs with different encoding methods.\nTo study this, we train the QNN with an encoding method to learn a particular boolean function, which is the target function. To bypass barren plateau issues [23] with traditional training methods, which make it difficult to obtain zero error on the training set, we instead train the QNNs by finding a set of parameters that obtain zero error on the training set. To do this, we randomly sample a set of parameters and use them in the QNN and then run the QNN with the training inputs and obtain the predicted Ypredict label. We calculate the training error and repeat this process until we obtain a set of parameters where the training error is zero. Once we have obtained that set of parameters (which ensures that that the QNN is trained to zero training error) we use these parameters (i.e. the trained QNN) to calculate the error (i.e. the generalisation error) on the test set. More details about the training method can be read in Section B2.\nWe find the generalisation error for target functions with different complexities. We have constructed certain target functions so that they have the properties we want to study, in particular functions with low-entropy and low-complexity, low-entropy and high-complexity, high-entropy and low-complexity, and high-entropy and high-complexity. We also generate random target functions. More details about the target functions and further results on the generalisation error can be read in Appendix C3.\nFigure 5 shows how the generalisation error (i.e. test error) varies by the Lempel-Ziv (LZ) complexity and entropy of the function across different encoding methods.\nFor basis encoding, the test error is around 0.5 for all values of complexity and entropy, which is to be expected, as it has no inductive bias and acts as a random learner. A random learner randomly predicts outputs on the test set and has a 50% chance of obtaining the correct output. Looking at the generalisation error further confirms this inductive bias.\nFor amplitude encoding, the test error increases as the LZ complexity of the function increases, which implies an inductive bias towards low-complexity functions. Low-complexity functions have a low test error, as such a QNN is most likely to predict simple functions when given the test set given its bias towards low-complexity functions. There is no straightforward pattern of the test error as the entropy increases, however, implying there is no bias towards low-entropy functions. We see that high-entropy functions can have a low test error.\nFor the ZZ feature map and random relu transform, the test error generally increases as the complexity increases, but this pattern is stronger as the entropy increases, implying a bias towards low-entropy functions. For the ZZ feature map, we can see that there are a couple of target functions that have a low-moderate complexity (below 25) but generalise poorly, with a test error around 0.5. Further inspection into these target functions reveal that they have a high entropy, showing that the ZZ feature map does not have a bias towards low-complexity functions when the entropy is high."}, {"title": "E. Expressivity of QNNs", "content": "A stronger inductive bias seems to imply a weaker expressivity and a weaker inductive bias seems to imply a stronger expressivity for the encoding methods we have studied. We have shown that amplitude encoding has a simplicity bias, similar to the bias of the DNN. Amplitude encoding, however, limits the expressivity of the QNN. This can be a problem because we would need to know something about our function to know whether it could be expressed by a QNN with amplitude encoding."}]}