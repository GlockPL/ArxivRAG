{"title": "PROMPT-CAM: A Simpler Interpretable Transformer for Fine-Grained Analysis", "authors": ["Arpita Chowdhury", "Dipanjyoti Paul", "Zheda Mai", "Jianyang Gu", "Ziheng Zhang", "Kazi Sajeed Mehrab", "Elizabeth G. Campolongo", "Daniel Rubenstein", "Charles V. Stewart", "Anuj Karpatne", "Tanya Berger-Wolf", "Yu Su", "Wei-Lun Chao"], "abstract": "We present a simple usage of pre-trained Vision Transformers (ViTs) for fine-grained analysis, aiming to identify and localize the traits that distinguish visually similar categories, such as different bird species or dog breeds. Pre-trained ViTs such as DINO have shown remarkable capabilities to extract localized, informative features. However, using saliency maps like Grad-CAM can hardly point out the traits: they often locate the whole object by a blurred, coarse heatmap, not traits. We propose a novel approach Prompt Class Attention Map (PROMPT-CAM) to the rescue. PROMPT-CAM learns class-specific prompts to a pre-trained ViT and uses the corresponding outputs for classification. To classify an image correctly, the true-class prompt must attend to the unique image patches not seen in other classes' images, i.e., traits. As such, the true class's multi-head attention maps reveal traits and their locations. Implementation-wise, PROMPT-CAM is almost a free lunch by simply modifying the prediction head of Visual Prompt Tuning (VPT). This makes PROMPT-CAM fairly easy to train and apply, sharply contrasting other interpretable methods that design specific models and training processes. It is even simpler than the recently published INterpretable TRansformer (INTR), whose encoder-decoder architecture prevents it from leveraging pre-trained ViTs. Extensive empirical studies on a dozen datasets from various domains (e.g., birds, fishes, insects, fungi, flowers, food, and cars) validate PROMPT-CAM superior interpretation capability.", "sections": [{"title": "1. Introduction", "content": "Vision Transformers (ViT) [9] pre-trained on huge datasets have greatly improved vision recognition, even for fine-grained objects [10, 39, 46, 51]. DINO [4] and DINOv2 [28] further showed remarkable abilities to extract features that are localized and informative, precisely representing the corresponding coordinates in the input image. These advancements open up the possibility of using pre-trained ViTs to discover \u201ctraits\u201d that highlight each category's identity and distinguish it from other visually close ones.\nOne popular approach to this is saliency maps, for example, Class Activation Map (CAM) [13, 24, 36, 50]. After extracting the feature maps from an image, CAM highlights the spatial grids whose feature vectors align with the target class's fully connected weight. While easy to implement and efficient, the reported CAM saliency on ViTs is often far from expectation. It frequently locates the whole object with a blurred, coarse heatmap, instead of focusing on subtle traits that tell visually similar objects (e.g., birds) apart. One may argue that CAM was not originally developed for ViTs, but even with dedicated variants like attention roll-out [1, 5, 14], the issue is only mildly attenuated.\nWhat if we look at the attention maps? ViTs rely on self-attention to relate image patches; the [CLS] token aggregates image features by attending to informative patches. As shown in [7, 26, 38], the attention maps of the [CLS] token do highlight local regions inside the object. However, these regions are not \u201cclass-specific.", "Red-winged Blackbird\" and other bird species is the red spot on the wing, having little to do with other body parts.\nHow can we leverage pre-trained ViTs, particularly their localized and informative patch features, to identify traits that are so special for each category?\nOur proposal is to prompt the ViTs with learnable \u201cclass-specific\" tokens, one for each class, inspired by [19, 30, 48]. These \"class-specific\u201d tokens, once inputted to ViTs, attend to image patches via self-attention, just like the [CLS] token. Yet, unlike [CLS] token which is \u201cclass-agnostic,\u201d these \"class-specific\" tokens can attend to the same image differently, having the potential to highlight local regions that are specific to the corresponding classes, i.e., traits.\nWe implement our approach, which we name Prompt Class Attention Map (PROMPT-CAM), as follows. Given a pre-trained ViT and a fine-grained classification dataset with C classes, we add C learnable tokens as extra inputs to the first Transformer layer. To make these tokens \u201cclass-specific,": "e collect their corresponding output vectors after the final Transformer layer and perform inner products with a shared vector (also learnable) to obtain C \"class-specific\" scores, following [30]. One may interpret each class-specific score as how clearly the corresponding class's traits are seen in the input image. Intuitively, the input image's ground-truth class should possess the highest score, and we encourage this by minimizing a cross-entropy loss, treating the scores as logits. We keep the whole pre-trained ViT frozen and only optimize the C tokens and the shared scoring vector. See section 3 for details and variants.\nFor interpretation during inference, we input the image and the C tokens simultaneously to the ViT to obtain the C scores. One can then select a specific class, for example, the highest-score class, and visualize the R multi-head attention maps to the image patches. (See section 3 for how to rank these R maps to highlight the most discriminative traits.) When the highest-score class is the ground-truth class, the attention maps reveal its traits. Otherwise, comparing the highest-score class's attention and the ground-truth class's attention explains why the image is misclassified. Example reasons involve the object in the image being partially occluded or in an odd pose, such that its traits were invisible, or somehow its appearance being too similar to a wrong class, perhaps due to lighting conditions (see Figure 5).\nPROMPT-CAM is fairly easy to implement and train. It requires no change to pre-trained ViTs and no specially designed loss function or training strategy\u2014just the standard cross-entropy loss and SGD. Indeed, building upon Visual Prompt Tuning (VPT) [12], one merely needs to adjust a few lines of code and can enjoy fine-grained interpretation. This simplicity sharply contrasts other interpretable methods like ProtoPNet [6] and ProtoTree [25]. Compared\nto INterpretable TRansformer (INTR) [30], which also featured simplicity, PROMPT-CAM has three notable advantages. First, PROMPT-CAM is encoder-only and can potentially take any ViT encoders. In contrast, INTR is built upon an encoder-decoder model pre-trained on object detection datasets. Thus, PROMPT-CAM can leverage up-to-date pre-trained models more easily. Second, as a result, PROMPT-CAM can be trained much faster-only the prompts and the shared vector need to be learned. In contrast, INTR typically demands full fine-tuning. Third, PROMPT-CAM produces cleaner and sharper attention maps than INTR, which we attribute to the usages of state-of-the-art ViTs like DINO or DINOv2. Put things together, we view PROMPT-CAM as a simpler yet stronger interpretable Transformer.\nWe validate PROMPT-CAM on over a dozen datasets: CUB-200-2011 [43], Birds-525 [32], Oxford Pet [29], Stanford Dogs [15], Stanford Cars [16], iNaturalist-2021-Moths [41], Fish Vista [23], Rare Species [40], Insects-2 [47], iNaturalist-2021-Fungi [41], Oxford Flowers [27], Medicinal Leaf [35], Stanford Cars [16] and Food 101 [2]. PROMPT-CAM can identify different traits of a category through multi-head attention and consistently localize them in images. To our knowledge, PROMPT-CAM is the only explainable or interpretable method for vision that has been evaluated on such a broad range of domains. We further show PROMPT-CAM's extendability by applying it to discovering taxonomy keys. Our contributions are two-fold.\n\u2022 We present PROMPT-CAM, an easily implementable, trainable, and reproducible interpretable method that leverages the representations of pre-trained ViTs to identify and localize traits for fine-grained analysis.\n\u2022 We conduct extensive experiments on more than a dozen datasets to validate PROMPT-CAM's interpretation quality, wide applicability, and extendability.\nComparison to closely related work. Besides INTR [30], our class-specific attentions are inspired by two other works in different contexts, MCTformer for weakly supervised semantic segmentation [48] and Query2Label for multi-label classification [19]. Both of them learned class-specific to-"}, {"title": "3. Approach", "content": "We propose Prompt Class Attention Map (PROMPT-CAM) to leverage pre-trained Vision Transformers (ViTs) [9] for fine-grained analysis. The goal is to identify and localize traits that highlight an object category's identity. PROMPT-CAM adds learnable class-specific tokens to prompt ViTs, producing class-specific attention maps that reveal traits. The overall framework is presented in Figure 3. We deliberately follow the notation and naming of Visual Prompt Tuning (VPT) [12] for ease of reference.\n3.1. Preliminaries\nA ViT typically contains N Transformer layers [42]. Each consists of a Multi-head Self-Attention (MSA) block, a Multi-Layer Perceptron (MLP) block, and several other operations like layer normalization and residual connections.\nThe input image I to ViTs is first divided into M fixed-sized patches. Each is then projected into a D-dimensional feature space with positional encoding, denoted by $e_j$, with $1 \\leq j \\leq M$. We use $E_0 = [e_1,\\ldots,e_M] \\in \\mathbb{R}^{D\\times M}$ to denote their column-wise concatenation.\nTogether with a learnable [CLS] token $x_0 \\in \\mathbb{R}^D$, the whole ViT is formulated as:\n$[E_i, x_i] = L_i([E_{i-1}, x_{i-1}]), i = 1,\\ldots, N,$\nwhere $L_i$ denotes the $i$-th Transformer layer. The final $E_N$ is typically used to represent the whole image and fed into a prediction head for classification.\n3.2. Prompt Class Attention Map (PROMPT-CAM)\nGiven a pre-trained ViT and a downstream classification dataset with C classes, we introduce a set of C learnable D-dimensional vectors to prompt the ViT. These vectors are learned to be \u201cclass-specific\u201d by minimizing the cross-entropy loss, during which the ViT backbone is frozen. In the following, we first introduce the baseline version.\nPROMPT-CAM-SHALLOW. The C class-specific prompts are injected into the first Transformer layer $L_1$. We denote each prompt by $p^c \\in \\mathbb{R}^D$, where $1 < c < C$, and use $P = [p^1,\\ldots,p^C] \\in \\mathbb{R}^{D\\times C}$ to indicate their column-wise"}, {"title": "concatenation. The prompted ViT is:", "content": "$[Z_1, E_1, x_1] = L_1([P, E_0, x_0])$,\n$[Z_i, E_i, x_i] = L_i([Z_{i-1}, E_{i-1}, x_{i-1}]), i = 2, \\ldots, N,$\nwhere $Z_i$ represents the features corresponding to $P$, computed by the $i$-th Transformer layer $L_i$. The order among $x_0$, $E_0$, and $P$ does not matter since the positional encoding of patch locations has already been inserted into $E_0$.\nTo make $P = [p^1,\\ldots, p^C]$ class-specific, we employ a cross-entropy loss on top of the corresponding ViT's output, i.e., $Z_N = [z^1,\\ldots, z^C]$. Given a labeled training example $(I, y \\in {1,\\ldots, C})$, we calculate the logit of each class by:\n$s[c] = w^Tz_N^c$, $1 \\leq c < C,$\nwhere $w \\in \\mathbb{R}^D$ is a learnable vector. $P$ can then be updated by minimizing the loss:\n$- \\log \\frac{\\exp (s[y])}{\\sum_c^C \\exp (s[c])}.$\nPROMPT-CAM-DEEP. While straightforward, PROMPT-CAM-SHALLOW has two potential drawbacks. First, the class-specific prompts attend to every layer's patch features, i.e., $E_i$, $i = 0,..., N - 1$. However, features of the early layers are often not informative enough but noisy for differentiating classes. Second, the prompts $p^1,\\ldots, p^C$ have a \"double duty.\" Individually, each needs to highlight class-specific traits. Collectively, they need to adapt pre-trained ViTs to downstream tasks, the original purpose of VPT [12]. In our case, the downstream task is a new usage of ViTs on a specific fine-grained dataset.\nTo address these issues, we resort to the VPT-Deep's design while deliberately decoupling injected prompts' roles. VPT-Deep adds learnable prompts to every layer's input. Denote by $P_{i-1} = [p_1^{i-1},\\ldots, p_C^{i-1}]$ the prompts to the $i$-th Transformer layer, the deep-prompted ViT is formulated as:\n$[Z_i, E_i, x_i] = L_i([P_{i-1}, E_{i-1}, x_{i-1}]), i = 1,\\ldots, N,$\nIt is worth noting that the features $Z_i$ after the $i$-th layer are not inputted to the next layer, and are typically disregarded. In PROMPT-CAM-DEEP, we repurpose $Z_N$ for classification, following Equation 1. As such, after minimizing the cross entropy loss in Equation 2, the corresponding prompts $P_{N-1} = [p_1^{N-1},\\ldots, p_C^{N-1}]$ will be class-specific. Prompts to the other layers' inputs, i.e., $P_i = [p_1^{i},\\ldots,p_C^{i}]$ for $i = 0,..., N - 2$, remain class-agnostic, because $p_c^i$ does not particularly serve for the $c$-th class, unlike $P_{N-1}$. In other words, PROMPT-CAM-DEEP learns both class-specific prompts for trait localization and class-agnostic prompts for adaptation. The class-specific prompts $P_{N-1}"}, {"title": "only attend to the patch features $E_{N-1}$ inputted to the last\nTransformer layer $L_N$, further addressing the other issue in\nPROMPT-CAM-SHALLOW.\nIn the following, we focus on PROMPT-CAM-DEEP.", "content": "3.3. Trait Identification and Localization\nDuring inference, given an image I, PROMPT-CAM-DEEP extracts patch embeddings $E_{N-1} = [e_1^{N-1},\\ldots, e_M^{N-1}]$ and follows Equation 3 to obtain $Z_N$ and Equation 1 to obtain $s[c]$ for $c \\in {1,\\ldots, C}$. The predicted label $\\hat{y}$ is:\n$\\hat{y} = \\arg \\max_{c \\in {1,...,C}} s[c].$\nWhat are the traits of class c? To answer this question, one could collect images whose true and predicted classes are both class c (i.e., correctly classified) and visualize the multi-head attention maps queried by $p_c^{N-1}$ in layer $L_N$. Specifically, in layer $L_N$ with R attention heads, the patch features $E_{N-1} \\in \\mathbb{R}^{D\\times M}$ are projected into R key matrices, denoted by $K_{N-1}^{c,r} \\in \\mathbb{R}^{D'\\times M}$, $r = 1,\\ldots,R$. The $j$-th column corresponds to the $j$-th patch in I. Meanwhile, the prompt $P_{N-1}$ is projected into R query vectors $q_{N-1}^{c,r} \\in \\mathbb{R}^{D'}$, $r = 1,\\ldots, R$. Queried by $p_c^{N-1}$, the $r$-th head's attention map $\\alpha_{N-1}^{c,r} \\in \\mathbb{R}^M$ is computed by:\n$\\alpha_{N-1}^{c,r} = \\text{softmax} (\\frac{{q_{N-1}^{c,r}}^T K_{N-1}^{c,r}}{\\sqrt{D'}})$\nConceptually, from the $r$-th head's perspective, the weight $\\alpha_{N-1}^{c,r}[j]$ indicates how important the $j$-th patch is for classifying class c, hence localizing traits in the image. Ideally, each head should attend to different (sets of) patches to look for multiple traits that together highlight class c's identity. By visualizing each attention map $\\alpha_{N-1}^{c,r}$, $r = 1,\\ldots, R$, instead of pooling them averagely, PROMPT-CAM can potentially identify up to R different traits for class c.\nWhich traits are more discriminative? For categories that are so distinctive like \"Red-winged Blackbird,\" a few traits are sufficient to distinguish them from others. To automatically identify these most discriminative traits, we take a greedy approach, progressively blurring the least important traits until the image is classified wrongly. The remaining ones highlight the traits that are sufficient for classification.\nSuppose class c is the true class and the image is correctly classified. In each greedy step, for each of the un-blurred heads indexed by r, we iteratively replace $\\alpha_{N-1}^{c,r}$ with $1$, and recalculate s[c] in Equation 1, where $1 \\in \\mathbb{R}^M$ is an all-one vector. Doing so essentially blurs the r-th head for class c, preventing it from focusing. The head with the highest blurred s[c] is thus the least important, as blurring it hurts classification the least. See Suppl. for more details.\nWhy is an image wrongly classified? When $\\hat{y} \\neq y$ for a labeled image (I, y), one could visualize both {$\\alpha_{y,r}^{N-1}$}$_{r=1}^R$"}, {"title": "and {$\\alpha_{\\hat{y},r}^{N-1}$}$_{r=1}^R$ to understand why the classifier made such\na prediction. For example, some traits of class y may be\ninvisible or unclear in I; the object in I may possess class\n$\\hat{y}$'s visual traits, for example, due to light conditions.", "content": "3.4. Variants and Extensions\nOther PROMPT-CAM designs. Besides injecting class-specific prompts to the first layer (i.e., PROMPT-CAM-SHALLOW) or the last (i.e., PROMPT-CAM-DEEP), we also explore their interpolation. We introduce class-specific prompts like PROMPT-CAM-SHALLOW to the i-th layer and class-agnostic prompts like PROMPT-CAM-DEEP to the first i - 1 layers. See the Suppl. for a comparison.\nFocused PROMPT-CAM for pair-wise comparison. To claim the highest prediction score, the ground-truth class's prompt $p_y^{N-1}$ must identify a comprehensive set of traits to tell itself apart from all the other categories. As a result, it may not prioritize the nuanced differences in patterns, colors, and shapes that distinguish it from the most visually similar class (e.g., animal species under the same Genus).\nWe investigate one approach to mitigating this, which is to feed only the ground-truth and targeted reference classes' prompts into PROMPT-CAM-DEEP during inference, denoted by y and y', respectively. We note that the MSA block in the Transformer layer $L_N$ allows each class-specific prompt to attend to the others. Subsampling the input prompts thus wound change the output score s[y] in Equation 1 and consequently the order of the least important heads, focusing the model on what to look at.\nPROMPT-CAM for discovering taxonomy keys. So far, we have focused on a \u201cflat\u201d comparison over all the categories. In domains like biology that are full of fine-grained categories, researchers often have built hierarchical decision trees to ease manual categorization, such as taxonomy. The role of each intermediate \"tree node\" is to dichotomize a subset of categories into multiple groups, each possessing certain group-level characteristics (i.e., taxonomy keys).\nThe simplicity of PROMPT-CAM allows us to efficiently train multiple sets of prompts, one for each intermediate tree node, potentially (re-)discovering the taxonomy keys. One just needs to relabel categories of the same group by a single label, before training. In expectation, along the path from the root to a leaf node, each of the intermediate tree nodes should look at different group-level traits on the same image of that leaf node. See Figure 10 for a preliminary result.\n3.5. What is PROMPT-CAM suited for?\nAs our paper is titled, PROMPT-CAM is dedicated to fine-grained analysis, aiming to identify and, more importantly, localize traits useful for differentiating categories. This, however, does not mean that PROMPT-CAM would excel in fine-grained classification accuracy. Modern neural net-"}, {"title": "works easily have millions if not billions of parameters.\nHow a model predicts is thus still an unanswered question,\nat least, not fully. It is known if a model is trained mainly\nto chase accuracies with no constraints, it will inevitably\ndiscover \"shortcuts\" in the collected data that are useful for\nclassification but not analysis [8, 11]. We thus argue:", "content": "To make a model suitable for fine-grained analysis, one\nmust constrain its capacity, while knowing that doing so\nwould unavoidably hurt its classification accuracy.\nPROMPT-CAM is designed with such a mindset. Unlike conventional classifiers with a fully connected layer on top, PROMPT-CAM follows [30] to learn a shared vector w in Equation 1, whose goal is NOT to record class-specific information BUT to answer the \"binary\u201d question: Based on where a class-specific prompt attends, does the class find itself in the input image?\nTo elucidate the difference, let us consider a simplified single-head-attention Transformer layer with no layer normalization, residual connection, MLP block, and other non-linear operations. Let V = {$v^1,\\ldots ,v^M$} $\\in \\mathbb{R}^{D\\times M}$ be the M input patches' value features, $a^c \\in \\mathbb{R}^M$ be the attention weights of class c, and a* $\\in \\mathbb{R}^M$ be the attention weights of the [CLS] token. Conventional models predict classes by:\n$y = \\arg \\max_c w_c^T (\\sum_j a^*[j] \\times v^j)$\n$= \\arg \\max_c \\sum_j a^*[j] \\times (w_c^T v^j),$\nwhere $w_c$ stores the fully connected weights for class c. We argue that such a formulation offers a \"detour\u201d such that the model can correctly classify an image I of class y even without meaningful attention weights. In essence, the model can choose to produce holistically discriminative value features from I with no spatial resolution, such that $v^j$ aligns with $w_y$ but $v^j \\approx v^{j'}, \\forall j \\neq j'$. In this case, no matter what a* is, as long as it sums to one as default in the softmax formula, the prediction remains intact.\nIn contrast, PROMPT-CAM predicts classes by:\n$y = \\arg \\max_c w^T (\\sum_j a^c[j] \\times v^j)$\n$= \\arg \\max_c \\sum_j a^c[j] \\times (w^T v^j),$\nwhere w is the shared binary classifier. (For brevity, we assume no self-attention among the prompts.) While the difference between Equation 7 and Equation 6 is subtle at first glance, it fundamentally changes the model's behavior. In essence, it becomes less effective to store class discriminative information in the channels of $v^j$, because there is no $w_c$ to align with. Moreover, the model can no longer produce holistic features with no spatial resolution; otherwise,"}, {"title": "it cannot distinguish among classes since all of their scores\ns[c] will be exactly the same, no matter what & is.\nIn response, the model must be equipped with two capa-bilities to minimize the cross-entropy error:", "content": "\u2022 Generate representative, localized features v\u00ed to precisely\nencode the trait (e.g., red spots) within each patch j.\n\u2022 Generate distinctive attention weights & among classes;\neach highlights traits frequently seen in class c.\nThese properties are what fine-grained analysis needs.\nIn sum, PROMPT-CAM discourages patch features from\nencoding class-discriminative holistic information (e.g., the\nwhole object shapes or mysterious long-distance pixel cor-relations), even if such information can be \"beneficial\" to a\nconventional classifier. To this end, PROMPT-CAM needs\nto distill localized, trait-specific information from the pre-trained ViT's patch features, which is achieved through the injected class-agnostic prompts in PROMPT-CAM-DEEP."}]}