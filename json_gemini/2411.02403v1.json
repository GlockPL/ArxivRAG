{"title": "A Persuasion-Based Prompt Learning Approach to Improve Smishing Detection through Data Augmentation", "authors": ["Ho Sung Shim", "Hyoungjun Park", "Kyuhan Lee", "Jang-Sun Park", "Seonhye Kang"], "abstract": "Smishing, which aims to illicitly obtain personal information from\nunsuspecting victims, holds significance due to its negative\nimpacts on our society. In prior studies, as a tool to counteract\nsmishing, machine learning (ML) has been widely adopted, which\nfilters and blocks smishing messages before they reach potential\nvictims. However, a number of challenges remain in ML-based\nsmishing detection, with the scarcity of annotated datasets being\none major hurdle. Specifically, given the sensitive nature of\nsmishing-related data, there is a lack of publicly accessible data\nthat can be used for training and evaluating ML models.\nAdditionally, the nuanced similarities between smishing messages\nand other types of social engineering attacks such as spam\nmessages exacerbate the challenge of smishing classification with\nlimited resources. To tackle this challenge, we introduce a novel\ndata augmentation method utilizing a few-shot prompt learning\napproach. What sets our approach apart from extant methods is\nthe use of the principles of persuasion, a psychology theory which\nexplains the underlying mechanisms of smishing. By designing\nprompts grounded in the persuasion principles, our augmented\ndataset could effectively capture various, important aspects of\nsmishing messages, enabling ML models to be effectively trained.\nOur evaluation within a real-world context demonstrates that our\naugmentation approach produces more diverse and higher-\nquality smishing data instances compared to other cutting-edging\napproaches, leading to substantial improvements in the ability of\nML models to detect the subtle characteristics of smishing\nmessages. Moreover, our additional analyses reveal that the\nperformance improvement provided by our approach is more\npronounced when used with ML models that have a larger number\nof parameters, demonstrating its effectiveness in training large-\nscale ML models.", "sections": [{"title": "1 INTRODUCTION", "content": "Smishing, a portmanteau of \"SMS\" (Short Message Service) and\n\"phishing,\" is one of the dominant approaches of social\nengineering attacks, manipulating mobile text messages to\ndeceive individuals and to illegally obtain personal information\n[24, 29]. Smishing, in general, comprises texts, URLs, self-\nanswering links, and contact information such as email addresses\nthat help convince its targets that the message is authentic and,\nconsequently, have the targets provide desired information [17,\n28].\nUnlike other types of social engineering attacks such as\nphishing, smishing has unique characteristics that render its\ntargets more vulnerable. Specifically, smishing messages are\ntransmitted through mobile devices, which heightens the\nsusceptibility of their targets due to factors such as small screens,\nlimited user awareness, and frequent credential input [19].\nTherefore, it is crucial to provide potential victims with\npreventive mechanisms that can enhance their resilience to\nsmishing.\nIn recent literature, machine learning (ML) trained with\nlabeled smishing data has emerged as a promising, scalable\nmechanism for preventing the potential harm by smishing [26].\nThis approach involves computationally identifying the semantic\nand syntactic characteristics of smishing messages, enabling the\ndifferentiation between messages with malicious intent and those\nwith benign intent [26].\nHowever, prior studies of smishing detection have faced a\nsignificant challenge in the development of ML models: the\nshortage of training data [18, 28]. Specifically, due to the sensitive\nnature of the data involved in smishing detection, it is extremely\ndifficult to find and utilize large, publicly available datasets for\nproper model development and evaluation [18, 28].\nAs a result, challenges have persisted in distinguishing\nsmishing messages from not only benign messages but also other\ntypes of social engineering attacks, such as spam messages, which\nshare similar characteristics with smishing messages [28]. This is\na significant issue because, depending on the types of social\nengineering attacks, different levels of social pressures and\nregulatory measures should be imposed. For instance, smishing\nand spam messages, while sharing similarities, have distinct\nimpacts on society and are handled differently from a legal\nstandpoint. Specifically, while smishing messages are deemed a\nsevere cybercrime and subject to stringent regulatory measures\n[23, 28], spam messages are often view as an intrusive marketing\nand not regulated to the same extent as smishing [22, 25].\nTo address the above issues, we propose a novel data\naugmentation approach for smishing detection. Specifically, we\nharness the power of large language models (LLMs) with prompt\nengineering based on the persuasion theory. Although, several\nprior studies have utilized prompt engineering for data\naugmentation in different domains [12, 21, 33], what set our\napproach apart from them are the prompts designed based on a\nsocial science theory that explains the underlying mechanism of\nsmishing. Particularly, our data augmentation process draws upon\nthe principles of persuasion to systematically capture different\naspects of real-world smishing messages [2, 5]\nWe evaluated our approach on the task of distinguishing\nsmishing messages from spam messages under multiple\nconditions. The results demonstrated that ML models trained on\nour augmented data outperformed those trained on original data\nby up to 5.3% in terms of the F1 measure. Moreover, our additional\nanalyses under varying experimental conditions confirm the\nrobustness of our methodological approach in enhancing\nsmishing detection."}, {"title": "2 RELATED WORK", "content": ""}, {"title": "2.1 Smishing Detection", "content": "In smishing detection, a dominating approach has been based on\nML [1, 10, 19, 26]. [10] manually crafted nine features for filter\nsmishing from benign messages and tested multiple ML\nalgorithms with these features. [19] utilized neural networks to\nidentify the most prominent features of smishing messages. [1]\nused textual features along with conventional ML models such as\nsupport vector machines, naive bayes, random forests, and logistic\nregressions to identify smishing messages. [26] employed\ndifferent correlation measures (e.g., Pearson, Spearman, Kendall,\nand Point biserial) along with ML algorithms to identify the most\neffective features for detecting smishing messages. Apart from\ntraditional ML approaches, transfer learning, leveraging the\nknowledge of pretrained LLMs, has recently become popular [11].\nDespite a large amount of attention paid to ML-based\nsmishing detection, there remain multiple challenges. First, as\nmentioned above, prior studies have faced a lack of publicly\navailable data for training and evaluating ML models. For instance,\namong 5858 text messages used by [20], only 538 have been\nclassified as smishing. In [1], only 278 smishing messages have\nbeen used. In addition, prior literature has primarily focused on\nthe relatively simpler task of distinguishing smishing from benign\nmessages (aka hams [18]). However, as mentioned earlier, in\npractical settings, it is at least equally important but more\nchallenging to differentiate smishing messages from other types\nof social engineering attacks such as spam messages, due to their\nsimilar semantic and syntactic structures but different regulatory\nimplications [23, 28]."}, {"title": "2.2 Text Data Augmentation", "content": "The primary objective of text data augmentation is to generate\ndiverse but coherent text instances, preserving the semantics of\nthe original data [36]. To this end, many data augmentation\nmethods, such as back translation and synonym replacement,\nhave been proposed [14, 35]. The back translation method\ninvolves translating the original content into a different language\nand then translating the result back into the original language [3,\n35]. Additionally, techniques known to be EDA approach (easy\ndata augmentation), which includes operations like synonym\nreplacement, random insertion, swapping, and deletion of words\n[32], have been largely utilized in text data augmentation.\nHowever, these approaches have limitations as they typically\nproduce augmented data that are syntactically similar to the\noriginal data. To address this issue, recently, there has been an\nemphasis on using LLMs to augment low-resource data."}, {"title": "2.3 Prompt Engineering in Text Data Augmentation", "content": "LLMs understand the semantic meanings and syntactic structures\nof human language through a large number of trainable\nparameters and training data [16]. They also have the ability to\ngenerate text as humans do [30]. Such versatility of LLMs can be\nhighly effective in data augmentation especially when coupled\nwith a proper prompt design.\nIn general, prior studies have employed the few-shot approach\nas their primary strategy, which present some demonstrations (i.e.,\nfew shots) of data augmentation to LLMs [9, 34]. For example, [4]\nhave suggested AugGPT, a ChatGPT-based text data\naugmentation technique, which produces semantically diverse\ndata instances by utilizing prompts with few effective\ndemonstrations. [21] have employed GPT-4 and ChatGPT to\nextend low-source datasets using ad-hoc prompt designs. [12]\nhave combined few-shot and contrastive learning for chatbot data\naugmentation. [33] have utilized prompts with iteratively sampled\ndemonstrations from the original, multilingual datasets for data\naugmentation.\nWhile our methodological approach shares some similarities\nwith those that have been discussed above, it sets itself apart from\nthem by incorporating a psychology theory, which systematically\ncaptures various aspects of smishing, into the design of prompts\nthat facilitates the generation of new data instances [6]. Since\nsmishing relies heavily on psychological manipulation to deceive\nvictims, integrating these principles allows us to better\nunderstand and replicate these tactics, ultimately facilitating the\ngeneration of realistic and diverse smishing messages, which is\ncrucial for augmenting high-quality data in this domain [2, 5].\nSpecifically, we have applied the principles of persuasion in this\nstudy, which identifies the underlying mechanism of The details\nof the principles will be elaborated further in the following section."}, {"title": "3 METHODOLGY", "content": ""}, {"title": "3.1 Data", "content": "We utilized the SMS Phishing Benchmark Dataset [20] as the\nbaseline dataset for implementing our data augmentation\napproach. The dataset suggests three types of SMS classifications:\nsmishing, spam, and ham. Among the three classes, our interest\nexclusively lies in smishing and spam messages since, as stated\nearlier, the task of distinguishing non-ham messages (which\nincludes both smishing and spam messages) from ham messages\nis much simpler. As a result, our dataset comprises a total of 1,127\nmessages, with 489 being spam messages and 638 being smishing\nmessages. Note that we split the dataset with an 8:2 ratio and use\nthe larger portion for data augmentation (i.e. 901 instances). We\nreserve the smaller portion of the split dataset for evaluation\nbecause the inclusion of this portion in data augmentation will\ncause the overestimation of our approach. We repeated this\nprocess five times with different partitions, akin to five-fold cross\nvalidation, and report the average results."}, {"title": "3.2 Prompt Design", "content": "Our prompt-based approach, utilizing an LLM, for data\naugmentation has the following input-output structure, which is\nalso illustrated in Figure 1-(a):\nInput: {\\(P_{role}\\), [SEP], \\(P_{persuasion-type}\\), [SEP],\n\\(P_{demo1}\\), [SEP], \\(P_{demo2}\\), \u2026, [SEP], \\(P_{demon}\\) },\nOutput: {\\(S_{1}\\), [SEP], \\(S_{2}\\), ..., [SEP], \\(S_{m}\\)},\nwhere \\(P_{role}\\) denotes a prompt that assigns a role to an LLM (as\neither smishing generator or spam generator), \\(P_{persuasion-type}\\)\nrefers to a prompt that explains a specific persuasion type to be\nemployed by an LLM for generating new samples, \\(P_{demo}\\) is a\nprompt that provides an LLM with an example of smishing (or\nspam) messages, and \\(S_{m}\\) is a newly generated sample. The\nnumber of demonstrations shown to an LLM (n in the input) and\nthat of new samples generated (m in the output) are\nhyperparameters. Note that the ad-hoc data augmentation in\nFigure 1-(b) (i.e., smishing w/o theory), one of the baselines in our\nevaluation, uses the prompt that excludes \\(P_{persuasion-type}\\) from\nthe input. An example of the input and output is presented in\nFigure 2.\nA key to generating proper new samples in our proposed\napproach is the \\(P_{persuasion-type}\\), i.e., the part of a prompt\ngrounded in well-established psychological theories. Specifically,\nin social science, several theories have been found to be relevant\nto the tactics used in smishing attacks, as illustrated below:\nPrinciples of Influence [2] examines the impact of reciprocity,\ncommitment and consistency, social proof, authority, liking, and\nscarcity on social influence. [2] work explains how social and\npsychological triggers can effectively persuade individuals,\nproviding crucial insight into the tactics used in smishing\nschemes.\nPsychological Triggers Similar to [2], [7] outlines several key\ntriggers, such as authority, intimidation, consensus (social proof),\nscarcity, urgency, and sympathy. These triggers highlight the\nemotional and cognitive vulnerabilities exploited by scammers to\nmanipulate their targets.\nPrinciples of Scams [27] identifies elements such as distraction,\nsocial compliance, herd principle, dishonesty, kindness, need and\ngreed, and time, illustrating the structural aspects of scams and\nhow they exploit human psychology.\n[5], which combines these theories into a consolidated\nframework, provides a comprehensive understanding of the\ndiverse and overlapping psychological manipulations employed\nin smishing. The framework covers a broad spectrum of social\nengineering and enhances the theoretical basis for our prompt\ndesigns in data augmentation. Specifically, [5] have suggested the\nfollowing five components that influence the effectiveness of\npersuasion (The full definitions and their examples are detailed in\nAppendix A.1):\n\u2022 Authority: This refers to individuals' inclination to easily be\npersuaded by the authority of an expert.\n\u2022 Social Proof: Individuals tend to believe what the majority of\npeople do or seem to believe.\n\u2022 Liking, Similarity, Deception: People are more likely to follow\nothers whom they know, like, or are familiar with.\n\u2022 Distraction: This relates to individuals' tendency to focus on\nwhat they can gain, lose, or need, especially during strong\nemotional states.\n\u2022 Commitment, Integrity, Reciprocation: People often hold the\nbelief that when someone makes a commitment, it will be\nhonored, and they feel compelled to reciprocate the commitment\nwith a favor.\nTo incorporate the above concepts into \\(P_{persuasion-type}\\), we\nfirst manually annotated the original data with corresponding\npersuasion types so that social engineering tactics specific to each\nsmishing message could be identified and, later, be used for data\naugmentation. We recruited five annotators, each holding a\nbachelor's degree or higher in the relevant fields of psychology.\nTheir task was to identify the most relevant persuasion principle\nto a given smishing message (i.e., a five-class classification task).\nPrior to annotation, we ensured that the annotators thoroughly\nunderstood the connection between smishing messages and the\nprinciples of persuasion by providing them with detailed\nguidelines and multiple examples. The guidelines included the\ndefinitions of each persuasion principle, along with the examples\ndemonstrating each principle. To resolve discrepancies in\ncategorization, we employed majority voting, requiring at least\nthree out of five annotators to agree for a decision to be accepted.\nIn instances where no clear majority was evident (less than 1%\nmissed the majority vote, amounting to 6 data points), the\nannotators convened to discuss the message together and reach a\nconsensus on the most appropriate persuasion principle, ensuring\na rigorous and comprehensive review process. The annotation\noutcome revealed a moderate level of agreement among\nannotators with a Fleiss' kappa coefficient of 0.456, indicating a\nmoderate but reliable level of consensus, consistent with accepted\nresearch standards.\nThe smishing examples (i.e., \\(P_{demo}\\)) were selected through a\nstratified random sampling approach. That is, for each iteration of\ndata augmentation, smishing examples that belong to the same\ntype of persuasion were randomly selected and used as references\n(i.e., few shots) for generating new data instances as indicated in\nFigure 1.\nAs noted earlier, for each iteration of data augmentation, we\ngenerated m new data instances by showing an LLM in randomly\nsampled demonstrations. The values of n and m were set to 5 and\n10, respectively, based on preliminary experiments that aimed to\nmaximize the diversity of the generated data while ensuring its\nquality. These values also align with those used in [33]. Compared\nwith the 1-to-1 matching strategy (i.e., one demonstration is given\nto generate one new data instance), this approach achieves a\nhigher level of diversity in the augmented data, capturing\nvariations in spacing, word order, and subtle semantic nuances\nwithin the content [33].\nFollowing the generation of new data, a post-processing step\nis performed to include only valid and unique examples in the\nfinal augmented dataset. Specifically, we examined whether\nproper, plausible information such as contact numbers, web links\n(URLs), and company names were embedded within smishing\ntexts. Each example must integrate these elements seamlessly and\nrealistically, as they are central to the authenticity of smishing\nattempts. We also rigorously filtered out any outputs that\nimproperly formatted this information, such as those including\nplaceholders or brackets (e.g., [Fake URL], [Recipients]) that did\nnot meet our quality standards. This meticulous scrutiny helped\nin refining the augmented dataset, ensuring that it closely mimics"}, {"title": "4 EXPERIMENT", "content": ""}, {"title": "4.1 Experiment Setting", "content": "As the LLMs for data augmentation, we employed OpenAI's API\nof GPT-3.5-turbo and GPT-4-turbo. The temperature of the LLM,\nwhich determines the degree of randomness of text generation,\nwas set to 0.85 to ensure diverse outcomes [13].\nAdditionally, we experimented with open-source language\nmodels such as Meta's Llama-2-7b-hf and Llama-2-7b-chat-hf\nunder the same settings. However, the use of Llama-2 models into\nour data augmentation process did not yield expected results. The\ngenerated outputs frequently failed to comply with our specific\nrequirements for crafting realistic smishing texts, such as stating,\n'I'm just an AI, I cannot generate smishing messages that are\ndesigned to deceive or harm individuals.' While such responses\nalign with ethical AI guidelines, they fall short of our project's\nneeds to create authentic and actionable smishing examples for\nmodel training. Given its inability to produce the necessary\nsmishing content, we excluded Llama-2 models from our\nexperiments.\nOur approach was tested compared against the following\nthree baseline datasets:\n\u2022 Original The dataset of [20].\n\u2022 Easy Data Augmentation (EDA) The datasets, developed by\n[32] which manipulates sentences through four techniques-\nSynonym Replacement (SR), Random Insertion (RI), Random\nSwap (RS), and Random Deletion (RD). (We followed a specific\nguideline of [32] see Appendix A.2)\n\u2022 Without theoretical components The LLM-based augmented\ndataset following previous studies on text data augmentation [33].\nSpecifically, we underwent the same augmentation process as\nours except for the inclusion of \\(P_{persuasion-type}\\), in its prompt.\nWe conducted our experiments with varying levels of\naugmentation: twofold, fivefold, and tenfold. For the twofold\naugmentation, both EDA and theory-based approaches resulted in\n1,802 instances, compared to 901 instances in the original dataset.\nWhen augmented fivefold, the total number of instances grew to\n4,505. Finally, for the tenfold augmentation, the number of\ninstances reached 9,010. This augmentation applied to both spam\nand smishing data, leading to proportional increases in the overall\ndataset size.\nFor each dataset, we employed multiple ML models to conduct\nthe binary classification of distinguishing smishing messages\nfrom spam messages. Specifically, we used BERT and RoBERTa\nwith different numbers of model parameters, ranging from BERT-\nbase (110M) to BERT-large (340M) and ROBERTa-base (125M) to\nROBERTa-large (355M; [8]). This allowed us to analyze the\ninfluence of data augmentation across varying model sizes while\ncontrolling the impact of model architecture. In addition, we\ntested our approach with much smaller models such as DistilBERT\n(66M; [8]) and ALBERT (11M). (Model details are included in\nAppendix A.3)\nWe trained the models up to 10 epochs with the AdamW\noptimizer [15] and chose the best performing model exploring the\nfollowing space of hyperparameters: the batch size of {8, 16, 32}\nand the learning rate of {1e-6, 5e-6, 1e-5, 5e-5}."}, {"title": "4.2 Descriptive Analyses", "content": "Before reporting on the impact of our augmentation framework\non smishing detection, we first present descriptive analyses\nregarding the characteristics of the augmented texts from both\nquantitative and qualitative perspectives."}, {"title": "4.2.1 Quantitative Analysis.", "content": "In Figure 3 and Appendix A.4, we\nshow metrics including the minimum, maximum, average, and\nstandard deviation of both character counts and word counts of\nthe augmented data. The results show that LLM-based prompt\nengineering (i.e., GPT-3.5-turbo, GPT-4-turbo) with theoretical\ngrounding produces the longest and most detailed texts, due to\nthe use of persuasive principles. Texts generated without\ntheoretical grounding are moderately longer and more complex\nthan the original and EDA datasets but less diverse than theory-\nbased texts. EDA methods have minimal impact, showing only\nminor syntactic changes, which suggests a limited improvement"}, {"title": "4.2.2 Qualitative Analysis.", "content": "LLM-based prompt engineering\nwith theoretical grounding produces the most realistic, coherent,\nand persuasive texts (see Appendix A.4). These texts effectively\nleverage psychological factors (i.e., urgency, fear of loss, and\nexclusivity), urging immediate actions. In comparison, texts\ngenerated without theoretical guidance are compelling but lack\nthe systematic persuasiveness of theory-based prompts. EDA\nmethods, while simple, often result in less coherent and less\npersuasive texts due to their straightforward augmentation\ntechniques.\nOverall, our theory-based prompt engineering demonstrates\nhigh quality in terms of the realistic aspect and diversity of\naugmented texts, making them more suitable for smishing\ndetection model training. Simple EDA methods, despite their ease\nof implementation, show the least improvement in text quality\nand diversity."}, {"title": "4.3 Smishing Detection Results", "content": "In Table 1, we summarize the overall F1 Score result (full results\nincluding precision, recall, and accuracy are presented in\nAppendix A.5). Overall, our augmentation method yields\nsignificant improvement in performance compared to the original\ndataset. Specifically, the best performing model in F1 Score was\nthe ROBERTa-large trained on the dataset augmented tenfold with\nthe theory for both GPT-3.5-turbo and GPT-4-turbo (i.e., 98.2%,\n96.0%), each improving the best performing model trained on the\noriginal dataset by 5.3% and 3.1% respectively.\nAdditionally, among the comparisons between the augmented\ndatasets, ML models trained on the augmented datasets with our\ntheory-based approach consistently produced better results than\nthose trained on datasets augmented by EDAs and by the without-\ntheory approach for both GPT-3.5-turbo and GPT-4-turbo.\nHowever, there are some exceptions to this trend. Models\nsuch as ALBERT and DistilBERT occasionally did not follow the\npattern of improvement seen with larger models, showing less\nconsistent gains when augmented with theory. We suspect that\nthis might be due to their small number of parameters, which may\nnot require a large amount of data for training. However, the\noverall performance trend strongly favors the use of our theory-\nbased augmentation, indicating its effectiveness in enhancing\nmodel performance across most scenarios.\nAnother notable observation is that the increase in\naugmentation folds does not consistently lead to improved F1\nscores in EDAs and the without-theory approach. The\nperformance of different models and conditions varies, and there\nis no clear positive correlation with the augmentation folds for\nEDAs and the without-theory approach. In contrast, our theory-\nbased data augmentation approach shows a more consistent and\npositive correlation between increased augmentation folds and\nimproved F1 scores. That is, models generally perform better as\nthe augmentation folds increase from 2x to 5x to 10x (see Figure\n4).\nOur theory-based approach leverages psychological principles\nto create more realistic and diverse data samples, enhancing the\nmodels' ability to generalize and improve performance. This\npositive correlation is especially evident in models like ROBERTa\nand BERT where significant improvements are observed with\nhigher augmentation folds. In comparison, models trained on\ndatasets augmented without theory or by EDAs show moderate\nimprovements, indicating the importance of incorporating\npsychological principles in data augmentation to maximize model\nperformance. Thus, we conclude that integrating theoretical\ngrounding into prompt engineering significantly enhances the\nquality and effectiveness of augmented datasets, making them\nmore suitable for effectively training smishing detection models."}, {"title": "5 CONCLUSION", "content": "Smishing poses significant societal risks, highlighting the\nimportance of developing effective computational methods for its\ndetection [28]. However, due to the sensitive nature of the\ninformation involved, collecting ground-truth data for smishing\nhas been exceptionally challenging [18, 28]. To this end, we\nsuggested a theory-based data augmentation approach for\nautomated smishing detection. Specifically, grounded in the\nprinciples of persuasion, we captured and incorporated the\nunderlying mechanism behind the creation smishing messages\ninto the prompt design for the LLM-based data augmentation. Our\nevaluation across multiple scenarios reveals that the application\nof persuation theories in prompt engineering for data\naugmentation does improve data quality and, hence, enhances\nmodel performance.\nThe contributions of our study are manifold. First, from the\nacademic perspective, it extends the extant literature on prompt-\nengineering-based data augmentation. To the best of our\nknowledge, our study is the first to incorporate social science\ntheories into the prompt design for data augmentation. In addition,\nfrom the industry perspective, our approach can help save costs\nassociated with collecting and crafting smishing messages\nrequired for training ML models. Lastly, our approach contributes\nto our society by helping individuals avoid falling victims to\nsmishing.\nHowever, our study is not without limitations, which\nnecessitate further exploration in the future studies. First, in\ndeveloping theory-based prompts, we assumed that smishing\nmessages aligned with only one persuasion principle. While this\nassumption is based on the framework proposed by [5], which\nsuggests minimal overlap among different principles, it is also\npossible that smishing messages could belong to multiple\npersuasion categories, which should be further investigated. In\naddition, while the purpose of our approach is to minimize human\nefforts in data augmentation, it still requires some degree of\nmanual processing. For instance, implementing our approach\nrequires smishing messages initially annotated with persuasion\nprinciples.\nFurthermore, there are some ethical concerns that need to be\ncarefully considered before implementing our approach in\npractice. For instance, one of the key concerns raised in\ncybersecurity research is the dual-use problem [31], where\ntechnological innovations can be exploited by malicious actors for\nharmful purposes. The approach proposed in this paper faces a\nsimilar issue, as it could potentially be misused by hackers,\nallowing them to evade the exposed strategies and devise\nworkarounds. However, we argue that gaining a deeper\nunderstanding of the implicit strategies behind smishing attacks\nwill actually help us comprehend the fundamental mechanisms\nhackers use. If hackers attempt to bypass these core strategies,\nthey may inadvertently weaken the effectiveness of their own\nattacks."}, {"title": "A APPENDIX", "content": ""}, {"title": "A.1 Principles of Persuasion Details", "content": ""}, {"title": "A.2 EDA [32] Guidelines", "content": "The augmentation parameter, a, crucially determines the extent\nof word alterations per sentence, calculated as \\(n = a \\times l\\), where n\nis the number of words changed, a is the augmentation factor, and\nl is the sentence length. [32] found \\(a = 0.1\\) to be optimal (\"Sweet\nSpot\") for enhancing performance without significantly distorting\nthe text:\n\u2022 SR: Randomly replace n words with synonyms.\n\u2022 RI: Randomly insert n synonyms into the sentence.\n\u2022 RS: Randomly swap n pairs of words.\n\u2022 RD: Randomly delete each word with a probability of \\(p =a\\)."}, {"title": "A.4 Quantitative and Qualitative Analysis", "content": ""}, {"title": "A.3 Model Details", "content": ""}]}