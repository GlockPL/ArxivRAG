{"title": "SEF: A Method for Computing Prediction Intervals\nby Shifting the Error Function in Neural Networks", "authors": ["Efstratios V. Aretos", "Dimitris G. Sotiropoulos"], "abstract": "In today's era, Neural Networks (NN) are applied in various scientific fields such as robotics, medicine,\nengineering, etc. However, the predictions of neural networks themselves contain a degree of uncertainty that\nmust always be taken into account before any decision is made. This is why many researchers have focused on\ndeveloping different ways to quantify the uncertainty of neural network predictions. Some of these methods are\nbased on generating prediction intervals (PI) via neural networks for the requested target values. The SEF (Shifting\nthe Error Function) method presented in this paper is a new method that belongs to this category of methods. The\nproposed approach involves training a single neural network three times, thus generating an estimate along with\nthe corresponding upper and lower bounds for a given problem. A pivotal aspect of the method is the calculation\nof a parameter from the initial network's estimates, which is then integrated into the loss functions of the other\ntwo networks. This innovative process effectively produces PIs, resulting in a robust and efficient technique for\nuncertainty quantification. To evaluate the effectiveness of our method, a comparison in terms of successful PI\ngeneration between the SEF, PI3NN and PIVEN methods was made using two synthetic datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "Neural networks are applied in various areas of human activity, such as the economy (e.g. prediction of stock prices\nor various economic indicators), medicine (e.g. prediction and diagnosis of diseases), transport (e.g. autonomous\ndriving, safety assistance systems), etc. Neural networks have a highly successful track record in modeling complex\nsituations and phenomena, often providing accurate answers to complex classification problems, regression, etc.\nHowever, in many cases, the predictions of neural networks involve a degree of uncertainty, which in many cases,\nsuch as in autonomous driving and medical diagnosis, can be fatal if not considered. It is therefore no coincidence\nthat in recent years scientific research has focused on quantifying the uncertainty of neural network predictions\nwhile ensuring that these predictions still provide satisfactory answers to given problems [1].\nOne of the most common methods for uncertainty quantification (UQ) is to use prediction intervals (PI). In\npractice, the neural network is used so that its final response is given in the form of intervals intended to estimate\nthe interval within which a future observation is likely to lie. This practice is beneficial in cases where we have a\nregression problem in which a continuous value has to be estimated and predicted, such as an economic indicator\nor temperature, etc. In this way, decision making can be made more accessible, as knowing the interval range in\nwhich the final value of the phenomenon under study is expected to fluctuate makes it easier to choose the next\nsteps or actions. Thus, using neural networks to create prediction intervals finds application in many problems of\neveryday life, such as sales forecasting, business risk analysis, weather forecasting, energy demand forecasting, etc.\n[1]."}, {"title": "A. Related work", "content": "The first papers aimed at creating methods to quantify uncertainty appeared about 25 years ago [2]-[4], but the\nnumber of publications has increased in recent years. Two widely used methods for uncertainty quantification are\nthe Bayesian approximation and ensemble learning techniques [1], [5], [6]. Many articles focus on Bayesian neural\nnetworks to quantify the uncertainty associated with deep neural network predictions using variational inference,\nsampling approaches, or Laplace approximation [5], [7], [8]. This category also includes Monte Carlo and dropout\nmethods [2], [9]. Methods using ensemble techniques create forecasts based on predictions obtained from multiple\nmembers of a model ensemble [5]. There are empirical ensemble approaches [10], methods that use ensemble\npruning algorithms such as deep ensemble [11], and Bayesian ensemble learning [12].\nMore modern methods are based on the calculation of prediction intervals (PIs), which are derived from the\noutput of a neural network, ensuring that the prediction value falls within the bounds for a specified confidence\nlevel \u03b3. Examples of such methods include the SQR method [13], which proposes a loss function to learn all the\nconditional quantiles of a given target variable, and methods like LUBE [14], QD [15], and IPIV (or PIVEN) [16],\n[17], which use modified loss functions containing appropriate hyperparameters to minimize the width of the lower\nand upper bounds while meeting the required confidence level. Furthermore, the PI3NN method [18] uses three\nneural networks to generate a point estimate, as well as the upper and lower bounds of the prediction interval."}, {"title": "B. Motivation", "content": "Although previous methods for finding suitable PIs, such as QD [15], SQR [13], and IPIV [16], have been\nsuccessful, they also present certain disadvantages and limitations. i) Often employ complex loss functions that\ninclude multiple hyperparameters to achieve optimal PIs. The extensive use of these hyperparameters typically\nmakes these methods time-consuming, requiring precise tuning to be efficient. Determining the appropriate pa-\nrameter values can be challenging, and the parameters often need to be readjusted for each problem. ii) Require\nsubstantial computational resources and extensive memory use. Generating appropriate PIs frequently involves\ncomplex procedures or custom architectures, increasing the computational difficulty. iii) Applying these methods\nuniversally across different problems is often impractical, as each new problem may necessitate specific adjustments\nand redesigns of the implementation method.\nAll of the above has been the motivation for our research. We tried to create a new method of creating PIs\nwithout the shortcomings of the previous methods. Our efforts led us to the SEF (Shifting the Error Function)\nmethod."}, {"title": "C. Objectives-Organization of the paper", "content": "The SEF method presented in this paper focuses on using appropriate neural networks to produce satisfactory\nPIs for any given problem, but at the same time corrects the weaknesses of other methods such as, among others,\ncomplex architectures-structures and the existence of non-self-adjusting parameters. SEF method generates with\nthe help of 3 neural networks suitable PIs that encapsulate the desired real targeting values satisfying a predefined\nconfidence level y and have the smallest possible width in order to ensure the practical usefulness of the method.\nMore specifically, in this paper with the presentation of the SEF method we try to present the main advantages of\nthe SEF method which are:\n\u2022\tits universal application to any regression problem,\n\u2022\tits ease of application as it does not require complex network architectures or complex error functions\n\u2022\tits application is not computationally expensive nor does it require complex time-consuming procedures\n\u2022\tno need to manually find the optimal value of the hyperparameter it uses, as it is calculated automatically in\nthe process\nFor this reason, the following structure is followed in this paper: in Section II a presentation of the proposed SEF\nmethod is given first by formulating and formalizing the problem to be solved (subsection II-A), then by analyzing\nthe steps of the main algorithm (II-B) and finally justifying the whole procedure (II-C). In Section III an application\nof the SEF method to two synthetic datasets is conducted and the results are compared with the results of two other\nrecent PI construction methods, the PI3NN method and the PIVEN method. In Section IV we present the main\nconclusions we have reached in this paper and in Section V we discuss the direction we will take in future steps."}, {"title": "II. THE PROPOSED SEF METHOD", "content": null}, {"title": "A. Problem Formulation", "content": "Consider a dataset $D = \\{(X_i, Y_i)\\}_{i=1}^n$ where each $X_i \\in \\mathbb{R}^d$ represents a d-dimensional input vector and $y_i \\in \\mathbb{R}$ is\nthe corresponding target value. The objective is to construct prediction intervals (PIs) $(l_i, u_i)$ for each target value\n$y_i$ with a desired confidence level $\\gamma \\in (0,1)$ (typically $\\gamma = 0.95$ or $\\gamma = 0.99$), such that the following conditions\nhold:\n\u2022 $P(l_i \\leq Y_i \\leq u_i) \\geq \\gamma$\n\u2022 $P(y_i < l_i) = P(Y_i > U_i) = \\frac{1-\\gamma}{2}$\nHere, $l_i$ and $u_i \\in \\mathbb{R}$ represent the lower and upper bounds of the PI for each $y_i$, respectively. The desired\nconfidence level $\\gamma$ indicates the probability that the true value $y_i$ falls within the interval $(l_i, u_i)$. Define a vector\n$K = \\{k_i\\}$, where $k_i$ is an indicator function defined [15] as\n$k_i = \\begin{cases}\n1, & \\text{if } l_i \\leq y_i \\leq u_i \\\\\n0, & \\text{otherwise}.\n\\end{cases}$\nThe vector $K$ essentially denotes whether each target value $y_i$ is encapsulated within its corresponding PI. The\nprediction interval coverage probability (PICP) [15] quantifies the proportion of target values ($y_i$) prediction\ncontained within their respective PIs. It is calculated as follows:\n$PICP = \\frac{1}{n} \\sum_{i=1}^{n} k_i$\nIn practice, our objective is to ensure that $PICP > \\gamma$. Furthermore, the mean prediction interval width (MPIW)\n[15] is defined as\n$MPIW = \\frac{1}{n} \\sum_{i=1}^{n} (u_i - l_i)$\nwhich measures the average width of the PIs and should be minimized, provided that the condition $PICP \\geq \\gamma$ is\nsatisfied. Another measure that is used is the Normalized MPIW (NMPIW),\n$NMPIW = \\frac{MPIW}{R}$\nwhere $R$ corresponds to the range of target values and allows us to compare PIs from different datasets [6]. The\ngoal is to construct prediction intervals $(l_i, u_i)$ that achieve a high coverage probability ($ \\geq \\gamma$) while keeping the\nintervals as narrow as possible."}, {"title": "B. The SEF Algorithm", "content": "The proposed method involves four main steps that require the training of three neural networks (NN). These\nnetworks share the same architecture, differing only in the constants added to their loss functions to achieve\ndifferent objectives. The primary advantage of this approach is that it simplifies the implementation and enhances\nexecution speed by avoiding extensive hyperparameter tuning beyond the initial network's essential parameters. In\nwhat follows, we describe the four steps of the SEF algorithm.\nStep 1: Training the initial estimator. This step involves training a neural network to solve a regression problem\nby approximating the target values ($y_i$). Let NNapprox be a neural network with an architecture defined by the\nnumber of layers, nodes within each layer, activation functions, and other hyperparameters. This network produces\npredictions $\u0177_i = NNapprox(X_i;0)$, while the network parameters @ are optimized by minimizing the mean squared\nerror (MSE) loss function\n$L(0) = \\frac{1}{n} \\sum_{i=1}^{n} (NNapprox (X_i; \\theta) \u2013 Y_i)^2$.\nThe goal is to train the first neural network to accurately approximate the target values \u0177, where y = NNapprox(X).\nTo achieve this, it is essential to prevent overfitting and ensure generalization. Various regularization techniques,"}, {"title": "C. Justification", "content": "To understand the justification for our algorithm from a geometrical perspective, let us depict pairs $(y_i, \u0177_i)$ in a\ncoordinate system, where the horizontal axis represents the actual target values $y_i$, and the vertical axis represents\nthe predicted values \u0177r. By analyzing this illustration, we can grasp the concept behind the SEF algorithm.\nThe bisector of the first and third quadrants is the line where $y = \u0177_i$. This line represents perfect predictions,\nwhere the predicted value exactly matches the target value. Any point on this line indicates that the prediction error\nis zero.\nPoints above the line $y = \u0177_i$ correspond to instances where the predicted value \u0177 is greater than the actual target\nvalue $Y_i$ ($Y_i > y_i$). This indicates that the model is overestimating the target value. In contrast, points below the"}], "equations": ["k_i = \\begin{cases}\n1, & \\text{if } l_i \\leq y_i \\leq u_i \\\\\n0, & \\text{otherwise}.\n\\end{cases}", "PICP = \\frac{1}{n} \\sum_{i=1}^{n} k_i", "MPIW = \\frac{1}{n} \\sum_{i=1}^{n} (u_i - l_i)", "NMPIW = \\frac{MPIW}{R}", "L(0) = \\frac{1}{n} \\sum_{i=1}^{n} (NNapprox (X_i; \\theta) \u2013 Y_i)^2.", "m1 =\\lfloor \\frac{(1-\\gamma)}{2}.n \\rfloor \\text{ and } m2 =\\lceil \\frac{(1+\\gamma)}{2}.n \\rceil", "\u03bc = max (|\u0431\u0442\u2081 |, |\u0431\u04422 |) .", "Llower (0) = \\frac{1}{n} \\sum_{i=1}^{n} [NNlower (X_i; \\theta) \u2013 (Yi \u2013 \u03bc)]^2.", "Lupper(0) = \\frac{1}{n} \\sum_{i=1}^{n} [NNupper (X_i; 0) \u2013 (Yi + \u03bc)]^2 .", "li = Yi - Ei and ui = Yi + \u20ac\u00a1.", "\\sum_{i=1}^{n}k_i = \\gamma,", "l = y - \u03bc", "u = y + \u03bc", "li = Yi - Ei and ui = Yi + \u20ac\u00a1."]}