{"title": "Interpretable Triplet Importance for Personalized Ranking", "authors": ["Bowei He", "Chen Ma"], "abstract": "Personalized item ranking has been a crucial component contributing to the performance of recommender systems. As a representative approach, pairwise ranking directly optimizes the ranking with user implicit feedback by constructing (user, positive item, negative item) triplets. Several recent works have noticed that treating all triplets equally may hardly achieve the best effects. They assign different importance scores to negative items, user-item pairs, or triplets, respectively. However, almost all the generated importance scores are groundless and hard to interpret, thus far from trustworthy and transparent. To tackle these, we propose the Triplet Shapley-a Shapely value-based method to measure the triplet importance in an interpretable manner. Due to the huge number of triplets, we transform the original Shapley value calculation to the Monte Carlo (MC) approximation, where the guarantee for the approximation unbiasedness is also provided. To stabilize the MC approximation, we adopt a control covariates-based method. Finally, we utilize the triplet Shapley value to guide the resampling of important triplets for benefiting the model learning. Extensive experiments are conducted on six public datasets involving classical matrix factorization- and graph neural network-based recommendation models. Empirical results and subsequent analysis show that our model consistently outperforms the state-of-the-art methods.", "sections": [{"title": "1 INTRODUCTION", "content": "Personalized ranking is widely regarded as the essence of recommender systems (RS) [33]. It ranks the recommended items according to user preferences to make the most relevant items appear at the top of the recommendation list, thereby improving user satisfaction and the benefits of service providers. To enable personalized ranking, implicit feedback (e.g., check-ins and clicks) is more broadly utilized than explicit feedback (e.g., ratings), due to its accessibility. Hereby, many approaches have been proposed using implicit feedback. Among them, Bayesian Personalized Ranking (BPR) [33] is one of the most representative paradigms that can be incorporated in many different types of methods like matrix factorization (MF)-based models [1, 17, 26], and graph neural network (GNN)-based models [14, 16, 25, 38, 40, 42]. In detail, BPR constructs (user, positive item, negative item) triplets and optimizes the pairwise ranking score between positive and negative (randomly sampled) items for each triplet. Indeed, the quality of constructed triplets largely affects the ranking performance, especially when negative items are randomly sampled from non-interacted items. Because a user may have different preference levels for positive items, and it is hard to tell whether the randomly sampled items are truly negative and how negative they are. Therefore, it is highly necessary to further distinguish the importance of such triplets.\nTo discern the triplet importance, four main categories of methods have been proposed: negative item sampling, positive pair re-weighting, using auxiliary information, and triplet importance modeling. Among them, negative item sampling techniques [8, 29, 32] prioritize items differently during the training process, based on criteria such as item popularity or user engagement. While this approach can enhance the model\u2019s focus on more influential negative items, it can induce biases by over-representing popular items and under-representing less common but potentially significant items. Positive pair re-weighting methods [41] adjust the influence of user-item interactions within the model by assigning different weights to them. The approaches in such two categories have recognized the necessity of applying different weights to positive or negative items. However, they only focus on the part of the triplet and neglect the whole, as illustrated in Figure 1. For the methods of using auxiliary information [24, 30, 45, 47], they rely on the side information like dwell time that is often unavailable in practical settings. In addition to these three types of methods, triplet importance modeling [44] advances one step further and takes the whole triplet into consideration. By dispatching triplet-level importance, this method can distinguish the contribution of each triplet in the training. However, these works either use a heuristic approach or directly utilize a black-box neural network module [44] to generate the triplet importance, where such importance scores are groundless and hard to interpret. The lack of interpretability will make both the importance score and the recommendation model less trustworthy, and even less fair due to the potential unknown bias introduced in importance generation. Besides, they fail to bring insights on how to adjust the sampling strategy, which wastes massive high-importance triplets that can be easily accessed with resampling, thus restricting the further improvement of model performance.\nTo overcome aforementioned drawbacks, we propose a more interpretable approach to generate the importance of each triplet and"}, {"title": "2 RELATED WORK", "content": "Implicit Feedback in Recommendation. Due to the easier accessibility than explicit feedback like rating scores [35, 36] in most recommendation scenarios, the implicit feedback like historical clicking or browsing behaviors has become the main data source in personalized recommender system. Actually, there have been many recommendation models developed to utilize the implicit feedback for conducting personalized ranking, from the conventional MF [26] and KNN [6] to the recent deep neural network-based NeuMF [17], NGCF [42], and LightGCN [16]. BPR [33] first notices that few of previous methods are directly optimized for the personalized ranking and proposes to address this challenge by constructing (user, positive item, negative item) triplets and pairwise training. In detail, BPR proposes the maximum posterior estimator derived from the Bayesian analysis to the problem. Based on this, some improvement schemes have also been proposed, like negative item sampling [8, 29, 32], positive pair re-weighting [41], using auxiliary information [24, 30, 43, 45, 47]. Futhermore, many real-world observations and empirical results have demonstrated that different triplets contribute differently to the model training performance. To prevent the performance loss due to treating all triplets equally, TIL [44] leverages a neural network to learn the triplet importance end-to-end. However, previous methods either use a heuristic approach or an unexplainable blackbox model to generate the triplet importance. It is hard to understand why assigning such triplet"}, {"title": "3 PRELIMINARIES", "content": "In this section, we first formulate the top-K recommendation task. Then, we review the Bayesian Personalized Ranking paradigm which is the foundation of our method.\nProblem Formulation\nThe recommendation task in this paper leverages the user implicit feedback as input. Let U and V denote the set of all users and items in the system, respectively.  $Y \\in \\mathbb{R}^{|U|\\times|V|}$ is the binary implicit feedback rating matrix. For each user $u \\in U$, the user preference data is represented by the set of items in his/her interaction history as $I_u = \\{i \\in V|Y_{u,i} = 1\\}$. The top-K recommendation task is then formulated: for each user $u \\in U$, given the training item set $S_u$ and the non-empty test item set $T_u$ (requiring that $S_u \\cap T_u = I_u$ and $S_u \\cap T_u = \\emptyset$), the model needs to recommend an ordered item set $X_u$ such that $|X_u| = K$ and $X_u \\cap S_u = \\emptyset$. Then, the recommendation quality is evaluated with some matching scores between $X_u$ and $T_u$, like Recall@K and NDCG@K.\nBayesian Personalized Ranking\nBayesian Personalized Ranking (BPR) has been widely integrated with many recommendation models and achieved great success in many real-world production scenarios [13, 16, 17, 26, 42]. The BPR method mainly consists of two parts: triplet construction and pairwise training. The details of them are as follows.\nTriplet Construction. Based on the assumption that the users prefer the interacted (positive) items over the uninteracted (negative) ones, the triplet construction space $D_s = U \\times V \\times V$ is first formalized by:\n$\\qquad D_s := \\{(u, i, j)|i \\in I_u, j\\in V\\setminus I_u\\},$\\nwhere for triplet $(u, i, j) \\in D_s$, i is the positive item, and j is the negative item. However, directly traversing all the triplets in $D_s$ for recommendation modeling learning will bring huge computation costs and poor convergence, which hinders effective training. Therefore, BPR chooses the triplets uniformly from the triplet construction space $D_s$. In detail, for each user and positive item pair (u, i), BPR uniformly samples a constant number (usually no more than ten) of negative items j, and thus obtains a triplet set $D_T$ for further training recommendation models.\nPairwise Training. Based on the Bayesian formulation of learning the correct personalized ranking for all items, BPR proposes the maximum posterior estimator to derive the generic optimization criterion (loss function) for personalized ranking. Specifically, BPR contrasts the user-positive item pair (u, i) with user-negative item pair (u, j) in each triplet $(u, i, j) \\in D_T$ to guide the model capturing the user u's preference:\n$\\qquad L_{BPR}(u, i, j; \\theta) = -ln \\sigma(\\hat{y}_{ui}(\\theta) - \\hat{y}_{uj}(\\theta)),$ (2)\nwhere $\\theta$ indicates the parameters of the recommendation model, like MF-based (MF [26], NeuMF [17]) and GNN-based ones (NGCF [42], LightGCN [16]). $\\hat{y}$ is an arbitrary real value representing the model's prediction of the user preference. $\\sigma(\\cdot)$ is the Sigmoid function."}, {"title": "4 METHODOLOGY", "content": "In this section, we first follow the triplet importance model approach and introduce the triplet importance-based weighted pairwise learning. Then, we propose the triplet Shapley as the interpretable and equitable importance to tackle the transparency and fairness issues of the existing methods. It also serves as the more discriminative triplet weight to facilitate pairwise learning. Next, we re-examine the triplet Shapley formulation from the joining process perspective and utilize the descent-based Monte Carlo method to approximate the triplet Shapley. Besides, we provide a control covariates scheme to stabilize the triplet Shapley estimation. Finally, we build a triplet importance prediction model to guide the triplet resampling, so as to adaptively augment the original constructed triplets.\nTriplet Importance for Pairwise Learning\nAlthough Bayesian personalized ranking has been successfully integrated into many recommendation models, it equally treats all triplets which may not capture the fine-grained user preference, since users have different preference levels on different items. Moreover, a randomly sampled item does not necessarily mean that the user dislikes it, especially for those similar to the positive items. These motivate us to assign importance scores to different triplets to facilitate the personalized ranking. To incur the triplet importance into the original BPR loss, we adopt the formulation from the previous work [44] as follows,\n$\\qquad L_{TI-BPR}(u, i, j; \\theta) = -W_{TI}^{(u,i,j)} ln \\sigma(\\hat{y}_{ui}(\\theta) - \\hat{y}_{uj}(\\theta)),$ (3)\nwhere $W_{TI}^{(u,i,j)}$ is the triplet importance of the triplet (u, i, j) for the BPR loss.\nTriplet Shapley as Interpretable Importance\nAlthough previous approaches [8, 29, 32, 41, 44] have been proven to enhance Bayesian pairwise user preference learning, few of them pay attention to the interpretability and equitability of the modeled triplet importance. Moreover, due to the black-box property"}, {"title": "5 EXPERIMENTS", "content": "In this section, we conduct experiments on several public datasets to demonstrate the effectiveness, applicability, interpretability, and time efficiency of our method. In the experiments, we mainly focus on answering the following questions:\nRQ1: Whether our method can achieve better recommendation performance than other baselines utilizing implicit feedback?\nRQ2: Whether the superiority of our method can be consistently performed when selecting different MF-based and GNN-based recommendation models as the backbone?\nRQ3: Does each component of our method contribute to the performance improvement (Ablation study)?\nRQ4: Can our method provide a reasonable and intuitive explanation to the importance score assigned to each triplet?\nRQ5: Whether our control covariate-based method can effectively stabilize the triplet Shapley approximation, thus leading to more reliable triplet Shapley values?\nRQ6: Whether the time complexity of our method is still acceptable considering the substantial computation cost brought by the triplet Shapley? In other words, Can our approximation approach effectively reduce the training time cost?\nExperiment Setup\nDatasets. We evaluate our method on six public datasets: Amazon-Books [15], Amazon-CDs [15], Yelp [2], Gowalla [3], ML-20M [12], and ML-Latest [12]. To accommodate the implicit feedback setting, for the datasets with explicit ratings, we preserve the ratings more than three (out of five) as positive feedback and treat all other ratings as missing entries.\nBaselines. Generally, previous works on utilizing implicit feedback for personalized ranking can be divided into four categories. Note that we do not compare with works on using auxiliary information considering this kind of information is often inaccessible. In experiments, we use representative works in left three categories as our baselines:\nNegative item sampling:\nWBPR [8]: This method assigns more sampling probabilities to the negative items with higher global popularity.\nAOBPR [32]: It adopts a context-specific adaptive sampler to oversample popular negative items.\nPRIS [29]: It utilizes the importance sampling to obtain negative samples according to their informativeness.\nPositive pair re-weighting:\nTCE and RCE [41]: They adaptively prune noisy positive interactions with large loss values in the training.\nTCE-BPR and RCE-BPR: The modified versions of the above two methods in which the point-wise loss is replaced with a pair-wise ranking loss following BPR's scheme.\nTriplet importance modeling:\nTIL-UI and TIL-MI [44]: They design a neural network-based weight generation module to learn triplet importance.\nResults and Analysis\nOverall Performance (RQ1). We provide the experiment results of all baselines and our ITIPR with different base recommendation models on six public datasets in Tabel 1. First, it can be noticed that triplet importance modeling methods: TIL-UI, TIL-MI, ITIPR achieve significantly better results than other types of methods, which validates the rationality of considering the personalized ranking problem from the triplet-level importance modeling perspective. Second, from the table, we can observe obvious performance improvement of our ITIPR over previous negative item sampling, positive pair re-weighting, using auxiliary information, and triplet importance modeling baselines in all public datasets on both Recall@20 and NDCG@20 metrics. In detail, ITIPR outperforms the best-performing baseline by 9.16% and 9.62% averagely on Recall@20 and NDCG@20 metrics, respectively, under all settings. This demonstrates that our triplet Shapley-based interpretable triplet"}, {"title": "6 CONCLUSION AND FUTURE WORKS", "content": "In this paper, we introduce the triplet Shapley for interpretable triplet importance measurement in Bayesian personalized ranking and improve assessment through a Monte Carlo method with control covariates to reduce variance. Our method, combined with importance-aware resampling, enhances recommendation model training. Experiments on six datasets confirm our approach's effectiveness and efficiency. Future work will focus on efficient computation for large-scale data in practical applications."}, {"title": "A SUPPLEMENTARY PRELIMINARIES", "content": "A.1 Main Notations\nThe main notations in this paper are summarized in Table 4.\nA.2 Base Recommendation Models\nMatrix factorization (MF)-based models [1, 17, 26] and Graph Neural Network (GNN)-based models [16, 25, 38, 40, 42] are two categories of most representative and commonly used recommendation models. In this paper, we adopt some popular and effective instances of them to demonstrate the applicability and robustness of our proposed framework. We provide the brief introduction as follows.\nMF-based Models: MF [26] is a pioneer and fundamental method in this line of research. In MF, the user-item interaction matrix is factorized into two matrices that represent the embeddings of users and items. The inner product of user u's embedding $p_u$ and item i's embedding $q_i$ is used to predict the user-item interaction between them:\n$\\qquad \\hat{Y}_{u,i} = p_u^T q_i.$\\nThe goal of MF is to minimize the difference between the predicted and actual ratings. Neural Matrix Factorization (NeuMF) [17] is an extension of MF that uses neural networks to learn embeddings of users and items, which allows more complex interactions between them. The output of the neural network which utilizes the u's embedding $p_u$ and item i's embedding $q_i$ as the input is used to predict the user-item interaction between them:\n$\\qquad \\hat{y}_{u,i} = MLP(p_u q_i, MLP(p_u, q_i)),$ (15)\nwhere MLP represents the multi-layer perceptron. NMF has been shown to outperform traditional MF in terms of prediction accuracy and scalability.\nGNN-based Models: Neural Graph Collaborative Filtering (NGCF) [42] is a graph-based recommender system model that leverages the power of GNN to learn user and item embeddings. NGCF considers the user-item interactions as a bipartite graph and uses GNN to propagate information between connected nodes in the graph. The"}, {"title": "B SUPPLEMENTARY METHODOLOGY", "content": "B.1 Proof for Theorem 1\nWe provide the following proof for the Theorem 1.\nPROOF. First, recall Eq. 4 and set $C = \\frac{1}{|D_T|}$. Then, the following transformation holds:"}]}