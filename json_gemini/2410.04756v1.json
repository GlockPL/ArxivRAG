{"title": "Item Cluster-aware Prompt Learning for Session-based Recommendation", "authors": ["Wooseong Yang", "Chen Wang", "Zihe Song", "Weizhi Zhang", "Philip S. Yu"], "abstract": "Session-based recommendation (SBR) aims to capture dynamic user preferences by analyzing item sequences within individual sessions. However, most existing approaches focus mainly on intra-session item relationships, neglecting the connections between items across different sessions (inter-session relationships), which limits their ability to fully capture complex item interactions. While some methods incorporate inter-session information, they often suffer from high computational costs, leading to longer training times and reduced efficiency. To address these challenges, we propose the CLIP-SBR (Cluster-aware Item Prompt learning for Session-Based Recommendation) framework. CLIP-SBR is composed of two modules: 1) an item relationship mining module that builds a global graph to effectively model both intra- and inter-session relationships, and 2) an item cluster-aware prompt learning module that uses soft prompts to integrate these relationships into SBR models efficiently. We evaluate CLIP-SBR across eight SBR models and three benchmark datasets, consistently demonstrating improved recommendation performance and establishing CLIP-SBR as a robust solution for session-based recommendation tasks.", "sections": [{"title": "1 INTRODUCTION", "content": "Session-based recommendation (SBR) has gained increasing attention due to their effectiveness in various online services [29], such as e-commerce, social media, and music platforms. Unlike traditional recommendation systems that model long-term static user preferences, SBRs focus on short-term dynamic user preferences embedded within sessions, providing more timely and accurate recommendations. Deep learning-based approaches have recently driven significant advances in SBRs by utilizing their exceptional feature representation capabilities to improve the modeling of complex user preferences embedded in sessions. Specifically, recurrent neural networks (RNNs) have been used to capture sequential dependencies within sessions by processing item sequences in order [7, 8]. Several studies employ attention mechanisms to enhance SBRs by selectively focusing on the most relevant items within a session, thereby capturing key patterns in user behavior [9, 14]. Graph neural networks (GNNs) extend these capabilities by representing sessions as graphs, allowing the models to capture intricate relationships between items through graph structures [32, 35].\nDespite the progress, most existing SBR approaches primarily focus on the sequential relations between items within a single session (intra-session item relationship), often neglecting the valuable information available across multiple sessions (inter-session item relationship). This significant limitation in inter-session modeling has been identified and proven in multiple studies [16, 22, 24, 30] as a critical issue in SBRs, hindering the accurate learning of user preferences and potentially affecting recommendation performance. To illustrate, consider three sessions for different users: session one {AirPods Pro, AirPods, AirPods Max}, session two {AirPods, Galaxy Buds, Beats Fit Pro}, and session three {Nike Dri-FIT Running Shirt, Adidas Ultraboost, Beats Fit Pro}. When focusing solely on intra-session information, we can observe that the sessions contain Apple earphones, earbuds, and running gears in each session, respectively. While the intra-session perspective provides immediate sequential insights, it struggles to capture more complex item relationships. For instance, the user of session three might also be interested in Airpods Pro instead of Beats Fit Pro, but it's challenging for the model to identify this solely from intra-session data, as there are no common items between session one and session three. In contrast, inter-session information can discover the deeper connections by linking Beats Fit Pro across session two and three, and AirPods across session one and two, bridging the gap between session one and three. This highlights the importance of inter-session information, as it enhances the understanding of user preferences beyond what intra-session information alone can achieve.\nAlthough several SBRs attempt to incorporate inter-session item relationships and some have shown effectiveness, most still face limitation in computational efficiency. Specifically, GCSAN [34] strives to utilize inter-session information but fails to fully model complex relationships between items, which limits its overall recommendation performance. In contrast, models like GCEGNN [31] and LESSR [3] demonstrate effectiveness in capturing inter-session item relationships. However, they are constrained by high computational complexity, leading to prolonged training times. These limitations underscore the need for a robust framework that can fully exploit complex item relationships across sessions while balancing both effectiveness and efficiency in SBRs.\nTo address the aforementioned challenges, we propose CLuster-aware Item Prompt learning framework for Session-Based Recomm endation (CLIP-SBR) that captures complex item relationships and efficiently embeds the information into the SBR models. To overcome the limitation in inter-session modeling, the first module, item relationship mining, constructs a global graph from session data. This graph models both intra- and inter-session item relationships in a single structure. Prior studies [3, 31, 32, 34, 35] have demonstrated the effectiveness of graph in capturing item relationships. Inspired by the approaches, the global graph represents items as nodes and item transitions as edges, allowing simultaneous modeling of relationships within and across sessions in one structure. Following graph construction, a community detection method [28] is used to identify item clusters that share similar user preferences. These clusters offer valuable insights, as items within the same cluster exhibit close relationships and similar user preferences.\nTo tackle the limitation in computational efficiency, which is the inefficiency of incorporating complex item relationships, we introduce the second module, item cluster-aware prompt learning. they suffer from high computational complexity. This module enhances the learning capabilities of SBR models efficiently by integrating learnable soft prompts for each identified item cluster. Prompt learning [17], originally introduced in natural language processing, began as a way to provide large language models with task-related information through natural language instructions, known as prompts. The concept evolved into learnable prompts, with discrete natural language prompts termed hard prompt and continuous, trainable prompts termed soft prompts. Soft prompts have demonstrated significant success due to their ability to provide task-related cues to pre-trained models during the tuning phase [13, 15, 25]. This approach has expanded to fields such as computer vision [5, 10, 36] and graph representation learning [4, 19, 26, 27], where soft prompts are used to deliver task-specific and data-related information during training. Notably, GPF [4] and SUPT [12] have proven the ability of soft prompt to deliver data-related information during tuning process. Inspired by the previous studies, we adopt soft prompts to integrate mined item relationship information into SBR models during training. By tailoring learnable soft prompts to specific item cluster, SBR models can effectively and efficiently learn user preferences embedded in session data, capturing both intra- and inter-session relationships. This comprehensive approach not only enhances recommendation performance in an efficient way but also ensures adaptability, making the CLIP-SBR framework universal across various SBR models. We examine CLIP-SBR on eight SBR baselines and three benchmark.\nTo summarize, the main contributions lie in:\n\u2022 We propose a graph-based method with community detection to design and extract complex item relationships from session data.\n\u2022 We propose a novel approach to enhance SBRs by incorporating item cluster-aware prompt into the model training phase.\n\u2022 To the best of our knowledge, CLIP-SBR is the first attempt to adopt a soft prompt to the SBR. Also, it is the pioneer work to introduce a soft prompt directly in the model training.\n\u2022 We conduct extensive experiments on five representative SBRs and three benchmark datasets to demonstrate the superiority of the proposed CLIP-SBR framework."}, {"title": "2 RELATED WORKS", "content": "2.1 Session-based Recommendation\nSession-based Recommendation (SBR) predicts the next user interaction based on recent behavior sequences, effectively capturing short-term user preferences. Recent advancements in deep learning have significantly enhanced SBRs by enabling more sophisticated modeling of item transitions within sessions. GRU4Rec [8] introduced Gated Recurrent Units (GRUs) for sequential dependency modeling, while models like NARM [14] and STAMP [18] leverage attention mechanisms to capture user intent and preference. CORE [9] addresses prediction inconsistencies by unifying session and item embeddings, reducing representation gaps. Graph neural networks (GNNs) have further improved SBRs by representing session sequences as graphs, as seen in SRGNN [34], which aggregates item information through gated GNNs, TAGNN [35] which employs target-aware attention to incorporate user interests. While these methods effectively model intra-session relationships, they often overlook the valuable inter-session information, limiting their ability to fully understand complex user behaviors. To address this, several inter-session SBRs have been proposed. GCSAN [34] uses self-attention on session graphs to capture intricate item relationships, while GCEGNN [31] combines item-level and session-level information using graph convolution and self-attention mechanisms. LESSR [3] introduces an edge-order preserving aggregation scheme and a shortcut graph attention layer to effectively capture global item relationships. Despite their effectiveness, they either inadequately capture inter-session information (GCSAN) or are computationally intensive (GCEGNN, LESSR). Our work proposes incorporating both intra- and inter-session item relationships using efficient cluster-aware prompts to enhance SBR performance.\n2.2 Prompt Learning\nPrompt learning is initially introduced in natural language processing (NLP) as a novel method to guide pre-trained language models in performing specific tasks by providing task-related information [17]. It originated with the use of discrete hard prompts: text-based instructions designed to provide task related information to pre-trained models [2]. However, due to the limitations of hard prompts that requires human intervention and limited adaptability, the concept has evolved to include continuous soft prompts. Soft prompts are learnable vectors that do not directly correspond to natural language but are optimized during training to enhance model performance on a given task [13, 15, 25]. In recent years, the effectiveness of soft prompts has been demonstrated beyond NLP, extending to domains such as computer vision (CV) and graph"}, {"title": "3 PROPOSED METHOD", "content": "The CLIP-SBR aims to exploit both intra- and inter-session item relationships to effectively model the user preferences embedded in sessions and enhance existing SBRs with the information. Figure 1 presents the overall flow of CLIP-SBR, which comprises two main components: 1) Item Relationship Mining. This component constructs a graph structure from session data to model item relationships with sufficient depth. It then identifies item clusters based on sequential dpendencies by employing existing community detection method. 2) Item Cluster-aware Prompt Learning. This component integrates learnable prompt vectors into item embeddings before they are fed into SBR models. The prompt vectors provide SBR models with information about item clusters during training. In this chapter, we first present the problem statement and then introduce the components of CLIP-SBR in detail.\n3.1 Problem Statement\nSession-based recommendation aims to predict the next item a user will interact with, based on the current session. Let $V = {v_1, v_2, ..., v_{||}}$ represent the set of all unique items across sessions, where $v_k$ represents the k-th item $(1 \\leq k \\leq |V|)$ in the sequence. We define a session set $S = {S_1, S_2, ..., S_{|S|}}$ and we denote the t-th session $(1 \\leq t \\leq |S|)$ as $S_t = {v_1^t, v_2^t, ..., v_{|S_t|}^t}$, where $v_l^t \\in V$ is the I-th interacted item $(1 \\leq l \\leq |S_t|)$ in $S_t$. The objective of session-based recommendation is to predict the top-K items $(1 \\leq K \\leq |V|)$ that the user is most likely to interact with next. This translates into forcasting the $(|S_t| + 1)$-th item based on the first $|S_t|$ items in the session.\n3.2 Item Relationship Mining\nAs the first module of the CLIP-SBR framework, Item Relationship Mining captures complex relationships between items in sessions using a graph-based approach that models both intra- and inter-session item relationships, inspired by prior SBR studies [3, 31, 32, 34, 35]. We first construct session graphs to capture sequential dependencies within individual sessions. To incorporate inter-session relationships, we create a global graph by connecting item nodes if they are linked in any session graph, enabling a unified view of both intra- and inter-session dynamics. By applying a community detection algorithm to this global graph, we identify item clusters-groups of items with strong interconnections and shared user preferences. This clustering step is crucial for uncovering latent patterns and user behaviors, ultimately enhancing the accuracy and efficiency of the SBR training process.\n3.2.1 Graph Construction. The graph construction process is a foundational step in our framework, designed to model the complex relationships between items in SBRs. We begin by constructing session graphs to capture intra-session item relationships. These session graphs serve as the basis for building a global graph, which captures inter-session item relationships, thereby providing a comprehensive representation of item dependencies across sessions.\nSession Graph Construction. In this step, we transform each session sequence into a session graph, denoted as $G_t = (V_t, E_t)$. Here, $V_t$ represents the set of items that a user interacts with within session $S_t$. The edge set $E_t = {(v_i^t, v_j^t) | v_i^t, v_j^t \\in V_t}$ captures the relationships between these items. Each edge $e_j$ is undirected and unweighted, capturing the sequential dependencies between adjacent items $v_i^t$ and $v_j^t$ within the session. This session graph effectively models intra-session item relationships by highlighting the item transitions within each session as edges.\nGlobal Graph Construction. To capture inter-session item relationships, we construct a global graph by aggregating session graphs with inter-session connections. This global graph, denoted as $G_g = (V_g, E_g)$, includes a node for each unique item in the dataset, where $V_g = V$. In this graph, edges are undirected and weighted, with the weight of an edge representing the frequency of item co-occurrences across different sessions. The graph aggregates connections from multiple session graphs, assigning the count of co-occurrences as the weight for each edge. Formally, the edge set is defined as $E_g = {(v_i, v_j) | v_i, v_j \\in V,}$, where each edge $e_j$ is associated with a weight $w_{ij}$, which quantifies the strength of the relationship between items $v_i$ and $v_j$ based on their co-occurrence frequency. The constructed global graph plays a crucial role in our framework by modeling both intra-session and inter-session item relationships in a single structure. We utilize this graph representation to detect clusters of items that are closely related.\n3.2.2 Item Cluster Detection. The process of detecting item clusters within the global graph $G_g$ plays a crucial role in capturing the complex relationships between items. In this study, a cluster refers to a subset of nodes within the graph that are more densely connected to each other than to nodes outside the subset. This high internal connectivity helps uncover latent item dependencies and user behavior patterns, which are essential for modeling complex item relationships embedded in session data. The goal of this step is to identify item clusters that exhibit strong relationships, which are critical for capturing nuanced user preferences in session-based recommendation. To achieve this, we employ the Leiden algorithm [28], a community detection method known for its superior performance in handling large-scale and complex graphs. The algorithm enhances the Louvain algorithm [1], by improving detection quality, accelerating convergence speed, and increasing robustness against noise and resolution limits. Furthermore, it effectively handles unconnected and large-scale graphs, both of which are common in recommendation settings, making the Leiden algorithm particularly suitable for our task of item cluster detection.\nWe apply the Leiden algorithm to the global graph $G_g$ to partition items into clusters:\n$Partition = Leiden(G_g) = {(v_k: c_m) | v_k \\in V_g, c_m \\in C}.$ (1)"}, {"title": "3.3 Item Cluster-aware Prompt Learning", "content": "In this section, we introduce a method to integrate the mined information about item relationships into SBR models during training. By leveraging learnable prompts, which have proven effective in providing data-related information to models, we enhance the capability of SBRs to capture both intra- and inter-session item relationships.\nFirst, session data is fed into the embedding layer of the existing SBR to obtain the initial item embeddings. Formally, we represent the initial item embeddings as:\n$V^{(0)} = EmbeddingLayer(V),$ (2)\nwhere $V^{(0)} = {v_1^{(0)}, v_2^{(0)},..., v_{||}^{(0)}}$ represents the set of initial item embeddings for the items in $V$. Here, we assign an unique and randomly initialized learnable vector (soft prompt), called cluster prompt, to each detected item cluster. The cluster prompt for a cluster $c_m$ is denoted as $\\hat{c_m}$. For each item $v_k$ in $V$, we retrieve its corresponding cluster prompt using the partition from the Leiden algorithm:\n$c_m = Partition(v_k),$ (3)\nwhere $c_m$ represents the cluster to which item $v_k$ belongs. The set of all cluster prompts is defined as $C = {c_1, ..., c_{|C|} }$.\nNext, we first normalize the initial item embedding $v_k^{(0)}$ and the cluster prompt $c_m$ to ensure balanced contributions. This step prevents the cluster prompt from overwhelming the item embedding and enables the model to learn balanced information. The normalized item embedding $\\hat{v_k^{(0)}}$ and normalized cluster prompt $\\hat{c_m}$ are then combined using a self-gating mechanism:\n$\\tilde{v_k^{(0)}} = g_k \\cdot \\hat{v_k^{(0)}} + (1 - g_k) \\cdot \\hat{c_m},$ (4)\nwhere $\\hat{v_k^{(0)}} = \\frac{v_k^{(0)}}{||v_k^{(0)}||}$ and $\\hat{c_m} = \\frac{c_m}{||c_m||}$ represent the normalized versions of the initial item embedding and cluster prompt, respectively, and $\\gamma$ denotes the prompting function. The scalar $g_k$ is a gating variable that controls the contribution of the item embedding and the cluster prompt. This self-gating mechanism dynamically balances the influence of both components based on their relevance, ensuring that the cluster prompt does not dominate and allowing the model to learn effectively.\nThe set of prompted item embeddings for $\\tilde{V^{(0)}}$ is defined as:\n$\\tilde{V^{(0)}} = {(\\tilde{v_1^{(0)}}), (\\tilde{v_2^{(0)}}),..., (\\tilde{v_{||}^{(0)}})}.$ (5)\nDuring the test phase, sessions in test dataset may contain unseen items. If a session includes both unseen items and items that are present in the global graph, new edges are added to the global graph to integrate the unseen items. If all items in a session are unseen, we assign the most frequent cluster to these items.\nPrompted item embeddings are passed through the existing SBR model during training, providing information about item relationships. Formally, given sessions S and prompted item embeddings $\\tilde{V^{(0)}}$, we apply the SBR model $f$ to obtain session embeddings:\n$\\tilde{S, V} = f(S, \\tilde{V^{(0)}}),$ (6)\nwhere $S = {S_1, S_2, ..., S_{|S|} }$ is a set of session embeddings with t-th element $s_t$, and $V = {v_1, v_2, ..., v_{|V|} }$ is a set of updated item embeddings with k-th element $v_k$.\nNext, we move to the prediction layer. In this layer, all items in $V$ are considered candidate items for recommendation. Let $Z$ represent the set of recommendation scores, where each element $z_k$ corresponds to the score for the target item $v_k \\in V$. Given session $S_t$, the score $z_k$ is computed by taking the inner product between the session embedding and the item embedding:\n$z_k = s_t \\cdot v_k$ (7)\nwhere $v_k$ is the updated item embedding for item $v_k$. The softmax function is then applied to the unnormalized scores $z_k$ to obtain the final output probabilities:\n$\\hat{y_k} = Softmax(z_k),$ (8)\nwhere $\\hat{y_k}$ denotes the probability of item $v_k$ being the next click in the current session. The loss function used for training is defined as the cross-entropy loss between the predicted probabilities $\\hat{y}$ and the one-hot encoded ground truth labels $y$. The cross-entropy loss measures the difference between the true distribution (given by the one-hot encoding) and the predicted distribution (given by the model's output). Formally, the loss is defined as:\n$L(y, \\hat{y}) = - \\sum_{k=1}^{|V|} y_k log(\\hat{y_k}),$ (9)\nwhere $y_k$ is the one-hot encoded ground truth for item $v_k$ (with $y_k = 1$ for the correct item and 0 for all others), and $\\hat{y_k}$ is the predicted probability that item $v_k$ is the correct next item.\nBy incorporating learnable cluster prompts into item embeddings, our approach enhances the SBR model's ability to capture complex item dependencies, resulting in more accurate and effective recommendations."}, {"title": "4 EXPERIMENTS", "content": "We have conducted extensive experiments to evaluate the proposed CLIP-SBR by answering the following four key research questions:\n\u2022 RQ1: Does CLIP-SBR improve the recommendation performance of SBR baseline models?\n\u2022 RQ2: Does the Item Relationship Mining module effectively capture and utilize complex item relationships?\n\u2022 RQ3: Does the Item Cluster-aware Prompt Learning module effectively and efficiently integrate item relationships into the recommendation process effectively and efficiently?\n\u2022 RQ4: How do different hyper-parameter settings impact the effectiveness of the CLIP-SBR framework?\n4.1 Experimental Setup\n4.1.1 Datasets. We employ three benchmark datasets that are widely used in the session-based recommendation.\n\u2022 Last.fm\u00b9 contains the complete listening behavior of approximately 1,000 users collected from Last.fm. In this paper, we focus on the music artist recommendation. We consider the top 40,000 most popular artists and group interaction records within an 8-hour window from the same user as a session, following former studies [3, 6].\n\u2022 Xing\u00b2 gathers job postings from a social networking platform, including interactions with the postings by 770,000 users. We split user's records into sessions following [23].\n\u2022 Reddit\u00b3 is a dataset collected from social media that includes tuples consisting of a user name, a subreddit where the user commented on a thread, and a timestamp of the interaction. The interaction data was segmented into sessions using a 60-minute time threshold, as outlined in [20].\nUsing the preprocessed data provided in [21] as a basis, we further process by following the previous studies [3, 23, 31], removing sessions with fewer than three interactions to exclude less informative data. Additionally, we retain only users with five or more sessions to ensure sufficient historical data. We allocated 10% of the sessions as the test set and the penultimate 10% as the validation set, with the remaining sessions used for training. Furthermore, for a session $S_t = {v_1^t, v_2^t, ..., v_{|S_t|}^t }$, we generate sequences and corresponding labels by a sequence splitting preprocessing, i.e.,$({v_1^t}, v_2^t), ({v_1^t, v_2^t}, v_3^t), ..., ({v_1^t, v_2^t, ..., v_{|S_t|-1}^t}, v_{|S_t|}^t)$ for training, valid and test across all the three datasets. The statistics of datasets, after preprocessing, are summarized in Table 1."}, {"title": "4.2 Results", "content": "4.2.1 Overall Performance (RQ1). Table 2 presents the experimental results of the eight baselines and their corresponding implementations using the CLIP-SBR framework on three real-world datasets. The best result in each column is highlighted in bold, and the top result within the intra-session category is underlined. We applied the CLIP-SBR framework to both intra-session and inter-session baselines to assess its impact. The results show that the CLIP-SBR leads to performance improvements across most of the baselines. In the intra-session baselines, we observed substantial improvements across the board, with the most significant performance gains in the NARM model. For the inter-session baselines, CLIP-SBR demonstrated notable improvements in GCSAN, while having a smaller impact on GCEGNN and no improvement on LESSR. Further analysis of the impact of applying CLIP-SBR to inter-session baselines is provided in Section 4.2.3.\nMoreover, the inter-session baselines (GCSAN, GCEGNN, LESSR) demonstrate comparable or even better performance than the intra-session baselines. Notably, GCEGNN outperforms all intra-session models on the Last.fm dataset, and LESSR achieves the highest metrics on the Xing dataset. These results highlight the potential of incorporating inter-session information to improve recommendation accuracy, emphasizing the importance of considering both intra-session and inter-session item relationships when developing robust session-based recommendation models.\nThe application of the CLIP-SBR framework to the intra-session baselines resulted in performance improvements in all but one case. Specifically, NARM saw a substantial improvement of 45.30% on Last.fm, 20.11% on Xing, and 13.04% on Reddit, marking it as one of the most improved models. TAGNN also demonstrated significant gains, particularly on Last.fm with a 33.91% increase, 15.31% on Xing, and 2.33% on Reddit. Similarly, GRU4Rec achieved notable enhancements of 29.77% on Last.fm, 7.61% on Xing, and 11.10% on Reddit. CORE exhibited improvements of 1.92%, 16.65%, and 4.51% across the respective datasets, while SRGNN showed increases of 31.54%, 1.44%, and 4.26% on the three datasets. When comparing intra-session CLIP-SBR models with inter-session models, the CLIP-SBR models generally outperformed in many instances. Notably, CLIP-TAGNN consistently surpassed all inter-session models across. CLIP-SRGNN also outperformed inter-session models on Last.fm and Reddit dataset, and outperformed GCSAN in MRR@5 and Recall@5, and GCEGNN in MRR@5. This indicates that the CLIP-SBR framework is highly effective in leveraging and designing inter-session information, leading to better overall performance.\nWe also applied CLIP-SBR to the inter-session models to assess its effectiveness. The impact varied across the three models: it had a substantial effect on GCSAN, a slight effect on GCEGNN, and almost no effect on LESSR. This suggests that the CLIP-SBR is less beneficial for GCEGNN that already capture inter-session information effectively, while providing significant improvements for GCSAN that do not sufficiently address it. For LESSR, the lack of improvement indicates that the model may not effectively utilize the additional information provided by CLIP-SBR. The impact of CLIP-SBR on inter-session models is further discussed in Section 4.2.3.\n4.2.2 Impact of Item Relationship Mining (RQ2). We evaluated the impact of the Item Relationship Mining module in CLIP-SBR by assessing performance across seven different scenarios.\n\u2022 C: The original CLIP-SBR applies distinct learnable prompts for each item's cluster, embedding them into the item representations. This allows the model to capture group-level item relationships and patterns across sessions.\n\u2022 U: User-specific prompts are added to item embeddings, maintaining a consistent prompt for a given user across all sessions. This helps the model capture user preferences and long-term behavioral patterns across sessions.\n\u2022 S: Session-specific prompts are applied to all items within a session, helping the model learn session-level patterns that reflect user intent or context within a specific session.\n\u2022 CU: Combines both cluster and user-specific prompts. Cluster prompts capture relational structure among items, while user prompts represent long-term user preferences, enabling a deeper understanding of user behavior and item relations.\n\u2022 CS: Combines cluster and session-specific prompts, adding both to item embeddings. This captures the dynamic context of the session (via session prompts) while preserving item relationships within clusters (via cluster prompts).\n\u2022 US: Combines user and session-specific prompts to balance short-term session intent with long-term user preferences. This enables the model to capture how user behavior shifts across sessions while keeping user-specific patterns maintained.\n\u2022 CUS: Combines cluster, user, and session-specific prompts, creating a comprehensive embedding. This setup captures group-level item relationships, user preferences across sessions, and dynamic session behavior simultaneously.\nWe trained these seven types of models for each baselines on each dataset and evaluated their performance improvement using MRR@5 and Recall@5 metrics. The results, as shown in Figure 2, reveal that in almost all cases, the original CLIP-SBR models with cluster prompts (C) exhibited the most significant improvement compared to the baseline models. Notably, models using user-specific prompts (U) showed the second highest improvement, indicating that incorporating user-specific prompts effectively provided personalizing information during the training phase, thereby enhancing the performance of the SBR models. In contrast, other scenarios, especially those involving combinations of prompts, did not yield"}, {"title": "4.2.3 Impact of Item Cluster-aware Prompt Learning (RQ3).", "content": "To evaluate the impact of the Item Cluster-aware Prompt Learning module, we assessed its effectiveness on intra-session and inter-session SBR models. As shown in Table 2 and Figure 2, our approach demonstrates substantial performance improvements, highlighting both the effectiveness and efficiency of the module. In terms of effectiveness, applying the Item Cluster-aware Prompt Learning module led to significant performance improvements in inter-session baselines. Specifically, CLIP-GCSAN showed notable gains, effectively compensating for GCSAN's limitations in capturing inter-session information, particularly on the Last.fm dataset. For GCEGNN, the module provided moderate improvements, suggesting that while GCEGNN already captures inter-session information effectively, the prompts still offer additional value. Conversely, CLIP-LESSR showed no improvement over the original LESSR, indicating that LESSR's inherent handling of inter-session information leaves little room for further enhancement from the prompts. Regarding efficiency, the Item Cluster-aware Prompt Learning module demonstrated significant advantages in terms of training time. As shown in Table 3, several CLIP models achieved better or comparable performance (MRR@5) with significantly less training time compared to the inter-session baselines (GCSAN, GCEGNN, LESSR). Among the CLIP models, CLIP-SRGNN shows a good balance between effectiveness and efficiency. It outperformed the inter-session baselines on Last.fm and Reddit, achieving higher MRR@5 with reduced training times-619.79 seconds on Last.fm and 196.71 seconds on Reddit, compared to GCSAN's 1032.88 seconds, GCEGNN's 625.71 seconds, and LESSR's 758.59 seconds on Last.fm, as well as the significantly longer times of the inter-session baselines on Reddit. For the Xing dataset, CLIP-SRGNN achieved comparable performance to the inter-session models while still requiring considerably less time-56.33 seconds versus 92.70 seconds for GCSAN and 60.60 seconds for GCEGNN. The CLIP-TAGNN achieves the best performance on MRR@5 at the expense of longer training time. This highlights the efficiency of the Item Cluster-aware Prompt Learning module, which achieves comparable or superior performance with reduced training time.\n4.2.4 Impact of hyperparameter. The Item Relationship Mining module in CLIP-SBR uses the Leiden algorithm for item cluster detection, with the resolution parameter controlling the granularity of community detection. We evaluated CLIP-GRU4Rec using various resolution values 0.1, 0.5, 1, 1.5, 2, 3, 5, with the MRR@5 results shown in Figure 3. Although no clear pattern emerged regarding how resolution changes affected performance, the model consistently performed best with a resolution of 1 across all datasets. Based on these findings, we use a resolution value of 1 in our implementation, as it effectively balances fine-grained and broader item relationships."}, {"title": "5 CONCLUSION", "content": "In this paper, we introduced the CLuster-aware Item Prompt learning framework for Session-Based Recommendation (CLIP-SBR), aimed at overcoming the limitations of existing SBR methods by effectively capturing both intra- and inter-session item relationships. The framework comprises two key modules: the first module identifies item clusters from session data, while the second module incorporates cluster-specific prompts to enhance the learning capabilities of SBR models. Extensive experiments demonstrated that CLIP-SBR consistently outperforms baseline models, highlighting its effectiveness."}]}