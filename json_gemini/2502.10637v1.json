{"title": "Proof of Response", "authors": ["Illia Polosukhin", "Alex Skidanov"], "abstract": "We present a mechanism that for a network of participants allows one participant of the network (Alice) to request some data from another participant (Bob) and either receive a response from Bob within a known-in-advance, bounded time b, or receive a proof that at least one edge on the way to Bob was broken within b, or receive a streaming payment proportional to time passed beyond b during which neither was received. This mechanism allows for building downstream applications that require provable responses from other participants, such as decentralized storage solutions, decentralized AI agents, and more.", "sections": [{"title": "Motivation", "content": "It is now inevitable that, in the future, the majority of tasks will be performed by a massive decentralized network of interconnected agents powered by large language models.\nAs the complexity of the tasks performed by agents increases, so will the average number of dependencies of the agents on other agents. As an example from an adjacent field, Python, NPM, and Rust packages can have dependencies on other packages, and installing a single package, such as a package to compute SHA-256 hashes, often results in the installation of dozens of other packages that it depends on.\nUnlike packages, which are generally hosted on a centralized server, and thus the availability of which is relatively reliable, agents will be hosted on a wide variety of hardware, and with varying reliability of implementations. If Alice wants her agent to depend on another agent hosted by Bob, she needs to be certain that the infrastructure on which Bob is hosting their agents is reliable, and that the agent itself does not go down due to software bugs.\nIf Bob's agent is down, Alice either needs to incur downtime herself; or have her agent's performance degrade due to unavailability of the features provided by Bob's agent; or design her service with potential downtime of Bob's agent, having a fail-over option.\nThe same problem exists outside of agents, with products and services gen-erally depending on external APIs provided by third parties. Generally, the"}, {"title": "Overview", "content": "The network consists of nodes, and some of the nodes are connected by edges. The entire topology of the network is persisted in a smart contract on NEAR. For each edge in the network, the two nodes have a state channel open (seel Poon and Dryja, 2016 for a good overview of payment channels, and Dziembowski, Faust, and Host\u00e1kov\u00e1, 2018 for generalized state channels), such that they can exchange small amounts of NEAR, and certain information, without touching the blockchain. Each node has some amount of stake. When the network becomes disconnected, we consider the part that has the smaller cumulative stake to be disconnected from the part with the larger cumulative stake. In such a case, every node in the partition with the smaller stake loses some percentage of their stake. Generally, severing any edge in the network results in a penalty paid by both nodes incident to it. In the event of network partitioning, the nodes in the smaller partition reimburse the nodes in the larger partition for all such penalties incurred.\nEach edge e is a tuple (Le, Ce, Be). Le is the promised latency that is chosen by the two nodes that established the connection. There are no constraints for"}, {"title": "Algorithm", "content": "Consider three nodes P, Q, and R on some path, such that Q relayed m to R, which in turn was relayed to Q from P.\nConsider two outcomes for Q:\nR follows the protocol. In this case, either R communicated to Q within the allocated latency the response or the proof of an edge removed from the graph, or R hasn't communicated either, but sent a sufficient amount of NEAR to pay for the delay. In the former case, Q is guaranteed to relay the response"}, {"title": "Payment for severed edges", "content": "For a particular pair of nodes P and Q, if one of them deviates from the protocol and the other is forced to break the edge, it's generally impossible to tell which node was faulty. Thus, when the edge is broken, by default both nodes will pay a small penalty for the edge removal.\nHowever, if P has reason to believe that Q is offline, the following protocol can be implemented to ensure that Q pays the whole penalty, while P pays nothing:\n1. Q starts deviating from the protocol (refuses to provide response or pay-ment for one or more messages in flight between P and Q);\n2. P immediately sends a transaction on-chain to sever the edge, which ini-tially charges both P and Q for half of the penalty; P also sends the proof of edge removal upstream to the previous node on the path;\n3. P sends a request to Q to provide the response to the message, or payment for the delay, using Proof of Response;\n4. IfQ is offline, P will eventually be able to remove a sufficient number of edges from the network to isolate Q, by repeatedly requesting the response. When a node is isolated, the network orchestrating contract on NEAR charges them to reimburse all the fees paid by other nodes for severing edges with them."}, {"title": "Bandwidth", "content": "A situation can occur when a particular edge is sufficiently popular that it cannot relay all the messages that choose to be sent through it. Let's say the edge connects nodes P and Q, and a message arrives to P to be relayed to Q,"}, {"title": "Usage", "content": "Proof of Response itself does not impose any requirements on the contents of the requests and responses nor on the latencies and bandwidths declared.\nIt is the responsibility of the protocols that are built on top of Proof of Response both to ensure the validity of messages exchanged and to have appro-priate requirements for promised latencies and bandwidths.\nParticipants in Proof of Response only need to provide a small stake that covers the micro-payments necessary for the state channels. Consequently, the protocols that build on top of Proof of Response can require the participants to deposit larger stakes, without making the participants have to stake large amounts twice.\nWhen Alice requests something from Bob via a protocol B built on top of Proof of Response, if the responser is delivered, it is signed by Bob. If Bob deviates from the protocol B in their response, Alice can provider to the smart contract governing B, and such a smart contract will have sufficient information to slash Bob for deviating.\nSimilarly, if Alice requests something from Bob and Bob does not respond, Alice can repeatedly send the request to Bob until Bob is isolated from the network, and then Alice can provide a proof that Bob is not in the connected component with the largest stake to the smart contract governing B, which in turn can slash Bob."}, {"title": "Minimum Bandwidth and Maximum Latency", "content": "Bob can attempt to bypass this requirement by creating a long chain of edges with very high latency or very low bandwidth, such that technically they are part of the graph, but in practice are not usable. As mentioned above, Proof of Response itself does not impose any constraints on declared latencies or band-width. It is the responsibility of B to define what being available means. In particular, B can and should define a minimum bandwidth and a maximum latency for the participants in their protocol.\nImposing the minimum bandwidth and maximum latency requires one care-ful consideration. It could be that Bob is well-connected to the graph, and it is"}, {"title": "Example Scenarios", "content": "Consider the following topology:\nAlex < 100ms -> Alice <- 200ms -> Bob <- 100ms -> Carol\nDave <- 100ms --> Eve <-- 100ms ----|"}, {"title": "Happy case", "content": "\u2022 Alex requests a packet from Carol. It's 400ms one-way, so he expects the response in 800ms.\n\u2022 Alice receives it 100ms later and forwards it to Bob with 600ms timeout.\n\u2022 Bob receives it 200ms later and forwards it to Carol with 200ms timeout.\n\u2022 Within 200ms, Bob receives the response and sends it back to Alice."}, {"title": "Eve is offline, Bob breaks the edge right away", "content": "\u2022 Alex requests a packet from Dave. It's 500ms one way, so he expects the response in 1000ms.\n\u2022 Alice receives it 100ms later and forwards it to Bob with 800ms timeout.\n\u2022 Bob receives it 200ms later and forwards it to Eve with 400ms timeout.\n\u2022 400ms later, Bob doesn't receive the response.\n\u2022 Bob is configured to communicate late payments with Alice every second.\n\u2022\nThe above will be common in all remaining examples\n\u2022 Bob doesn't see much value in the edge with Eve. At the end of the 400ms timeout, he immediately initiates the transaction to break the edge with Eve, and sends the proof of the initiation to Alice.\n\u2022 Alice receives it 100ms later and sends it to Alex. Alex has the proof that his request resulted in an edge being removed, and can choose to send the request again, via a different path."}, {"title": "Eve is offline, Bob waits a bit and pays for it", "content": "\u2022 Alex requests a packet from Dave. It's 500ms one way, so he expects the response in 1000ms.\n\u2022 Alice receives it 100ms later and forwards it to Bob with 800ms timeout.\n\u2022 Bob receives it 200ms later and forwards it to Eve with 400ms timeout.\n\u2022 400ms later, Bob doesn't receive the response.\n\u2022 Bob is configured to communicate late payments to Alice every second.\nEnd of common part\n\u2022\n\u2022 Bob doesn't see much value in the edge with Eve, but decides to wait until their next sync with Alice, which is due in ~1 second. ~1 second later, Bob pays Alice out of pocket the delay fee for this ~1s delay, and initiates the transaction to break the edge with Eve. The message to Alice comprises the delay payment for ~1s, and the proof of the transaction initiated (so that Alice doesn't expect any more late payments)."}, {"title": "Eve is offline, Bob waits, but doesn't pay the late fee", "content": "\u2022 Alex requests a packet from Dave, it's 500ms one way, so he expects the response in 1000ms.\n\u2022 Alice receives it 100ms later and forwards it to Bob with 800ms timeout.\n\u2022 Bob receives it 200ms later and forwards it to Eve with 400ms timeout.\n\u2022 400ms later, Bob doesn't receive the response.\n\u2022 Bob is configured to communicate late payments with Alice every second.\n\u2022\nEnd of common part\n\u2022 As in the previous example, Bob doesn't see much value in the edge with Eve, but decides to wait until their next sync with Alice, which is due in ~1 second. But this time around, ~1 second later Bob sends the message with the broken edge, pretending he sent it 1 second ago, and doesn't pay the late fee during their sync. By this time, following a similar timeline, Alice has already paid a late fee to Alex twice:"}, {"title": "Eve is offline, Bob waits longer", "content": "\u2022 Alex requests a packet from Dave, it is 500ms one way, so he expects the response in 1000ms.\n\u2022 Alice receives it 100ms later and forwards it to Bob with 800ms timeout."}, {"title": "Use case example", "content": "Proof of Response in itself only guarantees that some message signed by the destination will be received within the latency of the path, or an edge will be severed, but does not provide further guarantees. Here we outline an example of how this system can be used for a decentralized storage solution.\nIn decentralized storage solutions, such as Sia, it is relatively simple to ensure that the data was stored: the two participants can agree ahead of time on the"}, {"title": "Conclusion", "content": "Proof of Response provides a primitive that enables users of protocols built on top of it to request something from service providers, and either get a re-sponse signed by the service provider or a proof that the service provider is not responding, which can later be submitted to a smart contract on a blockchain. Such a primitive allows one to design autonomous agents and other APIs that can provide verifiable uptime to their users."}]}