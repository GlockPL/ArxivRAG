{"title": "Multimodal Gender Fairness in Depression\nPrediction: Insights on Data from the USA & China", "authors": ["Joseph Cameron", "Jiaee Cheong", "Micol Spitale", "Hatice Gunes"], "abstract": "Social agents and robots are increasingly being used in\nwellbeing settings. However, a key challenge is that these agents\nand robots typically rely on machine learning (ML) algorithms\nto detect and analyse an individual's mental wellbeing. The\nproblem of bias and fairness in ML algorithms is becoming an\nincreasingly greater source of concern. In concurrence, existing\nliterature has also indicated that mental health conditions can\nmanifest differently across genders and cultures. We hypothesise\nthat the representation of features (acoustic, textual, and visual)\nand their inter-modal relations would vary among subjects from\ndifferent cultures and genders, thus impacting the performance\nand fairness of various ML models. We present the very first\nevaluation of multimodal gender fairness in depression manifes-\ntation by undertaking a study on two different datasets from\nthe USA and China. We undertake thorough statistical and ML\nexperimentation and repeat the experiments for several different\nalgorithms to ensure that the results are not algorithm-dependent.\nOur findings indicate that though there are differences between\nboth datasets, it is not conclusive whether this is due to the\ndifference in depression manifestation as hypothesised or other\nexternal factors such as differences in data collection methodol-\nogy. Our findings further motivate a call for a more consistent\nand culturally aware data collection process in order to address\nthe problem of ML bias in depression detection and to promote\nthe development of fairer agents and robots for wellbeing.", "sections": [{"title": "I. INTRODUCTION", "content": "Mental health disorders (MHDs) are becoming increasingly\nprevalent [1]. In concurrence, there is a growing body of\nresearch which started to explore the use of agents or robotic\ncoaches to support mental wellbeing [2]\u2013[5]. However, a\nunique challenge is that mental health conditions manifest\nin diverse ways across individuals. The different manifes-\ntations and symptoms can be influenced by gender [6]-[8]\nand countries [9]. Brody et al. show that women aged 20 or\nover are nearly twice as likely to show signs of depression\nwhen compared to men aged 20 or over [10] and Hasin\net al. found a similar pattern in their survey of American\nadults (aged over 18) that targeted an investigation of major\ndepressive disorders [11]. Chang et al. observed that Koreans\nwere far more likely to show symptoms of low energy or\ndifficulties with concentration, whereas Americans were less\nlikely to show concentration difficulty and far more likely to\nshow high levels of work productivity [12]. Following such\ninsights, Juhasz et al. identify that depression can manifest\nand be displayed in very different ways across different\nnations and cultures [9]. As a result, many of the western-\ndeveloped depression diagnostic tools may be biased towards\nand better at identifying depression within Northern American\nand European demographic groups [9].\nConcurrently, ML bias is becoming a growing source of\nconcern [13]\u2013[17]. Given the high stakes involved in MHD\nanalysis, it is crucial to investigate and mitigate the ML biases\npresent. Recent research has indicated that ML bias is present\nin existing MH datasets and models [18]\u2013[20]. However, none\nof the existing work has investigated the problem of ML bias\nacross different countries and cultures. The gender and cultural\ndifferences in depression manifestation, diagnosis, and general\nsymptoms described in [9], [10], [12] clearly communicate\nthat symptoms of depression can significantly differ between\ndifferent genders and nations or cultures, potentially leading to\nbiased frameworks and datasets for depression diagnosis and\nmanifestation. Thus, we hope to tackle the aforementioned\ngaps by addressing the following research questions (RQs):\nRQ 1: Are there any differences in depression manifestation\nacross gender and countries? If present, what are the primary\nsources of difference in depression manifestation? To address\nthis research question, we conduct thorough statistical analysis\nof features between two datasets collected from different coun-\ntries, namely China and the USA, and evaluate to what extent\nthe difference in features impacts model performance. RQ 2:\nHow do the results compare between different ML models\nand modalities? To address this research question, we conduct\nthorough experimentation using a range of ML models to\nevaluate how the different models perform across the different\ndatasets and modalities. RQ 3: Are there any differences\nin ML model performance and fairness across gender and\ncountries? If present, are the differences in performance due to\nthe difference in depression manifestation as hypothesised? To\naddress this research question, we draw on the findings from\nthe previous two RQs and further evaluate some key insights\nthat may have impacted performance and fairness results.\nThe main contributions of this paper are as follows. First, we\naim to understand how biases occur with respect to gender and\nwhether they differ based on the location and dataset curation\nmethod. We do so by conducting experiments on two mul-\ntimodal depression datasets from the USA and China. Next,"}, {"title": "II. LITERATURE REVIEW", "content": "There have been recent attempts at using machine learning\nmethods, including both unimodal and multimodal approaches\nto automatically analyse and predict depression using extracted\nfeatures [21]\u2013[23]. It is possible to do so via several different\ndata sources such as physiological data [24], [25], motor ac-\ntivity data [26], [27] or audio-visual sources [28]\u2013[30]. Audio-\nvisual (AV) datasets typically include behavioural signals such\nas facial affect, body gestures and vocal intensity [28], [31],\n[32]. In general, multimodal approaches are shown to perform\nbetter than unimodal approaches [33]\u2013[35]. Most recently, Zou\net al. explored the effects of using unimodal and multimodal\nvariations of the visual, acoustic, and textual features extracted\nfrom the CMDC dataset [36]. The visual features Zou et al.\nidentified for extraction from the CMDC dataset were Eye\nGazes, Eye Landmarks, Head Poses, Facial Landmarks and\nFacial Action Units (AU) [37].\nExisting literature indicates that depression can manifest in\nvastly different ways across different cultures, countries and\ngenders [6], [7], [12]. Brody et al. and Hasin et al. demonstrate\nthat adult women are more likely to display signs of depression\n[10], [11]. Platt et al. investigate this observation further and\nattribute the increased manifestation of depression in women\nto the gender pay gap [38]. Across cultural differences in\ndepression symptoms, Chang et al. observed a difference\nin communicated energy levels and concentration between\ndepressed Koreans and Americans [12]. Further, Iwata and\nBuka found that Japanese university students reported higher\nlevels of low positive affect compared to American university\nstudents [39]. As a result, Japanese students were considered to\nbe more depressed than their American counterparts although\nthis may not necessarily be true [39].\nThere is only a handful of studies which have looked into\nbias in mental well-being prediction [18]\u2013[20], [40]\u2013[43]. Park\net al. [42] conducted their experiments on data collected\nin a clinical setting with a specific focus on post-partum\ndepression. Zanna et al. [19] conducted their experiments on\ndata collected in the wild with a specific focus on anxiety\nprediction. Park et al. [41] analysed bias across gender in\nmobile mental health assessment and proposed an algorith-\nmic impact remover to mitigate unwanted bias. Bailey and\nPlumbley [18] attempted to mitigate the gender bias present\nin the DAIC-WOZ dataset using data re-distribution. Cheong\net al. evaluated the impact of gender bias on depression\nprediction with various ML models using various unimodal\nand multimodal approaches [43].\nHowever, all the existing works have chiefly focused on\ninvestigating ML fairness for multiple ML models across"}, {"title": "III. EXPERIMENTAL SETUP", "content": "In this section, we provide the dataset information, and\nimplemented data pre-processing and model training details.\nWe use the Chinese Multimodal Depression Corpus\n(CMDC) dataset [36] and the American Extended Distress\nAnalysis Interview Corpus (E-DAIC) dataset [44] to address\nour research questions. The CMDC [36] is a Chinese dataset\ncontaining textual, acoustic, and visual data collected from 78\nparticipants. The semi-structured interview scripts contained\nquestions and topics of discussion verified by clinicians.\nGround-truth labels were obtained using the Patient Health\nQuestionnaire-9 (PHQ-9) [45]. The E-DAIC [46], [47] is\na US-based dataset. E-DAIC contains textual, acoustic and\nvisual data collected from 275 participants. E-DAIC employs\nthe Patient Health Questionnaire-8 (PHQ-8) to obtain the\nground-truth label [45]. The only difference between the PHQ-\n8 and the PHQ-9 is that the PHQ-8 does not include the ninth\nitem which relates to suicidal thoughts.\n1) CMDC Dataset: The dataset provided ready to use\nvisual features such as action units (AUs), eye gaze, head pose\nand facial landmarks extracted using OpenFace (version 2.2.0)\n[48]. OpenFace is used because it is considered the state-of-\nthe-art open-sourced tool for facial analysis. AUs are used as\nextracted features to describe the changing characteristics of\nfacial expression in depression since depressed patients may\nexhibit poor expression ability. Moreover, the occurrence of\nspecific facial movements (e.g. smile, corner of mouth down,\netc.) described by specific AUs (e.g., AU12) is directly related\nto depression. The acoustic features set used is the extended\nGeneva Minimalistic Acoustic Parameter Set (eGeMAPS)\n[49]. Another widely used open-source toolkit, openSMILE\n(version 3.0) [50], was used for acoustic feature extraction.\nSome examples of extracted acoustic features include pitch,\njitters, frequency, and bandwidth of Formant 1, 2, 3 etc. Visual\ndata for questions 2, 8, 10, 11, and 12 for all participants were\nremoved from subsequent ML experimentation as they were\nmissing. In addition, we remove participant MDD 23 as they\nhad no representative textual data. Zou et al. did not mention\nany of the identified gaps in the CMDC dataset [36].\n2) E-DAIC Dataset: There was no missing data in E-DAIC.\nFor the fairest comparison between CMDC and E-DAIC, we\npre-process the data in a similar fashion as done by Zou\net al. Across the visual and acoustic features, we therefore\nconcatenate the mean, max, and min features on the response-\npartitioned video frames to achieve temporal aggregation using\nthe provided extracted features in the E-DAIC dataset. In E-\nDAIC, the same set of visual features and acoustic features\nwere obtained using the OpenFace [48] and openSMILE\n[50] toolkits respectively. Readers can refer to [36], [46]\nfor further details. Across the textual modality, participant\nresponses obtained via the provided transcripts were inputs\nto a pretrained English BERT model [51] which resulted in a\n768 feature long textual feature vector per participant.\n1) ML Models: We investigate a binary classification setup\nwhere the models' goal is to predict whether a participant\nis classified as depressed or not. In addition to the models\nintroduced in [36], we ran our experiments on more models\nto ensure thorough evaluation. These models are the Support\nVector Machine with a linear kernel (SVM Linear), Support\nVector Machine with a radial basis function kernel (SVM\nRBF), Logistic Regression (LogReg), Naive Bayes (NB), K-\nNearest Neighbors (KNN), Decision Tree (Dec Tree) and the\nMultilayer Perceptron (MLP). All models were implemented\nin Python using the sklearn package. We have selected these\nbasic models in alignment with prior works (e.g., [52], [53],\n43]) which employed statistical representations of features for\ntraining data as we have done in this work.\n2) Statistical Analysis: We perform one-way multivariate\nANOVA (MANOVA) tests across both the visual and acous-\ntic features for both datasets. We further conduct two-way\nMANOVA tests to compare how significantly different the\nmeans of visual and acoustic features are between participants\nwithin both the Healthy Control (HC) versus the Major De-\npressive Disorder (MDD) groups and the male versus female\ngroups. All MANOVA analysis was implemented using the\n'statsmodels' package in Python [54]. Recent work indicates\nthat analysing interviewees' responses at a question level\nallows for finer grained understanding and detection of be-\nhavioral characteristics of depression [55]. Thus we conduct\nthe analysis on the CMDC dataset structured according to the\nquestions posed within their semi-structured interview [36].\n3) Training Process: All models were evaluated using\nstratified 5-fold cross validation. We form stratified folds of\nequal ratios of depressed and non-depressed participants and\nalso ensured equal ratios of male and female participants. This\nis to ensure that any observed disparities in model fairness\nacross genders are reflective of the model's behavior rather\nthan artefacts of the sampling process. The folds are consistent\nacross all classification tasks and models. Given that both\ndatasets have acoustic (A), textual (T), and visual (V) features,\nthe models were trained with every possible combination of\nthe feature modalities (A, T, V, A+T, A+V, T+V, A+T+V).\nWe adopt the evaluation metrics overall accuracy, F1 Score\nand Area Under the Receiver Operating Characteristics (AU-\nROC) used in [36] to evaluate each model's performance.\nA = 1 denotes the majority group (male) and A = 0 denotes\nthe minority group (female). \u00dd denotes the predicted class.\nWe use Equal Accuracy (EAGender) and Disparate Impact\n(DIGender) to evaluate each model's fairness in alignment\nwith existing works [43], [56], [57].\n\u2022 Equal Accuracy (EA), can be understood as the accu-\nracy gap between the majority and the minority group:\n$EAGender = |MAE(\u0176|A = 1) \u2013 MAE(\u0176|A = 0)|$,\nwhere MAE represents the Mean Absolute Error (MAE)\nof the classification task of each sensitive group.\n\u2022 Disparate Impact (DI), measures the ratio of positive\noutcome (\u0176 = 1) for the majority and minority groups\nas follows:\n$DIGender = \\frac{Pr(\u0176 = 1|A = 0)}{Pr(\u0176 = 1|A = 1)}$,\nEA is dependent on predicted and actual outcome whereas\nDI is mainly dependent on the predicted outcome. The\ncomplementary nature of both fairness measures thus provides\na better understanding of the bias present."}, {"title": "IV. STATISTICAL ANALYSIS RESULTS", "content": "We evaluate whether there are any differences in depres-\nsion manifestation across gender and countries. All statistical\nanalysis is conducted at a significance value of 0.05.\nFor CMDC, our statistical analysis revealed significant dif-\nferences between the different features representations across\ndepressed vs. non-depressed classes as well as gender.\n1) One-Way MANOVA (Visual): Looking at Table I, there\nare statistically significant differences between the HC/MDD\ngroups for the Action Unit (AU) classification features for\nall questions except 4, 5, 6, and 9. There are statistically\nsignificant differences between the HC/MDD groups for the\npose features for all questions except 9. Interestingly, there are\nno statistically significant differences between the HC/MDD\ngroups for the gaze features across all questions. This indicates\nthat participants labelled to have MDD in CMDC indeed\nexhibit different facial action unit activations and different\nhead orientations (poses) compared to HC participants, how-\never they do not exhibit significantly different gaze directions.\n2) Two-Way MANOVA (Visual): Table I indicates no sta-\ntistically significant differences between the HC/MDD and\nMale/Female groups for any of the OpenFace visual feature,\nindicating that the effect of depression status on the visual\nfeatures does not vary significantly by gender.\n3) One-Way MANOVA (Acoustic): Table II indicates that\nparticipants labelled to have MDD in CMDC indeed exhibit\ndifferent pitch, amplitude, and spectral sound character-\nistics compared to HC participants.\n4) Two-Way MANOVA (Acoustic): With reference to Ta-\nble II there are statistically significant differences between\nthe HC/MDD and Male/Female groups for some of the\nOpenSMILE acoustic feature subsets. The spectral acoustic\nfeatures are significantly different between the HC/MDD and\nMale/Female groups for all questions. The amplitude feature\nare different between the HC/MDD and Male/Female groups\nfor some questions. This indicates that the effect of depression\nstatus (HC/MDD) on the acoustic features, especially the spec-\ntral acoustic features and the amplitude acoustic features\nfor some questions, does vary across gender.\nFor E-DAIC, the statistical analysis reveal that there are\nsignificant differences between the gaze features of depressed\nand non-depressed participants.\n1) One-Way MANOVA (Visual): Table III indicates that\nthere are significant differences between the gaze features\nof depressed and non-depressed participants.\n2) Two-Way MANOVA (Visual): Table III indicates that the\neffect of depression status on the visual features does not vary\nsignificantly by gender in E-DAIC.\n3) One-Way MANOVA (Acoustic): Table IV indicates no\nsignificant differences between the acoustic features of\ndepressed and non-depressed participants.\n4) Two-Way MANOVA (Acoustic): Table IV indicates that\nthe effect of depression status on the acoustic features does\nnot vary significantly by gender in E-DAIC."}, {"title": "V. EXPERIMENTAL RESULTS", "content": "In this section, we evaluate the performance and fairness\nacross all the different ML models for both datasets."}, {"title": "VI. DISCUSSION OF FINDINGS", "content": "RQ1: Are there any differences in depression manifestation\nacross gender and countries? Results from Sections IV-A\nindicate that there are significant differences between the dif-\nferent features across depressed vs. non-depressed participants\nas well as gender for CMDC. This is true for both the visual\nand audio features. In addition, the spectral acoustic features\nand the amplitude acoustic features also varied significantly\nacross gender. However, this observation is not as significant\nfor E-DAIC as highlighted in Section IV-B. We see significant\ndifferences in depression manifestation across gender in both\ndatasets. However, a distinctive feature is that this observation\nis stronger for CMDC than for E-DAIC. This hints that\nthere may be statistically significant differences in depression\nmanifestation across the sample population in both datasets.\nRQ 2: How do the results compare between different ML\nmodels and modalities across the different datasets? There\nare differences in ML model performance and fairness. It is\ninteresting to note that for both datasets, certain models such as\nthe SVM Linear and the Logistic Regression models perform\nmuch better, and certain models such as NB perform poorly\nacross both datasets. Looking at the gender fairness results\non CMDC, multimodal setups generally result in a narrower\nrange of DI scores across gender than the unimodal setups.\nUsing a multimodal setup as compared to a unimodal setup\nprovides the classifiers with more information to learn from,\nwhich may have resulted in an improvement across the fairness\nand performance metrics [43], [58]. However, for E-DAIC, the\nrange of DI scores remain similar across both unimodal and\nmultimodal setups.\nRQ3: Are there any differences in ML model performance\nand fairness across gender and countries? If present, are\nthe differences in performance due to the differences in\ndepression manifestation as hypothesised? We see that\noverall, the ML models perform better for CMDC than for\nE-DAIC. In general, model performance was better across\nall feature-modality combinations when the classifiers are\ntrained and tested on the CMDC dataset. The change in\nperformance between CMDC and E-DAIC is in agreement\nwith Zou et al.'s benchmark evaluations on both datasets [36].\nIt is probable that the classifiers found it more difficult to\nrecognise the defining characteristics of depressed people in"}, {"title": "VII. CONCLUSION", "content": "A key takeaway from this study is that there were notable\ndifferences between each selected classifier's performance\nand gender fairness metrics across the CMDC and E-DAIC\ndatasets. However, it is not conclusive if this is due to cultural\ndifferences or due to differences in data collection methods.\nWe could not conduct statistical tests between both datasets\nas the data elicitation methods were too different. This was\none of the big limitations of this study as we could not\nascertain if the difference in performance across the two\ncountries were due to a difference in depression manifestation\nor data collection methodology [36], [59]. Future work could\ninvolve the creation of a new multimodal depression dataset\nwhere data is collected in multiple countries via a single\nclinically approved protocol (e.g., semi-structured interview).\nThe limited number of participants in CMDC and E-DAIC\nwas another limiting factor. Future work should ensure a\nreasonable number of samples for the underprivileged group in\nfairness metric calculation, to experiment with other evaluation\nmethods beyond just stratified k-fold cross validation, and\nconsider using other fairness metrics such as Equal Oppor-\ntunity and Equalized Odds [60] to ensure more thorough and\ncomprehensive evaluation. Future research can also focus on\ndeveloping solutions to mitigate bias issues in both datasets.\nThis will enhance our understanding of how to address bias\nin datasets from different countries. Future work can also\ninvestigate other methods [61], [62] or orthogonal forms of\nfairness [63], [64] to better understand the root cause of bias.\nWe made a conscious effort to repeat the experiments\nfor different algorithms to ensure that the results are not\nalgorithm-dependent. We hope that our work will encourage\nother researchers to take into consideration fairness and other\nethical concerns when developing ML-equipped agents and\nrobots for wellbeing [65]\u2013[69]. Given the high-stakes involved\nin using such agents and robots for wellbeing coaching [3],\n[5], [70], we hope our results and findings will encourage more\nconsistent and culturally-aware data collection for depression\n[71], thus paving the way towards developing fairer ML-\nequipped agents and social robots for providing wellbeing to\nall."}, {"title": "ETHICAL IMPACT STATEMENT", "content": "We recognise the sensitive nature of this study and have\nadopted measures aligned with ethical guidelines. The datasets\nused have been anonymised by the dataset owners to minimise\nprivacy impact. Our work attempts to avoid any bias against\ncertain groups of people that could result in discrimination.\nHowever, our results are limited to the datasets included in\nthis work. Future work should repeat the same analysis on\nother depression datasets to further validate our findings."}]}