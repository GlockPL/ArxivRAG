{"title": "VLSI Hypergraph Partitioning with Deep Learning", "authors": ["Muhammad Hadir Khan", "Bugra Onal", "Eren Dogan", "Matthew R. Guthaus"], "abstract": "Partitioning is a known problem in computer science and is critical in chip design workflows, as advancements in this area can significantly influence design quality and efficiency. Deep Learning (DL) techniques, particularly those involving Graph Neural Networks (GNNs), have demonstrated strong performance in various node, edge, and graph prediction tasks using both inductive and transductive learning methods. A notable area of recent interest within GNNs are pooling layers and their application to graph partitioning. While these methods have yielded promising results across social, computational, and other random graphs, their effectiveness has not yet been explored in the context of VLSI hypergraph netlists. In this study, we introduce a new set of synthetic partitioning benchmarks that emulate real-world netlist characteristics and possess a known upper bound for solution cut quality. We distinguish these benchmarks with the prior work and evaluate existing state-of-the-art partitioning algorithms alongside GNN-based approaches, highlighting their respective advantages and disadvantages.", "sections": [{"title": "I. INTRODUCTION", "content": "Modern Electronic Design and Automation (EDA) tools use partitioning throughout the design flow. This may be during placement, simulation, emulation, or any number of other steps. Improving partitioners can directly make these steps work better and improve design quality of results.\nFundamental partitioning heuristics like FM [1] and KL [2] work reasonably well for small graphs, but not for large ones. Spectral partitioning [3] improved upon this by using a graph's topological structure through its Eigenvectors to induce an ordering used for partitioning. This spectral ordering was frequently used to initialize the partitions and then the fundamental heuristics like FM were used for refinement. The state-of-the-art partitioning algorithms, however, use multi-level [4], [5] approaches that cluster and refine so that fundamental algorithms can scale to large graphs.\nRecently, partitioning has gained interest in the Machine Learning (ML) community for pooling in Graph Neural Networks (GNNs) [6]. Pooling performs clustering on a graph to create a reduced graph with a representative set of features on the fewer, new graph nodes. There have been numerous algorithms proposed for pooling in GNNs [7]\u2013[10].\nSimilar to pooling, the Generalizable Approximate Graph Partitioning Framework (GAP) [11] performs partitioning on general graphs by relying on features generated from the Principal Component Analysis (PCA) components. GAP is similar to spectral partitioning techniques [12] except that a linear ordering is avoided and instead an ML classification with a trainable inference step is utilized. Compared to the other ML pooling techiques, GAP is the only work to analyze inductive learning on unseen graphs.\nThe new ML partitioning and pooling algorithms, however, have not been considered for use in the VLSI domain. These pooling techniques are instead evaluated on graph classification benchmarks [13], node classification datasets (Cora, Citeseer, and Pubmed), computation graphs [11], or synthetic random graphs [11]. Graphs from VLSI design problems have unique characteristics compared to these, however. Most importantly, VLSI designs are hypergraphs and need to be expanded to a simple graph in order to be compatible with most GNN convolution and pooling layers. In particular, VLSI design graphs have gates with limited (e.g., 2-5) inputs and typically a single output. These gates have different areas depending on the number of transistors, their sizes, and their internal connectivity. Fan-out of these gates is also limited (e.g., 3-8) by wire resistance and load capacitance. Some special nets, like clocks and resets, may have high-fan-out that are later buffered. The nets that connect the fan-out are best represented as hyperedges with a single driver and multiple fan-out gates. Input/output pins, or terminal pins, usually have a fixed location and are permanently assigned to a single partition. Most applications of partitioning in VLSI also have a constraint on partition balance so that the gates fit in a given area. Lastly, VLSI design has many objectives such as criticality, wire length, noise, etc. for which net cut is merely a proxy.\nIn this paper, we propose a new set of synthetic benchmarks, called Partitioning Examples with Rent's Rule Derived Information (PERRDI), to analyze the advantages and disadvantages of ML partitioning for VLSI design. Our synthetic partitioning benchmarks have a known upper cut bound and resemble typical VLSI design netlist characteristics. We then use these to analyze the best methods to train ML partitioning, examine the run-time, and compare how sub-optimal it is to other partitioners and known upper bound solutions."}, {"title": "II. BACKGROUND", "content": ""}, {"title": "A. Synthetic Partitioning Benchmarks", "content": "One prior work, called Bipartitioning Examples with Known Upper bounds (BEKU) and Multi-way Partitioning Examples with Known Upper bounds (MEKU), examined partitioning on VLSI graphs by generating a set of \"known upper bound\" synthetic graphs [14]. BEKU and MEKU were used to study"}, {"title": "B. GNNS", "content": "Graph Neural Networks (GNNs) are types of neural net-work (NN) models. They input a non-uniform graph, unlike Convolutional Neural Networks (CNNs), which input a regular matrix [17]\u2013[19]. GNNs can be seen as specialized techniques of CNNs. GNN models can be trained for node prediction, edge prediction, and graph classification tasks.\nGNNs can be trained for either transductive or inductive inference. Transductive training refers to tasks that have a specific set of test inputs. On the other hand, inductive learning refers to training for a more general problem on unknown inputs. Similar to other NNs, GNNs can be trained in supervised and unsupervised ways.\nThe message passing feature is the core principle behind GNNs. This is an iterative process of updating the features (H) of the nodes using learnable weights (W). A message-passing layer can be written in matrix form as\n$H_{k+1} = \\sigma(A \\times H_k \\times W_k).$ (1)\nwhere $H_k$ is matrix of stacked feature vectors for each node at the $k^{th}$ layer; A is the adjacency matrix of the graph; $W_k$ is the learnable component in the $k^{th}$ layer; and $\\sigma(\\cdot)$ is any non-linear activation function. This message-passing method is used as a way to discover feature embeddings for further use with downstream tasks such as node prediction.\nGNNs can have an over-smoothing issue where node features converge to similar values for deeply layered net-works [20]. This can mostly be addressed by tuning the model's hyperparameters to have appropriate levels, but it has also been examined through adaptive mechanisms [21]."}, {"title": "C. GAP", "content": "The Generalizable Approximate Graph Partitioning (GAP) framework [11] is a deep learning-based approach using GNNs to efficiently partition graphs into balanced subsets while minimizing edge cuts. GAP consists of an embedding module and a partitioning module. The embedding module is used to extract topological structure of the input graph by leveraging the input node features and the graph connectivity. It's purpose is to learn a new set of node features that best represent the local connectivity. GAP uses GCN [17] and GraphSAGE [19] as the layers inside the embedding module to learn the node representations of the graph. The partitioning module takes the learned node representations as the input and generates the probabilities of each node belonging to partitions $S_1, S_2, ..., S_k$. This module consists of a fully connected layer followed by a softmax activation.\nGAP uses unsupervised learning and introduces a differentiable loss function that captures the minimum-cut objective of graph partitioning while leveraging back-propagation to optimize the model parameters. The loss function is the expected normalized cut which is defined as:\n$Ncut(S_1, S_2,...S_n) = \\sum_{k=1}^n \\frac{cut(S_k, \\overline{S_k})}{vol(S_k, V)}$ (2)\nwhere $S_k$ is partition k of n partitions on V nodes. The volume (vol) of a partition is the degree of all nodes belonging to the partition and the cut is the number of nets with at least one node inside ($S_k$) and one outside ($\\overline{S_k}$) of the partition. The cut of one partition k is\n$cut(S_k, \\overline{S_k}) = \\sum_{\\forall v_i \\in S_k, \\forall v_j \\in \\overline{S_k}} e(v_i, v_j)$ (3)\nfor one partition and half the sum of all partition cuts when considering the cut of an entire graph.\nThe GAP paper [11] performs an analysis of inductive learning which uses models trained on specific graphs to perform effectively on unseen ones. GAP incorporates graph embedding techniques using PCA to account for graph struc-tures.\nGAP indirectly considers partition balance through the volume portion of the loss function. Since the cut size of a partition is normalized to the volume, unequal volumes will indirectly result in unequal cut sizes. Later versions of GAP introduced an explicit balance loss, but this loss is not normalized and is the total difference of partition sizes from the ideal partition size. This means that combining the two loss functions results in primarily optimizing for balanced partitions and not minimum cut.\nGAP demonstrated significant improvements of up to 100\u00d7 in speed and simultaneous improvements in solution quality compared to hMETIS on Erd\u0151s-Reny\u00ed random graphs [22], scale free random graphs [23], and computation graphs [11]. However, they did not examine VLSI design graphs which have unique properties as mentioned earlier."}, {"title": "III. BENCHMARK IMPLEMENTATION", "content": "We propose a new set of synthetic benchmarks called Partitioning Examples with Rent's Rule Derived Information (PERRDI). Our benchmarks consider a Net Distribution Vector (NDV) to describe the fan-out of nets in a design, but we also utilize a Gate Distribution Vector (GDV) which simultaneously describes the number of inputs/outputs on gates in a design. Each of these is a discrete probability distribution function describing the sizes and their given probabilities extracted from real designs allowing the flexibility to rescale the graphs as needed.\nAlgorithm 1 details the pseudo-code for our proposed PER-RDI benchmarks. Using the probability distribution functions for NDV and GDV allow us the flexibility to scale the number of nodes in the graph which is an input to the algorithm. We denote a dictionary NDV with key-value pairs (s,p) where s \u2265 2 is the net-size and p \u2208 [0, 1] represent the percentage of this net-size in the design. Similarly, we denote a dictionary GDV with key-value pairs (g,p) where g \u2265 2 is the gate-pins and p \u2208 [0, 1] represent the percentage of this gate in the design.\nWe do a weighted sample from the GDV to get the maximum degree (max_deg) of each node which ensures our design follows the GDV distribution. We determine the number of cut nets (cut_pins) using the Rent's rule. Using the total number of components in each partition, the number of pins on that partition will determine the number of cut nets. Our algorithm adds cut nets until the predetermined number is met. Then it continues adding uncut nets until the current degree (cur_deg) of each node reaches the maximum degree (max_deg) limit. We do a weighted sample of the net sizes (net_size) from the NDV which ensures our design follows the NDV distribution."}, {"title": "IV. METHODOLOGY", "content": "We implemented our model using the Tensorflow [25] and Spektral [26] libraries. We used the same model parame-ters as in GAP-Random [11]: the embedding module uses GraphSAGE with 2 layers of 256 units and shared pooling,"}, {"title": "D. Net Models", "content": "The most significant difference between VLSI design graphs and other typical graphs is that VLSI applications use hyper-graphs. In a directed (or undirected) graph, an edge ($e_{ij}$) is a connection between node $n_i$ and $n_j$. In a hypergraph, a hyperedge is typically represented as a set of two or more nodes $e_n = \\{n_i, n_j, ...\\}$. During graph partitioning, a cut of a hyperedge will result in a cut of one just like a cut of an undirected edge. Often, hypergraphs are decomposed into simpler undirected or directed graphs.\nClique expansion is one model that enumerates all possible pairs of edges to form a complete graph to represent a hyperedge, so it grows quadratically in size. The decomposed edges are often given partial weight depending on the size of the edge to not change the total edge weight of the graph. While this has complete connectivity information, it is also problematic when considering cut sizes because you cannot distinguish between different hyperedges.\nStar expansion is a model that connects all nodes in a hyperedge to an extra zero weight node. The star model requires identifying star nodes separately from design nodes by zero weight so that it does not affect balance, but has the advantage that it grows only linearly in complexity. In partitioning, for example, the star node must also be added to a partition to determine the cut size.\nA fanout expansion (or sometimes called source/sink expan-sion) is a partial clique model that distinguishes the source or driver node of a hyperedge in a VLSI circuit from the other fanout or sink nodes. This model therefore only enumerates all edges from the driver and grows linearly.\nThere has been some work on Hypergraph Neural Net-works [24], but these have not been extended to GNN par-titioning or pooling."}, {"title": "VI. EVALUATION OF PARTITIONING ALGORITHMS", "content": ""}, {"title": "A. Graph Inference", "content": "In this section, we evaluate how well the GAP model can infer on new graphs and compare how it does with state-of-the-art partitioner (hMETIS) [5], fundamental heuristics (FM), and the known upper bound from PERRDI.\nIn order to study how well GAP performs on VLSI like graphs from PERRDI, we generated the training/validation/test set and used GAP alongside hMETIS, FM and Upper Bound from our graphs. Figure 2 shows this comparison.\nThe \"GAP same size model\u201d is a unique model specifically trained for each graph of a given node size and is considered as the baseline. We further explored how mixing the dataset with different varying graph sizes would affect the learning. For this, we trained \u201cGAP mixed size model\u201d where we provide a set of varying number and size: 5 \u00d7 100, 10 \u00d7 200, 15 \u00d7 300, 20 \u00d7 400, 60 \u00d7 500, 25 \u00d7 600, 20 x 700, 15\u00d7800, 10\u00d7900, and 5 \u00d7 1000. These had a total of 100,000 nodes. We used these to train the model and reserved a set to test on the ranges of graphs shown in the Figure 2. Note that even with graphs of sizes less than 5000 nodes, the GAP mixed model was able to achieve almost as good results as the baseline. However, apart from that there is a significant difference in terms of cut-size that GAP is able to achieve in comparison with other partitioners."}, {"title": "B. Run-Time", "content": "The distinct advantage of GAP compared to other parti-tioning methods is run-time. We evaluated on graphs ranging from 5000 to 30000 nodes and show the results in Figure 3. GAP inference run-time is nearly constant but computation of the PCA components for input features can be significant.\nWe used PyCUDA [31] to run parallel PCA computation for 1000 components for all sizes of graphs and included that along with GAP inference runtime. hMETIS, however, has significant increase in run-time compared to both inference and inference including PCA.\nThe GAP run-time remains constant until GPU memory is exhausted, but GNNs use sparse matrices for the adjacency matrix which enables very large graphs. The feature matrix, however, uses PCA components and is dense, so we discuss the size needed for these features later in Section VI-E."}, {"title": "C. Net Model", "content": "GNNs do not inherently support hyperedges so this requires modeling hypergraphs as simple graphs to utilize all of the layers and features available to GNNs. We use the mixed size training set for this experiment (i.e. one trained model for all GAP experiments) and evaluate on 10 random graphs of each size. We show the results of three different models (clique, fan-out, and star) and comapre the results with hMETIS, FM, and the known upper bound in Figure 4. The results show that the fan-out model has a significant improvement over both the clique and star models but there is still sub-optimality compared to the known upper bound and other partitioners."}, {"title": "D. Balanced Partitioning", "content": "GAP does not explicitly have a balance constraint, but it is indirectly considered in the normalized expected cut loss function, shown in Equation 2. The denominator has the volume of a partition which is the total degree of nodes that belong to a partition:\n$vol(S_k, V) = \\sum_{v_i \\in S_k, \\forall v_j \\in V} e(v_i, v_j)$. (4)\nSince the volume normalizes the cut of each partition relative to the total connections (degree), an imbalance of volume would result in an imbalance of normalized cut. In bi-partitioning, for example, the absolute cut of each partition is the same, but normalization by different volumes would result"}, {"title": "E. Graph Topology and Embedding", "content": "The graph structure has a direct impact on a graph's topology. Since GAP uses initial PCA components as features for the embedding, we explore the sensitivity to the number of these components used. The original GAP work used all of the features (e.g., for 1000 nodes, it used 1000 features) which would be too many for realistic VLSI designs and would result in slow training times. Also it might over-shadow other important features one might want to incorporate for the GNNs to learn from such as timing, reliability, and power.\nRelated to this, previous partitioning works have shown that more Eigenvectors are better for spectral partitioning [12], but we have found that GAP achieves a minimal cut size with far fewer features. We analyzed this by training a model with a mixed-size set of graphs and up to 1000 features (smaller graphs used fewer features and were padded by 0's). During inference on 10 test graphs of 1000 nodes, we varied the number of features used and the results are shown in Figure 5 with a mean known upper bound cut-size of 322.5. With lower numbers of features, the balancedness is quite high which can lead to an artificially low cut-size but the upper bound is best with at least 9 PCA components while balancedness stabilizes. The small increase of balancedness on the right is not a trend with further increases."}, {"title": "F. Multi-way Partitioning", "content": "GAP can perform multi-way partitioning by adjusting the final dense layer to have softmax k outputs for k-way par-"}, {"title": "VII. CONCLUSION", "content": "In this paper, we explored the advantages and disadvantages of applying Deep Learning (DL) to VLSI design partition-ing. We introduced and examined a new set of synthetic benchmarks, PERRDI, with known upper bound solutions and VLSI design-like characteristics. Our study demonstrated DL models' capability to infer partitions on novel, unseen VLSI design graphs, highlighting trade-offs with training methodolo-gies, net models, and number of input features. Notably, our findings show significant potential for run-time improvement with DL-based partitioning, but we also identify areas for enhancement, including cut-size quality, balance constraints, and k-way partitioning extensions."}]}