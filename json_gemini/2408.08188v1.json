{"title": "Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy", "authors": ["Shaojun Xu", "Xusheng Luo", "Yutong Huang", "Letian Leng", "Ruixuan Liu", "Changliu Liu"], "abstract": "Long-horizon planning is hindered by challenges such as uncertainty accumulation, computational complexity, delayed rewards and incomplete information. This work proposes an approach to exploit the task hierarchy from human instructions to facilitate multi-robot planning. Using Large Language Models (LLMs), we propose a two-step approach to translate multi-sentence instructions into a structured language, Hierarchical Linear Temporal Logic (LTL), which serves as a formal representation for planning. Initially, LLMs transform the instructions into a hierarchical representation defined as Hierarchical Task Tree, capturing the logical and temporal relations among tasks. Following this, a domain-specific fine-tuning of LLM translates sub-tasks of each task into flat LTL formulas, aggregating them to form hierarchical LTL specifications. These specifications are then leveraged for planning using off-the-shelf planners. Our framework not only bridges the gap between instructions and algorithmic planning but also showcases the potential of LLMs in harnessing hierarchical reasoning to automate multi-robot task planning. Through evaluations in both simulation and real-world experiments involving human participants, we demonstrate that our method can handle more complex instructions compared to existing methods. The results indicate that our approach achieves higher success rates and lower costs in multi-robot task allocation and plan generation.", "sections": [{"title": "1 Introduction", "content": "The challenge of long-horizon planning arises from factors such as uncertainty accumulation, computational complexity, delayed rewards and incomplete information. A strategy is by leveraging the task hierarchy. Hierarchical models have demonstrated a notable edge over flat models in interpretability and efficiency [1, 2]. However attractive, how to obtain hierarchy still remains an open problem. One pathway is to deduce hierarchy through the observation of task execution [3], which alleviates human effort yet poses a challenge due to a high requirement for abstraction reasoning. Conversely, the other route, which entails acquiring hierarchy directly from human, appears straightforward. Humans excel at hierarchical reasoning and are used to articulate hierarchically through language effortlessly [4]. Nonetheless, the hierarchical insights from humans cannot be readily integrated by algorithms without meticulous engineering. This gap between human preferences and algorithmic formulation impedes the application of hierarchy-based planning algorithms.\nLLMs, being trained on extensive textual corpus, exhibit common sense reasoning abilities, thereby efficiently managing everyday task specifications articulated in human languages. Our key observation is that hierarchy can be progressively obtained from human input with the help of a LLM."}, {"title": "2 Related Work", "content": "Language-Conditioned Robotic Planning Given instructions, there are two primary methods for generating actions [7]. The first uses deep-learning techniques translate instructions into low-level actions, such as joint states, examples of which include Open-X Embodiment [5] and Octo [18]. Such systems exhibit generalization capabilities across multiple modalities [19, 20], but they depend on large volumes of data. Alternatively, another method initially translates instructions into an intermediate representation, then employing off-the-shelf solvers to generate actions. This approach limits the solution space, thereby reducing the need for extensive data. The intermediate representations employed can vary from formal planning formalisms such as Planning Domain Definition Language (PDDL) and temporal logics, to less formal structures like code or predefined skills.\nPDDL is a model-based planning formalism outlining how to achieve a goal state from an initial state. Xie et al. [21] have explored prompting LLMs to extract goal states from instructions. Liu et al. [22] expand the approach to extract domain descriptions using LLMs. More recently, proposals for extensible benchmarks have emerged, aiming to systematically evaluate the planning capabilities of LLMs for tasks defined in PDDL [23]. LLMs also have shown promise in synthesizing code. ProgPrompt [24] leverages LLMs to call APIs that represent action primitives. Similarly, Code as Policies [25] employs LLMs to generate low-level executable code. Similar approaches are used in [26, 27, 28]. Instead of providing all APIs, Voyager [29] continuously writes executable codes and saves them in the skill library as reusable APIs. Saycan [30] uses LLMs to arrange pre-defined skills requiring precise visuomotor control. Inner Monologue [31] enhances this by integrating closed-loop language feedback to address failures. KNOWNO [32] adjusts LLM-based planners to align uncertainty, enabling the systems to seek assistance when necessary. A commonality is their focus on single-robot scenarios; however, extending these approaches remains largely unexplored.\nNatural Language to Temporal Logic Temporal logics are effective in tackling goals that involve temporal constraints and providing performance assurances. Initially, adaptations of natural language into temporal logics adopted grammar-based methods, which are well-suited for structured inputs [33]. More recently, the application of LLMs for such reasoning tasks has become popular [34]. Efforts like prompting GPT-3 to create LTL formulas by relying on established patterns. Cosler et al. [15] use LLMs to facilitate user interactions that help refine ambiguous or incorrect translations. However, these models focus on the translation process and do not tackle the challenges of language grounding in robotics-linking language with physical actions and environments. Pan et al. [35] develop a synthetic dataset of instructions paired with temporal logic formulas, used to fine-tune an LLM. Similarly, [36] translates languages into Signal Temporal Logic (STL) that handles combined task and motion planning. On the other hand, He et al. [37] create neural networks from scratch using synthetic data. Conversely, Patel et al. [38], Wang et al. [39] develop a weakly supervised semantic parser using execution trajectories without explicit LTL annotations. Liu et al. [40] introduce Lang2LTL, a modular system that employs LLMs to convert navigational commands into LTL specifications. Hsu et al. [41] use LLMs to transform natural language queries into First-Order Logic (FOL) programs, which are executed by FOL processors. In a different approach, Wang et al. [42] begin with a predefined LTL specification, with each predicate defined by concise instructions. Our research sets itself apart in several aspects: we address complex instructions using a hierarchical approach and incorporate task allocation among multiple robots."}, {"title": "3 Preliminary", "content": "Linear Temporal Logic Linear Temporal Logic (LTL) is composed of basic statements, referred to as atomic propositions AP, along with boolean operators such as conjunction (\u2227) and negation (\u00ac), and temporal operators like next (\u25cb) and until (U) [49]. LTL formulas follow the syntax:\n$\\varphi := \\top|\\pi | \\Phi_1 \\wedge \\Phi_2 |\\neg \\Phi|\\bigcirc \\Phi | \\Phi_1 \\text{U} \\Phi_2$, where $\\top$ stands for a true statement, and $\\pi$ is a boolean valued atomic proposition. Other temporal operators can be derived from U, such as \u25ca that implies $\\phi$ will be true at a future time. We focus on a subset of LTL known as syntactically co-safe formulas (sc-LTL) [50]. Any LTL formula encompassing only the temporal operators \u25ca and U and written in positive normal form (where negation is exclusively before atomic propositions) is classified under sc-LTL formulas [50], which can be satisfied by finite sequences followed by any infinite repetitions. This makes sc-LTL apt for reasoning about robot tasks with finite durations.\nHierarchical LTL A hierarchical LTL, denoted by $\\Phi = {\\phi_i^k | k = 1, ..., K, i = 1,...,|\\phi_k|}$ where $\\phi_i^k$ is the i-th sc-LTL specification at level k, $\\phi_k$ denotes all specifications at level k, and $|\\cdot|$ denotes the cardinality, includes K levels such that each specification at level k, for k = 1, . . ., K \u2013 1, is constructed from specifications at the lower level k + 1.\nWe refer to each specification $\\phi_i^k$ or $\\phi_k$ in $\\Phi$ as the \u201cflat\u201d specification. These flat specifications can be organized in a tree-like specification hierarchy graph, where each node represent a flat sc-LTL specification. Edges between nodes indicate that one specification encompasses another as a composite proposition. This composite proposition is, in essence, another flat sc-LTL formula. Leaf nodes represent leaf specifications at the K-th level that consist only of atomic propositions, while non-leaf nodes represent non-leaf specifications made up of composite propositions."}, {"title": "4 Natural Language to Hierarchical LTL", "content": "LLMs excel in common sense reasoning yet behavior poorly in logical reasoning [16, 51]. Therefore, we propose a two-stage method for translating natural language into hierarchical LTL using an intermediary structure known as the Hierarchical Task Tree. The framework is displayed in Fig. 1."}, {"title": "4.1 Conversion from human instructions to Hierarchical Task Tree", "content": "Definition 4.1 (Hierarchical Task Tree (HTT)) A Hierarchical Task Tree (HTT) is a tree T = (V,E, R), where a) V = {v1, v2, ..., vn} denotes the set of nodes, each representing a task. Each node is associated with a human instruction that describes its respective task. b) E \u2286 V\u00d7V represents the edges, indicating a decomposition relationship between tasks. Specifically, an edge e = (v1, v2) \u2208 E implies that child task v2 is one of sub-tasks of parent task v1. The node set V can be partitioned into multiple disjoint subsets {V1, ..., Vm}, such that all nodes within the same subset Vi share the same parent node. c) R \u2286 V\u00d7V defines the set of temporal relations between sibling tasks, which are decompositions of the same parent task. Specifically, a relation (v1, v2) \u2208 R, where v1, v2 \u2208 Vi for some i \u2208 {1, ..., m}, indicates that task v1 should be completed before task v2.\nThe tree is structured such that it unfolds level by level, where each child task is a decomposition of its parent task. The HTT is a simplified version of the hierarchical task network (HTN) as is specifically designed to align with the structure of hierarchical LTL. The relation R specifically captures the temporal relationships between sibling tasks that share the same parent. The temporal relationship between any two tasks can be inferred by tracing their lineage back to their common ancestor. This is the primary distinction between HTT and HTN, where HTN includes interdependencies between sub-tasks under different parent tasks. Another difference is that each node in the HTT is solely focused on the goal of a sub-task and does not incorporate other properties like preconditions and effects that are found in HTN. When a task instruction is received, we use LLMs to construct the HTT through a two-step process, as outlined in step 1 of Fig. 1.\n1. HTT without temporal relations R. The first step involves generating the nodes V and edges E, excluding the temporal relations R. Leveraging the LLMs' extensive understanding of hierarchical reasoning, the model decomposes the overarching task into a structured hierarchy. The decomposition continues until a task consists solely of sequential operations performed on a single object.\n2. Add temporal relations R. We achieve this by iterating over each non-leaf node. For each non-leaf node v, we consider V', which represents its child tasks at the level directly beneath it. Using LLMs, we then determine the temporal relations between sibling tasks within V'."}, {"title": "4.2 Generation of task-wise flat LTL specifications", "content": "Once the HTT representation is obtained, we advance to generate a single flat LTL specification for each node. This is described in Alg. 1, which employs a breadth-first search.\n1. Logical search For every non-leaf node v, we gather its child tasks V' and the temporal relations among them, defined by R' \u2286 V' \u00d7 V'. We then use LLMs to rephrase these child tasks and their temporal relations into syntactically correct sentences aligned with the semantics of LTL specifications (as illustrated in step 2.1 in Fig. 1). These reformulated sentences are input into a fine-tuned LLM that produces a single LTL formula (as depicted in step 2.2 in Fig. 1). It is important to note that we do not substitute the task node with its corresponding human instruction; instead, we use a \"lifted\" format where specific tasks are replaced with abstract symbols, like \"task 1.1 should be completed before task 1.2\". This abstraction allows the fine-tuned LLMs to operate without needing detailed knowledge of the tasks, as demonstrated in [35, 36].\n2. Action completion Given an HTT, each leaf node should represent a simple task on certain object, such as \u201ctask 1.1.1 place plates into the lower rack\" in Fig. 1. By viewing such simple task as a sequence of action steps, we prompt the LLM to generate a sequence of pre-defined API calls to expand the simple task. For instance, the symbol $\\pi_o^{plates}  that represents task 1.1.1 can be replaced with LTL specification composed of sequential APIs: $\\pi_o^{plates}  =  \\Diamond (\\text{Pickup(plate)} \\wedge \\Diamond \\text{Move(plate, lower\\_rack)});$ see step 2.2 in Fig. 1. After this step, a complete hierarchical LTL specifications is generated.\nRemark 4.2 Assuming the HTT contains n1 + n2 nodes (n\u2081 non-leaf nodes and n\u2082 leaf nodes), our method queries LLMs 2(n1+n2)+1 times. Firstly, LLMs are queried once to create the HTT without temporal relations. Subsequently, LLMs are invoked n1 + n2 times to derive temporal relations for non-leaf nodes and to complete actions for leaf nodes. Finally, a fine-tuned LLM is used n1 + n2 times to transform each node into flat LTL formulas."}, {"title": "5 Experimental Results", "content": "We evaluate the performance both in a simulated environment and through real-world experiments. For simulation, we use the AI2-THOR simulator [52] coupled with the ALFRED dataset [53]. AI2-THOR provides an interactive 3D environment that models various domestic settings. The ALFRED dataset focuses on natural language comprehension and embodied actions. We carried out two real-world experiments: one involving a robotic arm arranging fruits and vegetables on a tabletop, and another where four robotic arms transferred objects through handover. Throughout the evaluation, we employ the LLM ChatGPT-4 and aim to answer three key questions:\n1. Is our approach capable of handling complex human instructions effectively?\n2. Does our method successfully address tasks involving multiple robots while producing a high quality of solutions?\n3. Is our method flexible enough to adjust to the verbal styles of various users?"}, {"title": "5.1 Mobile manipulation tasks in AI2-THOR", "content": "Tasks The ALFRED dataset contains instructions for tasks with a number of strictly sequential steps, which we classify as base tasks. To create more complex tasks, we procedurally combine base tasks from the same floor plan and object configuration to generate derivative tasks, which are detailed in Appendix B.1. Derivative tasks are categorized based on the number of base tasks, which vary from 1 to 4."}, {"title": "6 Conclusions and Limitations", "content": "We proposed a method of transforming unstructured language into a structured formal representation with hierarchical structure. Our simulation and real-world experiment outcomes demonstrated that the framework offers an intuitive and user-friendly approach for deploying robots in daily situations.\nLimitations The proposed framework operates as an open loop without feedback. To transition to a closed-loop one, it is essential to integrate a syntax checker and a semantic checker. These components interact continually with LLMs to enhance the success rate. The syntax checker verifies adherence to the hierarchical LTL structure necessary for HTT representation. Meanwhile, the semantic checker offers feedback on errors when the planner fails to identify a solution. Another limitation is that once created, the HTT representation remains unchanged. Recall that we derive an LTL specification by extracting child tasks from a parent task. As more child tasks are included, the accuracy of translation drops. Therefore, to handle tasks with more base tasks, it is necessary to restructure the HTT to restrict the number of child tasks a single parent task has."}]}