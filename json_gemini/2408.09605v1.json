{"title": "Does Thought Require Sensory Grounding? From Pure Thinkers to Large Language Models", "authors": ["David J. Chalmers"], "abstract": "Presidential Address delivered under the title \u201cCan a Large Language Model Think?\u201d at the one hundred nineteenth Eastern Division meeting of the American Philosophical Association on January 6, 2023. Does the capacity to think require the capacity to sense? A lively debate on this topic runs throughout the history of philosophy and now animates discussions of artificial intelligence.", "sections": [{"title": "THE SENSE-THOUGHT THESIS", "content": "The primary thesis at issue is what I'll call the sense-thought thesis:\nSense-Thought Thesis: Thinking requires having had the capacity to sense.\nWe could put the thesis a little more precisely by saying that necessarily, if S thinks a thought at time t, then S was able to sense at some time at or before t. The rest of this section clarifies various elements of the thesis (if you don't care about these details, feel free to skip them).\nRegarding \"having had\u201d and \u201cat or before t\u201d: there are stronger sense-thought theses saying that thinking requires concurrent sensing or at least a concurrent capacity to sense. But the past-directed \u201chaving had\" thesis comes closer to capturing the formulations from Aquinas and Hume above, which seem to require that thinking be grounded in previous sensing. The past-directed thesis also plausibly allows that a being could lose the capacity to sense while continuing to think thoughts that were grounded in its prior sensory capacities. An alternative present-directed thesis without \u201chaving had,\u201d more in the spirit of Aristotle's formulation, says that all thinking requires (and perhaps is grounded"}, {"title": "PURE THINKERS", "content": "The sense-thought thesis turns on whether pure thinkers are possible. Pure thinkers, I'll stipulate, are beings that can think but that have never had the capacity to sense, and that lack even quasi-sensory capacities such as imagery. The name is reminiscent of Descartes's \u201cpure intellects.\u201d Both labels might seem to exalt the beings, but I do not intend that"}, {"title": "IS A PURE THINKER POSSIBLE?", "content": "Is a pure thinker who completely lacks sensory capacities possible? We can start by considering whether there are actual human cases. Deafblind people such as Helen Keller are occasionally brought up in this context, but Keller had many sensory capacities (touch, smell, taste, bodily senses), and even her deafness and blindness were not congenital. I don't know of any cases of a human with no functioning senses (including bodily senses) since birth, but it seems very likely that such a human would never develop the ability to think, at least given standard biology and today's medical technology. If so, there have been no actual human pure thinkers.\nWhat about future human pure thinkers, or possible human pure thinkers? Perhaps new technologies could make it possible to enable some human cognitive capacities without enabling sensory capacities, though it would probably be cruel to do so. If this is even possible, then the human sense-thought thesis is strictly speaking false, though a version of it restricted to actual humans could be true.\nWhat about broadening the scope to include nonhumans? Here the salient cases in the history of philosophy include angels and gods, while the most important cases for our purposes include Al systems. I will not argue that large language models are themselves pure thinkers. For a start, language models have inputs and outputs, whereas pure thinkers as we have defined them do not. But for our purposes in assessing the sense-thought thesis, it is useful to consider whether a more extreme system without inputs and outputs could be a pure thinker. Later, I'll return to the upshot for language models.\nIt seems clear that a pure thinker is at least prima facie conceivable. Science fiction stories sometimes discuss Al systems that are at least much like pure thinkers. For example, Robert Sawyer's novel Wake describes an Al system that gradually \u201cwakes up\" and starts thinking, without having any senses. Perhaps Sawyer's system as described has at least auditory imagery via voices in its head, but we can easily tweak the situation so that it has no sensory capacities (including no imagery) at all. Such a system seems clearly conceivable, at least on first appearances."}, {"title": "WHAT COULD A PURE THINKER THINK?", "content": "What would it be like to be a pure thinker? As I'm thinking of them, pure thinkers would be conscious and could undergo nonsensory experiences"}, {"title": "PURE THINKER/TALKERS AND LARGE LANGUAGE MODELS", "content": "How does our discussion of pure thinkers apply to Al systems? It suggests that the mere absence of sensory capacities in an Al system does not entail that the system cannot think or understand. The absence of sensory capacities may impose some limits on thinking, but they do not rule it out altogether. If we devised a \u201cpure\u201d Al system with no input/ output connections to the world, its lack of connections to the world would not alone prevent it from being able to think and understand a good deal, from mathematics to philosophy to speculative scientific hypotheses about reality. Of course, there could be other factors that can rule out thinking and understanding in Al systems altogether, but the lack of sensory grounding is not one of them.\nLarge language models are a trickier case. As we have seen, their capacities exceed those of pure thinkers in at least one important respect. They have a robust input/output system, receiving textual inputs and producing textual outputs."}, {"title": "CAN LARGE LANGUAGE MODELS THINK?", "content": "Where does all this leave large language models? I have not argued directly that large language models can think or understand. There are all sorts of arguments against thought and understanding in Al systems, from G\u00f6delian arguments to arguments that thought requires biology, that I have not addressed. There are also arguments specifically against thought and understanding in LLMs, from arguments that LLMs lack consciousness or communicative intent to arguments that they are \"stochastic parrots.\u201d All those arguments require separate treatment.\nStill, I have rebutted one argument against thinking and understanding in LLMs: the argument from sensory grounding. I have argued that the absence of (nonlinguistic) sensory capacities in large language models is not itself an obstacle to their thinking or understanding. If I am right, the standard grounding argument against LLM thought and understanding at the start of this paper fails. The first premise (LLMs lack sensory capacities) may be false, at least if we count linguistic inputs in LLMs as a sensory capacity. The second premise (genuine thought requires sensory capacities) is more clearly false: our examination of"}, {"title": "DOES SENSING BOOST THINKING?", "content": "Even if thinking does not require sensing, does sensing at least boost thinking? That is, do sensory capacities enhance cognitive capacities, in the sense of improving performance on cognitive tasks even when those tasks are not essentially tied to the sensory domain? In humans, the answer seems to be yes. The use of visual imagery can sometimes improve performance on mathematical tasks, for example, and visual memory can certainly enhance performance on memory tasks."}]}