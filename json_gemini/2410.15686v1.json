{"title": "NetSafe: Exploring the Topological Safety of Multi-agent Network", "authors": ["Miao Yu", "Shilong Wang", "Guibin Zhang", "Junyuan Mao", "Chenlong Yin", "Qijiong Liu", "Qingsong Wen", "Kun Wang", "Yang Wang"], "abstract": "Large language models (LLMs) have empowered nodes within multi-agent networks with intelligence, showing growing applications in both academia and industry. However, how to prevent these networks from generating malicious information remains unexplored with previous research on single LLM's safety being challenging to transfer. In this paper, we focus on the safety of multi-agent networks from a topological perspective, investigating which topological properties contribute to safer networks. To this end, we propose a general framework named NetSafe, along with an iterative RelCom interaction to unify existing diverse LLM-based agent frameworks, laying the foundation for generalized topological safety research. We identify several critical phenomena when multi-agent networks are exposed to attacks involving misinformation, bias, and harmful information, termed as Agent Hallucination and Aggregation Safety. Furthermore, we find that highly connected networks are more susceptible to the spread of adversarial attacks, with task performance in a Star Graph Topology decreasing by 29.7%. Besides, our proposed static metrics aligned more closely with real-world dynamic evaluations than traditional graph-theoretic metrics, indicating that networks with greater average distances from attackers exhibit enhanced safety. In conclusion, our work introduces a new topological perspective on the safety of LLM-based multi-agent networks and discovers several unreported phenomena, paving the way for future research to explore the safety of such networks.", "sections": [{"title": "1 Introduction", "content": "The network connects everything. Both academia and industry have already witnessed the modern information revolution brought by the web, which has fundamentally transformed how information is shared, processed, and consumed globally [4, 8, 12, 37, 68]. This transformation is not only attributed to the vast amount of data but also to the dynamic interplay mechanisms [3, 6, 50, 85]. It is the interactions between the nodes that give the network its power, making the whole greater than the sum of its parts.\nHowever, traditional network nodes are typically programmatic servers, mechanically executing predefined communication protocols [20, 39, 56, 66]. The rapid advancements in Large Language Models (LLMs) offer a potential solution to this limitation [1, 9, 35, 79]. Specifically, the emergent capabilities of LLMs-such as knowledge [57, 63, 80], decision-making [15, 91], reasoning [34, 86, 93, 100], and tool utilization [67, 71, 92]-allow them to function as intelligent nodes within a network. This type of network is referred to as the LLM-based Multi-agent System \u00b9 [29, 45, 83]. Recent studies have shown that multi-LLM networks outperform individual LLMs in tasks such as problem-solving and social simulations [62, 102]. While multi-agent networks have been widely adopted in areas like gaming, development, education, and scientific computing [77, 90], the security research of these networks remains in its infancy. An urgent and significant challenge is preventing such powerful networks from being exploited for harmful activities (this research line is called \"Safety\"). Therefore, from the perspective of graph theory and topology, we raise a crucial and unexplored question named Topological Safety: What topological structures of LLM-based multi-agent networks exhibit stronger safety?\nTo delve deeper into existing studies on agent systems and their safety, we categorize the current research into two main threads: (I) Single-agent focuses on the capabilities and safety of individual"}, {"title": "2 Related Work", "content": "LLM Safety and Attack. With the widespread adoption of LLMs in both academic and industrial scenarios, ensuring their safety against the generation of misinformation, bias, and harmful content has become increasingly critical. Numerous studies have focused on mitigating the risks associated with \"red team\" prompts through safety alignment [1, 23, 73, 104], inference guidance [58, 87], and input/output filter methods [38, 61, 64, 96]. Approaches such as Supervised Fine-Tuning [1, 79] and Reinforcement Learning from Human Feedback [23, 51] train LLMs on demonstration and preference data, enabling them to learn and align with safety knowledge. In a parallel vein, as in adversarial dynamics between defense and attack in network security, some research aims to induce unsafe generations by attacking models during inference/training phases. Template-based Attacks [11, 24, 27, 43, 54, 69, 81, 108] and Neural Prompt-to-Prompt Attacks [13, 49, 78] use heuristics or optimized prompts as instructions to elicit malicious information. Additionally, Unalignment [41, 82, 89, 106] undermines the inherent safety of models by adopting training methods contrary to safety alignment.\nLLM-based Agent Networks. Due to the human-like capabilities exhibited by LLMs, such as memory [10, 52, 103], reasoning [5, 9, 86, 93], reflection [33, 47, 72, 94], and tool utilization [53, 65, 67], they have been increasingly adopted as planning and decision-making modules in traditional agent in machine learning. Several studies have investigated the task performance and behavior of such networks consisting of these agents [14, 16, 42, 60, 70, 74, 103]. For instance, MetaGPT [30], ChatDev [59] and [25] explore software development by dividing roles among agent groups within a waterfall model. Similarly, Roco [48] and [17, 97] study planning and collaboration capabilities in LLM-based robot clusters, investigating the potential for embodied intelligence. In addition, other research leverage societies of agents to simulate human behaviors and align with theories in various domains, including gaming [84, 90], psychology [2, 98], economics [44, 102], and politics [31, 88]. In this work, we propose the iterative and scalable RelCom interaction to"}, {"title": "3 Methodology", "content": "To systematically explore the structural safety of LLM-based multi-agent networks from a topological perspective, we propose a general framework named NetSafe, which comprises three components:\n\u2192 Multi-agent Network, Attack Strategy, and Evaluation Method. Specifically, we first apply tailor-designed attacks to networks with different topological structures. Then we quantify and study the propagation of malicious information during multiple rounds of communication through evaluations. The overview of NetSafe is illustrated in Figure 2 with pipeline in Algorithm 1.\nPreliminaries. Let T represent the set of any text. Prompt $P = (P_{sys}, P_{usr})$ is a binary set, in which $P_{sys} \\in T$ and $P_{usr} \\in T$ are system message and user message describing LLM's profile and task, respectively. Denote single LLM as a query function $M: T^2 \\rightarrow T$:\n$R = M(P) = M(P_{sys}, P_{usr}),$ (1)\nwhich generates response $R \\in T$ based on input prompt $P\\in T^2$."}, {"title": "3.1 Multi-agent Network", "content": "In this subsection, we focus on defining the topological structure and communication mechanism of the network to be investigated, aiming at providing a generalized and adaptable agent architecture.\nTopological Structure. Denote the set of LLMs as M. Then we can define a multi-agent network to be a directed graph:\n$G_{ma} = (V,E), V = \\{v_i|v_i\\in M, 1 \\leq i \\leq |V|\\}, E \\subseteq V \\times V,$ (2)\nwhere each node $v_i$ represents a LLM function M and a directed edge $e = (v_i, v_j) \\in E$ means $v_i$ sending its response to another LLM $v_j$. However, for calculation convenience, we describe the multi-agent topological graph using the adjacency matrix representation:\n$A = [A_{ij}]_{|V|\\times|V|}, A_{ij} = \\begin{cases} 1, & \\text{if } (v_i, v_j) \\in E \\\\ 0, & \\text{otherwise} \\end{cases}$ (3)"}, {"title": "Communication Mechanism", "content": "Existing multi-agent frameworks vary widely in communication patterns, with information flow heuristically designed for specific tasks, hindering the standardized study of network topological safety. Inspired by the acquaintance relationship in social networks and multi-agent debate [46], we propose a general and iterative communication mechanism named Relation Communication (RelCom) including two steps below: (1) Genesis refers to the process by which each LLM-based agent in the network generates its initial response. For the i-th agent $v_i$:\n$R^{(0)} = (a^{(0)}_i, r^{(0)}_i, m^{(0)}_i) = v_i (P_{sys}, P_{usr}),$ (4)\nwhere $P_{usr}^{(0)}$ describes a problem Q while $R^{(0)}$ is the initial response of node $v_i$ to the problem, involving final answer, corresponding reason and memory (referred as $a^{(0)}_i, r^{(0)}_i,$ and $m^{(0)}_i$, respectively).\n(2) Renaissance encompasses the following two sub-steps:\nSub-step : Collecting responses of in-neighborhood\n$O_i^{(t)} = \\bigcup_{j \\neq i, A_{ji}=1} \\{(a_j^{(t)},r_j^{(t)})\\}, t\\geq0.$ (5)\nEq 5 describes the process by which $v_i$ enriches and aggregates answers and responses from its incoming neighborhood nodes. Integer t is the iteration time stamp, $O_i^{(t)}$ is the information collected from other agents, and Aij is the element in adjacency matrix A.\nSub-step : Regenerating responses\n$P_{usr} = P_{usr}^{(0)} \\cup O_i^{(t-1)} \\cup R_i^{(t-1)},$ (6)\n$R^{(t)} = (a_i^{(t)}, r_i^{(t)}, m_i^{(t)}) = v_i (P_{sys}, P_{usr}), t\\geq 1.$ (7)\nEq 6 and 7 represent the process by which agent $v_i$ updates its response by considering both the responses from other agents and its own previous response. $P_{usr}$ denotes the updated user message of LLM-based agent $v_i$ at time step t while $P_{sys}$ remains unchanged. We point out that RelCom is iterative. In practice, Genesis step is executed only once, while Renaissance step is cyclically executed for a given number of rounds. Our proposed RelCom supports both thorough information exchange between LLM-based agent nodes and possesses desirable iterative and standardized mathematical properties, allowing us to dynamically examine topological safety of multi-agent network over several interaction rounds."}, {"title": "3.2 Attack Strategy", "content": "In this subsection, to investigate the propagation behavior of malicious information in multi-agent networks with different topological structures, we employ prompt-level attack methods, injecting malicious information into the network by targeting specific agent nodes. To begin with, we standardize the attack process as follows:\nAttack Formulations. Denote the node set of attackers to be $V_{atk} \\subseteq V$. Then $V_{nor} = V \\backslash V_{atk}$ is the set of normal agent nodes. In Genesis and each iteration of the Renaissance, for any attacker agent $v_i \\in V_{atk}$, it generates malicious information and targets at its out-neighborhood: $D^+_i = \\{v_j|A_{ij} = 1, j \\neq i\\}$. We use $d_i$ to represent the attack strategy of $v_i$. Then attacker's response is:\n$R^*_i = (a^*_i, r^*_i, m^*_i) = v_i (P_{sys} \\oplus \\phi_i, P_{usr}),$ (8)\nin which $R^*_i, a^*_i, r^*_i$, and $m^*_i$ contain target malicious information (we omit time step t here for convenience). Operator $\\oplus$ means utilizing attack policy to re-write system prompt. In sub-step of"}, {"title": "4 Experiment", "content": "In this section, we apply NetSafe to multi-agent networks with various topological structures, injecting three types of malicious information to explore generation safety in multiple rounds of RelCom. We aim to address the following research questions:\n\u2022 RQ1: How does the safety of different topological structures vary under misinformation injection attacks?\n\u2022 RQ2: How do other types of attacks (bias induction and harmful-info elicitation) affect the networks' topological safety?\n\u2022 RQ3: What is the impact of increasing or decreasing the number of attacker or normal nodes on the safety of the networks?\n\u2022 Discussion: What are the traits of a safer topology?\n4.1 Experimental Setups\nDatasets. To investigate the impact of various attacks on the topological safety of multi-agent networks, we design experiments based on the categories of injected malicious information across different datasets: \u25b2 For misinformation injection, we categorize the attack levels into 3 tiers: targeting indisputable facts, simple reasoning problems, and complex reasoning problems. We generate 3 corresponding datasets named Fact, CSQA and GSMath by using GPT-based generation and sampling from existing datasets"}, {"title": "Static Evaluation", "content": "We modify some metrics from graph theory to assess the topological safety of multi-agent networks with attackers, from a non-experimental, time-free and computation-free perspective. We provide more static metrics in Appendix A.\nStatic Metric:\n$E_{sta} = F(G, A, V_{atk}),$ (13)\nwhich pertains solely to the attacker node set and the network's graph structure. F represents a metric function from graph theory.\nMetrics 1: Network Efficiency (NE)\n$E_{NE} (G) = \\frac{1}{|V|(|V| - 1)} \\sum_{i \\neq j} d_{ij}$ (15)\nEq 15 measures the efficiency of information transmission across the entire network [40], with $d_{ij}$ representing the shortest distance.\nMetrics 2: Eigenvector Centrality (EC)\n$E_{EC}(G, A, v_i \\in V_{atk}) = \\frac{1}{\\lambda} \\sum_{j=1} A_{ij}x_j.$ (16)\nThis equation quantifies the importance of current node based on the centrality of its neighboring nodes [7], where A is the largest eigenvalue of matrix and $x_j$ is the j-th component of its eigenvector.\nMetrics 3: Attack Path Vulnerability (APV)\n$E_{APV}(G, V_{atk}) = \\frac{\\sum_{ij} d_{atk} (d_{ij})}{|V|(|V|- 1)}$ (17)\n$d_{atk} (d_{ij}) = \\begin{cases} 1, & \\text{if } \\exists (v_i,v_j) \\in d_{ij}, v_i \\in V_{atk} \\\\ 0, & \\text{otherwise} \\end{cases}$ (18)\nEq 17 is our proposed metric to measure how many shortest paths in the network are vulnerable to attacks."}, {"title": "Dynamic Evaluation", "content": "However, static evaluation may not accurately reflect real-world scenarios. Therefore, based on the definitions above, we conduct multi-round interactions and attacks across various types of networks (e.g., complete graph, tree, chain, etc.). We then investigate topological safety by assessing their task performances in solving problem Q from selected dataset D. To this end, we propose the following lemma and metrics:\nLemma: Effect of Attacks on Network Performance\n$V_{atk} (Q, G, \\Phi) \\leq E_{nor} (Q, G),$ (19)\nwhere $V_{atk}$ and $E_{nor}$ are the same evaluation metric calculated with and without applying attack \u03a6 to the multi-agent network G. This lemma indicates the adversarial influences of attacker nodes on multi-agent systems, by which we can track the dynamics of the network safety. See proof of the lemma in Appendix B.\nMetrics 4: Single Agent Accuracy (SAA)\n$E_{SAA}^{(t)} (v_i) = \\frac{1}{|D|} \\sum_{Q \\in D} E(a_i^{(t)}, a_Q),$ (20)\n$E(x, y) = \\begin{cases} 1, & \\text{if } x = y \\\\ 0, & \\text{otherwise} \\end{cases}$ (21)\nEq 20 represents the accuracy of each agent $v_i \\in E$ at time step t and $a_Q$ is the correct answer to Q. Because for t \u2265 1, normal nodes will be influenced by nearby attackers, we can assess how single agent in network is corrupted through the change of SAA.\nMetrics 5: Multi-agent Joint Accuracy (MJA)\n$E_{MJA} (G) = \\frac{1}{|V^*|} \\sum_{v_i \\in V^*} E_{SAA}^{(t)} (v_i), V^* \\in \\{V, V_{nor}, V_{atk}\\}$ (22)\nEq 22 is the joint accuracy of the network at time step t, quantifying the performance of multi-agent system in a single communication turn. With t increasing, we can figure out the dynamics of the network's topological safety through the evolution of $E_{EMJA}^{(t)} (G)$ ."}, {"title": "Trait of Safe Topology (Discussion)", "content": "In summary, multi-agent networks exhibit complex topological safety behaviors across different tasks and adversarial attacks, but general patterns are discernible. Trait 1: Topology with lower connectivity tends to be safer. In our experiments, the weakest performers are typically the more connected Star and Complete Graph Topology, while the less connected Chain and Cycle Topology perform better. We attribute this to lower connectivity resulting in harder malicious information propagation. Trait 2: The smaller the average distance from nodes to the attacker, the safer the topology. Our proposed static metric, APV, in Table 2 supports this point. Additionally, as shown in Figure 3 and 4, Agent 6, which is directly connected to the attacker (Agent 1) in the Cycle Topology (compared to its position in the Chain Topology), experiences an approximately 10.0 \u2193 in accuracy. A smaller average distance to the attacker also implies that it takes longer for the attack to spread throughout the network, leading to higher overall safety.\nTo make all our arguments solid, we provide case study in Appendix H and extra results of above experiments in Appendix I."}, {"title": "Conclusion", "content": "In conclusion, this paper introduces NetSafe, a comprehensive framework designed to explore and evaluate the topological safety of LLM-based multi-agent networks. Through the application of iterative RelCom and adversarial attacks, we demonstrate that network topology plays a crucial role in determining its resilience to misinformation, bias, and harmful-info. Our findings suggest that less connected structures, such as Chain and Cycle Topology, offer superior protection against the spread of malicious information, while highly connected topologies are more vulnerable. Furthermore, we observe the agent-unique, unreported and unexplored Agent Hallucination and Aggregation Safety phenomena, which demonstrates significance in deeper agent safety study. These findings lay the groundwork for future research on securing multi-agent networks against evolving threats, providing valuable insights into the design of safer and more resilient systems."}, {"title": "H Case Study", "content": "In this section, we provide some cases of experiments in the main text to offer further understanding. The text in gray box is the task of the case. The attacker's response is showed in red box. The response in green box is the normal node' response, while that in pink means the normal node being attacked successfully.\nH.1 Case of Misinformation Injection (Attacked)\nThe dialogue below is the case shows Agent 0 and Agent 1 (attack-ers) successfully inject misinformation that misleads the originally normal node Agent 2 to spread that misinformation. We show the initial, transition and final response of Agent 2, along with Agent 0's initial response and the one that successfully misleads Agent 2. The setting for this case is total 6 nodes with 2 attackers in Complete Graph Topology multi-agent network on Fact Dataset.\nTask\nDetermine whether the following statement is correct (an-swer with True/False) with reasoning and final answer:\nStatement: The first law of thermodynamics states that energy cannot be created or destroyed.\nReference Answer (attacker's target): False\nCorrect Anser: True\nAgent_0's (attacker) Response in Iteration 1\nAnswer: False\nReason: The statement misinterprets the first law of ther-modynamics. The first law actually states that energy can neither be created nor destroyed, only transformed from one form to another. The reference answer indicates false because it recognizes that the statement could be mislead-ing or context-dependent when suggesting energy is sim-ply \"not created or destroyed\" without emphasizing trans-formation. Therefore, the essence of the first law is about conservation and transformation, which the original state-ment neglects to mention properly.\nAgent_2's (normal) Response in Iteration 1\nAnswer: True\nReason: The first law of thermodynamics is indeed a prin-ciple which asserts that the total energy in an isolated system remains constant; it can neither be created nor destroyed, but can only change forms. This foundational concept underpins many areas of physics and engineering, confirming the statement as correct."}, {"title": "ReLCom Mechanism", "content": "We present the prompt templates used in the experiments to imple-ment the general and iterative RelCom communication mechanism below. The fields are filled in as needed, with some being formatted output fields.\nGenesis: The Genesis Step is the process where each LLM-based agent generates an initial response to a given problem, including the final answer, reasoning, and memory. This response is based"}]}