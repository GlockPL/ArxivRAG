{"title": "PatUntrack: Automated Generating Patch Examples for Issue Reports without Tracked Insecure Code", "authors": ["Ziyou Jiang", "Lin Shi", "Guowei Yang", "Qing Wang"], "abstract": "Security patches are essential for enhancing the stability and robustness of projects in the open-source software community. While vulnerabilities are officially expected to be patched before being disclosed, patching vulnerabilities is complicated and remains a struggle for many organizations. To patch vulnerabilities, security practitioners typically track vulnerable issue reports (IRs), and analyze their relevant insecure code to generate potential patches. However, the relevant insecure code may not be explicitly specified and practitioners cannot track the insecure code in the repositories, thus limiting their ability to generate patches. In such cases, providing examples of insecure code and the corresponding patches would benefit the security developers to better locate and resolve the actual insecure code. In this paper, we propose PATUNTRACK, an automated approach to generating patch examples from IRs without tracked insecure code. PATUNTRACK utilizes auto-prompting to optimize the Large Language Model (LLM) to make it applicable for analyzing the vulnerabilities described in IRs and generating appropriate patch examples. Specifically, it first generates the completed description of the Vulnerability-Triggering Path (VTP) from vulnerable IRs. Then, it corrects potential hallucinations in the VTP description with external golden knowledge. Finally, it generates Top-K pairs of Insecure Code and Patch Example based on the corrected VTP description. To evaluate the performance of PATUNTRACK, we conducted experiments on 5,465 vulnerable IRs. The experimental results show that PATUNTRACK can obtain the highest performance and improve the traditional LLM baselines by +17.7% (MatchFix) and +14.6% (Fix@10) on average in patch example generation. Furthermore, PATUNTRACK was applied to generate patch examples for 76 newly disclosed vulnerable IRs. 27 out of 37 replies from the authors of these IRs confirmed the usefulness of the patch examples generated by PATUNTRACK, indicating that they can benefit from these examples for patching the vulnerabilities.", "sections": [{"title": "1 INTRODUCTION", "content": "Security patches are essential for enhancing the stability and robustness of projects in the Open-Source Software (OSS) community. In 2017, the Software Engineering Institute (SEI) at Carnegie Mellon University released the CERT Guide to Coordinated Vulnerability Disclosure (CVD) [10], which officially states that individuals or organizations should \"deploy a patch or take other remediation action\" before they disclose a vulnerability to the public security databases [3, 33], such as Common Vulnerabilities and Exposure (CVE) [6]. However, patching vulnerabilities is complicated and remains a struggle for many organizations [56]. For example, a vulnerability in the project python-markdown2 has \"no fix\" and \"welcome pull requests\" for a long time, as is reported in the issue trentm/python-markdown2/issues/285 [4]. These unpatched vulnerabilities can be utilized by attackers through deploying exploits to harm the affected systems (e.g., zero-day [17] and one-day [23, 26] attacks), resulting in millions dollars of business losses [63].\nOSS developers typically report vulnerabilities through the issue reports (IRs) [78]. Security practitioners, who manage the vulnerability disclosure, can then track these IRs with issue-tracking systems [5, 16], and analyze the relevant insecure code to generate potential patches. However, the relevant insecure code may not be explicitly specified and practitioners cannot track the insecure code in the repositories, thus limiting their ability to generate patches. In such cases, providing examples of insecure code and the corresponding patches would benefit the security developers to better locate and patch the actual insecure code. In general, generating example insecure code and patches is challenging, mainly due to the semantic gaps between code and natural language, as well as the information omission in developer's description of the venerability in the IRs. Our preliminary study in Section 2.1 shows that 69.0% of vulnerable IRs have no insecure code tracked with either manual analysis or State-of-the-Art (SOTA) commit trackers [68, 93], and over 70% of them were successfully exploited by attackers. These results inspire us to design an automated approach to generate patch examples based on the IRs without tracked insecure code, which can help security practitioners patch vulnerabilities soon after the IRs are created by the developers.\nIn this paper, we propose an automatic approach, i.e., PATUNTRACK, which generates patch examples from IRs without tracked insecure code. It optimizes the Large Language Model (LLM) with auto-prompting [73] to make it applicable for analyzing the types and triggering logic of vulnerabilities from their textual descriptions, and generating appropriate patches. PATUNTRACK consists of three main steps: First, it generates the description of the Vulnerability Triggering Path (VTP) from IR, which captures how the vulnerability is triggered. Second, it corrects potential hallucinations in the VTP description with external golden knowledge. Third, it utilizes the VTP description to predict the patch types and generates Top-K pairs Insecure Code and Patch Example.\nTo evaluate the performance of PATUNTRACK, we conducted experiments on 5,465 vulnerable IRs. The results show that PATUNTRACK achieves the highest performance and improves the traditional LLM baselines by +17.7% (MatchFix) and +14.6% (Fix@10) on average in patch example generation. Furthermore, we applied PATUNTRACK to generate patch examples for 76 newly disclosed vulnerable IRs that do not have tracked insecure code, and asked the authors whether our patch examples can assist them with patching the vulnerabilities. We have received replies from the authors for 37 IRs, and 27 replies confirmed the usefulness of the patch examples generated by PATUNTRACK, indicating that they can benefit from these examples for patching the vulnerabilities. To summarize, this paper makes the following main contributions:\n\u2022 Technique: PATUNTRACK, an automated approach to generate patch examples for vulnerable IRs without tracked insecure code. To the best of our knowledge, this is the first work on generating patch examples without guidance from the source code.\n\u2022 Evaluation: An experimental evaluation of PATUNTRACK that shows that PATUNTRACK outperforms all baselines on generating insecure code & patch examples, as well as a human evaluation on newly-disclosed vulnerable IRs that further demonstrates its usefulness in practice.\n\u2022 Data: The datasets and source code [9], which are made publicly available to facilitate the replication and the application of PATUNTRACK in the more extensive contexts."}, {"title": "2 PRELIMINARIES", "content": "In this section, we first conduct the preliminary study by analyzing the time cost of raising patches for the vulnerable IRs and the exploited ratio of IRs with/without tracked insecure commits. Then, we provide an example to illustrate the motivation of PATUNTRACK."}, {"title": "2.1 Preliminary Study of Vulnerability Patching", "content": "To analyze the time cost of vulnerability patching, we introduce a widely-used vulnerability dataset, i.e., GHArchive [8], which achieves the IRs in the software community. Among them, GHArchive contains vulnerable IRs with their original information of CVE-disclosed vulnerabilities, such as IR's textual descriptions, commits for insecure code and patch (indicated by links with string TCommit and TPatch), etc. We first analyze the time lag between the IR creation and the vulnerability patching by referring to the commit links to the vulnerable IRs containing insecure commits. Figure 1 (a) shows that nearly 20% of the vulnerable IRs require over 150 days to raise the patches for successfully fixing the vulnerabilities, and 38% require over 3 commits to fix the vulnerabilities.\nMoreover, we also analyze whether the tracked insecure commits may affect vulnerability exploitation by calculating the intersections of vulnerable IRs with tracked insecure commits and exploited vulnerabilities. We first decide whether the vulnerable IR contains the insecure commits with the following steps: we analyze the commit links in GHArchive; we utilize the SOTA commit tracker [93] to track the commits if GHArchive does not present the link; and we manually track the commit links if the previous steps cannot find the commit links.\nSecond, we determine whether the vulnerability is exploited by analyzing the logs in the links with TExploited for vulnerability exploitation, e.g., exploited time, IP address, and vulnerable version. We find that there are three types of exploitation as follows:\n\u2022 Unexploited: The vulnerabilities are not exploited by attackers.\n\u2022 Exploited (Failed): The vulnerabilities are exploited after they are fixed with specific patches.\n\u2022 Exploited (Successful): The vulnerabilities are exploited before they are fixed, which means the attackers may harm the systems.\nFigure 1 (b) shows that 2,976 of 4,316 vulnerable IRs (69.0%) cannot track the insecure commits from the GHArchive, Among these IRs without tracked insecure code, 71.7% of vulnerabilities in the vulnerable IRs are successfully exploited by attackers, which is +50.3% higher than IRs with insecure commits. These results show that the insecure commits with patches are important to reduce the exploitation of vulnerable IRs, but raising appropriate patches to fix the vulnerabilities is a time-consuming task."}, {"title": "2.2 Motivating Example", "content": "Figure 2 shows the motivation of generating insecure code & patch examples from the vulnerable IR. From the example, we analyze how the vulnerability is triggered based on the textual description of IR. The project first loads the library dynSync and initializes the parameter hostname. Then, it calls the function dynSync.resolve, which will execute the system command to look up the DNS server to resolve the hostname. However, this function-calling process has vulnerabilities, since the logic of resolve function contains the execution of the system command. If the attackers initialize the hostname with specific strings like \"$(id > /tmp/foo)\", it may inject the vulnerabilities and harm the system.\nReferring to the secure coding practices in OWASP [61], this vulnerability is a typical OS command injection (CWE-78) [54] and the type of patching is validating the input with Regex Testing, so the patch example will incorporate the validation of the inputs. The system commands will not execute if the input strings contain such specific strings, thus preventing the vulnerabilities."}, {"title": "3 APPROACH", "content": "The overall framework of PATUNTRACK is illustrated in Figure 3. Since the IR authors may miss some details in describing vulnerabilities, we first extract the VTP descriptions from IR's textual description and complete the missing nodes and edges. Second, since the pre-trained data and training strategy of LLMs have flaws that result in hallucinations, we propose VulCoK to correct the hallucinations in VTP descriptions. Third, we jointly generate insecure code & patch examples with patch type prediction with the corrected VTP description. For each step, we utilize auto-prompting to optimize LLM to make it applicable to analyze vulnerabilities."}, {"title": "3.1 Generating Complete VTP Description", "content": "The IR can be formulated as follows: {Title, Body}, where Title is the summarization of the main topic; Body contains a set of sentences that describe the details of IR. PATUNTRACK generates the complete VTP description by extracting the original VTP description from the IR textual descriptions, and completing the missing nodes and edges to update the vulnerable IRs."}, {"title": "3.1.1 VTP Description Extraction", "content": "Previously, Cheng et al.'s [19] define a Bug-Triggering Path (BTP) as a set of program statements to reside in the execution paths toward the location where the error is triggered, which is an effective method to detect and reproduce the vulnerabilities, and has been utilized by different vulnerability detectors [43, 44, 55]. However, there are gaps between normal bugs and vulnerabilities, so traditional BTPs are not useful to accurately find vulnerabilities. For example, the traditional BTP defines the operations of the program as package loading, variable declaration, and function calling, which are operations to trigger normal bugs in the OSS projects. On the contrary, vulnerabilities focus on the transmission of tainted data [20], where we find the \"source\" and \"sink\" code to describe the transmission path of the tainted data and locate the code lines that may produce the vulnerabilities.\nThe VTP description in our work can identify the triggering paths of vulnerability by incorporating the transmission of tainted data. The structure can be modeled as $G_{VTP} = (V_{VTP}, E_{VTP})$, where the $V_{VTP} = \\{Op_0, Op_1, ..., Op_t\\}$ is a series of nodes that describe the operations that may result in the vulnerability. The $Op_0$ is the start operation, which contains the operation to load the sources, such as loading third-party library and initializing variables, and $Op_t$ is the end operation that indicates the vulnerability is triggered after the previous operations are conducted.\nBased on the previous works [19] and our manual analysis on over 1K vulnerabilities, we summarize four types of operations that cover the triggering process of vulnerabilities. we manually analyzed the IRs with experienced security practitioners who participated in our data annotation to determine the types of operation nodes/edges with Open Card Sorting [69], a flexible classification method that allows us to create information categories freely, thus helping designers develop more appropriate types.\n\u2022 Src-Load: This operation indicates that the program loads the vulnerability-related source data, such as loading the packages that may have vulnerabilities and loading the variables that may contain the taint information.\n\u2022 Func-Call: Since some vulnerabilities are directly caused by the incorrect calling of the functions, such as the use-after-free [87] vulnerability, we specifically analyze the function calling processes that may trigger the vulnerabilities.\n\u2022 VulData-Transmit: This operation denotes the transmission of the vulnerable data. The data comes from the source variables or the different libraries, and will finally transmit to the sink code lines that may harm the system.\n\u2022 SecData-Transmit: This operation indicates the transmission of other data in the function calling process. Different from the VulData-Transmit, these data are secure and will not harm the system, and we also analyze the transmission of secure data to distinguish it from vulnerable data.\n\u2022 Vul-Trigger: We add this node to intuitively indicate the results of vulnerability triggering.\nThe edges in VTP description ($Op_i \\rightarrow Op_j$) $\u2208 E_{VTP}$ is the one-way link that denotes the transition of how to trigger the vulnerability, where $Op_i$ is the prerequisite operation for the $Op_j$. With the extracted VTP description, we can generate the insecure coding example which can reflect the vulnerable code in the projects, and generate patches based on the coding examples.\nEach node $Op_i$ is a triplet ($Op\\_Type$, $Op\\_Desc$, $Vul\\_Type$), where\n\u2022 The element $Op\\_Type$ is the previous type of operation node.\n\u2022 The $Op\\_Desc$ is the description of the operations, which briefly explains the information of each operation step with texts and a few code snippets. The $Vul\\_Type$ is the type of vulnerability, and we introduce the CWE type and the detailed error types in it to describe the vulnerability. Chow et al. [21] indicates that for different error types, the focuses of bug triggering methods are different. Inspired by it, we define seven error types in VTP based on our manual analysis of vulnerabilities, as shown in Table 1."}, {"title": "3.1.2 VTP Description Completing", "content": "Since some VTP descriptions are not complete and miss some essential operations and transitions in the paths, PATUNTRACK will first detect whether the extracted VTP description is complete. Then, it will complete the missing operation nodes and transitions. PATUNTRACK detects the operation-level and transition-level completeness, and adds the missing information in the nodes and edges in these levels.\n\u2022 Operation-level Completeness: PATUNTRACK detects whether the VTP description misses some intermediate operation nodes $Op_{miss}$, or the existing operation node $Op_i$ misses some information, such as the description of insecure code and $Vul\\_Type$ misses the error or CWE types. PATUNTRACK will ask the LLMs to reason the missing information within the operation nodes, or generate some new intermediate nodes between the existing operation nodes to complement the missing flows.\n\u2022 Transition-level Completeness: The transitions between the operations $Op_i \\rightarrow Op_j$ are missed, so the logic flow is not complete to trigger the vulnerability, and PATUNTRACK will add these transition edges to complement the VTP description.\nThe prompt for VTP description $P_{complete}$ completion utilizes the same format $P_0$. The only difference is that we add the definition of the previous completeness. The prompt will also contain the different focus $f_i$ for different vulnerability types."}, {"title": "3.1.3 Auto-Prompting for Generating VTP Description", "content": "Since some of the LLMs cannot be directly fine-tuned, such as ChatGPT, the researchers have utilized the text generation ability of LLM to design the specific prompt for each input, i.e., Auto-Prompting [73]. We design a meta-framework for auto-prompting, as is shown in Algorithm 1. It utilizes the score function $F_s$ to calculate the differences between predicted and ground-truth labels in the labeled dataset and updates the $f_i$ in the prompt. The line 1 indicates that the auto-prompting updates the prompt's focus $f_i$ by inserting, deleting, and modifying elements in the original prompts. The auto-prompting process controls the prompt updating with simple prompts, such as \"Please update the prompt by inserting|deleting|modifying the [item] to the prompt's focus f\", where [item] is the sample used to optimize the prompt. The samples come from the historical IRs that can track the ground-truth insecure code and patch. The line 3~8 indicate that PATUNTRACK utilizes a score function $F_s$ to analyze the similarity between LLM outputs and ground-truth (lower the score, higher the similarity). We select the most appropriate prompt $P_T$ based on the score differences among these three updated prompts.\nThe score function of auto-prompting the VTP description extractor and completer is calculated by analyzing the matching and masking scores, which can be formulated as follows:\n$F_s(VTP\\_Code |VTP\\_[M], VTP\\_IR|VTP\\_[M]', P_{extract}|P_{complete}) = \\underset{scorematch}{sim(VTP\\_Code^{-}, VTP\\_IR)} + \\underset{scoremask}{sim(VTP\\_[M], VTP\\_[M]')}$  (1)\nwhere $F_s$ is the score function that calculates the sum of two scores, i.e., $scorematch$ and $scoremask$. The first score analyzes whether LLM can accurately generate the VTP descriptions that reflect the triggering process of vulnerabilities, and $socremask$ analyzes whether LLM can complement the incomplete IRs.\nFor $scorematch$, The $VTP\\_IR$ is the generated IRs with original prompt $P_{extract}$, and $VTP\\_Code^{-}$ is the ground-truth triggering path from the insecure code. We utilize the edit distance, i.e., Levenshtein Distance [15], as the similarity, which is useful to measure the similarity between two texts. For $scoremask$, we randomly select some nodes in the extracted VTP, then reflect them to the original IR and mask these chosen texts $VTP\\_[M]$. We utilize the LLM to predict the masked text to $VTP\\_[M]'$ and calculate the edit distances between them. We utilize these scores to measure the performance of LLM on generating VTP descriptions and update the prompts with the meta-framework."}, {"title": "3.2 Correcting Hallucinatory VTP Description", "content": "In Huang et al's survey [34], they indicate that the pre-trained data, training, and decoding strategies of LLMs have flaws that result in content that is inconsistent with real-world facts, which is called LLM hallucinations. To address the hallucinations, Li et al. [42] proposed the CoK, which utilizes external golden knowledge for the hallucination correction. Inspired by this work, we propose the Vul-CoK, as is shown in Figure 5, which can correct the hallucinations in VTP operation nodes and transition edges."}, {"title": "3.2.1 Hallucinatory VTP Detection", "content": "The detection process of VTP description contains two parts. i.e., Vul-Type Hallucination Detection and Description Hallucination Detection, which detects the hallucinations in vulnerability types and descriptions of VTP nodes. We first introduce the external golden databases Table 2, which is selected based on the update time, the usage of databases in industry and research, and the number of vulnerabilities. We detect the hallucinations in the VTP description with the Breadth-First Search (BFS) [76], which searches for the current operation item $Op_{Item}$ and its connected operations $\\{Op_{Conn}|Op_{Item} \\rightarrow Op_{Conn}\\}$. The LLM first generates the queries for retrieving the golden items in the dataset D. Similar to Section 3.1.2, we also utilize the operation and the historical transitions to analyze whether they contain the hallucination. We utilize the prompt $P_{halDetect}$ with the prompt format $P_0$ to detect the hallucination, which contains the definition of hallucinations, as well as the focus list of CWE and error types."}, {"title": "3.2.2 Hallucinatory VTP Correction", "content": "For the VTP descriptions that contain the hallucinations, i.e., the hallucinations from type and description in VTP. First, suppose the CWE and error types are incorrect and contain hallucinations. In that case, the VulCoK needs to correct the hallucinatory types in the node $Op_{Item}$ and $Op_{Conn}$. If the types are correct, the LLM needs to correct the hallucinations of the VTP description and $Op_{Next}$ and re-generate the transitions for the new VTP operations. After these corrections, the original $G_{VTP}$ will be updated to $G_{VTP}$, and the current item $Op_{Item}$ will move to its connected items $Op_{Conn}$. The prompt $P_{halCorrect}$ utilizes the same format $P_0$ for correcting the hallucinations. It directly asks LLM to correct the VTP's vulnerability types and descriptions based on the retrieved golden knowledge, and it will also incorporate the focus list of different vulnerability types."}, {"title": "3.2.3 Auto-Prompting for VulCoK", "content": "Since the retrieved knowledge in the selected golden dataset incorporated the insecure code, the score function of auto-prompting the VulCoK is calculated by analyzing the similarity between the tracked insecure code and the golden knowledge's insecure code.\n$F_s(Code_{Gold}, Code^-, P_{halDetect}|P_{halCorrect}) = \\sum sim(Code_{Gold}, Code^{-})$ (2)\nwhere the $Code_{Gold}$ indicates the insecure code in the golden knowledge, and the sim is the edit distance. We sum all the distances in the retrieved knowledge, then we feed the $F_s$ into Algorithm 1 and update the prompt with this meta-framework."}, {"title": "3.3 Generating Insecure Code & Patch Example", "content": "In this section, PATUNTRACK first predicts the patch types based on the corrected VTP description. Then, it jointly generates the insecure coding & patch examples based on the patch types."}, {"title": "3.3.1 VTP-based Patch Type Prediction", "content": "Previously, Chow et al. [21] defines 12 patch types for fixing the normal bugs in OSS projects. They construct a mapping from the error types to the patch types, which reflect which types of patches are more frequently used for fixing certain bugs. Inspired by this work, we also ask the LLMs to predict the patch types before the patch example generation. First, since the manual investigation of vulnerable IRs with patches shows the types of patches for fixing the vulnerabilities are similar to fixing the normal bugs, we directly migrate the patch type defined by Chow et al. to our patch type prediction. Then, we ask the LLM to predict the patch type $Patch\\_Type$ for the VTP description $G_{VTP}$ and record the co-occurrence between the vulnerability type and patch type in the current predicted IRs $freq = \\#(Vul\\_Type, Patch\\_Type)/\\#Predicted\\_IR$. The prompt $P_{typePredict}$ incorporates the definition of patch types and the frequency, as well as the type and focus list in CWE and error types."}, {"title": "3.3.2 Joint Insecure Code & Patch Example Generation", "content": "After the prediction of patch types, we generate the patch example based on the $Patch\\_Type$ and the original VTP description $G_{VTP}$. Since some nodes are operations in the imported third-party libraries, we first ask the LLMs to select the nodes and edges that reflect the developer's insecure coding process. Then, we utilize the selected nodes and edges to jointly generate the pairs with insecure coding and patch examples. The idea of joint generation comes from multitask learning [41], where the incorrect output elements are modified based on other output elements' results, thus improving the accuracy of patch generation. The prompt $P_{generate}$ asks LLMs to select nodes/edges and jointly generate the pairs, as well as incorporates the focus list of CWE and error types"}, {"title": "3.3.3 Auto-Prompting for Patch Example Generation", "content": "The auto-prompting process for the patch example generation utilizes the edit similarity between generated code and ground-truth code in the historical IRs to optimize the prompts, and the score function is shown as follows:\n$F_s(Code^-|Patch^+, Code'|Patch', P_{typePredict}|P_{generate}) = \\underset{}{sim(Code', Code^-)} + sim(Patch', Patch^+)$ (3)\nwhere the $Code'$ and $Patch'$ are the generated insecure coding and patch examples. The $Code^-$ and $Patch^+$ are the ground-truth of insecure code and patch of the vulnerabilities. We also feed the $F_s$ into Algorithm 1 and update the prompt with the meta-framework."}, {"title": "4 EXPERIMENTAL DESIGN", "content": "To evaluate the performance of PATUNTRACK, we will investigate the following three research questions (RQs)\n\u2022 RQ1: How does PATUNTRACK perform on generating insecure code examples?\n\u2022 RQ2: How does PATUNTRACK perform on generating patch examples for fix the vulnerability?\n\u2022 RQ3: How does PATUNTRACK handle IRs when they lack detailed information?\n\u2022 RQ4: How does each component contributes to the PATUNTRACK on generating insecure coding and patch examples?"}, {"title": "4.1 Dataset Preparation", "content": "In this section, we first enrich the IRs from original GHArchive [8] with other two representative data sources, i.e., D2A [94] and PatchDB [80]; then, we denoise the D2A dataset to improve its quality; third, we preprocess the dataset with token replacement and split the dataset into IRs for auto-prompting and evaluation.\nSTEP 1: Collecting the Dataset. We collect the dataset from three major sources following previous works [39, 64]. The first data source is GHArchive [8], a comprehensive dataset that contains over 120K GitHub IRs since 2015. The second data source is D2A [94], which is built from real-world vulnerability prediction scenarios and contains over 10K insecure code found from GitHub IRs with their vulnerability types. The third data source is PatchDB [80], which incorporates over 4K security patches in the GitHub repositories. All the datasets have been widely used in multiple vulnerability identification tasks [18, 44, 46, 57, 64, 70]. We collect the vulnerability information in these two data sources by searching commit messages and vulnerable IRs, then we remove items without the searched vulnerable IRs.\nSTEP 2: Denoising the Dataset. The D2A is automatically built by the commit message analyzer, and the authors report that D2A only has 53% accuracy in extracting commits. Therefore, we remove 67 noisy samples from D2A as follows: we obtain the commit messages, and vulnerable IRs by manually searching the repositories; we remove the noisy items that the commit messages and IRs explicitly indicate that they do not contain the vulnerabilities; and in the remaining code, we remove the noisy items by checking whether the disclosed vulnerabilities are depreciated in the CVE.\nTo reduce the biases in the data-denoising process, we have invited three security practitioners with over 5-year experience to determine whether the dataset is correctly denoised. We ask them to independently check whether the removed noisy items are accurate. The average Cohen's Kappa [65] value is over 0.9, which means they highly agree on the noisy data removal.\nSTEP 3: Preprocessing the Dataset. The GitHub IRs collected from the web pages are in XML format, and we need to preprocess the IRs by ragging screenshots and code snippets. We preprocess the IRs with the following procedures: 1 we first utilize the Tencent OCR to transit the screenshots (wrapped by XML tag <a href=\".jpg|.png\">) to the text [77], then use [SCR] to tag the screenshots, and [CODE] to tag the code snippets (wrapped by XML tags <code>, </code>). The content will be [CODE] {content of code snippet} after tagging; we merge similar code snippets and page screenshots, which may have few differences and describe similar vulnerability information; and following the previous works [72], we remove other XML tags and retain the plain text inside, then we correct typos with Spacy [25]. We utilize 80% of the IRs with code commits for auto-prompting the LLMs, and the rest of the IRs for evaluation. In consequence, the evaluation dataset contains IRs with/without code labels."}, {"title": "4.2 Experimental Baselines", "content": "Non-LLM Baselines for Code Generation. CodeBert [27] is a large code model pre-trained on millions of code snippets with the BERT model. We fine-tune the CodeBert on the dataset for auto-prompting. Codeium [11] is a low-cost AI-driven approach for code completion and searching. We utilize these baselines to generate insecure code examples from the description of IR. Compared with other baselines, they achieve SOTA performances in our task.\nNon-LLM Baselines for APR. The APR tools also utilize the fine-tuned CodeBert as the baseline. InCoder [28] is designed for code infilling by adopting a causal masking objective. We fine-tune these two models on the (Insecure Code, Patch) pairs of evaluation dataset for auto-prompting. To keep these APR baselines consistent with PATUNTRACK, these two models generate the patches based on the generated insecure code example of PATUNTRACK. Compared with other baselines, they achieve SOTA performances in our task.\nBaselines with Generative LLMs. Recently, researchers have utilized the LLMs with prompt learning to automatically generate code and repair the bugs. We choose the three common LLM baselines in our tasks, which can achieve the SOTA performances. CodeT5 [81] is pre-trained on T5, which is an encoder-decoder model that takes into account token type information in the code. Codex (GPT-3) [91] and ChatGPT (i.e., GPT-3.5) [58] are two novel LLMs proposed by OpenAI, which use over 100B of parameters and are trained on over 10TB samples with multiple training strategies (few-shot, zero-shot, etc.). We choose the stable and well-maintained versions: t5-base [12], text-davinci-003 [60], and gpt-3.5-turbo [59], and use the same prompt in Section 3.3. Except for the ChatGPT, all the baselines are fine-tuned on our dataset, then generate code examples and predict types."}, {"title": "4.3 Metrics and Experimental Settings", "content": "Metrics. The first metric is the MatchLine, which is a strict metric that measures the proportion of total matched statements with the ground-truth code. The second is the MatchTrig and MatchFix, which measure the matching rate of statements that may contain insecure code (annotated with \"-\") and patch (annotated with \"+\"). These two metrics indicate whether the generated code can trigger or fix the vulnerabilities. We choose the K = 10 as the default value to measure these matching rates. AccType is utilized to measure the accuracy of type prediction, and it measures the average of both CWE and error types in insecure code examples. We also use the Triggering Rate (Trig@K) and Fixing Rate (Fix@K) to measure the triggering and fixing rate of generated code examples:\n$Trig@K = \\frac{\\#Trig\\_Vul@K}{\\#Total\\_Vul@K}, Fix@K = \\frac{\\#(Trig\\_Vul@K \\cap Fix\\_Vul@K)}{\\#Total\\_Vul@K}$ (4)\nwhere \"#\" is the symbol of the number calculation of evaluation samples, and Fix@K = 1 if both the vulnerability triggering and fixing are satisfied in the Top-K generated pairs. We choose K = 1, 5, 10 for measuring the triggering and fixing rates.\nParameter and Hardware Settings. We split 80% of IRs with code commits for auto-prompting, and the rest 20% and the IRs w/o commits for evaluation. We fine-tune all the baselines (except for ChatGPT) with batch_size = 8. All experiments are run on a PC with Windows 11 OS, NVIDIA GeForce RTX 2060."}, {"title": "5 RESULT", "content": "We introduce the PATUNTRACK to improve the T5, GPT-3, and ChatGPT's performances, and the model names are LLMS+PATUNTRACK. In the evaluation dataset with code labels, we analyze the matching rate between generated insecure code and the ground-truth labels of insecure code. In the evaluation dataset without code labels, we first utilize the open-sourced security testing tools, such as Zed [14] and Wapiti [13], etc., to test whether the generated insecure code example will trigger the corresponding vulnerabilities, and manually test the insecure code if the automatic detectors cannot trigger the vulnerabilities."}, {"title": "5.1 Performances on Insecure Code Generation", "content": "We introduce the PATUNTRACK to improve the T5, GPT-3, and ChatGPT's performances, and the model names are LLMS+PATUNTRACK. In the evaluation dataset with code labels, we analyze the matching rate between generated insecure code and the ground-truth labels of insecure code. In the evaluation dataset without code labels, we first utilize the open-sourced security testing tools, such as Zed [14] and Wapiti [13], etc., to test whether the generated insecure code example will trigger the corresponding vulnerabilities, and manually test the insecure code if the automatic detectors cannot trigger the vulnerabilities."}, {"title": "Advantages of PATUNTRACK", "content": "We believe that the benefits of PATUNTRACK come from three aspects. First, PATUNTRACK can obtain the description of how to trigger a vulnerability, and the VTP extractor and VTP completer improve the completeness of generated VTP, which can facilitate the LLMs to generate code that reflects the vulnerabilities. Second, the hallucination correction can reduce the VTP descriptions that do not reflect real-world vulnerabilities. Third, the CWE and error type in the VTP description help LLM to accurately analyze the type of vulnerability."}, {"title": "5.2 Performances on Patch Example Generation", "content": "The experiment settings on the evaluation dataset with/without code labels are the same as Section 5.1. To keep Non-LLM APR baselines consistent with PATUNTRACK, they generate the patches based on the generated insecure code example of PATUNTRACK.\nComparison Results. Table 5 illustrates the comparison results of PATUNTRACK on generating patch examples from IR textual description. Comparing the PATUNTRACK with all the code generation and LLM baselines, we can see that, the ChatGPT+PATUNTRACK can obtain the highest performances with 65.5% (MatchLine), 83.7% (MatchFix), and 78"}]}