{"title": "Game-Of-Goals: Using adversarial games to achieve strategic resilience", "authors": ["Asjad Khan", "Aditya Ghose"], "abstract": "Our objective in this paper is to develop a machinery that makes a given organizational strategic plan resilient to the actions of competitor agents (adverse environmental actions). We assume that we are given a goal tree representing strategic goals (can also be seen busi- ness requirements for a software systems) with the assumption that competitor agents are behaving in a maximally adversarial fashion (opposing actions against our sub goals or goals in general). We use game tree search methods (such as minimax) to select an optimal execution strategy (at a given point in time), such that it can maximize our chances of achiev- ing our (high level) strategic goals. Our machinery helps us determine which path to follow (strategy selection) to achieve the best end outcome. This is done by comparing alternative execution strategies available to us via an evaluation function. Our evaluation function is based on the idea that we want to make our execution plans defensible(future-proof) by selecting execution strategies that make us least vulnerable to adversar- ial actions by the competitor agents. i.e we want to select an execution strategy such that its leaves minimum room(or options) for the adversary to cause impediment/damage to our business goals/plans.", "sections": [{"title": "Introduction", "content": "In a rapidly evolving business landscape, organizations must make strategic deci- sions in adversarial environments where competitors, market forces, and regula- tory bodies continuously influence outcomes. Traditional decision-making frame- works often fail to account for the dynamic and competitive nature of real-world strategic planning. This paper presents an adversarial game-theoretic approach to strategic decision-making, leveraging game-tree search methods to enhance strategic resilience and optimize decision pathways. By modeling business strat- egy as a two-player adversarial game, our framework enables organizations to anticipate and mitigate the impact of competitive disruptions. [10,3]. Game-theoretic models have long been employed in fields such as economics, artificial intelligence, and cybersecurity to analyze adversarial interactions. Goal models play a critical role in requirements engineering, by providing a hierarchic representation of statements of stakeholder intent, with goals higher in the hier- archy (parent goals) related to goals lower in the hierarchy (sub-goals) via AND- or OR-refinement links. Goal models encode important knowledge about feasible,"}, {"title": "Decision making in adversarial settings", "content": "Decision making in adversarial settings involves reasoning about chains of moves and counter-moves by the adversarial entities involved. A telecom provider might reason along the following lines: If we offer high-speed web access at heavily dis- counted rates, we can rapidly build market share. Then competition can counter this by copying our strategy of heavily discounted data offers. We can counter their move by sustaining the heavy discounting for a longer period of time by"}, {"title": "Reasoning with augmented game trees", "content": "The problem we aim to solve is that of helping organizations select amongst alternative goal refinements (OR-refinements). Given a goal model that delimits that space of goals and subgoals that an organization can seek to satisfy, this is a critical (and indeed, only) decision problem to be solved. An AND-refinement of a goal is a statement of know-how that tells the organization how to achieve a parent goal (although without sequencing information, and thus falling short of being a full procedure or process model). OR-refinements offer alternative specifications of know-how for a given parent goal. We model the problem by viewing actions that take us closer to goal or subgoal satisfaction as game moves. The available goal model for the business is therefore not the game tree, but the goal model serves to constrain a different data structure, which we will henceforth call an augmented game tree (and which we will discuss in detail below). We observe the following: Our aim is to explore the consequences of selecting a given OR-refined sub- goal to pursue."}, {"title": "Empirical Evaluation", "content": "Our empirical evaluation investigates the feasibility of the proposed adversarial game-based strategic decision-making framework. Specifically, we examine how decision time scales with the number of propositional variables, the branching factor determined by condition-action rules, and the depth of game-tree explo- ration. The experiment consists of a simulation similar to a two-player game where the environment (adversary) and business each take turns under the assumption of a maximally adversarial model of the environment. We assume that a given business can take certain actions (having one or more effects) to achieve a certain sub-goal. These sub-goals are represented using a set of propositional variables. We start with an initial state where these variables have been assigned random True or False values, representing the current state of the business. The actions available to a business are determined by the condition-action rules. While the condition-action rule set can change dynamically during execution, for simplicity, we assume a static set. We iterate through the condition-action rule database to check whether the current state entails any conditions specified in the rule set. If one or more rules are applicable at the current state, actions can be taken to ensure the effects defined in the applicable rules become true. This step involves using an efficient SAT-solver, which takes as input a set of clauses and determines whether they are satisfiable. After the business has made its move, the environment makes its move, simulated by impeding the achievement of certain sub-goals. Once an action is executed, the state is updated using a state update operator function (as defined in Section 3), which incorporates the effect of the action, the current state, and the knowledge base. We use a random K-CNF Generator tool to generate a set of uniform random 3-SAT instances, ensuring that clauses are unique and do not contain the same variable twice. We consider cases where the number of variables is 60 and 65, generating clauses with a clause-to-variable ratio drawn from the interval [3.5-5.5]. To determine the next state, we compute similarity using Hamming distance and select states most similar to the current one."}, {"title": "Effects of Depth Cut-Off on Performance", "content": "A key parameter in game-tree search is the search depth cut-off, which deter- mines how far ahead the algorithm explores possible moves. Since the game is theoretically unbounded, a reasonable cut-off must be chosen based on com- putational resources. As seen in Figure 1, increasing the depth cut-off causes an exponential rise in compute time for both Minimax with Alpha-Beta Prun- ing and MCTS. Minimax is particularly affected due to its exhaustive search strategy, while MCTS scales more efficiently but still shows increasing compute costs."}, {"title": "Effects of Simulation Count on MCTS Performance", "content": "Unlike Minimax, MCTS relies on randomized simulations to estimate the best move. Figure 2 demonstrates the impact of increasing the number of simulations on compute time. The relationship follows a logarithmic trend, where compute time grows significantly at first but gradually plateaus, suggesting diminishing returns beyond a certain number of simulations. This suggests that practition- ers using MCTS in real-world strategic planning should tune the number of simulations based on available computational resources to balance accuracy and efficiency."}, {"title": "Comparative Performance of Search Algorithms", "content": "We compared three search strategies: Minimax with Alpha-Beta Pruning, which is a deterministic approach with exponential complexity; Monte Carlo Tree Search (MCTS), a sampling-based approach that scales more efficiently; and the Stochastic Game Model (Dice Roll), a probabilistic approach used in stochastic games. As shown in Figure 3, Minimax exhibits the highest compute time, fol- lowed by MCTS, with the stochastic model performing best. The reason is that Minimax explores all possible outcomes, whereas MCTS samples only the most promising branches. [10]. Minimax is computationally expensive and impractical for deep searches, making it unsuitable for real-time decision-making in rapidly changing business environments. MCTS provides a scalable alternative by focusing on the most promising moves rather than exhaustive search, making it a better choice for adaptive strategic planning. Stochastic models trade accuracy for efficiency, mak- ing them useful when computational resources are severely constrained. Business strategy modeling must balance depth of search, accuracy, and compute time, with MCTS emerging as the best overall choice. These insights suggest that busi- nesses can leverage adversarial game models with carefully tuned parameters to improve strategic resilience while remaining computationally feasible."}, {"title": "Comparative Performance of Search Algorithms", "content": "We compared three search strategies: Minimax with Alpha-Beta Pruning, which is a deterministic approach with exponential complexity; Monte Carlo Tree Search (MCTS), a sampling-based approach that scales more efficiently; and the Stochastic Game Model (Dice Roll), a probabilistic approach used in stochastic games. As shown in Figure 3, Minimax exhibits the highest compute time, fol- lowed by MCTS, with the stochastic model performing best. The reason is that Minimax explores all possible outcomes, whereas MCTS samples only the most"}, {"title": "Related work", "content": "Game-theoretic approaches to decision-making have been extensively studied in various domains, including artificial intelligence, economics, and cybersecu- rity. Classical works in game theory, such as those by von Neumann and Mor- genstern, laid the foundation for strategic reasoning in adversarial settings [3]. More recent advances have focused on leveraging machine learning to enhance decision-making in competitive environments [10,14]. In the field of artificial intelligence, Minimax search with Alpha-Beta pruning has been widely used in strategic decision-making, particularly in board games such as chess and Go [3,10]. Monte Carlo Tree Search (MCTS) has emerged as a powerful alternative, demonstrating remarkable success in complex, high-dimensional decision spaces [10]. From a business and economics perspective, adversarial game models have been applied to strategic planning and market competition. Researchers have ex- plored how organizations can anticipate competitor actions and optimize decision- making through predictive modeling [5,2]. Process mining techniques have also been utilized to extract actionable insights from business process data [1,11]. The role of requirements engineering in adversarial decision-making has also been explored. Studies have investigated how non-functional requirements, such as security and compliance, influence strategy formulation [6,12,9]. Addition- ally, the use of data-driven approaches to inform business strategies has gained prominence, with studies emphasizing the importance of mining customer re- quirements and analyzing behavioral patterns [15,17,8,13]. Multi-agent systems and reasoning about norms have been key areas of re- search in adversarial settings, particularly in regulatory compliance and institu- tional decision-making [4,18]. The study of sequential pattern mining has also provided insights into identifying strategic trends over time [7,16]. In summary, while significant research has been conducted in game the- ory, machine learning, and strategic decision-making, our work uniquely inte- grates these perspectives into a unified computational framework for adversarial decision-making in business strategy. By leveraging both classical and modern game-theoretic techniques, we aim to enhance the resilience of strategic execu- tion plans in competitive environments. The next section presents our proposed framework, detailing its theoretical underpinnings and methodological approach."}, {"title": "Conclusion", "content": "This paper presented a novel approach to strategic decision-making in adver- sarial business environments using adversarial game-tree search methods. By modeling business strategies as two-player adversarial games, we demonstrated how decision-makers can anticipate and counteract adversarial moves effectively. Through empirical evaluation, we showed that Minimax with Alpha-Beta Prun- ing, Monte Carlo Tree Search, and stochastic game approaches exhibit distinct computational and strategic trade-offs. Our findings indicate that MCTS pro- vides a well-balanced approach, offering scalability and computational feasibil- ity while maintaining robust decision-making capabilities. Minimax, although exhaustive, is computationally expensive and unsuitable for real-time applica- tions, whereas stochastic models provide efficiency at the cost of accuracy. These results highlight the importance of selecting appropriate search algorithms based on the strategic needs and computational constraints of a given business context. Future work will focus on extending this framework by incorporating machine learning techniques to refine strategy prediction and improve decision-making efficiency in complex, multi-agent environments. [14]."}]}