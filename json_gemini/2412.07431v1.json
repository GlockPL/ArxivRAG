{"title": "BENet: A Cross-domain Robust Network for Detecting Face Forgeries via Bias Expansion and Latent-space Attention", "authors": ["Weihua Liu", "Jianhua Qiu", "Said Boumaraf", "Chaochao lin", "Pan liyuan", "Lin Li", "Mohammed Bennamoun", "Naoufel Werghi"], "abstract": "In response to the growing threat of deepfake technology, we introduce BENet, a Cross-Domain Robust Bias Expansion Network. BENet enhances the detection of fake faces by addressing limitations in current detectors related to variations across different types of fake face generation techniques, where \"cross-domain\" refers to the diverse range of these deepfakes, each considered a separate domain. BENet's core feature is a bias expansion module based on autoencoders. This module maintains genuine facial features while enhancing differences in fake reconstructions, creating a reliable bias for detecting fake faces across various deepfake domains. We also introduce a Latent-Space Attention (LSA) module to capture inconsistencies related to fake faces at different scales, ensuring robust defense against advanced deepfake techniques. The enriched LSA feature maps are multiplied with the expanded bias to create a versatile feature space optimized for subtle forgeries detection. To improve its ability to detect fake faces from unknown sources, BENet integrates a cross-domain detector module that enhances recognition accuracy by verifying the facial domain during inference. We train our network end-to-end with a novel bias expansion loss, adopted for the first time, in face forgery detection. Extensive experiments covering both intra and cross-dataset demonstrate BENet's superiority over current state-of-the-art solutions.", "sections": [{"title": "I. INTRODUCTION", "content": "Recent advancements in Deepfake generation techniques have been remarkably impressive, producing convincingly fake facial images or videos. Exploiting these methods, an attacker could create deceptive news, defame public figures, or compromise security systems, leading to substantial risks with broad social and security consequences [1]\u2013[3]. Face forgery detection has arisen in response to these manipulated visuals, concentrating on the discriminative task of identifying forged regions through visual analysis.\nCurrent face forgery detection methods [4]\u2013[14] primarily focus on identifying forgery clues left by generative models, e.g., GANs [15]. They model detection as a binary classification task using a backbone network for learning global facial image representations, followed by a binary classifier to distinguish between real and fake images. However, forgers often manipulate faces to hide forgery clues, making detection challenging. Fortunately, deepfake methods typically struggle to mimic real faces' unique statistical pixel distribution, leading to noticeable inconsistencies between tampered and authentic regions [16]. This disparity is a key factor in developing proactive methods to highlight forgery clues efficiently.\nOn the other hand, advancements in deepfake technology have led to more sophisticated forgeries, blurring the line between real and fake content. As forgeries improve, the telltale signs become more nuanced and localized, rendering the global feature-based methods less effective. Also, the expanding spectrum of deepfake techniques challenges the cross-domain robustness of face forgery detection models, where \"cross-domain\" refers to the capability of these models to accurately identify fake faces generated by a variety of different deepfakes, each considered a separate domain. Even though existing solutions for detecting forgeries perform well on examples that share the same statistical distribution as the training data, they expect significant drops in effectiveness when the conditions deviate from this strict similarity [10], [17], [18].\nWith the above considerations in mind, in this paper, we propose BENet, a Cross-Domain Robust Bias Expansion Network, designed to augment face forgery detection capabilities. BENet incorporates a bias expansion module-based autoencoder for modeling the distributions of both real and fake faces. Specifically, while real faces exhibit consistent features, leading to largely invariant reconstructions by BENet, the network distinctly intensifies forgery clues when applied to fake faces and expands the bias against them. This approach establishes a dependable bias expansion for efficient forgery clues detection.\nInspired by breakthroughs in Transformer attention mechanisms [19], [20], we propose a novel Latent-space Attention (LSA) module that emphasizes the forgery-related inconsistencies by capturing the latent feature variances across multiple scales between the encoder and decoder. This multi-scale LSA approach not only captures fine-grained manipulations but also adapts to the holistic context of the face, ensuring a robust defense against even the most sophisticated forgeries.\nFurthermore, we incorporate a cross-domain detector module to strengthen BENet's capability in identifying unfamiliar cross-domain deepfake attacks. Traditionally, An open-set classifier should reject unknown samples while maintaining high accuracy on known ones [21], [22]. Intuitively, we formulate a Bias-against-Threshold filter to catch images that are significantly different (unknown fakes) from what the model"}, {"title": "II. RELATED WORKS", "content": "Earlier approaches to face forgery detection focused on hand-crafted features, particularly by examining inconsistencies in the color space [4]\u2013[7]. With recent strides in deep learning, CNNs have emerged as powerful tools, demonstrating significant performance gains [8]\u2013[14]. For instance, Zhou et al. [8] combined face classification with noise residual recognition, while Rossler et al. [9] used an Xception model for binary classification based on features extracted from cropped facial images. Qian et al. [11] and Li et al. [12] developed models focusing on frequency aspects to distinguish authentic and counterfeit faces. To uncover correlated input features and identifying anomalies within datasets, autoencoders have become instrumental in the last few years [17], [23]\u2013[28]. In the context of deepfake limitations in replicating genuine statistical pixel distribution, some research has incorporated autoencoders in this effort. For instance, Nguyen et al. [17] designed a CNN with a multi-task learning approach to detect and locate manipulated regions within images. Liu et al. [29] integrated a variational autoencoder into an innovative generalized residual federated learning scheme named FedForgery to learn discriminative residual feature maps. In a similar vein, Khalid et al. [30] introduced OCFakeDect, utilizing a one-class variational autoencoder (VAE) trained solely on authentic facial images. Cao et al. [14] detect differences between genuine and fake faces via a bipartite graph-based fusion of the autoencoder latent space and the decoder feature maps. As opposed to our approach, it is important to highlight that these methods apply autoencoders exclusively to real facial images, bypassing direct modeling of fake sample distribution. Thus, there is no evidence that the learned representations will be generalizable."}, {"title": "B. Attention for Face Forgery Detection", "content": "Recently, numerous studies based on attention mechanisms have been proposed for face forgery detection [31]\u2013[33], for the purpose of spotting forgeries and detecting subtle discrepancies more effectively. For example, Yadav et al. [31] used the 'Local Attentional Tamper Trace Extractor' (LATTE) to extract forgery traces at the block level, while the 'Global Attentional Tamper Trace Extracter' (GATTE) to aggregate tampering traces on a broader scale. Transformers [20] have recently been adapted for deepfake detection in models such as FTCN-TT [34], ICT [35], and AUNet [36]. Although these methods achieve promising results in the intra-domain, their performance significantly drops in the cross-domain evaluation. To cope with these, we: 1) Propose for the first time, an original aggregation strategy that integrates a latent-space attention mechanism (section III-B) for emphasizing the forgery-related inconsistencies and capturing the latent feature variances across multiple scales between the encoder and decoder, 2) We introduce a cross-domain detector (section III-D), which leverages the stability of the distribution of face features, compared to the fake face's counterpart, to best counter cross-domain manipulations. We showcase that these newly proposed modules ensure a robust detection of forgeries across various domains."}, {"title": "III. METHODOLOGY", "content": "For enhanced intra-domain and cross-domain face forgery detection, we propose BENet, which consists of three main components, namely Bias expansion, latent-space attention, and cross-domain detector, as shown in fig. 1. (A) Input images x (real or fake) are first processed by a bias expansion module (i.e., autoencoder), yielding reconstructed images $x_o = D(E(x))$. The resultant bias images $x'$ are derived by subtracting x from x.. (B) A multi-scale Latent-space Attention (LSA) module further emphasizes the forgery-related inconsistencies by capturing the latent feature variances between the encoder and decoder. The enriched LSA feature maps are then multiplied with the expanded bias images, resulting in a multi-faceted feature space used as input for a multi-layer perceptron (MLP) classifier for binary classification. BENet learning is optimized end-to-end by a newly designed contrastive loss. (C) A thresholded cross-domain detector is introduced further to improve the recognition accuracy during inference through facial domain verification. We detailed the BENet's components in the following subsections."}, {"title": "A. Bias Expansion Module", "content": "In order to expand the bias between real and fake reconstructions, we employ an autoencoder (fig. 1 (A)) to obtain reconstructed images $x_o$, which amplifies the deepfake clues of input images x. The reconstructed images $x_o$ are defined as:\n$x_o = AE(x)$ (1)\nwhere $AE()$ represents the reconstruction process of the autoencoder. Then, we calculate the bias images $x'$ by subtraction, which are denoted as:\n$x' = |x - x_o|$ (2)\nThe bias images are the pixel-level difference between the input images and the reconstructed versions, indicating deep-fake clues. We aim to expand deepfake bias while retaining the reconstructed real faces invariant. This is consistent with the idea of contrastive loss [37]. Therefore, we define bias expansion loss $L_{be}$ as follows:\n$L_{be} = L_1 + L_2 + L_3$ (3)\nHere,\n$L_1 = \\frac{1}{N} \\sum_{i=1}^N (1 - y_i) || x'_i ||_2$ (4)\n$L_2 = \\frac{1}{N} \\sum_{i=1}^N y_i max(m - || x'_i ||_2, 0)^2$ (5)\n$L_3 = \\frac{1}{N} \\sum_{i=1}^N \\sum_{j \\neq i, y_i = y_j}^M -log\\frac{exp(x_{i,j})}{\\sum_{k \\neq i, k \\in y_i} exp(x_{i,k})}$ (6)\nN is the number of samples from a batch, $y_i$ is the label of input image $x_i$, M is the number of samples with $Y_i = Y_j$ from a batch, and m is a margin parameter ensuring a minimum distance between original and reconstructed fake faces. BENet's bias expansion loss strengthens its ability to detect deepfake clues in fake faces. For real faces, $L_{be}$ aims to align reconstructed faces with originals by minimizing bias squared within real face samples in $L_1$. In contrast, $L_2$ increases the disparity between original and reconstructed fake faces by maximizing this bias. Furthermore, we expand the differences between real and fake faces through $L_3$. The effect of each component in $L_{be}$ is illustrated in Figure fig. 2. The synergistic aggregation of these three functions in BENet results in high sensitivity to even the slightest discrepancies introduced by facial forgery, enabling it to effectively identify fake faces. To the best of our knowledge, we are the first to adopt this newly designed bias expansion loss function for facial forgery detection."}, {"title": "B. Latent-space Attention Module", "content": "To achieve better representation of forged clues, we incorporate a novel Latent-Space Attention (LSA) module (fig. 1 (B)) that emphasizes the forgery-related inconsistencies by capturing the latent feature variances across multiple scales between the encoder and decoder. Let z denote the latent-space representation at the intermediary step. The computation of the autoencoder is as follows:\n$z = E(z | x)$ (7)\n$x_o = D(x_o | z)$ (8)\nIn this context, $E(\u00b7)$ and $D(\u00b7)$ denote the encoding and decoding functions. The encoder's multi-scale latent-space representations are denoted as $z_0, z_1, z_2,\u2026, z_n$, and the decoder's corresponding representations are $z'_0, z'_1, z'_2,\u2026, z'_n$. The LSA module employs Adaptive Average Pooling (AAP) to resize the multi-scale latent-space features from both the encoder and decoder to the dimensions of z. AAP is crucial for its flexibility in handling various input sizes and its efficiency in merging global spatial information from different scales. It dynamically adjusts pooling regions to produce a fixed-size output, preserving spatial information. The process of generating latent-space attention maps is represented by $LSA(\u00b7, \u00b7)$. These maps are computed for each feature map level. The final latent-space attention maps, labeled as s, result from aggregating these maps with the latent-space features z across multiple scales, as shown in fig. 3 (a). The equation for this calculation process is as follows:\n$s = \\sum_{k=0}^n LSA[AAP(z_k), AAP(z'_k)] + z = \\sum_{k=0}^n s_k + z$ (9)\nFinally, The enriched LSA feature maps are then synergized (i.e., multiplied) with the expanded bias images $x'$, resulting in a multi-faceted feature maps v. These maps, specifically refined for subtle forgeries, are then fed as input into the classifier for face forgery detection. The formulation of the feature maps v is defined as follows:\n$v = s \\times x'$ (10)\nUnlike global attention [20], [38], which generally considers global relationships within the image, LSA specifically targets the variational relationships of latent-space features during reconstruction. It addresses forged details loss by focusing on subtle and localized patterns in small, face-aligned blocks, learning semantically meaningful features and pinpointing key forgery clues with less computational overhead and improved detection efficiency.\nTo achieve this, we define $AAP(z_k)$ as queries and $AAP(z'_k)$ as keys and values, corresponding to the encoded or decoded latent-space features at scale k. To integrate deepfake clues from model-generated inconsistencies, we break down these queries, keys, and values into $P \\times P$ patches, as shown in fig. 3 (b). A value $\\beta \\in R$ in the latent-space attention maps $S_k$ is computed using the corresponding query value $a \\in R$ and its associated patch $Z \\in AAP(z'_k)$. This involves multiplying a by the key matrix patch Z, producing a $P \\times P$ size matrix. The values within this matrix are then subjected to the softmax function for activation. The softmax output, a weighted sum of patch Z from the value matrix, gives the final value $\\beta$ in the latent-space attention maps, which is expressed as follows:\n$\\beta = softmax(aZ) \u00b7 Z$ (11)\nThrough this computation of multi-scale LSA, BENet effectively focuses on the discrepancies in latent-space feature maps between the encoder and decoder. It not only captures fine-grained manipulations but also adapts to the holistic context of the input face, ensuring a robust defense against even the most sophisticated deepfake techniques."}, {"title": "C. Total Loss", "content": "The final comprehensive representation v, derived from Equation 10, serves as the input to a binary multi-layer perceptron (MLP) classifier to distinguish real from fake. We use the cross entropy loss $L_c$ as loss function:\n$L_c = -\\frac{1}{N} \\sum_{i=1}^N [y_i log p_i + (1 - y_i) log(1 \u2013 p_i)]$ (12)\nwhere N is the number of samples from a batch, y is the label, and p is the predicted probability.\nBy combining the bias expansion loss and the cross-entropy loss, the total loss of BENet is defined as:\n$L = \\lambda L_c + (1 \u2013 \\lambda) L_{be}$ (13)\nwhere $L_c$ denotes the objective of face forgery detection, and $\\lambda$ is a hyper-parameter to balance $L_c$ with the bias expansion loss $L_{be}$."}, {"title": "D. Cross-domain Detector Module", "content": "In contrast to the stable and localized feature distributions observed in real faces, fake facial features exhibit a long-tail distribution. This discrepancy arises from various factors, encompassing the diverse and unpredictable nature of forgery techniques and the underlying intent of image manipulation. This phenomenon becomes evident when examining the posterior probabilities distributions $p(D(x') | real)$ and $p(D(x') | fake)$, depicted in fig. 1, where D(x) represents the average per-pixel discrepancy across the bias image, $x'$, defined as $D(x') = \\frac{\\sum_{i=1}^N x'_i}{N}$, and N is the number of pixels in $x'$. Building upon this observation, we integrated a cross-domain detector module into BENet to identify fake instances that deviate from established distribution patterns, specifically those seen in the training data. Given the long-tail distribution characterizing fake samples, instances resulting from unknown image manipulations are expected to have a bias pixel discrepancy D(x) skewed towards the far right of the known distributions. Following this rationale, we designate an instance as a potentially unknown cross-domain fake face if its bias pixel discrepancy exceeds a threshold, denoted as theta. We Determine theta by calculating D(x) for all training samples and selecting the threshold for which 95% of training samples fall below it (see fig. 1)."}, {"title": "IV. THE PREDICTION ALGORITHM", "content": "The Algorithm 1 outlines the prediction process that embodies the proposed methodology for detecting face forgery."}, {"title": "V. EXPERIMENTS", "content": "1) Datasets: We evaluate BENet and its counterparts on FaceForensics++ (FF++) [9], Celeb-DF [39], Diverse Fake Face Dataset (DFFD) [32], and DeepFake Detection Challenge Dataset (DFDC) [40]. The FF++ dataset has 1,000 real videos from YouTube and 4,000 corresponding to four face manipulation methods: Deepfakes(DF) [41], FaceSwap(FS) [42], Face2Face(F2F) [43], and NeuralTextures(NT) [44]. The celeb-DF dataset contains 590 real videos and 5,639 Deepfake videos created using the same synthesis algorithm. DFFD adopts the images from FFHQ [45] and CelebA [46] datasets as the source subset and synthesizes forged images using various Deepfake generation methods. DFDC is a part of the DeepFake detection challenge, which has 1,131 original videos and 4,113 fake videos.\n2) Evaluation Metrics: To evaluate our proposed method, we report the most commonly used metrics in contemporary research, including accuracy (Acc) and area under the receiver operating characteristic curve (AUC).\n3) Implementation Details: In our experiments, we used the dlib toolkit [47] (version 19.24.0), renowned for its robust face recognition features. Dlib, a modern C++ toolkit, excels in machine learning algorithms and is particularly effective in computer vision tasks, including facial landmark detection and face recognition. Hence, we exploited these capabilities to accurately identify facial key points, facilitating the cropping and alignment of faces. These faces were then resized to a uniform 224x224 pixel size, forming the standardized input for our face forgery detection model, BENet. Note that this methodology is applied for all the three datasets, including FF++, Celeb-DF, and DFDC. For the DFFD [32] dataset, which covers a diverse array of facial forgeries, the source images are directly adopted from the FFHQ [45] and CelebA [46] datasets. The DFFD provides pre-cropped faces where the images are expertly transformed using various Deepfake generation methods. For all datasets, we adhere to the established train, validation, and test splits as originally defined and provided with each dataset. To augment our data, we applied random erasure and horizontal flipping. The network is trained using a batch size of 8, employing the Adam optimizer with an initial learning rate of 2e-4 and a weight decay of 1e-5. Note that the parameter $\\lambda$ in BENet's objective formulation is set to 0.5 based on empirical determination.\nWe implemented our BENet and the other comparative variants using PyTorch 1.7.1, leveraging the open-source Xception [48] codebase. Our experiments were conducted using a Tesla NVIDIA A800-SXM4-80GB GPU and an Intel(R) Xeon(R) Platinum 8358 CPU operating at 2.60GHz."}, {"title": "B. Experimental Results", "content": "1) Intra-evaluation: To evaluate the effectiveness and robustness of BENet, we conduct comprehensive comparison experiments with several state-of-the-art methods. Specifically, we experiment with the most challenging FF++ low-quality (LQ) dataset. This dataset is known for its complexity, which poses significant difficulties for many current methods in the field. Often, these existing approaches encounter struggles when dealing with the FF++ LQ, resulting in poor performance. As shown in table I, BENet's intra-evaluation performance outperforms other contemporary models in Acc/AUC with fair scores of 96.83/98.72(%), 99.23/99.98(%), 98.96/99.93(%), and 90.43/96.38(%) on FF++, Celeb-DF, DFFD, and DFDC, respectively. Particularly, we achieve a state-of-the-art AUC score of 98.72% on FF++(LQ). Notably, in comparison to the approach in [33], which employed a multi-attentional network concentrating on local features and textural details for addressing subtle forgeries, our method exhibits a remarkable improvement. This substantial performance boost highlights the efficacy of the introduced multi-scale attention mechanism applied to auto-encoder reconstructions. Overall, BENet shows consistent robustness across various complex scenarios and different datasets.\nTo further demonstrate the robustness of BENet more comprehensively, we expand our experimental scope to include the two other versions of FF++, namely FF++ (RAW) and FF++ high-quality (HQ). The latter is also known in the literature as \u201cC23\u201d. The FF++ (HQ) dataset is a well-recognized benchmark, as numerous existing face forgery detection methodologies have been assessed using it. The results of intra-dataset evaluations are shown in table II. Again, it is clear that BENet not only outperforms other existing approaches but again showcases its consistent capabilities and robustness in the intra-dataset scenario for both uncompressed (RAW) and High-Quality image data.\n2) Cross-evaluation: We also conduct a comprehensive cross-dataset evaluation of BENet to demonstrate its superior performance on unseen data when compared to other methods. Here, we use FF++ (LQ) as training data and we test BENet's performance against other models on Celeb-DF, DFFD, and DFDC. The results reported in table III demonstrate the robustness of BENet in cross-dataset evaluation, surpassing its competitors with substantial AUC scores of 77.86%, 76.59%, and 78.75% on Celeb-DF, DFFD, and DFDC, respectively. More specifically, BENet improves the best AUC in Celeb-DF with 9.15% achieved by PEL [49]. It also improves the best AUC scores achieved by RECCE [14] in the DFFD dataset with a large margin of 7.63%. In the challenging DFDC dataset, where existing methods typically show modest performance below the 69.06% bar, BENet achieves a state-of-the-art 78.75% accuracy, surpassing its closest competitor, RECCE, by 9.69%.\nTo further validate the robustness of BENet, we train it on FF+ (HQ) and test it on Celeb-DF, DFFD, and DFDC. The results, as shown in table IV, indicate that BENet surpasses competing methods by a considerable margin. For example, in comparison to the next best performer, RECCE, BENet demonstrates a notable improvement with margins of 7.94% and 6.19% in the Celeb-DF and DFDC datasets, respectively. These findings again underscore BENet's effectiveness and adaptability in various testing scenarios, reinforcing its potential as a robust solution for face forgery detection.\nFrom the above impressive results on both intra- and cross-evaluations, we believe that this can be attributed to two key factors: 1) BENet's approach of leveraging two modules -Bias expansion and LSA- for expanding \"real-fake\" reconstruction as well as learning richer variational relationships of latent-space features across multiple scales between real and fake faces; and more importantly 2) Incorporation of the cross-domain detector during inference to enhance its recognition accuracy.\nWe further offer insights into the effectiveness of face forgery detection methods when initially trained on one manipulation technique and then evaluated on another, following the evaluation protocol used in [14]. As shown in table V, BENet consistently outperforms other methods across all face manipulation methods, securing the highest AUC scores for each manipulation type. We argue that BENet's success is attributed to its robust feature representation learning strategy, which generalizes well beyond specific training data forgery signatures, enabling effective detection even with new, unseen manipulation methods.\n3) Robustness to Unseen Perturbations: In the current landscape of social media, where image processing is widespread, it is essential that forgery detection systems remain effective"}, {"title": "C. Ablation Study", "content": "In this section, we conduct exhaustive ablations to evaluate the effectiveness of various components and training strategies within BENet. We systematically modify the network by adding or removing specific elements, enabling a detailed analysis of each component's contribution, as depicted in table VII. Our baseline is the Xception model, a standard classification approach [9]. The training strategies include different loss functions: $L_c$, $L_1$, $L_{be}$, and $L_{rec}$, with the latter being the vanilla mean squared error (MSE) used for reconstruction purposes. Notably, in variation (\u2464), the reconstruction learning is applied exclusively to real faces, similar to the approach used in RECCE [14].\n1) Effectiveness of bias calculation: The inclusion of an auto-encoder (\u2461) for reconstructing input face images significantly enhances performance, with a 1.95% increase in Acc and 1.76% in AUC compared to the baseline variation (\u2460). Further improvements are observed when bias images are calculated (3), leading to an additional 1.08% rise in Acc and 1.87% in AUC. These results suggest that using autoencoder reconstructions in BENet to amplify deepfake clues is effective, and the computation of bias images further aids in making this information more straightforward for network optimization.\n2) Effectiveness of bias expansion loss: As previously mentioned, the bias expansion loss $L_{be}$ plays a pivotal role in guiding BENet's learning process to discern the bias within the reconstruction of real and fake faces. Thus, its formulation encompasses two elements: An invariant reconstruction component for real faces and a bias component for fake faces. Compared to variations without $L_{be}$ (\u2464, and), i.e., those solely utilizing reconstruction loss for real faces ($L_1$), the integration of bias expansion loss (\u2466) results in a significant improvement in both Acc and AUC.\n3) Effectiveness of latent-space attention: Excluding the LSA from BENet leads to a reduced ability to detect inconsistencies in subtle forgeries within the latent space. Compared to (3), adding the LSA module (4) brings an improvement of 1.88% and 1.77% in Acc and AUC, respectively. LSA lets BENet emphasize the forgery-related inconsistencies by capturing the latent feature variances across different scales for improved fine-grained manipulation detections.\n4) Effectiveness of cross-domain detector: We also examine the role of the cross-domain detector in BENet. When it is omitted (7), there is a significant drop in the model's ability to handle cross-domain forgeries. As such, We gain a fair improvement of 3.42% and 2.39% in Acc and AUC, respectively, with the full BENet model. This proves that cross-domain detector is instrumental for improved generalization of BENet on unseen cross-domain fake faces."}, {"title": "D. Experimental and Qualitative Analysis", "content": "1) Feature Distribution Analysis: The learned feature visualizations for the: (a) baseline, (b) RECCE, and (c) BENet, all trained on FF+ (LQ), are presented in fig. 6. For instance, we extract the features from the penultimate fully-connected layer, selecting 2000 samples each from FF++ for in-domain evaluation and Celeb-DF for cross-domain evaluation. The t-distributed stochastic neighbor embedding (t-SNE) [53] visualizations reveal that BENet learns highly discriminative features. In the t-SNE space, real and fake face embeddings are distinctly separated, more than in the baseline and RECCE. This notable separation observed in BENet feature clusters affirms its impressive ability to discern between authentic and counterfeit faces.\ninvolves a cross-manipulation training and testing approach where we train each component on images manipulated by one specific technique and then test it on images altered using a different manipulation technique. This cross-evaluation strategy is instrumental in determining the adaptability and resilience of each component of BENet when faced with various Deepfake generation methods. The results are shown in Table table IX.\nComparing with the \u201cFull BENet\u201d, the following observations can be made: 1) The improvement trend in AUC persists consistently across all cross-manipulations from variant 1 to 7; 2) The Full BENet consistently exhibits significantly better performance compared to other variants.\nThese outcomes provide additional validation for BENet's generalization capacities, originating from its proposed methodological construction. This level of detailed analysis we conducted is crucial in demonstrating the robustness and versatility of BENet in the rapidly evolving domain of Deepfake detection.\n2) Analysis of the Learned Feature Maps: We visualize the real/fake faces reconstructions and their related learned feature maps at different levels in BENet across various datasets. The results are shown in fig. 7. We observe the progressive refinement and adeptness of BENet in isolating and accentuating forgery clues across fake faces. First, we can notice the ability of BENet to reconstruct real faces consistently, with a little blur, while adaptively amplifying the deepfake clues present in fake faces (c). More specifically, The LSA module finely tunes its focus through the attentive examination of multi-scale representations derived from the bias expansion, subsequently intensifying the anomalies within the Bias image. Large-scale feature maps offer extensive but noisy clues, while small-scale ones provide detailed yet partial clues. Since the autoencoder differentially reconstructs to discover forgeries, the LSA module strives to further enhance them by capturing the differences in multi-scale features. Thus, for real faces characterized by consistent reconstruction, the attention map s holds a minimal weight, resulting in a negligible difference in the composite image v, i.e., often manifesting as a near-black image. Conversely, with fake faces, the reconstruction discrepancies elevate the s map's weight, and v accentuates the divergence rooted in $x'$. LSA further sharpens the classifier's ability to differentiate and flag deepfakes with greater capabilities by expanding the gap between real and fake images.\n3) Decision-making Analysis: fig. 8 visualizes the gradient-weighted activation mapping (Grad-CAM) [54] of our method in different evaluation settings. The comparative analysis of Grad-CAM outputs across all datasets shows that BENet has a clear advantage when detecting deepfake manipulations. In contrast to other models, BENet reliably produces heatmaps with distinct, well-defined areas of emphasis, especially over important face characteristics where forgeries are most detectable (e.g., eye, nose, and mouth). On the flip side, it generates fewer heatmaps on the real faces, as opposed to other methods. We argue that the multi-scale LSA module within BENet is crucial not only for highlighting subtle inconsistencies that other models overlook but also adapts to the holistic context of the face, ensuring a robust defense against even aginst the most sophisticated forgeries."}, {"title": "VI. LIMITATIONS OF THE PROPOSED METHOD", "content": "While BENet demonstrates notable robustness against cross-domain attacks, it may face difficulties when confronted with samples that closely resemble real faces. While it prioritizes the detection of cross-domain deepfakes to streamline incremental learning costs, addressing the nuances of deepfake variations closely mimicking real faces is paramount for enhancing the security of face recognition systems. In fig. 9, we present examples of failure cases encountered by BENet."}, {"title": "A. False Negative (Predict Fake as Real, Examples a-c)", "content": "This category typically includes challenging samples that the model may mistakenly identify as real. These difficulties arise from various factors, such as (1) low-quality images characterized by extreme dimness or poor resolution, (2) subtle or less apparent fake clues, and (3) limited visibility of facial features due to significant posing or angles, which can also be deemed as low-quality traits. These complex samples hinder the model's ability to perform nuanced reconstruction, leading to potential confusion with real images. These issues warrant further investigation in future studies."}, {"title": "B. False Positive (Predict Real as Fake, Examples d-f)", "content": "In this category, samples are often erroneously classified as fake faces by the model due to elements like obstructions or alterations. Instances include (d) faces with graffiti, (e) faces partially covered by hands, and (f) faces obscured by sunglasses. These kinds of occlusions can mislead the model into detecting them as artificial clues, thereby resulting in misidentification. This phenomenon highlights the need for models to better discern between genuine occlusions and deliberate falsifications.\nFinally, we emphasize the importance of the cross-domain detector erring on the side of false positives rather than false negatives when detecting face forgeries in the provided posterior probability distribution (PPD). False positives, while inconvenient, allow for a secondary verification process. In contrast, false negatives pose a significant threat to security systems, as they represent undetected forgeries. Therefore, while both errors are undesirable, false positives are preferable due to the additional safety net they provide through subsequent verification."}, {"title": "VII. CONCLUSION", "content": "We proposed BENet, a Cross-Domain Robust Bias Expansion Network for efficient face forgery detection. BENet leverages a bias expansion-based autoencoder to expand bias between real and fake face reconstructions to unveil hidden forged clues. To further tackle subtle forgeries, we incorporated an innovative LSA module designed to capture variations in latent-space between the encoder and decoder. Furthermore, to refine detection outcomes for unfamiliar cross-domain deepfakes, BENet integrates a cross-domain detector activated during inference, significantly boosting recognition accuracy. Rigorous evaluations, both quantitative and qualitative, conducted on SOTA benchmarks, evidenced the robustness of BENet across intra and cross-domain scenarios."}]}