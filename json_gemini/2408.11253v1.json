{"title": "Automatic Image Annotation (AIA) of AlmondNet-20 Method for\nAlmond Detection by Improved CNN-based Model", "authors": ["Mohsen Asghari Ilani", "Saba Moftakhar Tehran", "Ashkan Kavei", "Arian Radmehr"], "abstract": "In response to the burgeoning global demand for premium agricultural products, particularly within the\ncompetitive nut market, this paper introduces an innovative methodology aimed at enhancing the grading\nprocess for almonds and their shells. Leveraging state-of-the-art Deep Convolutional Neural Networks\n(CNNs), specifically the AlmondNet-20 architecture, our study achieves exceptional accuracy exceeding\n99%, facilitated by the utilization of a 20-layer CNN model. To bolster robustness in differentiating between\nalmonds and shells, data augmentation techniques are employed, ensuring the reliability and accuracy of\nour classification system. Our model, meticulously trained over 1000 epochs, demonstrates remarkable\nperformance, boasting an accuracy rate of 99% alongside a minimal loss function of 0.0567. Rigorous\nevaluation through test datasets further validates the efficacy of our approach, revealing impeccable\nprecision, recall, and F1-score metrics for almond detection. Beyond its technical prowess, this advanced\nclassification system offers tangible benefits to both industry experts and non-specialists alike, ensuring\nglobally reliable almond classification. The application of deep learning algorithms, as showcased in our\nstudy, not only enhances grading accuracy but also presents opportunities for product patents, thereby\ncontributing to the economic value of our nation. Through the adoption of cutting-edge technologies such\nas the AlmondNet-20 model, we pave the way for future advancements in agricultural product\nclassification, ultimately enriching global trade and economic prosperity.", "sections": [{"title": "1. Introduction", "content": "Agriculture plays a critical role in a country's long-term economic health. It goes beyond simply providing\nfood and materials. It's a major source of jobs, often the primary income source, for a significant portion of\nthe population. The agricultural landscape is constantly changing due to various factors. Rising incomes,\nglobalization, and increased focus on healthy eating all influence how food is produced. In the coming\nyears, the demand for various food items like fruits, vegetables, dairy, seafood, and meat is expected to rise\nsignificantly. Developing nations like Iran face a particular challenge in agriculture: a lack of automation\nand mechanized processes. Despite this, a substantial portion of Iran's population (around 58%) relies on\nagriculture for their livelihood. The country has significant potential for growth in the food processing\nsector, which could position them well for increased participation in global food trade. Iran boasts a thriving\ngrocery and food market, with retail sales accounting for a remarkable 70% of total revenue. The food\nprocessing industry is also a major contributor, holding a significant 32% share of the country's entire food\nmarket [1]. The food industry operates in a cutthroat environment where quality is the ultimate\ndifferentiator. Consumers are no longer satisfied with the bare minimum. Their heightened awareness and\nevolving preferences demand a relentless pursuit of excellence [2]. Despite advancements in technology, a\nsignificant portion of food quality evaluation remains stubbornly manual. This reliance on human\ninspectors, while possessing valuable experience, introduces a layer of subjectivity and inconsistency.\nPhysiological factors like fatigue or even hunger pangs can influence their judgment, leading to fluctuations\nin the evaluation process. This traditional method also proves to be inefficient. Manual inspections are time-\nconsuming and labor-intensive, ultimately driving up production costs. To stay ahead of the curve and meet\nthe ever-increasing demands of today's consumers, the food industry requires a more robust and objective\nquality evaluation system. Here's where automation steps in, offering a compelling solution [3, 4].\nOur increasingly globalized world relies heavily on the complex machinery of the food industry. This vast\nsystem encompasses everything from the planting of seeds (agriculture) to the products on our supermarket\nshelves (food processing, marketing, and sales). It's a tirelessly working engine ensuring a steady flow of\nfood across the globe. However, a crucial element within this industry, food quality evaluation, remains\nsurprisingly reliant on a traditional method: manual assessment by trained individuals. While this approach\nhas served the industry for a long time, it comes with inherent limitations. Manual evaluations are\nexpensive, requiring a significant workforce. Additionally, they are inherently subjective, as human\ninspectors rely on their own perceptions, which can be influenced by factors like fatigue or even personal\npreferences. This subjectivity can lead to inconsistencies in the evaluation process, potentially allowing\nproducts that don't meet quality standards to slip through the cracks [1]. As a result, the food industry faces\na growing pressure to elevate its standards of food quality evaluation. The need for objectivity, consistency,\nand efficiency in this critical process is becoming increasingly important. The global food industry is a\ncomplex and multifaceted giant, weaving together agriculture, food processing, marketing, and sales to\nbring food from farm to table. Its importance in our interconnected world is undeniable. Yet, a surprising\ntruth lies at the heart of this industry: food quality evaluation often remains a stubbornly manual process,\nrelying on trained individuals. While these inspectors bring valuable experience, this traditional method\nsuffers from several drawbacks. It's a costly endeavor, requiring significant manpower. More importantly,\nit's inherently subjective. Human inspectors, susceptible to fatigue, personal preferences, or even hunger\npangs, can introduce inconsistencies into the evaluation process. This subjectivity creates a risk - products\nthat don't meet quality standards could slip through the cracks. As a result, the industry faces a growing\ndemand for a more robust system one that prioritizes objectivity, consistency, and efficiency in food\nquality evaluation [1]. Almonds (Amygdalus Communis L.) are a fascinating nut, playing a dual role in\nthe world of food and agriculture. Not only are they a valuable source of health benefits, but they also\ncontribute significantly to thriving export industries in many regions. These perennial plants, cultivated in\ncold and temperate areas, produce energy-packed kernels. Aydin (2003) highlights the impressive\nnutritional profile of almonds, boasting 6 kcal g-1 of energy, 15.64% protein, and a remarkable oil content\nranging from 35.27% to 40%. Notably, almond kernel oil stands out for its high concentration of oleic acid,\nclocking in at around 40% [5].\nIran is a major player in the global almond production scene. However, their harvesting and handling\nmethods currently rely heavily on manual labor [6]. Practices like threshing are often done by hand or with\nthe aid of simple, homemade equipment. To optimize these various processes - threshing, conveying,\nsorting, and storing - a deeper understanding of the physical and mechanical properties of both the almond\nnuts and their kernels is crucial. This knowledge can lead to significant improvements in efficiency and\noverall crop management. To improve efficiency throughout the almond production chain, from harvesting\nto storage, researchers are actively investigating the nuts' physical and mechanical properties. One study\nexplored the relationship between size and rupture strength across ten different almond varieties [7].\nAnother delved into how moisture content affects the physical properties of both almond nuts and kernels.\nAdditionally, research has shed light on how factors like irrigation regimes, fertilization types, and even the\ncultivation year itself can influence the physical properties of almonds [6]. By understanding these various\naspects, researchers can develop strategies to optimize processes like threshing, conveying, sorting, and\nstoring, ultimately leading to a more efficient and productive almond industry. Currently, the process of\ngrading almonds relies heavily on manual methods. One traditional technique involves calculating\n\"adjusted kernel weight.\" This calculation factors in the weight of edible kernels, inedible ones, foreign\nmaterials, and excess moisture, using predetermined percentages [8, 9]. While this method exists, it suffers\nfrom several drawbacks. It's time-consuming, labor-intensive, and ultimately inefficient. Additionally, it\nstruggles with consistency, especially when evaluating visual aspects of the almonds like broken pieces,\nhalves, chips, scratches, splits, and the condition of their shells. In an attempt to improve efficiency,\ncomputer-based databases were introduced to replace manual calculations and grading. However, even\nthese digital systems weren't without flaws. Rounding errors, particularly at the hundredth decimal place,\npersisted [8]. This lack of precision could potentially lead to inconsistencies in the final grading results.\nWhile manual methods have traditionally dominated almond grading, recent advancements in image\nprocessing and analysis offer a promising alternative. This technology utilizes digital imaging, computer\nscanning, and specialized software to analyze almond kernels [10\u201313]. The software calculates factors like\nkernel area and pixel values, allowing for a more objective and automated classification process.\nTechniques like SHAPE, SeedCount, GrainScan, Smartgrain, and ImageJ have shown potential in\neffectively classifying different types of kernels. However, there are limitations to consider. Some of these\ntechniques are still under development, and others may be too cumbersome or expensive for large-scale\napplications. The key lies in finding an image processing solution that strikes a balance between accuracy,\nefficiency, and cost-effectiveness for the high-volume world of almond production. The world of almond\ngrading is undergoing a fascinating transformation. While manual methods have served the industry well\nfor many years, researchers are increasingly exploring the potential of machine learning to automate and\nimprove the process. Several studies have shed light on this exciting development. Mirzabe et al. [14]\ninvestigated the physical properties of almonds, employing statistical models and machine learning\ntechniques to analyze factors like bulk density and friction coefficient. Teimouri et al. [29] took a different\napproach, utilizing artificial neural networks (ANNs) to successfully categorize almonds into various\nclasses, including normal, broken, wrinkled, and double kernels. Their research yielded impressive results,\ndemonstrating the high sensitivity and accuracy of this approach in detecting almond quality variations.\nSharifi et al. [15] explore the integration of artificial intelligence with digital twin models to optimize\nstormwater management in smart cities, highlighting enhanced efficiency and sustainability of urban\ndrainage systems.\nAnother study (Vidyarthi et al. [8]) combined image processing with machine learning models like random\nforest and support vector machines (SVM) to predict the size and mass of almond kernels. This research\nhighlights the versatility of machine learning, showcasing its potential application beyond simple\nclassification tasks. Additionally, Reshadsedghi et al. [16] explored the use of ANNs to classify almond\nvarieties based on shell characteristics. Their approach involved extracting acoustic features from the shells\nand feeding them into the ANNs, achieving high classification accuracy for different shell types. Eski et al.\n[17] further broadened the scope of machine learning applications in almond production by designing a\nsystem to predict various physical properties based on just three key dimensions - length, width, and\nthickness. This research demonstrates the potential of machine learning to extract valuable insights from\nlimited data sets. While these studies showcase the immense potential of machine learning in almond\ngrading, it's important to acknowledge that some techniques are still under development. Additionally, cost-\neffectiveness remains a crucial consideration, particularly for large-scale production. Nevertheless, the\nresearch is clear: machine learning holds the promise to revolutionize almond grading, ushering in an era\nof greater efficiency, accuracy, and consistency. Almond recognition and quality assessment model\npresented in this study demonstrate promising real-time outcomes and can seamlessly integrate with\ncamera-based systems for on-the-fly fruit quality analysis. Notably, the AlmondNet-CNN based\narchitecture is characterized by a reduced number of parameters, enhancing its efficiency in training on a\nlarge volume of images within a shorter timeframe. Consequently, the model's processing time for real-\nworld images is minimized, making it highly suitable for precision agriculture applications. As the world\nof almond grading seeks to move beyond traditional manual methods, the integration of digital image\nprocessing and pattern recognition algorithms has emerged as a game-changer [18]. Ahmadi et al. [20]\nconducted an assessment of SAM and U-Net deep learning architectures for the identification of concrete\ncracks. SAM efficiently pinpoints longitudinal cracks using image segmentation techniques, while U-Net\nprecisely identifies spalling cracks by analyzing the characteristics of pixels. Employing both models\ntogether significantly enhances the detection of cracks, which is crucial for the safety and longevity of\nconcrete structures. Here, computer vision steps in as a powerful tool, offering speed, cost-effectiveness,\nconsistency, and most importantly, precision in inspection tasks. The food industry, in particular, has\nwitnessed a surge in the application of computer vision for quality assessment. Recognized for its vast\npotential, computer vision has placed the food industry among the top 10 sectors actively employing this\ntechnology [8]. Its success lies in its ability to perform objective and non-destructive evaluations across a\nwide variety of food products. This has been a key driver for substantial research and development efforts\nwithin the food industry, as the advantages of computer vision - objectivity, speed, and the contactless\nnature of inspection - have become increasingly clear [19]. Ahmadi et al. [30] created a supervised machine\nlearning framework tailored for digital twin uses, specifically for segmenting terrain in coastal areas.\nUtilizing USGS datasets and advanced deep learning methods, they categorized the coastal landscape of\nFlorida into distinct classes like water, grassland, and forest. This segmentation significantly improves\ndigital twins for more effective environmental surveillance and urban development planning. Govindan et\nal. [31] develop a stochastic optimization model for creating a resilient reverse logistics network to manage\ninfectious healthcare waste during crises like COVID-19. The model incorporates strategies like new\ncollection centers and third-party logistics to enhance resilience and efficiency in waste management. In\nthe context of computer vision for food quality assessment, a well-designed system goes beyond just the\nsoftware and algorithms. A critical partnership exists between the computer vision system itself and an\nillumination system. Imagine a personal computer (PC) equipped with specialized software, ready to\nanalyze food products. However, for this analysis to be effective, it needs clear and accurate information.\nThis is where the illumination system comes in. Just like good lighting is essential for taking a clear\nphotograph, the illumination system plays a vital role in capturing high-quality images of food products.\nThe quality of the captured image has a significant impact on the entire process. A well-lit image allows\nfor faster and less complex image processing steps later on. This translates to a more efficient system\noverall, and even plays a role in reducing the overall cost. In simpler terms, good lighting upfront means a\nsmoother and more cost-effective computer vision system for food quality evaluation.\nThis research takes a groundbreaking approach to almond quality assessment by introducing a novel deep\nlearning model called Almond-CNN. This model is specifically designed to identify and evaluate the quality\nof individual almonds within a mixed batch containing both almonds and shells. The researchers created a\nrobust dataset for training and testing the model. This dataset is comprised of real-world scenario images,\nmeticulously categorized into two distinct quality classes. The core of the system lies in a convolutional\nneural network (CNN) architecture. To ensure optimal performance, the model is trained on this\ncomprehensive dataset of 736 images, encompassing a variety of almond and shell combinations, over\nmultiple training cycles (epochs). Finally, the trained deep learning model undergoes rigorous testing to\nvalidate its accuracy and effectiveness [32]. The challenges faced by the researchers in developing the\nAlmond-CNN model were not insignificant. The dataset they compiled to train the model exhibited\nsignificant variations, both between different classes (almonds vs. shells) and even within the same class\n(variations among almond shapes and appearances). Additionally, the real-world scenarios these images\ncaptured added another layer of complexity. To address these challenges, the researchers divided their\ncomprehensive dataset of 736 images into three distinct subsets: training, validation, and testing. This\nmeticulous approach allowed them to train the model effectively while also ensuring its generalizability to\nunseen data. The results were impressive. The deep learning-based Almond-CNN model surpassed all\nexisting state-of-the-art models, achieving a remarkable 100% accuracy on a test set featuring entirely new\nimages. This speaks volumes about the model's effectiveness in real-world applications. Beyond accuracy,\nthe researchers also focused on creating a model that could seamlessly integrate into existing workflows.\nThe fruit recognition and quality assessment system they developed demonstrates promising real-time\ncapabilities. In simpler terms, the model can analyze fruits as they appear, without any delays. Furthermore,\nthe architecture of Almond-CNN is designed for efficiency. By using a reduced number of parameters, the\nmodel can be trained on large datasets in shorter timeframes. This translates to faster processing times for\nreal-world images, making it ideal for applications in precision agriculture, where speed and efficiency are\ncrucial."}, {"title": "2. Materials and Methods", "content": "This study investigated the potential of Convolutional Neural Networks (CNNs), a powerful deep learning\ntechnique, for recognizing and classifying almond kernels. Deep CNN architectures have become the go-\nto tools for effective image recognition, detection, and classification tasks due to their superior performance\n[21, 22]. A typical CNN architecture comprises multiple layers, including convolutional layers for feature\nextraction, non-linear activation layers for introducing non-linearity, and pooling layers for dimensionality\nreduction [23]. Deep CNNs offer several advantages over traditional shallow neural networks, including\nsparse interactions (limited connections between neurons), parameter sharing (reducing training\ncomplexity), and equivariance (consistent response to similar input features). These advantages make\nDCNNS superior classifiers compared to traditional approaches like logistic regression, linear regression,\nand Support Vector Machines (SVMs).\nBeyond basic CNN architecture, this research incorporated advanced image processing and machine\nlearning techniques to achieve high classification accuracy. These techniques included image augmentation\n(artificially creating more training data by manipulating existing images), transfer learning (leveraging pre-\ntrained models on similar tasks to accelerate training and improve performance), and dropout (randomly\ndropping neurons during training to prevent overfitting). By utilizing these techniques, the DCNN model\neffectively mitigated data noise and interference, leading to a more robust recognition and classification\nsystem for almond kernels. Transfer learning played a crucial role in this study. This technique involves\nrepurposing a pre-trained model on a related task to accelerate training and enhance the performance of the\nnew model. In this case, well-established deep learning models like AlexNet and GoogLeNet, already\ntrained on large image datasets, provided a valuable starting point. Transfer learning significantly reduced\nthe time and effort required to train the new DCNN model for almond kernel classification [24]. The\nresearch also focused on the effectiveness and adaptability of CNNs in preserving spatial relationships\nbetween data points within 3D image tiles. Unlike traditional neural networks where learnable parameters\nincrease significantly with the number of input features, CNNs scale their learnable parameters with filter\nsize and the number of filters used. This allows for increasing the number of layers without a substantial\nincrease in learnable parameters, promoting model efficiency [22]. After experimenting with various\nconfigurations, including different layer counts, kernel sizes, and pooling options, the researchers settled\non a specific CNN architecture (detailed in Figure 4) for subsequent training and testing. This architecture,\nsimilar to a previous strategy used for almond detection, achieved the highest average classification\naccuracy. The chosen CNN architecture consisted of three sets of sequential layers: 3D Convolution\n(CONV) for feature extraction, Batch Normalization (BN) for stabilizing training, Rectified Linear Unit\n(ReLU) for introducing non-linearity, and Max Pooling (MP) for dimensionality reduction. These sets of\nlayers were followed by Fully Connected (Dense) layers for combining extracted features, a Softmax layer\nfor generating probability distributions, and finally a Classification layer for assigning class labels (e.g.,\nalmond kernel or non-kernel) to the input data. Each convolutional layer utilized various 3D convolution\nfilters to extract relevant features within the input dataset [16]. The resulting features were then\nconcatenated along a new dimension, creating a richer representation for classification."}, {"title": "2.1 Image annotation", "content": "The ever-increasing volume of digital images, coupled with user demand for efficient access to vast data\nsets, has fueled the need for accurate and fast image retrieval technology. Automatic Image Annotation\n(AIA) emerges as a key solution, enabling image retrieval based on textual content. AIA presents a\nsignificant challenge in computer vision, as described by Barnard et al. [25], due to the inherent complexity\nand diverse nature of image content. It allows for swift and effective query, retrieval, and organization of\nimage information. AIA has applications in various areas, including online and offline data exploration,\nimage manipulation, and mobile annotation tools [25\u201328]. A typical image annotation system relies on two\ncritical elements: (1) a mechanism for semantically understanding the content of raw images, and (2) a\nNatural Language Processing (NLP) unit that translates the extracted semantic data into human-readable\nlabels [29]. In this study, we utilized LabelImg, a popular tool, for multi-class labeling of images. Figure\n1 showcases the LabelImg framework used for labeling almonds and shells. Specifically, Figure 1 (a, b,\nc) depict different instances of the labeling processFigure 1 (d) illustrates the labeling of a single almond,\nwhile Figure 1 (e) demonstrates the labeling of shells. LabelImg generates the labeled images as XML\nfiles, which capture both bounding boxes (encompassing the objects) and corresponding labels."}, {"title": "2.2 Image Pre-processing", "content": "Implementing a pre-processing pipeline before feeding images into a CNN model can significantly enhance\naccuracy and improve results. In the case of images containing both shells and almonds, the applied image\nprocessing steps play a crucial role. Converting the RGB images (Figure 2 (a)) to grayscale (Figure 2 (b))\nsimplifies the information while retaining essential features. The subsequent application of Gaussian blur\nand denoising techniques (Figure 2 (c)) helps in reducing noise and enhancing the clarity of relevant image\ndetails. Thresholding (Figure 2 (d)) further aids in isolating distinct features by creating a binary\nrepresentation, making it easier for the CNN model to focus on relevant information. Finally, employing\nCanny edge detection (Figure 2 (e)) contributes to the extraction of meaningful edges, providing the model\nwith well-defined boundaries for object recognition. This comprehensive image processing approach not\nonly refines the input data but also optimizes the images for improved learning and classification within the\nCNN model."}, {"title": "2.3 CNN Model Architecture", "content": "The CNN architecture is designed to effectively detect almonds and shells in images. The model, defined\nas a Sequential model, starts with a convolutional layer (Conv2D) with 64 filters of size 3x3, using the\nReLU activation function and maintaining spatial dimensions with padding. The input shape is set to (312,\n210, 320, 1), reflecting the dimensions of the images. Subsequently, max-pooling layers (MaxPooling2D)\nwith a pool size of 2x2 are applied to down-sample the feature maps while preserving spatial information.\nThe architecture further incorporates a convolutional layer with 128 filters and another set of max-pooling\nlayers. SpatialDropout2D is introduced for regularization to enhance model generalization. Additional\nconvolutional layers with 512 and 256 filters follow, each accompanied by max-pooling. A stride of 2 is\napplied in the 256-filter layer for further down-sampling. The subsequent layers include another\nconvolutional layer with 256 filters and a unique max-pooling layer with a pool size of 3x3. Two more\nconvolutional layers with 128 filters and corresponding max-pooling layers are included, concluding with\na dropout layer for regularization. Following the convolutional layers, the model transitions to a flattened\nlayer, preparing the data for fully connected layers. A dense layer with 64 neurons and ReLU activation is\nadded, providing a nonlinear transformation. BatchNormalization is introduced to normalize and stabilize\nactivations, contributing to model robustness. The final layer consists of two neurons with a softmax\nactivation function, facilitating binary classification between almonds and shells. This CNN architecture,\nwith its combination of convolutional, max-pooling, and fully connected layers, is well-suited for\neffectively learning and classifying features in almond and shell images."}, {"title": "3. Results and Discussion", "content": "This investigation leverages annotated objects from the LabelImg tool to enhance object identification\naccuracy, supplementing the model's training. Figure 5 provides a concise overview of training and\nvalidation outcomes. The dataset maintains a balanced 1:1 distribution of Almonds and Shells and intact\nimages, with a 5:1 training-validation split. Training accuracy is computed from a dataset of 736 images,\nand the validation set constitutes 20% of the training data. Exceptional accuracy is achieved, reaching close\nto 100% during the 831st epoch for training and 97.95% at the 899th epoch for validation. The use of two\nGPUs accelerates training in Kaggle, reducing the time needed for the 1000th epoch by approximately 40\nminutes. Notably, the estimated running time on a CPU alone exceeds 6 hours, underscoring the\ncomputational efficiency gained through GPU acceleration.\nIn our study, the Convolutional Neural Network (CNN) exhibited significant performance evolution over\n100 epochs, evident in decreasing loss and increasing accuracy for both training and validation datasets.\nInitially, during the first epoch, the training data showed a loss of 1.7970 with an accuracy of 47.39%, while\non the validation set, the loss was 1.4931 with an accuracy of 26.98%. Subsequent epochs displayed a\nconsistent trend of diminishing loss values and ascending accuracy scores. The final epoch, epoch 1000,\ndemonstrated remarkable convergence, with minimal loss values of 0.0567 on the training set (Figure 5\n(a)) and 0.0605 on the validation set (Figure 5 (b)), accompanied by high accuracies of 100% and 100%,\nrespectively. This convergence signifies the model's successful learning and generalization over the training\nperiod (Figure 5 (a,b)).\nThe CNN model exhibited highly efficient performance in detecting various objects, as indicated by\nprecision, recall, and F1-score metrics in Figure 5 (d). Specifically, almond and shell detections achieved\na precision, recall, and F1-score of 1.00, demonstrating robust identification. The model's overall accuracy\nacross all classes reached 0.99, underscoring its effectiveness in Almond identification within the dataset.\nMicro-averaged and weighted-averaged metrics further support the model's consistent and high-level\nperformance across different type of objects as Shells and Almond categories, with reported values of 0.991\nfor precision, recall, and F1-score in both micro and weighted averages. These results affirm the model's\nproficiency in efficiently detecting and classifying almonds and shells within the dataset comprising 106\ntests.\nThe overall prediction accuracy is depicted through a confusion matrix in Figure 5 (c), summarizing\naccurate predictions across all class labels in matrix form. The diagonal blue elements represent the number\nof correct predictions, with 44 for shell detection and 12 for almond detection out of the total data. White\nelements indicate inaccurate predictions, which are 0 for both classes."}, {"title": "4. Conclusion", "content": "In conclusion, our research presents a novel approach utilizing the LabelImg methodology to enhance the\naccuracy of almond detection within complex environments, leveraging the intelligence of Convolutional\nNeural Networks (CNNs). The intricate nature of almond and shell objects necessitates the adoption of a\nCNN-based approach, offering superior precision and reliability in classification tasks. By meticulously\nlabeling images containing intact and broken almonds, we curated annotated datasets comprising bounding\nboxes and labels, facilitating robust training and testing phases. Furthermore, this annotated data serves as\nvaluable feedback for refining preprocessing hyperparameters, enhancing the overall efficacy of our\nclassification system. Our study unveils compelling findings regarding the effectiveness of deep learning\nmethodologies in precisely categorizing almonds, with profound implications for nut packaging and the\nbroader food and crop industries. Noteworthy key findings include the successful training of a CNN model\nto detect almonds amidst a high volume of almonds and shells, achieving a remarkable prediction accuracy\nexceeding 99.1%. Furthermore, our CNN-based model, specifically implemented on AlmondNet-20,\ndemonstrates proficiency in distinguishing nut types, particularly almonds, boasting perfect precision,\nrecall, and F1-score metrics. We advocate for future investigations into exploring almond types to further\nrefine precision in classification tasks.\nMoreover, the strategic balancing of datasets significantly enhances training and validation performance,\nmanifesting in a remarkable performance improvement from 28% to 99.1%. Leveraging OpenCV for image\nprocessing, incorporating techniques such as GaussianBlur, fastNlMeansDenoising, adaptiveThreshold,\nand Canny, streamlines almond texture discrimination and shell identification, augmenting model accuracy\nand efficiency. Looking ahead, we identify LabelImg as a promising tool and strategy for handling images\nwith intricate details, facilitating streamlined annotation processes and contributing to the overall robustness\nof our classification system. In summary, our research underscores the transformative potential of deep\nlearning methodologies, particularly within the realm of agricultural product classification. By advancing\nalmond detection accuracy and efficiency, our study holds promise for reducing time and costs associated\nwith manual inspection and quality checks, thereby offering tangible benefits for industry stakeholders and\ndriving advancements in agricultural technology and productivity."}, {"title": "Data availability", "content": "Due to limitations in dataset sharing, the data is available upon reasonable request. Please contact Mohsen\nAsghari Ilani at mohsenasghari1990@ut.ac.ir for access."}, {"title": "Declarations", "content": null}, {"title": "Conflict of interest", "content": "The authors declare no conflict of interest."}]}