{"title": "Shaping AI's Impact on Billions of Lives", "authors": ["Mariano-Florentino Cu\u00e9llar", "Jeff Dean", "Finale Doshi-Velez", "John Hennessy", "Andy Konwinski", "Sanmi Koyejo", "Pelonomi Moiloa", "Emma Pierson", "David Patterson"], "abstract": "Artificial Intelligence (AI), like any transformative technology, has the potential to be a double-edged sword, leading either toward significant advancements or detrimental outcomes for society as a whole. As is often the case when it comes to widely-used technologies in market economies (e.g., cars and semiconductor chips), commercial interest tends to be the predominant guiding factor. The Al community is at risk of becoming polarized to either take a laissez-faire attitude toward Al development, or to call for government overregulation. Between these two poles we argue for the community of Al practitioners to consciously and proactively work for the common good. This paper offers a blueprint for a new type of innovation infrastructure including 18 concrete milestones to guide Al research in that direction. Our view is that we are still in the early days of practical Al, and focused efforts by practitioners, policymakers, and other stakeholders can still maximize the upsides of Al and minimize its downsides. To offer a sufficiently-broad and realistic perspective that captures the possibilities, we've assembled a team composed of senior computer scientists, policymakers, and rising stars in Al from academia, startups, and big tech\u2014a team that covers many Al domains (see Authors). In addition to our own expertise, our perspective is informed by interviews with two dozen experts in", "sections": [{"title": "Introduction", "content": "Artificial Intelligence (AI), like any transformative technology, has the potential to be a double-edged sword, leading either toward significant advancements or detrimental outcomes for society as a whole. As is often the case when it comes to widely-used technologies in market economies (e.g., cars and semiconductor chips), commercial interest tends to be the predominant guiding factor. The Al community is at risk of becoming polarized to either take a laissez-faire attitude toward Al development, or to call for government overregulation. Between these two poles we argue for the community of Al practitioners to consciously and proactively work for the common good. This paper offers a blueprint for a new type of innovation infrastructure including 18 concrete milestones to guide Al research in that direction. Our view is that we are still in the early days of practical Al, and focused efforts by practitioners, policymakers, and other stakeholders can still maximize the upsides of Al and minimize its downsides. To offer a sufficiently-broad and realistic perspective that captures the possibilities, we've assembled a team composed of senior computer scientists, policymakers, and rising stars in Al from academia, startups, and big tech\u2014a team that covers many Al domains (see Authors). In addition to our own expertise, our perspective is informed by interviews with two dozen experts in"}, {"title": "I. Putting Pragmatic AI in Context", "content": null}, {"title": "History of Technological Paradigm Shifts", "content": "Similar to the dawn of television, computers, nuclear power, and the internet, uncompromising antagonistic positions are being taken in these early days of practical Al. The polarized discourse on this new technology has devolved currently into a standoff between \"accelerationists\" and \"doomers.\" Like most practitioners of Al, we believe reality is more nuanced. One debated issue is the role of the government in Al's development. Recent efforts by companies to develop Al systems have been likened to the Manhattan Project in the 1940s or the Space Race of the 1960s. In terms of investment size, the nearly $2B for the Manhattan Project would be $27B in today's dollars, and the $26B to put a person on the moon would be $318B today. While current Al is roughly comparable in terms of size of investment, the big difference is that the U.S. government funded those efforts while private industry backs this one, and most of the talent involved are in the Al industry. Given this relationship, we need a new innovation infrastructure. Policy changes to improve the impact of Al are likely best accomplished via collaboration between government, industry, and academia.\u00b2 As a historical precedent, we can look at the role the government played in the development of integrated circuit chips and cars. In the first half of the 20th century, car manufacturers benefited as governments built and improved roads and freeways funded by gasoline taxes, created traffic lights and travel signs, and licensed drivers. In the 1960s, the U.S. created the National Highway Traffic Safety Administration and the Environmental Protection Agency, which set societal benefiting standards on car safety and emissions for the whole industry that might have been difficult for individual car manufacturers to do on their own. More recently, the government has funded academic research to improve cars. Examples are DARPA's self-driving challenge (won by academic researchers), automotive safety, and fuel efficiency. We envision a coordinated public-private partnership for Al. Its goal would be to remove bureaucratic roadblocks (e.g., to sharing data), ensure safety, and provide transparency and education to policymakers and the public. In addition to learning from historical precedents for the development of Al systems, we should also learn from the history of how transformative technologies have been deployed. One lesson learned from the rollouts of paradigm-shifting technologies like broadband internet, cloud, mobile devices, and social media is that their deployment was lengthier than technologists predicted, but their impact was even more widespread. Another lesson is that predictions of technological impact from people in other fields are similarly inaccurate [National Academies]: A third lesson is that it is often hard to accurately predict the unintended negative side effects until after the technologies were widely deployed, with social networking as the prime example."}, {"title": "Artificial Intelligence (AI)", "content": "Before we discuss Al's impact within each of our half-dozen fields, let's review how we got here. The term Artificial Intelligence (AI) was coined to define the science and engineering of making intelligent machines in 1956, only five years after the first commercial computer.\u00b3\nOne strand of Al that became popular over the next decades was to create a set of rules of the form \"if this happens do that, if that happens do this.\u201d The belief was that with sufficiently accurate and large sets of rules, intelligence would emerge. Within the big tent of Al, a contrarian strand did not accept that humans would ever be able to write such a set of rules. They believed that the only hope was to learn the rules from the data. That is, it was much harder to program a computer to be clever than it was to program a computer to learn to be clever. Just three years after Al was defined, they christened this bottom-up approach machine learning (ML).\nOne branch of the ML community believed the only hope for creating a program that could learn from data would be to imitate our one clear example of intelligence: the human brain. Our brains consist of 100 billion neurons with 100 trillion connections between them. This version of ML is based on a very simple model of a neuron, so this form of ML (that is also within the big tent of Al) is called a neural network. A typical neural network might use 100 million artificial neurons. Because current versions of neural networks have many more layers of artificial neurons than in the past, recent incarnations are also called deep neural networks or deep learning.\nNeural networks have two phases, training and serving (also called inference). Training is analogous to being educated in college and serving is like working after graduation. Training a neural network involves repeatedly showing it labeled data (e.g., images identified as cats or dogs) with the system adjusting its artificial neurons until it gives sufficiently accurate answers to questions about that data (e.g., is it a cat or a dog). Once trained, the goal is that the model should work well with data it has not yet seen (e.g., correctly determining if an image is of a cat or a dog).\nAfter decades of debates about which Al philosophy was best, in 2012 neural networks started to soundly beat the competition. The breakthrough 12 years ago wasn't so much the invention of new neural network algorithms as it was that Moore's Law led to machines that were 10,000 times faster and we could network many together to work in concert. That enabled training using 10,000 times more labeled data available from the World Wide Web. Virtually all news stories today concerning Al breakthroughs are, more precisely, about neural networks.\nThe excitement about Al spiked by ChatGPT in 2022 is about models with billions of neurons that take"}, {"title": "Artificial General Intelligence (AGI)", "content": "Before we can get to the impact of near term Al, we first need to consider the prospect of artificial general intelligence (AGI). An Al system can easily write a new bedtime story daily featuring your children as main characters. A different Al system could beat any human being at the classic strategy game of Go. As of now, no single Al system can do both of these things.\nEach can deliver amazing capabilities, but they are practically useless if they stray outside their lanes. In contrast to existing Al, proponents argue that an AGI that would be multitalented\u2014capable enough to win strategy games, diagnose diseases, analyze poetry, and contribute to applied computer science innovations that can further enhance the capacity of AGI systems.\nAGI has many definitions, but one framework gaining popularity emphasizes the range of tasks that an Al system reaches a target threshold compared to people and how well it compares to human-level performance for a given task [Morris et al.]. Thresholds are labeled based on the portion of people that the system outperforms: competent (>50%), expert (>90%), virtuoso (>99%), and superhuman (>100%).\nAlphaGo is rated superhuman, but only for playing Go, and is not competent at anything else. This breadth versus depth metric helps clarify AGI discussions.\nTremendous attention is being paid to AGI, deservedly so given its large potential positive and negative impact on the world. We applaud the serious investigations of AGI, including scientific work that aims to clarify relevant definitions and likely impacts. As we focus on impacts of current and near-term Al systems, we will not discuss AGI further, beyond mentioning that progress on the topic may accelerate both the benefits and risks we outline here.\nThe next part of the paper delves into the impact of Al systems in the half dozen fields we investigated."}, {"title": "II. Demystifying the Potential Impact of AI", "content": null}, {"title": "Employment", "content": "Our first topic for nearer-term Al is a major concern: the impact on jobs [National Academies]. Indeed, a Global Public Opinion Poll on Al found that the majority expect to be replaced at work by an Al system in the coming decade [Loewen et al.].\nTechnological advancements have long led to the decline of some jobs and the creation of new ones. For the U.S. workforce, 63% had jobs in 2018 that did not exist in 1940 [Autor 2022].\nDespite the downside of job disruption, a healthy economy relies on improving worker productivity. Two-thirds of the world's population lives in countries with below-replacement birth levels [Eberstadt] and many nations are facing labor shortages [Duarte]. The U.S. already lacks critical positions as varied as K-12 teachers, passenger airline pilots, physicians, registered nurses, software engineers, and school bus drivers. To supply needed services, high-income countries must either greatly expand their working population or significantly improve worker productivity [Manyika and Spence].\nThe impact of productivity gains on jobs depends on whether the demand for goods produced by that work is elastic or inelastic. If demand is inelastic, productivity gains means jobs will be lost [Bessen]. For example, agriculture is inelastic in the U.S., so gains meant dramatic declines in absolute numbers (fourfold) and its portion of the workforce (from 40% in 1900 to 20% in 1940, 4% in 1970, and 2% today) [Daly]. If product demand is sufficiently elastic, productivity-enhancing technology will increase industry employment [Bessen].\nFor example, programmers today are tremendously more productive than they were in 1970\u2014they have more powerful programming languages and tools, plus Moore's Law helped improve hardware a millionfold\u2014yet there were 11 times more programmers in 2020. Jet engines and autopilot systems boosted pilot productivity, and even so the U.S. has eight times more commercial airline pilots today than in 1970.\nAnother perspective on employment is the split between nonphysical tasks and physical tasks. In our view, the main impact of near-term Al systems will be on nonphysical tasks. We think robots will eventually have a large effect on the way in which physical tasks are performed in the world beyond manufacturing, but this may be five or more years behind the use of Al systems for purely digital or knowledge tasks [National Academies]. We don't focus on robotics in this paper, but there has been significant progress over the past decade on robots being able to learn to"}, {"title": "Education", "content": "The next topic is education, where productivity increases and greater equity have long been computing targets. Al systems are affecting classrooms, as 30% of U.S. K-12 teachers and 40% of their students already have used it [Manyika 2024]. Some predict a significant impact from Al on all levels of education [National Academies].\nFrom an employment perspective, we believe that education is elastic, as there is a huge demand for improving the effectiveness and efficiency of learning. Indeed, the U.S. and many other high-income nations face a shortage of K-12 teachers, as well as STEM graduates who could teach those topics in K-12 schools. \u00b9\u00b2\nToday's Al tutors such as CK-12 and Khanmigo likely already help some students. A major educational challenge in the U.S. is that K-12 students in high-poverty schools do much worse on standardized tests compared to students in other countries or to U.S. students from low-poverty schools. Selective use of Al tools might track socioeconomic status, which inadvertently could expand the educational gap between students at high-poverty schools versus low-poverty schools.\nBefore many schools will deploy Al tools for all their students, they likely first need careful evaluation including randomized control trials (RCTs) to establish in what circumstances they help or hurt and, if so, by how much. At least in the U.S., it will be difficult to get access to a sufficient number of K-12 students with the desired heterogeneity, their results on exams, and details of their backgrounds, schools, and teachers to assess Al tools properly. A separate challenge would be to convince parents and teachers that their students should be the subject of educational experiments where potentially valuable opportunities would be unavailable to other control groups. Another obstacle to deploying Al tools in K-12 schools in the U.S. is that there are many people beyond the teachers involved in the decision about what tools to use: administrators, school boards, parents, students, and so on. It may be hard to collect the scientific evidence to justify requiring their use, at least in the U.S.13\nColleges may offer an easier initial target for assessing the benefits of Al systems in education, as the content is more up to the instructor and their courses are much larger\u00b94. If we can first demonstrate the success of educational innovation via Al systems for freshman at community and four year colleges\u00b95, it may also simplify the task of deploying it in high schools16. Additionally, community colleges play a major role in adult education, including retraining [Schwartz and Lipson]. If Al systems could improve education for retraining, it might partially compensate for the downside of job disruption from Al deployment in inelastic fields."}, {"title": "Healthcare", "content": "The next topic is healthcare, responsible for 16% of the U.S. GDP [Vankar]. Like education, many believe that society should offer high-quality healthcare regardless of the wealth of individuals [Einav and Finkelstein].\nWe believe that healthcare is also elastic: demand for healthcare will increase more than proportionately as the cost and quality of provided healthcare improves [Baumol]. Indeed, the U.S. and many other countries are facing a shortage of healthcare professionals. Beyond improving the employment prospects of healthcare workers via productivity gains, these tools must also keep healthcare professionals in the decision path for actual recommendations for patient therapy, as Al systems are not guaranteed to make the best recommendation 100% of the time. Since people and Al systems tend to make different mistakes, the collaboration of experts with Al systems might help the quality of healthcare.\nHealthcare decisions are made with life-or-death stakes on short timeframes based on complex data, requiring years of specialized training for the best human clinicians. But even then, human specialists have limitations: they are experts in only narrow subdomains; informed by firsthand experience with only tens of thousands of patients; bound by the biases and imperfections of past medical knowledge; available only to the best-resourced healthcare systems; and unable to extract every pattern from the vast sea of medical data.\nThere are billions of genetic variants, terabytes of medical images, years of lab results, and nontraditional clinical data sources like smartwatch readings, nutritional logs, and environmental risk factors-the complexity of this information inherently exceeds human understanding. Perhaps this is why about 15% of all diagnoses in the U.S. are incorrect [Graber] and why most Americans will be misdiagnosed at least once in their lifetimes. Such errors contribute to ~10% of all U.S. deaths [Ball, Miller, Balogh].\nAl has the potential to reduce misdiagnosis rates and evaluate patients more accurately, but Al must first earn clinicians' trust. One way is to first deploy Al in healthcare domains with lower stakes than direct patient diagnosis, such as automating insurance paperwork or transcribing physician notes.\nMoreover, Al models can be deployed far more widely than highly trained specialists can: smartphones could put high-quality health expertise in the palm of every healthcare professional. We envision a world where all relevant health-related data and every past healthcare decision can be used to inform every future healthcare decision and benefit everyone.\nWe are currently far from that world, in part because healthcare professionals are the gatekeepers for deploying Al. Al practitioners should be humble about the enormous challenges that must be overcome to provide advanced tools, especially given unrealistic past claims that Al will soon obviate clinicians. Some of these challenges involve open research questions that arise in the deployment of real-world systems, around equity, usability, robustness, and interpretability, among others."}, {"title": "Information / News / Social Networking", "content": "While education and healthcare offer targets that could potentially increase the upsides of Al, the goal of this section is to reduce risks associated with one of the widely feared downsides of Al. In most of the scenarios discussed so far, Al systems act to provide information, such as personalized tutoring in education or helpful diagnostic information in medicine. However, Al may accidentally generate incorrect information (misinformation), or be used to maliciously generate incorrect information (disinformation) such as in the case of false news presented as fact (especially an issue in political election tampering), or generated visual imagery or spoken audio presented as real.\nA related concern is built-in harmful bias affecting critical decisions like criminal sentencing or mortgage lending. As Al systems become more independent in their interactions with humans and other Al systems, the potential benefits but also the risks posed by misinformation, disinformation, and bias grow, and whether an Al system can be trusted to engage in action aligned with the interests of users (or society) becomes even more important.\nTo achieve the potential of Al, we must build ways to maximize the benefits of Al-provided information but mitigate the effects of misinformation, disinformation, and bias. While the threats of disinformation to personal well-being and international security are clear, the threat of partial misinformation or bias is more nuanced: Al systems are imperfect, yet people expect their tools to be reliable.\nAs a result, people tend to overtrust Al systems not only in cases when it is purely wrong (e.g., recommending an unsafe drug dosage) but also only partially correct (e.g., radiology support that finds some tumors but not all) or biased (e.g., favoring some job candidates over others on the basis of protected characteristics). Market forces may add further gray zones with respect to bias if, for example, information providers allow sponsors to pay in exchange for Al-generated answers that favor certain products or viewpoints. (We further discuss ways of mitigating bias in the Governance section below.)\nSimilar problems will arise as Al systems begin to behave more independently, engaging in transactions or other interactions on behalf of users, with Al systems potentially overtrusting other Al systems. Successful ecosystems of Al systems and human agents will require the ability to assess whether the Al systems have behaved in a trustworthy manner, used relevant information effectively, and managed to navigate through misinformation.\nSolutions to overcoming Al misinformation, disinformation, and bias challenges will require not"}, {"title": "Media / Entertainment", "content": "Unlike education and healthcare, many areas of entertainment are inelastic [Pannell]. It is not obvious that if Al improved the productivity of fine artists and graphic designers that the market would grow to accommodate many more paintings and designs. And there is no shortage of fiction novelists; publishers have inboxes full of unsolicited manuscripts. Even a successful author like Stephen King had to adopt a pen name because his publishers feared he would write more books than his market would bear. 30\nJournalism is very different from writing fiction. Journalists must write to a tight deadline while simultaneously being under tremendous pressure to not make mistakes in their reporting. While there are some tedious news chores that are better left to Al systems-turning quarterly financial reports from companies into text or reporting on high school sports-investigative journalism and many other tasks are not low-hanging fruit for AI. CNET secretly (and now famously) tried using Al to write dozens of feature stories, but then had to write long correction notices about \u201cvery dumb errors.\u201d\nWe should develop Al methods specifically for fact-checking to enable a journalist Al tool that reliably and quickly copyedits reporters' stories, including checking for spelling of names and places. Given the importance of journalism in a democracy despite its current precarious economic state, Al tools that reduce the stress and burnout of journalists are likely a significant contribution to civil discourse.\nThe impact of Al systems on the movie industry is much harder to predict. The special effects using toy models and stop-action films before the 1980s have been replaced by computer-generated images, which surely employ many more people even if the skill sets are very different.31\nNeal Stephenson gives the analogy about the impact of Al systems on entertainment by trying to explain the impact of movies to stage actors in 1900. Back then they memorized plays, performed every night in front of a live audience with other actors, and needed to project their voices to reach the back of the theaters. Imagine if these actors were told that the future includes:\n\u2022 individual performances in a warehouse\n\u2022 no live audience\n\u2022 no need to project their voices\n\u2022 sometimes no other actors\n\u2022 A single performance recorded and repeated in thousands of theaters for months.\nThey would probably fear for their future and for the future of acting as a profession. Instead, live theater is still healthy on Broadway and the West End alongside cinema because audiences get different experiences from these varied performances.\nToday's image and video tools allow amazing control over every pixel on the screen, but they are infamous in their difficulty to use given the need to set hundreds of virtual knobs. If the tools themselves make it much easier for the director to keep control of the thousands of microdecisions need to create art"}, {"title": "Governance / National Security / Open Source", "content": "As Al systems permeate workplaces and daily life, policymakers and the public will face a range of choices-some relatively familiar and others opening up cans of worms of potential policy and regulatory challenges. Like aviation, television, and the internet before it, Al promises both bountiful rewards and potential perils. Yet its nature as a rapidly evolving, general-purpose technology that can be used to outsource human decision-making sets it apart. As people come to use Al systems more often in their workplaces and daily lives, policymakers are confronted with decisions not only about whether or how to design new policies for particular Al systems or uses, but also how to interpret existing laws that already govern what people do.\nExisting laws already govern many Al applications. Tort law, for instance, holds entities liable for unreasonable risks when deploying Al systems in services like accounting. Sector-specific regulations, such as FDA oversight of Al-enabled medical devices or provisions of international humanitarian law governing certain military decisions, remain applicable. The challenge lies in interpreting these laws for novel Al use cases, an endeavor that will often demand fact-specific judgments and greater knowledge from policymakers about the technical attributes of Al systems.\nAnother challenge is to address certain limited gaps in existing law with carefully targeted policies taking into account the unique capabilities and benefits of advanced Al systems, and deploying approaches that recognize how quickly the technology is changing. Safety and security testing for Al models-including appropriate backups and fail-safes-for managing critical infrastructure, such as power grids or air traffic control, is crucial.\nCountries need strategies to determine how the most advanced Al models enable adversaries to engage in cyberattacks or to design specialized weapons, and to reduce those risks. Nations vying for Al supremacy must balance cooperation between government and private companies with antitrust concerns.\nThe debate over whether to open-source Al models exemplifies the nuanced approach required. While sharing model weights and technical details can spur innovation, it may also aid adversaries. The devil is in the details: legal terms of sharing, built-in safeguards, and the extent of disclosed information all factor into the equation. Accordingly, policies designed to limit the risks of open-weight model releases must be carefully designed to retain as much as possible the benefits of openness while limiting the ease with which openly available models can be reconfigured for malign use [Bateman et al.].\nTo address the issues above, policymakers should consider seven key principles:\n1. Balance benefits and risks: Focusing solely on perils can stymie beneficial outcomes and innovation [Ng]. Autonomous vehicles, for example, may drive exceedingly cautiously and slowly in extreme driving conditions but could prove safer and more convenient in normal circumstances. Increasingly capable Al systems can behave in unexpected ways-particularly vast numbers of Al \"agents\" interacting with other Al systems on behalf of their users-and facilitate some malicious activities. But it can be as big a mistake to ignore the benefits as it is to ignore the risks. We must also bear in mind the difficulties inherent in governing fast-evolving technologies rather than their specific applications, and be wary of false dichotomies [Ng]. For example, by gradually but steadily expanding the range of"}, {"title": "Science", "content": "The poster child for Al in science is protein folding.\nRemarkably, the scientists involved received the Nobel Prize just six years after the first version of AlphaFold was released. It addressed a 50-year-old puzzle: how to predict protein structures from their amino acid sequences. Michael Levitt, who received the Nobel Prize in a related field, said AlphaFold advanced the field by 10 to 20 years. More than 2 million scientists in 190 countries have used it. The Nobel committee assesses the impact as follows:\n\u201cAmong a myriad of scientific applications, researchers can now better understand antibiotic resistance and create images of enzymes that can decompose plastic.\"\nNobelist John Jumper told us one of the enabling artifacts was the Protein Data Bank (PDB). Started in 1971, this peer-reviewed repository holds information about the 3D structures of proteins, nucleic acids, and complex assemblies. It holds 200,000 examples and is one of the best databases in biology, which made it an attractive target for Al systems. More curated datasets would create more opportunities for scientific advancement via Al systems, as progress can be limited by the availability of high-quality data. In many science fields\u2014chemistry, materials science, biology-researchers are now using \u201cself-driving labs\" that combine robotics and Al systems to reduce the time to make a new scientific discovery.\nIt was only a dozen years ago that neural networks started outcompeting Al alternatives. It is hard to overestimate the current excitement about the promise of Al within the broader scientific community [Hassabis and Manyika]. Here are more examples:\n\u2022 Black hole visualization. A partnership between Al systems and astrophysicists reveals events that are otherwise unseen. A Caltech research group used generative Al to make 3D videos of black hole M87*\u2014famously the first black hole to appear in an image-and of the flares that occur around the black hole at the center of our galaxy [Lin et al.] [Levis et al.].\n\u2022 Flood forecasting. Researchers were able to develop an Al model that achieves reliability in predicting extreme river-related events in ungauged watersheds at up to a five-day lead time [Nearing et al.] with reliability matching or exceeding those of instantaneous predictions (zero-day lead time). It now covers hundreds of millions of people in over 80 countries.\n\u2022 Materials discovery. The Graph Networks for Materials Exploration (GNOME) generates novel candidate crystals and predicts their stability [Merchant et al.]. GNOME successfully discovered 2.2 million new crystals of which 380,000 are the most stable, making them candidates for synthesis. Microsoft's MatterGen is another example that focuses on creating synthesizable materials with specific desired properties, such as chemical, symmetry, or electronic/magnetic characteristics [Zeni et al.]."}, {"title": "III. Harnessing AI for the Public Good", "content": "We proposed 18 Al milestones above where Al systems could benefit society. We next address how best to inspire and fund such Al research that enhances the public good. We recommend public and private interests pursue two paths to help researchers and practitioners reach these milestones. The first is to create prizes each worth $1M+ to incentivize reaching milestones that significantly advance the positive impact of Al. Rather than recognize past achievements, inducement prizes try to stimulate research on focused targets. They can work well in many fields [Eisenstadt et al.] We plan to have inducement prizes for every milestone in this paper."}, {"title": "Conclusion", "content": "Several reports surveyed the state of the art of Al and considered the potential rewards and risks of Al [Bommasani et al.] [Brynjolfsson et al.] [Horvitz et al.] [Littman et al.] [Manyika 2022] [Reuel et al.]. Like some of these papers, rather than predict what the societal impact of Al systems will be assuming a laissez-faire approach, we envision what the impact could be given directed efforts in research and policy on using Al systems for good. We also propose 18 targets to show how to deliver on those efforts while thinking carefully about dissemination strategy and, as we shall see, funding.\nWhile there are risks, there are also many known and unknown opportunities. It can be as big a mistake to ignore potential gains as it is to ignore risks. For example, some estimate that Al could plausibly raise the rate of growth in the U.S. gross domestic product from 1.4% currently to 3% [National Academies]. Doubling the growth rate could lead to \"poverty reduction, better health care, improved environment, stronger national defense, and reduced budget deficit.\"\nAl moves quickly, and governments must keep pace-or even better, ahead of developments. Decisions made today will shape the Al landscape of tomorrow, influencing everything from economic competitiveness to social stability. In the dawn of practical Al, thoughtful governance is not just desirable-it is essential.\nSimilar to how the government collaborated with industry in the successful development and deployment of cars and chips (see History), we"}, {"title": "Appendix I: Energy Usage of AI", "content": "Electricity use is a portion of the global carbon footprint, alongside carbon fuel use by automobiles and planes, agriculture emissions, deforestation, and manufacturing goods. There are carbon dioxide equivalent emissions (CO2e) from manufacturing Al hardware and operating Al hardware, respectively called embodied CO2e and operational CO2e. We focus on operational CO2e as it is by far the largest piece. \u00b3\u2079\nAccording to the International Energy Agency (IEA), data centers today use 1% of global electricity consumption, half of household digital electric appliances such as TVs, laptops, and cell phones [IEA].\nMoreover, Al systems use a small portion of all data center electricity.\u2074\u2070 Al's share at Google was <15% each year from 2019 to 2021 [Patterson et al. 2022], which would put Al's share of global electricity consumption at <0.15%. That would mean digital home appliances consume more than 10 times as much electricity as Al does in data centers.\u2074\u00b9\nAl relies on custom hardware that is five or more times as energy efficient for Al than conventional hardware. Hence, Al can be \u226580% of the data center computation but use \u226415% of its energy [Patterson et al. 2022]. If Al instead used standard computers, 80% of the computation would likely need more than half of the data center energy.\nBesides data centers, smartphones also run Al. Smartphone electricity use is dominated by the display, wireless radio, and chargers, so Al uses <3% of smartphone electricity [Patterson et al. 2024].\nThe excitement about the potential of LLMs has inspired hyperscalers to make plans to expand their data centers at a time when many competing demands strain the present capacity of electric utilities. Several hyperscalers have announced goals of net zero emissions by 2030 to 2035, so they are investigating generating their own carbon-free energy, including nuclear energy, to be able to expand their data centers.\nData center growth is hard to predict accurately, but even if data center growth is strong, the IEA observes:\n\"However, when considered in a broader context of total electricity consumption growth globally, the contribution of data centres is modest. ... continued economic growth, electric vehicles, air conditioners and the rising importance of electricity-intensive manufacturing are all bigger drivers.\u201d \u2074\u00b2 [IEA]"}, {"title": "Appendix II: The Rapid Upskilling Prize", "content": "Above we give one-paragraph sketches of what the proposed 18 milestones are without much detail on what it would take to win the inducement prize. To flesh out what a prize might look like, this appendix gives an example of the details for one: the Rapid Upskilling milestone from the Employment Section. The prize is $1M. Using the U.S. as a specific example, the goal is for full-time workers who earned <$30k per year to take a three- to six-month course that raises their income by \u2265$15k per year after completing the course. (The U.S. federal poverty level for a family of four was $30,000 in 2023. The $30K and $15K targets might have to change elsewhere.)\nHere are the requirements to win the prize:\n\u2022 \u226550% of people who take the training complete the training (to be inclusive).\n\u2022 \u226550% of people who complete the training increase their income for the subsequent year \u2265$15k (to avoid cherry-picking).\n\u2022 The program has at least 100 successful trainees (to demonstrate initial success).\n\u2022 There must be vetted documentation of the trainees (e.g., pay stubs and W-2 forms in the U.S.) before and after the program (to ensure validity of claims).\n\u2022 The program must document the potential scalability of the training system to hundreds of thousands or millions of people, and what the scaling would cost (to be able to address the size of the real problem).\n\u2022 Prize submissions will be accepted on May 15 each year until the prize is awarded (to have sufficient time to collect prior evidence).\nThe judges may decide to offer an Honorable Mention Award of $100K to programs which, in their view, come close to the ultimate goal but do not yet fulfill all requirements of the Rapid Upscaling Prize."}]}