{"title": "MultiFloodSynth: Multi-Annotated Flood Synthetic Dataset Generation", "authors": ["YoonJe Kang", "Yonghoon Jung", "Wonseop Shin", "Bumsoo Kim", "Sanghyun Seo"], "abstract": "In this paper, we present synthetic data generation framework for flood hazard detection system. For high fidelity and quality, we characterize several real-world properties into virtual world and simulate the flood situation by controlling them. For the sake of efficiency, recent generative models in image-to-3D and urban city synthesis are leveraged to easily composite flood environments so that we avoid data bias due to the hand-crafted manner. Based on our framework, we build the flood synthetic dataset with 5 levels, dubbed MultiFloodSynth which contains rich annotation types like normal map, segmentation, 3D bounding box for a variety of downstream task. In experiments, our dataset demonstrate the enhanced performance of flood hazard detection with on-par realism compared with real dataset.", "sections": [{"title": "Introduction", "content": "Deep learning algorithm requires high quality, diverse and large training dataset. However, gathering good dataset is labor-intensive and requires substantial cost, especially on hyper-scale situations like wildfire recognition (Hong et al. 2024), pine wilt disease detection (Jung et al. 2024) and so on. To mitigate this issue, a common solution today is to generate synthetic data and use them as training or refer-ence dataset (Kim et al. 2024). Recently, generative models (Hamza et al. 2024; Islam et al. 2024; Khullar et al. 2023) or real-time engine (Delussu, Putzu, and Fumera 2024) are leveraged for more plausible and efficient generation.\nHowever, there is a still concern that editability is insuf-ficient (that is few control parameter) to composite the fi-nal scene. Existing dataset has ambiguous label and one or two types of annotation. Furthermore, from the fact that syn-thetic dataset should reflect the real-world data, some do-mains have a significant difficulty due to the absence of high quality real data for reference, definition of label and in-consistent annotation problem. One of them is flood haz-ard situation which makes it difficult to collect the dataset. It stems from their specific situation where flood accidents frequently paralyze the digital system and physically col-lapse the surveillance device. Despite of this reason, existing works had explored to make real flood dataset with hand-crafted labeling (Wan et al. 2024; Wu et al. 2024b; Gao et al. 2024). They inevitably confront label-inconsistent problem like 2D bounding box. In addition, they only consider one or two types of annotation as ground truth, hindering their applicability to various computer vision tasks.\nIn this paper, we present a novel framework that uti-lizes a 3D engine to generate urban flood synthetic dataset, dubbed MultiFloodSynth. For fidelity, we faithfully attribute the flood hazard situation as several properties and compo-nents (e.g., layout (Shang et al. 2024), lighting, flood-level (Chaudhary et al. 2020; Wan et al. 2024), 3D object, cam-era view) for scene composition by exploring urban flood situation. Moreover, considering various computer vision tasks, our system includes a variety of annotation types such as normal map, instance/semantic/fine-grained segmentation map, camera 3D pos, 2D/3D bounding box, etc. Thanks to such editable attributes, our MultiFloodSynth improved the performance of object-localized flood level detection, while alleviating large dataset requirements for model training."}, {"title": "Related Works", "content": "Recently, generating non-real dataset, synthetic dataset is common technique in a variety of field which requires hyper-scale (Shang et al. 2024; Greff et al. 2022; Zhang et al. 2024; Xie et al. 2024; Wu et al. 2024a; Schieber et al. 2024; Shang et al. 2024; Wang et al. 2024b; Hao et al. 2024; Zhu et al. 2024; Valvano et al. 2024), impossible scenarios (Jung et al. 2024; Greff et al. 2022; Hummel and van Kooten 2019; Mit-tal et al. 2023; Kokosza et al. 2024; Amador Herrera et al. 2024), and so on. Synthetic dataset generation resolve such issues by constructing scene in virtual world and alleviate vexing manual process with auto labeling. Diverging from conventional way to generate synthetic data, it has been ex-plored to reflect the characteristics of real-world object to enhance the high fidelity and appropriateness (Richter, Al-Haija, and Koltun 2022; Lee, Shin, and Lee 2024; Ebadi et al. 2022). Since these strategy enhance the robustness and realism, it is crucial to consider these attributes for faithful synthesized data."}, {"title": "Flood Hazard Detection", "content": "Detecting flood situation can be considered as object de-tection using the level of flood of object. A multitude of studies on classifying and detecting objects based on deep learning algorithms has been continuously conducted to ad-dress abovementioned requirement (Lo et al. 2021; Pally and Samadi 2022; Karanjit, Pally, and Samadi 2023; Zhong et al. 2024; Wu et al. 2024b). However, most studies face chal-lenges such as a lack of data sharing, ethical concerns, ab-sence of abundance and limited labels. To do that, in this paper, we intent to address these issues in following section."}, {"title": "Proposed Method", "content": "Main objective is to synthesize urban-scale flood hazard situation in virtual scene and enhance the performance of flood-level detection system with our MultiFloodSynth by alleviating a problem of dataset collection. To commence, we describe the real-world flood hazard situation with some considerations and how our MultiFloodSynth promise the fi-delity. Overall pipeline is shown in Fig. 1."}, {"title": "Challenges of Real-World Flood Hazard Scenarios", "content": "Existing real-world dataset (Gao et al. 2024) was obtained on vehicle-based flood detection. This dataset includes label information divided into five levels based on the percentage of a vehicle submerged in water (Wan et al. 2024). Fig. 2 shows some samples of the data included in the real-world dataset. However, they have inconsistent problem with inco-herent bounding box by human-hand. Meanwhile, to simu-late the flood situation, it should be considered to appropri-ately composite several components including camera view, lighting condition and flood-level (i.e., flood height)."}, {"title": "Depicting Flood Scenarios in Virtual Simulator", "content": "In contrast to existing synthetic generation works, our framework is capable of controlling some parameters to composite final virtual scene as discussed in former subsec-tion. It allows the user to control the scene for user-wanted structure. Based on our exploration with several real-world data (Zhong et al. 2024; Gao et al. 2024; Wu et al. 2024b), we observed that following settings play a crucial role to de-termine the virtual scene: urban setting, flood settings which heavily affects to semantic feature in neural network. De-tailed parameters are listed in Table 1.\nFurthermore, since it is quite cumbersome to search sev-eral 3d objects for scene composition, we adopt image-to-3d model (Wu et al. 2024a) to generate 3D objects by inputting web-crawled car image. To avoid quality degradation and blurry texture, image-to-3d is used than text-to-3d (Lin et al. 2023). In the case of layout and building, we utilize 3D city generation (Xie et al. 2024) results for base layout."}, {"title": "Simulating Flood Wave", "content": "In flood hazard situation, flood simulating is pretty im-portant factor which determine the flood level (Wan et al. 2024) and annotation-level. Some attributes (e.g., reflection, roughness, opacity, specular, texture) of flood object will di-rectly affect to extract training feature by neural network. In this regards, we also simulate flood dynamics and visual ap-pearance as shown in Fig. 3. Three factors, main wave, wave foam, gravity, decide the visual magnitude of level-of-wave as dynamics. Other factors (e.g., wave size, depth, height) change the appearance of flood as static component."}, {"title": "MultiFloodSynth Generation", "content": "For flood synthetic generation, we construct flood environ-ments based on each objects by varying some parameters (Tab. 1) for diverse data distribution. Flood level is attributed into 5 level as multi-classes. To enhance the quality and do-main similarity, we adopt domain randomization (Rawal, Sompura, and Hintze 2023) in all the objects (e.g., light, camera view, object position, etc). Each object is randomly located in every generation pipeline to avoid bias and spar-sity of dataset and to include some crucial corner cases. As a result, our MultiFloodSynth consists of a total of 70,117 images, with 14,593 non-flooded images and 55,524 flooded images. Samples are illustrated in Fig. 4. Total image and instance for each class is listed in Tab. 3. For multi-type of annotations, we extract 9 types (i.e., semantic/instance/fine-grained segmentation, 2D/3D bounding box) of paired syn-thetic scene as shown in Fig. 5. For segmentation map, we allocate the label into car and flood. Differences between competing flood datasets are listed in Tab. 2."}, {"title": "Experiments", "content": "For detection model, we choose YOLOv10(Wang et al. 2024a). For training hyperparameters, we set batch size as 256, learning rate as 0.001 with 100 epochs. Image-to-3D model is used with Unique3D (Wu et al. 2024a). Our virtual environment is based on NVIDIA Omniverse simulator."}, {"title": "Comparison on Detection Performance", "content": "To evaluate the superiority of our MultiFloodSynth, we com-pare the flood detection performance by varying the train-ing dataset. Based on (Wan et al. 2024), we denotes previ-ous real dataset as $D_{real}$ and our dataset as $D_{synth}$. Then, we train the model with different training configuration as: (1) $D_{real}$, (2), $D_{synth}$, (3) $D_{real} + D_{synth}$. For evaluation metric, we include precision, recall, mAP at 50 and 50-95. In eval-uation, we train two size models, YOLOv10-N (small size) and YOLOv10-B (large size).\nThe results are shown in Tab. 4. It show that the real-world data training outperformed the synthetic data train-ing. However, training mixing two dataset ($D_{real} + D_{synth}$) demonstrated improved performance. To conclude, our Mul-tiFloodSynth boost the detection performance in flood haz-ard recognition task with consistent annotation while also alleviating the cost of burden data collection process."}, {"title": "Evaluation of MultiFloodSynth", "content": "Furthermore, we intend to evaluate our MultiFloodSynth in the perspective of realism compared with real dataset. To do that, we borrow the recent synthetic dataset evaluation met-ric, Realistic Score which is proposed in urban world gener-ation in (Shang et al. 2024). By randomly selecting 1K sam-ples in each dataset, we average the score. We normalized the scores of $D_{synth}$ based on the scores of the real dataset. As shown in Tab. 5, our dataset showed 93.17% plausibility which is similar level of realism compared with real dataset."}, {"title": "Explanation of Flood Detection Model", "content": "For explainability of detection, we adopt recent XAI method, EigenCAM(Muhammad and Yeasin 2020) which can analyze some specific parts of an input image that play a crucial role in the model decision. As shown in Fig. 6, our MultiFloodSynth played a crucial role in training and thus enables model to recognize important evidence from images."}, {"title": "Conclusions", "content": "In this paper, we have presented synthetic dataset genera-tion pipeline for urban flood detection into 5 levels and eval-uated the utility of our MultiFloodSynth. For faithful syn-thetic dataset, we charactersize several parameters including not only environmental settings, e.g., lighting color, camera position, but also flood simulation factors, e.g., roughness, texture, opacity, etc. To mitigate the data bias and domain gap, we adopt domain randomization and vary the above parameters in each generation pipeline. Moreover, for the sake of efficiency of pipeline, we leverage the recent gen-eration techniques, image-to-3D generation and urban city generation, for 3D object and base layout of virtual flood world, respectively. Experimental results demonstrated that the model trained with our synthetic dataset and real-world dataset show enhanced detection performance in object-localization based flood-level recognition. In addition, our MultiFloodSynth showed on-par realism compared with real dataset in terms of Realistic Score metric. To conclude, our MultiFloodSynth generated from our parameter-controllable flood environment can serve as a valuable training dataset, alternating data requirements of real-world dataset."}]}