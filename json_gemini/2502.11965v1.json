{"title": "A MIMO Wireless Channel Foundation Model via CIR-CSI Consistency", "authors": ["Jun Jiang", "Wenjun Yu", "Yunfan Li", "Yuan Gao", "Shugong Xu"], "abstract": "In the field of artificial intelligence, self-supervised learning has demonstrated superior generalization capabilities by leveraging large-scale unlabeled datasets for pretraining, which is especially critical for wireless communication models to adapt to a variety of scenarios. This paper innovatively treats Channel State Information (CSI) and Channel Impulse Response (CIR) as naturally aligned multi-modal data and proposes the first MIMO wireless channel foundation model, named CSI-CLIP. By effectively capturing the joint representations of both CIR and CSI, CSI-CLIP exhibits remarkable adaptability across scenarios and robust feature extraction capabilities. Experimental results show that in positioning task, CSI-CLIP reduces the mean error distance by 22%; in beam management task, it increases accuracy by 1% compared to traditional supervised methods, as well as in the channel identification task. These improvements not only highlight the potential and value of CSI-CLIP in integrating sensing and communication but also demonstrate its significant advantages over existing techniques. Moreover, viewing CSI and CIR as multi-modal pairs and contrastive learning for wireless channel foundation model open up new research directions in the domain of MIMO wireless communications.", "sections": [{"title": "I. INTRODUCTION", "content": "Self-supervised learning (SSL) has emerged as a potent paradigm within machine learning, establishing a significant presence in the field of artificial intelligence [1], [2]. By uncovering intrinsic structures and feature representations from unannotated datasets, SSL enables models to acquire more generalized knowledge, which is especially critical for wireless communication systems. This capability showcases remarkable flexibility in diverse application scenarios, not only achieving superior performance on specific tasks but also en-hancing system robustness and adaptability to tackle complex real-world environmental challenges. The foundation model pretrained with SSL demonstrates exceptional capability in extracting general feature representations, thereby providing substantial performance enhancements for various downstream tasks in wireless communication systems. It effectively trans-fers the general knowledge acquired to domain-specific ap-plications, including but not limited to wireless localization, beam management (BM), and channel identification.\nIn wireless communication systems, channel identification stands as a pivotal step to ensure high-quality communication. It entails the capacity to differentiate between line-of-sight (LoS) and non-LoS (NLoS) conditions, directly impacting the effectiveness of dynamic spectrum management and power control, thus ensuring optimized resource allocation and re-duced interference. Accurate channel recognition is fundamen-tal for efficient and reliable communication services.\nPositioning, as one of the core tasks in integrated sens-ing and communication (ISAC), holds obvious importance. Through precise positioning services, personalized user expe-riences such as accurate navigation or indoor location can be provided, while also offering critical data support for network optimization [3]. For instance, the high-precision position-ing, imaging, and environmental reconstruction capabilities enabled by sensing contribute to improved communication performance, including but not limited to more accurate beam-forming and faster beam failure recovery mechanisms [4].\nFurthermore, with the evolution of communication tech-nologies, especially entering the era of 5th-Generation Mobile Communication Technology (5G) and beyond to 6th, beam management has become an essential component for efficient data transmission to achieve faster data rates and overcome the challenges of high-frequency channel fading [5]. BM aims to enhance signal strength within target areas by adjusting the direction of antenna arrays to form directional beams. However, the introduction of large-scale multi-input multi-output (MIMO) systems complicates the BM process and intensifies resource demands. In configurations featuring 32 transmitting antennas paired with 8 receiving antennas, a com-plete BM operation can take approximately 160 milliseconds, with required time increasing exponentially as the number of antennas grows [6]. To address this challenge, researchers are actively exploring possibilities to optimize the BM process using Artificial Intelligence (AI) technologies, aiming to boost efficiency and reduce costs.\nIt is noteworthy that the 3rd Generation Partnership Project (3GPP) has acknowledged the immense potential of Al in the realm of wireless communications, listing it among key application directions. Document TR 38.843 [7] highlights positioning and beam management as primary scenes for AI empowerment, underscoring their strategic importance in the design of future communication architectures.\nAgainst this backdrop, we innovatively regard channel im-"}, {"title": "pulse response (CIR) and channel state information (CSI) as multimodal data, a perspective shift that introduces new research directions within MIMO wireless communications.", "content": "By incorporating contrastive learning into self-supervised pre-training methods [8], the model can concurrently capture features from both modalities, thereby providing a more gen-eralizable and efficient solution.\nIn summary, the main contributions of this paper can be summarized as follows.\n1) We introduce the first MIMO wireless channel founda-tion model, specifically designed for perception tasks, named CSI-CLIP. CSI-CLIP is capable of efficiently processing two distinct forms of data: CIR and CSI. Moreover, its design is task-agnostic, endowing it with versatile applicability across a multitude of scenarios.\n2) Furthermore, CSI-CLIP demonstrates outstanding cross-scenario adaptability and robust feature extraction capa-bilities. The model can capture and represent features within both CIR and CSI without relying on task-specific information, significantly enhancing its value as a general-purpose tool.\n3) The experimental results indicate that CSI-CLIP achieves substantial performance improvements com-pared to traditional supervised methods. In particular, in positioning tasks, there is an average performance increase of 22%, while in beam management task, the accuracy has improved by 1%, also improved in the channel identification task. These outcome not only highlight the potential and value of CSI-CLIP in practi-cal applications but also underscore its superiority over existing approaches."}, {"title": "II. RELATED WORKS", "content": "A. Foundation Model in Wireless Communication\nThe exploration of foundation models within the domain of wireless communication has recently gained significant momentum. This surge in attention is driven by the potential of foundation models to leverage self-supervised learning paradigms, such as Masked X Modeling (MXM), which facilitate seamless adaptation across various signal modalities.\nNotably, Ott et al. [9] introduced an radio foundationm model for 5G indoor positioning through the innovative use of Masked Time-step Modeling combined with Next Token Prediction. Meanwhile, LWM [10] pioneered the development of the first channel-aware foundation model using Masked Channel Modeling, specifically channel identification and Sub-6G to mmWave beam prediction on the DeepMIMO dataset [11]. Additionally, Aboulfotouh et al. [12] advanced human activity sensing and spectrum segmentation within WiFi envi-ronments by employing Masked Spectrogram Modeling.\nDespite these advancements, existing literature predomi-nantly centers on Multiple-Input Single-Output (MISO) sys-tems, overlooking the complexities associated with MIMO se-tups. A critical challenge in MIMO systems involves handling CSI characterized by pronounced periodic patterns and sparse"}, {"title": "CIR data as shown in the Fig 1. Current MXM pretraining methods may be inadequate in this context, as they tend to exploit strong correlations within unmasked data segments for straightforward signal reconstruction.", "content": "Such operations, including interpolation or repetition, remain effective even under conditions of high masking ratios, thereby impeding the acquisition of more generalized feature representations necessary for robust MIMO processing.\nB. Contrastive Learning\nContrastive learning, as a form of self-supervised learning, aims to learn data representations by minimizing the distance between positive sample pairs and maximizing the distance from negative sample pairs. This approach has achieved sig-nificant advancements in domains such as image and text pro-cessing, showcasing robust performance. Models like SimCLR [13] and MoCo [14] underscore the importance of maintaining consistency in data representation across different views. They are trained by treating different views of the same data as positive pairs and other data instances as negative pairs.\nHowever, the success of these methods largely hinges on effective data augmentation strategies. In the domain of im-ages, techniques such as random cropping and color distor-tion have proven to be effective augmentation means. For fields like wireless communications, however, implementing contrastive learning becomes more complex due to the lack of standardized data augmentation practices. Moreover, multi-modal models like CLIP [8], while not relying on traditional data augmentation, require substantial paired multimodal data, which can be challenging to obtain in practical applications.\nIn addition, TF-C [15], a pioneering method in time se-ries analysis, demonstrates that by combining temporal and frequency domain features through three contrastive learn-ing approaches (time domain, frequency domain, and time-frequency domain), the performance of downstream tasks can be significantly enhanced. Specifically, it employs a consis-tency loss to minimize the distance between time-based and frequency-based embeddings, thereby enforcing consistency in the latent space between the two domains. This strategy not only improves the feature representation capabilities of pretrained models but also provides a robust framework for time series analysis."}, {"title": "III. PROPOSED FRAMEWORK", "content": "Building on TF-C [15], CSI-CLIP proposes a novel ap-proach that views CIR and CSI as naturally aligned multi-modal data pairs. Unlike TF-C, which uses three contrastive learning mechanisms, CSI-CLIP adopts a single contrastive learning framework, similar to the CLIP model in computer vision. The original time series and its Fourier-transformed spectrogram are considered as positive sample pairs, while all other pairs serve as negative samples for contrastive learn-ing. This design is particularly well-suited for CIR and CSI in wireless communications, as both are inherently aligned in the time-frequency domain. Using multimodal contrastive learning, this approach captures features from both the time and frequency domains simultaneously, without the need for additional data augmentation, enhancing the feature represen-tation capabilities of pretrained models.\nA. Pretext Task\nThe architecture of CSI-CLIP draws inspiration from the recent advancements in contrastive learning within natural lan-guage processing and computer vision. As depicted in Fig. 2, the proposed model features a dual-pathway design, where each pathway is meticulously tailored for the processing of CIR and CSI, two modalities that, while distinct, share a close relationship within the domain of wireless communication data. The congruity of the backbone network structure across both pathways ensures that the extracted features possess a broad generalization capability while still capturing the idiosyncrasies unique to each modality."}, {"title": "During the feature extraction stage, each pathway operates autonomously, adapting its operations to the intrinsic prop-erties of its input.", "content": "For instance, CIR data are characterized by temporal information on signal propagation paths, whereas CSI encapsulates characteristics within the frequency domain. CSI-CLIP enhances its ability to uncover latent patterns within the data. The outputs from the two pathways are subsequently mapped into a shared embedding space, allowing for a unified representation of CIR and CSI.\n$z_i^c = f_c(CSI_i)$\n$z_i^e = f_e(CIR_i)$\nwhere $f_c$ and $f_e$ denote the encoder for CSI and CIR, respectively, and $z_i^c$ and $z_i^e$ represent the embeddings of CSI and CIR for the $i^{th}$ sample.\nTo ensure that the embeddings of the two modalities main-tain a meaningful relationship, a contrastive learning objective is introduced. This objective function aims to minimize the dis-tance between positive pairs (embeddings of the same sample from different modalities) and maximize the distance between negative pairs (embeddings of different samples). Specifically, the cosine similarity metric is employed to measure the align-ment of the embeddings. The learnable temperature parameter $\\tau$ controls the sharpness of the similarity distribution, allowing more nuanced control over contrast loss.\n$L= - \\frac{1}{N} \\sum_{i=1}^{N}log\\frac{exp(cos(z_i^c,z_i^e)/\\tau)}{\\sum_{j=1}^{N}exp(cos(z_i^c,z_j^e)/\\tau)}$\nHere, $N$ represents the batch size, and $cos(.,.)$ denotes the cosine similarity between two vectors. By optimizing this loss function, the model learns to produce embeddings that preserve the intrinsic relationships between CIR and CSI representations.\nB. Downstream Tasks\nIn the downstream task fine-tuning stage, transfer learning is used to leverage the rich feature representations embedded"}, {"title": "within pretrained models to boost task performance.", "content": "Specifi-cally, the pretrained CSI Encoder $f_c$ has already acquired the ability to extract general features from CSI data. These features exhibit broad applicability across a variety of CSI-based applications. By appending a task-specific head composed of two fully connected layers and subsequently fine-tuning this architecture with labeled data, the model can optimize the model for particular downstream tasks.\n1) Channel Identification: Channel Identification task can be formulated as a typical binary classification task, where the objective is to classify the input CSI into categories such as LoS and NLOS. The model is trained using the Cross-Entropy loss function as follow.\n$L = -\\sum_{c=1}^{C}y_clog(\\hat{y_c}),$\nwhere $C$ is the number of classes, $y_c$ is the indicator variable that equals one if class $c$ is the true class for the sample and zero otherwise, and $\\hat{y_c}$ is the predicted probability that the sample belongs to class $c$.\n2) Positioning: Positioning can be formulated as a regres-sion task aimed at estimating the coordinates of a user or device within a given space. The goal is to predict continuous values representing the location based on CSI.\nThe training process involves minimizing a Mean Squared Error (MSE) loss function, which quantifies the average squared difference between the predicted and actual positions.\n$\\frac{1}{N}\\sum_{i=1}^{N}\\Vert p_i - \\hat{p_i}\\Vert^2$\nwhere $p_i$ represents the true position coordinates of the $i^{th}$ sample, $\\hat{p_i}$ denotes the predicted position, and $N$ is the total number of samples.\n3) Beam Management: The goal of BM is to predict the optimal beam index $b^*$ by using the CSI of the user, denoted as $H$, and projecting it onto the steering vector $s(b)$ for each beam in the codebook. The received power for a given beam $b$ can be calculated as $P_{rx}(b) = \\Vert H. s(b) \\Vert^2$.\nConsequently, the optimal beam index $b^*$ is selected based on the maximization of the received power.\n$b^* = argmax_b P_{rx}(b)$\nThis optimization problem can be reformulated as a mul-ticlass classification task, where the objective is to classify the optimal beam index $b^*$. The model is trained using the Cross-Entropy loss function, as defined in equation 3."}, {"title": "IV. EXPERIMENT", "content": "A. Dataset\nThe CSI-CLIP model utilizes an extensive and varied dataset, which is integral to its design. This dataset encom-passes over 700,000 CSI samples, sourced from 35 distinct scenarios within the DeepMIMO dataset [11]. The diversity of these scenarios, both in terms of environment type and operating frequency, facilitates robust generalization across a multitude of wireless communication settings.\nThe dataset includes 35 different scenarios, covering a broad spectrum of indoor and outdoor environments. Operating fre-quencies range from Sub-6 GHz through mmWave up to tera-hertz, thus offering a comprehensive overview of the spectral bands relevant to contemporary wireless communications.\nTo maintain balanced representation across scenarios, a stratified sampling method is employed. Scenarios with fewer than 50,000 users are fully included, whereas for those exceed-ing this threshold, a subset is selected to preserve diversity and prevent any single scenario from disproportionately influenc-ing the dataset. This approach guarantees exposure to a wide array of conditions and user distributions, thereby enhancing the model's robustness and generalization.\nBefore being input into the model, all CSI samples are preprocessed, including min-max normalization and standard-ization, to ensure consistency and improve learning efficiency. During the fine-tuning stage for downstream tasks, 80% of the data is allocated for training, and others are reserved for validation. For BM task, 64 beams DFT codebook is used.\nTo demonstrate the generalization capability of CSI-CLIP, additional data were generated using Sionna RT [16] under identical configurations. Specifically, the etoile urban cellular communication scenario provided by Sionna was selected for this purpose. In this setup, User Equipment (UE) nodes are distributed at intervals of 1 meter within a typical single-site, three-sector layout, with the maximum distance to the Base Station (BS) not exceeding 200 meters. The BS is positioned at coordinates (0,0,30), while the UEs are located within the three sectors at a height of 1.5 meters. The carrier frequency is set to 3.5 GHz, and the maximum number of interactions between rays and scene objects is limited to 4.\nB. Implementation Details\nIn our implementation, the simulation parameters are con-figured as follows: the maximum number of propagation paths is 20; the system bandwidth is 10 MHz, and the number of subcarriers is 256. The base station employs an 8 \u00d7 8 uniform planar array (UPA), whereas user terminals feature a 2\u00d72 UPA configuration.\nThe encoder architecture is based on the ResNet50 [17] model, adapted to accommodate a two-channel input. All phases of training and testing for CSI-CLIP were executed on NVIDIA GeForce RTX 4090 GPUs. A batch size of 128 was adopted, and the training process was carried out for up to 300 epochs, with early stopping criteria applied to mitigate overfitting. An AdamW optimizer was used, with an initial learning rate of 0.0008, which is reduced by 20% every ten epochs if no improvement in minimal validation loss.\nC. Results analysis\nThe comparative analysis in Table I demonstrates CSI-CLIP's superior performance over supervised baselines in positioning and BM tasks across 35 heterogeneous scenarios. Despite using identical encoder structures and task heads, the"}, {"title": "key difference lies in their training paradigms.", "content": "Supervised models are trained on individual scenario datasets without cross-modal alignment between CSI and CIR representations. In contrast, the pretrained encoder in CSI-CLIP aligns features from both CSI and CIR, enabling it to capture their shared characteristics. This alignment significantly enhances general-ization across diverse environments and frequency bands.\nIn urban settings, CSI-CLIP achieves substantial reductions in positioning error and improvements in BM accuracy. For example, in Los Angeles, it reduced the average error distance from 49.03 meters to 34.18 meters (a decrease of 30.29%) and increased the precision of the BM from 75.68% to 78.38% (a gain of 2.70%). Notably, in scenarios with limited data, CSI-CLIP outperforms baselines, highlighting its practical value.\nEven in challenging environments, such as the Ol drone scenario at 200GHz, CSI-CLIP improved positioning by 40.02% and BM accuracy by 0.35%. These outcomes confirm that CSI-CLIP not only maintains high efficiency within spe-cific cities or frequency ranges but also consistently performs well under a broad set of conditions, demonstrating stability.\nIn the positioning task, despite the significant differences in error distances, CSI-CLIP generally achieved improvements ranging from 10% to 40%, average 22%. For the BM task, while the degree of improvement was relatively smaller, average 1%, CSI-CLIP provided positive improvements in almost all scenarios tested, reflecting consistent effectiveness. However, in some scenarios such as I2, a drop was observed, possibly due to the unique scenario characteristics."}, {"title": "Table II showcases the performance comparison of the chan-nel identification task across five distinct scenarios.", "content": "Although channel identification is a binary classification problem in which features under LoS and NLoS are relatively distin-guishable, leading to high accuracy (almost 100%) in most scenarios, CSI-CLIP still demonstrates exceptional capability.\nCSI-CLIP not only achieves extremely high accuracy in the majority of test scenarios but also realizes additional performance improvements over already excellent baselines. This achievement underscores the effectiveness and potential of CSI-CLIP in channel identification task, particularly in scenarios where features are less pronounced or environmental conditions are more complex.\nFurthermore, Table III illustrates the performance of CSI-CLIP on positioning task based on the SionnaRT simulation dataset, where the model was initially pretrained on the Deep-MIMO dataset. The results indicate that CSI-CLIP exhibits robust generalization capabilities even when confronted with data not encountered during training, achieving significant performance improvements compared to traditional supervised learning methods. Not only does CSI-CLIP excel on known datasets, but it also maintains a high level of accuracy and reliability in new environments. By offering more refined CSI embeddings, CSI-CLIP can make important contributions to the further optimization of ISAC systems."}, {"title": "V. CONCLUSIONS AND LIMITATIONS", "content": "This paper introduces the first MIMO wireless channels foundational model, named CSI-CLIP. It offers a comprehen-sive solution by simultaneously capturing the joint feature representation of CSI and CIR. Consequently, CSI-CLIP sig-nificantly enhances performance across multiple downstream tasks. Experimental results demonstrate that compared to tra-ditional supervised training methods, CSI-CLIP exhibits more robust feature representation and stronger generalization when processing CSI under different scenarios and frequencies, presenting substantial application prospects for practical ISAC systems.\nNevertheless, CSI-CLIP has certain limitations. For in-stance, it does not generalize well to scenarios with differing numbers of transmit/receive antennas and subcarriers from those used in our training configurations. The extracted CSI feature representations are not strong enough to support linear-probe. It is worth noting that previous studies have also strug-gled with these two issues, making them important directions for future research."}]}