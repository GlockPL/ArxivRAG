{"title": "Relating Answer Set Programming and\nMany-sorted Logics for Formal Verification", "authors": ["Zachary Hansen"], "abstract": "Answer Set Programming (ASP) is an important logic programming paradigm within the field of Knowl-\nedge Representation and Reasoning. As a concise, human-readable, declarative language, ASP is an\nexcellent tool for developing trustworthy (especially, artificially intelligent) software systems. However,\nformally verifying ASP programs offers some unique challenges, such as\n1. a lack of modularity (the meanings of rules are difficult to define in isolation from the enclosing\nprogram),\n2. the ground-and-solve semantics (the meanings of rules are dependent on the input data with which\nthe program is grounded), and\n3. limitations of existing tools.\n\nMy research agenda has been focused on addressing these three issues with the intention of making ASP\nverification an accessible, routine task that is regularly performed alongside program development. In\nthis vein, I have investigated alternative semantics for ASP based on translations into the logic of here-\nand-there and many-sorted first-order logic. These semantics promote a modular understanding of logic\nprograms, bypass grounding, and enable us to use automated theorem provers to automatically verify\nproperties of programs.", "sections": [{"title": "1 Introduction", "content": "Answer Set Programming (ASP) is an important logic programming paradigm within the field of Knowl-\nedge Representation and Reasoning. As a concise, human-readable, declarative language, ASP is an\nexcellent tool for developing trustworthy (especially, artificially intelligent) software systems. However,\nformally verifying ASP programs offers some unique challenges, such as\n1. a lack of modularity (the meanings of rules are difficult to define in isolation from the enclosing\nprogram),\n2. the ground-and-solve semantics (the meanings of rules are dependent on the input data with which\nthe program is grounded), and\n3. limitations of existing tools.\n\nMy research agenda has been focused on addressing these three issues with the intention of making ASP\nverification an accessible, routine task that is regularly performed alongside program development. In\nthis vein, I have investigated alternative semantics for ASP based on translations into the logic of here-\nand-there and many-sorted first-order logic. These semantics promote a modular understanding of logic\nprograms, bypass grounding, and enable us to use automated theorem provers to automatically verify\nproperties of programs."}, {"title": "2 Background", "content": "The stable model semantics of logic programs can be expressed in a variety of ways, each of which offers\nunique insights and utility [38]. For instance, logic programs can sometimes be viewed as \"shorthand\"\nfor propositional, first-order, default, or autoepistemic theories. These translational approaches (which\ntypically involve a syntactic transformation from ASP rules into a \u201cformula representation\u201d that uses the\nsyntax of first-order logic) offer some advantages over their fixpoint relatives. In particular, semantics\nthat let us bypass the issue of grounding are very convenient for program verification purposes. They\nallow us to disregard the specifics of the input data with which a program is paired when assessing the\nindependent meaning of the program.\n\nClark's Completion and its subsequent extensions [11, 39] provide a useful translational semantics for\na broad class of programs satisfying the tightness condition\u00b9 . Under these semantics, the logic program\n\np:-q. p:- r.\n\n1A tight program has a predicate dependency graph without positive cycles [20, 14]."}, {"title": null, "content": "is understood as the first-order theory\n\n\\(p \\leftrightarrow q \\lor r\\)\n\nwhich reflects the minimality of circumscription and the closely related principle of rational belief (we\nbelieve p only if we have to, that is, if and only if q or r holds) found in the autoepistemic intuitions\nbehind answer set programming [27]. However, completion semantics are only applicable to programs\nof a limited form \u2013 first-order logic cannot, for example, correctly capture the transitive closure of a\nbinary relation without non-standard assumptions like the Closed World Assumption. This restriction\ncan potentially be circumvented or at least relaxed through innovation in the areas of local tightness [21],\nloop formulas [37], tightening [48], and ordered completion [3].\n\nMore recently, a surprisingly deep connection between the logic of here-and-there [32] and ASP has\nyielded interesting results. The logic of here-and-there extends intuitionistic logic with the axiom schema\n\n\\(FV (F \\rightarrow G) \\lor \\neg G\\)\n\nof which the most commonly employed consequence is the weak law of excluded middle:\n\n\\(\\neg F \\lor F\\).\n\n(1)\nHere-and-there has a number of useful characteristics that make it applicable to the study of ASP [44].\nFirst, it acts as a well-behaved monotonic basis for equilibrium logic, which provides a non-monotonic\ninference relation that captures and generalizes the semantics of a broad class of ASP programs to full\npropositional logic (recall that while ASP rules have a very limited syntactic form, propositional formulas\ncan be very complex). Furthermore, intuitionistic logic cannot be strengthened more than here-and-there\nand still be strictly contained in classical logic, making it the strongest, well-behaved classical logic\navailable. Finally, the extension to ASP programs with variables is naturally covered by quantified\nformulas interpreted under the semantics of here-and-there.\n\nOne of the most fruitful consequences of this connection is the study of strong equivalence [40]. The\ncondition of strong equivalence states that two programs, \u03a0\u2081 and \u03a02, are strongly equivalent if I\u2081UI\nand I2 UI have the same answer sets for any program \u03a0. This condition is useful because it tells us\nthat our two programs are truly interchangeable: no matter which program they form a subcomponent of,\nthey can be swapped out without affecting the enclosing program's answer sets. It has been shown that\nthe strong equivalence of two programs can be established by deriving the formula representation of each\nprogram from the formula representation of the other within the logic of here-and-there; for propositional\nprograms this can be done in exponential time [40]. However, more complex ASP languages require\nmore sophisticated translations into formula representations, as well as extended deductive systems. For\nthe remainder of this paper, we will focus on a theoretical ASP language known as MINI-GRINGO.\n\nThe answer set solver CLINGO implements the language ABSTRACT GRINGO [24], whose semantics\nare defined by a translation (\u03c4) into the infinitary propositional logic developed by Truszczy\u0144ski [46].\nMINI-GRINGO is an expressive fragment of ABSTRACT GRINGO which supports negation, arithmetic,\nintervals, and basic choice rules [21]. The semantics of the language can be captured by a syntactic\ntransformation (\u03c4*) into first-order formula representations, which are interpreted under the HTA (here-\nand-there with arithmetic) deductive system [19]. An equivalent (and arguably simpler) characterization\nof these semantics are defined by the SM operator [23]. This operator transforms a program's (\u03a0) formula\nrepresentation (\u03c4*I) into a second-order sentence (SMp[\u03c4*(\u03a0)]) in which predicate quantification is used\nto minimize belief in the list p of intensional predicates (similar to circumscription). When p contains all\nthe predicates occurring in the logic program, then the models of SMp[\u03c4*(\u03a0)] correspond to the answer"}, {"title": null, "content": "sets of \u03a0. Bartholomew and Lee extend the concept of the SM operator to intensional functions [5].\nThis is once again rooted in the logic of here-and-there, where interpretations can be viewed as pairs\n(of \u201cworlds\u201d) (H,T). Predicate minimization through the SM operator is achieved by mandating that\npH \u2286 p\u00b9 for every p \u2208 p, similarly, for each intensional function f we require that fH \u2260 fT.\n\nThe study of the MINI-GRINGO language is motivated in large part by a desire to use automated rea-\nsoning tools for proving the correctness of ASP programs. ANTHEM is a software system that converts\nMINI-GRINGO programs into first-order formulas of two sorts (a supersort which consists of all program\nterms, and a subsort corresponding to integers) via the \u03c4* translation [20]. It then uses the first-order the-\norem prover VAMPIRE [35] to check the equivalence of the completion of the program (COMP[\u03c4*(\u03a0)])\nto a set of first-order formulas acting as a specification (S), under a set of assumptions characterizing the\nintended program inputs (A). That is, it attempts to establish the universal validity of\n\n\\(A \\rightarrow (COMP[\\tau *(\\Pi)] \\leftrightarrow S)\\)\n\nwhich, if it succeeds, is proof that the program I implements the specification. This procedure applies\nto io-programs, that is, ASP programs paired with placeholders as well as input and output predicate\nsymbols. Any predicate symbols that are neither input nor output symbols are private symbols \u2013 these\nauxiliary symbols are not essential for understanding the program's \"external\" behavior as characterized\nby the output symbols. For example, if we take prime/1 to be an output symbol, the programs\n\ncomposite(I*J) :- I = 2..n, J = 2..n.\nprime(I) :- I = 2..n, not composite(I).\n\nand\n\ncomp(X) :- X = I*J, I = 2..n, J = 2..n.\nprime(I) :- I = 2..n, not comp(I).\n\nclearly have the same external behavior (the extent of the prime/1 predicate) under the assumption that\nthe placeholder n is an integer, despite minor differences in how the auxiliary predicates are defined. This\nprocedure is only possible for programs satisfying the restrictions of tightness and absence of private\nrecursion.2\n\n2A program is tight if its predicate dependency graph has no cycles consisting of positive edges such as (p,p). A program\nhas private recursion if the subgraph induced by private symbols has no cycles."}, {"title": "3 Goals", "content": "My interest in the relationship of ASP to many-sorted first-order logic (and, more broadly, the logic of\nhere-and-there) is motivated by its application to software verification. My long-term research agenda\nis to help develop an accessible, tool-assisted methodology for formally verifying the correctness of\nASP programs. Clearly, such an agenda would extend beyond the duration of a single dissertation.\nFor this reason, I've organized the remainder of this research summary into sections showcasing which\npieces of this plan have already been addressed (Current Status and Preliminary Results), which pieces\nI plan to investigate during the remainder of my doctoral program (Ongoing Directions and Expected\nAchievements), and which pieces I hope to build on top of my eventual dissertation (Conclusions and\nFuture Directions)."}, {"title": "4 Current Status and Preliminary Results", "content": "Since joining the University of Nebraska Omaha (UNO) in Fall 2020, I have been engaged in several\nresearch projects under the umbrella topic of formal verification of ASP programs. Within this topic,\nI have been fortunate to collaborate with researchers at UNO, University of Texas at Austin, and the\nUniversity of Potsdam. My frequent collaborators include Dr. Yuliya Lierler (my advisor), Dr. Jorge\nFandinno, Dr. Vladimir Lifschitz, Dr. Torsten Schaub, and Tobias Stolzmann (another PhD student\nwriting his dissertation on topics related to ANTHEM). Where appropriate, I will distinguish between\ncollaborative work and work I've done independently."}, {"title": "4.1 Results Presented at Previous Doctoral Consortiums", "content": "Conditional literal semantics Conditional literals are a useful feature supported by CLINGO. The\nfollowing rule (from a Graph Coloring encoding) succinctly expresses that a vertex cannot have no\ncolors assigned to it.\n\n:- not asg(V, C) : col(C); vtx(V).\n\n(2)\nIn the spirit of Fandinno et al. (2020), Dr. Lierler and I developed a translation from a simple ASP\nlanguage that is (mostly) a subset of MINI-GRINGO extended with conditional literals to unsorted first-\norder logic [31]. This provided formal support for the intuition that conditional literals in this language\nrepresent nested implications within rule bodies. For example, the previous rule can be understood as\nthe first-order sentence\n\n\\(\\forall V((\\bigvee C(col(C) \\rightarrow \\neg asg(V,C)) \\lor \\neg vtx(V)) \\rightarrow 1).\\)\n\n(3)\nWe demonstrated that these semantics capture the behavior of CLINGO, and used them to prove the\ncorrectness of a k-coloring program.\n\nAggregate semantics Dr. Lierler, Dr. Fandinno, and I proposed a characterization of aggregate seman-\ntics that bypasses the need for grounding [16]. Instead, we apply a many-sorted generalization of the SM\noperator to a set of many-sorted first-order formulas (\u03ba\u03a0) representing a logic program (\u03a0). Aggregates\nare defined as functions on sets of tuples, whose members are restricted to those tuples satisfying the list\nof conditions present in the associated aggregate. We designed a set of second-order (first-order in the\npresence of finite aggregates) axioms to define the behavior of sets and aggregate function symbols. For\na class of standard interpretations satisfying assumptions such as a standard interpretation of addition,\nmodels of SM[\u03ba\u03a0] satisfying these aggregate axioms are in one-to-one correspondence with the stable\nmodels of I. When I is tight, the second-order characterization (SM[KI]) can be replaced by comple-\ntion (COMP[\u043a\u03a0]). Thus, for tight programs with finite aggregates, our proposed semantics define, via\nfirst-order logic, the behavior of CLINGO aggregates.\n\nModular proofs of correctness with aggregate constraints A key challenge in verifying logic pro-\ngrams is proving the correctness of groups of rules in isolation from the rest of the program. A \u201cdivide-\nand-conquer\" methodology is very natural for verification, but applying it to logic programs requires a\ncareful methodology, such as the one proposed by Cabalar, Fandinno, and Lierler (2020). They divide\ntheir example Hamiltonian Cycle program into various independent modules, whose behavior is cap-\ntured via the SM operator [6]. We extend their example to the Traveling Salesman problem with the"}, {"title": null, "content": "addition of an aggregate constraint (4) on the cumulative weight of the selected cycle, and use our many-\nsorted semantics for aggregates to verify the behavior of this constraint independently of the Hamiltonian\nCycle program [15]. Additionally, we prove the correctness of a Graph Coloring encoding containing\nchoice rules with cardinality bounds. This project showcases how the modular proof methodology can\nbe extended with our proposed aggregate semantics to argue the correctness of a broad class of logic\nprograms.\n\n:- #sum{ K,X,Y : in(X,Y), cost(K,X,Y) } > J, maxCost(J).\n\n(4)"}, {"title": "4.2 New Results", "content": "Extending MINI-GRINGO with conditional literals The ABSTRACT GRINGO fragment Dr. Lierler\nand I investigated in 2022 was unsorted, forbade double negations, and lacked support for arithmetic\noperations and intervals. These are important features supported by the MINI-GRINGO language on which\nANTHEM is based. We are working on extending the full MINI-GRINGO language presented in Fandinno,\nLifschitz, and Temple (2024) with conditional literals. The translation of conditional literals is largely\nthe same, but proving the correctness of the translation for this extended language is considerably more\ncomplicated. However, doing so allows us to check the strong equivalence of MINI-GRINGO programs\nwith conditional literals. Furthermore, this work is useful because it acts as a roadmap for the more\nchallenging task of extending MINI-GRINGO and ANTHEM with aggregates using our many-sorted first-\norder characterization.\n\nThis research has also yielded some interesting insights into the way conditional literals can be used\nto eliminate auxiliary predicates. Doing so makes modular programming, and constructing arguments of\ncorrectness about modular programs, considerably easier. For example, consider a traditional encoding\nof the Graph Coloring problem without conditional literals:\n\n{asg(V, C)} :- vtx(V), col(C).\n:- asg(V, C1), asg(V, C2), C1 != C2.\ncolored(V) :- asg(V, C).\n:- vtx(V), not colored(V).\n:- asg(V1, C), asg(V2, C), edge(V1, V2).\n\n(5)\n(6)\n(7)\n(8)\n(9)\nWe can eliminate the auxiliary predicate colored/1 by replacing rules (7-8) with the conditional literal\nconstraint (2). This example hints at a more general property. Note that the rule (7) expresses that a\nproperty (colored) holds for a vertex (V) if and only if there exists an element (C) such that V is mapped\nto C by the asg/2 predicate. This is an indirect way of expressing an existential quantification \u2013 in\nconjunction with rule (8), it expresses that every vertex must be mapped to a color. This condition can\nbe more concisely represented via conditional literal (3), which is classically equivalent to\n\n\\(\\forall V (vtx(V) \\rightarrow \\exists C (col(C) \\land asg(V,C))).\\)\n\nAxiomatizing new aggregates The many-sorted first-order logic characterization of aggregates Dr.\nLierler, Dr. Fandinno, and I developed captured the behavior of CLINGO's count and sum aggre-\ngates [16]. Furthermore, for programs adhering to the ASP-Core-2 standard [7], this characterization\nalso captures the ASP-Core-2 semantics. I have since extended this characterization with min, max,"}, {"title": null, "content": "and sum+ aggregates. This required developing first and second-order axiomatizations for the new ag-\ngregates and proving that they correctly captured the behavior of CLINGO. These results, alongside\nsignificant extensions such as a detailed section integrating our results with Clark's Completion, were\nrecently published in the Journal of Artificial Intelligence Research [17].\n\nRecursive aggregates The aggregate axiomatization projects described thus far have included a re-\nstriction on positive recursion through aggregates. While such recursion is a comparatively rare scenario\nin practice, it is very important to the study of strong equivalence. Since two programs \u03a0\u2081 and I2 must\nhave the same answer sets when combined with any program I to be strongly equivalent, any discussion\nof strongly equivalent logic programs must accommodate the case when I introduces recursion through\nthe aggregates of \u03a0\u2081 or \u03a02. To address this, Dr. Fandinno and I extended our aggregate semantics with\nintensional function symbols [30]. We treated aggregates as functions on sets of tuples \u2013 these so-called\n\"set symbols,\" which map ground terms to sets of tuples of ground terms, were treated intensionally. We\nfound that our proposed semantics coincides with the semantics of CLINGO, but naturally diverged from\nthe semantics of DLV in the presence of recursive aggregates. I presented these results at ASPOCP 2023.\n\nProgram to program verification The original version of ANTHEM required a specification written\nin first-order logic. However, it has since become clear that many ASP programmers would rather write\ntheir specifications in the form of a simple, easy-to-read ASP program. To support this, I developed the\nAP2P3 system on top of the original ANTHEM. The theoretical results supporting this procedure were\npublished in TPLP [18]. AP2P allows users to automatically confirm the (external) equivalence of two\nASP programs. This is primarily useful in the refactoring process, wherein a simple program may be\nsuccessively replaced by more complex programs in the interest of improving performance. Our system\nchecks that the essential behavior of the program has not been changed during refactoring.\n\nAnthem 2 The long-term viability of the prototypical ANTHEM system was threatened by technical\ndebt such as a lack of documentation, heavy dependence on deprecated Rust nightly features, and a di-\nvergence of the system's behavior from the supporting theory. I have been working in collaboration with\nDr. Lifschitz and Tobias Stolzmann on a complete overhaul and re-implementation of this prototype that\ncorrects and extends it in several ways. First, I have restructured and generalized the verification process\nto enable a symmetric treatment of program-to-program and program-to-specification verification. This\npositions ANTHEM as a tool to support refactoring ASP code in addition to its original functionality.\nSecond, Tobias Stolzmann and I have corrected the internal representation of many-sorted first-order\ntheories and the partial axiomatizations of standard interpretations. This eases (in particular) the han-\ndling of placeholders in io-programs. Third, I have designed and implemented a suite of transformations\nequivalent in the logic of here-and-there to simplify the formulas being passed to the backend theorem\nprover. Preliminary experiments show substantial improvements in runtime for certain programs. Fourth,\nDr. Lifschitz and I have designed and implemented an improved control language for writing proof out-\nlines, which offers users a considerably more fine-grained control over the formulation of verification\ntasks. This moves ANTHEM away from a one-shot system towards an interactive proof assistant, which\nis crucial for verifying non-trivial problems. Finally, I wrote a reference manual to resolve the issue of\nmissing documentation4.\n\n3https://ap2p.unomaha.edu/\n4The new system and user manual can be found here: https://github.com/potassco/anthem"}, {"title": "5 Ongoing Directions and Expected Achievements", "content": "Recursive aggregates Dr. Fandinno and I are currently developing recursive aggregate semantics for\nDLV analogous to those we created for CLINGO. We have designed a new translation to a many-sorted\nfirst-order language for DLV programs, that treats default negation in a different manner. This work\nsuggests that the difference between the treatment of recursive aggregates in CLINGO versus DLV stems\nfrom an underlying difference in their treatment of default negation. These new semantics allow us to\ndefine strong equivalence not just between a pair of CLINGO programs or a pair of DLV programs, but\nbetween a CLINGO program and a DLV program. These are exciting results that provide new insights into\nthe differences between these two major solvers.\n\nExtending ANTHEM with conditional literals More theoretical work needs to be done before I can\nimplement a translation for conditional literals within ANTHEM. First and foremost, the current results\nneed to be extended to io-programs. Additionally, while checking strong equivalence does not require\ntightness, checking external equivalence does. It is not yet clear to me how the notion of a predicate\ndependency graph changes in the presence of conditional literals, although first-order dependency graphs\nare a promising direction to explore [36].\n\nSets and many-sorted logic in ANTHEM This is the last major task I hope to accomplish as part of\nmy dissertation. The question of integrating our aggregate semantics into MINI-GRINGO and ANTHEM is\ndependent upon our ability to (partially) axiomatize our notion of standard interpretations. This special\nclass of interpretations makes some assumptions about the behavior of the set sort (for instance, that set\nmembership behaves in a standard way). There is reason to believe this is possible \u2013 VAMPIRE natively\nsupports a partial axiomatization of integer arithmetic [35] which we extend to a partial axiomatization\nof two-sorted standard interpretations by including certain custom axioms in every verification task. The\nThousands of Problems for Theorem Provers (TPTP) project has numerous partial axiomatizations of\ntheories compatible with VAMPIRE, including some focusing on set theory [45]. We may be able to\nuse these as a starting point, though the specifics (Figure 1) of our many-sorted domain may be hard to\nexpress. In particular, we need to capture the restrictions that\n\n1. the numeral universe |I|Sint is a subsort of the program term universe |I|Sprg,\n2. the tuple universe |I|Stuple consists of tuples of program terms, and\n3. the set universe |I| Sset is the power set of the tuple universe.\n\nThere is also the question of how theory extensions (such as set theory) impacts the runtime of VAMPIRE\nand, consequently, the usability of ANTHEM. Our experiments with ANTHEM and AP2P have already\nshown that certain programs containing integer arithmetic can be deceptively difficult to verify automat-\nically. For example, ANTHEM struggles to verify the external equivalence of\n\np(X*X) :- X = 0..n.\n\nand\n\np(X*X) :- X = -n..n.\n\nunder the assumption that n is an integer greater than 0."}, {"title": "6 Related Work", "content": "The Introduction identifies three core challenges to ASP verification: modularity, grounding, and tool\nsupport. Within each of these topics, there are a number of studies relevant to the research agenda\nproposed here."}, {"title": "6.1 Modularity", "content": "The notion of external equivalence presented earlier is closely related to modular equivalence for DLP\nand ELP-functions [33], which are in turn related to LP-functions [26, Section 2]. In these studies, the\nidea of program modules as composable functions mapping input atoms to output atoms (using hidden\nauxiliary atoms) has been explored in the context of disjunctive, propositional programs. The module\ntheorem [33] provides a compositional semantics for this class of programs.5 Our work on external\nbehavior of io-programs and modular arguments of correctness uses similar results established for a\ndifferent class of programs, specifically, programs with variables and arithmetic.\n\nTemplates are a construct roughly analogous to program modules, where global (public) predicates\nare renamed so as to interface with an enclosing program, and local (auxiliary/hidden/private) predicates\nare renamed with a procedure that (very nearly) guarantees the new identifiers are universally unique [1].\nThe use of templates promotes code reusability and eases the development of industrial-scale applica-\ntions [8]. This approach has the additional benefit of being able to test that simple invariants of templates\nhold in the context of an enclosing program. As an alternative to the re-writing strategy described above,\ntemplates can also be defined as higher-order definitions of predicates [12]. This is more in line with the\nsecond-order characterization of external behavior given by the SM operator.\n\n5Under certain reconfigurations of program modules, the module theorem can apply even when some input, output, or\nhidden atoms are forgotten [28]."}, {"title": "6.2 Grounding", "content": "Within the domain of translational semantics for ASP, a major distinction is between grounding-free ap-\nproaches, and semantics applied to grounded or propositional programs. A grounding-free translational\napproach is the basis of this proposal \u2013 it benefits from being more general, but suffers some restrictions"}, {"title": "6.3 Tool Support", "content": "Tools supporting formal verification of ASP programs can be roughly divided into the categories of test-\ning based and proof based systems. These are complementary approaches, since testing generally cannot\nprovide the same level of assurance but is fast and universally applicable. HARVEY is an ASP-based sys-\ntem for random testing of ASP programs [29]. ASPIDE is an integrated development environment (IDE)\nsupporting unit testing [2, 22]. Similarly to ANTHEM, this supports modular verification by specifying\nconditions on outputs for program \"units\" and automatically testing that these conditions are satisfied\nfor certain inputs. However, ANTHEM enables users to specify (possibly infinite) classes of inputs rather\nthan a finite set of test cases.\n\nExamples of proof based systems are SELP [9], TABEQL [47], LPEQ [34], and CCT [42]. SELP\nis closely related to this proposal, since it uses automated reasoning tools to check whether two logic\nprograms are strongly equivalent. One notable consequence of SELP's SAT checking methodology is its\nability to find a counterexample, which would be an interesting addition to ANTHEM. SELP differs from\nANTHEM in its use of SAT solving instead of theorem proving; a more important difference is that SELP\nsupports disjunctive propositional programs whereas ANTHEM supports normal programs with variables\nand arithmetic. TABEQL does not translate ASP programs into logical theories, but rather computes\nequilibrium models of arbitrary propositional theories using tableau calculi for here-and-there. The ASP-\nto-ASP translation tool LPEQ and its variant DLPEQ produce logic programs whose answer sets (if any)\nrepresent counterexamples to the weak or strong equivalence of a pair of programs.7 Similarly to SELP,\nthese systems accept disjunctive, variable-free logic programs. A more flexible system is CCT, which\ntests relativised strong equivalence with projection and uniform equivalence.8 CCT is very similar in\nspirit to ANTHEM, SELP, and LPEQ given that it relies on a translation to quantified Boolean formulas\nevaluated by backend solvers. This system is based on a general notion of program correspondence [13],\nand requires two sets of atoms (a context and a projection set) which behave similarly to ANTHEM's input\nand output predicates. Again, ANTHEM is more general: rather than dealing with concrete sets of atoms\nANTHEM operates on classes of inputs defined by first-order assumptions.\n7Two programs are weakly equivalent if they have the same answer sets; this is a special case of external equivalence.\n8Uniform equivalence is a special case of strong equivalence where it is assumed that the context is a set of facts rather than\nan arbitrary set of rules."}, {"title": "7 Conclusions and Future Directions", "content": "ASP modules I proposed this idea at the ICLP and LPNMR 2022 doctoral consortiums, and it received\nencouraging feedback from attendees. Building off of the modular verification methodology discussed\nearlier, I would like to develop a repository of verified ASP sub-programs (\"modules\") that provide"}, {"title": null, "content": "efficient, correct implementations of commonly encountered sub-problems. Each module would be ac-\ncompanied by a proof of correctness, whose guarantees can be used within an argument of the enclosing\nprogram's correctness. This could reduce the effort needed for programming, and some of the labor\nrequired to formally prove the correctness of the program. For example, defining the transitive closure\nof a binary relation is a common task in ASP programming. Integrating a generic module such as\n\ntransitive(X,Y) :- edge(X,Y).\ntransitive(X,Z) :- transitive(X,Y),edge(Y,Z).\n\nis preferable to re-inventing the wheel with a custom, unverified implementation. In this scenario, the\nprogrammer would only have to define the interfaces to and from the module, analogous to the input and\noutput interfaces proposed for disjunctive logic programs [33]. Each program in the repository should\nhave a natural language specification of intended behavior, a proof of correctness, and a description of\nhow to interface with the module. Thus, the idea is similar to that of ASP templates [1], with an emphasis\non reusability of the corresponding proofs of correctness. ASP practitioners could submit a (program,\nspecification) pair as a verification challenge, or submit fully verified modules ready for reuse. Besides\nthe transitive closure module, other common, generalizable sub-problems include functional relations\n(predicates defining a mapping from one set to another) and definitions of grid adjacency (typically used\nin 2D planning problems like ASPRILO [25]). While I'm still very interested in this task, I've come\nto realize that such a project is beyond the scope of my dissertation. I now see it as a top priority for\npost-graduate research.\n\nDiscussion The task of verifying ASP programs is complex, but relating them to equivalent theories in\nthe logic of here-and-there and many-sorted first-order logic is a promising approach. Much of my work\nhas focused on investigating this relationship in the presence of advanced language constructs, such as\naggregates and conditional literals. These are features on which modern ASP solutions rely heavily - yet\nthey are not even the most sophisticated features offered by modern solvers. Verification techniques for\nconstraint answer set programs, or for programs with optimization statements and theory propagators,\nare possible future directions of research with great potential.\n\nAnother topic of interest is the extension of ANTHEM with alternative backend solvers. Other ASP\nverification tools support finding counterexamples to program correspondence, which is an interesting\nand useful ability. An SMT solver like CVC5 [4] might enable ANTHEM to check countersatisfiability\nand/or generate counterexamples. Furthermore, intuitionistic theorem provers like nanoCOP-i [43] are\na natural avenue to explore given ASP's close relationship with the logic of here-and-there. Secondary\ntransformations like completion could be avoided completely if an intuitionistic theorem prover \u2013 possi-\nbly strengthened with axiom schemata such as (1) \u2013 shows itself capable of reasoning effectively within\n\u0397\u03a4\u0391.\n\nFinally, there is the topic of making the verification task accessible enough that ASP practitioners\nwill employ it in the real world. Automation is a great way to promote this \u2013 but much more work\nis required to make complex problems verifiable with reasonable resources. Reusing components of\nprograms and their corresponding proofs of correctness is another way to ease the burden on practitioners.\nTo encourage formal verification in practice, ANTHEM could be integrated as a plugin to an IDE like\nASPIDE in addition to behaving as a stand-alone tool. I plan to continue working on such tool-assisted\nverification strategies in the future."}]}