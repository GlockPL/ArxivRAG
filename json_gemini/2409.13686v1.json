{"title": "The Impact of Large Language Models in Academia: from Writing to Speaking", "authors": ["Mingmeng Geng", "Caixi Chen", "Yanru Wu", "Dongping Chen", "Yao Wan", "Pan Zhou"], "abstract": "Large language models (LLMs) are increasingly impacting human society, particularly in textual information. Based on more than 30,000 papers and 1,000 presentations from machine learning conferences, we examined and compared the words used in writing and speaking, representing the first large-scale investigating study of how LLMs influence the two main modes of verbal communication and expression within the same group of people. Our empirical results show that LLM-style words such as \"significant\u201d have been used more frequently in abstracts and oral presentations. The impact on speaking is beginning to emerge and is likely to grow in the future, calling attention to the implicit influence and ripple effect of LLMs on human society.", "sections": [{"title": "1 Introduction", "content": "The rapid development and popularity of large language models (LLMs) [OpenAI, 2024, Anthropic, 2024, OpenAI, 2023] have alerted more and more researchers to the impact of LLMs on human society. In this paper, we focus on the impact of LLMs in academia, especially on writing and speaking.\nWhile the rapid increase in usage and impact of LLMs have been demonstrated in academic papers [Liang et al., 2024a, Geng and Trotta, 2024], few studies have addressed the influence of LLMs beyond writing. Only recently, a preprint pointed out the impact of LLMs on the words used in speaking, as collected in YouTube videos [Yakura et al., 2024]. The similarities and differences in how writing and speaking are influenced, in particular for the same population, have not been explored. Through papers and presentations from recent machine learning conferences, we try to fill in this missing piece.\nWe would also like to call attention to the implicit impact of LLMs, by which we mean people who do not directly use LLMs to generate content but who have been influenced through exposure to such content. Researchers have placed more focus on the use and direct impacts of LLMs and not enough on the implicit ones. For instance, the titles of papers [Matsui, 2024, Kobak et al., 2024, Astarita et al., 2024] analyzing the use of LLMs in academic papers begin with \"delving into\" (one of ChatGPT's signature words), and Kobak et al. [2024] state that they didn't use LLMs to write their paper. Besides, detecting a mixture of machine-generated and human-written text is another difficulty being actively researched [Lee et al., 2022, Gao et al., 2024, Zhang et al., 2024].\nPeople can use LLMs to write emails or accomplish tasks other than paper writing, which leads to a change in their English expression and is reflected in their academic output at a later point in time."}, {"title": "2 Methods", "content": "2.1 Anomaly Detection\nGiven that word frequencies are always changing, the issue of noise cannot be ignored. To reduce the error caused by the randomness of word usage, the target words are considered as a group, denoted as $W_I = {w_i | i \u2208 I}$, where i is the frequency ranking in the corresponding dataset.\nFor a group of words WI, the control group with shift n is defined as $W_{In} = {W_{i+n} | i \u2208 I_0}$. Given a corpus S, the corresponding frequency Fn(S) is $F_n(S) = \\sum_{w\u2208I_n} f_w(S)$, where $f_w$ means the frequency of word w in set S. The frequency ratio between two different corpus is $R_n (S, S') = \\frac{F_n(S)}{F_n (S')}$.\nConstructing control groups to analyze changes in word frequency has been used before [Matsui, 2024, Yakura et al., 2024]. In this paper, the words in each group have roughly the same frequency based on the ranking in the dataset, which shows whether the change in frequency of the target words is unusual.\n2.2 LLM Simulations and Impact Estimation\nSome researchers have estimated the impact of LLMs by excess vocabulary only [Kobak et al., 2024], but the words in the abstract are also related to the topic of the paper, and the hot topics of machine learning conferences change frequently. Therefore, it is also helpful to perform LLM simulations, and compare texts before and after processing, essential for a reliable estimation of LLM impact.\nIf the frequency of word i is f(S1) and f(S2) in a corpus before and after LLM processing, the frequency change rate ri is estimated as $r_i = \\frac{f_i(S_2)-f_i(S_1)}{f_i(S_1)}$. Then for the \u201cproportion\" (impact) of LLMs texts \u03b7(S), the following equation is a simplified version of the method proposed by Geng and Trotta [2024],\n$f_i^a(S) \u2212 f_i^*(S) = \u03b7(S) f_i^*(S)r_i + d_i(S)$ (1)\nwhere $f_i^a(S)$ represents the frequency of word i in the set of texts S, $f_i^*(S)$ represents the one if LLMs do not affect writing abstracts, and $d_i(S)$ is a noise term.\nThe estimate of LLM impact given by Ordinary Least Squares (OLS) is expressed as\n$\\hat{\u03b7}(S) = \\frac{\\sum_{i\u2208I}(f_i^a(S) \u2212 f_i^*(S)) f_i^*(S)r_i}{\\sum_{i\u2208I}(f_i^*(S)r_i)^2}$ (2)\nwhere I is the set of words used for estimation, and different I give us different estimates."}, {"title": "3 Datasets and Results", "content": "3.1 Datasets\nTo better explore and compare how the \u201csame\" people are affected in writing and speaking by LLMs, we crawled presentations and meta information of papers from three conferences: International Conference on Machine Learning (ICML), International Conference on Learning Representations (ICLR), Conference on Neural Information Processing Systems (NeurIPS). The abstracts of papers rather than the full papers were used in the analysis, as the former are more representative. More than 30,000 abstracts and 1,000 talks were considered, with full details in Appendix B.\n3.2 Word Frequencies Analysis in Speaking and Writing\nResearchers have discovered that the frequency of some words started to increase rapidly across academic papers in different disciplines after the end of 2022, and we found a similar trend also for"}, {"title": "3.3 Distribution of Frequency Ratios", "content": "The word frequencies in the abstracts of poster papers in NeurIPS from 2021 to 2023 were used for ranking i the words to form the control group WI with the shift as defined in section 2.1. The frequency ratio $R_n (S, S')$ for the abstracts and talks of the ICML oral papers in 2024 compared to"}, {"title": "3.4 LLM Simulations", "content": "The simulations of LLM were performed on GPT-3.5 with a simple prompt: \u201cRevise the following sentences:\" [Geng and Trotta, 2024]. The word frequency analysis on the abstracts revised by ChatGPT is in Figure 3a, obtained after the same calculations as for Figures 1a and 1c. The frequency of these words has all increased \u201csignificantly\" after ChatGPT processing, which reconfirms that ChatGPT favors these words. The comparison of simulated and original data in Figure 3b tells us that words sensitive to ChatGPT processing are in the minority."}, {"title": "3.5 LLM Impact Estimations", "content": "The ChatGPT-modified abstracts of spotlight (poster) papers from ICML 2022 were utilized to calculate \u00eei and LLM impact estimations. And f* (S) is approximated by the word frequency of the"}, {"title": "4 Conclusions and Discussions", "content": "LLMs have started a paradigm revolution in AI and transformed the game completely. While the discussion of the social impact of LLMs began long before the storm hit [Solaiman et al., 2019], it took some time to really \"delve into\" it.\nOur work is the first paper to estimate the effect of LLMs on the same group of people in writing and speaking, and one of the first to analyze the impact on human communication and beyond text. Although traces of LLMs are only nascent in the presentations of machine learning conferences, their usage and impact in writing have been illustrated by much literature and the results above and are becoming more and more profound in academia.\nOur findings demonstrate the impact of LLMs in the abstracts of papers in top machine learning conferences, even in the oral papers. For ICML 2024, out of more than 9000 submitted papers, only 144 were accepted as oral, where we still find quite a bit of LLM-style text.\nSpeech is one of the scenarios in which LLMs have an implicit impact (broadly), for it is usually safe to assume that the speaker is not using an LLM while presenting. It is also true that researchers may have prepared presentations or slides using LLMs, in which case their choice of wording may have been literally influenced. The sample sizes in speaking are not as large as in writing, but they are homogenized and representative. In addition, because of the difference between written and spoken language, it is actually difficult to directly compare LLM impact on writing and speaking.\nThe rapid increase in AI-generated content requires us to pay more attention, as synthetic data can lead to model collapse [Shumailov et al., 2024, Guo et al., 2023a, Briesch et al., 2023] and even knowledge collapse [Peterson, 2024]. LLM-style sentences are appearing more and more in academic papers, and the implicit impact of LLMs seems unstoppable. In the near future, a paper considered"}, {"title": "Presentation Example", "content": "'Opening': 'Hi Embassy Kuala',\n'Introduction': 'And this presentation is about our clear paper titled complex query answering with neuron predictors. And this is joint work with Erik Daniel Helle',\n'Related Work': 'So let's consider the setting. We have a knowledge graph graph structured knowledge base where knowledge about the world is represented in the form of relationships between entities. In the knowledge graph like this, one notes correspond to objects in the world or also upset concepts and I just correspond to relationships between these. In this example we have a knowledge graph about biomedical entities which tells us that paroxetine is used to treat anxiety and as bisimulation as a biological action. And that a pixel band treats deep vein thrombosis and one of its pharmacological effects is that it's an anticoagulant. Now one problem with real world where large scale knowledge graphs is that they are often incomplete. In this particular case, we are missing a link stating the topics abandons a medication that deep vein thrombosis is a disease and that a pixel band kind of side effects when taken together with oxygen. A very effective solution to identifying missing links in large knowledge graphs is via neural in production models in neural prediction. The underlying idea is that we can learn an embedding vector for all the nodes in the graph. For example, in this case we will learn an embedding back to for a pixel band proximity in bisimulation, Deep vein thrombosis and all other entities in the graph. Now assume we want to know the type of relationship if any between a pixel band and boxed in the likelihood that two entities in this case picks abandoned parks 18 are linked by a given type of relationship in this case interacts is a function of the embedding vectors of the source node. In this case a pixel man and embedding vector of the target node in this case, proximity in. And we can use this function for ranking missing links and find out that for example, a pixel bunnies are likely to interact with oxytocin. Even if this link is not directly available in the knowledge graph. Now consider the problem of answering complex queries on incomplete knowledge graphs. Here we have a query which medications have side effects when taken with drugs for treating anxiety and we want to have a list of medications that hands are query. This query can be formalized in logic form and it reads as follows, find M where M is available such that there is a D. Which is also variable, such that I am interacts with the and the tweets anxiety know that this is just an example and our method supports arbitrarily complex logic queries with conjunctions and dysfunctions. Now the best solution for solving this problem proposed so far is the following. First we automatically generate millions of complex query answer path and then we train a deep neural network to produce the correct answers given the creator, the neural model works as follows. First we represent the complex query as a graph. We were each note um corresponds either to a variable or to an entity in the query. Then the graph is passes through a deep neural network which will return ranking list of answers. Now that two main problems with this approach, one is that training is extremely expensive, since the models need to be trained on millions of genetic queries. Also, it's not really clear what happens if we evaluate on queries that differ from the queries that we used for training. Another issue is that there is no explanation for the reasons why a given answer was predicted to solve these problems',\n'Method': 'In this work, we propose a completely new paradigm for answering complex queries on incomplete knowledge graphs. We first train a model F. I, financing simple atomic queries like which drugs to it anxiety. And then we convert its query into an optimization problem where we need to identify the optimal values of the variables in this case, M and D. In the query that maximize the likelihood of both that M interacts with the and likely that the tweets anxiety. Then those two likelihoods are aggregated using a T norm, which is a continuous relaxation of the logical and from fancy logic. And depending on whether we search for the best values of M and the united creator continuous space, we can cast this problem as either as a continuous or discrete optimization problem. In the discrete case, we want to identify the best mapping from variables to entities that maximizes the score of the query. We experimented with a very simple greedy approach to solve this problem, we first start with the variable D. And search for the K most likely values for the by finding the top K. Treatments for anxiety according to the Newell in prediction model. Then for each of the candidate values of the we identify the most likely values for the problem and then we compute the query scores, originated parts of values for M and E, and which are the most likely values for MMD. Another approach we experimented with consists in directly optimizing the vector representations associated with the variables MMD. This can"}, {"title": "Results", "content": "Yeah. So we experimented on a variety of complex grid structures. And despite being only trained on simple creation, we can see that our model systematically generalize is too complex queries better than models trained on complex queries. In the first place, He had results on 3 - 15 K 237 for different complex great types. Here we can see the results on three basic 15 K. Any other results on 995 and here we have the average results between all types of complex queries that we considered. And we can see that our model produces significantly more accurate results on all the traii datasets. This improves of the existing models, both in terms of the data efficiency, because we only need to train our model on a much smaller dataset of simple queries and also in terms of out of out of distribution generalization, because we get better generalization accuracy on complex queries without having to train on them In the 1st place. Another really nice feature of this model is that it can provide explanations for its predictions. Other models in the space only returns a list of answers to the query. For instance, in this case, the answer is being produced at a pixel ban, I'm 15 block setting and others. Our model can also be used to provide the intermediate results associated with each query in the form of the variable assignments used to produce the answer. For example, here we can see that a pixel ban and I'm tellin were considered as answers because according to the model, they interact with oxytocin while dual oxygen was considered as as an answer because according to the model, it interacts with pregabalin and this allows us to check whether the results are being produced for the right reasons. In this case box setting and pregabalin are two possible treatments for anxiety. So the model is producing the correct answers for the correct reasons. This is not always the case. For example, consider the following query from feedback is 15 K 237. What international organizations contain the country of nationality of thomas Aquinas here, the model was able to return the correct set of answers NATO asI, D U and Wt O. However, this return for the wrong reasons. Um thomas Aquinas was mistakenly assumed to be from the US from the UK are from Germany. While the correct nationality of thomas Aquinas is italian. Our model enables us to detect such iris and possibly cracked them by refining the underlying newly prediction model"}, {"title": "Ending", "content": "So, to summarize in this paper, we propose a new approach France and complex creates on large scale and incomplete knowledge graphs. In our approach, we first train a neural prediction model on the task of answering simple atomic creation. And then we cast the problem of answering complex grace as an optimization problem where we need to find the mapping from variables, quantities that maximizes the score of the complex square. And we show that our approach generalizes extremely well to complex queries despite not having been trained on them in the first place, all the source code, the pre trained models and datasets online at this link. And if you want to collaborate on this topic or have any questions or comments, please feel free to reach out to us and thank you for listening. thank you very much So you may be. Now we will move to the next paper about complex query answering"}, {"title": "Q&A", "content": "So we had one question from Cartier uh she mentioned that the work is supplied to relatively small data said she wants to know essentially what happens if you try to scale it up. And I follow with the second question quickly. I was wondering essentially because you have these different types of you know, complex queries and then you have two types of optimization. One is the continuous relaxation, another is the greedy discrete approach. Which one is better in which case is there any kind of ideal correlation between types of I don't know, complexity of the queries, how they are designed and so on or Yes, thank you. Thanks to the great questions. So about the first one about getting the method up to much larger quantities of data like the millions um of data points they use in other methods. I think it's super interesting and we can I think we might observe significant improvement for that from that. For example. One thing that we're doing at the moment is we are fixing how so we select one continuous relaxation of the logical end and are as an input parameter, we select the two norm and that economic beforehand as an input parameter and then we just execute the method but I think by scaling this matter to larger conditional data and to complex creates during training we can think of for example to um to train how we represent the logical and and or within the architecture and we can we would be able to use for example, paramedic economics and economies, which we are not touching at the moment because we don't use complexities, complexities during training. And also um the naturally predictors that we use for answering economic queries are not really trained. Um so um are not really trained on complex crises in in the first place that trained on atomic quiz. And I think that so the scores are not really trying to do interact together in some sense. So I think we might be able to observe a"}, {"title": null, "content": "significant improvement from that as well. About the other question. So what we observed is that the discrete search seems to work consistently better than the continuous search um across all datasets and the types of complex queries. And we think that that might happen because the the continuous search for the entity representations might find some entity representations that do not do not correspond to any real entities in some sense. Or maybe the model might hallucinate some, I don't know, a dog with seven legs. Uh The other entities that are not really close in terms of representations to real entities in the knowledge base. So I think that's my that that might be a reason why um this could search works consistently better on uh continue such. Um Thanks. Okay, thank you very much. I think that answers the question. So I'll hand over tell me actually have another question about the linking paper. So you have a two step approach for your first predict links and then you run queries on top of that. Can you comment on? No, no, basically the links are predicted. Um so basically the links are predicted as kind of a part of the optimization problem. We translate the complex series into each complex query is translated into an optimization problem and the neural predictor. Um that makes whether there is a link between two entities is kind of a component of this optimization problem because correcting like all drinks beforehand, doesn't scale up because you can have billions of possible links uh in the name, like materializing all the links beforehand doesn't really uh scale also like you need to decide uh what whether to materialize a link or not. So basically the link prediction process is part of the complex variants diagnosis. Uh this map"}]}