{"title": "Neural Two-Level Monte Carlo Real-Time Rendering", "authors": ["Mikhail Dereviannykh", "Dmitrii Klepikov", "Johannes Hanika", "Carsten Dachsbacher"], "abstract": "We introduce an efficient Two-Level Monte Carlo (subset of Multi-Level Monte Carlo, MLMC) estimator for real-time rendering of scenes with global illumination. Using MLMC we split the shading integral into two parts: the radiance cache integral and the residual error integral that compensates for the bias of the first one. For the first part, we developed the Neural Incident Radiance Cache (NIRC) leveraging the power of fully-fused tiny neural networks [M\u00fcller et al. 2021] as a building block, which is trained on the fly. The cache is designed to provide a fast and reasonable approximation of the incident radiance: an evaluation takes 2-25\u00d7 less compute time than a path tracing sample. This enables us to estimate the radiance cache integral with a high number of samples and by this achieve faster convergence. For the residual error integral, we compute the difference between the NIRC predictions and the unbiased path tracing simulation.\nOur method makes no assumptions about the geometry, materials, or lighting of a scene and has only few intuitive hyper-parameters. We provide a comprehensive comparative analysis in different experimental scenarios. Since the algorithm is trained in an on-line fashion, it demonstrates significant noise level reduction even for dynamic scenes and can easily be combined with other importance sampling schemes and noise reduction techniques.", "sections": [{"title": "1 INTRODUCTION", "content": "Rendering global illumination effects remains challenging in interactive and real-time applications, even with modern hardware-accelerated ray tracing. Monte Carlo methods, which are used to compute a solution to the Rendering Equation [Kajiya 1986] are prone to noise due to their stochastic nature, amplified by complex materials and occlusions in a scene. Techniques such as importance sampling, and more recently learning-based approaches have demonstrated effectiveness in addressing these issues, mitigating the noise problem significantly using radiance caching [Boiss\u00e9 et al. 2023; Gassenbauer et al. 2009; Ward et al. 1988], photon mapping [Hachisuka et al. 2008; Jensen 1996], adaptive sampling [Mitchell 1987], vertex connection and merging [Georgiev et al. 2012] and path guiding [Vorba et al. 2019].\nOur work also depends on caching: we use several path tracing samples to initialize a cached representation of the incident radiance field in the scene. This cache can then be evaluated to yield a fast approximation of the actual light field.\nIn our approach, we introduce a novel caching method using fully-fused tiny neural networks, inspired by the Neural Radiance Cache (NRC) [M\u00fcller et al. 2021], and multiresolution hash encoding [M\u00fcller et al. 2022]. The important novelty of our method is that we employ Neural Incident Radiance Caches (NIRCs) which are specifically designed to cache incident radiance (as opposed to outgoing radiance with NRCs). This allows us to query the cache for incident radiance at a shading point post-material evaluation to efficiently approximate the shading integral without additional ray tracing. Our combination with a Two-Level Monte Carlo scheme enables us to compensate for the resulting bias. For biased rendering, we introduce a new Balanced Termination Heuristic (BTH) to enhance path termination efficiency, leveraging the strengths of NIRCs while addressing their limitations with glossy details. The BTH allows us to use our cache instantly at the primary bounce since it predicts incident radiance directly, unlike the NRC Spread Angle Heuristic (SPH), which is unsuitable for stopping at the primarily visible surface.\nAlong with that, we assessed the differences between Control Variates (CV) and Two-Level Monte Carlo methods by comparing analytical models, such as Spherical Harmonics (SH) and mixtures of von Mises-Fisher (vMF) lobes, commonly used in the earlier research [Pantaleoni 2020] [Vorba et al. 2014], alongside Neural Control Variates (NCV) [M\u00fcller et al. 2020]. While NCV is specifically designed to satisfy Control Variates requirements by providing analytical integral computation, our results show that NIRC in the Two-Level Monte Carlo framework can achieve lower variance of the residual"}, {"title": "2 BACKGROUND", "content": "Light transport simulation. The rendering equation [Kajiya 1986] describes how light interacts with a scene. The radiance $L_o(x, \\omega_o)$ leaving a point x in direction $\\omega_o$ is:\n$L_o(x, \\omega_o) = L_e (x, \\omega_o) + \\int_{\\mathbb{H}^+} L_i (x, \\omega_i) f_r (x, \\omega_i, \\omega_o) \\cos \\theta_i d\\omega_i$, (1)\nwhere $L_e(x, \\omega_o)$ is the radiance emitted at x in direction $\\omega_o$. The reflected light is computed by integrating over all incident light directions $\\mathbb{H}^+$. $L_i(x, \\omega_i)$ is the incident light, $f_r(x, \\omega_i, \\omega_o)$ is the bidirectional reflectance distribution function, and $\\cos \\theta_i$ is the"}, {"title": "3 RELATED WORK", "content": "Radiance Caching. Since the seminal work of Ward et al. [Ward et al. 1988], numerous advances have been made in caching techniques. Important developments include the widely employed irradiance volumes [Greger et al. 1998] and the introduction of radiance caching [Krivanek et al. 2005] using spherical harmonics for directional domain representation. These methods have seen significant enhancements for both offline [Dubouchet et al. 2017; Marco et al. 2018; Zhao et al. 2019] and real-time rendering [Majercik et al. 2019], and new approaches to processing and storing lighting information [Binder et al. 2018; Pantaleoni 2020; Rehfeld et al. 2014; Scherzer et al. 2012; Silvennoinen and Lehtinen 2017; Vardis et al. 2014]. The popularity of neural networks leads to the Neural Radiance Cache (NRC) [M\u00fcller et al. 2021] which offers a method for dynamic scenes, learning during rendering and leveraging low-cost computation over memory access by utilizing fully-fused neural networks. A combination of NRC with multiresolution hash encodings significantly accelerates training convergence while improving\nthe quality of radiance signal reconstruction [M\u00fcller et al. 2022]. Moreover, pre-trained neural networks have been shown to support dynamic parameters such as mesh positions or light parameters [Diolatzis et al. 2022; Rainer et al. 2022] and still predict a reasonable approximation of global illumination. In contrast to the aforementioned works, we focus on efficient caching of incident radiance, a step that significantly improves rendering performance and lets us use the cache for an efficient unbiased Monte Carlo estimator for real-time rendering.\nNeural Methods. Neural Methods comprise a variety of techniques: Xie et al. [Xie et al. 2022] provide a detailed analysis of such techniques with an emphasis on Neural Radiance Fields (NeRFs) [Mildenhall et al. 2020]. Neural Radiosity [Hadadan et al. 2021] has parallels with traditional radiosity techniques but computes a solution to the rendering equation by applying neural networks to minimize the residuals. Additionally, deep neural networks can be used for guiding path tracing by generating scattering directions [M\u00fcller et al. 2019; Vicini et al. 2019; Zhu et al. 2021] and by this enhancing the efficiency of Monte Carlo integration in light transport simulation.\nControl Variates (CV). A control variate g(x), with a known expected value $E[g(x)]$, can be used to estimate the integral of a function f(x) with:\n$E[f(x)] \\approx E[g(x)] + \\frac{1}{N} \\sum_{i=1}^{N} \\frac{f(X_i) - g(X_i)}{p(X_i)}$ (7)\nwhere $X_i$ are points sampled according to a probability distribution function p. Control Variates show a certain similarity to Multi-Level Monte Carlo, however, they differ in that the expected value $E[g(x)]$ is computed analytically. This is also an inherent limitation: CVs require a mathematical framework for analytical integration over the domain. In our case, the expected value is derived from the cache-based integral in a MLMC framework."}, {"title": "4 NEURAL INCIDENT RADIANCE CACHE", "content": "The computation of $L_i(x, \\omega_i)$ is the most resource-intensive part of Equation (1). This is due to the need to trace rays, find intersection points, fetch surface material parameters and evaluate Equation (1) for a set of positions and directions, which often results in noisy estimations. In this work, we address this problem by firstly splitting $L_i (x, \\omega_i)$ term into indirect lighting part $L_{ind}(x, \\omega_i)$ and direct $L_{nee} (x, \\omega_i)$:\n$L_i (x, \\omega_i) = L_{ind}(x, \\omega_i) + L_{nee} (x, \\omega_i)$ (8)\nsince we will use MIS combination with next event estimation for $L_{nee} (x, \\omega_i)$. Secondly, we propose a cache that approximates $L_{ind}(x, \\omega_i)$ via a neural network while computing the other terms normally:\n$L_{ind} \\approx f_c (x, \\omega_i, \\omega_o, \\phi, w) = n_i(x, \\omega_i, \\phi, w) f_r (x, \\omega_i, \\omega_o) \\cos \\theta_i$. (9)\nHere $n_i (x, \\omega_i, \\phi, w)$ is a neural network with optimizable parameters (weights) w, conditioned on a surface position x, incident vector $\\omega_i$, and a set of additional features $\\phi$ provided for facilitating the search of correlation between target values and input parameters. This function $n_i$ serves as the Neural Incident Radiance Cache (NIRC), approximating incoming lighting from all (hemi)-spherical directions onto a shading point.\nUsing Equation (9), we are able to formulate an unbiased Multi-Level Monte Carlo estimator for computing the rendering equation:\n$L_o(x, \\omega_o) \\approx L_e (x, \\omega_o) + \\hat{L}_c (x, \\omega_o) + \\hat{L}_r (x, \\omega_o)$ (10)\n$\\hat{L}_c(x, \\omega_o) \\approx \\frac{1}{N} \\sum_{i=1}^{N} \\frac{n_i (x, \\omega_i, \\phi, w) f_r (x, \\omega_i, \\omega_o) \\cos \\theta_i}{p(\\omega_i)}$ (11)\n$\\hat{L}_r(x, \\omega_o) \\approx \\frac{1}{N} \\sum_{i=1}^{N} \\frac{(L_i (x, \\omega_i) - n_i(x, \\omega_i, \\phi, w)) f_r (x, \\omega_i, \\omega_o) \\cos \\theta_i}{p(\\omega_i)}$ (12)"}, {"title": "4.1 Neural Network Architecture", "content": "Inspired by previous work we leverage the power of fully-fused executed multi-layer perceptions (MLP) [M\u00fcller et al. 2021] to represent a radiance field. MLP can efficiently approximate signals defined over a five-dimensional manifold conditioned on surface a position (3D) and an outgoing direction (2D), even with real-time performance on GPUs. However the expressive power of a tiny"}, {"title": "4.2 Radiance Cache Optimization", "content": "To effectively optimize the trainable parameters w, we must derive a suitable and practical loss function. Recall that Multi-Level Monte Carlo (MLMC) methods aim to reduce the overall variance of the estimator. This reduction is achievable when the variance of the residual estimator is minimized. The residual estimator $F_r$, Equation (5), which can be defined as $F_r = E [f(x) -f_c(X,w)]$, represents the expectation of the normalized difference between the function\nf and its controlled approximation $f_c$. The variance of $F_r$ is given by\n$V((F_r)) = \\int_\\mathbb{D} \\frac{(f(x) - f_c (x, w) - F_r)^2}{p_r(x)} p_r(x) dx$. (13)\nWe can derive a numerical one-sample estimator for this variance of $(F_r)$ which is then utilized as a loss function:\n$\\langle V((F_r)) \\rangle \\approx \\frac{(f(x) - f_c (x, w)}{p_r(x)} - F_r)^2 \\frac{p_r(x)}{q_r(x)}$ (14)\nHere, $q_r(x)$ denotes the probability density function of the sampling points used for estimating the variance. We employ the same sampling methods for estimating the variance in Equation (14) as well as for estimating the residual error in Equation (5), leading to $q_r = p_r$. This results in the final variance-based loss function:\n$\\langle L_V (f, f_c, w) \\rangle \\approx \\frac{(\\frac{f(x) - f_c (x, w)}{p_r(x)} - F_r)^2}{2}$ (15)\nWe observe that we essentially obtain a squared distance between the cache and ground truth function, offset by the residual error's expectation. This suggests the optimization problem has potentially many solutions for any possible shift value.\nEmpirical experiments shown in Figure 5 highlight the adverse impact of integrating the residual error's expectation into the optimization point, justifying our reliance on the basic squared difference loss function:\n$\\langle L^2 (f, f_c, w) \\rangle = \\frac{(f(x) - f_c (x, w))^2}{p_r(x)}$ (16)\nConsidering the high dynamic range of the data we divide the metric by the squared f(x) to ensure higher gradient weights for dark regions of a rendering scene as in [Lehtinen et al. 2018]:\n$\\langle L_{rel} (f, f_c, w) \\rangle = \\frac{(f(x) - f_c (x, w))^2}{p_r(x) (sg(f_c(x, w)^2) + \\epsilon)}$ (17)"}, {"title": "4.3 Cache application", "content": "Our algorithm follows the megakernel path tracing approach. For each vertex $x_j$, we generate $N_i$ incident vectors $\\omega_i$, where $N_i$ denotes the number of samples of the NIRC at each vertex $x_j$, to estimate the cached radiance term $L_c$. This process requires collecting all per-surface parameters and incident vectors $\\omega_i$. These values are used for both cache estimation and for calculating the additional terms in Equation (11) for $\\omega_i$. To estimate the residual error Equation (12), we need a set of directions $\\omega_i$ which are uncorrelated to the directions used to compute Equation (11).\nWe use independent sampling of $\\omega_i$ according to the surface BSDF for both $L_c$ and $L_r$. Alternative sampling strategies like path guiding for residual integral estimation have been explored in other studies [M\u00fcller et al. 2020]. To keep our study focused, we only employ basic importance sampling here. While we can show an improvement over baseline methods with this approach already, it would be an interesting future extension to perform direction sampling by incident radiance here (for instance by rejection sampling with the NIRC).\nAfter the ray tracing pass, the collected parameters are encoded, aggregated, and utilized in the NIRC inference. The results from the inference are combined with the remaining terms in Equation (11) to compute the final rendered image.\nFor the training of our cache, we follow the algorithm of the original Neural Radiance Cache [M\u00fcller et al. 2021]. A significant modification is that we use a separate rendering pass for training. This decision is based on the following observation: using training paths derived directly from the main path tracing paths leads to performance issues in our implementation. Training requires us to trace paths of unbounded length to remain unbiased (by using Russian roulette). Since the main rendering paths are considerably shorter in our biased version, this results in thread divergence. We found that executing a separate path tracing pass for training paths not only simplifies the process but also slightly improves performance. While there will still be thread divergence due to differing path lengths, given that we only use about 2-3% the number of training paths as compared to the number of pixels, this additional pass does not incur substantial overhead. This method ensures efficient training of the cache while maintaining the integrity and performance of the main rendering process."}, {"title": "4.4 Path Termination Heuristics", "content": "The original NRC uses the Spread Angle Heuristic (SPH) for path termination, which almost always results in path termination after the first bounce, as shown in Figure 12. This suggests that we can leverage our cache instantly at the primary bounce without the need for this intermediate bounce since our cache predicts incident radiance directly.\nThe NRC path termination heuristic is defined as follows:\n$\\alpha(x_1... x_n) = \\prod_{i=2}^{n} \\frac{||x_{i-1}-x_{i}||}{p(\\omega_i | x_{i-1}, \\omega_i) \\cos \\theta_i} (18)$\n$\\alpha_0 = \\frac{||x_0 - x_1 ||^2}{4\\pi \\cos \\theta_1}$ (19)\nwhere $p(\\omega_i)$ is the BSDF sampling PDF and $\\theta_i$ is the angle between $\\omega_i$ and the surface normal at $x_i$. Paths are terminated if:\n$\\alpha(x_1...x_n) > c \\alpha_0$, (20)\nwhere c is a hyperparameter equal to 0.01.\nThis heuristic is not directly applicable in our setting since we want the ability to terminate on the first directly visible path vertex. We propose a new criterion inspired by the balance heuristic [Veach and Guibas 1995], which we call the Balanced Termination Heuristic (BTH). The BTH leverages the strengths of NIRC while acknowledging its limitations, particularly with glossy details. It essentially computes the MIS weight of BRDF sampling vs. a virtual diffuse sampling scheme with $N_c$ samples. We calculate the continuation probability $P_s$ as:\n$P_s = \\frac{p(\\omega_i)}{p(\\omega_i) + \\frac{N_c}{\\pi}}$ (21)\nwhere $p(\\omega_i)$ is the pdf of the sampled scattering direction, and $N_c$ is the number of neural samples. The path termination criteria are as follows:\ni = 1: stop if $\\xi > P_s$, (22)\ni > 1: stop if $\\xi > P_s$ or $\\alpha(x_1...x_i) > c \\alpha_0$,\nwhere $\\xi \\in [0, 1)$ is a uniformly distributed random variable. If terminated, the current surface is shaded using $N_c$ directions sampled according to the surface BRDF, incorporating direct lighting with Monte Carlo integration using Multiple Importance Sampling (MIS) and Next Event Estimation (NEE). Delta reflections automatically continue tracing without termination. For a fair comparison with NRC, we use its heuristic for all surfaces $x_i$ where i > 1, ensuring that paths are not terminated later than they would be with NRC."}, {"title": "5 NEURAL VISIBILITY CACHE", "content": "In the previous section, we addressed the computation of incident illumination from other surfaces. While this approach works for the special case of lighting from an environment map, this type of illumination is important enough to warrant special treatment to improve efficiency. In particular, for environment map lighting we know that the incident radiance is the product of visibility V and environment illumination Li: $V(x_i, x_{i+1}) L_i (x_i, , x_{i+1})L_i (x_i, \\omega_i)$. Since $L_i$ is known from the scene definition we only have to find V. For that purpose, we propose a specialized Neural Visibility Cache (NVC) which is trained to only estimate the visibility term instead of the final radiance signal. V takes on values between zero and one (potentially including partial visibility due to transparency or transmittance in volumes), so we use a sigmoidal activation function on the output neurons of the NVC. Further details and empirical observations related to this approach are discussed in Section 6.2."}, {"title": "7 DISCUSSION AND FUTURE WORK", "content": "Examining the quality of NIRC. The decision to store incident radiance in our cache, as opposed to outgoing radiance in Neural Radiance Caching (NRC), is an inherent challenge for the model as it effectively has to learn the geometrical structure of a scene. As we discussed earlier this can lead to missed local reflection effects and impact performance with highly specular surfaces. When comparing converged renders using the biased estimators based on NRC"}, {"title": "8 CONCLUSION", "content": "In this paper, we presented a two-level Monte Carlo estimator for real-time global illumination rendering. We train and evaluate tiny neural networks on the fly to approximate incident radiance, as the first level of the estimator. A second level is used to create an unbiased estimator in the context of multi-level Monte Carlo. We also present a biased variant which can reduce the residual error further in the same rendering time. Both variants produce lower errors in equal time comparisons in most experiments than previously published work on neural radiance caching [M\u00fcller et al. 2021]. In addition, our experiments revealed that combining the MLMC framework with NIRC can offset integration costs while achieving superior variance reduction of the residual error estimator compared to Control Variates. Our key insights to achieving this are a data representation that stores incident radiance (avoiding a costly ray trace to determine visibility when querying the cache), a carefully selected set of inputs to the neural network (producing more accurate output to support this new storage), and a tightly coupled implementation that avoids round trips to global memory where possible. Our comprehensive cache analysis further demonstrated that we can significantly reduce the number of rays traced for indirect illumination by leveraging our cache, leading to more efficient rendering without significantly sacrificing quality.\nWe found that the allocation of sample counts for path vertices along a transport path influences the final variance significantly and should be investigated in more detail. This concept aligns with principles previously explored in classical light transport simulations, as demonstrated in the previous works [Rath et al. 2022] [Vorba and K\u0159iv\u00e1nek 2016].\nWe only experimented with dynamic scene content but did not specifically optimize the cache to quickly react to drastic changes. For instance, distributing the training workload more into regions of the cache that have low quality might improve the results. Utilizing hierarchical caches has the potential to more quickly distribute information about light sources in the scenes, and could provide interesting interplay with the multi-level Monte Carlo paradigm. We believe that research in this area promises to be applicable for real-time and offline rendering."}]}