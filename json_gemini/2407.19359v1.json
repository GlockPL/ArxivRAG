{"title": "Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction", "authors": ["Yuan Xue", "Nan Du", "Anne Mottram", "Martin Seneviratne", "Andrew M. Dai"], "abstract": "The paradigm of 'pretraining' from a set of relevant auxiliary tasks and then 'finetuning' on a target task has been successfully applied in many different domains. However, when the auxiliary tasks are abundant, with complex relationships to the target task, using domain knowledge or searching over all possible pretraining setups is inefficient and suboptimal. To address this challenge, we propose a method to automatically select from a large set of auxiliary tasks, which yields a representation most useful to the target task. In particular, we develop an efficient algorithm that uses automatic auxiliary task selection within a nested-loop meta-learning process. We have applied this algorithm to the task of clinical outcome predictions in electronic medical records, learning from a large number of self-supervised tasks related to forecasting patient trajectories. Experiments on a real clinical dataset demonstrate the superior predictive performance of our method compared to direct supervised learning, naive pretraining and simple multitask learning, in particular in low-data scenarios when the primary task has very few examples. With detailed ablation analysis, we further show that the selection rules are interpretable and able to generalize to unseen target tasks with new data.", "sections": [{"title": "1 Introduction", "content": "The wide adoption of electronic medical record (EMR) systems has generated large repositories of patient data in the form of multivariate time-series. These data are increasingly used for supervised learning, with the goal of providing decision support to clinicians by predicting clinical outcomes for individual patients [1]. Recent examples have focused on the prediction of inpatient mortality [2], acute kidney injury [3], circulatory shock [4], etc.\nOne major challenge with EMR modeling is that the raw data is high-dimensional, noisy, sparse and heterogeneous, as it is generated in the course of routine clinical care [5]. Furthermore, accurately labeling clinical endpoints can be extremely challenging and often requires time-consuming manual chart review by clinicians, meaning that modeling must be data efficient. Even in cases where the outcome label is more clearly encoded, e.g. mortality, data availability is often still an issue as there are only a limited number of patients with that outcome in a selected cohort.\nTo tackle these issues of data quality and label shortage, a common approach widely applied in computer vision (CV) and natural language processing (NLP) domains is pretraining and finetuning. Pretraining involves learning a compact representation on related tasks with abundant data. These learned representations can then be finetuned on the primary task with limited labels, assisting supervised performance by leveraging prior knowledge.\nEMRs contain thousands of different laboratory tests, observations, medications, procedures etc., for each patient over time. Using the trajectories of these time series data as self-supervised objectives provides a promising way to learn a useful patient representation. However, naively pretraining across"}, {"title": "2 Learning Tasks", "content": "In a longitudinal EMR dataset, a patient's record is a collection of sequential clinical-visit data which can be naturally represented as multi-variate time series. Each time series captures the readings over time from one type of clinical measurement (e.g., blood pressure, lactate, etc.), or intervention (e.g., ventilator settings). For a given patient, we use xf to represent the fth feature value f \u2208 F at the\ntime step t. $x_f = \\{x_f^t\\}_{t=1}^T$ denotes the fth time series, and T is the number of time steps. We also\nuse xt as the |F|-dimensional feature vector at the time t.\nPrimary supervised task: Clinical outcome prediction. For each sequence $\\{x_t\\}_{t=1}^T$, there is an\nassociated label y representing the occurrence of a clinical outcome of interest, e.g., sepsis, shock,\nmortality, etc. The goal is to learn a model that predicts the most likely label value \u0177 for a given input\nsequence $\\{x_t\\}_{t=1}^T$. The learning process thus takes the standard form of supervised learning with a\nloss l(\u0177, y) associated with the model.\nAuxiliary task: Trajectory forecast. The goal of the trajectory forecast task is to model the\ndistribution of the future values of raw EMR data elements p(x\u03c4+1:\u03c4+H|x1:\u03c4) given the past history\nx1:\u03c4. Here, \u03c4 is the time of prediction, H represents the number of time steps we look into the future,\nand $x_{\\tau+1:\\tau+H} = \\{x_f^{\\tau+h}\\}_{h=1}^H$. This task by nature takes the form of self-supervised learning since\nthe future values of a time series can be easily treated as the learning signal. Compared to the clinical\noutcome prediction task, the patient's trajectory forecast task requires no human labels, and many\npowerful self-supervised techniques can be applied to the task [6-13].\nWe can expect that pretraining with self-supervised trajectory forecast tasks for each feature f \u2208 F\nwill produce useful patient representations for the clinical outcome prediction task which often has\nfew examples. However, when the set of auxiliary tasks |F| is large, both joint pretraining using all\nthe tasks in F, or successive pretraining in an iterative way, can be sub-optimal and inefficient in that\nnot all the auxiliary tasks are equally useful for transferring knowledge to the target primary task,\nleading to a less informative representation for downstream tasks."}, {"title": "3 Automatic Task Selection", "content": "We study the problem of learning to select the most relevant trajectory forecast tasks so that the\nlearned representation is optimized for improving the performance of the target clinical outcome\nprediction task (schematic in Figure 1). In the following sections, we present our problem formulation,\nmodel design, and learning algorithms."}, {"title": "3.1 Problem Formulation", "content": "Selecting the optimal subset of auxiliary trajectory forecast tasks from F requires exploring 2||\ncombinations, which is prohibitive in practice. To make the search space continuous, we relax"}, {"title": "3.2 Bi-level Optimization", "content": "The optimization of the meta objective 2 determines the quality of the learned representation from\nthe encoder with parameter \u03b8eNp, and it includes two loops of learning processes shown in Figure 1.\nGiven a fixed \u03bb as one configuration, the inner loop first finds a candidate representation through\nthe self-supervised learning on the trajectory forecast tasks, some of which receives more attention\nwhile others may be discarded. It then finetunes the representation via supervised learning on the\nclinical outcome prediction task. The quality of the learned representation is measured by the meta\nobjective of the outer loop. The outer loop then updates the configuration of the inner loop to locate a"}, {"title": "4 Experiments", "content": "We evaluate our proposed algorithm, referred to as AutoSelect, using the openly accessible\nMIMIC-III dataset [17] which contains over 38,000 adult patients admitted to the intensive\ncare unit. We select a set of 96 common clinical measurements, which constitutes the set\nof candidate auxiliary tasks used for trajectory forecast. All values were normalized using z-\nscore, and missing values were imputed by carrying forward the last observation. Yet, the\nmodel is always trained only using the true values as the targets instead of the imputed values.\nWe consider three primary supervised learning\ntasks defined using the criteria in Table 1. The\nprediction uses data from the first 48 hours of the\nICU admission, and the label is positive if the cri-\nteria are fulfilled within the next 48 hour window\n(i.e. 48-96 hours post admission). Moreover, the\nevent sequence of each patient is also restricted to\na window of 48 hours in the past, so that the bias\ntowards longer stays can be alleviated. For simplicity, the latter two organ failure tasks are defined in\na lightweight manner following the SOFA score criteria [18]. We report the details of the inclusion\nand exclusion criteria, the cohort and feature statistics, data preprocessing methods and results on\nadditional tasks in the Appendix."}, {"title": "4.1 Baselines and Experiment Setting", "content": "Supervised Learning. We train a single baseline model with exactly the same architecture as the\nmodel used for the primary tasks of Table 1 in AutoSelect. Given that these primary tasks often have\nlow resources, we expect supervised learning to have low predictive performance in general.\nPretraining (All). This is the same pretraining-and-finetuning paradigm as in the work of [19]. We\nfirst learn the patient representation by pretraining using all the 96 self-supervised trajectory forecast\ntasks, and then finetune the model on the target tasks in Table 1.\nCoTrain via Multitask Learning. This is a simple widely used multitask learning setup. We first\ncotrain the target task with all the auxiliary tasks, and use a task weight hyperparameter to balance the\nlosses between these two groups of tasks. We set the weight of the target loss to be 10 tuned by the\nvalidation set performance to make the losses in the same scale, and the auxiliary task has a weight of\n1. After the co-training stage, we finetune the model using only the data of the primary task.\nExperimental Setup. The sequence-to-sequence architecture of the trajectory forecast task uses an\nLSTM for both encoder and decoder, where the hidden state has a dimension of 70. For the primary\nclinical outcome prediction task, the decoder is replaced by a simple 1-layer MLP as the classification\nhead. All the baselines and our method use the same architecture. This does not prevent our method\nfrom using more advanced architectures. All models were implemented* in TensorFlow [20].\nFor the direct supervised learning baseline, we use early stopping with the validation set to avoid\noverfitting. For all the experiments of the other approaches, we run approximately 5,000 steps during\nthe pretraining stage, followed by 5 epochs for finetuning. For AutoSelect, these 5,000 steps are\nfurther divided between inner loop steps and outer meta-learning steps, so that the total number of\ntraining steps is consistent with other pretrained methods for fair comparison. The learning rates\nof all training loops were tuned and are 0.001 for supervised learning, 0.005 for self-supervised\nlearning, 0.01 for \u03bb hyper-gradient update. Detailed hyperparameter tuning process is reported in the\nAppendix. Finally, we use 10-fold cross validation and estimate the standard error of the mean. For\neach fold, we split the dataset into train/validation/test according to 80%/10%/10% based on the hash\nvalue of the patient ID, and AUC-ROC is used as the evaluation metric by default with standard error\nreported in the parentheses next to it."}, {"title": "4.2 Performance Comparison of Clinical Outcome Prediction", "content": "Table 2 shows the results of gradually adding more training data by taking 1%, 10% and 100% from\nthe original train dataset. We first observe that the performance of all methods in all tasks increases\nas more training data from the primary task are used. In the low resource regime, \u2018Pretrain (All)' has\nbetter performance than naive supervised learning, which is expected since it can transfer knowledge\nby learning from the auxiliary trajectory forecast tasks. Second, we also observe that the 'CoTrain'\nbaseline has a hard time to balance all the 96 self-supervised trajectory forecasts and the supervised\noutcome prediction task even if it has an additional finetuning process. More sophisticated mixing\nratios are thus needed to reconcile the different training speed of each task. Finally, we further\ncompare AutoSelect to the two-stage pipeline approach [21] in the extreme case of using 1% of the"}, {"title": "4.3 Ablation Study", "content": "What tasks are selected? We now examine the pretraining tasks that were assigned with higher\nweights in the meta learning process shown in Figure 2b. The following features were consistently\nranked within the top 20 across different training data splits for mortality prediction: invasive and\nnon-invasive blood pressures, heart rate, anion gap, respiratory rate (Full list is available in the\nAppendix). These represent a mixture of common vital signs and laboratory values that are clinically\nsensible correlates for mortality. Indeed, there is significant overlap with the input features for\nclassical risk scores that have been validated as mortality predictors in intensive care (e.g. APACHE\nII [22]). The top features for the other two supervised tasks, kidney dysfunction and low blood\npressure, are detailed in the Appendix. Notably, the top features for low blood pressure include all\navailable blood pressure recordings; however in the kidney dysfunction task, creatinine, which is the\nlaboratory value on which the outcome is defined, does not appear in this top list. Our hypothesis is\nthat creatinine is measured sparsely - typically once every 24 hours - thus providing a weak signal\nover the 48 hour window of the self-supervising trajectory forecast task.\nHow good are the selected tasks? To further validate the quality of top selected tasks and evaluate\nthe impact of these features as pretraining tasks on the supervised outcome, we have conducted two\nablation studies. In the first, we pretrain the encoder using the top selected auxiliary tasks only,\nreferred to as 'Pretrain (Top)'. In the second, we instead pretrain the model with the remaining\nauxiliary tasks excluding the top ones, referred to as 'Pretrain (Down)'. The hypothesis is that the top\nselected tasks already capture the necessary knowledge needed to optimize the performance of the\ntarget task, while the remaining ones are less important. We report the results of these two studies in\nTable 3. It shows that 'Pretrain (Top)' performs closer to AutoSelect and is consistently better than\n'Pretrain (Down)' and 'Pretrain (Full)', suggesting that the top selected tasks are able to transfer the\nmost useful information to the target task. Meanwhile, we also observe that 'Pretrain (Down)' has\nsimilar performance to \u2018Pretrain (Full)' showing that the useful signals are indeed overshadowed in\nthe learned representation with the full set of tasks.\nHow does the learning occur? Figure 2a presents the training dynamics of AutoSelect for the\nmortality task as an example. During the pretraining stage, its performance measured by AUC-ROC\nin the validation set keeps improving and then jumps even higher when the finetuning stage starts at\nstep 5,500 when the validation performance of the auxiliary tasks reaches the peak. The performance\nof mortality prediction then quickly decreases due to overfitting to its small finetuning data. The\nblue curve represents the learning process of \u2018Pretrain (All)'. Because the mortality task was not\ninvolved in the pretraining stage, it only starts from the beginning of finetuning. The yellow curve\nis the process of \u2018CoTrain', where the validation performance of the mortality task first jumps and\nthen decreases during the pretraining period. This is caused by the learning speed difference among\nall the tasks where the training of the small primary task starts to overfit while that of the other\nauxiliary tasks still improves. Finally, we study the impact of different training steps of the nested\nlearning loops of AutoSelect. By fixing the total number of iterations around 5,000, in Figure 2c, we\nexplore different configurations by varying the number of self-supervised training iterations (NP) at\nthe inner loop from 1,000 steps to 10 steps where (1,000/5) means 1,000 inner loop iterations and 5\nouter loop iterations. In addition, the inner supervised training loop (Ns) is configured to take 1/10\nof the self-supervised iterations (NP). We observe AutoSelect is generally robust across different\nconfigurations, and sweet points seem to be around (100/50) and (50/100)."}, {"title": "How does AutoSelect generalize?", "content": "Finally, we look at how well the learned weights of the auxiliary\ntasks guided by a given target task are able to generalize to unseen new tasks. We first use the\nmortality prediction task as the given primary task to guide the selection of the auxiliary trajectory\nforecast tasks. Then, we treat BP and KD as two new tasks, and directly finetune the model using 1%\nand 10% of the train data respectively. The reason is that, from a clinical perspective, mortality is a\nmore general endpoint than specific dysfunctions. The hypothesis is that representations learned on\nthe more general endpoint of mortality will be useful for more specific tasks. The prediction results\nare given in the top row of Table 3. Despite training only on the mortality task, the learned weights\nof the auxiliary tasks are able to improve the performance of BP and KD compared to the 'Pretrain\n(All)' baseline. Next, we use BP and KD to guide the selection learning separately, and then test on\nthe mortality task at the bottom of Table 3. Since the specific dysfunction does not always imply an\nendpoint of mortality, the predictive performance on mortality is slightly worse than the respective\nresults of AutoSelect."}, {"title": "5 Related Work", "content": "Multi-Task Learning and Task selection. Recent research on multitask learning [23] aims at either\ngeneralizing from a source multitask learning domain to a target multitask domain [24], or learning\na good trade-off among different tasks [25]. There have been approaches to the task scheduling\nproblem via a separate two-stage pipeline [21, 26], and Requeima et al. [27] learns to adjust model\narchitectures to automatically adapt to new tasks. Doersch and Zisserman [28] combines multiple\nself-supervised tasks to train useful visual representations. Being complementary, our method learns\nto automatically select a set of auxiliary tasks, each of which is a self-supervised time-series learning\nproblem, so that pretraining on these tasks can lead to a better representation for a target supervised\nlearning task in an end-to-end differentiable framework.\nMeta learning. Meta learning [29-32] seeks to acquire an initialization optimized for a set of tasks\nfrom the same distribution [33-35, 32]. One challenge of meta learning frameworks is that they\nrely on manually-defined training tasks, and hand-crafting these tasks can be time-consuming. The\nwork of [33] presents unsupervised methods for inducing an adaptive meta-training task distribution\nand the work of [34] automatically constructs tasks from unlabeled data. We address this challenge\nvia automatic selection over a large number of self-supervised tasks. Our method is similar in spirit\nto the work of [35] in that both direct the meta-learning process using a supervised target task,\nbut we differ in that [35] meta-learns an unsupervised learning rule, while our work meta-learns a\nself-supervised task weight distribution.\nPatient Representation Learning. The self-supervised task in our work is related to recent progress\non state representation learning especially via patient trajectories [7-10]. The objectives in these\nworks are often reconstruction errors in the entire observation space, and thus are not incentivized to\ncapture latent factors that are useful for downstream tasks. To address this issue, the work of [36, 37]\nlearn state representations by predicting the future in latent space with a probabilistic contrastive loss,\nwhile our work directs the representation learning by reducing error on a downstream target task."}, {"title": "6 Conclusion", "content": "We demonstrate how to leverage trajectory forecasts over clinical observations as self-supervised\npretraining tasks to improve the quality of clinical outcome predictions. We present an efficient"}, {"title": "7 Broader Impact", "content": "This work presents a method for efficiently learning patient representations using EMR data. Although\nthis is demonstrated with a subset of the full raw EMR, and for only a handful of clinical outcomes\nin intensive care patients, it is a proof-of-concept that may be useful for a range of other predictive\nmodeling using various types of longitudinal health data. The impact may be greatest in low-data\nscenarios - e.g. clinical use-cases where labeling is very challenging or where there are few eligible\npatients in the EMR. The code for this method will be made available to the research community on\nGitHub.\nThere are numerous ethical considerations associated with any EMR modeling, which have been\ndiscussed in the literature [38, 39]. Issues include numerous biases in the observational EMR data,\ne.g. on the basis of gender, ethnicity or socioeconomic status, which can propagate into predictive\nmodels. These fairness considerations also apply to representation learning architectures as presented\nhere.\nFinally, if this method were to be brought forward to real world deployment in conjunction with\na decision support tool, it would have to be subject to appropriate clinical safety review and trials\nacross different populations, with consideration given to issues such as drift and robustness."}, {"title": "8 Appendix", "content": "8.1 Full Algorithm\nBased on Equation 10 to 12, the gradient of \u03bb (Equation 8) can be solely determined by the signals of\nboth \u03b1 and \u03b2. The full algorithm is given in Algorithm 2."}, {"title": "8.2 Dataset and Data Preprocessing", "content": "We evaluate our proposed algorithm using the open access MIMIC-III dataset [17] which contains\npatients admitted to the intensive care unit of Beth Israel Deaconess Medical Center between 2001\nand 2012.\nThere are 38,485 adult inpatient encounters included in the study. Supervised tasks were triggered at\n48 hrs after ICU admission with a lookahead horizon of 48 hours (i.e. 48-96 hours post admission)\nfor the following endpoints: inpatient mortality, renal and liver failure, and circulatory shock. For this\nproof of concept work, the latter three organ failure endpoints were defined in a lightweight manner"}, {"title": "8.3 Hyperparameters and Selections", "content": "The learning rates of all training loops were tuned jointly with the state size of LSTM via a grid\nsearch. Table 6 shows the list of values considered, the criteria we use in choosing the hyperparameter\nand the final value selection."}, {"title": "8.4 Additional Experiment Results", "content": "Table 7 provides predictive performance (AUC-ROC) over the additional Liver Failure prediction task\nalong with the other three tasks. We also report the AUC-PR (i.e., Average Precision (AP)) of different\ncompeting methods for the four primary outcome prediction tasks under consideration in Table 8. As\nwe could see, AutoSelect outperforms both \u2018Pretrain (All)' and 'CoTrain' by a significantly large\nmargin in low-data scenarios for all four tasks with respect to both metrics."}, {"title": "8.5 Top Tasks", "content": "The features that are associated with the top trajectory forecast auxiliary tasks for each primary task\nare listed in Table 9."}]}