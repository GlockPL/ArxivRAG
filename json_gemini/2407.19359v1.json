{"title": "Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction", "authors": ["Yuan Xue", "Nan Du", "Anne Mottram", "Martin Seneviratne", "Andrew M. Dai"], "abstract": "The paradigm of 'pretraining' from a set of relevant auxiliary tasks and then 'finetuning' on a target task has been successfully applied in many different domains. However, when the auxiliary tasks are abundant, with complex relationships to the target task, using domain knowledge or searching over all possible pretraining setups is inefficient and suboptimal. To address this challenge, we propose a method to automatically select from a large set of auxiliary tasks, which yields a representation most useful to the target task. In particular, we develop an efficient algorithm that uses automatic auxiliary task selection within a nested-loop meta-learning process. We have applied this algorithm to the task of clinical outcome predictions in electronic medical records, learning from a large number of self-supervised tasks related to forecasting patient trajectories. Experiments on a real clinical dataset demonstrate the superior predictive performance of our method compared to direct supervised learning, naive pretraining and simple multitask learning, in particular in low-data scenarios when the primary task has very few examples. With detailed ablation analysis, we further show that the selection rules are interpretable and able to generalize to unseen target tasks with new data.", "sections": [{"title": "1 Introduction", "content": "The wide adoption of electronic medical record (EMR) systems has generated large repositories of patient data in the form of multivariate time-series. These data are increasingly used for supervised learning, with the goal of providing decision support to clinicians by predicting clinical outcomes for individual patients [1]. Recent examples have focused on the prediction of inpatient mortality [2], acute kidney injury [3], circulatory shock [4], etc.\nOne major challenge with EMR modeling is that the raw data is high-dimensional, noisy, sparse and heterogeneous, as it is generated in the course of routine clinical care [5]. Furthermore, accurately labeling clinical endpoints can be extremely challenging and often requires time-consuming manual chart review by clinicians, meaning that modeling must be data efficient. Even in cases where the outcome label is more clearly encoded, e.g. mortality, data availability is often still an issue as there are only a limited number of patients with that outcome in a selected cohort.\nTo tackle these issues of data quality and label shortage, a common approach widely applied in computer vision (CV) and natural language processing (NLP) domains is pretraining and finetuning. Pretraining involves learning a compact representation on related tasks with abundant data. These learned representations can then be finetuned on the primary task with limited labels, assisting supervised performance by leveraging prior knowledge.\nEMRs contain thousands of different laboratory tests, observations, medications, procedures etc., for each patient over time. Using the trajectories of these time series data as self-supervised objectives provides a promising way to learn a useful patient representation. However, naively pretraining across"}, {"title": "2 Learning Tasks", "content": "In a longitudinal EMR dataset, a patient's record is a collection of sequential clinical-visit data which can be naturally represented as multi-variate time series. Each time series captures the readings over time from one type of clinical measurement (e.g., blood pressure, lactate, etc.), or intervention (e.g., ventilator settings). For a given patient, we use $x_t^f$ to represent the $f$th feature value $f \\in F$ at the time step $t$. $x^f = \\{ x_t^f \\\\}_{t=1}^T$ denotes the $f$th time series, and $T$ is the number of time steps. We also use $x_t$ as the $|F|$-dimensional feature vector at the time $t$.\nPrimary supervised task: Clinical outcome prediction. For each sequence $\\{x_t\\}_{t=1}^T$, there is an associated label $y$ representing the occurrence of a clinical outcome of interest, e.g., sepsis, shock, mortality, etc. The goal is to learn a model that predicts the most likely label value $\\hat{y}$ for a given input sequence $\\{x_t\\}_{t=1}^T$. The learning process thus takes the standard form of supervised learning with a loss $l(\\hat{y}, y)$ associated with the model.\nAuxiliary task: Trajectory forecast. The goal of the trajectory forecast task is to model the distribution of the future values of raw EMR data elements $p(x_{\\tau+1:\\tau+H}|x_{1:\\tau})$ given the past history $x_{1:\\tau}$. Here, $\\tau$ is the time of prediction, $H$ represents the number of time steps we look into the future, and $x_{\\tau+1:\\tau+H} = \\{ x_{\\tau+i}^f \\\\}_{i=1}^H$. This task by nature takes the form of self-supervised learning since the future values of a time series can be easily treated as the learning signal. Compared to the clinical outcome prediction task, the patient's trajectory forecast task requires no human labels, and many powerful self-supervised techniques can be applied to the task [6-13].\nWe can expect that pretraining with self-supervised trajectory forecast tasks for each feature $f \\in F$ will produce useful patient representations for the clinical outcome prediction task which often has few examples. However, when the set of auxiliary tasks $|F|$ is large, both joint pretraining using all the tasks in $F$, or successive pretraining in an iterative way, can be sub-optimal and inefficient in that not all the auxiliary tasks are equally useful for transferring knowledge to the target primary task, leading to a less informative representation for downstream tasks."}, {"title": "3 Automatic Task Selection", "content": "We study the problem of learning to select the most relevant trajectory forecast tasks so that the learned representation is optimized for improving the performance of the target clinical outcome prediction task (schematic in Figure 1). In the following sections, we present our problem formulation, model design, and learning algorithms."}, {"title": "3.1 Problem Formulation", "content": "Selecting the optimal subset of auxiliary trajectory forecast tasks from $F$ requires exploring $2^{|F|}$ combinations, which is prohibitive in practice. To make the search space continuous, we relax"}, {"title": "3.2 Bi-level Optimization", "content": "The optimization of the meta objective 2 determines the quality of the learned representation from the encoder with parameter $\\theta_e$, and it includes two loops of learning processes shown in Figure 1.\nGiven a fixed $\\lambda$ as one configuration, the inner loop first finds a candidate representation through the self-supervised learning on the trajectory forecast tasks, some of which receives more attention while others may be discarded. It then finetunes the representation via supervised learning on the clinical outcome prediction task. The quality of the learned representation is measured by the meta objective of the outer loop. The outer loop then updates the configuration of the inner loop to locate a"}, {"title": "3.3 Efficient Gradient-based Learning Algorithm", "content": "Exact evaluation of Equation 8 is expensive in that $\\nabla_{\\theta_e} \\Psi$ ($\\theta_{e}^{i-1}, \\theta_{d}^{i-1}, \\lambda$) and $\\nabla_{\\theta} \\Phi^{i+1}$ ($\\theta_{e}^{i}, \\theta_{c}^{i}$) include the Jacobian and Hessian matrix of the gradient update operation $\\Psi^i$ and $\\Phi^{i+1}$. Motivated by related techniques in [16], we propose an efficient first-order approximation to Equation 8. More specifically, given that $\\theta^S = I_{train} (\\theta_{e}^{NP})$ = $\\theta_{e}^{NP+Ns-1}$ - $\\eta \\nabla_{\\theta_e} l_{train}$ in Equation 2, the gradients $\\{\\nabla_{\\theta_e} l_{train}\\}$ are treated as constants [16]. By applying the chain rule with the gradient approximation, we can have\n$$\n\\frac{\\partial l_{val}}{\\partial \\lambda} = \\frac{\\partial l_{val} (\\theta_{e}^{N_S}, \\theta_{c}^{N_S})}{\\partial \\theta_{e}^{N_S}} \\frac{\\partial \\theta_{e}^{N_S}}{\\partial I_{train} (\\theta_{e}^{NP})} \\frac{\\partial I_{train} (\\theta_{e}^{NP})}{\\partial \\theta_{e}^{NP}} \\frac{\\partial l_{train} (\\theta_{e}^{NP}, \\theta_{d}^{NP} | \\lambda)}{\\partial \\lambda}, \n$$\nwhere we have $\\frac{\\partial \\theta_{e}^{N_S}}{\\partial I_{train} (\\theta_{e}^{NP})}$ to be the identity matrix due to the gradient approximation, $\\frac{\\partial I_{train} (\\theta_{e}^{NP})}{\\partial \\theta_{e}^{NP}} = 1/\\frac{\\partial^2 l_{train} (\\theta_{e}^{NP}, \\theta_{d}^{NP} | \\lambda)}{\\partial {\\theta_{e}^{NP}}^2}$ which can be simply achieved at the end of the self- supervised training, and $\\frac{\\partial l_{train} (\\theta_{e}^{NP}, \\theta_{d}^{NP} | \\lambda)}{\\partial \\lambda}$ can be obtained via back-propagation. The overall first-order approximation algorithm is given in Algorithm 1. After the joint training, there will be a final round of finetuning on the target task alone. Experimentally, we find this stage is useful when the target task has very few examples, and its contribution decreases as more training examples become available."}, {"title": "4 Experiments", "content": "We evaluate our proposed algorithm, referred to as AutoSelect, using the openly accessible MIMIC-III dataset [17] which contains over 38,000 adult patients admitted to the intensive care unit. We select a set of 96 common clinical measurements, which constitutes the set of candidate auxiliary tasks used for trajectory forecast. All values were normalized using z-score, and missing values were imputed by carrying forward the last observation. Yet, the model is always trained only using the true values as the targets instead of the imputed values. We consider three primary supervised learning tasks defined using the criteria in Table 1. The prediction uses data from the first 48 hours of the ICU admission, and the label is positive if the cri- teria are fulfilled within the next 48 hour window (i.e. 48-96 hours post admission). Moreover, the event sequence of each patient is also restricted to a window of 48 hours in the past, so that the bias towards longer stays can be alleviated. For simplicity, the latter two organ failure tasks are defined in a lightweight manner following the SOFA score criteria [18]. We report the details of the inclusion and exclusion criteria, the cohort and feature statistics, data preprocessing methods and results on additional tasks in the Appendix."}, {"title": "4.1 Baselines and Experiment Setting", "content": "Supervised Learning. We train a single baseline model with exactly the same architecture as the model used for the primary tasks of Table 1 in AutoSelect. Given that these primary tasks often have low resources, we expect supervised learning to have low predictive performance in general.\nPretraining (All). This is the same pretraining-and-finetuning paradigm as in the work of [19]. We first learn the patient representation by pretraining using all the 96 self-supervised trajectory forecast tasks, and then finetune the model on the target tasks in Table 1.\nCoTrain via Multitask Learning. This is a simple widely used multitask learning setup. We first cotrain the target task with all the auxiliary tasks, and use a task weight hyperparameter to balance the losses between these two groups of tasks. We set the weight of the target loss to be 10 tuned by the validation set performance to make the losses in the same scale, and the auxiliary task has a weight of 1. After the co-training stage, we finetune the model using only the data of the primary task.\nExperimental Setup. The sequence-to-sequence architecture of the trajectory forecast task uses an LSTM for both encoder and decoder, where the hidden state has a dimension of 70. For the primary clinical outcome prediction task, the decoder is replaced by a simple 1-layer MLP as the classification head. All the baselines and our method use the same architecture. This does not prevent our method from using more advanced architectures. All models were implemented* in TensorFlow [20].\nFor the direct supervised learning baseline, we use early stopping with the validation set to avoid overfitting. For all the experiments of the other approaches, we run approximately 5,000 steps during the pretraining stage, followed by 5 epochs for finetuning. For AutoSelect, these 5,000 steps are further divided between inner loop steps and outer meta-learning steps, so that the total number of training steps is consistent with other pretrained methods for fair comparison. The learning rates of all training loops were tuned and are 0.001 for supervised learning, 0.005 for self-supervised learning, 0.01 for A hyper-gradient update. Detailed hyperparameter tuning process is reported in the Appendix. Finally, we use 10-fold cross validation and estimate the standard error of the mean. For each fold, we split the dataset into train/validation/test according to 80%/10%/10% based on the hash value of the patient ID, and AUC-ROC is used as the evaluation metric by default with standard error reported in the parentheses next to it."}, {"title": "4.2 Performance Comparison of Clinical Outcome Prediction", "content": "Table 2 shows the results of gradually adding more training data by taking 1%, 10% and 100% from the original train dataset. We first observe that the performance of all methods in all tasks increases as more training data from the primary task are used. In the low resource regime, \u2018Pretrain (All)' has better performance than naive supervised learning, which is expected since it can transfer knowledge by learning from the auxiliary trajectory forecast tasks. Second, we also observe that the 'CoTrain' baseline has a hard time to balance all the 96 self-supervised trajectory forecasts and the supervised outcome prediction task even if it has an additional finetuning process. More sophisticated mixing ratios are thus needed to reconcile the different training speed of each task. Finally, we further compare AutoSelect to the two-stage pipeline approach [21] in the extreme case of using 1% of the"}, {"title": "4.3 Ablation Study", "content": "What tasks are selected? We now examine the pretraining tasks that were assigned with higher weights in the meta learning process shown in Figure 2b. The following features were consistently ranked within the top 20 across different training data splits for mortality prediction: invasive and non-invasive blood pressures, heart rate, anion gap, respiratory rate (Full list is available in the Appendix). These represent a mixture of common vital signs and laboratory values that are clinically sensible correlates for mortality. Indeed, there is significant overlap with the input features for classical risk scores that have been validated as mortality predictors in intensive care (e.g. APACHE II [22]). The top features for the other two supervised tasks, kidney dysfunction and low blood pressure, are detailed in the Appendix. Notably, the top features for low blood pressure include all available blood pressure recordings; however in the kidney dysfunction task, creatinine, which is the laboratory value on which the outcome is defined, does not appear in this top list. Our hypothesis is that creatinine is measured sparsely - typically once every 24 hours - thus providing a weak signal over the 48 hour window of the self-supervising trajectory forecast task.\nHow good are the selected tasks? To further validate the quality of top selected tasks and evaluate the impact of these features as pretraining tasks on the supervised outcome, we have conducted two ablation studies. In the first, we pretrain the encoder using the top selected auxiliary tasks only, referred to as 'Pretrain (Top)'. In the second, we instead pretrain the model with the remaining auxiliary tasks excluding the top ones, referred to as 'Pretrain (Down)'. The hypothesis is that the top selected tasks already capture the necessary knowledge needed to optimize the performance of the target task, while the remaining ones are less important. We report the results of these two studies in Table 3. It shows that 'Pretrain (Top)' performs closer to AutoSelect and is consistently better than 'Pretrain (Down)' and 'Pretrain (Full)', suggesting that the top selected tasks are able to transfer the most useful information to the target task. Meanwhile, we also observe that 'Pretrain (Down)' has similar performance to \u2018Pretrain (Full)' showing that the useful signals are indeed overshadowed in the learned representation with the full set of tasks.\nHow does the learning occur? Figure 2a presents the training dynamics of AutoSelect for the mortality task as an example. During the pretraining stage, its performance measured by AUC-ROC in the validation set keeps improving and then jumps even higher when the finetuning stage starts at step 5,500 when the validation performance of the auxiliary tasks reaches the peak. The performance of mortality prediction then quickly decreases due to overfitting to its small finetuning data. The blue curve represents the learning process of \u2018Pretrain (All)'. Because the mortality task was not involved in the pretraining stage, it only starts from the beginning of finetuning. The yellow curve is the process of \u2018CoTrain', where the validation performance of the mortality task first jumps and then decreases during the pretraining period. This is caused by the learning speed difference among all the tasks where the training of the small primary task starts to overfit while that of the other auxiliary tasks still improves. Finally, we study the impact of different training steps of the nested learning loops of AutoSelect. By fixing the total number of iterations around 5,000, in Figure 2c, we explore different configurations by varying the number of self-supervised training iterations (NP) at the inner loop from 1,000 steps to 10 steps where (1,000/5) means 1,000 inner loop iterations and 5 outer loop iterations. In addition, the inner supervised training loop (Ns) is configured to take 1/10 of the self-supervised iterations (NP). We observe AutoSelect is generally robust across different configurations, and sweet points seem to be around (100/50) and (50/100)."}, {"title": "How does AutoSelect generalize?", "content": "Finally, we look at how well the learned weights of the auxiliary tasks guided by a given target task are able to generalize to unseen new tasks. We first use the mortality prediction task as the given primary task to guide the selection of the auxiliary trajectory forecast tasks. Then, we treat BP and KD as two new tasks, and directly finetune the model using 1% and 10% of the train data respectively. The reason is that, from a clinical perspective, mortality is a more general endpoint than specific dysfunctions. The hypothesis is that representations learned on the more general endpoint of mortality will be useful for more specific tasks. The prediction results are given in the top row of Table 3. Despite training only on the mortality task, the learned weights of the auxiliary tasks are able to improve the performance of BP and KD compared to the 'Pretrain (All)' baseline. Next, we use BP and KD to guide the selection learning separately, and then test on the mortality task at the bottom of Table 3. Since the specific dysfunction does not always imply an endpoint of mortality, the predictive performance on mortality is slightly worse than the respective results of AutoSelect."}, {"title": "5 Related Work", "content": "Multi-Task Learning and Task selection. Recent research on multitask learning [23] aims at either generalizing from a source multitask learning domain to a target multitask domain [24], or learning a good trade-off among different tasks [25]. There have been approaches to the task scheduling problem via a separate two-stage pipeline [21, 26], and Requeima et al. [27] learns to adjust model architectures to automatically adapt to new tasks. Doersch and Zisserman [28] combines multiple self-supervised tasks to train useful visual representations. Being complementary, our method learns to automatically select a set of auxiliary tasks, each of which is a self-supervised time-series learning problem, so that pretraining on these tasks can lead to a better representation for a target supervised learning task in an end-to-end differentiable framework.\nMeta learning. Meta learning [29-32] seeks to acquire an initialization optimized for a set of tasks from the same distribution [33-35, 32]. One challenge of meta learning frameworks is that they rely on manually-defined training tasks, and hand-crafting these tasks can be time-consuming. The work of [33] presents unsupervised methods for inducing an adaptive meta-training task distribution and the work of [34] automatically constructs tasks from unlabeled data. We address this challenge via automatic selection over a large number of self-supervised tasks. Our method is similar in spirit to the work of [35] in that both direct the meta-learning process using a supervised target task, but we differ in that [35] meta-learns an unsupervised learning rule, while our work meta-learns a self-supervised task weight distribution.\nPatient Representation Learning. The self-supervised task in our work is related to recent progress on state representation learning especially via patient trajectories [7-10]. The objectives in these works are often reconstruction errors in the entire observation space, and thus are not incentivized to capture latent factors that are useful for downstream tasks. To address this issue, the work of [36, 37] learn state representations by predicting the future in latent space with a probabilistic contrastive loss, while our work directs the representation learning by reducing error on a downstream target task."}, {"title": "6 Conclusion", "content": "We demonstrate how to leverage trajectory forecasts over clinical observations as self-supervised pretraining tasks to improve the quality of clinical outcome predictions. We present an efficient"}, {"title": "7 Broader Impact", "content": "This work presents a method for efficiently learning patient representations using EMR data. Although this is demonstrated with a subset of the full raw EMR, and for only a handful of clinical outcomes in intensive care patients, it is a proof-of-concept that may be useful for a range of other predictive modeling using various types of longitudinal health data. The impact may be greatest in low-data scenarios - e.g. clinical use-cases where labeling is very challenging or where there are few eligible patients in the EMR. The code for this method will be made available to the research community on GitHub.\nThere are numerous ethical considerations associated with any EMR modeling, which have been discussed in the literature [38, 39]. Issues include numerous biases in the observational EMR data, e.g. on the basis of gender, ethnicity or socioeconomic status, which can propagate into predictive models. These fairness considerations also apply to representation learning architectures as presented here.\nFinally, if this method were to be brought forward to real world deployment in conjunction with a decision support tool, it would have to be subject to appropriate clinical safety review and trials across different populations, with consideration given to issues such as drift and robustness."}, {"title": "8 Appendix", "content": "8.1 Full Algorithm\nBased on Equation 10 to 12, the gradient of A (Equation 8) can be solely determined by the signals of both a and \u03b2. The full algorithm is given in Algorithm 2."}, {"title": "8.2 Dataset and Data Preprocessing", "content": "We evaluate our proposed algorithm using the open access MIMIC-III dataset [17] which contains patients admitted to the intensive care unit of Beth Israel Deaconess Medical Center between 2001 and 2012."}, {"title": "8.3 Hyperparameters and Selections", "content": "The learning rates of all training loops were tuned jointly with the state size of LSTM via a grid search. Table 6 shows the list of values considered, the criteria we use in choosing the hyperparameter and the final value selection."}, {"title": "8.4 Additional Experiment Results", "content": "Table 7 provides predictive performance (AUC-ROC) over the additional Liver Failure prediction task along with the other three tasks. We also report the AUC-PR (i.e., Average Precision (AP)) of different competing methods for the four primary outcome prediction tasks under consideration in Table 8. As we could see, AutoSelect outperforms both \u2018Pretrain (All)' and 'CoTrain' by a significantly large margin in low-data scenarios for all four tasks with respect to both metrics."}, {"title": "8.5 Top Tasks", "content": "The features that are associated with the top trajectory forecast auxiliary tasks for each primary task are listed in Table 9."}]}