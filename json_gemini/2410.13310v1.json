{"title": "Active inference and deep generative modeling for cognitive ultrasound", "authors": ["Ruud JG van Sloun"], "abstract": "Ultrasound has the unique potential to offer access to medical imaging to anyone, everywhere. Devices have become ultra-portable and cost-effective, akin to the stethoscope. Nevertheless, and despite many advances, ultrasound image quality and diagnostic efficacy are still highly operator- and patient-dependent. In difficult-to-image patients, image quality is often insufficient for reliable diagnosis. In this paper, we put forth the idea that ultrasound imaging systems can be recast as information-seeking agents that engage in reciprocal interactions with their anatomical environment. Such agents autonomously adapt their transmit-receive sequences to fully personalize imaging and actively maximize information gain in-situ. To that end, we will show that the sequence of pulse-echo experiments that an ultrasound system performs can be interpreted as a perception-action loop: the action is the data acquisition, probing tissue with acoustic waves and recording reflections at the detection array, and perception is the inference of the anatomical and or functional state, potentially including associated diagnostic quantities. We then equip systems with a mechanism to actively reduce uncertainty and maximize diagnostic value across a sequence of experiments, treating action and perception jointly using Bayesian inference given generative models of the environment and action-conditional pulse-echo observations. Since the representation capacity of the generative models dictates both the quality of inferred anatomical states and the effectiveness of inferred sequences of future imaging actions, we will be greatly leveraging the enormous advances in deep generative modelling (generative AI), that are currently disrupting many fields and society at large. Finally, we show some examples of cognitive, closed-loop, ultrasound systems that perform active beamsteering and adaptive scanline selection, based on deep generative models that track anatomical belief states.", "sections": [{"title": "I. INTRODUCTION", "content": "ULTRASOUND (US) has the potential to revolutionize and democratize medical imaging due to its cost-effectiveness and portability. However, achieving consistent, precise and robust diagnostics remains a challenge. The diagnostic performance of US is dependent on skilled operators and exams still fail frequently on hard-to-image patients. The group of hard-to-image patients is moreover growing rapidly due to the rising incidence of obesity worldwide. Studies show that reduced image quality leads to worse observer variability, reproducibility, and accuracy of diagnostic parameters in ultrasound exams [1], [2].\nThe biggest adversaries for ultrasound image quality and diagnostic accuracy stem from patient- and user-specific factors, i.e. patient geometry and user interaction. These factors thus vary across exams, and within exams. Given this, it is reasonable to hypothesize that optimal imaging requires closed-loop, goal-directed system behaviour, through sequential optimal experiment (=transmit-receive) design via its reciprocal interactions with the physical environment.\nBased on this hypothesis, this paper proposes a brain-inspired paradigm for such a cognitive ultrasound transmit-receive control system. It recognizes that the cycle of ultrasound data acquisition and reconstruction can be interpreted as a perception-action loop: the action is the acquisition, probing the anatomy, and the perception is the reconstruction that infers what object most likely generated that acquired data. This data acquisition cycle has associated costs (e.g. time and energy), and hence in practice one always deals with partial observations of the time-varying object.\nPerception-action loops are commonly used in neuroscience and cybernetics to explain the behaviour of intelligent agents, which also typically deal with partial observations of the world around them. A now widely-accepted brain theory is that agents establish an internal generative model of the world in"}, {"title": "II. PERCEPTION-ACTION LOOPS", "content": "\"Each movement we make by which we alter the appearance of objects should be thought of as an experiment designed to test whether we have understood correctly the invariant relations of the phenomena before us\" Helmholtz [10]\nIntelligent agents, such as the brain, continuously engage in interactions with their environment. These interactions are reciprocal, i.e. agents take actions which affect their environment, and their environment in turn affects their observations. These observations solicit new actions, closing the so-called perception-action loop. Useful actions are those that lead to desired outcomes/observations. To be effective at achieving this, an agent must understand the environment, and the consequences of actions on that environment. Rational agents thus pursue the understanding of their environment through actions that lead to information gain, while at the same time being goal-directed. Such behavior requires the"}, {"title": "The ultrasound action space", "content": "At this point, it becomes useful to briefly discuss what the action space of an ultrasound agent entails. Many of the controllable sensing parameters in ultrasound are similar to those commonly considered in cognitive radar systems. They include both transmit and receive parameters. On the transmit side, at the most abstract level, the agent is tasked with the design of an optimal, maximally informative, transmit code. At the most fine-grained level, this code is governed by a complete shaping of the transmit waveforms and timing for each of the transmitters, subject to the constraints of feasibility imposed by the analog transmit chain. A more coarse representation would be to only control the delays and gains applied to each transmitter, shaping the transmit beam. Practical ultrasound systems typically execute a sequence of such coded transmit events (e.g. a series of focused scan lines), and many practical codes will need to be considered in the context of a full sequence to evaluate the impact they have on the information gain achieved by that sequence."}, {"title": "III. DEEP GENERATIVE MODELS", "content": "The potential gains of using accurate generative priors in ultrasound perception-action loops can perhaps most easily be understood when realizing that most combinations of pixels that form images are not interesting at all. Although a 5-second"}, {"title": "Diffusion models:", "content": "Diffusion models are state-of-the-art in image and video generation. A notable challenge that diffusion models overcome is the need for explicit normalization of learned density functions (i.e. assuring that $\\int p(x)dx = 1$)."}, {"title": "IV. PERCEPTUAL INFERENCE", "content": "We will now make the perception step in our perception-action loop explicit. Perception is the act of updating beliefs about the states governed by the generative model in Eqn. (1) given new information. Indeed, information is that which induces a change of beliefs. Note that this is distinct from learning, which is to infer the generative model (functional form and/or parameters) itself and occurs across longer timescales. In the following, we will assume that the agent has established or has access to a sufficiently accurate generative model. This may be obtained through past interactions and observations (training data) and/or injected knowledge of physics, that is available at t = 0.\nAt time step t the agent first takes an action at, which leads to observations \u0177t. Given the tuple of all observations and actions performed thus far, which we denote as yo:t = (Yo:t, ao:t), a rational agent will seek the minimal update of past/prior beliefs about 20:t that satisfies the constraints imposed by the new data - beliefs must only be revised to the"}, {"title": "V. ACTIVE INFERENCE AND INFORMATION GAIN", "content": "\"What is the first and most fundamental thing a newborn infant has to do? If one subscribes to the free energy principle, the only thing it has to do is to resolve uncertainty about causes of [...] sensations.\" \u2013 Friston [23]\nThe active inference paradigm postulates that an agent's desires are encoded by their generative models, which attribute more mass to states and observations that are aligned with preferred outcomes [24]. Humans desire to stay alive and hence place a strong prior on equilibrium conditions"}, {"title": "VI. IMPLEMENTING PERCEPTION-ACTION LOOPS", "content": "Estimating the entropies in Eqn. (12) is not trivial in practice, especially for the flexible class of density functions needed to accurately describe high-dimensional images and their (possibly nonlinear) observations. It is worth reiterating that simple linear models based on members of the exponential family that do have closed-form expressions are insufficient for what we try to achieve. Instead, we hypothesise that performing approximate inference with accurate (deep) generative models is more fruitful than pursuing exact inference with overly simple models. This confronts us with the daunting task of performing reliable approximate inference using highly nonlinear (deep) generative models. For the sake of brevity, in what follows we make the dependency of future observations on the actions a' implicit and use shorthand notation y to indicate the tuple of all past observations and actions yo:t-1."}, {"title": "A. Approximate posterior inference", "content": "A common approach to approximating the posterior density function is to use a set of samples/particles {$x_1^T, ..., x_{N_p}^T$} ~ p(x0:T|\u0177) and weights {$W_1,...,W_{N_p}$} that are proportional to the probability of the sample belonging to the target distribution:\n$q(x_{0:T}|\\hat{y}) = \\sum_{i=1}^{N_p} \\omega_i \\delta(x_{0:T} - x_{0:T}^i)$,\nwith $\\sum_i \\omega_i = 1$. Sampling methods make no explicit assumptions about the functional form of the density functions and hence have low bias. This does come at the expense of relatively high variance, and resolving it requires paying a computational price, e.g. in terms of the number of samples required to get good (mode) coverage of the distribution.\nMany methods allow for effective and/or efficient sampling from a posterior. For instance, deep generative diffusion models enable posterior sampling by integrating a data-consistency/likelihood step into the reverse diffusion process [18]. Another alternative is to use classic sequential Monte-Carlo methods (e.g. particle filters) [26]. These methods exploit the sequential structure of states to perform highly efficient tracking of the distribution under arbitrary (possibly non-differentiable) nonlinear forward models. Such forward models can be physics-based, or learned from data, e.g. a pre-trained deep generative latent variable model that fits $p(x_t) = \\int_z p(x_t|z)p(z)dz$ using variational inference [13]."}, {"title": "B. Approximate entropy models", "content": "Given a set of posterior samples, the next step is to estimate the entropy terms in our action-value function. Recall that our action-value function is the action-conditional mutual information between state and future observations, and decomposes into two entropies: The marginal entropy of the observations, H(y+|y), and the state-conditional entropy of the observations, H(y+|x7,\u0177) (see Eqn. (12)). In the most general case, both depend on the action, although there are many practical examples for which the latter dependency is negligible (recall the discussion at the end of Section V).\nWe nevertheless start with the expected conditional entropy (the remaining uncertainty about y+ if x were known) as choosing a reasonable entropy model is more straightforward. Assuming a forward measurement model with additive Gaussian noise n\u0442, \u0456.\u0435. \u0423\u0442 = f(x,a\u2081) + n\u2081, the conditional entropy model is also a Gaussian. Given posterior samples {x},...,x} ~ p(x, y) with uniform weights, we then have that:"}, {"title": "VII. EXAMPLES", "content": "We will now illustrate the concepts described above in the context of concrete ultrasound imaging applications. From sections VII-A, to VII-C, we will cover (A) active inference with low-dimensional generative models based on first principles, (B) perceptual inference with complex data-driven deep generative models in high dimensions, and finally, (C) active inference using deep generative models."}, {"title": "A. Active beamsteering using sequential Monte-Carlo", "content": "1) Generative model: We start with an agent that is tasked with the sequential selection of optimal focused transmit beams for tracking the position of a moving Doppler target xt = (0,2t, wt), with Ot its angular position, z\u0142 its axial position, and wt its Doppler frequency at timestep t [32]. The observation at timestep t, \u0177t \u2208 R No, is an angular power Doppler profile. It is computed by pixel-based receive beam-forming and subsequent Doppler processing of an ensemble of channel data coming from focused transmits with a fixed focal depth zx and steering angle \u00e2t = 0. The agent's generative model given a series of actions ar is given by:"}, {"title": "B. Multipath haze suppression using diffusion models", "content": "1) Generative model: The previous example shows how cognitive ultrasound imaging improves target tracking given a physics-based model of the observations and a linear Gaussian state transition function in R\u00b3. To move to more complex and high-dimensional states, such as high-resolution reflectivity maps in RN\u00d7N, we will first need to expand the modelling. We will therefore train a generative diffusion model from data. We consider an agent that is tasked with the suppression of multipath clutter (\"haze\") from (linearly) beamformed RF data patches y \u2208 RN\u00d7N in cardiac imaging [6]. To that end, we define the following generative model, assuming linear scattering:"}, {"title": "C. Active subsampling using temporal diffusion models", "content": "1) Generative Model: Our final example concerns an agent that performs adaptive compressive sensing [35], [36] through active subsampling of ultrasound scanlines. We will use the approach by Nolan et al. [37] to design subsampling masks that maximize information gain given a diffusion-based generative model. Subsampling transmit events (be it scanlines, diverging waves, or otherwise) is typically used to minimize costs associated with data acquisition, such as acquisition time. Our agent is tasked with the reconstruction of a sequence of T ultrasound frames X1:T \u2208 RNz\u00d7N\u300f\u00d7T from goal-directed partial observations y1:T \u2208 RNzxkxT, with a budget of k < Ny focused scanlines per frame. We formulate the following observation model:"}, {"title": "VIII. DISCUSSION", "content": "This paper gives a new interpretation of the ultrasound transmit-receive cycle as a perception-action loop, in which pulse-echo experiments are adaptively designed to maximize information gain given a generative model. It treats ultrasound"}, {"title": "IX. CONCLUSION", "content": "Ultrasound systems engage in repeated reciprocal interactions with the anatomical environment that they probe, and this cycle of probing and receiving data can be interpreted as a perception-action loop. Active inference offers a probabilistic framework for developing agents that implement such perception-action loops, which when augmented with deep generative models that govern anatomical beliefs, unlocks closed-loop high-dimensional imaging. We here showed how these principles can be used for cognitive ultrasound systems that maximize information gain by changing their probing of the environment. The promise that this holds for ultrasound imaging is significant; it may spur a paradigm shift in the design of systems, akin to cognitive radar systems, that autonomously strive to maximize diagnostic value in-situ."}]}