{"title": "Robot Behavior Personalization from Sparse User Feedback", "authors": ["Maithili Patel", "Sonia Chernova"], "abstract": "As service robots become more general-purpose, they will need to adapt to their users' preferences over a large set of all possible tasks that they can perform. This includes preferences regarding which actions the users prefer to delegate to robots as opposed to doing themselves. Existing personalization approaches require task-specific data for each user. To handle diversity across all household tasks and users, and nuances in user preferences across tasks, we propose to learn a task adaptation function independently, which can be used in tandem with any universal robot policy to customize robot behavior. We create Task Adaptation using Abstract Concepts (TAACo) framework. TAACo can learn to predict the user's preferred manner of assistance with any given task, by mediating reasoning through a representation composed of abstract concepts built based on user feedback. TAACo can generalize to an open set of household tasks from small amount of user feedback and explain its inferences through intuitive concepts. We evaluate our model on a dataset we collected of 5 people's preferences, and show that TAACo outperforms GPT-4 by 16% and a rule-based system by 54%, on prediction accuracy, with 40 samples of user feedback.", "sections": [{"title": "I. INTRODUCTION", "content": "Service robots have the potential to assist diverse users across warehouses, homes, assisted living facilities, etc., by performing tasks based on user commands [1]\u2013[4]. However, these methods require unambiguous commands [1], [2], such as 'pick up the cereal box from the pantry and bring it here', or need the user to resolve ambiguities during operation [3], [4]. For complex, high-level tasks, such as 'help me with breakfast', unambiguous definition of every detail is impractical, and robots must autonomously adapt to user preferences to assist with under-specified tasks. Such adaptation includes determining 'when' a task should be done, 'how' it should be done, and 'who' should do it. Prior works have explored questions of anticipating 'when' a task should be done [5]\u2013[7], and details of 'how' the user prefers a task to be executed [8]-[11], but the final question of 'who' should do a given task, between humans and robots [12]-[15], is relatively under-explored in the context of personal household preferences.\nThis problem involves two main challenges: the diversity in preferences across users, and diversity across the vast space of tasks that a robot might encounter. Given the growing demand for robotic support in homes and assisted living facilities, we focus on older adults, a demographic that prior studies [16] have shown differ in their preferences regarding high-level activities, such as meal preparation, that they prefer delegating to a robot. We examine preferences over more granular tasks, such as wiping the countertop and preparing coffee, through a case study involving interviews with five older adults, and find low agreement on preferences between users, indicated by an average pairwise Cohen's Kappa of 0.23, underscoring the need for personalization to each user.\nAlthough users prefer to customize robots themselves [17], existing methods on task allocation [12], [13] in human-robot teaming primarily focus on optimizing task efficiency rather than user preferences, and methods that consider user preferences [14], [15] require exhaustive annotation or prior experience across the space of tasks, which becomes intractable for general robots that can perform a multitude of tasks. If users were required to set explicit rules for the preferences we gathered, they would require on average 76.5 rules for every 100 scenarios. Our key insight is that while the space of all actions is diverse and intractable, people's preferences associated with them are anchored in a relatively smaller space of abstract concepts (e.g. fragility of an object, mundaneness of a task, being particular about a task, etc.). Moreover, an understanding of such abstract concepts can be bootstrapped from prior knowledge sources, and utilizing them explicitly in an intermediate representation helps the robot align its reasoning mechanism with the user's, and leverage"}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "In this section, we discuss prior work on personalizing robot behavior to user preferences and bootstrapping prior knowledge contained in LLMs.\nA common approach to personalization of robot tasks is for users to utilize end-user programming methods to di-rectly codify their preferences. Interfaces which allow a user to define 'if...then...' style rules based on abstract semantic conditions, such as food is being prepared [17], or IoT sensor triggers [18], have enabled personalized scheduling of high level behaviors. Automatic parsing of user rules into Temporal Logic has been used to administer customized cognitive therapy sessions [19]. However, in giving the users total control over robot actions, these methods require the user to be accurate and exhaustive in defining their expectations. For complex behaviors involving detailed preferences, user-specification of tasks have been shown to fail due to unforeseen repercussions [20], [21].\nMore generally, personalization in human robot interaction involves adapting to user's task preferences on 'how' and 'when' a task should be executed, as well as 'who' should execute a given task. Towards addressing the 'how' question, prior works have learned to adapt to the user's preferred manner of executing various tasks, such as learning preferred trajectories, object locations, or action ordering, based on demonstrations [8]-[10], interactive feedback [11], [22], [23], facial expressions [24], or scene context [25], [26]. Prior works have also explored the 'when' question to enable proactivity through behavior prediction. In collaborative settings [7], [27]-[29], such as robot handovers, short-term predictions have been used to improve task efficiency and fluency, and in household assistance [5], [6] long-term predictions have enabled timely robot assistance without direction.\nThe final question is that of accounting for user preferences while determining 'who' a task should be allocated to; this topic remains relatively under-explored in prior work in the context of household robots. The field of task allocation has extensively addressed assignment of tasks in multi-robot and human-robot teams [12]\u2013[14]. However, existing works primarily weigh the utilities and costs of various allocations, aiming to optimize the efficiency of achieving task goals. While this is useful in factory settings, in domestic settings, the goal shifts from task efficiency to promoting user comfort and satisfaction. In such settings, the robot must understand allocation preferences of which tasks the users prefer doing themselves, as opposed to delegating to a robot. Closest to our work are methods that seek to recover hidden human preferences, by learning a reward function [15], [30]. But these works are limited to pre-specified tasks and require past collaboration experience with the particular user on those tasks. Transferring user preferences across tasks has been investigated towards optimizing handovers [29], and expanding user capabilities [31]. We aim to generalize allocation preferences of the user across an open set of tasks.\nFinally, abstract semantic knowledge from foundational models has been leveraged in various robotic applications, but most related to our work is task-related robotic assistance for humans. Foundational models have enabled direct user interaction with robots towards efficiently teaching tasks to the robot [4], natural instruction following [32], [33], creating queryable scene representations [34], [35], and explaining robot failures [36]. Knowledge about human norms encoded in Large Language Models (LLMs) has been leveraged to personalize robot behavior [37] and to model humans [38]. These works use the LLM as a reasoning mechanism to directly perform the target task [36], [38] or create a structured framework to solve the task and employ the LLM to solve parts of it [4], [37]. Prior works have also used LLMs to embed input information into semantically rich latent spaces [2], [39]. In addition to using latent embeddings, we use an LLM to create an intermediate representation explicitly in the form of abstract concepts."}, {"title": "III. PROBLEM FORMULATION", "content": "The primary aim of this work is to learn a model $\\Phi$ to predict the desired task adaptation $\\phi$ to regulate the execution of $t$ to match user preferences, and produce an explanation $E_{robot}$ for its prediction. We assume that the high-level behavior of the robot is governed by a plan or policy $\\pi$, which suggests task $t$ that the robot should perform, in accordance with the world state $s \\in S$, and robot's goal. As the robot performs various tasks $t$ in the household, produced by neither proactively or reaction to a command, the user can provide feedback $u$, about their preferred adaptations. Over time, using $u$, the robot must learn a function to predict the preferred task adaptation $\\phi$ for novel tasks that it encounters.\nWe represent task $t$, through a tuple of the components de-scribing it, $t = (c^a, c^h, \\{c^o\\}, \\{c^l\\})$. $c^a$ is an action description, e.g. dusting the mantel. $c^h$ is the corresponding high-level activity, e.g. cleaning the living room. $\\{c^o\\}$ is a set of objects involved in the action, e.g. $\\{mantel, duster, porcelain jar, photo frame\\}$. $\\{c^l\\}$ is a set of locations involved in executing the action, e.g. $\\{living room\\}$. We allow each component to be any natural language phrase and so the task is not confined to a closed set, and can be generated by open-set language-based planners, as well as classical or RL-based planners for which language labels are available. The state $s \\in S$ is comprised of a set of binary variables $s = \\{s_i\\}$, and can include predicates such as 'user is asleep', 'guests are present', 'weekend' etc.\nThe aim of this work is to utilize prior user feedback $u$ to adapt robot behavior. We use a task adaptation $(t,s) \\rightarrow \\phi$ to represent adaptation of robot behavior over a task $t$. The task adaptation $\\phi$, can be one of acting on task $t$ immediately (do_now), acting on $t$ later (do_later), reminding or requesting the user to do $t$ (remind), and not doing anything about $t$ (no_action). A function $\\Phi$ which predicts a task adaptation is used to personalize robot behavior in one of two ways: as a filter downstream of $\\pi$ to determine whether or not to execute the action selected by $\\pi$, or as an external constraint to $\\pi$, allowing it to optimize for user preferences, similar to accounting for user schedules [40] or motion constraints [41]. To personalize to a given user, the robot has access to user"}, {"title": "IV. METHOD", "content": "The Task Adaptation using Abstract Concepts framework (TAACo), addresses the two main challenges in learning $\\Phi$, portrayed in Figure 1: 1) generalization to an open-set of tasks by extracting relevant semantic information from any novel household task, and 2) personalized prediction of preferred action adaptation based on limited feedback. As outlined in Figure 2, TAACo is composed of a Commonsense module and a Personalization module to address the two challenges. Based on the idea that people's preferences are grounded in abstract semantic concepts, such as fragility of objects or mundaneness of tasks, we use such semantic concepts to create an intermediate representation between the two modules. This representation helps explain model decisions in an intuitive manner, and leverage user-generated explanations to align the personalization model with the user. Unlike prior works [42], [43], we do not restrict the set of concepts to a predefined closed set, instead allowing the user to define new concepts as needed through natural language.\nThe aim of the Commonsense Module is to extract relevant semantic information about the task $t$ into an intermediate representation $\\bar{t} = \\{(x, \\theta_x, m)\\}$. To create $\\bar{t}$ we distill semantic information from each task component $c^x$, which can be of one of four component types $x \\in \\{a, h, o, l\\}$ (action, high level activity, object, location), by predicting a score $m$ of how well it matches each of a set of relevant abstract concepts $\\{\\theta_x\\}$. For every concept $\\theta_x^i$, component $c^x$ pair, we prompt GPT-4 to predict a score on a scale of 1-10, and linearly rescale it to [0,1], to obtain $m$. Each component-concept pair prompt is independent, without any context of other task components, concepts or prior feedback, allowing responses to be cached and reused across personas and tasks. We create an initial set of concepts for each component type, emulating a factory configuration, and adapt to each user by adding new concepts obtained from user feedback to these sets.\nThe Personalization Module predicts the preferred adap-tation for each task, given the task and world state. The task input is represented in the form of abstract concepts $\\bar{t} = \\{(x,\\theta^x,m)\\}$, and the world state as a set of binary variables $S = \\{s_i\\}$. We first embed each input, includ-ing each tuple element of the task representation and state variables, independently into a set of three latent vectors: a type embedding $h_x$, a concept embedding $h_\\theta$, and a score embedding $h_m$. The three vectors are concatenated to form inputs to a transformer encoder with a classification head to predict the final task adaptation.\nFor the task representation, we embed each element of the tuple $(x, \\theta, m)$ to create the three latent vectors. We create $h_x$ by learning an embedding for each component type $x \\in \\{a,h,o,l\\}$. We create $h_\\theta = p_c(Y_{LLM}(\\theta))$ using an off-the-shelf language embedder $Y_{LLM}$, and projecting the resulting embedding into latent space using a learned concept projection function $p_c$. We create $h_m = p_m(m)$ using a feedforward magnitude projection function $p_m$ to project the match scores $m$. To embed the task representation, we use a single learned $h_x$, and a learned concept embedding $h_\\theta$ for each binary state variable $s_i \\in S$. To create $h_m$ reuse $p_m$ to project the binary state value $h_m = p_m(m)$, $m \\in \\{0,1\\}$. We pass the final latent embedding for each input component $h_xh_\\theta h_m$, along with an output token, <OUT>, through a transformer encoder. We use the output feature at  to classify the desired task adaptation through a classification head. We train the Personalization Module in a supervised manner using preference data obtained from the user.\nWe generate model explanations using the human-interpretable intermediate representation, and align the model's reasoning with the user's by explicitly training the model's explanations. Such training not only improves the"}, {"title": "V. EVALUATION", "content": "We conduct quantitative evaluation of TAACo on custom data obtained from real users. In this section, we describe evaluation data, baselines and metrics, and model training."}, {"title": "VI. RESULTS", "content": "In this section, we compare the prediction and explanation performance of TAACo against baselines and an oracle version of our model, and perform an analysis of the kinds of errors each model makes. We study how performance improves as more user feedback becomes available, by varying the number of user preference samples used in training, with each sample consisting of data pertaining to one task. Finally, we empirically show the importance of using concepts and training based on user-generated explanations."}, {"title": "VII. ROBOT DEMONSTRATION", "content": "Finally, we show a proof-of-concept of our system on a stretch robot, showcasing personalization across a diverse array of tasks and associated concepts, as shown in the video and Figure 6. With our framework, the robot can accept feedback over a few tasks to customize behavior, and generalize to a wider set of tasks across the household."}, {"title": "VIII. CONCLUSION AND LIMITATIONS", "content": "In this work, we propose TAACo, which can help adapt robot behavior to user preferences by picking between four ways of assisting with a task: doing it now, doing it later, reminding the user about it, or not doing anything. Our core contribution is the use of abstract concept-based representation and training, which allows generalization to an open-set of household tasks and enables explainability. However, our work has some limitations, opening avenues for future work. First, our input task representation includes a textual action and activity description, and a set of objects and locations, which cannot capture details, such as the role of an object in the given task, which might be pertinent to some preferences. Second, for some individuals or environments, the notion of component-concept alignment might diverge from the norm. Since we do not customize the commonsense module, we cannot model such preferences. Finally, future work can explore ideas of modeling change in user preferences, and lifelong learning in context of this problem."}]}