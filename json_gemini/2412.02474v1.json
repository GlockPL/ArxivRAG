{"title": "F-SE-LSTM: A Time Series Anomaly Detection Method with Frequency Domain Information", "authors": ["Yi-Xiang Lu", "Xiao-Bo Jin", "Jian Chen", "Dong-Jie Liu", "Guang-Gang Geng"], "abstract": "With the development of society, time series anomaly detection plays an important role in network and IoT services. However, most existing anomaly detection methods directly analyze time series in the time domain and cannot distinguish some relatively hidden anomaly sequences. We attempt to analyze the impact of frequency on time series from a frequency domain perspective, thus proposing a new time series anomaly detection method called F-SE-LSTM. This method utilizes two sliding windows and fast Fourier transform (FFT) to construct a frequency matrix. Simultaneously, Squeeze-and-Excitation Networks (SENet) and Long Short-Term Memory (LSTM) are employed to extract frequency-related features within and between periods. Through comparative experiments on multiple datasets such as Yahoo Webscope S5 and Numenta Anomaly Benchmark, the results demonstrate that the frequency matrix constructed by F-SE-LSTM exhibits better discriminative ability than ordinary time domain and frequency domain data. Furthermore, F-SE-LSTM outperforms existing state-of-the-art deep learning anomaly detection methods in terms of anomaly detection capability and execution efficiency.", "sections": [{"title": "1. Introduction", "content": "With the development of society, time series data closely related to people are generated in large quantities in various fields, such as: network traffic data generated when surfing the Internet [1], transaction data generated by online transactions with others [2], bioelectric signal data displayed on the electrocardiogram [3], flow data generated by traffic monitoring equipment [4] and sensor data generated by Internet of Things (IoT) devices [5], etc. Fig. 1 shows two time series of network traffic data, which exhibit similar trends over time, and thus have the same intrinsic regularity. However, in the event of an attack on the server, network intrusion, traffic congestion, or network equipment failure that poses a threat to network security, the inherent patterns in the time series of this network traffic will be disrupted, leading to the emergence of abnormal points or anomalous data trends. Therefore, anomaly detection of time series plays an important role in reducing economic losses, maintaining network security and social stability."}, {"title": "2. Related work", "content": "With the development of science and technology, machine learning and deep learning models play an increasingly important role in many applications, especially in the field of artificial intelligence and have achieved good application results. In the field of time series, machine learning and deep learning models can also better fit the characteristics of time series. Therefore, many researchers have gradually applied machine learning and deep learning models to time series anomaly detection. Up to now, many time series anomaly detection methods based on machine learning and deep learning models have been explored. We summarize these methods into methods based on machine learning models, methods based on convolutional neural networks, methods based on recurrent neural networks, and methods based on various deep learning models according to the different algorithms used. These methods are summarized below and their advantages and disadvantages are analyzed."}, {"title": "Methods based on machine learning models.", "content": "This method mainly uses machine learning models and some feature extraction algorithms to construct a time series anomaly detection method. For example, Anton et al. [21] preprocess temporal data of network traffic time series using principal component analysis and detect anomalies using SVM and random forest classifiers to address network intrusion. Experiments have verified that the above two machine learning models have good effects in industrial Internet applications on two network attack datasets in industrial environments. To make up for the lack of a single model, Zhou et al. [22] fused k-nearest neighbor, symbolic aggregation approximation, and Markov model into one fusion model, and proposed an anomaly detection method called KSM. This method mainly performs time domain analysis on the time series data in order to extract the features of amplitude variation and sequence shape, which can detect anomalies caused by shape and amplitude variation more accurately. This method has higher data anomaly identification ability than most single methods. In addition, some researchers have adopted the method of frequency domain spatial embedding to convert time series time domain data into frequency domain data, construct frequency domain features and then use machine learning models for detection. For example, He and Pi [23] used short-time Fourier transform (STFT) to transform time series time domain data into frequency domain data, and then implemented early warning and detection of helicopter rotor failure using a one-class classification method based on support vector data description (SVDD). Experiments show that the method can clearly detect the damage of helicopter rotor on the vibration data of a real helicopter."}, {"title": "Methods based on convolutional neural networks.", "content": "This method mainly uses convolutional neural network to construct time series anomaly detection method. For example, Hwang et al. [24] proposed a malicious traffic detection mechanism D-PACK based on network traffic time domain data by combining CNN and Autoencoder. This mechanism can only detect the first few bytes of the first few packets of each flow, which greatly reduces the data input, thereby improving the detection speed, and its accuracy is not much different from full detection, which can be better applied to industry. Wen and Keyes [25] proposed a convolutional U-Net time series segmentation approach based on time series raw data for anomaly detection, which is the first time to use a CNN-based deep network for time series segmentation and shows better anomaly detection ability in time series. In order to solve the network intrusion problem, Ullah and Mahmoud [26] constructed network traf-"}, {"title": "Methods based on recurrent neural networks.", "content": "This method mainly adopts recurrent neural network or its variants to construct time series anomaly detection method. For example, Zhang and Zou [29] used an LSTM neural network model to predict sequences from light curve data and output prediction errors for anomaly detection. Experimental results show that the model has good application effects in light curve time series prediction and anomaly detection. To address the problem of anomaly detection in time series, Malhotra et al. [30] used stacked LSTM networks to forecast time series and detect anomalous sequence through prediction errors. The model has produced promising results on many different types of real-world datasets, and also verified that the LSTM-based model outperforms the RNN-based model in time series anomaly detection. For some unpredictable time series, they proposed an LSTM-based Encoder-Decoder model to reconstruct time series and detect abnormal sequences through the reconstruction error [31]. Experimental results show that the model can detect some unpredictable abnormal sequences, reflecting the robustness of the model. Wang et al. [32] improved LSTM to predict time series data in rail transit systems and detect abnormal data based on prediction errors. A large number of experiments have been carried out in the real subway operation environment to verify the effectiveness of the proposed scheme, and at the same time, it has better performance than the existing anomaly detection methods. Kieu et"}, {"title": "Methods based on various deep learning models.", "content": "This method uses a variety of existing neural networks to construct a time series anomaly detection method. For example, Kim and Cho [36] adopted the C-LSTM model [37] proposed by Zhou et al. to detect anomalous network traffic. The model combines CNN and LSTM, which can simultaneously extract spatial and temporal features of time series data, and has better anomaly detection ability than other machine learning and deep learning models. Yin et al. [38] stacked multiple time series into a time series matrix. At the same time, referring to the C-LSTM model structure, they combined CNN and LSTM-based autoencoder to construct a C-LSTM-AE model suitable for time series matrices. The model can well extract the time-related features generated by the time series matrix, and achieve better detection performance than C-LSTM on the network traffic dataset.\nAmong these time series anomaly detection methods, although the machine learning method can effectively detect the anomaly of time series data, this method simply regards the time series as a vector in a multidimensional space without considering the relationship between each data point. Therefore, it is difficult to extract the deep features of time series. The deep learning method can focus on the association between data points and can better extract the characteristics of time series. For example, the convolutional neural network can extract the spatial correlation features of the time series, and the recurrent neural network can extract the temporal correlation features. In addition, a small number of researchers use the frequency domain space embedding"}, {"title": "3. Methodology", "content": "In order to detect hidden abnormal data more accurately, and improve the anomaly detection ability of time series, a time series anomaly detection method F-SE-LSTM based on frequency domain is proposed, which includes the following steps: (1) Construct frequency matrix data by FFT; (2) Extract features of frequency matrix by using SENet and LSTM; (3) Output anomaly detection results by DNN. Below we first describe the steps to create the frequency matrix, then describe the construction of the anomaly detection model, and finally describe the parameter settings of the proposed method."}, {"title": "3.1. Creation of frequency matrix", "content": "Consider a time series x = (x1, x2, ..., xL) of length L, as shown in Fig. 3(a), the time series x is divided into M sequences of length N through the sliding window, namely\n\nD =\n\nEach sample in the dataset that contains an outlier is considered an abnormal sample, and a sample that does not contain an outlier is considered a normal sample. In order to make full use of the temporal correlation information of the samples and distinguish the normal samples and abnormal samples as accurately as possible, as shown in Fig. 3(b), we continue to divide the samples of length N into H subsequences of length T through another sliding window, and finally each sample is converted into a time series matrix:\n\nTo find the abnormal samples that are difficult to identify in the time domain, we transform the time series matrix into other domains to construct relevant features. The Fourier series is a special triangular series that can approximately represent any periodic function that meets the Dirichlet Conditions, which provides the basis for transformations to other domains. In general, we discuss the Fourier series in the complex domain by introducing Euler's formula, as in the following equation:\n\nf(t) = \\sum_{n=-\\infty}^{\\infty} C_n e^{\\frac{2 \\pi n}{i}} \n\nwhere t is time, n is frequency, and i is an imaginary unit. In order to transform the function from time domain space to frequency domain space and expand it to non periodic function, Fourier transform (FT) was developed. FT can directly realize the transformation of the signal from the time domain space to the frequency domain space by the following equation:\n\nF(\\omega) = \\int_{-\\infty}^{\\infty} f(t)e^{-iwt} dt,\n\nwhere w is angular frequency, F(w) is frequency domain function, which plays a key role in the field of signal processing.\nDue to the inability to obtain continuous signals in practical applications, signals can only be sampled at certain time intervals. To describe the frequency domain of discrete sequence data, we introduce the discrete Fourier Transform (DFT):\n\nX(n) = \\sum_{t=0}^{T-1} e^{-inwt} x(t), n = 0,1,2,...,T-1, \n\nwhere the input {x(t)} is the time domain data, and the output {X(n)} is the frequency domain data of the complex plane. It is necessary to take the modulus of the complex number X(n) to obtain the frequency amplitude y(n) for facilitating subsequent calculation:\n\ny(n) = |X(n), n = 0,1,2,\u2026, T \u2013 1."}, {"title": "3.2. Deep anomaly detection model", "content": "Here, we introduce a deep learning model combining SENet and LSTM for anomaly detection. SENet is a CNN with channel attention mechanism, which can improve accuracy by modeling the correlation between feature channels and strengthening important features. It can extract not only the interdependence between image pixels, but also the interdependence between channels, and has higher feature extraction capabilities than CNN. Therefore, SENet is suitable for extracting the dependencies between frequencies within a certain time period. On the other hand, LSTM, as a variant of RNN [39], can well model the temporal context dependencies of long and short sequences, and thus can model the dependencies between frequencies of different periods. Combining the above two neural network models can allow the detection algorithms to give full play to their respective advantages in time series anomaly detection, so as to build a more robust anomaly detection model.\nFor the constructed frequency matrix Sf \u2208 RH\u00d7(F+1), as shown in Fig. 4(a), SENet first convolves the adjacent frequencies in each time period to obtain U \u2208 RH\u00d7W\u00d7C for extracting the dependencies between adjacent frequencies, where W is the frequency dimension size after convolution, and C is the channel dimension size. In Fig. 4(b), the matrix Uc \u2208 RH\u00d7W of each channel in U is squeezed to obtain P\u2208 R1\u00d71\u00d7C for extracting the dependency between channels by the following equation:\n\nP_c = \\frac{1}{HW} \\sum_{i=1}^{HxW}\\sum_{j=1}^{HxW} U_c(i, j),\n\nwhere Pc \u2208 R1\u00d71 is the matrix of the channel dimension of the tensor P. Then according the compress and excitation mechanism, the correlation coefficient tensor P\u2208 R1\u00d71\u00d7C is obtained by convolving the channels of P. Finally, each channel vector UHxw \u2208 RC in U is operated with P such as:\n\nV_{Hxw} = tanh(U_{Hxw} * P),\n\nwhere tanh is the activation function, the symbol * is the Hadamard product, and the VHxw \u2208 RC is the channel vector in tensor V \u2208 RH\u00d7W\u00d7C which contains frequency and channel related information.\nIn the next step, we extract the frequency-related feature between different time periods through LSTM. The H output matrices VH \u2208 RW\u00d7C on the time dimension are taken as H time steps and each matrix is spliced into a one-dimensional vector z\u0142 of size W\u00d7C, and then input into the LSTM neural network. LSTM contains LSTM cells that process the input data of each time step in a recurrent fashion. LSTM cells include forget gates, input gates, output gates, cell states and hidden states. The forget gate, input gate and output gate in Eqn. (10), (11) and (12) can operate the input data z\u2081 and the hidden state ht-1 to obtain the corresponding gating coefficients, where is the sigmoid activation function, and W and b are weights and biases. Then, as shown in Eqn. (13), (14) and (15), the forget gate can choose to forget the unimportant information in the previous cell state, and the input gate can retain the important information of the input data, so as to obtain the new cell state ct. Finally, the output gate determines the important information that the current cell state can output, and use the new hidden state h\u2081 as the output of LSTM.\n\nf_t = \\sigma(W_f [h_{t-1}, z_t] + b)\n\ni_t = \\sigma(W_i [h_{t-1}, z_t] + b^i)\n\no_t = \\sigma(W_o [h_{t-1}, z_t] + b^o)\n\n\\tilde{C_t} = tanh(W[h_{t-1}, Z_t] + b^c)\n\nC_t = f_t * C_{t-1} + i_t * \\tilde{C_t}\n\nh_t = o_t * tanh(c_t)\n\nIn order to output time series anomaly detection results, it is necessary to use DNN to reduce the di-"}, {"title": "3.3. Parameter configurations", "content": "This section will describe the parameters of the constructed frequency matrix and the parameters of the model structure to ensure that the proposed method can be better adapted to our problem.\nWhen constructing sample sequences, we follow the settings in the literature and set the sample sequence length N to 60. For the construction of the frequency matrix, we set the size of the sliding window T to 30 to balance time information and frequency information. Then the number of subsequences H is 31, the maximum frequency F is 15, and the shape of the final frequency matrix Sf is 31 \u00d7 16."}, {"title": "4. Experiment", "content": "In this section, we compare our method with other methods on publicly available datasets. A hardware environment consisting of Intel (R) Xeon (R) Gold 5218 CPU, A100-PCIE-40GB GPU and 256 GB RAM was used. In terms of software, we mainly use the Sklearn machine learning framework and the PyTorch deep learning framework to build time series anomaly detection methods."}, {"title": "4.1. Datasets", "content": "We select 4 time series real datasets related to network traffic and Internet devices for experiments: the A1 dataset in Yahoo Webscope S5 [40] and the AWS, Known, Traffic datasets in Numenta Anomaly Benchmark [41]. The A1 dataset contains 67 sequences of web traffic from Yahoo, each containing 1000 observations. The AWS dataset contains 17 sequences, including the CPU usage rate of Amazon services, the number of network input bytes, and the number of disk read bytes, and most of the sequences have more than 4,000 observations. The Known dataset contains 7 sequences, including temperature sensor data and CPU utilization, with thousands to tens of thousands of observations. The Traffic dataset contains 7 series of vehicle sensor occupancy, speed and travel data, each containing 1000 to 3000 observations."}, {"title": "4.2. Data preprocessing", "content": "Since the time series value range of each dataset is different, we normalized each original sequence to a sequence with a mean of 0 and a standard deviation of 1, and then used the method described in the previous section to create a sample with a sequence length of 60. Random stratified sampling is used to divide the dataset into training set, validation set and test set according to the ratio of 6:2:2, where the proportion of abnormal samples in the three sets is roughly equal."}, {"title": "4.3. Evaluation metrics", "content": "In order to fully verify the advantages and disadvantages of the proposed method, multiple evaluation metrics are used: accuracy, precision, recall and F1, as shown in:\n\nAccuracy = \\frac{TP + TN}{TP + FP + FN + TN},\n\nPrecision = \\frac{TP}{TP + FP},\n\nRecall = \\frac{TP}{TP + FN},\n\nF1 = 2 * \\frac{Precision \u00d7 Recall}{Precision + Recall},\n\nwhere abnormal samples are marked as true positive (TP) when the prediction is correct, normal samples are marked as false positive (FP) when the prediction is wrong, abnormal samples are marked as false negative (FN) when the prediction is wrong, and normal samples are marked as true negative (TN) when the prediction is correct.\nGenerally, accuracy is the proportion of all samples correctly predicted. Precision is the correct proportion of predicted abnormal samples, and the larger the value, the lower the abnormal false alarm rate. Recall is the proportion of correct prediction in abnormal samples, and the larger the value, the lower the abnormal missed detection rate. F1 combines precision and recall, while the higher the value, the better the comprehensive detection effect. In order to measure the comprehensive"}, {"title": "4.4. Results and analysis", "content": "We set up the following sets of experiments to fully verify the effectiveness of each step in the proposed method, and the experimental codes\u00b9 are uploaded to GitHub. In order to ensure the fairness of the experiment, the machine learning models used in the experiments are all set to default parameters, and the hyperparameters learning rate, batch size, epochs and random state of the deep learning model are set to 0.001, 512, 500 and 1, respectively. In the training of the deep learning model, we take the sum of the F1 scores of each epoch and the 5 epochs before and after (in total 11 epochs) on the validation set as the validation score. Then the number of epochs with the highest validation score is applied for testing on the test set."}, {"title": "4.4.1. Effectiveness of frequency domain features", "content": "We first used FFT to convert sequence samples of length 60 into frequency bands, and then used various machine learning models to conduct experiments with time domain data and frequency domain data, including k-nearest neighbor (kNN), logical regression (LR), support vector machine (SVM), decision tree (DT) and random forest (RF). From the results in Table 4, it can be seen that the F1 score of frequency domain data is higher than that of time domain data on various models and multiple datasets, which shows that frequency domain data is more discriminative than time domain data in anomaly detection."}, {"title": "4.4.2. Effectiveness of frequency matrix", "content": "Since the deep learning model can directly process matrix data, we used three commonly used neural networks, such as DNN, CNN and LSTM, to detect time series vectors (Fig. 3(a)), frequency vectors (vectors undergo FFT transformation), time series matrices (Fig. 3(b)) and frequency matrices (Fig. 3(c)). As shown in Fig. 5, each line represents the F1 score of the model on different datasets, where TV, FV, TM and FM represent the input data as time series vectors, frequency vectors, time series matrices and frequency matrices. It can be observed that the F1 score of frequency data of the same dimension is higher than that of time series data, and the F1 score of high-dimensional data of the same data type is higher than that of low dimensional data, indicating that the frequency matrix as input data can fully capture"}, {"title": "4.4.3. Parameter exploration of frequency matrix", "content": "To further verify the impact of sliding window size T on the performance of various deep learning algorithms, we set T to 10, 20, 30, 40, and 50 respectively, and conducted comparative experiments on DNN, CNN and LSTM. The experimental results are shown in the Table 5. When T is 30, the total number of the highest F1 scores is far more than the total number of other values of T, and for each model, the value has advantages in at least half of the datasets. In general, this value balances the number of frequencies and time periods in the sequence samples, making the time information and frequency information extracted by the model more sufficient."}, {"title": "4.4.4. Effectiveness of proposed model", "content": "In order to verify that the model constructed by the method in this paper can fully and effectively extract the features of the frequency matrix, we performed two experiments. For the first experiment we used the constructed frequency matrix as input data and trained using LSTM+DNN, CNN+LSTM+DNN and SENet+LSTM+DNN (the proposed model). In the second experiment, we used the time matrix and frequency matrix as input data respectively, and used the proposed model for training.\nThe first experimental result is shown in Fig. 6. The proposed model outperforms LSTM+DNN in all four datasets and achieves the highest F1 scores on two datasets. Although CNN+LSTM+DNN also achieved the highest F1 score on two datasets, it is lower than LSTM+DNN on the other two datasets. This shows that SENet performs more stable than CNN in time series anomaly detection. The second experimental result is shown in Table 6. The F1 score obtained by the proposed model with frequency matrix as input is better than that with time matrix as input on all four datasets.\nTherefore, the idea of using SENet to extract channel-related features is valid, and the proposed model is also more suitable for extracting features of frequency matrices."}, {"title": "4.4.5. Comparison between our method and state-of-the-art methods", "content": "We compare the proposed method with existing state-of-the-art methods. For the fairness of the experiment, the sample sequence length of all these methods is uniformly set to 60. Fig. 7 shows the evaluation metrics"}, {"title": "5. Conclusion", "content": "In our work, we propose an anomaly detection method for time series, termed F-SE-LSTM, from the perspective of the frequency domain: we first utilize sliding windows and FFT to construct the frequency matrix, and then extract frequency-related information within and between time periods with SENet and LSTM respectively. Comparative results with other methods that the frequency matrix constructed by our method exhibits superior discriminative ability compared to ordinary time domain and frequency domain data, as it fully leverages the information of the frequency matrix and demonstrates outstanding performance on multiple real datasets. Compared with existing deep learning-based anomaly detection methods, our approach achieves higher average F1 score and average recall rates, surpassing the best methods by 1.2% and 2.2% respectively. Furthermore, this method also outperforms most other existing methods in terms of training speed and number of model parameters.\nIn future work, we aim to integrate both time domain and frequency domain data, striving to develop a more robust time series anomaly detection method."}]}