{"title": "DAMe: Personalized Federated Social Event Detection with Dual Aggregation Mechanism", "authors": ["Xiaoyan Yu", "Yifan Wei", "Pu Li", "Shuaishuai Zhou", "Hao Peng", "Li Sun", "Liehuang Zhu", "Philip S. Yu"], "abstract": "Training social event detection models through federated learning (FedSED) aims to improve participants' performance on the task. However, existing federated learning paradigms are inadequate for achieving FedSED's objective and exhibit limitations in handling the inherent heterogeneity in social data. This paper proposes a personalized federated learning framework with a dual aggregation mechanism for social event detection, namely DAMe. We present a novel local aggregation strategy utilizing Bayesian optimization to incorporate global knowledge while retaining local characteristics. Moreover, we introduce a global aggregation strategy to provide clients with maximum external knowledge of their preferences. In addition, we incorporate a global-local event-centric constraint to prevent local overfitting and \"client-drift\". Experiments within a realistic simulation of a natural federated setting, utilizing six social event datasets spanning six languages and two social media platforms, along with an ablation study, have demonstrated the effectiveness of the proposed framework. Further robustness analyses have shown that DAMe is resistant to injection attacks.", "sections": [{"title": "1 INTRODUCTION", "content": "Social Event Detection (SED) aims to pinpoint unusual occurrences that involve specific times, locations, people, content, etc., in the real world from social media platforms [29]. Traditionally, individual platforms collect their own data to train SED models. However, users tend to post content across various platforms driven by personal preferences (e.g., linguistic preferences [36] and social affiliations [34]). Consequently, the models trained individually by each platform are susceptible to their inherent biases, leading to a limited scope and incomplete detection of events. Meanwhile, due to privacy concerns, existing regulations prohibit organizations from sharing data without user consent [38], making it unfeasible to centralize data for training purposes. In such scenarios, the most straightforward solution is implementing Federated Learning (FL) [24]. In FL, each client (participant) trains a local model using their private data, while the central server facilitates information exchange among clients by iteratively aggregating the locally uploaded model weights. This paper initiates the study on Federated Social Event Detection (FedSED).\nImplementing SED through FL necessitates considering its inherent characteristics and challenges. Firstly, FedSED aims to facilitate clients in achieving better performance on their respective data. Unlike traditional FL [18, 24], which prioritizes"}, {"title": "2 RELATED WORK", "content": "Federated Learning (FL), an advanced paradigm for decentralized data training, has garnered significant attention in recent years [46]."}, {"title": "2.1 Social Event Detection", "content": "Social event detection, aiming to identify potential social events from social streams, is a longstanding and challenging task. Recent SED methods primarily rely on Graph Neural Networks (GNNs) [2, 6, 27, 28, 33, 35, 36, 43]. These approaches construct message graphs to represent social message data, integrating various attributes that complement each other and serve independent roles in propagating and aggregating text semantics. For instance, KPGNN [2] builds an event message graph using user, keyword, and entity attributes, then employs inductive Graph Attention Networks (GAT) to learn message representations. Furthermore, some approaches adopt multi-view learning strategies to enhance the feature learning process. MVGAN [6], for instance, learns message features from both semantic and temporal views and incorporates an attention mechanism to fuse them. ETGNN [35] focuses on learning representations from co-hashtag, co-entity, and co-user views. However, current works have not yet explored methods utilizing federated learning to enhance the comprehensiveness and accuracy of SED."}, {"title": "2.2 Federated Learning", "content": "Federated Learning (FL), an advanced paradigm for decentralized data training, has garnered significant attention in recent years [46]."}, {"title": "3 PRELIMINARIES", "content": "In this section, we outline the problem formulations of Federated Learning (FL) and Social Event Detection (SED), then define the threat model in the federated setting."}, {"title": "3.1 Federated Learning", "content": "This paper considers FL with one central server and K clients. The dataset $D_k$, locally collected by client k, remains inaccessible to others. Below is an overview of the training process for the classic FL algorithm FedAvg [24]:\nStep 1 Initialization. At the initial communication round r = 0, all local model parameters of K clients are initialized as the global model parameter: $\u03b8^r_k = \u03b8^0_S$, where $\u03b8^r_k$ and $\u03b8^0_S$ denotes the model parameters of client k and the server at round 0, respectively.\nStep 2 Client Update. Each client k trains the model on their private dataset $D_k$ with task objective $L(D_k; \u03b8^r_k)$. Then, upload the trained local model parameters $\u03b8^{r+1}_k$, to the server.\nStep 3 Server Execute. The server aggregates the received parameters by $\u03b8^{r+1}_S = \\frac{1}{N_{sum}} \\sum_{k=1}^{K} N_k\u03b8^{r+1}_k$, where $N_k$ denotes the number of data samples of client k, and $N_{sum}$ is the total number of data samples across all clients. Then, the server distributes the new global model parameters to clients in the following round.\nIterate Steps 2 and 3 continuously until the final communication round. The global objective of the overall FL process is:\n$\\arg \\min_\u03b8 L(\u03b8) = \\sum_{k=1}^K L(D_k; \u03b8).$"}, {"title": "3.2 Social Event Detection", "content": "Given a collection of social messages M, a social event detection algorithm aims to learn a model $f(M; \u03b8) = E$ from M, where \u03b8 is the model parameter, $E = \\{e_j | 1 \u2264 j \u2264 |E|\\}$ is the set of events (all labels)."}, {"title": "3.3 Threat Model", "content": "Current federated paradigms are vulnerable to injection attacks [22]. In this work, the threat model is defined by the presence of malicious clients deliberately injecting backdoors within the training data (data poisoning attack) or uploading corrupted parameters to the server (model poisoning attack) to sabotage the FL process (e.g., performance, collaboration). Such attacks could have profound repercussions on the global model and threaten FL's reliability and accuracy. We analyze the robustness of the proposed framework against injection attacks in Section 6.2."}, {"title": "4 METHODOLOGY", "content": "This section presents the proposed framework, which consists of four key components: backbone model of SED, local aggregation, global aggregation, and global-local alignment. The overall framework is illustrated in Figure 1."}, {"title": "4.1 Backbone Social Event Detection Model", "content": "For FedSED, we apply GAT (Graph Attention Network) as our backbone SED model and map the text encoding of different languages into a shared vector space.\nSocial Message Graph Construction. As illustrated in Figure 1(c), attributes (including users, hashtags, and entities) are extracted from messages and connected with their corresponding messages, forming a heterogeneous social graph. Then, the heterogeneous social graph is projected onto a homogeneous social graph by retaining the original message nodes and adding edges connecting message nodes with shared attributes. In this graph, nodes represent messages, and edges signify the associations between messages.\nSocial Message Representation. The message embedding is obtained by concatenating the message's textual and temporal embedding. The temporal embedding corresponds to the message's timestamp in the OLE date format. Regarding textual embedding, accommodating the linguistic differences among clients is essential for FL. Consequently, all clients utilize the pre-trained language model, SBERT-based (Sentence-BERT [31]) multilingual model [32] to encode the textual content of messages. This implementation ensures that messages in diverse languages reside within a unified feature space."}, {"title": "4.2 Local Aggregation via Bayesian Optimization", "content": "We introduce a local aggregation mechanism, where clients learn a strategy that incorporates global knowledge while preserving their local characteristics rather than being directly overridden by the global model. The following optimization problem is formulated to describe the local aggregation process at the r-th communication"}, {"title": "4.2.1 Objective Function", "content": "round for client k:\n$\u03b8^{r+1}_k \u2190 \u03bb \u00b7 \u03b8^r_l + (1 - \u03bb) \u00b7 \u03b8^r_g$,\nwhere $\u03b8^r_l$ and $\u03b8^r_g$ denote the local and global model parameters, respectively. $\u03bb \u2208 R$ represents the aggregation weight (the weight of local preservation). Local aggregation strives to determine the optimal or near-optimal weight $\u03bb$, that allows clients to acquire the maximum amount of knowledge. The process of $\u03b8^{r+1}_k \u2190$ is described in Section 4.4.\nBayesian Optimization (BO) algorithm [9] is a widely employed approach for optimizing functions with costly or challenging direct evaluations. We utilize BO for determining the aggregation weight $\u03bb^r$ for Local Aggregation (BOLA), as shown in Figure 1(d). BOLA is accomplished through a three-step BO procedure: first defining the objective function, then modeling it using a Bayesian statistical model, and finally determining the subsequent sampling position by an acquisition function.\n4.2.1 Objective Function. The objective function for a single round of local aggregation can be formulated as follows (symbols denoting the r-th round and client k are omitted for simplicity):\n$\u03bb = arg \\max_{\u03bb\u2208 [\u03b1,1]} f(\u03bb \u00b7 \u03b8^r_l + (1 - \u03bb) \u00b7 \u03b8^r_g, D)$,\nsuggesting that the aggregation weight $\u03bb$ can be evaluated by observing the task-specific performance of the aggregated model on private datasets D, e.g., NMI score for SED performance. $\u03bb$ is controlled by a hyperparameter $\u03b1 \u2208 [0, 1)$ to reduce search space."}, {"title": "4.2.2 Bayesian statistical model", "content": "To model the object function (Equation 3), Gaussian Process regression (GPR) is applied. Specifically, for any finite set of points $\u03bb = [\u03bb_1, \u03bb_2, ..., \u03bb_n]$, the joint distribution of the corresponding function values $f(\u03bb) = [f(\u03bb_1), f(\u03bb_2), ... , f(\u03bb_n)]$ follows a multivariate Gaussian distribution. Consequently, f(\u03bb) is characterized as a Gaussian process, denoted as:\n$f(\u03bb) \u223c Normal (\u03bc (\u03bb), \u03ba (\u03bb, \u03bb))$,\nwhere $\u03bc(\u00b7)$ and $\u03ba(\u00b7, \u00b7)$ denote the mean and kernel functions, respectively. The learnable parameters in these functions can be estimated through maximum likelihood estimation.\nApplying Bayes' rule, we obtain a joint probability distribution:\n$\\left[\\begin{array}{l}f(\u03bb) \\\\ f(\u03bb^*)\\end{array}\\right] \\sim Normal \\left(\\left[\\begin{array}{l}\u03bc(\u03bb) \\\\ \u03bc(\u03bb^*)\\end{array}\\right], \\left[\\begin{array}{ll}K & K^* \\\\ K^* & K^{**}\\end{array}\\right]\\right)$,\nwhere $\u03bb^*$ denotes the current optimal value of $\u03bb$, which serves as the objective of the optimization process. $K = \u03ba(\u03bb, \u03bb), K^* = \u03ba(\u03bb, \u03bb^*)$, and $K^{**} = \u03ba(\u03bb^*, \u03bb^*)$. Based on the joint distribution of f(\u03bb) and f($\u03bb^*$), the conditional distribution is as follows:\n$f(\u03bb^*) | f(\u03bb) \\sim Normal(\u03bc^*, \u03ba^*)$,\n$\u03bc^* = \u03bc(\u03bb^*) + K^*K^{-1}(f(\u03bb) - \u03bc(\u03bb))$,\n$\u03ba^* = K^{**}-K^*K^{-1}K^*$.\nThrough the above equations, it is observed that the posterior distribution's statistical properties $\u03bc^*$ and $\u03ba^*$ are modeled using GPR on the prior distribution's mean function $\u03bc(\u03bb)$ and covariance function $\u03ba (\u03bb, \u03bb^*)$."}, {"title": "4.2.3 Acquisition function", "content": "The acquisition function is used to determine the next aggregation weight. In this work, we apply the"}, {"title": "4.3 Global Aggregation via 2D Structural Entropy Minimization", "content": "Under the federated framework described in Section 3.1, personalized global aggregation aims to provide clients with maximum external information by producing global models that can benefit individual clients more. The server needs an aggregation strategy that considers client heterogeneity and individual characteristics to maximize external knowledge for all clients. To achieve this objective, we construct a client graph $G_{client}$ based on clients' similarity. By minimizing the two-dimensional Structural Entropy (2DSE) of $G_{client}$, a graph capturing the internal similarities among clients is obtained, finalizing the Global Aggregation strategy for each client (SEGA). This process is demonstrated in Figure 1(b).\n$G_{client}$ is an undirected, fully connected, weighted graph consisting of K nodes corresponding to K clients, with their similarities as edge weights. The similarity between client models can be estimated by providing them with the same input and measuring the similarity between their respective outputs. On this basis, the server first generates a random graph $G_{random}$ as input to all client models [11]. With graph pooling [15], the server obtains different client models' representations of the same graph, and the similarity between client u and v is calculated as:\n$sim(u, v) = \\frac{h_u^T h_v}{||h_u|| ||h_v||}$,\nwhere $h_u$ is the averaged output of all node embeddings in the input graph $G_{random}$ and sim(u, v) = 1."}, {"title": "4.4 Local Optimization", "content": "In Section 4.2, we introduced a local aggregation strategy that aggregates $\u03b8^r_l$ and $\u03b8^r_g$ into $\u03b8^r_k$. This section describes the local optimization of f(\u03b8) with local data, maintaining the proximity between the local and the global models while preventing overfitting to the local data. The overall process is shown in Figure 1(e).\nStep 1: Triplet Loss. Essentially, the objective of SED is to maximize similarity among messages belonging to the same event. Current approaches in SED [2] employ contrastive triplet loss to guide the optimization process. The triplet loss is computed as:\n$L = \\sum_{(m_i,m_i^+,m_i^-)\u2208\\{T\\}} \\max\\{D(h_{m_i}, h_{m_i^+})- D(h_{m_i}, h_{m_i^-}) + \u03b1, 0\\},$ \nwhere $(m_i, m_i^+, m_i^-) \u2208 \\{T\\}$ is a set of constructed triples, $m_i$ represents the anchor sample, $m_i^+$ represents the positive sample (i.e., a sample from the same class as the anchor sample), and $m_i^-$ represents the negative sample (i.e., a sample from a different class than the anchor sample). D() calculates the Euclidean distance between samples, $h_{m_i}$ denotes the representation of message $m_i$, \u03b1 is the margin parameter, and * = {g, l} denotes global or local.\nStep 2: Global-Local Event-Centric Constraint. In FedSED, data among clients exhibits non-IID characteristics. This non-IID nature leads to \"client-drift\", resulting in low model utility. Building on this observation, our study introduces an Event-Centric Constraint that aligns the Global and Local models closer (GLECC). Firstly, the client obtains message representations from global model f($\u03b8^g$) and aggregated model f($\u03b8^l$). Then, we learn the event representation from f($\u03b8^g$) and f($\u03b8^l$) based on the representations of the messages within each event:\n$h_{e_i} = \\frac{1}{N_{e_i}} \\sum \\{h_{m_j} m_j \u2208 e_i\\},$ \nwhere $N_{e_i}$ is the total number of messages in event $e_i$, and * = {g, l} denotes global or local. Finally, GLECC is calculated with pairwise loss [33] as:\n$L_{GLECC} = \\frac{1}{N_E} \\sum_{i=1}^{N_E} ||h_{e_i} - h_{e_i}||_2,$\nwhere $N_E$ denotes the number of events in the current batch. By pulling closer the representations of the same event in both global and local models, the server and client establish a mutual consensus on representation learning. This alignment mitigates the risk of overfitting to local data, preventing divergence from the global context, as well as the tendency to solely pursue the global objective while disregarding local characteristics.\nStep 3: Overall Loss. The overall loss during the optimization process is calculated as follows:\n$L = L + L_{GLECC}$,\nwhere \u03b1 is calculated as:\n$\u03b1 = exp(min\\{(L - L^g), 0\\})$"}, {"title": "5 EXPERIMENTAL SETUPS", "content": "This section introduces the experiment setups. We outline the following research questions (RQs) as guidelines for our experiments:\n\u2022 RQ1: Compared to existing FL approaches, can the proposed DAMe improve local performance?\n\u2022 RQ2: Is the proposed framework robust (able to withstand injection attacks) in the setting of federated learning?\n\u2022 RQ3: How does each component of the proposed framework contribute to the overall performance?\n\u2022 RQ4: Regarding computation and communication, is the proposed framework efficient?"}, {"title": "5.1 Datasets", "content": "We conducted experiments on 6 datasets, spanning 6 languages and 2 platforms. Table 1 presents the statistics of all datasets. The English Twitter [25] dataset, the French Twitter [23] dataset, and the Arabic Twitter [1] dataset are publicly available. We collect the rest of the datasets from Weibo in Chinese and Twitter in Japanese and German. First, we extracted key events from Wikipedia pages in multiple languages for 2018. Subsequently, we retrieved relevant posts from Twitter or Weibo using event keywords and crawled them to construct the datasets. The events listed on Wikipedia pages in different languages are customized according to users' preferences in that language, making the obtained dataset closely resemble real-world distributions."}, {"title": "5.2 Federated Setting", "content": "Prior works [20, 44] often partition a single dataset into multiple clients to mimic the federated setting. However, such practices fail to capture the non-IID nature of real-world data. This study breaks this cycle by treating each dataset as an independent client in the experiments. This enables us to replicate the complexities of real-world data distribution across platforms more accurately. By preserving the inherent non-IID characteristics of the data, we aim to enhance the fidelity of our federated learning experiments and provide insights that are more applicable to practical scenarios. In our experiments, we utilize a setup consisting of one server and six clients, each with social message data in distinct languages."}, {"title": "5.3 Baselines", "content": "In addition to Local training without parameter sharing, we compare DAMe with two categories of FL methods in the task of SED: (1) Classic FL methods: FedAvg [24] aggregates a weighted global model for all clients. FedProx [18] introduce regularization to alleviate disparities between the global and local models. (2) Personalized FL methods: Per-FedAvg [8] fine-tunes the global model on the client side to achieve personalization. In Ditto [17], each client learns an additional personalized model by incorporating a proximal term to extract information from the updated global model. SFL [4] constructs a client graph on the server and aggregates personalized models for each client via structural information. In APPLE [21], clients have access to all other clients' models and aggregates locally. FedALA [47] dynamically aggregates the global and local parameters at a fine-grained level based on the local objective."}, {"title": "5.4 Implementation Details", "content": "The experiments are implemented using the PyTorch framework and run on a machine with eight NVIDIA Tesla A100 (40G) GPUs. We randomly sample 70%, 20%, and 10% for training, testing, and validation as common studies on SED [2, 33]. For all methods, we employ the SED model in Section 4.1 as the backbone model. The backbone model consists of two layers of GAT, where each node in the batch aggregates messages from 800 direct neighbors and 100 one-hop neighbors. We set the mini-batch size to 2000, the learning rate to be 1e - 3, the margin for the contrastive triplet loss to 3, and employed the Adam optimizer. During the FL process, we perform 50 communication rounds, and each client conducts local training for 1 epoch, a compromise value across all baselines [4, 47].\nThe baseline methods are implemented based on open-source implementations on Github23. For SFL, the client-wise relation graph is constructed based on the distances between model parameters using Euclidean distance. It is observed that FedALA failed to converge and entered a state of deadlock after the initial communication round. Therefore, we set a local patience of 10 for FedALA. We set the number of epochs for local training to 50.\nFor the robustness analysis, we conducted injection attacks involving model poisoning and data poisoning5 following [49] and [30], respectively.\nAll methods utilize k-means clustering. All experiments are repeated 5 times to mitigate the uncertainty of deep learning methods. We report the average value and standard deviation of the 5 repetitions. All implementations are available at https://github.com/XiaoyanWork/DAMe."}, {"title": "5.5 Evaluation Metric", "content": "Technically, SED involves learning representations of social messages and clustering them into specific events. We evaluate the performance of all methods using three commonly used metrics for clustering tasks: Normalized Mutual Information (NMI) [7], Adjusted Mutual Information (AMI) [42], and Adjusted Rand Index (ARI) [42]. These metrics quantify the similarity between the"}, {"title": "6 EXPERIMENTAL RESULTS", "content": "detected and ground truth clusters. A higher score of these metrics indicates better message representation."}, {"title": "6.1 RQ1: Federated Performance", "content": "This section investigates the performance of SED with various FL systems. The result is demonstrated in Table 2. The results show that DAMe has outperformed all baseline methods on all metrics for each client dataset. Especially on the Arabic dataset, which suffers from limited data samples, DAMe surpasses the baseline methods by at least 0.16, 0.17, and 0.16 regarding NMI, AMI, and ARI, respectively. This observation indicates that DAMe has the potential to integrate most external knowledge from other clients, thereby promoting local performance to the greatest extent. It is observed that compared to local training, DAMe achieves an average gain of 0.07, 0.09, and 0.14 in NMI, AMI, and ARI, respectively, surpassing all FL baseline methods. These results highlight that the proposed framework meets the objective of FedSED, which is to enhance the performance of individual clients and benefit all clients involved. Moreover, in comparison to the pFL methods, the results reveal the following: (1) When comparing methods that directly override the local model with the global model (SFL, PerFedAvg, Ditto), these methods encounter challenges in achieving satisfactory local performance. This is because, in each communication round, training is perceived as starting from scratch on the client side, initialized with the global parameters. In the case of PerFedAvg, fine-tuning on the client side with local data necessitates an additional training round after the FL process. However, during local fine-tuning, there is a risk of catastrophic forgetting, whereby the learned information from the global model can be lost. As for SFL, which aggregates the global model using structural information on the server side, does not significantly contribute to local performance improvement. This is because the objective is to personalize the model with local data, and a model that integrates the majority of external knowledge and overrides the local model disregards the importance of local characteristics, which are crucial factors in personalization. Consequently, SFL does not surpass local training in most cases. (2) When comparing DAMe with methods that locally aggregate models (FedALA and APPLE), it is observed that, for APPLE, exposing each client to other clients' local models does not necessarily lead to improved local performance. This is because clients cannot accurately determine which models are useful or possess similar distributions to their own. As for FedALA, the performance is relatively satisfactory due to its parameter-level aggregation, which aids in identifying relevant knowledge within the global model. However, FedALA's approach of dispatching the global model based on weighted averages of data samples does not provide clients with the most advantageous information they require. In contrast, our proposed framework addresses this limitation by considering client similarity during the global aggregation process. This allows the server to dispatch an aggregated global model better aligned with each client's specific needs. To sum up, the proposed dual aggregation mechanism significantly enhances the performance of local training. This is achieved by considering the local characteristics and providing clients with the knowledge"}, {"title": "6.2 RQ2: Robustness Analysis", "content": "To evaluate DAMe's robustness, we investigate its resistance to two types of attacks: model poisoning attacks and data poisoning attacks. In both attacks, the malicious client possesses the English dataset and aims to compromise the FL process. In the model poisoning attack, the client uploads manipulated parameters to the server [49], resulting in a model with no practical utility. In the"}, {"title": "6.3 RQ3: Analysis on DAMe", "content": "This section presents an ablation study to identify the contribution of the components in DAMe and analyze the effect of the modules. The results of the ablation study are presented in Figure 2. The findings demonstrate that all proposed components enhance the performance of FedSED. Specifically, BOLA exhibits a substantial influence on performance improvement. This indicates that in pFL settings, it is crucial to empower clients to determine how much they incorporate knowledge from the global model, while preserving their individual characteristics during training. Moreover, SEGA significantly improves performance and surpasses the baseline SFL, aggregating the global model based on structural information within a client graph. This finding suggests that our approach, which leverages client similarity and minimizes the 2DSE of the client graph for global aggregation, effectively identifies pertinent knowledge that boosts local performance. Lastly, GLECC also plays a role in improving overall performance. This implies that aligning the global and local representations of the same event is advantageous for achieving a consensus between the global and local models, thereby mitigating the inherent heterogeneity.\nWe analyze the Bayesian search space in the last communication round of the FL process and present the visualization of BOLA in Figure 3. For all clients, DAMe achieves the best performance. For French, German, and Japanese Twitter, DAMe without BOLA"}, {"title": "6.4 RQ4: Overhead Analysis", "content": "Here, we delve into the crucial factors in FL, including the convergence, computation and communication overhead of the proposed framework and baseline methods.\nConvergence As depicted in Figure 4, the proposed DAMe demonstrates stable convergence. This stability can be attributed to DAMe's tailored design for the task of SED, which focuses on learning message representations and performing clustering. DAMe stands out as the first work to consider the characteristics of the SED task, unlike baseline methods, which serve as a general framework for FL. This task-specific approach allows DAMe to better suit the requirements of SED, enhancing its performance and convergence compared to the less specialized FL baselines.\nComputation Overhead The second column in Table 4 presents the time consumption of all methods during the entire training process. It is observed that DAMe without the GLECC module has the shortest time for training in the FL setting, shorter than DAMe, since it omit the process of obtaining the global and local event representation. Moreover, Per-FedAvg and Ditto exhibit the longest training times, surpassing DAMe's duration by 1.5 times. This can be attributed to their approaches of local fine-tuning or training additional local models, which significantly prolongs the training process. However, contrasting the results in Table 2, these methods do not demonstrate substantial performance improvements. In this regard, DAMe demonstrates success in such scenarios by achieving notable task performance while maintaining reasonable computational overhead.\nCommunication Overhead The communication overhead is shown in the last column in Table 4. In most scenarios, the methods adhere to the centralized FL setting, where a single server communicates with all clients, leading to a consistent communication overhead across the same parameter scales. However, APPLE adopts a decentralized FL setting, where all clients interact with each other to determine a local aggregation strategy. This significantly increases the communication overhead as the number of clients grows. In our experiment, where K = 6, the communication overhead of APPLE is 3.5 times higher compared to other methods."}, {"title": "7 CONCLUSION", "content": "In this paper, we initiate the study on FedSED and propose DAMe, a personalized federated framework for social event detection that incorporates two aggregation strategies. In DAMe, the server provides clients with maximum external knowledge with a structural entropy-based global aggregation strategy; clients leverage received knowledge and retain local characteristics to the greatest extent by a Bayesian optimization-based local aggregation strategy. Moreover, the local optimization process is guided by an event-centric constraint that mitigates the issues arising from heterogeneity, while preventing overfitting to the local data. Extensive experiments on six SED datasets across six languages and two platforms"}]}