{"title": "Disentangling Age and Identity with a Mutual Information Minimization Approach for Cross-Age Speaker Verification", "authors": ["Fengrun Zhang", "Wangjin Zhou", "Yiming Liu", "Wang Geng", "Yahui Shan", "Chen Zhang"], "abstract": "There has been an increasing research interest in cross-age speaker verification (CASV). However, existing speaker verification systems perform poorly in CASV due to the great individual differences in voice caused by aging. In this paper, we propose a disentangled representation learning framework for CASV based on mutual information (MI) minimization. In our method, a backbone model is trained to disentangle the identity- and age-related embeddings from speaker information, and an MI estimator is trained to minimize the correlation between age- and identity-related embeddings via MI minimization, resulting in age-invariant speaker embeddings. Furthermore, by using the age gaps between positive and negative samples, we propose an aging-aware MI minimization loss function that allows the backbone model to focus more on the vocal changes with large age gaps. Experimental results show that the proposed method outperforms other methods on multiple Cross-Age test sets of Vox-CA.\nIndex Terms: speaker verification, cross-age, mutual information minimization, disentangled representation learning", "sections": [{"title": "1. Introduction", "content": "With the remarkable advancement of deep learning, current X-Vector based models [1-3] and margin-based loss functions [4,5] have achieved excellent performance in automatic speaker verification (ASV). Despite the impressive success of general ASV, most systems are not robust and are easily affected by various complex factors in reality, including speaker-to-microphone distance, language and speaking style. While increasing research attention has been attracted to the above factors [6-8], aging factors on ASV are rarely studied due to the insufficiency of relevant data in the past.\nCross-Age Speaker Verification (CASV) aims to verify the same speaker's recordings across different ages. In recent years, [9, 10] provide partial age labels of speakers from Vox-Celeb [11, 12] by manual labeling. [13] adopt the face age estimation method to automatically conduct age labels for Voxceleb, providing possibilities for CASV task. The cross-age scenes are challenging because of the increasing intra-identity distance for the same speaker's voice caused by aging. Physiologically, as humans age, their vocal organs (i.e., vocal tract and vocal folds) change, resulting in variations in acoustic characteristics (i.e., F0, formant and loudness) [14, 15]. In a word, the aging factors result in significant intra-identity variations.\nA typical example is illustrated in Fig.1 that speaker embeddings have marked variations within the same identity across different ages while those of different identities are more similar, raising challenges in current ASV systems. While voice aging is a complex process affected by intrinsic and extrinsic factors, the changes of measurable acoustic parameters have similar trends [16]. Hence, it is feasible and significant to disentangle the speaker representation into age embedding and age-invariant identity embedding for CASV.\nExisting disentangling method in CASV directly eliminates age information from speaker representation via an age classification loss and gradient reversal [13]. However, the gradient reversal tends to confuse age information rather than recognize and disentangle it from identity information. Moreover, while making age information indistinguishable, gradient reversal can only learn age information, rather than effectiveness on speaker representation of aging factors.\nIn this paper, we propose a mutual information (MI) based approach to learn age-invariant speaker embeddings. Specifically, our method consists of a backbone model and an MI estimator. The relationship between the two modules is similar to the generative adversarial network [17]. The MI estimator is trained to measure the MI between age and identity embeddings from the backbone model while the backbone model is guided to minimize the MI between these two embeddings by the MI estimator. The MI minimization (MIM) results in identity-related embeddings containing as little age information as possible, approaching age-invariant speaker embeddings. Moreover, we propose a novel aging-aware (AA) MI minimization loss function to let the backbone model pay more attention to the influence of aging factors on speaker representation, leading to better age-invariant speaker embeddings.\nThe major contributions are summarized as follows:"}, {"title": "2. Method", "content": "As illustrated in Fig. 2, our method consists of two modules. The backbone model extracts the initial embedding $x_{init}$ and disentangles it into age embedding $x_{age}$ and age-invariant identity embedding $x_{id}$. The mutual information (MI) estimator learns to estimate the MI and guides the backbone model to minimize the MI between $x_{age}$ and $x_{id}$ via back-propagation.\n2.1. Representation Disentanglement\nThe backbone model is designed to extract age embedding $x_{age}$ and age-invariant identity embedding $x_{id}$. The feature encoder extracts feature maps $x' \\in R^{c \\times f \\times t}$ from an input audio $x \\in R^{1 \\times T}$. As $x'$ represents high-level information, we adopt global statistics pooling to capture global speaker information $x_{init} \\in R^d$ and attentive statistics pooling $x_{age} \\in R^d$ to capture age-related information. These two pooling layers lead to initial disentanglement of age information.\nMotivated by previous works [13, 18], we model $x_{age}$ and $x_{id}$ as statistically independent variables. Since the initial embedding $x_{init}$ represents speaker information, which consists of both age information and age-invariant information, we define the disentanglement as:\n$x_{init} = x_{age} + x_{id}$\nAfter disentanglement, we obtain the identity-related embedding $x_{id}$ through a simple subtraction. We then use ArcFace loss $L_{id}$ for identity classification and softmax loss $L_{age}$ for age classification to learn the corresponding embeddings.\n$L_{id} = - \\frac{1}{N} \\sum_{i=1}^{N} log \\frac{e^{s \\cdot cos(\\theta_{y_i}+m)}}{\\sum_{j=1}^{N} e^{s \\cdot cos(\\theta_{y_i}+m)} + \\sum_{j; y_j \\neq y_i} e^{s \\cdot cos \\theta_j}}$\n$L_{age} = - \\frac{1}{N} \\sum_{i=1}^{N} log \\frac{e^{z_i}}{\\sum_{j=1}^{J} e^{z_j}}$\nwhere $y_i$ and $z_i$ are the corresponding logits of the ground truth identity and age labels. Through this multi-task learning framework, we ensure that $x_{id}$ contains abundant identity-related information and $x_{age}$ contains abundant age-related information.\nDifferent from identity classification, where different identities vary greatly, ages with few gaps are indistinguishable in real scenes. Therefore, the target of $L_{age}$ is to map $x_{age}$ into its corresponding age groups.\n2.2. Mutual Information Minimization\n2.2.1. Basic Optimization\nMI estimation has been widely used in deep learning to constrain correlation between variables [18-20]. We consider it also promising to disentangle age-related and age-invariant information from initial speaker embeddings. The MI between $x_{age}$ and $x_{id}$ is defined as :\n$I(x_{age}; x_{id}) = \\int_{X_{age}} \\int_{X_{id}} log \\frac{p(x_{age}, x_{id})}{p(x_{age})p(x_{id})} dp(x_{age}, x_{id})$\nwhere $p(x_{age}, x_{id})$ is the joint probability distribution while $p(x_{age})$ and $p(x_{id})$ are the marginals.\nFor MI minimization, the common practice is to estimate and minimize the upper bound of MI. In this paper, we adopt the sampled Contrastive Log-ratio Upper Bound (CLUB) [21] as the basic MI minimizing function, which is better in the bias-variance estimation trade-off and more effective for MI minimization. As the conditional distribution $p(x_{age}|x_{id})$ is unknown, a variational distribution $q_{\\theta} (x_{age}|x_{id})$ with parameter $\\theta$ modeled by a neural network is used to approximate real distribution $p(x_{age} x_{id})$. The upper bound of MI is defined as:\n$\\mathcal{I}(x_{age}; x_{id}) :=E_{p(x_{id},x_{age})} [log q_{\\theta} (x_{age}|x_{id})] - E_{p(x_{id})} E_{p(x_{age})} [log q_{\\theta} (x_{age} x_{id})]$\nWith sample pairs $(x_{age}, x_{id})_{i=1}^{N}$, the MI minimization objective function for the backbone model is defined as:\n$L_{MIM} = \\frac{1}{N} \\sum_{i=1}^{N} [log q_{\\theta} (x_{age}|x_{id}) - log q_{\\theta} (x_{age} x_{id}^k)]$\nWhere $(x_{age}^k, x_{id})$ is the negative pair sampled from the same training batch with the condition $ki \\neq i$. Meanwhile, the MI"}, {"title": "2.2.2. Aging-Aware Mutual Information Minimization", "content": "estimator is trained to minimize the KL-divergence between real distribution $p(x_{age} x_{id})$ and the variational distribution $q_{\\theta} (x_{age}|x_{id})$ so that $q_{\\theta} (x_{age}|x_{id})$ is an accurate approximation to $p(x_{age} x_{id})$:\n$L_{KL} = KL(p(x_{age} x_{id}) || q_{\\theta} (x_{age}|x_{id}))$\nSince the absolute error is bounded by the approximation performance $KL(p(x_{age} x_{id}) || q_{\\theta} (x_{age}|x_{id}))$, the MI between $x_{id}$ and $x_{age}$ is also estimated with less bias by maximizing the $E_{p(x_{id},x_{age})} [log q_{\\theta} (x_{age} x_{id})]$.\nIn CASV, since age labels are noisy and aging factors have different effects on people, $L_{MIM}$ fluctuates within a very wide range due to the log-ratio bound. We propose to replace the log-ratio bound with probability-ratio so that $L_{MIM}$ fluctuates more slightly.\nMoreover, in a previous study [16], the researchers found that vocal aging across short-term is not obvious in measurable acoustic parameters (i.e., F0). This is also consistent with human perception, where vocal changes over a few years are almost imperceptible. In Eq. 6, the negative sample $x_{age}^k$ is randomly selected from the same batch. However, $q_{\\theta} (x_{age}|x_{id}^k)$ is expected to be equally maximized regardless of the age gaps between $x_{age}$ and $x_{age}^k$.\nTo better utilize the relations contained in age labels, we reweight the age gap of $x_{age}$ and $x_{age}^k$ to learn correlations among different ages by a hyper-parameter $\\delta_o$. This aging-aware objective function is defined as:\n$L_{AA-MIM} = - \\frac{1}{N} \\sum_{i=1}^{N} log(z_{age} - z_{age}^k + \\delta_o)$\n$L_{AA-MIM} = \\sum_{i=1}^{N} [q_{\\theta} (x_{age}|x_{id}) - q_{\\theta} (x_{age}|x_{id}^k)] \\cdot log(z_{age} - z_{age}^k + \\delta_o)$\nwhere $z_{age}$, $z_{age}^k$ is the ground truth age labels and $\\delta_o$ is an offset hyper-parameter. Via Eq. 9, the backbone model is trained to minimize the MI between $x_{id}$ and $x_{age}$.\n2.3. Overall Framework\nAs illustrated in Fig. 2, the backbone model with parameter $\\phi$ is optimized by three supervised tasks: identity classification loss $L_{id}$, age classification loss $L_{age}$, MI minimization loss $L_{AA-MIM}$:\n$L = L_{id} + \\lambda_{age} L_{age} + \\lambda_{MI} L_{AA-MIM}$\nwhere $\\lambda_{age}$ and $\\lambda_{MI}$ are hyper-parameters to balance the overall loss. The overall training process is described in Algorithm 1."}, {"title": "3. Experiments", "content": "3.1. Datasets\nVox-CA train set [13] constructed on Voxceleb2 [12] is used to train the model which contains 5990 speakers with 1085425 utterances. Vox-CA test sets constructed on Voxceleb1 [11] consist of multiple test trials with different cross-age scenes. We chose both Only-CA and Vox-CA trials for evaluation. Compared with Only-CA, Vox-CA takes gender and nationality into account when constructing negative pairs. In addition, the widely used Voxceleb1 test sets(i.e., Vox-O, Vox-E, Vox-H) are adopted to evaluate the performance of the general speaker verification task. The details of the test sets used in this paper are reported in Table. 1. MUSAN [22] and RIRs [23] are used for data augmentation.\n3.2. Experimental Settings\nThe input 80-dimensional Fbank is extracted with a frame length of 25ms and frame hop of 10ms. Three data augmentation methods are adopted: 1) adding noise using MUSAN. 2) adding reverberation using RIR. 3) speed perturbation. When training, each utterance is cut into chunks that contain a length of 200 frames.\nFor the backbone model, Resnet34 [24] is adopted as the feature encoder. The initial learning rate (LR) of the Stochastic gradient descent (SGD) optimizer is 0.1 and follows an Expo-"}, {"title": "4. Results", "content": "nential Decrease with a weight decay of le-4. We also adopt the warming up LR in the first six epochs. The training process is stopped when LR dropped to 5e-5. The ArcFace loss $L_{id}$ is used with a scaling factor of 48 and a margin of 0.2. The softmax loss $L_{age}$ is used for age group classification, where age is split into 7 groups: 0-20, 21-30, 31-40, 41-50, 51-60, 61-70, 71-80. The hyper-parameters of L are set as following: $\\lambda_{age}$ = 0.1 and $\\lambda_{MI}$ = 0.0001.\nFor the MI estimator, $q_{\\theta} (x_{age}|x_{id})$ is parameterized by a Gaussian distribution. The mean and variance vectors are obtained by a series of fully-connected (FC) layers and non-linear transformations. The network to obtain the mean vector consists of a 256 \u00d7 512 FC layer, a ReLU layer and a 512 \u00d7 256 FC layer. The network to obtain the variance vector consists of a 256 \u00d7 512 FC layers, a ReLU layer, a 512 \u00d7 256 FC layer and a Tanh layer. Adam [25] with an LR of le-5 and a weight decay of 1e-4 is used to optimize the MI estimator.\nFor all networks, the batch size of the input is 384. No backend scoring is used in inference. The experiment is conducted on Wespeaker [26].\nSame as most SV tasks, Equal Error Rate (EER) and Minimum Detection Cost Function (minDCF) with $P_{target}$ = 0.01 and $C_{FA}$ = $C_{Miss}$ = 1 are adopted as the evaluation metrics.\n4.1. Results on Cross-age tasks\nTable. 2 shows the performance of the current methods on Vox-CA test sets. We re-implement ResNet34 [24] and SOTA ResNet34+ADAL [13] for comparison. Compared with ResNet34+ADAL, our method achieves relative improvement in overall performance by 1.53% in EER and 4.79% in minDCF, respectively, demonstrating that our method learns better age-invariant speaker embeddings.\nIn addition, we further conduct two ablation experiments to analyze the contributions of each proposed component. 'Ours w/o AA' denotes that the aging-aware function is removed and $\\delta_o$ is set to 1 regardless of the age gaps in Eq.8. Then if the MI estimator is removed ('Ours w/o MIM'), the backbone model is only supervised by age and identity classification loss. As can be seen in Table. 2, without the aging-aware function, the performance declines on most sets. Then if the MIM process is removed, the performance becomes even worse than the baseline"}, {"title": "4.2. Results on General tasks", "content": "ResNet34 model. We consider that the architecture of the backbone model to split $x_{id}$ and $x_{age}$ from $x_{init}$ is effective only when combined with disentanglement methods (i.e., gradient reversal [27] and MI minimization [21]). Without disentanglement methods to model the relations between age and identity, the performance can not be improved.\nIn this subsection, we introduce the performance of Voxceleb official test sets, which are conducted for general speaker verification. As is reported in Table. 3, the results among the three methods are similar, which indicates that the disentanglement of age- and identity-related information has little influence on general speaker verification.\n4.3. Visualization of Disentanglement\nTo qualitatively illustrate the effectiveness of the disentanglement, we showcase t-SNE of speaker embeddings in the cross-age scenes. We chose the target speaker 'id10113' and its negative trials in Vox-CA20 for visualization. As can be seen in Fig. 3, the points with red color represent the speaker embedding from the target speaker, while others denote the negative speakers. Since the initial $x_{init}$ contains both age and identity information, resulting in great intra-identity distance, the target speaker can be easily rejected. Compared with $x_{init}$, the disentangled $x_{id}$ embeddings show lower intra-identity distance, which indicates that $x_{id}$ tends to be age-invariant."}, {"title": "5. Conclusion", "content": "In this paper, we propose a disentangling method for CASV based on MIM. The innovation of our proposed method lies in introducing an MI estimator to the backbone model to disentangle age and identity information. By minimizing the MI between age and identity embedding, our method leads to better age-invariant speaker embeddings. In addition, we proposed an aging-aware MIM loss to utilize the relations between different ages. Experimental results in Vox-CA test sets outperform the SOTA method by 1.53% in EER and 4.79% in minDCF, respectively, demonstrating the effectiveness of our method."}]}