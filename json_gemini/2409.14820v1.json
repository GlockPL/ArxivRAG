{"title": "Past Meets Present:\nCreating Historical Analogy with Large Language Models", "authors": ["Nianqi Li", "Siyu Yuan", "Jiangjie Chen", "Jiaqing Liang", "Feng Wei", "Zujie Liang", "Deqing Yang", "Yanghua Xiao"], "abstract": "Historical analogies, which compare known\npast events with contemporary but unfamiliar\nevents, are important abilities that help peo-\nple make decisions and understand the world.\nHowever, research in applied history suggests\nthat people have difficulty finding appropriate\nanalogies. And previous studies in the AI com-\nmunity have also overlooked historical analo-\ngies. To fill this gap, in this paper, we focus on\nthe historical analogy acquisition task, which\naims to acquire analogous historical events for\na given event. We explore retrieval and gen-\neration methods for acquiring historical analo-\ngies based on different large language mod-\nels (LLMs). Furthermore, we propose a self-\nreflection method to mitigate hallucinations\nand stereotypes when LLMs generate histor-\nical analogies. Through human evaluations\nand our specially designed automatic multi-\ndimensional assessment, we find that LLMs\ngenerally have a good potential for historical\nanalogies. And the performance of the mod-\nels can be further improved by using our self-\nreflection method.", "sections": [{"title": "1 Introduction", "content": "Historical analogy, which draws comparisons be-\ntween contemporary and past situations, is a vital\ntool in applied history (Achenbaum, 1983; Guldi\nand Armitage, 2014; Parsons and Nalau, 2016; Ghi-\nlani et al., 2017; Keulen, 2023). These analogies\nenable a deeper understanding of historical events\nand facilitate informed decision-making in address-\ning present difficulties (Bartha, 2013; Axelrod and\nForster, 2017). For example, as shown in Figure 1,\nwhen the COVID-19 pandemic spread around the\nworld, the influenza pandemic of 1918 emerged\nas an analogy, aiding in the navigation of the cri-\nsis. However, historians have found that individ-\nuals, particularly politicians, often misuse histori-\ncal analogies. They tend to gravitate towards the\nfirst analogy that comes to mind, are influenced\nby superficial similarities, and rarely conduct thor-\nough analyses (Ghilani et al., 2017; Khong, 2020).\nFurthermore, the creation of historical analogies\ninvolves having extensive knowledge of historical\nevents and selecting the appropriate one, which\ncan also be a great challenge. Therefore, exploring\nlarge language models (LLMs) (AI-Meta, 2024;\nOpenAI, 2022, 2023) with the ability to automati-\ncally generate historical analogies is of great value.\nTraditional studies within the AI community\nhave concentrated on recognizing and generating\nword analogies, e.g., \u201cking is to man as queen is\nto woman\", using word embeddings (Gladkova\net al., 2016; Fournier et al., 2020; Ushio et al.,\n2021) or by training language models (LMs) (Cz-\ninczoll et al., 2022; Chen et al., 2022; Yuan et al.,\""}, {"title": "2 Related Work", "content": "Analogy Making Early research in the AI com-\nmunity primarily focuses on generating word analo-\ngies (Gladkova et al., 2016; Fournier et al., 2020;\nUshio et al., 2021; Yuan et al., 2023c) to examine\nthe capabilities of LMs in analogy-making. Re-\ncent advancements in LLMs (OpenAI, 2022, 2023;\nAI-Meta, 2024) have expanded this focus from sim-\nple word analogies to the generation of analogies\ninvolving more complex entities, including sys-\ntems (Yuan et al., 2023b), processes (Bhavya et al.,\n2022; Sultan and Shahaf, 2022; Sultan et al., 2024),\nparagraphs (Webb et al., 2022; Wijesiriwardene\net al., 2023; Ding et al., 2023; Ye et al., 2024; Yuan\net al., 2024), and stories (Jiayang et al., 2023). De-\nspite these developments, most studies have con-\ncentrated on analogies within the scientific domain\nor everyday scenarios, overlooking the significance\nof historical analogy, which is pivotal in applied\nhistory (Schuman and Rieger, 1992; Parsons and\nNalau, 2016; Ghilani et al., 2017). In contrast, our\nresearch is the first to investigate and assess how\nLLMs can identify historical analogy. This capabil-\nity could significantly facilitate access to historical\ninsights and robustly support policy and decision-\nmaking processes (Keulen, 2023).\nLanguage Model as Knowledge Base Previous\nresearch has demonstrated that, pre-trained with\nextensive datasets, LLMs can implicitly encode a"}, {"title": "3 Historical Analogy Generation", "content": "3.1 A Cognitive Perspective for Historical\nAnalogy\nHistorical analogy facilitates comparisons between\ncontemporary and past situations, offering an ac-\ncessible view of history and validating policies\nand decisions (Schuman and Rieger, 1992; Keulen,\n2023). Margaret Thatcher likened Iraq's invasion\nof Kuwait to the Munich Agreement, thereby using\nhistorical analogy to support their intervention ac-\ntions in Iraq (Conolly-Smith, 2009). Therefore, his-\ntorical analogy is a vital tool in applied history (Par-\nsons and Nalau, 2016).\nHistorical analogy employs the same logical\nstructure as analogical reasoning. In the context\nof historical analogy, both events and personalities\nfrom the source domain serve to formulate an ar-\ngument by analogy, elucidating the present issue\n(the target domain). However, research conducted\nby historians indicates that individuals, particularly\npoliticians, ordinarily use history badly. They of-\nten gravitate towards the first analogy that comes\nto mind, are easily swayed by superficial similari-\nties, and rarely pursue in-depth or extensive anal-\nysis (Ghilani et al., 2017; Dobney, 1974; Khong,\n2020). Therefore, it is crucial to develop a frame-\nwork that facilitates the automatic, straightforward,\nand precise acquisition of historical analogy."}, {"title": "3.2 Task Formulation", "content": "Historical analogy acquisition task aims to obtain\na historical event for the given event to form an\nanalogy. Given the input event E\u2081 and its descrip-\ntion D\u2081, the goal is to output the event from history\n\u0415\u043d, which is analogous to the input event. Figure 1\npresents an example of a historical analogy."}, {"title": "3.3 Data Construction", "content": "To comprehensively evaluate the ability of LLMs\nto acquire historical analogies, we categorized his-\ntorical analogies into two categories, i.e., popular\nanalogy and general analogy.\nPopular Analogy Popular analogies are analo-\ngies that are well known to the general public and\nalready have standardized results, often proposed\nby newspapers, historians, and politicians. For ex-\nample, the COVID-19 pandemic is often analogous\nto the Spanish pandemic. To obtain these analogies,\nwe manually collect samples of popular analogies\nfrom web pages and articles related to historical\nanalogies. Due to the limited number of valid\nanalogies and the presence of misuses or controver-\nsies, we end up with 20 test samples that are widely\nrecognized, have standard answers, and show some\ndegree of creativity.\nGeneral Analogy LLMs may have learned popu-\nlar analogies during their pre-training phase. There-\nfore, we also construct general analogy sets that\ncomprise general historical events that lack univer-\nsally recognized analogical events. Specifically,\nwe first collect 658 historical events spanning from\n8000 BCE to the present from Google Arts and\nCulture. These events were categorized into four\nthemes: War, Politics, Culture and Society, and\nEconomy. We select 50 samples, each from the\nfirst three categories and 10 from the Economy cat-\negory, creating a balanced general analogical set to\nassess the LLM's ability to draw historical analo-\ngies across different themes. Since there are no\nstandardized answers for general analogies, it is\nnecessary to develop automated evaluation metrics\nto assess the quality of analogies between analogy\nevents and input events."}, {"title": "3.4 Human Evaluation Metrics", "content": "Due to the lack of quantitative criteria for evaluat-\ning analogies, this paper uses a ranking approach"}, {"title": "3.5 Automatic Evaluation Metrics", "content": "For Popular Analogies, we can calculate the\nPass@1 based on the standard answers. However,\nit is not applicable to General Analogies, necessitat-\ning the development of broader metrics for automat-\nically evaluating historical analogies quantitatively.\nDrawing on the historical applied science, we de-\nvelop a multi-dimensional similarity metric (MDS)\nto evaluate historical analogies automatically.\nDimension Summary In historiography, the uni-\nversal structure of events encompasses topic, back-\nground, process, and result. Therefore, for an event\nE and its description D, we utilize GPT-4 to sum-\nmarize these four dimensions based on D, resulting\nin D = (DTopic, DBackground, DProcess, DResult). The\nprompt template for GPT-4 to summarize the di-\nmensions of the event is shown in Appendix C.2.\nMulti-level Similarity Previous research (Bunge,\n1981; Jiayang et al., 2023) indicates that analogies\nare effective when they share abstract-level simi-\nlarities (i.e., abstract similarity), such as themes,\ncentral ideas, and processes, rather than identical\nentities and behaviors (i.e., literal similarity). For\nabstract similarity, based on the four summarized\ndimensions, we instruct GPT-4 to rate the abstract\nsimilarity between E1 and EH for each dimension\non a scale from 1 to 4. The prompt template for\nthis scoring is shown in Appendix C.1. For literal\nsimilarity, we first perform the NLTK tokeniza-\ntion (Bird, 2006) on each summary and calculate\nthe Jaccard similarity (Niwattanakul et al., 2013).\nA higher abstract similarity score indicates a better\nanalogy between E\u2081 and Eh, while lower literal\nsimilarity scores indicate more innovation. Thus,\nthe overall multi-dimensional similarity formula is:\nMDS = \u2211 wd. sim Abs (DI, DH).\ndED\nmax(a \u2013 simLit(DI, DH), 0), (1)\nwhere D = {Topic, Background, Process, Result},\nwa represents the weight of each dimension's score,\nDa (D) represents the description of E1 (EH) in\nthe d dimension. Given that descriptions are di-\nmensionally summarized by GPT-4, even identical\nevents may have differing descriptions. Therefore,\na serves as a threshold to prevent overly similar\nanalogies.\nEffectiveness of Automatic Evaluation To de-\ntermine wd and a, and to validate the automatic\nevaluation, we manually evaluate the historical\nanalogous data and calculate their correlation co-\nefficients with the automated evaluation results.\nSpecifically, we use GPT4 to generate four dif-\nferent analogies for each popular analogy as the\nevaluation dataset. For the manual assessment, we\nemploy three annotators to rank the four results,\nwith Fleiss's \u043a = 0.97. For the automated assess-\nment, we adopt our automatic multi-dimensional\nsimilarity metric to rank.\nThe results show that the best correlation coef-\nficient with the manual results is obtained when\nthe dimension weights are (0.5, 1, 2, 2) for (topic,\nbackground, process, result) and the similarity\nthreshold a is 0.35. In this setting, the Kappa\ncoefficient (McHugh, 2012) is 0.67, and the Pear-\nson (Pearson, 1920) and Spearman correlation co-\nefficients (Spearman, 1961) are 0.72 and 0.73, re-\nspectively, confirming the reliability of automatic\nevaluation."}, {"title": "4 Method", "content": "In this section, we explore various methods of lever-\naging LLMs to get historical analogies. These\nmethods fall into two primary categories: 1) dataset\nretrieval methods and 2) free generation methods.\nThe illustration of these methods is shown in Fig-\nure 2. The prompt templates for LLMs in each\nmethod are shown in the Appendix C."}, {"title": "4.1 Dataset Retrieval Method", "content": "In order to obtain analogous events, a common\npractice is to select from existing datasets. In this\npaper, we use Google Arts and Culture, which con-\ntains 658 events, serving as a event pool for LLMs"}, {"title": "4.2 Free Generation Method", "content": "Due to the growing number of historical events,\nrelying on a fixed dataset for analogies can lead to\nissues such as high overhead, slow processing, and\nchallenges in updating. Since LLMs have learned\nextensive knowledge about historical events dur-\ning pre-training, we can employ LLMs to generate\nanalogous historical events.\nDirect Generation Given Er and D\u2081, this\nmethod directly asks LLMs to generate the anal-\nogous historical event EH. This approach heavily"}, {"title": "5 Results", "content": "5.1 Model Choice\nFor the main experiment, we choose the open-\nsource model Llama3.1-8B-Instruct (AI-Meta,\n2024) and the closed-source model ChatGPT\n(gpt-3.5-turbo-0125) (OpenAI, 2022), both\nwith the temperature set to 0.1.\n5.2 Main Result\nAutomatic Evaluation Results The results are\nshown in Table 1 and Figure 3. We find that:\n1) Both Llama and ChatGPT perform better on\nthe Popular Analogy than on the General Analogy.\nIn particular, Direct Generation method achieves"}, {"title": "6 Conclusion", "content": "In this paper, we explore the concept of historical\nanalogy and examine the ability of LLMs to acquire"}, {"title": "Limitations", "content": "First, our evaluation mainly focuses on the accu-\nracy of the analogous historical events, without\nassessing the reasons provided by the model due\nto the challenges in automatic evaluation of rea-\nsoning. Second, while our evaluation considers\nfour specific dimensions to determine the correct-\nness of historical analogies, it is important to note\nthat in real-life contexts, additional factors such as\ngender, party affiliation, and motivation might also\nbe considered, particularly by politicians. How-\never, we believe that the evaluation of these ad-\nditional dimensions could be automated through\nthe application of our proposed evaluation method-"}]}