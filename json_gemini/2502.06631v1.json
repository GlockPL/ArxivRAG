{"title": "Conformal Predictions for Human Action Recognition with Vision-Language Models", "authors": ["Tim Bary", "Cl\u00e9ment Fuchs", "Beno\u00eet Macq"], "abstract": "Human-In-The-Loop (HITL) frameworks are integral to many real-world computer vision systems, enabling human operators to make informed decisions with AI assistance. Conformal Predictions (CP), which provide label sets with rigorous guarantees on ground truth inclusion probabilities, have recently gained traction as a valuable tool in HITL settings. One key application area is video surveillance, closely associated with Human Action Recognition (HAR). This study explores the application of CP on top of state-of-the-art HAR methods that utilize extensively pre-trained Vision-Language Models (VLMs). Our findings reveal that CP can significantly reduce the average number of candidate classes without modifying the underlying VLM. However, these reductions often result in distributions with long tails. To address this, we introduce a method based on tuning the temperature parameter of the VLMs to minimize these tails without requiring additional calibration data. Our code is made available on GitHub at the address https://github.com/tbary/CP4VLM.", "sections": [{"title": "I. INTRODUCTION", "content": "Modern Computer Vision (CV) systems offer high performances over a wide variety of tasks, even surpassing human expertise in some cases. However, many applications still rely on Human-In-The-Loop (HITL) frameworks, either to enhance the performance of the underlying CV approach or due to the critical nature of the application, which requires the final decision to be made by a human. The field of video analysis is no stranger to this dynamic, with HITL frameworks used for video segmentation [1], a notably challenging task, as well as vehicle identification for autonomous driving [2] or Human Action Recognition (HAR) in the context of video surveillance [3].\nIn this context, Conformal Predictions (CP) have garnered significant interest. CP frameworks provide a reduced label set with a robust guarantee on ground truth coverage from the uncertainty estimates of an underlying model, provided a calibration set. This framework has proven beneficial when used in conjunction with human annotators, particularly in object classification tasks [4], [5]. This makes CP especially useful in critical applications or when a model's performance on a specific task is suboptimal, complementing existing HITL frameworks for tasks such as HAR.\nHistorically, the HAR problem was approached with statistical methods relying on features carefully crafted by experts [6]. Later on, the advent large-scale datasets as well as high performing deep-learning frameworks lead researcher to use such networks trained in a supervised manner [7]\u2013[10]. Although the latter showed a significant leap in accuracy, they are largely unable to handle novel classes at test-time. Current state-of-the art approaches [11] circumvent this problem by relying on extensively pre-trained Vision Language Models (VLMs), which can use textual descriptions of the classes to generate ad-hoc classifiers with strong zero-shot performance [12]. Recently, foundation models including VLMs have been shown to be strong conformal predictors on general image classification benchmarks [13].\nIn this work, we explore the effectiveness of using CPs on top of off-the-shelf VLMs for HAR classification tasks, without any additional fine-tuning. Our results demonstrate that CPs can significantly reduce the number of possible classes for a given video clip, even with high coverage guarantees. We also find that the sizes of the resulting conformal sets typically follow a long-tailed distribution (represented in Figure 1, top). Since human annotation time increases with the number of options available for selection [4], [14], [15], strategies to shorten this tail and reduce conformal set sizes are valuable, particularly in applications where decision time is constrained, such as live video monitoring. To address this, we highlight the importance of tuning the temperature parameter of the VLM to control the distribution of conformal set sizes. This adjustment can be made using only the calibration set, ensuring no additional data cost for conformal predictor calibration, while preserving the theoretical guarantees of the CP framework.\nWe summarize our contributions as follow:\n\u2022 We demonstrate the significant benefits of applying a conformal predictor on off-the-shelf VLMs for human action recognition tasks.\n\u2022 We propose an efficient, actionable approach to control the long-tail distribution of conformal set sizes. This method, specifically designed for VLMs, preserves the theoretical guarantees of the conformal predictor."}, {"title": "II. RELATED WORK", "content": "Providing reliable confidence estimates for predictions made by deep learning models is essential in many applications. CP offers a solution by producing sets of potential output classes for a given input, with guarantees\u2014under mild distributional assumptions\u2014that the true class will be included in the set with a specified probability.\nThe Least Ambiguous set-valued Classifier (LAC) [16]\u2013[18] computes a non conformity score for each sample $i$ inside a calibration set-which differs from the training, validation, and test sets-as:\n$S_i = 1 - Y_{i,k^*}$ (1)\nwhere $k^*$ is the ground-truth class of sample $i$ and $Y_{i,k}$ the $k$th component of the soft label $y_i$ within the $K$-simplex $\\Delta_K$, as predicted by the model. For a specific error tolerance $\\alpha$, the $1 - \\alpha$ quantile $\\hat{q}$ is derived from the distribution of the non-conformity scores of the calibration samples. The prediction sets for a test sample $i$ is obtained by including all classes $k$ for which $Y_{i,k} \\geq 1 - \\hat{q}$.\nThis approach provides theoretical guarantees, specifically that the conformal prediction set for a test sample will, on average, include the true class with a probability of at least $1 - \\alpha$. This property, known as coverage, holds for the dataset as a whole but does not ensure class-specific coverage. For a detailed discussion on the theoretical guarantees and assumptions, refer to [16], [17]."}, {"title": "B. Human action recognition", "content": "In this work, HAR denotes the problem of classifying video clips or images of a person or group of person performing a well defined action into a set of classes. To address this challenge, early methods focused on the use of handcrafted features [6], [20]. Later on, thanks to the emergence of large scale datasets such as Kinetics [21] and advances in machine learning, approaches transitioned to the design of carefully crafted deep-learning architectures trained in a supervised manner. Those architectures include networks based on convolutional building blocks [7]-[9] and more recently transformers [10].\nHowever, these models are designed to predict a fixed set of classes and do not generalize to settings not seen during training. Current state-of-the-art approaches avoid this problem by relying on VLMs, which can gracefully handle novel classes at test-time due to their extensive pretraining. This paradigm was introduced by [11], and later refined by several works such as [22] and [23]."}, {"title": "C. Vision-Language models", "content": "Vision-language alignment has become a highly influential paradigm for pretraining models that can tackle a broad range of downstream tasks with minimal or no reliance on labeled data. Contrastive approaches such as CLIP [12] learn a common representation for textual descriptions and images by concurrently optimizing a textual and visual encoders to retrieve positive pairs of captions and images. Therefore, encoding texts describing the classes of the problem at hand, which are called textual prompts, allows for the creation of an ad-hoc classifier by comparing the similarities of input images to the encoded prompts.\nFormally, the textual prompts for each of the class $k \\in [1, K]$ are processed by the textual encoder to yield the corresponding $\\ell_2$ normalized embedding $t_k \\in \\mathbb{R}^d$, where $d$ is the dimension of the shared latent space for images and texts. The query image $x_i$ is then mapped to its $\\ell_2$ normalized embedding $f_i \\in \\mathbb{R}^d$ through the visual encoder, and similarities scores\n$\\ell_{i,k} = f_i^\\intercal t_k$ (2)\nare computed for each class. These logits can be transformed into probabilistic predictions $y_i \\in \\Delta_K$ with the softmax function as follows:\n$Y_{i,k} = \\frac{\\exp(\\ell_{i,k} / T)}{\\sum_{j=1}^K \\exp(\\ell_{i,j} / T)}$ (3)\nIn Equation 3, the temperature parameter $\\tau$ controls the sharpness of the resulting probabilistic prediction. When $\\tau$ goes to infinity, the soft labels are uniformly equal to $1/K$ while the softmax becomes the $\\operatorname{argmax}$ operator when $\\tau = 0$. Note that the temperature parameter is not an hyper-parameter of the pre-training procedure, as it is also optimized during pre-training [12]."}, {"title": "III. METHODS", "content": "We conduct our experiments using three video clip datasets: HMDB51 (51 classes) [24], UCF101 (101 classes) [25] and Kinetics400 (400 classes) [21]. For HMDB51 and UCF101, we use all available samples and split them into a 10-shot calibration set and a testing set. For Kinetics400, we apply the same splitting method to the testing and validation samples from the official split from [21]. The results reported are averaged over 40 random seeds for data splitting.\nTo compute embeddings for each video clip, we extract 10 frames at uniform intervals throughout the video, and use the average of their corresponding visual embeddings, yielding a single global embedding per video. This approach corresponds to the Global Average Pooling (GAP) method described in [11]. For text prompts, we use the template: \u201ca photo of a person doing {class}.\u201d Unless otherwise specified, we use a CLIP model with a ViT-B/16 image encoder. Using this setup, we achieve base accuracies of 54% on Kinetics400, 69% on UCF101 and 48% on HMDB51."}, {"title": "B. Temperature tuning for tail size reduction", "content": "In the upper part of Figure 1, we observe how a Conformal Predictor, when combined with an off-the-shelf VLM significantly reduces the number of classes from which a human expert must choose. However, distribution of set sizes appears long-tailed on the right. This means that, for a small proportion of samples, the number of classes in the conformal set remains relatively large.\nPrevious research has shown that human decision time increases with the number of available choices [14], [15], and many practical scenarios follow Hick's law, which describes a logarithmic relationship. More recent studies suggest a sigmoidal model [26] to capture the dependence of decision time on task uncertainty, for which the number of classes in the conformal sets could serve as a proxy. This highlights the importance of controlling the tail of the set size distribution, especially for applications such as live video monitoring, where the maximum time spent by a human operator to annotate a data point is limited.\nAs $T$, the temperature parameter, affects the predicted soft labels through Equation 3, its variation indirectly influences the distribution of the non-conformity scores derived from the 10-shots calibration sets (Equation 1). Consequently, $\\tau$ also impacts the value of $\\hat{q}$, the $1 - \\alpha$ quantile of these non-conformity scores. The relationship between $\\hat{q}$ and $\\tau$, shown on Figure 2 for different $\\alpha$, is convex. To minimize the tail of the conformal set sizes distribution, we select the temperature $\\tau^* = \\operatorname{arg\\,min}_{T \\in \\mathbb{R}} \\hat{q}(T)$."}, {"title": "IV. RESULTS AND DISCUSSION", "content": "Figure 3 illustrates how the tail of the conformal set size distribution (quantiles at 0.9, 0.95, and 0.975) varies with the inverse temperature 1/\u315c across the three datasets introduced in Section III-A for different a values. Each curve includes a red dot marking 1/T*, our estimated temperature that minimizes the tail size. To validate this estimation method, a green dot indicates the true optimal temperature, 1/Topt, whenever it significantly differs from our estimate. Across all selected quantiles, a values, and datasets, the tail size obtained with T* was at most 0.775 larger than the one achieved with Topt, underscoring the robustness of our method. The figure also reveals that the sensitivity of tail set size to deviations from 1/Topt increases as a decreases. Specifically, for lower a values, deviations from the optimal temperature lead to more pronounced tail size increases. This highlights the importance of precise temperature tuning for applications demanding higher coverage guarantees.\nFigure 4 demonstrates the impact of a on tail size reduction, comparing it against the typical untuned value of 1/7 = 100 commonly used in VLMs. Notably, the reduction in tail size is most significant for smaller a, aligning with the findings in Figure 3. For Kinetics400, this reduction reaches as much as 77 classes at the highest quantile and lowest a. As a increases, the tail size reduction diminishes, reflecting a distribution shift toward smaller set sizes. However, this reduction in tail size comes at the cost of an increased average set size. Figure 5 shows that average set sizes decrease as 1/7 increases, eventually plateauing. Unfortunately, the temperatures T* that minimize the tail size (marked in red in Figure 5) occur before this plateau, leading to a higher average set size compared to the typical 1/7 = 100 setting. This trade-off is visualized in Figure 6, following a similar trend as the tail size reduction shown in Figure 4.\nThe bottom portion of Figure 1 illustrates how the conformal set size distribution changes when transitioning from 1/T = 100 to 1/T = 1/T*. Adjusting 1/7 influences the distribution of conformal set sizes in two ways:\n1) Tail Shift The distribution tail shifts, with the optimal tail size depending on a and the dataset, lying at the lower end of the 1/7 range. Deviations from 1/Topt increase the tail size more rapidly for 1/\u315c > 1/Topt than for 1/\u315c < 1/Topt.\n2) Average Shift The average set size decreases sharply with increasing 1/7 until reaching a plateau or minimum, beyond which it may increase slightly at a slower rate.\nAs these two effects have different optimal 1/7 values for a given a, it is impossible to simultaneously optimize both. A compromise temperature can be chosen based on task-specific priorities to balance the trade-offs effectively.\nTo ensure the generality of our findings, we repeated the experiments with CLIP models with alternative visual encoders, including ViT-L/14, ViT-B/32, ResNet101, and ResNet50. Figure 7 shows the results for a = 0.03, demonstrating that our temperature tuning method significantly reduces tail set sizes across both ViT-based and CNN-based architectures."}, {"title": "V. CONCLUSION AND FUTURE WORKS", "content": "In this paper, we demonstrated how integrating Conformal Predictors with off-the-shelf Vision-Language Models (VLMs) can significantly reduce the number of possible classes in Human Action Recognition tasks while maintaining coverage guarantees. Our findings highlight the influence of the temperature parameter 7 on the distribution of conformal set sizes, which mediates a trade-off between low mean, long-tailed distributions and higher mean, shorter-tailed ones.\nThe relationship between annotation time and the number of classes remains an open question. Classical studies [14], [15] suggest a logarithmic dependency on decision time, while alternative models propose a sigmoid relationship with task uncertainty [26]. Future research could develop models linking annotation speed and accuracy to conformal set sizes, offering practical insights for optimizing workflows.\nFinally, we note that Conformal Prediction requires calibration sets, and using these sets to adapt VLMs to specific tasks can violate the exchangeability assumption, weakening CP's theoretical guarantees. However, recent advancements in few-shot VLM adaptation [27]-[30] provide promising avenues for preserving these guarantees. Future work could focus on strategies to leverage calibration sets effectively while ensuring theoretical integrity."}]}