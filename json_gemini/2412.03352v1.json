{"title": "Intuitive Axial Augmentation Using Polar-Sine-Based Piecewise Distortion for Medical Slice-Wise Segmentation", "authors": ["Yiqin Zhang", "Qingkui Chen", "Chen Huang", "Zhengjie Zhang", "Meiling Chen", "Zhibing Fu"], "abstract": "Most data-driven models for medical image analysis rely on universal augmentations to improve performance. Experimental evidence has confirmed their effectiveness, but the unclear mechanism underlying them poses a barrier to the widespread acceptance and trust in such methods within the medical community. We revisit and acknowledge the unique characteristics of medical images apart from traditional digital images, and consequently, proposed a medical-specific augmentation algorithm that is more elastic and aligns well with radiology scan procedure. The method performs piecewise affine with sinusoidal distorted ray according to radius on polar coordinates, thus simulating uncertain postures of human lying flat on the scanning table. Our method could generate human visceral distribution without affecting the fundamental relative position on axial plane. Two non-adaptive algorithms, namely Meta-based Scan Table Removal and Similarity-Guided Parameter Search, are introduced to bolster robustness of our augmentation method. Experiments show our method improves accuracy across multiple famous segmentation frameworks without requiring more data samples. Our preview code is available in: https://github.com/MGAMZ/PSBPD.", "sections": [{"title": "1. Introduction", "content": "Research Significance: Deep learning models have seen significant advancements in healthcare, including the widespread adoption of automated lesion segmentation, which alleviated the workload of radiologists and contributed to diagnostic precision. The up-to-date data-driven models often require a sufficient amount of data to obtain acceptable results, which can lead to unaffordable research costs in the medical field. In the computer vision community, various data augmentation techniques are widely used as part of preprocessing [2] to alleviate data scarcity. In the field of medical imaging, an excellent augmentation method can bring the following practical significance:\n> Reduce the annotation cost of medical datasets.\n> Fully tap the value of existing precious annotations without the need for more radiologists.\n> Improve the robustness of automated annotation to enhance the \"reliability\" that is crucial in the medical field.\nConsidering there're plenty of existing neural networks for medical image analysis, we argue that creating a methodology that is applicable to most models is more impactful than solely focusing on developing an enhanced neural network model.\nTraditional Augment: Effective but Counterintuitive. Recent research [9] suggests that some data augmentation methods transform the original data in more extreme ways (e.g. Erasing, Solarize) fig. 1. Medical experts often find these samples unreasonable, not present in the real world, and devoid of practical significance. However, the reality is not the case. Experimental results show that neural networks seem to still prefer these exaggerated enhancement methods, learning more knowledge from the \u201cunreasonable\" samples and showing better performance on downstream tasks. The reasons for this phenomenon are controversial, but it is clear that the interpretability of these data augmentation methods is very poor, which is particularly important in medical AI scenarios [28, 31].\nMedical Radiologic Scan Sequences: Unexplored Potential. We notice there're significant differences in the physical imaging processes between radiologic scan images and common camera images. Patients undergoing these radiologic scans are usually required to lie flat on their backs with their hands behind their heads and arms raised above their heads for the examination, and the posture adopted by the patient is difficult to control precisely. Their motions directly influence the reconstruction results on every slice [30] fig. 1. This means that the same subject will obtain different reconstruction results when undergoing different scans, and these diverse samples can help neural networks fit more efficiently [23]. However, due to limitations in medical resources and the harmful effects of radiation, it is not acceptable to repeatedly scan the same subject [21, 32]. Considering that the subject itself does not change in the aforementioned differences, it is possible to simulate the reconstruction slice with human posture changes from the known scan sequences. Moreover, standard DICOM files potentially enables the precise execution of various data preprocessing tasks through the utilization of non-adaptive algorithms.\nOur Method: Intuitive Distortion. According to the above, we proposed a Polar-sine-based Piecewise Affine Distortion specifically for medical radiologic image augmentation. Our approach, maps the reconstruction results of the original cross-sections to a distribution of which containing the subject's posture changes. This is done to simulate the appearance when the body of the scanned individual exhibits slight distortions. In order to prevent disrupting the fundamental relative positional relationships of the human body's tissues during augmentation, we construct a random transformation algorithm based on polar coordinates combined with sine functions. The scan table will be precisely identified and eliminated utilizing metadata-driven geometric algorithm. To align AI more closely with the intuitive aspects of medical practice, we incorporate similarity metrics to regulate the intensity of distortion, preventing unreasonable augmented samples. This approach also deliberately improves the efficiency of neural network search, thereby conserving resources during model fine-tuning. To our knowledge, this is the first data augmentation algorithm inspired by the differences in reconstructed slices due to uncertainties in human posture. Our preview code is available in: https://github.com/MGAMZ/PSBPD. In summary, our augmentation algorithm has the following features:\n> It can generate any number of augmented sequences with differences from a single scan sequence, with controllable impact on the crucial relative positional features of human organs.\n> Its hyperparameters are guided by similarity metrics, providing better interpretability and precision that are crucial in the medical field.\n> It can eliminate the noise introduced by the scan table by using DICOM-metadata-based geometric positioning, achieving both excellent effects and speed."}, {"title": "2. Related Works", "content": "Medical Radiologic Image Preprocess. [4] and [13] jumped out of the traditional idea of improving the accuracy of the model, and matched the physical imaging process of CT into the neural network, which greatly improved the contrast of images and the visibility of some difficult to observe tissues. This method is highly interpretable, but requires a calibration for each CT imaging device to obtain certain required parameters. This reduces its ease of use and accessibility. [30] emphasized the volumetric measurement of CT images and proposed a 2.5-D augmentation method. [15] skillfully isolated the image of the lesion area and then altered its background, which could even come from irrelevant samples. This approach aligns with deep learning practices and experiences [12, 5], yet it offers little in terms of explainability, which is crucial for medical applications. For instance, it is highly unconventional for images of the stomach and kidney to be present within the same slice.\nAffine in Medical Image Processing. [8] reviewed the augmentation method to ease data scarcity of medical image. They pointed out that affine transformations (e.g., flip, rotation, translation, scaling, cropping and shearing) have widely used as a part of the pre-processing workflow for medical images. [9] further analyzed the latest research on augmentation and believed that augmentation is very effective for medical datasets. However, most studies have not been able to prove that their methods are effective for different models. [36] used multiple Affine Matrices on high-dimensional CT feature maps to differentially deform the vertebral bodies and surrounding soft tissues, leading to better registration performance. This is mainly due to the different elastic deformation characteristics between different tissues inside the body. [35] proposed an affine-enhanced arterial spin labeling (ASL) image registration method for MRI images. In this method, the affine transformation will be applied to image according to six parameters learned by deep learning neural network. [11] proposed a two-stage unsupervised learning framework for deformable medical image registration."}, {"title": "3. Methods", "content": "3.1. Data Preprocess Overview\nAccording to the latest research [29, 34, 24], deep learning models need to preprocess the data with several augmentation before inputting it into the model. The method we proposed is one part of the preprocess, as indicated in fig. 2. All symbols used in mathematical procedure description of the proposed distortion are shown in table 1.\nPixel Array Conversion will read reconstructed image stored in dcm file series using method proposed in [19]. Each patient's scan includes multiple dcm files containing various meta data, which provides more possibilities for downstream tasks. The Resize operation is executed before the Distortion to achieve better performance, as the Distortion has an O(H\u00d7W) complexity. Normalization is performed after Distortion as a way to ensure that reconstructed pixel array conform to a standard distribution before being fed into the model.\n3.2. Implementation of Distortion\n3.2.1. Affine Control Point Initialization\nTo perform affine, we prepare a 2D grid of control points that are evenly distributed over the image. During the affine process, the pixels corresponding to the control points are moved along with the control points themselves."}, {"title": "3.2.2. Affine Control Point Destination Calculation", "content": "Based on the previous description, we should ensure the following two points in the mapping transformation:\n> The continuity relationship between image pixels remains unchanged.\n> In order to conform to the distortion of the human body in reality, the distortion transformation should be reasonable comparing with actual scenarios.\nTo meet these requirements, we abandon the traditional calculation method based on the Cartesian coordinate system and convert the control point matrix to the polar coordinate system with the center of the Rsmap as the pole. For any radial line in the polar coordinate system, we distort it from a ray-like shape to a sine function shape, and map all points on this ray to its distorted version. First, we randomly determine the actual distortion intensity parameters from a specified intensity range. This operation is to increase the intensity of data augmentation, since A and w controls the overall intensity of augmentation. We introduced a random factor \u03a8, which can determine the amplitude a and frequency f actually applied in the transformation.\na = (2\u03a8 \u2013 1) A, f = (2\u03a8 \u2013 1) \u03c9\nThen, correct the index order from pixel array space to physical location X, Y, and calculate the polar coordinates of the point with subscript indices x, y in the polar coordinate with @ as the pole.\nymap = - \u0443 - 1\nrmap, =G (x, y, \u0398 = (\u03b4/2, \u03b4/2))\nThe key of the distortion is mapping each ymap to a new location new. This conversion is performed with polar coordinate system, allowing us to easily control the absolute distance between each control point and the reconstruction center to remain constant, i.e. (\uc655, \uc0dd). This satisfies the second requirement shown at the beginning of this chapter.\nOnew= asin (map.2.fr)\nAfter conversion, we use \u0393 to invert the point rimg, new to Cartesian coordinates, which means backspacing to pixel array space:\nXnew, Ynew-cord =\u0413(rimg,)\nvYnew\nOur method will apply this algorithm on all pixels to generate the target control map RTmap (6). The a and f parameters remain unchanged for one sample but varies across different samples. Obviously, a single transformation map only performs a fixed transformation, which does not conform to the idea of data augmentation, i.e. generating multiple different samples from one sample. The traditional rotate augmentation could also be achieved by adding a factor to new (7).\nRTmapy+1,x+1 = (ynew, Xnew)\nnew-rotate = new+ \u03bc.\u03bc\u03b5 (0)\nThe algorithm's space and computational complexity are both O(82). A larger d is advantageous for generating more precise images with segmented affine mapping. We consider 6 \u2265 16 to make the graphics reasonable. These two points will be described in detail in the following sections. We give an example of generated control point map and its converted version in fig. 3."}, {"title": "3.2.3. Piecewise Affine Execution", "content": "Now that the affine control point map Rsmap and its destination map RTmap has been generated, affine operation is available. As to piecewise affine, a Delaunay triangulation of the points is used to form a mesh R^N^\u00d73\u00d72 containing i triangles. Delaunay triangulation function [7] is designed to maximize the minimum of all the angles of the triangles from a point set.\nRNA\u00d73\u00d72 = Delaunay (Rsmap8\u00d78)\nwhere N is the number of the generated triangles of triangulation.\nDelaunay tends to avoid narrow triangles, as these triangles can lead to extreme distortions in image transformations. One triangle R\u25b3,i3\u00d72 is composed of three control points (U1, U2, v3) \u2208 Z\u207a, i is the index of \u25b3. The piecewise affine will apply customized transformations for each triangle. We assume H as one triangle's transformation matrix, and the piecewise affine can be described as (9).\n\u03b7\u0394\nRdistorted SxS= H+Rai\ni=1\nWe visualize examples using the proposed algorithm with a \u2208 {1, 2}, \u03c9 \u2208 {1,2,3,4} in fig. 4."}, {"title": "3.3. Metadata-driven Scan Table Removal", "content": "In our research, the dataset comes from one hospital's standardized DICOM data, which includes metadata [10] related to the scan table, thus allowing geometric modeling to remove the unneeded scanning bed's HU value. The metadata and their symbols we use are illustrated in table 3. We define the physical table position as:\nPtable= (+)\nThe vertical distance between the reconstruction field center and table can be calculated as eq. (11), all elements in this formula are of physical space rather than pixel space:\nd = vertical- (Pable - r) = vertical- (h +42\u2013r)\nThe unit of & is mm/pixel. We define a valid mask with center and radius i eq. (12), which is used to locate the area without undesirable object imaging. All pixels outside this mask will be override by \u025b.\n=  \u00d7 41\n\u03b6\nFor pin Rpixels:\nif ||p - 02|| > \u03bb\u00b2(12):\np = \u03b5\nWe give several examples of its effect in fig. 5 and fig. 7. The geometric definition is illustrated in fig. 6."}, {"title": "3.4. Similarity-Guided Hyperparameters Search", "content": "We employ SIFT (Scale-Invariant Feature Transform) [16, 17] and ORB (Oriented FAST and Rotated BRIEF) [27] to gauge the similarity of images pre- and post-augmentation [1]. These techniques efficiently highlight the feature discrepancy between images. Typically employed in image search, matching, and alignment [3, 6], we pioneer their application in the context of setting augmentation hyperparameters (i.e. \u0391, \u03c9). Our improved training strategy with similarity guide is shown in algorithm 1."}, {"title": "3.5. IRB Approval", "content": "The dataset is provided by Department of Gastrointestinal Surgery, Shanghai General Hospital. The dataset's details are shown in 2 The hospital's experts labeled the slice containing the largest gastric cancer area for each patient. The research was under the approval from Shanghai General Hospital Institutional Review Board (No. [2024] 032). The Approval Letter is available if required."}, {"title": "4. Experiments", "content": "4.1. Experiment Basic Settings\nThe invalid area in dcm pixel array is represented by a negative constant value of -2000. These padding values significantly affect the data value distribution, skewing the mean, and reducing the fitting speed fig. 8. All dem metadata used in this research are listed in table 3, patients' private information is not included.\nAdditionally, we utilized publicly available large-scale datasets to validate the effectiveness of our proposed method, i.e. AbdomenCT1K[18, 33] and CT-ORG[25, 33]."}, {"title": "4.2. Similarity Guide Results", "content": "We observe that the number of successful SIFT pairings starts to plummet with a \u2248 3, f \u2248 1.5 fig. 9. The neural network ablation experiments also exhibit an exciting parallel trend: accuracy starts to falter rather than improve when the augmentation intensity with A > 7, \u03c9 > 3. The Pearson correlation coefficient between model performance and two similarity metrics are PSIRF-Acc = -0.625 and PORB-Acc = -0.618.\nThis proves that we can use similarity detection to quickly and effectively predict the performance of neural networks under this parameter without any actual training.\nGiven that our annotations are focused on gastric lesions, we have conducted an in-depth examination of the similarity levels across upper abdomen. This is aimed at assisting in a more comprehensive determination of the optimal distortion intensity fig. 10. The similarity criterion is described in eq. (13). A higher N\u2081 indicates a greater complexity of textures in the respective axial position, enabling the extraction of a larger number of feature points.\nN = \u03a3Sim (R\u2081, Distortion (R\u2081, A = j, W = i)) | | j\u2208 j \u2208 1 1}\niel\nI = {0.5, 1, 2, 3, 4, 5, 6, 7, 8}\nwhere \u25b3 represent the distance on Y axis between labelled slices and target slices."}, {"title": "5. Discussions", "content": "To our knowledge, our approach is one of the few instances within the Medical Imaging domain that employs image similarity metrics for neural network hyperparameter search [22]. Similar to the meta-data-driven Scan Table Removal technique, it offers significantly higher throughput compared to approaches relying solely on deep learning, while maintaining comparable accuracy. To implement these methods, researchers need to delve into a deeper understanding of medical imaging sequences. Given the remarkable efficacy of these non-deep-learning approaches, it's encouraging to foresee an increase in similar algorithms tailored for applications in medical imaging."}, {"title": "6. Conclusion", "content": "In this paper, we propose an augment method for scan series using polar-sine-based piecewise affine distortion. This method is able to generate any number of virtual samples from an existing scan sequence while ensuring that the relative anatomical structures of the human body are not severely altered, thereby enhancing the learning capability of downstream neural networks. The method is easy to deploy in today's mainstream deep learning frameworks and is compatible with most medical radiologic imaging data containing Slice-Wise dimension. Experiments have proven that this method can provide significant accuracy improvements on various types of deep-learning-based segmentation models."}]}