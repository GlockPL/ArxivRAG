{"title": "I See, Therefore I Do: Estimating Causal Effects for Image Treatments", "authors": ["Abhinav Thorat", "Ravi Kolla", "Niranjan Pedanekar"], "abstract": "Causal effect estimation under observational studies is challenging due to the lack of ground truth data and treatment assignment bias. Though various methods exist in literature for addressing this problem, most of them ignore multi-dimensional treatment information by considering it as scalar, either continuous or discrete. Recently, certain works have demonstrated the utility of this rich yet complex treatment information into the estimation process, resulting in better causal effect estimation. However, these works have been demonstrated on either graphs or textual treatments. There is a notable gap in existing literature in addressing higher dimensional data such as images that has a wide variety of applications. In this work, we propose a model named NICE (Network for Image treatments Causal effect Estimation), for estimating individual causal effects when treatments are images. NICE demonstrates an effective way to use the rich multidimensional information present in image treatments that helps in obtaining improved causal effect estimates. To evaluate the performance of NICE, we propose a novel semi-synthetic data simulation framework that generates potential outcomes when images serve as treatments. Empirical results on these datasets, under various setups including the zero-shot case, demonstrate that NICE significantly outperforms existing models that incorporate treatment information for causal effect estimation.", "sections": [{"title": "Introduction", "content": "Causal effect estimation under observational studies is a critical yet challenging problem in the realm of causal inference as it enables a clear understanding of the impact of specific treatments or interventions on particular outcomes. It has omnipresent applications including, but not limited to, domains such as healthcare, economics, social sciences, education, entertainment and e-commerce. In this work, we specifically study Individual Treatment Effect (ITE) estimation which is the most granular causal effect estimation task. ITE focuses on estimating the impact of a treatment at an individual level, as opposed to average causal effects, which apply to entire populations or sub-populations. ITE helps to achieve personalization of treatments based on user attributes. A few use cases of ITE across various domains include, personalization of content, product, and investment plan recommendations in the entertainment, e-commerce, and finance industries, respectively.\nIn causal effects estimation literature, majority of the works represent treatments in one-hot encoding format or categorical nature. But, often these treatments are multi-dimensional such as images and graphs, do contain rich information and hence potentially can be used in the causal effects estimation if made available. This raises a question whether the causal effects estimates can be improved, in particular ITEs, by utilizing treatment attributes in the estimation process. To that end, there are a limited number of works (Harada and Kashima 2021; Kaddour et al. 2021; Nilforoshan et al. 2023) in the literature that try to address the above question. These works demonstrated ways of effective utilization of treatment attributes in the ITE estimation and showcased improved results. However, all these works have considered either graph or textual treatments, in their respective experiments. In this work, we study the ITE estimation problem for treatments being images and demonstrate an effective way to utilize treatment attributes that results into improved ITE estimates.\nWe provide motivation for our problem, ITE estimation for image treatments, with the following prevalent use cases in our daily lives. Consider an OTT (Over-The-Top) or video hosting application that displays its contents using thumbnails to the users. Suppose each content is present in multiple thumbnail variants and the goal is to personalize thumbnails for users to maximize the user engagement. This problem can be posed as an ITE estimation problem where thumbnails and users preferences to them correspond to treatments and their effects respectively.\nConsider another application in e-commerce or website publishing that sells products by displaying product images on their platform. Each product typically features multiple images (photos) captured from various angles and under different lighting conditions. Suppose, if the goal is to personalize product display images to maximize click through rates then it can be approached using our framework by considering product images as treatments and estimating users' preferences as treatment effects.\nWe now briefly talk about the key challenges in our work. First and foremost challenge is the lack of existing datasets for the ITE estimation of image treatments. It necessitated us to simulate a new dataset that required extensive research and experimentation in terms of the appropriate image data and mathematical formulation of their induced effects on users. Second, to the best of our knowledge, there are very few existing works (Harada and Kashima 2021; Kaddour et al. 2021; Nilforoshan et al. 2023) that leverage treatment information in the literature, with no empirical results specifically addressing image treatments in ITE estimation.This gap presents a significant challenge for addressing the task at hand. Finally, the inheritance nature of our setup containing multiple treatments under observational studies increases the problem complexity in terms of confounding bias. We outline the salient contributions of our work that address the aforementioned challenges.\n\u2022 We propose a semi-synthetic data simulation setup that generates potential outcomes for the case of multiple image treatments.\n\u2022 We propose a novel neural network architecture, NICE, for ITE estimation of image treatments with a combination of Mean Square Error (MSE) and Maximum Mean Discrepancy (MMD) losses.\n\u2022 We showcase the superior performance of NICE against baselines, on the Rooted Precision in the Estimation of Heterogeneous Effects (PEHE) metric, across various treatment assignment bias conditions in numerical experiments.\n\u2022 We also conduct experiments under zero-shot scenarios where models are evaluated on unseen treatments during the training. Under these settings too, we observe that NICE outperforms baselines by a significant margin.\nWe organize the rest of the paper as follows. We provide a comprehensive survey of related work in the following section. We introduce the mathematical formulation of the problem in the Problem Formulation section. The Proposed Model section then provides the technical details of our proposed NICE model. The subsequent sections, Data Simulation and Experiments, detail our data simulation setup and present a comparative analysis of our numerical results. Finally, we conclude the work and outline few potential future research directions in the Conclusions section."}, {"title": "Literature Survey", "content": "In this work, we deal with the estimation of ITEs that hold at individual unit level as opposed to the predominantly studied Average Treatment Effects (ATE) (Shpitser and Pearl 2012; Pearl 2017), which hold at whole population level, estimation in the literature. Specifically, we study ITE estimation under multiple image treatments setup by utilizing treatments information in the estimation hence we restrict ourselves contrasting our work with only ITE estimation under multiple treatments and (or) works that utilized treatments information in the estimation. Most of the works that involve multiple treatments (Yoon, Jordon, and Van Der Schaar 2018; Schwab, Linhardt, and Karlen 2018; Guo, Li, and Liu 2020; Schwab et al. 2020; Thorat et al. 2023) do not consider the rich multi-dimensional treatment information in the estimation and merely represent them as scalars using one hot encoding.\nThere are few existing works (Harada and Kashima 2021; Kaddour et al. 2021; Nilforoshan et al. 2023) that utilized treatments information in the ITE estimation under multiple treatments setup. The authors in (Harada and Kashima 2021) consider the problem of ITE estimation for multiple graph treatments, different from our setup of image treatments, and demonstrated ways to utilize the graph treatments information to obtain improved causal effects estimates. The work in (Kaddour et al. 2021) deals with the ITE estimation for structured treatments such as graph, image and textual by incorporating treatments information in the estimation process. However, their proposed algorithm, SIN, is evaluated only on the datasets with graph treatments in the their experiments. Hence, SIN's performance on image treatments datasets has not been studied yet, making SIN one of the baselines in our work. The following latest work (Nilforoshan et al. 2023) also utilizes treatments information for ITE estimation but it is primarily on the zero-shot tasks, estimation of treatment effects on the unseen treatments by model during training."}, {"title": "Problem Formulation", "content": "In this section, we briefly outline the problem considered in this work. Let $k \\in \\mathbb{N}$ and $n\\in \\mathbb{N}$ denote the number of available treatments and the number of instances/users. We use i, x and t for referencing users, their covariates and treatments respectively. Let $x_i \\in \\mathcal{X} \\subset \\mathbb{R}^d$, $t_i \\in \\{1,2,\\dots,k\\}$, denote covariates, index of assigned treatment of user-i. We use $I_t \\in \\mathcal{I} \\subset \\mathbb{R}^m$ to denote the image corresponding to the treatment-t.\nWe follow the Rubin-Neyman (Rubin 2005) potential outcomes framework for introducing the problem. Let $y_i^t$ denotes the potential outcome of user-i when treatment-t is applied. Since $t_i$ is the treatment given to user-i, $y_i^{t_i}$ denotes the observed outcome or factual outcome of user-i. For brevity purposes, we write $y_i^{t_i}$ as $y_i^{obs}$. Given user-i with covariates $x_i$, and a pair of treatments a, b, let us define ITE of treatment a w.r.to b, using notation $\\tau^{a,b}(x_i)$, as below:\n$\\tau^{a,b}(x_i) = \\mathbb{E} [y_i^a \\mid x = x_i] - \\mathbb{E} [y_i^b \\mid x = x_i].$ (1)\nIn our setup, we assume that the treatments are images and are available to the model. In the following, we provide the technical formulation of our problem statement. Given n observations, $\\{(x_i, I_{t_i}, y_i^{obs})\\}_{i=1}^n$, of users with covariates $x_i$, their assigned treatment images, $I_{t_i}$, and the corresponding observed potential outcomes, $y_i^{obs}$, our goal is to estimate ITEs, given in equation (1), for all pairs of treatments.\nFor the quantification of a model's performance we use the standard metric in the literature named PEHE whose formulation is given below:\n$\\epsilon_{PEHE} = \\frac{1}{\\binom{k}{2}} \\sum_{a=1}^{k} \\sum_{b=a+1}^{k} \\sqrt{\\frac{1}{n} \\sum_{i=1}^n \\big( \\tau^{a,b}(x_i) - \\hat{\\tau}^{a,b}(x_i) \\big)^2},$ (2)\nwhere $\\hat{\\tau}(\\cdot)$ represents the estimated PEHEs produced by a model."}, {"title": "Proposed Model", "content": "The NICE framework, designed for ITE estimation with image-based treatments, is founded on the principle of strong ignorability (Rubin 2005). This principle encompasses two essential assumptions: conditional independence (unconfoundedness) and positivity, both formally articulated below.\nAssumption 1 (Conditional Independence (Unconfoundedness)). Given the covariates, $x_i$, the treatment assignment, t, is independent of the potential outcomes, ensuring that all confounding variables affecting both treatment assignment and outcomes are accounted for within $x_i$:\n$(y_i^1, y_i^2,\\dots,y_i^k) \\amalg t \\mid x_i$.\nAssumption 2 (Positivity (Overlap)). This assumption ensures that every subgroup defined by $\\{x = x_i\\}$ has a positive probability of receiving any of the treatments $a \\in \\{1,2,\\dots, k\\}$. It guarantees sufficient variation in treatment assignments observed across all values of X, which can be expressed as:\n$0 < P(t = a \\mid x = x_i) < 1 \\forall 1 \\leq a \\leq k$.\nEstimating causal effects is challenging because some confounders are difficult to measure directly in the observational data. This limitation undermines the strong ignorability condition, which presumes that all confounders are accounted for in the data. The absence of this condition may make the causal effect estimates biased, as unobserved confounders can influence both treatment assignment and outcomes.\nThe challenge of confounding is further exacerbated for the case of image treatments. Due to their complex and detailed nature, images can introduce additional layers of variability that are not always directly observable. By incorporating these rich treatment attributes, ITE estimation can account for hidden confounders, thereby improving the accuracy of ITE estimates.\nOur proposed model, NICE, addresses ITE estimation by utilizing treatment information, specifically images. Figure 1 illustrates the detailed architecture of the NICE model, comprising three key steps mentioned below.\nA. Generating representations for both covariates and treatments simultaneously and then concatenating these outputs\nB. Employing individual treatment head networks to generate counterfactual estimates\nC. Computing a treatment regularization loss to mitigate the treatment assignment bias or confounding bias along with regression loss to ensure accurate predictions.\nThis structured approach enables our model to effectively account for the complex information contained in images, thereby improving the accuracy of counterfactual estimations. Detailed explanations of our model architecture are as follows."}, {"title": "A. Learning Representation of User Covariates and Observed Image Treatments", "content": "We employ two distinct fully connected networks to learn representations of covariates, $x \\in \\mathcal{X}$, and observed image treatments $I_t \\in \\mathcal{I}$, capturing their low-dimensional embeddings. Specifically, we define two functions, $\\Phi : \\mathcal{X} \\rightarrow \\mathbb{R}^{d_1}$ and $\\Psi : \\Lambda(I) \\rightarrow \\mathbb{R}^{d_2}$, to extract representations for covariates and treatment images.\nThe utility of learning covariate representations to enhance causal effect estimation has been previously demonstrated in the literature (Shalit, Johansson, and Sontag 2017). Similarly, learning treatment representations has been explored, particularly in graph-based contexts, as in Graphite(Harada and Kashima 2021), SIN (Kaddour et al. 2021) and CaML (Nilforoshan et al. 2023) algorithms. In our approach, we first use an existing image embedding model, denoted by $\\Lambda$, for obtaining image embeddings. Then, these image embeddings are fed to a representation network, $\\Psi$. Currently, we considered two popular well studied models in the literature such as ResNet (He et al. 2016) and VGG (Simonyan and Zisserman 2014) as candidates for $\\Lambda$ in the NICE model. In particular, $\\Lambda$ is used solely to infer image treatment embeddings and is not a trainable component in the NICE model.\nNote that, representation of I as a one-hot encoding of discrete treatments aligns with the standard multiple treatments setting. However, this approach fails to leverage the rich structural information inherent to image treatments and consequently suffers in causal effect estimates. Further, we concatenate the covariates and treatment representations to create a joint embedding, which is then utilized by the treatment head networks for ITE estimation."}, {"title": "B. Treatment Head Networks", "content": "In the second part of our model, we leverage concatenated embeddings of user covariates and treatments representations as a unified input to distinct treatment head networks corresponding to each treatment category. Given k available treatments, we train k fully connected networks to learn the functions for each individual treatment, aimed at estimating the potential outcomes. We denote these treatment head networks as $\\pi_t$ for $t \\in \\{1,2,\\ldots, k\\}$. Mathematically, for an instance i with covariates $x_i$ and observed treatment $t_{obs} = t$, $\\pi_t$ is defined as:\n$\\pi_t (\\Phi(x_i), \\Psi(\\Lambda(I_{t_{obs}}))) = w_t^O (W_t^L \\sigma (\\ldots \\sigma (W_t^1 (\\Phi(x_i), \\Psi(\\Lambda(I_{t_{obs}}))))))$,\nwhere $W_t^l$ and $w_t^O$ represent the weights of the l-th FC layer and the regression layer in the network head-t, respectively. The neural network bias terms follow the same rule and are omitted here for simplicity.\nWith both components of the model described, our model's prediction of the potential outcome for treatment t given instance i is defined as:\n$\\hat{y}_i^t = \\pi_t(\\Phi(x_i), \\Psi(\\Lambda(I_t)))$ (3)"}, {"title": "C. Loss Function", "content": "We optimize our model using two primary loss functions: (i) Regression Loss and (ii) Treatment Regularization Loss, denoted as $L_1$ and $L_2$, respectively. These loss terms are balanced using parameters $\\alpha$ and $\\beta$.\nTo achieve high predictive accuracy on observed outcomes, we employ the traditional mean square error loss. Given that each treatment group exhibits a unique distribution, optimizing the regression loss enables us to capture the approximate means for each treatment group. Specifically, we optimize the head network corresponding to the observed treatment t. The regression loss function $L_1$ is defined as:\n$L_1 = \\frac{1}{n} \\sum_{i=1}^n (y_i^{obs} - \\hat{y}_i^{t_i})^2$ (4)\nWe use the Treatment Regularization loss, denoted by $L_2$, computed using both covariates and treatments representation, to address treatment assignment bias - a crucial step in our model. As mentioned earlier, we concatenate the covariates and treatments representations to form a joint embedding. Considering that the latent spaces of covariates and treatments may differ, our goal is to achieve a balanced representation that accounts for treatment assignment bias. To that end, special cases of Integral Probability Metrics (IPM) have been utilized in the literature to obtain a balanced representation (Johansson, Shalit, and Sontag 2016). We employ a special case of IPM, specifically Maximum Mean Discrepancy (MMD) loss (Sriperumbudur et al. 2012), to obtain a balanced representation of joint embedding across all treatments. In particular, the treatment regularization loss computes the average MMD distance between the joint embeddings of covariates and image treatment representations across all treatment pair combinations, whose mathematical formulation is given below:\n$L_2 = \\frac{1}{\\binom{k}{2}} \\sum_{a=1}^{k} \\sum_{b=a+1}^{k} MMD (\\{\\Phi; \\Psi(\\Lambda)\\}_t=a, \\{\\Phi; \\Psi(\\Lambda)\\}_t=b),$ (5)\nwhere the notation $\\{\\Phi; \\cdot\\}$ denotes the concatenation operation. This approach aims to optimize both covariate and treatment representations, thereby mitigating the confounding effects introduced by the complex nature of treatments, in this case, images.\nIn summary, the total loss function L used to optimize the NICE framework comprises a regression loss term and an IPM loss term. The hyperparameters $\\alpha$ and $\\beta$ balance these two loss components to achieve optimal performance. The combined loss L is defined as:\n$L = \\alpha \\cdot L_1 + \\beta \\cdot L_2.$ (6)"}, {"title": "Data Simulation", "content": "Evaluating causal effects presents inherent challenges, primarily due to the difficulty in obtaining ground truth for counterfactual outcomes in observational datasets. The existing literature often addresses this by synthetically generating potential outcomes resulting into semi-synthetic datasets. In other words, the covariates and treatments can correspond to real-world data, while the potential outcomes are synthetically generated. However, to the best of our knowledge, there are no existing datasets available for our problem that involve images as treatments. Therefore, we focus on generating new semi-synthetic datasets to evaluate NICE algorithm against the baselines. Specifically, in our case, treatment images correspond to real world data, user covariates and potential outcomes are synthetically generated.\nWe now briefly outline the details of our datasets generation process. We generate our dataset using PosterLens (Aptlin 2021) dataset that contains posters of various movies and their respective ResNet embeddings. We first randomly draw 20k posters' ResNet (He et al. 2016) embeddings of size 512 from the PosterLens dataset. These embeddings are used as a proxy for users' covariates, x, mentioned in the Problem Formulation section. For a given user with covariates, our goal is to estimate their opinion on the shown poster, a real valued scalar. Note that, here, treatments are the posters shown to users and their opinions are considered as a proxy for the treatment effects. We generate multiple datasets based on the selected number of available treatments, which can be 4, 8 and 16.\nTo generate potential outcomes for the k number of treatments setup we first generate (k + 1) centroids as follows. Either randomly select (k + 1) ResNet embeddings from the 20,000 embeddings selected above or train a KMeans clustering algorithm on the 20,000 embeddings with (k+1) clusters as an input and take the resultant centroids. We use $z_i$ to denote centroids. We use $y_i^t$ to denote final potential outcomes for user-i and treatment-t. Our final potential outcomes are product of two quantities $\\tilde{y}_i^t$ and $d_i^t$ that are generated as follows.\n\u2022 Generation of $\\tilde{y}_i^t$: For each treatment-t, generate $\\mu_t$ and $\\sigma_t$ as follows: $\\mu_t \\sim \\mathcal{N}(0.45, 0.15)$ and $\\sigma_t \\sim \\mathcal{N}(0.1, 0.05)$. Then, $\\tilde{y}_i^t$ is an i.i.d sample drawn from $\\mathcal{N}(\\mu_t, \\sigma_t)$. Observe that $\\tilde{y}_i^t$'s are stochastic in nature and the distribution solely dependent on the treatment.\n\u2022 Generation of $d_i^t$: It tries to measure the preference of user with covariates $x_i$ to a treatment represented using its ResNet embedding which is defined as: $d_i^t = x_i \\cdot z_t + x_i \\cdot z_k+1$  $\\forall 1 \\leq i \\leq n$ & $1 \\leq t \\leq k$.\nGiven the above, the final potential outcomes, denoted by $y_i^t$ for any $1 \\leq i \\leq n$ & $1 \\leq t \\leq k$, are defined as\n$y_i^t = c \\tilde{y}_i^t d_i^t = c \\tilde{y}_i^t [x_i \\cdot z_t + x_i \\cdot z_k+1],$ (7)\nwhere $c > 0$ is a fixed constant and we keep it as 5 in the experiments.\nWe now briefly explain the process of observed treatment generation. Let $p_{i,t}$ denote the probability of treatment-t assigned to user-i, defined as below:\n$p_{i,t} = \\frac{exp (\\kappa_t y_i^t)}{\\sum_{a=1}^k exp (\\kappa_a y_i^a)},$ (8)\nwhere $\\kappa = [\\kappa_1,\\kappa_2,\\cdots,\\kappa_k] > 0$, is a set of parameters that controls the treatment assignment bias. In other words, choosing $\\kappa_a >> \\kappa_b$, $b \\neq a$ makes the treatment assignment distribution skewed towards $a^{th}$ treatment. For a given user-i, we randomly assign a treatment with the above probabilities, $p_{i,t}$, and call it as the observed treatment for that user."}, {"title": "Experiments", "content": "In this section, we provide details of the experiments conducted to evaluate the performance of NICE against various baselines. We begin by outlining the baselines considered in the experiments, followed by a comparison of NICE performance with these baselines across different scenarios, including zero-shot tasks. Finally, we provide details of the parameters used in NICE and the baselines. In all our experiments, we use the datasets as described in the Data Simulation section and all models are evaluated using the square root of PEHE metric defined in equation 2."}, {"title": "Baseline Methods", "content": "We compare our framework with adaptations of existing methods, to our problem, that leverage treatment attributes for estimating causal effects. To that end, we include modified versions of GraphITE (Harada and Kashima 2021), CaML (Nilforoshan et al. 2023), and the Structured Intervention Network (SIN) (Kaddour et al. 2021) in the baselines, as these algorithms incorporate treatment attributes to enhance causal effect estimation. We also aim to include an additional baseline that does not use treatment information, to effectively demonstrate the benefits of incorporating treatment information in the causal effects estimation. As NICE primarily operates on treatment head networks, we consider TARNet (Shalit, Johansson, and Sontag 2017) as another baseline that does not use treatment information in the estimation.\nGraphITE utilizes graphs as treatments to improve causal effect estimation with the HSIC criterion, reducing bias introduced by the treatment representation space. In the performance comparison Table 1, we include results of our experiments for GraphITE with the HSIC criterion. Similarly, we compare the performance of our algorithm with the SIN algorithm, which primarily relies on Robinson decomposition to include a quasi-convergence guarantees for estimators. CaML (causal meta-learning) uses a meta-learning approach to estimate pseudo outcomes of estimators. One common modification required for our experiment was to replace the graph representation network in these algorithms, as they primarily utilize graphs as treatments, with an image representation network to evaluate NICE with these methods."}, {"title": "NICE Performance Assessment", "content": "We conducted a comprehensive evaluation of NICE across various experimental settings to assess its ITE estimation capabilities. The experimental evaluation focused on testing the hypothesis that integrating treatment attributes, particularly images, enhances the accuracy of ITE estimators. To validate this hypothesis, we employed semi-synthetic datasets as described in the data simulation section. Our results demonstrate that NICE consistently outperforms the baseline algorithms in causal estimation, particularly when dealing with 4, 8, and 16 treatment groups. Results shown in all tables are means and standard deviations of $\\sqrt{EPEHE}$ values computed across 10 iterations. We use bold face to indicate the best results in the tables. As the number of treatments increases, the complexity of the problem escalates. Notably, the performance gap between NICE and the baseline methods widens as the number of treatments increases, as illustrated in Table 1.\nNext, we evaluate the performance of NICE in a treatment-embedding agnostic setup using a semi-synthetic dataset generated with ResNet embeddings. To assess the robustness of our approach, we also test NICE using VGG-based image embeddings (Simonyan and Zisserman 2014) to account for potential dataset biases that might arise from the semi-synthetic data generation process. In experiments involving variations in the number of treatments, we observe that NICE, when utilizing VGG embeddings, often surpasses the baseline methods and the ResNet-based NICE implementation, as shown in experiment evaluation Tables 1-4. These results underscore the model's effectiveness in causal estimation across different treatment representation embeddings.\nBaseline methods that we compare NICE with also claim to have zero-shot capabilities for ITE estimation on unseen treatments during training of the models. We evaluate both NICE and these baseline methods for their zero-shot abilities in the context of images as treatment setups. For this evaluation, we use a modified version of the PEHE metric, referred to as the rooted Zero-Shot PEHE metric ($EPEHE_{ZS}$), which is defined as follows:\n$\\epsilon_{PEHE_{ZS}} = \\frac{1}{\\binom{k}{k-1}} \\sum_{\\substack{a=1\\\\ a\\neq z}}^k \\sqrt{\\frac{1}{n} \\sum_{i=1}^n (\\tau^{a,z}(x_i) - \\hat{\\tau}^{a,z}(x_i))^2},$ (9)\nwhere z is the zero-shot treatment whose samples are not seen by the model during training. Observe that in the above equation, PEHE is computed using only treatment pairs that include the zero-shot treatment, as our goal is to evaluate the ITE estimation capabilities of the model in zero-shot scenarios\nThis metric allows us to effectively evaluate the performance of NICE and baselines in handling ITE estimation for image treatments not seen during training. As illustrated in Table 2, NICE consistently outperforms baseline methods in zero-shot ITE estimation for the image treatments.\nIn real-world scenarios, treatment assignments can be highly skewed based on user covariates, which significantly amplifies the treatment assignment bias. To assess the performance of NICE under such conditions, we simulate scenarios by increasing the treatment assignment bias, $\\kappa_a$, for a specific treatment. This ensures that treatment assignment distribution is skewed towards treatment-a. In particular, we consider two scenarios where $\\kappa_a = 10$ for $1 < a < k$ and $\\kappa_k = 50$ and 100. As illustrated in Tables 3 and 4, NICE consistently outperforms baseline methods in these treatment assignment bias experiments, demonstrating its robustness in handling highly skewed treatment assignment scenarios."}, {"title": "Model Parameters", "content": "We briefly outline the experimental setup for optimizing NICE and baseline algorithms. For covariate representation, we use a fully connected (FC) network with Tanh and ELU activation functions. Similarly, for treatment representation and causal estimator head networks, we employ FC networks with variations in the number of nodes and layers. In dataset simulation, we generate 20, 000 instances in each experiment. The data is split into training, validation, and test sets, and performance is assessed using the PEHE metric by comparing predicted potential outcomes against the ground truth for all instances. To achieve optimal performance for NICE-ResNet, NICE-VGG, and baseline algorithms, we implement techniques such as early stopping, learning rate scheduling, weight decay, and dropout. Details of hyperparameter tuning and search ranges are provided in Table 5."}, {"title": "Conclusion", "content": "In this study, we propose, NICE, a novel framework designed to estimate individual causal effects when images are considered as treatments. To validate the efficacy of NICE, we propose a unique semi-synthetic data simulation technique that generates potential outcomes for image treatments. NICE leverages image treatment attributes to estimate potential outcomes in scenarios involving multiple treatments. Notably, NICE demonstrates zero-shot causal effect estimation capabilities, enabling it to infer causal outcomes for novel treatments. Experimental results show that NICE consistently outperforms various baselines across different setups, achieving the best performance on the PEHE metric. For future work, we plan to explore the scalability of NICE to more complex datasets, as well as its applicability to real-world scenarios beyond semi-synthetic simulations. Additionally, we aim to enhance the framework's interpretability and extend its capabilities to handle more diverse and complex treatment types, such as video or multimodal data."}]}