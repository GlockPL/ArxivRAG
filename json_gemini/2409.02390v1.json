{"title": "Neural Dynamics Model of Visual Decision-Making: Learning from Human Experts", "authors": ["Jie SU", "Fang CAI", "Shu-Kuo ZHAO", "Xin-Yi WANG", "Tian-Yi QIAN", "Da-Hui WANG", "Bo HONG"], "abstract": "Uncovering the fundamental neural correlates of biological intelligence, developing mathematical models, and conducting computational simulations are critical for advancing new paradigms in artificial intelligence (AI). In this study, we implemented a comprehensive visual decision-making model that spans from visual input to behavioral output, using a neural dynamics modeling approach. Drawing inspiration from the key components of the dorsal visual pathway in primates, our model not only aligns closely with human behavior but also reflects neural activities in primates, and achieving accuracy comparable to convolutional neural networks (CNNs). Moreover, magnetic resonance imaging (MRI) identified key neuroimaging features such as structural connections and functional connectivity that are associated with performance in perceptual decision-making tasks. A neuroimaging-informed fine-tuning approach was introduced and applied to the model, leading to performance improvements that paralleled the behavioral variations observed among subjects. Compared to classical deep learning models, our model more accurately replicates the behavioral performance of biological intelligence, relying on the structural characteristics of biological neural networks rather than extensive training data, and demonstrating enhanced resilience to perturbation.", "sections": [{"title": "1 Introduction", "content": "Abstracting the structures of biological neural systems into mathematical models and constructing artificial neural networks based on these abstractions to address real-world problems, represents a pivotal approach to innovation in artificial intelligence. Over the past decades, this approach has achieved significant success in various fields such as pattern recognition and computer vision [1-5]. Visual perception, a fundamental process through which humans and animals interpret and interact with the environment, is a central topic in both neuroscience an artificial intelligence (AI). Understanding the neural mechanisms underlying perceptual decision-making not only provides insights into biological systems but also has the potential to drive advancements in AI technologies. Convolutional neural network (CNN) models, inspired by the receptive fields and parallel distributed processing in animal vision systems, have achieved notable success in tasks such as object detection, facial recognition [6-8], and action recognition [9, 10], often surpassing human performance. However, these models face significant limitations, including the need for vast amounts of labeled data, lack of biological interpretability, and susceptibility to adversarial attacks. These limitations highlight the gap between current AI systems and biological neural networks regarding robustness, efficiency, and flexibility. Addressing these challenges requires a paradigm shift towards models that more closely mimic the underlying principles of biological neural computation.\nMotion perception is critical for animals to detect potential conspecifics, preys or predators, and is vital for their survival. The motion perception system starts with retinal input, travels through the lateral geniculate nucleus (LGN) to the primary visual cortex (V1), and then projects to parietal areas along the dorsal visual pathway, supporting spatial attention and eye movements [11]. Direction-selective (DS) neurons are widely present in brain areas such as V1, middle temporal area (MT), and lateral"}, {"title": "2 Results", "content": "intraparietal area (LIP) [12-14], which are essential for motion perception. The direction preference of V1 DS neurons depends on the spatial pattern of LGN neurons to which they are connected [15, 16]. Motion perception relies on the integration of both spatial and temporal dimensions of information [17]. Spatial integration is achieved by the larger receptive fields of MT neurons [18, 19], while temporal integration primarily relies on the temporal integration properties of LIP neurons [12, 20].\nBased on the physiological structures and properties of neurons and circuits in the LIP area, Wang proposed a recurrent neural circuit model [21]. Within this model, two groups of direction-selective excitatory neurons are capable of integrating lower-level synaptic inputs and performing cognitive tasks through recurrent excitation and mutual inhibition mechanisms. The model's attractor dynamics enhance its ability to perform decision-making and working memory tasks, replicate neural activity patterns observed in non-human primates, and achieve performance consistent with experimental data. Subsequent researches have extended the model by focusing on its simplification, theoretical analyses and training methodologies [22-25]. These studies primarily emphasize fitting and interpreting biological experimental data, showcasing significant biological plausibility and interpretability. However, neuron parameters are usually determined based on averaged experimental data, without considering the physiological characteristics that underlie behavioral differences among individuals. Moreover, the model has not been optimized based on biological features found in primates, which limits its impact and application in artificial intelligence.\nNumerous studies have investigated the relationship between the physiological or structural features of the human brain and behavior [26]. These studies span various human behaviors, including cognitive functions such as working memory [27], language acquisition [28], theory of mind [29], and social functions like social network size [30]. Some research examines differences in physiological characteristics between healthy and diseased groups, for example, correlations between neurodegenerative diseases and"}, {"title": "2.1 A Neural Dynamics Model of Visual Decision-Making with Behavioral Performance and Neural Activities Similar to Primates", "content": "We constructed a neural dynamics model that encompasses the four key brain areas of the dorsal visual pathway (LGN, V1, MT, and LIP, Figs. la-c). This model forms an artificial biological neural network capable of motion perception and performing the Random Dot Kinematogram (RDK) task. The neurons in our model adopt the Leaky Integrate-and-Fire (LIF) model and are interconnected through excitatory synapses (AMPA, NMDA) and inhibitory synapses (GABA) (see \u00a7 4.2). The spikes of different neuron groups were recorded during the RDK task (Fig. 1d-f).\nThe electrophysiologic recordings show that V1 neurons exhibit direction selectivity, which is further enhanced in the MT neurons. In the LIP area, neurons that prefer a specific motion direction gradually dominate, while those favoring the opposite direction are suppressed, resulting in a \u201cwinner-take-all\" effect. Additionally, V1 and MT neuron activation increases with motion coherence but stabilizes during the stimulus period. In contrast, LIP neurons show a gradual ramping of activation, with the ramping speed proportional to motion coherence (Fig. 1d-f). These simulated neural activities closely resemble those recorded in electrophysiological experiments with macaque monkeys [13, 42], demonstrating the biological plausibility of our model.\nThe performance of our model was evaluated using the entire Random Dot Kinematogram (RDK) dataset (see \u00a7 4.1). We calculated the choice probability and average reaction time for each coherence level. Fig. 2a (upper panel) presents the psychometric curve of the model (in blue), which is similar to the psychometric curves of human subjects (in orange). The model's sensitivity (slope of the psychometric curve, k in Equation 1) is 19.31 \u00b1 0.17 (mean\u00b1SEM of 45 experiments), significantly exceeding"}, {"title": "2.2 Model Optimization Inspired by Structural Connectivity of Human Experts", "content": "the average level of human subjects (36 subjects, 15.1 \u00b1 1.9, t = 2.50, p = 0.015, two-sample t-test). Moreover, the model's decision time curve aligns with the reaction times of human subjects. As coherence increases (task difficulty decreases), the decision time gradually becomes shorter, as illustrated in Fig. 2a (lower panel).\nIn electrophysiological experiments, microstimulation of specific brain regions can induce behavioral changes [13, 42]. To verify whether our neural dynamics model exhibits similar characteristics to biological motion perception systems, we conducted virtual cortical stimulation experiments. External currents were injected into different groups of neurons in our model to investigate if the results matched those observed in biological experiments [13, 42].\nApplying continuous extra current (0pA to 40 pA, Fig. 2b) to MT neurons that prefer leftward motion shifted the model's psychometric curve to the right, indicating an increased leftward choice preference (slope=-0.18, p < 0.001), This manipulation slightly reduced the model's sensitivity (slope=-0.25, p < 0.001), and altered decision times, decreasing for leftward and increasing for rightward motions, aligning with observations in animal studies [42]. Conversely, applying extra current to neurons that"}, {"title": "2.3 Model Optimization Inspired by Functional Connectivity of Human Experts", "content": "prefer rightward motion resulted in a leftward shift of the psychometric curve and a corresponding leftward shift in the decision time curve (Fig. 2c, intercept changed with external currents: slope=0.18, p < 0.001; sensitivity changes with external currents: slope=-0.26, p < 0.001). Moreover, when stimulating both groups of neurons in the MT region without selection (OpA to 40 pA), the model's sensitivity slightly declined (slope=-0.26, p < 0.001), but the decision time notably reduced (Fig. 2e). Correspondingly, stimulating all neurons in the V1 region significantly altered the model's sensitivity (slope=-0.50, p < 0.001) and decision time (Fig. 2d). However, stimulating all excitatory neurons in the LIP area did not affect the model's sensitivity (slope=0.005, p = 0.60) or decision time (Fig. 2f).\nStructural connectivity estimated from neuroimaging techniques reflects the mesoscopic properties of fibers, which are directly related to behavioral outcomes [26-30]. To identify the key parameters influencing the task performance, we collected behavioral and neuroimaging data from 36 human subjects performing the RDK tasks. In the correlation analysis, we found a significant negative correlation between the mean fractional anisotropy (FA) value of white matter in the left lateral occipital region and subjects' behavioral performance (r = -0.435, p = 0.008, uncorrected Pearson correlation, Fig. 3a). This indicates that subjects with lower mean FA values in this area performed better in the behavioral experiment. The lateral occipital region, located in the occipital lobe, includes white matter pathways connecting the primary visual cortex and the MT area. Lower FA values may reflect reduced anisotropy and predict a denser distribution of fiber bundles in this region.\nThe relative white matter volume in the right inferior parietal region (i.e., the ratio of ROI volume to total brain volume, estimated from MR T1 images) was also"}, {"title": "2.4 Superior Robustness of Neural Dynamics Model Under Perturbation", "content": "significantly positively correlated with subjects' behavioral performance (r = 0.373, p = 0.025, uncorrected Pearson correlation, Fig. 3c). This suggests that subjects with better performance had a larger white matter volume in this area, indicating a broader range of fiber tracts. The inferior parietal region, located between the occipital and parietal lobes, includes the white matter pathway connecting the MT and LIP regions, which might be associated with decision-making in the brain. These results demonstrate correlations between behavioral performance and the structural features of the visual dorsal pathway. No other structural features showed significant correlations.\nIn response to key parameters identified in MRI studies, specifically the white matter connections from V1 to MT and from MT to LIP, which influence behavioral performance, we employed a neuroimaging-informed fine-tuning approach to adjust model parameters based on MRI analysis results. For the mean FA of left lateral occipital area (Fig. 3a), we modified the average connection weight of the V1-to-MT connections in the model (Fig. 3b, upper panel) accordingly. Increasing the connection weight at lower strengths (mean of the connection matrix gradually increasing to 2) enhanced model sensitivity and reduced decision times, aligning with the observed behavioral correlations. However, further increases in the connection weight led to reduced decision times but a decline in sensitivity (Fig. 3b, lower panel). Similarly, adjusting the connection ratio between MT and LIP neurons (Fig. 3d upper panel) revealed that increasing the ratio from low levels improved model sensitivity and reduced decision times, aligning with neuroimaging and behavioral correlations. However, beyond a certain range, further increases in the connection ratio decreased both model sensitivity and decision times (Fig. 3d lower panel).\nTo assess the robustness of our model, we conducted four types of perturbation experiments on both the neural dynamics model and the convolutional neural network model, as described in Section 4.7. Noise was introduced by either discarding or adding noise to the connection weights or neurons in each module of the models. Figs. 4b-i show the changes in accuracy of the CNN and neural dynamics models at each layer with varying perturbation intensities (see Table 1 for statistics, and Extended Fig. 2 for changes in sensitivity).\nFrom these figures, it is evident that our neural dynamics model performs better compared to the CNN model under perturbation. The CNN's accuracy typically declines more significantly with increased perturbation, whereas the neural dynamics model remains more stable overall. Notably, the model's performance remains largely unaffected when noise is introduced into modules corresponding to higher-level brain regions. For example, discarding connections from MT to LIP (Fig. 4f, red) or adding noise to these connections (Fig. 4g, red) has minimal impact on model accuracy, far less than the perturbation effects on the CNN (Figs. 4b&c, red). Adding noise to the"}, {"title": "3 Discussion", "content": "input current of neurons almost does not affect the neural dynamics model's performance (Fig. 4i, except the purple). Adding noise to LGN neurons causes model failure (Figs. 4g&i, purple), likely due to the sparse connections between V1 and LGN leading to over-reliance on LGN signals. Discarding neurons in the decision layer LIP (Fig. 4g, blue) also drastically reduces model performance, as too few LIP neurons cannot maintain the attractor states corresponding to decisions, causing the model to rapidly degrade to a resting state with a single attractor [44], effectively rendering it unable to make decisions.\nIn this study, we developed a neural dynamics model for motion perception and decision-making that simulates the visual dorsal pathway. The model incorporates biomimetic neurons and synapses with dynamic characteristics and kinetic properties as its core elements. These components enable the model to exhibit neural activities and behavioral outputs that are comparable to those of the biological brain, including responses to virtual electrical stimulation. By leveraging neuroimaging insights such as the structural features identified from human experts, we employed neuroimaging-informed fine-tuning to optimize the model parameters, leading to improved performance. Compared to CNNs, our model achieves similar performance with fewer parameters, more closely aligns with biological data, and exhibits greater robustness to perturbations.\nParameter optimization for neural dynamics model is both critical and challenging due to the complexity of nonlinear dynamic systems. Previous studies have primarily"}, {"title": "4 Methods", "content": "employed data fitting techniques using neural or behavioral data, which are feasible for small-scale models. However, as neural dynamics models increase in scale and complexity, with larger number of parameters and higher computational demands, optimization become significantly more computationally intensive and difficult. while it is theoretically possible to optimize key parameters in some simplified models through analytical methods, such method is generally impractical for more complex models. This study, for the first time, explores the application of neuroimaging data in model optimization, a process we term neuroimaging-informed fine-tuning. While this approach may not achieve the global optimum, it offers practical directions for parameter optimization and significantly reduces the search space. It is noteworthy that excessive adjustments to parameters can impair model performance. This observation implies the existence of an optimal range for these parameters that maximizes performance. Biological neural systems, refined over billions of years of evolution, regulate these parameters within such an optimal range, with minor variations accounting for individual differences.\nTargeting neuroimaging-informed fine-tuning, we identified brain regions associated with visual decision-making in human subjects through behavioral and imaging experiments. Subjects exhibiting superior performance in visual tasks tend to have lower mean FA values in the occipital region, indicating a higher degree of neural branching in the lateral occipital area. Variations in white matter characteristics within the adults are thought to result from inherent brain structure and the long-term maturation process from childhood to adulthood [45], suggesting that individuals with advanced visual capabilities likely have undergone extensive training and development in visual function. We also identified correlations between the functional connectivity of MT-AAIC and LIP-suborbital with behavioral performance. Variations in functional connectivity between subjects are primarily influenced by their level of participation and cognitive engagement during experiments [46], suggesting that"}, {"title": "4.1 The RDK Dataset", "content": "expert subjects are more engaged and attentive during tasks. We hypothesize that this process involves top-down regulation from higher-level brain areas to task-related regions, potentially enhancing synaptic transmission efficiency. The structural and functional connectivity features observed in human subjects account for their superior performance from the perspectives of innate structure, long-term development, and short-term participation. These findings, applied to key parameter adjustments in the model, indicate that the neural dynamics model aligns with biological intelligence and shows good interpretability in physiological terms. This proposes a potential path for enhancing the model's performance through neuroimaging-informed fine-tuning.\nIn the model, LIP Neurons primarily rely on differences in input currents for decision-making. Larger input currents enable the model to reach the decision threshold more quickly but reduce accuracy. For instance, increasing the connection strength between V1 and MT, between MT and LIP, or increasing the number of MT neurons connected to LIP enhances the total currents received by LIP neurons (see Fig 5a). This enhancement improves signal differentiation among neuronal groups that prefer different directions, thereby increasing accuracy (see Fig 3b&d, first half). However, larger input currents cause attractors in decision space to shift towards the diagonal (see Fig. 5b, from 2 to 3) [44]. In this scenario, inhibitory neurons are less effective at suppressing DS neurons that prefer the opposite direction, disrupting the winner-take-all dynamics and deteriorating model performance (see Figs. 3b&d, second half).\nSimilarly, modifying the recurrent connection weights among LIP neuronal groups alters the energy landscape of the decision space. Stronger recurrent connections eliminate the resting states attractor and expand the size of the decision state attractors (see Fig. 5c) [44]. This modification improves performance during the initial phase (see Fig. 3h, first half), but excessively large decision attractors can lead to rapid decision-making in the presence of noise, thereby reducing accuracy (see Fig. 3h, second half).\nRandom Dot Kinematogram (RDK) is a classic and common psychophysical paradigm used to study visual motion perception. In a typical RDK stimulus, numerous small dots are randomly distributed on the screen moving at different speeds in different directions, without a clear pattern. This randomness is crucial, preventing subjects from relying solely on local motion cues to judge overall motion characteristics. Typically, a certain proportion of dots (signal dots) move in a specified direction (target"}, {"title": "4.2 The Neural Dynamics Model", "content": "Adjusting the number of LIP neurons also alters the energy characteristics in the decision space. If the parameters result in stable decision-state attractors, the model can make decisions and maintain the states without external stimuli, demonstrating a degree of working memory capability. This enables decision-making with limited information by integrating noisy evidence, which can shorten decision time but introduces a risk of errors. Conversely, if only one resting state attractor exists, the model fails to reach the decision threshold under any stimulus and cannot make decisions, as evidenced by the perturbation experiment (Fig. 4h, blue), where we deliberately chose the preferred direction associated with higher firing rate neurons for decision. In real-world scenarios, the model would not make a choice in this situation. Similarly, parameter adjustments can lead to another monostable mode, where neuron groups preferring opposite directions both exhibit high firing rates, resulting in an inability to make reasonable decisions (Figs. 4g&i, purple).\nIn 2-alternative forced choice (2-AFC) tasks, researchers often model decision-making as evidence accumulation over time, using approaches such as the drift diffusion model (DDM) [47-49], racing diffusion model [50, 51], and linear ballistic\naccumulator (LBA) model [52]. The temporal integration in the LIP module resembles the DDM (see discussions in [21-23, 53]), and can be directly related to it [54, 55]. This type of evidence accumulation is not present in feedforward DCNN models. Additionally, the dynamic nature of the LIP constitutes an attractor network [22], where, through iterative processes, the network's state stabilizes near attractors. This differs fundamentally from traditional DCNNs, which categorize through spatial partitioning within representational spaces, and may explain why neural dynamics models exhibit better stability and noise resistance.\nIn summary, integrating neural dynamics into AI models can bridge the gap between biological intelligence and artificial systems, leading to the development of next-generation AI that is both interpretable and resilient like biological organisms. By leveraging advances in neuroscience to construct models with neural dynamics, we are able to create AI systems that better mimic biological behavior. The neuroimaging-informed fine-tuning method enhances performance while preserving the advantages of neural dynamics. This approach ensures both high performance and explainability, aligning with biological plausibility and computational efficiency. This synthesis between advanced AI techniques and in-depth neuroscientific insights represents a promising direction for future research and development in both fields.\nThe neural dynamics model constructed in this study simulates four key areas of the dorsal pathway involved in motion perception, corresponding to the LGN, V1, MT and LIP regions of the motion perception decision system from primary to high levels (Fig. la). We did not directly model lower visual pathway modules (retina, ganglion cells, etc.) in detail, but simplified them into temporal and spatial convolution calculations, directly mapping visual input to the total input current of LGN neurons as the model's input.\nThe LGN layer of the model was constructed based on previous research [15, 16]. The LGN is divided into two groups of ON and OFF neurons adapting the Leaky Integrate-and-Fire (LIF) model, each group containing 10000 neurons, all with double Gaussian spatial receptive fields (Equation 2, Fig. 1b middle). These neurons cover a"}, {"title": "4.3 A CNN Model for Motion Perception", "content": "visual angle of 0.35\u00b0 (x,y \u2208 [\u22120.175, 0.175] in Equation 2), corresponding to a 9\u00d79 pixel area. They are alternately overlapped and arranged regularly in space (Fig. 1b top), covering the entire 300 \u00d7 300 field of view, forming a two-dimensional plane corresponding to the image space. ON and OFF neurons have different temporal profiles, with ON neurons responding slower than OFF neurons (approximately 10 ms, Equation 3, Fig. 1b bottom). Images of 300 \u00d7 300 pixels are convolved spatially with the 9 \u00d7 9 spatial convolution kernels, then the time step is reduced to 2 ms (120 frames expanded to 1000 frames) through nearest-neighbor interpolation, and temporal convolution with a sliding time window of 160 ms is performed. At each time point, two sets of 100 \u00d7 100 convolution results are obtained, which serve as the stimulus-induced current for each neuron in the ON and OFF neuron groups, respectively, and together with Ornstein-Uhlenbeck noise [60] form the input current of LGN neurons.\n$A(x,y) = \\frac{\\alpha}{\\pi \\sigma_{\\alpha}^2} exp(\\frac{-x^2 + y^2}{\\sigma_{\\alpha}^2}) - \\frac{\\beta}{\\pi \\sigma_{\\beta}^2} exp(\\frac{-x^2 + y^2}{\\sigma_{\\beta}^2})$\nwhere a = 1, \u03b2 = 1, $ \\sigma_{\\alpha} $ = 0.0894, $ \\sigma_{\\beta} $ = 0.1259 [15].\n$K(t) = \\frac{t^a}{\\tau_{\\alpha}^a} exp(-\\frac{t}{\\tau_{\\alpha}}) - \\frac{t^\\beta}{\\tau_{\\beta}^\\beta} exp(-\\frac{t}{\\tau_{\\beta}})$\nwhere $ \\tau_{\\alpha} $ = 3.66, $ \\tau_{\\beta} $ = 7.16, \u03b1 = 1, \u03b2 = 0.8 for ON neurons, and a = 1, \u03b2 = 1 for OFF neurons [15].\nThe other three brain regions are composed of LIF neuron groups, with each neuron group connected to the neurons in the previous layer with specific structures and probabilities. The V1 area has a total of 5000 neurons, divided into two groups, namely G1 and G2. Each V1 neuron receives input from one ON cell and one OFF cell arranged in a specific pattern through AMPA synapses. In the LGN projection received by the G1 group neurons, the ON cells are always located to the left of the OFF\nA convolutional neural network (CNN) model (MotionNet) was built similar in structure and scale to the neural dynamics model for comparison (Fig. 4a). The model receives video input with a resolution of 300 \u00d7 300 pixels, processes it through spatial convolutions of 9 \u00d7 9 pixels and temporal convolutions of 10 frames, resulting in two 100 x 100 feature maps matching the input of LGN neurons. These feature maps are converted to two 50 \u00d7 50 maps using 3 \u00d7 3 convolutional kernels. The two channels are then processed with 11 \u00d7 11 convolutional kernels to generate two 20 \u00d7 20 feature maps. After average pooling along the time dimension, these features are mapped to a 400-dimensional vector by a linear layer, and finally to output neurons using another linear layer. All neurons utilize the ReLU activation function except the output layer, which is passed through a softmax transformation for fitting the one-hot encoded direction classification information."}, {"title": "4.4 RDK Behavioral and Neuroimaging Experiments in Human Subjects", "content": "cells. Similarly, in the LGN projection received by the G2 group neurons, the ON cells are always located to the right of the OFF cells (Fig. 1c). The MT area contains two groups of neurons, L and R, each consisting of 400 neurons. The L group neurons receive input from the G1 group neurons within a certain receptive field, while the R group neurons receive input from the G2 group neurons within the same receptive field. The connections between MT and V1 corresponding neuron groups are also formed by AMPA synapses, with a synaptic conductance of \u011f = 2.0 nS.\nThe LIP area is constructed according to the model in literature [21], consisting of excitatory neuron groups A and B (each with 300 neurons) and an inhibitory neuron group I (500 neurons). The A group neurons receive random projections from L, while the B group neurons receive projections from R (50% of neurons for each group) with AMPA synapses. Connections within excitatory groups A, B, as well as connections from excitatory groups to inhibitory neuron group I, are formed by AMPA and NMDA synapses with different temporal characteristics. The inhibitory neuron group I inhibits neurons in groups A and B through GABA synapses. The connection strengths (synaptic conductance coefficients) of the above connections follow a normal distribution N(\u011f, 0.5g), where the average conductance from MT to LIP is \u04ef\u043c\u0442 = 0.1 nS, the average conductance among excitatory neurons in LIP is \u011fAMPA = 0.05 nS, \u012aNMDA = 0.165nS, the average conductance from excitatory neurons to inhibitory neurons in LIP is JAMPA = 0.04nS, \u012aNMDA = 0.13 nS. If the connection strength between two neurons is less than 0, there is no connection (Fig. 1c). Additionally, the connection weights between neurons with the same direction preference increase to w = 1.3 times the original weight (Hebb-strengthened weight), while the connection weights between neurons with different direction preferences weaken to w = 0.7 times the original weight (Hebb-weakened weight).\nThe neurons in the model are all LIF neurons, a commonly used model in computational neuroscience to approximate the behavior of biological neurons. The resting"}, {"title": "4.5 Neuroimaging Data Analysis Methods", "content": "To avoid overfitting the training data and ensure accurate model comparison, MotionNet was not directly trained on the RDK dataset. Instead, it utilized generated moving random images as the training data. Specifically, a random grayscale image was generated and stretched randomly. A window covering the image was moved in random directions to obtain the necessary animation data. The speed and direction of movement were randomly assigned, and the training labels (supervision information, moving left or right) were determined by the direction of movement along the horizontal axis.\nMotionNet was trained with the cross-entropy loss function and stochastic gradient descent (SGD) method. The initial learning rate was set at 0.01, reduced to 10% at the 5th and 15th epochs. The momentum was set to 0.9, with a batch size of 64, and each epoch contained 500 batches. Training stopped at the 20th epoch. The model from the 20th epoch was selected for testing based on its convergence and stability during training. Similar analyses were then conducted on this model using the RDK dataset, paralleling those applied to the neural dynamics model. This approach ensured a fair comparison between the two models' performance under the same experimental conditions. Specifically, twenty consecutive frames were randomly selected from a 120-frame animation as input for MotionNet. The model's choices under various coherences were recorded and psychometric curves were fitted. For result stability, each trial was repeated twice. Unlike the neural dynamics model, MotionNet, being a CNN, lacks a concept of time, so we focused on its psychometric curve and related parameters (sensitivity).\nSubjects: Thirty-six subjects participated in this RDK experiment (12 males, 24 females, mean age 29 \u00b18 years). Each subject conducted a behavioral experiment with\nmembrane potential is set to Vr = -70mV, and when the membrane potential of a neuron reaches -50 mV, it fires an action potential, resetting to -55 mV during the refractory period [61]. The LIF model was selected due to its simplicity and computational efficiency, while still capturing essential dynamics of neuronal firing. In addition to synaptic currents and external currents, each neuron receives Ornstein-Uhlenbeck noise, a standard approach for modeling stochastic fluctuations in neuronal input. The time constant of OU noise T = 10ms, and mean current of 400 pA with a variance of 100 were chosen to match the noise characteristics observed in biological neurons. for LIP excitatory neurons, a higher mean current of 550 pA was used to simulate the enhanced excitatory drive from other excitatory neurons without direction selectivity. For excitatory neurons, the parameters are Cm = 0.5nF, g\u2081 = 25 nS, and refractory period 7 = 2 ms. For inhibitory neurons, the parameters are Cm = 0.2 nF, gi = 20 nS, and refractory period T = 1 ms. The AMPA, NMDA, and GABA synapses in the model follow the settings in the literature [21, 62].\nWe use the overall firing rate of neuron groups A or B in the LIP region as the basis for whether the model makes a decision. When the average firing rate exceeds a threshold (30 Hz) or when the stimulus finishes, the model selects the direction preferred by the neuron group with the higher firing rate as its final output. By simulating the model with each stimulus in the aforementioned RDK dataset, we obtain the accuracy of the model's decisions and the number of time steps taken for the decision (decision time) under different coherence levels. We can estimate a psychometric function through least squares regression (Equation 1). This method yields behavioral metrics, including the model's psychometric curve and sensitivity indices.\nFurthermore, our model, which possesses a structure akin to biological systems and neurons that mirror those of the biological nervous system, allows for the execution of virtual electrophysiological experiments, recording and analyzing the firing"}, {"title": "4.6 Neuroimaging-Informed Fine-Tuning", "content": "characteristics of each neuron group in the model, and even performing virtual electrical stimulation on neurons by adding additional current inputs, to study the characteristics of the model (Figs. 2b&c).\nDue to the randomness of RDK stimuli and the neural dynamics of the model, to ensure the robustness of the results, each stimulus was repeated twice in the model performance test, and the neural dynamics model was re-initialized and repeated five times. The selection probabilities and average decision times for each coherence level were calculated and estimated using the psychometric curve (Equation 1), and the decision time curve was estimated using a moving median smoothing algorithm with a coherence window of 10% (Fig. 2a upper panel). For human subjects, we conducted a bootstrap analysis on the behavioral data, where the trials of each subject were randomly sampled with replacement, and the median of 1000 bootstrap samples was calculated for each subject. The final average performance over all subjects was plotted.\nA convolutional neural network (CNN) model (MotionNet) was built similar in structure and scale to the neural dynamics model for comparison (Fig. 4a). The model receives video input with a resolution of 300 \u00d7 300 pixels, processes it through spatial convolutions of 9 \u00d7 9 pixels and temporal convolutions of 10 frames, resulting in two 100 x 100 feature maps matching the input of LGN neurons. These feature maps are converted to two 50 \u00d7 50 maps using 3 \u00d7 3 convolutional kernels. The two channels are then processed with 11 \u00d7 11 convolutional kernels to generate two 20 \u00d7 20 feature maps. After average pooling along the time dimension, these features are mapped to a 400-dimensional vector by a linear layer, and finally to output neurons using another linear layer. All neurons utilize the ReLU activation function except the output layer, which is passed through a softmax transformation for fitting the one-hot encoded direction classification information.\ndirection), while the remaining dots (noise dots) move randomly [56, 57]. Movement in a fixed direction is referred to as coherent motion, and observers' ability to report the direction of coherent motion increases with the percentage of coherent motion dots, accompanied by shorter reaction times. This proportion known as coherence, is a measure of task difficulty [58], making it the most important control parameter in RDK stimuli. RDK can conveniently control the relative saliency of motion stimuli, making it suitable for coherence threshold detection or measuring changes in subject behavior with coherence.\nIn a 2-alternative forced choice (2-AFC) task, with the proportion of coherent motion or its logarithm as the independent variable, a psychometric curve can be plotted showing the probability of a subject choosing a certain direction. This curve typically follows a sigmoid shape and can be described by the equation (1).\n$p=\\frac{1}{1+e^{-kx+b}}$\nHere, the slope k of the linear part is referred to as sensitivity, with higher sensitivity indicating a better ability to distinguish between two directions of motion and better behavioral performance. The intercept b describes the bias of the decision-maker, i.e., the extent to which the decision-maker tends to choose one direction over the other. A good decision-maker should have higher sensitivity and smaller bias.\nTo ensure consistency in data during model testing, we generated different RDK stimuli using the specialized neuroscience and experimental psychology software PsychoPy [59] with varying parameters and stored the stimuli in the form of three-dimensional arrays.\nComputer vision systems that use a camera as the perceptual input typically measure input videos and images in pixels, rather than in degrees as in studies of biological vision. Therefore, the RDK animation used in this study is pixel-based. Specifically,\nData analysis: The performance of the subjects in the behavioral RDK experiment was quantitatively analyzed using psychometric curves, and Pearson correlation analysis was performed between the behavioral results and the structural and functional features estimated from the MRI data. For behavioral data, a psychometric curve was"}, {"title": "4.7 Interference Resistance Experiment of the Model", "content": "fitted to each subject's staircase performance, and perceptual ability was determined by taking '1 \u2013 79.4% accuracy'.\nPearson correlations were calculated between the above features from structural (number of voxels per subregion, cortical area, average cortical thickness), diffusion (mean FA, mean MD), and functional (resting-state FC elements) images and the perceptual ability indices of the subjects. The ROIs were determined by the parcellation"}]}