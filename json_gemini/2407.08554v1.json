{"title": "ESTABLISHING RIGOROUS AND COST-EFFECTIVE CLINICAL TRIALS FOR ARTIFICIAL INTELLIGENCE MODELS", "authors": ["Wanling Gao", "Yunyou Huang", "Dandan Cui", "Zhuoming Yu", "Wenjing Liu", "Xiaoshuang Liang", "Jiahui Zhao", "Jiyue Xie", "Hao Li", "Li Ma", "Ning Ye", "Yumiao Kang", "Dingfeng Luo", "Peng Pan", "Wei Huang", "Zhongmou Liu", "Jizhong Hu", "Gangyuan Zhao", "Chongrong Jiang", "Fan Huang", "Tianyi Wei", "Suqin Tang", "Bingjie Xia", "Zhifei Zhang", "Jianfeng Zhan"], "abstract": "A profound gap persists between artificial intelligence (AI) and clinical practice in medicine, primarily due to the lack of rigorous and cost-effective evaluation methodologies. State-of-the-art and state-of-the-practice AI model evaluations are limited to laboratory studies on medical datasets or direct clinical trials with no or solely patient-centered controls. Moreover, the crucial role of clinicians in collaborating with AI, pivotal for determining its impact on clinical practice, is often overlooked. For the first time, we emphasize the critical necessity for rigorous and cost-effective evaluation methodologies for AI models in clinical practice, featuring patient/clinician-centered (dual-centered) AI randomized controlled trials (DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI) as an effective proxy for DC-AI RCTs. Leveraging 7500 diagnosis records from two-phase inaugural DC-AI RCTs across 14 medical centers with 125 clinicians, our results demonstrate the necessity of DC-AI RCTs and the effectiveness of VC-MedAI. Notably, VC-MedAI performs comparably to human clinicians, replicating insights and conclusions from prospective DC-AI RCTS. We envision DC-AI RCTs and VC-MedAI as pivotal advancements, presenting innovative and transformative evaluation methodologies for AI models in clinical practice, offering a preclinical-like setting mirroring conventional medicine, and reshaping development paradigms in a cost-effective and fast-iterative manner.", "sections": [{"title": "1 Introduction", "content": "Artificial intelligence (AI) holds immense promise in clinical practice [1-4] but falls into permissive, time-consuming, and costly evaluations. While randomized controlled trials (RCTs) are considered the gold standard for rigorous evaluation [5, 6], applying them to AI models in clinical practice poses new challenges. On the one hand, clinicians remain the primary decision-makers in medicine, viewing AI as a supportive rather than a leading force in shaping patient care [7, 8]. However, traditional trial methodologies, which typically use controls like no intervention, placebo, or sham solely for patients, fail to accommodate the dual focus on both patients and clinicians. This oversight ignores the crucial synergy between AI models and clinicians, hindering the effective integration of AI into clinical practice [1], as highlighted by criticisms [9, 10] faced by AI-driven decision support tools, including those officially approved [11, 12]."}, {"title": "2 Results", "content": "Diagnosis data from DC-AI RCTs. We perform the first rigorous and comprehensive DC-AI RCTs on sepsis. We set two-phase trials and a series of comparative"}, {"title": "3 Discussion", "content": "In this study, we innovatively emphasize the critical necessity for rigorous and cost-effective evaluation methodologies for AI models in clinical practice, featuring patient/clinician-centered (dual-centered) AI randomized controlled trials (DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI). We perform the first rigorous and comprehensive DC-AI RCTs across 14 medical centers involving 125 clinicians. Phase #1 using three models constitutes the basis for VC-MedAI, further confirming the necessity of a rigorous approach and DC-AI RCTs. Phase #2 using a new AI model provides prospective trials for evaluating VC-MedAI, verifying its effectiveness as a substitute for DC-AI RCTs and as a preclinical-like process mirroring conventional medicine.\nConventional clinical trials mainly regard patient as main subjects and adopt patient-centered trials including experimental or control groups to assess new techniques, device, or drugs [29-32]. In contrast, AI models in clinical practice relies on clinician-in-the-loop mechanism and the patients are no longer the solely subjects. Despite numerous proposals for AI software and devices in clinical practice [24, 33, 34], none have conducted DC-AI RCTs. According to a survey [9] in 2022, only 39 (0.33%) out of 11,839 articles have conducted RCTs. Among these, 92% (36/39) compared AI-assisted tools to controls using standard care, while 5% (2/39) used a sham treatment without AI assistance as a control [9], all overlooking clinician synergy. In this condition, it is challenging to determine the extent of the AI software's impact and whether it has a positive effect, no matter from the accuracy, diagnosis time, or cost perspective. Our study addresses this deficiency and offers the first rapid and cost-effective alternative for AI model evaluations in clinical practice."}, {"title": "4 Methods", "content": "The design of DC-AI RCTs. We conduct DC-AI RCTs across 14 medical centers with 125 clinicians. The patient cohort is well chosen from MIMIC [35-38] datasets. The AI models include state-of-the-art/practice algorithms \u2014 the survival analysis based cox proportional hazards model (CoxPHM) model [24, 39] and deep learning based long short term memory (LSTM) model [33], specifically, low-quality (AUC 0.75), medium-quality (AUC 0.85), high-quality (AUC 0.95) LSTM-based models, a high-quality (AUC 0.95) CoxPHM-based model, and a random model (AUC 0.5) as control. We category the patients into five groups randomly. In Phase #1, the first group is diagnosed by clinicians without and with the above random or LSTM-based models, having no idea about the model properties. In total, group #1 contains five settings. For comparison, patient group #2 to #4 are diagnosed with the assistance of three LSTM-based AI models and the clinicians are aware of the model properties. In total, Phase #1 contains eight settings. In Phase 2, a new CoxPHM-based model is employed to assist the diagnosis of patient group #1 and group #5, with the model's properties being invisible to clinicians for group #1 and visible for group #5. To unveil clinician's behaviors and their intricate interactions with AI, every clinician is assigned"}, {"title": "Declarations", "content": "Competing interests\nThe authors declare no conflicts of interest and no competing interests.\nEthics statement"}, {"title": "Appendix A Supplementary Methods", "content": "10 patient-centered and clinician-centered (dual-centered) clinical settings.\nThe DC-AI RCTs are conducted across 14 medical centers collaborated with 125 human clinicians. The patient cases are classified into five groups randomly. The 10 clinical settings are as follows:\n\u2022 The patient cases of Group #1 are diagnosed by human clinicians with and without the AI model assistance. Human clinicians can only see inference results of AI models while having no idea about the model characteristics like model name and model quality on testdata.\n(1) diagnose without AI model assistance.\n(2) diagnose with a random model (control group with AUC 0.5).\n(3) diagnose with a LSTM-based low-quality (AUC 0.75) model.\n(4) diagnose with a LSTM-based medium-quality (AUC 0.85) model.\n(5) diagnose with a LSTM-based high-quality (AUC 0.95) model.\n(6) diagnose with a CoxPHM-based high-quality (AUC 0.95) model. [Phase #2]\n\u2022 For the other four patient groups, human clinicians make diagnosis decisions while being aware of the AI model's name and qualities.\n(7) The patient cases of Group #2 are diagnosed by human clinicians with the assistance of a LSTM-based low-quality (AUC 0.75) model.\n(8) The patient cases of Group #3 are diagnosed by human clinicians with the assistance of a LSTM-based medium-quality (AUC 0.85) model.\n(9) The patient cases of Group #4 are diagnosed by human clinicians with the assistance of a LSTM-based high-quality (AUC 0.95) model.\n(10) The patient cases of Group #5 are diagnosed by human clinicians with the assistance of a CoxPHM-based high-quality (AUC 0.95) model. [Phase #2]\nThe patient cases within each experimental and control groups are randomly allocated to clinicians. Each clinician is allocated with six patient cases randomly from every clinical setting. The total diagnosis records is 7500 (125 clinicians * 6 patient cases * 10 settings).\nThe features used in VC-MedAI.\n(1) The clinician features contain eight dimensions.\n\u2022 institution level reflects the hospital ratings on the overall quality and performance. We have three rating categories including A, B, and C.\n\u2022 sex indicates whether a clinician is male or female.\n\u2022 age indicates the age of a clinician.\n\u2022 years of working refers to the number of years a clinician has been employed or actively working in a hospital.\n\u2022 department refers to specific divisions or units within a hospital that focus on providing specialized medical care and services like emergency department. We have 14 department categories."}]}