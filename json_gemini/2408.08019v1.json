{"title": "Accelerating High-Fidelity Waveform Generation via Adversarial Flow Matching Optimization", "authors": ["Sang-Hoon Lee", "Ha-Yeong Choi", "Seong-Whan Lee"], "abstract": "This paper introduces PeriodWave-Turbo, a high-fidelity and high-efficient waveform generation model via adversarial flow matching optimization. Recently, conditional flow matching (CFM) generative models have been successfully adopted for waveform generation tasks, leveraging a single vector field estimation objective for training. Although these models can generate high-fidelity waveform signals, they require significantly more ODE steps compared to GAN-based models, which only need a single generation step. Additionally, the generated samples often lack high-frequency information due to noisy vector field estimation, which fails to ensure high-frequency reproduction. To address this limitation, we enhance pre-trained CFM-based generative models by incorporating a fixed-step generator modification. We utilized reconstruction losses and adversarial feedback to accelerate high-fidelity waveform generation. Through adversarial flow matching optimization, it only requires 1,000 steps of fine-tuning to achieve state-of-the-art performance across various objective metrics. Moreover, we significantly reduce inference speed from 16 steps to 2 or 4 steps. Additionally, by scaling up the backbone of PeriodWave from 29M to 70M parameters for improved generalization, PeriodWave-Turbo achieves unprecedented performance, with a perceptual evaluation of speech quality (PESQ) score of 4.454 on the LibriTTS dataset. Audio samples, source code and checkpoints will be available at https://github.com/sh-lee-prml/PeriodWave.", "sections": [{"title": "Introduction", "content": "This paper explores the methods to accelerate neural ODE waveform generator novel by combining recent advanced generative models, conditional flow matching (CFM) (Lipman et al. 2022; Tong et al. 2023) with generative adversarial networks (GANs) (Goodfellow et al. 2014; Lee et al. 2021). Recently, PeriodWave (Lee, Choi, and Lee 2024) successfully adopted CFM for neural waveform generation tasks by proposing novel period-aware generator architecture that can reflect the implicit periodic features of waveform signal, and they firstly outperformed the GAN-based neural waveform generation models (Kong, Kim, and Bae 2020; Lee et al. 2023; Shibuya, Takida, and Mitsufuji 2024) which previously dominated the waveform generation tasks.\nHowever, although PeriodWave could generate high-fidelity waveform signal with iterative refinement, they still require significantly more sampling steps compared to GAN-based models that only need a single generation step. To address this limitation, we propose efficient tuning method, adversarial flow matching optimization which can transform the pre-trained CFM-based generative models into fixed-step generator by leveraging reconstruction loss and adversarial feedback. This simple modification yields state-of-the-art waveform generator by achieving unprecedented performance, with a perceptual evaluation of speech quality (PESQ) (Rix et al. 2001) score of 4.454 on LibriTTS benchmark.\nIn this paper, we propose PeriodWave-Turbo, an efficient but powerful few-steps ODE waveform generator tuned from the pre-trained CFM-based Waveform generator via adversarial flow matching optimization. The main contributions of this work are as follows:\n\u2022 We propose PeriodWave-Turbo, a novel ODE-based waveform generator achieving state-of-the-art performance on the objective and subjective evaluation.\n\u2022 We successfully accelerate the CFM-based models by adversarial flow matching optimization that utilizes few-step generation and adversarial feedback.\n\u2022 The results shows that our models have much more powerful performance on the two-stage TTS pipelines than other GAN-based models and the pre-trained CFM generator.\n\u2022 We demonstrate the effectiveness of the proposed methods by exploring different model sizes. We observed that scaling up the model size simply improved the performance by achieving a PESQ score of 4.454.\n\u2022 These improvements only requires few-steps of fine-tuning from the pre-trained CFM teacher models. The entire training time significantly reduced.\n\u2022 We will release all source code and checkpoints."}, {"title": "Related Works", "content": "Accelerating Methods for Few-Step Generator\nDiffusion-based generative models have demonstrated their powerful performance across various domains. However, they require iterative sampling processes, resulting in slow inference speed. To address this limitation, several methods have been proposed to accelerate synthesis speed.\nFirst, consistency models (CM) (Song et al. 2023; Ye et al. 2023) have introduced one-step or few-step generation method by directly mapping noise to data, achieving improved performance through distilling pre-trained models. Consistency trajectory models (CTM) integrated CM and score-based models, and utilized adversarial training to enhance performance. FlashSpeech (Ye et al. 2024) proposed adversarial consistency training by using the SSL-based pre-trained model.\nDenoising diffusion GAN (DDGAN) (Xiao, Kreis, and Vahdat 2022; Oh, Lee, and Lee 2024) integrated the denoising process with a multimodal conditional GAN to enable faster sampling. UFOGen (Xu et al. 2024) enhanced the performance by using an improved reconstruction loss and initializing pre-trained diffusion models for both generator and discriminator. Adversarial diffusion distillation (ADD) (Sauer et al. 2023) leveraged a pre-trained teacher model for distillation and utilized adversarial training on the student models for one-step generation. Latent adversarial diffusion distillation (LADD) (Sauer et al. 2024) unified the discriminator and teacher models for more efficient training. Distribution matching distillation (DMD) (Yin et al. 2024b) demonstrated high-quality one-step generation via distribution matching distillation and reconstruction loss. DMD2 (Yin et al. 2024a) significantly improved few-step generation performance by eliminating reconstruction loss and integrating adversarial training with distribution matching distillation.\nIn summary, many works demonstrated that a well-designed reconstruction loss and adversarial training are crucial for efficient few-step generator."}, {"title": "Adversarial Feedback for Waveform Generation", "content": "So far, GAN-based models have dominated the waveform generation tasks by utilizing various well-designed discriminators to capture the specific characteristics of waveform signals. MelGAN (Kumar et al. 2019) first proposed a multi-scale discriminator (MSD) that reflects features from different scales of waveform signals using down-sampling. HiFi-GAN (Kong, Kim, and Bae 2020) introduced the multi-period discriminator (MPD) that can capture the implicit period features by reshaping the waveform signal with specific periodd of prime numbers. UnivNet (Jang et al. 2021) presented the multi-resolutional spectrogram discriminator (MRD) to capture different features in spectral domains. Fre-GAN (Kim et al. 2021; Lee et al. 2022) utilized resolution-wise discriminators. Abocodo (Bak et al. 2023) proposed collaborative multi-band discriminator (CoMBD) and sub-band discriminator (SBD). EnCodec (D\u00e9fossez et al. 2023) modified the MRD by using complex values of spectral features. (Gu et al. 2024) proposed a multi-scale sub-band Constant-Q Transform discriminator (MS-SB-CQTD) that improves the modeling of pitch and harmonic information in waveform signals."}, {"title": "PeriodWave-Turbo", "content": "Flow Matching for Waveform Generation\nRecently, the flow matching technique has shown great potential in generating high-quality waveforms by aligning the probability flow between the noise and the target distribution. PeriodWave (Lee, Choi, and Lee 2024) employs CFM to create a waveform generator and incorporates a period-aware generator architecture to capture the temporal features of input signals with greater precision. This approach enables the model to learn complex patterns across signals with varying periodicities by extracting and combining features from each period to generate vector fields. However, despite the effectiveness of flow matching-based models, the iterative processing steps can be slow, posing challenges for real-time applications. Thus, further optimization is necessary to improve generation speed while maintaining output quality."}, {"title": "Adversarial Flow Matching Optimization", "content": "Few-step Generator Modification We accelerate waveform generation by modifying the pre-trained CFM generator into fixed-step generator. We initialize the parameter by the pre-trained PeriodWave, and generate raw waveform signal from the noise $z_0$ with a fixed few-step ODE sampling. We used two or four step generation with Euler method. While this modification restricts the model with fixed step, fine-tuning the model with fixed-step makes it as a specialist for better optimization. Additionally, compared to a single step GAN generator, few-step generator could refine the waveform with iterative samplings (Koizumi et al. 2023; Jang, Lim, and Park 2023; Huang et al. 2022; Koizumi et al. 2022; Roman et al. 2023) by reducing the train-inference mismatch (Tan et al. 2024). However, it is important to fine-tune the model with the properly designed objectives. To do this, we firstly do a deep dive on the acceleration methods for waveform generation by comparing several reconstruction losses, adversarial training, and distillation methods"}, {"title": "Reconstruction Loss", "content": "Unlike the pre-training method with flow matching objective, we can utilize reconstruction losses on the raw waveform signals reconstructed by fixed step sampling and ODE solver. According to previous waveform generation models, we adopt the Mel-spectrogram reconstruction loss by transforming the waveform signal by short-time Fourier transformation (STFT) and Mel-filter $\\psi$ for focusing the human-perceptual frequency as follows:\n$L_{mel} = ||\\psi(x) - \\psi(\\hat{x})||_1.$\n(1)\nwhere $\\hat{x}$ is sampled with $G(x_t, c, t)$ and ODE solver (Euler method) with fixed steps, $c$ denotes Mel-spectrogram, and $[0, 0.25, 0.5, 0.75]$ for $t$ of four-step generator.\nFurthermore, we adopt multi-scale Mel-spectrogram reconstruction loss by using different parameters of STFT and Mel-filters. Following (Kumar et al. 2024), we also utilizes the hop sizes of $[8, 16, 32, 64, 128, 256, 512]$ and window sizes set to hop_size\u00d74 to capture the different resolution of frequency information. For comparison, we conduct the ablation study with multi-scale STFT loss without Mel-filters. But, this decreases the performance by generating high-noisy electric sound on the samples.\nAdversarial Training Although multi-scale Mel-spectrogram reconstruction loss could improve the reproduction, stability and convergence speed, it does not guarantee the high-quality waveform generation in subjective perceptual quality by resulting in noisy sound of generated samples. To overcome this issue, we also utilize the adversarial feedback by adopting multi-period discriminator (MPD) and multi-scale sub-band Constant-Q Transform discriminator (MS-SB-CQTD) as follows:\n$L_{adv}(D) = E_{x} [(D(x) - 1)^2 + D(G(x_t, c, t))^2],$\n(2)\n$L_{adv}(G) = E_{x} [(D(G(x_t, c, t)) \u2013 1)^2]$\n(3)\nwhere $D$ consists of MPD and MS-SB-CQTD, and we additionally utilize the feature matching loss $L_{fm}$ which is the"}, {"title": "Final Loss", "content": "The total loss for PeriodWave-Turbo can be expressed as follows:\n$L_{final} = L_{adv}(G) + \\lambda_{fm}L_{fm} + \\lambda_{mel}L_{mel}$   (4)\nwhere $\\lambda_{fm}$ and $\\lambda_{mel}$ are set to 2 and 45, respectively, and we utilize four-step generation with Euler method."}, {"title": "Model Size", "content": "We train the PeriodWave and PeriodWave-Turbo with different model sizes. Specifically, we train three models: Small (S, 7.57M), Base (B, 29.80M, original setting), and Large (L, 70.24M) models as indicated in Table 1."}, {"title": "Experiment and Result", "content": "Dataset We train the model with the open-source benchmark dataset, LJSpeech (Ito and Johnson 2017) and LibriTTS (Zen et al. 2019). Both datasets are widely used for waveform reconstruction tasks. First, LJSpeech is a high-quality single-speaker speech dataset consisting of 13,100 samples with a sampling rate of 22.05 kHz. Following (Kong, Kim, and Bae 2020), we utilize the same hyperparameter of STFT and Mel-filters with a hop size of 256, window size of 1024, FFT size of 1024, Mel filter of 80 Bins. Second, LibriTTS dataset is a high-quality multi-speaker speech dataset consisting of 354,780 samples (555 Hours and 2,311 Speakers) with a sampling rate of 24 kHz. Following (Lee et al. 2023), we utilize the same hyperparameter of STFT and Mel-filters with a hop size of 256, window size of 1024, FFT size of 1024, Mel filter of 100 Bins."}, {"title": "Pre-training", "content": "We pre-train PeriodWave-S/B with flow matching objective for 1M steps using the AdamW optimizer with a learning rate of 2\u00d710-4, batch size of 128 on four NVIDIA A100 40GB GPUs. We pre-train PeriodWave-L with the same hyperparameter on four NVIDIA A100 80GB GPUs. During pre-training, we segmented the waveform signal by 32,768 frames for efficient training. For LJSpeech, we only train the Base model of 29.73M. Table 1 indicated the pre-training time of each model for 1M steps. Pre-training the model with FM objective shows tremendous efficiency compared to GAN training."}, {"title": "Training", "content": "To accelerate the CFM-based PeriodWave, we fix the sampling steps with four and use the Euler method for ODE solver. We train the PeriodWave-Turbo from the pre-trained PeriodWave with adversarial flow matching optimization of Equation 4. For LJSpeech, we train the PeriodWave-Turbo for only 0.1M steps using the AdamW optimizer with a learning rate of 2\u00d710-5, batch size of 32 on four NVIDIA A100 40GB GPUs. For LibriTTS, we train the PeriodWave-Turbo-S/B for 0.3M steps using the AdamW optimizer with a learning rate of 2\u00d710\u22125, batch size of 32 on four NVIDIA A100 40GB GPUs. We train the PeriodWave-Turbo-L with the same hyperparameter on four NVIDIA A100 80GB GPUs. We segmented the waveform signal by 32,768 frames for efficient training. Table 1 indicated the training time of each model for 0.3M steps. Compared to fully GAN training that requires 2.5M (Kong, Kim, and Bae 2020), 5M(Lee et al. 2023), 10M (Shibuya, Takida, and Mitsufuji 2024), our method only requires much smaller training steps (0.3M)."}, {"title": "ODE Sampling", "content": "Although the teacher models (PeriodWave) use Midpoint method with sampling steps of 16, PeriodWave-Turbo models utilize Euler method with sampling steps of four. We discussed the inference speed at the Table 5."}, {"title": "LJSpeech: High-quality Single Speaker Dataset", "content": "We evaluate the LJSpeech benchmark performance by comparing HiFi-GAN, BigVGAN-base, BigVGAN, BigVGAN-v2, PriorGrad, and PeriodWave. Note that BigVGAN-base and BigVGAN are trained with LibriTTS dataset for 5M steps and BigVGAN-v2 is trained with large-scale dataset including multi-lingual speech, environmental sounds, and instruments. Table 2 demonstrates that PeriodWave-Turbo achieived state-of-the-art performance in all objective metrics. Furthermore, tuning the model with only 1,000 training steps could achieve better performance than other large-scale trained models without M-STFT. This show the efficiency of our adversarial flow matching optimization. We observed that additional training consistently improve the performance in all metrics. We will release the final checkpoint of PeriodWave-Turbo (LJSpeech) together."}, {"title": "LibriTTS: Multi-speaker Dataset with 24,000 Hz", "content": "Following BigVGAN, we first evaluate the LibriTTS benchmark performance by comparing UnivNet, Vocos, BigVSAN, BigVGAN, BigVGAN-v2, and PeriodWave. Table 3 demonstrated the effectiveness of our model in terms of all metrics. Additionally, PeriodWave-Turbo achieves unprecedented performance, with a perceptual evaluation of speech quality (PESQ) score of 4.454 on this benchmark with only LibriTTS dataset. Furthermore, the results for different model sizes show the robustness of our structure in that PeriodWave-Turbo-S (7.57M) also has better performance than BigVSAN (112.4M) and BigVGAN (112.4M). Furthermore, scaling up the model could improve the performance consistently. Although additional training could decrease the distance of STFT domain, our model already shows better perceptual quality so we stop the training in early steps. To further demonstrate this, we conducted additionally evaluation on subjective evaluation, OOD scenarios, and two-stage TTS.\nWe also evaluated the objective evaluation for the test subsets of LibriTTS. Table 4 shows the consistent results with the dev subsets, and our model also has the best performance on all metrics without M-STFT. Note that the loss curve for M-STFT is not converged but we stop the training for training efficiency."}, {"title": "Subjective Evaluation", "content": "Additionally, we evaluate the subjective evaluation for the same test subsets of LibriTTS. Table 5 demonstrated that our model has better performance than the previous models including large-scale GAN-based models and teacher models (PeriodWave). The results also demonstrated the effectiveness of our proposed method in that PeriodWave-Turbo-S (7.57M) shows better performance than the large-scale GAN-based models with \u00d714.84 smaller model parameters. PeriodWave-Turbo-L achieved the best performance."}, {"title": "Inference Speed and Memory Usage", "content": "We calculated the xRT on CPU and GPU with AMD EPYC 7313 and NVIDIA RTX A6000, respectively. xRT denotes the synthesis speed relatative to real-time. We utilize the same samples from the test subsets of LibriTTS. We successfully accelerate the inference speech compared to our teacher models. Specifically, thanks to adversarial flow matching optimization, PeriodWave-Turbo-B could improve the performance with \u00d77.57 faster inference speech compared to PeriodWave-B. Additionally, our models without large model requires lower VRAM usages."}, {"title": "MUSDB18-HQ: Multi-track Music Audio Dataset for Out-Of-Distribution Robustness", "content": "We conducted the objective evaluation on the MUSDB18-HQ dataset, a multi-track music audio dataset to evaluate the out-of-distribution (OOD) robustness. We compared the performance of our models with the UnivNet, Vocos, BigVSAN, BigVGAN, and BigVGAN-v2. Table 6 demonstrated the robustness of our model on the OOD samples. we our model performed better at almost objective metrics.\nAdditionally, we conducted the subjective evaluation on the MUSDB18-HQ dataset. We compared the similarity MOS for each instruments, and our models has higher SMOS than other models except for BigVGAN-v2 as indicated in Table 7. We analyzed that using the powerful and novel period-aware vector field estimator for our generator could refine the waveform signal with iterative samplings, and the Table 6 also demonstrated that the effectiveness of pitch and periodicity modeling resulting in better audio quality and similarity. For model scalability, scaling up the model could improve the robustness of out-of-distribution scenarios."}, {"title": "Zero-shot TTS Results on LibriTTS dataset", "content": "Previously, large-scale GAN-based models show low performance on two-stage TTS which consists of acoustic model and neural vocoder due to training-inference mismatch issue. Although they reconstruct the waveform signal from the ground-truth Mel-spectrogram, they might lose their robustness on the synthesized Mel-spectrogram by acoustic models due to the imperfect conditioning (Roman et al. 2023).\nTo further demonstrate the effectiveness of our models, we conduct the evaluation on two-stage TTS pipelines with ARDIT-TTS (Liu et al. 2024). We calculate the character error rate (CER) and word error rate (WER) by using Whishper-large-v2, and speaker encoder cosine similarity (SECS) by using WavLM and Resemblyzer, UTMOS for audio quality, and subjective evaluation MOS.\nTable 8 shows that PeriodWave-Turbo-B/L have better speech accuracy in terms of CER and WER than other previous models. All models have almost same SECS results, and this means that SECS is more related to acoustic model. The UTMOS results show that our models have better audio quality. The subjective evaluation results also demonstrate our model have better naturalness on two-stage TTS scenarios."}, {"title": "Ablation Study", "content": "Reconstruction Loss We compared three reconstruction losses including multi-scale Mel-spectrogram (M-Mel) loss, single-scale Mel-spectrogram (Single Mel) loss, and multi-scale STFT (M-STFT) loss at Table 9. We found that most models without GAN collapsed after 10k steps and only M-Mel loss could make the training stable without GAN loss. Single Mel loss has lower performance than M-Mel loss, and the model with M-STFT generates a high electric noise.\nAdversarial Feedback Although M-Mel loss could improve the robustness in terms of objective metrics, the generated samples contain a lot of artifact resulting in low perceptual quality. To reduce this problem, it is crucial to utilize the adversarial feedback with well designed discriminator. With MPD and MS-SB-CQTD, our model can be trained stably, and the performance consistently improved during training.\nDistribution Matching Distillation We found that DMD with the pre-trained FM generator as a teacher model could not improve the performance. We can discuss it because we already use the strong time-aligned condition Mel-spectrogram for neural vocoder so DMD is not necessary. However, we see that adopting this loss could improve the performance of text-conditional generation tasks such as text-to-audio model.\nPre-training It is important to utilize the pre-trained CFM generator for adversarial flow matching optimization. First, this significantly reduce the entire training time. comparing the models trained with same time, PeriodWave-Turbo-B performed much better than the model from the scratch (0.5M)."}, {"title": "Few-step Generation", "content": "We trained the model by modifying it as two-step generator. This model also achieved higher performance than other previous models, and has better efficiency. However, increasing the steps results in better performance so we utilize four-step generation as default settings."}, {"title": "Conclusion", "content": "In this work, we present PeriodWave-Turbo, a novel ODE-based few-step waveform generator. With adversarial flow matching optimization, we successfully accelerate the CFM-based waveform generator. Our results demonstrate both the effectiveness and efficiency of our approach, achieving state-of-the-art performance across nearly all objective and subjective metrics. Notably, our model attained an unprecedented PESQ score of 4.454 on the LibriTTS benchmark. Furthermore, our model exhibits superior robustness in OOD and two-stage TTS scenarios.\nWhile our models demonstrate powerful generative performance and training efficiency, we recognize the opportunity to further optimize inference speed. In future work, we intend to enhance inference speed by adopting multiple STFT-based down-sampling method, replacing the current downsampling block in UNet. Additionally, we believe that our model has the potential to be adapted for end-to-end text-to-speech and text-to-audio generation tasks. Therefore, we plan to extend our work to encompass versatile conditional generative models. We hope that our approach will contribute to the study of waveform generation, and as such, we will release all source code, checkpoints, and TTS/VC application (Choi, Lee, and Lee 2023, 2024) together."}]}