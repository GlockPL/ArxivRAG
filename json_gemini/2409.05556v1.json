{"title": "SCIAGENTS: AUTOMATING SCIENTIFIC DISCOVERY THROUGH MULTI-AGENT INTELLIGENT GRAPH REASONING", "authors": ["Alireza Ghafarollahi", "Markus J. Buehler"], "abstract": "A key challenge in artificial intelligence is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data. In this work, we present SciAgents, an approach that leverages three core concepts: (1) the use of large-scale ontological knowledge graphs to organize and interconnect diverse scientific concepts, (2) a suite of large language models (LLMs) and data retrieval tools, and (3) multi-agent systems with in-situ learning capabilities. Applied to biologically inspired materials, SciAgents reveals hidden interdisciplinary relationships that were previously considered unrelated, achieving a scale, precision, and exploratory power that surpasses traditional human-driven research methods. The framework autonomously generates and refines research hypotheses, elucidating underlying mechanisms, design principles, and unexpected material properties. By integrating these capabilities in a modular fashion, the intelligent system yields material discoveries, critique and improve existing hypotheses, retrieve up-to-date data about existing research, and highlights their strengths and limitations. Our case studies demonstrate scalable capabilities to combine generative AI, ontological representations, and multi-agent modeling, harnessing a 'swarm of intelligence' similar to biological systems. This provides new avenues for materials discovery and accelerates the development of advanced materials by unlocking Nature's design principles.", "sections": [{"title": "1 Introduction", "content": "One of the grand challenges in the evolving landscape of scientific discovery is finding ways to model, understand, and utilize information mined from diverse sources as a foundation for further research progress and new science discovery. Traditionally, this has been the domain of human researchers who review background knowledge, draft hypotheses, assess and test these hypotheses through various methods (in silico or in vitro), and refine them based on their findings. While these conventional approaches have led to breakthroughs throughout the history of science, they are constrained by the researcher's ingenuity and background knowledge, potentially limiting discovery to the bounds of human imagination. Additionally, conventional human-driven methods are inadequate for exploring the vast amount of existing scientific data to extrapolate knowledge toward entirely novel ideas specially for multi-disciplinary areas like bio-inspired materials design where a common goal is to extract principles from Nature's toolbox and bring it to bear towards engineering applications.\nThe emergence of artificial intelligence (AI) technologies presents a potential promising solution by enabling the analysis and synthesis of large datasets beyond human capability, which could significantly accelerate discovery by uncovering patterns and connections that are not immediately obvious to human researchers [1, 2, 3, 4, 5]. Therefore, there is great interest in developing AI systems that can not only explore and exploit existing knowledge to make significant scientific discoveries but also automate and replicate the broader research process, including acquiring relevant knowledge and data [6, 7, 8, 9, 10].\nLarge language models (LLMs), such as OpenAI's GPT series [11], have demonstrated remarkable progress in diverse domains, driven by their robust capabilities [12, 13, 14, 15, 16]. These foundational general-purpose AI models [17, 18, 19, 11] have been increasingly applied in scientific analysis, where they facilitate the generation of new ideas and hypotheses, offering solutions to some of the intrinsic limitations of conventional human-driven methods [20, 21, 22, 23, 24, 25, 26]. Despite their successes, significant challenges persist regarding their ability to achieve the level of expertise possessed by domain specialists without extensive specialized training. Common issues include their tendency to produce inaccurate responses when dealing with questions that fall outside their initial training scope, and broader concerns about accountability, explainability, and transparency. These problems underscore the potential risks associated with the generation of misleading or even harmful content, requiring us to think about strategies that increase their problem-solving and reasoning capabilities.\nIn response to these challenges, in-context learning emerges as a compelling strategy to enhance the performance of LLMs without the need for costly and time-intensive fine-tuning. This approach exploits the model's inherent ability to adapt its responses based on the context embedded within the prompt, which can be derived from a variety of sources. This capability enables LLMs to execute a wide array of tasks effectively [27, 28, 29]. The potential to construct powerful generative AI models that integrate external knowledge to provide context and elicit more precise responses during generation is substantial [30]. The central challenge is to develop robust mechanisms for the accurate retrieval and integration of relevant knowledge that enables LLMs to interpret and synthesize information pertinent to specific tasks, particularly in the realm of scientific discovery.\nThe construction of knowledge bases and the strategic retrieval of information from them are gaining traction as effective methods to enhance the generative capabilities of LLMs. Recent advancements in generative AI allow for the efficient mining of vast scientific datasets, transforming unstructured natural language into structured data such as comprehensive ontological knowledge graphs [31, 32, 6, 33, 34]. These knowledge graphs not only provide a mechanistic breakdown of information but also offer an ontological framework that elucidates the interconnectedness of different concepts, delineated as nodes and edges within the graph.\nWhile single-LLM-based agents can generate more accurate responses when enhanced with well-designed prompts and context, they often fall short for the complex demands of scientific discovery. Creating new scientific insights involves a series of steps, deep thinking, and the integration of diverse, sometimes conflicting information, making it a challenging task for a single agent. To overcome these limitations and fully leverage AI in automating scientific discovery, it's essential to employ a team of specialized agents. Multi-agent AI systems are known for their ability to tackle complex problems across different domains by pooling their capabilities [35, 23, 36, 37, 38]. This collaborative approach allows the system to handle the intricacies of scientific discovery more effectively, potentially leading to breakthroughs that are difficult to achieve by single agents alone.\nBuilding on these insights, our study introduces a method that synergizes the strengths of ontological knowledge graphs [39, 40] with the dynamic capabilities of LLM-based multi-agent systems, setting a robust foundation for enhancing graph reasoning and automating the scientific discovery process. Within this generative framework, the discovery workflow is systematically broken down into more manageable subtasks. Each agent in the system is assigned a distinct role, optimized through complex prompting strategies to ensure that every subtask is tackled with targeted expertise and precision. This strategic division of labor allows the AI system to proficiently manage the complexities of scientific research, fostering effective collaboration among agents. This collaboration is crucial for generating, refining, and critically evaluating new hypotheses against essential criteria like novelty and feasibility.\nCentral to our hypothesis generation is the utilization of a large ontological knowledge graph, focusing on biological materials, and developed from around 1,000 scientific papers in this domain [6]. We implemented a novel sampling strategy to extract relevant sub-graphs from this comprehensive knowledge graph, allowing us to identify and understand"}, {"title": "2 Results and discussion", "content": "LLMs have demonstrated a relatively high level of proficiency across a wide range of tasks, including question answering, hypothesis development, summarizing and contrasting ideas, processing complex information, executing tasks, and even writing code. However, conventional inference strategies often fail to produce sophisticated reasoning and detail in the generated data. By using a set of interacting models, and assigning distinct roles to LLM-based agents, effective multi-agent AI systems can be constructed. When combined with carefully crafted prompts and in-context learning from graph representation of data, these systems are capable of generating scientific ideas and hypotheses. We now present results from a several experiments we conducted with our proposed framework (details about implementation, see Materials and Methods section)."}, {"title": "2.1 Multi-agent system for graph reasoning and scientific discovery", "content": "Figure 1 illustrates the outline of our proposed multi-agent model designed to automate the scientific discovery process based on the key concepts and relationships retrieved from a comprehensive knowledge graph developed from scientific papers (Figure 1a). This figure further showcases two distinct strategies deployed in this study for generating novel scientific hypotheses, both of which harness the collective intelligence of a team of agents. These strategies integrate the specialized capabilities of each agent, systematically exploring uncharted research territories to produce innovative and high-impact scientific hypotheses. The full description of the agents incorporated in SciAgents is listed in Figures S1-S4 in the Supporting Information.\nThe key difference between these approaches lies in the nature of the interaction between the agents. In the first approach (Figure 1b), the interactions between agents are pre-programmed and follow a predefined sequence of tasks that ensure consistency and reliability in hypothesis generation. In contrast, the second approach features fully automated agent interactions without any predetermined order of how interactions between agents unfold, providing a more flexible and adaptive framework that can dynamically respond to the evolving context of the research process. This second strategy (Figure 1c) also incorporates human-in-the-loop interactions, enabling human intervention at various stages of research development. Such interventions allow for expert feedback, refinement of hypotheses, or strategic guidance, specification about certain materials, types or features, ultimately enhancing the quality and relevance of the generated scientific ideas. Moreover, the second approach provides a more robust framework where additional tools could be readily incorporated. For instance, we have empowered our automated multi-agent model with the Semantic Scholar API as a tool that provides it with an ability to check the novelty of the generated hypothesis against the existing literature.\nFigure 2 shows an overview of the entire process from initial keyword selection to the final document. We employ a hierarchical expansion strategy where answers are successively refined and improved, enriched with retrieved data, critiqued and amended by identification or critical modeling, simulation and experimental tasks and adversarial prompting. The process begins with initial keyword identification or random exploration within a graph, followed by path sampling to create a subgraph of relevant concepts and relationships. This subgraph forms the basis for generating structured output in JSON following a specific set of aspects that the model is tasked to develop. These include the hypothesis, outcome, mechanisms, design principles, unexpected properties, comparison, and novelty. Each component is subsequently expanded on with individual prompting, to yield significant amount of additional detail, forming a comprehensive draft. This draft then undergoes a critical review process, including amendments for modeling and simulation priorities (e.g., molecular dynamics) and experimental priorities (e.g., synthetic biology). The final integrated draft, along with critical analyses, results in a document that can guide further scientific inquiry."}, {"title": "2- Deep Insights with LLM-Based Analysis", "content": "Utilizing our LLM-powered ontologist agent, we move deeper into the intricacies of the relationships that have been mapped out in the earlier path generation stage. By examining the connections and nuances among the identified concepts, the agent helps transition from static knowledge retrieval to dynamic knowledge generation. This crucial shift is what enables the model to identify gaps in existing research and propose new angles of inquiry, thereby laying the groundwork for novel ideas and hypotheses. In this context, the role of the ontologist agent is instrumental. It applies advanced reasoning and inference techniques to synthesize and interpret the complex web of data. This capability allows it to extract significant insights that might not be obvious at first glance, offering a richer, more detailed understanding of the relationships."}, {"title": "3- Research Hypothesis Generation and Expansion", "content": "This stage is where the effects of our multi-agent system emerges. The scientist agent harnesses the extensive knowledge parsed from the knowledge graph and further refined by the ontologist to propose novel research ideas. Through complex prompting, as shown in Figure 5, the agent is assigned specific roles and is tasked with synthesizing a novel research proposal that integrates all key concepts from the knowledge graph. The designated agent, Scientist_1, is configured to deliver a detailed hypothesis that is both innovative and logically grounded, aiming to advance the understanding or application of the provided concepts. The agent creates a proposal that carefully addresses the following seven key aspects: hypothesis, outcome, mechanisms, design principles, unexpected properties, comparison, and novelty. This approach ensures a thorough exploration and evaluation of the new scientific idea, allowing for a detailed assessment of its feasibility, potential impact, and areas of innovation.\nThe proficiency of the Scientist_1 LLM agent in generating novel research hypotheses is demonstrated in Figure 3. The concept involves integrating silk with dandelion-based pigments to create biomaterials with enhanced optical and mechanical properties. The proposed enhancement in mechanical properties stems from a hierarchical organization of silk combined with the reinforcing effects of the pigments. According to the model, this proposed composite material could exhibit significantly improved mechanical strength, reaching up to 1.5 GPa compared to traditional silk materials, which range from 0.5 to 1.0 GPa. Additionally, the use of low-temperature processing and dandelion pigments is projected to reduce energy consumption by approximately 30%. This example underscores the potential of translating knowledge graphs into unprecedented material designs, facilitating a seamless transition from theoretical data to practical applications in materials science.\nThe research idea proposed by Scientist_1 provides a foundational abstract for a more detailed research proposal that is developed through subsequent agentic interactions. To enhance and deepen this initial concept, Scientist_2 is tasked with rigorously expanding upon and critically assessing the idea's various components. This agent is specifically instructed to integrate, wherever possible, quantitative scientific information such as chemical formulas, numerical values, protein sequences, and processing conditions, significantly enriching the proposal's scientific depth and accuracy. Additionally, Scientist_2 is directed to comment on specific modeling and simulation techniques tailored to the project's needs, such as simulations for material behavior analysis or experimental methods. This thorough review and enhancement process, including clear rationale and step-by-step reasoning, ensures that the research proposal is robust, well-grounded, and ready for further development. This systematic approach not only solidifies the scientific underpinnings of the proposal but also prepares it for successful implementation and future exploration.\nThe expanded research idea provided by Scientist_2 is showcased in the Supplementary Information, revealing a thorough rationale and sequential reasoning for various aspects of the research proposal. Here are selected key points to exemplify the model's contributions:"}, {"title": "2.2 Autonomous agentic modeling", "content": "The experiments so far were conducted using the non-automated multi-agent system (see Figure 1), whereas the second approach described in this section uses an automated way to generate a research hypothesis from a knowledge graph that facilitates dynamic interactions.\nThe automated multi-agent system consists of a team of AI agents, each powered by a state-of-the-art general purpose large language model from the GPT-4 family [11], accessed via the OpenAI API [44]. Each agent has a specific role and focus in the system which is described by a unique profile. Our team of agents with the following entities collaborate in a dynamic environment to create a research proposal:"}, {"title": "3 Conclusion", "content": "We introduced a multi-agent AI framework designed to autonomously generate and refine research hypotheses by leveraging LLMs and a comprehensive ontological knowledge graph 1, applied here in the context of biologically inspired materials. Our results demonstrate the significant potential of integrating AI agents with specialized roles to tackle the complex and interdisciplinary nature of scientific discovery, particularly in the domain of bio-inspired materials. The automated system effectively navigated the intricate web of relationships within the knowledge graph, generating diverse and novel hypotheses that align with unmet research needs. The proposed approach, harnessing a modular, hierarchically organized (Figure 2) swarm of intelligence (Figure 1) similar to biological systems with multiple iterations to model the process of negotiation a solution during the process of thinking and reflecting about a problem, offers a much more nuanced reasoning approach than conventional zero-shot answers generated by AI systems, as shown in Figure 11.\nThe ontological knowledge graph representation of data plays a crucial role in our approach, as it serves as the foundational structure that guides the research idea generation, ensuring that the hypotheses proposed by the AI agents are both informed by and rooted in a vast network of interconnected scientific concepts. By systematically navigating this graph, our multi-agent system identifies and capitalizes on previously unrecognized relationships, aiming towards the creation of highly-rated innovative ideas that are as feasible as they are groundbreaking. The incorporation of assessment strategies is an important strategic aspect that reflects adversarial relationships commonly identified in conventional research strategies, such as team-based efforts or peer-review. A notable feature was the finding that the autonomous multi-agent system can develop sophisticated problem solving strategies (see, Figure 7) on its own. These types of results are expected to improve as more powerful foundation models become available, especially with better long-term planning and reasoning capabilities.\nThe multi-agent approach proved particularly effective in decomposing the scientific discovery process into manageable subtasks, enabling a more systematic exploration of the knowledge landscape. By assigning distinct roles to each agent-ranging from path generation and deep analysis to hypothesis formulation and critical review, we achieved a thorough and rigorous development of research ideas. Our experiments showed that the system could consistently"}, {"title": "4 Materials and methods", "content": ""}, {"title": "4.1 Ontological knowledge graph", "content": "We use a large graph generated as part of earlier work [6] in this research.\nThe graph utilized here includes 33,159 nodes and 48,753 edges and represents the giant component of the graph generated from around 1,000 papers with 92 communities. We use the BAAI/bge-large-en-v1.5 embedding model."}, {"title": "4.2 Heuristic pathfinding algorithm with random waypoints", "content": "The algorithm presented in this work combines heuristic-based pathfinding with node embeddings and randomized waypoints to discover diverse paths in a graph. The primary goal is to find a path between a source and a target node by estimating distances using node embeddings. The embeddings are generated using a pre-trained model and are crucial for the heuristic function, which estimates the distance between the current node and the target node. By relying on these embeddings, the algorithm adapts to the topological structure of the graph, allowing it to effectively traverse complex networks. Additionally, the algorithm uses a modified version of Dijkstra's algorithm that introduces a randomness factor to the priority queue, creating paths that are not strictly deterministic [45]. We chose the randomness factor to be 0.2 in our experiments.\nAn additional feature of the algorithm is the introduction of random waypoints to diversify the pathfinding process. These waypoints are selected from neighboring nodes that are not part of the initial path, enabling the algorithm to explore alternative routes. The randomization factor controls the balance between heuristic-driven search and stochastic exploration, making it flexible for different use cases. After the path is found, a subgraph consisting of the path nodes and their second-hop neighbors is generated, providing a broader context for the discovered route. The resulting paths are then used as substrate for graph reasoning."}, {"title": "4.3 Graph reasoning", "content": ""}, {"title": "4.3.1 Initial ideation", "content": "The initial step in the approach develops a scientific hypothesis based on a knowledge graph derived from a heuristic path in a given graph $G$ as described in Section 4.2. Here the graph $G$ represents a set of interconnected nodes, where each node can represent an entity or concept, and edges represent relationships between these nodes. The algorithm begins by identifying two key nodes, keyword_1 and keyword_2, which can either be explicitly specified or randomly selected from $G$. If the shortest_path flag is set to True, the function computes the shortest path between these nodes by using embeddings to estimate the best-fitting nodes, leveraging a pre-existing function called find_path. If shortest_path is set to False, a heuristic pathfinding approach is employed, which incorporates randomization and potentially random waypoints to explore more diverse paths. The graph structure is used not only for identifying the connectivity between the nodes but also for guiding the algorithm's search for the most relevant or exploratory paths based on the node embeddings.\nOnce a path between keyword_1 and keyword_2 is established, the function constructs a knowledge graph from the path and its relationships. This knowledge graph consists of the nodes traversed and the relationships (edges)"}, {"title": "4.3.2 Expansion of the initial concepts", "content": "The final phase of the methodology focuses on leveraging the expanded research concept to identify key scientific questions and prioritize actionable research directions, particularly in the domains of molecular modeling and synthetic biology. This phase employs a generative model to analyze the complete research document, which includes the knowledge graph, expanded concepts, and critical reviews, with the goal of extracting the most impactful scientific questions. These questions are then further expanded into detailed experimental and simulation plans, or other specific aspects that a user wants to explore in detail.\nUsing the JSON developed as described in Section 4.3.1 we conduct several systematic steps.\nStep 1: Prompt-Driven Expansion of Key Research Aspects\nThe next phase involves systematically expanding specific aspects of the hypothesis using a series of targeted prompts. For each aspect of the research, a detailed prompt is constructed to critically assess and improve the scientific content of that aspect. The primary aspects are drawn from the JSON dictionary, where we iterate over all elements in that data structure.\nThe following steps summarize how the model expands each research aspect:\nA prompt is created for each field in the JSON data structure, asking the model to expand upon the original content by adding quantitative details such as chemical formulas, material properties, or specific experimental methods.\nThe model is also instructed to provide a step-by-step rationale for the proposed scientific improve-ments.\nFor example, the prompt format includes:\nExpand on the following aspect: {field}.\nCritically assess the original content, add specifics, such as chemical formulas, sequences, microstructures, and rational improvements:\n{JSON_dictionary [field]}\nThe model generates expanded content under a heading such as ### Expanded Mechanisms or ### Expanded Outcomes. Each response is added to res_data_expanded to track the expanded fields.\nThe iterative process is repeated for each of the first seven fields in res_data, ensuring that every major aspect of the research concept is thoroughly evaluated and improved upon."}]}