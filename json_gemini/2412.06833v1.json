{"title": "Detecting Fake News on Social Media: A Novel Reliability Aware Machine-Crowd Hybrid Intelligence-Based Method", "authors": ["Yidong Chai", "Kangwei Shi", "Jiaheng Xie", "Chunli Liu", "Yuanchun Jiang", "Yezheng Liu"], "abstract": "Fake news on social media platforms poses a significant threat to societal systems, underscoring the urgent need for advanced detection methods. The existing detection methods can be divided into machine intelligence-based, crowd intelligence-based, and hybrid intelligence-based methods. Among them, hybrid intelligence-based methods achieve the best performance but fail to consider the reliability issue in detection. In light of this, we propose a novel Reliability Aware Hybrid Intelligence (RAHI) method for fake news detection. Our method comprises three integral modules. The first module employs a Bayesian deep learning model to capture the inherent reliability within machine intelligence. The second module uses an Item Response Theory (IRT)-based user response aggregation to account for the reliability in crowd intelligence. The third module introduces a new distribution fusion mechanism, which takes the distributions derived from both machine and crowd intelligence as input, and outputs a fused distribution that provides predictions along with the associated reliability. The experiments on the Weibo dataset demonstrate the advantages of our method. This study contributes to the research field with a novel RAHI-based method, and the code is shared at https://github.com/Kangwei-g/RAHI. This study has practical implications for three key stakeholders: internet users, online platform managers, and the government.", "sections": [{"title": "1. Introduction", "content": "Social media platforms like Twitter and Weibo empower users to share news from their own perspectives and experiences (Hu 2021, Hu and Hong 2022). With millions of users engaging daily, news on social media spreads rapidly (Fang et al. 2024), making it a significant channel for information dissemination (Kahr et al. 2024). According to a 2021 Pew Research Center survey, 48% of American adults frequently rely on social media for news. However, this surge in news sharing also comes with a proliferation of fake news (Ul Hussna et al. 2021). Worse still, fake news tends to spread much faster and wider than true news (Garc\u00eda Lozano et al. 2020), posing significant risks to society and becoming a pressing social issue. For instance, during the COVID-19 pandemic, misinformation suggesting that disinfectants could treat the virus circulated widely and tragically led to three fatalities after consuming hand sanitizer in New Mexico. For another example, social bots manipulate and disseminate fake news, thereby distorting online discussions, influencing public opinion, and posing a significant threat to societal systems, such as the integrity of presidential elections (Mendoza et al. 2024). Such instances underscore the dire consequences of fake news on social media and the urgent need for advanced detection methods.\nA plethora of methods have been proposed by both social media companies and academic researchers for the detection of fake news (Cardoso et al. 2019). Given the overwhelming volume of content on social media platforms, discerning what is true and what is not requires a sophisticated understanding of the information at hand. Intelligence plays a pivotal role in this process. These detection methods can be categorized into three types based on the intelligence they leverage (Collins et al. 2021). The first type relies on machine intelligence and is thus referred to as machine intelligence-based methods (Mundra et al. 2023). These methods employ various machine learning models to extract intelligence such as learning useful discriminative features from various sources like news publishers (Hayawi et al. 2023), text bodies (Chen et al. 2023), and images (Uppada et al. 2023) to assess the veracity of news articles. However, these methods are solely dependent on historical data, making them less effective when faced with emerging news stories (Hu et al. 2022). The second type of methods harness intelligence from a crowd of users and are therefore called crowd intelligence-based methods (Tchakount\u00e9 et al. 2020). Users' responses to fake and truthful news articles differ due to their own knowledge and experiences (Li et al. 2022). For example, users may write refutations or comments to clarify when they perceive news as fake, while they may offer positive feedback if they believe the news is truthful (Souza"}, {"title": "2. Literature Review: Fake News Detection in Social Media", "content": "Fake news refers to intentionally fabricated news articles designed to deceive readers (Dennis et al. 2023, Shu et al. 2017, Yuan et al. 2021). The content of fake news mimics truthful news but lacks the rigorous journalistic standards necessary for credibility (Mehta et al. 2022). Social networks offer convenient channels for disseminating information, making them fertile ground for the spread of fake news (Mocquard et al. 2020). Given the scale and seriousness of fake news on social media, various automated detection methods have been proposed to address this issue. According to the types of intelligence they exploited, the existing methods can be categorized into three types: machine intelligence-based detection, crowd intelligence-based detection and hybrid intelligence-based detection (Collins et al. 2021)."}, {"title": "2.1 Machine Intelligence-Based Detection Methods", "content": "Machine intelligence-based detection methods utilize machine learning to identify fake news by learning distinguishing features from news content and social context. Fake news and truthful news exhibit different patterns in content, such as headlines, body text, images, and videos (Shu et al. 2017), as well as in social context, including user engagements and behaviors on social media. Early research employed traditional machine learning models like Logistic Regression (LR),"}, {"title": "2.2 Crowd Intelligence-Based Detection Methods", "content": "Crowd intelligence-based detection methods rely on users' responses to gauge the veracity of news, leveraging human judgment and thoughts. On social media, where users feel less restrained and express themselves more openly (Suler 2004), some users leave comments to alert others to fake news (Benjamin and Raghu 2023). Large groups are often collectively smarter than individuals in assessing news veracity (Souza Freire et al. 2021), making user responses valuable for fake news detection. Many platforms utilize responses such as comments, reposts, likes/dislikes, and reports. For example, Reddit allows users to cast votes, with a lower Reddit score reducing"}, {"title": "2.3 Hybrid Intelligence-Based Detection Methods", "content": "Hybrid intelligence-based detection methods combine machine intelligence and crowd intelligence, leveraging their complementary strengths (F\u00fcgener et al. 2021). Human crowds, with their background knowledge, better understand news context and nuances and can seek external sources to verify suspicious news. In contrast, machine learning models are more efficient and can detect fake news early, even with minimal user response. By combining these strengths, hybrid methods achieve state-of-the-art performance in fake news detection. A critical component of hybrid methods is the fusion of machine and crowd intelligence. Current approaches include feature concatenation-based methods (Albahar 2021) and Bayesian network-based methods (Wei et al. 2022, Yang et al. 2019). Feature concatenation combines features from both intelligences into a unified set for detection (Albahar 2021). Bayesian network methods infer the veracity of"}, {"title": "3. The Proposed Method: A Reliability-Aware Hybrid Intelligence-Based Method", "content": "In response to the three research questions, we propose a novel reliability-aware hybrid intelligence-based fake news detection method with three modules. We adopt deep learning to learn machine intelligence in our method. Hence, the first module in our proposed method models the reliability of prediction from a deep learning-based fake news detector. It outputs a Gaussian distribution which reflects the reliability of the predictions. The second module is to model the reliability of prediction from a crowd of users whose reliabilities are inferred by considering the difficulties of different tasks. It outputs a Beta distribution that reflects the reliability of the crowd's predictions. The third module fuses the Gaussian distribution and the Beta distribution by optimizing a certain distribution with maximum likelihood. The framework is shown in Figure 1."}, {"title": "3.1 First Module: The Module to Model Machine Intelligence", "content": "As aforementioned, few fake news detection studies have considered the uncertainty in machine intelligence, thus failing to consider the reliability of the detection. However, the uncertainty in machine intelligence and deep learning in particular has become an important focus in areas such as healthcare, cybersecurity, and automated driving (Abdullah et al. 2022, Suk et al. 2024, Yang et al. 2024). Various methods have been proposed to model uncertainty, including ensemble learning, fuzzy theory, and Dempster-Shafer evidence theory-based methods. Among these methods, Bayesian deep learning stands out, offering clear insights into modeling uncertainty and providing a solid theoretical foundation (Gawlikowski et al. 2023). Therefore, it has become a major tool to model the machine intelligence uncertainty to inform the corresponding reliability. Hence, we also adopt Bayesian deep learning in this study.\nBayesian deep learning models the uncertainty of deep learning models in a Bayesian manner. Particularly, Bayesian deep learning incorporates the Bayesian theorem into deep learning where the model parameters follow a distribution and are updated based on the Bayesian theorem. Bayesian deep learning first puts prior distributions (denoted as $p(w)$) over the model's parameters (denoted as $w$ ). Then, given observed samples $X = \\{x_1, ...,x_n\\}$ and their corresponding labels $Y = \\{y_1, ..., y_n\\}$, the posterior distribution (denoted as $p(w|X, Y)$) is inferred based on the Bayesian theorem $p(w|X,Y) = \\frac{p(Y|X,w)p(w)}{p(Y|X)}$. With the learned parameters"}, {"title": "3.2 Second Module: The Module to Model Crowd Intelligence", "content": ""}, {"title": "3.2.1 Difficulty-Based User Reliability Estimation Method", "content": "Our estimation method is based on the Classical Test Theory (CTT) which posits that errors exist in the results of project testing and gives a simple evaluation method for the difficulty of the project. In our case, each fake news will attain many comments from different users, and the fake news is more difficult if only a smaller number of users respond correctly. We denote the difficulty of each news i as $d_i$ and then $d_i$ is computed as\n$d_i = \\frac{|U'_i|}{|U_i|}$        (3)\nwhere $|U_i|$ denotes the number of users who leave comments on news i, and $|U'_i|$ is the number of users who correctly identify news i according to their comments.\nAccording to Item Response Theory (IRT) which argues that there is a positive relationship between project difficulty and user ability. In our case, when a user can correctly gauge the veracity of a piece of news to which most users had incorrectly responded, this user is given more credit for their reliability. Then, we utilize the news difficulty $d_i$ to infer the reliability of a user j, which is denoted as $c_j$. Let $N_j$ denote the number of news items on which the user j has left comments, and $C_{ji}$ represent the set of news items that user j correctly identifies. The reliability of user j is then computed as\n$c_j = \\frac{1}{N_j}\\sum_{i \\in C_{j}} d_i$ (4)"}, {"title": "3.2.2 Supervision-Guided User Reliability Adjustment", "content": "Based on two well-established theories (i.e., Classical Test Theory and Item Response Theory), $c_j$ can accurately reflect the reliability of each user. Then, the $c_j$ is utilized to aggregate the users' responses. For news i, we denote the set of users who believe the news is fake as $F_i$, while the users that believe the news is true as $T_i$. Then, the aggregated prediction that the news is fake is computed as\n$E_{crowd} = \\frac{\\sum_{j \\in F_i} c_j}{\\sum_{j \\in F_i} c_j + \\sum_{j \\in T_i}c_j}$         (5)\nHere we introduce a supervision signal from the ground-truth to adjust the value of $c_j$, thereby further enhancing the accuracy of $c_j$ in reflecting the user's reliability. Hence, we call this"}, {"title": "3.3 Module of Fusion: A New Likelihood Maximization-Based Fusion Mechanism (LMFM)", "content": "Since the prediction from machine intelligence is a Gaussian distribution while the prediction from crowd intelligence is a Beta distribution, the fusion module outputs a distribution that contains the richest information from both sources. Fusing multiple distributions into one is common in the research field. Most previous studies fuse multiple homogenous distributions by minimizing the sum of the discrepancy between the existing distributions and the fused distribution. Formally, assuming there are K distributions $\\{f_k\\}$, they aim to find a distribution $f_{fused}$ by\n$f_{fused} = argmin_f \\sum_k DIS(f, f_k)$     (10)\nwhere $DIS(f, f_k)$ refers to the discrepancy between distribution f and the distribution $f_k$. This approach operates well in the situation of fusing homogenous distributions because it is relatively easy to compute the discrepancy between two homogenous distributions such as two Gaussian distributions or two Beta distributions. However, this approach is not suitable for our study because we need to fuse a Gaussian distribution and a Beta distribution, which are heterogeneous distributions, and the discrepancy between a Gaussian and a Beta distribution is not well-defined. Therefore, in this study, we propose a new Likelihood Maximization-based Fusion Mechanism"}, {"title": "3.4 Learning the Parameters of The Proposed Method", "content": "The goal of the first two modules is to provide predictions that enable higher precision in detecting fake news. Therefore, the parameters of these modules are updated by maximizing the likelihood of the ground-truth, denoted as $f(y_i|x_i)$, where $y_i$ is the correct label of news $x_i$. For the third module, its main goal is to obtain a high-quality fused distribution based on the output distributions of the first two modules, hence the likelihood defined in Equation (12) is the goal. Formally, let the parameters of the first two modules be $\\theta_1$ and $\\theta_2$, where $\\theta_1$ refers to the weights (w) of the Bayesian deep learning model, and $\\theta_2$ encompasses users' reliability $\\{c_j\\}$. We also denote the parameters of the third module as $\\theta_3$, which includes $V_h, b_h, V_o$, and $b_o$. The optimal $\\theta_1$, denoted as $\\theta^*_1$, is given by,\n$\\theta_1 = argmax_{\\theta_1} \\prod_i f(y_i|x_i, \\theta_1)$       (16)\nBy taking the logarithm, this can be rewritten as,\n$\\theta^*_1 = argmax_{\\theta_1} \\sum_i log(f(y_i|x_i, \\theta_1))$       (17)\nSince the ground-truth $y_i$ is either 0 or 1, this can be expressed in cross-entropy form as:\n$\\theta^*_1 = argmin_{\\theta_1} - \\sum_i [y_i log(f(y_i = 1|x_i, \\theta_1)) + (1 \u2013 y_i) log(f(y_i = 0|x_i, \\theta_1))]$       (18)\nHowever, obtaining the optimal $\\theta_1$ is challenging due to the presence of local minima. As is common practice in deep learning, we adopt gradient descent methods such as SGD to update $\\theta_1$ gradually. Formally, denoting the term we hope to minimize as $L_{machine} = \u2013 \\sum_i [y_i log(f(y_i = 1|x_i, \\theta_1)) + (1 \u2013 y_i) log(f(y_i = 0|x_i, \\theta_1))]$, then,\n$\\theta_1 \\leftarrow SGDOptimizer (\\nabla_{\\theta_1} L_{machine}, \\theta_1)$       (19)\nSimilarly, $\\theta_2$ is updated as follows:\n$\\theta_2 \\leftarrow SGDOptimizer(\\nabla_{\\theta_2} L_{crowd}, \\theta_2)$       (20)"}, {"title": "4. Evaluation", "content": "First, we describe the dataset used for the evaluation. Next, we outline the baseline algorithms and the evaluation metrics used for comparison. Then, we detail the experiments we conducted and present the results we obtained."}, {"title": "4.1 Dataset Description", "content": "We selected a publicly available Weibo rumor dataset to evaluate our model. Sina Weibo is a popular public online social media platform in China. Faced with the huge market demand in China, its daily traffic reaches billions, making it an important platform for information release and dissemination. The Weibo rumor dataset includes 1538 rumors and 1849 non-rumors. They enter the website backend management system through the API interface provided by Weibo to obtain the required news source information and all forwarding/commenting information. The Weibo rumor dataset specifically includes two parts: Weibo original texts with non-rumor and rumor tags, as well as forwarded/commented content with user IDs and posting times. The original texts of the Weibo dataset can be analyzed by machine learning, while the commented contents reflect crowd intelligence.\nWe further preprocessed the data with the following steps. 1) Removing special characters: As suggested by previous studies (Truong and Tran 2023), special characters such as punctuation marks and emojis that appear in news are removed. 2) Segmenting words: To enable the extraction of Chinese text features, this study utilizes the Jieba segmentation tool (Sun 2012) to process the original Chinese news text, breaking it down into distinct sets of words.3) Removing stop words: We refer to the Baidu Chinese stop word list (Na and Xu 2015) to remove stop words such as \"these\", \"I\", \"is\". 4) Removing null values: Since some news texts become null after removing stop words, we remove these null values. 5) Dividing the dataset: We randomly divided the mixed news data into training, validation, and testing dataset with a ratio of 7:2:1.\nWe then denoted the attitude of each user's comments. Since some users participated in commenting only a few times, data sparsity makes it hard to accurately measure their reliability."}, {"title": "4.2 Experiments", "content": "We evaluate the model with accuracy, precision, recall, and F1. Additionally, we include the area under the receiver operating characteristic curve (AUC). For all five metrics, a higher value indicates better performance."}, {"title": "4.2.1 Experiment 1: Comparison with Baselines", "content": "As mentioned in the literature review, the existing methods can be divided into three categories: 1) machine intelligence-based, 2) crowd intelligence-based, and 3) machine and crowd intelligence-based methods. Hence, the baselines in the experiment also include the three types.\nFor the machine intelligence-based ones, the existing methods are mainly based on CNN, LSTM, GRU, or Transformer. Hence, this study includes a CNN-based method (Kim 2014), an LSTM-based method (Bankar and Gupta 2023), a GRU-based method (Aslam et al. 2021), and a BERT-based method (Wu et al. 2023).\nFor the crowd intelligence-based methods, we compare our method with majority voting (MV) (Penrose 1946), weighted voting (WV), and unsupervised fake news detection framework (UFD) (Yang et al. 2019). The MV method determines the veracity of news by the attitude of the majority users' comments. WV assigns a weight for different users based on the accuracy of user recognition of news, and then determines the veracity of news by the attitude which obtains a larger sum of the weight. UFD creates a probability relationship between the reliability of users commenting news and the authenticity of the news with the Bayesian network, and it infers the authenticity of news by Bayesian learning."}, {"title": "4.2.2 Experiment 2: Ablation Analysis", "content": ""}, {"title": "1) Advantage of Combining Both Types of Intelligence", "content": "We compare our method with the variants where only machine intelligence or crowd intelligence is exploited."}, {"title": "2) Advantage of Considering The Reliability of Machine Intelligence", "content": "We show the advantage of considering reliability by comparing the model that considers (i.e., the Bayesian model with reliability) and that without. In particular, the model without considering reliability is a classic BERT, while the model that considers reliability is a BERT equipped with Bayesian learning. The comparison results are in Table 4."}, {"title": "3) Advantage of Adjusting The Reliability of Crowd Intelligence", "content": "In the crowd intelligence module, we propose calculating the reliability of each user based on the IRT statistical theory and then updating it with the supervision-guided user reliability adjustment. To examine the advantage of adjustment, we removed this module and tested the model's performance. The results are shown in Table 5. As shown in the table, the model without adjusting the weights achieved only an accuracy of 85.16%, a recall of 85.41%, an F1 score of 85.11%, and an AUC value of 89.37%, proving the effectiveness of the supervision-guided user reliability adjustment method."}, {"title": "4.3 Experiment on Dynamic Fake News Detection", "content": "In the early stages of news publication, user responses are sparse, and machine intelligence plays a dominant role. Initially, when no user responses are available, machine intelligence analyzes the news's veracity based solely on its content. Over time, as user responses accumulate, crowd intelligence becomes increasingly significant. This section evaluates the accuracy of fake news detection as user responses grow. In the experiment, the publication time was set as 1 minute, and model performance was assessed at intervals: 1 minute, 2 minutes, 3 minutes, 4 minutes, 5"}, {"title": "4.4 Case Study", "content": "In this section, we used several examples to demonstrate how our model works. We used BERT as the machine distribution discrimination method, combined with the output results of user"}, {"title": "5. Conclusion", "content": "Social media platforms empower users to share news from their own perspectives and experiences. However, the dissemination of fake news on social media platforms underscores the urgent need for advanced detection methods. Three types of methods have been proposed for the"}]}