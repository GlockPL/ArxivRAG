{"title": "MemWarp: Discontinuity-Preserving Cardiac Registration with Memorized Anatomical Filters", "authors": ["Hang Zhang", "Xiang Chen", "Renjiu Hu", "Dongdong Liu", "Gaolei Li", "Rongguang Wang"], "abstract": "Many existing learning-based deformable image registration methods impose constraints on deformation fields to ensure they are globally smooth and continuous. However, this assumption does not hold in cardiac image registration, where different anatomical regions exhibit asymmetric motions during respiration and movements due to sliding organs within the chest. Consequently, such global constraints fail to accommodate local discontinuities across organ boundaries, potentially resulting in erroneous and unrealistic displacement fields. In this paper, we address this issue with MemWarp, a learning framework that leverages a memory network to store prototypical information tailored to different anatomical regions. MemWarp is different from earlier approaches in two main aspects: firstly, by decoupling feature extraction from similarity matching in moving and fixed images, it facilitates more effective utilization of feature maps; secondly, despite its capability to preserve discontinuities, it eliminates the need for segmentation masks during model inference. In experiments on a publicly available cardiac dataset, our method achieves considerable improvements in registration accuracy and producing realistic deformations, outperforming state-of-the-art methods with a remarkable 7.1% Dice score improvement over the runner-up semi-supervised method. Source code will be available at https://github.com/tinymilky/Mem-Warp.", "sections": [{"title": "1 Introduction", "content": "Cardiovascular disease, a major cause of death worldwide [22], depends on medical imaging, especially cine-MRI [13], for diagnosis and treatment. Deformable image registration [3], a crucial step for cardiac analysis, has seen improvements through learning-based neural networks. These models vary from unsupervised to semi- and weakly-supervised frameworks. Unsupervised methods are favored"}, {"title": "2 Methodology", "content": ""}, {"title": "2.1 Preliminaries", "content": "Deformable image registration aims to establish voxel-level correspondences between a moving image $I_m$ and a fixed image $I_f$. The spatial relationship is represented by $\\phi(x) = x + u(x)$, where $x$ is a spatial location within the domain $\\Omega \\subset \\mathbb{R}^{H\\times W\\times D}$, and $u(x)$ denotes the displacement vector at that location. In unsupervised learning, a network $F_{\\theta}$ is trained to predict the deformation field $\\phi$, with its weights $\\theta$ optimized by minimizing a composite loss function $\\mathcal{L}$. This function combines metrics for dissimilarity between the warped moving image and the fixed image, and the smoothness of the deformation field: $\\mathcal{L} = \\mathcal{L}_{sim}(I_f, I_m \\circ \\phi) + \\lambda \\mathcal{L}_{reg}(\\phi)$. Here, $\\lambda$ serves to balance the smoothness constraint on the deformation field, with methods like the discontinuous regularizer proposed by Ng et al. [18] falling under this strategy. Semi-supervised methods, including our MemWarp, introduce an additional Dice loss $\\mathcal{L}_{dsc}(J_f, J_m \\circ \\phi)$ to assess the dissimilarity between the warped moving mask and the fixed mask. Weakly-supervised models need mask inputs for the network $F_{\\theta}$. For instance, DDIR [9] requires both moving and fixed masks, while textSCF [8] requires only the fixed mask."}, {"title": "2.2 Laplacian Pyramid Warping Network", "content": "To decouple feature extraction from similarity matching, we develop a Laplacian pyramid warping network (LapWarp) that leverages residual deformation fields across multiple scales, from coarse to fine. Contrary to previous method LapIRN [16,17], which applies image pyramids directly to raw images, LapWarp performs warping on feature maps and allows for interactions at all levels of the pyramid. This ensures stable training within its pyramid framework without requiring the warm starts or multi-stage coarse-to-fine training strategies.\nNetwork Architecture: LapWarp deviates from classic Unet by stacking moving and fixed images across the batch dimension and employing a unique decoder structure. In each decoder level, moving image features are first warped using the previous level's field. A standard decoder layer then extracts features from both images as a batch, which a flow generator uses at each pyramid level to create the residual deformation field by re-stacking features along channels.\nGiven $n$ pyramid levels, we obtain $n$ residual deformation fields, labeled from $\\Delta\\phi_n$ to $\\Delta\\phi_1$, and $n + 1$ total deformation fields, labeled from $\\phi_{n+1}$ to $\\phi_1$, with both sets following the convention that a larger index indicates a coarser level. At level $i + 1$, the feature maps $\\hat{I}_{m_{i+1}}$ and $\\hat{I}_{f_{i+1}}$ are generated by its decoder $d_{i+1}$. These feature maps, stacked along the channel dimension, are processed by the flow generator $f_{i+1}$ to produce the residual deformation field $\\Delta\\phi_{i+1} = f_{i+1}(\\hat{I}_{m_{i+1}}, \\hat{I}_{f_{i+1}})$. This residual field is then combined with the upsampled and scaled (by a factor of 2) deformation field $\\phi_{i+2}$ from level $i + 2$, resulting in the deformation field for level $i + 1$, given by $\\phi_{i+1} = \\Delta\\phi_{i+1} + \\phi_{i+2}$. For the $i$th level, the encoder feature maps $I_{m_i}$ and $I_{f_i}$, together with upsampled decoder"}, {"title": "2.3 Discontinuity-Preserving Deformable Registration", "content": "DDIR [9] is the first neural network solution to generate high-quality, discontinuity-preserving deformation fields, but it requires segmentation masks for both training and inference, linking deformation field quality to segmentation accuracy. Additionally, DDIR's use of masks increases computational load by splitting image pairs per anatomical region. MemWarp tackles these challenges by incorporating a memory network [21] that adaptively learns prototypical feature representations for different anatomical regions. Empirical evidence suggests that learning such prototypical features is not feasible when features from moving and fixed images are entangled, which led to the development of LapWarp.\nAnatomical Filters: Typically, the flow generator uses convolutional or self/cross-attention layers as in transformers, ending with a single convolutional filter of kernel size 1 to produce the deformation field. Our approach replaces this filter with dynamic filters [8, 26], adapting to the voxel context based on fixed feature maps. Given $x$ as a location vector within $\\Omega \\subset \\mathbb{R}^{H_i\\times W_i\\times D_i}$, let $\\hat{I}_{m_i}$ and $\\hat{I}_{f_i}$ represent the moving and fixed feature maps from the decoder"}, {"title": "Memory Addressing & Filter Generation:", "content": "Define $D \\in \\mathbb{R}^{N\\times N}$ as a diagonal matrix filled with ones and $g$ as the MLP operation. The memory matrix $M$ is derived as $M\\in \\mathbb{R}^{3C\\times N} = g(D)$. Utilizing the fixed feature map $\\hat{I}_{f_i} \\in \\mathbb{R}^{S_i\\times 3C}$ ($S_i = H_i \\times W_i \\times D_i$) as the query, memory addressing and filter generation proceed as follows:\n$$J_i = softmax(\\frac{{\\hat{I}_{f_i}}^T M}{||M||_{2,\\alpha1}}),$$$$w_i = reshape(J_i M^T),$$where the division by $||M||_{2,\\alpha1}$ applies $L_2$ normalization along the 1st axis of the tensor $M$, and the softmax is then applied along the 2nd axis of the tensor. With $w_i$ obtained, the deformation field is generated in accordance with Eq. (1). The reshape function transforms $w_i \\in \\mathbb{R}^{S\\times 3C}$ into $w_i \\in \\mathbb{R}^{S\\times 3\\times C}$."}, {"title": "Anatomical Region Loss:", "content": "The feature representation $\\hat{I}_{f_i}(x)$at pyramid level $i$ of the fixed image produces the memory-addressed $J_i \\in \\mathbb{R}^{S\\times N}$, which acts as a segmentation probabilities across $N$ regions. Across all pyramid levels, we apply Dice loss: $\\mathcal{L}_{rgn} = \\sum_{i=1}^n DSC(up(J_i), J_f) \\times \\lambda_1$, where $J_i$ is the network output, $J_f$ is the fixed segmentation mask from the dataset, and the $up$ function upsamples $J_i$ to match $J_f$'s resolution."}, {"title": "2.4 Loss function & Overall Framework", "content": "The composite loss function for MemWarp is formulated as:\n$$\\mathcal{L} = \\mathcal{L}_{sim}(I_f, I_m \\circ \\phi) + \\mathcal{L}_{dsc}(J_f, J_m \\circ \\phi) + \\lambda_1 \\mathcal{L}_{reg} + \\mathcal{L}_{rgn},$$with $\\mathcal{L}_{reg} = \\sum_{i=1}^n ||\\nabla u_i(x)||_2 (u_i(x) = \\phi_i(x) - x)$ and $\\lambda$ adjusting the smoothness regularization strength. The framework of MemWarp aligns with traditional registration frameworks like VoxelMorph but introduces three critical adjustments: 1) Moving and fixed images are combined along the batch dimension; 2) Flow generators, enhanced by memory networks, supplement a conventional Unet, yielding a gradually warped moving image for each decoder level; 3) Deep supervision [14] is employed on the memory-addressed tensors to encourage discontinuities across regions."}, {"title": "3 Experiments & Results", "content": "We evaluate MemWarp's effectiveness using the ACDC dataset [5], which includes 150 subjects. Each subject is provided with images from both End-diastole (ED) and End-systole (ES) phases alongside segmentation masks. For intra-subject registration, images from both ED to ES and ES to ED phases are required to be aligned, resulting in a total of 300 pairs ([100+50] \u00d7 2). Of these, 170 pairs are allocated for training, 30 for validation, and the remaining 100 for testing. The distribution is stratified to ensure subjects with various diseases are evenly represented across training, validation, and testing phases, with no overlap of subjects between training or validation and testing. All images undergo a min-max normalization to (0,1), are resampled to a voxel size of 1.8 \u00d7 1.8 \u00d7 10 mm and adjusted to a size of 128 x 128 \u00d7 16."}, {"title": "3.1 Implementation Details & Comparator Methods", "content": "Experiments use Python 3.7 and PyTorch 1.9.0 [19] on a machine equipped with an A100 GPU, and a 16-core CPU with 32GB RAM. Training employs the Adam optimizer with a learning rate of 4e-4, a batch size of 4, and cosine decay, running for 400 epochs. The Mean Square Error (MSE) serves as the similarity loss, complemented by L2 regularization on the spatial gradients of the deformation field ($\\lambda = 0.01$ in Eq. (4)), following [3, 10], with seven integration steps in the diffeomorphic layer. For MemWarp, a diffeomorphic layer is used at all pyramid levels except the first. Other models apply only MSE loss, Dice Loss, and regularization as outlined in Eq. (4)'s initial three terms.\nComparator Methods: MemWarp is benchmarked against top learning-based models such as VoxelMorph [3], TransMorph [7], LKU-Net [12], and Slicer Network [25], as well as DDIR [9] which is recognized for its discontinuity-preserving capabilities in cardiac registration. For DDIR, we employ the leading model nnFormer [27] for segmentation, achieving a Dice score of 90.15% on the test set. Slicer Network is assessed with an added guidance loss per its original configuration, while MemWarp and the other models are tested under a consistent experimental framework. We also include traditional methods like ANTs [2] and Demons [24]. While MemWarp is model-agnostic, we utilize the backbone of LKU-Net in this implementation.\nEvaluation Metrics: Aligned with standard practices [3,7], our evaluation employs the Dice coefficient and the 95th percentile Hausdorff Distance (HD95) for anatomical alignment evaluation. HD95 values are averaged across all anatomical structures for individual subjects. Additionally, the standard deviation of the logarithm of the Jacobian determinant (SDlogJ) is utilized to evaluate the quality of diffeomorphism."}, {"title": "3.2 Results & Analysis", "content": "Registration Accuracy: Table 1 illustrates that all methods produce smooth displacement fields with low SDlogJ values; however, increased SDlogJ alongside higher Dice scores indicates inherent discontinuities in cardiac alignments."}, {"title": "3.3 Discussions", "content": "Let $I_{m_i}$ and $I_{f_i}$ be the feature maps of moving and fixed images at pyramid level $i$. MemWarp operates under the assumption that the 'brightness' at any given location $p\\in \\Omega$ in $I_{f_i}$ remains constant compared to moving image [11], which is formulated as:\n$$\\nabla I_{f_i}(p) \\cdot u(p) = I_{m_i}(p) - I_{f_i}(p),$$where $\\nabla I_{f_i}(p) = \\langle \\frac{\\partial I_{f_i}}{\\partial x}(p), \\frac{\\partial I_{f_i}}{\\partial y}(p), \\frac{\\partial I_{f_i}}{\\partial z}(p) \\rangle$. Eq. (5) holds provided that the magnitude of $u(x)$ is less than one voxel. In the MemWarp framework, we employ an $n$-level Laplacian image pyramid to ensure $2^{(n-1)} > d_{max}$, where $d_{max}$ is the maximum possible displacement magnitude. This setup ensures that the coarsest level meets the conditions of Eq. (5), with each finer level processing a pre-warped moving image, thus maintaining the model's assumption throughout all levels.\nBased on the assumption, we've implemented two major modifications in neural network architecture to enhance registration performance. First, we decouple feature learning from flow estimation. Unlike traditional registration networks that combine moving and fixed images at the network's input, MemWarp employs a U-net for feature extraction and adds a simple convolution layer at each pyramid level to compute flow and performs warping, ensuring each level satisfies Eq. (5). Second, the smoothness requirement of Eq. (5) aligns well with features derived from segmentation networks, as segmentation can be regarded as the ultimate form of image harmonization [6]. This reinforces that effective segmentation features are equally beneficial for registration. Consequently, MemWarp"}, {"title": "4 Conclusions", "content": "In conclusion, MemWarp establishes a new benchmark for cardiac registration, outperforming existing methods by effectively preserving essential anatomical details and reducing artifacts. Its success hinges on two pivotal elements: the decoupling of moving and fixed feature maps via LapWarp, and the memory network's use of region loss for maintaining discontinuities across boundaries. MemWarp's effectiveness is validated by a significant 7.1% Dice score enhancement over the nearest semi-supervised competitors. Moreover, MemWarp uniquely addresses discontinuities without needing segmentation masks at inference, yet it can still generate segmentation masks comparable to top segmentation methods."}]}