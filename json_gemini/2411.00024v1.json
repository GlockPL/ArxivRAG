{"title": "A Perspective for Adapting Generalist AI to Specialized Medical AI Applications and Their Challenges", "authors": ["Zifeng Wang", "Hanyin Wang", "Benjamin Danek", "Ying Li", "Christina Mack", "Hoifung Poon", "Yajuan Wang", "Pranav Rajpurkar", "Jimeng Sun"], "abstract": "The integration of Large Language Models (LLMs) into medical applications has sparked widespread interest across the healthcare industry, from drug discovery and development to clinical decision support, assisting telemedicine, medical devices, and healthcare insurance applications. This perspective paper aims to discuss the inner workings of building LLM-powered medical AI applications and introduces a comprehensive framework for their development. We review existing literature and outline the unique challenges of applying LLMs in specialized medical contexts. Additionally, we introduce a three-step framework to organize medical LLM research activities: 1) Modeling: breaking down complex medical workflows into manageable steps for developing medical-specific models; 2) Optimization: optimizing the model performance with crafted prompts and integrating external knowledge and tools, and 3) System engineering: decomposing complex tasks into subtasks and leveraging human expertise for building medical AI applications. Furthermore, we offer a detailed use case playbook that describes various LLM-powered medical AI applications, such as optimizing clinical trial design, enhancing clinical decision support, and advancing medical imaging analysis. Finally, we discuss various challenges and considerations for building medical AI applications with LLMs, such as handling hallucination issues, data ownership and compliance, privacy, intellectual property considerations, compute cost, sustainability issues, and responsible AI requirements.", "sections": [{"title": "Introduction", "content": "Artificial intelligence (AI) is increasingly being integrated into various medical tasks, including clinical risk prediction,\u00b9 medical image understanding, 2 and synthetic patient records generation.3 Typically, these models are designed for specific tasks and will struggle with unfamiliar tasks or out-of-distribution data.4 Large language models (LLMs) are foundation AI models characterized by their extensive training data and enormous model scale. Unlike traditional AI models, LLMs demonstrate an emergent capability in language understanding and the ability to tackle new tasks through in-context learning. 5 For example, we can teach LLMs to conduct a new task by providing the text explanation of the task (or \"prompts\"), the input and output protocols, and several examples. This adaptability has sparked interest in employing generalist LLMs to medical AI applications such as chatbots for outpatient reception. Contrary to the common belief that generalist LLMs will excel in many fields, we advocate that domain-specific AI adaptations for medicine are more effective and safe. This paper will overview how various adaptation strategies can be developed for medical AI applications and the associated trade-offs.\nGeneralist LLMs such as ChatGPT can support broad tasks but may underperform in specialized domains. One notable drawback is the occurrence of \"hallucinations,\" which are fabricated facts that look plausible yet incorrect. High-stakes medical applications such as patient-facing diagnosis tools are especially vulnerable to such inaccurate information. 10 In response, adaptation methods in LLM for medicine have thrived, focusing on enhancing LLMs' domain-specific capabilities (Fig. 1b). They include finetuning LLMs on medical data, 11 adding relevant medical information to the prompts for LLMs via retrieval-augmented generation (RAG),12 and equipping LLMs with external tools to building AI agents achieving autonomous planning and task execution. 13 With the increasing practice in developing LLM-based AI applications, it is becoming evident that cutting-edge performance is increasingly driven by the mixture of these adaptations14 and systematic engineering of multiple AI components. 15\nWe present a systematic overview of adaptation methods and organize them in a framework for developing LLM-based medical AI applications. Fig. 1 outlines various adaptation methods and high-level strategies, including:\n\u2022 Model development: This includes techniques like pretraining, where medical knowledge is injected into generic models via continual pretraining on medical datasets, 16 and finetuning, which ensures that the model's outputs are consistent with domain knowledge and human preferences. 17\n\u2022 Model optimization: Strategies such as prompt optimization enhance the relevance and accuracy of model responses, ,14 while retrieval-augmentation generation (RAG) utilizes external data to create richer, more informed prompts. 12 More advanced operations include building autonomous AI agents 18 and chaining multiple AI modules to enable complex workflows. 19\n\u2022 System engineering: We can optimize the performance of medical AI by taking a system engineering approach. This includes subtasking by assigning clearly defined, narrow-scope tasks to each system component to improve reliability, 20 involving human-in-the-loop to boost oversight and refinement, 21 result verification for maintaining accuracy and robustness,22 and interconnected AI agents focusing different aspects of the task for improving medical conversational reasoning. 23\nNext, we describe this framework for developing medical AI applications in detail, focusing on diverse medical AI use cases. We will end by describing the associated challenges and opportunities for further development of LLM-based medical AI applications."}, {"title": "Adapting Large Language Models for Medical AI", "content": "This section will describe different strategies for adapting LLMs to build medical AI applications."}, {"title": "Model development: building medical-specific LLMs", "content": "Pretraining Generic LLMs such as ChatGPT are trained on vast, diverse datasets to develop a broad understanding of language.5 A continual pretraining of generic LLMs on medical data, such as medical publications, clinical notes, and electronic health records (EHRs), can enhance LLMs' alignment in medical languages. For example, MEDITRON is based on the open-source LLaMA model,24 further trained on medical data including PubMed articles and medical guidelines. It performs comparably to larger generalist models such as GPT-425 in medical question answering. Another model, Panacea, shows the benefit of LLMs in clinical trial search, design, and patient recruitment via a continual pretraining of generic LLMs on clinical trial documents, including trial protocols and trial-related publications. 16\nInstruction finetuning Instead of pretaining with medical data without specific task supervision, an LLM can also learn from paired custom queries and their expected responses to perform multiple target tasks. This training process is known as instruction finetuning.26 For example, when PaLM, a 540-billion parameter LLM, underwent instruction tuning, it resulted in MedPaLM, which achieved 67.6% accuracy on US Medical Licensing Exam-style questions.11\nAnother important finetuning objective is alignment, which ensures LLM outputs are consistent with human preferences with high quality and safety. One prominent method for alignment is Reinforcement Learning from Human Feedback (RLHF), which was instrumental in developing ChatGPT.27 RLHF starts with training a reward model based on human feedback, which then steers the LLM toward responses that align with human values and expectations using reinforcement learning. An example of a medical application of alignment is LLaMA-Clinic, where multiple clinicians provide feedback to guide the models for generating high-quality clinical notes. 17"}, {"title": "Model optimization: strategies for improving LLM performance", "content": "Prompt optimization Prompt indicates the user inputs to LLMs, which can include the task description, the expected input and output formats, and some input/output examples. For example, this input \"Your task is to summarize the input clinical note. Please adhere to these summarization standards: [...list of criteria]. Refer to these examples: [...list of examples]. Keep in mind: [...list of important hints],\" can guide LLMs towards generating the summary of patient notes. This practice leverages the principle of in-context learning, where LLMs adapt to new tasks based on the input prompts without additional training.5 Research shows that the structure and content of the prompt significantly affect the model's performance. For instance, chain-of-thought prompting28 encourages LLMs to engage in multiple steps of reasoning and self-reflection, thereby enhancing the output quality. Another strategy involves ensembling, 29, 30 where outputs derived from multiple prompts are synthesized to produce a final, more robust response. In the medical domain, MedPrompt14 has demonstrated its ability to outperform domain-tuned LLMs by combining multiple prompting techniques. Additionally, TrialGPT31 effectively adapts LLMs to match patient notes to the eligibility criteria of a clinical trial through prompting.\nHandcrafted prompts are highly dependent on domain knowledge and trial-and-error, but they can still perform suboptimally and cause reliability issues in applications. Techniques such as automatic prompt generation32 and optimization33 were hence proposed. These approaches can transform the adaptation of LLMs for medical tasks into a more structured machine-learning task. For example, requesting an LLM to summarize clinical notes could start with a simple prompt like \"Summarize the input clinical note.\" Using a collection of example notes and expert-written summaries, automatic summarization evaluation metrics can serve as the target for iterative prompt refinement. The prompt can ultimately evolve into a more advanced prompt consisting of professional task description, representative examples, and clear output format requirement description."}, {"title": "System engineering: developing compound medical AI systems", "content": "In addition to breaking down tasks into multiple steps, building medical AI systems requires thoughtful design of modules to execute these substeps effectively. Equally important is the orchestration of these modules into a cohesive pipeline, a process we refer to as subtasking. We split the substaking development into two levels: modules and pipelines.\n\u2022 Modules are crafted using LLM operation tools (e.g., prompt optimization), typically featuring a specialized prompt and designed for interaction with other system components."}, {"title": "Use cases of LLMs for medical AI applications", "content": "Table 1 lists a a number of studies that have explored adapting LLMs to medical AI tasks. In this section, we review a few example use cases, reinterpreting them through the lens of the proposed framework. Additionally, we discuss some potential improvements of those use cases.\nClinical note generation Creating clinical notes is a routine task for physicians. These notes record the patient's medical history, present conditions, and treatment plans."}, {"title": "Opportunities and challenges in LLMs for medical \u0391\u0399", "content": "Multimodality Multimodal capabilities represent a key growth direction for LLMs in medical applications. A patient journey naturally comprises many information-rich modalities such as lab tests, imaging, genomics, etc. While generalist AI has demonstrated amazing capabilities in understanding and reasoning with biomedical text (e.g., MedPrompt95), competence gaps abound in the multimodal space, with vision-language model being a prominent example. E.g., GPT-4V performs poorly on identifying key findings from chest X-rays, even compared to much smaller domain-specific models (e.g., LLaVA-Rad96). Efficiently bridging such multimodal competency gaps thus represents a key growth frontier for medical AI. Progress is particularly fast in biomedical imaging, from harnessing public image-text data (e.g., BiomedCLIP,97 PLIP,98 CONCH99) to efficiently training vision-language models (e.g., LLaVA-Med100) to learn text-guided image generation and segmentation (e.g., BiomedJourney, 101 RoentGen, 102 BiomedParse). While promising, challenges abound in multimodal medical AI, from pretraining in challenging modalities (e.g., GigaPath103) to multimodal reasoning for precision health. Much remains to be done.\nInterpretability While LLMs hold significant potential for enhancing medical tasks, their interpretability remains a critical challenge. As deep learning models, LLMs often function as black boxes, making it difficult to trace the reasoning behind specific outputs. This lack of transparency can hinder clinical decision-making and raise concerns about accountability. To address these issues, developing explainable AI methodologies is essential for gaining a deeper understanding of LLMs. 104 At present, techniques such as chain-of-thought and program-of-thought can be employed to reveal the step-by-step reasoning and operational processes behind LLM outputs, improving their interpretability in medical applications. 28, 105\nHallucination The risk of \"hallucinations\" in LLM outputs, where the model generates plausible-sounding but incorrect or fabricated information, has been widely docu-"}, {"title": "Conclusion", "content": "Generalist AI models have the potential to revolutionize the medical field. A range of adaptation methods have been proposed to tailor these models for specialized applications (Table 1). In this review, we documented existing adaptation strategies and organized them within a framework designed to optimize the performance of medical AI applications from a systems engineering perspective. Our analysis and discussion of published use cases demonstrate the benefits of this framework as a systematic approach to developing and optimizing LLM-based medical AI. However, we also recognize the potential challenges that arise as the complexity of medical AI applications increases, particularly in monitoring, validation, and maintenance. Future research and development are essential to solidify the utility of LLM-driven medical AI applications, enhance patient outcomes, democratize access to quality healthcare, and reduce the workload on medical professionals."}]}