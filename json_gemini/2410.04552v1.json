{"title": "Modeling Social Media Recommendation Impacts Using Academic Networks: A Graph Neural Network Approach", "authors": ["Sabrina Guidotti", "Gregor Donabauer", "Simone Somazzi", "Udo Kruschwitz", "Davide Taibi", "Dimitri Ognibene"], "abstract": "The widespread use of social media has highlighted potential negative impacts on society and individuals, largely driven by recommendation algorithms that shape user behavior and social dynamics. Understanding these algorithms is essential but challenging due to the complex, distributed nature of social media networks as well as limited access to real-world data. This study proposes to use academic social networks as a proxy for investigating recommendation systems in social media. By employing Graph Neural Networks (GNNs), we develop a model that separates the prediction of academic infosphere from behavior prediction, allowing us to simulate recommender-generated infospheres and assess the model's performance in predicting future co-authorships. Our approach aims to improve our understanding of recommendation systems' roles and social networks modeling. To support the reproducibility of our work we publicly make available our implementations: https://github.com/DimNeuroLab/academic_network_project", "sections": [{"title": "1 Introduction", "content": "The widespread use of social media has revealed various aspects that may negatively affect both society and individuals using such platforms [2,10,17]. Social networks are complex systems where user interactions are heavily influenced by recommendation algorithms, which shape user behavior and, in turn, the broader social impact [20]. Examples for algorithmic threats on social media include filter bubbles [19] and echo chambers [10]. Understanding the underlying mechanisms is crucial for mitigating negative effects and promoting societal well-being [20]. However, studying these mechanisms is challenging [4,6] due to the distributed, heterogeneous, and large-scale nature of social media networks [7,5] as well as a lack of access to real-world data, making it difficult to align theoretical models with real-world dynamics."}, {"title": "2 Related Work", "content": "Much research in recommender systems focuses on the broader social and behavioral impact. Studies for example showed that the presentation of recommendations can significantly influence user satisfaction [18] or that social explanations can affect user interactions but do not always improve satisfaction with the content [22]. Recommenders are also known to influence consumer preferences through mechanisms like the anchoring effect when users trust the system [1].\nSimulations of recommenders can help to reveal effects of such systems. They have for example investigated how repeated interactions can amplify biases, such as popularity bias and filter bubbles, impacting long-term user behavior [27] or that personalized recommendations can increase commonality among users leading to increased consumption and a more homogeneous product mix [8,12].\nFor example, addressing biases in recommenders is crucial, as they can lead to discrepancies between offline evaluations and online performance, negatively affecting user trust which requires efforts in debiasing such systems [3] and understanding how biases propagate through user profiles can help in developing more accurate and fair recommendation algorithms [16].\nBuilding on work that has used academic networks in tasks like web user profiling [23], topic expertise search [25] or social network extraction of academics [24], we want to use such data to improve understanding how different simulated infospheres influence learning of user behaviour."}, {"title": "3 Methodology", "content": "Our approach involves three key components: (1) characterizing the history of the agents' behavior within the social network, (2) simulating a recommender system by integrating infosphere into the network, and (3) learning models on these networks to evaluate how different infospheres influence the model's prediction performance of the agents' future behavior."}, {"title": "3.1 Agent History and Infosphere Simulation", "content": "For modelling the authors' History we track the papers they have written, the co-authors they have collaborated with, and the topics they have worked on. This history is represented as a time-dependent graph Gy, containing all observable information up to year y. Each graph Gy includes three types of nodes: author, paper, and topic, as well as three types of edges: (author, writes, paper), (paper, deals_with, topic), and (paper, cites, paper). Paper nodes are characterized by the year of publication. All other nodes in the graph are initialized with random embeddings which are jointly learnt during model training.\nWe then introduce the concept of Infosphere, representing the information an author might encounter through a recommender system or other algorithmic components. Such systems access content and authors beyond the author's direct and local experience, with suggestions guided by the author's prior interactions rather than random selection. Our concept of infosphere is related to the idea of impressions, which are defined as the recommendations presented to the user along with their corresponding interactions [21]. Although difficult to model due to limited knowledge of the underlying algorithms, we simulate the infosphere with minimal assumptions, ensuring that it includes both information the author has definitely encountered and what they might have encountered through similar processes. We use information from subsequent years' graphs to derive a set of paths that represent the author's connections with nodes in their history as they appear in the following year within the current year's graph. By adding noise based on a set of probabilities which determine whether to follow existing paths or switch directions we aim to make the simulation more realistic. This approach allows us to develop models that keep user and recommender modeling separate, so that the recommenders can pursue different objectives. By creating a minimal infosphere, we develop a more robust and general model of authors, which can be used to refine recommender systems based on principles such as content similarity. For comparison, we also generated alternative infospheres: one consisting of the n most popular papers in a given year y, and another focusing on then most popular papers within the m most-used topics by an author x in that year."}, {"title": "3.2 Seedgraph and Expansion", "content": "Our infosphere calculation is based on a seedgraph, a directed graph composed of paths associated with each author. Each path traces the shortest connection from an element in the author's history in year y + 1 back to the graph in year y.\nWe first initialize a \"frontier-seeds\" dictionary with the author's publications and related information, then iteratively expand both the author node and the \"frontier-seeds\" by 1-hop. A \"compare-frontiers\" function identifies paths when overlaps occur. The process continues until all paths are identified, allowing efficient seedgraph construction by merging node lists when common nodes are found.\nTo achieve realistic expansion, the seedgraph is extended with plausible alternative paths. For better understanding, nodes can be interpreted as colored as white, orange, or green, where orange nodes belong to the seed graph, green nodes are added during expansion, and white nodes belong to neither. The algorithm requires several inputs: the author-node, the full-graph, the seed graph, and parameters (p1, p2, p3, f):\np1: Probability of following a path of orange nodes (seedgraph). Higher values extend the original infosphere.\np2: Probability of following a path of green nodes (expanded graph). Higher values create paths similar to the seedgraph.\np3: Probability of returning to the author node. Higher values concentrate noise near the author node.\nf: Number of new nodes added per seedgraph path (2, 4, or 6)."}, {"title": "3.3 Behaviour Prediction", "content": "To assess the impact of the simulated recommender via infosphere on the prediction of future actions of agents (authors) within the social network, we evaluate how the configurations described previously affect a model's ability to forecast future co-authorship collaborations.\nWe model the task of co-authorship prediction as a link prediction problem and learn a GNN that predicts future co-authorships that do not yet exist as edges in the current graph. To do this, we add co-author edges derived by multi-hop walks from author nodes across the existing heterogeneous graph. In both scenarios - predicting links within a specific year or forecasting future connections - we also add and sample negative examples of edges at a ratio of 1:1."}, {"title": "4 Experiments", "content": ""}, {"title": "4.1 Dataset", "content": "We use the DBLP-Citation-network v14 dataset [26] from AMiner, which includes data from sources like DBLP, ACM, and MAG to provide a comprehensive overview of academic publications and their citation relationships. We selected this dataset as it is the most up-to-date dataset available (released in 2023) and offers a reasonable number of nodes and edges making it a good fit for our experiments. Specifically, it contains 5,259,858 paper nodes and 36,630,661"}, {"title": "4.2 Infosphere Parameters", "content": "We evaluate different parameters for creating the infosphere as described previously. When reporting results based on these combinations we refer to the run ids assigned here.\ntrial0 Random Infosphere\ntrial1 (p1=0.5; p2=0.5; p3=0.5; f=2)\ntrial2 (p1=0.75; p2=0.5; p3=0.5; f=2)\ntrial3 (p1=0.5; p2=0.75; p3=0.5; f=2)\ntrial4 (p1=0.5; p2=0.5; p3=0.75; f=2)\ntrial5 (p1=0.25; p2=0.75; p3=0.25; f=2)"}, {"title": "4.3 Model and Training", "content": "For the learning process, we use an encoder-decoder network. The encoder consists of a heterogeneous Graph Neural Network with two consecutive graph convolution layers to encode the input graphs and generate expressive node representations. In our experiments we evaluated GraphSAGE [11] and Heterogeneous Graph Transformer (HGT) [13] as encoder layers. While HGT uses Transformer blocks for neighborhood aggregation we vary the aggregation strategies for GraphSAGE. The decoder is a simple two-layer feed-forward neural network that classifies node pairs as either connected (existing edge/link) or not, making the task as a binary classification problem. The model is trained end-to-end using binary cross-entropy loss and the Adam optimizer. We run training for 500 epochs with early stopping and a patience of 10, the batch-size is set to 1024 and the the learning rate to 0.00001."}, {"title": "5 Results", "content": "Table 1 summarizes the results from our experiments on predicting co-authors using various model setups and infosphere configurations. We achieved an accuracy of 78-80% when predicting co-authors without any infosphere. When incorporating the infosphere generated by our methods, performance improved, with accuracy reaching around 88%, particularly in setups without seedgraph expansions. Testing different aggregation functions (sum, min, mean, max) yielded minimal differences in outcomes.\nWe also evaluated an alternative infosphere based on the most popular papers (10 and 50). This approach performed worse than using the future infosphere and was comparable to or worse than having no infosphere, likely due to the noise introduced by less relevant papers. The min aggregation function slightly improved results but remained close to those without an infosphere."}, {"title": "6 Conclusion", "content": "In this study, we successfully demonstrated how simulating recommenders through infospheres helps understanding user behavior when based on academic network data. Our analysis showed that the infosphere most benefits predictions of new edges that are not present in the history. These findings can help to improve the understanding of how recommender mechanisms influence communities, especially those currently exposed to negative impacts in social networks."}]}