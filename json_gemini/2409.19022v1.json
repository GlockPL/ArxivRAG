{"title": "Application of AI-based Models for Online Fraud Detection and Analysis", "authors": ["Antonis Papasavva", "Shane Johnson", "Ed Lowther", "Samantha Lundrigan", "Enrico Mariconti", "Anna Markovska", "Nilufer Tuptuk"], "abstract": "Background: Fraud is a prevalent offence that extends beyond financial loss, impacting victims emotionally, psychologically, and physically. The advancements in online communication technologies, allow for online fraud to thrive in this vast network, with fraudsters increasingly using these channels for deception. With the progression of technologies like Generative Artificial Intelligence (GenAI), there is a growing concern that fraud will increase and scale, using these advanced methods such as deep-fakes in phishing campaigns. However, the application of Al in detecting and analyzing online fraud remains understudied. This review addresses this gap by investigating Al's role in analyzing online fraud using text data.\nMethods: We conducted a Systematic Literature Review (SLR) on Al and Natural Language Processing (NLP) techniques for online fraud detection. The review adhered to the PRISMA-ScR protocol, with eligibility criteria including language, publication type, relevance to online fraud, use of text data, and Al methodologies. Out of 2, 457 academic records screened, 350 met our eligibility criteria, and 223 were analyzed and included herein.\nResults: We report the state-of-the-art NLP techniques used to analyse various online fraud categories; the data sources used for training the NLP models; the NLP algorithms and models built; and the performance metrics employed for model evaluation. We find that the current state of research on online fraud is broken into the various scam activities that take place, and more specifically, we identify 16 different frauds that researchers focus on. Finally, we present the latest and best performing Al methods used towards detecting online scam and fraud activities.\nConclusions: This SLR enhances the academic understanding of Al-based detection methods for online fraud and offers insights for policymakers, law enforcement, and businesses on safeguarding against such activities. We conclude that focusing on specific scams lacks generalization, as multiple models are required for different fraud types. Furthermore, the evolving nature of scams limits the effectiveness of models trained on outdated data. We also identify issues in data limitation or training bias reporting from researchers, along with issues on model performance reporting, with some studies selectively presenting metrics, leading to potential biases in model evaluation.", "sections": [{"title": "Background", "content": "Online fraud has emerged as one of the most pervasive\nand challenging threats in the digital age affecting in-\ndividuals of all ages, businesses of different sizes, and\ngovernments. Defined broadly, online fraud is an um-\nbrella term that involves acts of deception or deliberate"}, {"title": "1 Online Fraud and Al", "content": "We now discuss online fraud and various AI method-\nologies in detail for further reader information. Online\nfraud refers to any deliberate act of deception con-\nducted over the Internet to obtain an unlawful or un-\nfair gain. It involves exploiting online platforms, ser-\nvices, and technologies to deceive individuals or organ-\nisations for financial, personal, or material gain. Online\nfraud can take many forms, each characterised by the\nmethod of deception and the medium used to perpe-\ntrate the fraud."}, {"title": "1.1 Fraud Categories", "content": "The list of online fraud activities is extensive and con-\nstantly evolving with new types or sub-types emerging.\nDeveloping a comprehensive taxonomy or classification\nfor all online fraud activities requires special attention,\nwhich is beyond scope of this work. Below we outline\nsome of the well-known online fraud types.\nPhishing is the process where fraudsters imperson-\nate representatives of legitimate organisations or ac-\nquaintances of the targeted victim to trick them into\nproviding personal information such as usernames,\npasswords, credit card details, or bank account de-\ntails. This activity can be done through various\nmediums, like email, phone calls (aka Vishing), SMS\n(aka Smishing), and any other way of online com-\nmunication. There are various phishing scams that\nsurfaced over the years, including the Royal Mail\nscam [14], banking scams [15], HMRC scams [16],\nand many others. Notably, phishing scams often\ninclude deceptive web addresses created by cyber-\ncriminals to trick victims into believing they are vis-\niting legitimate websites. The primary goal of these\nURLs is to steal personal data including usernames,\npasswords and credit card details for financial gain.\nFake Reviews are deceptive or fraudulent reviews\ncreated to mislead potential customers about the\nquality, reliability, or legitimacy of a product, ser-\nvice, or app. On fraudulent e-commerce websites and\napp stores, fake reviews play a crucial role in trick-\ning victims into trusting and using fraudulent apps\nor purchasing substandard or non-existent products.\nThis leads to potential victims trusting fraudulent"}, {"title": "1.2 Al techniques", "content": "This study investigates AI-based techniques for pro-\ncessing unstructured text data to analyse fraud. Much\nof this text data, such as news articles, research papers,\ngovernment reports, books, social media posts (such\nas tweets and Facebook comments), communications\n(such as emails, SMS messages, and chat logs), and\nweb content (such as reviews on online marketplaces,\ntravel and hospitality platforms, and comments on\nvideo sharing platforms), is inherently unstructured.\nStatista reported the global data created, captured,\ncopied, and consumed is 64.2 zettabytes in 2020, and it\nis expected to exceed 180 zettabytes by 2025 [31]. With\neach new digital platform or communication channel,\nthis data is increasing. Most of this created data is\nunstructured text data that provides opportunities for\nunderstanding human behaviour, habits, opinions and\nexperiences. It contains information about users' expe-\nriences, events, themes, opinions and sentiments that\ncan be important for deriving meaningful insight from\ntheir experience related to fraudulent activities. Man-\nual traditional data analysis techniques like keyword\nsearches and coding of themes, are often limited and\nunachievable to extract meaningful insights, making\nadvanced computer-driven automated techniques nec-\nessary.\nHowever, this data often demonstrates significant\nchallenges due to the diversity of natural (human) lan-\nguage. This includes dealing with noise, which includes\nirrelevant data, a wide array of linguistic variations"}, {"title": "Model evaluation", "content": "The performance of the model\nneeds to be evaluated. In the case of supervised mod-\nelling, this will involve measuring the performance\nof the model on the test data. The classic supervised\nmachine learning algorithms can be evaluated using\nperformance metrics such as confusion matrix (Fig-\nure 2), accuracy, precision, recall, F1-score, sensi-\ntivity, specificity, Receiver Operating Characteristic\n(ROC) curve, and the Area Under the Curve (AUC)\ncurve:\nAccuracy = $\\frac{TP+TN}{TP+TN+FP+ FN}$\nPrecision = $\\frac{TP}{TP + FP}$\nRecall = $\\frac{TP}{TP+FN}$\nF1 score = $\\frac{2* Precision * Recall}{Precision + Recall}$\nWhere:\nTrue Positives (TP): The model correctly predicts\npositive class (e.g., those that were classified as\nscam.)\nTrue Negatives (TN): The model correctly predicts\nnegative class (e.g., those classified as not-scam).\nFalse Positives (FP): The model incorrectly predicts\nthe positive class but it is not (e.g. not-scam is pre-\ndicted as a scam)."}, {"title": "1.3 Advanced NLP techniques", "content": "This section provides a brief introduction to advanced\nNLP techniques, aiming to familiarise the reader with\nthese concepts as they are later referred to during the\nSLR findings.\nWord embeddings is a technique in NLP that encodes\nwords as vectors of real numbers to capture their simi-\nlarities. Words that are closer together in the vector\nspace are expected to have similar meanings or re-\nlationships. Two of the widely used word embedding\ntechniques are Word2Vec and GloVe. Word2Vec uses\na simple neural network trained on large text datasets\niteratively to predict either context words or target\nwords. Word2Vec uses two approaches [32]: Continu-\nous Bag of Words (CBOW) predicts the target word"}, {"title": "1.4 Research approach", "content": "Although there are some literature reviews related to\nthe application of AI for fraud and crime, to our best\nknowledge there are currently no SLRs that attempt to\nunderstand the state-of-the-art towards detecting on-\nline fraud in general. Overall, the literature reviews\nthat we found discuss the state-of-the art towards\ndetecting specific online fraud or scams, e.g., credit\ncard fraud alone. In this work, we aim to understand\nwhether there are universal AI methodologies that at-\ntempt to detect online fraud, focusing on textual data."}, {"title": "2 Systematic Review", "content": "Systematic reviews differ from traditional literature re-\nviews as they aim to identify all relevant studies that\naddress a set of research questions using a methodol-\nogy that is structured and can be replicated [37]."}, {"title": "2.1 Methods", "content": "The following methodology was employed to conduct\nthe SLR, and address the selection process for identi-\nfying relevant publications and to avoid biases."}, {"title": "2.1.1 Protocol", "content": "For this SLR we follow the Preferred Reporting Items\nfor Systematic Reviews and Meta-Analysis extensions\nfor Scoping Reviews (PRISMA-SCR), as proposed by\nMoher et al. [38]."}, {"title": "2.1.2 Eligibility", "content": "This review focuses on studies that use AI-based mod-\nels, specifically NLP models, including Machine Learn-\ning (ML) and Deep Learning (DL) techniques using\ntext data. For example, studies that employ AI to de-\ntect fraudulent bank accounts, fraudulent credit card\ntransactions, or fraudulent networks of users online,\nare not to be included.\nTo be considered for inclusion in the SLR, we used the\nfollowing eligibility criteria:\nPeer-Reviewed Studies: We focused on peer-\nreviewed studies published in English between 2019\nand March 2024. Our search was restricted to aca-\ndemic records found in journals and conference\nproceedings. We excluded theses, legal documents,\npatents, and citations from these studies.\nGrey Literature: To capture the latest AI-based\nmodels, we also included grey literature, specifically\npre-prints from ArXiv published in 2023 that have\nnot yet been incorporated into conference proceed-\nings or book chapters.\nSearch Strategy: shows the search strings\nused to detect related literature in ACM Library,\nProQuest, Web of Science, IEEE Xplore, ArXiv, and\nGoogle Scholar. The authors finalized this string af-\nter trying various searches in these libraries.\nScope and Focus: Studies must address fraud per-\nformed online and use AI-based methodologies for\nanalysing online fraudulent activities. The focus is\non studies using textual data, whether from scam-\nmers, victims, or victim reports, to understand, de-\ntect, or analyse online fraud activities. Our goal\nis to understand what is the state-of-the-art on\nmodels that are designed to prevent and detecting\nscams (tricking the victim) before the victim gets\ndefrauded which will lead them to monetary losses.\nStudies that analyse money transactions, credit card\ntransactions, and cryptocurrency transactions are\nexcluded, from this review, as they do not use text\ndata.\nAI-Methodology: Papers must include a method-\nology section or a similar section where the authors\ndiscuss their AI implementation and fine-tuning\nalong with the accuracy of their model. Finally, we\nconsider studies published after 2019.\nPublication timeframe: Papers published be-\ntween 2019 and March 2024 are included in this\nreview. This period was selected to manage the over-\nwhelmingly large volume of papers on online fraud\nand to align with our available resources. Also, we\nbelieve that studies conducted before 2019 are less\nlikely to reflect recent advancements in AI methods.\nGiven the rapid evolution of AI-based models, fo-\ncusing on the 2019-March 2024 period ensures the"}, {"title": "2.1.3 Data extraction", "content": "Next, the authors agreed on the data that should be\nextracted from the included studies. The task of ex-\ntracting data was carried out by only one of the three\nreviewers. This was deemed sufficient since the re-\nviewer's role involved extracting the required details\nfrom the papers, and it was unnecessary for a second\nreviewer to check accuracy. The only aspect of the data\nextraction that the reviewer had to conceptualize was\nthe specific Fraud Type analyzed by the study under\nquestion. For example, if a study is analyzing Phishing\nURLs, then it is labelled as Phishing URLs.\nNot all papers explicitly specified the type of fraud\nthey were analysing. Due to the diversity of scams,\nthere is no agreed way of labelling fraud types. As as\nresult, we used an umbrella term to categorise them.\nFor example, online scam campaigns, made by bot\nusers to advertise fraudulent phishing URLs include\nfake users and phishing URLs fraud analysis, hence\nwe agreed to label papers of broad online scam cam-\npaigns as social media scams.\nTo ease the representation of our findings, we do not\nclassify a paper with more than one fraud type. More\nspecifically, the reviewer had to resort to the main goal\nof the paper towards annotating the kind of fraud it\nanalyzes. For example, if a paper used phishing emails\nto extract phishing URLs towards detecting phishing\nURLs, then that paper would be labelled as Phishing\nURLs, as that is the main goal of the study. The fi-\nnal version of the data extracted from each record is\ndepicted in Table 2, along with relevant examples."}, {"title": "3 Results", "content": "The PRISMA-SCR flow diagram in Figure 3 sum-\nmarises the study selection process for the two aca-\ndemic searches. 2,617 stuides were identified for eli-\ngibility screening. The ACM Digital Library returned\n389 documents, IEEE Xplore returned 712 documents,\nWeb of Science returned 253 documents, ProQuest re-\nturned 783 documents, Google Scholar returned 399\ndocuments, and ArXiv returned 47 documents. An ad-\nditional 15 papers were recommended by the experts\nin the area. After removing duplicates, 2, 457 papers\nremained for further review.\nAt this stage, 10% of these papers were selected\n(N = 242) for Inter-Rater Reliability, to calculate the\nmulti-annotator agreement between the three annota-\ntors of this review. The Fleiss Kappa score between\nall three annotators was 0.83, indicating almost per-\nfect agreement. The Cohen Kappa Agreement was also"}, {"title": "3.2 Types of Online Fraud", "content": "shows the types of fraud analyzed in the full-\ntext papers that were included in the qualitative analy-\nsis. The reviewer of these studies manually coded each\npaper with the scam type that the study is focusing on,\nbased on the title, abstract, and methodology of the\nstudies. The majority of studies that were included for\nqualitative analysis focus on phishing detection, with\nabout a third (29%) of the studies focusing on detect-\ning phishing URLs online (N = 64). More specifically,\nthese works tackle the problem of automatically de-\ntecting whether a given URL is likely to be fraudu-\nlent. A large number of papers were related to detect-\ning phishing emails (N = 29), followed by studies on\nSMS phishing detection (N = 20). Other studies on\nphishing include phone call transcripts towards under-\nstanding and detecting voice call phishing (N = 12)\nand a small number of studies attempt to understand\nphishing methods via victim reports (N = 4).\nMoving on to other types of fraud, we found many\nstudies that attempted to detect fake reviews on vari-\nous platforms like Google Play Store, Apple App Store,\nYelp, and TripAdvisor (N = 23). Another widely stud-\nied scam focus was recruitment fraud (N = 20). We\nalso found a number of studies that employed AI tech-\nniques to detect fake accounts on Facebook, Insta-\ngram, and Twitter (N = 18).\nA few studies used Generative AI (GenAI) to gain a\nbetter understanding of some of the latest methods of\nphishing and other fraud types. GenAI represents cases\nwhere advanced LLMs are misused towards social en-\ngineering attacks. GenAI models, have revolutionised"}, {"title": "4 Summary of Findings", "content": "We now provide a summary of our findings, categorized\nper fraud activity analyzed within the papers that are\nincluded in our SLR for qualitative analysis."}, {"title": "4.1 Data Sources", "content": "First, we report the most popular data sources used\nand the datasets analyzed.\nPhishing URLs. We start with understanding the\npreferable data sources and methodologies employed\nfor the analysis and detection of Phishing URLs, as it\nis the most popular scam type category we detected in\nour SLR. In total, we analyze the data sources and de-\ntection methodologies of the identified 63 papers that\nattempt to tackle this issue. summarizes the\ndata sources and methodologies used to detect Phish-\ning URLs, as found in the literature.\nFirst, we find that researchers used various websites\nthat offer information on URLs for the analysis of ma-\nlicious and legitimate domains. This information may\nbe webpage rankings (how trusted the webpage is),\nphishing reports, and historical data. By far, the most\npopular data source used was PhishTank,[2] a website"}, {"title": "4.2 Methodologies employed", "content": "We now discuss the most popular AI and NLP method-\nologies employed per online frayd type.\nPhishing URLs. We find that the records included\nin our SLR attempt to automatically detect phish-\ning URLs using a variety of NLP and AI methodolo-\ngies. These models included classic supervised machine\nlearning algorithms such as Naive Bayes (NB), Ran-\ndom Forest (RF), Decision Tree (DT), Support Vector\nMachines (SVM), XGBoost (Extreme Gradient Boost-\ning), KNN (k-Nearest Neighbors), as well as Artificial\nNeural Networks (ANN) and more advanced in deep\nlearning such as Long Short-Term Memory (LSTM)\nand Convolutional Neural Network (CNN). LSTMs\nare a type of Recurrent Neural Network (RNN) de-\nsigned to capture long-dependencies in sequential data,\nmaking them suitable for handling and predicting se-\nquences of text. On the other hand, CNNs aim to iden-\ntify key features in the text by capturing local pat-\nterns. These models were developed for binary classi-\nfication tasks, whether a URL is fraudulent or not.\nNLP techniques related to text mining have been\nused to extract features from URLs, which are then\nused as features to train the AI-based classification"}, {"title": "4.3 Key Findings", "content": "Given the findings of this SLR, we attempt to address\nour Research Questions.\nPhishing URLs. While established datasets have\nplayed a crucial role in the development of phishing\nURL detection models, there is a clear need to incorpo-\nrate more dynamic and current data sources. Leverag-\ning user-reported phishing URLs from social networks,\nalong with data from Telecom and Security organiza-\ntions, offers a more effective approach to combating\nphishing attacks. These sources provide real-time, di-\nverse, and relevant data that enhance the robustness\nand accuracy of detection models, keeping pace with\nthe evolving nature of phishing threats. By combin-\ning the strengths of both traditional and modern data\nsources, researchers can develop more comprehensive\nand adaptive phishing detection systems, better pro-\ntecting users from phishing URLs.\nRegarding the methodologies used, we find that the\nexisting literature used state-of-the-art methodologies\nfor the analysis and detection of phishing URLs. No-\ntably, RF seems to be the stand-alone model that\nworks best, while other hybrid methodologies also re-\nport promising performance.\nPhishing Emails. While publicly available datasets\nhave laid the groundwork for phishing email detection\nresearch, the rapidly evolving nature of phishing at-\ntacks requires the use of more dynamic and up-to-date\ndata sources. Leveraging user-reported emails, real-\ntime spam collections, and advanced synthetic data\ngeneration techniques can significantly enhance the\nrobustness and accuracy of phishing detection mod-\nels. By combining traditional datasets with innovative\ndata sources, researchers can develop more comprehen-\nsive and adaptive phishing detection systems, better\nequipped to detect phishing activities via email.\nAll of the works that opted for automated phishing\nemail detection report very good performance on their\ndetection models, with RF, BERT, LSTM, RNN, and\nSVM being the most popular."}, {"title": "5 Discussion", "content": "We now discuss our findings, detailing recognised lim-\nitations and shortcomings detected in the reporting of\nAI models related to the performance and data sources\nused. We also provide recommendations for researchers\ndeveloping detection models for online fraud."}, {"title": "5.1 Data Sources", "content": "Overall, we analyzed the data sources and detection\nmethodologies of 222 papers that aim to address a\nrange of online fraud problems. Although our findings\nreveal a preference for well-established datasets, espe-\ncially in the automated detection of various phishing\nand fake reviews detection, more recent studies (pub-\nlished after 2023) seem to shift towards more dynamic\nand recent sources.\nWe found that the overwhelming majority of the\nPhishing domain detection studies relied on well-\nknown and extensively studied datasets from web-\nsites like PhishTank, OpenPhish, and SpamHaus. In\ncontrast, others used datasets made available from\nprevious studies or publicly available repositories like\nKaggle, University of California Irvine (UCI) Machine\nLearning Repository, and GitHub. This is also the case\nfor studies that focused on phishing email detection,\nfake review detection, and fraudulent recruitment de-\ntection. However, while these established datasets pro-\nvide a valuable foundation for research, they come with\nlimitations.\nOnline fraud is dynamic, with new scam techniques\nfrequently emerging and older methods, like phishing\nURLs and websites, continually evolving. Studies show\nhat LLM empowered bots or scammers could be de-\nployed to generate and automate sophisticated and\ntargeted fraudulent and phishing content online, either\nthat being an email, a professional profile, or deceptive\nTerms and Conditions for fake e-commerce websites.\nHence, relying on outdated datasets may limit the ef-\nfectiveness of detection models when applied to cur-\nrent or evolving threats. At the same time, the static\nnature of previously used datasets does not capture"}, {"title": "5.2 Methodologies", "content": "The methodologies employed across various studies on\nphishing and fraudulent activities involve a wide range\nof AI that incorporate NLP, machine learning and\ndeep learning techniques. Most of these techniques in-\nvolve using extracting features using NLP techniques\nand then applying supervised machine learning (i.e.\nlabelled data) and deep learning algorithms to build\nbinary classifiers.\nFor phishing URLs, Machine Learning and Deep\nlearning algorithms such as CNN, ANN, KNN, LSTM,\nNB, RF, DT, SVM, and XGBoost were commonly\nused, often with URL feature extraction through NLP\nmethods like character counts and n-grams. We also\nfound various works that applied hybrid approaches\nwhere they combined multiple methodologies, demon-\nstrating strong detection capabilities. Similarly, phish-\ning email detection heavily relied on NLP for feature\nextraction (e.g., LDA, BERT) followed by AI models\nlike RF, NB, and SVM for classification. Similar tech-\nniques were applied for phishing SMS detection.\nIn vishing (phishing phone calls), transcript anal-\nysis primarily conducted using NLP and AI models,\nwith some studies examining deepfake voice detection.\nUser reports on phishing activities utilized models like\nBERT and RF, while fake reviews often involved sen-\ntiment analysis with methods like VADER.\nFraudulent job postings detection involved both use\nof machine learning and deeep learning models such as\nLR and Bi-LSTM. Romance fraud detection used sen-\ntiment detection methods and machine learning mod-\nels (e.g. RF) and deep learning models (e.g. LSTM).\nFor fraudulent investment and crypto manipulation,\nclassic machine learning models like DT, XGBoost,\nand SVM were employed. Studies on fraudulent e-\ncommerce and crowdfunding leveraged advanced NLP\nand machine learning techniques, including GPT-4 and\nLR, respectively.\nAlthough the research and detection methodologies\napplied by the detected literature perform well, they\nare not without theirlimitations. Overall, popular ma-\nchine learning algorithms like RF and SVM often rely\nheavily on the quality of features extracted, which can\nbe labor-intensive and may miss out on subtle indica-\ntors when dealing with large set of data."}, {"title": "5.3 Recommendations", "content": "Datasets. The reliance on older, established datasets\nfor training AI-based models is a double-edged sword.\nWhile they offer a solid foundation for model develop-\nment and are used for omparative analysis, their static\nnature may limit their effectiveness in detecting evolv-\ning or emerging fraud trends, hence limiting their ef-\nfectiveness for detecting new types of fraud. Therefore,\nthere is a strong case for incorporating more dynamic\nand diverse data sources. Recent studies that use cus-\ntom crawlers to gather data from a variety of online\nplatforms that focus on on a range of fraud types exem-\nplify best practices in this area. These approaches pro-\nvide real-time, relevant data that can significantly im-\nprove the adaptability and accuracy of detection mod-\nels. Going forward, it is recommended that researchers\nconsider combining established datasets with freshly"}, {"title": "6 Conclusion", "content": "In this systematic literature review, we have examined\na wide range of studies focusing on the detection of var-\nious fraudulent activities using AI based models that\nuse techniques from Natural Language Processing in-\ncluding machine learning and deep learning. Our goal\nwas to examine the current state-of-the-art AI-based\nmodels used for development and training, investigate\nthe sources of data, and assess how these models are\nevaluated for effectiveness in analysing and detecting\nfraudulent activities. Due to limited resources, we have\nrestricted the data collection for the SLR to the years\n2019-2024. The studies we identified highlight a focus\non a wide range of fraudulent activities, with particu-\nlar attention given to phishing attacks. However, there\nis growing interest towards the use of more advanced\nAI like Chat GPT for creating deceptive content as well\nas a tool that can be used for scam-baiting.\nWhile significant attention have been given to build-\ning classification models that could be used to detect\nfraudulent activities, particularly with hybrid and ad-\nvanced NLP techniques and deep learning, including\nLLMs, there remains a considerable room for improve-\nment. The key AI-model development areas that re-\nquire attention include performance reporting, repro-\nducibility and transparency. Providing detailed perfor-\nmance reporting will help compare and evaluate dif-\nferent models. Improving reproducibility requires en-\nsuring that the studies can be replicated and there\nis sufficient content for others to achieve this. Increas-\ning transparency means providing clear information on\nhow the AI-based models work and make decisions.\nThis will help fraud practitioners to interpret and un-\nderstand the models, and mitigate any biases in AI-\nbased models.\nFurthermore, most existing models rely heavily on\nlabelled data and supervised machine-learning tech-\nniques. Future studies should give some attention to\nthe application of unsupervised and semi-supervised\nmachine learning for detecting fraud. Similarly, the\ndata sources used for training these models are not\nsuitable for capturing dynamic nature of fraud. Future"}]}