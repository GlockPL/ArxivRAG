{"title": "Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models", "authors": ["Jia-Hong Huang*", "Chao-Chun Yang*", "Yixian Shen", "Alessio M. Pacces", "Evangelos Kanoulas"], "abstract": "The legal landscape encompasses a wide array of lawsuit types, presenting lawyers with challenges in delivering timely and accurate information to clients, particularly concerning critical aspects like potential imprisonment duration or financial repercussions. Compounded by the scarcity of legal experts, there's an urgent need to enhance the efficiency of traditional legal workflows. Recent advances in deep learning, especially Large Language Models (LLMs), offer promising solutions to this challenge. Leveraging LLMs' mathematical reasoning capabilities, we propose a novel approach integrating LLM-based methodologies with specially designed prompts to address precision requirements in legal Artificial Intelligence (LegalAI) applications. The proposed work seeks to bridge the gap between traditional legal practices and modern technological advancements, paving the way for a more accessible, efficient, and equitable legal system. To validate this method, we introduce a curated dataset tailored to precision-oriented LegalAI tasks, serving as a benchmark for evaluating LLM-based approaches. Extensive experimentation confirms the efficacy of our methodology in generating accurate numerical estimates within the legal domain, emphasizing the role of LLMs in streamlining legal processes and meeting the evolving demands of LegalAI.", "sections": [{"title": "1 INTRODUCTION", "content": "The legal field spans a broad spectrum of lawsuit types, encompassing motor vehicle accidents, personal injury compensation, estate distribution, medical malpractice, and various other areas. Lawyers encounter significant challenges in delivering prompt and accurate information to their clients across these various lawsuit types, particularly when it comes to crucial aspects like potential imprisonment duration or financial repercussions in case of unsuccessful lawsuits. This difficulty arises from the necessity to navigate extensive legal documentation and precedent to provide informed responses, referring to Figure 1. Unfortunately, this process not only prolongs legal proceedings but also introduces inconsistencies and uncertainties in legal outcomes [82]. Using the U.S. as an example, compounding this issue is the fact that, according to the U.S. Financial Education Foundation (USFEF) [44], over 40 million lawsuits are filed annually in the United States. However, the total number of registered lawyers in the United States from 2007 to 2022 was only approximately 1.34 million. This highlights a severe scarcity of legal experts or practitioners. Consequently, there is an urgent need to enhance the effectiveness and efficiency of traditional legal proceedings and workflows.\nIn recent years, spurred by rapid advancements in deep learning, researchers have increasingly turned to the application of deep learning techniques within the realm of legal Artificial Intelligence (LegalAI) [82]. This trend has led to the proposal of several new LegalAI datasets [7, 8, 15, 45, 73], which serve as pivotal benchmarks for research in this burgeoning field. Leveraging these datasets, researchers have embarked on exploring Natural Language Processing (NLP)-based solutions for a range of LegalAI tasks, including legal judgment prediction [1, 9, 53, 81], legal entity recognition and classification [2, 5], court view generation [76], legal summarization [3, 18], and legal question answering [46, 56, 65].\nHowever, existing methodologies in LegalAI frequently encounter challenges when attempting to accurately compute specific numerical values for legal-related estimations, such as compensations or prison durations, based on available data. This difficulty probably stems from the predominant emphasis of current legal datasets on traditional NLP text-based tasks like summarization, judgment"}, {"title": "2 RELATED WORK", "content": "In this section, we explore the significant developments across three pivotal areas in the integration of Al within the legal domain. Starting with the early applications of conventional AI to tackle legal challenges, we then transition to the critical role of LegalAI datasets in refining and enhancing Al's capabilities for legal applications. Finally, we delve into the advancements brought forth by LLMs, which have reshaped the landscape of NLP and AI, offering novel methodologies and approaches in the legal field."}, {"title": "2.1 Conventional AI in Legal Contexts", "content": "The intersection of Al with the legal domain has evolved significantly, transitioning from rule-based expert systems to sophisticated deep learning models. Early endeavors in LegalAI sought to replicate human legal reasoning through systems like TAX\u039c\u0391\u039d and HYPO, which employed rule-based logic to navigate legal principles [16, 61]. While these systems laid the groundwork for Al's application in legal contexts, they were limited by the scope of their hardcoded knowledge and lacked the ability to generalize beyond their specific programming.\nDeep Learning and Legal Judgment Prediction (LJP): The exploration of LJP using deep learning technology marks a significant milestone in LegalAI. The authors of [21, 51, 68] have pioneered this domain by employing neural networks to analyze legal documents and predict outcomes. These advancements not only showcase the potential of novel models in enhancing performance but also underscore the importance of leveraging deep learning for more accurate legal analytics.\nInnovations in Model Architectures: The drive to improve LJP performance has led to the adoption of more sophisticated neural network architectures. For instance, the authors [9] introduced gating mechanisms to refine the prediction of penalties, while the authors of [57] developed multi-scale attention models to address the complexities of cases with multiple defendants. These innovations highlight the continuous search for model architectures that can better capture the nuances of legal reasoning.\nUtilization of Legal Knowledge: A notable direction in recent LegalAI research is the integration of legal knowledge into AI models. In [53], the use of attention mechanisms between facts and law articles exemplifies how AI can leverage legal knowledge to improve charge predictions. Similarly, the topological graph approach utilizes the relationships between different LJP tasks, demonstrating the value of structured legal knowledge in enhancing model performance [81].\nAdvancements in Legal Entity Recognition and Other NLP Applications: Beyond LJP, significant progress has been made in legal entity recognition, classification, and other NLP-based tasks. [2, 5] in developing models for legal entity recognition and classification have paved the way for more sophisticated document analysis techniques. Additionally, innovations in court view generation and legal summarization by [18, 76] have opened new avenues for automating the synthesis and summarization of legal texts.\nLegal Question Answering: The domain of legal question answering has also benefitted from AI advancements, with researchers developing models that provide precise responses to complex legal inquiries. The contributions by [46, 56, 65] in this space further bridge the gap between legal knowledge and AI capabilities, offering promising tools for legal practitioners and the public.\nThe shift from conventional AI to deep learning within the legal sector signals a paradigm transformation, enhancing the efficiency, accuracy, and accessibility of legal analyses and democratizing legal expertise. However, this advancement brings forth challenges such as the opaque nature of deep learning models [13, 20, 23-42, 50, 69, 72, 75, 77-80, 84], which often operate as \"black boxes\", making it difficult to discern the logic behind their decisions. This opacity poses a significant issue in the legal domain where the"}, {"title": "2.2 LegalAI Datasets", "content": "The evolution and impact of LegalAI have been markedly accelerated by the advent and meticulous development of various legal datasets. These datasets, each meticulously curated to reflect the intricacies of legal processes and knowledge, have been instrumental in propelling forward the application of AI in the realm of law. They serve as a critical bridge, connecting traditional legal expertise with the computational efficiency and scalability of modern AI technologies.\nAmong these, the JEC-QA dataset introduced by [83] emphasizes the growing necessity for specialized datasets geared towards facilitating question-answering mechanisms within legal contexts. This need is echoed in contributions such as CAIL2019-SCM by [15, 74], which focus on aspects like case similarity and judicial reading comprehension, thereby underscoring the imperative to thoroughly understand and interpret judicial documents. The contributions of [6, 7] further expand LegalAI's research scope, introducing datasets for multi-label text classification on EU legislation and for neural legal judgment prediction in English. These efforts significantly enhance the textual analysis capabilities of AI models while broadening their application across different legal systems. In parallel, the work [55] on summarizing contracts into plain English addresses the critical need for making legal documents more comprehensible and accessible, reinforcing Al's role in demystifying legal language. The dataset CAIL2018 by [73] further exemplifies the Al's potential in automating and predicting legal outcomes, offering a robust platform for judgment prediction. Furthermore, the LENER-BR dataset by [54], aimed at named entity recognition in Brazilian legal texts, highlights the importance of specialized Al models for legal document analysis and information extraction. Similarly, the COLIEE dataset by [45] and the legal case law search test collection by [52] provide vital resources for evaluating legal information extraction, entailment, and the performance of legal search engines, underscoring the comprehensive nature of LegalAI studies. Moreover, the inclusion of datasets like JURISDIC by [11] for legal dictation in Polish, the LKIF Core ontology by [19] for basic legal concepts, and the HOLJ corpus by [17] for legal text summarization, each adds a unique dimension to the LegalAI research landscape. These contributions not only aid in the development of AI models tailored for legal text processing but also highlight"}, {"title": "2.3 Large Language Models", "content": "The integration of LLMs into the realm of NLP and AI marks a significant milestone in the advancement of technology. Models like GPT [4] and BERT [12] have been at the forefront of this evolution, showcasing an unprecedented ability to understand and generate human language across a variety of tasks such as translation, summarization, and question-answering [4, 12]. The significance of these developments extends beyond the enhancement of Al's linguistic capabilities, as they lay the groundwork for broader applications in multiple domains.\nThe scaling of LLMs, as highlighted by the works of [59, 67], has propelled NLP to new heights, enabling machines to perform tasks with a level of sophistication that was previously unattainable. A key breakthrough in this journey has been the discovery of LLMs' inherent ability for zero-shot and few-shot learning, which has revolutionized the way these models are applied to solve tasks with minimal initial guidance [49]. This led to the emergence of \"prompting\" techniques, fundamentally altering how models are conditioned to perform specific tasks, thereby enhancing their utility across a range of applications [60, 62]. Despite their successes, traditional prompting methods faced limitations in complex, multi-step reasoning tasks, leading to the development of the \"chain-of-thought (CoT)\" prompting technique. This technique, inspired by human problem-solving strategies, has significantly improved LLMs' performance in tasks requiring intricate reasoning, demonstrating the versatility and adaptability of these models in tackling more sophisticated challenges [70, 71]. Expanding the application of LLMs into mathematical reasoning, techniques like Zero-shot-CoT and MathPrompter have showcased the potential of LLMs in solving arithmetic problems and conducting mathematical analysis by generating algebraic expressions or Python functions. This not only underscores LLMs' ability in arithmetic tasks but also highlights their reliability through the validation of intermediate steps, as evidenced by their performance on the MultiArith dataset [43, 47].\nThe progress in LLM technologies marks a significant shift towards more versatile and intelligent AI applications, expanding their influence from linguistic to non-linguistic domains, particularly in the legal sector. Our initiative, aimed at improving decision-making and operational efficiency within the legal domain through LLMs, harnesses these advancements to tackle the distinct challenges encountered by legal professionals. By integrating LLMs' mathematical reasoning capabilities with tailored prompts, our goal is to enhance the precision and efficacy of legal workflows, thereby bridging the traditional methods of legal practice with contemporary technological innovations. The introduction of a curated dataset tailored for precision-focused LegalAI tasks further substantiates our approach, affirming the potential of LLMs to revolutionize legal processes and contribute to a more streamlined, accessible, and equitable legal system."}, {"title": "3 METHODOLOGY", "content": "The proposed method encompasses several essential components, including in-context learning and specially designed prompts. Each of these components will be introduced in the subsequent subsections. Additionally, to validate the effectiveness of the proposed method for precision-oriented LegalAI tasks, we propose a dataset focused on asset value estimation within the legal domain."}, {"title": "3.1 In-context Learning", "content": "GPT-3 [4] and other LLMs have exhibited remarkable proficiency in few-shot predictions without requiring fine-tuning. This entails providing the model with a task description in natural language along with a small number of examples. The effectiveness of this learning capability hinges on scaling model size, data, and computing resources. [10, 14, 58, 63] have proposed various training methodologies for different types of LLMs. These models exhibit a notable capacity to leverage few-shot prompts for accomplishing unseen tasks without the necessity of fine-tuning, a capability that emerges prominently in LLMs compared to their smaller counterparts. While LLMs [4, 10] have showcased remarkable success across various NLP tasks, their aptitude for reasoning has often been viewed as limited. It's important to note that merely scaling up the model size does not necessarily enhance this capability.\nRecent advancements have introduced the concept of \"chain of thoughts\" prompting, also known as in-context learning, as a potent technique to augment the reasoning prowess of LLMs when processing text [71]. This method entails presenting the model with multiple instances of reasoning chains, enabling LLMs to learn and apply the underlying template to solve intricate, unseen tasks effectively. Notably, the \"chain of thoughts\" approach bears resemblance to the strategy employed in the Visual Question Answering task, where addressing basic questions aids in tackling complex queries [22]. These recent findings underscore the robust reasoning capabilities of LLMs. Nevertheless, the current research landscape in LegalAI predominantly concentrates on text-based tasks such as legal question answering and legal summarization. In contrast, this"}, {"title": "3.2 Prompts Design", "content": "In this study, we advocate for the utilization of in-context learning coupled with specially formulated prompts to address precision-oriented tasks within the legal domain. Our prompts are designed with specific examples that encompass various attributes, including house specifications like area, location, and type, as well as details related to scam amounts or injury locations/parts. Each example is accompanied by corresponding answers such as house prices, compensation values, or durations of imprisonment. These examples serve as training demonstrations for LLMs to predict outputs for unseen test examples.\nConsider the prompt format illustrated in Figure 2 as a case in point. The first step in designing prompts entails extracting pivotal information from each judgment, ensuring a uniform textual description format encompassing information on injuries and compensation amounts. Following this, the next step involves framing a question that pertains to forecasting trends based on the provided cases. The proposed prompt format is devised to aid the LLM in identifying patterns within the presented cases. By leveraging these discerned patterns, the LLM is empowered to make predictions for the given test cases. If the variable of interest transitions from compensation to imprisonment duration, the procedure remains consistent, as depicted in Figure 3."}, {"title": "3.3 Proposed Precision-Oriented LegalAI Dataset", "content": "The valuation of properties, encompassing houses, lands, and various assets, is a prevalent practice in the legal domain, particularly in cases involving legacy or property division disputes. However, this process is typically time-consuming and resource-intensive due to the participation of numerous experts in the estimation phase. The complexity and duration of the overall process are further compounded by the involvement of experts specializing in property valuation. Consequently, there is an urgent need for an effective method to streamline and enhance the entire valuation process. Using house value estimation as an illustrative case, this study introduces a dataset specifically tailored to the common and crucial task of estimating house values. This dataset serves to assess the efficacy of the proposed method in addressing the precision requirements inherent in such tasks within the legal domain. The presented dataset comprises 58 data samples, with 45 samples allocated for in-context learning and the remaining 13 utilized for testing purposes. Each house data sample within the proposed"}, {"title": "4 EXPERIMENTS AND ANALYSIS", "content": "In this section, our objective is to assess the efficacy of the proposed method tailored for numerical estimation tasks within the legal domain. To accomplish this, we will conduct a validation of our method using the real-world dataset we have introduced for housing price estimation within the legal domain. The specifics of this dataset are outlined in the Methodology section."}, {"title": "4.1 Experimental Settings", "content": "Acquiring authentic and up-to-date data related to houses within legal domain poses challenges, resulting in a relatively modest size for the proposed dataset. Despite its smaller scale, this dataset proves sufficient for the purpose of in-context learning [71]. In the in-context learning phase, various attributes such as address, total price, transaction date, unit price, total area, proportion of the main building, age of the building, number of floors, and primary use are provided. In the testing phase, only the attributes of address, total area, proportion of the main building, age of the building, number of floors, and primary use are supplied. The model is tasked with predicting the total price during the testing phase. Once the total price is predicted, the unit price can be determined based on the available information of the total area and the predicted total price.\nWe conduct experiments using state-of-the-art LLMs, including OpenAI GPT-3.5, OpenAI GPT-4, Claude AI, and Google Bard with Gemini. The error rate (ER) and mean absolute percentage error (MAPE) metrics are employed to quantify the model's performance. MAPE is a measure used to assess the accuracy of a predictive model, particularly in forecasting tasks. It calculates the average absolute percentage difference between the predicted values and the actual values. The absolute values of errors are taken to prevent positive and negative errors from canceling each other out. MAPE is expressed as a percentage, and lower values indicate better predictive accuracy. The formula for calculating MAPE is provided in Equation (1)."}, {"title": "4.2 Evaluation and Analysis", "content": "OpenAI GPT-3.5.\nGPT-3.5 stands as a sophisticated iteration of OpenAI's GPT language model, following the achievements of its predecessor, GPT-3. This model is engineered to produce text that closely resembles human language in response to given inputs. Employing a transformer architecture, GPT-3.5 undergoes pre-training on an extensive corpus of internet text, enhancing its capacity to comprehend and generate coherent responses across diverse domains. Notably, it exhibits refined capabilities in contextual understanding, nuanced response generation, and adept handling of intricate language tasks. In this study, we harness GPT-3.5 for in-context learning, utilizing a meticulously crafted prompt detailed in the Methodology section. The efficacy of this approach is then evaluated using our proposed precision-oriented dataset. As shown in Table 1, the MAPE value is 40.75%. This outcome suggests that there is room for improvement in GPT-3.5's numerical estimation capabilities.\nOpenAI GPT-4.\nGPT-4 represents the latest advancement in OpenAI's series of LLMs, incorporating multimodal capabilities. This iteration, following in the footsteps of its predecessors, employs a transformer-based architecture and a training paradigm that combines public data with third-party licensed data to predict the next token. Subsequently, the model undergoes fine-tuning through reinforcement learning, incorporating feedback from both human and AI sources to ensure alignment with human language nuances and policy compliance. The implementation of GPT-4 in ChatGPT marks an evolution from the previous version based on GPT-3.5, albeit with some persisting challenges. Notably, GPT-4 introduces vision capabilities (GPT-4V), enabling the model to process image inputs within the ChatGPT framework. To assess GPT-4's performance on our proposed dataset,"}, {"title": "5 DISCUSSION", "content": "In this work, we present three applications that harness the integration of law and LLM technology: 1. Predicting compensation amounts in finger injury cases, 2. Forecasting housing market prices, and 3. Evaluating sentencing in fraud cases.\nThe first application involves predicting compensation amounts in civil cases, particularly in scenarios like car accidents or property damage disputes. Determining compensation often hinges on various factors, such as the type of vehicle involved in accidents or the severity of bodily injuries sustained. Despite having detailed case information, lawyers may still struggle to accurately estimate compensation, leading to challenges in decision-making regarding settlement or litigation. By leveraging LLMs and extensive historical judgment data, this approach provides a more objective insight into compensation trends. This aids lawyers in promptly assessing potential judgment outcomes and refining legal strategies. While this paper primarily examines the correlation between finger injuries and compensation amounts, this methodology can be extended to other civil case types or factors influencing judgment amounts.\nThe second application focuses on assessing housing market values, which proves valuable not only in cases concerning damaged real estate but also in scenarios involving property division or compensation for property encroachment. In these situations, property market values play a crucial role in determining case outcomes. Furthermore, the versatility of the proposed method extends to determining land market values, highlighting its broad applicability in legal practice.\nThe third application focuses on predicting the severity of criminal sentences in criminal cases, which is typically influenced by factors such as the nature and magnitude of the crime, as well as the defendant's post-crime conduct. Despite the availability of detailed case specifics, lawyers often face challenges in accurately predicting sentence severity. Leveraging LLMs to analyze past judgment data and discern the relationship between specific factors and sentence severity enables a more objective prediction of sentencing outcomes, thereby enhancing the quality of legal advice provided. While this study concentrates on predicting sentence severity based on fraud amounts, this research direction is poised to expand to encompass other factors or criminal areas.\nHowever, trends in judgments may not remain static, and unique factors in individual cases could deviate from past judgment outcomes. These nuances still necessitate resolution by experienced lawyers. Therefore, the current applications do not aim to replace lawyers but rather serve as valuable tools for optimizing research and decision-making processes, reducing time consumption, and alleviating the financial burden of legal fees on litigants."}, {"title": "6 CONCLUSION AND FUTURE WORK", "content": "The legal field faces substantial challenges in delivering timely and accurate information across a spectrum of lawsuit types, exacerbated by the intricacies of legal documentation and the limited availability of legal experts. This highlights the urgent requirement for more efficient and effective legal procedures. While recent advancements in deep learning have prompted researchers to investigate solutions for various LegalAI tasks to enhance the efficacy of legal processes, challenges remain in accurately computing specific numerical values for legal-related estimations. To address this gap, our study proposes an innovative approach that integrates LLMs with specially designed prompts tailored to precision-oriented LegalAI applications. This approach seeks to enhance traditional legal proceedings and workflows while meeting the demand for precise numerical estimates in practical scenarios. The contributions of our work include introducing an LLM-based method to enhance legal proceedings, proposing a novel prompt design for addressing financial or precision-oriented challenges within the legal domain, presenting a real-world dataset of house prices for validating LLM-based methods, and conducting extensive experiments to evaluate the efficacy of the proposed approach in estimating parameters relevant to legal proceedings. Our findings underscore the potential of LLM-based methods in meeting the precision requirements of LegalAI applications, offering promising solutions to the challenges encountered in the legal domain. In summary, the suggested LLM-based approach aims to establish a more streamlined, accessible, and equitable legal system. Moreover, the proposed LLM-based method shows significant potential in improving the interpretability and transparency of AI applications within legal contexts, thereby playing a pivotal role in alleviating the inherent opacity associated with current applications of deep learning-based models.\nPotential future research directions using LLM-based methods include exploring the correlation between specific factors and compensation judgments in diverse civil cases, such as car accidents, property damage, joint real estate division, and property misappropriation cases. Additionally, studies could investigate the correlation between specific factors and sentencing severity in various criminal cases, including embezzlement, breach of trust, property crimes, and other case-specific characteristics."}]}