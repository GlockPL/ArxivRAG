{"title": "COMAL: Collaborative Multi-Agent Large Language Models for Mixed-Autonomy Traffic", "authors": ["Huaiyuan Yao", "Longchao Da", "Vishnu Nandam", "Justin Turnau", "Zhiwei Liu", "Linsey Pang", "Hua Wei"], "abstract": "The integration of autonomous vehicles into urban traffic has great potential to improve efficiency by reducing congestion and optimizing traffic flow systematically. In this paper, we introduce CoMAL (Collaborative Multi-Agent LLMs), a framework designed to address the mixed-autonomy traffic problem by collaboration among autonomous vehicles to optimize traffic flow. CoMAL is built upon large language models, operating in an interactive traffic simulation environment. It utilizes a Perception Module to observe surrounding agents and a Memory Module to store strategies for each agent. The overall workflow includes a Collaboration Module that encourages autonomous vehicles to discuss the effective strategy and allocate roles, a reasoning engine to determine optimal behaviors based on assigned roles, and an Execution Module that controls vehicle actions using a hybrid approach combining rule-based models. Experimental results demonstrate that CoMAL achieves superior performance on the Flow benchmark. Additionally, we evaluate the impact of different language models and compare our framework with reinforcement learning approaches. It highlights the strong cooperative capability of LLM agents and presents a promising solution to the mixed-autonomy traffic challenge. The code is available at https://github.com/Hyan-Yao/COMAL", "sections": [{"title": "1 Introduction", "content": "Recently, there has been significant growth in end-to-end autonomous driving systems [1]. The integration of large language models (LLMs) [2, 3] enhances the ability to generalize to unseen traffic scenarios with embedded common-sense knowledge. These models [4, 5, 6] primarily focus on optimizing the performance of individual ego vehicles. However, it also matters to study the problem of mixed-autonomy traffic to better deploy autonomous vehicles in society [7]. In this article, we enable connected autonomous vehicles (CAVs) to collaborate with human-driven vehicles across the traffic network, aiming to optimize overall traffic flow and system-wide efficiency.\nTraffic dynamics are extremely complex and chaotic dynamical systems [8]. Pioneering researchers [9, 10] typically trade away the complexity of the model for desirable provable properties. To this end, they propose a series of hand-designed control rules [11, 12] to direct a fleet of vehicles to form a desired stable motion pattern. The experiments [13, 14] suggest that autonomous vehicles can enhance traffic throughput, which highlights the potential of mixed-autonomy systems. To model the complex interactions between autonomous and human-driven vehicles in mixed-autonomy traffic systems, simulation-based numerical methods like the Flow benchmark [7, 15] have proven to be effective tools. Flow, a deep reinforcement learning (RL) framework, enables the systematic design of RL tasks to improve overall traffic flow, including the control of autonomous vehicles and traffic signals. With its ability to simulate dynamic multi-agent environments, Flow has facilitated the rise of multi-agent RL, which has gained popularity for modeling emergent behaviors in mixed-autonomy traffic systems [16]. By allowing autonomous vehicles to learn cooperative strategies, multi-agent RL enables interaction with both human-driven and other autonomous vehicles, optimizing traffic flow. These RL-based models demonstrate strong performance in specific traffic scenarios, effectively learning control policies for coordinating mixed-autonomy traffic [17, 18]. However, human behaviors in real-world settings are highly varied and unpredictable, while road networks are more complex and diverse. Deep RL performs well in specific and controlled environments but struggles to generalize across different scenarios [19] due to its reliance on large amounts of specific training data. Meanwhile, it is difficult to understand the decision-making process of RL, which limits its interpretability.\nRethinking human behavioral patterns, adolescents can learn to drive in just 20 hours and handle unfamiliar situations [20], while young children can spontaneously cooperate to enhance work efficiency [21]. Human decision-making and cooperation are inherently"}, {"title": "2 Related Work", "content": "2.1\nMixed-Autonomy Traffic\nMixed-autonomy traffic, where connected autonomous vehicles (CAVs) along with human-driven vehicles exist in a system [7], presents a significant challenge in traffic dynamics modeling and control. A control strategy named the \"slow-in, fast-out\" approach [13] has demonstrated improvements in traffic throughput with a minimal percentage of autonomous vehicles.\nReinforcement learning (RL) offers a more dynamic and adaptable solution. Benchmarks in RL [25] like Mujoco and the Arcade Learning Environment [26] provide systematic evaluation and comparison of algorithms. And especially for Mixed-Autonomy, benchmark Flow [7] proposes four traffic scenarios to illustrate distinct RL problems including shockwave minimization, inflow management, efficient merging, and intersection control. It evaluates and compares RL algorithms like Trust Region Policy Optimization (TRPO) [15, 27], Proximal Policy Optimization (PPO) [28], Evolutionary Strategies (ES) [29], and Augmented Random Search (ARS) [30] in traffic scenarios. [31] also explores the mixed-autonomy scenario in a multi-agent traffic signal control system [32].\n2.2 Large Language Model-based Multi-Agents\nLarge Language models (LLMs) have become integral to multi-agent systems [23] due to their capabilities in generalization and common-sense reasoning. LLM-based multi-agent systems leverage these strengths to enhance decision-making and communication among agents [33]. This approach is particularly beneficial in complex scenarios like mixed-autonomy traffic, where it is essential to have effective interaction between human drivers and autonomous systems.\nThe communication structure of LLM-based multi-agent systems varies across different studies to address specific challenges [23, 34, 24]. For example, research [24] has explored both centralized and decentralized communication structures for LLM-based"}, {"title": "3 Methodology", "content": "We introduce COMAL, a framework designed for LLM agents integrated into connected autonomous vehicles (CAVs) to collaborate and enhance the overall velocity and driving smoothness of traffic flow. As illustrated in Figure 1, we delineate COMAL at two distinct levels: the single-agent pipeline and the multi-agent workflow.\nAt the single-agent level, the LLM-based agents make decisions based on prompts that include few-shot experiences stored in memory, as well as scenario descriptions derived from environmental perception. The agents operate in two modes: task allocation within the Collaboration Module and planner generation within the Reason Engine. The multi-agent workflow consists of three modules: the Collaboration Module, the Reason Engine, and the Execution Module. In the Collaboration Module, COMAL establishes a shared message pool that facilitates brainstorming and collaborative decision-making among agents. Within this shared space, agents collectively allocate tasks, define their respective roles, and formulate individual driving plans. Each agent then generates a rule-based driving planner in Reason Engine, which is subsequently executed within the Execution Module to ensure coordinated driving behavior and smooth traffic flow.\n3.1 Single-Agent Pipeline\nThe quality of prompts significantly influences the output quality of LLM. COMAL utilizes a prompt generator that integrates all essential information for effective decision-making. The workflow for each individual agent involves several steps: (1) encode the scenario into a textual description within the Perception Module; (2) recall relevant driving experiences from the"}, {"title": "3.1.1 Environment Perception Module", "content": "To efficiently extract prompts from complex environmental data and enhance the scene understanding of LLMs, we design an Environment Perception Module. This module extracts key information from the simulation environment and constructs a textual scenario description. The description follows a set of standard rules to generate a thorough representation in natural language. The scene information is divided into two parts: static map and dynamic agents, as shown in Figure 2.\nThe static map information represents the scenario type, providing semantic priors for vehicle motion planning. The description of the map helps the LLM intuitively understand the scenario's geometry. The dynamic information describes the motion of the ego vehicle and surrounding agents, which directly influences the planning of vehicles' movement."}, {"title": "3.1.2 Memory Module", "content": "Similar to human drivers, the agent must make decisions based on reasoning processes that are informed by past driving experiences. To achieve this, we employ a Memory Module that stores experiences from previous driving scenarios and handmade instructions. Initially, the agent is provided with a set of predefined experiences, which the LLM then updates continuously as it engages in reasoning during new situations. This approach allows the agent to refine its decision-making over time, improving its performance in diverse driving contexts."}, {"title": "3.2 Multi-Agent Workflow", "content": "In a mixed-autonomy traffic setting, where CAVs operate alongside human drivers, the main objective is to optimize overall traffic flow. To achieve this, we propose a three-stage decision-making workflow. In the Collaboration Module, agents first discuss and allocate tasks within a public message pool. In Reason Engine, each agent then independently"}, {"title": "3.2.1 Collaboration Module", "content": "Collaborative agents work together towards a shared objective, typically exchanging information to enhance the collective solution. In the Collaboration Module, all CAVs participate interactively by forming a queue for brainstorming and communication. In the brainstorming session, the vehicles take turns subsequently speaking in a public channel to propose strategies and assign tasks among themselves. This collaborative effort ensures that each CAV understands its specific role in the traffic system.\nCommunication Structure Here, we introduce a shared message pool to boost communication efficiency, as shown in Figure 3. This communication structure maintains a shared message pool where agents can publish messages and subscribe to the latest messages from one another. Agents will take turns to speak one at a time until the strategy is fully developed and each agent's role is clearly defined."}, {"title": "3.2.2 Reason Engine", "content": "During team brainstorming, each agent determines its role and formulates a strategy to collaborate with other vehicles. Based on these defined roles, the Reason Engine generates an appropriate driving planner to effectively control the vehicle. The Reason Engine takes scenario description and predefined system prompts as inputs. Subsequently, the LLM generates the driving planner based on IDM through reasoning guided by a hierarchical chain-of-thought prompt."}, {"title": "System Prompt", "content": "The system prompt defines the planning task and associated driving knowledge. Its primary goal is to standardize the format of both input and output data, as well as clarify the objectives of planner generation. Specifically, it ensures a clear understanding of the physical meaning of each parameter in the IDM planner, such as speed limit (vo), maximum acceleration (am), and minimum headway (so). This provides a structured foundation for the decision-making process."}, {"title": "Hierarchical Chain-of-thougts", "content": "The hierarchical chain-of-thought process involves four critical components: role clarification, scene understanding, motion instruction, and planner generation. Initially, it is crucial to clarify the role and task of the ego vehicle within a collaborative context. Then the LLM is directed to focus on key information in the scenario, such as headway distance and lead vehicles. Based on the scenario analysis, the LLM is then prompted to provide motion instructions for the ego vehicle. Finally, each agent utilizes scenario analysis and motion instructions to generate a driving planner, parameterized by IDM model."}, {"title": "3.2.3 Execution Module", "content": "We utilize the rule-based IDM model as a planner to execute driving strategies by adjusting its parameters. IDM is a car-following model to compute longitudinal dynamics. In this model, the acceleration ak for vehicle k is defined by its bumper-to-bumper headway sk (distance to preceding vehicle), velocity uk, and relative velocity \u0394\u03c5\u03ba, via the following equation:\n$a_k = Amax[1 - (\\frac{Uk}{\\nu_0})^\\delta \u2013 (\\frac{8*(Uk,\\Delta Uk)}{Sk})^2]$\nwhere s* is the desired headway of the vehicle, denoted by:\n$s* (\u03c5k, \u0394\u03c5k) = s_0 + max(0, \u03c5kT + \\frac{\u03c5k\\Delta \u03c5k}{2\\sqrt{amaxb}}$\nwhere so, \u03c5\u03bf, \u03a4, \u03b4, amax, b are given parameters. We set the desired time headway T, the comfortable braking deceleration b, and the acceleration exponent \u03b4 as constants while adjusting the desired velocity vo, the minimum spacing so, and the maximum acceleration @max to tailor the driving planners. Thus Reason Engine generates a driving planner by customizing IDM's parameters (vo, amax, So)."}, {"title": "4 Experiments", "content": "In a mixed-autonomy setting, a subset of vehicles are tasked with the objective of improving overall traffic flow and mitigating the formation and propagation of stop-and-go waves. Thus, in our experiments, we aim to address several key questions:\n\u2022 How can CAVs enhance traffic flow and eliminate stop-and-go shockwaves?\n\u2022 How do multiple LLM-based agents collaborate to achieve this goal?\n\u2022 Do different LLM models influence the results?"}, {"title": "4.1 Implementation Details", "content": "The experiments are conducted in Flow [15] with SUMO [37], a microscopic simulator for traffic and vehicle dynamics. For details on the architecture and on training autonomous vehicles to maximize system-level velocity, we refer the readers to [15]. The environment offers several driving models to simulate human driver and a realistic interaction between vehicles. We adopt OpenAI GPT-40-mini, Qwen-72B/32B/7B in this paper."}, {"title": "4.2 Scenarios", "content": "We evaluate our model on the Figure Eight (FE), Ring, and Merge scenarios from the Flow benchmark. Further details are provided below and illustrated in Figure 1 (c).\nRing The ring road network consists of a circular lane where vehicles continuously travel in a loop. It is commonly used to study traffic dynamics, as disturbances can cause stop-and-go waves. In mixed-autonomy scenarios, CAVs are deployed to reduce these waves and enhance traffic flow stability."}, {"title": "Figure Eight (FE)", "content": "The FE network builds on the ring road by connecting two circular loops via an intersection. In mixed-autonomy scenarios, CAVs are introduced to smooth traffic and prevent stop-and-go waves."}, {"title": "Merge", "content": "The merged network simulates highway disturbances caused by vehicles entering from an on-ramp, which creates stop-and-go waves. In mixed-autonomy scenarios, CAVs are tasked with mitigating these waves based on local observations and adjusting to fluctuating vehicle numbers in the open network.\nWe investigate different levels of difficulty for each proposed benchmark by adjusting their scenario-specific meta-parameters. Table 1 provides detailed descriptions of the selected meta-parameters for each benchmark."}, {"title": "4.3 Metrics", "content": "To provide a comprehensive assessment of traffic flow and mitigate the occurrence of shockwaves, we utilize two metrics:\n\u2022 Average vehicle speed in the network (m/s). Higher values indicate better overall traffic flow.\n\u2022 Standard deviation of vehicle speed (m/s). The smaller is more stable. Lower values reflect greater stability and consistency in traffic movement."}, {"title": "4.4 Specification on Communication", "content": "In this section, we focus on the interactive process among agents as they work to solve the mixed-traffic problem. In the FE scenario, the agents recognize the need to form a queue, identify a leader, and designate the remaining agents as followers. The process of task allocation and leader selection is illustrated in Figure 3. Additionally, in the ring and merge scenarios, agents aim to eliminate shockwaves. Their reasoning is as follows: if there is relative traffic congestion ahead of the ego vehicle, the agent approaches the lead vehicle slowly; otherwise, it accelerates to follow the lead vehicle closely."}, {"title": "4.5 Quantitative Results", "content": "We evaluated our model on the aforementioned benchmarks, varying the number or percentage of CAVs across different settings.\nAs shown in Table 2, we compared the performance of COMAL with that of human drivers. The results indicate that as the number of CAVs increases, COMAL's performance generally improves and surpasses that of human drivers. This highlights the strong capability of LLM agents in achieving effective cooperation. A visualization of the vehicle trajectories in Ring 0 setting is shown in Figure 4. We can see that the proposed CoMAL framework can stabilize the unstable vehicle flow."}, {"title": "4.6 Ablation Studies", "content": "We conducted a detailed analysis of the effectiveness of each component of CoMAL in the FE 1 and Merge 1 scenarios, as presented in Table 3.\nAblation on Perception The comparisons in the second and fifth rows of Table 3 demonstrate the effectiveness of incorporating textual descriptions of the map and agents' motion states in the Perception Module. Once perception information is lost, agents are no longer able to comprehend the spatial relationships between the ego vehicle and surrounding agents. As a result, their capacity for effective collaboration and reasoning is significantly impaired.\nAblation on Memory The comparisons in the third and fifth rows of Table 3 illustrate the impact of the Memory Module, in which specific experiences are allocated for each scenario. In the absence of high-quality experiences, agents are more susceptible to errors in both discussion and reasoning.\nAblation on Collaboration The comparison presented in the fourth and fifth rows of Table 3, as well as in the first row, highlights the effectiveness of the Collaboration Module. The absence of a collaboration mod-"}, {"title": "4.7 Discussion", "content": "Compared to RL method We conducted experiments on FE and the Merge scenarios by comparing them to RL methods developed in [7]. The results are shown in Table 5. The Ring is not included in this experiment because the adopted RL benchmark doesn't have the Ring scenario embedded. In the FE scenario, COMAL demonstrates robust global collaboration, whereas multi-agent RL models struggle to differentiate roles, hindering effective cooperation. Consequently, COMAL outperforms RL-based approaches. However, in the Merge scenario, CoMAL performs less effectively than RL, indicating that the collaboration is not global. This finding highlights the critical importance of cooperation in enhancing performance."}, {"title": "Comparison of various LLM models", "content": "We evaluate performance across LLM models of varying sizes (see Table 4). The GPT-40-mini achieves the highest performance among these. Among open-source models, the Qwen 72B has a similar level with the GPT-40-mini, while the Qwen 32B shows slightly lower performance, and the Qwen 7B performs significantly worse. Notably, we observe that in scenarios requiring extensive collaboration, the performance of smaller models deteriorates more rapidly. This finding suggests that collaboration is a more challenging task than reasoning within the COMAL framework."}, {"title": "5 Conclusion", "content": "In this paper, we present COMAL, an effective LLM-based multi-agent framework to address mixed-autonomy traffic challenges. By prompt-tuning LLMs with a hierarchical LLM-based planner, COMAL is able to handle complex vehicle driving tasks towards a collaborative goal under mixed-autonomy traffic. The LLM agent does so by serving primarily as a high-level commander, coordinating with lower-level controllers to execute detailed operations. Extensive experiments demonstrate the significant potential of multi-agent systems driven by LLMs to make informed decisions and collaborate effectively in driving scenarios.\nWe also acknowledge the limitations of our current work and would like to point out several important future directions. First, we can extend the experimental current settings to more agents and improve their collaboration to see if there would be emerging behaviors formed like in RL methods. Second, our paper addresses a simplified use of LLMs alone, whereas the combination of RL with LLM might be helpful in improving the performance of LLMs. In the future, more sophisticated scenarios will be explored to test the possibility of LLM's behavior in complex tasks."}]}