{"title": "Evaluating Personality Traits in Large Language Models: Insights from Psychological Questionnaires", "authors": ["Pranav Bhandari", "Usman Naseem", "Amitava Datta", "Nicolas Fay", "Mehwish Nasim"], "abstract": "Psychological assessment tools have long helped humans understand behavioural patterns. While Large Language Models (LLMs) can generate content comparable to that of humans, we explore whether they exhibit personality traits. To this end, this work applies psychological tools to LLMs in diverse scenarios to generate personality profiles. Using established trait-based questionnaires such as the Big Five Inventory and by addressing the possibility of training data contamination, we examine the dimensional variability and dominance of LLMs across five core personality dimensions: Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. Our findings reveal that LLMs exhibit unique dominant traits, varying characteristics, and distinct personality profiles even within the same family of models.", "sections": [{"title": "Introduction", "content": "Understanding the behaviour of LLMs is essential as they are increasingly used in diverse fields such as education, law, business and medicine[9] where they significantly influence human interactions and decision-making processes. These models can generate coherent and insightful content, allowing personal recommendation and solving complex problems [12]. However, concern for ethical considerations, inherent bias and the potential for misuse still exist[9] which must be addressed by exploring the underlying patterns through systematic approaches such as psychological assessments [3]. Explaining specific behaviours exhibited by LLMs comes with significant challenges, particularly when these LLMs generate specific outputs with no insights into the underlying reasoning[3]. This challenge forms a strong motivation to systematically apply psychological tools to analyse and interpret the personality traits exhibited by LLMs.\nPersonality plays a critical role in shaping conversations in many ways, such as exchanging empathy, creating openness, and mitigating harm that is measured through well-established psychometric tools in humans. Tests such as the IPIP-NEO-60[8], HEXACO[10], and TIPI[2] are validated through long-standing rigorous processes such as internal consistency, test-retest methods, and convergence validity with similar tests.\nSince LLMs are trained on vast amounts of human-produced data, we argue that even if they lack behaviour in a true psychological sense, their outputs may still reflect psychological traits. Furthermore, psychological assessments have proven to be relevant, reliable and valid for large-scale language models[11] in the literature. We use five different tools such as the Big Five Inventory (BFI) [6] that measure various dimensions of personality in multiple LLMs to understand their personality traits. In contrast to existing literature[4, 9], where tests are directly administered to LLMs introducing potential bias, as these models may have encountered the questions during training, we restructure the tests to create their closest representations and validate them prior to administration. Additionally, the questionnaires are randomised to eliminate dependency bias between them."}, {"title": "Contributions:", "content": "Our contributions are as follows: 1). Firstly, we systematically assess LLMs personality traits using restructured personality questionnaires to resolve training data contamination and reduce dependency bias; 2). We then present the distinct personality profiles of LLMs to provide insights into their personality traits; 3). Finally, we conduct the dimensional analysis for dominance and variability across each trait of the personality questionnaires for all the LLMs used.\nWe find that LLMs often score higher in traits like Agreeableness, Openness, and Conscientiousness, reflecting their cooperative, creative, and organised behaviour. Furthermore, we show that LLMs exhibit varying consistency across dimensions of dominance and variability when tested across different models. Overall, we provide a systematic approach to understanding LLM personality traits using established questionnaires."}, {"title": "Literature Review:", "content": "Notable connections of LLM with psychology began with the advent of models such as GPT-3 [9]. Various perspectives of psychology are infused to understand behaviours from multiple dimensions such as emotion, cognition [12], Theory-of-Mind, and morality [7]. Identifying personality traits has been one of the main emphasises in the field of study [4, 5, 11-13]. Psychometric tools such as IPIP-NEO-120[11], Big Five Inventory (BFI) [6, 7], are predominantly used in the literature to assess the five dimensions of personality mentioned above.\nVariations in prompts and the use of role-playing agents have been impersonated in several studies to study different personality behaviours in LLMs [9]. The major aim behind these studies was to assess whether the behaviour is consistent or changing across different simulated situations. Context-sensitive variations were observed for several scenarios [4, 9]. Jiang et al. [5] used personality prompting methods to induce and tailor the personality of LLMs according to the dynamic needs of the tests. This also draws attention to the need to enforce ethical factors for LLMs to create a safe and moderated environment for users.\nA limited number of LLMs and personality traits sharing the same domain in the literature restrict the scope of analysis. The small sample size at this exploratory stage could impact the validity of results across models. A significant concern is the use of these tests in their original form, raising the risk of training data contamination and potential bias due to the sequential nature of questions within the same Big Five Personality dimension [3]."}, {"title": "Methodology", "content": "The basic methodology consists of administering various personality tests from psychology to LLMs. Five personality traits questionnaires are used, all containing five dimensions of personality i.e., Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. Each questionnaire has varying questions with strengths (\u2191) and weaknesses (\u2193). Despite variations in the depth of judgment, question types, and scoring methods, all these tests consistently measure the five common dimensions of personality traits. Each test is administered to LLMs using system and user prompts (Figure 1) at least three times per LLM to ensure score consistency and avoid mix-ups across combinations.\nLikert scale scores obtained from querying LLMs are processed based on each questionnaire's scoring rules and visualised in various formats. These methods aim to address gaps in the literature regarding the administration of such questionnaires to LLMs."}, {"title": "Removing Training Data Contamination", "content": "To remove the training data contamination as stated in the literature [3], a 2-step procedure was implemented. Initially, each question in the questionnaire was reworded to contain a different structure while the purpose of the question was intact. We used high-end models such as GPT-40\u00b9 to reconstruct the questions. These were"}, {"title": "Systematic Sequence of Prompts", "content": "Once the prompts and questions were finalised, they were administered to LLMs in a randomised order to mitigate dependency bias from specific personality traits. Questions were presented in batches of 10 to preserve contextual understanding, with answers remapped upon completing each iteration. Across all models, 100 iterations were conducted using a minimum temperature setting and the responses were mapped accordingly."}, {"title": "Calculate Coefficient of Variation", "content": "While various tests are administered across different LLMs, it is important to analyse the consistency of the scores for the reliability and robustness of the tests. This analysis examines the variability of scores in the five different personality traits, across multiple runs (n = 100). To analyse this variability, we calculate the Coefficient of Variation (CV) for the scores of a specific personality dimension (e.g., openness, neuroticism) across all personality questionnaires for a given model. The CV is computed using the Mean (M) and Standard Deviation (SD) CV as: $CV = \\frac{SD}{M} \u00d7 100%$."}, {"title": "Results", "content": "Three models from the Llama family i.e., Llama-3-8B-Instruct, Llama-3.1-8B-Instruct, Llama-3.2-3B-Instruct and two from the OpenAI family i.e., GPT-4 and GPT-40-mini are used in the experiments.\nThe reason to choose different models from the same family is to effectively compare the results as models from the same family share similar structures with some changes in the methodology allowing us to understand the impact of minor changes concerning personality traits."}, {"title": "Personality Profiles of LLMs", "content": "Table 2 provides an insight into the personality scores of LLMs. Figure 2 illustrates the personality profiles of LLMs across five tests. Agreeableness and Neuroticism scores from the BFI questionnaire are comparable across models, whereas other tests reveal gaps, suggesting a more uniform alignment with these traits when evaluated using the BFI.\nAgreeableness consistently shows higher average scores across all LLMs compared to other dimensions, while Neuroticism demonstrates lower average scores across all tests. Lower scores in Neuroticism indicate that LLM exhibit calm, emotionally stable, and resilient behaviour in their responses. These scores highlight the tendency of LLMs to maintain balanced and neutral behaviour, avoiding extreme or negative emotional expressions. Moderate levels of Extraversion are observed across all LLMs in all tests, except for Llama-3.2-3B-Instruct, which shows lower sociable or enthusiastic tendencies in the mini-IPIP and TIPI questionnaires. This indicates that its behaviour may vary in specific contexts as captured by these tests. These deviations highlight the influence of the model-specific design and the sensitivity of the questionnaire in assessing personality traits. Openness and Conscientiousness are generally higher for all LLMs across all personality questionnaires. This suggests that LLMs consistently exhibit traits of curiosity, creativity (Openness), reliability, organisation, and attention to detail (Conscientiousness). These higher scores likely reflect the models' design to provide thoughtful, adaptable, and structured responses."}, {"title": "Dimensional Variability Across Models", "content": "As mentioned in the methodology Section 3.3 we calculate the CV for each model for each of the five dimensions across all the personality questionnaires except for the TIPI because they are measured in the Likert scale of 1-7 as opposed to all other personality inventories which are measured from 1-5."}, {"title": "Dimensional dominance by Model Type", "content": "LLMs exhibit varying strengths across personality traits, reflecting their training strategies and alignment methods. Our study explores whether LLMs trained with distinct data and methods demonstrate different dominating dimensions. To evaluate dimensional dominance, the mean score for each dimension is calculated across all questionnaires for each LLM, identifying the dimension with the highest mean. For the OpenAI models, the dominance is around the Agreeableness domain. The implications are these models emphasize traits that support the domain such as cooperation, friendliness, and trustworthiness.\nThe Llama models however have dimensional dominance across varying dimensions. For Llama-3-8B-Instruct, Conscientiousness is the dominant dimension meaning it is efficient and organised, and has strong alignment with traits such as reliability and attention to detail. Llama-3.1-8B-Instruct however, dominates the Openness dimension, which adheres toward having strong traits such as creativity, insight and originality with wide ideas. Lastly, Llama-3.2-3B-Instruct dominates Agreeableness, representing traits such as sympathetic and user-friendly interactions. Although these numbers indicate dimensional dominance for certain traits, visuals from Figure 2 show a contiguous nature across most dimensions.\nThere might be various reasons behind this such as the interconnection of personality traits like Agreeableness and Conscientiousness overlapping in their behavioural expressions. Furthermore, Fine-Tunings can contribute towards not demonstrating extreme behaviours in a specific personality trait to maintain the balance."}, {"title": "Conclusion", "content": "This study systematically evaluates the personality traits of LLMs using established psychological questionnaires. By administering diverse tests varying in depth and length, we analyse the strengths and limitations of widely used LLMs from the Llama and OpenAI families. The findings reveal that models, whether from the same or different families, exhibit distinct personality traits and differences in dimensional dominance. For instance, GPT-4 models emphasise Agreeableness, while Llama models highlight Conscientiousness or Openness, reflecting variations in fine-tuning objectives and design goals. Additionally, traits like Extraversion and Agreeableness show high consistency, whereas Neuroticism yields more uncertain results, underscoring the need for careful questionnaire design to enhance test validity."}]}