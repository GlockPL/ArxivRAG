{"title": "Deep Feature Embedding for Tabular Data", "authors": ["Yuqian Wu", "Hengyi Luo", "Raymond S. T. Lee"], "abstract": "Tabular data learning has extensive applications in deep learning but its existing embedding techniques are limited in numerical and categorical features such as the inability to capture complex relationships and engineering. This paper proposes a novel deep embedding framework with leverages lightweight deep neural networks to generate effective feature embeddings for tabular data in machine learning research. For numerical features, a two-step feature expansion and deep transformation technique is used to capture copious semantic information. For categorical features, a unique identification vector for each entity is referred by a compact lookup table with a parameterized deep embedding function to uniform the embedding size dimensions, and transformed into a embedding vector using deep neural network. Experiments are conducted on real-world datasets for performance evaluation.", "sections": [{"title": "Introduction", "content": "Tabular data remains the most common and valuable data for a wide spectrum of businesses to date, including retail, finance, recommendation, fraud detection, healthcare [2,3,20] and etc. Tabular data learning refers to the predictive modeling of tabular data [7,8], which is highly structured with each row corresponding to an instance and each column to a specific feature. Real-world tabular data typically involves a fixed set of columns, with both numerical and categorical features. One of the main characteristics of tabular data is that these features are heterogeneous. Specifically, each numerical feature is a scalar value, quantitatively measuring a specific dimension, whereas each categorical feature is an ordinal identifier, uniquely denoting a specific entity, e.g., words in NLP, products in recommendation [1,3], and so on. Due to the heterogeneity of features, and particularly, possible large cardinality of categorical features, e.g., millions or even billions of user or product IDs, traditional learning models such as SVM and GBDT can not effectively handle tabular data."}, {"title": "Related Work", "content": "Deep Tabular Learning. Tabular data [21, 22, 24-26] is a data type used in many real-world applications, e.g., recommendation [1,3] and healthcare [2, 20], to extract insights from tabular data for advanced analytics [2, 7-9]. Tabular data learning is mostly shallow models, such as GBDT, while they scale poorly to categorical features of high cardinality. There are many deep models have been proposed for tabular data in recent years, which can be broadly categorized into enhanced-DNN [5], tree-like [22], attention-based [2, 7,9] and interaction-based [1-3, 13] DNNs. Enhanced DNNs propose enhancements to vanilla DNNs for effective tabular learning, such as disjunctive normal form in Net-DNF [5] and scaled exponential linear units in SNNs [22] to replace conventional linear feature extractors; Tree-like models pursued to copy the success of tree-based models by imitation, such as differentiable oblivious decision tree ensembles in NODE [24] and the integration of trivial neural networks as weak learners into iterative gradient boosting learning in GrowNet [21]; Following the success of attention-based models in various domains, several new attention mechanisms are proposed for tabular data, e.g., iterative selective attention on features in TabNet [7] and multi-head gated attention in ARM-Net [2]. Although various architectures and mechanisms have been proposed for deep tabular learning, their success is to a large extent, contingent on input feature embedding, which determines the amount of information to be passed to these models.\nNumerical Feature Embedding. Numerical embedding is the core of deep tabular learning, which enhances the semantic meaning of scalar feature value of each numerical feature for subsequent learning. The existing numerical embedding techniques can be categorized into three major groups: handcrafted embedding [4, 10], linearly-scaled embedding [1,2], and discretization [11]. Many works such as Wide & Deep [4] and SNNs [24] directly pass the original feature to DNNs. Then, works like YouTube deep ranking model [10] encode numerical features using several handcrafted functions. These works [1,2] use linearly-scaled embedding, which are efficient and general. There are also recent works proposed to discretize each numerical feature into a categorical feature and then embed it via lookup for effective embedding. For example, AutoDis [11] used soft discretize on each feature and calculate a weighted average of a fixed set of embeddings attached to this feature. These embedding via discretization often requires tremendous engineering efforts to decide the right techniques and hyperparameters for each step despite higher effectiveness. Our proposed deep numerical embedding, by contrast, is generic and effective, which can be used as an off-the-shelf module and trained end-to-end with deep models.\nCategorical Feature Embedding. Learned embedding is the core technique for passing categorical features to deep models [1\u20133, 13, 15]. Categorical feature embedding can represent many inputs, e.g., users [1,3], items [2, 15], words, or any other entities by learning a corresponding unique continuous vector. Since uniqueness is required to distinguish different entities, the number of embedding entries corresponds to the possible number of entities can lead to a large lookup table [15-17]. There are many recent works propose to reduce the embedding size, the number of embeddings by sharing lookup entries via hashing [12,14,15]. For instance, HashEmb [12] proposes to use multiple hash functions, each of which corresponds to a lookup table for learned weighted aggregation; Hybrid Hashing [14] uses embedding lookup for frequent entities and double hashing for less frequent ones for reducing the embedding size; and DHE [15] uses thousands of hash function to convert the categorical feature back into a continuous vector and use a DNN for deep transformation as the proposed deep embedding. However, hashing inevitably leads to collisions resulting in less effective embedding; and hashing typically requires great engineering efforts and many hyperparameters to be tuned and non-negligible extra computation [26]. Our proposed deep embedding for categorical features circumvents these issues by following a more general two-step design, where the first feature identification step requires considerably fewer parameters, and the second deep transformation makes the final embedding more effective through collaborative learning effect."}, {"title": "Problem Formulation", "content": "This section is to formulate the deep feature embedding problem for tabular data learning. The predictive modeling is to learn a mapping function \\(f : x \\rightarrow y\\), where x is the feature vector, and y is the prediction target. The feature vector x consists of M numerical features and N categorical features:\n\\(x = [x_1^{(n)}, x_2^{(n)},...,x_M^{(n)}, x_1^{(c)}, x_2^{(c)},...,x_N^{(c)}]\\) (1)\nwhere \\(x_i^{(n)} \\in R\\) is the i-th numerical feature, and \\(x_j^{(c)} \\in N\\) is the j-th categorical feature. Each numerical feature \\(x_i^{(n)}\\) is a real number, typically normalized into [0, 1] or N(0, 1); and each categorical feature \\(x_j^{(c)}\\) is a natural number that uniquely identifies an entity, e.g., a specific movie or product.\nFeature Embedding. Feature embedding is to encode each feature value separately into a corresponding d-dimensional continuous vector space for subsequent modeling. It can be defined by realizing mapping functions for respective features:\n\\(f^{(n)} : x_i^{(n)} \\rightarrow x_i^{(n)}, x_i^{(n)} \\in R^d\\) (2)\n\\(f^{(c)} : x_j^{(c)} \\rightarrow x_j^{(c)}, x_j^{(c)} \\in R^d\\)\nwhere \\(f_i^{(n)}\\) and \\(f_j^{(c)}\\) are the embedding functions for the i-th numerical feature and j-th categorical feature respectively. After embedding, both numerical and categorical features are standardized, and the resultant matrix \\(X = [x_1^{(n)},...,x_M^{(n)}, x_1^{(c)},...,x_N^{(c)}]\\) will then be forwarded to the subsequent neural networks for further modeling, e.g., capturing feature interactions [1-3]."}, {"title": "Deep Feature Embedding", "content": "This section introduces mainstream feature embedding methods for numerical and categorical features, discussing their strengths and weaknesses. Then, we present deep feature embedding techniques, analyzing their effectiveness, efficiency, and generality for deep tabular data learning."}, {"title": "Numerical Feature Embedding", "content": "Feature embedding for a numerical feature is to derive a deterministic function that maps a scalar feature value to a d-dimensional vector as formulated in Equation 2. Since numerical features in tabular data often carry distinct semantic meanings in different scales, the feature values are typically normalized before embedding, e.g., via min-max linear transformation [1,2] or z-score standardization [22].\nMost traditional learning models and many deep models [4, 10] directly use the normalized feature values as inputs, namely no embedding. While for more recent DNN-based models, the common practice is to embed each numerical feature [2,3,8,11,13] into continuous vector representations.\nDeep Embedding for Numerical Feature The proposed deep embedding framework is illustrated in Figure 1. It consists of two steps. Note that all numerical features are required to be normalized prior embedding.\nStep-1: Feature Expansion. Each input feature value \\(x^{(n)}\\) is first expanded into a d-dimensional feature vector:\n\\(x_i = x_i^{(n)} \\gamma_i + \\beta_i, i \\in R^d\\) (3)\nwhere \\(\\gamma_i, \\beta_i \\in R^d\\) are learned embedding sensitivity and embedding bias. In particular, each dimension of the output feature vector \u00c2\u00bf follows a different distribution: \\(E[\\hat{x}_{ik}] = \\gamma_{ik} E[x^{(n)}] + \\beta_{ik}\\) and \\(Var[\\hat{x}_{ik}] = \\gamma_{ik}^2 \\cdot Var[x^{(n)}]\\), i.e., the mean and variance of the input feature \\(x^{(n)}\\) are scaled and shifted by \\(\\gamma_{ik}\\) and \\(\\beta_{ik}\\), respectively. Sine each pair of \\(\\gamma_{ik}\\) and \\(\\beta_{ik}\\) are learned independently, \u00c2\u00bf allows for representing a single feature value \\(x^{(n)}\\) in d feature dimensions, with different biases and sensitivities. Further, in a way reminiscent of positional encoding, each embedding bias \\(B_i\\) is dedicated to a corresponding numerical feature, which learns the globally static representations across inputs for this feature. Experiment results showed that a simple effective embedding bias enhancement to the linearly-scaled approach can solely improve the fluency of numerical embedding.\nStep-2: Deep Transformation. After expanding into a d-dimension feature vector \u00c2\u00bf, we further propose to transform the embedding vector via a DNN:\n\\(x_i^{(n)} = f_i^{(n)}(x_i; w_i^{(n)}), x_i^{(n)} \\in R^d\\) (4)\nwhere the deep transformation \\(f_i^{(n)} : R^d \\rightarrow R^d\\) is paramterized by \\(w_i^{(n)}\\) with \\(n_w\\) parameters to be learned. Specifically, \\(f_i^{(n)}\\) is a l-layer feed-forward network (FFN) with residual connection [8] and the exp-centered (ExU) activation function [18].\nThe DNN \\(f_i^{(n)}\\) is introduced to further capture complex non-linear interactions among the expanded features. Thanks to the universal approximation capability of neural networks [2,8,19], such deep transformation will further increase the modeling capacity and improve the embedding effectiveness. We note that although additional parameters and computation are introduced, the embedding overhead is typically negligible as compared with the subsequent deep modeling. Further, the whole deep embedding process can be vectorized, which can be readily implemented in any platform and accelerated by modern hardware such as GPUs."}, {"title": "Categorical Feature Embedding", "content": "Categorical feature embedding as formulated in Equation 2 is to determine a mapping function from an integer identifier to a d-dimension vector. Essentially, any entities can be embedded into continuous vector representations, e.g., words, products, or even a range of a numerical feature as discussed in Section 4.1. Traditional learning models, such as SVM and GBDT, typically encode categorical features statically with no embedding, e.g., via one-hot or binary encoding. In contrast, categorical embedding standardizes the input for the subsequent DNN-based modeling [2,3,15-17], and the whole modeling pipeline can then be trained in an end-to-end manner. This section will present mainstream categorical embedding techniques and present the proposed categorical embedding.\nDeep Embedding for Categorical Feature Despite the computational efficiency and generality, the main problems with embedding lookup are that firstly, the parameter size of the lookup table can be huge; and secondly, embeddings are learned separately and in a shallow manner, i.e., by simple indexing. To make categorical embedding more parameter-efficient and effective, we propose deep categorical embedding with the following two steps and illustrate the deep embedding framework.\nStep-1: Entity Identification. Embedding each entity with an individual lookup entry is, to a large extent, inevitable for capturing the representations uniquely and effectively. Therefore, we also adopt an embedding lookup table for each categorical feature. While the lookup table here only needs to provide a unique identification vector for each entity. As a consequence, the lookup table can be much smaller, specifically, \\(E \\in R^{\\bar{d} \\times v}\\), with \\(\\bar{d} < d\\). The identification vector for \\(x_j^{(c)}\\) is then \\(x_j = E[x_j^{(c)}], x_j \\in R^{\\bar{d}}\\).\nStep-2: Deep Transformation. After obtaining the identification vector \\(x_j\\), we propose to adopt a similar deep transformation as for numerical features: \\(x_j^{(c)} = f_j^{(c)}(x_j; w_j^{(c)}), x_j^{(c)} \\in R^d\\), where \\(f_j^{(c)} : R^{\\bar{d}} \\rightarrow R^d\\) is the deep embedding function paramterized by \\(w_j^{(c)}\\) with \\(n_w\\) learnable parameters. The deep transformation is to firstly, restore the dimensionality back to a uniform embedding size d, and secondly, make the final embedding more effective with the strong modeling capacity of DNNs.\nIn essence, the deep transformation proposed here is a way to achieve model compression and collaborative learning via deep matrix factorization. Specifically, the conventional one-step embedding lookup is now factorized into two steps, where the first step only needs to learn a more parameter-efficient identification vector, and the second step is then to construct the final embedding with a shared DNN. The highly redundant lookup table can thus be mostly compressed into the DNN, and the embedding parameter size shrinks from \\(v_j \\cdot d\\) to \\(v_j \\cdot \\bar{d} + n_w\\). As the DNN is collaboratively learned and shared by all entities, the DNN embeddings can be more effective than simple individually-learned lookup ones. Typically, the distribution of the entities is highly uneven, i.e., mostly following a power-law distribution, and therefore, the embeddings of infrequent entities are less indexed and trained as for embedding lookup. While for the proposed two-step approach, the embeddings are mainly learned based on the shared DNN, and the knowledge can be transferred from other embeddings during training. On the downside, the deep transformation incurs extra computation at runtime. However, we note that the runtime computation can be considerably reduced by simply caching the embeddings of frequent entities, or, totally removed by reconstructing the entire lookup table once and for all via precomputation."}, {"title": "Experiments", "content": "Experimental Setup\nDataset The proposed deep embedding framework used five real-world datasets on representative domains, namely app recommendation (Frappe), movie recommendation (MovieLens), click-through rate prediction (Avazu, Criteo), healthcare (Diabetes130) for evaluation."}, {"title": "Overall Prediction Performance with Various Embedding Methods in ARM-Net Model", "content": "Experiments have used eight distinct embedding methods [1, 9-12, 21, 26] on ARM-Net model to evaluate across five real-world datasets. Based on the findings from Table 4, our embedding framework has consistently demonstrated outstanding performance across the majority of datasets. Particularly notable is the performance on the Frappe dataset, where our method (0.9855) outperforms the second-best approach (0.9803) by 0.52%, highlighting a significant margin of superiority. Despite Linearly-Scaled Embedding achieving the top result (0.8092) on the Criteo dataset, our proposed deep embedding approach (0.8090) still maintains competitiveness. This indicates that even when certain methods hold a slight advantage on specific datasets, our deep embedding approach remains effective in competing with them and even outperforms them on other datasets. We will delve deeper into the effectiveness and applicability of deep embedding methods in Section 5.3 and Section 5.5."}, {"title": "Comparing DL models and GBDT", "content": "We evaluate the performance of GBDT and four deep learning models using our feature embedding framework on five public datasets using AUC as a metric. The results are shown in Table 5. We found that the embedding framework models improves performance over the original model on most datasets. They also perform better than GBDT on some datasets, such as Frappe, MovieLens, and Criteo. For instance, on the Frappe dataset, ARM-Net embedded in the framework achieves an AUC of 0.9855, which is 0.30% higher than CatBoost's AUC of 0.9825, 1.48% and 0.56% respectively lower than XGBoost. Using the embedded framework, they outperform XGBoost by 0.15% and 0.4%. These findings show that our embedding framework enhances the information encoding and feature representation capabilities of deep learning models for tabular data, guiding the selection of appropriate models for different tasks and scenarios. It is worth noting that CatBoost achieved the best performance on the Diabetes130 dataset with fewer features; we attribute this to the bias of neural networks towards overly smooth solutions and the impact of uninformative features on MLP-like neural networks more significantly [24].\nIn summary, our study showcases the embedding framework's ability to enhance deep learning model performance in diverse tabular data scenarios. We"}, {"title": "The Impact of Deep Transformation Layer Number on Model Performance", "content": "We studied the impact of changing the number of deep transformation layers (each with 500 neurons) on model performance, as shown in Figure 4. In the Frappe dataset, two layers provide the best balance of performance, as more layers can lead to overfitting by capturing noise. In the Diabetes130 dataset containing fewer features, increasing the number of transformation layers cannot significantly improve the representation ability, but will introduce too much noise. Therefore, we recommend designing model depth based on dataset characteristics for optimal performance."}, {"title": "Ablation study", "content": "This study conducted an ablation experiment to evaluate the performance of original deep learning models compared to models incorporating embedding frameworks. The experiment was conducted on five different datasets, namely Frappe, MovieLens, Avazu, Criteo, and Diabetes130 with results listed in Table 5. It demonstrate that the models with embedding frameworks consistently outperformed the original models across most datasets. Specifically, on the Frappe dataset, ARM-Net with our embedding framework achieved an AUC of 0.9855, significantly higher than the accuracy of 0.9766 obtained by original ARM-Net. On the MovieLens dataset, DCN and CIN with our framework attained AUCs of 0.9553 and 0.9516, respectively, surpassing the AUCs of original DCN (0.9401) and CIN (0.9401). Similarly, on the Criteo dataset, DCN with our embedding framework exhibited an AUC of 0.8083, outperforming the AUC of original DCN (0.7959). Lastly, on the Diabetes130 dataset, DCN with the embedding framework demonstrated an AUC of 0.6844, outshining the AUC of original DCN (0.6765).\nOverall, these findings showed that models incorporating embedding frameworks generally outperform the original models on most datasets, with significant performance improvements (increases of over 1%) observed in some cases, which indicates that embedding frameworks have a positive impact on information encoding and feature representation to offer an effective approach for deep learning models performance optimization. Notably, while models with embedding frameworks generally outperform the original models, there are instances where their performance is comparable or slightly inferior. The effect of Embedding Size is also examined with ARM-Net model on Frappe dataset is illustrated in Figure 3. It showed that the benefits of incorporating embedding frameworks into deep learning models across multiple datasets."}, {"title": "Conclusion", "content": "This paper proposed a novel deep embedding framework for tabular data to overcome limitations in handling numerical and categorical features. It used deep neural networks to enhance the effectiveness, efficiency, and generalization of feature embeddings with a two-step feature expansion and deep transformation technique for numerical features, and a parameter-efficient deep factorization embedding method for categorical features. Experimental results supported the efficacy of the proposed framework. Future research directions include exploring the embedding module optimization mechanisms methods for different functional transformations to each feature to expand the scope of diverse datasets and comparative analyses with other machine learning algorithms. These can further understand embedding's importance and potential in tabular deep learning."}]}