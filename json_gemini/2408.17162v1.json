{"title": "Deep Feature Embedding for Tabular Data", "authors": ["Yuqian Wu", "Hengyi Luo", "Raymond S. T. Lee"], "abstract": "Tabular data learning has extensive applications in deep learning but its existing embedding techniques are limited in numerical and categorical features such as the inability to capture complex relationships and engineering. This paper proposes a novel deep embedding framework with leverages lightweight deep neural networks to generate effective feature embeddings for tabular data in machine learning research. For numerical features, a two-step feature expansion and deep transformation technique is used to capture copious semantic information. For categorical features, a unique identification vector for each entity is referred by a compact lookup table with a parameterized deep embedding function to uniform the embedding size dimensions, and transformed into a embedding vector using deep neural network. Experiments are conducted on real-world datasets for performance evaluation.", "sections": [{"title": "1 Introduction", "content": "Tabular data remains the most common and valuable data for a wide spectrum of businesses to date, including retail, finance, recommendation, fraud detection, healthcare [2,3,20] and etc. Tabular data learning refers to the predictive modeling of tabular data [7,8], which is highly structured with each row corresponding to an instance and each column to a specific feature. Real-world tabular data typically involves a fixed set of columns, with both numerical and categorical features. One of the main characteristics of tabular data is that these features are heterogeneous. Specifically, each numerical feature is a scalar value, quantitatively measuring a specific dimension, whereas each categorical feature is an ordinal identifier, uniquely denoting a specific entity, e.g., words in NLP, products in recommendation [1,3], and so on. Due to the heterogeneity of features, and particularly, possible large cardinality of categorical features, e.g., millions or even billions of user or product IDs, traditional learning models such as SVM and GBDT can not effectively handle tabular data."}, {"title": "2 Related Work", "content": "Deep Tabular Learning. Tabular data [21, 22, 24-26] is a data type used in many real-world applications, e.g., recommendation [1,3] and healthcare [2, 20], to extract insights from tabular data for advanced analytics [2, 7-9]. Tabular data learning is mostly shallow models, such as GBDT, while they scale poorly to categorical features of high cardinality. There are many deep models have\nbeen proposed for tabular data in recent years, which can be broadly categorized\ninto enhanced-DNN [5], tree-like [22], attention-based [2, 7,9] and interaction-\nbased [1-3, 13] DNNs. Enhanced DNNs propose enhancements to vanilla DNNs\nfor effective tabular learning, such as disjunctive normal form in Net-DNF [5]\nand scaled exponential linear units in SNNs [22] to replace conventional linear\nfeature extractors; Tree-like models pursued to copy the success of tree-based\nmodels by imitation, such as differentiable oblivious decision tree ensembles in\nNODE [24] and the integration of trivial neural networks as weak learners into\niterative gradient boosting learning in GrowNet [21]; Following the success of\nattention-based models in various domains, several new attention mechanisms\nare proposed for tabular data, e.g., iterative selective attention on features in\nTabNet [7] and multi-head gated attention in ARM-Net [2]. Although various\narchitectures and mechanisms have been proposed for deep tabular learning,\ntheir success is to a large extent, contingent on input feature embedding, which\ndetermines the amount of information to be passed to these models.\nNumerical Feature Embedding. Numerical embedding is the core of deep\ntabular learning, which enhances the semantic meaning of scalar feature value\nof each numerical feature for subsequent learning. The existing numerical em-\nbedding techniques can be categorized into three major groups: handcrafted\nembedding [4, 10], linearly-scaled embedding [1,2], and discretization [11]. Many\nworks such as Wide & Deep [4] and SNNs [24] directly pass the original feature to\nDNNs. Then, works like YouTube deep ranking model [10] encode numerical fea-\ntures using several handcrafted functions. These works [1,2] use linearly-scaled\nembedding, which are efficient and general. There are also recent works pro-\nposed to discretize each numerical feature into a categorical feature and then\nembed it via lookup for effective embedding. For example, AutoDis [11] used\nsoft discretize on each feature and calculate a weighted average of a fixed set\nof embeddings attached to this feature. These embedding via discretization of-\nten requires tremendous engineering efforts to decide the right techniques and\nhyperparameters for each step despite higher effectiveness. Our proposed deep\nnumerical embedding, by contrast, is generic and effective, which can be used as\nan off-the-shelf module and trained end-to-end with deep models.\nCategorical Feature Embedding. Learned embedding is the core technique\nfor passing categorical features to deep models [1\u20133, 13, 15]. Categorical feature\nembedding can represent many inputs, e.g., users [1,3], items [2, 15], words, or\nany other entities by learning a corresponding unique continuous vector. Since\nuniqueness is required to distinguish different entities, the number of embedding\nentries corresponds to the possible number of entities can lead to a large lookup\ntable [15-17]. There are many recent works propose to reduce the embedding size,\nthe number of embeddings by sharing lookup entries via hashing [12,14,15]. For\ninstance, HashEmb [12] proposes to use multiple hash functions, each of which\ncorresponds to a lookup table for learned weighted aggregation; Hybrid Hash-\ning [14] uses embedding lookup for frequent entities and double hashing for less\nfrequent ones for reducing the embedding size; and DHE [15] uses thousands of\nhash function to convert the categorical feature back into a continuous vector"}, {"title": "3 Problem Formulation", "content": "This section is to formulate the deep feature embedding problem for tabular data learning. The predictive modeling is to learn a mapping function f : x \u2192 y, where x is the feature vector, and y is the prediction target. The feature vector x consists of M numerical features and N categorical features:\n\nX = [x_1^{(n)}, x_2^{(n)},...,x_M^{(n)}, x_1^{(c)}, x_2^{(c)},...,x_N^{(c)}]\n\nwhere $x_i^{(n)} \\in \\mathbb{R}$ is the i-th numerical feature, and $x_j^{(c)} \\in \\mathbb{N}$ is the j-th categorical feature. Each numerical feature $x_i^{(n)}$ is a real number, typically normalized into [0, 1] or $\\mathcal{N}(0, 1)$; and each categorical feature $x_j^{(c)}$ is a natural number that uniquely identifies an entity, e.g., a specific movie or product.\nFeature Embedding. Feature embedding is to encode each feature value separately into a corresponding d-dimensional continuous vector space for subsequent modeling. It can be defined by realizing mapping functions for respective features:\n\nf^{(n)} : x^{(n)} \\rightarrow \\hat{x}^{(n)}, \\hat{x}^{(n)} \\in \\mathbb{R}^d\nf^{(c)} : x^{(c)} \\rightarrow \\hat{x}^{(c)}, \\hat{x}^{(c)} \\in \\mathbb{R}^d\n\nwhere $f^{(n)}$ and $f^{(c)}$ are the embedding functions for the i-th numerical feature and j-th categorical feature respectively. After embedding, both numerical and categorical features are standardized, and the resultant matrix X = [$\\hat{x_1^{(n)}},...,\\hat{x_M^{(n)}},\\hat{x_1^{(c)}},...,\\hat{x_N^{(c)}}$] will then be forwarded to the subsequent neural networks for further modeling, e.g., capturing feature interactions [1-3]."}, {"title": "4 Deep Feature Embedding", "content": "This section introduces mainstream feature embedding methods for numerical and categorical features, discussing their strengths and weaknesses. Then, we present deep feature embedding techniques, analyzing their effectiveness, efficiency, and generality for deep tabular data learning.\nStep-1: Feature Expansion. Each input feature value $x^{(n)}$ is first expanded into a d-dimensional feature vector:\n\n\\hat{x_i} = x_i^{(n)} \\gamma_i + \\beta_i, i \\in \\mathbb{R}^d\n\nwhere $\\gamma_i, \\beta_i \\in \\mathbb{R}^d$ are learned embedding sensitivity and embedding bias. In particular, each dimension of the output feature vector $\\hat{x_i}$ follows a different distribution: $\\mathbb{E}[\\hat{x}_{ik}] = \\gamma_{ik} \\mathbb{E}[x^{(n)}] + \\beta_{ik}$ and $\\text{Var}[\\hat{x}_{ik}] = \\gamma_{ik}^2 \\text{Var}[x^{(n)}]$, i.e., the mean and variance of the input feature $x^{(n)}$ are scaled and shifted by $\\gamma_{ik}$ and $\\beta_{ik}$, respectively. Sine each pair of $\\gamma_{ik}$ and $\\beta_{ik}$ are learned independently, $\\hat{x_i}$ allows for representing a single feature value $x^{(n)}$ in d feature dimensions, with different biases and sensitivities. Further, in a way reminiscent of positional encoding, each embedding bias $\\beta_i$ is dedicated to a corresponding numerical feature, which learns the globally static representations across inputs for this feature. Experiment results showed that a simple effective embedding bias enhancement to the linearly-scaled approach can solely improve the fluency of numerical embedding.\nStep-2: Deep Transformation. After expanding into a d-dimension feature vector $\\hat{x_i}$, we further propose to transform the embedding vector via a DNN:\n\n\\hat{x}^{(n)} = f^{(n)}(\\hat{x}_i; w^{(n)}), \\hat{x}^{(n)} \\in \\mathbb{R}^d\n\nwhere the deep transformation $f^{(n)}: \\mathbb{R}^d \\rightarrow \\mathbb{R}^d$ is paramterized by $w^{(n)}$ with $n_w$ parameters to be learned. Specifically, $f^{(n)}$ is a l-layer feed-forward network (FFN) with residual connection [8] and the exp-centered (ExU) activation function [18].\nThe DNN $f^{(n)}$ is introduced to further capture complex non-linear interactions among the expanded features. Thanks to the universal approximation capability of neural networks [2,8,19], such deep transformation will further increase the modeling capacity and improve the embedding effectiveness. We note that although additional parameters and computation are introduced, the embedding overhead is typically negligible as compared with the subsequent deep modeling. Further, the whole deep embedding process can be vectorized, which can be readily implemented in any platform and accelerated by modern hardware such as GPUs.\nStep-1: Entity Identification. Embedding each entity with an individual lookup entry is, to a large extent, inevitable for capturing the representations uniquely and effectively. Therefore, we also adopt an embedding lookup table for each categorical feature. While the lookup table here only needs to provide a unique identification vector for each entity. As a consequence, the lookup table can be much smaller, specifically, E \u2208 $\\mathbb{R}^{\\tilde{d} \\times v}$, with $\\tilde{d} < d$. The identification vector for x is then $x_j' = E[x]$, $x_j' \\in \\mathbb{R}^{\\tilde{d}}$.\nStep-2: Deep Transformation. After obtaining the identification vector $x_j'$, we propose to adopt a similar deep transformation as for numerical features:\n\\hat{x}_j^{(c)} = f^{(c)}(x_j'; w^{(c)}), \\hat{x}^{(c)} \\in \\mathbb{R}^d$, where $f^{(c)}: \\mathbb{R}^{\\tilde{d}} \\rightarrow \\mathbb{R}^d$ is the deep embedding function paramterized by $w^{(c)}$ with $n_w$ learnable parameters. The deep transformation is to firstly, restore the dimensionality back to a uniform embedding size d, and secondly, make the final embedding more effective with the strong modeling capacity of DNNs.\nIn essence, the deep transformation proposed here is a way to achieve model compression and collaborative learning via deep matrix factorization. Specifically, the conventional one-step embedding lookup is now factorized into two steps, where the first step only needs to learn a more parameter-efficient identification vector, and the second step is then to construct the final embedding with a shared DNN. The highly redundant lookup table can thus be mostly compressed into the DNN, and the embedding parameter size shrinks from v\u22c5d to v\u22c5 d + \u00f1w. As the DNN is collaboratively learned and shared by all entities, the DNN embeddings can be more effective than simple individually-learned lookup ones. Typically, the distribution of the entities is highly uneven, i.e., mostly following a power-law distribution, and therefore, the embeddings of infrequent entities are less indexed and trained as for embedding lookup. While for the proposed two-step approach, the embeddings are mainly learned based on the shared DNN, and the knowledge can be transferred from other embeddings during training. On the downside, the deep transformation incurs extra computation at runtime. However, we note that the runtime computation can be considerably reduced by simply caching the embeddings of frequent entities, or, totally removed by reconstructing the entire lookup table once and for all via precomputation."}, {"title": "5 Experiments", "content": "5.1 Experimental Setup\nDataset The proposed deep embedding framework used five real-world datasets on representative domains, namely app recommendation (Frappe), movie recommendation (MovieLens), click-through rate prediction (Avazu, Criteo), healthcare (Diabetes130) for evaluation. These dataset properties are summarized in\nTable 3.\n5.2 Overall Prediction Performance with Various Embedding Methods in ARM-Net Model\nExperiments have used eight distinct embedding methods [1, 9-12, 21, 26"}]}