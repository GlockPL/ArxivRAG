{"title": "Multi-scale Conditional Generative Modeling for Microscopic Image Restoration", "authors": ["Luzhe Huang", "Xiongye Xiao", "Shixuan Li", "Jiawen Sun", "Yi Huang", "Aydogan Ozcan", "Paul Bogdant"], "abstract": "The advance of diffusion-based generative models in recent years has revolution-ized state-of-the-art (SOTA) techniques in a wide variety of image analysis and synthesis tasks, whereas their adaptation on image restoration, particularly within computational microscopy remains theoretically and empirically underexplored. In this research, we introduce a multi-scale generative model that enhances con-ditional image restoration through a novel exploitation of the Brownian Bridge process within wavelet domain. By initiating the Brownian Bridge diffusion process specifically at the lowest-frequency subband and applying generative adversarial networks at subsequent multi-scale high-frequency subbands in the wavelet do-main, our method provides significant acceleration during training and sampling while sustaining a high image generation quality and diversity on par with SOTA diffusion models. Experimental results on various computational microscopy and imaging tasks confirm our method's robust performance and its considerable reduc-tion in its sampling steps and time. This pioneering technique offers an efficient image restoration framework that harmonizes efficiency with quality, signifying a major stride in incorporating cutting-edge generative models into computational microscopy workflows.", "sections": [{"title": "Introduction", "content": "Within the last decade, the landscape of image synthesis has been radically transformed by the advent of generative models (GMs) [58, 24, 57]. Among their broad success in various image synthesis applications, image restoration, including super-resolution, shadow removal, inpainting, etc, have caught much attention due to their importance in various practical scenarios. Image restoration aims to recover high-quality target image from low-quality images measured by an imaging system with assorted degradation effects, e.g., downsampling, aberration and noise. Numerous tasks in photography, sensing and microscopy can be formulated as image restoration problems, and therefore the importance of image restoration algorithms is self-evident in practical scenarios [27, 34, 66, 60].\nDue to the ill-posedness of most image restoration problems, the application of generative learning becomes crucial for achieving high-quality image reconstruction. The wide applications of deep learning (DL)-based generative models in image restoration began with the success of generative"}, {"title": "Related works", "content": "As an important branch of computational imaging, computational microscopy springs up in recent years and aims to restore high-quality, multi-dimensional images from low-quality, low-dimensional measurements, usually with under-resourced equipment. Since the first work on microscopy image super-resolution reported in 2017 [48], DL has enabled a wide spectrum of novel applications that were impossible with conventional optical technologies, e.g., microscopy image super-resolution surpassing the physical resolution limit of microscopic imaging systems [60], volumetric imaging reconstructing 3D sample volumes from sparse 2D measurements [68], and virtual image labelling to match the contrast conventionally provided by chemical or biological markers [49]. Compared to general image restoration in computational imaging, microscopy image restoration mainly differs in two aspects: (1) The degeneration process, including the transfer function, noise and aberration of the imaging system is generally complex, unknown and hard to measure precisely; and such degeneration process could vary significantly in real-world scenarios due to the variations of subjects, hardware and imaging protocols. (2) Strict pixel-wise correspondence between output and ground truth images and consistency with physical laws are generally emphasized [4]."}, {"title": "Generative models", "content": "GANs are well-known for generating high-qaulity, photorealistic samples rapidly [14, 16]. Through training a discriminator that tells ground truth images apart from fake images generated by the generator network, GANs outperformed traditional CNNs trained with hand-crafted, pixel-based structural losses such as L1 and L2 by providing a high-level, learnable perceptual objective. Conditional GANs such as Pix2Pix [27], pix2pix HD [63] and starGAN [8] have been successfully applied in a wide spectrum of image-to-image translation and image restoration tasks, including image colorization [44], style transfer [31], image deblurring [34], etc. Unsupervised image-to-image translation has also been extensively explored, such as cycleGAN [75], UNIT [38], DualGAN [72], etc. In the fields of biomedical and microscopy imaging, researchers have also explored the applications of GANs, e.g., reconstructing low-dose CT and MRI images [71, 21], denoising microscopy images [66], super-resolving diffraction-limited microscopy images [60], among others.\nAlternatively, transformer and related architectures have recently emerged and shown superior performance over convolutional neural networks (CNNs)-based GANs. Swin transformer [39] and SwinIR [37] have established a strong transformer-based baseline with competitive performance to CNNs. TransGAN substituted CNNs in the common GAN framework with transformers and improved the overall performance [29]. More recently, diffusion models (DMs) have been introduced and proved to be the state-of-the-art generative model in various image generation benchmarks [24, 45]. Dhariwal"}, {"title": "Methods", "content": "To address the aforementioned limitations, here we introduce a novel multi-scale conditional generative model (MSCGM) for image restoration based on multi-scale wavelet transform and Brownian bridge stochastic process. For one thing, multi-scale wavelet transform effectively and losslessly com-presses the spatial dimensions of conditional images, eliminating the lossy encoding process of current autoencoder-based DMs. Notably, our method does not involve the pre-training of autoencoders in competitive methods on a sufficiently large and diverse dataset sampled from the image domain. For another, Brownian bridge stochastic process incorporates the modelling of low-quality conditional image into both the forward and reverse diffusion process and better utilizes the information of the conditional images. Besides, we theoretically analyze the distributions of low- and high-frequency wavelet subbands and apply Brownian bridge diffusion process (BBDP) and GAN to the multi-scale generation of low- and high-frequency subbands, respectively. In sum, the contributions of this work are three-fold:\n1. We are the first to factorize the conditional image generation within multi-scale wavelet domains, establishing a theoretical groundwork for a multi-scale conditional generative modeling;\n2. Capitalizing on the unique distribution characteristics of wavelet subbands, we propose the innovative MSCGM, which seamlessly integrates BBDP and GAN;\n3. We evaluate the MSCGM on various image restoration tasks, demonstrating its superior perfor-mance in both sampling speed and image quality than competitive methods."}, {"title": "Preliminaries", "content": "The outstanding success and wide applications of score-based diffusion models have been witnessed in the past years. Generally, for a Gaussian process {xt, t = 1,\u2026, T} defined as:\nq(xt|xt\u22121) = N (xt; \u221a1 \u2013 \u03b2tXt\u22121, \u03b2tI), t = 1,\u2026 ,T,\n(1)\nthe denoising DM attempts to solve the reverse process by parameterizing the conditional reverse distribution as:\nP(Xt-1/Xt) = N (Xt;  \u221aat I),\n(2)\nHere at, \u03ac\u03c4, \u03b2\u03c4, \u03c3\u03c4 are constants, and e\u0473 is the network estimating the mean value of the reverse process. Despite the high image quality achieved by the denoising process, the total sampling steps T can be very large and make the sampling process time-consuming.\nTheorem 1. For a given error & between the generated distribution pe and the true distribution p, the sampling steps needed can be expressed by [20]:\nT = O(\u03b5\u00ae\u00b2\u03ba\u00b3),\n(3)\nwhere k is the condition number of the covariance matrix of p.\nTherefore, for highly non-Gaussian distributed images, e.g., microscopy images (please refer to Appendix C, where we theoretically and statistically demonstrate the high degree of non-Gaussianity of microscopy datasets), which tends to have high sparsity, resolution and contrast, standard diffusion models may not be practical due to their slow sampling speed and large sampling steps required for such distributions.\nTo overcome this limitation, we turned to multi-scale wavelet transform (as detailed in Appendix D), which offers an excellent latent space (i.e., wavelet domain) for generative modeling. The wavelet domain not only facilitates lossless compression but also provides low-frequency coefficients with near-Gaussian distributions. Consequently, we transform the diffusion process into the wavelet domain, thereby introducing a novel multi-scale wavelet-based generative model. It can be shown that the diffusion in wavelet domain is a dual problem to the original diffusion in the spatial domain. For a detailed explanation of this duality, please see Appendix E. Due to the distinct characteristics of wavelet coefficients in low- and high-frequency subbands (as detailed in Appendix C), we adopt different generative modeling approaches for the low- and high-frequency coefficients, marking a key innovation in our work. Specifically, while the low-frequency wavelet coefficients exhibit a Gaussian tendency, the high-frequency coefficients are sparse and non-Gaussian. Therefore, for the low-frequency coefficients, we employed the Brownian Bridge Diffusion Process (BBDP) [35], and for the high-frequency coefficients, we utilized a Generative Adversarial Network (GAN) based generative method."}, {"title": "Brownian bridge diffusion process", "content": "We leverage BBDP to better model the conditional diffusion process and apply it to image restoration. Image restoration tasks focus on the generation of the target image xo \u2208 RH\u00d7W\u00d7C from a conditional"}, {"title": "Multi-scale conditional generative model", "content": "Wavelet transform, with its theoretical details outlined in Appendix D, is characterized by an orthogo-nal transform matrix A \u2208 RN2 \u00d7 N\u00b2. The wavelet transform decomposes an image x \u2208 RN\u00b2 to one low-frequency (LL) subband x \u2208 R and remaining high-frequency subbandsXHER3N24\nDefinition 4 (Multi-scale wavelet decomposition of conditional image generation). With multi-scale wavelet transformation, we can reformulate the conditional probability distribution of x0 on y as\np(xo|y) = \u041f=1P(XH|X, Y)p(x|YL),\n(10)\nwhere S denotes the maximum scale and\n(\u0445\u043d, \u0445) = \u0410\u0445\u043e, (x\u00b2+1,x+1)T = Ax\u0131, k = 1, ...\n(11)\nDifferent from existing approaches, our method leverages BBDP and GANs to handle low- and high-frequency subbands at various scales respectively, and the schematic diagram of our model is illustrated in Fig. 2. For the coarsest level low-frequency subband \u00e6, due to the whitening effect of the low-frequency subband after wavelet transform, DMs can effectively and efficiently approximate p(xy) with fewer sampling steps, while generating diverse and photorealistic images. For another, though the conditional distribution of high-frequency subbands deviates from unimodal Gaussian distributions considerably, the multi-scale GAN is able to approximate their multi-modal distribution and sample the full-resolution images rapidly in a coarse-to-fine style. Since the BBDP at the coarsest level produces samples with good diversity and fidelity, the possibility of mode collapse commonly observed in pure GAN models can be minimalized."}, {"title": "Experiments", "content": "In this section, we first elucidate the design and training details of our method, as well as the prepa-ration of training and testing datasets. Then, we evaluate our method on various image restoration tasks in computational and microscopy imaging, and compare it with baseline methods. At the end of this section, we further perform ablation study to analyze the importance of essential components in MSCGM."}, {"title": "Experimental setup and implementation details", "content": "For the BBDP at the coarsest wavelet scale, we adapt the UNet architecture with multi-head attention layers as practiced in [45]. The number of sampling steps is set as 1000 for training. The Brownian"}, {"title": "Evaluation metrics", "content": "Peak Signal-to-Noise Ratio (PSNR) is commonly used to measure the quality of reconstruction in generated images, with higher values indicating better image quality. Structural Similarity Index Measure (SSIM) [64] assesses the high-level quality of images by focusing on changes in structural information, luminance, and contrast. Fr\u00e9chet Inception Distance (FID) score [23] is used in generative models like GANs to compare the distribution of generated images against real ones, where lower FID values imply images more similar to real ones, indicating higher quality."}, {"title": "Results and comparison", "content": "In this section, we first evaluate our method on two microscopy image restoration tasks with different samples and then on three natural image restoration tasks, encompassing various popular image restoration applications in computational imaging and computational microscopy. First, we apply our method to microscopy images, where the degradation process is complex and unknown. Given the pronounced contrast and sparsity inherent in microscopy images, it is crucial to use generative models capable of handling multi-modal distributions to adapt effectively to complex microscopy datasets. We utilize our method to perform super-resolution on microscopy images of nano-beads and HeLa cells, transforming diffraction-limited confocal images to achieve resolution beyond the optical diffraction limit and match the image quality of STED microscopy. Next, we assess the adaptability of our method to various image restorations tasks of natural images, including a 4\u00d7 super-resolution task on DIV2K dataset, a shadow removal task on natural images (ISTD dataset) and on a low-light image enhancement task on natural images (LOL dataset). Through comparison against competitive methods on various testbeds, we demonstrate the superior effectiveness and versatility of our method for image restoration.\nMicroscopy Image Super-resolution: We evaluate our method on microscopy image super-resolution tasks and compare it with existing generative models in this field. Unlike natural image super-resolution, the LR images are not downsampled but sampled at the same spatial frequency as the HR images. However, the LR images are limited by the optical diffraction limit, which is equivalent to a convolution operation on the HR images with a low-pass point spread function (PSF). We apply our method to confocal (LR) images of fluorescence nanobeads to evaluate its capability to overcome the optical diffraction limit (see Methods for sample and dataset details). "}, {"title": "Conclusion", "content": "To address the limitations of exsiting diffusion models in conditional image restoration, we demon-strate a novel generative model for image restoration based on Brownian bridge process and multi-scale wavelet transform. By factorizing the image restoration process in the multi-scale wavelet domains, we utilize Brownian bridge diffusion process and generative adversarial networks to recover different wavelet subbands according to their distribution properties, consequently accelerate the sampling speed significantly and achieve high sample quality and diversity competitive to diffusion model baselines.\nLimitations: In this work, while we mainly present multi-scale wavelet transformation using the common Harr bases, the future work could investigate designing more efficient wavelet or learned bases. Besides, the adversarial training employed in this study can be unstable and sensitive to training setups. In summary, our method provides a practical solution to issues with generative learning and facilitates the applications of advanced generative models on computational and microscopy imaging."}, {"title": "Score regularity for discretization", "content": "Theorem 5. Suppose the Gaussian distribution p = N(0, \u03a3) and distribution po from time reversed SDE, the Kullback-Leibler divergence between p and p\u014d relates to the covariance matrix \u2211 as:KL(p || Po) \u2264 \u03a8\u0442 + \u03a8\u2206t + \u03a8\u0442,\u2206t, with:\n\u03a8\u0442 = f (e-4T |Tr ((\u03a3 \u2013 Id)\u03a3)|),\n(14)\n\u03a8\u2206t = f (At |Tr (\u03a3\u22121 \u2013 \u03a3(\u03a3 \u2013 Id)\u22121log(\u03a3)/2 + (Id \u2013 \u03a3\u22121)/3)|),\n(15)\n\u03a8\u03c4,\u2206t = o(\u2206t + e-4T), \u2206t \u2192 0, T\u2192 +\u221e\n(16)\nwhere f(t) = t \u2013 log(1 + t) and d is the dimension of \u03a3, Tr (\u03a3) = d.\nProposition 1. For any \u20ac > 0, there exists T, \u2206t \u2265 0 such that:\n(1/d) (\u03a8\u0442 + \u03a8\u2206t) \u2264 \u20ac,\n(17)\nT/\u2206t < \u0421\u0454\u00af\u00b2\u043a\u00b3,\n(18)\nwhere C \u2265 0 is a universal constant, and \u043a is the condition number of \u03a3.\n[20] provides the proof outline for Theorem 5, based on the following Theorem 6,\nTheorem 6. Let N \u2208 N, \u2206t > 0, and T = N\u2206t. Then, we have that ~ N(\u03bc\u03bd, \u03a3\u00d1) with\n\u2211 = \u03a3 + exp(-4T)\u03a3\u00ce + \u2206t\u03a8\u2191 + (\u2206t)\u00b2RT,\u2206t,\n(19)\n\u03bc\u03bd = \u03bc + exp(-2T)\u03bc\u03c4 + Atef + (At)\u00b2 T,A,\n(20)\nwhere \u2211\u00ce, \u03a8\u00ce, RT,\u2206t \u2208 Rd\u00d7d, \u00b5T, e\u00ce, rT,\u2206t \u2208 Rd, and ||RT,\u25b3t|| + ||rT,\u25b3t|| < R, not dependent on T > 0 and \u2206t > 0. We have that\n\u03a3\u00ce = \u2212(\u03a3 \u2013 Id)(\u03a3\u03a3\u22121)2,\n(21)\n\u2191 = Id - 22 (\u03a3 \u2013 Id)-1log(\u03a3) + exp(-2T)\u03a8.\n(22)\nIn addition, we have\n\u03bc\u03c4 = \u2212\u03a3-1\u03a4\u03a3\u03bc,\n(23)\n-1\ne\u00ce = {\u221221\u22121 -22-1 - \u03a3(\u03a3 - Id) - log()} (\u03a3 \u2013 Id) -\u00b9 log(\u03a3) \u03bc + exp(-2T)\u03bc\u03c4,\n(24)\nwith \u03a8, \u00b5bounded and not dependent on T.\nTheorem 7. Suppose that \u2207 log pt(x) is 42 in both t and x such that:\nsup ||\u00b2 log pt(x)|| \u2264 K,\n||dt\u2207log pt (x)|| \u2264 Me-at||x||\n(25)\nfor some K, M, a > 0. Then, ||\u0440 - Po||\u0433v < \u03a8\u0442 + \u03a8\u2206t + \u03a8\u0442,\u2206t, where:\n\u03a8\u0442 = \u221a2e-T KL (p || N(0, Id))1/2\n(26)\n6\u221aAt [1 + Ep (||x|14)1/4] [1 + K + M (1 + 1/20)1/2]\n(27)\n\u03a8T,At = 0 (\u221aAt+e-T)\n(28)\nTheorem 7 generalizes Theorem 5 to non-Gaussian processes. Please refer to [20] for the complete proof."}, {"title": "Characteristics of high and low frequency coefficients in the wavelet domain", "content": "In an image, pixel intensities are represented as random variables, with adjacent pixels exhibiting correlation due to their spatial proximity. This correlation often follows a power-law decay:\nC(d) =,\n(29)\nwhere C(d) is the correlation between pixels separated by distance d, and a and \u03b2 characterize the rate of decay.\nThe wavelet transform (i.e., Haar wavelet transform), particularly its down-sampling step, increases the effective distance d among pixels, thereby reducing their original spatial correlation. This reduction is crucial for applying the generalized Central Limit Theorem [51, 67, 11, 3], which requires that the individual variables (pixels, in this case) are not strongly correlated.\nAt scale k in the wavelet decomposition, the low-frequency coefficients, Xk, representing the average intensity over nk pixels, are calculated as:\nXk = (X1 + X2 + . . . + Xnk),\n(30)\nwhere ne is the number of pixels in each group at scale k.\nAs the scale increases, the effect of averaging over larger groups of pixels, combined with the reduced correlation due to down-sampling, leads to a scenario where the generalized Central Limit Theorem can be applied. Consequently, the distribution of X tends towards a Gaussian distribution:\n\u03a7\u03ba\u039d(\u03bc\u03ba,\u03ba),\n(31)\nwhere \u03bc\u03b5 and \u03c3\u03b5 are the mean and variance of the averaged intensities at scale k, respectively. This Gaussian tendency becomes more pronounced at higher scales due to the combination of reduced pixel correlation and the averaging process."}, {"title": "Sparsity and non-Gaussianity of high-frequency coefficients", "content": "High-frequency coefficients, when analyzed through wavelet transform, exhibit a distinct property of sparsity, characterized by a majority of wavelet coefficients being near or at zero, with only a sparse representation of significant non-zero coefficients. This sparsity highlights the efficiency of wavelet transforms in encoding signal details and abrupt changes. Furthermore, these high-frequency components often deviate from Gaussian distributions, tending towards leptokurtic distributions [13] with higher peaks and heavier tails. This non-Gaussian nature suggests a concentration of energy in fewer coefficients and is crucial in applications like signal denoising and compression, where recognizing and preserving these vital characteristics is paramount.\nL\nIn the following proposition, we theoretically show that the conditional distribution of xon x exhibits highly non-Gaussian properties and yields sparse samples. For a given image \u00e6 and threshold t, the sparsity of its high-frequency coefficients at k-scale is defined as:\nk\ns(x) =,\n(32)\nHere |||| is the norm counting the number of 1s in the vector. In this way, we could estimate the expected sparsity of the true marginal distribution p(x). Considering that the LL coefficients with approximate Gaussian distribution given the whitening effect of wavelet decomposition, we have the following proposition.\nProposition 2. For a sufficiently large k, if the expected sparsity of \u00e6\u2081 has a lower bound a\nE(s(x)) \u2265 \u03b1,\n(33)\nwhere a \u2208 [0,1]. Then the conditional expected sparsity of xon x is bounded by\nk\nE(s(x)x) \u2265\u03b1 - \u03b5,\n(34)\nwhere \u025b > 0 is a small positive number determined by k.\nProof. According to Eq. 31, for a sufficiently large k we could assume that\n|p(x) - fk(x)dx \u2264 \u025b,\n(35)\nwhere f(x) is the PDF of standard Gaussian distribution. Notice that\nE(s(x))\n=/ s(x4)p(s(x)=x*)p(x)dx{ds\n= // B(s(x)|x)p(x)dx \u2265 a\n(36)\n(37)\nSince s is a bounded function in [0, 1], E(s(x)) has an uniform lower bound with respect to all x, denoted as a'. In other words, there exists a' \u2208 [0, 1] such that\nE(s(x)|x) \u2265 a', \u2200x\n(38)\nWe can get\nE(s(x)/xp(x)dx\n=/ E(s(x)|x)p(x)dx\n=/ E(s(x)|x)f(x)dx\n+/E(s(x)|x)(p(x) - f(x))dx\n(39)\n> \u03b1'"}, {"title": "Quantifying Non-Gaussianity of datasets", "content": "Third- and fourth-order sample cumulants, i.e., skewness and kurtosis, to quantify the non-Gaussianity of certain sample distributions [15]. The non-Gaussianity of high-frequency subbands can be evidenced by the kurtosis plot with respect to wavelet scales in Fig. 6. The kurtosis of high-frequency subbands of microscopy images increases with the wavelet scales, showing the high non-Gaussianity of the distribution of high-frequency coefficients.\nSkewness is a measure of the asymmetry of the probability distribution of a real-valued random variable. It quantifies how much the distribution deviates from a normal distribution in terms of asymmetry. The skewness value can be positive, zero, negative, or undefined. In a perfectly symmetrical distribution, skewness is zero. Positive skewness indicates a distribution with an extended tail on the right side, while negative skewness shows an extended tail on the left side.\nThe mathematical formula for skewness is given by:\nY1= E(X)\n(41)\nwhere X is the random variable, u is the mean of X, o is the standard deviation of X, and E denotes the expected value.\nThe greater the absolute value of the skewness, the higher the degree of non-Gaussianity in the distribution.\nKurtosis is a measure of the \"tailedness\" of the probability distribution of a real-valued random variable. It provides insights into the shape of the distribution's tails and peak. High kurtosis in a data set suggests a distribution with heavy tails and a sharper peak (leptokurtic), while low kurtosis indicates a distribution with lighter tails and a more flattened peak (platykurtic). Kurtosis is often compared to the normal distribution, which has a kurtosis of 3 (excess kurtosis of 0)."}, {"title": "Wavelet transform", "content": "Wavelet transforms are derived from a single prototype function known as the 'mother wavelet'. This function undergoes various scaling and translation processes to generate a family of wavelets. The general form of a wavelet function (x), derived from the mother wavelet, is expressed as:\n\u03c8\u03b1,\u044c(x) =\u03c8,\n(43)\nwhere a, b \u2208 R, a \u2260 0, and x \u2208 D, with a and b representing scaling and translation parameters, respectively, and D being the domain of the wavelets."}, {"title": "Multiresolution analysis (MRA)", "content": "MRA is crucial in the Wavelet Transform [28, 47]. It involves constructing a basic functional basis in a subspace Vo within L\u00b2(R) and then expanding this basis through scaling and translation to cover the entire space L2 (R) for multiscale analysis.\nFor each k \u2208 Z and k \u2208 N, we define the scale function space as Vk = {f|f is restricted to (2-kl, 2-k (1+1)) for all l = 0, 1, . . ., 2k \u2013 1 and vanishes elsewhere}. Each space Vk encompasses a dimension of 2k, with each subspace Vi nested within Vi+1:\nVo V1 V2 C... Vn....\n(44)\nUsing a base function (x) in Vo, we can span Vk with 2n functions derived from f(x) through scaling and translation:\nf(x) = 2k/2(2kx \u2212 1), 1 = 0,1,..., 2k \u2212 1.\n(45)\nThese functions, \u03c6\u03b9(x), are known as scaling functions and they project any function into the approximation space Vo. The orthogonal complement of Vk in Vk+1 is the wavelet subspace Wk, satisfying:\nVk Wk = Vk+1, Vk Wk.\n(46)"}, {"title": "Wavelet decomposition and reconstruction", "content": "The Discrete Wavelet Transform (DWT) provides a multi-resolution analysis of signals, useful in various applications [18, 19, 69]. For a discrete signal f[n], DWT decomposes it into approximation coefficients cA and detail coefficients cD using the scaling function (x) and the wavelet function (x), respectively:\nCA[k] = \u2211h[n - 2k] f[n],\n(50)\nn\ncD[k] = \u2211g[n \u2013 2k] f[n],\n(51)\nwhere h[n] and g[n] are the low-pass and high-pass filters, respectively. This decomposition process can be recursively applied for deeper multi-level analysis.\nReconstruction of the signal f' [n] from its wavelet coefficients uses inverse transformations, employ-ing synthesis filters ho[n] and go[n]:\nf'[n] = \u2211 cA[k] ho[n \u2212 2k] + cD[k] \u00b7 go[n \u2013 2k],\n(52)\nwhere the synthesis filters are typically the time-reversed counterparts of the decomposition filters. In multi-level decompositions, reconstruction is a stepwise process, beginning with the coarsest approxi-mation and progressively incorporating higher-level details until the original signal is reconstructed."}, {"title": "Haar wavelet transform", "content": "The Haar wavelet [59], known for its simplicity and orthogonality, is a fundamental tool in digital signal processing. Its straightforward nature makes it an ideal choice for a variety of applications, which is why we have incorporated it into our project. The discrete wavelet transform (DWT) using Haar wavelets allows for the efficient decomposition of an image into a coarse approximation of its main features and detailed components representing high-frequency aspects. This process, enhanced by multi-resolution analysis (MRA), facilitates the examination of the image at various scales, thereby uncovering more intricate details.\nThe mathematical representation of the Haar wavelet and its scaling function is as follows:\n{,\n(t) = -1 if 0.5 < t < 1,\n(53)\n{,\n(54)"}, {"title": "Duality proof", "content": "For the Score-based Generative Model (SGM) [58, 24, 57], the forward/noising process is mathemat-ically formulated as the Ornstein-Uhlenbeck (OU) process. The general time-rescaled OU process is expressed as:\ndXt = -g(t)2X+dt + \u221a2g(t)dBt.\n(59)\nHere, (Xt)t\u2208[0,1] represents the noising process starting with Xo sampled from the data distribution. (Bt)t\u2208[0,T] denotes a standard d-dimensional Brownian motion. The reverse process, X, is defined such that (X) t\u2208 [0,T] = (XT\u2212t)t\u2208[0,T]. Assuming g(t) = 1 in standard diffusion models, the reverse process is:\ndX = (X + 2\u2207 log pr\u2212t(X+\u00af)) dt + \u221a2dBt.\n(60)\nHere, pt is the marginal density of Xt, and \u2207 log pt is the score. To revert X0 from XT via the time-reversed SDE, accurate estimation of the score log pt at each time t is essential, alongside minimal error introduction during SDE discretization."}, {"title": "Generative modeling in wavelet domain", "content": "Consider X as the image vector in the spatial domain. The discrete wavelet transform (DWT) [54, 22] of X can be expressed as:\nX = AX, X \u2208 Rd.\nHere, A represents the discrete wavelet transform matrix, which is orthogonal, satisfying AAT = I. Various forms of A are utilized in practice, such as Haar wavelets.\nIn the context of score-based generative modeling, we consider the forward (or noising) process, which can be formulated by the Ornstein-Uhlenbeck (OU) process. This is mathematically described as:\ndXt = -x(t)2X+dt + \u221a\u221a2y(t)dBt,\n(62)\nwhere Bt is a standard d-dimensional Brownian motion. Upon applying DWT to Xt, the transformed Xt also follows the OU process:\ndx = -x(t)2Xdt + \u221a2x(t) AdBt, X = AX0.\n(63)\nDefining B\u2081 = ABt, which also behaves as a standard Brownian motion. If Xo is sampled from a distribution p, then Xo originates from the distribution\nq = Ta#p,\n(64)\nwhere Ta denotes the linear transformation operation by A and # represents the pushforward operation. Consequently, we have\n\u011d(x) = p(Ax).\nLet pt be the density distribution of X\u2081 and \u011dt that of Xt. Then,\nqt = Ta#pt, Q(x) = pt(Ax).\nDefine the score functions for both processes as:\nSt = log pt,\n(67)\nThese functions are related by:\nrt(x) =\n= Ast(ATx).\n(68)\nFor the reverse processes denoted as + and, assuming y(t) = 1, they are given by:\ndx = (X + 2sT-t(X+)) dt + \u221a2dBt,\n(69)\nHere, Bt = ABt. Exploring the second SDE:\ndx = (x+2r-t(x)) dt + \u221a2dBt\n=(x+2AST-t(ATX)) dt + \u221a2dBt\n(70)"}, {"title": "Posterior distribution of Brownian bridge diffusion model", "content": "Brownian bridge process can prove to be Markovian and hence defined alternatively by its one-step forward process. The one-step forward process q(xtxt-1, y) can be derived as:\n1\nq(xt Xt-1, Y)=N(1-mtxt-1+(mt-1)y, dt-1). (73)\nHere St\\t-1 = 8t - St-1 (1-mt-1)2 and mt = .\n(1-mt)\nThe reverse process can be derived by Bayesian formula and shown to be a Gaussian process with mean \u00b5'(xt, xo, y) and variance \u0431\u0406:\nP(XtXt-1, Y)p(xt-1|X0, 2 Y)\nP(Xt-1|Xt, X, Y) = N(xt-1; \u03bc\u03b5(xt, xo, y), \u03b4\u03af\u0399),\n(74)\n\u03bc'\u03b5(xt, x0,y) =+(mt-1St-10 (75)\nStt-1-1\n(76)\nUtilizing the estimate of xo by ee in Eq. 5, we could eliminate xo in Eq. 75 and rewrite Eq. 75 as [35]:\n\u03bc'\u03b5(x, y) =+\n= Cxtxt + Cyty \u2013 Cet\u22080(xt, Y, t),\n(77)\n(78)"}, {"title": "Training and sampling algorithms", "content": "Algorithm 1 Training of BBDP\n1: repeat\n2: Xo, Y ~ q(x0, y)\n3: t ~ Uniform([1,\uff65\uff65\uff65,T])\n4: \u20act ~ N (0, I)\n5: Take gradient descent step on\nVol||mt(y - xo) + \u221adtet \u2013 Eo(xt, y, t)||2\n6: until converged\nAlgorithm 2 Sampling\n1: Sample y~ q(y)\n2: Wavelet transform S times to get {Y, YH,\u2026\u2026, YH}\n3: for t = T, T \u2013 1,..., 1 do\n4: z ~ N (0, I) if t > 1, else z = 0\n5: X-1,L = CxtX,L + CytY - Ceto(x,L, Y, t) + \u221ad\u0131z\n6: end for\n7: x = x,L\n8: for k = S, S \u2013 1,\uff65\uff65\uff65, 1 do\n9: x = G(x, y, z)\n10: XL = A-1(x)\n11: end for\n12: Return x = x"}, {"title": "Datasets and implementation details", "content": "For super-resolution experiments on DIV2K"}, {"title": "Multi-scale Conditional Generative Modeling for Microscopic Image Restoration", "authors": ["Luzhe Huang", "Xiongye Xiao", "Shixuan Li", "Jiawen Sun", "Yi Huang", "Aydogan Ozcan", "Paul Bogdant"], "abstract": "The advance of diffusion-based generative models in recent years has revolution-ized state-of-the-art (SOTA) techniques in a wide variety of image analysis and synthesis tasks, whereas their adaptation on image restoration, particularly within computational microscopy remains theoretically and empirically underexplored. In this research, we introduce a multi-scale generative model that enhances con-ditional image restoration through a novel exploitation of the Brownian Bridge process within wavelet domain. By initiating the Brownian Bridge diffusion process specifically at the lowest-frequency subband and applying generative adversarial networks at subsequent multi-scale high-frequency subbands in the wavelet do-main, our method provides significant acceleration during training and sampling while sustaining a high image generation quality and diversity on par with SOTA diffusion models. Experimental results on various computational microscopy and imaging tasks confirm our method's robust performance and its considerable reduc-tion in its sampling steps and time. This pioneering technique offers an efficient image restoration framework that harmonizes efficiency with quality, signifying a major stride in incorporating cutting-edge generative models into computational microscopy workflows.", "sections": [{"title": "1 Introduction", "content": "Within the last decade, the landscape of image synthesis has been radically transformed by the advent of generative models (GMs) [58, 24, 57]. Among their broad success in various image synthesis applications, image restoration, including super-resolution, shadow removal, inpainting, etc, have caught much attention due to their importance in various practical scenarios. Image restoration aims to recover high-quality target image from low-quality images measured by an imaging system with assorted degradation effects, e.g., downsampling, aberration and noise. Numerous tasks in photography, sensing and microscopy can be formulated as image restoration problems, and therefore the importance of image restoration algorithms is self-evident in practical scenarios [27, 34, 66, 60].\nDue to the ill-posedness of most image restoration problems, the application of generative learning becomes crucial for achieving high-quality image reconstruction. The wide applications of deep learning (DL)-based generative models in image restoration began with the success of generative"}, {"title": "2 Related works", "content": "As an important branch of computational imaging, computational microscopy springs up in recent years and aims to restore high-quality, multi-dimensional images from low-quality, low-dimensional measurements, usually with under-resourced equipment. Since the first work on microscopy image super-resolution reported in 2017 [48], DL has enabled a wide spectrum of novel applications that were impossible with conventional optical technologies, e.g., microscopy image super-resolution surpassing the physical resolution limit of microscopic imaging systems [60], volumetric imaging reconstructing 3D sample volumes from sparse 2D measurements [68], and virtual image labelling to match the contrast conventionally provided by chemical or biological markers [49]. Compared to general image restoration in computational imaging, microscopy image restoration mainly differs in two aspects: (1) The degeneration process, including the transfer function, noise and aberration of the imaging system is generally complex, unknown and hard to measure precisely; and such degeneration process could vary significantly in real-world scenarios due to the variations of subjects, hardware and imaging protocols. (2) Strict pixel-wise correspondence between output and ground truth images and consistency with physical laws are generally emphasized [4]."}, {"title": "2.2 Generative models", "content": "GANs are well-known for generating high-qaulity, photorealistic samples rapidly [14, 16]. Through training a discriminator that tells ground truth images apart from fake images generated by the generator network, GANs outperformed traditional CNNs trained with hand-crafted, pixel-based structural losses such as L1 and L2 by providing a high-level, learnable perceptual objective. Conditional GANs such as Pix2Pix [27], pix2pix HD [63] and starGAN [8] have been successfully applied in a wide spectrum of image-to-image translation and image restoration tasks, including image colorization [44], style transfer [31], image deblurring [34], etc. Unsupervised image-to-image translation has also been extensively explored, such as cycleGAN [75], UNIT [38], DualGAN [72], etc. In the fields of biomedical and microscopy imaging, researchers have also explored the applications of GANs, e.g., reconstructing low-dose CT and MRI images [71, 21], denoising microscopy images [66], super-resolving diffraction-limited microscopy images [60], among others.\nAlternatively, transformer and related architectures have recently emerged and shown superior performance over convolutional neural networks (CNNs)-based GANs. Swin transformer [39] and SwinIR [37] have established a strong transformer-based baseline with competitive performance to CNNs. TransGAN substituted CNNs in the common GAN framework with transformers and improved the overall performance [29]. More recently, diffusion models (DMs) have been introduced and proved to be the state-of-the-art generative model in various image generation benchmarks [24, 45]. Dhariwal"}, {"title": "3 Methods", "content": "To address the aforementioned limitations, here we introduce a novel multi-scale conditional generative model (MSCGM) for image restoration based on multi-scale wavelet transform and Brownian bridge stochastic process. For one thing, multi-scale wavelet transform effectively and losslessly com-presses the spatial dimensions of conditional images, eliminating the lossy encoding process of current autoencoder-based DMs. Notably, our method does not involve the pre-training of autoencoders in competitive methods on a sufficiently large and diverse dataset sampled from the image domain. For another, Brownian bridge stochastic process incorporates the modelling of low-quality conditional image into both the forward and reverse diffusion process and better utilizes the information of the conditional images. Besides, we theoretically analyze the distributions of low- and high-frequency wavelet subbands and apply Brownian bridge diffusion process (BBDP) and GAN to the multi-scale generation of low- and high-frequency subbands, respectively. In sum, the contributions of this work are three-fold:\n1. We are the first to factorize the conditional image generation within multi-scale wavelet domains, establishing a theoretical groundwork for a multi-scale conditional generative modeling;\n2. Capitalizing on the unique distribution characteristics of wavelet subbands, we propose the innovative MSCGM, which seamlessly integrates BBDP and GAN;\n3. We evaluate the MSCGM on various image restoration tasks, demonstrating its superior perfor-mance in both sampling speed and image quality than competitive methods."}, {"title": "3.1 Preliminaries", "content": "The outstanding success and wide applications of score-based diffusion models have been witnessed in the past years. Generally", "as": "n"}]}]}