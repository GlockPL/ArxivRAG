{"title": "Multi-scale Conditional Generative Modeling for Microscopic Image Restoration", "authors": ["Luzhe Huang", "Xiongye Xiao", "Shixuan Li", "Jiawen Sun", "Yi Huang", "Aydogan Ozcan", "Paul Bogdant"], "abstract": "The advance of diffusion-based generative models in recent years has revolution- ized state-of-the-art (SOTA) techniques in a wide variety of image analysis and synthesis tasks, whereas their adaptation on image restoration, particularly within computational microscopy remains theoretically and empirically underexplored. In this research, we introduce a multi-scale generative model that enhances con- ditional image restoration through a novel exploitation of the Brownian Bridge process within wavelet domain. By initiating the Brownian Bridge diffusion process specifically at the lowest-frequency subband and applying generative adversarial networks at subsequent multi-scale high-frequency subbands in the wavelet do- main, our method provides significant acceleration during training and sampling while sustaining a high image generation quality and diversity on par with SOTA diffusion models. Experimental results on various computational microscopy and imaging tasks confirm our method's robust performance and its considerable reduc- tion in its sampling steps and time. This pioneering technique offers an efficient image restoration framework that harmonizes efficiency with quality, signifying a major stride in incorporating cutting-edge generative models into computational microscopy workflows.", "sections": [{"title": "Introduction", "content": "Within the last decade, the landscape of image synthesis has been radically transformed by the advent of generative models (GMs) [58, 24, 57]. Among their broad success in various image synthesis applications, image restoration, including super-resolution, shadow removal, inpainting, etc, have caught much attention due to their importance in various practical scenarios. Image restoration aims to recover high-quality target image from low-quality images measured by an imaging system with assorted degradation effects, e.g., downsampling, aberration and noise. Numerous tasks in photography, sensing and microscopy can be formulated as image restoration problems, and therefore the importance of image restoration algorithms is self-evident in practical scenarios [27, 34, 66, 60]. Due to the ill-posedness of most image restoration problems, the application of generative learning becomes crucial for achieving high-quality image reconstruction. The wide applications of deep learning (DL)-based generative models in image restoration began with the success of generative"}, {"title": "Related works", "content": "As an important branch of computational imaging, computational microscopy springs up in recent years and aims to restore high-quality, multi-dimensional images from low-quality, low-dimensional measurements, usually with under-resourced equipment. Since the first work on microscopy image super-resolution reported in 2017 [48], DL has enabled a wide spectrum of novel applications that were impossible with conventional optical technologies, e.g., microscopy image super-resolution surpassing the physical resolution limit of microscopic imaging systems [60], volumetric imaging reconstructing 3D sample volumes from sparse 2D measurements [68], and virtual image labelling to match the contrast conventionally provided by chemical or biological markers [49]. Compared to general image restoration in computational imaging, microscopy image restoration mainly differs in two aspects: (1) The degeneration process, including the transfer function, noise and aberration of the imaging system is generally complex, unknown and hard to measure precisely; and such degeneration process could vary significantly in real-world scenarios due to the variations of subjects, hardware and imaging protocols. (2) Strict pixel-wise correspondence between output and ground truth images and consistency with physical laws are generally emphasized [4]."}, {"title": "Generative models", "content": "GANs are well-known for generating high-qaulity, photorealistic samples rapidly [14, 16]. Through training a discriminator that tells ground truth images apart from fake images generated by the gener- ator network, GANs outperformed traditional CNNs trained with hand-crafted, pixel-based structural losses such as L1 and L2 by providing a high-level, learnable perceptual objective. Conditional GANs such as Pix2Pix [27], pix2pix HD [63] and starGAN [8] have been successfully applied in a wide spectrum of image-to-image translation and image restoration tasks, including image coloriza- tion [44], style transfer [31], image deblurring [34], etc. Unsupervised image-to-image translation has also been extensively explored, such as cycleGAN [75], UNIT [38], DualGAN [72], etc. In the fields of biomedical and microscopy imaging, researchers have also explored the applications of GANs, e.g., reconstructing low-dose CT and MRI images [71, 21], denoising microscopy images [66], super-resolving diffraction-limited microscopy images [60], among others. Alternatively, transformer and related architectures have recently emerged and shown superior performance over convolutional neural networks (CNNs)-based GANs. Swin transformer [39] and SwinIR [37] have established a strong transformer-based baseline with competitive performance to CNNs. TransGAN substituted CNNs in the common GAN framework with transformers and improved the overall performance [29]. More recently, diffusion models (DMs) have been introduced and proved to be the state-of-the-art generative model in various image generation benchmarks [24, 45]. Dhariwal"}, {"title": "Methods", "content": "The outstanding success and wide applications of score-based diffusion models have been witnessed in the past years. Generally, for a Gaussian process {xt, t = 1,\u2026, T} defined as: \n$$q(x_t|x_{t-1}) = \\mathcal{N} (x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_tI), t = 1,\\dots ,T,$$\n(1)\nthe denoising DM attempts to solve the reverse process by parameterizing the conditional reverse distribution as: \n$$p_{\\theta}(x_{t-1}/x_t) = \\mathcal{N} \\bigg(x_t; \\frac{1}{\\sqrt{\\alpha_t}} \\bigg( x_t-\\frac{\\beta_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\epsilon_{\\theta}(x,t) \\bigg) , \\sigma_t^2I \\bigg).$$\n(2) \nHere $\\alpha_t$, $\\bar{\\alpha}_t$, $\\beta_t$, $\\sigma_t$ are constants, and $\\epsilon_{\\theta}$ is the network estimating the mean value of the reverse process. Despite the high image quality achieved by the denoising process, the total sampling steps $T$ can be very large and make the sampling process time-consuming.\nTheorem 1. For a given error $\\epsilon$ between the generated distribution $p_{\\epsilon}$ and the true distribution $p$, the sampling steps needed can be expressed by [20]: \n$$T = O(\\epsilon^{-2}\\kappa^3),$$\n(3)\nwhere $\\kappa$ is the condition number of the covariance matrix of $p$. Therefore, for highly non-Gaussian distributed images, e.g., microscopy images (please refer to Appendix C, where we theoretically and statistically demonstrate the high degree of non-Gaussianity of microscopy datasets), which tends to have high sparsity, resolution and contrast, standard diffusion models may not be practical due to their slow sampling speed and large sampling steps required for such distributions. To overcome this limitation, we turned to multi-scale wavelet transform (as detailed in Appendix D), which offers an excellent latent space (i.e., wavelet domain) for generative modeling. The wavelet domain not only facilitates lossless compression but also provides low-frequency coefficients with near-Gaussian distributions. Consequently, we transform the diffusion process into the wavelet domain, thereby introducing a novel multi-scale wavelet-based generative model. It can be shown that the diffusion in wavelet domain is a dual problem to the original diffusion in the spatial domain. For a detailed explanation of this duality, please see Appendix E. Due to the distinct characteristics of wavelet coefficients in low- and high-frequency subbands (as detailed in Appendix C), we adopt different generative modeling approaches for the low- and high-frequency coefficients, marking a key innovation in our work. Specifically, while the low-frequency wavelet coefficients exhibit a Gaussian tendency, the high-frequency coefficients are sparse and non-Gaussian. Therefore, for the low-frequency coefficients, we employed the Brownian Bridge Diffusion Process (BBDP) [35], and for the high-frequency coefficients, we utilized a Generative Adversarial Network (GAN) based generative method."}, {"title": "Brownian bridge diffusion process", "content": "We leverage BBDP to better model the conditional diffusion process and apply it to image restoration. Image restoration tasks focus on the generation of the target image $x_0 \\in \\mathbb{R}^{H\\times W \\times C}$ from a conditional"}, {"title": "Multi-scale conditional generative model", "content": "Wavelet transform, with its theoretical details outlined in Appendix D, is characterized by an orthogo- nal transform matrix $A \\in \\mathbb{R}^{N^2 \\times N^2}$. The wavelet transform decomposes an image $x \\in \\mathbb{R}^{N^2}$ to one low-frequency (LL) subband $x_L \\in \\mathbb{R}^{\\frac{3N^2}{4}}$ and remaining high-frequency subbands $x_H \\in \\mathbb{R}^{\\frac{N^2}{4}}$.\nDefinition 4 (Multi-scale wavelet decomposition of conditional image generation). With multi-scale wavelet transformation, we can reformulate the conditional probability distribution of $x_0$ on $y$ as \n$$p(x_0|y) = \\prod_{k=1}^{S}p(x_H^k|x_L^k, y_H^k)p(x_L^k|y_L^k),$$\n(10)\nwhere S denotes the maximum scale and \n$$(x_H^k, x_L^k)^T = Ax_0, (x_H^{k+1}, x_L^{k+1})^T = Ax_L^k, k = 1, ....$$\n(11)\nDifferent from existing approaches, our method leverages BBDP and GANs to handle low- and high-frequency subbands at various scales respectively, and the schematic diagram of our model is illustrated in Fig. 2. For the coarsest level low-frequency subband $x_L$, due to the whitening effect of the low-frequency subband after wavelet transform, DMs can effectively and efficiently approximate $p(x_L|y_L)$ with fewer sampling steps, while generating diverse and photorealistic images. For another, though the conditional distribution of high-frequency subbands deviates from unimodal Gaussian distributions considerably, the multi-scale GAN is able to approximate their multi-modal distribution and sample the full-resolution images rapidly in a coarse-to-fine style. Since the BBDP at the coarsest level produces samples with good diversity and fidelity, the possibility of mode collapse commonly observed in pure GAN models can be minimalized."}, {"title": "Experiments", "content": "In this section, we first elucidate the design and training details of our method, as well as the prepa- ration of training and testing datasets. Then, we evaluate our method on various image restoration tasks in computational and microscopy imaging, and compare it with baseline methods. At the end of this section, we further perform ablation study to analyze the importance of essential components in MSCGM."}, {"title": "Experimental setup and implementation details", "content": "For the BBDP at the coarsest wavelet scale, we adapt the UNet architecture with multi-head attention layers as practiced in [45]. The number of sampling steps is set as 1000 for training. The Brownian"}, {"title": "Evaluation metrics", "content": "Peak Signal-to-Noise Ratio (PSNR) is commonly used to measure the quality of reconstruction in generated images, with higher values indicating better image quality. Structural Similarity Index Measure (SSIM) [64] assesses the high-level quality of images by focusing on changes in structural information, luminance, and contrast. Fr\u00e9chet Inception Distance (FID) score [23] is used in generative models like GANs to compare the distribution of generated images against real ones, where lower FID values imply images more similar to real ones, indicating higher quality."}, {"title": "Results and comparison", "content": "In this section, we first evaluate our method on two microscopy image restoration tasks with different samples and then on three natural image restoration tasks, encompassing various popular image restoration applications in computational imaging and computational microscopy. First, we apply our method to microscopy images, where the degradation process is complex and unknown. Given the pronounced contrast and sparsity inherent in microscopy images, it is crucial to use generative models capable of handling multi-modal distributions to adapt effectively to complex microscopy datasets. We utilize our method to perform super-resolution on microscopy images of nano-beads and HeLa cells, transforming diffraction-limited confocal images to achieve resolution beyond the optical diffraction limit and match the image quality of STED microscopy. Next, we assess the adaptability of our method to various image restorations tasks of natural images, including a 4\u00d7 super-resolution task on DIV2K dataset, a shadow removal task on natural images (ISTD dataset) and on a low-light image enhancement task on natural images (LOL dataset). Through comparison against competitive methods on various testbeds, we demonstrate the superior effectiveness and versatility of our method for image restoration. \nMicroscopy Image Super-resolution: We evaluate our method on microscopy image super- resolution tasks and compare it with existing generative models in this field. Unlike natural image super-resolution, the LR images are not downsampled but sampled at the same spatial frequency as the HR images. However, the LR images are limited by the optical diffraction limit, which is equivalent to a convolution operation on the HR images with a low-pass point spread function (PSF). We apply our method to confocal (LR) images of fluorescence nanobeads to evaluate its capability to overcome the optical diffraction limit (see Methods for sample and dataset details)."}, {"title": "Conclusion", "content": "To address the limitations of exsiting diffusion models in conditional image restoration, we demon- strate a novel generative model for image restoration based on Brownian bridge process and multi- scale wavelet transform. By factorizing the image restoration process in the multi-scale wavelet domains, we utilize Brownian bridge diffusion process and generative adversarial networks to recover different wavelet subbands according to their distribution properties, consequently accelerate the sampling speed significantly and achieve high sample quality and diversity competitive to diffusion model baselines.\nLimitations: In this work, while we mainly present multi-scale wavelet transformation using the common Harr bases, the future work could investigate designing more efficient wavelet or learned bases. Besides, the adversarial training employed in this study can be unstable and sensitive to training setups. In summary, our method provides a practical solution to issues with generative learning and facilitates the applications of advanced generative models on computational and microscopy imaging."}, {"title": "Code and data availability", "content": "The codes of our reported method is available at https://anonymous.4open.science/ r/MSCGM-E114. The DIV2K dataset [1] is obtained from https://data.vision.ee. ethz.ch/cvl/DIV2K/, and the ISTD dataset [61] is obtained from https://github.com/ DeepInsight-PCALab/ST-CGAN. The microscopy image datasets (nanobeads and HeLa cells) are requested from Wang et al. [60] and partial demo images are uploaded to https://anonymous. 4open.science/r/MSCGM-E114."}, {"title": "Score regularity for discretization", "content": "Theorem 5. Suppose the Gaussian distribution p = N(0, \u03a3) and distribution po from time reversed SDE, the Kullback-Leibler divergence between p and p\u014d relates to the covariance matrix \u2211 as: KL(p || Po) \u2264 \u03a8\u0442 + \u03a8\u2206t + \u03a8\u0442,\u2206t, with: \n$$\\Psi_{\\tau} = f (e^{-4T} |Tr ((\\Sigma \u2013 Id)\\Sigma)|),$$\n(14) \n$$\\Psi_{\\Delta t} = f (\\Delta t |Tr (\\Sigma^{-1} \u2013 \\Sigma(\\Sigma \u2013 Id)^{-1}log(\\Sigma)/2 + (Id \u2013 \\Sigma^{-1})/3)|),$$\n(15) \n$$\\Psi_{\\tau,\\Delta t} = o(\\Delta t + e^{-4T}), \\qquad \\Delta t \\to 0, T\\to +\\infty$$\n(16)\nwhere f(t) = t \u2013 log(1 + t) and d is the dimension of \u03a3, Tr (\u03a3) = d. Proposition 1. For any $\\epsilon > 0$, there exists T, \u2206t \u2265 0 such that:\n$$(1/d) (\\Psi_{\\tau} + \\Psi_{\\Delta t}) \\leq \\epsilon,$$\n(17) \n$$T/\\Delta t < C_{\\epsilon^{-2}\\kappa^3},$$\n(18) \nwhere C \u2265 0 is a universal constant, and \u043a is the condition number of \u03a3. [20] provides the proof outline for Theorem 5, based on the following Theorem 6,"}, {"title": "Characteristics of high and low frequency coefficients in the wavelet domain", "content": "In an image, pixel intensities are represented as random variables, with adjacent pixels exhibiting correlation due to their spatial proximity. This correlation often follows a power-law decay: \n$$C(d) = \\frac{1}{(1 + ad)^{\\beta}}$$\n(29)\nwhere C(d) is the correlation between pixels separated by distance d, and a and \u1e9e characterize the rate of decay. The wavelet transform (i.e., Haar wavelet transform), particularly its down-sampling step, increases the effective distance d among pixels, thereby reducing their original spatial correlation. This reduction is crucial for applying the generalized Central Limit Theorem [51, 67, 11, 3], which requires that the individual variables (pixels, in this case) are not strongly correlated. At scale k in the wavelet decomposition, the low-frequency coefficients, Xk, representing the average intensity over nk pixels, are calculated as: \n$$X_k = \\frac{1}{n_k} (X_1 + X_2 + ... + X_{n_k}),$$\n(30) \nwhere ne is the number of pixels in each group at scale k. As the scale increases, the effect of averaging over larger groups of pixels, combined with the reduced correlation due to down-sampling, leads to a scenario where the generalized Central Limit Theorem can be applied. Consequently, the distribution of X tends towards a Gaussian distribution: \n$$X_k \\sim \\mathcal{N}(\\mu_k, \\frac{\\sigma_k^2}{n_k}),$$\n(31) \nwhere \u03bc\u03b5 and \u03c3\u03b5 are the mean and variance of the averaged intensities at scale k, respectively. This Gaussian tendency becomes more pronounced at higher scales due to the combination of reduced pixel correlation and the averaging process."}, {"title": "Sparsity and non-Gaussianity of high-frequency coefficients", "content": "High-frequency coefficients, when analyzed through wavelet transform, exhibit a distinct property of sparsity, characterized by a majority of wavelet coefficients being near or at zero, with only a sparse representation of significant non-zero coefficients. This sparsity highlights the efficiency of wavelet transforms in encoding signal details and abrupt changes. Furthermore, these high-frequency components often deviate from Gaussian distributions, tending towards leptokurtic distributions [13] with higher peaks and heavier tails. This non-Gaussian nature suggests a concentration of energy in fewer coefficients and is crucial in applications like signal denoising and compression, where recognizing and preserving these vital characteristics is paramount. In the following proposition, we theoretically show that the conditional distribution of $x_{\\ell}$ on $x_L^k$ exhibits highly non-Gaussian properties and yields sparse samples. For a given image \u00e6 and threshold t, the sparsity of its high-frequency coefficients at k-scale is defined as: \n$$s(x_{\\ell}^k) = \\frac{||1{\\{x_{\\ell}^k \\leq t\\}}||}{L^2}, k = 1, 2, ...,$$\n(32)\nHere $||*||$ is the norm counting the number of 1s in the vector. In this way, we could estimate the expected sparsity of the true marginal distribution $p(x_{\\ell}^k)$. Considering that the LL coefficients with approximate Gaussian distribution given the whitening effect of wavelet decomposition, we have the following proposition. Proposition 2. For a sufficiently large k, if the expected sparsity of $x_{\\ell}^1$ has a lower bound a \n$$\\mathbb{E}(s(x_{\\ell}^k)) \\geq \\alpha,$$\n(33)\nwhere $\\alpha \\in [0,1]$. Then the conditional expected sparsity of $x_{\\ell}^k$ on $x_L^k$ is bounded by \n$$\\mathbb{E}(s(x_{\\ell}^k)|x_L^k) \\geq \\alpha - \\epsilon,$$\n(34) \nwhere \u025b > 0 is a small positive number determined by k."}, {"title": "Quantifying Non-Gaussianity of datasets", "content": "Third- and fourth-order sample cumulants, i.e., skewness and kurtosis, to quantify the non-Gaussianity of certain sample distributions [15]. The non-Gaussianity of high-frequency subbands can be evidenced by the kurtosis plot with respect to wavelet scales in Fig. 6. The kurtosis of high-frequency subbands of microscopy images increases with the wavelet scales, showing the high non-Gaussianity of the distribution of high-frequency coefficients."}, {"title": "Skewness ($\u03b3_1$)", "content": "Skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable. It quantifies how much the distribution deviates from a normal distribution in terms of asymmetry. The skewness value can be positive, zero, negative, or undefined. In a perfectly symmetrical distribution, skewness is zero. Positive skewness indicates a distribution with an extended tail on the right side, while negative skewness shows an extended tail on the left side. The mathematical formula for skewness is given by: \n$$\\gamma_1 = \\mathbb{E} \\bigg[\\bigg(\\frac{X - \\mu}{\\sigma}\\bigg)^3\\bigg]$$\n(41) \nwhere X is the random variable, u is the mean of X, o is the standard deviation of X, and E denotes the expected value. The greater the absolute value of the skewness, the higher the degree of non-Gaussianity in the distribution."}, {"title": "Kurtosis ($\u03b2_2$)", "content": "Kurtosis is a measure of the \"tailedness\" of the probability distribution of a real-valued random variable. It provides insights into the shape of the distribution's tails and peak. High kurtosis in a data set suggests a distribution with heavy tails and a sharper peak (leptokurtic), while low kurtosis indicates a distribution with lighter tails and a more flattened peak (platykurtic). Kurtosis is often compared to the normal distribution, which has a kurtosis of 3 (excess kurtosis of 0)."}, {"title": "Non-Gaussianity of datasets", "content": "Here we examine the non-Gaussianity of the distribution of DIV2K training dataset and the mi- croscopy nanobead dataset used in this work. Table 4 summarizes their skewnesses and kurtoses. We observe that microscopy images tend to have larger absolute values of skewness and kurtosis, confirming their highly non-Gaussian distribution and the high condition number for microscopy image restoration problem. As a result, standard DMs with the assumption that the distribution of target images is close to normal does not hold for microscopy images and may lead to performance degradation and excessive sampling time."}, {"title": "Wavelet transform", "content": "Wavelet transforms are derived from a single prototype function known as the 'mother wavelet'. This function undergoes various scaling and translation processes to generate a family of wavelets. The general form of a wavelet function \u03c8a,b(x), derived from the mother wavelet, is expressed as: \n$$\\psi_{a,b}(x) = \\frac{1}{\\sqrt{a}} \\psi(\\frac{x - b}{a}),$$\n(43)\nwhere a, b \u2208 R, a \u2260 0, and x \u2208 D, with a and b representing scaling and translation parameters, respectively, and D being the domain of the wavelets."}, {"title": "Multiresolution analysis (MRA)", "content": "MRA is crucial in the Wavelet Transform [28, 47]. It involves constructing a basic functional basis in a subspace Vo within L\u00b2(R) and then expanding this basis through scaling and translation to cover the entire space L2 (R) for multiscale analysis. For each k \u2208 Z and k \u2208 N, we define the scale function space as Vk = {f|f is restricted to (2-kl, 2-k (1+1)) for all l = 0, 1, . . ., 2k \u2013 1 and vanishes elsewhere}. Each space Vk encompasses a dimension of 2k, with each subspace Vi nested within Vi+1: \n$$V_0 \\subset V_1 \\subset V_2 \\subset ... \\subset V_n \\subset ... $$\n(44) \nUsing a base function \u03c6(x) in Vo, we can span Vk with 2n functions derived from f(x) through scaling and translation: \n$$\\phi_l^k(x) = 2^{k/2}\\phi(2^kx - l), l = 0,1,..., 2^k - 1.$$\n(45) \nThese functions, \u03c6l(x), are known as scaling functions and they project any function into the approximation space Vo. The orthogonal complement of Vk in Vk+1 is the wavelet subspace Wk, satisfying:\n$$V_k \\oplus W_k = V_{k+1}, V_k \\perp W_k.$$\n(46)"}, {"title": "Wavelet decomposition and reconstruction", "content": "The Discrete Wavelet Transform (DWT) provides a multi-resolution analysis of signals, useful in various applications [18, 19, 69]. For a discrete signal f[n], DWT decomposes it into approximation coefficients cA and detail coefficients cD using the scaling function \u03c6(x) and the wavelet function \u03c8(x), respectively:\n$$c_A[k] = \\sum_{n} h[n - 2k] \\cdot f[n],$$\n(50)\n$$c_D[k] = \\sum_{n} g[n \u2013 2k] \\cdot f[n],$$\n(51) \nwhere h[n] and g[n] are the low-pass and high-pass filters, respectively. This decomposition process can be recursively applied for deeper multi-level analysis. Reconstruction of the signal f' [n] from its wavelet coefficients uses inverse transformations, employ- ing synthesis filters ho[n] and go[n]: \n$$f'[n] = \\sum_{k} c_A[k] \\cdot h_0[n \u2013 2k] + c_D[k] \\cdot g_0[n \u2013 2k],$$\n(52) \nwhere the synthesis filters are typically the time-reversed counterparts of the decomposition filters. In multi-level decompositions, reconstruction is a stepwise process, beginning with the coarsest approxi- mation and progressively incorporating higher-level details until the original signal is reconstructed."}, {"title": "Haar wavelet transform", "content": "The Haar wavelet [59], known for its simplicity and orthogonality, is a fundamental tool in digital signal processing. Its straightforward nature makes it an ideal choice for a variety of applications, which is why we have incorporated it into our project. The discrete wavelet transform (DWT) using Haar wavelets allows for the efficient decomposition of an image into a coarse approximation of its main features and detailed components representing high-frequency aspects. This process, enhanced by multi-resolution analysis (MRA), facilitates the examination of the image at various scales, thereby uncovering more intricate details. The mathematical representation of the Haar wavelet and its scaling function is as follows: \n$$\\phi(t) = \\begin{cases}\n1 & \\text{if } 0 < t < 0.5, \\\\\n-1 & \\text{if } 0.5 < t < 1, \\\\\n0 & \\text{otherwise}, \\\\\n\\end{cases}$$\n(53) \n$$\\phi(t) = \\begin{cases}\n1 & \\text{if } 0 < t < 1, \\\\\n0 & \\text{otherwise}, \\\\\n\\end{cases}$$\n(54)"}, {"title": "Generative modeling in spatial domain", "content": "For the Score-based Generative Model (SGM) [58, 24, 57], the forward/noising process is mathemat- ically formulated as the Ornstein-Uhlenbeck (OU) process. The general time-rescaled OU process is expressed as: \n$$dX_t = -g(t)^2X_tdt + \\sqrt{2g(t)}dB_t.$$\n(59)\nHere, (Xt)t\u2208[0,1] represents the noising process starting with Xo sampled from the data distribution. (Bt)t\u2208[0,T] denotes a standard d-dimensional Brownian motion. The reverse process, X, is defined such that (X) t\u2208 [0,T] = (XT\u2212t)t\u2208[0,T]. Assuming g(t) = 1 in standard diffusion models, the reverse process is: \n$$dX_t = (X_t + 2\\nabla log p_{T-t}(X_t)) dt + \\sqrt{2}dB_t.$$\n(60)\nHere, pt is the marginal density of Xt, and \u2207 log pt is the score. To revert X0 from XT via the time-reversed SDE, accurate estimation of the score log pt at each time t is essential, alongside minimal error introduction during SDE discretization."}]}