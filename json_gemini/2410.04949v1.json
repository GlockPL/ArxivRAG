{"title": "Leverage Knowledge Graph and Large Language Model for Law Article Recommendation: A Case Study of Chinese Criminal Law", "authors": ["Yongming Chen", "Miner Chen", "Ye Zhu", "Juan Pei", "Siyu Chen", "Yu Zhou", "Yi Wang", "Yifan Zhou", "Hao Li", "Songan Zhang"], "abstract": "Court efficiency is vital for social stability. However, in most countries around the world, the grassroots courts face case backlogs, with decisions relying heavily on judicial personnel's cognitive labor, lacking intelligent tools to improve efficiency. To address this issue, we propose an efficient law article recommendation approach utilizing a Knowledge Graph (KG) and a Large Language Model (LLM). Firstly, we propose a Case-Enhanced Law Article Knowledge Graph (CLAKG) as a database to store current law statutes, historical case information, and correspondence between law articles and historical cases. Additionally, we introduce an automated CLAKG construction method based on LLM. On this basis, we propose a closed-loop law article recommendation method. Finally, through a series of experiments using judgment documents from the website \"China Judgements Online\", we have improved the accuracy of law article recommendation in cases from 0.549 to 0.694, demonstrating that our proposed method significantly outperforms baseline approaches.", "sections": [{"title": "1 Introduction", "content": "In a modern rule-of-law society, the efficiency of court judgments is crucial for ensuring economy growth and social stability (Dakolias, 2014; Fix-Fierro, 2003; Rizos & Kapopoulos, 2021). Meanwhile, Xvguang (2024) revealed that the current backlog of cases in courts is enormous, which means the workload of judicial personnel is heavy. Wu (2024) showed that there is a great need for intelligent tools to assist judicial personnel in improving the efficiency of case adjudication, since intelligent tools boost judicial efficiency by categorizing similar cases, speeding up research, and staying updated with new laws, ensuring faster and more consistent decisions.\nLaw article recommendation entails predicting the relevant law articles applicable to a case based on its factual description. With the advancement of computer science, many data science techniques have been applied to this task, greatly improving efficiency. Classic law article recommendation techniques, such as LSTM (Hochreiter & Schmidhuber, 1997), Text-CNN(Kim, 2014), GRU (Cho et al., 2014), RCNN (Lai et al., 2015), HAN (Z. Yang et al., 2016), and DPCNN (Johnson & Zhang, 2017), are based on traditional machine learning methods. These methods focus solely on the correspondence between case facts and law article ids, while overlooking the semantic information in law articles. Moreover, these methods are highly susceptible to the effects of insufficient data and imbalanced data labels. Therefore, there is a need to solve above problems.\nSome researchers utilized Large Language Model (LLM) to complete the task of law article recommendation (Ma et al., 2024; Shui et al., 2023; X. Yang et al., 2024). When engaging with extensive LLMs, users are enabled to not only retrieve the numeral and textual format of law article but also to investigate the rationale behind the applicability of these statutes to the specific case by posing supplemental inquiries. Moreover, users have the capability to probe into the rationale for the non-selection of other analogous provisions. However, Dahl et al. (2024) found that directly using LLMs is prone to hallucinations, generating incorrect law article information. Therefore, it is necessary to introduce a fully accurate legal information and case knowledge base for auxiliary analysis.\nTo mitigate the issue of hallucination, researchers introduced Retrieval-Augmented Generation (RAG) technology to enhance the generation capability of LLMs, by retrieving relevant information from external knowledge bases (Cai et al., 2022; Lewis et al., 2020). Currently, RAG technology has been applied in fields such as code generation (Gou et al., 2024), autonomous driving (Dai et al., 2024), and enterprise management(O'Leary, 2024). However, research on RAG methods in the domain of law article recommendation remains relatively underexplored. RAG is divided into two parts: retrieval and generation. In academic discussions, greater attention is often given to the retrieval component of RAG, whereas the generation process is predominantly handled by LLMs. Classic retrieval methods include TFIDF-based retrieval (Aizawa, 2003), BM25-based retrieval (Robertson & Zaragoza, 2009), and retrieval methods based on frozen BERT (Borgeaud et al., 2022). However, the above methods mainly focus on the word level and rarely use macro semantics for matching. To deal with that problem, Chaudhri et al. (2022) proposed that the Knowledge Graph (KG), an unstructured database that uses a directed graph structure to store data, is highly suitable to serve as a database for RAG technology. Pan et al. (2024) have pointed out that the integration of KGs with LLMs shows great potential for future research. Edge et al. (2024) have utilized LLMs to automatically construct knowledge graphs, which are then used to enhance the generation capabilities of LLMs. This method performs well in terms of comprehensiveness and diversity of answers. However, the KGs generated using this method often have complex structures and lack a fixed schema, making them difficult for users to modify, such as adding new cases or removing outdated ones.\nTo address the above issues, we introduce knowledge graph technology and large language model technology to improve the output accuracy in law article recommendation tasks. Initially, we pre-design the schema of a Case-Enhanced Law Article Knowledge Graph (CLAKG) capable of simultaneously storing current law articles and historical cases information as a database. On this basis, we also introduce an automated CLAKG construction method based on LLM. Furthermore, we design a closed-loop human-machine collaboration method to complete the law article recommendation task. To demonstrate the effectiveness of our proposed method, we constructed a dataset of Chinese criminal law judgments. We compared the method introduced in this paper with approaches based on BERT, methods utilizing LLM, and the LLM approach based on TFIDF.\nThe remainder of this paper is organized as follows. Section 2 proposes a closed-loop law article recommendation framework. Section 3 utilizes the method from the second section to construct the CLAKG and compares the accuracy of this method with other baseline approaches. Lastly, the conclusions and future work are highlighted in Section 4."}, {"title": "2 Method", "content": "The pipeline of CLAKG-based law article recommendation is shown in Figure ??. We first establish a knowledge graph based on the designed schema. Initially, nodes and relationships are extracted from law articles and judgments in cases to construct the Law Article Knowledge Graph (LAKG) and the Adjudicated Cases Knowledge Graph (ACKG). Subsequently, by utilizing a Large Language Model (LLM), these two graphs are integrated to form CLAKG. This part is introduced in Section 2.1. Building upon this, we have developed a human-machine Collaborative law article recommendation framework. Users describe new case information, and the LLM would provide potentially applicable law articles based on keyword matching and graph embedding techniques. Moreover, the system can provide similar historical case information from the CLAKG, followed by providing most relevant law articles that match the new case using LLM. This part is introduced in Section 2.2. Following the above process, the user reviews the law articles provided by the system and corrects any inaccuracies. The new case information is used to update the CLAKG."}, {"title": "2.1 Case-Enhanced Law Article Knowledge Graph Construction", "content": "As shown in Figure 2a, the Case-Enhanced Law Article Knowledge Graph (CLAKG) is composed of the Law Article Knowledge Graph (LAKG) and the Adjudicated Case Knowledge Graph (ACKG). The LAKG includes original article of law, law article id, and key information. The key information is extracted from the original article of law using a LLM. For a more detailed instruction of LLM prompts in the task of retrieving law article key information or a specific example, we direct the reader to Section 1.1 of supplementary material. The ACKG contains the name of a case, time of the court session, prosecution reason, and the specifics of a case. The description of the case process is derived from the content of the judgment documents processed using a LLM. For a more detailed instruction of LLM prompts in the task of retrieving case process, we direct the reader to Section 1.2 of supplementary material.\nBased on the reference law articles written in the judgment documents, it is possible to link the name of a case node with law article id nodes. We analyze the correlation between case information and the corresponding key information of applicable law articles using a LLM and ultimately select up to five of the most relevant keywords for connection. For a more detailed instruction of LLM prompts in the task of matching case information to the corresponding key information of applicable law articles, we direct the reader to Section 1.3.2 of supplementary material. To ensure the consistency and accuracy of the knowledge graph. We ignore any keywords that do not exist in the graph output by the large language model. Tables 1 and 2 provide the details of all types of nodes and relationships in the CLAKG."}, {"title": "2.2 LLM and CLAKG Based Law Article Recommendation Framework", "content": "The LLM and CLAKG based law article recommendation framework is shown in figure ??. Before the start of the law article recommendation task, the CLAKG constructed in Section 2.1 needs to undergo graph embedding preprocessing using the Relational Graph Convolutional Network (RGCN) model mentioned in Section 2.2.1. The process of law article recommendation begins with the user inputting a newly emerged case. In Section 2.2.2, a LLM is used to match the k most relevant keywords to this new case (with k=8 as selected in this paper). Based on this, in Section 2.2.3, a candidate law article retrieval algorithm is employed to retrieve q candidate law articles that may be suitable for the new case (with q=5 as chosen in this paper). In Section 2.2.4, the information from the new case input by the user is integrated with the candidate law articles and historical case information obtained in Section 2.2.3 into a prompt, which is then passed to the LLM to complete the law article recommendation task."}, {"title": "2.2.1 Graph Embedding on CLAKG with RGCN", "content": "Graph embedding involves utilizing the topological structure information in knowledge graphs to assign embedding vectors to each node within the graph. The Graph Convolutional Network(GCN) model, initially proposed by Kipf and Welling (2016), was the first graph neural network used for graph embedding. Schlichtkrull et al. (2018) improved upon the GCN, introducing the Relation Graph Convolution Neural Networks (RGCN), which assigns different weights to different relationships, enhancing the quality of graph embeddings.\nThe node embedding vector update formula for the RGCN model is shown in Equation 1.\n$h_i^{(l+1)} = \\sigma (\\sum_{r \\in R} \\sum_{j \\in N_i^r} \\frac{1}{c_{i,r}} W_r^{(l)} h_j^{(l)} + W_0^{(l)} h_i^{(l)})$ (1)\nwhere $h_i^l$ represents the embedding vector of node i in the l-th layer, $N_i^r$ represents all neighboring nodes of node i that have relationship r. $c_{i,r}$ is a hyperparameter, which in this paper is taken as N. Both $W_r^{(l)}$ and $W_0^{(l)}$ are parameter matrices.\nThe graph embedding training task adopted in this paper is link prediction. For the link prediction task, part of the dataset consists of several triples (head node, relation, tail node) selected from the knowledge graph G = (V,E,R), which are used as positive examples. Another part of the dataset consists of randomly selected entities and relations from the knowledge graph, which are used to construct triples (head node, relation, tail node) that do not actually have a connection in the graph, i.e., fabricated triples, used as negative examples. The training objective of the model is to distinguish whether the given triples truly exist in the graph or are fabricated. The number of positive and negative triples is equal, which helps to prevent bias during model training.\nThe training process of the model is shown in Figure ??. Firstly, the system randomly initializes the embedding vectors for all nodes and relations. Based on this, the system updates the node embeddings using Equation 1. The system then calculates the score based on the DisMult decomposition, as described in Equation 2. This paper selects the cross-entropy function as the loss function, as described in Equation 3. When the triple is a positive example, meaning the information truly exists in the knowledge graph, the value of y is 1. When the triple is a negative example, meaning the information does not exist in the graph, the value of y is 0.\n$f(s, r, o) = e_s^T R_r e_o$ (2)\nwhere $e_s$ and $e_o$ represent the embedding vectors of the nodes s and o, and $R_r$ is the embedding vector of the relation r.\n$Loss = - \\frac{1}{(1 + \\omega) |T|} \\sum_{(s,r,o,y) \\in T} [ y log(l(f(s, r, o))) + (1 - y) log (1 - l(f(s, r, o))) ] $ (3)\nwhere I represents all the datasets, and I is the logistic activation function, as described in Equation 4.\n$l(x) = \\frac{1}{1+ e^{-x}} = \\frac{e^x}{e^x + 1}$ (4)"}, {"title": "2.2.2 Matching Key Information Nodes in CLAKG with LLM", "content": "In this section, we aim to match the relevant key information nodes within CLAKG based on current case information provided by users. To facilitate this process, we have designed prompts for the LLM, which include the expert role, task description, details of the newly reported case, known key information nodes, and example outputs. For a more detailed instruction of LLM prompts in the task of matching key information nodes in the CLAKG related to new case information, we direct the reader to Section 2.1 of supplementary material."}, {"title": "2.2.3 Law Article and Case Retrieval Algorithm", "content": "In this section, we propose an algorithm for retrieving historical case information and candidate law articles by leveraging the aforementioned data to identify the law article most relevant to the current case.\nThe proposed method for retrieving candidate law article involves traversing all \u2018key information' nodes obtained in 2.2.2 and retrieving the 'Original article of law' nodes that are connected to the 'key information' nodes via 'key' relationships. These nodes are then aggregated into a set container, with all 'Original article of law' nodes in the set representing the candidate law article. Given that the number of candidate law articles in the set container may be substantial, it is essential to select those law articles most analogous to the newly reported case for further analysis. To this end, each node in the container is evaluated by calculating the distance scores (cosine similarity) between the 'Original article of penal law nodes' embedding vector and the multiple \u2018key information' nodes embedding vector obtained in 2.2.1. These distance scores are summed to yield a cumulative distance score between each 'Original article of law' node and the newly reported case. Ultimately, the top five \u2018Original article of law' nodes with the highest cumulative distance scores are selected as the candidate law articles, serving as reference points for the LLM in completing the law article recommendation task."}, {"title": "2.2.4 LLM-Enhanced Law Article Recommendation", "content": "Our method intends to incorporate reference case information and the original text of candidate law articles to eliminate the hallucinations of LLMs. After retrieving candidate law articles and relevant historical cases with the method described in Section 2.2.3, The knowledge graph is then queried for key details, and this integrated information helps determine the applicability of the candidate articles. The prompt used for the LLM in this chapter consists of expert roles, task descriptions, information on new criminal cases, reference case information, candidate law articles, and output examples."}, {"title": "3 Experiment", "content": ""}, {"title": "3.1 Datasets", "content": ""}, {"title": "3.2 CLAKG Construction and Graph Embedding", "content": "We employed the method described in Section 2.1 to integrate the LAKG and the ACKG, resulting in the CLAKG. The types and numbers of nodes in CLAKG are presented in Table 3, while the types and numbers of relationships are detailed 4.\nWe employed the RGCN model described in Section 2.2.1 to perform graph embedding preprocessing on CLAKG. Our hyperparameter choices were as follows: hdim = 16, test_size = 0.2, learning_rate = 0.01, \u043f\u0438\u0442\u0435\u0440ochs = 50. We selected the model results corresponding to the highest Test AUC as the final graph embedding outcome. The Train AUC and Test AUC curves are presented in Figure ??. Upon examining this figure, we observed that the Train AUC exhibited an overall upward trend. The Test AUC increased when Epoch < 31 and decreased when Epoch \u2265 31. Consequently, we selected the model results at Epoch 31 as the final graph embedding outcome."}, {"title": "3.3 Case Study", "content": "We illustrate the law recommendation process based on LLM and CLAKG using the case of \"Zhang Yue's offenses of bribery and abuse of power\" as an example. Initially, the user inputs the details of a new case:\nDuring Zhang Yue's tenure as cultural administrator and grid member of Yongfeng Village, Zhang Yue manipulated residential information to secure illicit benefits, accepting 72,500 yuan in bribes. After the crime was uncovered, he voluntarily admitted his wrongdoing and returned the funds.\nThe system then retrieves keywords pertinent to the case using the methodology outlined in Section 2.2.2, identifying the following terms: ['accepting bribes', 'abuse of power', 'bribery']. Subsequently, the system locates the corresponding node IDs within the CLAKG and obtains the graph embedding vectors for these nodes as described in Section 3.2. Utilizing the historical case information and the candidate law articles retrieval algorithm specified in Section 2.2.3, the system identifies the candidate law articles and their associated cases, as depicted in Section 2.2 of supplementary material.\nThe system consolidates the above information into a prompt using the method described in Section 2.2.4, and submits it to the LLM to carry out the law recommendation task. Ultimately, the LLM outputs \"Article 385\" as the recommended law article. The result produced by the LLM is consistent with the outcome recorded in the court judgment."}, {"title": "3.4 Test Result", "content": ""}, {"title": "3.4.1 Analyzing the Impact of Label Imbalance in Training", "content": "We utilized the BERT model for law article recommendation as comparison methods. This method was compared against the method proposed in this paper: the LLM(specifically OpenAI's ChatGPT-4.0) for law article recommendation based on CLAKG (with case information).\nAs shown in the Table 5, the accuracy of the BERT model is only 0.289. Upon analyzing the results provided by the BERT method, we discovered that this method classified all test cases under \"Article 133.\" We believe this could be due to the small size of the training set, an imbalance in training labels (Franklin, 2005), or an inappropriate loss function. Even after replacing the cross-entropy loss function with the Focal Loss function, the model still classified all test cases as \"Article 133\".\nThe proposed model (LLM+CLAKG) achieved an accuracy of 0.694, which is significantly higher than that of the BERT-based method. This indicates that the proposed approach effectively mitigates the impact of the insufficient data and label imbalance in training."}, {"title": "3.4.2 Analyzing the Impact of Hallucinations in LLMs", "content": "We utilized the LLM (specifically OpenAI's ChatGPT-4.0, as well as other LLMs used in different methods) for law article recommendation as comparison method. This method was compared against the method proposed in this paper: the LLM for law article recommendation based on CLAKG (with case information).\nAs shown in the Table 6, the accuracy of the LLM without external legal data is significantly higher than that of the BERT model, achieving an accuracy of 0.549. However, it is still lower than the proposed model (LLM+CLAKG). We attribute this to the hallucinations of LLM and the proposed approach effectively mitigates the impact of label imbalance in training. The proposed model (LLM+CLAKG) achieved an accuracy of 0.694, which is significantly higher than that of the LLM-based method. This indicates that the proposed approach effectively mitigates the Huallucinations in LLMs."}, {"title": "3.4.3 Analyzing the Impact of Utilizing Macro Semantics", "content": "We utilized the LLM (specifically OpenAI's ChatGPT-4.0, as well as other LLMs used in different methods) based on TFIDF for law article recommendation as comparison method. This method was compared against two method proposed in this paper: the LLM for law article recommendation based on CLAKG (with case information) and the LLM for law article recommendation based on CLAKG (no case information).\nAs shown in the Table 7, both the TFIDF-based law article recommendation method and the CLAKG-based law article recommendation method mitigate the hallucinations of the LLM and improve its accuracy, with the latter performing better. We believe this is because the former only matches at the text level, while the latter matches the new case with keywords at the semantic level. Additionally, the latter utilizes all information within the CLAKG through graph embedding techniques, allowing it to calculate the most relevant law articles from a holistic perspective."}, {"title": "4 Conclusion", "content": "This paper proposes an efficient law article recommendation approach using a Case-Enhanced Law Article Knowledge Graph (CLAKG) combined with a Large Language Model (LLM). CLAKG integrates law articles and case information. It is characterized by a rich topological structure formed through usage relationships and shared key information found in judgments, which enhances the effectiveness of law article recommendation tasks. The proposed approach integrates LLMs with CLAKG, enabling more accurate recommendations of law articles and related cases by utilizing macro semantics to mitigate LLM hallucinations. The effectiveness of the proposed approach is verified through comprehensive comparisons with several baseline models on the law article recommendation task. This approach effectively addresses challenges such as insufficient data, imbalanced labels, and LLM hallucinations, leading to a significant improvement in the accuracy of the law article recommendation task.\nIn future work, we plan to expand the data volume of CLAKG, particularly by incorporating more case data to further enhance the performance of law article recommendation. Additionally, we will explore further applications of the CLAKG-LLM integration to improve the efficiency of court judgments."}]}