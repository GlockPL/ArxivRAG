{"title": "VIRTUAL NODES IMPROVE LONG-TERM TRAFFIC PREDICTION", "authors": ["Xiaoyang Cao", "Dingyi Zhuang", "Jinhua Zhao", "Shenhao Wang"], "abstract": "Effective traffic prediction is a cornerstone of intelligent transportation systems, enabling precise forecasts of traffic flow, speed, and congestion. While traditional spatio-temporal graph neural networks (ST-GNNs) have achieved notable success in short-term traffic forecasting, their performance in long-term predictions remains limited. This challenge arises from over-squashing problem, where bottlenecks and limited receptive fields restrict information flow and hinder the modeling of global dependencies. To address these challenges, this study introduces a novel framework that incorporates virtual nodes additional nodes added to the graph and connected to existing nodes-to aggregate information across the entire graph within a single GNN layer. Our proposed model incorporates virtual nodes by constructing a semi-adaptive adjacency matrix. This matrix integrates distance-based and adaptive adjacency matrices, allowing the model to leverage geographical information while also learning task-specific features from data. Experimental results demonstrate that the inclusion of virtual nodes significantly enhances long-term prediction accuracy while also improving layer-wise sensitivity to mitigate the over-squashing problem. Virtual nodes also offer enhanced explainability by focusing on key intersections and high-traffic areas, as shown by the visualization of their adjacency matrix weights on road network heat maps. Our advanced approach enhances the understanding and management of urban traffic systems, making it particularly well-suited for real-world applications.", "sections": [{"title": "1 Introduction", "content": "Forecasting traffic conditions, such as flow, speed, and congestion, plays a central role in intelligent transportation systems (ITS). This capability is essential for enhancing urban traffic efficiency and mitigating congestion, which are critical challenges in modern cities. The task relies on analyzing extensive datasets collected from road sensors, GPS devices, and historical traffic records to identify and model traffic patterns. Advanced methodologies, including statistical models, machine learning techniques, and deep learning frameworks, have significantly contributed to progress in this area.\nGraph Neural Networks (GNNs) have demonstrated remarkable success in traffic prediction, particularly in short-term forecasting. However, their ability to handle long-term predictions remains constrained. According to Wang et al. [2020], forecasts with a time span of less than one hour are classified as short-term, while those extending beyond one hour are regarded as medium or long-term [Hou et al., 2014, Yu et al., 2018]. Long-term traffic prediction requires not only capturing long-range correlations but also effectively incorporating global spatial and temporal information. The message-passing mechanism of Graph Neural Networks (GNNs), which operates by recursively aggregating information from neighboring nodes, presents a significant limitation as it primarily focuses on local connections, often neglecting global relationships. The recursive structure of GNNs gives rise to the over-squashing problem [Alon and Yahav, 2020], in which information from distant nodes becomes compressed into fixed-size representations as it propagates through the network layers. Various research has extensively documented the limitations of fixed-size vector representations, showing that they create information bottlenecks that hinder the effective capture of long-range dependencies. Moreover, as the distance between nodes increases, stacking additional GNN layers often leads to performance degradation, making it increasingly difficult to retain detailed information from distant nodes [Alon and Yahav, 2020, Banerjee et al., 2022, Di Giovanni et al., 2023]. Given the critical role of global and spatially long-range dependencies-where distant locations can substantially influence future traffic conditions-it is essential to incorporate global spatial information into long-term prediction models to improve their accuracy and performance.\nVirtual nodes are an effective graph rewiring technique designed to enhance the representation of long-range correlations in graphs. Unlike conventional graph rewiring, which dynamically modifies the graph's structure to optimize information flow, virtual nodes introduce additional nodes without altering the original graph topology. These virtual nodes are connected to all existing nodes, with their graph signals and edge weights either manually specified or automatically learned based on task requirements. Acting as intermediaries, virtual nodes facilitate the efficient aggregation of global information, mitigating the over-squashing problem that arises when information from distant nodes is compressed and lost during propagation. By enabling the integration of information from the entire graph within a single GNN layer, virtual nodes streamline the message-passing process, allowing models to effectively capture long-range dependencies and critical spatial relationships.\nVirtual nodes have proven effective in enhancing molecular graph representation for drug discovery [Li et al., 2017] and improving graph-level pattern recognition in classification tasks [Gilmer et al., 2017, Pham et al., 2017, Li et al., 2017, Liu et al., 2022]. Despite their demonstrated success in these domains, the application of virtual nodes in traffic prediction remains largely unexplored. Virtual nodes are particularly well-suited for traffic prediction due to their ability to address the challenges of long-term forecasting. By efficiently capturing long-range dependencies across traffic networks, they enable models to predict traffic conditions over extended periods with greater accuracy. Moreover, virtual nodes provide an intuitive explainability to the model. They can be viewed as intelligent transportation hubs that gather information from different parts of the traffic network and broadcast it throughout the system. Functioning as a central processing unit, virtual nodes synthesize data to offer a holistic view of the entire traffic system through GNN's message-passing mechanism.\nIn this study, we propose an advanced traffic prediction model that incorporates virtual nodes within a semi-adaptive adjacency matrix framework. Our model aims to address the limitations of traditional ST-GNNs, particularly their difficulty in capturing long-range spatial dependencies crucial for accurate long-term traffic prediction. The primary contributions of this study are as follows:\n\u2022 Virtual Node Integration: We introduce virtual nodes to address the over-squashing problem in ST-GNNs, enhancing their ability to capture long-range spatial correlations. This method is versatile and can be seamlessly integrated into existing ST-GNN architectures.\n\u2022 Semi-Adaptive Adjacency Matrix: A semi-adaptive adjacency matrix framework is proposed, combining distance-based and adaptive adjacency matrices. This hybrid design effectively learns the connection weights for virtual nodes, striking a balance between model complexity and adaptability to improve the integration of virtual nodes.\n\u2022 Enhanced Long-Term Prediction Accuracy and Sensitivity: Experimental results demonstrate that incorporating virtual nodes significantly improves long-term traffic prediction accuracy. Moreover, the layer-wise sensitivity of ST-GNNs is notably increased, indicating stronger connections between distant nodes and effectively mitigating the over-squashing problem.\n\u2022 Explainability and Visualization: Our approach provides improved explainability by visualizing the real-to-virtual adjacency matrix and generating road network heat maps. These visualizations reveal spatial patterns in connection weights, with higher weights automatically assigned to traffic-critical regions, such as major intersections and junctions.\nThe rest of the paper is organized as follow: Section 2 explains GNNs, ST-GNNs, and the challenge of long-term traffic prediction; Section 3 reviews relevant research on traffic prediction and graph rewiring techniques; Section 4 details our approach, including virtual node integration and the semi-adaptive adjacency matrix; Section 5 presents the dataset, ablation studies, model comparisons, sensitivity analysis, and visualization results; and Section 6 summarizes findings, discusses implications, and suggests future research directions."}, {"title": "2 Problem description and preliminaries", "content": ""}, {"title": "2.1 Graph neural networks", "content": "Graph Neural Networks (GNNs) [Scarselli et al., 2008] have recently emerged as one of the most prominent machine learning architectures for analyzing graph-structured data. They have been widely adopted in various domains where data is naturally represented as graphs, such as traffic prediction [Wu et al., 2021a, Zhuang et al., 2022, Bai et al., 2020], biochemistry [Gilmer et al., 2017, Jumper et al., 2021], and social network analysis [Fan et al., 2019, He et al., 2020].\nGNNs recursively learn vector representations for each node by aggregating information from its neighbors. To formalize this process, we adopt the following notational conventions: calligraphic fonts denote sets, bold uppercase letters represent matrices, bold lowercase letters denote vectors, and subscripts are used for indexing nodes and time steps.\nLet the graph be defined as G = (V, E, A), where V represents the set of nodes (locations), E denotes the set of edges, and A \u2208 R|V|\u00d7|V| is the adjacency matrix encoding spatial relationships between nodes. The specific definition of the adjacency matrix A used in this study is given in Section 5.1. In each layer i, the node features are updated as follows [Scarselli et al., 2008]:\n$h_v^{(i)} = UPDATE^{(i)} (h_v^{(i-1)}, AGG^{(i)} (\\{h_u^{(i-1)} | u \\in N(v)\\}))$,\nwhere $UPDATE^{(i)}$ and $AGG^{(i)}$ are differentiable parameterized functions, and $h_v^{(0)}$ represents the initial node feature. Here, N(v) denotes the set of neighboring nodes of node v. For node-level tasks such as traffic prediction, the output in the final layer N is used directly:\n$\\hat{y}_v = Wh_v^{(N)}$.\nWhile GNNs are effective for modeling static relationships within a topological structure, they are inherently limited to processing data at fixed time points and cannot capture the patterns of feature evolution over time in sequential data, which are crucial for traffic prediction. To overcome this limitation, Spatio-Temporal Graph Neural Networks (ST-GNNs) have been proposed. These models extend the capabilities of traditional GNNs by incorporating temporal dependencies, often leveraging architectures such as Long Short-Term Memory Networks (LSTMs) [Hochreiter and Schmidhuber, 1997] and Transformers [Vaswani et al., 2017]. This enhancement allows ST-GNNs to effectively model the spatio-temporal dynamics required for accurate traffic prediction."}, {"title": "2.2 ST-GNNs for traffic prediction", "content": "ST-GNNs have been widely applied in traffic prediction tasks [Bai et al., 2020, Li et al., 2018, Wu et al., 2021a, Zhuang et al., 2022, Han et al., 2019, 2021, Kong et al., 2020, Yu et al., 2018, Shao et al., 2022], demonstrating strong capabilities in modeling complex spatio-temporal dynamics. ST-GNNs address the spatial and temporal components of traffic data through distinct mechanisms. The spatial component is handled by GNNs, which aggregate and extract features by capturing relationships between nodes (locations). Meanwhile, the temporal component leverages methods such as Gated Recurrent Units (GRUs) [Cho et al., 2014], Temporal Convolutional Networks (TCNs) [Lea et al., 2017], and Transformers [Vaswani et al., 2017] to model sequential patterns over time. Specifically, for each time step, GNNs are used to extract spatial features and generate graph embeddings, which are then fed into the temporal module. These temporal models take embeddings from a fixed number of past time steps as input and predict graph signals for specified future time steps. This integration of GNNs and temporal techniques allows ST-GNNs to effectively capture both spatial and temporal dependencies, ensuring accurate traffic predictions.\nWe denote the traffic dataset inputs as $X \\in R^{|V|\\times t}$, where t is the number of time steps. The objective is to predict the target value $Y_{1:|V|,t:t+k}$ for the future k time steps, given all past data up to time t, denoted as $X_{1:|V|,1:t}$. Given a graph G = (V, E, A), the goal of the ST-GNN models is to design a model $f_\\theta$, parametrized by $\\theta$, such that:\n$Y_{1:|V|,t:t+k} = f_\\theta(X_{1:|V|,1:t}; G) = f_\\theta(X_{1:|V|,1:t}; V, E, A)$,\nwhere $Y_{1:|V|,t:t+k}$ is the predicted target value. The loss function like Mean Absolute Error (MAE) is used to optimize the model parameters $\\theta$ during training."}, {"title": "2.3 Long-term traffic prediction", "content": "Previous research has primarily focused on using spatio-temporal graph neural networks (ST-GNNs) for short-term traffic prediction, typically within a 60-minute horizon when the temporal granularity is 5 minutes (Zhuang et al. [2022], Han et al. [2021], Kong et al. [2020], Yu et al. [2018], Shao et al. [2022]). This limitation arises because the information propagation speed between nodes in ST-GNNs is relatively slow, making it challenging to accurately predict long-term traffic states. Due to the nature of the GNN message-passing mechanism, each layer aggregates information only from neighboring nodes. As shown in Equation (1), each node v updates its representation $h_v^{(i)}$ by aggregating features from its immediate neighbors N(v) at the previous layer i \u2013 1. Information from nodes that are l-hops away requires at least I layers for their information to reach node v. Consequently, capturing long-range dependencies requires stacking many layers, which can lead to the over-squashing problem.\nIn the context of traffic prediction, the over-squashing problem becomes particularly evident. Consider an example in Figure 1, where an accident occurs at the westernmost node of a road network. The impact gradually propagates throughout the traffic flow along the network. Traditional ST-GNNs, which aggregate information from neighboring nodes, require multiple layers to convey the impact from the westernmost to the easternmost node. This slow propagation results in the compression of information into fixed-size representations as it passes through the layers, causing critical details from distant nodes to be lost or diminished. This latency hinders the ability of ST-GNNs to promptly capture the effects of sudden incidents on traffic flow, thereby limiting their efficacy for long-term prediction.\nThis study introduces a method based on Virtual Nodes (Gilmer et al. [2017]) to accelerate the learning of spatio-temporal relationships in ST-GNNs. Virtual Nodes are connected to all real nodes in the network, enabling them to aggregate information from across the entire graph in a single GNN layer. Weights between the Virtual Nodes and other nodes in adjacency matrix A are determined through an adaptive learning mechanism, ensuring appropriate weight allocation to diverse information types. The incorporation of Virtual Nodes accelerates the message passing process in ST-GNNs, improving the accuracy of long-term traffic prediction."}, {"title": "3 Literature Review", "content": "After introducing the problem and concept, and before we delve into our proposed methodology, we review the existing work on ST-GNN for traffic prediction, as well as the current state of technology regarding virtual nodes."}, {"title": "3.1 Traffic prediction with ST-GNN", "content": "With the advancement of deep learning in recent years, researchers have explored various frameworks for traffic prediction, including Convolutional Neural Networks (CNNs) (Yao et al. [2018, 2019]), Recurrent Neural Networks (RNNs) (Bai et al. [2020], Li et al. [2018]), and ST-GNNs (Bai et al. [2020], Li et al. [2018], Wu et al. [2021a], Zhuang et al. [2022], Han et al. [2019, 2021], Kong et al. [2020], Yu et al. [2018], Shao et al. [2022]). ST-GNNs, in particular, have garnered attention for their ability to simultaneously handle spatial and temporal dependencies. This capability is crucial for accurately modeling real-world traffic conditions, which constantly fluctuate across time and space, necessitating dynamic handling of spatio-temporal correlations. Spatially, ST-GNNs convert road network topologies into graph structures, allowing them to handle a wide array of non-Euclidean spatial data. Temporally, they effectively learn the non-linear and periodic patterns in traffic data, leading to robust performance in complex traffic prediction tasks.\nDCRNN (Li et al. [2018]) is one of the first models that simultaneously learns spatial and temporal dependencies, using GNNs to process spatial relationships and RNNs to process temporal dynamics. STGCN (Yu et al. [2018]) utilizes CNN to concurrently manage spatial and temporal dependencies, offering higher computational efficiency compared to RNNs. AGCRN (Bai et al. [2020]) and Graph WaveNet (Wu et al. [2019]) introduce adaptive adjacency matrices, allowing for the dynamic adjustment of weights to capture the hidden spatial dependencies more accurately. DGCRN (Li et al. [2023]) extracts dynamic characteristics from node attributes, enabling the generation of time-varying adjacency matrices. GMAN (Zheng et al. [2020]) leverages a self-attention mechanism to effectively capture global spatio-temporal correlations, enhancing GNN's ability to process global information.\nHowever, the architecture of ST-GNNs leads to the over-squashing problem (Alon and Yahav [2020]), where information from distant nodes is compressed into fixed-size representations as it propagates through the layers. This compression can cause important details from distant nodes to be lost or diminished, resulting in a bottleneck that limits the model's ability to capture long-range dependencies effectively. Consequently, ST-GNNs face challenges in processing global information and long-term interactions, which significantly restricts their predictive capabilities. To address these limitations, researchers have proposed the Graph Transformers (GTs) to handle global information by applying global attention mechanisms (Chen et al. [2022a], Kim et al. [2022], Dwivedi et al. [2022], Wu et al. [2021b]). However, all transformers suffer from their quadratic space and memory requirements, thus limiting their practical applicability in larger networks. Therefore, techniques have emerged that focus on modifying the network structure to effectively learn long-range dependencies."}, {"title": "3.2 Graph rewiring", "content": "Graph Rewiring is an effective method for addressing long-range interactions in graphs. It modifies connections between nodes by adding or adjusting edges and nodes, thus optimizing the network structure to enhance information propagation. Its capacity to capture global information has led to successful applications in various graph-level tasks such as Graph Classification (Gilmer et al. [2017], Pham et al. [2017], Li et al. [2017], Liu et al. [2022]). In practice, graph rewiring is often combined with virtual nodes to enhance node connectivity and improve global information capture (Li et al. [2017], Hwang et al. [2022], Qian et al. [2024]). Pham et al. [2017] introduced the Virtual Column Network incorporating a single fully-connected virtual node to learn representations of the entire graph. Br\u00fcel-Gabrielsson et al. [2022] utilized positional encodings to rewire graphs with k-hop neighbors and virtual nodes. Recently, Qian et al. [2023] developed a probabilistic rewiring approach, sampling edges from a trainable distribution to strategically add relevant edges while excluding less beneficial ones. Subsequently, Qian et al. [2024] refined their method by incorporating virtual nodes for implicit rewiring, enhancing the transfer of long-range information.\nApplying graph rewiring to time-series data, such as traffic prediction, presents unique challenges due to the dynamic nature of temporal dependencies. AGCRN (Bai et al. [2020]) replaces the traditional distance-based adjacency matrix with an adaptive adjacency matrix tailored for time-series prediction, enabling the model to dynamically learn connectivity patterns based on temporal data. TimeGNN (Xu et al. [2023]) utilizes Gumbel-Softmax to learn discrete adjacency matrices that represent the evolving graph structure at each time step, effectively capturing temporal changes without relying on a fixed structure. Similarly, Chen et al. [2022b] employ a balanced graph structure learning method, which involves an adaptive adjacency matrix construction to balance the trade-off between local and global information capture, However, these methods neglect the information in the original adjacency matrix, potentially missing crucial static relationships. DGCRN (Li et al. [2023]) integrates the original adjacency matrix into the adaptive one, leveraging both static and dynamic information, but its complexity and requirement for additional data, such as traffic speed, limit its practicality.\nThis study proposes a method that incorporates virtual nodes to enhance connectivity and combines the benefits of both the original and adaptive adjacency matrices, improving the model's capacity to capture local and global temporal dependencies without additional data complexities."}, {"title": "4 Methodology", "content": "In this section, we describe how to enhance the original graph with virtual nodes and apply this augmented graph for traffic prediction. The first part introduces the structure of STGCN (Yu et al. [2018]), which are selected as our predictive model $f_\\theta$. Following this, we explain the incorporation of virtual nodes into the graph. We propose two approaches for integrating virtual nodes: using an adaptive adjacency matrix and a semi-adaptive adjacency matrix. The adaptive adjacency matrix is entirely task-driven, learning the optimal connections based on the prediction task, whereas the semi-adaptive adjacency matrix leverages both task-driven learning and geographical information to form connections. Combining two parts, the overall process of our method is illustrated in Figure 2."}, {"title": "4.1 Framework of STGCN", "content": "Spatio-temporal graph convolutional network (STGCN) is designed to capture both spatial and temporal dependencies in traffic data (Yu et al. [2018]). The framework integrates Graph Convolutional Networks (GCNs) for spatial feature extraction and Temporal Convolutional Networks (TCNs) for temporal feature extraction. This combination allows STGCNs to effectively model the complex spatio-temporal dynamics inherent in traffic data.\nRecall the notation in Section 2, let G = (V, E, A) be a graph where V is the set of nodes, & is the set of edges, and A \u2208 R|V|\u00d7|| is the adjacency matrix. Given the node features matrix X \u2208 R|V|\u00d7F, where F is the number of features, the spatial convolution operation in a GCN layer can be defined as:\n$H^{(l+1)} = \\sigma (A H^{(l)}W^{(l)})$, where $H^{(l)}$ is the input to the l-th layer, $W^{(l)}$ is the weight matrix for the l-th layer, and $\\sigma$ is an activation function. The output of the GCN layer is then passed to the TCN layer to capture temporal dependencies.\nThe temporal convolution operation can be represented as:\n$Z^{(t+1)} = \\phi (\\sum_{k=0}^{K-1} W_k Z^{(t-k)})$, where $Z^{(t)}$ is the input to the t-th time step, $W_k$ are the temporal convolutional filters, K is the kernel size, and \u222e is the activation function. By stacking multiple GCN and TCN layers, STGCNs can effectively model both spatial and temporal aspects of traffic data.\nIn our study, we use STGCN as the base model $f_\\theta$ for short-term traffic prediction. The STGCN model takes as input the spatio-temporal data and the graph structure and outputs the predicted traffic conditions. We further build models upon it to demonstrate the adaptation for long-term traffic prediction."}, {"title": "4.2 Semi-adaptive adjacency matrix with virtual nodes", "content": "In this section, we present our approach to enhance ST-GNN with virtual nodes, utilizing a semi-adaptive adjacency matrix. This method aims to effectively capture both local and global dependencies by integrating task-specific learning with geographic information.\nWe introduce virtual nodes to connect all existing real nodes V in the graph G. The introduced virtual node set is denoted as $V_{virtual}$, with $|V_{virtual}| = n_v$, where $n_v$ represents the number of virtual nodes. These virtual nodes are topologically connected to all existing real nodes, although the connection weights are initially unknown. This setup facilitates the aggregation of comprehensive information across the entire network, enhancing the model's ability to capture both local and global dependencies."}, {"title": "Adaptive Adjacency Matrix Construction", "content": "We compute an anti-symmetric matrix $A_{adapt}$ as follows:\n$A_{adapt} = ReLU(E_1E_2^T - E_2E_1^T)$.\nAccording to previous research (Wu et al. [2020]), the learned relation in time series forecasting is supposed to be uni-directional. The resulting $A_{adapt}$ is uni-directional. To remove weak connections, we apply a threshold r, retaining only the elements in $A_{adapt}$ that exceed this threshold and setting the rest to zero. Mathematically, this can be represented as:\n$A_{adapt,ij} = \\begin{cases}A_{adapt,ij} & \\text{if } A_{adapt,ij} \\geq r \\\\0 & \\text{otherwise},\\end{cases}$\nwhere $A_{adapt,ij}$ represents the element in $A_{adapt}$ at position (i, j)."}, {"title": "Semi-adaptive Adjacency Matrix Construction", "content": "Given a distance-based adjacency matrix $A_{dist}$, we augment it with the virtual node connections from $A_{adapt}$. The semi-adaptive adjacency matrix $A_{semi}$ is constructed by integrating the adaptive matrix with the distance-based matrix:\n$A_{semi} = \\begin{bmatrix} A_{dist} & A_{adapt, real\\_to\\_virtual} \\\\A_{adapt, virtual\\_to\\_real} & A_{adapt, virtual\\_nodes} \\end{bmatrix}$\nThe relationships between $A_{adapt,real\\_to\\_virtual}$, $A_{adapt,virtual\\_to\\_real}$, $A_{adapt,virtual\\_nodes}$, and $A_{adapt}$ are given by:\n$A_{adapt,real\\_to\\_virtual} = A_{adapt}[1 : |V|, |V| + 1 : |V| + n_v]\\\\A_{adapt,virtual\\_to\\_real} = A_{adapt}[|V| + 1 : |V| + n_v, 1 : |V|]\\\\A_{adapt,virtual\\_nodes} = A_{adapt} [|V| + 1 : |V| + n_v, |V| + 1 : |V| + n_v]$\nIn this matrix, $A_{adapt,real\\_to\\_virtual}$ and $A_{adapt,virtual\\_to\\_real}$ are the parts of $A_{adapt}$ that correspond to the connection weights between real nodes and virtual nodes. This approach ensures that the semi-adaptive adjacency matrix leverages both the inherent geographical information and the task-specific learned relationships."}, {"title": "Virtual Node Signals Initialization", "content": "To ensure computational simplicity, we initialize the virtual node signals to zero, indicating that virtual nodes start with no traffic flow information at the initial time step. This allows the virtual nodes to gradually learn and aggregate relevant information from the real nodes through the adaptive learning process."}, {"title": "5 Experiment", "content": ""}, {"title": "5.1 Dataset", "content": "The dataset used for this research is the San Diego (SD) sub-dataset sourced from the LargeST benchmark dataset (Liu et al. [2023]). This dataset provides a comprehensive collection of traffic data from 716 sensors located in San Diego County, California. These sensors cover a variety of highways and collect data on traffic flow. The data spans from January 1, 2017, to December 31, 2021, providing a rich temporal coverage to study traffic patterns and their fluctuations.\nIn LargeST dataset, the adjacency matrix A is given through a thresholded Gaussian kernel (Shuman et al. [2013]), where $A_{ij} = exp(-\\frac{d_{ij}^2}{\\sigma^2})$ if $A_{ij} \\geq r$, otherwise $A_{ij} = 0$. Here, $d_{ij}$ denotes the road network distance between nodes i and j, o is the standard deviation of all distances, and r is the threshold. Consequently, the adjacency matrix A reflects the geographical affinities of the regions, with shorter distances indicating larger adjacency values.\nThe SD sub-dataset, being the smallest in the LargeST collection, was specifically chosen to strike an optimal balance between computational demand and the complexity of model parameters. This choice addresses potential overfitting issues that could arise when virtual nodes are added to small-sized graphs where information propagation is already efficient without additional enhancements. The SD dataset, with its 716 nodes and 17,319 edges, offers a moderately scaled environment ideal for testing the impact of virtual nodes. Its detailed descriptions are listed in Table 1 and the spatial distributions of all sensors are given in Figure 3."}, {"title": "5.2 Baseline models and evaluation metrics", "content": "In our study, we aim to assess the impact of various adjacency matrix configurations on the performance of our predictive model. Naturally, the original STGCN is one of the baseline models.\nMoreover, We employ a modified \"All-ones\" setting as a baseline where only the rows and columns corresponding to a single virtual node in the adjacency matrix are set to ones, while the remaining parts are still distance-based. Specifically, that means we assign $A_{adapt,real\\_to\\_virtual} = 1$, $A_{adapt,virtual\\_to\\_real} = 1$. This approach simplifies the interaction framework to some extent while preserving the essential distance-based connections. This baseline is contrasted with adaptive and semi-adaptive matrices that are specifically designed to capture the dynamic interconnections and contextual relationships among data points."}, {"title": "5.3 Model comparison", "content": "We apply different adjacency matrix configurations on STGCN (Yu et al. [2018]) to test whether virtual nodes help long-term traffic prediction. Notably, our approach is applicable to any ST-GNN or other graph models accepting adjacency matrices as input, we will include more models in our future studies.\nWe choose various adjacency matrix configurations for comparison:\n\u2022 A distance-based pre-defined adjacency matrix serves as the baseline.\n\u2022 The \"All-ones\" case introduced in Section 5.2.\n\u2022 An adaptive adjacency matrix with virtual nodes derived from node embeddings.\n\u2022 A semi-adaptive adjacency matrix that integrates both pre-defined and adaptive matrices.\nFor the latter two configurations, we assessed the effects of introducing between one and twenty virtual nodes on prediction accuracy. We utilized time series data from the years 2019 to 2020 for training and testing, encompassing a total of 35,040 time frames. We evaluated the model's predictive performance across 1 to 20 prediction horizons, where each horizon corresponds to a five-minute interval, the same as the sampling rate.\nAll our experiments are implemented on a machine with Ubuntu 22.04, with Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz CPU, 128GB RAM, and NVIDIA GeForce RTX 4080 GPU."}, {"title": "To evaluate the performance of these configurations, we use two primary metrics: Root Mean Squared Error (RMSE) and Mean Absolute Percentage Error (MAPE). These metrics are widely used in the literature for their effectiveness in measuring prediction accuracy and error.", "content": "The RMSE is defined as:\n$RMSE = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}$, where $y_i$ represents the observed values, $\\hat{y_i}$ represents the predicted values, and n is the number of observations. RMSE provides a measure of the average magnitude of the prediction errors, giving higher weight to larger errors.\nThe MAPE is defined as:\n$MAPE = \\frac{1}{n} \\sum_{i=1}^{n} |\\frac{y_i - \\hat{y_i}}{y_i}|$, MAPE expresses the prediction accuracy as a percentage, making it easier to interpret the model's performance relative to the actual values."}, {"title": "5.4 Sensitivity analysis", "content": "The sensitivity analysis focuses on evaluating the impact of varying the number of virtual nodes on the performance of both adaptive and semi-adaptive configurations. Figures 6 provide insights into this sensitivity analysis, illustrating the RMSE and MAPE metrics for different numbers of virtual nodes across multiple prediction horizons.\nAdaptive Adjacency Matrix: Figure 6a displays the RMSE and MAPE trends for adaptive configurations with 1, 2, 5, 10, and 20 virtual nodes compared to the distance-based baseline. The distance-based configuration exhibits the lowest RMSE and MAPE across all prediction horizons, suggesting that the adaptive configurations, despite their complexity, do not outperform the simpler distance-based approach. As the number of virtual nodes increases, there is no significant improvement in either RMSE or MAPE, indicating that the additional parameters introduced by virtual nodes do not translate to better performance. In fact, the adaptive configurations show higher error rates, which may imply overfitting and instability due to the increased model complexity. Therefore, we need to limit the complexity of the adjacency matrix, prompting us to explore semi-adaptive configurations.\nSemi-adaptive Adjacency Matrix: Figure 6b presents the RMSE and MAPE trends for semi-adaptive configurations. The semi-adaptive configurations generally show better performance than both the adaptive configurations and the distance-based baseline across all prediction horizons. As the number of virtual nodes increases from 1 to 10, the overall performance improves, with the configurations of 1 and 2 virtual nodes already surpassing the baseline in some horizons. Notably, the Semi-10 V.N. configuration demonstrates significantly lower RMSE and MAPE compared to other semi-adaptive settings and the baseline, particularly in longer horizons. This indicates that a balanced complexity, as seen with the Semi-10 V.N. configuration, provides the optimal enhancement in prediction accuracy. When the number of virtual nodes reaches 20, the performance declines, suggesting that the optimal number of virtual nodes is around 10."}, {"title": "5.5 Visualization of virtual nodes", "content": "In this section", "Matrix": "We begin by visualizing the adjacency matrix that captures the connections between real nodes and virtual nodes. Figure 7a shows the heat map of this adjacency matrix for the semi-adaptive configuration with ten virtual nodes", "Map": "Next", "findings": "Virtual Nodes 3, 8, and 10 have stronger connections with multiple regions of the road network, while the remaining virtual nodes exhibit relatively weaker connections, suggesting that Virtual Nodes 3, 8, and 10 play crucial roles in aggregating information from the real nodes"}]}