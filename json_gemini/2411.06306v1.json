{"title": "Optimal Driver Warning Generation in Dynamic Driving Environment", "authors": ["Chenran Li", "Aolin Xu", "Enna Sachdeva", "Teruhisa Misu", "Behzad Dariush"], "abstract": "The driver warning system that alerts the human driver about potential risks during driving is a key feature of an advanced driver assistance system. Existing driver warning technologies, mainly the forward collision warning and unsafe lane change warning, can reduce the risk of collision caused by human errors. However, the current design methods have several major limitations. Firstly, the warnings are mainly generated in a one-shot manner without modeling the ego driver's reactions and surrounding objects, which reduces the flexibility and generality of the system over different scenarios. Additionally, the triggering conditions of warning are mostly rule-based threshold-checking given the current state, which lacks the prediction of the potential risk in a sufficiently long future horizon. In this work, we study the problem of optimally generating driver warnings by considering the interactions among the generated warning, the driver behavior, and the states of ego and surrounding vehicles on a long horizon. The warning generation problem is formulated as a partially observed Markov decision process (POMDP). An optimal warn-ing generation framework is proposed as a solution to the proposed POMDP. The simulation experiments demonstrate the superiority of the proposed solution to the existing warning generation methods.", "sections": [{"title": "I. INTRODUCTION", "content": "The road traffic plays an important role in people's lives. With the development of the complexity of city road net-works, it is crucial for an advanced driver assistance system to be able to alert the potential risks to the human driver during driving. As shown in the studies of the human driver behavior with the warning system [1]\u2013[3], existing driver warning technologies, mainly the forward collision warning and unsafe lane change warning, can reduce the risk of collision caused by human errors.\nHowever, studies show that the human drivers' reactions to warnings vary with the type of warning and different drivers [4], [5], while the existing methods have not addressed this phenomenon adequately. Most methods in the literature mainly generate the warning in a one-shot manner without modeling the ego driver's reactions and surrounding objects [6]\u2013[8], which reduces the flexibility and generality of the system over different drivers and scenarios. Meanwhile, the triggering conditions of warning are mostly rule-based threshold-checking based on the current state, such as the time-to-collision (TTC) and the minimum safety distance [9]\u2013[11], which lacks the prediction of the potential risk in a sufficiently long future horizon. As a consequence, the current warning systems, while effective in preventing collisions, tend to prompt urgent and uncomfortable braking actions. Studies have emphasized the importance of execut-ing smoother and more comfortable braking maneuvers to assist drivers in avoiding not only identified dangers but also collisions with subsequent vehicles [12].\nThis work seeks to address these issues by formulating an optimal warning generation problem that considers the relation between the generated warning and the driver's reaction and also the interaction between the ego vehicle and other agents on a long horizon. The problem is modeled as a partially observed Markov decision process (POMDP), in which we quantify the value of warnings through the comfort and safety of the future ego vehicle trajectory in the context of surrounding objects, and the cost through their format and frequency. An optimal warning generation framework is proposed as a solution to the POMDP. The key contributions of this work are as follows:\nWe propose a novel formulation of the optimal warning generation problem that considers the driver and surround-ing vehicle reactions, and both the safety and the comfort of future ego trajectories.\nWe propose a warning generation framework combining driver behavior estimation as the solution to the above problem. The framework has the flexibility to incorporate any prediction models of the driving scenario.\nThe proposed method is evaluated over comprehensive closed-loop simulation experiments, which demonstrates the superiority of the proposed solution to the existing warning generation methods."}, {"title": "II. RELATED WORKS", "content": "A. Driver warning system\nMost methods in the literature generate the warning through threshold-checking based on the current state. [7] generates the warnings by continuously comparing Time Headway with a flexible threshold that is updated based on drivers' actions. [8] generates warnings based on the distance identified from the front camera and the drivers' attention identified from the inside camera. Some methods consider a longer horizon by utilizing a learned neural network. The method in [11] and [13] utilizes a neural network to predict the driver's behavior and generate warnings based on the TTC threshold. There are also some methods trying to solve the problem through vehicle-to-vehicle connections. In [10], warnings are produced based on the driving intention of other vehicles which are transmitted to the ego vehicle through vehicle-to-vehicle (V2V) communication."}, {"title": "III. PROBLEM FORMULATION", "content": "A. Ego Driving Behavior\nTo provide necessary and accurate warning information to the ego driver, it is essential to model the ego driving be-havior, which can be represented by a driving policy $\\pi(a|s_t)$. a denotes the driver's action including the acceleration and steering angle. $s_t$ is the current state of the scenario, including ego dynamic states and its history $x_t$, all the N surrounding agents' dynamic states and their history $Y_t = \\{y_t^1, ..., y_t^N\\}$, and all the other environment information like map and so forth.\nWe model the ego driving behavior into four different modes, as shown in Table I. Before the warning is provided, the ego driver may already notice the danger and drive safely considering all the other agents. The ego driving behavior under this mode is denoted by $\\pi_{safe}(a|s_t = (X_t, Y_t))$.\nMeanwhile, the ego driver can also be distracted and carelessly ignore the danger, under which the policy can be denoted as $\\pi_{blind}(a|s_t)$. Even though the driver is driving unsafely under $\\pi_{blind}$, the driving behavior should still follow the human driving properties. Thus, we can derive $\\pi_{blind}$ from $\\pi_{safe}$ by masking out $Y_t$:\n$\\pi_{blind}(a|s_t) = \\pi_{safe}(a|s_t = (x_t, 0)).$ (1)\nAfter the warning, it can be observed that sometimes the driver tends to decelerate immediately before really considering the scene and optimizing their actions [4]. The action policy on this mode is denoted by $\\pi_{brake}(T_R)(a|s_t)$. Under this policy, the ego driver will take brake action for $T_R$ time, and recover to $\\pi_{safe}$ after that:\n$\\pi_{brake}(T_R)(a|s_t) =\\begin{cases}\na_{decelerate}, & t < T_R \\\\\n\\pi_{safe}(a|s_t = (X_t, Y_t)), & t \\geq T_R\n\\end{cases}$ (2)\nwhere $a_{decelerate}$ is a fixed action that has negative accel-eration and $T_R$ is a fixed parameter as it is a feature of an individual. Note that $\\pi_{brake}$ is always a sub-optimal compared with $\\pi_{safe}$ as its action space during $T_R$ is a subset of $\\pi_{safe}$.\nIn addition to that, it also takes some time before the human really begins to react to the warning [1], [2], [12]. To describe this behavior, we define the delay policy $\\pi_{delay} (\\pi_1, \\pi_2, T_D)(a|s_t)$. When driving with this policy, the ego driver will follow $\\pi_1$ for $T_D$ time and switch to $\\pi_2$ after that, where $\\pi_1$ and $\\pi_2$ can be any driving policies except delay itself:\n$\\pi_{delay}(\\pi_1, \\pi_2, T_D)(a|s_t) = \\begin{cases}\n\\pi_1(a|s_t), & t < T_D \\\\\n\\pi_2(a|s_t), & t \\geq T_D\n\\end{cases}$ (3)\nSimilarly, we are also considering $T_D$ is fixed over different combinations of behaviors, as it is a feature of an individual.\nIn practice, those behaviors can be obtained through different methods, such as data-driven methods in [14]\u2013[17] and model-based methods in [18]\u2013[21]. We don't assume any specific methods in our framework.", "B. Behavior Transition": "After providing the warning information, there is a chance that the driver doesn't notice the warning and doesn't react to the warning [2], [4], [5]. Meanwhile, the different levels of warning can make drivers react to the scene in different ways [4], [12]. Thus, it is crucial to model the behavior transition of the driver when receiving the warnings. Let\n$\\Gamma(\\pi_i, w_t) = Pr(\\pi_j|\\pi_i, w_t)$ (4)\nrepresent the probability of the driving policy $\\pi_i$ switching to another policy $\\pi_j$ after receiving the warning $w_t \\in W$, where $W = \\{No warning, Text, Voice, Alarm, Take over\\}$ is the set of possible warnings that can be provided to the driver.\nIn practice, this model can be obtained through the human drivers' data. However, there is still some domain knowledge that needs to be included. When the scenario is extremely dangerous and the system decides to take over the control to force the vehicle to slow down, the driving policy will switch to $\\pi_{brake}$ immediately without any delay. Meanwhile, as $\\pi_{brake}$ is a more cautious behavior than $\\pi_{safe}$, any warning can only transform $\\pi_{safe}$ to $\\pi_{brake}$ but not the opposite direction.", "C. System Modeling": "With the modeling of the ego driving behavior and its transition, the warning generation problem can be discretized and modeled as a Markov decision process (MDP) problem,"}, {"title": "IV. BEHAVIOR ESTIMATION", "content": "As discussed in the previous section, in practice, it can be difficult for the system to directly obtain the current ego driving behavior. However, the states of the scenario $s_t$ as well as the driver's actions $a_t$ are easy to access through sensors. Therefore, we can estimate the ego driver's behavior through the state measurements and driver's actions by Bayesian inference. The estimation is computed with three steps: model prediction, observation correction, and state transition. These steps compose a generic design, thus when we have some other observations of the driving behavior like head pose and and gaze [7], [25], it can be fused into these steps easily.\n1) Model prediction: Let $b(\\pi^{BW})$ denote the estimated behavior distribution, and $b(\\pi^{BW}_0)$ be the initial estimated distribution. After receiving the warning, the estimation will be updated with the model:\n$\\bar{b}(\\pi^{AW}) = \\sum_{\\pi \\in \\Pi} \\Gamma(\\pi, w_t)b(\\pi^{BW} = \\pi),$ (8)\nwhere $\\bar{b}(\\pi^{AW})$ is the estimated distribution after the model prediction step, $\\Pi$ is the set that contains all possible driving policies.\n2) Observation correction: After the ego driver takes an action $a_t$, the estimated behavior will be updated through the Bayesian inference:\n$b^{+}(\\pi^{AW} = \\pi) = \\frac{\\pi(a_t|s_t) \\times \\bar{b}(\\pi^{AW} = \\pi)}{\\sum_{\\pi \\in \\Pi} \\pi(a_t|s_t) \\times \\bar{b}(\\pi^{AW} = \\pi)},$ (9)\nwhere $b^{+}(\\pi^{AW})$ is the estimated distribution after the obser-vation correction step.\n3) State transition: Based on the state transition modeling Eq. (6), the estimated distribution of the behavior at the next step before the warning can be obtained by:\n$b(\\pi^{BW}_{t+1}) = b^{+}(\\pi^{AW}).$ (10)\nNote that for behavior $\\pi_{brake}$ and $\\pi_{delay}$ that have internal behavior transitions, such transitions may happen as time passes and will be captured during this state transition update step."}, {"title": "V. OPTIMAL WARNING SEARCHER", "content": "With the estimated behavior distribution, the problem can be solved either through the MDP formulation which utilizes the most probable behavior from estimation, or POMDP which considers the whole estimated distribution and solves the optimization over the belief space. However, due to the complexity of the problem and the exponential tendency of the development of future states, it is infeasible to solve the exact POMDP problem in real-time. In the following subsec-tions, we investigate two different approximated solutions to the POMDP problem.\nA. MDP with estimated state\nAfter acquiring the estimated behavior distribution, we can extract an estimate from the distribution as an estimated state and solve the problem as MDP. The behavior estimates are generated by the following equation:\n$\\pi^{*BW}_t = \\begin{cases}\n\\pi_{blind}, & b(\\pi^{BW} = \\pi_{blind}) > T h_{safety} \\\\\narg \\max_{\\pi} b(\\pi^{BW} = \\pi), & otherwsie\n\\end{cases},$ (11)\nwhere $\\pi^{*BW}_t$ is the extracted estimates at time step t, $T h_{safety}$ is a safety threshold to satisfy the robustness and safety requirement of the warning system."}, {"title": "VI. EXPERIMENTS", "content": "In this section, we conduct several experiments to eval-uate the proposed framework. In Sec. VI-A, we introduce the environment setting and configurations of the proposed framework for experiments and the rule-based warning gen-erator baseline. In Sec. VI-B, we present the closed-loop simulations and provide an analysis of the performance."}, {"title": "VII. CONCLUSIONS", "content": "In this work, we study the problem of optimally generating driver warnings by considering the interactions between the generated warning and the driver behavior. We propose a flexible POMDP formulation with an optimal warning gen-eration framework to solve the proposed problem. Simulation results demonstrate the superiority of the proposed solution to the existing warning generation methods."}]}