{"title": "INTELLIGENCE AT THE EDGE OF CHAOS", "authors": ["Shiyang Zhang", "Aakash Patel", "Syed A Rizvi", "Nianchen Liu", "Sizhuang He", "Amin Karbasi", "Emanuele Zappala", "David van Dijk"], "abstract": "We explore the emergence of intelligent behavior in artificial systems by inves-\ntigating how the complexity of rule-based systems influences the capabilities of\nmodels trained to predict these rules. Our study focuses on elementary cellu-\nlar automata (ECA), simple yet powerful one-dimensional systems that generate\nbehaviors ranging from trivial to highly complex. By training distinct Large Lan-\nguage Models (LLMs) on different ECAs, we evaluated the relationship between\nthe complexity of the rules' behavior and the intelligence exhibited by the LLMs,\nas reflected in their performance on downstream tasks. Our findings reveal that\nrules with higher complexity lead to models exhibiting greater intelligence, as\ndemonstrated by their performance on reasoning and chess move prediction tasks.\nBoth uniform and periodic systems, and often also highly chaotic systems, re-\nsulted in poorer downstream performance, highlighting a sweet spot of complexity\nconducive to intelligence. We conjecture that intelligence arises from the ability\nto predict complexity and that creating intelligence may require only exposure to\ncomplexity.", "sections": [{"title": "INTRODUCTION", "content": "The emergence and nature of intelligence within computational systems have long been subjects of\nfascination and rigorous study in the fields of artificial intelligence (AI) and theoretical computation.\nTraditional AI methodologies predominantly involve training models on high-quality datasets inher-\nently imbued with human intelligence\u2014such as natural language corpora, expert-annotated datasets,\nor data reflecting human cognitive processes (Coleman et al., 2019). This approach operates under\nthe assumption that creating intelligent behavior necessitates exposure to intelligent data sources. In\ncontrast, this paper explores an alternative hypothesis: that intelligence can emerge from modeling\nsimple systems as long as they exhibit complex behaviors, even when the process that generates the\ndata lacks inherent intelligence.\nTo investigate this hypothesis, we utilize Stephen Wolfram's elementary cellular automata (ECA)\nas our experimental framework. ECAs are one-dimensional, binary-state, discrete computational\nsystems defined by 256 possible 8-bit rules. They generate a diverse spectrum of behaviors ranging\nfrom simple, repetitive patterns to highly complex and chaotic structures (Wolfram, 1983). Despite\ntheir simple rule-based definitions, certain ECAs produce patterns of significant complexity, making\nthem ideal for examining the relationship between intelligence and complexity.\nOur methodology involves training separate instances of the GPT-2 language model (Radford et al.,\n2019) on datasets generated by individual ECAs. The models are tasked with predicting future"}, {"title": "BACKGROUND", "content": ""}, {"title": "ELEMENTARY CELLULAR AUTOMATA", "content": "Cellular automata (CAs) are computational models of complex systems, consisting of a grid of cells\nthat evolve over time based on simple rules. They were first introduced by John von Neumann in the\n1940s (von Neumann, 1966). CAs have been widely used to simulate various physical, biological,\nand computational systems due to their simplicity and ability to produce complex behavior.\nElementary Cellular Automata (ECAs) (Wolfram & Mallinckrodt, 1994) are a type of one-\ndimensional cellular automaton where each cell has a binary state, and its next state is determined\nby a simple rule that depends only on the current state of the cell and its two immediate neighbors.\nThere are 256 possible ECA rules, 88 of which are unique after accounting for symmetries(Castillo-\nRamirez & Maga\u00f1a-Chavez, 2023). Notable examples include Rule 110, which has been proven to\nbe Turing complete(Cook, 2009), and Rule 90, which generates the fractal-like Sierpinski triangle.\nThese rules are categorized into four classes based on their behavior when initialized with random\nconditions: Class I, which evolves to a homogeneous state; Class II, which forms simple periodic\nstructures; Class III, which produces chaotic and aperiodic patterns; and Class IV, which exhibits\ncomplex structures (Castillo-Ramirez & Maga\u00f1a-Chavez, 2023).\nECAs are valuable computational models used to explore complex systems and emergent behav-\niors arising from simple rules. Their usefulness lies in their simplicity and the variety of patterns\nthey can produce, making them ideal for studying pattern formation in computation (Meunier,\n2016), physics (Banerjee & Dalui, 2024), and mathematical biology (Rasolonjanahary & Vasiev,\n2020). Additionally, ECAs have been utilized in cryptography as a basis of certain security frame-\nworks (Corona-Berm\u00fadez et al., 2022) and in computer science education (Staubitz et al., 2016) to\nillustrate concepts in algorithms and computational theory. Their ability to model intricate systems\nwith minimal computational resources has made ECAs a popular tool across scientific disciplines."}, {"title": "LARGE LANGUAGE MODELS", "content": "Large language models (LLMs) are advanced artificial intelligence systems designed to understand\nand generate human-like text based on vast datasets (Brown et al., 2020). By leveraging deep learn-\ning techniques, these models analyze patterns in language to perform tasks such as translation, sum-\nmarization, and conversational dialogue (Devlin et al., 2018). Notable examples like OpenAI's\nGPT-4 have demonstrated remarkable capabilities in producing coherent and contextually relevant\nresponses across a wide range of topics(Achiam et al., 2023). The development of LLMs repre-\nsents a significant advancement in natural language processing, opening up new possibilities for\napplications in education, research, and industry (Katz et al., 2023)."}, {"title": "COMPLEXITY MEASURES", "content": "Various complexity measures have been proposed to assess the behavior of dynamical systems. In\nthis work, we employ the following measures:\n1. Lempel-Ziv Complexity assesses the compressibility of a sequence by counting the num-\nber of unique substrings in the sequence (Lempel & Ziv, 1976)."}, {"title": "METHODOLOGY", "content": "In this study, we systematically investigate the relationship between system complexity and emer-\ngent intelligence. This section outlines our methodology, including the steps for data generation and\nmodel pretraining. An overview of the training process and task evaluations is provided in Figure 1."}, {"title": "DATA GENERATION", "content": "To train our models, we simulate a selection of ECA rules. Each simulation generates a sequence\nof binary vectors, where each vector represents the system's state at a specific time step. For each\nsample, we begin with a randomly initialized vector as the automaton's initial state. The system\nis then evolved over 1000 time steps by repeatedly applying the chosen ECA rule. This process\nproduces a sequence of binary vectors that capture the evolving dynamics of the ECA over time.\nTo increase the diversity of the training data, we extract random spatiotemporal windows from the\nfull sequences. Specifically, we sample subsequences by selecting random windows of 60 time steps\nand 100 spatial dimensions from the binary vectors. This method exposes the model to a variety of\ncontexts and state configurations, enhancing its ability to learn the dynamics of the ECA rules and\ngeneralize to new sequences. Each training sequence represents a randomly selected segment in"}, {"title": "TRAINING PROCEDURE FOR GPT-2 MODELS", "content": "We utilized a modified GPT-2 architecture Radford et al. (2019) adapted for binary input and output\ndata, enabling it to perform next-token prediction on sequences of binary states. Instead of using a\ntraditional token embedding layer followed by a softmax over a vocabulary, we replaced the token\nembeddings with a linear projection layer that directly maps binary vectors into the model's embed-\nding space. The GPT-2 model processes these embeddings to capture temporal dependencies and\npatterns within the sequences. At the output, we apply a linear projection layer to map the model's\nhidden states back to the data dimensionality, generating the prediction for the next state of binary\nvariables at each time step. This adaptation allows the GPT-2 model to handle binary data directly\nand perform next-token prediction without relying on a predefined vocabulary. This also makes the\nmodel deterministic, in line with the deterministic nature of ECAS."}, {"title": "PRETRAINING SETUP", "content": "Each model was pretrained on next-token prediction using data generated from a single ECA rule for\nup to 10,000 epochs. Early stopping based on validation loss was utilized to prevent overfitting and\nconserve computational resources. The training data were organized into batches of 64 sequences,\neach comprising 60 time steps and 100 spatial dimensions.\nWe employed the Adam optimizer with an initial learning rate \u03b7 = 2 \u00d7 10-6and a weight decay\nof 0.01. A learning rate scheduler with a linear warm-up over the first 10% of the total steps was\nimplemented to stabilize the initial stages of training and improve convergence rates. After the\nwarm-up phase, we applied cosine annealing to gradually decay the learning rate over the remaining\ntraining steps. Gradient accumulation was used to handle larger effective batch sizes within the\nconstraints of GPU memory, allowing us to simulate larger batch sizes by accumulating gradients\nover multiple mini-batches. To prevent exploding gradients, we applied gradient clipping with a\nmaximum norm of 1.0."}, {"title": "EXPERIMENTS", "content": "To evaluate the emergent intelligence of models trained on cellular automata, we conducted experi-\nments on three downstream tasks: one easy and one hard reasoning task inspired by the Abstraction\nand Reasoning Corpus (ARC) (Chollet, 2019), and a challenging chess move prediction task. These\ntasks were designed to quantify the models' abilities in reasoning, abstraction, and long-term predic-\ntion, thereby assessing the level of intelligence encoded during pretraining on ECA rules of varying\ncomplexities. We freeze the layers of the pretrained GPT-2 models and train only the input and out-\nput projection layers for downstream tasks to ensure that performance differences reflect the inherent\ncapabilities of the models.\nOur central hypothesis is that models pretrained on complex rules will exhibit superior performance\non downstream tasks compared to those pretrained on simple rules. The inclusion of both easy and\nhard tasks allows us to observe different performance trends and better understand the relationship\nbetween pretraining complexity, task difficulty, and emergent intelligence. The chess move predic-\ntion task, in particular, serves as an excellent system to test reasoning due to its inherent complexity\nand requirement for strategic thinking."}, {"title": "DOWNSTREAM TASK: REASONING", "content": "We developed a downstream task inspired by the ARC (Chollet, 2019) to evaluate models' problem-\nsolving and reasoning abilities. Our approach utilizes sequence completion problems that require\nthe model to infer transformation rules from provided examples and apply them to novel scenarios.\nThe data consists of a fixed number of shapes on a grid. At each time step, any of the following\ntransformations can be applied to each shape: changing the color, rotating the shape by 90\u00b0, or"}, {"title": "DOWNSTREAM TASK: CHESS MOVE PREDICTION", "content": "For the chess experiment, we evaluated the capability of the different ECA-pretrained models to\npredict next moves in chess games represented using Standard Algebraic Notation (SAN)(Alg). We\nuse chess games from the Lichess Elite database (Lic), focusing on games played between January\nand April 2016 by Grandmasters with ratings of 2200 and above. Each game was represented as\na sequence of SAN moves. We split this collection into training, validation, and test sets using an\n80-10-10 split to facilitate model training and evaluation. Each game sequence was segmented into\nsubsequences of 60 moves each, and any subsequence shorter than this length was padded sequences\nto length 60.\nWe added an embedding layer to convert the SAN tokens into vector representations, which were\nthen processed using the frozen ECA-pretrained model. A linear output layer was used to transform\nthe outputs to the vocabulary size corresponding to the SAN tokens. These input and output layers\nwere trained while the rest of the model was frozen. The model was trained using cross-entropy loss,\nthe Adam optimizer(Kingma, 2014), and a learning rate scheduler with warm-up. Early stopping\nwas also implemented."}, {"title": "HARDWARE AND SOFTWARE", "content": "The experiments were conducted using PyTorch version 2.1.2 and the Transformers library (version\n4.41.0), with CUDA version 12.4 for GPU acceleration. The models were trained on 12 NVIDIA\nH100 GPUs, each with 80 GB of memory, running on Red Hat Enterprise Linux 8.8."}, {"title": "RESULTS", "content": "In this section, we present our results exploring the relationship between system complexity and\nemergent intelligence in LLMs. The following sections detail our analyses of task performance and\nattention patterns across models trained on varying rule complexities."}, {"title": "RELATIONSHIP BETWEEN INTELLIGENCE AND COMPLEXITY", "content": "Figure 2 presents the model performance across three downstream tasks (easy reasoning, hard rea-\nsoning, and chess move prediction) as a function of the complexity of the ECA rules the models\nwere pretrained on. The top row highlights the relationship between performance and the Lempel-\nZiv complexity of the rules, while the bottom row categorizes the performance by Wolfram's com-\nplexity classes. For clarity, two representative rules from each complexity class are displayed on the\nleft, with their corresponding performance annotated in the top plots.\nFor the reasoning tasks, models generally achieve near-perfect accuracy when trained for sufficient\nlong time. Therefore, instead of reporting absolute accuracy, we focus on model efficiency, defined"}, {"title": "MODELS LEARN COMPLEX SOLUTIONS FOR SIMPLE RULES", "content": "The elementary cellular automata (ECA) are inherently memoryless, meaning the state at the next\ntime point is determined only by the current time point, without any consideration of past states. For\neach model, a straightforward solution exists: simply learning the 8-bit ECA rule and applying it to\nthe current state to predict the next state. However, alternative solutions may also be possible, where\nthe model leverages historical states for its predictions. The key question is whether the model is\nmerely learning the trivial solution or if it is integrating information from the state history.\nTo explore this, we analyze the self-attention scores with respect to the last state in the input se-\nquence, which the model uses to predict the next state (see Section 3.2). Specifically, we examine\nthe attention values corresponding to the final ten states before the target state. Figure 4 illustrates"}, {"title": "CONCLUSION", "content": "We hypothesize that the emergence of intelligence is closely tied to a model's capacity to predict\nand process complexity. Based on our results, we conjecture that training models on increasingly\ncomplex data may be sufficient to generate intelligent behavior. Perhaps complexity is all you need?"}]}