{"title": "EvoAL 2048", "authors": ["Bernhard J. Berger", "Christina Plump", "Rolf Drechsler"], "abstract": "Explainability and interpretability of solutions generated by AI products are getting more and more important as AI solutions enter safety-critical products. As, in the long term, such explanations are the key to gaining users' acceptance of AI-based systems' decisions [4].\n\nWe report on the application of a model-driven optimisation to search for an interpretable and explainable policy that solves the game 2048. This paper describes a solution to the Interpretable Control Competition [6]. We focus on solving the discrete 2048 game challenge using the open-source software EVOAL [2, 8] and aimed to develop an approach for creating interpretable policies that are easy to adapt to new ideas. We use a model-driven optimisation approach [5] to describe the policy space and use an evolutionary approach to generate possible solutions. Our approach is capable of creating policies that win the game, are convertible to valid Python code, and are useful in explaining the move decisions.", "sections": [{"title": "INTRODUCTION", "content": "Explainability and interpretability of solutions generated by AI products are getting more and more important as AI solutions enter safety-critical products. As, in the long term, such explanations are the key to gaining users' acceptance of AI-based systems' decisions [4].\n\nWe report on the application of a model-driven optimisation to search for an interpretable and explainable policy that solves the game 2048. This paper describes a solution to the Interpretable Control Competition [6]. We focus on solving the discrete 2048 game challenge using the open-source software EVOAL [2, 8] and aimed to develop an approach for creating interpretable policies that are easy to adapt to new ideas. We use a model-driven optimisation approach [5] to describe the policy space and use an evolutionary approach to generate possible solutions. Our approach is capable of creating policies that win the game, are convertible to valid Python code, and are useful in explaining the move decisions."}, {"title": "APPROACH", "content": "The proposed solution builds on EvoAL-a Java-based data-science research tool-which allows users to express optimisation problems using domain-specific languages (DSLs) and offers a rich extension API for problem-specific extensions. EvoAL offers different optimisation algorithms, such as evolutionary algorithms, genetic programming, and model-driven optimisation.\n\nNormally, EvoAL uses two DSLs to configure an optimisation problem. Using the data description language, a user can specify the problem-specific data. The mapping to an optimisation algorithm and the algorithm configuration is done by using the optimisation language. As we aim to use a model-driven approach, we use a third DSL of EVOAL-the definition language-to describe the abstract syntax [3] of the policy. The generated model is then turned into Python code by using model-to-text concepts."}, {"title": "EXPERIMENTAL RESULTS", "content": "The allowed budget contains 200.000 evaluations of the game. We configured the EA to use a population size of 100 individuals. For a fitness evaluation, we decided to simulate six games with the same policy, resulting in 200000 / 6 = 333 generations that can be executed.\n\nFigure 3 shows the development of the highest tile reached during the evolution process. As a policy run simulates six games, the data points in dark blue show the best highest tile value of a policy run and the light blue data points show the average value of the highest tile of a policy run. The filled data points represent the best individual of a generation, while the non-filled data points represent the average result of a generation. The depiction shows that whenever the process succeeds in generating a new best highest tile, the average highest tile first improves (the policies are getting more stable) before the best highest tile can reach the next level.\n\nThe result of the optimisation run is a policy that reached a max(highest-tile) of 2.048, an average(highest-tile) of 1.276, and an average (total-score) of 14.093.\n\nThe shown policy focuses on increasing the score gain and chooses to go in the direction that promises higher score gain. The remaining queries, such as willBeSorted, are part of some poli-cies but did not make it into the best policy. At the same time, the policy only uses three out of four directions, which might leave room for further improvement, but we assume that the situation where the board would have to be moved into the fourth direction occurs very seldom.\n\nHaving a given board situation, the policy allows one to explain precisely why a certain move was made. On the one hand, the state queries are easy to understand and, on the other hand, they can be calculated for a given board to show the decision process. While being explainable, our approach is flexible and can easily be extended with additional queries without having to change the optimisation process."}]}