{"title": "Towards Understanding the Role of Sharpness-Aware Minimization Algorithms for Out-of-Distribution Generalization", "authors": ["Samuel Schapiro", "Han Zhao"], "abstract": "Recently, sharpness-aware minimization (SAM) has emerged as a promising method to improve generalization by minimizing sharpness, which is known to correlate well with generalization ability. Since the original proposal of SAM by Foret et al. (2021), many variants of SAM have been proposed to improve its accuracy and efficiency, but comparisons have mainly been restricted to the i.i.d. setting. In this paper we study SAM for out-of-distribution (OOD) generalization. First, we perform a comprehensive comparison of eight SAM variants on zero-shot OOD generalization, finding that the original SAM outperforms the Adam baseline by 4.76% and the strongest SAM variants outperform the Adam baseline by 8.01% on average. We then provide an OOD generalization bound in terms of sharpness for this setting. Next, we extend our study of SAM to the related setting of gradual domain adaptation (GDA), another form of OOD generalization where intermediate domains are constructed between the source and target domains, and iterative self-training is done on intermediate domains, to improve the overall target domain error. In this setting, our experimental results demonstrate that the original SAM outperforms the baseline of Adam on each of the experimental datasets by 0.82% on average and the strongest SAM variants outperform Adam by 1.52% on average. We then provide a generalization bound for SAM in the GDA setting. Asymptotically, this generalization bound is no better than the one for self-training in the literature of GDA. This highlights a further disconnection between the theoretical justification for SAM versus its empirical performance, as noted in Wen et al. (2023), which found that low sharpness alone does not account for all of SAM's generalization benefits. For future work, we provide several potential avenues for obtaining a tighter analysis for SAM in the OOD setting. In summary, our theoretical results provide a solid starting point for analyzing SAM in OOD settings, and our experimental results demonstrate that SAM can be applied to OOD settings to significantly improve accuracy, and that newer variants of SAM can be leveraged for further improvements in accuracy.", "sections": [{"title": "1 Introduction", "content": "A promising new optimization algorithm called Sharpness-Aware Minimization (SAM) exploits a known relationship between the \"flatness\" of a minimum and its i.i.d. generalization (Jiang et al., 2020; Dinh et al., 2017; Keskar et al., 2017; Hochreiter & Schmidhuber, 1997), proposing a robust optimization procedure that leads to significant performance gains in the i.i.d. setting (Foret et al., 2021). However, SAM remains remains understudied in the out-of-distribution (OOD) generalization setting, which is central topic of interest at this time, both theoretically and empirically (Kumar et al., 2020; Cha et al., 2021; Arjovsky et al., 2020; He et al., 2024; Ye et al., 2021; Zhao et al., 2022; 2019; Ben-David et al., 2010). Furthermore, a number of SAM variants have been proposed to improve the accuracy and efficiency of the original SAM algorithm, with comparisons mainly restricted to the i.i.d. setting (Kim et al., 2022; Li et al., 2024; Du et al., 2022; Kwon et al., 2021; Mueller et al., 2024; Liu et al., 2022; Ni et al., 2022).\nInspired by the practical success of SAM and its variants in the i.i.d. setting and interested in its potential to enhance OOD generalization, we perform an empirical and theoretical study of OOD generalization with SAM and its variants. Our work makes the following contributions:\n1. In Section 2, we provide an introduction to eight SAM variants, including the original SAM. Then, in Section 3, we perform a comprehensive comparison of the zero-shot OOD generalization capabilities for these eight SAM variants. We find over four empirical benchmarks that SAM outperforms the Adam baseline by 4.76% on average and that strongest SAM variants outperform the Adam baseline by 8.01%. This suggests that SAM can be used to improve zero-shot OOD generalization, and that the strongest SAM variants can be used for an even further improvement.\n2. To understand these performance gains, in Section 3.3 we provide a theoretical analysis of SAM under the distribution shift setting, with an OOD generalization bound based on sharpness in Lemma 1 derived in Section 3.3.\n3. Next, in Section 4.2, we extend the setting considered above to gradual domain adaptation, where we have a sequence of unlabeled intermediate domains leading from the source to target domain. Our experiments across all four benchmarks demonstrate that SAM outperforms the Adam baseline by 0.82% on average and the strongest SAM variants achieve an even greater 1.52% average improvement over Adam, suggesting that SAM and the strongest SAM variants can be used for consistent performance gains in GDA as well.\n4. Finally, in Section 4.4, we provide a bound extending Lemma 1 to the GDA setting and compare it to the prior bound in Wang et al. (2022) in Section 4.5. Although it is asymptotically the same as prior work in the GDA literature (Wang et al., 2022), we present several potential avenues for tightening this bound in future work in Section 4.6."}, {"title": "2 Preliminaries", "content": "Classifier and Loss We consider a parametric model family \u0472 C Rk with each model defined with respect to a specific choice of parameter \u03b8\u2208 \u0398. The classifier induced from a model @ is denoted fo : X \u2192 Y. We consider bounded loss functions l : Y \u00d7 X \u00d7 \u04e8 \u2192 [0,1] and define the population and empirical risk with respect to (w.r.t.) parameters \u03b8\u2208 \u0398as E(\u03b8) := E(x,y)~\u03bc[l(y, x, 0)], for"}, {"title": "2.1 Background on SAM Variants", "content": "In Algorithm 1, we provide flexible algorithmic psuedocode for SAM with variant-specific oracles to account for the fact that the SAM variants compute the gradients, perturbations, and final descent steps in different ways. Below, we provide a brief explanation of the modifications each of the SAM variants makes to the gradients, perturbations, and final descent steps."}, {"title": "3 A Study of SAM for Zero-Shot OOD Generalization", "content": "In this section, we perform experiments comparing all eight of the previous SAM variants for zero-shot OOD generalization in Section 3.1, discuss the key takeaways from the experiments in Section 3.2, and perform a theoretical analysis of SAM for OOD generalization in Section 3.3."}, {"title": "Zero-Shot OOD Generalization", "content": "In zero-shot OOD generalization, a model es is trained on a source domain S \u2208 \u2206(X \u00d7 Y) with a training set {(xi, Yi)}=1 drawn i.i.d. from S. Then, \u03b8\u03c2 is evaluated on a test set drawn i.i.d. from a target domain T\u2208 \u2206(X \u00d7 V). The zero-shot OOD generalization error is given by Er(0s)."}, {"title": "3.1 Experiments Comparing SAM Variants for Zero-Shot OOD Generalization", "content": "Datasets We use the same datasets as Wang et al. (2022), with a brief description of each given below."}, {"title": "3.2 Discussion of Results", "content": "In Table 2, we report the zero-shot OOD accuracy on the 1 \u2013 \u0415\u0442(0s) for each of the optimizers. Across all four datasets, the original SAM outperforms the Adam baseline by 4.76% on average, while the strongest SAM variants outperform the baseline by 8.01% on average. Variants such as LookSAM, F-SAM, and FisherSAM offer the strongest and most consistent improvement over SAM. Among the variants with reduced computational cost (ESAM, LookSAM, K-SAM, and NoSAM), LookSAM and NoSAM perform the best, often outperforming original SAM in addition to being more efficient."}, {"title": "Understanding the FisherSAM Performance Gains", "content": "To recall, FisherSAM computes the perturbation according to:"}, {"title": "Understanding the FriendlySAM Performance Gains", "content": "Unlike FisherSAM, the connection between the FriendlySAM objective and OOD performance is not as explicit. To recall, FriendlySAM computes the perturbation according to"}, {"title": "3.3 Theoretical Analysis of SAM for OOD Generalization", "content": "To start, we define the Wasserstein distance, which we use to capture the distance between probability distributions."}, {"title": "4 A Study of SAM for Gradual Domain Adaptation", "content": "In this section, we study SAM applied to a related OOD generalization setting called gradual domain adaptation (GDA), where self-training is performed on intermediate domains between the source and target domain to improve the target domain accuracy (Kumar et al., 2020; Wang et al., 2022; Zhuang et al., 2024; He et al., 2024). We provide an introduction to GDA in Section 4.1, describe our experimental setup in Section 4.2, discuss our experimental results in Section 4.3, provide a generalization bound based on sharpness for GDA in Section 4.4, compare our bound to that of the prior work Wang et al. (2022) in Section 4.5, and discuss several potential avenues for obtaining a tighter bound in Section 4.6."}, {"title": "4.1 Gradual Domain Adaptation (GDA)", "content": "Gradually Shifting Distributions We adopt the settings of Wang et al. (2022) and Kumar et al. (2020), where we have T + 1 gradually shifting distributions indexed by {0,1,...,T}, with 0 corresponding to the source domain. Each domain t \u2208 [T] is a distribution \u00b5t over X \u00d7 Y and we start with a training distribution {(xi, yi)}\u2081 drawn i.i.d. from the source domain \u03bc\u03bf. To ease the presentation, we assume that each subsequent domain has n unlabeled training examples, where n \u00ab no. We measure distribution shifts according to the Wasserstein distance and define the following shorthand notation."}, {"title": "Gradual Domain Adaptation", "content": "In gradual domain adaptation (GDA), a learner is given no labeled examples from a source domain with index t = 0, and then given sequential access to n unlabeled examples from domains t = {1, 2, ...,T}:"}, {"title": "4.2 Experiments Comparing SAM Variants for GDA", "content": "In this section, we perform an empirical study of SAM for GDA using the same four datasets as in Section 3.\nDatasets and Model Setup We use the same datasets and model setup as our earlier experiment, as detailed in Section 3.1. As in the experiments from Section 3, on Rotated MNIST, Color MNIST, and Portraits, we train for 100 epochs in the source domain for all optimizers, and on Covertype, we train for 25 epochs in the source domain. The results of this experiment are presented in Figure 1.\nSAM Variant Setup We use the same hyperparameter setup for the SAM variants as given in Appendix B. Due to limited compute, we do not perform the entire ablation of intermediate domains for all of the SAM variants. Instead, we choose the optimal number of intermediate domains T* for SAM from Figure 1 and obtain the results for this choice of T*."}, {"title": "4.3 Discussion of Results", "content": "In Figure 1, we report the target domain accuracy 1-\u0415\u0442(\u04e9\u0442) for each of the optimizers. Our results reveal that SAM outperforms Adam (SAM with p = 0) on all datasets: by 1.03% on Covertype, by 0.96% on Portraits, by 0.75% on Rotated MNIST, and by 0.53% on Color MNIST. This suggests that SAM can be applied to GDA to consistently achieve stronger performance. For most of the experimental datasets, any value of p\u2208 {0.01, 0.02, 0.05, 0.1, 0.2} tends to outperform Adam, suggesting that SAM is not too sensitive to the perturbation radius hyperparameter. On Rotated MNIST, Portraits, and Color MNIST, SAM with p = 0.2 leads to the strongest performance and the improvement is relatively monotonic in p, while on Covertype, SAM with p = 0.05 leads to the strongest performance.\nIn our study of SAM variants for GDA in Table 3, we find that the strongest SAM variants lead to an average improvement of 1.42% compared to using Adam, in comparison to SAM, which only"}, {"title": "4.4 Generalization Bound for SAM for GDA", "content": "In this section, we provide an extension of Theorem 1 to the related setting of gradual domain adaptation (GDA), a technique which improves target domain error by performing gradual self-training (GST) on unlabeled intermediate domains between the source and target domain, for which the average distribution shift is small (Kumar et al., 2020; Wang et al., 2022). The algorithm that performs GDA by GST using SAM is presented in Algorithm 2."}, {"title": "4.5 Comparison of Sharpness-Aware Bound With Standard Bound", "content": "The bound we obtain in Theorem 2 is of the form"}, {"title": "4.6 Obtaining a Tighter Sharpness-Aware Error Analysis", "content": "In the proof of Theorem 2 in Appendix A, the only term that depends on the error difference between shifted domains is 7+1 =0 Et(\u03b8\u03c4), which is bounded by repeatedly applying Lemma 1 to domain pairs (\u03bct, \u03bct+1) for t \u2208 {0, 1, . . ., T\u22121}. Thus, we can expect the overall sample complexity to remain the same between our Theorem 2 and the main result in Wang et al. (2022). Assuming one continues to use the discrepancy based framework and the Sequential Rademacher Complexity from Kuznetsov & Mohri (2020b); Rakhlin et al. (2015), the only way to improve the analysis would be to provide a tighter error difference between shifted domains, as in Lemma 1, where we obtained\nWe conjecture that one may be able to get a tighter bound for SAM through a localized analysis that analyzes the error difference between shifted domains specifically for the sharpness-aware minimization classifier, in contrast to the current uniform analysis which applies to every classifier in the model class \u0398. A localized analysis could exploit implicit properties of SAM, such as denoised features (Chen et al., 2024), lower-rank features (Andriushchenko et al., 2023), or balanced feature learning (Springer et al., 2024), to get a tighter bound. However, we leave development of a localized analysis framework for future work."}, {"title": "5 Related Works", "content": "Sharpness and Generalization The study of the relationship between sharpness and general-ization dates back to at least Hochreiter & Schmidhuber (1997), which motivates flat minima by a minimum description length argument. Since then, Keskar et al. (2017) have explored how various hyperparameter choices affect sharpness and Jiang et al. (2020) have found that sharpness is among the empirical measures most strongly correlated with generalization. However, Dinh et al. (2017) demonstrated that sharp minima can indeed generalize under reparameterizations which cause flat minima to become arbitrarily sharp. A follow-up work of this proposes a measure of sharpness tied to the information geometry of the data that is invariant under reparameterizations (Liang et al., 2019). Many other works have continued to explore algorithms that lead to flatter solutions (Foret et al., 2021; Wortsman et al., 2022; Chaudhari et al., 2019) \u2013 notably, SAM (Foret et al., 2021) and empirical settings in which these algorithms work (Kaddour et al., 2022).\nSharpness and OOD Generalization In the context of domain generalization (DG), Cha et al. (2021) propose a modified version of stochastic weight averaging (Izmailov et al., 2018) which leads to flatter minima with improved DG. They also provide generalization bounds that depend on the"}, {"title": "6 Limitations and Future Work", "content": "The main limitation of this work is the discrepancy between our theoretical analysis based off sharpness, which is the same asymptotic rate as the prior work Wang et al. (2022), and our empirical results demonstrating consistent performance gains for SAM. At the end of Section 4.6, we posed a conjecture for how the analysis for SAM can be tightened. Future work can perform a more detailed theoretical analysis of SAM in order to explain the empirical benefits of using SAM for OOD generalization. Additionally, future work can attempt to theoretically explain the strong performance benefits of using SAM variants like FisherSAM and FriendlySAM for OOD generalization."}, {"title": "7 Conclusion", "content": "In this paper, we performed a theoretical and empirical study of SAM for OOD generalization. First, we experimentally compared eight SAM variants on zero-shot OOD generalization, finding that, across our four benchmarks, the original SAM achieved a 4.76% average improvement over the Adam baseline, while the strongest SAM variants achieved a 8.01% average improvement over the Adam baseline. Next, we derived an OOD generalization bound based on sharpness. Then, we experimentally compared the eight SAM variants on gradual domain adaptation (GDA), where intermediate domains are constructed between the source and target domain and iterative self-training is done on these intermediate domains to improve the target domain error. Our experiments found that, across our four benchmarks, the original SAM achieved a 0.82% average improvement over the Adam baseline, while the strongest SAM variants achieve a 1.42% average improvement over the Adam baseline. We provided an extension of our OOD generalization bound to get a generalization bound based on sharpness for GDA, which had the same asymptotic rate as the prior bound in Wang et al. (2022). This discrepancy between the theoretical and empirical results sheds light on the broader issue of giving tighter generalization bounds for SAM, especially in the OOD setting, to reconcile its consistent performance gains in practice. Our theoretical results provide a starting point for doing this, and our empirical results suggest that SAM can be used empirically to achieve significant gains for OOD generalization."}, {"title": "A Full Proofs", "content": ""}, {"title": "A.1 Sharpness-Aware Error Difference Over Shifted Domains", "content": "Restatement of Lemma 1. Given an error function E\u03bc(\u03b8) := E(x,y)~\u03bc[l(y, x, 0)] with loss satisfying Assumption 1 and any measures \u00b5, v on Y \u00d7 X, we have that"}, {"title": "A.2 Sharpness-Aware Domain Adaptation Error", "content": "Restatement of Theorem 1. Given distributions \u00b5,v over X \u00d7 Y and an error function E with loss satisfying Assumption 1 with some local minimum \u03b8\u03bc such that E\u03bc(\u03b8\u03bc) \u2264 E\u20ac~N(0,p21) [\u0395\u03bc(\u03b8\u03bc + \u20ac)] for some p > 0, then w.p. \u2265 1 \u2014 \u0431,"}, {"title": "A.3 Sharpness-Aware Generalization Bound", "content": "Restatement of Lemma 2. For any p > 0 and model \u03b8\u2208 \u04e8\u0441 Rk total parameters, if E(0) < \u0395\u03b5~\u039d (0,\u03c1\u00b21) [\u03b5(\u03b8 + \u0454)], then w.p. \u2265 1 \u2013 \u03b4,"}, {"title": "A.4 Total Sharpness-Aware Error Under GDA", "content": "Restatement of Theorem 2. For any d\u2208 (0,1), w.p. \u2265 1 \u2013 d, the population risk of the gradually adapted model Oy constructed from intermediate models 00,...,\u04e9\u0442\u22121 according to Algorithm 2 and satisfying \u2200t \u2208 [T], E(\u03b8) \u2264 E\u20ac~N(0,p21) [E(\u03b8t + \u20ac)] for some pt > 0, can be bounded according to:"}, {"title": "A.5 Helper Lemmas", "content": "Lemma 3 (Standard Error Between Shifted Domains - Lemma 1 of Wang et al. (2022)). Given an error function \u03b5\u03bc(\u03b8) := E(x,y)~\u03bc[l(y, x, 0)] with loss satisfying Assumption 1 and any measures \u03bc,\u03bd on Y \u00d7 X, we have that"}, {"title": "B SAM Variant Hyperparameters", "content": "Our experiments and hyperparameter search are performed over three random seeds for varying values of p\u2208 {0.01, 0.02, 0.05, 0.1, 0.2}, with the exception of ASAM. For ASAM, the authors suggest using a value of p that is roughly 10 times larger than the value for SAM, so we test \u03c1 \u0395 {0.1, 0.2, 0.5, 1, 2}. For K-SAM, we follow the guidance from the original paper and set K = B/2, where B is the batch size. For LookSAM, following the recommendations of the authors, we set k = 5 and test a \u2208 {0.5, 0.7, 0.1}. For FriendlySAM, following the original experiments, we set \u03c3 = 1 and test \u03c6\u2208 {0.6, 0.9, 0.95}. For ESAM, following the original experiments, we set y = 0.5 and we test \u03be\u2208 {0.5, 0.6}. Finally, for FisherSAM, we test \u03b7 \u2208 {0.01, 0.2, 0.5, 1}. In Table 1, we report the best accuracy values obtained over all hyperparameter settings for each SAM variant on each of the four datasets."}]}