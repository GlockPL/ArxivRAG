{"title": "Improving Bias in Facial Attribute Classification: A Combined Impact of KL Divergence induced Loss Function and Dual Attention", "authors": ["Shweta Patel", "Dakshina Ranjan Kisku"], "abstract": "Ensuring that AI-based facial recognition systems produce fair predictions and work equally well across all demographic groups is crucial. Earlier systems often exhibited demographic bias, particularly in gender and racial classification, with lower accuracy for women and individuals with darker skin tones. To tackle this issue and promote fairness in facial recognition, researchers have introduced several bias-mitigation techniques for gender classification and related algorithms. However, many challenges remain, such as data diversity, balancing fairness with accuracy, disparity, and bias measurement. This paper presents a method using a dual attention mechanism with a pre-trained Inception-ResNet V1 model, enhanced by KL-divergence regularization and a cross-entropy loss function. This approach reduces bias while improving accuracy and computational efficiency through transfer learning. The experimental results show significant improvements in both fairness and classification accuracy, providing promising advances in addressing bias and enhancing the reliability of facial recognition systems.", "sections": [{"title": "1 Introduction", "content": "Facial recognition(FR) technology [5] is commonly used for both authentication and identification purposes, but performance inconsistencies across different demographic groups raise concerns about fairness. These biases disproportionately affect underrepresented populations, potentially restricting their access to important services and resources. As AI systems are increasingly applied in critical sectors like mortgage approval and criminal justice, preventing discriminatory outcomes becomes crucial [4]. A survey by NIST's FRVT [1] highlighted substantial performance differences based on gender and race, underscoring ethical issues. Addressing these biases is crucial to ensure FR systems are fair and reliable, prompting ongoing research to reduce such disparities. Demographic bias in FR"}, {"title": "2 Related Works", "content": "This section offers a comprehensive review of some existing works, systematically structured into two primary subsections: a) Classical Machine Learning approaches and b) Deep Learning approaches."}, {"title": "2.1 Classical Machine Learning techniques", "content": "Research in computer vision has long focused on identifying gender and demographic attributes from facial images. The authors of [16] proposed a method for extracting primary and secondary facial features for race classification using the Viola-Jones method for face detection and Sobel edge operators for regions like the forehead, eyes, and lips. However, this method was limited by a small, constrained dataset. The method discussed in [12] utilized biologically inspired features with Gabor filters, but accuracy decreased when training on females and testing on males, likely due to dataset imbalance. In contrast, [13] extracted 77 facial landmarks from the \"T\" region of the face, using the mRMR algorithm and k-NN for demographic classification. While accurate, this method was limited to frontal face detection and performed poorly on side faces. The work reported in [14] used periorbital features from facial images and proposed an ethnicity recognition system, employing a level co-occurrence matrix, colour histogram for feature extraction, and a random forest classifier. However, this study used a private dataset and lacked state-of-the-art comparative analysis. A work [15] that introduced a compact-fusion features framework for ethnicity classification, utilizing four handcrafted techniques for feature selection, embedding extraction, and SVM one-vs-all classification. While effective, this method does not control the feature reduction ratio and struggles with large-scale data due to high computing demands. To address these issues, hybrid techniques have been developed. For example, a combination of ML-based SVM classifier with DL-based feature extractors [17], used a pre-trained VGG16 model. Effective hybrid models require a thorough understanding of both the problem and the involved models."}, {"title": "2.2 Deep Learning approaches", "content": "The advancement in deep learning methods like adversarial learning, variational autoencoder, transfer learning, etc., has led to significant achievements in miti-"}, {"title": "3 Proposed Methodology", "content": "The proposed work achieves unbiased and enhanced performance for the face attribute classification. Merely using a balanced dataset across different demographics will not give an unbiased performance; specific, explicit criteria must be introduced to deal with the algorithmic bias. In this section, we discuss the proposed approach that uses a customised loss function to mitigate the bias in race and gender classification by enhancing the critical features and suppressing the irrelevant features using an attention mechanism."}, {"title": "3.1 Overview", "content": "The aim of the proposed work is to train a model that minimizes statistically significant performance variation across different groups. Such variations can stem from image-related factors, like pose, illumination, and resolution, which introduce intrinsic bias, and from subject-related factors, like race, gender, and age, which lead to algorithmic bias affecting facial attribute recognition. Our"}, {"title": "3.2 Attention Characterized Map Generation", "content": "The human vision focuses on features related to the task at hand in its purview. If we want to recognise the gender of the person, we will focus on the features"}, {"title": "3.3 KL-Divergence Induced De-biasing Loss Function", "content": "After feature extraction, the network was optimized on three criteria: minimizing cross-entropy loss between predicted and target logits, reducing the variation in confidence scores of predictions, and decreasing the intra-class distance between positive embeddings. A KL divergence-regularized term was added to the cross-entropy loss to account for all probability values. KL divergence [32], a measure of how one probability distribution differs from a reference, is non-negative and reaches zero only when distributions are identical. While cross-entropy loss typically focuses on the highest probability, incorporating KL divergence adds flexibility, improving model calibration and generalization, particularly when labels are uncertain or regularization is applied. This approach helps produce more accurate and less biased predictions by aligning the predicted distribution with a target distribution. The Classification Loss is defined as follows:\n$L_{combined} = \\sum_{i=1}^{N} y_i log(\\hat{y}_i) + \\lambda \\sum_{i=1}^{N} P (i) log \\frac{P(i)}{Q(i)}$\nwhere N denotes the number of samples, $y_i$ denotes the true label for the i-th sample, $\\hat{y}$ denotes the predicted probability for the i-th sample, $\\lambda$ denotes the regularised term for KL-Divergence loss, P (i) denotes the actual confidence score for the i-th sample and Q(i) denotes the predicted confidence score for the i-th sample.\nIn addition to the face attribute classification objective function, a regularization term is included to reduce the intra-class distance between demographic groups. The Mahalanobis distance is used to measure intra-class distance for each race. To achieve this, the following loss components are defined:\n$L_{intra-class} = \\beta \\frac{1}{N} \\sum_{CEC ielc} (e_i \u2013 \\mu_c)^T S^{-1}(e_i \u2212 \\mu_c)$\nwhere C represents set of all classes,I denotes set of indices of samples in class c,$e_i$ is the embedding of sample i\u201a$\\mu_\u0109$ denotes mean embedding (centre) of class c, S denotes covariance matrix of all embeddings, $S^{-1}$ represents the inverse of the covariance matrix,N is the total number of intra-class pairs and $\\beta$ denotes hyperparameter."}, {"title": "3.4 Working principle", "content": "The attention mechanism is primarily concerned with identifying the most critical aspects of the input data. This approach is also useful for distinguishing between different classes by recognizing their unique characteristics. KL divergence, on the other hand, quantifies the disparity between the target probability distribution and the predicted probability distribution, motivating the model to generate a probability distribution that is more similar to the intended distribution. The intra-class compactness promotes the clustering of embeddings that belong to the same class, thereby reducing variability within the same class and enhancing the discriminative features. In conjunction with these regularization terms, the attention mechanism enables the model to focus on the most salient features, enhance accuracy by considering the probability distribution, and narrow the gap between the intra-class distance of different classes. We reduce the number of incorrect predictions by utilizing the KL-regularization term."}, {"title": "4 Experimental Setup", "content": "The proposed model is trained using the gender- and race-balanced FairFace dataset to reduce classification bias. To evaluate the model, we use the balanced FairFace [18], UTKFace [20], and BFW [21] datasets. These datasets ensure that evaluations are unbiased and equally distributed across genders and races. They include diverse photos varying in age, gender, pose, lighting, and expression. A detailed description of the datasets is provided below:"}, {"title": "4.2 Pre-processing", "content": "All face images are cropped and resized to 240 \u00d7 240 pixels using Multi-Task Cascaded Convolutional Neural Networks (MTCNN) [24]. The dataset contains images from uncontrolled environments, making face detection challenging due"}, {"title": "4.3 Implementation details", "content": "The proposed model is trained on the FairFace dataset using a pre-trained Inception-ResNet V1 model, initially trained on the VGGFace2 [26] dataset, to extract key facial features. For evaluation, we use the UTKFace and BFW datasets, which are balanced for race and gender. These datasets are pre-processed in the same manner as the FairFace dataset. Training is optimized with the AdamW optimizer, a weight decay of 0.002, and a batch size of 64. The learning rate starts at 0.0001 and decays to 1e-7 with patience set to 7 and a factor of 0.1, reducing the learning rate if the validation loss does not improve for seven consecutive epochs. The model is trained to produce a 512-dimensional embedding representation. On an Nvidia Tesla V100 GPU, the average training speed is 6.6 images per second, with a total of 7.5 million model parameters."}, {"title": "4.4 Evaluation Metrics", "content": "We evaluated the model's performance using classwise classification accuracy and overall accuracy, comparing our results to State-Of-The-Art (SOTA) methods. Additionally, we employed the Degree of Bias (DoB), which calculates the standard deviation of classification accuracy across facial attribute subgroups. Lower DoB values indicate less bias, while higher values reflect greater bias, signifying accuracy variation between target groups. To further assess uneven performance, we used the Max/Min ratio, defined as the ratio of maximum to"}, {"title": "5 Evaluation", "content": ""}, {"title": "5.1 Experimental Results", "content": "The proposed attention-based hybrid model was evaluated on the FairFace test subset for bias estimation across ethnicity-gender groups, followed by testing on UTKFace and BFW datasets. Figure 5 shows the training accuracy curve, with initial fluctuations due to regularization techniques like dropout and data augmentation to prevent overfitting. The model achieved training accuracies of 97.45% for gender classification and 95.12% for race classification, with validation accuracies of 97.28% and 95.07%, respectively. Performance was measured using metrics sensitive to both prediction accuracy and confidence."}, {"title": "5.2 Analysis and Discussion", "content": "The attention mechanism in our model effectively extracts and amplifies complex patterns, allowing it to match or exceed the performance of state-of-the-art (SOTA) methods. Figure 6 shows the raw augmented input images, features highlighted by the attention module, which enhances features from each channel of the intermediate feature map with higher values. The ReLU activation function in the attention network ensures that only prominent features are retained."}, {"title": "5.3 Comparison with SOTA models", "content": "Table 5 shows the comparative analysis of the proposed model with some SOTA methods for overall classification accuracy for race attribute, the Degree of bias and the max/min ratio, which depicts disparity as metrics. The table shows that the proposed approach comprises a dual attention mechanism, regularized loss function and the class balanced batch that has achieved remarkable performance compared with other SOTA methods. The proposed model has obtained the highest overall classification accuracy and least DoB which represents the model is able to mitigate the bias in race classification. Though the max/min ratio is not the least one, but comparable with other methods. Although the results for the BFW dataset are lower compared to the Fairface and UTKFace datasets, this is due to the BFW dataset having fewer samples and less diversity in terms of poses and illumination, which limits the model's ability to generalize and perform well."}, {"title": "6 Conclusion and Future Scope", "content": "To mitigate the bias in facial attribute recognition, we have introduced a novel method comprised of an attention mechanism and custom loss function that minimises the losses at logits, confidence score and embedding level. The experimental evaluations demonstrate that the proposed model significantly enhances both fairness measures and classification accuracy compared to existing methods. Specifically, the attention mechanism reduces bias effectively, and the custom loss function improves overall performance, facilitating equitable facial recognition. Pre-trained models, often biased due to their training datasets, can affect subsequent tasks and may be difficult to interpret due to their \"black box\" nature. In the future, we plan to train the model from scratch on a balanced and diverse dataset. Additionally, most available datasets focus on binary gender groups, but developing a fair system requires considering all gender identities, including LGBTQ+. Future research will address this underexplored area with some novel frameworks."}]}