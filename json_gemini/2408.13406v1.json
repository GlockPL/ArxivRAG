{"title": "Optimizing Collaboration of LLM based Agents for Finite Element Analysis", "authors": ["Chuan Tian", "Yilei Zhang"], "abstract": "This paper investigates the interactions between multiple agents within Large Language Models (LLMs) in the context of programming and coding tasks. We utilize the AutoGen framework to facilitate communication among agents, evaluating different configurations based on the success rates from 40 random runs for each setup. The study focuses on developing a flexible automation framework for applying the Finite Element Method (FEM) to solve linear elastic problems. Our findings emphasize the importance of optimizing agent roles and clearly defining their responsibilities, rather than merely increasing the number of agents. Effective collaboration among agents is shown to be crucial for addressing general FEM challenges. This research demonstrates the potential of LLM multi-agent systems to enhance computational automation in simulation methodologies, paving the way for future advancements in engineering and artificial intelligence.", "sections": [{"title": "1. Introduction", "content": "Large Language Models (LLMs) have recently made a significant impact across various domains, highlighting their potential as powerful tools, particularly in education, healthcare, and research (Sallam, 2023). They have shown exceptional capabilities in Natural Language Processing (NLP) to understand and generate human-like text with remarkable fluency and coherence. Moreover, LLMs are capable of handling language translation, image recognition, and code programming (Zhu et al., 2023; Bai et al., 2023; Nijkamp et al., 2022). Ongoing research efforts continue to improve the performance of LLMs, break through their limitations in engineering, and create new opportunities for real-world applications. For example, G\u00f6pfert et al. (2024) introduced a discourse-centric AI design process idea as the core of engineering design, aiming to integrate experiments, simulations, and topology optimizations by using LLM. A potential benefit of this approach is enabling machines to engage in the reasoning process for multi-modal models. This engagement helps in creating models with learned representations that more accurately reflect the skills needed in the design process.\nThanks to the ongoing research efforts, advancements in LLMs have led to innovative solutions that effectively harness their capabilities. AutoGen framework, as shown in Figure 1 (Wu et al., 2023), emerges as a comprehensive framework tailored to leverage the potential of LLMs in adaptive communication. By enabling seamless interaction among multiple conversational agents and integrating human input through automated chat systems, AutoGen extends the utility of LLMs across various domains. Meanwhile, this framework facilitates task delegation, particularly emphasizing coding and programming activities, thereby enhancing productivity in NLP and software development contexts."}, {"title": "2. Methodology and Experiments", "content": "The experiments are carried out in Google Colab, utilizing the AutoGen framework to create multi-agent systems for linear elastic problems. Only the essential libraries, FEniCS and Matplotlib, are installed, with no additional FEA software environments included. The generative code design relies on the GPT-3.5-turbo model through API keys. Consistent 4-step query and agent definitions are used across all experiments, with some agent profiles and the query modified from MechAgents (Ni & Buehler, 2024) as shown in Query 1. The query with the \u2018Planner' agent is created and shown in Query 2, the detailed research setup is shown in Table 1, and the agent profile is shown in Table 2.\nExperimental Setup"}, {"title": "3. Results", "content": "This section presents the results of the experiments conducted to evaluate the performance of various multi-agent combinations in solving linear elastic problems using FEniCS. The x-axis of the plots is the different combinations of the agents, and the y-axis is the probability of successful runs based on 40 consecutive runs. Each combination will be conducted with a 4-step query for the linear elastic tasks."}, {"title": "3.1 Assess the Impact of Agent Roles", "content": "The experiment investigates the difference and dependency between the \u2018Executor' and 'Expert' agent role impacts on the linear elastic problem. Figure 2 shows that the Eng + Exe combination has the highest probability of success among the different proxy combinations for simple scenarios, reaching 97.5%. Besides, the Eng + Exp1 combination has a success probability of 77.5%, while the Eng + Exe + Exp1 combination has a slightly higher likelihood of success at 82.5%. However, only the Eng + Exe + Exp1 combination is likely to succeed for complex scenarios with holes at 12.5%.\nFigure 3 demonstrates the difference and dependency for the linear elastic problem between the \u2018Executor' and \u2018Expert' agents after the \u2018Planner' is involved. For the Plan + Eng + Exe + Exp combination, in simple scenarios, the Displacement scenario achieves a success probability of 70.0%, while the Shear Displacement scenario reaches 65%. This combination is unique among the three in its ability to handle complex cases, with a success rate of 7.5%. In contrast, the Plan + Eng + Exp combination shows the lowest success probability of 5%. Moreover, for the Plan + Eng + Exe combination, the Displacement scenario has a 57.5% success probability, and the Shear Displacement scenario stands at 55%.\nFigure 4 is based on the FEniCS results extracted from Figure 3 and then compared to Figure 2. Its purpose is to compare whether the \u2018Executor' and 'Expert' perform differently for the linear elastic problem for these two scenarios (with and without 'Planner') under FEniCS software. It reveals that implementing the \u2018Planner' agent led to a significant decrease in all success rates for both simple and complex scenarios when either the 'Executor' or \u2018Expert' is missing in the framework. Meanwhile, the success rate for the Plan + Eng + Exe + Exp combination slightly decreased from 82.5% to approximately 79% for simple cases, and from 12.5% to 8.8% for complex cases, compared to the Eng + Exe + Exp1 combination. Both scenarios (with and without 'Planner') have the same trend that the success rates tend to be stable around 70% to 80% for the simple cases and increased for the complex cases, respectively, when both the \u2018Executor' and \u2018Expert' exist in the framework."}, {"title": "3.2 Assessing the Impact of Overlapping Agent Roles", "content": "Figure 5 illustrates whether the overlapping (Expert2 and Exxpert2) agent roles will influence the success rate for the linear elastic task without the \u2018Executor' agents in the framework. For the Eng + Exp combination, both the simple cases have a probability of success at 77.5%. It is observed that with an additional \u2018Expert' agent, the success rate for simple tasks will slightly increase. On the one hand, the Eng + Exp1 + Exp2 combination shows a higher success probability for the Displacement scenario at 90.0%, while the Shear Displacement scenario stands at 80.0%. On the other hand, in the Eng + Exp1 + Exxp2 combination, the Displacement scenario has a success probability of 82.5%, and the Shear Displacement scenario is at 80.0%. None of these combinations have successfully solved the complex problems.\n('Expert2 and 'Exxpert2') when the \u2018Executor' agent exists in the framework for solving the linear elastic problem. It is shown that this time, the additional \u2018Expert' will slightly influence the success rate for simple tasks. The Eng + Exe + Expl combination, for simple scenarios, has a high success probability of 82.5%. At the same time, in the Eng + Exe + Exp1 + Exxp2 combination, the Displacement scenario reaches a success probability of 90.0%, and the Shear Displacement scenario has a probability of 82.5%. However, for the Eng + Exe + Exp1 + Exxp2 combination, the Displacement scenario shows a decreasing trend of 75.0% success probability, and the Shear Displacement scenario is at 77.5%. It is observed that the additional \u2018Expert' agent does not affect the performance for complex tasks, all three combinations have the same success rate for dealing with complex cases, at 12.5%."}, {"title": "4. Discussion", "content": ""}, {"title": "4.1 Executor and Expert Synergy as a Key to Improving Task Outcomes", "content": ""}, {"title": "4.1.1 Simple Tasks: Executor Can Generate Constructive Feedback that Improves Success Rates", "content": "Observations reveal an intriguing trend: for simple scenarios, having an agent dedicated solely to code execution proves notably advantageous compared to relying solely on text-based agents such as \u2018Expert'. The key benefit of the \u2018Executor' agent is its ability to provide immediate feedback, including error messages, directly to the \u2018Engineer'. This feedback greatly expedites error resolution and increase the success rate for simple tasks, as shown in Figure 2. Specifically, the \u2018Executor' serves as an immediate feedback mechanism, providing specific feedback on direct errors. By doing so, the 'Executor' helps the \u2018Engineer' to correct the error by avoiding falling into the trap of false confidence, where progress by the \u2018Engineer' is based on a flawed or incomplete understanding of the query. Consequently, the 'Executor' ensures the code aligns more closely with the desired outcome, reducing the likelihood of producing incorrect coding solutions for simple tasks."}, {"title": "4.1.2 Simple Tasks: Expert Could Generate Misleading Comments that Reduce Success Rates", "content": "In Figure 2, it is observed that the combination of \u2018Engineer' and \u2018Expert' reduces the success rate for simple tasks from 97.5% to 77.5% compared to the 'Engineer' and 'Executor' combination. This decrease is mainly due to the 'Expert' often suggesting additional information that the \u2018Engineer' then incorporates into the code, even though it wasn't part of the original query. For instance, the \u2018Expert' might recommend setting the top and bottom edge boundary conditions of a plate to 0 to ensure all boundaries are applied. However, the value of 0 at boundary edges means the edges are fixed rather than free, as shown in Appendix Figure 4, which contradicts the query. Sometimes, the \u2018Engineer' initially generates the correct plot but then follows additional suggestions from the \u2018Expert', leading to an incorrect plot for the simple tasks."}, {"title": "4.1.3 Expert and Executor Can Work Together to Solve Complex Tasks that Neither One Can Solve Individually", "content": "For complex cases like scenarios involving a hole in the plate, direct feedback from agents such as the \u2018Executor' can sometimes increase code complexity, leading to a chain reaction of intricate issues that become harder to resolve with each iteration, for instance, when the \u2018Executor' provides the error message to the framework, the way of solving the problems is randomly generated by the \u2018Engineer' based on its database, which usually is to directly change the relevant code, however, such direct changes in the code are often not supported by the FEM software or only a part of the code is changed by the 'Engineer' rather than all code lines that are related to the error message, thus the error message will continuously appear or cannot be solved, an example of the details is shown in Appendix Conversation 1. In contrast, agents like the 'Expert' often tend to trust the \u2018Engineer' code, particularly in the absence of code execution, the \u2018Engineer' will often program the same errors during the runs, whether the framework is based on FEniCS or other software, as shown in Appendix Conversation 2. For example, after execution manually, the codes can either not be executed or wrongly plotted. Under such trust, the 'Expert' fails to spot the potential errors in the codes and the \u2018Expert' believes the \u2018Engineer' is making the correct code. Still, sometimes the \u2018Expert' suggests additional solutions, which confuses the 'Engineer' when translating the text message into code, as shown in Appendix Conversation 3 and Appendix Figure 1. Such suggestions will also increase the chance of incorrect plots by providing additional boundary conditions. The combination of 'Expert' and 'Engineer' agents alone did not yield a high success rate, suggesting their presence does not inherently lead to high performance."}, {"title": "4.1.4 Executor and Expert Agents Boost FEA Success Despite Random Prompts", "content": "In Figure 3, a new agent called \u2018Planner' is integrated into the framework to provide a more general and random prompt for the linear elastic FEM tasks. The \u2018Planner' randomly selects FEA software for the multi-agent system to use in Python frameworks. This leads to a significantly reduced success rate, primarily because the \u2018Planner' frequently suggests using the Abaqus Python style, resulting in coding errors when executed in Abaqus. And these errors cannot be transferred to the \u2018Executor' for providing feedback to the \u2018Engineer'. Thus, to better explain and compare the results, only the FEniCS outcomes are extracted from all outcomes (with the 'Planner' agent framework) and compared to the previous multi-agent system without the 'Planner' agent, as shown in Figure 4. The synergy between agents is disrupted if either the \u2018Executor' or \u2018Expert' is missing. Without the \u2018Executor', codes are poorly executed, causing implementation and error message issues by continuously trusting the \u2018Engineer' codes, as shown in Appendix Figure 1. Without the 'Expert', the \u2018Executor' lacks the necessary insights for complex scenarios, leading to lower success rates due to increased randomness by fixing the same error messages with random coding, as illustrated in Appendix Figure 3.\nWhen both the \u2018Executor' and 'Expert' are part of the framework, once the \u2018Planner' suggests FEniCS software, such a centralized approach (by suggesting a certain software as a prompt in the conversation) allows all agents to work towards a unified objective, minimizing miscommunication and redundant efforts. By delivering clear plans and specifying tools, the \u2018Planner' aligns the efforts of the \u2018Engineer', \u2018Executor', and \u2018Expert'. This coordination allows each agent's contributions to complement one another, resulting in a more cohesive and efficient workflow. Consequently, the synergy between the \u2018Executor' and \u2018Expert' enhances the communication interaction, leading to a higher success rate. As shown in Conversation 8, when the \u2018Planner' selects the correct software environment, the subsequent interactions yield accurate outputs. This significantly improves the success rate for the Plan + Eng + Exe + Exp combination, which is only slightly lower than the Eng + Exe + Exp1 combination. One potential reason for the slightly decreased success rate compared to the Eng + Exe + Exp1 combination could be that, after extracting only the FEniCS results, the samples decreased slightly. Besides, despite the occasional failure of the \u2018Expert' to provide useful suggestions, successful combinations demonstrate that the presence of both the \u2018Executor' and \u2018Expert' enables the other agents to effectively solve complex cases for more general design purposes. However, the centralized approach by the 'Planner' does not help when either the \u2018Executor' or \u2018Expert' is not in the framework, it emphasizes that the synergy between the \u2018Executor' and 'Expert' agents is essential to performing FEA tasks, this is the main reason that the success rate for the combinations without either of these two agents is decreased significantly."}, {"title": "4.2 Overlapping Agent Roles Don't Substantially Improve Task Performance", "content": ""}, {"title": "4.2.1 Similar Expert Mirrors Each Other with Limited Enhancements in Success Rates", "content": "An experiment introduced \u2018Expert2', an additional agent identical to the original 'Expert1', aiming to enhance the conversation's performance and the success rate for the linear elastic FEA tasks. Results depicted in Figure 5 show a slight success rate increase. However, the \u2018Engineer' agent primarily focuses on revising code based on \u2018Executor' error messages, often without utilizing input from both \u2018Expert' agents. Moreover, 'Expert2' frequently mirrors or agrees with 'Expert1' without offering additional insights across 40 random runs. This suggests a limited enhancement of the similar or same multi-agent dynamics during conversations, as detailed in Appendix Conversation 5.\nDespite repetitive responses, the success rate increase may stem from a consistent emphasis on using the FEniCS format during the two \u2018Expert' repeated conversations, aligning with task requirements. This indicates there is an in-context learning for LLM agents in the conversation rather than deeper task understanding from the query initially. Occasionally, both the \u2018Expert' agents failed to provide additional suggestions. By continuously trusting the \u2018Engineer' code, it is questionable whether success results from the \u2018Engineer' capability or the \u2018Expert' agents' performance. For example, the 'Engineer' corrects code before \u2018Experts' suggestions after post \u2018Executor' error messages, complicating the attribution of success solely to dual 'Expert' agents."}, {"title": "4.2.2 Opposite Expert Agents Is Ineffective in Enhancing Success Rate", "content": "A subsequent experiment investigated the issue by introducing a different agent labelled 'Exxpert2', detailed in the Table 2. Despite differing definitions between \u2018Exxpert2' and 'Expert1', the findings reveal no improvement in system performance. In fact, integrating \u2018Exxpert2' resulted in a slight decrease in success rates for simpler cases. This decline occurred because \u2018Exxpert2' often provided additional suggestions that could be misleading for the \u2018Engineer'. For example, \u2018Exxpert2' could advise on boundary conditions when Expert1 did not do it, which could potentially lead to an incorrectly plotted boundary. In addition, \u2018Exxpert2' also have the same potential to mirror \u2018Expert1's behaviour as \u2018Expert2' as discussed in the previous section, hence decreasing the success rate."}, {"title": "5. Conclusion", "content": "Future research should delve deeper into the relationship between the different roles of agents and the effectiveness of Retrieval-Augmented Generation (RAG) or other advanced prompt techniques. This exploration could systematically vary the roles of agents involved in different tasks, evaluating the impact on the workflow's efficiency and accuracy. By identifying the optimal roles of agents for various tasks, researchers can create more streamlined workflows that minimize redundancy while maximizing the benefits of RAG assistance. Additionally, exploring alternative advanced prompt techniques or combinations could enhance the capabilities of multi-agent workflows. Experimenting with different prompt formats, reinforcement learning strategies, or hybrid approaches might reveal novel methods to improve automated code generation and computational analysis.\nThis study explores the complex dynamics of multi-agent interactions within LLMs, particularly in programming and coding environments. Using the AutoGen framework, we facilitate efficient communication among conversational agents to evaluate the effectiveness of different configurations based on the probability of 40 random runs for each combination. Our findings illustrate that for a simple linear elastic FEA problem, using a code generation agent (\u2018Engineer'), a direct feedback response agent (\u2018Executor'), and an evaluation agent (\u2018Expert') could significantly improve the performance of the model through conversations and interactions. The lack of either \u2018Executor' or \u2018Expert' in the system will dramatically lead to failure. Besides, simply adding the \u2018Expert' agents does not significantly influence the results, whether these agents have or don't have the same agent profile. These findings underscore the potential of LLM multi-agent systems in investigating their relationships to advance computational automation of simulation methodologies for more complex scenarios, offering promising prospects for innovation in engineering and artificial intelligence."}]}