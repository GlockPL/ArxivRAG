{"title": "The Potential and Perils of Generative Artificial Intelligence for Quality Improvement and Patient Safety", "authors": ["Laleh Jalilian", "Daniel McDuff", "Achuta Kadambi"], "abstract": "Generative artificial intelligence (GenAI) has the potential to improve healthcare through automation that enhances the quality and safety of patient care. Powered by foundation models that have been pretrained and can generate complex content, GenAI represents a paradigm shift away from the more traditional focus on task-specific classifiers that have dominated the AI landscape thus far. We posit that the imminent application of GenAI in healthcare will be through well-defined, low risk, high value, and narrow applications that automate healthcare workflows at the point of care using smaller foundation models. These models will be finetuned for different capabilities and application specific scenarios and will have the ability to provide medical explanations, reference evidence within a retrieval augmented framework and utilizing external tools. We contrast this with a general, all-purpose AI model for end-to-end clinical decision making that improves clinician performance, including safety-critical diagnostic tasks, which will require greater research prior to implementation.", "sections": [{"title": "1 Introduction", "content": "Following the release of OpenAI's Chat Generative Pre-trained Transformer (ChatGPT) (San Francisco, CA, USA) in November 2022, the adoption of generative artificial intelligence (GenAI) and foundation models has witnessed a notable surge (1). The impact was so dramatic that it contributed to attitudes changing towards how soon so-called Artificial General Intelligence (AGI) might be achieved (2). At their most basic, foundation models receive text queries and generates text output in return (3,4). In medical research settings, foundation models have been studied for use in various tasks such as operative and progress note-writing (5, 6), answering patient questions (7), generating clinical summaries (6), creating differential diagnoses (8) and understanding and reasoning over personal health data (9). While the excitement surrounding the application of foundation models for improving clinician performance is palpable, these models have also demonstrated the ability to produce medically inaccurate or nonsensical outputs, hallucinate facts (10\u201312) and propogate existing biases (13). Yet, despite these limitations, Generative AI is already being integrated into health systems (14). Generative AI holds the potential to transform many aspects of clinical medicine over the long term, ranging from improved patient diagnosis to precision treatment strategies. However, health systems are more likely to realize its immediate benefits by applying this technology towards improvements in quality, safety, and efficiency through well-defined, low-risk, high-value, and low-variation, repetitive and standardized use cases. A frequent approach in AI development for clinical applications is the pursuit of use cases which require near-perfect AI"}, {"title": "2 Foundation Models Capabilities", "content": "A foundation model refers to a model that is (pre)trained on a large, broad dataset and can be adapted to a wide variety of downstream tasks without needing to be trained from scratch, giving it so-called \"zero-shot\" capabilities (17). Foundation models such as GPT (1), BLOOM (18), LLaMA2 (19) and StableDiffusion (20) are characterized by their scale in terms of training data, computational resources, and parameter size. Most foundation models utilize the transformer architectures (21), which can handle multi-modal data, including images, videos, audios, and 2D-waveforms. These models can be fine-tuned with smaller, more specific datasets to perform tasks that involve multiple modalities, such as image captioning, visual question-answering, or any task where understanding and generating content require both textual and non-textual information (22). Fine-tuning updates the pretrained parameters to better suit the requirements of the specific task at hand. A key strength to the use of foundation models includes their ability to leverage their pretraining to adapt to tasks that were not explicitly part of their initial training data. They have demonstrated reasoning (23) and planning (24) capabilities and excel at data processing tasks such as integration and cleaning (25)."}, {"title": "2.1 Retrieval-Augmented Generation", "content": "An important advancement in foundation models is the development of retrieval-augmented generation (RAG), which combines the generative capabilities of transformers with a retrieval mechanism that can access large external knowledge bases. This allows the model to incorporate the latest data or retrieve and highlight the most pertinent information for specific use cases. As an example, a RAG model could dynamically present the latest clinical guidelines (26) or patient-specific information in an interactive user interface. This ensures that the interface and generated text is not only based on the immediate data available but is also informed by relevant medical knowledge (27). Such a capability may augment clinical decision support systems that are dependent on current medical knowledge and limit the possibility of hallucinations. Training language models to utilize tools such as Internet search Application Programming Interfaces (APIs) (28) is another method to retrieve information that the model might not be able to generate directly."}, {"title": "2.2 Larger Proprietary vs. Smaller Domain-Specific Models", "content": "While larger proprietary and centralized models like GPT-3.5 first gained the attention of the public, these models can be costly, are associated with privacy risks, and may be inaccurate. Their use may also not be feasible for health systems that do not have HIPAA-compliant Azure instances. Recent literature suggests that smaller models, when fine-tuned on specific domains, can surpass the performance of their proprietary counterparts (29). This opens the possibility to use smaller, more efficient models that can address privacy, accuracy, and cost in healthcare. An optimal approach for foundation model-integrated application development will need to consider health system resource availability, domain specificity, degree of generalization, and the task-specific requirements. The usefulness and acceptance of the model will also depend on the quality of its output, and understanding when the model fails and the effects of failure (30)."}, {"title": "3 Improving Quality and Safety at the Point of Care", "content": "Immediate applications of generative AI could prioritize non-diagnostic clinical and administrative tasks that can be labor-intensive, require manual review and input, and are well-defined (31, 32). By automating lower risk tasks, generative AI could support healthcare workers and administrators in performing their duties more effectively."}, {"title": "3.0.1 Dynamic User Interfaces to Support Interaction with Data for Informed Decision Making", "content": "Current EHR interfaces present excessive data and are associated with adverse events, medical errors, and poor communication (33). A nascent body of research focuses on using generative AI to create dynamic user interfaces (34) that facilitate healthcare workers interacting with and querying complex medical data, including patient data, compliance manuals, standard operating procedures, and evidence-based guidelines. Conceptually, this differs from training medicine-specific foundation models (35) or using models for prediction (36). Instead, generative AI-based systems may present an intuitive interface that can streamline interactions with multiple digital tools and sources of information, significantly augmenting clinicians' capabilities by efficiently extracting and analyzing crucial information from vast amounts of patient data. Since the foundation model supplies knowledge from institutionally improved sources through RAG, the potential for hallucinations is limited. This enhances the practical impact of Generative AI tools while addressing current issues with using these models in clinical settings such as hallucinations (37). GenAI-supported dynamic interfaces can provide evidence-based information to healthcare teams at the point of care (38), possibly improving adherence to evidence-based guidelines (39), reducing inter-provider variation, and provisioning the basic standard of care. Additionally, by transforming lengthy equipment manuals into interactive question and answer systems, GenAI can help clinical engineering teams with healthcare equipment maintenance while accessing key information as needed (40). This enhances engineer productivity and indirectly contributes to the equipment's working quality."}, {"title": "3.0.2 Improving Clinical Documentation for Clinicians and Administrators", "content": "The accurate and comprehensive documentation of clinical notes is paramount for ensuring effective communication, care quality, and patient safety. As they currently exist, notes suffer from issues such as note bloat (copying and pasting), information overload (automatic inclusion of data and administrative documentation), and disorganization. Generative AI's assistive writing abilities can reduce documentation burden for clinicians by using language capabilities to document specific medical terminology and increase record accuracy. This would this provide higher quality documentation and training data for future iterations of EHR foundation models (41). They can assist clinical documentation by writing referral notes and prescriptions and generate concise summaries (42, 43), among other applications. They can parse medical records and synthesize them into clear, concise summaries of active and historical conditions. They can also interact with medical records by converting unstructured data into structured formats. Recent work demonstrates that foundation models can extract key data elements from patient notes and reformat this information into a structured layout to aid in filtering clinical trials (29). Additionally, a \"prompt engineering\" framework has enabled batch queries to process large volumes of pathology reports for structured information extraction and estimation without requiring extensive task-specific human annotation and model training (44). In complex, high-stakes online pharmacy prescription processing, where the magnitude of prescriptions received daily can contain many inaccuracies, a data-driven pharmacy support system using Generative AI has already enhanced quality and reduced errors, allowing pharmacy teams to focus on ensuring patient safety and well-being (45)."}, {"title": "3.0.3 Dynamic Checklists for Adherence to Evidence-Based Practice", "content": "Since gaining traction in the context of perioperative care, use of checklists in routine patient care has expanded to multiple fields of medicine. Unlike static checklists, dynamic checklists display data appropriate to a patient's clinical context but also provide guidelines relevant to the checklist items. Dynamic checklists significantly improve compliance with best practices during ward rounds in the ICUs (46) and are associated with reductions in length of stay (47). They are supported by hard-coded logic, but generative AI can be applied to assess the patient's eligibility for specific practices, emphasize items that are most important, and remove items that aren't indicated, to ensure that teams are compliant with best practices, all in a user-friendly interface. They can be used during rounding, during note writing, or during procedural care to ensure that all aspects of care are addressed. A concrete example of where generative AI can be applied to dynamic checklists is adherence to lung protective ventilation (LPV) in patients on mechanical ventilators, whether intra-operatively or in the ICU. In ICUs that adhere to LPV, noticeable improvements in both short- and long-term patient outcomes and reductions in healthcare costs (48, 49) are noted. However, LPV is not universally implemented used across ICUs and ORs, because of challenges including developing and digitizing clinical protocols for LPV management and a lack of IT resources to acquire and analyze LPV metrics within the EHR (50). In the OR and ICUs of the future, a generative AI-enhanced dynamic checklist integrated within the EHR can assess ideal body weight, tidal volumes on the ventilator, and adherence to LPV protocols. This can help to standardize operative and ICU ventilator management, reduce inter-provider practice variation, and ensure that any patient on a ventilator has received consideration towards applying LPV."}, {"title": "3.0.4 Health System Data Auditing, Extraction, and Population", "content": "Foundation models could become a core component of data discovery, exploration, and extraction systems in healthcare. They have demonstrated superior capability on three data discovery tasks, including table-class detection, column-type annotation and join-column prediction (25). They could be applied to extracting data from disparate data warehouses and data lakes in health systems to reduce data silo'ing, which limits the ability of health systems to use their data effectively. Currently, notable reasons for silo'ing include different departments using different data formats, which impacts data aggregation in one central area. Examples of this include perioperative data warehouses which hold data captured in EHR systems but may not include data from other relevant systems, such as imaging systems. Foundation models can help in extracting information from disparate data sources and formats and can be used to translate different medical terminologies and data structures into a unified format, facilitating easier data integration into individual department-level data warehouses. This could increase the utility of health system data and improve the ability of health systems to engage in predictive analytics or even basic auditing."}, {"title": "4 Implementation Path for Responsible Generative AI", "content": "While a significant body of scholarship has focused on model development, realizing generative AI's potential in healthcare requires structured and context-sensitive approaches rooted in implementation science (51). Multidiscplinary teams consisting of experts in computer science, healthcare workers, administrative staff, and other members of the healthcare community will need to guide the development of \"end to end\" systems, with consideration into the details around design, user experience, workflow integration, ease of adoption, and continued performance monitoring within clinical workflows. Ideally, these models should function within interactive systems that are usable, support workflow, and meet the needs of end users (52\u201354). Studies will be needed to quantitatively assess how GenAI systems impact user experience, efficiency, productivity, and workload (55\u201358) in real world clinical workflows, in order to continuously verify the purported benefits of the technology. The total cost of implementation, which includes not only the cost to run the model but also expenses associated with monitoring, maintenance, and any necessary infrastructure adjustments, will also need to be estimated."}, {"title": "4.1 Risks", "content": "Risks with foundation models for any task include the potential for hallucinations, omission, and bias (59). A major challenge in deploying foundation models for healthcare tasks is how to control the output to prevent hallucinations. Current models do not evaluate the quality or provide a measure of uncertainty for their outputs. Additionally, many datasets contain too much data to provide to a foundation model in a prompt, which may lead to outputs with clinically relevant omissions. The quality of data used in both pre-training and instruction fine tuning of foundation models for different tasks impacts the performance of the model, and this data has to be carefully assessed for quality, quantity, and diversity (60). Algorithmic bias towards underrepresented minorities may perpetuate or even increase healthcare disparities (61\u201364), and techniques will be needed to mitigate these biases to ensure that LLMs promote health equity across diverse populations (65, 66). If the training data contains under-representation of certain demographics groups or outdated medical practices, generative AI may inadvertently embed theses biases in its outputs and potentially cause harm. These risks threaten acceptance and adoption of any future AI tools for use in healthcare (67). It is also not yet well understood if GenAI may exert unpredictable effects on the quality and patient safety, and measurement of various outcomes such as fairness and safety in the specific environment will need to be done to assess the impact of the technology. Finally, particular attention must be given to the study of automation complacency (68)."}, {"title": "5 Conclusion", "content": "Early penetration of Generative AI into healthcare may be on tasks where it performs reasonably well in ways that enable digital standardization towards delivering higher quality, more efficient, and safer care. As healthcare slowly integrates GenAI, using principles of implementation science and studying the impact on patient outcomes and clinical operations will be important. A careful and coordinated approach that involves scrutiny, customization of this technology to its specific context, and regularly verifying how GenAI assists in clinical encounters, could address concerns associated with adopting Gen AI in healthcare. While considerable amount of work still needs to be done to ensure that \"human in the loop\" GenAI systems are practical, reliable, and safe, we envision a future where GenAI systems can meaningfully accelerate quality, safety, and efficiency in healthcare delivery."}]}