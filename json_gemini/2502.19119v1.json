{"title": "Chemical knowledge-informed framework for privacy-aware retrosynthesis learning", "authors": ["Guikun Chen", "Xu Zhang", "Yi Yang", "Wenguan Wang"], "abstract": "Chemical reaction data is a pivotal asset, driving advances in competitive fields such as pharmaceuticals, materials science, and industrial chemistry. Its proprietary nature renders it sensitive, as it often includes confidential insights and competitive advantages organizations strive to protect. However, in contrast to this need for confidentiality, the current standard training paradigm for machine learning-based retrosynthesis gathers reaction data from multiple sources into one single edge to train prediction models. This paradigm poses considerable privacy risks as it necessitates broad data availability across organizational boundaries and frequent data transmission between entities, potentially exposing proprietary information to unauthorized access or interception during storage and transfer. In the present study, we introduce the chemical knowledge-informed framework (CKIF), a privacy-preserving approach for learning retrosynthesis models. CKIF enables distributed training across multiple chemical organizations without compromising the confidentiality of proprietary reaction data. Instead of gathering raw reaction data, CKIF learns retrosynthesis models through iterative, chemical knowledge-informed aggregation of model parameters. In particular, the chemical properties of predicted reactants are leveraged to quantitatively assess the observable behaviors of individual models, which in turn determines the adaptive weights used for model aggregation. On a variety of reaction datasets, CKIF outperforms several strong baselines by a clear margin (e.g., ~20% performance improvement over FedAvg on USPTO-50K), showing its feasibility and superiority to stimulate further research on privacy-preserving retrosynthesis.", "sections": [{"title": "1 Introduction", "content": "Retrosynthesis is a fundamental technique in organic chemistry that involves designing synthetic routes for a target molecule by working backwards from the desired product to commercially available starting materials. It is of great importance as it allows chemists to discover novel reactions for scarce or even brand-new molecules, optimize existing synthesis pathways, and circumvent processes that are costly, risky, and time-consuming.\nDespite the critical role of retrosynthesis in organic chemistry, developing machine learning (ML) models for retrosynthesis presents significant challenges. Chief among these is the necessity for extensive chemical reaction datasets , the compilation of which entails considerable expense. This expense arises from the requirement for specialized equipment, skilled labor, and material resources, as well as the conversion of unstructured records into structured data. While a limited number of chemical reaction datasets are available open source , the majority are proprietary, maintained by commercial entities. Furthermore, companies may develop new chemical reactions crucial for advancing key fields (e.g., materials , drugs , and energy solutions ), but are often hesitant to share this data.\nThis proprietary stance is primarily due to two reasons. On the one hand, reaction data is often sensitive and confidential, as it may reveal proprietary or classified information that belongs to a specific entity or organization . For example, a pharmaceutical company may want to protect its findings that leads to the synthesis of a new drug, or a government agency may want to safeguard its reaction data that relates to their future development. On the other hand, reaction data is often valuable and competitive , which may confer an advantage or disadvantage to a certain entity or organization. For instance, a rival company may want to gain insight into the developed reactions of its competitors to gain an edge in the market, or a hostile state may want to access the frequently used reactions of its adversary to prepare for competitions in advance.\nAs aforementioned, only a limited number of retrosynthesis datasets are available openly, and sharing chemical reaction data with external parties might expose sensitive information (products, processes, intellectual property, etc.), which may cause compromised interests and unfair competition. This often leads to the emergence of \"data islands\" where data collected in different organizations remains siloed and inaccessible to the broader research community. Such fragmentation impedes progress significantly, as the collective benefit of shared insights is lost, slowing the pace of scientific discovery and application. Therefore, there is a pressing need to develop frameworks for privacy-preserving retrosynthesis learning that enable the sharing of valuable knowledge without compromising proprietary information. Developing such frameworks would facilitate a collaborative environment conducive to the advancement of retrosynthesis while addressing both privacy and competitive concerns. Despite its clear benefits for the scientific community and societal good, this area remains surprisingly under-explored in the existing literature. From an ML perspective, the current standard training paradigm for data-driven retrosynthesis models is to use one global"}, {"title": "2 Results", "content": "Privacy-aware retrosynthesis with CKIF. We prioritize the privacy of chemical reaction data by ensuring that sensitive information is not shared among participants. Instead of gathering raw reaction data into one single edge, CKIF supports distributed model training through the sharing of processed, non-sensitive chemical knowledge (i.e., model parameters) derived from reaction data. CKIF operates through iterative communication rounds, each comprising two stages: local learning and chemical knowledge-informed model aggregation. During local learning, clients independently train their models on proprietary reaction data, initializing from either random value in the first round or from their personalized aggregated model from the previous communication round. In the aggregation stage, clients exchange trained model parameters to leverage collective knowledge while maintaining data privacy. The core of CKIF is its CKIW strategy, which replaces conventional fixed-weight averaging methods. When a client receives models from other participants, it evaluates their relevance using local"}, {"title": "3 Discussion", "content": "As an essential skill for organic chemists, retrosynthesis requires expert knowledge, creativity, and intuition. In the modern era, chemical reaction data become a valuable asset across various scientific domains such as materials science, pharmaceuticals, and energy. However, sharing such data can expose trade secrets, violate patents, and lead to unfair competition or security compromises. To address these challenges, this paper introduces CKIF, a distributed machine learning framework that enables collaborative training without the need to exchange raw reaction data, thereby ensuring data privacy a major concern in sensitive scientific domains. By leveraging the distributed and heterogeneous nature of reaction data sources, CKIF not only improves efficiency but also reduces communication overhead, latency, and bandwidth consumption. CKIF allows for the distribution of computation across multiple clients closer to data sources, enhancing parallelism and fault tolerance.\nCKIF incorporates chemical symbolic knowledge in the form of molecule fingerprints to guide model aggregation, resulting in personalized models that enhance the accuracy and relevance of retrosynthesis predictions. This knowledge-based approach allows each participating chemical entity to benefit from the collective insights. In addition, empirical results suggest that CKIF's performance improves with an increasing number of clients and training samples, showcasing CKIF's scalability. By applying CKIF to retrosynthesis, one can expect the collaborative discovery and optimization of new chemical transformations from various and confidential data sources. Experiments on various experimental settings show that CKIF outperforms locally trained models (Locally Trained) and even those trained on centralized data (Centrally Trained). We hope that CKIF opens up new possibilities for advancing privacy-aware retrosynthesis and related fields. In addition, we aim to inspire more research on privacy-preserving ML methods for other scientific domains and applications.\nDespite these strengths, our work has limitations that necessitate further exploration. First, CKIF'performance relies on the quality of local data from each chemical entity, which might vary significantly in practice. Second, the model aggregation based on chemical knowledge uses the same molecule fingerprints and measurements for all clients, which might not accurately capture the personalized target distribution of each client and might contain unintentional bias. Future work will explore customized molecule fingerprints or measurements that meet the unique needs of each client. Third, our evaluation metrics are focused on the validity and uniqueness of the generated synthetic routes, overlooking the practicality and feasibility of the synthesis in terms of cost, yield, and environmental impact.\nDuring the privacy-aware learning process, each chemical entity trains their personalized models locally and only model parameters are communicated. However, this process is not immune to privacy threats, as malicious attackers can infer sensitive information from the model updates exchanged between the clients , i.e., data representation leakage from gradients or models. Several methods have been proposed to address this essential issue of privacy leakage, such as encrypting the model updates or adding noise to them using differential privacy . While addressing privacy leakage and other security concerns (such as data poisoning) remains an active research area , our contribution is orthogonal to these developments. These methods, in principle, can be seamlessly incorporated into our framework."}, {"title": "4 Methods", "content": "Problem formulation. In the present study, we focus in particular on the challenge of learning retrosynthesis models in a privacy-aware setting where reaction data are proprietary and cannot be shared among chemical entities (clients) or with an external central server. To address this, CKIF is specifically designed to allow for the collaborative improvement of retrosynthesis models without sharing sensitive reaction data between participants. The collaboration occurs through multiple rounds of communication where only implicit and explicit chemical knowledge\u2014rather than raw reaction data is exchanged. For the retrosynthesis prediction task itself, we define it as the process of training a machine learning model (or hypothesis) that maps a target molecule to its corresponding precursors (i.e., reactants).\nPrivacy-aware model training. The standard Transformer is adopted to learn a probabilistic mapping $P(y|x)$ from a given target molecule $x$ to reactants $y$. Suppose there are a total of $K$ clients, each possessing a local reaction dataset $\\{(x_n, y_n)\\}_{n=1}^{N_i}$, where $N_i$ denotes the number of reactions stored on the $i$-th client $C_i$. Our objective is to collaboratively learn a retrosynthesis model with parameters $\\Theta$, without centralizing or sharing training reaction data. In the remaining content, we first formally define the steps of each communication round of CKIF, and introduce the learning objective of retrosynthesis model. We then elaborate on the CKIW strategy which learns a personalized model for each client.\nAt each communication round of CKIF, three procedures are performed sequentially for all clients. Firstly, model parameters generated by the previous round are used for parameter initialization (random initialization for the first round). Secondly, the initialized models of each client are trained locally on their own reaction data for\na fixed number of epochs (or iterations) to minimize the following objective function:\n$L = -\\log P(y|x; \\Theta)$.\nOnce trained, each client $C_i$ sends their parameters $\\Theta^{C_i}$ to the central server. Thirdly, after collection, these parameters are aggregated (i.e., weighted sum) to a new global model by the central server: $\\Theta^G = \\sum_{k=1}^{K} w_k \\Theta^{C_k}$, where $w_k$ is the weighting factor for client $C_k$. As one of the most widely used methods in federated learning, FedAvg defines the weighting factor for $C_i$ as the proportion of training samples: $w_i = N_i/(\\sum_{k=1}^{K} N_k)$.\nDespite being prevalent, mainstream federated learning methods like FedAvg struggle to handle data heterogeneity  one common characteristic of chemical entities, where reaction data often reflects specialized research focuses or industrial interests. To address this, CKIF further investigates the problem of privacy-preserving retrosynthesis learning with a focus on client-specific needs. Concretely, CKIF enables each chemical entity to have a personalized model that adapts to their own data distribution and preferences, while also benefiting from the chemical knowledge of other clients by only exchanging model parameters. Consequently, instead of performing a standard aggregation of global parameters $\\Theta^G$ in each communication round, CKIF redefines the aggregation process to create a personalized model for each client (see Algorithm 1). For instance, the personalized model for client $C_i$ is obtained by:\n$\\Theta^{C_i} = \\sum_{k=1}^{K} w_{ik} \\Theta^{C_k}$\nwhere $w_{ik}$ denotes the adaptive weighting factor power by the proposed CKIW strategy (Algorithm 2). $w_{ik}$ quantifies the importance of models from other clients $C_k$ relative to the given client $C_i$, and is normalized as:\n$w_{ik} = \\begin{cases}\\mu + (1 - \\mu) \\frac{\\exp(s_{i,k}/\\tau)}{\\sum_{j=1,j \\neq i}^{K} \\exp(s_{i,j}/\\tau)} & i \\neq k\\\\(1-\\mu) \\sum_{j=1,2\\neq j}^{K}(\\frac{\\exp(s_{i,j}/\\tau)}{\\sum_{l=1,j\\neq l}^{K} \\exp(s_{i,l}/\\tau)}) & i=k\\end{cases}$\nwhere $\\mu$ and $\\tau$ are hyperparameters that control the influence of self's model $\\Theta^{C_i}$ and neighboring clients' models $\\Theta^{C_k}$. $s_{ik}$ represents the similarity score between the reactants predicted by $C_k$ and the annotated ones stored in $C_i$. Note that the process of measuring similarity involves using proxy reaction data, which are stored securely and processed locally on each client. During the collaborative training process, only the model parameters are communicated. In our experiment, all reaction data in the validation set are chosen as the proxy reaction data. Clients can optionally provide additional proxy reaction data for improved measurement.\nIn the above distributed training procedure, the strategy used to assign weights to individual models during aggregation is of great importance  for the performance, convergence, etc. Generic weighting strategies, such as count-based averaging, rely on handcrafted metrics. Such heuristic methods have significant limitations:"}]}