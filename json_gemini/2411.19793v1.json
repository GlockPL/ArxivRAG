{"title": "VOICE COMMUNICATION ANALYSIS IN ESPORTS", "authors": ["Aymeric Vinot", "Nicolas Perez"], "abstract": "In most team-based esports, voice communications are prominent in the team efficiency and synergy. In fact it has been observed that not only the skill aspect of the team but also the team effective voice communication comes into play when trying to have good performance in official matches. With the recent emergence of LLM (Large Language Models) tools regarding NLP (Natural Language Processing) [18], we decided to try applying them in order to have a better understanding on how to improve the effectiveness of the voice communications. In this paper the study has been made through the prism of League of Legends esport. However the main concepts and ideas can be easily applicable in any other team related esports.", "sections": [{"title": "1 Introduction", "content": "In most team-based esports, voice communications are prominent in the team efficiency and synergy. In fact it has been observed that not only the skill aspect of the team but also the team effective voice communication comes into play when trying to have good performance in official matches. With the recent emergence of LLM (Large Language Models) tools regarding NLP (Natural Language Processing) [18], we decided to try applying them in order to have a better understanding on how to improve the effectiveness of the voice communications. In this paper the study has been made through the prism of League of Legends esport. However the main concepts and ideas can be easily applicable in any other team related esports.\nToday, this aspect of voice analysis in esport is overlooked due to the lack of tools an shared knowledge that could help solve this problem. Moreover this subject is a very interesting study case. In fact we need to employ few-shot techniques to perform our study on esport voice communication as very few to none datasets are publicly available. This is why we conducted this analysis in order to find some starting tracks in this field. The main objectives of such voice communication analysis are to build metrics to determine how effective players are communicating during the game. In fact building such evaluation tools could be very relevant to correlate with in-game performance metrics, thus trying to pin-point the positive and/or negative potential impacts of communication quality in the overall game performance. After some surveys with coaches in professional teams we ended up with two main issues regarding the communication effectiveness :\n\u2022 Duplicate communications: Sometimes players are communicating the same idea several times in a short period of time. Hence blurring the conversation and reducing the effectiveness of the communication.\n\u2022 Parasite communication: Sometimes players communicate ideas that are unclear/not relevant in the context of the game.\nThis article aims to propose possible solutions for these two problems that will be respectively treated in section 3 and section 4"}, {"title": "2 Audio processing pipeline", "content": "Just before diving into the details of our solutions, we wanted to share with you how we treated such audio files. For this we used the work of Bain et. al. [2] to transcribe the audio into text. The method used in [2] can be seen at Figure 1\nThus, with the help of [2] and some adjustments, the following has been done:\n1. First we transcribe the audio file using Whisper [1] from OpenAI.\n2. Then we perform speaker diarization with the help of PixIT model [11] implemented by pyannote.audio [4].\n3. Finally we perform forced-text alignment to align words spoken by each player with its timestamp.\nHowever it is possible to use direclty other pieces of software (discord bots and so on) to skip the uncertainty of the speaker-diarization step. As we observed that some pieces of speech were wrongly attributed to a given speaker."}, {"title": "3 Duplicate communications", "content": "In this section we will present an approach of repetitive/duplicate communication detection based on lexical similarity. By using this approach, we move closer to the process of retrieving relevant pieces of information in open-domain question answering [5] by checking how similar two pieces of text are by semantic/lexical meaning. One of the advantage of using sentence similarity is being able to have easily interpretable and non-chaotic results."}, {"title": "3.1 Explanation and solution of the problem", "content": null}, {"title": "3.1.1 Formal explanation and solution", "content": "Traditionally, when comparing the similarity between two pieces of text to leverage lexical similarities, we often use TF-IDF or BM25 weighting [17]. However these approaches based on near-exact matches between keywords between two pieces of text suffer from the lexical gap and do not generalize well [3]. By contrast, approaches based on neural networks allow learning beyond lexical similarities, resulting in way better performances for our task. We will refer to this method by \"semantic similarity\". This metric will be used on each sentences and compare it to every other previous sentences spoken by the given player in the last W seconds. For example, consider the following snippets of conversation :\n010 [082.458:084.699] SPEAKER_00 I mean in 3:00, we have to watch out for Zyra though.\n011 [091.545:092.866] SPEAKER_00 I think they're rebased, yeah.\n012 [113.055:113.855] SPEAKER_00 Zyra is doing golem.\n013 [114.075:114.876] SPEAKER_00 Zyra is doing golem.\n014 - [122.020:123.141] SPEAKER_00 He was pecking left.\n015 [123.501:124.161] SPEAKER_00 He was leaving.\n021 [177.551:178.012] SPEAKER_00 I'll do ignite.\n022 [180.774:181.654] SPEAKER_00 Push base, push base."}, {"title": "3.1.2 Mathematical explanation and solution", "content": "In the precedent section we talked about a way of extracting the semantic meaning/similarity of a sentence. There are severall methods to extract such embeddings, like word embedding. Here we take a novel approach of using sentence embedding models [16] that takes into account the context to compute the embedding of a given sentence. With the embedding of the reference sentence, we can then compute the embedding of all the previous sentences that has been spoken by the given player in the last W seconds. By applying this embedding process with sentence transformer [16], we ensure that the semantic meaning of the sentence is encoded within the dimensions of the embedding vector in a high dimensional space (\u2248 1024 dimensions). The main goal of projecting our sentences in this high-dimensional space is enable decoding using neural networks or direct Euclidian/linear algebra methods.\nThe most common way to compare if two vectors are close to each other is the cosine similarity. This idea is somewhat the same when we perform retrieval operations in the Open Domain Question Answerign Task [13]. By applying this cosine similarity to all the sentences in the last W seconds, we then have a set of $N_w$ similarity scores from which we take the maximum similarity score. As its name suggests, the cosine similarity returns the $| cos(\\theta)$ of the angle $\\theta$ between two embedding vectors. The closest to 1 this value is, the closest in terms of meaning these two vectors (i.e. sentences) are."}, {"title": null, "content": "Let $S_t$ the set of all sentences spoken by our player in a window of W seconds before t. We have,\n$S_t = \\{s_i | i \\in [t \u2013 W; t \u2013 1]\\}$ (1)\nTo compute the similarity between two sentences we compute the cosine similarity of the two sentences embeddings. As previously mentionned, these sentence embeddings are computed via a succession of BERT [6] blocks, forming a sentence transformer [16]. For a sentence $S_t$ spoken at time t we denote $E_{S_t}$ its corresponding embedding vector. We then have for the cosine similarity of two sentences spoken at t and t' :\n$cosine\\_sim(E_{S_t}, E_{S_{t'}}) = \\frac{\\langle E_{S_t} \\cdot E_{S_{t'}}\\rangle}{||E_{S_t}|| \\times ||E_{S_{t'}}||}$ (2)\nWhere $\\langle,\\rangle$ is the dot product of two vectors.\nWe then have the score of all the sentences denoted by it's time t index within 0 and $T_{max}$, where $T_{max}$ is the amount of sentences spoken by our player :\n$\\forall t \\in [0, T_{max}], Global\\_Score = max(cosine\\_sim(E_{S_t}, E_{S_{t'}}))$ (3)\n$\\forall t \\in [0, T_{max}], Global\\_Score = max(cosine\\_sim(E_{S_t}, E_{S_{t'}}))$ (3)\nThis score basically tells us: \"For the sentence spoken at time t, it has as score of beeing redundant to the $i^{th}$ sentence preceding it\"\nYou can see in Figure 2 that for each sentences of SPEAKER_00 we have a score ranging from 0 to 1 that leverage how much this given sentence is being flagged as a repetitive one based on the previous context. And you can see that sentence 024, as mentioned in section 3.1.2, has a high similarity score (0.65), which echoes to the semantic meaning of sentence 022."}, {"title": "3.2 Experiments", "content": "In this section we will take a closer look on how the method detailed in 3.1 behaves on a given piece of conversation. Please refer to Figure 3 alongside reading this section."}, {"title": "3.2.1 Experimental set-up", "content": "\u2022 W: 15s\n\u2022 Embedding model : \"mixedbread-ai/mxbai-embed-large-v1\" [14]\n\u2022 Audio length: 235s\n\u2022 Amount of speakers : 3"}, {"title": "3.2.2 Performances/Experiments", "content": "Here in this section we will take a closer look on another game where we used our tool on. The main objective here is to analyze to determine if the results aligns with the expected outcomes. The transcriptions of Figure 3 are listed in Appendix 8.1.\nFor the purpose of clarity we will only focus on SPEAKER_01, however feel free to perform the same analysis for SPEAKER_02 and SPEAKER_00.\nOn Figure 3 most sentences have a score around 0.5, indicating typical communication characteristics. This behavior is widely due to how conversation are done, sentences tend to focus on similar subjects, here being what's happening within the game. However it is noticable that if the score is raising above the 0.6 threshold, the given sentence is somewhat repetitive.\nLet's take the case of the 12th sentence. Here are below the sentences spoken by SPEAKER_01 15s before sentence 12:\n007 [69.556:71.557] SPEAKER_01 Okay, I'm moving top side now, okay?\n008 [71.577:73.239] SPEAKER_01 Probably just ward, but he can move top.\n009 [73.259:0074.4] SPEAKER_01 I think you should base and I'll stay.\n010 [074.86:76.141] SPEAKER_01 I can get BF in two waves.\n011 [77.482:78.503] SPEAKER_01 I think we can't, boys.\n012 [79.104:79.864] SPEAKER_01 No, no, no, we can't."}, {"title": "4 Parasite communications", "content": "As we have seen in section 3.2 sometimes the way that players express their thoughts might not be clear, causing blurred and unclear communication among players and penalizing in the short term the team's performance. To assess this issue we have tried to use a similar approach based on lexical and semantic similarity [5]."}, {"title": "4.1 First approach of the problem", "content": null}, {"title": "4.1.1 Explanation and solutions", "content": "The first aproach of solving this problem was somewhat similar to the one seen in section 3. But to address the inherent uncertainty in such communication, we came up, thanks to the help of professional coaches, with a set of phrasing that would be representative of the unwanted communnication styles (see Appendix 8.2). For example given the two following sentences:\n001 [77.482:78.503] SPEAKER_01 I think we can't, boys\n002 [77.482:78.503] SPEAKER_01 We can't\nThese two sentences are inherently saying the same thing, for sentence 001, the phrasing is not appropriate. In fact such phrasing would yield uncertainty in voice communications, hence making communication less effective and directive.\nThis can be verified by comparing the sentences embeddings with the embedding of the phrasing \"I think\" ($P1$) (extracted from the list of phrasing listed in Appendix 8.2) with the embedding model of [14] :\n$Score_1 = cosine\\_sim(E_{s_1}, E_{p_1}) = 0.5109$\n$Score_2 = cosine\\_sim(E_{s_2}, E_{p_1}) = 0.4027$ (4)\nHere we clearly have $Score_1 > Score_2$, which validates the fact that the first sentence is more parasite than the second one. To build such metric we would proceed as following:\nLet $n_i$ the amount of sentences spoken by SPEAKER_$i$ and $P_j$ the $j^{th}$ parasite phrasing from Appendix 8.2. We first compute for each sentences spoken by SPEAKER_$i$, the similarity score with each parasite phrasings. We have then for each sentence $S_k, k\\in[0, n_i]$:\n$SC = \\{cosine\\_sim(E_{s_l}, E_{p_j}) | j \\in [0, n_i]\\}$ (5)\nWe then take the maximum of these scores and flag it as parasite if it is above 0.6. We denote it as $F_{s_i}$. Let F the set of real number between 0.6 and 1. We have:\n$F = \\{x \\in R | 0.6 \\leq x \\leq 1\\}$\n$F_{S_i} = 1_F(max(SC))$ (6)\nWhere $1_F(\\cdot)$ is the characteristic function of the set F that yields 1 if the parameter is in the given set and 0 otherwise."}, {"title": "4.1.2 Limitations", "content": "With this process, each sentences is flagged at 0 or 1 given if we deem it as parasite. Before taking the maximum of $S_e)$ we have the following heatmap at Figure 5. On each column of this heatmap we have the similarity score between the given sentence and every parasite phrasing from appendix 8.2. And it's by analysing the maximum values of each similarity score columns that we flag the sentence as parasite or not."}, {"title": "4.2 Refining the first aproach : Embedding refining", "content": "To leverage this issue, we could compute the embedding of the conversation context a fixed time prior to the problematic sentence, then make a pooling operation on the individual token embeddings, that has been recomputed with the context of the converstation, corresponding to the problematic sentence. The overall process is depicted in Figure 7"}, {"title": "4.2.1 Experiments", "content": "For this section we will take a look at the interference of SPEAKER_00 in the example shown at Figure 9. The sentences spoken as well as the corresponding recomputed interference heatmap are availabale at Appendix 8.3. In our example SPEAKER_00 has spoken 23 sentences."}, {"title": "5 Performance", "content": null}, {"title": "5.1 Experimental set-up", "content": "\u2022 W: 15s\n\u2022 Audio length: 359s\n\u2022 Amount of speakers : 3\n\u2022 Amount of sentences: 129\nAll the data has been labelized by human and including professional coaches in the process to ensure the quality of labeling."}, {"title": "5.2 Results", "content": "Here in table 1, the results of the experimental set-up above is provided on the duplicate communication model and parasite communication model. For duplicate communication and parasite communicaiton we took a fixed threshold of decision at 0.6."}, {"title": "6 Related Works", "content": "The analysis of voice communication, especially within team-oriented environments, has gained our attention as advancements in Natural Language Processing and machine learning provide new tools for interpreting nuanced human interactions. However in this paper, we only took a look at the voice communication aspect of the League of Legends. As explained in the following section 7 we think that correlating these metrics with in-game performance indicators could be relevant to better capture the team performance. That is why we will present some related works that treats the in-game and draft part of the competitive aspect of League of Legends.\nDraft recommendation system: Some work have been done regarding building a model to rec-ommend champions picks within a draft based on the draft context and the player games history. A dual network approach has been presented by the KAIST [7] paper. One networks aims to reproduce the embedding system of the BERT network [6] by taking from the player's match histroy the champions he played, the roles and some other features in order to generate the embedding of that player profile. Then the other network is a prediction autoregressive transformer-based neural network that recommends the best champions given the draft state and the embedding of our player.\nPredicting match outcome to extract relevant player metrics: Some other works were re-lated around building prediction model in order to predict the match outcome. A first approach of using machine learning methods and classic architectures with real time statistics (team champion kills, total golds, etc...) was explored by Jailson B. S. Junior et. al. [8]. In this article they proceeded of training several machine learning common architectures (Random Forest, Logistic Regression, Naive Bayes, Gradient Boosting, XGBoost, LightGBM, MLP, Bagging and RNN) on these real-time game data to predict the match outcome.\nSimilarly the work from P. Jalovaara [9] is using a neural network approach. With some precise tuning on MLP networks and training objectives P. Jalovaara managed to have promising results in predicting match outcome and extending his methods to optimal build path as well.\nAnother notable work is the one from Jiang et. al. [10] where they've build a custom embedding system called NICE (Neural Individualized Context-aware Embeddings). This system aims to use contextual information of a given player in a given state of the game to predict the match outcome. In order to do this they generate the embeddings from a set of features of these sets :\n$user \\times global\\_context \\times individual\\_contexts$ (7)\nAll this performed with the help of the Non-Negative Tensor Factorization [12] method."}, {"title": "7 Conclusion and discussion / improvements", "content": "In this paper, we presented an approach to analyze voice communications in esports, specifically focusing on detecting duplicate and \"parasite\" communication in League of Legends. Through the use of semantic similarity measures and NLP embedding techniques, we developed metrics to assess communication quality and its potential impact on team performance. While the results offer promising results some dark parts still remains to be assessed that might be subject of future research."}, {"title": "7.1 Improvements", "content": "Specialized Embedding Model: One of the limitation of our current approach is that it relies on embeddings from models trained on general-purpose corpora. In fact in this paper we used such general-purpose embedding model from [14, 19]. Future work could focus on developing an embedding model trained specifically on League of Legends or other esports related datasets. This would likely capture the unique linguistic patterns, terminology, and contextual cues in esports, potentially improving the model's ability to identify nuanced, context-sensitive communication.\nCorrelation with In-Game Performance: Currently, the relationship between communication quality and team performance remains unmentioned in our analysis. Future research could try to incorporate in-game performance metrics with communication metrics. Hence trying to build multimodal metrics that could encapsulate better player and team performance. This approach could reveal more direct associations between communication effectiveness and game outcomes, providing empirical validation on the impact of voice communication on team success.\nRaw Audio Analysis: At first we focused on applying NLP techniques on transcribed text as it easier than treating raw audio file. That is why extending this methodology to include raw audio data could provide a richer understanding of communication dynamics. By leveraging audio features such as tone, pitch, and volume, we might capture additional elements of speaker intent and sentiment that text alone cannot convey. A way of such integreation would be to use whisper's encoder [1] to generate audio embedding of each pieces of speech. Integrating these audio features could create a multimodal analysis model, enhancing the detection of key communication traits. However the problem of using general-purpose audio model still remains when applying it on specialized League of Legend data.\nImproved Detection of Parasite Sentences: Our current decision function for flagging \"para-site\" sentences is binary and based on a fixed similarity threshold. In our work we chose 0.6 as it was one of the most reliable threshold. To refine this, we could implement a smoother decision function that adjusts the threshold based on the context and speaker. By using a continuous rather than binary function, the model might better discriminate between minor conversational nuances and genuinely disruptive communication patterns, enhancing its sensitivity to context. This way we could try to reproduce the linear and smooth activation function after a linear layer in an MLP network, but adapted as a decision function for \"parasite\" activation on a given piece of speech.\nEnhanced parasite phrasing/sentiment encoding: The current model considers only short, isolated pieces of sentences/phrasing to detect a parasitic speech. Future work could involve a more sophisticated parasite phrasing/sentiment encoding mechanism that captures the broader emotional tone of phrases within the game's context. For instance, pooling embeddings of multiple related words or phrases could yield more accurate parasite phrasing/sentiment vectors, improving the model's ability to assess both positive and negative influences of communication on team dynamics.\nNew metric sentence relevance: Currently our parasite sentence detection only takes into ac-count sentences that reflects hesitation and/or uncertainty in the way it is spoken. However it does not takes into account the fact that players might talk about irrelevant topics during the game, hense making the team lose focus on the said game. One approach would be to also use sentence similarity but this time comparing the vector embedding of the current sentence with the embedding of the conversation 15s prior to the said sentence. By doing this we could have a metric that could ensure how often each player are talking about topics that are not directly related to the game's state."}, {"title": "7.2 Practical Contributions", "content": "In summary, while our study provides a foundational framework for analyzing voice communication in esports, these potential improvements represent valuable opportunities for refinement. Continued researchin these areas could contribute to a more holistic and nuanced understanding of how communication impacts team performance in competitive gaming.\nBeyond the theoretical insights provided, this work offers tangible applications that can aid coaches in opti-mizing team performance through improved communication analysis. By applying the voice-communication metrics developed here, coaches can gain a clearer understanding of each player's communication profile, identifying tendencies like repetitive or unclear communication that might by a liability for the overall team cohesion. This profile-based insight can help coaches adapt their feedback to suit each player's unique communication style, fostering better synergy in team interactions.\nFurthermore, this analysis provides a comprehensive overview of team communication as a whole, allowing coaches to assess how effectively the team communicates in tense situations. By visualiz-ing patterns of redundant and parasite communications, coaches can identify specific areas where the team excels or struggles, giving them a baseline measure of team coordination that can be optimized over time.\nFinally, the insights from this study can serve as a valuable resource for planning future training sessions. Coaches can target identified weaknesses in communication, structuring training exercises to address specific issues such as reducing redundant calls or encouraging more direct communication during critical in-game moments. This approach not only enhances communication quality but also ensures that each practice session is strategically aligned with the team's communication needs."}, {"title": "8 Appendix", "content": null}, {"title": "8.1 Communication Logs", "content": "000 [00.942:02.163] SPEAKER_01 You need to push out, XXXX.\n001 [02.884:03.424] SPEAKER_01 Oh, okay.\n002 [03.684:05.826] SPEAKER_01 They do my Gromp.\n003 [17.837:18.618] SPEAKER_01 I'll face Zyra, Leona.\n004 [19.078:22.741] SPEAKER_01 I'm going.\n005 [23.622:23.882] SPEAKER_01 Can you?\n006 [30.828:32.469] SPEAKER_01 Okay, not bad, got a kill WP.\n007 [69.556:71.557] SPEAKER_01 Okay, I'm moving top side now, okay?\n008 [71.577:73.239] SPEAKER_01 Probably just ward, but he can move top.\n009 [73.259:0074.4] SPEAKER_01 I think you should base and I'll stay.\n010 [074.86:76.141] SPEAKER_01 I can get BF in two waves.\n011 [77.482:78.503] SPEAKER_01 I think we can't, boys.\n012 [79.104:79.864] SPEAKER_01 No, no, no, we can't.\n013 [83.027:83.688] SPEAKER_01 Yeah, me too, me too.\n014 [83.728:84.008] SPEAKER_01 No waves.\n015 [87.848:88.868] SPEAKER_01 My mid is going pretty good.\n016 [89.028:92.269] SPEAKER_01 I survived the early game phase, so... What's up, dude?\n017 [094.27:095.07] SPEAKER_01 Bot is going pretty good.\n018 [105.152:106.713] SPEAKER_01 Uhh... I have a tree in my back.\n019 [107.513:107.693] SPEAKER_01 Okay.\n020 [107.713:112.554] SPEAKER_01 I mean, we don't have imp there, so... Everyone moving, yeah.\n021 [119.443:120.163] SPEAKER_01 I will not push this.\n022 [120.784:121.044] SPEAKER_01 Okay.\n023 [124.826:130.829] SPEAKER_01 He wants to W from here, but... Any flash, XXXX?\n024 [138.813:140.174] SPEAKER_01 I'm basically late, but I'm really strong."}, {"title": "8.2 Parasite Phrasings", "content": "\u2022 I think\n\u2022 I don't think\n\u2022 We should\n\u2022 We shouldn't\n\u2022 Maybe\n\u2022 We could\n\u2022 We couldn't\n\u2022 Hmmmmmmmmm\n\u2022 I don't know\n\u2022 I'm not sure\n\u2022 Can we ?\n\u2022 Can I engage?"}, {"title": "8.3 Materials for analysis", "content": null}, {"title": "8.3.1 Logs", "content": "000 [50.899:55.501] SPEAKER_00 Okay guys, whenever someone flash, say it, I'm pinging it, because I got it, so it's easy for me.\n001 [81.726:82.547] SPEAKER_00 I mean, I can't.\n002 [99.511:100.551] SPEAKER_00 No, they just go Void.\n003 [100.811:103.092] SPEAKER_00 If we can... Could we go into Drake?\n004 [103.432:104.012] SPEAKER_00 I miss or no?\n005 [180.564:181.205] SPEAKER_00 I'm dying, I'm dying."}, {"title": "8.3.2 Interference Heatmap Recomputed", "content": "006 [236.328:236.768] SPEAKER_00 Nice try.\n007 [238.028:241.67] SPEAKER_00 Only XXXXX flashed?\n008 [256.878:258.659] SPEAKER_00 I think get some items and then we can fight again.\n009 [258.799:260.18] SPEAKER_00 Now, about fight maybe.\n010 [261.181:262.082] SPEAKER_00 Wait Lucian, let me pull this.\n011 [262.142:263.162] SPEAKER_00 I get, I get one more.\n012- [335.402:336.643] SPEAKER_00 When Nami is there, we can TP.\n013- [337.624:338.204] SPEAKER_00 If they hit turret.\n014 - [347.841:348.621] SPEAKER_00 They can swap him maybe?\n015 [348.961:349.622] SPEAKER_00 Can they swap him?\n016 [350.323:351.143] SPEAKER_00 Yeah, they can.\n017 [355.447:355.707] SPEAKER_00 Okay.\n018 [356.748:357.228] SPEAKER_00 I'll stop him.\n019 [357.368:357.789] SPEAKER_00 I'll stop him.\n020 [357.829:360.271] SPEAKER_00 He's here.\n021 [361.732:362.633] SPEAKER_00 He's still not there, okay?\n022 [362.653:363.434] SPEAKER_00 If he's there, he will TP.\nThe max interfering scores that are higher than 0.6 are highlighted in cyan for clarity purposes."}, {"title": "8.4 Interference Heatmap Not Recomputed", "content": "This heatmap is computed from the same audio sample of above heatmap, but without the embedding refinment"}]}