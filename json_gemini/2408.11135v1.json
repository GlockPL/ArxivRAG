{"title": "MS\u00b3D: A RG Flow-Based Regularization for GAN Training with Limited Data", "authors": ["Jian Wang", "Xin Lan", "Yuxin Tian", "Jiancheng Lv"], "abstract": "Generative adversarial networks (GANs) have made impressive advances in image generation, but they often require large-scale training data to avoid degradation caused by discriminator overfitting. To tackle this issue, we investigate the challenge of training GANs with limited data, and propose a novel regularization method based on the idea of renormalization group (RG) in physics.We observe that in the limited data setting, the gradient pattern that the generator obtains from the discriminator becomes more aggregated over time. In RG context, this aggregated pattern exhibits a high discrepancy from its coarse-grained versions, which implies a high-capacity and sensitive system, prone to overfitting and collapse. To address this problem, we introduce a multi-scale structural self-dissimilarity (MS3D) regularization, which constrains the gradient field to have a consistent pattern across different scales, thereby fostering a more redundant and robust system. We show that our method can effectively enhance the performance and stability of GANs under limited data scenarios, and even allow them to generate high-quality images with very few data.", "sections": [{"title": "1. Introduction", "content": "The challenge of training GANs with limited data has garnered increasing attention within the research community. Numerous studies (Zhao et al., 2020a; Karras et al., 2020a; Jiang et al., 2021; Tseng et al., 2021; Fang et al., 2022; Cui et al., 2023) have reached a consensus: insufficient data often leads to overfitting in the discriminator. This overfitting results in a lack of meaningful dynamic guidance for the generator, ultimately causing its performance to degrade.\nData augmentation, a standard solution to prevent overfitting in deep learning (Shorten & Khoshgoftaar, 2019), has been widely applied to GAN training in limited data scenarios. Traditional (Zhao et al., 2020b; Tran et al., 2021) and differentiable (Zhao et al., 2020a) data augmentation techniques for both real and generated images, as well as various adaptive augmentation strategies (Karras et al., 2020a), have shown good performance on several standard benchmarks. However, the effectiveness of data augmentation heavily depends on specific handcrafted types or a costly search process, which limits its generality (Zhao et al., 2020b; Karras et al., 2020a). Additionally, data augmentation addresses data deficiency by enhancing the quantity and diversity of samples without providing a deeper understanding of the internal dynamics of GANs.\nIn this paper, we address the problem of GAN deterioration from a novel perspective and introduce a model regularization method. Unlike most existing regularization techniques (Tseng et al., 2021; Cui et al., 2022; 2023) that focus on improving the discriminator's generalization across different data distributions to avoid overfitting, our approach explores the intrinsic properties of neural networks to uncover potential clues. Specifically, we observe that in settings with limited data, the gradients provided by the discriminator, i.e., $\u2207_x f(x; \\phi)$, gradually exhibit an aggregation pattern. This pattern indicates that the discriminator concentrates its attention on a small portion of the input"}, {"title": "2. Related Work", "content": "Generative adversarial networks. Generative adversarial networks (GANs) (Goodfellow et al., 2014) have made significant advancements in generating high-quality and diverse images. This progress is attributed to the development of more robust objective functions (Arjovsky et al., 2017; Gulrajani et al., 2017; Zhao et al., 2017; Mao et al., 2017; Song & Ermon, 2020), advanced architectures (Miyato et al., 2018; Miyato & Koyama, 2018; Zhang et al., 2019), and effective training strategies (Denton et al., 2015; Zhang et al., 2017; Karras et al., 2018; Liu et al., 2020). Notable examples include BigGAN (Brock et al., 2019) and StyleGAN (Karras et al., 2019; 2020b), which are capable of generating high-resolution images with rich details and diverse styles. This paper focuses on the challenges and solutions for training GANs with limited data.\nTraining GANs under limited data setting. Training GANs with limited data presents significant challenges, as the discriminator may overfit, leading to degraded generated samples (Webster et al., 2019; Gulrajani et al., 2019). One common approach to mitigate this issue is data augmentation (Karras et al., 2020a; Tran et al., 2020; Zhang et al., 2020; Zhao et al., 2020a; 2021; 2020b), which enriches the data distribution by applying transformations to the original samples. However, data augmentation is not straightforward for GANs, as it can alter the target distribution or introduce artifacts (augmentation leaking). Recent methods have been designed to address these challenges, such as differentiable augmentation (Zhao et al., 2020a), adaptive augmentation (Karras et al., 2020a), and generative augmentation (Zhao et al., 2020b).\nAnother approach is model regularization, which prevents the discriminator from overfitting by imposing constraints or penalties on its parameters or outputs. While model regularization is commonly used to stabilize GAN training and prevent mode collapse, it is particularly effective in data-limited settings where overfitting is more severe. Techniques include adding noise to the discriminator's inputs or outputs (Arjovsky & Bottou, 2017; S\u00f8nderby et al., 2017; Jenni & Favaro, 2019), applying gradient penalties (Gulrajani et al., 2017; Mescheder et al., 2018), using spectral normalization (Miyato et al., 2018; Miyato & Koyama, 2018), and adding consistency loss (Zhang et al., 2020). Recent innovations, such as the LC regularization term (Tseng et al., 2021), which modulates the discriminator's evaluations using two exponential moving average variables and connects to LeCam divergence (Cam, 1986), have shown significant benefits. DigGAN (Fang et al., 2022) addresses gradient discrepancies between real and generated images, improving GAN performance. Additionally, leveraging external knowledge by using pre-trained models as additional discriminators (Kumari et al., 2022), aligning discriminator features"}, {"title": "3. Methodology", "content": "3.1. Generative Adversarial Networks\nGenerative adversarial networks (GANs) (Goodfellow et al., 2014) are a class of generative models designed to synthesize realistic data samples from a latent noise vector z. GANs consist of two neural networks: a generator g(\u00b7; \u03b8) that transforms the noise vector into a data sample, and a discriminator f(\u00b7; \u03c6) that distinguishes between real and generated samples. These networks are trained adversarially; the generator aims to produce samples that mimic the real data distribution, while the discriminator aims to accurately classify samples as real or fake. The training objective of GANs is formulated as a minimax game:\n$\\min_{\\theta} \\max_{\\Phi} E_{x} [\\log f(x; \\phi)]+E_{z}[\\log(1-f(g(z; \\theta); \\phi))].$ (1)\nThe optimal solution is a Nash equilibrium where the generator produces samples indistinguishable from real data, and the discriminator assigns a probability of 0.5 to all samples."}, {"title": "3.2. Perceptual Narrowing Phenomenon", "content": "Discriminator overfitting is a critical issue in GAN training with limited data, leading to a degradation in the quality of generated images (Zhao et al., 2020a; Karras et al., 2020a; Jiang et al., 2021; Tseng et al., 2021). This phenomenon is demonstrated in our experiments with StyleGAN2 (Karras et al., 2020b) on OxfordDog dataset (Parkhi et al., 2012), as shown in Fig. 2(a). The discriminator becomes increasingly confident about the real images from the training set while becoming less confident about real images from the validation set, leading to a deterioration in Fr\u00e9chet Inception Distance (FID) (Heusel et al., 2017) over time.\nAdditionally, we observe that the gradient field $\u2207_x f(x; \u03c6)$ of the discriminator with respect to the input becomes more aggregated over time, as shown in Fig. 3(a). Intuitively, this aggregation may provide fragmented guidance to the generator. We refer to this as the perceptual narrowing phenomenon. To quantify this, we devise a metric that counts the connected regions $N_{agg}$ by assigning 1 to gradient values above a threshold and 0 to the rest, followed by a connected component analysis. The ratio of connected regions to the total number of pixels, i.e., $R_{agg} = \\frac{N_{agg}}{H\\times W}$, indicates the degree of gradient aggregation. Visual representations of connected regions are shown in Fig. 3(a, right).\nExtensive experiments on four small-scale datasets using various divergence measures and GAN architectures (detailed in Section 4) consistently showed that the number of connected regions initially increases but then decreases as training progresses, indicating increasing gradient aggregation (Fig. 2b, left). In contrast, with data augmentation or increased data volume to mitigate overfitting, the number of connected regions remains stable (Fig. 2b, middle and right). These findings suggest a link between overfitting and gradient aggregation in limited data GAN training.\nOur analysis introduces a fresh perspective through the renormalization group (RG) (Kadanoff, 1966; Wilson, 1971), a technique devised to gradually extract the coarser statistical features of a physical system through local transformation. We observe that, in contrast to the dispersed pattern, the aggregated pattern demonstrates a significant divergence from its coarse-grained counterpart, as illustrated in Fig. 1. This self-dissimilarity (SD) reveals that the system processes information distinctively across different scales (Jacobs & Jacobs, 1992; Wolpert & Macready, 2007), implying that the system is capable of encoding extensive information processing into its dynamics. This suggests that the system is both efficient and possesses a high degree of \"plasticity\" (learnability) from a neurological perspective (Hensch, 2004). Nonetheless, it also indicates that the system is sensitive and susceptible to minor disturbances that could lead to notable alterations in its dynamics (Achille et al., 2019). These properties hint at the system's tendency"}, {"title": "3.3. Multi-scale Structural Self-dissimilarity", "content": "Building upon the previous analysis, we introduce a novel regularization method, termed multi-scale structural self-"}]}