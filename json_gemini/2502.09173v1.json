{"title": "Two-Stage Representation Learning for Analyzing Movement Behavior Dynamics\nin People Living with Dementia", "authors": ["Jin Cui", "Alexander Capstick", "Payam Barnaghi", "Gregory Scott"], "abstract": "In remote healthcare monitoring, time series representation\nlearning reveals critical patient behavior patterns from high-\nfrequency data. This study analyzes home activity data from\nindividuals living with dementia by proposing a two-stage,\nself-supervised learning approach tailored to uncover low-\nrank structures. The first stage converts time-series activi-\nties into text sequences encoded by a pre-trained language\nmodel, providing a rich, high-dimensional representation.\nIn the second stage, these vectors are transformed into a\nlow-dimensional latent state space using a PageRank-based\nmethod. This PageRank vector captures latent state transi-\ntions, effectively compressing complex behavior data into a\nsuccinct form that enhances model interpretability. This low-\nrank representation not only enhances interpretability but also\nfacilitates clustering and transition analysis, revealing key\nbehavioral patterns correlated with clinical metrics such as\nMMSE and ADAS-Cog scores. Our findings demonstrate the\nframework's potential in supporting cognitive status predic-\ntion, personalized care interventions, and large-scale health\nmonitoring.", "sections": [{"title": "Introduction", "content": "In remote healthcare monitoring applications, the use of\nwearables and Internet of Things (IoT) devices to contin-\nuously collect time-series data, as is shown in Figure 1, of-\nten with second-level accuracy or finer, has become increas-\ningly common. However, the sheer scale of such data makes\nit difficult for human experts to analyze or use directly, ne-\ncessitating the use of time-series deep learning techniques\nfor effective analysis and diagnosis.\nTraining on large volumes of unlabeled time-series data\nposes a significant challenge. Semi-supervised and unsuper-\nvised methods are typically employed to encode and ex-\ntract data features for downstream tasks like classification\nor regression, demonstrating their ability to capture deep\nfeatures. Semi-supervised methods, such as nearest neigh-\nbor contrastive learning and temporal relation prediction,\nefficiently utilize both labeled and unlabeled data, improv-\ning the quality of representations for downstream tasks like\nclassification (Kim et al. 2024; Fan et al. 2021). Unsuper-\nvised methods focus on learning robust representations with-\nout relying on labels, often leveraging contrastive learning\ntechniques and innovative data augmentations to capture\nkey temporal patterns (Franceschi, Dieuleveut, and Jaggi\n2019; Lee, Kim, and Son 2024). Attention mechanisms\nand domain-adaptive techniques further enhance the inter-\npretability of encoded features, aligning them more closely\nwith human intuition and domain-specific insights (Lyu et al.\n2018). However, this strategy faces two challenges: first,\nlabeling criteria for time-series data is often vague, which\ncan significantly impact model performance; second, the en-\ncoded data remain vast, unintuitive, and difficult to interpret\n(Ye and Ma 2023; Hill et al. 2022).\nIn this work, we focus on time-series data characterized\nby irregular discrete values. Extending the methods intro-\nduced in (Capstick et al. 2024), we present preliminary re-\nsults of a second-order representation learning method de-\nsigned to aid in clustering, identifying similar clinical cases,\nand uncover patients' interpretable behavioral patterns. This\nis achieved through a large language model encoding com-\nbined with a two-dimensional vectors representation and\ntransfer pattern analysis."}, {"title": "Our Contribution", "content": "We propose an integrated approach for discovering latent\nstates of activity. This method comprises several key steps:\n1. Temporal Data Preprocessing: The raw temporal data\nis first preprocessed to remove noise and standardize the\ndata for consistency.\n2. Language Model Encoding: A language model is\ntrained on our dataset to encode the preprocessed tem-\nporal data into high-dimensional vector representations.\nTo enhance the model's learning capability, we perform\npseudo labeling using one-hot similarity. This allows the\nmodel to better capture temporal dependencies and pat-\nterns in the data.\n3. Dimensionality Reduction and Clustering: To visual-\nize the high-dimensional embeddings, we apply dimen-\nsionality reduction techniques such as t-SNE to project\nthe data into a 2D space. Clustering algorithms are then\nused to identify distinct latent states within the data.\n4. Transition Pattern Analysis with PageRank: By defin-\ning a transition matrix between these low-rank latent\nstates, we use the PageRank algorithm to analyze transi-\ntion patterns. This approach compresses complex tempo-\nral data into interpretable, low-rank state vectors, allow-\ning us to determine the influence and significance of each\nstate within the transition graph and provide insights into\npatient behavior dynamics.\nThis analytical framework will aid in the clinical diagno-\nsis of patients and support the development of personalized\ncare programs. The availability of dataset and code for this\nwork is discussed in appendix."}, {"title": "Related Work", "content": "Time-series forecasting is primarily to predict future val-\nues based on previously observed data points. Traditional\nstatistical methods, most notably the Autoregressive Inte-\ngrated Moving Average (ARIMA) model, have long been\nutilized due to their mathematical simplicity and flexibil-\nity in application (Rizvi 2024; Kontopoulou et al. 2023).\nWhile ARIMA remains a staple for scenarios where data ex-\nhibits linear patterns, recent developments in machine learn-\ning have introduced sophisticated models capable of cap-\nturing non-linear dependencies, thus offering potential im-\nprovements in forecasting accuracy and robustness (Masini,\nMedeiros, and Mendes 2023; Rhanoui et al. 2019).\nThe advent of the Generative Pre-trained Transformer\n(GPT) by OpenAI marked a significant milestone in the field\nof natural language processing (Brown et al. 2020), catalyz-\ning a wave of innovations in large language models (LLMs).\nLarge Language Models (LLMs) have profoundly trans-\nformed natural language processing and are increasingly be-\ning considered for diverse applications beyond text, such as\ntime series data analysis. The study by (Bian et al. 2024)\npresents a framework that adapts LLMs for time-series rep-\nresentation learning by conceiving time-series forecasting\nas a multi-patch prediction task, introducing a patch-wise\ndecoding layer that enhances temporal sequence learning.\nSimilarly, (Liu et al. 2024) propose a model which lever-\nages the autoregressive capabilities of LLMs for time series\nforecasting. In Capstick et al. (2024), the authors apply a\nGPT-based text encoder to string representations of in-home\nactivity data to enable vector searching and clustering. Us-\ning a secondary modelling stage, we extend these ideas to\nenable further analysis and interpretability.\nPageRank, originally developed to rank web pages, is\nan algorithm designed to assess the importance of nodes\nwithin a directed graph by analyzing the structure of links\nwithin networks (Page et al. 1999). While it was initially\ncreated for search engines, its application has since ex-\npanded across various disciplines. For instance, in biolog-\nical networks, (Iv\u00e1n and Grolmusz 2011) employed person-\nalized PageRank to analyze protein interaction networks,\nproviding scalable and robust techniques for interpreting\ncomplex biological data. Similarly, (B\u00e1nky, Iv\u00e1n, and Grol-\nmusz 2013) introduced an innovative adaptation of PageR-\nank for metabolic graphs. This cross-disciplinary applica-\ntion of PageRank highlights its potential for analyzing com-\nplex systems beyond its original domain."}, {"title": "Methods", "content": "Mathematical Foundations of the Model\nGiven a discrete data sample $X = {X_1, X_2, ..., X_n}$, the fol-\nlowing steps describe the transformation process:\n1. Sampling and Text Conversion: Each sample $x_i$ is\nconverted into a text representation $T(x_i)$.\n2. Language Model Encoding: A pre-trained language\nmodel $f_{LM}$ is applied to obtain high-dimensional vector em-\nbeddings for the text data:\n$h_i = f_{LM}(T(x_i)), h_i \\in R^d$.\n3. Dimensionality Reduction: The high-dimensional\nembeddings are projected into a 2D space using a dimen-\nsionality reduction method $\\Pi$, such as t-SNE:\n$z_i = \\Pi(h_i), z_i \\in R^2$.\n4. PageRank and Deep State Vector Extraction: A tran-\nsition matrix $P$ between points in 2D space is constructed,\nand the PageRank algorithm is applied to further reduce the\ndimensionality:\n$v_i = PageRank(P), v_i \\in R^k, k \\ll d$.\nThe final low-dimensional vectors $v_i$ capture deep seman-\ntic relationships from the original data."}, {"title": "The Dataset", "content": "We obtained a dataset collected from 134 people diag-\nnosed with dementia, capturing their home location move-\nment data between July 1, 2021, and January 30, 2024. The\ndataset records the time entering different rooms and sleep-\ning mats, alongside clinical metrics such as MMSE (Kur-\nlowicz and Wallace 1999), ADAS-Cog (Kueper, Speechley,\nand Montero-Odasso) scores from regular tests. It also in-\ncludes details on various factors such as demographic data,\ncomorbidities, and other medical information. The dataset\ncontains a total of 66,096 recording days. A more detailed\ndescription of the dataset is provided in Appendix. After ex-\ncluding patients with missing data, the final dataset used for\nfurther analysis contained 50 participants with complete in-\nformation."}, {"title": "Our Framework", "content": "Our framework consists of several key stages: data prepro-\ncessing and encoding, latent state discovery, and transition\npattern analysis.\nFirst, we preprocess the raw temporal data to remove\nnoise and ensure consistency. This process is illustrated in\nFigure 2. We then utilize the all-MiniLM-L12-v2 model\n(Muennighoff et al. 2023) as the language model encoder.\nThis model excels at capturing similarities in textual infor-\nmation, making it suitable for analyzing similarities between\nrecorded dates and uncovering potential relationships. We\nfine-tune the model using its pretrained weights to adapt to\nthe specific characteristics of our dataset. The preprocessed\ntemporal data is then encoded into 384-dimensional vector\nrepresentations, capturing the inherent temporal dependen-\ncies and patterns within the data.\nGiven the unlabeled nature of our temporal data, we adopt\na cluster-based contrast sample selection method and triplet\nloss for training and evaluation. Further details on the lan-\nguage model training process are described in Appendix.\nTo visualize and interpret the high-dimensional embeddings,\nwe apply the t-SNE dimensionality reduction technique\n(van der Maaten and Hinton 2008) to project the data into\na 2D space. K-means clustering is then employed to iden-\ntify distinct latent states within the data. As the data points\nare temporally ordered, this 2D map allows us to visualize\neach participant's latent activity map as their movement pat-\ntern projected onto a specific dimension. Finally, we define\na transition matrix between the different latent states and ap-\nply the PageRank algorithm (Page et al. 1999) to analyze the\ntransition patterns, as is shown in Figure 3, details of this al-\ngorithm are available in Appendix. In this study, we present\na scalable approach to analyze vast amounts of temporal data\nin patient movement behavior. Consider a single participant\nwith continuous, complete data collected over a three-month\nperiod. Given that the passive infrared (PIR) sensors record\ndata in seconds, the approximate dataset size would be 3 x\n30 \u00d7 86,400 = 7,776,000 sparse records for a single individ-\nual. Such a data volume is infeasible for direct analysis by\nhuman experts and would require extensive computational\nresources to process with most machine learning models.\nOur method addresses this challenge by transforming this\nhigh-dimensional dataset into a low-dimensional, semanti-\ncally interpretable representation. Specifically, through our\ntwo-stage encoding and PageRank-based dimensionality re-\nduction, we compress the data into a latent state vector of\nlength five. Each element in this vector is not only compu-\ntationally efficient but also carries interpretable semantic in-\nformation, facilitating transparent and personalized insights\ninto patient behavior dynamics. This approach exemplifies\nthe application of low-rank structures to manage and inter-\npret complex temporal datasets in healthcare AI, supporting\npersonalized intervention strategies."}, {"title": "Experiments", "content": "After clustering the text vectors of the test set using K-\nmeans, we identified the optimal clustering result at 5\nclusters, suggesting five latent states across all single-day,\nsingle-participant behavioral patterns. Figure 4 shows the\nclustering results after the dimension reduction of the em-\nbeddings using t-SNE. By examining the transformation of\nindividual vectors in two dimensions, we can visualize the\nbehavioral trajectories of different participants within the\nembedding space (see appendix for more participant visu-\nalizations). Collaborating with clinical experts, we can ex-\nplore the semantics represented by these clusters and their\nrelationship to patient medical characteristics.\nMore significantly, by applying the random walk model\nand the PageRank algorithm to these two-dimensional plots,\nin combination with clinical expert opinions and diagnos-\ntic results, we can quantitatively assess the deeper semantics\nrepresented by the vector clusters, or latent states. Figure 5\npresents a multi-period heatmap analysis, segmented across\nfive time intervals to visualize patient behavior dynamics.\nThe top row of heatmaps illustrates the PageRank values in\ndifferent latent states (1-5) for each participant over time,\nwith each interval representing a period of three months. The\nintensity of color in each cell reflects the PageRank value for\na particular state and participant, highlighting shifts in domi-\nnant latent states and revealing periodic patterns in behavior.\nThis aggregation reduces the high-dimensional behavioral\ndata to a low-rank, interpretable representation. The bottom\nrow of the heatmaps shows the cosine similarity matrices\nbetween the participants for each respective time interval.\nThese matrices indicate how similar participants' behaviors\nare to each other within each period, with higher similarity\nvalues shown in darker shades. The block patterns visible in\nsome intervals suggest clustering tendencies among partici-\npants with similar behavioral patterns. The heatmap analysis\nreveals distinct behavioral patterns among participants, with\ncertain individuals demonstrating notable stability and peri-\nodicity in their daily activity states. For example, several par-\nticipants consistently show high PageRank values for spe-\ncific latent states (such as state 2 or 3) across multiple time\nintervals. This stability may indicate regular lifestyle pat-\nterns or consistent routines, which can be critical for predict-\ning daily behavior and planning personalized interventions.\nIn contrast, some participants exhibit significant shifts in\ntheir PageRank values between periods, particularly around\nseasonal transitions or specific time frames (e.g., August-\nOctober 2022 and May-July 2023). These variations may re-\nflect seasonal effects or environmental changes influencing\npatient behavior, underscoring the need to account for time-\nrelated factors when designing personalized monitoring and\nintervention strategies. The cosine similarity heatmaps re-\nveal clusters of participants who display high similarity in\nbehavior during certain intervals (e.g., May-July 2023 and\nAugust 2023-January 2024), forming identifiable groups.\nThis similarity may suggest shared behavioral characteris-\ntics or similar health conditions between these participants,\npossibly due to common lifestyle factors, environmental in-\nfluences, or comparable stages in disease progression. These\ngroup-level patterns provide information on cohort-based\nbehavioral dynamics, supporting the development of indi-\nvidualized and group-based healthcare management strate-\ngies.\nBased on the clustering and SHAP analyses of PageRank-"}, {"title": "Conclusion", "content": "In conclusion, our initial results demonstrate that by ap-\nplying our framework, we show that our latent states vec-\ntor based on patient daily activity patterns can be useful\nfor exploring behavior dynamics. While these findings of-\nfer a promising approach to exploring the relationship be-\ntween behavior and clinical characteristics, further research\nis needed to refine the model and validate its broader appli-\ncations, including potential use in medical data augmenta-\ntion."}]}