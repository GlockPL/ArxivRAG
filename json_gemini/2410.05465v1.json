{"title": "On the Expressive Power of Tree-Structured Probabilistic Circuits", "authors": ["Lang Yin", "Han Zhao"], "abstract": "Probabilistic circuits (PCs) have emerged as a powerful framework to compactly represent probability distributions for efficient and exact probabilistic inference. It has been shown that PCs with a general directed acyclic graph (DAG) structure can be understood as a mixture of exponentially (in its height) many components, each of which is a product distribution over univariate marginals. However, existing structure learning algorithms for PCs often generate tree-structured circuits or use tree-structured circuits as intermediate steps to compress them into DAG-structured circuits. This leads to the intriguing question of whether there exists an exponential gap between DAGs and trees for the PC structure. In this paper, we provide a negative answer to this conjecture by proving that, for n variables, there exists a sub-exponential upper bound $n^{O(logn)}$ on the size of an equivalent tree computing the same probability distribution. On the other hand, we also show that given a depth restriction on the tree, there is a super-polynomial separation between tree and DAG-structured PCs. Our work takes an important step towards understanding the expressive power of tree-structured PCs, and our techniques may be of independent interest in the study of structure learning algorithms for PCs.", "sections": [{"title": "Introduction", "content": "Probabilistic circuits (PCs) [7, 29], also commonly known as sum product networks (SPNs) [24], are a type of deep graphical model that allow exact probabilistic inference efficiently in linear time with respect to the size of the circuit. Like other deep models, the parameters of a PC can be learned from data samples [38]. Because of these desirable properties, they have been increasingly applied in various contexts, including generative modeling [35], image processing [2, 34], robotics [30], planning [25] and sequential data including both textual and audio signals [6, 23]. Compared with deep neural networks, the sum and product nodes in PCs admit clear probabilistic interpretation [36] of marginalization and context-specific statistical independence [3], which opens the venue of design-ing efficient parameter learning algorithms for PCs, including the expectation-maximization (EM) algorithm [12], the convex-concave procedure (CCCP) [38], and the variational EM algorithm [37].\nPerhaps one of the most important properties of PCs is that they can be understood as a mixture of exponentially (in its height) many components, each of which is a product distribution over univariate marginals [38]. Intuitively, each sum node in PC can be viewed as a hidden variable that encodes a mixture model [36] and thus a hierarchy of sum nodes corresponds to an exponential number of components. This probabilistic interpretation of PCs has led to a number of interesting structure learning algorithms [1, 9, 13, 17, 22, 27]. However, almost all of the existing structure learning algorithms for PCs output tree-structured circuits, or use tree-structured circuits as intermediates to compress them into DAG-structured circuits. Because of the restricted structure of trees, such algorithms do not fully exploit the expressive power of PCs with general DAG structures, and often"}, {"title": "1.1 Our Contributions", "content": "In this work we attempt to answer the question above by leveraging recent results in complexity theory [11, 26, 33]. Our contributions are two-folds: an upper and lower bound for the gap between tree and DAG-structured PCs. In what follows we will first briefly state our main results and then introduce the necessary concepts and tools to tackle this problem.\nAn Upper Bound In Section 3, inspired by earlier works in Valiant et al. [33] and Raz and Yehudayoff [26], we show that, for a network polynomial that can be computed efficiently with a DAG-structured PC, there always exists a sub-exponentially-sized tree-structured PC to represent it. An informal version of our main result for this part is stated below.\nTheorem 1.1 (Informal). Given a network polynomial of n variables, if this polynomial can be computed efficiently by a PC of size poly(n), then there exists an equivalent tree-structured PC of depth O(log n) and of size $n^{O(log n)}$ that computes the same network polynomial.\nWe prove this result by adapting the proof in Raz and Yehudayoff [26]. Our construction involves two phases: Phase one applies the notion of partial derivatives for general arithmetic circuits to represent intermediate network polynomials alternatively, and construct another DAG-structured PC using those alternative representations; we will provide fine-grained analysis on the new DAG, such that its depth is O(log n) and its size is still poly(n). Phase two applies the standard duplicating strategy for all nodes with more than one parent to convert the new DAG into a tree. This strategy will lead to an exponential blowup for an arbitrary DAG with depth D, since the size of the constructed tree will be $n^{O(D)}$. However, note that the DAG constructed in the first phase has depth O(log n). Combining it with the duplicating strategy, we will be able to construct an equivalent tree-structured PC of size upper bounded by $n^{O(log n)}$, as desired.\nThe original algorithm in Raz and Yehudayoff [26] only reduces the depth to $O(log^2 n)$ due to their restriction on the graph of using nodes with at most two children. This restriction is not necessary for PCs, and by avoiding it, we show that the depth can be further reduced to O(log n) with a slight modification of the original proof in Raz and Yehudayoff [26].\nA Lower Bound In Section 4, we show that under a restriction on the depth of the trees, there exists a network polynomial that can be computed efficiently with a DAG-structured PC, but if a tree-structured PC computes it, then the tree must have a super-polynomial size. The following informal theorem states our main result for this part, which will be formally addressed in Section 4.\nTheorem 1.2 (Informal). Given n random variables, there exists a network polynomial on those n variables, such that it can be efficiently computed by a PC of size O(n log n) and depth O(log n), but any tree-structured PC with depth $o(log n)$ computing this polynomial must have size at least $n^{w(1)}$.\nOur result is obtained by finding a reduction to Fournier et al. [11]. We first fix an integer k and a network polynomial of degree $n = 2^{2k}$. To show that the polynomial is not intrinsically difficult to represent, i.e., the minimum circuit representing it shall be efficient, we explicitly construct a PC of depth O(log n) and size O(n log n). Next, suppose via a black box, we have a minimum tree-structured PC of depth $o(log n)$ computing this polynomial. After removing some leaves from that minimum tree but maintaining its depth, we recover a regular arithmetic tree that computes a network polynomial of degree $\\sqrt{n} = 2^k$. Moreover, as shown in [11], if an arithmetic tree with depth $o(log n)$ computes this low-degree polynomial, then the size of the tree must be at least $n^{w(1)}$. Our operations on the minimum tree PC must reduce its size; therefore, the original tree must have a larger size than $n^{w(1)}$, and this fact concludes our proof."}, {"title": "1.2 More Related Work", "content": "There is an extensive literature on expressive efficiency of network structures for PCs and probabilistic generating circuits (PGCs) [35], another probabilistic graphic model. Very recently, it was shown in"}, {"title": "Preliminaries", "content": "We first introduce the setup of probabilistic circuits and relevant notation used in this paper.\nNotation A rooted directed acyclic (DAG) graph consists a set of nodes and directed edges. For such an edge $u \\rightarrow v$, we say that u is a parent of v, and v is a child of u. We use $Ch(u)$ to denote the set of children of the node u. We say there is a directed path from a to b if there is an edge $a \\rightarrow b$ or there are nodes $u_1,\\cdots, u_k$ and edges $a \\rightarrow u_1 \\rightarrow \\cdot \\rightarrow u_k \\rightarrow b$; in this case, we say that a is an ancestor of b and that b is a descendant of a. If two vertices v and w are connected via a directed path, we call the number of edges in a shortest path between them as the distance between them, denoted by $dist(v, w)$. A directed graph is rooted if one and only one of its nodes has no incoming edges. A leaf in a DAG is a node without outgoing edges. A cycle in a directed graph is a directed path from a node to itself, and a directed graph without directed cycles is a DAG. For two disjoint sets A and B, we will denote their disjoint union by $A \\sqcup B$ to emphasize their disjointedness.\nClearly, each directed graph has an underlying undirected graph obtained by removing arrows on all edges. Although by definition, a DAG cannot have a directed cycle, but its underlying undirected graph may have an undirected cycle. If the underlying undirected graph of a DAG is also acyclic, then that DAG is called a directed tree. Every node in a directed tree has at most one parent. If two nodes share a parent, one is said to be a sibling of the other.\nProbabilistic Circuits A probabilistic circuit (PC) is a probabilistic model based on a rooted DAG. Without loss of generality, in our work, we focus on PCs over Boolean random variables. We first introduce the notion of network polynomial. For each Boolean variable X, we use the corresponding lower case alphabet x to denote the indicator of X, which is either 0 or 1; for the same variable, $\\bar{x}$ represents the negation. In many cases, we use $1:N$ to denote the index set $[N]$. A PC over Boolean variables $\\{X_1,\\ldots,X_n\\}$ computes a polynomial over the set of indicators $\\{x_1,\\ldots x_n, \\bar{x}_1,\\ldots,\\bar{x}_n\\}$; we will refer this polynomial as the network polynomial. In the network, the leaves are indicators of variables, and all other nodes are either sum or product nodes; a node that is not a leaf may also be called an internal node. Each internal node computes a polynomial already: a sum node computes a weighted sum of the polynomials computed by its children, and a product node computes the product of the polynomials computed by its children. A PC is said to be normalized if the weights of the outgoing edges from a sum node sum to one. It was shown in Zhao et al. [36] that, every unnormalized PC can be transformed into an equivalent normalized PC within linear time.\nTo represent valid probability distributions, a PC must satisfy two structural properties: decompos-ability and smoothness. To define them, we need to define the scope of a node, which is the set of variables whose indicators are descendants of that node. For a node v, if the indicator x of the variable X is one of descendants of v, then $X \\in scope(v)$; more generally, $scope(v) = \\bigcup_{v' \\in Ch(v)} scope(v')$."}, {"title": "Definition 2.1 (Decomposability and Smoothness).", "content": "A PC is decomposable if and only if for every product node v and any pair of its children $v_1$ and $v_2$, we have $scope(v_1) \\cap scope(v_2) = (\\emptyset)$. A PC is smooth if and only if for each sum node, all of its children have the same scope.\nIn this paper we restrict our attention to PCs that are both decomposable and smooth, since otherwise we can always transform a PC into an equivalent one that is both decomposable and smooth in quadratic time [36]. The degree of a monomial is the sum of the exponents of all its variables, and the degree of a polynomial f, denoted by deg(f) is the highest degree among its constituent monomials. A polynomial is said to be homogeneous if all of its monomials have the same degree. A PC is said to be homogeneous if all of its sum and product nodes compute a homogeneous polynomial. Later, we will show that decomposability and smoothness imply homogeneity, and vice versa with mild conditions. For a node v in a PC, we use deg(v) to denote deg($f_v$). As emphasized earlier, this paper investigates the quantitative relationship between a DAG and a tree, which are both PCs and represent the same probability distribution. To make the terminology uncluttered, we will call the former a DAG-structured PC, and the latter a tree PC. If a tree PC computes the same network polynomial as a DAG-structured PC, then the tree PC is said to be an equivalent tree PC with respect to that DAG-structured PC.\nUnless specified otherwise, we will use $\\Phi$ to denote the entire PC in consideration and f the network polynomial computed by the root. For each node v, the sub-network rooted at v is denoted by $\\Phi_v$ and the polynomial computed by v is $f_v$. The set of variables in $f_v$ is $X_v$, which is a subset of $\\{X_1,\\ldots, X_n\\}$. The size of the network $\\Phi$, denoted by $|\\Phi|$, is the number of nodes and edges in the network. The depth of $\\Phi$, denoted by $D(\\Phi)$, is its maximum length of a directed path.\nPartial Derivatives In the process of proving the upper bound, a key notion named partial derivative is frequently used and formally defined below.\nDefinition 2.2 (Partial Derivative). For two nodes v and w in a network $\\Phi$, the partial derivative of the polynomial $f_v$ with respect to the node w, denoted by $\\partial_w f_v$, is constructed by the following steps:\n1. Substitute the polynomial $f_w$ by a new variable y.\n2. Compute the polynomial computed by v with the variable y; denote the new polynomial by $f_v$. Due to decomposability, $f_v$ is linear in y.\n3. Define the partial derivative $\\partial_w f_v = \\frac{\\partial f_v}{\\partial y}$.\nObserve that the chain rule in calculus also holds for our notion here, and therefore leads to the two following facts:\n* Let v be a sum node with children $v_1$ and $v_2$, and the edges have weight $a_1$ and $a_2$, respectively, then by definition $f_v = a_1 f_{v_1} + a_2 f_{v_2}$. For any other node w, the partial derivative is $\\partial_w f_v = a_1 \\cdot \\partial_w f_{v_1} + a_2 \\cdot \\partial_w f_{v_2}$.\n* Similarly, let v be a product node with children $v_1$ and $v_2$, then $f_v = f_{v_1} \\cdot f_{v_2}$. For any other node w, we have $\\partial_w f_v = f_{v_1} \\cdot \\partial_w f_{v_2} + f_{v_2} \\cdot \\partial_w f_{v_1}$.\nThe partial derivative has been proven to be a powerful tool in the field of complexity theory and combinatorial geometry [14, 15]. Readers are welcome to refer Chen et al. [5] for more details and extensive background. \nArithmetic Circuits An arithmetic circuit, aka algebraic circuit, is a generalization of a probabilistic circuit. Such a circuit shares the same structure as a PC and also computes a network polynomial. If an arithmetic/algebraic circuit is a directed tree, then we call it an arithmetic/algebraic formula. In the proof of the lower bound, the notion of monotonicity of a formula is essential, whose definition relies on the concept parse tree.\nDefinition 2.3 (Parse Tree). A parse tree of a formula $\\Phi$ is a sub-formula of $\\Phi$ which corresponds to a monomial of f, the network polynomial computed by $\\Phi$. Parse trees of $\\Phi$ is defined inductively by the following process:\n* If the root of $\\Phi$ is a sum node, a parse tree of $\\Phi$ is obtained by taking a parse tree of one of its children together with the edge between the root and that child.\n* If the root of $\\Phi$ is a product node, a parse tree of $\\Phi$ is obtained by taking a parse tree of each of its children together with all outgoing edges from the root."}, {"title": "Definition 2.4 (Monotonicity).", "content": "An algebraic formula is monotone if the monomial computed by any of its parse trees has a non-negative coefficient in the network polynomial."}, {"title": "A Universal Upper Bound", "content": "In this section, we present our first main result, which provides a universal upper bound on the size of an equivalent tree versus a DAG-structured PC.\nTheorem 3.1. For any given DAG-structured PC over n variables and of size poly(n), there exists an equivalent tree-structured PC of size $n^{O(log n)}$ nodes and of depth O(log n), computing the same polynomial.\nAs discussed earlier, our constructive proof heavily relies on deeper properties of partial derivatives, and applying them to represent sub-network polynomials. Our strategy, inspired by Raz and Yehuday-off [26], will be efficient if the circuit being considered is a binary circuit, i.e. every node has at most two children. While such structure is rare for natural networks, we make the following observation, that an arbitrary PC can always be transformed to a binary one with a polynomial increase in size and depth. The proof and an illustrating figure will appear in Appendix A.\nLemma 3.2. Given a DAG-structured PC $\\Phi$, we may transform it into another DAG $\\Phi'$ that computes the same network polynomial and every node in $\\Phi'$ has at most two children. Moreover, the differences between the sizes and depths of $\\Phi'$ and $\\Phi$ are only in polynomial size.\nTherefore, for the remaining discussion in this section, we will assume without loss of generality, that a given PC is binary. During the conversion process towards a binary circuit, some intermediate nodes may be created to ensure no sum node is connected to another sum node and no product node is connected to another product node. The set of those intermediate nodes is denoted by 1, and will be present in our later discussions. Next, we present a key property of partial derivatives, which holds for any (including non-binary) PC.\nLemma 3.3. Given a PC $\\Phi$, if v and w are two nodes in $\\Phi$ such that $\\partial_w f_v \\neq 0$, then $\\partial_w f_v$ is a homogeneous polynomial over the set of variables $X_v \\setminus X_w$ of degree deg(v) \u2013 deg(w).\nThe next lemma tells that, given a product node, its partial derivative with another node with a restriction on degree can be expressed using its children.\nLemma 3.4. Let v be a product node and w be any other node in a PC $\\Phi$, and deg(v) < 2 deg(w). The children of v are $v_1$ and $v_2$ such that deg($v_1$) \u2265 deg($v_2$). Then $\\partial_w f_v = f_{v_2} \\cdot \\partial_w f_{v_1}$.\nTo construct the sub-exponential tree, the key is to compress many nodes with partial derivatives. Fundamentally, we will use the following results to show that such compression works because each node, and each partial derivative of any node with any other, can be more concisely represented using partial derivatives. The key question is to find eligible nodes, so that taking partial derivatives with respect to them will lead to compact expressions. Inspired by the observation in Raz and Yehudayoff [26], we define the following set $G_m$, which will be critical in our later process.\nDefinition 3.5. Given a PC $\\Phi$ and an integer m \u2208 N, the set $G_m$ is the collection of product nodes t in $\\Phi$ with children $t_1$ and $t_2$ such that $m < deg(t)$ and $max \\{deg(t_1), deg(t_2)\\} \u2264 m$.\nWith this set, we may choose a set of nodes as variables for partial derivatives for any node in a PC, and the following two lemmas respectively illustrate: 1) the compact expression of the sub-network polynomial $f_v$ for any node v in a PC; 2) the compact expression of $\\partial_w f_v$ given two nodes v and w with a degree restriction. It is easy to observe that $1 \\cap G_m = \\emptyset$.\nWe now present two key lemmas that will be central to the proof for the upper bound. Specifically, they spell out the alternative representations for the network polynomial of any node, and the partial derivative of any pair of nodes.\nLemma 3.6 ([26]). Let m \u2208 N and a node v such that $m < deg(v) < 2m$, then $f_v = \\sum_{t \\in G_m} f_t \\cdot \\partial_t f_v$.\nLemma 3.7 ([26]). Let m\u2208 N, and v and w be two nodes such that deg(w) < m < deg(v) < 2 deg(w), then $\\partial_w f_v = \\sum_{t \\in G_m} \\partial_w f_t \\cdot \\partial_t f_v$."}, {"title": "3.1 Construction of $\\Psi$, another DAG-structured PC with restriction on depth", "content": "Given a binary DAG-structured PC $\\Phi$ with n variables and poly(n) nodes, we explicitly construct a tree PC with size $n^{O(logn)}$ and depth O(log n). Specifically, the construction takes two main steps:\n1. Transform $\\Phi$ to another DAG-structured PC $\\Psi$ with size poly(n) and depth O(log n).\n2. Apply a simple duplicating strategy to further convert $\\Psi$ to a tree with size $n^{O(log n)}$ and the same depth of $\\Psi$.\nWe will later show that step two can be simply done. Step one, however, needs much more careful operations. Each iteration, starting from i = 0, again needs two steps:\n1. Compute $f_v$ for each node v such that $2^{i-1} < deg(v) \u2264 2^i$ using the compact expression illustrated earlier. We will show that, computing one such polynomial adds poly(n) nodes and increases the depth by at most two on $\\Psi$. This new node representing $f_v$ will be a node in $\\Psi$, denoted by $v'$.\n2. Compute all partial derivatives $\\partial_w f_u$ for two non-variable nodes u and w in $\\Phi$, such that u is an ancestor of w and $2^{i-1} < deg(u) - deg(w) \u2264 2^i$ and deg(u) < 2deg(w). Like those new nodes representing sub-network polynomials from $\\Phi$, this new node representing a partial derivative will also be a node in $\\Psi$, denoted by (u, w). We will show that computing a partial derivative with respect to each pair adds poly(n) nodes and increases the depth by at most two on $\\Psi$.\nThe process is summarized in Algorithm 1. Before presenting the construction, we first confirm the quantitative information of $\\Psi$, the output of the algorithm. The first observation is the number of iterations: The degree of the root of $\\Phi$ is n, so at most log n iterations are needed for the entire process. Each iteration only increases the size of the updated circuit by poly(n) and the depth by a constant number. Consequently, the final form of $\\Psi$ has size poly(n) and depth O(log n).\nWe now provide an inductive construction of $\\Psi$ starting from i = 0. After each step, it is necessary to verify the validity of the updated $\\Psi$. Although decomposability is easy to verify, smoothness is less straightforward. To tackle this, we argue that the final state of $\\Psi$ is homogeneous, i.e. every node in $\\Psi$ computes a homogeneous polynomial, and consequently $\\Psi$ is smooth due to the following lemma.\nLemma 3.8. If a decomposable PC contains n variables and computes a polynomial of degree n, then it is homogeneous if and only if it is smooth.\nIteration zero (i = 0): During this iteration, for the first step, we only need to consider nodes v such that 0.5 < deg(v) \u2264 1; the degree of any node must be an integer, so we must have deg(v) = 1, i.e. v represents an affine polynomial. Without loss of generality, we may assume all such affine nodes are sum nodes with strictly more than one child. Indeed, if a product node represents an affine"}, {"title": "3.2 Construction of the Sub-Exponential Tree", "content": "We conclude the proof of Theorem 3.1 in this section by transforming the newly constructed $\\Psi$ into a sub-exponential tree. The transformation is a simple application of the naive duplication strategy, which will be illustrated below. In summary, given a poly(n)-sized DAG, the size of the transformed tree directly depends on the depth of the original DAG.\nDuplication Strategy Given a DAG-structured PC of size V and depth D, a natural algorithm to a tree is that, if a node v has k > 1 parents, then duplicate the sub-tree rooted at v for k \u2212 1 times, and connect each duplicated sub-tree to a parent of v. Indeed this algorithm generates a tree computing the same function as the original DAG does, but in the worst case we have to duplicate the entire graph O(V) times and such iterative duplication may be executed for every layer from the first to layer D. Therefore, in the worst case, the final tree has size O($VD$).\nThe construction of $\\Psi$ shows that its size is O($n^3$) and depth is O(log n). Using the naive duplication, we obtain that the size of the final tree is $n^{O(log n)}$"}, {"title": "A Conditional Lower Bound", "content": "In this section, we present our second main result, which provides a lower bound on the tree complexity of a network polynomial given a restriction on the depth of the tree. Obtaining a lower bound for the problem of circuit complexity is in general a more difficult problem than obtaining an upper bound because one cannot achieve this goal by showing the failure of a single algorithm. Instead, one must construct a specific polynomial, and confirm that no algorithm can produce an"}, {"title": "Theorem 4.1.", "content": "Given an integer k > 1 and $n = 2^{2k}$, there exists a network polynomial $P \\in R[x_1,\\cdots,X_n, \\bar{x}_1,\\cdots,\\bar{x}_n]$ of degree $n = 2^{2k}$, such that any probabilistic tree of depth o(log n) = o(k) computing P must have size $n^{\u03c9(1)}$.\nNote that if the polynomial P is innately difficult to be represented by PCs, i.e., if it cannot even be represented efficiently by DAG-structured PCs, then separation is not shown. To show separation, P should be efficiently computed by a DAG-structured PC, but any tree-structured PC representing P must have a strictly larger size. Our next construction, described with more details in Algorithm 3, confirms a separation by constructing an efficient DAG-structured PC $P^*$ that computes P. This PC has size O(n log n) and depth 2k = 2log n, where k is the integer given in Theorem 4.1.\nProposition 4.2. The tree PC P* is decomposable and smooth."}, {"title": "Proof of Theorem 4.1.", "content": "The proof of Theorem 4.3 in Fournier et al. [11] uses the polynomial class H(k,r) as the hard polynomial Q in the statement, in particular, with r = 2, $n = 2^{2k}$ and d(n) = $\\sqrt{n} = 2^k$. Note that the depth of $\\Pi'$ is o(log d) = o(k), and the degree of $H(k,2)$ is d = $2^k$, so the conditions in the statement of Theorem 4.1 are indeed satisfied. Since $\\Pi'$ is obtained from $\\Pi$ by removing leaves, we obtain the following inequality that concludes the proof:\n$|\\Pi| > |\\Pi' \u2265 n^{\u03c9(1)}.$"}, {"title": "Conclusion", "content": "In this paper we have shown that given a network polynomial with n variables that can be efficiently computed by a DAG-structured PC, we can construct a tree PC with at most sub-exponential size and is no deeper than O(log n). On the flip side, we have also shown that there indeed exists a polynomial that can be efficiently computed by a poly(n)-sized PC without a depth restriction, but there is a super-polynomial separation if we restrict the depth of the tree to be o(log n). Our results make an important step towards understanding the expressive power of tree-structured PCs and show that an sub-exponential upper bound is possible. However, the lower bound is still largely open, and we have only shown a separation under a specific depth restriction. One potential direction for the future work are discussed below: although the upper bound $n^{O(logn)}$ is sub-exponential, it is still prohibitively large as n grows. The construction outputs a tree of depth O(log n), which would be considered as a shallow tree. Is it possible to further reduce the size of the tree, possibly in the cost of a larger depth?"}, {"title": "A Missing proofs in Section 3", "content": "In this section we provide the proofs of the lemmas and theorems that are not included in the main text. For better readability, we first restate the statements and then provide the proofs."}, {"title": "Proof of Lemma 3.2", "content": "Given a depth-D network with V nodes and E edges, we scan over all its nodes. If a sum node has more than two children, say $M_1,\\ldots, M_k$, then keep $M_1$ and create a product node, whose only child is an intermediate sum node. The intermediate sum node has two children: $M_2$ and another just created intermediate sum node. Keep going and until an intermediate sum node has $M_k$ as the only child.\nThe operation is the same if a product node has more than two children by just exchanging sum and product. Note that for one operation for a node with k children, the depth increases by 2(k-1), and 2(k-1) nodes and edges are added. Once we do the same for all nodes, the number of increased depth, nodes, and edges are upper bounded by\n$2 \\times \\left( \\sum_{N \\in V} (\\sum_{out-degree of node N if N has more than two children} - 2) \\right) 2V \u2264 2E \u2013 2V \u2208 O(E)$.\nIn fact, for depth, this upper bound is very conservative because, for example, if a node has three children, one of its children again has three children. After we operate on both of them, the depth increases by four only. A better upper bound is O(M) \u2264 O(V), where M is the maximum out-degree in the original network. It is easy to check that each child of the root computes the same polynomial as before, and so does the new network. Clearly, the new network is still decomposable and smooth if the original network is."}, {"title": "Proof of Lemma 3.3", "content": "Lemma 3.3. Given a PC I, if v and w are two nodes in \u03a6 such that $\\partial_w f_v \\neq 0$, then $\\partial_w f_v$ is a homogeneous polynomial over the set of variables $X_v \\setminus X_w$ of degree deg(v) \u2013 deg(w)."}, {"title": "Proof. Clearly,", "content": "$\\partial_w f_v \\neq 0$ implies that w is a descendant of v. We prove the statement by induction on L, the length of the longest directed path from v to w. If L = 0, i.e. w = v, then $\\partial_w f_v$ = 1 and the statement trivially holds. Suppose the statement is true for all L and now the longest distance from v to w is L + 1. We prove the statement by discussing two cases, whether w is a sum or product node.\nCase I: w is a sum node. We first assume w is a sum node, and its parent inside this particular path v \u2194 w is u, whose children are w and w'. We write $f_z$ as the polynomial if we substitute w with y, and $f_v$ as the polynomial if we substitute u with y. Note that if we write them as functions with respect to y, then $f_v(y) = f_v(y \\cdot f_{w'})$, and hence\n$\\frac{\\partial f_v}{\\partial_w} = \\frac{\\partial f_v(y)}{\\partial y} = \\frac{\\partial f_v(y \\cdot f_{w'})}{\\partial y} = \\frac{\\partial f_v(y \\cdot f_{w'})}{\\partial (y f_{w'})} \\cdot f_{w'} = \\partial_u f_v f_{w'}$.\nBy the inductive hypothesis, $\\partial_u f_v$ is a homogeneous polynomial over the set of variables $X_v \\setminus X_u$ of total degree deg(v) \u2013 deg(u), so $\\partial_u f_v$ must also be homogeneous, and its degree is deg($\\partial_u f_v$) +\ndeg($w'$) = deg(v)-deg(u)+deg($w'$) = deg(v)-deg(w)-deg($w'$)+deg($w'$) = deg(v)-deg(w), and it is over variables $(X_v \\setminus X_u) \\cup X_{w'} = (X_v \\setminus (X_w \\sqcup X_{w'})) \\cup X_{w'} = X_v \\setminus X_w$.\nCase II: w is a product node. Next, assume w is a product node. In this case, u is a sum node and deg(u) = deg(w) = deg(w'), and $X_u = X_w = X_{w'}$. Let the weight of the edge u \u2192 w be a, and the weight for u \u2192 w' be b. Then, $f_v(y) = f_v(ay + bf_{w'})$, and\n$\\frac{\\partial f_v}{\\partial_w} = \\frac{\\partial f_v(y)}{\\partial y} = \\frac{\\partial f_v(ay + bf_{w'})}{\\partial y} = a \\cdot \\frac{\\partial f_v(ay + bf_{w'})}{\\partial (ay + bf_{w'})} = a \\partial_u f_v$.\nClearly, by the inductive hypothesis, both $\\partial_u f_v$ and $\\partial_w f_v$ are homogeneous, and they have the same degree and set of variables. Specifically, deg($\\partial_w f_v$) = deg($\\partial_u f_v$) = deg(v) \u2013 deg(u) = deg(v) \u2013 deg(w), and $X_{w,v} = X_{u,v} = X_v \\setminus X_u = X_v \\setminus X_w$."}, {"title": "Proof of Lemma 3.4"}]}