{"title": "Multi-LLM-Agent Systems: Techniques and Business Perspectives", "authors": ["Yingxuan Yang", "Jun Wang", "Qiuying Peng", "Weinan Zhang"], "abstract": "In the era of (multi-modal) large language models, most operational processes can be reformulated and reproductionized using LLM agents. The LLM agents can perceive, control, and get feedbacks from the environment so as to accomplish the given tasks in an autonomous manner. Besides the environment-interaction property, the LLM agents can call various external tools to ease the task completion process. The tools can be regarded as a predefined operational process with private or real-time knowledge that does not exist in the parameters of LLMs. As a natural trend of development, the tools for calling are becoming autonomous agents, thus the full intelligent system turns out to be a multi-LLM-agent system (MLAS). This paper discusses the technical and business landscapes of MLAS. Comparing to the previous single-LLM-agent system, a MLAS has the advantages of i) higher potential of task-solving performance, ii) higher flexibility for system changing, iii) proprietary data preserving for each participating entity, and iv) feasibility of monetization for each entity. To support the ecosystem of MLAS, we provide a preliminary version of such MLAS protocol considering technical requirements, data privacy, and business incentives. As such, MLAS would be a practical solution to achieve artificial collective intelligence in the near future.", "sections": [{"title": "1 BACKGROUND AND TREND", "content": "The Internet ecosystem has evolved significantly, transitioning from traditional web applications to 5G networks. 5G technology has revolutionized network capabilities, enabling ultra-low latency communication, extensive device connectivity, and high-bandwidth data transmission [1]. This technological advancement has built a strong infrastructure that supports complex distributed systems and real-time applications, changing how applications interact within the network. The development of Large Language Models (LLMs) [45] marks a key advancement in artificial intelligence. These models have progressed from basic text processors to advanced systems that can reason, understand multiple forms of input, and make decisions independently [66]. The rise of AI agents powered by LLMs\u00b9 has further changed the landscape, introducing entities that can understand context, adapt to various tasks, and operate with greater autonomy [76, 78]. As a result, these AI agents demonstrate unprecedented abilities in task execution and problem-solving, marking a significant leap in AI applications.\nA key change in the AI landscape is the shift from basic tool usage to advanced agent interaction [37, 55]. Initially, LLMs were primarily employed as tools for specific tasks, such as text generation or analysis. Now, they have evolved into autonomous agents that can choose and use various tools independently. This change marks a shift from passive tool use to active agent-based problem-solving, where LLMs decide on tool selection based on context and needs.\nAnother significant development is the move from simple Internet connectivity to intelligent collaboration [12, 39]. Traditional Internet applications that rely on predefined protocols and APIs for communication, limiting the flexibility and adaptability of system interactions. With the rise of multi-LLM-agents, a new mode of collaboration has emerged. These agents can communicate, negotiate, and work together using natural language protocols. This change allows for more dynamic and intelligent interactions, leading to meaningful collaboration between intelligent entities.\nThe advent of multi-LLM-agents [9, 11, 12, 19-22, 24, 27, 33, 35, 39, 49, 64, 70, 72, 80] will introduce a new era of business: multi-LLM-agent system (MLAS). This paradigm will expand on traditional paradigms like SaaS, PaaS, and IaaS by integrating Al agent deployment and management with cloud computing principles. MLAS will enable applications to deploy specialized intelligent agents that collaborate with other agents while ensuring data privacy and security. Moreover, MLAS will include a marketplace for developers to monetize agents, while users can access and combine various agent services to suit their needs. The platform will be built on layered architecture, standardized communication protocols, and robust security mechanisms, promoting sustainable business frameworks and collaborative innovations.\nIncentivization via Monetization Mechanisms. Just like the Internet applications are highly incentivized to connect to the Internet, the agents in a MLAS are also highly incentivized based on monetization mechanism design. First, the experience data generated from interacting within a MLAS is crucial for training well-functional agents. In MLAS, the agents receive the task instructions from upstream agents, perform inner-agent reasoning and tool usage, send task instructions to downstream agents and acquire their returned information, and obtain the final task accomplishment results. Such"}, {"title": "2 KEY AI TECHNICAL ASPECTS", "content": "The architecture of LLM-based Al agents consists of several interrelated components essential for autonomous operation and intelligent interaction. At its core, this architecture is designed to effectively process inputs, maintain contextual relevance, make informed decisions, and generate appropriate responses.\nThe interaction wrapper serves as the principal interface through which the agent interacts with its environment and other agents. This component manages the flow of incoming and outgoing communications. It adapts to various input modalities, and standardizes them for internal processing. The interaction wrapper implements protocol-specific adaptations to ensure seamless integration with various communication standards. This approach preserves the internal consistency of the agent's operations.\nMemory management is pivotal to the architecture. It includes both short-term working memory and long-term episodic storage. The short-term memory buffer retains immediate context and recent interactions, facilitating conversational coherence. Meanwhile, the long-term memory system archives significant experiences and learned patterns, enabling the agent to adapt its responses based on historical interactions and enhancing decision-making capabilities in contextually rich scenarios.\nThe cognitive functionality of the architecture is currently underpinned by Chain-of-Thought (CoT) reasoning [67, 75]. This structured reasoning framework decomposes complex tasks into manageable logical steps, thereby facilitating clarity and thoroughness in problem-solving. The CoT mechanism enables the agent to articulate intermediate reasoning states, verify logical consistency, and engage in self-correction through a systematic analysis of its reasoning processes.\nAdditionally, to enhance the agent's operational capacity beyond natural language processing, the tool integration framework is necessary [37, 46, 55]. This subsystem discovers and registers tools, maps of parameters between natural language commands and tool APIs, monitors execution, handles errors, and interprets results. It ensures the effective integration of external functionalities into its decision-making processes.\nThe architecture also features a sophisticated routing mechanism that governs the connections with neighboring agents. This component is instrumental in facilitating dynamic neighbor discovery, making capability-based routing decisions, balancing loads across the agent network, and enforcing policy-based access control. Such networking capabilities are vital for ensuring efficient communication and collaboration within multi-agent systems.\nFurthermore, the architecture incorporates feedback loops that enable continuous learning and adaptation. These loops facilitate the processing of interaction outcomes, allowing the agent to update its internal models and refine its decision-making strategies based on experiential learning. The integration of these architectural elements not only establishes a robust foundation for the autonomous operation of MLAS but also significantly enhances their collaborative capabilities within multi-agent systems."}, {"title": "2.2 Mechanisms and Architectures of MLAS", "content": "As a multi-agent system, the design of mechanisms and architectures of a MLAS is crucial for its success. Roughly, according to the coordination form of a MAS, there are three major architectures of a MLAS.\nFirst, for fully centralized architectures, the whole system has full control of the engaged agents, which is a very high requirement, then centralized training with centralized execution methods can be used, and the agents will act with high coordination. In practice, such methods can be applied only when the agents are the applications developed over an OS-liked platform and grant the data and control access to the platform. Second, for decentralized architectures with global credit allocation, the whole system cannot fully control the engaged agents but can allocate credit to each one for each accomplished task, then centralized training with centralized execution methods can be applied. This is much more practical since each agent (and the entity behind it) does not have to grant the data or control access to the platform. Also, the platform can still incentivize the engaged agents to improve their collaboration performance by allocating credit to the team. Third, for fully decentralized architecture, i.e., there is no access to data or control for each engaged agent and no credit allocation for the platform, the agents in the system will need to find their own way to collaborate with others and improve themselves. In such a case, the mechanism design will be much important from the beginning."}, {"title": "2.3 Protocols of Agent Interaction", "content": "The Multi-LLM-Agent System (MLAS) framework necessitates sophisticated interaction protocols to facilitate effective agent collaboration. These protocols must bridge the gap between traditional structured formats and natural language understanding, addressing unique challenges posed by LLM-based agents' probabilistic decision-making and emergent capabilities [42].\nCore Challenges and Key Issues. The development of MLAS protocols presents several fundamental challenges in protocol effectiveness measurement, behavioral diversity optimization, and non-transitive interaction management."}, {"title": "Core Protocol Framework", "content": "We propose a comprehensive protocol framework consisting of five essential components: the instruction processing protocol, the message exchange protocol, the consensus formation protocol, the credit allocation protocol and the experience management protocol.\nThe Instruction Processing Protocol standardizes the interpretation of user instructions through structured parsing mechanisms and context-aware processing pipelines [4]. This protocol implements sophisticated disambiguation techniques to handle uncertain or incomplete instructions, maintaining consistency across multiple interaction rounds.\nThe Message Exchange Protocol establishes the foundation for inter-agent communication through standardized message formats and adaptive transmission mechanisms [59, 79]. This protocol dynamically switches between synchronous and asynchronous modes based on task requirements and system load, implementing priority-based routing algorithms to optimize message delivery under varying conditions.\nThe Consensus Formation Protocol implements distributed decision-making mechanisms through a combination of voting systems and negotiation frameworks [3]. This protocol adapts consensus thresholds dynamically based on task criticality and system state, ensuring robust decision-making while maintaining system responsiveness. When proposals conflict, agents can resolve disagreements through negotiation, ensuring that progress is still made despite differences in opinion. Voting protocols allow agents to express preferences and reach a decision even when full consensus is not achievable, thus preventing deadlocks and ensuring that tasks continue to progress.\nThe Credit Allocation Protocol addresses the challenge of fair contribution assessment through multi-level propagation mechanisms. Agents that participate in tasks receive corresponding credit based on their contributions [79]. By implementing task-specific metrics and performance-based distribution algorithms, this protocol ensures equitable reward allocation while incentivizing collaborative behavior.\nThe Experience Management Protocol facilitates collective learning through structured logging and pattern extraction mechanisms [77]. Each agent logs its experiences and learning outcomes during task execution. These experience records may include successes, failures, the effectiveness of strategies used, and interactions with other agents. This protocol implements cross-agent knowledge sharing algorithms, enabling systematic improvement of system performance through accumulated experience.\nThe effectiveness of MLAS depends on the seamless integration of these protocols, as illustrated in Figure 2. The hierarchical organization enables dynamic protocol selection and efficient resource utilization, while maintaining system scalability."}, {"title": "2.4 Agent Training Methods", "content": "In MLAS, each agent has the incentive to improve itself in order to get more credits assigned to them from the platform. In terms of \"agent training\", we mean the methods of improving the agent's performance, including tuning-free methods and parameter-tuning methods.\nTuning-free Methods. In the field of LLM agents, tuning-free methods are strategies to improve performance without modifying model parameters. These methods are beneficial when direct parameter tuning is costly or impractical. Key tuning-free methods include:\n\u2022 Prompt Engineering: Prompt engineering involves designing specific input prompts to elicit desired responses from LLM agents. By carefully structuring prompts, agents can align more closely with task requirements without any parameter adjustments [5].\n\u2022 Few-Shot Learning: Few-shot learning provides limited examples within the prompt, helping the agent understand new tasks. In zero-shot learning, models tackle tasks solely through natural language instructions, leveraging pre-trained knowledge. Both approaches enable flexibility and adaptability in multi-agent environments [50, 75, 78].\n\u2022 External Tool Utilization: Agents can enhance their capabilities by interacting with external tools or APIs. Using external resources, such as databases or calculators, allows agents to perform complex tasks without additional model training [46, 55].\nThese tuning-free methods are particularly valuable in MLAS. They enable agents to adapt quickly and work together on complex tasks in dynamic environments, supporting smooth collaboration with minimal computational costs.\nParameter-tuning Methods. To directly tune the parameters of the LLMs behind each agent, the alignment methods and multi-agent reinforcement learning methods can be used. First, the alignment methods for tuning LLMs are generally based on supervised learning loss based on the target output or the preference of the experts. Directly fitting the experts' output corresponds to the behavioral cloning methods in agent imitation learning [48], while training over the experts' preference pairs improves the agent's policy in a learning-to-rank manner [51]. Such a kind of method has not been much utilized in a multi-agent task as the alignment target is not clearly formulated in such a scenario. Second, multi-agent reinforcement learning (MARL) is a key method for training agent policy in a multi-agent system, which formulates the task as a multi-agent sequential decision-making problem [7]. Here, we mainly consider cooperative MARL methods as, in general, the agents are organized to pursue team success, i.e., to fulfill the user's task. According to the form of agent coordination in training and execution, MARL methods can be divided into three major categories, namely i) centralized training with centralized execution [61, 68], ii) centralized training with decentralized execution [41, 53], and iii) decentralized training and execution [62, 63]."}, {"title": "2.5 Attacks and Defenses in MLAS", "content": "As MLAS systems handle sensitive data and critical operations, their security is a top concern. The distributed nature of MLAS introduces unique vulnerabilities beyond those of single-LLM systems. Malicious actors can target not only individual agents but also exploit inter-agent communications and collective decision-making processes. This section examines the attacks against MLAS and the defense mechanisms, with a focus on their implications in multi-agent systems.\nAttack Surface and Vulnerabilities. MLAS face three main types of attacks.\nFirst, prompt injection attacks manipulate input prompts to trick models into generating harmful responses. These attacks are particularly dangerous in MLAS, where compromised agents can propagate malicious prompts across the system. Recent work [81] show how slight changes in input phrasing can bypass defenses, while research [40] demonstrate how system prompts can be modified using escape characters and context omission.\nSecond, memory and data poisoning attacks target the knowledge bases that agents use for decision-making. In MLAS, poisoned data can affect multiple agents simultaneously. Research shows how contaminated knowledge bases in retrieval-augmented generation (RAG) systems can cause cascading errors throughout the agent network [73]. Other study highlights how poisoned training samples with specific triggers can compromise fine-tuned agents, impacting system reliability [74].\nThird, model inversion and extraction attacks aim to reconstruct training data or extract model details through targeted queries. Analysis indicates that these attacks are particularly effective in MLAS, where attackers responses from multi-agents to enhance extraction efficiency [43]. The risk of data leakage is especially high for systems handling sensitive personal or commercial data, as shown by recent work on prompt-based vulnerabilities [57].\nDefense Mechanisms and Future Directions. Several defense strategies have been proposed to counter these attacks, each addressing specific vulnerabilities in MLAS environments.\nInput sanitization techniques, such as prompt randomization and query encapsulation, help neutralize prompt injection attacks. One work demonstrate the effectiveness of these methods in MLAS contexts, though they may introduce communication overhead [54]. An improved approach involves adaptive delimiter strategies that maintain communication efficiency [26].\nPerplexity-based filtering is another promising defense. Several researches show that monitoring model perplexity can detect adversarial prompts without compromising model utility [2, 29]. In MLAS, this method can be enhanced by cross-validating perplexity scores across agents, though careful calibration is required to avoid false positives during legitimate interactions.\nAdversarially robust fine-tuning has also proven useful for enhancing MLAS security. A dual-model approach, where adversarial samples are generated and validated during training, offers significant benefits [44]. Further optimization focus on balancing robustness and utility, making these techniques particularly valuable for MLAS by enabling system-wide application while preserving agent specialization [71].\nDespite these advances, challenges remain in securing MLAS. Current defenses often struggle with the dynamic nature of agent interactions, where complex communication patterns can trigger false positives. Additionally, the computational overhead of comprehensive security measures can affect system performance, requiring a balance between security and efficiency.\nLooking ahead, several research directions are crucial. First, there is a need for standardized security evaluation frameworks for MLAS that account for individual agent vulnerabilities and system-wide risks. Second, developing lightweight security measures that maintain communication efficiency is an open challenge. Finally, adaptive defense mechanisms that evolve with emerging threats will be essential for long-term security.\nTo ensure the safe deployment of MLAS, future research should focus on a holistic approach that combines robust model architectures, effective training procedures, and dynamic defense mechanisms. This will be critical for maintaining public trust as MLAS systems continue to grow in complexity and impact."}, {"title": "3 KEY BUSINESS ASPECTS", "content": "Drawing from our research on MLAS, we present our vision of its business implications across three critical dimensions: privacy preservation, traffic monetization, and intelligence monetization. We anticipate how MLAS could reshape business paradigms and explore the potential trajectories of its commercial applications."}, {"title": "3.1 Privacy Preservation in MLAS", "content": "The rise of MLAS introduces new privacy challenges that go beyond those of traditional multi-agent systems. Unlike conventional agents, which exchange structured data, LLM agents handle rich, contextual information that may contain sensitive data embedded in natural language conversations, reasoning processes, and knowledge representations. Privacy preservation in MLAS is critical because these systems process natural language data, which can inadvertently leak sensitive information through semantic connections and implicit knowledge representations.\nPrivacy-Preserving Challenges. We identify three distinct levels of privacy concerns that require systematic analysis and novel solutions:\n\u2022 At the semantic level, the challenge lies in LLMs' natural language processing, which may inadvertently reveal sensitive information through contextual associations and semantic connections. Traditional privacy mechanisms, designed for structured data, are insufficient for handling such complex information, especially against attacks that exploit semantic vulnerabilities.\n\u2022 At the agent interaction level, the continuous exchange of information between agents introduces privacy risks. Sensitive information can be exposed not only through direct content but also through behavioral patterns and response characteristics. Additionally, maintaining conversation history and context windows in each agent creates persistent vulnerabilities over time.\n\u2022 At the system architecture level, the distributed nature of MLAS complicates the enforcement of privacy guarantees across all components while maintaining system efficiency. The dynamic interactions between agents and their evolving knowledge further challenge the implementation of robust privacy protections.\nPrivacy-Preserving Technologies. Recent research has explored various technologies to address privacy challenges, ranging from cryptographic techniques to system-level solutions.\nAt the foundational level, Homomorphic Encryption (HE) [13] enables secure computation on encrypted data, supporting private agent-to-agent communication and inference. While promising in privacy-preserving machine learning [23] and secure data sharing [10], HE's computational complexity remains a significant challenge in MLAS.\nSecure Multi-Party Computation (SMPC) [38] enables secure collaborative computation among multiple agents. SMPC has been used in privacy-preserving data analysis [34] and collaborative learning [31] in traditional multi-agent systems, but scaling this technology to large MLAS remains known.\nFor system-level protection, Trusted Execution Environments (TEEs) [15] provide hardware-based security guarantees. Technologies such as Intel SGX [15], ARM TrustZone [47], and AMD SEV [56] create secure enclaves for sensitive computations. However, integrating TEEs into MLAS requires careful consideration of security and performance trade-offs.\nAdditionally, Differential Privacy (DP) [16] offers mathematical methods for privacy-preserving data analysis. While effective for protecting sensitive information in collaborative tasks, DP faces unique challenges in natural language processing, such as managing privacy budgets and preserving utility.\nResearch Directions and Open Challenges. Advancing privacy preservation in MLAS involves addressing several key issues. First, existing privacy metrics do not fully capture the complexities of semantic information leakage in natural language processing. There is a need for MLAS-specific privacy frameworks that account for both direct and indirect information flows in semantic spaces. Second, integrating privacy-preserving technologies across MLAS requires a unified approach that combines data protection, secure computation, and communication security. Performance optimization and scalability remain major hurdles, especially as agent networks expand, and maintaining privacy while enabling efficient collaboration is critical. Future research should focus on creating comprehensive privacy frameworks tailored to MLAS. This includes standardizing privacy protocols, developing efficient implementations, and establishing evaluation metrics to ensure the practical deployment of privacy-preserving MLAS systems."}, {"title": "3.2 Traffic monetization", "content": "Traffic Monetization in MLAS involves generating commercial value by managing user traffic and optimizing ads, using the strengths of various agents. This includes improving traffic flow, boosting click-through rates (CTR), and increasing conversion rates (CVR) [32]. MLAS leverages each agent's capabilities to enhance user engagement and make advertising strategies more effective. The system also ensures fair and transparent revenue allocation. This section explores Traffic Monetization in MLAS, covering business scenarios, revenue models, profit allocation, and the roles of application agents.\nBusiness Scenarios and Revenue Generation. In MLAS, agents analyze user behaviors and preferences to optimize traffic management and deploy targeted advertisements. Through real-time data analytics, agents identify the most relevant ads to engage users, thereby enhancing click-through rates (CTR) and conversion rates (CVR). This approach builds user profiles and uses intelligent recommendation systems to personalize ads, boosting engagement and driving purchases. Revenue in MLAS mainly comes from advertising, using Cost Per Click (CPC) and Cost Per Action (CPA) models [30]. In the CPC model, advertisers pay based on clicks, with agents earning commissions based on their contribution to traffic management and ad effectiveness. In the CPA model, payments are made for completed purchases, rewarding agents who drive conversions with a higher share of the revenue. In addition to advertising, income can be generated through user subscriptions for premium features or personalized services within specific applications, such as advanced analytics dashboards or exclusive access to specialized tools. These monetization strategies work together, with agents optimizing traffic flow, user engagement, and ad targeting to drive overall profitability.\nProfit Allocation Mechanisms. Converting revenue into profits that are fairly distributed among agents is key to Traffic Monetization. The process starts by assessing each agent's contribution to traffic generation, ad clicks, and conversions, using metrics like CTR and CVR to quantify individual impact. To ensure fairness, MLAS may use blockchain-based smart contracts to automate the distribution process, minimizing bias and human error. Additionally, a scoring system rates agents based on their performance, including factors like user feedback and engagement. Agents with higher scores receive a larger share of revenue, incentivizing better performance and continuous optimization. Attribution methods, such as the Shapley Value, ensure profits are allocated based on each agent's contribution to the system [58]. Dynamic adjustment mechanisms allow real-time updates to revenue shares based on agent performance and market conditions, ensuring fair compensation for optimizing traffic and ads. Incorporating metrics like CPM (Cost Per Mille) adds a more nuanced approach to revenue allocation, offering a deeper understanding of ad performance beyond just clicks and conversions [6].\nRoles of Application Agents. Different types of application agents play distinct yet interrelated roles in Traffic Monetization. Advertising agents manage and deploy advertisements, using data analytics to optimize ad performance and increase user engagement. They select the best ad placements and adjust strategies based on real-time data and user behavior. Data analysis agents analyze user behavior, providing insights that help advertising agents refine ad strategies and improve content. These agents help create accurate user profiles and identify emerging trends to make advertising more effective. Transaction agents handle user purchases, ensuring smooth transactions and tracking conversions. They link sales performance to specific ads, helping advertisers improve future campaigns and boost conversion rates (CVR). Subscription agents manage premium services, offering personalized features and contributing additional revenue streams. These agents also contribute to long-term user engagement by enhancing retention and loyalty, supporting sustained revenue growth.\nTraffic Monetization in MLAS creates a system where revenue is generated and shared through the collaboration of different agents. By improving traffic management, optimizing ads, and ensuring fair distribution, MLAS makes sure all agents benefit fairly. Future research should focus on improving attribution models like the Shapley Value to make profit allocation even fairer. Adding metrics like CPM will also help allocate revenue more accurately and improve monetization strategies."}, {"title": "3.3 Intelligence Monetization", "content": "Intelligence Monetization in Multi-LLM-Agent Systems represents a significant evolution in Al commercialization by leveraging the collaborative capabilities of specialized agents. Unlike traditional single-model paradigms, multi-agent systems enable dynamic interactions among specialized agents, each designed to address specific tasks, thereby facilitating the creation of more versatile and robust intelligence solutions. This paradigm has shown promise in various applications, as exemplified by Microsoft's Copilot Studio Platform, launched on November 19, 2024. The platform supports an ecosystem of over 1,800 large models and offers open APIs and integration tools, enabling enterprises to incorporate agent technology into workflows and applications for enhanced customization and scalability [65].\nRevenue Generation through Data-Driven Services. A key revenue model in Intelligence Monetization within MLAS is the sale of data-driven services [18, 25, 60, 65]. Specialized agents analyze distinct datasets-such as consumer preferences, product usage, and market trends-to generate actionable insights. These insights are delivered in the form of reports, forecasts, or tailored recommendations that businesses can purchase. For instance, one agent may provide personalized user behavior insights to enhance marketing, while another offers market trend analysis to guide strategic planning. By integrating specialized agents, MLAS offers a broad range of insights, which can be monetized through subscription models or one-time reports. In practice, successful implementations like OpenAI's GPT-4 API [45] have demonstrated how multiple specialized models can work in concert, with distinct agents handling different aspects of the intelligence pipeline. These include specialized agents for data processing and preprocessing, deep pattern recognition and insight generation, recommendation transformation, and platform integration.\nInnovative Licensing and Agent Marketplaces. MLAS also introduces novel licensing approaches that move beyond traditional software licensing. One of the most prominent is the Agent-as-a-Service (AaaS) [52], as seen in Google Cloud's AutoML, which enables dynamic agent deployment based on computational needs, with usage-based pricing and automatic scaling [14]. Complementing this will be the emergence of agent marketplace platforms, creating ecosystems for third-party agent development and deployment, as demonstrated by Hugging Face's model hub adapted for deployment of LLMs [17]. Furthermore, hybrid deployment architectures will become increasingly popular, combining on-premise agent deployment for sensitive operations with cloud-based agents for scalable tasks, as seen in IBM's Watson services which use distributed agent architecture [28].\nIntelligence Monetization within MLAS offers a sustainable revenue framework by harnessing the collective intelligence of specialized agents. Looking ahead, as demand for AI-driven insights grows, MLAS's role in delivering scalable, actionable intelligence will continue to expand. Future developments should focus on enhancing agent collaboration for real-time insights and adapting to emerging business models and industries, offering tailored solutions to meet specific needs."}, {"title": "3.4 Integration of 3 Business Aspects", "content": "The three key business aspects of MLAS form an interconnected framework that drives both commercial success and ethical operation. Data privacy ensures trust and compliance while allowing secure data usage. This foundation supports traffic monetization by generating user engagement data while adhering to privacy regulations. Intelligence monetization transforms these privacy-preserved interactions into actionable insights and services. As MLAS evolves, maintaining a balance between privacy, commercial success, and technological progress will be critical for long-term sustainability. Future development should focus on strengthening these connections while adapting to evolving privacy regulations and market demands."}, {"title": "4 CASE STUDY", "content": "Building on the technical foundations and business considerations of MLAS, we now delve into real-world implementations to illustrate how these theoretical frameworks are realized in practice.\nThrough carefully selected case studies, we explore how different architectural choices influence system efficiency, data privacy, and monetization capabilities. These examples not only validate our theoretical insights but also shed light on the challenges and opportunities inherent in deploying MLAS solutions."}, {"title": "4.1 Architectures in MLAS", "content": "The implementation of MLAS in real-world applications reveals various architectural patterns, each designed to address specific operational requirements and constraints.\nAs we analyze current MLAS deployments, we observe that architectural choices significantly influence system capabilities, from privacy protection to operational efficiency. Figure 4 illustrates four fundamental patterns that have emerged in practice:\n\u2022 Star Architecture: In this structure, a central agent coordinates communication with all other agents [20, 27, 49, 70, 72]. This centralized control model works well when one agent is responsible for task distribution and overall orchestration.\n\u2022 Ring Architecture: Agents are arranged in a circular configuration, each communicating with its predecessor and successor [9, 36]. This decentralized structure supports sequential task processing, ensuring each agent has a specific role in the task pipeline.\n\u2022 Graph Architecture: This network allows for a fully interconnected system where each agent can communicate directly with any other agent [11, 80].This architecture creates a fully or non-fully interconnected network where each agent can communicate with their neighbors. It provides maximum flexibility and redundancy, allowing multiple communication pathways to support complex interactions.\n\u2022 Bus Architecture: This structure uses a fixed workflow or Standard Operating Procedure (SOP), where tasks are sent to a central bus, which then distributes them to the appropriate agents or processes [21, 33, 35, 64]. The bus ensures a clear input-output mechanism and a structured flow of tasks in a sequential manner."}, {"title": "4.2 A Decentralized Star Architecture in MLAS", "content": "Figure 5 and Figure 6 present our first case study of MLAS implementation in a music service scenario. The system uses a centralized architecture where several agents, including a Personal Agent, an Orchestrator Agent, and a Song Agent, collaborate to process user's music playback requests. In this setup, the Orchestrator Agent acts as a central hub, managing communication and coordinating tasks among the agents.\nHowever, this centralized approach means that all agents must send their data, including sensitive user information, through the Orchestrator Agent to complete tasks. While efficient for coordination, this design creates potential privacy and security risks since user data passes through multiple agents.\nTo address these privacy concerns, we propose a modified decentralized Star Architecture, illustrated in Figure 7 and Figure 8 through a travel booking scenario. In this new design, the Orchestrator Agent still coordinates tasks but avoids directly handling sensitive data. Instead, specialized agents, like the Navigation Agent or Ticket Agent, process their tasks independently and interact directly with user data when needed. This setup reduces privacy risks while maintaining system efficiency.\nIn the decentralized architecture, the Orchestrator Agent focuses on breaking down user instructions into smaller tasks and deciding the order of task execution. It stays uninvolved in sensitive data processing and only reconnects when tasks are completed or additional coordination is required. Each specialized agent handles its specific tasks within its own data domain, ensuring privacy and security.\nA fair credit allocation system, as shown in Figure 6 and Figure 8, managed by the Transaction Logger, ensures that all agents receive appropriate rewards based on the tasks they complete and the resources they use. This credit allocation approach improves data protection and system security while keeping operations efficient."}, {"title": "5 CONCLUSION & FUTURE", "content": "In this paper, we provide our analysis on the future development of multi-LLM-agent systems (MLAS) from the perspectives of techniques and business. Technically, compared to the traditional single-LLM-agent systems, MLAS has a higher potential for overall performance and system flexibility; and commercially, MLAS brings the feasibility of proprietary data preservability and monetization through traffic and intelligence, which essentially incentivizes various entities to contribute to the whole ecosystem. Several effective protocols for multi-agent communication and collaboration are developed in progress, which will drive the implementation of the MLAS ecosystem towards achieving artificial collective intelligence in the near future."}]}