{"title": "Explainable AI Methods for Multi-Omics Analysis: A Survey", "authors": ["Ahmad Hussein", "Mukesh Prasad", "Ali Braytee"], "abstract": "Advancements in high-throughput technologies have led to a shift from traditional hypothesis-driven methodologies to data-driven approaches. Multi-omics refers to the integrative analysis of data derived from multiple 'omes', such as genomics, proteomics, transcriptomics, metabolomics, and microbiomics. This approach enables a comprehensive understanding of biological systems by capturing different layers of biological information. Deep learning methods are increasingly utilized to integrate multi-omics data, offering insights into molecular interactions and enhancing research into complex diseases. However, these models, with their numerous interconnected layers and nonlinear relationships, often function as black boxes, lacking transparency in decision-making processes. To overcome this challenge, explainable artificial intelligence (xAI) methods are crucial for creating transparent models that allow clinicians to interpret and work with complex data more effectively. This review explores how xAI can improve the interpretability of deep learning models in multi-omics research, highlighting its potential to provide clinicians with clear insights, thereby facilitating the effective application of such models in clinical settings.", "sections": [{"title": "1 Introduction", "content": "Omics is a broad field that involves the analysis of biological information interactions across different omes, such as genomics, proteomics, transcriptomics, metabolomics, and microbiomics [20]. Genomics is the most established among omics fields, it focuses on identifying genetic variations linked to disease, treatment response, or patient prognosis in medical research[20] . Transcriptomics involves studying gene transcription and transcriptional"}, {"title": "2 Background", "content": ""}, {"title": "2.1 Overview on Multi-Omics Deep Learning Methods", "content": "Deep learning (DL) approaches leverage integrated Multiomics data to improve accuracy and efficiency in biomarker discovery and patient stratification [3, 15]. DL models have been successfully employed to classify cancer types based on gene expression patterns and methylation data, identify biomarkers associated with survival rates, and develop tools for cancer type classification using somatic mutations. Integrating multiple omics datasets allows for a more comprehensive understanding of disease mechanisms and facilitates the development of personalized treatment strategies tailored to individual patients' molecular backgrounds [15]. DL is a subset of machine learning that uses artificial neural networks (ANNs), which are inspired by biological neural networks. It has the ability to learn features accross several layers. DL is increasingly recognized as a powerful approach for encoding and learning from heterogeneous and complex data, in both supervised and unsupervised settings. DL methods have made significant advancements in various artificial intelligence challenges and are increasingly being applied in biomedical research, particularly in omics data analysis. DL have demonstrated superior performance in terms of sensitivity, specificity, and efficiency compared to previous methods, particularly in overcoming challenges such as low signal-to-noise ratios and large datasets with a high number of variables. Moreover, with DL algorithms different omics layers and other sources of information, such as medical images or clinical health records can be integrated. This integration of big data analysis is driving the implementation of personalized medicine approaches, enabling early disease detection, classification, and personalized therapies tailored to each patient's biochemical background [27]."}, {"title": "2.2 Overview of Explainable Artificial Intelligence Methods", "content": "The high dimensionality of omics data and the emergence of advanced AI, ML, and DL approaches has generated opaque black box models, prompting researchers to turn to explainable artificial intelligence (xAI) for analyzing"}, {"title": "3 Methodology", "content": "The review was conducted using a set of relevant keywords Figure(4a), such as \"Multi-omics,\" \"xAI,\" \"Explainable,\" \"Deep Learning,\" \"Omics,\" \"Genomics,\" \"Cancer,\" and \"Biomarkers. The keywords was searched across multiple academic databases, including Google Scholar, Springer Link, IEEE, and ScienceDirect. More than 600 papers were returned. The papers were screened by keywords and titles, narrowing them down to 300. These 300 papers were further screened based on their titles and abstracts. From these, 22 studies were selected based on inclusion criteria, which required the use of an omics or multi-omics framework combined with explainable AI (xAI) methods. The selected papers were then analyzed qualitatively to extract insights and conclusions pertinent to the"}, {"title": "4 Review of Explainable Al Methods for Multi-Omics", "content": ""}, {"title": "4.1 Model Agnostic Approaches", "content": ""}, {"title": "4.1.1 SHAP Shapley additive explanations", "content": "Shapley values are based on coalitional game theory, where the feature values of a data instance act as players in a coalition, and Shapley values tell us how to fairly distribute the prediction among the features [40]. SHAP explains the prediction of an instance x by computing the contribution of each feature to the prediction. Shapley values provide explanations by assigning a value called weight to"}, {"title": null, "content": "each feature for a particular prediction. SHAP considers all possible predictions, using all possible combinations of inputs, to guarantee consistency and local accuracy. KernelSHAP and TreeSHAP are two variants of SHAP; KernelSHAP is a model-agnostic approach based on LIME and Shapley values concepts, while Tree SHAP computes exact SHAP values for decision tree-based models [38]. The SHAP explanation is specified by the formula:\n\n$\\Phi_{i} = \\sum_{s\\subseteq d\\backslash\\{i\\}} \\frac{s!(d-s - 1)!}{|d|!} [F_{s\\cup\\{i\\}} (x_{s\\cup\\{i\\}}) - F_{s}(x_{s})] $.\n\nIt represents the SHAP value for feature i, indicating its contribution to the prediction for the instance x . d is the set of all features in the dataset, and s is a subset of d excluding feature i. GradientSHAP is an xAI method implemented based on Shapley values. It approximates the Shapley value by computing an expectation of gradients over a distribution of baselines. This implementation extends the concept of IntegratedGradients from utilizing a single baseline to utilizing several baselines sampled over a distribution and computing an expectation of gradients for them. GradientSHAP is defined as:\n\n$GSi(x) = \\int_{x'\\sim p_B} \\bigg[ (x_i - x'_i) \\int_{\\alpha=0}^{1} \\frac{\\partial F(x' + \\alpha(x - x'))}{\\partial x_i} d\\alpha \\bigg] p_B(x') dx'$\n\nThis formula represents the GradientSHAP value for feature i in instance x, x\" is the baseline sample, is the input sample and F is the neural network model [30, 38, 40].\nSHAP have been incorporated into several multi-omics investigation studies table 2, each with distinct ap- proaches. In a study [30] aimed at uncovering important DNA methylation biomarkers for non-small cell lung cancer (NSCLC) classification, an xAI-guided deep learning network was developed. The framework consists of two blocks: Block A for NSCLC instance classification using a model that combines an autoencoder with a feed-forward neural network with methylation data as input, and Block B for biomarker discovery using various xAI methods including IntegratedGradients, GradientSHAP, and DeepLIFT to eventually identify a set of 7 significant biomarkers. The datasets used for experimentation were generated by the TCGA Research Network, specifically for NSCLC classes, and were extracted from LinkedOmics and cBioportal portals. The set of discovered biomarkers was evaluated for their classification performance, clinical efficacy, and association with biological pathways. The model's performance was assessed using 10-fold cross-validation to ensure the robustness and reliability of the results, with accuracy as the primary metric. Another study [31] introduced XL1R-Net; an Explainable AI-driven improved L1-regularized deep neural architecture for NSCLC biomarker identification. It is a novel approach designed to identify clinically relevant biomarkers for NSCLC, distinguishing between its"}, {"title": null, "content": "major subtypes, LUAD and LUSC. The model utilizes gene expression data, focusing on copy number variations (CNVs) as input. The xAI methods used include IntegratedGradients, GradientSHAP, and DeepLIFT, to compute the contribution score of each gene. The model successfully identified twenty biomarkers, with nine overlapping with existing literature and seven novel NSCLC-relevant biomarkers discovered. The identified biomarkers show potential for targeted drug development and significant relevance in predicting patient survival. The model demonstrates superior classification performance for subtype classification of NSCLC instances compared to standard neural networks and achieves a state-of-the-art classification accuracy of 84.95% in subtyping NSCLC into its primary subtypes LUAD and LUSC.\nXAI-CNV Marker is a proposed framework to discover robust biomarkers for breast cancer subtypes [51], the framework identified CNV biomarkers linked to enriched pathways and prognostic capabilities and achieved a 5-fold cross-validation classification accuracy comparable to state-of-the-art methods. The framework utilizes deep learning for breast cancer classification, it consists of two main sub-modules: an autoencoder for data compression and a feed-forward classifier for cancer subtype classification. The xAI part of the framework incorporates a discovery algorithm that employs various explainable models including Gradient Input, Integrated Gradient, Epsilon Layerwise Relevance Propagation, DeepLIFT, and SHAP, for interpreting the model's decisions and identifying relevant biomarkers. Gene set analysis, survival analysis, and draggability analysis was applied to establish the clinical relevance of the identified biomarkers, in addition, the identified biomarkers was validated on an independent cohort (METABRIC dataset) to confirm their efficacy in distinguishing breast cancer subtypes .\nAutoGGN [34] is another framework that integrates omics data with molecular networks to enhance classification tasks. The framework underwent evaluation across three classification tasks: single-cell embryonic stage, pan- cancer type, and breast cancer subtyping, demonstrating superior performance compared to other methods. The framework utilized several datasets, including the TCGA Breast Cancer Subtype dataset, which comprised data from 396 patients with overlapping feature data and subtype information; the TCGA Pan-cancer dataset, consisting of 5780 patient samples with both gene expression and somatic mutation profiles across 24 cancer types; and a Mouse Single-cell Transcriptomes dataset, containing single-cell RNAseq profiles from 116,312 single cells across 10 developmental stages of mouse embryos, with a final dataset containing 10,000 single-cell samples. SHAP was employed for feature importance estimation, highlighting the crucial features for the classification tasks.\nA study [3] aiming to stratify cancer patients into high-risk and low-risk groups using multi-omics integration utilized a multi-omics feature learning framework with three main components: feature extraction, tensor analysis, and risk prediction. Autoencoders were employed for dimensionality reduction, followed by fusing the processed data into a tensor using the CP decomposition method to facilitate the extraction of interpretable latent factors. The risk prediction aspect of the framework employed classification for tumor purity prediction in breast cancer datasets and clustering for stratifying cancer risk groups based on integrated multi-omics data, including SCNV, miRNA, RNAseq, and methylation. Clustering methods were evaluated using survival analysis, and SHAP was utilized to understand the contribution of biomarkers to the latent variables of omics data. Additionally, t-SNE was employed to visualize the latent variables extracted from the multi-omics data to aid in identifying clusters of samples with similar latent variable values. The study focused on Breast Invasive Carcinoma and Glioma datasets, as they contained more than 600 clinical samples, making them suitable for analysis. The proposed framework outperformed MOFA \u2013 A framework for unsupervised integration of multi-omics datasets - in terms of statistical significance and clustering accuracy.\nThe presented models encounter several limitations that affect their performance and generalizability. These include the small number of samples in some omics datasets as well as the complexity of biological systems which poses challenges in capturing the heterogeneity of all biological processes. Moreover, the limited biological interpretation in such studies which focuses primarily on computational aspects necessitates further research to interpret the biological significance. Issues related to demographic variations and potential biases in the datasets,"}, {"title": null, "content": "particularly concerning the under representation of certain ethnic groups, may hinder the applicability of the model's findings across diverse populations. The \"black-box\" nature of deep learning models presents challenges in comprehensively understanding decision-making processes, despite efforts to incorporate explainable AI (XAI) tools. Dependency on high-quality data for training, concerns regarding data availability and privacy, as well as challenges associated with model complexity and interpretability, further constrain the models' utility and accessibility. While promising results are observed in specific classification tasks, the ability of the models to generalize across diverse biological datasets and conditions remains to be fully evaluated."}, {"title": "4.1.2 LIME Local Interpretable Model-Agnostic Explanations", "content": "LIME is an open-source framework aimed at illuminating the decision-making processes of machine learning models, thereby fostering trust in their utilization. Its \"local\" nature involves analyzing specific instances rather than providing a broad explanation for the model's behavior. It explains how a particular instance is categorized. Being \"interpretable\" implies that users should grasp the model's operations. For example, in image classification, it reveals which parts of an image influence predictions, while with tabular data, it highlights influential features. \"Model-Agnostic\" denotes its applicability to any black-box algorithm, past or future, disregarding whether the model's internal workings are transparent, it treats all models as black boxes. The term \"explanations\" refers to the output generated by the LIME framework. LIME is designed to interpret the decision-making processes of machine learning models across various data types and can effectively provide explanations for complex deep learning models by focusing on the neighbourhood of a specific instance [11, 40]. A framework for radiomics to predict Radiation Pneumonitis (RP) [53], a radiation-induced chest irritation, utilized radiographic images from 122 patients undergoing chest radiotherapy for various thoracic malignancies. Different Gradient Boosting Machines (GBMs) such as XGBoost, LightGBM, and CatBoost were used, and PyRadiomics, a Python package designed for analyzing radiographic images, was employed for feature extraction."}, {"title": "4.1.3 PDP and ALE", "content": "A Partial Dependence Plot (PDP) illustrates the marginal effect that a feature set S has on the predicted outcome of a machine learning model. It helps to identify whether the relationship between the target and a feature is linear, monotonic, or more complex. PDPs work by marginalizing the model's output over the distribution of features in set C, allowing the function to reflect the relationship between the features in set S and the predicted outcome. This marginalization process results in a function dependent solely on the features in S, encompassing interactions with other features. The partial function reveals the average marginal effect on the prediction for given values of features in S. A key assumption of PDPs is that the features in C are not correlated with those in S; if this assumption is violated, the calculated averages may include unlikely or impossible data points, thus distorting the PDP. The partial dependence function $f_{x_s} (x_s)$ is estimated using the following formula:\n\n$\\frac{1}{n} \\sum_{i=1}^{n} f(x_s, x_c^{(i)}).$\n\nthe partial dependence function shows the average predicted outcome when the features in S are fixed at specific values $x_s$, while the other features (in set C) vary over their marginal distribution [40]. Accumulated Local Effects (ALE) plots describe how features influence the prediction of a machine learning model on average. ALE plots are a faster and unbiased alternative to Partial Dependence Plots (PDPs). They provide a robust method for interpreting the influences of predictors in machine learning models. ALE plots focus on calculating the average change in the model's prediction as a feature varies, while averaging out the effects of other features. This approach addresses the limitations of PDPs by not assuming independence between features, thus avoiding biased interpretations in the presence of correlated predictors. ALE plots visualize and clarify feature interactions and their impact on model predictions, especially in scenarios involving high-dimensional data spaces, like multi-omics [63]. In a study [42], QLattice, a symbolic-regression-based algorithm, was applied to Proteomics Alzheimer's disease data. The dataset was split, allocating 80% for training and 20% for testing. From the QLattice analysis on the training partition, the ten best unique models were derived. The best model was then selected based on the lowest Bayesian Information Criterion (BIC) score, indicating the best balance of model complexity and fit. This chosen model incorporates MAPT (tau protein), age at CSF collection, and LILRA2 as inputs, using addition operations to estimate the probability of Alzheimer's disease (AD) in patients. Notably, MAPT, a known AD biomarker, emerged as a consistent variable in the highest-scoring models from the QLattice, though other features varied among the models. A Partial Dependence Plot (PDP) was used to analyze the influence of MAPT on AD risk, showing how changes in MAPT levels alone could predict changes in AD risk, independent of interactions with other features. Another study [14] focusing on paediatric neuroblastoma, the MYCN gene amplification-known to indicate aggressive tumour behavior and poor survival-was examined using CT-based morphologic and radiomics features. Six morphologic and 107 quantitative gray-level texture radiomics features were extracted from volumes of interest manually outlined in the imaging data. The final predictive model utilized the eXtreme Gradient Boosting (XGBoost) algorithm. To interpret the influence of predictive features within this model, Accumulated Local Effects (ALE) plots were employed to provide insights into how each variable influenced the prediction of MYCN amplification status. ALE plots revealed that having more than six image-defined risk factors (IDRF) was associated with a higher probability of MYCN amplification, highlighting the utility of ALE plots in uncovering complex relationships within high-dimensional imaging data."}, {"title": "4.1.4 Permutation Feature Importance", "content": "PermFIT is a permutation-based feature importance method designed to identify significant features in machine learning models. It is a computationally efficient method as model refitting is not needed when it is employed. PermFIT calculates feature importance scores by assessing the expected increase in prediction errors when the values of a feature are permuted, thus indicating the feature's impact on the model's outcome. PermFIT [59] utilizes various visualization techniques such as bar plots and heat maps to output the calculated feature importance scores. PermFIT is characterized by enhanced statistical robustness and valid statistical inference as it does not require prior knowledge of feature distributions and incorporates permutation tests with cross-fitting. In a study [59] utilizing PermFIT for the identification of important biomarkers for complex diseases via machine learning models, datasets such as Reverse Phase Protein Arrays (RPPA) Data from three kidney cancer studies in The Cancer Genome Atlas (TCGA), HITChip Atlas Microbiome Data employed for studying the human intestinal tract microbiome, TCGA Kidney Cancer Data specifically analyzed for identifying important features associated with kidney cancer and BMI Levels from HITChip Atlas. PermFIT was implemented across (DNN, RF, SVM) models to estimate and test the feature importance. It outperformed existing feature selection methods, demonstrating its robustness and effectiveness. PermFIT's performance improvement is restricted by the inherent limitations of the machine learning models it is applied to, such as RF's inefficiency in modelling interaction terms, and its effectiveness in deciphering complex genetic architecture may be limited for traits with strong gene-gene interactions due to the underlying model's capabilities."}, {"title": "4.2 Model Specific Approaches", "content": ""}, {"title": "4.2.1 Attention Mechanisms", "content": "Attention mechanisms mimic our brain's way of focusing on specific things while ignoring others. In deep learning, they facilitate the processing of large amounts of information by focusing on the most important parts. Attention is becoming a key part of explaining how computers explain images, understand languages, and make decisions. By using attention, deep learning models can enhance their performance across various tasks by effectively managing the information to which they attend, thereby improving efficiency and accuracy. Attention mechanisms are usually categorized based on four criteria, as shown in table 3 [62]."}, {"title": null, "content": "Attention mechanisms were utilized in various multi-omics studies table 2, MultiGATAE [17] is a novel cancer subtype identification method using multi-omics data and attention mechanisms. Eight TCGA Datasets were used for experiments, the study focused on various cancer types, including kidney renal clear cell carcinoma (KIRC), breast invasive carcinoma (BRCA), colon adenocarcinoma (COAD), skin cutaneous melanoma (SKCM), glioblastoma multiforme (GBM), lung squamous cell carcinoma (LUSC), liver hepatocellular carcinoma (LIHC), and ovarian serous cystadenocarcinoma (OV). The developed model employs a graph autoencoder network alongside K-means clustering for subtype identification. MultiGATAE constructs a similarity graph from multi-omics data, which is then processed by a graph autoencoder network consisting of a graph attention network and an omics- level attention mechanism to derive embedding representations. Subsequently, K-means clustering is applied to these embeddings to identify cancer subtypes. According to the model authors, MultiGATAE demonstrates superior performance in identifying distinct subtypes with varying survival outcomes across multiple cancer datasets and outperforms state-of-the-art methods in this task. MOGLAM [13] is another framework for disease"}, {"title": null, "content": "classification task. The model takes in mRNA expression, DNA methylation, and miRNA expression data from KIPAN dataset for kidney cancer type classification, SCC dataset for pan-cancer classification and BRCA dataset for breast invasive carcinoma. It consists of three modules: dynamic graph convolutional network with feature selection (FSDGCN), multi-omics attention mechanism (MOAM), and omic integrated representation learning (OIRL). FSDGCN Learns optimal omic-specific embedding information while identifying important biomarkers. MOAM Adapts the attention mechanism to assess the importance of embedding information from different omics, enabling the model to emphasize more relevant omics data for downstream classification tasks. OIRL uses common and complementary information between different omics data types, aiming to enhance the model's classification performance by integrating multi-omics data in a more meaningful way. The model's performance was evaluated using accuracy (ACC), average F1 score weighted by support (F1weighted), and macro-averaged F1 score (F1macro), performance was compared against eight other methods, showing superior results in terms of ACC and F1 scores on the used datasets.\nMOMA [33] is a multi-task attention learning algorithm designed for the interpretation and classification of multi-omics data. It focuses on identifying disease-related biological pathways through multi-omics module analysis and classification. The model comprises three stages: building a module for each omic dataset, highlighting important modules across omics data using module attention, and multi-task learning for each dataset. MOMA aims to provide interpretability alongside performance which is crucial in biology and medicine for accurate decision-making related to diagnosis and treatment. It can predict phenotypes and detect modules containing genes related to phenotypes by utilizing a module attention matrix to identify the most relevant modules for a specific phenotype. When compared with other models, it demonstrates robust performance and good generalization even in the presence of heavy noise . The Multi-omics Fusion Graph Attention Network (MFGAN) [35] integrates multiple omics data for survival and drug response prediction in digestive system tumors (DST). It employs the Graph Transformer (GT) for learning new graph structures and the Graph Attention Network (GAN) to extract features from omics data. Additionally, it incorporates the View Correlation Discovery Network (VCDN) to combine omics data features. The model uses omics data from TCGA and GDSC databases, including gene expression, DNA methylation, and copy number variation and predicts survival risk and drug response. Evaluation via 5-fold cross-validation, with a focus on mean AUC and AUPR scores, demonstrates improved performance compared to other methods.\nThe methods discussed exhibit several limitations inherent to the analysis of cancer omics data. These include challenges related to sample size, potential bias introduced by excessive clustering, and the lack of differentiation in node weights affecting feature relevance. Additionally, issues arise from unspecified omics types, potentially compromising the model's efficiency to consider correlations between omics data types. Furthermore, limitations such as the \"curse of dimensionality,\" reliance on labelled data, and performance dependency on data quality and completeness are noted. While the models offer advancements, concerns persist regarding their complexity, accessibility, and interpretability, as well as variations in performance across different cancer types, feature selection oversights, and dataset scale constraints. Future efforts aim to address these limitations by incorporating additional omics data types and expanding dataset scales for improved generalization."}, {"title": "4.2.2 Class Activation Mapping", "content": "Class Activation Map (CAM) [10, 38] is an explanation method suitable for convolutional neural networks with global average pooling. It enables CNNs to perform object localization, alongside classification, without the need for bounding box annotations. CAM highlights the discriminative region of the input image to identify its class, utilizing activation maps of the last convolutional layer to train linear classifiers for each class and estimate the final class. The important image regions for prediction are identified by projecting the weights of the output layer onto the convolutional feature map. CAM requires retraining linear classifiers for each class, making it time-consuming. Gradient-weighted CAM (Grad-CAM) is a proposed method aimed at reducing the time complexity of CAM. Grad-CAM is suitable for any convolutional neural network"}, {"title": null, "content": "architecture and utilizes the gradients of the target feature flowing into the final convolutional layer to visualize the class activation maps. Additionally, it highlights the important regions in the input image of the selected feature. However, it's noteworthy that Grad-CAM may fail in localizing objects with multiple occurrences of the same class.\nOmics-CNN [5] is a Convolutional Neural Network-based framework designed for high-throughput omics data classification. The study utilizes one transcriptomics and one proteomics dataset, along with clinical and demographic data, which include various characteristics such as age, BMI, pre-existing medical conditions, and laboratory measurements like C-reactive protein (CRP), absolute neutrophil count, and D-dimer. The objective is to develop diagnostic models and identify biosignatures for Ischemic Stroke (IS) and COVID-19 infection. The framework integrates dimensionality reduction, preprocessing, clustering, and explainability techniques. To tackle the high-dimensional nature of omics data, both univariate and multivariate techniques for dimensionality reduction are employed. The preprocessing pipeline involves normalization of datasets from different sources to generate a consistent expression matrix. Architecturally, the Framework comprises convolutional layers, pooling layers for input down-sampling, dense layers for learning complex feature relationships, and a softmax activation function for class prediction. Gradient Weighted Class Activation Mapping (GW-CAM) analysis is applied to identify the most important features for classification, aiding in the discovery of diagnostic biomarkers. Notably, the framework demonstrates high accuracy in identifying biosignatures for Ischemic Stroke and COVID-19, achieving accuracies of 96% and 95.41%, respectively. Another novel approach is DeepInsight-3D [4], designed to predict patient-specific anticancer drug responses from multi-omics data by employing data-to-image conversion for CNN application. The framework converts multi-layered tabular omics data into corresponding images, which are organized and coloured before being fed into a CNN for automatic feature extraction and analysis. DeepInsight-3D provides a methodological basis xAI, facilitating the identification of biologically relevant gene sets and the discovery of functional annotations important for classifications, aligning with known pathways and mechanisms in cancer and drug resistance. Utilizing patient-derived xenograft (PDX) datasets, including multi-omics profiles such as gene expression, copy number alterations (CNA), and somatic mutations, the model's performance was evaluated on seven datasets from The Cancer Genome Atlas (TCGA) and PDX, showcasing its capability in analyzing complex multi-omics data. Additionally, training and test datasets were constructed from Genomics of Drug Sensitivity in Cancer (GDSC) and TCGAPDX, resulting in more than seven datasets for comprehensive testing and validation of the model's predictive capabilities. The model architecture employs manifold techniques for data transformation alongside hull algorithms for mapping elements to pixel locations. It incorporates Class Activation Mapping (CAM) for identifying gene activation regions and an element decoder for isolating a subset of genes and then uses CNN for automatic feature extraction and analysis of the constructed images. DeepInsight-3D's performance was compared against several benchmark methods, including MOLI, NMF, feed-forward net, and others, using AUC as a key metric, demonstrating its robustness to high dimensionality and complex relationships between variables.\nIn a study [6] utilizing CNN and CAM for head and neck cancer outcome prediction, the aim was to detect image patterns that might not be covered by a traditional radiomic framework and to enhance the performance of traditional radiomics. A CNN framework was designed for medical image analysis, with the dataset consisting of pre-treatment CT images from 106 patients, identical to that used in a benchmark study. Gradient Class Activation Maps (CAM) were employed to illustrate the areas of the tumour images that were most crucial for the model's decision-making, highlighted in red on the images. These maps were then combined with the original CT images to aid researchers and clinicians in understanding how the model interpreted the images to make predictions, providing a visual explanation of the model's thought process. The CNN model outputs included predictions on distant metastasis, loco-regional failure, and overall survival, with AUC values of 0.88, 0.65, and 0.70, respectively, demonstrating its capability to predict cancer treatment outcomes based solely on CT images. In addition to CAM, feature activation maps are used as tools to trace back the spatial location of regions responsible for"}, {"title": null, "content": "signature activation and to help in identifying the spatial-anatomical locations, enhancing interpretability in medical imaging. Activation maps have shown utility in differentiating histological subtypes of non-small cell lung cancer (NSCLC) by highlighting the importance of peritumoral regions in radiomics-based predictions [12].\nThe discussed studies face various limitations. The Omics-CNN framework, for instance, requires significant computational resources due to the large set of features in omics data. There is also a trade-off between model simplicity and performance when using multivariate dimensionality reduction methods. Furthermore, identi- fying meaningful biomarkers is challenging due to the complexity and noise inherent in omics data. Similarly, DeepInsight-3D faces constraints such as limited sample sizes, the complexity of anticancer drug response, and the need for sufficient training samples to achieve accurate estimations. These factors highlight potential challenges in practical applications. Furthermore, while Radiomics Feature Activation Maps offer interpretability benefits, they have several limitations. The model struggles to implement combination approaches for outcomes other than distant metastasis. Its reliance on a dataset of only 300 patients may limit generalizability. Training the model de novo without fully capturing the potential of transfer learning is another drawback. Moreover, the focus on pre-segmented tumor volumes simplifies the task but overlooks the variability in clinical segmentation."}, {"title": "4.2.3 Integrated Gradients and Layerwise Relevance Propagation (LRP)", "content": "Integrated Gradients is an attribution method used in Explainable AI to determine the importance of individual features in a model's prediction. It calculates the integral of the gradients of the model's output with respect to the input features, taken along a straight path from a baseline (usually a zero vector or a neutral input) to the actual input. This method provides a way to attribute the change in the model's prediction to the change in the input features, ensuring that the attributions are both complete and consistent. In multi-omics analysis, Integrated Gradients can be particularly useful for understanding the deep learning models used for the integration process by revealing how different input features contribute to the final prediction [41]. Layerwise Relevance Propagation (LRP) is an Explainable AI method used to decompose the prediction of a neural network by attributing the relevance of the prediction back through the layers to the input features. By propagating the prediction score backwards through the network, LRP redistributes the relevance from the output to the input using specific propagation rules that ensure the conservation of the total relevance. This method helps in understanding which features contribute most to the prediction, offering insights into the decision-making process of complex Deep learning models [48].\nA study [22] utilized Graph Convolutional Neural Network (GCNN) and Layer-wise Relevance Propagation (LRP) for stable feature selection and biomarker discovery in breast cancer. The study addressed instability in feature selection experienced with traditional methods. In the proposed framework, GCNN structured gene expression data using molecular network information, enhancing the model's ability to identify relevant features, while LRP explained model decisions by attributing relevance scores to input features, making gene prediction interpretation easier. Using a large breast cancer dataset, GCNN+LRP provided the most stable gene lists. The study also found that GCNN+SHAP is useful for impactful features in classification performance but less stable than LRP. GCNN+LRP demonstrated the most stable and interpretable feature sets, outperforming SHAP and traditional approaches, aiding in consistent biomarker identification across datasets and better understanding of breast cancer. Another Study, the GENIUS framework [37] integrates multi-omics data using advanced deep learning models tailored for image analysis. To enhance the detection of hidden, nonlinear patterns, this framework transforms multi-omics data into spatially connected images where each gene is represented as a pixel, allowing convolutional layers to analyze these spatial connections. The framework comprises an encoder, which compresses genomic information into a latent vector, a decoder, which reconstructs the image from the latent vector, and convolutional layers that extract information from the reconstructed image using a series of convolutional and max-pooling layers. Integrated Gradients (IG) are then used to assign attribution scores to each feature, allowing the interpretation of the model's predictions. The IG method evaluates the relative contribution of individual features, providing attribution scores for each gene in the transformed genome image. This helps"}, {"title": null, "content": "identify which genes drive the model's predictions and are likely associated with disease progression. The study demonstrated significant improvements in predicting metastatic cancer progression from primary tumors. The framework was validated on multi-omics datasets from The Cancer Genome Atlas and two independent cohorts representing different stages of bladder carcinoma.\nRegarding limitations, the GENIUS methodology may not fully satisfy the criteria of stability, interpretability, and classification performance simultaneously. Perturbed features can lead to artifacts, making it unclear if differences in feature impact originate from the data, model misbehaviour, or explanation method issues. In the other GCNN+LRP Framework there is a bias toward highly expressed genes in LRP-selected features, which may not correlate with impactful classification performance. The findings regarding GCNN+LRP's suitability for biomarker discovery are context-specific and may not generalize across different datasets or cancer types without further validation. The transformation of multi-omics datasets into images might introduce biases or lose information, and the framework's performance with different types of omics data needs extensive validation."}, {"title": "4.2.4 DeepLIFT", "content": "Deep Learning Important Features (DeepLIFT) is a widely used explanation framework for deep neural networks, providing insights into the importance of each feature in model predictions. It operates by comparing the model output to a reference output, based on differences in input from a reference input [9", "max": "perations, as found in Maxout or Maxpooling neurons, beyond utilizing gradients alone.\nIn a study [23"}]}