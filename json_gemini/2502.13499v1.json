{"title": "Hidden Darkness in LLM-Generated Designs: Exploring Dark Patterns in Ecommerce Web Components Generated by LLMs", "authors": ["ZIWEI CHEN", "JIAWEN SHEN", "LUNA", "KRISTEN VACCARO"], "abstract": "Recent work has highlighted the risks of LLM-generated content for a wide range of harmful behaviors, including incorrect and harmful code. In this work, we extend this by studying whether LLM-generated web design contains dark patterns. This work evaluated designs of ecommerce web components generated by four popular LLMs: Claude, GPT, Gemini, and Llama. We tested 13 commonly used ecommerce components (e.g., search, product reviews) and used them as prompts to generate a total of 312 components across all models. Over one-third of generated components contain at least one dark pattern. The majority of dark pattern strategies involve hiding crucial information, limiting users' actions, and manipulating them into making decisions through a sense of urgency. Dark patterns are also more frequently produced in components that are related to company interests. These findings highlight the need for interventions to prevent dark patterns during front-end code generation with LLMs and emphasize the importance of expanding ethical design education to a broader audience.", "sections": [{"title": "1 Introduction", "content": "Large language models (LLMs) have shown impressive potential in code generation automation by converting natural language descriptions into code [21]. In the context of front-end code generation, implementing visual designs is a complex and time-consuming task that demands skill and expertise. With LLMs, these technical barriers are lowered for people who are unfamiliar with specific programming languages [24, 32]. Recent studies have also started exploring the use of Visual Language Models (VLMs) to generate HTML directly from designs and sketches [26, 48]. These studies highlight a growing trend toward making front-end development more accessible to general users.\nAs AI-assisted programming systems become increasingly adopted, concerns have been raised about the practical use of their generated code, including security [45], correctness [29], web accessibility [5] and input-output clarity [27]."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Automatically Generated Code", "content": "Program synthesis, the pursuit of automating software development, has been a long-standing area of research interest [33, 50]. Since their introduction, there has been extensive research on how LLMs can assist with software engineering tasks, especially in code generation [6, 29, 52]. Results show that LLMs play a significant role in improving code-writing efficiency and aiding in understanding code logic and structure [22].\nLLMs have also lowered technical barriers to front-end development for end-users with little or no programming knowledge to create their own websites. Through the text-to-code approach, users provide functionality descriptions that LLMs translate into HTML and CSS code. Several studies have explored website generation using LLMs and deep learning models. Huang et al. [23] tested creation of low-fidelity UI mock-ups from textual descriptions with a transformer-based generative model. Cal\u00f2 and De Russis [10] proposed a template-based approach to help end users use LLMs to achieve the desired functionality for their websites with a proof-of-concept implementation through GPT-4.\nIn addition to text-to-code input, research has also started to explore the possibilities of UI-to-code with LLMs. This enables users to obtain code that reproduces designs from design prototypes [1], design sketches [26], or website images [48].\nAt the same time, there are growing interests in evaluating the quality of the code generated by LLMs, including code correctness [28, 29, 54], readability and maintainability [14, 29], security vulnerabilities [49] and other aspects. Recent studies have begun shifting their focus from the code itself to the artifacts created using code generated by"}, {"title": "2.2 The Growth of Dark Patterns", "content": "Dark patterns are designs that use knowledge of human behavior to trick users into actions that benefit a service provider but go against the users' intentions or desires [9, 17]. Such dark patterns have been found across websites and mobile platforms in various domains, including automated systems [4], ecommerce [36], mobile games [2], trending mobile apps [13], and social platforms [39, 47].\nThese intentional design choices have a strong neg-\native impact on user behaviors. Some dark patterns\nuse visual interference to steer users' decision-making.\nOthers influence behavior more subtly, such as by\nhiding information, making processes intentionally\ndifficult, or even using forced actions that users can-\nnot avoid [28]. Recognizing dark patterns is challeng-\ning for users, as their diversity allows many to be\noverlooked, even when users are aware of common\ndark pattern practices [7]. Falling into traps of dark\npatterns can cause individual financial loss, invade\nprivacy, and increase cognitive burden [37].\nThe emergence of these unethical designs can be\nattributed to multiple reasons. In the lab session de-\nsigned by Chivukula et al. [12], designers' dark in-\ntentions and interpretation of user values resulted\nin trade-offs between ethical decisions and user at-\ntraction. Another common reason is that stakehold-\ners with organizational power deprioritize user in-\nterests [51], focusing instead on the company's own\nbenefits, primarily financial gains [25]. In this case,\nGray et al. [16] argued that unethical designs stem\nfrom systemic issues rather than the actions of indi-\nvidual bad actors."}, {"title": "2.3 Taxonomies of Dark Patterns", "content": "Previous studies on dark patterns have provided a taxonomy of dark patterns, covering high-level attributes, broad categories, and specific types. Since dark patterns were first identified as an ethical issue in 2010, Brignull [8] introduced a typology with eight categories, each providing definitions and detailed examples. With a reference to Brignull's taxonomy, Gray et al. [17] created a hierarchy of five primary themes focusing on strategic motivations, including nagging, obstruction, sneaking, interface interference, and forced action. Mathur et al. [36] took another step to identify"}, {"title": "3 Methods", "content": "In our work, we conducted an audit, testing how likely LLMs are to produce dark patterns when generating code. We tested three factors: 1) model, 2) ecommerce component, and 3) whose interests are prioritized in the prompt. The four models selected were popular LLMs: Claude, GPT, Gemini, and CodeLlama. The components generated were 13 common parts of ecommerce platforms (e.g., search, product reviews, checkout, etc.). Finally, the interests captured company interests, user interests, and a baseline condition with no interest specified."}, {"title": "3.1 Condition 1: Varying LLMs", "content": "Our first condition tested different LLMs, to assess whether some models are more likely to produce dark patterns than others. The specific versions used were Claude 3.5 Sonnet [44], GPT-40 [43], Gemini-2.0-flash-exp [3], and CodeLlama-34b-Instruct [46]. These models were selected because: (1) as coding is becoming more accessible to non-experts, ChatGPT, Gemini, and Claude are among the most popular commercial LLMs available to general users [11]; (2) including CodeLlama allows comparison of performance between non-commercial and commercial LLM; (3) these models are all fine-tuned with code datasets [15, 43, 44, 46]."}, {"title": "3.2 Condition 2: Varying Ecommerce Components", "content": "The second condition in our experiment tested different components of ecommerce websites (or widgets). Our study focused on ecommerce, because previous work has identified a significant number of dark pattern instances in this context [36]. We selected 13 commonly seen components (see Table 2) on shopping websites and wrote one-sentence descriptions for each, all following a consistent format.\nThese components were selected because of their relevance and importance for ecommerce websites based on two considerations: (1) We first identified seven features that were either essential for users to complete their shopping tasks or assist them in the process, including search, product details, shopping cart, checkout, shipment tracking, and customer reviews; (2) We then included six more components that represented common strategies used by services to enhance user engagement, such as featured products, promotional information (e.g., sales banners and discount offers), membership mechanisms (e.g., signup and unsubscribe options), and newsletter subscriptions. Table 2 lists all component descriptions. These descriptions were carefully reviewed by the authors to ensure they were neutral, free of bias, and did not provide any information that might lead towards dark patterns."}, {"title": "3.3 Condition 3: Varying Whose Interests Are Prioritized", "content": "The final condition tested whether highlighting different stakeholder interests in the prompt would increase the likelihood of generating dark patterns, with three versions: company interests, user interests, and a baseline condition. The company interests case was included because previous research indicates that companies often deliberately design manipulative practices in pursuit of profit [20, 25]. We aimed to explore whether focusing on company benefit-related goals in system prompts increased the likelihood of LLMs generating dark patterns. In this case, the system prompt included the guidance, \u201cDesign widgets with the interests of the company in mind, like increasing conversion rate, basket size, and number of purchases.\" Metrics like conversion rate and basket size are popular measures of sales performance that marketers and businesses focus on [35, 38], and could increase the likelihood that generated code would use tactics to trick customers into additional purchases.\nThe user interests case was included because user-centered design principles often preclude the development of dark patterns. For example, principles of consistency would prevent designers from offering unequal options [41]. In this case, the prompt included the added instruction, \u201cDesign widgets with user-centered design principles in mind, like user autonomy, flexibility, and consistency.\u201d These two interests-based additions were written to have similar length, complexity, and jargon, to prevent any factor other than the interest from impacting the generated code. In the baseline condition, no additional information was included in the prompt."}, {"title": "3.4 Prompts", "content": "LLM prompts were structured into two parts: system prompts and user prompts. The separation between system and user prompts was intended to provide a distinction between overall instructions for consistent results and individual tasks. System prompts define the LLM's overall behavior, tone, and boundaries, ensuring consistent and safe interactions. User prompts, on the other hand, specify tasks or queries dynamically, tailoring the LLM's responses to user needs [42]. All four LLMs were tested using the same system and user prompt structure. CodeLlama's system prompt included an extra instruction to wrap the code with <!DOCTYPE html> and </html>, and enclose CSS styles within <style> and </style> tags, ensuring a consistent code structure with the other three models for building the next-step annotation pipeline. The prompt template used for both system and user prompts is included in Table 3."}, {"title": "4 Analysis", "content": "Our analysis hand-annotated all LLM-generated code for the presence/absence of dark patterns and used those counts to calculate statistical measures of difference. The original response for each prompt pair was a single file using HTML and CSS to create a single component of an ecommerce website. Rather than evaluate the code directly, we developed an automated pipeline to compile the code and screenshot the design. While these visual representations can include minor issues (the most common being that LLMs were prompted to use placeholder image URLs which do not compile), they were generally much easier to assess for the presence of dark patterns than the original code.\nThree independent, trained designers labeled each output for the presence of dark patterns. In addition, drawing on a taxonomy developed in prior work [37], we labeled six attributes defined in Table 1 for each LLM-generated component design: asymmetric, covert, deceptive, information hiding, restrictive, and disparate treatment. After an"}, {"title": "5 Results", "content": "In the 312 components generated by all four LLMs, 115 (37%) were found to have at least one dark pattern. We found at least one example of every dark pattern attribute proposed by Mathur et al. [37] and provided an example of each in Figure 1. Further analysis revealed which models, interests, and components of an ecommerce pipeline are most likely to generate dark patterns. We also separated the analysis of specific dark pattern attributes [37], identifying which dark patterns are most frequently produced by LLMs."}, {"title": "5.1 Comparing Models: CodeLlama Produced Fewer Dark Patterns Than Other LLMs", "content": "When comparing the number of generated components with dark patterns across different models, we found some models generated fewer dark patterns than others. In particular, CodeLlama-34b-Instruct generated only 22 (28.2%) components with dark patterns, while the other three models produced similar larger numbers of dark patterns: Gemini-2.0-flash-exp created 30 components with dark patterns (38.5%), GPT-40 generated 31 (39.7%), and Claude 3.5 Sonnet produced 32 (41%).\nWe conducted a full four-way Chi-square test to evaluate whether the differences in the number of components with dark patterns generated by the four models were statistically significant. However, the test result revealed that while there are variations in the frequency of dark patterns across the models, these differences are not statistically significant ($\\chi^2$ = 3.46, p = 0.33)."}, {"title": "5.2 Comparing Ecommerce Components: Sales, Discount, and Membership Components Were Most Likely to Include Dark Patterns", "content": "Comparing the frequency of dark patterns across the different ecommerce components showed that some components are much more likely to be generated with dark patterns than others, as shown in Figure 2. Across 24 generation attempts for each type of ecommerce component, newsletter signup components contained dark patterns 92% of the time, followed by discount offers (88%), membership signups (75%), and sales banners (67%). On the other hand, certain ecommerce components, such as product details, featured product, user logins, shopping carts, order tracking, and product search, rarely or never contained dark patterns."}, {"title": "5.3 Comparing Whose Interests Are Prioritized: User Interests Decreased While Company Interests Increased Dark Patterns", "content": "To evaluate whether varying interest priorities influence dark pattern generation, we analyzed the data across baseline, user interests, and company interests. Under the baseline condition, 38 components (36.5%"}, {"title": "5.4 Comparing Dark Pattern Attributes: Hiding Information And Restricting Actions Are Most Common", "content": "Over one-third (37%) of the components generated were found to have at least one dark pattern. Among these, 60 components exhibited a single dark pattern attribute, 50 had two dark pattern attributes, and 5 displayed three dark pattern attributes, resulting in a total of 175 identified instances of attributes. Since the labeling schema allowed multiple dark pattern attributes in the same component, the percentages reported below in this section reflect the proportion of components containing each attribute relative to the total number of components with dark patterns. Figure 1 provides examples drawn from our dataset that illustrate the six dark pattern attributes (originally defined in Table 1)."}, {"title": "5.4.1 Information Hiding", "content": "The \"information hiding\u201d attribute is the most commonly identified dark pattern, appearing in 66 components (57% of components with dark patterns). Most \"information hiding\" dark pattern designs omit crucial information that users need to make informed decisions. Examples include: not presenting terms of service or privacy policies during newsletter or membership sign-ups (24), using urgency messages like \u201climited offer\u201d or \u201cflash sales\" without providing a deadline to pressure users into making decisions (19), displaying positive customer reviews without explaining why they were selected (10), hiding the cost of product add-ons (4), and hiding details about future charges while only mentioning that the first month of membership is free (2). Another tactic used by the dark pattern is obscuring or delaying information. For example, terms of service or privacy policies may be made to appear unclickable through subtle color choices (6), or the option for free shipping is delayed (1)."}, {"title": "5.4.2 Restrictive", "content": "The \u201crestrictive\" attribute is the second most common, with 44 instances identified (38%). These dark patterns restrict users' actions, forcing them to proceed in a way that aligns with the service's interests. For example, some components do not include the absence of a close button for membership, newsletter sign-up, or other popovers (41). Some do not provide options to remove products or return to shopping in the shopping cart (3)."}, {"title": "5.4.3 Covert", "content": "The \"covert\" attribute is the third most common, appearing in 33 instances (29%). The most common example is limited-time messages that do not have a specified expiration date (19), followed by countdown timers (10). Other examples include offering lures during membership cancellation, such as discounts or the option to pause membership (3), and pressured selling, where products users did not add are recommended in the shopping cart (1)."}, {"title": "5.4.4 Asymmetric", "content": "The \"asymmetric\u201d attribute is found in 16 instances (14%). The asymmetry is reflected in using brighter or green colors for buttons such as \"Keep Membership\" during cancellations or \"Add to Cart\" on product detail pages (11), pre-selecting costly default options during membership sign-up (4), and using tiny fonts to disclose that discounts only apply to selected items (1)."}, {"title": "5.4.5 Disparate Treatment", "content": "The \"disparate treatment\" attribute appears in 11 instances (10%). These designs use the attribute to encourage actions that benefit the company or discourage actions that could disadvantage it. The benefits offered to users are often discounts on products or membership prices. For example, a 10% discount is used to encourage users to sign up for memberships or newsletters (8). Similarly, discounts are provided during the membership cancellation process to discourage users from completing their cancellations (3)."}, {"title": "5.4.6 Deceptive", "content": "The least frequently observed attribute is \"deceptive\", appearing in only 5 instances (4%). The deception includes designs that highlight discounts for featured products without providing the original price (2), creating false beliefs that the products are on sale. In the checkout process, add-ons such as gift wrapping and shipping insurance lack price information, leading users to mistakenly believe these services are free (2). Additionally, deception can involve using color to emphasize prices, making users think a product is discounted without offering further clarification (1)."}, {"title": "6 Discussion", "content": "Our findings show that a significant percentage of web component designs produced by LLMs contain at least one dark pattern. If users directly implement this code on their websites, it may lead to unintended ethical issues that manipulate end-users into making choices against their best interests. Although there are variations in the frequency of dark patterns generated by the four models tested in this study, all produced significant numbers of dark patterns. As the generation of dark patterns is currently unavoidable, human intervention is crucial, and the responsibility extends beyond designers to include developers and other LLM users. This highlights the need for educational opportunities to raise awareness and equip these users to address dark patterns effectively."}, {"title": "6.1 Prioritize Interventions based on Component Types", "content": "Systematic interventions are needed when using LLMs for website generation with code assistance. Our research findings show that dark patterns are more likely to be generated in certain types of web components, such as newsletter and membership sign-ups, as well as promotional components like discount popovers and sales banners. Therefore, when using LLMs for code generation in front-end development, it is important to pay extra attention and prioritize interventions to components tied to company interests, such as revenue generation, customer retention, user data collection, and user engagement."}, {"title": "6.2 Building Mental Models as Interventions", "content": "Gray et al. [7] found that users often struggle to identify dark patterns that use deceptive strategies, such as hiding information, forcing actions, or using trick questions. This presents a significant challenge for LLM users who try to address dark patterns, as our study shows that a large portion of the LLM-generated dark patterns - 57% of the identified components - fall under the category of information hiding. Without a clear mental model of what information should be provided, these dark patterns can be very challenging to spot. The examples provided in this study for the six dark pattern attributes can serve as a reference and a starting point for users to understand the types of tricks that LLM-generated designs might use under each attribute.\nThere is ongoing discussion on how to scale up efforts to expose users to a wider variety of dark patterns for educational purposes. Lu et al. [30] proposed several approaches to increase scalability, including using machine learning for automated dark pattern recognition and using community contributions to crowdsource examples of dark patterns, gather meta-information about designers' intentions behind the designs, and support developers in creating"}, {"title": "6.3 Proposing Safe Meta Prompts for Ethical Design Generation with LLMs", "content": "In this study, we also tested conditions that reflected different stakeholder interests. However, these conditions did not yield statistically significant differences. The results suggest that providing broad stakeholder interests has a minimal impact on the generation of dark patterns by LLMs. This indicates that containing high-level guidance in prompts is insufficient to address the issue of dark patterns in LLM-generated designs. However, providing more detailed user-centered design principles in the form of meta-prompts could be more effective. Such prompts could offer specific instructions on prioritizing user needs and ethical design principles, potentially resulting in designs that better reflect user interests and reduce the presence of dark patterns."}, {"title": "6.4 Extending Design Responsibility and Expanding the Need for Education", "content": "Reducing dark patterns has been viewed as a primary responsibility of designers, as they have power and influence over interface design [16, 18]. A large portion of past efforts to combat unethical designs has focused on providing ethical education to designers and UX professionals to increase their awareness and sensitivity to user values [19, 31, 40].\nHowever, as LLMs become increasingly capable in front-end development, handling both design and coding tasks, dark pattern designs can bypass designers and be directly presented to end users. In one way, this shifts the power dynamic, as LLM users can redesign and modify the UI generated by LLMs, reducing the traditional control held by designers [30]. On the other hand, this also makes it more challenging for users as they must critically evaluate the quality and ethics of the generated work, as they must assess it from both a design and a code quality perspective. This added complexity highlights the need for LLMs users to gain a deeper understanding of what are ethical designs. Without this knowledge, users may unintentionally integrate unethical designs into their applications.\nThis emphasizes the importance of expanding ethical design education to a broader audience, beyond just designers. It is also necessary for LLM products to integrate user-centered design principles into the training and testing while increasing user awareness of potential risks in generated designs."}, {"title": "7 Conclusion", "content": "In this paper, we conducted an audit of four LLMs to evaluate their likelihood of generating dark pattern designs in code for 13 ecommerce web components. Our findings revealed a significant percentage of designs containing dark patterns, performance differences among models, variations in the frequency of dark patterns across ecommerce components and different stakeholder interests. We also provided detailed examples and distributions for each dark pattern attribute produced by the LLMs. This study highlights the critical need for human intervention when using LLMs as AI-assisted programming tools for front-end development. Additionally, we call for expanding ethical design education to a broader audience, as the shift in design responsibility brought by LLMs now involves more users in addition to traditional designers."}]}