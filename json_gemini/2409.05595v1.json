{"title": "SynMorph: Generating Synthetic Face Morphing Dataset with Mated Samples", "authors": ["Haoyu Zhang", "Raghavendra Ramachandra", "Kiran Raja", "Christoph Busch"], "abstract": "Face morphing attack detection (MAD) algorithms have become essential to overcome the vulnerability of face recognition systems. To solve the lack of large-scale and public-available datasets due to privacy concerns and restrictions, in this work we propose a new method to generate a synthetic face morphing dataset with 2450 identities and more than 100k morphs. The proposed synthetic face morphing dataset is unique for its high-quality samples, different types of morphing algorithms, and the generalization for both single and differential morphing attack detection algorithms. For experiments, we apply face image quality assessment and vulnerability analysis to evaluate the proposed synthetic face morphing dataset from the perspective of biometric sample quality and morphing attack potential on face recognition systems. The results are benchmarked with an existing SOTA synthetic dataset and a representative non-synthetic and indicate improvement compared with the SOTA. Additionally, we design different protocols and study the applicability of using the proposed synthetic dataset on training morphing attack detection algorithms.", "sections": [{"title": "INTRODUCTION", "content": "ACE recognition systems(FRS) have been widely de- the training data to avoid overfitting. Hence, it is essential\nFloyd frente application scenarios, such\nas automatic border control [1]. Nonetheless, with the im-\nprovement of FRS in generalization and the development\nof image manipulation techniques, it is also shown that\nFRS is vulnerable to various types of attacks [2] [3]. Hence,\nit is essential to develop corresponding attack detection\nalgorithms to protect the FRS from potential attacks. Face\nmorphing attack detection (MAD) is the technology de-\ntecting attacks that combine the face images from two or\nmore individuals into a single morphed image. Based on\nthe attack scenario and the types of input, MAD can be\nclassified into single image-based morphing attack detection\n(S-MAD) and differential image-based morphing attack de-\ntection (D-MAD). S-MAD aims to detect the face morphing\nattack based on a single image presented to the algorithm.\nThe common application scenario is validating photos sub-\nmitted during the application for a visa or passport and\nvalidating the existing database without morphed images.\nThe D-MAD case simulates the scenario of automatic bor-\nder control, where a suspicious image in the passport is\nvalidated, given the supplementary information from trust-\nworthy probes captured by the gate cameras.\nVarious MAD approaches have been designed by re-\nsearchers [1]. Additionally, based on their approach, they\ncan be roughly classified into explicit methods using engi-\nneered features such as hand-crafted texture descriptors and\nimplicit methods with advanced deep learning techniques\nthat can achieve better generalizability. In both cases, most\nof the algorithms are data-driven and while the former\noffers some explainability, the latter needs a larger size of\nto have large-scale and high-quality training datasets to\ndevelop generalized and robust MAD algorithms and test-\ning datasets to evaluate and benchmark existing algorithms\nfrom different developers. However, due to privacy regu-\nlations, face samples are considered sensitive data, which\nmakes it challenging to collect the dataset on a large scale\nand difficult to share between researchers in different insti-\ntutes.\nSeveral works have been done to address this challenge.\nThe most common solution is benchmarking different algo-\nrithms with in-house protocol and database. However, as\nthe dataset is not publicly available, it lacks transparency.\nMeanwhile, this will make the results from different re-\nsearch work challenging to compare and, hence, less repro-\nducible. Another existing solution is benchmarking MAD\nalgorithms in public evaluation platforms such as NIST\nFATE MORPH [2], and Bologna Online Evaluation Platform\n(BOEP) [3] 1. In this way, trained algorithms are submitted to\nthe evaluation platforms and benchmarked with other sub-\nmitted algorithms. However, submitting to these platforms\nrequires following a specific application programming in-\nterface, which is not convenient for all of the approaches\nand their implementations. Further, the training phase of the\nsubmitted algorithms is not transparent between different\nalgorithms as the developers use their own training data.\nA convenient approach is to use a transparent, sharable\nsynthetic dataset that can scale into a large number of\nsamples. Several works have been conducted to design"}, {"title": "RELATED WORKS", "content": "Existing non-synthetic face morphing datasets are usually\nconstructed based on FRLL [12], FRGC v2.0 [13], Color\nFERET [14], Utrecht ECVP [15], Casia-webface [16] or other\nin-house datasets. The common challenge is that the morph\ndatasets generated by most of these datasets are not publicly\nsharable for benchmarking MAD algorithms. FRLL-Morph\n[17] is the existing public-available face morphing dataset,\nwhile only 102 subjects and one mated sample for each\nsubject are included in the dataset. Hence the number of\nmorphed samples and non-morphed samples are heavily\nunbalanced. This indicates another challenge of face mor-\nphing dataset: it is challenging to construct a face morphing\ndataset with both high quality and sufficient size of data for\ntraining generalized MAD algorithms.\nAs several works have been studying the applicability\nof using synthetic data for training and evaluating face\nrecognition task [18], Damer et al. [6] proposed a method\nto generate a synthetic face morphing dataset. In their\nSMDD dataset, non-morphed images are generated using\nthe StyleGAN [7] model in 256 x 256 image resolution."}, {"title": "PROPOSED METHOD", "content": "In this section, we introduce the proposed method for gener-\nating a synthetic face morphing dataset. As shown in Figure\n2, the method can be divided into three parts: generation of\nbase samples, generation of mated samples, and generation\nof morphs. First of all, the base samples here denote the\nimages representing different identities in the dataset and\nwill be used to generate mated samples with the same\nidentity. More specifically, base samples are controlled with\nface image quality and intra-identity diversity so that each\nbase sample aims to represent a high-quality face image of\na unique identity among the dataset. Then, corresponding\nmated samples are generated by applying different attribute\nediting techniques to the original base sample. Finally, for\neach base sample, paired base samples for morphing are\nselected based on similarity and two morphing algorithms\nare applied to generate the morphed samples."}, {"title": "Generation of Base Samples", "content": "For the generation of synthetic images, we use the Style-\nGAN2 [9] model pre-trained on the FFHQ dataset [7]. A pre-\ntrained StyleGAN2 generator maps between a known latent\nspace and the pixel space. Hence, by randomly sampling la-\ntent vectors $z \\sim \\mathcal{N}(0, 1)$ in the known distribution, random\ndifferent faces can be generated. Following the architecture\nof the StyleGAN2 model, the random sampled latent vector\nfrom Z-space will be further mapped by the pre-trained\nmapping network f to W-space as $w = f(z)$. To simulate\nthe construction of a face morphing database, our target is\nto generate images that have acceptable face quality for the\nenrolment process of the passports and diverse identity in-\nformation between different random images. To ensure the\nface image quality of the accepted samples, we first apply\na latent editing technique to neutralize the random sample\nand then use an explicit face quality filtering pipeline to\nfilter out non-interesting images. The neutralization process\nwas proposed by Colbois et al. [4], where the author pro-\nposed to use semantically controlled non-synthetic data to\ncompute the corresponding linear shifting that is required in\nthe latent space to achieve the neutralization of a synthetic\nimage. By fitting SVM classifier for binary attribute classifi-\ncation, the unit normal vector n of the SVM's hyperplane is\ncomputed as the shifting direction in latent space, and the\nmean distance d of sample points in each class is calculated\nas the scale for editing to each corresponding class. More\nspecifically, the sample is edited to have a frontal pose\nangle, neutralized expression, and neutralized illumination\nconditions. The binary classes of the pose are based on left\nor right poses and the binary classes of the illumination are\nbased on light flashed from left or right. Hence the neu-\ntralization is sequentially projecting the W-latent vector to\ncorresponding decision boundary as $w' = w - (w \\cdot n_p) \\cdot n_p$\nand $w'' = w' - (w' \\cdot n_i) \\cdot n_i$, where $n_p$ and $n_i$ are unit normal\nvectors of the decision boundary for classifying pose and\nillumination respectively. The binary classification of expres-\nsion is between neutral and smiling expressions, hence the\nW-latent needs to be first projected to the decision boundary\nusing the unit normal vector $n_{ns}$ and then shifted with the\npre-computed mean distance $d_{ns}$ towards the neutral class\nas $w''' = w'' - (w'' \\cdot n_{ns}+d_{ns}) \\cdot n_{ns}$. In the further filtering\npipeline, we apply img2pose [20] to determine the yaw\nand pitch angle and only accept within the range of [-5, 5]\ndegree for both yaw and pitch angles, and then use Dlib\n[21] landmark detection and canny edge detection operator\non the bridge of the nose to filter out face images with closed\neyes or covered by glasses. To enrich the diversity of identity\ninformation sampled in our database, we use VGGFace2 [22]\nFRS to compare between the processing sample and each of"}, {"title": "Algorithm of generating mated samples for Syn- Morph dataset", "content": "To generate mated samples, given a base sample, we gen-\nerate the mated sample of this subject by editing identity-\nirrelevant attributes, e.g., illumination, ageing effect, etc.,\nbased on pre-computed latent shifting directions [4] [23].\nMeanwhile, different editing strategies are applied to simu-\nlate the data used in different application scenarios (S-MAD\nor D-MAD). Face editing is, similar to the editing during\nthe neutralization process when generating base samples,\nachieved by linearly interpolating the latent vector used to\ngenerate the face image on a specific direction and scale\nfactor. The directions are pre-computed decision boundaries\nof semantic face attributes in the latent space and the scale\nfactor is a scalar controlling the scale of editing (for example,\na larger scale factor for age progression will add stronger\nageing effects on the edited face image). For the S-MAD\ncase, to keep the face image quality acceptable for passports,\nwe edited the combination of illumination and ageing effect\nin a minor scale (noted as IFGS - InterFaceGAN for S-\nMAD). Given a normalized W-latent vector $w_B$ from the\nbase samples and unit normal vectors from the decision\nhyperplane of illumination flashed from left to the right $n_i$,\nthe ageing effect from younger or older than 30 years old $n_A$\nfollowing: $w_{IFGS} = w_B + \\alpha_I \\cdot n_I + \\alpha_A \\cdot n_A$ with different\ncombinations of scale factors $\\alpha_I$ and $\\alpha_A$. For the D-MAD\ncase, to simulate the probe images at the gate, editing to sim-\nulate the wilder condition is required. In the setting named\nIFGD, we edit more attributes, including pose, expression,\nillumination, and ageing effect, with larger scale factors $\\beta$ as:\n$w_{IFGD} = w_B + \\beta_p \\cdot n_p + \\beta_{NS} \\cdot n_{NS} + \\beta_I \\cdot n_I + \\beta_A \\cdot n_A$. In\nthe setting of FRPCA, we apply the random editing method\nproposed by Grimmer et al. [24] using PCA and control of\nVGGFace2 [22] FRS. 55 principle components in W latent\nspace are computed as $n_{PCA}$. For all of the generated mated\nsamples, VGGFace2 FRS is applied to ensure the identity\npreservation between a base sample and generated mated\nsamples."}, {"title": "Generation of Morphs", "content": "For the generation of morphs, we select one GAN-based\nmorphing algorithm, MIPGAN-II [10] and one landmark-\nbased morphing algorithm, LMA-UBO [11]. To select the\npairs of images for generating morphs, VGGFace2 [22] FRS\nmodel is used to compute the similarity score of each base\nimage and other base images with the same gender and\nset (training, testing and validation). For the training set, 50\npairs with the top 50 highest similarity scores are selected.\nFor the Dev and Test set, a full combination of pairs is\nselected due to the number of subjects. In this way, around\n100000 morphs are generated for each morphing algorithm."}, {"title": "EXPERIMENT AND RESULTS", "content": "The objective of our experiment design is to evaluate the\nperformance of the proposed SynMorph method for gen-\nerating a synthetic morph dataset. By using the proposed\nmethod, we first generate a synthetic face morphing dataset\nwith a large number of samples. Then, we evaluate the\ndataset from different perspectives and benchmark it with a\nnon-synthetic face morphing dataset for further studies. As\na face-morphing dataset, the two main performance factors\nare face image quality and attack ability towards FRS. Data\nwith low face image quality might not be acceptable for the\nface recognition system and morphing attacks that are not\nable to threaten FRS are not effective and representative of\nattacks [25]. Also, it would be essential to compare with\nnon-synthetic data and study consistency or gap between\ntheir performances. Finally, one of the intentions of devel-\noping the synthetic face morphing dataset is to use it as a\nlarge-scale and privacy-friendly dataset for developing and\nbenchmarking morphing attack detection systems. Hence,\nwe will select several S-MAD and D-MAD algorithms and\nbenchmark them with different evaluation protocols us-\ning proposed synthetic and non-synthetic face morphing\ndatasets."}, {"title": "Dataset", "content": "As described in Section 3, We first randomly generate base\nsamples and manually select 1175 male and 1175 female as\nthe 2350 different identities with binary pseudo gender in\nour dataset. Then, similar to constructing the non-synthetic\nface morphing dataset, we first split the base samples into\ntraining (1000), development (75), and testing (100) sets for\nthe male and female groups, respectively. Then for each sub-\ngroup, we generate the mated samples and morphs. For\neach base sample, we generate a fixed number of mated\nsamples for the three types of mated sample generation\nmethods named IFGS (63), IFGD (90), and FRPCA (55). For\nthe IFGS and IFGD methods, the generated mated samples\nare further filtered based on FRS to exclude the images\nwithout identity preservation, while the FRPCA algorithm\nitself manages the scale of editing using FRS control so\nthere's no further filtering process. Finally, for the morph\ngenerating, we generate 50 morphs for each subject without\nduplications and symmetric pairs (Subject A is morphed\nwith B, and again, subject B is morphed with A). The morph\npairs are based on base samples from each group and hence\nwithout crossing of genders. As the development set and\ntest set have 75 and 100 base samples, we use a full combi-\nnation of the subject pairs to generate the morphs in order\nto keep a balanced number of morphed and non-morphed\ndata. In the end, our SynMorph dataset 141k (IFGS), 210k\n(IFGD), and 129k (FRPCA) non-morphed samples, and 115k\n(each of MIPGAN [10] and LMA [11]) morphed samples.\nThe base images are generated by StyleGAN2 model [9]\ntrained on the FFHQ [7] dataset with an image resolution\nof 1024 by 1024. To compare the quality between existing\nsynthetic morph datasets, we selected the SMDD [6] dataset\nas a baseline and also benchmark with a representative\nhigh-quality non-synthetic morph dataset based on FRGC\nV2 dataset [10]. SMDD dataset (training part) contains 25k\nnon-morphed images and 15k morphed images generated"}, {"title": "Face Image Quality Assessment", "content": "As face morphing attack aims at attacking face recognition\nsystems, it is essential to evaluate its biometric sample\nquality. Meanwhile, inspired by [28], we measure the syn-\nthetic dataset's applicability by applying Face Image Quality\nAssessment (FIQA). Face Image Quality Assessment (FIQA)\nestimates the recognition performance of biometric systems.\nIn this work, we selected FaceQnet v1 [19] and SER-FIQ\n[29] algorithms to extract the quality scores. FaceQnet v1\nis an end-to-end deep learning model that is trained by\nlabelling the FRS comparison score between to-be-estimated\nsamples and high-quality samples as ground-truth scores.\nSER-FIQ is an unsupervised and FRS-dependent approach\nthat estimates the quality score by applying dropout on a\nspecific face recognition network to obtain its subnetworks\nand then measuring the stability of embeddings extracted\nby different sub-networks. Hence, it covers both supervised\nand unsupervised FIQA methods.\nAs a comparison, we select a representative non-\nsynthetic face morphing dataset generated by FRGC v2 [13]"}, {"title": "Vulnerability Analysis", "content": "Vulnerability analysis on FRS against our SynMorph\ndataset, Morphing Attack Potential (MAP) [30] is applied"}, {"title": "Morphing Attack Detection", "content": "For morphing attack detection experiments, we designed 3\nprotocols:\n\u2022 Protocol I: training and testing sets have the same\ntype of data\n\u2022 Protocol II: training and testing sets have different\ntypes of data\n\u2022 Protocol III: training set is mixed with synthetic\nand non-synthetic data, tested on synthetic and non-\nsynthetic data separately\nProtocol I evaluates the common scenario of using the\nsame type of data to construct the training and testing set\nof MAD algorithm. For example, if the training set contains\nnon-synthetic data, the test set also contains non-synthetic\ndata. This simulates the applicability of using synthetic\ndata for benchmarking between MAD algorithms. Further,\nit should be investigated whether the model trained on\nsynthetic data can be generalized to the detection of non-\nsynthetic data. Protocol II evaluates the MAD performance\nof cross-testing between data types. If the model is trained\nwith synthetic data, the MAD results on non-synthetic data\nwill be reported, and vice versa when the model is trained\non non-synthetic data. Finally, in Protocol III we evaluate"}, {"title": "Evaluation on S-MAD Algorithms", "content": "Figure 9 shows the evaluation results of Protocol I on S-\nMAD algorithms. As noted in Figure 9a and Figure 9b,\nwhen trained with non-synthetic LMA-UBO data, the Xcep-\ntion method achieves a lower detection error rate than the\nMorphHRNet Algorithm. It can also be noticed that training\nwith LMA-UBO morphs achieves higher generalizability\nthan training with MIPGAN-based morphs, while training\nand testing with MIPGAN-II morphs are easier than the\nLMA-UBO morphs. Figure 9c and 9d shows that when using\nlarge numbers of synthetic data for training and testing,\nboth algorithms have shown very low classification error\nrate even for detecting the unknown type of morphing\nattacks.\nAs shown in Figure 10a and Figure 10b, when training\non non-synthetic data and testing on synthetic data, the\nXception algorithm shows a more robust performance than\nMorphHRNet. Both algorithms show a quite high error\nrate when training on synthetic data and testing on non-\nsynthetic data.\nIn Figure 11, we report the Protocol III results when\nMAD algorithms are trained with together synthetic and\nnon-synthetic data and have different train-test settings. An\noverall lower detection error rate on synthetic data can be\nnoticed due to the larger size of synthetic data compared\nto non-synthetic data in the training set. Comparing the\nbenchmarked algorithms to detect non-synthetic morphing\nalgorithms, Figure 11a shows that Xception algorithm has\na higher accuracy when the model is trained by LMA-\nUBO morphs, while Figure 11b indicates that the MorphHR-\nNet performs better BPCER at low MACER. Regarding"}, {"title": "Evaluation on D-MAD Algorithms", "content": "Differing from the previous evaluations of S-MAD algo-\nrithms, for D-MAD data we have two types of synthetic\ndata: synthetic IFGD and synthetic FRPCA. Synthetic IFGS\ndata will be used to simulate the enrollment non-morph\ndata. Figure 12 shows the D-MAD evaluation results of\nthe DDFR algorithm for Protocol I. When training and\ntesting on the same type of data, in all cases, the detection\nperformance degradation on unknown attacks remains and\nis especially obvious in Figure 12b where the model is\ngeneralizing with training data of non-synthetic data with\nMIPGAN-II morphs to LMA-UBO morphs. Evaluation re-\nsults of training and testing with different types of data\nare illustrated in Figure 13. Similar to the observation for S-\nMAD results, cross-testing between different types of data,\nboth for training on synthetic and testing on non-synthetic,\nand training on non-synthetic and testing on synthetic,\nshows a high classification error rate. It is also shown\nin Figure 13c and 13e that when the models are trained\nwith synthetic LMA-UBO data and tested on non-synthetic\ndata, results of inter-morphing-algorithm testing is similar\nand even lower than intra-morphing algorithm cases. In\nthe comparison between Figure 13c-13d and Figure 13e-\n13f, training and testing the model with both MIPGAN-\nII based data even achieved lower detection accuracies.\nThe results of training with the mix of synthetic and non-\nsynthetic data are shown in Figure 14. When the algorithm is\ntrained with landmark-based morphs, it is shown in Figure\n14a that the classification error rate of testing on synthetic\nIFGD data with MIPGAN morphs is quite high. Other three\ncurves when testing on non-synthetic data (with landmark-\nbased or GAN-based morphs) have shown similar detection\nperformance at low MACER. Figure 14b shows the results of\nusing MIPGAN-II morphs for training. In this case, testing\non datasets with also MIPGAN-II morphs shows an overall\nlower classification error rate than datasets with LMA-UBO\nmorphs. Comparing different types of testing data, detec-\ntion accuracy on synthetic data is, in general, lower than\nresults on non-synthetic data. Similar observations hold for\nusing synthetic data with mated samples generated by the\nother algorithm (FRPCA) in Figure 14c and Figure 14d.\nFigure 15 includes the benchmarking of the landmark-\nbased face de-morphing algorithm (LMFD). It is shown that\nthe MACER and BPCER of the synthetic data are overall\nhigher than the non-synthetic data. Comparing results on\nusing the same type of data but with morphs generated\nby different morphing algorithms, a consistent trend can\nbe observed: detecting the MIPGAN-II morphs has a lower\nerror rate than detecting LMA-UBO morphs."}, {"title": "DISCUSSIONS AND LIMITATIONS", "content": "Our evaluation results on face image quality assessment\nshow that the synthetic face morphing dataset also has a\nconsiderable face image quality, meaning that their qual-\nity is acceptable for a passport enrolment application and\nsimilar to non-synthetic data. Similar trends have also been\nindicated in other works for synthetic face data. For the\nSER-FIQ method, there's a gap between our method and\nthe selected baseline synthetic dataset, SMDD dataset, and\nthe non-synthetic face morphing dataset. This might be\nbecause the SMDD dataset is filtered based on FaceQnet\nquality scores during dataset generation. Hence the data\nshow high-quality scores when again being evaluated by\nFaceQnet afterwards. In this case, our proposed method\nshows a higher face image quality than SMDD dataset and\nis also closer to the score distribution of non-synthetic data.\nRegarding vulnerability analysis, the proposed Syn-\nMorph dataset shows a higher face morphing attack\npotential compared to the non-synthetic face morphing\ndataset, which shows the effectiveness of generated syn-\nthetic morphs. However, it should be noted that the vul-\nnerability analysis is based on the comparisons between\nmorphs and mated samples. For the synthetically gener-\nated samples, we used FRS-control for identity preservation\nand several editing techniques, while compared to the real\napplication cases, it remains a challenge for the synthetic\ndata to simulate the large variation on different mated face\nrepresentations, especially for the probe images used for D-\nMAD with wilder capturing conditions.\nWhen benchmarking S-MAD algorithms, due to the\nsmall number of non-synthetic images for training, using\nMIPGAN-based morphs as training data usually makes it\neasy for the model to overfit on the determination between\nGAN-generated images and non-synthetic images instead of\nlearning the traces of morphing, which makes it challenging\nto generalize on unseen LMA-based attacks. When training\nthe S-MAD model with non-synthetic data with MIPGAN-\nbased morphs, we used reconstructed non-morphed images\nwith the same backbone StyleGAN2 generator as MIPGAN-\nII to mitigate the bias between non-morphed non-synthetic\nimages and morphed non-synthetic images. However, the\ngap remains quite noticeable compared to models trained\non the non-synthetic landmark-based dataset. This is also\nexplained in Figure 10a-10b where the MACER is very high.\nFor results of Protocol II as shown in Figure 10, it is challeng-\ning for the algorithms trained only on non-synthetic data\nto directly generalize to synthetic data (or vice versa). On\nthe other hand, for the synthetic data, as the non-morphed\nimages of synthetic data are originally GAN-generated,\nthe morphs generated by the landmark algorithm may\nalso leave some GAN-based traces. Hence, when using the\nsynthetic data for training, it is challenging to generalize\non non-synthetic data as shown in Figure 10c-10d. When\ntraining together with synthetic and non-synthetic data, the\nclassification error rate reduces significantly compared to\ntraining with one type of data and testing one another, but\nalso higher than training and testing with the same single\ntype of data (intra-type evaluation).\nFor D-MAD cases, as the training pairs can be combi-\nnations of pairs with suspicious images and mated probe"}, {"title": "CONCLUSION", "content": "In this paper, we've proposed a new method for generating\na synthetic face morphing dataset with high image quality\nand support for both S-MAD and D-MAD by generating\nthe mated samples. Then, we use the proposed method to\ngenerate a large-scale synthetic morph dataset and eval-\nuate its performance. Results show a higher face image\nquality compared to the baseline and considerably higher\nmorphing attack potential to 4 FRS. Additionally, we stud-\nied the applicability of using our synthetic face morphing\ndataset for training S-MAD and D-MAD algorithms. Results\nshow that the synthetic data can be used for training and\nevaluating MAD algorithms. Due to the large number of\nsamples, generalizability between different types of MAs\ncan be improved in some cases. However, it is also shown\nthat crossing between bona fide and synthetic data remains\nchallenging. Hence, it is suggested to carefully report when\nusing synthetic data for evaluating MAD. It remains an open\ntopic on how to effectively use synthetic face morphing\ndatasets such as SynMorph to reduce the detection error\nrate of MAD algorithms on non-synthetic data."}]}