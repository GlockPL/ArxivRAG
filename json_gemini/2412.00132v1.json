{"title": "Road User Classification from High-Frequency GNSS Data Using Distributed Edge Intelligence", "authors": ["Lennart K\u00f6pper", "Thomas Wieland"], "abstract": "Real-world traffic involves diverse road users, ranging from pedestrians to heavy trucks, necessitating effective road user classification for various applications within Intelligent Transport Systems (ITS). Traditional approaches often rely on intrusive and/or expensive external hardware sensors. These systems typically have limited spatial coverage. In response to these limitations, this work aims to investigate an unintrusive and cost-effective alternative for road user classification by using high-frequency (1-2 Hz) positional sequences. A cutting-edge solution could involve leveraging positioning data from 5G networks. However, this feature is currently only proposed in the 3GPP standard and has not yet been implemented for outdoor applications by 5G equipment vendors. Therefore, our approach relies on positional data, that is recorded under real-world conditions using Global Navigation Satellite Systems (GNSS) and processed on distributed edge devices. As a starting point, four types of road users are distinguished: pedestrians, cyclists, motorcycles, and passenger cars. While earlier approaches used classical statistical methods, we propose Long Short-Term Memory (LSTM) recurrent neural networks (RNNs) as the preferred classification method, as they represent state-of-the-art in processing sequential data. An RNN architecture for road user classification, based on selected motion characteristics derived from raw positional sequences is presented and the influence of sequence length on classification quality is examined. The results of the work show that RNNs are capable of efficiently classifying road users on distributed devices, and can particularly differentiate between types of motorized vehicles, based on two- to four-minute sequences.", "sections": [{"title": "I. INTRODUCTION", "content": "Real-world traffic consists of various types of participants ranging from vulnerable road users, such as pedestrians and cyclists, to light vehicles, like motorcycles and small passenger cars, and up to heavy trucks. Determining the type of these participants \u2013 commonly referred to as vehicle classification, or more broadly, road user classification \u2013 has been a key challenge since the early 2000s across various applications in Intelligent Transport Systems (ITS), including traffic management and monitoring, highway tolling, traffic flow estimation, and urban planning [1], [3], [4]. Of course, the categorization of road user types strongly depends on the context and the specific application. Several definitions can be considered, ranging from broad categories, like those mentioned above (pedestrians, cyclists, ...), to arbitrarily fine-grained categorizations. For example, a well-known definition considering vehicle classes is the categorization by the United States Federal Highway Administration that proposes 13 categories based on the vehicle weight, length, number of axles and axle spacing [5]. Traditional approaches use various types of hardware sensors, chosen according to the application's requirements and the level of classification detail needed. Some applications require the installation of physical components on road or pavement segments. These fixed-location sensor systems include pneumatic tubes, inductive loops, piezoelectric sensors, and weigh-in-motion systems. Approaches utilizing such sensor systems are generally categorized as traffic-intrusive methods since they frequently require on-site work that interferes with traffic [4], [6], [7]. In exchange some of these methods can achieve high classification performance, even providing a full 13-class vehicle classification with high accuracy. However, the high installation and maintenance costs of such systems limit their widespread deployment [4], [5], [8]. Furthermore, literature highlights that intrusive methods are restricted to certain applications and prone to errors or limitations under specific conditions. For example, pneumatic tubes do not perform well on high-speed roads and inductive loop detector-based systems encounter issues in congestion situations [1], [4], [5], [8]. In response to these limitations, less intrusive alternatives have gained increasing popularity, including fixed-position and mobile sensor systems, as well as vehicle-mounted sensors that utilize infrared, ultrasonic, and radar technologies. Those systems offer a trade-off in costs and applicability on one hand, and granularity on the other. Moreover, such sensor systems may be affected by several environmental and traffic conditions [1, 5]. Another yet unmentioned unintrusive approach is the classification based on images or videos obtained from (surveillance) cameras [4], [10], [11]. Advances in computer vision and deep learning techniques, particularly convolutional neural networks (CNNs), have significantly improved the performance of camera-based classification systems. Given sufficient training data for the underlying networks, modern camera-based approaches can classify vehicles with high granularity, even under adverse conditions such as noisy or dark images [12], [13], [14]. However, they still face certain limitations, e.g., when the line of sight between the camera and the vehicle is obstructed by environmental factors. To overcome the limitations of existing approaches, a cutting-edge solution could involve the use of 5G networks, which are generally capable of determining positional data for each user device in a certain cell [15], [16]. During the establishment of our 5G campus networks, we planned to utilize this data for the classification task. However, when our project started in 2021, the positioning features were not implemented in the 5G core network, and later, support was limited to indoor scenarios. As a preliminary substitute, Global Navigation Satellite System (GNSS) data was chosen. The widespread adoption of GNSS trackers in general-purpose devices, particularly smartphones, facilitates comprehensive spatiotemporal trajectory data collection. Typically used for navigation or geo-localization purposes, such devices can continuously measure their location with a high sampling rate of around one sample per second. GNSS data can be easily processed to further obtain speeds, accelerations, and decelerations. The frequency, quality, and information content of GNSS data generated from modern smartphones combined with the fact that using GNSS infrastructure does not incur extra costs (since the system is already designed and deployed) therefore motivates the use of this data within several transportation-related applications [5], [12], [19]. However, the utilization of general-purpose GNSS data for such applications is still relatively unexplored in literature, with some works in driving behavior analysis [20], transportation mode prediction [20], [21], [22] and just a few approaches for vehicle classification [5], [6], [12]. Simoncini et al. [5] (2018) investigated vehicle classification into small-, medium-, and heavy-duty categories using low-frequency GPS trajectories with a mean sampling interval of 90 seconds. The extensive dataset contained about one million trajectories, each with at least 20 timesteps, corresponding to a duration of approximately 30 minutes. Features such as distance, time, velocity, and road type were extracted for each GPS sample pair. Recurrent neural networks (RNNs) with Long Short-Term Memory (LSTM) layers were employed for classification. The best model achieved a Macro-Recall of 0.79 for binary classification of light- and heavy-duty vehicles, but only 0.66 for all three classes due to difficulties in distinguishing medium- from small-duty vehicles. Dabiri et al. [12] (2020) used a Convolutional Neural Network (CNN) architecture for a similar task. Their dataset included about 230,000 trajectories with an average sampling interval of 17 seconds and a duration of approximately 20 minutes. The trajectories were preprocessed to capture vehicle motion characteristics and roadway features. The CNN model achieved a macro-recall of 0.74 for binary classification but struggled with all three classes, resulting in a macro-recall of 0.63. The authors of both [5] and [12] suggest that higher-frequency GNSS data might improve their models' ability to capture vehicle motion variations, potentially leading to more granular and reliable classifications with shorter observation durations. More recent approaches either rely on camera infrastructure [23], [24], [11], on vehicular ad-hoc networks (VANETs) [8] or road sensors [7]. This paper investigates road user classification using GNSS data by evaluating a deep learning approach to classify high-frequency positional sequences (trajectories) recorded in real-world conditions with general-purpose devices. As a starting point, we focused the classification task on scenarios within medium-sized towns and rural communities, limiting it to four types of road users, namely pedestrians, cyclists, motorcycles, and passenger cars. The data was specifically collected for this paper utilizing a smartphone app developed for this project. After training, the model can be deployed on smartphones, enabling classification on mobile devices acting as distributed edge devices. We chose LSTM-RNNs for classification as they represent the current state-of-the-art in machine learning for processing sequential data. An RNN architecture for road user classification based on selected motion characteristics is presented and the influence of sequence length on classification quality is examined. We generate multiple datasets and preprocess them to derive suitable, generalizable features. The results of the work show that RNNs are highly capable of reliably classifying volatile non-motorized road users, such as pedestrians or cyclists, based on even short sequences. The classification of motorized vehicles is considerably more challenging. However, the capability to efficiently classify corresponding sequences improves with increasing sequence lengths. Our method achieves an F1-score of 0.82 for passenger cars and 0.76 for motorcyclists based on sequences of just two-minute length or of 0.85 and 0.77 based on four-minute sequences respectively. It therefore demonstrates its potential to classify road users (especially motorized vehicles) not only reliably but also with shorter observation periods than existing approaches that utilize lower-frequency GNSS data. The remaining sections are organized as follows: Section II presents the methodology we followed, describing the utilized data and its preprocessing, as well as the generalized recurrent neural network architecture we used in our experiments. The results of these experiments are subsequently presented in Section III, followed by our conclusion and remarks on future research in Section IV."}, {"title": "II. METHODOLOGY", "content": "In this section, we outline the methodology of our approach, describing data acquisition and preprocessing as well as the utilized neural network architecture."}, {"title": "A. Data Acquisition", "content": "A primary challenge in GNSS-based road user classification is the limited availability of high-quality, publicly accessible datasets, particularly for vulnerable and critical user groups, such as cyclists and motorcyclists. The dataset used in this work was therefore collected by a relatively small group of just six volunteers in everyday traffic, using a mobile app specifically developed for this purpose. A total of 165 real-world road user trajectories were collected, representing a duration of approximately 32 hours. The trajectories collected by the app are labeled and can be categorized in four classes. About 34.6% of the collected data represent passenger cars, 24.5% cyclists, 20.3% motorcyclists and 20.6% pedestrians. Each trajectory comprises a sequence of timestamps, latitudes, longitudes, and accuracy measurements recorded with a sampling frequency of approximately one second. All trajectories were collected in the Upper Franconia region of Germany, where Coburg University is located. Consequently, the data primarily originates from traffic in medium-sized towns and rural areas, with no representation of urban traffic. To investigate the impact of different sequence lengths, we first generated three datasets from the collection of trajectories by truncating each trajectory to multiple sequences with lengths of 60 (1min), 120 (2min) or 240 (4min) data points, respectively. This truncation method also provides the benefit of increasing our sample size as a side effect. Sequences shorter than the expected length are discarded at this stage. The remaining sequences are split into a training set (75%) and a test set (25%) using stratified sampling to preserve class ratios. The training set is further divided into actual training data (80%) and validation data (20%). This split is also stratified. We also created datasets with two-second sampling intervals by removing alternate data points in each sequence, yielding three additional datasets with a length of 30 (1min), 60 (2min) or 120 (4min) data points respectively. The rationale behind increasing the sampling interval is to introduce greater temporal and spatial distances between the recorded positions, potentially reducing noise in the sequences and its impact on the features calculated in the next subsection."}, {"title": "B. Feature Extraction", "content": "Let ${p_t}_{t=1}^T = {p_1, \u2026,p_T}$ be a sequence of T datapoints (GNSS-samples) that represents a single trajectory in a given dataset. Each datapoint $p_t = [lat_t, lon_t, t_t, acc_t]$ is a vector comprising a timestamp $t_t$ in milliseconds (ms) since epoch, the measured latitude $lat_t$, and longitude $lon_t$ in decimal degrees, as well as the estimated accuracy $acc_t$. To obtain the input sequences for the recurrent neural network, several transformations were applied to the given sequences. To reduce the strong bias arising from the geographical and temporal constraints of the collected data, as well as the limited number of data collectors, each sequence ${p_t}_{t=1}^T$ is transformed to an input sequence ${x_t}_{t=1}^T$ with each input-vector $x_t$ consisting of the following features:\nTime difference: the time elapsed between consecutive measurements in seconds:\n$\u0394t_t = \\frac{t_t - t_{t-1}}{1000}$         (1)\nFor t = 1, we set $\u0394t_1$ to 0.\nVelocity: the interval velocity, representing the rate at which a road user covered the distance between consecutive measurements, in meters per second:\n$v_t = \\frac{s_t}{\u0394t_t}$         (2)\nHere $s_t$ is the great-circle (spherical) distance, which can be calculated by the Haversine formula. For t = 1, $v_1$ is later set to the value of $v_2$ (backward-filling).\nAcceleration: the positive interval acceleration, indicating the increase in velocity of a road user in the current interval compared to the last interval, in meters per square second:\n$a_t = max(\\frac{v_t - v_{t-1}}{(\u0394t_t + \u0394t_{t-1})/2}, 0)$.        (3)\nFor t \u2264 2, we set $a_t$ to 0.\nDeceleration: the negative interval acceleration (deceleration), indicating the decrease in velocity of a road user in the current interval compared to the last interval, in meters per square second:\n$a_t^- = -min(\\frac{v_t - v_{t-1}}{(\u0394t_t + \u0394t_{t-1})/2}, 0)$.        (4)\nFor t \u2264 2, we set $a_t^-$ to 0.\nBearing rate: The absolute rate at which a road user has changed its direction of movement (bearing/heading) since the last interval in radians per second:\n$\u03c9_t = \\frac{\u03c0 - ||\u03b2_t - \u03b2_{t-1}| - \u03c0|}{(\u0394t_t + \u0394t_{t-1})/2}$        (5)\nHere $\u03b2_t$ is the bearing between consecutive measurements, in radians (0 \uc2a8 north, \u03c0/2 east, -\u03c0/2 \uc2a4 west, \u03c0\uc2a8 south). The bearing between two coordinates on a sphere, can be calculated by the following formula:\n$\u03b2_t = atan2(x, y) \u2208 (-\u03c0, \u03c0]$        (6)\nwith\n$x = cos(\\tilde{lat_t}) \u00d7 sin(\\tilde{lon_t} - \\tilde{lon_{t-1}})$         (7)\nand\n$y = cos(\\tilde{lat_{t-1}}) \u00d7 sin(\\tilde{lat_t}) - sin(\\tilde{lat_{t-1}}) \u00d7 cos(\\tilde{lat_t}) \u00d7 cos(\\tilde{lon_t} - \\tilde{lon_{t-1}})$.        (8)\nHere \u0303 indicates, that the coordinates have been converted to radians. For t \u2264 2 $\u03b2_t$ is set to 0.\nNote that if duplicate positions occur in the sequences, this may lead to some $\u0394t_t$ values being equal to 0, which prevents the correct calculation of $v_t$ and $\u03b2_t$. Therefore, the features $a_t$, $a_t^-$ and $\u03c9_t$, which depend on these, cannot be correctly computed either. To tackle this problem, non-computable $v_t$ and $\u03b2_t$ are directly set to their last computable values within the sequence (forward-filling). An advantage of this approach is that the dependent features can be calculated based on the filled values, albeit with a certain degree of error. Finally, the preprocessing of the data is completed by standardizing the calculated features-"}, {"title": "C. Neural Network Architecture", "content": "The goal of this work is to classify each GNSS-trajectory given in the datasets mentioned in section II.A according to the type of road user that generated it. Therefore, each trajectory was transformed to a sequence of input vectors ${x_t}_{t=1}^T$, $x_t = [\u0394t_t, v_t, a_t, a_t^-, \u03c9_t ] \u2208 R^5$, computed according to the formulae in section II.B. Given that the classification task involves sequential data, we opted to use recurrent neural networks, particularly Long Short-Term Memory networks, for our experiments due to their effectiveness in capturing temporal dependencies. Unlike traditional feedforward architectures or convolutional neural networks (CNNs), which are optimized for static or spatial data respectively, RNNs are inherently suited for processing sequential information [25], [26]. While we acknowledge that other architectures such as transformers [27] have shown strong performance in various domains of sequential-processing, we believe that RNNs, offer a simpler, more lightweight architecture suitable for deployment on edge devices with relatively limited computational resources. Moreover, RNNs with LSTM cells are advantageous in this scenario because they are specifically designed for sequential data and can capture the temporal and dynamic nature of positional data. Other alternatives like bilinear neural networks [28], while potentially useful for specific relationships in static data, but typically requiring fixed-size inputs, making them less flexible for variable-length sequences in positional data, are not inherently suitable for modeling time-series data or trajectories where past and future positions are crucial for classification. Since it is difficult to estimate the network's optimal architecture and hyperparameters, a generalized RNN architecture, as shown in Fig. 1, is adopted and later used to consider different network configurations. According to the depiction, the RNNs considered consist of an input and output layer as well as three separate groups of hidden layers. The input layer is fixed to contain exactly five fully connected input nodes, one for each input feature listed above. The output layer consists of exactly four fully connected neurons activated by the Softmax function, each representing one of the possible road user types. By utilizing the Softmax function the value of an individual output neuron can be interpreted as the probability that a sequence, based on every processed timestep up to t, belongs to the class represented by the respective neuron. Regarding the hidden layers, the generalized architecture provides high flexibility for adapting the network, e.g., through hyperparameter tuning. Nevertheless, some structure is provided by the arrangement of the hidden layers into three separate groups. This arrangement is inspired by the RNN architecture proposed by Simoncini et al. in [5]. Accordingly, the input layer is followed by a group of $l_{i\u2192r}$ input-to-recurrent fully connected feed-forward layers, $l_r$ recurrent LSTM cells and $l_{r\u2192o}$ recurrent-to-output fully connected feed-forward layers, finally leading to the output layer. The number of layers in each group ($l_{i\u2192r}, l_r, l_{r\u2192o}$), the number of neurons/units per hidden layer/cell n and the activation function \u03c6(\u00b7) are hyperparameters of the generalized architecture. n and \u03c6(\u00b7) are equally set for every hidden layer, to mitigate the complexity of the hyperparameter tuning process. The idea behind arranging the hidden layers into three groups is as follows: The input-to-recurrent group operates independently on each temporal input. This means it always applies the same (learned) function to each input vector in what can be thought of as a feature extraction phase. In contrast, the recurrent group operates sequence-wise, meaning that it applies a function that depends not only on the current temporal input, but also on the previous state of the group. Since this state depends on every previous input, one can think of this group as the memory of the network, which is meant to decode and store temporally encoded information. The final output of the recurrent group is a reduction of the whole input sequence to a single fixed-length vector, which is subsequently post-processed by the recurrent-to-output group to finally produce the output of the network [5]. It is important to note that networks with the given architecture in fact generate one prediction for each temporal input and can therefore be classified as a sequence-to-sequence RNN. However, with respect to the given classification task, one could consider the network as a sequence-to-vector RNN because its final output provides the most likely prediction. Nevertheless, the sequence-to-sequence design will come in handy when training the networks, because this allows the computation of gradients not solely with respect to the loss of the final output but with respect to the total loss across every temporal output. This increases the number of gradients backpropagated, resulting in an acceleration and stabilization of the training process. Each temporal output of the RNNs represents a probability vector, with values ranging from zero to one and summing up to a total of one. Therefore, categorical cross-entropy is used as the loss function for training optimization. To further accelerate the training, the Adam optimization method is used. To keep the hyperparameter tuning process simple, we use the default parameters proposed in [29]. The training is performed with minibatches of size 32. To prevent overfitting, we implement early stopping with a patience period of 10 epochs. Training halts if there is no further decrease in loss on the validation set during this period. Afterwards, the weights from the epoch with the best loss are restored. The Glorot (Xavier) uniform initialization is used to initialize the model weights. This method has proven effective in mitigating vanishing gradient issues due to neuron saturation during training [30]. To identify optimal hyperparameter configurations, the grid search method is utilized to tune the hyperparameter of the generalized RNN architecture with respect to a specific dataset."}, {"title": "III. EXPERIMENTAL RESULTS", "content": "In this section, we present the experimental results of the hyperparameter optimization as well as the evaluation process and provide an interpretation of the final models."}, {"title": "A. Results of Hyperparameter Tuning", "content": "As already mentioned in subsection II.A, we consider a total of six variants of our dataset for the road user classification task. These variants differ in terms of the sampling interval and the length of the corresponding sequences. Both variables can be thought of as additional hyperparameters for this specific classification task. For each dataset we performed a grid search, as described in subsection II.C, for finding good hyperparameters according to our RNN architecture proposed there. Table III lists the result of this grid search: the hyperparameters yielding the best found RNN model for the specific datasets. Regarding the found hyperparameters, some notable observations can be made.\nWithin this specific classification task, the hyperbolic tangent seems to outperform the ReLU function as activation function \u03c6(\u00b7) for the hidden layers, consistently achieving a lower validation loss.\nThe increase of the sampling interval to two seconds results in a reduction of the validation loss across all sequence lengths. Interestingly, this effect appears to amplify with increasing sequence length (loss differences across the sequence lengths: 0.0028 [1 min], 0.0129 [2 min], 0.0169 [4min]). So, the descent increase of the sampling interval may indeed mitigate the impact of noise on the derived features, yielding a balance between reducing noise and minimizing the loss of information content.\nAdditionally, longer sequences, depending on a constant sampling interval, lead to a significant decrease of the validation loss. We will further discuss the cause of this effect in the next subsection.\nWith respect to the remaining hyperparameters, no clear trends can be inferred from the table. While it appears that the RNNs tend towards deeper input-to-recurrent groups, a single LSTM cell and rather shallow recurrent-to-output groups, there are also individual deviations from these tendencies.\nIn conclusion, the found models (identified by <sampling interval>_<seq. length in min.> (<rank>)) can be ranked by their loss as follows: 2s_4min (1.) < 1s_4min (2.) < 2s_2min (3.) < 1s_2min (4.) < 2s_1min (5.) < 1s_1min (6.)."}, {"title": "B. Model Performance and Interpretation", "content": "Based solely on the validation loss, the best performance in road user classification within the set boundaries was achieved based on the model relying on sequences with a sampling interval of 2s and a sequence length of 120 samples (4min). Normally, the subsequent evaluation would exclusively focus on this best-found model. However, we decided to evaluate multiple models based on the test data within this chapter: specifically, all models referring to a sampling interval of 2 seconds. This comparison is not intended to provide any specific recommendation for model selection but rather to offer insights into the impact of sequence length on the classification performance of the RNNs. The results of the evaluation of these models are presented as Confusion matrices in Table IV. Inherently the number of test sequences used to build these matrices shrinks with increasing sequence length. It should be noted that this may promote random effects, negatively influencing the validity of the derived performance metrics. However, the number of sequences should be sufficient for a rough assessment of the models. We use these confusion matrices to calculate the F1-Scores per class and the overall Macro-F1-Scores for each model and present them in Table V. Unsurprisingly, all models demonstrate excellent performance in classifying pedestrian trajectories, consistently achieving high F1-Scores, with a perfect score of 1.0 for the 2 min model. The 4min model exceptionally achieves the lowest score for pedestrians, due to a single misclassification with the cyclist class, which has a significant impact due to the small size of the test dataset. The models retain a high performance for the cyclist class, particularly excelling for the model using the 4 min sequence length, achieving an F1-Score of 0.9825. However, the positive correlation between the classification performance of the models and the length of the underlying sequences becomes unambiguous when considering the classes of motorcyclists and passenger cars. The consistent improvement in the capability of discriminating trajectories generated by motorized vehicles results in a F1-score of 0.7692 for motorcyclists and 0.8525 for passenger cars. This correlation is also reflected by the consistent increase of the Macro-F1-Score, which especially indicates a robust performance across all classes for the 2 min and 4 min models. To give even further insights into the effect of the sequence length on the classification performance with respect to the specific classes, Fig. 2 plots the ratio of incorrectly classified test sequences against the evaluated sequence length (in timesteps) independently for each of the three models. The curves can be interpreted as representing the error rates of the models for individual classes at a specific point in time during the observation period. Note that all models seem to demonstrate the capability to give a relatively robust pre-categorization into pedestrians, cyclists, and motorized vehicles (motorcycles and passenger cars combined) within a temporal span of just 1 to 5 timesteps. We believe that the models likely base this pre-categorization on the leading velocity-values in the sequences, which, in many scenarios, should be sufficient to make a reasonable preliminary distinction among the three categories. (e.g., a velocity value of 50 km/h is implausible for a pedestrian, relatively unlikely for a cyclist, but typical for motorized vehicles). Among the motorized categories, either passenger cars or motorcyclists appear to serve as the default assumption. This becomes apparent as one of the two classes in all three models initially starts with an error rate close to 1.0, while the error rate of the other class is relatively low right from the beginning. With increasing timesteps, the prediction of all models is inherently becoming more precise. However, with respect to the 1 min and 2 min models the underlying sequence length only seems sufficient for the pedestrian and arguably the cyclist class to reach some form of a plateau. Regarding the motorcyclists and passenger car classes, there appears to be an ongoing downward trend for at least one of both classes across all models, implying that longer sequences would likely result in further improvement of the classification performance. This assumption is supported by our experimental results, as an increase in sequence length (from 1 min to 2 min and 2 min to 4 min) obviously led to better classification performance. It can be assumed that further increase (beyond 4 min) would result in additional, albeit diminishing, improvement. We posit that a precise classification of road users requires sequences of a certain length, because road users appear challenging to differentiate (solely on GNSS data) within many common traffic situations, e.g., think of road users waiting at traffic lights, stuck in traffic or slowed down by preceding cyclists. Distinguishing motorized vehicles, which often display similar behaviors both in specific situations and generally, appears to require longer sequences to increase the likelihood of capturing scenarios, such as acceleration or cornering, that improve predictive accuracy. As indicated by the late reductions of the classification errors in the last chart, such situations may occur late (or do not occur at all) within individual sequences."}, {"title": "IV. CONCLUSION UND FUTURE WORK", "content": "In response to the limitations of traditional road user classification approaches, i.e. approaches that utilize expensive and potentially intrusive fixed-point or mobile sensor systems with low spatial coverage, this work investigated an unintrusive and cost-effective alternative based on LSTM-RNNs applied to high frequency GNSS sequences, collected from general-purpose edge devices such as smartphones. As a starting point, we restricted the classification task to scenarios within the boundaries of medium-sized towns and rural communities, and to four types of road users, namely: pedestrians, cyclists, motorcycles, and passenger cars. The data specifically collected for this study consists of 165 trajectories, amounting to a total duration of approximately 32 hours. The results of the work indicate that our method, which utilized RNNs with LSTM-cells and input-to-recurrent- as well as recurrent-to-output-feed-forward-layers, is capable of reliably classifying pedestrians, cyclists, and motorized vehicles, based on even short sequences. The more granular classification of motorized vehicles into motorcyclists and passenger cars is considerably more challenging. However, the capability to efficiently classify corresponding sequences has shown to improve with increasing sequence lengths. Our method achieves a F1-score of 0.82 for passenger cars and 0.76 for motorcyclists based on sequences of just two-minute length or of 0.85 and 0.77 based on four-minute sequences respectively. By classifying road users not only reliably but also based on a considerably lower duration of observation it therefore demonstrates its potential to outperform existing approaches, that utilize lower-frequency GNSS data. However, the scope of the examined classification task is currently quite limited. Future research should explore the impact of a wider range of road conditions \u2013 such as urban, rural, and highway settings \u2013 on classification performance, as different environments may affect GNSS data characteristics and influence road user behavior. Additionally, expanding the range of road user types to include more vehicle classes, such as buses and trucks, could help validate the model's generalizability across a broader set of real-world applications. While our method offers an effective alternative, it is currently less granular and accurate than state-of-the-art fixed- point and mobile sensor approaches. Since our experiments have been carried out on a considerably small dataset, this may change with more high-frequency GNSS trajectories, featuring more traffic scenarios, becoming available to train the models. Moreover, where applicable, integrating data from other sensors, such as radars and cameras, could further enhance the accuracy and robustness of classification systems utilizing the proposed method. This multi-sensor approach could allow better differentiation, especially between vehicles, and improve performance in complex traffic environments where GNSS data alone may be limited. Furthermore, we hope that 5G positioning for street scenarios will be available in the near future such that we can pursue our original intention. An important consideration not yet addressed in this study is the dynamic nature of road users, who may switch their mode of transportation - and consequently their classification - at any time in real-world traffic, like leaving a car to walk or climbing on a bicycle to get along faster. However, since our networks are designed for sequence-to-sequence classification, the dynamic classification of the transportation mode can be natively achieved with our models by just training them with correspondingly labeled data. Beyond that, future research may apply and extent similar approaches to other related problems, such as driving behavior identification or determining the relevance of road users in an extended environment with respect to a specific autonomous hero-vehicle. Moreover, efforts should include the evaluation of alternative network architectures to further enhance the robustness and performance of the models. This may involve investigating the use of other recurrent cells, such as Gated Recurrent Units (GRU-cells), attention mechanisms [27], or one-dimensional convolutional layers. Finally, it is crucial to address some ethical, legal and privacy concerns associated with our method. Since adversaries can use a similar approach to discover hidden information from road users and use it to re-identify a target, advanced privacy methods may need to be developed to resolve such issues."}]}