{"title": "Maximizing Relation Extraction Potential: A Data-Centric Study to Unveil Challenges and Opportunities", "authors": ["Anushka Swarup", "Avanti Bhandarkar", "Olivia P. Dizon-Paradis", "Ronald Wilson", "Damon L. Woodard"], "abstract": "Relation extraction is a Natural Language Processing task aiming to extract relationships from textual data. It is a critical step for information extraction. Due to its wide-scale applicability, research in relation extraction has rapidly scaled to using highly advanced neural networks. Despite their computational superiority, modern relation extractors fail to handle complicated extraction scenarios. However, a comprehensive performance analysis of the state-of-the-art relation extractors that compile these challenges has been missing from the literature, and this paper aims to bridge this gap. The goal has been to investigate the possible data-centric characteristics that impede neural relation extraction. Based on extensive experiments conducted using 15 state-of-the-art relation extraction algorithms ranging from recurrent architectures to large language models and seven large-scale datasets, this research suggests that modern relation extractors are not robust to complex data and relation characteristics. It emphasizes pivotal issues, such as contextual ambiguity, correlating relations, long-tail data, and fine-grained relation distributions. In addition, it sets a marker for future directions to alleviate these issues, thereby proving to be a critical resource for novice and advanced researchers. Efficient handling of the challenges described can have significant implications for the field of information extraction, which is a critical part of popular systems such as search engines and chatbots.", "sections": [{"title": "I. INTRODUCTION", "content": "Relation extraction is a critical step in the task of information extraction that aims to draw high-level inferences from textual data. As the name suggests, relation extraction involves extracting relationships between target nouns, called entities, that bring forth the semantic meaning of the text. It finds usage in various Natural Language Processing (NLP) applications. For example, relation extraction is widely used in question-answering systems to connect question entities to target answer entities [1]. Such methods are essential for customer support applications like chatbots and digital personal assistants. Similarly, relation extraction is critical for knowledge base (KB) completion [2]. KBs are structured repositories that store data as triplets of entities and relationships (entity1, relation, entity2). KBs find applicability in search engines like Google, Yahoo, and Bing, as they provide an efficient solution for storing large amounts of information to answer search queries. Furthermore, relation extraction can be employed in various other domains to extract knowledge regarding interactions between drugs, proteins, genes, and diseases [3] in biomedical and global industry dynamics [4], [5] in business. Thus, owing to its wide-scale applicability, a plethora of research exists in the domain.\nModern-day relation extractors heavily employ deep learning architectures such as BERT [6], ERNIE [7], and more recently, GPT-3 [8] for extracting complex entity and relation representations from the input data. Regardless, it has been observed that modern relation extractors perform well in simple scenarios but poorly on complicated data and relation types. For example, issues like longer input lengths, multiple relations per sample, overlapping entities, fine-grained relationships, and long-tail data distribution pose challenges that most relation extractors cannot handle efficiently. Although a plethora of traditional surveys that comprehensively summarize the literature exists in this field [9]\u2013[18], [18]\u2013[25], they lack a thorough discussion of the issues faced by the relation extractors and their potential causes. Additionally, the perspective of finding drawbacks in the algorithms rather than concentrating on the data-specific reasons for the challenges is favored in the literature. More importantly, most works focus on very few datasets and algorithm combinations, making it difficult to get a holistic view of the attributes that pose complications for relation extractors [20]\u2013[25]. This also entails that the challenges and future directions proposed by such studies may lack credibility. Consequently, we perform an in-depth data-centric analysis to put the challenges in perspective and provide a navigable guide through the abundance of research in this field for novice readers to find problem areas that require more attention.\nThis paper presents the first data-centric performance analysis that investigates a diverse set of relation extraction algorithms to highlight the complex data attributes adversely affecting them. Compared to the existing studies discussed above, this work aims to investigate the root cause of the issues faced by the algorithms by focusing on the attributes of the data. The study summarizes the most important relation extraction paradigms in the literature and highlights the key challenges and future directions backed by an exhaustive set of experiments. Finally, the goal here is not to find shortcomings in the algorithms but rather to determine the data characteristics that make it difficult for neural relation extractors to detect relationships efficiently. This enables future research that addresses these challenges to help create better relation extractors. Thus, the contributions of this work are as follows:\n1) Comprehensive algorithm comparison and sample level analysis of 15 neural relation extractors, including the much recent LLM-based algorithms on seven large-scale datasets to highlight reasons behind the performance gap in the field.\n2) Extensive discussion on open challenges in relation extraction and future directions to resolve them.\n3) A software repository of datasets and re-implemented LLM-based algorithms shared for practitioners in industry and academia for reproducibility\u00b9.\nThe remainder of the paper is structured as follows. Section II presents an overview of the field by discussing a general pipeline for relation extraction and the research done in this field. Section III gives an overview of the datasets, algorithms, and methodology used to conduct the performance analysis. Also, it details findings from a general performance assessment of the algorithms. Section IV discusses the data-centric performance analysis, which aims to answer where and why modern relation extractors fail. Finally, Section V discusses the research gaps and future directions to further the field of relation extraction. We conclude the paper with some closing remarks in Section VI."}, {"title": "II. BACKGROUND & RELATED WORK", "content": "Relation extraction is the task of extracting relationships between entities [26], [27] from textual data. For example, the sentence \"Eno Raud was the son of the writer Mart Raud.\" depicts the relation son between the entities Eno Raud and Mart Raud. Such relationships provide rich contextual knowledge critical to language understanding. Two types of relations exist in the literature, and a few examples of each category are shown in Table I. First, simple relations describe the semantic relationship between the two entities. Second, directional relations define the semantic relationship and the relation's directionality. For example, the relation Component-Whole(el, e2) represents a relationship between two entities where entityl is a component of entity2. The relation labeling is done using combinations of automatic and manual labeling strategies. Distant supervision, a technique that automatically labels relations by linking entities in the text to entities present in KBs, has been a widely used labeling strategy in this field and is discussed in section II-B.\nThe research in relation extraction has been divided into three sub-domains. The first area deals with classifying relationships between pre-defined entities, also known as relation classification. The second area deals with extracting entities and relations between them as relation triplets (entity1, relation, entity2), known as joint relation extraction. Both algorithms work in a supervised manner wherein the former"}, {"title": "A. Relation Classification", "content": "Relation classification techniques aim to extract semantic relationships between pre-defined entities present in text. Initial research in relation classification began with feature-based and kernel-based algorithms that used low-level NLP features such as part-of-speech (POS) and dependency parsers or developed specialized kernels for the task. These algorithms employed machine learning technologies [10] to classify relationships between pairs of target entities. With the advent of neural networks, research started incorporating deep learning architectures for relation classification. However, the literature has followed a uniform pipeline regardless of technology. A typical relation extractor classifies relationships by extracting feature representations of the input data. The input to a relation classifier consists of relation labels and text samples labeled with entity mentions. The relation labels are converted to numeric integers or verbalized before being used as input by the classifier. The entities in the text sample are annotated through manual labeling or using named entity recognizers such as Spacy and Stanford CoreNLP [31]. The annotation of the type of entity with its position in the text is also prevalent in the literature. The entity-annotated text sample acts as an input to the classifier. Most machine learning relation extractors extract low-level features from the text sample, such as POS tags, WordNet hypernyms, dependency parsers, and words between entities [12]. These features are used as input to the classifier. On the other hand, deep learning relation extractors employ neural network architectures for feature extraction. Neural networks such as convolution neural networks (CNNs) and recurrent neural networks (RNNs) are exceptional in learning complex internal representations from input data. Additionally, long short-term memory networks (LSTMs) that capture long-range dependencies and large language models, such as BERT and RoBERTa, that extract contextual representations of the text sample are employed for extracting meaningful text and entity representations. Subsequently, the extracted features are used to classify text samples into various relational categories using a classification layer. The classification module usually consists of support vector machine (SVM) [9] for machine learning algorithms and simple multilayer perceptrons (MLP) for deep learning algorithms. The classifier generates output scores for all the relation classes. The final relation label is assigned to the top-scoring class.\nResearch in relation classification ranges from machine learning and statistical approaches to more recent neural networks. Although machine learning algorithms could extract semantic relationships from the data, they required considerable feature engineering and manual labor to create handcrafted rules [11]. On the other hand, neural networks could extract complex internal representations from the input text, providing a noise-prone alternative to external NLP features employed by previous methods. Thus, the research focus in this field has predominantly shifted to using neural networks for relation classification. As discussed above, language model-based neural approaches for relation classification extracted complex internal representations of the input data using neural network architectures and used a separate classification head to predict the relationships. Subsequently, a new paradigm was introduced with the advancement of generative language models, especially GPT-3, making it possible to employ the language model as a predictor. Various prompting strategies were used to probe the knowledge present within the language model. The following section discusses the research endeavors in traditional and prompt-based categories."}, {"title": "1) Traditional Approaches:", "content": "Extracting relationships between two entities requires an efficient understanding of relevant information that can be present anywhere in the input sample. Recurrent architectures, such as the LSTM, proved very useful due to their capability of capturing long-range dependencies. Thus, all initial relation classifiers employed LSTM architectures with a fully connected softmax layer for classification. Algorithms such as Attn-BLSTM [32] and CRNN-Att [33] were among the first to provide enhanced solutions to relation extraction by incorporating different strategies of attention mechanisms [34] enabling them to extract essential information present anywhere in the input sample. However, they did not account for the position and presence of the entities in the training process. Subsequent research focused on using entity-specific information, such as position features, to aid the classification process [35], [36]. However, the recurrent architectures lacked at relation classification due to their shorter context window making them prone to forgetting past states. Thus, with the introduction of the transformer architecture [34], pre-trained language models (PLMs) were heavily employed for relation classification.\nPopular PLMs such as BERT and ROBERTa [37] have performed exceptionally well in various NLP tasks. They are trained on large corpora of data using masked language modeling (MLM) styled training and can be easily fine-tuned on smaller task-specific datasets, providing significant performance gains. Initially, PLM-based algorithms for relation classification aimed to understand contextual information with minimum knowledge of the entities and gradually progressed to more advanced forms of additional knowledge. For example, RBERT [38] and RoBERTa-large [39] used contextualized token representations from pre-trained BERT and RoBERTa models and incorporated knowledge about the global position of entities by introducing special tokens at the input level. Subsequently, algorithms started incorporating more advanced forms of knowledge by mapping entities to their knowledge base (KB) counterparts [7], [40]\u2013[42]. The introduction of PLM-based algorithms significantly advanced the research in the field due to the capabilities of the networks to extract and connect contextual representations of the entities and the relations. However, such relation classifiers suffered due to the objective gap between the pre-training and fine-tuning strategies. Most PLM-based relation classifiers used MLM to pre-train the language model, while a classification objective was used for fine-tuning. Prompt-based algorithms were introduced to alleviate the reliance on separate classification modules and use the language models as a classifier."}, {"title": "2) Prompt-based Approaches:", "content": "Prompt-based techniques aim to model the relation classification problem as an auto-regressive text generation task, enabling language models to be predictors rather than feature extractors [43]. This ability is achieved using cloze-style (fill-in-the-blanks) prompts or statements to probe the language model to perform various downstream tasks. A typical prompt consists of a template and verbalizing the label space. The prompt is coupled with the input sentence and made to answer a cloze-style statement. This technique is now widely employed in the NLP literature and has shown great improvements in zero and few-shot learning where training data is scarce. However, adapting the prompting strategy to relation classification has been a challenging task due to the diversity of the large label space. Not only is it difficult to create distinct verbalizations of multiple relations manually, but it is also difficult to fit the large label space in prompts, especially for expensive LLMs such as the GPT variants. Thus, prompt-based approaches for relation classification aimed to alleviate these issues by creating custom prompt-tuning strategies by employing PLMs like BERT, ROBERTa, T5, and BART [24], [44], [45].\nFinally, with the introduction of GPT-3, most research in relation classification has shifted to the use of chat-based LLMs. These algorithms use manually curated prompt templates designed to ask the LLM cloze-style questions. The prompt is oftentimes augmented with selected training demonstrations to carry out few-shot learning [46], [47]. For few-shot learning, various demonstrations are added to the prompt to guide the LLM to better learn the task specifics. This is called the in-context learning (ICL) framework, and research in this subdomain has concentrated on creating better demonstration retrieval strategies for relation classification [48]. Finally, recent algorithms have further tried to advance the field by combining PLMs and LLMs to create better few-shot extractors [49]."}, {"title": "B. Distant Supervision", "content": "The distant supervision paradigm was developed to cater to the need for larger annotated datasets by creating them without human intervention. This was accomplished by aligning training corpora with KBs such as Freebase, DBPedia and Wikidata. Mintz et al. [50] were the first to introduce this paradigm in the context of relation extraction. According to their research, if two entities (el,e2) participate in a relation X present in a knowledge base D, then all sentences from a text corpus C containing (el,e2) will participate in the relation X. This way, large amounts of data could be automatically annotated using relations from knowledge bases. Although this technique attracted much attention, it was built on a stringent assumption that all sentences containing (el,e2) must belong to a given relation. This assumption was prone to falter, leading to the wrong labeling of the datasets.\nMost research in distant supervision revolved around alleviating the problem of noisy labels by finding efficient ways of selecting sentences associated with specific relations. A prominent work done by Riedel et al. [51] relaxed the above assumption and restated the distant supervision paradigm as follows: If two entities (el,e2) belonging to a text corpus C participate in a relation X present in a knowledge base D then out of all the sentences containing (e1,e2) from C, at least one sentence will participate in the relation X. This new assumption significantly helped reduce the number of noisy labels; however, it worked on the assumption that an entity pair could not participate in multiple relations. This assumption faltered when it came to large, distantly supervised datasets. Thus, the multi-instance multi-label (MIML) paradigm for relation extraction was introduced to enable the joint modeling of entities and relations and to combat the problem of overlapping relations [52], [53]. The MIML paradigm emphasized the need and benefits of extracting relations and entities in a single pipeline. Thus, the joint relation extraction paradigm was developed."}, {"title": "C. Joint Relation Extraction Algorithms", "content": "In the literature discussed above, the knowledge of entities was obtained before the relation classification process. However, separate entity extraction strategies can lead to issues like induction of noise, discrepancies in feature space, and loss of critical information about the entities. Therefore, joint relation extraction algorithms were developed to unify the entity and relation extraction pipelines. Initial work in joint modeling employed handcrafted features such as integer linear programming and card-pyramid parsing [12], [54]. The models learned entity representations and used them to extract relations. Model parameters were updated jointly using both entity and relation labels. Subsequently, novel techniques were introduced, such as employing neural networks to better learn global features with little use of syntactic grammar [55]. These methods worked on a table-filling framework and incrementally extracted entities and relations with joint parameter updates. However, the entity and relation extraction pipelines were still separate and created redundant information [56]. The triplet extraction paradigm was introduced to unify the entity and relation extraction pipelines further. It extracted relation triplets in the form of (entity1, relation, entity2) in one go rather than extracting entities and relations consecutively. Novel tagging mechanisms were introduced to extract relation triplets from text [56], [57]. These algorithms were designed as a sequence labeling task and needed humans to design complex tagging schemes [58].\nOne of the primary challenges for the early joint relation extractors was the problem of multiple relations and overlapping entities. The assumption that two entities participate in a single relation in a given sentence is rarely satisfied in real-world data. Relationships can occur in various forms in natural text. For example, the sentence \"Dominican Republic signer and songwriter Juan Luis Guerra led the Latin Grammy Awards nominations followed by Puerto Rico's Ricky Martin\" depicts the relation city of birth between the entities Dominican Republic and Juan Luis Guerra. However, the same relationship exists between Puerto Rico and Ricky Martin. A sentence can exhibit multiple relations by sharing the same or different entities [59]. Entity pair overlap (EPO) and single entity overlap (SEO) are two instances of this problem where multiple relations are shared between both or a single entity. Thus, subsequent research in this field was done to develop relation extractors robust to this issue. Some methods to solve this problem included creating better representation schema for instances with overlap [60], incorporating relational knowledge as apriori to avoid extracting irrelevant entities [39], decomposition-based methods [61], [62] and using the seq2seq paradigm to circumvent the need for triplet extraction in a particular order [58], [58].\nThe triplet extraction paradigm allowed for seamless information sharing of entity and relation types, which helped tackle the problem of entity overlap. However, such models suffered from exposure bias due to the discrepancies in the context provided during training and inference [63]. Thus, subsequent solutions aimed at further unifying the extraction process by introducing various strategies such as token-pair linking and entity-relation interaction modeling [63], [64].\nThis section highlighted the plethora of research endeavors in relation extraction literature. The efforts can be categorized into classification and extraction strategies that aim to classify relationships from a pre-defined label set or extract entity and relation triplets, respectively. The algorithms introduced have progressively advanced over time, each employing a significantly more advanced deep learning backbone than the previous one. The most recent one was the introduction of relation extraction algorithms using OpenAI's GPT-3 architecture, which has shown notable performance in low-resource scenarios. These research efforts have imparted significant gains to the field of relation extraction. However, there is still a considerable performance gap in the field where relation extractors have not reached their full potential. This study hypothesizes that the disparity comes from input data characteristics that pose complicated use cases for relation extractors to tackle. Thus, the study highlights some of these complex data characteristics by looking at a diverse group of relation extraction algorithms and critically examining their effectiveness in extracting relationships from complex textual data. To this end, the next section discusses the methodology used for a data-centric performance analysis and some preliminary insights from it."}, {"title": "III. METHODOLOGY", "content": "This study aims to gain insights into the decision-making process of neural algorithms and highlight challenging data characteristics that potentially inhibit the performance of relation extractors. Thus, exhaustive experiments encompassing 15 relation extraction algorithms and seven datasets were conducted. This section details the methodology used to conduct the analysis and the insights gained from it."}, {"title": "A. Datasets & Complex Data Characteristics", "content": "Seven SOTA datasets from the relation extraction literature were used for this study. The datasets were chosen based on their complex data characteristics. These characteristics deal with the challenging aspects of real-world data that adversely affect the performance of relation extractors. Therefore, it is critical to analyze the performance of the algorithms under such complicated scenarios. To this end, this analysis categorizes the datasets according to the data complexities they exhibit.\nEach selected dataset represents one or more characteristics that challenge the accurate extraction of relations by neural relation extractors. These characteristics include fine-grained relations, long-text samples, multiple relations associated with a sample and overlapping entities, and long-tail data distribution. The datasets were categorized based on these categories. Furthermore, their counter-categories were also created as a baseline for comparison. The details of these categorizations are presented below.\n\u2022 Fine-grained vs. Coarse relations. Fine-grained relation distribution deals with the presence of numerous relations in a dataset. Such a distribution leads to the relation labels having similar meanings and are usually difficult to distinguish from each other. For example, the WebNLG dataset has more than 100 relation labels. The label space includes relationships such as \"chief\u201d and \"leaderName\", which can easily be confused together without a sound understanding of the associated context. Efficient handling of fine-grained datasets is critical for extracting relations from real-world data where numerous relationships can be present, and fine-grained distinction is necessary for discriminating between similar relation types. Thus, datasets with 40 or more relation labels were categorized as fine-grained relation datasets and datasets with less than 40 relations as coarse relation datasets.\n\u2022 Long vs. short input. The number of words or length of the input text sample has been a source of disparity in all NLP tasks. Both long and short inputs can provide complex use cases that might impede the performance of relation extraction algorithms. On the one hand, the short input text is challenging to tackle due to its succinct nature and insufficient knowledge. For example, it is difficult to interpret the relation entity-origin between entities beer and barley from the sentence \"space beer is made from barley grown in space\u201d. On the other hand, long input lengths might cause issues due to conflicting contextual information and the need for a larger context window. Efficient handling of short-input samples can prove to be beneficial when extracting relations from social media platforms like Twitter, where the text lengths are restricted. Similarly, extracting relations from long-input text can be critical to summarizing lengthy text documents abundant in biomedical, finance, and academic fields. Thus, datasets with an average sample length greater than 35 tokens were categorized as long-input datasets. Similarly, datasets with an average sample length of less than and equal to 35 tokens were categorized as short input datasets.\n\u2022 Multiple relations and overlapping entities vs. one-to-one associations. As discussed in Section II-C, text samples incorporating entities that share multiple relation labels are a big concern in the relation extraction literature. The presence of these complex attributes leads to the possibility of multiple correct predictions for a text sample. Efficient extraction of relations shared among the same entities can make algorithms robust to intricate data from business and finance domains, which are abundant with one-to-many associations. Thus, the datasets were categorized into multiple/overlap and one-to-one categories based on the presence or absence of this complex characteristic.\n\u2022 Long-tail vs. uniform distribution. The long-tail data distribution deals with the severely skewed distribution of representative input data for different relations in a dataset. For example, the WebNLG dataset consists of relation classes with only one sample. Such distribution has been known to adversely impact the performance of relation extractors. Efficient handling of long-tail distribution is critical for low-resource applications in NLP, such as clinical information extraction and personality prediction. Thus, the datasets were categorized into long-tail and uniform categories based on the distribution of the data."}, {"title": "B. Algorithms", "content": "SOTA relation classification and extraction algorithms were implemented from the literature to conduct the data-centric performance analysis presented in this study. The algorithms chosen represent the major paradigms present in the domain of neural relation extraction. Thus, they provide a comprehensive view of the literature in this field. The following sections give brief details of the methodology used by these algorithms.\n1) Relation Classification Algorithms: The relation classification experiments were conducted using algorithms ranging from recurrent architectures to modern LLMs. Although LLMs provide significant performance gains for relation classification, it is essential to analyze recurrent algorithms to get a holistic view of the field. Furthermore, existing research only showcases the performance of these algorithms on a select few datasets. Hence, a comprehensive analysis of the recurrent algorithms for their generalizability and robustness to complex data characteristics might lead to novel and crucial insights into the field. Thus, this work utilizes three recurrent architectures.\n\u2022 Att-BLSTM [32], a single-layer bidirectional long short-term memory (BLSTM) network with an attention mechanism to extract the most important information present in the input sample.\n\u2022 PAWARE [35] utilizes entity information by augmenting each token with its relative position to the entities. The algorithm uses a position-aware attention mechanism on the output of a 2-layer LSTM network to create a fine-grained representation of the input.\n\u2022 Entity-BLSTM [36], uses a single-layer BLSTM network with self- and entity-aware attention mechanisms. It incorporates entity-type information using latent topic clustering along with the position features used by PAWARE.\nA crucial area with significant research has been the use of PLMs for relation classification. These algorithms aim to fine-tune SOTA PLMs by introducing various learning strategies. Some of the most high-performing algorithms that have been implemented for this work have been discussed below.\n\u2022 RBERT [38] uses contextualized token representations and sentence encodings from a pre-trained BERT model. It incorporates knowledge about the global position of entities by introducing special tokens at the input level.\n\u2022 Roberta_base [39] presents a RoBERTa-based baseline for relation classification. It introduces various methods of adding entity-related information to the input sentence, such as entity mention and type markers.\n\u2022 LUKE [71] treats entities as separate tokens and uses their contextualized representation with the input tokens. The model used a RoBERTa-base transformer and applied custom pre-training strategies based on entity masking to achieve the relation extraction objective.\n\u2022 ERNIE [7] incorporates information about entities by mapping them to their knowledge base (KB) counterparts. It uses a dual encoder strategy in which the first encoder (BERT) creates holistic input representations, and the second decoder injects external knowledge from the KBs.\nWith the popularity of decoder-based algorithms, relation classification was transformed into a language generation task using various prompt-based algorithms. These algorithms target both supervised and few-shot learning paradigms. Two SOTA prompt-tuning algorithms have been explored for this study.\n\u2022 KnowPrompt [44] incorporates knowledge contained in relation labels by using virtual answer words. The representation of these words is optimized using a RoBERTa model by calibrating them with respect to the context words.\n\u2022 GenPT [45] reformulates relation classification as a text-infilling task compared to the masked language modeling style used by other prompt tuning methods to eliminate rigid prompt restrictions. The algorithm uses an entity-guided decoding strategy to align the generated sequences with the predefined labels, making the prediction process more effective. The algorithm experiments with Bart [72], T5 [73], and RoBERTa-base PLMs, with ROBERTa achieving the highest performance.\nFinally, two LLM-based algorithms were utilized for this study. These algorithms target the few-shot learning paradigm and employ chat-based LLMs. It must be noted that the SOTA algorithms in the relation classification literature are still constrained to the use of GPT-based models. Thus, both the selected algorithms use GPT-3.5 architectures.\n\u2022 GPT-RE [74] utilizes sentence similarity (simCSE [75]) with a KNN-based demonstration retrieval strategy to perform in-context learning with a GPT-based architecture. The study also introduces the use of relation representations from PLMs, such as BERT, that are finetuned for the RE task to extract relevant demonstrations. However, due to the unavailability of the source code, only the sentence similarity paradigm was used in this study.\n\u2022 UnleashLLM [46] exploits GPT-3.5 for relation classification by creating prompts with task-related instructions with the complete label list. The entity types are also embedded within the demonstrations. The study also proposed a data augmentation strategy, which has not been implemented for this study due to resource constraints.\n2) Joint Relation Extraction Algorithms: To analyze the performance of the joint relation extraction paradigm, four SOTA encoder and decoder-based algorithms were utilized for this study. It was found that the few studies that used prompting and LLMs for this task did not have publicly available source code and sufficient instructions for reproducibility. Thus, prompting-based joint relation extractors have not been investigated in this study. The algorithms in this category have been discussed below.\n\u2022 SPN4RE [58], an improved decoder-based algorithm that eliminates the need for ordered triplet extraction using a non-autoregressive decoder. The decoder is bidirectional and is composed of stacked identical transformer layers. The algorithm also introduces a bipartite loss function invariant to any permutation of predictions.\n\u2022 TDEER [61] is a decomposition-based algorithm that uses a translating layer to map the generated sequence of labels to the final output, considering the dependencies between entities and relations. A binary classifier predicts all entities' start and end positions, followed by a multi-label classifier to extract multiple relations associated with an input sample. Additionally, it incorporates a negative sampling strategy to address the accumulation of errors at various stages.\n\u2022 RIFRE [62] uses a decomposition strategy, which is enhanced by making use of a graph neural network (GNN) and adding knowledge of the relations before extraction.\n\u2022 UniRel [64] uses a BERT-base encoder to encode contextual representations of entities, relations, and the input sentence. It models entity-entity and entity-relation interactions using the self-attention mechanism of a transformer."}, {"title": "C. Experimental Methodology", "content": "This performance analysis aims to answer where, how, and why neural models fail to extract relations from textual data. For this, 15 neural relation extraction algorithms were selected to extract relations from the above-mentioned datasets. The algorithms were re-implemented using open-source codes available on GitHub. Algorithms such as PAWARE, Roberta_base, and UnleashLLM required entity type information, which was only available for TACRED and RETACRED datasets. Thus, the NER tool from Stanford CoreNLP [31] was used to annotate the other datasets with the entity type information. However, even this endeavor could not categorize all entities with their corresponding types, and many entities were annotated with the unknown ('O') entity type. The statistics of this entity annotation process are available in Table XII in the Appendix. Also, the annotated datasets have been released with the source code. Finally, adjustments were made to the algorithms to accommodate for the incomplete entity-type information. Detailed implementation details of the affected algorithms can be found in Section A in the Appendix. The subsequent methodology can be divided into two categories: 1) Supervised and 2) Few-shot learning strategies.\n1) Supervised Strategy: For supervised learning, the relation classification algorithms were categorized into Recurrent, PLM-based, and Prompt-PLM approaches, and all joint extractors were evaluated individually. These algorithms were trained in the supervised setting, where the complete training and development sets were utilized during fine-tuning of these models. The training was done using 5-fold cross-validation with hold-out testing. Most datasets were used as-is, but FewRel was restructured to make it compatible with the supervised pipeline used for this analysis. Specifically, 100 instances from each class were sampled for the training set and 200 for the validation and test set [7]. Also, for joint relation extractions, the duplicate samples in the datasets were grouped together, and their corresponding relations were restructured in the form of entity and relation triplets.\nFor evaluation, micro-averaged F1 scores without the contribution of the negative class were used to analyze both relation classification and joint relation extraction algorithms based on the trend in the literature. Also, the \"exact\" match criterion was used to match the predicted triplets with the ground truth triplets [76] for the joint extractors. The predicted triplets were matched using both head and tail tokens of the entities and the relation between them.\n2) Few-shot Strategy: Similarly, more recent algorithms were utilized for few-shot learning and categorized into prompt and LLM-based approaches. The few-shot strategy deals with training algorithms using a small subset of the original training data in a low-resource setting. They have been tagged as Prompt-PLM and Prompt-LLM. Both PLM and LLM-based algorithms utilizing prompts were trained using this strategy. The GenPT algorithm was trained using Bart, T5, and RoBERTa. However, only the RoBERTa models were used for the data-centric analysis as they consistently performed well on most datasets. To create a basis for comparison with the traditional approaches, algorithms RBERT and RoBERTa_base (some of the best algorithms from the supervised category) were also trained using this setting and were categorized as PLM-based algorithms.\nFor this study, 1, 5, 10, 20, and 30-shot datasets were created by random sampling from each class. The sampling used three seed values (13, 42, and 100). Thus, experiments were"}, {"title": "D. Results", "content": "The trained algorithms were made to predict relationships from the test samples of the selected datasets. This section highlights some findings from analyzing the performance of the algorithms to show the validation of the conducted experiments and highlight any intersections or deviations from trends in the literature. To this end", "setting": "First"}, {"setting": "Next, in low resource settings, it was found that the Prompt-PLM algorithms consistently performed well on the relation classification task across the k-shots used for training/demonstrations as depicted by Table XVI. Two major inferences can be drawn from this finding. First, traditional PLM-based algorithms are inefficient at extracting relationships from textual data in low-resource scenarios, as seen by the low comparative performances of these algorithms. Second, converting the relation extraction objective to a language generation objective has significant benefits that best come into play without considerable training data.\nFinally, the performances of the LLM-based algorithms were found to be highly volatile and depended on the properties of the target datasets. Although the algorithms DeepKE and GPT-RE showed performance gains for some dataset combinations, especially in the 1-shot setting, making these algorithms compatible with the task was difficult. First, the performance scores depicted in Table XVI for the LLM-based algorithms had to be calculated from a smaller subset of the test data because of the tendency of the LLMs to generate out-of-domain predictions that were not a part of the original label space. Thus, such samples had to be discarded from the performance calculation. This issue is evident by the extremely low performance on the TACRED and RETACRED datasets, which have complicated label space verbalization. Second, it was impossible to fit the full label space into the input prompt, especially for the larger dataset. Thus, the DeepKE algorithm could not be evaluated in a greater than 1-shot setting. This observation highlights the inefficiency of the LLM-based algorithms for relation classification, where it is common to"}]}