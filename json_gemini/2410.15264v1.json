{"title": "AI Can Enhance Creativity in Social Networks", "authors": ["Raiyan Abdul Baten", "Ali Sarosh Bangash", "Krish Veera", "Gourab Ghoshal", "Ehsan Hoque"], "abstract": "Can peer recommendation engines elevate people's creative performances in self-organizing social networks? Answering this question requires resolving challenges in data collection (e.g., tracing inspiration links and psycho-social attributes of nodes) and intervention design (e.g., balancing idea stimulation and redundancy in evolving information environments). We trained a model that predicts people's ideation performances using semantic and network-structural features in an online platform. Using this model, we built SocialMuse, which maximizes people's predicted performances to generate peer recommendations for them. We found treatment networks leveraging SocialMuse outperforming AI-agnostic control networks in several creativity measures. The treatment networks were more decentralized than the control, as SocialMuse increasingly emphasized network-structural features at large network sizes. This decentralization spreads people's inspiration sources, helping inspired ideas stand out better. Our study provides actionable insights into building intelligent systems for elevating creativity.", "sections": [{"title": "Challenges and Our Solutions", "content": "The key reasons why explorations of AI and creativity in self-organizing social networks remained under-addressed in literature can be broadly organized into two categories: (i) data collection and (ii) intervention design challenges.\nData collection challenges. First, it is challenging to curate datasets in the wild that contain explicit and unambiguous observations of creative network edges, i.e., the links between social sources of creative inspiration and the corresponding recipients. People may find inspiration from human and non-human sources and may not leave"}, {"title": "Intervention design challenges", "content": "Our prior experiments show that cognitive, network-structural, and psycho-social contextual factors can influence creative performances in social networks [22\u201324]. However, designing interventions to \u2018tweak' the contextual factors toward ideation advantage is non-trivial:\nFirst, different contextual features affect creative outcomes differently in an intertwined manner, making intervention design difficult. For instance, there is a tension between semantic forces that can help one's creativity and social network structural forces that can inhibit it [22]. Drawing from the Associative Theory of creative cognition, external stimuli that are semantically different from one's own ideas may help a person access concepts in their long-term semantic memory that they could not on their own, potentially inspiring novel ideas in that person [3, 6\u20138, 11] (please see Supplementary Text for more details). In social networks, the ideas of the most creative performers tend to have large semantic distances from commonly generated ideas [22]. Thus, generating peer recommendations based on idea-level semantic distances can lead to the best performers being recommended to others in the network at a disproportionately high rate.\nHowever, a network structural counter-effect can simultaneously kick in: most people themselves tend to seek inspiration from the highest performers as they self-organize in the network [22]. This tendency increases the overlap in people's inspiration sources, which, in turn, increases redundancy even in their independently-generated ideas. The simple peer-recommendation heuristic of leveraging semantic distances to maximize stimulation chances can thus worsen the redundancy problem. Moreover, psycho-social contextual factors (e.g., effects of homophily and popularity cues) can also affect network connection evolution and idea redundancy patterns in social networks [23, 24], further complicating the intervention design problem. How an AI"}, {"title": "Overview of SocialMuse", "content": "At a high level, the SocialMuse system combines a (i) Performance score prediction module with a (ii) Recommendation generation module. The system flowchart is\nPerformance score prediction module. We compile a dataset from our previous experiments to train and test a performance score prediction model (total Ne = 360 egos, see Methods for details) [22\u201324]. We build on the simple intuition that people strive to generate ideas that stand out from prior ideas in a given task or prompt. Therefore, we take 'marginal distinct idea count' as the target score in our prediction, operationalized by the number of new ideas an ego generates during attempt 2 of a given round against the pool of distinct ideas submitted by previous egos who completed that round. Each ego ei contributes four data points with target scores se, capturing their marginal distinct idea counts in rounds t \u2208 {2,3,4,5}.\nAs input features of those data points, we consider (i) semantic features from round t-1 (computed from the round t -1 ideas of ego ei and the actual alters they followed in round t) and (ii) network structural features from round t (computed from the round t network comprising the alter connections of the egos upto and including ei). In essence, we capture how the most recent semantic and network contextual features affect an ego's marginal distinct idea counts in a given round t of idea generation. We find an XGBoost model (M) to produce the best test-set prediction performance with R2 = 32.58%. The details of model training are provided in the Methods section."}, {"title": "Validation Experiment Setup", "content": "We conduct a randomized controlled experiment in the virtual laboratory with (i) AI-informed treatment and (ii) AI-agnostic control conditions. We use the same data collection framework explained in the 'Challenges and Our Solutions' Section. We collect data from ten independent trials, each comprising 6 alters, 18 egos in the treatment condition, and 18 egos in the control condition (total N = 420). Egos from both conditions within a trial seek inspiration from the same set of alters, where they can view the pseudo-usernames and text-based ideas of the alters in the same order. In"}, {"title": "Results", "content": "The AI seeks to boost an ego's marginal distinct idea count in attempt 2 of the upcoming round against the cumulative idea pool of prior egos who completed that round (all attempts combined). Therefore, we report the egos' performances in attempt 2 in the following analyses. We find that the marginal distinct idea counts of the treatment egos (per ego per round) are indeed significantly higher than those of the control egos (Figure 4(A); \u03b2 = 0.46, SE = 0.1, P < 0.001; linear mixed-effects model; Supplementary Table S1). Furthermore, the marginal distinct idea counts show a significant downward trend as the networks grow larger (i.e., as more egos asynchronously complete the experiment; \u03b2 = \u22120.13, SE = 0.01, P < 0.001; linear mixed-effects model; Supplementary Table S2). This intuitively makes sense since contributing new ideas becomes more difficult as the roundwise pool of prior ideas grows with an increasing network size. The marginal distinct idea counts do not vary significantly across rounds.\nWe examine the non-redundant idea counts of the egos, where an idea is defined as non-redundant if submitted by only one ego out of all the 18 egos in the network who eventually complete the study (both attempts combined). We find that the treatment egos significantly outperform the control egos in this metric (Figure 4(B); \u03b2 = 0.40, SE = 0.1, P < 0.001; linear mixed-effects model; Supplementary Table S3). In other words, while the AI focuses on optimizing an ego's marginal number of distinct ideas against prior egos (and not future egos), the ideas of the treatment egos remain non-redundant more successfully than the control egos once all egos complete the study.\nUltimately, at a network level, the treatment egos collectively accumulate significantly more distinct ideas per round than their control counterparts (\u03b2 = 8.70, SE = 1.78, P < 0.001; linear mixed-effects model; Supplementary Table S4).\nBoth marginal distinct idea count and non-redundant idea count metrics assess the novelty of an idea based on how 'rare' it is against socially generated idea pools. This social rarity-based scoring approach falls short in accounting for an idea's semantic and subjective qualities. Therefore, to complement the above analysis, we next examine the semantic properties of the egos' ideas using the Creativity Quotient (CQ) metric. CQ employs information-theoretic measures to quantify creativity based on the semantic diversity of one's idea set (higher CQ indicates better creativity; see"}, {"title": "AI-driven networks are more decentralized than AI-agnostic networks, but not perfectly egalitarian", "content": "The bipartite network among the egos and alters is initialized with a perfectly decentralized (egalitarian) structure, where all alters have the same number of ego-followers in the first round. Namely, as the egos join the experiment asynchronously, the network structure in Figure 1(A) is used to initialize their alter connections in round 1. From there, the egos in both conditions choose their own alters to take inspiration from in the subsequent rounds. Although there are five rounds of idea generation, the"}, {"title": "Network structural features impact AI decision-making more in larger networks", "content": "The performance score prediction model in SocialMuse employs two broad categories of input features: semantic and network structural features. We use SHapley Additive exPlanation (SHAP) values [31, 33] to probe how the two categories of features affect the AI-driven peer recommendations. SHAP values help attribute a prediction to different features and quantify the impact of each feature on the model output.\nFigure 6(A) shows the fraction of AI-generated recommendations dominated by semantic features across different network sizes. We consider network sizes 2 to 18 for this analysis since comparing the impacts of the two categories makes less sense for a network size of 1 (which has no meaningful network structural information). As the network size grows, the dominance of the semantic category depicts an inverse U-shaped trend, peaking at around the network size of 8. Beyond this peak, the network"}, {"title": "Being recommended boosts one's novelty ratings", "content": "In the treatment condition, different alters can be recommended to different egos for the same future round based on the differences in relevant contextual factors. Furthermore, the alters' ideas are shown to all egos identically in the rewiring stage of each round, where the egos rate all of the shown ideas on novelty before submitting their alter-followee choices. This setting allows us to systematically probe whether the recommendations have any causal impact on the egos' perception of the alters' ideas. To test this, we analyze whether the same idea from the same alter receives any different novelty ratings from the treatment egos when the alter is recommended versus when they are not recommended. We find that being recommended significantly boosts novelty ratings received by an alter's ideas (\u03b2 = 0.042, SE = 0.013, P < 0.001; linear mixed-effects model; see Supplementary Table S8). In other words, the egos perceive an alter's ideas to be more novel when they are primed by the peer recommendations on the screen. Importantly, this finding paints a picture of how the AI-generated recommendations influence ego behavior in the experiment."}, {"title": "Discussion", "content": "Our findings contribute to (i) the scientific study of creativity in self-organizing social networks and (ii) the practical scope of building intelligent peer recommendation systems to elevate creativity in this setting. We trained a supervised learning model that predicts ideation performances based on semantic and network structural features. Using this model, we built a peer recommendation engine, SocialMuse, that maximizes people's predicted performance scores to make peer recommendations. Through a randomized controlled experiment, we showed that AI-informed treatment networks leveraging SocialMuse significantly outperformed AI-agnostic control networks on several measures of creativity. We further found that the treatment networks were more decentralized at large network sizes than control networks, partly due to the AI model increasingly prioritizing network-structural features at large network sizes."}, {"title": "Methods", "content": "SocialMuse System\nPerformance score prediction model training. Training data. We trained a regression-based prediction model using the data from three of our previous experiments [22\u201324]. Namely, we curated data from the (1) 'Dynamic' condition of [22], (2) both conditions of [23], and (3) 'Baseline' condition of [24]. Each prior experiment had several independent networks of 18 egos, leading to a total of Nprior = 360 egos in the curated dataset. The egos asynchronously completed their tasks of generating ideas on the five prompt objects in five rounds (the prompt objects and their sequence were consistent across experiments). The ideas in the dataset are annotated so that the same ideas are assigned the same unique idea ID.\nTarget score. We reanalyzed the prior data to calculate the 'marginal distinct idea count' of each ego in each round as the target score in our prediction. To capture this, we added the egos to their 18-ego networks one at a time (in the order in which they completed the original experiments). This generated a growing pool of ideas for each round as the egos were added to the network. Each ego was scored on the number of new ideas they contributed to this pool in attempt 2 of each round. Thus, each ego ei contributed four data points with target scores st capturing their marginal distinct idea counts in rounds t \u2208 {2, 3, 4, 5}.\nInput features. As input features of these data points, we considered (i) Semantic and (ii) Network structural features.\nRecommendation generation module. During deployment, at the end of round t - 1, SocialMuse recommended an ego two alters to follow (out of six) in the upcoming round t. Each trial in our validation experiment had na = 6 alters, and the ego needed to follow exactly k = 2 of them at the end of each round. This lead to (a) = 15 alter-pair alternatives. Given the small search space, we took a brute-force search approach to find and recommend the most promising alter-pair to each ego in each round. To operationalize this, we constructed 15 sets of network features from 15 \u2018hypothetical' network structure alternatives that would emerge if the ego followed the different alter-pair options. Namely, for each alter-pair alternative, we added the two ego-alter connections to the network structure emerging from the connection choices of prior egos in round t. We computed the networkstructural features (the ones listed above) from that hypothetical network. We also computed semantic features from round t -1 for each of those 15 configurations (same"}, {"title": "Validation Experiment", "content": "We recruited 420 US-based participants from Prolific. There were 10 trials with independent participants. Each trial had 6 alters, 18 egos in the treatment condition, and 18 egos in the control condition. Participants were randomly assigned their roles (alter/ego) and study conditions. The race distribution was: White: 314, Black or African American: 53, Asian: 22, two or more races: 7, other: 24. The gender distribution was: female: 177, male: 238, other: 5. The age distribution was: 18-24: 45, 25-34: 178, 35-44: 116, 45-54: 51, 55+: 30. Two-sample Chi-squared tests did not show any detectable difference in the race, gender, or age distributions across the control and treatment conditions (P > 0.05 for each demographic variable). Thus, any observed differences among the study conditions cannot be systematically attributed to differences in the distributions of the demographic categories.\nCreativity task. Unlike convergent thinking, which requires individuals to zero in on known correct answers (as tested in traditional school exams), divergent thinking leads"}, {"title": "Measures", "content": "Measuring creative performance. We used four complementary metrics for quantifying creative performances, as commonly employed in the literature: marginal distinct idea count, non-redundant idea count, Creativity Quotient, and SemDis scores.\nMarginal distinct idea counts and non-redundant idea counts. We first discarded inappropriate submissions that did not meet the specified requirements. Since the same idea can be phrased differently by different people, we collected or 'binned' the same yet differently phrased ideas together under common bin IDs.\nCreativity Quotient (CQ). This metric builds on the intuition that if a participant's ideas are very similar to each other, they are likely subtle variations of a small number of semantic categories.\nConcepts are organized as syn-sets or synonym sets in WordNet, where the nouns are linked with \u2018is a' relationships. We removed stop-words and punctuation from the ideas and ran a spell-checker.\nNext, we split the ideas into their constituting set of concepts and converted the terms into nouns for availing the 'is a' relationships. We then computed the information content of those concepts. The taxonomic organization of WordNet implies that concepts with many hyponyms convey less information than concepts with fewer hyponyms [74]. Therefore, infrequent concepts at the leaf nodes hold more information than their abstracting nodes. The Information Content, I, of a concept c can thus be calculated as,\n$$I(c) = \\frac{\\log(\\frac{w}{h(c)}+1)}{\\log(w)} = 1 - \\frac{\\log(h(c) + 1)}{\\log(w)}$$"}, {"title": "", "content": "where h(c) is the number of hyponyms of c, and w is the total number of concepts in WordNet. The denominator normalizes the metric against the most informative concept to ensure I \u2208 [0, 1].\nNext, we calculated the semantic similarity of each pair of concepts in the idea-set, C1 and C2, as [75],\n$$sim(C_1, C_2) = 1 - \\frac{I(C_1) + I(C_2) - 2 \\times sim_{MSCA}(C_1, C_2)}{(I(c_1)"}, {"title": "", "content": "where sim(C1, C2) is a function of the information overlap between the two concepts, simMSCA(C1, C2). This overlap is calculated using the information content of the Most Specific Common Abstraction (MSCA) that subsumes both concepts,\n$$sim_{MSCA}(C_1, C_2) = \\frac{max}{c' \\in S(C_1, C_2)} I(c'),$$\nwhere S(C1, C2) is the set of concepts subsuming c\u2081 and C2.\nGiven the pair-wise concept similarities, we computed the multi-information, Im, as the shared information across the idea set. We crafted the max spanning tree from the network of concepts and their pairwise similarity values. We summed over the edge weights in the max spanning tree to get Im. Finally, we calculated Qas,\n$$Q = N - I_m,$$\nMeasuring inequality in the alters' follower counts. The popularity of an alter i is defined by his/her share of followers,\n$$G = \\frac{{\\frac{1}{2S^2} \\sum_{i=1}^{S} \\sum_{j=1}^{S} |m_i - m_j|}}{{\\frac{1}{S} \\sum_{k=1}^{S} m_k}}$$"}, {"title": "Supplementary Text", "content": "Cognitive basis of creativity. The classic Associative Theory posits that people's semantic memory (a long-term memory system) stores concepts in a meaningful way, where related concepts are more strongly connected than unrelated ones [1-5]. Given an idea-generation prompt, a person's cognitive processes scan the local neighborhood of relevant concepts in their semantic memory and help generate an initial set of ideas [6].\nAfter depleting these initial obvious ideas, a person can arrive at original ideas by accessing remote concepts and recombining various aspects of those non-obvious concepts into novelty [7-9].\nThis long-term memory circuitry can be stimulated by external priming, triggering additional ideas one could not think of on their own [10-12]."}]}