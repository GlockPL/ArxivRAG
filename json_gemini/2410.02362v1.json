{"title": "A Comprehensive Survey of Mamba Architectures for Medical Image Analysis: Classification, Segmentation, Restoration and Beyond", "authors": ["SHUBHI BANSAL", "SREEHARISH A", "MADHAVA PRASATH J", "MANIKANDAN S", "SREEKANTH MADISETTY", "MOHAMMAD ZIA UR REHMAN", "CHANDRAVARDHAN SINGH RAGHAW", "GAURAV DUGGAL", "NAGENDRA KUMAR"], "abstract": "Mamba, a special case of the State Space Model, is gaining popularity as an alternative to template-based deep learning approaches in medical image analysis. While transformers are powerful architectures, they have drawbacks, including quadratic computational complexity and an inability to efficiently address long-range dependencies. This limitation affects the analysis of large and complex datasets in medical imaging, where there are many spatial and temporal relationships. In contrast, Mamba offers benefits that make it well-suited for medical image analysis. It has linear time complexity, which is a significant improvement over transformers. In sequence modeling tasks, computational complexity grows linearly with the length of the input sequence. Mamba processes longer sequences without attention mechanisms, enabling faster inference and requiring less memory. Mamba also demonstrates strong performance in merging multimodal data, improving diagnosis accuracy and patient outcomes. The paper's organization allows readers to appreciate Mamba's capabilities in medical imaging step by step. We begin with clear definitions of relevant concepts regarding SSMs and concept models, including S4, S5, and S6. We then explore Mamba architectures, including pure Mamba, U-Net variants, and hybrid models that combine Mamba with convolutional networks, transformers, and Graph Neural Networks. Subsequent sections cover Mamba optimizations, techniques such as weakly supervised and self-supervised learning, scanning mechanisms, and a detailed analysis of applications across various tasks. We provide an overview of available datasets and several experimental results regarding Mamba's efficacy in different domains. Furthermore, we detail the challenges and limitations of Mamba, along with other interesting aspects and possible future directions. The final subsection explains the importance of Mamba in medical imaging and provides an analysis and conclusions regarding its usage and enhancement measures. This review aims to demonstrate the transformative potential of Mamba in overcoming existing barriers within medical imaging while paving the way for innovative advancements in the field.", "sections": [{"title": "Introduction", "content": "In recent few decades, there has been a remarkable improvement in the field of medicine through the application of machine learning [111] as well as deep learning [114]. The initial architectures of neural networks like Convolutional Neural Networks (CNNs) [82] played a pivotal role in better image segmentation [74], classification [79, 106], and object detection [81]. Medical images are complex, but CNN's were able to analyze 3D structures in a 2D plane and so proved useful in biomedical image computing especially into image segmentation [108], tumor detection [17], organ segmentation [160], and disease diagnosis imaging [16]. CNNs have been applied extensively to medical imaging tasks, namely segmentation, classification and reconstruction. One weakness, however, is that they can lack when sequencing data, or multitasking which requires long-range dependencies. For example, in the area of medical image segmentation, the use of CNNs may not perform well as one would expect since they may not be able to model super-resolution inter-dependence of an image and its parts.\nSome of the drawbacks of CNNs have been addressed by transformers [107, 124] as advancements of technologies that have better sequential data processing and long-range dependencies. Still, there are some disadvantages as well. The main problem is the scaling of computed attention which grows quadratically with the sequence length, thus makes the use of such attention costly and hard on sequences that are very long. Moreover, many additional resources and data are usually needed, which is quite a problem if one has to work in a resource-restricted environment such as in the medical domain. In regard to the shortcomings of classical CNNs and transformers, there has been noticeable progress in research on different types of models which could efficiently represent the long sequences and their intricate dependencies. Of late, State Space Models (SSMs) [47] have gained much attention as one of such alternatives as the Mamba [45] model.\nMamba, aims to address the problems related to modern deep learning techniques. Selective state spaces are employed to quickly assimilate vast lengths of sequences, combine various modes and command extensive yet practical resolutions. The architecture of Mamba incorporates selective scan mechanism and hardware aware algorithm which support high efficiency in storage and computation of the intermediate results. This helps Mamba perform very well in some tasks such as medical image segmentation [128, 134, 138], classification [44, 99, 150], synthesis, registration and reconstruction [62, 83, 162] where long range dependency and high complexity is involved. Mamba has performed promisingly well in the biomedical field, especially in the fields of biomedical imaging, genomics and processing clinical notes. Thus, the model comes in handy in capturing long range and multi-modal data oriented tasks which involve subtle relationships and dependencies between units of information.\nThere exist several survey papers on Mamba. However, these might do either of the following works [101, 104] cover the framework broadly or are restricted to its use only in the vision domain [87, 140, 153]. It is worth noting that only [56] provided a review of Mamba which was focused on its uses in medical domain. However, our survey paper is more extensive and detailed than those of [56]. In particular, the present work emphasizes the analysis of public resources such as medical datasets, and presents some empirical data on the applicability of Mamba within medical practice, including various resources and interventions to be utilized within Mamba in a healthcare context. In addition to this, we include the latest research and developments of Mamba architectures for medical image analysis. Moreover, we have structured our work in such a way that readers will appreciate the organizational spans of Mamba including its strengths, weaknesses and prospects within the medical arena.\nIn this survey, we focus on use, methods and problems of Mamba state space models within the medical domain. We provide a complete overview of the current state of development of this direction, focusing on determining the advantages and disadvantages of the Mamba models, as well as their future prospects. The rest of the paper is organized as follows. Section 2 discusses the key terms related to SSM, different Mamba architectures are explained in Section 3.1. Several Mamba optimizations are discussed in Section 3.3. Several techniques such as weakly supervised, semi-supervised, self supervised, contrastive learning, and multimodal learning are explained in Section 3.4. Different scanning mechanisms in Mamba are discussed in Section 3.2, several applications in different domains are explained in Section 3.5. Datasets are summarized in Section 4. Experimental results showing Mamba performance across different tasks are discussed in Section 5. Limitations and emerging areas are explained in Section 6, finally we conclude the work by giving future directions in Section 7."}, {"title": "Core Concepts of SSM", "content": "In the realm of deep learning, Transformers have consistently dominated in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. The self-attention [124] mechanism within Transformers has greatly improved the understanding of these modalities by generating an attention matrix from the query, key, and value vectors. While the attention matrix is beneficial, it suffers from quadratic time complexity. The recent advancements, such as FlashAttention by Dao et al. [20, 21] and linear attention [72], have addressed this issue by reducing the time complexity. For instance, in linear attention, the key is multiplied by the value instead of the query, and the softmax function is replaced with a similarity function. Mamba developed by Gu et al. [45] further mitigates this problem by transforming the quadratic time complexity into linear time complexity in a recurrent manner. Mamba is the first model without attention to match the performance of a very strong Transformer. The core concepts of Mamba and its derivation from SSM are explained in the following sections."}, {"title": "State Space Models", "content": "State Space Models (SSMs) uses an approach similar to Kalman filter [71]. SSMs convert a one-dimensional input sequence u(t) into an N-dimensional continuous latent state x(t), which is then projected into a 1D output signal y(t). The entire process of a state space model can be represented as shown in Equation 1 and Equation 2:\nx'(t) = Ax(t) + Bu(t)\n(1)\ny(t) = Cx(t) + Du(t)\n(2)\nParameters A, B, C, D are initialized differently in SSM models such as S4, S5 and S6. To apply a discrete input sequence u(uo, u\u2081, ...), instead of a continuous function u(t), the sequence should be discretized using a parameter \u2206, known as the step size. This process also involves discretizing parameters (A, B, C, D). In the following sections, we discuss each model and its specific discretization steps."}, {"title": "Structured State Space Sequence Models (S4)", "content": "S4 proposed by Gu et al. [47] demonstrates how to efficiently compute all forms of the SSM: the recurrent representation, and the convolutional representation. Additionally, S4 employs a bilinear method for discretizing the parameters of the SSM, converting the state space parameter A into an approximation A. In S4, the parameter D from the original state space model is either set to 0 or used as a residual connection.\nThe discrete SSM can be expressed in its recurrent form as shown in Equation 3 and Equation 4.\nxk = \\overline{A}xk-1 + \\overline{B}uk \\overline{A} = (I \u2212 \u2206/2\u00b7 A)^{-1}(\u0399 + \u0394/2 \u00b7 A)\n(3)\ny_k = \\overline{C}xk \\overline{B} = (I \u2212 \u0394/2 \u00b7 A)^{-1}(\u0394\u0392)\n\\overline{C} = C\n(4)\nUnrolling the equation above leads us to the convolutional aspect of S4 in Equation 5 & Equation 6.\nxo = Buo X1 = \\overline{A}Bu0 + Bu1\nX2 = \\overline{A}^2Bu0 + \\overline{A}BU1 + Bu2\n(5)\nYo = CBuo Y1 = C\\overline{A}BU0 + \u0421\u0412\u04381\ny2 = CA^2Bu0 + \u0421\u0410\u0412\u04181 + CBU2\n(6)\nThis can be vectorized into a convolution as shown in Equation 7 & Equation 8 with an explicit formula for the convolution kernel as shown in Equation 9.\nYk = CA^{-k-1-}Buo + CA^{-k-1-}BU1 CA + + CA\\overline{B}Uk\u22121 + \u0421\u0412\u0438\u043a\ny = K * u.\n(7)\n(8)\nK\u2208R^{L} := k_{\\theta}(\\overline{A}, B, C) := (C\\overline{A}B)_{i\u2208[L]} = (\u0421\u0412, \u0421\u0410\u0412, ..., CA^{L-1-}B).\n(9)\nEquation 7 & Equation 8 represents a single convolution, and K is referred as the SSM convolution kernels or filters. The parameters of S4 are initialized randomly, except for A. The A parameter is initialized as a HiPPO Matrix, which is defined in Equation 10:\n(HiPPO Matrix) A_{nk} =\n\n(2n + 1)^{1/2}(2k + 1)^{1/2} if n > k\n \\sqrt{n+1}\nif n = k\n0\nif n < k\n(10)\nS4 addresses the limitations of transformers by implementing these strategies. This empowers SSMs to excel in tasks requiring long-range dependencies such as Path-X [118] . In contrast, Transformers"}, {"title": "Simplified State Space Layers for Sequence Modeling (S5)", "content": "S5 proposed by Smith et al. [113], extends from S4 with similar initialization conditions, but enhances the architecture by adopting a Multiple Input Multiple Output (MIMO) approach. Notably, S5 introduces a learnable time scale parameter (\u2206), replacing the fixed parameter used in S4. Parameters in S5 are discretized using the Zero Order Hold (ZOH) method as mentioned in Equation 11, providing a refined parameter system compared to S4.\n\\overline{A} = e^{A\u0394}, \\overline{B} = A^{-1} (\\overline{A} \u2013 I) B, \\overline{C} = C, \\overline{D} = D.\n(11)\nIn terms of computation, S5 employs a fully recurrent connection with parallel scanning, as detailed in Equation 3 and Equation 4. The authors highlight that a smaller latent space employs SSM to do parallel scanning where an associative operation is used in between during offline setting. This characteristic positions S5 for both online and offline processing, highlighting its utility in recurrent tasks within the time domain."}, {"title": "Selective Structured State Space Models (S6)", "content": "Extended from S5, S6 introduced by Gu et al. [45] incorporates SSMs within the Mamba Architecture. S6 builds upon the foundational assumptions of previous SSMs by leveraging a projection of the input function (using a linear layer) for initializing parameters B and C. Notably, S6 also applies this projection to the step size parameter i.e., \u0394. To enhance computational efficiency, S6 implements faster recurrence connections using operations on the Static Random Access Memory (SRAM) of the GPU, with storage on the High Bandwidth Memory (HBM) similar to the principles outlined in FlashAttention mechanism by Dao et al. [21] and FlashAttention-2 mechanism by Dao et al. [20]. The parameters in S6 are discretized using the Zero Order Hold method, following the approach set by S5. The Mamba architecture integrates components from both H3[42] and Gated MLP, incorporating an additional SSM layer and connections resembling the green parallelograms found in H3. Algorithm 1 & Algorithm 2 outlined below shows the differences between S4 and S6.\nMamba integrates a selective mechanism into its state space models (S6) to prioritize important content dynamically during training. SSM + Selection (S6) outlines a computational process for handling input sequences x and generating corresponding output sequences y. It begins by initializing a structured matrix A and projecting the input sequence x into tensors B and C using specific functions s\u00df and sc. The parameter \u2206, serves as a time step parameter which is used in discretization. It is computed based on a function \u03c4 incorporating additional parameters and s\u2206. Subsequently, A and B undergo discretization alongside \u2206, resulting in transformed tensors A and B as mentioned below in Equation 12.\n\\overline{A} = exp(\u0394\u0391)\n\\overline{B} = (\u0394\u0391)^{-1}(exp(\u0394\u0391) \u2013 \u0399)\u00b7 \u0394\u0392\n(12)\nThe core of the algorithm involves applying a state space model (SSM) function to x using (A, B, C) facilitating a time-varying recurrence process (\u201cscan\u201d). This approach ensures that the output sequence y reflects the transformations and interactions specified by SSM and selection mechanisms integrated within the architecture of S6."}, {"title": "Medical Image Analysis using Mamba", "content": "In this section, we cover the categorization of literature related to Mamba architectures, explore the optimizations that enhance their performance, and discuss various techniques and adaptations that expand their capabilities. Furthermore, we examine scanning techniques pertinent to Mamba and conclude by showcasing its diverse and impactful applications in the medical field."}, {"title": "Mamba Architectures", "content": "In this section, we explore and discuss the architectural landscape of Mamba, beginning with an exploration of the foundational pure Mamba design and its evolution through variants of U-Net. We then transition into the realm of hybrid architectures, where Mamba is ingeniously combined with other powerful techniques to achieve enhanced performance and tackle complex tasks."}, {"title": "Pure Mamba", "content": "Vision Mamba (ViM) proposed by Zhu et al. [164] incorporates bidirectional SSM by combining convolution with S6 in both forward and backward direction. Moreover, softplus [159] function is applied over the selective scan parameter \u22060 to make sure the parameter stays positive. The parameters of the S6 are discretized with \u22060 parameter mentioned above. ViM employs a training strategy similar to Vision Transformers (ViT) [24] where patches of inputs are tokenized by separating them into non-overlapping patches and applying a convolution layer on each patch with dimension d. The tokenized patches are then concatenated with class labels and learnable position encoding are added to the class label and tokenzied patches. Concatenating the class label in the middle has proven to work well as it exploits the recurrent nature of networks. Overall, ViM shows comparable differences in memory and performance to parametric heavy models such as DeiT-Ti (Data-efficient image Transformers-Tiny), DeiT-S (Data-efficient image Transformers-Small) proposed by Touvron et al. [119] on tasks such as object detection, classification and segmentation. Particularly on higher dimensional images such as 1248 \u00d7 1248, ViM consumes 73.2% less memory than DeiT and 2.8\u00d7 faster than DeiT.\nVMamba proposed by Liu et al. [88] employs an architecture similar to transformers, replacing the traditional multihead attention block [124] with a novel approach. It utilizes a Visual State Space (VSS) block, which differentiates it from the standard Mamba architecture by incorporating depthwise convolution and SS2D (2D selective scan). This new implementation features a non-multiplicative branching method and replaces S6 used in Mamba with SS2D. While S6 performs well for NLP tasks, extending it to 2D vision data presents challenges in making S6 modules scan-independent. SS2D addresses this by implementing a gating mechanism, eliminating the need for branched multiplication as proposed in Mamba and ViM. In VMamba, patches are initially partitioned within the stem module, resulting in a feature map of size H/4 \u00d7 W/4. As the data progresses through the layers, the feature map dimensions change sequentially to H/8 \u00d7 W/8, H/16\u00d7W/16, and finally H/32 \u00d7 W/32, with C representing the network's arbitrary dimensionality. Each stage, except the first, includes a downsampling block alongside VSS. Ultimately, a prediction head is employed to generate outputs for the designated task. SS2D consists of two stages: 1) cross scan module 2) cross merge module. The cross scan module in VMamba scans patches in four different directions: top to bottom, bottom to top, left to right and right to left. For each direction, an independent SSM is utilized, and the representations from these SSMs are combined using cross merging. On the performance perspective, VMamba achieves superior metrics with a minimal number of parameters and memory usage. Its performance is comparable to ViM-S, DeiT-S, and DeiT-B across various tasks including semantic segmentation, classification, and object detection.\nPlain Mamba proposed by Yang et al. [141] is a non-hierarchical SSM, similar to Vision Trans-formers (ViT). Drawing inspiration from ViT, Plain Mamba begins with patch embedding combined with position embedding, followed by a plain Mamba layer. In contrast to VSS, the plain Mamba layer utilizes gated multiplication of features, similar to ViM, but instead of a single SSM block, it employs four SSMs with continuous 2D scanning. The scan orders are the same as in VMamba, ensuring no positional bias and promoting uniform image understanding. Plain Mamba, also incorporates direction-aware updating by embedding 2D relative position information into a flattened 1D layer within the SSM. Unlike ViM, it uses global pooling, followed by a classification head on top.\nExtension of VMamba: Pei et al. [102] proposed the EVSS block, which stands for Efficient Visual State Space, combines local and global features effectively. EVSS block , employs the ES2D module to extract the global feature map and a depth-wise convolutional branch to obtain the local feature map. It also incorporates a squeeze excitation block similar to SqueezeNet which is proposed by Iandola et al. [64]. The global and local features are then combined. ES2D introduces a novel method of patch-wise scanning. Initially, the input image is divided into patches belonging to different groups. These patches undergo forward and backward 2D scanning, similar to the VSS method, and are then passed to S6 and merged. In the overall architecture, EVSS blocks are utilized in the initial stages, while inverted residual blocks are employed in later stages. In conclusion, EfficientVMamba achieves better performance with less number of parameters compared to transformer-based and convolution-based models.\nLi et al. [80] introduced the Mamba ND Block, which evaluates different scanning methods for 2D and 3D image representations. They found that the most effective approach involves scanning forward and then backward across height, width, and volume/time (if applicable). Separate Mamba blocks are designated for each scanning direction. The Mamba ND models outperformed transformer-based models while utilizing fewer parameters, resulting in enhanced performance in tasks such as video classification."}, {"title": "Variants of U-Net", "content": "The integration of Mamba blocks into the U-Net [108] architecture has resulted in several variants which are designed to improve its performance. For instance, they can be added before the first encoder layer, after an encoder layer, within the skip connections or can even replace the whole encoder block in UNet architecture.\nRuan et al. [109] proposed VM-UNet where images are converted into tokens using a patch embedding block. The encoder of the network contains two VSS blocks with patch merging block and skip connection in each layer of the encoder. The decoder contains a patch expanding block followed by a VSS block with skip connections added from the encoder. Finally, the representations from the decoder are then passed on to the final projection layer which reconstructs the image back into its original size i.e., the number of classes.\nArchit et al. [2] introduced ViM-UNet which uses ViM as its base Mamba. ViM-UNet features ViM encoder with bidirectional SSM layers, while its decoder copies the design of UNEt TRansformers (UNETR) [54] using convolution and transposed convolution layers. To enhance efficiency, ViM-UNet introduces flexibility in its encoder sizes, such as tiny and small. In contrast, the traditional UNet uses a standard CNN for biomedical segmentation. UNet relies heavily on skip connections between corresponding encoder and decoder blocks to capture better features. However, ViM-UNet takes a different approach by excluding these skip connections and using ViM as the encoder. This key architectural change allows ViM-UNet to achieve efficient global feature extraction and improved segmentation performance, without the need for the skip connections that are important in the traditional UNet.\nInspired by VM-UNet [109], Zhang et al. [156] proposed the second version called VM-UNet-V2. The model differs from VM-UNet by not using skip connections between subsequent encoder to decoder layers. Instead, features from each block of encoder are fused using Semantics and Details Infusion block (SDI block). VSS captures contextual information within images, while SDI module improves the integration of both low-level and high-level features, leading to a comprehensive understanding of image features. By combining these elements, VM-UNetV2 maximizes the potential of SSMs within the UNet, thus offering a more efficient and powerful solution for segmentation tasks.\nWang et al. [128] proposed LKM-UNet, a novel architecture designed for efficient 2D and 3D medical image segmentation. LKM-UNet uses strengths of Mamba to achieve superior performance in both local and global modeling with linear time complexity. The use of large windows within SSM improves the receptive field compared to CNNs and Transformers. The network architecture includes a hierarchical and bidirectional Mamba block, enhancing spatial modeling capabilities by integrating Pixel-level (PiM) and Patch-level (PaM) SSMs. LKM-UNet excels in capturing both fine-grained details and long-range dependencies from data. The model achieves efficient feature extraction and segmentation through a U-shaped network with encoder-decoder blocks, layers for downsampling and upsampling along with skip connections.\nWu et al. [134] proposed High-order Vision Mamba UNet (H-vmunet) which enhances the 2D-selective-scan (SS2D) mechanism and also introduced higher-order interactions to reduce redundant"}, {"title": "Hybrid Architectures", "content": "In this section, we explore hybrid architectures that combine Mamba with other powerful techniques. We cover Mamba's integration with convolutions for enhanced feature extraction, attention mechanisms and transformers for capturing contextual relationships, recurrence for modeling sequential data and GNNs for graph structured data. Additionally, we touch upon other miscellaneous hybrid approaches that demonstrate Mamba's versatility.\nMamba with Convolution: CNNs often face challenges in capturing long-range dependencies due to their inherent focus on local features and computational complexity. SSMs have the ability to handle long sequences of data. The combination of Mamba with convolution plays a huge role in capturing local spatial information along with capturing long range dependencies from medical images. Some of the papers that demonstrate these hybrid approaches are as follows: Ma et al. [93] introduced U-Mamba, a hybrid CNN-SSM architecture integrating Mamba blocks within the encoder of U-Net, demonstrating superior performance over traditional CNN-based and transformer-based segmentation networks across various modalities and segmentation targets. Wang et al. [132] proposed Mamba-U-Net which integrates pure Vision mamba in the U-Net along with linear embedding and VSS block in the model. Xu et al. [139] developed HC-Mamba, which uses dilated convolution followed by depth-wise separable convolution along with Mamba. It improves the receptive field and reduces the parameters of the model. Another innovative model, SegMamba"}, {"title": "Scanning", "content": "Attention mechanisms, especially self-attention have a quadratic time complexity causing computational costs to grow quadratically with sequence length. In contrast, scanning operations generally have linear time complexity, making them more efficient for long sequences. The scan operation involves calculating an array, like the prefix sum, where each value is determined by using the previously calculated value and the current input. Similarly, the recurrent form of SSM can be viewed as a scan operation. Scanning is a crucial component in mamba, especially when handling multidimensional inputs. The selection of the scanning mechanism in Mamba models is crucial as it enhances efficiency and provides important information.\nThe scanning methodologies used in mamba models are detailed as follows:\n(1) Bidirectional Scan : In bidirectional scan (forward and backward scan) [164], after tokenizing image patches, they are processed through the forward SSM. Simultaneously, the same tokenized representations of images are independently processed through the backward SSM. This scanning mechanism primarily used in ViM-based models, enables the model to capture contextual information from both directions, improving its ability to understand and represent the image data effectively.\n(2) Selective Scan 2D : SS2D [88] performs scanning operations in three directions: top to bottom, left to right, and in reverse direction. Each mamba block is placed to work independently within these directions. SS2D mirrors the self-attention process seen in transformers. It overcomes the limitations of bidirectional scan in ViM, but it also leads to a loss of patch continuity. To address this, SS2D incorporates a scan merge step, where representations from each scan direction are combined into a unified output.\n(3) Continuous 2D Scan : Continuous 2D scan [141] resolves the issue which is experienced in SS2D. It involves integrating direction-aware parameters into cross-scan mechanism and organizing patches accordingly. This approach ensures the preservation of patch continuity and maintains the contextual understanding of images. The continuous 2D scanning adds direction-aware parameter into data dependent parameter of SSM (B) which is expressed in Equation 13 and Equation 14.\nhki = Aihk,i-1 + (Bi + \u0398k,i)xi\n(13)\nYi = \u03a3(Cihki + Dxi), Yi = YOZi\n(14)\n(4) Zigzag Scan : The extension of continuous 2D Scan is zigzag scan [61] where the images are scanned with continuous scanning mechanism in both forward and backward direction. Zigzag scan is developed to enhance the continuity of patches in the images which are used for diffusion models such as ZigMa [61].\n(5) Spatiotemporal Selective Scan : Spatiotemporal selective scan [146] is used to scan on videos where the patches are unfolded on each frame along rows and columns and then concatenated with the frame sequence of h\u2208 R^{Ci\u00d7T(HW)} . In this setup, scanning is done bidirectionally to know about temporal dependency. Parallelly, scanned patches are stacked around temporal axis to construct the spatial sequence in the form of h e R^{C\u00a1\u00d7(HW)T}, to integrate information of each pixel from all frames. In short, one scan focuses on scanning with time dependency along frames and the other focuses on scanning each pixel along the time axis.\n(6) Local Scan : Local Scanning [63] overcomes limitations of scanning methods in ViM and VMamba by preserving local dependencies in images through distinct local windows. This technique maintains the global context of the image without compromise. The authors suggest using 7 \u00d7 7 and 2 \u00d7 2 local windows to capture the local context while alternating the scan direction. Vertical and horizontal scans with direction flipping are used to grasp the global context of image tokens.\n(7) Efficient 2D Scan : Efficient Scan 2D (ES2D) [102] emphasizes efficient image scanning by skipping scan patches with a step size p. It partitions selected spatial dimension features into m and n using sine and cosine functions to determine the patch location. The entire operation is mathematically expressed in Equation 15.\nO\u2081 = X[:, m :: p, n :: p],\n(15)\n{O^{scan}_i} = SS2D({O_i}^{i=1}_{14}),\nY[:, m :: p, n :: p] \u2190 O^{merge}_i,"}, {"title": "Mamba Optimizations", "content": "In this section, we discuss research papers that focus on lightweight, efficient, and optimized model architectures."}, {"title": "Lightweight and Efficient", "content": "Lightweight and efficient models are designed to be smaller, quicker, and use fewer resources, while maintaining good performance.\nLight Mamba UNet (LightM UNet) proposed by Liao et al. [85] combines Mamba and UNet architectures in a lightweight framework which aims to tackle computational challenges in real world medical environment. The Residual Vision Mamba (RVM) layer is proposed to improve SSM for deep semantic feature extraction from images in a pure Mamba-based manner.\nLightM-UNet overcomes the existing state-of-the-art methods with only 1.09 M parameters and 267.19 GFLOPs. UltraLight Vision Mamba UNet (UltraLight VM-UNet) introduced by Wu et al. [135] is a lightweight vision Mamba model. An excellent performance is achieved by Parallel vision Mamba (PVM) method that is used for efficiently processing deep features with lowest computational complexity, while maintaining the overall number of processing channels constant. PVM is primarily composed using Mamba combined with residual connections and adjustment factors. This combination allows traditional Mamba to capture remote spatial relations without introducing additional parameters and computational complexity. Several comparisons have been done with the state-of-the-art lightweight models across three public skin lesion datasets. In this analysis, the UltraLight VM-UNet shows the competitive performance with only 0.049M parameters and 0.060 GFLOPs. UltraLight VM-UNet parameters are 87.84% lower than the parameters of LightM-UNet.\nMUCM-Net proposed by Yuan et al. [149] is an efficient model which combines Mamba State-Space Models with UCM-Net architecture to improve segmentation and feature learning. In this model, Mamba-UCM is optimized for mobile deployment, providing high accuracy with minimal computational requirements (approximately 0.055 \u2013 0.064GFLOPs and 0.071 \u2013 0.139M parameters).\nLightCF-Net proposed by Ji et al. [69] is a novel and efficient lightweight architecture used as a long-range context fusion network for real-time polyp segmentation. A new FAEncoder module has been developed, merging Large Kernel Attention (LKA) with channel attention mechanisms to extract deep representational features of polyps and uncover long-range relationships. Furthermore, a novel Visual Attention Mamba Module (VAM) module has been integrated into skip connections to capture extensive contextual dependencies from encoder-extracted features, prioritizing crucial information and mitigating background noise interference using attention mechanisms. Evaluation is done on four polyp segmentation datasets which showcases its operational efficiency and segmentation accuracy compared to leading lightweight polyp segmentation networks. While this method achieves good results in segmentation task, the complexity of the medical environment and limitations of labeled data during training pose challenges, preventing it from fully meeting the demands of medical applications. The model features 1.52 M parameters, operates at 3.25 GFLOPs, and achieves a frame rate of 33 FPS. Chen et al. [15] proposed MiM-ISTD for Infrared Small Target Detection (ISTD). It utilizes Mamba to effectively capture both local and global information from the given data. This approach ensures higher efficiency with very less computational costs. Experiments conducted on NUAA-ISTD and IRSTD-1k datasets, where MiM-ISTD demonstrated superior performance in terms of both accuracy and efficiency compared to other related methods. MiM-ISTD is ten times faster than the state-of-the-art method and it reduced GPU memory usage by 73.4% during high resolution image testing."}, {"title": "Techniques and Adaptations", "content": "In this section, we explore techniques and adaptations for Mamba architectures such as weakly supervised, semi-supervised ands self-supervised approaches. These approaches are used in scenarios where data annotations are absent, partially present or inconsistent, and used to improve the model's ability to learn from unstructured or incomplete or semi-structured data."}, {"title": "Weakly Supervised Learning", "content": "Weakly Supervised Learning (WSL) uses a small amount of correctly labeled data along with a large amount of data with incomplete labels. Instead of having detailed labels for each data, this approach works with data that has noisy and partial labels. Wang et al. [130] proposes Weak-Mamba-UNet, a WSL strategy which incorporates three different architectures but with the same symmetrical encoder-decoder networks. The three networks consist of a CNN based U-Net, known for capturing local features; a Swin Transformer-based SwinUNet, which excels in understanding global context and a VMamba-based Mamba-UNet, for efficiently capturing long-range dependency. The proposed WSL framework employs a multi-view cross-supervised learning approach for scribble-based supervised medical image segmentation. The work introduced partial cross-entropy to leverage only the scribble annotations during the training of the network. The overall loss is composed of the scribble-based partial cross-entropy loss and the dense-signal pseudo label dice-coefficient loss. The network demonstrates promising results in segmentation tasks achieving an accuracy of 99.63% on MRI Cardiac [9] dataset."}, {"title": "Semi-Supervised Learning", "content": "Semi-supervised learning uses a fewer amount of labeled data and a larger amount of unla-beled data during training. Ma et al. [92", "components": "supervision loss, self-supervised contrastive loss, and semi-supervised loss. Semi-Mamba-UNet was tested on ACDC MRI Cardiac Dataset [9"}]}