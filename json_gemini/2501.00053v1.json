{"title": "Implementing Trust in Non-Small Cell Lung Cancer Diagnosis with a Conformalized Uncertainty-Aware AI Framework in Whole-Slide Images", "authors": ["Xiaoge Zhang", "Tao Wang", "Chao Yan", "Fedaa Najdawi", "Kai Zhou", "Yuan Ma", "Yiu-ming Cheung", "Bradley A. Malin"], "abstract": "Ensuring trustworthiness is fundamental to the development of artificial intelligence (AI) that is considered societally responsible, particularly in cancer diagnostics, where a misdiagnosis can have dire consequences. Current digital pathology AI models lack systematic solutions to address trustworthiness concerns arising from model limitations and data discrepancies between model deployment and development environments. To address this issue, we developed TRUECAM, a framework designed to ensure both data and model trustworthiness in non-small cell lung cancer subtyping with whole-slide images. TRUECAM integrates 1) a spectral-normalized neural Gaussian process for identifying out-of-scope inputs and 2) an ambiguity-guided elimination of tiles to filter out highly ambiguous regions, addressing data trustworthiness, as well as 3) conformal prediction to ensure controlled error rates. We systematically evaluated the framework across multiple large-scale cancer datasets, leveraging both task-specific and foundation models, illustrate that an Al model wrapped with TRUECAM significantly outperforms models that lack such guidance, in terms of classification accuracy, robustness, interpretability, and data efficiency, while also achieving improvements in fairness. These findings highlight TRUECAM as a versatile wrapper framework for digital pathology Al models with diverse architectural designs, promoting their responsible and effective applications in real-world settings.", "sections": [{"title": "Main", "content": "In the field of digital pathology, artificial intelligence (AI) has shown significant potential for enhancing decision support across a wide spectrum of clinical tasks, from diagnosing and distinguishing between various types of cancers to detecting subtle histopathological changes that may predict disease progression [1-3]. However, the reliability of medical AI models can be significantly compromised by their inherent limitations, such as weak ability in measuring uncertainty and controlling error rates. These issues are further compounded by data discrepancies between model development and deployment environments, including variations in patient demographics, disease characteristics, data acquisition techniques, staining protocols, and clinical practices. Addressing these challenges is essential to ensure model reliability, uphold patient safety, and establish trustworthiness in AI systems for medical applications [4, 5].\nRather than simply training AI models to produce the most likely outcome for patients as a point estimate\u2014a practice that often lacks context and can lead to inaccurate interpretations\u2014researchers have sought to quantify the confidence associated with AI generated results. This additional layer of insight can enable users to better interpret the reliability of a model's prediction or classification, helping inform when to accept the results [6-8]. Multiple uncertainty quantification (UQ) approaches have been recently integrated into AI development to characterize confidence [9\u201312]. For instance, Olsson and colleagues [13] developed a conformalized deep convolutional neural network ensemble to generate all likely cancer diagnoses in biopsies and demonstrated the value of uncertainty estimates in flagging classifications with insufficient confidence. Additionally, Dolezal and colleagues [14] applied a Monte Carlo Dropout technique to quantify the uncertainty in classifications distinguishing between lung adenocarcinoma and squamous cell carcinoma, facilitating the recognition of high- versus low-confidence outputs to address domain shifts. And, most recently, Sun and colleagues [15] introduced TISSUE, a general framework for estimating uncertainty in spatial gene expression predictions that works by creating well-calibrated prediction intervals.\nDespite advances in quantifying uncertainty, the current collection of approaches do not adequately align with several of the essential properties needed for safeguarding practical utilization of pathology AI, and medical AI more broadly [16]. First, an ideal UQ approach should consistently characterize a model's confidence across varying levels of data risk. Beyond capturing uncertainty for in-domain (In-D) data, it should reliably identify out-of-domain (OOD) inputs, address potential distribution shifts between data used during model development and data encountered after deployment, and recognize regions within a slide that could adversely impact inference. At the present time, AI systems generally do not systematically address these challenges. Second, the claimed confidence interval (e.g., a set of likely cancer subtypes) or the error rate established for real-world inference must closely align with the observed outcomes. For example, if a model predicts with 95% confidence, then the true value should fall within the predicted range in 95% of the cases. Although existing methods, such as Platt [17-19] and temperature scaling [20, 21], seek to improve calibration, they neither ensure consistency between expected and observed confidence nor objectively represent the model's confidence. Notably, these methods lack the ability to abstain from inputs that are difficult to infer accurately, a practice widely advocated for reliable medical AI with human in the loop [5]. Third, when estimating uncertainty, an effective UQ approach should enhance interpretability without adding substantial computational overhead beyond its deterministic counterpart (i.e., the original model without UQ). This is essential for medical imaging applications, where strict time constraints and resource limitations demand rapid and efficient processing without compromising reliability. Most UQ approaches rely on ensemble-based estimations, which require a large number of repeated inferences to be made using the same pathology AI models to estimate uncertainty for each patch (or tile) in a single slide. Given that these models typically contain millions of parameters, the resulting computational demand for generating uncertainty and interpretability can become prohibitively large, hindering their usability in practice [22].\nIn light of these issues, we set out to equip pathology AI with a formal, principled, and scalable UQ, as well as demonstrate how it empowers trustworthy subtyping of non-small-cell lung cancers (NSCLC) [23] using whole-slide images (WSI). We decompose the trustworthiness of medical AI into two constituent parts: 1) data trustworthiness, which ensures that the input data during deployment aligns with the model's training scope and allows ambiguous slide regions to be excluded, and 2) model trustworthiness, which offers valid confidence intervals with a customizable level of coverage, ensuring the true label is covered in a specified proportion of classifications. To do so, we developed TRUECAM (Fig. 1a), a framework that provides TRustworthiness-focused, Uncertainty-aware, End-to-end Cancer diagnosis with Model-agnostic capabilities. TRUECAM consists of three components designed to simultanuously ensure data and model trustworthiness: 1) a spectral-normalized neural Gaussian process (SNGP) to establish informative data representation and uncertainty quantification, 2) an elimination of ambiguous tiles (EAT) mechanism for filtering out noisy patches from slides, and 3) conformal prediction (CP) to enable a statistically guaranteed error rate. We then conducted a wide range of experiments with several large cancer datasets, utilizing a widely adopted specialized model (i.e., Inception-v3 [24, 25]) and multiple"}, {"title": "Results", "content": "An overview of TRUECAM\nThis study focuses on distinguishing between two main types of of NSCLC-lung adenocarcinoma (LUAD) and lung squamous cell carcinoma (LUSC)\u2014each of which is defined by distinct biological, morphological, molecular, and prognostic features that inform which therapeutic approach to undertake for a patient [23]. WSIs of lung tissue specimens were used for this specific task. In this paper, we use the term \u201cprediction\u201d interchangeably with \u201cclassification\u201d where needed to align with the established terminology convention in conformal prediction.\nWe designed the TRUECAM framework (Fig. 1a) to wrap around deep learning models of various architectures, sizes, and purposes for imaging tasks (Fig. 1b). TRUECAM employs SNGP to perform distance-preserving transformations on input data and efficiently estimate data uncertainty, enhancing data trustworthiness by enabling OOD detection and data shift control before model inference. Furthermore, CP is applied on top of SNGP to calibrate model predictions (represented as a set of values, i.e., prediction set), providing a statistical guarantee on the model's coverage of true labels. These components contribute complementary functions to assure the trustworthiness of AI for NSCLC subtyping. Specifically, SNGP establishes a valid foundation for CP to operate. This is important because CP generally requires that data in the deployment environment comes from the same underlying distribution as those in the development environment, known as data exchangeability\u2014an assumption that might not hold true in the real-world setting, where OOD data and distribution shift are common. Meanwhile, CP calibrates the outputs of SNGP to ensure the statistical validity of model coverage. Notably, the distance-preserving data transformation by SNGP facilitates an effective identification of tiles that only add ambiguity to NSCLC subtyping. EAT can then be applied to enhance the supervisory signal\u2014leading to a more reliable model-while significantly reducing the computational load during inference (Fig. 1c). The details of model design and implementation are described in the Methods.\nIn this study, we relied on two digital pathology datasets of NSCLC stained with hematoxylin and eosin (H&E) (Fig. 1d), both of which are large-scale, multi-institutional initiatives in the United States: 1) 941 WSIs from The Cancer Genome Atlas (TCGA), and 2) 1,306 WSIs from the Clinical Proteomics Tumor Analysis Consortium (CPTAC). Additionally, we constructed an OOD dataset from the same source as TCGA, which incorporates 631 WSIs of non-lung cancers. For simplicity, we refer to these three datasets as TCGA, CPTAC, and TCGA-OOD. The details for these datasets are provided in the Methods.\nTo assess the effectiveness of TRUECAM, we evaluated two types of AI models. We utilized Inception-v3, a widely used convolutional neural network architecture for image inference [24, 25], as a representative classifier for specialized medical imaging tasks within the TRUECAM framework. In this context, we used TCGA for model training and internal validation, while we used CPTAC as an independent external validation dataset to assess TRUECAM's effectiveness in scenarios requiring model transferability. We further investigated four digital pathology foundation models that exemplify the recent advancements in large, general-purpose models in the field: 1) UNI [26], 2) CONCH [27], 3) Prov-GigaPath [28], and 4) TITAN [29]. Since foundation models are pretrained on diverse datasets, offering strong knowledge transferability as an image encoder, and downstream task-specific classifiers are typically lightweight and easy to train, our evaluation focused solely on the setting where each healthcare organization trains and evaluates its own site-specific model using its data. Accordingly, TCGA and CPTAC were utilized to mimic this setting, such that we"}, {"title": "Integration of distance-aware uncertainty estimation improves NSCLC subtyping performance", "content": "We trained three deep neural network models, all based on the Inception-v3 architecture, to discriminate between LUSC and LUAD: 1) a deterministic model without UQ, referred to as Deterministic, which represents the original Inception-v3, 2) a Monte Carlo Dropout-based model (referred to as MC Dropout) to enable UQ [14], and 3) a model that utilizes SNGP to quantify uncertainty (referred to as SNGP). We provide model details in the Methods. Following the design in [14], all models were trained at the tile level, with slide-level classifications obtained by averaging tile-level outputs across each WSI. For patients with multiple WSIs, the final patient-level diagnosis was derived by averaging the slide-level classifications across all WSIs for that patient.\nWe deactivated TRUECAM's CP functionality and EAT to assess the effectiveness of SNGP. At the tile level (using tiles as subtyping units), SNGP consistently outperformed Deterministic on the TCGA dataset in both accuracy (p < 0.001) and the area under receiver operator curves (AUROC) (p < 0.001) (Fig. 2a). In addition, when evaluated on TCGA, SNGP significantly outperformed MC Dropout in terms of both accuracy (p < 0.01) and AUROC (p < 0.001). When evaluated on the external CPTAC dataset, SNGP outperformed MC Dropout by 4.9% (p < 0.001) and Deterministic by 7.2% (p < 0.001) in accuracy, and exceeded MC Dropout by 4.5% (p < 0.001) and Deterministic by 5.7% (p < 0.001) in AUROC (Fig. 2d)."}, {"title": "Conformalized SNGP establishes statistical coverage guarantee while enhancing NSCLC subtyping efficiency", "content": "We enabled CP in TRUECAM and then assessed its effectiveness in calibrating SNGP-based NSCLC subtyping by generating a prediction set for each patient. A set size of 2 indicates that the model lacks sufficient confidence to definitively classify input data as either LUAD or LUSC, effectively resulting in abstention. Two broadly used measures in the literature, validity and efficiency [30\u201332] were evaluated. We consider a model to be valid at an error level a when the proportion of the prediction set containing the true subtype (i.e., model coverage) is at least 1 \u2013 a. Efficiency is determined by the size of the prediction sets\u2014we deem a model to be more efficient when it produces smaller prediction sets, provided that validity is maintained. This is because more concise and informative outputs are generally preferred by both service providers and patients.\nThere are several findings we wish to highlight. First, all three of the models achieved the validity requirements at both the tile and patient levels across the TCGA and CPTAC testing datasets for three distinct error levels (Supplementary Tables 9, 10). Second, for each considered coverage 1 a, conformalized SNGP consistently produced significantly smaller prediction sets than conformalized MC Dropout and Deterministic at both the tile and patient levels (Fig. 2e,g). Such an advantage generalized well to the external CPTAC dataset at both the tile and patient levels (Fig. 2f,h). More concretely, at a = 0.05, conformalized SNGP produced 41,570 more tiles with a single NSCLC subtype output (set size of one) on average, which was a 31.4% increase over conformalized MC Dropout. In other words, when validity was ensured, conformalized SNGP exhibited a significantly higher efficiency in terms of the number of informative outputs in NSCLC subtyping than other models (Supplementary Tables 11,12). Third, as expected, lowering the value of a, which decreases the tolerance for model miscoverage, resulted in larger prediction sets across all models, datasets, and classification levels (Fig. 2e-h). In other words, more tiles and patients were classified as \u201cunsure\u201d (i.e., abstention) to reduce the likelihood of classifications containing only a single, but incorrect, subtype.\nWe further investigated the models' patient-level classifications, which include the following categories 1) single and correct, 2) single but incorrect, and 3) uncertain between subtypes (abstention). For all considered error levels, conformalized MC Dropout achieved similar patient-level performance as Deterministic in terms of patient numbers under each category (Fig. 2i,j). By contrast, conformalized SNGP consistently produced more single and correct classifications in both of the TCGA and CPTAC testing datasets than the other two models, while incurring a similar number of single but incorrect classifications (Fig. 2i,j). Specifically, at a = 0.01, conformalized SNGP classified approximately six more patients with a single and correct NSCLC subtype than conformalized MC Dropout, reflecting a 23.4% increase (Fig. 2i). This advantage was further amplified in the CPTAC testing dataset, where it classified around 30 more patients with single and correct subtype at a 0.01, corresponding to a 83.7% increase than conformalized MC Dropout (Fig. 2j). As an artifact of bounded error rates, the increase in correctly identified patients by conformalized SNGP was accompanied by a comparable reduction in classifications with abstention. These findings collectively highlight enhanced overall performance and greater efficiency of TRUECAM, as evidenced by the increased ratio of single and correct classifications, underscoring its superior practical utility.\nNext, we examined the capability of TRUECAM to manage errors when committing to a single subtype prediction. We define the definitive-answer error rate (referred to as DA error rate) as the proportion of patients with single but incorrect subtype designation among all patients with single subtype classification. Before activating CP, TRUECAM demonstrated the lowest error rate for both TCGA and CPTAC (Fig. 2k,l). In other words, when the model outputs were not conformalized (i.e., classifications were binary, based solely on the highest probability between subtypes), SNGP outperformed both MC Dropout and Deterministic, a finding consistent with the results shown in Fig. 2c,d. When CP allows a model to abstain on uncertain inputs, all models achieved a reduction in DA error rate, with a steady decline as the significance level a decreases. Notably, at a = 0.01, CP induced a DA error rate of 1.9% in TCGA, representing an 84.8% reduction compared to using SNGP alone. In other words, SNGP, without CP, made approximately one error for every eight patients, whereas with CP at a = 0.01, SNGP made only one error for every 100 patients on average. These"}, {"title": "Eliminating ambiguous tiles (EAT) concurrently augments classification and CP performance in NSCLC subtyping", "content": "In clinical inference using a WSI, not all regions provide diagnostic value to pathologists (e.g., areas with normal, non-cancerous cells). However, the current practice in digital pathology typically involves utilizing all tiles\u2014often numbering in the hundreds to tens of thousands from a single WSI (Fig. 1d)\u2014paired with coarse-grained slide-level labels for training diagnostic models [33\u201337]. Such a weakly supervised learning process inherently introduces noise, as many normal tiles may be inaccurately associated with tumor labels [38]. This practice can lead to reliability issues and inefficiencies as models are forced to learn from irrelevant or non-informative regions (even with attention mechanisms in place). These, in turn, dilute the signal necessary for accurate and efficient NSCLC subtyping, which undermines data trustworthiness.\nTo filter out non-informative tiles for the NSCLC subtyping task, we applied k-means clustering to the tile representations of the TCGA training data extracted by SNGP. We calculated the Silhouette coefficient [39] and determined k = 3 as the optimal number of clusters. We observed that one cluster contained mostly tiles from WSIs with the true label of LUAD, another cluster contained mostly tiles with the true label of LUSC, and the final cluster was not dominated by either subtype (Fig. 3a). Using t-distributed stochastic neighbor embedding (t-SNE) visualization (Fig. 3b), we observed that the clustering pattern consistently aligned with the label distribution depicted in Fig. 3a.\nSubsequently, we measured the ambiguity of all of the tiles to quantify model discernibility (formally defined in the Methods) and observed that the ambiguity scores were significantly higher in the cluster lacking clear label dominance (referred to as ambiguous cluster) than the other two clusters (Fig. 3c). This suggests that the tiles in the ambiguous cluster may only add ambiguity to NSCLC subtyping when aggregating tile-level classifications. Motivated by these observations, we hypothesized that eliminating ambiguous tiles through the EAT process would strengthen the supervisory signals for model training and lead to more accurate subtyping of NSCLC. To test this hypothesis, we compared the classification and CP performance of TRUECAM before and after activating EAT.\nTo do so, we removed the training tiles from the ambiguous cluster (accounting for 66.7% of all training tiles) and used the remainder of the data to train a new classification model (Fig. 1c), which we refer to as SNGP-EAT. For new WSI inference, tiles from a new slide with their latent representations falling within the ambiguous cluster were excluded from the NSCLC subtyping task using SNGP-EAT.\nIn addition to comparing SNGP-EAT with SNGP, we established another baseline model, referred to as SNGP-RE, which follows the same procedure as SNGP-EAT but eliminates an equal number of tiles that are selected uniformly at random. SNGP-EAT achieved a 2.83% improvement in patient-level classification accuracy compared to SNGP (p < 0.001) on TCGA and an 8.05% increase (p < 0.001) on CPTAC (Fig. 3d, Supplementary Table 8). By contrast, SNGP-RE consistently performed worse than both SNGP and SNGP-EAT in terms of accuracy and AUROC (Extended Data Fig. 2a-d). Moreover, EAT improved CP efficiency by producing significantly smaller prediction set sizes (Extended Data Fig. 2e-h, Supplementary Tables 11, 12) and generated more single and correct classifications in both the TCGA and CPTAC cohorts (Fig. 3e,f), except for the TCGA setting with a = 0.01, while yielding a comparable number of single but incorrect classifications as the models without EAT. Meanwhile, a comparison of DA error rates also favored SNGP-EAT (Extended Data Fig. 2i,j, Supplementary Tables 13,14)."}, {"title": "TRUECAM achieves fairer NSCLC diagnosis compared to other methods", "content": "We investigated how TRUECAM affects fairness by comparing it to a set of baseline models. We first evaluated the classification performance gap, defined as the maximum difference in accuracy among patient subgroups based on race and sex (Supplementary Table 1). This was assessed in scenarios without CP. We then extended this evaluation to fairness in terms of average set sizes of CP across these subgroups. A large difference in set sizes between two subgroups suggests greater uncertainty in the model's predictions for one subgroup compared to the other."}, {"title": "TRUECAM enables effective OOD detection and distribution shift control", "content": "In pathology AI deployment, WSIs that differ from the model's training data in aspects such as cohorts, tissue types, devices, and other factors are prevalent and difficult to detect. For models equipped with CP, the claimed model coverage may no longer hold valid under such condition. This potentially undermines reliability and poses a serious risk to patient health. We now show that TRUECAM is able to safeguard CP by detecting data that is outside of the model's scope (i.e., OOD data).\nWe built the TCGA-OOD dataset that contains 698 WSIs from 631 patients with non-lung cancers (See Supplementary Table 1 and Methods for details), and then combined it with an In-D dataset, which integrates the TCGA calibration and testing datasets. We defined two distinct measures to quantify the degree to which an input WSI is out of the model's scope: 1) an uncertainty-based OOD score, which aggregates tile-level uncertainty as determined by the model's UQ module (e.g., Gaussian layer for SNGP and SNGP-EAT, stochastic dropout layer for MC Dropout), and 2) a probability-based OOD score, which aggregates tile-level classification probabilities, calculated as \\(1 - \\frac{1}{N}\\sum_{i=1}^{N} \\max_{\\hat{y}_{k}} P(\\hat{y}_{k}|x_{i})\\), where \\(p(\\hat{y}_{k}|x_{i})\\) denotes the probability of tile i being classified as label \\(\\hat{y}_{k}\\). We observed that probability-based OOD scores from SNGP-EAT exhibited the strongest ability to distinguish between In-D and OOD WSIs, achieving the highest AUROC of 0.949, significantly outperforming Deterministic (0.876), MC Dropout (0.884), and SNGP (0.898) (Fig. 5a). At a 0.95 precision, SNGP-EAT achieved a true positive rate (TPR, i.e., recall) of 0.929, which is 46.0%, 41.5%, and 33.3% higher than Deterministic, MC Dropout, and SNGP, respectively (Fig. 5b). This observation also generalized to uncertainty-based OOD scores. Notably, for both Inception-v3-based SNGP models, probability-based OOD scores were more effective than uncertainty-based scores for identifying OOD inputs (Supplemtentary Table 15). As such, the probability-based OOD score was relied upon in the subsequent investigations related to Inception-v3-based models.\nWe further examined the effect of identifying and removing OOD inputs from inference enabled by TRUECAM on the empirical coverage of a model (i.e., model validity). When we randomly sampled an equal number of OOD patients to match the size of the In-D"}, {"title": "TRUECAM's benefits extend to digital pathology foundation models", "content": "Beyond specialized medical AI models like Inception-v3, which perform tile-level inference and aggregation, TRUECAM seamlessly integrates with general-purpose foundation models to make slide-level inference directly, without the need for tile-level result aggregation (Fig. 1b). Specifically, TRUECAM utilizes a foundation model's pretrained encoder to extract tile representations from each slide, assigns ambiguity values to discard confusing tiles, and processes remaining tiles either through ABMIL for tile-level models or a slide encoder for slide-level models. For evaluation, we systematically assessed TRUECAM's performance with two recently released foundation models for digital pathology: UNI [26], a visual model, and CONCH [27], a visual-language model. For these two models, TRUECAM enforces distance-preserving transformations within the widely-adopted attention-based multiple instance learning (ABMIL) architecture [40] by incorporating spectral normalization in fully-connected layers. The final layer is updated with a Gaussian process to enable UQ. To assess tile ambiguity for EAT within the context of foundation models, a tile-level classifier aligned with the target task remains essential. Thus, we integrated TRUECAM with an AutoML system, AutoGluon [41], to identify ambiguous tiles. Upon the completion of EAT, the trained ABMIL model was directly reused for inference without the need for retraining. For slide-level foundation models like Prov-GigaPath and TITAN, the adaptation of TRUECAM was slightly different. See the Methods for details.\nWe now show that TRUECAM established both data and model trustworthiness for NSCLC subtyping using digital pathology foundation models, addressing shortcomings of their original versions in deployment environments. We highlight the following key observations. First, when applied to foundation model-based ABMIL in the absence of CP, both UNI-TRUECAM and CONCH-TRUECAM, which removed 60.0% of tiles per slide based on the ambiguity score defined in the Methods, enhanced the patient-level NSCLC subtyping accuracy (Fig. 6a). Specifically, UNI-TRUECAM and CONCH-TRUECAM reduced the error rate by 10.04% and 8.48%, respectively, than their deterministic counterparts (Fig. 6i,j). This highlights the combined effectiveness of SNGP and EAT in overcoming model limitations that contribute to suboptimal performance. See Supplementary Table 29 for TRUECAM's impact on the"}, {"title": "TRUECAM delivers efficient interpretation and inference", "content": "Compared to traditional approaches that rely solely on attention for interpretation, TRUECAM offers a diagnostic basis for model inference through two interpretability layers informed by its UQ module: 1) tile-level ambiguity scores, which assess each tile's potential to introduce confusion and help eliminate corresponding regions, and 2) a global attention map that shows the reliance of slide-level inference on each remaining tile after EAT.\nTo validate the diagnosis basis of TRUECAM across models, we randomly selected and visualize two WSIs from the TCGA testing cohort: one representing LUAD (Extended Data Fig. 7) and one for LUSC (Extended Data Fig. 8). A pathologist (F.N.), blinded to any model-derived information, received these WSIs to delineate tumor regions with significant diagnostic relevance for NSCLC subtyping. A random selection of tiles from various representative regions was also provided to the pathologist to assess their informativeness for distinguishing LUAD from LUSC. We observed that the regions with relatively low ambiguity scores closely aligned with the annotated areas by the pathologist, which facilitated their discrimination between LUAD and LUSC using established diagnostic criteria. Specifically, these low-ambiguity regions contained cancer epithelial areas, which were critical for distinguishing NSCLC subtypes. By contrast, regions with higher ambiguity scores lacked distinct morphological features of either NSCLC subtype. For example, tiles with blue borders from both LUAD and LUSC WSIs contained inflamed non-neoplastic lung parenchyma, areas of stroma, or necrosis, all of which were devoid of tumor-specific morphological hallmarks (Extended Data Fig. 7, 8). Some regions appeared as poorly preserved or fields with artifacts, further undermining their utility in subtype discrimination.\nAfter applying EAT, the morphological features in regions with high attention weights became the primary basis for the model's classification. As confirmed by the pathologist, the high-attention regions highlighted in blue were generally consistent with the diagnostic criteria used to determine the NSCLC subtype. Tiles with red borders exemplified this alignment: LUAD-specific regions revealed glandular arrangements characteristic of adenocarcinoma, such as well-formed acinar patterns, while LUSC-specific regions displayed intercellular bridges, focal keratinization, and dense eosinophilic cytoplasm, all consistent with the morphological features used in pathologic classification. However, not all regions contributed equally to subtype discrimination. Regions lacking clear indicators for either subtype were recognized by TRUECAM with correspondingly low attention weights. For example, tiles with"}, {"title": "Discussions", "content": "Trustworthiness of pathology AI is often compromised by model limitations in delivering reliable performance and quantifying uncertainty with statistical implication. Moreover, data challenges like noisy patches and the complexity of model deployment environment, including OOD data and distribution shifts, further undermine trustworthiness of pathology AI. To address these issues, we developed TRUECAM, a framework designed to seamlessly integrate with models with various architectures, purposes, and complexities, to enable responsible and trustworthy AI-driven NSCLC subtyping in pathology.\nTRUECAM holds significant implications for the practical application of pathology AI models in real-world clinical settings. The most immediate benefit of TRUECAM lies in its significant reduction in the likelihood of AI models producing incorrect results. However, its impact extends beyond improving diagnostic accuracy; it redefines how pathology AI can be responsibly integrated into clinical workflows of cancer diagnostics. To manage the risk of erroneous patient-level diagnoses and ensure statistically guaranteed error bounds, TRUECAM adaptively defers uncertain or OOD cases to expert pathologists, fostering a collaborative decision-making process. Importantly, the framework tackles a fundamental challenge in pathology AI: inference data may experience distribution shifts, whether due to temporal changes at the same site, inter-site variability, or demographic and medical practice-based differences, all of which can undermine model trustworthiness. By addressing these issues, TRUECAM ensures that AI acts as a reliable assistant rather than an inflexible tool, which complements clinical workflows while mitigating the risks of automation bias. Critically, TRUECAM'S deferral mechanism is proactive, customizable, and strategic, abstaining less frequently than other models while achieving superior accuracy. This demonstrates the framework's ability to recognize and act on its own limitations, which confines AI usage within a trusted scope and reduces the cognitive load on pathologists, who can focus their expertise and effort on the most challenging cases [42-44]. By integrating reliability, adaptability, and collaboration, TRUECAM establishes itself as a transformative step toward making AI a trusted partner for clinical decision-making.\nTRUECAM not only confines diagnostics to the trusted scope of pathology AI but also lays a solid foundation for responsibly expanding this scope through a built-in awareness of its limitations. In a human-AI collaborative framework, expert pathologists can assign definitive labels to slides flagged as OOD or those where the model abstains from making a prediction. These newly labeled data"}], "equations": [{"content": "L_{1} \\times ||x_{1}-x_{2}||_{x} \\leq ||h(x_{1})-h(x_{2})||_{H} \\leq L_{2} \\times ||x_{1}-x_{2}||_{X},"}, {"content": "W_{l}=\\left\\{\\begin{array}{ll}  \\frac{c}{\\left\\|W_{l}\\right\\|_{2}} W_{l}, & \\text { if } c< \\left\\|W_{l}\\right\\|_{2} \\\\  W_{l}, & \\text { otherwise. }  \\end{array}\\right."}, {"content": "f_{N \\times 1} \\sim \\mathcal{N}\\left(0_{N \\times 1}, K_{N \\times N}\\right), \\text { where } K_{i, j}=\\exp \\left(-\\frac{\\left\\|h_{i}-h_{j}\\right\\|_{2}^{2}}{2 \\sigma^{2}}\\right)."}, {"content": "f_{N \\times 1} \\sim \\mathcal{N}\\left(0_{N \\times 1}, \\Phi \\Phi^{T}\\right), \\text { where } \\Phi=\\sqrt{\\frac{2}{D_{L}}} \\cos \\left(W_{L} h_{i}+b_{L}\\right),"}, {"content": "g_{k}\\left(h_{i}\\right)=\\sqrt{\\frac{2}{D_{L}}} \\cos \\left(W_{L} h_{i}+b_{L}\\right)^{T} \\beta_{k}, k=1, \\ldots, K,"}, {"content": "p\\left(y^{*} \\mid x^{*}\\right)=\\int_{s \\sim \\mathcal{N}\\left(\\mu_{k}\\left(x^{*}\\right), \\sigma_{k}\\left(x^{*}\\right)\\right)} \\gamma(s),"}, {"content": "\\Gamma: \\mathcal{X} \\rightarrow\\left\\{\\text { subset of }\\{1,2, \\ldots, K\\}\\right\\},"}, {"content": "1-\\alpha \\leq P\\left(y^{*} \\in \\Gamma\\left(x^{*}\\right) \\mid x^{*}\\right) \\leq 1-\\alpha+\\frac{1}{R+1},"}]}