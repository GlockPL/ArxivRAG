{"title": "Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology", "authors": ["Junior Cedric Tonga", "Benjamin Clement", "Pierre-Yves Oudeyer"], "abstract": "The automatic generation of hints by Large Language Models (LLMs) within Intelligent Tutoring Systems (ITSs) has shown potential to enhance student learning. However, generating pedagogically sound hints that address student misconceptions and adhere to specific educational objectives remains challenging. This work explores using LLMs (GPT-40 and Llama-3-8B-instruct) as teachers to generate effective hints for students simulated through LLMS (GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling math exercises designed for human high-school students, and designed using cognitive science principles. We present here the study of several dimensions: 1) identifying error patterns made by simulated students on secondary-level math exercises; 2) developing various prompts for GPT-40 as a teacher and evaluating their effectiveness in generating hints that enable simulated students to self-correct; and 3) testing the best-performing prompts, based on their ability to produce relevant hints and facilitate error correction, with Llama-3-8B-Instruct as the teacher, allowing for a performance comparison with GPT-40. The results show that model errors increase with higher temperature settings. Notably, when hints are generated by GPT-40, the most effective prompts include prompts tailored to specific errors as well as prompts providing general hints based on common mathematical errors. Interestingly, Llama-3-8B-Instruct as a teacher showed better overall performance than GPT-40. Also the problem-solving and response revision capabilities of the LLMs as students, particularly GPT-3.5-turbo, improved significantly after receiving hints, especially at lower temperature settings. However, models like Mistral-7B-Instruct demonstrated a decline in performance as the temperature increased. This study advances our understanding of the potential and limitations of LLMs in educational contexts, towards integrating these models into pedagogically grounded.", "sections": [{"title": "1. Introduction", "content": "Digital education has gained popularity over the last decade, highlighting the importance of Intelligent Tutoring Systems (ITSs). These systems are seen as essential tools to address specific educational challenges, such as the need for personalized learning in a system often"}, {"title": "2. Related work", "content": ""}, {"title": "2.1. Advances in ITS in Education through LLMs", "content": "Thanks to their ability to provide students with a personalized and effective learning experience, ITSs have gained popularity in the field of education (Winkler and S\u00f6llner, 2018). According to (Feng et al., 2021), these systems can be classified into four main categories. Dialogue-based tutoring ITS, such as AutoTutor (Graesser et al., 2004) and Beetle (Dzikovska et al., 2010) leverage natural language to identify students' misconceptions and respond to their prompts. Constraint-based scaffolding models (Mitrovic et al., 2013), exemplified by KERMIT (Suraweera and Mitrovic, 2002) use constraints predefined by human experts to respond to student queries. Model tracing (Liu et al., 2022; Sonkar et al., 2020) monitors students' knowledge states to capture their problem-solving skills. Bayesian network modeling (Corbett and Anderson, 1995) extends model tracing by using Bayesian networks.\nFurthermore, recent advances in generative artificial intelligence, particularly with the emergence of LLMs such as GPT-4 (Bubeck et al., 2023) from OpenAI and more compact models like Llama (Touvron et al., 2023b) from Meta, have demonstrated their poten-"}, {"title": "2.2. LLMs for Feedback and Hint Generation", "content": "Before the recent advances in generative artificial intelligence, one of the commonly used approaches for generating feedback or hints in the educational field relied on features de-signed to detect errors in students' responses. A rule-based system was then employed to provide relevant comments or hints (Botelho et al., 2023; Kochmar et al., 2020; Lan et al., 2015; Razzaq et al., 2020; Singh et al.; Song et al., 2021). This approach was popular due to its interpretability and reliability. However, it required significant human effort to adapt to new types of questions. With the advent of LLMs, a more general approach for gen-erating feedback or hints involves using these advanced models either through prompting\n(Al-Hossami et al., 2023; McNichols et al., 2024; Nguyen et al., 2023; Steiss et al., 2023;\nWang et al., 2024) or fine-tuning (Qinjin Jia et al., 2022). Several studies have been con-ducted in this area, particularly in the context of programming education. For example, (Roest et al., 2023) explored how LLMs can contribute to programming education by pro-viding students with automated hints for the next steps. They found that most of the feedback messages generated by LLMs describe a specific step to follow and are personal-ized based on the student's code and approach. However, these hints can sometimes contain misleading information and lack sufficient detail when students are nearing the end of an exercise.\nSimilarly, (Phung et al., 2023) studied the role of generative AI models in providing human tutor-like hints to help students resolve errors in their faulty programs. However,"}, {"title": "2.3. Simulation of Human Behaviors by LLMs", "content": "LLMs have the ability to simulate human behaviors, a capability that has shown promis-ing applications in the field of education. For instance, (Markel et al., 2023) introduced GPTeach, an interactive teacher training tool based on a chat system. This tool allows novice teachers to practice with simulated students, using GPT to take a prompt and generate a response to it (Brown et al., 2020). In our study, inspired by the work pre-sented in (Markel et al., 2023), we simulate both teachers and students. Moreover, other studies have suggested that LLMs can be prompted to replicate desired model behaviors (Jiang et al., 2021, 2022; Liu et al., 2021). Recently, a study (Argyle et al., 2023) demon-strated that with specific prompting techniques, LLMs can successfully simulate human sub-populations. This work is supported by (Arora et al., 2022), who described various effective prompting techniques. In contrast to these approaches, (Park et al., 2023, 2022) used specialized GPT prompting techniques to simulate not just one person, but an entire online community composed of simulated individuals, each with a unique personality."}, {"title": "3. Methodology", "content": "As a first step, generating high-quality hints requires a rigorous approach to understanding how hints are created when LLMs play the roles of students and teachers. Then, how can we simulate a student and a teacher with LLMs? To achieve this, we used prompt engineering\n(Sahoo et al., 2024)."}, {"title": "3.1. Prompt design for question hint generation", "content": "To obtain high-quality hints, various approaches were considered for designing prompts and compare them. This led to the development of specific pipelines allowing to test and identify the best prompts for generating relevant and useful hints. A detailed picture of the pipeline can be found in Appendix 4(a). This pipeline is divided into two main stages. The first stage is executed first, followed by the second stage using the datasets obtained from the first stage.\nThe first stage implements the generation and classification of the student answers. The objective of this step is to create, for each exercise, a diverse dataset of incorrect answers, including different incorrect reasoning or solutions.\n1.  Resolution by the student model: For each exercise, the student model solves it using the prompt described in Appendix A.3.1, producing reasoning and a response.\n2.  Verification of the response by GPT-40: The response from the student model is compared to the correct solution using the prompt in Appendix A.3.4.\n These two steps are repeated a predetermined number of times $num\\_simulations$ where $num\\_simulations$ represents the number of attempts to solve the same exercise by the student model.\n3.  Error classification: After manually evaluating the incorrect responses of simulated students, we identified the following common types of errors: misunderstanding, inter-pretation, calculation, simplification, algebraic errors, partial answers, term grouping, and incorrect substitution. To automate the determination of these error types, we employed GPT-40 using few-shot prompting (Sahoo et al., 2024), as detailed in the prompt described in Appendix A.3.4, which includes examples for each common error type. GPT-40 was then used to categorize error types or groups of errors (multiple errors present in a simulated student's incorrect response), allowing for the creation of a diverse error dataset with various reasoning mistakes or incorrect solutions, using the prompt described in Appendix A.3.5.\nAt the end, a dataset of exercise solutions is produced that includes all the student model's responses, whether correct or incorrect, corresponding to the number of simulations con-ducted. We also have an error classification dataset containing various incorrect responses and reasoning by error type.\nThe second stage implements the generation of hints and revision of various incorrect responses. Only one incorrect answer per error type is retained from the error classification dataset obtained in stage 1 to form the one used in this step.\n1.  Hint generation by the teacher Model: For an incorrect response in the dataset, the teacher model generates appropriate hints based on the type of prompt used for hint generation. These prompts are described in Appendix A.4.\n2.  Revision of the response by the student model: The student model uses these hints to revise its initial response using the prompt in the Appendix A.3.2.\n3.  Verification of the revised response by GPT-40: The revised response is checked again by GPT-40 to ensure it is now correct. This is done by using the prompt described"}, {"title": "3.2. Pipeline for evaluating the best prompts", "content": "To evaluate these prompts, we implemented the pipeline illustrated in Figure 4(b). This pipeline describes a process for evaluating the best prompts. Initially, responses are col-lected from a dataset of exercise resolutions generated by a student model. If a response is incorrect, a teacher model provides a hint using the best-selected prompt. The student model then revises its response based on this hint. The revised response is subsequently sub-mitted to GPT-40 for re-verification, and the outcome is recorded. This process is repeated for all responses in the dataset. By the end of the pipeline, we have a comprehensive dataset containing all responses before and after hint generation, along with their corresponding evaluations."}, {"title": "4. Experiments settings", "content": "For these experiments, we worked with the mathematics exercises from MIA Seconde ed-ucational software. MIA Seconde is an educational tool developed by EvidenceB, which offers remediation exercises in French and mathematics for students in general, technolog-ical, and vocational high school classes. These exercises were initially developed through collaboration with researchers in cognitive science and neuroscience, drawing on insights into how the student's brain functions and theories about human mathematical cognition. The theory underlying the MIA Seconde exercises is documented in guides called pedagogi-cal summaries. A pedagogical summary is an official document from EvidenceB that serves as a reference for the design of these exercises. These summaries are organized into different modules, objectives, and activities, each focusing on a specific knowledge or skill.\nModules correspond to an overarching skill developed in the exercises. It generally refers to a sub-discipline of French or mathematics, for example, \"quantities and measurements\"."}, {"title": "5. Experiments and results", "content": "In this section, we analyze the performance of GPT-40 and Llama-3-8B-Instruct as teachers by evaluating their ability to generate helpful hints for solving math problems. We examine student model errors, the best hint generation prompts, and the impact of temperature on the models' problem-solving and revision skills."}, {"title": "5.1. What types of errors student models make when solving math exercises,\nand how does it depend on the temperature parameter?", "content": "The types of errors considered are: Comprehension Error: the student does not understand the problem or instructions clearly; Partial Response: the student provides only part of the answer and fails to complete it correctly; Term Grouping Error: the student incorrectly combines or groups terms in an expression; Simplification Error: the student simplifies an expression incorrectly; Calculation Error: the student performs mathematical operations incorrectly; Incorrect Substitution Error: the student substitutes the wrong value in an expression or equation; Interpretation Error: the student misinterprets the instructions or data; Algebraic Error: the student makes mistakes in algebraic manipulations. These errors were identified through manual evaluation and common student mistakes in math, then used in \"few-shot prompting\u201d with GPT-40 for evaluating student model responses, as mentioned in the error classification phase of the pipeline (see 3.1). We manually verified the phases of answer checking, error classification and error type determination to ensure GPT-40's was not making any mistakes. In most cases, the results were correct (around 98% of the time).\nTo analyze the types of errors made by the student models when solving the four exercises under standard settings (default temperature), the first two steps of the initial stage in the pipeline for determining the best prompt for hint generation (see Figure 4(a)) were executed 40 times for each exercise. It is equally interesting to observe how the results vary when the temperature value is adjusted, as temperature is a parameter that controls the creativity and diversity of the responses generated by the model. To explore this, the process was repeated for each temperature value (0, 0.2, 0.5, 0.8, 1) across all models. Studying the effects of different temperature values would also allow us to determine whether the temperature parameter can influence the student model's ability to incorporate a hint"}, {"title": "5.2. What type of prompt is most effective for generating hints with GPT-40?", "content": "In order to select the best prompts for generating hints, we defined several prompts, which can be grouped into two categories.\nFirst, prompts based on the types of errors made by the student model aim to correct a key aspect of the student's response. They are based on reasoning, the student's response, the instruction, the cognitive approach, the correct answer, and the exercise, and incorporate these elements into the context. They are labelled as follow: prompt_hint_reason is based on the student's reasoning; prompt_hint_method is based on the method used by the student; prompt_hint_concpt is based on the application of concepts;"}, {"title": "5.3. What is the influence of the temperature parameter on the performance\nof the student models in solving exercises and revising answers?", "content": "We worked with the best prompts from both categories, specifically the calculation-based prompt for the specialized prompts and BaselineTwo for the baseline-type prompts. To study how temperature could impact the resolution and revision by the student models, we used the validation pipeline shown in Figure 4(b). Note that when revising the student's response, the same temperature value used during the resolution is applied. Metric such as accuracy was used to quantify the performance of these models using the best prompts. It was computed as the number of correct responses out of the 40 repetitions divided by the number of responses (number of correct+number of incorrect responses).\nFigures 3 and 2 do not show a clear direct link between the ability of student models to solve exercises and revise their answers when GPT-40 or Llama-3-8B-instruct are used as teachers. However, for the GPT student model, we observe that accuracy during both solving and revision decreases when the temperature is set to 1, which is not always the case for the other student models. Conversely, for lower temperatures (e.g., 0 or 0.2), accuracy increases."}, {"title": "5.4. How does the accuracy of student model problem-solving evolve before\nand after providing hints when they are guided by Llama-3-8B-Instruct\ncompared to GPT-40?", "content": "Since our goal is to use LLMs for hint generation, we were curious to see how a smaller language model like Llama-3-8B-Instruct would perform in generating hints. Therefore, we used it as the teacher model in the pipeline shown in Figure 4(b), utilizing the best prompts.\nFigures 3 and 2 show that whether the BaselineTwo prompt or the one based on cal-culation errors is used with GPT-40 or Llama-3-8B-instruct, the models manage to correct themselves. A notable improvement is particularly observed for the GPT-3.5-turbo model. Indeed, the accuracy of this model increases significantly after receiving a hint, even if its ini-tial accuracy was low. In contrast, the other models show a more moderate increase. When GPT-40 is used as the teacher, the hints provided by the error-based prompt seem more effective in improving the student models' performance than those from the BaselineTwo prompt. However, the opposite effect is observed with Llama-3-8B-instruct as the teacher. Comparing the two teacher models, the figures suggest that the overall performance is better"}, {"title": "6. Discussion and Limitations", "content": "Our work addresses a gap in hint generation research within the field of mathematics edu-cation. We demonstrated that language models could identify their own errors when acting as students, with error patterns varying based on the temperature setting. Higher temper-atures led to more diverse outputs but increased errors, while lower temperatures produced more deterministic. This error detection was crucial for selecting effective prompts for gen-erating a synthetic hint dataset. We found that prompts focused on error correction and the BaselineTwo prompt were most successful. This aligns with the known challenges lan-guage models face with calculations and reasoning tasks. Interestingly, our results differ from a previous study (Renze and Guven, 2024) on Multiple-Choice Question Answering (MCQA), which found that temperature did not impact problem-solving abilities but af-fected text variability. In contrast, we observed no clear link between temperature and problem-solving in our non-MCQA tasks, where we used only zero-shot approaches.\nGPT-3.5-turbo showed the most effective self-correction after receiving optimized hints, likely due to the prompts being tailored for base GPT models, leading to a significant correction gap compared to other student models. Mistral-7B-instruct-v3 and Llama-3-8B-instruct, however, already had high accuracy with the hints, making further improvement harder, though their additional corrections remain noteworthy.\nNotably, the Llama-3-8B-instruct model outperformed GPT-40 in accuracy when using the best prompts, challenging the assumption that larger models like GPT-40 are always superior. Future work should include a qualitative analysis of the generated hints in relation to pedagogical criteria and their relevance, as well as explore the potential of fine-tuning smaller models, such as Llama-3-8B-instruct, for hint generation.\nThis study has, however, several limitations. First, we only used four exercises from different modules, which is not sufficient for a comprehensive analysis, even though each exercise was solved 40 times. Results may differ with other exercise variants within these modules. Additionally, the cost of the API limited the number of exercises we could analyze.\nThe prompts for hint generation were optimized for GPT models, not for other models, so more tailored prompts might produce better results for non-GPT models. We also limited our analysis to GPT-4o and GPT-3.5-turbo due to cost constraints. Error type classification was evaluated only with GPT-40, without the involvement of human experts, though some human verification was done. Including expert evaluation would provide deeper insights. Finally, the lack of qualitative analysis of the generated hints is another limitation, as such an analysis could offer valuable context and improve the overall assessment of hint quality."}, {"title": "Appendix A. Additional information", "content": ""}, {"title": "A.1. Experimental pipelines", "content": "This section outlines the pipelines used in our various experiments."}, {"title": "A.2. Implementation details", "content": "We used the OpenAI API to interact with models based on GPT, such as GPT-40 and GPT-3.5-turbo. For other open-source models, like Llama-3-8B-Instruct and Mistral-7B-"}, {"title": "A.3. Prompts", "content": "In this section, we present the various prompts used in the pipelines. These prompts were written in French in our experiments, but for the purposes of the paper, we have translated them into English."}, {"title": "A.3.1. PROMPT FOR EXERCISE RESOLUTION BY THE STUDENT MODEL", "content": "{\"role\": \"system\", \"content\": \"You are a high school student who must solve mathematics exercises.\"},\n{\"role\": \"user\", \"content\":\u2019''Your objective is to answer the questions in the exercises by following the given instructions.\nExercise and question: {exercise}\nInstructions: {instruct}\nRequired answer format: use a JSON format with the following structure:\n{\"reasoning\": \"Explain your reasoning here...\", \"answer\": \"Provide your answer here...\"}\nI emphasize that you must follow the required response format, and also that you must answer the questions in the exercises by following the instructions as given, without adding anything.\u2019'''}"}, {"title": "A.3.2. PROMPT FOR ANSWER REVIEW BY THE STUDENT MODEL", "content": "{\"role\": \"system\", \"content\": \"You are a high school student who must solve mathematics exercises.\"},\n{\"role\": \"user\", \"content\": '''You provided an incorrect answer to a math exercise.\nA teacher has given you a hint to help you understand your mistake and correct it. Your objective is to review your response to the questions in the exercise using the hint provided by the teacher.\nExercise and question: {exercise}.\nInstruction: {instruct}\nHint: {hint}"}, {"title": "A.3.3. PROMPT FOR CLASSIFYING HINTS", "content": "{\"role\":\"system\"", "content\":\"You are an expert in teaching mathematics\"},\n{\"role\": \"user\", \"content\":\u2019'\u2019Your task is to verify if a student's revised answer\nto a mathematics exercise is correct or not by comparing it with the correct\nanswer(s) provided. The exercises may have either a single correct answer or\nmultiple correct answers.\nThe correct answer(s) for the exercise: {answer}\nThe student's revised answer: {revised_response}\nThe hint: {hint}\n1)- If the student's revised answer does not match the correct answer or any\nof the correct answers (if multiple), then put the hint in the \"wrong_hint\" field\nof the output.\n2)- If the student's revised answer includes at least one correct answer or\nall the correct answers, put the hint in the \"correct_hint\" field of the output.\nI insist on this, please follow this criterion.\n3)- If the hint contains the correct answer(s) or parts of the correct answer(s),\nthen put the hint in the \"wrong_hint\" field of the output.\nPut the output in a JSON format with the following structure: {{\"": "orrect_hint\"", "\",\\\"": "rong_hi=\nMake sure that the generated output does not contain escape characters such as\nline breaks (\\\\n) or slashes (\\\\).\nPlease provide a clean and readable output. I insist on this. Do not make any\nformatting errors.\nFollow the output format, and also follow the evaluation criteria and your role.\nDo not add anything else.\u2019'''}"}, {"title": "A.3.4. PROMPT FOR CHECKING IF THE ANSWER IS CORRECT AND DETECTING THE\nTYPE OF ERROR", "content": "{\"role\": \"system\",\"content\": \"You are an expert in teaching mathematics\"},\n{\"role\": \"user\",\"content\":\u2019\u2019\u2019Your task is to verify whether a student's answer\nto a mathematics exercise is correct or not by comparing it with the correct\nanswer(s) provided. Exercises may have either a single correct answer or multiple\ncorrect answers.\nThe correct answer(s) for the exercise: {answer}\nThe student's answer: {student_answer}\nThe student's reasoning: {reasoning}"}, {"title": "A.3.5. PROMPT FOR OBTAINING THE DIVERSE DATASET WITH DIFFERENT REASONING\nAND ANSWERS PER TYPE OF ERRORS", "content": "{\"role\": \"system\", \"content\": \"You are an expert in teaching mathematics\"},\n{\"role\": \"user\", \"content\": f\u2019','\nYour task is to classify a list of reasonings that contain multiple categories\nof errors. For each error category, you must provide the best examples with different\nreasoning.\nIn each reasoning, there may be multiple error categories. If that's the case,\nthen you must find examples that are different for that group of error categories.\nThe error categories are already provided in the reasonings.\nFor each error category or group of error categories, you need to identify and\nprovide the best k examples of different reasoning.\n### Output Format\nMake sure the generated output does not contain escape characters such as line\nbreaks (\\\\n) or slashes (\\\\).\nPlease provide a clean and readable output. I insist on this. Do not make any\nformatting errors. Do not add errors that are not in the list.\nYou must provide the output in JSON format with the following structure:\n{{\n\"different_reasoning\": {{\n\"category_1\": [\n{{", "gpt_initial_reasoning\"": "\",\"", "initial_response\"": "\",\"", "evaluation\"": "n\"", "}},\n],\n\"category_2\": [\n{{": "pt_initial_reasoning\": \"", ",\"": "nitial_response\": \""}, {",\"": "valuation\":\n\""}, {"title": "A.4. Prompt for hint generation", "content": "For the generation of hints, there are only a few differences in the user's role in each prompt.\nThe rest of the content is identical, which is why we will include a complete example of one\nprompt. For the other prompts, we will only provide the user's role definition, specifying\nthat the rest of the prompt follows the same structure."}, {"title": "A.4.1. BASELINE PROMPT", "content": "BaselineOne prompt\n{\"role\": \"system\"", "content\": \"You are an expert in teaching mathematics, helping\nstudents solve a math exercise by providing guiding hints following a specific\ncognitive approach.\"},\n{\"role\": \"user\", \"content\":\u2019\u2019\u2019Your goal is to generate progressive hints to\nhelp students solve an exercise while following the specified cognitive approach.\nThe hints should be given in increasing order of difficulty and should not reveal\nthe final solution. The hints should encourage students to think independently\nwhile providing useful guidance. The hints must be in the form of questions,\nand they must not reveal the correct answer or any part of it I insist on this.\nThe exercise and question: {exercise}.\nInstruction: {instruct}\nThe correct answer to the exercise: {answer}\nGuide according to the cognitive approach: {demarche_cog}\nRequired response format: use a JSON format with the following structure: {{\"": "ints\"", "prompt\n\"role\"": "user\", \"content\":\u2019\u2019\u2019Your goal is to identify the common mistakes that\nstudents might make and to generate hints in the form of questions that can help\nthem correct their mistakes and progress in solving the exercise. The hints must\nbe in the form of questions, and they must not reveal the correct answer or any\npart of it, I insist on this..."}, {"title": "A.4.2. PROMPT BASED ON ERROR TYPE", "content": "Prompt based on the student's reasoning\n{\"role\":\"system\", \"content\": \"You are an expert in teaching mathematics\"},\n{\"role\": \"user\", \"content\":\u2019\u2019\u2019Your goal is to provide a clear and relevant hint\nto the student to help them correct their reasoning mistakes in math exercises.\nIf the student has the correct answer, propose a hint to reinforce their understanding.\nThis hint must be in the form of a question. Additionally, the hint must not\ninclude the correct answer to the exercise or any part of it."}, {"title": "A.6. Description of exercises and pedagogical elements", "content": "This section presents the exercises used in our study, including key pedagogical elements such as the cognitive approach associated with each exercise, the type of exercise, the ex-ercise statement, instructions, and the corresponding answer. The exercises were originally written in French, and the experiments were conducted in French as well. The prompts were also written in French. For the purpose of this paper, we have translated them into English."}, {"title": "\u0391.6.1. EXERCISE 1 MODULE 1", "content": "Cognitive Approach: Transition from the concept of partitioning to the concept of frac-tion as a quotient, through the imposition of a constraint on the whole.\nLevel 1\nThis series of activities (A7, A8, A9) aims to gradually move beyond the intuitive notion that an equitable division of a whole composed of multiple units requires taking an equal part of each unit. Starting from Level 2, a condition imposed in the problem statement \"forces\" the student to counter this conception. The goal is to progressively reach the un-derstanding of a fraction as a quotient. At Level 1, the statement aligns with the student's intuitive conception, with no imposed conditions.\nType of Exercise: The student is presented with a problem involving the division of a whole, composed of $n$ units, into $m$ parts.\nExample: The whole consists of 4 units, represented by 4 wooden planks. The whole is divided into 3 equal parts, and the student is asked to interpret the value of one part's size, given the condition of equal portions of each unit. The statement allows the student with a partition-based understanding of fractions to solve the problem by reasoning as follows:\n is like 4 times one-third of 1.\nExercise Statement:\n\"Elias bought two quiches of the same size. He decides to eat one-quarter of the quiches"}, {"title": "A.6.2. EXERCISE 2 MODULE 2", "content": "Cognitive Approach: Adopt a dual perspective to model a multi-step algebraic problem using a literal expression represented both as a sum and as a product.\nLevel 4\nThis series of activities (A1, A2, A3, A4) encourages flexibility in problem-solving strategies, moving beyond the strategy suggested by the problem's context and enabling the student to consider an alternative strategy based on the distributive property. This activity rein-forces mastery of this property. Depending on the problem scenario, the student's intuitive approach might involve modeling with a literal expression in either expanded form (sum of expressions) or factored form (product of expressions).\nAt Level 4, one step in the problem requires expressing one variable in terms of another, with an additional challenge introduced as the relationship between these two variables is expressed as a ratio. This ratio involves either multiplying by a fraction less than 1 or dividing by a whole number. For example,  of a tulip corresponds to 1 rose.\nType of Exercise: The student is asked to model a two-step problem using a literal expression by selecting one or more correct answers from four given options.\nExercise Statement:\n\"To decorate her house, Julie enters a store and buys 5 of each of the following items: green plants and flower pots. The price of a green plant varies depending on the store's stock. A green plant costs 3 times as much as a matching flower pot.\nLet $p$ be the price of a green plant. How much did Julie pay in total?\"\nInstruction:\nIdentify the expressions that represent the total price Julie paid.\nSelect the correct answer(s): $5p + ? 5(p+)? 5p+\u00a7?$\nAnswer:\n$5p+  and 5(p+).$"}, {"title": "A.6.3. EXERCISE 1 MODULE 2 (SIMILAR TO THE PREVIOUS MODULE, ONLY THE\nEXERCISE IS PRESENTED HERE)", "content": "Exercise Statement:\n\"In a restaurant, there are 30 tables. Each table has a bouquet. The number of roses in each bouquet varies depending on the arrivals. Each bouquet contains three times fewer roses than tulips.\nLet $r$ be the number of roses. How many flowers are there in total in this restau-rant?\""}, {"title": "A.7. Example of good and poor revision of student models on exercise 1 -\nmodule 1 after receiving a hint from the teacher model using one of the\nbest prompts", "content": "The conversation between teacher and student is in French in our experiments, but we have translated it into English for the purposes of this paper.\n\u2022 Teacher Model: Llama-3-8B-instruct\nStudent Model: GPT-3.5-turbo\nInitial Reasoning: Elias decided to eat a quarter of both quiches, so he will eat 1/4 of each quiche. Since he wants to eat an equal part of each quiche, he will eat half of the portion he took from each quiche, which is 1/2 * 1/4 = 1/8 of each quiche.\nInitial Answer: Elias will eat 1/8 of the first quiche and 1/8 of the second quiche."}]}