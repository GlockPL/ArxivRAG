{"title": "An investigation into the causes of race bias in AI-based cine CMR segmentation", "authors": ["Tiarna Lee", "Esther Puyol-Ant\u00f3n", "Bram Ruijsink", "Sebastien Roujol", "Theodore Barfoot", "Shaheim Ogbomo-Harmitt", "Miaojing Shi", "Andrew P. King"], "abstract": "Artificial intelligence (AI) methods are being used increasingly for the automated segmentation of cine cardiac magnetic resonance (CMR) imaging. However, these methods have been shown to be subject to race bias, i.e. they exhibit different levels of performance for different races depending on the (im) balance of the data used to train the AI model. In this paper we investigate the source of this bias, seeking to understand its root cause(s) so that it can be effectively mitigated. We perform a series of classification and segmentation experiments on short-axis cine CMR images acquired from Black and White subjects from the UK Biobank and apply AI interpretability methods to understand the results. In the classification experiments, we found that race can be predicted with high accuracy from the images alone, but less accurately from ground truth segmentations, suggesting that the distributional shift between races, which is often the cause of AI bias, is mostly image-based rather than segmentation-based. The interpretability methods showed that most attention in the classification models was focused on non-heart regions, such as subcutaneous fat. Cropping the images tightly around the heart reduced classification accuracy to around chance level. Similarly, race can be predicted from the latent representations of a biased segmentation model, suggesting that race information is encoded in the model. Cropping images tightly around the heart reduced but did not eliminate segmentation bias. We also investigate the influence of possible confounders on the bias observed.", "sections": [{"title": "Introduction", "content": "Cardiac Magnetic Resonance (CMR) imaging is widely used to acquire images for diagnosis and prognosis of cardiovascular conditions. Artificial intelligence (AI) methods are increasingly being used to automate the estimation of functional biomarkers from cine CMR by automatic delineation (segmentation) of cardiac"}, {"title": "Contributions", "content": "The contribution of this work is to investigate the cause of bias in AI-based CMR segmentation models. We show that the main source of bias is in the image content outside of the heart region and that bias can be reduced by cropping the images before training the AI models."}, {"title": "Methods", "content": ""}, {"title": "Dataset", "content": "The dataset used in the experiments described in this paper comprised cine short axis (SAX) CMR images from 436 subjects from the UK Biobank [8]. For each subject, typically 7 - 13 SAX slices were available at 50 time frames covering the cardiac cycle. The demographic information of the subjects can be found in"}, {"title": "Models used", "content": "To perform the investigations into the source of bias we employ two types of AI model: a classification model and a segmentation model.\nResNet-18 is a deep convolutional neural network (CNN) for classification consisting of 18 layers [10]. The network has residual blocks and skip connections which can be used to form deep networks. For the classification experiments (Experiments 1 and 2 in the Results), the model was trained for 100 epochs with an initial learning rate of 0.001 which decreased by a factor of 10 every 50 epochs. The loss function used was binary cross entropy and the model was optimised using stochastic gradient descent. The batch size was 16. The images were augmented using random mirroring, rotating, scaling and translation. As the images are greyscale, no colour intensity transformations were used. Each model was trained 10 times with different random seeds and train/validation splits and the mean and standard deviation for these 10 runs is reported.\nFor the classification network, we also employed the gradient-weighted class activation mapping method, or GradCAM, which is a visualisation and interpretability method [11]. The gradients of the target class (in our case, race) in the last convolutional layer of the classification network were visualised to produce a heatmap which shows the areas of an image that were most important for the classification decision.\nFor the segmentation experiments, we used nnU-Net, a self-adapting frame-work for segmentation of biomedical images [12]. The network automatically"}, {"title": "Statistical evaluation", "content": "Classification accuracy was evaluated using overall accuracy, sensitivity and specificity. Differences in performances were evaluated using a two-tailed Student's t-test of the accuracies of the 10 runs. Segmentation performance was evaluated using the Dice Similarity Coefficient (DSC) which measures the overlap between ground truth and predicted segmentations where 1 is a perfect overlap and 0 is no overlap. Confounder analysis was performed using linear regression models in SPSS Statistics (IBM Corp. Released 2023. IBM SPSS Statistics for Macintosh, Version 29.0.2.0 Armonk, NY: IBM Corp)."}, {"title": "Results", "content": "The experiments performed using the data and models described above aimed to investigate three aspects of the bias in AI CMR segmentation performance as detailed below."}, {"title": "Experiment 1: Source of bias", "content": "Bias in AI models is often the result of a distributional shift in the data of subjects in different protected groups. Combined with imbalance in the training data, these distributional shifts can lead to bias in performance of AI models [6,13]. However, the distributional shift can be in the images, the ground truth segmentations or a combination of both. Understanding the origin of the bias in trained segmentation models is important when deciding on strategies to address it. Therefore, the first experiment aimed to assess the extent of the distributional shift between the CMR images and/or the ground truth segmentations.\nTo quantify the extent of the distributional shifts, we trained ResNet-18 models to classify the race of the subject (White vs Black) from a single SAX CMR image and/or segmentation. The SAX CMR images and ground truth segmentations of the 218 Black and 218 White subjects were randomly split"}, {"title": "Experiment 2: Localisation of source of bias", "content": "The first set of experiments resulted in high accuracy for race classification, suggesting a strong distributional shift. They also suggested that the source of the bias was mainly in the images and that it was being encoded into the segmentation model. Therefore, we next sought to understand which parts of the images were leading to the distributional shift and hence the bias. To visualise the relative importance of the different regions of the image, we used GradCAM [11] applied to the race classification models.\nThe results are shown in with normalised CMR images and Grad-CAM images. These representative examples show that for both the Black and White subjects, the most attention is being given to non-heart regions such as subcutaneous fat. Further examples can be seen in Fig. S2 and Fig. S3.\nBy visual inspection of all test images, we found that 42% of the images had the highest activations in non-heart anatomical regions of the body whereas only 6% had the highest activation in heart regions. The remaining 52% could be classified as 'activations due to image artefacts' (50%) and \u2018other' where there were no clear activations in any particular area (2%). These image artefacts become visible after normalising the images which occurs before model training."}, {"title": "Experiment 3: Are the biases observed in AI CMR segmentation due to confounders?", "content": "Differences in covariates between protected groups may lead to distributional shifts and consequent bias in the AI CMR segmentation models. We investigate whether this is the case by comparing the DSC and the covariates of the subjects"}, {"title": "Discussion", "content": "In this paper, we have shown that race can be predicted from single SAX CMR images with very high accuracy. However, the accuracy of predicting race from CMR segmentations was noticeably lower, indicating that the distributional shift between White and Black protected groups is mostly in the CMR images as opposed to the manual segmentations.\nThe GradCAM images showed that the classification networks had the highest activations in non-heart regions such as subcutaneous fat and image artefacts, a result that was further demonstrated by the classification experiments using a dataset with the heart \"removed\" from the images. The accuracy here remained high whereas we found low classification accuracy using images cropped tightly around the heart. This suggests that there are fewer race-specific features in the images of the hearts of White and Black subjects and that the distributional shift is mostly in non-heart regions. A similar result was found in [16] where occluding regions identified by saliency maps as important for race classification from chest X-ray images caused the accuracy to decrease.\nWhen looking at segmentation tasks, the high classification accuracy of the logistic regression model showed that subjects' races were encoded in the latent representations of the CMR images, which makes this encoding a likely cause of the bias in segmentation performance. Cropping the images in a similar fashion to the classification experiments reduced, but did not eliminate, the bias found in the segmentation experiments. We speculate that the remaining bias is due to some anatomical differences in the heart region and the fact that it was not possible to completely crop out non-heart regions in all images because of the variability in heart size and the need to maintain a constant image size for AI model training.\nThe covariate analysis indicated that some variables seem to be acting as confounders. LVEDM, LVSV and LVEF were correlated with DSC score for Black subjects but not for White subjects. Black and White subjects are known to have differences in body composition such as fat distribution and bone density [17] as well as differences in cardiac anatomy such as Black subjects having higher left ventricular mass [18]. These distributional shifts may be recognisable to a model and may be used for classification tasks and lead to bias in segmentation tasks. MRI year was also a confounder for Black subjects. We further investigated this and found that, by chance, the White subjects selected in our dataset were on average scanned in earlier years than the Black subjects. It is possible that there were differences in image artefacts over time due to small changes in the acquisition protocol, which would be consistent with the GradCAM activations focusing on artefact areas 50% of the time. Therefore, we reran the segmentation experiments (using the different levels of race imbalance as in Experiment 2) using data which were also matched by MRI year but found no difference in bias characteristics or performance (see Fig. S5). Therefore, we conclude that this was a spurious confounding effect caused by random selection of White subjects who were scanned earlier."}, {"title": "Conclusion", "content": "We have performed a series of experiments to investigate the cause of AI CMR segmentation bias. Our conclusions are (i) the distributional shift between White and Black subjects is mostly, but not entirely, in the images rather than the segmentations, (ii) differences in body fat composition outside of the heart are a likely cause of the distributional shift and hence the bias, (iii) cropping the images around the heart reduces but does not eliminate the bias. Our results will likely be valuable to researchers aiming the train fair AI CMR segmentation models in the future.\nAs a recommendation for future development of AI CMR segmentation tools, we suggest that training models using images cropped around the heart may be beneficial. However, this does raise the question of how best to crop images in this way at inference time, when ground truth segmentations are obviously not available. Region-of-interest detection methods such as Mask R-CNN [19] may be useful for this purpose. We also emphasise that such an approach should not be seen as a substitute for more equal representation in CMR datasets. Our experiments have focused on Black and White subjects but previous work [6] has shown that similar bias effects exist for Asian subjects and by sex [7]. Therefore, we argue for greater representation of all protected groups in CMR datasets."}]}