{"title": "Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences", "authors": ["Claudio Pinhanez", "Paulo Cavalin", "Luciana Storto", "Thomas Fimbow", "Alexander Cobbinah", "Julio Nogima", "Marisa Vasconcelos", "Pedro Domingues", "Priscila de Souza Mizukami", "Nicole Grell", "Majo\u00ed Gongora", "Isabel Gon\u00e7alves"], "abstract": "Since 2022 we have been exploring application areas and technologies in which Artificial Intelligence (AI) and modern Natural Language Processing (NLP), such as Large Language Models (LLMs), can be employed to foster the usage and facilitate the documentation of Indigenous languages which are in danger of disappearing. We start by discussing the decreasing diversity of languages in the world and how working with Indigenous languages poses unique ethical challenges for AI and NLP. To address those challenges, we propose an alternative development AI cycle based on community engagement and usage. Then, we report encouraging results in the development of high-quality machine learning translators for Indigenous languages by fine-tuning state-of-the-art (SOTA) translators with tiny amounts of data and discuss how to avoid some common pitfalls in the process. We also present prototypes we have built in projects done in 2023 and 2024 with Indigenous communities in Brazil, aimed at facilitating writing, and discuss the development of Indigenous Language Models (ILMs) as a replicable and scalable way to create spell-checkers, next-word predictors, and similar tools. Finally, we discuss how we envision a future for language documentation where dying languages are preserved as interactive language models.", "sections": [{"title": "1 Introduction", "content": "Most of the recent extraordinary developments in Artificial Intelligence (AI) and Natural Language Processing (NLP), such as Large Language Models (LLMs), have predominantly used English language texts and data gathered in developed countries. These advancements have primarily targeted the needs and problems of those populations. Even within these countries, racial, ethnic, and linguistic minorities have been largely underrepresented in the construction of such models and technologies.\nThis paper describes research and work with Indigenous communities performed in the context of a joint project by IBM Research and the University of S\u00e3o Paulo, covering a period from early 2022 to mid-2024, under the auspices of the Center for Artificial Intelligence (C4AI).\nThe work described in this paper is premised on the need to increase the diversity of representation and knowledge in the technologies and language models being built. This involves encompassing a broad and diverse range of languages, peoples, places, and genders, as part of a social justice and decolonial agenda (Buccella, 2023).\nIn particular, we have been working for the past two years to create AI technologies for Indigenous peoples in Brazil, targeting small communities in where Indigenous languages are still in use but under threat. About 200 languages are spoken currently in Brazil by between one to two million people, but the vast majority of these languages are in danger of disappear until the end of the century (Moseley, 2010). Many of these languages are spoken by fewer than 100 people, often elderly, and are at immediate risk. Even the most spoken Indigenous language in Brazil, Tikuna, probably has at most 50,000 speakers.\nThe projects and ideas described here explore the development of technologies to support Indigenous communities in documenting, preserving, and vitalizing their languages. Developing language technologies, both for speech and text, for these languages has been difficult in the past because of a lack of resources and linguistic knowledge and of appropriate computational technologies capable of working with small amounts of data.\nHowever, as discussed in a recent UNESCO publication (Llanes-Ortiz, 2023), \u201c... artificial intelligence, natural language processing and automated speech recognition and voice processing could pro-"}, {"title": "2 Language Diversity is Decreasing", "content": "Languages are the most comprehensive record of human linguistic and cognitive evolution (Hale et al., 1992) and documenting and analyzing them is as important as Archaeology and Anthropology for understanding humanity's past. Moreover, languages have distinct ways of organizing thinking and comprehending reality and society (Harrison, 2008). The disappearance of a language, when its last speaker dies, is equivalent to the destruction of an archaeological site or the extinction of a specie.\nThere are about 7,000 different languages spoken in the world today, with 4,000 of them spoken solely by approximately 370 million Indigenous people. Of these, 2,680 are likely to disappear by the end of the century (Moseley, 2010). This threat to Indigenous languages has led the United Nations to establish 2022-2032 as the Decade of Indigenous Languages, in an effort led by UNESCO (UNESCO, 2020b). Language endangerment is a continuum, highly dependent on the number of speakers and, particularly, whether young children and teenagers speak the language."}, {"title": "3 Working with Indigenous Communities", "content": "Our work has been guided by the principle that technologies and solutions for Indigenous peoples must be developed with them, as stated in the Declaration of Los Pinos: \u201cNothing for us without us.\" (UNESCO, 2020a).\nSince the start of this project in 2022, we have been engaging with many communities in Brazil, including the Guarani Mbya, Guarani Kaiow\u00e1, Guarani Nhandewa, Tupi, Terena, Bar\u00e9, Wassu, Tukano, Pankararu, Zo\u00e9, and Mehinako peoples. We have also engaged organizations which work with Indigenous communities in Brazil, such as the Ministry of Indigenous Peoples, the Interamerican Development Bank (BID), the Federation of the Indigenous Organizations of the Rio Negro (FOIRN), the National Foundation of Indigenous Peoples (FUNAI), the Plurinational Union of Indigenous Students (UPEI), the Socio-Environmental Institute (ISA), and many other NGOs.\nThese engagements have resulted in two projects with communities of speakers of two languages, Guarani Mbya and Nheengatu, which we describe in this section. However, before discussing the projects, it is important to discuss the ethical principles and guidelines we have used to frame our engagement with those communities."}, {"title": "3.1 AI Research with Indigenous Peoples", "content": "Doing research with Indigenous peoples is subjected to specific guidelines and legal constraints. Mihesuah (1993) is a good example of a comprehensive set of guidelines for research with US American Indigenous communities. Straits et al. (2012) also proposed a set of guidelines on how to engage in research with Native US American communities based on 11 principles, including native-centrism, co-learning and ownership, continual dialogue, transparency and accountability, integrity, and community relevance."}, {"title": "3.2 Working in a Guarani Mbya School", "content": "In the case of the works described in this paper, we started in 2022 to contact various Indigenous groups and organizations in Brazil. Following a series of meetings with the Tenond\u00e9 Por\u00e3 community on the outskirts of S\u00e3o Paulo city, in 2023 we were invited by the community to explore the use of writing assistants by Indigenous high school students and to conduct activities fostering community-lead linguistic documentation and analysis. This school is part of an Indigenous land, home to approximately 1,500 people, where the main language is Guarani Mbya.\nThe Guarani Mbya language is spoken by approximately 6,000 people in Brazil (Morello and Seiffert, 2011), mostly in the South-Southeast region. Although it is still actively spoken and well-studied, there are few sources of translated texts and digitized data. Guarani Mbya belongs to the Tupi linguistic family and it is related to the Guarani language spoken by millions of people in Paraguay and Bolivia. However, it is as different from Guarani as Portuguese is from Spanish.\nThe invitation from the Tenond\u00e9-Por\u00e3 community led to weekly 2-hour workshops where various technologies and prototypes were introduced to and used by the high school students of the Gwyra Pepo Indigenous Guarani School. The students explored these technologies and discussed how to modify and improve them. As a result of this work, we developed an initial prototype of a writing assistant for the Guarani Mbya language, which included rudimentary electronic dictionaries, and word prediction, and basic translation.\nThe technical aspects of those tools are discussed in sections 4 and 5 but some of them could only be built because we applied state-of-the-art AI technology. For instance, the translator was developed by fine-tuning a German-English high-quality translator using data obtained from traditional dictionaries, schoolbooks, and folk tales, mostly from the collection of Prof. Robert Dooley (Dooley, 1985, 1988a,b, 2016), an expert in Guarani Mbya.\nWe faced a major challenge when we began designing the workshops with the high school students. As discussed in more detail in (Pinhanez, 2023), the last 15 years have produced many scholarly works with cases of engagement with Indigenous communities for the design of digital artifacts (Awori et al., 2015; Muntean et al., 2017; Taylor et al., 2017; Muashekele et al., 2019; Reitsma et al., 2019; Tzou et al., 2019; Moradi et al., 2020; Shedlock and Hudson, 2022). Most of these works focus describing key principles that designers should follow when engaging with Indigenous communities.\nHowever, while this literature offer extensive descriptions of what should be done in the design process, it often provides very limited on how the actual design process should happen. For instance, when considering the use of Respectful Design, proposed by Sheehan (2011), we could not find any literature on how it should be implemented in actual design processes. There are a few exceptions were details about how design workshops were conducted were actually provided (Taylor et al., 2017; Muashekele et al., 2019; Tzou et al., 2019). However, even in those cases a systematic description of the methods and means was never provided nor good ideas and practices on how to actually conduct the design workshops.\nInterestingly, some works discussing community research related to Indigenous education, schools, and connectivity (Franchetto, 2008a; Hermes et al., 2012; Arola, 2017; Leal and Teles, 2022) and Indigenous writing (Johnson, 1997; Franchetto, 2008a) were more helpful. In particular, the discussion in (Arola, 2017) about being an Indigenous person vs. doing the Indigenous way was enlightening and helped us to outline some initial ideas for the workshop.\nBased on this concept, we structured our workshops around three principles. First, we adopted the conversational structure observed in the three meetings we had with the leadership of the Tenond\u00e9-Por\u00e3 community. In those meetings, everyone was welcomed to voice their opinions, whenever they felt comfortable, and the discussion progressed at its own pace toward a consensus. In our work at the high school, students could enter and leave the classroom, stop to smoke their pipes, small children were welcomed to observe, and humor and laughing were valued and welcomed, similar to what we had observed in the meetings with the community.\nSecond, we began the process by exploring the students' current activities on the Internet, particularly on WhatsApp and in the game Free Fire. This served as a starting point to examined their use of"}, {"title": "3.3 An AI Development Cycle Suitable for Indigenous Communities", "content": "Consider all the different ethical issues discussed in sections 3.1 and the lessons learned working with the Guarani Mbya students explored in 3.2, we started to question whether the traditional ways AI has been often developed would work for Indigenous communities.\nFigure 4.a shows the traditional AI development cycle to text-based systems which starts with an initial cycle of data gathering, often from the Internet, identified as data crawling, followed by model training, and a repeating cycle of model usage, data collection from the users' interaction with the model, and retraining of the model.\nIs Internet crawling a feasible strategy for endangered Indigenous languages? Putting aside for a moment the issue of how to get approval and permission from Indigenous peoples to use data obtained from the Internet, an important technical challenge is to find public websites containing text in endangered Indigenous languages. As discussed before, data from disappearing languages is scarce (Vasconcelos et al., 2024), even for the languages considered here, with the number of speakers ranging from 1,000 to 100,000.\nTo find this data, which is dispersed among vast amounts of content in more used languages, it is fundamental to employ automatic mechanisms for language identification. In (Cavalin et al., 2023) we explored the development of language identifiers for 7 Brazilian Indigenous languages, using an SVM classifier with bag-of-words features trained on data from the Bibles dataset described in section 4. When tested with non-Bible data, recognition accuracy varied from 37.3% to 91.7% in test datasets with only Indigenous languages samples. Accuracy was higher when similar languages from the same linguistic family were considered. However, in a realistic evaluation where the data from more commonly used non-Indigenous languages were also present in high proportions, the performance was much worse (Cavalin et al., 2023).\nThe first impulse of AI developers and scientists in such conditions would be to engage the community to create a data gathering mechanism based on the promise of future use of the system. In our experience, this is very difficult because of both the difficulties in communicating how AI is built and the common distrust of those communities towards research projects as discussed before. Instead, our experience with the Guarani Mbya people suggested that a different framework for AI development is needed, centralized on the use of the tools by the community.\nFigure 4.b shows a diagram of the proposed AI development cycle. First, it is anchored on community engagement and community sovereignity, as central pillars to ethically and sustainably realize the focus of the development which is community usage. To enable the initial use by the community, there is an initialization step, with approval of the community, where a starter model is built based on linguistic data such as publicly available dictionar-"}, {"title": "3.4 Working with Nheengatu Speakers", "content": "Following our engagement with the Guaranis, we decided to focus on another Indigenous language, Nheengatu, which is spoken by approximately 20,000 people across three different areas of the Amazon area and in the Northeast of Brazil. This language is used by various peoples and ethnicities, including cases where the language was adopted by groups after the loss of their original language, such as the Bar\u00e9 people (Epps and Stenzel, 2013).\nThe choice of Nheengatu was motivated the availability of public data and knowledge, its multi-ethnic characteristic, the participation of linguistic experts at the University of S\u00e3o Paulo, and ongoing Indigenous-led initiatives focused on translation in Nheengatu. Also, there have been some recent efforts to bring Nheengatu to the digital world, such as the self-learning tool Nheengatu app.\nIn our on-going engagement with the community, we have been working on two basic workstreams."}, {"title": "4 Building Translators with Ultra-Low Amounts of Linguistic Data", "content": "In this section we look into the technical challenges and the solutions we have found to create bilingual machine translators (MTs) for Indigenous languages based solely on publicly available linguistic data, following the initialization process of the development cycle of figure 4.b. Given the extremely limited amounts of data available for most Indigenous languages, especially for endangered ones, the development of translators for such languages is only feasible today due to recent developments in AI technology, such as the use of Transformer technologies (Vaswani et al., 2017) and the availability of open pre-trained Large Language Models (LLMs) (Joo et al., 2023).\nThe most common way to create MTs for low-resource languages such as endangered Indigenous Languages involves taking generic LLMs, pre-trained on large corpus using self-supervised techniques with high levels of data, and fine-tune them with a much smaller parallel downstream corpus in the target language (Lee et al., 2022; Mager et al., 2023). This usually results in better translation accuracy than training from scratch with limited data (Adelani et al., 2022). Additionally, some results suggest that translation quality can be improved by using data from multiple languages or multilingual models (Saleh et al., 2021).\nHowever, our experience in building translators for Indigenous languages has led us into a different direction. First, we saw that multilingual translators often achieve falsely improved accuracy results by adopting a \u201ccheating\u201d strategy of memorization (Cavalin et al., 2024). Furthermore, we investigated the impact of adding more fine-tuning data, particularly in the situation where the additional data raised ethical concerns (Domingues et al., 2024). Unfortunately, we observed traces of contamination in the outputs, though in limited numbers and scope. We also found that the most significant improvement in accuracy was obtained by manually enhancing the quality of the fine-tuning training data.\nThese results and associated challenges, discussed in technical detail next, suggest that it is feasible to fine-tune LLMs into valuable bilingual translators using data commonly available for Indigenous languages that have been reasonably documented and studied by linguists, if some key methodological conditions, such as data cleanli-"}, {"title": "4.1 The Data Used in our Research", "content": "To develop both writing assistants and translators, we have been exploring machine learning methods based on small amounts of data. The data used in our work can be divided into two basic types: data extracted from linguistic sources, such as dictionaries, lexicons, theses, and publicly available books; and data extracted from multiple versions of the Bible available on the Internet.\nWe have been working exclusively with Brazilian Indigenous languages (BILs). Brazil was home to about 270 Indigenous languages according to the 2010 Census (IBGE, 2010), although some linguistic experts believe the actual number is more likely to be close to 200 (Franchetto, 2020; Storto, 2019). Those languages were spoken by approximately 800,000 people (IBGE, 2010), with half living in Indigenous lands, although the 2022 Census revised this number to about 1.7 million. Storto (2019) provides a good overview of the history, structure, and characteristics of a few BILs. Almost all of these languages are considered endangered (Moseley, 2010), remnants of the 1,000 languages estimated to be in use in Brazil before the arrival of Westerners 500 years ago (Rodrigues, 2019).\nThe first type of data comprises data extracted from publicly available dictionaries, lexicons, theses, and books. For the languages in the range of 1,000 to 100,000 speakers we are targeting, such sources are common, mostly created through linguistic research and educational efforts. We have mostly collected resources for two languages we have been working with, Guarani Mbya and Nheengatu. The data, often in the form of PDF files, are processed by scripts and manually, resulting in datasets with pairs of sentences, for the training of translators, or well-structured sentences, for the training of encoders of Indigenous languages models and to be used in development of the writing-support tools. Following the previous discussion, we do not release publicly or share this data without the permission of the associated Indigenous communities.\nThe second type of data was collected in the early stages of the project by researchers from IBM Research and comprises 39 Indigenous languages"}, {"title": "4.2 The Perils of Multilingual Translators", "content": "To evaluate whether using multilingual MTs was a effective strategy for endangered Indigenous languages, as often suggested by the literature (Lee et al., 2022; Chen and Abdul-Mageed, 2022), we used the Bibles dataset, and fine-tuned two commonly-used LLMs using one bilingual and two multilingual fine-tuning strategies."}, {"title": "4.3 The Impact of Data Quantity", "content": "While working with the Tenond\u00e9-Por\u00e3 community and their commitment to enabling their high-school students to write in Guarani Mbya, we considered that having translators to and from Portuguese would be helpful. Following our experiences with fine-tuning MTs in the context of the Bibles dataset, we started developing a Guarani Mbya to English MT to be used in conjunction with a commercial English-Portuguese translator.\nTo train the MT, we created a dataset, referred to as the Dictionary dataset, with pairs of sentences from three different sources. The first source was a set of Guarani Mbya short stories with 1,022 sentences, available in Portuguese and English (Dooley, 1988a,b). The second source comprised 245 texts extracted from PDF files with a pedagogical character (Dooley, 1985). The third source was Robert A. Dooley's Lexical Guarani Mbya dictionary (Dooley, 2016), a reference work for the language, from which we extracted 2,230 sentence pairs. In total, the Dictionary dataset had 3,155 training and 300 test sentence pairs.\nWe then considered using the Guarani Mbya subset of the Bibles' dataset to increase the amount of training data. Keenly aware of the ethical issues of using texts from the Bible in a translator for Indigenous languages in Brazil, we conducted a series of experiments, detailed in (Domingues et al., 2024), to determine whether the additional \"toxic\" data from the Bible was useful and, if so, how much its use would contaminate the outputs.\nAs a baseline for this study, we defined the zeroshot model, consisting of the original German-English WMT19 model (Ng et al., 2019) without any fine-tuning. Using only the Bibles training set, we generated three different models based on directly fine-tuning WMT19: mbya, the WMT19 model fine-tuned with only the Guarani Mbya data from the Bibles training set; TGf, the WMT19 model fine-tuned with Bibles data from 10 languages of the Tupi-Guarani linguistic family; and all, the WMT19 model fine-tuned with data from all the 39 Indigenous languages of the Bibles training set.\nUsing the data from the Dictionary training set, we generated four additional models: dict, the WMT19 model fine-tuned only with Dictionary data; mbya>dict, the mbya model fine-tuned a second"}, {"title": "4.4 Quantifying Contamination", "content": "Having established that adding the Bible data could improve the accuracy of the Guarani Mbya to English translator, even when tested only with non-Bible sentences, the work then focused on quantifying the extent of contamination in the output. Specifically, we aimed to determine how many of the translators' outputs contained, either explicitly or implicitly, typical words or language from the Bible."}, {"title": "4.5 The Impact of Data Quality", "content": "In our collaboration with the high school students of the Tenond\u00e9-Por\u00e3 community, we incorporated the dict Guarani Mbya to English translator with a commercial, API-based English to Portuguese translator into a writing assistant, which will be discussed in detail in section 5. As expected, due to the low SacreBLEU and chrF average scores (see figure 7), the quality of the translations it generated were of limited usefulness to the students.\nImproving the quality of this translator was important, so we began by seeking a better understanding of the errors it was producing and assessing the usefulness of different parts of the output. Drawing conclusions about human usefulness of a translator based only on values from automatic metrics such as SacreBLEU is challenging, since they rely on straightforward computations such as word comparison and n-grams, often overlooking semantic issues. Therefore, to determine the usefulness of the translators, we conducted a human evaluation on the texts generated from the test set inputs.\nThis evaluation, described in detail in (Pinhanez et al., 2024) involved the ranking of each of the generated outputs in a seven-point scale according to how useful it would be for someone proficient in the language using the translator as a writing support: near-perfect, correct, mostly correct, usable, mostly incorrect, incorrect, and very wrong.\nFigure 8 (left) shows the histogram of the distribution of the 300 outputs of the Guarani Mbya translator (dict), according to the usefulness scale. About 40% of all outputs were in the very wrong category, with 26% categorized as incorrect and mostly incorrect categories. Of the remaining 34%, about 28% were sentences requiring a significant level of human intervention to be used (usable and mostly correct categories), with only 7% suitable for an automatic translation scenario. As a reference, the distribution of the SacreBLEU scores of these 300 outputs is shown in figure 8 (right).\nAs we moved to work with the Nheengatu community, as discussed earlier, we decided to apply the same techniques to develop a Nheengatu to English translator. The Nheengatu dataset comprised sentences from five different sources with Portuguese translations. The first source was the Nheengatu lexicon (\u00c1vila, 2021) with 6,846 sentences extracted from the lexicon examples. We processed the original file provided by the author. The second source was Corpus"}, {"title": "5 Using AI to Create Writing Assistants", "content": "In the second workstream of our project we are developing technologies for the creation of digital writing assistants which can simplify and foster the use of Indigenous languages among their communities, especially teenagers and young adults. This need was identified in our work with both the Guarani Mbya and Nheengatu communities.\nStimulating the use of writing is also, as discussed before, one of the effective methods to diminish the process of forgetting a language learned by individuals as a child. This is true both for languages which were learned orally from family members, friends, and community and also in cases where the formal education process had actually thought them how to read and write. Moreover, in the context of increasing use of digital tools and Internet access, providing easy ways for writing in Indigenous languages in those media is likely to be key to reach teenagers and young adults, often the heaviest users of such tools.\nWe have been developing such writing assistants within the communities using a process of co-design where different component tools are prototyped, put together, and tested with Indigenous speakers in the context of different tasks. How those tools are assembled, integrated, and accessed is an essential part of the process, as well as the development of the tools themselves. The main tools we have been building are:\nWord dictionary: a tool to provide access to words, their meanings, and translations based on approximate search;\nWord completion: a tool which suggests words that can complete a partially-typed word;\nNext-word completion: a tool which suggests words which can follow a partially-typed sentence;\nSpell checker: a tool which suggests corrections in the words of a partially- or a fully-typed sentence;\nTranslator: a tool which translates words and sentences to and from the Indigenous language and another language, or between different orthographies of the same language.\nIn many ways, those are the typical writing-support tools which languages with a large number of speakers have easily available in word editors, social media apps, and similar. They are often built by dedicated, large professional teams, using traditional programming and machine learning methods, with the support of deployment and maintenance people. We do not believe that such resources are likely to be made available to endangered Indigenous languages, what has prompted us to develop an strategy to build those tools in the context of limited resources and data.\nFigure 10 depicts an overview of the technical strategy we have devised based on developing Indigenous Language Models (ILMs) by fine-tuning existing LLMs of more resourced languages. The fine-tuning process uses linguistic and educational data as well as data from the Internet, extracted and formatted by a set of training data generators, so the ILM is trained to perform the tasks of the component tools described before, such as word completion and spell checking. As the tools are incorporated into applications and used by the community, the new generated data can be used to improve the ILMs and the tools.\nThere are two structuring premises behind the proposal of this strategy. The first premise is the admission that there are very limited data resources for a given endangered Indigenous language and therefore they should be used efficiently and judiciously. The lack of data clearly pushes towards a fine-tuning strategy instead of a full training model for which there would not be enough data. At the same time, as discussed before, fine-tuning data must be as correct and clean as possible, suggesting as much as possible the use of linguistic data such as dictionaries, lexicons, theses, education materials, and carefully collected web data.\nThe second key premise, and possibly the most controversial, is the use of an ILM as the basis for all tools. This ILM can be tailored to produce the outcomes of the different component tools by the use appropriate prompting. Using different prompts, the same model can produce translations, provide word and sentence completions, generate answers to questions, or simply retrieve the meanings of words.\nThe main reason to adopt this technical strategy is replicability: the ILM allows all tools to share a single knowledge and data framework which can be built in a replicable manner from linguistic data. At the heart of our strategy is the idea that all the"}, {"title": "5.1 Prototyping Writing Assistants", "content": "The development of prototypes of writing assistants started about one month after we begun to have weekly workshops at the Tenond\u00e9-Por\u00e3 high school. We employed technology probes (Hutchinson et al., 2003), a variation of the idea of cultural probes (Gaver and Dunne, 1999), a.k.a. design probes. The main idea was to insert some sort of technological artifact into the classroom which could elicit responses from the students in the context of actual writing tasks.\nThe first technology probe was a rudimentary version of the Guarani Mbya to Portuguese translator, accessible through a bare-bones Internet interface. It showed it had almost no use for the students, aggravated by the poor quality of the translations. But it triggered good conversations with the students about what kind of writing support would be useful for them. Based on this feedback, we started focusing on another component tools which"}, {"title": "5.2 Developing the Component Tools", "content": "In the development of the actual tools used in the prototypes of the writing assistants described in the previous paragraphs, we did not use a single ILM as the source of the component tools as advocated in the description of our technical strategy shown in figure 10. The main reason was that the process of co-design and development of the prototypes required to have versions of those tools working, to some extent, in the early steps of the initialization process, as part of the new development cycle proposed before (depicted in figure 4.b).\nWe now briefly describe the development process of the tools which were actually used and discuss how we will move to a single-source ILM framework. Notice that the existence of those tools will eventually simplify the training of the generic ILM because they can be easily employed to generate prompt-like synthetic training data for the generic ILM.\nThe word dictionary used in the Guarani Mbya and Nheengatu prototypes was implemented by looking up a database of words extracted from actual dictionaries available for the language. This database contained associated descriptions in Brazilian-Portuguese and English of each word. One shortcoming of that version was not listing valid variations of base words, such as the use of prefixes and suffixes to indicate gender, number and verbal tenses. Most dictionaries for major languages used in editing tools often incorporate the handling of variations by direct programming rules for valid modifications, a time- and effort-consuming process. We believe this can also be"}, {"title": "6 Can Languages Be Documented by Endangered Language Models?", "content": "When the last native speaker of a language dies, a language is lost together with the large amount of the knowledge accumulated through generations by peoples and communities. Humanity as a whole loses not only tacit knowledge about the world and the culture of communities but also different ways of thinking and structure knowledge and cognition.\nWhen a language ceases to be spoken and used, what is left, in the best cases, are documents and media registering its use by previous speakers: texts, books, recordings, videos. In many cases, there are also linguistic material such as grammars, dictionaries, articles and books, and other linguistic materials with systematic, analytical descriptions of the language. In some rare cases, such media has been used to revitalize the language, that is, to enable a new generation of speakers to use the language or a good approximation of it. The most famous case of revitalization is the case of Hebrew, which was a lost language in the beginning of the 20th century and currently is spoken and used by millions of people (Thomason, 2015).\nThe tools most commonly used today by linguists for the documentation of Indigenous languages are FLEX and ELAN, which create and manage databases of annotated lexical and textual information. FLEX allows for a text to be automatically labelled or glossed with items from the dictionary and ELAN allows for a media archive to be transcribed and translated. Both have the possibility of synchronizing work done in parallel by more than one user. It would be ideal if these tools could be adapted computationally to interact with AI systems, if possible, and adapted to smartphones, to facilitate documentation by linguists and speakers. This improvements would be of great help on making documentation less time consuming and more accessible.\nLinguistic documentation is vital for the preservation and vitalization of Indigenous languages, and native and community speakers must be able to work actively as researchers on these databases together with non-Indigenous researchers. Moreover, efficient tools which record the time spent by users on the database could inaugurate a new economic activity for Indigenous researchers, allowing documentation projects switch from grants to hourly payments to remunerate participants.\nThe emergence of LLMs and interactive chatbots based on them has created a possible new framework to document an endangered language, based on the development of Endangered Language Models (ELMs) following methodologies similar to our technical strategy described in figure 10. Figure 15 shows the main components of the process of creating and using ELMs, including the direct interaction of the model with native speakers as a key source of training data.\nWe are not aware of any on-going initiative to preserve a language using this approach of creating an ELM for it but we think this is possibly a novel way to avoid the negative aspects of losing a language. ELMs may be able to provide future generations with more interactive ways to do research"}, {"title": "7 Previous and Related Work", "content": "The work described in this paper certainly did not happen in a vacuum. There have been considerable work, especially in the last 5 years, looking into how to apply AI technologies in support of endangered languages and, in particular, Indigenous languages. A detailed survey is beyond the scope of this paper.\nA good survey of early work was done by Mager et al. (2018) which described work, data resources, and challenges of language technologies for American Indigenous languages. Kuhn et al. (2020) described many different language technology initiatives of the Indigenous Languages Technology (ILT) project at the National Research Council of Canada, including the construction of corpora for several languages, annotation tools, speech recognition systems, and read-along audiobooks. Neubig et al. (2020) summarized a workshop on the state of use of technology for language documentation in 2019. And Mager et al. (2023) presented a detailed discussion on the challenges and common approaches to develop machine translation systems for Indigenous languages of America.\nIn particular, NLP technologies have been used in varied contexts and scenarios of endangered languages. Alavi et al. (2015) discussed whether an automatic conversational system could be used to document languages; Anastasopoulos (2019) explored diverse language tools for language documentation; Anastasopoulos et al. (2020) discussed modern NLP issues with endangered languages; Bird (2018) looked into the specific issue of using mobile technologies; Cruz and Waring (2019) listed linguistic issues of using technology for endangered languages; Everson and Waring (2019) described a platform for community-based description of Indigenous languages; Foley et al."}]}