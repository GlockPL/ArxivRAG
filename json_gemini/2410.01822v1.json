{"title": "The Importance of Causality in Decision Making: A Perspective on Recommender Systems", "authors": ["Emanuele Cavenaghi", "Fabio Stella", "Alessio Zanga", "Markus Zanker"], "abstract": "Causality is receiving increasing attention in the Recommendation Systems (RSs) community, which has realised that RSs could greatly benefit from causality to transform accurate predictions into effective and explainable decisions. Indeed, the RS literature has repeatedly highlighted that, in real-world scenarios, recommendation algorithms suffer many types of biases since assumptions ensuring unbiasedness are likely not met. In this discussion paper, we formulate the RS problem in terms of causality, using potential outcomes and structural causal models, by giving formal definitions of the causal quantities to be estimated and a general causal graph to serve as a reference to foster future research and development.", "sections": [{"title": "1 INTRODUCTION", "content": "Predicting and deciding are two fundamentally different tasks. As described by the Ladder of Causation [16], a decision manipulates the system which can react to our decision, while a prediction does not affect the system in any manner: the system is eventually affected only when we exploit the prediction to make a decision. Overlooking this difference usually leads to biased predictions that, in turn, result in wrong decisions. The RSs community is facing several problems with biased estimates [6] to assess the effect of recommendations based on predictions. Indeed, according to [1, 17], the recommendation problem is usually framed as a prediction problem while, as pointed out in [5, 8], it is indeed a decision-making problem, since we have to decide which item(s) to recommend."}, {"title": "2 CAUSAL DECISION-MAKING", "content": "The first step is to have a CG that describes the data-generating process of the system under study. The CG can be learned by combining observational data with experts' knowledge through a process called causal discovery, which is enabled by several causal discovery algorithms [19, 20]. While the CG must be learned in each scenario, we proposed a reference CG for RSs [5] to guide the construction of a CG for specific RSs problems as done in [3, 4].\nThe problem of recommending a single item with features I to a user U in context C is described by the CG of Figure 2 where the node X represents the action of recommending an item whose domain corresponds to the item set, i.e., x \u2208 dom(X). For example, in film recommendation, dom(X) is the catalogue of the films and our recommendation X is one of the films in the catalogue. To decide which item to recommend to the current user U in context C, we use a policy x based on user and context features. Once we decide which item x to recommend, the corresponding item's features I are fixed and they mediate the effect of our recommendation X on the user feedback Y through the path X \u2192 I \u2192 Y. For example, once we decide to recommend a film, its genre is fixed (X\u2192 genre), and the genre (likely) affects a user's feedback (genre \u2192 Y). It is worth noticing that not all the item's features have to influence the user's feedback, i.e., some item's features are not taken into account by the users. On the other hand, part of the effect of the recommendation X on the user's feedback Y may not be captured by the modelled features I and flows directly through the edge X \u2192 Y. For example, if we are not able to model the film's popularity, its effect will flow through the edge X \u2192 Y as this feature is not modelled."}, {"title": "2.2 Causal Estimand Identification", "content": "To exploit the potential of causality, we should frame the quantity to estimate as a causal estimand that encodes the notion of the causal effect of a variable (the cause) on another (the effect). We define it using the POs framework and the do-operator [2, 7], as E[Y|do(X = x), u, i, c]. This encodes the value of the expected feedback Y given by the user u in context c when we recommend item x with features i. The difference that separates causal estimands from classical statistical estimands is the presence of the so-called do-operator, denoted with do(X = x), that defines the intervention of fixing the value of X to x for the whole population of users. In contrast, conditioning on X = x means that X takes a value x naturally, which simply translates to focusing only on the sub-population where X has been observed to be equal to x. In a decision-making problem, such as RSs, we are interested in estimating causal estimands since we actively decide which item(s) to recommend.\nHowever, expressions with the do-operator can only be estimated in controlled experiments where the variables in the do-terms can be appropriately controlled. To estimate a causal estimand using only observational data, it is necessary to remove the do-terms and obtain an equivalent expression. To this end, the adjustment formula estimator [7] adopts a model-based approach to adjust for an adjustment set Z and obtain a statistical estimand:\n\n P(Y = y|do(X = x)) = \\sum_{z} P(Y = y|X = x, Z = z)P(Z = z)  (1)\n\nTo identify the variables that must be included in Z, we can query the CG by evaluating an identification criterion, such as the backdoor criterion [7], frontdoor criterion [15] or do-calculus [2]. In particular, if no identification is possible with do-calculus, the causal effect is guaranteed to be unidentifiable. Thus, every estimate of the causal estimand will be biased."}, {"title": "2.3 Estimation", "content": "Once we have proved the identifiability of the causal estimand, i.e., once we have shown that the causal estimand is equal to a statistical estimand, this can be estimated using classical statistical estimators. Any model that is compatible with the type of the outcome variable, e.g. linear regression for a continuous outcome or neural networks for non-linear relations, is suitable for this estimation. Clearly, the model should be chosen carefully for each problem by considering the data characteristics to avoid estimation errors."}, {"title": "2.4 Making Decisions", "content": "Finally, with the estimated causal effects, e.g., the effect of our recommendation on the user's propensity to click on the recommended item(s), we can decide which items to recommend. This could be done in different ways: (i) greedy, (ii) e-greedy and (iii) more sophisticated policies. In recent years, several works have exploited causality by linking it to Multi-Armed Bandit (MAB) [9, 13, 14] and Reinforcement Learning (RL) [12]. For example, in [10], the authors define the notion of Possibly-Optimal Minimal Intervention Set with the idea of determining the minimum set of variables on which we should intervene to understand all the possible arms that are worth intervening on. Moreover, [11] extends the method by considering that some variables can not be manipulated. Using causality with RL, [21, 22] approached the Dynamic Treatment Regimes problem with confounded observational dataset."}, {"title": "3 CONCLUSIONS", "content": "In this paper, we proposed a causal view of the RS problem and highlighted the importance of framing the recommendation problem in terms of causality. The causality framework can, in our view, be considered as a single framework allowing researchers to wholis-tically define and address several problems widely acknowledged in the RSs community to bridge the gaps in future works.\nHowever, we would like to stress that causality is not magic but ruthlessly honest and, differently from other approaches, it makes explicit assumptions, such as ignorability and unconfoundedness, leaving us with the burden of judging whether they are likely to be satisfied for the addressed context. Indeed, causality is not the sole ingredient to solve the RS problem while we are fully convinced that exploiting the body of knowledge generated over more than 30 years of research in RSs and users' behaviour remains fundamental."}]}