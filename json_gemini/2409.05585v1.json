{"title": "Latent 3D Brain MRI Counterfactual", "authors": ["Wei Peng", "Tian Xia", "Fabio De Sousa Ribeiro", "Tomas Bosschieter", "Ehsan Adeli", "Qingyu Zhao", "Ben Glocker", "Kilian M. Pohl"], "abstract": "The number of samples in structural brain MRI studies is often too small to properly train deep learning models. Generative models show promise in addressing this issue by effectively learning the data distribution and generating high-fidelity MRI. However, they struggle to produce diverse, high-quality data outside the distribution defined by the training data. One way to address the issue is using causal models developed for 3D volume counterfactuals. However, accurately modeling causality in high-dimensional spaces is a challenge so that these models generally generate 3D brain MRIS of lower quality. To address these challenges, we propose a two-stage method that constructs a Structural Causal Model (SCM) within the latent space. In the first stage, we employ a VQ-VAE to learn a compact embedding of the MRI volume. Subsequently, we integrate our causal model into this latent space and execute a three-step counterfactual procedure using a closed-form Generalized Linear Model (GLM). Our experiments conducted on real-world high-resolution MRI data (1mm) demonstrate that our method can generate high-quality 3D MRI counterfactuals.", "sections": [{"title": "Introduction", "content": "Generative AI models have demonstrated great potential to advance numerous medical fields including neuroimaging with 3D brain MRIs [18,22]. The synthesis of medical images is particularly promising for tasks like improving image quality, imputing missing modalities [32], and modeling disease progression [31,7,8]. Recent advances in diffusion probabilistic models (DPMs) [6,24] have played a significant role in this development as they are able to accurately capture the underlying data distributions. This results in synthesized medical images containing a great amount of detail [28,11] that also differ from the training samples [9,30]. Nevertheless, a key challenge remains generating realistic samples that are outside the distribution defined by the training dataset [10]. Overcoming this challenge is essential to the generalizability of large-scale models [30]. One way to address this shortcoming is by incorporating causality between factors during the generation progress [17]. For example, aging causes a thinning of the cortex that is accelerated in those with alcohol use disorder or Alzheimer's disease, which provides a causal interaction not taken into account by statistical models. Here, we propose to integrate causality in the synthesis of 3D brain"}, {"title": "Methodology", "content": "Our method comprises a two-stage process (outlined in Fig. 1) that performs counterfactual generation of MRIs given attributes, e.g., age and brain regions of interest (ROIs). Given an intervention on (at least) one of these attributes, a Deep Structural Causal Model (DSCM) deploys a causal graph to compute the counterfactual of the attributes. For example, consider a brain MRI scan of an 80-year-old female, from which we extract the attributes age=80, sex=female, and"}, {"title": "Deep Structural Causal Models", "content": "A structural causal model (SCM) [17] is a triple $M := (U,V, F)$ consisting of two sets of variables: (i) exogenous variables $U = {u_1,...,u_n}$; (ii) endogenous variables $V = {v_1, ..., v_N}$, and a set of functions known as causal mechanisms $F = {f_1,...,f_N}$, which determine the values of the endogenous variables: $v_k := f_k(pa_k, u_k)$, where $pa_k$ are the direct causes (parents) of $v_k$. It is possible to perform an intervention on any $u_k$ by, e.g., setting it to a constant $do(v_k := c)$ and thereby disconnect $v_k$ from its causal parents. SCMs enable the estimation of counterfactuals (hypothetical scenarios) via a three-step process: (i) abduction: infer the posterior distribution $P(U | X)$, which represents the current state of the world; (ii) action: perform one or more interventions to obtain a modified model; (iii) prediction: infer counterfactual values of the endogenous variables using the modified model and the posterior $P(U | X)$.\nIn this work, we use a deep structural causal model (DSCM) [15] to model the causal relationships between patient attributes such as age, brain regions of interest, and diagnosis. Following [4], a DSCM uses a conditional normalizing flow [23] as the mechanism for each endogenous variable $v_k := f_k(u_k; pa_k)$, to enable tractable and explicit abduction of the exogenous noise $u_k = f_k^{-1}(v_k; pa_k)$."}, {"title": "Latent SCM for 3D Counterfactual MRIS", "content": "To fully leverage the latent SCM described in Section 2.1, a high-dimensional MRI x first has to be encoded to a corresponding latent feature z, for which we use a VQ-VAE. Then, we obtain its counterfactual $z'$ based on $pa_z$, which is finally decoded to the MRI counterfactual $x'$. We now discuss the process of obtaining these latent features z and estimating the counterfactuals $z'$, after which decoding is trivial given a trained VQ-VAE."}, {"title": "Computing latent feature z", "content": "To obtain a latent feature z from a 3D MRI x, we employ a Variational Autoencoder (VQ-VAE) [14]. VQ-VAEs comprise an encoder $E$ and decoder $D$, as well as a code book $C$ that performs vector quantisation (VQ). That is, code book $C$ empowers mapping a 3D MRI x to a quantized encoding.\nThe first step in the process of computing the latent feature z is using the encoder $E$ to map the 3D MRI $x \\in R^{D \\times H \\times W}$ to its lower-dimensional feature representation $z := E(x) \\in R^{d \\times h \\times w \\times n_D}$. Correspondingly, the decoder $D$ aims to reconstruct a 3D MRI $x = D(z)$ from a compressed embedding z. The training objective of the model is to minimize the reconstruction error. Once latent feature z is obtained, we apply vector quantization, which discretizes the continuous latent space using a set of embedding units $C := {(k,e(k)) : k = 1,2,..., N_c and e(k) \\in R^{nD}}$. This allows an MRI to be represented very efficiently by a set of indices (a.k.a. code) as defined with respect to the code book. Notably, this process also serves a regularization purpose to avoid overfitting the model during training.\nAfter the encoding and vector quantization steps are finished, the latent representation z is described by $d \\times h \\times w$ vectors of $n_D$ dimensions each. This is achieved by searching the nearest neighbor of the embedding units in codebook $C$ for each feature vector in $z_e$. In other words, each of the $d \\times h \\times w$ vectors $z_c \\in R^{nD}$ from z is paired with its closest representative $e(k)$ from the codebook"}, {"title": "Estimate latent counterfactual $2 and $", "content": "Given feature $z = Q(E(x))$, we will build a closed-form mechanism $f$ for $z$, such that its exogenous variable is given by $u_z = f_o^{-1}(pa_z, z)$. We achieve this by using the GLM. Specifically, we first flatten the feature as a vector with dimension $K = d \\times h \\times W \\times n_D$. Then, a feature matrix $Z \\in R^{N \\times K}$ is built for all the N samples in the dataset. At the same time, the $pa_z$ for all training samples is accumulated to construct a matrix $P \\in R^{N \\times m}$, where m is the number of variables in $pa_z$. Then, an ordinary least square estimator [13] is applied to solve the GLM's normal equations so that the linear parameters $B$ can be represented by the closed-form solution\n$B = (P^TP)^{-1}P^TZ$.\nSubsequently, the Abduction step of the counterfactual generation can be represented as the computation of the residual component $U_z \\in R^{N \\times K}$ acting as the exogenous variable for features $Z$, which is given by\n$U_z = Z \u2013 PB = (I \u2013 (P^TP)^{-1}P^T)Z$.\nGiven that we construct $P$ explicitly, we find that the solution for $B$, and thus for $U_z$, is of closed-form. This is computationally feasible as we perform the GLM in the latent space, not in the high-dimensional MRI space. Our method is scalable and easily lends itself to cases containing many more samples. Like metadata normalization [13], we can accumulate the B with momentum.\nThe Action step of the counterfactual generation can be realized by using the causal graph to produce counterfactual parents $pa_z$. Once we have the $pa_z$, the Prediction step of counterfactual generation can be achieved by adding factor-specific embeddings back to the exogenous variable as follows:\n$2 = U_z + PB$."}, {"title": "Experiments", "content": "We train our VQ-VAE model using 8566 t1-weighted brain MRIs pooled from two datasets: the Alzheimer's Disease Neuroimaging Initiative [20] (ADNI (1511 subjects)) and the National Consortium on Alcohol and Neurodevelopment in Adolescence [1] (NCANDA (808 subjects)). Besides, 400 subjects are left for testing. Processing includes denoising, bias field correction, skull stripping, affine registration to a template (which correctes for difference in head size and thus sex and race), and normalizing intensity values between 0 and 1. The voxel resolution is 1mm and we pad each MRI to spatial resolution 144 \u00d7 176 \u00d7 144. Based on the latent space of VQ-VAE, the DSCM model is trained on an in-house MRI dataset (PIs Drs. Pfefferbaum and Sullivan) with 826 samples from 400 subjects consisting of individual diagnosed with alcohol use disorder (AUD) and healthy controls. Compared to controls, the brain regions frontal, insula, and parietal lopes are smaller in those with AUD [25]. Therefore, we build our casual graph, as in Fig. 2, using these five variables, i.e., age, diagnosis, frontal, insula, and parietal. After the training, we evaluate the model with respect to its ability to create counterfactuals and the anatomical plausibility of the synthetic 3D MRIs."}, {"title": "Counterfactual Generation", "content": "This part demonstrates that our model can perform different interventions to the generation process and output high-fidelity 3D counterfactuals. Given a MRI example, we apply an intervention do() to age and diagnosis in our causal graph"}, {"title": "Counterfactual Evaluation", "content": "By preforming random intervention, 400 counterfactuals are synthesized. We then compare with synthetic MRIs from recent generative models and also evaluate it anatomical plausibility to qualify its value for neuroimaging studies. The comparison methods include GAN models like CCE-GAN [30], VAE-GAN [12], \u03b1-WGAN [10], and HA-GAN [26]; and diffusion models like latent diffusion model (LDM) [21] and cDPM [18]. Qualitative results of all 7 models are shown in Appendix while only the best four are shown in Fig. 3 due to space limitations. Of those four methods, HA-GAN was the only method that was not able to produced the MRIs that looked like those of healthy controls. On the other side LDM produces the noisiest MRI and the MRI of cDPM has clear slice artefacts. In contrast, the MRI of our model shows clear gray-matter boundaries and looks most similar to the real MRI. Finally, our model is much faster than the diffusion-based method as their is no need for the multi-step diffusion process.\nWe evaluate its anatomical plausibility by comparing its subcortical similarity with the real data. To this end, we run Freesurfer pipeline [5] for both of the 400 real samples and the synthetic ones to conduct the brain pacellation and compute automatic segmentation volume (aseg). We report the effect size (using Cohen's d coefficient [2], d) to 24 sub-cortical differences with the real brain MRIs. As shown in Table 1, 50% of the sub-corticals have a |d| < 0.2, which means these brain regions are very similar to the real ones. More than 90% of the 24 brain regions have an effect size that is less than 0.4, which suggests"}, {"title": "Discussion", "content": "While our work proposes novel methodology for embedding counterfactual reasoning into generative AI models to enhance interpretability and generative performance, and outperforms state-of-the-art models in generating 3D MRIS, several challenges remain. Firstly, building a DSCM is challenging on high-dimensional data [3] without sacrificing the quality of generated counterfactuals. This can be further hindered if the size of the dataset is small. To mitigate this issue as much as possible, we compute counterfactuals in the lower-dimensional latent space, although this requires us to control information at a scalar-level, challenging the decoder to generate high-dimensional 3D MRIS.\nSecondly, for disease prevention purposes in a clinical setting, it is non-trivial to comprehensively assess the anatomical plausibility of the counterfactuals and generated MRIs when we intervene on a diagnosis, as these present novel findings."}, {"title": "Conclusion", "content": "We propose a novel brain counterfactual for 3D MRI generation, which fully fills three rungs of Pearl's ladder of causation. The model adeptly performs causal modeling while capable of generating high-quality 3D brain volumes. This is achieved by our latent structural counterfactual model, which contains a deep SCM constructed in a latent space. We then run a GLM on this low dimensional latent space to synthesize counterfactuals, to mitigate significant computational challenges posed by performing interventions directly on the 3D brain MRIs. The generated MRIs show high anatomical resolution, while the counterfactual generation contains an efficient intervention strategy to generate high-quality 3D counterfactuals."}]}