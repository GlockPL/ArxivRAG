{"title": "A Survey on Private Transformer Inference", "authors": ["YANG LI", "XINYU ZHOU", "YITONG WANG", "LIANGXIN QIAN", "JUN ZHAO"], "abstract": "Transformer models have emerged as game-changers to revolutionize the field of Artificial Intelligence (AI). For instance, both ChatGPT [42] and Bing [40] have made the power of transformer-based models widely accessible, democratizing advanced Al capabilities. These models leverage attention mechanisms [55] adeptly to capture long-range dependencies in sequences of input tokens, allowing them to accurately model contextual information. Besides, unlike traditional task-specific learning approaches, large transformer models (e.g., GPT [46] and BERT [10]) are trained on huge quantities of unlabeled textual data and are directly useful for a wide variety of applications such as sentiment analysis, language translation, content generation, and question answering.\nHowever, the application of large transformers still presents certain risks, particularly regarding privacy issues [35, 52]. Most popular transformer models operate in a pattern called Machine Learning as a Service (MLaaS), where a server provides the model and inference services to users who own the data. For instance, OpenAI provides ChatGPT as an online platform and offers remote APIs for developers, allowing users to access services by submitting prompts or messages. Nevertheless, this pattern raises privacy concerns: users need to transmit their private data to a company's server and have no direct control over how their data is handled. They must trust that the server processes the data honestly and follows the agreed terms of service. There exists a risk that the server could misuse the data, including unauthorized processing, storing the data indefinitely, or even selling it to third parties. Even if the server is trustworthy, there are inherent risks associated with centralized data storage, such as data breaches or unauthorized access by malicious insiders. These risks are particularly concerning when dealing with sensitive or personally identifiable information. Therefore, while MLaaS offers significant convenience and computational power, it also necessitates careful consideration of privacy issues. As a result, serious user data privacy concerns have been raised, which even led to a temporary ban of ChatGPT in Italy [33, 38]. Hence, there exists a gap between high-performance transformer inference services and privacy concerns, motivating the study of Private Transformer Inference (PTI).\nPrivate inference is a cryptographic protocol that allows for model inference while ensuring that the server gains no knowledge about the users' input, and the users learn nothing about the server's model, apart from inference results. Recently, private inference on transformers has been achieved by using private outsourced computation techniques, such as secure Multi-Party Computation (MPC) [61] and Homomorphic Encryption (HE) [15]. MPC enables multiple parties to jointly compute a function over their inputs while keeping those inputs private. Its essence is to allow the computation of results without any party revealing their private data to others. HE provides a way to perform computations on encrypted data without needing to decrypt it. This means that data can be processed in its encrypted form, preserving privacy and security throughout the computation process. HE is extremely useful in MLaaS as it allows clients to encrypt their data before sending it to the cloud for processing. The server can then compute the model's functions directly on the encrypted data, providing results without ever accessing the raw data.\nIn this paper, we review state-of-the-art papers that implement PTI using different private computation techniques, primarily focusing on MPC and HE technologies. We discuss their pros and cons and propose some future avenues to tackle. Furthermore, we propose a set of evaluation guidelines to compare solutions in terms of resource requirements. The key contributions of this paper are summarized as follows:\n(1) Provide a comprehensive literature review of proposed solutions in the field of secure transformer inference from recent three years (2022-2024);\n(2) Provide a breakdown of the main challenges faced in this field, as well as typical solutions that are implemented to mitigate them;", "sections": [{"title": "1 INTRODUCTION", "content": "Transformer models have emerged as game-changers to revolutionize the field of Artificial Intelligence (AI). For instance, both ChatGPT [42] and Bing [40] have made the power of transformer-based models widely accessible, democratizing advanced Al capabilities. These models leverage attention mechanisms [55] adeptly to capture long-range dependencies in sequences of input tokens, allowing them to accurately model contextual information. Besides, unlike traditional task-specific learning approaches, large transformer models (e.g., GPT [46] and BERT [10]) are trained on huge quantities of unlabeled textual data and are directly useful for a wide variety of applications such as sentiment analysis, language translation, content generation, and question answering.\nHowever, the application of large transformers still presents certain risks, particularly regarding privacy issues [35, 52]. Most popular transformer models operate in a pattern called Machine Learning as a Service (MLaaS), where a server provides the model and inference services to users who own the data. For instance, OpenAI provides ChatGPT as an online platform and offers remote APIs for developers, allowing users to access services by submitting prompts or messages. Nevertheless, this pattern raises privacy concerns: users need to transmit their private data to a company's server and have no direct control over how their data is handled. They must trust that the server processes the data honestly and follows the agreed terms of service. There exists a risk that the server could misuse the data, including unauthorized processing, storing the data indefinitely, or even selling it to third parties. Even if the server is trustworthy, there are inherent risks associated with centralized data storage, such as data breaches or unauthorized access by malicious insiders. These risks are particularly concerning when dealing with sensitive or personally identifiable information. Therefore, while MLaaS offers significant convenience and computational power, it also necessitates careful consideration of privacy issues. As a result, serious user data privacy concerns have been raised, which even led to a temporary ban of ChatGPT in Italy [33, 38]. Hence, there exists a gap between high-performance transformer inference services and privacy concerns, motivating the study of Private Transformer Inference (PTI)."}, {"title": "2 BACKGROUND", "content": ""}, {"title": "2.1 Private Inference", "content": "Consider a scenario where a client C possesses private data x, and a server S hosts a model M. The client C aims to utilize M to compute the inference result M(x). The privacy requirement is that the server learns nothing about x, and the client learns nothing about M except what can be inferred from the M(x). Following [64], we formally define private inference as follows:\nDEFINITION 1. A protocol I between server S with model M and client C with input x is considered private if it satisfies:\n\u2022 Correctness. The final output of protocol II, denoted as y, is as same as the correct inference result M(x)."}, {"title": "2.2 Transformer Architecture", "content": "Transformer is an encoder-decoder architecture in which both parts have a similar structure. We mainly focus on the encoder here. The encoder comprises a stack of identical blocks, each with two sub-layers: a multi-head self-attention mechanism and a feed-forward network. Residual connection and layer normalization (LayerNorm) are utilized around each of the two sub-layers. An encoder's architecture and process flow are shown in Fig. 1.\nEmbedding. At the start of the encoder, an embedding layer is employed to transform input tokens into continuous feature vector representations. Concretely, given $X_{input} \\in \\mathbb{R}^{m \\times 1}$, an embedding lookup table is used to generate output $X \\in \\mathbb{R}^{m \\times d}$, where m denotes the length of tokens and d represents the model dimension.\nAttention. Attention layers capture context and dependencies among the input through the multi-head attention mechanism. Specifically, an input $X \\in \\mathbb{R}^{m \\times d}$ is fed into L multi-head attention layers. Each layer linearly projects the"}, {"title": "2.3 Privacy Preservation Techniques", "content": "This subsection introduces the popular cryptographic techniques involved in current PTI studies."}, {"title": "2.3.1 Functional Encryption", "content": "Functional encryption is a form of encryption that allows evaluating certain functions over encrypted data. The results of these functions are \"leaked\" from the ciphertexts, i.e., the result of the function is in plain data. This is beneficial for inference computation since only the first layer of the model needs to be run on encrypted data, and the rest can be run on plain data. However, this does leak some client data information to the server; the server learns the model output and the intermediate results of the computation."}, {"title": "2.3.2 Secure Multi-Party Computation (MPC)", "content": "Secure MPC [14] refers to a collection of cryptographic algorithms and protocols, e.g., garbled circuits, secret sharing, and oblivious transfer, which allows multiple parties to jointly implement a computation task while keeping their respective data private. In essence, although all parties collaborate to perform a computation, no one can access information that compromises the privacy of others. The objective of MPC is to develop a secure protocol enabling these participants to collectively evaluate a function on their private inputs, ensuring that the output is accurate while safeguarding their private data, even in the presence of curious or malicious participants.\nSecure MPC can be formally described as follows: Consider n parties, denoted as (P1, ..., Pn), where each party Pi"}, {"title": "2.3.3 Homomorphic Encryption (HE)", "content": "HE is a form of encryption that enables computations on encrypted data directly without decryption. The computations remain encrypted and, once decrypted, yield results identical to those obtained from the same operations on unencrypted data. Most HE schemes are based on public key cryptography, where a public key (pk) is used to encrypt data and a secret key (sk) to decrypt results. The public key can be shared freely for encryption purposes, whereas the secret key is required to decrypt messages. These schemes are secure because access to the public key does not compromise the private key. An overview of the main homomorphic operations is as below.\n\u2022 Enc(pk, m) \u2192 c: On public key pk and a plaintext m, perform encryption to obtain a ciphertext c.\n\u2022 Dec(sk, c) \u2192 m: On secret key sk and a ciphertext c, perform encryption to obtain the plaintext message m.\n\u2022 Eval(pk, $c_0,..., c_{k-1}, C$) \u2192 Enc(pk, C($m_0, ..., m_{k-1}$)): On public key pk, ciphertexts $c_1,..., c_k$ encrypted from $m_1,..., m_k$, and a circuit C (sequence of operations), outputs an encrypted computation result as same as the evaluation result of Enc(pk, C($m_0,..., m_{k-1}$)).\nNonetheless, every operation on encrypted data introduces a small amount of noise, which accumulates as more operations are performed. Beyond a certain threshold, this noise can become large enough to prevent correct decryption. We can categorize HE schemes by the operations used in circuit C and its computational depth, i.e., the number of consecutive operations required for evaluation.\n\u2022 Partially Homomorphic Encryption: Schemes support the evaluation of circuits consisting of a single type of operation-either addition or multiplication-but not both.\n\u2022 Somewhat Homomorphic Encryption (SHE): SHE schemes enable a limited number of addition and multiplication operations on encrypted data, but this capability is restricted to a subset of computational circuits. The primary limitation arises from the accumulation of noise with each operation, which inherently restricts the depth of circuits that can be processed.\n\u2022 Fully Homomorphic Encryption (FHE): FHE schemes allow for arbitrary operations on encrypted data, unrestricted by the type or the number of operations. A key feature of FHE is bootstrapping, a process designed to manage noise accumulation during operations. Bootstrapping involves decrypting a ciphertext c and then"}, {"title": "3 PIVACY THREATS IN SECURE INFERENCE", "content": "Semi-honest. The semi-honest security model is based on the assumption that all parties involved in computation will honestly follow the established protocols while passively attempting to gather extra private information during its execution. This model is often used when the parties have a basic level of trust in each other, not to actively disrupt the process. Semi-honest security is a common assumption for privacy-preserving machine learning (PPML). The parties have to trust each other to some extent so that they can jointly contribute to the result of inference.\nHonest-Majority. The honest-majority security model operates under the assumption that as long as the majority of the participants are honest and follow the protocol, they can prevent a minority who may be dishonest from tampering with the process or stealing private information. It is suited for situations involving more participants, where not everyone might be fully trustworthy. This model enhances security by allowing the computation to tolerate some level of misbehavior from a minority of the participants without compromising the integrity or confidentiality of the overall process."}, {"title": "4 AN OVERVIEW OF PRIVATE TRANSFORMER INFERENCE STUDIES: SETUPS, CRYPTOGRAPHIC APPROACHES, PROS AND CONS", "content": "This section provides an overview of state-of-the-art private transformer inference (PTI) studies, along with a critical review of their strengths and weaknesses. Specifically, we first introduce a secure inference system setup in Section ??. Then, we review current PTI studies and their privacy-preserving approaches in Section 4.2. A discussion about strengths and weaknesses is finally presented in Section 4.3."}, {"title": "4.1 Bottlenecks in private transformer inference", "content": "In recent years, there has been significant development in neural network private inference for traditional CNN (Convolution Neural Network) and RNN (Recurrent Neural Network) models [27, 51]. However, due to essentially different structures, private transformer inference brings several new challenges.\nLarge Matrix Multiplications. First, transformer models involve a huge number of large matrix multiplications rather than matrix-vector multiplications widely studied in CNN. In addition, a transformer model usually consists of multiple encoders (i.e., decoders), and the multiplication scale is much higher than the traditional networks. Direct extensions of existing matrix-vector multiplication protocols to transformers typically result in unaffordable overheads [8, 18].\nComplex Nonlinear Functions. Traditional neural networks commonly employ crypto-friendly non-linear functions, e.g., Rectified Linear Unit (ReLU), Maxpool and batch normalization. In Contrast, transformers extensively employ Gaussian Error Linear Unit (GeLU), Softmax and LayerNorm functions. These complex nonlinear functions are critical"}, {"title": "4.2 An overview of PTI studies with employed cryptographies", "content": "We examine the cutting-edge PTI studies (2022-2024) in Table 4, including their setups, employed tools, threat models and improved components. In particular, the studies are classified and discussed based on their running setups (2PC, 2PC-Dealer and 3PC). We believe that the choice of setups significantly affects the tools employed, the threat model, and the components to be improved. For instance, secure matrix multiplication requires additional privacy protection (e.g., HE) and overheads under the 2PC setup and is therefore optimized in all 2PC-based studies, but not in 2PC-Dealer and 3PC setups [1, 8, 12, 17, 28, 32, 36, 50, 59].\nStudies based on 2PC [7, 11, 18, 20, 34, 43, 64] follow the most common server-client-participated computation paradigm and often assumes a standard semi-honest (i.e., honest-but-curious) threat model. The two parties, often server and client, will honestly follow the inference protocol while passively attempting to gather extra private information during its execution, which is a natural and practical consideration for current MLaaS platforms. In particular, THE-X [7] and NEXUS [64] manage to implement purely HE-based PTI frameworks, which requires them to optimize almost all nonlinear layers, as nonlinearity is often not supported by HE. In contrast, other studies [11, 18, 20, 34, 43] favor MPC+HE hybrid frameworks to improve the performance (e.g., inference speed, model accuracy) at the cost of additional complexity in the setups. As we have discussed, secure matrix multiplication in 2PC is the bottleneck for optimization as it requires additional privacy protection.\nIn both 2PC-Dealer and 3PC setups, the introduction of a \"helper party\" has effectively eliminated matrix multiplication as a significant bottleneck. However, nonlinear layers, especially Softmax and GeLU, now represent the primary sources of overhead in MPC [12, 28, 59]. GeLU requires a high-order Taylor expansion involving many multiplications, while Softmax demands iterative squaring for exponentials and comparisons for numerical stability. Hence, we can see from Table 4 that most studies manage to improve the performance of Softmax and GeLU. Apart from standard semi-honest assumption [8, 12, 17, 28, 36, 50, 59], PrivFormer [1] and PPTIF [32] can work under the honest-majority setup, where two out of three parties are honest adversaries, and the last one can be semi-honest or even malicious. Nonetheless, even though 2PC-Dealer and 3PC setups could improve secure inference performance efficiently, the assumption of a trusted dealer or non-colluding server parties is sometimes considered unrealistic in practice [20]."}, {"title": "4.3 Strengths and Weaknesses.", "content": "MPC and HE both enable secure computation, and there is no clear better technique. Instead, the choice has to be made based on multiple factors depending on the applications. Here, we provide a critical review of their strengths and weaknesses in terms of communication cost, computational overhead and privacy protection.\nClient Computation. Some studies require the client to frequently participate in the computation during the inference process, and hence they tend to assume that clients also have relatively high computing resources. However, involving clients in computation could pose significant consumption challenges to low-power devices in practical, e.g., mobile devices. THE-X [7]\nModel Performance. THE-X [7] and MPCFormer [28] simply replace the nonlinear layers with cryptography-friendly approximations for efficiency and, therefore, suffer a significant model performance degradation. To cure the accuracy drop, MPCFormer [28] applies a knowledge distillation (KD) [19] method to train the approximated model,"}, {"title": "5 LINEAR LAYERS IN TRANSFORMERS", "content": "Linear layers in transformers mainly involve large matrix multiplications (MatMul) in attention and feed-forward layers, and this section discusses the state-of-the-art literature on secure MatMul in PTI. Specifically, Section ?? first provides a breakdown of linear layers in a standard Transformer encoder. Then, Section 5.1 generalizes the two kinds of main-stream secure MatMul protocols in current PTI studies."}, {"title": "5.1 Large Matrix Multiplications", "content": "The inference of a transformer-based model can involve hundreds of large matrix multiplications. For ease of under-standing, we first present an example of MatMul operation as follows:\nExample 5.1. Given two matrices $A \\in \\mathbb{R}^{m \\times n}$ and $B \\in \\mathbb{R}^{n \\times k}$, the matrix multiplication output C is:\n$C = A \\times B$,\nwhere $C \\in \\mathbb{R}^{m \\times k}$, and its each element $C_{i,j}$ can be regarded as:\n$C_{i,j} = \\sum_{k=1}^{N} A_{i,k} B_{k,j}$\nAccording to (5), we can see that each element of the MatMul output C can be computed as the sum of products of corresponding elements from the rows of A and the columns of B. This naive finding allows us to break the whole matrix multiplication into a series of addition and multiplication operations, and cryptographic primitives can be adapted to support these operations.\nParticularly, to implement secure MatMul protocols, current PTI studies adopt the following main-stream ways:\n\u2022 Secret Sharing (SS)-based Scheme: In the SS-based scheme, the matrices A and B are divided into shares and distributed among multiple parties. Each party holds a share of A and B but not the original matrices. The matrix multiplication is performed on the shares, and the results are combined to obtain the final result.\nStrengths:\nAdditions can be easily evaluated locally \"for free\", dramatically saving communication resources.\nWeaknesses:\nMultiplications need extra communication between parties.\n\u2022 Homomorphic Encryption (HE)-based Scheme: Here, one matrix (A or B) is encrypted using HE that supports arithmetic operations on ciphertexts. The two matrices are then multiplied, and the MatMul output is decrypted to obtain the final product.\nStrengths:\nHE-based methods naturally support mixed computations, which is communication-friendly.\nWeaknesses:\nOperations involving ciphertexts require more computation and are applied component-wisely by default, resulting in a considerable computational overhead.\nNext, we further detail state-of-the-art PTI studies on SS-based MatMul protocols and HE-based MatMul protocols in Section 5.2 and Section 5.3, respectively."}, {"title": "5.2 Secrete Sharing-based MatMul protocols", "content": "We first introduce secrete sharing-based MatMul protocols in current secure transformer inference studies. Specifically, secrete sharing schemes support adding secret-shared values locally (without interaction) by simply adding the"}, {"title": "5.3 Homomorphic Encryption-based MatMul protocols", "content": "The use of HE for matrix multiplications in transformers is still relatively unexplored. There is little work on PTI using HE-based protocols for matrix multiplications. While matrix multiplication is inherently compatible with HE, as it involves only additions and multiplications, a straightforward implementation can be highly inefficient. Specifically, HE-based MatMul protocols in transformers still face several key challenges:"}, {"title": "6 NON-LINEAR LAYERS", "content": "Securing the non-linear functions in Transformers poses another challenge due to their complexity in cryptographic primitives. The bulk of the total run time is from non-linear layers for both MPC and HE studies [18, 28, 43]. Non-linear functions in Transformers include Softmax, GeLU and LayerNorm. We detail each of them in the following subsections."}, {"title": "6.1 Softmax", "content": "In the attention mechanism, one key challenge is the implementation of the nonlinear Softmax operation. For the sake of numerical stability [16], when given an input vector x \u2208 Rd, the Softmax function can be computed as:\n$Softmax(x) = \\frac{exp (x_i - \\hat{x})}{\\sum_{j=1}^{d} exp (x_j - \\hat{x})} \\forall i \\in [d]$\nwhere $\\hat{x} = max_{i \\in [d]} x_i$. It is worth noting that all inputs to the exponential function in (6) are non-positive now. The main challenge is to efficiently calculate the underlying exponential function and division computation. Next, we discuss recent research advancements in optimizing Softmax and provide a detailed comparison in Table 8.\nTech Tips: In essence, the Softmax function could be regarded to perform a re-weight normalization of the obtained attention map, and its general form is formulated as follows:\n$Softmax(x_i) = \\frac{F(x_i)}{\\sum_{j=1}^{d} F(x_j) + \\epsilon}$\nwhere function F(.) widely adopts the exponential function exp(.) and $\\epsilon$ is a small positive number to avoid a zero denominator. Therefore, existing studies mainly optimize its computation in the following two methods:\n\u2022 Employ more crypto-friendly functions to server as F(x) in Softmax, such as the ReLU(x) and quadratic function $(x + c)^2$. Those functions often consist of more basic arithmetic operations (e.g., multiplications and comparisons), the overhead to compute Softmax(xi), thus dramatically decreasing overheads. It is worth noting that this approach comes at the cost of a significant drop in accuracy.\n\u2022 Directly utilize different polynomial approximations (e.g., the Taylor series) of exp(x) to serve as F(x). This method could help to maintain the accuracy. However, one should be careful about the choice of polynomial approximation order; too high a polynomial order can bring better accuracy while reducing computational efficiency obviously."}, {"title": "Crypto-friendly Functions", "content": "Studies [6, 28, 36, 63, 65] that favour the first solution often use aggressive crypto-friendly functions and, therefore, require additional training to minimize the loss of accuracy. Specifically, we present their methods as follows:\n$Softmax(x_i) \\approx \\frac{F(x_i)}{\\sum_{j=1}^{d} F(x) + \\epsilon}$ , for F(x) =\n$(x + c)^2$, in MPCFormer [28], SecFormer [36]\nReLU(x), in MPCVIT [63]\n$(\\alpha x + c)^2$, in SAL-VIT [65]\n$(x + c)^4$, in RNA-VIT [6]\nIt is obvious that (8) and the original Softmax (6) differ a lot by numerical values. Hence, the above studies all utilize the Knowledge Distillation (KD) [19] method to bridge the performance gap."}, {"title": "Polynomial Approximations", "content": "Studies [12, 20, 34, 43, 64] employ polynomial approximation to replace the original exp(x) in Softmax. The computation of polynomials can be decomposed into basic addition and multiplication operations, which are easily supported by cryptographic techniques. BOLT [43] decomposes the input $x_i - \\hat{x}$ into a non-negative integer z and a float number $p \\in (-\\ln 2,0]$, where $x_i - \\hat{x} = (-\\ln 2)z + p$. Then, the exponentiation is approximated as exp(xi) = exp(p) >> z, where >> denotes the right shift operator. Since the range of p is relatively small, a 2-degree polynomial is enough for the approximation:\n$exp(p) \\approx 0.3585(p + 1.353)^2 + 0.344.$\nFor the $\\frac{1}{\\sum_{j \\in [d]} exp (x_j - \\hat{x})}$ part, i.e., the reciprocal of the summed exponential function's outputs, BOLT uses the reciprocal protocol from SIRNN [48]. Besides, NEXUS [64], CipherGPT [20], PUMA [12] and BumbleBee [34] all approximate the exponential function in Softmax using the Taylor series.\n, for\n\\approx\nif $x \\leq a$\n$\nexp(x) = \\frac{1}{(1+\\frac{x}{r})^2}$  ,\nif $a \\leq x \\leq 0$\na = inf, r = 6, in NEXUS [64]\na=-13, r = 6, in BumbleBee [34]\na = -16, in CipherGPT [20]\na = -14, r = 5, in PUMA [12]\nAdditionally, NEXUS uses its proposed QuickSum and the Goldschmidt division algorithm to compute the reciprocal of the sum of exponential functions. Rovida et al. [49] approximates Softmax using the Maclaurin series:\n$exp(x) \\approx \\sum_{i=0}^{6} \\frac{x^i}{i!}$"}, {"content": "and for the division operation, they use a Chebyshev polynomial approximation:\n$\\frac{1}{x} \\approx \\frac{c_0}{2} + \\sum_{i=1}^{119} c_iT_i(x)$"}, {"title": "LUTs.", "content": "Some studies [17, 18] use look-up tables (LUTs) for Softmax. A LUT is a pre-computed table stored in memory, containing input-output pairs. It allows for quick retrieval of function values by directly looking up results, eliminating the need for real-time calculation. Iron [18] uses a tree-reduction protocol to evaluate the max function and then"}, {"title": "6.2 GeLU", "content": "Rather than crypto-friendly ReLU, Transformers utilize GeLU activations. The GeLU (Gaussian Error Linear Unit) activation function is defined as follows:\n$GeLU(x) = \\frac{x}{2} [1 + erf(\\frac{x}{\\sqrt{2}})]$,\nwhere erf() denotes the Gaussian error function which is given by $erf(x) = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{x} e^{-t^2} dt$. In many libraries, e.g., PyTorch, the following approximation is provided:\n$GeLU(x) \\approx \\frac{x}{2} [1 + tanh(\\sqrt{\\frac{2}{\\pi}}(x + 0.044715x^3)]$,\nand where:\n$tanh(x) = \\frac{e^{2x} - 1}{e^{2x} + 1}$\nHence, the main challenge is how to efficiently handle the nonlinear erf(x) (i.e., tanh(x)) part.\nTech Tips: The function GeLU(x). Besides, polynomials are still available to approximate either tanh(x) (i.e., erf (x)) or the entire GeLU(x)\nSome studies [7, 28] approximate GeLU simply using crypto-friendly ReLU or ReLU approximation. For example, THE-X [7] and PowerFormer [44] directly replaces the GeLU layers with ReLU activation functions:\n$GeLU(x) \\approx ReLU(x) = max(0, x)$"}, {"title": "6.3 Layer Normalization", "content": "Layer normalization ensures that the inputs across different layers of the network have a consistent mean and variance, helping to stabilize deep neural networks. It is applied after each attention block and feed-forward layer. For a given vector x \u2208 Rd, the Layer normalization function is defined as follows:\n$LayerNorm(x) = \\gamma [\\frac{(x) - \\mu}{\\sigma}] + \\beta [i=1,..., d]$,\nwhere $\\mu = \\sum_{i=1}^{d}x_i/d$ and $\\sigma = \\sqrt{\\sum_{i=1}^{d}(x_i - \\mu)^2}$ are mean and standard deviation, and y and \u1e9e are affine transform parameters. The calculation of u only requires additions and multiplications by a constant. Thus, the main challenge lies in the required reciprocal square root operation. Next, we discuss the methods to cope with LayerNorm in different studies and report the performance in Tab. 10.\nSome studies [7, 18, 64] have developed methods to mitigate the computation overhead of parameters u and \u1e9e for efficiency. For instance, THE-X [7] employs two sets of learnable parameters $\\tilde{\\gamma} := [\\gamma_1,..., \\gamma_d]$ and $\\tilde{\\beta} := [\\beta_1, ..., \\beta_d]$ to avoid the calculations of original \u00b5 and \u03b2. Specifically, it simplifies LayerNorm as follows:\n$LayerNorm(x) \\approx x \\odot \\tilde{\\gamma} + \\tilde{\\beta}$,\nwhere y handles both normalization and linear transformation, and $\\odot$ denotes for the Hadamard product. A distillation will be applied in (24) to learn from the original LN layers and bridge the performance gap. Iron [18] combines the weights of LayerNorm ( and \u1e9e) with the next linear layer's weights to save one matrix multiplication. This results in a simplified output from LayerNorm as follows:\n$LayerNorm(x) = \\gamma[x_i - \\mu]_{i=1,..., d}$"}, {"title": "A MPC SETTINGS", "content": "We first present the popular MPC settings employed in current secure inference studies. Each of them has different requirements and assumptions on the participating parties. Generally speaking, the 2PC setup is the most natural for secure inference, while 3PC and 2PC-Dealer setups usually support a wider variety of operations and improve the MPC performance. We compare their strengths and weaknesses in Table. 13.\n\u2022 2-party computation (2PC): This is the basic MPC setting where two participants engage in computation without mutual trust. Each party contributes their input to the computation, but neither can see the other's data. This setting is the most intuitive and commonly used for secure inference, as it only involves two parties and minimizes the complexity of trust and coordination.\n\u2022 Honest-majority 3-party computation (3PC): This configuration introduces an additional \"helper\" party, increasing the capabilities of the computation. In this model, the adversary may corrupt any single party without compromising the integrity of the computation. The presence of the third party allows for a broader range of operations and enhances the overall performance of MPC.\n\u2022 2PC with trusted dealer (2PC-Dealer): In this scenario, a trusted dealer plays a crucial role during a pre-processing phase by distributing input-independent correlated randomness to the two computation parties. This randomness is used to facilitate and speed up computations. The trusted dealer is not involved in the computation itself but enables more efficient processing."}]}