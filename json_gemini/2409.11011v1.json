{"title": "Enhanced segmentation of femoral bone\nmetastasis in CT scans of patients using\nsynthetic data generation with 3D diffusion\nmodels", "authors": ["Emile Saillard", "Aur\u00e9lie Levillain", "David Mitton", "Jean-Baptiste Pialat", "Cyrille Confavreux", "H\u00e9l\u00e8ne Follet", "Thomas Grenier"], "abstract": "Purpose:\nBone metastasis have a major impact on the quality of life of patients and\nthey are diverse in terms of size and location, making their segmentation\ncomplex. Manual segmentation is time-consuming, and expert segmenta-\ntions are subject to operator variability, which makes obtaining accurate", "sections": [{"title": "1 Introduction", "content": "Bone metastasis are frequent in cancer patients, particularly those with primary\nprostate or breast cancer [11]. These metastasis often lead to various complica-\ntions, like pathological fractures, having a significant impact on patients' quality\nof life. Computed tomography (CT) is a widely utilized imaging technique to\nassess the risk of pathological fractures clinically.\nSegmenting bone metastasis poses significant challenges due to the diverse\ntypes of metastasis, varying sizes, and lesion locations. Manual segmentation of\nthese lesions is particularly time-consuming, reflecting the complexity of the task.\nMoreover, intra- and inter-operator variability in bone metastasis segmentation\nis substantial, especially for smaller lesions [2]. This variability, although dataset-\ndependant, underscores the complexity of segmentation and affects applications\nlike biomechanical simulations where reproducibility is key and sensitivity to\nsegmentation is important [5]. Models trained for automatic segmentation of\nfemoral bone metastasis using CT data have been documented [3,8,14]. How-\never, the segmentation quality achieved by these models is insufficient for clini-\ncal use [13]. The lack of public datasets with CT images of femoral metastasis\nhinders model comparison, as performance depends heavily on the dataset used.\nMoreover, the lack of manually annotated data complicates the training pro-\ncess, leading to lower generalizability of trained models due to overfitting. Data"}, {"title": "2 Materials and Methods", "content": "In this section, we describe the datasets used to train and evaluate the different\nmodels. We outline the different processing steps and model architectures em-\nployed for image synthesis and bone metastasis segmentation. This is a prospec-\ntive study."}, {"title": "2.1 Data", "content": "The dataset used for metastasis segmentation consists of 29 manually segmented\nCT-scans of anonymized patients with femoral osteolytic metastasis (National\nnumber: 2019-A01202-55): 20 from the MEKANOS cohort ((Hospices civils Lyon,\nagreement number N. 21-5467, May 28th 2021)), 9 from the DEMETOS cohort\n(Hospices civils Lyon, RNIPH, MR-004-21_5467). Additionally, 9 femoral CT\nscans of patients from the DEMETOS cohort from 3 different centers were also\nused to further evaluate segmentation performance and to evaluate operator\nvariability.\nExamples of femurs from the 3 centers used for this study are displayed in\nFigure 1, along with operator segmentations. The scans from MEKANOS were\nacquired in clinical routine following a specific procedure (constant table height,\nquality phantom QA Mindways, 120 kV, 270 mAs, 1 Pitch, Field of view 360 mm\nand 200 mm, reconstruction: standard filter B, 512 \u00d7 512 matrix, slice thickness\n0.7 mm) and with three manufacturers' acquisition systems (General Electric,\nPhilips and Siemens). The remaining scans were not acquired with a standard\nprotocol and had therefore various area scanned, acquisition systems used as well\nas voxel sizes. All femurs have at least one osteolytic metastasis, each manually"}, {"title": "2.2 Operator variability", "content": "We evaluate operator variability on 9 metastatic femurs from 3 different centers.\nTwo novice operators A and B (one master student and an assistant professor\nin biomechanics) and an expert radiologist (C) manually segmented the femoral\nmetastasis. The DICE score is calculated between the operators to quantify\ninter-operator variability. To assess intra-operator variability, operators A & B\nsegmented the same metastasis again after three months. We also compare man-\nual segmentations to automatic segmentation (model \"diffusion + fine-tuning\")\non those 9 metastatic femurs."}, {"title": "2.3 Data synthesis", "content": "Ad-hoc data synthesis To improve the robustness of our segmentation mod-\nels, we propose a fully automated image synthesis pipeline that increases the\nquantity of training data by generating realistic pathological images using exist-\ning lesions and healthy femurs, as illustrated in Figure 2.\nUsing the manual segmentation of the metastasis, the lesion is first extracted\nfrom the original CT volume and then cropped via a random intersection with an\nellipsoid shape, mimicking a realistic lesion shape. Spatial transforms (rotations\n& scaling) are then applied to the lesion. For greater realism and diversity, the\nedges of the lesion are smoothed by a mean filter, followed by the addition"}, {"title": "Diffusion Network", "content": "We propose a novel approach to enhance the diversity and\nrealism of our synthetic dataset using diffusion models. We train a custom 3D\nDDPM [7,9] to improve the quality of the previously generated synthetic sets.\nUnlike traditional image generation, our focus is not on creating new samples\nfrom scratch but on modifying existing images, as inpainting [10] or anomaly\ndetection methods [18]. This enables us to train our model effectively with a\nsmaller training dataset.\nUsing the following forward (diffusion) process q on the data x, iteratively\nadding gaussian noise following a normal law N, as in [7]:\nq(x_{1:T}|x_0) := \\prod_{t=1}^{T} q(x_t|x_{t-1}),\tq(x_t|x_{t-1}) := N(x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_tI)  (1)"}, {"title": "2.4 Metastasis Segmentation", "content": "The same MONAI framework is used to implement the 3D UNet segmentation\nnetwork.\nFor all trainings, the same architecture and hyper-parameters, as the same\ntest folds, are used. The network consists of a 5-level UNet with 32, 64, 128,\n256, and 512 channels. The input size of patches is fixed to 96 \u00d7 96 \u00d7 64. The\nDICE loss is optimized with SGD momentum using a weight of 0.9 and an initial\nlearning rate of 0.025, an exponential decay of 0.999 for real data, and 0.99 for\nboth synthetic and diffusion sets. Classical data augmentation is performed: flips,\nrotations, scaling, Gaussian noise addition, and contrast enhancement. An early-\nstopping criterion is used to stop the trainings with a patience of 200 epochs.\nThese trainings are performed on NVIDIA P100 GPUs (16GB GPU RAM) and\nrequire 1 day/fold for the real images set, and 6 days/fold for the whole synthetic\nand diffusion sets. Post-processing based on morphological operations is added\nto improve segmentation performance. Fine-tuning on real images uses almost\nthe same parameters except lr = 0.001, no decay, and a patience of 25 epochs.\nFive UNet models are obtained: one trained using real images only (Real),\none using synthetic set only (Synthetic), one fine-tuning the previous using real\nimages (Synthetic+FT), one using diffusion set only (Diffusion), one fine-tuning\nthe previous using real images (Diffusion+FT).\nWe investigate the influence of the number of training samples on the overall\nsegmentation performance, by training additional models with 100, 500 and 2000\nsynthetic samples respectively, with training time ranging from 12 hours to 3\ndays.\nAll models are assessed on our 29 pathological real data using a 5-fold cross-\nvalidation. The 9 additional pathological volumes used for the operator vari-\nability, which are not included in training, are used in testing, for a total of\n38 test samples. The lesions involved in the tested fold are excluded from any\ncontribution in the synthetic images involved in the remaining training folds.\nWe quantify the segmentation performance using the DICE score, the Haus-\ndorff distance (HD and HD95), and the Average Symmetric Surface Distance\n(ASSD) [12]."}, {"title": "2.5 Statistical analysis", "content": "The statistical significance of segmentation approaches is tested against the re-\nsults obtained with the network trained using only the real images. As some\nvariables were not normally distributed even after transformation, we used non-\nparametric tests. After running the Kruskal-Wallis test showing differences (P <"}, {"title": "3 Results", "content": "The results on lesion segmentation operator variability are displayed in Table\n1. Both the intra- and inter-operator variability are substantial, with an intra-\noperator DICE of 0.77 and an inter-operator DICE of 0.73 between novices and\n0.72 between expert and novice. Those results are comparable to what can be\nfound in existing studies [3,14]. Automatic segmentations reach a mean DICE\nof 0.71 with novice operators and 0.75 with the expert.\nThe visual quality of the synthetic images depicted in Figure 3 is notable, al-\nthough, in some instances, the added lesion may appear insufficiently integrated\ninto the image. Nevertheless, after only a few steps of the diffusion process, the\nintegration of the lesion becomes more realistic.\nThe results obtained depending on the amount of synthetic data can be\nobserved in Table 2. As expected, adding more synthetic data improves the\nsegmentation performance. However, we can observe that performance reaches\na plateau, with comparable results obtained when using 2000 or 5975 samples.\nWhile HD, HD95 and ASSD keep decreasing when using more samples, the DICE\nstops improving, with even a slight decrease.\nFigure 5 provides a comparison with real metastasis and showcases the au-\ntomatic segmentations obtained using the five differently trained models.\nThe contribution of synthetic data with or without diffusion and fine-tuning\nis apparent, with clear metrics improvement compared to the model trained on\nreal data only. Some lesions are not accurately segmented and the algorithms can\nalso produce false positives that can negatively impact metrics such as Hausdorff\nvalues.\nThe distance metrics show important differences between the models, with\nthe best model in terms of segmentation performance (DC=0.65) not having the\nbest results in terms of HD and ASSD. This indicates a presence of false positives\nthat can be further away from the ground-truth segmentation, but given the very\nclose values obtained on ASSD and the better DICE value, the model \"Diffusion\n+ FT\" is the best overall. Improving the dedicated post-processing could help\ndiminish the differences between the models in terms of HD."}, {"title": "4 Discussion", "content": "We have generated synthetic volumes to alleviate the issue of data scarcity for\nour segmentation task.\nWe observed that most synthesized volumes have an overall convincing visual\nquality and although some samples do not have a high realism, our results show"}, {"title": "5 Conclusion", "content": "We propose a data synthesis pipeline that produces realistic and varied metastatic\nimages, allowing to better train lesions segmentation models and thus achieve\nbetter performance than comparable state-of-the art models.\nOur data synthesis pipeline enables the generation of a large quantity of vol-\numes along with ground-truth labels, substantially enhancing overall segmenta-\ntion performance. Incorporating 3D diffusion models enhances the realism and\ndiversity of synthetic images, although further investigation into the generated\nsamples is necessary to comprehensively assess model performance. The seg-\nmentation results obtained with our approach are encouraging, but challenges\nremain in addressing segmentation and detection errors and extending testing\nacross diverse datasets to enable clinical applications."}]}