{"title": "Socially-Informed Reconstruction for Pedestrian Trajectory Forecasting", "authors": ["Haleh Damirchi", "Ali Etemad", "Michael Greenspan"], "abstract": "Pedestrian trajectory prediction remains a challenge for autonomous systems, particularly due to the intricate dynam-ics of social interactions. Accurate forecasting requires a comprehensive understanding not only of each pedestrian's previous trajectory but also of their interaction with the surrounding environment, an important part of which are other pedestrians moving dynamically in the scene. To learn effective socially-informed representations, we propose a model that uses a reconstructor alongside a conditional vari-ational autoencoder-based trajectory forecasting module. This module generates pseudo-trajectories, which we use as augmentations throughout the training process. To further guide the model towards social awareness, we propose a novel social loss that aids in forecasting of more stable trajectories. We validate our approach through extensive experiments, demonstrating strong performances in comparison to state-of-the-art methods on the ETH/UCY and SDD benchmarks.", "sections": [{"title": "1. Introduction", "content": "Pedestrian trajectory prediction estimates a target pedestrian's future location after examining the observed locations of the pedestrian in the scene [1]. This capability is essential for safe route planning of autonomous vehicles [31] as it requires accurate and reliable predictions to ensure the safety of pedestrians and drivers [3]. By accurately forecasting future paths of pedestrians in the scene, proactive measures can be taken to prevent potential accidents [22]. Similarly, trajectory forecasting helps to understand and model pedestrian behaviour, allowing vehicles to anticipate and react to pedestrians' movements in real time [4, 18,32]. Additionally, it can assist in the analysis of pedestrian movement patterns in crowded areas to optimize pedestrian infrastructure [26].\nA key aspect of human trajectory forecasting that distinguishes it apart from other time-series problems [24, 29] is the inherent human element [25]. Humans are social beings, and interactions between individuals significantly influence how we navigate through (especially crowded) spaces [1]. For instance, when walking in a crowded area, people naturally adjust their paths to avoid potential collisions with others. This social dynamic is critical in predicting human movements accurately. Prior works [6, 13, 14,34] have shown that considering social interactions in trajectory forecasting models can lead to more precise predictions, as these interactions play a crucial role in determining individual movement patterns. Another challenge in human trajectory forecasting, which is shared by many deep learning applications, is the high cost of collecting labeled data. A standard approach to mitigate this issue is to apply standard augmentations to the data prior to training [2, 5, 30]. However, while standard augmentation techniques have been initially developed and are well-suited for static images, they do not necessarily translate well to trajectory data. As a result, developing methods to generate more effective augmented trajectories, particularly those that consider social interactions, can significantly enhance the learning process, leading to better performance in real-world applications.\nIn this paper, to address the problems described above, we propose a novel trajectory forecasting model. Our method uses several distinct elements to improve representations and enhance the stability of the predictions. First, it uses a trajectory reconstruction module to operate alongside the forecaster. The inclusion of this module improves the learned representations and simultaneously allows the reconstructed pseudo-trajectories to be fed back to the training pipeline as augmentations. Our model only selects challenging pseudo-trajectories to be used as augmentations to ensure that the model is exposed to difficult scenarios that improve its robustness and generalization capabilities. Second, our model includes a novel loss, called social loss, to enforce socially accurate predictions in the generated future time-stamps. We illustrate an overview of our method in Figure 1. To evaluate the performance of our solution, we experiment on 5 popular pedestrian trajectory forecasting benchmarks [10, 17], namely ETH, Hotel, Univ, Zaral, Zara2, and Stanford Drone Dataset (SDD) [20]. Our experiments show our method to outperform the state-of-the-art based on standard forecasting"}, {"title": "2. Related Work", "content": "2.1. Trajectory Forecasting\nA variety of methods have focused on the social attribute of trajectories, in which multiple pedestrians are influenced by each other. Social GAN [6] employed adversarial training to improve the accuracy of their model in complicated social scenarios. By synthesizing realistic trajectories, it refines predictions by incorporating both individual and social context. A pooling module was used to aggregate features from other pedestrians in the scene, though this module could cause the model to struggle in crowded environments. Later, Trajectron++ [23] introduced a social model for trajectory forecasting, where interactions were modelled by summing the feature vectors of neighboring pedestrians. While computationally efficient and a relatively simple operation, this method could oversimplify the interactions in a scene. So-cial Spatio-Temporal Graph Convolutional Neural Network (Social-STGCNN) [13] departs from previous aggregation methods and uses a graph network with an adjacency matrix based on distances between pedestrians to forecast future trajectories. Although this operation allows the model to account for neighbouring pedestrians, it may not adapt to changing social contexts such as group behaviors due to the non-learnable adjacency matrix. To improve the social connection between trajectories, Agentformer [34] proposed a new form of attention in their transformer architecture. Whereas methods prior to Agentformer generally modelled the social and temporal information separately, the new form of attention jointly addressed both the temporal and the social aspects of trajectory prediction. Later, Social Implicit [14] proposed to forecast each pedestrian's future trajectory by using sub-modules trained for specific speed ranges. This approach may not fully capture scenarios where pedestrians adjust their speed in response to others.\nA different set of methods explore the importance of goals, i.e. the final timestep, for trajectory prediction [12, 32,35]. Unlike previous models that focus on a single, long term goal, SGNet [28] introduced a step-wise goal estimator which dynamically estimated and utilizes goals at multiple timesteps. YNet [11] cast goal estimation and future trajectory prediction into image form, utilizing convolutional neural networks in the form of a UNet architecture to predict both the goals and the future trajectory by sampling from the generated heatmap at the network output. However, both SGNet and YNet lack a structure for the social prediction of trajectories."}, {"title": "2.2. Social, Psychological, and Behavioral Factors", "content": "Incorporating environmental context, psychological factors and behaviour patterns of pedestrians is crucial for predicting trajectories and motions of humans. Psychological and behavior attributes such as personal space and goal-"}, {"title": "3. Method", "content": "3.1. Problem Setup\nLet $X_t = {x_{t,1}, x_{t,2}, ..., x_{t,N}}$ represent a set of 2D locations of N pedestrians at time t, where $x_{t,i} \\in \\mathbb{R}^2$. We denote $S_p = {X_1, X_2, ..., X_{t_p}}$ and $S_f = {X_{t_p+1}, X_{t_p+2}, ..., X_{t_f}}$ as sequences of locations of N pedestrians at the past and future timesteps, respectively, with $t_p$ and $t_f$ as the present and final timesteps. The goal of social trajectory forecasting is to accurately predict multiple plausible future trajectories given $S_p$, such that $||x_i - x_j|| > \\epsilon, \\forall i \\neq j$, where $\\epsilon$ is the minimum acceptable distance between two pedestrians at a given timestep.\n3.2. Proposed Approach\nTo address the above-mentioned problem, we propose a new solution which consists of three key components: a social forecaster, a social reconstructor, and a pseudo-trajectory generator. At a high level, the social forecaster predicts the future trajectory locations for each pedestrian in the scene given their locations in past timesteps. The social reconstructor reproduces the locations at past timesteps which have been partially masked for each pedestrian. Finally, the pseudo-trajectory generator creates new trajectory sequences by sampling from the reconstructed trajectories, which will then be used in future training iterations. The architecture for our proposed approach is illustrated in Figure 2. Following, we describe each element of our method in detail."}, {"title": "3.2.1 Social Forecaster", "content": "The past trajectories $S_p$ are first fed to the social forecaster module, which is inspired by the Conditional Variational Autoencoder-based forecaster proposed in [34] and consists of four components: Encoder, Conditional Prior Network (CPN), Predictor Posterior Distribution Network (PPDN), and Forecasting Decoder. The encoder module consists of a transformer encoder which uses agent-aware attention [34].\nThe input to this attention unit is query Q, key K and value V. The attention output is calculated as:\n$A = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_m}})V$, (1)\n$\\text{SocialAtt}(Q, K, V) = M \\odot (Q_{self}K_{self}^T) + (1 - M) \\odot (Q_{other}K_{other}^T)$, (2)\nwhere A is the attention weight matrix; $d_m$ is the model dimension; $Q_{self} = QW_{self}$ and $Q_{other} = QW_{other}$ are the query values projected by weights $W_{self}$ and $W_{other}$, and; $K_{self} = KW_{self}$ and $K_{other} = KW_{other}$ are the key values projected by weights $W_{self}$ and $W_{other}$. In Eq. 2, for matrix M, the attention mask between pedestrian i and j is defined as $M_{ij} = I(i \\mod N = j \\mod N)$. When i=j, the attention weight matrix A is masked to include only those weights that correspond to the relationship between the pedestrian itself at different timesteps. However, when $i \\neq j$, the attention weight matrix represents the relationship between pedestrian i and pedestrian j at different timesteps.\nTo produce the latent code $z \\in \\mathbb{R}^{N \\times d_z}$ for all N target pedestrians, we pass the encoded features to the CPN module, which is a linear layer. This module generates the parameters $\\mu_F$ and $\\sigma_F$ of for the prior Normal distribution $p_{\\phi_F}(z|S_p) = N(\\mu, \\text{Diag}(\\sigma_F)^2)$, where $\\phi_F$ is the set of parameters for the CPN module. PPDN consists of an agent-aware cross-attention mechanism (explained earlier), followed by a linear layer similar to that of the CPN. This module utilizes both ground truth (future) and past timesteps to output the parameters of the posterior distribution $q(z|S_p, S_f) = N(\\mu, \\text{Diag}(\\sigma_F)^2)$. The latent code generated by PPDN and the ground truth future timesteps are then passed on to the transformer forecasting decoder at training time. This decoder consists of an agent-aware self-attention module followed by cross-attention. Masking is implemented in the agent-aware self-attention inside the decoder to prevent the previous timesteps from peeking into the future ground truth values.\nTo train the social forecaster, the negative evidence lower bound (ELBO) is employed as follows:\n$\\mathcal{L}_F = -E_{q_{\\phi_F}(z|S_p,S_f)}[\\log(p_{\\theta_F}(S_f|z, S_p))] + KL(q_{\\phi_F}(z|S_p, S_f)||p_{\\phi_F}(z|S_p))$, (3)\nwhere $p_{\\theta_F}(S_f|z, S_p)$ is the conditional likelihood. The initial term in the formula denotes the prediction error, for"}, {"title": "3.2.2 Social Reconstructor", "content": "To further enforce the training process and provide stronger encoded representations of past trajectories Sp, our model includes a social reconstructor module in parallel with the social forecaster, where the encoder between the two modules are shared. To create the input for the social reconstructor, we mask the past trajectory Sp by a ratio of R. We zero out R% of the total timesteps in the trajectory selected randomly, which we name $S_{masked}$. The social reconstructor"}, {"title": "3.2.3 Total Loss", "content": "The final loss function is formulated as:\n$L_{Total} = w_1 L_F + w_2 L_R + w_3 (L_{SocF} + L_{SocR})$, (9)\nwhere $w_1, w_2$ are corresponding weights for the CVAE, and VAE (reconstructor) modules, and $w_3$ is the weight for the social loss functions for both the forecaster and reconstructor."}, {"title": "3.2.4 Pseudo-trajectory Generation", "content": "We propose a pseudo-trajectory generator for augmenting the training set with samples that are challenging for the forecaster module. We follow the strategy proposed in [33] and monitor the fluctuations in the loss value for each sample. Throughout training, each sample goes through phases of 'descending' where the loss decreases for that sample between two consecutive epochs, and 'ascending' where it increases. Accordingly, difficult samples tend to experience more 'ascending' states than 'descending' throughout the training. As the approach introduced in [33] is primarily designed for classification, we adapt the process for our specific regression task of trajectory forecasting:\n$d_{i,e} = \\text{min}(L_F(i, e) - L_F (i, e-1), 0) \\cdot \\text{ln} \\frac{L_F(i, e)}{L_F(i, e - 1)}$, (10)\n$a_{i,e} = \\text{max}(L_F(i, e) - L_F(i,e-1), 0) \\cdot \\text{ln} \\frac{L_F(i, e)}{L_F(i, e - 1)}$, (11)\nwhere $L_F(i, e)$ is the loss for instance i at epoch e. To label an instance as difficult after $N_c$ epochs of observing $a_{i,e}$ and $d_{i,e}$, we count the number of epochs in which $d_{i,e} > a_{i,e}$, meaning that the training loss has been descending for that instance. The cumulative sum of this indicator over $N_c$ epochs is calculated as follows:\n$\\text{Count}(i) = \\sum_{e=1}^{N_c} I(d_{i,e} > a_{i,e})$. (12)\nAn instance is flagged as difficult if $Count(i) < D \\times N_c$, where D is a predefined threshold parameter.\nDuring the training process, we initially focus on training the social forecaster and social reconstructor across the entire dataset for a fixed number of epochs, $N_T$. This step is important in establishing a robust foundation to enable reasonable reconstructions of difficult cases as part of a continuous training process.\nThe reconstructed version of the samples that are determined to be challenging, its reconstructed masked sequence, $\\hat{S_p}$, are then processed through the social forecaster module to predict future timesteps. We then concatenate the reconstructed sequences with their corresponding forecasted segments as follows:\n$S_{Aug} = S_p \\cup SF(\\hat{S_p})$, (13)\nwhere $S_{Aug}$ is the newly augmented scene, and SF(.) is the social forecaster function. The integration of identifying and addressing difficult samples occurs in tandem with ongoing training, enhancing the model's capacity to effectively handle such cases without interrupting the training process. This continuous loop ensures that our model dynamically adapts and improves its performance on challenging instances within the training set."}, {"title": "4. Experiments", "content": "Datasets. We evaluate our method using the ETH/UCY benchmark [10, 17] and SDD [20]. The ETH/UCY benchmark features real world pedestrian trajectories across five scenes including: ETH, Hotel, Univ, Zaral and Zara2. Each scene contains both multiple and single trajectories, with the multiple trajectory scenarios demonstrating collision avoidance and group behaviour. We use the same coordinate format originally used by SGAN [6]. For SDD, following DAG-NET [15] and Social Implicit [14], we convert the pedestrian locations from pixels to metric coordinates.\nEvaluation Metrics. We use the following three metrics to evaluate our method.\nAverage Distance Error (ADEK): This metric calculates the average L2 distance between the ground truth and each of K trajectories predicted by the model. The formulas for minimum and mean ADE calculation are defined as follows:\n$ADE_{min} = \\frac{1}{KT} \\sum_{t=1}^{T} \\min_{k=1}^{K} ||S^{(k)}(n,t) - S_f(n,t)||^2$, (14)\n$ADE_{mean} = \\frac{1}{KT} \\sum_{k=1}^{K} \\sum_{t=1}^{T} ||S^{(k)}(n,t) - S_f(n, t) ||$. (15)\nFinal Distance Error (FDEK): This metric measures the distance between the predicted final destination and the ground truth final coordinates for all K predicted trajectories. The formulas for minimum and mean FDE are defined as:\n$FDE_{min} = \\min_{k=1}^{K} || S^{(k)}(n,T) - S_f(n,T)||^2$, (16)\n$FDE_{mean} = \\frac{1}{K} \\sum_{k=1}^{K} || S^{(k)}(n, T) - S_f(n, T) ||^2$. (17)\nSince all benchmarks use metric measurements, the values of ADEK and FDEK are expressed in meters.\nKernel Density Estimate-based Negative Log Likelihood (KDE-NLL): This metric, which we refer to as KDE, calculates the mean negative log likelihood of the ground truth under the predicted distribution. The distribution is created by fitting a kernel density estimate to trajectory samples [8,27]. As KDE measures the negative log likelihood, it is unitless.\nImplementation Details. We follow a leave-one-out strategy used in previous works [6, 13, 14,34], where we train our model on 4 sets of scenes, and evaluate on the remaining set."}, {"title": "5. Results", "content": "Performance. We compare our method against several models, comprising Social Implicit [14], Social GAN [6], Social STGCNN [13], YNet [11], and Agentformer [34]. The ADEmin/FDEmin and KDE results for K=20 model predictions on ETH/UCY are presented in Table 1. Looking at the ADEmin/FDEmin results, our method shows competitive performance compared to previous methods. However, relying solely on Eqs. 14 and 16, which are 'best of K' metrics, for evaluations may in some cases be misleading. While these metrics evaluate how well one of the produced set of K samples falls close to the ground truth, it could also improve merely by a method producing a set of trajectories with a large variance that spans across numerous possible future scenarios, and then simply choosing that trajectory that best matches the ground truth. In practice, during inference, ground truth is unknown, and so such a metric could lead us to a low-confidence prediction.\nFollowing previous works such as [23], to address this issue, we use KDE which penalizes the distributions for both inaccuracy and spread. Unlike the other metrics, KDE considers both the closeness to the true value, as well as the degree of dispersion of a set of hypothesized solutions. In this way, KDE simultaneously rewards accurate and less dispersed distributions, which together we denote as stability. The KDE results for our proposed method in Table 1 show an improvement (i.e. increased stability) over the state-of-the-art and previous works. Additionally, to further address the issue of 'best of K' predictions, we evaluate the methods based on K = 1 and rely on ADE1/FDE1. We present these results in Table 2, where we observe that our method generates stronger predictions in the majority of cases when compared to prior works. From the results presented in Table 1, we notice that Agentformer [34] uses all of the scenes in the benchmark regardless of the number of pedestrians in the scene. In contrast, Social Implicit [14], Social GAN [6], Social STGCNN [13], and YNet [11] train and test their methods on the same benchmark but exclude scenes with only a single pedestrian. To conduct a fair comparison, we retrained all methods excluding Agentformer [34] to include both the single pedestrian and multi-pedestrian scenes. This improved over the original reported results in Social STGCNN [13], Social GAN [6] and Social Implicit [14]. We also evaluate our method on SDD and depict the results in Table 3. Our results outperform the state-of-the-art on this dataset for all three metrics.\nAblation Studies. To investigate the contribution of each component in our proposed method, we perform extensive ablation studies on the ETH/UCY benchmark in Table 4. Specifically, we investigate the effect of five different scenarios: social reconstruction with three types of augmentation (difficulty-based sampling (ours), random sampling, and inverse sampling), social reconstruction without augmentation, and no social reconstruction. For random sampling augmentation, the sequences from the training set are chosen randomly and added to the dataset. For inverse sampling augmentation, we modified Eq. 12 to\n$Count(i) = \\sum_{e=1}^{N_c} I(d_{i,e} < a_{i,e})$. This modification implies selecting the easy sequences in the training data and further augmenting the dataset with these samples. We also"}, {"title": "6. Conclusion", "content": "In this paper, we introduced a pedestrian trajectory fore-caster that uses a social loss to generate socially-informed pseudo-trajectories. Our proposed method uses a reconstructor to generate pseudo-trajectories which are used to augment the learning process. We have shown that injecting these pseudo-trajectories from the partially trained network improves results when compared to augmenting from a similar statically generated offline dataset. Our novel loss function decreases the number of overlaps between predicted pedestrian locations at future timesteps, while keeping the predictions accurate and increasing stability of predictions. Our experiments on standard benchmark datasets and metrics show our method to outperform existing state-of-the-art trajectory prediction methods."}, {"title": "A.1. Pseudocode", "content": "Our proposed method is detailed in Algorithm 1. We train our model for NT epochs initially. During this warm-up period, we also record the values of the loss LF for each sample i and epoch e. After this period, we calculate Count for each sample i and determine their inclusion as a pseudo-trajectory if $Count(i) < D \\times N_c$. Here, Nc denotes the number of epochs where the loss for each sample has been recorded. At the end of warm-up period $N_c = N_T$, while after the warm-up period $N_c = N_{Int}$, where $N_{Int}$ is the epoch interval between pseudo-trajectory generations. To generate the final augmented samples we concatenate the reconstructed past timestep $\\hat{S_p}$ and the social forecaster output trajectory $SF(\\hat{S_p})$. Prior to each augmentation, we erase the previously added trajectories from the training data."}, {"title": "A.2. Training and Architectural Details", "content": "Hyperparameters The hyperparameters that we used to train our models with are depicted in Table A.1. We observed that the Univ dataset was sensitive to overfitting, due to a higher number of test samples compared to the train samples, as well as the difference between the fewer number of crowded scenes in the train partition compared to the larger number in the test partition. To effectively address this, the size (number of parameters) of the model was reduced for this dataset, by reducing the values of the hyperparameters dm and dff, as shown in the first two rows of Table A.1. We used the Steplr scheduler, which has the two hyperparameters of gamma and stepsize as depicted in Table A.1."}, {"title": "A.3. Additional Visualizations and Results", "content": "In this section, we provide visualizations of forecasted trajectories for four examples shown in Figure A.1 to illustrate the effect of social loss on the number of location overlaps. According to the standard protocol, trajectories are included within each scene only for those pedestrians whose trajectories (combining both ground"}]}