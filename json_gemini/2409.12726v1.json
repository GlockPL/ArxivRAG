{"title": "CLOUDY WITH A CHANCE OF ANOMALIES: DYNAMIC GRAPH\nNEURAL NETWORK FOR EARLY DETECTION OF CLOUD\nSERVICES' USER ANOMALIES", "authors": ["Revital Marbel", "Yanir Cohen", "Ran Dubin", "Amit Dvir", "Chen Hajaj"], "abstract": "Ensuring the security of cloud environments is imperative for sustaining organizational growth and\noperational efficiency. As the ubiquity of cloud services continues to rise, the inevitability of cyber\nthreats underscores the importance of preemptive detection. This paper introduces a pioneering\ntime-based embedding approach for Cloud Services Graph-based Anomaly Detection (CS-GAD),\nutilizing a Graph Neural Network (GNN) to discern anomalous user behavior during interactions\nwith cloud services. Our method employs a dynamic tripartite graph representation to encapsulate\nthe evolving interactions among cloud services, users, and their activities over time. Leveraging\nGNN models in each time frame, our approach generates a graph embedding wherein each user is\nassigned a score based on their historical activity, facilitating the identification of unusual behavior.\nResults demonstrate a notable reduction in false positive rates (2-9%) compared to prevailing methods,\ncoupled with a commendable true positive rate (100%). The contributions of this work encompass\nearly detection capabilities, a low false positive rate, an innovative tripartite graph representation\nincorporating action types, the introduction of a new cloud services dataset featuring various user\nattacks, and an open-source implementation for community collaboration in advancing cloud service\nsecurity.", "sections": [{"title": "Introduction", "content": "Detecting anomalous behavior in cloud services is crucial for maintaining a secure environment and mitigating potential\nthreats [1, 2]. Anomalies can manifest in various forms, including user behavior anomalies and network anomalies.\nAnomalies often indicate potential security incidents, such as data breaches, unauthorized access, or malicious activities\n[3]. By detecting anomalous behavior in the early stages, organizations can quickly respond to potential threats and\nmitigate the risks associated with these incidents. Therefore, early detection and prevention can significantly reduce the\nimpact of security breaches and minimize the potential damage to an organization's reputation, finances, and operations.\nAdditionally, detecting anomaly behavior complies with data protection regulations: Organizations are subject to\nvarious data protection regulations, various regulations exist for different purposes and may prevent an organization\nfrom trading in specific regions or dealing with large companies. Detecting and addressing user and network anomalies\nin cloud services is essential to maintaining compliance with these regulations. Failure to detect and respond to security\nincidents can result in significant fines, penalties, and reputational damage. Anomalies may also indicate unauthorized\naccess to sensitive data, attempts to tamper with or alter data, or events that could lead to data loss or unavailability.\nBy detecting and addressing these issues, organizations can maintain the trust of their customers and partners while\nensuring the continuous operation of their cloud services.\nTargeting end-users in order to infiltrate an organization's cloud service has become more and more common [4]. One\nexample of such an attack is abducting a cloud account and utilizing its computing power to mine bitcoins [5]. These\nattacks are hard to detect since there are thousands of API calls every minute, and figuring out that the user abuses\nits free access to the cloud for crypto-hijacking is not straightforward since the user has permission to perform the\ngiven action. Alas, restricting the user's permission to a minimum can slow software development since requesting and\nobtaining permissions is a timely process. Limiting a developer to specific permissions is currently the best practice\nbut it creates a process in which the developer has to repeatedly request the system admin for permissions. As such,\nthis paper provides a method for developers to sustain the system's permissions while ensuring high security. Several\nworks try to tackle the problem of developing auto models for anomaly detection based on machine learning methods\n[6, 7], Fuzzy Time Series Forecast Model [8] and Long Short Term Memory (LSTM) [9]. Common anomaly detection\nmethods mostly focus on detecting abnormal transactions between the user and the cloud but don't consider the user\nbehavior over time [10, 11] or possible connections between users that have similar behavior [12, 3, 1]. Hence, these\nmethods fail to detect slow and abnormal user activity changes.\nOur contribution: This work presents a novel method that models users' interactions with the cloud over time and\nuses a Graph Neural Network-based (GNN-based) model to identify users' behavior changes. The model is based on\nthe assumption that learning the similarity between users' behavior, when accessing a certain cloud or using a certain\nactivity, helps detect anomalies in the early phase of the attack. This study approaches the detection of users and\nnetwork anomaly behavior by representing the network of users, servers, and actions as a dynamic graph. Herein, a\ngraph neural network (GNN) model is used in each time frame to create an embedding vector for each node in the\ngraphs. This vector representation encapsulates the behavior of each component with respect to other components in\nthe graph. The anomaly detection is determined using a custom anomaly score function, which is defined for each node\nin the graph.\nSpecifically, this paper presents the following contribution:\n\u2022 Detecting User Anomalies in Early Stage: We present a novel method for identifying potential malicious\nintent or activity of cloud users. This early detection capability allows for a timely response and prevents\nsecurity breaches or minimizes their impact. Moreover, the early detection mechanism significantly reduces\nthe potential for large-scale damage, reinforcing the system's overall cybersecurity framework and reliability.\n\u2022 Low Rate of False Positives: Another contribution of this work lies in developing a model that boasts a\nsignificantly low rate of false positives. Conventionally, systems have struggled to maintain a balance between\naccurate attack recognition and limiting the occurrence of false alarms. Achieving a lower false positive\nrate ensures that security alerts retain their urgency and are not disregarded due to over-saturation. This"}, {"title": "Related Work", "content": "Security in cloud-based networks has been well-researched. Previous works include protocols for improving group\ndata sharing [13], ensuring the integrity of cloud data and the privacy of sensitive information [14], failures detection\nin the cloud [15, 16] or analyzing network traffic in order to identify anomalies in the traffic generated in and out\nof the cloud [17]. Many infiltration attacks on cloud accounts are done through the end user [18]. This is done with\nsocial engineering (tricking the user into providing information that helps infiltrate the cloud account), or by obtaining\nthe user credentials in another way [19]. End users in most of the cloud accounts can escalate permissions due to\nmisconfigurations and exploits. Thus, recognizing end-user anomaly provides an additional layer of defense mechanism\non top of utilizing the cloud resources, since each cloud provides a kind of record to the API calls performed by all the\nend users [20].\nThe world of Deep Learning (DL) keeps growing, and its use for spotting unusual patterns or anomalies is drawing\na lot of attention. Many Deep Learning techniques were studied for detecting intrusion-based attacks on the cloud,\nThirumalairaj et al.[21] suggested a Support Vector Machine (SVM) classifier to detect infiltrations. Aboueata et al.\n[22] used an additional Artificial Neural Network (ANN) layer to detect intrusions or anomalous behavior in the cloud\nenvironment. Other methods used Auto Encoders for detecting DDoS attack traffic in the cloud [23], Recurrent Neural\nNetwork (RNN) for detecting intrusions in SDN-based Networks [24] or A meta-heuristic assisted model [25] including\nK-means clustering model, centroids selection and hybrid optimization methods for cloud intrusion detection.\nAdding to the strengths of DL, Graph Neural Networks (GNNs) have also shown promise in anomaly detection.\nAnomaly detection using graph representation is a research field covering both theoretical and AI (GNN)- based works.\nTheoretical works include Subgraph-based techniques [26, 27] that aim to identify malicious connections by detecting\nsubstructures within the graph. Community-based methods [28, 29, 30] aim to detect nodes that breach community\nboundaries and Bayesian approaches [31, 32] utilize a learned statistical model to measure anomalies. A spectral graph\nembedding approach is presented by Modell et al. [33] using bipartite graphs and spectral graph embedding. GNNs are\nparticularly suited for handling structured data, such as networks or graphs [34, 35, 36, 37]."}, {"title": "Our Approach", "content": "The problem of detecting anomalies in cloud services networks can be broken down into three main sub-problems:\nGraph representation of the network, designing a model for graph embedding, and defining an anomaly score function\nthat gives a high score for abnormal behavior. The next sections detail our proposed method for every sub-problem,\nending with a whole solution to the problem of user behavior anomaly detection."}, {"title": "Graph Representation", "content": "Inspired by the work of [33], which constructed a bipartite graph of users and resources, we designed an extended\ngraph representation to include the user's activities in the cloud servers. Specifically, we used a dynamic tripartite graph\n[38] representation that consists of three disjoint sets of nodes (users, activities and cloud servers), where edges can\nonly connect nodes from different sets, and not within the same set. In our representation, an edge cannot connect two\nusers or two servers. The edges in this graph represent the connection between the users, actions and services over time.\nFormally, we consider a tripartite dynamic graph $G$ with $n$ user nodes, $m$ server nodes, and $k$ action nodes denoted\nas: $V_u$, $V_s$, and $V_a$, respectively. The edges in $G$: $E \\subset V_u \\times V_a \\times V_s \\times N^+$, represent connections between clients\nand cloud service via action. Therefore, for a user $u$ that accesses service $s$ using action $a$ two edges will be added\nto $G$ so that: $(u, a)$ and $(a, s) \\in E$. Additionally, an edge is assigned with time stamps and weight so that an edge\n$(v_i, v_j, t, w) \\in E$ represents the number of connections $w$ between vertex $v_i$ and $v_j$ prior time $t$. For each time window,\n$T: [t_0, t]$, let $A(T) \\in R$ be the adjacency matrix of the graph in time $t$.\nOur approach sets each entry $A_{uv}^{T}$ to the number of times there has been a connection between vertices $u$ and $v$ prior to\ntime $t$. Such graph representation aims to model the different graph components' activities throughout time."}, {"title": "Node Embedding", "content": "For the structural vector representation of each node in the graph, which also considers the weight of edges, we used the\nnode2vec model [39]. This model is known for effectively capturing and preserving complex network structures in a\nlow-dimensional space. Node2vec uses a random walk approach to generate the neighborhood of a node. This approach\ntakes into account both immediate neighbors and far-off nodes information, creating robust vector embeddings. The\nnode2vec algorithm is efficient and scalable which makes it suitable for large-scale systems representation such as\ncloud services systems."}, {"title": "The Node2vec model embedding", "content": "The node2vec model [39] is an unsupervised learning algorithm that generates continuous feature representations for\nnodes in a graph by preserving the network structure. Node2vec is an adaptation of the word2vec algorithm [40],\noriginally designed for natural language processing to create word embeddings. This model's algorithm consists of two\nmain steps: generating random walks and learning node embeddings using a neural network.\n\u2022 Generating random walks: For a given graph $G(V, E)$, where $V$ is the set of nodes and $E$ is the set of edges,\nthe algorithm performs random walks starting from each node. The random walks aim to explore the local\nand global structure of the graph. In node2vec, the random walks are biased by two hyperparameters, $p$ and $q$,\nwhich control the exploration strategy.\n\u2022 Learning node embeddings using a neural network: Once the random walks are generated, a skip-gram\nneural network is used to learn the node embeddings. The objective is to maximize the probability of observing\neach of the node's neighbors for a given target node based on their co-occurrences in the random walks.\nMathematically, the optimization problem can be defined as follows:\nGiven a target node $u \\in V$ with a set of neighbors $N(u)$, the goal is to maximize the following objective function:\n$\\max f \\sum_{u \\in V}[-log(Z_u) + \\sum_{n \\in N(u)}f(n) \\cdot f(u)] \\qquad(1)$\nWhere: $Z_u$ is defined as a per-node partition that captures the similarity between the target vertex $u$ and the other\nvertices in $V$ under the function $f$. This function is mostly defined as the dot product between the function projection of\ntwo vertices. In the node2vec model, it is defined as follows:\n$Zu = \\sum_{v \\in V} exp f(u) \\cdot f(v) \\qquad(2)$"}, {"title": "Weighted random walks", "content": "A random walk on a graph is a sequence of nodes that are visited by a random process that moves from one node to a\nneighboring node according to some predefined probabilities. A biased random walk is a type of random walk on a\ngraph where the probability of transitioning from the current node to each neighboring node is not uniform but depends\non some predefined rules or biases [39].\nThe weighted random walk method extends the original random walks approach by incorporating edge weights into\ncalculating walk biases during the random walk process. This approach uses the bias-weighted random walk based on\ntwo parameters: $p$ and $q$. These parameters control the likelihood of returning to the previous node (p) or exploring\nnew nodes (q) at each step of the walk. The random walk starts at a given node $v$ and performs a sequence of steps to\ngenerate a random walk of a certain length. At each step of the walk, the algorithm chooses one of the neighbor nodes\nof the current node $u$ to move to with this probability:\n$P(v_u) = \\begin{cases}1/p & \\text{if } (u, v) \\in E \\\\1 & \\text{if } u = v \\\\1/q & \\text{if } (u, v) \\notin E \\end{cases} \\qquad (3)$\nwhere $E$ is the set of edges in the graph.\nEach random walk sequence is used to construct a co-occurrence matrix that captures the pairwise relationships between\nnodes in the graph. The co-occurrence matrix is constructed by counting the number of times that each pair of nodes\nappears in the same random walk sequence. Formally, a co-occurrence matrix $M$ is a square matrix of size nxn, where\nn is the number of nodes in the graph, and each entrance $M_{i,j}$ is defined as the number of times that nodes $i$ and $j$\nappear together in the random walk sequence. This matrix is used as an input to a skip-gram [40, 41] model to learn\nlow-dimensional embeddings of the nodes in the graph.\nOur approach is as follows: after processing the data as a graph of cloud entities, we apply the weighted Node2Vec\nalgorithm to obtain node embeddings. This approach allows us to identify and visualize anomalies in the graph structure\nand gain insights into the underlying system's behavior. The node2vec model provides a vector embedding for each\nnode in the graph (users, activities and cloud servers). Denote the vectors $X_1, ..., X_m \\in R^d$ as embeddings of the\nusers; our approach is to only use the user embeddings. Note that the vector embedding size of the Node2Vec model is\na hyperparameter (typically in the range of 32 to 512). The choice of embedding size depends on various factors, such"}, {"title": "Anomaly Score", "content": "We dynamically assign an anomaly score for each user $u$ in a time $t$ as follows: Let $r$ be the cloud service last approached\nby $u$ and let $R = \\{u : (u,r,t'),t' < t\\}$, denote the set of users who have accessed service $r$ before time $t$. Let $X_u$\nand $X_R$ be the vector embeddings for $u$ and $R$. The anomaly score for $u$ is determined using the Nearest-Neighbor\n(NN) [42] algorithm on the users embeddings in the following equation:\n$\\text{Anomaly Score(u)} = NN(X_u, X_R) \\qquad (4)$\nIn the nearest neighbor algorithm, the distance is quantified utilizing Euclidean similarity. By comparing the obtained\nanomaly score with a pre-established benchmark, one can determine if the recently added edge presents atypical\nproperties.\nFor users that didn't access service $r$ before time $t$ the anomaly score will be 0. This approach aids in monitoring\nnew users accessing the service, as it enables the observation of score fluctuations over time and the identification of\nanomalous conduct by examining relative scores."}, {"title": "Dataset", "content": "Amazon Web Services (AWS) is the largest cloud provider with a market share of 32% [43]. Hence, we decided to use\nAWS as our cloud provider for research. AWS provides the companies that use their cloud services with an activity\ntracking tool called CloudTrail. In order to test our proposed algorithm, we created a new benchmark dataset based\non public CloudTrail records using Summit Route [44]. The Summit Route is a free training site for practicing attack\ntechniques. This platform offers anonymized CloudTrail logs from \"flaws.cloud\". Using this platform, we generated\ncloud services logs that include five common attacks embedded in simulated legitimate traffic. The legitimate traffic was\nsimulated for each user in the cloud service by assigning it normal \"day-to-day\" tasks according to its role and access.\nEvery enterprise that extensively utilizes cloud services from major providers such as AWS, Microsoft, and Google\nhas the capability to monitor and track user activities within the cloud through user activity logs. In this research, we\nfocused on leveraging the CloudTrail API calls recorder as can be seen in [45] and [46], which serves as a foundational\nframework for detecting various attacks on AWS cloud services. CloudTrail, an AWS service specifically designed\nfor auditing purposes, captures a comprehensive record of all user activities within an AWS account. These activities\nencompass a wide range of actions, including instance creation and termination, file uploads, and retrieval of database\nmetadata through API calls which are recorded. Furthermore, CloudTrail provides valuable metadata pertaining to users\nand cloud services, such as timestamps, user IDs, service IDs, and status codes. Our cloudtrail log includes 107116 API\ncalls over 32 days. AWS has over 200 services. In our dataset, we tracked 79 different services. Our dataset contains\n5 attacks; four attacks were performed using one user (each) and one attack was performed using 4 users. In order\nto simulate the attacks we used a sandbox and downloaded the API calls performed by the users who performed the\nattack, and merged them into our dataset. In addition, we added previous legitimate actions to each user. Each attack\noccurs on a different day. However, all of the attacks follow several days of legitimate behavior to simulate cases when\na legitimate user starts behaving in an abnormal way. To the best of our knowledge there isn't a labeled dataset available\nto the public."}, {"title": "Attacks Simulation", "content": "To simulate different kinds of user anomalies, we created five variations of common attacks:\n\u2022 Cryptojacking in a cloud account: Cryptojacking [47, 48] is a common attack where the attacker uses a\nuser's cloud computing resources in order to create a distributed mining workforce. Once the attacker gains\naccess to the user's resources, he launches new instances and installs malicious software on them. This\nmanifests as launching and terminating instances in CloudTrail logs, which generates a massive irregular\namount of RunInstances and TerminateInstances (CloudTrail API calls) in our auditing service. This attack\nmay hold devastating results, such as increasing the cost of the cloud provider during this attack, halting\ncurrent workloads and preventing the use of computing power due to quotas.\n\u2022 Targeted billing attack: In a targeted attack, the attacker's main goal is to take out small to medium-sized\nbusinesses by halting their development. Attacking the company's cloud services is the only way to perform"}, {"title": "Results", "content": "In this section, we present the results of our study. This section describes the details of our framework in Section 5.1,\nevaluates our method by comparing it to a baseline method in Section 5.2, and finally, analyzes the results in Section5.3."}, {"title": "Framework", "content": "The initial stage of our experiment involved classifying the API calls into distinct groups. The categorization resulted in\nthe formation of the subsequent classes. Since there are over 3,000 different events in Cloudtrail, unique to each service,\nwe decided to categorize the events. For example, retrieving sensitive information can be performed on a number of\ncloud services. Consequently, there isn't a need for a new node because they resemble the same action. Our categories\nand description can be seen in Table1.\nUpon categorizing the actions, we divided our dataset into time frames. This was possible because our dataset contains\na timestamp of each API call. We represented each time frame as a graph, as mentioned in Section 3. Afterwards, we\nactivated the weighted node2vec algorithm [39], in order to receive an embedding representing the user activity. The\ngraph embedding encapsulates the users within the graphs as a vector, delineating the associations of each user with a\nspecific action and, in turn, each action with a respective service. We separated the graph into groups of users. Given an\naction a and a user u, $X_a = \\{u \\in X_a \\text{ if } u \\text{ performed a during the given time frame}\\}$, for each group ($X_a$) we graded\neach user ($u \\in X_a$) within this group with an anomaly score by calculating the euclidean distance of the closest user in\nthe same group. Since we created the attacks, we could isolate the users who performed the attacks. We tested our\nmethod for each attack separately."}, {"title": "Baseline", "content": "To evaluate the effectiveness of our method, it is essential to compare it against a reliable baseline. For this purpose,\nwe used the [33] approach as our comparative standard. This approach utilizes a dataset of users accessing a range\nof shared servers. They partitioned their dataset into time-specific segments, much like our own methodology. Their\ngraphical representation consisted of two primary nodes, the user nodes and server nodes, further enriching the data\nanalysis process. In the baseline method, each time frame is represented as a graph such that each user and each server"}, {"title": "Experimental Results", "content": "Our experiment determined the system's merit using the false positive rate as a crucial metric. Indeed, the importance\nof detecting an attack cannot be overstated. However, maintaining a low false positive rate is arguably of equal\nsignificance. A high rate of false positives can breed complacency, leading to a lessened seriousness attributed to alerts.\nThis could culminate in real attacks being overlooked and potentially result in delayed detection or an attack going\ncompletely unnoticed.\nTable 2 shows the false positive rate using our approach and the baseline method. Figure 3\ndemonstrates the threshold detection for both the baseline and our method."}, {"title": "User anomaly score distribution", "content": "In this section, we will look closer at user score distributions of the CS-GAD and baseline methods and understand the\nimportance of a wider spread of user anomaly scores, meaning larger variance. Comparing and analyzing our proposed\nmethod against the baseline is done by comparing the variance of scores across different attacks. Since our goal is to\nensure we can identify anomalies, we confirm that a user with abnormal behavior would have a score with high variance\ncompared to their peers.\nTable 4 presents the variance of both methods for each attack."}, {"title": "Adjusting time frames windows", "content": "Next, we discuss the trade-off between choosing a large time window and decreasing accuracy. Our proposed method is\nsensitive to some external parameters that define its precision level and, consequently, the run time. One significant\nparameter is the choice of time window size for data partitioning, as it determines the resolution at which we observe\nthe dynamic network of cloud calls. Naturally, decreasing resolution enhances the accuracy of the method. In our case,\nit is caused by two reasons: Firstly, the larger our time window, the smaller the relative score of each user compared\nto their peers. This is due to the increased variance between the scores, as explained in Section 5.3.1. Secondly, the\nsmaller the time window, the earlier we can identify attacks, simply because we perform more anomaly score checks\nwithin the same time window.\nHowever, reducing the time window size comes at a cost in terms of higher runtime, as we compute the graph embedding\nmore frequently, which is a computationally expensive process. Therefore, for each dataset, it is beneficial to assess\nthe viability of different time windows in terms of runtime and accuracy and determine the threshold between them.\nNext, we will present our analysis of the selection of different time window sizes for the dataset presented here. In\nour experiments, we used two different time-windows: one-day and one-hour time windows to evaluate our method as\nexplained in Section 5.1. Figure 4 shows the results of our method using different time windows in the lateral movement\nattack. As shown in Figure 4(a), user 24 was overlooked when we used a larger time window. This was primarily due\nto their involvement in a lateral movement attack, a strategy in which multiple users are engaged over time and their\nbehaviors increasingly resemble each other, as they access similar resources. In this example, our method detected the\ninitial attackers but failed to recognize the remaining ones when employing a large time window (one day). Conversely,\nan additional attacker was identified when we utilized a smaller time window (one hour) in Figure 4(b).\nDeciding the time window size is key to increasing the detection rate. After conducting multiple tests, we have found\nthat using a one-hour time window size is optimal for detecting anomalies and accurately differentiating between\nmalicious and legitimate users on datasets of our scale."}, {"title": "Conclusion and Future Work", "content": "Cloud-based information management has become a prevalent field in recent years, with many companies leveraging\ncloud services for their daily data storage and computation needs. In light of this, a problem of increasing external attacks\non these companies has emerged, intending to cause harm or steal cloud computing time for various purposes. These\nattackers exploit the vulnerabilities of individual cloud network users who have a range of access permissions. Such\nattacks often go unnoticed, as many user activity monitors don't typically reveal any deviations in their permissions.\nThis study presents a method that uses a graph representation of user activities in cloud services over time. This method\nemploys a GNN algorithm for graph embedding of these activities and assigns an anomaly score to each user. We have\ndemonstrated that this method is robust in identifying different types of attacks and yields relatively low false positive\nrates compared to a basic method by 2 - 9 percent. Furthermore, we have constructed a benchmark of cloud network\ntraffic that simulates network attacks and normal user behavior. This benchmark is open to all and serves as a valuable\nresource for further research and development in this area.\nIn the future, we intend to evaluate our algorithm on datasets of a larger scale to test its efficacy and scalability. Moreover,\nwe aim to refine our approach by taking into account a range of additional factors, including multiple resource creation\nvia a single API call and the consideration of status codes. Looking ahead, we aim to also build preventive actions\nwithin the cloud system. This could mean limiting user permissions if we spot something odd, effectively putting that\nuser on hold until we can be sure their activity is safe. This way, we're not only identifying problems but taking active\nsteps to stop them, helping to make the cloud environment more secure."}]}