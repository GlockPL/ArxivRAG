{"title": "ADAF: An Artificial Intelligence Data Assimilation Framework for Weather Forecasting", "authors": ["Yanfei Xiang", "Weixin Jin", "Haiyu Dong", "Mingliang Bai", "Zuliang Fang", "Pengcheng Zhao", "Hongyu Sun", "Kit Thambiratnam", "Qi Zhang", "Xiaomeng Huang"], "abstract": "The forecasting skill of numerical weather prediction (NWP) models critically depends on the accurate initial conditions, also known as analysis, provided by data assimilation (DA). Traditional DA methods often face a trade-off between computational cost and accuracy due to complex linear algebra computations and the high dimensionality of the model, especially in nonlinear systems. Moreover, processing massive data in real-time requires substantial computational resources. To address this, we introduce an artificial intelligence-based data assimilation framework (ADAF) to generate high-quality kilometer-scale analysis. This study is the pioneering work using real-world observations from varied locations and multiple sources to verify the AI method's efficacy in DA, including sparse surface weather observations and satellite imagery. We implemented ADAF for four near-surface variables in the Contiguous United States (CONUS). The results indicate that ADAF surpasses the High Resolution Rapid Refresh Data Assimilation System (HRRRDAS) in accuracy by 16% to 33% for near-surface atmospheric conditions, aligning more closely with actual observations, and can effectively reconstruct extreme events, such as tropical cyclone wind fields. Sensitivity experiments reveal that ADAF can generate high-quality analysis even with low-accuracy backgrounds and extremely sparse surface observations. ADAF can assimilate massive observations within a three-hour window at low computational cost, taking about two seconds on an AMD MI200 graphics processing unit (GPU). ADAF has been shown to be efficient and effective in real-world DA, underscoring its potential role in operational weather forecasting.", "sections": [{"title": "Plain Language Summary", "content": "Numerical Weather Prediction (NWP) models require precise initial conditions, known as analysis, to obtain accurate forecasts. This is achieved through data assimilation (DA), which combines different types of observations. Traditional DA methods struggle to balance computational cost and accuracy because of the complex mathematical operations involved and the need to handle a lot of information quickly. To solve this, the Artificial Intelligence-based Data Assimilation Framework (ADAF) was created. ADAF uses a deep learning model to improve the accuracy of analysis, using observations from various sources and locations such as weather stations and satellites. When evaluated in the Contiguous United States (CONUS), ADAF exhibits 16% to 33% higher accuracy than the state-of-the-art DA system in depicting near-surface atmospheric conditions and can reconstruct atmospheric states during severe wind events such as tropical cyclones. It performs well even with limited data. ADAF can process large amounts of data at a low computational cost. This study demonstrates the effectiveness of the AI method in the real-world DA scenario, showing great promise to make weather forecasts more efficient and reliable."}, {"title": "1 Introduction", "content": "The precision of weather forecasts is highly dependent on the quality of the initial conditions provided by data assimilation (DA) (Bauer et al., 2015; Griffith & Nichols, 2000; Hunt et al., 2005). DA methods improve initial conditions by assimilating observations into numerical weather prediction (NWP) models, increasing the reliability of the forecast (Asch et al., 2016). Traditional DA methods are classified into variational, ensemble, and hybrid methods (Bannister, 2017). Variational methods, such as three- and four-dimensional variational assimilation (3D-Var and 4D-Var), minimize a cost function to optimize model states (Janiskov et al., 1999; Rabier et al., 2000; Gauthier et al., 2007; Courtier et al., 1998; Rabier et al., 1998). Ensemble methods, such as the Ensemble Kalman Filter (EnKF) and Particle Filter, use multiple simulations for system state estimation, supporting nonlinear and non-Gaussian models (Buehner et al., 2010b, 2010a; Evensen, 2003). Hybrid methods combine ensemble and variational approaches to max-"}, {"title": "2 Methods", "content": "imize strengths and overcome respective limitations, improving background error covariance matrices and localization (Lee et al., 2022).\nDespite traditional DA methods have evolved, they often face a trade-off between computational cost and accuracy due to complex linear algebra computations and the high dimensionality of the model, especially in nonlinear systems (Boudier et al., 2023; Khaki et al., 2018). In addition, processing substantial amounts of observational data in real time increases resource demand (Eyre et al., 2022). This becomes especially challenging when the model's state variables differ significantly from the observations in nature or resolution. In practice, DA methods often rely on simplifying assumptions such as linearity and Gaussianity or approximations such as tangent linear and adjoint models (Miller et al., 1999; McLaughlin, 2002). These assumptions and approximations can limit the accuracy of DA methods (Kurosawa & Poterjoy, 2021). Moreover, the implementation and maintenance of these sophisticated algorithms require expertise and ongoing optimization, further contributing to the cost. Balancing these factors requires thoughtful algorithm design, model simplification, and leveraging high-performance computing resource.\nMachine learning (ML) techniques are increasingly being utilized to improve the accuracy and efficiency of traditional DA methods (Bonavita et al., 2021; Penny et al., 2022; Sonnewald et al., 2021; Howard et al., 2024; Huang et al., 2024; W. Wang et al., 2024). These efforts focus on creating cost-effective ML models to simplify the formulation of traditional DA methods, thus improving computational feasibility. Several studies have highlighted the connection between DA and ML (Geer, 2021; Abarbanel et al., 2018; Bocquet et al., 2019). In the Bayesian framework, DA and ML are unified in that they both utilize prior knowledge to solve an inverse problem (Sonnewald et al., 2021). Recent progress includes the development of inverse observation operators (Frerix et al., 2021), the estimation of error covariance matrices (Cocucci et al., 2021; Melinc & Zaplotnik, 2024), the combination of traditional DA methods with surrogate AI-based dynamic models (Li et al., 2023; Chattopadhyay et al., 2023), the joint training of surrogate models for the dynamic system along with the DA solver (Legler & Janji, 2022; Arcucci et al., 2021; Fablet et al., 2021), the derivation of tangent-linear and adjoint models (Hatfield et al., 2021; Xiao et al., 2024) and the AI models for assimilating observations (Huang et al., 2024; K. Chen et al., 2024; Xu et al., 2024; Keller & Potthast, 2024; Andrychowicz et al., 2023).\nIdealized scenarios, such as Lorenz attractor, quasi-geostrophic, and barotropic vorticity models, are commonly used in previous studies to test methodological effectiveness (Brajard et al., 2020; Yasuda & Onishi, 2023; Howard et al., 2024). These scenarios are overly simplified, thus misrepresenting the complexities of actual atmospheric and oceanic systems. Operating at broader scales, they miss finer details and fail to capture the unpredictable nature of real-world data, which may cause AI models to excel in experimental settings but struggle in practice. Furthermore, most previous studies are based on pseudo-observations (Xiao et al., 2024; Huang et al., 2024; Y. Wang et al., 2022), which are derived by sampling and adding noise to the reanalysis data. However, pseudo- and real-world observations differ in spatial distribution, variables, and quality. Real-world data are crucial for verifying the efficacy of the AI methods in DA.\nDespite the potential to predict future states directly from observations, practical applications still depend on the initial field for a 24-hour forecast (Andrychowicz et al., 2023). This dependency exists because atmospheric analysis offers a more complete and accurate representation than individual observations (P. Houtekamer & Mitchell, 2001). DA can correct errors and inconsistencies found in raw observations, reducing random noise, and providing a smoother, more reliable representation. In addition, the analysis field fills spatial and temporal gaps between sparse observations, ensuring continuous coverage across regions and time. Thus, the analysis field is indispensable for accurate weather forecasting, serving as initial conditions in both traditional numerical and AI forecasting models (Pathak et al., 2022; Bi et al., 2023; Lam et al., 2023; L. Chen et al., 2023; K. Chen et al., 2023).\nIn this study, we introduce an AI-based data assimilation framework (ADAF) to generate high-quality kilometer-scale analysis. This study is the pioneering work using multisource real-world observations to verify the AI method's efficacy in DA, including sparse surface weather observations and satellite imagery. ADAF can handle surface location-varying observations effortlessly. We implemented ADAF for four near-surface variables in the Contiguous United States (CONUS). The results indicate that ADAF surpasses HRRRDAS in representing near-surface atmospheric conditions, demonstrating closer alignment with real observations. ADAF shows accuracy enhancements of 16% to 33% over RTMA and 5.7% to 7.7% relative to observations. Sensitivity experiments reveal that ADAF can generate high-quality analysis even with low-accuracy backgrounds and extremely sparse surface observations. ADAF can reconstruct tropical cyclone wind fields and assimilate massive observations within a three-hour window at low computational cost, taking about two seconds on an AMD MI200 GPU. ADAF has been proven efficient and effective in real-world DA, highlighting its potential in operational weather forecasting.\nThis paper is structured as follows. In Section 2, we describe the general concept of DA and the proposed AI-based data assimilation framework (ADAF). The pipeline of ADAF and the architecture of the neural network are detailed. In Section 3, we present the data used in this study, the implementation of the experiment, and the evaluation approaches. We assessed performance by grid-to-grid and grid-to-station and compared these results with the state-of-the-art DA system. We also performed sensitivity experiments to verify the robustness of our method. In addition, some cases, including the tropical cyclone, were visualized to demonstrate the effectiveness of our method. Section 4 concludes the paper and describes the future direction of research."}, {"title": "2 Methods", "content": ""}, {"title": "2.1 General Concept", "content": "The Kalman Filter (KF) and its variants (Kalman, 1960; Evensen, 1994) are important DA algorithms to estimate the state of a dynamic system over time. It consists of two iterative steps: predicting the future state and updating the estimate with new data. The prediction step projects the current state estimate forward in time, utilizing the dynamic model that describes the state evolution.\n\\(Xf (t) = M+ [X\u00ba (t \u2212 1)] + h(t)\\)\nwhere \\(Xf(t)\\) denotes the predicted state estimate at time t. \\(M_+\\) is the dynamic model that advances the state from time t\u22121 to t. \\(X\u00ba(t-1)\\) represents the optimal state estimation (also known as analysis) at the previous time t\u22121. h(t) quantifies the model error, indicating the uncertainty in the dynamic model.\nAfter obtaining the predicted state, the KF integrates observations to refine the state estimate during the analysis step. In this process, the Kalman gain is used to balance the uncertainties in the predicted state and observations. The relevant equations are as follows:\n\\(d(t) = Y(t) \u2013 H\u2081 [Xf(t)] + e(t)\\)\n\\(K(t) = Pf (t)H [H\u2081Pf(t)H + R(t)]^{-1}\\)\n\\(Xd(t) = K(t)d(t)\\)\n\\(X\u00ba(t) = Xf (t) + Xd(t)\\)\nwhere d(t) is the innovation vector at time t, indicating the difference between observations and the predicted state. Y(t) is observations. \\(H_t\\) is the observation operator that maps the model's state variables to the observation space. K(t) is the Kalman gain. \\(P^f (t)\\) is the forecast error covariance matrix indicating uncertainties in the system's predicted state. R(t) is the observation error covariance matrix representing the uncertainties in observations. e(t) represents the observation noise.\nThe product \\(Xd(t) = K(t)d(t)\\) computes the adjustment that is used to refine the forecast state \\(Xf(t)\\). The optimal state \\(X\u00ba(t)\\), known as the analysis, is obtained by adding the product to the predicted state to better align with the new observation Y(t). Despite this, computing this product poses certain difficulties. A key issue is the precise determination of the Kalman gain K(t), which depends on accurately estimating the forecast and observation error covariance matrices (\\(P^f\\) and R). This is challenging because of their dynamic properties and the computational demands of matrix operations, particularly in high-dimensional contexts (Furrer & Bengtsson, 2007; Zhen & Harlim, 2015; X. Liang et al., 2012; Furrer & Bengtsson, 2007). Additionally, computing the innovation vector d(t) is crucial and can be hindered by nonlinear observation operators and the quality and sparsity of observations (Tandeo et al., 2020; Carri et al., 2019).\nTo overcome the computational challenges in traditional EnKF methods, our research aims to use a neural network \\(F_{NN}\\) to approximate the product K(t)d(t), offering a data-driven substitute for conventional DA methods, which can be formulated as follows:\n\\(F_{NN} (Xf (t), Y (t); 0) = X\u00b2(t)\\)\n\\(X\u00ba(t) = X\u00a3 (t) + F\u2116\u2116(Xf(t), Y(t); 0)\\)\nwhere \u03b8 denotes the model parameters of \\(F_{NN}\\)."}, {"title": "2.2 ADAF: AI-based Data Assimilation Framework", "content": "Figure 1(a) illustrates an overview of ADAF. The inputs encompass three types of data: observations, background, and topography. Observations include surface weather observations \\(Y^o\\) and satellite imagery \\(Y^s\\) within the T-hour window. The background \\(X^f (t)\\) derives from the 1-hour forecast at time t. The output of the neural network is the analysis \\(X^a(t)\\) at time t. Various multimodal data, including specific humidity, topography, and radiation, often serve as indirect proxies for target states like air temperature. Capturing these relationships is challenging due to their varying spatial coverage and dimensions. Although a mapping function, such as the observation operator that bridges heterogeneous state-observation spaces, is available, imperfect knowledge can amplify errors in high-dimensional states, necessitating further calibrations to correct biases (J. Liang et al., 2023; Qu et al., 2024).\nDeep learning overcomes this challenge by learning a function that maps both states and observations into a unified, reduced-order latent space. In this study, we used an encoder that inputs a concatenation of background, topography, and each observation modality along the channels. The decoder then maps the latent features extracted via the encoder to the state space. Subsequently, the reconstruction module reconstructs the adjustment \\(Xd(t)\\). Finally, this adjustment is added to the background \\(X\u0192 (t)\\), resulting in the analysis \\(X^a(t)\\).\nFirst, we used an encoder to extract latent features from the inputs. This procedure is depicted in Equation 8, which uses a 2D convolution layer (Conv2D) with a kernel size of 3 x 3.\n\\(Fo = Henc(Y\u00b0, Y, X\u00a3 (t), Z)\\)\nWhere \\(H_{enc}\\) is the function of encoder. \\(F_0\\) are the latent features. \\(Y^o = {Y^o(t-i)}, i = 0,1,..., T\\) and \\(Y^o = {Y^$(t \u2212 i)},i = 0,1,..., T\\) are the surface weather observations and satellite radiation within T-hour window. Z denotes topography. \\(X^\u0192 (t)\\) represents the background.\nThe latent features extracted by the encoder are fed into the decoder \\(H_{dec}\\), as depicted in the following equations:\n\\(F_{DF} = Hdec(Fo)\\)\nwhere \\(F_0\\) denotes the combined features. \\(F_{DF}\\) denotes the deep features decoded by the decoder \\(H_{dec}(\\cdot)\\). The decoder uses residual Swin transformer blocks (RSTB) (J. Liang et al., 2021) and a 2D convolution layer to learn from the fusion features of the observations and the background, to capture high-frequency information, as illustrated in Figure 1(c). Employing a long skip connection allows the model to transmit low-frequency information directly to the reconstruction module. This enables the module to focus on high-frequency data, thus stabilizing the training process. The intermediate features \\(F_1, F_2, F_3\\) and the final deep feature \\(F_{DF}\\) are decoded sequentially as follows:\n\\(Fi = HRSTB (Fi\u22121), i = 1,2,3\\)\n\\(FDF = HConv(F3) + Fo\\)\nwhere \\(H_{RSTB}(\\cdot)\\) indicates the ith RSTB and \\(H_{Conv}(\\cdot)\\) is the final convolutional layer. \\(F_{DF}\\) is a feature map with 64 channels, which is forwarded to the reconstruction module. The RSTB comprises Swin Transformer layers (STL) and convolutional layers, as illustrated in Figure 1(c). The residual connection offers an identity-based linkage between various blocks and the reconstruction module, facilitating the aggregation of features at different levels. STL (Liu et al., 2021) includes multi-head self-attention (MSA) (Vaswani et al., 2023), layer normalization (LayerNorm), fully connected layers (FC), and a residual connection, as shown in Figure 1(c).\nThe reconstruction module is used to reconstruct the adjustment of states by combining features of the encoder and decoder, as described in Equation 12. This module includes pixel shuffle layers (Shi et al., 2016) and convolution layers with a kernel size of 3 \u00d7 3, as illustrated in Figure 1(b).\n\\(Xd(t) = Hrec(Fo + FDF)\\)\nwhere \\(H_{rec}(\\cdot)\\) is the function of the reconstruction module. \\(X^d(t)\\) is the adjustment. Finally, the analysis is produced by adding adjustment and background using the following equation:\n\\(X\u00ba(t) = Xd(t) + X\u00a3 (t)\\)"}, {"title": "3 Experiments", "content": ""}, {"title": "3.1 Data Preparation", "content": ""}, {"title": "3.1.1 Types of Datasets", "content": "The data used in this study can be grouped into four categories: forecast, analysis, observations, and static topography data. Forecast data is generated by High Resolution Rapid Refresh (HRRR) (Dowell et al., 2022), a 3 km resolution NWP model developed by the National Oceanic and Atmospheric Administration (NOAA). HRRRv4 is the latest version, released in December 2020, exhibits a significant improvement in DA using the HRRR 3-km data assimilation system (HRRRDAS). The geopotential height from the European Centre for Medium-Range Weather Forecasts Reanalysis v5 (ERA5) (Hersbach et al., 2019) is used as the topography.\nThe analysis generated by HRRRDAS is used as initial conditions in HRRRv4. In HRRRDAS, the DA process uses the Ensemble Kalman Filter (EnKF) to assimilate traditional observations, satellite data, and radar reflectivity. More details can be found in Appendix A. Another set of analysis data is sourced from the Real-Time Mesoscale Analysis (RTMA) (Pondeca et al., 2011), which offers a high spatial and temporal resolution analysis of near-surface weather conditions. RTMA provides hourly analysis with a resolution of 2.5 km in the CONUS.\nWe used two types of observations: surface weather observations and satellite imagery. Surface weather observations are sourced from WeatherReal-Synoptic (Jin et al., 2024), which gives quality control to station measurements collected by Synoptic Data. For more details, please visit the Synoptic Data official website (Synoptic, 2024). The"}, {"title": "3.1.2 Data Processing", "content": "average number of observations at each hour is illustrated in Figure B1. And the spatial distribution is shown in Figure B2. Satellite imagery is obtained from Geostationary Operational Environmental Satellite-16 (GOES-16) (Tan et al., 2019). The Advanced Baseline Imager (ABI) on the satellite provides high spatial and temporal resolution in multiple spectral bands, comprising wavelengths from visible to infrared with a spatial resolution of approximately 1 km and a temporal resolution of approximately 15 minutes. This study utilized 2, 7, 10, and 14 bands with central shortwaves of 0.64, 3.9, 7.3, and 11.2 \u00b5m, associated with winds, clouds, water vapor, and rainfall.\nOur research focuses on the CONUS, which is bounded by 24.70\u00b0 to 50.25\u00b0N, 64.00\u00b0 to 128.00\u00b0W. Near-surface meteorological variables are crucial for understanding and predicting various environmental and climatic processes that directly impact human activities. We focused on four near-surface meteorological variables, including 2 meter temperature (T2M), specific humidity (Q), 10 meter u-component of wind (U10) and 10 meter v-component of wind (V10). All data were regularized to grids of size 512\u00d71280 with a spatial resolution of 0.05 \u00d7 0.05\u00b0. The surface weather observations were mapped to the nearest grids. The training dataset of the AI model consists of input-target pairs. Table 1 provides a summary of the input and target datasets used in our study. The inputs include surface weather observations within a 3-hour window, GOES-16 satellite imagery within a 3-hour window, background from HRRR forecast, and topography. The target combines RTMA with surface weather observations, using observations at measured locations and RTMA for locations without observations. We used the difference between the background and target as the label during the training phase."}, {"title": "3.2 Implementation", "content": "The data used in this study cover the period from October 2020 to September 2023. The data sets for training, validation and testing were split without any temporal overlap and ordered as follows: training data cover October 2020 to September 2021, validation data cover October 2021 to September 2022, and test data cover October 2022 to September 2023. To normalize the input and target, the max-min normalization was used. Given the noise in real-world data, the L1 loss remains relatively unaffected by minor data variations, resulting in more stable model predictions (N. Zhang et al., 2020; Barron, 2019). This stability is crucial in real-world applications. Therefore, we used the"}, {"title": "3.3 Evaluation", "content": "L1 loss function to minimize the difference between ADAF's output and the target, as defined below:\n\\(L1 = \\frac{1}{C \\times H \\times W} \\sum_{c=1}^{C} \\sum_{i=1}^{H} \\sum_{j=1}^{W} |\\hat{Xd}_{c,i,j} - Xd_{c,i,j}|\\)\nwhere Xd represents the target adjustment and \\(\\hat{X}d\\) denotes the ADAF's output. C, H, and W represent the number of variables and the number of points on the latitude and longitude grids, respectively.\nThe model was trained on four AMD MI200 GPUs for a total of 750 epochs, with batch size = 4 per GPU. The entire model training process lasted approximately 36 hours. The AdamW optimizer (Loshchilov & Hutter, 2019) was used with parameters \u03b2\u2081 = 0.9, \u03b22 = 0.999 and a weight decay coefficient of 1\u00d710\u22125. We implement the ReduceLROnPlateau scheduling method (PyTorch: ReduceLROnPlateau, 2024) to dynamically adjust the learning rate. This approach reduces the learning rate when the chosen evaluation metric does not show improvement after a set period of patience. After training, ADAF can perform data assimilation on a single AMD MI200 GPU in approximately 2 seconds.\nTo evaluate the performance of our proposed ADAF, we generate analysis at 00:00, 06:00, 12:00, and 18:00 UTC in the test dataset. Our study uses two evaluation approaches: grid-to-grid and grid-to-station evaluation. The grid-to-grid evaluation involves a comparison between ADAF analysis and RTMA's gridded analysis. For grid-to-station evaluation, ADAF analysis is compared with surface weather observations. Gridded analysis data and sparse surface weather observations play different roles and originate from different methods. Analysis data is utilized to initialize models and forecasts, whereas surface weather observations offer localized atmospheric conditions in real-time. Analysis data relies heavily on sophisticated mathematical modeling and DA methods to create a synthesized view of the atmosphere, while surface weather observations rely mainly based on direct measurements and quality control. In the analysis, the grid value is the average value of each grid, whereas surface weather observations mean measurements specific to a local location. Therefore, analysis data and surface observations can serve as ground truth from different perspectives. Analysis data provide a synthesized and model-based view of the atmosphere, and surface weather observations offer direct and localized measurements."}, {"title": "3.4 Results", "content": ""}, {"title": "3.4.1 Accuracy of ADAF analysis", "content": "To demonstrate the advantages of ADAF over traditional DA methods, we evaluated the accuracy of the analysis generated by ADAF and HRRRDAS. HRRRDAS is the state-of-art DA system used in HRRRv4. It uses the ensemble Kalman filter (EnKF) (P. L. Houtekamer & Zhang, 2016), specifically the ensemble square root filter (EnSRF) (Tippett et al., 2003), to integrate a 1-hour HRRR forecast and observations. HRRRDAS utilizes observations from different sources, such as surface measurements, GOES-16 satellite imagery, and radar reflectivity data from NOAA's Multi-Radar Multi-Sensor (MRMS) project. Further information is available in Section Appendix A. Similarly to HRRRDAS, we performed DA using the proposed ADAF by combining a 1-hour HRRR forecast and observations, including surface weather observations from Synoptic and four channels of satellite imagery from GOES-16. The main difference between HRRRDAS and ADAF is their DA algorithms and observations. HRRRDAS uses EnKF, while ADAF uses a neural network (see Section 2.2). And HRRRDAS assimilate three types of observation: surface measurements, 16 channels of GOES-16 satellite imagery, and radar reflectivity data. ADAF only uses two types of observation: four channels of GOES-16 satellite imagery and surface weather observations. Further information about the data is provided in Section 3.1. It is important to note that more observation types are allowed to be assimilated in ADAF. Our study only validates the feasibility of the AI method to assimilate multisource observations. We apply ADAF to generate the analysis for four near-surface variables: T2M, Q, U10 and V10 at 00:00, 06:00, 12:00, and 18:00 UTC. A year-long data assimilation was performed on the test dataset, covering October 2022 to September 2023. The domain-averaged metrics were computed using two evaluation approaches mentioned in Section 3.3.\nIn grid-to-station validation, we compared ADAF analysis, HRRRDAS analysis, and RTMA with surface weather observations using cross-validation techniques. In every DA process, approximately 10% of surface observations (around 1600 stations) were randomly withheld from ADAF's input. Figure 2 illustrates the errors in ADAF analysis, HRRRDAS analysis, and RTMA. The ADAF analysis shows a lower mean RMSE compared to the HRRRDAS analysis: 1.67, 1.14, 1.81, and 1.83 for T2M, Q, U10, and V10, respectively, versus 1.81, 1.21, 1.96, and 1.98 from HRRRDAS, with improvements of 7.7%, 5.7%, 7.7%, and 7.6%. The ADAF analysis demonstrates a higher CORR compared to HRRRDAS, indicating a closer alignment with observations. The CORR values for U10 and V10 are lower than those for T2M and Q, highlighting the challenge of"}, {"title": "3.4.2 Sensitive to Observation Sparsity", "content": "reconstructing the wind state in DA accurately. This challenge stems from the inherent complexity of atmospheric dynamics, which is due to nonlinear interactions among different atmospheric components. Overall, the results demonstrate that the ADAF analysis is more closely aligned with actual observations than the HRRRDAS analysis, indicating that ADAF can effectively extrapolate sparse observations to provide reliable data for unobserved areas. Furthermore, ADAF can process surface observations with varied locations without effort. This is because the observations' locations in the input are not fixed during the training and testing phases. This feature increases ADAF's suitability for real-world conditions, where measurement's location often vary.\nThe errors in the ADAF analysis are higher than those in RTMA, possibly because RTMA utilized all observations, whereas ADAF used only a subset. RTMA employs the two-dimensional variational analysis method (2D-Var) (Pondeca et al., 2011), which requires careful tuning of error covariance parameters for accurate results, particularly with low-quality background fields (Vogelzang et al., 2009). However, ADAF can be easily adapted to low-accuracy backgrounds without careful adjustments, as shown in Section 3.4.3. In 2D-Var, computational cost is significantly influenced by both model resolution and data volume, with higher resolution enhancing DA performance but leading to a cubic increase in computational cost (Barth\u00e9l\u00e9my et al., 2022; Yasuda & Onishi, 2023). On the other hand, ADAF remains mostly unaffected by the volume of data, as the data are pre-processed into a tensor for efficient GPU processing (Q. Zhang et al., 2016).\nIn grid-to-grid validation, we evaluated the errors of the ADAF analysis and HRRRDAS analysis compared to RTMA, as shown in Figure 3. The ADAF analysis shows reduced errors compared to the HRRRDAS analysis, presenting mean RMSE values of 0.70, 0.48, 0.69, and 0.70 for T2M, Q, U10, and V10, respectively, versus 0.86, 0.64, 1.04, and 1.03\nto assess ADAF's sensitivity to sparse surface observations, we tested it with different observation sparsity levels. The sparsity of observation is represented as the observation grid ratio, as defined in Equation 18. The ratio varied between 0.5% and 2.2% in our study. NaNs at grid points without observations were substituted with zeros.\n\\(Observation grid ratio = \\frac{total number of observation grid points}{total number of grid points (= 512 \\times 1280)}\\)\nFigure 5 illustrates the relationship between observation sparsity and errors in ADAF analysis. The errors are quantified by the domain-averaged RMSE and CORR, compared to RTMA. The ADAF analysis (depicted with blue lines) generally shows lower RMSE and higher CORR compared to the HRRRDAS analysis (depicted with red lines) at various observation sparsity levels. The HRRRDAS errors are constant because the sparsity of observations in the HRRRDAS analysis has not changed. The results show that the ADAF analysis achieves greater accuracy than the HRRRDAS analysis, which uses EnKF, even when observations are highly sparse (with an observation grid ratio of 0.5%). The errors in the ADAF analysis on land are smaller than those in the HRRRDAS analysis, mainly because that surface observations on land provide valuable information to the land state reconstruction. As surface observations become sparser, the error correspondingly increases, suggesting that a higher density of observations can enhance the accuracy of the analysis. Furthermore, ADAF's computational cost remains unchanged even as the number of observations grows, because the data are pre-processed into a tensor for efficient GPU processing. In summary, ADAF is robust to generating high-quality"}, {"title": "3.4.3 Sensitive to Background Accuracy", "content": "analysis even when observations are extremely sparse, indicating that the proposed ADAF method can transfer available observations into unobserved regions.\nTo assess the impact of background accuracy on ADAF, we performed a sensitivity analysis using backgrounds derived from different lead times. The accuracy of the background declines as the lead time increases, as the quality of weather forecasts deteriorates with a longer lead time due to the chaotic nature of atmospheric processes (Ramage, 1976; Chantry et al., 2019). We train a model for each lead time. Figure 6 shows the relationship between lead time and analysis errors (represented as RMSE and CORR), which are compared to RTMA. The results indicate that ADAF analysis outperforms HRRRDAS analysis, generated via EnKF, with reduced RMSE and increased CORR for most lead times. Although HRRRDAS errors remain constant with a 1-hour forecast as background, ADAF demonstrates superior accuracy over HRRRDAS under the same conditions. ADAF analysis errors increase when background with longer lead times is used, highlighting the importance of background accuracy for analysis generation. Notably, these errors rise substantially for longer lead time backgrounds in U10 and V10, suggesting wind field reconstruction heavily depends on background accuracy. In summary, ADAF is capable of producing high-quality analysis even when utilizing backgrounds with low accuracy, thus enhancing the timeliness of the DA process."}, {"title": "3.4.4 Cases Visualization", "content": "To assess ADAF's capacity to reconstruct atmospheric state during extreme wind events", "06": 0}]}