{"title": "Automating Legal Concept Interpretation with LLMs:\nRetrieval, Generation, and Evaluation", "authors": ["Kangcheng Luo", "Quzhe Huang", "Cong Jiang", "Yansong Feng"], "abstract": "Legal articles often include vague concepts to\nadapt to the ever-changing society. Providing\ndetailed interpretations of these concepts is a\ncritical task for legal practitioners, which re-\nquires meticulous and professional annotations\nby legal experts, admittedly time-consuming\nand expensive to collect at scale. In this paper,\nwe introduce a novel retrieval-augmented gen-\neration framework, ATRI, for AuTomatically\nRetrieving relevant information from past ju-\ndicial precedents and Interpreting vague legal\nconcepts. We further propose a new bench-\nmark, Legal Concept Entailment, to automate\nthe evaluation of generated concept interpreta-\ntions without expert involvement. Automatic\nevaluations indicate that our generated inter-\npretations can effectively assist large language\nmodels (LLMs) in understanding vague legal\nconcepts. Multi-faceted evaluations by legal\nexperts indicate that the quality of our concept\ninterpretations is comparable to those written\nby human experts. Our work has strong impli-\ncations for leveraging LLMs to support legal\npractitioners in interpreting vague legal con-\ncepts and beyond.", "sections": [{"title": "1 Introduction", "content": "When legislative bodies enact laws, in order to\nmake relatively fixed legal texts more applicable\nto an ever-changing society, the legal texts often\ncontain some vague (Endicott, 2000) and open-\ntextured (Hart and Green, 2012) concepts. For\nexample, in the Criminal Law of the People's Re-\npublic of China, the article corresponding to the\ncrime of Theft states: \"...\u5165\u6237\u76d7\u7a83...\u7684,\u5904\u4e09\u5e74\n\u4ee5\u4e0b\u6709\u671f\u5f92\u5211...\" (\"Whoever ... enter a dwelling\nto steal shall be sentenced to imprisonment of\nnot more than 3 years, ...\"). The term \"dwelling\"\nis a vague concept, and the article does not pro-\nvide a clear definition of what kind of places are"}, {"title": "3 Preliminaries", "content": "The basic method of legal experts for writing le-\ngal interpretation involves extensively reading a\nlarge volume of previous legal cases, books, papers,\nand other materials related to specific legal articles.\nThey then provide detailed interpretations of the\nspecific applications of these articles, especially\nconcerning the vague concepts within them. Such\nvague concepts are prevalent in legal articles, and\ntheir boundaries are not clear or well-defined. In\nthis work, we focus on interpreting vague concepts\nwithin legal articles.\nWe introduce a challenging task, Vague Legal\nConcept Interpretation, which aims to provide inter-\npretations for vague concepts in articles based on\npast cases. Formally, we define the task of Vague\nLegal Concept Interpretation as follows. Given a\nlegal article a and a vague concept c within it, our\ntask is to generate a legal interpretation e for the\nconcept c, detailing the circumstances under which\nc applies or not."}, {"title": "4 Legal Concept Interpreter", "content": "In order to obtain interpretations of vague legal\nconcepts automatically, we design a framework,\nATRI. Following the method of legal experts, our\nframework summarizes the specific applications of\nthe vague concept in judicial practice based on rel-\nevant case judgments. Specifically, our framework\nis composed of three parts (Figure 1): (1) Retrieve:\nRetrieve case judgments that mention the concept.\n(2) Filter&Extract: Select cases where the con-\ncept is analyzed in detail within the judgments, and"}, {"title": "4.1 Retrieving case judgments", "content": "To find case judgments that might be helpful to in-\nterpret the vague concept, the first step is to retrieve\nthe cases that mention the concept. Formally, given\na vague concept c and the article a that the concept\nbelongs to, we will first find all the case judgments\ncited the Number of article a from a database that\nstores previous case judgments. Then we will re-\ntrieve the cases that mention the concept c through\nexact string matching and all of the retrieved cases\nform the set Do.\nThe case judgment database is constructed by\ncollecting legal case judgments published on China\nJudgments Online\u00b9. This is the largest public case\njudgment platform in China, which is the official\nwebsite hosted by the Supreme People's Court of\nChina. Our database includes information from\nthe years 1985 to 2021 available on the website,\nensuring the comprehensiveness of the source.\nA case judgment typically contains 5 parts:\nHeader, Facts, Court view, Verdict and Conclusion\n2. Among them, the court view section explains\nthe legal rationale and basis for the judgment. We\nadopt a retrieval approach based on exact string\nmatching to check whether the vague concept ap-\npears in the court view section of a case judgment.\nWe do not use dense retrieval or other fuzzy match-\ning methods for retrieving because legal terminol-"}, {"title": "4.2 Filtering relevant case judgments and\nExtracting reasons", "content": "In this step, we aim to filter relevant cases from\nthe cases that just mention the concept and extract\nreasons for the determination of the vague concept\nin these cases. We define relevant cases of a con-\ncept as those cases in which the court view section\nprovides a detailed reason why the vague concept\napplies to the case or not. We want to filter rele-\nvant cases because not all judgments that mention\na concept are valuable for generating interpretation\nof the concept. Some cases are relatively simple\nor straightforward, and judges may not provide de-\ntailed discussions of the concept in the judgment\u00b3.\nWe first use LLMs to filter the relevant cases\nfrom Do. Taking the court view as input, we first\nrequire the LLM to determine whether it provides\na detailed reason, r, for why the concept c applies\nor not. If so, then extract this reason. The reason\nr should be a combination of original sentences\nfrom the court view. Next, we prompt the LLM\nto determine whether the concept applies to the\ncase based on the court view, yielding a binary\nlabel l (Yes/No). The prompt we use for filtering is\nshown in Appendix F. From this process, we obtain\na refined case set D\u2081 containing cases that discuss\nthe concept in detail in the court view."}, {"title": "4.3 Generating Concept Interpretations", "content": "After collecting the relevant cases and reasons, this\nstep leverages an LLM to summarize these past\nexperiences and generate an interpretation of the\nvague concept.\nAn interpretation should elaborate on how the\nvague concept has been explained or applied by the\ncourts. We designed the interpretation to consist of\nthree main components: Analysis, which explains\nthe basic meaning of the concept and its applica-\nbility conditions; Case Examples, which provides\nrepresentative positive and negative cases from past\nrulings; and Judicial Discretion, which offers cri-\nteria to guide judges in flexibly applying vague\nconcepts based on case specifics. (see Appendix E)\nThe input to the LLM for generating interpre-\ntations consists of the following components: (1)\nlegal article a, (2) vague concept c (3) reason set R\n(4) interpretation example eo. We require the out-\nput interpretation to follow the same format as the\ninterpretation example eo, to ensure a consistent\nand standardized format. (see Appendix E.2)"}, {"title": "5 Is generated interpretation reliable?", "content": "To evaluate the quality of the generated interpreta-\ntions, previous work has predominantly relied on\nhuman evaluation. We also conducted a human\nevaluation, as detailed in Section 7. However, hu-\nman evaluation is inherently subjective, and we aim\nto assess the quality of the generated concepts in\na more objective and quantitative manner. There-\nfore, we propose a new benchmark, Legal Concept\nEntailment, which is reproducible and enables an\nobjective comparison of interpretations generated"}, {"title": "5.1 Legal Concept Entailment Task", "content": "If an interpretation of a concept is good, it should\nassist humans or models in better determining\nwhether the concept applies to an unseen case and\nin providing the corresponding reasoning. Based\non this assumption, we design the Legal Concept\nEntailment task. Given the fact description of a\ncase relevant to the vague concept, the task is to\ndetermine whether the concept applies and provide\na reason. We use a fixed LLM, to perform this\nclassification task. By incorporating interpretations\nfrom different sources into the input, we can ob-\nserve changes in the classification accuracy, which\nallows us to assess the quality of the interpretations.\nThe more accurate the classification, the higher the\nquality of the interpretation.\nFormally, this task is divided into two parts. The\nfirst part is a binary classification task: for a vague\nconcept c in a legal article a, given the fact de-\nscription f of an unseen relevant case d, the out-\nput should be a binary label \u00ce (Yes/No), indicating\nwhether c applies to the fact f. The second part is\na generation task, which requires generating a rea-\nson \u00ee to explain the prediction result of the binary\nclassification task. An example is shown in Fig 2."}, {"title": "5.2 Dataset", "content": "We recruited a legal expert with substantial judicial\nexperience to identify frequently encountered le-\ngal articles and vague concepts in judicial practice.\nSpecifically, we selected articles cited in the case\ndatabase by more than 10,000 cases, resulting in a\ntotal of 14 articles and 16 concepts.\nFor each concept, we collected relevant cases,\nwhich are those where judges provided detailed dis-\ncussions of the concept in their rulings. These cases"}, {"title": "5.3 Evaluation Metrics", "content": "For the classification task, we use Accuracy (Acc.),\nMacro Precision (Ma-P), Macro Recall (Ma-R),\nand Macro F1 (Ma-F) as the evaluation metrics.\nThe reason for using macro average is that the num-\nber of cases relevant to each concept is imbalanced,\nand we want to give equal weight to all classes.\nFor the reason generation task, we use a GPT-\n4-based evaluator to evaluate the consistency be-\ntween the generated reason \u00ee and the gold reason r\nfrom the court view, following previous LLM-as-a-\nJudge based methods (Zheng et al., 2023; Zhu et al.,\n2023). We require the GPT-4 to rate from 1 to 10\nfor the consistency between the r and r, with higher\nscores indicating greater consistency. Specifically,\nwe use gpt-40-2024-08-06 (Achiam et al., 2023)\nand set the temperature to 0. The prompt we use\nfor evaluation is in Appendix F.1.5. Note that, if\nthe classification result is incorrect, the consistency\nscore is directly set to 0."}, {"title": "5.4 Method", "content": "This section introduces how to perform the Legal\nConcept Entailment task with the incorporation of\nconcept interpretations. First, we generate the in-\nterpretations for the concepts following the method\ndescribed in Section 4. To prevent data leakage,\nthe cases used for generating interpretations do not\noverlap with the test set. Next, we prompt the LLM"}, {"title": "5.5 Baselines", "content": "We compare our method with two baseline cate-\ngories: \"w/o Interpretation,\" where the LLM re-\nlies solely on its internal knowledge for the Legal\nConcept Entailment Task, and \"w/ Interpretation,\"\nwhere the LLM is provided with an interpretation\nof the vague concept for the task.\nw/o Interpretation (1) Random: We use ran-\ndom guessing of \"Yes\" or \"No\" as a weak baseline.\n(2) Zero-shot (ZS): The LLM performs the Le-\ngal Concept Entailment task in a zero-shot setting.\nSpecifically, only the legal article a, the vague con-\ncept c, and the fact description f of the relevant\ncase d are provided as input. (Shown in the left half\nof Figure 2.) (3) Chain-of-Thought (Kojima et al.,\n2022): Using the prompt \"Let's think step by step\"\nto encourage the LLM to generate intermediate\nsteps and improve its reasoning.\nw/ Interpretation We introduced concept inter-\npretations generated by different approaches, in-\ncluding human-written and model-generated inter-\npretations, to compare them with our method: (1)\nJudicial Interpretation (JI): We recruit a legal\nexpert to retrieve judicial interpretations for the\nconcept c. Judicial interpretations are explanations\nissued by the Supreme People's Court on how to\nspecifically apply the law. (2) Expert interpreta-\ntion (EI): We collect legal professionals' interpre-\ntations for the concept c from FaXin and WeChat\nofficial accounts of major law firms, which are\nof high quality. (3) LLM Direct Interpretation\n(DI) : Without providing relevant cases, the LLM\ngenerates an interpretation of the vague concept c\ndirectly based on its internal knowledge."}, {"title": "5.6 Result", "content": "We report the performance of our method and all\nbaselines on Legal Concept Entailment Task in"}, {"title": "5.6.1 Classification Task", "content": "For the classification task, we found that:\n(1) LLMs possess some level of discriminative\nability. The performance of \"w/o Interpretation\"\nsurpasses that of random guessing. Besides, the\nperformance of CoT surpasses that of Zero-shot,\ndemonstrating that step-by-step reasoning is bene-\nficial for the Legal Concept Entailment Task.\n(2) Interpretations for vague concepts are valu-\nable. The performance of \"w/ Interpretation\" sig-\nnificantly outperforms that of \"w/o Interpretation\".\n\"w/ Direct Interpretation\" shows that LLMs can\nleverage their extensive internal knowledge to rea-\nson about vague concepts and generate useful legal\nconcept interpretations. \"w/ Judicial Interpreta-\ntion\" falls short of \"w/ Direct Interpretation\". We\nattribute this to the relatively simple explanations\nprovided in judicial interpretations, which lack the\ndepth required to guide LLMs in evaluating the\napplicability of vague concepts to specific cases.\nThe performance of \"w/ Expert Interpretation\" is\ninferior to ATRI. We attribute this to the fact that\nexpert-written interpretations are often overly ab-\nstract and detailed, which results in poorer readabil-\nity. We will discuss this in detail during the human\nevaluation (Sec 7).\n(3) Utilizing relevant cases is necessary. ATRI\noutperforms \"w/ Direct Interpretation\", demonstrat-\ning the effectiveness of generating interpretations\nwith reference to relevant cases."}, {"title": "5.6.2 Reason Generation Task", "content": "For the reason generation task, we found that: (1)\nThe consistency score of ATRI is the highest, show-\ning significant improvement over both \"w/o Inter-"}, {"title": "5.7 Case study", "content": "Figure 3 presents an example of different meth-\nods applied to the Legal Concept Entailment Task.\nAs demonstrated in the case, our framework accu-\nrately understands the applicability conditions of\n\"dwelling\" and outputs the right prediction with\nthe right reasoning path. Our framework precisely\ncaptures the features of dwelling theft. In contrast,\nZero-shot gave the wrong answer with the misun-\nderstanding of the concept \"dwelling\". For \"w/ Di-\nrect Interpretation\", although it reaches the correct\nconclusion, the reasoning process contains errors\nand uncertainties. It failed to clarify the vague con-\ncept in this specific scenario, using the expression\nof \"may not fully satisfy\"."}, {"title": "6 What affect interpretation quality?", "content": "In this section, we will discuss the impact of differ-\nent settings in our framework ATRI on the quality\nof generated interpretations."}, {"title": "6.1 How to retrieve cases", "content": "To verify that using LLM to filter cases and per-\nform label balancing on the case set can yield more\nuseful relevant cases, we conducted the following\nexperiments: (1) No retrieval, where no cases are\nretrieved (i.e. LLM Direct Interpretation); (2) w/o\nFiltering, which does not use LLM to filter cases or\nperform label balancing; (3) w/o Balancing, which"}, {"title": "6.2 Number of cases", "content": "We investigated the impact of using different num-\nbers of case judgments on the quality of generated\nconcept interpretations. Specifically, we sampled\ndifferent numbers of reasons from the extracted\nreason set R as input to the LLM. The results in\nFigure 4 demonstrate that a greater number of input\nreasons leads to higher-quality interpretations.\nThe more cases legal practitioners review, the\nmore comprehensive their concept interpretations\nbecome. Our findings align with this process, show-\ncasing LLMs' ability to analyze numerous cases\neffectively, highlighting their advantage to assist in\nlegal concept interpretation."}, {"title": "6.3 Which parts of a case is useful?", "content": "In the second step of our framework, we only ex-\ntract a few sentences discussing the concept from\nthe court view of each relevant case, without includ-\ning the complete fact description and court view.\nWe aim to investigate whether this might result in\nthe loss of important information from the case,"}, {"title": "6.4 Components of Interpretation", "content": "In the interpretation generation step, we ask the\nmodel to output the following components: Analy-\nsis, Example Cases, and Judicial Discretion. In this\nsection, we will investigate whether each of these\ncomponents is necessary. Specifically, we delete\none main component at a time while keeping the\nother parts unchanged. The specific role of each\ncomponent is detailed in Appendix E.\nThe results (Table 4) show that each component\nof the generated concept interpretation contributes\nto the overall performance. Notably, removing the\n\"Example Cases\" section results in the most signifi-\ncant performance drop, highlighting the importance\nof providing specific case examples."}, {"title": "7 Why our interpretations better than\nothers?", "content": "In the previous sections, we validated the effective-\nness of our framework through performance on the\nLegal Concept Entailment Task. In this section,\nwe further analyze the strengths of the generated\ninterpretations through human evaluation."}, {"title": "7.1 Evaluation Metrics", "content": "We recruited 2 human evaluators with a legal edu-\ncation background to assess the legal concept inter-\npretations generated by Qwen2.5 (72B). To provide\na comprehensive evaluation of the interpretation,\nhuman raters judge the following metrics: (1) Ac-\ncuracy (Acc.), (2) Informativeness (Info.), (3)\nNormativity (Norm.), (4) Comprehensiveness\n(Comp.), (5) Readability (Read.). We use a 10-\npoint Likert scale, where 1 represents \"very poor\"\nand 10 represents \"very good\". 6"}, {"title": "7.2 Results", "content": "In Table 5, we have several interesting observa-\ntions: (1) The average score of ATRI is the highest,\nindicating that ATRI can generate legal concept in-\nterpretations that are comparable to those produced\nby legal experts. (2) The Comprehensiveness score\nof ATRI is much higher than that of Expert Interpre-\ntation, indicating that ATRI, which involves having\nLLMs read a vast number of cases, effectively gen-\nerates more comprehensive concept interpretations.\n(3) Expert Interpretation (EI) receives the lowest\nscore in Readability, indicating that the interpreta-\ntions written by legal experts tend to be abstract or\ncomplex, which hinders understanding by both hu-\nmans and LLMs. (4) In Accuracy, Informativeness,\nand Normativity, ATRI shows improvements over\nDirect Interpretation (DI). Although there is still\nsome gap with Expert Interpretation, it is important\nto note that Expert Interpretation was produced by\nlegal experts who spent a considerable amount of\ntime, while ATRI is already approaching human-\nlevel performance. In the future, combining the two\napproaches may be a better option, such as having\nthe LLM first generate a draft, which can then be\nrevised by legal experts to significantly improve\nefficiency."}, {"title": "8 Conclusion", "content": "In this work, we explore the novel application of\nLLMs in interpreting vague legal concepts. We\npropose a data-driven, fully automatic framework\nto generate legal interpretations for a given vague\nconcept. We further introduce a new task, Legal\nConcept Entailment, to automatically evaluate the\ngenerated interpretations. Both automatic and hu-\nman evaluations demonstrate that our generated\ninterpretations are useful and comparable to those\nwritten by legal experts. Our study suggests con-\nsiderable potential for using LLMs in advancing\nlegal interpretation and beyond."}, {"title": "Limitations", "content": "Sample Size Given the limited financial budget\navailable to conduct our research, we chose to con-\nduct our study on a smaller dataset to reduce the\ncosts associated with using GPT-4 for scoring and\nhiring human evaluators. We would like to em-\nphasize that even at this scale, the costs are not\negligible. For example, evaluating the consistency\nscore of the reasons across all experiments cost ap-\nproximately $300. For human evaluation, scoring\nthe interpretations generated by the LLM and those\nwritten by legal experts cost around $130."}, {"title": "Potential Risk of Dataset Leakage", "content": "Although\nthe large language model used in our experiments\non Legal Concept Entailment Task is open-source,\nits training dataset is not fully transparent, which\nraises the possibility of data leakage. To address\nthis issue, we evaluated various methods on the\nsame base model to ensure a fair comparison.\nThe relative improvements under different settings\ndemonstrate our advantages."}, {"title": "Ethical Considerations", "content": "Privacy and Data Security Legal datasets fre-\nquently contain sensitive details about individuals\nand organizations, and improper handling can re-\nsult in significant privacy violations. To safeguard\nthis information, the case judgment dataset used in\nour experiments is thoroughly anonymized."}, {"title": "LLM-related Risks", "content": "Large language models\n(LLMs) can inherit biases or inaccuracies from\nthe data they are trained on, potentially leading\nto flawed legal interpretations. While LLMs can\nassist in generating legal concepts, they should\nnot replace human judges or be used in real-world\ndecision-making. Human oversight is essential to\nensure fairness and accuracy in legal processes."}, {"title": "Code of Conduct", "content": "This research follows the\nACL Code of Ethics and respects participants'\nanonymity. We recruited two senior law school\nstudents for manual annotation and experiments,\nobtaining the participants' consent. We pay them\nwages higher than the local average hourly rate. We\nensure that the content generated by the LLM was\nsafe and non-offensive."}, {"title": "E.1 The structure of generated concept interpretation", "content": "The generated concept interpretation includes the following main components:\n\u2022 Analysis: Cites judicial interpretations or other legal text to define the basic meaning, applicability\nconditions, and exclusions of the vague concept.\n\u2022 Example Cases: Provides specific case examples illustrating how the vague concept is applied; this\nsection includes 5 Positive Cases and 5 Negative Cases.\n\u2022 Judicial Discretion: Provides multiple judgment criteria to guide judges on how to flexibly apply\nthe vague concept based on the specifics of the case."}, {"title": "E.2 Details of the interpretation example eo", "content": "We additionally select a vague concept co and its corresponding article ao. Co and ao are not the same\nas any of the concepts and articles selected in Section 5.2. Using the methods outlined in Section 4,\nwe derive a reason set R0. These three components serve as input to the LLM. We generate multiple\ndistinct interpretations. A legal expert then selects one interpretation that best adheres to legal format\nspecifications and modifies it to ensure correctness and clarity. We designate the revised interpretation as\nthe interpretation example eo."}, {"title": "E.3.1 Original text in Chinese", "content": "\u5728\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u5211\u6cd5\u7b2c\u4e8c\u767e\u516d\u5341\u56db\u6761\u4e2d,\u201c\u76d7\u7a83\u516c\u79c1\u8d22\u7269,\u6570\u989d\u8f83\u5927\u7684\u201d\u6d89\u53ca\u76d7\u7a83\u884c\u4e3a\u7684\u5b9a\u7f6a\n\u548c\u91cf\u5211,\u8be5\u6761\u6587\u7684\u5b9e\u65bd\u4e2d,\u5176\u4e2d\u7684\u201c\u5165\u6237\u76d7\u7a83\u201d\u4e2d\u201c\u6237\u201d\u7684\u6982\u5ff5\u53ef\u80fd\u4f1a\u4ea7\u751f\u4e00\u5b9a\u7684\u6cd5\u5f8b\u89e3\u91ca\u4e0a\u7684\u6a21\n\u7cca\u6027\u3002\u53f8\u6cd5\u7a0b\u5e8f\u4e2d,\u6cd5\u5b98\u9700\u8981\u6839\u636e\u6848\u4ef6\u7684\u5b9e\u9645\u60c5\u51b5\u5bf9\u201c\u6237\u201d\u7684\u5b9a\u4e49\u8fdb\u884c\u5177\u4f53\u5316\u548c\u89e3\u91ca\u3002"}]}