{"title": "MoireDB: Formula-generated Interference-fringe Image Dataset", "authors": ["Yuto MATSUO", "Ryo HAYAMIZU", "Hirokatsu KATAOKA", "Akio NAKAMURA"], "abstract": "Image recognition models have struggled to treat recognition robustness to real-world degradations. In this context, data augmentation methods like PixMix improve robustness but rely on generative arts and feature visualizations (FVis), which have copyright, drawing cost, and scalability issues. We propose MoireDB, a formula-generated interference-fringe image dataset for image augmentation enhancing robustness. MoireDB eliminates copyright concerns, reduces dataset assembly costs, and enhances robustness by leveraging illusory patterns. Experiments show that MoireDB augmented images outperforms traditional Fractal arts and FVis-based augmentations, making it a scalable and effective solution for improving model robustness against real-world degradations.", "sections": [{"title": "1. Introduction", "content": "Image recognition techniques, particularly those based on deep learning, are promising for real-world applications; however, image classification using deep learning models is said that less robust to diverse real-world degradations than that of human visual perception [10, 21]. Consequently, as the accuracy of image recognition models improves, the goal of increasing classification robustness with respect to real-world degradations is widely seen as one of the central challenges in image recognition with deep learning.\nOne promising technique for improving the robustness of image recognition models for classification task is data augmentation such as Mixup [38] and CutMix [36]. Using these data augmentation methods, we can increase image counts while reducing overfitting, thus potentially improving robustness. The proposed data augmentation method known as PixMix [11] extends training datasets with images taken from mixing sets by combining real and synthetic images. The mixing is done both additively or multiplicatively. PixMix pipeline achieves improvements in both robustness and image classification accuracy.\nHowever, the use of these images entail at least three practical disadvantages: i) Some of the human-designed digital patterns and generative arts are protected by copyright, and thus commercial use of PixMix data augmentation remains questionable. ii) Generating FVis requires multiple CNNs trained on large image datasets, and is thus a high-cost operation for assembling images into datasets. iii) For both Fractal arts and FVis the number of images that may be feasibly assembled into a mixing set is limited in practice.\nAll of these problems may be eliminated by auto-generating data augmentation images from mathematical formulas. For example, in the methods named \"Formula-driven Supervised Learning (FDSL)\", we can construct large-scale image datasets which are privacy-safe, copyright-free, and light collecting images costs. In FDSL context, Fractal DataBase (FractalDB), Shader, etc. are proposed. As discussed in the original PixMix paper, tests to characterize the performance of FractalDB and Shader, indicate that formula-generated images are less effective for improving robustness than Fractal arts and FVis.\nThus, the aim of the present study is to devise a strategy for constructing a formula-generated mixing set that can improve the robustness of the classification model compared to fractal / FVis. Our data augmentation procedure is the same as that of PixMix, but here we propose a novel family of data augmentation images that promise improved robustness: interference-fringe images, for which we use the term MoireDB images and their constructed Moir\u00e9 DataBase (MoireDB).\nThe idea of generating Moir\u00e9 images is motivated by the hypothesis that using illusory images for data augmentation should tend to increase robustness; this hypothesis, in turn, is based on the close relation between Moir\u00e9 images and optical illusions, as well as on the known fact that deep learning models trained on such images exhibit increased robustness. We construct MoireDB, a repository of automatically formula-generated Moir\u00e9 images, and use it as an auxiliary image set to create a PixMix augmented dataset; then we train a deep learning model on this augmented dataset and measure the robustness of its image classification.\nOur proposal of MoireDB offers several key advantages, including the following.\n\u2022 The use of MoireDB for data augmentation improves robustness with respect to real-world degradations.\n\u2022 MoireDB contains only formula-generated images, eliminating copyright problems and making the database suitable for commercial use.\n\u2022 The images constituting MoireDB are auto-generated, reducing the cost of assembling images into datasets."}, {"title": "2. Related Work", "content": "Digital images are susceptible to noise, compression, and other sources of corruption caused by a broad range of mechanisms. Although such corruption does not prevent human visual perception from identifying images with high accuracy, it does significantly reduce the image identification accuracy of image recognition models [10], and improving the robustness of image recognition models is a central challenge for image recognition research.\nThe robustness of image recognition models may be quantified by testing on specialized datasets such as ImageNet-C and CIFAR-C, which consist of images that have been corrupted in various ways such as by adding noise, blurring, weathering, or applying digital transformations to reflect 15 types of corruption commonly experienced by digital images; as an example, one corrupted image from CIFAR-C is shown in Fig. 2.\nTo quantify robustness using ImageNet-C or CIFAR-C, the image classification accuracy is measured for each of the 15 categories of image corruption, and an average is performed over all categories to yield a mean corruption error (mCE); smaller mCE values indicate greater robustness.\nIn addition to quantifying robustness against corruption, robustness may also be quantified against adversaries, i.e., adversarial attacks, by measuring image classification accuracy for special test images in the ImageNet and CIFAR datasets to which adversarial attacks have been applied; again, lower values of the image classification accuracy indicate greater robustness."}, {"title": "2.2. Robustness and illusory images", "content": "Image recognition models have been often shown to be affected by illusory images in the same ways humans are. For example, illusions that confuse viewers into making erroneous color judgments [7], and illusions that trick viewers into perceiving a boundary contour that is not actually present [5] provoke responses from deep learning models that resemble the responses of human viewers [6, 32]. Illusory studies investigating the behavior of image recognition models on such illusory images often include descriptions of tests to characterize robustness; for example, studies of color-related illusions use corrupted images obtained by subjecting test images to attacks mimicking the image representations responsible for inducing illusions\u2014to test the behavior of deep learning models [6]. The results of such tests indicate improved robustness for CNNs capable of accounting for illusions. Similarly, studies of boundary-contour illusions have discussed tests to assess the robustness of deep learning models capable of taking illusions into consideration [5].\nOne common type of illusion involves static images that viewers erroneously perceive to be in motion; illusions of this type often feature concentric circles or striped patterns [5, 14]. One well-known class of images of this type is composed of images incorporating interference fringes; as mentioned above, we refer to such images as Moir\u00e9 images. Moir\u00e9 images are produced by superposing simple patterns of stripes, concentric circles, or similar elements. They are closely related to optical illusions and have been studied in fields ranging from image processing to visual art [28].\nMoir\u00e9 patterns arise naturally in digital images; for example, interference between a striped texture pattern and the spatial frequencies present in a digital image can produce Moir\u00e9 textures. Within the field of image recognition, researchers have studied techniques for eliminating Moir\u00e9 features in digital images and for creating image recognition models capable of recognizing the emergence of Moir\u00e9 features [8, 31]. In the latter case, the creation of Moir\u00e9-aware image recognition models has been shown to improve robustness against image corruption [31].\nThese observations suggest that illusory images and Moir\u00e9 images may have significant ramifications for robustness\u2014and motivate the basic assumption on which the present study is premised. Namely, we hypothesize that using Moir\u00e9 images for data augmentation will improve the robustness of deep learning models trained on the resulting augmented datasets."}, {"title": "2.3. \u03a1\u0399\u03a7\u039cIX", "content": "In the PixMix approach to data augmentation, training images from databases such as ImageNet or CIFAR are combined additively or multiplicatively with an auxiliary set of structurally complex images to yield an augmented dataset; deep learning models trained on the augmented dataset then exhibit improved image identification accuracy and robustness compared to models trained on the non-augmented dataset. In the original PixMix proposal, the auxiliary set of structurally complex images included two types of images: Fractal arts and FVis. Examples of these two types of images are shown in Fig 3.\nFractal arts (note that this is different from FractalDB) are manually designed images downloaded from DeviantArt; these images contain shapes and color schemes designed to pique the curiosity of human visual perception, and are thus expected to be structurally complex. FVis are machine-generated images that may be downloaded from OpenAI Microscope. This database allows visualization results for image features as extracted by various pre-trained CNN models operating on a large image dataset to be downloaded in the form of image files. The structural complexity of these feature-visualization images is often comparable to that of Fractal arts.\nGiven an input image dataset, PixMix produces an augmented dataset by performing repeated mixing operations. Specifically, each input image is subjected to a randomly chosen number (at most 5) of mixing steps and in each step, the image is mixed either with an input image or with an image chosen from the auxiliary image set, and the mixing is performed either additively or multiplicatively (chosen at random). Deep learning models trained on PixMix augmented datasets are known to exhibit improved image identification accuracy and robustness compared to other data augmentation methods such as Mixup [38] or CutMix [36].\nHowever, some Fractal arts are protected by copyright, and thus commercial use of PixMix remains questionable. Moreover, both Fractal arts and FVis are enormously costly to generate, and the number of images that may be feasibly assembled into a dataset is limited in practice.\nAll of these problems may be eliminated by using formula-generated image datasets. Examples include DeadLeaves and FractalDB, discussed in detail in Section 2.3. However, data augmentation using the formula-generated images of FractalDB [15] and DeadLeaves (Squares) [1] is known to be less effective than data augmentation using Fractal arts and FVis.\nTherefore, in the present study, we propose, investigate, and evaluate the performance of a new strategy for data augmentation using formula-generated images that promises image identification accuracy and robustness comparable to or greater than that of data augmentation using Fractal arts and FVis."}, {"title": "2.4. Formula-driven Supervised Learning (FDSL)", "content": "In formula-driven supervised learning (FDSL), a large image dataset consisting of formula-generated images is used to pre-train a image recognition model.\nPre-training of image recognition models on large-scale image datasets is known to yield significant improvements in image identification accuracy for additional training [4, 12, 19]. The pre-training with large-scale image datasets is typically chosen to be ImageNet, which contains over 14 million real-world images.\nHowever, ImageNet and other large-scale image datasets collected on the Internet cannot be used commercially, because the images they contain are subject to copyright protections and privacy concerns [2, 3, 35]. The large amounts of time and manpower required to generate annotations by hand, as well as the high cost of assembling images into datasets, also render this approach impractical. FDSL eliminates problems of usage rights and of costly dataset construction [15]; because the formula-generated image datasets constructed and used in FDSL methods consist of copyright-free images, they-unlike ImageNet-may be used to train deep learning models intended for commercial use.\nOne proposed strategy for constructing formula-generated image datasets is that of the FractalDB, and image recognition models pre-trained on FractalDB are known to yield improved image recognition accuracy during additional training, as is true for models pre-trained on ImageNet. The formulas used to generate images in FractalDB are based on fractal geometry, and a wide variety of shapes and patterns may be drawn by varying the adjustable parameters in these formulas.\nAs of 2024, the FDSL framework has been extended for representations (e.g., tiling [16], contours [17], Perlin noise [13]), modalities (e.g., video [18], multi-view [33], point cloud [34]), and tasks (e.g., segmentation [26], limited pre-training [23, 24], 3D segmentation [29]).\nHere, the current FDSL dataset boasting the greatest pre-training efficacy is VisualAtom [30]. Images in VisualAtom, like images in FractalDB, can be made to incorporate a wide variety of shapes and patterns by varying adjustable parameters in the image-generation formulas. The formulas used to generate VisualAtom images can also produce images featuring outlines of complex and diverse shapes. In PixMix-based approaches, auxiliary images of greater structural complexity are known to be more effective for data augmentation. This explains why the formula-generated images constituting FractalDB and VisualAtom have proven themselves useful in practice.\nFor these reasons, in discussing the results of tests to evaluate the performance of the novel technique proposed herein (Section 4.2), we will contextualize this performance by comparing it to the observed performance of data augmentation using FractalDB (as reported in the original PixMix paper) and to that of data augmentation using VisualAtom."}, {"title": "3. Data augmentation using formulagenerated Moir'e images", "content": "In the present study, we propose MoireDB, a formula-generated image dataset for data augmentation. Our goal is to ensure that training on MoireDB-augmented image datasets increases the robustness of image recognition models for classification tasks. Section 3.1 describes our procedure for generating the Moir\u00e9 images comprising MoireDB, while Section 3.2 discusses our strategy for data augmentation using generated Moir\u00e9 images.\nAs noted above, the idea of generating Moir\u00e9 images for use in data augmentation is motivated by the hypothesis that using and against illusory images for data augmentation should improve robustness."}, {"title": "3.1. Generation of Moir\u00e9 images", "content": "Our algorithm for generating the Moir\u00e9 images constituting MoireDB is depicted schematically in Fig. 4. The starting point is a simple procedure (Fig. 4, far left) for generating a concentric-circle pattern; this procedure is described by a formula, discussed below, containing multiple adjustable parameters such as the coordinates $(x_c, y_c)$ of the common center point. To generate a single Moir\u00e9 image, we invoke this formula multiple times\u2014with randomly chosen values for the adjustable parameters\u2014to yield a set of multiple distinct concentric-circle patterns (Fig. 4, center), then simply superpose these to yield the Moir\u00e9 image (Fig. 4, far right). The superposition of randomly generated concentric-circle patterns gives rise to the characteristic interference fringes of Moir\u00e9 images, and varying the adjustable parameters defining the concentric-circle patterns allows a wide range of distinct fringe patterns to be realized.\nThe image representing each concentric-circle pattern is generated by a formula that computes a brightness value for each pixel in the image. Each Moir\u00e9 image depends on several adjustable parameters: the number $Q_n$ of concentric-circle patterns superposed, and, for each of these patterns, the center-point coordinates $(x_c, y_c)$ and an interval frequency parameter $\\nu$ described below. Values for all of these parameters are chosen randomly within the ranges listed in Table 1. Each concentric-circle pattern may be described as a superposition of circles of the form\n$f_{Qn} = \\frac{1}{Qn} \\sum_{k=1}^{m} \\eta_k \\ \\eta_k \\in \\mathbb{R}^2$\nwhere m is the number of circles drawn in the pattern and $\\eta_k$ represents the k-th circle. Denoting the radius of this circle by $r_k$, and recalling that the circle is centered at $(x_c, y_c)$, we may express $\\eta_k$ in the form\n$\\eta_k = \\begin{cases} x= (r_k \\cos \\theta + x_c) \\times g \\\\ y = (r_k \\sin \\theta + y_c) \\times g\\end{cases} (0 \\leq \\theta < 2\\pi)$\nThe center-point coordinates $(x_c,y_c)$ are chosen at random from a uniform distribution. The quantity g in this expression, representing the brightness at point (x, y), is a sinusoidally varying function of the radial distance r:\n$g = (V_M (\\cos(\\nu \\times \\pi \\times r)) + 1) \\times 255$,\nwhere $V_M$ is the amplitude of the sinusoidal brightness variation. Using the brightness g to define a grayscale value for each pixel yields an image representing the concentric-circle pattern. Choosing the number of concentric-circle patterns $Q_n > 1$ then ensures interference between the patterns, yielding the desired Moir\u00e9 image.\nWe set the size of generated images to be 512 \u00d7 512 [pixel]; the number of circles m drawn for each concentric-circle pattern is determined as appropriate based on the image size and the interval frequency $\\nu$."}, {"title": "3.2. Data augmentation using Moir\u00e9 images", "content": "Our strategy for data augmentation using Moir\u00e9 images is outlined schematically in Fig. ??, and Fig. 5 shows a detailed diagram of the operational pipeline of our PixMix implementation with Moir\u00e9 images, in this case for an example involving 1 additive mixing operation and 2 multiplicative mixing operations. Our data augmentation procedure is the same as that used in PixMix. The number of Moir\u00e9 images we generate for data augmentation is 14,230, chosen to match the number of Fractal arts used in PixMix. For each image, the parameter values in the image-generation formulas are chosen at random from the ranges listed in Table 1. For each mixing step, we choose an image at random from the set of generated images and mix it either additively or multiplicatively with the selected Moir\u00e9 image or with the input image."}, {"title": "4. Experimental evaluation", "content": "We conducted experimental tests to assess the effectiveness of data augmentation using MoireDB, comparing the results against robustness values obtained via several alternative models: data augmentation using Fractal arts and FVis, as originally proposed for PixMix, and PixMix with data augmentation images taken from FractalDB and VisualAtom.\nThe training model we use is WideResNet [11, 37]. We use CIFAR as a training-image dataset. For each of the various data augmentation strategies, we create an augmented version of the CIFAR training-image dataset, then train WideResNet on the augmented dataset for 100 epochs and measure the robustness of the trained model. Robustness is measured on the CIFAR-C dataset of test images using the Corruptions and Adversaries evaluation tasks [11].\nThe Corruptions task involves using CIFAR-C to measure robustness against image corruption [10]. The metric for this assessment is the previously mentioned mCE, which is smaller for greater robustness. mCE is computed as the mean image identification accuracy for the 15 types of image corruption represented by CIFAR-C.\nThe Adversaries task involves measuring robustness against adversarial attack [22]. The metric for this assessment is the image identification accuracy, with lower values indicating better performance. Adversarial attacks are applied to CIFAR test images."}, {"title": "4.2. Results of robustness tests", "content": "Table 2 shows the results of tests to assess the impact of MoireDB-based data augmentation on the robustness of image classification. The column labeled \"Baseline\" lists results from the original PixMix paper [11].\nFrom Table 2 we see that data augmentation using MoireDB achieves better image identification robustness than any other method\u2014including data augmentation using Fractal arts-for both CIFAR-10-C and CIFAR-100-C. Comparing results for the FDSL datasets FractalDB, VisualAtom, and MoireDB, we see that, in every test of robustness, the largest robustness improvement is achieved for data augmentation using MoireDB.\nThese results demonstrate that MoireDB-based data augmentation can yield robustness improvements comparable to or greater than data augmentation using Fractal arts or FVis.\nTo analyze the test results in greater detail, we consider image classification accuracies for the various types of image corruption in CIFAR-100-C. From Table 3 we see that, for all forms of image corruption caused by noise, the greatest improvement in image classification robustness is achieved by data augmentation using FVis. On the other hand, from Table 4 we see that, for various forms of blurring, MoireDB tends to yield greater robustness improvements than other image datasets. According to Table 4, we can see MoireDB with PixMix performaed better results on the blurred noise types on the validation of CIFAR-100-C dataset.\nSimilarly, from Tables 5 and 6 we see that, for image corruption due to snow or frost, as well as for image corruption due to elastic deformation or pixelation, data augmentation using MoireDB achieves the greatest improvement in robustness."}, {"title": "5. Conclusion", "content": "In the present study, we proposed MoireDB, a formula-generated dataset of interference-fringe images for use with the PixMix method of data augmentation, and conducted experiments to assess its impact on robustness. Our results showed that, for several test categories, data augmentation using MoireDB achieved a greater improvement in robustness than data augmentation with Fractal arts or FVis. This demonstrates that formula-generated images based on illusory images can help improve the robustness of deep learning models for image classification."}]}