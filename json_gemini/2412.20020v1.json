{"title": "Calibre: Towards Fair and Accurate Personalized Federated Learning with Self-Supervised Learning", "authors": ["Sijia Chen", "Ningxin Su", "Baochun Li"], "abstract": "In the context of personalized federated learning, existing approaches train a global model to extract transferable representations, based on which any client could train personalized models with a limited number of data samples. Self-supervised learning is considered a promising direction as the global model it produces is generic and facilitates personalization for all clients fairly. However, when data is heterogeneous across clients, the global model trained using SSL is unable to learn high-quality personalized models. In this paper, we show that when the global model is trained with SSL without modifications, its produced representations have fuzzy class boundaries. As a result, personalized learning within each client produces models with low accuracy. In order to improve SSL towards better accuracy without sacrificing its advantage in fairness, we propose Calibre, a new personalized federated learning framework designed to calibrate SSL representations by maintaining a suitable balance between more generic and more client-specific representations. Calibre is designed based on theoretically-sound properties, and introduces (1) a client-specific prototype loss as an auxiliary training objective; and (2) an aggregation algorithm guided by such prototypes across clients. Our experimental results in an extensive array of non-i.i.d. settings show that Calibre achieves state-of-the-art performance in terms of both mean accuracy and fairness across clients. Code repo: calibre.", "sections": [{"title": "I. INTRODUCTION", "content": "With federated learning (FL) [1], multiple clients collaboratively train a global model while keeping their local datasets private. However, with data heterogeneity, the local accuracies that clients achieve may diverge significantly after training the same model on their different local datasets. This leads to the failure of achieving a more uniform or fair distribution of client test accuracies [2]. Known as model unfairness, this challenge motivated existing research on personalized federated learning [3], which focused on training a global model for each client to use as its starting point when training its personalized model. Such personalized models are better aligned with local data and may therefore improve fairness.\nUnfortunately, when the local data distributions across clients are severely non-independent and identically distributed (non-i.i.d.), it remains challenging to improve model fairness across clients while maintaining high overall performance. For example, while fine-tuning a trained global model within each client can improve the mean client test accuracy, it often leads to a higher variance, resulting in unfairness. This discrepancy primarily stems from significant variations in the local data distribution of individual clients, when compared to the global data distribution across all clients. In the context of data heterogeneity with non-i.i.d. data across clients, it would be ideal to achieve both low variance to improve fairness in local test accuracies across clients, while simultaneously maximizing the overall mean accuracy.\nTo achieve both objectives, it has been shown in the recent literature that personalized model training needs high-quality representations of samples as its starting point. Therefore, existing research [4], [5], [6], [7] attempted to train an encoder as the global model, which is capable of capturing generic representations from the underlying non-i.i.d. data. However, training models with these existing mechanisms depend on label information. Consequently, when some classes or labels are over-represented in the data from certain clients, model training may become biased towards these majority classes. This can result in limited representations that are hard to generalize well across all clients, exacerbating the issue of unfairness. Furthermore, the overall performance of these existing mechanisms is also significantly reduced if clients do not have an adequate number of labeled samples.\nIn this paper, we argue that utilizing self-supervised learning (SSL) as a training approach for the global model is an effective solution to these issues. SSL allows the global model to be trained in an unsupervised manner without the need for labels, thereby mitigating the issues related to label skewness. More importantly, with the objective function of SSL, the global model is trained to extract invariant features across clients. With transferable representations obtained from SSL training as a starting point, each client can then train a high-quality personalized model, even if the number of samples is limited. Although recent efforts in the literature, such as FedEMA [8], explored the usage of SSL in conventional federated learning, how SSL can be used for personalized federated learning remains uncharted territory.\nIn this paper, we propose a new framework, referred to as Calibre, that employs self-supervised learning to train global models with a focus on two fundamental objectives of personalization: the best possible fairness across all clients, and optimal mean client test accuracies. Calibre contains two federated learning stages: the training stage that trains a global model using SSL, and the personalization stage that allows"}, {"title": "II. RELATED WORK", "content": "Existing research in the FL literature has shown that the quality of the global model deteriorates when clients across the board have non-i.i.d. data. Personalized federated learning (pFL) [3], [13] was proposed with the target of training personalized models for individual clients while maintaining fairness across clients, in that the variance of local test accuracies is low. One of the primary research directions [4], [6], [7], [14] exploits representation learning to train a global model capable of extracting transferable representations. With this model as the starting point, each client can train a high-quality personalized model. Particularly, FedRep [6] jointly learns a single global representation and many local heads. FedBABU [7] shares a similar two-stage training approach to our work. In the first stage, it trains a shared encoder using decentralized datasets, after which each client optimizes its local head by leveraging the features extracted from the fixed encoder. In contrast to approaches that heavily rely on strong supervision information, such as labels, our work takes a different approach by incorporating self-supervised learning (SSL) [15] into personalized FL. By leveraging SSL, we enhance the generality of the global model without the need of using labels in training data samples.\nExploring unsupervised training methods for addressing non-i.i.d. challenges in federated learning is a burgeoning research area. Existing studies that were closely related to our work, such as [8], [9], [10], employed SSL frameworks, including BYOL [16], SimCLR [17], and Simsiam [18]. The overarching objective was to optimize the global model using multiple augmentations or views of the same input data. Specifically, FedEMA [8] conducted a comprehensive empirical investigation into federated self-supervised learning. Based on this study, FedEMA introduced a novel approach that combined elements of BYOL and employed an exponential moving average (EMA) scheme. To the best of our knowledge, no prior research explored the effectiveness of self-supervised learning in the context of personalized FL, while simultaneously considering fairness and overall performance."}, {"title": "III. PROBLEM FORMULATION", "content": "Unlike conventional federated learning that trains a global model $\\theta$ across $C$ clients, personalized federated learning (pFL) aims to produce personalized models {$\\phi_c$}$_{c=1}^{C}$ for individual clients. This leads to an optimization problem given by $\\min_{\\phi_c} L_c (\\phi_c; D_c)$, where $L_c$ and $D_c$ is the loss function and the local train set of client $c$, respectively. Among various methodologies toward achieving personalized FL, this paper focuses on the paradigm [6], [7], [8] in which clients cooperatively train a global model $\\theta$, containing fully convolutional layers $\\theta_b$ and fully-connected layers $\\theta_h$. After reaching convergence, each client utilizes $\\theta_b$ to extract features to train its $\\phi_c$ based on the local dataset. For the purpose of evaluation, each client tests its trained $\\phi_c$ on the local test dataset $D'_c$. In the context of image classification that we focus on, clients compute accuracies {$a_1$,...,$a_C$}. This paper focuses on a common challenge in non-i.i.d. data scenarios, particularly where the label distributions vary considerably across clients."}, {"title": "A. Model Fairness and Overall Performance", "content": "Mean accuracy computed on {$a_1$,...,$a_C$} presents the overall performance but fails to give insights into how well individual clients can train personalized models. Under the non-i.i.d. data of clients, the global model $\\theta$ may be trained to be biased towards the data distribution of certain clients. Therefore, when $\\theta$ is eventually used by clients for personalization under non-i.i.d. data, such bias introduces highly variable performance between different clients as the trained global model cannot generalize well to some local datasets.\nThis disparity in model performance across different clients is commonly recognized as model unfairness [19]. We formally extend this to personalized FL. Specifically, fairness is defined as the case if, based on the trained global model, clients can generate personalized models with similar performance. In terms of accuracy, this leads to {$a_1$,...,$a_C$} of clients presenting a low divergence, meaning that the variance computed from these test accuracies is low.\nWe argue that targeting a high overall performance but sacrificing model fairness, or vice versa, is extremely detrimental when applying personalized FL to real-world applications. Therefore, in this paper, our objective is to impose better fairness by decreasing the accuracy variance, while still achieving the best possible mean accuracy."}, {"title": "B. Personalized FL with Self-Supervised Learning", "content": "As pointed out by the existing literature [6], [7], the core idea to improve fairness is to train the global model toward extracting the generic features containing common patterns of the dataset. And thus, any clients can train personalized models based on these extracted features of local samples. Motivated by these observations, we propose introducing self-supervised learning (SSL), an unsupervised learning approach, to train the global model under personalized FL, pFL-SSL. This is because the objective of SSL does not include labels, and as a result, learned representation is not tied to specific labeled outcomes. This generalizes well to local samples with different label distributions; with non-i.i.d. data, the trained global model will be less biased towards the data distribution of a certain subset of clients.\nTherefore, the preliminary design is to train the global model with SSL and then perform personalization on each individual client based on the transferable representation learned by the trained global model. First, during the training stage, the global model is trained with the loss function of SSL [17] till reaching the convergence. Subsequently, during the personalization stage, each client utilizes $\\theta_b$ of the $\\theta$ as the feature extractor of the local samples and then $\\phi_c$ is trained in"}, {"title": "C. Representations with Fuzzy Class Boundaries", "content": "With pFL-SSL, the transferable representations extracted by $\\theta$ on local samples are expected to demonstrate two key properties: 1) exhibiting distinct class boundaries, even in the presence of class-imbalanced samples for each client [21], and 2) encompassing transferable generic semantics. However, based on our experiment performed on CIFAR-10 under non-i.i.d. data across 100 clients, we observed that the representations learned by pFL-SimCLR and pFL-BYOL, as shown in Fig. 1 and Fig. 2, do not exhibit these properties. In contrast, the 2D embeddings of features reveal the following two limitations of PFL-SSL."}, {"title": "IV. Calibre: A NEW PFL FRAMEWORK", "content": "In this section, we begin with a theoretical exploration of the impact of self-supervised representations containing fuzzy class boundaries on personalization. As a result, the derived theorem guides our design of Calibre towards fair and accurate personalized FL.\nTo train the personalized model $\\phi_c$, the $\\theta_b$ extracts features from the input $x'$, resulting in the latent representation $z = f_{\\theta_b}(x')$, which is utilized to make a prediction with $\\phi_c$, denoted as $\\tilde{y}'$. Therefore, the predicted label $\\tilde{y}'$ is obtained based on information derived from: 1) the local dataset $D$, where $x' \\in D$ is processed by models to produce $\\tilde{y}'$; and 2) $\\theta_b$, the encoder responsible for extracting latent features, directly contributing to $\\tilde{y}'$."}, {"title": "A. Generality-Personalization Tradeoff Theorem", "content": "The learning for the personalized model $\\phi_c$ of each client depends on the self-supervised representations $z$ extracted by the global $\\theta_b$. We denote this process as $x' \\rightarrow z \\rightarrow \\tilde{y}'$. Thus, from the information theory perspective, this process can be formulated by two information flows, including $x' \\in D \\rightarrow \\tilde{y}'$ and $\\theta_b \\rightarrow \\tilde{y}'$.\nExcessively generic representations. On the one hand, when self-supervised representations $z$ primarily exhibit generic features across clients, such as sample-wise similarity, the training for $\\phi_c$ is adversely affected as a result of failing to capture the class distinguishability information from client-specific data $D_c$, as witnessed in Fig. 2. This can be denoted as $q(\\tilde{y}'|x', \\phi_c)q(\\phi_c|D, \\theta_b) = q(\\tilde{y}'|x', \\phi_c)q(\\phi_c|\\theta_b)$, in which the personalized model $\\phi_c$ is independent of the dataset $D$ in the client, such that $q(\\tilde{y}'|x', \\theta_b, D) = q(\\tilde{y}'|x', \\theta_b)$. Hence, we have Lemma 1 which improves personalization by maximizing the information from $D$ to the prediction.\nLemma 1. Given $\\theta_b$ and the learned representation Z, we can implicitly encourage the model to use the client's local training data D by maximizing the lower bound of $I(\\tilde{y}'; D|\\theta_b, z)$ shown as $I(x';\\tilde{y}'|\\theta_b) - E [KL(p(z|x', \\theta_b)||r(z))]$, where $r(z)$ is a variational approximation to the marginal.\nProof. With $KL(p(\\tilde{y}'|z,\\theta_b)|q(\\tilde{y}'|z,\\theta_b)) \\geq 0$, $I(\\tilde{y}';z,\\theta_b)$ has a lower bound $\\int p(z, \\tilde{y}'|\\theta_b) \\log q(\\tilde{y}'|z, \\theta_b)d\\tilde{y}'dz$, where $q(\\tilde{y}'|z, \\theta_b)$ is a variational approximation to the target distribution $p(\\tilde{y}'|z, \\theta_b)$. Then, given\n$\\int p(z, \\tilde{y}'|\\theta_b)d\\tilde{y}'dz = \\int \\int p(x',\\tilde{y}'|\\theta_b)p(z|x',\\theta_b)dx'd\\tilde{y}'dz$\nwe can approximate the lower bound of $I(\\tilde{y}';z, |\\theta_b)$ by using the empirical data distribution of $p(x', \\tilde{y}')$ on $D'$. We obtain $I(\\tilde{y}';z, |\\theta_b) \\geq E \\int p(z|x', \\theta_b) \\log q(\\tilde{y}'|z, \\theta_b)dz$. Utilizing the reparameterization trick, this can be estimated as $E_{x'} E_{\\epsilon \\sim N(0,1)} [\\log q(\\tilde{y}'|x', \\theta_b, \\epsilon)]$.\nExcessive personalization. On the other hand, personalized learning is hindered when the trained global encoder $\\theta_b$ mainly concentrates on capturing client-specific class distribution from local samples, while providing limited prior generic information learned from datasets of other clients. As a result, with no information from $\\theta_b$ being included, the training for $\\phi_c$ relies solely on the information flow from the D. This can be mathematically denoted as $q(\\tilde{y}'|x', \\phi_c,\\theta_b)q(\\phi_c|D,\\theta_b) = q(\\tilde{y}'|x', \\phi_c)q(\\phi_c|D)$, in which $\\phi_c$ only depends on limited local samples D, thus significantly damaging the training speed and the prediction performance. Therefore, we should enhance the generic of self-supervised representations by improving the mutual information $I(\\tilde{y}'; z|\\theta_b)$. Thus, we have lemma 2.\nLemma 2. With the representation z obtained by applying the $\\theta_b$ on the sample x', more information of $\\theta_b$ can be given to personalized prediction $\\tilde{y}'$ by maximizing the mutual information $I(\\tilde{y}';z|\\theta_b)$ with a lower bound estimated as $E_{x',\\tilde{y}'} \\int p(Z|x', \\theta_b) \\log p(\\tilde{y}'|z, \\theta_b)dz$.\nProof. We first get a zero term $I(x';\\tilde{y}'|D, \\theta_b, z)$. Then, we can naturally follow the theoretical analysis in the Appendix A.2 of the work [11] to obtain $I(\\tilde{y}'; D|\\theta_b, z) \\geq I(x'; \\tilde{y}'|\\theta_b, Z)$. For each client, the input $x'$ used to predict $\\tilde{y}'$ is the sample"}, {"title": "V. EXPERIMENTAL RESULTS", "content": "Experimental platform. All experiments are conducted on Plato, an open-source research framework for federated learning. We utilize a single NVIDIA RTX A4500 GPU with 20 GB of CUDA memory. Additionally, one task is allocated 10 CPUs, each CPU having 3GB of memory.\nDatasets. We perform the evaluation on three widely-used datasets, CIFAR-10, CIFAR-100, and STL-10 [12]. The first three frequently utilized datasets comprise fully annotated samples. However, STL-10 comprises 100,000 unlabeled samples in addition to 5,000 labeled training samples.\nModel settings. We utilize the ResNet-18 network in experiments on CIFAR-10, CIFAR-100 and STL-10 datasets. In order to maintain a fair comparison, the fully-connected layers of both networks are substituted with a linear classifier. Consequently, for the CIFAR-10, CIFAR-100, and STL-10 datasets, the input dimension of this classifier is set to 512, corresponding to the number of classes as the output. We refer to the fully convolutional neural part as the Encoder while the linear classifier as the Head. Thus, in SSL approaches, the Encoder is the feature backbone, which also behaves as the global model exchanged between clients and the server. Calibre (BYOL), Calibre (SimCLR), Calibre (MoCov2), Calibre (Simsiam), Calibre (SwAV), and Calibre (SMoG) are built upon BYOL [16], SimCLR [17], Simsiam [18], MoCoV2 [20], SwAv [24], and SMOG [25], respectively.\nBenchmark approaches. Well-known federated learning approaches, including FedAvg [1], LG-FedAvg[4], SCAFFOLD [26], are included as the benchmark approaches. Specifically, FedAvg-FT and SCAFFOLD-FT refer to scenarios where the global model is initially trained using FedAvg and SCAFFOLD, respectively. Subsequently, the Head component of the model is fine-tuned based on the local dataset. Our experiments also contain advanced personalized FL approaches, including FedRep [6], FedBABU [7], FedPer [14], PerFedAvg [27], APFL [28]. Calibre is also compared with Ditto [19], which achieves fairness through personalization. Additionally, we assess Calibre against the closely related work FedEMA [8] to provide a comprehensive evaluation. Finally, in addition to these approaches, we allow each client to train its personalized model (i.e., a linear classifier) separately based solely on their local datasets. Script-Convergent refers to the model trained until convergence, whereas Script-Fair corresponds to the model trained after 10 epochs.\nLearning settings. We have a total of 100 clients participating in training the global model for 200 rounds. In addition, there are 50 novel clients that are excluded from the training process. In each round, 10 clients are randomly selected to perform 3 epochs of local update. After 200 rounds of training, all 150 clients will download the trained global model to perform the personalization based on the local dataset. Leveraging the trained global model, denoted as the Encoder, as the feature extractor, each client optimizes their personalized model for 10 epochs using the SGD optimizer with a learning"}, {"title": "A. Experimental Setup", "content": "Experimental platform. All experiments are conducted on Plato, an open-source research framework for federated learning. We utilize a single NVIDIA RTX A4500 GPU with 20 GB of CUDA memory. Additionally, one task is allocated 10 CPUs, each CPU having 3GB of memory.\nDatasets. We perform the evaluation on three widely-used datasets, CIFAR-10, CIFAR-100, and STL-10 [12]. The first three frequently utilized datasets comprise fully annotated sam-ples. However, STL-10 comprises 100,000 unlabeled samplesin addition to 5,000 labeled training samples.\nModel settings. We utilize the ResNet-18 network in experi-ments on CIFAR-10, CIFAR-100 and STL-10 datasets. In orderto maintain a fair comparison, the fully-connected layers of bothnetworks are substituted with a linear classifier. Consequently,for the CIFAR-10, CIFAR-100, and STL-10 datasets, the inputdimension of this classifier is set to 512, corresponding tothe number of classes as the output. We refer to the fullyconvolutional neural part as the Encoder while the linearclassifier as the Head. Thus, in SSL approaches, the Encoderis the feature backbone, which also behaves as the global modelexchanged between clients and the server. Calibre (BYOL),Calibre (SimCLR), Calibre (MoCov2), Calibre (Simsiam),Calibre (SwAV), and Calibre (SMoG) are built upon BYOL[16], SimCLR [17], Simsiam [18], MoCoV2 [20], SwAv [24],and SMOG [25], respectively.\nBenchmark approaches. Well-known federated learningapproaches, including FedAvg [1], LG-FedAvg[4], SCAFFOLD[26], are included as the benchmark approaches. Specifically,FedAvg-FT and SCAFFOLD-FT refer to scenarios where theglobal model is initially trained using FedAvg and SCAFFOLD,respectively. Subsequently, the Head component of the modelis fine-tuned based on the local dataset. Our experimentsalso contain advanced personalized FL approaches, includingFedRep [6], FedBABU [7], FedPer [14], PerFedAvg [27],APFL [28]. Calibre is also compared with Ditto [19], whichachieves fairness through personalization. Additionally, weassess Calibre against the closely related work FedEMA [8]to provide a comprehensive evaluation. Finally, in addition tothese approaches, we allow each client to train its personalizedmodel (i.e., a linear classifier) separately based solely on theirlocal datasets. Script-Convergent refers to the model traineduntil convergence, whereas Script-Fair corresponds to the modeltrained after 10 epochs.\nLearning settings. We have a total of 100 clients par-ticipating in training the global model for 200 rounds. Inaddition, there are 50 novel clients that are excluded fromthe training process. In each round, 10 clients are randomlyselected to perform 3 epochs of local update. After 200 roundsof training, all 150 clients will download the trained globalmodel to perform the personalization based on the local dataset.Leveraging the trained global model, denoted as the Encoder,as the feature extractor, each client optimizes their personalizedmodel for 10 epochs using the SGD optimizer with a learning"}, {"title": "B. Accuracy", "content": "As shown in Fig. 3, and Fig. 4, Calibre, built upon four SSL methods, consistently obtains competitive accuracy. Especially, Calibre (SimCLR) maintains the highest mean accuracy in various non-i.i.d. settings of four datasets. In the Q-non-i.i.d. setting, when applied to the datasets CIFAR-10, CIFAR-100, and STL-10, Calibre utilizing the SimCLR learning structure demonstrates superior performance in terms of mean accuracy. It outperforms sub-optimal methods by 1.71%, 1.51%, and 6.03% on the respective datasets. This is because features extracted by the global model trained with Calibre contain cluster information. Moreover, based on these transferable representations, the personalized model converges faster and can generalize better on the specific dataset, even when local samples are limited and imbalanced. Finally, any client can train a high-quality personalized model to gain high accuracy on its test set.\nWhile both non-i.i.d. settings involve label skewness among clients, the D-non-i.i.d. setting presents a greater challenge than the Q-non-i.i.d. setting. This is because, in the D-non-i.i.d. setting, each client experiences sample skewness among classes, further complicating the learning process. Remarkably, under the D-non-i.i.d. setting for the STL-10 dataset, Calibre (SimCLR) significantly outperforms FedBABU by a considerable margin of 15.18%. The primary reason is"}, {"title": "V. A", "content": "Experimental SetupExperimental platform. All experiments are conductedon Plato, an open-source research framework for federatedlearning. We utilize a single NVIDIA RTX A4500 GPU with20 GB of CUDA memory. Additionally, one task is allocated10 CPUs, each CPU having 3GB of memory.Datasets. We perform the evaluation on three widely-useddatasets, CIFAR-10, CIFAR-100, and STL-10 [12]. The firstthree frequently utilized datasets comprise fully annotated sam-ples. However, STL-10 comprises 100,000 unlabeled samplesin addition to 5,000 labeled training samples.Model settings. We utilize the ResNet-18 network in experi-ments on CIFAR-10, CIFAR-100 and STL-10 datasets. In orderto maintain a fair comparison, the fully-connected layers of bothnetworks are substituted with a linear classifier. Consequently,for the CIFAR-10, CIFAR-100, and STL-10 datasets, the inputdimension of this classifier is set to 512, corresponding tothe number of classes as the output. We refer to the fullyconvolutional neural part as the Encoder while the linearclassifier as the Head. Thus, in SSL approaches, the Encoderis the feature backbone, which also behaves as the global modelexchanged between clients and the server. Calibre (BYOL),Calibre (SimCLR), Calibre (MoCov2), Calibre (Simsiam),Calibre (SwAV), and Calibre (SMoG) are built upon BYOL[16], SimCLR [17], Simsiam [18], MoCoV2 [20], SwAv [24],and SMOG [25], respectively.Benchmark approaches. Well-known federated learningapproaches, including FedAvg [1], LG-FedAvg[4], SCAFFOLD[26], are included as the benchmark approaches. Specifically,FedAvg-FT and SCAFFOLD-FT refer to scenarios where theglobal model is initially trained using FedAvg and SCAFFOLD,respectively. Subsequently, the Head component of the modelis fine-tuned based on the local dataset. Our experimentsalso contain advanced personalized FL approaches, includingFedRep [6], FedBABU [7], FedPer [14], PerFedAvg [27],APFL [28]. Calibre is also compared with Ditto [19], whichachieves fairness through personalization. Additionally, weassess Calibre against the closely related work FedEMA [8]to provide a comprehensive evaluation. Finally, in addition tothese approaches, we allow each client to train its personalizedmodel (i.e., a linear classifier) separately based solely on theirlocal datasets. Script-Convergent refers to the model traineduntil convergence, whereas Script-Fair corresponds to the modeltrained after 10 epochs.Learning settings. We have a total of 100 clients par-ticipating in training the global model for 200 rounds. Inaddition, there are 50 novel clients that are excluded fromthe training process. In each round, 10 clients are randomlyselected to perform 3 epochs of local update. After 200 roundsof training, all 150 clients will download the trained globalmodel to perform the personalization based on the local dataset.Leveraging the trained global model, denoted as the Encoder,as the feature extractor, each client optimizes their personalizedmodel for 10 epochs using the SGD optimizer with a learning"}, {"title": "VI. CONCLUDING REMARKS", "content": "In this paper, we focused on personalized federated learning and have thoroughly investigated how a fair model performance across clients can be achieved while maximizing the average training performance. Our objective for designing Calibre, our new personalized federated learning framework, was to adopt self-supervised learning (SSL) in the training stage to train a global model that could generalize well to individual clients. However, we empirically found that although this model benefits model fairness across clients, its average accuracy is even worse. It turned out that the root cause for this observation was the lack of class separation information in the representations extracted by the global model. After a comprehensive theoretical analysis, we presented a theorem, called generality-personalization tradeoff, to include cluster information in the representation of SSL. With these insights, we proposed a new contrastive prototype adaptation mechanism that was able to improve the mean accuracy while maintaining a uniform accuracy across clients (model fairness). We showed convincing results from a wide array of experiments that Calibre achieves higher model fairness, maintains better mean accuracy, and shows more consistent performance on multiple non-i.i.d. data scenarios than its state-of-the-art alternatives in the literature."}]}