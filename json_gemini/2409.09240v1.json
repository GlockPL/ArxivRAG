{"title": "Cross-Entropy Optimization for Hyperparameter Optimization in Stochastic Gradient-based Approaches to Train Deep Neural Networks", "authors": ["Kevin Li", "Fulu Li"], "abstract": "In this paper, we present a cross-entropy optimization method for hyperparameter optimization in stochastic gradient-based approaches to train deep neural networks. The value of a hyperparameter of a learning algorithm often has great impact on the performance of a model such as the convergence speed, the generalization performance metrics, etc. While in some cases the hyperparameters of a learning algorithm can be part of learning parameters, in other scenarios the hyperparameters of a stochastic optimization algorithm such as Adam [5] and its variants are either fixed as a constant or are kept changing in a monotonic way over time. We give an in-depth analysis of the presented method in the framework of expectation maximization (EM). The presented algorithm of cross-entropy optimization for hyperparameter optimization of a learning algorithm (CEHPO) can be equally applicable to other areas of optimization problems in deep learning. We hope that the presented methods can provide different perspectives and offer some insights for optimization problems in different areas of machine learning and beyond.", "sections": [{"title": "1. Introduction", "content": "In machine learning, the most fundamental components of the system are the learning algorithms. A hyperparameter of a learning algorithm is often used to control the learning process, whose value may have great impact on the performance of the learning algorithm such as the convergence speed and other performance metrics such as the value of a pre-defined loss function for a given data set. Another aspect is the estimation of the generalization performance of the model, which is often accomplished by using cross-validation techniques with a totally different data set. The goal is to choose a set of values for the hyperparameters of a learning algorithm to maximize the generalization performance. In some cases, some hyperparameters of a learning algorithm can be included as part of learning parameters with multiple independent learning processes with different sets of hyperparameters. While in some other scenarios, it may not be applicable for some hyperparameter of a learning algorithm to be part of learning parameters. Therefore, it is a common practice to apply some hyperparameter optimization techniques to choose optimal or sub-optimal hyperparameters for a given learning algorithm.\nFor example, the stochastic optimization method of Adam in [5] uses the hyper-parameters $\\beta_1, \\beta_2 \\in [0, 1)$ to control the exponential decay rates of these moving averages of the first moment (the mean) and the second raw moment (uncentered variance) of the gradients respectively. By choosing proper values of the hyperparameters of $\\beta_1, \\beta_2$, the basic idea is to assign smaller weights to the gradients too far in the past [5,7]. As discussed in [5,7], in some cases both $\\beta_1, \\beta_2$ are held constant and in other cases $\\beta_1$ might be kept decreasing over time. In the experiments in [7], a grid search method is used in choosing the hyperparameters of $\\alpha$ and $\\beta_2$.\nNowadays, stochastic gradient-based optimization methods are the key pillars to train deep neural networks and a hyper parameter is a parameter whose value is used to control the learning process during the training of deep neural networks. As discussed in [11], traditional stochastic gradient descent (SGD) algorithm for training deep neural networks requires careful tuning of the learning rate and momentum parameters. Momentum-based approaches accumulate gradients over time to maintain the momentum for the optimizer and to avoid being stuck in some local minima. In [5], a widely used approach named Adam was presented to adapt the learning rate for each parameter of the deep neural networks based on first and second moments of the gradients. In [7], Reddi et al discussed some of the convergence issues of Adam and pointed out that some of the convergence problems of approaches that employed exponential moving average of the past"}, {"title": "2. The Related Work", "content": "Existing hyperparameter optimization methods include: (a) grid search, i.e., essentially an exhaustive search over a given hyperparameter space; (b) random search, which can explore much more potential values than grid search for continuous hyperparameters; (c) Bayesian optimization, which employs a probabilistic model between hyperparameter values and objectives evaluated on a given data set and it has shown to outperform both grid search and random search with fewer evaluations; (d) gradient-based optimization, which computes the gradients with respect to hyperparameters when applicable for some learning algorithms and then optimizes the hyperparameters based on gradient decent philosophy; (e) evolutionary optimization, which employs an evolutionary algorithm to find the best possible hyperparameters for a given learning algorithm; (f) population-based methods, which updates the hyperparameters as well as the weights of neural networks during the training of the models with multiple independent learning processes with different hyperparameteres of the learning algorithm; (g) early stopping-based approach, which starts as a random search over the hyperparameters space and successively prunes low-performing ones until there is only one model remaining.\nNotably, the basic idea of cross entropy (CE) method [6, 9, 10] is to translate the deterministic optimization problem into a corresponding stochastic one and then use rare event simulation techniques to find the optimal solution. In [6], Li et al presented a random tree optimization approach for the construction of the most parsimonious phylogenetic trees based on CE method, where an iterative optimization process is applied to reduce the parsimony score of a tree with the principle of cross entropy optimization. As discussed in [6, 9, 10], cross entropy (CE) method differs from other well-known random search algorithms for global optimization such as simulated annealing [1,2,8], tabu search [3] and genetic algorithms [4], which are local search heuristics and employ the notion of local neighborhood structures. Cross entropy (CE) method employs multi-extremal optimization process based on Kullback-Leibler cross-entropy, importance sampling, etc. Therefore, cross entropy (CE) method represents a global random search procedure rather than a local one.\nOur work differs from existing hyperparameter optimization methods in that we use cross-entropy optimization with a probability distribution over hyperparameter space, where some rare event simulation techniques are used to find the optimal values of the hyperparameters for a given learning algorithm. The cross-entropy operation is achieved by virtue of probability update after the performance evaluation after each round of randomly-generated hyperparameter samples based on probability distributions, where a small portion of top performers are given higher probabilities for the next round. The iterative optimization process ends when the convergence conditions are achieved or a pre-defined early-stop criteria is met."}, {"title": "3. Hyperparameters Optimization for Adam", "content": "We have some basic notations for the cross entropy optimization of hyperparameters in Adam and its variants [5,7] as follows: Let $\\beta$ be a hyperparameter for a given learning algorithm. Let $F(\\beta)$ stand for the performance metric for a given value of $\\beta$, a given learning algorithm and a given data set for a given machine learning problem. Let $n_d$ be the number of data sets for a given machine learning problem. Let $n_{ml}$ be the number of machine learning problems. We also assume that the proper value range of $\\beta$ is given as"}, {"title": "4. Analysis in the Framework of EM", "content": "Following [6], we give an in-depth analysis on CEHPO algorithm in the framework of expectation maximization (EM) [12] in this section, which could shed some light on the theoretical justifications of some of the operations in the process of cross entropy optimization.\nLet $D$ indicate the values of the observed variables, e.g., the data sets in the learning experiments, and let $W$ denote the hidden data, e.g., the weights in the neural networks. Let $P$ be the probability mass function of the complete data with some hyperparameters given by $\\beta$ and others such as $\\theta$, etc. For the sake of simplicity, we only consider hyperparameters of $\\beta$ and omit other parameters such as $\\theta$, etc. in the following discussions. Therefore, we have $P(D, W|\\beta)$ as the complete data likelihood, which can be thought of as a function of $\\beta$.\nBy using the Bayes's rule and the law of total probability, the conditional probability of the hidden data given the observed data and $\\beta$ can be expressed as:\n$P(W|D, \\beta) = \\frac{P(D, W|\\beta)}{P(D|\\beta)}$\n$P(W|D, \\beta) = \\frac{P(D|W,\\beta)P(W|\\beta)}{\\sum_{\\hat{W}}P(D|W,\\beta)P(W|\\beta)}$\nwhere $\\hat{W}$ indicates the estimated weights of the neural networks.\nThe goal is to estimate the values of $\\beta$. The E-step is given by:\n$E: Q(\\beta) = E_W[log(P(D, W |\\beta))]$\nwhere $Q(\\beta)$ is the expected value of the log-likelihood of the complete data.\nThe expected value of log-likelihood in Equation (11) can be further expressed as:\n$Q(\\beta) = \\sum_{W} P(W|D, \\beta) \\times log(P(D, W |\\beta))$\nIn the CEHPO algorithm, $\\beta$ evolves from $\\beta_0$ to $\\beta_1, \\beta_2, ..., \\beta_{t-1}, \\beta_t$ based on the improved $\\beta$ samples according to Equation (4), Equation (5), Equation (6) and Equation (7) for better performance of the given learning algorithm for the given machine learning problem. The update process of $q_i$s according to Equation (4) and Equation (5) minimizes the cross entropy based on the Kullback-Leibler cross entropy principle [9, 10] and importance sampling philosophy.\nThe M-step is given by:\n$M: \\beta_t = arg \\underset{\\beta}{max} Q(\\beta)$\nwhere $\\beta_t$ is the value of $\\beta$ that maximizes (M-step) the conditional expectation (E-step, e.g., Equation (11)) of the complete data log-likelihood given observed data set under the previous parameter value of $\\beta_{t-1}$. Notably, for each set of weights for the neural network, there is a likelihood value for $\\beta$. We can thus calculate an expected value of the likelihood, which depends on the previously assumed value of $\\beta$ as it influenced the probabilities of the weights of the neural network, e.g, W.\nAs discussed in [6], for traditional EM algorithm, it can be shown that an EM iteration does not decrease the observed data likelihood function. However, there is no guarantee that the data set converges to a maximum likelihood estimator. In other words, EM is a local search algorithm. In the CEHPO algorithm based on cross entropy optimization method, a multi-extremal search is employed due to the adoption of Kullback-Leibler cross-entropy [9,10] and importance sampling techniques. It can be shown in [9,10] that with high probability the observed data likelihood function increases and eventually converges to one so long as the"}]}