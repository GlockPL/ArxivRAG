{"title": "On the Inherent Robustness of One-Stage Object Detection against Out-of-Distribution Data", "authors": ["Aitor Martinez-Seras", "Javier Del Sera", "Alain Andres", "Pablo Garcia-Bringas"], "abstract": "Robustness is a fundamental aspect for developing safe and trustworthy models, particularly when they are deployed in the open world. In this work we analyze the inherent capability of one-stage object detectors to robustly operate in the presence of out-of-distribution (OoD) data. Specifically, we propose a novel detection algorithm for detecting unknown objects in image data, which leverages the features extracted by the model from each sample. Differently from other recent approaches in the literature, our proposal does not require retraining the object detector, thereby allowing for the use of pretrained models. Our proposed OoD detector exploits the application of supervised dimensionality reduction techniques to mitigate the effects of the curse of dimensionality on the features extracted by the model. Furthermore, it utilizes high-resolution feature maps to identify potential unknown objects in an unsupervised fashion. Our experiments analyze the Pareto trade-off between the performance detecting known and unknown objects resulting from different algorithmic configurations and inference confidence thresholds. We also compare the performance of our proposed algorithm to that of logits-based post-hoc OoD methods, as well as possible fusion strategies. Finally, we discuss on the competitiveness of all tested methods against state-of-the-art OoD approaches for object detection models over the recently published Unknown Object Detection benchmark. The obtained results verify that the performance of avant-garde post-hoc OoD detectors can be further improved when combined with our proposed algorithm.", "sections": [{"title": "1. Introduction", "content": "The rapid advancement and widespread adoption of Artificial Intelligence (AI) systems for real-world applications have underscored the urgent need for these models to be safe and trustworthy [1]. What trustworthiness means for AI is a highly debated concern in the recent years, attracting significant interest from the research community. A major breakthrough in shedding light on trustworthy AI was the publication of the \u201cEthical Guidelines for Trustworthy AI\" [2] in 2019 by the European Union, a regulatory actor of relevance in this matter. The text outlines seven key requirements for trust-worthy AI and identify three essential pillars for fulfilling these requirements. The technical robustness and safety of an AI system is recognized as one of the seven requirements and a fundamental pillar of trustworthiness [3]. More recently, another important actor in the regulatory landscape, the National Institute of Standards and Technology (NIST) has defined in [4] the technical robustness as a system's capacity to sustain its performance across diverse conditions. It entails not only consistent functioning under anticipated sce-narios, but also the ability to minimize potential risks to individuals when operating in environments subject to unexpected events.\nFor this purpose, ensuring the safety of Machine Learning (ML) mod-els involves developing robust systems capable of handling unknown seman-tics, effectively distinguishing between known and unknown data instances. When it comes to object detection tasks from image data, these models must be able to navigate open-world environments by discerning between back-ground (irrelevant information), known objects (relevant information within the training distribution), and unknown objects (relevant information out-side the training distribution). In this context, substantial efforts have been directed towards the field of Open World Object Detection (OWOD) [5]-\n[8]. The goal pursued in this research area is to develop models capable of detecting unknown objects and incrementally learning new categories over time. Predominantly, research in this area has concentrated on methodolo-"}, {"title": "2. Related Work and Contribution", "content": "This section provides an overview of existing OoD techniques tailored for object detection (Subsection 2.1), reviews key works within the OWOD framework (Subsection 2.2), and presents this paper's contributions to the OoD literature (Subsection 2.3)."}, {"title": "2.1. Out-of-Distribution Detection in Object Detection", "content": "As noted in the introduction, the goal of OoD detection is to identify unknown samples in classification tasks\u2014specifically, samples with semantics not present in the training distribution. Numerous techniques have been proposed in this area. e.g., ReAct [10], GradNorm [11], MSP [12], ODIN [13] or Energy [14]. These techniques were originally conceived for detecting OoD data in image classification tasks. In object detection tasks, however, OoD detection refers to the model's ability to locate and identify objects in an image that do not belong to any of the classes it was trained to recognize. While traditional object detection models are trained to detect a fixed set of classes, OoD detection enables these models to recognize when an object falls outside this known set, flagging it as unknown.\nDue to its higher complexity than in traditional image classifier, the de-tection of unknowns in object detection models has garnered increasing in-terest during the last couple of years. Several methods devised to cope with this problem have been reported in the literature, such as those presented in [15] and [16]. Both are focused on regularizing a two-stage object detection model via the usage of unknowns. In the former, Virtual Outlier Synthe-sis (VOS) technique is proposed to synthesize virtual outliers in the feature space, without relying on external data to allow the model to better learn the boundaries between known and unknown classes. In the latter, the same objective is pursued. Differently, unknowns are obtained or distilled from videos leveraging contiguous frames and a dissimilarity metric based on the L2 distance between features of the object proposals.\nAnother example is [17], where authors propose a post-hoc OoD detector for object detection that utilizes Sensitivity-Aware FEatures (SAFE) ex-tracted from residual convolutional layers and abnormal batch normalization activations. SAFE extracts object-specific feature vectors and employs a"}, {"title": "2.2. Open-World Object Detection Framework", "content": "The OWOD framework was introduced by [5] to address the limitations of traditional object detection models that assume all object classes are known during training. In the open-world setting, a model is expected to not only detect known objects but also identify unknown objects that do not belong to the training classes. The evaluation protocol established was based on the concepts and metrics introduced in [19]. It consist of grouping the classes of into sequential tasks, where each task introduces new classes incrementally and the not-yet-included classes are treated as the unknowns to be detected. This protocol is based on the PASCAL VOC [20] and COCO [21] datasets, which are two of the most commonly used benchmark datasets in object detection. All PASCAL classes and data are considered to be the first task. The remaining 60 classes of COCO are grouped into three successive tasks with semantic drifts that are incrementally introduced to simulate the unknowns arriving at the model's input. Since its inception, this evaluation protocol has been adopted by most contributions dealing with open-world object detection tasks.\nIn the literature related to OWOD, it is important to note that most methods proposed to date hinge on the addition of an \u201cunknown\u201d class to a two-stage object detection model. This newly added class is trained using pseudo-labels obtained by several heuristics or techniques. Thereupon, each contribution to the literature following this approach introduces different al-gorithmic updates to the training algorithm to improve the performance of the model over the \"unknown\" class, while preserving the detection capabil-ities on the known classes.\nThe solution proposed in [5] called ORE uses contrastive clustering, an unknown-aware proposal network and an energy-based unknown identifica-tion to address the challenges of open-world detection. This way ORE is able to predict unknown objects as \u201cunknown\" and incrementally learn new classes as their labels become available, without forgetting previously learned"}, {"title": "2.3. Contribution", "content": "In the light of the reviewed OWOD literature, it becomes evident that there is a clear trend towards using two-stage models that undergo retraining to acquire the capability to detect unknown objects. To avoid this computa-tional burden, it is imperative to analyze the performance of OoD techniques for one-stage models which do not require retraining of the object detection model. In our research, we align our approach with the work of [25], by focusing exclusively on the first task of OWOD (the ability to detect un-known objects), without subsequently retraining the model with these newly identified classes. Our contributions in this regard can be summarized as follows:\n\u2022 We explore the effectiveness of classic post-hoc OoD techniques on one-stage object detectors. Specifically, we investigate the performance of tra-"}, {"title": "3. Open-World Object Detection by Feature Map Characterization", "content": "In this section we introduce our proposed OoD detection algorithm which, given its reliance on the feature maps within the model, is hereafter referred to as the FMap detector. Subsection 3.1 presents the general workflow of FMap, while Subsection 3.2 details in depth each of its compounding algo-rithmic steps. Next, Subsection 3.3 elaborates on the benefits of employing Supervised Dimensionality Reduction (SDR) with our detector. Finally, Sub-section 3.4 outlines an approach to enhance the capabilities for identifying"}, {"title": "3.1. High-level Description of FMap", "content": "We begin by pausing at the general workflow followed by FMap, which is illustrated in Figure 1. In essence, FMap characterizes the activation space at the output of a single-stage object detection model, i.e., we character-ize the feature maps computed by the model for its input. In doing so, it is important to first note that modern single-stage object detection models employ a Feature Pyramid Network (FPN) [26] to enhance their ability to detect objects at various scales. Therefore, the characterization of activations made by FMap must account for this feature. In the case of two-stage detec-tors, feature maps of different strides are merged and standardized to have a uniform number of output channels or dimensions after the FPN. In con-trast, mainstream one-stage detectors do not perform this standardization, resulting in each stride having unique dimensions and producing predictions independently.\nSince FMap is tailored for one-stage detectors, each stride is characterized separately within its own space as each prediction emanates from only one of the strides. This means that features from different strides are processed by distinct layers, and hence may not share the same number of dimensions or the same semantic meaning. The workflow of FMap comprises the following steps:\n1. First FMap iterates over the in-distribution (ID) data \u2013 namely, the train-ing dataset - to collect all the extracted feature maps of objects correctly predicted by the trained model, together with the stride from which each object prediction is produced.\n2. Subsequently, for each class and stride, we cluster its embedding space and aggregate all object embeddings inside every cluster into a centroid, which is done by computing the mean of every feature within the cluster. This yields multiple centroids for each class in each stride, serving as the representatives of the concepts in the embedding space corresponding to that class.\n3. The score for each query sample is defined as the minimum distance of the instance's features to the centroids of the predicted class in the respective stride (since each prediction originates from only one stride). Based on"}, {"title": "3.2. Low-level Description of FMap", "content": "This section provides a more detailed description of the FMap detector, along with a schematic summary in Algorithm 1. As previously mentioned, the first step is to characterize the ID by creating the representative features or centroids of each class in each stride by making use of clustering techniques. Hence, we start extracting the features from the ID samples by iterating over the training dataset $\\mathcal{D}_{tr}$ and collecting the predictions. The dataset consists of images $x \\in \\mathbb{R}^{W\\times H\\times C}$ with objects represented by targets $y = \\{b, c\\}$, where $b \\in \\mathbb{R}^4$ denotes the bounding box coordinates and $c\\in \\{1, 2, ..., C\\}$ the class or category of the object. $C$ represents the number of classes in $\\mathcal{D}_{tr}$. Each image can contain one or multiple targets (labeled objects). Among all the predictions $y = \\{b,c\\}$ generated by the model, only the correctly predicted ones are considered for feature extraction, i.e., $\\mathcal{Y}_{correct} = \\{y \\text{ such that } c = \\hat{c} \\text{ and } IoU(b, \\hat{b}) \\geq \\Gamma_{I o U}\\}$, where $IoU$ denotes Intersection over Union and $\\Gamma_{I o U} \\in \\mathbb{R}(0,1)$ is a predefined threshold. Features $f \\in \\mathbb{R}^{D_{\\varphi}}$ are extracted from the feature maps $v$, where $D_{\\varphi}$ represents the dimensionality of the stride indexed by $\\varphi \\in \\{1, 2, ..., \\Phi\\}$ being $\\Phi$ the total number of strides (line 5 of Algorithm 1).\nTo perform the extraction of the features corresponding to each predic-tion, we utilize the RoIAlign operation as described in [27]. The inputs are a bounding box $b$, the desired output size (height and width) for the features $f$ of the box, the complete feature maps $v$, and the ratio between the spatial resolution of the bounding boxes (height and width of the original image) and the spatial resolution of the feature maps (their height and width). The operation outputs the desired features $f$ specific to the bounding box $b$ out of the whole feature maps $v$. It is crucial to emphasize that each prediction originates from a specific stride, thereby implying that its features possess the dimensionality of that specific stride. In particular, the number of channels are maintained after the RoIAlign operation.\nFollowing the process outlined in the previous subsection, we obtain a collection of features $f_{\\varphi,c}^m$ for each stride $\\varphi$ and class $c$. These features are independently grouped using a clustering algorithm to yield a number $M_{\\varphi,c}$ of clusters $\\{Q_{m,\\varphi,c}\\}_{m=1}^{M_{\\varphi,c}}$ (line 10 of Algorithm 1). Features for each (class, stride) combination are clustered separately. The number of clusters per class can be established as a hyper-parameter, or instead determined by optimiz-ing an internal clustering validation metric. Next, by using an aggregation function $f_{agg}(\\cdot)$, we aggregate the features of all samples in each cluster, and"}, {"title": "3.3. Supervised Dimensionality Reduction", "content": "Since the algorithm operates on feature maps that come from the feature extraction part of an object detection model, it typically deals with high-dimensional features, namely, high values of $D_{\\varphi}$ in the previously introduced algorith. The large dimensionality of feature maps can make feature maps become increasingly sparse due to the large volume of the feature space grows, making their distance-based characterization less effective towards detecting OoD objects.\nTo alleviate this effect, we propose to apply SDR techniques to the ex-tracted features $f$, so that FMap is able to distinguish between ID and OoD features more accurately. SDR techniques combine unsupervised dimension-ality reduction algorithms with supervised loss functions to produce low-dimensional representations of the data, while preserving clear class bound-aries. The SDR method can be represented as a model or trainable function"}, {"title": "3.4. Enhanced Unknown Object Localization", "content": "One key aspect of the usage of OoD techniques for unknown object detec-tion is their reliance on the predictions generated by the single-stage model, which in turn depend on the inference confidence threshold, a user-selected hyperparameter. The inference confidence threshold represents the minimum confidence value a prediction must achieve to be considered valid and subse-quently be output by the model. Specifically, these OoD methods can only identify an unknown object if it has been incorrectly predicted as one of the known classes, at which point the algorithm must detect this prediction as an OoD instance or unknown object. Hence, the inference confidence threshold controls the relation between the precision in detecting known objects and the recall of unknown objects: lowering its value would probably result in more unknown objects detected, but at the penalty of increasing the missed classifications of known objects.\nTo reduce this dependency, we propose an unsupervised algorithm to generate proposals for potential unknown objects regardless of the inference"}, {"title": "4. Experimental Setup", "content": "In order to assess the performance of the proposed FMap detector, we design an extensive experimentation aimed to inform the responses to four research questions (RQ), formulated as follows:\n\u2022 RQ1: Which is the optimal configuration for the proposed FMap OoD detector?\n\u2022 RQ2: How does FMap perform when compared to logits-based post-hoc OoD detection methods in single-stage object detectors?\n\u2022 RQ3: Does a fusion of feature-based methods with logits-based methods outperform other potential ensemble configurations?\n\u2022 RQ4: How do unknown object detection algorithms implemented on single-stage models perform when compared to the state of the art?\nThe remainder of this section offer details on the benchmark (Subsection 4.1, evaluation metrics (Subsection 4.2), implementation details (Subsection 4.3), post-hoc methods for comparison (Subsection 4.4) and fusion strategies"}, {"title": "4.1. Evaluation Benchmark", "content": "The evaluation is based on the UOD benchmark presented in [25]. It follows the practice of previous works on the topic of open-world object de-tection by using the PASCAL VOC dataset [20] as the training ID dataset, which contains annotations of 20 object categories. For test purposes, the UOD benchmark uses two subsets of the COCO dataset [21], namely COCO-00D and COCO-Mix. The former contains only objects that are unknown, whereas the latter mixes both known and unknown instances. In both cases, un-"}, {"title": "4.2. Evaluation Metrics", "content": "To gauge the performance of the models in detecting known and unknown objects, we consider several metrics widely used in the literature related to this area [25]. To evaluate the performance of known object detection we consider the mean Average Precision (mAP) considering that an object is spatially detected in the image when the IoU between a bounding box prediction and the true bounding box of the object is at least 0.5. In order to evaluate the performance in OoD or unknown object detection, we first define $TP_u$ as the true positive proposals of unknown objects (i.e., correctly detected unknowns); $FN_u$ for false negative proposals (namely, unknowns detected as knowns), and $FP_u$ for false positive proposals (corr. known objects detected as unknown). Based on these definitions, we utilize the following performance metrics:\n\u2022 The Unknown Average Precision (U-AP), the average precision computed only over the unknown class.\n\u2022 The Recall Rate (U-REC) and Precision Rate of Unknown objects (U-PRE), defined as:\n$U-\\text{REC} = \\frac{TP_u}{TP_u + FN_u}$,\n$U-\\text{PRE} = \\frac{TP_u}{TP_u + FP_u}$"}, {"title": "4.3. Implementation Details", "content": "In terms of sotware implementation, we rely on the model templates pro-vided by the Ultralytics library [30], selecting YOLOv8 as the one-stage object detector used throughout the experiments. The number of strides $\\zeta$ is 3. We trained the model from scratch over the PASCAL VOC ID training dataset for 300 epochs, using a batch size equal to 16.\nRoIAlign and aggregation operations. We use average as the operation to perform the aggregation of the features $f_{agg}(\\cdot)$ in the vanilla FMap method. For RoIAlign, it is necessary to choose the height and width of the resulting features. We opt for a one-pixel (1 \u00d7 1) output size, hence every prediction's features will be of size equal to the number of channels in the corresponding stride.\nDetermining the thresholds for the OoD methods. FMap requires determining a threshold for each class and stride. Therefore, we need sufficient samples in each case for the thresholds to be representative of the ID data. Therefore, instead of only using the validation split from the training dataset (PASCAL VOC in this case), we harness all samples within the train and validation datasets to compute these thresholds. Furthermore, the TPR used to de-termine the thresholds $\\lambda^{\\varphi, c}$ is set at 95%, which is a common choice in the literature."}, {"title": "4.4. Post-hoc OoD Detection Methods", "content": "The post-hoc OoD detection methods implemented for our experimental benchmark are selected based on their model-agnostic nature, i.e. they can be directly applicable to any type of classification branch within a neural network model, without any ambiguity of how they should implemented.\nPost-hoc techniques like MSP [12], Energy [14] and ODIN [13], which only rely on the output of a classification branch, meet the criteria of being directly applicable to a one-stage object detector. We refer them as logits-based methods, as they only operate on the logits of the classification branch to compute their OoD scores. These three mentioned methods are the ones included in our benchmark. In case of ODIN, the input perturbation is"}, {"title": "4.5. Fusion Strategies", "content": "In response to RQ3, we investigate the performance of ensembles of feature-based (like the proposed FMap) and logits-based OoD techniques. The fusion of FMap with the considered post-hoc algorithms finds its mo-tivation in the results of [9], where fusion strategies were also explored for detecting OoD instances in image classification tasks.\nWhen fusing two OoD techniques, it is crucial to establish a criterion to resolve discrepancies between the predictions of both methods. One option can be to employ an AND criterion, by which a sample is declared to be OoD if both methods classifies it as such. This approach typically results in increased precision (U-PRE) but decreased recall (U-REC) for unknown objects. In contrast, an OR criterion would yield a sample classified as OoD if any of the methods (or both of them) predicts the sample as such. Con-sequently, an OR fusion rule potentially increases the recall at the expense of precision for both known and unknown objects. Figure 3 summarizes the operational mechanics of the AND and OR voting strategies."}, {"title": "5. Results and Analysis", "content": "We now proceed by presenting and discussing on the experimental results obtained to address the RQs posed in the previous section. First, we aim to determine which FMap configuration performs best (RQ1, Subsection 5.2). Then, we compare FMap to existing post-hoc methods (RQ2, Subsection 5.3). Subsequently, we combine FMap with post-hoc methods to ascertain if the resulting ensemble of feature-based and logits-based methods elicits better results than when used separately (RQ3, Subsection 5.4). Finally, we compare our findings against state-of-the-art OoD detection methods de-signed for object detection models (RQ4, Subsection 5.5)."}, {"title": "5.1. Preamble", "content": "Since this paper gravitates on single-stage object detection models with open-world detection capabilities, we focus on finding the optimal configura-tion of the selected YOLOv8 object detector by balancing the performance in detecting both known and unknown objects. Hence, we focus on mAP as the representative score quantifying the capability of the model to detect known instances, whereas U-F1 is the indicator of the method's effectiveness in recognizing unknown objects. Specifically, for the latter we use the sum of unknown F1 (hereafter referred to as U-F1 in the text and U-F1sum in the plots) obtained on both COCO-OoD and COCO-Mix, while mAP is calculated only from COCO-Mix since COCO-00D includes only annotations for unknowns objects.\nBuilding on these methodological choices, it is important to highlight the insight presented in Subsection 3.4, where we emphasize the significance of the inference confidence threshold. This threshold can be regarded as a variable that calibrates the balance between the model's known and unknown object detection capabilities. Thus, during the performance assessment of the single-stage model (RQ1, RQ2 and RQ3), we aim to delineate the trade-off between known and unknown detection metrics arising when configuring the inference confidence threshold. We represent this trade-off by means of two-dimensional scatter plots, with the different configurations of cluster methods and distance metrics distinguished by unique markers and colors. For each configuration, several inference confidence thresholds are tested and plotted. The optimal configurations are those which are non-dominated by any other configuration/technique (in the Pareto sense), i.e. those for which there is no other configuration/technique that improves one objective without worsening"}, {"title": "5.2. RQ1: Which is the optimal configuration for FMap?", "content": "To address this first research question, we identify the non-dominated configurations for the FMap method for its naive (vanilla) version (Algorithm 1), and when expanded with the SDR (Subsection 3.3) and EUL (Subsection 3.4) techniques. Subsequently, we compare these optimal configurations to delineate the final front of non-dominated FMap configurations.\nVanilla FMap. The initial analysis involves the vanilla version of the FMap method, examined in conjunction with various clustering methods and dis-tance metrics. The comparative results are depicted in Figure 5. A first glance at this plot verifies that the choice of clustering method (indicated by color) significantly impacts on the performance of the model in detect-ing known objects (mAP). Generally, aggregating all features into a single large cluster per class and stride (denoted as the One cluster method, shown in blue) results in higher mAP and lower U-F1 scores. Conversely, con-figurations that generate multiple clusters (thereby increasing the number of centroids for comparison) typically exhibit reduced mAP scores, but en-hanced performance in detecting unknown objects. Notably, increasing the number of clusters from 2 to 3 \u2013 which often occurs in our experiments with both KMeans (in red) and HDBSCAN (in orange) to forcing 10 clusters in KMeans (denoted as KMeans10, in green) leads to a further decrease in mAP while marginally improving U-F1. These obserbations are corroborated by examining the non-dominated configurations. Configurations yielding the highest mAP predominantly utilize the One clustering method, while those achieving larger U-F1 scores generally employ a greater number of clusters. Notably, the best U-F1 score is achieved using KMeans10. Furthermore, with respect to the A-OSE metric (which quantifies the number of unknown in-stances erroneously classified as known objects) the depicted results expose a clear trend: an increase in the number of clusters correlates with a reduction in classification errors for unknown instances, i.e., lower A-OSE values.\nAdditionally, an analysis of the impact of distance metrics reveals signifi-cant findings. The L\u2081 and L2 distance metrics typically enhance the detection"}, {"title": "5.3. RQ2: How does FMap perform when compared to logits-based post-hoc OoD detection methods in single-stage object detectors?", "content": "Our discussion follows by evaluating the performance of the optimal con-figurations of FMap found in the previous section, and by comparing it to that of post-hoc or logits-based techniques. These methods also depend on the inference confidence threshold set for the single-stage object detector, prompting the testing of several confidence thresholds for each post-hoc al-gorithm.\nThe results of this performance comparison are depicted in Figure 10. Among the post-hoc methods, MSP emerges as the top performing one. When compared to the FMap method at comparable levels of unknown F1"}, {"title": "5.4. RQ3: Does a fusion of feature-based methods with logits-based methods outperform other potential ensemble configurations?", "content": "The results achieved in response to RQ2 suggest an important question. Although the FMap method is marginally outperformed by post-hoc detec-tion techniques, could it potentially serve as a superior choice for method fusion, as opposed to relying solely on the more effective logits-based meth-ods for ensemble strategies?"}, {"title": "5.5. RQ4. How does the performance of unknown object detection algorithms implemented on single-stage models compare to that of the SOTA?", "content": "We conclude our experiments with RQ4, for which we compare the best performing FMap-based methods discovered so far to state-of-the-art meth-ods in the UOD benchmark [25]. For the sake of readability in the reported results, we have selected the most recent and well-performing comparison baselines, and we have also included the most competitive results of the vanilla, SDR and EUL versions of FMap.\nResults are presented in Table 2. When examining the detection out-comes for known objects, it becomes evident that the mAP values for the"}, {"title": "6. Conclusions and Future Research Lines", "content": "This work has gravitated on the detection of unknown objects in single-stage object detector models, a problem that closely relates to the open-world object detection paradigm. Specifically, we have proposed a new unknown object detection method (FMap), which characterizes the feature maps ex-tracted by object detection models to decide whether the object predictions issued by such models correspond to known (ID) or unknown (OoD) objects. In addition, we have designed two ways of improving the performance of the vanilla FMap method. The first reduces the dimensionality of extracted fea-"}]}