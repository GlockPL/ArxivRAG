{"title": "MOS-Attack: A Scalable Multi-objective Adversarial Attack Framework", "authors": ["Ping Guo", "Cheng Gong", "Xi Lin", "Fei Liu", "Zhichao Lu", "Qingfu Zhang", "Zhenkun Wang"], "abstract": "Crafting adversarial examples is crucial for evaluating and enhancing the robustness of Deep Neural Networks (DNNs), presenting a challenge equivalent to maximizing a non-differentiable 0-1 loss function. However, existing single objective methods, namely adversarial attacks focus on a surrogate loss function, do not fully harness the benefits of engaging multiple loss functions, as a result of insufficient understanding of their synergistic and conflicting nature. To overcome these limitations, we propose the Multi-Objective Set-based Attack (MOS Attack), a novel adversarial attack framework leveraging multiple loss functions and automatically uncovering their interrelations. The MOS Attack adopts a set-based multi-objective optimization strategy, enabling the incorporation of numerous loss functions without additional parameters. It also automatically mines synergistic patterns among various losses, facilitating the generation of potent adversarial attacks with fewer objectives. Extensive experiments have shown that our MOS Attack outperforms single-objective attacks. Furthermore, by harnessing the identified synergistic patterns, MOS Attack continues to show superior results with a reduced number of loss functions.", "sections": [{"title": "1. Introduction", "content": "Deep neural network (DNN) models have significantly advanced the field of computer vision [15, 26, 28, 38], yet they are vulnerable to adversarial examples [20, 43]. Such examples are inputs that have been subtly modified to cause misclassification, potentially leading to catastrophic consequences in real-world scenarios [7, 16, 19]. Consequently, the development of sophisticated adversarial attack algorithms is crucial for evaluating and enhancing the robustness of these models [11, 34, 52]. However, devising these algorithms presents inherent challenges due to the non-differentiable nature of the original optimization problem, necessitating the use of surrogate loss functions [21] to facilitate gradient-based adversarial attacks [11, 20, 34].\nThe metric for measuring misclassification is the non-differentiable 0-1 loss function, which surrogate loss functions endeavor to approximate [30]. Adversarial attacks are designed to generate a perturbation \u03b4 that causes the misclassification of an input x with its corresponding label y. This can be formulated as:\n$\\max_{\\delta\\in B} L_{0-1}(h_\\theta(x + \\delta), y),$\nwhere $h_\\theta$ represents the DNN model parameterized by \u03b8, $L_{0-1}$ denotes the 0-1 loss function, and B is the set of allowable perturbations.\nConsidering the computational intractability of the problem in Equation (1) [3], contemporary research commonly employs a differentiable surrogate loss function in place of the 0-1 loss function. This approach enables the utilization of gradient-based optimization techniques to address the resultant surrogate optimization problem. It has propelled considerable progress in gradient-based algorithms, including the Fast Gradient Sign Method (FGSM) [20], Projected Gradient Descent (PGD) [34], and Carlini & Wagner (C&W) attack [8]. Notably, the versatility of the PGD attack has increased with the adoption of diverse surrogate loss functions (APGD-CE, APGD-DLR) [41] and the integration of sophisticated optimization techniques (ACG) [51]. These developments have given rise to more sophisticated adversarial methods.\nWhile single-objective attacks have attracted considerable attention, there is an emerging trend towards integrating multiple loss functions to bolster the attack's efficacy. Some early endeavors include using multiple targeted loss functions to guide untargeted attack [21] and the strategic alternation of loss functions in the attack process[2]. Furthermore, the adoption of diverse surrogate loss functions such as GAMA [41], \u0412\u0421\u0415 [46], and DLR [11] has been instrumental in advancing adversarial attacks.\nDespite the potential advantages for incorporating multiple loss functions, direct optimization with a vast array of adversarial examples is inefficient. Moreover, the methodology for targeting suitable loss functions to mount effective adversarial attacks is lacking. Therefore, it is imperative"}, {"title": "2. Background", "content": "Adversarial attacks encompass methods that create adversarial examples, which are used to assess and enhance model robustness [11, 34]. A white-box threat model is often considered for evaluating adversarial robustness, where the adversary has full access to the model's architecture, parameters, and gradients. While white-box existing strategies mainly focus on one surrogate loss function [1, 18, 25, 51], a recent trend is the integration of multiple loss functions into the attack paradigm [5, 14, 33, 42, 44].\nSingle-Objective Attacks. White-box attack methodologies typically employ a singular surrogate loss function, focusing on optimization to craft adversarial examples. Established strategies include the FGSM [20], C&W attack [8], and PGD attack [34]. Croce et al. proposed a novel parameter-free approach, Auto-PGD (APGD) attack, utilizing both Cross Entropy (CE) and the Difference of Logits Ratio (DLR) loss functions. These were subsequently incorporated into the AutoAttack framework as APGD-CE and APGD-DLR [11]. Expanding upon this, Yamamura et al. enhanced APGD with conjugate gradient techniques, resulting in the creation of the powerful Auto Conjugate Gradient (ACG) attack [51].\nMulti-Objective Attacks. Recent advancements in adversarial research have involved the integration of multiple surrogate loss functions into the attack framework. Gowal et al. introduced multiple targeted losses to enhance untargeted PGD attacks [21]. Further, work by Nikolaos et al. established that the strategic variation of surrogate loss functions considerably improve adversarial attack performance [2]. However, these studies typically lack a systematic approach and a solid theoretical underpinning for managing multiple losses.\nConcurrently, researchers have expanded the adversarial attack framework by introducing other types of objectives. Williams et al. investigated the inclusion of additional norm constraints [48], while Guo et al. and Liu et al. have investigated the trade-off between perturbation intensity and confidence measures [24, 33]. These efforts have contributed to the development of more diversified attack methodologies.\nOur approach represents the first attempt to systematically incorporate multiple loss functions into adversarial attacks and optimize the corresponding multi-objective optimization problem using a minimal set of examples via smooth set-based optimization techniques."}, {"title": "3. Multi-Objective Set-based Attack", "content": "In this section, we propose the problem formulation of the smooth set-based approach for multi-objective adversarial attacks. We begin by defining the multi-objective adversarial attack, which employs multiple surrogate loss functions, as a multi-objective optimization problem. Subsequently, we introduce the decomposed subproblems and identify three optimization challenges. Finally, we propose the formulation of the smooth set-based optimization problem as a solution to the challenges posed by the multi-objective nature of adversarial attacks.\nThis study seeks to simultaneously optimize multiple surrogate loss functions, rather than relying on a singular loss function, to craft adversarial examples. Given m loss functions L1,..., Lm, we define a multi-objective optimization problem as follows:\n$\\max_{\\delta\\in B} f(\\delta) = (f_1(\\delta), ..., f_m(\\delta)),$\n$f_i(\\delta) = L_i(h_\\theta(x + \\delta), y), \\forall i \\in \\{1,...,m\\}.$\nThe notation remains consistent with the single-objective scenario as depicted in Equation (1). Furthermore, this paper adopts the extensively utilized $l_\\infty$-ball as the constraint set for perturbations, denoted by B = {\u03b4 : $||\\delta||_\\infty < \\epsilon$}.\nExamples with higher values across multiple surrogate loss functions are more susceptible to misclassification by the model. In existing literature, this statement is supported by frequent misclassifications of adversarial examples with high values on singular loss functions [11, 34, 51].\nNevertheless, since there is often no single solution that maximizes all the loss functions simultaneously, a set of best trade-off solutions becomes necessary. This set of solutions is called the Pareto set, and the corresponding values of the objective functions are called the Pareto front. A formal description of Pareto optimality is delineated below:\nDefinition 3.1 (Pareto Optimal). A solution $\u03b4^*$ is Pareto optimal if there is no other solution \u03b4 such that $f_i(\u03b4) \\geq f_i(\u03b4^*)$ for all i \u2208 {1,...,m} and $f_i(\u03b4) > f_i(\u03b4^*)$ for at least one i \u2208 {1,...,m}."}, {"title": "3.2. Decomposition-Based Optimization", "content": "In this research, we employ the Tchebycheff decomposition to transform the multi-objective problem into a suite of single-objective subproblems. Contrary to the linear scalarization method, the Tchebycheff approach is capable of targeting any location on the Pareto front. This is well-recognized in the discipline of multi-objective optimization [13, 35, 53]. By adopting this method, given K weight vectors w\u2081,..., wk, the k-th decomposed subproblem is defined as follows:\n$\\max_{\\delta\\in B} g_k(w_k) = \\min_i w_{ki}|f_i(\\delta) \u2013 z_i|,$ \nwhere $w_{ki}$ is the i-th element of the k-th weight vector, and $z_i$ denotes the ideal value for the i-th objective. Upon solving these subproblems, a set of solutions correlated with the weight vectors is obtained. This set can approximate the Pareto set, as illustrated in Figure 1a.\nThe Tchebycheff method is instrumental in identifying both convex and non-convex parts of the Pareto front with vertical contour lines [45], as demonstrated in Figure 1a. Nonetheless, it presents three challenges in optimization:\n\u2022 Complexity: Accurate approximation of the Pareto front necessitates multiple points, exceeding the number of objectives (> m).\n\u2022 Ambiguity: The selection of appropriate weight vectors is challenging.\n\u2022 Non-differentiability: The function $g_k$ contains non-differentiable points."}, {"title": "3.3. Smooth Set-based Optimization", "content": "To address the challenges associated with Tchebycheff decomposition, we propose a formulation that leverages a smooth set-based optimization approach. The primary issue is the number of adversarial examples needed to maximize the surrogate loss functions. We tackle this by deliberately selecting a set of K adversarial examples, with K < m. Additionally, we default the weight vector to an all-ones configuration to eliminate the ambiguity in selecting the weight vector. Lastly, we smooth the optimization problem to circumvent non-differentiability issues.\nSet-based Optimization Suppose we have a set of K adversarial examples A = {$\u03b4_1,..., \u03b4_K$} to accommodate multiple objectives and one weight vector w for specifying the contour lines. The set-based optimization problem can be formulated as:\n$\\max_{\\Delta} g(A|w) = \\min_i w_i| \\max_{k_i} f_i(\\delta_{k_i}) - z_i|,$ \nwhere $w_i$ is the i-th element of the weight vector, and $z_i^*$ is the optimal value of the i-th objective function.\nA Geometric Interpretation. The inner maximization problem as formulated in Equation (4) allows each perturbation vector, \u03b4 \u0395\u0394, to impart its dimensionality upon the objective function. We conceive a 'virtual adversarial example' as a combination of the most advantageous dimensional attributes of adversarial examples. The essence of the set-based optimization procedure lies in pushing this virtual adversarial example towards extreme points along the contour lines, as depicted in Figure 1b.\nWe investigate the relationship between the number of adversarial examples K and the number of loss functions m. Specifically:\n\u2022 K <m: A smaller number of adversarial examples are utilized to address a multitude of objectives. This approach enables optimization of the functions using reduced resources. In the extreme scenario where K = 1, a single solution must fulfill all objectives.\n\u2022 K = m: there exists a theoretical optimal solution comprising the individual optimal adversarial examples for each objective function. Through proper optimization, this ideal state may be achieved.\nSo far, the first two challenges of decomposition-based optimization have been addressed by the set-based optimization problem. However, the third challenge remains unresolved. This can lead to oscillation in the optimization process, as illustrated in Figure 1b. Therefore, we need to design a smooth approximation of the set-based optimization problem.\nSmooth Set-based Optimization To smooth the above optimization problem, we need to take advantage of smooth max and smooth min operators:\n$\\max \\{x_1,...,x_m\\} \\approx \\mu \\log(\\sum_{i=1}^m e^{x_i/\\mu}),$\n$\\min \\{x_1,...,x_m\\} \\approx -\\mu \\log(\\sum_{i=1}^m e^{-x_i/\\mu}),$\nwhere \u03bc is a smoothing parameter. A proof of the above approximation can be found in [6].\nUsing the above operators, the objective function in Equation (4) can be approximated as:\n$g(A|w) = \\min_i w_i| \\max_{k_i} f_j (\\delta_{k_1}) - z_i|$\n$\\approx -\\mu \\log(\\sum_{i} e^{-(W_i/\\mu \\log(\\sum_{k=1}^{K} e^{f_i(\\delta_k)/\\mu}) - z_i)/\\mu})$\nFurthermore, if we consider $z_i^* = 0$ and a uniform weight vector with $w_i = w_j, \\forall i, j$, we can get our final optimization problem as:\n$\\max_\\Delta g(A) = -\\mu\\log( \\sum_i (\\sum_{k=1}^K e^{f_i(\\delta_k)/\\mu})^{-1})$\nThe above formulation eases the optimization process and avoids oscillations in the optimization process, which is analyzed in the multi-objective literature [32]. We illustrate the smoothed set-based optimization problem along with a possible optimization trajectory in Figure 1c."}, {"title": "4. Methodology", "content": "By formulating a smooth set-based optimization problem, we can now apply gradient-based optimization algorithms for its efficient resolution. Within the domain of adversarial attacks, our framework incorporates the well-known APGD algorithm [11]. In this section, we provide a detailed explanation of our attack, as outlined in Algorithm 1."}, {"title": "4.1. MOS Attack: Implementation by APGD", "content": "Initialization. The initialization process involves specifying the input parameters and determining the initial adversarial examples. We follow a procedure similar to that used in the APGD. However, our approach take as input 1) a set of adversarial examples A, and 2) an objective function g(A) defined in Equation (7).\nMomentum-based Update Rule. We adopt the same momentum-based update rule as in APGD, which is considered to be stable and efficient. The details are delineated in lines 9 and 10 of Algorithm 1. Our modification addresses the optimization of a set of adversarial examples rather than a single example. Therefore, we have adjusted the update rule to: 1) optimize X and A concurrently, and 2) implement a set-based projection operator.\nOptimzation Representation. Considering our function g incorporates A and subsequent projection requires X's range, concurrent optimization of both is essential. Notably, the statement in line 9 consistently applies because $\\nabla_X g(\\Delta) = \\nabla_{\\Delta} g(\\Delta)$, with $\\Delta \\gets X + x$."}, {"title": "4.2. Automated Synergistic Pattern Mining", "content": "Few solutions automatically maximize different loss functions in groups in smooth set-based optimization [31]. To mine these loss synergistic patterns, we propose an automated mining method. This method includes two steps: 1) determining the dominant examples that contribute to the loss maximization, and 2) determining the synergistic pattern of these dominant examples.\nDetermining Dominant Examples. With a set of K perturbations A = {$\u03b4_1,..., \u03b4_K$} from the MOS Attack, we aim to identify the dominant perturbations that maximize the loss functions. Formally, we want to find an index vector \u03b2 = [\u03b21,..., \u03b2K], \u03b2i \u2208 {0,1}, \u2200i, for specifying a subset of perturbations \u0394\u03b2 = {$\u03b4_i|\u03b2_i = 1$} that still maximize the loss functions.\nWe first perform min-max normalization on the loss functions $f_i(\\delta_k)$, \u2200i, and then the above formulation can be rewritten as a bi-objective optimization problem:\n$\\min_{\\beta} (\\sum_{i=1}^m \\frac{\\max_{k=1}^K \\beta_k f_i (\\delta_k)}{\\sum_{k=1}^K f_i (\\delta_k)}, ||\\beta||_0)$,\nwhere $\\bar{f_i} (\\delta_k)$ is the normalized loss function. The first term serves to minimize the optimization gap. The $l_0$ norm, which is the number of non-zero elements in a vector, aims to minimize the number of selected examples.\nSmooth Relaxation. Since the above problem is an NP-hard combinatorial optimization problem, we relax it by introducing a smooth relaxation. Specifically, we relax the first objective by incorporating smooth operators in Equation (5) and the second objective by replacing the $l_0$ norm with the $l_1$ norm. The relaxed problem is then:\n$\\min_\\beta  \\mu \\log(\\frac{\\sum_{i=1}^m \\sum_{k=1}^{K} e^{f_i(\\delta_k)/\\mu}}{\\sum_{i=1}^m \\sum_{k=1}^{K} e^{\\beta_k f_i(\\delta_k)/\\mu}}) + \\lambda||\\beta||_1,$\nwhere \u039b controls the sparsity.\nThe above problem is smooth and fully differentiable, and we can solve it using gradient-based methods. After the above problem is solved, we can get the dominant example index B. Here, we set a threhold T to further make \u03b2 binary."}, {"title": "4.3. Implementation: Loss Functions", "content": "The final step of implementing our attack is to specify multiple surrogate loss functions. We incorporate a selection of significant loss functions that are well-documented in existing literature [10, 34, 46], along with innovative loss functions that have been identified through rigorous exploration in the domain of loss search [30, 50]. Details of these loss functions can be found in Table 1 and Table 2."}, {"title": "5. Experiment", "content": ""}, {"title": "5.1. Experiment Setup", "content": "Datasets and Models. We employed 17 distinct from RobustBench [12], which includes 12 models [4, 27, 36, 37, 40, 47] trained on the CIFAR-10 [28] dataset and 5 models [39, 49] based on ImageNet [15] dataset. For performance evaluation, we used all 10,000 test images from the CIFAR-10 validation dataset and 5,000 images from ImageNet validation dataset. To enable direct comparison with the reported accuracy of the ACG attack, we preserved the same image indexing for the ImageNet dataset as [51].\nComparative Attacks. For comparative purposes, we incorporate the widely recognized APGD-CE attack, the state-of-the-art ACG-CW, and the comprehensive APGD-All attack. The latter aggregates optimal outcomes from an ensemble of eight distinct APGD attacks, each employing unique loss functions from Table 1.\nAttack Parameters. Notably, the number of iterations for our implemented attacks, including MOS Attack, APGD-CE, and APGD-All, are uniformly set to 50. This choice ensures thorough and rigorous testing of all methods. Ad-"}, {"title": "5.2. Overall Results", "content": "This section presents the comparative results of our proposed MOS-8 attack alongside other competing algorithms, delineating them in terms of Attack Success Rate (ASR).\nSingle-objective v.s. Multi-objective. The results demonstrate that multi-objective approaches outperform single-objective approaches. The most effective single-objective approach is the ACG-CW attack, utilizing 5 restarts and 100 attack steps; however, despite a considerably higher number of attack steps $N_{iter}$ = 100, it only achieved the best ASR in 3 out of 17 instances, with a rate of 3 out of 12 for CIFAR-10 and failing to succeed in any of the 5 cases for ImageNet.\nMOS-8 v.s. APGD-All. The MOS-8 Attack demonstrates a slight superiority over APGD-All. Notably, the MOS-8 Attack achieved comparable or better results with only five adversarial examples, whereas APGD-All utilized eight. MOS-8 Attack achieved an average rank of 1.58 on CIFAR-10 and 1.60 on ImageNet, while APGD-All attained an average rank of 2.00 on CIFAR-10 and 1.40 on ImageNet.\nLoss Functions. APGD-All's findings underscored the superiority of loss 4-7 in Table 1, as attacks using them consistently achieved the highest ASR out of 8 attack across all models on both CIFAR-10 and ImageNet. This observation reveals the importance of selecting appropriate loss functions for adversarial attacks.\nModel Robutness. As the complexity of the model escalates, mirrored by the sophistication of the architecture, the performance disparity between MOS-8 Attack and APGD-CE narrows. This indicates an incremental trend of model robustness, making them more challenging to be attacked."}, {"title": "5.3. MOS Attack Upper Bound", "content": "To evaluate the gap between the performance of our adversarial examples and the hypothetical optimal set delineated in Section 3.3, we conducted an array of APGD attacks on CIFAR-10 dataset. Specifically, we implemented 8 separate APGD attacks, each employing a unique loss function and accompanied by five restarts. For each image in the dataset, we identified the single most effective adversarial example out of the 40 (8 attacks x 5 restarts) created. The ASR was then calculated based on these examples to serve as an indicator of the maximum achievable performance.\nResults. The comparison between the MOS-8 Attack with K = 1, K = 8, and the upper bound is presented in Table 4. Generally, the discrepancy is minimal. Even when a single adversarial example is tailored to address all loss functions in MOS-8 Attack, near-optimal outcomes are achieved. Additionally, leveraging eight adversarial examples brings the results within a negligible difference from the upper bound, with less than a 0.35% gap in ASR."}, {"title": "5.4. MOS Attack Analysis.", "content": "In this section, we employ our framework to conduct an automated analysis of the relationships among various loss functions. The solutions used for analysis is obtained from MOS-8 Attack with K = 8 for both CIFAR-10 and ImageNet datasets. The parameters selected were a sparsity coefficient of \u03bb = 1, a binary threshold of T = 0.85, and a contribution threshold of C = 0.75.\nWe start by identifying the synergistic patterns among loss functions for all model architectures within each dataset. Subsequently, informed by these patterns, we design the MOS-3* attack, utilizing three selected surrogate loss functions."}, {"title": "5.4.1 Loss Synergistic Pattern", "content": "Figure 2 depicts the synergistic loss patterns for CIFAR-10 and ImageNet. A significant portion of the adversarial examples\u201461.3% for CIFAR-10 and 57.8% for ImageNet\u2014contribute to all loss functions, indicating that the majority of solutions optimize them concurrently. This observation suggests a low level of conflict among the loss functions and helps explain why employing a single loss function (K = 1) can yield near-optimal results."}, {"title": "5.4.2 MOS-3* Attack", "content": "The predominant patterns are 0+1+2+3+6+7 and 4+5, as they ranked first and second in both datasets, as shown in Figure 3. We subsequently constructed a compact version of MOS Attack, termed MOS-3* Attack, using losses 5, 6, and 7. For validation of the effectiveness of MOS-3* Attack, we compared it against MOS-3 Attack, which is constructed utilizing the first three loss functions.\nResults. As illustrated in Table 5, MOS-3* Attack outperforms MOS-3 Attack. MOS-3* Attack has achieved better performance across all models with K = 1 adversarial example, surpassing that of MOS-3 Attack with K = 3 adversarial examples. Moreover, MOS-3* Attack's performance is comparable to that of MOS-8 Attack. The above outcomes confirm the value of leveraging loss synergistic patterns to design more efficient yet effective attacks."}, {"title": "6. Conclusion", "content": "Our work has introduced the MOS Attack, a novel multi-objective adversarial attack framework that effectively combines multiple surrogate loss functions to generate adversarial examples. The MOS-8 Attack, utilizing eight such functions, has shown superior performance on CIFAR-10 and ImageNet datasets compared to existing state-of-the-art methods. The framework's automated method for identifying synergistic patterns among loss functions has led to the development of the efficient MOS-3* tri-objective attack. Our contributions offer a scalable and extensible approach to adversarial machine learning, highlighting the potential for more resource-efficient and potent adversarial attack strategies in the future."}]}