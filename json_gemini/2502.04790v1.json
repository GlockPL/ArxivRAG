{"title": "S2-MAD: Breaking the Token Barrier to Enhance Multi-Agent Debate Efficiency", "authors": ["Yuting Zeng", "Weizhe Huang", "Lei Jiang", "Tongxuan Liu", "Xitai Jin", "Chen Tianying Tiana", "Jing Li", "Xiaohua Xu"], "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across various natural language processing (NLP) scenarios, but they still face challenges when handling complex arithmetic and logical reasoning tasks. While Chain-Of-Thought (CoT) reasoning, self-consistency (SC) and self-correction strategies have attempted to guide models in sequential, multi-step reasoning, Multi-agent Debate (MAD) has emerged as a viable approach for enhancing the reasoning capabilities of LLMs. By increasing both the number of agents and the frequency of debates, the performance of LLMs improves significantly. However, this strategy results in a significant increase in token costs, presenting a barrier to scalability. To address this challenge, we introduce a novel sparsification strategy designed to reduce token costs within MAD. This approach minimizes ineffective exchanges of information and unproductive discussions among agents, thereby enhancing the overall efficiency of the debate process. We conduct comparative experiments on multiple datasets across various models, demonstrating that our approach significantly reduces the token costs in MAD to a considerable extent. Specifically, compared to MAD, our approach achieves an impressive reduction of up to 94.5% in token costs while maintaining performance degradation below 2.0%.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) have shown exceptional capabilities across a variety of natural language processing (NLP) tasks. However, even the most advanced LLMs exhibit limitations in complex mathematical reasoning and logical inference scenarios. To address these challenges, researchers have introduced techniques such as Chain-of-Thought (CoT) reasoning which decomposes complex problems into sequential steps, and self-consistency (SC) mechanisms, along with self-correction strategies. Despite these innovations, studies have shown that LLMs still struggle to improve through self-correction alone. An emerging alternative is the Multi-agent Debate (MAD) framework, in which multiple independent agents propose and critique their own answers through rounds of debate, ultimately converging on a more robust consensus. MAD has demonstrated promise in addressing the limitations of LLM self-correction by leveraging diverse agent perspectives to refine answers over iterative discussions. However, as the number of agents and debate rounds increase, the token cost escalates significantly, limiting the scalability of MAD, especially in resource-constrained environments. To alleviate the token cost problem in multi-agent debates, researchers have proposed several strategies. For instance, summarizes agents' outputs at the end of each round, while introduces a \"forgetting\" mechanism, where only the previous round's outputs is retained for future rounds. Another approach, Sparse-MAD (S-MAD), reduces communication overhead by limiting information exchange to neighboring agents. GroupDebate (GD) further reduces token cost by clustering agents into smaller debate groups that exchange intermediate results between groups."}, {"title": "Preliminary", "content": "Problem Definition. MAD, which integrates multiple agents for interactive communication to derive solutions, has demonstrated an effective approach in the application of LLMs, particularly in addressing complex logical reasoning and mathematical problems. Given an input question Q that requires an answer, a total of M participating Language Model (LLM)-based agents engage in a multi-round debate, which is denoted as $A_i$, where $i \\in \\{1,2,..., M\\}$. Given a total of T debate rounds, each round of debate is denoted as $t\\in \\{1,2,...,T\\}$. We define the output of each agent $A_i$ at round t as $O_i^t$. We assume that the upper bound of the token cost for each agent's output is C. Our goal is to maximize answer accuracy while minimizing token consumption through optimizing the interaction patterns among the agents in multi-agent debate.\nMAD-based Methods and Token Cost. (i) MAD involves several steps. Initially, each agent is provided with a question and generates an individual response. These responses then form the new input context for each agent, leading to the generation of subsequent responses. This debate procedure is repeated over multiple rounds, with the final answer derived through majority voting. The token cost complexity is\n$Token_{MAD} = O (MTQ + (M^2T + MT^2)C)$.\n(ii) S-MAD decreases token consumption by sparsifying the fully connected topology of information exchange among agents within the standard MAD framework. Let $P_r$ denote the probability of each edge being removed. The token cost complexity can be represented as\n$Token_{S-MAD} = O (MTQ + (1 - P_r)M^2TC)$.\n(iii) GD reduces token consumption through a group discussion strategy. Let N denote the number of groups and S represent the number of inter-group debate stages. The token cost complexity is computed as $Token_{GD} = (MTQ+ (MRT + MSN)C)$."}, {"title": "Methodology", "content": "In this section, we first introduce the overall process of S\u00b2-MAD along with the details of Decision-Making Mechanism. And then we provide mathematical analysis of the token cost for our method subsequently."}, {"title": "Selective Sparse MAD Process", "content": "As illustrated in Figure 2, the debate process of S2-MAD consists of three main stages: the generation of initial responses, group discussions under the Decision-Making Mechanism and finally reaching consensus.\nInitial Response Generation. In the initial round of debate, each agent is initialized as a LLM. To simulate diverse thought processes and ensure the generation of varied solutions, we employ a random decoding strategy by adjusting the temperature of model. During the first round, all agents independently produce their respective solutions for the given problem."}, {"title": "Grouping Discussion with Decision-Making Mechanism.", "content": "From the second round onward, the Decision-Making Mechanism empowers agents to evaluate whether to engage in debate by assessing the similarity of intra- or inter-group viewpoints relative to their own perspectives. Agents will actively participate in debates when they encounter responses that present differing viewpoints, either from within their group or from other groups. Following these discussions, agents update their answers accordingly based on insights gained during the debate process.\nReaching Consensus. Our approach incorporates an early termination mechanism that allows us to conclude the debate when information has been exchanged between groups and all summarized viewpoints align. Conversely, if discrepancies remain among agents' solutions after the debate concludes, a majority vote will determine which solution is accepted as consensus."}, {"title": "Decision-Making Mechanism", "content": "Upon receiving information, the Decision-Making Mechanism first employs the Similarity Calculation Module to calculate similarities among different pieces of information. Subsequently, it eliminates redundant perspectives of agents through the Redundancy Filtering Module. Finally, Conditional Participation Module is utilized to determine whether the agent should engage in the debate.\nSimilarity Calculation Module. Following the generation of outputs, each agent undertakes a comprehensive assessment of the similarity between its own output and those produced by other agents or groups. This evaluation can be conducted through various methodologies; in this context, we employ a straightforward approach that involves analyzing key points within the outputs to determine their degree of similarity. Specifically, we employ regular expression matching to extract answers from the agents' responses and identical answers are considered to reflect similar viewpoints. Additionally, we also propose an alternative vectorization-based approach, where the responses are vectorized using an embedding model, and the cosine similarity is computed to evaluate the similarity of their viewpoints. In our further experiments, we conduct a comprehensive comparison of the performance of these two methods (See Section 4.3). By focusing on essential elements, agents can effectively gauge how closely aligned their perspectives are with those presented by others.\nRedundancy Filtering Module. Prior to engaging in the debate, agents systematically filter all incoming information to ensure relevance and uniqueness. Outputs that are identified as similar to either their own or previously received viewpoints are promptly discarded from consideration. This rigorous filtering process guarantees that each agent exclusively considers unique perspectives during discussions, thereby minimizing redundancy and fostering a more dynamic exchange of ideas.\nConditional Participation Module. Agents actively engage in debate when divergent viewpoints exist within or among groups, recognizing that such differences enrich the discourse and lead to more robust conclusions. Conversely, if all outputs align consistently without variation, agents will opt to remain silent rather than contribute redundant information. At the conclusion of each round of debate, agents update their knowledge base with accepted viewpoints gleaned from interactions with others; this iterative learning process enhances their ability to respond thoughtfully and effectively in subsequent rounds."}, {"title": "Token Cost Analysis", "content": "In S2-MAD, we summarize the outputs from wht-nin each group at the end of each stage. Given a group of agents $G_j$ which has completed a stage s of debate, we denote its summary as $Sum_j^s$. Since in S2-MAD each agent determines participation based on whether viewpoints are consistent, we define the number of agents with differing viewpoints from the $i^{th}$ agent $D_i$ is:\n$\\sum_{i'\\in G_j} Sim(O_i^{t-1}, O_{i'}^{t-1}) < \\epsilon$,\n$\\sum_{i'\\in G_j} 1$,\n$(s - 1)R + 1 < t < min(sR,T)$\n$\\sum_{i'\\in G_j} Sim(O_i^{t-1}, Sum_j^{s-1}) < \\epsilon$,\n$t = (s - 1)R +1$\n(1)\nTherefore, apart from generating the initial answer, the probability of agent $A_i$ participating in the debate in round t is\n$P_i^t = \\begin{cases}\n1, D_i > 0 \\\\\n0, D_i = 0\n\\end{cases}$\n(2)"}, {"title": "Experiments", "content": "Tasks and Metrics. To evaluate the effectiveness and efficiency of S\u00b2-MAD in mathematical and logical reasoning tasks, we use total token cost and accuracy (ACC) as evaluation metrics across five representative tasks: (1) GSM8K: a dataset designed to assess the model's reasoning ability in complex mathematical problems. (2) MATH: a dataset covers various branches of mathematics to evaluate the capacity to generate problem-solving logic and reasoning processes. (3) MMLU: a dataset that aimed at evaluating the model's overall performance across diverse tasks. (4) GPQA: a multiple-choice question dataset, containing 448 questions across various disciplines. (5) Arithmetic: a datasets evaluates the model's fundamental mathematical reasoning abilities.\nBaselines. We compare our S2-MAD with the following baselines: (1) Chain-of-Thought (CoT); (2) Self-Consistency with Chain-of-Thought (CoT-SC); (3) Multi-agent Debate (MAD); (4) Sparse MAD (S-MAD); (5) GroupDebate (GD).Experiments are conducted with different numbers of agents, rounds, and group strategies. For example, (5,4) represents using 5 agents and 4 rounds, while CoT-SC(40) indicates CoT-SC with 40 reasoning paths.\nImplementation Details. We set the number of intra-group rounds to 2 and use a forgetting mechanism to retain the outputs from the previous round only. At the end of each intra-group discussion phase, we filter and summarize the results from the same groups. Our experiments use GPT-3.5-turbo-0301, GPT-4-0613 and Llama-3.1-8B-Instruct as agents, evaluating all baselines and our S2-MAD in a zero-shot setting. Since the accuracy rate of the Arithmetic dataset reached 100% in a single GPT-4, no further comparison was conducted. Details about the prompts and additional results for GPT-40-mini and GPT-40-0806 are showed in the Appendix C and Appendix D.\nFor the Similarity Calculation Module, we primarily use regular expression matching for the main results and cosine similarity for further analysis, which uses the Bert-base-uncased model to vectorize the agent's responses and calculate the cosine similarity between the responses."}, {"title": "Main Result", "content": "In this section, we conducted a detailed comparison of our method with multi-agent debate methods (including MAD, S-MAD, GD) and single-agent methods (including CoT, CoT-SC). The main observations are as follows: firstly, we compare S2-MAD with MAD. The results presented in Table 1 shows that S2-MAD consistently reduces total token cost across different models while maintaining comparable accuracy, it achieves a reduction of 94.5%, 84.2%, 92.4%, 83.6% and 88.7% on the five datasets respectively compared to MAD. The variation in these percentages is due to the varying difficulty of the questions, which impacts model performance. Furthermore, compared to S-MAD and GD, our approach achieves up to 90.2% and 87.0% less token cost, respectively. This demonstrates that there is a significant amount of redundancy in the information exchange during multi-agent debate, leading to the inefficiency of token cost throughout the debate process.\nWe also conducted a comparison with the single-agent method CoT, achieving a significant improvement in accuracy across five datasets, especially achieving up to 19.3% and 12.6% on GPQA and MMLU dataset. Furthermore, when compared with the Cot-SC method, we successfully reached or exceeded Cot-SC's performance on certain datasets, such as GPQA and Arithmetic, while using relatively fewer token cost."}, {"title": "In-Depth Analysis", "content": "Similarity Calculation Strategy. In this section, we conduct further comparison on similarity calculation strategies using GPT-40-mini. As shown in Table 2, the method of vectorizing the responses and calculating their cosine similarity can achieve the best accuracy and the lowest token cost at a specific threshold. Specifically, on the MATH dataset using GPT-40-mini, setting \u03c4 to 0.40 results in a 2.2% improvement in accuracy and a 94.7% reduction in token cost compared to the MAD method. However, when \u03c4 is set to 0.96, the increased token cost actually leads to a decrease in ACC. Furthermore, as illustrated in the Figure 3, the token cost remains relatively low when \u03c4 < 0.85, but increases sharply thereafter. This is attributed to the prompt's strict formatting constraints on the agent's output, which cause high similarity among outputs. Additionally, we observed that the relative optimal threshold values for accuracy vary across different datasets (e.g., approximately 0.1 for GSM8K and 0.4 for MATH), making it challenging to manually determine the optimal threshold settings."}, {"title": "Ablation Study", "content": "To investigate the impact of different modules and strategies on performance, we conducted ablation experiments on the GSM8K dataset using GPT-3.5-turbo, are shown in Table 4. Our S2-MAD achieved an accuracy of 85.6% with a token cost of 4.73k, demonstrating a significant 72.7% reduction compared to MAD. We further explored sparsity through constrained communication topologies, which slightly decreased accuracy to 84.7% while retaining a similar token cost. Without the early stopping strategy led to a slight accuracy drop to 84.4% but maintained a comparable token cost of 4.99k. In contrast, removing the jump strategy resulted in a more substantial decline in accuracy to 80.8% and an increase in token usage to 9.45k, We hypothesize that this is due to insufficient information diversity, causing redundant checks that impact response accuracy. Finally, although removing the filtering module can increase accuracy to 87.6%, it also leads to an increase in token cost of 13.4k."}, {"title": "Related Work", "content": "LLM Reasoning\nMany studies have explored ways to improve the logical reasoning abilities of LLMs. CoT mimics human thought processes by breaking complex tasks into sequential steps. Many CoT variants extend this framework by generating multiple reasoning chains and selecting the optimal one based on specific criteria. Building on this, Tree-of-Thoughts (ToT) structures the reasoning process into a tree-like path, where each step serves as a decision point, enabling the evaluation of multiple reasoning paths and self-assessment. Similarly, Skeleton-of-Thought accelerates answer generation by first creating a skeletal framework and then completing the content in parallel for each point. Table-of-Thoughts improves reasoning accuracy through structured modeling of the reasoning process. While these CoT-based methods follow structured reasoning paths, more complex reasoning structures have been proposed. For instance, Graph-of-Thoughts models reasoning as a flexible graph, allowing for non-linear task solving beyond the limitations of chains or trees. Methods such as Least-to-Most and Lambada take a problem decomposition approach, breaking tasks into subproblems and solving them step-by-step, where each sub-answer informs the next step. Additionally, frameworks like LReasoner introduce mechanisms that enhance reasoning by extracting logical structures embedded in the problem. Logic-LM combines symbolic solvers to convert natural language into symbolic formulas and introduces a self-refinement module to correct errors during the reasoning process.\nMulti-agent Debate\nMAD is a promising approach to enhance the reasoning capabilities of LLMs by facilitating discussions among multiple agents who collaboratively refine and update generated answers. presents a MAD framework where multiple agents engage in \"tit for tat\" argumentation, managed by a judge, to stimulate divergent thinking in LLMs. Building on this foundation, introduce the FORD framework, which organizes a three-stage debate aligned with real-world scenarios, comprising fair debate, mismatched debate, and round-table debate formats. present a framework that mirrors the academic peer review process, allowing models to autonomously develop solutions, review each other's work, and revise their answers based on feedback. ChatEval , another MAD framework, employs diverse communication strategies and varied role prompts to foster human-like interactions and evaluations in natural language dialogue. Moreover, address cognitive constraints in multi-agent debates by integrating prior knowledge retrieval and a self-selection module, enhancing reasoning capabilities and overall performance. Further exploring collaboration, analyze the autonomous enhancement of negotiation strategies among LLMs through role-playing and iterative AI feedback within a structured negotiation game, highlighting the trade-offs between deal quality and risk management. However, as the number of agents and debate rounds increases, token costs can rise significantly. To mitigate this, suggests summarizing agent outputs at the end of each round for subsequent inputs, and introduces a \"forgetfulness\" mechanism to retain only the previous round's output. The MAD-Sparse approach utilizes a sparse communication strategy, limiting information exchange to adjacent agents. Additionally, GroupDebate promotes a grouping strategy, allowing agents to debate internally while sharing interim results. However, these methods do not enable agents to critically assess the redundancy of incoming information, limiting overall efficiency."}, {"title": "Conclusion", "content": "In this work, we identified the issue of redundant viewpoints among agents in Multi-agent Debate (MAD). To address this, we proposed Selective Sparse Multi-Agent Debate (S2-MAD), a novel strategy designed to reduce token cost by selectively incorporating non-redundant viewpoints from different agents, thereby significantly improving the efficiency of information exchange and debate. Our theoretical analysis verify the effectiveness of S2-MAD, and extensive experiments conducted on five benchmark datasets demonstrate that S2-MAD can significantly reduce token cost in MAD while maintaining competitive performance. For future work, we aim to refine S2-MAD by further optimizing the identification and condensation of non-redundant viewpoints between agents, with the goal of further reducing token cost and enhancing efficiency. Additionally, exploring methods to increase the diversity of thought among agents will be key to improving the overall accuracy of S2-MAD."}, {"title": "Limitation", "content": "Despite the significant reduction in token cost achieved by S\u00b2-MAD, our method has several limitations. First, the reduction in token cost exhibits variability depending on the consistency of agent responses. When agents' answers differ significantly, the efficiency gains are limited, whereas more consistent responses yield a greater reduction in token cost. This variability introduces an element of unpredictability to the system's overall efficiency. Second, the judge module in S\u00b2-MAD is sometimes unable to filter out redundant viewpoints. The module relies on keyword extraction using regular expressions to determine whether agents' outputs convey the same idea. However, when agents express similar views with different wording or synonyms, the judge module may fail to detect these similarities, resulting in redundant exchanges of information. This can undermine the potential gains in efficiency and contribute to token cost redundancy. Therefore, there remains room for improvement in optimizing the token cost of S\u00b2-MAD."}]}