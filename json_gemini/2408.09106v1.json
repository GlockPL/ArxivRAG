{"title": "Fragment-Masked Molecular Optimization", "authors": ["Kun Li", "Xiantao Cai", "Jia Wu", "Bo Du", "Wenbin Hu"], "abstract": "Molecular optimization is a crucial aspect of drug discovery, aimed at refining molecular structures to enhance drug efficacy and minimize side effects, ultimately accelerating the overall drug development process. Many target-based molecular optimization methods have been proposed, significantly advancing drug discovery. These methods primarily on understanding the specific drug target structures or their hypothesized roles in combating diseases. However, challenges such as a limited number of available targets and a difficulty capturing clear structures hinder innovative drug development. In contrast, phenotypic drug discovery (PDD) does not depend on clear target structures and can identify hits with novel and unbiased polypharmacology signatures. As a result, PDD-based molecular optimization can reduce potential safety risks while optimizing phenotypic activity, thereby increasing the likelihood of clinical success. Therefore, we propose a fragment-masked molecular optimization method based on PDD (FMOP). FMOP employs a regression-free diffusion model to conditionally optimize the molecular masked regions without training, effectively generating new molecules with similar scaffolds. On the large-scale drug response dataset GDSCv2, we optimize the potential molecules across all 945 cell lines. The overall experiments demonstrate that the in-silico optimization success rate reaches 94.4%, with an average efficacy increase of 5.3%. Additionally, we conduct extensive ablation and visualization experiments, confirming that FMOP is an effective and robust molecular optimization method. The code is available at: https://anonymous.4open.science/r/FMOP-98C2.", "sections": [{"title": "Introduction", "content": "Molecular optimization plays a crucial role in drug discovery (Xia et al. 2024), which involves the modification and improvement of lead compounds identified through initial screening to enhance their drug-like properties (Wu et al. 2022). Historically, molecular optimization is planned manually according to knowledge and experience in the pharmacology, and optimized through fragment-based screening or synthesis (Chen et al. 2021). However, manual molecular optimization is not easily scalable to different needs and cannot be automated for large-scale optimization; thus, this strategy is insufficient for meeting the demands of current drug discovery (Schneider et al. 2020).\nIn recent years, deep learning (DL) methods, particularly diffusion models (Ho, Jain, and Abbeel 2020), have been observed to effectively optimize molecules that meet specific conditions (Zhou et al. 2024; Gu et al. 2024), with the potential to accelerate traditional paradigms. Molecular optimization can rapidly identify potential drug candidates using existing experimental data and molecular structures, reducing the need for blind experimentation and enhancing research efficiency (Choudhuri et al. 2023). Several molecular optimization methods have been proposed to enhance candidate molecule performance, such as target pocket- (Huang et al. 2024) and property-based molecular optimization (Lee et al. 2024).\nTarget pocket-based molecular optimization methods rely on understanding specific pocket structures and their hypothesized roles in combating diseases (Moffat et al. 2017). Challenges such as a limited number of available targets and difficulty capturing clear structures hinder innovative drug development. In contrast, phenotypic drug discovery (PDD) (Vincent et al. 2022a) does not depend on well-defined target structures and can identify hit compounds with novel and multi-target properties. PDD emphasizes the phenotypic effects of molecules within disease-related biological systems (Sadybekov and Katritch 2023) and has significantly contributed to the discovery of first-in-class drugs (Swinney 2013). By observing the phenotypic changes that molecules induce in cells, tissues, or organisms, PDD identifies potential drugs without requiring prior knowledge about specific"}, {"title": "Method", "content": "Problem Formulation. Molecular optimization aims to enhance a molecule's properties to reveal improved alternatives. For the PDD-based optimization task, the molecule's property is its efficacy in a specific cell line, denoted as IC50.\nLet one molecule be represented as G, the cell line as C = {C1, C2, ..., Cm}, and their IC50 as Y = {Y1, Y2,..., Ym}. The optimized molecule's Y with respect to C is denoted as Y'. Therefore, for a given (G, Ci, Yi), the optimized result y' should satisfy y' < y. Based on our fragment-masked method, we decomposed G into a scaffold Sf and a side chain Sc, where a mask marks the side chain's fragment structure. For one molecule G = (A, X), MX \u2208 R^{|X|} denotes an ordered array of the atom mask X \u2208 R^{|X|}, where the atoms on the scaffold are labeled as 0 and those on the side chain as 1. In addition, MA \u2208 R^{|X|\u00d7|X|} represents an ordered array of the edge mask A \u2208 R^{|X|\u00d7|X|}, with edges on the side chain labeled as 1 and those on the scaffold or between scaffolds and side chains labeled as 0.\nOverview. To generate molecules with a specific distribution under numerical drug response conditions, we employed a regressor-free conditional diffusion method. As illustrated in Fig. 2, we integrated specific conditions about the cell line C and IC50 Y into the scoring estimation to guide the diffusion model. Specifically, to establish the molecules' conditional constraints, we split the molecule into its scaffold and side chain to generate the fragment masks. Then, we performed molecule splitting according to the Murcko scaffold method.\nFinally, during the sampling phase, the drug response and fragment mask jointly constrained the sampling process, generating specific fragments that met the conditions in the mask regions.\nMolecular Conditional Generation\nTypically, the input conditions for molecular optimization methods are categorical. To more precisely and efficiently optimize molecular graphs to specific conditional distributions, our model for conditional generation follows the regressor-free molecular generation method (Li et al. 2024a), which can effectively generate molecules under the given numerical conditions. Moreover, the conditions comprise text labels for the PDD task (i.e., the cell line name and IC50 values) and fragment mask arrays MX and MA.\nTo effectively receive text conditions, we employed a contrastive learning strategy to align the two feature types. The drug, cell line, and fusion drug response encoders are denoted as \u03a6G, PC, and IF respectively.\nMoreover, the text encoder that describes the reaction process between the drugs and cell lines is denoted as \u0424\u0442, and its input text \u0424\u0442 is generated through a template with two parameters (C,Y), as the response value of the drug with the name of the cell line is [IC50]. For the i-th representations (di, ci) generated by the IF and the j-th captions (cj, yj) produced by the caption encoder in a batch B, we normalized the feature vectors in a hyper-sphere using ui:=\u03a6F(ci)||\u03a6F(Ci)|| and vj := \u0424\u0442(Cj)||\u0424\u0442(Cj)||. Finally, the similarity between u\u2081 and vj was calculated as uTvj. Hence, the supervised contrastive loss function LNCE can be expressed as:\nLNCE=1N\u2211Ni=1[logNexp(uTi\u03c5j/\u03c3)\u2211Nl=1exp(uTil/\u03c3)+logNexp(\u03c5Tjui/\u03c3)\u2211Nl=1exp(\u03c5Tj\u03c5i/\u03c3)](1)\nwhere, N is the size of the batch B, and \u03c3 is the temperature for scaling the logits.\nBy pre-training \u0424\u0442 using contrastive learning, we ensured that its encoding space is aligned with that of F. Subsequently, we adopted an approach similar to the classifier-free guidance method, using the pre-trained contrastive model PF as a conditional encoder. To guide the generation process towards the desired sampling conditioning information C = \u0424\u0442(\u0441\u0456, Yi), we sampled the conditional distribution qo (G/c), and carried the expectations over to the samples Go~ Pdata and Gt ~ Pot (Gt|Go, c). Thus, the transition probability pot (Gt|Go, c) can be represented as follows:\nPot (Gt|Go, c) = pot(Xt|Xo, c)pot (At|Ao, c). (2)\nFor time t, we introduced objectives (Song et al. 2020) to generalize score matching and estimate the scores as follows:\nminEt{\u03bb1(t)EGt,EG0|Go||\u2207Xtlog pot(Xt|X0,c)\u2212\u03b5\u03b8(Xt,c)2}+minEt{\u03bb2(t)EGt,EAt|Ao||\u2207Atlog pot(At|Ao,c)\u2212\u03b5\u03b8(At,c)2}(3)(4)\nwhere, \u03bb1(t) and \u03bb2(t) are positive weighting functions and \u03b5\u03b8 and \u03b5\u03b8 denoted the noise prediction models based on the GNNs (Jo, Lee, and Hwang 2022; Zhang, Rao, and Agrawala 2023) to estimate scores \u2207alogpt(Xt, At, c) and xlogpt (Xt, At, c), respectively. These two noise prediction models are jointly referred to as eo (G, c).\nFragment Mask Generation\nScaffolds typically refer to a molecule's core structure or main ring system that determines its basic shape and properties (Li et al. 2019). In contrast, side chains are the branches or functional groups attached to the scaffolds. By altering the side chain properties, we can modulate the molecule's solubility, polarity, reactivity, and various properties. As a result, we designed a fragment-based molecular optimization method. Molecular fragmentation is primarily based on the scaffolds and side chains in the molecule's structure, and we applied rule-based constraints to the fragmentation results."}, {"title": "Fragment-Masked Molecular Optimization", "content": "For a specific molecule G = (A, X), we first analyzed the molecule's scaffold using the Murcko scaffold function in the RDKit tool (denoted as FMs(\u00b7)), extracting its core scaffold structure Sf and side chains Sc.\nSc, Sf = Fcheck(FMS(G)) (5)\nIn this instance, these side chains are referred to as fragments. After excluding the fragments containing only single atoms (e.g., C, N, Cl, and F), we verified the connectivity between Sf and Sc using Fcheck(.).\nFcheck={1,if Connect(Sc,Sf)|=10,if Connect(Sc,Sf)|\u22601(6)\nIf a fragment Se has multiple connection points to the scaffold Sf, it makes the optimization task very difficult but also destroys the original scaffold's properties. Consequently, these fragments were not considered for optimization.\nAdditionally, by determining whether a fragment has only one atom connected to the retained scaffold with the function Fcheck(), we ensured its independent optimizability. This is because MX is generated based on MA. To ensure that the information of separate chemical bonds is not disclosed, we marked the row and column elements corresponding to the atoms in the fragment as 1 in MX.\nFinally, the fragment Sc that meets the criteria is considered for optimization. Furthermore, the fragment masking involves two matrices, used for atom and bond masking in the graph G, respectively.\nMX(i)={1,ifi\u2208Sc0,otherwise(7)\nMA(i,j)={1,ifi/j\u2208Sc0,otherwise(8)\nSpecifically, the atom indices in Se correspond to those where the elements of MX are 1. In addition, the matrix MA is derived from MX, where the elements of MA are set to 0 if the atoms are part of the scaffold Sf.\nFragment-Masked Molecular Optimization\nMolecular optimization aims to enhance specific molecular properties by leveraging their intrinsic information. This paper focuses on optimizing the molecules' fragment regions to improve their cell line experiment responses. Hence, we employed a trained conditional diffusion denoising model. The condition's inputs include the original molecule G, two masks MA and MX, and the PDD task targets (ci, Yi). The output comprises multiple structurally similar molecules G' that exhibit improved IC50 values, denoted as y, for the given cell line ci.\nSpecifically, as each reverse step from Gt to Gt\u22121 relies solely on Gt, it is essential to guide the masked region generation according to the known regions of Gt and the input optimization targets, described as follows:\n{A1\u223cN(\u221a\u00af\u03b1tA0,(1\u2212\u00af\u03b1t)I)X1\u223cN(\u221a\u00af\u03b1tX0,(1\u2212\u00af\u03b1t)I)}knAtukn\u22121\u223cN(\u03bc\u03b8(At,t),\u03a3(At,t))Xukn\u223cN(\u03bc\u03c6(Xt,t),\u03a3\u03c6(Xt,t))(9)(10)\nwhere, Ao and Xo are the adjacency and node matrices of the initial molecule G+ at time t = 0, \u03b2 is the schedule"}, {"title": "Rule-Based Chemical Bond Post-Processing", "content": "function, and \u0101t = \u03a0\u22121(1 \u2212 \u03b2\u2081). In addition, the reverse process is modeled by two neural networks (the details can be found in Eqs. 3 and 4) that predict the parameters \u03bc\u03bf/\u03c6(\u00b7) and 20/$() of the Gaussian distributions with the given conditions.\nFinally, at time step t \u2212 1, unknown (Aukn, Xukn) and known regions (Akn, Xkn) are identified, constrained using two masks, and combined to form Gt-1(Xt\u22121, At-1):\n{At\u22121=WMAAtunkn+(1\u2212(1\u2212MA)A1)Xt\u22121=WMXXtunkn+(1\u2212MX)X1(11)\nwhere, \u2299 denotes the element-wise product, \"kn\" and \"ukn\" are the abbreviations for \"known\" and \"unknown,\" respectively. W is a coefficient that gradually decreases from 1 to 0 over time t, and is used to control the scaffold's influence on the sampled region. After combining the known and optimized generated regions using the masks, the resulting Gt-1 is incorporated into the next denoise step as follows:\n\u03b5\u03b8(Gt\u22121,c)=w\u03b5\u03b8(Gt+\u03b5,c)+(1\u2212w)\u03b5\u03c1(Gt+\u03b5,0)(12)\nwhere, the noise \u2208 ~ N(0, I), w is a conditional control strength parameter (w > 0), and w = 0 indicates unconditional generation.\nRule-Based Chemical Bond Post-Processing. During the sampling phase, the GNN-based score prediction model's inherent limitations in the molecular generation process prevent each atom from obtaining information beyond the GNN layer's k-hop neighborhood. This limitation may cause the model to miss global features or long-range interactions between atoms when generating molecular structures, which can, in turn, affect the overall structural rationality and stability of the molecule (Kim et al. 2023; Cai et al. 2022). Therefore, global optimization is necessary.\nThus, we changed the global features of the sampled molecule Go to correct specific local edge types. Specifically, we changed the molecular structure by converting continuous double bonds to single and modifying six-carbon double-bonded to aromatic rings. These corrections ensure that the generated molecules meet the chemical stability and structural rationality requirements, thereby improving the accuracy and effectiveness of molecular optimization."}, {"title": "Experiment", "content": "Experimental Setup\nThis study utilized two primary datasets: QM9 (Ramakrishnan et al. 2014) and GDSCv2 (Yang et al. 2013). The QM9 dataset was used for pre-training the model to enhance molecular diversity, and contains approximately 133,885 molecules. These data provide the model with rich molecular information, improving its generalization ability. Likewise, the GDSCv2 dataset was used for tasks related to drug response prediction (Shubham et al. 2024; Campana, Prasse, and Scheffer 2024), and comprises approximately 190,853 samples, covering 945 cell lines and 220 drugs. GDSCv2 enables learning and predicting drug response distributions. This is significant for precision medicine and new drug development (Ren et al. 2023).\nEvaluation Criteria. Molecules labeled with drug response for the cell line \u03b7 are selected from the GDSCv2 dataset, focusing on those with IC50 values in the top 20% to 30%. These molecules, referred to as yn, were used as the target molecules for optimization. N@100 is a counting function, if the IC50 of the optimized molecules yn is lower than the average yn, the count is incremented by one. The Improv. represented the improvement in IC50 before and after molecular optimization. Our method calculated the average increase based on the true IC50 values for each molecule being optimized, while other methods also used the average IC50 of these molecules to compute the average increase.\nIt is important to note that the generated or optimized molecules' the efficacy (i.e., the IC50) in various cell lines was predicted using the deep learning models and not wet lab validation. This is because the wet lab validation involves molecular synthesis and cell-based assays, processes that are time-consuming and extremely costly. Therefore, we relied on the out-of-domain drug response prediction (OOD-DRP) methods (Li et al. 2024c; Chen et al. 2022; Sharifi-Noghabi et al. 2021) to predict the IC50 of the newly generated molecules. The contrastive learning drug response model based on natural language supervision (CLDR) focused on out-of-domain generalization and demonstrated state-of-the-art correlation in response predictions (Li et al. 2024b). Consequently, we used the CLDR as the OOD-DRP method.\nOverall Experiments\nTo validate the effectiveness of FMOP, this study has meticulously ensured fairness by comparing it with five baseline models. GDSS (Jo, Lee, and Hwang 2022), DiGress (Vignac et al. 2023), and DruM2D (Xu et al. 2023) are unconditional molecular generation methods, while MOOD (Lee, Jo, and Hwang 2023) and CDGS (Huang et al. 2023) are"}, {"title": "Ablation Study", "content": "conditional molecular generation methods that utilize specific category and the dataset distributions to guide molecular generation. Existing molecular optimization methods can be broadly categorized into target pocket- and property-based molecular optimization. Target pocket-based methods require detailed structural information and binding site data, whereas property-based optimization methods fail to integrate cellular genomics and drug-cell fusion information. Consequently, these methods cannot be directly compared with our approach.\nTo verify whether our method can effectively optimize molecules to achieve better drug response values, we conducted overall experiments involving various diffusion models. Due to the novelty of the molecule generation method, generated molecules are out-of-domain and require the OOD-DRP model to have a high generalization capability. Therefore, we used the CLDR method (Li et al. 2024b), which has excellent generalization performance, to predict the optimized molecules.\nTable 1 displays the optimization results of six methods in three different cell line scenarios and the average optimization results across 945 cell lines. Our method achieves the best optimization and increase rate results, surpassing the second-best method by 36.0% and 76.7%, respectively. To verify that our method can effectively optimize fragment regions while maintaining scaffold consistency, we conducted a visual comparison of the results. As shown in Fig. 3, our method maintains scaffold consistency while optimizing the masked region. In contrast, other methods' optimization success was primarily due to the random generation of a few molecules with good efficacy across various cell lines. However, these methods cannot adjust the sampling space distribution for specific tasks, resulting in poor performance.\nAblation Study\nIn the FMOP method, the PDD task information and fragment masks are encoded as indispensable conditions, and their impact on the final optimization results is significant. Therefore, three key points need to be explored:\nQ1: Do the conditional information (i.e., the expected IC50 values and cell line types) play a crucial role in the molecular optimization process, thereby improving optimization success rates and efficacy enhancements?\nQ2: Can fragment masking effectively focus optimization on specific regions to improve efficacy and optimization success rates?\nQ3: Given the current issues with aromatic ring quality and single/double bond generation, is rule-based chemical bond post-processing an effective method for molecular generation?\nAs shown in Table 2, each component significantly contributes to the model's overall performance. For Q1, without the fragment mask prompt, our method generates molecules"}, {"title": "Visualization Analysis", "content": "randomly, resulting in a drastic decline in the success rate to 0.3% and an improvement of 2.1%, with only 26 instances reaching N@100. This indicates that the fragment mask is crucial for identifying key molecular features.\nFor Q2, when task guidance is removed, the success rate is 5.0%, and the improvement rate remains at 2.1%. The absence of task guidance leads to a random fragment generation strategy, where we use the top N most frequent fragments to assemble the scaffold, yielding a success rate of 5%. This demonstrates that task guidance is essential for potential molecule optimization.\nFor Q3, the success rate further increased to 94.4% through post-processing based on the aromatic ring recognition rules. This suggests that molecular modifications are essential for achieving a high success rate, although they introduce some complexity.\nVisualization Analysis\nTo explore whether the molecules generated or optimized using different methods achieved a certain confidence level instead of merely evaluating the methods based on numerical values, we visually analyzed the molecular structures generated using our optimization method and baselines across different cell lines. As shown in Fig. 3, our method generates unique molecules for each cell line, ensuring that the optimization process does not converge to the same local optimum across different cell lines. In comparison, the molecules generated using other methods were generally similar, highlighting that our method is able to optimize molecular structures based on the specific response values of each cell line, thereby achieving more effective and suitable molecular structures. Furthermore, our method's predicted IC50 values remain consistently low across different cell lines, indicating that our optimized molecules have a competitive advantage compared to de novo designed molecules. For example, for cell line 906792, our method generated a molecule with an IC50 value of 0.48, while the other approaches generated different molecules with IC50 values ranging from 0.49 to 0.51.\nSince measuring the IC50 for all virtually generated molecules on 945 specific cell lines in a short time is impractical, we utilized the CLDR method to predict these values. To validate our method's effectiveness, as shown in Fig. 4, we predicted the IC50 values for the cell lines 906792, 688006, and 949090, and visualized the mean and variance by assuming a Gaussian distribution. As a result, our proposed FMOP method demonstrated a strong competitiveness in the lower IC50 range. For example, in Fig. 4a, the IC50 values for the molecules generated by FMOP fall between 0.47 and 0.53, while those generated using other methods mostly fall between 0.49 and 0.52. Additionally, the IC50 distribution of the original molecules (denoted as 'Origin') ranged between 0.51 and 0.52. After optimization using our method, the mean IC50 of the molecules showed a significant improvement, approximately by 3%. The results generated by MOOD and DruM2D are represented by  , indicating that only one single effective molecule was optimized for cell line 906792, resulting in a variance of 0."}, {"title": "Conclusion", "content": "To address the PDD challenge of generating molecules, which requires screening a vast number of possible molecular structures, we proposed the FMOP method. To the best of our knowledge, the FMOP is the first optimization method for the PDD task. FMOP employs a regression-free diffusion model to conditionally sample the masked regions of molecules for optimization, effectively generating new molecules with similar scaffolds and improved efficacy. We optimized the molecules for all 945 cell lines on the GDSCv2. The overall experiments demonstrated that the in-silico optimization success rate reaches 94.4%, with an average efficacy increase of 5.3%. Additionally, we conducted extensive ablation studies and visualization experiments, proving that FMOP is an effective and robust molecular optimization method."}, {"title": "Reproducibility Checklist", "content": "This paper:\n\u2022 Includes a conceptual outline and/or pseudocode description of AI methods introduced yes\n\u2022 Clearly delineates statements that are opinions, hypothesis, and speculation from objective facts and results yes\n\u2022 Provides well marked pedagogical references for less-familiare readers to gain background necessary to replicate the paper yes\nDoes this paper make theoretical contributions?\nyes\n\u2022 All assumptions and restrictions are stated clearly and formally yes\n\u2022 All novel claims are stated formally (e.g., in theorem statements). yes\n\u2022 Proofs of all novel claims are included. yes\n\u2022 Proof sketches or intuitions are given for complex and/or novel results. yes\n\u2022 Appropriate citations to theoretical tools used are given. yes\n\u2022 All theoretical claims are demonstrated empirically to hold. yes\n\u2022 All experimental code used to eliminate or disprove claims is included. yes\nDoes this paper rely on one or more datasets?\nyes\n\u2022 A motivation is given for why the experiments are conducted on the selected datasets yes\n\u2022 All novel datasets introduced in this paper are included in a data appendix. yes\n\u2022 All novel datasets introduced in this paper will be made publicly available upon publication of the paper with a license that allows free usage for research purposes. yes\n\u2022 All datasets drawn from the existing literature (potentially including authors' own previously published work) are accompanied by appropriate citations. yes\n\u2022 All datasets drawn from the existing literature (potentially including authors' own previously published work) are publicly available. yes\n\u2022 All datasets that are not publicly available are described in detail, with explanation why publicly available alternatives are not scientifically satisficing. NA\nDoes this paper include computational experiments?\nyes\n\u2022 Any code required for pre-processing data is included in the appendix. yes\n\u2022 All source code required for conducting and analyzing the experiments is included in a code appendix. yes"}, {"title": "", "content": "All source code required for conducting and analyzing the experiments will be made publicly available upon publication of the paper with a license that allows free usage for research purposes. yes\n\u2022 All source code implementing new methods have comments detailing the implementation, with references to the paper where each step comes from yes\n\u2022 If an algorithm depends on randomness, then the method used for setting seeds is described in a way sufficient to allow replication of results. yes\n\u2022 This paper specifies the computing infrastructure used for running experiments (hardware and software), including GPU/CPU models; amount of memory; operating system; names and versions of relevant software libraries and frameworks. yes\n\u2022 This paper formally describes evaluation metrics used and explains the motivation for choosing these metrics. yes\n\u2022 This paper states the number of algorithm runs used to compute each reported result. yes\n\u2022 Analysis of experiments goes beyond single-dimensional summaries of performance (e.g., average; median) to include measures of variation, confidence, or other distributional information. yes\n\u2022 The significance of any improvement or decrease in performance is judged using appropriate statistical tests (e.g., Wilcoxon signed-rank) yes\n\u2022 This paper lists all final (hyper-)parameters used for each model/algorithm in the paper's experiments. yes\n\u2022 This paper states the number and range of values tried per (hyper-) parameter during development of the paper, along with the criterion used for selecting the final parameter setting. partial"}]}