{"title": "NSP: A Neuro-Symbolic Natural Language Navigational Planner", "authors": ["William English", "Dominic Simon", "Rickard Ewetz", "Sumit Jha"], "abstract": "Path planners that can interpret free-form natural language instructions hold promise to automate a wide range of robotics applications. These planners simplify user interactions and enable intuitive control over complex semi-autonomous systems. While existing symbolic approaches offer guarantees on the correctness and efficiency, they struggle to parse free-form natural language inputs. Conversely, neural approaches based on pre-trained Large Language Models (LLMs) can manage natural language inputs but lack performance guarantees. In this paper, we propose a neuro-symbolic framework for path planning from natural language inputs called NSP. The framework leverages the neural reasoning abilities of LLMs to i) craft symbolic representations of the environment and ii) a symbolic path planning algorithm. Next, a solution to the path planning problem is obtained by executing the algorithm on the environment representation. The framework uses a feedback loop from the symbolic execution environment to the neural generation process to self-correct syntax errors and satisfy execution time constraints. We evaluate our neuro-symbolic approach using a benchmark suite with 1500 path-planning problems. The experimental evaluation shows that our neuro-symbolic approach produces 90.1% valid paths that are on average 19-77% shorter than state-of-the-art neural approaches.", "sections": [{"title": "I. INTRODUCTION", "content": "The proliferation of robotics and autonomous systems [1] has resulted in the development of numerous complex high-level path planners [2]\u2013[4]. Path planners take an objective and a description of the environment as an input and generate a path planning solution. Path planners vary based on the type, format, and completeness expectation of their input and outputs [5]\u2013[7]. It is desirable for planners to be verifiable, or provide some form of correctness guarantee [8], [9]. Recent efforts have sought to incorporate Natural Language Processing (NLP) technologies such as Large Language Models (LLMs) in order to create planners that accept natural language as input rather than graphical and spatial input types [10]. This development is due to the desire for humans to be able to easily interface with robotic agents using free-form natural language [11]. Existing solutions to navigational path planning are based on symbolic [12], [13] or neural solution strategies [14], [15].\nSymbolic approaches generate solutions through deterministic rule-based reasoning [16], which satisfy correctness guarantees, but are sensitive to non-conformal inputs and are limited by the knowledge embedded in the NL-to-Symbol mapping model [17]. Such systems largely rely on specialized resources, such as semantic parsers and lexicons, to interpret free-form natural language instructions, and struggle with the ambiguity of free-form natural language [11]. They require precise semantic interpretations to map instructions accurately onto a predefined action sequence. For these reasons, symbolic approaches have a limited capacity to work with natural language inputs, and those that do cannot generalize to unseen inputs [18].\nNeural approaches produce solutions by mapping inputs directly to actions through learned patterns, which is computationally intensive and typically requires a manually predefined action space [16], [19]. Another line of work in this domain has used LLMs to translate NL instructions into a symbolic expression in a formal system, such as Linear Temporal Logic (LTL) [20], [21]. These approaches, however, require the engineering of a symbolic vocabulary, and other forms of manual labeling. More recently, LMMS have been use to directly solve various forms of reasoning problems [22]\u2013[24]. This has opened the door to directly solving path planning problems using the innate reasoning abilities of LLMs. The quality of LLM generated solutions can be improved using prompting strategies such as few-shot prompting and chain of thought reasoning [25], [26].\nIn this paper, we propose a neuro-symbolic framework called NSP for solving path planning problems in free-form natural language. The framework uses a neural LLM to parse the description of the objective and environment. The LLM also ingests the API of a graph library. Next, the LLM produces a symbolic graph representation of the environment and a path planning algorithm that operates on the graph. The generated code utilizes syntax and API calls from the graph library. Finally, the algorithm is executed on the graph to produce a solution path. A feedback loop is used to allow the LLM to self-correct syntax errors and satisfy execution time constraints. The main contributions of this paper are, as follows:\n\u2022 A neuro-symbolic approach to solving path planning problems in free-form natural language. The approach leverages the advantages of symbolic approaches while circumventing the need for predefined symbolic representations. Both the distance graph and the path planning algorithm are generalized using the LLM.\n\u2022 The neuro-symbolic feedback loop from the execution environment is able to resolve hallucinations and syntax errors generated by the LLM. The feedback methodology substantially improves the robustness of the natural language to symbolic translation, which is a key challenge for neuro-symbolic approaches.\n\u2022 The proposed approach is evaluated using a dataset of 1500 natural language path planning scenarios. Compared with state-of-the-art LLM based approaches [26], the NSP framework improves the valid path success rate by up to 76%. On average, the feedback loop is"}, {"title": "II. RELATED WORK", "content": "Prior to the broad adaptation of LLMs, NL-based path planners required a method of mapping free-form NL inputs to a symbolic structure. Typically, this mapping is embedded into a model during training and requires formal environmental and behavioral specifications [13] [27]. This specification is necessary both to search a space for optimal solutions and to guarantee the validity of a proposed solution. In these approaches, the NL input of the path planning task is first mapped to a symbolic action space, and the resulting operations are executed deterministically. The scalability of this approach is limited by the up-front cost of engineering the seed lexicons. To adapt to unseen inputs, re-training of the entire model would be necessary, as the planner itself is incapable of reasoning outside the bounds of the action space. Consequently, purely symbolic path planning approaches cannot handle inputs in the form of free form natural language."}, {"title": "B. Large Language Models in Path Planning", "content": "LLMs have been widely adopted as a valuable tool for natural language path planning tasks [28] [29]. Their ability to extract dense information from natural language inputs has significantly advanced the state-of-the-art. High-level path planners require some knowledge of their environment to function efficiently, and LLMs have been shown to possess the reasoning capabilities necessary to decode this information from natural language inputs. Furthermore, LLMs themselves produce language-based output which can in turn be used to inform future prompts and contexts, which has been shown to improve reasoning abilities and update the model's knowledge [30] [31] [32].\nThere are two primary uses of LLMs in path planners. Firstly, they are used as a translator between free-form NL input and an action space. This alleviates the adaptability concerns with regard to symbolic methods, since LLMs are likely to have this knowledge already embedded, although the output of this model is still restricted to the seed lexicon [19]. Therefore, this approach is only applicable to predefined problem formulations. The second is to perform reasoning in order to create the navigational plan itself. In this case, the model itself provides a path directly. While it is impressive that LLMs can directly solve simple problem instances, the performance rapidly declines when the complexity of the considered problems are scaled-up. To enable LLMs to solve larger problem instances, the performance can be boosted using prompting strategies."}, {"title": "C. Approaches to Prompting", "content": "In this section, we discuss how the reasoning capabilities of LLMs can be improved by using prompting methodologies. In particular, we review the concepts of zero-shot prompting, chain-of-thought prompting, and self-consistency.\nZero_Shot: Zero-shot prompting expects the model to complete the task and return an answer without previous examples or reasoning steps included in the prompt. Zero-shot prompting exemplifies the base abilities of an LLM, relying solely on its embedded knowledge and generalization abilities.\nO-COT [33]: Zero-shot chain-of-thought prompting encourages the LLM to articulate intermediate reasoning steps in its response, but does not include reasoning examples. This approach has been shown to improve reasoning capabilities in multiple domains, including finding the shortest path on a graph [22]. Note that it is difficult to provide few-shot examples when the model must be capable of solving multiple problem types.\nSC [34] is a method of prompting that generates multiple independent reasoning paths and answers. The most common answer is selected as the final answer. This approach attempts to reduce the likelihood of errors by comparing across multiple outputs."}, {"title": "III. PROBLEM FORMULATION", "content": "This paper considers the problem of path planning from natural language. We first define the natural language path planning problem. Next, we provide a small example of a problem instance and the expected output.\nProblem Definition: The input is described in natural language and consists of i) a description of the environment, ii) the objective of the path planning problem, and iii) any constraints in the environment. A path planner is expected to take the input specification and generate a solution path through the environment.\nFormally, we define the path planning problem using a string triplet $D = (E,S,C)$, where $E$ is a string in NL that contains a description of all locations in an environment, as well as the spatial relationships between these locations. The description may include specific distances between pairs of locations or default to unit distances. The description is constructed based on an underlying ground truth graph $G_T = (V_T, E_T)$, where the vertices and the weighted edges capture the locations and the distances between connected spatial locations, respectively. $S$ is an NL string containing the objective of the path planning problem. The objective may include both shortest path problems and traveling salesman problems. $C$ is an NL string that contains all constraints on $S$. The constraints include locations and spatial connections that may not be utilized in the solution path. Most importantly, the options and syntax of each of the individual strings and their concatenations should be treated as unknown to the path planner. The path planner is expected to generate a solution path $P$, consisting of a set of vertices ${v_1,..., v_n}$. For the path to be valid, all vertices are required to belong to $V_T$ and all pairs of adjacent vertices $(v_i, v_{i+1}) \\in P$ are required to exist in $E_T$. If the solution path is valid, the path length is compared with the known optimal lower bound from the ground truth graph $G_T$.\nSample Problems: We provide two small sample problems considered by our problem formulation below.\n\"There is a house with Room1, Room2, Room3, and Room4. Room1 is connected to Room2 and Room3, Room2 is connected to Room3 and Room4, and Room3 is connected to Room4. Start in Room1 and move to Room2. Do not pass through Room4.\" The expected output from this problem instance would be \u201c[Room1, Room3, Room2]\u201d."}, {"title": "IV. THE NSP FRAMEWORK", "content": "In this section, we describe the proposed NSP framework, which is a neuro-symbolic approach to solving path planning problems in free-form natural language. The input to the NSP framework is the free-form natural language description of the path planning problem, $D = (E + S + C)$. The output is a solution to the problem, the path $P$.\nThe neuro-symbolic translation involves using an LLM to translate the natural language input into symbolic representations, including a graph and parameters $(G,I)$, an algorithm $F$ to solve the path planning problem, and a function call $F(G, I)$. The LLM ingests the API of a graph library to provide tools for the LLM to utilize in its code generation. An overview of the framework is provided in Figure 1. The details of the neuro-symbolic translation are provided in Section IV-A. The neuro-symbolic planning and feedback step involves executing the function call generated in the previous step. If the symbolic path planning algorithm can be executed as expected, this step directly produces a solution $P$ to the path planning problem. If a compilation error is encountered during the execution, or if the execution time exceeds a limit, the (neural) feedback is provided back to the neuro-symbolic translation in the form of natural language. The details of the neuro-symbolic planning and feedback are given in Section IV-B. The flow is illustraited with a case study in Section IV-C."}, {"title": "A. Neuro-Symbolic Translation", "content": "The first step in the NSP framework is the neuro-symbolic translation. The goal of this step is to translate the natural language inputs into an algorithm $F$ that takes a graph $G$ and parameters $I$ as the input. By executing $F(G,I)$, the algorithm should generate a solution path $P$.\nThe translation of the natural language inputs to the symbolic intermediate representations is performed using prompt \u201cThe path planning problem is: {problem description D}\nWrite a Python function 'create_graph()' that generates a distance graph using the NetworkX library based on the path planning problem. The function should return a NetworkX weighted graph object.\nAdditionally, write another function 'solve_problem(graph, args)' that solves the path planning problem in the form of a node traversal order list. Your response should include the complete function code and a definition of args, which is an array containing any parameters you may need for the solution function, in your response. Do not return any incomplete functions.\nThe available libraries are networkx and itertools. If this problem is similar to another problem with a known efficient solution, use it in your implementation.\n{graph library API}\nan LLM. While LLMs are capable of generating high quality code from scratch, the desired task is challenging to be performed zero-shot. To improve the quality of the code generation, we leverage a combination of i) access to graph libraries and ii) clever prompting strategies. While the path planner does not know the exact problem that it will be requested to solve, most planning problem can be modeled and solved using distance graphs. Therefore, we provide the API of a graph library in the prompt to the LLM. Our prompting strategy takes inspiration from prior work that has established prompt patterns that are most successful in eliciting correct code generation [35]. Specifically, we provide the names and parameters of the functions, a description of their purpose, what libraries are available, and the names of relevant variables that need to be defined.\nOur developed prompt template for solving the path planning problems is shown in Figure 2. The template delineates requirements for the type of code that will be output by the model. The features of the input that are not predefined that is, the problem description $(D = (E, S, C'))$ contain all the information required by the model to successfully map our inputs to a partial solution $(F(G,I))$"}, {"title": "B. Neuro-Symbolic Planning & Feedback", "content": "The second step of the NSP framework is the neuro-symbolic feedback & planning step. The inputs are the intermediate components (G, I, F) generated in the previous step. In this step, we execute the algorithm F on the arguments (G,I). The result is one of three types of feedback: an interpreter error, a timeout error, or a solution path P. If a solution path is generated, the path P is returned as the solution to the considered problem description D. Otherwise, we trigger a feedback loop to handle either the interpretation error, or the timeout error. If the feedback loop is invoked more than m = 5 times, we report that NSP is unable to generate a valid solution path.\nThe use of a feedback loop is motivated by the fact that an LLM by itself can not reliably write flawless code in one attempt. Syntactical or logical errors may be present, and so before we finalize our path plan, we run the algorithm with the compiler or interpreter of the programming language. In our implementation, we leverage the Python programming language and the Python interpreter. In the case that the interpreter detects an error in the code or the code does not execute within the specified time, we append the respective errors to the input and repeat step 1, i.e., the neuro-symbolic translation in Section IV-A. Specifically, we append the error template shown in Figure 4. If the interpreter did not produce an error, the path is considered verified and correct."}, {"title": "V. EXPERIMENTAL EVALUATION", "content": "The experimental evaluation is broken into the following sections: construction of the evaluation dataset is explained in Section V-A, experimental setup is given in Section V-B, results on the Shortest Path and Traveling Salesman problems are discussed in Section V-C and Section V-D, respectively, error analysis in Section V-E, and a general discussion in Section V-F."}, {"title": "A. Dataset Construction", "content": "The evaluation dataset is composed of 1500 randomly generated navigational path planning scenarios. Each scenario is classified by the parameters num_rooms $\\in$ [5, 10, 15, 20,25] and graph_type $\\in$ [weighted, unweighted]. These scenarios are further divided into Shortest Path problems and Traveling Salesman problems. Shortest Path problems are divided into constrained $\\in$ [true, false] denoting whether the path planning problem D includes any constraints C. There are 30 unique combinations of the scenario parameters and 50 scenarios for each combination of scenario parameters, resulting in a total of 1500 scenarios. In addition to the parameters of each scenario, each entry includes a string description of the environment S, a string description of the path planning problem P, a graph isomorphic with the house in the description $G = (V, E,w)$, where $V = {U_1, U_2, ..., U_n}$, $E = {(V_i, V_j)|V_i, V_j \\in V, i \\neq j}$, and $w \\in R$, and the optimal solution path $P = (V_1, V_2, ...V_k)$ for this scenario.\nThe Shortest Path graphs are constructed by initially creating a complete graph. The number of nodes in the given graph is determined by the num_rooms parameter. Then, edges between the nodes are randomly removed until 40% of the edges remain. Finally, two nodes are randomly chosen as the start and end nodes. The shortest path between these nodes becomes the optimal path P. The graph is algorithmically traversed to build the natural"}, {"title": "B. Evaluation Setup", "content": "We define a set of metrics to evaluate the navigation performance of the proposed method for each scenario type. These metrics include Success Rate, Optimal Path Rate, Path Efficiency Rate, and Inference Time. Success Rate is defined as $P_C \\div P_T$, the number of path solutions that successfully reach the end node $P_C$ divided by the total number of path solutions generated $P_T$. Optimal Path Rate is defined as $P_O \\div P_C$, where $P_O$ is the number of solution paths that reach end node using the shortest path. Path Efficiency Rate is defined as $\\sum len(P_O) \\div \\sum len(P_C)$, the sum of the edge lengths len() of optimal paths $P_O$ divided by the sum of the edge lengths of the generated paths $P_C$. A perfect performance is indicated by a score of 100% in each of these metrics. Inference Time is the time it takes for the model API call to return the output. Attempts is also included specifically for NSP to show the average number of feedback loop iterations per trial.\nWe evaluate our approach against four baselines. These include zero-shot prompting (Zero_Shot), zero-shot chain-of-thought prompting (O-CoT), zero-shot+self-consistency prompting (Zero_Shot+SC), and zero-shot chain-of-thought+self-consistency prompting (O-CoT+SC). Each of these approaches are described in Section II. We use these prompting approaches to demonstrate the performance gains achieved by NSP over other techniques.\nGPT-4o-mini is used as the main LLM during evaluation. At the time of writing, GPT-4o-mini is the newest LLM from OpenAI, providing the best price-per-token to processing power tradeoff.\nExperimental evaluations were performed on a desktop with an Intel Core i7-13700O (16 cores, 5.2 GHz) CPU, an NVIDIA RTX A4000 (16 GB) GPU, and 32 GB of RAM."}, {"title": "C. Shortest Path Problem", "content": "In this section, we discuss the results of evaluations on each approach for the Shortest Path problem. The Shortest Path problem consists of finding the shortest path between two locations and the constraints may include forbidden rooms and/or forbidden traversals between rooms.\nTable I shows the performance of the evaluated approaches across path planning scenarios containing 5, 10, 15, 20, and 25 rooms, with each room set containing 200 scenarios. For the 5-room path planning scenarios, all approaches achieve high success rates, with O-CoT at 93%,"}, {"title": "D. Traveling Salesman Problem (TSP)", "content": "In this section we discuss results of our evaluation of each approach on the Traveling Salesman problem. The Traveling Salesman problem consists of finding a path that visits each location in an environment exactly once, beginning and ending in a specified location. A successful TSP path plan must at least visit every location in the input. We have verified that every TSP trial in our evaluation dataset contains a cycle that visits each node.\nTable II shows the performance of the evaluated approaches across path planning problem scenarios containing 5, 10, 15, 20, and 25 rooms, where each different room set"}, {"title": "E. Error Analysis", "content": "In this section we review the most common errors caught by the NSP feedback loop. At the conclusion of the evaluation, there were a total of 57 unaccounted errors remaining, i.e, 57/1500 trials were failed because errors were not resolved after the maximum number of feedback iterations was reached. Among these 57 occurences are 17 KeyErrors, 13 TypeErrors, 10 NameErrors, 6 NetworkXErrors, 4 OtherErrors, 3 ValueErrors, 2 IndexErrors, 1 UnboundLocalError, and 1 AttributeError In almost every case the most frequently encountered error, KeyError, occurs when solve_problem() attempts to iterate over the rooms in the graph and inadvertently attempts to access an element of the graph that does not exist. On several occasions, the model responded to this feedback by implementing a try-except block in the definition of solve_problem(), such as in the following:"}, {"title": "F. Evaluation Summary", "content": "Direct prompting and chain-of-thought approaches are capable of generating correct paths in most cases, however their performance declines sharply when measured by the efficiency of the paths they produce. In the least difficult scenario, these methods produce optimal paths 20% less frequently than the proposed method. NSP maintains an efficiency of > 96% for all trials, while other methods fall dramatically, demonstrating < 20% efficiency in more difficult trials. Overall, NSP outperforms direct and chain-of-thought approaches in terms of success rate and optimal path planning in all cases. As the number of rooms grows, so does the complexity of the planning problem and the inference time required to plan a path in that environment. While all models perform well in terms of their ability to generate plausible paths, our neuro-symbolic approach significantly outperforms others in the creation of optimal path plans from natural language inputs. Our approach produces paths that are only an average of 1% longer than the optimal path lengths for the shortest path problem."}, {"title": "VI. CONCLUSION", "content": "We propose a prompting framework for path planning that leverages the generalization, abstraction, and code-generating abilities of LLMs and combines them with symbolic verification performed by the Python interpreter. Expanding on previous work in the domains of programmatic prompting and path planning, we establish a feedback loop between the Python interpreter and the LLM that allows the model to correct its mistakes before a final path plan is submitted by the framework. We use partially constructed prompts containing programming instructions for the model that are then combined with the natural language inputs required to solve the problem. The framework then produces a Python program, which is fed to the Python interpreter to return a path in our environment. Our experiments demonstrate that NSP improves LLM task performance across multiple metrics."}]}