{"title": "A Composite Fault Diagnosis Model for NPPs\nBased on Bayesian-EfficientNet Module", "authors": ["Siwei Li", "Jiangwen Chen", "Hua Lin", "Wei Wang"], "abstract": "This article focuses on the faults of important\nmechanical components such as pumps, valves, and pipelines in\nthe reactor coolant system, main steam system, condensate\nsystem, and main feedwater system of nuclear power plants\n(NPPs). It proposes a composite multi-fault diagnosis model\nbased on Bayesian algorithm and EfficientNet large model\nusing data-driven deep learning fault diagnosis technology. The\naim is to evaluate the effectiveness of automatic deep learning-\nbased large model technology through transfer learning in\nnuclear power plant scenarios.", "sections": [{"title": "I. INTRODUCTION", "content": "The primary and secondary circuits are the core\ncomponents of nuclear power units, with high frequency of\nfaults, wide impact range, and high diagnostic difficulty. The\ntraditional nuclear power fault diagnosis method analyzes the\ncollected data and identifies potential problems or abnormal\npatterns through statistical, trend analysis, spectrum analysis,\nand other methods. This method relies on expert experience\nand lacks adaptability and generalization ability. In recent\nyears, machine learning has developed rapidly, and Artificial\nNeural Network (ANN) networks have been applied to NPPs\nfault diagnosis[1]. However, the training process requires\nmanual adjustment of network weights and bias parameters,\nand its performance depends on multiple factors such as\nnetwork structure, training data, and optimization algorithms,\nresulting in limited generalization ability[2]. With the\nbreakthrough progress of large models in deep learning in\ncomplex system modeling and pattern recognition, large\nmodels combined with parameter optimization algorithms\nwill be applied to the diagnosis of faults in the primary and\nsecondary circuits of NPPs. By constructing a highly robust\nand strong generalization diagnostic model, the speed,\naccuracy, and interpretability of fault diagnosis in NPPs can\nbe improved, providing guarantees for safe and efficient\noperation. Therefore, conducting research on fault diagnosis\nmethods based on deep learning for the primary and\nsecondary circuits of NPPs is of great significance.\n\nCurrently, most of the proposed large-scale models are\ndeveloped around areas such as image classification and\nsegmentation, object monitoring, text classification, video\nclassification, audio classification, and machine translation [3].\nExperience has shown that large models can perform\nreasonable calculations on classification and regression\nproblems, but they have not yet delved into the field of\nindustrial control, so they still have great prospects in the field\nof NPP fault diagnosis."}, {"title": "II. METHODS", "content": "A. Bayesian Optimization Algorithm\n\nFor neural networks, setting hyperparameters is crucial for\nlearning outcomes. The widely used search hyperparameter\nmethods include manual parameter tuning, Grid Search,\nRandomized Search, Bayesian Optimization, and so on. The\nparameters of large models are exceedingly vast, and the\nnetwork structure is highly intricate, rendering it arduous to\nacquire effective hyperparameters through manual parameter\ntuning. The grid search method is an exhaustive method in the\nsearch space and is not suitable for large hyperparameter\nsearches. Random search is faster than network search, but\nthe combination of hyperparameters may result in worse\nresults. Therefore, we choose Bayesian optimization method.\n\nBayesian optimization was developed by J Snoek, and its\nmain idea is to update the posterior distribution of the\noptimized objective function (a generalized function that only\nrequires specifying inputs and outputs, without knowing the\ninternal structure and mathematical properties) by\ncontinuously adding sample points until the posterior\ndistribution basically fits the true distribution[4]."}, {"title": "B. EfficientNet Large Model", "content": "Large models usually refer to a neural network model with\nvast of parameters, high computational complexity, and\ncomplex model structure. The purpose of its design is to\nimprove the expressive and predictive performance of the\nmodel, enabling it to handle more complex tasks and data[5].\n\nLarge models can be mainly divided into language models,\nvisual models, and multimodal models. As is well known,\nGPT (Generative Pre-trained Transformer) is a pre-trained\nlanguage model based on the Transformer architecture. Due\nto the characteristics of fault diagnosis tasks, we choose to\nconduct research based on visual large models. ViT (Vision\nTransformer), SE ResNeXt, Inception, EfficientNet, etc. are\nwidely used models in CV large models. EfficientNet applies\nan efficient neural network architecture, which achieves\nefficient model design by uniformly scaling the depth, width,\nand resolution of the network, thereby reducing computation\nand parameter complexity while maintaining accuracy[6]. It\nis a high-performance solution designed specifically for\nimage classification and recognition when computing\nresources are limited. Therefore, we decide to compare the\nEfficientNet model with some commonly used large models\nto explore the application prospects of EfficientNet in the\nfield of nuclear power plant fault diagnosis.\n\nHowever, large models require a large amount of\ncomputing resources and large-scale data for training, and for\nsmall and medium-sized research institutes or institutions, the\ncost of developing or training their own large models from\nscratch is difficult to accept. This poses difficulties for the\ndeployment of large models in specific industrial fields. For\nthe above reasons, we chooses to deploy the pre-trained large\nmodel EfficientNet and other models through transfer\nlearning, which can also provide a feasible reference for other\nresearchers to use large models[7].\n\nThe overall algorithm flow is shown in Fig.1. The\nnormalized data is processed into images using the grayscale\nalgorithm, and then 70% of the training set image data is used\nto search for model hyperparameters. The resulting\nhyperparameters are fed into EfficientNet along with the\ntraining data."}, {"title": "III. EXPERIMENT AND RESULTS", "content": "A. Dataset description\n\nWe conducted simulation modeling on AP1000 units and\nran the simulation models in three power scenarios: 50% FP\n(Full Power), 75% FP, and 100% FP. Inject 6 typical faults\ninto the model uniformly in each power scenario and collect\ndata from 10725 real-time parameters at 1200 time points\nunder the faults. In addition, for the 100% FP power scenario,\nthree additional composite operating conditions are injected."}, {"title": "B. Data Pre-processing", "content": "The raw data collected are dimensional with significant\ndifferences in magnitude. Consequently, it is necessary to\nnormalize the original data by removing dimensions and\nconverting them to the same level. In addition, if we can\nensure a stable distribution of nonlinear inputs during training,\nwe can reduce problems such as vanishing gradients due to\nsaturation and thus speed up network training[8]. So we use\nMin-max normalization to normalize the data, and the\nnormalized data range is[0,1].\n\n$x' = \\frac{x - min(x)}{max(x) - min(x)}$ (1)\n\nAmong them, min(x)\u3001max (x) is the minimum and\nmaximum values of the sample data, respectively.\n\nThe collected data consists of over 200 million data points.\nDirectly inputting them into the model for training not only\nyields poor performance but also poses challenges in the\ntraining process. The fault data from the simulation model is\ntypical of multiple sets of one-dimensional time series data,\nand the correlation and characteristics between the data are\nnot obvious. Transforming one-dimensional data into two-\ndimensional data can make it easier to identify repetitive\npatterns and abnormal features in images. The commonly\nused methods for two-dimensional data include wavelet\ntransform (WT), Grami angle field method (GAFS), Markov\ntransition field method (MTF) and so on[9].\n\nThe methods analyze the temporal evolution of a single\nparameter in the time dimension, providing insights into its\nperiodicity and autocorrelation characteristics. However, they\nfail to capture the comprehensive representation and overall\ncharacteristics of nuclear power plant parameters.\n\nBased on the above analysis, we decide to use image\ngrayscale algorithm to process all the raw data (i.e.10725\nparameter data) collected at each time step of the model into\na 104 * 104 two-dimensional grayscale image to obtain a\ntwo-dimensional representation of the overall parameters of\nthe nuclear power plant. After processing by the image\ngrayscale algorithm, the data mapping results are shown in\nFig 2."}, {"title": "C. Bayesian Optimization", "content": "We set the initial number of Bayesian search points to\n10, and simultaneously run 5 Bayesian search algorithms. 70%\nof the training set data is randomly sampled for Bayesian\nsearch. When the accuracy of the search results reaches 90%,\nthe search is stopped in advance and the hyperparameter\ncombination is returned. The search results of hyperparameter\ncombination are shown in Table II."}, {"title": "D. Results and comparison", "content": "We will input the hyperparameters obtained from the\nBayesian Optimization algorithm into the EfficientNet model\nfor training. And by comparing the diagnostic results of the\nproposed method with other widely used large models on the\nsame dataset for multiple fault scenarios of multiple power\nsingle faults and full power composite faults in nuclear power\nplant AP1000 units (as shown in Table III), the large model\ncan correctly identify most of the confusing nuclear power\nplant fault images for professionals. The accuracy represents\nthe proportion of the number of correctly diagnosed faults to\nthe total number of sample faults. As we can see from the\ntable, the accuracy of the model in diagnosing up to 21 types\nof faults in the test set was the lowest at 91.5% and the highest\nat 96.4%. Generally, a larger F1-Score value indicates a\nhigher quality model. It is the harmonic mean of precision and\nprecision and interacts with recall. The EfficientNet model\nachieves 95.3% F1-Score. Precision is the fraction of all\nexamples that the model predicts to be positive that are\nactually positive, and it is concerned with how well the model\npredicts a positive example.\n\nRecall is the fraction of all positive examples that are\npredicted to be true. As with precision, higher is better.\nOverall, the predicted results of the model are consistent with\nthe actual fault types. The large-scale model method based on\nautomatic deep learning can effectively improve the\nefficiency of fault diagnosis in nuclear power plants.\n\nEfficientNet and other large models encounter difficulties\nin identifying highly similar faults, possibly due to the\npresence of numerous redundant parameters within the\noverall 10725 parameters collected from the nuclear power\nplant at each moment. These redundancies occupy a\nsignificant portion of the grayscale feature image and are\nmistakenly recognized as important features by the model,\nleading to reduced prediction accuracy and potential\ndeviations. Humans can effectively identify power plant\nfaults based on composite information such as displayed\nimages and sounds. However, large models represented by\nEfficientNet only rely on images, and their recognition\naccuracy is close to or even higher than that of professionals.\nThis once again highlights the broad application prospects of\nlarge model technology based on automatic deep learning in\nthe field of nuclear power plant fault diagnosis."}, {"title": "IV. SUMMARY", "content": "In response to the shortcomings of traditional nuclear\npower fault diagnosis methods, this paper proposes a large\nmodel combining parameter optimization algorithms, aiming\nto improve and optimize the efficiency of nuclear power fault\ndiagnosis. The experimental results show that the fault\ndiagnosis model based on Bayesian algorithm and\nEfficientNet large model exhibits high accuracy in diagnosing\nsingle or composite faults of main components in the primary\nand secondary circuits of nuclear power systems at different\npower levels. This discovery fully demonstrates the enormous\npotential and feasibility of large-scale deep learning models\nin fault diagnosis in the field of nuclear power, providing\nstrong technical support for safe operation of nuclear power."}]}