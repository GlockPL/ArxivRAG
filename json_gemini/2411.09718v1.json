{"title": "Non-Functional Requirements in Medical Imaging", "authors": ["Amanda Garde Vallentin"], "abstract": "The diagnostic imaging departments are under great\npressure due to a growing workload. The number of required\nscans is growing and there is a shortage of qualified labor. AI\nsolutions for medical imaging applications have shown great\npotential. However, very few diagnostic imaging models have been\napproved for hospital use and even fewer are being implemented\nat the hospitals. The most common reason why software projects\nfail is poor requirement engineering, especially non-functional\nrequirements (NFRs) can be detrimental to a project. Research\nshows that machine learning professionals struggle to work with\nNFRs and that there is a need to adapt NFR frameworks to\nmachine learning, AI-based, software. This study uses qualitative\nmethods to interact with key stakeholders to identify which types\nof NFRs are important for medical imaging applications. The\nstudy was done on a single Danish hospital and found that\nNFRs of type Efficiency, Accuracy, Interoperability, Reliability,\nUsability, Adaptability, and Fairness were important to the\nstakeholders. Especially Efficiency since the diagnostic imaging\ndepartment is trying to spend as little time as possible on each\nscan.", "sections": [{"title": "I. INTRODUCTION", "content": "NOWADAYS our healthcare system relies heavily on\nimaging data to diagnose and treat patients: 90% of all\nhealthcare data is imaging data [14]. All this data must be\nanalyzed and is in most cases done by radiologists. However,\nthe increase in imaging data has overtaken the number of\nradiologists. The results can be missed findings and long turn-\naround times which will jeopardize the patients' safety [14]. In\nDenmark it is especially the guarantee of treatment of cancer\nthat takes up many of the radiologists' resources and because\nthe investigation of most diseases today has evolved to require\nscans [4]. There is a potential for deep learning models to\nrelieve some of the pressure at the hospitals because they, like\nradiologists, can learn to recognize patterns. For this project, I\nwill focus on computer-aided detection (CADe) and diagnosis\n(CADx) medical imaging applications. These technologies are\nused to localize and classify entities of medical scans [14]\nand have the potential to lessen workload the workload of\nradiologists as well as improve diagnosing of patients."}, {"title": "A. Current State of Medical Imaging", "content": "As of 2022, 521 AI-enabled medical devices have been ap-\nproved by the FDA (Food and Drug Administration in the US).\nOut of those, 391 devices are in radiology [3]. This number\nincludes all kinds of models and algorithms that are based\non AI, consequently, we do not know how many of those are\nmedical imaging applications. The MONAI lab (Medical Open\nNetwork for Artificial Intelligence) published a report in 2021\nthat highlights that very few, if any, of the developed medical\nimaging applications have been implemented in hospitals [14].\nThey point towards the integration of models in the clinical\nworkflow as one of the biggest challenges for successful\nimplementation [14]. Chan et al. emphasize that many of the\nradiologist's tasks are too complex for current deep learning\nmodels, for example comparing two patient scans to detect\nchanges [2]. Liu et al. highlight that most medical imaging\nstudies do not validate their results externally or compare their\nperformance to radiologists [8]. Varoquaux and Cheplygina\ndocument how research in the area is guided by data set\navailability rather than clinical relevance and how this will\nlead to diminishing returns when continuing the research in\nmedical imaging [13]. Given the circumstances, there seems\nto be a lack of focus on the domain which might jeopardize\nfurther development in the field and implementation of the\nmodels in the hospitals."}, {"title": "B. The Importance of Non-Functional Requirements", "content": "When looking at traditional software projects, it is well-\ndocumented that many software development projects fail.\nThe CHAOS report from 2015 presents that the percentage of\nfailed and challenged projects is still high. In 2015 only 29%\nof the projects in their database were considered successful\n1]. Many project failures can be directly linked to poor\nrequirements gathering, analysis, and management [10]. This\ncan for example occur when users are not involved at all\nor only at the beginning of the process or when there is\nmiscommunication between the client and the development\nteam [10].\nLike it is for traditional software projects, Requirement\nEngineering (RE) should be a key process in the development\nof medical imaging applications because it ensures that the\ndevelopers understand the client and user needs and thereby\ngain domain focus in the development process.\nRE is a discipline within Software Engineering (SE) where\nthe goal is to develop requirements for a software system\nthat describe what the system should provide and its con-\nstraints [11, Chapter 4]. There are two types of requirements:\nfunctional and non-functional requirements (NFR). Functional\nrequirements describe the behavior of the system, NFRs are\nconstraints on the system [11, Chapter 4]. According to\nSommerville, it can be detrimental to a system if an NFR\nis not being met, for example, if an aircraft system does not\nmeet reliability requirements, it is not safe and will not be\nused [11, Chapter 4]. Also, the NFRs may affect the overall\narchitecture of the system which can make them expensive and\nhard to meet. Therefore, it is important to put great emphasis\non NFRs in the RE process because of their significant effect\non the system in question."}, {"title": "C. Non-Functional Requirements in Medical Imaging", "content": "Habibullah et al. recently published a study where they\ninterviewed Machine Learning (ML) professionals about their\ncurrent use of NFRs. They found that most interviewees\nstruggled with defining and measuring NFRs for ML systems\nand that some NFRs from the development of traditional\nsoftware need to be redefined to be applicable or relevant for\nML models [6]. This suggests that there are also challenges\nahead for those medical imaging developers that want to work\nwith defining NFRs because the framework has not been\nadapted properly to the type of software they are developing.\nThe goal of this research project is to take the first step to\ncreate a framework that can help medical imaging developers\nimplement NFRs in their application, to ensure that in the\nfuture, more medical imaging models will be implemented in\nthe hospital to lessen the workload of the radiologists."}, {"title": "II. METHODOLOGY", "content": "The overall approach of the project is to follow the princi-\nples of the RE process process which consist of three activities\n[11, Chapter 4]:\n\u2022 Elicitation and analysis (discovering requirements by\ninteracting with stakeholders)\n\u2022 Specification (converting requirements into a standard\nform)\n\u2022 Validation (checking that the requirements define what\nthe customer wants)\nThe activities are performed iteratively to ensure that the SE\nteam understand exactly what the client needs and they can\navoid making expensive changes to the requirements of the\nproduct [11, Chapter 4]. Each time the activities are performed,\nthe requirements grow more specific. In this project, I will\nfocus on the elicitation and analysis step and the specification\nstep.\nTraditionally, these steps are performed when you have a\nspecific design problem in mind, for example developing an\nimaging model that can detect liver tumors. Time will show\nwhether this approach will result in an actual framework or\nsomething unexpected. Additionally, I have chosen to focus\non the \"user\" stakeholders. Partly because of the scope of the\nresearch project but also because the MONAI lab pointed out\nthat the biggest roadblock for medical imaging applications is\nto merge the models into the clinical workflow. The key users\nare naturally radiologists, the doctors who describe the scans\nbut potentially also radiographers who perform the scans on\nthe patients."}, {"title": "A. Qualitative Methods", "content": "For the elicitation of requirements, I have chosen to use\nqualitative methods. These types of methods are ideal when\nthe goal is to understand a new field, you are not familiar\nwith [12]. Since I have limited knowledge about the field\nof diagnostic imaging and hospitals in general, these types\nof methods seem appropriate. Methods like interviews and\nobservations are characterized by the researcher using herself\nas an instrument to extract data. This raises ethical dilemmas\nbecause it is inevitable to build a relationship with the subjects\nwhich might influence the results, and secondly, the researcher\nshould be careful not to misuse the subjects' trust [12].\nFurthermore, it is important to address the threats to the\nvalidity of the study. Below each method I will reflect upon the\nvalidity and categorize the threats as researcher's bias (negative\ninfluence of researcher's knowledge and assumptions), reactiv-\nity (influence of researcher's presence), and respondent bias\n(subjects not being honest or trying to please the researcher)\n[7]."}, {"title": "B. Interview", "content": "Interviews are a popular method for requirement elicitation\nand there are different types depending on the objective of\nthe interview [15]. At the beginning of the project, I did an\ninterview with a chief radiographer at a Danish hospital. It was\na semi-structured interview with some predefined questions\nand themes, see interview guide in Appendix A. Since I\nhad limited knowledge of the field at the time, I choose\nto do a semi-structured instead of a structured interview.\nThe advantages of this method are that the interviewer does\nnot need to have deep knowledge about the topic of the\ninterview and therefore this type of interview can be held\nat the beginning of a project [15]. At the same time, the\ninterviewer still has some control over the conversation since\nthey decide the overall themes, which is not the case with a\ncompletely unstructured interview, where it is the interviewee\nwho decides the themes [12]. However, it can be difficult for\nan interviewer to remain in control during the semi-structured\ninterview because the interviewee also is allowed to bring in\nnew themes that may or may not be relevant.\n1) Objective of Interview: The main objective of the in-\nterview was to gain a basic understanding of the domain\ndiagnostic imaging. Another objective was to gain the trust\nof the chief radiographer and as a result, they would open the\ngate of the hospital and allow me to do research there. Before\nthe interview, I send them an agenda of the themes I wanted\nto cover as well as some questions below each theme. On the\nagenda, I also expressed how many field visits I would like. I\nframed it as a \u201c\u00d8nskescenarie\u201d (Wish Scenario) to emphasize\nthat it was negotiable. During the interview, it emerged that\nthe chief radiographer had been very involved with the current\nprocesses of buying medical imaging applications for the\nwhole region. They had many insights about the current\nimplementation problems of AI medical imaging solutions\nand the future financial and ethical challenges of using AI\nfor diagnostic imaging. Hence the semi-structured nature of\nthe interview allowed them to unfold themes that I had not\nthought of myself.\n2) Threats to Validity: Firstly, the interview was only done\nwith one subject, and it cannot be ruled out that another chief\nradiographer would have produced different data. However, the\nchief radiographer was a good representative of the field since\nthey had been involved in the decisions of buying AI solutions\nfor the whole region. I used a dictating machine to record\nthe interview to lessen the researcher's bias. The transcribed\ninterview can be found in Appendix B. If only notes are taken"}, {"title": "C. Ethnography", "content": "Ethnographic methods seek to study people in their field\nover a period to gain a deeper understanding of the activ-\nities that the subject performs as well as the relationships\nbetween the different stakeholders [15]. There are degrees of\ninvolvement depending on the chosen form of observation.\nFor example, the researcher can be a \"a fly on the wall\", or\nthe researcher can have more of an \u201capprentice role\". The\ndownsides of these methods are that they can be very time-\nconsuming [15]. Moreover, the subjects of study are prone\nto reactive bias since they can act differently because of the\nresearcher's presence [12].\n1) Objective of Ethnography: The objective to use ethnog-\nraphy was to obtain an understanding of the reality of the\nradiographers and radiologists and thereby gaining insights\nin their matters of concern. This was be done by visiting a\ndiagnostic imaging department on two different days where\nI first observed the radiographers and then the radiologists.\nIdeally, the observations would have lasted longer than just two\ndays. I did not feel comfortable asking for more days since the\ndiagnostic departments are under great pressure now. Although\nit was not ideal, I still believe I gained some valuable insights\ninto the domain with only two days in the field. During my\nvisits, I had a visible role where I also asked questions about\nwhat they were doing and why they were doing it in a certain\nway. Also, many of the staff at the hospital were curious about\nwhat I was doing there, and I had to explain many times\nwhat my project was about and what my background was.\nThey were not used to having other than medical students\naround and naturally, we also had many conversations about\nAI. Therefore, these visits that were supposed to be mainly\nobservational also turned into a bundle of smaller interviews.\n2) Threats to Validity: A challenge was that many of the\nradiologists seemed uncomfortable with me observing them\nwhen they were describing scans, which might have led them\nto act differently in my presence and thereby reactivity bias.\nI believe this is due to the nature of their work. They spend\nthe majority of their time in front of their computers and I\nmyself would also feel uncomfortable or watched if someone\nwas observing how I worked on my computer. Luckily, I ended\nup finding one radiologist that did not seem to mind having\nme around and was good at explaining their process. Hence\nmy understanding of the workflow of the radiologist is mainly\nbased on that person. Even though this person was comfortable\nwith being observed, they might still have been reactive bias.\nIt was generally easier to observe the radiographers that\nwere naturally very focused on the patients resulting in them\nseemingly forgetting about my presence from time to time.\nOn both my visits, I carried a notebook where I wrote down\nobservations and quotes from the people I talked to as well as\nsmall drawings of workflows. I could tell that this also distracted the subjects from\ntime to time and some of them were very curious as to what\nI was writing down. This might have also caused respondent\nbias because they were aware that I was writing notes. Another\naspect that should be mentioned is that most of the subjects\ndid not have \"a choice\u201d regarding me observing them (as far\nas I am aware). Since the approval of the chief radiographer, I\nnegotiated dates with the managing radiographer who assigned\none of the radiographers and radiologists to be responsible\nfor me. Therefore I tried to be as mindful as possible and\navoided people that seemed uncomfortable with me. During\ndata processing, I anonymized all the subjects down to their\ngender and tried not to include sensitive information. The\ndemography of the subjects was mixed. There was a broad\nrepresentation of different ethnic backgrounds and an over-\nweight of women in both radiographers and radiologists. There\nwas also a broad age representation. However, there were more\nolder radiologists than young ones. Most of them were in their\nforties and fifties. There were more young radiographers than\nold, many of them were in their thirties.\""}, {"title": "D. Affinity Diagram", "content": "Affinity Diagram is a way of analyzing field data from\nthe users which reveals their matters of concern [5]. Before\nbuilding an Affinity Diagram, all field data is condensed and\nwritten onto post-its that can be moved around. The post-its are\nplaced on a wall in smaller groups that describe a single issue\nor point that is relevant to the design problem. The groups must\nbe small, and the groups cannot be predefined but must emerge\nfrom the data. Afterwards, each group will be assigned a blue\npost-it that describes the point of the group in the voice of the\nuser. For example, if there is a group of post-its describing how\nradiologists are busy in different ways, a blue post-it for this\ngroup might say \"I must always describe images as fast as I\ncan\". Finally, the blue post-its are organized in areas of interest\nwhich are pink labels. Those labels are then grouped under\ngreen labels that depict whole themes [5]. When the Affinity\nDiagram is finished, the product is a hierarchical structure that\ndescribes the users' matters of concern in different levels of\ndetail. As a viewer, it is easy to get an overview of the users'\nneeds."}, {"title": "1) Objective of Affinity Diagram:", "content": "The objective of the\nAffinity Diagram was to infer the radiographers' and radi-\nologists' matters of concern from the collected data. I chose\nthis method because it creates a visual overview of all the\ndata and their connection to the themes. It also shows what\ndata contributed to what themes which can make it easier to\ndetect bias or find areas that need further research. Lastly,\nthe data can be of different types, so it is possible to analyze\nboth interview and observation data simultaneously. However,\nI had to alter the method since I had fewer data pieces\nthan recommended and wanted to create a digital board that\ncould easily be viewed and shared. Usually, a board is built\nwith data from 12-16 user interviews with 50-100 notes per\nuser [5]. I have been in contact with around 20 users (8\nradiologists, 12 radiographers, and 1 chief radiographer) and\nended up with around 100 notes on my affinity board. From\nmy bachelor, I have experience in using the method with less\ndata than recommended with good results, therefor I chose to\nuse the method despite my data shortcomings. Traditionally,\nan Affinity Diagram is built as an analog board with paper\npost-its and they are built with a bigger group of people. This\nis mainly done to speed up the process, but also to validate\nthe inferred themes. Depending on how much data there is,\nthe board can get enormous which makes it inconvenient to\nhang somewhere in the duration of the project.\n2) Threats to Validity: Since I am a team of one person, I\ndid not have the opportunity to build the diagram with team\nmembers. Hence a researcher's bias is expected. In hindsight,\nI should have sought out some fellow students or researchers\nto help me build the Affinity Diagram, or at least have tested\nif someone else would have chosen the same themes over the\nsame data. To lessen the bias I looked at the data pieces in\nrandom order to avoid pre-imposed themes."}, {"title": "III. ANALYSIS", "content": "The analysis process consisted of two phases: Collection\nof Data and Data Analysis. The objective of the first phase\nwas to transform the interview and observations into smaller\ndata pieces that could be analyzed. In the second phase, the\nobjective was 1) transform the data into matters of concern\nand 2) translate matters of concern into NFRs. The process\nwill be detailed in the following paragraphs."}, {"title": "A. Transform Interview into Post-It Format", "content": "Firstly, I transcribed the interview to translate the audio file\ninto text that could easily be analyzed. I did an initial coding\nof the interview where the text was grouped into themes,\nsee Appendix C. The themes are decided by the researcher\nand what meaning she deducts from the different parts of the\ninterview [12]. Coding is usually applied to identify themes\nand patterns across multiple interviews. As described in earlier,\nthere was only a single interview. Therefore, I used coding to\ncategorize the interview into parts that I believed were relevant\nto include in the Affinity Diagram, instead of comparing\nthemes across interviews. Below are the identified themes of\nthe interview:"}, {"title": "B. Transform Observations into Post-It Format", "content": "Transforming the data from the field visits were done\ndifferently from the interview since there were no audio\nrecordings. Instead, I had my field notes and my memory\nto rely on. Naturally, this also introduced researcher bias.\nPerhaps to a greater extent than before, since there was no\naudio recording of the visits. When I returned from the field\nvisits, I wrote down what I experienced either the same\nevening or the next morning to ensure that no important\ndetails would be forgotten. Traditionally during fieldwork, the\nresearcher keeps account of their observations in a journal that\nis later used to write what is called \"thick descriptions\" [12].\nThick descriptions are extremely detailed accounts of what\nthe researcher observed that include the cultural practices and\nbeliefs of the subjects [9]. Since I had limited time in the\nfield, I simply described the situations I had observed and\nexperienced in the hospital and did not write a journal. I chose\na vignette format where I described specific situations from\ndifferent locations. The goal of the fieldwork was not to get a deep understanding of\nthem but rather an understanding of their workflow and matters\nof concern. Lastly, I picked out quotes from the vignettes\nthat were central to my observation or reflected something\ninteresting. These quotes were also written on post-its in Miro\nso they could also enter the Affinity Diagram."}, {"title": "C. Transform data into matters of concern", "content": "When the data entered the Affinity Diagram, it was kept in\nthree groups depending on where it came from. The groups\nwere data from the interview with the chief radiographer, ob-\nservations of radiographers, and observations of radiologists.\nEach group was assigned a color to ensure that when the initial\ngroups later were broken up, you would still be able to tell\nwhere the data came from. Usually in Affinity Diagrams, the"}, {"title": "1) Current Al is a bad investment for us:", "content": "This matter of\nconcern stems from two issues that the hospitals are facing\nright now when they want to buy AI solutions for diagnostic\nimaging. The first issue is that they cannot afford the current\nsolutions. If they invest in an AI solution, they need to know,\nthat it can save them resources. The resources can be in the\nform of staff; maybe they can settle with 8 radiologists instead\nof 7, or it can be in saved time so that current radiologists\ncan describe images faster. However, the results, they know\nabout, show that there can only be saved minimal resources\nand that the investments have been loss-making transactions\nmeaning that the cost of using AI was much larger than the\nsaved resources. Another problem is that the hospitals lack a\nfair way of financing the models. Right now, the diagnostic\nimaging department is told that they need to pay for the models\nsince the models work on their scans instead of for example\nspreading the cost evenly among all departments. The second\nissue is that they are concerned about what implications the\nAl models will have in the future for them. For example, can\nradiologists get sued for not trusting an Al prediction if it\nlater turns out that the patient got sick? Also, none of the AI\nsuppliers will take legal responsibility for their models' results,\nso an AI prediction always needs to be held up against a real\nradiologist's opinion. This is also why it is difficult to avoid the\nAI models being a loss-making investment because they are\nnot legally allowed to replace radiologists. Also, it is important\nfor the hospital that the AI solutions have a low level of false\npositives since these types of results potentially can make the\nhospital spend unnecessary resources on patients that are not\nsick."}, {"title": "2) Our radiographers do more and more radiology:", "content": "This\nmatter of concern stems from the matter of concern below;\nthey are pressured on time and staff. A solution they have\nbeen working towards in the past years is to move some of\nthe workloads of the radiologists to the radiographers. It is\neasier to hire radiographers than radiologists. This means that\nmost X-rays are not described by \"describing radiographers\"\nwho have received special education to learn how to describe\nthose scans properly. The ultrasounds will also be done by\nspecialized radiographers in the future. An interesting thing\nthat I noticed during my field visits was that the radiographers\nalso analyzed the scans and told me about what they could see\nwas wrong with the patient. It turns out that they also look\nfor abnormalities in the patient to detect if there is an acute\nissue that needs to be looked at right away."}, {"title": "3) We are pressured on time and staff:", "content": "Another major\nmatter of concern is that both the radiologist and radiographers\nare understaffed while the number of required scans for\npatients are increasing. This also means that they have fewer\nresources to help educate new radiographers and radiologists\nwhich creates a negative reinforcement loop. The radiologists\nexpress that their systems are not geared to handle as many\nscans as they do now and that they also avoid using extra\naids. For example, they have access to a program that shows\nthe scans in better resolutions, but most of them do not use it\nbecause it takes too long to open the programs. Therefore,\nthey request that the software they will buy in the future\nwill save them valuable time. They want software where they\ndo not have to click around in many different interfaces but"}, {"title": "4) We must always adapt:", "content": "The last identified matter of\nconcern is that the work of both radiographers and radiologists\nis very challenging because there are many factors that needs\nto be considered when they scan and describe a patient. They\nmust always adapt to the special circumstances of exactly that\npatient. For example, a patient can have an injury that prevents\nthe radiographers from doing a scan after the book. Or maybe\nthe patient has an old injury that still shows up on the scan\nbut does not need to be treated. In general, every patient looks\ndifferent which also makes it challenging to know what is\nabnormal and dangerous and what is not."}, {"title": "D. Translate Matters of Concern into Non-Functional Re-quirements", "content": "The following NFRs can be identified from the analysis:\n1) The application must make the overall process of scan-\nning or describing a patient faster by XX%\n2) The AI model must have a false positive percentage\nunder XX%\n3) The application must only take XX seconds to open and\nrun\n4) All important information must be shown in the same\nuser interface\n5) The model must be able to run on many different patients\nand types of scans\nIn table 5 in Habibullah et al.'s article about NFRS for Ma-\nchine Learning [6], several NFRs for machine learning systems\nare identified and defined. Their list can be compared to the\nidentified NFRs of this project to translate them into more\ngeneral NFRs that medical imaging application developers\nshould design for.\n1) Efficiency: Habibullah defines efficiency as \"The ability\nto accomplish something with minimal time and effort\" which\nboth the first and the second requirement is describing because\nthe hospitals need to save resources to be willing to invest.\nAdditionally, using the application should take up as little time\nas possible for the already time deficient radiographers and\nradiologists. Hence this general NFR relates to the first and\nthird requirement.\n2) Accuracy: Habibullah defines accuracy as \"The number\nof correctly predicted data points out of all the data points\".\nThe radiologists of course want predictions from the model\nthat are as accurate as possible. However, it is especially\nimportant to them that the predictions have a low amount\nof false positives because that can potentially mean wasted\nresources on healthy patients. Consequently the accuracy NFR\nshould be more detailed and specifying levels of sensitivity\nand specificity. Thus this general NFR relates to the second\nrequirement.\n3) Interoperability: Habibullah defines interoperability as\n\"The ability for two systems to communicate effectively\".\nPossibly the application could be integrated with the current\nIT systems as an \"add in\" to ensure that the user will spend\nas little time as possible on opening up and running the\napplication. Therefore this general NFR could apply to the\nfirst and third requirement.\n4) Reliability: Habibullah defines reliability as \"The proba-bility of the software performing without failure for a specific\nnumber of uses or amount of time\u201d. The application needs to\nhave a reliable runtime and should be able to handle the big\nimaging data seamlessly. If the application is not reliable, the\nradiologist will not use it since they cannot afford to waste\nany time. Again, this general NFR also applies to the first and\nthird requirement.\n5) Usability: Habibullah defines usability as \"How effec-tively users can learn and use a system\u201d. From my data, the\nradiologists see usability as using as few clicks as possible.\nThey like to have all essential information they need in\none interface. Hence this general NFR relates to the fourth\nrequirement.\n6) Adaptability: Habibullah defines adaptability as \"The\nability of a system to work well in different but related\ncontexts\". In the case of the radiologists, it could mean that\nthe models would also work on scans that are abnormal. For\nexample there could be medical equipment in the scan like\ntubes or the scan could be from an abnormal angle due to\na patient's injury. Thus this general NFR applies to the fifth\nrequirement.\n7) Fairness: Habibullah defines fairness as \"The ability of\na system to operate in a fair and unbiased manner\". This is\nalso related to adaptability above. The application should be\nable to work on all types of patients. Therefore this general\nNFR also applies to the fifth requirement."}, {"title": "IV. DISCUSSION", "content": "From performing the two first key activities in the RE pro-cess, elicitation, and specification, it was possible to identify\nfive different non-functional requirements that can be linked\nto seven different general NFRs. However, the five identified\nNFRs are too broad or non-specific for developers to work\nwith. The next steps to specify them further would be to\nvalidate the findings with the stakeholders and generally do\nmore iterations of the RE process. An apparent limitation of\nthe result is that the data only comes from a single Danish\nhospital. Further research is needed to confirm or deny whether\nthe identified NFRs also apply to other diagnostic imaging\ndepartments in Denmark or other countries."}, {"title": "B. Weaknesses in the Analysis", "content": "As was mentioned in the Methodology paragraph, the\nAffinity Diagram can reveal weak points in the analysis since\nyou can see what data contributed to what themes. Generally,\nit is ideal if each blue theme post-it has data from different\nusers to make sure that the themes are representative of all the\nusers or a group of users. If we look at the green high-level\nmatter of concern \"Current AI is a bad investment for us\"\nand follow the hierarchy down to the blue post-its, it appears\nthat most of the yellowish data post-its have the same sand\ncolor, which means that they come from the interview with\nthe chief radiographer,"}, {"title": "C. Resource Savings VS Performance", "content": "A major finding in this study was also that there seems\nto be a significant difference in what the hospitals value in\nmedical imaging AI applications and what the developers\nvalue in medical imaging AI applications. The hospitals see\nit as a way to save resources and can actually not afford to\ninvest in the solutions unless they see a return on investment.\nContrary to the hospitals, the developers focus on creating\nmodels that perform better than radiologists [8]. This is a\nrather unfortunate difference, and it makes me wonder if the\ndevelopers are aware that their models cannot legally replace\nradiologists. When a radiologist still needs to check every\nsingle prediction and decide whether they believe it or not,\nnaturally they also need to analyze the scan. Then it is difficult\nto imagine any amount of time saved and then it does not pay\nfor the hospitals. These findings could be viewed as a symptom\nof the lack of focus on the domain that medical imaging\napplication developers may have. However, it is also important\nto raise the question of whether these types of developers\nhave the competencies or tools to understand the domain.\nTraditionally, these types of developers come from a data\nscience background and are experts in analyzing data, finding\npatterns with the help of statistics and math, and now also\nmachine learning. Yet they do not know much about software\nengineering. For example, I had to explain to my research\ngroup, PURRLab, which researches in medical imaging, what\nrequirement engineering and non-functional requirements are.\nThis raises another question of who exactly should oversee the\nrequirement engineering process and who will benefit from\nmy study. Further research is needed to determine who should\nundertake requirement engineering tasks for medical imaging\napplications."}, {"title": "V. CONCLUSION", "content": "By using qualitative methods to understand the matters of\nconcern of radiographers and radiologists, this study identified\ngeneral non-functional requirements. These may be used by\nmedical imaging application developers to ensure that more\napplications are implemented in the hospitals and relieve some\npressure on the diagnostic imaging departments. The results\nshould be validated in further research since the data only\ncame from a single hospital and since the analysis may be\nsubject to researcher bias since only one person contributed\nto the analysis. Further research is also needed to detail the\nrequirements."}]}