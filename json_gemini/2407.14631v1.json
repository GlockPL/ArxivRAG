{"title": "Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: a comprehensive analysis", "authors": ["Kamyab Karimi", "Ali Ghodratnama", "Reza Tavakkoli-Moghaddam"], "abstract": "In recent decades, breast cancer has become one of the leading causes of mortality among women. This disease is not preventable because of its unknown causes; however, its early diagnosis increases patients' recovery chances. Machine learning (ML) can be utilized to improve treatment outcomes in healthcare operations while diminishing costs and time. In this research, we suggest two novel feature selection (FS) methods based upon an imperialist competitive algorithm (ICA) and a bat algorithm (BA) and their combination with ML algorithms. This study aims to enhance diagnostic models' efficiency and present a comprehensive analysis to help clinical physicians make more precise and reliable decisions. $K$-nearest neighbors (KNN), support vector machine (SVM), decision tree (DT), Naive Bayes, AdaBoost (AB), linear discriminant analysis (LDA), random forest (RF), logistic regression (LR), and artificial neural network (ANN) are some of the methods employed. Sensitivity, accuracy, precision, mean absolute error $F$-score, root mean square error, Kappa, and relative absolute error calculated the performance of the methods. This paper applied a distinctive integration of evaluation measures and ML algorithms using the wrapper feature selection based on ICA (WFSIC) and BA (WFSB) separately. We compared two proposed approaches for the performance of the classifiers. Also, we compared our best diagnostic model with previous works reported in the literature survey. Experimentations were performed on the Wisconsin diagnostic breast cancer (WDBC) dataset. Results reveal that the proposed framework that uses the BA with an accuracy of 99.12% surpasses the framework using the ICA and most previous works. Additionally, the RF classifier in the approach of FS based on BA emerges as the best model and outperforms others regarding its criteria. Besides, the results illustrate the role of our techniques in reducing the dataset dimensions up to 90% and increasing the performance of diagnostic models by over 99%. Moreover, the result demonstrates that there are more critical features than the optimum dataset obtained by proposed FS approaches that have been selected by most ML models, including the standard error of area, concavity, smoothness, perimeter, the worst of texture, compactness, radius, symmetry, smoothness, concavity, and the mean of concave points, fractal dimension, compactness, concavity that can remarkably affect the efficiency of breast cancer prediction. This study illustrates the role of our approaches in enhancing treatment outcomes in healthcare operations.", "sections": [{"title": "1 Introduction", "content": "Compared to other types of cancer, breast cancer is considered one of the significant and the second most prevalent cause of death among women\u00b9 (Chaurasia & Pal, 2014). In 2014, an estimated 232,714 new breast cancer cases were diagnosed in women, with 297,800 female patients dying (Mandal, 2017). In 2020, there will be 2.3 million diagnoses and 685,000 deaths worldwide. Breast cancer had been diagnosed in 7.8 million women alive in the previous five years by the end of 2020, making it the world's most common cancer.\u00b2 The American Cancer Society (ACS) reports that 99% of people who receive treatment for breast cancer in the earliest stage live for five years or longer after diagnosis.\u00b3\nThe methods for cancer diagnosis primarily depend on the expertise of physicians whose medical imaging is used to assist in this process and diagnose specific symptoms generally occurring in later stages of cancer. This disease is treatable early when symptoms and clinical signs appear in advanced stages (Li & Chen, 2018). Therefore, diagnosing in the early stages can save the lives of many patients. Also, due to human and healthcare operations errors, various treatments that experts and doctors accomplish might not be effective enough, and timeliness is also costly.\u2074\nMisdiagnosis leads to incorrect treatments, which causes the patients to lose the best time for treatment, which will prompt drastic results (Reddy et al., 2022). As a result, selecting a framework to predict the nature of the breast tumor and categorizing it as benign or malignant is of utmost importance.\nMachine learning (ML), one of the most widely used branches of artificial intelligence (AI), engages with the development and investigation of methods and algorithms that provide computers and systems with the ability to train and learn. ML greatly assists in saving operational costs and improving the speed of the data analysis (Russell & Norvig, 2021). For example, in recent years, with the increase in community knowledge and AI development, especially in data mining, many studies have been conducted regarding the early detection of breast cancer (Mate & Somai, 2021). On the one hand, classification models exploited in data-mining methods determine the type of tumor and the accuracy of diagnosis. However, on the other hand, vast amounts of information and features in a dataset consume much time and create high computational costs for ML algorithms to process this amount of data (Tohka & van Gils, 2021). Hence, reducing the dimensions of the dataset to its more critical information content is of particular importance.\nFeature selection (FS) plays an essential role in ML algorithms. It aims to remove the irrelevant or redundant features of the data to achieve better classification performance (Qasim & Algamal, 2020). As a result, FS methods improve breast cancer prediction and diagnosis"}, {"title": "2 Literature survey", "content": "Extensive studies have investigated and diagnosed breast cancer using different data mining and ML methods. This section reviews two subjects, including diagnosis without and with FS."}, {"title": "2.1 Diagnosis without FS methods", "content": "Some studies performed in this area have merely compared ML methods. For instance, various data mining methods and classification algorithms have been used to compare methods' performance and not to improve them. Support vector machine (SVM) and artificial neural network (ANN) approaches are examined as ML methods for classification in the WEKA tool by Bayrak et al. (2019). They have compared the results obtained from these methods using the parameters of the Accuracy, Precision, recall, and receiver operating characteristic (ROC) diagram. The SVM has shown the best performance in the accuracy of 96,9957%. Alshammari and Mezher (2020) provided Using the WEKA tool, and a comparative analysis was carried out. Lazy IBK (instance-based learning with parameter K), Naive Bayes (NB), logistic regression (LR), DT, lazy locally weighted learner, lazy k-star, decision stump, rules"}, {"title": "2.2 Diagnosis with FS methods", "content": "FS has been a hot topic of study in recent years. Several kinds of research undertaken a detailed literature study on feature selection strategies. On the Wisconsin prognosis breast cancer (WPBC) dataset, Sakri et al. (2018) focused on improving the accuracy value utilizing an FS approach called particle swarm optimization (PSO), as well as reduced error pruning (REP), tree KNN, and NB. The Saudi Arabian women's breast cancer issue was held from their endeavor standpoint. According to their findings, women over 46 are the most common victims of this deadly illness. Salma and Doreswamy (2020) proposed a hybrid diagnostic model that combines the feed-forward neural network (FNN), the Bayesian algorithm (BA), and the gravitational search algorithm (GSA). According to the research, the hybrid BATGS model outperforms its counterparts, generating a high accuracy of 94.28% for the WDBC"}, {"title": "2.3 Research gap", "content": "As revealed in Table 1, several implications can be drawn from the literature review of studies on diverse feature selection and ML algorithms. First, most papers used just a few measures like Accuracy (Liu et al., 2019; Mahendru & Agarwal, 2019; Rao et al., 2019) or other common criteria such as sensitivity and specificity (Bayrak et al., 2019; Salma & Doreswamy, 2020; Wang et al., 2018) that could not be comprehensive for making more precise decisions, since there was not always a specific criterion to use, and multiple criteria were needed for multiple settings. Likewise, ML algorithms that operate well on one criterion may not operate well on other criteria (Caruana & Niculescu-Mizil, 2004; Sokolova & Lapalme, 2009). Thus, in addition to the mentioned criteria, we exert other applicable measures such as precision, F-score, Kappa statistic, RMSE, RAE, and MAE to raise the validity of the research. Second, the use of evolutionary algorithms as search techniques in the wrapper approach upturned the overall efficiency of the ML algorithms. As a result, we offer two novel feature selection approaches that combine the ICA and BA with ML algorithms. The WFSIC and WFSB aim to eliminate irrelevant data with less predictive output and select more essential features for increasing accuracy and performance of diagnosis at early stages since the selection of more important data from the dataset results in saving the costs of collecting medical data and reducing the time of diagnosis and patients' wait for treatment. Third, previous works have utilized less than five classifiers to diagnose breast cancer, which can be less comprehensively and reliable.\nIn contrast, all nine possible ML algorithms for classification problems have not been exploited to predict breast cancer (Abdar et al., 2020; Bayrak et al., 2019; Liu et al., 2019; Mahendru & Agarwal, 2019; Rao et al., 2019; Salma & Doreswamy, 2020; Wang et al., 2018). Using nine ML algorithms enhances decision-making reliability and presents a comprehensive analysis for clinical physicians. These classifiers are NB, SVM, KNN, LR, DT, ANN, linear discriminant analysis (LDA), and two ensemble learning algorithms, AB and RF. Table 1 classifies the related literature review and the status of our contribution.\nMyopically, Table 1 shows that four assessment criteria for predicting and diagnosing breast cancer, Kappa, MAE, RMSE, and RAE have not been utilized or have been used sparingly in recent papers. Additionally, two ensemble learning algorithms (i.e., Ensemble AB and RF) have not been employed in recent studies in machine learning algorithms. Furthermore, our research differs from the previous studies such that no study has ever combined these nine assessment criteria and these nine machine learning algorithms to identify breast cancer.\nThis research is more thorough since no other study has combined these 18 rating criteria with machine learning methods. Additionally, Tables 8 and 10 show that in previous studies for the diagnosis of breast cancer, a technique for ranking and importance of each feature of the dataset according to the number of their selection by the learning stage (training) of machine learning algorithms in conjunction with the suggested feature selection methods was used. The cross-validation approach (K-fold) utilized in this study was not put into practice; it helps medical professionals diagnose diseases more quickly and affordably by letting them know, which aspects are most important. It lowers the mortality rate and raises the likelihood of rescuing the patient."}, {"title": "3 Materials and methods", "content": "This section would like to discuss the dataset, proposed FS methods, meta-heuristics, and ML algorithms. Then, at the end of this section, we explain our framework, including the mentioned cases."}, {"title": "3.1 Wisconsin breast cancer database", "content": "The dataset used in this study was obtained from the University of California's ML division and is accessible in its database under the WDBC6 license. This dataset includes 569 instances, each encompassing 30 real-valued input features. There are 212 malignant and 357 benign patients within this dataset. The 30 attributes are calculated from the digitalized images of a chest mass. Ten attributes with continuous values are calculated for each cell nucleus with 30 desired properties. For each picture, calculating the mean, standard error (SE), and worst or greatest (mean of the three largest values) values of these features yields 30 features. For example, the mean radius is field 1, the radius standard error is field 11, and the worst radius is field 21. Table 2 lists the features and their descriptions."}, {"title": "3.2 Proposed meta-heuristic algorithms", "content": "The ICA and the BA are surveyed in this subsection as one crucial part of the proposed framework, whose applications to disease prediction are investigated and compared."}, {"title": "3.2.1 ICA", "content": "The ICA is an evolutionary algorithm for global optimization that provides a solution inspired by imperialistic competition. The main foundations of this algorithm are assimilation policy, colonial competition, and revolution. Like other optimization algorithms, the ICA requires the definition of different steps whose repetition can optimize the problem (Hosseini & Al Khaled, 2014; Javanmard et al., 2014; Molla-Alizadeh-Zavardehi et al., 2016; Nekooghadirli et al., 2014; Sedehzadeh et al., 2016; Shirzadi et al., 2017; Zhalechian et al., 2017).\nThe ICA's method may be summed up as follows:\n(1) Initialization: create the $N_{Ipop}$ population.\n(2) Create an initial empire by calculating $c_i$ for each person, sorting $c_i$ in decreasing order for all solutions, selecting $N_{imp}$ best solutions from $N_{pop}$ as imperialists, and allocating $N_{col}$ great countries to the imperialists.\n(3) Assimilate colonies, carry out a revolution in certain colonies, and swap the colony and imperialist if feasible for each empire.\n(4) Be victorious in imperialist competition.\n(5) Destroy the empire by removing all of the nations.\n(6) Continue to Step 3 if the termination requirement is not met; otherwise, cease looking.\nThe country cost is measured concerning the objective function: the less the cost, the better the solution. $N_{imp}$ is the most cost-effective solution, characterized by imperialists. The remainder of the nations has been designated as colonies. $N_{col}$ is a kind of colony that may be expressed as $N_{col} = N_{pop} - N_{imp}$ (Atashpaz-Gargari & Lucas, 2007). The first empires are formed by awarding colonies to imperialists (k) and conferring power ($P_k$) on the imperialists:\n$P_k = \\frac{Y_k}{\\sum_{v=1}^{N_{imp}} Y_v}$\nwhere $Y_v = max_k{c_k} - c_v$ denotes the normalized cost, whereas $c_k$ is the imperialist $k$'s cost. The number of initial colonies impacted by imperialist $k$ is calculated as round {$P_k \\times N_{col}$}, where the round is a function that returns the fractional number's an adjacent integer. $H_k$ is also the collection of imperialist $k$'s colonies.\nEach empire's colony alters as much as $\\epsilon$ possible along with the direction $e$ toward its imperialist throughout the assimilation process. It is important to note that $\\epsilon$ is a random number with a random probability distribution [0, $\\beta \\times e$], where $\\beta \\in [1, 2]$. Setting $s > 1$ forces the colony to adopt an imperialist mindset. A diversion is proposed to avoid colonies being somewhat absorbed in imperialism. If there isn't a variation, the answer is more likely to be locked in a local optimum. Where @ is an arbitrary parameter, the deviation parameter @ follows a uniform probability distribution [$\\theta, \\theta$].\nWhen it comes to the ICA's revolution, it's about shifting certain colonies' positions owing to unanticipated differences in their qualities. A colony's traits will be altered if its language or religion is changed, leading to a shift in its location (Li & Chen, 2018).\nFollowing the assimilation and revolution processes, each colony's cost is linked to that of its imperialist, and a colony is traded with the imperialist if the colony's cost is lower. Imperialist rivalry is a major step toward an empire's ultimate might. The total cost of empire $k$ is denoted by $TC_k$. For each empire $k$, we first calculate $TC_k$ by:\n$TC_k = c_k + \\zeta \\times mean{Cost(colonies of empire_k)}$\nwhere $\\zeta$ is a positive integer in the range of 0 to 1 that is close to 0, the normalized total cost of empire $k$ and empire $k$'s influence is then calculated as follows:\n$NTC_k = max_h{TC_h} - TC_k$\n$EP_k = \\frac{NTC_k}{\\sum_{v=1}^{N_{imp}} NTC_v}$\nFollowing the definition of a vector [$EP_1 - \\beta_1, EP_2 - \\beta_2, ..., EP_{N_{imp}} - \\beta_{N_{imp}}$], the weakest colony from the poorest empire is assigned to the empire with the largest index. $I$ denote a random integer associated with the uniform distribution in the range of [0, 1]. The ICA's pseudo-code is shown in Fig. 1."}, {"title": "3.2.2 \u0392\u0391", "content": "The collective behavior of bats inspires the BA in their natural environment. It is based on the phenomenon of bats' treble sound reflection and the receiving of these sounds by the bat. The tool for reflecting sound and receiving its reflection in tiny bats provides them with significant hunting and crossing obstacles (Yang, 2010). The BA's steps are described as follows:\nStep (1) Generating the primary population: primary bats, initial parameters, and constants are determined. The initial population of bats is generated entirely randomly in the search solution space, as mentioned in Eq. (5). $X_i$ is a vector of random variables denoting the observed attributes.\n$X_i = (x_i^1, ..., x_i^d, ..., x_i^N)  i = 1, 2, ..., N$\nStep (2) Calculating the objective function: at this step, the objective function, which in this paper is identical to the cost function, is determined for each bat.\nStep (3) Updating the speed and position of bats: each bat moves with speed $V_i$ and a position $X_i$ in the repetition of t and N-dimension search space and moves towards the best bat ($X_*$). Also, each bat has a random frequency ($f_i$) in the range of [$f_{min}, f_{max}$]. Then, according to Eqs. (6)\u2013(8), new temporary positions are generated with frequency adjustment and updating the speed of all bats. In this study, the initial velocity of each bat is set to zero, and their initial positions are selected randomly (Yang, 2010, 2013).\n$f_i = f_{min} + (f_{max} - f_{min})\\beta$\n$V_i^t = V_i^{t-1} + (X_* - X_i^t) f_i$\n$X_i^t = X_i^{t-1} + V_i^t$\nStep (4) Evaluating the chances of bats and updating their velocity and pulse emission rate: Each bat has a chance to receive a pulse from the top bat. The pulse emission rate ($R_i$) must be less than a random value (rand) to detect this issue. Then, the position, velocity, and $R_i$ of the bats are updated in case the new position of each bat is checked using two conditions, in which both of those conditions hold. First, the new position of each bat must be better than its previous position, and second, the loudness of the bats' voice ($A_i$) must be higher than the random value. The related equations are shown below.\nif rand > $R_i$\n$X_{new} = X_i + \\epsilon A$\nif (rand < $A_i \\& f(x_{new}) < f(x_i))$\n$A_i^{t+1} = \\alpha A_i^t$, $R_i^{t+1} = R_i^t[1 - exp(-\\gamma t)]$\nIn the proposed formulas, $\\beta$ represents a random number falling in the range of [0, 1] related to the uniform distribution in [0, 1], $\\epsilon$ indicates a random number in [-1, 1], and a and y are constant (Qasim & Algamal, 2020).\nStep (5) Controlling the convergence: In convergence, the optimization stops; otherwise, the algorithm returns to Step 2, and then, Steps 2\u20135 are repeated. After completing the iterations of the BA, the position of the best bat will be the solution to the optimization problem. The BA's pseudo-code is displayed in Fig. 2."}, {"title": "3.3 FS methods using the ICA and BA", "content": "This section explains the importance of using the FS method in the proposed framework. The FS chooses a minimum set of features by leaving out irrelevant features. The result of the mining task on the minimum set becomes more satisfactory than that of the complete feature set. Overall, the benefits of feature selection are as follows (Kaufmann, 1999):\n\u2022 Reducing the curse of dimensionality.\n\u2022 Generalizing the model.\n\u2022 Speeding up the model building process.\n\u2022 Enhancing the interpretability and comprehensibility of the resulting model.\nThe wrapper and filter methods are the most general methods utilized in the FS. The filter approach is a simple strategy for sorting the features based on criteria. As a whole, filter approaches are computationally inexpensive and straightforward. Meanwhile, selecting an appropriate learning algorithm can be challenging. On the other hand, under the wrapper approach, performance optimization of an ML model is used to choose the best feature subset. Wrapper approaches use a machine learning algorithm, and a metaheuristic optimization strategy is employed to get the best feature set. Besides, the classification process using the best features will be more straightforward and accurate (Qasim & Algamal, 2020). This work uses a wrapper feature selection (WFS) technique based on the BA and ICA and mixes them with ML algorithms to train and build classification models. The ICA and BA were selected as the metaheuristic optimization algorithms in this WFS approach because of their excellent performance (Ahmadi et al., 2013; Hosseini & Al Khaled, 2014; Lu et al., 2021; Salma & Doreswamy, 2020)."}, {"title": "3.4 ML algorithms", "content": "This section entirely describes the ML algorithms used in the presented framework. In addition, it notes that basic models of the algorithms are utilized for diagnosis."}, {"title": "3.4.1 ANN", "content": "Neural networks are interconnected processing elements known as neurons that solve a problem. One of the key advantages of ANN is that it can learn to explain complicated real-world data that is noisy, such as x-ray pictures and medical records, without explicitly doing so (Smith, 1993). An ANN comprises three layers hidden, input, and output layers. The neurons in every layer are linked with a specific weight. The weights are initialized randomly at first and then updated based on the output of the ANN such that the amount of the output is less compared to the previous iteration. The number of nodes at the input layer equals the number of features. The number of labels is represented by the number of nodes in the output layer. Trial and error are used to determine the number of nodes in the hidden layer. Furthermore, each node has a transfer function that creates output within an acceptable range (Aslan et al., 2018)."}, {"title": "3.4.2 SVM", "content": "The SVM is a supervised ML algorithm employed for regression and classification Vapnik and Chervonenkis (Vapnik & Chervonenkis, 1991). Each data sample in the SVM is represented as a dot on the data scatter plot in N-dimensional space, where N is the number of features in the data sample. In addition, the value for each attribute represents one of the components of the point's coordinates on the plot. Then, it classifies different and distinct data by drawing a straight line. One of the main benefits of the SVM is that, unlike empirical risk minimization-based statistical learning techniques, it tries to reduce structural risk, demonstrating a great capacity to prevent overfitting (Wang et al., 2018)."}, {"title": "3.4.3 NB", "content": "The NB classification method exploits the Bayesian theorem and independence assumption between variables. It is recognized as a member of the family of probability-based classifications (Mandal, 2017). Bayesian classifiers determine the most probable class for a given case based on its feature vector. Because of the independence assumption, NB saves time. Another advantage is that NB needs a smaller training dataset than other machine learning techniques (Rish, 2001)."}, {"title": "3.4.4 \u039a\u039d\u039d", "content": "KNN is a learning method that is based on instances. It implies it uses whole training instances to predict output for unknown data rather than learning weights from training data. The K Nearest data points are used to anticipate the new Datapoint's class or continuous value. Furthermore, since KNN is a non-parametric algorithm, the mapping function has no fixed shape (Coomans & Massart, 1982). Because there is no training period, the strategy is simple to comprehend and apply (Aslan et al., 2018)."}, {"title": "3.4.5 LR", "content": "LR is a supervised probabilistic machine learning technique that predicts a category target variable. LR aims to develop the most economical and best-fitting model to explain the connection between a collection of independent (predictor or explanatory) variables and an outcome (dependent or response variable). This method is reasonably robust, adaptable, and simple to apply and lends itself well to interpretation. LR, unlike LDA, does not make any assumptions about the distribution of the explanatory variables (Pohar et al., 2004; Tolles & Meurer, 2016)."}, {"title": "3.4.6 DT", "content": "A DT is a supervised machine learning technique that uses a directed graph to describe probable answers to a decision under specified parameters. The graph is made up of nodes that are divided into three groups: choice, chance, and terminal nodes. A chance node depicts the likelihood of particular outcomes. A decision node represents a choice that has to be taken, and a terminal node represents the decision path's conclusion (Kami\u0144ski et al., 2018). The DT algorithms provide great accuracy, stability, and readability prediction models. DTs have minimal variance because they make no assumptions about the target variable (Hamsagayathri & Sampath, 2017)."}, {"title": "3.4.7 LDA", "content": "The LDA focuses on the association between a categorical variable and a group of associated factors. It is a collection of multivariate statistical techniques for determining a linear combination of features that distinguishes or characterized two or more classes of objects or occurrences. The trained classifier of LDA finds the class with the most negligible misclassification cost to predict new data (McLachlan, 1992)."}, {"title": "3.4.8 RF", "content": "The RF is a set of tree predictors in which each tree is determined by the values of a random vector collected independently and uniformly across all trees in the forest. As the number of trees in a forest becomes larger, the generalization error converges to a point (Breiman, 1996; Ho, 1995). The downside of DT classifiers is that they are prone to overfitting the training set. The RF's ensemble architecture compensates for this and enables it to generalize effectively to new data. They are also adept at dealing with massive datasets with high dimensionality (Dietterich, 2000)."}, {"title": "3.4.9 AB", "content": "In machine learning, the AB is a boosting approach that is employed as an ensemble method. The weights are reassigned to each instance in this procedure, with greater weights applied to erroneously categorized occurrences. Merging weak learners repeatedly corrects the faults of the weak classifier and increases accuracy. It is also resistant to overfitting (Freund & Schapire, 1997; K\u00e9gl, 2013)."}, {"title": "3.5 Evaluation criteria", "content": "In this research, the following creditable criteria are exploited to evaluate and compare the efficiency of ML algorithms in diagnosing the benignity and malignancy of disease. True negative (TN) and true positive (TP) rates are suggested to evaluate the classifier's performance. The confusion matrix, shown in Table 3, calculates TP and TN. As shown in Table 3, TP represents the number of true positives or instances that were accurately classified as benign tumors. FN stands for false negatives, which are harmless tumor instances misclassified as malignant; TN is for true negatives, which are accurately labeled cases in the malignant tumor. The number of false positives (FP) is the number of malignant tumor cases that were misclassified as benign."}, {"title": "3.5.1 Accuracy", "content": "The measure of accuracy represents the percentage of correct separation of data into their corresponding classes. It is well-defined as the number of correctly classified data into their related classes over the total data in the set for classification models. It is formulated by:\n$Accuracy = \\frac{TP+TN}{TP+FN + FP + TN}$"}, {"title": "3.5.2 Sensitivity", "content": "The fraction of positive cases that are appropriately classified as positive is known as sensitivity. This measure is calculated by:\n$Sensitivity(TPR) = \\frac{TP}{TP+FN}$"}, {"title": "3.5.3 Specificity", "content": "On the contrary, diagnosing the negative class sometimes becomes essential to the sensitivity measure. Specificity refers to the model's ratio of negative cases correctly diagnosed as negative samples. This measure is calculated by:\n$Specificity = \\frac{TN}{TN+FP}$"}, {"title": "3.5.4 Precision", "content": "The precision measure denotes that the ratio of the data the classifier recognizes as positive is truly positive. This criterion is defined by:\n$Precision = \\frac{TP}{TP+FP}$"}, {"title": "3.5.5 F-Score", "content": "This measure is defined as the combination of sensitivity and precision criteria and is the harmonically average of these two criteria, defined as follows:\n$F-Score =2x\\frac{(Recall \\times precision)}{(Recall + precision)}$"}, {"title": "3.5.6 Kappa statistic", "content": "The Kappa statistic is a prominent measure for evaluating model compatibility. This statistic compares the suggested model's findings to the results provided by the stochastic classification approach. This criterion can be calculated using Eqs. (18)\u2013(20).\n$K = \\frac{[P(A) \u2013 P(E)]}{[1 - P(E)]}$\n$P(A) = (TP +TN)/N$\n$P(E) = [(TP + FN) \\times (TP + FP) \\times (TN + FN)]/N^2$"}, {"title": "3.5.7 \u039c\u0391\u0395", "content": "It is equal to the average of the discrepancies between the observed and projected values. This error is the average prediction error. The value for this index is defined by:\n$MAE = \\frac{1}{n} \\sum_{i=1}^{n} |X_{imeas} - X_{ipred}|$\nwhere n, $X_{ipred}$, and $X_{imeas}$ represent the number of measured variables, the amount of the predicted variable, and the amount of the measured variable, respectively."}, {"title": "3.5.8 RMSE", "content": "The RMSE is also a fit or objective function and is the root of the mean square error index. This index indicates the absolute error among the simulation and observation variables. The value of this index is stated by:\n$RMSE = \\frac{1}{n} \\times \\sqrt{\\sum_{i=1}^{n}[(x_{imeas} - X_{ipred})^2]}$"}, {"title": "3.5.9 RAE", "content": "The RAE is a method for evaluating the performance of a predictive model. As shown below, it is a ratio calculated by dividing the absolute error by the variable's actual value.\n$RAE = \\frac{[\\sum_{i=1}^{N}(X_{ipred} \u2013 X_{imeas})^2]^{1/2}}{[\\sum_{i=1}^{N}X_{imeas}^2]^{1/2}}$"}, {"title": "3.6 Proposed framework", "content": "This section describes the proposed framework illustrated in Fig. 3. The goal, according to it, is to improve the effectiveness of diagnostic models by combining the two novel WFS approaches based on the ICA and BA with ML algorithms for breast cancer prediction. The most significant features from the Wisconsin breast cancer dataset WDBC from the UCI machine-learning repository are obtained using the WFSIC and WFSB algorithms. Furthermore, we applied nine machine learning methods that have never been used before, making our research more comprehensive in assisting doctors. In reality, we use various machine learning methods since each algorithm has its strengths and limitations and acts differently depending on the dataset. As a result, testing with various methods ensures that the best model is chosen and that variations in choosing the best features are kept to a minimum (Johnson et al., 2022).\nPreprocessing, which includes filling in missing data, eliminating outliers, splitting data, and normalizing, is done in the first step of our architecture. The data is separated into two pieces in the dividing section: training and testing data. To normalize the distribution and boost the success rate, normalization must be used. For normalizing, the feature scaling approach is utilized (Hosseini & Al Khaled, 2014). This method's formula is as follows:\n$x' = \\frac{X - X_{min}}{X_{max} - X_{min}}$\nAfter that, in the second stage, for the WFSB or the WFSIC, they are individually integrated with ML algorithms along with the K-fold cross-validation (K-FCV) method and used to train them and reduce the dimensions of the clean dataset obtained from stage one. After training ML algorithms with the proposed WFS techniques and K-FCV, classification models are generated, and each ML algorithm creates the best feature set to assess its classifiers. For the WFSB, All the particles are randomly initialized using Eq. (5). After the initialization, each particle's acceleration, frequency, and position are calculated using Eqs. (6)\u2013(8), respectively. Finally, the velocity and position of each particle are updated using Eqs. (9)\u2013(12). This process is continued until the stopping criterion is satisfied (Qasim & Algamal, 2020). In our experiment, the end criterion is the maximum number of iterations.\nFor the WFSIC, all countries that are feature subsets are initialized randomly. After that, imperialists are selected based on the lowest cost of countries, and others are assigned to imperialists as colonies using Eq. (1). Then, assimilation and revolution operations are performed, and the cost of empires is calculated using Eq. (2) and compared with other colonies. If it is more than others, its position will be exchanged. Finally, the weakest colony from the weakest empire changes to one, which is more likely to process it using Eqs. (3) and (4) (Atashpaz-Gargari & Lucas, 2007; Lei et al., 2019).\nThen, in the third stage, the dataset with selected features acquired from the WFSIC or WFSB integrated with ML algorithms is applied to evaluate diagnostic models generated by training in the second stage. On the one hand, Modern ML algorithms often have hyper-parameters to adjust. That is why; we deploy hyper-parameter tuning manually by trial and error for some ML algorithms. Furthermore, changing the settings of certain hyper-parameters may have little impact on the model's performance. As a result, it is suggested that the essential hyper-parameters for each method be examined (Probst et al., 2019). In ANN, for example, the ideal value for the number of hidden layers is five (Johnson et al., 2022). Furthermore, for LR and NB, we do not test any hyper-parameters. The LR features a regularisation hyper-parameter that runs an embedded FS. The NB contains the smoothing parameter alpha that controls whether or not Laplace smoothing is used during the training process. Due to the use of WFS techniques and Laplace smoothing, there is no need to tweak hyper-parameters for LR and NB. Nevertheless, we apply the K-FCV method to tune hyper-parameter K for the KNN and obtain its best value at five (Tohka & van Gils, 2021).\nMeanwhile, Model validation is crucial in assessing ML models' effectiveness to avoid overfitting. Because of that, in this stage, nine ML algorithms are trained with the K-FCV method to validate diagnostic models' performance. Moreover, the K-FCV method minimizes the dependency of results on the randomly chosen training samples during the estimation of a predictor to ensure that results on unobserved samples are robust.\nK-FCV divides the training dataset into k-subsets of nearly similar size at random. The ML method is trained repeatedly using the k-1 folds and then tested on the final remaining fold, allowing each fold to be used as a test case once. The overall K-FCV (OCV) is calculated by averaging the k folds' key performance indicators ($F_i$) as follows:\n$OCV = \\frac{1}{k} \\sum_{i=1}^{k} F_i$\nWhen k is set too high, a small number of sample combinations are generated, limiting the number of alternative iterations. If K is too low, different training sets will appear throughout the folds, increasing bias. Because empirical investigations have demonstrated that models derived from four-FCV do not suffer large variation, k is chosen as four in this research. Furthermore, four-FCV allows for a compromise between computational cost and model variance (Azar & El-Said, 2014; Olson & Delen, 2007).\nThe dataset in this research is split into two parts: training and testing. The training set comprises 60% of the observations in the dataset, whereas the test set contains 40% of the observations.\nThe ML algorithms are trained using the training dataset and four-FCV. The test set is used to determine how well the tweaked ML models perform. The 60:40 split was chosen to guarantee enough training data for the machine learning algorithms to observe more instances and train using diverse patterns. The 60:40 split also ensures enough cases in the test set to determine how well the ML models generalize to new data (Johnson et al., 2022)."}, {"title": "4 Computational results", "content": ""}, {"title": "4.1 Comparative analysis", "content": ""}, {"title": "4.1.1 ML algorithms integrated with the WFSIC method", "content": "For the WFSIC method, the performance results are demonstrated in Table 6. Concerning Accuracy and Sensitivity, all models are improved. AB with a ratio of 98.95% and LR with a ratio of 98.58% have the best execution in terms of accuracy and sensitivity, respectively. From the specificity point of view, DT, ANN, AB, and RF classifiers are increased so that AB has higher proficiency with a ratio of 99.44%. In contrast, the best specificity performance is associated with the LDA model with a ratio of 99.71% when we do not exploit the WFSIC approach. However, this model is inappropriate since its sensitivity is low and does not balance Sensitivity and Specificity. A good prediction model should make a reasonable balance between Sensitivity and Specificity. When looking at these two measures, we notice that the three models of the ANN, AB, and RF have made a good balance between Sensitivity and Specificity such that the AB is the best of them, thanks to higher values. Concerning the Kappa statistic, with a ratio of 97%, the NB method has the highest compatibility against a random classifier model. According to the Precision and F-score, which is harmonically average of Sensitivity and Precision, the best implementation is related to the AB with a ratio of 99.1% and 98.6%, respectively. In terms of MAE, RMSE, and RAE, the AB has revealed better performance with the lowest values.\nAnother conclusion that can be taken from Table 7 would be that the efficiency of all models has been reinforced given the WFSIC approach in Accuracy, sensitivity, Kappa, MAE, and RMSE. Furthermore, the performance of five of nine models, including the ANN, AB, KNN, LDA, and NB, is dramatically improved.\nBy and large, the comparison of all evaluation criteria illustrates that the AB classifier is chosen as the best diagnostic model in combination with the WFSIC approach and is classified the dataset with 17 features. Nevertheless, suppose the performance of models based on the number of features is considered. In that case, the NB classification model has the lowest number of features among all models by using only eight features. The number of the best features resulting from each method is shown in Table 6. Note that the best results are shown in boldface.\nThe WFSIC technique identifies the best features for each ML model, as shown in Table 8. The findings show that various machine learning models create diverse feature sets. Nonetheless, several models have a lot in common among the feature sets found. Seven ML methods, for example, choose Area SE, Concavity SE, Texture Worst, and Compactness Worst, suggesting that these features may be necessary for breast cancer prediction. Six methods choose Concave points Mean, Fractal dimension Mean, Smoothness SE, Radius Worst, and Symmetry Worst. These features may also aid doctors in detecting breast cancer in its early stages. It also saves money since suppliers no longer have to develop additional features."}, {"title": "4.1.2 ML algorithms integrated with the WFSB method", "content": "The performance results in Table 9 indicate the combination between ML algorithms and the WFSB. From the Accuracy, Sensitivity, and specificity point of view, the RF classifier with 99.12, 98.58, and 99.44% ratios, respectively, outperformed all models, with only ten features. Furthermore, this model achieves better accomplishment thanks to the lowest values in the MAE, RMSE, and RAE criteria. According to Kappa statistics, with a ratio of 98%, it has the highest compatibility against a random classifier. The best execution was related to the RF classifier with 99.1% and 98.8% ratios concerning precision and F-score.\nAs mentioned earlier, due to balancing between Sensitivity and Specificity, five models of the SVM, NB, LR, RF, and ANN classifiers are desirable to diagnose more reliable, and the RF is superior in a balancing state since it has higher values in these two criteria. Another result we want to mention can be revealed in Table 7. However, the proficiency of all models is reinforced given the WFSB method. The two models of NB and AB have experienced remarkable improvement. Meanwhile, the highest performance enhancement by the WFSB compared to the method without FS is concerned with the NB model, which achieved this result using eight features.\nBy analyzing the obtained results, we conclude that the RF classifier acquires the best performance regarding all criteria combined with the WFSB approach by selecting ten features. In another finding, if the performance of models based on the number of features is considered, the DT classification model has the lowest number of features by using only three features with an accuracy rate of 95.78%. Nevertheless, it is not an appropriate model to predict breast cancer since its sensitivity is low and does not balance Sensitivity and Specificity.\nAs demonstrated in Table 10, the best features for each ML model are identified for the WFSB approach. Like the WFSIC, there are more critical features that have been selected by most ML models in the WFSB approach. For example, Texture_Worst is the feature that seven models have selected. Moreover, Six models have chosen Perimeter_SE and Radius_Worst. Also, Compactness_Mean, Concavity_Mean, Smoothness_Worst, Concavity_Worst, and Symmetry_Worst have been selected by five models, which means that these features are more critical than others."}, {"title": "4.2 Comparison between the performances of WFSIC and WFSB", "content": "Several issues can be stated when comparing the results obtained from the WFSIC and WFSB and investigating Tables 6, 7, 9, and 11. First, it should be noted that all classification models had performance advancements in these techniques. However, suppose each approach is evaluated and compared separately. In that case, five models have an extraordinary development in the WFSIC versus without it since they have significantly improved in the minimum of four criteria or their primary (i.e., accuracy, sensitivity). For example, the highest rate of improvement is related to the KNN, which has experienced a growth of about 16% in accuracy and sensitivity. In return, with the WFSB method, two of the nine existing models have experienced extra performance reinforcement, indicating that selecting feature is more effective with the WFSIC than the WFSB. Second, about the lowest number of features chosen, WFSB integrated with the DT algorithm with selecting three features acts superiorly compared to WFSIC combined with the NB with choosing eight features. Third, regarding overall efficiency, WFSB integrated with the RF classifier provided superior performance by recording better evaluation criteria and selecting fewer features than the WFSIC combined with the AB classifier.\nTable 12 compares the results of previous research in the literature with the approaches proposed in this study. The evaluation criteria and ML models utilized in each study are stated in this table. According to this table, there are several reasons why our research is more authentic and reliable than the others. One of the main reasons would be that most papers have utilized just a few very common criteria such as accuracy, sensitivity, and specificity that could not be comprehensive to make more precise decisions for physicians. We have used nine criteria and nine ML algorithms to make our work more reliable. Besides, the current research has outperformed all evaluation measures among all studies that have used FS methods cited in Table 12 and most previous papers.\nAnother rationale is that the highest balancing between Sensitivity and Specificity derives from our paper, while there are vast differences between these two measures among other studies. Hence, our classifiers are more reliable to employ in real clinical predictions. As we mentioned, this study exploits nine possible ML models for classification problems that have never been used before and utilizes more evaluation measures than most current studies. Therefore, this paper could potentially be considered one of the most validating and reliable works performed."}, {"title": "5 Discussion and implications", "content": "Despite many advances in the healthcare and health sciences, breast cancer remains the main cause of mortality among women (O'Brien et al., 2007). Moreover, this disease is curable at early stages, providing the correct and timely diagnosis. Knowing these, we propose a novel framework with a comprehensive analysis to enhance treatment outcomes for breast cancer prediction with an accuracy of over 99%, which is higher than most other medical techniques. In our framework, the WFS methods based on the ICA and the BA separately and their combination with ML algorithms are applied.\nAlthough accuracy and sensitivity might not be enough for reliable diagnosis to manage high-dimensional data sets, if specialists consider them as decision criteria, we can recommend the RF classifier integrated with WFSB. This model attains 99.12 and 98.58% accuracy and sensitivity, respectively. Besides, a valid diagnostic model balances Specificity and Sensitivity, which means the difference between them in a balanced model is low (Dziak et al., 2020). In this respect, we present the RF combined with the WFSB and the AB combined with the WFSIC that are the most balanced models of all studies indicated in Table 12 such as (Mojrian et al., 2020; Sakri et al., 2018; Salma & Doreswamy, 2020; Sangaiah & Vincent Antony Kumar, 2019), since the difference between the two criteria of sensitivity and specificity is approximately 1%.\nNevertheless, if Sensitivity and Specificity are nearly the same levels, medics can exert Kappa statistics to ensure their decisions. Concerning Kappa, we indicate that the RF classifier with a ratio of 98% has the highest compatibility versus a random model, which means it is less misleading than using accuracy as a metric and is superior to previous works (Hamsagayathri & Sampath, 2017; Oladele et al., 2021; Sakri et al., 2018).\nIn addition to the former criteria, for the precision and F-score, our paper recommends applying the RF model combined with the WFSB with the best performance regarding the precision of 99.1%, F-score of 98.8%, and other former criteria. Finally, we simultaneously propound error measures along with other measures for the most sustainable and trustworthy breast cancer prediction, including MAE, RMSE, and RAE with a ratio of 1, 9, and 6%, respectively, employing the RF model integrated with the WFSB approach that are the lowest values than the current studies (Hamsagayathri & Sampath, 2017; Mojrian et al., 2020; Sakri et al., 2018). The physicians could consider error measures with the other proposed criteria in this study at the same time to make more reliable decisions. When comparing our approaches, we should assert that the WFSIC boosted the efficiency of five ML models and outperformed the WFSB regarding the number of models that had notable progress. Another proposed approach (i.e., the WFSB) had the highest scores concerning nearly all evaluation measures with fewer selected features than the WFSIC, as illustrated in Tables 6 and 9. The best features chosen by individually integrating WFSIC and WFSB with ML algorithms had in common. These features include Area_SE, Concavity_SE, Texture_Worst, Compactness_Worst, Concave points_Mean, Fractal dimension_Mean, Smoothness_SE, Radius_Worst, Symmetry_Worst, Perimeter_SE, Compactness_Mean, Concavity_Mean, Smoothness_Worst, and Concavity_Worst.\nOn the whole, it can be decided from the observations and analysis of the obtained results that the WFSB is the best of our approaches, which outperforms the WFSIC and other ML models by selecting only 33% (i.e., ten features) of the dataset's features, which prompts clinical diagnosis cost and time to diminish. Furthermore, because each ML algorithm has merits and demerits, using different models with different traits makes our best model robust. Consequently, our paper could help physicians make more meticulous decisions with less patient wait time, medical cost, and higher authenticity than most previous works. To endorse our approaches, we achieved an accuracy of over 99% using nine ML algorithms and nine evaluation criteria.\nIn terms of the research's key implications for the current literature, this publication proposed a new paradigm for breast cancer prediction. Moreover, it is essential to note that the works illustrated in Table 12 have exerted the dataset used in this study and are considered benchmarks. It was observed that the best accuracy that is related to Mahendru and Agarwal (2019) yielded 97.3%, the best sensitivity obtained was 97.56% from (Mojrian et al., 2020), and the best specificity was 94.39% that is acquired by (Mojrian et al., 2020), the best precision resulted by (Mojrian et al., 2020) was 99.1%, the best yielded F-score was 98.3% from (Mojrian et al., 2020), the best Kappa obtained was 93.7% from (Oladele et al., 2021). The best RMSE acquired was 15% from (Mojrian et al., 2020). The performance metrics obtained from these investigations are lower than those obtained from the RF and AB models proposed in this study. Additionally, these papers consider fewer ML models than those assessed in our framework. Consequently, we believe our framework has produced better outcomes and accurately and thoroughly forecasts breast cancer based on a set of medical features.\nIn terms of practical consequences, this work has created data mining methods that specialists may use to forecast breast cancer more accurately and distinguish the best breast cancer traits and their numbers. To this end, oncology-focused healthcare practitioners may use the proposed framework to respond more quickly and make more reliable treatment choices, enhancing treatment results and saving costs. As a result, the suggested machine learning-based tools will aid in advancing healthcare analytics for breast cancer prediction."}, {"title": "6 Conclusions and future work", "content": "The implications of combining WFS approaches based on the ICA and BA with ML algorithms to improve treatment outcomes with better reliability for breast cancer prediction were investigated in this research. It was demonstrated that the performance of all introduced ML algorithms could be improved by using our proposed approaches (i.e., the WFSIC and WFSB). The WFSB outperformed the WFSIC regarding nearly all evaluation criteria in our framework. In all evaluation measures, the RF classifier integrated with the WFSB achieved higher scores than other ML models combined with the WFSB or WFSIC. Moreover, the RF model has had better performance than most previous studies. The AB classifier was the best diagnostic model combined with the WFSIC approach with 17 selected features. Besides, regarding the number of models with significant performance improvement, the WFSIC with five ML models accomplished better than the WFSB with two models. For instance, the KNN underwent an approximately 16% increase in accuracy and sensitivity. Furthermore, the results acquired by the proposed FS approaches reveal that the nine features, including the standard error of area, concavity, smoothness, perimeter, the worst of texture, compactness, radius, symmetry and the mean of concave points, fractal dimension, compactness, concavity rank among the superlative critical features and could considerably influence the efficiency of breast cancer prediction.\nThe RF and AB integrated with the WFSB and WFSIC, respectively, have been the most balanced models since the difference between the two criteria of sensitivity and specificity is approximately 1%. This illustrates that these two models are considered better diagnostic models for breast cancer prediction.\nWhile there are significant disparities between these two metrics in previous research, our article has the most considerable balance between sensitivity and specificity. Since the difference between the two criteria of sensitivity and specificity is approximately 1%, the RF combined with the WFSB and AB combined with the WFSIC are the most balanced models of all studies listed in Table 12, including (Mojrian et al., 2020; Sakri et al., 2018; Salma & Doreswamy, 2020; Sangaiah & Vincent Antony Kumar, 2019).\nFor the number of selected features, our best model chose only 10 (i.e., 33%) features, and the DT integrated with the WFSB selects only 3 (i.e., 10%) features for breast cancer prediction. In addition, the contributions of this study reflected the superiority of the proposed techniques compared to most previous studies in model performance. For example, the RF model combined with the WFSB achieved over 99% concerning the accuracy, specificity, and precision and attained over 98% regarding sensitivity, F-score, and Kappa. Hence, healthcare operators could exploit the WFSIC and WFSB to predict breast cancer in less time and costs at early stages with higher efficiency. Likewise, our research can be applied in natural clinical diagnostic systems and therapy to assist clinical physicians in making more reliable decisions thanks to using more ML models than other works, making our study more comprehensive.\nThis paper's limitation could be that our proposed framework was executed using only one breast cancer dataset. Among the constructive suggestions for further expanding this research, one can mention using other breast cancer datasets. Also, this study has far-reaching ramifications since it can be used to treat and investigate various forms of cancer, such as lung, colorectal, and prostate cancers. Another offer is that our framework can be used for other FS methods (e.g., relief ranking and information gain) and different metaheuristic algorithms to present more comparative analysis. Moreover, we try to work on the KNN and the NB, which have attained immense boosting by our approaches."}]}