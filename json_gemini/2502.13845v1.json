{"title": "Enhancing LLM-Based Recommendations Through Personalized Reasoning", "authors": ["Jiahao Liu", "Xueshuo Yan", "Dongsheng Li", "Guangping Zhang", "Hansu Gu", "Peng Zhang", "Tun Lu", "Li Shang", "Ning Gu"], "abstract": "Current recommendation systems powered by large language models (LLMs) often underutilize their reasoning capabilities due to a lack of explicit logical structuring. To address this limitation, we introduce CoT-Rec, a framework that integrates Chain-of-Thought (CoT) reasoning into LLM-driven recommendations by incorporating two crucial processes: user preference analysis and item perception evaluation. CoT-Rec operates in two key phases: (1) personalized data extraction, where user preferences and item perceptions are identified, and (2) personalized data application, where this information is leveraged to refine recommendations. Our experimental analysis demonstrates that CoT-Rec improves recommendation accuracy by making better use of LLMs' reasoning potential. The implementation is publicly available at https://anonymous.4open.science/r/CoT-Rec.", "sections": [{"title": "1 Introduction", "content": "Due to their powerful understanding, reasoning, and generation capabilities, large language models (LLMs) have demonstrated remarkable success across multiple fields [37, 45, 57, 64]. Consequently, LLM-powered recommendations have attracted increasing attention [4, 18, 24, 31, 63]. LLMs contribute to recommender systems (RSs) in two ways: (1) LLMs as RSs [21, 36, 39, 65], where LLMs directly performing recommendation tasks, including LLM-as-Retriever and LLM-as-Ranker; (2) LLM-enhanced RSs [29, 35, 69], where LLMs augment conventional recommendation models (CRMs). Chain-of-Thought (CoT) [53] enhances LLMs' capacity for solving complex tasks by breaking down solutions into intermediate steps. However, existing LLM-powered recommendation approaches often rely on LLMs to perform or enhance recommendation tasks directly based on users' interaction history, without explicitly modeling the reasoning process. As a result, they do not fully exploit the reasoning capabilities of LLMs.\nIn this paper, we identify two key CoT processes-user preference analysis and item perception analysis-when performing or enhancing recommendation tasks with LLMs. Furthermore, we propose a pipeline named CoT-Rec to incorporate user preference and item perception into LLM-powered recommendations. As shown"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 LLM-as-RSs", "content": ""}, {"title": "2.1.1 LLM-as-Retriever", "content": "LLM-as-Retriever leverages LLMs to recall a set of potentially relevant items from an entire item set based on a user's interaction history. To ensure that the retrieved items remain within item set, three key paradigms have been proposed: bi-step grounding, indexing, and modal alignment. Bi-Step Grounding [10, 28] retrieves items by measuring the similarity between the textual output of the LLM and the candidate set. A pioneering work in this area is BIGRec [1], which reformulates the recommendation task by first grounding the LLM's output from the language space to the recommendation space, and subsequently aligning it with the actual item space. Indexing [6, 22] discretizes items into semantically meaningful tokens and employs beam search for retrieval. A notable example is LC-Rec [70], which aligns language tokens with item index tokens through task-specific optimizations, effectively bridging the gap between language representations and item indexing. Modal Alignment [5, 23, 59, 68] transforms the semantic vectors encoded by the Collaborative Retrieval Model (CRM) to align them with the semantic space of the LLM, replacing the traditional next-token prediction head with a next-item prediction head. This approach seamlessly integrates collaborative filtering information into the LLM, leading to significant improvements in retrieval performance."}, {"title": "2.1.2 LLM-as-Ranker", "content": "The LLM-as-Ranker paradigm [3, 38] requires LLMs to either rank a set of candidates based on a user's interaction history (list-wise ranking) or predict the likelihood of user interaction with a specific item (point-wise ranking). Point-wise Ranking. TALLRec [2] represents a pioneering effort in this domain. Subsequent studies have introduced notable advancements, including integration with Click-Through Rate (CTR) models [26, 27], optimization of user preference modeling [71], and improvements in text-like encoding techniques [67]. List-wise"}, {"title": "2.2 LLM-enhanced RSS", "content": "LLM-enhanced recommender systems (RSs) leverage LLMs to enhance the capabilities of Collaborative Retrieval Models (CRM) during the training phase, while LLMs are not required during inference. Depending on the type of knowledge provided by the LLM, some studies utilize LLMs to construct or optimize graphs that encode structural knowledge for CRM [16, 33, 43, 51, 58, 66]. Others introduce interaction information into CRM by generating synthetic interactions [48, 54]. Additionally, certain works enhance CRM inputs by optimizing features [17, 32, 49] or generating textual content [9, 47, 56, 61]. Furthermore, some approaches improve CRM's ability to learn high-quality representations by leveraging embeddings [8, 11, 12, 34, 42, 52, 62]."}, {"title": "3 Preliminaries", "content": "In this section, we introduce the sequential recommendation task and two methods that we use as backbones.\nSequential Recommendation. Given a user u who has interacted chronologically with an item sequence [i1, i2, ..., in], the goal of sequential recommendation is to predict the next item in+1 that the user is likely to engage with.\nSASRec [19] consists of an input layer, an embedding layer, a sequence modeling layer, and a prediction layer. The input layer processes a sequence of item IDs, which are mapped to embeddings in the embedding layer. The sequence modeling layer employs a unidirectional Transformer to capture feature interactions and aggregate information across items. Finally, the prediction layer outputs a probability distribution over the next item.\nLlamaRec [60] follows an LLM-as-Ranker approach. It first fine-tunes the LLM, which, given a candidate set, is instructed to predict the index (e.g., A, B, C, D) of the item the user is most likely to engage with. Based on the distribution of the predicted indices, the candidate set is then ranked in a list-wise manner."}, {"title": "4 Methods", "content": "We have introduced the overall process of CoT-Rec through Figure 1. Here, we present its details."}, {"title": "4.1 Personalized Information Extraction", "content": "The personalized information extraction stage extracts user preferences and item perception based on a user's interaction sequence."}, {"title": "4.1.1 User Preference Maintenance Module", "content": "As shown in Figure 2, this module extracts user preferences by analyzing interaction sequences. Prior research suggests that even when temporal information is explicitly highlighted in the prompt, LLMs struggle to capture temporal relationships within interaction sequences accurately [14]. To improve LLMs' temporal sensitivity, we take inspiration from RNNs and process items in batches following chronological order. Each batch's processing result is summarized as short-term interest, which helps derive long-term preferences. Specifically, the short-term interest from the first batch directly serves as the initial long-term preference. Thereafter, each new short-term interest is integrated with the preceding long-term preference to update it. Additionally, adjacent batches partially overlap to maintain information continuity."}, {"title": "4.1.2 Item Perception Analysis Module", "content": "As shown in Figure 3, this module enables the LLM to capture a user's perception of a specific item through role-playing. The process consists of three steps. First, the LLM generates an objective description of the item. Next, based on the extracted long-term preference, the LLM simulates the user writing a review of the item. Finally, key terms are extracted from the review to summarize the user's subjective impression. By adopting a role-playing approach, the LLM generates differentiated perception information based on varying user preferences, thereby capturing the diversity in individual understandings of the same item. Notably, both objective descriptions and subjective perceptions can be utilized."}, {"title": "4.1.3 Scalability", "content": "All operations in the personalized information extraction stage are performed offline, ensuring no impact on inference efficiency during the service phase."}, {"title": "4.2 Personalized Information Utilization", "content": "Figure 4 shows the model architecture of the personalized information utilization stage in CoT-Rec."}, {"title": "4.2.1 Architecture", "content": "The retrieval stage demands very high throughput. However, LLMs' inference speed is several orders of magnitude lower than that of CRMs. As a result, employing LLMs as retrieval"}, {"title": "4.2.2 CRM-as-Retriever", "content": "We define the Encode & Map operation as T : string \u2192 RdLM \u2192 Rdcrm. Specifically, a language model (LM) first encodes the text into an embedding of dimension d\u2081M, which is then mapped into the CRM embedding space of dimension dCRM via a dimensionality reduction technique.\nPrevious research suggests that initializing the embedding layer of SASRec with item captions processed through the Encode & Map operation can improve recommendation accuracy. However, this approach has two main limitations: (1) item captions provide limited information; and (2) SASRec relies exclusively on item sequences, omitting user information.\nTo address these limitations, we enhance SASRec by prepending the user ID to the item interaction sequence, explicitly linking it to a specific user. We further apply the Encode & Map operation to user preferences, using the resulting embeddings to initialize user representations. Similarly, we process both item captions and descriptions through the Encode & Map operation to initialize item embeddings. This approach ensures that CRM inputs incorporate user preferences and item descriptions-two essential intermediate results in the CoT process."}, {"title": "4.2.3 LLM-as-Ranker", "content": "Building on LlamaRec, we integrate user preferences and users' perceptions of candidate items, obtained during the personalized information extraction phase, into the prompt. Additionally, we construct an instruction-tuning dataset incorporating personalized information and leverage LoRA [15] to fine-tune the LLM for ranking tasks."}, {"title": "4.2.4 Scalability", "content": "In the retrieval stage, the improved CRM differs from the original only by incorporating an additional user embedding as input. Consequently, the optimization in CRM-as-Retriever has minimal impact on inference efficiency. Furthermore, LLM-as-Ranker is deployed on the user side, ensuring that its inference process imposes no additional computational burden on the server."}, {"title": "5 Experiments", "content": "In this section, we empirically evaluate whether CoT-Rec improves the performance of CRM-as-Retriever and LLM-as-Ranker. We do not compare it with other LLM-powered recommendation methods, as our focus is on exploring how CoT-Rec can effectively integrate with existing methods to achieve greater performance gains, rather"}, {"title": "5.1 Settings", "content": ""}, {"title": "5.1.1 Datasets", "content": "We conducted experiments on three datasets from distinct domains: Amazon Review (Food) [13] (e-commerce), MIND [55] (news), and Yelp (reviews). For each dataset, we retained users and items with at least five interactions and ordered them chronologically."}, {"title": "5.1.2 Evaluation", "content": "For CRM-as-Retriever, the task is to retrieve the correct item from the entire set. We evaluate CRM-as-Retriever using the leave-one-out method, which is widely adopted for assessing sequential recommendation methods. The accuracy of the retrieval stage is measured using Hit@K and NDCG@K. For LLM-as-Ranker, the task is to rank the candidate set retrieved in the previous stage. We evaluate the accuracy and position bias of the ranking stage using NDCG@K and MAPB. Position bias refers to the effect where the LLM's output is influenced by the target item's position within the candidate set. We fix K = 10 and report the average over five independent runs.\nWe propose Mean Absolute Position Bias (MAPB) to quantify the position bias in LLMs. Assuming the candidate set size is M, the sample bias is defined as: Sample Biasi = 1/M \u2211M j=1 |ri,j \u2212\u0159\u2081|, where ri,j is the predicted rank of the target item when placed in position j, and \u0159\u2081 = 1/M\u2211M j=1 rij is the average predicted rank of the target item for sample i. Then, MAPB is defined as: MAPB = 1/n \u03a3n i=1 Sample Bias\u2081, where n is the number of the samples. MAPB measures the average absolute deviation of the target item's predicted rank from its mean rank across all possible positions and all samples. A lower MAPB indicates that the model is less sensitive to the target item's position, which suggests better robustness to position bias."}, {"title": "5.1.3 Backbones", "content": "We select SASRec [19] and BERT4Rec [44] as the CRM for the retrieval stage, and Qwen2.5-7B-Instruct as the LLM for the ranking stage. The hyperparameters can be found in the code repository. Due to space limitations, we only present the results of SASRec. The BERT4Rec results are available in the repository and lead to consistent conclusions."}, {"title": "5.2 Results", "content": ""}, {"title": "5.2.1 CRM-as-Retriever", "content": "Table 1 presents the performance of CRM-as-Retriever under different enhancement methods. When User"}, {"title": "5.2.2 LLM-as-Ranker", "content": "Table 2 presents the effectiveness of different candidate set ranking methods. Here, Retriever refers to the retrieval model used. \"CRM\" refers to the basic SASRec model (as in Table 1 with \"User Embedding=None\" and \"Item Embedding=Random\"), while \"CRM++\" denotes its improved version (as in Table 1 with \"User Embedding-Preference\" and \"Item Embedding-Description\"). The Ranker denotes the ranking method. \"None\" indicates that no LLM-based ranking is applied, and the CRM retrieval results are used directly. \"LLM\" performs ranking without user preference and item perception. \"LLM+\" incorporates user preferences and objective item descriptions, while \"LLM++\" further integrates user preferences and subjective item perception of the candidate set."}, {"title": "6 Conclusions", "content": "We propose CoT-Rec, which enhances LLM-powered recommendations via two key CoT processes: user preference analysis and item perception analysis. Experimental results effectively validate our approach. Inference efficiency analysis shows that CoT-Rec introduces negligible overhead, suggesting its potential for industrial applications. Expanding CoT-Rec to other backbones is a promising avenue for future research."}]}