{"title": "Devising a Set of Compact and Explainable Spoken Language Feature for Screening Alzheimer's Disease", "authors": ["Junan Li", "Yunxiang Li", "Yuren Wang", "Xixin Wu", "Helen Meng"], "abstract": "Alzheimer's disease (AD) has become one of the most significant health challenges in an aging society. The use of spoken language-based AD detection methods has gained prevalence due to their scalability due to their scalability. Based on the Cookie Theft picture description task, we devised an explainable and effective feature set that leverages the visual capabilities of a large language model (LLM) and the Term Frequency-Inverse Document Frequency (TF-IDF) model. Our experimental results show that the newly proposed features consistently outperform traditional linguistic features across two different classifiers with high dimension efficiency. Our new features can be well explained and interpreted step by step which enhance the interpretability of automatic AD screening.", "sections": [{"title": "1. Introduction", "content": "Alzheimer's disease (AD) detection presents a significant and growing challenge to healthcare and economic systems due to costly and complex diagnoses [1, 2, 3]. Current research underscores the importance of early intervention and the need for economically accessible, non-invasive and affordable alternatives for AD detection [4, 5, 6, 7]. Consequently, speech and language alternatives have emerged as early AD indicators, offering a promising, non-invasive diagnostic approach suitable for large-scale screening [8]. The Cookie Theft picture description task is one of the common cognitive assessment tasks that evaluates language and cognitive impairments through patients' descriptions of a complex scene.\nFor spoken language-based AD detection, two primary methods have recently been prevalent: linguistic feature extraction with classifier models and the use of pre-trained language models (PLMs) like BERT. Studies such as [9] focus solely on linguistic features, applying them across multiple languages. [10] combined linguistic features and classifiers for aphasia subtype classification, incorporating semantic coherence for robust results.\nAnother approach uses PLMs to capture semantic information and context. For instance, [11] utilized various acoustic and linguistic features, including BERT, to compare different PLMs. They found that BERT-based features significantly improved detection accuracy with both manual and ASR transcripts. Building on this, [12] advanced PLMs by incorporating prompt-based fine-tuning for AD detection, aligning training objectives with AD classification tasks for state-of-the-art results. An earlier study by [13] used PLMs like Whisper and BERT, integrating high-level acoustic and linguistic features along with task-related information to enhance accuracy. More recently, [14] investigated the impact of using ASR transcription on both linguistic feature-based methods and PLM-based methods.\nMore recently, Large Language Models (LLMs) such as GPT-4, which have shown remarkable capabilities in various tasks, are increasingly being explored for their potential in aiding AD detection. [15] explored the feasibility of using ChatGPT for primary screening of Mild Cognitive Impairment (MCI) based on text conversation analysis. Similarly, [16] assessed GPT-4's potential in dementia diagnosis, highlighting its strengths in zero-shot settings and interpretable explanations, but also its limitations, such as the inability to be fine-tuned and sensitivity to input quality. Moreover, prompt-based LLMs for AD detection face several challenges. Firstly, their outputs are not always controllable or traceable, as changes in the LLMs' versions may lead to shifts in their outputs. Secondly, substantial computational power is required due to the extremely large size of these models' parameters. Lastly, there are privacy concerns associated with uploading user data to the cloud.\nPrevious research has extensively utilized traditional linguistic features and language models. However, these studies did not explicitly consider task-specific features such as content coverage, which is critical for cognitive assessment. This work introduces a novel set of features, including those that leverage the Term Frequency-Inverse Document Frequency (TF-IDF) concept and features related to the Cookie Theft task. We utilize the advanced linguistic capabilities and visual processsing ability of LLMs to help the generation of our new features. The proposed new features are more interpretable for humans, thereby enhancing the explainability of AD detection. We compared our new features with 40 traditional linguistic features referenced in the literature [14]. The experimental results demonstrate that our new feature set, which is compact with only around 37.5% in dimensionality compared with the conventional feature set, consistently outperforms the traditional linguistic features. We achieved an competitive accuracy of 85.4% on the ADRESS test set using only a 15-dimensional feature set, highlighting the dimensional efficiency of our features.\nTo summarize, this work has three main contributions. First, we pioneered the breakdown of the Cookie Theft picture and leveraged the visual processing ability of LLMs to generate features. Our approach ensures that every step is clear and reasonable, leading to a traceable and explainable feature generation process. Secondly, we utilized tried and true technique from Information Retrieval (IR) to provide novel and grounded features from different perspectives. Lastly, we proposed a compact, effective, and explainable feature set that achieves competitive results compared to previous research."}, {"title": "2. Method", "content": "The dataset utilized in this study is derived from the ADRESS Challenge 2020 [17], which represents a curated subset of the Pitt Corpus within the DementiaBank database [18]. It comprises 156 speech samples and their corresponding transcripts from English-speaking participants engaged in the Cookie Theft picture description task. The participants are categorized into two groups: those without Alzheimer's disease (HC) and those with Alzheimer's disease (AD), with each group including 35 males and 43 females. The dataset is methodically divided into training and testing sets, featuring 108 participants in the training set and 48 participants in the testing set. Both sets are meticulously balanced for age, gender, and disease condition."}, {"title": "2.2. Feature Engineering", "content": "In our work, we propose 11 new features for this task. Table 1 summarizes these 11 features with their corresponding description. In this section, We will introduce the definition and extraction process for each feature in the following section."}, {"title": "2.2.1. Topic Related Features", "content": "A critical aspect of the Cookie Theft picture description task is to evaluate the comprehensiveness of a subject's description in terms of picture content and topics. As illustrated in Fig. 1(a), the picture is segmented into three distinct topics: the boy and girl taking cookies, the mother and the water sink, and the window with curtain. We then segment the picture into three sub-images based on the identified topics and send these cropped images to the multimodal LLM\u00b9, leveraging its visual processing capabilities to generate relevant keywords, as illustrated in Fig. 1. For each sub-picture, we conduct 50 iterations of keyword generation and aggregate the results to ensure comprehensive content coverage. We manually check each iteration's output to prevent any potential hallucination and each step of the generation is trackable. With these three sets of keywords, we calculate the keyword hit rate within each topic to quantify the degree of detail in the descriptions.\nAlthough the topic keyword method effectively evaluates how a subject describes local parts of the picture, it lacks information from the global picture, such as the connections between topics. To assess the description coverage of the entire picture, we can adopt metrics from the image captioning task (e.g., BLEU and METEOR scores). These metrics quantify the degree of match between the description and the 'golden standard,' making them suitable for our needs. To generate the 'golden standard,' we input the entire Cookie Theft picture into the multimodal LLM and leverage its visual analysis capability to produce detailed verbal descriptions of the picture. We performed 15 iterations of this generation, considering the 15 responses as the 'golden standards.' The averaged BLEU and METEOR scores over these 15 'golden standards' serve as the final score. Accordingly, we propose five new features: BLEU-1, BLEU-2, BLEU-3, and BLEU-4, calculated using different n-gram schemes, and the METEOR score."}, {"title": "2.2.2. TF-IDF Related Features", "content": "Borrowing the idea of TF-IDF from IR [19], we propose a new feature called TF-IDF Score for this task. Let's consider each subject's transcript as a document d and the training document set as D. Each document d has a corresponding label (HC or AD). We denote the HC document set as dHC, AD document set as dAD, where dHC, dAD \u2208 D."}, {"title": "Then we obtain the TF of the term t in document d by calculating the the number of times t appears in d divided by the total number of terms in d i.e.", "content": "TF(t, d) = \\frac{f_{t,d}}{\\sum_{t' \\in d} f_{t',d}}  \\qquad(1)"}, {"title": "where: ft,d is the occurrences of term t in document d.", "content": "\\sum_{t' \\in d}f_{t',d} is the total number of terms in d.\nThe inverse document frequency (IDF) is a measure of how much information the word provides, that is, if it is common or rare across all subjects. It is defined as:"}, {"title": "IDF(t) =", "content": "log(\\frac{|D|}{\\|{d \\in D : t \\in d}\\|})  \\qquad(2)"}, {"title": "where: D is the total number of documents in the training set D. \\|{d \u2208 D : t \u2208 d}\\| is the number of documents in which the term t appears (i.e., the document frequency of t).\nThen the TF-IDF weight for a term t in d is the product of its TF and IDF:", "content": "TF-IDF(t, d) = TF(t, d) \u00d7 IDF(t)  \\qquad(3)\nThen we construct the TF-IDF vector for each document d\u2208 D. Let T be the set of unique term from the document set. The i-th value of the vectors coresponds to the i-th term in T If the i-th term is in the document the value would be its TF-IDF, else 0, i.e."}, {"title": "vd =", "content": "{\\begin{cases}\nTF-IDF(t_i, d) & \\text{if } t_i \\in d \\\\\n0 & \\text{if } t_i \\notin d\n\\end{cases}}  \\qquad(4)"}, {"title": "i=1", "content": "where |T| is the total number of unique terms.\nThen the HC reference vector is calculated by averaging the TF-IDF vectors of all documents in the document set dHc:"}, {"title": "VHC =", "content": "\\frac{1}{|d_{Hc}|} \\sum_{d \\in d_{HC}} Vd  \\qquad(5)"}, {"title": "Similarly, by replacing dHc by dAD and performing same calculation with Equation (5), we obtain the the AD reference vector VAD", "content": "Lastly, two similarity features of d are calculated as follows:\nTF-IDF similarity HC(d) = CosSimilarity (vd, VHC)  \\qquad(6)\nTF-IDF similarity AD(d) = CosSimilarity (vd, VAD)  \\qquad(7)\nIn our analysis, we observed that certain key terms, such as 'window' (objects) and 'overflow' (actions), may be overlooked by some AD subjects for various reasons. To quantify this observation, we propose using the keyword hit rate as a feature. To select appropriate keywords, we choose the top 30 terms that have the highest values in VHC as keywords. The TF-IDF keyword hit rate is then determined by dividing the number of mentioned keywords by the total number of keywords (30).\nWe also add four linguistic features that are not included in the previous research into our feature set: averaged parse tree depth, filler pause number, filler pauses ratio and word error rate\u00b2."}, {"title": "3. Experiment", "content": "We constructed classifiers based on two widely recognized methods: Random Forest (RF) and XGBoost. To ensure optimal performance, we employed Bayesian Optimization [20] to determine the appropriate set of hyperparameters for each model. The hyperparameters identified through this process were kept fixed across all settings, ensuring consistency and robustness in our evaluation. In our work, we follow the standard train test split of ADRESS dataset.\nWe used three different feature sets in our experiment. The first set comprised 40 traditional linguistic features proposed by [14]. The second set included our 15 new features and the third set combined the linguistic features and the new features together."}, {"title": "3.2. Results", "content": "Table 3 presents the overall experimental results of this work. The bold numbers indicate the highest scores within the model and the red numbers represent the best score among all. It is evident that our new features consistently outperform traditional linguistic features. These results highlight the effectiveness of the new features. We achieve the best performance of 85.4% accuracy, this result is comparable to previous research which uses a fine-tuned BERT model and nearly ten times the number of feature dimensions. Furthermore, the new features are more intuitive for humans to understand and are closely related to the Cookie Theft picture description task, thereby enhancing the explainability of spoken language-based AD detection.\nWe found that combining the linguistic features with the new features may worsen performance compared to using only the new features which suggest the importance of applying feature selection to the linguistic features for filtering some noisy features."}, {"title": "4. Discussion", "content": null}, {"title": "4.1. Feature Importance and ANOVA F-values", "content": "To further substantiate the effectiveness of our features, we extracted the feature importance from the RF model. Fig. 2(a) presents the top 15 important features in the RF. Notably, four of our new features ranking in the top fifteen. Additionally, we plotted the top 15 features with the highest ANOVA F-values. Fig. 2(b) indicates that our new features are highly relevant to AD detection as four of them ranking in the top five.\nAmong our proposed features, we identified that topic 1 keyword hit rate and the TF-IDF similarity HC are particularly effective, consistently ranking in the top five for both the importance of the RF feature and the ANOVA F values. Furthermore, other topic keyword features also demonstrated high effectiveness."}, {"title": "4.2. Ablation Study", "content": "We also conducted an ablation study to dive deeper for the inverstigation. We incrementally added features based on their ANOVA F-values and assessed their impact on the accuracy of AD detection tasks. Fig. 3 illustrates the results of this study. A notable increase in accuracy is observed between feature numbers 1 and 8; however, accuracy declines and fluctuates as the number of features increases. The optimal result was achieved by incorporating four traditional linguistic features and four new features, however it does not outperform only using new features, hence the feature selection based on ANOVA F-values may not be suitable. Determining a more effective feature selection to better integrate traditional features with our new features will be a focal point for future research."}, {"title": "5. Conclusion", "content": "In conclusion, we have proposed a compact set of features that are both more explainable and more effective for AD detection. We introduced the concept of leveraging TF-IDF alongside advanced LLMs' viusal processing ability to generate useful features. Our experiments demonstrate that our new features outperform the traditional features and achieve a competitive performance with high dimensional efficiency and interpretability."}]}