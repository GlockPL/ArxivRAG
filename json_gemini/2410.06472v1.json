{"title": "Enabling Novel Mission Operations and Interactions with ROSA: The Robot Operating System Agent", "authors": ["Rob Royce", "Marcel Kaufmann", "Jonathan Becktor", "Sangwoo Moon", "Kalind Carpenter", "Kai Pak", "Amanda Towler", "Rohan Thakker*", "Shehryar Khattak*"], "abstract": "The advancement of robotic systems has revolutionized numerous industries, yet their operation often demands specialized technical knowledge, limiting accessibility for non-expert users. This paper introduces ROSA (Robot Operating System Agent), an AI-powered agent that bridges the gap between the Robot Operating System (ROS) and natural language interfaces. By leveraging state-of-the-art language models and integrating open-source frameworks, ROSA enables operators to interact with robots using natural language, translating commands into actions and interfacing with ROS through well-defined tools. ROSA's design is modular and extensible, offering seamless integration with both ROS1 and ROS2, along with safety mechanisms like parameter validation and constraint enforcement to ensure secure, reliable operations. While ROSA is originally designed for ROS, it can be extended to work with other robotics middle-wares to maximize compatibility across missions. ROSA enhances human-robot interaction by democratizing access to complex robotic systems, empowering users of all expertise levels with multi-modal capabilities such as speech integration and visual perception. Ethical considerations are thoroughly addressed, guided by foundational principles like Asimov's Three Laws of Robotics, ensuring that AI integration promotes safety, transparency, privacy, and accountability. By making robotic technology more user-friendly and accessible, ROSA not only improves operational efficiency but also sets a new standard for responsible AI use in robotics and potentially future mission operations. This paper introduces ROSA's architecture and showcases initial mock-up operations in JPL's Mars Yard, a laboratory, and a simulation using three different robots. The core ROSA library is available as open-source \u00b9.", "sections": [{"title": "1. INTRODUCTION", "content": "In recent years, the field of robotics has witnessed significant advancements, with robots playing crucial roles in industries such as manufacturing, healthcare, and space exploration. As robotic systems become more complex and capable, the need for intuitive and efficient human-robot interaction has grown exponentially [1]. However, traditional methods of controlling and programming robots often require specialized knowledge and technical expertise, creating barriers for operators and limiting the accessibility of robotic technologies. It is not uncommon for operators to require advanced degrees and meticulous training to effectively operate even modestly capable robotic systems [2].\nROSA, the \"Robot Operating System Agent,\u201d addresses these challenges by introducing a first of its kind AI Agent that enables human-robot interaction (HRI) in the form of natural language. ROSA leverages large language models (LLMs) and open-source software like the Robot Operating System (ROS) [3] and LangChain [4] to implement a Reasoning and Acting (ReAct) agent [5] capable of understanding and executing commands on its robotic host. By integrating with the ROS and ROS2 [6] ecosystems, ROSA provides easy access to a wide range of tools and functionalities that allow users to perform tasks such as system diagnostics, monitoring, and invoking existing navigation and manipulation tasks, without the need for extensive technical training. ROSA aims to make robotic systems more accessible and user-friendly, empowering a broader range of operators to interact with robots in a more intuitive manner.\nThe remainder of this paper is organized as follows: Section 2 situates ROSA within the context of related work and provides background information on ROS, LLMs, and ReAct agents. Section 3 details ROSA's agent architecture, explaining its action space, system prompts, tool invocation, and safety mechanisms. Section 4 provides details on the implementation of ROSA, covering tool design, parameterization, ROS functionalities, and model selection. Section 5 discusses how ROSA enhances human-robot interaction by bridging the knowledge gap and enabling multi-modal communication. In Section 6, we explore a subset of capabilities unlocked by ROSA on actual robotic systems. Ethical considerations are explored in Section 7, which incorporates foundational principles and proposes community guidelines for responsible AI and robotics. Finally, Section 8 concludes the paper, summarizing the contributions and outlining directions for future work."}, {"title": "Target Audience and Use Cases", "content": "ROSA is designed to benefit a wide range of users within the robotics community. Robotics researchers and developers can use it to streamline development and verification & validation (V&V). Field operators and technicians, tasked with operating robots in dynamic environments, can now perform routine operations without requiring specialized training and a deep understanding of ROS. Further, educators and students will find ROSA enhances their learning experience by allowing them to focus on fundamental robotics concepts, free from the complexities of command-line interfaces. Finally, hobbyists and makers, who may not possess extensive technical backgrounds, can engage with robotics in a more accessible manner, fostering greater experimentation and innovation.\nROSA offers substantial advantages in a variety of practical scenarios. In disaster response, it enables rapid deployment and control of robots through natural language commands, making it easier to manage operations in emergency situations. In space exploration, ROSA can assist astronauts in controlling robotic arms and assistive robots, where traditional interfaces may be impractical due to constraints of the working environment. In industrial automation, it can simplify the monitoring and control of robotic systems on manufacturing floors, empowering personnel without deep technical expertise to operate complex machinery. Finally, in education and training, ROSA can serve as a versatile platform for teaching robotics concepts, lowering barriers for academic institutions and learners alike."}, {"title": "2. BACKGROUND", "content": "The rapid evolution of robotics over the last decade has led to increasingly sophisticated systems with advanced capabilities in perception, manipulation, and autonomy. However, interfacing with these robotic systems remains a significant challenge, especially for users without extensive technical backgrounds. Frameworks like ROS have reduced development overhead by promoting modular and reusable robotic software components. Nevertheless, a steep learning curve persists in interacting with and controlling robots, particularly when using traditional command-line interfaces or programming languages.\nRecent advancements in AI-driven natural language processing, especially through LLMs, offer a promising avenue for bridging the gap between humans and AI agents at large [7]. By enabling natural language interfaces, these models make robotic systems more accessible and easier to use. This section discusses related work in robot development, AI-driven assistants, and natural language interaction frameworks, and provides an overview of the foundational technologies that power ROSA."}, {"title": "Related Work", "content": "There have been several notable efforts aimed at bridging the gap between natural language processing and robotic control. Projects like Microsoft's LATTE [8] and research efforts like Google's \u201cLanguage Models as Zero-Shot Planners\" [9] explore how LLMs can be utilized for robotic task planning and execution. These initiatives showcase the potential of LLMs to interpret human instructions and translate them into robotic actions. However, direct integration of LLMs with robotic systems remains a challenge, primarily due to the inherent ambiguity of natural language and the difficulties in ensuring the consistent and reliable execution of tasks.\nROSA distinguishes itself from these efforts by adopting a more pragmatic and targeted approach. Instead of using LLMs for direct robot control, ROSA functions as an operator interface that leverages existing robot functionality within the ROS ecosystem. ROSA capitalizes on the strengths of LLMs to translate natural language into high-level commands while managing the intricacies of ROS behind the scenes. This method allows ROSA to provide a more reliable and user-friendly interface, avoiding some of the challenges inherent in direct LLM-based robotic control, while still benefiting from LLM capabilities.\nIn related work, Koubaa et al. investigate human-robot interaction (HRI) by utilizing the capability of LLMs to convert natural language queries into formal commands, enabling written or spoken language to be translated into structured commands for robotic systems. While this method breaks down certain barriers in HRI, it also introduces new challenges. Specifically, it demands expertise in \"prompt engineering\" and \"ontology-guided task elicitation\" [1], which require a deep technical understanding of LLM functionality, ontology creation, and formal specification. ROSA, by contrast, aims to simplify this process by utilizing pre-built frameworks and established methodologies to map natural language to robotic behavior. This allows developers to focus more on enhancing robotic capabilities rather than mastering the complexities of LLM operation and ontology design. Another important distinction between ROSA and [1] is that ROSA constitutes an embodied agent, as detailed in the following sections, which provides additional flexibility in the way queries are transformed into robotic actions."}, {"title": "Preliminaries", "content": "Robot Operating System-ROS is an open-source framework designed for developing robot software [3]. It provides a collection of tools, libraries, and conventions that streamline the creation of complex robotic behaviors across various platforms. By standardizing robotic programming, ROS encourages code reuse and collaboration, making it a cornerstone of modern robotics.\nAt its core, ROS enables modularity and scalability through a peer-to-peer network of processes called nodes, which can be distributed across multiple computers. These nodes communicate via a publisher/subscriber model using topics, or request/response interactions through services, fostering flexibility in system design. shows a basic ROS setup, but real-world systems are often much more complex, involving dozens or even hundreds nodes, topics, and services.\nThanks to its active community, ROS has become a standard for robotics research and development. Key features include a hardware abstraction layer, device drivers for common sensors and actuators, and communication tools for seamless data exchange between nodes. ROS also offers package management for easy software distribution and reuse, along with multi-language support, particularly for Python and C++.\nROS also includes core tools for managing and interacting with robotic systems, such as rosnode for monitoring nodes, rostopic for interacting with the message-passing system, rosparam for dynamic reconfiguration, and rosservice for triggering actions. However, these tools often require"}, {"title": "3. AGENT ARCHITECTURE", "content": "ROSA's architecture seamlessly integrates advanced language models with the ROS ecosystem, enabling natural language interactions that effectively control and query robotic systems. This section examines the key components of ROSA's architecture, explaining how each part contributes to its overall functionality. illustrates the high-level architecture of ROSA, showing the general flow of information between various modules during execution."}, {"title": "Action Space", "content": "The action space in ROSA is defined as the set of tools2 the agent can call within its working environment. It encompasses a subset of the standard ROS tools, as well as several utility commands and functions that ROSA can invoke in response to user queries. By defining a comprehensive action space, ROSA ensures that it can handle a wide range of tasks, from simple information retrieval to invoking complex control functions.\nROSA's action space includes integration with standard ROS tools such as rosnode, rostopic, rosservice, and rosparam. This integration allows the agent to perform actions like listing active nodes, inspecting topics, and managing parameters. Developers can extend ROSA's capabilities by adding custom functions tailored to specific robots or applications, thereby expanding the action space to include robot-specific commands and behaviors. Importantly, the"}, {"title": "Robot System Prompts", "content": "Robot System Prompts (RSP's) are a set of prompts that help guide ROSA's behavior. They are critical for ROSA's ability to maintain contextual awareness and provide coherent and relevant interactions. These prompts supply the language model with essential insights about the robot's identity, environment, and operating conditions, ensuring that ROSA's responses are well-aligned with the robot's specific capabilities and constraints.\nBy utilizing RSP's, ROSA gains a deeper understanding of the robot's unique characteristics, such as how it presents itself to users and interacts with human operators. The prompts also establish clear operational boundaries, including safety protocols and limitations that ROSA must respect when issuing commands or making decisions. Furthermore, by providing detailed descriptions of the physical and digital environments the robot inhabits, ROSA can better anticipate and react to environmental changes in real-time. For instance, knowing that the physical robot is intended for use in a subterranean environment can better inform the invocation and inference of a tool used for scene understanding."}, {"title": "Tool Invocation and Multi-Tool Usage", "content": "Tool calling is a core mechanism by which ROSA executes actions within the ROS environment. When ROSA interprets a user's natural language request, it identifies the appropriate tool(s) to invoke to fulfill the request. provides a flowchart of the tool calling process within ROSA, illustrating how natural language inputs are transformed into actions within the ROS environment.\nThe process involves several key steps. First, ROSA forwards the query to the LLM, along with a list of all available tools, RSP's, and chat history. Next, the LLM interprets the intent of the query and maps it to one or more tools within ROSA's action space, selecting the most relevant tools based on their name, parameters, and description. The LLM also determines the necessary parameters for the tool based on the user's request, filling in any missing information using default values or by asking follow-up questions. After parameter mapping, the selected tool is invoked, and the action is performed within the ROS environment. Finally, ROSA forwards the response of the tool back to the LLM to observe the outcome of the action and generate feedback to inform the user of the result."}, {"title": "Safety and Constraint Handling", "content": "Safety is a paramount consideration in ROSA's design. The agent incorporates multiple layers of safety checks and constraint handling mechanisms to prevent unintended or unsafe actions. Before invoking commands, ROSA validates parameters to ensure they are within acceptable ranges, maintaining awareness of the robot's current state-such as battery levels, system health, and environmental conditions.\nCertain actions, services, parameters, or topic names can be blacklisted to prevent ROSA from accessing sensitive functions or making prohibited changes. For critical actions, ROSA may request confirmation from the operator before proceeding. If an error occurs during tool invocation, ROSA handles it gracefully, providing informative feedback and adjusting its actions as needed.\nThe structured outputs from the tools enhance ROSA's ability to enforce safety constraints and handle edge cases. By including error messages, validation results, and metadata within the returned data, ROSA can detect potential issues and respond appropriately, ensuring robust interactions even when unexpected situations arise."}, {"title": "Custom Agents", "content": "Benefits of Custom Agents-Creating custom agents offers several significant benefits. Firstly, it allows for specialization by tailoring the agent to specific robots or applications, which enhances effectiveness by ensuring that the agent's capabilities align closely with the operational needs. Secondly, custom prompts and tools can enforce safety protocols relevant to the specific robot, leading to improved safety during operations. This customization ensures that the agent adheres to all necessary guidelines and constraints unique to the robot's environment.\nFurthermore, adapting the agent's persona and interaction style to suit operator preferences leads to an enhanced user experience. This personalization can make interactions more intuitive and efficient, thereby increasing operator satisfaction and productivity. Lastly, custom agents provide extensibility, allowing developers to add new functionalities as the robot's capabilities expand. This flexibility ensures that the agent can evolve alongside the robot, accommodating updates and advancements without requiring a complete overhaul of the system. By providing a framework for creating custom agents, ROSA empowers developers to build intelligent, context-aware interfaces for a wide range of robotic systems."}, {"title": "4. IMPLEMENTATION", "content": "ROSA is implemented in Python and leverages the Robot Operating System (ROS) to interact with robotic systems. The architecture is modular and extensible, designed to work seamlessly with both ROS1 and ROS2. This section provides a technical deep dive into ROSA's implementation, focusing on the structure of the tools, parameterization, coverage of ROS functionalities, and model selection considerations. The ROSA code base is available at https://github.com/nasa-jpl/rosa for reference."}, {"title": "Tool Structure and Organization", "content": "At the core of ROSA are the tools-Python functions that encapsulate various functionalities useful for robotics development and operation, including a large subset of the standard ROS tools. These tools are designed to be modular, reusable, and easily integrated with LangChain, enabling the language model to interact effectively with the ROS environment.\nTools are organized into modules based on their functionality and ROS version compatibility. Specifically, there are separate modules for ROS1 and ROS2 tools, named ros1.py and ros2.py, respectively. This separation allows ROSA to support both versions of ROS without conflict, and facilitates maintenance and extension of the tool set. Additionally, common tools are provided in modules like calculation.py and log.py, offering utility functions applicable across both ROS versions.\nEach tool function is decorated with the @tool decorator from the LangChain library. This decorator registers the function as an action that the language model agent can invoke. By standardizing the way tools are defined and registered, ROSA ensures consistent behavior and seamless"}, {"title": "Parameterization and Input Handling", "content": "To allow flexible and efficient interaction with the ROS environment, ROSA's tools are designed to accept well-defined parameters, often with default values and optional arguments. This approach enables the language model to perform complex queries and operations by selectively specifying the necessary parameters. Many tools accept a pattern parameter, allowing users to specify regular expressions to filter results. This is particularly useful when dealing with a large number of nodes or topics, as it enables targeted queries. The namespace parameter enables tools to operate within specific ROS namespaces, providing granular control over the scope of operations.\nAdditionally, a blacklist parameter can be used to exclude certain nodes, topics, or services from the output, enhancing safety and customization by preventing unintended interactions with critical system components. To streamline the inclusion of default blacklists and ensure consistent safety measures across tools, ROSA implements an inject_blacklist decorator. This decorator automatically injects any user-provided blacklist into tools that have a blacklist parameter, reducing the potential for human error and simplifying tool definitions. By centralizing safety mechanisms like a blacklist, ROSA maintains a high standard of operational safety without burdening individual tool implementations. This design decision enhances both usability and security."}, {"title": "Coverage of ROS Functionalities", "content": "ROSA provides comprehensive coverage of typical ROS functionalities through its extensive set of tools, enabling interaction with various system components. For nodes, ROSA includes tools to list active nodes, retrieve node information, and terminate nodes when necessary. For topics, tools are available to list topics, echo messages, and retrieve detailed topic information. Services can be managed through"}, {"title": "Integration with LangChain and the ReAct Framework", "content": "ROSA integrates with the LangChain library to implement the ReAct (Reasoning and Acting) framework, allowing the language model agent to process natural language inputs, reason about appropriate actions, and invoke the corresponding tools. LangChain handles prompt management by facilitating prompt chaining, which is used to guide the language model's understanding of ROSA's capabilities, constraints, and the context of the interaction. It also manages conversational memory, enabling ROSA to maintain state across interactions and provide coherent, context-aware responses.\nThe ReAct framework facilitates the logic of selecting and executing tools based on the language model's reasoning. When the model determines that an action is required to answer a query or fulfill a command, it can invoke the appropriate tool, pass the necessary parameters, and process the returned structured data. This integration streamlines the interaction between the language model and the ROS environment, allowing for seamless execution of commands and retrieval of information. It also abstracts the complexity of tool invocation, making it easier to extend ROSA's capabilities.\nSystem prompts [11] play a crucial role in this integration by providing the language model with instructions and context. These prompts define the agent's persona, capabilities, limitations, and critical instructions, ensuring that the language model operates within the intended parameters. An"}, {"title": "Model Selection and Trade-offs", "content": "The choice of the language model significantly impacts ROSA's performance, capabilities, and resource requirements. ROSA currently supports chat models like GPT-40, Claude 3.5 Sonnet, and Llama 3.2. The selection between API-based and local inference models depends on the specific needs and constraints of the deployment environment. There are two requirements a model must satisfy in order to be used with ROSA:\n1. It must support tool calling [12].\n2. It must have a context length of no less than 8192 tokens\nFor API inference, models like GPT-40 are recommended due to their advanced reasoning capabilities and lower cost per token. These models offer superior performance in understanding complex queries and generating accurate responses. However, they require internet connectivity and may raise concerns regarding data privacy and dependency on external services. For local inference, models like Llama 3.1 8B provide a balance between performance and resource requirements. Running models locally enhances privacy and reduces reliance on external services, which is beneficial in secure or resource-constrained environments. However, local models may require optimization to achieve real-time performance and may have limitations in handling long context windows or complex reasoning tasks.\nWhen selecting a model, trade-offs between context length, performance, resources, and deployment considerations must be evaluated. Larger models typically offer better performance but require more computational resources. Models with longer context windows can handle extended conversations but may consume more memory and processing power. Deployment considerations, such as the need for offline operation or data privacy requirements, may influence the choice of a local model over an API-based one."}, {"title": "Implementation Decisions and Design Choices", "content": "Several key design decisions were made during the implementation of ROSA to enhance usability, safety, and effectiveness. The modular architecture, separating tool packages into ROS1, ROS2, calculation, logging, and other modules, simplifies maintenance and allows for clear separation of version-specific functionalities. This organization facilitates easier updates and scalability as ROS evolves.\nROSA provides standardized methods for defining tools and ensuring consistent application of safety measures. By automating aspects like parameter injection and tool registration, the ROSA libraries reduces the potential for errors and streamline the development process by design. Parameterization of tools with options like patterns, name spaces, and blacklists provides flexibility while maintaining control over operations. Allowing the language model to specify these parameters enables ROSA to perform precise actions as instructed by the user, enhancing the agent's usefulness in varied scenarios. Returning structured data enhances the language model's ability to generate accurate responses and reduces the risk of confabulation. This design choice is critical in ensuring that operators receive reliable information, thereby increasing trust in the system. The integration with LangChain and the ReAct framework abstracts the complexity of tool invocation and reasoning processes, allow"}, {"title": "5. HUMAN-ROBOT INTERACTION", "content": "Effective human-robot interaction is crucial for maximizing the utility and accessibility of robotic systems. ROSA is designed to enhance this interaction by providing a natural language interface, simplifying the way operators communicate with robots."}, {"title": "Bridging the Knowledge Gap with AI Assistance", "content": "Robotic systems, particularly those utilizing ROS, are inherently complex and are often developed by interdisciplinary teams where each member specializes in a specific domain [13]. This specialization leads to a fragmentation of"}, {"title": "Multimodal Interaction Capabilities", "content": "ROSA's default mode of operating is via text interactions. This can be in the form of a command-line interface (CLI) using Python's Read-Evaluate-Print-Loop (REPL), or via a custom Graphical User Interface (GUI) such as a simple web page made with HTML and JavaScript, or potentially more advanced GUI's like a Single-Page Application (SPA), or dedicated supervisory interfaces for multi-robot systems [14]. While ROSA uses text-based interaction by default, its design allows for the integration of additional input and output modalities to enhance human-robot interaction.\nSpeech Integration-Speech communication, being a natural and intuitive way for humans to interact, can be integrated into ROSA through speech-to-text (STT) and text-to-speech (TTS) libraries available in Python. This enables operators to converse with the robot verbally, issuing commands and receiving responses audibly. Implementing speech integration involves capturing audio input from the operator, processing it with an STT module, and passing the transcribed text to ROSA. The response from ROSA is then converted back to speech using a TTS module. This extension facilitates hands-free operation, which is ideal in situations where the operator's hands are occupied or when interacting with wearable devices, and enhances accessibility for operators with visual or motor impairments.\nBeyond speech, ROSA's architecture allows for integration with additional modalities to further enhance interaction. For instance, gesture recognition can be incorporated by using vision-based systems to interpret operator gestures as commands. Augmented Reality (AR) interfaces can overlay information and controls onto the operator's field of view, while Virtual Reality (VR) can create immersive environments for remote operation or simulation of robotic systems. Additionally, haptic feedback can provide tactile responses to operator inputs, enhancing control precision. These modalities can be integrated using appropriate sensors and software libraries, expanding the ways operators can interact with robotic systems.\nVisual Perception and Image Recognition-ROSA extends its interaction capabilities through visual perception by pro-"}, {"title": "Enhancing Communication and Collaboration", "content": "ROSA transforms human-robot interaction by allowing operators to communicate with robots using natural language, similar to how they would interact with another human. This approach offers several advantages:\n\u2022 Reduced Learning Curve: Operators do not need to learn specialized programming languages or command-line interfaces.\n\u2022 Increased Efficiency: Natural language commands can expedite task execution by eliminating complex syntax.\n\u2022 Improved Collaboration: Facilitates better teamwork between operators and robots, especially in dynamic environments.\n\u2022 Accessibility to Non-Experts: Allows individuals without technical backgrounds to operate and interact with robots effectively."}, {"title": "Supporting Diverse Operator Expertise Levels", "content": "By aggregating and interpreting comprehensive system knowledge, ROSA supports operators with varying levels of expertise. Novice operators can perform tasks and troubleshoot issues without extensive training or support from SMEs, making robotics more approachable. Experienced operators benefit from quick access to detailed technical information, aiding in complex decision-making and allowing them to focus on advanced operational aspects. Additionally, ROSA serves as an educational resource, helping new operators learn about the system through interactive queries and responses, effectively functioning as a training tool."}, {"title": "Future Opportunities in Human-Robot Interaction", "content": "ROSA's flexible architecture opens avenues for future enhancements in human-robot interaction:\n\u2022 Contextual Understanding: Improving the agent's ability to understand context and disambiguate commands based on situational awareness.\n\u2022 Emotional Intelligence: Incorporating affective computing to recognize and respond appropriately to human emotions and stress levels.\n\u2022 Personalization: Adapting interaction styles to individual operator preferences and communication patterns.\n\u2022 Learning and Adaptation: Enabling ROSA to learn from interactions to improve its responses and recommendations over time.\n\u2022 Multilingual Support: Extending natural language capabilities to support multiple languages, enhancing global accessibility.\nThese advancements have the potential to make human-robot interaction even more seamless and intuitive, broadening the applicability of robotic systems across various industries and use cases. ROSA significantly enhances human-robot interaction by simplifying communication and making complex robotic systems more accessible. By bridging the knowledge gap through AI assistance and supporting multiple interaction modalities, including visual perception and image recognition, ROSA empowers operators to interact with robots naturally and effectively. This advancement not only improves operational efficiency but also democratizes the use of robotic technology, enabling a wider range of users to leverage the capabilities of advanced robotic systems."}, {"title": "6. DEMONSTRATIONS", "content": "To demonstrate ROSA's capabilities, we developed custom agents for three unique robotic systems, each with their own operational nuances and idiosyncrasies. Our demonstrations focus on the usability of ROSA and serve to emphasize the range of capabilities that can be unlocked by integrating it with various robots. We show that ROSA is a versatile framework for enabling effective operations of robotic systems, irrespective of operator background and underlying knowledge of the platforms upon which they operate. For each of the robots, we categorize the tools into either \"uplink\" or \"downlink,\" where uplink tools elicit some form of physical control over the robot, and downlink tools use telemetry and other data systems to assess the robots health, generate reports, aggregate information, and so on. The sections below elucidate a prototypical workflow using ROSA as the primary interface for operations. While ROSA is completely interoperable with standard operating interfaces, our demonstrations omit the latter for brevity. Please note that all of the interactions below are actual interactions between human operators and ROSA. All of the actions performed by ROSA were successfully executed to completion and without incident."}, {"title": "Demonstration #1: NeBula-Spot", "content": "NeBula-Spot is a quadruped that was originally developed at JPL in response to the DARPA Subterranean Challenge [15]. It utilizes a Boston Dynamics Spot robot as its base platform and enhances it with a full suite of sensors and onboard devices that comprise JPL's NeBula autonomy stack."}, {"title": "Uplink tools", "content": "\u2022 State Change: the ability to sit down, stand up, and enter stairs mode.\n\u2022 Movement: the ability to move a specified distance upon a given set of axes or goal pose.\n\u2022 Turn in place: the ability to turn (yaw) either left or right by a specified angle."}, {"title": "Downlink tools", "content": "\u2022 Diagnostics: retrieves an array of diagnostics and telemetry messages from various subsystems.\n\u2022 System reports: creates a comprehensive system report using raw data retrieved from diagnostics channels, logs, health monitors, etc.\n\u2022 Scene Interpretation: retrieve the latest image from the front camera and interpret the scene, including item and"}, {"title": "Demonstration #2: EELS", "content": "EELS (Exobiology Extant Life Surveyor) is a serpentine robot and mobile instrument platform conceived to explore both surface and subsurface structures, assess habitability of"}, {"title": "Uplink tools", "content": "\u2022 Gaits: the ability to change into different gaits, including shape-based gaits, side-winding, leader-follower, and screw-velocity allocator.\n\u2022 Waypoint Navigation: the ability to issue a waypoint goal and have EELS autonomously navigate to it while simultaneously avoiding obstacles.\n\u2022 Raise/Lower Head : the ability to set specific bend and twist joints such that the head of the robot articulates upward or downward."}, {"title": "Downlink tools", "content": "\u2022 Scene Understanding: retrieve the latest image from one of four available cameras and describe the scene.\n\u2022 Real-time feeds: opens various real-time feeds including live video feeds coming from the on-board cameras. These feeds are opened in standard ROS tools like rviz and rqt_image_viewer.\n\u2022 Telemetry: retrieve state information and other telemetry data, such as the state of the robots joints and actuators."}, {"title": "Demonstration #3: NVIDIA Nova Carter", "content": "NVIDIA Nova Carter is a reference robot to develop and test autonomous mobile robot (AMR) applications [18]. Unlike the other robots we tested with ROSA, the Nova Carter was operated entirely in simulation using NVIDIA IsaacSim. We used a Martian terrain generated to replicate real conditions on the surface of Mars (Figure 19). Integrating ROSA in a virtual environment allowed us to test the extent of the agent's capabilities without being restricted by constraints posed by physical hardware and environments."}, {"title": "Uplink tools", "content": "\u2022 Movement: the ability to move forward or backward a certain distance, or for a certain amount of time, at the specified rate.\n\u2022 Turning: the ability to turn left or right by some specified angle.\n\u2022 Camera Rotation: the ability to rotate the on-board camera sensor by \u00b1180\u00b0."}, {"title": "Downlink tools", "content": "\u2022 LiDAR Scan: initiate a LiDAR scan at some specified frequency and retrieve the resulting point-cloud data, which is also published to a pre-determined topic.\n\u2022 Image Capture: capture the most recent frame from the live camera feed and store the images in a folder on the host operating system.\n\u2022 Collision Check: use the point-cloud from a LiDAR scan to check for potential collisions within a specified field-of-view."}, {"title": "7. ETHICS FOR EMBODIED AGENTS", "content": "The development and deployment of Embodied Agents\u00b3 like ROSA presents significant ethical considerations that must be addressed to ensure safe, responsible, and beneficial deployment. As robots become more autonomous and capable of complex interactions, it is imperative to establish guidelines and frameworks that promote ethical behavior, safeguard human welfare, and build public trust."}, {"title": "Incorporating Foundational Ethical Principles", "content": "Isaac Asimov's Three Laws of Robotics [19] have long served as a foundational reference for ethical behavior in robotics:\n1. First Law: A robot may not injure a human being or, through inaction, allow a human being to come to harm.\n2. Second Law: A robot must obey orders given it by human beings except where such orders would conflict with the First Law."}, {"title": "Accountability and Transparency", "content": "Building trust with users requires accountability and transparency in decision-making processes and actions taken by the agent. By providing access to its reasoning traces (see Section 2), ROSA's actions and decision making become transparent to human operators, and allows them to understand the reasoning behind the actions it takes. This form of Explainable Al helps validate correctness and foster trust in the underlying mechanisms that constitute ROSA and its integration with robotic systems. Further, maintaining detailed logs of actions and interactions allows for greater traceability over the agents decisions. In the event of an incident, these records can be reviewed to understand the sequence of events and/or policy failures that led to the adverse outcome. Responsible parties can audit these records to determine the correct course of action and provide remedy and resolution. However, even with these facilities in place, ultimate accountability will fall upon the organizations and individuals who design and develop the robotic systems and the agents which these robotic systems embody. Therefore, these authors highly recommend a course of development and operations that follow the principles outlined in this section."}, {"title": "Safety and Risk Mitigation", "content": "Ensuring the safety of humans and the environments in which embodied agents operate must be of paramount importance. In keeping with Asimov's Laws, embodied agents like ROSA shall also seek to reduce the risk of damage to the hardware they embody. Toward those ends, we propose the following essential safety mechanisms:\n\u2022 Facilities for Human Intervention: For uplink commands, those that elicit some form of physical control over the robot, embodied agents shall allow for manual human intervention and provide facilities to override any and all commands, whether they be active or planned, at any given time, regardless of the agents intended behavior, desired end state, or original operative commands.\n\u2022 Redundancy and Failover Mechanisms: Embodied agents shall be designed with redundancy in critical systems and include failover mechanisms to handle and recover from incidents gracefully. In cases of uncertainty or ambiguity, the agent shall default to a safe state and seek clarification from its human operators.\n\u2022 Parameter Validation and Constraint Enforcement: Before executing actions, embodied agents shall validate all input parameters to ensure they are within safe and acceptable ranges. Constraints and guardrails shall be implemented and enforced to prevent operations that could lead to damage or harm.\n\u2022 Continuous Monitoring and Testing: Regular monitoring and testing are essential to maintain reliability. Em-"}, {"title": "Privacy and Data Protection", "content": "With the ability to process and interpret vast amounts of data, including textual and sensory inputs, ROSA must ensure that privacy is upheld and data is secured. To that end, ROSA does not collect or retain data between sessions, and does"}, {"title": "Avoidance of Harm", "content": "Measures should be taken to prevent ROSA from being used for harmful purposes. This includes restricting access to critical functions and implementing failover mechanisms. By default, the open-source ROSA libraries do not include any \"uplink\" tools. Rather, we have deliberately chosen to include only \"downlink\" tools, or those tools which can be used only to observe and understand the systems under which the agent operates. Our aim in doing so is to encourage adopters to take a holistic approach to developing and deploying embodied agents, with their own particular configurations, operating environments, hardware, and robotic capabilities. Effectively, the impetus for safe operations is placed on the organizations and individuals who choose to adopt and implement custom agents using the ROSA framework.\nFurther measures should be taken to ensure the ability for human intervention, as outlined above. In practice, this might include the creation of specific \u201ccommand multiplexers\" that only process the commands from ROSA if there is not an override command coming from a human operator. For instance, you may have a \u201cteleop multiplexer\u201d that subscribes to commands from"}]}