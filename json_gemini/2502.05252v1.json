{"title": "GSM-\u221e: How Do Your LLMs Behave over Infinitely Increasing Context Length and Reasoning Complexity?", "authors": ["Yang Zhou", "Hongyi Liu", "Zhuoming Chen", "Yuandong Tian", "Beidi Chen"], "abstract": "Long-context large language models (LLMs) have recently shown strong performance in information retrieval and long-document QA. However, to tackle the most challenging intellectual problems, LLMs must reason effectively in long and complex contexts (e.g., frontier mathematical research). Studying how LLMs handle increasing reasoning complexity and context length is essential, yet existing benchmarks lack a solid basis for quantitative evaluation. Inspired by the abstraction of GSM-8K problems as computational graphs and the ability to introduce noise by adding unnecessary nodes and edges-we develop a grade-school math problem generator capable of producing arithmetic problems with infinite difficulty and context length under fine-grained control. Using our newly synthesized GSM-\u221e benchmark, we comprehensively evaluate existing LLMs. We find a consistent sigmoid decline in reasoning performance as complexity increases, along with a systematic inference scaling trend: exponentially increasing inference computation yields only linear performance gains. These findings underscore the fundamental limitations of current long-context LLMs and the key challenges in scaling reasoning capabilities. Our GSM-\u221e benchmark provides a scalable and controllable testbed for systematically studying and advancing LLM reasoning in long and complex contexts.", "sections": [{"title": "1 Introduction", "content": "Recently, state-of-the-art long-context LLMs (Team et al., 2024a; MiniMax et al., 2025) have achieved astonishing performance in a tremendously long context, where Team et al. (2024a) achieves near-perfect performance in 10M multimodal retrieval and long document QA. However, for long-context LLMs to contribute to cutting-edge mathematical and scientific discoveries or function as autonomous agents, they must be capable of processing dense, complex information and reason through multi-step tasks. For instance, Sir Andrew Wiles' proof (Wiles, 1995) of Fermat's Last Theorem in 1995 spans more than 88K highly compact tokens with deep logical connections, making context-level RAG (Lewis et al., 2021) insufficient and highlighting the need for long-context LLMs. Therefore, it is crucial to benchmark and facilitate long-context LLMs for complex reasoning and high-density information processing.\nAlthough widely used, current long-context bench-"}, {"title": "2 Related Work and Problem Statement", "content": "Despite the wide popularity of some existing long-context benchmarks, this section reveals and elaborates on the three key limitations: low complexity, detectable noise, and low resource or limited quantity of test examples. These three limitations make it extremely challenging to measure long-context LLMs' progress toward advanced intellectual agents using existing benchmarks.\nLow Complexity. A significant portion of long-context evaluation datasets, including RULER (Hsieh et al., 2024b), LongBench (Bai et al., 2024), LongBench v2 (Bai et al., 2025), and LOFT (Lee et al., 2024), primarily assess retrieval and summarization rather than complex reasoning. As shown in Figure 3, our experiments demonstrate that RAG systems achieve competitive results with Llama3.1-70B-Instruct across these datasets. Notably, RAG outperforms LLMs in retrieval-focused tasks (e.g., RULER, LOFT) and performs comparably in text summarization and QA (most LongBench tasks), as well as structured reasoning problems such as variable"}, {"title": "3 Computational Graphs", "content": "In this section, we detailed the construction of computational graphs, the key construct that enables GSM-\u221e generation of infinite quantities of arbitrary context length and reasoning complexity. Specifically, we explain in detail the potential mapping between reasoning problems and computational graphs in Section 3.1, and in Section 3.2, we propose to generate indistinguishable noise by strategically extending the computational graph."}, {"title": "3.1 Graph Construction to Build Reasoning Problems", "content": "After carefully studying GSM-8K problems, we draw the following crucial observations, which allow us to map a randomly generated computational graph to grade-school-level math reasoning problems that cover all possible operations and relationship types.\nMapping Explicit Ops to Computational Graphs\nFrom Every operation used in the GSM-8K is one of the four \"+\", \"-\", \"\u00d7\", and \"\u00f7\". Consider the following example when operations are presented explicitly, \"Eggs cost twice as much as tomatoes, while tomatoes cost 1 dollar each.\" These statements mention operations (\"plus\", \"more\u201d, \u201ctimes\u201d, etc.) can easily be abstracted out as a computational graph with variables, \u201cdollar per egg\" and \"dollar per tomato\", as nodes. There are two edges one pointing from \"dollar per tomato\" to \"dollar per egg\", while another one from a constant 2 to \"dollar per tomato\". Another similar example is shown in Figure 6 (a). Therefore, randomly generating a computational graph with different topology of edge connections will lead to a new reasoning problem once the natural language context are attached to the nodes of the graph.\nGenerating Implicit + using Computational Graphs\nOn the other hand, the operations can also be presented implicitly hidden in natural language hierarchies. \"Mary earns 20 dollars in the morning, while she earns 25 dollars in the afternoon. How much total she earned that day?\" Although the problem doesn't explicitly mention addition, the solution has to sum up 20 and 25 to get 45. The reason is that natural language assumes a working day consists of morning and afternoon. Similarly, all four operations can be hidden in natural language hierarchies. Inspired by Ye et al. (2024a), we adopt its construct of \u201cAbstract Parameters\u201d and \u201cInstance Parameters\" to construct computational graphs that facilitate the generation of problem statements containing the hidden operations. Essentially, the newly added constructs can be thought of as adding the \"total money\" as a new node to the computational graph, which has two edges coming in, one from node \"Morning money\" and the other one from node \"Afternoon money\". But when generating the problem, we omit the description of two edges pointing to the node \u201ctotal money on Friday\". We also illustrate it in Figure 6(b). Following Ye et al. (2024a), we connect the specific instance parameters to the abstract parameters using red edges. To reiterate, these edges are omitted, forcing the LLMs to use commonsense and inducing implicit operations.\nGenerating Implicit \u00d7 using Computational Graphs - every variables in the above-mentioned problem"}, {"title": "3.2 Noise Construction Using Computational Graphs", "content": "Spider Topology - We observe that we can view noise as extending the computational graph to incorporate fake and unnecessary parameters and operators. However, two critical questions emerge. First, how to extend the computational graph without contaminating the original graph's solution and contaminations? We found that edges have to point outwards from the nodes in the original graph to the newly added noise nodes, essentially preventing the noise nodes from contributing to the core graph. Second, how to maximize the chance that RAG cannot retrieve the essential graph? It turns out interconnecting edges between newly added noise nodes won't contribute help detering RAG's retriever. We find out a simple trick works well: ensuring the majority of the added edges connect core nodes and the noise nodes contribute to a semantically close noise. We call this design Spider Topology as shown in Figure 6(c).\nWe evaluated the resulting noise using two RAG systems presented in 2. The results are shown in Figures 5(c) and (d). Llama3.1-70B-Instruct achieves drastically stronger performance than the two RAG systems on 8K 2-entity problems and 3-entity problems. We also carried out the same study before on our data set setting 2, in Figure 5(b). We found that the RAG retriever now completely cannot distinguish which essential chunks from noise chunks, showing a clear contrast with vt tasks of the same context length in (a)."}, {"title": "4 GSM-\u221e", "content": "In this section, we present key techniques that enable the synthetic dataset to be diverse in operations in Section 4.1, LLM-understandable, and enable the evaluation to be free from non-reasoning factors in Section 4.2. Then, we present synthetic problem generators capable of generating grade-school math questions with arbitrary reasoning difficulty and context length. Thus, we generate a suite of benchmarks called GSM-\u221e detailed in Section 4.3."}, {"title": "4.1 Challenge 1: How to Generate Implicit\n and \u00f7 Operations?", "content": "Firstly, we review why the abstract-instance construct can only generate \u201c+\u201d and \u00d7 but not \u201c-\u201d and. The key limitation of Ye et al. (2024a) abstract parameters and instance parameter design is that it is only able to generate problems with solutions with the \u201cforward\u201d and constructive ordering. Shown in Figure 6 (a) and (b), the design dictates that the specific and detailed variables should be defined before a more abstract variable."}, {"title": "4.2 Challenge 2: How to Ensure LLM-understandable Problem Generation?", "content": "Mapping computation graphs to natural language is critical for evaluating LLMs' reasoning capabilities. To automate this process, we develop inter-swappable templates that enhance linguistic diversity while maintaining clarity. Several key considerations inform our design.\nFirst, Certain syntactic forms, such as possessive constructions (e.g., A's B), are straightforward to encode but can mislead LLMs due to their deviation from natural language. For example, South Zoo's Penguin is restructured as Penguin in South Zoo, and South Zoo's Adult Penguin's Average Number of Newborn Children becomes Average Number of Newborn Children per Adult Penguin in South Zoo. Through extended trial and error, variable names with different entity numbers are presented naturally in all prepared templates.\nSecond, the number of constraints applied to the random graph generation process is as little as possible, forcing templates to enforce unit consistency across two-entity and three-entity variables to enable assignment between these two. For instance, \"The average number of animal children per penguin in South Zoo\" must share a unit with \"The number of penguins in South Zoo\" to allow variable assignments.\nThird, to ensure real-world knowledge doesn't confuse the LLM's decision, we avoid specific real-world locations, people's names, and festival names from appearing in the template. Based on these constricts, we propose three different templates that meet real-world templates: children-animal-zoo, teachers-school-district, and awards-movies-festival. We present in Appendix G an ablation study showing that three templates are consistent in overall performance with only minor fluctuations when evaluated using Llama-3.1-8B-Instruct. At each op, equal problems are tested for both constructive ordering (forward) and reverse ordering (reverse)."}, {"title": "4.3 Benchmark Details", "content": "With the synthetic problem generators detailed in Section 4, we then use them to generate problems to build a suite of reasoning tasks with increasing complexity. For the brevity of reference, we refer to the generated problems with only explicit operations as \"Easy\", the generated problems with 2-entity variables at maximum as \"Medium\", and the generated problems with 3-entity variables at maximum as \"Hard.\nIdeally, when evaluating an LLM, we want to evaluate all difficulty levels, from the most basic logic complexity to when it completely fails to solve any problem. For the Easy subset of problems, it usually leads to large operation counts for powerful LLMs. However, although complexity-wise not challenging, LLMs trained with internal COT tend to generate very long arguments, saturating their API output generation limit (4K for many models). Thus, we observe a sudden decay in accuracy in large ops, not because of LLMs' ability bottlenecks, but because of the above-mentioned nuance. Thus, we make a tweak to its problem: Instead of asking the LLM to find the value of"}, {"title": "5 Evaluation", "content": "In this section, we present comprehensive evaluations of various LLMs on GSM-\u221e. Specifically, the section is organized as follows:\n\u2022 Section 5.1 presents the complete comparison of LLMs on both zero-noise tasks and long-context tasks. Besides"}, {"title": "5.2 LLM Performance Degradation Can be Modeled Using Sigmoid Function", "content": "Our construction of GSM-\u221e enables precise measurement of LLM performance across fine-grained difficulty levels. For each subtask, we observe a clear trend: LLM accuracy declines as the number of required operations increases. Surprisingly, most models exhibit a sigmoid-like performance decay, as shown in 10 for forward problems"}, {"title": "5.3 Reverse Problems are Harder to Solve for LLMs", "content": "The generator of GSM-\u221e can generate both the \"forward\" and the \"reverse\" problems, which can be compared separately. Most LLMs perform worse in reverse problems than forward ones, shown in Figure 10(b) using Mistral-Large (Jiang et al., 2023a). For the Medium, only Jamba-1.5-Large out of a total of 18 LLMs evaluated do reverse problems better than forward problems, and the average difference in AUC is 604. For the Hard subtask, 5 out of 18 models have larger reverse problems AUC, Deepseek R1, Gemini-1.5-Pro-002, Qwen2.5-7B-Instruct Qwen et al. (2025), 40-mini, and Jamba-1.5-Large (Team et al., 2024b). The average difference in AUC is 154. A detailed breakdown is listed in Appendix F. Besides, LLM performance on reverse problems can also be modeled by a sigmoid mapping. Five more LLM plots are presented in Appendix F."}, {"title": "5.4 Long-context Degradation and Noise Ablation", "content": "We evaluate LLM performance across increasing context lengths (0, 8K, 16K, 32K) and observe a consistent decline in performance as context length increases. Notably, models exhibit different decay patterns. We present results for 10 models across 3 subtasks, each with four curves representing different context lengths. All 30 plots are in Appendix H.\nWe conduct an ablation study on three noise types: GSM-\u221e (ours), LLM-generated, and random. For LLM- generated noise, we prompt GPT-40 to create a fake documentary-style commentary on random problems, occasionally introducing nonsensical variable mentions. For random noise, we follow Hsieh et al. (2024), using generic statements like \"The sky is blue. The tree is green.\" We evaluate Llama3.1-70B-Instruct and a RAG system under all three noise types in an 8K context. Interestingly, RAG outperforms long-context LLMs on LLM-generated and random noise, effectively filtering irrelevant content. However, it fails to distinguish GSM-\u221e noise from essential problem statements."}, {"title": "5.5 Limitations of Repeated Sampling", "content": "The construction of GSM-\u221e allows us to study techniques for Inference Scaling as well. Specifically, we study repeated sampling (Brown et al., 2024a; Snell et al., 2024) and its effectiveness under different reasoning complexity. We study both Qwen2.5-7B-Instruct and Llama3.1-8B-Instruct with the best-of-N settings similar to Brown et al. (2024b). Interestingly, we find that repeated sampling seems to boost the performance the most for smaller op count subsets, and the benefit of repeated sampling diminishes gradually for larger op count subsets, Qwen2.5-7B-Instruct behavior is plotted in Figure 9(a) with different repeated trial settings.\nSurprisingly, suppose we calculate the AUC score under every curve corresponding to each number of repeated trial settings. In that case, we find that the increment in the AUC score from two consecutive settings is close. If we plot the AUC score versus the number of repeated trial settings and take the log scale of the repeated trial N, the graph is linear, as shown in Figure 9(b). The R-squared is greater than 0.99 for both Qwen2.5-72B-Instruct and Llama3.1-8B-Instruct, where Llama3.1-8B-Instruct. Therefore, GSM-\u221e helps reveal that Repeated Sampling leads to linear AUC Improvement from exponentially increasing computation cost."}, {"title": "6 Conclusion", "content": "Long-context LLMs have the potential to tackle complex, information-dense tasks requiring deep reasoning and coherent long-form generation. To advance their development and benchmarking, we introduce GSM-\u221e, a synthetic long-context reasoning benchmark generated entirely by a software-based system with fine-grained control over complexity and information density. Through extensive evaluations on GSM-\u221e, we uncover key insights to inform future LLM training and inference improvements."}]}