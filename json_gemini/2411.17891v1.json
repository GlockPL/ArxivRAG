{"title": "Medical-Grade Platform\nfor Medical Imaging AI", "authors": ["Kalina P. Slavkova, PhD", "Melanie Traughber, DSc", "Oliver Chen, MD", "Robert Bakos", "Shayna Goldstein", "Dan Harms", "Bradley J. Erickson, MD, PhD", "Khan M. Siddiqui, MD"], "abstract": "Technological advances in artificial intelligence (AI) have enabled the development of large vision language\nmodels (LVLMs) that are trained on millions of paired image and text samples. Subsequent research efforts have\ndemonstrated great potential of LVLMs to achieve high performance in medical imaging use cases (e.g., radiology\nreport generation), but there remain barriers that hinder the ability to deploy these solutions broadly. These include\nthe cost of extensive computational requirements for developing large scale models, expertise in the development of\nsophisticated AI models, and the difficulty in accessing substantially large, high-quality datasets that adequately\nrepresent the population in which the LVLM solution is to be deployed. The HOPPR Medical-Grade Platform\naddresses these barriers by providing powerful computational infrastructure, a suite of foundation models on top of\nwhich developers can fine-tune for their specific use cases, and a robust quality management system that sets a\nstandard for evaluating fine-tuned models for deployment in clinical settings. The HOPPR Platform has access to\nmillions of imaging studies and text reports sourced from hundreds of imaging centers from diverse populations to\npretrain foundation models and enable use case-specific cohorts for fine-tuning. All data are deidentified and\nsecurely stored for HIPAA compliance. Additionally, developers can securely host models on the HOPPR platform\nand access them via an API to make inferences using these models within established clinical workflows. With the\nMedical-Grade Platform, HOPPR's mission is to expedite the deployment of LVLM solutions for medical imaging\nand ultimately optimize radiologists' workflows and meet the growing demands of the field.", "sections": [{"title": "Introduction", "content": "Artificial Intelligence (AI) is revolutionizing\nhealthcare, particularly in medical imaging, where it\nhas demonstrated immense potential to enhance\ndiagnostic accuracy, reduce clinical workload, and\nimprove patient outcomes\u00b9\u00b2. Radiology is a data-\nintensive field that relies heavily on the interpretation\nof complex images while incorporating information\nfrom previous reports and patient medical records.\nThe complexity and redundancy inherent in\nradiologists' tasks have catalyzed significant AI-driven\ninnovations. The integration of AI in radiology\nextends beyond traditional image classification tasks\nand is expanding into more sophisticated applications,\nincluding report generation and evaluation, predictive\ndiagnostics, and functioning as a second reader\u00b9\u00b3.\nThese developments are largely fueled by the\nevolution of generative AI and foundation models,\nwhich are multimodal, large-scale models capable of\nunderstanding and processing diverse data types. Such\ngenerative models, trained on vast amounts of\nimaging and clinical data, can be fine-tuned to adapt\nto specific clinical applications while ensuring high\nlevels of accuracy and reliability.\nHOPPR's Medical-Grade Platform\nexemplifies these advancements by providing a\ncomprehensive infrastructure for the training, fine-\ntuning, and deployment of AI models that adhere to\nregulatory requirements within clinical settings.\nSpecifically, medical-grade status is conferred by the\ndevelopment of the HOPPR platform under a robust\nquality management system (QMS), following ISO\n13485, that aligns with the stringent demands of\nhealthcare oversight and sets a new standard for\nfoundation models in medical imaging applications.\nThe platform comprises four essential pillars\u2014\nPlatform, Data, Foundation Models, and Validation &\nRegulatory each designed to address critical aspects\nof medical AI implementation. Its medical-grade\nhosting environment allows for the seamless"}, {"title": "Background", "content": "What is a Foundation Model?\nFoundation models are large-scale AI models\nconsisting of billions of parameters, trained on\nextensive and diverse datasets\u2014often comprising\nmillions of examples\u2014through scaled-up self-\nsupervision. This enables them to learn generalized\nfeatures from the training data. Training foundation\nmodels necessitates vast computational resources and\nsubstantial amounts of high-quality data. Once\ntrained, however, foundation models can significantly\nexpedite the development of task-specific models\nthrough fine-tuning (See Figure 1). Fine-tuning refers\nto the process of taking a foundation model\npretrained on large datasets and continuing to train on\na smaller, curated dataset to improve performance for\na specific task.\nPreviously, deep learning research\npredominantly focused on training smaller models\nfrom scratch-starting with randomly initialized\nweights or weights from a different task for specific\nuse cases. This approach resulted in task-specific\nmodels limited to the tasks they were trained to\nperform. Foundation models are shifting the AI\nresearch paradigm away from training models from\nscratch. This shift allows developers to begin with a\nfoundation model that has learned generalized data\nrepresentations, enabling fine-tuning for specific tasks\nto be accomplished more rapidly and with\nsignificantly less data and computational resources\ncompared to the traditional approach. For example,\ncommercial large language models (LLMs), such as\nGPT-4 from OpenAI, are initially pretrained on vast\namounts of publicly available text data to learn\nrepresentations of text in various contexts."}, {"title": "Foundation Models in Medical Imaging", "content": "When VLMs are scaled up to perform across\nmore complex tasks, they are referred to as large\nVLMs (LVLMs). The application of LVLMs to\nmedical imaging data has demonstrated significant\npotential in optimizing radiologists' workflows by\nautomating time-intensive tasks, such as report\ngeneration and serving as a second reader for\nevaluating studies. Due to the high prevalence of\nchest X-ray and abdominal CT studies compared to\nother modalities like MRI, considerable efforts have\nfocused on developing LVLMs for CT and X-ray\nprocessing. \"Merlin\" is one such VLM that has been\npretrained on approximately 6 million images sourced\nfrom roughly 15,000 CT scans with corresponding\ndiagnosis codes and radiology reports. It has been\nextensively evaluated on numerous clinical tasks,\nranging from five-year disease prediction to report\ngeneration 10."}, {"title": "The HOPPR Medical-Grade Platform", "content": "The HOPPR Platform is powered by\nproprietary LVLMs pretrained on the largest medical\nimaging dataset assembled to date, comprising over\n120 million imaging studies spanning 10 years with 70\nmillion added annually. This extensive dataset has\nbeen acquired through partnerships with over 400\nimaging centers across eight states, encompassing all\ndemographics and ethnicities and covering thousands\nof diagnostic assessments. A large, representative\ndataset is essential for developing models that\nperform robustly across all socioeconomic and\ndemographic scenarios.\nA Platform for Deep Interaction with Imaging Studies\nThe HOPPR platform offers model hosting\ncapabilities for customers seeking to deploy custom\nmodels for evaluating imaging studies (see Figure 2\nfor an example use case). Through this partnership,\nusers can upload studies and analyze them using their\nprovided model via the medical-grade, secure\nHOPPR API that is hosted by a trusted cloud service\nand managed by a dedicated platform team. This API-\nbased solution allows customers to seamlessly embed\nthe capabilities of the HOPPR Foundation Models\nwithin their existing applications and workflow."}, {"title": "Fine-Tuning for Customer Use Cases", "content": "To promote AI democratization, HOPPR\nprovides powerful computational resources and\nexpertise for developing custom models based on the\nHOPPR Foundation Models (see Figure 3). By fine-\ntuning these foundation models, customers can create\ncustom models in a significantly shorter time frame\nwith substantially less data and computational\nrequirements compared to training task-specific\nmodels from scratch. The typical workflow for fine-\ntuning with HOPPR's support involves the following\nsteps:\n1. Initial Evaluation: For a given customer use case\nand required performance level, the initial step\ninvolves evaluating the HOPPR Foundation\nModels out-of-the-box on the task (i.e., without\nfine-tuning) using HOPPR data as well as real-\nworld data specific to the context of the use case.\nIf performance at this stage is sufficient, no fine-\ntuning is necessary.\n2. Data Acquisition and Curation: If the expected\nperformance is not achieved, the next step is to\nacquire additional data that fits the context of the\nuse case. If the customer cannot provide this\ndata, they may opt for HOPPR-assisted data\ncuration and labeling for the specific use case.\n3. Fine-Tuning: HOPPR plans to provide and\nexpand self-service tools for fine-tuning that\ncustomers may use if the use case is compatible\nwith the available tooling. Otherwise, HOPPR\nexperts will develop a custom fine-tuning\nsolution for the customer."}, {"title": "How is Data Security and Privacy Ensured?", "content": "Given the vast amount of data that HOPPR\nhas obtained through site partnerships, it is imperative\nthat a secure, HIPAA-compliant system is in place for\ndata management. HOPPR de-identifies all data by\ntransforming entries in the DICOM headers. For\nexample, patient age is recorded as 89+ years, and the\nacquisition date is randomly shifted by \u00b17 days.\nAdditionally, HOPPR employs \"hiding in plain\nsight\"\u00b9\u00b9 and many other techniques to ensure there is\nno malicious or accidental disclosure of Protected\nHealth Information (PHI). A proprietary process is\nimplemented to remove any \u201cburnt in\u201d PHI in the\nimages as well. These transformations ensure that no\nPHI data remain in the reports and images."}, {"title": "Conclusion", "content": "The HOPPR Medical-Grade Platform\nprovides the infrastructure and a suite of tools to\nexpedite the development and deployment of AI-\nbased solutions for improving radiologists' workflows\nin an era of ever-growing demand for medical\nimaging. A key component of the HOPPR platform,\nthe HOPPR Foundation Models, are large vision-\nlanguage models pretrained on large amounts of high-\nquality imaging studies with corresponding text\nreports. Customers can fine-tune these models with\nadditional context-specific data to improve\nperformance for specific use cases. With this\nplatform, HOPPR anticipates increased development\nof state-of-the-art AI tools and ease of clinical\nimplementation that will address the current and\nfuture needs of radiology in all communities."}]}