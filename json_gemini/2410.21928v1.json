{"title": "Differentiable Inductive Logic Programming for Fraud Detection", "authors": ["Boris Wolfson", "Erman Acar"], "abstract": "In the domain of financial services, fraud detection is one of the tasks that can greatly benefit from explainable AI (XAI) research. Addressing that demand, we investigate the applicability of Differentiable Inductive Logic Programming (@ILP) as an explainable AI approach to Fraud Detection. Although the scalability of \u2202ILP is a well-known issue, we show that with some data curation such as cleaning and adjusting the tabular and numerical data to the expected format of background facts statements, it becomes much more applicable. While in processing it does not provide any significant advantage on rather more traditional methods such as Decision Trees, or more recent ones like Deep Symbolic Classification, it still gives comparable results. We showcase its limitations and points to improve, as well as potential use cases where it can be much more useful compared to traditional methods, such as recursive rule learning.", "sections": [{"title": "1 Introduction", "content": "Fraudulent activity is as old as money itself [8]. In modern society, fraud contributes not only to financial loss but also impacts people, industries, entities, services, and the environment. According to the Annual Fraud Report from UK Finance, the overall fraud losses in the UK in 2022 added up to $ 1.2 billion, of which fraud losses across payment cards and remote banking had a share of $ 726.9 million [10].\nFraudulent action detection classically has been addressed with rule-driven approaches and is still largely a part of the industry practice since explainability in fraud-detection is an important criterion. However, they require laborsome hand crafting when it comes to extending these rules to an ever-changing world with ever-changing business rules, regulations, and even fraud schemes which are dynamic by nature.\nRecently, there has been a rise in the use of machine learning (ML) and data-driven approaches thanks to their high accuracy and adaptivity, however, due to their opaque nature, explaining them requires developing new approaches, giving birth to the field of explainable AI (XAI). Regarding inherently explainable methods such as Decision Trees (DTs), much of the work done is related to simple rule extraction in the If-Then form. This requires a lot of data to train the model, and it is still limited in the generalization and compactness of rules. Generalization is important in the fraud detection area as the available data is usually highly unbalanced towards non-fraudulent transactions. On the other hand, very large rules explaining data do not really help, as they are not easy to progress by the practitioners either.\nA recent research agenda called Neuro-Symbolic (NeSy) AI focuses on combining the strengths of both worlds; namely developing systems that are both rule-based in nature but also using the strength of flexibility and accuracy of ML approaches [12].\nOne approach that deals well with small datasets and is known for its ability for generalization is the Inductive Logic Programming (ILP) paradigm, and early and partly less explored rule-based machine learning approach [16]. ILP provides a set of rules that explains the input dataset. The dataset consists of positive and negative examples, and the program entails all the positive examples and does not entail any negative ones. Thus, from the machine learning point of view, the ILP system is ultimately a binary classifier that not only explains the data itself but is robust enough to generalize on unseen data. The main disadvantage of ILP, however, is that it does not deal well with noisy, erroneous, or ambiguous data [9].\nMore recently, a few works emerged suggesting a neural symbolic extension for implementing the ILP in the very NeSy spirit, one of which is Differentiable Inductive Logic Programming \u2202ILP [9]. Evans and Grefenstette [9] showed that ILP can provide generalization when applied to noisy data.\nIn this paper, we investigate further extension of a ILP as a potential application of it to fraud detection, which to the best of our knowledge, is not yet done. In doing so, we look for answers to the following research questions:\nRQ1 What is the level of performance concerning other traditional approaches, such as Decision Trees and Deep Symbolic Classification?\nRQ2 What is the trade-off between the size of the rule vs its performance?\nRQ3 To what extent can \u018fILP provide explanatory rules by using Recursive Structures for detecting relationships between different agents?\nTo address these questions, first, we develop a synthetic dataset to test the performance of \u018fILP, and then we train and evaluate the"}, {"title": "2 Related Work", "content": "Multiple approaches to derive rules from the tabular data exist - the most famous one is the DT approach, where the IF \u2013 THEN \u2013 ELSE set of rules is applied to split the data into different categories [3]. Although DTs provide explanatory rules, these rules come in multiple spits, affecting interpretability. In addition, as was shown by Bengio et al. [2] DTs are known to overfit and lack generalization. Other approaches use Neural Networks to derive the set of rules, by implementing AND, and OR logical operators by two consecutive layers respectively. The Decision Rules Network (DR- Net), and the Relational Rule Network (R2N) for example, provide a set of rules in a disjunctive normal form (DNF) as shown in Equation 1 [13, 19].\nIF A or B or C ... THEN\n(1)\nThe work of Collery et al. [6] extended this approach by applying an R2N layer as a convolutional window, for discovering patterns for the classification of sequential data. These approaches deliver an inherently explainable set of rules but cannot derive recursive predicates or invent a new predicate. The size of the derived rule formula expresses the importance of recursion. In addition, recursion is useful in generalizing from small datasets. The ability of predicate invention allows algorithms to learn patterns without explicit input from domain experts.\nAs an alternative to \u018fILP, there are other differentiable inductive logic methods, such as differentiable Neural Logic ILP (dNL-ILP) [17] and MetaAbd [7]. Both dNL-ILP and \u018fILP learn target predicates based on the facts defined by the set of predicates and auxiliary predicates. Domain experts usually define auxiliary predicates. The difference between the two approaches lies in how the initial set of rules is generated. \u018fILP has several restrictions in so-called language bias, the template that defines how to generate the rules. dNL-ILP has however fewer restrictions and is thus expected to be more scalable. MetaAbd approach implements background knowledge as a set of rules, instead of facts and works on images, with no explicit positive and negative examples. All three are capable of implementing recursion and inventing predicates. In this work, we opted to start exploring \u018fILP because it is a well-studied and more well-known framework.\nOn the XAI methods that are applied to fraud detection, there has been a large body of work. As most well-known industry standards include logistic regression and DTs.\nHajek et al. [11] compares the performance of the XGBoost (a non-explainable industry standard) framework to other conventional methods, applied on the PaySim dataset, and recent work by Visbeek et al. [21], introduced a Deep Symbolic Classification"}, {"title": "3 The Method: JILP", "content": "In introducing the main method, JILP, we give the intuitive explanation leaving the technical details out and referring the interested reader to [9].\nThe rules of an ILP framework are written as clauses of the following form:\n\u0397 \u2190 \u03921, \u03922, ...., \u0392\u03b7, (2)\nwhere atom H is defined as the head of the clause and the set of atoms B1, B2, ...., Bn is defined as the body of the clause. Atom is a predicate applied to a set of terms. Where each term is a variable, for example, a client ID. If all the atoms in the body are true, then the head is necessarily true. The clause is also defined as a definite clause because it has only one head.\nFor example, the following program defines the set of rules R for connected relations as the transitive closure of the edge relation:\nconnected(X, Y) \u2190 edge(X, Y)\nconnected(X, Y) \u2190 edge(X, Z), connected (Z, Y).\n(3)\nHere, the background knowledge can be defined as a set of all edges, the positive examples as a set of all known connections, and the negative examples as a set of examples where the variables are not connected.\nJILP learns a set R of definite clauses such that the union set of background facts B and R entails all the atoms in a set of positive examples P, and does not entail all the atoms in a set of negative examples N:\nB, R \u22a8 y, \u2200y \u2208 P\nB, R \u22ad y, \u2200y \u2208 N\n(4)"}, {"title": "3.1 Clause Generations", "content": "Two types of predicates are distinguished in JILP: the intensional and extensional predicates. The set of extensional predicates Pe are the given predicates from the background knowledge, and the set of intensional Pi are the predicates to be learned. The set Pi consists of the target predicate and additional auxiliary predicates Pa. The central component of ILP is based on generating a list of possible definite clauses for intensional predicates, also known as a language bias [20]. The clauses are generated by the so-called rule template \u03c4, which defines the range of clauses to generate. Two clauses define each predicate p, therefore there are two templates (\u03c4\u03c1, \u03c4\u03c1).\n\u03c4 = (n, int) (5)\nWhere n specifies the number of existentially quantified variables allowed in the clause, and int is a flag that determines whether the atoms in the clause can use intensional predicates Pi.\nThe following restrictions are applied when generating clauses:\n\u2022 Each clause consists of exactly two atoms. Where an atom y is any grounded predicate.\n\u2022 A predicate has a maximal arity of two.\n\u2022 The variable that appears in the head of the clause must appear in its body.\n\u2022 An atom is not used in the same clause's head and body (circular restriction).\nIt was discovered during development, that the software suite generated rules of the following shape:\nFraud(X) \u2190 Predicate1(X)\nPredicate1(X) \u2190 Fraud(X), Predicate2(X) (6)\nThe Atom Fraud(X) does not appear directly in the body of the same rule but appears after in the body of a dependent Atom Predicate1(X). Therefore, in addition to the formal restrictions mentioned in the work of Evans and Grefenstette [9], an extension of the circular restriction was introduced; that is, the target predicate with the same variable can not appear in the head and body of both clauses defining the predicate."}, {"title": "3.2 Pipeline", "content": "In this section, we describe different aspects of the implementation. The general overview of the process is described in Figure 1.\n3.2.1 Adjustment of dILP to use tabular data. JILP is applied to background knowledge consisting of a set of facts, and positive and negative examples of the predicates. The set of facts is binary, therefore the existing input data should be adjusted to the same binary format. A work of Ciravegna et al. [5] about Logic Explained Networks (LEN), suggested discretizing numerical data into different bins to enable a neural learner to use the data. We exploit a similar approach for importing the fraudulent data into the model, by applying a threshold to values to test if it is above or below it. Thus converting a numerical column to a binary one. The binarised column is called a predicate of arity one. Because a predicate is a function of a variable, for the grounding purposes of a variable, it is assigned to an index of the transaction in the dataset, thus explicitly applying the uniqueness of the relevant transaction, for example, isFraud(X), is a predicate is Fraud of the transaction X. The DT and the DSC thresholds will be used to binarise the tabular data.\nWhen discussing more complicated predicates with an arity of two, when considering a predicate based on sender and receiver, the grounding of the variable's facts is based on the sender and receiver identity number, assuming that the identity number is unique. For example, isFraud(X, Y), is a predicate isFraud of a transaction between X and Y.\n3.2.2 Rule size. Rule size is defined through the number of possible predicate columns to incorporate in the logical program."}, {"title": "3.2.3 Program Template", "content": "As discussed before, JILP requires an input of Program Template, consisting of the inference step T, a set of auxiliary predicates as in Rule size, and rule templates."}, {"title": "3.2.4 SQL query generator", "content": "For the 1-arity predicate, an SQL query was generated based on the derived rule and applied to the tabular data. An example rule with a form (Equation 7):\nTarget(X0) \u2190 Pe1(Xo), pred1(Xo)\nTarget(X0) \u2190 Pe2(X0), pred2(Xo)\npred1(X0) \u2190 Pe3(X0), pred2(Xo)\npred2(X0) \u2190 Pe4(Xo).\n(7)\nFollowing this rule, the SQL generator gives the query:\nSelect\nPe4 as pred2,\nPe3 as pred1,\nPe2 and pred2 or Pe1 and pred1 as Target,\nfrom Fraud_Table"}, {"title": "4 Data and the Experimental Setup", "content": "A considerable amount of research was done on a simulated scenario PaySim which can be found on Kaggle site\u00b9. In this dataset, the fraudulent behavior of the agents aims to profit by taking control of customers' accounts and trying to empty the funds by transferring them to another account and then cashing out of the system. We chose this dataset because it allows us to effectively compare the method to other studies working with the same dataset.\nThe dataset contains 6.3 million transactions over one month of simulation, from which the number of fraudulent transactions is 8.2K, giving a ratio of circa 0.13%."}, {"title": "4.0.1 Explorative Data Analysis", "content": "Figure 2 shows the fraudulent and valid transaction amount density distributions. Looking into the median and average values, it can be seen that both the Fraudulent and the Valid distributions are shifted with respect to each other. The average and median of fraudulent transactions are higher than the valid ones, meaning the transaction value should play a role in the fraud classification."}, {"title": "4.0.2 Feature engeneering", "content": "For the missing value treatment and aggregates calculation we followed the work of Visbeek et al. [21].\nMissing values treatment. No null or NaN values were identified in the dataset, however, there are transactions with zero values for old and new balances. Those are transactions from or to the Merchants, who are the Customers with an ID starting with M. The balances for these types of transactions were changed to be equal to the amount of a transaction. An additional external origin, and external destination flags were calculated to mark those types of transactions.\nTest, train, validation. The transaction data was randomly split into train (85%) and test(15%) sets. Subsequently, the training set was split into the validation (15%) and train (85%) sets. Assuming"}, {"title": "4.1 Synthetic generated test data", "content": "Dummy Set. To understand the role of hyperparameters such as the number of inference steps and program templates, we first test our methods on a small set with dummy synthetic data, the dataset consisted of five binary columns A, B, C, D, and Target. Where the Target column is true if A, B, C, and D are True. The values for A, B, C, and D were randomly generated and are equal to True or False. The goal is that the target predicate should be correctly learned with 100% accuracy.\nAdditional Fraud scenarios. The final datasets were created to explore the ability of the method to model recursive predicates. These Fraud scenarios differ from the one described in PaySim, intended to create a rule that can define a chain of fraudulent events. The concept is based on the transitivity case and the graph connection examples from JILP. The transitivity case was generated based on the random generation of the transactions between different entities, for the cases where one entity received a fraudulent transaction and then performed a transaction with another entity. This type of transaction scheme is defined as a Chain of Fraud."}, {"title": "4.2 Experimental Setup", "content": "The implementation of the \u018fILP method is based on the code published by ai-systems \u00b2. The aggregated features were made with the DuckDb package \u00b3 using SQL queries. The models based on PaySim and Dummy datasets were trained with an X13 Dell laptop, and the recursive examples were trained on the Snellius supercomputer \u2074."}, {"title": "4.3 Evaluation metrics", "content": "4.3.1 Performance. The performance of the fraud detection framework will be evaluated by the commonly used metrics for classification: accuracy, recall, precision, and F1 score. Additionally,"}, {"title": "5 Results", "content": "The following sections present the results of rule learning over the binarised data. In each case, the number of positive and negative instances is mentioned. The positive instances are where the Target Predicate is True, and the negative is where the Target is False. The Training set table may contain the rows where all the fact columns are False. Those are dropped since \u018fILP requires a set of facts that are True over the constant sets. Therefore, the number of instances may be less than the number of data rows.\nDerived rules are presented as they appeared from the derivation. In several cases, a head atom is defined by a duplication of an atom in the rule's body. This is explained by the approach's requirement that a body be defined by exactly two atoms."}, {"title": "5.1 A, B, C, D scenario", "content": "The first experiment was to test the influence of the number of inference steps on \u018fILP performance on a dummy dataset. Number of auxiliary predicates: |pa| = 2\nFor the different inference steps, the following rules were achieved"}, {"title": "T = 2 inference steps", "content": "Target(X0) \u2190 D(Xo), pred2(X0)\npred1(X0) \u2190 D(Xo), pred2(X0)\npred2(X) \u2190 C(X0), A(X0)\n(8)\nHere the rule only partially covers the dataset, because when rephrased it is\nTarget(X0) \u2190 D(X0), C(X0), A(X0)\n(9)\nremarkably pred2 does not influence the solution"}, {"title": "T = 3 inference steps", "content": "Target(Xo) \u2190 pred1(X0), pred1(X0)\npred1(X0) \u2190 pred2(X0), B(X0)\npred2(Xo) \u2190 C(X0), D(X0)\n(10)\nHere the rule again partially covers the dataset, but with other predicates:\nTarget(Xo) \u2190 B(X0), C(X0), D(X0)\n(11)"}, {"title": "T = 5 inference steps", "content": "Target(Xo) \u2190 pred1(Xo), B(Xo)\npred1(Xo) \u2190 pred2(X0), A(Xo)\npred2(X) \u2190 C(X0), D(X0)\n(12)\n(13)\nwhich can be rephrased as:\nTarget(Xo) \u2190 B(X0), A(X0), C(X0), D(X0)"}, {"title": "T = 10 Inference steps", "content": "This is an example of a circular dependency between pred1 and Target predicates derived during training.\nTarget(Xo) \u2190 pred1(X0), B(Xo)\npred1(X0) \u2190 Target(X0), Target(Xo)\n(14)\npred2(X0) \u2190 A(X0), D(X0)\nwhich can be rephrased as:\nTarget(X0) \u2190 B(X0), Target(X0), A(Xo), D(X0)\n(15)\nmeaning Target depends on Target\nT = 10 (Prevent recursion)\nTarget(Xo) \u2190 pred1(X0), C(X0)\npred1(X0) \u2190 pred2(Xo), A(Xo)\npred2(X0) \u2190 B(X0), D(X0)\n(16)\nwhich is also a full rule, covering the dataset. But T = 5 is enough inference steps to cover such a dataset."}, {"title": "5.2 PaySim learning", "content": "To provide a more objective answer to RQ1 we trained \u018fILP on the PaySim dataset. Training on the full original training set was impossible due to memory limitations. We trained \u018fILP on two smaller trainsets, consisting of 50:50% and 1% Fraud ratio."}, {"title": "5.2.1 Baseline performance", "content": "For establishing a baseline, a DT classifier and a classifier based on the DSC rule were evaluated. When the DT classifier was tuned to maximize the MCC score."}, {"title": "5.2.2 Parameters", "content": "All the tests were run with T = 5 inference steps, based on the assumption, that the number of required auxiliary predicates is equal to or is less than two in the \"A, B, C, and D\" simulated case."}, {"title": "5.2.3 DT thresholds", "content": "In Table 5 the results for the DT thresholds dataset case are summarized,"}, {"title": "5.2.4 Dataset based on DSC rule", "content": "Results are presented in Table 6. For both cases the same rule was learned: isFraud(Xo) if type_TRANSFER(X0) and external_dest(X0) are True, explaining the same performance results."}, {"title": "5.2.5 Training set for 1% fraction fraud cases", "content": "To estimate the influence of a smaller fraction of the Fraudulent class on the training performance, we extracted 1000 non-fraudulent and 10 fraudulent transactions from DT and DSC thresholds datasets."}, {"title": "5.2.6 Dataset based on DT thresholds including the negation", "content": "When deriving binary predicates based on the DT thresholds, the negated branches are not being checked by JILP, as it cannot generate the negated predicates. Therefore additional predicates were generated, equaled to the negation of the first set. The Fraud templates should support the DT paradigm, which defines rules as if A then B, else if"}, {"title": "5.2.7 Applying a large number of predicates", "content": "In order to provide an answer for RQ2 we tested various numbers of auxiliary predicates from two to eight to cover all possible columns in the DT dataset. The results showed the same performance as reported for two predicates. Meaning it did not show a difference in performance."}, {"title": "5.3 Learning the Recursive Structures", "content": "In the final set of experiments aimed at answering RQ3, we tested the ability of ILP to model recursive predicates. In this scenario, the knowledge of fraud is already known, for example by the superior classification algorithm, but there is an intention to derive patterns in the data, as in the case of money laundering patterns."}, {"title": "5.3.1 Fraud Relationship", "content": "In this scenario, the intention was to derive based on the dataset a rule, that can find a fraudulent relationship, based on background knowledge. The tabular dataset was prepared based on the example of Graph Connectedness from the original paper. All the transactions are fraudulent.\nThe derivation of a rule took 957 seconds, based on the input consisting of 4 Facts and 9 Positive examples:\nFraudsters(X, Y) \u2190 Fraud (X, Y)\nFraudsters(X, Y) \u2190 Fraud(Z, Y),\nFraudsters(Z, X)\n(24)\nHere the first Rule is Fraudsters(X, Y) \u2190 Fraud (X, Y) is inherent based on the dataset, as for the transaction between 1 and 2 (Fraud(1, 2)). The second rule is reflected by the example of Fraud transactions between 1 and 2 (Fraud (1, 2)) and 1 and 4 are Fraudsters from the facts (Fraudsters(1, 4)), therefore it explains 2 and 4 are Fraudsters (Fraudsters (2, 4)). Although it does appear in the facts, here we can see that it can be generalized to the examples which do not appear in the training set."}, {"title": "5.3.2 Chain of Fraud", "content": "This is an extension of the previous example, with a rationale to create a dataset with a chain of events, to find a rule for the transaction between three parties, participated in fraud.\nThe derivation of a rule took 1355 seconds, based on the input consisting of 36 facts, 5 positive and 21 negative examples:\nFraud_Chain(X, Y) \u2190 Fraud(Z, X), Transaction (X, Y) (25)\nThat rule can be translated as \"There is a chain of Fraud between X and Y if there is a transaction from X to Y and a fraud event between any Z and X."}, {"title": "6 Discussion", "content": "In this section, we interpret the obtain results from the angles of performance, scalability, circular dependency and interpretability in general."}, {"title": "6.1 Performance", "content": "6.1.1 Dummy dataset. When learning the rules from an error-free dataset \u018fILP succeeds in finding the logical rules. The number of inference steps can be seen as a hyperparameter for tuning as in the case of A, B, C, D rule learning.\n6.1.2 PaySim dataset. Regardless of the way of training on the DT or DSC converted Datasets, JILP was in line with the performance on the test set in terms of all the metrics compared to the performance of the DSC approach. The DT Classifier performed about 10% better than \u018fILP achieved in terms of F1, Recall, and MCC metrics,\n6.1.3 Data Conversion. We covered two approaches to utilizing tabular data for ILP methods, based on transaction IDs, or based on agent IDs. We showed how to prepare binary data based on the DT or DSC thresholds, and what Program Templates to use. When JILP was applied to the dataset prepared by DT thresholds, the number of auxiliary predicates, and a fraction of Fraud influenced the performance. We saw that for data including only positive (non-negated) columns and 50-50% split, the performance based on the Recall, F1, and MCC were lower\n6.1.4 Recursion and Connectivity. \u018fILP succeeded in learning the rule for the Fraud Relationship and the Chain of Fraud cases."}, {"title": "6.2 Scalability", "content": "The work ofEvans and Grefenstette [9] addressed the reason for memory consumption, it depends on the size of invented predicates and constants sets. The constant set size is proportional to the dataset length. In addition, memory size also depends on the amount of the generated clauses. In the case where templates define the predicates with an arity of two, JILP generates a very large dataset of clauses. This is the cause for the large training time when applied to relatively small datasets as in the case of connectivity and recursion."}, {"title": "6.3 Circular Dependency", "content": "We showed that \u018fILP can induce rules that have circular dependencies between predicates, the chance is higher in the case of one arity predicates. We implemented the removal of circular dependency on the target predicate. Yet we suspect that because there is no restriction to using two head atoms from two different clauses in each other bodies, there still is a chance of circularity in other predicates. Implementing additional circular restrictions on the predicate generation could be another future topic to investigate."}, {"title": "6.4 Interpretability", "content": "The generated set of rules are in the form of implications (If-Then sentences), and have higher expressivity, as they are relational and can even express circular dependencies, as opposed to DT rules of a rather flat hierarchy with many branches. Hence, we assume they are readable by a human with a basic logic programming background (still to be confirmed by future research)."}, {"title": "7 Conclusion", "content": "In this article, we have investigated the application of \u018fILP on fraud detection. Currently, the method seems insufficient for application in real-world scenarios; a key limitation is the usage of binary predicates, requiring the creation of the binary features from the numerical data with the help of other classification techniques. An additional overhead comes from the high complexity and memory consumption required to create predicates for the approach.\nRegarding RQ1, we have seen that training on a small part of the PaySim dataset, JILP cannot outperform the techniques used for data transformation to the Boolean format, required by \u018fILP. However, JILP showed the ability to provide a more explainable rule than the DT, when examining the size of the formula. Training of the full PaySim dataset was not possible due to the memory limitation, therefore it is not clear what would be the performance when trained on a larger training set (hence part of future research). Concerning RQ2, we have seen that this parameter can play the role of underfitting in the worst-case scenario as a rule will not cover all the relationships in the data. In addition, as shown in the case when applying a varying number of rules, the performance stayed the same when learning the DT dataset (5.2.7).\nFinally, with regards to RQ3, for more complicated scenarios that require building recursive rules, \u018fILP successfully provided explanatory rules to the dataset that the methods such as DT, or DSC by the definitions of the approaches, were not able to derive."}]}