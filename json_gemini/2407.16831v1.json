{"title": "Networks of Networks: Complexity Class Principles Applied to Compound AI Systems Design", "authors": ["Jared Quincy Davis", "Boris Hanin", "Lingjiao Chen", "Peter Bailis", "Ion Stoica", "Matei Zaharia"], "abstract": "As practitioners seek to surpass the current reliability and quality frontier of monolithic models, Compound AI Systems consisting of many language model inference calls are increasingly used. In this work, we construct systems, which we call Networks of Networks (NoNs) organized around the distinction between generating a proposed answer and verifying its correctness, a fundamental concept in complexity theory that we show empirically extends to Language Models (LMs). We introduce a verifier-based judge NoN with K generators, an instantiation of \"best-of-K\" or \"judge-based\" compound AI systems. Through experiments on synthetic tasks such as prime factorization, and core benchmarks such as the MMLU, we demonstrate notable performance gains. For instance, in factoring products of two 3-digit primes, a simple NoN improves accuracy from 3.7% to 36.6%. On MMLU, a verifier-based judge construction with only 3 generators boosts accuracy over individual GPT-4-Turbo calls by 2.8%. Our analysis reveals that these gains are most pronounced in domains where verification is notably easier than generation-a characterization which we believe subsumes many reasoning and procedural knowledge tasks, but doesn't often hold for factual and declarative knowledge-based settings. For mathematical and formal logic reasoning-based subjects of MMLU, we observe a 5-8% or higher gain, whilst no gain on others such as geography and religion. We provide key takeaways for ML practitioners, including the importance of considering verification complexity, the impact of witness format on verifiability, and a simple test to determine the potential benefit of this NoN approach for a given problem distribution. This work aims to inform future research and practice in the design of compound AI systems.", "sections": [{"title": "1 Introduction", "content": "In scenarios where practitioners are willing to expend a higher budget to go beyond the current reliability and quality frontier achievable via today's state-of-the-art monolithic models, Compound AI Systems consisting of many language model inference calls are increasingly employed Zaharia et al. [2024], Alp, Stechly et al. [2023], Chen et al. [2024], Valmeekam et al. [2023]. Implicitly or explicitly, we are often constructing networks of these calls: networks of networks, of sorts. This begs the question of what principles can guide the structure of the composition of these networks. As a central idea in this direction, we propose constructions organized around an explicit delineation between generation complexity and verification complexity. Correctly answering a question typically involves both generating a proposed answer and verifying that this answer is correct. This distinction between generation and verification is an organizing principle in complexity theory since, in many cases, the fastest algorithms for generation are more computationally expensive than generic algorithms for verification.\nThe key message of this article is that verification vs. generation complexity asymmetry notions continue to hold empirically when replacing tailored algorithms with Language Models (LMs). That this should be the case is not obvious, because it is far from clear what sorts of algorithms LMs use when asked to either generate or verify. We demonstrate our findings using a simple compound LM inference system that explicitly separates generation and verification calls. Specifically, we consider a compound AI system we term a verifier-based judge system with K generators, which works as follows:\n\u2022 A query/question q is fed independently into K language model calls, which can be different models or the same model K times (we typically use GPT-40 or GPT4-turbo). K is a hyper-parameter.\n\u2022 For k = 1,..., K the kth LM generator outputs Gk(q) = (\u03b1\u03ba, \u03c0\u03ba), where ak is the proposed answer and \u03c0\u03b5 is the proposed explanation for why this answer is correct.\n\u2022 Answer-explanation pairs (\u03b1\u03ba, \u03c0\u03ba) are provided one at a time to another LM, which acts as a verifier or judge. For each k = 1,..., K, the LM returns J(q, \u03b1\u03ba,\u03c0\u03ba) \u2208 {0,1}. An output of 1 means ak correctly answers the question q, given the explanation \u03c0\u03ba. If J(q, \u03b1\u03ba, \u03c0\u03ba) = 1, the answer ak is accepted and the algorithm terminates and returns ak.\n\u2022 If all answers are rejected, then a random answer is returned.\nNote that these verifier-based judges explicitly separate generation and verification. We find that they lead to notable performance gains on both synthetic and benchmark algorithmic reasoning tasks.\nFor example, we consider factoring an integer into a product of two primes. This is a canonical problem for which it is widely believed that generation is computationally expensive since it requires factoring, while verification is fast because it only involves multiplication. We find that individual calls to GPT-4o have a very low probability of correctly factoring even numbers p which are the product of 2 three digit integers (around 3.7%), while the same LM has approximately a 90% probability of correctly deciding whether a given factorization is valid. In particular, using a judge-based verifier system with K = 10 generators allows us to improve the performance from 3.7% to 36.6% (see Table 1). This matches almost exactly the probability of at least one generator proposing a correct factorization, as predicted by the our analysis in \u00a72.2.\nThis simple example suggests that when using compound systems made up of many calls to an LM it can be useful in problems with hard generation and relatively easy verification to invest more resources into generation than verification. This is precisely what is done in invoking chain of thought with Gemini Team et al. [2023] and in AlphaCode2 Li et al. [2022].\nTo further validate this beyond factorization tasks, we study the performance of verifier-based judge systems on MMLU Hendrycks et al. [2020]. We continue to find significant improvements in overall performance. Individual GPT-4-Turbo calls obtain an accuracy of 81.2%, but a verifier-based judge with K = 3 generators obtains 84% accuracy. The gains are magnified when broken down by topic, with subjects such as Abstract Algebra, Formal Logic, High School Math, and High School Physics-which arguably exhibit especially large gaps between the complexity of generation and verification-showing gains ranging from 6.35% to 8.76% (see Tables 3 and 4).\nBased upon our results, we encourage ML practitioners to Think about verification complexity. Some tasks will be more verifiable than others. Most traditional computing and software engineering tasks, in particular, possess this property. Our results suggest this asymmetry extends to LMs as well, when prompted to act as verifiers; however, you can also employ classical simulators, unit tests, or other components as verifiers in Compound AI Systems design. Also, note that given questions sampled from a distribution, there is a simple test for (i) whether the approach proposed in this paper will help for subsequent problems, as expressed in \u00a72.2, and (ii) to what extent.\nWe hope practitioners will find these discussions helpful in informing future research and practice in this emerging domain."}, {"title": "2 Verifier-Based Judges: Formalism and Analysis", "content": "In this section, we introduce verifier-based judges."}, {"title": "2.1 Construction", "content": "In this section, we introduce verifier-based judges.\nDefinition 1 (Verifier-Based Judge). A verifier-based judge J for a query q and K answer-witness\npairs (a, \u03c0) = ((a1, \u03c0\u2081),..., (\u03b1\u03ba,\u03c0\u03ba)) operates as follows:\nLet o be a random permutation of {1, . . ., K}. Then:\n\nJ(q, (\u03b1, \u03c0)) = \\begin{cases}\n\u03b1\u03c3(\u03af) & \\text{if } \\exists i \\leq K : V(q, \u03b1\u03c3(\u03af), \u03c0\u03c3(i)) = 1 \\\\\n        & \\text{and } \\forall j < i, V(q, \u03b1\u03c3(j), \u03c0\u03c3(j)) = 0\\\\\n        random a\u017c & \\text{if } i \\leq K, V(q, \u03b1\u03c3(\u03af), \u03c0\u03c3(i)) = 0\n\\end{cases}\n(1)\nNote that this is a version-zero construction without notions of verifier confidences. If no answer is\naccepted by the verifier, a random answer is returned. This is described in pseudo-code in Algorithm\n1.\nIntuitively, a single verifier-based judge operating over many generators should be effective when:\n(i) each generator individually exhibits moderate variance; (ii) different generators are not too cor-\nrelated; (iii) for a typical query, the probability a typical generator gives the correct answer is low;\n(iv) it is notably easier for the verifier to discern the correct answer-witness pair than it is for the\ngenerators to produce it. In other words, verification is easier than generation. Formally, this\nfinal statement corresponds to requiring for a correct answer-witness pair (a*, \u03c0*) that\nP(V(q, \u03b1*, \u03c0*) = 1) > P(G\u00bf(q) = (a*, \u03c0*)) for any generator Gi.\nWe make this precise in the following section."}, {"title": "2.2 Verifier-based Judge Performance Characterization", "content": "In this section, we determine analytically the performance of a verifier-based judge on a given query\nq with a unique correct answer a* in the simple case where we have access to K iid generators. Note\nthat this iid assumption won't strictly hold in practice in many cases, but empirical results concord\nwith this analysis well for the instance when generators are obtained by sampling with a fixed high\ntemperature and independent random seeds from the outputs of a given LM2. The performance of the\nverifier-based judge across a collection of queries is then simply obtained by averaging the results\nin this section over the query instance. We express our answers in terms of the three fundamental\nquantities:\nc := P (J(q, (\u03b1, \u03c0)) = 1 | a = a*)\ns := P (J(q, (\u03b1, \u03c0)) = 0 | a \u2260 a*)\nr(q) := P(G(q) = (a*, \u03c0) for some \u03c0).\nThese quantities are the analogs of classical PCP notions of completeness, soundness, and generation\ncomplexity that are ubiquitous in complexity theory (see e.g. Arora and Safra [1998])."}, {"title": "Theorem 1 (Verifier-Based Judge Performance).", "content": "Consider a verifier-based judge system with K iid\ngenerators, and fix a query q with a unique correct answer a*. We have\n\\mathbb{P}(J(q) = a*) = rc\\frac{1 \u2013 (1 \u2013 \u03b2) ^{K}}{\u03b2} + (1 \u2212 \u03b2) ^{K} \\frac{1}{|\\mathcal{A}|} \u03b2 := 1 \u2212 ((1 \u2013 c)r + s(1 - r)). (2)\nProof. We have\n\\mathbb{P} (verifier correct) = \u2211_{j=1}^{K} \\mathbb{P} (Gj correct and accepted, Gi rejected \u2200 i < j)\n+ \\mathbb{P}(G1,..., GK rejected, random answer correct)\n= \u2211_{j=1}^{K} \\mathbb{P} (Gj correct) \\mathbb{P} (Gj accepted | Gj correct) \u03a0_{i<j} \\mathbb{P} (Gi rejected)\n+ \u03a0_{i<j} \\mathbb{P} (G\u2081 rejected) \\frac{1}{|\\mathcal{A}|},\nwhere for the second equality we have used the independence between both generators and the\nverifier. Note that, by definition,\n\\mathbb{P} (Gj correct) \\mathbb{P} (Gj accepted | Gj correct) = rc, \\mathbb{P} (Gi rejected) = \u03b2.\nSumming on j = 1, ..., K completes the derivation.\nTo complete our analysis in this section, we seek to describe how much we expect to gain with a\nverifier-based judge above the natural baseline of using a single generator by computing the differ-\nence\nG(q, K) = \\mathbb{P}(J(q) = a*) \u2013 r(q)\nbetween the probability that a verifier-based judge returns the correct answer and the probability that\na single generator returns the correct answer."}, {"title": "Theorem 2 (Verifier-Based Judge Gain).", "content": "When the number of generators K goes to infinity, the gain\nof a verifier-based judge is positive if and only if:\nr\u22600,1 and c = \\mathbb{P} (J(\u03b1, \u03c0) = 1 | a = a*) > \\mathbb{P} (J(\u03b1, \u03c0) = 1 | a \u2260 a*) = 1 \u2212 s. (3)\nThe second condition is precisely the statement that the judge is more likely to accept a correct\nanswer than an incorrect answer.\nProof. Taking K\u2192\u221e in (2) gives\nlim_{K\u2192\u221e} [\\mathbb{P}(J(q) = a*)-r] = r(\\frac{c}{\u03b2}-1).\nNote that\nc = \\mathbb{P} (J(\u03b1, \u03c0) = 1 | a = a*)\n\u03b2 = \\mathbb{P} (J(\u03b1, \u03c0) = 1)\n= \\mathbb{P} (J(\u03b1, \u03c0) = 1 | a = a*) \\mathbb{P} (a = a*) + \\mathbb{P} (J(\u03b1, \u03c0) = 1 | a \u2260 a*) \\mathbb{P} (a \u2260 a*).\nHence,\nc > \u03b2  \\mathbb{P} (J(\u03b1, \u03c0) = 1 | a = a*) > \u03b2(J(\u03b1, \u03c0) = 1 | a \u2260 a*).\nas desired.\nThis theorem shows that verifier-based judge system confers a gain, at least with a large number of\ngenerators, as soon as it's completeness exceeds a threshold determined by its soundness. Moreover,\nthe extent of this gain is proportional to the query difficulty.\nOur analysis also reveals the diminishing returns of increasing the ensemble size K. While larger\nensembles generally improve performance, the marginal benefit decreases, suggesting an optimal"}, {"title": "3 Experiments", "content": "In this section we present the two kinds of experiments discussed in the Introduction. First, in\n\u00a73.1, we detail experiments using LMs for prime factorization. Then, in \u00a73.3, we break down our\nexperiments on MMLU."}, {"title": "3.1 Prime Factorization", "content": "As an example problem to demonstrate that sometimes verification is easier than generation for LMs,\nwe invoke and probe the classic problem of prime factorization.\nThe prime factorization problem is core to cryptography and foundational algorithms like RSA\n[Rivest et al., 1978]. It turns out it is very laborious to factor a number that is a product of two\nlarge primes into the constituent primes; however, it is relatively easy to multiply two primes. Thus,\nif I have two candidate constituent primes, it can be easy and relatively quick to multiply them to\ntest if they constitute a valid factorization.\nBuilding on this intuition, we conjectured that a simple verifier-based judge system could outper-\nform a baseline of single LM calls. To understand this, we first implemented two components:\n\u2022 Generators tasked with factorization.\n\u2022 Verifiers tasked with assessing a factorization and deeming it correct or incorrect.\nWe started off using GPT-40 and asking it to help us factor numbers that are a product of two 3-digit\nprimes. This yielded a 3.70% success rate for the generators. For the verifier task of assessing a\nfactorization as correct or incorrect, a GPT-40-based verifier was able to correctly classify a proposed\nfactorization 90.11% of the time. Moreover, these results were well calibrated as excited by the\ncompleteness and soundness of the verifier, which intuitively correspond to the true positive and\ntrue negative rates.\nThese initial results convinced us to compose these components into a verifier-based judge system.\nBased on those results, the baseline GPT-40 in this case model achieved the 3.7% on up-to-3 digit\nfactorization and a verifier-based judge system with K = 10 generators achieved 36.6%3."}, {"title": "3.2 Lottery Ticket Problem", "content": "As another sub-experiment, we looked at a problem we viewed as classically non-verifiable, which\nwe call the lottery ticket problem. In this problem, we have an oracle that picks a number within\nsome range (0 and 100, for example). The task of the generator models is to guess the number. We\nthen give the N guesses from the generators to the judge model and asks it to, optionally considering\nthe guesses from the generators (\"advisors\") guess the oracle's number. As one might expect, a\nverifier-based judge confers no advantage in this case and success is roughly 1/N regardless."}, {"title": "3.3 MMLU", "content": "Beyond these specific examples, we also ran probes on the Massive Multitask Language Understand-\ning (MMLU) benchmark [Hendrycks et al., 2020].\nOn the MMLU, we ran a baseline model of just gpt-4-1106-preview with temperature 1.0. We\nexplored a number of temperatures in early probing and observed no clear performance gain pattern."}, {"title": "4 Related Work", "content": "The concept of composing multiple calls to models to improve performance has been implicitly\ninvoked repeatedly in recent months. The Gemini Technical Report employed a novel scheme at\ninference time, termed CoT@32, as opposed to the default 5-shot prompting invocation scheme\nTeam et al. [2023]. DeepMind's AlphaCode 2, in order to go \"beyond the capabilities of existing AI\nsystems,\" employed a method that uses large-scale transformers to generate \"up to a million code\nsamples per problem\" and then filters down the set to converge to a solution. Li et al. [2022]. N-\nshot prompting itself implicitly is a systems approach in that it often elicits longer (and thus higher\nlatency / costlier) responses from models but can result in improved performance. Wei et al. [2022].\nChen et al. [2024], Li et al. [2024] probed how calling an LLM many times can improve or degrade\nperformance on a task set, depending on the distribution of query difficulty in the set. Numerous\nother recent works have explored iteratively chaining self-improvement calls Madaan et al. [2024],\nWang et al. [2024], Valmeekam et al. [2023], Stechly et al. [2023],\nThese self-improvement or ensemble systems can perhaps be unified and viewed through a single\nframework as wide or deep networks (or meshes) of calls to a given model or a cross a set of models\nand modules."}, {"title": "Self-Verification and Collections of Model Calls", "content": "Stechly et al. [2023], Valmeekam et al. [2023]\ncalled into question claims that models can self-critique and iteratively self-refine [Madaan et al.,\n2024] their solutions when invoked in deep chains of calls. Stechly et al. [2023] evaluated iterative\nself-improvement claims over a suite of graph coloring problems and found that GPT4 achieves sub\n20% accuracy; however, perhaps most surprisingly, they found the accuracy diminished in \"self-\ncritiquing mode.\" Their work explained this by noting that even when GPT4 can guess a valid\ncoloring by chance, its self-critiquing might lead to degradation in performance. This is congruent\nwith results in Chen et al. [2024], which notes that making more calls to what it called voting-based\nLLM systems (ensembles with a voting-based aggregation function) can diminish performance for\n\"hard\" queries due to a sort of variance-reduction that hurts questions where the likelihood of a\ncorrect answer is <50% since the model might otherwise have \"gotten lucky\". Conversely, other\nrecent works like Li et al. [2024], Madaan et al. [2024] also explored calling models in structured\nforms and demonstrated that this could lead to performance gain, even showing that systems consist-\ning of weak LLMs can surpass the performance of the best individual LLM in social conversation\nsettings Wang et al. [2024].\nThese seemingly disparate results can be reconciled, perhaps. Stechly et al. [2023],\nValmeekam et al. [2023], suggest that when an \"externally sound verifier\" module is leveraged, \"try\nagain\" systems methods can induce performance gains. This suggests that networks of calls can\nengender gains, but only under certain conditions.\nWe hope that our study and the discussion of the concept of verifiability complexity can shine a light\non some of those conditions."}, {"title": "Classical complexity notions of verification and generation.", "content": "Comparison of verification and\ngeneration has been extensively studied via the lens of the classic computational complex-\nity Papadimitriou [2003], Courcoubetis and Yannakakis [1995], Clarke [1997]. In fact, one of the\nmost popular classes of problems, NP problems, are those whose solutions can be verified in poly-\nnomial time. Pioneering theoretical computer science (TCS) work Courcoubetis and Yannakakis\n[1995] places deep emphasis on understanding how verification can be leveraged to provably gener-\nate (approximately) high-quality solutions to hard problems. In the context of LMs, however, it is\nunclear which \u201calgorithm\u201d an LLM uses and thus which \u201ccomplexity\" it incurs to solve a problem.\nThis paper, though, demonstrates that the notion of verification and generation complexity can still\napply to LMs, and can be leveraged to inform the design of compound LLM systems."}, {"title": "5 Conclusion and Future Work", "content": "Here we motivate the consideration of complexity class principles in Compound AI Systems design.\nWe argue that LM practitioners should consider, measure, and build around the potential verification\nvs. generation difficulty asymmetry in their domain of interest."}]}