{"title": "3D Geometric Shape Assembly via Efficient Point Cloud Matching", "authors": ["Nahyuk Lee", "Juhong Min", "Junha Lee", "Seungwook Kim", "Kanghee Lee", "Jaesik Park", "Minsu Cho"], "abstract": "Learning to assemble geometric shapes into a larger target structure is a pivotal task in various practical applications. In this work, we tackle this problem by establishing local correspondences between point clouds of part shapes in both coarse- and fine-levels. To this end, we introduce Proxy Match Transform (PMT), an approximate high-order feature transform layer that enables reliable matching between mating surfaces of parts while incurring low costs in memory and computation. Building upon PMT, we introduce a new framework, dubbed Proxy Match TransformeR (PMTR), for the geometric assembly task. We evaluate the proposed PMTR on the large-scale 3D geometric shape assembly benchmark dataset of Breaking Bad and demonstrate its superior performance and efficiency compared to state-of-the-art methods.", "sections": [{"title": "1. Introduction", "content": "Shape assembly aims to determine the precise placement of each constituent part and construct a larger target shape as a whole. This task holds paramount significance, especially in the context of various applications encompassing robotics (Wang & Hauser, 2019; Zakka et al., 2020; Zeng et al., 2021), manufacturing (Tian et al., 2022), computer graphics (Li et al., 2012), and computer-aided design (Chen et al., 2015; Jacobson, 2017). Despite its pivotal role in industrial productivity and the plethora of applications, the field of shape assembly remains relatively underexplored in the literature due to the intricate challenge it presents: demands a comprehensive understanding of geometric structures and analyses of pairwise relationships between local surfaces of input parts to establish accurate assembly.\nThere have been several recent attempts (Schor et al., 2019; Li et al., 2020a; Wu et al., 2020; Li et al., 2020b; Huang et al., 2020; Narayan et al., 2022; Chen et al., 2022; Wu et al., 2023b) to address the task of shape assembly, but these methods fall short of achieving accurate assembly. They typically represent each part as a global embedding and perform regression to predict a placement for each part. The global encoding strategy for each part, while simplifying the process, greatly limits local information by collapsing spatial resolutions, which is necessary to localize the mating surface. Indeed, accurate shape assembly requires a detailed analysis of both fine- and coarse-level spatial information of the parts in recognizing mating surfaces and establishing correspondences between the surfaces. Therefore, a promising approach would be to retain the spatially rich part representations during the encoding phase and analyze pairwise local correspondence relationships between them for reliable localization and matching of mating surfaces.\nIn the realm of correspondence analysis within image matching, prior methods (Rocco et al., 2018; Min & Cho, 2021; Kim et al., 2022; Min et al., 2021; Rocco et al., 2020) typically utilize a high-order feature transform, i.e., high-dimensional convolution or attention, to achieve the objectives of localizing relevant instances and establishing correspondences between them. The high-order feature transforms, which assess structural patterns of correlations in high-dimensional spaces, have been empirically validated for their efficacy in identifying accurate visual matches. However, the quadratic complexity with respect to input spatial resolution still remains as a significant drawback, limiting their application to only low-resolution (coarse-grained) inputs. Such a limitation becomes particularly problematic in the context of geometric assembly since meticulous alignment between parts requires analyzing high-resolution (fine-grained) to precisely identify 'geometric compatibility' between mating surfaces to match.\nIn this paper, we address this issue by introducing a new form of low-complexity high-order feature transform layer, dubbed Proxy Match Transform (PMT), to tackle the challenges of geometric shape assembly. The layer is designed"}, {"title": "2. Related Work", "content": "3D shape assembly & registration. Previous research in generative models for 3D objects has primarily focused on building objects through the combination of basic 3D primitives. A prevalent approach trains specialized models tailored to individual object classes, enabling the assembly of objects from volumetric primitives such as cuboids (Tulsiani et al., 2017). In contrast, Khan et al. (2019) proposes a unified model that can generate cuboid primitives in various classes. Additionally, variational autoencoders (VAEs) have been employed to model objects as compositions of cuboids, offering robust abstractions that distill local geometric details and elucidate object correspondences (Kingma & Welling, 2014; Jones et al., 2020).\nParallel to these developments, research in the part assembly has aimed to construct complete objects from predefined semantic parts. The method of Li et al. (2020b) predicts translations and rotations for part point clouds to assemble a target object from an image reference. Extending this, Narayan et al. (2022); Huang et al. (2020) have conceptualized part assembly as a graph learning challenge, utilizing iterative message passing techniques to integrate parts into cohesive objects. These approaches heavily rely on the PartNet dataset (Mo et al., 2019) to ensure semantic correspondence between the assembled parts and the target models, demonstrating that while geometric shapes are foundational, semantic cues can significantly guide and streamline the assembly process. Our research diverges from these methods by focusing on the assembly of parts without predefined semantics. A closely related methodology is that of Chen et al. (2022), which also tackles the problem of 3D shape assembly by integrating implicit shape reconstruction, providing a relevant benchmark.\nAdditionally, the concept of 3D shape assembly overlaps with the domain of 3D registration, especially in scenarios characterized by low overlap between a pair of point clouds. Techniques such as those proposed by Huang et al. (2021) and Yu et al. (2021) leverage self-attention and cross-attention mechanisms within and across point cloud features to transform 3D features, facilitating enhanced matching accuracy. Qin et al. (2022) further advances this by mapping transformation-invariant data to the positional embeddings of transformer layers, optimizing the matching process in low-overlap conditions. Despite their efficacy, the practical application of these methods in fine-grained matching scenarios is often constrained by the quadratic complexity associated with their matching layers, highlighting a critical area for improvement in computational efficiency and scalability. Our work addresses these challenges by proposing a novel approach that optimizes the computational demands of feature matching while maintaining high robustness.\nHigh-order feature transform for matching. High-order feature transforms are essential in (both image and point cloud) matching tasks, helping to establish consensus among correspondences within a high-dimensional space. Initially introduced by Rocco et al. (2018), the concept of a learning-based neighborhood consensus supports the identification of accurate matches by leveraging neighboring ambiguous matches between 2D images. This approach has also been adapted for 3D registration tasks, notably by Choy et al. (2020), who utilized a 6D sparse convolutional layer to filter out outlier correspondences. Given the high computational complexity associated with high-order feature transforms, several studies have proposed methods to reduce this burden. Techniques such as decomposing high-dimensional convolutional kernels (Min et al., 2021) and sparsifying the correlation map with top-k scores (Rocco et al., 2020) have been effective. Further, Shi et al. (2023) enhanced matching efficiency by creating a sparse correlation matrix through the grouping of input tokens, significantly reducing the number of tokens involved. More recent advances have integrated the self-attention mechanism to utilize global feature consensus effectively, although these methodologies, proposed by Cho et al. (2021) and Kim et al. (2022), come at a higher computational cost."}, {"title": "3. Proposed Approach", "content": "In the task of geometric shape assembly, analyzing geometric compatibility between fractured shapes is of utmost importance; the geometric properties of the mating surfaces should exhibit consistency, where vertices, edges, and surfaces seamlessly fit together to form a coherent structure. To achieve reliable localization of mating surfaces between shapes, a model needs to analyze the compatibility of all possible feature correspondences and accurately identify spatially consistent matches. In the field of visual matching and its applications (Rocco et al., 2018; Choy et al., 2020; Min & Cho, 2021; Cho et al., 2021; Min et al., 2021), a trending approach for assessing match reliability is the utilization of high-order feature transform, e.g., convolution or self-attention. This technique effectively assesses patterns within neighborhood matches in a differentiable manner. Building upon these principles, we will now explore the theoretical formulation of high-order transform, with a specific emphasis on its application for enhancing pairwise feature correlation.\nPreliminary. High-order convolution (Rocco et al., 2018; Choy et al., 2020; Min & Cho, 2021) generalizes the standard convolution by taking as input more functions, feature maps, or sets. In the context of our problem, we consider two point clouds $X = \\{x_i \\in \\mathbb{R}^3\\}_{i=1}^{|X|}$ and $Y = \\{y_i \\in \\mathbb{R}^3\\}_{i=1}^{|Y|}$, and focus on the 2nd-order convolution with two sets of features $F_x$ and $F_y$, associated with the two point clouds, respectively. For ease of notation, we represent these features in matrix form, i.e., $F_x \\in \\mathbb{R}^{|X| \\times D_{emb}}$, where $D_{emb}$ is the feature embedding dimension, and indexes each feature embedding using its associated point $x \\in X$ such that $(F_x)_x \\in \\mathbb{R}^{D_{emb}}$, and same goes for $F_y$. We also express the feature correlation of two points from each point cloud, $x$ and $y$, as $C(x,y) := (F_x)_x \\cdot (F_y)_y^\\top \\in \\mathbb{R}$. The 2nd-order convolution on $(F_x, F_y)$ with kernel $K$ is then defined as:\nConv(Fx, Fy)(x,y) := \u03a3 (n,m)\u2208N(x)\u00d7N(y) C(n,m)K([n \u2013 x, m - y]), (1)\nwhere N(\u00b7) represents a set of neighbor points and $K: \\mathbb{R}^6 \\rightarrow \\mathbb{R}$ is a convolutional kernel, represented as a mapping function that takes a displacement vector onto learnable weight scalar.\nBuilding upon insights from the work of Cordonnier et al. (2020), we consider Lemma 1 which states that the conv layer in Eq. 1 can be re-formulated as a form of multi-head self-attention under sufficient conditions:\nLemma 1. Consider a bijective mapping of natural numbers, i.e., heads, onto 6-dimensional local displacements: t(h) : [Nh] \u2192 \u2206(x,y). Let A(h) \u2208 R|x||Y|\u00d7|x||Y| be an"}, {"title": "3.1. Proxy Match Transform: an efficient high-order feature transform with sub-quadratic complexity", "content": "To overcome the limitation, we introduce an efficient feature matching layer, dubbed Proxy Match Transform, which approximates high-order convolution with sub-quadratic complexity. Given a pair of features ($F_x, F_y$) as inputs, PMT layers with Nh heads\u00b9 are defined as follows:\nPMT(Fx) := \u03a3 h\u2208 [Nh] A (h) FxP(h)Tw(h), (4)\nPMT (F) := \u2211 h\u2208[Nh] ApFyP(h)Twp), (5)\nwhere $w_x^{(h)} \\in \\mathbb{R}$ is a learnable weight scalar, $A_x^{(h)} \\in \\mathbb{R}^{|X| \\times |X|}$ is local attention matrix\u00b2, and $P^{(h)} \\in \\mathbb{R}^{D_{proxy} \\times D_{emb}}$ is proxy tensor that satisfies the following:\np(i) Tp(j) = {IDemb, IDemb, if i = j 0, otherwise. (6)\n(h)\nAt each head, the layer initially constructs a correlation between the input feature $F_x$ and the proxy tensor $P^{(h)}$ such that $C_x^{(h)} := F_xP^{(h)T}$ in much smaller size of $|X| \\times D_{proxy}$, compared to the pairwise feature correlation $C = F_xF_y^\\top \\in \\mathbb{R}^{|X| \\times |Y|}$ as defined in Eq. 1. After applying learnable weight $w_x^{(h)}$, the output at position $(n,m) \\in \\mathbb{X} \\times D_{proxy}$ is computed through a weighted-sum of its neighborhood matches lying on the spatial dimension of feature map $F_x$, e.g., $\\{(n', m)\\}_{n'\\in N(n)}$ where $|N(n)| = \\epsilon < |X|$. To formally put, the Proxy Match Transform output at head h given input Fx at position (n, m) is defined as\nPMT(FX)(mm) = A) (n:) FxP(h) (:,m) wp)\n(h)\n= \u03a3n'\u2208N(n) A(n) C) (n.m) Wp). (7)\n(h)\n(h)\nPMT(Fy)(h) is similarly defined with a different set of parameters of A) and w). It is important to note that the PMT layers perform two independent transforms for feature matching, one for Fx and the other for Fy. Despite the independence, matching between the feature pair is effectively facilitated by a shared proxy tensor P. This proxy tensor allows for the exchange of information between the features, eliminating the need to construct and convolve memory-intensive pairwise feature correlations, which often contain sparse and limited informative match scores. We demonstrate how the PMT effectively approximates existing high-order convolution in Sec. 3.2 and empirically prove the efficacy of the use of proxy tensor and different parameter sets in geometric shape assembly in Sec. 4.4."}, {"title": "3.2. Constraints for Proxy Match Transform", "content": "For the Proxy Match Transforms to express the high-order convolution, we assume the following constraints, (i) orthonormality constraint: $P^{(i)T}P^{(i)} = I_{D_{emb}}$ if i = j, and (ii) zero-matrix constraint: $P^{(i)T}P^{(j)} = 0\\in \\mathbb{R}^{D_{emb}\\times D_{emb}}$ otherwise for all i,j\u2208 [Nh]. Under such conditions, a dot product between two Proxy Match Transforms can effectively approximate high-order convolution. Our main theoretical result is provided below.\nTheorem 1. If we assume $P^{(i)T}P^{(j)} = I_{D_{emb}}$ if i = j and $P^{(i)T}P^{(j)} = 0$ otherwise for all i, j \u2208 [Nh], and define"}, {"title": "3.3. Overall architecture", "content": "The proposed architecture, dubbed Proxy Match TransformeR (PMTR) comprises four main parts: (1) feature extraction, (2) coarse-level matching, (3) fine-level matching, and (4) transformation prediction & training objectives. As illustrated in Fig. 2, our pipeline begins with the point cloud pair embedding. The feature extraction network generates three pairs of features, each at distinct spatial resolutions. These feature pairs are subsequently fed to a corresponding PMT layer, which facilitates both coarse-level matching (for mating surface localization) and fine-level matching (for geometric matching). The outputs from the coarse matching phase are utilized to establish a preliminary correspondence between the mating surfaces of the input parts, which is crucial for identifying potential areas of alignment. Subsequently, the fine matching phase is designed to refine these correspondences, focusing exclusively on reliable matches identified during the coarse matching stage. This allows for precise correspondence establishment, ensuring accurate assembly as demonstrated by our experiments in Sec. 4.4.\nFeature extraction. A pair of point clouds to match is fed to a feature embedding network, reducing their spatial resolution to provide a coarse-level feature pair. Each of the two subsequent upsampling layers connected in series provides features in a higher resolution. From this U-Net-shaped architecture, similar to KPConv-FPN (Thomas et al., 2019), the model gives three pairs of point cloud features with different spatial resolutions: $\\{(F_{x_n}, F_{y_n})\\}_{n=1}^3$ where $F_{x_n} \\in \\mathbb{R}^{|X_n| \\times D_{n-emb}}$ with $|X_1| < |X_2| < |X_3|$, which implies that $F_{x_1}$ is the coarse feature with the smallest number of features. $\\{V_n\\}_{n=1}^3$ is similarly defined. The coarse feature pair $\\{(F_{x_1}, F_{y_1})\\}$ is used to identify potential mating surfaces to match, while the others $\\{(F_{x_n}, F_{y_n})\\}_{n=2}^3$ are used to precisely align the identified potential surface matches.\nCoarse-level matching. At this stage, PMT processes the coarse feature pair $\\{(F_{x_1}, F_{y_1})\\}$, in order to evaluate the potential local correspondence between the feature set. This is achieved without directly computing the pairwise correlation matrix $F_{x_1} F_{y_1}^\\top$, which would otherwise result in a quadratic dimensionality of $\\mathbb{R}^{|X_1| \\times |Y_1|}$. Instead, a pair of PMTs operates in a manner that allows them to be refined independently to provide two refined coarse-level features $(F_{x_c}, F_{y_c})$ as follows:\nPMT(Fx\u2081) = Fx, PMT(Fy\u2081) = Fy.. (10)\nDespite this independence, the transformations ensure that the dot product of the refined features closely approximates the output of a high-order feature transformation. The ap-"}, {"title": "4. Experiments", "content": "In this section, we discuss the dataset and evaluation metrics used (Sec. 4.1), implementation details (Sec. 4.2), the results of pairwise shape assembly with comprehensive analysis (Sec. 4.3), an in-depth ablation study to inspect the efficacy of the proposed techniques (Sec. 4.4), and extension of our evaluation to the task of multi-part assembly (Sec. 4.5).\n4.1. Dataset and Evaluation Metrics\nDataset. In our experiments, we utilize the Breaking Bad dataset (Sell\u00e1n et al., 2022), a large-scale dataset of fractured objects for the task of geometric shape assembly, which consists of over 1 million fractured objects simulated from 10K meshes of PartNet (Mo et al., 2019) and Thingi10k (Zhou & Jacobson, 2016). For pairwise assembly training and evaluation, we exclusively select a subset of the Breaking Bad dataset that contains two-part objects (Sect. 4.3). For multi-part assembly, we expand our evaluation to include all samples in the dataset, encompassing objects with 2 to 20 parts (Sec. 4.5).\nEvaluation metrics. Following the evaluation protocol of Sell\u00e1n et al. (2022), we measure the root mean square error (RMSE) between the ground-truth and predicted rotation (R) and translation (T) parameters, and the Chamfer distance (CD) between the assembly results and ground-truth. In addition, we introduce and report a new metric, called CoRrespondence Distance (CRD), which is defined as the Frobenius norm between the input pair of the assembled point cloud; unlike CD, CRD offers a more comprehensive measure of correspondence, capturing both proximity and structural alignment between the assembled objects. We compute the evaluation metrics of RMSE (R) and RMSE (T) based on relative transformation, e.g., rotation and translation, between the input fracture pair, instead of the absolute pose as in the previous literature (Chen et al., 2022; Wu et al., 2023b) by setting the largest fracture as an anchor and computing the relative transformation. The formal definitions of the evaluation metrics can be found in the Appendix D."}, {"title": "5. Scope and Limitations", "content": "Despite the advances in efficient point cloud matching and shape assembly, our method still faces several limitations. First, the accuracy of our method can be compromised in scenarios with extremely low overlap between point clouds, which can hinder the identification of reliable correspondences. Second, our method, like many others in the field, requires extensive training on domain-specific datasets to achieve optimal performance. Third, while our experiments demonstrate the efficacy of PMT in shape assembly tasks, it has not been extensively tested across other potential applications such as robotics, manufacturing, digital artistry, or even restoration of ancient artifacts via more accurate and detailed part assembly. Thus, the applicability of our approach beyond geometric shape assembly remains to be fully validated. We leave this to future work."}, {"title": "6. Conclusion", "content": "We have introduced a low-complexity, high-order feature transform layer, Proxy Match Transform, designed for efficient approximation of traditional compute-intensive high-order feature transforms. The significant performance improvements over the state of the arts with a lower computational cost indicate its real-world applicability from artifact reconstruction to manufacturing. Although the proposed method has been applied exclusively to geometric shape assembly in this work, its significant improvements in various evaluation metrics reveal its potential for broad applications."}, {"title": "A. Theoretical Analysis of Proxy Match Transform", "content": "We now derive sufficient conditions such that Proxy Match Transform can express high-dimensional convolution. Our main theoretical result is given below.\nTheorem 1. If we assume $P^{(i)T}P^{(j)} = I_{D_{emb}}$ if i = j and $P^{(i)T}P^{(j)} = 0$ otherwise for all i, j \u2208 [Nh], and define\nand $w^{(h)} := w_x^{(h)} w_y^{(h)}$, then, the dot-product of Proxy Match Transform outputs\nwith a sufficient number of heads N\u0127 can express high-dimensional convolutional layer with kernel $K : \\mathbb{R}^6 \\rightarrow \\mathbb{R}$: PMT(Fx) \u00b7 PMT(Fy)T = Conv(Fx, Fy).\nProof. We first take the dot-product of Proxy Match Transform outputs and simplify:\nPMT(Fx) \u00b7 PMT(Fy)\n= \u03a3A FxP(h)Tw(h)h\u2208 [Nh] \u03a3AyFyP(h)Tw(h)h\u2208 [Nh]T\n= \u03a3(i,j)\u2208[Nh]2 wAFxP(1) TP(i) FYTAwT)\n= \u03a3(i,j)\u2208[Nh]2 8(i, j) (WAFxFyTAw)\n= \u03a3h\u2208[Nh] wAFxFyTAw,\nwhere d(i, j) provides 1 if i = j and 0 otherwise. Using definitions of A(h) \u2208 R|x||Y|\u00d7|x||V| and w(h) \u2208 R, the output at a specific position (x, y) \u2208 R6 is as follows:\nTAw\n\u03a3h\u2208[Nh] (n,m)\u2208Xxy (T\n(PMT(Fx) \u00b7 PMT(Fy)) (x,y) = \u03a3h\u2208[Nh] AxwxAxFn:\n= \u03a3h\u2208[Nh] \u03a3(n,m)\u2208xxy A A (x.n) Fx (n,:) FyT A"}]}