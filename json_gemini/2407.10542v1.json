{"title": "3D Geometric Shape Assembly via Efficient Point Cloud Matching", "authors": ["Nahyuk Lee", "Juhong Min", "Junha Lee", "Seungwook Kim", "Kanghee Lee", "Jaesik Park", "Minsu Cho"], "abstract": "Learning to assemble geometric shapes into a larger target structure is a pivotal task in various practical applications. In this work, we tackle this problem by establishing local correspondences between point clouds of part shapes in both coarse- and fine-levels. To this end, we introduce Proxy Match Transform (PMT), an approximate high-order feature transform layer that enables reliable matching between mating surfaces of parts while incurring low costs in memory and computation. Building upon PMT, we introduce a new framework, dubbed Proxy Match TransformeR (PMTR), for the geometric assembly task. We evaluate the proposed PMTR on the large-scale 3D geometric shape assembly benchmark dataset of Breaking Bad and demonstrate its superior performance and efficiency compared to state-of-the-art methods.", "sections": [{"title": "1. Introduction", "content": "Shape assembly aims to determine the precise placement of each constituent part and construct a larger target shape as a whole. This task holds paramount significance, especially in the context of various applications encompassing robotics (Wang & Hauser, 2019; Zakka et al., 2020; Zeng et al., 2021), manufacturing (Tian et al., 2022), computer graphics (Li et al., 2012), and computer-aided design (Chen et al., 2015; Jacobson, 2017). Despite its pivotal role in industrial productivity and the plethora of applications, the field of shape assembly remains relatively underexplored in the literature due to the intricate challenge it presents: demands a comprehensive understanding of geometric structures and analyses of pairwise relationships between local surfaces of input parts to establish accurate assembly.\nThere have been several recent attempts (Schor et al., 2019; Li et al., 2020a; Wu et al., 2020; Li et al., 2020b; Huang et al., 2020; Narayan et al., 2022; Chen et al., 2022; Wu et al., 2023b) to address the task of shape assembly, but these methods fall short of achieving accurate assembly. They typically represent each part as a global embedding and perform regression to predict a placement for each part. The global encoding strategy for each part, while simplifying the process, greatly limits local information by collapsing spatial resolutions, which is necessary to localize the mating surface. Indeed, accurate shape assembly requires a detailed analysis of both fine- and coarse-level spatial information of the parts in recognizing mating surfaces and establishing correspondences between the surfaces. Therefore, a promising approach would be to retain the spatially rich part representations during the encoding phase and analyze pairwise local correspondence relationships between them for reliable localization and matching of mating surfaces.\nIn the realm of correspondence analysis within image matching, prior methods (Rocco et al., 2018; Min & Cho, 2021; Kim et al., 2022; Min et al., 2021; Rocco et al., 2020) typically utilize a high-order feature transform, i.e., high-dimensional convolution or attention, to achieve the objectives of localizing relevant instances and establishing correspondences between them. The high-order feature transforms, which assess structural patterns of correlations in high-dimensional spaces, have been empirically validated for their efficacy in identifying accurate visual matches. However, the quadratic complexity with respect to input spatial resolution still remains as a significant drawback, limiting their application to only low-resolution (coarse-grained) inputs. Such a limitation becomes particularly problematic in the context of geometric assembly since meticulous alignment between parts requires analyzing high-resolution (fine-grained) to precisely identify 'geometric compatibility' between mating surfaces to match.\nIn this paper, we address this issue by introducing a new form of low-complexity high-order feature transform layer, dubbed Proxy Match Transform (PMT), to tackle the challenges of geometric shape assembly. The layer is designed"}, {"title": "2. Related Work", "content": "3D shape assembly & registration. Previous research in generative models for 3D objects has primarily focused on building objects through the combination of basic 3D primitives. A prevalent approach trains specialized models tailored to individual object classes, enabling the assembly of objects from volumetric primitives such as cuboids (Tulsiani et al., 2017). In contrast, Khan et al. (2019) proposes a unified model that can generate cuboid primitives in various classes. Additionally, variational autoencoders (VAEs) have been employed to model objects as compositions of cuboids, offering robust abstractions that distill local geometric details and elucidate object correspondences (Kingma & Welling, 2014; Jones et al., 2020).\nParallel to these developments, research in the part assembly has aimed to construct complete objects from predefined semantic parts. The method of Li et al. (2020b) predicts translations and rotations for part point clouds to assemble a target object from an image reference. Extending this, Narayan et al. (2022); Huang et al. (2020) have conceptualized part assembly as a graph learning challenge, utilizing iterative message passing techniques to integrate parts into cohesive objects. These approaches heavily rely on the PartNet dataset (Mo et al., 2019) to ensure semantic correspondence between the assembled parts and the target models, demonstrating that while geometric shapes are foundational, semantic cues can significantly guide and streamline the assembly process. Our research diverges from these methods by focusing on the assembly of parts without predefined semantics. A closely related methodology is that of Chen et al. (2022), which also tackles the problem of 3D shape assembly by integrating implicit shape reconstruction, providing a relevant benchmark.\nAdditionally, the concept of 3D shape assembly overlaps with the domain of 3D registration, especially in scenarios characterized by low overlap between a pair of point clouds. Techniques such as those proposed by Huang et al. (2021) and Yu et al. (2021) leverage self-attention and cross-attention mechanisms within and across point cloud features to transform 3D features, facilitating enhanced matching accuracy. Qin et al. (2022) further advances this by mapping transformation-invariant data to the positional embeddings of transformer layers, optimizing the matching process in low-overlap conditions. Despite their efficacy, the practical application of these methods in fine-grained matching scenarios is often constrained by the quadratic complexity associated with their matching layers, highlighting a critical area for improvement in computational efficiency and scalability. Our work addresses these challenges by proposing a novel approach that optimizes the computational demands of feature matching while maintaining high robustness.\nHigh-order feature transform for matching. High-order feature transforms are essential in (both image and point cloud) matching tasks, helping to establish consensus among correspondences within a high-dimensional space. Initially introduced by Rocco et al. (2018), the concept of a learning-based neighborhood consensus supports the identification of accurate matches by leveraging neighboring ambiguous matches between 2D images. This approach has also been adapted for 3D registration tasks, notably by Choy et al. (2020), who utilized a 6D sparse convolutional layer to filter out outlier correspondences. Given the high computational complexity associated with high-order feature transforms, several studies have proposed methods to reduce this burden. Techniques such as decomposing high-dimensional convolutional kernels (Min et al., 2021) and sparsifying the correlation map with top-k scores (Rocco et al., 2020) have been effective. Further, Shi et al. (2023) enhanced matching efficiency by creating a sparse correlation matrix through the grouping of input tokens, significantly reducing the number of tokens involved. More recent advances have integrated the self-attention mechanism to utilize global feature consensus effectively, although these methodologies, proposed by Cho et al. (2021) and Kim et al. (2022), come at a higher computational cost."}, {"title": "3. Proposed Approach", "content": "In the task of geometric shape assembly, analyzing geometric compatibility between fractured shapes is of utmost importance; the geometric properties of the mating surfaces should exhibit consistency, where vertices, edges, and surfaces seamlessly fit together to form a coherent structure. To achieve reliable localization of mating surfaces between shapes, a model needs to analyze the compatibility of all possible feature correspondences and accurately identify spatially consistent matches. In the field of visual matching and its applications (Rocco et al., 2018; Choy et al., 2020; Min & Cho, 2021; Cho et al., 2021; Min et al., 2021), a trending approach for assessing match reliability is the utilization of high-order feature transform, e.g., convolution or self-attention. This technique effectively assesses patterns within neighborhood matches in a differentiable manner. Building upon these principles, we will now explore the theoretical formulation of high-order transform, with a specific emphasis on its application for enhancing pairwise feature correlation.\nPreliminary. High-order convolution (Rocco et al., 2018; Choy et al., 2020; Min & Cho, 2021) generalizes the standard convolution by taking as input more functions, feature maps, or sets. In the context of our problem, we consider two point clouds $X = {x_i \\in \\mathbb{R}^3}_{i=1}^{|X|}$ and $Y = {y_i \\in \\mathbb{R}^3}_{i=1}^{|Y|}$, and focus on the 2nd-order convolution with two sets of features $F_x$ and $F_y$, associated with the two point clouds, respectively. For ease of notation, we represent these features in matrix form, i.e., $F_x \\in \\mathbb{R}^{|X| \\times D_{emb}}$, where $D_{emb}$ is the feature embedding dimension, and indexes each feature embedding using its associated point $x \\in X$ such that $(F_x)_x \\in \\mathbb{R}^{D_{emb}}$, and same goes for $F_y$. We also express the feature correlation of two points from each point cloud, $x$ and $y$, as $C(x,y) := (F_x)_x \\cdot (F_y)_y \\in \\mathbb{R}$. The 2nd-order convolution on $(F_x, F_y)$ with kernel $K$ is then defined as:\n$\\textrm{Conv}(F_x, F_y)(x,y) := \\sum_{(n,m)\\in \\mathcal{N}(x)\\times \\mathcal{N}(y)} C(n,m)K([n - x, m - y])$.$\\ (1)\nBuilding upon insights from the work of Cordonnier et al. (2020), we consider Lemma 1 which states that the conv layer in Eq. 1 can be re-formulated as a form of multi-head self-attention under sufficient conditions:"}, {"title": "3.1. Proxy Match Transform: an efficient high-order feature transform with sub-quadratic complexity", "content": "To overcome the limitation, we introduce an efficient feature matching layer, dubbed Proxy Match Transform, which approximates high-order convolution with sub-quadratic complexity. Given a pair of features $(F_x, F_y)$ as inputs, PMT layers with $N_h$ heads\u00b9 are defined as follows:\n$\\textrm{PMT}(F_x) := \\sum_{h\\in [N_h]} A^{(h)}_{X}F_x P^{(h)T}w^{(h)}_{x},$\\ (4)\n$\\textrm{PMT}(F_y) := \\sum_{h\\in [N_h]} A^{(h)}_{Y}F_y P^{(h)T}w^{(h)}_{y},$\\ (5)\nwhere $w^{(h)}_{x} \\in \\mathbb{R}$ is a learnable weight scalar, $A^{(h)}_{X} \\in \\mathbb{R}^{|X| \\times |X|}$ is local attention matrix\u00b2, and $P^{(h)} \\in \\mathbb{R}^{D_{proxy} \\times D_{emb}}$ is proxy tensor that satisfies the following:\n$P^{(i)T}P^{(j)} = \\begin{cases} \\mathbb{I}_{D_{emb}}, & \\text{if } i = j \\\\ 0, & \\text{otherwise.} \\end{cases}.$\\ (6)"}, {"title": "3.2. Constraints for Proxy Match Transform", "content": "For the Proxy Match Transforms to express the high-order convolution, we assume the following constraints, (i) orthonormality constraint: $P^{(i)T}P^{(i)} = \\mathbb{I}_{D_{emb}}$ if $i = j$, and (ii) zero-matrix constraint: $P^{(i)T}P^{(j)} = 0 \\in \\mathbb{R}^{D_{emb} \\times D_{emb}}$ otherwise for all $i,j \\in [N_h]$. Under such conditions, a dot product between two Proxy Match Transforms can effectively approximate high-order convolution. Our main theoretical result is provided below.\nTheorem 1. If we assume $P^{(i)T}P^{(j)} = \\mathbb{I}_{D_{emb}}$ if $i = j$ and $P^{(i)T}P^{(j)} = 0$ otherwise for all $i, j \\in [N_h]$, and define $A^{(h)}_{(x,y), (n,m)} := A^{(h)}_{X(x,n)} \\cdot A^{(h)}_{Y(y,m)}$ and $w^{(h)} :=$"}, {"title": "3.3. Overall architecture", "content": "The proposed architecture, dubbed Proxy Match TransformeR (PMTR) comprises four main parts: (1) feature extraction, (2) coarse-level matching, (3) fine-level matching, and (4) transformation prediction & training objectives. As illustrated in Fig. 2, our pipeline begins with the point cloud pair embedding. The feature extraction network generates three pairs of features, each at distinct spatial resolutions. These feature pairs are subsequently fed to a corresponding PMT layer, which facilitates both coarse-level matching (for mating surface localization) and fine-level matching (for geometric matching). The outputs from the coarse matching phase are utilized to establish a preliminary correspondence between the mating surfaces of the input parts, which is crucial for identifying potential areas of alignment. Subsequently, the fine matching phase is designed to refine these correspondences, focusing exclusively on reliable matches identified during the coarse matching stage. This allows for precise correspondence establishment, ensuring accurate assembly as demonstrated by our experiments in Sec. 4.4.\nFeature extraction. A pair of point clouds to match is fed to a feature embedding network, reducing their spatial resolution to provide a coarse-level feature pair. Each of the two subsequent upsampling layers connected in series provides features in a higher resolution. From this U-Net-shaped architecture, similar to KPConv-FPN (Thomas et al., 2019), the model gives three pairs of point cloud features with different spatial resolutions: $\\{(F_{x_n}, F_{y_n})\\}_{n=1}^{3}$ where $F_{x_n} \\in \\mathbb{R}^{|X_n| \\times D_{n-emb}}$ with $|X_1| < |X_2| < |X_3|$, which implies that $F_{x_1}$ is the coarse feature with the smallest number of features. $\\{V_n\\}_{n=1}^{3}$ is similarly defined. The coarse feature pair $\\{(F_{x_1}, F_{y_1})\\}$ is used to identify potential mating surfaces to match, while the others $\\{(F_{x_n}, F_{y_n})\\}_{n=2}^{3}$ are used to precisely align the identified potential surface matches.\nCoarse-level matching. At this stage, PMT processes the coarse feature pair $\\{(F_{x_1}, F_{y_1})\\}$, in order to evaluate the potential local correspondence between the feature set. This is achieved without directly computing the pairwise correlation matrix $F_{x_1} \\cdot F_{y_1}^T$, which would otherwise result in a quadratic dimensionality of $\\mathbb{R}^{|X_1| \\times |V_1|}$. Instead, a pair of PMTs operates in a manner that allows them to be refined independently to provide two refined coarse-level features $(F_{x_c}, F_{y_c})$ as follows:\n$\\textrm{PMT}(F_{x_1}) = F_{x_c}, \\textrm{PMT}(F_{y_1}) = F_{y_c}.$\\ (10)\nDespite this independence, the transformations ensure that the dot product of the refined features closely approximates the output of a high-order feature transformation. The ap-"}, {"title": "4. Experiments", "content": "In this section, we discuss the dataset and evaluation metrics used (Sec. 4.1), implementation details (Sec. 4.2), the results of pairwise shape assembly with comprehensive analysis (Sec. 4.3), an in-depth ablation study to inspect the efficacy of the proposed techniques (Sec. 4.4), and extension of our evaluation to the task of multi-part assembly (Sec. 4.5).\n4.1. Dataset and Evaluation Metrics\nDataset. In our experiments, we utilize the Breaking Bad dataset (Sell\u00e1n et al., 2022), a large-scale dataset of fractured objects for the task of geometric shape assembly, which consists of over 1 million fractured objects simulated from 10K meshes of PartNet (Mo et al., 2019) and Thingi10k (Zhou & Jacobson, 2016). For pairwise assembly training and evaluation, we exclusively select a subset of the Breaking Bad dataset that contains two-part objects (Sect. 4.3). For multi-part assembly, we expand our evaluation to include all samples in the dataset, encompassing objects with 2 to 20 parts (Sec. 4.5).\nEvaluation metrics. Following the evaluation protocol of Sell\u00e1n et al. (2022), we measure the root mean square error (RMSE) between the ground-truth and predicted rotation (R) and translation (T) parameters, and the Chamfer distance (CD) between the assembly results and ground-truth. In addition, we introduce and report a new metric, called CoRrespondence Distance (CRD), which is defined as the Frobenius norm between the input pair of the assembled point cloud; unlike CD, CRD offers a more comprehensive measure of correspondence, capturing both proximity and structural alignment. We compute the evaluation metrics of RMSE (R) and RMSE (T) based on relative transformation, e.g., rotation and translation, between the input fracture pair, instead of the absolute pose as in the previous literature (Chen et al., 2022; Wu et al., 2023b) by setting the largest fracture as an anchor and computing the relative transformation. The formal definitions of the evaluation metrics can be found in the Appendix D."}, {"title": "4.2. Implementation details", "content": "We implement our PMTR using PyTorch Lightning (Falcon & team, 2019). The experiments were carried out on a machine with Intel(R) Xeon(R) Gold 6342 CPU @ 2.80GHz and NVIDIA GeForce RTX 3090 GPU. For all experiments, except those including GeoTransformer, we use ADAM (Kingma & Ba, 2015) optimizer with a learning rate of $1 \\times 10^{-3}$ for 150 epochs. For GeoTransformer, we use identical settings but only reduce the learning rate to $1 \\times 10^{-4}$ to prevent model divergence. To ensure uniform point density among fractures, we uniform-sample approximately 5,000 points on the surface of holistic objects and allocate the number of sample points for each fracture proportional to the surface area of each fracture. Each of the coarse- and fine-level matchers consists of 2 PMT(\u00b7) layers ($N_t = 2$) with non-linearity and group norm (Wu & He, 2018). See Appendix C for further details.\nAvoiding quadratic complexity of attention in PMT. In our actual implementation, we use local, i.e., sparse, attention for $A^{(h)}_{X} \\cdot A^{(h)}_{Y}$ by collecting attention scores of the 'neighborhood' of each position, thus reducing attention size to $|X| \\times \\epsilon$ instead of $|X| \\times |X|$ where $\\epsilon \\in \\mathbb{N}^+$ is the number of neighbors: $\\epsilon << |X|$. Specifically, attention at position $x \\in \\mathbb{R}^3$ denoted as $A^{(h)}_{X(x,:)} \\in \\mathbb{R}^{1 \\times \\epsilon}$ is limited to the neighborhood of x, represented by $\\mathcal{N}(x)$. Then, the output of PMT at x is formulated as $\\textrm{PMT}(F_x)(x,:) = \\sum_{h \\in [N_h]} A^{(h)}_{X(x,:)} F_X (\\mathcal{N}(x),:)P^{(h)T}w^{(h)}_y$, where $F_X(\\mathcal{N}(x),:) \\in \\mathbb{R}^{\\epsilon \\times D_{emb}}$ represents the neighborhood features of position x. This method significantly reduces the computational complexity typically associated with full pairwise attention, which would otherwise be quadratic, i.e., $|X| \\times |X|$. This reduction in complexity mirrors the strategies found in the existing literature, such as those described by Thomas et al. (2019). However, for the sake of simplicity, we narrate with a conventional form of square attention matrices $A^{(h)}_{X} \\in \\mathbb{R}^{|X| \\times |X|}$ or $A^{(h)}_{Y} \\in \\mathbb{R}^{|Y| \\times |Y|}$ to illustrate our methodology in this paper.\nAssessment with relative transformations. Note that the"}, {"title": "4.3. Pairwise Shape Assembly", "content": "To evaluate our method, we categorize the previous methods into two groups based on their approach to transformation parameters $\\{R|t\\}$ prediction. The first group includes 'regression methods' that encode each part into a global embedding and directly regress their absolute transformations using MLP: Global (Li et al., 2020a), LSTM (Wu et al., 2020), DGL (Huang et al., 2020), NSM (Chen et al., 2022), and Wu et al. (2023b). The second group consists of 'matching-based methods' that estimate relative transformations by aligning their predicted correspondences between each pair of parts: GeoTransformer (Qin et al., 2022) and Jigsaw (Lu et al., 2023).\nExperimental results and analysis. We evaluate our method and compare it against baseline methods on the everyday and artifact subsets of the Breaking Bad dataset. Tab. 1 presents the results, which demonstrate that our method consistently outperforms all baseline methods on both subsets. In Fig. 4, we provide qualitative comparisons between ours and the baselines, using mesh representation for better visualization.\nTo provide deeper insights into the learned shared proxy $P^{(h)}$, we visualize how the proxy and the refined coarse-level features ($F_{x_c}$ and $F_{y_c}$) are distributed in the feature space via t-SNE. As shown in Fig. 3, the visualization reveals that subsets of the source and target features (orange and lightblue) and the proxy (purple) form distinct clusters"}, {"title": "4.4. Ablation studies", "content": "Effect of proxy tensor in assembly. To verify the effect of proxy tensor in PMT, we conducted a series of ablation studies on the everyday subset of the Breaking Bad dataset. Specifically, we examine the impact of the shared proxy tensor by either removing it or using two different proxies instead of a shared one. The results, summarized in Tab. 2, clearly indicate that both removing the proxy and not sharing it lead to a significant decline in assembly performance. This underscores the efficacy of the shared proxy in facilitating information exchange in PMT.\nNext, we explore the impact of $L_{orth}$ and $L_{zero}$, which serve as sufficient conditions to constrain the PMT layer to represent the high-dimensional convolutional layers, as detailed in Sec. 3.2. The results are presented in Tab. 3; as is evident from the table, the best performance is achieved when both losses are incorporated. This highlights the significance of these constraining conditions for PMT, as they are crucial in enabling PMT to effectively approximate the high-dimensional convolution.\nComparison between different matchers. To demonstrate the efficacy and efficiency of the proposed matching layer, PMT, we conduct ablations by either removing it (None) or replacing it with different layers: a single linear transformation (Linear), multi-layer perceptron (MLP), high-"}, {"title": "4.5. Multi-part Assembly", "content": "To assess the generalizability of our method, we extend our evaluation to include multiple input parts, i.e., multi-part assembly, which requires the model to understand the pairwise correspondence relationships among all input parts. Utilizing the two-part assembly framework (Fig. 2), it begins with computing relative transformations between each pair of $P$ parts. We then construct a pose graph wherein each node and factor respectively represent an individual part and the predicted relative transformation, i.e., pose, between two parts. To optimize this pose graph for assembly, we employ a recent transformation averaging method detailed in the work of Dellaert et al. (2020). After the optimization, we evaluate our method using the metrics from pairwise assembly, supplemented by Part Accuracy (PACD) (Huang et al., 2020) - the percentage of parts with Chamfer Distance less than the predefined threshold of 0.01 as well as CRD-based Part Accuracy (PACRD) with 0.1 threshold. As seen from Tab. 6 and Fig. 4, our method significantly surpasses all baselines on all metrics on the multi-part assembly, demonstrating robust generalization to multiple input scenarios. For details on the evaluation metrics, see Appendix D."}, {"title": "5. Scope and Limitations", "content": "Despite the advances in efficient point cloud matching and shape assembly, our method still faces several limitations. First, the accuracy of our method can be compromised in scenarios with extremely low overlap between point clouds, which can hinder the identification of reliable correspondences. Second, our method, like many others in the field, requires extensive training on domain-specific datasets to achieve optimal performance. Third, while our experiments demonstrate the efficacy of PMT in shape assembly tasks, it has not been extensively tested across other potential applications such as robotics, manufacturing, digital artistry, or even restoration of ancient artifacts via more accurate and detailed part assembly. Thus, the applicability of our approach beyond geometric shape assembly remains to be fully validated. We leave this to future work."}, {"title": "6. Conclusion", "content": "We have introduced a low-complexity, high-order feature transform layer, Proxy Match Transform, designed for efficient approximation of traditional compute-intensive high-order feature transforms. The significant performance improvements over the state of the arts with a lower computational cost indicate its real-world applicability from artifact reconstruction to manufacturing. Although the proposed method has been applied exclusively to geometric shape assembly in this work, its significant improvements in various evaluation metrics reveal its potential for broad applications."}, {"title": "A. Theoretical Analysis of Proxy Match Transform", "content": "We now derive sufficient conditions such that Proxy Match Transform can express high-dimensional convolution. Our main theoretical result is given below.\nTheorem 1. If we assume $P^{(i)T}P^{(j)} = \\mathbb{I}_{D_{emb}}$ if $i = j$ and $P^{(i)T}P^{(j)} = 0$ otherwise for all $i, j \\in [N_h]$, and define $A^{(h)}_{(x,y), (n,m)} := A^{(h)}_{X(x,n)} \\cdot A^{(h)}_{Y(y,m)}$ and $w^{(h)} := w^{(h)}_{x}w^{(h)}_{y}$, then, the dot-product of Proxy Match Transform outputs with a sufficient number of heads $N_h$ can express high-dimensional convolutional layer with kernel $K : \\mathbb{R}^6 \\rightarrow \\mathbb{R}$: $\\textrm{PMT}(F_x) \\cdot \\textrm{PMT}(F_y)^T = \\textrm{Conv}(F_x, F_y)$.\nProof. We first take the dot-product of Proxy Match Transform outputs and simplify:\n$\\begin{aligned}\\textrm{PMT}(F_x) \\cdot \\textrm{PMT}(F_y)^T &= \\bigg( \\sum_{h\\in [N_h]} A^{(h)}_{X}F_x P^{(h)T}w^{(h)}_{x} \\bigg) \\bigg( \\sum_{h\\in [N_h]} A^{(h)}_{Y}F_y P^{(h)T}w^{(h)}_{y} \\bigg)^T \\\\ &= \\sum_{(i,j)\\in [N_h]^2} A^{(i)}_{X}F_x P^{(i)T}P^{(j)} F_y^T A^{(j)T}_{Y}w^{(i)}_{x} w^{(j)}_{y} \\\\ &= \\sum_{(i,j)\\in [N_h]^2} \\delta(i, j) \\bigg( w^{(i)}_{x} A^{(i)}_{X}F_x F_y^T A^{(i)T}_{Y} w^{(i)}_{y} \\bigg) \\\\ &= \\sum_{h\\in [N_h]} \\bigg( A^{(h)}_{X}F_x F_y^T A^{(h)T}_{Y} \\bigg) w^{(h)},\\end{aligned}.\\$\\ (14) (15) (16) (17)\nwhere $\\delta(i, j)$ provides 1 if $i = j$ and 0 otherwise. Using definitions of $A^{(h)} \\in \\mathbb{R}^{|X||Y| \\times |X||V|}$ and $w^{(h)} \\in \\mathbb{R}$, the output at a specific position $(x, y) \\in \\mathbb{R}^6$ is as follows:\n$\\begin{aligned} \\big( \\textrm{PMT}(F_x) \\cdot \\textrm{PMT}(F_y) \\big)(x,y) &= \\sum_{h\\in [N_h]} \\bigg( A^{(h)}_{X(x,:)} F_x F_y^T A^{(h)}_{Y(y,:)} \\bigg) w^{(h)} \\\\ &= \\sum_{h\\in [N_h]} \\sum_{(n,m)\\in X \\times Y} A^{(h)}_{X(x,n)} F_x (n,:) F_y(m) A^{(h)T}_{Y(m,y)} w^{(h)} \\\\ &= \\sum_{h\\in [N_h]} \\sum_{(n,m)\\in X \\times Y} \\bigg( A^{(h)}_{(x,y),:}) \\bigg) C(n,m) w^{(h)} \\\\ &= \\sum_{h\\in [N_h]} A^{(h)}_{((x,y),:)} C w^{(h)}.\\end{aligned}.\\$\\ (18) (19) (20) (21)\nNow consider the following Lemma:\nLemma 1. Consider a bijective mapping of natural numbers, i.e., heads, onto 6-dimensional local displacements: $t(h) : [N_h] \\rightarrow \\Delta(x, y)$. Let $A^{(h)} \\in \\mathbb{R}^{|X||Y| \\times |X||Y|}$ be an attention matrix that holds the following:\n$\\begin{aligned} A^{(h)}_{(x,y), (n,m)} = \\begin{cases} 1, & \\text{if } t(h) = (n, m) - (x, y) \\\\ 0, & \\text{otherwise.} \\end{cases}.\\end{aligned}.\\$\\ (22)\nThen, for any high-dimensional convolution with a kernel $K : \\mathbb{R}^6 \\rightarrow \\mathbb{R}$, there exists $\\{w^{(h)} \\in \\mathbb{R}\\}_{h \\in [N_h]}$ such that following equality holds:\n$\\textrm{Conv}(F_x, F_y)(x,y) = \\sum_{h\\in [N_h]} A^{(h)}_{((x,y),:)} C w^{(h)}.\\$\\ (23)"}, {"title": "B. Efficiency of Proxy Match Transform", "content": "To demonstrate the superiority of the proposed PMT, we provide the efficiency comparison between different matchers, e.g., Geometric Transformer (GeoTr) by Qin et al. (2022) and Proxy Match Transform (PMT), both during training and inference phases in Tab. 7. \u201cCoarse-only\u201d and \u201cCoarse + Fine\u201d refer to two different Proxy Match TransformeR (PMTR) models with PMT integrated only at the coarse-level and both levels, respectively. Specifically, we measure the computational efficiency by employing Floating Point Operations Per Second (FLOPS), and to assess the memory overhead and footprint, we record the peak memory usage for each method during both the training and inference phases, as well as the number of parameters. We also provide the training/inference times required for each matcher. For clarity in our comparison, when measuring the FLOPS, number of parameters, and train/inference times, we exclude those associated with the backbone and focus solely on the matchers: the coarse- or fine-level matcher."}, {"title": "C. Additional implementation Details", "content": "Attention Calculation. We adopt the relative-position encoding strategy of PerViT (Min et al., 2022) to compute the attention $A^{(h)}$. Specifically, we compute pairwise Euclidean distances $R_x \\in \\mathbb{R}^{|X| \\times |X|}$ each of which entry at position q, k \u2208 R\u00b3 is defeind as $(R_x)_{q,k} = ||q- k||_2$. An MLP processes this to provide an attention score $A^{(h)}_{X}$. $A^{(h)}_{Y}$ is similarly defined. We refer the readers to the work of Min et al. (2022) for additional details.\nModel hyperparameters. For the backbone network, we utilize KPConv-FPN (Thomas et al., 2019) with subsampling radius of 0.01. We leverage the global attention matrix for coarse-level matcher, and the local attention matrix (See Sec. 4.2) for fine-level matchers. The number of attention heads $N_h$ is set to 4. Refer to Tab. 8 for the rest of the hyperparameters. Each matcher takes a specific input and output feature pair, applies a type of attention mechanism, and uses various hyperparameters crucial for its operation."}, {"title": "D. Evaluation Metrics", "content": "We employ four different metrics to assess the results. Consider a pair of input point clouds $X, Y$. The ground truth SE(3) relative pose between the point clouds is represented by $R_{GT}, t_{GT}$, while the prediction is denoted as $R, t$. We define $T(\\cdot)$ as a function that transforms input pose with corresponding rotation R and translation t.\nChamfer Distance (CD). The chamfer distance between two point clouds $S_1, S_2$ is defined as\n$\\textrm{d}_{CD}(S_1, S_2) = \\frac{1}{|S_1|} \\sum_{x \\in S_1} \\min_{y \\in S_2} ||x - y||_2^2 + \\frac{1}{|S_2|} \\sum_{x \\in S_2} \\min_{y \\in S_1} ||x - y||_2^2,$\\ (25)\nwhich measures the sum of the distance between nearest neighbor correspondences between point clouds. To assess the quality of shape assembly, we measure the chamfer distance between ground truth assembly and the prediction as:\n$CD = \\textrm{d}_{CD}(T(X) \\cup Y, T_{GT}(X) \\\\cup Y).$\\ (26)\nCoRrespondence Distance (CRD). While the Chamfer distance calculates the distance between two point clouds, its ability to capture more complex features of the object's geometry, such as symmetry and rotation, is limited. To overcome this limitation, we define a new metric, CoRrespondence Distance (CRD). CRD is simply defined as the Frobenius norm between two point clouds:\n$CRD = \\frac{1}{L} \\sum_{i=1}^{L} ||(T(X) \\cup Y)_i - (T_{GT}(X) \\cup Y)_i||_F,$\\ (27)\nwhere $L = |X| + |Y|$ is the size of assembled object. By considering all pairwise distances between point clouds, it offers a more comprehensive measure of similarity, capturing both proximity and structural alignment:\nRotational-, Translational-RMSE (RMSE(R), RMSE(T)). Finally, to directly measure the prediction accuracy of transformation parameters, we compute the root mean square error (RMSE) between predicted and ground-truth rotation and translation, respectively. Following the protocols of Sell\u00e1n et al. (2022), we use Euler angle representation for rotation:\n$\\textrm{RMSE(R)} = \\sqrt{\\frac{1}{3}} ||R - R_{GT}||_F, \\textrm{RMSE(T)} = \\sqrt{\\frac{1}{3}} ||t - t_{GT}||_F.$\\ (28)"}, {"title": "E. Additional Qualitative Results", "content": null}]}