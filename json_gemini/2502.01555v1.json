{"title": "Query Brand Entity Linking in E-Commerce Search", "authors": ["Dong Liu", "Sreyashi Nag"], "abstract": "In this work, we address the brand entity linking problem for e-commerce search queries. The entity linking task is done by either i) a two-stage process consisting of entity mention detection followed by entity disambiguation or ii) an end-to-end linking approaches that directly fetch the target entity given the input text. The task presents unique challenges: queries are extremely short (averaging 2.4 words), lack natural language structure, and must handle a massive space of unique brands. We present a two-stage approach combining named-entity recognition with matching, and a novel end-to-end solution using extreme multi-class classification. We validate our solutions by both offline benchmarks and the impact of online A/B test.", "sections": [{"title": "1 Introduction", "content": "Manufacturer identity is the second most important attribute identi-fied in search queries behind product-type in e-commerce. Correctly recognizing brand names, whether mentioned directly (e.g., through explicit company names) or indirectly (e.g., through product-specific terminology), is an important component of search query under-standing and is crucial to providing a good shopping experience to customers. The current string-based approach to brand identi-fication in search queries presents several challenges: (i) unifying brand name variants across different languages and regions (e.g., a Western brand name written in its original form versus its repre-sentation in Asian scripts), (ii) different surface forms for the same brand (e.g., abbreviations versus full names) and (iii) identifying brand relationships between parent and sub-brands (e.g., a parent company and its product line brands). Therefore, in addition to recognizing the brand names mentioned in the query, it is also important to link them to the corresponding global brand entity. It would be valuable to unify the concept of brand across different e-commercial stores in a single namespace, i.e., brand entity (identity to each brand itself). Each brand entity is is unique across languages, stores and surface forms. As part of this effort, we aim to recognize the brand entity for branded search queries. We define branded search queries as those queries with clearly specified brand intents, e.g., <brand> running shoes. Such queries have a single brand entity as its shopping intent. We view this as an entity linking problem where the brand needs to be identified and subsequently linked to a unique brand entity in our brand database.\nEntity linking is the task of recognizing meaningful mentions in a textual context and linking them to a knowledge base [13, 14]. In literature, entity linking sometimes assumes that the entity men-tions are already given or detected, for example, using a named entity recognition (NER) system. However, in this paper, we define entity linking as the combined task of entity recognition and entity disambiguation that operates on the raw textual context. In the e-commerce domain, entity linking is especially important to under-stand search queries and the customer's shopping intent. It is used to extract the important attributes in a search query, e.g., brand, product type etc. and link them to known entities in a knowledge base. The most common approach to entity extraction is a two-step process consisting of: i) entity recognition, and ii) entity disam-biguation. The goal of entity recognition is to identify meaningful spans from the textual context. When recognizing multiple entity types, this step also includes tagging the mentioned entity span with its entity type. The recognized spans are usually ambiguous in nature and the entity disambiguation step is then performed to link the span to a knowledge base. Often there are multiple candidate entities in the knowledge base that match the recognized entity. The entity linker generates and ranks these candidates. In two-step methods, when a mention span is identified via a Named Entity Recognition (NER) model, there are commonly three ways to gener-ate entity candidates: i) surface form matching; ii) expansion using aliases; iii) prior probability matching. In surface form matching such as [8, 11, 20], a candidate list is generated such each entity match at least a surface form of the mention. Matching may be done via either exact or fuzzy matching. For expansion with aliases [5], a dictionary of additional aliases is constructed to grouping known surface forms and aliases of a brand together. As for the prior probability method [16], a pre-calculated prior probability of corresponding entities for given certain mentions is used to infer the possible entity candidates for a given query. After the candi-date generation in the two-step methods, the entity candidates are usually ranked according to their relevance to the mention input, where the relevance can also take into account the context of the mention. Candidate ranking can be done via computing the Lev-enshtein distance or via vector product in a semantically enriched embedding space where both entity and mention are represented by semantic vectors [2, 6, 10].\nRecent approaches have also performed joint entity recognition and disambiguation. This includes approaches that perform both steps simultaneously [12, 15], allowing for interaction and shared knowledge between the two steps. Other approaches eliminate the two-step process entirely and tackle this problem as an end-to end task, directly predicting the entity from the input textual context. For example, [7] use BERT to formulate the task as a sequence labeling problem, where each token in the text is assigned an en-tity link or a NIL class (a none class indicating no entity). Thus, they perform token classification over the entire entity vocabulary. Yet another approach retrieves entities by generating their unique names, left to right, token-by-token in an autoregressive fashion and conditioned on the context [1].\nThe entity linking of e-commence queries is challenging since the query length is usually short (averaging about 2.4 words per query) and there is limited additional context. Unlike web search, such queries often lack the natural language structure and open source NLP models are unable to handle such query distributions well. Further, brands are a very important concept in e-commerce and there are hundreds of thousands of unique brands on such services with new being constantly added. In this work, we pro-posed different solutions to the brand entity linking problem. Our contributions can be summarized as follows:\n(1) We first build a two-stage entity linking model for e-commerce query brand entity prediction, consisting of an NER brand recognition model (we employ the pretrained NER model as shall be explained in 2.1) and a surface form matching step.\n(2) We explore both lexical and semantic matching techniques for surface form matching and develop a product type-based filtering step for brand entity prediction refinement in mas-sive brand output space.\n(3) We propose a novel end-to-end extreme multi-class classifi-cation model to directly takes the search query as input and predicts the relevant brand entity. The end-to-end model is then integrated with the two-stage model as a fused solution for brand entity linking problem. We conduct extensive of-fline experiment benchmarks and online A/B test to validate our solution."}, {"title": "2 Preliminaries", "content": "We introduce three preliminaries models that are applied as part of our proposed methods."}, {"title": "2.1 MetaTS-NER", "content": "One of our baseline solution replies on named-entity recognition (NER). Therefore we introduce the NER model used in this work. We utilize the MetaTS-NER [9] model for brand string detection. MetaTS-NER is a multilingual DistilmBERT-based for sequential labeling. The model is fitted with internal data to predict eight kinds of attribute type annotation, i.e., product line, media title, brand, gender, material, artist, color and size for product search queries. Our first two-stage framework of brand entity linking has a dependency on this model since it consumes the brand name annotations of queries."}, {"title": "2.2 Q2PT", "content": "Our solutions would rely on product type intents of search query to disambiguate the the brand entity linking. We thus need a product type classification model to parse a search query. The classification model that we leverage is an internal model, i.e. query-to-product-type model (Q2PT). The deep learning classification model is BERT-based search query classification model and fitted with internal dataset. We would use acronym PT for product type."}, {"title": "2.3 PECOS", "content": "PECOS (Prediction in Enormous and Correlated Output Spaces) [19] is a general purpose tool aimed at solving extreme multi-class classi-fication problems. PECOS firstly representing each label by seman-tic vector (sparse or dense vector) and then runs repetitively clus-tering algorithm to build hierarchical label tree. Then a set of score functions are trained in supervised machine learning fashion to do inference on the hierarchical label tree. The solution allows to find best matches from a large search space effectively and efficiently. PECOS has been applied in information retrieval track successfully for semantic matching that allows generating a semantic match-set beyond the limitation of conventional lexical matching. PECOS for semantic matching not only enjoys competitive prediction accu-racy and also offers low inference latency thanks to the hierarchical clustering tree and doubly-sparse data structure [4]. For example, the inference latency is less than 5 ms per query for generating predictions from a class space of 100 million products [3]. In this work, we would apply the framework provided by PECOS to train new classification model for our entity disambiguation task."}, {"title": "3 Brand Entity Linking via Two-Stage Framework", "content": "Following the typical two-stage approach in entity linking, i.e., a mention detection step followed by entity disambiguation, we utilize the MetaTS-NER model to build a two-stage framework for brand entity prediction. As shown in Figure 1 and Figure 2, in the first stage, we will extract the brand name from branded search queries using the NER model. In the second stage, we map the extracted brand name to the corresponding brand entity using a matcher followed by a filtering step. The two-stage solutions are detailed in the following sections."}, {"title": "3.1 MetaTS-NER + Exact Lexical Matching", "content": "In our first benchmark, we implement the matcher as a static dic-tionary with the keys being brand names and the values being the brand entities. For an input query, MetaTS-NER detects the brand name in its string form. The output of MetaTS-NER is then fed to the matcher. The dictionary serves as an extract string matcher that performs a lookup based on this output. We construct this dictionary alike internal dataset from brand-name2entity dataset (detailed in Section 6.1). In the dictionary dataset, each brand entity may have multiple textual representations (e.g., full names and their abbreviated forms). We collect all valid representations as potential keys in our dictionary. Since some brand name representations are store-specific, we append the store tag to the beginning of the dic-tionary key. For representations that are common across multiple stores, we duplicate the same brand name and add corresponding store tag as prefix. While each brand entity is unique, brand names on the other hand do not have this constraint.\nIn building the matching mapping, there is another challenge that two brand entities may share the same brand name, i.e. a brand name may be mapped to more than one brand entities without fur-ther context. To address the ambiguity of one-to-many mappings, we implement a filtering step to disambiguate between the multiple brand entity candidates based on the query context, i.e. the other side information in Figure 1. We apply a product-type (PT) based filtering strategy that aims to match the intended product-type of the input query with the known product-types of the candidate brand entities. The product-type information for a brand entity is pre-computed based on the catalog data. Since we do not have an authoritative source for brand-PT relationships, we approximate this data indirectly from products stamped with the brand enti-ties. For every unique brand entity, we sample and collect a list of impressed products (those shown as part of search results for any query) over a four month period, where their corresponding PTs are aggrated. Hence for each brand entities, we have a list of associated PTs. We note that this is not an exhaustive list of PTs and we are unable to collect this data for every brand entity. We use the Q2PT model to predict the product-type for the query. If the dictionary lexical matcher has mapped the brand surface form to multiple brand entities, we only select those brand entities that have PT matching the Q2PT prediction. We found that this filtering was able to narrow down the prediction to a single brand entity for over 50% of multi-brand-entity prediction cases. We do not make any brand-entity prediction for the queries that still map to multiple brand entities to ensure high precision. The solution is illustrated in Figure 1."}, {"title": "3.2 NER + PECOS Semantic Matching", "content": "Simple string matching based on surface forms often fails to capture brand name variations. When different textual representations of the same brand (such as abbreviations and full names) are not all included in the dictionary, some valid mentions may be missed. To address this limitation, we explore semantic matching as an alternative retrieval approach for brand mention matching in entity linking.\nWe formulate the matching step as a eXtreme Multi-class Classi-fication (XMC) problem. Given the MetaTS-NER brand output, a learning-based model aims to efficiently tag the brand name with its most relevant class (i.e., brand entity) from the large-scale output space (i.e., the brand entity space). The number of brand entities is quite large (around 600K) and many of them can be correlated to a certain degree. The large output space corresponds to a long-tailed label distribution, suggesting that many labels have very few rel-evant queries. These characteristics are commonly-shared in the XMC problem. From this perspective, we implement the matcher with the state-of-the-art XMC solver PECOS.\nThe minimum inference latency introduced by PECOS also makes it appealing as a plug-in component for existing real-time services in the query understanding engine. In Figure 2, we illustrate the Mention2Entity-PECOS (M2E-PECOS) method which replaces the lexical matcher by the semantic matcher powered by PECOS. Specif-ically, we use semantic matching for brand entity generation from a large output space to tackle the limitation in exact lexical string matching on surface forms.\nModel training and inference: Unlike the lexical matcher which is parameter-free and does not need model training, PECOS requires training data to estimate model parameters. We replace the dictionary based exact lexical matcher with the PECOS semantic matcher to get the Mention2Entity-PECOS (M2E-PECOS) method. The input and output spaces remain the same as the lexical match-ing method. The model consumes the MetaTS-NER brand name prediction as its input and classifies it into one of the brand enti-ties in the output space. The model is trained using the training data that shall be explained in section 6.1. We extract (brand name, brand entity) pairs as relevant training instances. Each predicted brand entity comes with a relevance score, which is used in the sequential filtering stage. If the product type based filtering cannot disambiguate brand entities, we can rely on the relevance score and select the highest-scored brand entity. Both training and inference of M2E-PECOS have the vectorization step of projecting the textual brand names into numerical vector space (we use TF_IDF vector-ization for experiments). We train a single M2E-PECOS model that is capable of doing inference on multi-lingual brand names."}, {"title": "4 Brand Entity Linking via Extreme Multi-Class Classification Framework", "content": "The two-stage approaches have the following limitations: i) Since the two-stage approach relies on two independent steps, each can introduce errors, which means error can propagate from one step to the following step. ii) The first-stage NER casts a bottle neck for recall performance. If the MetaTS-NER model fails to recognize a brand, we are unable to retrieve a brand entity. The matcher can also fail to retrieve a relevant brand entity in some cases. Furthermore, string matching can only retrieve explicitly mentioned brands from queries. Brands can also be implied through product names. For instance, a product line name may indicate a specific manufacturer without explicitly stating it. The two-stage approach cannot retrieve such implicit brand references. Additionally, two-stage methods are more cumbersome and complex than end-to-end methods. To tackle these limitations, we propose an end-to-end method for brand entity linking that directly predicts brand entities from input queries.\nFor the end-to-end model, the extreme multi-class classifier, PECOS is directly exposed to the input queries. This simplifies model training, deployment and inference significantly compared to the two-stage approach. Figure 3 shows the framework. The PECOS model directly takes a query as input and predicts relevant brand entities. Afterwards, a filtering step is conducted that utilizes the PECOS relevance scores along with its predictions to post-process the predictions. Similar to the two-stage approaches, we utilize the PT filtering step to ensure a PT match with the query. We refer to this model as Q2E-PECOS. The label space for Q2E-PECOS is collected from the brand-name2entity dataset (see Section 6.1) as the collection of all unique and valid brand entities. We have 61678 such brand entities as our classes.\nAn important point to note is that the majority of search queries do not contain a brand intent. The input to our brand entity linking model is all search queries, out of which branded queries are only a subset. To address this, we add a NO_ENTITY class to the brand entity space to allow our model to handle non-branded queries. In other words, we expect the Q2E-PECOS to predict NO_ENTITY label for non-branded queries.\nModel Training and Inference: Q2E-PECOS model directly maps queries to brand entities that is different from two-stage framework in Section 3. The training data of Q2E-PECOS is multi-lingual and is explained in section 6.1.1 in detail. The training data contains both valid brand entities and dummy entity (NO_ENTITY). In the inference stage, when multiple classes are predicted for an input query, NO_ENTITY (if predicted) and valid brand entities are ranked according to their relevance scores. A simple way is to choose the highest-scored class on the basis of PT match for the input query, which is what we implement in this approach."}, {"title": "5 Fusion of the Q2E-PECOS and Extract Lexical Match Prediction", "content": "The proposed Q2E-PECOS model as a one-stage solution is simpler and capable of covering more variety of brand names than extract-string matching based method. However, while Q2E-PECOS allows us to retrieve a wider variety of brands, it shows lower precision compared to extract-string matching based solution. To receive the benefits of both methods, we can run the two methods in parallel independently from each other and fuse their predictions as a post processing step to make the final prediction for a query. When both predictions are available for a query, we select the MetaTS-NER + exact lexical match prediction over Q2E-PECOS to opt for higher precision. The diagram of the fusion solution is shown in Figure 4."}, {"title": "6 Experiments", "content": "The datasets for model training and evaluation are pruned from internal data. We explain them in the following sections."}, {"title": "6.1 Datasets", "content": "The datasets for model training and evaluation are pruned from internal data. We explain them in the following sections."}, {"title": "6.1.1 Training Datasets", "content": "The training dataset consists of three folds and is explained as the following.\nBrand-name2entity dataset: Brand-name2entity dataset is inter-nal dictionary-like dataset with each entry being brand name, brand entity pair. The dataset has two user cases: i) It serves as part of the training data where a brand name is considered as a pseudo query. ii) it assists to the strongly-labeled dataset building as would be explained in the following section. As for why we use this as part of training data, we consider it as a form of data augmentation. Sim-ilar augmentation has been explored in the extreme zero-shot text classification [18] and large-scale retrieval of the search engine [17].\nStrongly-labeled dataset: The srong-labeled dataset is a dataset derived from search queries annotated by human judges internally. The data contains both branded as well as non-branded queries. The internal annotations consist of top query attributes like brand, color, size etc. The data set is used for NER model training. For the purpose of our brand entity linking, we only utilize the brand labels and mark all other attributes as O (Other). The dataset covers 13 languages: English, Spanish, German, French, Italian, Japanese, Dutch, Portuguese, Polish, Turkish, Swedish, Arabic and Czech. We collect 806972 training pairs from this dataset. The dataset contains the brand name from the human annotated label. To build mapping from a search query to brand entity, we add an additional step of mapping the brand name to its corresponding brand entity through exact string matching by leveraging brand-name2entity dataset. This gives us the strongly-labeled dataset.\nWeakly-labeled query data from sampled search engagements: Although the brand-name2entity data source is rich in its brand distribution, the brand names alone do not match the query distribu-tion. Since we ultimately wish to identify brand entities for search queries, we sampled and aggregated the historical search traffic to collect a weakly-labeled set of branded queries. We sampled query-product pairs that have a strong association through past search engagement aggregated over a time period. From the sampled data, we also collect the brand names for each of these products. We then check if the brand name is present in the associated query string as a substring. If it is present, we label the query with that brand name. Note that we rely on the strong query-product association to make this labeling and we do not verify these labels through human annotation. We build 1308816 such examples as part of training data."}, {"title": "6.1.2 Test Dataset", "content": "We use a held-out subset of the strongly-labeled dataset as our gold test dataset. As mentioned previously, the dataset contains queries with their annotated brand names and the associ-ated entities. Since we add the corresponding brand entities through exact string matching using the brand name. The mapping process can sometimes lead to more than one brand entity being selected. Since we cannot be sure of the right one, we discard such examples for the purpose of precision and recall measurement. There are 28439 queries in total in the test dataset, out of which 24054 queries (84.5%) are labeled with single brand entity whereas 4385 queries are multi-brand-entity labelled queries."}, {"title": "6.2 Evaluation Metrics", "content": "Following the typical Recall and Precision definition, we define our metrics as\nRecall = $\\frac{\\text{Number of queries getting correctly single-brand-entity prediction}}{\\text{Number of queries having single-brand-entity label in test data}}$\nPrecision = $\\frac{\\text{Number of queries getting correctly single-brand-entity prediction}}{\\text{Number of queries having single-brand-entity prediction}}$\nThough there are some queries with multi-brand-entity labels. We believe they are queries with brand name intent which takes up about 15% in our test data. We define a metric named Coverage to include these group of test queries by\nCoverage = $\\frac{\\text{Number of queries with single-brand-entity prediction}}{\\text{Total number of query in test data}}$\nThe difference between the recall and coverage metrics is the following: i) recall only counts the correctly predicted single-brand-entity labelled query number whereas coverage includes also wrong single-brand-entity predicted cases as well. ii) As for denominators, recall counts the queries with single-brand-entity labels whereas coverage also counts the none-single-brand-entity labelled queries. We include the coverage metric due to our limitation of test data labeling."}, {"title": "6.3 Numerical Results", "content": "We present our experimental results in Table 1. We present multiple experiment runs depending on the training data and fusion config-urations used. Here, the fusion parameter refers to post-processing fusion strategy mentioned in section 5.\nWe first measure precision, recall and coverage metrics for each online retail store. The evaluation is performed over two store clusters, i.e. Group-1 and Group-2. The two groups differ greatly in size, evaluation data volume and search query pattern distributions. Hence, we average the metrics for both groups separately.\nWe first look at the two-stage methods, i.e. MetaTS-NER + Exact Lexical Match and M2E-PECOS. With the fusion technique, it can be seen that semantic matching via PECOS does help to improve the coverage over the exact lexical matching technique. But we see a drop in both recall and precision when moving from exact lexical match to semantic match. While the semantic matching technique can retrieve more brand entities, it does so with a lower precision. When a fusion of the lexical and semantic matching techniques is applied, we see improvement in both coverage and recall, whereas the precision is slightly affected.\nNext, we compare the Q2E-PECOS model to the baseline model MetaTS-NER + Exact Lexical Match. We see that the training data choice has a significant impact in the performance of the Q2E-PECOS model. This is expected since the end-to-end model re-quires a lot more data to learn the task. When only using the brand-name2entity and the strongly-labeled datasets, Q2E-PECOS pre-forms worse than the MetaTS-NER + Exact Lexical Matching model across all metrics. Adding the fusion strategy improves the model performance significantly. This shows that with limited data, both models have complimentary effects. When we add in the weakly-labeled catalog data, we see the Q2E-PECOS model improve over our baselines even without the fusion mechanism. Finally, we get the best performance across all metrics when combining all training data sources and also including fusion mechanism.\nFalse alarm evaluation: All metrics shown in Table 1 were measured on the gold test set containing only branded queries. In the real-world e-commerce services, we wish to deploy such a model for all queries and expect the model to be able to identify branded queries and then predict the corresponding brand entity. To study the impact of the model in such a setting, we collected 85K non-branded queries and observe the predictions by the different models. We define the false alarm rate in this evaluation as the percentage of non-branded queries for which the model incorrectly predicts a brand entity. Table 2 reports the rates for the four main models. As we can see, the exact lexical match based method receives the lowest false alarm. The M2E-PECOS has a slightly larger false alarm and Q2E-PECOS model further increases the rate by 3%. Although we see an increased false alarm rate with our best Q2E-PECOS model, we believe the increase is still acceptable given the overall performance gain of this model along with its more simplified implementation."}, {"title": "7 Online Results from A/B Test", "content": "In e-commerce, identifying the right brand and linking to right entity is crucial in ensuring the relevant products are retrieved and ranked for the customer. Failing to do so can result in a negative shopping experience. To assess comparative performance, we con-ducted A/B testing between our two proposed approaches under real-world conditions. In the A/B testing, the NER followed with exact lexical match is the control solution while the fusion solution as shown in Figure 4 is the treatment. The fusion solution improves the brand entity recall by +11% in Group-1 cluster stores and +5.44% in Group-2 Cluster stores in online experiment. Furthermore, the A/B test shows the fusion solution increases customer engagement by 0.02% and improves immediate contribution profit by 0.03%."}, {"title": "8 Conclusion", "content": "In this work, we proposed a two-stage method and an end-to-end classification approach for brand entity linking for e-commerce search queries. We conduct extensive experiments using various modeling and data augmentation techniques and show improved performance compared to the more commonly used two-stage ap-proaches to this problem. We also explore the feasibility of deploy-ing such a model on real-world search query traffic. Given the result, we show that there is good scope for improvement in exploring end-to-end techniques for attribute extraction tasks. We also built a fusion solution including both the two-stage and one-stage models into one framework. The solution has been valided by an online A/B test."}]}