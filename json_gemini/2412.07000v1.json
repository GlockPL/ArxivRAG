{"title": "Extreme AutoML: Analysis of Classification, Regression, and NLP Performance", "authors": ["Edward Ratner", "Elliot Farmer", "Brandon Warner", "Christopher Douglas", "Amaury Lendasse"], "abstract": "Utilizing machine learning techniques has always required choosing hyperparameters. This is true whether one uses a classical technique such as a KNN or very modern neural networks such as Deep Learning. Though in many applications, hyperparameters are chosen by hand, automated methods have become increasingly more common. These automated methods have become collectively known as automated machine learning, or AutoML. Several automated selection algorithms have shown similar or improved performance over state-of-the-art methods. This breakthrough has led to the development of cloud-based services like Google AutoML, which is based on Deep Learning and is widely considered to be the industry leader in AutoML services. Extreme Learning Machines (ELMs) use a fundamentally different type of neural architecture, producing better results at a significantly discounted computational cost. We benchmark the Extreme AutoML technology against Google's AutoML using several popular classification data sets from the University of California at Irvine's (UCI) repository, and several other data sets observing significant advantages for Extreme AutoML in accuracy, Jaccard Indices, the variance of Jaccard Indices across classes (i.e. class variance) and training times. (Abstract)", "sections": [{"title": "I. INTRODUCTION", "content": "The selection of model structure and the corresponding hyperparameters is a challenge faced by modern practitioners of machine learning on a regular basis. This applies to methods that have been around for many years such as KNN's where the number of neighbors to be used and the choice of the distance metric need to be selected, as well modern Deep Learning networks where the number of hidden layers, the number of neurons per layer, the choice of activation functions and regularization have to all be decided prior to training the model (Ivakhnenko et al., 1967). In this paper, we focus on the application of extreme learning machines (ELMs), where the choices of the number of neurons and regularization needs to be made among others (Miche et al., 2009; Khan et al., 2020; Liu and Wang, 2010; Van Heeswijk et al., 2011; Grigorievskiy et al., 2014). Many practitioners select hyperparameters based on their prior experience. Many employ a trial-and-error method using a training and validation set. More recently some practitioners have employed numerical optimization techniques in order to optimize the hyperparameters. In that case, the parameters of the optimization method itself become new hyperparameters"}, {"title": "A. Extreme Learning Machines", "content": "Extreme Learning Machines (ELMs) are a form of generalized feedforward neural networks that employ a single layer of randomly generated hidden neurons. These types of networks can solve classification, regression, and clustering problems. ELMs are a member of the class of neural architecture called Randomized Neural Networks (RNNs). These networks contrast many other common architectures in that they randomly generate hidden nodes. Thus, weights from the first layer may be independent from the training data. Previous research has shown that ELMs are able to provide a unified learning platform with widespread feature mappings in both regression and classification tasks (Huang et al., 2004). Furthermore, ELMs are more easily optimizable when compared to classical algorithms like Support Vector Machines (SVMs) due to the single-layer architecture (Lendasse et al., 2013).\nELMs are fundamentally different from networks that rely on conventional back-propagation due to the lack of dependence between input and output weights. Thus, ELMS have a non-iterative, linear ordinary least squares solution for the output weights. Huang et al. (2004) illustrated ELM's universal approximation capability, suggesting ELMs can universally approximate any continuous target functions in any compact subset X in Euclidean space. ELMs have illustrated learning speeds thousands of times faster than other feedforward neural network algorithms that rely on backpropagation while also obtaining greater generalization performance (Huang et al., 2004; Warner et al., 2023). ELMs may use any activation function that is an infinitely differentiable function (i.e., monotonic) and is bounded from -1 to 1 (e.g., hyperbolic 89 tangent). The output of an ELM may be denoted as\n$\\\u0423_k = \\sum_{j=1}^{m} \\beta_{j,k} g (\\sum_{i=1}^{n} W_{i,j}x_i + b)$\nwhere x represents the input to the network and y as the k'th output. n, m, and k represent the number of neurons in the input, hidden, and output layers, respectively (Huang et al., 2004). w, and $\u00df$, represent the corresponding weights for the input and output neurons. b represents the bias values used 96 by the neurons in the hidden layer. Lastly, g(.) denotes the activation function employed for each neuron. Eq. (1) may then be written as\n$H\u00df = y$\nwhere H is the hidden layer output matrix. The output neurons' weights, $\u00df_{1m, 1k}$, are then computed with the generalized Moore-Penrose pseudoinverse matrix as\n$\u00df = H^+y,$\nwhere H+ is the generalized Moore-Penrose pseudoinverse matrix of H, and y is the resultant output of the system. There are various modeling decisions to consider when using ELMs. First, one must choose an activation function that is monotonic and is bounded from 1 to 1 (e.g., hyperbolic tangent. Theoretically, one could scan different activation functions but this is generally held constant. The hyperparameters of ELMs include the number of neurons, the value of the bias term, weights, and regularization term (alpha). While the weights are random, one must choose a method for selecting a diverse combination of random weights. Additionally, if one is using an ensemble of ELMs, one must decide on the number of ELMs in the ensemble. Just as in other neural architectures, one may select the optimal hyperparameters using iterative, hybrid, or grid search approaches. In sum, conventional neural architectures that utilize backpropagation suffer from significant bottlenecks caused by slow gradient-based learning algorithms and iterative hyperparameter tuning. ELMs, on the other hand, provide state-of-the-art predictive performance using a fraction of the compute resources required by Deep Learning architectures due to the randomized single-hidden layer structure. As illustrated in the experiments below, this results in the ELM's ability to provide similar or superior performance in a small fraction of the time taken by Deep Learning."}, {"title": "II. MATERIALS AND METHODS", "content": ""}, {"title": "A. Overview of Novel Approach", "content": "Unlike Deep Learning architectures, a single ELM does not need a computationally intensive, iterative process to determine its neuron weights. Our recent paper introduces our novel ensemble learning methodology (Warner et al., 2024). In this approach, the neuron weighs are determined by solving a single linear system. An ensemble of ELMs can then be created to achieve more robust performance. Though many ensembling techniques have been explored, the choice of hyperparameter selection for each ELM in the ensemble remains an open question. Extreme AutoML has approached machine learning classification, regression, and time-series prediction in a fundamentally different way, where a proprietary algorithm is used to choose each ELMs hyperparameters (Warner et al., 2023). This allows our Extreme AutoML technology to produce fast, accurate models on both small data and large sets. This novel architecture enables the users of our technology to leverage their dynamic data in real-time.\nClassical and Deep Learning algorithms also require extensive hyperparameter optimization. Extreme AutoML's revolutionary architecture automatically produces highly accurate models without the need to iteratively optimize hyperparameters, allowing users to instead focus their efforts on leveraging these state-of-the-art models to their advantage. Another important consideration to consider when choosing the best machine learning technology for classification problems is the variability of performance across classes. While a model with an overall relatively high accuracy may seem adequate at first, poor performance in one or more of the classes will result in a significant decrease in utility. The metric that best measures performance across classes is the Jaccard Index (Fletcher and Islam, 2018):\n$J(A,B) = \\frac{A\\cap B}{A \\cup B}$\nwhere J is the Jaccard Distance between sets A and B, where the Jaccard Index is computed for each class. The Jaccard index is a monotonically increasing function of the F1-score, and therefore, both criteria would lead to the same rankings (Fletcher and Islam, 2018). Many models produce higher Jaccard indices for over-represented class, while the underrepresented classes have significantly lower Jaccard indices. This results in high Jaccard Index variability a highly undesirable result in most applications. Models that produce higher Jaccard Indices for underrepresented classes and thus much lower Jaccard index variability illustrate greater generalization and utility. In the following sections, we report the results for classification. Since the results reported earlier (Warner et al., 2023), the Extreme AutoML platform has undergone coding optimization resulting in further improvements in efficiency."}, {"title": "B. Structured Datasets and Methodology", "content": "The University of California at Irvine's machine learning repository contains thousands of open-source datasets used for classification, regression, time series, and clustering experiments. To best benchmark Extreme AutoML's technology against state-of-the-art industry leaders, performance comparisons were made on classification models side by side with Google's AutoML service. Classification is a machine learning task by which an"}, {"title": "III. RESULTS", "content": ""}, {"title": "A. Classification", "content": ""}, {"title": "a) Human Activity Recognition Using Smartiphones", "content": "Table 1 shows the breakdown of the Human Activity Recognition (Anguita et al., 2013) dataset's attributes and the performance for each learning method, each using one training set per each of the 8239 samples. The data in the Human Activity Recognition set were collected using 30 volunteers equipped with smartphones (Samsung Galaxy S II). While the smartphone was mounted on the participants' waist, the volunteers were recorded while performing common activities of daily living (ADL) including walking, walking upstairs, walking downstairs, sitting, standing, and laying down. The embedded sensors in the smartphone (accelerometer and gyroscope) then recorded 3-axial linear acceleration and 3-axial angular velocity acceleration measurements, which maintained at a constant rate of 50Hz. The sensor signals were then pre-processed using noise filters, sampling in fixe width sliding windows of 2.56 sec and 50% overlap. The acceleration signals, which contain gravitational and body motion variables, were separated using a Butterworth low-pass filter. Since gravitational forces only contain low frequency components, a filter cutoff of 0.3 Hz was used. Finally, each window measurement resulted in a"}, {"title": "b) Parkinson's Disease Classification", "content": "In the second experiment using the Parkinson's dataset (Sakar et al., 2019), 1202 training samples were used for the 752 attributes. These data were collected using patients (23 men and 41 women) with Parkinson's disease, ranging in ages from 33 to 87. The data collection process began by setting the microphone to 44.1 KHz, followed by a physician's examination consisting of pronouncing the sustained phonation of the vowel /a/ in three repetitions. Preprocessing steps were conducted using various speech signal processing algorithms including Time Frequency Features, Mel Frequency Cepstral Coefficients (MFCCs), Wavelet Transform based Features, Vocal Fold Features and TWQT features. In our experiment, the Extreme AutoML accurate method outperformed Google AutoML by 1.45% accuracy whilst training almost 300 times faster. Figure 3 shows the breakdown of the accuracy and Jaccard Indices for the two classes in the dataset. For each of the classes and methods, Extreme AutoML outperformed Google AutoML in terms of Jaccard Indices, further illustrating greater generalization capabilities."}, {"title": "c) QSAR Oral Toxicity", "content": "The third experiment used data from the QSAR Oral Toxicity dataset (Ballabio et al., 2019). This dataset was developed at the Milano Chemometrics and QSAR Research Group in Bicocca, Italy, in collaboration with the U.S. Environmental Protection Agency. The researchers used a set of chemicals provided by the ICCVAM Acute Toxicity Workgroup (U.S. Department of Health and Human Services) to develop in-silico models for the purpose of predicting oral systemic toxicity for filling regulatory needs. In this experiment, AutoML accurate method performed 2.17% better than Google AutoML whilst training 24 times faster. Table 5 shows the breakdown of the Jaccard Indices for each of the classes in the QSAR Oral Toxicity model. For each of the classes and methods, Extreme AutoML outperformed Google AutoML in terms of Jaccard Indices. Most notably, in this unbalanced dataset, the Jaccard Index for the underrepresented class was more than 2x higher for the Extreme AutoML model than the Google AutoML model."}, {"title": "d) CNAE-9 Business Classiciation", "content": "The CNAE-9 dataset (Ciarelli and Oliveira, 2012) contains vectorized representations of 108 documents of free-text business descriptions of Brazilian companies organized into a subset of 9 categories catalogued in the National Classification of Economic Activities database. Preprocessing steps conducted by the researchers included removing prepositions, transforming words into their canonical form, and vectorizing each document where the weight of each word is its frequency in the document. This dataset is highly sparse, with over 99% of the matrix being filled with zeros. Using this data set, our Extreme AutoML approach performed 1.4% better than Google AutoML, whilst training 1760 times faster. Figure 5 shows the breakdown of the Jaccard Indices for 269 each of the classes in the CNAE9 Business Classification model. Our AutoML's minimum Jaccard Index was higher than Google AutoML by 0.1, a 20% improvement."}, {"title": "e) Classification Results Summary", "content": "In this section, we share the overall classification performance of the two methodologies by comparing relative error rates, training times, and variance (both relative and absolute) of Jaccard Indices across classes for all datasets. We begin by presenting the relative error rates in Figure 5 below."}, {"title": "IV. REGRESSION RESULTS", "content": ""}, {"title": "B. Regression Results", "content": ""}, {"title": "a) Movie Revenue Prediction", "content": "The movie industry generates billions of dollars of revenue annually. The industry has, however, historically struggled with predicting which movies will end up being successful and which will end up flopping. Given the large investment needed to produce modern movies, it is highly desirable to understand the likely outcome of any given movie release. To that end, several researchers have attempted to predict movie success as defined by various success metrics. Several studies have attempted to predict movie popularity, normally 307 partitioned into a few categories (Vijarania et al., 2022; Lakshmi et al., 2020; Iqbal et al., 2021; Sahu 308 et al., 2023; Mbunge et al., 2022). From a business planning point of view, predicting the actual revenue generated by a movie is significantly more desirable. This, up to this point, has proven quite difficult. Though a number of publications report results for movie revenue prediction (Mbunge et al., 2022; Zhang et al., 2009; Zhou et al., 2019; Zhou et al., 2018), these do not actually attempt to predict the numerical revenue. Rather, the attempt to classify the movie revenue into a handful of classes, which is a much more limited type of information. Even with that constraint, the best results have relatively modest, with the best current outcomes for American movies standing at around 55% accuracy for classification into six classes (Zhou et al., 2018). Here, we report the application of Extreme Auto ML technology to predict the revenue of American movies. This was motivated by both commercial considerations, as well as our desire to demonstrate Extreme AutoML on a full regression problem. The data was extracted from the very popular IMDB website. The data sets contain information such as the movie budget, the movie genre, the release date, the full list of the cast by name, and the full list of the crew by name. The data set also contains the generated revenue and the IMDB popularity, which were both measured after the movie release. For this study, we focused on revenue prediction and discarded the popularity data. The non-numerical inputs were one-hot encoded and individuals who appeared in the list only a few times were discarded. Our final data set consisted of 3049 movies for which both the production budget and the final revenue were available."}, {"title": "V. NATURAL LANGUAGE PROCESSING (NLP) RESULTS", "content": ""}, {"title": "A. SMS Spam Classification", "content": "To demonstrate Extreme AutoML's suitability for natural language processing problems, we selected a dataset of 5572 SMS texts from the UCI ML Repository. This corpus is a collection of SMS 342 spam messages, which were manually extracted from the Grumbletext website (a UK forum where users submit text messages, they receive which they believe might be spam). Another subset of 3,375 SMS randomly chosen ham messages from the NUS SMS Corpus (NSC) were added to the corpus. These messages were collected manually by the Department of Computer Science at the National University of Singapore. These messages were mostly produced by Singaporean students attending the university. The messages were collected from volunteers who were knowingly aware that their contributions were to be made public. Additionally, a list of 450 SMS ham messages were collected from Caroline Tag's PhD Thesis. Finally, the corpus contained the SMS Spam Corpus v.0.1 Big, which contains 1,002 SMS ham messages and 322 spam messages. In this experiment, two Extreme AutoML classification models were trained using industry-standard feature extraction techniques the first using BERT (Devlin et al., 2019) and the second using RoBERTa (Liu et al., 2019). These results were then compared to results obtained by using the OpenAI platform which uses GPT-3 (Brown et al., 2020), the state-of-the-art language model (at the time of publication) which powers ChatGPT. For reference, we also included classification benchmarks using a convolutional neural network trained with Word2Vec (Mikolov et al., 2013), a previous generation feature extraction technique, as well as a multinomial Na\u00efve Bayes model trained using TF-IDF (Sammut et al., 2010). For these less sophisticated methods, SMOTE oversampling (Chawla et al., 2002) was utilized to artificially bring 360 the target \"spam\" class from approximately 13% up to 50%."}, {"title": "VI. CONLUSIONS AND FUTURE WORK", "content": "In this paper, we compare Extreme AutoML to state-of-the-art approaches for various machine learning contexts. We compare the classification performance on several classification datasets from the UCI repository using Google AutoML and Extreme AutoML. We compare performance with a regression problem of movie revenue prediction between Extreme AutoML and XGBoost. We also analyzed the performance of Extreme AutoML on an NLP dataset, comparing the results to OpenAI, as well as several more traditional methodologies. We also provide an overview of Extreme AutoML's novel approach, differentiating it from the near-ubiquitous Deep Learning paradigm. We show significantly better results on a number of key metrics of interest for the Extreme AutoML approach for classification problems, regression problems, and NLP applications. In future work, we plan to do additional benchmarking across an even wider range of machine-learning applications."}, {"title": "VII. AUTHOR CONTRIBUTIONS", "content": "E. R., E. F., B. W., and C. D. are all employed by Verseon International Corp. A. M. is a consultant to Verseon International Corp."}, {"title": "VIII. FUNDING", "content": "This research received no external funding."}, {"title": "IX. ACKNOLOWLEDGEMENTS", "content": "The content of this manuscript has been presented, in part, at the IEEE Extreme Learning Machine 2021 Conference, (Warner, et al., 2023)."}, {"title": "X. DATA AVAILABILITY STATEMENT", "content": "The regression dataset analyzed for this study can be found in the Film Success GitHub repository [https://github.com/ryan-anderson-560ds/explorations/blob/master/film_success/tmdb_5000_movies.csv]. The rest of the data is available from the UCI Repository."}]}