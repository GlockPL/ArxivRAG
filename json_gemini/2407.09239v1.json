{"title": "FedVAE: Trajectory privacy preserving based on Federated Variational AutoEncoder", "authors": ["Yuchen Jiang", "Ying Wu", "Shiyao Zhang", "James J.Q. Yu"], "abstract": "The use of trajectory data with abundant spatial- temporal information is pivotal in Intelligent Transport Systems (ITS) and various traffic system tasks. Location-Based Services (LBS) capitalize on this trajectory data to offer users person- alized services tailored to their location information. However, this trajectory data contains sensitive information about users' movement patterns and habits, necessitating confidentiality and protection from unknown collectors. To address this challenge, privacy-preserving methods like K-anonymity and Differential Privacy have been proposed to safeguard private information in the dataset. Despite their effectiveness, these methods can impact the original features by introducing perturbations or generating unrealistic trajectory data, leading to suboptimal performance in downstream tasks. To overcome these limitations, we propose a Federated Variational AutoEncoder (FedVAE) approach, which effectively generates a new trajectory dataset while preserving the confidentiality of private information and retaining the structure of the original features. In addition, FedVAE leverages Varia- tional AutoEncoder (VAE) to maintain the original feature space and generate new trajectory data, and incorporates Federated Learning (FL) during the training stage, ensuring that users' data remains locally stored to protect their personal information. The results demonstrate its superior performance compared to other existing methods, affirming FedVAE as a promising solution for enhancing data privacy and utility in location-based applications.", "sections": [{"title": "I. INTRODUCTION", "content": "With the increasing popularity of GPS-embedded devices, data collection, and data mining technologies, a vast amount of trajectory data has been generated [1]. This data is widely utilized in various domains, including travel time prediction [2] and location-based services [3]. These applications serve as crucial components in enabling the adaptive development of ITS. However, the collection of trajectory data raises signif- icant privacy concerns as it may contain sensitive information about users' daily lives [4]. If the data is not adequately protected, it can be susceptible to misuse and unauthorized access, potentially leading to privacy breaches and harm to individuals. Therefore, it is crucial to prioritize the protection of users' privacy when utilizing such data.\nRecently, there has been a growing interest in the develop- ment of privacy-preserving methods for GPS trajectory data.\n[5] propose a method based on the K-Anonymity technique to generate new trajectory data from real datasets. Addition- ally, Differential Privacy (DP), introduced by [6], has been utilized to protect against possible attacks by applying Laplace Noise to location data. However, these methods often modify trajectory data, which could introduce bias and compromise the integrity of the entire database. Therefore, it is important to balance privacy preservation and data utility. To achieve this, we turn to machine learning methods that are efficient in extracting the features of the dataset. It is assumed that the dataset is generated from underlying latent space so that models can capture the latent representation of the dataset. Therefore, we need a generative model that approximates the data probability distribution by Bayesian inference as well as generating an entirely new dataset. Thus, the Variational Au- toEncoder (VAE) model is proposed to generate a new dataset with a similar feature space and data distribution compared with the original dataset. Besides, Federated learning (FL) provides a way to maintain user privacy in centralized data settings for deep learning models. The training process occurs locally on devices or edge servers, allowing the model to learn from decentralized data without sending individual data to a central server. This approach strikes a balance between utilizing valuable data for model training and preserving user privacy, making it a promising framework for privacy-preserving deep learning in real-world applications [7].\nIn this paper, we address the privacy-preserving task for tra- jectory datasets by employing the federated learning approach alongside trajectory generation methods. To contextualize our research, we comprehensively review and compare existing privacy-preserving methods specifically tailored for trajectory datasets. We also explore various trajectory data generation approaches and delve into the realm of federated learning, providing a crucial foundation for the subsequent methodology introduction. We take advantage of the FL framework and VAE model to propose a novel methodology, Federated Variational AutoEncoder (FedVAE), for generating new trajectory data based on actual data while preserving user privacy. We evalu- ate our approach in both privacy and utility metrics. Especially, our approach is evaluated in a practical downstream task, namely, traffic mode identification (TMI), to demonstrate its utility. The experimental results showcase the exceptional data utility of the generated dataset while maintaining user location privacy. The workflow of the proposed theme is illustrated"}, {"title": "II. RELATED WORK", "content": "Over the past few decades, researchers have proposed vari- ous approaches to address the challenge of preserving location privacy in LBS. These approaches can be broadly classified into two main architectures: centralized and non-centralized. In a centralized architecture, a centralized entity is employed to protect location privacy. The most widely used method is K-anonymity [8], which ensures that each data point is indistinguishable from at least k-1 other data points [9], [10]. It is commonly applied in sensitive databases to prevent the identification of unique users through queries. On the other hand, non-centralized architectures include obfuscation-based methods, such as introducing perturbations into collected or quantizing locations [6], as well as cryptographic-based meth- ods [11]. However, these approaches have their drawbacks. For example, finding a trusted third party for centralized methods and cryptographic-based methods [11] is a challenging task. Besides, obfuscation-based methods can be vulnerable to background knowledge attacks [12], where attackers can apply additional information to de-anonymize users.\nTo summarize, previous methods for preserving privacy in trajectory data overlooked semantic information, resulting in a loss of dataset utility. Additionally, approaches involving cryp- tographic or clustering operations are unsuitable for handling sparse and large datasets. Hence, a trajectory generation-based method is proposed using a VAE model, maintaining the origi- nal feature space and producing new data. In line with real-life scenarios, FL is applied to the training process, ensuring users' data is kept locally and not exposed to other devices, thus protecting users' privacy and improving operational efficiency."}, {"title": "B. Trajectory generation", "content": "Trajectory generation methods are utilized to enhance the feature space in sparse data or reduce noise in noisy datasets, making the data more informative and useful for subsequent tasks. There are several methods for generating trajectory data. [13] generates new trajectory data by space discretization and synthesis according to mobility patterns and movable constraints. [14], [15] use machine learning to generate a new dataset from the original dataset. However, they are unsuitable for our goal of maintaining the original feature space, which is important in subsequent tasks. Besides, training GAN-based models can be challenging due to gradient vanishing and explosion issues. Therefore, we turn to VAE-based models, generally used for data augmentation [16]. They focus on both reconstruction and distribution loss, making them effective for data generation."}, {"title": "C. Federated Learning", "content": "In the conventional machine learning paradigm, data is typically sent to central servers for training. However, this raises concerns about privacy and data security. To address these concerns, FL has emerged as a solution to facilitate com- munication between local clients and central servers without transferring the original data [17]. The key idea is that the clients contribute to the model training process by uploading their local updates of the model's gradients to the servers instead of sharing raw data. Then these updates are aggregated on the servers to create a comprehensive model. This approach ensures the privacy and security of the data, as the raw data remains on the client's local devices.\nIn the context of FL, a commonly used approach is federated averaging (FedAVG) [18]. In FedAVG, the locally trained models are weighted according to the size of the respective"}, {"title": "IV. METHODOLOGY", "content": "In this section, we introduce the proposed VAE model for trajectory generation within the local client, which describes the mechanics of VAE. We also present the federated learn- ing framework, which enables the training process, thereby achieving communication-efficient training."}, {"title": "A. Local VAE Model for Trajectory Generation", "content": "We propose a VAE model for generating new trajectory data in the local clients, as illustrated in Figure 2. It consists of two fundamental components: an encoder and a decoder. The encoder module aims to capture the underlying latent representation of the input data (i.e., GPS trajectory and travel mode labels). In contrast, the decoder module focuses on generating synthetic data that aligns with the distribution of the original training data from the latent vector.\n1) Encoder module: Given a collection of GPS trajectories, we first pass them into Recurrent Neural Network (RNN)- based layers to capture the sequential features. Additionally, linear layers are employed to incorporate auxiliary features such as traffic modes and related attributes into the model. The resulting encoder produces a latent representation \\( z \\), which is further transformed via a non-linear function to produce a probability distribution \\( p_{\\theta}(x) \\) over the latent space. Subsequently, a set of generative latent vectors is sampled from the distribution and passed into the decoder module to generate synthetic trajectory data.\nHowever, directly computing the probability distribution \\( p_{\\theta}(x) \\) is computationally challenging due to its complexity. To overcome this issue, Bayesian inference is employed by incorporating a prior distribution \\( p_{\\epsilon}(z) \\) and the true posterior"}, {"title": null, "content": "distribution \\( p_{\\theta}(z|x) \\) [21]. In this paper, we assume a standard Gaussian distribution as the prior distribution \\( p_{\\theta}(z) \\). The true posterior distribution is then approximated using variational inference [21], [22] by minimizing the Kullback-Leibler (KL) divergence between \\( p_{\\theta}(x|z) \\) and an approximate posterior distribution \\( q_{\\phi}(x|z) \\). Instead of directly using a variational distribution, we employ an inference model parameterized by \\( \\phi \\) to generate the mean \\( \\mu \\) and variance \\( \\sigma \\) of the approximat- ing variational distribution. This allows us to formulate the minimization process as follows:\n\\[\\n\\ln p_{\\theta}(x) = L_{\\theta,\\phi}(x) + KL(q_{\\phi}(z|x)||P_{\\theta}(z|x)),\\n\\]\nwhere \\( \\ln() \\) is the natural logarithm operator.\nThis form can be obtained by averaging the objective function over all data as:\n\\[\\nL_{\\theta,\\phi}(x) = E_{q_{\\phi}(z|x)}[\\ln p_{\\epsilon}(x|z)] - KL(q_{\\phi}(z|x)||p_{\\theta}(z)).\\n\\]\nThe first term in Eq. 2 corresponds to the reconstruction loss, which quantifies the negative log-likelihood of the input data \\( x \\) given the latent vector \\( z \\). It measures how well the decoder reconstructs the original input. The second term rep- resents the regularization term, which computes the Kullback- Leibler (KL) divergence between the posterior distribution \\( q(z|x) \\) and the prior distribution \\( p_{\\epsilon}(z) \\). This regularization term encourages the posterior distribution to closely match the prior distribution closely, thereby preventing the model from overfitting and ensuring a more structured latent space.\nWe can obtain an unbiased estimation of Eq. 2 by sampling \\( z \\sim q_{\\phi} \\) and performing stochastic gradient ascent to optimize it. However, a challenge arises when updating the model's weights due to the inability to differentiate the sampling op- eration from a Gaussian distribution during backpropagation. To address this, we employ the reparameterization trick [23]. It involves sampling \\( \\epsilon \\) from a standard Gaussian distribution \\( \\epsilon \\sim N(0, I) \\) and constructing the latent vector as \\( z = \\mu + \\sigma\\epsilon \\).\n2) Decoder module: After sampling from the posterior distribution \\( z \\sim q_{\\phi} \\), the decoder module is responsible for reconstructing the original input data \\( x \\) from the latent vector \\( z \\). The decoder module is composed of RNN-based layers and linear layers. The RNN-based layers and the linear layer decode the latent vector \\( z \\) into trajectory decoding \\( Tr_i \\) and feature recovery \\( Em_i \\) respectively, which are subsequently fed into the linear layers to reconstruct the original input data.\n3) Optimization: Our loss function comprises two com- ponents: the reconstruction loss \\( L_r \\) and the Kullback-Leibler (KL) divergence loss \\( L_{kl} \\), as mentioned in Section IV-A1. The KL divergence loss ensures the alignment between the latent vector space and a standard Gaussian distribution, regulating the distribution difference. The reconstruction loss consists of two parts: the trajectory generation loss and the embedding feature loss. Our paper focuses on the downstream task of traffic mode identification. Hence, the trajectory generation loss is defined as the Mean Squared Error (MSE) between the trajectory decoding \\( Tr_i \\) and the original trajectory \\( Tr_i \\). Meanwhile, the embedding feature loss is calculated as the Cross-Entropy Loss (CEL) between the embedding feature\n\\( Em_i \\) and the feature recovery \\( Em_i \\). The optimization target \\( L \\) of the proposed model is formulated as follows:\n\\[\\nL = L_r + L_{kl} = \\sum_{i=1}^{n}(Tr_i - Tr'_i)^2 - \\sum_{i=1}^{n} Em'_i \\log(Em_i) + KL(q(\\phi)(z|x)||p_{\\theta}(z)),\\n\\]\nwhere \\( \\log() \\) is the logarithm operator.\nWe employ a truncated function in our trajectory generation loss to improve the generalization of newly generated trajecto- ries. We establish a threshold to ensure that the reconstruction loss remains within a reasonable range for real-life scenarios. When the reconstruction loss surpasses this threshold, it is truncated to zero, resulting in only the KL divergence loss \\( L_{kl} \\) being utilized for model updates. In this study, we set the threshold to 0.000625 for MSE reconstruction loss, corresponding to a geographic distance error of fewer than 4 kilometers for the reconstructed trajectories."}, {"title": "B. Global Federated Training Framework", "content": "Figure 3 shows the whole training framework. Details are described below:\n1) Initialization: The central server has an initial central model and each local client has an initial local model. During each epoch, the model of each client is initialized with the weights of the central model.\n2) Training: The training process is distributed across client servers instead of central servers. As described above, to minimize the amount of raw data stored on central servers, clients contribute to the model training process by uploading their local updates of the model's gradients.\n3) Aggregation: Subsequently, the central server uses the FedAVG algorithm to update the model's weights from clients' gradients. The federated framework ensures that the original data is not directly collected by the central server while still enabling the successful training of the global model necessary for our specific objectives.\n4) Communication overhead: Considering realistic situa- tions, communication overhead needs to be discussed. When the client number is small, a small-scale federated learning model is built up by the FedAVG algorithm. When large-scale"}, {"title": "V. EXPERIMENT", "content": "In this section, we introduce the dataset, competing baseline, experiment set, and evaluation metrics in detail. We analyze the results in terms of privacy analysis with anonymization, trajectory statistics between the original trajectory data and the generated data, as well as the utility application in the downstream task TMI."}, {"title": "A. Dataset", "content": "We employ Microsoft's Geolife dataset [24], [25] for our experiment, which is extensively utilized for traffic mode identification [26]. The dataset comprises both labeled and unlabeled data, collected from a total of 182 users, including 69 users with labeled data and 113 users with unlabeled data. For five years, the users record their traffic mode data in the form of Global Positioning System (GPS) points and timestamps, along with the corresponding traffic mode, which encompasses activities such as walking, biking, and bus transit.\nMoreover, the collection of raw data from users varies in length, thus requiring pre-processing steps such as cutting and padding. According to the Geolife dataset, we divide each tra- jectory into sub-sequences of length 100, which is a reasonable length that contains enough traffic mode information, and pads shorter sequences with zeros. Additionally, a mask matrix is constructed to record padded segments and distinguish valid and invalid parts for loss computation by binary values. For unpadded segments, the mask is a sequence of ones with a length of 100."}, {"title": "B. Competing Baseline", "content": "To demonstrate the applicability of FedVAE, we adopt three representative methods for traffic mode identification, which are K-Neighbor and MLP and Semi-supervised Convolutional AutoEncoder. We also select three privacy-preserving methods for trajectory data and compare their performance in the traffic mode identification task. It is noticed that the performance is evaluated by accuracy and variance in TMI tasks.\n\u2022 Perturbation. This approach randomly perturbs each lo- cation point so that the privacy information will be ambiguous.\n\u2022 Mixzone [5]. Mixzone aims to find a spatiotemporal zone in which multiple trajectories traverse. Then mixing and perturbing operations are applied to these trajectory data so that the adversaries can not identify each trajectory.\n\u2022 K-Anonymity [10]. This method generates another k - 1 trajectory based on K-Anonymity. It generates k - 1 points around each selected sensitive point with private information like homes and workplaces. It randomly connects these k - 1 location point pairs with other nonsensitive location points into k - 1 trajectories to protect the original trajectory.\nBesides, we controlled the hyper-parameters of these base- line methods to get the optimal performance. From the given range of parameters, we test their performances in the TMI task to judge the best parameter combination. For Mixzone, we choose the best pair of hyper-parameters with \\( k \\) as 6, which stands for the number of users passing through the zone, and L-limit as 0.1, which controls the length limit of each trajectory included in the zone. As for K-Anonymity, we choose k as 5, which represents the trajectory anonymous degree, to achieve optimal performance."}, {"title": "C. Experiment settings", "content": "We implemented our model using PyTorch. The model is trained on the server with 2.1 GHz Intel Xeon CPU E5-2620 v4 CPUs, 128G RAM, and nVidia 2080Ti 11G GPUs. The model is trained using Adam optimizer with an initial learning rate of 0.01, and the learning rate turns to 0.001 when 500 epochs are finished. The batch size is set to 2000. We split the whole dataset into train, test and validation sets with the rate of 8:1:1 to avoid over-fitting. The model is trained for 2000 epochs, and early stopping is applied when the loss is not changing anymore.\nBesides, for the federated training stage, we set the client number as 69 to meet the real-world situation, as our dataset includes 69 users with labeled data. FedAVG algorithm to- gether with the Joint-Announcement protocol is used to handle large-scale training scenarios. The hyperparameters in the model are the same for each local client."}, {"title": "D. Evaluation Metrics", "content": "We employ three metrics to evaluate the performance of the proposed models. Firstly, privacy protection performance is evaluated in terms of anonymized level, by comparing similarity across different travel modes. Lower similarity indi- cates a higher anonymized level. Additionally, we evaluate the statistical properties of the generated and original trajectory distributions using KL divergence. A lower KL divergence signifies a more similar distribution of trajectories between them. Furthermore, we compare the experiment results and show the improvement between our and the best of others.\nPrivacy metric: The dataset's privacy level is evaluated by the similarity of the original and generated one. Higher similarity means a higher risk of attacks as attackers can identify the user of the trajectories when generated trajectories are similar to the original one. We evaluate the similarity by applying relative distance between GPS points on the trajectory. Given two trajectories \\( P \\) and \\( P' \\) and their traffic mode, we define their similarity of them:\n\\[\\n\\text{Similarity}(P, P', \\text{mode}) = \\alpha \\frac{\\beta_{\\text{mode}}}{\\text{dist}(P,P')} = \\alpha \\frac{\\beta_{\\text{mode}}}{\\frac{1}{n} \\sum_{i=1}^{n} \\text{dist}(p_i, P'_i)}.\\n\\]"}, {"title": "E. Experiment Analysis", "content": "Table I provides a comprehensive comparison of various privacy-preserving methods utilized in the context of the TMI task. The evaluation revolves around two key metrics: Similar- ity, which reflects the level of privacy protection (lower values indicate better privacy anonymization), and Utility, which is assessed through classification accuracy (higher values are desirable) and variance (lower values are preferred) in the TMI task. The evaluation experiments are conducted several times and the average of results are recorded.\nPrivacy Analysis: As shown in Table I, the proposed Fed- VAE model achieves the most substantial privacy preservation with a low Similarity value of 0.20, outperforming other models. It demonstrates a remarkable 60.78% enhancement in privacy protection. FedVAE generates synthetic trajectories with minimal similarity to the original data. By creating entirely new trajectories, the model reduces the risk of privacy attacks and protects individual user information effectively.\nUtility Analysis: The utility of the generated trajectory datasets is evaluated using the travel mode classification ac- curacy and its variance, as depicted in Table I. The proposed FedVAE model demonstrates superior accuracy across all base models, achieving values of 82.53%, 78.35%, and 91.04%"}, {"title": "VI. DISCUSSION", "content": "1) Model Scalability: In addition to the aforementioned experiments, we have also conducted tests on our method to evaluate its stability in the federated learning structure, which is crucial for ensuring its continued effectiveness as the number of clients increases or decreases. The model suc- cessfully converged regardless of the variation in the number"}, {"title": "VII. CONCLUSION", "content": "In this research, we proposed a FedVAE model to address privacy-preserving tasks for trajectory datasets, which com- bines federated learning and VAE techniques to maintain the original feature space and ensure privacy protection when gen- erating synthetic trajectories. Our comprehensive experiments and analysis show that FedVAE outperforms other privacy- preserving models, achieving the lowest similarity value which indicates its effectiveness in the privacy protection task, and the highest travel mode identification accuracy which exhibits great utility in a downstream task. Furthermore, the generated trajectories showed similar patterns when compared with the original trajectory data."}]}