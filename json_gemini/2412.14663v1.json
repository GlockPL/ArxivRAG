{"title": "IOHunter: Graph Foundation Model to Uncover Online Information Operations", "authors": ["Marco Minici", "Luca Luceri", "Francesco Fabbri", "Emilio Ferrara"], "abstract": "Social media platforms have become vital spaces for public discourse, serving as modern agor\u00e1s where a wide range of voices influence societal narratives. However, their open nature also makes them vulnerable to exploitation by malicious actors, including state-sponsored entities, who can conduct information operations (IOs) to manipulate public opinion. The spread of misinformation, false news, and misleading claims threatens democratic processes and societal cohesion, making it crucial to develop methods for the timely detection of inauthentic activity to protect the integrity of online discourse. In this work, we introduce a methodology designed to identify users orchestrating information operations, a.k.a. IO drivers, across various influence campaigns. Our framework, named IOHunter, leverages the combined strengths of Language Models and Graph Neural Networks to improve generalization in supervised, scarcely-supervised, and cross-IO contexts. Our approach achieves state-of-the-art performance across multiple sets of IOs originating from six countries, significantly surpassing existing approaches. This research marks a step toward developing Graph Foundation Models specifically tailored for the task of IO detection on social media platforms.", "sections": [{"title": "Introduction", "content": "Online social media platforms have become essential for fostering public discourse, where users engage in debates on critical political and social issues. The integrity of these online spaces is paramount, given their significant role in shaping public opinion and influencing societal outcomes, such as elections or public health interventions (Starbird 2019; Ferrara 2015; Nogara et al. 2022). However, these platforms are increasingly vulnerable to state-sponsored Information Operations (IOs), which seek to manipulate narratives, spread disinformation, and foster division through the promotion of hate speech and other harmful content (Badawy, Ferrara, and Lerman 2018; Zannettou et al. 2019; Suresh et al. 2024; Minici et al. 2024). The proliferation of such campaigns poses a significant threat to democratic processes, highlighting the urgent need for robust methods to detect and mitigate these operations (World Economic Forum 2024).\nThe development of machine learning techniques for IO detection is a rapidly growing area of research. Recent studies, such as Luceri et al. 2024, have demonstrated the potential to leverage graph machine learning techniques for this purpose. Specifically, they leverage node2vec embeddings of similarity networks constructed from behavioral traces, such as co-sharing patterns, to detect coordinated users driving IOs, namely IO drivers. Their findings highlight the potential of using topological structures based on similarity patterns, combined with graph machine learning techniques, for detecting IOs. However, they did not explore whether recent advancements in Graph Neural Networks (GNNs) could further improve performance. GNN-based approaches not only provide a more powerful framework for modeling online user behavior but also offer inductive capabilities, enabling generalization to nodes not seen during training. This flexibility is particularly crucial for deploying auditing tools in dynamic environments, where threats can arise from new users or, even more critically, from IOs originating in different geopolitical contexts.\nGeneralizing across different IOs-referred to here as cross-IO detection is inherently difficult, as distinct IOs often employ different coordination strategies and may operate in different languages (Luceri et al. 2024).\nContribution of this work. In this paper, we propose IOHunter, an architecture for IO detection that combines the message-passing paradigm of GNNs with multi-modal information derived from both network structure and textual content. Unlike existing approaches that are either based on graph structure or textual content, IOHunter builds on the emerging concept of Graph Foundation Models (GFMs). Traditional GNNs are typically trained from scratch on specific tasks and datasets, limiting their ability to generalize across different domains. In contrast, IOHunter integrates GNNs with embeddings extracted from Language Models to create a GFM capable of leveraging large-scale, diverse graph data with the goal of rapidly adapting to new tasks or datasets. Our approach is thoroughly detailed in the Methodology section. We evaluate IOHunter on six datasets from Twitter, each representing an IO originating from distinct geopolitical contexts: UAE, Cuba, Russia, Venezuela, Iran, and China. IOHunter achieves improvements of up to"}, {"title": "Related Work", "content": "Research in IO detection has extensively analyzed individual account activities to detect participation in influence campaigns, particularly focusing on bots (software-controlled accounts) and trolls (state-backed human operators) (Mazza et al. 2022; Ferrara 2023). Bot detection has been a focal point, with various solutions utilizing machine learning strategies to (i) identify bot characteristics, such as posting frequency, content patterns, and network behavior (Yang et al. 2019; Chen and Subramanian 2018; Cresci et al. 2016), and/or (ii) distinguish patterns of bot behavior from organic human behavior (Pozzana and Ferrara 2020). Notably, the Botometer tool (Yang et al. 2019; Yang, Ferrara, and Menczer 2022) has played a significant role in scaling bot activity research on Twitter, enabling studies focused on the identification of bot-driven influence campaigns (Shao et al. 2018; Stella, Ferrara, and De Domenico 2018; Deb et al. 2019; Grinberg et al. 2019; Luceri et al. 2019).\nHowever, recent studies have emphasized that IO coordination extends beyond automated bots, highlighting the role of human-operated trolls in these operations (Nizzoli et al. 2021; Hristakieva et al. 2022). Research on state-sponsored trolls has been categorized into three primary detection methods: content-based, behavioral-based, and sequence-based approaches. Content-based methods analyze the linguistic features of posts to identify deceptive or coordinated messaging (Alizadeh et al. 2020; Luceri, Boniardi, and Ferrara 2024; Im et al. 2020). Behavioral-based approaches focus on user activity patterns, such as posting activity and interaction signals, to detect coordinated inauthentic behavior (Luceri, Giordano, and Ferrara 2020; Kong et al. 2023; Sharma et al. 2021). Sequence-based techniques, on the other hand, model the temporal sequence of actions to uncover orchestrated activities over time (Nwala, Flammini, and Menczer 2023; Ezzeddine et al. 2023)."}, {"title": "Network-Based IO Detection", "content": "In addition to machine learning-based methods, a significant body of research has focused on detecting IOs through network-based approaches. These methods aim to uncover tactics of online coordination by identifying unexpected or exceptional similarities in the actions of multiple users (Pacheco, Flammini, and Menczer 2020; Pacheco et al. 2021; Nizzoli et al. 2021; Mannocci et al. 2024; Magelinski, Ng, and Carley 2022; Luceri et al. 2024). The underlying assumption is that connections between highly similar users-such as those who share the same content, use similar hashtags, or post at synchronized times can reveal coordinated clusters likely engaged in IOs.\nNetwork-based detection typically involves constructing networks that represent user similarities using edge weights, where higher weights indicate stronger behavioral correlations. By exploiting network properties to filter out organic users, researchers identify clusters of users exhibiting collective similarity and potentially driving IOs (Pacheco et al. 2021; Luceri et al. 2024). This approach has proven effective in revealing coordinated activities, providing valuable insights into the structure and scale of influence campaigns."}, {"title": "Graph Foundation Model", "content": "The challenge of training models capable of generalizing across diverse graph domains and tasks has recently attracted significant attention (Mao et al. 2024). Earlier work in this area has focused on self-supervised approaches to enable rapid adaptation to downstream tasks on the same graph (Lu et al. 2021; De Nadai et al. 2024) or to generalize across graphs from different domains (Qiu et al. 2020; Jiang et al. 2021). However, these methods do not address the challenge of integrating multi-modal information.\nRecent advancements have explored the use of LMs to generate transferable features in heterogeneous graph settings, such as personalization (Damianou et al. 2024) and e-commerce applications (Xie et al. 2023). Others, like PRODIGY (Huang et al. 2024) and OFA (Liu et al. 2024), focus on adapting graph tasks to leverage the generalization capabilities of LLMs for in-context learning tasks.\nIn contrast, our approach specifically targets the problem of IO detection across three distinct learning regimes. Within this context, we demonstrate that integrating multi-modal signals combined with massive pre-training-while keeping the LM weights frozen-is an effective strategy to achieve a GFM tailored to the IO detection task."}, {"title": "Problem Definition", "content": "We are given an undirected graph $G = (V, E)$, where $V = \\{v_1, ..., v_n\\}$ represents the set of nodes, and $E \\subset V \\times V$ denotes the set of edges. In this context, G models the relationships between social media users, with an edge $l(v_1, v_2) \\in E$ existing if two users $v_1$ and $v_2$ are considered similar. We will also refer to G as the similarity network\u00b9.\nFor each user $v_i \\in V$, we have access to a set of content $C_i$ (e.g., texts, images) that $v_i$ has shared on the social network. Additionally, each user $v_i$ is associated with a label $Y_i \\in \\{0, 1\\}$, where 1 indicates an IO driver and 0 represents a legitimate user.\nOur objective is to learn two functions: a multi-modal projection $p : V \\rightarrow \\mathbb{R}^d$ and a probabilistic node classifier $f_{\\theta} : \\mathbb{R}^d \\rightarrow [0, 1]$. The multi-modal projection $p_{\\psi}$ maps each node $v_i$ to a point $z_i = p_{\\psi}(V_i | G, C_i)$ in a d-dimensional latent space, utilizing both the contextual information from G and the content $C_i$ shared by the user. For simplicity, we will refer to this embedding as $p_{\\psi}(V_i)$.\nThe node classifier $f_{\\theta}$ takes the low-dimensional representation $z_i$ as input and outputs a score $s_i = f_{\\theta}(z_i)$, indicating the likelihood that $v_i$ is an IO driver. Given that our task is a binary classification problem, we optimize the complete set of learnable parameters $\\Theta = \\{\\psi, \\theta\\}$ by minimizing"}, {"title": "Methodology", "content": "Our objective is to detect IO drivers by integrating two sources derived from the behavioral traces of social media users: (i) the textual content they share and (ii) the similitude of their sharing activities as captured by similarity networks. Our approach, illustrated in Fig. 1, begins by extracting textual embeddings from user-shared posts and graph embeddings from the Fused Similarity Network (see below). These two data modalities are then blended using a cross-attention module, allowing the model to learn interactions between the content and network contexts. The resulting multi-modal embeddings are subsequently input into a GNN, which leverages this enriched representation to accurately predict user categories.\nThe process of constructing a similarity graph generally follows a consistent approach in the literature (Pacheco, Flammini, and Menczer 2020; Pacheco et al. 2021; Luceri et al. 2024). We consider different similarities including the sharing of identical links (co-URL), hashtags (co-hashtag), or content (text similarity), the re-sharing of the same tweets (co-retweet), and automation-driven actions such as rapid retweeting (fast-retweet) to build five distinct similarity networks. We construct a bipartite graph between users and entities, where the entities correspond to the specific behavioral trace being analyzed (e.g., for the Co-URL trace, the entities are the URLs). The Fast Retweet bipartite network is constructed similarly to the co-retweet bipartite network, but it excludes connections where the retweet takes more than 10 seconds. In this bipartite network, users are linked to entities based on their sharing activities, with weights assigned using TF-IDF to account for the popularity of each entity. Consequently, each user is represented as a TF-IDF vector of the shared entities. This bipartite graph is then transformed into a similarity network, where users are connected based on the similarity of their behavioral traces.\nBuilding on (Luceri et al. 2024), we combine the five similarity networks by linking two nodes in a if they are connected in any of the individual similarity networks.\nFor each user $v_i$, we extract a low-dimensional embedding from its set of shared content $C_i$. Since the main source of information in our experiments is textual content, we use a Sentence Transformer, SBert (Reimers and Gurevych 2019). We refer to $c_i \\in \\mathbb{R}^{d_c}$ as the content embedding of $v_i$, where $d_c$ is output dimensionality of SBert. If $|C_i| > 1$ then $c_i$ will be the average of the embeddings of each single content in $C_i$.\nTo consider the contextual information provided by the graph G, we abide by the best practice (Cui et al. 2022), and divide degree values into $d_g$ buckets, then map the degree value distributed in each bucket range into one class, and finally construct a unique one-hot vector for each class. Hence, we encode the structural information of each node $v_i$ to a one-hot vector $g_i \\in \\{0, 1\\}^{d_g}$."}, {"title": "Experiments", "content": "This experimental section examines whether our IOHunter can detect IOs on social media networks. We address the following research questions investigating the applicability of our proposal in different, realistic data regimes:\n*   What performance does IOHunter achieve in a supervised IO detection task compared to state-of-the-art methods?\n*   In a more realistic scenario with limited labeled data, can IOHunter maintain strong predictive performance and outperform the best state-of-the-art method in this data regime?\n*   Does a pre-training on a massive dataset enable IOHunter to generalize effectively across unseen IOs?"}, {"title": "Experimental Settings", "content": "We conduct our experiments on 6 datasets from (Seckin et al. 2024), including IO activities in countries such as UAE, Cuba, Russia, Venezuela, Iran, and China. In accordance with previous studies (Luceri et al. 2024), we select these state-sponsored campaigns for their extensive scale, evident from their size in Table 1. Each country can include multiple campaigns, mirroring real-world situations where both campaign-based and organic conversations from a single country might intersect.\nThe datasets exhibit different properties in terms of number of nodes, density, edge homophily and label imbalance. We use the class-insensitive edge homophily (Lim et al. 2021) to evaluate the degree of homophily in each graph. Notably, there is significant variation in homophily across\nTo evaluate IOHunter performances, we compare it with state-of-the-art methods for the task of IO detection. We select two methods introduced by Luceri et al. (2024). The first one, NodePruning categorizes a user as an IO driver depending on their eigenvector centrality in the Fused Similarity Network. If this centrality value exceeds a certain threshold, the user is labeled as an IO driver. The second is based on node2vec (Node2vec+RF), which extracts node embedding based on the local network topology. The node2vec representations of the Fused Similarity Network are then used as input features for a Random Forest classifier to detect whether a user is an IO driver or not. To extend the set of baselines, we also include two more architectures. The first one is a shallow multilayer perceptron (MLP) trained on content-based features (SBert+MLP). Each user is represented by the average of their top 5 most popular tweets' embedding. Those are extracted using a sentence transformer, SBert (Reimers and Gurevych 2019). The last type of archi-"}, {"title": "Supervised Detection of IOs (RQ1)", "content": "Table 2 shows the performances of IOHunter and compares it with other baselines and existing approaches. Our proposed method demonstrates a clear and consistent improvement over the state-of-the-art node2vec+RF across all six datasets, with an average percentage gain of 9.25% in terms of Macro-F1. The performance enhancement is particularly noteworthy, ranging from a gain of +1.8% on the UAE dataset to a +20% on the Iran dataset. This breadth of improvement across diverse datasets underscores the robustness and versatility of our approach, especially in scenarios where traditional methods like node2vec+RF may not fully capture the complexity of the data and diversity of IOs.\nA critical factor in IOHunter success is the effective integration of both structural and textual features, which proves essential for achieving competitive results across all datasets. Relying exclusively on either structural or textual features, as evidenced by the inconsistent performance of the NodePruning and SBert models, falls short of delivering reliable outcomes across IOs. The need to combine both modalities is paramount, as neither feature set alone can encapsulate the full complexity required for effective user classification. The strength of our approach lies in its ability to seamlessly blend these modalities, which is a key driver behind its superior performance across diverse datasets.\nMoreover, the inclusion of a cross-attention mechanism in our model significantly enhances performance compared to a straightforward multi-modal concatenation approach (i.e., GNN in Table 2), as evidenced by superior outcomes on 6 out of the 6 datasets. This improvement is not only reflected in higher absolute performance but also in greater stability. The cross-attention mechanism mitigates the variability often observed in models relying on simple concatenation, which can be sensitive to initial conditions such as random seed variations. By effectively capturing the interactions between different data modalities, the cross-attention mechanism enables a more reliable integration, ensuring consistent and robust results."}, {"title": "IO Detection under Data Scarcity (RQ2)", "content": "To evaluate the robustness and effectiveness of IOHunter, we conducted a series of experiments designed to test its performance under varying levels of data scarcity. We simulated different degrees of sparsification by downsampling the training set to create sparser versions. Specifically, we train our model using only the 0.1%, 1%, 5%, 10%, 25%, and 50% of the original training data. For each level of sparsification, we trained both IOHunter and node2vec+RF, which is the leading approach in the literature for detecting IOs (Luceri et al. 2024). This experimental design allows us to assess the robustness of IOHunter in scenarios where labeled data is extremely limited, a common challenge in"}, {"title": "Generalizable Cross-IO Detection (RQ3)", "content": "To evaluate the cross-IO generalization capability of IOHunter, we designed an experiment inspired by the principles underlying foundation models in computer vision (Zhai et al. 2022; Cherti et al. 2023) and natural language processing (Kaplan et al. 2020; Hernandez et al. 2021). The goal of this experiment is to determine whether pretraining the model on a diverse set of countries can enable it to generalize effectively to a new country for which no training data has been seen during pretraining. Also, we assess whether fine-tuning the pretrained model on a small fraction of data from the test country can further enhance its performance, particularly when labeled data is scarce.\nIn this experiment, we employ a leave-one-out strategy where the model is pretrained on data from all countries except one, which is reserved as the test country. We repeat this process for each of the six countries: Cuba, Russia, Venezuela, China, United Arab Emirates (UAE), and Iran. Following the pretraining phase, we evaluate the model\u2019s performance on the test country both in its pretrained state (referred to as the \u201cOnly PreTrain\u201d strategy) and after fine-tuning it on just 0.1% of the training data from the test country (referred to as the \u201cPreTrain & FineTune on 0.1%\u201d strategy). The results are then compared against a baseline model that is trained only on 0.1% of the test country\u2019s training data without any pretraining.\nCross-country generalization experiments, presented in Table 3, highlight the significant advantages of our pretraining strategy. The \u201cOnly PreTrain\u201d strategy, which involves pretraining on all countries except the test country, achieves remarkable performance. In four out of the six datasets, this strategy surpasses the performance of a model trained in a fully-supervised fashion on 0.1% of the test country\u2019s training data. This outcome demonstrates the model\u2019s strong ability to generalize across different datasets, effectively transferring knowledge from one domain to another. Furthermore, when we apply the \u201cPreTrain & FineTune on 0.1%\u201d strategy, the performance improves even further. Fine-tuning the pretrained model on a tiny percentage of the test country\u2019s data leads to an average improvement of more than 10% in Macro-F1 scores across all countries. This result underscores the power of combining massive pretraining with targeted fine-tuning, as it allows the model to adapt to the characteristics of the new domain with minimal supervision.\nThese findings suggest that pretraining on a diverse set of countries not only equips the model with a strong baseline capability for cross-country generalization but also that fine-tuning on a small fraction of data from the target country can yield substantial performance gains. This approach is particularly valuable in scenarios where labeled data is scarce or expensive to obtain."}, {"title": "Ablation Study", "content": "We present the results of experiments designed to evaluate the importance of three key components of IOHunter: the cross-attention mechanism for integrating the two modalities, the graph modality, and the text modality. The findings of this ablation study are summarized in Table 4.\nOur analysis shows that using a simple concatenation of the two modalities (denoted as \u201cIOHunter w/o CrossAttn\u201d in the table) is suboptimal consistent with the results in Table 2 and offers limited advantages compared to a uni-modal classifier based solely on the graph modality (denoted as \"IOHunter w/o Text\" in the table). This aligns with prior findings on the challenges of training a multi-modal classifier that consistently outperforms the best uni-modal alternative (Wang, Tran, and Feiszli 2020). Moreover, incorporating the text modality via the cross-attention mechanism (denoted as \"IOHunter\" in the table) leads to an approximately 9% improvement over the graph-only approach. This result highlights the need to use both information sources for an effective IO classifier."}, {"title": "Conclusions", "content": "In this work, we introduced IOHunter, a novel GFM designed to detect IOs across various social media platforms. By integrating the strengths of LMs and GNNs, our approach leverages both textual and network-based features to accurately identify IO drivers across multiple countries and campaigns.\nIOHunter significantly outperforms state-of-the-art methods in supervised, scarcely-supervised, and cross-country IO settings. This is achieved through the model\u2019s ability to generalize across diverse and evolving contexts, enabled by pretraining on extensive, multi-country datasets and fine-tuning with minimal labeled data. The robustness of IOHunter in scenarios with limited data availability underscores its practical applicability in real-world settings, where access to labeled data is often limited. Additionally, the cross-country generalization experiments highlight the model\u2019s potential to transfer knowledge between different geopolitical contexts.\nMoving forward, our work paves the way for the development of more sophisticated GFMs tailored to more graph-related tasks. Future research could explore the application of IOHunter to domains where detecting coordinated, malicious activities is critical, as well as the integration of additional data modalities to further improve detection capabilities. Ultimately, IOHunter represents a significant step toward safeguarding the integrity of online discourse by providing a scalable, adaptable, and highly effective solution for uncovering information operations on social media platforms."}]}