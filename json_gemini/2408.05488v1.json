{"title": "Structure and Reduction of MCTS for Explainable-AI", "authors": ["Ronit Bustina", "Claudia V. Goldman"], "abstract": "Complex sequential decision-making planning problems, covering infinite states' space have been shown to be solvable by AlphaZero type of algorithms. Such an approach that trains a neu-ral model while simulating projection of futures with a Monte Carlo Tree Search algorithm were shown to be applicable to real life plan-ning problems. As such, engineers and users interacting with the re-sulting policy of behavior might benefit from obtaining automated explanations about these planners' decisions offline or online. This paper focuses on the information within the Monte Carlo Tree Search data structure. Given its construction, this information contains much of the reasoning of the sequential decision-making algorithm and is essential for its explainability. We show novel methods using in-formation theoretic tools for the simplification and reduction of the Monte Carlo Tree Search and the extraction of information. Such in-formation can be directly used for the construction of human under-standable explanations. We show that basic explainability quantities can be calculated with limited additional computational cost, as an integrated part of the Monte Carlo Tree Search construction process. We focus on the theoretical and algorithmic aspects and provide ex-amples of how the methods presented here can be used in the con-struction of human understandable explanations.", "sections": [{"title": "1 Introduction", "content": "Complex real life planning problems, such as autonomous vehicles' behavior, can be framed as sequential decision-making problems. Given a general route for the vehicle, the vehicle needs to deter-mine the specific steering angle and accelerations that result in what we would consider to be good driving. Due to the complexity of the problem, in which there are many relevant entities with probabilistic behaviors, the preferred solution falls within the reinforcement learn-ing (rl) paradigm [23]. Moreover, due to the very large (practically infinite) state and action spaces in real life problems, a promising approach heavily researched is based on the AlphaZero algorithm [19, 20] which is a model-based algorithm allowing us to perform an evaluation of the specific state encountered in real-time and use off-line learned insights only as prior information [9]. The AlphaZero algorithm builds on the Monte Carlo Tree Search (MCTS) approach [4, 24], which gradually builds a tree from the current state (which is the root of the tree), to depict the possible futures (the evaluation) resulting from different sequences of actions.\nThe motivation for this work is the need to explain the decisions of the planning system to an engineer or user that is experiencing that planner's resulting behavior. As such, this work falls in under ex-plainable AI (\u03a7\u0391\u0399) [6, 1, 17, 16, 10]. Explanations designed specif-ically for automotive applications, meaning during automated func-tions of the vehicle, were also considered in [26], [3] and [7]. We are considering XAI for sequential decision making, which has also received some attention. A wider review of this problem that specif-ically focused on contrastive explanations was done in [11]. Explana-tions as model reconciliation, meaning the explanations come in light of the differences between the model of the AI system and the user model were examined in [5, 21, 22]. Specifically, in [21] the sug-gested approach is to combine the extraction of explanations with the planning problem. The explanations considered in [13] are pol-icy summarization. The goal of policy summarization is to convey the strengths and weaknesses of the agent by demonstrating their be-havior in a subset of informative states. Another work that follows a similar line, but focuses on the explanability of RL agents is [18]. Another approach, considered in [12], focuses on producing more explicable planning results. They do so by learning an explicabil-ity distance function between the AI plans and human's input. This learned explicability distance function is then used as a heuristic to guide the search towards explicable plans. In [14] the authors con-sidered a setting similar to ours, with an RL agent that uses search trees to reach its decision. The problem they are considering is the ability of humans (AI experts) to identify reasoning flaws. They too are faced with the complexity of the search tree, and suggest the con-struction of a user interface to assist in the identification process. The work we suggest here could be a valuable tool to support such efforts.\nFinally, [2], considers the same problem of explainability of MCTS, and gives some high-level directions towards its solution.\nThe XAI for sequential decision making in automated driving is a very complex problem. To simplify the problem we suggest that it can be studied by answering three main questions: When, What and How to explain. The when refers to the decision of whether or not to provide an explanation at any point in time during the ride. The what refers to the actual content of the explanation, and the how refers to the modality in which this explanation will be conveyed. These questions are not independent\u00b9 and the split comes only as a method to simplify the overall problem. Our focus in this work is on the extraction of information from the planner that can assist in determining the above mentioned aspects of the explanations. We shortly provide concrete examples of usage of the methods suggested here relating to both the when and what questions."}, {"title": "2 Entropy of MCTS as a Measure of Structure", "content": "The MCTS algorithm gradually builds a tree, starting from the cur-rent root state, by performing the following four steps over and over again until some time/computation budget is concluded [4]:\n1. Selection: starting from the root node, the selection process goes down the tree until it reaches a leaf node. The specific selec-tion used is the Upper Confidence Bound applied to Trees (UCT) which balances exploitation of actions that have shown to be fa-vorable, and exploration of actions that have not been sufficiently explored.\n2. Expansion: when reaching a leaf node, it can be a terminal node, in which case it cannot be expanded. If the node is not a terminal node, the tree is expanded to the set of actions that can be consid-ered from this node.\n3. Simulation/Neural Network (NN): the properties of the expanded node can be evaluated using a Monte-Carlo simulation, where multiple roll-outs reaching a terminal state are performed to assess the value of the expanded node, and a prior distribution over its ac-tions. In the AlphaZero family of algorithms the off-line learning of the value and prior per state (node) replace this.\n4. Back-propagation: after expanding and extracting the value and prior distribution of the node, this new information is back-propagated all the way up the tree to the root node. The update is done for the accumulated value at each node and the number of visits at each node.\nThus, at every step the tree is expanded by a single node (exclud-ing cases of terminal nodes in which there is no expansion). When the time/computation budget is over, the choice of action at the root node is usually determined as the most visited child of the root. An example of such a tree is given in Figure 1. At each node in the tree the vector corresponding to the number of visits of its children nodes can be considered a probability vector reflecting the choice of the algorithm to expand the tree in one direction over the other. This as-pect, together with the gradual expansion are the main points used next.\nA tree, in which each node contains a probability vector, can be depicted as a discrete random process:\nX0, X1,..., Xn, (1)\nwhere Xo is the random variable over the possible actions considered at the root node, distributed according to the probability vector avail-able at the root. X1 is the random variable over all possible actions from the children of the root node, where the probability can now be extracted from the probability at the root node and the probability vectors at each of its children. We continue this until we reach the leaf nodes of the tree.\nThe entropy measure reflects the uncertainty of a random process. It is maximized if at each node all possible actions are considered and are equally likely (uniformly distributed). The more uniform the distribution the wider the tree, since all options were considered and expanded upon. On the other hand, the more deterministic the pro-cess is, meaning the probability is concentrated on less actions, and less actions were expanded further. In this case the tree is thinner and more concentrated. Thus, an entropy measure at a node gives us insight to the structure of the subtree expanded from that node. Moreover, having at our disposal the entropy measure at every node we enhance our ability to determine the structure of the tree at differ-ent levels of resolution. As explained above, the structure of the tree reflects important aspects in the reasoning of the algorithm and can be directly translated to an explanation. The entropy of trees with unbounded degree was also considered in [8], motivated by a dif-ferent purpose of considering the lossless compression of these data structures.\nOur first goal is to provide efficient methods for calculating the entropy at each node, given that these trees are MCTS that have a specific construction process. As this is a discrete random process, the standard method for calculating its entropy is as follows:\n\u0397 (\u03a7\u03bf, \u03a71,..., Xn) = H (Xo) + H (X1, ..., Xn|Xo) (2)\n n\n= \u0397 (\u03a7\u03bf) + \\sum_{i=1} \u0397 (\u03a7i|\u03a7o,..., Xi\u22121)\nwhere we used the chain rule. H (Xo) is easily calculated from the probability vector at the root. The conditional entropy requires more delicate care. To make this simpler we use the following notation:\nTi = X0,..., Xi-1. (3)\nThis notation denotes the possible paths to a node at level i. T0 is the empty path that leads to the root node of the MCTS. T1 = X0 and thus defines the paths that lead to the nodes that constitute the root nodes of the subtrees in depth one (children of the root node).\n\u0397 (\u03a7i|\u03a7o,..., Xi\u22121) = H (Xi|Ti)\n= \\sum_{j\u2208[|A|]} Pr(Ti = tj) H (Xi|Ti = tj) (4)\nwhere A is the action space, which determines the maximum number of children each node may have. The notation [x] denotes the set {0,1,...,x-1}. Thus, the maximum number of nodes at level i is |A|\u00b2, assuming all actions are valid at each node. Putting it together, we have that the entropy of a MCTS is:\n\u0397 (\u03a7\u03bf, \u03a71,..., Xn) = H (Xo) +\n\\sum_{i=1}^n \\sum_{j\u2208[|A|]} Pr(Ti = tj) H (Xi|Ti = tj). (5)\nEquation (5) suggests a recursive implementation, going down the tree from its root, and calculating the probabilities to each node throughout. The main issue with an implementation following (5) is that since any expansion of the tree changes the probabilities (the probabilities from the root to each node) throughout the tree, such an expansion requires us to recalculate the entropy from scratch.\nAs an alternative approach we go back to equation (2) and using the following notation:\nT\u00b2 = Xi, Xi+1,..., Xn (6)\nwe can write it as follows:\n\u0397 (\u03a7\u03bf,..., Xn) =H (Xo) + H (X1,..., Xn|Xo) (7)\nH (T\u00b0) =H (X\u2030) + H (T\u00b9|Xo)\n=H (Xo)\n+ \\sum_{j\u2208[|A|]} Pr (Xo = xj) H (T\u00b9|Xo = xj) .\nThe above can be further extended since for each j \u2208 [|A|] we have that H (T1|Xo = xj) is:\nH (X1|X0 = x) + H (X2, ..., Xn|X1, Xo = xj) =\n\u0397 (\u03a71 \u03a7\u03bf = xj) +\n\\sum_{k\u2208 [|A|]} Pr (X1 = xk|Xo = xj) H (T2|X1 = xk, Xo = xj).\nWe can clearly see that this writing suggests a different, and perhaps cleaner, recursive implementation. We can first observe that this re-cursive implementation builds, at every stage, on the calculation of the entropy of the subtrees - H (T\u00b9|Xo = xj). The advantage of this is that we can produce directly from this formalization the en-tropy measure at each node of the tree, and not only at the root of the tree. A second significant difference is that the multiplications are with conditional probabilities. This difference is very significant since it reduces the computational impact as a result of changes done"}, {"title": "3 Reduction of MCTS using Subtree Removal", "content": "So far we tackled the extraction of information spread within the tree to numerical values that capture the structure, and hence the rea-soning of the AlphaZero algorithm. We have shown that this can be done efficiently. Another usage of these numerical entropy values is in tackling the aspect of size.\nReduction of a tree can be done in several ways. One can unify two nodes into one, or summarize two subtrees into a single subtree. In this work we specifically consider the reduction of a tree using only subtree removals. This means, that the tree can be reduced by picking the set of nodes that will be removed, where by removing a node we remove the entire subtree spanned from it.\nAny form of removal usually has some guiding criteria defining when to perform a removal. The specific choice of the criterion de-pends on the intended usage of the reduced tree. Our goal is to obtain a smaller, and more concise MCTS. We want to reduce the size of the MCTS, while still holding to the information it conveys. Such information contains, for example, the regions that the algorithm ex-panded more, the main children that were expanded at each level, etc. Thus, we propose a criterion that examines this exact trade-off. On the one hand we wish to reduce the size of the MCTS, meaning the number of nodes, while on the other hand we have the entropy of the MCTS which captures the interest. The trade-off between entropy and size should leave us with a MCTS that is smaller and focused on complex areas that are of interest. In mathematical terms this can be written as:\nmax {H (T\u00ba) \u2013 Blog (|A|) numberOf Nodes}. (12)\nwhere \u03b2 is the trade-off factor, numberOf Nodes can be approxi-mated by the value of the numberOf Visits in MCTS (as most visits result with an expansion of the tree, meaning they increase the tree by one node) and A is our action space.\nIn order to make the two terms comparable we consider both terms as descriptive information. The first term, the entropy, provides us with the number of bits required to describe the tree given the prob-ability vectors that were extracted from the number of visits. For the second term, we consider a worst case tree with numberOf Nodes nodes, in the sense of description. An upper bound on the longest de-scription is attained by a uniformly distributed tree over all possible actions, Al, at each node. The range of relevant values to consider for \u03b2 are [0, Bub] where:\nBub = \\frac{H (T)}{log (|A|) numberOf Nodes}. (13)\nExamining equation (12) we have a clear understanding of how the right element behaves when we remove a subtree, as it is monotoni-cally decreasing in numberOf Nodes. H (T\u00ba), on the other hand, is a bit more complex. This is the entropy of the entire tree. When we remove a subtree somewhere within the tree, the entropy of the entire tree changes. However, it does not necessarily increase or decrease. The next theorem shows exactly how the entropy of a node changes, given that one of its immediate children has been removed.\nTheorem 1. Assume a node at depth i defined by Ti = t, with N number of visits accumulated at its children. Its entropy is given by equation (8). When we remove child k the entropy of this node is as follows:\nH (Ti|Ti = t) =\nHTT (Ti|Ti = t) +\n\\frac{1}{1 \u2212 Pr(Xi = xk|Ti = t)}\n(Pr(Xi = xk|Ti = t)H (Ti|Ti = t) \u2212 Hb(Pr(Xi = xk|Ti = t))\n\u2212H (Ti+1|Ti = t, Xi = xk)), (14)\nwhere H() is the binary entropy.\nTheorem 1 gives us the new entropy of the node whose child has been removed in terms of the original entropy of that node (before the removal) - H (Ti|Ti = t). We can see that not in all cases will the entropy decrease when a child node is removed. Whether a removal will decrease or increase the entropy, depends on the expression in the last two rows of (14). These rows examine the difference between a fraction of the original entropy (according to the probability of the removed child) and the contribution of the removed node given in two terms: the binary entropy of the probability of the removed child and the entropy contribution of the removed child. This is to be ex-pected, and gives us an exact expression to examine whether a spe-cific removal will increase or decrease the entropy of its parent node.\nTheorem 1 considers the effect of a subtree removal on the entropy of the immediate parent node, however, we are more interested in how a removal effects the entropy of the entire tree. Recall that a removal of a subtree changes not only the probability vector of the parent node (and hence its local entropy contribution), but also the probability vectors of all of its ancestors.\nThe next theorem considers the more general effect by considering the change to the entropy of a parent node given that the entropy of one of its children has changed. This result can be used over and over to propagate the change in entropy up the tree.\nTheorem 2. Assume a parent node at depth i defined by Ti = t, with Np number of visits accumulated at its children (counts). Fur-ther assume that the lth child of this node had a change in its subtree that resulted with a decrease in the accumulated number of visits of its children from N to N(1-p) and as a result of this change the en-tropy of this child changed from He = H (Ti+1|Ti = t, Xi = xe) to He = H (Ti+1|Ti = t, Xi = xe). The entropy of the parent node is as follows:\nH (Ti|Ti = t) =\nH (TT\u2081 = t) + 1(PH (Ti|Ti = t) \u2013 Hb(p))\n+(Pr(Xi = xe|Ti = t) \u2013 p).\n(H (Ti+1|Ti = t, Xi = xe) - H (Ti+1|Ti = t, Xi = xe))) (15)\nwhere\np = \\frac{p}{Pr(Xi = xe|Ti = t)} = p \\frac{Np}{N} (16)\nProof. Proof is available in Appendix D.\nNote that Theorem 2 is not a generalization of Theorem 1. Theo-rem 2 allows us to concatenate the change up the tree, while Theorem 1 considers a local removal of a subtree. Thus, in practice, we will first use Theorem 1 to assess the change of the entropy after the local removal and then we will iteratively use Theorem 2 to propagate the change up the tree.\nFrom the above expression we clearly see that in order to evaluate the effect of a removal on the entropy of the tree we need to examine only the trajectory path from the changed node all the way to the root. At each node we need only the original entropy value, the counts and the probability of the changed node.\nThe proof of the theorems requires the following lemma and more specifically the corollary that follows:\nLemma 3. Assume a probability vector:\np = (p1, p2, ..., 1 \u2013 \u03a3pi). (17)\ni\nNow assume that we change it to the following vector:\n\n\np = (\\frac{p_1}{1-p},  \\frac{p_2}{1-p}, ...,\\frac{p_{e-1}}{1-p},\\frac{p_ep}{1-p} , \\frac{p_{e+1}}{1-p},...,  \\frac{1- \u03a3p_i}{1-p})\n\n (18)\nwhere p is some probability value in (0,pe) (note that the change to the lth component is different). The change to the entropy is as follows:\nH(p) = \\frac{1}{1-p} H(p) - \\frac{1}{1-p} Hb (p) (19)\nwhere H() is the binary entropy.\nCorollary 4. Assume a natural number N > 1 and a probability vector p with entropy denoted as H(p). The following is the vector of appearances:\nN (p1, p2, ..., 1 \u2013 \u03a3pi) = Np. (20)\ni\nBy removing the lth element from this vector, meaning that we con-sider the following probability vector:\n\n\np = (\\frac{Np_1}{N}, \\frac{Np_2}{N} ,...,  \\frac{Np_{e-1}}{N}, \\frac{Np_{e+1}}{N}, ..., \\frac{(1-\u03a3p_i)  } {N})   (21)\nwhere N = N - Npe, the entropy changes according to:\nH(p) =  \\frac{-1}{1- p_e} H(p)\n=  H(p) + \\frac{1}{1- p_e} Hb(p_e)\n \\frac{1}{1- p_e} [p_e H(p) - Hb(p_e)] (22)"}, {"title": "4 Implementation & Empirical Evaluations", "content": "There is a gap between our theoretical ambition to achieve a reduc-tion according to the entropy vs. size trade-off and its possible feasi-ble implementations. The two central issues are, first, that there are 2numberOfNode possible subsets of reductions to consider. Second, the benefit of a specific subtree reduction might change once another subtree reduction is performed. Putting these two together makes the complexity of finding the optimal solution unaffordable. Thus, we chose greedy methods to perform reduction that are motivated by the trade-off given in equation (12). The first is a local approach that goes down the tree and for each node finds the optimal reduction set, meaning the set of children of that node that if removed would pro-duce the highest trade-off, and performs their reduction. The second base-line approach is a two-stage approach. It goes down the tree and finds the best possible reduction set from each node. This reduction is not performed but rather placed in a priority list - pList. This pri-ority list is kept sorted from best reduction set to worst. Note that the trade-off values determining the performance of a specific reduction are measured assuming that this it the only reduction performed on the entire tree. The second stage is to go over pList. We consider three variants of the second stage. The first variant performs all re-ductions in pList. The second variant performed the reductions in pList until we reach a reduction that no longer improves the trade-off of the entire tree in its new form (after reductions performed thus far). The last variant, denoted as two-stage V2, examines each ele-ment in pList whether the specific reduction set improves the trade-off of the entire tree in its new form. The difference between the second and last variants is that the last variant continues to go over pList even if a bad element, which did not improve the trade-off has been encountered. The one-stage approach gives more preferences to reductions up the tree, since those are encountered first and per-formed. It has the advantage that future potential reductions are eval-uated on the already reduced tree. Alternatively, the two-stage ap-proach evaluates each node as if no reductions have been performed, and by that allows all potential reductions to compete fairly. This em-phasizes the difference between the one-stage approach and the first variant, which although performing all reductions in the priority list, these can be very different reductions than those performed by the one-stage approach. The complexity of both base-line algorithms is O(N2A log N), where N is the number of nodes in the tree, and 2 Al is included to show the dependency on the cardinality of A.\nThe performances of all four algorithms were examined on two simulated driving scenarios, a curved highway, and a ramp-merge. We used the open source traffic simulator SUMO [15] and the flow framework [25] for both training and evaluation of AlphaZero with the limited action space of seven actions. A decision step was per-formed every 1sec of simulation time. We used a discounting factor of y = 0.9, identical weights for the exploration and exploitation el-ements in the Upper Confidence Tree (UCT) and a computation bud-get of 60 iterations for the construction of the MCTS during training and 100 during evaluation (meaning that when no terminal states are encountered the resulting evaluation trees contain 100 nodes). Eval-uations were done after limited training (10-15 iterations). For each of the four algorithmic settings, we evaluated each scenario by per-forming five evaluation drives, each such evaluation drive resulted with 25 - 80 trees.\nThe suggested reduction algorithms, which we applied on every single tree obtained, receive a criterion as input. The suggested cri-terion, given in (12), depends on the trade-off parameter B. We eval-uated each of the four algorithms for three different values of \u03b2: BUB, BUB and BUB, where BUB is given in (13) and depends on the specific tree considered.\nAfter applying the four reduction algorithms on each MCTS, for all three values of \u00df, we compared the reduced versions with the original version. We examined several aspects including the change in entropy, size and trade-off between the original MCTS and its re-duced form. We also examined the effect of the main path (path of highest probability down the tree), and main subtree (subtree of high-est probability action from root), and similarly the effect on the sec-ondary path and subtree (where secondary is the highest probability action from the root). All numerical results are provided in Appendix F.\nHere we provide the graphs examining the trade-off, entropy and size only for the ramp-merge scenario. The change in these three values was measured as the difference between the original value and the new value divided by the original value. Thus, when the result is negative it means an increase, whereas a positive result is a decrease. We expect the trade-off to increase (negative result) and the size to decrease, however the entropy can go either way, and we hoped to see an increase.\n5 Summary"}, {"content": "In this work we tackle two aspects of the MCTS that are fundamental in our ability to support explainability of sequential decision-making algorithms that construct MCTS, such as AlphaZero. The first aspect is the spread of information throughout the MCTS, and specifically information related to the reasoning process of the algorithm. We show that this information, which influences the resulting structure of the MCTS, can be showcased as numerical entropy values that can be calculated efficiently during the expansion of the MCTS. The second aspect is the size of the resulting MCTS. We propose to use the entropy values as guiding values in the reduction of the tree in a trade-off criterion, thus preserve interesting attributes of the MCTS while attempting to reduce its size. We examine greedy algorithms motivated by the suggest criterion and evaluate their performance on MCTSs produced in driving simulations.\nThese methods come as a tool to assist in the extraction of meaningful understandable explanations of the sequential decision-making algorithm. We have only began to apply them in such con-structions, and see numerous different paths for the future."}, {"title": "Appendix", "content": ""}, {"title": "A Basic Implementation of Entropy Calculation", "content": "A basic implementation of the calculation of the entropy at each node assumes a given tree. The approach recursively goes down the tree and is given in Algorithm 3. As mentioned in the paper, the benefit of following the suggested formalization is that it produces the entropy not only of the entire MCTS but also at every node for the subtree spanned from it.\nThe advantage of the above algorithm is in its simplicity and clar-ity. Its main disadvantage is that it works for a given finalized prob-ability tree. Thus, if we change something in the original tree (for example, expand by a single node) and wish to receive the updated entropies, using the above algorithm, we will need to re-run it over the entire updated tree. The two methods shown for the calculation of the entropy in Algorithm 3 and the Algorithm that piggy-backs MCTS (given in the paper) provide exactly the same values. They are equivalent."}, {"title": "B Proof of Lemma 3", "content": "Proof. We first want to show that p is a valid probability vector by showing that the sum of its components is one:\n\\frac{p_i}{1-p} + \\frac{1- \u03a3 p_i}{1-p}  = \\frac{\u03a3 p_i - p + 1- \u03a3 p_i }{1-p} = \\frac{1}{1-p} = 1. (23)\nWe are comparing two entropies. The original entropy is of p, and is as follows:\nH(p) = - \u03a3pilogi - (1-\u03a3\u03b9) log (1-\u03a3\u03b9)\n=- pi\nand we want to connect it to the entropy of p, meaning after the change to the lth component. We can do so through the following observations:\np =(1-p). \\frac{p_1}{1-p} , ...,  \\frac{p_{e-1}}{1-p}, \\frac{p_ep}{1-p} , \\frac{p_{e+1}}{1-p},...,  \\frac{1- \u03a3p_i}{1-p}\n+ p. (0,..., 0, 1, 0, . . ., 0) (24)\nThus, we can think of two random variables. The first is a binary random variable, denoted by B, with probability \u00f4 to be one and 1 p to be zero. The second random variable X is defined over an alphabet of size |A|, and depended on B. When B is zero, X is distributed according to\n\\frac{p_1}{1-p} , ...,  \\frac{p_{e-1}}{1-p}, \\frac{p_ep}{1-p} , \\frac{p_{e+1}}{1-p},...,  \\frac{1- \u03a3p_i}{1-p} .).\n(25)\nWhen B is one X is deterministic and its value is set to the th element in the alphabet. Thus, the entropy can be written as follows:\nH(p) = H(X, B) = H(B) + H(X|B)\n= Hb(p)\n+ Pr (B = 0) H(X|B = 0) + Pr (B = 1) H(X|B = 1)\n= Hb(p) + (1 \u2212 p)H(X|B = 0)\n= Hb(p) + (1 \u2212 p)H(p). (26)\nThis concludes the proof."}, {"title": "C Proof of Theorem 1", "content": "Proof of Theorem 1. When a subtree is removed, the contribution of that subtree reduces to zero. However, the entropy of the tree is now calculated as if this subtree was never part of the tree. The entropy of any subtree is given by (equation (8) in the paper):\nH (T\\Ti = t) = H (Xi\\Ti = t) +\n\u03a3Pr(X = Xj T = 1)\nje[A]] (T+1\\T = t, Xi = x). (27)\nWe can identify that the removal has two implications. The first is on the local entropy, meaning the first argument on the right-hand-side. The second is on the proportion of the contributions of the entropies of the child nodes. Both elements change since by removing a subtree we change the probability vector in the parent node from p given by equation (20) in the main paper to p defined by equation (21) in the main paper. We first write this equation with the following simplified notation: Pr(Xi = xj|Ti = t) = pj, j\u2208 |A| and H (Ti+1|Ti = t, Xi = xj) = Hj, \u2200j\u2208 |A|. Thus, the above equation can be written as follows:\nH (TiTi = t) =H(p) + \u03a3pHj. (28)\nj\u2208[A]],j\u2260k\nwhere we also simplified the local entropy to a notation that shows the dependency on the probability vector (probability vector is given in bold). The change to the local entropy is according to Corollary 4, thus we have\nH (TiTi = t) = \\frac{1}{1-pk} (H(p) \u2013 Hb (pk)) +\n\u03a3 pjHj\nje[A]],j\u2260k\nWe continue to expand this to obtain the entropy expression of the original tree:\nH (TiTi = t)\n(29)\n1\n= \\frac{1}{1- Pk} (H(p) \u2013 Hb (pk)) + \u03a3 pjHj - PkHk\nje[A]\n1\n=\\frac{1}{1-Pk} (H(p) \u2013 Hb (pk)) + \u03a3 \\frac{Pj}{1-Pk}\nHj - \\frac{ Pk}{1-Pk}\nHk\nje[A]\n=\\frac{1}{1-Pk} (H(p) \u2013 Hb (pk)) + \u03a3 \\frac{Pj Hj}{1- Pk} - \\frac{PkHk}{1- Pk}\nje[A]\n(30) =\n\\frac{1}{1-Pk} (H(p) \u2013 Hb (pk) + \u03a3 \\frac{PjHj}{1- Pk} - PH - \\frac{ PkHk}{1- Pk}\n1\n=\\frac{1}{1-Pk}(H(p) + \u03a3 pjHj - (Hb (pk) + PkHk)\nje[A]] =\n\\frac{1}{1- Pk}(H (Ti|Ti = t ) - (Hb(pk) + PkHk))\n=HTT (T\u00b2/Ti = t ) + \\frac{1}{1- Pk}\\frac{PH (T\u00b2 Ti = t )}{1- Pk} (Hb(pk) + Hk)\n\\frac{1}{1- Pk}PkHk)\n= H (T/T =t) +\\frac{1}{1-pk} (PkH (Ti Ti = t ) - Hb (pk) - Hk).\nReturning to the original notation we reach the desired result. \u03a0"}, {"title": "D Proof of Theorem 2", "content": "Proof. We consider a parent node with Np children nodes", "vector": "np = p1", "has": "N = N(1-p) counts", "node": "\u00d1p = Np \u2013 Np. The important connection that we require is that Nppe = N + 1 since the fraction that each child contributes, is its own accumulated count at its children plus one (accounting for the node of the child). Given this observation we have that\n\u00d1p = Np - Np = Np \u2013 p(Nppe \u2013 1)\n= Np (1-(ppe- \\frac{1}{Np})). (31)\nDenoting\np=p(pe- \\frac{1}{Np})"}]}