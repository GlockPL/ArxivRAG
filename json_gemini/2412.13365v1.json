{"title": "Quantitative Predictive Monitoring and Control for Safe Human-Machine Interaction", "authors": ["Shuyang Dong", "Meiyi Ma", "Josephine Lamp", "Sebastian Elbaum", "Matthew B. Dwyer", "Lu Feng"], "abstract": "There is a growing trend toward AI systems interacting with humans to revolutionize a range of application domains such as healthcare and transportation. However, unsafe human-machine interaction can lead to catastrophic failures. We propose a novel approach that predicts future states by accounting for the uncertainty of human interaction, monitors whether predictions satisfy or violate safety requirements, and adapts control actions based on the predictive monitoring results. Specifically, we develop a new quantitative predictive monitor based on Signal Temporal Logic with Uncertainty (STL-U) to compute a robustness degree interval, which indicates the extent to which a sequence of uncertain predictions satisfies or violates an STL-U requirement. We also develop a new loss function to guide the uncertainty calibration of Bayesian deep learning and a new adaptive control method, both of which leverage STL-U quantitative predictive monitoring results. We apply the proposed approach to two case studies: Type 1 Diabetes management and semi-autonomous driving. Experiments show that the proposed approach improves safety and effectiveness in both case studies.", "sections": [{"title": "Introduction", "content": "There is a growing trend toward AI systems interacting with humans to revolutionize a range of application domains such as healthcare and transportation. However, unsafe human-machine interaction can lead to catastrophic failures (e.g., crashes of automated vehicles (Banks, Plant, and Stanton 2018) and robot-caused fatalities (Yang et al. 2022). Ensuring the safety of human-machine interaction poses significant challenges. First, safety is an emergent property that requires holistic reasoning about AI systems and human operators (Ma, Stankovic, and Feng 2021). Second, modeling human-machine interaction should account for the inherent uncertainty of human behavior. Moreover, safe and prompt decision-making under uncertainty entails predictive monitoring, i.e., making predictions about future states and monitoring if safety requirements would be violated. We concretize these challenges using a motivating example below.\nType 1 Diabetes (T1D) is a chronic disease that affects millions of patients whose pancreas produces little to no insulin to regulate blood glucose (BG). Uncontrolled diabetes may cause hypoglycemia (BG below 70 mg/dL) or hyperglycemia (BG above 180 mg/dL), which over time can lead to serious damage to organs such as the kidneys and heart. Over the past decades, advanced technologies such as continuous glucose monitoring (CGM) sensors and insulin pumps have been developed to reduce the need for patients to check BG via finger-pricking and self-injections of insulin. Recently, there have been promising breakthroughs in the development of Artificial Pancreas Systems (APS), which are automated or semi-automated closed-loop insulin delivery systems to regulate BG levels. A typical APS controller calculates insulin dosages based on CGM sensor readings and user input (e.g., meal carbohydrates). There has been increasing interest in using machine learning techniques to predict future BG levels, which are then fed into an APS controller. To guarantee a safety requirement, such as \"BG levels should be regulated within the range of 70-180 mg/dL to avoid hypoglycemia or hyperglycemia\", it is not sufficient to only check APS control actions. Instead, it is necessary to reason about the behavior of the entire closed-loop system of APS, including the insulin pump, CGM sensor, as well as patient physiology (e.g., glucose metabolism) and behavior (e.g., eating).\nTo tackle these challenges, we propose a novel logic-based quantitative predictive monitoring and control approach, as illustrated in Figure 1. We adopt Recurrent Neural Networks (RNNs), which are well-suited to time series data (Bengio, Goodfellow, and Courville 2017), for making sequential predictions about future BG levels. Commonly used RNNs, such as long short-term memory (LSTM) networks, are deterministic models that generate the same predictions with the same input (Hochreiter and Schmidhuber 1997; Ma et al. 2020). To account for the uncertainty of human physiology and behavior, we cast deterministic RNNs"}, {"title": "Background", "content": "Stochastic regularization techniques (SRTs) are commonly employed to transform deterministic deep learning models into Bayesian models, enabling uncertainty estimation. In this work, we transform a deterministic RNN model into a Bayesian RNN model via SRTs. We consider four commonly used SRTs: Bernoulli dropout, Bernoulli dropConnect, Gaussian dropout, and Gaussian dropConnect (Gal 2016). These SRTs have various ways to determine which neuron connections to drop based on sampling from a probability distribution with certain dropout rate $p$. The larger the value of $p$, the more neuron connections are retained.\nA Bayesian RNN model yields a set of sequential predictions by applying Monte Carlo sampling $N$ times. At each step $t$ along the sequence, a Gaussian distribution $\\Phi_\\tau \\sim \\mathcal{N}(\\theta_\\tau, \\sigma^2_\\tau)$ can be estimated, whose mean $\\theta_\\tau$ and variance $\\sigma_\\tau^2$ are calculated based on the Monte Carlo samples $\\{x_{\\tau}^{(1)}, ..., x_{\\tau}^{(N)}\\}$. The uncertainty estimates of Bayesian RNN predictions are bounded by the Gaussian distribution's confidence interval $[\\Phi_\\tau^{-}(\\epsilon), \\Phi_\\tau^{+}(\\epsilon)]$ under a confidence level $\\epsilon \\in (0, 1)$. The larger the confidence interval range, the higher the estimated uncertainty."}, {"title": "Signal Temporal Logic with Uncertainty", "content": "(Ma et al. 2021) characterize Bayesian RNN predictions as a flowpipe signal $\\omega$ over a discrete time domain $T$. At each time $t$, the flowpipe contains all values bounded within a confidence interval $[\\Phi_t^{-}(\\epsilon), \\Phi_t^{+}(\\epsilon)]$. Figure 2 shows an example flowpipe of predicted BG levels.\nSignal Temporal Logic with Uncertainty (STL-U) with the following syntax is proposed in (Ma et al. 2021).\n$\\phi := \\mu(\\epsilon) \\mid \\neg \\phi \\mid \\phi_1 \\wedge \\phi_2 \\mid \\bigcirc_I \\phi \\mid \\Diamond_I \\phi \\mid \\phi_1 \\mathcal{U}_I \\phi_2$\nwhere $\\bigcirc_I, \\Diamond_I$ and $\\mathcal{U}_I$ are temporal operators \"always\", \"eventually\", and \"until\" with a time interval $I \\subseteq T$, respectively. $\\mu(\\epsilon)$ is an atomic predicate whose value is determined by a function $f(x) > 0$ for $x \\in [\\Phi_t^{-}(\\epsilon), \\Phi_t^{+}(\\epsilon)]$ under a confidence level $\\epsilon$. For example, $\\Box_{[0, 3]}(BG_{\\epsilon=90\\%} > 70)$ is an STL-U formula expressing the requirement that \u201cthe predicted BG level under a 90% confidence level should always be above 70 mg/dL in the next three hours\u201d.\nSTL-U semantics defined in (Ma et al. 2021) include two indices: strong satisfaction (i.e., all values bounded within the flowpipe's confidence interval satisfy $\\phi$), and weak satisfaction (i.e., there exists some value within the flowpipe's confidence interval satisfying $\\phi$). For example, the flowpipe shown in Figure 2 strongly satisfies $\\Box_{[t, t_1]}(BG_{\\epsilon} > 70)$, weakly satisfies $\\Diamond_{[t, t_2]}(BG_{\\epsilon} > 70)$, and strongly violates $\\Box_{[t, t_3]}(BG_{\\epsilon} > 70)$.\nAdditionally, a loss function, denoted by $\\mathcal{L}_{sat}$, is proposed in (Ma et al. 2021) based on STL-U strong/weak satisfaction relations to calibrate the uncertainty estimation of Bayesian RNNs by guiding the choice of SRTs and dropout rates."}, {"title": "Approach", "content": "The goal of our approach is to provide quantitative information about the degree to which an STL-U formula is satisfied or violated, which is imperative for fine-grained decision making in safe human-machine interaction. To achieve this goal, we develop a new STL-U quantitative monitor in Section 3.1. The monitoring results are leveraged to improve the uncertainty calibration through a new loss function in Section 3.2 and an adaptive control method in Section 3.3."}, {"title": "STL-U Quantitative Monitor", "content": "We propose a new quantitative semantics of STL-U, which computes a robustness degree function $\\rho(\\phi, \\omega, t)$ indicating how much an STL-U formula $\\phi$ is satisfied or violated by a flowpipe signal $\\omega$ at time $t$.\nLet $v = [\\underline{v}, \\overline{v}]$ denote a real-valued interval. We define the following three interval operations:\n$-* v \\triangleq [-\\overline{v}, -\\underline{v}]$\n$\\min^{*}(v_1, ..., v_n) \\triangleq [\\min(\\underline{v_1}, ..., \\underline{v_n}), \\min(\\overline{v_1}, ..., \\overline{v_n})]$\n$\\max^{*}(v_1, ..., v_n) \\triangleq [\\max(\\underline{v_1}, ..., \\underline{v_n}), \\max(\\overline{v_1}, ..., \\overline{v_n})]$.\n$\\rho(\\mu(\\epsilon), \\omega, t) = [\\min(f(x)), \\max(f(x))], \\forall x \\in [\\Phi_t^{-}(\\epsilon), \\Phi_t^{+}(\\epsilon)]$\n$\\rho(\\neg \\phi, \\omega, t) = -*\\rho(\\phi, \\omega, t)$\n$\\rho(\\phi_1 \\wedge \\phi_2, \\omega, t) = \\min^{*}(\\rho(\\phi_1, \\omega, t), \\rho(\\phi_2, \\omega, t))$\n$\\rho(\\bigcirc_I \\phi, \\omega, t) = \\min^{*}_{t'\\in (t+I)} \\rho(\\phi, \\omega, t')$ where I is the time\n$\\rho(\\Diamond_I \\phi, \\omega, t) = \\max^{*}_{t'\\in (t+I)} \\rho(\\phi, \\omega, t')$ where I is the time\n$\\rho(\\phi_1 \\mathcal{U}_I \\phi_2, \\omega, t) = \\max^{*}_{t'\\in (t+I)} (\\min^{*}( \\rho(\\phi_2, \\omega, t'), \\min_{t'' \\in [t, t']} \\rho(\\phi_1, \\omega, t'')))$\nIntuitively, a robustness degree function yields an interval whose lower/upper bounds corresponding to the worst/best cases of a flowpipe satisfying or violating an STL-U formula. A positive (resp. negative) robustness value indicates the degree of satisfaction (resp. violation).\nAlgorithm 1 illustrates STL-U quantitative monitoring algorithm based on Definition 1. We can apply this algorithm recursively to monitor complex STL-U formulas with multiple levels of nesting temporal operators. The algorithm has a linear time complexity with respect to the length of the flowpipe, $\\omega$.\nHere is an example of checking the flowpipe in Figure 2 against an STL-U formula $\\Box_{[t, t_3]}(BG_{\\epsilon} > 70)$. First, we check the atomic predicate at each time $\\tau \\in [t, t_3]$, and compute the robustness degree interval $[\\min(f(x)), \\max(f(x))]$ for all $x \\in [\\Phi_{\\tau}^{-}(\\epsilon), \\Phi_{\\tau}^{+}(\\epsilon)]$, where $f(x) = x - 70$. The flowpipe at $t_2$ is bounded by $[60, 80]$ and yields a robustness degree interval $[-10, +10]$. The flowpipe at $t_3$ is bounded by $[40, 65]$ and its robustness degree interval is $[-30, -5]$. Finally, we obtain a robustness degree interval for the always operator $\\Box_{[t, t_3]}$ by taking the minimal of the lower/upper bounds of the atomic predicate's robustness degree intervals over all time steps $\\tau \\in [t, t_3]$. The resulting robustness degree interval, $[-30, -5]$, indicates that the predicted flowpipe would violate the requirement by -30 and -5 in the worst and best-case scenarios, respectively."}, {"title": "Uncertainty Calibration", "content": "A Bayesian RNN model may produce divergent uncertainty estimates for a model trained on identical data, depending on various choices of SRTs and dropout rates. The current practice often selects an SRT and dropout rate empirically or guided by traditional deep learning metrics such as prediction accuracy, which tend to overestimate uncertainty (i.e., the wider the flowpipe, the higher the accuracy of containing the ground truth trace).\nWe propose a loss function based on STL-U quantitative monitoring results to guide the choice of SRTs and dropout"}, {"title": "Adaptive Controller", "content": "A typical (deterministic) controller, denoted by $\\pi: S \\rightarrow A$, takes an input state $s \\in S$ from the environment and produces an output action $a \\in A$. We develop an adaptive controller $\\pi': S \\times \\rho \\rightarrow A$ that adapts control actions based on STL-U quantitative monitoring results $\\rho(\\phi, \\omega, t)$ as shown in Figure 3. The adaptation schema can be domain-specific.\nAs a proof of concept, we present an adaptive controller based on the Basal-Bolus Controller (Kovatchev et al. 2009) included in the UVA/PADOVA T1D Simulator. The default Basal-Bolus Controller takes input such as the current BG level and meal carbohydrates, and computes the basal and bolus insulin dosages as control actions to regulate BG levels. A constant amount of basal insulin is delivered at each step, denoted by $defaultBasal$, whose value is calculated by multiplying the patient's body weight with a constant representing the steady state insulin rate per kilogram. Additionally, the controller issues a (non-zero) bolus insulin at a step when the patient takes a meal with carbohydrates. The bolus insulin dosage, denoted by $mealBolus$, is calculated based on the amount of carbohydrates, the current and target BG levels, and the patient's carbohydrate ratio and correction factor."}, {"title": "Conclusion", "content": "In this work, we present a logic-based quantitative predictive monitoring and control approach to enhance the safety of human-machine interaction under uncertainty. Using Bayesian RNN models, we represent the uncertainty of human behavior and employ a novel STL-U quantitative predictive monitor to compute robustness degree intervals, which indicate the satisfaction or violation of STL-U requirements. We design a new loss function leveraging STL-U results to optimize uncertainty estimation in Bayesian RNNs by selecting the best combination of SRT and dropout rate. Additionally, adaptive controllers adjust control actions based on robustness intervals.\nExperiments with a T1D patient simulator demonstrate that the proposed approach enables early and accurate detection of safety hazards and improves the safety and effectiveness of T1D management. Furthermore, the loss function outperforms state-of-the-art baselines in uncertainty estimation. Results from a semi-autonomous driving case study also show enhanced safety, confirming the approach's generalizability.\nFuture work includes testing alternative RNN models, developing principled adaptive control for broader domains, incorporating priority-based dynamic enforcement of requirements, validating in real-world settings, and extending to diverse case studies like human-robot interaction."}, {"title": "Correctness", "content": "Given an STL-U formula $\\phi$ and a flowpipe $\\omega$, the following properties hold.\n$\\rho > 0 \\Rightarrow (\\omega, t) \\models_s \\phi$\n$\\rho < 0 \\Rightarrow (\\omega, t) \\not \\models_s \\phi$\n$\\rho > 0 \\Rightarrow (\\omega, t) \\models_w \\phi$\n$\\rho < 0 \\Rightarrow (\\omega, t) \\not \\models_w \\phi$\nwhere $\\underline{\\rho}$ and $\\overline{\\rho}$ are the lower and upper bounds of the robustness degree interval $\\rho(\\phi, \\omega, t)$, and $\\models_s$ (resp. $\\models_w$) denotes the strong (resp. weak) satisfaction relations.\nWe prove the first property $\\underline{\\rho} > 0 \\Rightarrow (\\omega, t) \\models_s \\phi$ by structural induction below. The rest of the three properties can be proved similarly.\nBased on Definition 1, $\\underline{\\rho}$ is the minimal value of $f(x)$ for all $x \\in [\\Phi_t^{-}(\\epsilon), \\Phi_t^{+}(\\epsilon)]$. If $\\underline{\\rho} > 0$, then $f(x) > 0$ for all $x$ bounded within the flowpipe's confidence interval. Thus, the flowpipe $\\omega$ strongly satisfies $\\mu(\\epsilon)$ at time $t$.\n$\\underline{\\rho} = -\\max(f(x)) > 0$ for all $x \\in [\\Phi_t^{-}(\\epsilon), \\Phi_t^{+}(\\epsilon)]$, we have $f(x) < 0$ for all the flowpipe's values bounded within its confidence interval. Thus, the flowpipe $\\omega$ strongly satisfies $\\neg \\phi$ at time $t$.\nLet $\\underline{\\rho_1}$ and $\\underline{\\rho_2}$ denote the lower bounds of robustness degree intervals $\\rho(\\phi_1, \\omega, t)$ and $\\rho(\\phi_2, \\omega, t)$, respectively. Since $\\underline{\\rho} = \\min^{*}(\\underline{\\rho_1}, \\underline{\\rho_2}) > 0$, we have both $\\underline{\\rho_1} > 0$ and $\\underline{\\rho_2} > 0$. Thus, the flowpipe $\\omega$ strongly satisfies $\\phi_1 \\wedge \\phi_2$ at time $t$.\nSince $\\underline{\\rho} = \\min^{*}_{t'\\in (t+I)}\\rho(\\phi, \\omega, t') > 0$, we have $\\rho(\\phi, \\omega, t') > 0$ for every time step $t' \\in (t+I)$. Thus, the flowpipe $\\omega$ strongly satisfies $\\bigcirc_I \\phi$ at time $t$.\nSince $\\underline{\\rho} = \\max^{*}_{t'\\in (t+I)}\\rho(\\phi, \\omega, t') > 0$, we have $\\rho(\\phi, \\omega, t') > 0$ for at least one step $t' \\in (t+I)$. Thus, the flowpipe $\\omega$ strongly satisfies $\\Diamond_I \\phi$ at time $t$.\n$\\underline{\\rho} = \\max^{*}_{t'\\in (t+I)} (\\min^{*}( \\rho(\\phi_2, \\omega, t'), \\min^{*}_{t'' \\in [t, t']} \\rho(\\phi_1, \\omega, t'')))$.\nSince $\\underline{\\rho} > 0$, there must exist a step $t' \\in (t+I)$ such that $\\min^{*}( \\rho(\\phi_2, \\omega, t'), \\min^{*}_{t'' \\in [t, t']} \\rho(\\phi_1, \\omega, t'')) > 0$, which is equivalent to $\\rho(\\phi_2, \\omega, t') > 0$ and $\\rho(\\phi_1, \\omega, t'') > 0$ for all $t'' \\in [t, t']$. Thus, there exists a time $t' \\in (t+I)$ with $(\\omega, t') \\models_s \\phi_2$ and $(\\omega, t'') \\models_s \\phi_1$ for all $t'' \\in [t, t']$. By definition, the flowpipe $\\omega$ strongly satisfies $\\phi_1 \\mathcal{U}_I \\phi_2$ at time $t$."}, {"title": "Case Study: Semi-Autonomous Driving", "content": "To demonstrate the generalizability of the proposed approach, we apply it to a second case study of semi-autonomous driving using the CARLA simulator. We consider a benchmark scenario of car following on a straight road provided in (SafeBenchTeam 2023). The goal of vehicle control is to smooth the acceleration, thereby avoiding hard brakes and sharp accelerations during car following to ensure safety and comfort. We specify the requirement using an STL-U formula: $\\phi = \\Box_{[0, \\infty)}[(acceleration_{\\epsilon} > -6.0) \\wedge (acceleration_{\\epsilon} < 6.0)]$.\nAdaptive controller. Algorithm 3 adapts the vehicle controller based on the STL-U quantitative monitoring results. Specifically, it adjusts the vehicle's throttle and brake based on the following factors: the vehicle's average throttle and brake $meanThrottle, meanBrake$ in the past 5 steps, $currentThrottle$ and $currentBrake$ at this time step returned by the original controller of the behavior agent, and the worst-case robustness degrees of predicted acceleration flowpipes. It also sets the upper bounds on the throttle and brake, which are represented as $maxThrottle, maxBrake$, and takes the $currentSpeed$ at this step and a lower threshold of speed $minSpeed$ into"}]}