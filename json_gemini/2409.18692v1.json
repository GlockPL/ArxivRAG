{"title": "MG-Net: Learn to Customize QAOA with Circuit Depth Awareness", "authors": ["Yang Qian", "Xinbiao Wang", "Yuxuan Du", "Yong Luo", "Dacheng Tao"], "abstract": "Quantum Approximate Optimization Algorithm (QAOA) and its variants exhibit immense potential in tackling combinatorial optimization challenges. However, their practical realization confronts a dilemma: the requisite circuit depth for satisfactory performance is problem-specific and often exceeds the maximum capability of current quantum devices. To address this dilemma, here we first analyze the convergence behavior of QAOA, uncovering the origins of this dilemma and elucidating the intricate relationship between the employed mixer Hamiltonian, the specific problem at hand, and the permissible maximum circuit depth. Harnessing this understanding, we introduce the Mixer Generator Network (MG-Net), a unified deep learning framework adept at dynamically formulating optimal mixer Hamiltonians tailored to distinct tasks and circuit depths. Systematic simulations, encompassing Ising models and weighted Max-Cut instances with up to 64 qubits, substantiate our theoretical findings, highlighting MG-Net's superior performance in terms of both approximation ratio and efficiency.", "sections": [{"title": "Introduction", "content": "Combinatorial optimization problems (COPs) [1], central to numerous scientific and engineering disciplines [2, 3, 4], often defy efficient classical solutions due to their computational complexity [5, 6]. A promising strategy to overcome these computational challenges involves harnessing the power of quantum computing, as these COPs can be mapped to Ising Hamiltonians whose ground states denote optimal solutions [7, 8]. Leveraging this quantum representation, the Quantum Approximate Optimization Algorithm (QAOA) [9] has emerged to address these COPs. In particular, theoretical analyses [10, 11, 12, 13] underscore the potential of QAOA, suggesting its superiority over classical counterparts in certain contexts, particularly with unlimited infinite circuit depth. Meantime, empirical studies [14, 15, 16] affirm its applicability across a diverse spectrum of problems and devices.\nDespite these advancements, QAOA's practical efficacy is challenged by the quantum coherence limits of modern quantum devices, as there is a ceiling on the allowable maximum circuit depth p. As a result, standard QAOA often underperforms classical counterparts [18, 19]. This motivates a research shift towards redesigning the mixer Hamiltonian $H_M$, a key component of QAOA. As illustrated in Fig. 1(a), supported by the results of quantum adiabatic evolution [20, 21], alternative $H_M$ may exist that guide the system along a more direct and efficient trajectory-a shortcut to the solution state, leading to a better performance compared to the standard QAOA. Besides, as shown in Fig. 1(b), empirical evidence indicates that the form of $H_M$ promising a good performance is varied with the allowable p. As such, diverse alternatives $H_M$ are proposed in past years, drawing upon concepts from quantum annealing [22], incorporating additional trainable parameters [17] or exploiting permutation symmetry [23]. However, these approaches require deep domain expertise and often lack generalizability across different tasks and circuit configurations p.\nIn response to these challenges, here we first analyze the convergence of QAOA on various mixer Hamiltonian configurations and circuit depths with the tool of representation theory [24]. Our finding reveals that (i) the convergence of QAOA can be enhanced through parameter grouping in the mixer Hamiltonian; (ii) the specific strategy for parameter grouping is dependent on the particular problem and the value of p. These two findings are instrumental in understanding the interplay between p, parameter grouping, and the overall efficiency of the QAOA, providing valuable insights for the design of the mixer Hamiltonian.\nEnvisioned by the achieved theoretical results, we propose an end-to-end learning framework, termed Mixer Generator Network (MG-Net), to dynamically design the mixer Hamiltonian $H_M$ for a class of problems and distinct circuit depth constraints. Conceptually, MG-Net takes the problem's description and the available circuit depth p as input and directly outputs the optimal mixer Hamiltonian for a p-QAOA. There are three distinguished features of our proposal: (i) The ability to dynamically adjust $H_M$ according to p, enhancing its compatibility with practical quantum devices; (ii) Fast customization of $H_M$ for unseen problems and circuit depth p, attributed to the multi-condition controlled generative network architecture; (iii) Circumvent the need for the expensive collection of a vast training dataset of optimal $H_M$ by employing an estimator-generator structure alongside a two-stage training approach. Note that the developed techniques can be flexibly extended to other variational quantum algorithms (VQAs) [25, 26], which may be independent of interests.\nThe contributions of this paper are:\n\u2022 We provide a rigorous theoretical analysis on the convergence of QAOA with sufficient circuit depth, elucidating the link between the performance and the parameter grouping in QAOA circuits. This analysis offers guidance on the design of mixer Hamiltonian to achieve a high approximation ratio for a specified circuit depth.\n\u2022 We propose MG-Net, which dynamically tailors its predicted mixer Hamiltonian $H_M$ to suit the given problem and circuit depth. Our model greatly reduces the cost of collecting labeled training data, attributed to an estimator-generator framework and a two-stage training strategy.\n\u2022 The proposed MG-Net demonstrates remarkable generalization ability from a limited dataset to a broad spectrum of combinatorial problems, which facilitates rapid and efficient creation of $H_M$ for unseen problems, advancing the practical utility of QAOAs.\n\u2022 Extensive experiments on the Transverse-field Ising model and Max-Cut up to 64 qubits verify our theoretical discoveries and demonstrate the advantage of MG-Net in achieving higher approximation ratios at various circuit depths compared to other quantum and traditional methods."}, {"title": "Background", "content": "2.1 Quantum approximation optimization algorithm\nConsidering a COP defined on a set of N binary variables $z = z_1 \\cdots z_N$, where $z_i \\in {\\pm 1}$, our objective is to identify a bit string z that maximizes a specific objective function $C(z) : {+1}^N \\rightarrow \\mathbb{R}_{\\geq 0}$. Intuitively, the solution space grows exponentially with N, rendering the exact solution to many COPs intractable [1]. In practice, an alternative approximation algorithm is selected to seek an approximate solution z to achieve a high approximation ratio $r = C(\\hat{z})/C_{\\text{max}}$, where $C_{\\text{max}} = \\max_z C(z)$.\nIn response to this inherent complexity, Quantum Approximate Optimization Algorithm (QAOA) [9] is proposed. In this framework, the bit string z is encoded into a quantum state $|x\\rangle = |x_1 \\cdots x_N\\rangle$ with $x_i = (1 - z_i)/2$, and the objective function C(x) is encoded into the problem Hamiltonian $H_c \\in \\mathbb{C}^{2^N \\times 2^N}$ so that $H_c |x\\rangle = C(x) |x\\rangle$. Refer to Appendix A for the omitted details.\nQAOA is a hybrid quantum-classical algorithm that combines a parameterized quantum circuit (PQC) for state evolution and a classical optimizer for parameter updates. For a p-layer QAOA circuit shown in Fig. 1(a), the quantum state $|\\psi_p\\rangle$ is prepared by alternately applying the problem Hamiltonian $H_c$ and the mixer Hamiltonian $H_M = \\sum_{i=1}^N X_i$ on the initial state $|\\psi_0\\rangle$, formulated as\n$|\\psi_p(\\alpha, \\beta)\\rangle = \\prod_{k=1}^p e^{-i \\beta_k H_M} e^{-i \\alpha_k H_c} |\\psi_0\\rangle$, (1)\nwhere $\\alpha = (\\alpha_1, ..., \\alpha_p)$ and $\\beta = (\\beta_1, ..., \\beta_p)$ are 2p trainable parameters. These parameters are optimized to maximize the expectation value of the problem Hamiltonian $H_c$:\n$(\\alpha^*, \\beta^*) = \\arg \\max_{\\alpha,\\beta} F_p(\\alpha, \\beta)$, (2)\nwhere $F_p(\\alpha, \\beta) = \\langle \\psi_p(\\alpha, \\beta)|H_c|\\psi_p(\\alpha, \\beta)\\rangle$ can be estimated by multiple measurements on the quantum system. As $F_p(\\alpha^*, \\beta^*)$ approaches the optimal value $C_{\\text{max}}$ of the objective function, we can obtain the approximate solution to the combinatorial optimization problem with high probability by measuring the state $|\\psi_p(\\alpha^*, \\beta^*)\\rangle$ in the computational basis. A metric for assessing the performance of QAOA is the approximation ratio $r = F_p(\\alpha^*, \\beta^*)/C_{\\text{max}}$.\n2.2 Symmetry in QAOA\nSymmetry, ansatz design, and effective dimension. A symmetry $S$ refers to the unitary operator leaving the operator H invariant such that $S^{\\dagger} H S = H$ (or $[S, H] = 0$). All symmetries form a group $\\mathcal{S}$ where given any two symmetries $S_1, S_2 \\in \\mathcal{S}$, the compositions $S_1 S_2$ and $S_2 S_1$ are also symmetries in $\\mathcal{S}$. Among various symmetries, the most relevant one to our work is the permutation symmetry $\\pi \\in S_N$, with the subscript being the qubit count N and $S_N$ being the symmetric group. For example, a permutation $\\pi$ with $\\pi(1) = 3, \\pi(2) = 1, \\pi(3) = 2$ acting on the state $|\\psi_1\\rangle|\\psi_2\\rangle|\\psi_3\\rangle$ yields $\\pi|\\psi_1\\rangle|\\psi_2\\rangle|\\psi_3\\rangle = |\\psi_3\\rangle|\\psi_1\\rangle|\\psi_2\\rangle$. Throughout the whole study, we denote the group of permutation symmetries of the problem Hamiltonian $H_c$ as $Per(H_c) = {\\pi \\in S_N | \\pi^{\\dagger} H_c \\pi = H_c}$.\nConsider an N-qubit PQC $U(\\theta) = \\prod_{k=1}^K e^{-i H_k \\theta_k}$ with $\\theta \\in \\Theta$ and $d = 2^N$. We call $U(\\theta)$ a symmetric PQC with respect to the problem Hamiltonian $H_c$ if there exists a symmetry group $\\mathcal{S}$ of $H_c$ such that $[U(\\theta), S] = 0$ for any $\\theta \\in \\Theta$ and $S \\in \\mathcal{S}$. This symmetry is determined by the generators of PQCs $\\mathcal{A} = {H_1, ..., H_K}$ which is also called ansatz design, as $[U(\\theta), S] = 0$ holds for any $\\theta \\in \\Theta$ if and only if $[H_k, U(\\theta)] = 0$ for any $k \\in [K]$. Such symmetry can be quantified by the effective dimension [27, 28].\nDefinition 2.1 (Effective dimension). Consider an N-qubit QAOA instance $(\\vert \\psi_0\\rangle, U(\\theta), H_c)$ where $U(\\theta)$ acts on the vector space $V$. If there exists a direct sum decomposition $V = \\bigoplus_{i=1}^r V_i$ and $V^* \\in {V_i}_{i=1}^r$ such that $U(\\theta) |\\psi_0\\rangle \\in V^*$ for any $\\theta$ and the ground state of the problem Hamiltonian $|\\psi^*\\rangle$ satisfies $|\\psi^*\\rangle \\in V^*$, then the effective dimension $d_{\\text{eff}} \\leq 2^N$ is defined as the dimension of $V^*$.\nExperimental and theoretical analysis has shown that symmetric ansatz design with a small effective dimension contributes to better trainability [29, 28, 30]."}, {"title": "Convergence theory of QAOA", "content": "In this section, we theoretically illustrate how employing appropriate parameter grouping corresponds to better convergence performance. Similar to Refs. [27] and [28], our derivations are based on the observation that the exploited PQC with highly-symmetric ansatz structure generally enables a faster convergence rate.\nTheorem 3.1 (Convergence). Consider a QAOA instance denoted as $(\\vert \\psi_0\\rangle, U(\\theta), H_c)$ with $U(\\theta)$ determined by the related ansatz design. Let $\\mathcal{A}_{FG}, \\mathcal{A}_{PG}, \\mathcal{A}_{NG}$ be the ansatz designs of the circuits with parameters fully grouped, partially grouped, and no-grouped. Their effective dimension yields\n$d_{\\text{eff}} (\\mathcal{A}_{FG}) = d_{\\text{eff}}(\\mathcal{A}_{PG}) \\leq d_{\\text{eff}} (\\mathcal{A}_{NG})$, (3)\nwhere the equality in the inequality holds if there is no spatial symmetry in $H_c$. Besides, there exists a $d_{\\text{eff}}$-dependent threshold C so that circuit depth $p > C$, the iterations T required to achieve the same approximation ratio yield\n$T_{PG} = T_{FG} \\leq T_{NG}$. (4)\nThe proof of Theorem 3.1 and more elaborations are presented in Appendix B. The achieved results, combined with the over-parameterization theory of PQCs [30], deliver the following two implications. First, when the circuit depth $p > C$ is sufficiently large such that all PQCs with various ansatz designs reach the over-parameterization regime, performing the parameter grouping can effectively decrease the effective dimension $d_{\\text{eff}}$ compared with the PQCs with no-parameter grouping, leading to a faster convergence rate. Second, the over-parameterization of QAOA occurs when the number of trainable parameters exceeds a critical point that is proportionally related to $d_{\\text{eff}}$.\nThe above two implications indicate the selection of $\\mathcal{A}_{FG}, \\mathcal{A}_{PG}, or \\mathcal{A}_{NG}$ is complicated and is both depth- and problem-dependent. In particular, given a specified p, adopting a parameter grouping strategy can simultaneously reduce the number of parameters and the effective dimension, making it difficult to determine whether the QAOA reaches the over-parameterization regime. For instance, in a scenario such that the parameter grouping strategy drastically reduces the number of parameters but only slightly reduces the effective dimension, an over-parameterized QAOA could transform to an under-parameterized QAOA, leading to a degraded convergence as the optimization can be easily stuck in bad local minimal [31, 32]."}, {"title": "MG-Net", "content": "The implication of Theorem 3.1 inspires us to devise a method for dynamically generating an appropriate mixer Hamiltonian $H_M$ tailored to both the problem G at hand and the specified circuit depth p. For this purpose, we harness the power of deep learning and devise an end-to-end learning framework, dubbed Mixer Generator Network (MG-Net)."}, {"title": "Framework of MG-Net", "content": "Before presenting the proposed MG-Net, let us first formalize the learning problem towards designing the mixer Hamiltonian $H_M$. To incorporate different Pauli operators and parameter grouping strategies, we extend the definition of an N-qubit mixer Hamiltonian $H_M$ in Eqn. (1) to a more generalized form, supporting flexible operators and parameter correlations by substituting the Pauli-X operator with a selection of general Pauli operator and stratifying the N operators into K groups. Mathematically, the refined mixer Hamiltonian yields\n$H_M = \\sum_{j=1}^K \\beta_j \\sum_{i\\in G_j} P_i$, (5)\nwhere $\\beta_j$ refers to the trainable parameter controlling the j-th group of operators, $P_i \\in {X_i, Y_i}$, and $G_j$ contains the indices of operators belonging to the j-th group such that $\\cup_{i\\in G_j} = [N]$ and $G_i \\cap G_j = \\emptyset$ for $\\forall i \\neq j$. In this sense, operators in the same group are correlated with each other, sharing the same parameter. In this way, the design of $H_M$ is decoupled into two distinct tasks: determine the parameter groups ${G_j}_{j=1}^K$; identify the appropriate operator types $P_i$. With the reformulation above, the decoupled tasks can be accomplished by learning a mapping rule $f : (G,p) \\rightarrow (\\mathcal{G}, \\mathcal{P})$ with $\\mathcal{G} = {G_j}_{j=1}^K$ and $\\mathcal{P} \\in {X, Y}^N$ referring to the parameter correlation and mixer Hamiltonian.\nDesigning a model to learn f faces two main challenges:\n(C-1) The variety of combinatorial optimization tasks leads to uncertain input formats for the model, which necessitates a universal representation method and retains essential properties of the original data, such as permutation invariance;\n(C-2) The exponential growth of the search space for both parameter correlation and operator types, (i.e., scaling at $O(N^N)$ and $O(2^N)$, respectively), hurdles the design of an effective learning method. For instance, directing training a learning model in the supervised learning paradigm may require computationally unaffordable training examples to ensure good prediction accuracy.\nWe next present an end-to-end learning framework\u2014Mixer Generator Network (MG-Net), as depicted in Fig. 2, to address the above challenges. Particularly, to address C-1, we devise a problem encoder which transforms each problem G into a unified directed acyclic graph $G_c$, ensuring a consistent and effective input format. Coupled with the mixer encoder, it maps both the problem and mixer"}, {"title": "Implementation of MG-Net", "content": "Hamiltonian to a shared hidden space. To address C-2, MG-Net features a unique estimator-generator framework, supplemented by a two-stage training strategy. The role of these techniques is summarized below and their implementation details are demonstrated in the subsequent subsections.\nRole of estimator. Rather than directly seeking the optimal parameter correlation strategy $G^*$ and operator type $P^*$ for a given (G, p), we devise a cost estimator to map the relationship between (G, P) and the achievable minimal cost $F_p$ of the corresponding QAOA in Eqn. (2).\nRole of generator. We devise a generator to predict $(\\mathcal{G}, \\mathcal{P})$ that minimizes the cost estimator's output. This design requires only the cost of any mixer Hamiltonian as a label, thus avoiding the exhaustive search of optimal pairs $(G^*, P^*)$.\nTwo-stage training. The pipeline is visualized in Fig. 2(a).\n\u2022 Stage 1 (Cost Estimator Training). This stage, marked in purple, focuses on training the cost estimator using supervised learning. Inputs include the problem graph G, potential mixer Hamiltonians $H_M$, and the chosen circuit depth p, with the corresponding cost y as the target label.\n\u2022 Stage 2 (Mixer Generator Training). This stage, marked in orange, freezes the cost estimator and only updates the mixer generator to minimize the output of the cost estimator under the unsupervised learning paradigm.\nFor inference on unknown problem instances (in Fig. 2(b)), MG-Net employs only the mixer generator to predict the optimal mixer Hamiltonian, which is then fed into a QAOA solver to derive the final solution. Distinguished by its ability to generalize effectively across a class of problems from a limited learning set, MG-Net sets itself apart from previous studies. Refer to Appendix. C for discussion.\n4.2 Implementation of MG-Net\nData encoder in MG-Net. MG-Net exploits three types of data encoder, i.e., the problem encoder, mixer encoder, and depth encoder, which maps the given problem G, the candidate mixer Hamiltonian $H_M$, and the specified depth p to the same hidden feature space. The construction of these encoders is introduced below and the omitted details are deferred to Appendix D.2.\nCost estimator in MG-Net (Stage 1). Recall Stage 1 in Sec. 4.1, the cost estimator takes the encoded problem graph $G_c$, the encoded mixer Hamiltonian $G_M$, and the encoded circuit depth $x_p$ as inputs, and outputs the prediction of the achievable minimum loss of the corresponding QAOA. Each input is processed by an independent branch respectively: the problem graph branch, the mixer Hamiltonian branch, and the circuit depth branch, as shown in Fig. 3(a). The concatenation of three types of features is subsequently utilized by a multi-layer perceptron (MLP) to output the minimum loss $\\hat{y}$ that the QAOA ansatz can achieve. Refer to Appendix. D.3 for details.\nMixer generator in MG-Net (Stage 2). The mixer generator in MG-Net takes $G_c$ and $x_p$ as input and outputs a targeted mixer Hamiltonian $H_M$. Specifically, the mixer generation is composed of two separate sub-generators: the operator type generator and the parameter grouping generator defined in Eqn. (5), shown in Fig. 3(b). The operator type generator is responsible for generating operator types $\\mathcal{P}$, which is conceptualized as a graph node classification task. The parameter grouping generator is responsible for predicting the sets of index groups ${G_j}_{j=1}^K$ with an unspecified K, which is modeled as a link prediction task. Refer to Appendix. D.3 for details.\n4.3 Training strategy\nThe training process of MG-Net is varied for the first and second stages, under supervised and unsupervised learning paradigms, respectively.\nM\nFirst-stage training. This stage involves constructing a labeled dataset $\\mathcal{D}_{Tr} = {(G^{(i)}_c, G^{(i)}_M, x^{(i)}_p), y^{(i)}}_{i=1}^M$, where the i-th sample consists of a tuple of features (i.e., the problem description $G^{(i)}_c$, the mixer $G^{(i)}_M$, and the circuit depth feature $x^{(i)}_p)$, and the label $y^{(i)}$ representing the minimum cost value achievable by this QAOA instance (i.e., determined by repeatedly executing such a QAOA with varying initial parameters). Once $\\mathcal{D}_{Tr}$ is ready, the cost estimator is optimized by minimizing the loss function\n$\\mathcal{L}_{ce} = \\lambda_d L_e + \\lambda_r L_r$, (6)"}, {"title": "Experiments", "content": "We evaluate the performance of MG-Net by two typical applications of QAOA: weighted Max-Cut and Transverse-field Ising model (TFIM), each of which is elucidated below.\nWeighted Max-Cut. Denote a weighted graph as $G = (V, E, W)$, where V is the set of vertices of graph, E is the set of graph edges, $W = {W_{ij}}_{(i,j)\\in E}$ is the set of weights assigned to each edge. The problem Hamiltonian for the weighted Max-Cut problem is $H_{\\text{MaxCut}} = 0.5 * \\sum_{(i,j)\\in E} W_{ij} Z_i Z_j$, where $Z_i$ is a Pauli-Z operator acting on the i-th qubit.\nTFIM. Our focus is a class of inhomogeneous TFIMs: $H_{\\text{TFIM}} = - \\sum_{(i,j)} J_{ij} Z_i Z_j - h \\sum_i X_i$, where $J_{ij}$ is the interaction strength between neighboring spins (or qubits) (i, j), and h signifies the strength of a global transverse field applied to each spin. In this model, the interaction strengths $J_{ij}$ can vary between different pairs of spins, adding a layer of complexity to the system.\n5.1 Experiment configuration\nDataset construction.The Max-Cut problem focuses weighted 3-degree regular (w3r) graphs, where the edge weights ${W_{ij}}$ are uniformly sampled from [0, 1]. The TFIM focuses on 1D instances where a qubit $i \\in [N - 1]$ has neighbors $i\\pm1 (mod N)$. The strength $J_{ij}$ and h are uniformly sampled from [0.5, 1.5] and [0.1,2] respectively. The training dataset $\\mathcal{D}_{Tr}$ in Sec. 4.3 contains S = 100 instances for both two tasks with size up to N = 64 qubits, while The test dataset $\\mathcal{D}_{Te}$ contains another 100 problem instances which are different from that of $\\mathcal{D}_{Tr}$. Refer to Appendix D.1 for details."}, {"title": "Results", "content": "Cost estimator acts as an accurate performance indication for QAOA. The behavior of the cost estimator on the test dataset with varying circuit depths p and two distinct parameter grouping strategies NG and FG (defined in Theorem 3.1) is recorded in Fig. 4. In Fig. 4(a), we observed a strong correlation between the estimated and minimum cost values, and the correlation strength changes with p and parameter grouping strategy. Particularly, the cost estimator predicts a high likelihood of finding the most accurate solution for QAOA circuits with FG parameters and a depth of p = 92. This prediction aligns with the actual performance of QAOA under these specific conditions.\nWe next focus on the behavior of the cost estimator concerning p as shown in Fig. 4(b). We note that for FG (standard QAOA), the estimated loss decreased monotonically with increasing p, aligning with standard QAOA's behavior. Under the NG scenario (multi-angle QAOA), a transition that QAOA performance begins to decline is observed when the circuit becomes excessively long (p > 42). These results indicate the reliability of the cost estimator as a performance indicator for QAOA and reveal the complexities in QAOA performance under conditions of increased circuit length.\nMixer generator. We next evaluate the performance of the customized mixer Hamiltonian generated by MG-Net. As shown in Fig. 5(a), the number of trainable parameters #P of the generated quantum circuits aligns with the maximum in scenarios where all parameters are non-correlated (labeled as 'NG') for smaller circuit depths p < 20. This alignment indicates that MG-Net effectively enhances the expressibility of the QAOA ansatz for limited-depth circuits without significantly increasing the number of parameters, thereby avoiding potential trainability issues. As p increases, a transition occurs. The growth rate of #P starts to decelerate, reaching a notable transition point at p = 62 for Max-Cut (p = 52 for TFIM). Beyond this threshold, the generated mixer Hamiltonians gradually converge towards the configuration seen in standard QAOA, with fully grouped parameters.\nFig. 5(b) compares the effective dimension $d_{\\text{eff}}$ of quantum circuits achieving high approximation ratio $r\\geq 0.995$ in standard QAOA and MG-Net driven QAOA. The results show that circuits generated by MG-Net achiever $\\geq 0.995$ across all values of p, even as low as p = 2, outperforming standard QAOA, which only reaches this level for p > 50 for Max-Cut (p > 20 for TFIM). Besides, the effective dimension of these high-quality quantum circuits gradually decreases with growing p, in line with the convergence analysis in Theorem 3.1. These findings suggest that MG-Net dynamically adjusts quantum circuits in response to changes in circuit depth p, thereby consistently ensuring high performance."}, {"title": "Conclusion", "content": "In this study, we analyze QAOA's convergence on varied mixer Hamiltonians, focusing on parameter grouping strategies. We introduce MG-Net for dynamically generating optimal mixer Hamiltonians for various problems and circuit depths. Numerical experiments on Max-Cut and TFIM confirm MG-Net's efficacy in enhancing QAOA's approximation ratio, particularly for large-scale problems, while ensuring low circuit complexity. This research advances the understanding and application of QAOA across various circuit depths."}, {"title": "Optimization of QAOA", "content": "In this section", "m": "its density matrix is $\\rho = \\sum_{j=1"}, "m p_j \\rho_j$ with $\\rho_j = |\\psi_j\\rangle \\langle \\psi_j|$ and $Tr(\\rho) = 1$.\nA quantum gate is a unitary operator that can evolve a quantum state $\\rho$ to another quantum state $\\rho'$. Namely, an n-qubit gate $U \\in U(2^n)$ obeys $U U^{\\dagger} = U^{\\dagger} U = I_{2^n}$, where $U(2^n)$ refers to the unitary group in dimension $2^n$. Typical single-qubit quantum gates include the Pauli gates, which can be written as Pauli matrices:\n$X = \\begin{bmatrix} 0 & 1\\\\ 1 & 0 \\end{bmatrix}, Y = \\begin{bmatrix} 0 & -i\\\\ i & 0 \\end{bmatrix}, Z = \\begin{bmatrix} 1 & 0\\\\ 0 & -1 \\end{bmatrix}$. (8)\nThe more general quantum gates are their corresponding rotation gates $R_x(\\theta) = e^{-i \\frac{\\theta}{2} X}, R_y(\\theta) = e^{-i \\frac{\\theta}{2} Y}$, and $R_z(\\theta) = e^{-i \\frac{\\theta}{2} Z}$ with a tunable parameter $\\theta$, which can be written in the matrix form as\n$R_x(\\theta) = \\begin{bmatrix} \\cos \\frac{\\theta}{2} & -i \\sin \\frac{\\theta}{2}\\\\ -i \\sin \\frac{\\theta}{2} & \\cos \\frac{\\theta}{2} \\end{bmatrix}, R_y(\\theta) = \\begin{bmatrix} \\cos \\frac{\\theta}{2} & \\sin \\frac{\\theta}{2}\\\\ - \\sin \\frac{\\theta}{2} & \\cos \\frac{\\theta}{2} \\end{bmatrix}, R_z(\\theta) = \\begin{bmatrix} e^{-i \\frac{\\theta}{2}} & 0\\\\ 0 & e^{i \\frac{\\theta}{2}} \\end{bmatrix}$. (9)\nThey are equivalent to rotating a tunable angle $\\theta$ around x, y, and z axes of the Bloch sphere, and recovering the Pauli gates X, Y, and Z when $\\theta = \\pi$. Moreover, a multi-qubit gate can be either an individual gate (e.g., CNOT gate) or a tensor product of multiple single-qubit gates.\nThe quantum measurement refers to the procedure of extracting classical information from the quantum state. It is mathematically specified by a Hermitian matrix H called the observable. Applying the observable H to the quantum state $|\\psi\\rangle$ yields a random variable whose expectation value is $\\langle \\psi| H |\\psi\\rangle$.\nHamiltonian and ground state. In quantum computation, a Hamiltonian is a Hermitian matrix that is used to characterize the evolution of a quantum system or as an observable to extract the classical information from the quantum system. Specifically, under the Schr\u00f6dinger equation, a quantum gate has the mathematical form of $U = e^{-i t H}$, where H is a Hermitian matrix, called the Hamiltonian of the quantum system, and t refers to the evolution time of the Hamiltonian. Typical single-qubit Hamiltonians include the Pauli matrices defined in Eqn. (8). As a result, the evolution time t refers to the tunable parameter $\\theta$ in Eqn. (9). Any single-qubit Hamiltonian can be decomposed as the linear combination of Pauli matrices, i.e., $H = a_1 I + a_2 X + a_3 Y + a_4 Z$ with $a_j \\in \\mathbb{C}$. In the same way, a multi-qubit Hamiltonian is denoted by $H = \\sum_{j=1}^m a_j P_j$, where $P_j \\in {I, X, Y, Z}^{\\otimes n}$ is the tensor product of Pauli matrices. In quantum chemistry and quantum many-body physics, the Hermitian matrix that describes the quantum system to be solved is denoted as the problem Hamiltonian $H_c$. Within the context of QAOA, the information of the graph is encoded in the problem Hamiltonian, which is also called cost Hamiltonian. Another essential Hamiltonian in QAOA refers to the mixer Hamiltonian $H_M$, which is designed to facilitate transitions between different states (solutions), allowing the algorithm to explore the solution space.\nWhen taking the problem Hamiltonian as the observable, the quantum state $|\\psi^*\\rangle$ is said to be the ground state of problem Hamiltonian H if the expectation value $\\langle \\psi^*| H |\\psi^*\\rangle$ takes the minimum eigenvalue of H, which is called the ground energy. The solution of the optimization problem is encoded in the ground state of the problem Hamiltonian.\nOptimization of QAOA. The loss function for QAOA with problem Hamiltonian $H_c$ is generally defined as\n$\\mathcal{L}(\\theta = (\\alpha, \\beta)) = \\langle \\psi_0|U(\\theta)^{\\dagger} H_c U(\\theta)|\\psi_0\\rangle$, (10)\nwhere $U(\\theta)$ refers to the parameterized unitary implemented on a quantum computer and $|\\psi_0\\rangle$ is an easily prepared state, which is generally set as the computational basis state $|0^n\\rangle$. The optimization of the loss function $\\mathcal{L}(\\theta)$ can be completed by gradient-based methods. A plethora of optimizers have been designed to estimate the optimal parameters $\\theta^* = \\min_{\\theta} \\mathcal{L}(\\theta)$. Here we introduce the implementation of the first-order gradient-based optimizer for self-consistency. Refer to [25"]}