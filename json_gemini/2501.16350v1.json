{"title": "A Method for Multi-Hop Question Answering on Persian Knowledge Graph", "authors": ["Arash Ghafouri", "Mahdi Firouzmandi", "Hasan Naderi"], "abstract": "Question answering systems are the latest evolution in information retrieval technology, designed to accept complex queries in natural language and provide accurate answers using both unstructured and structured knowledge sources. Knowledge Graph Question Answering (KGQA) systems fulfill users' information needs by utilizing structured data, representing a vast number of facts as a graph. However, despite significant advancements, major challenges persist in answering multi-hop complex questions, particularly in Persian. One of the main challenges is the accurate understanding and transformation of these multi-hop complex questions into semantically equivalent SPARQL queries, which allows for precise answer retrieval from knowledge graphs. In this study, to address this issue, a dataset of 5,600 Persian multi-hop complex questions was developed, along with their decomposed forms based on the semantic representation of the questions. Following this, Persian language models were trained using this dataset, and an architecture was proposed for answering complex questions using a Persian knowledge graph. Finally, the proposed method was evaluated against similar systems on the PeCoQ dataset. The results demonstrated the superiority of our approach, with an improvement of 12.57% in F1-score and 12.06% in accuracy compared to the best comparable method.", "sections": [{"title": "1. Introduction", "content": "A knowledge graph is a collection of interconnected entities enriched with semantic labels [1], where nodes represent entities and edges depict the relationships between them [2]. Entities can be various types of named and unnamed objects, such as persons, locations, organizations, events, times, concepts, and more [3]. Knowledge graphs have a wide range of applications, including in search engines, natural language processing, question-answering systems, information extraction, and social networks like LinkedIn and Facebook. The first and most comprehensive Persian-language knowledge graph, named \"FarsBase,\" has been introduced, focusing on general knowledge. Given the absence of an effective knowledge graph in the Persian language, \"FarsBase\" can serve as one of the most crucial resources for natural language question-answering systems [4].\nAnswering questions based on a knowledge graph (KGQA) is a fundamental task in the field of natural language processing, focusing on providing answers to questions posed in natural language by utilizing the information stored in a knowledge graph. KGQA has gained significant attention due to its pivotal role in various intelligent applications. For instance, systems such as Amazon Alexa, Apple Siri, and Microsoft Cortana are examples of platforms that leverage KGQA to respond to user inquiries [5].\nEarly research on KGQA primarily focused on answering simple questions containing a single fact. However, addressing complex questions (involving multiple facts) in English still presents challenges, such as difficulties in understanding complex queries, constructing high-quality datasets, and other related issues. In contrast, research on"}, {"title": "2. Related Works", "content": "In general, there are four primary approaches to Knowledge Graph Question Answering (KGQA):\nTraditional Approach: Traditional KBQA methods rely on manually defined templates and rules to parse complex questions. These methods often require linguistic expertise and face scalability issues [6]. Berant et al. [7] implemented a standard bottom-up parser that generates a large set of question templates based on the entities and relationships of a knowledge base and uses a recursive derivation parser to map parsed phrases to the knowledge base entities and relationships using four predefined manual operations. Bast et al. [8] proposed a template-based model called Aqqu, which maps questions based on three templates by identifying entities, matching them to the knowledge base, and selecting the best response template using a ranking model.\nSemantic Parsing (SP) Approach: In neural semantic parsing-based methods, the goal is to transform natural language questions into executable queries. The natural language question is first understood and interpreted by the system, which then converts it into a general logical form. This logical form is subsequently matched with various knowledge bases, and eventually, it is executed on the relevant knowledge bases according to their specific query formats. In most cases, this executable logical form corresponds to SPARQL queries [9]. Das et al. [10] introduced a"}, {"title": "3. Background", "content": "A knowledge base is a structured database that contains a collection of facts about entities, typically derived from structured repositories like WIKIDATA [24], FreeBase [25], YAGO [26], DBpedia [27] and others, or extracted from encyclopedias like WIKIPEDIA [28]. Knowledge bases are usually represented as graphs, hence the term \"knowledge graphs\" is used for knowledge bases stored in a graph structure [29]. Since the advent of the Semantic Web, knowledge graphs have become associated with Linked Data projects, both focusing on linking entities and concepts [30]. Linked Data refers to a type of structured data that is interlinked with other data, making it suitable for semantic queries. Semantic Web and Linked Data are commonly stored in the RDF (Resource Description Framework) data format. RDF is a graph-based model used to describe interconnected entities such as objects, places, events, abstract concepts and the like. This model provides the best framework for integrating, linking, and reusing data to represent and present a knowledge graph. In Figure 3, the RDF data structure is schematically represented. This structure, as a graph-based model, is used to represent entities and their relationships. RDF consists of three core elements: Subject, Predicate, and Object, collectively referred to as a \"Triple\".\nThe first and most comprehensive knowledge base dedicated to the Persian language, specifically in the domain of general knowledge, is known as FarsBase [31]. Given the absence of a useful knowledge base in the Persian language, FarsBase can serve as one of the most important resources for natural language question answering [32]. The data in a knowledge graph is typically described in triples, consisting of a subject, predicate and object meaning that the subject and object are connected by a predicate [33]."}, {"title": "3. Proposed Methods", "content": "We propose an innovative method for answering multi-hop complex questions, which consists of four key steps: 1) Decomposition of the complex question into simpler questions, 2) Named Entity Recognition and Linking from the simpler questions, 3) Logical Form Generation for each simple question, and 4) Sequential and step-by-step execution of the generated logical forms on the knowledge graph. The diagram related to this process is presented in Figure 4."}, {"title": "3.1 Question Decomposition Component", "content": "Understanding complex questions necessitates multi-hop reasoning. To enhance the comprehensibility of this reasoning and make it easier for users to engage with and comprehend it, this component decomposes complex questions into smaller, semantically meaningful segments. Our approach draws inspiration from the method proposed by Wolfson et al. [35], which emphasizes breaking down complex questions into simpler sub-components. The question decomposition process performed by this component is demonstrated in Figure 5 below."}, {"title": "3.1.1 MRDCPQ Dataset", "content": "In the absence of a ready-made dataset for decomposing complex questions into simpler ones in Persian, we have created the Persian MRDCPQ dataset as the first dataset for semantically decomposing complex questions into smaller semantic units. This dataset has been created according to the standards of the BREAK [36] dataset and based on the PeCoQ [34] dataset, which is related to complex Persian questions over the FarsBase [25] knowledge graph. To provide the necessary infrastructure for better analysis and reasoning over complex multi-hop Persian questions, the MRDCPQ dataset was created. This dataset includes 5,600 complex Persian questions that have been decomposed into smaller semantic units in the form of semantic representation. The purpose of this dataset is to facilitate understanding and answering complex Persian questions.\nData Collection: The complex questions in this dataset were extracted from multi-entity and multi-hop questions. During the dataset construction process, approximately 15,000 multi-hop complex questions were extracted from the PeCoQ dataset. Out of these, 5,600 questions that were correctly decomposed by the annotators were selected for the final dataset.\nAnnotation: Fourteen Persian language experts, who were well-versed in natural language processing (NLP) and question answering systems, were responsible for annotating the data. Each complex question was decomposed into smaller semantic units. The initial semantic decomposition for each question was performed by two independent annotators, and the quality of these decompositions was then reviewed by another annotator. In cases where discrepancies existed in the annotations, all annotators discussed and finalized the decomposition. The MRDCPQ dataset is divided into three categories: training (80%), testing (10%), and validation (10%).\nData Generation Process: To generate the smaller semantic units from complex questions, the information available in the \"Named Entities\" and \"Question Relations\" columns was used. Each multi-hop complex question in the PeCoQ dataset includes named entities and relations present in the question. These two aspects were provided as assisting elements to the annotators in separate columns alongside each multi-hop complex question. This allowed the annotators to better decompose the complex questions into simpler semantic units. This information helps annotators perform precise and logical decomposition of the questions. The ultimate goal is to decompose each complex question into"}, {"title": "3.1.2 The Implementation of Question Decomposition Component", "content": "This component was implemented by fine-tuning the mT5 language model [37] on the MRDCPQ dataset. The mT5 model, which supports multiple languages, was chosen due to its ability to perform well on various linguistic tasks across different languages, including Persian. By training the model specifically on the MRDCPQ dataset, the goal was to enable the model to decompose complex Persian questions into simpler, semantic sub-components effectively. The trained model generates outputs that break down multi-step questions into logical segments, allowing for easier processing and reasoning. An example of the output produced by the trained model is shown in Table 2."}, {"title": "3.2 Named Entity Recognition (NER) Component", "content": "A complex multi-step question may involve multiple named entities. In the first stage, named entities need to be extracted from the simplified semantic segments derived from the complex question (MRDCPQ). For this purpose, a Named Entity Recognition (NER) module has been developed by fine-tuning the ParsBERT [38] model (Farahani et al., 2020) on the MRDCPQ dataset. The PeCoQ dataset, from which the complex multi-step questions were extracted, includes named entities based on the FarsBase knowledge graph. Therefore, these named entities were applied to the decomposed question segments as the dataset for the NER task to fine-tune the model.\nExperimental results indicate that our proposed NER method outperforms existing Persian language tools in extracting named entities from decomposed segments of complex questions. The evaluation of our NER tool is discussed in section 4.\nAfter extracting named entities, the next step is linking them to FarsBase. Following the Zero-shot method introduced by Wu et al [39]. we first extract five candidates from the FarsBase knowledge graph using string similarity. We then map the abstract information of each candidate entity from FarsBase into dense vectors using the ParsBERT [38] model for dense retrieval. Next, the vector of each candidate entity is compared with the vector of the complex question text from which the named entity was extracted. This comparison is conducted using cosine similarity. The"}, {"title": "3.3. MRDCPQ to SPARQL Query Generator Component", "content": "In this section, we focus on generating a dataset by leveraging the decomposed components of complex questions (MRDCPQ), which are, in essence, simplified questions normalized to form SPARQL queries. Each MRDCPQ acts as an input, while its corresponding SPARQL query serves as the output. The process of building this dataset, aimed at converting the decomposed parts of complex questions into SPARQL queries, was expedited due to the availability of the Relations key in the PeCoQ dataset.\nDataset Construction Process: For the creation of this dataset, alongside the development of the MRDCPQ dataset, a SPARQL query was generated for each simplified component of the complex question. The creation of these queries relied on the entities extracted from the complex question and the Relations available for each query in the PeCoQ dataset. These extracted entities and relations guided the SPARQL query generation process. Figure 7 illustrates the fine-tuning process of the mT5-based model, which converts decomposed parts of a complex question (MRDCPQ) into executable SPARQL queries.\nTo enhance the process, the mT5 model was fine-tuned using a custom dataset. This dataset included natural language questions and their corresponding SPARQL queries. By training the model on this specific dataset, the system learned how to map a simplified, structured query into a full SPARQL query. The model was trained to identify key components such as the main entity (e.g., Digikala), relevant relations (e.g., headquarter), and target attributes (e.g., population). This fine-tuning enabled the model to generate SPARQL queries step by step, starting from an entity and progressing through the relations to the final information retrieval. By breaking down each MRDCPQ into its logical steps, the model can automate the query creation process, making the overall conversion from complex natural language queries into SPARQL more efficient."}, {"title": "3.4. SPARQL Query Execution and Response Composition", "content": "This component is responsible for executing the hierarchical SPARQL queries generated in the previous stage on the knowledge graph (KG). Given that the results from each SPARQL query need to be used in the subsequent query, managing this process is another essential task of this component. At the end of the process, the final response is refined and prepared as the answer to the complex question posed.\nAs illustrated in Figure 8, the breakdown of a complex question into individual simpler components (MRDCPQ) helps structure the query-building process. Each parsed component contributes to a distinct SPARQL query step. For example, the figure 8 demonstrates how the question \"What is the population of the country where Digikala's headquarters is located?\" is split into three parts: \"Digikala,\" \"headquarters,\" and \"population,\" resulting in successive SPARQL queries to gather the required information from the knowledge graph.\nThe component consists of two subcomponents:\n1. Execution of SPARQL Queries on the Knowledge Graph: Handles the execution of each query step-by- step, ensuring that results from one query feed into the next.\n2. Final Response Preparation: Formats and finalizes the output, ensuring it is well-structured for the original complex question."}, {"title": "4. Evaluation", "content": "To evaluate the proposed method, it is necessary to assess the constituent components and the efficiency of each, which will be detailed subsequently."}, {"title": "4.1 Question Decomposition Component", "content": "In this research, the evaluation of the model for decomposing complex questions into simpler questions based on the Task Decomposition Accuracy (TDA) metric yielded a score of 77.61%. TDA is particularly well-suited for evaluating the precision of breaking down complex questions into simpler ones. This metric is highly effective in assessing the core task at hand, which is decomposing complex questions into simpler, manageable steps. The focus of TDA is on evaluating the accuracy of splitting complex tasks into simpler subtasks.\nThe Task Decomposition Accuracy (TDA) metric measures whether the decomposition of complex questions into simpler questions has been carried out correctly. In other words, it examines whether the extracted steps are logically correct, precise, and arranged in the proper sequence.\nKey criteria assessed using the TDA method include:\n\u2022 Semantic Segment Accuracy: Each part of the question must be accurately transformed into a simpler step.\n\u2022 Correct Sequencing: The steps should be logically connected and follow one another in a step-by-step manner.\n\u2022 Complete Coverage of the Question: The decomposed questions must cover the entire meaning of the complex question."}, {"title": "4.2 Named Entity Recognition (NER) Component", "content": "Table 3 demonstrates that fine-tuning ParsBERT on the MRDCPQ dataset significantly improves its performance in the Named Entity Recognition (NER) task compared to ParsBERT models trained on the Arman and PeCoQ datasets. The fine-tuning process allows ParsBERT to better capture domain-specific nuances, particularly when handling multi-hop complex questions, thereby enhancing its ability to recognize named entities more accurately. The comparison highlights the importance of task-specific training data in improving the accuracy of NER models, especially in complex question-answering systems based on knowledge graphs."}, {"title": "4.3. MRDCPQ to SPARQL Query Generator Component", "content": "In the process of generating SPARQL queries from the simplified questions (MRDCPQ), which were decomposed by the \"Question Decomposition Component\" in the previous stage, we utilized a fine-tuned mT5 model trained on a prepared dataset. The evaluation of this step shows that the model effectively transformed the simplified questions into their corresponding SPARQL queries, achieving an F1 Score of 82.35%. This result highlights the model's robust performance in converting natural language questions into executable logical forms on the knowledge graph."}, {"title": "4.4. The Component of Extracting Answers from the Knowledge Graph", "content": "In order to assess the efficiency of the proposed method, the results obtained from the Component of Extracting Answers from the Knowledge Graph in our approach were compared to the only existing similar work, namely the research by Etezadi et al. [23], which includes the PeCoQ dataset and a proposed evaluation method for it. As illustrated in Table 4 and Figure 9, the findings demonstrate that our proposed method achieves significant improvements across key metrics: precision by 13.12%, recall by 11.96%, F1 score by 12.57%, and accuracy by 12.06% when compared to Etezadi's method."}, {"title": "5. Conclusion and Future Works", "content": "In this paper, we proposed a novel approach to address the challenge of answering complex natural language questions by leveraging a Persian knowledge graph. Our method consists of four main components: question parsing, named entity recognition, conversion of complex questions into SPARQL queries, and answer extraction from the knowledge graph. These components work together to accurately respond to user queries. A significant challenge we focused on was the transformation of complex questions into SPARQL queries, which was achieved by breaking down complex questions into simpler sub-questions, converting each into a SPARQL query, and then merging the results. The proposed approach was tested against existing methods using the PeCoQ dataset, and the results demonstrated its superiority in various evaluation metrics.\nIn future work, we aim to explore the following directions to further enhance the system:\n1. Expanding the dataset for question decomposition: Increasing the dataset size and diversity to include a broader spectrum of complex questions across different domains.\n2. Improving language models: Incorporating advanced language models, such as large-scale models, to increase system accuracy and efficiency.\n3. Exploring multimodal learning: Integrating textual and visual data to enable the system to handle multimedia-based queries.\nThese directions could significantly improve the performance of question-answering systems and lead to a better user experience when dealing with complex queries."}]}