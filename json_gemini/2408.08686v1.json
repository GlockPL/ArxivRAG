{"title": "SC-Rec: Enhancing Generative Retrieval with Self-Consistent Reranking for Sequential Recommendation", "authors": ["Tongyoung Kim", "Soojin Yoon", "Seongku Kang", "Jinyoung Yeo", "Dongha Lee"], "abstract": "Language Models (LMs) are increasingly employed in recommendation systems due to their advanced language understanding and generation capabilities. Recent recommender systems based on generative retrieval have leveraged the inferential abilities of LMs to directly generate the index tokens of the next item, based on item sequences within the user's interaction history. Previous studies have mostly focused on item indices based solely on textual semantic or collaborative information. However, although the standalone effectiveness of these aspects has been demonstrated, the integration of this information has remained unexplored. Our in-depth analysis finds that there is a significant difference in the knowledge captured by the model from heterogeneous item indices and diverse input prompts, which can have a high potential for complementarity. In this paper, we propose SC-REC, a unified recommender system that learns diverse preference knowledge from two distinct item indices and multiple prompt templates. Furthermore, SC-REC adopts a novel reranking strategy that aggregates a set of ranking results, inferred based on different indices and prompts, to achieve the self-consistency of the model. Our empirical evaluation on three real-world datasets demonstrates that SC-REC considerably outperforms the state-of-the-art methods for sequential recommendation, effectively incorporating complementary knowledge from varied outputs of the model.", "sections": [{"title": "1 Introduction", "content": "Sequential recommendation (Kang and McAuley 2018; Sun et al. 2019; Hidasi and Karatzoglou 2018; Tang and Wang 2018) aims to predict a user's next interaction by capturing the context (or preference) from users' interaction history. With the remarkable advancement of language models (LMs), recent progress in sequential recommender systems has been driven by utilizing LMs to leverage their text understanding and generation capabilities (Dai et al. 2023; Bao et al. 2023; Yuan et al. 2023; Li et al. 2023; Zhang et al. 2023). To formulate the recommendation task within generative LMs, existing methods have adopted the generative retrieval approach (Rajput et al. 2023; Hua et al. 2023; Zheng et al. 2023), which decodes the item identifiers (e.g., titles, attributes, descriptions, and numeric IDs) by taking the user's interaction history as the input prompt. Based upon this architecture, several foundation models have been proposed, such as P5 (Geng et al. 2022) and M6Rec (Cui et al. 2022), specifically fine-tuned for recommendation tasks.\nTo effectively inject item knowledge into the LM-based recommenders via item identifier tokens, there have been several efforts to construct an item index in a hierarchical structure (Rajput et al. 2023; Hua et al. 2023), where the structure encodes various aspects of item knowledge. Most existing studies have tried to encode semantic information of items, including textual descriptions (Rajput et al. 2023) or predefined category (Hua et al. 2023; Lin et al. 2023) provided by item metadata, into the hierarchical index structure. Additionally, inspired by the concept that items with frequent co-occurrence are more similar, several indexing methods have been proposed to distill collaborative information into the index structure; for example, previous work employs spectral clustering on the item co-occurrence matrix (Hua et al. 2023) by using matrix factorization.\nIn this work, we focus on varied outputs generated by an LM-based recommender, depending on (1) input prompt templates that describe the detailed instruction for the sequential recommendation task, and (2) types of hierarchical item indices that are used to represent each item as multiple tokens. For example, as depicted in Figure 1, the successful retrieval of a target item often hinges on the structure of the item index, because each index structure is built based on unique sources of user/item information. In our preliminary analysis, we observe that the model's diverse outputs (i.e., top-K ranked lists) capture complementary knowledge in predicting user's next items. Specifically, less than 50% of the correctly predicted answers are shared among the retrieval results obtained with different item indices. Furthermore, the model captures diverse contexts from various prompt templates, leading to varied retrieval results that encompass complementary predictions by over 5%. This analysis motivates us to make a final ranked list by aggregating a set of ranking results to achieve self-consistency of the recommendation model. This is consistent with recent findings that pursuing self-consistency across diversely-sampled reasoning paths can remarkably enhance the reasoning capability of LLMs (Wang et al. 2022a).\nBased on this motivation, we present SC-REC, a novel framework for Self-Consistent sequential Recommendation. SC-REC leverages diverse prompt templates and heterogeneous item indices for enhancing generative retrieval through self-consistency. To be specific, our framework consists of three stages: (1) item multi-index generation, (2) multi-index recommender training, and (3) self-consistency score-based reranking. First, it generates two types of indices based on the concept of hierarchical quantization (Lee et al. 2022) by using collaborative and semantic embeddings of items. Second, our model predicts the next preferred item based on an input prompt that describes the user's interaction history, incorporating variation through diverse templates and heterogeneous item indices. In the end, SC-REC reranks the items by aggregating a set of ranked lists based on the two metrics: confidence and consistency. These metrics measure \"how confident the model is in predicting each item to be near the top rank\" and \"how consistent the model is in predicting the rank of each item\u201d, respectively.\nOur empirical evaluation on three real-world datasets demonstrates that our SC-REC framework considerably outperforms the state-of-the-art methods for the sequential recommendation task. Specifically, SC-REC effectively generates a high-quality reranked list by integrating complementary knowledge from heterogeneous index types and diverse prompt templates. We also provide extensive quantitative, ablative, and exploratory experiments to verify the effectiveness of each proposed technique."}, {"title": "2 Related Work", "content": "Generative retrieval leverages the generation capabilities of generative models to enhance information retrieval systems by directly generating relevant contents from the database. GENRE (De Cao et al. 2020) was proposed for the entity retrieval task, which retrieves entities by generating their unique names token-by-token in an autoregressive manner. DSI (Tay et al. 2022) focuses on the document retrieval task, which retrieves document identifiers that are relevant to queries. It first assigns a structured semantic document ID to each document. Then, given a query, a unified text-to-text model is trained to autoregressively decode the document's identifier token-by-token. Subsequently, NCI (Wang et al. 2022b) proposes a new decoder architecture that can take into account position information for DSI."}, {"title": "2.2 Sequential Recommendation", "content": "Sequential recommendation refers to the task of predicting the next item users will interact with based on the sequence of their past interactions.\nTraditional sequential recommender Early approaches often rely on Markov Chain techniques to model user behavior based on historical interactions (Rendle 2010). GRU4Rec (Hidasi et al. 2015) is the first work to use Gated Recurrent Unit (GRU) for sequential recommendation, while SASRec (Kang and McAuley 2018) employs the self-attention mechanism, similar to decoder-only transformer models, to capture long-range dependencies. Additionally, transformer-based models, such as BERT4Rec (Sun et al. 2019) and Transformers4Rec (de Souza Pereira Moreira et al. 2021), leverage masking strategies for training. Recent studies have explored pre-training techniques by using self-supervised learning tasks. S\u00b3-Rec (Zhou et al. 2020) uses pre-training on four self-supervised tasks to improve the quality of item embeddings. VQ-Rec (Hou et al. 2023) proposes a new approach to build a transferable sequential recommender through contrastive pre-training and cross-domain fine-tuning methods.\nGenerative sequential recommender Recently, the generative retrieval approach has been actively employed for sequential recommendation (Rajput et al. 2023; Hua et al. 2023; Zheng et al. 2023). This approach leverages the inference and generation capabilities of language models to directly generate sequences of indices for the target item. P5 (Geng et al. 2022) integrates various recommendation tasks into a natural language generation framework. P5-IDs (Hua et al. 2023) introduces various indexing methods, including Collaborative ID, Semantic ID, and Sequential ID, designed for use with the P5 model. TIGER (Rajput et al. 2023) utilizes a tree-structured vector quantization (VQ) (Van Den Oord, Vinyals et al. 2017), which constructs a coarse-to-fine sequence of quantized codewords, to generate item IDs based on text features. TransRec (Lin et al. 2023) presents multi-faceted identifiers that cover various aspects (e.g., title and attribute) from the textual metadata of items, and LC-Rec (Zheng et al. 2023) proposes various semantic alignment tasks to facilitate the integration of item indices into LLMs. Despite their effectiveness, an effective and systematic integration of heterogeneous information for indexing has remained unexplored."}, {"title": "3 PRELIMINARIES", "content": "In this section, we outline the sequential recommendation task and provide a motivating analysis of how collaborative and semantic IDs capture different aspects of knowledge."}, {"title": "3.1 Problem Formulation", "content": "Given a user-item interaction dataset, U and I denote the set of users and items, respectively. User-item interactions (e.g., review, click, and purchase) are represented by Z(u) = [i_1, i_2,...,i_L], where u \u2208 U, i_u \u2208 I, and L = |Z(u)|. The goal of the sequential recommendation task is to predict the next item i_{L+1} that a user will be interested in based on the user's interaction history Z(u).\nIn this work, we focus on a language model-based sequential recommendation (Geng et al. 2022), which takes a user's interaction history in the form of an instruction prompt. In this setting, T denotes the set of diverse templates used for prompting the language model, and H_t is the set of correct prediction (i.e., test interaction) presented in the output top-K ranked list when using template t."}, {"title": "3.2 Complementarity from Diverse Prompts and Heterogeneous Item Indices", "content": "We conduct an in-depth analysis of how much complementary knowledge are encoded in the generated ranked lists when predicting the next item using different (1) prompt contexts and (2) index types.\nExperimental settings for analysis To explore the complementarity of ranking results in sequential recommendation models, we finetune the P5 model (Geng et al. 2022) to predict the next item using diverse prompt templates and heterogeneous types of item index. The model captures context from the input, which is constructed from an interaction sequence of item indices based on a prompt template, and then generates a ranked list for the next item. Since the input context serves as preference knowledge for generating a ranked list, different contexts produce diverse results.\nTo consider diverse contexts from different prompts, we simply utilize 10 templates employed in P5 for sequential recommendation. These prompts introduce perturbations to the item sequences through slight variations in vocabulary and their order. For the detailed prompts, refer to the Table 5 in Appendix. Moreover, to address heterogeneous item indices, we construct two types of item indices, referred to as CEID and SEID, based on collaborative and semantic item information, respectively. Following the previous work on item indexing (Rajput et al. 2023), we use the RQ-VAE (Lee et al. 2022) architecture with collaborative and semantic item embeddings. More details about the index generation process based on RQ-VAE is discussed in Section 4.1.\nComplementarity across prompts To investigate the complementarity of results across 10 different prompt templates, we measure Pairwise Exclusive-hit Ratio (PER) (Kang et al. 2022) which represents the proportion of correct results exclusively predicted by prompts.\n\\(PER(t_1; t_2) = \\frac{|H_{t_1} - H_{t_2}|}{H_{t_1}}\\)\n\\(PER(t_1; t_2)\\) quantifies the knowledge of user-item relationship correctly captured by template t\u2081 but not by template t\u2082 based on Hit@10 predictions. We compute the PER values for all pairs among the 10 different templates, and visualize the results in the PER map. In Figure 2, there exists complementarity in hit ratio across prompt variations within the same index type (i.e., CEID and SEID), with minor prompt changes causing up to 5% performance differences.\nComplementarity across item index types We also measure Complementary Hit Ratio (CHR) (Kang et al. 2022) to examine the complementarity between the two index types.\n\\(CHR_{avg}(T_1; T_2) = \\frac{1}{|T_1|} \\sum_{t \\in T_1} \\frac{|H_t - \\bigcup_{t' \\in T_2} H_{t'}|}{|H_t|}\\)\n\\(CHR_{avg}(T_1; T_2)\\) quantifies the average of the complementary knowledge that cannot be captured by each of templates in T\u2081 but can be covered by the predictions from the set of templates in T\u2082 based on Hit@10 predictions. A high \\(CHR_{avg}\\) value indicates that prediction results can be greatly complemented by those of the counterpart. Notably, in Table 1, we observe that the \\(CHR_{avg}\\) values between the two different item index types exceed 48%.\nObservations Our preliminary experiments demonstrate that the model captures highly diverse contextualized representations (i.e., preference knowledge), resulting in varied inference outcomes due to differences in prompts and item index types. Firstly, varied prompts introduce nuanced differences in the contextual information considered by the model, leading to diverse outputs. Secondly, the model acquires significantly different contextualized representations from heterogeneous indices. This shows that leveraging heterogeneous indices derived from various sources introduces different inductive biases, which enable the model to learn diverse patterns or representations.\nTo sum up, both prompt templates and index types play pivotal roles in shaping recommendation outcomes. Therefore, incorporating diverse prompts and heterogeneous indices can significantly enhance the model's efficacy in generating accurate recommendations. Our research aims to leverage this diversity in a complementary manner to improve recommendation performance through reranking."}, {"title": "4 Method", "content": "In this section, we present SC-REC, a sequential recommendation framework that leverages diverse prompt templates and heterogeneous item indices with its reranking strategy based on self-consistency. In contrast to previous sequential recommendation methods that use a homogeneous item index (Rajput et al. 2023), SC-REC incorporates heterogeneous item indices into a single neural model, to leverage complementary knowledge from diverse prediction results. The overview of SC-REC is illustrated in Figure 3."}, {"title": "4.1 Item Multi-Index Generation", "content": "We present the construction process for collaborative embedding-based item index (i.e., CEID) and semantic embedding-based item index (i.e., SEID), which are also used for our analysis in Section 3.2.\nItem embedding generation Item embeddings can be effectively computed from either collaborative or semantic information. To obtain the collaborative embeddings, we define a user-item interaction matrix and optimize a collaborative filtering (CF) model, such as LightGCN\u00b9 (He et al. 2020), to encode a user's item interaction history. It is worth noting that LightGCN is optimized solely on the training data used for sequential recommendation tasks to prevent data leakage. For semantic embeddings, we use Sentence-T5 (Ni et al. 2021) as a text encoder to convert each item's textual information, such as title, brand, categories, description, and attributes, into the item embedding vectors.\nIndex tree generation from item embeddings For each type of embedding, we generate its corresponding index tree using the tree-structured vector quantization (VQ) method (Van Den Oord, Vinyals et al. 2017), specifically residual-quantized variational autoencoder (RQ-VAE) (Lee et al. 2022). This approach enhances autoregressive generation by providing hierarchical item representations, allowing the model to capture dependencies at multiple levels of abstraction. This structured approach offers richer context for sequence generation. Detailed equations for RQ-VAE are provided in the appendix B.\nHandling collisions of item IDs Depending on the distribution of item embeddings, ID collisions may occur, which results in multiple items being mapped to the same ID. To mitigate these collisions, we introduce an additional identifier at the final level of the codeword to ensure their uniqueness. Colliding items receive a unique identifier starting from 1, while non-colliding items have a zero (0) appended to their unique ID to maintain consistent codeword lengths."}, {"title": "4.2 Multi-Index Recommender Training", "content": "Language model for sequential recommendation To effectively capture users' historical interactions within natural language contexts, we employ the P5 model (Geng et al. 2022) as the backbone of our sequential recommender model. The P5 model uses an encoder-decoder architecture with the pre-trained T5 language model (Raffel et al. 2020), fine-tuned for various recommendation tasks.\nOur approach is built upon a language model-based generative retrieval framework, to directly generate the index of the next item. For the sequential recommendation task, we arrange the sequence of items according to the user's interaction history in a chronological order. Subsequently, we convert this sequence of items into the sequence of item indices, by using CEID and SEID (in Section 4.1). To construct the final input prompt, we utilize the input prompt templates employed in P5 for sequential recommendation tasks.\nModel training with heterogeneous item indices User u's purchase history of items is given as Z = (i_1, i_2,...,i_n), where the index of each item \\(i_n\\) is denoted by \\((ID_{i_n,1},..., ID_{i_n,L})\\) with a code length of L. Then, the user's interaction history sequence of indices can be represented as follows:\n\\((ID_{i_1,1}, ID_{i_1,2},..., ID_{i_1,L}), ..., (ID_{i_n,1}, ID_{i_n,2},..., ID_{i_n,L})\\).\nTo distinguish these newly created Out-of-Vocabulary (OOV) tokens from existing ones, we use angle brackets <>. We introduce additional special tokens to represent the indices of items and task instructions to ensure effective learning of both index types by our model. We utilize two additional special tokens, \u201c(C)\u201d and \u201c<S>\u201d each for CEID and SEID, to serve as index type indicators. Each index type indicator is placed between \u201citem\u201d and the actual item indices, specifying the type of the ID. Additionally, at the end of the prompt, we explicitly provide the task instructions as \u201cGiven (C), predict (C).\u201d and \u201cGiven <S>, predict <S>.\u201d, respectively. This reconfiguration of prompts allows our single model to effectively learn each type of item index separately. The below table provides an example of an actual training instance made by the CEID index.\n\u201cUser_u has purchased: item_(C)(CEIDi1,1)...(CEIDi1,L),..., item_ (C) (CEIDin,1)...(CEIDin,L). Predict the next possible item to be bought by the user. Given (C), predict (C).\u201d\nAnswer: \"item_(C)<CEIDin+1,1)...(CEIDin+1,L)\"\nThe training tasks can be formatted as conditional generation tasks in a sequence-to-sequence manner. We optimize the negative log-likelihood of the target item index to be generated as following equation:\n\\(L=-\\sum_{x \\in \\{CEID, SEID\\}} \\sum_{t \\in T} \\sum_{l=1}^{L} log P(Z_{lt}^x|Z)\\).    (3)"}, {"title": "4.3 Self-Consistency for Item Reranking", "content": "Our goal is to generate a final ranked list of the top-K items that accurately reflects user preferences and maintains consistency across diverse prompts and heterogeneous indices. To effectively leverage complementary knowledge, we propose a novel reranking strategy that aggregates items consistently ranked highly across the ranked lists. This reranking process is built upon the concept of self-consistency (Wang et al. 2022a), measured by two distinct metrics:\n\u2022 Confidence: How confident is the model in predicting the rank of each item near the top?\n\u2022 Consistency: How consistent is the model in predicting the rank of each item?\nWhen the model consistently places an item near the top in multiple ranked lists, it can be considered a more confident and reliable prediction to be ranked high in the final list.\nTo be specific, our P5 recommender generates a list of K most likely items for each prompt template and index type based on beam search of beam size K. As discussed in Section 3.2, diverse prompt templates and heterogeneous index structures lead to diverse predictions in the ranked lists.\nLet rank(i; x, t) denote the rank of item i from template t with index type x, where a lower value means a higher ranking position. Then, we can make a collection of ranking positions \\(\\pi^x(i)\\) of item i from the set of templates T and index type x \u2208 {CEID, SEID},\n\\(\\pi^x(i) = \\{rank(i; x, t)|t \\in T\\}\\)        (4)\nNote that we include an item i's ranking position in \\(\\pi^x(i)\\) only in case that the item is ranked at top-K within each ranked list, i.e., rank(i; x,t) < K. Based on \\(\\pi^x(i)\\), we define two self-consistency scores, named CONF and CONS, which are calculated for each item i.\nFirst, the score CONF aims to measure the confidence of the model in predicting item i near the top rank; thus, we define the score by the average ranking position of item i, transformed by a monotonically decreasing function f. A higher CONF Score for an item implies that its predictions can be considered more confident.\n\\(CONF(\\pi^x(i)) = f(mean(\\pi^x(i))) = f(\\frac{\\sum_{r \\in \\pi^x(i)} r}{|\\pi^x(i)|}) = f(\\bar{r})\\)   (5)\nIn this work, we use the function f(r) = exp(-r/\\tau) to put more emphasis on top positions, where \u03c4 is a hyperparameter controlling the emphasis.\nIn addition, the score CONS is designed to measure how consistent the model is in predicting the rank of each item; thus, it is modeled by the sample standard deviation of the ranking position of item i with function f. To calculate the sample standard deviation of an item's rank within multiple lists, we only consider the item i such that |\\(\\pi^x(i)\\)| > 1. In this sense, a higher CONS score for an item implies that its predictions can be considered more reliable.\n\\(CONS(\\pi^x(i)) = f(stdev(\\pi^x(i))) = f(\\sqrt{\\frac{\\sum_{r \\in \\pi^x(i)} (r - \\bar{r})^2}{|\\pi^x(i)| - 1}})\\)       (6)\nFor each index type x, the self-consistency score (i.e., SCEID (i) and SSEID(i)) is obtained by the combining the CONF and CONS over diverse prompt templates.\n\\(S^x(i) = \\alpha \\cdot CONF(\\pi^x(i)) + (1 - \\alpha) \\cdot CONS(\\pi^x(i))\\)   (7)\nwhere \\(\\alpha\\) is the hyperparameter to balance the importance between CONF and CONS of each item across multiple ranked lists from T. In the end, the final reranked item list is obtained by selecting top-K items based on their final self-consistency score S(i), defined by\n\\(S(i) = S^{CEID}(i) + S^{SEID}(i)\\)      (8)\nNote that our final self-consistency score S(i) effectively incorporates complementary knowledge from diverse prompt templates and heterogeneous index types, which alings with the concept of self-consistency."}, {"title": "5 Experiments", "content": "In our experiments, we utilize the three datasets: Amazon Beauty, Amazon Sports, and Yelp. The Amazon datasets (He and McAuley 2016) are obtained from Amazon.com for product recommendations, while the Yelp dataset comprises a collection of user ratings and reviews for business recommendations. We present the dataset statistics and preprocessing details in Appendix A.1.\nEvaluation setup To assess the recommendation performance, we use two popular top-N ranking metrics: (1) hit ratio (H@K) and (2) normalized discounted cumulative gain (N@K). In our experiments, we set K to 5 and 10. For rigorous evaluation, we report full-ranking results across the entire item set rather than relying on sample-based evaluation. For generating a ranked list from a language model, we use beam search with a beam size of 20. For the self-consistency score-based reranking, we set \u03c4 = 10 and the number of templates |T| = 10.\nBaselines We compare various recommendation methods, categorized into three groups: (1) collaborative filtering methods, (2) sequential recommendation with autoregressive modeling, and (3) generative retrieval methods based on PLMs. For detailed descriptions of the baseline methods, please refer to Appendix A.2."}, {"title": "5.2 Experimental Results", "content": "Effectiveness of SC-REC framework In Table 2, we compare the recommendation performance of SC-REC with baseline methods on the three datasets. Overall, SC-REC consistently achieves superior performance across all datasets. Generative retrieval-based recommenders (i.e., P5-IDs and TIGER) generally perform well, surpassing traditional sequential recommendation methods. showing superior performance compared to the existing sequential recommendation methods. Notably, their performance largely varies depending on the indexing approach, which shows the importance of proper indexing.\nWe also observe that simply appending two types of indexes (e.g., CID+IID and CID+SemID) often fails to fully leverage their complementary knowledge and can largely degrade performance. In particular, P5 (CID+SemID), which concatenates Collaborative ID and Semantic ID, demonstrates limited performance. In other words, the consecutive generation of two hierarchical information is not suitable for auto-regressive decoding. In contrast, SC-REC (CID+SemID) shows that our self-consistency scoring enhances effectiveness not only in the case of (CEID+SEID) but also when using (CID+SemID), by effectively integrating and refining predictions from each.\nAnalysis of self-consistent reranking strategy We conduct a detailed analysis to validate our reranking strategy that integrates two heterogeneous index types (i.e., CEID and SEID) based on two self-consistency metrics (i.e., CONF and CONS). We analyze the impacts of each component by ablating it from the reranking process. We report the reranking results of (1) a multi-index recommender trained by using both CEID and SEID and (2) two single-index recommenders each of which is trained on either CEID and SEID.\nFor the multi-index recommender, the best performance is achieved by using both index types and metrics. Ablating either index type consistently degrades the performance. In the Yelp dataset, where item metadata lacks detailed descriptions, SEID shows lower performance compared to other datasets. We observe that our reranking strategy effectively integrates complementary knowledge from different index types, consistently generating high-quality recommendations, especially when textual information is limited. This can be particularly beneficial in practical scenarios when textual information is limited. Additionally, ablating either metric degrades performance. This indicates that both confidence and consistency effectively reveal prediction reliability, supporting the validity of our design.\nFor the single-index recommender, where each index is derived from the inference results of different models that store distinct knowledge in their parameters, our reranking strategy performs well overall. However, the tendency is slightly different compared to the multi-index recommender. Specifically, we observe that the consistency metric is less effective, possibly due to the discrepancy in the training behaviors of the two different models.\nImpacts of template numbers We analyze the impacts of template numbers used for reranking. We increase the number of prompts used for aggregation from 2 to 10, and investigate the performance variation accordingly. From Figure 4, we observe a strong positive correlation between the number of prompts and recommendation performance. This result aligns well with our finding that Varied prompts introduce nuanced differences in the contextual information, leading to diverse outputs. It also supports the effectiveness of our self-consistency reranking in integrating the complementary knowledge from different prompts. The experimental result for the Yelp dataset is provided in the Appendix C.\nAnalysis of scoring function We analyze the impacts of the scoring function f(x) = exp(-x/\u03c4) in our reranking strategy. We report the results with five different values of \u03c4 \u2208 {2, 5, 10, 20, 40}. As \u03c4 increases, the function becomes less sharp, thereby considering the overall confidence and consistency across the top-ranked items. On the other hand, with a very small \u03c4, the function assigns a particularly high score to a few top-rank positions, which cannot effectively consider both aspects. In Figure 5, we observe a consistent increasing trend up to \u03c4 = 10, and stable performance beyond 10. These results show that the proposed technique is not sensitive to the hyperparameter choice, and also supports the effectiveness of our reranking strategy that considers both confidence and consistency of predictions."}, {"title": "6 Conclusion", "content": "This paper first presents an in-depth analysis showing that complementary knowledge is revealed from the generated ranked lists when the model uses various prompt contexts and heterogeneous index types. Motivated by the analysis, we seek to leverage this complementarity through self-consistency of the recommendation model to improve the performance. We propose SC-REC framework that collectively utilizes diverse prompt templates and heterogeneous item indices to enhance generative retrieval-based sequential recommendation. We devise a systematic approach to generate collaborative and semantic IDs and train a unified model using multi-index information. Furthermore, we introduce a new self-consistency score-based item reranking, which produces a final ranked list by harnessing complementary knowledge from a collection of ranked lists. We validate the superiority of SC-REC through extensive experiments.\nWhile our model effectively reranks diverse prompts and heterogeneous index types for sequential recommendation tasks, it inevitably incurs higher computational costs. Nevertheless, our research highlights the significant advantage of leveraging self-consistency to effectively integrate diverse prompt and heterogeneous item indices into a unified model. This approach ensures robust and complementary inference across various item information sources. We will focus on developing strategies to enhance computational efficiency while maintaining the effectiveness of our model."}, {"title": "A Detailed Descriptions for Experiments", "content": "Following previous methods (Zhou et al. 2020; Rajput et al. 2023; Zheng et al. 2023), We filtered unpopular users and items with less than five interactions. The maximum interaction sequence length is uniformly set to 20 same as baselines. Table 4 summarizes the statistics of the datasets. We extract transaction records from Jan 1, 2019, to Dec 31, 2019, consistent with prior studies (Hua et al. 2023) for Yelp dataset. For each dataset, we employ a leave-one-out setting to split it into training, validation, and testing sets, following the widely-used evaluation protocol (Kang and McAuley 2018; Zhou et al. 2020). Specifically, within each user's interaction history, each of the second-to-last and last item is allocated to the validation and testing set, respectively, while all other items in the sequence are included in the training set. we only keep the 5-core datasets, and filter unpopular items and inactive users with fewer than five interaction records."}, {"title": "A.2 Baselines", "content": "The first group includes the representative collaborative filtering method.\n\u2022 LightGCN (He et al. 2020) utilizes lightweight GCN encoders, which linearly propagate the interaction of users and items.\nThe second group includes sequential recommendation methods with auto-regressive modeling.\n\u2022 GRU4Rec (Hidasi and Karatzoglou 2018) is a GRU-based sequence model that predicts the next item given the user's sequential interaction history.\n\u2022 Bert4Rec (Sun et al. 2019) employs the transformer architecture for sequential recommendation. It adopts a mask prediction task for BERT to effectively model item sequences.\n\u2022 SASRec (Kang and McAuley 2018) is a sequential recommender that employs a unidirectional network, adopting a self-attention mechanism to model long-term dependencies in item sequences.\n\u2022 S\u00b3-Rec (Zhou et al. 2020) enhances data representation in recommender systems by leveraging self-supervised learning methods to capture correlations between items and attributes.\nThe last group includes the PLM-based generative retrieval approach with an item index."}, {"title": "A.3 Implementation details", "content": "For RQ-VAE used for item index construction, its encoder and decoder consist of five linear layers, utilizing ReLU activation. The both types of item embeddings(i.e., CEID and SEID) and latent vectors have a dimensionality of 768 and 32, respectively. The codebook size and length are fixed to 256 and 3, respectively, for all datasets. To initialize the code vectors, we utilize k-means clustering with 100 iterations on the instances of the first batch. We train RQ-VAE for 10,000 epochs using the AdamW (Loshchilov and Hutter 2017) optimizer with a learning rate of 1e-3, utilizing a linear learning rate scheduler. The batch size is 4,096, and neither dropout nor batch normalization is applied.\nFor P5 used for sequential recommendation, we employ T5-small (Raffel et al. 2020) as the backbone. We use the default SentencePiece tokenizer (Sennrich, Haddow, and Birch 2015), and train the model for 20 epochs using the AdamW optimizer with a batch size of 64 and a peak learning rate of 1e-3 incorporating a linear learning rate scheduler. For each epoch, each item interaction within a user's history is paired with every prompt template, while the item index type is randomly selected."}, {"title": "B Details of RQ-VAE", "content": "RQ-VAE is originally designed for image compression to approximate feature maps into sequences of discrete codes by using a recursive and coarse-to-fine quantization method, instead of increasing the codebook size. RQ-VAE first encodes an item embedding x \u2208 Rd into its latent vector z \u2208 Rd'. The codebook is a predefined set of vectors used for quantization, which contains discrete latent representations learned during the training process. At each level l, we have a codebook C(1) = \\{e\\}_{i=1}^{W}, where each code vector e is a learnable cluster center with code length L and codebook size W. Each latent vector, referred to as codeword, represents a prototype of the data distribution. During quantization, the encoder maps continuous latent representations to the nearest codeword in the codebook, effectively approximating the original data.\nThen, the quantization process is defined by\n\\(c_l = argmin_{e \\in C^{(l)}} ||r_{l-1} \u2013 e ||^2\\)      (9)\n\\(r_l = r_{l-1} \u2013 c_l\\)\nwhere the \\(c_l\\) is the quantized codeword at level l and the \\(r_l\\) denotes the residual of latent z at the level. We define the zero-th residual as"}]}