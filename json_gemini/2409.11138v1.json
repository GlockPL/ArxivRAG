[{"title": "Learning Generalized Hamiltonians using fully Symplectic Mappings", "authors": ["Harsh Choudhary", "Chandan Gupta", "Vyacheslav Kungrutsev", "Melvin Leok", "Georgios Korpas"], "abstract": "Many important physical systems can be described as the evolution of a Hamiltonian system, which has the important property of being conservative, that is, energy is conserved throughout the evolution. Physics Informed Neural Networks (PINNS) and in particular Hamiltonian Neural Networks (HNNs) have emerged as a mechanism to incorporate structural inductive bias into the NN model. By ensuring physical invariances are conserved, the models exhibit significantly better sample complexity and out of distribution accuracy than standard NNs. Learning the Hamiltonian as a function of its canonical variables, typically position and velocity, from sample observations of the system thus becomes a critical task in system identification and long-term prediction of system behavior. However, in order to truly preserve the long run physical conservation properties of Hamiltonian systems, one must use symplectic integrators for a forward pass of the system's simulation. While symplectic schemes have been used in the literature, they are thus far limited to situations when they reduce to explicit algorithms, which include the case of separable Hamiltonians or augmented non-separable Hamiltonians. In general, symplectic integrators are implicit in nature, making backpropagation challenging. Noting the self-adjoint property of symplectic integration, we propose a method for incorporating one integrator for the forward and backward pass in order to perform training on the NN trajectories. We use a predictor-corrector method to warm start the procedure, easing the computational challenges of solving an implicit symplectic integrator. We show that the method is robust to noise and provides a good approximation of the system Hamiltonian when the state variables are sampled from a noisy observation. Our method unlike previous works assumes a single generic Hamiltonian structure which after training can be used to capture long-term behavior of systems governed by complex dynamics as well as modeling the evolution from different input data. In the numerical results, we show the performance of the method with respect to Hamiltonian reconstruction and conservation, indicating its particular advantage for non-separable systems.", "sections": [{"title": "Introduction", "content": "The Hamiltonian and Lagrangian formalism is standard in mathematical physics for expressing dynamics in many physical systems. Beyond leading to reliable schemes to derive ODE dynamics of the system, there are deep structural, geometric, topological, and analytic properties of the Hamiltonian and Lagrangians functions that can be used to understand the system and its dynamics (Marsden and Ratiu 1999). The Lagrangian L = T \u2013 U is the difference of the kinetic and potential energy, and the action is a functional of the curve q : [0,T] \u2192 Q that is given by \\(\\int_0^T L(q, \\dot{q})dt\\), and the dynamics is given by the extremizer of the action functional. The stationarity of the action yields the Euler-Langrange equations, a second-order ODE that describes the dynamics. By contrast, when the kinetic energy is quadratic in the velocities, the Hamiltonian is the sum of the kinetic and potential energies and coincides with the total energy, and the Hamilton's equations for the dynamics is a system of first-order ODEs. As demonstrated in (Bou-Rabee and Marsden 2009), symplectic integrators exhibit excellent preservation of chaotic invariant sets, even with coarse timesteps, which is in contrast to non-geometric methods. This phenomena can be understood in terms of a KAM theorem for symplectic algorithms, as discussed in (Feng and Qin 2010). These results indicate that symplectic discretizations are particularly valuable for capturing the qualitative properties of chaotic Hamiltonian systems. As such, by learning the Hamiltonian itself rather than to seek to learn trajectories, we are able to learn properties of the system without the impossible task of numerical handling the sensitivity of such systems.\nIf the Hamiltonian is time-invariant, then the Noether quantity associated with time-translational symmetry is conserved along the flow. This implies many important conservation properties across physical systems of interest. However, non-geometric methods, such as the Euler and explicit Runge-Kutta methods do not generally conserve the Hamiltonian over larger time scales (Hairer, Lubich, and Wanner 2006), and this phenomenon inspired the development of energy-preserving and symplectic integration schemes to circumvent this problem. A result in (Zhong and Marsden 1988) shows that it is not generally possible for a fixed-timestep integrator to simultaneously preserve the energy and the symplectic structure, so for remainder of this paper, we will focus on symplectic integrators, since they exhibit excellent near energy conservation for exponentially long times via a backward error analysis result (Reich 1999). A method is said to be symplectic if it preserves the canonical symplectic form, \\(w = \\sum_{i=1}^d dp_i \\wedge dq^i\\); see subsequent sections and also (Channell and Scovel 1990). Geometric integrators preserve geometric invariants of the flow, and the use of such integrators have been instrumental in understanding the long-term quali-"}, {"title": "Background", "content": "tative properties of many important physical systems (Ruth 1983; Hairer, Lubich, and Wanner 2006; Feng and Qin 2010).\nWe now consider the problem of learning from data the dynamics of a system which respects certain physical laws and thus requires the symplectic form to be conserved, i.e., Hamiltonian systems.\nIn recent years, the field of Physics Informed Machine Learning has brought significant advances in architecture and learning techniques. By enforcing physical inductive biases while learning the dynamics, through appropriate structural modifications to standard NN training, the learning process requires much fewer samples to accurately fit the data and better out-of-distribution error. This includes the recent development of Hamiltonian Neural Networks (Bertalan et al. 2019). By defining a Hamiltonian as a Neural Network, a more physical representation of the system is available. Incorporating symplectic integrators, and thus accurate reconstruction of the more complex Hamiltonian systems, however, provides technical challenges that we address in this work.\nIn our work, we consider a generic Hamiltonian ansatz parametrized by a Neural Network (NN) which can be used to approximate both separable and non-separable Hamiltonians. We train this NN through data in the form of trajectories fit to the integrator simulations in a loss function. In the forward and backward passes, we use a symplectic integrator to perform the operation mapping the trajectory to the Hamiltonian. In order to ease the computational load of solving an implicit integrator (as necessary for non-separable Hamiltonians), we use a predictor-corrector method to warm start the procedure. Note that using the symplectic integrator provides for better global error guarantees even with fewer sample points to train on.\nIn the subsequent sections, we first give a background on Hamiltonian mechanics and numerical simulation as well as the recent works in the direction of predicting Hamiltonians from observational data. Later in Sec. Fully Symplectic Hamiltonian Neural Network, we describe our method of incorporating an implicit symplectic integration into the forward and adjoint calculation of the HNN model inference and training. We also describe the equations for predictor-corrector implementation used to assist in the computational load of the solution. In Sec. Numerical Results, we show the numerical results for a few textbook separable Hamiltonian physical systems and a couple of systems with non-separable Hamiltonians, showing the prediction capabilities of our symplectic training algorithm compared to existing schemes.\nBeyond modeling and uncertainy physical systems, the Hamiltonian formalism has been effectively used in a range of fields where energy concepts are natural. This includes a complex systems perspective on economic modeling (Cass and Shell 2014) and an application to portfolio management (Tzagkarakis and Maurer 2020)."}, {"title": "Dynamics of Hamiltonian Mechanics", "content": "Physical systems may be described by either Lagrangian or Hamiltonian mechanics. Both are powerful formalisms that provides unified frameworks for describing the dynamics of a wide range of physical systems, from simple harmonic oscillators to complex celestial bodies. By expressing the state of a system in terms of generalized coordinates and momenta, and defining the system's energy as a function of these variables, the equations of motion can be derived in a systematic manner. This approach reveals the structure and conservation laws of the system, such as the conservation of energy and symplectic structure, which play a crucial role in understanding its long-term behavior and stability. Furthermore, since Hamilton's equations is a system of first-order differential equations, the trajectory has a geometric interpretation as the integral curve of a vector field on phase space.\nIn recent years, there has been a growing interest in incorporating the principles of Hamiltonian mechanics into the design of neural networks, giving rise to the field of Hamiltonian Neural Networks (HNNs) (Greydanus, Dzamba, and Yosinski 2019); see next section. Mathematically, by constructing neural networks that respect the symplectic structure and conservation laws of Hamiltonian systems, HNNs can learn and generalize from data in a more physically meaningful and interpretable way which is critical for tasks such as modeling and control of complex dynamical systems.\nLet \\((M,\\omega)\\) be a symplectic manifold, where M\nis a 2d-dimensional smooth manifold and \\(\\omega\\) is a\nclosed, non-degenerate 2-form on M. Let \\((q,p) =\n(q_1,..., q_d, p_1,..., p_d)\\) be a system of canonical coordinates\non M, such that M can be viewed locally as a cotangent\nbundle T*Q, where Q is a configuration manifold, and the\nsymplectic form \\(\\omega\\) can be expressed as:\n\\[\\omega = \\sum_{i=1}^d dq^i \\wedge dp_i.\\\\]\nThe kinetic energy T : R>0 \u00d7 TQ \u2192 R and the potential\nenergy U: Q\u2192 R are assumed to be smooth functions. The\nLagrangian function L : R>0 \u00d7 TQ \u2192 R is defined as:\nL(t, q, \\dot{q}) = T(t, q, \\dot{q}) \u2013 U(q),\nand the action functional S : C\u00b2([to, t1], Q) \u2192 R is defined\nas:\n\\[S[q] = \\int_{t_0}^{t_1} L(t, q(t), \\dot{q}(t))dt.\\\\]\nThen, the dynamics of the system is governed by Hamilton's\nprinciple:\n\\[\\delta S[q] = 0,\\\\]\nfor all variations \u03b4q(t) of q(t) that vanish at the endpoints,\ni.e., \u03b4q(to) = \u03b4q(t1) = 0. This yields the Euler-Lagrange\nequations:\n\\[\\frac{d}{dt}\\frac{\\partial L}{\\partial \\dot{q}_i} - \\frac{\\partial L}{\\partial q_i} = 0, \\text{ for } i = 1,..., d.\\\\]\nThese dynamics can be described in terms of the Hamiltonian\nformulation using the Hamiltonian and the symplectic form\n(1), which are geometric objects that are invariants of the\nflow. This makes the Hamiltonian approach a particularly\ndesirable way of constructing data-driven models that respect\nthe geometric properties of the underlying dynamical system."}, {"title": "Symplectic HNNS", "content": "We introduce the Legendre transform FL: TQ \u2192 T*Q,\n(q, \\dot{q}) \u2192 (q, \\frac{\\partial L}{\\partial \\dot{q}}). This leads to the conjugate momenta,\n\\[p_k = \\frac{\\partial L}{\\partial \\dot{q}_k} \\text{ for } k = 1,...,d.\\\\]\nThe Hamiltonian function H : T*Q \u2192 R is defined as:\n\\[H(q, p) = \\sum_{k=1}^d p_k\\dot{q}_k \u2013 L(q, \\dot{q}),\\\\]\nwhere \\(\\dot{q}_k\\) is expressed as a function of (q,p) by inverting\nLegendre transform. Equivalently, the dependence on the\nvelocities on the right-hand side can be eliminated by extrem-\nizing with respect to the velocities, which is analogous to\nthe approach adopted in Pontryagin's maximum principle.\nGiven H, we can define a unique vector field XH on T*Q,\nthe Hamiltonian vector field, by the condition\n\\[dH = \\omega(X_H,.).\\\\]\nThe Hamiltonian vector field XH takes the form\n\\[X_H = \\sum_{i=1}^d \\frac{\\partial H}{\\partial p_i} \\frac{\\partial}{\\partial q_i} - \\frac{\\partial H}{\\partial q_i} \\frac{\\partial}{\\partial p_i}\\\\]\nThe integral curves of XH are the solutions to Hamilton's\nequations\n\\[\\dot{p}_i = -\\frac{\\partial H}{\\partial q_i}, \\quad \\dot{q}_i = \\frac{\\partial H}{\\partial p_i} \\text{ for } i = 1,..., d.\\\\]\nWhile we have derived Hamilton's equations using local\ncanonical coordinates, (4) defines a global vector field on\nM. These equations describe the flow of the system in phase\nspace and are equivalent to the Euler-Lagrange equations (2)\nderived from Hamilton's principle if the Legendre transfor-\nmation is globally invertible and the Lagrangian L is related\nto the Hamiltonian H by (3).\nFor completeness, the Hamilton-Jacobi partial differential\nequation,\n\\[\\frac{d}{dt}S + H(q, \\frac{\\partial}{\\partial q}S) = 0,\\\\]\ndescribes the generating function S for the canonical trans-\nformation, that maps (q(to),p(to)) to (q(t1),p(t1)). This\nprovides an alternative method for solving Hamilton's equa-\ntions (Abraham and Marsden 1978), and Jacobi's solution to\nthe Hamilton-Jacobi equation is given in terms of the action\nfunctional evaluated along the solution of the Euler-Lagrange\nequations."}, {"title": "Hamiltonian and Lagrangian Neural Networks", "content": "Ref. (Greydanus, Dzamba, and Yosinski 2019) introduced\nHamiltonian Neural Networks, a class of neural networks that\ncan learn arbitrary Hamiltonian functions of a given physical\nsystem. Given the canonical coordinates q = (q1,\u2026\u2026,qa)T,\np = (p1,\u2026\u2026,pa)T, these are given as input to a neural net-\nwork, and the following loss is optimized :\n\\[L(p,q, \\Theta) = \\|\\frac{\\partial H}{\\partial p} - \\frac{dq}{dt}\\|^2_F + \\|\\frac{\\partial H}{\\partial q} + \\frac{dp}{dt}\\|^2_F\\\\]\nwhere F denotes the Frobenius norm and Hamilton's equa-\ntions\n\\[\\dot{q} = \\frac{\\partial H}{\\partial p}, \\quad \\dot{p} = -\\frac{\\partial H}{\\partial q},\\\\]\nare computed using backpropagation based on the input co-\nordinates, and the time derivatives are considered targets\nrecorded from the data. Once the Hamiltonian is learned,\nthe dynamics are generated using external integrators that\nintegrate Hamilton's equations for the learned Hamiltonian\nencoded in the HNN.\nSimilarly, Ref. (Cranmer et al. 2020) introduced La-\ngrangian Neural Networks, a class of NNs that can learn\narbitrary Lagrangian functions of a given physics system.\nThe coordinates are q = (q1,\uff65\uff65\uff65, qa)T, \\dot{q} = (\\dot{q}1,\uff65\uff65\uff65, \\dot{q}a)T\nIn (Greydanus, Dzamba, and Yosinski 2019), the residual\nerror for a first-order gradient is optimized, however, in this,\nthe residual error for a second-order gradient is optimized :\n\\[\\ddot{q} = (\\nabla_{\\dot{q}}\\nabla_{\\dot{q}}^T L)^{-1}(\\nabla_q L - (\\nabla_q\\nabla_{\\dot{q}}^T L)\\dot{q}),\\\\]\nwhich is obtained by solving the Euler-Lagrange equations\n(2) for \\(\\ddot{q}\\). Once the Lagrangian is learned, an external integra-\ntor is used to integrate the Euler-Lagrange equations for the\nlearned Lagrangian function.\nGenerally, calculating the loss gradients for network train-\ning is a difficult task when the loss is a function of the system\nstate, which is in turn governed by an ODE. Formally, the Em-\npirical Risk minimization problem is defined as minimizing\nthe approximate Real Risk\n\\[E := E_e(t) [\\|q-q_{gt} - \\epsilon(t)\\|^2 + \\|p - p_{gt} - \\epsilon(t)\\|^2],\\\\]\nwith, q = q(0, t), p = p(0, t) and \\(\\epsilon(t) = B(t)\\), a Brownian\nmotion (thus resulting in normal-valued samples). We approx-\nimate this in training to data by minimizing the Empirical\nRisk over data \\(\\{(q_{t,n}, p_{t,n}\\}_{t\\in[T],n\\in[N]}\\), defined to be,\n\\[E_N(p,q) := \\frac{1}{NT}\\sum_{t=0}^T \\sum_{n=0}^N \\|p_{t,n} - p_{t,n}\\|^2 - \\|q_{t,n} - q_{t,n}\\|^2.\\\\]\nHowever, given that a neural network defines a function that\nultimately defines a system of ODEs, the optimization prob-\nlem contains constraints:\n\\[\\begin{aligned}\n&\\underset{\\theta}{\\text{minimize }} E_N(\\theta,t)\\\\\n&\\text{subject to }\\begin{cases}\n\\dot{q}(t, \\theta) + \\frac{\\partial H(\\theta,q,p)}{\\partial p} = 0, \\\\\n\\dot{p}(t, \\theta) - \\frac{\\partial H(\\theta, q, p)}{\\partial q} = 0.\n\\end{cases}\n\\end{aligned}\\\\]\nWe seek to minimize this loss function w.r.t. model parame-\nters 0. However, in order to do so, we need to compute the\nnumerical simulation of an ODE system with the right-hand\nside defined by partial derivatives of the Hamiltonian with\nrespect to canonical variables p and q. In order to perform\ninference and compute the backpropagation, the composition\nof a numerical integrator, viewed as an operator, will be re-\nquired. This presents the primary technical challenge that has"}, {"title": "Symplectic Integration in NNs: Previous Work", "content": "spawned the design of various algorithms meant to perform\nthis with both accuracy and computational tractability.\nParticularly for such optimization problems, the space com-\nplexity of gradient computation w.r.t. the parameters using\nthe standard backpropagation scales with timesteps. This\nmakes it computationally expensive to store the gradients in\nthe memory while solving for complex Hamiltonians over\nlonger timescales. By eschewing the classical end-to-end\nbackpropagation approach in favor of inputting a symplec-\ntic integrator into the computation, this scaling issue can be\npartially ameliorated.\nSince the original proposal by (Greydanus, Dzamba, and\nYosinski 2019) and the concurrent work by (Bertalan et al.\n2019), HNNs have generated much scientific interest. This\nhas spawned generative (Toth et al. 2019), recurrent (Chen\net al. 2019), and constrained (Zhong, Dey, and Chakraborty\n2019) versions, as well as Lagrangian Neural Networks\n(Cranmer et al. 2020) have been proposed. Most of these\nworks considered either explicit integration schemes, some\nnearly implicit schemes, or used a separable ansatz for the\nNeural Nets.\n(Chen et al. 2019), in contrast to HNNs, directly optimize\nthe actual states observed at each time step for a given initial-\nization by integrating the partial derivatives using a symplec-\ntic integrator (leapfrog algorithm) and backpropagating each\nsquared error through time. The state at the next time step\nis predicted using the symplectic integrator, in this way the\nentire time series is predicted, which is then compared with\nobserved states. Note that they make the assumption that the\nHamiltonian is separable, which is significant as the leapfrog\nalgorithm is generally implicit, but if the Hamiltonian is sep-\narable, then the algorithm becomes explicit.\n(Xiong et al. 2020) proposes a generalized HNN frame-\nwork, which can be used for non-separable Hamiltonians\nwhere they approximate the original non-separable Hamil-\ntonian by an Augmented one, proposed in (Tao 2016) with\nan extended phase space and a tunable parameter \\(\\omega\\) which\ncontrols the binding between the two copies of Hamiltonian\nand model them using NNs. They propose an in-place sym-\nplectic integration scheme for the dynamics. The assumption\nof Augmented Hamiltonian leads to increased complexity\nwith regards to adjusting the binding parameters. As before,\nthe use of the algorithm in (Tao 2016) is motivated by the\nfact that it is explicit even for non-separable Hamiltonians.\nOur work bypasses this by introducing a single generic\nNetwork for the parametrized Hamiltonian with fully sym-\nplectic integration schemes to predict the system dynamics\nwith computational benefit that they are self-adjoint, and so\nthe solution of the adjoint system can be computed using a\nvery simple lift of the integrator."}, {"title": "Fully Symplectic Hamiltonian Neural Network", "content": "Consider the generic problem of learning a Hamiltonian\nH(q,p) from data, that is, noisy observations. We may\nchoose to parametrize it, consider H(0; q, p), where \\(\\theta \\in R^d\\)\nare the parameters of a neural network such that the Hamil-\ntonian is some function of the three arguments. We can also\nconsider the system identification problem of knowing the\nfunctional form of the Hamiltonian (or Lagrangian) but not\nthe specific parameter values. Inference in the network, for\ngiven trained 0*, amounts to providing a value of q and p\nwith an output depending on 0*.\nOne simulates the Hamiltonian dynamics by computing\ngradients of H with respect to q and p, then applying a numer-\nical integrator to the first-order dynamics. The application\nof a symplectic integrator at this stage enforces accuracy\nand long term stability of the procedure. For algorithm see\nAppendix\nThe novelty of this work is that we consider forward and\nbackward passes based on implicit symplectic integrators.\nThis poses a challenge as this typically requires the solution\nof a nonlinear equation. Fortunately, by the application of\na fixed-point iteration, paired with a explicit predictor, this\nalgorithm can converge to the solution quickly."}, {"title": "Constructing our Symplectic PRK scheme", "content": "For Hamiltonian systems, we have the following system of\nequations :\n\\[\\frac{d}{dt} q = f(q,p,t), \\quad \\frac{d}{dt} p = g(q, p,t).\\\\]\nThese can be integrated using a partitioned Runge-Kutta\nscheme:\n\\[\\begin{aligned}\nq_{n+1} &= q_n + h_n \\sum_{i=1}^S b_i k_{n, i}, \\\\\np_{n+1} &= p_n + h_n\\sum_{i=1}^S B_i l_{n,i},\n\\end{aligned}\\\\]\nwhere\n\\[\\begin{aligned}\nk_{n,i} &= f(Q_{n,i}, P_{n,i},t_n + C_i h_n), \\\\\nl_{n,i} &= g(Q_{n,i}, P_{n,i}, t_n + C_i h_n).\n\\end{aligned}\\\\]\nwhich are evaluated at the internal stages,\n\\[Q_{n,i} = q_n + h_n \\sum_{j=1}^S a_{ij}k_{n,j}, \\quad P_{n,i} = p_n + h_n \\sum_{j=1}^S A_{ij}l_{n,j}.\\\\]\nA partitioned Runge-Kutta scheme is symplectic if the fol-\nlowing conditions hold:\n\\[C_i = C_i, b_i = B_i, \\quad B_i = 1, ..., s;\\\\\nb_i A_{ij} + B_j a_{ji} - b_i B_j = 0, \\quad i, j = 1, ..., s.\\\\]"}, {"title": "Adjoint sensitivity approach for the computation of the gradient", "content": "The sensitivity analysis by the adjoint method has its roots\nin several fields, such as control theory, geophysics, seismic\nimaging, and photonics (J\u00f8rgensen 2007; Xiao, Deng, and\nWang 2021). The adjoint method gives the gradients of a cost\nthat is in Lagrange form, and this has gained some traction\nrecently in the deep learning community, after it was shown\nin the Neural ODEs paper (Chen et al. 2018) that it is pos-\nsible to parameterize the vector field defining an ODE by a\nneural network and differentiate along the flow to learn the"}, {"title": "Evaluation Criteria", "content": "vector field. Since then, the adjoint method has been mostly\nused in the NeuroODE context as a constant memory gradi-\nent computation technique. Here in this work we follow the\nclassic ODE constraint optimization-based approach where\nwe assume that our dynamics comes from a parametrized\nHamiltonian H(0, qi, Pi). The optimization is then w.r.t. the\nNeural Network parameters which minimize the squared loss.\nIn usual cases where a Neural Network is used as a function\napproximator, the gradients are computed using backpropa-\ngation which is a standard way to optimize the cost function\nadjusting the network weights. In our case, the forward pass\nincludes a Symplectic ODE solver which means as we in-\ncrease the simulation length, the computational graph grows\nas well, as we need to track all the intermediate operations\nin order to backpropagate through it. This can be understood\nwith this simple example that follows. Consider a cost func-\ntion of the form:\n\\[L = \\frac{1}{N}\\sum_{i=1}^N (Y_i-Y_t)^2,\\\\]\nwhere each yi is obtained via forward propagation through a\nsymplectic ODE solver, i.e., any such yi can be written as:\n\\[Y_i = f(Y_{i-1}(Y_{i-2}(.\u2026\u2026\u2026Y_1 (Y_0, \\Theta)....), \\Theta), \\Theta),\\\\]\nwhere each intermediate evaluation is registered to the com-\nputational graph. It is clear that if we are solving for larger\nsimulation lengths, the number of evaluations in the back-\nward pass will scale with the number of timesteps as shown\nbelow for one of the weight parameters:\n\\[\\frac{dL}{d\\theta_k} = \\sum_{i=1}^{N} \\frac{\\partial Y_i}{\\partial Y_{i-1}}\\prod_{j=i}\\]\nwhereby each \\(y_i\\) is a function of \\(Y_{i-1}, Y_{i-2},...,Y_1\\). In con-\ntrast to this, using the adjoint sensitivity method for gradient\ncalculation will amount to solving the adjoint equations back-\nward in time which is a constant memory task where we only\nneed the current variable and its partial derivatives in the\nmemory at any particular instant saving significantly on com-\nputational overhead while maintaining a decent prediction\naccuracy. However, the stability of the method for rapidly\nevolving dynamics is still an interesting area of study and\ncould be analyzed further in the future. Please see Appendix\nfor the Hamiltonian adjoint equations."}, {"title": "Hamiltonian Systems", "content": "Our primary focus is on the accu-\nrate prediction of the long-term dynamics of the system. An\nimportant thing to note here is that even though our Neural\nNetwork is parameterizing the Hamiltonian of the system, we\ncan't directly compare the Hamiltonian values as H1 (q, p, t)\nand H2(q, p,t) = H1(q, p,t) + f(q, t) where f is a function\nthat does not affect the equations of motion, both Hamiltoni-\nans can describe the same dynamical behavior under certain\nconditions. For simplest of cases, consider H and H + \u0441.\nNeural Networks when used as functional approximators\nlearn to generate a nearly equivalent representation of the test\nfunction that minimizes the empirical loss and unless we ex-\nplicitly use some cost function over Hamiltonian value(which\nin our case we assume we don't have access to), we can't\nsay for sure that our network would exactly give the same\nHamiltonian value as the analytical one."}, "title", "Spring-Mass Hamiltonian System", "content", "The spring-mass system is a standard Hamiltonian system\nwith closed-form solution with Hamiltonian and governing\nequations given as:\n\\[H= \\frac{p^2}{2}+ \\frac{q^2}{2}; \\quad \\dot{q}=p, \\quad \\dot{p}=-q.\\\\]\nData Generation The input data was generated using\nthe symplectic solver where we sampled 20490 initial values\nof q, p and generated the trajectories from t = 0 to t = 10\nsec. The data was then divided in train, validation and test\nsets in a 4:1:1 set policy."]}, {"title": "Double Well potential", "content": "Particle in a double-well potential is another commonly stud-\nied system in classical and quantum mechanics where a par-\nticle moves under the influence of a quartic potential with\n2 stable fixed points, in our case we consider a symmetri-\ncal double potential well with Hamiltonian and governing\nequations given as:\n\\[\\begin{aligned}\nH &= \\frac{p^2}{2} + \\frac{1}{4}q^4 - \\frac{1}{2}q^2 \\\\\n\\dot{q} &= p, \\\\\n\\dot{p} &= q - q^3.\n\\end{aligned}\\\\]\nData Generation\nremains the same where we sampled 20490 initial values of q,p\nand generated the trajectories from t=0 to t=20 sec. The data\nwas then divided in train, val and test sets in 4:1:1 sets.\nTraining Parameters The network architecture and the\ntraining parameters were same as the last case."}, {"title": "Non-Separable Systems", "content": "We now consider a non-trivial example of dynamics gov-\nerned by a non-separable Hamiltonian. The system below\nhas 3 fixed points, two of which : (\u22121,1), (1, -1) are sad-\ndle points and one (0,0) non-linear center with limit cycles."}, {"title": "Non-Separable Systems", "content": "We now consider a non-trivial example of dynamics gov-\nerned by a non-separable Hamiltonian. The system below\nhas 3 fixed points, two of which : (\u22121,1), (1, -1) are sad-\ndle points and one (0,0) non-linear center with limit cycles.\nFor descriptive plots, we confine ourselves around the stable\nfixed point as the other trajectories around the saddle points\nescape rapidly toward infinity. (Strogatz 2001). The dynamics\nmathematically is represented as:\n\\[\\begin{aligned}\nH &= \\frac{1}{2} p^2 + qp^2 + \\frac{1}{4}q^4 + \\frac{1}{4} \\\\\n\\dot{q} &= p - 2qp,\\\\\n\\dot{p} &= q - q - p^2.\n\\end{aligned}\\\\]\nData Generation The input data generation pipeline\nremains the same where we sampled 20490 initial values of\n{q,p} and generated the trajectories from t = 0 to t = 20\nsec with a noise factor of 0.01. The data was then divided\ninto train, validation and test sets in a 4:1:1 policy."}, {"title": "Henon-Hieles Potential", "content": "Now we move to higher dimensional systems where we have\nthe possibility of Chaos. Chaotic systems are inherently de-\nterministic but unpredictable over larger time scales as the\nlocal error while numerically solving the system scales ex-\nponentially with a factor called Lyapunov exponent which\nmakes the close-by trajectories diverge quickly. However,\nsince some of these systems are completely deterministic and\nhave a well defined Hamiltonian and governing dynamics, it\nis still possible to learn the dynamics from a few initial obser-\nvations of the system before Chaos settles in, where we can\nuse and assess the full potential of the generic architecture of\nour Network. We consider a well-known non-linear dynam-\nical system namely the H\u00e9non-Heiles system (HH) which\nis a simplified model restricted to the plane motion of a star\naround a galactic centre under the following two degrees of\nfreedom Hamiltonian function which corresponds to the total\nenergy of the system. The system exhibits chaotic behaviour\nbut there are regions of stability that can help our model\nlearn the governing dynamics(Barrio and Wilczak 2020). The\nhamiltonian H and the corresponding equations of motion\nare given by:\n\\[\\begin{aligned}\nH &= \\frac{p_x^2 + p_y^2}{2} + \\frac{q_x^2 + q_y^2}{2} + q_x^2 q_y - \\frac{q_y^3}{3}, \\\\\nq_x &= p_x,\\\\\nq_y &= p_y,\\\\\np_x &= -q_x - 2q_xq_y,\\\\\np_y &= -q_y - q_x^2 + q_y^2\n\\end{aligned}\\\\]"}, {"title": "Adjoint System", "content": "As discussed earlier", "form": "n\\[\\int_{t_0}^T L(x(t), t)dt + \\Phi(x(T)),\\\\]\nwith respect to initial conditions or system parameters. The\nadjoint system (Fujimoto and Sugie 2001, 2002) is derived\nto efficiently compute these sensitivities. It is defined by\nintroducing adjoint variables \\(\\lambda(t)\\) that satisfy"}]