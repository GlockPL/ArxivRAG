{"title": "Learning Generalized Hamiltonians using fully Symplectic Mappings", "authors": ["Harsh Choudhary", "Chandan Gupta", "Vyacheslav Kungrutsev", "Melvin Leok", "Georgios Korpas"], "abstract": "Many important physical systems can be described as the evolution of a Hamiltonian system, which has the important property of being conservative, that is, energy is conserved throughout the evolution. Physics Informed Neural Networks (PINNS) and in particular Hamiltonian Neural Networks (HNNs) have emerged as a mechanism to incorporate structural inductive bias into the NN model. By ensuring physical invariances are conserved, the models exhibit significantly better sample complexity and out of distribution accuracy than standard NNs. Learning the Hamiltonian as a function of its canonical variables, typically position and velocity, from sample observations of the system thus becomes a critical task in system identification and long-term prediction of system behavior. However, in order to truly preserve the long run physical conservation properties of Hamiltonian systems, one must use symplectic integrators for a forward pass of the system's simulation. While symplectic schemes have been used in the literature, they are thus far limited to situations when they reduce to explicit algorithms, which include the case of separable Hamiltonians or augmented non-separable Hamiltonians. In general, symplectic integrators are implicit in nature, making backpropagation challenging. Noting the self-adjoint property of symplectic integration, we propose a method for incorporating one integrator for the forward and backward pass in order to perform training on the NN trajectories. We use a predictor-corrector method to warm start the procedure, easing the computational challenges of solving an implicit symplectic integrator. We show that the method is robust to noise and provides a good approximation of the system Hamiltonian when the state variables are sampled from a noisy observation. Our method unlike previous works assumes a single generic Hamiltonian structure which after training can be used to capture long-term behavior of systems governed by complex dynamics as well as modeling the evolution from different input data. In the numerical results, we show the performance of the method with respect to Hamiltonian reconstruction and conservation, indicating its particular advantage for non-separable systems.", "sections": [{"title": "Introduction", "content": "The Hamiltonian and Lagrangian formalism is standard in mathematical physics for expressing dynamics in many physical systems. Beyond leading to reliable schemes to derive ODE dynamics of the system, there are deep structural, geometric, topological, and analytic properties of the Hamiltonian and Lagrangians functions that can be used to understand the system and its dynamics (Marsden and Ratiu 1999). The Lagrangian $L = T \u2013 U$ is the difference of the kinetic and potential energy, and the action is a functional of the curve $q : [0,T] \u2192 Q$ that is given by $\\int_{0}^{T} L(q, \\dot{q})dt$, and the dynamics is given by the extremizer of the action functional.\nThe stationarity of the action yields the Euler-Langrange equations, a second-order ODE that describes the dynamics. By contrast, when the kinetic energy is quadratic in the velocities, the Hamiltonian is the sum of the kinetic and potential energies and coincides with the total energy, and the Hamilton's equations for the dynamics is a system of first-order ODEs. As demonstrated in (Bou-Rabee and Marsden 2009), symplectic integrators exhibit excellent preservation of chaotic invariant sets, even with coarse timesteps, which is in contrast to non-geometric methods. This phenomena can be understood in terms of a KAM theorem for symplectic algorithms, as discussed in (Feng and Qin 2010). These results indicate that symplectic discretizations are particularly valuable for capturing the qualitative properties of chaotic Hamiltonian systems. As such, by learning the Hamiltonian itself rather than to seek to learn trajectories, we are able to learn properties of the system without the impossible task of numerical handling the sensitivity of such systems.\nIf the Hamiltonian is time-invariant, then the Noether quantity associated with time-translational symmetry is conserved along the flow. This implies many important conservation properties across physical systems of interest. However, non-geometric methods, such as the Euler and explicit Runge-Kutta methods do not generally conserve the Hamiltonian over larger time scales (Hairer, Lubich, and Wanner 2006), and this phenomenon inspired the development of energy-preserving and symplectic integration schemes to circumvent this problem. A result in (Zhong and Marsden 1988) shows that it is not generally possible for a fixed-timestep integrator to simultaneously preserve the energy and the symplectic structure, so for remainder of this paper, we will focus on symplectic integrators, since they exhibit excellent near energy conservation for exponentially long times via a backward error analysis result (Reich 1999). A method is said to be symplectic if it preserves the canonical symplectic form, $w = \\sum_{i=1}^n dp_i \\wedge dq^i$; see subsequent sections and also (Channell and Scovel 1990). Geometric integrators preserve geometric invariants of the flow, and the use of such integrators have been instrumental in understanding the long-term quali-"}, {"title": "Background", "content": "Dynamics of Hamiltonian Mechanics\nPhysical systems may be described by either Lagrangian or Hamiltonian mechanics. Both are powerful formalisms that provides unified frameworks for describing the dynamics of a wide range of physical systems, from simple harmonic oscillators to complex celestial bodies. By expressing the state of a system in terms of generalized coordinates and momenta, and defining the system's energy as a function of these variables, the equations of motion can be derived in a systematic manner. This approach reveals the structure and conservation laws of the system, such as the conservation of energy and symplectic structure, which play a crucial role in understanding its long-term behavior and stability. Furthermore, since Hamilton's equations is a system of first-order differential equations, the trajectory has a geometric interpretation as the integral curve of a vector field on phase space.\nIn recent years, there has been a growing interest in incorporating the principles of Hamiltonian mechanics into the design of neural networks, giving rise to the field of Hamiltonian Neural Networks (HNNs) (Greydanus, Dzamba, and Yosinski 2019); see next section. Mathematically, by constructing neural networks that respect the symplectic structure and conservation laws of Hamiltonian systems, HNNs can learn and generalize from data in a more physically meaningful and interpretable way which is critical for tasks such as modeling and control of complex dynamical systems.\nLet $(M,w)$ be a symplectic manifold, where $M$ is a 2d-dimensional smooth manifold and $w$ is a closed, non-degenerate 2-form on $M$. Let $(q,p)=(q_1,..., q_d, p_1,..., p_d)$ be a system of canonical coordinates on M, such that M can be viewed locally as a cotangent bundle $T^*Q$, where $Q$ is a configuration manifold, and the symplectic form $w$ can be expressed as:\n$\\omega = \\sum_{i=1}^{d} dq^{i} \\wedge dp_{i}.$\n(1)\nThe kinetic energy $T : \\mathbb{R}_{>0} \\times TQ \\rightarrow \\mathbb{R}$ and the potential energy $U: Q\\rightarrow \\mathbb{R}$ are assumed to be smooth functions. The Lagrangian function $L : \\mathbb{R}_{>0} \\times TQ \\rightarrow \\mathbb{R}$ is defined as:\n$L(t, q, \\dot{q}) = T(t, q, \\dot{q}) \u2013 U(q)$,\nand the action functional $S : C^{2}([t_{0}, t_{1}], Q) \\rightarrow \\mathbb{R}$ is defined as:\n$S[q] = \\int_{t_{0}}^{t_{1}} L(t, q(t), \\dot{q}(t))dt.$\nThen, the dynamics of the system is governed by Hamilton's principle:\n$\\delta S[q] = 0,$\nfor all variations $\\delta q(t)$ of $q(t)$ that vanish at the endpoints, i.e., $\\delta q(t_{0}) = \\delta q(t_{1}) = 0$. This yields the Euler-Lagrange equations:\n$\\frac{d}{dt}\\frac{\\partial L}{\\partial \\dot{q_{i}}} - \\frac{\\partial L}{\\partial q_{i}} = 0, \\text{ for } i = 1,..., d.$\n(2)\nThese dynamics can be described in terms of the Hamiltonian formulation using the Hamiltonian and the symplectic form (1), which are geometric objects that are invariants of the flow. This makes the Hamiltonian approach a particularly desirable way of constructing data-driven models that respect the geometric properties of the underlying dynamical system."}, {"title": "Symplectic HNNS", "content": "We introduce the Legendre transform $FL: TQ \\rightarrow T^*Q$, $(q, \\dot{q}) \\rightarrow (q, \\frac{\\partial L}{\\partial \\dot{q}})$. This leads to the conjugate momenta,\n$p_k = \\frac{\\partial L}{\\partial \\dot{q}_k} \\text{ for } k = 1,...,d.$\nThe Hamiltonian function $H : T^*Q \\rightarrow \\mathbb{R}$ is defined as:\n$H(q, p) = \\sum_{k=1}^{d} p_k\\dot{q}_k \u2013 L(q, \\dot{q}),$\n(3)\nwhere $\\dot{q}_k$ is expressed as a function of $(q,p)$ by inverting Legendre transform. Equivalently, the dependence on the velocities on the right-hand side can be eliminated by extremizing with respect to the velocities, which is analogous to the approach adopted in Pontryagin's maximum principle. Given $H$, we can define a unique vector field $X_H$ on $T^*Q$, the Hamiltonian vector field, by the condition\n$dH = \\omega(X_H,.).$\nThe Hamiltonian vector field $X_H$ takes the form\n$X_H = \\sum_{i=1}^{d} \\frac{\\partial H}{\\partial p_i}\\frac{\\partial}{\\partial q_i} - \\frac{\\partial H}{\\partial q_i}\\frac{\\partial}{\\partial p_i}.$\n(5)\nThe integral curves of $X_H$ are the solutions to Hamilton's equations\n$\\dot{p}_{i} = -\\frac{\\partial H}{\\partial q_{i}}$\n$\\dot{q}_{i} = \\frac{\\partial H}{\\partial p_{i}}  \\text{ for } i = 1,..., d.$\nWhile we have derived Hamilton's equations using local canonical coordinates, (4) defines a global vector field on M. These equations describe the flow of the system in phase space and are equivalent to the Euler-Lagrange equations (2) derived from Hamilton's principle if the Legendre transformation is globally invertible and the Lagrangian $L$ is related to the Hamiltonian $H$ by (3).\nFor completeness, the Hamilton-Jacobi partial differential equation,\n$\\partial_{t}S + H(q, \\partial_{q}S) = 0,$\ndescribes the generating function S for the canonical transformation, that maps $(q(t_{0}),p(t_{0}))$ to $(q(t_{1}),p(t_{1}))$. This provides an alternative method for solving Hamilton's equations (Abraham and Marsden 1978), and Jacobi's solution to the Hamilton-Jacobi equation is given in terms of the action functional evaluated along the solution of the Euler-Lagrange equations.\nHamiltonian and Lagrangian Neural Networks\nRef. (Greydanus, Dzamba, and Yosinski 2019) introduced Hamiltonian Neural Networks, a class of neural networks that can learn arbitrary Hamiltonian functions of a given physical system. Given the canonical coordinates $q = (q_{1},\u2026\u2026,q_{d})^{T}$, $p = (p_{1},\u2026\u2026,p_{d})^{T}$, these are given as input to a neural network, and the following loss is optimized :\n$L(p, q, \\Theta) = ||\\frac{\\partial H}{\\partial p} - \\frac{dq}{dt}||^{2}_{F} + ||\\frac{\\partial H}{\\partial q} + \\frac{dp}{dt}||^{2}_{F}$\nwhere F denotes the Frobenius norm and Hamilton's equations\n$\\dot{q} = \\frac{\\partial H}{\\partial p}$\n$\\dot{p} = -\\frac{\\partial H}{\\partial q},$\n(6)\nare computed using backpropagation based on the input coordinates, and the time derivatives are considered targets recorded from the data. Once the Hamiltonian is learned, the dynamics are generated using external integrators that integrate Hamilton's equations for the learned Hamiltonian encoded in the HNN.\nSimilarly, Ref. (Cranmer et al. 2020) introduced Lagrangian Neural Networks, a class of NNs that can learn arbitrary Lagrangian functions of a given physics system. The coordinates are $q = (q_{1},\u2026\u2026, q_{d})^{T}$, $\\dot{q} = (\\dot{q}_{1},\u2026\u2026, \\dot{q}_{d})^{T}$ In (Greydanus, Dzamba, and Yosinski 2019), the residual error for a first-order gradient is optimized, however, in this, the residual error for a second-order gradient is optimized :\n$\\ddot{q} = (\\nabla_{\\dot{q}}\\nabla_{\\dot{q}}^{T}L)^{-1}(\\nabla_{q}L \u2013 (\\nabla_{q}\\nabla_{\\dot{q}}^{T}L)\\dot{q}),$\nwhich is obtained by solving the Euler-Lagrange equations (2) for $\\ddot{q}$. Once the Lagrangian is learned, an external integrator is used to integrate the Euler-Lagrange equations for the learned Lagrangian function.\nGenerally, calculating the loss gradients for network training is a difficult task when the loss is a function of the system state, which is in turn governed by an ODE. Formally, the Empirical Risk minimization problem is defined as minimizing the approximate Real Risk\n$E := \\mathbb{E}_{e(t)} [||q-q_{gt}-e(t)||^{2} + ||p-p_{gt}-e(t)||^{2}]$,\nwith, $q = q(0, t)$, $p = p(0, t)$ and $e(t) = B(t)$, a Brownian motion (thus resulting in normal-valued samples). We approximate this in training to data by minimizing the Empirical Risk over data $\\{q_{t,n}, p_{t,n}\\} _{t\\in[T], n\\in[N]}$, defined to be,\n$E_{N} (p,q) := \\frac{1}{NT} \\sum_{t=0}^{T} \\sum_{n=0}^{N} [||q-q_{t,n}||^{2} + ||p-p_{t,n}||^{2}].$\n(7)\nHowever, given that a neural network defines a function that ultimately defines a system of ODEs, the optimization problem contains constraints:\n$\\underset{\\Theta}{\\text{minimize}} \\quad E_N(\\Theta, t)$\n$\\text{subject to} \\quad \\dot{q}(t, \\Theta) - \\frac{\\partial H(\\Theta, q, p)}{\\partial p} = 0,$\n$\\dot{p}(t, \\Theta) + \\frac{\\partial H(\\Theta, q, p)}{\\partial q} = 0.$\n(8)\nWe seek to minimize this loss function w.r.t. model parameters $\\Theta$. However, in order to do so, we need to compute the numerical simulation of an ODE system with the right-hand side defined by partial derivatives of the Hamiltonian with respect to canonical variables p and q. In order to perform inference and compute the backpropagation, the composition of a numerical integrator, viewed as an operator, will be required. This presents the primary technical challenge that has"}, {"title": "Symplectic Integration in NNs: Previous Work", "content": "Particularly for such optimization problems, the space complexity of gradient computation w.r.t. the parameters using the standard backpropagation scales with timesteps. This makes it computationally expensive to store the gradients in the memory while solving for complex Hamiltonians over longer timescales. By eschewing the classical end-to-end backpropagation approach in favor of inputting a symplectic integrator into the computation, this scaling issue can be partially ameliorated.\nSymplectic Integration in NNs: Previous Work\nSince the original proposal by (Greydanus, Dzamba, and Yosinski 2019) and the concurrent work by (Bertalan et al. 2019), HNNs have generated much scientific interest. This has spawned generative (Toth et al. 2019), recurrent (Chen et al. 2019), and constrained (Zhong, Dey, and Chakraborty 2019) versions, as well as Lagrangian Neural Networks (Cranmer et al. 2020) have been proposed. Most of these works considered either explicit integration schemes, some nearly implicit schemes, or used a separable ansatz for the Neural Nets.\n(Chen et al. 2019), in contrast to HNNs, directly optimize the actual states observed at each time step for a given initialization by integrating the partial derivatives using a symplectic integrator (leapfrog algorithm) and backpropagating each squared error through time. The state at the next time step is predicted using the symplectic integrator, in this way the entire time series is predicted, which is then compared with observed states. Note that they make the assumption that the Hamiltonian is separable, which is significant as the leapfrog algorithm is generally implicit, but if the Hamiltonian is separable, then the algorithm becomes explicit.\n(Xiong et al. 2020) proposes a generalized HNN framework, which can be used for non-separable Hamiltonians where they approximate the original non-separable Hamiltonian by an Augmented one, proposed in (Tao 2016) with an extended phase space and a tunable parameter w which controls the binding between the two copies of Hamiltonian and model them using NNs. They propose an in-place symplectic integration scheme for the dynamics. The assumption of Augmented Hamiltonian leads to increased complexity with regards to adjusting the binding parameters. As before, the use of the algorithm in (Tao 2016) is motivated by the fact that it is explicit even for non-separable Hamiltonians.\nOur work bypasses this by introducing a single generic Network for the parametrized Hamiltonian with fully symplectic integration schemes to predict the system dynamics with computational benefit that they are self-adjoint, and so the solution of the adjoint system can be computed using a very simple lift of the integrator."}, {"title": "Fully Symplectic Hamiltonian Neural Network", "content": "Consider the generic problem of learning a Hamiltonian H(q,p) from data, that is, noisy observations. We may choose to parametrize it, consider $H(\\Theta; q, p)$, where $\\Theta \\in \\mathbb{R}^{d}$ are the parameters of a neural network such that the Hamiltonian is some function of the three arguments. We can also consider the system identification problem of knowing the functional form of the Hamiltonian (or Lagrangian) but not the specific parameter values. Inference in the network, for given trained $\\Theta^*$, amounts to providing a value of q and p with an output depending on $\\Theta^*$.\nOne simulates the Hamiltonian dynamics by computing gradients of H with respect to q and p, then applying a numerical integrator to the first-order dynamics. The application of a symplectic integrator at this stage enforces accuracy and long term stability of the procedure. For algorithm see Appendix\nThe novelty of this work is that we consider forward and backward passes based on implicit symplectic integrators. This poses a challenge as this typically requires the solution of a nonlinear equation. Fortunately, by the application of a fixed-point iteration, paired with a explicit predictor, this algorithm can converge to the solution quickly.\nConstructing our Symplectic PRK scheme\nFor Hamiltonian systems, we have the following system of equations :\n$\\frac{d}{dt}q = f(q,p,t), \\quad \\frac{d}{dt}p = g(q, p,t).$\n(9)\nThese can be integrated using a partitioned Runge-Kutta scheme:\n$q_{n+1} = q_{n} + h_{n} \\sum_{i=1}^{S} b_{i}k_{n,i},$\n$p_{n+1} = p_{n} + h_{n} \\sum_{i=1}^{S} B_{i}l_{n,i},$\n(10)\nwhere\n$k_{n,i} = f(Q_{n,i}, P_{n,i},t_{n} + c_{i}h_{n}),$\n$l_{n,i} = g(Q_{n,i}, P_{n,i}, t_{n} + c_{i}h_{n}).$\n(11)\nwhich are evaluated at the internal stages,\n$Q_{n,i} = q_{n} + h_{n} \\sum_{j=1}^{S} a_{ij}k_{n,j}, \\quad P_{n,i} = p_{n} + h_{n} \\sum_{j=1}^{S} A_{ij}l_{nj}.$\n(12)\nA partitioned Runge-Kutta scheme is symplectic if the following conditions hold:\n$c_{i} = C_{i}, b_{i} = B_{i}, \\quad \\sum_{i=1}^{S} b_{i} = 1,\\quad b_{i} A_{ij} + B_{j}a_{ji} - b_{i} B_{j} = 0, \\quad i, j = 1, ..., s.$\n(13)\nAdjoint sensitivity approach for the computation of the gradient\nThe sensitivity analysis by the adjoint method has its roots in several fields, such as control theory, geophysics, seismic imaging, and photonics (J\u00f8rgensen 2007; Xiao, Deng, and Wang 2021). The adjoint method gives the gradients of a cost that is in Lagrange form, and this has gained some traction recently in the deep learning community, after it was shown in the Neural ODEs paper (Chen et al. 2018) that it is possible to parameterize the vector field defining an ODE by a neural network and differentiate along the flow to learn the"}, {"title": "Numerical Results", "content": "spawned the design of various algorithms meant to perform this with both accuracy and computational tractability.\nParticularly for such optimization problems, the space complexity of gradient computation w.r.t. the parameters using the standard backpropagation scales with timesteps. This makes it computationally expensive to store the gradients in the memory while solving for complex Hamiltonians over longer timescales. By eschewing the classical end-to-end backpropagation approach in favor of inputting a symplectic integrator into the computation, this scaling issue can be partially ameliorated.\nIn this section, we investigate our method's performace for various kinds of dynamical systems starting with first-order non-linear dynamical systems and then evaluating the performance on Hamiltonian systems.\nHamiltonian Systems\nNow we shift our analysis to systems governed by Hamiltonian dynamics where we present some numerical results for identifying governing dynamics for increasingly complex systems.\nEvaluation Criteria Our primary focus is on the accurate prediction of the long-term dynamics of the system. An important thing to note here is that even though our Neural Network is parameterizing the Hamiltonian of the system, we can't directly compare the Hamiltonian values as $H_1(q, p, t)$ and $H_2(q, p,t) = H_1(q, p,t) + f(q, t)$ where f is a function that does not affect the equations of motion, both Hamiltonians can describe the same dynamical behavior under certain conditions. For simplest of cases, consider H and H + c. Neural Networks when used as functional approximators learn to generate a nearly equivalent representation of the test function that minimizes the empirical loss and unless we explicitly use some cost function over Hamiltonian value(which in our case we assume we don't have access to), we can't say for sure that our network would exactly give the same Hamiltonian value as the analytical one.\nSpring-Mass Hamiltonian System\nThe spring-mass system is a standard Hamiltonian system with closed-form solution with Hamiltonian and governing equations given as:\n$H = \\frac{p^2}{2} + \\frac{q^2}{2}, \\quad \\dot{q}=p, \\quad \\dot{p} = -q.$\n(16)\nData Generation The input data was generated using the symplectic solver where we sampled 20490 initial values of q, p and generated the trajectories from t = 0 to t = 10 sec. The data was then divided in train, validation and test sets in a 4:1:1 set policy."}, {"title": "Double Well potential", "content": "Training Parameters The Neural Network consists of 3 hidden layers with 32 neurons each. The network was trained taking 10 initial points from each training trajectory with train and validation losses plotted for the same.\nParticle in a double-well potential is another commonly studied system in classical and quantum mechanics where a particle moves under the influence of a quartic potential with 2 stable fixed points, in our case we consider a symmetrical double potential well with Hamiltonian and governing equations given as:\n$H = \\frac{p^2}{2} + \\frac{q^4}{4} - \\frac{q^2}{2}$\n$\\dot{q} = p, \\quad \\dot{p} = q - q^3.$\n(17)\nData Generation The input data generation pipeline remains the same where we sampled 20490 initial values of q,p and generated the trajectories from t=0 to t=20 sec. The data was then divided in train, val and test sets in 4:1:1 sets.\nTraining Parameters The network architecture and the training parameters were same as the last case.\nNon-Separable Systems\nWe now consider a non-trivial example of dynamics governed by a non-separable Hamiltonian. The system below has 3 fixed points, two of which : (\u22121, 1), (1, -1) are saddle points and one (0,0) non-linear center with limit cycles."}, {"title": "Henon-Hieles Potential", "content": "For descriptive plots, we confine ourselves around the stable fixed point as the other trajectories around the saddle points escape rapidly toward infinity. (Strogatz 2001). The dynamics mathematically is represented as:\n$H = \\frac{1}{2}(p_x^2 + p_y^2) + \\frac{1}{2}(q_x^2 + q_y^2) + q_x^2q_y - \\frac{1}{3}q_y^3$\n$\\dot{q} = p-p^3, \\quad \\dot{p} = q-p^2.$\n(18)\nData Generation The input data generation pipeline remains the same where we sampled 20490 initial values of {q,p} and generated the trajectories from t = 0 to t = 20 sec with a noise factor of 0.01. The data was then divided into train, validation and test sets in a 4:1:1 policy.\nTraining Parameters and method The Neural Network consists of 3 hidden layers with 32 neurons each as in the previous tests. As the system under study is way more complex, the network was trained taking 10 initial points from each training trajectory with train and validation losses plotted for the same.\nHenon-Hieles Potential\nNow we move to higher dimensional systems where we have the possibility of Chaos. Chaotic systems are inherently deterministic but unpredictable over larger time scales as the local error while numerically solving the system scales exponentially with a factor called Lyapunov exponent which makes the close-by trajectories diverge quickly. However,"}, {"title": "Conclusion", "content": "is defined as follows:\n$M = (\\int |(\\frac{\\partial H}{\\partial p})_{pred} - (\\frac{\\partial H}{\\partial p})_{true}|dqdp)(\\int |(\\frac{\\partial H}{\\partial q})_{pred} - (\\frac{\\partial H}{\\partial q})_{true}|dqdp).$\nThe adjoint approach normally results in gradients that differ from backprogation, unless the adjoint system is computed using the cotangent lift of the numerical integrator used in the forward propagation, in which case the adjoint approach yields gradients that coincide with backpropagation. More generally, this holds when the adjoint system is integrated"}, {"title": "Adjoint System", "content": "As discussed earlier, a Hamiltonian system is described by the state variables $x(t) = (q(t),p(t)) \\in \\mathbb{R}^{2n}$, where q and p represent generalized coordinates and momenta, as usual, evolves according to Hamilton's equations.\nLet L(x(t), t) be a scalar function of the state variables and let $\\Phi(x(T))$ be a terminal cost. We are often interested in computing the sensitivity of a functional of the form:\n$\\int_{t_0}^{T} L(x(t), t)dt + \\Phi(x(T)),$\n(21)\nwith respect to initial conditions or system parameters. The adjoint system (Fujimoto and Sugie 2001, 2002) is derived to efficiently compute these sensitivities. It is defined by introducing adjoint variables $\\lambda(t)$ that satisfy:\n$\\frac{d \\lambda}{dt} = -(\\frac{\\partial^2 (L(x,t)}{\\partial x^2})^{T}\\lambda,$      (22)\nwith the terminal condition $\\lambda(T) = \\nabla\\Phi(x(T))$ and J a skew-symmetric matrix, usually\n$J = \\begin{bmatrix}\n0 & I\\\\\n-I & 0\n\\end{bmatrix} \\in \\mathbb{R}^{2n x 2n}$\nThis adjoint system evolves backward in time and allows for the efficient computation of gradients through the method of reverse accumulation. The specific form of the adjoint system for our Hamiltonian problem is given by:\n$\\frac{d}{dt} \\begin{bmatrix}q(t) \\\\ p(t)\\end{bmatrix} = \\begin{bmatrix} \\nabla_{p}H(q,p, \\Theta,t) \\\\ -\\nabla_{q}H(q,p, \\Theta,t)\\end{bmatrix},$\n(23)\nwhere q(0) := $q_0$ and p(0) := $p_0$. We further define\n$\\begin{aligned}\n&L_{\\text{aug}} = L - \\lambda_{\\text{q}}^{\\top} f_{\\text{aug}} - \\lambda_{\\text{p}}^{\\top} z_{\\text{aug}}\n\\end{aligned}$\n(24)\nBased on these definitions, the corresponding adjoint system for the Hamiltonian dynamics is given by:\n-\\sum_{\\lambda} f_{\\lambda}^{\\top} \\frac{d}{dt} \\lambda_{\\text{aug}}\n(25)\nwhich when applied to the Hamiltonian system, results in:\n$\\frac{d}{dt} \\begin{bmatrix} \\lambda_{\\text{q}} \\\\ \\lambda_{\\text{p}}\\end{bmatrix} = -\\begin{bmatrix} \\nabla_{p,q}H_{\\text{q}} & \\nabla_{q,q}H_{\\text{q}} \\\\ \\nabla_{p,p}H_{\\text{p}} & -\\nabla_{q,p}H_{\\text{p}}\\end{bmatrix} \\begin{bmatrix}\\lambda_{\\text{q}} \\\\ \\lambda_{\\text{p}}\\end{bmatrix},$\n(26)\nwhere $\\lambda_q = \\nabla L_q, \\lambda_p = \\nabla L_p$. This gives:\n$\\frac{d}{dt} \\lambda_{\\text{q}} = -\\nabla_{q}H_{\\text{p}}\\lambda_{\\text{q}} - \\nabla_{q,q}H_{\\text{q}}\\lambda_{\\text{p}}$\n$\\frac{d}{dt} \\lambda_{\\text{p}} = -\\nabla_{p,p}H_{\\text{p}}\\lambda_{\\text{q}} + \\nabla_{p}H_{\\text{q}}\\lambda_{\\text{p}}$\nSolving these equations backward in time subject to :\n$\\lambda_{\\text{q}} = \\frac{dL}{dq}$ and $\\lambda_{\\text{p}} = \\frac{dL}{dp}$\n(28)\ngives the adjoint state which is in-turn used to calculate the loss gradients through:\n$\\frac{dL}{d\\Theta} = \\int\\limits_0^T \\lambda(t)^T \\frac{\\partial z}{\\partial \\Theta} dt$\n(29)"}]}