{"title": "Social AI and The Equation of Wittgenstein's Language User With Calvino's Literature Machine", "authors": ["W. J. T. Mollema"], "abstract": "Is it sensical to ascribe psychological predicates to Al systems like chatbots based on large language models (LLMs)? People have intuitively started ascribing emotions or consciousness to social AI (\u2018affective artificial agents'), with consequences that range from love to suicide. The philosophical question of whether such ascriptions are warranted is thus very relevant. This paper advances the argument that LLMs instantiate language users in Ludwig Wittgenstein's sense but that ascribing psychological predicates to these systems remains a functionalist temptation. Social Als are not full-blown language users, but rather more like Italo Calvino's literature machines. The ideas of LLMs as Wittgensteinian language users and Calvino's literature-producing writing machine are combined. This sheds light on the misguided functionalist temptation inherent in moving from equating the two to the ascription of psychological predicates to social AI. Finally, the framework of mortal computation is used to show that social Als lack the basic autopoiesis needed for narrative fa\u00e7ons de parler and their role in the sensemaking of human (inter)action. Such psychological predicate ascriptions could make sense: the transition \u2018from quantity to quality' can take place, but its route lies somewhere between life and death, not between affective artifacts and emotion approximation by literature machines.", "sections": [{"title": "I. Introduction", "content": "In response to the rise of social artificial intelligence (AI) \u2013 what Marco Facchin and Giacomo\nZanotti (Facchin & Zanotti, 2024) call \u201caffective artificial agents\u201d \u2013 people have started ascribing\nemotions, consciousness or thoughts to large language models (LLMs) on an intuitive basis\n(Schwitzgebel, 2023). The range of reactions to these technologies has varied from love to suicide\n(Walker, 2023; Steinberg, 2023). While those extremes remain fringe cases, the need for dealing with\nthe philosophical question when such ascriptions would be warranted has arisen. This question is\naddressed through the lens of the interrelations of language-use, literature and human behaviour\ntowards AI systems. It will be examined if it makes sense to ascribe psychological predicates to AI\nsystems and chatbots powered by LLMs (ChatGPT, Claude, Llama, among others) in particular. On\nwhat grounds such ascriptions could be valid is an intricate question. Some have since long heeded\nAl researchers from describing AI models with \u2018rich psychological terms'. Impairment of scientific\ncommunication, distraction from actual novel empirical findings on AI, and the risk of running into\npremature conclusions in ethics and law are some of the reasons for caution (Shevlin & Halina, 2019,\np. 167).\nHowever, there must be some incentive for these ascriptions. For the present, you should think of\na 'psychological predicate' as a descriptive property pertaining to your own or another being's \u2018mind',\nto use the neat fa\u00e7on de parler. Since that may still be a bit cryptic to you, the following examples\nof attributions of properties of the psyche might be clarifying: \u2018Anton thinks Fyodor is pretentious',\n\u2018Thomas is in love with Aranea', \u2018Sharik is in pain', \u2018Estragon remembered that he was hungry'.\nAnother way to put it, as M. R. Bennett and P. M. S. Hacker have, is to conceive of psychological\npredicates as a \u201cwide range of cognitive, cogitative, perceptual and volitional capacities\u201d (Bennett &\nHacker, 2003, p. 68): knowing, seeing, understanding, feeling, recognising and so on. Importantly,\nthey are made available to you in language-use. They are identifiable through third-person\nbehavioural signs and first-person phenomenology that denote their presence, but it is language that\nties that all together. The idea of a fa\u00e7on de parler, a way of speaking about something, should thus\nbe a helpful way to think about them; a way to group together all their facets into an information-rich\npackage: a concept. As such, they are linguistic referents with the grammatical role of predicates that\nare about constellations of behaviour and feeling. People speak of having them and ascribe them to\nothers or animals. And, when applied to inanimate objects, they are used in narrative or metaphorical\nsenses, or they are invoked when using the \u2018intentional stance' to predict things' behaviour (it really\ndepends on who you ask).\nThis essay tries to convince you that LLMs are a specific kind of AI, namely linguistic AI. The\nfunction they perform is that of the specific kind of intelligence underlying language-use, but not that\nof others (even though transfer learning shows that there are hints of general intelligence in them as\nwell). This is not to say that all they amount to are word producers, as they are able to exploit the\npowers of language as well: mathematics, physics, and computer code are languages too, after all."}, {"title": "II. Conceptual framework and structure", "content": "The recurrent themes of the subsequent sections are the concept of a \u2018psychological predicate' that\nwas already introduced in the above and its intertwinement with language-use. In part III, it is argued\nhow LLMs digitally incarnate the Wittgensteinian language user. Through their language-use, social\nAls become effective artificial agents by virtue of their \u201cemotion recognition, expression, and\nconditioning.\" Facchin and Zanotti (2023, p. 4) have argued that this is the case for the chatbot LLM\nReplika. The concepts central to this line of argument are 'language-game' (Sprachspiel) and\n'language-use' (Sprachgebrauch). For Wittgenstein, the meaning of language resides in how\nlanguage is used by a \u2018form of life.' Language-use points to the meaning of the words in the context\nof the use, with the natural history of the form of life as a backdrop (Wittgenstein, 1975). Language-\ngames, then, are \u201cthe whole\u201d of \"language and the activities into which it is woven\u201d (Wittgenstein,\n2009, \u00a77). The consideration of language as an activity of the living, which serves many purposes\nobvious as well as hidden \u2013 is important for the analysis of the use that social AI makes of language.\nLike the language-games that contain them as moves, not all uses of language have the same function\nor serve the same purpose. What connects language-games is a form of \u2018family resemblance': \u201ca\ncomplicated net of similarities that overlap and intersect; sometimes fundamental similarities,\nsometimes similarities in details\u201d (Wittgenstein, 2009, \u00a766). Social Al's unmistakable mastery of\nlanguage is what makes the equation of language user and writing machine so seductive: Al's\nlanguage-use resembling that of humans suggests the origin of the Al's use resembles the origin of\nthe activity the human language-use is embedded in. This mastery of language surpasses plain\nanthropomorphising of animals and inanimate objects into a humanising of social AI. Much like\nhumans, Als seem situated in language (homo lingualis (Zelthukina, et al., 2016)) or speak to you as\nhumans do (homo loquens (Matthews, 2003)). In short, social Al's capability of engaging with\nhumans in digital language-games and its consequences are examined.\nSubsequently, in part IV, it will be shown that instead, all social Al's computational architecture\namounts to is the refracting and extending of language patterns from training data, so that really\nascribing psychological predicates to these systems remains a functionalist temptation. The concept\nfacilitating this explicatory move is that of the \u2018literature machine' (Calvino, 1986). The literature\nmachine sketches the other side of the tempting equation: AI systems in the end differ from full-\nblown language users and more closely resemble writing machines in the sense Italo Calvino has\ngiven to these words. Calvino's writing machines are machines that produce and reproduce words in\na way that is meaningful to the human reader. They are machines that engage in the \u201ccombinatorial\ngame\" that is literature \u201cthat pursues the possibilities implicit in its own material [...]\u201d and \u201cthat at a\ncertain point is invested with an unexpected meaning\u201d (Calvino, 1986, p. 23). The idea of LLMs as\nWittgensteinian language users and Calvino's conjecture of the literature-producing language\nmachine is then combined to show why ascribing psychological predicates equals succumbing to a\nmisguided functionalist temptation.\nFunctionalism in this context, as will be explained in detail in part V, is the thesis that if an AI\nsystem's states mirror the brain states giving rise to a psychological phenomenon (isomorphism), then\nthat phenomenon is realized by the AI system (Cocchiarella, 2019). Based upon this understanding,\nthe limitations of the functionalist temptation are uncovered. The emerging paradigm of mortal\ncomputation is proposed as an alternative. The idea of a \u2018mortal computer' is borrowed from the work\nof Alexander Ororbia and Karl Friston (2024). Mortal computers are autopoietic computing systems\nthat are self-regarding in thermodynamical, biophysical and cybernetic ways. It is argued in in part V\nthat the research program of mortal computation shows that current LLMs in the sense of Calvino's\nwriting machines fundamentally lack the building blocks for being self-regarding and self-\nmaintaining, which any meaningful language-use presupposes: extension, embodiment, embedding,\nenactivity and elementarity. These basic constituents of mortality are the grounds that warrant the"}, {"title": "III. Digital language-games: LLM as Wittgensteinian language user", "content": "Now that the main conceptual actors have been introduced, the first argumentative act can commence.\nThe temptation for ascribing psychological predicates to social Als starts with their linguistic\nengagements with humans in digital language-games. A digital language-game is not game-based\nlanguage learning like Duolingo, but the use of words in accordance with the dynamic rules of\nlanguage so that these words come to make sense to fellow language users through digital media.\nEver since the emergence of computers, the Internet, mobile phones and especially social media,\nsearch engines, smartphones and email, many of the language-games people engage in or have created\nhave taken on a digital character. This is to say that WhatsApp, chat services, search engines, dating\napps, etc., constitute new language-games or have shifted the face of old ones that now depend on\ndigital interfaces (writing letters, visiting libraries, small talk). It is within these digital interfaces that\nLLMs' linguistic intelligence and mastery of language enable the substitution of the human language\nuser for the AI-powered one.\nThe question whether LLMs are deserving of humanisation by way of psychological predicates in\nthese language-games should be taken very seriously. Intuitions regarding anthropomorphising were\nalready touched upon. Qua quality of argument, one shouldn't expect much from the shallow move\nthat any appeal to intuition is. Where an intuition comes up, an unexplained socio-cultural or natural\nhistory resides. Recently however, Martin Stokhof proposed a \u2018philosophie pauvre': a conception of\nphilosophy as a practice of inciting \u2018changes in perspective' (Stokhof, 2022b, pp. 21-22). Simply put,\nby way of philosophy minor changes to one's conceptual perceptions occur, which leads to seeing\nhow things stand in another way. Philosophie pauvre is \u201ca modest, hesitating, critically self-reflecting\nphilosophy [...]. Rather than trying to carve out a highly specialised, exclusively philosophical\ndomain, it seems it is both more modest and more productive to view philosophy as one way of\ndealing with the episodic, the everyday.\u201d What is important for the subject of this text is that Stokhof\nraised the question whether such \u2018changes in perspective' could result in a new angle for making\nsense of \u201chow/when/why to treat AI as akin to/on a par with human intelligence\u201d. Stokhof asks:\nWhen will we treat artificial systems as intelligent? In much the same way that the\nhumanity of others is a matter of attitude, as Wittgenstein indicated in Philosophical\nInvestigations, 420, II iv, 19, AI and our relation to it is a matter of attitude as well.\nWhen we grow up with AI in ways that are sufficiently similar to the ways in which\nwe grow up with humans, the attitudes we have towards them, AI and humans, will be\nthe same. If we look at the initial question from this episodic point of view, our\nconsiderations may still touch on abstract and theoretical questions. But the\nperspective from which we address them and the role that is played by the answers\nthat we come up with, is fundamentally different. One such more abstract\nconsideration revolves around the fact that there are, of course, lots of intermediate\ncases. AI can play many different roles in our lives that range from pure, tool-like\nfunctionality to something that invokes a \u2018humanlike' stance. What is crucial is that\nthese differences do not correlate one-to-one with conceptual differences. And that is\nwhy the conceptual way of viewing the question falls short (Stokhof, 2022a, p. 135).\nThe richness of Stokhof's \u2018episodic' approach to human relations with AI lies in its explanatory\npower. Regarding our use of language towards each other not as fixed, but as a product of human\ngeneration explains why people react to (love, befriend, hate) and treat (ascribe sentience) social AI\nas they do. They're already having the same forms of \u2018intersubjectivity' in digital language-games\nwith social AI as they have with real humans. The impact of the \u2018change in perspective' lies in its\nhonest embrace of the idea that the ways words like intelligence and emotion are used towards humans\ndepend on a natural history and a tradition of enacting and handing down these concepts"}, {"title": "IV. Calvino's literature machine", "content": "In one of his letters from 1886, Anton Chekhov disclosed that at times he wrote his stories \u201cmachine-\nlike, half thoughtless, not caring in the least about the reader or myself...\u201d (Chekhov, 1952, p. 87).\nYou, a twenty-first century reader, might view this as a first-person description of a \u2018System 1'\nprocess. Daniel Kahneman famously used this term to speak of intuitive, automatic and subconscious"}, {"title": "V. Mortal computation and the functionalist temptation", "content": "While much attention is given to the \u2018emergence' of psychological phenomena from computer\nmachinery, pursuing the functionalist temptation is all but uncontroversial. To understand the\ntemptation of moving from language-use and literature machine to the genuine emergence of\npsychology, let's sketch the common view of this emergence. Although the algorithms underlying\nLLMs perform relatively simple computations, the model it has given rise to after training is opaque\nand so complex that it is not understood and may have given rise to cognition or forms of intelligence\n(The Guardian, 2023). This view presupposes that simple algorithmic computations can give rise to\nmore complex computational behaviour. The functionalist premise that needs to be accepted for this\nidea to be plausible is that of the isomorphism between the states an AI system is in and the brain\nstates of a human mind (Cocchiarella, 2019). In turn, the gradually accumulating computational\ncomplexities would qualify as sentience once an isomorphism with the brain state of sentience is\nachieved. Simple computations of processing a single input sequentially lead to the transformation of\nall the training data, thereby gradually giving rise to an entire semantic space that is learnt by the\nmodel. Based upon this semantic space, the system, when presented with a novel input, exhibits\nsophisticated cognitive capacities.\nAccording to classic functionalism, Nino Cocchiarella maintains, there are three levels of\n'consciousness' of such an AI system. (1) The \u201cself-regarding behavior\u201d that is characteristic of"}, {"title": "VI. Results", "content": "It is time to take stock of the results. The exploration of Wittgenstein's language user in digital spaces\nin combination with the thinking tool that is Calvino's literature machine, has enabled the previous\nsection to pinpoint what the functionalist approach to social AI lacks. To recapitulate, it was found\nthat LLM-based social Als convincingly participate in digital language-games because their\nlanguage-use seems conversants to be interchangeable with human language-use in the same contexts.\nHowever, through the development of Calvino's idea of the literature machine, it was shown that all\nthat text that is generated by a statistical recombination of elements amounts to is the automation of\nlanguage production. This text can be meaningful only in interaction with the reader: it asks for the\ndisautomisation of reading, and this is where it falls short of being full-blown language-use: it is not\nsimultaneously embedded in a process of mutual sensemaking. Coming from social AI, the narrative\nfunction is not self-maintaining. This result does not diminish the potency of social AI qua literature\nmachines but rather sharply distinguishes them from human interaction through language and\nexplains why social Al's apparent mastery of digital language-games gives rise to the misguided\ninference that the psychological predicates language carries must be applicable as well.\nIn functionalist LLMs, software is always disjoint from the object executing it and it only comes\nwith the illusion of being a self-regarding system. The framework of mortal computation showed\nautopoiesis is way beyond their computational capabilities, as the LLM's emotional intelligence is\nnot embodied, embedded, extended, or enacted. As such, can one really hold that the LLM's\nrecognition, expression, and conditioning of human emotion \u201cresembles (behaves like) a living\nhuman being\", as Wittgenstein said? The results of the disqualification of functionalism and the\nframing of psychological predicates as fa\u00e7ons de parler that are very particular to human narrative\nsensemaking enable us to answer negatively: no, here the point has been reached where the\nshortcomings of the functionalist temptation of equating language-use with literature machinery have\nbecome visible. Emotions, from a biological perspective, are enactive, embodied, and extended and\nhave a purpose to maintaining the system emulating them and perturbing its direct environment.\nNow the hypothesis pursued from the outset can genuinely be asserted: only of a mortal computer\nthat emotionally \u201cresembles (behaves like) a living human being\u201d can one sensibly say: \u2018it is angry',\n\u2018It is in love with me,' and so on. Social Als are but Calvinoan literature machines, reproducing old\nand creating new narrations of human life.\nThe relevance of these findings has practical consequences and yields theoretical directions for\nresearch as well. The most salient practical consequence is that everyday ascriptions of psychology\nto social Al are nonsensical, and therefore, active resistance to these ascriptions is warranted.\nTheoretically speaking, three important questions that could direct future research are prompted by\nthe characterisation of social Als as Calvinoan literature machines. First, there is the pursuit of the\nstudy of LLMs qua literature machines. In the tradition of Calvino's own venture to create artificial\""}, {"title": "VII. Conclusion", "content": "Moving backward from mortal computation and functionalism, through Calvino's literature machine\nand Wittgenstein's language user, one returns to Stokhof's philosophie pauvre. It is time to answer\nhis inquiry whether the question \u201chow/when/why to treat Al as akin to/on a par with human\nintelligence\" requires a philosophical change in perspective. The short answer is that it does. The\nlonger answer is that it should, however, not be the change that succumbs to the functionalist\ntemptation: ascribing psychological predicates to AI relinquishes the bounds of sense. Equating\naffective agents' linguistic capacities and literary potential with human phenomenology remains\nnonsensical. The corollary of this conclusion is a simple, short answer to the nested question \u2018when\nto treat Al as human': not yet. Until social Als have come to behave and resemble human beings in\ntheir autopoiesis and environmental grounding, it will not really make sense to describe them using\nthe same psychological predicates used for narrating and making sense of the behaviour of humans\nas a whole.\nIn conclusion, a change in perspective is needed regarding how humans tend to use psychological\npredicates. They are narrative fa\u00e7ons de parler for making sense of animal (inter)action. Someday, it\nwill make sense to describe Als in these animal-centred terms, namely when they surpass animism\nand have become mortal themselves. The transition \u2018from quantity to quality' can take place, but its\nroute lies somewhere between life and death, not between affective artifact and emotion\napproximation by literature machines.\"\n    }"}]}