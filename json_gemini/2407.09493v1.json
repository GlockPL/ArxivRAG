{"title": "Social AI and The Equation of Wittgenstein's Language User With Calvino's Literature Machine", "authors": ["W. J. T. Mollema"], "abstract": "Is it sensical to ascribe psychological predicates to AI systems like chatbots based on large language models (LLMs)? People have intuitively started ascribing emotions or consciousness to social AI (\u2018affective artificial agents'), with consequences that range from love to suicide. The philosophical question of whether such ascriptions are warranted is thus very relevant. This paper advances the argument that LLMs instantiate language users in Ludwig Wittgenstein's sense but that ascribing psychological predicates to these systems remains a functionalist temptation. Social Als are not full-blown language users, but rather more like Italo Calvino's literature machines. The ideas of LLMs as Wittgensteinian language users and Calvino's literature-producing writing machine are combined. This sheds light on the misguided functionalist temptation inherent in moving from equating the two to the ascription of psychological predicates to social AI. Finally, the framework of mortal computation is used to show that social Als lack the basic autopoiesis needed for narrative fa\u00e7ons de parler and their role in the sensemaking of human (inter)action. Such psychological predicate ascriptions could make sense: the transition \u2018from quantity to quality' can take place, but its route lies somewhere between life and death, not between affective artifacts and emotion approximation by literature machines.", "sections": [{"title": "I. Introduction", "content": "In response to the rise of social artificial intelligence (AI) \u2013 what Marco Facchin and Giacomo Zanotti call \u201caffective artificial agents\u201d \u2013 people have started ascribing emotions, consciousness or thoughts to large language models (LLMs) on an intuitive basis (Schwitzgebel, 2023). The range of reactions to these technologies has varied from love to suicide (Walker, 2023; Steinberg, 2023). While those extremes remain fringe cases, the need for dealing with the philosophical question when such ascriptions would be warranted has arisen. This question is addressed through the lens of the interrelations of language-use, literature and human behaviour towards AI systems. It will be examined if it makes sense to ascribe psychological predicates to AI systems and chatbots powered by LLMs (ChatGPT, Claude, Llama, among others) in particular. On what grounds such ascriptions could be valid is an intricate question. Some have since long heeded Al researchers from describing AI models with \u2018rich psychological terms'. Impairment of scientific communication, distraction from actual novel empirical findings on AI, and the risk of running into premature conclusions in ethics and law are some of the reasons for caution (Shevlin & Halina, 2019, p. 167).\nHowever, there must be some incentive for these ascriptions. For the present, you should think of a 'psychological predicate' as a descriptive property pertaining to your own or another being's \u2018mind', to use the neat fa\u00e7on de parler.\u00b9 Since that may still be a bit cryptic to you, the following examples of attributions of properties of the psyche might be clarifying: \u2018Anton thinks Fyodor is pretentious', \u2018Thomas is in love with Aranea', \u2018Sharik is in pain', \u2018Estragon remembered that he was hungry'. Another way to put it, as M. R. Bennett and P. M. S. Hacker have, is to conceive of psychological predicates as a \u201cwide range of cognitive, cogitative, perceptual and volitional capacities\u201d (Bennett & Hacker, 2003, p. 68): knowing, seeing, understanding, feeling, recognising and so on. Importantly, they are made available to you in language-use. They are identifiable through third-person behavioural signs and first-person phenomenology that denote their presence, but it is language that ties that all together. The idea of a fa\u00e7on de parler, a way of speaking about something, should thus be a helpful way to think about them; a way to group together all their facets into an information-rich package: a concept. As such, they are linguistic referents with the grammatical role of predicates that are about constellations of behaviour and feeling. People speak of having them and ascribe them to others or animals. And, when applied to inanimate objects, they are used in narrative or metaphorical senses, or they are invoked when using the \u2018intentional stance' to predict things' behaviour (it really depends on who you ask).\nThis essay tries to convince you that LLMs are a specific kind of AI, namely linguistic AI. The function they perform is that of the specific kind of intelligence underlying language-use, but not that of others (even though transfer learning shows that there are hints of general intelligence in them as well). This is not to say that all they amount to are word producers, as they are able to exploit the powers of language as well: mathematics, physics, and computer code are languages too, after all."}, {"title": "II. Conceptual framework and structure", "content": "The recurrent themes of the subsequent sections are the concept of a \u2018psychological predicate' that was already introduced in the above and its intertwinement with language-use. In part III, it is argued how LLMs digitally incarnate the Wittgensteinian language user. Through their language-use, social Als become effective artificial agents by virtue of their \u201cemotion recognition, expression, and conditioning.", "language-game": "Sprachspiel) and 'language-use' (Sprachgebrauch). For Wittgenstein, the meaning of language resides in how language is used by a \u2018form of life.' Language-use points to the meaning of the words in the context of the use, with the natural history of the form of life as a backdrop (Wittgenstein, 1975). Language-games, then, are \u201cthe whole\u201d of \"language and the activities into which it is woven\u201d (Wittgenstein, 2009, \u00a77). The consideration of language as an activity of the living, which serves many purposes \u2013 obvious as well as hidden \u2013 is important for the analysis of the use that social AI makes of language. Like the language-games that contain them as moves, not all uses of language have the same function or serve the same purpose. What connects language-games is a form of \u2018family resemblance': \u201ca complicated net of similarities that overlap and intersect; sometimes fundamental similarities, sometimes similarities in details\u201d (Wittgenstein, 2009, \u00a766). Social Al's unmistakable mastery of language is what makes the equation of language user and writing machine so seductive: Al's language-use resembling that of humans suggests the origin of the Al's use resembles the origin of the activity the human language-use is embedded in. This mastery of language surpasses plain anthropomorphising of animals and inanimate objects into a humanising of social AI. Much like humans, Als seem situated in language (homo lingualis ) or speak to you as humans do (homo loquens (Matthews, 2003)). In short, social Al's capability of engaging with humans in digital language-games and its consequences are examined.\nSubsequently, in part IV, it will be shown that instead, all social Al's computational architecture amounts to is the refracting and extending of language patterns from training data, so that really ascribing psychological predicates to these systems remains a functionalist temptation. The concept facilitating this explicatory move is that of the \u2018literature machine' (Calvino, 1986). The literature machine sketches the other side of the tempting equation: AI systems in the end differ from full-blown language users and more closely resemble writing machines in the sense Italo Calvino has given to these words. Calvino's writing machines are machines that produce and reproduce words in a way that is meaningful to the human reader. They are machines that engage in the \u201ccombinatorial game", "that pursues the possibilities implicit in its own material [...]": "nd \u201cthat at a certain point is invested with an unexpected meaning\u201d (Calvino, 1986, p. 23). The idea of LLMs as Wittgensteinian language users and Calvino's conjecture of the literature-producing language machine is then combined to show why ascribing psychological predicates equals succumbing to a misguided functionalist temptation.\nFunctionalism in this context, as will be explained in detail in part V, is the thesis that if an AI system's states mirror the brain states giving rise to a psychological phenomenon (isomorphism), then that phenomenon is realized by the AI system (Cocchiarella, 2019). Based upon this understanding, the limitations of the functionalist temptation are uncovered. The emerging paradigm of mortal computation is proposed as an alternative. The idea of a \u2018mortal computer' is borrowed from the work of Alexander Ororbia and Karl Friston (2024). Mortal computers are autopoietic computing systems that are self-regarding in thermodynamical, biophysical and cybernetic ways. It is argued in in part V that the research program of mortal computation shows that current LLMs in the sense of Calvino's writing machines fundamentally lack the building blocks for being self-regarding and self- maintaining, which any meaningful language-use presupposes: extension, embodiment, embedding, enactivity and elementarity. These basic constituents of mortality are the grounds that warrant the"}, {"title": "III. Digital language-games: LLM as Wittgensteinian language user", "content": "Now that the main conceptual actors have been introduced, the first argumentative act can commence.\nThe temptation for ascribing psychological predicates to social Als starts with their linguistic engagements with humans in digital language-games. A digital language-game is not game-based language learning like Duolingo, but the use of words in accordance with the dynamic rules of language so that these words come to make sense to fellow language users through digital media. Ever since the emergence of computers, the Internet, mobile phones and especially social media, search engines, smartphones and email, many of the language-games people engage in or have created have taken on a digital character. This is to say that WhatsApp, chat services, search engines, dating apps, etc., constitute new language-games or have shifted the face of old ones that now depend on digital interfaces (writing letters, visiting libraries, small talk). It is within these digital interfaces that LLMs' linguistic intelligence and mastery of language enable the substitution of the human language user for the AI-powered one.\nThe question whether LLMs are deserving of humanisation by way of psychological predicates in these language-games should be taken very seriously. Intuitions regarding anthropomorphising were already touched upon. Qua quality of argument, one shouldn't expect much from the shallow move that any appeal to intuition is. Where an intuition comes up, an unexplained socio-cultural or natural history resides. Recently however, Martin Stokhof proposed a \u2018philosophie pauvre': a conception of philosophy as a practice of inciting \u2018changes in perspective' (Stokhof, 2022b, pp. 21-22). Simply put, by way of philosophy minor changes to one's conceptual perceptions occur, which leads to seeing how things stand in another way. Philosophie pauvre is \u201ca modest, hesitating, critically self-reflecting philosophy [...]. Rather than trying to carve out a highly specialised, exclusively philosophical domain, it seems it is both more modest and more productive to view philosophy as one way of dealing with the episodic, the everyday.\u201d What is important for the subject of this text is that Stokhof raised the question whether such \u2018changes in perspective' could result in a new angle for making sense of \u201chow/when/why to treat AI as akin to/on a par with human intelligence\u201d. Stokhof asks:\nWhen will we treat artificial systems as intelligent? In much the same way that the humanity of others is a matter of attitude, as Wittgenstein indicated in Philosophical Investigations, 420, II iv, 19, AI and our relation to it is a matter of attitude as well. When we grow up with AI in ways that are sufficiently similar to the ways in which we grow up with humans, the attitudes we have towards them, AI and humans, will be the same. If we look at the initial question from this episodic point of view, our considerations may still touch on abstract and theoretical questions. But the perspective from which we address them and the role that is played by the answers that we come up with, is fundamentally different. One such more abstract consideration revolves around the fact that there are, of course, lots of intermediate cases. AI can play many different roles in our lives that range from pure, tool-like functionality to something that invokes a \u2018humanlike' stance. What is crucial is that these differences do not correlate one-to-one with conceptual differences. And that is why the conceptual way of viewing the question falls short (Stokhof, 2022a, p. 135).\nThe richness of Stokhof's \u2018episodic' approach to human relations with AI lies in its explanatory power. Regarding our use of language towards each other not as fixed, but as a product of human generation explains why people react to (love, befriend, hate) and treat (ascribe sentience) social AI as they do. They're already having the same forms of \u2018intersubjectivity' in digital language-games with social AI as they have with real humans. The impact of the \u2018change in perspective' lies in its honest embrace of the idea that the ways words like intelligence and emotion are used towards humans depend on a natural history and a tradition of enacting and handing down these concepts"}, {"title": "IV. Calvino's literature machine", "content": "In one of his letters from 1886, Anton Chekhov disclosed that at times he wrote his stories \u201cmachine-like, half thoughtless, not caring in the least about the reader or myself...\u201d (Chekhov, 1952, p. 87). You, a twenty-first century reader, might view this as a first-person description of a \u2018System 1' process. Daniel Kahneman famously used this term to speak of intuitive, automatic and subconscious psychological processes. On the other hand, \u2018System 2' \u2013 System 1's partner in crime \u2013 encompasses the execution of attentive, deliberate and more cognitively demanding tasks (Kahneman, 2011). Writing, such as Chekhov is doing, can in principle be regarded as executable by System 1 as well as by System 2 depending on the context of the writing. Compare the differences between writing an essay, a grocery list, a text message and an email and you see how the production of words to some end can be intuitive and automatic in some cases, as well as deliberate and slow in others. Loosely stated, for humans the execution depends on the complexity of the thoughts channelled into writing and the level of attention devoted to the writing task. As such, one can make sense of Chekhov's remarks as the description of System 1 language production.\nThe takeaway points that should not be lost on you of this redescription of a writer's experience of writing are the mechanicity and automaticity of this writing process. Writers, as Italo Calvino has noted, \"are already writing machines; or at least they are when things are going well\u201d (Calvino, 1986, p. 16). Could LLMs generating language be analogous to the System 1 characterisation of human writing? Calvino's homo narrans, the storytelling or even literary human, is more specific than the homo lingualis or loquens encountered before. For the homo narrans, what is characteristic of human language-use is the creation of narrations and the replaying of existing narrations of its behaviour, that of others and the environment. It is therefore not at all strange to conceive of the fa\u00e7ons de parler that carry psychological predicates as stabilized patterns of narration of human life. This is something that is explicitly echoed by Harari, who sees the story as the most powerful force driving human history \u2013 whether the story is religious, political or social in nature. According to Calvino, at the root of this storytelling lies the recombination of predefined elements of speech: words that, when used in narration, \u201cacquired new values and transmitted them to the ideas and images they defined\u201d (Calvino, 1986, p. 6). The usage of quasi-stable elements does not impair the countless permutations and transformations the elements can undergo in their recombination.\nCalvino's 1967 lecture \u201cCybernetics and Ghosts", "electronic brain": "hat produces meaningful text via a combinatorial process. Simultaneously thinking of today's LLMs, you could see how these writing machines have algorithmically learned the storytelling elements of human language from their training data (the entire Internet) and are reproducing the storytelling patterns in their data. In short, they exploit narrative images humans have constructed and put to text: language-games that concern the narration of how information is transmitted from one human to another for the purposes of education and science, news with a storyline, small talk, etc. \u201cThe literature machine,\u201d Calvino wrote,\n...can perform all the permutations possible on a given material, but the poetic result will be the particular effect of one of these permutations on a man endowed with a consciousness and an unconscious, that is, an empirical and historical man. (Ibid., p. 6).\nRegardless of the unlimited potential for creative recombination (that undoubtedly statistically adheres closely to narrative patterns from the training data), the production of words stands in need of a reader, an interpreter, on which they are to have effect. The produced words stand by themselves, are externalised so to speak. \u201cIsn't a word a word\u2500still a word\u2500regardless of who, or what, wrote it?", "I": "as disappearing: \"The psychological person is replaced by a linguistic or even a grammatical person, defined solely by his place in the discourse\u201d (Calvino, 1986, p. 8). The written (literary) text is a"}, {"title": "V. Mortal computation and the functionalist temptation", "content": "While much attention is given to the \u2018emergence' of psychological phenomena from computer machinery, pursuing the functionalist temptation is all but uncontroversial. To understand the temptation of moving from language-use and literature machine to the genuine emergence of psychology, let's sketch the common view of this emergence. Although the algorithms underlying LLMs perform relatively simple computations, the model it has given rise to after training is opaque and so complex that it is not understood and may have given rise to cognition or forms of intelligence (The Guardian, 2023). This view presupposes that simple algorithmic computations can give rise to more complex computational behaviour. The functionalist premise that needs to be accepted for this idea to be plausible is that of the isomorphism between the states an AI system is in and the brain states of a human mind (Cocchiarella, 2019). In turn, the gradually accumulating computational complexities would qualify as sentience once an isomorphism with the brain state of sentience is achieved. Simple computations of processing a single input sequentially lead to the transformation of all the training data, thereby gradually giving rise to an entire semantic space that is learnt by the model. Based upon this semantic space, the system, when presented with a novel input, exhibits sophisticated cognitive capacities.\nAccording to classic functionalism, Nino Cocchiarella maintains, there are three levels of 'consciousness' of such an AI system. (1) The \u201cself-regarding behavior\u201d that is characteristic of animals with a nervous system; (2) the \u201creflexive abstraction\u201d of a linguistic representational system; and (3) \"introspective self-consciousness\u201d (Cocchiarella, 2019). At first glance, stage (1) seems easily attained for LLMs, at least in their language-use; they are able to answer questions about themselves. Clearly stage (2) can be obtained as well, as becomes clear from their language-use: prompt it well and the LLM's reflexive abstraction of complex concepts is better than that of the average human. For stage (3), the case is more mysterious and this is where the notion of emergence is so important. Using the idea of emergence as a genuine possibility, stage (3) is smuggled in along with the attainment of stage (2).\nWithout taking on the task of arguing the entire endeavour of attaining stage (3) functional consciousness is impossible, an emphasis should be placed on how this view runs into problems straight away. Apart from the conflation of the use of the words for psychological predicates (such as sentience) with 'the brain being in a certain state' that Wittgenstein has long shown to be conceptually confused (Wittgenstein, 2009, \u00a7180), the notion of emergence has its own problems. Joscha Bach laments that \u201cwedging the popular notion of emergence\u201d is a tactic to close an \u201cexplanatory gap", "weak emergence,\" Bach states, will not make intelligence appear magically. The functionality has to be accounted for in the algorithms themselves (Bach, 2008, ibid.). This means that even when a system is able to exhibit properties that its individual components could not, this exhibition can be readily reduced into compositional contributions of the individual components. Neglecting that emergence is only a placeholder-concept, unsupportive of any inference, would naively presuppose the functionalist multiple realisability of cognition to be true. \u2018If the realisation of the function is observed, then the cognition must also be there', so this line of reasoning goes. That would be problematic, because without empirical backup, it only works on paper by buying the isomorphism of AI state and brain state in the first place.\nFurthermore, this brand of functionalism entails that (i) what counts as cognition depends on the function that is performed by cognition and (ii) that this function could be realised in different material substrates as long as the formalism that specifies the function is present. The controversiality of these two points lies in the overly top-down approach \u2013 sometimes derided as \u2018computational chauvinism' \u2013 that it expresses. In short, it foregoes really taking structural complexities of the material substrate into account (Piccinini, 2006, p. 344) and systematically neglects the linguistic nature of many of the concepts that are supposedly explained away by correspondences of the electronic to the neuronal. As has been asserted in the previous sections, there is a strong sense in which the psychological predicates one is seeking to emulate are fa\u00e7ons de parler; narrations of human interaction. They can only sensibly be applied to the human being as a whole, not to one of its parts (mind \u2013 model). Their use is namely logico-grammatically entangled with human behaviour \u2013 not with brain or computational model behaviour. The fallacy inherent in this line of reasoning has famously been called the 'mereological fallacy' by Bennett and Hacker: the ascription of a predicate to a part of a whole that is misguided (speed to the engine instead of the car; wise to the brain instead of the person, etc.), because it can only apply to the whole in its entirety (Bennett & Hacker, 2003, pp. 68-78).\nThis embedding of psychological predicates in language is a result that is promising for the prospect of engineering social AI, since language-use has proven to be well tokenizable and controllable for LLMs. Hence the function is in the language and emotional intelligence can be perfected via algorithmic approximation. On the other hand, this spells trouble for the functionalist framing of the matter. Paradoxically as it may sound at first, if psychological predicates are fundamentally ways of narration grafted upon biological behaviours, then their function is mostly in the language and not \u2018in the brain'. Therefore, approximating their function leads to the\"\n    },\n    {\n      \"title\": \"VI. Results\",\n      \"content\": \"It is time to take stock of the results. The exploration of Wittgenstein's language user in digital spaces in combination with the thinking tool that is Calvino's literature machine, has enabled the previous section to pinpoint what the functionalist approach to social AI lacks. To recapitulate, it was found that LLM-based social Als convincingly participate in digital language-games because their language-use seems conversants to be interchangeable with human language-use in the same contexts. However, through the development of Calvino's idea of the literature machine, it was shown that all that text that is generated by a statistical recombination of elements amounts to is the automation of language production. This text can be meaningful only in interaction with the reader: it asks for the disautomisation of reading, and this is where it falls short of being full-blown language-use: it is not simultaneously embedded in a process of mutual sensemaking. Coming from social AI, the narrative function is not self-maintaining. This result does not diminish the potency of social AI qua literature machines but rather sharply distinguishes them from human interaction through language and explains why social Al's apparent mastery of digital language-games gives rise to the misguided inference that the psychological predicates language carries must be applicable as well.\nIn functionalist LLMs, software is always disjoint from the object executing it and it only comes with the illusion of being a self-regarding system. The framework of mortal computation showed autopoiesis is way beyond their computational capabilities, as the LLM's emotional intelligence is not embodied, embedded, extended, or enacted. As such, can one really hold that the LLM's recognition, expression, and conditioning of human emotion \u201cresembles (behaves like) a living human being\", as Wittgenstein said? The results of the disqualification of functionalism and the framing of psychological predicates as fa\u00e7ons de parler that are very particular to human narrative sensemaking enable us to answer negatively: no, here the point has been reached where the shortcomings of the functionalist temptation of equating language-use with literature machinery have become visible. Emotions, from a biological perspective, are enactive, embodied, and extended and have a purpose to maintaining the system emulating them and perturbing its direct environment.\nNow the hypothesis pursued from the outset can genuinely be asserted: only of a mortal computer that emotionally \u201cresembles (behaves like) a living human being": "an one sensibly say: \u2018it is angry', \u2018It is in love with me,' and so on. Social Als are but Calvinoan literature machines, reproducing old and creating new narrations of human life.\nThe relevance of these findings has practical consequences and yields theoretical directions for research as well. The most salient practical consequence is that everyday ascriptions of psychology to social Al are nonsensical, and therefore, active resistance to these ascriptions is warranted. Theoretically speaking, three important questions that could direct future research are prompted by the characterisation of social Als as Calvinoan literature machines. First, there is the pursuit of the study of LLMs qua literature machines. In the tradition of Calvino's own venture to create artificial"}, {"title": "VII. Conclusion", "content": "Moving backward from mortal computation and functionalism, through Calvino's literature machine and Wittgenstein's language user, one returns to Stokhof's philosophie pauvre. It is time to answer his inquiry whether the question \u201chow/when/why to treat Al as akin to/on a par with human intelligence\" requires a philosophical change in perspective. The short answer is that it does. The longer answer is that it should, however, not be the change that succumbs to the functionalist temptation: ascribing psychological predicates to AI relinquishes the bounds of sense. Equating affective agents' linguistic capacities and literary potential with human phenomenology remains nonsensical. The corollary of this conclusion is a simple, short answer to the nested question \u2018when to treat Al as human': not yet. Until social Als have come to behave and resemble human beings in their autopoiesis and environmental grounding, it will not really make sense to describe them using the same psychological predicates used for narrating and making sense of the behaviour of humans as a whole.\nIn conclusion, a change in perspective is needed regarding how humans tend to use psychological predicates. They are narrative fa\u00e7ons de parler for making sense of animal (inter)action. Someday, it will make sense to describe Als in these animal-centred terms, namely when they surpass animism and have become mortal themselves. The transition \u2018from quantity to quality' can take place, but its route lies somewhere between life and death, not between affective artifact and emotion approximation by literature machines.\"\n    }"}]}