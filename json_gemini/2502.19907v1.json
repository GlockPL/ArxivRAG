{"title": "Order Doesn't Matter, But Reasoning Does:\nTraining LLMs with Order-Centric Augmentation", "authors": ["Qianxi He", "Qianyu He", "Jiaqing Liang", "Yanghua Xiao", "Weikang Zhou", "Zeye Sun", "Fei Yu"], "abstract": "Logical reasoning is essential for large lan-\nguage models (LLMs) to ensure accurate and\ncoherent inference. However, LLMs struggle\nwith reasoning order variations and fail to\ngeneralize across logically equivalent transfor-\nmations. LLMs often rely on fixed sequential\npatterns rather than true logical understanding.\nTo address this issue, we introduce an order-\ncentric data augmentation framework based\non commutativity in logical reasoning. We\nfirst randomly shuffle independent premises to\nintroduce condition order augmentation. For\nreasoning steps, we construct a directed acyclic\ngraph (DAG) to model dependencies between\nsteps, which allows us to identify valid\nreorderings of steps while preserving logical\ncorrectness. By leveraging order-centric\naugmentations, models can develop a more\nflexible and generalized reasoning process.\nFinally, we conduct extensive experiments\nacross multiple logical reasoning benchmarks,\ndemonstrating that our method significantly\nenhances LLMs' reasoning performance\nand adaptability to diverse logical structures.", "sections": [{"title": "Introduction", "content": "Large language models (LLMs) have demonstrated\nexceptional performance across various real-world\napplications (Jaech et al., 2024; Dubey et al., 2024;\nLiu et al., 2024a). Logic reasoning (Cummins et al.,\n1991) is essential for LLMs. It allows models to\ndraw valid conclusions, maintain coherence, and\nmake reliable decisions across tasks (Pan et al.,\n2023; Liu et al., 2023).\nHowever, LLMs are sensitive to reasoning order\nand struggle with logically equivalent transforma-\ntions (Chen et al., 2024; Berglund et al., 2023b;\nTarski, 1956). First, the models are highly sensitive\nto the order of premises, with perturbing the order\nleading to up to a 40% performance drop (Chen\net al., 2024; Liu et al., 2024b). Additionally, if the\ntesting order is reversed compared to the training\norder, accuracy drops drastically. For example, in\nthe case of data involving two entities within a sin-\ngle factual statement, accuracy drops from 96.7%\nto 0.1% when training is left-to-right and testing is\nright-to-left. (Berglund et al., 2023b,a; Allen-Zhu\nand Li, 2023). This suggests that LLMs follow\na rigid logical reasoning order driven by learned\npatterns rather than true logical understanding.\nExisting LLM logical data augmentation meth-\nods do not effectively address the sensitivity to\nequivalent transformations. First, many logical\ndatasets are specifically designed for certain do-\nmains, such as specialized fields or exam ques-\ntions, primarily to broaden the scope of logical\nreasoning data collection and application (Han\net al., 2022; Liu et al., 2020; Yu et al., 2020). Sec-\nond, a line of work aims to enhance the model's\nreasoning by mapping natural language to sym-\nbolic reasoning (Olausson et al., 2023; Xu et al.,\n2024; Pan et al., 2023), but it primarily provides\nsymbolic tools for understanding logical language\nrather than enhancing the logical structure itself.\nLastly, another augmentation method creates a\n\"vacuum\" world to block interference from real-\nworld logic (Saparov and He, 2022), but it focuses\non the impact of the model's prior experience on\nreasoning, without addressing the design of logical\nequivalence.\nIn fact, commutativity is a crucial property\nof logical reasoning. As established by G\u00f6del's\ncompleteness theorem (G\u00f6del, 1930) and Tarski's\nmodel theory (Tarski, 1956), commutativity means\nthat independent logical units can be freely re-\nordered without changing the essence of the logical\nstructure. Therefore, in logical reasoning, first, in-\ndependent premises are commutative. As shown\nin the upper half of Fig. 1, different orders of\npremises represent equivalent problem structures.\nFurthermore, as demonstrated by Gentzen's proof\ntheory (Gentzen, 1935), reasoning steps are also\ncommutative, provided their dependencies are in-\ntact. As shown in the lower half of Fig. 1, changing\nthe order of steps without disrupting the depen-\ndencies results in an equivalent reasoning process.\nHowever, altering the order of dependent steps dis-\nrupts inference and prevents a coherent path to the\ncorrect conclusion.\nIn this work, we propose an order-centric data\naugmentation framework that explicitly incorpo-\nrates logical commutativity into LLM training. For\ncondition order, we randomly shuffle all indepen-\ndent premises. For reasoning steps, we construct a\nstructured, step-by-step reasoning process, identify\nstep dependencies using a directed acyclic graph\n(DAG), and apply topological sorting to reorder rea-\nsoning steps while preserving logical dependencies.\nOrder-centric data augmentation allows models to\nlearn logical equivalence through commutativity,\nleading to a deeper understanding of logic, rather\nthan relying solely on fixed patterns to solve prob-\nlems. Our experiments show that order-centric aug-\nmentation outperforms training on datasets with a\nfixed logical structure, enhancing the model's over-\nall reasoning ability and improving its performance\nin complex shuffled testing scenarios."}, {"title": "Related Work", "content": "2.1 Order Effect of Language Models\nLarge language models are sensitive to reason-\ning order. While word order variations in natu-\nral language have little impact (Cao et al., 2023;\nAbdou et al., 2022), disrupting the order in rea-\nsoning tasks significantly degrades performance.\nChen et al. (2024) show that models perform op-\ntimally only when the premise order matches the\nsequence required for the reasoning process. To ad-\ndress this, Liu et al. (2024b) propose reorganizing\npremise order to reduce order sensitivity. However,\nthis approach is task-specific and lacks generaliz-\nability. Furthermore, the Reversal Curse reveals\nthat models fail to grasp logical equivalence when\ntrained with a fixed linguistic order (Berglund et al.,\n2023b). Golovneva et al. (2024) mitigate this by\nproposing reverse training, where LLMs learn both\nforward and reverse reasoning by randomly shuf-\nfling words or segments within a sentence. This\nhighlights the need for diverse training data with\nvaried orderings.\nCompared to the above works, we extend to\nmore complex logical reasoning scenarios, build-\ning upon this concept by leveraging commutativity\nfor data augmentation in logical reasoning, which\nhelps models generalize across different reasoning\nstructures and enhances robustness.\n2.2 Logical Reasoning Enhancing\nExisting methods to enhance LLMs' logical reason-\ning ability mainly fall into three categories: inte-\ngrating symbolic reasoning, training and inference\nstrategies, and leveraging data augmentation.\nSymbolic reasoning enhances LLMs by trans-\nforming natural language into formal logic, pro-\nviding a symbolic approach that helps models un-\nderstand logic (Olausson et al., 2023; Xu et al.,\n2024; Zhang et al., 2023). Training and inference"}, {"title": "Problem Formulation", "content": "In this paper, we formulate the problem of log-\nical reasoning in a unified representation. Let\n\ud835\udc37 = {\ud835\udc43, \ud835\udc36, \ud835\udc3f} represent a logical reasoning prob-\nlem, where \ud835\udc43 = {\ud835\udc43\u2081, \ud835\udc43\u2082, ..., \ud835\udc43\u2099} is the set of\npremises, \ud835\udc36 is the conclusion, and \ud835\udc3f is the la-\nbel, which takes a value from a finite set, such\nas {\ud835\udc61\ud835\udc5f\ud835\udc62\ud835\udc52, \ud835\udc53\ud835\udc4e\ud835\udc59\ud835\udc60\ud835\udc52, \ud835\udc62\ud835\udc5b\ud835\udc50\ud835\udc52\ud835\udc5f\ud835\udc61\ud835\udc4e\ud835\udc56\ud835\udc5b}, indicating whether \ud835\udc36\ncan be logically inferred from \ud835\udc43. In step-based\ndata augmentation, we extend the representation to\ninclude a solution \ud835\udc46 = {\ud835\udc46\u2081, \ud835\udc46\u2082, ..., \ud835\udc46\u2098}, where\n\ud835\udc46 consists of reasoning steps that derive the con-\nclusion from the premises. This process can be\nabstracted as a directed acyclic graph (DAG). Typi-\ncal logical reasoning datasets only provide labels.\nTherefore, we construct \ud835\udc46 ourselves. The specific\nconstruction of \ud835\udc46 will be detailed in Sec. 4.2."}, {"title": "Method", "content": "In this section, we introduce condition order aug-\nmentation in Sec. 4.1 and answer order augmenta-\ntion in Sec. 4.2. The framework is shown in Fig.\n2.\n4.1\nCondition Order Augmentation\nDue to the commutativity of premises, swapping\nindependent premises results in the same solution.\nHence, we perturb the order of premises, enabling\nmodels to learn the logical equivalence of condition\nreordering.\n4.1.1 Shuffling the Order of Premises\nGiven a logical reasoning dataset \ud835\udc37c =\n{\ud835\udc43, \ud835\udc36, \ud835\udc3f}, we first extract the premise set \ud835\udc43 =\n{\ud835\udc43\u2081, \ud835\udc43\u2082, ..., \ud835\udc43\u2099}. To generate augmented data, we\napply a random permutation \ud835\udf0e to the premise set \ud835\udc43,\nproducing a new ordered premise set \ud835\udc43 ran. Specif-\nically:\n\ud835\udc43 ran = {\ud835\udc43\ud835\udf0e(1), \ud835\udc43\ud835\udf0e(2),..., \ud835\udc43\ud835\udf0e(\ud835\udc5b)}\nFor example, if the original order is\n[\ud835\udc43\u2081, \ud835\udc43\u2082, \ud835\udc43\u2083, \ud835\udc43\u2084, . . ., \ud835\udc43\u2099], after applying the\npermutation \ud835\udf0e, the new order might be\n[\ud835\udc43\u2083, \ud835\udc43\u2084, \ud835\udc43\u2081, \ud835\udc43\u2099, ..., \ud835\udc43\u2082, . . .]."}, {"title": "Leveraging LLMs for Logical Reasoning Solutions", "content": "4.2.1\nSince logical reasoning datasets typically provide\nonly a single label (e.g., true/false) without a Chain-\nof-Thought (CoT) reasoning process, we generate\ndetailed step-by-step reasoning solutions to bridge\nthis gap (Xu et al., 2024). We use LLMs\u00b9 for this\nprocess. As shown in Fig. 3, the methodology\nconsists of three main steps: (1) For datasets with-\nout First-Order Logic (FOL) expressions, We ex-\ntract their premises and conclusion and convert\nthem into the corresponding FOL representations.\n(2) The FOL-augmented premises, along with the\nground truth labels, are fed into the model, prompt-\ning it to generate a step-by-step solution. Each\nstep must clarify its purpose and reasoning, leading\nto a final conclusion. (3) The generated solutions\nare then reprocessed by the model to extract the\npremise indices and prerequisite step indices used\nin each reasoning step.\n4.2.2 Constructing the Step Dependency DAG\nAfter obtaining the logical reasoning solutions,\nthe current data can be represented as \ud835\udc37s =\n{\ud835\udc43, \ud835\udc36, \ud835\udc3f, \ud835\udc46}, where \ud835\udc46 = {\ud835\udc46\u2081, \ud835\udc46\u2082, ..., \ud835\udc46\u2098} con-\nsists of reasoning steps. We represent \ud835\udc46 as a\ndirected acyclic graph (DAG), denoted as \ud835\udc3a =\n(\ud835\udc49, \ud835\udc38), where \ud835\udc49 = {\ud835\udc46\u2081, \ud835\udc46\u2082, . . ., \ud835\udc46\u2098} is the set of\nreasoning steps, and \ud835\udc38 \u2282 \ud835\udc49 \u00d7 \ud835\udc49 is the set of di-\nrected edges. An edge (\ud835\udc46i, \ud835\udc46j) indicates that step\n\ud835\udc46j depends on the result of step \ud835\udc46i.\nEach step \ud835\udc46i is represented as a tuple:\n\ud835\udc46i = (\ud835\udc3a\ud835\udc5c\ud835\udc4e\ud835\udc59i, \ud835\udc43used,(i), \ud835\udc46used(i), \ud835\udc45\ud835\udc52\ud835\udc60\ud835\udc62\ud835\udc59\ud835\udc61i)\nwhere \ud835\udc3a\ud835\udc5c\ud835\udc4e\ud835\udc59i describes the goal of the step, \ud835\udc43used(i)\nrepresents the directly used atomic premises,\n\ud835\udc46used(i) \u2282 \ud835\udc49 denotes the prerequisite steps that must\nbe executed before \ud835\udc46i, and \ud835\udc45\ud835\udc52\ud835\udc60\ud835\udc62\ud835\udc59\ud835\udc61i is the result\nderived from the execution of \ud835\udc46i.\n4.2.3 Generating Augmented Solution\nSequences\nA valid reasoning process must maintain all logical\ndependencies between steps while allowing flexi-\nbility in ordering interchangeable steps. We define\nthe dependency constraints as follows:\n\u2022 A step \ud835\udc46i is \ud835\udc56\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc5d\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc52\ud835\udc5b\ud835\udc61 if \ud835\udc46used(i) = \u2205 (i.e., it\nhas no prerequisite steps)."}, {"title": "Generating Augmented Data", "content": "4.1.2\nWe denote the original dataset as \ud835\udc37c = {\ud835\udc43, \ud835\udc36, \ud835\udc3f}\nand the augmented dataset as \ud835\udc37'c = {\ud835\udc43ran, \ud835\udc36, \ud835\udc3f},\nwhere \ud835\udc43ran represents the randomly shuffled\npremises. The transformation from \ud835\udc37c to \ud835\udc37'c in-\nvolves perturbing the order of the premises while\nkeeping the conclusion \ud835\udc36 and the label \ud835\udc3f un-\nchanged. Each original data sample generates \ud835\udc58\ninstances of condition order augmentation, leading\nto an augmented dataset \ud835\udc37 containing \ud835\udc58 \u00d7 |\ud835\udc37c|\ninstances, where |\ud835\udc37c| is the size of the original\ndataset."}, {"title": "Answer order Augmentation", "content": "4.2\nDue to the commutativity of reasoning steps, we\nperturb the order of solution steps to help mod-\nels learn the logical equivalence of the reasoning\nprocess. However, reasoning steps often have de-\npendencies, where the execution of one step may\nrely on the result of another. To address this, we\npropose a method for identifying valid step reorder-\nings that ensures these dependencies are preserved."}, {"title": "Experiments", "content": "We conduct experiments to evaluate the effective-\nness of our method, focusing on overall perfor-\nmance, training efficiency, and generalization capa-\nbility.\n5.1 Experiment Setup\nDatasets (1) FOLIO (Han et al., 2022) is a natu-\nral language inference dataset annotated with first-\norder logic (FOL), consisting of 1001 training sam-\nples and 231 test samples. (2) RuleTaker (Clark\net al., 2020) requires models to determine whether\na conclusion is entailed by a set of premises, cover-\ning various reasoning difficulties. Due to its large\nscale, we uniformly sample 1000 training and 1000\ntest instances across different difficulty levels. (3)\nLogicNLI (Tian et al., 2021) is an NLI-style dataset\nthat isolates first-order logic reasoning from com-\nmonsense inference for precise logical evaluation.\nSimilarly, we sample 1000 instances from both its\ntraining and test sets.\nModels We conduct experiments on Llama-\n3-8B-Instruct (AI@Meta, 2024), Llama-2-13B-\nChat (Touvron et al., 2023) and Mistral-7B-Instruct-\nv0.3 (Jiang et al., 2023), evaluating model per-\nformance under five training conditions: (1) Un-\ntrained: The original model without any additional\ntraining. (2) Vanilla SFT: Models fine-tuned only\non the original training set, i.e., \ud835\udc37c = {\ud835\udc43, \ud835\udc36, \ud835\udc3f}.\n(3) Vanilla SFT + Condition Shuffling: Models\ntrained on both the original dataset and an aug-\nmented version with shuffled condition orders, i.e.,\n\ud835\udc37c = {\ud835\udc43, \ud835\udc36, \ud835\udc3f} and \ud835\udc37'c = {\ud835\udc43ran, \ud835\udc36, \ud835\udc3f}. (4)\nSFT with COT: Models fine-tuned with training\ndata that includes Chain-of-Thought (COT) reason-\ning steps, i.e., \ud835\udc37s = {\ud835\udc43, \ud835\udc36, \ud835\udc3f, \ud835\udc46}. (5) SFT with\nCOT + Answer Steps Shuffling: A model trained\nwith COT data and additional augmentations with\nshuffled reasoning steps, i.e., \ud835\udc37s = {\ud835\udc43, \ud835\udc36, \ud835\udc3f, \ud835\udc46}\nand \ud835\udc37's = {\ud835\udc43, \ud835\udc36, \ud835\udc3f, \ud835\udc46ran}.\nAll models are trained using full fine-tuning,\nwith a 1:1 mix of ShareGPT (Chiang et al., 2023) in\neach dataset. Training is conducted on four A100\nGPUs for four epochs. Each model is trained ex-\nclusively on a single dataset, with augmentation\napplied only to that dataset, and evaluated on the\ncorresponding test set without cross-dataset mix-\ning.\nWe applied random shuffling to the premises\nof each training sample to generate one condition-\naugmented instance. Due to some data containing\nmultiple valid step orderings, we randomly selected\none transformation from each original data to con-\ntrol the data size. Additionally, we shuffled the\npremises in the test set to create a condition shuffled\ntest set, enabling better evaluation of the model's\nperformance across different logical orders. The\ndata sizes for both the training and test sets are\nprovided in Tab. 1.\n5.2 Overall Performance\nTab. 2 shows that our method effectively im-\nproves model reasoning performance. Compared"}, {"title": "Training Efficiency", "content": "5.2.1\nTo ensure fairness and exclude the effect of in-\ncreased data size, we test the accuracy of check-\npoints with the same number of training steps, com-\nparing the performance of condition order augmen-"}, {"title": "Analysis", "content": "6\n6.1\nCondition Augmentation with Varying\nShuffling Degrees\nTo investigate the effects of premise order trans-\nformations, we divide the Kendall tau distance \ud835\udf0f\nbetween different premise orders and the original\norder into 10 groups, each spanning a 0.2 range\nwithin [-1,1). A \ud835\udf0f value of 1 indicates forward\norder, -1 indicates a complete reversal, and 0 rep-\nresents a more uniform shuffling. Additionally,\nrandom shuffle means that \ud835\udf0f values from the entire\nrange may be included. We conduct experiments\non RuleTaker using different \ud835\udf0f values for condition-\nbased data augmentation.\nTo explore the importance of using DAG for step\ndependencies in step augmentation, we use the An-\nswer Step Shuffled data from Tab. 1 as a baseline.\nWe randomly shuffle the steps in the original COT\nprocess and assess its performance to evaluate the\nimpact of random step reordering without DAG\ndependencies.\nAs shown in Tab. 4, not utilizing DAG dependen-\ncies leads to a performance drop compared to DAG-\nbased augmentation. The decline is particularly\nsevere on FOLIO, where LLaMA3-8B-Instruct and\nLLaMA2-13B-Chat show a drop of 7.64% and\n4.68% in the shuffled test. In contrast, Ruletaker\nand LogicNLI experience a smaller decline.\nTo explore the underlying cause of this phe-\nnomenon, we investigate the degree of dependency\nbetween steps in the step dependency DAG. We\nintroduce the Topological Freedom Index (TFI).\nThis metric measures how loosely or tightly con-\nnected a DAG is, and it is calculated as follows:\n\ud835\udc47\ud835\udc39\ud835\udc3c =\n\ud835\udc41\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f \ud835\udc5c\ud835\udc53 \ud835\udc63\ud835\udc4e\ud835\udc59\ud835\udc56\ud835\udc51 \ud835\udc60\ud835\udc52\ud835\udc5e\ud835\udc62\ud835\udc52\ud835\udc5b\ud835\udc50\ud835\udc52\ud835\udc60\n\ud835\udc39\ud835\udc4e\ud835\udc50\ud835\udc61\ud835\udc5c\ud835\udc5f\ud835\udc56\ud835\udc4e\ud835\udc59 \ud835\udc5c\ud835\udc53 \ud835\udc61\u210e\ud835\udc52 \ud835\udc5b\ud835\udc62\ud835\udc5a\ud835\udc4f\ud835\udc52\ud835\udc5f \ud835\udc5c\ud835\udc53 \ud835\udc60\ud835\udc61\ud835\udc52\ud835\udc5d\ud835\udc60\nNumber of valid sequences represents the num-\nber of valid topological orderings that respect the\ndependency constraints within the DAG. Factorial\nof the number of steps corresponds the number of"}, {"title": "Conclusion", "content": "7\nIn this paper, we systematically study how to en-\nhance the logical reasoning ability of LLMs by\naddressing their limitations in reasoning order vari-\nations. We introduce an order-centric data aug-\nmentation framework based on the principles of\nindependency and commutativity in logical reason-\ning. Our method involves shuffling independent\npremises to introduce order variations and con-\nstructing directed acyclic graphs (DAGs) to identify\nvalid step reorderings while preserving logical de-\npendency. Extensive experiments across multiple\nlogical reasoning benchmarks demonstrate that our\nmethod significantly improves LLMs' reasoning\nperformance and their adaptability to diverse logi-\ncal structures."}, {"title": "Limitations", "content": "8\nOur work primarily focuses on logical commutativ-\nity within propositional reasoning tasks. However,\nthis property extends beyond these tasks. It is also\nprevalent in many other reasoning scenarios, such\nas mathematical problems and other logic-based\ntasks. This remains an area for future exploration.\nAdditionally, while we have explored the impact\nof condition order and answer order augmentations\non model performance, how to further integrate\nand refine these augmentations for better logical\nreasoning capability is still an open question. We\nbelieve our exploration will provide valuable in-\nsights for future work on logical equivalence and\ncommutativity in reasoning."}, {"title": "Appendix", "content": "A\nA.1 Details of Generating Solutions\nIn Sec. 4.2, We discuss how to generate step-by-\nstep solutions through \ud835\udc37 = {\ud835\udc43, \ud835\udc36, \ud835\udc3f}. Specifi-\ncally, we follow these steps:\n(1) For datasets that do not have first-order logic\n(FOL) expressions, such as RuleTaker and Log-\nicNLI, we extract their premises and conclusions,\nand use GPT-40-mini with prompts as shown in\nTab. 6 to convert them into corresponding FOL\nrepresentations. FOLIO, on the other hand, already\nincludes FOL expressions, so no conversion is re-\nquired.\n(2) The FOL-enhanced premises and ground\ntruth labels are input into the model, prompting\nit to generate step-by-step solutions. As shown\nin the prompt in Tab. 7, we add two domain-\nspecific examples from each dataset to the prompt,\nrequiring the model to clearly define the purpose\nand reasoning for each step, eventually leading\nto the final conclusion. The Task prompt speci-\nfies the possible values for the label. Specifically,\nin FOLIO, the label values are {\ud835\udc47\ud835\udc5f\ud835\udc62\ud835\udc52, \ud835\udc39\ud835\udc4e\ud835\udc59\ud835\udc60\ud835\udc52, \ud835\udc48\ud835\udc5b-\n\ud835\udc58\ud835\udc5b\ud835\udc5c\ud835\udc64\ud835\udc5b}, in RuleTaker they are {\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc4e\ud835\udc56\ud835\udc59\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61, \ud835\udc5b\ud835\udc5c\ud835\udc61\n\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc4e\ud835\udc56\ud835\udc59\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61}, and in LogicNLI they are {\ud835\udc52\ud835\udc5b\ud835\udc61\ud835\udc4e\ud835\udc56\ud835\udc59\ud835\udc5a\ud835\udc52\ud835\udc5b\ud835\udc61,\n\ud835\udc5b\ud835\udc52\ud835\udc62\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc59, \ud835\udc60\ud835\udc52\ud835\udc59\ud835\udc53_\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc51\ud835\udc56\ud835\udc50\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b, \ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc61\ud835\udc5f\ud835\udc4e\ud835\udc51\ud835\udc56\ud835\udc50\ud835\udc61\ud835\udc56\ud835\udc5c\ud835\udc5b}.\n(3) The model then reprocesses the generated\nsolutions, using prompts like the one shown in Tab.\n8, to extract the premise indices and premise step\nindices used in each reasoning step.\nA.2 Kendall Tau Distance\nIn our study, we investigate the effects of premise\norder transformations by using the Kendall tau dis-\ntance \ud835\udf0f. This coefficient measures the correlation\nbetween two ordered lists, providing a quantitative\nway to assess how much one order differs from an-\nother. We user to categorize various permutations\nof premise orders and assess their impact on model\nperformance.\nThe Kendall tau coefficient \ud835\udf0f is calculated as\nfollows:\n\ud835\udf0f =\n\ud835\udc36 \u2212 \ud835\udc37\n(\ud835\udc5b\n2)\nwhere \ud835\udc36 is the number of concordant pairs (pairs\nof items that are in the same relative order in both\nlists), and \ud835\udc37 is the number of discordant pairs\n(pairs that are in opposite order in both lists). The\ntotal number of possible pairs is (\ud835\udc5b2), where n is\nthe number of items being compared."}]}