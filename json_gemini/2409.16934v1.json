{"title": "Investigating OCR-Sensitive Neurons to Improve Entity Recognition in Historical Documents", "authors": ["Emanuela Boros", "Maud Ehrmann"], "abstract": "This paper investigates the presence of OCR-sensitive neurons within the Transformer architecture and their influence on named entity recognition (NER) performance on historical documents. By analysing neuron activation patterns in response to clean and noisy text inputs, we identify and then neutralise OCR-sensitive neurons to improve model performance. Based on two open access large language models (Llama2 and Mistral), experiments demonstrate the existence of OCR-sensitive regions and show improvements in NER performance on historical newspapers and classical commentaries, highlighting the potential of targeted neuron modulation to improve models' performance on noisy text.", "sections": [{"title": "1 Introduction", "content": "Context and Motivation. The ability to accurately process and extract information from historical documents is essential for the computational analysis and study of digitised archives. Over the last decade, numerous projects have emerged to mine the rich information contained in unstructured texts obtained via optical character recognition (OCR), aiming notably to support exploration and discovery [16,19], enable computational analysis [49,37], and improve cultural heritage data availability and curation [43,42,10]. While these efforts are promising and to a large extent already successful, they face a recurring challenge, namely the variable and often mediocre quality of OCR transcriptions. Misrecognised characters and words, sometimes affecting entire sections of text, severely impact the performance of downstream processes [53], including language modelling [51] and named entity processing [34,26,22,18]. Whatever the task, the document type and the language, OCR noise is a pervasive issue that undermines the robustness of deep neural language models, which are affected by even slightly perturbed input [20,38].\nVarious approaches have been and are being developed to mitigate OCR noise. These include improving transcription accuracy [41], devising post-correction techniques [29,8] and increasing the resilience of models to corrupted input. In addressing the latter, approaches have focused on adapting either the model architecture or"}, {"title": "2 Discovering OCR-sensitive Layers and Neurons", "content": "Our approach is twofold: first, we try to identify regions of the network affected by noise by focusing on whole representations. Second, we closely examine the behaviour of individual neurons. Both experiments share the same setup, which we present first.\n2.1 Experimental Setup\nModels. This study focuses on the decoder-only Transformer architecture and is based on two pre-trained large language models (LLM), Llama2 and Mistral. Released by Meta AI, Llama2 is a series of foundation models trained on 2 trillion tokens from a diverse mix of publicly available sources [52]. Although Wikipedia is part of the pre-training data, the language distribution is extremely imbalanced, with approximately 90% of the material in English. Compared to its predecessor, Llama2 has not only been trained on more data, but also features a doubled context length and grouped-query attention. We use Llama2-7B2. In order to base our observations on more than one model and to strengthen the findings of this study, we also experiment with Mistral, specifically Mistral-7B3. This model is based on a similar architecture to Llama2 and integrates grouped-query and sliding window attention [30]. Little information is published about its training data, except that it has been trained on several languages, with a focus on French, German, Spanish and Italian. Mistral outperforms Llama2 on several benchmarks.\nNoise Augmented Token Dataset. For both representation-level and neuron-level experiments, we need the same input with varying levels of OCR noise. To this end, we build a fairly simple dataset composed of unique tokens, which are then replicated three times with different OCR noise levels. As the basis for correct, non-noisy text, we use the corrected version of French historical newspapers of the Common Corpus\u2074, from which we randomly select 2,447 (up to 400MB) documents. The text is tokenised, POS-tagged, and, by selecting only verbs and nouns, a set of 158,513 unique correct tokens is created. These tokens are then altered by introducing character-level distortions typical of OCR engine errors, such as substituting similar-looking characters or omitting characters altogether. The error simulation is performed using the NLPAug library [35] and is applied three times to each token with different parameters, resulting in pairs of (token_correct, token_altered) with different OCR noise levels, as follows:\nlow: insertion of one character alteration, e.g. (editorial, editor1al), producing altered variants within 0.8-1.0 Levenshtein similarity;\naverage: insertion of 2 to 5 character alterations, e.g. (editorial, ed1tur1al) (0.6-0.8 Levenshtein similarity);\nhigh: insertion of 3 to 10 character alteration, e.g. (editorial, eo1t0r1al) (0-0.6 Levenshtein similarity).\nThis generation method was favoured over using real OCR output as it allows for easier control of the noise level. The result is a multi-level noise augmented token"}, {"title": "2.2 Detecting Layer Regions Sensitive to OCR Noise", "content": "Our initial focus is on studying full vector representations to determine whether certain regions of the model are sensitive to OCR noise5.\nNetwork Structure. Llama2 and Mistral are based on the same architecture, which consists of an embedding layer, followed by 32 decoder blocks, and a final output layer [54]. Each decoder block includes a self-attention layer and a feed-forward neural network implemented as a multi-layer perceptron (MLP), both preceded by normalisation and followed by residual connections. The MLP layers consist of two fully connected layers with a non-linear activation in between: the first layer projects representations to a higher dimensional space (from 4,096 to 11,008), thereby enriching the feature sets by expanding the dimension of the hidden states [3], and the second projects the activation back to the original dimensions. Because they apply non-linear transformations to hidden states, MLP layers are essential to learning complex patterns and have been shown to act as memories encoding knowledge [12,24].\nExperiment. We focus on the MLP up-projection layers within each decoder block, examining their behaviour when fed with correct tokens compared with their counterparts with high, average and low levels of OCR noise. To measure the similarity or dissimilarity between two layers, we use the linear centered kernel alignment (CKA) similarity index [32]. CKA is specifically designed to compare internal representations of neural networks based on layer activations, both within a single network and across different networks. Invariant to orthogonal transformations and scaling, CKA is particularly helpful in neural network interpretability and analysis as it allows to understand how different input variables, network architectures, or even training datasets influence internal representations of models. For two representations, a high CKA value (close to 1) indicates that they are very similar, while a low CKA value (close to 0) reveals activation variability, indicating dissimilarity and suggesting that the layers or models process information differently.\nIn this experiment, each token and its three altered versions are fed (forward pass) through each up-projection layer of the 32 decoders in our LLMs, and the CKA value is computed on the obtained activations (CKA(layer_activations(token_correct), layer_activations(token_altered))). This process provides, for each up-projection layers, a measure of how similarly the layer responds to a correct token compared to the three altered versions.\nResults. Figure 1 shows the CKA values between correct and low | average|high OCR noise-altered input tokens for each of the 32 layers. Specifically, a given CKA value point at a given layer corresponds to the CKA between the activation of that layer in response to a correct token and the activation of the same layer in response to one"}, {"title": "2.3 Identifying OCR-sensitive Neurons", "content": "We now focus on finding neurons that react to OCR noise by using their activation differences.\nNeurons. In the layers of the MLP neural network, it is possible to study the activation of neurons by examining the transformations that occur through the layers, particularly before and after the application of the non-linear activation function. More specifically, the functioning of neurons can be described by considering how an MLP processes a normalised hidden state vector $x \\in \\mathbb{R}^{d_{model}}$, that is to say: $MLP(x) = W_{out}\\sigma(W_{in}x + b_{in}) + b_{out}$ where $W_{out}$ and $W_{in}$ are matrices in $\\mathbb{R}^{d_{model} \\times d_{mlp}}$and $\\mathbb{R}^{d_{mlp} \\times d_{model}}$, respectively, that are learned over time, and $b_{in}$ and $b_{out}$ are the learned bias terms. The function $\\sigma$ is a point-wise non-linear activation function, corresponding to SwiGLU in the models analysed here [48]. The activation of a specific neuron $j$ for various inputs $x$ can be examined using $\\sigma(w_j^T x + b)$. Similarly, the activations of a neuron can be examined by looking at row $j$ of $W_{in}$ or the transpose of $W_{out}$.\nExperiment. Similarly to the previous experiment, we provide each MLP layer with pairs of correct and altered tokens. Instead of examining layer activations via CKA, we focus on differences in neuron activations to identify neurons that significantly and consistently \u201cdeviate\" from others when exposed to OCR noise. First, a neuron $n$ in an MLP layer is considered activated if its activation values $\\sigma(x)$ exceed zero [40,50]. Then, it is defined as OCR-sensitive if the difference between its activations in response to correct tokens and its activations in response to altered tokens is significantly higher than that of other neurons in the same layer when responding to the same inputs. The activation difference $act\\_diff_n$ of neuron $n$ is the absolute difference between the mean of its activations for correct and altered tokens:\n$diffn = |\\frac{1}{N}\\sum_{i=1}^{N}correct\\_token(s) - \\frac{1}{N}\\sum_{i=1}^{N}altered\\_token(s)|$.\nThis difference is significant if it is greater than the sum of the mean activation differences $diff$ and the standard deviation of the activation differences $diff$ for all other neurons in the layer: $diff_n > \\overline{diff} + \\sigma_{diff}$. We compute the activation differences of neurons in each layer across all pairs and identify those with significant differences. Neurons showing significant activation differences in more than 90% of the pairs are classified as OCR-sensitive neurons. This conservative threshold helps identify neurons that consistently react strongly to OCR noise across altered tokens.\nResults. The number of OCR-sensitive neurons for each layer in both models is shown in Figure 1 (purple shaded area), together with the CKA values. We observe that the theoretical inverse relationship between a low CKA value and a higher number of neurons classified as OCR-sensitive holds true, albeit with some exceptions. If this negative relationship is clear for the early layers (2-10) of Mistral, for layers 12 and some later layers (24-26) of both models, the observation points for Llama 2 are less consistent. This shows that while these approaches appear to be effective in assessing the presence of OCR-sensitive layers and neurons, it remains difficult to obtain unambiguous observations on which to base clear-cut conclusions for large models. Nevertheless, both the CKA values and the number of OCR-sensitive neurons show that there are groups of layers and neurons that are consistently sensitive to OCR noise, suggesting that it may"}, {"title": "3 Neuron Ablation for NER on Historical Documents", "content": "We investigate the influence of OCR-sensitive neurons on LLM's performance in NER on historical documents through a systematic neuron ablation study.\nData. We use the French parts of the HIPE-2020 (hipe2020) and of the Ajax Multi-Commentary (ajmc) NER benchmarks [21,44]. Hipe2020 consists of historical newspapers from 19C-20C, while ajmc includes 19C scholarly commentaries on Sophocles' Ajax. Both datasets contain OCR noise.\nExperiments. Both models are fine-tuned using the law-rank adaptation strategy [27]6. To establish a baseline, models are fine-tuned on the training sets without neuron ablation. Each fine-tuning process is repeated five times and the results on test sets are averaged to account for possible variances between runs. Baseline F1-scores are: for hipe2020, 50.72 \u00b1 0.07 (Llama2) and 52.88 \u00b1 0.07 (Mistral) and, for ajmc, 33.63 \u00b1 0.05 (Llama2) and 46.29 \u00b1 0.06 (Mistral). Next, we neutralise neurons of the MLP up-projection layers by changing their activation values during the forward pass. For each neuron n, activations are adjusted by introducing a mask M containing a neutralising factor a, with M[n] = a if n is a neuron to neutralise and M[n] = 1 otherwise. The adjusted hidden states h' are then given by $h' = h \\odot M$, where h represents the original hidden states and $\\odot$ denotes element-wise multiplication."}, {"title": "4 Conclusions", "content": "This study provides a preliminary assessment of OCR-sensitive layers and neurons in Transformer models, highlighting their impact on model performance in the presence of OCR. We identified critical layer regions within Llama 2 and Mistral that exhibit heightened sensitivity to OCR noise. Optimising these layers (0-2, 11-13, 23-28) could enhance NER performance, particularly in the final layers. However, the distinct improvements observed across different datasets (hipe2020 and a jmc) underscore the need for noise level-specific adaptations. Future work will focus on specific types of OCR errors and their distributions in the training data. Additionally, expanding the analysis to other models and datasets can provide a broader perspective on OCR sensitivity and performance improvements in various contexts."}, {"title": "Limitations", "content": "Despite the promising results, our study has several limitations that should be addressed in future work. First, the process of identifying OCR-sensitive neurons is highly dependent on the specific datasets and noise levels used in the experiments. While we used a diverse set of OCR noise levels, we focused only on two datasets in French, thus the findings may not generalise across different OCR systems or text corpora. Not only, but we considered only nouns and verbs for this preliminary experiments, while probably missing activations on other parts of speech. Thus, we leave this for our future work, where we will explore more datasets and OCR noise conditions to validate the generalisability of the identified sensitive neurons. Second, the method of neuron neutralisation, which involves scaling down neuron activations, may oversimplify the complex dynamics of neuron interactions within the model. While this approach provides insights into the role of specific neurons, it does not account for potential compensatory mechanisms that might occur when certain neurons are deactivated. More sophisticated techniques, such as neuron editing or neuron replacement strategies, could provide a deeper understanding of the role of these neurons. Finally, while we showed improvements in model performance by neutralising OCR-sensitive neurons, the practical implementation of these techniques in real-world systems remains challenging. We would still need to address the computational overhead and complexity of dynamically identifying and neutralising these neurons."}]}