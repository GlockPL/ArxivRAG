{"title": "SCALING VIRTUAL WORLD WITH DELTA-ENGINE", "authors": ["Hongqiu Wu", "Zekai Xu", "Tianyang Xu", "Jiale Hong", "Weiqi Wu", "Hai Zhao", "Min Zhang", "Zhezhi He"], "abstract": "In this paper, we focus on virtual world, a cyberspace where people can live in. An ideal virtual world shares great similarity with our real world. One of the crucial aspects is its evolving nature, reflected by the individuals' capacity to grow and thereby influence the objective world. Such dynamics is unpredictable and beyond the reach of existing systems. For this, we propose a special engine called Delta-Engine to drive this virtual world. A associates the world's evolution to the engine's expansion. A delta-engine consists of a base engine and a neural proxy. Given an observation, the proxy generates new code based on the base engine through the process of incremental prediction.\nThis paper presents a full-stack introduction to the delta-engine. The key fea-ture of the delta-engine is its scalability to unknown elements within the world, Technically, it derives from the prefect co-work of the neural proxy and the base engine, and the alignment with high-quality data. We an engine-oriented fine-tuning method that embeds the base engine into the proxy. We then discuss a human-AI collaborative design process to produce novel and interesting data ef-ficiently. Eventually, we propose three evaluation principles to comprehensively assess the performance of a delta engine: naive evaluation, incremental evalua-tion, and adversarial evaluation.", "sections": [{"title": "1 INTRODUCTION", "content": "The virtual world, often more idealistic than reality, presenting a utopian escape and an alternative life, has captivated human imagination for decades. Films like \"Free Guy\" and \"Ready Player One\" have presented this vision for us. In this paper, we pay attention to the dynamic nature of a world. In the real world, individuals keep growing and being stronger, by exercising, learning, and experiencing. The world is also shaped by individuals and keeps changing. In the virtual world, our idea is to allow the users to fully personalize their own growing curves, becoming \u201cthemselves\u201d.\nWe model this dynamic nature of such a virtual world system as the scaling of its back engine. We propose Delta-Engine. Its codebase will become more and more along with the process of individuals growing new talents. A delta-engine is a neural engine (Wu et al., 2024a), which collaborates two units: a base engine and a neural proxy. The base engine programs the prototype of the world; the proxy expands it by producing new code on the base engine, triggered by specific observations, e.g. special signals in the world, high-level instructions by users. Recent LLMs (large language models) (Brown et al., 2020; OpenAI, 2023; Touvron et al., 2023; Jiang et al., 2023) are great candidates which can process diverse inputs, e.g. languages, scripts, images. Delta-engines can be a wide range of modules of the virtual world, e.g. growing individuals, malleable surroundings, a series of magical items. This paper unfolds from the following aspects.\n\u00a7 2: The first concern is the efficiency of the LLM in face of limitless scaling of the delta-engine. Therefore, we ensure that the LLM proxy always generates the incremental code snippets following the current engine, for either adding new features or overloading existing methods.\n\u00a7 3: The delta-engine relies on the alignment process using high-quality data to enhance the co-work of two units; more importantly, to inspire the LLM's generaliziblity, which emphasizes the novelty and interestingness of the data. We present a collaborative design process with both humans and AI."}, {"title": "2 DELTA-ENGINE", "content": "Base Engine A base engine is the initial state of the delta-engine. It depicts the prototype of the virtual world, typically a mass of objects with associated methods, as well as basic utilities.\nAs any object (e.g. environment, individual) grows, which means it acquires new properties. Its associated engine is given new code. For example, considering an individual born with a blank template. Its initial engine may be several lines of code supporting its only walking ability. As it grows stronger and learns to run and even fly, its codebase is updated to reflect these new abilities.\nNeural Proxy The proxy is a neural wrapper around the base engine. In our paper, it is a large language model, particularly one of those specialized LLMs that are additionally pre-trained on code, e.g. CodeLLaMA (Rozi\u00e8re et al., 2023), CodeGemma (Mesnard et al., 2024). These models can be instructed by a wide range of inputs, e.g. a piece of natural language, structured scripts like json, and images, the way that the code expanding process is triggered.\nWe denote all the objects and methods of the engine at some moment as a state. The LLM proxy seeks to predict the new state moment-by-moment. We introduce an efficient manner to model this process.\nIncremental Prediction Given an observation, a delta-engine seeks to predict the incremental value (e.g. inheritance, overloading, adding) based on the current engine state. This idea can be formalized as:\n$\\Delta y_t = F(Y_{t-1}, X_t; E)$ (1)\nwhere F is the proxy model, & is the base engine, xt is the observation, Yt-1 is the current engine state, and Ayt is the incremental value of Yt-1 and Yt. Yt can be obtained by merging Ayt and Yt\u22121:\nYt = m(Ayt, Yt-1) (2)"}, {"title": null, "content": "where m is the merge function. Specifically, m can be determined by the base engine, and therefore the process of incremental prediction takes the following form:\n$\\mathbf{Y}_{t} = F\\left(\\mathbf{Y}_{t-1}, X_t, \\mathcal{E}\\right)$. (3)\nFor the initial state when yo is none, it reduces to y\u2081 = F(x1,E).\nFigure 2 illustrates the template we use for incremental prediction in Delta-Pok\u00e9mom. We provide the role script, a structured paragraph the details the pokemon role, and the current implementation of the role, as the reference for the model. What follows is a high-level instruction indicating the direction of the role's growth. Based on these three blocks, the model programs the incremental value of the role as the response. Specifically in the response, we develop a decorator \"Increment\u201d to merge the new code into the engine."}, {"title": "3 HUMAN-AI CO-DESIGN", "content": "The delta-engine transfers the development process of the system to a hybrid of programming and data engineering. Beyond programming the base engine and user interfaces, developers are tasked to design a sufficient amount of data to align the LLM proxy. This process is labor-intensive. Even experienced professional designers can't always come up with fresh and innovative ideas. A recent philosophy is to synthesize pseudo data using powerful LLM as generators (Wang et al., 2023; Wu et al., 2024b). However, there can be significant and unknown biases within the synthetic data constructed by LLMs themselves (Shumailov et al., 2023), making the resultant model vulnerable. Instead, in our project, we adopt a human-AI co-design process, where LLMs are harnessed as assistant designers, working collaboratively with human designers. We seek to integrate human factors into the synthetic distribution to mitigate bias risks and produce high-quality data.\nWe first discuss two major demands.\nBeing Novel Players are highly creative. For example, they won't be satisfied with similar content for long; they keep discovering novel and imaginative elements in the virtual world. Therefore, it is"}, {"title": "3.1 PROTOTYPES ENHANCED IMAGINATION", "content": "We conjecture that LLMs lack or even do not have imagination; their creative outputs are still guided by the prompts they receive. However, the naive prompts e.g. \"please use your imagination\", \"forget who you are\" fail to offer useful clues to inspire LLM's imagination. To address this, we propose to leverage an explicit prototype, a specific entity described in a paragraph, as the imaginative foundation. It facilitates the generation of novel content by providing a concrete reference point.\nFigure 3 illustrates the idea. For example, we seek to use Tyrannosaurus as the prototype to design a pokemon. We begin with retrieving the description about the Tyrannosaurus from Wikipedia. The result is a new pokemon characterized by stronger bite power, aligning with the notable feature of Tyrannosaurus. In addition to real-world entities, prototypes can also come from fictional sources. In our project, we retrieve animals from Wikipedia, e.g. Tyrannosaurus, Smilodon, Sperm Whale; also retrieve the virtual creatures from \u201cMonster Hunter\"\u00b9, a popular action video game. The right side of Figure 3 is an example. The distinction between two sources is that the super-natural creatures in Monster Hunter typically lead to higher uniqueness of the roles designed upon them. However, these roles may go too far, increasing the likelihood of grammatical errors within the generated code, then being filtered out by the evaluator, which we will discuss below.\""}, {"title": "3.2 TAGS OF INTEREST", "content": "Quantifying interestingness has always been a challenging task (Nelson & Mateas, 2007; Todd et al., 2024). It is highly subjective and lacks a precise definition, making it difficult to devise instructions for LLMs to assess. In this paper, we hypothesize that interestingness is an accumulation of potential"}, {"title": "3.3 DESIGN PROCESS", "content": "Figure 5 illustrates our co-design process with both human and AI (LLM) participation. We initialize the sampling pool with 20 manually-crafted seed instances of script-code pairs. The human designer first determines the prototype and prompts the LLM designer to generate a novel role script based on the prototype. Then, the LLM designer is prompted to program the role script into role code. More specifically, we sample 5 instances from the sampling pool to augment the LLM's coding, while refraining from intervening its designing. A key observation is that the in-context instances of other role scripts may bias the effect of the prototype, incurring low creativity of the response. On the other hand, in-context instances act as useful references for the LLM to generate high-quality role code since the programming step does not rely on creativity but accuracy. Specifically, we sample the most relevant roles by calculating the similarity of the role scripts and offer the top 5 instances of script-code pairs to the LLM. The LLM designer we use is either one of GPT4 and Claude3.\nThe newly designed script-code pair will be sent to the evaluator, a combination of both rule-based and manual strategies. First, code that fails to compile (e.g. due to grammatical errors) or introduces new methods yet without calling them will be filtered out. Second, code that fails to pass the interestingness evaluator mentioned above will also be discarded. After the rule-based filtering, the"}, {"title": null, "content": "human designer makes the final check on the script and code. Eventually, we place the new instance into the sampling pool ready for the next cycle of design.\nAn important trick is that, we replace the third-party LLM designers (GPT4/Claude3) with one of the trained proxy model in the middle of the design process. We find these LLMs, while powerful, still struggle with the nuanced requirements of the programming problem in our project, providing low-accuracy responses, while the aligned one can tackle much better.\nThe co-design process is slower compared to the fully automated process with solely LLM designers. On the flip side, the incorporation of AI greatly accelerates the creative process of human designers. In Figure 5, we observe that human designers mainly act as a prototype designer and a joint evaluator to refine the eventual samples."}, {"title": "4 TRAINING", "content": "Engine-oriented Fine-tuning A large virtual world contains a complicated base engine. Its codebase can be huge. It is troublesome for the LLM proxy to get access to the entire & to evaluate F(Yt-1, xt, E). Rather than retrieval-based augmentation (Lewis et al., 2020; Gao et al., 2023; Zhang et al., 2024; Cai et al., 2022), which samples the most relevant code pieces from the base engine F(Yt-1, xt, Et), we treat the base engine & as a latent variable of the LLM proxy, denoted as F\u025b. Eq. 3 can thus be yt = Fe(Yt-1,xt).\nWe evaluate F\u025b by further fine-tuning the model. Specifically, we convert the base engine into an instruction-tuning dataset. Each of the samples corresponds to one or two methods in the engine. The instruction is presented in natural language. It explains the target method and queries the model to enhance it with new functionality. This process can be done manually or by strong LLMs like GPT4 and Claude3. The LLM proxy is then fine-tuned on these engine-correlated instructions to learn the alignment between the base engine's implementation and natural language, integrating the entire E into the model.\nRephrasing In addition, rephrasing is a useful trick (Liu et al., 2024; Wu et al., 2024a). We rephrase the descriptions within the role scripts for a number of times to make them diverse.\nThe training process of our delta-engine can be summarized as a two-stage process, beginning with engine-oriented fine-tuning followed by supervised fine-tuning on the rephrased version of the data we create in \u00a7 3."}, {"title": "5 EVALUATION", "content": "In this section, we introduce three folds of evaluation to access the performance of delta-engines. The experimental results are reported in the next section."}, {"title": "5.1 NAIVE EVALUATION", "content": "The naive evaluation covers our basic attempt to measure correctness of the engine, particularly generalizability in face of novel scenarios. We prepare two sets of test data, corresponding to easy and hard. The easy-level data comprises 19 existing pokemons, all of which have appeared in official pokemon games. We sample them from the internet. This set of data is easier because the majority of the pokemons in the training data inevitably shares similarity with the existing ones. Their distributions are closer. On the other hand, we invite 10 volunteers to manually craft the hard-level set. All of them are not only experienced in playing pokemon games, but also have a wealth of experience with a wide range of games, greatly allowing them to design novel pokemon roles. Eventually, we obtain 14 original pokemon scripts. We program them and obtain the ground truth role code. From Table 1, we see that the number of grow-ups within the hard data is much more. The visualization of easy and hard dataset is previouly showed in Figure 4.\nWe report two scores.\n\u2022 Exe% We use Exe% to represent the success rate of executing the role code on top of the engine. Specifically, we randomly synthesize 100 roles as imaginary opponents and have the role under test to battle with them, choosing a random action each time. One success will be counted if all actions are executed successfully through all opponents.\n\u2022 Acc% We further verify the correctness of the role code. We use Acc% to represent the functional correctness, which is calculated among the successfully executed roles. The step is done by GPT4, which is prompted to compare two code snippets."}, {"title": "5.2 INCREMENTAL EVALUATION", "content": "A delta-engine is a continuous overlay on the base engine. A natural concern rises that how much of the content can be overlaid. It might be hindered by two potential factors. The first is the limit of the input length. A overly large engine state can surpass the length limit of the LLM proxy, incurring low-quality prediction. The second is LLMs' inherent limit in long-range capturing, especially when the input length is large.\nIn this evaluation, we continuously prompt the LLM proxy with incremental scripts and measure the performance of its response. Specially, we randomly sample the abilities and moves from existing database to make a \u201csuper patchwork\" pokemon, and use this script to prompt the delta-engine in the incremental prediction manner. This process is repeated for many times.\nEmpirically, the incremental evaluation can show us the idea of the number of grow-ups constructed in the training data, to ensure the inference quality of incremental prediction."}, {"title": "5.3 ADVERSARIAL EVALUATION", "content": "The third evaluation is very specialized for our domain. It is not normal for users to intentionally enters problematic or counter-common instructions because they won't obtain any useful help. However, this situation can be normal for players who seek fun from the games. It might be a special fun of entering provocative or strange inputs to the delta-engine to see what will happen. We thus introduce adversarial evaluation to measure the behavior of the delta-engine against those inputs. In the adversarial evaluation, the executable rate becomes the major metric because most of the queries cannot be completely materialized in the virtual world.\nThe adversarial evaluation set is manually crafted, too. Compared to the naive evaluation, we additionally invite 5 random persons. All of them are not familiar with pokemons and 1 of them even never plays games. As experienced players and newbies will give very different cases, the final evaluation set will be more comprehensive."}, {"title": "6 EXPERIMENT", "content": "We fine-tune CodeGemma-7b (Mesnard et al., 2024)3. CodeGemma is a code LLM that is additionally pre-trained on a large number of code corpora. We train the model using LoRA (Hu et al., 2022) with r = 8, a = 32, and learning rate/batch size 1.5e-4/4 for 5 epochs."}, {"title": "7 RELATED WORK", "content": "We're still working on the process of organizing all the relevant papers."}, {"title": "A DELTA-POK\u00c9MON", "content": "Delta-Pok\u00e9mon is a secondary game based on Pok\u00e9mon, only for research purposes. Players can craft our own pokemons by issuing natural language scripts and battle with others. As opposed to official games, here, each pokemon can possess more than two abilities and five different moves. Pokemons can acquire one new ability/move each time they grow.\nFurthermore, the styles of abilities and moves can be entirely different, too. For example, among our human-crafted pokemons, one is able to revive itself with 50% of HP upon being knocked out for the first time; ones summon unique field conditions. All of these can be portrayed by players' natural language descriptions.\nDespite its openness and freedom, the game remains simple in its battle format. So far, it supports one-one battle without switching and usage of items."}]}