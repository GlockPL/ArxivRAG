{"title": "Bridging Context Gaps: Enhancing Comprehension in Long-Form Social Conversations Through Contextualized Excerpts", "authors": ["Shrestha Mohanty", "Sarah Xuan", "Jacob Jobraeel", "Anurag Kumar", "Deb Roy", "Jad Kabbara"], "abstract": "We focus on enhancing comprehension in small-group recorded conversations, which serve as a medium to bring people together and provide a space for sharing personal stories and experiences on crucial social matters. One way to parse and convey information from these conversations is by sharing highlighted excerpts in subsequent conversations. This can help promote a collective understanding of relevant issues, by highlighting perspectives and experiences to other groups of people who might otherwise be unfamiliar with and thus unable to relate to these experiences. The primary challenge that arises then is that excerpts taken from one conversation and shared in another setting might be missing crucial context or key elements that were previously introduced in the original conversation. This problem is exacerbated when conversations become lengthier and richer in themes and shared experiences. To address this, we explore how Large Language Models (LLMs) can enrich these excerpts by providing socially relevant context. We present approaches for effective contextualization to improve comprehension, readability, and empathy. We show significant improvements in understanding, as assessed through subjective and objective evaluations. While LLMs can offer valuable context, they struggle with capturing key social aspects. We release the Human-annotated Salient Excerpts (HSE) dataset to support future work. Additionally, we show how context-enriched excerpts can provide more focused and comprehensive conversation summaries.", "sections": [{"title": "1 Introduction", "content": "In recent years, there has been a troubling rise in polarization, both on social media and even in public spaces in society, with these spaces being increasingly dominated by loud and extreme voices. Motivated by this reality, we focus on small-group conversations as a medium to bring people together, strengthen community building and understanding, and present people a space to share personal stories and experiences related to crucial matters that affect their daily lives. These conversations can be recorded (with consent) thus allowing the sharing of excerpts from one conversation in many other conversations. This can help in promoting a collective understanding of relevant issues, highlighting perspectives and experiences to other groups of people who might otherwise be unfamiliar with, and thus unable to relate to, these experiences.\nA key challenge here is that excerpts taken from one conversation and shared in another setting might be missing key elements or crucial context that was previously introduced in the original conversation, e.g., background information about the speaker, their intent, or key details about the story or perspective being shared. This could lead to misunderstandings or misinterpretation and could elicit negative reactions from the receiving side as they may not fully grasp the background that shapes the speaker's words. This issue is increasingly common in today's digital landscape, where missing context often fuels misunderstandings (Mauranen, 2006) and perpetuates false and harmful stereotypes that contribute to dehumanization (Roy, 2023). Moreover, this problem is exacerbated when, as in our case, conversations become longer and richer in themes and shared experiences.\nIn this work, we examine the role of highlighted salient excerpts and the influence of social factors in understanding long-form group conversations, spanning tens of thousands of words. We assess how well these excerpts can convey socially relevant information and explore the effectiveness of contextualizing excerpts to improve readability and overall understanding, a process we term effective contextualization of the excerpt. More specifically, we examine how Large Language Models (LLMs) can retrieve and synthesize additional information"}, {"title": "2 Related Work", "content": "Social dialogue: Social group conversations, in the context of our study, refer to discussions within small groups where participants share experiences, perspectives, and viewpoints on topics of communal relevance. These conversations are rich in social dynamics, often featuring personal stories, emotional expressions, and diverse perspectives. They have been recognized as valuable across various fields, offering insights into collective understanding, civic governance, and nuanced perspectives in the social sciences (Roy, 2023; Schroeder et al., 2024). Past work highlighted the importance of such dialogues in fostering better decision-making and legitimizing democratic outcomes. Dialogue networks (Roy, 2023) rely on such conversations among a small group of people to capture their perspectives on local issues and enable participation in civic and democratic processes. Deliberative polling has demonstrated the role of discourse in improving decision outcomes (Fishkin, 1997), while storytelling has been shown to enhance productive deliberation in forums (Ryfe, 2006). Sustained dialogue, as noted by (Saunders, 1999), plays a critical role in transforming relationships amidst deeply rooted conflicts. This body of work underscores the significance of social group conversations as a medium for understanding collective reasoning, resolving conflicts, and studying broader societal dynamics. These conversations can be lengthy, on average over an hour long (Schroeder et al., 2024) necessitating approaches to distill key points.\nSocially aware NLP models: Recent advances in NLP and LLMs have enabled the development of more socially aware models. Ziems et al. (2024) discuss the growing ability to create such models for computational social science problems. Several works (Flek, 2020; Hovy and Yang, 2021; Yang et al., 2024) emphasized the importance of understanding the relationship between language and social context, advocating for the development of socially aware NLP systems. Our work builds on these efforts by integrating attention mechanisms to better capture social factors within conversations.\nExtracting social dynamics and speaker characteristics in NLP: LLMs have been applied to understand both emotional undertones and social meaning in conversations, as well as to extract speaker characteristics. Dutt et al. (2024) use machine-generated rationales to deduce the emotional and social meaning behind conversational statements, while (Chae and Davidson, 2023) focuses on extracting social stances from online dialogue. Additionally, (Jurafsky et al., 2009) and (Broniatowski, 2012) presented methods for identifying the speaker's personality and identity from the text. We are inspired by these methods to explore the use of LLM-generated enriched contexts to enhance the understanding of both the speaker's identity and the social dynamics surrounding the conversation excerpt.\nHuman-in-the-loop for contextualization and synthesis: Human-in-the-loop methods have proven effective in refining LLM-generated content. (Jiang et al., 2024) involves human experts to improve the quality of LLM-generated content used to help in the understanding of complex legal concepts. Additionally, (Chen et al., 2023) illustrates how human-highlighted information can improve LLM-generated summaries while (Yao et al., 2023) shows enhanced domain-specific summarization by incorporating human edits into machine-generated outputs. In our work, we leverage human-identified salient excerpts and use LLMs to generate contextual information, improving comprehension of social conversations. Additionally, we focus on much longer, multi-party conversations."}, {"title": "3 Human-annotated Salient Excerpts Dataset (HSE)", "content": "To enable the salient excerpt-driven understanding of social group conversations, we create the Human-annotated Salient Excerpts Dataset (HSE)\u00b9. This dataset is built on top of the Fora dataset (Schroeder et al., 2024), which includes social group conversations organized by the non-"}, {"title": "4 Problem Setup: Effectively Contextualizing Excerpts", "content": "Understanding excerpts from long-form social group conversations could be non-trivial and time-consuming given their length. Our primary goal is to contextualize these excerpts to provide meaningful and useful information, which we term effective contextualization. We formalize the problem as follows:\nThe data consists of long-form group conversations $C = {C_1, C_2,...,C_n}$, where each $C_j$ is a conversation among K participants on some topic(s). For each $C_j$, a set of salient excerpts (in our case human-highlighted) is available, $E_j = {e_{j1}, e_{j2},...,e_{jm}}$, where $e_{jt}$ is a salient excerpt. For a given excerpt from a conversation, we aim to generate additional context so that the overall comprehensibility and understanding of the conversation are improved.\nFormally, $\u011b_{jl} = f(C_j, e_{jl})$ represents the context-enriched excerpt for $e_{jl}$. Here, f is an LLM that is used for extracting the relevant information and generating $\u011b_{jl}$. This process of generating the effective context for a given excerpt is referred to as effective contextualization.\nThe key questions here are: (1) What additional information should be sought for effective contextualization in a social group conversation? (2) How do we evaluate effective contextualization?"}, {"title": "4.1 Factors in Effective Contextualization", "content": "Our work is inspired by (Hovy and Yang, 2021) which uses linguistic frameworks such as systemic functional linguistics (Halliday and Matthiessen, 2013) and the Cooperative Principle (Grice, 1975), proposing factors for effective communication in social conversational settings. We focus on the Speaker Characteristics and Context factors to improve the understanding of excerpts and specifically emphasize the following factors to improve the comprehensibility and usefulness of excerpts:\n\u2022 Speaker characteristics: Demographic details (age, gender, ethnicity), educational, and occupational references, along with relevant personal or cultural experiences.\n\u2022 Speaker motivation: Understanding the reasons behind a speaker's statements, including the context of the questions or comments they respond to."}, {"title": "4.2 Evaluating Effective Contextualization", "content": "Once an effectively contextualized excerpt $\u011b_{ji}$ has been generated, we evaluate the effectiveness of this contextualization by evaluating how well $\u011b_{ji}$ improves the comprehension and informativeness through the additional information. We also evaluate the relevance and consistency of the generated excerpt $\u011b_{ji}$ with respect to the original excerpt $e_{jl}$ and the conversation $C_j$. The overall evaluation is done through subjective evaluations involving humans as well as through objective faithfulness analyses. The subjective evaluations are done across dimensions such as understandability, readability, completeness, and cohesiveness."}, {"title": "4.3 Implicit and Explicit Effective Contextualization", "content": "We utilize Large Language Models (LLMs) for the effective contextualization of conversation excerpts. For a given excerpt e from a conversation C, we use an LLM to generate a Context-Enriched Excerpt (CEE), using the surrounding contexts within C. We use two approaches:\n\u2022 $CEE_i(e)$ represents the excerpt obtained through implicit contextualization, where zero-shot capabilities of the LLM (Kojima et al., 2022) are leveraged to generate context without explicit instructions on social attributes.\n\u2022 $CEE_e(e)$ represents the excerpt obtained through explicit contextualization, where the LLM is guided by In-Context Learning (ICL) (Brown, 2020) and is explicitly instructed to incorporate specific social attributes from the conversation.\nIn both cases, the input consists of both the conversations and the excerpts. The LLM is tasked with gathering relevant information from the conversation, whether by focusing on explicit social attributes (in $CEE_e$) or by relying on inherent language patterns in the implicit case (in $CEE_i$). Prompts for both methods are provided in Appendix D.\nMore formally, $CEE_e(e_{jl}) = f_e(C_j, e_{jl})$ and $CEE_i(e_{jl}) = f_i(C_j, e_{jl})$ represent the explicit and implicit context-enriched excerpts for $e_{jl}$ respectively. $f_e$ corresponds to the LLM's generation with an explicit focus on social attributes, and $f_i$ corresponds to the zero-shot generation without explicit instructions."}, {"title": "5 Experimental Setup", "content": "We now describe the overall experimental setup and details of the evaluation approach. We investigate the effective contextualization of excerpts in the following three directions.\nCEE vs $CEE_i$: Our first empirical evaluation studies the difference in explicit vs implicit effective contextualization. More specifically, we conduct subjective evaluations to analyze and compare the excerpts and their context-enriched version ($CEE_e$ and $CEE_i$) across various dimensions such as understandability, readability, and cohesiveness (Table 1). The contextualization function f here is GPT-4 Omni (GPT4-0) (Achiam et al., 2023). The details of the evaluation process are described in the subsequent section.\nLLMs for contextualization: We next compare different LLMs for the task of effective contextualization. We compare 3 LLMs GPT-4 Omni (GPT4-o) (Achiam et al., 2023), Llama 3.1-70b (Dubey et al., 2024) and Claude Opus (Anthropic, 2024). Llama 3.1-70b is an open-source LLM whereas the other two are not. Due to cost considerations, we limit our experimentation on Claude and Llama to only explicit contextualization (as opposed to both implicit and explicit). This comparative analysis helps us evaluate the relative effectiveness of different state-of-the-art LLMs in generating meaningful and faithful context for conversation excerpts. Complete prompts and further details are provided in Appendix D.\nClarification through extrinsic knowledge: To further probe the efficacy of LLMs in generating context-enriched excerpts for social conversation, we investigate their ability to clarify uncommon terms and phrases which can further improve the generated excerpt. As part of the explicit contextualization method ($CEE_e$), we prompt the LLMs (Appendix D.3) to clarify any specialized terms or phrases that might not be common knowledge by requiring the LLM to provide additional explanations"}, {"title": "5.1 Evaluation", "content": "We conduct an evaluation of the enriched context for 90 annotated excerpts from the HSE dataset (Section 3) through a combination of subjective human assessments and objective faithfulness measures. We assessed the quality of the enriched excerpts produced by various models, focusing on dimensions such as faithfulness, text quality, and speaker perception.\nSubjective human evaluation: We recruited 75 human evaluators from Prolific with a 99-100% approval rating to evaluate the enriched contexts. Participants assessed the excerpts on textual quality (understandability, readability, redundancy, completeness, cohesiveness) and speaker perception (agreement with the speaker's point of view, perception of the speaker as honest or trustworthy, respect for the speaker, empathy for the speaker, the ability to see the speaker's point of view (POV)). This evaluation determined how well the enriched contexts convey the speaker's original message and their social perception.\nEach excerpt was rated by at least three evaluators. Quantitative data was collected using likert scale ratings [1-5], and qualitative insights were gathered through open-ended responses. Details of the survey and prompts are available in Appendix F.\nFaithfulness and objective metrics: To measure the consistency of the enriched context with the source conversation, we assess the faithfulness (Li et al., 2022) of the information extracted from the conversations and compare it with the annotated social attributes from the HSE dataset. We categorize the extracted attributes into short-response factors and long-response factors, based on the type and depth of the information being conveyed:\n\u2022 Short-response factors are brief, factual details like the speaker's name, gender, age, occupation, race, and economic status. These require minimal elaboration and can typically be conveyed in a few words.\n\u2022 Long-response factors involve more nuanced and context-rich information, such as the speaker's background, personal experiences, significant events, or locations. These require detailed explanations to capture complexity. For instance, locations could be specified at multiple levels (e.g., city, state, country), adding depth to the context, which makes them long-response factors."}, {"title": "6 Results and Discussion", "content": "6.1 Textual quality and Speaker Perception\nCEE vs $CEE_i$: A total of 90 annotated excerpts from the HSE dataset were used for this analysis, and each excerpt was rated by an average of 4-5 crowdsourced evaluators, resulting in 433 total responses. On average, each excerpt contained 128 words. The implicit contextualization ($CEE_i$) contexts have an average length of 267 words, while the enriched ($CEE_e$) contexts average around 55\n6.2 Qualitative Analysis of Responses\nBeyond the quantitative evaluation, the comments from the evaluators provided nuanced insights into how the inclusion of social attributes and background information influenced their perceptions. We provide some qualitative insights through these comments.\nEvaluators emphasized the value of background information such as the speaker's name and other contextual cues, which helped them connect more deeply with the speaker while preferring conciseness. This enhanced trustworthiness, empathy, and the overall utility of the contexts. One participant stated, \"Giving background information about the speaker gave it a personal touch and helped me empathize with the reader more.\u201d Another participant echoed this sentiment, saying that the $CEE_e$ context \"succinctly introduces [speaker name] as a high school student from Gardiner, Maine, sharing her thoughts on essential career skills such as collaboration, writing, and speaking.\"\nThe preference for $CEE_e$ was frequently attributed to its ability to offer a broader and more socially rich context without excessive detail. As noted earlier, $CEE_e$ produces considerably shorter enriched contexts and is yet preferred on factors such as readability and cohesiveness. One participant commented, \u201cI preferred the $CEE_e$ context because it offers a broader context for the excerpt, explaining the community's overall goals and how the speaker's concerns fit into those goals. This context makes the excerpt more meaningful and easier to understand.\u201d This underscores how $CEE_e$ successfully situates the excerpt within the larger conversation while maintaining conciseness, thus enhancing the overall understandability.\nWe also observe that disagreement with the speaker's POV could coexist with high ratings in empathy and the ability to understand the speaker's perspective. In several cases, evaluators rated their agreement with the speaker's perspective as low (1-2), while still giving high ratings (3-5) for empathy and related perception questions. The $CEE_e$ con-"}, {"title": "6.3 Clarification through Extrinsic Knowledge", "content": "As part of the explicit contextualization ($CEE_e$) process, we prompted the LLMs to clarify uncommon or specialized terms to enhance comprehensibility by incorporating extrinsic knowledge not directly mentioned in the conversation. This included providing additional context about locations (e.g., Cornwallis, Durham), explaining abbreviations (e.g., a school district acronym or a church's name), or elaborating on specialized terms not defined in the conversation (e.g., \"green roofs,\" \"heat island\"). Figure 2 illustrates the distribution of these categories. The \"Other\" category refers to terms that did not fall into the three prevalent categories. Terms in this category were largely names of other participants in the conversation. Of the 433 responses collected during the human evaluations, 128 responses included specifically flagged terms that required elaboration. The $CEE_e$ process successfully addressed only 55 of these instances, highlighting that LLMs still struggle to consistently identify and explain uncommon terms critical for tailoring content to the reader. However, when the models correctly defined terms using extrinsic knowledge, the evaluators found the elaboration helpful, particularly for specialized terms that could otherwise cause confusion, which helped in improving their understanding of the excerpt."}, {"title": "6.4 Faithfulness Analysis", "content": "It is important that the enriched contexts remain consistent with the original conversation. We evaluate the consistency of the enriched contexts with the original conversation through an objective faithfulness analysis, focusing on both short-response and long-response factors (Table 3). Both $CEE_e$ and $CEE_i$ performed well in extracting short-response information, such as the speaker's name, gender, and race, demonstrating high precision. The explicit contextualization ($CEE_e$) exhibited slightly higher recall rates, suggesting it was more adept at capturing a broader range of relevant details, aligning with its design to identify social attributes efficiently. However, the LLMs struggled with long-response factors, such as speaker background, shared personal experiences, and location context, likely due to the high variability and open-ended nature of these elements suggesting areas for future improvement. Despite this challenge, $CEE_i$ showed a stronger ability to extract fine-grained information, as it focused on highlighting key attributes within the conversation. Comparisons of GPT-40, Claude Opus, and Llama 3.1-70b for faithfulness are detailed in Appendix A. Claude Opus generated the most faithful responses."}, {"title": "7 Context-Enriched Excerpts for Enhanced Comprehension of Conversation", "content": "Intuitively, highlighted salient excerpts could be useful in highlighting key information or providing some form of a summary of the full conversation. To evaluate whether context-enriched excerpts lead to better summaries, we compare the effectiveness of these excerpts against direct summarization of the full conversations. Specifically, we generate and compare three types of summaries (using GPT-"}, {"title": "8 Conclusion", "content": "Long-form social group conversations often convey rich information but are challenging to process due to their length. Human-highlighted salient excerpts provide anchor points for understanding but can lack sufficient context, potentially leading to misunderstandings, particularly given the informal and personal nature of these conversations. To address this, we introduced a method using LLMs to augment salient excerpts with effective contextualization. This approach significantly improved comprehension, readability, and empathy by enriching excerpts with meaningful context. While LLMs show promise, challenges remain in capturing speaker background, personal experiences, contextualizing locations, and addressing unique terminology. We also demonstrated the utility of contextualized excerpts for summarizing lengthy conversations, with subjective evaluations highlighting their improved effectiveness. To support further research, we release the Human-annotated Salient Excerpts (HSE) dataset as a resource for advancing understanding and contextualization in social conversations."}, {"title": "9 Limitations", "content": "Consistency of generated context: LLMs can produce different results with each iteration. To ensure consistency, we set the model temperature to O for deterministic outputs and collected a large number of responses to accurately reflect the representative average rating from the population.\nFaithfulness evaluation: F1 scores are lower for open-ended questions due to their subjective nature, which complicates standardization. For instance, responses about a speaker's background varied among annotators, highlighting the challenge of standardizing such tasks. Further research is needed to develop better methods and metrics for measuring faithfulness, as noted by (Risch et al., 2021) and (Xu et al., 2024). Our final method for assessing faithfulness was chosen as other methods, such as Named Entity Recognition and entailment approaches (Goyal and Durrett, 2021; Manakul et al., 2023), were less suitable for our specific use case.\nNumber of excerpts: Due to cost constraints, we analyzed only 90 excerpts. Each required multiple ground truth annotators to get accurate ground truth data, making the process expensive."}, {"title": "10 Ethics Statement", "content": "Code of Conduct The informed consent of all survey participants and annotators was obtained before participation. This study received approval from the Institutional Review Board (IRB) at our university, and participants were compensated at a rate above the minimum wage for the state of Massachusetts.\nPrivacy of Models: We are aware of the privacy concerns associated with releasing information to LLM models for analysis. We used GPT and Claude via APIs, and both OpenAI and Anthropic have stated that data sent to the API would not be used for training (OpenAI; Anthropic). As a note, the Fora dataset (Schroeder et al., 2024) upon which we build our HSE dataset involves conversation data that has received the proper consent to be publicly released and underwent anonymization to further preserve the privacy of the conversation participants."}]}