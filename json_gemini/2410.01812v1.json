{"title": "From Text to Multimodality: Exploring the Evolution and Impact of Large Language Models in Medical Practice", "authors": ["Qian Niu", "Keyu Chen", "Ming Li", "Pohsun Feng", "Ziqian Bi", "Junyu Liu", "Benji Peng"], "abstract": "Large Language Models (LLMs) have rapidly evolved from text-based systems to multimodal platforms, significantly impacting various sectors including healthcare. This comprehensive review explores the progression of LLMs to Multimodal Large Language Models (MLLMs) and their growing influence in medical practice. We examine the current landscape of MLLMs in healthcare, analyzing their applications across clinical decision support, medical imaging, patient engagement, and research. The review highlights the unique capabilities of MLLMs in integrating diverse data types, such as text, images, and audio, to provide more comprehensive insights into patient health. We also address the challenges facing MLLM implementation, including data limitations, technical hurdles, and ethical considerations. By identifying key research gaps, this paper aims to guide future investigations in areas such as dataset development, modality alignment methods, and the establishment of ethical guidelines. As MLLMs continue to shape the future of healthcare, understanding their potential and limitations is crucial for their responsible and effective integration into medical practice.", "sections": [{"title": "I. INTRODUCTION", "content": "The landscape of healthcare is constantly evolving, driven by an unprecedented explosion of data. Electronic health records, medical imaging, genomic sequencing, and wearable sensors generate an overwhelming amount of information, exceeding human capacity for efficient analysis and interpretation [1]. This phenomenon presents both an opportunity and a challenge: ingesting this information can revolutionize healthcare, but doing so requires innovative tools capable of processing and synthesizing these diverse data streams. Artificial intelligence (AI) has emerged as a powerful force in addressing this challenge, with large language models (LLMs) at the forefront of this revolution.\nInitially, LLMs focused primarily on text-based tasks, demonstrating remarkable proficiency in understanding and generating human-like language [2]. However, the inherent multimodality of medicine, where clinical decisions often rely on the synthesis of information from diverse sources such as images, text, and genomics, necessitates more versatile models [3]. This need has given rise to Multimodal Large Language Models (MLLMs), a new generation of LLMs capable of processing and integrating information from various modalities. These advanced models potentially unlock a new era of precision medicine and personalized healthcare, offering a more comprehensive approach to medical data analysis and decision-making.\nA key strength of MLLMs is their ability to bridge the gap between unstructured and structured data, a particularly valuable feature in healthcare where information is often fragmented across different formats. For example, the REALM framework leverages LLMs to encode clinical notes and in-tegrates them with time-series EHR data, enhancing clinical predictions by incorporating external knowledge from knowl-edge graphs [4]. In a similar vein, the MedDr model [5] employs a diagnosis-guided bootstrapping strategy to build vision-language datasets, showcasing superior performance across various medical tasks through a retrieval-augmented diagnosis approach. These advancements underscore the po-tential of MLLMs to enhance data interoperability and extract meaningful insights from diverse sources, potentially revo-lutionizing how healthcare professionals access and utilize patient information.\nMLLMs show great potential for transforming healthcare by enabling a more comprehensive understanding of patient health, potentially leading to improved diagnostics, personal-ized treatment plans, and enhanced patient engagement [6]. For instance, these models could analyze a patient's medical history, imaging scans, and genetic data to provide more accurate diagnoses and predict disease risks, facilitating early intervention and tailored treatment strategies. In the field of medical imaging, the integration of LLMs has demonstrated significant progress. Research has shown the effectiveness of visual language models (VLMs), a subset of MLLMs, in ana-lyzing various biomedical images, including brain MRIs, blood cell images, and chest X-rays [7]. A notable example is the LlaVA-Rad model, a lightweight and open-source multimodal system that has achieved state-of-the-art results on standard radiology tasks. This model has surpassed larger counterparts in both performance and accessibility, making it particularly suitable for real-world clinical applications [6].\nMLLMs could also enhance communication between pa-tients and healthcare providers through interactive chatbots and virtual assistants, potentially improving patient engagement and healthcare accessibility [8]. The creation of chatbots like MedAide, which utilize optimized tiny-LLMs on edge devices, demonstrates the capacity of MLLMs to provide medical assistance in resource-limited settings and remote areas, addressing challenges in healthcare access [9]. However, developing reliable and trustworthy medical chatbots requires addressing critical issues such as accuracy, privacy protection, and bias mitigation to meet the high standards required for patient care and safety.\nOur review aims to offer an overview of the current state of MLLMs in medicine and healthcare. We will not only examine their architecture, capabilities, and limitations, but also explore potential applications across various medical domains. We will critically assess the challenges and research gaps impeding the widespread adoption of MLLMs in clinical settings, including data limitations, technical difficulties, and ethical considerations [10]. For example, the evaluation of LLMs in healthcare often relies on benchmarks that are usually unfit for real-world diagnostic frameworks and are likely vulnerable to data leakage [11], which indicates the need for standardized evaluation frameworks and comprehensive datasets that accurately reflect the clinical practice. By analyz-ing the current research landscape and identifying key areas for further development, this review seeks to guide the responsible and effective integration of MLLMs into healthcare. Our goal is to contribute to a brighter future where AI assists clinicians and enhances patient care, while addressing the unique challenges and requirements within the field. In order to provide a clear overview of the various applications and components of MLLMs in medicine, we present a taxonomy"}, {"title": "II. THE RISE OF MULTIMODAL LARGE LANGUAGE MODELS IN MEDICINE", "content": "Large language models (LLMs) represent a significant ad-vancement in artificial intelligence, demonstrating remarkable capabilities in comprehending and generating human-like text. Architecturally, they often rely on the Transformer network [36], a powerful neural network structure that excels at cap-turing long-range dependencies and contextual relationships within text. LLMs are initially trained on massive text corpora, a process known as pre-training, to develop a generalized understanding of language structure and patterns. This pre-training phase allows them to learn a wide range of linguistic features and relationships, making them adaptable to various downstream tasks.\nLLMs can be fine-tuned on smaller, task-specific datasets to further refine their performance in specific domains. For example, ClinicalT5 [37] demonstrates how a general-purpose LLM (T5) can be adapted for clinical text by fine-tuning it on the MIMIC-III dataset. This adaptation to the medical domain is crucial for addressing the unique challenges of medical language, including its specialized vocabulary and complex semantic relationships [38].\nDespite impressive capabilities, LLMs may face many limi-tations. One notable issue is \"hallucination\", where the model generates plausible but incorrect or nonsensical information, as highlighted in the study by Ziaei and Schmidgall [39]. Hallucination can be particularly problematic in healthcare, where accuracy and reliability are the top priorities [28], [40]. Additionally, biases present in the training data can propagate to the model's outputs, leading to unfair or discriminatory outcomes, as discussed in the paper by Reddy [41]. Addressing these biases requires careful data curation and model develop-ment strategies [42].\nIntegrating LLMs with other modalities, such as images and videos, results in MLLMs. MLLMs like GPT-4V [43], [44] and Gemini [45], [46] process and generate both text and visual information, which opens up new possibilities for medical applications. For example, MLLMs can be used to generate captions for medical images [47], answer visual ques-tions about medical images [48], and even assist in medical report generation [49]. On the other hand, MLLMs are still in their early stages, and these models often face challenges in terms of accuracy, reliability, and ethical considerations [50]. Further research is needed to fully explore the potential of MLLMs and address these challenges to enable their safe and effective deployment in clinical practice."}, {"title": "B. Multimodality in Medicine: Embracing the Rich Variety of Data", "content": "Medicine is inherently multimodal, as it involves many types of information beyond just written text. For example, when a patient comes in with a possible lung infection, their case might include several kinds of data: written information like their medical history and symptoms noted by doctors, images from chest X-rays, sound recordings of their breathing, and even genetic information to assess their personal risk. Combining these different types of information is important for getting a complete picture of a patient's health and more accurate and personalized medical care [51]. This is where multimodal models shine, because they are designed to process and integrate various types of data.\nWe have seen a surge in developing MLLMs capable of processing and integrating diverse medical data types [52]. The study by Tian et al. [53] exemplifies this trend, showcasing a Med-MLLM model that handles both visual and textual data for improved clinical decision-making, particularly in rare diseases and pandemics. MLLMs could revolutionize various medical practices. For instance, in radiology, MLLMs are being explored for generating comprehensive reports [54], assisting in diagnosis by analyzing both images and clinical notes [4], and facilitating visual search and querying within patient imaging history [55].\nMLLMs for more specialized medical tasks has also gained momentum. SkinGPT-4 is a system designed for dermato-logical diagnosis using both images and clinical data, which offers autonomous image evaluation and treatment recommen-dations [16]. Developing robust and reliable MLLMs requires overcoming many challenges. Large, diverse, and unbiased medical datasets across multiple modalities are crucial [48]. Accuracy, interpretability, explainability, interoperability, and ethics are important to be discussed before integrating into existing clinical workflows [35]."}, {"title": "C. Modality Alignment Methods: Bridging the Semantic Gap", "content": "Integrating different data types into LLMs is challenging, mainly because of differences in how each type represents information. Aligning these modalities is essential for LLMs to process and reason over multimodal data. Researchers are currently exploring several methods for addressing this issue, which can be grouped into four main categories.\n\nMultimodal Converters: These methods transform data from different modalities into a unified representation that LLMs can understand. For example, images might be converted into textual descriptions or embeddings before being fed into the LLM. This approach is seen in models like X-LLM [19], which treats modalities as foreign lan-guages and converts them to text, or LIFTED [56], which transforms modalities into natural language descriptions for improved clinical trial outcome prediction.\nMultimodal Perceivers: These methods directly enhance the LLMs' perception of multimodal data. A vision encoder can be integrated into the LLM architecture to enable it to directly process and understand images and texts. Med-Flamingo [15] incorporates a vision trans-former for medical image understanding. Similar ap-proaches can be seen in models like SkinGPT-4 [16], which combines a vision transformer with a LLM for dermatological diagnosis, and MedVersa [34], which uses a LLM as a learnable orchestrator to process both visual and linguistic information to interpret medical images.\nTools Assistance: These methods uses external tools for multimodalities. A knowledge graph can link concepts across modalities and provide additional context for the LLM. The study by Gao et al. [20] uses the Unified Medical Language System (UMLS) knowledge to en-hance diagnosis generation. A similar approach is used in BioLORD-2023 [21], which integrates LLMs with knowledge graphs to improve performance in semantic textual similarity, biomedical concept representation, and named entity linking.\nData-Driven Methods: These methods rely on large-scale multimodal datasets to train LLMs directly on multimodal tasks and often involves developing new architectures and training strategies so the modals can learn from different modalities simultaneously. Models like BiomedGPT [23] are trained on those diverse mul-timodal datasets. The recent open-source frameworks like Hippocrates [22] further facilitates this approach by providing access to training datasets, codebases, and evaluation protocols, encouraging further collaborative efforts.\nEach method has its own strengths and weaknesses. Multimodal converters are relatively simple but may lead to in-formation loss during conversion [57]. Multimodal perceivers can potentially capture richer relationships between modalities, but requires more complex architectures and training. Tools assistance uses existing knowledge bases and resources but may not be comprehensive or up-to-date. Data-driven methods can achieve high performance but require large and diverse datasets."}, {"title": "III. APPLICATIONS OF MLLMS IN MEDICINE", "content": "While MLLMs integrate diverse data modalities, offering a more comprehensive view of patient health and the ability to detect complex patterns for improved diagnosis, treatment personalization, and risk assessment [58], their development is still in the early stages. As a result, LLMs continue to dominate the field due to their maturity and established performance. This section introduces both LLMs and MLLMs, while emphasizing the promise of multimodal models."}, {"title": "A. Clinical Decision Support", "content": "Diagnosis and Treatment Recommendations: NYUTron is an LLM trained on clinical notes, for predicting patient outcomes with high accuracy [1]. PMC-LLaMA is a perfor-mant LLM for medical Q&A [59]\u2013[61]. Almanac is an LLM augmented with retrieval capabilities from curated medical resources and has significant improvements in factuality, com-pleteness, user preference, and safety for clinical decision-making [12]. Med-PaLM 2 is a specialized LLM for medicine, showcased superior performance on medical question an-swering and treatment recommendation tasks, significantly outperforming GPT-3.5 [2]. Med-PaLM M is a MLLM achiev-ing competitive performance on medical question answering, radiology report generation, etc. [62].\nPrognostic Prediction and Risk Stratification: Beyond diagnosis, LLMs have also shown promise in prognostic prediction and risk stratification. Researchers have tried to use LLMs for prognostic prediction in immunotherapy, achieving encouraging results in improving accuracy and facilitating early disease detection [13]. Studies have demonstrated the potential of LLMs and MLLMs to predict outcomes like mortality, length of stay, and readmission using structured EHR data, outperforming traditional machine learning models in few-shot settings. [26], [63] The Health-LLM, a LLM framework that has vision capability in the future integrating health reports and medical knowledge into LLMs, has also been proposed for enhanced disease prediction and personal-ized health management, showcasing its superior performance over existing systems [64].\nDespite the potentials, LLM and MLLMs face limitations in clinical decision support. Explainability and interpretabil-ity remain challenging, as their complex decision-making processes often lack transparency, hindering clinician trust and understanding [65]. Another concern is the potential for bias and unfairness due to inherent biases in MLLM training data, which can exacerbate healthcare disparities [66]. Extensive real-world validation in diverse clinical settings is crucial to ensure the effectiveness and safety of MLLMs before widespread adoption, addressing potential risks and unexpected outcomes [35].\nSeveral real-world case studies have demonstrated the po-tential of LLMs in clinical decision support. One study showed that an LLM optimized for diagnostic reasoning improved clin-icians' differential diagnosis accuracy on challenging medical cases [67]. Another study found that an LLM could accurately classify patient acuity levels in the emergency department, comparable to human physicians [31].\nThe performance of LLMs in clinical decision support is often evaluated using traditional metrics like accuracy, precision, recall, F1 score, and AUC [68]. Evaluating their effectiveness in this context requires moving beyond accu-racy and considering additional factors like interpretability, fairness, impact on clinical workflows, and user trust [69]. The development of standardized evaluation frameworks and benchmarks, such as CLUE and BenchHealth, is crucial for assessing the clinical performance and real-world applicability of LLMs [70]-[72]."}, {"title": "B. Medical Imaging", "content": "MLLMs are rapidly transforming medical imaging by of-fering potential for significant improvements in diagnosis, treatment planning, and patient care. These models, capable of processing and interpreting both textual and visual data, allow for a more comprehensive understanding of patient conditions. The MISS framework, proposed by Chen et al., treats med-ical Visual Question Answering (VQA) as a generative task, achieving excellent results with fewer multimodal datasets and demonstrating the advantages of generative models in practical applications [14]. A key strength of MLLMs lies in their ability to analyze medical images in conjunction with textual information such as radiology reports, clinical notes, and patient history. This integration of multimodal data allows for a more holistic and nuanced understanding of a patient's condition. Yildirim et al. demonstrate the value of this approach in radiology, arguing that integrating multimodal data can lead to a more comprehensive patient assessment [55]. MLLMs can automate the generation of radiology re-ports, potentially improving efficiency and accuracy while reducing radiologists' workload [54]. MLLMs also facilitate visual question answering, enabling clinicians to interact with medical images by asking specific questions and receiving relevant information from the model [73].\nDespite advantages, several limitations hinder the adoption of MLLMs in medical imaging. One major challenge is the reliance on high-quality, labeled data. Chen et al. address this issue in their work on the MISS framework, proposing solutions for leveraging limited datasets [14]. Interpreting complex medical images may requires specialized knowledge that current MLLMs do not fully possess. Mehandru et al. stress the need for high-fidelity simulations to accurately assess LLM performance in these complex scenarios [73]. Ethics about fairness in image interpretation is also crucial, as these models can perpetuate existing healthcare disparities if not carefully designed and evaluated. Yildirim et al. discuss these considerations in detail, focusing on design requirements for ethical AI use in radiology [55]."}, {"title": "C. Patient Engagement and Communication", "content": "MLLMs has changed patient engagement and communica-tion in healthcare. By integrating visual and textual modalities, MLLMs can create more personalized and interactive expe-riences, enhance patient education, facilitate communication, and provide tailored health recommendations.\nChatbots and Virtual Assistants: One of the most promis-ing applications of MLLMs in patient engagement is chatbots and virtual assistants. Traditional chatbots often rely on rule-based systems or simple ML models, with limited ability to understand complex queries and provide nuanced responses. MLLMs, however, can understand both text and images to create more natural and engaging conversations and result in improved patient experiences [26], [74], [75].\nPersonalized Health Recommendations: MLLMs can also be used to generate personalized health recommendations by analyzing patient data and medical knowledge. By integrating information from electronic health records, medical literature, and even patient-provided images, MLLMs provide tailored advice on lifestyle changes, medication adherence, etc [17].\nPatient Education: Educating patients improves health outcomes, but traditional methods often rely on static materials that may be difficult to understand or hard to be tailored towards individual needs. MLLMs generates personalized ed-ucational materials that are interactive, engaging, and easy to comprehend. The MedSumm framework, for example, utilizes LLMs and VLMs to generate detailed summaries of Hindi-English code-mixed medical queries, integrating visual aids to improve comprehension and support personalized medical care [18]."}, {"title": "D. Research and Development", "content": "MLLMs are offering promising solutions for literature re-view, drug discovery, clinical trial matching, and knowledge extraction. They have accelerated discoveries and enhanced knowledge extraction.\nLiterature Review and Knowledge Extraction: MLLMs are proving invaluable for navigating and synthesizing the vast and ever-growing body of biomedical literature. For instance, BioLORD-2023 integrates LLMs with knowledge graphs to achieve state-of-the-art performance in semantic textual similarity, concept representation, and named entity linking, enabling researchers to extract meaningful insights from complex medical texts [76], [77]. Similarly, MedMT5 tries to overcome language barriers in medical research by offering a robust, open-source, multilingual model for the medical domain, allowing for broader access to knowledge across different languages [32].\nDrug Discovery: While still in the early stages, MLLMs in drug discovery holds potential [78]. These models can analyze complex biological data, such as protein structures and drug interactions, to identify potential drug targets and accelerate the drug development process. By integrating information from various modalities, MLLMs can facilitate a more holistic understanding of disease mechanisms and drug interactions, potentially leading to the discovery of novel therapeutics and personalized medicine approaches.\nClinical Trial Matching: MLLMs can significantly im-prove the efficiency and accuracy of matching patients to suitable clinical trials. These models can analyze patient data, including medical history, genetic information, and imaging data, to identify potential eligibility criteria and match patients with ongoing trials. The ability of MLLMs to process and understand multimodal data can enhance the identification of eligible patients, leading to more effective recruitment and potentially faster clinical trial completion."}, {"title": "E. Administrative Tasks", "content": "Administrative tasks in healthcare is immense, which con-sumes significant time and resources that could be allocated to improve patient care. MLLMs offer transformative solu-tions by automating many of these tasks, which streamlines processes and improves the overall efficiency. MLLMs can handle tasks in documentation, billing, scheduling, etc. with remarkable speed and accuracy.\nAutomation of Documentation: MLLMs are transforming clinical documentation by automating tasks such as generating radiology reports [49] and transcribing medical conversations [79]. This automation can free up clinicians' time, allowing them to focus on patient care rather than paperwork. For example, one study explored the use of LLMs to simplify radi-ological reports for improved patient comprehension, finding that LLMs can effectively create more accessible reports while acknowledging the need for careful validation to mitigate potential inaccuracies [80].\nBilling and Scheduling: The application of MLLMs in billing and scheduling processes can significantly improve efficiency and reduce errors. These models can analyze pa-tient data, insurance information, and scheduling constraints to automate appointment scheduling, generate billing codes, and process insurance claims. By streamlining these tasks, MLLMs can reduce administrative burdens on healthcare staff and improve patient satisfaction by reducing wait times and simplifying billing processes."}, {"title": "IV. RESEARCH GAPS AND UNANSWERED QUESTIONS", "content": "While the potential of MLLMs in healthcare is significant, their development and evaluation are hindered by limitations in data resources. As highlighted by [62], medicine is inherently multimodal, with data spanning text, imaging, genomics, and more. Yet, current research faces several key challenges related to data:\nScarcity of Large-Scale, Multimodal Datasets: Existing biomedical datasets are often limited in size and scope, particularly those incorporating multiple modalities. Some researchers mitigates the lack of datasets with locally-aligned phrase grounding annotations for complex semantic modeling [81], while other researchers often propose new dataset when releasing new models [82]. The lack of large-scale datasets and their restricted size and scope is a major bottleneck for training robust and generalizable MLLMs for diverse medical tasks, especially when considering the need for datasets that reflect real-world clinical scenarios [64], [73].\nLack of Diversity and Representation: Existing datasets often lack diversity in terms of patient demographics, medical conditions, and healthcare settings. This issue is particularly relevant when considering the potential biases introduced [83]. Chen et al. emphasizes the challenges of few-shot learning in predicting rare disease areas due to limited data [13]. The lack of representation results in biased models that perform poorly on underrepresented populations or specific medical conditions. The reliance on single-language data, primarily English, is also a major concern [32], [84], [85]. It is difficult to access large amounts of domain-specific pre-training data for multiple languages, which makes it difficult to resolve linguistic bias [32].\nChallenges in Data Acquisition and Annotation: Obtain-ing high-quality, annotated multimodal data in healthcare is complex and resource-intensive. [86] notes that medical image annotation is costly and time-consuming, while [87] points to the lack of LLMs trained on medical records. This challenge is complicated by the need for expert annotations [61], [88]. The scarcity of medical image-text pairs for pre-training, due to privacy and cost issues, is another major issue [14]. Additionally, ensuring data privacy and obtaining informed consent are critical ethical considerations that require careful attention, particularly when dealing with sensitive medical information [35]."}, {"title": "B. Interdisciplinary Collaboration and Knowledge Integration", "content": "1) Fostering Effective Interdisciplinary Collaboration: The development of clinically relevant and useful MultiModal Large Language Models (MLLMs) requires bridging the gap between computer science and medicine. This interdisciplinary challenge calls for collaboration among medical professionals, data scientists, ethicists, and policymakers [65], [89], [90]. Such collaboration is essential to foster a shared understanding of both the technical capabilities of LLMs and the specific needs and constraints of the healthcare domain.\nAs LLMs become more integrated into healthcare work-flows, it is crucial to define the roles and responsibilities of various stakeholders [91]. [10] stresses the importance of incentivizing users, developers, providers, and regulators to prepare for the transformative role of LLMs in evidence-based sectors. This preparation includes establishing clear guidelines for accountability and oversight to ensure the safe and ethical use of these powerful tools in healthcare settings.\nClinicians' expertise is vital in guiding the development and evaluation of MLLMs to ensure they address real-world clinical needs [67], [92] illustrates how integrating an LLM optimized for diagnostic reasoning into a clinical workflow can improve diagnostic accuracy and comprehensiveness. How-ever, further research is needed to explore effective methods for incorporating clinicians' feedback and domain expertise throughout the model development process. This ongoing col-laboration between healthcare professionals and AI developers is key to creating MLLMs that can truly enhance patient care and clinical decision-making [56], [93]-[95]."}, {"title": "C. Enhancing Knowledge Integration", "content": "Beyond textual data, integrating domain-specific knowledge from sources like medical ontologies, knowledge graphs, and clinical guidelines is essential for the effectiveness of Large Language Models (LLMs) in complex medical tasks [81]. A Significant challenge in deploying LLMs for healthcare is addressing the issues of hallucinations and bias. LLMs can generate factually incorrect information and perpetuate biases present in their training data, which is particularly concerning in medical contexts. To tackle this problem, [96] introduces Med-HALT, a benchmark and dataset specifically designed to evaluate and mitigate hallucinations in medical LLMs. This tool emphasizes the critical need to address these issues for safer healthcare applications. Additionally, [97] underscores the importance of incorporating diverse real-world data and domain-specific knowledge to reduce factual inaccuracies and improve the model's grounding in real-world clinical scenarios.\nThe development of multilingual models represents another crucial area for advancement in medical LLMs. Most LLMs are trained primarily on English data, which limits their accessibility and applicability in diverse linguistic contexts. The potential of bilingual fine-tuned LLMs, such as Taiyi, can achieve superior performance on biomedical NLP tasks compared to general LLMs [98]. However, more research is needed to develop effective methods for creating and evaluat-ing multilingual medical LLMs that can cater to the needs of diverse patient populations [84], [99]."}, {"title": "D. Ethical and Regulatory Framework", "content": "The potential of MLLMs in healthcare is clear, but their deployment in real-world clinical settings presents significant ethical and regulatory challenges that demand careful consid-eration and further research.\nA key issue is the lack of clear guidelines and regulations specifically tailored for the development, deployment, and evaluation of LLMs in healthcare [87], [89]. Existing frame-works for medical AI may not fully address the unique ethical and legal implications of LLMs, especially in the context of multimodality. This gap in comprehensive guidance creates uncertainty for developers, clinicians, and regulators, which could impede responsible innovation and safe implementation.\nBias, fairness, and transparency are critical concerns in the use of LLMs in healthcare. Several studies highlight the potential for bias due to imbalances in training data [10], [13], [30]. This can result in unfair or inaccurate outcomes, partic-ularly for underrepresented or marginalized populations. The lack of transparency in LLM and MLLM training processes and decision-making mechanisms also raises concerns about accountability and trust [89]. Future research should focus on developing robust methods for identifying, quantifying, and mitigating biases, as well as ensuring transparency in their development and deployment.\nPatient privacy and data security are important when using LLMs in healthcare, as they involve processing sensitive patient information. Integrating multiple data modalities in MLLMs adds complexity to data management and raises ad-ditional privacy concerns [3]. Developing secure data storage, de-identification techniques, and access control mechanisms are crucial areas for future research. These challenges are particularly evident in specific medical fields, such as dentistry, where the use of LLMs requires robust safeguards to protect patient data [33], [100], [101].\nAdditional research is needed to define the optimal balance between human oversight and LLM autonomy, and establish-ing robust governance structures for LLMs in healthcare is essential to ensure accountability and public trust. A frame-work for evaluating LLMs in healthcare, including a gover-nance layer to ensure accountability and public confidence, has been proposed [41]. Clear guidelines and standards are needed for data governance, model development, performance evaluation, bias mitigation, and transparency. A collaborative approach involving developers, clinicians, ethicists, regulators, and patients is vital for establishing trust and promoting the responsible use of LLMs in healthcare [102]."}, {"title": "E. Technical Advancements Required", "content": "Realizing MLLMs' potential requires overcoming signifi-cant technical challenges. Existing research highlights several key areas where advancements are urgently needed. Advancing Modality Alignment Methods Current modality alignment methods, which aim to bridge the semantic gap between different data types like text and images, often struggle to capture the complex relationships and nuances present in medical data. This limitation hinders the ability of MLLMs to integrate information effectively and generate accurate and coherent outputs [7], [103]. Novel approaches are needed to create more robust and nuanced alignment methods that can capture the complex interdepen-dencies between different modalities, ensuring a more holistic understanding of medical data.\nUnveiling the \"Black Box\" The \"black box\" nature of large language models, where their internal workings and decision-making processes remain opaque, is a significant challenge for their deployment in high-stakes medical decisions. Clinicians need to understand the rationale behind AI-generated outputs to trust and validate their recommendations. The lack of transparency and inter-pretability in current LLMs hinders the ability to identify potential biases, errors, or inconsistencies in their reasoning. Further research to understand how LLMs make decisions, particularly in the context of assessing clinical acuity is needed [31]. Developing methods to make LLMs more transparent and interpretable is crucial for ensuring their safe and responsible use in medical applications [104], [105].\nEnhancing Generalization and Robustness Achieving reliable generalization and robustness across di-verse medical contexts, patient populations, and languages is crucial for the real-world deployment of MLLMs. Current models often struggle to generalize beyond their training data, which leads to inaccuracies and biases when applied to new populations or scenarios. The study by Zhang et al. demonstrates that while LLMs can effectively analyze data from specific medical specialties, their performance often decreases when applied to other areas [73]. Additional efforts should focus on developing methods to enhance the generalization ca-pabilities of MLLMs, ensuring that they perform consistently and reliably across different medical contexts, diverse patient populations, and various languages.\nDeveloping Efficient and Scalable Models The large size and computational demands of MLLMs pose a significant barrier to their deployment in resource-constrained settings. Training and deploying these models require substantial computational power, which can be pro-hibitively expensive [106], [107]. Developing efficient and scalable models that operates on less powerful devices or with reduced computational resources is crucial for making these technologies more accessible and equitable in healthcare."}, {"title": "V. FUTURE DIRECTIONS AND CONCLUSION", "content": "This review has emphasized the potential of LLMs and MLLMs to revolutionize medicine and healthcare. While showing early promise in areas like patient-trial matching [108], generating radiology reports [109], and assisting with clinical diagnostics [62], LLMs are still in their early stages. Significant research gaps remain and must be addressed to unlock their full potential and ensure safe, responsible, and equitable integration into clinical practice."}, {"title": "Data Augmentation and Access", "content": "Data Augmentation and Access: The scarcity of large-scale, high-quality, and diverse multimodal datasets is a major bottleneck [106]. This is especially true for languages other than English [32]. Future research shall focus on:\nDataset Creation and Curation: Developing large, well-annotated datasets encompassing diverse medical specialties, patient populations, and languages is crucial [85]. This includes incorporating visual data like medical images, alongside text from EHRs, clinical notes, and medical literature [110]. Datasets should represent real-world scenarios and address issues like imbalanced data [38]. The OmniMedVQA bench-mark provides a good example of a comprehensive dataset that addresses some of these challenges [48].\nPrivacy-Preserving Data Sharing: Investigating innovative methods like federated learning [33] to enable collaborative data sharing and model training while preserving patient privacy.\nStandardization and Interoperability: Developing stan-dardized data formats and categories to facilitate data integra-tion and interoperability across different healthcare systems and institutions. This is crucial for training models that can generalize well to new settings [111]."}, {"title": "Advanced Modality Alignment", "content": "A key area for future research is developing more so-phisticated methods for aligning different modalities. Future research could focus on developing novel architectures and training strategies that can better capture the complex relation-ships between different modalities, leading to more accurate and robust predictions [112]."}, {"title": "C. Interpretability and Explainability", "content": "A critical area for future research is enhancing the in-terpretability and explainability of MLLMs. This lack of transparency in current LLMS MLLMs can hinder trust and adoption in clinical settings. Traditional evaluation methods for MLLMs are usually insufficient for clinical settings, as they don't adequately assess their impact on real-world workflows [73]. Future research should focus on developing methods to make MLLM decision-making processes more transparent and understandable, such as generating human-readable explana-tions for their predictions or visualizing the processes that contribute to their decisions."}, {"title": "Robust Evaluation Frameworks", "content": "Robust and standardized evaluation frameworks becomes increasingly critical as MLLMs become increasingly sophis-ticated. Current evaluation methods often rely on limited datasets and metrics to non-clinical tasks, restricting the poten-tial to capture the full range of capabilities and biases [113]. To ensure the safe and effective of clinical MLLMs, future effort should spend on developing additional standardized benchmarks with closer clinical relevance."}, {"title": "E. Ethics and Compliance", "content": "The ethical implications of MLLMs in healthcare cannot be overstated. Its training data contain sensitive patient in-formation, raising concerns about privacy and data security [29]. Biased training data can lead to discriminatory outcomes, potentially exacerbating existing health disparities. Therefore, clear regulatory frameworks and guidelines are necessary to govern the development, deployment, and use of MLLMs in clinical settings [35]. Addressing these ethical and compliance challenges will be beneficial to establish trust and ensure the responsible use of MLLMs in healthcare."}]}