{"title": "UltraLightSqueezeNet: A Deep Learning Architecture for Malaria Classification with up to 54x fewer trainable parameters for resource constrained devices", "authors": ["Suresh Babu Nettur", "Shanthi Karpurapu", "Unnati Nettur", "Likhit Sagar Gajja", "Sravanthy Myneni", "Akhil Dusi", "Lalithya Posham"], "abstract": "Lightweight deep learning approaches for malaria detection have gained attention for their potential to enhance diagnostics in resource constrained environments. For our study, we selected SqueezeNet1.1 as it is one of the most popular lightweight architectures. SqueezeNet1.1 is a later version of SqueezeNet1.0 and is 2.4 times more computationally efficient than the original model. We proposed and implemented three ultra-lightweight architecture variants to SqueezeNet1.1 architecture, namely Variant 1 (one fire module), Variant 2 (two fire modules), and Variant 3 (four fire modules), which are even more compact than SqueezeNetV1.1 (eight fire modules). These models were implemented to evaluate the best performing variant that achieves superior computational efficiency without sacrificing accuracy in malaria blood cell classification. The models were trained and evaluated using the NIH Malaria dataset. We assessed each model's performance based on metrics including accuracy, recall, precision, F1-score, and Area Under the Curve (AUC). The results show that the SqueezeNet1.1 model achieves the highest performance across all metrics, with a classification accuracy of 97.12%. Variant 3 (four fire modules) offers a competitive alternative, delivering almost identical results (accuracy 96.55%) with a 6x reduction in computational overhead compared to SqueezeNet1.1. Variant 2 and Variant 1 perform slightly lower than Variant 3, with Variant 2 (two fire modules) reducing computational overhead by 28x, and Variant 1 (one fire module) achieving a 54x reduction in trainable parameters compared to SqueezeNet1.1. These findings demonstrate that our SqueezeNet1.1 architecture variants provide a flexible approach to malaria detection, enabling the selection of a variant that balances resource constraints and performance.", "sections": [{"title": "I. INTRODUCTION", "content": "Malaria, caused by the protozoan parasite Plasmodium falciparum, is a severe disease transmitted through the bites of infected mosquitoes. Symptoms include fever, headaches,\nnausea, and, in severe cases, seizures, jaundice, and coma,\nwhich can ultimately lead to death. In 2022, the World Health\nOrganization reported approximately 249 million malaria\ncases and 608,000 fatalities worldwide. The African region"}, {"title": "II. RELATED WORKS", "content": "Conventional machine learning (CML) methods have been\nwidely utilized for automated malaria diagnosis over the\nyears. However, since 2017, there has been a significant shift\ntoward deep learning (DL) methods, owing to their advanced\ncapabilities and improved effectiveness in malaria diagnosis\ncompared to CML for Malaria Classification."}, {"title": "A. DEEP LEARNING APPROACHES FOR MALARIA\nCLASSIFICATION", "content": "Previous studies have explored deep learning methods for\ndetecting malaria in blood cells, yielding promising results.\nDong et al. (2017) [21] investigated automated malaria\ndiagnosis using deep learning, leveraging a dataset of red\nblood cell images labeled by pathologists. They evaluated\nLeNet, AlexNet, and GoogLeNet, achieving classification\naccuracies over 95%, surpassing the 92% accuracy of the\nsupport vector machine (SVM). The study highlighted the\nability of deep learning methods to automatically extract\nfeatures, reducing reliance on human expertise [21]. Bibin et\nal. (2017) [22] utilized a deep belief network (DBN) to\nclassify 4,100 blood smear images as parasite or non-\nparasite, achieving an F-score of 89.66%, sensitivity of\n97.60% and specificity of 95.92%. This first application of\nDBNs for malaria detection outperformed state-of-the-art\nmethods using color and texture features with a pre-trained\nand fine-tuned DBN architecture. In a later study, Rajaraman\net al. (2018) [23] evaluated pre-trained CNNs for malaria\nparasite detection in blood smear images, showing promising\nresults for feature extraction and classification.\nVijayalakshmi et al. (2019) [24] developed a deep learning\nmodel combining VGG19 and Support Vector Machine\n(SVM) for identifying falciparum malaria parasites. Using\ntransfer learning, the model achieved 93.1% classification\naccuracy, outperforming state-of-the-art CNN models in\naccuracy, sensitivity, specificity, precision, and F-score. This\napproach highlights the potential of transfer learning in"}, {"title": "B. LIGHTWEIGHT DEEP LEARNING APPROACHES FOR\nMALARIA CLASSIFICATION", "content": "Lightweight deep learning models have become essential in\nmalaria classification due to their ability to operate\neffectively on devices with limited computational resources,\nsuch as mobile phones and embedded systems. Yang et al.\n[30] developed a smartphone app using deep learning for\ndetecting malaria parasites in thick smear images, combining\nIGMS for screening and CNN for classification. Their\nmethod, the first to apply deep learning on smartphones for\nthick smears, is evaluated at the patient level [30].\nShivaramakrishnan et al. (2017) [31] developed a\ncustomized deep learning model for malaria cell\nclassification, achieving 98.61% accuracy with lower\ncomplexity and computation time. Their model\noutperformed state-of-the-art methods, including pre-trained\nmodels, offering an effective tool for large-scale automated"}, {"title": "III. METHODOLOGY", "content": "Our proposed models for malaria detection adopt a well-\nstructured methodology, as shown in Figure 1, carefully\nfollowed to ensure reliability and precision at every stage. The\nprocess begins with the acquisition and preprocessing of\nmalaria cell images, where various image enhancement\ntechniques are applied to improve data quality and relevance\nfor analysis. Next, we implement the novel SqueezeNet1.1\narchitecture variants we introduced alongside the\nSqueezeNet1.1 architecture. These variants were developed to\nfurther reduce the complexity of the SqueezeNet1.1\narchitecture, aiming to lower computational resource\nrequirements while maintaining high performance. The\noriginal SqueezeNet1.1 architecture was modified with 1, 2,\nand 4 fire modules and was systematically explored to\noptimize the balance between accuracy and efficiency. The\nselected variant is then trained on the preprocessed image\ndataset. Following training, the model undergoes rigorous\nevaluation to assess its effectiveness in distinguishing between\nmalaria-infected and healthy cells. Finally, we compare the\nperformance of our novel SqueezeNet1.1 architecture variants\nto identify the most suitable one that ensures better\nperformance and resource efficient malaria detection."}, {"title": "1) Dataset", "content": "Our research leverages the malaria dataset [38] from Kaggle\n(sourced from NIH), a well-established and thoroughly\nannotated collection of microscopic images tailored for\nmalaria-related research. The dataset includes 27,558\nimages, divided equally between 13,779 images of\nuninfected cells and 13,779 images of parasitized red blood\ncells. We allocated 20% (5,512 images) for validation and\n80% (22,046 images) for training."}, {"title": "2) Image Processing", "content": "In this study, we implemented image processing techniques\nto enhance the detection of malaria-infected cells in\nmicroscopic images. The approach included resizing images\nto a target size of (130, 130), converting them from BGR to\nRGB color space, and normalizing pixel values to a range of\n[0, 1] for consistent input to the model. These preprocessing\nsteps standardize the images, ensuring consistency and\nimproving the model's ability to learn effectively.\nAdditionally, we applied image augmentation to increase the\ndiversity of the training dataset and improve the model's\ngeneralization. The augmentation process included rotation\n(\u00b110 degrees), zooming (up to 10%), width and height shifts\n(up to 10% of the image size), and flipping images both\nhorizontally and vertically. By introducing these\naugmentations, we effectively simulated variability in the\ndataset, making the model more robust to real-world\nscenarios."}, {"title": "3) SqueezeNet", "content": "Smaller CNN models, like SqueezeNet, offer significant\nadvantages, such as reduced computational overhead and\nfaster training, making them well-suited for deployment on\nresource-limited devices. Their scalability across various\nhardware environments and ability to simplify cloud-to-device\ndeployment enables efficient model downloads for\nautonomous systems. Additionally, they are ideal for memory-\nconstrained hardware like Field-Programmable Gate Arrays\n(FPGAs), which excel in parallel processing within resource-\nlimited contexts. Given these advantages, we selected\nSqueezeNet as the core architecture for our solution."}, {"title": "IV. RESULTS", "content": "We performed the experiments on Google Colab, utilizing\nCPU resources, 51 GB of RAM, and 225.8 GB of disk space.\nTo implement our proposed Squeezenet variant models, we\nutilized Python 3, along with essential libraries such as Scikit-\nLearn, Matplotlib, Keras, and TensorFlow. We have taken the\noriginal Squeezenet1.1 code from authors Forrest Iandola and\nChristopher Masch's Github repositories [52][53] and further\nmodified the code for proposed variants based on the details\nincluded in the methodology section. We have made our\nSqueezenet1.1 Variant's code available in the GitHub\nrepository [54]. We trained Squeezenet1.1 and variants with a\nmalaria training dataset of 22046 images.\nFor model compilation, we used the Adam optimizer with a\nlearning rate of 1e-4, paired with a categorical cross-entropy\nloss function. Training was carried out on augmented data for\n100 epochs with a batch size of 32. After the training we\ncompared the performance of the SqueezeNet1.1 variants and\nthe original SqueezeNet1.1 model, using a validation dataset\nof 5512 images, consisting of 2756 malaria infected and 2756\nnon-infected images. The models were evaluated based on\nvarious metrics outlined in the methodology section.\nSqueezeNet1.1. Variants 1 and 2 show moderate performance,\nwith Variant 1 lagging behind the most. Notably, all models\nexhibit well-aligned training and validation curves, indicating\nminimal overfitting and strong generalization capabilities\nacross the board. In our study, we observed a clear trend\ntoward model convergence across all SqueezeNet1.1 and\nvariants, as indicated by the stabilization of both training and\nvalidation loss over the course of training. The validation\naccuracy either closely matches or slightly exceeds the\ntraining accuracy in most cases, underscoring the model's\nability to maintain strong predictive performance while being\nwell-regularized and generalizing well to unseen data."}, {"title": "V. Discussions", "content": "Overall, the results of our study underscore the potential of\nSqueezeNet1.1variants as effective architectures for malaria\ndetection. From our comprehensive evaluation, the original\nSqueezeNet1.1 achieves slightly better results compared to\nVariant 3. However, this advantage is accompanied by\nincreased computational demands, as indicated by longer\ntraining and inference times and a larger model size. Among\nthe variants, Variant 3 proves to be a competitive alternative,\ndemonstrating an effective balance between classification\nperformance and computational efficiency. Variant 3 results\nclosely match SqueezeNet1.1 in accuracy and other evaluation\nmetrics. Variant 3's reduced model complexity and faster\ntraining and inference times make it particularly well-suited\nfor deployment in resource-constrained environments. This\nhighlights the potential of judicious architectural\nsimplifications to achieve both efficiency and strong\npredictive capability. Variants 1 and 2 showcase an explicit\ntrade-off between performance and computational demands.\nThese models, characterized by further reduced model size\nand complexity, demonstrate promising results but exhibit\nslightly lower accuracy and higher misclassification rates\ncompared to Variant 3 and SqueezeNet1.1. Nevertheless, their\nlightweight design and significantly faster processing times\nmake them attractive for very high resource-constrained\nenvironments. Despite their simplicity, both variants maintain\nsatisfactory performance, further validating the adaptability of\nSqueezeNet-based architectures to meet varying\ncomputational resource limitations.\nOur analysis further reveals that while increasing the number\nof fire modules in the architecture enhances classification\nperformance, the benefits plateau beyond a certain point. This\nobservation suggests diminishing returns with additional\ncomplexity, emphasizing the importance of balancing\nperformance gains against computational overhead. Variant 3\nexemplifies this balance by achieving competitive accuracy\nwith fewer fire modules, thereby offering a more efficient\nsolution without significant compromise in malaria\nclassification performance.\nIn comparison to other deep learning architectures, such as\nResNet-50 and VGG-16, our proposed ultra-lightweight\nvariants demonstrate remarkable computational efficiency.\nResNet-50 and VGG-16, though powerful, require\nsubstantially larger model sizes and longer training times,\nmaking them less practical for deployment in low-resource\nenvironments. In contrast, SqueezeNet1.1, a streamlined\nversion of SqueezeNet1.0, reduces computational demands by\n2.4x. The further optimizations in our proposed variants build\non this efficiency, providing even more compact and resource-\nfriendly solutions. Overall, the study highlights the\nadaptability of SqueezeNet1.1 and its variants for malaria\ndetection, offering a spectrum of solutions that cater to diverse\nresource constraints. These findings emphasize the\nimportance of tailoring model complexity to application-\nspecific requirements, ensuring an optimal balance between\ncomputational efficiency and predictive performance."}, {"title": "VI. Limitations", "content": "Despite the promising results, our study has limitations that\nneed to be addressed in future work. The model was trained\nand evaluated on a single dataset, the Kaggle Malaria dataset\n(sourced from NIH). While this dataset is comprehensive and"}, {"title": "VII. CONCLUSION", "content": "Our study demonstrates the computational effectiveness of\nour novel ultralight weight SqueezeNet1.1 architecture\nvariants for malaria detection. The results confirm that the\noriginal SqueezeNet1.1 model, with its 8 fire modules, offers\nthe best classification performance but at the cost of\nincreased computational demands. On the other hand,\nVariant 3 (with four fire modules) achieves nearly identical\naccuracy with a 6x reduction in computational overhead and\nsignificant reduction in training, inference time, making it a\nstrong candidate for deployment in environments with\nlimited computational resources. Variants 1(one fire module)\nand 2 (two fire modules), despite their slightly lower\nclassification accuracy, offer substantial reductions in\ncomputational overhead, with Variant 2 reducing\ncomputational demands by 28x and Variant 1 achieving a\n54x reduction compared to SqueezeNet1.1. Variants 1 and 2\noffer substantial reductions in training and inference time,\nmaking them suitable for scenarios with extreme resource\nconstraints.\nWhile these models show promising results in a binary\nclassification task, future research could extend them to\nmulti-class classification or other medical imaging tasks.\nAdditionally, improving the interpretability of these models\nthrough explainable AI techniques could enhance their\nclinical applicability. Overall, our study highlights the\npotential of our SqueezeNet1.1 architecture variants for\nmalaria detection, offering a flexible approach that allows for\nthe selection of the most suitable model based on resource\nconstraints, balancing complexity and performance."}]}