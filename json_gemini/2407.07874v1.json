{"title": "Toto: Time Series Optimized Transformer for Observability", "authors": ["Ben Cohen", "Emaad Khwaja", "Kan Wang", "Charles Masson", "Elise Ram\u00e9", "Youssef Doubli", "Othmane Abou-Amal"], "abstract": "This technical report describes the Time Series Optimized Transformer for Observability (Toto), a new state-of- the-art foundation model for time series forecasting developed by Datadog. In addition to advancing the state of the art on generalized time series benchmarks in domains such as electricity and weather, this model is the first general-purpose time series forecasting foundation model to be specifically tuned for observability metrics. Toto was trained on a dataset of one trillion time series data points \u2013 the largest among all currently published time series foundation models. Alongside publicly available time series datasets, 75% of the data used to train Toto consists of fully anonymous numerical metric data points from the Datadog platform. In our experiments, Toto outperforms existing time series foundation models on observability data. It does this while also excelling at general-purpose forecasting tasks, achieving state-of-the-art zero-shot performance on multiple open benchmark datasets.", "sections": [{"title": "Background", "content": "We present Toto, a groundbreaking time series forecasting foundation model developed by Datadog. Toto is specifically designed to handle the complexities of observability data, leveraging a state-of-the-art transformer architecture to deliver unparalleled accuracy and performance. Toto is trained on a massive dataset of diverse time series data, enabling it to excel in zero-shot predictions. This model is tailored to meet the demanding requirements of real-time analysis as well as compute and memory-efficient scalability to very large data volumes, providing robust solutions for high-frequency and high-dimensional data commonly encountered in observability metrics."}, {"title": "Observability data", "content": "The Datadog observability platform collects a vast array of metrics across multiple subdomains, crucial for monitoring and optimizing modern infrastructure and applications. These metrics include infrastructure data such as memory usage, CPU load, disk I/O, and network throughput, as well as application performance indicators like hit counts, error rates, and latency. Additionally, Datadog integrates specific metrics from numerous SaaS products, cloud services, open-source frameworks, and other third-party tools. The platform allows users to apply various time series models to proactively alert on anomalous behavior, leading to a reduction in time to detection (TTD) and time to resolution (TTR) of production incidents. The complexity and diversity of these metrics present significant challenges for time series forecasting. Observability data often requires high time resolution, down to seconds or minutes, and is typically sparse with many zero-inflated metrics. Moreover, these metrics can display extreme dynamic ranges and right-skewed distributions. The dynamic and non-stationary nature of the systems being monitored further complicates the forecasting task, necessitating advanced models that can adapt and perform under these conditions."}, {"title": "Traditional models", "content": "Historically, time series forecasting has relied on classical models such as ARIMA, exponential smoothing, and basic machine learning techniques. While foundational, these models necessitate individual training for each metric, presenting several limitations. The need to develop and maintain separate models for each metric impedes scalability, especially given the extensive range of metrics in observability data. Moreover, these models often fail to generalize across different types of metrics, leading to suboptimal performance on diverse datasets. Continuous retraining and tuning to adapt to evolving data patterns further increase the operational burden. This scaling limitation has hindered the adoption of deep learning-based methods for time series analysis, even as they show promise in terms of accuracy."}, {"title": "Foundation models", "content": "Large neural network-based generative models, often referred to as \"foundation models,\" have revolutionized time series forecasting by enabling accurate predictions on new data not seen during training, known as zero-shot prediction. This capability significantly reduces the need for constant retraining on each specific metric, thus saving considerable time and computational resources. Their architecture supports the parallel processing of vast data volumes, facilitating timely insights essential for maintaining system performance and reliability. Through pretraining on diverse datasets, generative models exhibit strong generalization across various types of time series data. This enhances their robustness and versatility, making them suitable for a wide range of applications. Zero-shot predictions are particularly attractive in the observability domain, where the limitations of traditional methods are felt very acutely. The most common use cases for time series"}, {"title": "Recent work", "content": "The past several years have seen the rise of transformer-based models as powerful tools for time series forecasting. These models leverage multi-head self-attention mechanisms to capture long-range dependencies and intricate patterns in data. To address the unique challenges of time series data, recent advancements have introduced various modifications to the attention mechanism. For example, Moirai uses \u201cany-variate\u201d attention to model dependencies across different series simultaneously. Factorized attention mechanisms have been developed to separately capture temporal and spatial (cross-series) interactions, enhancing the ability to understand complex interdependencies. Other models have used cross-channel attention in conjunction with feed-forward networks for mixing in the time dimension. Additionally, causal masking and hierarchical encoding can improve the efficiency and accuracy of predictions in time series contexts. These innovative transformer-based models have demonstrated state-of-the-art performance on benchmark datasets, frequently surpassing traditional models in both accuracy and robustness. Their capacity to process high-dimensional data efficiently makes them ideal for applications involving numerous time series metrics with varying characteristics, such as observability. Even more recently, a number of time series \u201cfoundation models\" have been released. By pre-training on extensive, multi-domain datasets, these large models achieve impressive zero-shot prediction capabilities, significantly reducing the need for constant retraining. This paradigm is appealing for the observability context, where we constantly have new time series to process and frequent retraining is impractical."}, {"title": "Problem statement", "content": "At Datadog, our time series data encompasses a variety of observability metrics from numerous subdomains. These metrics present several challenges for existing forecasting models: \u2022 High time resolution: Users often require data in increments of seconds or minutes, unlike many publicly-available time series datasets that are at hourly frequency or above. \u2022 Sparsity: Metrics such as error counts often track rare events, resulting in sparse and zero-inflated time series. \u2022 Extreme right skew: Latency measurements in distributed systems exhibit positive, heavy tailed distributions with extreme values at high percentiles. \u2022 Dynamic, nonstationary systems: The behavior of monitored systems change frequently due to code deployments, infrastructure scaling, feature flag management, and other configuration changes, as well as external factors like seasonality and user-behavior-driven trends. Some time series, such as those monitoring fleet deployments, can also have a very low variance, exhibiting a piecewise-constant shape. \u2022 High-cardinality multivariate data: Monitoring large fleets of ephemeral cloud infrastructure such as virtual machines (VMs), containers, serverless functions, etc. leads to high cardinality data, with hundreds or thousands of individual time series variates, often with limited historical data for each group. \u2022 Historical anomalies: Historical data often contains outliers and anomalies caused by performance regressions or production incidents. Foundation models pre-trained on other domains struggle to generalize effectively to observability data due to these characteristics. To overcome this, we developed Toto, a state-of-the-art foundation model that excels at observability forecasting while also achieving top performance on standard open benchmarks."}, {"title": "Model architecture", "content": "Toto is a decoder-only forecasting model. This model employs many of the latest techniques from the literature, and introduces a novel method for adapting multi-head attention to multivariate time series data (Fig. 1)."}, {"title": "Transformer design", "content": "Transformer models for time series forecasting have variously used encoder-decoder , encoder- only, and decoder-only architectures. For Toto, we employ a decoder-only architecture. Decoder architectures have been shown to scale well, and allow for arbitrary prediction horizons. The causal next-patch prediction task also simplifies the pre-training process. We use techniques from some of the latest large language model (LLM) architectures, including pre-normalization, RMSNorm , and SwiGLU feed-forward layers."}, {"title": "Input embedding", "content": "Time series transformers in the literature have used various approaches for creating input embeddings. We use non-overlapping patch projections (Fig. 3), first introduced for Vision Transformers and popularized in the time series context by PatchTST . Toto was trained using a fixed patch size of 32."}, {"title": "Attention mechanism", "content": "Observability metrics are often high-cardinality, multivariate time series. Therefore, an ideal model will natively handle multivariate forecasting. It should be able to analyze relationships both in the time dimension (what we refer to as \u201ctime-wise\u201d interactions) and in the channel dimension (what we refer to as \"space-wise\" interactions, following the convention in the Datadog platform of describing different groups or tag sets of a metric as the \u201cspace\u201d dimension). In order to model both space and time-wise interactions, we need to adapt the traditional multi-head attention architecture from one to two dimensions. Several approaches have been proposed in the literature to do this, including: \u2022 Assuming channel independence, and computing attention only in the time dimension. This is efficient, but throws away all information about space-wise interactions. \u2022 Computing attention only in the space dimension, and using a feed-forward network in the time dimension. \u2022 Concatenating variates along the time dimension and computing full cross-attention between every space/time location. This can capture every possible space and time interaction, but it is computationally costly. \u2022 Computing \"factorized attention,\" where each transformer block contains a separate space and time attention computation. This allows both space and time mixing, and is more efficient than full cross-attention. However, it doubles the effective depth of the network. In order to design our attention mechanism, we follow the intuition that for many time series, the time relationships are more important or predictive than the space relationships. As evidence, we observe that even models that completely ignore space-wise relationships (such as PatchTST and TimesFM ) can still achieve competitive performance on multivariate datasets. However, other studies (e.g. Moirai ) have shown through ablations that there is some clear benefit to including space-wise relationships. We therefore propose a novel variant of factorized attention, which we call \"Proportional Factorized Space-Time Attention.\" We use a mixture of alternating space-wise and time-wise attention blocks. As a configurable hyperparameter, we can change the ratio of time-wise to space-wise blocks, thus allowing us to devote more or less compute budget to each type of attention. For our base model, we selected a configuration with one space-wise attention block for every two time-wise blocks. In the time-wise attention blocks, we use causal masking and rotary positional embeddings with XPOS in order to autoregressively model time-dependent features. In the space-wise blocks, by contrast, we use full bidirectional attention in order to preserve permutation invariance of the covariates, with a block-diagonal ID mask to ensure that only related variates attend to each other. This masking allows us to pack multiple independent multivariate time series into the same batch, in order to improve training efficiency and reduce the amount of padding."}, {"title": "Probabilistic prediction head", "content": "In order to be useful for forecasting applications, a model should produce probabilistic predictions. A common practice in time series models is to use an output layer where the model regresses the parameters of a probability distribution. This allows for prediction intervals to be computed using Monte Carlo sampling. Common choices for an output layer are Normal and Student-T, which can improve robustness to outliers. Moirai allows for more flexible residual distributions by proposing a novel mixture model incorporating a weighted combination of Gaussian, Student-T, Log-Normal, and Negative-Binomial outputs. However, real-world time series can often have complex distributions that are challenging to fit, with outliers, heavy tails, extreme skew, and multimodality. In order to accommodate these scenarios, we introduce an even more flexible output likelihood. To do this we employ a method based on Gaussian mixture models (GMMs), which can approximate any density function. To avoid training instability in the presence of outliers, we use a Student-T mixture model (SMM), a robust generalization of GMMs that has previously shown promise for modeling heavy-tailed financial time series . The model predicts k Student-T distributions (where k is a hyperparameter) for each time step, as well as a learned weighting. When we perform inference, we draw samples from the mixture distribution at each timestamp, then feed each sample back into the decoder for the next prediction. This allows us to produce prediction intervals at any quantile, limited only by the number of samples; for more precise tails, we can choose to spend more computation on sampling (Fig. 2)."}, {"title": "Input/output scaling", "content": "As in other time series models, we perform instance normalization on input data before passing it through the patch embedding, in order to make the model generalize better to inputs of different scales . We scale the inputs to have zero mean and unit standard deviation. The output predictions are then rescaled back to the original units."}, {"title": "Training objective", "content": "As a decoder-only model, Toto is pre-trained on the next-patch prediction task. We minimize the negative log-likelihood of the next predicted patch with respect to the distribution output of the model. We train the model using the AdamW optimizer."}, {"title": "Hyperparameters", "content": "The hyperparameters used for Toto are detailed in Table A.1, with 103 million total parameters."}, {"title": "Training data", "content": "We pretrained Toto with a dataset of approximately one trillion time series points. Of these, roughly three-quarters are anonymous observability metrics from the Datadog platform. The remaining points come from the LOTSA dataset , a compilation of publicly-available time series datasets across many different domains."}, {"title": "Datadog dataset", "content": "The Datadog platform ingests more than a hundred trillion events per day. However, much of this data is sparse, noisy, or too granular or high in cardinality to be useful in its raw form. To curate a high- quality dataset for efficient model training, we sample queries based on quality and relevance signals from dashboards, monitor alerts, and notebooks. This provides a strong signal that the data resulting from these queries is of critical importance and sufficient quality for observability of real-world applications. Datadog metrics are accessed using a specialized query language supporting filters, group-bys, time aggregation, and various transformations and postprocessing functions. We consider groups returned from the same query to be related variates in a multivariate time series (Fig. 4). After we retrieve the query results, we discard the query strings and group identifiers, keeping only the raw numeric data. Handling this vast amount of data requires several preprocessing steps to ensure consistency and quality. Initially, we apply padding and masking techniques to align the series lengths, making them divisible by the patch stride. This involves adding necessary left-padding to both the time series data and the ID mask, ensuring compatibility with the model's requirements. Various data augmentations are employed to enhance the dataset's robustness. We introduce random time offsets to prevent memorization caused by having series always align the same way with the patch grid. After concatenating the Datadog and LOTSA datasets for training, we also implement a variate shuffling strategy to maintain diversity and representation. Specifically, 10% of the time, we combine variates that are not necessarily related, thus creating new, diverse combinations of data points. To sample the indices, we employ a normal distribution with a standard deviation of 1000, favoring data points that were closer together in the original datasets. This Gaussian sampling ensures that, while there is a preference for adjacent data points, significant randomness is introduced to enhance the diversity of the training data. This approach improves the model's ability to generalize across different types of data effectively. By implementing these rigorous preprocessing steps and sophisticated data handling mechanisms, we ensure that the training data for Toto is of the highest quality, ultimately contributing to the model's superior performance and robustness."}, {"title": "Synthetic data", "content": "We use a synthetic data generation process similar to TimesFM to supplement our training datasets, improving the diversity of the data and helping to teach the model basic structure. We simulate time series data through the composition of components such as piecewise linear trends, ARMA processes, sinusoidal seasonal patterns, and various residual distributions. We randomly combine five of these processes per variate, introducing patterns not always present in our real-world datasets. The generation process involves creating base series with random transformations, clipping extreme values, and rescaling to a specified range. By making synthetic data approximately 5% of our training dataset, we ensure a wide range of time-series behaviors are captured. This diversity exposes our models to various scenarios during training, improving their ability to generalize and effectively handle real-world data."}, {"title": "Results", "content": "We report experimental results for a pre-trained Toto model in Section 5.1 and Section 5.2. To evaluate predictions, we sequentially divide a time series into context and forecast segments. We input the context segment into Toto and autoregressively generate output patches by sampling from the Student-T mixture model distribution. We forecast a number of steps equal to the nearest multiple of the patch size, then truncate the predictions to the desired length. In order to keep inference time consistent, we vary the number of samples generated based on the cardinality and length of the dataset, with a minimum of 100 samples. We take the median sample at each time step as the final point prediction. This prediction is then compared against the ground-truth forecast segment for evaluation."}, {"title": "LSF benchmarks", "content": "To assess general-purpose time series forecasting performance, we use the Long Sequence Forecasting (LSF) benchmark datasets (ETTh1, ETTh2, ETTm1, ETTm2, Electricity, and Weather) . We evaluate with forecast lengths of 96, 192, 336, and 720 time steps, in sliding windows with stride 512, and average the results. For Toto, we used a historical context window of 512 steps and took the median of 200 samples. Following standard practice, we report normalized Mean Absolute Error (MAE) and Mean Squared Error (MSE), fitted on a training split, in order to be able to compare performance across different datasets. We compared Toto's performance with the reported results of other recent zero-shot foundation models , as well as full-shot time series forecasting models. We display these results in Table 1. Toto demonstrates exceptional performance across a variety of benchmark datasets, excelling in zero-shot scenarios. In the LSF datasets, Toto consistently outperforms other models in terms of MAE and MSE. For example, on the ETTh1 dataset, Toto achieves an MAE of 0.389 and an MSE of 0.363, outperforming all zero-shot models, including the previously reported Moirai series and TimesFM. Macro-averaging across the six LSF datasets, Toto achieves an MAE of 0.312 and MSE of 0.265, again exceeding Moirai's reported zero-shot performance as well as the reported performance of the full-shot models. Several architectural choices and data features likely contribute to Toto's superior performance. The novel Proportional Factorized Space-Time Attention mechanism allows Toto to efficiently capture both temporal and spatial dependencies within multivariate time series data. Additionally, the extensive training on a diverse dataset of one trillion time series points, including a mix of real-world observability metrics and multi-domain time series data, enhances Toto's ability to handle varied characteristics of different benchmark datasets. While Toto generally excels, there are areas where its performance is closely matched by other models. In full-shot scenarios, models like PatchTST, Crossformer, and FEDformer show competitive results. For example, on the Electricity dataset, while Toto achieves a leading zero-shot MAE of 0.246 and MSE of 0.157, iTransformer and TimesNet also show strong performance, indicating that these models can catch up when additional training data is available. Overall, Toto's architectural innovations and extensive training data enable it to achieve state-of-the-art performance across diverse benchmarks, excelling in zero-shot scenarios while remaining highly competitive in full-shot contexts."}, {"title": "Datadog benchmark", "content": "We created a benchmark using anonymous Datadog data to assess performance across various observability metrics. To ensure a representative and realistic sample, we sampled data based on quality and relevance signals from dashboards, monitor alerts, and notebooks. This benchmark comprises 983,994 data points from 82 distinct multivariate time series, encompassing 1,122 variates. We analyzed summary statistics of the series in our benchmark to identify characteristics that make observability time series challenging to forecast. The categories and their definitions are as follows: \u2022 Sparse: Series with a low density of observations, indicating infrequent recording of data or rare events. \u2022 Extreme right skew: Series with a distribution heavily skewed to the right, characterized by a few very high values and many lower values. \u2022 Seasonal: Series exhibiting regular and recurring patterns, often linked to daily, weekly, or yearly cycles. \u2022 Flat: Series with minimal variability, showing little to no change over time. The relative proportion of these cases are displayed in Table 3. To assess the prediction of other zero-shot models on the DD Benchmark, we follow sampling procedures delineated in their respective manuscripts. In short, for Chronos models, we generate 20 samples and take the median prediction. For Moirai models, we take the median of 100 samples and set the patch size to \"auto\". TimesFM only produces point predictions of the mean, so we use those directly. Since TimesFM and Chronos only support univariate forecasting, we process each variate independently. Moirai, on the other hand, like Toto, makes joint predictions for each group of related variates. For Toto, we utilize the same evaluation procedure we used on the LSF benchmarks. The evaluation results (Table 2) demonstrate that Toto outperforms the other models. We evaluate using a prediction length of 365, the maximum forecast window available for previous time series models within the Datadog platform. We use a historical context window of 512 steps. Because observability data can have extreme variation in both magnitude and dispersion, we select symmetric mean absolute percentage error (sMAPE) as a scale-invariant performance metric. We also report symmetric median absolute percentage error (sMdAPE), a robust version of sMAPE that minimizes the influence of the extreme outliers present in observability data. With the lowest SMAPE of 0.672 and sMdAPE of 0.318, Toto proves to be the most accurate for forecasting observability time series data. These results suggest that current open datasets may not provide sufficient information to extrapolate to the specific nuances of observability data, highlighting the importance of training on more relevant data as demonstrated by Toto's superior performance."}, {"title": "Conclusions", "content": "Toto, through a novel architecture and pre-training corpus, demonstrates state-of-the-art performance both on public benchmarks and on the Datadog observability benchmark. We look forward to sharing"}, {"title": "Impact statement", "content": "In developing Toto, Datadog follows a structured approach to ensure responsible development, focusing on identifying, assessing, and mitigating potential risks associated with the use of our model. Given that Toto is not intended for mass distribution and specifically generates time series forecasts for observability data, the potential harms are considerably lower compared to more general-purpose models. At Datadog, our primary focus is on ensuring the accuracy, reliability, and security of the forecasts generated by Toto, which are crucial for maintaining and optimizing infrastructure and application performance. We carefully analyze the potential for Toto to produce incorrect or misleading forecasts that could impact decision-making processes in critical systems. Additionally, we consider the implications of Toto's performance across diverse datasets, ensuring it can generalize well without introducing significant errors."}, {"title": "Future directions", "content": "Many exciting areas of exploration remain for further study. If you are interested in working with us, please reach out to the authors by email. Some future research questions that particularly intrigue us include: \u2022 Multi-modal inputs: Incorporate additional input modalities such as query metadata and captions to enhance forecast performance. \u2022 Autonomous troubleshooting agents: Augment Datadog's AI agents for troubleshooting and incident response by integrating modality-specific foundation models like Toto to improve their reasoning and planning capabilities with telemetry data. \u2022 Conversational interfaces: Align time series forecasting models with LLMs to develop conversational agents capable of interpreting and reasoning about time series data. \u2022 Model enhancements and scaling: Explore ways to improve and scale model performance through optimizations such as new types of input embeddings, attention mechanisms, and examining alternative variate groupings to capture richer interactions."}, {"title": "Contributions", "content": "Contributors are listed in alphabetical order. Othmane Abou-Amal, Joseph Banks, Mayeul Blanzat, Ben Cohen, Youssef Doubli, Ben Hinthorne, Emaad Khwaja, Jared Ledvina, Charles Masson, Sajid Mehmood, Elise Ram\u00e9, Maxime Visonneau, Kan Wang."}, {"title": "Acknowledgements", "content": "Our work is made possible by the efforts of numerous teams at Datadog. Special thanks and acknowledgement to: Johan Andersen, Roashan Ayene, Romoli Bakshi, Kevin Beach, Bill Birkholz, Rob Boll, Maxim Brown, Benedetto Buratti, Marion Chan-Renous, Jessica Cordonnier, Ben Donohue, Zakaria Fikrat, Quentin Fran\u00e7ois, Erica Hale, Michael Hoang, Joe Jones, Max Livingston, Jesse Mack, Amine Naouas, Sean O'Connor, Brendan Rhoads, Phil Sarin, Vyom Shah, Aaron Taa, Bharath Vontimitta, Dominique West, Steven Zhou."}]}