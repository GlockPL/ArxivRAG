{"title": "FADAS: Towards Federated Adaptive Asynchronous Optimization", "authors": ["Yujia Wang", "Shiqiang Wang", "Songtao Lu", "Jinghui Chen"], "abstract": "Federated learning (FL) has emerged as a widely adopted training paradigm for privacy-preserving machine learning. While the SGD-based FL algorithms have demonstrated considerable success in the past, there is a growing trend towards adopting adaptive federated optimization methods, particularly for training large-scale models. However, the conventional synchronous aggregation design poses a significant challenge to the practical deployment of those adaptive federated optimization methods, particularly in the presence of straggler clients. To fill this research gap, this paper introduces federated adaptive asynchronous optimization, named FADAS, a novel method that incorporates asynchronous updates into adaptive federated optimization with provable guarantees. To further enhance the efficiency and resilience of our proposed method in scenarios with significant asynchronous delays, we also extend FADAS with a delay-adaptive learning adjustment strategy. We rigorously establish the convergence rate of the proposed algorithms and empirical results demonstrate the superior performance of FADAS over other asynchronous FL baselines.", "sections": [{"title": "1. Introduction", "content": "In recent years, federated learning (FL) (McMahan et al., 2017) has drawn increasing attention as an efficient privacy-preserving distributed machine learning paradigm. An FL framework consists of a central server and numerous clients, where clients collaboratively train a global model without sharing their private data. FL entails each client conducting multiple local iterations, while the central server periodically aggregates these local updates into the global model. Following the original design of the FedAvg algorithm (McMahan et al., 2017), a large number of stochastic gradient descent (SGD)-based FL methods have emerged, aiming to improve the performance or efficiency of FedAvg (Karimireddy et al., 2020; Acar et al., 2021; Wang et al., 2020b).\nIn addition to the successes of SGD-based algorithms in enhancing the efficiency of FL, the adoption of adaptive optimization techniques is becoming increasingly prevalent in FL. Adaptive optimization techniques such as Adam (Kingma & Ba, 2015) and AdamW (Loshchilov & Hutter, 2017) have proven their advantages over SGD in effectively training or fine-tuning large-scale models like BERT (Devlin et al., 2018), ViT (Dosovitskiy et al., 2021), and Llama (Touvron et al., 2023). This progress has encouraged the incorporation of adaptive optimization into the FL settings, taking advantage of their ability to navigate update directions and dynamically adjust learning rates. For example, FedAdam (Reddi et al., 2021) and FedAMS (Wang et al., 2022b) employ global adaptive optimization after the server aggregates local model updates. Moreover, strategies such as FedLALR (Sun et al., 2023a), FedLADA (Sun et al., 2023b), and FAFED (Wu et al., 2023) replace SGD with the Adam optimizer for the local training phase, exemplifying the utility of local adaptive optimizations in FL.\nHowever, existing methods in adaptive FL still rely on traditional synchronous aggregation approaches, where the server must wait for all participating clients to complete their local training before global updates. This reliance presents a significant challenge to the practical implementation of adaptive FL methodologies, as the server is required to wait until slower clients, which may have limited computation or communication capabilities. While asynchronous FL strategies such as FedBuff (Nguyen et al., 2022) and FedAsync (Xie et al., 2019) have been investigated to improve the scalability and to study the impact of client delays on the convergence of SGD-based FL algorithms, the specific implications of asynchronous delays on nonlinear adaptive gradient operations are not completely understood. This motivates us to explore the following question:\nCan we develop an asynchronous method for adaptive federated optimization (with provable guarantees) that enhances training efficiency and is resilient to asynchronous delays?"}, {"title": "2. Related Work", "content": "Federated learning. FL, as introduced by McMahan et al. (2017), has become a pivotal framework for collaboratively training machine learning models on edge devices while keeping local data private. Following the initial FedAvg algorithm, several works studied the theoretical analysis and empirical performance of it (Lin et al., 2018; Stich, 2018; Li et al., 2019a; Karimireddy et al., 2020; Wang & Joshi, 2021; Yang et al., 2021), and a range of works aim to improve FedAvg from different perspectives, such as reducing the impact of data heterogeneity (Karimireddy et al., 2020; Acar et al., 2021; Wang et al., 2020b), saving the communication overhead (Reisizadeh et al., 2020; Jhunjhunwala et al., 2021), and adjusting the parameter aggregation procedure (Tan et al., 2022; Wang & Ji, 2023).\nAdaptive FL optimizations and adaptive updates. Besides traditional SGD-based methods, there is a line of works focusing on adaptive updates in FL. A local adaptive FL method with momentum-based variance-reduced gradient was used in FAFED (Wu et al., 2023). Li et al. (2023) proposed a framework for local adaptive gradient methods in FedDA. FedLALR (Sun et al., 2023a) uses local adaptive optimization in FL with local historical gradients and periodically synchronized learning rates. FedLADA (Sun et al., 2023b) is an efficient local adaptive FL method with a locally amended technique. Jin et al. (2022) developed novel adaptive FL optimization methods from the perspective of dynamics of ordinary differential equations. Moreover, Reddi et al. (2021) introduced FedAdagrad, FedAdam and FedYogi, and Wang et al. (2022b) proposed FedAMS for global adaptive FL optimizations. Several works of global adaptive learning rate (Jhunjhunwala et al., 2023) and adaptation in aggregation weights (Tan et al., 2022; Wang & Ji, 2023) are also related to adaptive learning rate adjustment.\nAsynchronous SGD and asynchronous FL. There have been extensive studies over the years about asynchronous optimization techniques, including asynchronous SGD and its various adaptations. For example, Hogwild (Niu et al., 2011) includes an applicable lock-free, coordinate-wise asynchronous method and has been widely used in multi-thread computation. A body of works focuses on the theoretical analysis and explorations of asynchronous SGD (Mania et al., 2017; Nguyen et al., 2018; Stich et al., 2021; Leblond et al., 2018; Glasgow & Wootters, 2022) and discusses the gradient delay in the convergence rate (Avdiukhin & Kasiviswanathan, 2021; Mishchenko et al., 2022; Koloskova et al., 2022; Wu et al., 2022). Within federated learning, innovative asynchronous aggregation algorithms like FedAsync (Xie et al., 2019) allow the server to update the global model once a client finishes local training, and FedBuff (Nguyen et al., 2022) introduces a buffered aggregation approach. There are also many works focusing on algorithms based on FedBuff with theoretical and/or empirical analysis (Toghani & Uribe, 2022; Ortega & Jafarkhani, 2023; Wang et al., 2023), and other aspects of asynchronous FL (Chen et al., 2020b; Yang et al., 2022; Bornstein et al., 2023). Although adaptive FL and asynchronous FL have achieved the success of training large machine learning models with desirable numerical performance, the exploration of asynchronous updates in the context of adaptive FL has not been well-studied yet. In this paper, we start with the asynchronous update framework in adaptive FL and further integrate delay-adaptive learning rate scheduling into it."}, {"title": "3. Preliminaries", "content": "Federated learning. A general FL framework considers a distributed optimization problem across N clients:\n$\\min_{x \\in \\mathbb{R}^d} f(x) := \\frac{1}{N} F(x) = \\sum_{i=1}^N E_{\\xi_i \\sim D_i} [F_i(x; \\xi_i)],$ (1)\nwhere $x \\in \\mathbb{R}^d$ is the model parameter with d dimensions, $F_i(x)$ is the loss function corresponding to client i, $D_i$ is the local data distribution on client i. The objective in Eq. (1) can be interpreted as setting $p_i = \\frac{1}{N}$ for all clients in another commonly used objective function in FL, i.e., $f(x) = \\sum_{i=1}^N p_iE_{\\xi_i \\sim D_i} [F_i(x; \\xi_i)]$ with $p_i \\geq 0$ and $\\sum_{i=1}^N p_i = 1$. FedAvg (McMahan et al., 2017) is a typical synchronous FL algorithm to solve Eq. 1, where in the t-th global round, each participating client i performs local SGD updates as follows:\n$\\begin{aligned}x_{i,k+1} &= x_{i,k} - \\eta_l \\nabla F_i(x_{i,k}; \\xi) \\text{ and } x_{i,0} = x_t\\end{aligned},$ (2)\nwhere $\\eta_l$ is the learning rate. After several local steps (e.g., K steps of local training), the server performs a global averaging step after receiving all the updates from assigned clients in $S_t$, i.e., $x_{t+1} = \\frac{1}{|S_t|} \\sum_{i \\in S_t} x_{i,K}$.\nAdaptive optimization and its application to FL. Several adaptive optimizers have been proposed to improve the convergence of SGD, such as Adagrad (Duchi et al., 2011), RMSProp (Tieleman et al., 2012), Adam (Kingma & Ba, 2015) and its variant AMSGrad (Reddi et al., 2018). In general machine learning optimization, Adam effectively inherits the benefits of both momentum and RMSProp optimizers, leading to better empirical performance in practical applications.\nReddi et al. (2021) first introduced adaptive federated optimization, which applies the adaptive optimizers during the global aggregation steps in FL. FedAMSGrad (Tong et al., 2020) and FedAMS (Wang et al., 2022b) further adjust the effective global learning rate in adaptive FL. Specifically, FedAdam and FedAMS take the idea of viewing the difference of local updates $\\triangle_t^{\\text{sync}} = \\frac{1}{|S_t|} \\sum_{i \\in S_t} (x_{i,K} - x_t)$ as a pseudo-gradient, and applies the Adam or AMSGrad optimizer when updating global model $x_{t+1}$ using $\\triangle_t^{\\text{sync}}$, i.e.,\n$\\begin{aligned}m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) \\triangle_t^{\\text{sync}},\\\\\nv_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) (\\triangle_t^{\\text{sync}} \\odot \\triangle_t^{\\text{sync}}),\\\\\nx_{t+1} &= x_t + \\eta \\frac{m_t}{\\sqrt{v_t} + \\epsilon} \\quad \\text{(FedAdam)},\\\\\nv_t &= \\max(v_{t-1}, v_t), x_{t+1} = x_t + \\eta \\frac{m_t}{\\sqrt{v_t} + \\epsilon} \\quad \\text{(FedAMS)},\\end{aligned}$\nwhere $\\odot$ denotes the element-wise product for two vectors, and for vectors $x, y \\in \\mathbb{R}^d$, $\\sqrt{x}, x/y, \\max(x, y)$ denote the element-wise square root, division, and maximum operation of the vectors.\nAsynchronous updates in FL. In asynchronous FL, clients train the model asynchronously and update it to the server once it finishes several steps of local training. FedBuff (Nguyen et al., 2022) has improved the global update steps with the concept of buffer based on the initial FedAsync baseline (Xie et al., 2019). In FedBuff, it requires the framework maintain a given number (referred to as the concurrency $M_c$) of clients that are actively local training. At the t-th global round, after the client i finishes local training, it sends its local update $\\triangle_i = x_{i,K} - x_t$ to the server, where t - $\\tau_i$ is the global round where client i starts local training and $0 \\leq \\tau_i < t$. The server simultaneously accumulates the model update $\\triangle_i$ to the global update direction $\\triangle_t \\leftarrow \\triangle_t + \\triangle_i$, and sends the latest global model to a randomly selected client who is idle. When the number of accumulated updates reaches the given buffer size of M, the server updates the global model with the averaging $\\triangle_t/M$. Meanwhile, clients who have not finished their local training will continue their training based on the previously received global model, and are not affected by the global model updates on the server. During the training, the framework always maintains a fixed number ($M_c$) of clients who are conducting local training. This is achieved by having the server randomly sample an idle client for training each time a client completes its local training and sends its update to the server.\nDiscussion about synchronous and asynchronous methods. Synchronous FL typically offers consistency and stability, i.e., all client updates are based on the same global model, and this consistency may lead to a more stable and predictable learning process. However, when there exist one or a few clients that are much slower than the majority of clients, which often happens in large-scale systems, synchronous FL can be inefficient since every client needs to wait for the slowest client before progressing with the next round of training. Asynchronous FL is more efficient when clients have system heterogeneity such as diverse computational capabilities or communication bandwidth. In FL, if the delay among clients is relatively uniform, synchronous FL tends to be more stable and efficient. Overall, the choice between synchronous and asynchronous FL hinges on specific needs and system characteristics. Synchronous FL is ideal in homogeneous systems, while asynchronous FL is advantageous in heterogeneous systems with potential straggler clients."}, {"title": "4. Proposed Method: FADAS", "content": "Although adaptive FL methods achieve promising convergence and generalization performance theoretically and empirically, the existing adaptive FL methods are restricted to synchronous settings, as the server needs to wait for all the assigned clients to finish their local updates for aggregation and then update the global model. However, those synchronous adaptive FL algorithms are susceptible to the presence of stragglers, where slower clients with insufficient computation or communication speed impede the progress of the global update.\nTo improve the efficiency and resiliency of adaptive FL in the presence of stragglers, we introduce FADAS, a Federated Adaptive ASynchronous optimization method. Similar to FedAdam and FedAMS, the proposed FADAS algorithm takes the model update difference from clients as a pseudo-gradient and it updates the global model following an Adam-like update scheme. Algorithm 1 summarizes the details. FADAS keeps the local asynchronous training scheme as FedBuff and maintains the concept of concurrency and buffer size for flexible control of the number of active clients and the frequency of global model update. In FADAS, after the server aggregates to obtain model update difference $\\triangle_t$, it finds an adaptive update direction, whose components are computed based on the AMSGrad optimizer (Reddi et al., 2018) as follows:\n$\\begin{aligned}m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) \\triangle_t,\\\\\nv_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) \\triangle_t \\odot \\triangle_t,\\\\\nv_t &= \\max(v_{t-1}, v_t).\\end{aligned}$ (3)\nIn general, FADAS enables clients to conduct local training in their own pace, and the server aggregates the asynchronous updates for global adaptive updates. It improves the training efficiency and scalability of over synchronous adaptive FL while inheriting the advantage of adaptive optimizer of reducing oscillations and stabilizing the optimization process.\nAlthough FADAS applies asynchronous local training for adaptive FL, the global adaptive optimizer adjusts the global update direction only based on local updates but without considering the impact of asynchronous delay. Intuitively, a large asynchronous delay from a client means that this model update is made based on an outdated global model. This may lead to a negative effect on the convergence, and later we also verify this intuition in the theoretical analysis. This inspires us to apply a delay-adaptive learning rate adjustment to improve the resiliency of FADAS to stragglers with large delays. Specifically, we let the server track the delay for every received model update and adopt a delay-adaptive learning rate. We highlight the delay-adaptive steps in Algorithm 1 and those steps are executed with almost no extra overhead.\nDelay tracking. In general, the server manages the delay record for each client through straightforward time-stamping. For example, the server records the global update round t' when it broadcasts the current global model $x_t$ to client i, the client conducts local training with $x_t$. When the server receives the first $\\triangle$ from client i at round $t > t'$, the gradient delay for $\\triangle$, which is $\\tau_i^t = t - t'$, is updated and recorded on the server.\nDelay-adaptive learning rate. Assume that for each global update round t, clients in the set $M_t$ ( $|M_t| = M$) send updates to the server. The received model updates at global round t have a maximum delay $\\tau^{\\text{max}}_t$ defined as $\\tau^{\\text{max}}_t := \\max{\\{\\tau_i, i \\in M_t\\}}$. Suppose we set up a delay threshold $T_c$, we can define a delay-adaptive learning rate as:\n$\\eta_t = \\begin{cases}\\eta & \\text{if } \\tau^{\\text{max}}_t < T_c,\\\\min \\left\\{\\eta, \\frac{\\eta}{\\tau^{\\text{max}}_t} \\right\\} & \\text{if } \\tau^{\\text{max}}_t > T_c.\\end{cases}$ (4)\nIntuitively, this design implies that we need to turn the learning rates down for the model update $\\triangle_t$ with larger current-step delays. Specifically, if the current-step maximum delay $\\tau^{\\text{max}}_t$ is larger than a given threshold $T_c$, we scale down the learning rates for this step in proportional to $1/\\tau^{\\text{max}}_t$ (also capped by a constant learning rate $\\eta$) to avoid that the high-latency update worsens the convergence. Comparison with FedAsync (Xie et al., 2019). FedAsync (Xie et al., 2019) also studies delay-adaptive weighted averaging during global model updates. In FedAsync, after the server receives a local model $x_{\\text{new}}$, it updates $x_t$ based on $x_t = (1 - \\alpha_t) x_{t-1} + \\alpha_t x_{\\text{new}}$, and FedAsync includes a hinge strategy of $\\alpha_t$ which is similar to our delay-adaptive strategy in Eq. (4). However, unlike FedAsync, where the server updates the global model immediately upon receiving a new update from a client, FADAS updates the global model less frequently. In FADAS, the server accumulates"}, {"title": "5. Theoretical Analysis", "content": "In this section, we delve into the theoretical analysis of our proposed FADAS algorithm. We first introduce some common assumptions required for the analysis. Subsequently, we present the analysis in two parts: one focusing on FADAS without delay adaptation, as discussed in Section 5.1, and the other on the delay-adaptive FADAS in Section 5.2.\nAssumption 5.1 (Smoothness). Each objective function on the i-th worker $F_i(x)$ is L-smooth, i.e., $\\forall x, y \\in \\mathbb{R}^d$,\n$\\|\\nabla F_i(x) - \\nabla F_i(y) \\| \\leq L\\|x-y\\|$.\nAssumption 5.2 (Bounded Variance). Each stochastic gradient is unbiased and has a bounded local variance, i.e., for all $x, i \\in [N]$, we have $E [\\|\\nabla F_i(x; \\xi) - \\nabla F_i(x)\\|]^2 \\leq \\sigma^2$, and the loss function on each worker has a global variance bound, $\\frac{1}{N} \\sum_{i=1}^N \\|\\nabla F_i(x) - \\nabla f(x)\\|]^2 \\leq \\sigma_g^2$.\nAssumption 5.1 and 5.2 are standard assumptions in federated non-convex optimization literature (Li et al., 2019b; Yang et al., 2021; Reddi et al., 2021; Wang et al., 2022b; Wang & Ji, 2023). The global variance upper bound of $\\sigma_g$ in Assumption 5.2 measures the data heterogeneity across clients, and a global variance of $\\sigma_g^2 = 0$ indicates a uniform data distribution across clients.\nAssumption 5.3 (Bounded Gradient). Each loss function on the i-th worker $F_i(x)$ has G-bounded stochastic gradient on l2 norm, i.e., for all $\\xi$, we have $\\|\\nabla F_i(x; \\xi)\\| \\leq G$.\nAssumption 5.3 is necessary for adaptive gradient algorithms for both general (Kingma & Ba, 2015; Chen et al., 2020a), distributed (Wang et al., 2022a) and federated adaptive optimization (Reddi et al., 2021; Wang et al., 2022b; Sun et al., 2023b). This is because the effective global learning rate for adaptive gradient methods is $\\frac{\\eta}{\\sqrt{v_t} + \\epsilon}$, and we need a lower bound for $\\sqrt{v_t} + \\epsilon$ to guarantee that the effective learning rate does not vanish to zero.\nAssumption 5.4 (Bounded Delay of Gradient Computation). Let $\\tau_i^t$ represent the delay for global round t and client i which is applied in Algorithm 1. The delay $\\tau_i^t$ is the difference between the current global round t and the global round at which client i started to compute the gradient. We assume that the maximum gradient delay (worst-case delay) is bounded, i.e., $\\tau_{\\text{max}} = \\max_{t \\in [T], i \\in [N]} {\\tau_i^t} < \\infty$.\nAssumption 5.4 is common in analyzing asynchronous and anarchic FL algorithms which incorporate the gradient delays into their algorithm design (Koloskova et al., 2022; Yang et al., 2021; Nguyen et al., 2022; Toghani & Uribe, 2022; Wang et al., 2023).\nAssumption 5.5 (Uniform Arrivals of Gradient Computation). Let the set $M_t$ (with size M) include clients that transmit their local updates to the server in global round t. We assume that the clients' update arrivals are uniformly distributed, i.e., from a theoretical perspective, the M clients in $M_t$ are randomly sampled without replacement from all clients [N] according to a uniform distribution\u00b9.\nAssumption 5.5 is also discussed in Anarchic FL (Yang et al., 2022), which has been utilized to analyze the AFA-CD algorithm proposed therein."}, {"title": "5.1. Convergence Rate of FADAS", "content": "For expository convenience, in the following, we provide the theoretical convergence analysis of FADAS under the case of $\\beta_1 = 0$. The theoretical analysis and the proof for the general case of $0 < \\beta_1 < 1$ are provided in Appendix A. We define the average of the maximum delay over time as $\\tau_{\\text{avg}} = \\frac{1}{T} \\sum_{t=1}^T \\tau^{\\text{max}}_t = \\frac{1}{T} \\sum_{t=1}^T \\max_{i \\in [N]} {\\tau_i^t}$ which is useful in our analysis.\nTheorem 5.6. Under Assumptions 5.1-5.5, let T represent the total number of global rounds, K be the number of local SGD training steps and M be the number of the accumulated updates (buffer size) in each round. If the learning rate $\\eta$ and $\\eta_l$ satisfies $\\eta \\eta_l \\leq \\min { \\frac{\\epsilon^3 M(N-1)}{180 C G N(N-M) \\tau_{\\text{max}} K L}, \\frac{\\epsilon^2 M(N-1)}{12 \\sqrt{C G N(M-1)} \\tau_{\\text{max}} K L}} $, $\\eta_l \\leq \\sqrt{\\frac{\\epsilon^2}{360 C G \\tau_{\\text{max}} K L}}$, then the global iterates {xt}=1 of Algorithm 1 satisfy\n$\\frac{1}{T} \\sum_{t=1}^T E[\\|\\nabla f(x_t)\\|^2] \\leq O(\\frac{\\sqrt{F_0}}{T \\sqrt{K M}} + \\frac{\\sqrt{F_0} g}{T \\sqrt{K M}} + \\frac{F G}{T \\sqrt{V M}} + \\frac{F_{\\tau_{\\text{max}}} \\tau_{\\text{avg}}}{T V M})$ (6)\nRemark 5.8. Corollary 5.7 suggests that given sufficiently large T and relatively small worst-case delay $\\tau_{\\text{max}}$, the proposed FADAS (without delay-adaptive learning rate) achieves a convergence rate of $O(\\frac{1}{\\sqrt{T K M}})$ w.r.t. T and M.\nComparison to asynchronous FL methods. Compared with the analysis for FedBuff in Nguyen et al. (2022) and Toghani & Uribe (2022), our analysis for FADAS obtains a relaxed dependency on the worst-case gradient delay $\\tau_{\\text{max}}$, and FADAS achieves a slightly better rate on non-dominant term than $O(\\frac{\\tau}{\\sqrt{T K M}})$ obtained in Toghani & Uribe (2022). Moreover, Wang et al. (2023) also studied the convergence for FedBuff with relaxed requirements for $\\tau_{\\text{max}}$, and our FADAS achieves a similar convergence of $O(\\frac{1}{\\sqrt{T K M}} + \\frac{\\tau_{\\text{max}} \\tau_{\\text{avg}}}{V T M})$ as in Wang et al. (2023). It is worthwhile to mention that recently CA2FL (Wang et al., 2023) improves the convergence of asynchronous FL under heterogeneous data distributions, while the improvement is obtained by using the cached variable on the server for global update calibration.\nNote that when $\\tau_{\\text{max}}$ in Eq. (6) is large, particularly in cases where $\\tau_{\\text{max}} > \\sqrt{VT}$, then $\\frac{\\tau_{\\text{max}} \\tau_{\\text{avg}}}{V T M}$ becomes the dominant term in the convergence rate. This implies that a large worst-case delay $\\tau_{\\text{max}}$ may lead to a worse convergence rate. In the next subsection, we demonstrate that the delay-adaptive learning rate strategy can relieve this problem and enhance FADAS with better resilience to large worst-case delays."}, {"title": "5.2. Convergence Rate of Delay-adaptive FADAS", "content": "In the following, we provide the convergence analysis for delay-adaptive FADAS with $\\beta_1 = 0$. To get started, we first define the median of the maximum delay over all communication rounds [T]:\n$\\tau_{\\text{median}} = \\text{median}{\\{\\tau^{\\text{max}}_1, \\tau^{\\text{max}}_2, ..., \\tau^{\\text{max}}_T\\}}.$ (7)\nThe definition of $\\tau_{\\text{median}}$ implies that the number of global update rounds that have a maximum delay greater than $\\tau_{\\text{median}}$ is less than half of the total number of global updates T. With this definition, we present the following theorem characterizing the convergence rate of delay-adaptive FADAS.\nTheorem 5.9. Under Assumptions 5.1\u20135.5, let T be the total number of global rounds, K be the number of local SGD training steps and M be the number of the buffer size in each round. If the learning rate $\\eta$ and $\\eta_l$ satisfies $\\eta \\eta_l < \\min{\\{\\frac{\\epsilon^3 M(N-1)}{60 C G N(N-M) \\tau_{\\text{max}} K L}, \\frac{\\epsilon^2 M(N-1)}{12 \\sqrt{C G N(M-1)} \\tau_{\\text{max}} K L}\\}}$, $\\eta_l \\leq \\sqrt{\\frac{\\epsilon^2}{360 C G \\tau_{\\text{max}} K L}}$ and $\\eta < \\sqrt{\\frac{\\epsilon}{M}}$, then the global iterates {xt}=1 of Algorithm 1 satisfy\n$\\frac{1}{T} \\sum_{t=1}^T \\frac{1}{N_t} E[\\|\\nabla f(x_t)\\|^2] \\leq \\frac{4 C G}{T} \\frac{F + \\eta \\eta_l K T}{M \\epsilon^3} + \\frac{20 C G \\eta \\eta_l K L^2 (\\sigma^2 + 6 K \\sigma_g^2)}{M \\epsilon^3} + \\frac{8 C G \\eta^2 \\eta_l K L^2 T T_{\\text{avg}}}{T M \\epsilon^3} \\sum_{t=1}^T \\frac{1}{N_t} + \\frac{N-M}{N-1} \\frac{\\sigma^2}{M \\epsilon^3} [15 \\eta^2 K^2 L^2 (\\sigma^2 + 6 K \\sigma_g^2) + 3 K \\sigma_g^3] + \\frac{N-M}{N-1} {\\frac{8 C G \\eta_t^2 + 6 K \\sigma_g^2}{M e^2}}.$ (8)\nwhere $F = f(x_1) - f^*$, $f^* = \\min_x f(x) > -\\infty$ and $C_G = \\frac{1}{K} K G + \\epsilon$.\nCorollary 5.10. If we pick $T_c = \\tau_{\\text{median}}$, the global learning rate $\\eta = \\Theta(\\frac{T_c \\sqrt{F}}{\\sqrt{T K M} (\\sigma^2 + K \\sigma_g^2)})$ and $\\eta_l = \\Theta(\\frac{\\sqrt{F}}{\\sqrt{T K} (\\sigma^2 + K \\sigma_g^2)})$, then for sufficiently large T, the global iterates {xt}=1 of Algorithm 1 satisfy\n$\\frac{1}{T} \\sum_{t=1}^T \\frac{1}{N_t} E[\\|\\nabla f(x_t)\\|^2] \\leq O(\\frac{\\sqrt{F_0}}{\\sqrt{T K M}} + \\frac{\\sqrt{F_0} g}{\\sqrt{T K M}} + \\frac{F G T_c}{T \\sqrt{V M}} + \\frac{F T_{\\text{avg}} F (T_c^2 + T_c T_{\\text{avg}})}{T}+).$ (9)\nRemark 5.11. Corollary 5.10 suggests that with sufficiently large T, delay-adaptive FADAS also achieves a convergence rate of $O(\\frac{1}{\\sqrt{T K M}})$ w.r.t. T and M.\nRemark 5.12. Compared to the convergence rate in Corollary 5.7, the convergence rate in Corollary 5.10 does not rely on the (possibly large) worst-case delay $\\tau_{\\text{max}}$. In cases where $T_c = \\tau_{\\text{median}} \\approx \\tau_{\\text{avg}} \\ll \\tau_{\\text{max}}$, Corollary 5.10 relaxes the requirement from $\\tau_{\\text{max}}$ to $\\tau_{\\text{median}}$ for achieving the desired convergence rate. Since $\\tau_{\\text{median}}$ describes the median of $\\tau^{\\text{max}}_t = \\max_{i \\in [N]} {\\tau_i^t}$ in each round t, the convergence rate in Corollary 5.10 is less sensitive to stragglers who may cause a large worst-case delay in the system."}, {"title": "6. Experiments", "content": "We explore the performance of our proposed FADAS algorithm through experiments on vision and language tasks", "https": ""}, {"title": "FADAS: Towards Federated Adaptive Asynchronous Optimization", "authors": ["Yujia Wang", "Shiqiang Wang", "Songtao Lu", "Jinghui Chen"], "abstract": "Federated learning (FL) has emerged as a widely adopted training paradigm for privacy-preserving machine learning. While the SGD-based FL algorithms have demonstrated considerable success in the past, there is a growing trend towards adopting adaptive federated optimization methods, particularly for training large-scale models. However, the conventional synchronous aggregation design poses a significant challenge to the practical deployment of those adaptive federated optimization methods, particularly in the presence of straggler clients. To fill this research gap, this paper introduces federated adaptive asynchronous optimization, named FADAS, a novel method that incorporates asynchronous updates into adaptive federated optimization with provable guarantees. To further enhance the efficiency and resilience of our proposed method in scenarios with significant asynchronous delays, we also extend FADAS with a delay-adaptive learning adjustment strategy. We rigorously establish the convergence rate of the proposed algorithms and empirical results demonstrate the superior performance of FADAS over other asynchronous FL baselines.", "sections": [{"title": "1. Introduction", "content": "In recent years, federated learning (FL) (McMahan et al., 2017) has drawn increasing attention as an efficient privacy-preserving distributed machine learning paradigm. An FL framework consists of a central server and numerous clients, where clients collaboratively train a global model without sharing their private data. FL entails each client conducting multiple local iterations, while the central server periodically aggregates these local updates into the global model. Following the original design of the FedAvg algorithm (McMahan et al., 2017), a large number of stochastic gradient descent (SGD)-based FL methods have emerged, aiming to improve the performance or efficiency of FedAvg (Karimireddy et al., 2020; Acar et al., 2021; Wang et al., 2020b).\nIn addition to the successes of SGD-based algorithms in enhancing the efficiency of FL, the adoption of adaptive optimization techniques is becoming increasingly prevalent in FL. Adaptive optimization techniques such as Adam (Kingma & Ba, 2015) and AdamW (Loshchilov & Hutter, 2017) have proven their advantages over SGD in effectively training or fine-tuning large-scale models like BERT (Devlin et al., 2018), ViT (Dosovitskiy et al., 2021), and Llama (Touvron et al., 2023). This progress has encouraged the incorporation of adaptive optimization into the FL settings, taking advantage of their ability to navigate update directions and dynamically adjust learning rates. For example, FedAdam (Reddi et al., 2021) and FedAMS (Wang et al., 2022b) employ global adaptive optimization after the server aggregates local model updates. Moreover, strategies such as FedLALR (Sun et al., 2023a), FedLADA (Sun et al., 2023b), and FAFED (Wu et al., 2023) replace SGD with the Adam optimizer for the local training phase, exemplifying the utility of local adaptive optimizations in FL.\nHowever, existing methods in adaptive FL still rely on traditional synchronous aggregation approaches, where the server must wait for all participating clients to complete their local training before global updates. This reliance presents a significant challenge to the practical implementation of adaptive FL methodologies, as the server is required to wait until slower clients, which may have limited computation or communication capabilities. While asynchronous FL strategies such as FedBuff (Nguyen et al., 2022) and FedAsync (Xie et al., 2019) have been investigated to improve the scalability and to study the impact of client delays on the convergence of SGD-based FL algorithms, the specific implications of asynchronous delays on nonlinear adaptive gradient operations are not completely understood. This motivates us to explore the following question:\nCan we develop an asynchronous method for adaptive federated optimization (with provable guarantees) that enhances training efficiency and is resilient to asynchronous delays?"}, {"title": "2. Related Work", "content": "Federated learning. FL, as introduced by McMahan et al. (2017), has become a pivotal framework for collaboratively training machine learning models on edge devices while keeping local data private. Following the initial FedAvg algorithm, several works studied the theoretical analysis and empirical performance of it (Lin et al., 2018; Stich, 2018; Li et al., 2019a; Karimireddy et al., 2020; Wang & Joshi, 2021; Yang et al., 2021), and a range of works aim to improve FedAvg from different perspectives, such as reducing the impact of data heterogeneity (Karimireddy et al., 2020; Acar et al., 2021; Wang et al., 2020b), saving the communication overhead (Reisizadeh et al., 2020; Jhunjhunwala et al., 2021), and adjusting the parameter aggregation procedure (Tan et al., 2022; Wang & Ji, 2023).\nAdaptive FL optimizations and adaptive updates. Besides traditional SGD-based methods, there is a line of works focusing on adaptive updates in FL. A local adaptive FL method with momentum-based variance-reduced gradient was used in FAFED (Wu et al., 2023). Li et al. (2023) proposed a framework for local adaptive gradient methods in FedDA. FedLALR (Sun et al., 2023a) uses local adaptive optimization in FL with local historical gradients and periodically synchronized learning rates. FedLADA (Sun et al., 2023b) is an efficient local adaptive FL method with a locally amended technique. Jin et al. (2022) developed novel adaptive FL optimization methods from the perspective of dynamics of ordinary differential equations. Moreover, Reddi et al. (2021) introduced FedAdagrad, FedAdam and FedYogi, and Wang et al. (2022b) proposed FedAMS for global adaptive FL optimizations. Several works of global adaptive learning rate (Jhunjhunwala et al., 2023) and adaptation in aggregation weights (Tan et al., 2022; Wang & Ji, 2023) are also related to adaptive learning rate adjustment.\nAsynchronous SGD and asynchronous FL. There have been extensive studies over the years about asynchronous optimization techniques, including asynchronous SGD and its various adaptations. For example, Hogwild (Niu et al., 2011) includes an applicable lock-free, coordinate-wise asynchronous method and has been widely used in multi-thread computation. A body of works focuses on the theoretical analysis and explorations of asynchronous SGD (Mania et al., 2017; Nguyen et al., 2018; Stich et al., 2021; Leblond et al., 2018; Glasgow & Wootters, 2022) and discusses the gradient delay in the convergence rate (Avdiukhin & Kasiviswanathan, 2021; Mishchenko et al., 2022; Koloskova et al., 2022; Wu et al., 2022). Within federated learning, innovative asynchronous aggregation algorithms like FedAsync (Xie et al., 2019) allow the server to update the global model once a client finishes local training, and FedBuff (Nguyen et al., 2022) introduces a buffered aggregation approach. There are also many works focusing on algorithms based on FedBuff with theoretical and/or empirical analysis (Toghani & Uribe, 2022; Ortega & Jafarkhani, 2023; Wang et al., 2023), and other aspects of asynchronous FL (Chen et al., 2020b; Yang et al., 2022; Bornstein et al., 2023). Although adaptive FL and asynchronous FL have achieved the success of training large machine learning models with desirable numerical performance, the exploration of asynchronous updates in the context of adaptive FL has not been well-studied yet. In this paper, we start with the asynchronous update framework in adaptive FL and further integrate delay-adaptive learning rate scheduling into it."}, {"title": "3. Preliminaries", "content": "Federated learning. A general FL framework considers a distributed optimization problem across N clients:\n$\\min_{x \\in \\mathbb{R}^d} f(x) := \\frac{1}{N} F(x) = \\sum_{i=1}^N E_{\\xi_i \\sim D_i} [F_i(x; \\xi_i)],$ (1)\nwhere $x \\in \\mathbb{R}^d$ is the model parameter with d dimensions, $F_i(x)$ is the loss function corresponding to client i, $D_i$ is the local data distribution on client i. The objective in Eq. (1) can be interpreted as setting $p_i = \\frac{1}{N}$ for all clients in another commonly used objective function in FL, i.e., $f(x) = \\sum_{i=1}^N p_iE_{\\xi_i \\sim D_i} [F_i(x; \\xi_i)]$ with $p_i \\geq 0$ and $\\sum_{i=1}^N p_i = 1$. FedAvg (McMahan et al., 2017) is a typical synchronous FL algorithm to solve Eq. 1, where in the t-th global round, each participating client i performs local SGD updates as follows:\n$\\begin{aligned}x_{i,k+1} &= x_{i,k} - \\eta_l \\nabla F_i(x_{i,k}; \\xi) \\text{ and } x_{i,0} = x_t\\end{aligned},$ (2)\nwhere $\\eta_l$ is the learning rate. After several local steps (e.g., K steps of local training), the server performs a global averaging step after receiving all the updates from assigned clients in $S_t$, i.e., $x_{t+1} = \\frac{1}{|S_t|} \\sum_{i \\in S_t} x_{i,K}$.\nAdaptive optimization and its application to FL. Several adaptive optimizers have been proposed to improve the convergence of SGD, such as Adagrad (Duchi et al., 2011), RMSProp (Tieleman et al., 2012), Adam (Kingma & Ba, 2015) and its variant AMSGrad (Reddi et al., 2018). In general machine learning optimization, Adam effectively inherits the benefits of both momentum and RMSProp optimizers, leading to better empirical performance in practical applications.\nReddi et al. (2021) first introduced adaptive federated optimization, which applies the adaptive optimizers during the global aggregation steps in FL. FedAMSGrad (Tong et al., 2020) and FedAMS (Wang et al., 2022b) further adjust the effective global learning rate in adaptive FL. Specifically, FedAdam and FedAMS take the idea of viewing the difference of local updates $\\triangle_t^{\\text{sync}} = \\frac{1}{|S_t|} \\sum_{i \\in S_t} (x_{i,K} - x_t)$ as a pseudo-gradient, and applies the Adam or AMSGrad optimizer when updating global model $x_{t+1}$ using $\\triangle_t^{\\text{sync}}$, i.e.,\n$\\begin{aligned}m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) \\triangle_t^{\\text{sync}},\\\\\nv_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) (\\triangle_t^{\\text{sync}} \\odot \\triangle_t^{\\text{sync}}),\\\\\nx_{t+1} &= x_t + \\eta \\frac{m_t}{\\sqrt{v_t} + \\epsilon} \\quad \\text{(FedAdam)},\\\\\nv_t &= \\max(v_{t-1}, v_t), x_{t+1} = x_t + \\eta \\frac{m_t}{\\sqrt{v_t} + \\epsilon} \\quad \\text{(FedAMS)},\\end{aligned}$\nwhere $\\odot$ denotes the element-wise product for two vectors, and for vectors $x, y \\in \\mathbb{R}^d$, $\\sqrt{x}, x/y, \\max(x, y)$ denote the element-wise square root, division, and maximum operation of the vectors.\nAsynchronous updates in FL. In asynchronous FL, clients train the model asynchronously and update it to the server once it finishes several steps of local training. FedBuff (Nguyen et al., 2022) has improved the global update steps with the concept of buffer based on the initial FedAsync baseline (Xie et al., 2019). In FedBuff, it requires the framework maintain a given number (referred to as the concurrency $M_c$) of clients that are actively local training. At the t-th global round, after the client i finishes local training, it sends its local update $\\triangle_i = x_{i,K} - x_t$ to the server, where t - $\\tau_i$ is the global round where client i starts local training and $0 \\leq \\tau_i < t$. The server simultaneously accumulates the model update $\\triangle_i$ to the global update direction $\\triangle_t \\leftarrow \\triangle_t + \\triangle_i$, and sends the latest global model to a randomly selected client who is idle. When the number of accumulated updates reaches the given buffer size of M, the server updates the global model with the averaging $\\triangle_t/M$. Meanwhile, clients who have not finished their local training will continue their training based on the previously received global model, and are not affected by the global model updates on the server. During the training, the framework always maintains a fixed number ($M_c$) of clients who are conducting local training. This is achieved by having the server randomly sample an idle client for training each time a client completes its local training and sends its update to the server.\nDiscussion about synchronous and asynchronous methods. Synchronous FL typically offers consistency and stability, i.e., all client updates are based on the same global model, and this consistency may lead to a more stable and predictable learning process. However, when there exist one or a few clients that are much slower than the majority of clients, which often happens in large-scale systems, synchronous FL can be inefficient since every client needs to wait for the slowest client before progressing with the next round of training. Asynchronous FL is more efficient when clients have system heterogeneity such as diverse computational capabilities or communication bandwidth. In FL, if the delay among clients is relatively uniform, synchronous FL tends to be more stable and efficient. Overall, the choice between synchronous and asynchronous FL hinges on specific needs and system characteristics. Synchronous FL is ideal in homogeneous systems, while asynchronous FL is advantageous in heterogeneous systems with potential straggler clients."}, {"title": "4. Proposed Method: FADAS", "content": "Although adaptive FL methods achieve promising convergence and generalization performance theoretically and empirically, the existing adaptive FL methods are restricted to synchronous settings, as the server needs to wait for all the assigned clients to finish their local updates for aggregation and then update the global model. However, those synchronous adaptive FL algorithms are susceptible to the presence of stragglers, where slower clients with insufficient computation or communication speed impede the progress of the global update.\nTo improve the efficiency and resiliency of adaptive FL in the presence of stragglers, we introduce FADAS, a Federated Adaptive ASynchronous optimization method. Similar to FedAdam and FedAMS, the proposed FADAS algorithm takes the model update difference from clients as a pseudo-gradient and it updates the global model following an Adam-like update scheme. Algorithm 1 summarizes the details. FADAS keeps the local asynchronous training scheme as FedBuff and maintains the concept of concurrency and buffer size for flexible control of the number of active clients and the frequency of global model update. In FADAS, after the server aggregates to obtain model update difference $\\triangle_t$, it finds an adaptive update direction, whose components are computed based on the AMSGrad optimizer (Reddi et al., 2018) as follows:\n$\\begin{aligned}m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) \\triangle_t,\\\\\nv_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) \\triangle_t \\odot \\triangle_t,\\\\\nv_t &= \\max(v_{t-1}, v_t).\\end{aligned}$ (3)\nIn general, FADAS enables clients to conduct local training in their own pace, and the server aggregates the asynchronous updates for global adaptive updates. It improves the training efficiency and scalability of over synchronous adaptive FL while inheriting the advantage of adaptive optimizer of reducing oscillations and stabilizing the optimization process.\nAlthough FADAS applies asynchronous local training for adaptive FL, the global adaptive optimizer adjusts the global update direction only based on local updates but without considering the impact of asynchronous delay. Intuitively, a large asynchronous delay from a client means that this model update is made based on an outdated global model. This may lead to a negative effect on the convergence, and later we also verify this intuition in the theoretical analysis. This inspires us to apply a delay-adaptive learning rate adjustment to improve the resiliency of FADAS to stragglers with large delays. Specifically, we let the server track the delay for every received model update and adopt a delay-adaptive learning rate. We highlight the delay-adaptive steps in Algorithm 1 and those steps are executed with almost no extra overhead.\nDelay tracking. In general, the server manages the delay record for each client through straightforward time-stamping. For example, the server records the global update round t' when it broadcasts the current global model $x_t$ to client i, the client conducts local training with $x_t$. When the server receives the first $\\triangle$ from client i at round $t > t'$, the gradient delay for $\\triangle$, which is $\\tau_i^t = t - t'$, is updated and recorded on the server.\nDelay-adaptive learning rate. Assume that for each global update round t, clients in the set $M_t$ ( $|M_t| = M$) send updates to the server. The received model updates at global round t have a maximum delay $\\tau^{\\text{max}}_t$ defined as $\\tau^{\\text{max}}_t := \\max{\\{\\tau_i, i \\in M_t\\}}$. Suppose we set up a delay threshold $T_c$, we can define a delay-adaptive learning rate as:\n$\\eta_t = \\begin{cases}\\eta & \\text{if } \\tau^{\\text{max}}_t < T_c,\\\\min \\left\\{\\eta, \\frac{\\eta}{\\tau^{\\text{max}}_t} \\right\\} & \\text{if } \\tau^{\\text{max}}_t > T_c.\\end{cases}$ (4)\nIntuitively, this design implies that we need to turn the learning rates down for the model update $\\triangle_t$ with larger current-step delays. Specifically, if the current-step maximum delay $\\tau^{\\text{max}}_t$ is larger than a given threshold $T_c$, we scale down the learning rates for this step in proportional to $1/\\tau^{\\text{max}}_t$ (also capped by a constant learning rate $\\eta$) to avoid that the high-latency update worsens the convergence. Comparison with FedAsync (Xie et al., 2019). FedAsync (Xie et al., 2019) also studies delay-adaptive weighted averaging during global model updates. In FedAsync, after the server receives a local model $x_{\\text{new}}$, it updates $x_t$ based on $x_t = (1 - \\alpha_t) x_{t-1} + \\alpha_t x_{\\text{new}}$, and FedAsync includes a hinge strategy of $\\alpha_t$ which is similar to our delay-adaptive strategy in Eq. (4). However, unlike FedAsync, where the server updates the global model immediately upon receiving a new update from a client, FADAS updates the global model less frequently. In FADAS, the server accumulates"}, {"title": "5. Theoretical Analysis", "content": "In this section, we delve into the theoretical analysis of our proposed FADAS algorithm. We first introduce some common assumptions required for the analysis. Subsequently, we present the analysis in two parts: one focusing on FADAS without delay adaptation, as discussed in Section 5.1, and the other on the delay-adaptive FADAS in Section 5.2.\nAssumption 5.1 (Smoothness). Each objective function on the i-th worker $F_i(x)$ is L-smooth, i.e., $\\forall x, y \\in \\mathbb{R}^d$,\n$\\|\\nabla F_i(x) - \\nabla F_i(y) \\| \\leq L\\|x-y\\|$.\nAssumption 5.2 (Bounded Variance). Each stochastic gradient is unbiased and has a bounded local variance, i.e., for all $x, i \\in [N]$, we have $E [\\|\\nabla F_i(x; \\xi) - \\nabla F_i(x)\\|]^2 \\leq \\sigma^2$, and the loss function on each worker has a global variance bound, $\\frac{1}{N} \\sum_{i=1}^N \\|\\nabla F_i(x) - \\nabla f(x)\\|]^2 \\leq \\sigma_g^2$.\nAssumption 5.1 and 5.2 are standard assumptions in federated non-convex optimization literature (Li et al., 2019b; Yang et al., 2021; Reddi et al., 2021; Wang et al., 2022b; Wang & Ji, 2023). The global variance upper bound of $\\sigma_g$ in Assumption 5.2 measures the data heterogeneity across clients, and a global variance of $\\sigma_g^2 = 0$ indicates a uniform data distribution across clients.\nAssumption 5.3 (Bounded Gradient). Each loss function on the i-th worker $F_i(x)$ has G-bounded stochastic gradient on l2 norm, i.e., for all $\\xi$, we have $\\|\\nabla F_i(x; \\xi)\\| \\leq G$.\nAssumption 5.3 is necessary for adaptive gradient algorithms for both general (Kingma & Ba, 2015; Chen et al., 2020a), distributed (Wang et al., 2022a) and federated adaptive optimization (Reddi et al., 2021; Wang et al., 2022b; Sun et al., 2023b). This is because the effective global learning rate for adaptive gradient methods is $\\frac{\\eta}{\\sqrt{v_t} + \\epsilon}$, and we need a lower bound for $\\sqrt{v_t} + \\epsilon$ to guarantee that the effective learning rate does not vanish to zero.\nAssumption 5.4 (Bounded Delay of Gradient Computation). Let $\\tau_i^t$ represent the delay for global round t and client i which is applied in Algorithm 1. The delay $\\tau_i^t$ is the difference between the current global round t and the global round at which client i started to compute the gradient. We assume that the maximum gradient delay (worst-case delay) is bounded, i.e., $\\tau_{\\text{max}} = \\max_{t \\in [T], i \\in [N]} {\\tau_i^t} < \\infty$.\nAssumption 5.4 is common in analyzing asynchronous and anarchic FL algorithms which incorporate the gradient delays into their algorithm design (Koloskova et al., 2022; Yang et al., 2021; Nguyen et al., 2022; Toghani & Uribe, 2022; Wang et al., 2023).\nAssumption 5.5 (Uniform Arrivals of Gradient Computation). Let the set $M_t$ (with size M) include clients that transmit their local updates to the server in global round t. We assume that the clients' update arrivals are uniformly distributed, i.e., from a theoretical perspective, the M clients in $M_t$ are randomly sampled without replacement from all clients [N] according to a uniform distribution\u00b9.\nAssumption 5.5 is also discussed in Anarchic FL (Yang et al., 2022), which has been utilized to analyze the AFA-CD algorithm proposed therein."}, {"title": "5.1. Convergence Rate of FADAS", "content": "For expository convenience, in the following, we provide the theoretical convergence analysis of FADAS under the case of $\\beta_1 = 0$. The theoretical analysis and the proof for the general case of $0 < \\beta_1 < 1$ are provided in Appendix A. We define the average of the maximum delay over time as $\\tau_{\\text{avg}} = \\frac{1}{T} \\sum_{t=1}^T \\tau^{\\text{max}}_t = \\frac{1}{T} \\sum_{t=1}^T \\max_{i \\in [N]} {\\tau_i^t}$ which is useful in our analysis.\nTheorem 5.6. Under Assumptions 5.1-5.5, let T represent the total number of global rounds, K be the number of local SGD training steps and M be the number of the accumulated updates (buffer size) in each round. If the learning rate $\\eta$ and $\\eta_l$ satisfies $\\eta \\eta_l \\leq \\min { \\frac{\\epsilon^3 M(N-1)}{180 C G N(N-M) \\tau_{\\text{max}} K L}, \\frac{\\epsilon^2 M(N-1)}{12 \\sqrt{C G N(M-1)} \\tau_{\\text{max}} K L}} $, $\\eta_l \\leq \\sqrt{\\frac{\\epsilon^2}{360 C G \\tau_{\\text{max}} K L}}$, then the global iterates {xt}=1 of Algorithm 1 satisfy\n$\\frac{1}{T} \\sum_{t=1}^T E[\\|\\nabla f(x_t)\\|^2] \\leq O(\\frac{\\sqrt{F_0}}{T \\sqrt{K M}} + \\frac{\\sqrt{F_0} g}{T \\sqrt{K M}} + \\frac{F G}{T \\sqrt{V M}} + \\frac{F_{\\tau_{\\text{max}}} \\tau_{\\text{avg}}}{T V M}})$ (6)\nRemark 5.8. Corollary 5.7 suggests that given sufficiently large T and relatively small worst-case delay $\\tau_{\\text{max}}$, the proposed FADAS (without delay-adaptive learning rate) achieves a convergence rate of $O(\\frac{1}{\\sqrt{T K M}})$ w.r.t. T and M.\nComparison to asynchronous FL methods. Compared with the analysis for FedBuff in Nguyen et al. (2022) and Toghani & Uribe (2022), our analysis for FADAS obtains a relaxed dependency on the worst-case gradient delay $\\tau_{\\text{max}}$, and FADAS achieves a slightly better rate on non-dominant term than $O(\\frac{\\tau}{\\sqrt{T K M}})$ obtained in Toghani & Uribe (2022). Moreover, Wang et al. (2023) also studied the convergence for FedBuff with relaxed requirements for $\\tau_{\\text{max}}$, and our FADAS achieves a similar convergence of $O(\\frac{1}{\\sqrt{T K M}} + \\frac{\\tau_{\\text{max}} \\tau_{\\text{avg}}}{V T M})$ as in Wang et al. (2023). It is worthwhile to mention that recently CA2FL (Wang et al., 2023) improves the convergence of asynchronous FL under heterogeneous data distributions, while the improvement is obtained by using the cached variable on the server for global update calibration.\nNote that when $\\tau_{\\text{max}}$ in Eq. (6) is large, particularly in cases where $\\tau_{\\text{max}} > \\sqrt{VT}$, then $\\frac{\\tau_{\\text{max}} \\tau_{\\text{avg}}}{V T M}$ becomes the dominant term in the convergence rate. This implies that a large worst-case delay $\\tau_{\\text{max}}$ may lead to a worse convergence rate. In the next subsection, we demonstrate that the delay-adaptive learning rate strategy can relieve this problem and enhance FADAS with better resilience to large worst-case delays."}, {"title": "5.2. Convergence Rate of Delay-adaptive FADAS", "content": "In the following, we provide the convergence analysis for delay-adaptive FADAS with $\\beta_1 = 0$. To get started, we first define the median of the maximum delay over all communication rounds [T]:\n$\\tau_{\\text{median}} = \\text{median}{\\{\\tau^{\\text{max}}_1, \\tau^{\\text{max}}_2, ..., \\tau^{\\text{max}}_T\\}}.$ (7)\nThe definition of $\\tau_{\\text{median}}$ implies that the number of global update rounds that have a maximum delay greater than $\\tau_{\\text{median}}$ is less than half of the total number of global updates T. With this definition, we present the following theorem characterizing the convergence rate of delay-adaptive FADAS.\nTheorem 5.9. Under Assumptions 5.1\u20135.5, let T be the total number of global rounds, K be the number of local SGD training steps and M be the number of the buffer size in each round. If the learning rate $\\eta$ and $\\eta_l$ satisfies $\\eta \\eta_l < \\min{\\{\\frac{\\epsilon^3 M(N-1)}{60 C G N(N-M) \\tau_{\\text{max}} K L}, \\frac{\\epsilon^2 M(N-1)}{12 \\sqrt{C G N(M-1)} \\tau_{\\text{max}} K L}\\}}$, $\\eta_l \\leq \\sqrt{\\frac{\\epsilon^2}{360 C G \\tau_{\\text{max}} K L}}$ and $\\eta < \\sqrt{\\frac{\\epsilon}{M}}$, then the global iterates {xt}=1 of Algorithm 1 satisfy\n$\\frac{1}{T} \\sum_{t=1}^T \\frac{1}{N_t} E[\\|\\nabla f(x_t)\\|^2] \\leq \\frac{4 C G}{T} \\frac{F + \\eta \\eta_l K T}{M \\epsilon^3} + \\frac{20 C G \\eta \\eta_l K L^2 (\\sigma^2 + 6 K \\sigma_g^2)}{M \\epsilon^3} + \\frac{8 C G \\eta^2 \\eta_l K L^2 T T_{\\text{avg}}}{T M \\epsilon^3} \\sum_{t=1}^T \\frac{1}{N_t} + \\frac{N-M}{N-1} \\frac{\\sigma^2}{M \\epsilon^3} [15 \\eta^2 K^2 L^2 (\\sigma^2 + 6 K \\sigma_g^2) + 3 K \\sigma_g^3] + \\frac{N-M}{N-1} {\\frac{8 C G \\eta_t^2 + 6 K \\sigma_g^2}{M e^2}}.$ (8)\nwhere $F = f(x_1) - f^*$, $f^* = \\min_x f(x) > -\\infty$ and $C_G = \\frac{1}{K} K G + \\epsilon$.\nCorollary 5.10. If we pick $T_c = \\tau_{\\text{median}}$, the global learning rate $\\eta = \\Theta(\\frac{T_c \\sqrt{F}}{\\sqrt{T K M} (\\sigma^2 + K \\sigma_g^2)})$ and $\\eta_l = \\Theta(\\frac{\\sqrt{F}}{\\sqrt{T K} (\\sigma^2 + K \\sigma_g^2)})$, then for sufficiently large T, the global iterates {xt}=1 of Algorithm 1 satisfy\n$\\frac{1}{T} \\sum_{t=1}^T \\frac{1}{N_t} E[\\|\\nabla f(x_t)\\|^2] \\leq O(\\frac{\\sqrt{F_0}}{\\sqrt{T K M}} + \\frac{\\sqrt{F_0} g}{\\sqrt{T K M}} + \\frac{F G T_c}{T \\sqrt{V M}} + \\frac{F T_{\\text{avg}} F (T_c^2 + T_c T_{\\text{avg}})}{T}+).$ (9)\nRemark 5.11. Corollary 5.10 suggests that with sufficiently large T, delay-adaptive FADAS also achieves a convergence rate of $O(\\frac{1}{\\sqrt{T K M}})$ w.r.t. T and M.\nRemark 5.12. Compared to the convergence rate in Corollary 5.7, the convergence rate in Corollary 5.10 does not rely on the (possibly large) worst-case delay $\\tau_{\\text{max}}$. In cases where $T_c = \\tau_{\\text{median}} \\approx \\tau_{\\text{avg}} \\ll \\tau_{\\text{max}}$, Corollary 5.10 relaxes the requirement from $\\tau_{\\text{max}}$ to $\\tau_{\\text{median}}$ for achieving the desired convergence rate. Since $\\tau_{\\text{median}}$ describes the median of $\\tau^{\\text{max}}_t = \\max_{i \\in [N]} {\\tau_i^t}$ in each round t, the convergence rate in Corollary 5.10 is less sensitive to stragglers who may cause a large worst-case delay in the system."}, {"title": "6. Experiments", "content": "We explore the performance of our proposed FADAS algorithm through experiments on vision and language tasks, using the CIFAR-10/100 (Krizhevsky et al., 2009) datasets with ResNet-18 model (He et al., 2016) for vision tasks, and applying the pre-trained BERT base model (Devlin et al., 2018) for fine-tuning several datasets from"}]}]}