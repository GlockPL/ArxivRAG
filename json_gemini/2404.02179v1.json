{"title": "Distributed and Rate-Adaptive Feature Compression", "authors": ["Aditya Deshmukh", "Venugopal V. Veeravalli", "Gunjan Verma"], "abstract": "We study the problem of distributed and rate-adaptive feature compression for linear regression. A set of distributed sensors collect disjoint features of regressor data. A fusion center is assumed to contain a pretrained linear regression model, trained on a dataset of the entire uncompressed data. At inference time, the sensors compress their observations and send them to the fusion center through communication-constrained channels, whose rates can change with time. Our goal is to design a feature compression scheme that can adapt to the varying communication constraints, while maximizing the inference performance at the fusion center. We first obtain the form of optimal quantizers assuming knowledge of underlying regressor data distribution. Under a practically reasonable approximation, we then propose a distributed compression scheme which works by quantizing a one-dimensional projection of the sensor data. We also propose a simple adaptive scheme for handling changes in communication constraints. We demonstrate the effectiveness of the distributed adaptive compression scheme through simulated experiments.", "sections": [{"title": "I. INTRODUCTION", "content": "A prevalent way in which machine learning models are trained involves collecting data from various relevant sources, and training the models on the aggregated data. However, in many applications, the input data is often collected from distributed sources at inference time. Examples include, the Internet of Things (IoT) networks, security systems with surveillance sensors, and driverless cars collecting data from sensors and receiving data from wireless receivers. In these applications, the volume of data is generally high and decisions are time-sensitive, and so it is important to have low latency. Moreover, when the data is being communicated through wireless channels, bit-rates can be quite low either for energy conservation purposes or because of poor channel conditions. Thus, it is imperative to optimize the data-stream pipelines in order to provide maximum information relevant to the performance of the downstream task. Moreover, in practice these pipelines are also subject to changes in bit-rates, and so it is necessary for the solutions to be adaptive to these changes.\nIn this work, we try to answer the following question:\nHow to maximize information (relevant to the downstream task) received at a pretrained model at inference time when input data is collected in a distributed way through communication-constrained channels that are subject to change?\nWe consider a distributed sensor network that consists of m sensors and a fusion center. The sensors collect multi-modal observations, compress and quantize them, and send them to the fusion center through communication-constrained channels. The fusion center contains a learning model, which is pretrained on a training dataset of the uncompressed multi-modal data. We consider the goal of designing efficient feature compressors that can adapt to dynamic communication constraints, while maximizing inference performance at the fusion center. In order to design the compressors, we assume that we have access to a calibration dataset, which may be a subset of the dataset on which pretrained model is trained.\nThere is considerable literature on distributed compression for detection and estimation when the underlying sensor data distributions (or families of distributions) are known (see, e.g., [1]-[3]). In this work, we do not assume knowledge of the sensor data distributions.\nRecently, a line of works have studied the problem of designing distributed compression/quantization schemes for machine learning. A customized quantization scheme for diagonal linear discriminant analysis in a distributed sensor setting was proposed by [4]. [5] showed that the problem of designing optimal distributed feature compression schemes is NP-hard and proposed deep neural-network (DNN) based solutions for the task of classification. [6] propose a task-relevant feature extraction framework based on the information bottleneck principle, and adopt the distributed information bottleneck framework to formalize a single-letter characterization of the optimal rate-relevance trade-off for distributed feature encoding. [6] also proposed DNN-based solutions for their proposed framework. While these works demonstrate that inference performance can be maintained under high levels of compression, the proposed schemes are not adaptive, i.e., if the communication constraints change, the proposed compression schemes need to be re-trained, which may be impractical for delay-sensitive applications.\nOur contributions are as follows:\n1) We propose a framework for designing optimal compression schemes when the pretrained model is a linear regressor, which also extends to the general learning model case. To the best of our knowledge, this is the first work which analyzes distributed compression schemes for distributed linear regression. Assuming knowledge"}, {"title": "II. PROBLEM SETUP", "content": "We first consider the case where the pretrained model at the fusion center is a linear regressor.\nConsider the following linear model:\n$\\hat{y} = (x, \\beta)$ (1)\nwhere $\\hat{y} \\in \\mathbb{R}$ is the response variable, $x \\in \\mathbb{R}^d$ is the regressor, and $\\beta \\in \\mathbb{R}^d$ is the learned parameter.\nThe sensors are assumed to observe different features of the regressor x. Let the ith sensor observe features indexed by $S_i \\subset [d]$. We assume that $S_i$'s are non-empty and pairwise disjoint. Let $d_i = |S_i|$. We denote the observation of ith sensor by $x^{(i)} \\in \\mathbb{R}^{d_i}$:\n$x^{(i)} = [x_r, r \\in S_i]$. (2)\nAssume that the ith sensor quantizes its observation using $B_i$ bits (equivalently, $K_i = 2^{B_i}$ levels), by using a quantizer of the form $Q_i : \\mathbb{R}^{d_i} \\rightarrow \\{c_1,...,c_{K_i}\\}$, where $c_k$'s are the quantization vectors (to be optimized) lying in $\\mathbb{R}^{d_i}$. Let the quantized observation of the ith sensor be denoted as $\\mathbf{x}^{(i)} \\in \\mathbb{R}^{d_i}$:\n$\\mathbf{x}^{(i)} = Q_i(x^{(i)})$. (3)\nLet the complete quantization output of the regressor x through this distributed quantization scheme be denoted as $\\mathbf{x}$.\nWith slight abuse of notation, let the calibration data be denoted as $\\{x_j\\}_{j=1}^n$ (the individual components of $x_j$ will be denoted by $x_{j,r}$). Let $\\hat{y}_j = (x_j, \\beta)$ and $\\tilde{y}_j = (\\mathbf{x}_j, \\beta)$ be the estimated response for the unquantized and quantized regressors $x_j$ and $\\mathbf{x}_j$, respectively. We represent n such equations in the following matrix form:\n$Y = X\\beta \\quad \\text{and} \\quad Y = \\mathbf{X}\\beta$ (4)\nwhere jth row of the matrices X and $\\mathbf{X}$ are $x_j$ and $\\mathbf{x}_j$, respectively. For analysis purposes, let $X^{(i)}$ and $\\mathbf{X}^{(i)}$ be the matrices with jth row as $x_j^{(i)}$ and $\\mathbf{x}_j^{(i)}$, respectively, $j=1,...,n$. Let the corresponding contributions of ith sensor be denoted by\n$\\hat{Y}^{(i)} = X^{(i)}\\beta^{(i)} \\quad \\text{and} \\quad \\tilde{Y}^{(i)} = \\mathbf{X}^{(i)}\\beta^{(i)}$ (5)\nrespectively. Note that we denote random variables with a boldface font. A reasonable objective is to design the quantizers $Q_1,..., Q_m$ in order to minimize the MSE:\n$\\min_{Q_1,..., Q_m} E[(\\tilde{\\mathbf{y}} - \\mathbf{y})^2]$ (6)\nHere, the expectation is taken over the distribution of the input x, conditioned on the learned parameter $\\beta$ being fixed. However, the underlying data distribution is unknown in most practical cases. Conventionally, the method of empirical risk minimization (ERM) is applied to approximately solve an objective of the form in (6). However, as we argue in the following remark, the ERM approach does not provide a complete solution for the problem considered.\nRemark 1. The empirical form of the optimization problem in (6) is\n$\\min_{Q_1,..., Q_m} \\frac{1}{N} \\sum_{j=1}^N (\\tilde{y}_j - y_j)^2$ (7)\n$\\min_{Q_1,..., Q_m} \\frac{1}{N} \\sum_{j=1}^N (\\sum_{i=1}^m (\\mathbf{x}_j^{(i)} - x_j^{(i)}, \\beta^{(i)}))^2$ (8)\nAlthough it is possible to obtain a local minimum of this empirical objective through best-response dynamics by considering a potential game (see [8]), the solution does not capture the entire form of the quantizers $Q_i(.),$ but only the provides us with the quantizers' outputs on the calibration data, i.e., $Q_i(x^{(i)})$. Particularly, the formulation in (7) does not capture the constraint that at inference time, the ith quantizer has access to data only at the ith sensor.\nHence, we first analyze the population-based objective given in (6), and obtain the structure of the optimal quantizers in the following lemma.\nLemma 1. The optimal quantizers for optimization problem in (6) simultaneously satisfy the following structure (which is provided for an arbitrary ith sensor):\n$Q_i(x^{(i)}) = c_k^{(i)}, \\text{if} \\quad x^{(i)} \\in D_k^{(i)}, \\text{for} \\quad k \\in [K_i]$, (9)\nwhere $\\mathbf{c}_k^{(i)}$ and $D_k^{(i)}$ are the minimizers of\n$\\min_{\\mathbf{c}_k^{(i)}, D_k^{(i)}, k=1}^{K_i} \\int_{D_k^{(i)}} f_i(\\mathbf{c}_k^{(i)}, x^{(i)}) p_i(x^{(i)}) dx^{(i)}$, (10)"}, {"title": "III. GENERAL LEARNING MODEL", "content": "We now consider a general pretrained learning model at the fusion center:\n$\\hat{y} = f(x; \\theta)$ (30)\nwhere $x \\in \\mathbb{R}^{d_{in}}$ is the input, $y \\in \\mathbb{R}^{d_{out}}$ is the output, and $\\theta$ denotes the learned parameters of the model. Let the loss function minimized during training be denoted by $l(\\hat{y}, y)$, where y denotes the ground-truth label in the training dataset. It is assumed that the loss function l is differentiable with respect to the input x. Following the conclusion of the previous section, we posit that the sensor observations should be projected (or encoded) first in a low-dimensional space and then quantized. The fusion center decodes the received quantized encoded observations and then applies the learned model to produce the output.\nNote that the problem of designing optimal encoders and decoder is quite difficult for the general learning model. We propose using VQ-VAEs [7] for this purpose. VQ-VAEs have shown great empirical success in compressing images and audios (for the purpose of reconstruction) in an unsupervised fashion, as well as being good generative models for generating images and audio signals. In this work, we demonstrate the effectiveness of VQ-VAEs in quantizing sensor inputs in the distributed setting, when the downstream task is not re-construction, but a more general task captured by a pretrained model.\nA VQ-VAE architecture comprises of an encoder E, a vector-quantizer equipped with a codebook and a decoder D. Let $z_e(x) = E(x)$ be the latent representations generated by the encoder. Typically, the latent representation takes the form of a tensor in $R^{h \\times w \\times d_1}$. We term the following values as pixels of the latent representation:\n$[z_e(x)]_{i,j} \\in R^{d_1}$. (31)\nThe sizes of first two dimensions, h and w, are fixed given the input size $d_{in}$ and the encoder. The last dimension $d_1$ is a hyper-parameter, which can be varied. Let the codebook be represented by a set of K vectors in $R^{d_1}: \\{c_1,...,c_K\\}$. The vector quantizer acts along the last dimension of $z_e(x)$ and outputs $z_q(x)$:\n$[z_q(x)]_{i,j} = c_{k_{i,j}}$, (32)\nwhere $k_{i,j} \\in \\text{arg} \\min_{t \\in [K]} || [z_e(x)]_{i,j} - c_t ||_2$. (33)\nLet the output of the decoder be $\\hat{x} = D(z_q(x))$. Typically, VQ-VAEs are trained with the goal of minimizing reconstruction loss.\nIn the distributed setting, the VQ-VAEs components are split up. The encoders and vector-quantizers are located at the sensors. We use super-script (i) to denote a quantity/component at ith sensor. We assume a general form of a decoder D at the fusion center (see Figure 3). Note that this captures the case wherein there are different decoders corresponding to each sensor at the fusion center. The quantized latent representations $z_q^{(i)}(x^{(i)})$ are communicated to the fusion center using $B_i = \\log_2(K_i)$ bits. The fusion center concatenates these quantized latent representations and feeds them into the decoder. The decoder outputs $\\hat{x}$, which is then fed into the pretrained model. Let the calibration data be denoted by $(x_j, y_j), j = 1,...,n$. The whole distributed compression system is trained end-to-end while fixing the pretrained model. Since our goal is associated with the downstream task, we propose the following loss function:\n$L = \\frac{1}{n} \\sum_{j=1}^n l(\\tilde{y}_j, y_j) + \\beta_1 L_i + \\beta_2 L_j$ (34)\nwhere\n$L_i = \\beta_1 ||sg(z_e^{(i)}(x^{(i)})) - z_e^{(i)}(x^{(i)}) ||^2$\n$+ \\beta_2 ||z_e^{(i)}(x^{(i)}) - sg(z_q^{(i)}(x^{(i)}))||^2$ (35)\n$\\tilde{y} = f(\\hat{x}; \\theta)$ (36)\n$\\hat{x} = D(z_q(x))$ (37)\n$z_q(x) = \\text{concat}(z_q^{(1)}(x^{(1)}), ..., z_q^{(m)}(x^{(m)}))$. (38)\nIn (35), sg(.) refers to the stop-gradient operation which blocks gradients from flowing into its argument, and the concat function in (38) is the concatenation of the components into a single tensor/vector. Note that the loss terms on the RHS of (35) are the codebook learning loss and the commitment loss as described in [7]."}, {"title": "IV. CONCLUSION", "content": "We studied the problem of distributed and adaptive feature compression in a distributed sensor network, wherein a set of sensors observe disjoint multi-modal features, compress them, and send them to a fusion center containing a pretrained learning model for inference for a downstream task. To gain insight, we first analyzed the case where the pretrained model is a linear regressor. Assuming knowledge of the underlying data distribution, we obtained structure of the optimal compression scheme. Under a practically reasonable approximation, we leverage the aforementioned structure to develop an algorithm that does not require knowledge of underlying"}]}