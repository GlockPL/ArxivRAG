{"title": "SwarmGPT-Primitive: A Language-Driven Choreographer for Drone Swarms Using Safe Motion Primitive Composition", "authors": ["Vedant Vyas", "Martin Schuck", "Dinushka O. Dahanaggamaarachchi", "Siqi Zhou", "Angela P. Schoellig"], "abstract": "Catalyzed by advancements in hardware and software, drone performances are increasingly making their mark in the entertainment industry. However, designing smooth and safe choreographies for drone swarms is complex and often requires expert domain knowledge. In this work, we introduce SwarmGPT-Primitive, a language-based choreographer that integrates the reasoning capabilities of large language models (LLMs) with safe motion planning to facilitate deployable drone swarm choreographies. The LLM composes choreographies for a given piece of music by utilizing a library of motion primitives; the language-based choreographer is augmented with an optimization-based safety filter, which certifies the choreography for real-world deployment by making minimal adjustments when feasibility and safety constraints are violated. The overall SwarmGPT-Primitive framework decouples choreographic design from safe motion planning, which allows non-expert users to re-prompt and refine compositions without concerns about compliance with constraints such as avoiding collisions or downwash effects or satisfying actuation limits. We demonstrate our approach through simulations and experiments with swarms of up to 20 drones performing choreographies designed based on various songs, highlighting the system's ability to generate effective and synchronized drone choreographies for real-world deployment.", "sections": [{"title": "I. INTRODUCTION", "content": "Autonomous drones have increasingly been deployed at large events such as concerts, championships, and even the opening ceremonies of the Olympic Games [1]\u2013[3]. The appeal of drones as performers lies in their agile nature, which allows them to create striking visual impacts through highly synchronized motion. Coordinated movements in large swarms additionally offer a powerful medium for artistic expression and provide visual sentiment that complements human counterparts in large-scale performances.\nWhile drone swarms are capable of performing agile and synchronized motions, coordinating swarms for artistic movements in drone shows is a challenging problem. The design process must not only ensure that synchronized movements deliver the desired impact but also meet constraints imposed by the drone swarm system. For instance, it must account for smoothness, feasibility, collision avoidance, and downwash effects to ensure the performance is deployable on hardware [4]\u2013[6]. Balancing artistic expression with constraint satisfaction requires expert knowledge and makes the design process non-intuitive and laborious in nature.\nRecent advances in foundation models, facilitated by the availability of large datasets, have led to the emergence of language and visual language models as natural interfaces for human interaction [7]. The underlying semantics and reasoning capabilities of these large-scale models have been increasingly leveraged in robotics. Examples include contextual reasoning for navigation [8], [9], affordance analysis in grasping and manipulation [10], [11], and shaping reward functions and guiding informative data collection for skill acquisition [12]. Despite these successes, reliably integrating foundation models into robotic systems remains challenging any erroneous signal can propagate through feedback loops and result in irreversible consequences [7], [13]. This complexity is further amplified in robot swarm applications and is particularly true for swarms of drones, where any contact between drones immediately leads to catastrophic failures.\nIn our recent work, SwarmGPT [14], we made an initial effort to leverage large language models (LLMs) for intuitive drone swarm choreography designs. Specifically, we used the LLM as an interface to generate high-level choreography plans as waypoints. To ensure safe operation, SwarmGPT incorporates a lower-level safety filter that constrains inputs from the language-based planner to produce collision-free, physically feasible trajectories. While this approach simplifies the choreography design process, waypoint-based prompting can lead to response failures, inconsistent swarm formations, increased inference time and infeasible constellations as the number of drones grows.\nMotivated by prior work [15], [16], we propose SwarmGPT-Primitive, which allows the LLM to compose choreographies based on a library of motion primitives for synchronized and rhythmic performances (Fig. 1). The primitive-based choreography design process allows for more visually compelling compositions while still ensuring safety through a distributed optimization-based safety filter design [17]. The combination of primitive-based motion parametrization and a distributed safety filter enhances the scalability of our approach to larger swarms.\nOur contributions are as follows: First, we introduce SwarmGPT-Primitive, a language-based choreographer that facilitates the creation of complex drone swarm choreographies using a library of motion primitives. Second, we integrate the language-choreographed motion primitives with a state-of-the-art optimization-based safety filter framework to ensure the feasibility and safety of the generated choreographies and show that the primitive-based approach results in more self-consistent performances. Finally, we demonstrate the efficacy of our method through the real-world deployment of different choreographies for swarms of up to 20 drones."}, {"title": "II. PROBLEM STATEMENT", "content": "In this work, we consider a set of N drone performers. Our goal is to design a choreography for the drone swarm that is synchronized to a music piece and is modifiable by a non-expert user through language input. The choreography is generated as a set of position references $r_n$ with n denoting the drone index. The position trajectories of individual drones must be sufficiently smooth for the drones to track and comply with a set of feasibility and safety constraints for real-world deployment.\nThe drone performers in our work are nano-quadrotors (Fig. 1b), of which the dynamics can be represented as\n$\\dot{p_n} = v_n,$\n$m\\dot{v_n} = -mg + R_nf_n,$\n$\\dot{R_n} = R_nS(\\omega_n),$\n$I\\dot{\\omega}_n = I\\omega_n \\times \\omega_n + \\tau_n,$\t(1)\nwhere $p_n \\in R^3$ and $v_n \\in R^3$ are the translational position and velocity, respectively, $R_n \\in R^{3\\times3}$ represents the quadrotor orientation, $\\omega_n \\in R^3$ is the body angular velocity, m is the mass of the quadrotor, $I \\in R^{3\\times3}$ is the inertia matrix, $f_n \\in R^3$ and $\\tau_n \\in R^3$ are the force and the torque generated by the four motors of the quadrotor, $S(\\cdot)$ denotes the skew-symmetric matrix mapping of a vector, and $g \\in R^3$ is the gravitational force vector. Each quadrotor is equipped with a cascaded control system that converts high-level position references $r_n$ to low-level motor commands that determine $f_n$ and $\\tau_n$ and thereby induce desired motions [18]."}, {"title": "III. THE SWARMGPT-PRIMITIVE FRAMEWORK", "content": "In this section, we present our proposed SwarmGPT-Primitive framework for generating safe swarm choreographies from language. An overview of the proposed SwarmGPT-Primitive framework is shown in Fig. 2, which consists of the following core modules: (i) a music processor, (ii) a language-based choreographer, (iii) a motion primitive generator, and (iv) an optimization-based safety filter. We present details of the individual modules in the respective subsections below."}, {"title": "A. Music Processor", "content": "In the music processor, we analyze the waveform of the raw audio file and determine a set of beat times as well as a set of associated audio features to which the choreographies would be synchronized. The beat times are computed based on the novelty function of the waveform, following the spectral-based approach outlined in [19]. Intuitively, the novelty function characterizes the distance between successive signal points of the audio, and gives us a measure of how much tones stand out. We define beat times\n$B = \\{t_0, t_1, ..., t_T\\}$\t(2)\nas the peaks of the novelty function, where T\u2208 N corresponds to the total number of beats. To extract the beats, we use standard peak detection tools from [20]. The time stamps form the basis for all subsequent planning steps and are further annotated with their novelty, decibels relative to full scale (i.e., their loudness) and their respective chords. To estimate chords from the audio track, we make use of the hidden Markov model-based approach described in [19]. Including this information enables planning performances that are linked more closely to the original audio track."}, {"title": "B. Language-Based Choreographer", "content": "Given the extracted beat times and audio features, each choreography is formed from a sequence of motion primitives for the swarm. We use an LLM [21] to compose this sequence based onf parameterized motion primitives. The initial prompt introduces the task, provides the music information, and lists the available primitives such as rotate, helix, spiral and wave with usage examples. Based on these, the LLM selects specific primitives, their parameters, and respective motion start beats $t_i \\in B$ and end beats $t_f \\in B$. We present a detailed discussion of the motion primitives in the following subsection.\nIn case of planning failures such as omitting beat times, using non-existent primitives or when parameters selected by the LLM result in trajectories violating basic physical bounds, the LLM receives a failure report and self-corrects its errors. In addition to self-corrections, after visualizing the performance in either simulation or experiments, users can modify the swarm choreography directly using natural language via additional reprompting.\nThe motion primitives for a swarm of N drones are defined as tuples [15]:\n$MP_m = (t_{m,i},t_{m,f}, \\{c_{m,n}\\}_{n=1}^N, T_m(c, t)),$\t(3)\nwhere m \u2208 N[0,M] is the motion primitive index, $t_{m,i} \\in B$ and $t_{m,f} \\in B$ are the start time and the end time of the motion primitive, respectively, $c_{m,n} \\in R^3$ is a unique configuration vector associated with a particular drone n for the motion primitive m, and $T_m(c,t) : R^3 \\times [t_{m,i}, t_{m,f}] \\rightarrow R^3$ is the position reference trajectory generator. The position reference trajectory for each drone is\n$r_{m,n}(t) = T_m(c_{m,n},t), t \\in [t_{m,i}, t_{m,f}].$\t(4)\nThere are different ways to define primitive trajectory generators. One general formulation for trajectory generators has the following form (with the primitive index m dropped for clarity):\n$T(c_n,t) = M(c_n) + T_{per}(c_n, t) + T_{poly}(c_n, t),$\t(5)\nwhere $M(c_n)$ is constant with respect to time, and $T_{per} (c_n, t)$ and $T_{poly}(c_n, t)$ are defined as follows:\n$T_{per} (c_n, t) = \\sum_{p=1}^{P} (A_p(c_n) sin(\\omega_p t) + B_p (c_n) cos(\\omega_p t)),$\t(6)\n$T_{poly} (c_n, t) = \\sum_{q=1}^{Q} C_q(c_n) t^q.$\t(7)\nIn the general formulation (5), the terms $M(c_n)$, $A_p(c_n)$, $B_p(c_n)$, $C_q(c_n)$, $\\omega_p$, P, and Q are parameters defining the motion primitives.\nNote that, when $C_q(c_n)$ is zero for all q and n, we recover the motion primitive generator defined in [15]. As shown in [15], with the first two terms alone, diverse periodic behaviours such as rigid body rotation and wave patterns can be achieved for rhythmic drone performances. With the addition of $T_{poly}(c_n,t)$, we can further incorporate non-periodic components into the choreography. In general, we can formulate an infinite set of primitives and represent them in the form of (5); four example motion primitives are shown in Fig. 3.\nAt the start of each motion primitive, each drone has to be assigned a unique initial trajectory vector $c_{n,m}$ in $MP_m$. Assignment problems have been extensively studied in combinatorial optimization and can be viewed as minimizing the cost incurred by assigning as many agents to as many tasks as possible given a cost function. In our case, we choose the Euclidean distance between the drones and the next motion primitive's start configuration as our metric. The globally optimal mapping can be found with the Hungarian algorithm [22], with implementation details available in [23].\nIn our approach, a library of motion primitives is instantiated as callable functions. These are exposed to the LLM through a primitive name and a set of parameters which the LLM has control over (Fig. 3). Based on the provided music annotations, the LLM composes motion by selecting motion primitives with appropriate parameters and beat times."}, {"title": "C. Optimization-Based Safety Filter", "content": "The language-based choreographer outputs a choreography as a set of position reference trajectories. The reference trajectory for each drone n in the swarm is the augmentation of the trajectories from individual motion primitives:\n$r_n(t) = \\begin{cases} T_0 (c_{0,n}, t), & \\forall t \\in [t_{0,i}, t_{0, f}), \\\\ T_1 (c_{1,n}, t), & \\forall t \\in [t_{1,i}, t_{1,f}), \\\\ \\vdots & \\\\ T_M (c_{M,n},t), & t \\in [t_{M,i},t_{M,f}], \\end{cases}$\t(8)\nwhere M\u2208 N is the total number of primitives in the choreography. While individual motion primitives can be designed such that the trajectories $T_m(c_{m,n},t)$ are smooth and collision-free for $t \\in [t_{m,i}, t_{m,f}]$, this does not guarantee safe performances. In particular, in between two consecutive motion primitives, the swarm needs to transition dynamically based on their current positions, and these transitions can result in collisions and non-smooth behaviours.\nTo certify that trajectories are feasible and safe for deploying to the real-world system, we employ an underlying safety filter that optimizes swarm trajectories for smoothness while adhering to safety constraints. Intuitively, the safety filter allows the drones to follow the designed trajectories where possible and deviate from their trajectory where the proximity to another swarm member necessitates collision avoidance. The incorporation of the safety filter generally allows us to decouple choreography design and the satisfaction of safety constraints for deployment.\nWe formulate the safety filter as a distributed multi-agent trajectory optimization problem that is solved in a receding horizon manner. As compared to centralized methods (e.g., [15], [24]), the distributed methods can be implemented efficiently in real-time and scale up to larger swarms [17], [25]. In the distributed formulation, we discretize the reference trajectories at fixed time intervals \u03b4t based on a pre-specified control frequency and, at each sampling time $t_k = t_0 + k\u03b4t$, each drone n solves an independent optimization problem over a finite prediction horizon $[t_k,t_{k+K}]$:\n$r_{n,k:k+K}^* \\overset{\\text{k}}{=} safe(x_{n,k}, r_n, \\{p_{j,k:k+K}^*\\}_{j\\neq n}),$\t(9)\nwhere the notation \u201c$i\\overset{\\text{k}}{}$\u201d means the variable at time step i predicted at time step k, \":\" abbreviates consecutive time steps, K \u2208 N is the prediction horizon, $x_{n,k} = [p_{n,k}^T, v_{n,k}^T]^T$ is a vector containing the current position and velocity of the drone, and $p_{j,k:k+K}^*\\overset{\\text{k-1}}{} \\in R^3$ is the predicted position of neighboring drone j in the swarm based on the optimization from the previous time step. The optimization problem in (9) is solved for every time step $t_k \\in \\{t_0, t_0+\u03b4t, t_0+2\u03b4t, ..., t_r\\}$ for each drone n, and certified position reference for drone n at $t_k$ is given by the first element of the optimized variable obtained at each time step: $r_n^*(t_k) = r_{n,k}^*\\overset{\\text{k}}{}$ .  \nThe safety filter optimization problem safe solved for individual drones at time step k is defined as follows (with the drone index n dropped for brevity):\n$\\min_{u_{i\\text{k}}} \\sum_{i \\in K} \\alpha ||u_{i\\text{k}}||_2^2 + \\beta \\sum_{i \\in K} ||\\overset{(D)}{u_{i+1\\text{k}}} - \\overset{(D)}{u_{i\\text{k}}}||_2^2$\t(10a)\ns.t. $x_{\\text{kk}} = x_k$\t(10b)\n$\\overset{(d)}{u_{\\text{kk}}} = \\overset{(d)}{u_{\\text{kk-1}}}, \\forall d \\in D$\t(10c)\n$x_{i+1\\text{k}} = Ax_{i\\text{k}} + Bu_{i\\text{k}}, \\forall i \\in K$\t(10d)\n$p_s = r^{(d)}(t_s), \\forall s \\in S_k, \\forall d \\in D$\t(10e)\n$p_{i\\text{k}} \\le P, \\forall i \\in K$\t(10f)\n$||v_{i\\text{k}}^{(1)}||^2 \\le v^2, \\forall i \\in K$\t(10g)\n$f^2 \\le ||\\overset{(2)}{p_{i\\text{k}}} + g || \\le \\bar{f}^2, \\forall i \\in K$\t(10h)\n$||p_{i\\text{k}} - p_{j,i\\text{k}}||^2 \\ge 1, \\forall i \\in K, \\forall j\\in J.$\t(10i)\nwhere $K = \\{k, k + 1, ..., k + K \u2212 1\\}$ is the set of time indices over the horizon, \u03b1, \u03b2 \u2208 $R_{>0}$ are cost function parameters, $u_{i\\text{k}}$ is the optimization variable parameterized as Bernstein polynomials [17], $u_{k:k+K\u22121|k}$ are values of $u_{i\\text{k}}$ sampled at discrete time steps, the superscript $(.)^{(d)}$ denotes the d-th order derivative with respect to time, $D = \\{0, 1, ..., D\\}$ with D being the desired level of continuity enforced, (A, B) are identified system matrices representing the closed-loop dynamics of the quadrotor system, $S_k$ is a set of time indices for sampling the reference trajectory, $x_{i\\text{k}} = [p_{i\\text{k}}^{(1)}, v_{i\\text{k}}^{(1)}]^T$ with $v_{i\\text{k}}^{(1)} = p_{i\\text{k}}^{(2)}$, (p, P) are the position bounds characterizing the size of the flying arena, v is the maximum allowable speed, (f, $\\bar{f}$) are the minimum and maximum mass-normalized collective thrusts generated by the motors, J is the set of neighboring drone indices, $O_i$ is a diagonal matrix with the diagonal elements characterizing the dimensions of ellipsoidal collision envelopes for collision and downwash avoidance [6]. Intuitively, the safety filter optimization (10) encourages the certified trajectory $r^*(t)$ to match the trajectory generated by the language-based choreographer r(t), while ensuring the trajectory is smooth, feasible, and collision-free for real-world deployment.\nNote that, when solving (10), we first attempt to enforce (10e) as a hard constraint such that the certified trajectory matches the choreography trajectory as much as possible. In case the optimization problem is infeasible (e.g., the raw trajectories do result in collisions), (10e) is treated as a soft constraint such that the position reference deviations are penalized but not enforced to be zero.\nThe optimization problem in (10) is a non-convex, quadratically constrained quadratic program (QCQP). In our work, the optimization problem is solved using the AMSwarm algorithm [17], where the quadratic constraints are directly handled via polar parametrization. As shown in [17], the distributed optimization problem (9) can be solved efficiently; for a swarm of up to 50 agents, the computation time for each drone at each time step is on the millisecond level."}, {"title": "IV. SIMULATION AND EXPERIMENTAL RESULTS", "content": "Our proposed approach is demonstrated using the Crazyflies 2.1 as shown in Fig. 1. Each Crazyflie is equipped with a controller that converts high-level position references to low-level motor commands. We conducted our simulated experiments with gym-pybullet-drones [26], which is a drone swarm simulator modelled after the Crazyflies. Our hardware setup for real deployment is based on the Crazyswarm testbed [27]. Each drone receives its current reference position from a ground station via radios and tracks the desired position with its onboard controllers."}, {"title": "A. Scaling Swarm Sizes", "content": "In our first experiment, we show the improved scalability of using our proposed primitive-based approach as compared to a waypoint-based approach, where the LLM outputs the position waypoints for individual drones. In Fig. 4, we summarize the design success rates of our primitive-based approach with and without self-correction as well as that of the waypoint-based formulation for different swarm sizes. Each method is evaluated three times on five different songs, which corresponds to a total of 15 performances for each drone swarm size case. Performances with planned collisions (i.e., two drones occupying the same position at the same time) are counted as failures.\nWhile the safety filter guarantees that these configurations can still be flown safely, the trajectories are strongly affected by these corrections and the output hints at flawed geometrical reasoning. As shown in Fig. 4, the design success rate of the previous pipeline drops as the swarm size increases from its initial 75% for a swarm of four drones to below 20% for 20 drones. Introducing motion primitives significantly reduces the performance drop and maintains a success rate between about 65% to 85%, albeit with significant fluctuations. With the introduction of self-correction, this further increases to over 90% across all cases.\nThere are two possible reasons that performances planned using a waypoint-based approach increasingly suffer from planning failures as the number of drones in the swarm increases. First, the syntax is verbose, and the number of required output tokens linearly grows with the swarm size. This increases the chances of format errors or skipped drones. Second, current state-of-the-art LLMs have limited geometric reasoning capabilities when operating directly on coordinates and are likely to repeat a position for two drones for larger swarms. In contrast, the motion primitive approach exposes only the primitive names together with semantically interpretable parameters for the LLM to use in high-level choreography design, which makes the overall approach less prone to reasoning errors and more scalable to larger swarms."}, {"title": "B. Safety Filter Intervention", "content": "An additional benefit of using primitives is that the motions within each primitive can be designed to comply with feasibility and safety constraints. As a consequence, the safety filter's modifications are mainly restricted to the transitions between primitives. The reduced necessary intervention in turn leads to swarm performances that more faithfully represent the original design. To quantify this effect, we examine several swarm performances with a growing number of drones. After simulating the joint performances, we also simulate each drone individually to exclude the influence of evasion maneuvers by the safety filter. The trajectories of all drones are then compared to their counterpart in the swarm performances. Fig. 5 shows the mean and variance of these deviations depending on the swarm size. Leveraging motion primitives leads to consistent performances with minimal interventions from the safety filter. Conversely, the waypoint-based approach suffers from larger deviations as the size of the swarm grows, significantly reducing its scalability.\nFor the primitive-based approach, the transitions between two consecutive primitives are not guaranteed to be collision-free. Fig. 6 shows a comparison of the interagent distance distribution with and without the safety filter applied to the valid choreographies shown in Fig. 4. As evident from the plot, the safety filter efficaciously resolves any detected collisions in the primitive-based choreography design."}, {"title": "C. Swarm Behaviour Modification Through Language", "content": "Our proposed framework integrates an automated re-prompting mechanism to refine and correct any inaccuracies in drone choreography generated by LLMs. After visualizing the choreography designs in either simulation or experiments, the user is able to modify the swarm behaviour and refine the choreography through natural language instructions. Fig. 7 illustrates a comparative analysis between the initial choreography and the version reprompted through language. Both versions are subjected to identical verification procedures (Fig. 2) to guarantee the safety and reliability of the choreography for deployment. The overall system provides an intuitive interface for non-expert users to interact with the drone swarm without concerns about compliance with feasibility and safety constraints."}, {"title": "D. Real-World Deployment", "content": "We demonstrate the improved capabilities of SwarmGPT-Primitive by deploying choreographies for swarms of up to 20 drones to the Crazyflies hardware. A long-exposure capture of one performance is included in Fig. 1, and a video of the drone performances can be found at http://tiny. cc/swarmgpt-primitive. In the video, we showcase drone swarm performances designed by the SwarmGPT-Primitive framework based on various music genres and the capabilities of the system for modifying swarm behaviours through language instructions. The choreographies are accurately tracked by the drones' controllers, with an average tracking error of approximately 4.8 \u00b1 2.77 cm. Through the set of experimental demonstrations, we show that the proposed SwarmGPT-Primitive framework seamlessly integrates the reasoning capabilities of LLMs with the desired guarantees offered by the safety filter and enables non-expert users to easily design deployable choreographies for relatively large drone swarms."}, {"title": "V. CONCLUSIONS", "content": "In this work, we presented SwarmGPT-Primitive, a framework for generating drone swarm choreographies through natural language. Our system significantly improved the planning success rates for larger swarms by leveraging LLMs to compose choreographies using a library of motion primitives. We further enhanced the planning success rate by introducing a self-correction mechanism into the pipeline, allowing the LLM to revise errors in the choreography generation. To ensure feasibility and safety for real-world deployment, an optimization-based safety filter was designed to modify uncertified trajectories when necessary. We verified our approach in both simulation and real-world experiments for swarms of up to 20 drones. Our experiments demonstrated the scalability of the proposed SwarmGPT-Primitive approach and the system's ability to facilitate complex choreographies with minimal expert intervention. Overall, the SwarmGPT-Primitive architecture offers a blueprint for safely integrating LLMs into complex robotic systems."}]}