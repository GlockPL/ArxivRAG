{"title": "Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective", "authors": ["Yujin Oh", "Pengfei Jin", "Sangjoon Park", "Sekeun Kim", "Siyeop Yoon", "Kyungsang Kim", "Jin Sung Kim", "Xiang Li", "Quanzheng Li"], "abstract": "Ensuring fairness in medical image segmentation is critical due to biases in imbalanced clinical data acquisition caused by demographic attributes (e.g., age, sex, race) and clinical factors (e.g., disease severity). To address these challenges, we introduce Distribution-aware Mixture of Experts (dMoE), inspired by optimal control theory. We provide a comprehensive analysis of its underlying mechanisms and clarify dMoE's role in adapting to heterogeneous distributions in medical image segmentation. Furthermore, we integrate dMoE into multiple network architectures, demonstrating its broad applicability across diverse medical image analysis tasks. By incorporating demographic and clinical factors, dMoE achieves state-of-the-art performance on two 2D benchmark datasets and a 3D in-house dataset. Our results highlight the effectiveness of dMoE in mitigating biases from imbalanced distributions, offering a promising approach to bridging control theory and medical image segmentation within fairness learning paradigms. The source code will be made available.", "sections": [{"title": "1. Introduction", "content": "The inherent imbalance and ill-posed nature of data collected in clinical practice, impacted by demographic attributes such as gender and race, as well as clinical factors, e.g., disease severity, emphasize the need for fairness-aware learning approaches in medical data analysis (Ktena et al., 2024; Jin et al., 2024). Deep neural networks, due to their data-driven optimization processes, often overfit to prevalent patterns while failing to adequately learn from under-represented ones, leading to potentially biased predictions and weakening fairness across demographic subgroups, as shown in Figure 1. Although advanced fairness training strategies have been actively developed (Tian et al., 2025; 2024; Li et al., 2024), distributional approaches remain underexplored-despite the fact that clinical and demographic factors play a significant role in many clinical decision-making (Chester et al., 2020; Theodore et al., 2023). Clinicians consider demographic factors such as age, gender, and race alongside a patient's unique condition to assess both individual and subgroup characteristics. This process not only informs clinical factors like disease stage and decision-making but also implicitly shapes region/population-specific practice patterns based on cumulative experience and local demographics. However, current fairness learning approaches primarily focus on explicit factors such as demographic attributes but neglect implicit/contextual factors such as disease progression patterns or severity, despite the fact that these factors can be potential influence by region/population characteristics.\nBuilding on these distributional insights and the need for broader applicability across diverse attributes, we propose Distribution-aware Mixture of Experts (dMoE), a framework that adaptively incorporates individual characteristics and distributional patterns into deep neural network training. This architecture is grounded in an in-depth analysis of the Mixture of Experts (MoE) framework (Shazeer et al., 2017) with the adaptation of an optimal control perspective system. By analyzing the structural parallels between MoE and traditional control systems (\u00c5str\u00f6m & Murray, 2021), we reinterpret MoE as a feedback control mechanism. We further enhance its gating mechanism to incorporate distributional information as a mode-switching control for adaptive parameter selection, resulting in dMoE (Figure 2). This approach ensures robust and fair performance across diverse demographic and clinical subgroups.\nMoreover, to ensure broad applicability, we integrate dMoE with various network architectures, including transformers (Vaswani et al., 2017) and convolutional neural networks (CNNs), demonstrating the generalizability of its architecture and making the framework well-suited for a wide range of medical image analysis tasks. We validate the effectiveness of dMoE based on the segmentation task on multiple clinical datasets with diverse segmentation masks for diagnosis and treatment planning tasks. Experimental results demonstrate that dMoE not only advances state-of-the-art (SOTA) fairness learning approaches but also presents a way to incorporate distributional attributes to provide robust and equitable diagnosis and clinical decision-making across diverse demographic and clinical attributes.\nOur core contributions are summarized as follows:\n\u2022 We reinterpret MoE from the perspective of feedback control mechanism and extend it into dMoE for fairness learning by incorporating distributional awareness.\n\u2022 dMoE operates seamlessly within transformers and CNNs, enabling its use in 2D and 3D segmentation tasks across demographic and clinical attributes.\n\u2022 Extensive medical image segmentation experiments for diagnosis and treatment planning demonstrate dMoE's robustness, demonstrating its effectiveness in mitigating biases from imbalanced medical data distributions."}, {"title": "2. Related Work", "content": "2.1. Fairness Learning in Medical Image Segmentation\nFairness-oriented medical image segmentation datasets with demographic information (Tschandl et al., 2018; Tian et al., 2024) have enabled research on bias mitigation, driving the development of robust fairness training strategies. Advanced generative approaches (Li et al., 2024; Ktena et al., 2024) aim to generate diverse samples from skewed distributions to mitigate bias. However, challenges remain in addressing the computational demands and achieving high-quality sample generation for high-dimensional medical images, such as 3D whole-body computed tomography (CT), for use in augmentation datasets. On the other hand, fairness-focused loss function modifications, such as distributionally robust optimization (DRO) (Sagawa et al., 2019) and fair error-bound scaling (FEBS) (Tian et al., 2024), have been proposed to integrate fairness considerations directly into the optimization process. While partially effective, these methods are vulnerable to the data distribution within the training batch, limiting their applicability in 3D medical image segmentation, where large batch sizes are constrained. Furthermore, existing benchmarks and studies primarily focus on demographic attributes (Tian et al., 2025; Jin et al., 2024), often overlooking critical clinical factors, such as tumor progression and metastasis, which contribute to regional variations in clinical practice patterns due to inherent biases. In this study, we propose a general method to mitigate bias arising from both demographic and clinical factors.\n2.2. Mixture of Expert in Multi-distribution Learning\nRecent advances in the MoE framework (Shazeer et al., 2017) have demonstrated remarkable potential for adapting AI models to diverse data distributions, particularly within continual learning paradigms. MoE enhances robustness and adaptability when confronted with previously unseen data patterns (Rype\u015b\u0107 et al., 2024; Yu et al., 2024). In the medical domain, MoE has been effectively extended to address challenges such as multimodal integration (Jiang & Shen, 2024), scanning modality heterogeneity (Zhang et al., 2024), and catastrophic forgetting issues in continual learning (Chen et al., 2024; Wang et al., 2024), unifying these approaches into a cohesive framework that enhances performance. However, theoretical insights into how MoE facilitates the adaptation of disparate distributions to a target distribution remain limited. This study clarifies the underlying mechanism of MoE as dynamic parameter selection, and integrates environmental attributes into its gating mechanism, enabling distributional adaptation for medical image segmentation."}, {"title": "2.3. Training Neural Networks as Optimal Control", "content": "Neural networks, especially those with shortcut connections, perform complex transformations through successive modifications of a hidden state. These networks can be conceptualized as undergoing a continuous dynamic process, which can be described using ordinary differential equations (ODEs) (Weinan, 2017; Lu et al., 2018). Training these networks resembles solving an optimal control problem, where the objective is to adjust the network parameters, i.e., weights, to minimize a loss function (Chen et al., 2018; Sun et al., 2024).\nFixed-architecture feedforward neural networks can be regarded as operating under a non-feedback control. Employing a consistent strategy, however, can be restrictive in dynamic environments (\u00c5str\u00f6m, 1995). To address this limitation, feedback control mechanisms (Doyle et al., 2013; \u00c5str\u00f6m & Murray, 2021) offer an alternative by enabling continuous monitoring and adjustment based on the system's outputs and desired targets. Furthermore, mode-switching control (Yamaguchi et al., 1996; Boskovic & Mehra, 2000) introduces additional flexibility by enabling the policy to alternate between multiple optimized operational modes in response to external inputs. This capacity is essential for managing complex systems across different conditions and offers a robust response to diverse operational challenges (Yu et al., 2017). Likewise, in the context of image segmentation, adopting varying strategies- such as leveraging distributional attributes of the input-proves beneficial and serves as the motivation for our method."}, {"title": "3. Method", "content": "In the methods section, we provide theoretical insights and the motivation for proposing the distribution-aware MoE as a solution for fairness learning. We begin by revisiting MoE in Section 3.1 and then expand it into dMoE in Section 3.2. After defining dMoE, in Section 3.3, we further elaborate on the principles of optimal control and demonstrate how dMoE can be formulated as a mode-switching optimal control problem, by providing conceptual connections between them, as illustrated in Figure 2(a) and Figure 2(b) (bottom).\n3.1. Revisiting MoE\nThe MoE framework (Shazeer et al., 2017), which serves as the backbone structure for our proposed dMoE, originally leverages sparse gating to achieve computational efficiency while allowing for large model capacity. The output of the MoE layer is defined as follows:\n$$y = \\sum_{i=1}^{n}G(x); E_{i}(x),$$\nwhere n is the total number of experts, $E_{i}(x)$ represents the output of the i-th expert network for the input x, and $G(x)$ is the output of the gating network, a sparse n-dimensional vector that determines which experts are activated. The MoE approach fundamentally relies on sparsity, where the gating network engages only a limited subset of experts for each input, substantially lowering computational overhead by excluding inactive experts from processing. The gating function calculates $G(x)$ using methods such as Noisy Top-K Gating, which prioritizes the most relevant k experts while nullifying contributions from the remaining n k. Both the gating network and the experts are optimized simultaneously through backpropagation, ensuring seamless integration and fine-tuning of the MoE layer. This design facilitates a significant expansion of model capacity without proportionally increasing computational demands, making it particularly well-suited for large-scale tasks like language modeling and machine translation.\n3.2. Distribution-aware MoE\nNow, we explain our proposed Distribution-aware Mixture of Experts (dMoE), as illustrated in Figure 2(a). We further provide detailed network architecture in Appendix A.1. Unlike traditional sparse MoE, our proposed dMoE module integrates multiple distribution-wise router networks $G_{attr}$ and a set of n expert modules, consisting of shallow multi-layer perceptron (MLP) neural networks, defined as $E = \\{Expert_{1}, Expert_{2}, ..., Expert_{n}\\}$. We start by patching intermediate image embeddings from l-th layer block output, represented as $h_{l} \\in \\mathbb{R}^{H_{l}W_{l}D_{l}\\times C_{h_{l}}}$, into patches $h_{l} \\in \\mathbb{R}^{N_{l}\\times C_{h_{l}}}$, where the total number of patches is $N_{l} = H_{l}W_{l}D_{l}$. Here, $H_{l}$, $W_{l}$, $D_{l}$, and $C_{h_{l}}$ correspond to the height, width, depth, and channel dimensions of the intermediate image embeddings, respectively. For the transformer, which already has a predefined dimension, we omit this process. Given these patched embeddings $h_{l}$ and an attribute flag attr, the activated router $G_{attr}$ identifies the top-k experts. The final output is computed as a weighted sum of the outputs of these selected experts:\n$$h_{l} = h_{l} + \\sum_{i=1}^{k} G_{attr}(h_{l})\\cdot E_{i}(h_{l}),$$\nwhere $G_{attr}(\\cdot)$ outputs a weight matrix prioritizing each expert's contribution in a center-specific manner. The resulting weighted output is combined with $h_{l}$, representing the shared path, to yield the final unpatched dMoE image embedding $h_{l} \\in \\mathbb{R}^{H_{l}W_{l}D_{l}\\times C_{h_{l}}}$. The router network $G_{attr}$ computes sparse weights H using Gaussian noise, as follows:\n$$G_{attr}(x) = Softmax(KeepTop-k(H(x), k)),$$\n$$H(x)_{i} = (x^{T}\\cdot W)_{i}+Normal()\\cdot Softplus((x^{T}.W_{noise})_{i}),$$\n$$KeepTop-k(v, k)_{i} = \\begin{cases} v_{i} & \\text{if } v_{i} \\text{ is in top k elements of v},\\\\ -\\infty & \\text{otherwise.} \\end{cases}$$\nwhere, Wand $W_{noise}$ are trainable weight matrices, $Normal() \\sim N(0,1)$, $KeepTop-k(\\cdot)$ retrains only the top-k expert contributions, and $Softmax()$ function normalizes the selected weights. Following the dMoE modules, the embeddings $h_{l}$ are passed to the decoder, which predicts the final output, $\\hat{y}$. The network is optimized using the segmentation loss:\n$$min \\mathcal{L}(y, \\hat{y}) = -\\mathbb{E}_{x \\sim Px} [y_{i} log \\hat{p}(y_{i})],$$\nwhere M represents any 2D-to-3D neural network architecture equipped with our proposed dMoE module, $y \\in \\mathbb{R}^{HWD}$ is the ground-truth label, and the predicted output $\\hat{y} \\in \\mathbb{R}^{HWD}$, which is computed as follows:\n$$\\hat{y} = M(x, attr),$$\nwhere x is the input image and attr is the attribute flag.\n3.3. Interpreting dMoE Through Optimal Control\nIn this section, we begin by providing a brief overview of training deep neural networks from the perspectives of dynamical systems and optimal control. Next, we demonstrate that for a given feedforward architecture as a non-feedback control, MoE can be interpreted as state feedback control. Finally, we show how dMoE relates to the mode-switching control variant of optimal control.\nNeural networks create complex transformations by applying a sequence of changes to a hidden state. These transformations can be represented mathematically as follows:\n$$h_{l+1} = h_{l} + f(h_{l}, \\theta_{l}).$$\nThis equation illustrates iterative updates similar to an Euler discretization of a continuous transformation. The dynamics of these transformations are governed by an ODE, parameterized by a neural network, which is a continuous representation of the hidden units' dynamics:\n$$dh_{l} = f(h_{l}, u_{l})dt.$$\nIn practical applications, such as training neural networks with a dataset labeled $\\{x,y\\}$, the goal is to minimize the objective function through an optimization process:\n$$arg \\min_{\\{\\theta_{l}\\}} \\mathbb{E}_{\\{x,y\\}} [\\mathcal{L}(\\hat{y}, y)| h_{l+1} = h_{l} + f(h_{l}, \\theta_{l}), h_{l} = x, y = h_{l} ].$$\nThis optimization problem can be seen as the discretization of a terminal control problem, which is governed by the neural ODE:\n$$arg \\min_{\\{u\\}} \\mathbb{E}_{\\{x,y\\}} [\\mathcal{L}(\\hat{y}, y)| dh_{l} = f(h_{l}, u_{l}), h_{l} = x, y = h_{l} ].$$\nHere, the MoE framework can be considered an approximation of feedback control, also known as closed-loop control, as illustrated in Figure 2(b) (middle). The feedback control ensures optimal operational outcomes by leveraging real-time state information, $h_{l}$ to adjust control inputs dynamically. This is expressed mathematically as:\n$$dh_{l} = f(h_{l}, u_{l}(h_{l}))dt.$$\nGiven the complexity of optimizing policy function through neural networks, kernel methods (Hofmann et al., 2008) are often employed for parameterization:\n$$u(h_{l}) \\approx \\sum_{i} K(h, h_{l})u(h_{l}),$$\nwhere K is a kernel function, $h_{i}^{'}$ are anchor points, and $u(h_{i}^{'})$ are fixed values. This re-parameterization facilitates the shift in optimization focus from the function u itself to the fixed parameters $\\theta = u(h_{i}^{'})$, enhancing the manageability and efficiency of the optimization process:\n$$f(h_{l}, u(h_{l})) \\approx f(h_{l}, \\sum_{i} K(h_{l}, h_{i}^{'}) \\theta_{i}).$$\nWe consider the following kernel function\n$$K(h_{l}, h_{i}^{'}) = \\frac{exp(\\langle\\phi(h_{l}), \\phi(h_{i}^{'})\\rangle)}{\\sum_{j} exp(\\langle\\phi(h_{l}), \\phi(h_{j}^{'})\\rangle)}.$$\nTo facilitate the learning of the kernel function \u03c6 we employ a reparameterization technique where $(\\phi(h_{l}), \\phi(h_{i}^{'})) = (h_{l}, \\phi^{*}(h_{i}^{'})) = (h \\cdot W)_{l}^{i}$. Here, the transformed parameter $\\phi^{*}(h_{i}^{'})$ are represented by the i-th column of W, with * denoting the transpose of \u03c6. Due to considerations of computational complexity and robustness, we have incorporated Noisy Top-K Gating, corresponding to Eqs. 3, 4, and 5. Specifically, if the function f is linear with respect to its second argument and can be interpreted as the strategy of an expert, where each expert $E_{i}$ acts as a controller with fixed parameters $\\theta_{i}$, then the following equation holds:\n$$f(h_{l}, \\sum_{i} K(h, h_{i}^{'})) = \\sum_{i} K(h_{l}, h_{i}^{'}) f(h_{l}, \\theta_{i})\n= \\sum_{i} G_{i}(h_{l})E(h_{l}).$$\nIn the field of optimal control, the methodology of choosing or switching between different control strategies based on varying environmental conditions is commonly referred to as mode-switching control or multi-modal control. This approach involves selecting the most suitable control law not only depending on the state h, but also on system parameters attr, aiming to optimize overall system performance.\nIn particular, we consider a special case by introducing a switching logic dependent on the external environmental conditions denoted by attr. The dynamics of the system are described by the following equation:\n$$dh_{l} = f(h_{l},u_{l}), u_{l} = K_{s(attr)}(h_{l}),$$\nwhere $\\kappa$ is a control strategy mapping that selects the most appropriate control input based on the current state and environment. If the system features several potential control modes, \u03ba may comprise multiple sub-strategies, $\\kappa_{1}, \\kappa_{2},..., \\kappa_{m}$, each applicable under specific conditions. The logic for switching modes is governed by the switching function s(attr).\nTo prevent overfitting and to share knowledge learned from images of different distributions, we utilize a shared expert $E_{i}$ across different flags attr. For each attribute, a distinct G is trained, implying that for different attr, we adopt different functions \u03c6 in Eq. 15, analogous to using different matrices W in Eq. 4. This results in the following control scheme:\n$$\\sum_{i=1}^{k} G_{attr}^{i} (h_{l}) \\cdot E_{i}(h_{l}).$$\nConsidering that the neural network's layerwise structure represents a discrete form of the control, incorporating Patchify leads to Eq. 2. Therefore, dMoE can be interpreted as attribute-wise mode-switching control variant of optimal control for fairness learning, as reflected in the structural resemblance illustrated in Figure 2(a) and (b) (bottom)."}, {"title": "4. Experimental Results", "content": "4.1. Datasets\nTo demonstrate the effectiveness of our proposed dMoE framework as an optimal control approach, we conduct extensive experiments on two benchmark datasets and an in-house dataset. For each dataset, we visualize the data distribution for each attribute in Figure 1 and provide further details of the training and test datasets in Appendix A.2. For the 2D segmentation experiments, we utilize two datasets: 1) Harvard-FairSeg (Tian et al., 2024) and 2) HAM10000 (Tschandl et al., 2018). For the 3D segmentation experiments with clinical attributes, we utilize our in-house radiotherapy target dataset for prostate cancer patients.\nHarvard-FairSeg is a scanning laser ophthalmoscopy (SLO) fundus image dataset comprising 10,000 samples with pixel-wise optic cup and outer neuroretinal rim segmentation masks for diagnosing glaucoma. It includes six key demographic attributes\u2014age, gender, race, ethnicity, language preference, and marital status-enabling comprehensive studies of fairness. In this study, we focus on the race attribute, i.e. race \u2208 {Black, Asian, White}, as individuals from minor attribute subgroups face a risk of developing glaucoma compared to other groups, yet the segmentation accuracy is often lowest for this demographic (Tian et al., 2024). Fairness and segmentation performance are evaluated on the test benchmark, which consists of 2,000 samples.\nHAM10000 is a dermatology image dataset comprising 10,015 2D RGB samples with binary segmentation masks for diagnosing skin lesions. It includes demographic attributes such as sex and age, enabling targeted analysis of distributional disparities. In this study, we focus on the age attribute, as younger and older populations are underrepresented in the dataset. For age categorization, patients are divided into four groups at 20-year intervals, with the test benchmark consisting of 1,061 samples.\nRadiotherapy Target Dataset comprises pelvic CT scans of prostate cancer patients, accompanied by clinical target volume (CTV) segmentation masks for radiotherapy planning in radiation oncology. The dataset includes clinical factors, such as tumor staging and histopathological findings. In this study, we focus on the Tumor (T)-stage attribute, i.e. T-stage \u2208 {T1, T2, T3, T4}, as the dataset exhibits an imbalance in population distribution. For example, radiotherapy can be applied across all T-stages in prostate cancer, but its aim may vary depending on clinical practices. In certain regions, radiotherapy alone is used as definitive treatment for both early and advanced stages without surgery. In contrast, other regions favor radiotherapy alone for early stages, while combining surgery with adjuvant radiotherapy for advanced stages, reflecting institutional variations in treatment patterns. To address biases arising from the imbalanced T-stage distribution when training deep neural networks for radiotherapy target segmentation, we utilize a training dataset comprising 721 primary prostate cancer patients from Yonsei Cancer Center, Seoul, South Korea, and validate network performance using an independent test set of 132 primary prostate cancer patients from Yongin Severance Hospital, Yongin, South Korea. The data collected for this study has been ethically approved by the IRB of the Department of Radiation Oncology at Yonsei Cancer Center and the Department of Radiation Oncology at Yongin Severance Hospital (IRB numbers 4-2023-0179 and 9-2023-0161).\n4.2. Implementation Details\nFor all experiments, we set the dMoE module hyperparameters with Top-k as 2 and the number of experts n as 8. Each expert layer consists of a standard MLP with two linear layers, a ReLU activation, and a dropout layer. For 2D segmentation tasks, we use TransUNet (Chen et al., 2021) as the backbone with the standard ViT-B architecture. The network is trained following the setup used in previous studies. All the input images are center-cropped and resized into 2D patches of size 224 x 224 pixels with a batch size of 42. The network is trained with a learning rate of 0.01 for 300 epochs on the Harvard-FairSeg dataset and 100 epochs on HAM10000, following the benchmark setting. The best performance is selected from checkpoints saved at 100-epoch intervals. For 3D radiotherapy target segmentation task, we adopt the 3D Residual U-Net (\u00c7i\u00e7ek et al., 2016) as the backbone architecture, since it is reported as an effective architecture for radiotherapy target segmentation (Oh et al., 2024). The network is trained using randomly cropped 3D patches of size 384 \u00d7 384 \u00d7 128 voxels and a batch size of 4. During evaluation, the entire 3D CT volumes are processed using a sliding window approach. The training is conducted with a learning rate of 5 \u00d7 10-5 over 100 epochs and early stopping based on the validation dataset. The additional computational costs introduced to each backbone are compared in Appendix A.3. We implement the networks using PyTorch (Paszke et al., 2019) in Python with CUDA 11.8. The AdamW (Loshchilov & Hutter, 2017) optimizer with exponential learning rate decay is used for all experiments. For 2D segmentation tasks, we use a single NVIDIA A100 80GB GPU, while for the 3D segmentation task, we use a single NVIDIA RTX A6000 48GB GPU.\n4.3. Baseline Method and Evaluation Metrics\nWe evaluate our method against baseline approaches for fairness learning. On the 2D Harvard-FairSeg dataset, we compare our approach with reported metrics from adversarial (ADV) training (Madras et al., 2018), distributionally robust optimization (DRO) (Sagawa et al., 2019), fair-error-bound scaling (FEBS) (Tian et al., 2024), and generative model-based augmentation (FairDiff). We implement our method under the same training conditions as the benchmark methods. For further experiments on the 2D HAM10000 dataset and the 3D radiotherapy target dataset, we compare our method with FEBS among SOTA methods. We exclude the generative model-based approach, FairDiff, as it requires additional image generation and evaluation tailored to 2D and 3D datasets, which makes it suboptimal for direct comparison. Moreover, we use the default MoE as an additional baseline, replacing our proposed dMoE modules by default MoE modules without distribution-aware router. We implement all methods under the same training conditions as our method. To evaluate performance, we employ the Dice Similarity Coefficient, Intersection over Union (IoU), as well as equity-scaled segmentation performance (ESSP) metrics for both Dice and IoU-denoted as ES-Dice and ES-IoU-following (Tian et al., 2024):\n$$ESSP = \\frac{I(\\{(\\hat{y}, y)\\} )}{1 + \\Delta}$$\nwhere,\n$$\\Delta = \\sum_{attr \\in A} |I(\\{(\\hat{y}, y)\\} ) - I(\\{(\\hat{y}, a, y) | a = attr\\}\\} )|,$$\nwhere I \u2208 {Dice, IoU} and A represents the set of all demographic groups. While ESSP evaluates fairness in performance across diverse demographic subgroups, it has limitations in capturing substantial performance gains for specific subgroups, particularly in the 3D radiotherapy target segmentation task. We complement the limitation of ESSP metrics by providing quantitative analysis with violin plots, which offer a more detailed visualization of equity and performance distribution across diverse subgroups."}, {"title": "4.4. Results", "content": "4.4.1. 2D SEGMENTATION WITH DEMOGRAPHIC ATTRIBUTES\nWe first evaluate dMoE for 2D segmentation on benchmark datasets. For the Harvard-FairSeg neuroretinal rim and optic nerve segmentation tasks, our method consistently achieves SOTA performance in terms of ES-Dice and ES-IoU, surpassing previous fairness learning approaches, as shown in Table 1. Specifically, our method demonstrates superior performance for the minor attribute subgroup (Black), achieving a Dice score of 0.776 for rim segmentation, compared to FairDiff (0.743) and FEBS (0.733). Similarly, for optic cup segmentation, our method significantly improves performance for the Asian attribute subgroup, achieving a Dice score of 0.844 compared to FairDiff (0.832) and FEBS (0.825). Although MoE, which removes the distribution-aware gating network from our proposed method, achieves comparable performance (0.845), dMoE outperforms MoE across other subgroups for both rim and cup segmentation. Furthermore, the shared structure within dMoe module across subgroups enables synergistic effects, maintaining or even improving performance for the major attribute subgroup (White). For the HAM10000 skin lesion segmentation task, our method also demonstrates SOTA performance in ES-Dice and ES-IoU, with scores of 0.841 and 0.749, respectively, outperforming MoE (0.836 and 0.742) and FEBS (0.787 and 0.679), as shown in Table 2. Specifically, loss function modification methods, such as FEBS, exhibit inferior performance across attribute subgroups compared to the baseline method. This suggests that when the training dataset for each subgroup is insufficient, these methods may sacrifice overall performance. MoE shows promising results for minor attribute subgroups, dMoE further enhances equity across all subgroups.\n4.4.2. 3D RADIOTHERAPY TARGET SEGMENTATION WITH CLINICAL ATTRIBUTES\nWe further evaluate dMoE for 3D radiotherapy target segmentation, using T-stage as a distributional attribute. Table 3 summarizes the segmentation performance. Despite the test set being acquired from a different hospital with a distinct data distribution, dMoE demonstrates promising generalization performance. The strength of dMoE is particularly evident in underrepresented subgroups, such as T1 and T4 where the frequency is significantly lower than that of T2 and T3, by resulting the most notable performance improvements in these subgroups. Specifically, dMoE demonstrates robust and consistent performance, particularly excelling in the T4 subgroup with a Dice score of 0.767, significantly outperforming FEBS (0.660) and MoE (0.683). Moreover, despite the limited sample size of the T1 subgroup, dMoE achieves superior performance. This consistent improvement demonstrates dMoE's generalizability and robustness, even when applied to datasets from different centers with varying data distributions.\nHowever, as noted in Section 4.3, ESSP metrics have limitations in capturing significant performance gains for minor attribute subgroups. To address this, we further illustrate violin plots in Figure 3(a). Comparison on violin plots, with equity measures indicated by transparent blue lines, confirms dMoE's ability to maintain equity across attribute-wise subgroups. Qualitative results for each subgroup are presented in Figure 3(b). As observed in the ground truth labels, the radiotherapy target volume tends to expand with the progression of the tumor's clinical stage. This trend is distinctly captured by dMoE, which demonstrates superior adaptability to distribution-specific characteristics, thereby achieving notable fairness in performance.\n4.4.3. ABLATION STUDIES\nWe further conduct additional analyses to explore the effects of various configurations of the dMoE module. Specifically, we vary the placement of the dMoE module within the encoder and decoder and investigate whether its parameters should be shared or separated across layers to determine the optimal architecture. Detailed ablation study results are provided in Appendix A.4."}, {"title": "5. Conclusion, Limitations & Future Work", "content": "Adopting an optimal control perspective, we design distribution-aware Mixture of Experts (dMoE) architectures to address data imbalance issues. By modeling distribution as an external factor influencing control, we integrate dMoE into medical image segmentation for more effective handling of imbalanced clinical datasets. Given the nature of clinical practice, which accounts for distributional characteristics, our proposed algorithm offers a promising solution to data imbalance and provides a robust framework for clinical decision-making that aligns with clinicians' perspectives. Notably, ensuring distributional equity is essential for real-world clinical AI deployment, where training and deployment dataset distributions often differ. Our distribution-aware dMoE holds promise in adapting trained models to unknown distributions, thereby improving the success of clinical AI integration across diverse hospitals.\nHowever, several limitations remain for this study:\nFirst, while we explore diverse attributes across three datasets, the performance improvement trends vary depending on the task and dataset characteristics. Moreover, the optimal configuration of the dMoE module varies between the two different architectures. Future research will focus on uncovering the underlying characteristics of attribute-wise subgroups within each dataset to identify the factors driving these variations and will aim to develop a more generalized module capable of delivering task-agnostic performance improvements.\nSecond, our focus on a single attribute per task limits the exploration of combined attribute imbalances. For instance, while patients with T2-stage cancer may be prevalent, further subgroup imbalances, such as age or metastasis status, could exist. Addressing this issue may require integrating multiple attributes within a hierarchical dMoE framework, which we plan to explore in future studies.\nLast, this study adopts an optimal control perspective to design efficient deep neural network architectures, leveraging back-propagation for parameter optimization. Future research will explore how advanced numerical methods from optimal control theory can inspire novel optimization algorithms specifically tailored to enhance fairness learning.\nDespite these limitations, we believe our distribution-aware approach represents a step forward in advancing fairness learning for diverse data-imbalanced clinical scenarios."}, {"title": "Impact Statement", "content": "This paper aims to advance fairness in medical image segmentation by addressing biases arising from imbalanced clinical data distributions. Our work demonstrates robustness across diverse datasets and network architectures, contributing to equitable and reliable AI-driven healthcare applications."}, {"title": "A. Appendix", "content": "A.1. Detailed Network Architecture.\nWe provide the network architecture for a better understanding of the dMoE modules location within each Transformer-based and CNN-based architecture in Table 4 and Table 5, respectively.\nA.2. Dataset Details.\nWe further provide the trainset and testset for each dataset, along with the attribute subgroup-wise data distribution and percentiles for the trainset in Table 6.\nA.3. Comparison on Computations.\nWe compare the computational complexity of incorporating the MoE or dMoE module into the backbone in Table 7.\nA.4. Ablation Study Results.\nWe perform ablation studies to examine the effects of various configurations of the dMoE module. Specifically, we investigate performance changes based on 1) dMoE Location within the network, by inserting the dMoE module at different layers within the encoder, the decoder, or both for comparison. We also examine whether 2) dMoE Parameters should be shared or separated across layers to determine the optimal architecture. In the case of parameter sharing for CNNs, we incorporate additional linear layers before and after the dMoE module to match the channel dimensions across different layer blocks.\nFor performing experiments, we use the HAM10000 dataset for Transformer-based architecture (TransUNet), while for CNN-based architecture (3D ResUNet), we utilize a radiotherapy target segmentation task, by reporting performance using the ES-Dice and Dice score as the metric.\nAs shown in Table 8 and Table 9, inserting the dMoE module within the encoder, decoder, or both yields comparable performance for both architectures, particularly for minority groups (The subgroup with Age < 20 for HAM10000 dataset and the T4-stage subgroup for radiotherapy target dataset). Therefore, we retain the dMoE module within the encoder only to optimize network training efficiency. In the Transformer-based architecture, sharing dMoE parameters across layers enhances performance due to consistent dimensionality between layers. Conversely, in CNN-based architecture, differences in layer-wise dimensionality reduce the effectiveness of parameter sharing. This necessitates adding dimension-matching linear layers before and after the dMo"}]}