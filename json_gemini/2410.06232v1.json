{"title": "DON'T CUT CORNERS: EXACT CONDITIONS FOR MODULARITY IN BIOLOGICALLY INSPIRED REPRESENTATIONS", "authors": ["Will Dorrell", "Kyle Hsu", "Luke Hollingsworth", "Jin Hwa Lee", "Jiajun Wu", "Chelsea Finn", "Peter E Latham", "Tim EJ Behrens", "James CR Whittington"], "abstract": "Why do biological and artificial neurons sometimes modularise, each encoding a single meaningful variable, and sometimes entangle their representation of many variables? In this work, we develop a theory of when biologically inspired representations\u2014those that are nonnegative and energy efficient- modularise with respect to source variables (sources). We derive necessary and sufficient conditions on a sample of sources that determine whether the neurons in an optimal biologically-inspired linear autoencoder modularise. Our theory applies to any dataset, extending far beyond the case of statistical independence studied in previous work. Rather, we show that sources modularise if their support is \"sufficiently spread\". From this theory, we extract and validate predictions in a variety of empirical studies on how data distribution affects modularisation in nonlinear feedforward and recurrent neural networks trained on supervised and unsupervised tasks. Furthermore, we apply these ideas to neuroscience data. First, we explain why two studies that recorded prefrontal activity in working memory tasks conflict on whether memories are encoded in orthogonal subspaces: the support of the sources differed due to a critical discrepancy in experimental protocol. Second, we use similar arguments to understand why preparatory and potent subspaces in RNN models of motor cortex are only sometimes orthogonal. Third, we study spatial and reward information mixing in entorhinal recordings, and show our theory matches data better than previous work. And fourth, we suggest a suite of surprising settings in which neurons can be (or appear) mixed selective, without requiring complex nonlinear readouts as in traditional theories. In sum, our theory prescribes precise conditions on when neural activities modularise, providing tools for inducing and elucidating modular representations in brains and machines.", "sections": [{"title": "1 Introduction", "content": "Our brains are modular. At the macroscale, different regions, such as visual or language cortex, perform specialised roles; at the microscale, single neurons often precisely encode single variables such as self-position [22] or the orientation of a visual edge [29]. This mysterious alignment of meaningful concepts with single neuron activity has for decades fuelled hope for understanding a neuron's function by finding its associated concept. Yet, as neural recording technology has improved, it has become clear that many neurons behave in ways that elude such simple categorisation: they appear to be mixed selective, responding to a mixture of variables in linear and nonlinear ways [50, 65]. The modules vs. mixtures debate has recently been reprised in the machine learning community. Both the disentangled representation learning and mechanistic interpretability subfields are interested in when neural network representations decompose into meaningful components. Findings have been similarly varied, with some studies showing meaningful single unit response properties and others showing clear cases of mixed tuning (for a full discussion on related work see Appendix A). This brings us to the main research question considered in this work: Why are neurons, biological and artificial, sometimes modular and sometimes mixed selective?\nIn this work, we develop a theory that precisely determines, for any dataset, whether the optimal learned representations will be modular or not. More precisely, in the linear autoencoder setting, we show that modularity in biologically constrained representations is governed by a sufficient spread condition that can roughly be thought of as measuring the extent to which the support of the source variables (sources, aka factors of variation) is rectangular. This sufficient spread condition bears resemblance to identifiability conditions derived in the matrix factorisation literature [61, 62], though both the precise form of the problem we study and the condition we derive differ (Appendix A). This condition on the sources is much weaker than the case of mutual independence studied in previous work [69], and commensurately broadens the settings we can understand using our theory. For example, the loosening from statistical independence to rectangular support enables us to predict when linear recurrent neural network (RNN) representations of dynamic variables modularise.\nFurther, these results empirically generalise to nonlinear settings: we show that our source support conditions predict modularisation in nonlinear feedforward networks on supervised and autoencoding tasks as well as in nonlinear RNNs. We also fruitfully apply our theory to neuroscience data. First, we explain why previous works studying working memory representation in prefrontal cortex reported conflicting results on whether memories are encoded in orthogonal subspaces: the support of the sources differed due to a critical discrepancy in experimental protocol. Second, we use these same ideas to understand why preparatory and potent subspaces in RNN models of motor cortex are only sometimes orthogonal. Third, compared to previous theories, we more precisely explain why grid cells only sometimes warp in the presence of rewards. And fourth, we highlight a variety of settings in which neurons are optimally mixed- selective without any need for flexible nonlinear categorisation, offering a plausible alternative justification for the existence of mixed-selectivity. In summary, our work contributes to the growing understanding of neural modularisation by highlighting how source support determines modularisation and explaining puzzling observations from both the brain and neural networks in a cohesive normative framework."}, {"title": "2 Modularisation in Biologically Inspired Linear Autoencoders", "content": "We begin with our main technical result: necessary and sufficient conditions for the modularisation of biologically inspired linear autoencoders."}, {"title": "2.1 Preliminaries", "content": "Let $s \\in \\mathbb{R}^{d_s}$ be a vector of $d_s$ scalar source variables (sources, aka factors of variation). We are interested in how the empirical distribution, $p(s)$, affects whether the sources' neural encoding (latents), $z \\in \\mathbb{R}^{d_z}$, are modular with respect to the sources, i.e., whether each neuron (latent) is functionally dependent on at most one source. Following [69], we build a simplified model in which neural firing rates perfectly linearly autoencode the sources while maintaining nonnegativity (since firing rates are nonnegative):\n$z = W_{in}s + b_{in}, s = W_{out}z + b_{out}, z \\ge 0$. (1)\nSubject to the above constraints, we study the representation that uses the least energy, as in the classic efficient coding hypothesis [4]. We quantify this using the $l^2$ norm of the firing rates and weights:\n$\\min_{W_{in}, b_{in}, W_{out}, b_{out}} (\\langle ||z||^2 \\rangle_{p(s)} + \\lambda (||W_{out}||_F^2 + ||W_{in}||_F^2)) \text{ s.t. } (1)$. (2)\nWe remark that there are common analogues of representational nonnegativity and weight energy efficiency in machine learning (ReLU activation functions and weight decay, respectively). When the sources are statistically independent, i.e. $p(s) = \\prod_{i=1}^{d_s} P(s_i)$, then the optima of (2) have modular latents [69]. We now improve on this result by showing necessary and sufficient conditions that guarantee modularisation for any dataset, not just those that have statistically independent sources."}, {"title": "2.2 Intuition for Source Support Modularisation Conditions", "content": "To provide intuition, consider a hypothetical mixed selective neuron,\n$z_j = W_{j1}s_1 + W_{j2}s_2 + b_j$, (3)\nthat is functionally dependent on both $s_1$ and $s_2$. Perhaps, however, a modular representation, in which this neuron is broken into two separate modular encodings, would be better. If so, the optimal solution would have neurons that only code for single sources:\n$z_{j1} = W_{j1}s_1 + b_j', z_{j''} = W_{j2}s_2 + b_j''$. (4)\nFor simplicity, we assume the two sources are linearly uncorrelated, have mean zero, and are supported on an interval centered at zero (Figure 1a; we relax these assumptions in our full theory). Then, for fixed $w_{j1}$ and $w_{j2}$, the optimal (energy efficient) bias should be large enough to keep the representation nonnegative, but no larger:\n$b_j = \\min_{s_1,s_2} [W_{j1}s_1 + W_{j2}s_2], b_j' = \\min_{s_1} w_{j1}s_1, b_j'' = \\min_{s_2} W_{j2}s_2$, (5)\nwhere the minimizations are constrained to the support of the empirical distribution $p(s_1, s_2)$. Now that both representations are specified, we can compare their costs. When calculating the energy loss one finds that, in this simplified setting, most terms are zero or cancel, and hence the mixed selective case uses less energy (2) when\n$b_j^2 < b_j'^2 + b_j''^2$. (6)\nThe key takeaway from this exercise lies in how $b_j$ is determined by a joint minimization over $s_1$ and $s_2$ (5). Mixing occurs when $s_1$ and $s_2$ do not take on their most negative values at the same time, since then $b_j$ does not have to be large in order to maintain positivity. Graphically, this corresponds to a large-enough corner missing from the support of the sources' joint distribution (Figure 1)."}, {"title": "2.3 Precise Conditions for Modularising Biologically Inspired Linear Autoencoders", "content": "We now make precise the intuition developed above. All proofs are deferred to Appendix B.\nTheorem 2.1. Let $s \\in \\mathbb{R}^{d_s}, z \\in \\mathbb{R}^{d_z}, W_{in} \\in \\mathbb{R}^{d_z \\times d_s}, b_{in} \\in \\mathbb{R}^{d_z}, W_{out} \\in \\mathbb{R}^{d_s \\times d_z}, and b_{out} \\in \\mathbb{R}^{d_s}$, with $d_z > d_s$. Consider the constrained optimization problem\n$\\min_{W_{in}, b_{in}, W_{out}, b_{out}} (\\langle ||z^{[i]}||_2^2 \\rangle + \\lambda (||W_{out}||_F^2 + ||W_{in}||_F^2))$\ns.t.\n$z^{[i]} = W_{in}s^{[i]} + b_{in}, s^{[i]} = W_{out}z^{[i]} + b_{out}, z^{[i]} \\ge 0$, (7)\nwhere $i$ indexes a finite set of samples of $s$. At the minima of this problem, the representation modularises, i.e. each row of $W_{in}$ has at most one non-zero entry, iff the following inequality is satisfied for all $w \\in \\mathbb{R}^{d_s}$:\n$(\\min_i[w^Ts^{[i]}])^2 + \\sum_{j,j'\\neq j} w_jw_{j'} \\langle (s_j - \\langle s_j \\rangle) (s_{j'} - \\langle s_{j'} \\rangle) \\rangle > \\sum_{j=1}^{d_s} (w_j \\min_i s_j^{[i]})^2$, (8)\nwhere $s := s - \\langle s^{[i]} \\rangle_i$; and assuming that $\\min_i s_j^{[i]} \\le \\max_i s_j^{[i]} \\forall j \\in [d_s]$ w.l.o.g.\nOur theory prescribes a set of inequalities that determine whether an optimal representation is modular. If a single inequality is broken, the representation is mixed (at least in part); else, the representation is modular: each neuron's activity is a function of a single source. These inequalities depend on two key properties of the sources: the shape of the source distribution support in extremal regions, and the pairwise source correlations. Remarkably, they do not depend on the energy tradeoff parameter $\\lambda$. These inequalities can be visualised, as done in the wrapped figure. For a given dataset, {$s^{[i]}$} (blue dots), we can calculate $\\langle s_j^{[i]} s_{j'}^{[i]} \\rangle$ and each $\\min_i s_j^{[i]}$ as they are simple functions of the dataset. For all unit $w$, we can draw the line\n$w_x = \\sum_{j=1}^{d_s} w_j^2 (\\min_i s_j^{[i]})^2 - \\sum_{j,j'\\neq j}^{d_s} w_j w_{j'} \\langle (s_j - \\langle s_j \\rangle) (s_{j'} - \\langle s_{j'} \\rangle) \\rangle$, (9)\nEach $w$ gives us a line, and if there exists a line (such as the red one) that bounds the source support, then an optimal representation must mix. This exercise also motivates the following equivalent statement of our conditions."}, {"title": "Theorem 2.2. In the same setting as Theorem 2.1, define the following matrix:", "content": "$S = \\begin{pmatrix} (\\min_i s_1^{[i]})^2 - \\langle s_1 s_1 \\rangle & -\\langle s_1 s_2 \\rangle & \\dots \\\\ -\\langle s_2 s_1 \\rangle & (\\min_i s_2^{[i]})^2 - \\langle s_2 s_2 \\rangle & \\dots \\\\ \\vdots & \\vdots & \\ddots \\end{pmatrix}$. (10)\nDefine the set $E = \\{y : y^T S^{-1} y = 1\\}$. Then an equivalent statement of the modularisation inequalities (8), is the representation modularises iff $E$ lies within the convex hull of the datapoints.\nThis therefore provides a simple test: create $S$ and draw the set $E$ which, if $S$ is positive definite (as it often is), is an ellipse as shown in the wrapped figure above. The optimal representation modularises iff the convex hull of the datapoints encloses $E$. If $S$ has some positive and some negative eigenvalues, then the optimal representation must mix. To further clarify our results, we also present a particularly clean special case."}, {"title": "Corollary 2.3. In the same setting as Theorem 2.1, if", "content": "$\\min_i s_j^{[i]} = \\max_i \\forall j \\in [d_s]$, i.e. each source is range- symmetric around its mean, then the optimal representation modularises if all sources are pairwise extreme-point independent, i.e. if for all $j, j' \\in [d_s]^2$:\n$\\min_i \\langle s_j^{[i]} s_{j'}^{[i]} \\rangle \\in \\{\\max s, \\min s\\} = \\min_i s^{[i]} s^{[i]}$. (11)\nIn other words, if the joint distribution is supported on all extremal corners, the optimal representation modularises.\nThe above results apply to autoencoders trained to linearly encode and decode the pure source vector $s^{[i]}$. In Ap- pendix B.4 we derive similar results for linear mixtures of sources, i.e. where the data the autoencoder receives and reconstructs is $x^{[i]} = As^{[i]}$ for some mixing matrix $A$.\nValidation of linear autoencoder theory. We show our inequalities correctly predict modularisation. In particular, as an illustration of the precision of our theory, we create a dataset which transitions from inducing modularisation to inducing mixing via the removal of a single critical datapoint (Figure 1c). Further, we generate many datasets, create the optimal biological representation, and measure the angle $\\theta$ between the most-mixed neuron's weight vector and its closest source direction, a proxy for modularity. The top of Figure 1d shows that our theory correctly predicts which datasets are modular ($\\theta = 0$). Further, despite our theory being binary (will it modularise or not?), empirically we see that a good proxy for how mixed the optimal representation will be is the degree to which the inequalities in Theorem 2.1 are broken. Finally, in the bottom of Figure 1d we show that on the same datasets a measure of source statistical interdependence, as used in previous work, does not predict modularisation.\nPredictions beyond our theory. From our theory we extract qualitative trends to empirically test in more complex settings. Since extremal points play an outsized role in determining modularisation, we consider three trends that highlight these effects. (1) Datasets from which successively smaller corners have been removed should become successively less mixed, until at a critical threshold the representation modularises. (2) It is vital that not just any data, but rather corner slices, that are removed. Removing similar amounts of random or centrally located data from the dataset should not cause as much mixing. (3) Introducing correlations into a dataset while preserving extreme-point or range independence should preserve modularity relatively well."}, {"title": "3 Modularisation in Biologically Inspired Nonlinear Feedforward Networks", "content": "Motivated by our linear theoretical results, we explore how closely biologically constrained nonlinear networks match our predicted trends. We study nonlinear representations with linear and nonlinear decoding in supervised and unsupervised settings. Surprisingly, coarse properties predicted by our linear theory generalise empirically to these nonlinear settings (Figure 2).\nMetrics for representational modularity and inter-source statistical dependence. To quantify the modularity of a nonlinear representation, we design a family of metrics called conditional information-theoretic modularity (CInfoM), an extension of the InfoM metric proposed by Hsu et al. [27]. Intuitively, a representation is modular if each neuron is informative about only a single source. We therefore calculate the conditional mutual information between a neuron's activity and each source variable given all other sources. The conditioning is necessary to remove the effect of sources leaking information about each other; prior works consider independent sources or do not account for this effect. CInfoM then measures the extent to which a neuron specialises to its favourite source, relative to its informativeness about all sources. In order to compare multiple schemes that change $p(s)$ in different ways, we report normalised source multiinformation (NSI) as a measure of source statistical interdependence. NSI involves estimating the source"}, {"title": "What-where task.", "content": "Inspired by the modularisation of what and where into the ventral and dorsal visual streams, we present nonlinear networks with simple binary images in which one pixel is on. The network is trained to concurrently report within which region of the image ('where'), and where within that region ('what') the on pixel is found, producing two outputs which we take as our sources, each an integer between one and nine. (More complex inputs or one-hot labels also work, see Appendix E.) We regularise the activity and weight energies, and enforce nonnegativity using a ReLU. If what and where are independent from one another, e.g. both uniformly distributed, then under our biological constraints (but not without them, see Appendix E) the hidden layer modularises what from where. Breaking the independence of what and where leads to mixed representations in patterns that qualitatively agree with our theory (Figure 2a left): cutting corners from the source support causes increasing mixing. Conversely, making other more drastic changes to the support, such as removing the diagonal, does not induce mixing. Similarly, introducing source correlations while preserving the rectangular support introduces less mixing when compared to corner cutting that induces the same amount of mutual information between what and where. The various source distributions at different NSI values are visualised in Figure 2b."}, {"title": "Nonlinear autoencoding of sources.", "content": "Next we study a nonlinear autoencoder trained to autoencode multidimensional source variables. Again we find (Figure 2a middle) that under biological constraints independent source variables (NSI = 0) result in modular latents and that source corner cutting (orange) induces far more latent mixing compared to introducing source correlations while preserving rectangular support (green), or removing central data (purple)."}, {"title": "Disentangled representation learning of images.", "content": "Finally, for an experiment involving high-dimensional image data, we turn to a recently introduced state-of-the-art disentangling method, quantised latent autoencoding (QLAE; Hsu et al. [27, 28]). QLAE is the natural machine learning analogue to our biological constraints. It has two components: (1) the weights in QLAE are heavily regularised, like our weight energy loss, and (2) the latent space is axis-wise quantised, introducing a privileged basis with low channel capacity. In our biologically inspired networks, nonnegativity and activity regularisation conspire to similarly structure the representation: nonnegativity creates a preferred basis, and activity regularisation encourages the representation to use as small a portion of the space as possible. We study the performance of QLAE trained to autoencode a subset of the Isaac3D dataset [43]. We find the same qualitative patterns"}, {"title": "4 Modularisation in Biologically Inspired Recurrent Neural Networks", "content": "Compared to feedforward networks, recurrent neural networks (RNNs) are often a much more natural setting for neuroscience. Excitingly, the core ideas of our analysis for linear autoencoders also apply to recurrent dynamical formulations, and similarly extend to experiments with nonlinear networks."}, {"title": "4.1 Linear RNNS", "content": "Linear sinusoidal regression. Linear dynamical systems can only autonomously implement exponentially growing, decaying, or stable sinusoidal functions. We therefore study biologically inspired linear RNNs constrained to model stable sinusoidal signals at certain frequencies:\n$z(t + dt) = W_{rec}z(t) + b_{rec}, W_{out}z(t) = \\begin{bmatrix} cos(\\omega_1 t + \\phi_1) \\\\ cos(\\omega_2 t + \\phi_2) \\end{bmatrix}, z(t) \\ge 0$. (12)\nWe study the optimal nonnegative, efficient, recurrent representations, $z_t$, and show that whether the representations of the two frequencies within $z_t$ modularises depends on their ratio. We prove and verify empirically that if one frequency is an integer multiple of the other the encodings mix, whereas if their ratio is irrational they should modularise. Further, we show empirically, and prove in limited settings, that rational non-harmonic ratios should modularise (Appendix C). The intuition for this result is much the same as the linear autoencoding setting: the natural notions of sources are the signals $(cos(\\omega_1 t), sin(\\omega_1 t), cos(\\omega_2 t), sin(\\omega_2 t))$. Using these sources, we must simply ask: does their support allow for a reduction in activity energy via mixing? In Figure 3a, we visualise the source support for the three prototypical relationships between $\\omega_1$ and $\\omega_2$: irrational, rational (but not harmonic), and harmonic. Results of neural network verifications are in Figure 3b (details Appendix G). In the irrational case, the source support is essentially rectangular, so the model modularises. In the harmonic case, large chunks of various corners are missing from the source support, so the model mixes. In the rational case, even though the source support is quite sparse, the corners are sufficiently present such that modularising is still optimal."}, {"title": "Modularisation of grid cells.", "content": "We now show that these spectral ideas can explain modules of grid cells. Grid cells are neurons in the mammalian entorhinal cortex that fire in a hexagonal lattice of positions [22]. They come in groups, called modules; grid cells within the same module have receptive fields (firing patterns) that are translated copies of the same lattice, and different modules are defined by their different lattice [60]. Current theories suggest that the grid cell system can be modelled as a RNN with activations built from linear combinations of frequencies [14], just like the linear RNNs considered here. Importantly, these grid cell theories use the same biological constraints as in this work and show that modules form because the optimal code contains non-harmonically related frequencies that are encoded in different neurons (Figure 3e top). This modularisation can now be theoretically justified in our framework, since non-harmonic frequencies are range-independent and so should be modularised (Figure 3e bottom)."}, {"title": "4.2 Nonlinear RNNS", "content": "Mixed sinusoidal regression for nonlinear RNNs. We train nonlinear ReLU RNNs with biologically inspired constraints to perform a frequency mixing task (details Appendix G). We provide a pulse input $P_{\\omega}(t) = I [mod(t) = 0]$ at two frequencies, and the network has to output the resulting \"beats\" and \"carrier\" signals:\nz(t + \\Delta t) = ReLU (W_{rec}z(t) + W_{in} \\begin{bmatrix} P_{\\omega_1} (t) \\\\ P_{\\omega_2} (t) \\end{bmatrix} + b_{rec}),  \\begin{bmatrix} cos([\\omega_1 - \\omega_2]t) \\\\ cos([\\omega_1 + \\omega_2]t) \\end{bmatrix} = W_{out}z_t + b_{out}$. (13)\nResults are in Figure 3c. Identical range-dependence properties but applied to the frequencies $\\omega_1 \\pm \\omega_2$ and $\\omega_1 + \\omega_2$ determine whether or not the network modularises: irrational, range-independent frequencies modularise; harmonics, with their large missing corners, mix; and other rationally related frequencies are range-dependent but no sufficient corner is missing, so they modularise.\nModularisation in nonlinear teacher-student distillation. To test our predictions of when RNNs modularise, but in settings more realistic than pure frequencies, we generate training data trajectories from randomly initialised teacher RNNs with tanh activation function, and then train student RNNs (with a ReLU activation function) on these trajectories. The student's representation is constrained to be nonnegative (via its ReLU) and has its activity and weights regularised (see Appendix G.2 for details). Using carefully chosen inputs at each timestep, we are able to precisely control the teacher RNN hidden state activity (i.e., the source distribution). This allows us to change correlations/statistical independence of the hidden states, while either maintaining or breaking range independence. We consider three settings (Figure 3e). First, when statistical and range independence are progressively broken (in orange). Second, where statistical, and to a lesser extent range, independence gets progressively broken (in green). Third, where only statistical independence gets progressively broken (in purple). We qualitatively observe, as our linear theory predicts, that students learns modular representations when range independence is maintained regardless of the statistical dependence of the teacher RNN hidden states (Figure 3f)."}, {"title": "5 Modularisation of Prefrontal Working Memory", "content": "We now apply our results to neuroscience to explain a puzzling difference in monkey prefrontal neurons in two seemingly similar working memory tasks. In both tasks [71, 45], items are presented to an animal, and, after a delay, must be recalled according to the rules of the task. Similarly, in both tasks, as well as in neural networks trained to perform these tasks [8, 48, 70], the neural representation during the delay period consists of multiple subspaces, each of which encodes a memory of one of the items. Bizarrely, in one task these subspaces are orthogonal to one another [45], a form of modularisation in the representation of different memories sans a preferred basis, while in the other they are not [71].\nIn more detail, Xie et al. [71] train monkeys on a sequential working memory task in which the subject observes a sequence of N dots positioned on a screen then, after a delay, must report that same sequence via saccading to the dot locations in order (Figure 4a). They find that the neural representation in the delay period decomposes into N subspaces (one for each item) that are significantly non-orthogonal. (To calculate the alignment we reanalysed the data using a different measure of alignment from the original paper, inspired by Panichello and Buschman [45]. This is because we find other measures to be biased Appendix H). On the other hand, in a related task, Panichello and Buschman [45] (P&B) find orthogonal memory. They present monkeys with two coloured squares, one below the other, then, after a delay, present a cue that tells the monkey to recall the top or bottom colour via a saccade to the appropriate point on a colour wheel (Figure 4c). P&B find that, during the delay after cue presentation, the colours are encoded in two subspaces that are orthogonal to one another (Figure 4d).\nWhy does one experiment result in orthogonality but the other not? Our theory says that differences in range (in)dependence can lead to modular or mixed (orthogonal or not in this case) codes. Crucially, across trials, P&B sample the two colours independently, whereas Xie et al. [71] sample the dots without replacement. The latter sampling scheme compromises orthogonality since there are corners (indeed an entire diagonal) missing from the source support."}, {"title": "6 Orthogonalisation of Preparatory and Potent Subspaces in Motor Cortex", "content": "For our second neuroscience puzzle we turn to the motor cortex. Neural activity in primate motor cortex appears to drive movements, such as reaching. Further, in classic delayed-reach tasks, where the monkey is shown a cue then, after a delay, has to reach towards that cue, there is a delay-period activity that encodes which movement the monkey is preparing to make [33]. This has led researchers to break the motor cortical neural activity into two subspaces: a preparatory neural subspace, in which upcoming movements are prepared, and a potent subspace that actually drives behaviour. RNN models trained on delayed-reach tasks also show preparation related activity. However, while in neural data these two subspaces are orthogonal, in most RNN models the two are aligned [21]. Intriguingly, a further study trained RNNs to perform two cued-reaches rapidly, one after another, and found that then the preparatory and potent subspaces were orthogonal [75]. Why are these subspaces aligned in RNNs trained on single action tasks, but orthogonal in both the brain and networks trained on dual-reach tasks?\nThis can be understood in our framework as an independence effect. During the dual-reach, but not the single-reach, task, the preparatory and potent subspaces are both being concurrently used. This ensures that the activity in the two subspaces can be range independent from one another, whereas in the single-reach case either the preparatory or the potent signal is non-zero, but never both. Since independence drives orthogonalisation, this means that only in the dual-task case is there a push towards orthogonalising the representation. We train networks to perform simple analogues of the single- and dual-reach tasks (details Appendix I) and recover the same results as stated: only those trained on dual-reach tasks have close-to-orthogonal potent and preparatory subspaces Figure 5. Finally, this effect only occurs if preparation and movement overlap. If a network is trained on dual-reach tasks in which the second preparatory cue arrives after the end of the first movement, the subspaces again align Figure 5. Motor cortex likely orthogonalises these subspaces since it is regularly performing sequences of movements, preparing the next while performing another. This is natural, but does mean that our predictions are really about the behaviour of RNN models, since no motor cortex is likely to have range-dependent preparatory and potent activity over the course of the animal's lifetime."}, {"title": "7 Modular or Mixed Codes for Space & Reward", "content": "Our last riddle comes from the entorhinal cortex. This brain area has been thought to contain precisely modular neurons, such as the grid cell code for self-position [22], object vector cells that fire at a particular displacement from objects [30], and heading direction cells [63]. Two recent papers examined the influence of rewarded locations on the grid cell code and find differing effects on the modularity of grid cells. Butler et al. [11] find that rewards rotate the grid cells, but preserve their pure spatial coding, while Boccara et al. [7] find that the grid cells warp towards the rewards, becoming mixed-selective to reward and space.\nWhittington et al. [69] study this discrepancy and point to the importance of the reward distribution in these two tasks: Boccara et al. [7] fix the positions of the possible rewards during one day, whereas Butler et al. [11] alternate the animals between periods of free-foraging for randomly placed rewards and periods of specific rewarded locations. However, the arguments of [69], which rely on source independence, are insufficient to explain these modularisation effects, as in neither case are reward and position independent; even in the experiments of Butler et al. [11] there are regions of space that are much more likely to be rewarded.\nHowever, with our improved understanding of modularisation, this makes sense. Despite Butler et al. [11] correlating reward and position, critically, they leave them range independent\u2014all combinations of reward and position are possible. On the other hand, Boccara et al. [7] make certain combinations of reward and position impossible, making them not just correlated, but range correlated. As such, our theory matches this modularisation pattern. To test this we train a linear biological RNN (details Appendix I) to report both its self-position and displacement from a reward as it moves around an environment (Figure 6). We train RNNs on settings with different relationships between reward and position; for some RNNs the rewards are in fixed positions in every environment (range dependent and statistically dependent), for others reward and position are uniformly random in each room (range independent and statistically independent),"}, {"title": "8 The Mixed Origins of Mixed Selectivity", "content": "Why neurons might be mixed selective is a matter of debate in neuroscience [3, 65]. Theories of nonlinear mixed selectivity have argued that, analogously to a nonlinear kernel, such schemes permit linear readouts to decode nonlinear task functions of the sources. This is likely a key part of the mixed selectivity found in some brain areas, like the cerebellum [37], mushroom body [1], and perhaps certain prefrontal or hippocampal representations [6, 9]. However, our theory raises the possibility for other explanations of both nonlinear and linear mixed selectivity that do not require tasks including nonlinear functions of the sources.\nMissing sources. First, a purportedly mixed selective neuron could actually be a modular encoding, but of a source variable unknown to the experimenter. For example, despite the many modular neurons in entorhinal cortex, there are also many neurons that seem mixed selective to combinations of spatial variables, such as speed, heading direction, or position [23]. An alternate explanation is that these neurons may (in part) be purely selective for another unanalysed variable that is itself correlated with the measured spatial variables or behaviour. We highlight a simple example of this effect in Figure 7a, b. Imagine a mouse is keeping track of three objects as it moves in an environment (Figure 7a); we"}, {"title": "Range-dependent sources.", "content": "Second, our theory gives a precise set of inequalities for (biologically constrained) modular- isation of scalar sources. Breaking the condition means the optimal representation is linearly mixed selective (Figures 1, 3, 4 and 7). These ideas also qualitatively predict modularisation of nonlinear feedforward and recurrent networks across a range of settings (Figures 2 and 3). Figure 7e, f re-illustrates these results, which suggest that nonlinear mixed selectivity might exist simply to save energy, rather than the typical rationale of permitting flexible linear readouts of arbitrary categorisations [3, 65]."}, {"title": "Sequential processing.", "content": "Finally, multiple works have highlighted nonlinear mixed selectivity to stimulus feature and time within task [46, 12, 13", "67": "train monkeys to view sequences of two images separated fixed delays (Figure 7g). To be rewarded, monkeys must report the stimuli, e.g., by saccading to the images in the correct sequence. Recently, Mikkelsen et al. [41"}]}