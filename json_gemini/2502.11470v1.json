{"title": "Optimized Detection of Cyber-Attacks on IoT Networks via Hybrid Deep Learning Models", "authors": ["Ahmed Bensaouda", "Jugal Kalita"], "abstract": "The rapid expansion of Internet of Things (IoT) devices has significantly increased the potential for cyber-attacks, making effective detection methods crucial for securing IoT networks. This paper presents a novel approach for detecting cyber-attacks in IoT environments by combining Self-Organizing Maps (SOMs), Deep Belief Networks (DBNs), and Autoencoders. These techniques are employed to create a system capable of identifying both known and previously unseen attack patterns. A comprehensive experimental framework is established to evaluate the methodology using both simulated and real-world traffic data. The models are fine-tuned using Particle Swarm Optimization (PSO) to achieve optimal performance. The system's effectiveness is assessed using standard cybersecurity metrics, with results showing an accuracy of up to 99.99% and Matthews Correlation Coefficient (MCC) values exceeding 99.50%. Experiments conducted on three well-established datasets NSL-KDD, UNSW-NB15, and CICIoT2023 demonstrate the model's strong performance in detecting various attack types. These findings suggest that the proposed approach can significantly enhance the security of IoT systems by accurately identifying emerging threats and adapting to evolving attack strategies.", "sections": [{"title": "1. Introduction", "content": "The rapid proliferation of Internet of Things (IoT) devices, now integral to both consumer and industrial systems, has contributed to a significant increase in network traffic complexity. Diverse IoT applications, ranging from smart homes to industrial automation, expose these systems to increasingly sophisticated cyber-attacks that continue to evolve in scale and strategy [1, 2, 3, 4]. As IoT ecosystems expand rapidly, cybercriminals exploit security gaps, posing a challenge for traditional detection mechanisms to keep pace with evolving threats. This underscores the need for advanced detection frameworks that not only identify current threats but also adapt proactively to emerging attack strategies.\nExisting network security methods, especially signature-based intrusion detection systems (IDS), are limited by their dependence on predefined patterns to detect threats. While effective against known vulnerabilities, they struggle against previously unknown (zero-day) attacks, as their reactive nature cannot cope with the rapidly changing threat landscape [5]. The explosive growth in IoT traffic further exacerbates these challenges, making it difficult for conventional systems to efficiently process and analyze network data in real-time without sacrificing accuracy [6]. This gap creates an urgent need for innovative, robust, and scalable solutions capable of protecting IoT networks from a wide spectrum of threats.\nIn response to these challenges, this paper proposes an advanced network intrusion detection framework that leverages Self-Organizing Maps (SOMs), Deep Belief Networks (DBNs), and Autoencoders, augmented by novel optimization techniques, to enhance both detection performance and operational efficiency. By employing a multi-faceted approach, the framework is designed to capture and analyze the complex spatial and temporal features inherent in IoT traffic. This holistic analysis allows for the identification of anomalous behaviors that traditional methods often miss, particularly when dealing with highly dynamic network environments.\nThe integration of these components not only enhances detection accuracy, but also addresses the pressing issue of scalability, making the framework viable for real-time deployment in large-scale IoT networks. By incorporating state-of-the-art machine learning techniques and optimization strategies, the proposed framework delivers a comprehensive solution for improving intrusion detection in highly dynamic and data-intensive IoT environments.\nRecent advances in machine learning-based IDS have demonstrated the potential of hybrid models that combine supervised and unsupervised learning techniques to tackle sophisticated attacks [7]. Furthermore, the introduction of attention mechanisms has significantly advanced the effectiveness as well as interpretability of deep learning models, allowing researchers and practitioners to better understand the reasoning behind model predictions [8]. Building on these developments, this paper leverages the strengths of SOMS, DBNs, and Autoencoders to create a unified framework specifically tailored to the unique security challenges posed by IoT environments.\nIn summary, the proposed detection framework represents a significant step forward in network security. By addressing the limitations of existing methods and introducing cutting-edge machine learning innovations, this research aims to provide a scalable and adaptable solution to the growing threat of cyber-attacks in IoT ecosystems. The subsequent sections provide a detailed explanation of the proposed methodology, experimental setup, and results, highlighting the practical effectiveness of the framework in real-world IoT scenarios. The key contributions of this paper are summarized as follows:\n\u2022 We present a novel detection framework that integrates SOMS, DBNs, and Autoencoders to capture complex spatial-temporal patterns in IoT traffic, enabling more precise anomaly detection and attack classification.\n\u2022 We introduce an advanced optimization algorithm that combines gradient-based hyperparameter tuning with adaptive learning rate adjustments, resulting in faster convergence and improved model performance.\n\u2022 We apply an attention mechanism to enhance feature extraction, providing deeper insights into the decision-making process of the detection system and improving model interpretability.\n\u2022 We propose a novel cost function that synergizes reconstruction errors from Autoencoders with feature clustering from SOMs and hierarchical representations from DBNs, yielding a more robust evaluation metric for model performance.\nThe structure of the paper is as follows: Section 2 reviews related work, providing context and background for the study. Section 3 offers a detailed explanation of the proposed detection framework. Section 4 presents and analyzes the experimental results. Section 5 concludes the paper with key findings, while Section 6 offers a discussion of the results, and Section 7 outlines potential directions for future research."}, {"title": "2. Related Work", "content": "This section reviews recent advances in network intrusion detection systems (NIDS), machine learning techniques applied to IoT security, and optimization strategies for improving detection frameworks. The reviewed works focus on developments from 2023-2025, highlighting the latest trends in using deep learning, hybrid models, and feature extraction techniques to enhance security in IoT environments.\nRecent advancements in IoT-specific threat detection highlight a growing trend toward hybrid models that combine supervised and unsupervised learning techniques. These models effectively mitigate the limitations of traditional methods by leveraging the strengths of both paradigms, resulting in improved detection accuracy, adaptability, and robustness. For instance, Kaliyaperumal et al. [9] introduced a hybrid unsupervised learning approach using Self-Organizing Maps to detect unknown threats in dynamic IoT ecosystems. Similarly, Tariq et al. [10] developed a hybrid intrusion detection system (IDS) that integrates machine learning with signature-based methods, significantly enhancing the detection of both known and emerging threats, including zero-day attacks in IoT networks.\nTo address feature selection challenges, Shenify et al. [11] proposed a model combining supervised learning with Spider Monkey Optimization. This approach optimizes feature selection, making it particularly effective in resource-constrained IoT environments where computational efficiency is critical.\nFurther innovations include adversarial realism and robust learning techniques. For example, Vitorino [12] explored hybrid learning models designed to enhance the resilience of IoT IDS against adversarial attacks. Additionally, Zhang et al. [13] investigated hybrid anomaly detection models by combining autoencoders with traditional machine learning algorithms, providing more reliable detection of complex and subtle attack patterns.\nA notable development in deep learning for IoT threat detection is the CNN-FDSA model by Kalidindi and Arrama [14]. This hybrid deep learning framework uses Convolutional Neural Networks (CNNs) and Deep Stacked Autoencoders (DSA) to detect botnet attacks in IoT networks. The model processes IoT network traffic with Quantile normalization, employs feature extraction techniques like Information Gain and City Block Distance, and addresses data imbalance through oversampling. Achieving 92.4% accuracy with high precision, recall, and F-measure, CNN-FDSA demonstrates its capability in reducing false positives and managing complex, imbalanced datasets. Future directions for this work include real-time botnet detection and the development of multi-layered security frameworks to fortify IoT networks.\nThese studies collectively reinforce the value of hybrid models that integrate unsupervised feature extraction with supervised classification techniques. By enhancing detection accuracy, adaptability, and resilience, these approaches align closely with the goals of this work to advance IoT-specific threat detection frameworks."}, {"title": "2.1. Data Privacy and Security in IoT Networks", "content": "Privacy concerns in IoT networks are a significant issue, as intrusion detection often requires access to sensitive data. Approaches like federated learning offer solutions, but challenges related to data leakage and model accuracy persist. Olanrewaju-George and Pranggono [15] proposed a federated learning-based intrusion detection system (IDS) for Internet of Things (IoT) devices, leveraging both unsupervised and supervised deep learning models to address security and privacy challenges in IoT networks. The study compares the performance of federated learning (FL) trained models with traditional non-FL models using the N-BaIoT dataset, which includes data from nine IoT devices. While the combination of unsupervised autoencoders (AEs) for anomaly detection and supervised deep neural networks (DNNs) for attack classification enhances the robustness and accuracy of the IDS, challenges related to data leakage and model accuracy persist. Data leakage can occur when sensitive information unintentionally influences model training, compromising privacy and security, while model accuracy may be impacted by the decentralized nature of FL, affecting its generalization across diverse devices. Hyperparameter tuning and the use of the FedAvgM FL algorithm help mitigate these issues, improving model performance, with results indicating that the unsupervised AE model trained via FL outperforms other models across various evaluation metrics. This demonstrates the effectiveness of FL in improving both performance and data privacy for IoT IDS, despite ongoing challenges around data leakage and model accuracy.\nChen et al. [16] explored privacy-preserving computation in federated learning (FL), emphasizing the importance of safeguarding data privacy in Al applications. This work surveys various privacy-preserving computation protocols, such as secure multi-party computing (SMC), homomorphic encryption (HE), differential privacy (DP), trusted execution environments (TEEs), and zero-knowledge proofs (ZKP). The study categorizes privacy attacks and highlights inference attacks, malicious servers, and poisoning attacks that pose threats to privacy in FL. Additionally, it evaluates and compares the security properties and efficiency of different protocols through experiments using common datasets like MNIST and CIFAR-10. The paper concludes by suggesting future research directions, including the integration of ZKP with FL and exploring machine unlearning for improved privacy and regulatory compliance.\nBuilding upon these privacy-enhancing techniques, Ali et al. [17] integrated Blockchain and Federated Learning (FL) to enhance intrusion detection systems (IDS) in industrial Internet of Things (IIoT) networks. The study addresses the limitations of centralized machine learning approaches in IIoT due to privacy and computational challenges, emphasizing the decentralization benefits offered by FL. Blockchain enhances security and privacy by enabling verifiable and secure data exchanges, while FL supports collaborative model training without exposing sensitive data. The paper provides a detailed analysis of existing IDS techniques, identifies trends and gaps in IIoT security, and suggests future research directions for combining Blockchain and FL. In conclusion, it stresses the importance of advanced, decentralized intrusion detection systems to protect IIoT networks and drive the success of Industry 4.0.\nWhile these studies highlight promising approaches to improve data privacy and security in IoT systems, challenges persist, including maintaining high model accuracy without compromising privacy, handling decentralized data securely, and ensuring that the implemented privacy-preserving protocols do not hinder the system's performance or scalability. Future work may explore more efficient methods for balancing security and performance, such as combining federated learning with edge computing, or refining blockchain protocols to improve their scalability and energy efficiency in IoT environments."}, {"title": "2.2. Network Intrusion Detection in IoT", "content": "The rapid adoption of IoT devices has intensified the need for robust network intrusion detection systems (NIDS) capable of identifying sophisticated cyber-attacks in real-time. Traditional IDS approaches are often inadequate in handling the unique characteristics of IoT environments, such as large-scale distributed systems, constrained resources, and heterogeneous communication protocols [18, 19]. To address these challenges, recent studies have shifted towards more adaptive and intelligent frameworks that leverage machine learning to enhance detection capabilities.\nOne such effort is the lightweight IDS proposed by Shen et al. [20], specifically designed for resource-constrained IoT devices. By employing a convolutional neural network (CNN) architecture, the system effectively balances detection accuracy with computational overhead, making it suitable for real-time deployment. While this approach has proven instrumental in mitigating common attack types such as Distributed Denial of Service (DDoS) and man-in-the-middle attacks, it is less effective against more complex intrusion patterns, highlighting the need for further advancements.\nBuilding on these advancements, Wang et al. [21] developed a deep learning-based NIDS that enhances feature extraction by combining group convolution for spatial features, Split-Attention for feature selection, and BiGRU for temporal features. To overcome data imbalance issues, they employed a Conditional Tabular Generative Adversarial Network (CTGAN), which significantly improved detection accuracy across datasets. Their model achieved impressive results, with accuracy rates of 91.08%, 94.55%, and 97.47% on the UNSW-NB15, CIC-IDS2018, and CIC-IOT2023 datasets, respectively. However, the system's high computational resource requirements and long training times present barriers to scalability, which the authors aim to address through cloud-edge collaboration and transfer learning.\nFurther addressing the need for robust IoT NIDS, Mynuddin et al. [22] introduced a system leveraging CNN for spatial feature extraction and Bidirectional Long Short-Term Memory (Bi-LSTM) for temporal pattern learning. This model excelled in binary classification tasks on the NSL-KDD dataset, achieving an outstanding accuracy and detection rates. However, challenges with the U2R class due to insufficient data underscore the importance of tackling data imbalance to enhance robustness.\nTo optimize feature selection and detection performance, Asgharzadeh et al. [23] proposed a hybrid intrusion detection system (IDS) for the Internet of Things (IoT) that combined deep learning and optimization techniques to enhance anomaly detection accuracy. They introduced a convolutional neural network (FECNNIOT) for effective high-level and low-level feature extraction and developed a binary multi-objective Gorilla Troops Optimizer (BMEGTO) to optimize feature selection. The proposed CNN-BMEGTO-KNN method achieved outstanding accuracy of 99.99% on the TON-IoT dataset and 99.86% on the NSL-KDD dataset. It outperformed traditional deep learning models like LSTM and MLP in terms of accuracy, precision, recall, and F1-score. The novelty of their approach lay in the advanced CNN design and the adaptation of the Gorilla Troops Optimizer for multi-objective binary feature selection.\nIn a different approach, Darabi et al. [24] introduced a novel Micro Reinforcement Learning Classifier (MRLC) for intrusion detection systems, leveraging a Deep Q-Network (DQN) agent to perform fine-grained learning for binary and multiclass classification tasks. The MRLC processes each training sample as an independent experiment, associating the value of each sample with the agent's learning rate to ensure robust learning. The approach incorporates a dynamic reward mechanism that guides the agent to prioritize accurate intrusion detection. They evaluated the architecture on three datasets, NSL-KDD, CIC-IDS2018, and UNSW-NB15, achieving an accuracy of 99.56%, 99.99%, and 99.01%, respectively. The novelty depends on their single-sample learning strategy, replay buffer updates, and ability to achieve comparable results even with a significantly reduced training set."}, {"title": "2.3. Deep Learning Approaches for IoT Security", "content": "Recent developments in deep learning have shown tremendous potential in improving the detection of complex, multi-stage cyber-attacks in IoT networks. Researchers have been particularly focused on the application of unsupervised learning techniques such as Self-Organizing Maps (SOMs), Deep Belief Networks (DBNs), and Autoencoders, which can detect previously unknown attack patterns without relying on labeled datasets [25, 26].\nThe integration of SOMs into IDS frameworks has garnered significant attention in the IoT domain due to their ability to map high-dimensional data into lower-dimensional representations, thus simplifying anomaly detection. For instance, Quraishi et al. [27] proposed a framework for real-time anomaly detection and mitigation in IoT-based smart grid cybersecurity systems, leveraging advanced deep neural networks, including autoencoders, LSTMs, GANs, and SOMs, along with transfer learning and attention mechanisms. The framework incorporated real-time adaptive mitigation strategies capable of autonomously responding to cyber threats, ensuring seamless operation of the smart grid. Extensive real-world testing demonstrated the system's scalability and resilience across a variety of cyber threats, affirming its practical applicability and robustness. Comparative evaluations against traditional methods highlighted its superior performance in anomaly detection, informed mitigation, and scalability. This comprehensive and versatile solution established a robust foundation for protecting IoT-based smart grids from evolving cybersecurity threats, offering a promising advancement for the field.\nDeep Belief Networks (DBNs) show promise in capturing temporal dependencies within IoT network traffic, which is crucial for detecting advanced persistent threats (APTs). Yang et al. [28] developed a real-time intrusion detection mechanism for wireless networks using a Conditional Deep Belief Network (CDBN). To address issues like data imbalance and dimensionality, the researchers created the \"SamSelect\" under-sampling algorithm and designed the Stacked Contractive Auto-Encoder (SCAE) for feature reduction. They combined the CDBN with these techniques to detect attacks in real-time, achieving an impressive detection accuracy of 97.4% with a detection time of 1.14 ms. Their study pioneered the application of CDBN to wireless network intrusion detection and introduced the SamSelect algorithm to balance the AWID dataset. The experimental results demonstrated that their method outperformed other deep and shallow learning approaches, showed robustness against noise, and provided valuable insights for advancing cybersecurity research.\nAutoencoders have been employed to further enhance detection frameworks by reducing data dimensionality and isolating outliers [29]. Ashraf et al. [30] introduced a LSTM autoencoder-based Intrusion Detection System (IDS) designed for Intelligent Transportation Systems (ITS), with a particular emphasis on detecting cyber-attacks targeting Autonomous Vehicles (AVs) and the Internet of Vehicles (IoVs). This IDS leveraged statistical feature extraction alongside the robust learning capabilities of LSTM to effectively detect anomalies in both in-vehicle communications and external network traffic. The architecture demonstrated proficiency in managing heterogeneous data by eliminating redundancy and extracting highly representative features, which significantly enhanced detection accuracy and minimized false alarms. Furthermore, it provided a comprehensive solution capable of addressing multiple attack vectors across in-vehicle and external communication systems. Despite its strengths, the system faced certain limitations, such as difficulties in accurately classifying multiclass attack categories and challenges related to scaling for large and complex IoV environments.\nIn addition, Prince et al. [31] explored how integrating IEEE standards and deep learning techniques enhanced the security of IoT devices in Japan from 2019 to 2024. They highlighted how the rapid adoption of IoT technology introduced significant cybersecurity challenges, driving the need for advanced protection methods. By conducting surveys and technical assessments, they identified key areas where IEEE standards and deep learning models, such as CNN and LSTM, effectively detected and mitigated cyber threats. Their findings showed that these approaches significantly improved the security posture of IoT networks, addressing risks like DoS attacks and malware. They also emphasized the importance of policy support and collaborative efforts between policymakers, researchers, and industry stakeholders to sustain and strengthen IoT security. Future research directions suggested continued exploration of deep learning advancements, federated learning, and real-time intelligence sharing to combat evolving cyber threats in IoT environments.\nDarabi et al. [24] examined the integration of machine learning (ML) techniques to enhance Industrial IoT (IIoT) security. It highlighted the benefits of IIoT, such as intelligent analytics and predictive maintenance, but also addressed the associated cybersecurity risks, including malware and cyberattacks. The study provided a comprehensive review of ML-based methods for vulnerability detection and security improvement, emphasizing techniques like CNN, LSTM, and active defense strategies. Additionally, the paper explored challenges in device authentication, data modeling, network detection, and static analysis, while suggesting future directions for adaptive machine learning models and unified data standards to address these issues. Finally, it outlined the evolving threat landscape in IIoT and discussed how ML models are essential for identifying and mitigating new cybersecurity risks.\nInuwa and Das [32] examined various machine learning methods for detecting anomalies in cyberattacks on IoT networks. It compared the efficacy of techniques such as Support Vector Machine (SVM), Artificial Neural Network (ANN), Decision Tree (DT), Logistic Regression (LR), and k-Nearest Neighbours (k-NN). The research utilized two large datasets ToN-IoT and BoT-IoT to evaluate the performance of these methods using metrics like accuracy, precision, recall, F1 score, and AUC score. Neural networks demonstrated superior performance among the methods, making them the most effective for anomaly detection. The findings suggested the potential for integrating these methods into industrial IoT environments for both research and practical applications. The study also highlighted future directions, including the incorporation of deep learning models and ensemble approaches to enhance anomaly detection in IoT networks.\nThe paper Ghaffari et al. [33] explored the security challenges associated with the rapid growth of IoT devices and applications. It highlighted vulnerabilities such as node spoofing, unauthorized data access, and cyberattacks, emphasizing the critical role of machine learning (ML) and deep learning (DL) in addressing these issues. The study provided a comprehensive review of ML/DL approaches in IoT security, categorizing recent research and offering insights into their opportunities, advantages, and limitations. The paper discussed state-of-the-art IoT-specific security challenges, including cyberattacks, eavesdropping, and intrusion detection. It also analyzed the integration of ML/DL with metaheuristic algorithms and addressed the adaptability challenges in ML/DL systems for dynamic IoT environments. Finally, the paper suggested the use of advanced algorithms like graph neural networks and AdaBoost for improving the accuracy of anomaly detection and classification in IoT security."}, {"title": "2.4. Hybrid Models for Network Intrusion Detection", "content": "The integration of multiple deep learning models has become an increasingly popular strategy for addressing the multifaceted nature of IoT security challenges. Hybrid models offer the benefit of combining the strengths of different techniques to provide a more comprehensive analysis of network traffic [34, 35, 36]. These models often incorporate both supervised and unsupervised learning techniques to maximize detection accuracy and adaptability to evolving threats.\nXuan et al. [37] introduced a hybrid framework that combines DBNs and recurrent neural networks (RNNs) for detecting sophisticated cyber-attacks. Their system achieved superior performance in identifying advanced persistent threats (APTs), where attack signatures evolve over time. The hierarchical representation of traffic features provided by DBNs complemented the temporal analysis capabilities of RNNs, creating a robust detection mechanism. However, this approach faced challenges in real-time applications due to the computational complexity associated with both DBNs and RNNs, highlighting a common trade-off in hybrid model design.\nBuilding on the need for computational efficiency, Albahar et al. [38] introduced a hybrid model that combines Directed Batch Growing Self-Organizing Map (DBG-SOM) and Radial Basis Function Neural Network (RBFNN) for anomaly-based intrusion detection. They addressed the limitations of traditional methods by designing DBG-SOM, which conserves topology more effectively and reduces network distortions. They further improved the model's accuracy and training speed by integrating DBG-SOM with RBFNN. This approach utilizes DBGSOM's dynamic growth mechanism and RBFNN's high precision, significantly outperforming earlier SOM and RBFNN-based models. Their experimental evaluation on three publicly available datasets (NSL-KDD, UNSW-NB15, and CICIDS2017) confirms that their hybrid model surpasses the conventional SOM-RBFNN approach and makes valuable contributions to intrusion detection systems.\nExpanding on these earlier frameworks, Chen et al. [39] proposed a hybrid intrusion detection system (IDS) that combined Network Intrusion Detection Systems (NIDS) and Host-based Intrusion Detection Systems (HIDS). This approach addressed limitations in detecting complex attacks, such as Advanced Persistent Threats (APTs), by leveraging a BERT-based methodology to transform host data into numerical formats. The system integrated this numerical representation with network data using a feature-flattening technique, enabling comprehensive analysis. It employed a two-stage collaborative classifier, first filtering benign traffic with a binary classifier and then using a multi-class classifier to identify specific attack types. The system demonstrated significant performance improvements over traditional machine learning models like XGBoost, particularly in detecting challenging attacks such as DoS-LOIC-UDP and DoS-SlowHTTPTest. The use of public datasets, CICIDS 2018 and NDSec-1, further validated the system's effectiveness, with macro average F1 scores showing notable improvements. Future work focused on enhancing accuracy through the inclusion of minority attack classes, data augmentation, and deep learning-based methods.\nBukhari et al. [40] took a different approach by introducing the the FL-SCNN-Bi-LSTM model to improve intrusion detection in Wireless Sensor Networks (WSNs). This hybrid framework combined Federated Learning (FL) with Stacked Convolutional Neural Networks (SCNN) and Bidirectional Long Short-Term Memory networks (Bi-LSTM), addressing privacy concerns by enabling multiple sensor nodes to collaboratively train a global model without sharing raw data. By leveraging advanced feature selection and deep learning methodologies, the model effectively detected sophisticated and previously unknown threats, achieving high performance on WSN-DS and CIC-IDS2017 datasets. However, challenges such as scalability, real-time processing, and adaptability to evolving threats remained, underscoring the need for further optimization and advanced feature selection techniques. Despite these challenges, the model demonstrated superior accuracy and robustness compared to traditional classifiers like SVM and LightGBM.\nFurther enhancing hybrid model design, Ullah et al. [41] integrated transformer-based transfer learning with traditional approaches to tackle imbalanced network traffic in intrusion detection. Their method, IDS-INT, leveraged semantic analysis through a multi-head attention-based transformer model to improve feature representation, addressing the challenges posed by imbalanced and complex datasets. The use of Synthetic Minority Oversampling Technique (SMOTE) ensured effective detection of minority attacks, while CNN and LSTM models incorporated for deep feature extraction. This combination of methods delivered high precision, recall, and F1-scores, outperforming traditional approaches. Additionally, the inclusion of explainable AI provided transparency and trustworthiness, making IDS-INT suitable for real-time and imbalanced network environments. This approach highlighted the importance of balancing innovation with practicality in real-world scenarios.\nFinally, Manocchio et al. [42] introduced FlowTransformer, a transformer-based framework tailored for Network Intrusion Detection Systems (NIDS). By focusing on flow-based data rather than packet-based analysis, the model effectively addressed scalability and privacy concerns associated with traditional methods. FlowTransformer incorporated interchangeable components, such as input encodings and classification heads, offering flexibility for various NIDS configurations. Evaluations on benchmark datasets demonstrated that the choice of classification heads significantly influenced model performance, with a notable reduction in model size by over 50% while maintaining accuracy. This flexibility and efficiency positioned FlowTransformer as a scalable solution for handling large-scale traffic in modern networks.\nCollectively, these studies underscore the potential of hybrid models to enhance intrusion detection systems by combining the strengths of various deep learning techniques. Future research will benefit from exploring broader datasets, refining preprocessing techniques, and optimizing hyperparameters to improve scalability and computational efficiency. As network environments grow increasingly complex, hybrid deep learning models will play a pivotal role in fortifying network and cloud infrastructures against sophisticated cyber threats."}, {"title": "2.5. Optimization Techniques in IoT Intrusion Detection", "content": "Optimizing the performance of IDS frameworks for IoT security has become a central focus of recent research, especially given the computational constraints of many IoT devices. Gradient-based optimization algorithms, adaptive learning rates, and hyperparameter tuning have been employed to improve both the accuracy and efficiency of machine learning models used in IDS frameworks [43, 44].\nOne of the key breakthroughs in this area is the work by Wei et al. [45], who proposed an adaptive learning rate adjustment mechanism to improve the convergence speed of deep learning-based IDS models. Their approach reduced the training time by 30%, while maintaining high detection accuracy, making it suitable for real-time deployment in large-scale IoT environments. Similarly, Kunang et al. [46] proposed a hybrid deep learning-based intrusion detection system (IDS) for IoT platforms, which combined unsupervised feature extraction and supervised classification. The model leveraged five unsupervised approaches, including deep autoencoders and stacked models, to effectively reduce data dimensions and extract relevant features. Researchers implemented an automatic hyperparameter tuning method using Bayesian optimization to enhance performance, achieving nearly 100% accuracy and a false positive rate close to 0% on the BoT-IoT dataset, along with 99.17% accuracy and a 0.18% FPR on the CSE-CIC-IDS2018 dataset. The novelty lay in its unique combination of feature extraction methods, transfer learning, and advanced hyperparameter tuning, which outperformed previous studies in terms of detection rate and classification of a broader range of attack types.\nIn parallel, metaheuristic algorithms have emerged as powerful tools for optimizing the feature selection process in IDS frameworks. For instance, Mrudula et al. [47] applied particle swarm optimization (PSO) to identify the most relevant features from IoT traffic data, effectively reducing the dimensionality and computational overhead without compromising detection accuracy. The application of metaheuristic techniques such as PSO and genetic algorithms not only enhances the performance of IDS frameworks but also addresses the unique resource constraints of IoT environments, paving the way for more efficient and scalable solutions.\nBased on these foundational techniques, Majidian et al. [48] introduced a novel intrusion detection system for IoT networks that leverages Software-Defined Networking (SDN) and optimized random forest models. By partitioning the network into subdomains and employing an ensemble classification model based on decision trees optimized by genetic algorithms, their approach achieved significant improvements in scalability and adaptability. This distributed architecture reduced computational overhead and enabled localized or cooperative intrusion detection, addressing challenges inherent in diverse IoT environments. Experimental evaluations using the NSLKDD and NSW-NB15 datasets demonstrated superior accuracy rates, underscoring the effectiveness of combining SDN with optimized machine learning models. Future directions for this work include the integration of deep learning techniques for feature extraction and dynamic updates to adapt to emerging threats.\nExtending these principles to specialized IoT domains, Korium et al. [49] developed an intrusion detection system tailored for the Internet of Vehicles (IoV), focusing on complex attack scenarios like Denial-of-Service, Botnets, and Sniffing. Their methodology incorporated Z-score normalization, regression-based feature selection, and ensemble models such as Random Forest and LightGBM, enhanced through hyperparameter optimization. By combining multiple datasets for training, they achieved a remarkable balance between accuracy and execution time, with notable improvements over traditional approaches. This study highlights the benefits of dataset integration and advanced ensemble modeling, while also identifying future opportunities in deep reinforcement learning and transfer learning to further enhance IDS performance.\nFinally, Pandithurai et al. [50] applied a similar optimization driven approach to cloud security by focusing on DDoS attack detection. Using the Honey Badger Optimization (HBO) algorithm for feature selection and a Bi-LSTM classifier, their model achieved impressive accuracy and sensitivity metrics. This work exemplifies the growing trend of integrating optimization algorithms with advanced machine learning models to address the evolving threats in both IoT and cloud environments. By combining Bayesian and Z-Score normalization with HBO and Bi-LSTM, the study effectively bridged the gap between robust feature selection and high-accuracy intrusion detection.\nThese studies illustrate the diverse strategies being employed to enhance IDS frameworks for IoT and related domains. From adaptive learning rates and hyperparameter tuning to metaheuristic optimization and advanced ensemble modeling, researchers continue to push the boundaries of what is achievable in intrusion detection, paving the way for more resilient and scalable solutions."}, {"title": "2.6. Attention Mechanisms for Enhancing Model Interpretability", "content": "The use of attention mechanisms in deep learning models has gained considerable traction in IoT security due to their ability to improve feature extraction and model interpretability. Attention mechanisms allow models to focus on the most relevant portions of the input data, thereby enhancing decision-making processes [51, 52].\nSarker et al. [53] proposed an attention-based CNN to improve the interpretability of IDS models by highlighting the most critical features contributing to the model's decisions. This technique has been particularly effective in identifying subtle attack patterns that traditional models might overlook. By applying attention mechanisms, the model demonstrated improved detection accuracy and reduced false-positive rates in high-traffic IoT environments.\nBuilding on this work, Admass and Bogale [54] developed an attention-based hybrid model that integrates LSTM networks with DBNs. The attention mechanism enabled the model to prioritize critical time steps in the LSTM sequence, significantly enhancing the detection of complex temporal attack patterns. This approach not only improved detection rates but also provided insights into the model's decision-making process, addressing concerns related to the black-box nature of deep learning models.\nThe landscape of network intrusion detection in IoT environments has seen significant advancements in recent years, particularly through the application of deep learning and hybrid models. The integration of SOMs, DBNs, Autoencoders, and attention mechanisms has demonstrated great promise in enhancing both the accuracy and interpretability of IDS frameworks. However, challenges related to scalability, real-time processing, and computational efficiency persist, particularly in resource-constrained IoT environments. Future research should focus on optimizing these frameworks for deployment in large-scale IoT networks, while continuing to explore innovative techniques for improving detection accuracy and reducing false-positive rates.\nFurthermore, Saiyed et al. [55] introduced the ADEPT system, an AI-driven solution for DDoS detection in Consumer IoT (CIoT) networks, which combined explainable and optimized deep ensemble learning techniques. The system integrated CNN and LSTM models in an attention-based framework, achieving over 90% accuracy in detecting both high- and low-volume DDoS attacks while optimizing resource use through Differential Evolution-based pruning and Min-Max quantization. ADEPT incorporated a user interface that leveraged SHAP for global feature importance explanations and risk assessments, enhancing model interpretability and facilitating Human-Computer Interaction (HCI). Evaluations using diverse datasets, such as ToN-IoT and CICIOT-2023, demonstrated the system's adaptability to varying attack scenarios and its efficient deployment on resource-constrained edge devices. The system balanced detection accuracy with computational efficiency, achieving consistent performance across attack types while reducing inference time and memory usage. Future work aimed to optimize the network data parser, integrate pruning during training, and explore human-in-the-loop strategies for improved real-world applicability.\nBahadoripour et al. [56] introduced an explainable deep federated multi-modal framework for detecting cyber-attacks in Industrial Control Systems (ICS), preserving data privacy while addressing challenges posed by heterogeneous data distributions across clients. The model employed representation learning to transform client data into a latent space, domain adaptation to align diverse client distributions into a mutual representation space, and federated learning to collaboratively train a detection model without data sharing. The SHapley Additive exPlanations (SHAP) method enhanced explainability by supporting feature importance analysis, which facilitated better decision-making and improved model retraining. Experimental evaluations demonstrated an 8.2% improvement in F1-score across three clients and a 4.9% increase when using a reduced feature set, showcasing its adaptability and robustness in varying scenarios. Future work aimed to integrate attention layers for model interpretability without external tools like SHAP and explore enhancements for real-world applicability.\nAbudurexiti et al. [57] introduced an explainable unsupervised anomaly detection framework designed for Industrial Internet of Things (IIoT) systems. The framework addressed challenges posed by limited labeled data and aimed to improve interpretability. By extracting local features through a one-dimensional CNN combined with a Convolutional Block Attention Module (CBAM), the framework captured long-term dependencies using an improved Time Convolutional Network (TCN) and Kolmogorov-Arnold Network (KAN) based Variational Auto-Encoder (VAE). The model trained in an unsupervised manner and utilized Explainable Artificial Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP), to enhance feature importance analysis. Experimental evaluations showed that the framework outperformed other unsupervised methods, achieving effective anomaly detection in complex industrial systems. The study also discussed potential future work, including semi-supervised methods and adaptation across various domains.\nXie et al. [58] proposed an anomaly detection model called Meta-MWDG to effectively solve the problem of multivariate time series anomaly detection in IoT environments. This model combined technologies such as multi-scale discrete wavelet decomposition, dual graph attention networks, and model-agnostic meta-learning (MAML) to improve the precision and generalization of anomaly detection. By integrating multi-scale discrete wavelet decomposition and dual graph attention networks, the model captured temporal dependencies and feature correlations at different scales. The joint optimization strategy using gated recurrent units (GRU) combined with a multi-head self-attention mechanism enhanced the precision of anomaly detection while reducing model parameters. MAML further improved the model's performance by enabling quick adaptation to new tasks with limited training data."}, {"title": "2.7. Challenges in Detecting Unknown Attacks", "content": "The detection of unknown attacks presents significant challenges across various domains, including network security, IoT, and industrial cyber-physical systems. Despite advancements in machine learning and deep learning techniques, several recurring themes emerge from the reviewed approaches, highlighting both solutions and remaining hurdles.\nDifferent studies adopt various methodologies to address unknown attacks. For instance, Ahmad et al. [59", "60": "integrate anomaly detection with abductive reasoning, using Isolation Forest and Answer Set Programming (ASP) to diagnose unknown threats in smart homes. Zohourian et al. [61"}]}