{"title": "Detecting and Measuring Confounding Using Causal Mechanism Shifts", "authors": ["Abbavaram Gowtham Reddy", "Vineeth N Balasubramanian"], "abstract": "Detecting and measuring confounding effects from data is a key challenge in causal inference. Existing methods frequently assume causal sufficiency, disregarding the presence of unobserved confounding variables. Causal sufficiency is both unrealistic and empirically untestable. Additionally, existing methods make strong parametric assumptions about the underlying causal generative process to guarantee the identifiability of confounding variables. Relaxing the causal sufficiency and parametric assumptions and leveraging recent advancements in causal discovery and confounding analysis with non-i.i.d. data, we propose a comprehensive approach for detecting and measuring confounding. We consider various definitions of confounding and introduce tailored methodologies to achieve three objectives: (i) detecting and measuring confounding among a set of variables, (ii) separating observed and unobserved confounding effects, and (iii) understanding the relative strengths of confounding bias between different sets of variables. We present useful properties of a confounding measure and present measures that satisfy those properties. Empirical results support the theoretical analysis.", "sections": [{"title": "Introduction", "content": "Understanding the underlying causal generative process of a set of variables is crucial in many scientific studies for applications in treatment and policy designs [44]. While randomized controlled trials (RCTs) and causal inference through active interventions are ideal choices for understanding the underlying causal model [19, 12, 13, 55], RCTs and/or active interventions are often impossible/infeasible, and some times unethical [50, 6]. Research efforts in causal inference hence rely on observational data to study causal relationships [44, 59, 65, 18, 41]. However, recovering the underlying causal model purely from observational data is challenging without further assumptions; this challenge is further exacerbated in the presence of unmeasured confounding variables.\nA confounding variable is a variable that causes two other variables, resulting in a spurious association between those two variables. As exemplified with Simpson's paradox [58] and many other studies [20, 1, 31], the presence of confounding variables is an important quantitative explanation for why correlation does not imply causation. It is challenging to observe and measure all confounding variables in a scientific study [60, 44]. Identifying latent or unobserved confounding variables is even more challenging, and misinterpretation presents various challenges in downstream applications, such as discovering causal structures from observational data. Numerous methods operate under the assumption of causal sufficiency [45, 4, 60, 8, 51, 65], implying the non-existence of unobserved confounding variables. Causal sufficiency presupposes that all pertinent variables required for causal inference have been observed. However, this may not be a practical or testable assumption.\nThe study of confounding has various applications, chief among them being causal discovery - identifying the causal relationships among variables [38, 40, 63]. It is also useful for determining whether a set of observed confounding variables is sufficient to adjust for estimating causal effects [29], measuring the extent to which statistical correlation between variables can be attributed to confound-"}, {"title": "Related Work", "content": "The study of confounding has typically been embedded as part of causal discovery algorithms in most existing work. Causal discovery methods can be categorized according to several criteria, including the type of data utilized (observational versus interventional/experimental), parametric versus non-parametric approaches, or whether they relax causal sufficiency assumptions [65, 59]. Considering our focus in this work on studying confounding comprehensively by going beyond observed confounding variables, we discuss literature that are directed towards methods that relax the causal sufficiency assumption and rely on experimental data.\nCausal Discovery via Observational Data, Relaxing Causal Sufficiency: Constraint based causal discovery algorithms produce equivalence class of graphs that satisfy a set of conditional independence constraints [60, 11, 9, 42]. Other methods such as [2, 28, 27] reduce the problem complexity by assuming a parametric form of the underlying causal model (e.g., variables are jointly Gaussian in Chandrasekaran et al. [7]), thereby returning unique causal graphs. Nested Markov Models (NMMs) [56, 57, 49, 14] allow identifiability of causal models with latent factors by using (pairwise) Verma constraints. A recent approach using differentiable causal discovery [2] combines NMMs with the differentiable constraint [66] to discover a partially directed causal network and likely confounded nodes. Unlike these methods, our focus in this work is on detecting and measuring confounding under various settings, instead of recovering the entire causal graph or equivalence class.\nCausal Discovery Using Data From Multiple Environments: Given access to a set of observed confounding variables, very recent work [29] presented testable conditional independence tests that are violated only when there is unobserved confounding. However, their analysis is focused towards the downstream causal effect estimation. We aim to provide a unified framework for studying and measuring confounding under different types of contextual information available."}, {"title": "Background and Problem Setup", "content": "Let X be a set of observed variables and Z be a set of unobserved or latent variables. The values of X, Z can be real, discrete, or mixed. Let G be the underlying directed acyclic graph (DAG) among the variables V = X \u222a Z. Directed edges among the variables in V indicate direct causal influences. Assume that the set of unobserved variables Z are jointly independent and are exogenous to X (i.e., Z_i \\bot Z_j and X_k \\not \\rightarrow Z_j \\forall i,j,k). In this setting, any two nodes X_i, X_j \\in X sharing a common parent Z_k \\in Z are said to be confounded, and Z_k is said to be a confounding variable. For a node X_i \\in X, PA_i = {X_j \\in X|X_j \\rightarrow X_i} \\cup {Z_j \\in Z|Z_j \\rightarrow X_i} denotes the set of parents of X_i.\nFor a node X, P(X_i|PA_i) is called the causal mechanism of X_i. The causal mechanism P(X_i|PA_i) encodes how the variable X_i is influenced by its parents PA_i. Following earlier work [22, 38, 45, 21, 46, 52], we make the following general assumption about the underlying causal mechanisms of data.\nAssumption 3.1. (Independent Causal Mechanisms [44, 47]) A change in P(X_i|PA_i) has no effect on and provides no information about P(X_j|PA_j) \\forall j \\ne i.\nIdentifying confounding from only observational data is challenging without further assumptions [28]. Hence, following earlier work [38, 29, 40], we assume that the data over the variables X is observed over multiple contexts or environments. While there are various ways of formulating/constructing contexts, in this paper, we assume that each context is created as a result of either hard (a.k.a. structural) interventions or soft (a.k.a. parametric) interventions on a subset V_s \\subseteq V of variables where S is a set of indices. Performing hard intervention on a variable V_i is the same as setting the value of V_i to a value v_i. Hard intervention on a variable V_i removes the influence of its parents PA_i on V_i. Performing soft intervention on a variable V_i is the same as changing the causal mechanism of V_i, P(V_i|PA_i), with a new causal mechanism P(V_i|PA_i). Soft intervention on a variable V_i does not remove the influence of its parents PA_i on V_i. The idea of explicitly considering context information and using different contexts as context variables to create extended causal graphs has been studied in the literature. Context variables are also called as policy variables, decision variables, regime variables, domain variables, environment variables, etc. [40, 45, 17, 22].\nLet C = {C_1, C_2, ..., C_n} be the set of n contexts and let P_C(X), c \\in C, denotes the probability distribution of the observed variables X in the context c. Let C_{SAR}, where S, R are sets of indices, be"}, {"title": "Detecting and Measuring Confounding", "content": "In this section, we present methods for detecting and measuring confounding for various scenarios in which shifts in causal mechanisms are observed. Considering any three observed variables X_i, X_j, X_o \\in X and an unobserved confounding variable Z \\in Z, we present measures of confounding depending on the information about mechanism shifts of X_i, X_j, X_o, Z. Each of the following subsections includes: (i) a definition of confounding, (ii) a corresponding definition of the confounding measure, (iii) a method for isolating the unobserved confounding measure from the overall confounding, (iv) an extension of the confounding measure to more than two variables, and (v) key properties of the proposed confounding measures. See Tab. 1 and Fig. 1 for an overview."}, {"title": "Setting 1: Measuring Confounding Using Directed Information Between Xi, Xj.", "content": "In this setting, we use the fact that directed information does not vanish in the presence of a confounding variable [64, 48]. To this end, we leverage the interventional effects of X_i, X_j on each other to define a measure of confounding."}, {"title": "Algorithm", "content": "Algorithm 1 outlines the procedures to measure confounding in all three settings and can be extended to the case where we evaluate conditional confounding and evaluating confounding among multiple variables. We present two real-world examples where our methods can be applied in Appendix \u00a7 B."}, {"title": "Experiments and Results", "content": "We perform simulation studies to verify the correctness of the proposed measures. All the experiments are run on a CPU. We report the mean and standard deviation of results taken over five random seeds. Code to reproduce the results is presented in the supplementary material. Code is available at https://github.com/gautam0707/CD_CNF.\nMeasuring Confounding: In this set of experiments, we consider the following four causal structures made of three nodes X_i, X_j, Z: G1 : Empty graph over Z, X_i, X_j i.e., nodes are isolated in the graph, G2: X_i\\rightarrow X_j, G3 : Z \\rightarrow X_i, Z \\rightarrow X_j, G4 : Z \\rightarrow X_i, Z \\rightarrow X_j, X_i\\rightarrow X_j. In G1, G2, there is no confounding between X_i, X_j and in G3, G4 there is confounding effect of Z on X_i and X_j. Results in Fig. 2 show that our measures output zero when there is no confounding between X_i, X_j and output positive values when X_i, X_j are confounded by a confounding variable Z.\nMeasuring Conditional Confound-ing: We consider the following two causal structures. G5: Z_1\\rightarrow X_i, Z_1\\rightarrow X_j, Z_2 \\rightarrow X_i, Z_2 \\rightarrow X_j, X_i\\leftrightarrow X_j. G6 : Z \\rightarrow X_i, Z \\rightarrow X_j, X \\rightarrow X_j. In G5, X_i and X_j are confounded by two variables Z_1, Z_2. We measure conditional confounding between X_i, X_j conditioned on (\\emptyset, Z_1, and Z_2 respectively. Since confounding still exists in all of the above conditioning settings, CNF-2 correctly returns positive confounding value in all three cases (see Fig. 3 left). On the other hand, in G6, we measure conditional confounding"}, {"title": "Downstream Causal Effect Estimation:", "content": "For the causal graphs G3, G4, we examine the impact of controlling for nodes identified using our method. We measure the causal effect of X_i on X_j with and without controlling for the detected confounding variable and report the absolute difference between the true and estimated causal effects in Tab. 3. The results show that controlling for the variables identified by our method reduces the bias in the estimated causal effects.\nBinary Data - Erd\u00f6s-R\u00e9nyi Causal Graphs: To verify the performance of our method on a large scale, similar to [38], we generate causal graphs of various number nodes using Erd\u00f6s-R\u00e9nyi model. In these experiments, each context is a result of intervention on one node. This is the reason for having the same value for number of nodes N and number of contexts C. Sample size denotes the number of data points used in each context. We detect and measure whether each pair of nodes is confounded or not. We then calculate the Precision, Recall, and F1 scores. Our confounding measures obtain good results across all settings."}, {"title": "Conclusions, Limitations, and Future Work", "content": "In this paper, based on the known causal mechanism shifts of observed variables, we propose three measures of confounding along with their conditional and multivariate variants. We also study key properties of these measures. Our measures complement each other depending on the available context information. We propose algorithms to compute the proposed measures and empirically verify their correctness. However, for the same confounded pair of variables, our metrics may yield different results depending on the chosen measure. As discussed in the introduction, the measures are intended to assess the relative strengths of confounding rather than for point-to-point comparison. The number of contexts required to evaluate the measure can be large because many contexts without changes in particular mechanisms are discarded. Identifying appropriate real-world datasets and applying the proposed measures to those datasets is an interesting area for future work, as is developing measures that efficiently use context information. Additionally, devising new definitions for confounding and proposing corresponding confounding measures is also an interesting future direction. We aim to pursue these ideas."}, {"title": "Setting 2: Detecting and Measuring Confounding Using the Mechanism Shifts of Z.", "content": "The previous setting utilizes the interventional effects of X_i(X_j) on X_j(X_i) to define a measure of confounding between X_i, X_j. In this setting, we utilize the association between the observed marginal distributions of X_i, X_j under causal mechanism shifts of Z to measure confounding. To this end, similar to [38], we make the following assumption.\nAssumption 4.1. (Shift Faithfulness [38]) Let Z be a common parent for a set of variables X_s \\subset X. Then each causal mechanism shift in Z between two contexts c, c' entails a causal mechanism change in each X_i \\in X_s between the same contexts c, c'.\nOne consequence of the Assumption 4.1 is that a change in the causal mechanism of Z induces correlations between the expectations of X_i, X_j in different contexts. To understand this, consider the following structural equations.\nZ \\sim N(\\mu(c), \\sigma^2(c)) \nX_i := \\alpha Z + \\epsilon_i\nX_j := \\beta X_i + \\gamma Z + \\epsilon_j"}, {"title": "Setting 3: Observing the Causal Mechanism Shifts in Z and Known Causal Path Direction Between Xi and Xj", "content": "Similar to the previous settings, we utilize marginal and conditional distributions of X_i, X_j to define a measure of confounding. By prior knowledge, if we know the direction of causal path between X_i, X_j, we can utilize the causal direction to measure confounding as explained below. In addition to the notations E^{Z}_i, E^{Z}_j introduced in the previous setting, let us denote for each c \\in C^{\\{i\\}\\{j\\}}, E^{X_i}_{X_j\\sim P_c (X_i|X_j)} (X_i|X_j), E^{X_j}_{X_i\\sim P_c (X_j|X_i)} (X_j|X_i) with E^{X_i}, E^{X_j} respectively. We now leverage dependency among these variables to define the measure of confounding. Intuitively, if X_i \\rightarrow X_j and if we observe a change in the causal mechanisms of both X_i, X_j due to the causal mechanism changes in Z, we also observe a change in the causal mechanism P(X_j|X_i).\nDefinition 4.7. (Confounding Measure 3) When the causal mechanism shifts are observed for X_i, X_j and the causal direction between the nodes X_i, X_j is known, under the Assumptions 3.2-4.1, the measure of confounding CNF-3(X_i, X_j) between X_i \\in X and X_j \\in X is defined as\n\\begin{cases} 1-e^{-I(E^{X_i}E^{X_j})} & \\text{if } X_i\\rightarrow\\ldots\\rightarrow X_j \\\\ 1-e^{-I(E^{X_j}E^{X_i})} & \\text{if } X_j\\rightarrow\\ldots\\rightarrow X_i \\\\ CNF-2(X_i, X_j) & \\text{Otherwise} \\end{cases}\nTo measure the unobserved confounding strength in the presence of an observed confounding variable X_o, similar to setting 2, we can modify Eqn. 10 to condition on the variable X_o.\nBeyond Pairwise Confounding: Using the Assumption 4.2, we have the following.\nTheorem 4.5. Let X_s be a set of variables such that all X_i, X_j \\in X_s are pairwise confounded and the causal relationships among each pair X_i, X_j. Then X_s is jointly confounded if and only if for each triple X_i, X_j, X_k \\in X_s we have I(E^{X_i}_{X_j}E^{X_i}_{X_k}) < I(E^{X_i}_{X_j}E^{X_i}_{X_k}).\nSince we have access to random variables E^{X_i} in addition to E^{Z}_i, E^{Z}_j, it is not straightforward to use all of them to measure joint confounding. To keep the measure simple, we let the measure of joint confounding among the variables X_s be the same as CNF-2(X_s). That is, CNF-3(X_s) = CNF-2(X_s). Setting 3 is an alternative to Setting 2 when we know the direction of the causal path between X_i, X_j. Settings 2 and 3 act as complementary to each other in validating the correctness of our analysis.\nTheorem 4.6. For any three observed variables X_i, X_j, X_o, and an unobserved confounding variable Z, the following statements are true for the measure CNF-3."}]}