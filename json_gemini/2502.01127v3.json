{"title": "The Battling Influencers Game: Nash Equilibria Structure of a Potential Game and Implications to Value Alignment", "authors": ["Young Wu", "Yancheng Zhu", "Jin-Yi Cai", "Xiaojin Zhu"], "abstract": "When multiple influencers attempt to compete for a receiver's attention, their influencing strategies must account for the presence of one another. We introduce the Battling Influencers Game (BIG), a multi-player simultaneous-move general-sum game, to provide a game-theoretic characteriza-tion of this social phenomenon. We prove that BIG is a potential game, that it has either one or an infinite number of pure Nash equilibria (NEs), and these pure NEs can be found by convex optimization. Interestingly, we also prove that at any pure NE, all (except at most one) influencers must exaggerate their actions to the maximum extent. In other words, it is rational for the influencers to be non-truthful and extreme because they antici-pate other influencers to cancel out part of their influence. We discuss the implications of BIG to value alignment.", "sections": [{"title": "1. Introduction", "content": "Life is full of agents who want to influence others: Food truck vendors entice us with BBQ samples; Social media influencers review selective pickleball brands to persuade us; Editors publish op-eds to sway public opinions. When multiple influencers with conflicting interests battle for our attention, intuitively they would be strategic and adjust their actions to account for the presence of one another in order to be effective.\nThis paper presents a game theoretic definition of the Battling Influencers Game (BIG). We model the influencers as players in a multi-player simultaneous-move general-sum game. Our main technical result is that BIG is a potential game with special pure Nash Equilibria structures. Consequently, we can predict how rational influencers would adjust their strategies in the battle: exaggeration is inevitable. This prediction may shed new computational light on the genesis of misinformation.\nAs a use case, BIG can be applied to the AI value alignment problem. The receivers of the influence were traditionally people, but can extend to AI value alignment algorithms. However, unlike in standard machine learning, our focus is not on the value alignment algorithm itself. Instead, BIG predicts how battling alignment-data providers could be motivated to intentionally produce training data that do not truthfully reflect their values. While out of scope for the current paper, our insight can help design future value alignment algorithms to remove such incentives."}, {"title": "2. Related Work", "content": "Our work provides a game theoretic model of the numerical example and informal theorem in section 5 of (Park et al., 2024), in particular, we also assume strategic data providers (which we call influencers) to large language models (which we call receivers), and our model leads to results consistent with their example where the data providers untruthfully report their opinions. In addition, we prove the existence of pure strategy Nash equilibria of this class of games, and we show the property that almost all influencers maximally exaggerate their preferences in every equilibrium. Our work is also closely related to (Hao & Duan, 2024), which mod-els the interaction between multiple influencers by a dy-namic Bayesian game. They described the phenomenon of strategic extreme exaggeration, which is also discussed in (Sun et al., 2024), (Soumalias et al., 2024), (Conitzer et al., 2024), and (Roughgarden & Schrijvers, 2017) for various applications, but they do not explicitly compute the equilibria of the original game or quantify the amount of exaggeration. In comparison, we use a static game with known influencer types and we are able to provide better characterizations of the set of equilibria of the game.\nValue alignment aims to make language models produce outputs that are more aligned with human values. Exist-ing training frameworks tailored for this purpose, such as (Ouyang et al., 2022) and (Rafailov et al., 2024), collect preference data from humans and train a large language model to follow users' intent. However, research in this direction mostly focuses on the algorithmic aspects of value alignment and does not emphasize the heterogeneity of hu-man values. There has been work that studies how to make LLMs align with diverse preferences of different demo-"}, {"title": "3. Problem Definition", "content": "The Battling Influencer Game (BIG) is an n-player simultaneous-move game. The players are the n influ-encers. The players have a common continuous action space $X \\subset \\mathbb{R}^d$ which is compact and convex. Let $x_i \\in X$ be the action of the ith player for $i \\in [n] := \\{1, 2, ..., n\\}$. For ex-ample, $x_i$ could be the embedding vector of the text corpus that influencer i produces. A joint action, or pure strategy profile, $x = (x_1,...,x_n)$ denotes the simultaneous action choice of all influencers. As in standard literature, we also write $x = (x_i, x_{-i})$ when we want to emphasize player i.\nFor the narrative, we posit a receiver whom the influencers want to influence. The receiver is not a strategic agent and not a player of the game. Like an impressionable person, the receiver aggregates to various degrees the inputs it re-ceives from all influencers. In this paper we consider affine receivers of the form\n$\\bar{x} := W_0x_0 + \\sum_{i=1}^n W_ix_i,$\nwhere $w_i$, $i \\in [n]$ is a real-valued (not necessarily normal-ized) weight that signifies how much influence influencer i has on the receiver. For example, a company which can af-ford to buy more ads has a larger $w_1$ compared to a company with a smaller budget. $x_0 \\in X$ is a bias term that, together with $w_0 \\in \\mathbb{R}$, denotes a fixed, constant \"background\" influ-ence that is beyond the control of the n influencers. The receiver (1) is common knowledge to all players.\nThe n influencers each has a target $t_i \\in \\mathbb{R}^d$ (i.e. the target is not restricted to X). For example, $t_i$ could be the embedding vector of the published party manifesto of political party i. The goal of influencer i is to drive the receiver's $\\bar{x}$ close to $t_i$. This goal is reflected in the loss (negative utility) function of influencer i. For concreteness, here we consider squared 2-norm as the loss:\n$l_i(\\bar{x}) := ||\\bar{x} - t_i||_2^2 = ||W_0x_0 + \\sum_{i=1}^n W_ix_i - t_i||_2^2.$\n(See Section 5.1 for an alternative using cosine similarity.) As rational agents, the influencers want to selfishly minimize"}, {"title": "4. Pure NEs of BIG and Their Properties", "content": "Definition 2. A pure strategy Nash equilibrium of the game $G = (n, X, \\{l_i\\}_{i=1}^n)$ is a strategy profile $x \\in X^n$ satisfy-ing,\n$l_i(x_i, x_{-i}) \\leq l_i(y, x_{-i}), \\forall y \\in X, i \\in [n].$\nA mixed strategy Nash equilibrium is a pure strategy Nash equilibrium of the mixed extension $G' = (n, \\Delta X, \\{l_i\\}_{i=1}^n)$ where the set of actions for each player is a distribution (called a mixed strategy) over the original action set X, that is, a mixed strategy profile $s_{1:n}$ with $s_i \\in \\Delta X$ satisfying,\n$\\mathbb{E} [l_i(s_i, s_{-i})] \\leq \\mathbb{E}[l_i(s', s_{-i})], \\forall s' \\in \\Delta X, i \\in [n].$\nIn general, for finite games, for example, when X is finite, there exists at least one mixed strategy Nash equilibrium, but computing the Nash equilibrium is PPAD-complete (Poly-nomial Parity Arguments on Directed graphs). When X is not finite, which is usually the case for our BIG problem, a mixed strategy Nash equilibrium is not guaranteed to exist.\nPotential games are games with a special structure and allow strong results on pure Nash equilibria. We will show BIG is a potential game. The difficulty is in finding the potential function. The following theorem provides a constructive proof.\nTheorem 1 (Potential Game). The Battling Influencers Game G is a potential game with the potential function\n$\\phi(x) = \\phi(x_1,...,x_n) := (\\sum_{i=0}^n W_ix_i)^2 - 2 \\sum_{i=1}^n W_i^T t_i x_i$"}, {"title": "5. Extensions of BIG", "content": "5.1. An Alternative Player Loss Function\nUp to now influencer i's loss function (2) is based on the Euclidean distance between its target point $t_i \\in X$ and the receiver $\\bar{x}$. In some applications, the following negative inner product loss can be more appropriate:\n$l_i(\\bar{x}) := -t_i^T\\bar{x}.$\nThat is, influencer i has a small loss if the receiver $\\bar{x}$ has a large projection onto the direction of target direction $t_i$.\nBIG with this negative inner product loss (14) has an even stronger guarantee: the game has a Weakly Dominant Strat-egy Equilibrium.\nDefinition 4 (Weakly Dominant Strategy Equilibrium (wDSE)). An action profile $x = (X_1...X_n) \\in X^n$ is a wDSE if for every player i,\n$l_i(x_i, x_{-i}) \\leq l_i(y, x_{-i}), \\forall y \\in X, x_{-i} \\in X^{n-1}.$\nRemark 1. The term weakly dominant strategy equilibrium is used in Chapter 4.5 of (Tadelis, 2013), and it is also called dominant strategy equilibrium in Chapter 10.3 of (Os-borne, 1994), and dominant strategy solution in Chapter 1.3.1 of (Roughgarden, 2010). As noted in (Osborne, 1994), an action in a wDSE is not required to weakly dominate all other actions for a player since the player could have mul-tiple actions that are equivalent, all of which dominate the remaining actions. wDSE is also a weaker solution concept compared to (strictly) dominant strategy equilibrium, which requires strict inequality everywhere,\n$l_i(x_i, x_{-i}) < l_i(y, x_{-i}), \\forall y \\in X, x_{-i} \\in X^{n-1}.$\nTheorem 5 (Existence of wDSE). Under loss (14), game G has a wDSE x satisfying,\n$\\bar{x} \\in \\underset{x_i \\in X}{\\operatorname{argmax}} W_i^T t_ix_i, \\forall i \\in [n].$"}, {"title": "5.2. Finite Action Space", "content": "So far, we have assumed that the influencers' action space X is a compact and convex (hence infinite unless singleton) subset of $\\mathbb{R}^d$. In some applications, the influencers are re-stricted to picking their actions from a finite X instead. For example, X may be the collection of news articles published by all professional news agencies within the past 24 hours, and each influencer may select a handful of such news arti-cles to place on a social media user (the receiver)'s timeline. This motivates the extension to finite action space:\nDefinition 5 (BIG with finite action space). Battling Influ-encer Game with finite action space is an n-player general-sum game $F = (n, \\{D(k_i)\\}_{i=1}^n, \\{l_i\\}_{i=1}^n)$, where the ac-tion space of player i, $D(k_i)$ is the set of all subsets con-taining $k_i$ elements (optionally allow repeats) from a fi-nite $X \\subset \\mathbb{R}^d$. The loss function of player i is given by $l_i(\\bar{x}) = ||\\bar{x} - t_i||_2^2$ with\n$\\bar{x} = w_0x_0 + \\sum_{i=1}^n W_i(\\frac{1}{k_i}\\sum_{j=1}^{k_i} x_i^{(j)}),$\nwhere $x_i^{(j)}$ is the jth element in player i's chosen subset. The parameters $x_0$, $\\{W_i\\}_{i=0}^n$, $\\{t_i\\}_{i=1}^n$ and $\\{k_i\\}_{i=0}^n$ are com-mon knowledge to all players.\nIn the original BIG G (Definition 1) where X is convex, allowing the players to choose multiple items would not affect the results since choosing multiple items is equivalent to choosing the mean of these items, which is still in X. In the new game, the average of items in X may not be in X. However, the new game can be interpreted as each influencer picks one \u201cmeta item\u201d $\\bar{x}_i$ instead of $k_i$ items, with\n$W_i' = \\frac{W_i}{k_i}$ $x'_i = \\sum_{j=1}^{k_i} x_i^{(j)}.$\nProposition 6. F is also a potential game, with a potential"}, {"title": "6. Implications of BIG to Value Alignment", "content": "6.1. Heterogeneous Value Alignment as a Game\nWe now show empirically that a stylized version of value alignment can be modeled by BIG. We are interested in the"}]}