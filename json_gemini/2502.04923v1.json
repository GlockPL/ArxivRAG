{"title": "CACHED MULTI-LORA COMPOSITION FOR MULTI- CONCEPT IMAGE GENERATION", "authors": ["Xiandong Zou", "Mingzhu Shen", "Christos-Savvas Bouganis", "Yiren Zhao"], "abstract": "Low-Rank Adaptation (LoRA) has emerged as a widely adopted technique in text- to-image models, enabling precise rendering of multiple distinct elements, such as characters and styles, in multi-concept image generation. However, current approaches face significant challenges when composing these LoRAs for multi- concept image generation, particularly as the number of LoRAs increases, result- ing in diminished generated image quality. In this paper, we initially investigate the role of LoRAs in the denoising process through the lens of the Fourier fre- quency domain. Based on the hypothesis that applying multiple LoRAs could lead to \"semantic conflicts\", we have conducted empirical experiments and find that certain LoRAs amplify high-frequency features such as edges and textures, whereas others mainly focus on low-frequency elements, including the overall structure and smooth color gradients. Building on these insights, we devise a fre- quency domain based sequencing strategy to determine the optimal order in which LoRAs should be integrated during inference. This strategy offers a methodical and generalizable solution compared to the naive integration commonly found in existing LoRA fusion techniques. To fully leverage our proposed LoRA order sequence determination method in multi-LoRA composition tasks, we introduce a novel, training-free framework, Cached Multi-LoRA (CMLoRA), designed to efficiently integrate multiple LoRAs while maintaining cohesive image genera- tion. With its flexible backbone for multi-LoRA fusion and a non-uniform caching strategy tailored to individual LoRAs, CMLORA has the potential to reduce se- mantic conflicts in LoRA composition and improve computational efficiency. Our experimental evaluations demonstrate that CMLoRA outperforms state-of-the-art training-free LoRA fusion methods by a significant margin \u2013 it achieves an aver- age improvement of 2.19% in CLIPScore, and 11.25% in MLLM win rate com- pared to LoraHub, LoRA Composite, and LoRA Switch.", "sections": [{"title": "1 INTRODUCTION", "content": "In the realm of generative text-to-image models (Ramesh et al., 2021; Saharia et al., 2022; Podell et al., 2023; Esser et al., 2024; Rombach et al., 2022; Ramesh et al., 2022), the integration of Low- Rank Adaptation (LoRA) (Hu et al., 2021) in image generation stands out for its ability to fine-tune image synthesis with precision and minimal computational cost. LoRA stands out in its capability for controllable generation, it enables the creation of specific characters, particular types of clothing, unique styles, or other distinctive visual features, and can be trained and later used to produce varied and precise representations of these elements in the generated images. However, existing image generation methodologies utilizing LoRAs encounter limitations in effectively combining multiple LoRAs, particularly as the quantity of LoRAs to be amalgamated increases, thus hindering the composition of complex images. Given this limitation, a critical question emerges: How can we effectively composite multiple trained LoRAs in a training-free manner, while still retaining their unique individual attributes in image generation?\nAs shown in Figure 2, we find that directly applying pre-trained LoRA modules to compose the image often leads to semantic conflicts. This failure primarily arises because independent LoRAs"}, {"title": "2 \u041c\u0415\u0422\u041dOD", "content": ""}, {"title": "2.1 PRELIMINARY", "content": ""}, {"title": "Text-to-Image Diffusion Models", "content": "Diffusion models (Ho et al., 2020; Song et al., 2020) belong to a class of generative models that gradually introduce noise into an image during the forward diffusion process and learn to reverse this process to synthesize images. When combined with pre-trained text embedding, text-to-image diffusion models (Podell et al., 2023; Esser et al., 2024) are capable of generating high-fidelity images based on text prompts. The diffusion model, denoted as ee, with trainable parameters 0, is optimized to predict the noise added to the noisy latent representation zt, conditioned on the provided text c. Typically, a mean-squared error loss function is utilized as the denoising objective:\n$L = \\mathbb{E}_{z,c,\\epsilon,t} [||\\epsilon - \\epsilon_{\\theta}(z_t, t, c)||^2],$ (1)\nwhere $\u03f5 \u223c N(0, 1)$ is the additive Gaussian noise, $z_t$ is the latent feature at timestep t and $e_\u03b8$ is the denoising U-Net with learnable parameter \u03b8."}, {"title": "Low-Rank Adaptation", "content": "The Low-Rank Adaptation (LoRA) technique freezes the pre-trained model weights and introduces trainable low-rank decomposition matrices into each layer of the neu- ral network architecture, thereby significantly reducing the number of trainable parameters required for downstream tasks (Hu et al., 2021). For a pre-trained weight matrix $W \u2208 R^{m\u00d7n}$ in a diffusion model ee, we constrain its update by representing the latter with a low-rank decomposition, i.e., updating W to W, where W = W + \u2206W = W + BA. $B \u2208 R^{m\u00d7r}$ and $A \u2208 R^{r\u00d7n}$ are matrices of a low-rank factor r, satisfying r < min(n, m)."}, {"title": "2.2 LORA DISPARITY BASED ON FOURIER ANALYSIS", "content": "We hypothesize that the challenges in scaling multiple LoRA modules stem from the \"semantic conflicts\" that arise among them, given that LoRAs are typically trained independently and fuse features with varying amplitudes across different frequency domains during the denoising process. Building on the notable disparities in how different LoRAs fuse high-frequency components during the denoising process, as illustrated in Figure 1, we expand our investigation to delineate the spe- cific contributions of various LoRAs within this process and to explore the internal characteristics of LoRAs based on their profiled categories. We aim to establish a Fourier-based method to classify LoRAs according to their frequency responses and group them into distinct sets, as shown in Fig- ure 2. Using our profiling approach, LoRAs are categorized into high-frequency and low-frequency sets. During inference, high-frequency LoRAs are primarily utilized in the early stages of denoising to enhance detail and texture, while low-frequency LoRAs are predominantly applied in the later stages to refine overall structure and coherence.\nTo evaluate the salient characteristics of the contribution of high-frequency components modifica- tion from different LoRAs in the denoising process, we conduct a controlled experiment based on the testbed ComposLoRA (Zhong et al., 2024), comprising of 5 different LoRA categories: Charac- ter, Clothing, Style, Background and Object. We first use the diffusion model combined with each LORA in different profiled LoRA categories to generate a batch of images. Then we use the 2D Fast Fourier Transform (FFT) to transform images from the spatial domain to the frequency domain and"}, {"title": "2.3 CACHED MULTI-LORA", "content": "In this paper, we investigate multi-LoRA composition within the context of diffusion models, align- ing with prior studies on LoRA merging (Gu et al., 2024; Zhong et al., 2024). Building on the training-free LoRA integration methods introduced by Zhong et al. (2024), we focus on two well- established frameworks: LoRA Switch and LoRA Composite, as outlined in Appendix A.3. Based on our evaluations detailed in Section 3.2, while LoRA Composite injects all activated LoRAs at each timestep during the denoising process, LoRA Switch \u2013 activating only one LoRA per timestep \u2013 performs better in the multi-LoRA composition task.\nSince LORA Switch outperforms LoRA Composite based on the evaluation in Section 3.2, we hy- pothesize that LoRA Switch mitigates the \u201csemantic conflicts\" in multi-LoRA fusion by limiting activation to a single LoRA per timestep. However, by applying the frequency profiling approach described in Section 2.2 to classify LoRAs into high-frequency (H) and low-frequency (L) sets, we conjecture that LoRA Composite can potentially surpass LoRA Switch, since the effective LoRA partitioning strategy could allow LoRA Composite to integrate multiple LoRAs efficiently while minimizing semantic conflicts. Thus, we introduce a flexible multi-LoRA framework based on LORA Composite, termed Cached Multi-LoRA."}, {"title": "2.3.1 LORA COMPOSITE", "content": "CMLORA is grounded in the LoRA partition approach illustrated in Section 2.2, focusing on the systematic investigation of optimal dominant LoRA fusion sequences to enhance multi-LoRA in- tegration. Our framework involves calculating both unconditional and conditional score estimates for each LoRA individually at every denoising step. With a set of N LoRAs in place, let \u03b8\u2081 denote the parameters of the diffusion model es after incorporating the i-th LoRA. The collective guidance $\u00ea(z_t, c)$ based on textual condition c is derived by aggregating the scores from each LoRA:\n$\u00ea(z_t, c) = \\frac{1}{N} \\sum_{i=1}^{N} w_i [(1 \u2013 s) \\cdot e_{\\theta_i} (z_t) + s \\cdot e_{\\theta_i} (z_t, c)],$ (5)\nwhere w\u2081 is a real scalar weight allocated to each LoRA and $\u2211_i w_i < \u221e$, intended to adjust the influence of the i-th LoRA. By aggregating these scores, the technique ensures balanced guidance"}, {"title": "2.3.2 THE CACHING MECHANISM", "content": "To amplify the contribution of the determined dominant LoRA and ensure more stable frequency fusion in multi-LoRA composition, we further introduce caching strategies for non-dominant LoRAs during the denoising process."}, {"title": "Cache Interval Determination", "content": "As shown in Figure 6, the percentage of steps with a similarity greater than 0.9 between cached latent feature maps and the current step follows a distinct trend across all LoRAs in LoRA Composite framework. To capture the similarity trend of feature maps fused by LoRAs, we propose a non-uniform caching interval strategy with two specialized hyper-parameters: C1, C2 \u2208 Z. These hyper-parameters control the strength of the caching behavior during inference. Specifically, for a denoising process with T timesteps, the sequence of timesteps that performs full inference is:\n$I = I_1 \u222a I_2 \u222a I_3$\n$I_1 = {c_1 \\cdot t | 0 \u2264 c_1 \\cdot t < \u230a0.4 \\cdot T\u230b, where t \u2208 Z}$\n$I_2 = {\u230a0.4 \\cdot T\u230b + c_2 \\cdot t | \u230a0.4 \\cdot T\u230b < c_2 \\cdot t < \u230a0.9 \\cdot T\u230b, where t \u2208 Z}$\n$I_3 = {\u230a0.9 \\cdot T\u230b + c_1 \\cdot t | \u230a0.9 \\cdot T\u230b < c_1 \\cdot t < T, where t \u2208 Z}.$\n(8)\nThe interval [\u230a0.4\u00b7T\u230b, \u230a0.9\u00b7T\u230b] are established based on the condition that the similarity of the cached features exceeds 20% with a 90% confidence interval, as demonstrated in Caching Inter- val and Modulation Hyper-parameters in Appendix F. This strategic approach aims to further mitigate the issue of semantic conflict in multi-LoRA composition. Notably, it offers two key ad- vantages. First, it amplifies the features contributed by the dominant LoRA feature map, while minimizing changes in features fused from non-dominant LoRAS, allowing the dominant LoRA to play a more critical role during the denoising process. Second, it mitigates the negative effects of frequency conflicts in the Fourier domain, thereby achieving a more balanced trade-off between multi-concept fusion and texture preservation for the activated LoRAs during the inference. The effectiveness of our proposed caching strategy is discussed in Section 3.2.2.\nIn summary, by leveraging a Fourier-based approach to partition LoRAs based on their frequency characteristics, we can determine the optimal order of dominant LoRA application during the de- noising process. Building on this partitioning strategy, we introduce CMLORA, a novel LoRA com- position framework that employs a flexible multi-LoRA injection backbone: denoising the noisy image with the predominant contributions of dominant LoRAs, while incorporating supplementary contributions from cached non-dominant LORAS."}, {"title": "3 EXPERIMENTS", "content": ""}, {"title": "3.1 EXPERIMENTAL SETUP", "content": "Models and Evaluation Setup We begin by examining the prompt-only generative method with- out incorporating concept LoRAs (Rombach et al., 2022), denoted as the naive model. In addi- tion, we utilize training-free multi-LoRA composition methods with the same text prompt used in the naive model, including LoRA Switch (Zhong et al., 2024), LoRA Composite (Zhong et al., 2024), and LoRA Merge (HuggingFace, 2023). Alongside these methods, we incorporate the Lo- raHub (Huang et al., 2023) framework, which fluidly combines multiple LoRA modules with few- shot learning, as our baseline. For each baseline method, we apply our proposed caching method, denoting the results as LoRA Switch (CacheD), LoRA Composite (CacheD), and LoRA Merge (CacheD), respectively. We also consider a uniform cache interval strategy governed by a hyper-parameter c. For all T denoising steps, the sequence of timesteps that performs full inference is defined as:\n$I = {c \\cdot t|0 \u2264 c \\cdot t \u2264 T, where t \u2208 Z}.$\n(9)\nThis extension allows us to integrate multi-LoRA composition methods with varying uniform caching strategies for evaluation, as analyzed in Appendix F.2. Additionally, we integrate our pro- posed LoRA partitioning strategy to LoRA Switch also as a baseline, referred as Switch-A. The analysis of computational cost is detailed in Appendix B.2.\nBased on the testbed ComposLoRA (Zhong et al., 2024), we curate two unique subsets of LoRAs representing realistic and anime styles. Each subset comprises a variety of elements: 3 characters, 2 types of clothing, 2 styles, 2 backgrounds, and 2 objects, culminating in a total of 22 LoRAs. We discuss the challenges in constructing a well-defined multi-LoRA composition testbed in Ap- pendix D.\nEvaluation Metrics We employ CLIPScore (Hessel et al., 2022) and ImageReward (Xu et al., 2023) to evaluate the comprehensive image generation capabilities of all multi-LoRA composition"}, {"title": "4 RELATED WORK", "content": ""}, {"title": "4.1 MULTI-CONCEPT TEXT-TO-IMAGE GENERATION", "content": "Multi-concept composable image generation plays a crucial role in digital content customization, allowing for the creation of images that align with predefined specifications. Existing research in this domain primarily focuses on the following approaches: adjusting the generative processes of diffusion models to better align with specified requirements (Jiang et al., 2024; Kumari et al., 2023; Xiao et al., 2024; Lin et al., 2024), or integrating a series of independent modules that impose desired constraints (Kwon et al., 2024; Gu et al., 2024; Zhong et al., 2024).\nWhile traditional methods excel at producing images based on general concepts, they often struggle with the precise integration of user-defined objects (Kumari et al., 2023; Gafni et al., 2022). Other approaches can compose specific objects into images but often require extensive fine-tuning and struggle with multiple objects simultaneously (Huang et al., 2023; Shah et al., 2023). To address these limitations, we propose a training-free, instance-level LoRA composition framework, which enables the accurate assembly of user-specified elements in image generation."}, {"title": "4.2 MULTI-LORA INTEGRATION MANIPULATIONS", "content": "Recent research has focused on leveraging large language models (LLMs) or diffusion models as base models, aiming to manipulate LoRA weights for various objectives. These include element composition in image generation (Yang et al., 2024; Shah et al., 2023), reducing the parameters needed for multi-modal inference (Chen et al., 2024; Chavan et al., 2023), and adapting models for domain-specific applications (Zhang et al., 2023; Kong et al., 2024; Li et al., 2024). In the realm of LoRA composition techniques, approaches like LoraHub (Huang et al., 2023) utilize few- shot demonstrations to learn coefficient matrices for merging LoRAs, allowing for the fusion of multiple LoRAs into a single new LoRA. LORA Merge (HuggingFace, 2023) employs addition and negation operators to merge LoRA weights through arithmetic operations. Different from weight- based composition methods, LoRA Switch and LoRA Composite (Zhong et al., 2024) maintain all LORA weights intact and manipulate the interactions between LoRAs during inference.\nNevertheless, these methods often lead to instability in the merging process as the number of LoRAs increases, leading to semantic conflicts and visual artifacts of generated images. Additionally, they do not adequately utilize the interactive dynamics between the LoRA models and the base model. To address these challenges, our study proposes a novel perspective: analyzing the contributions of different LoRAs in the Fourier domain and developing a novel LoRA-composition framework to mitigate the semantic conflicts arising from multi-LoRA composition."}, {"title": "5 CONCLUSION", "content": "In this study, we investigate the contributions of various LoRAs to multi-LoRA composition in the Fourier domain. To understand the origins of semantic conflicts in multi-LoRA image generation, we perform a frequency-based analysis of their latent feature maps, revealing significant dispari- ties in frequency contributions among different LoRAs. This finding leads us to propose a versatile Fourier-based profiling method to sequence the fusion of dominant LoRAs during inference, which can be seamlessly integrated into various multi-LoRA frameworks. Finally, we introduce a power- ful training-free framework called Cached Multi-LoRA, which denoises images by prioritizing the contributions of dominant LoRAs while incorporating supplementary information from cached non- dominant LoRAs. To validate our approach, we evaluate CMLORA on the ComposLoRA testbed and introduce a scalable, automated evaluation framework based on MiniCPM-V, designed to avoid out-of-distribution issues."}, {"title": "A LORA-BASED MANIPULATIONS", "content": ""}, {"title": "A.1 LORA MERGE THROUGH A WEIGHT FUSION PERSPECTIVE", "content": ""}, {"title": "Component-wise Composition of LoRA", "content": "LORA Merge is usually realized by linearly combin- ing multiple LoRAs to synthesize a unified LoRA, subsequently plugged into the diffusion model. Formally, when introducing N distinct LoRAs, the consequent updated matrix \u0174 in e\u0473 is given by:\n$W = W + \\sum_{i=1}^{N} w_i\\triangle W_i = W + \\sum_{i=1}^{N}W_iB_i A_i,$\n(10)\nwhere $\u2211_i w_i = 1$ (HuggingFace, 2023). This manner prevents any adverse impact on the em- bedding of the original model, but it leads to the loss of individual LoRA characteristics, as the composition weight wi for each trained LoRA is reduced."}, {"title": "Element-wise Composition of LoRA", "content": "This process integrates the corresponding parameters of the LORA modules, requiring the modules being combined to have the same rank r to properly align the structures (Huang et al., 2023). Given that \u2206Wi = BiAi, the combined LoRA module W can be obtained by:\n$W = (w_1B_1 + w_2B_2 + \u00b7\u00b7\u00b7 + w_NB_N)(w_1A_1 + w_2A_2 + \u2026 + w_NA_N),$\n(11)\nwhere the set of optimal weights {w1,w2,\u2026\u2026, wN} are trained through a black-box optimization."}, {"title": "A.2 LORA MERGE THROUGH A GRADIENT FUSION PERSPECTIVE", "content": "Compared to weight fusion, gradient fusion aligns the inference behavior of each individual concept, significantly reducing identity loss (Gu et al., 2024). The gradient fusion method first decodes the individual concepts using their respective LoRA weights. It then extracts the input and output features associated with each LoRA layer. These input/output features from different concepts are concatenated, and fused gradients are used to update each layer W using the following objective:\n$W = arg \\min_{W} \\sum_{i=1}^{N} ||(W_0 + \\triangle W_i)X_i \u2013 WX_i||_F^2,$\n(12)\nwhere X\u2081 represents the input activation of the i-th concept and || || denotes the Frobenius norm."}, {"title": "A.3 LORA MERGE THROUGH A DECODING-CENTRIC PERSPECTIVE", "content": ""}, {"title": "LORA Switch", "content": "With a set of N LoRAs, the methodology initiates with a prearranged sequence of permutations. Starting from the first LoRA, the model transitions to the subsequent LoRA every T step (Zhong et al., 2024). The active LoRA at each denoising timestep t, ranging from 1 to the total number of steps required, is determined by the following equations:\n$x = [((t \u2212 1)mod(\u039d\u03c4))/\u03c4] +1,$\n$W_i = W + w_i\\triangle W_i = W + w_iB_i A_i,$\n(13)\nwhere i indicates the index of the currently active LoRA, iterating from 1 to N, [.] is the floor func- tion, and the weight matrix Wt is updated to reflect the contribution from the weighted active LoRA wi Wi. By selectively enabling one LoRA at a time, LoRA Switch ensures focused attention to the details pertinent to the current element, thus preserving the integrity and quality of the generated image throughout the process (Zhong et al., 2024)."}, {"title": "LORA Composite", "content": "LoRA Composite method involves calculating both unconditional and condi- tional score estimates for each LoRA individually at every denoising step. By aggregating these scores, the technique ensures balanced guidance throughout the image generation process (Zhong et al., 2024)."}, {"title": "A.4 CMLORA", "content": ""}, {"title": "A.4.1 RELATION TO CLASSIFIER FREE GUIDANCE", "content": "With a set of N LoRAs in place, let \u03b8\u2081 denote the parameters of the diffusion model ee after in- corporating the i-th LoRA. For a generative model es integrated with i-th LoRA, its classifier-free guidance \u0113, (zt, c) based on textual condition c is:\n$(1-s) \\cdot e_{\\theta_i} (z_t) + s \\cdot e_{\\theta_i} (z_t, c).$\n(15)\nThe collective guidance \u00ea(zt, c) based on textual condition e is derived by aggregating the scores from the generative model integrated with each LoRA:\n$\u00ea(Z_t, c) = \\frac{1}{N} \\sum_{i=1}^{N} Wi[(1-s) \\cdot e (zt) + seo (Zt, c)],$\n(16)\nwhere w\u2081 is a real scalar weight allocated to each LoRA and $\u2211_i Wi < \u221e$, intended to adjust the influence of the i-th LORA.\nBy aggregating these scores, the technique ensures harmonized guidance throughout the image gen- eration process, facilitating the cohesive integration of all elements represented by different LoRAs."}, {"title": "B EXPERIMENTAL RESULTS", "content": ""}, {"title": "B.1 IMAGEREWARD AND CLIPSCORE", "content": "To ensure the reliability of our experimental results, we conduct image generation using three ran- dom seeds. All reported results in this paper represent the average evaluation scores across these three runs. The experiments were run with a mix of NVIDIA A100 GPUs with 40GB memory and NVIDIA V100 GPUs with 16GB memory. The total amount of inference time for all multi-LoRA composition methods under all metrics is around 1300 GPU hours."}, {"title": "B.2 COMPUTATIONAL COST ANALYSIS", "content": "Across the investigated caching mechanisms, our proposed caching mechanism Cachep demonstrates the best performance, indicating that multi-LoRA composition methods utilizing Cache D degrade the semantic accuracy and aesthetic quality of the generated images the least. While the computational cost of the cache mechanism Cachep lies between that of uniform caching mecha- nisms Cachec=2 and Cachec=3, multi-LoRA composition methods with CacheD outperform those using other uniform caching mechanisms, as shown in Table 4. Notably, Cachep can achieve, and in some cases surpass, the performance of advanced multi-LoRA composition methods, such as Switch-A and CMLORA, especially as the number of composed LoRAs N increases. Visual demon- strations of these results are provided in Figures 13 to 16. However, we find that there also exists a trade-off between the performance of multi-LoRA composition methods and their computational cost. Although CMLORA achieves superior performance compared to Merge and Switch, it comes with higher computational costs. For instance, at N = 2, CMLORA incurs 912.350 G MACs com- pared to 789.770 G for Merge and 734.053 G for Switch. Similarly, at N = 5, CMLoRA reaches 1570.335 G MACs, significantly higher than 946.721 G for Merge and 731.811 G for Switch."}, {"title": "B.3 MLLM EVALUATION", "content": ""}, {"title": "D LIMITATIONS AND FAILURE CASES", "content": "There are some limitations of our work. First, it is important to note that there is a lack of a detailed image generation class taxonomy. This gap poses challenges in systematically classifying well- defined conceptual groups, particularly due to the semantic overlaps that inherently exist among some conceptual categories. These overlaps blur the boundaries between different conceptual cat- egories, making it difficult to establish a robust and well-defined multi-LoRA composition testbed. However, if different LoRA categories possess distinct frequency characteristics, our proposed CM- LORA approach can still perform effectively. Secondly, as a training-free method, CMLORA oper- ates independently of additional prior knowledge related to region or layout features, such as bound- ing box constraints or masked attention maps. This characteristic simplifies its deployment but also introduces certain limitations in handling spatial relationships effectively. As a result, CMLORA struggles to effectively combine multiple LoRAs within similar semantic categories. This limitation is particularly problematic when multiple concepts within the same conceptual category need to be localized independently. The absence of explicit mechanisms for managing these localizations can lead to potential semantic conflicts, such as concept vanishing or distortion. These issues become especially pronounced when the frequency spectra of overlapping concepts interfere excessively. Finally, we initially employ the traditional image metric, CLIPScore, to evaluate the comprehensive image generation capabilities of all multi-LoRA composition methods. While CLIPScore performs well to evaluate general image-text alignment within its domains, it encounters limitations when applied to scenarios requiring the assessment of out-of-distribution (OOD) concepts, such as user-specific instances. Its evaluations fall short in capturing specific compositional and quality aspects, as it lacks the capability to discern the nuanced features of individual elements (Zhong et al., 2024). This limitation inherently results in a compressed range of evaluation scores for multi-LoRA com- position methods, causing improvements to appear marginal despite significant advancements in comprehensive compositional quality. To address this evaluation gap, we leverage the capabilities of multi-modal large language models (MLLMs) to evaluate composable multi-concept image gen- eration in Section 3.2.2."}, {"title": "D.1 DEMONSTRATION OF FAILURE CASES IN MULTI-LORA COMPOSITION", "content": ""}, {"title": "E EVALUATION METHODOLOGY", "content": "Existing traditional image generation metrics primarily focus on text-image alignment but often overlook the complexity of individual elements within an image and the quality of their composition. Thus, we construct the following evaluation pipeline based on the MLLM."}, {"title": "E.1 EVALUATION PIPELINE", "content": "Image generation: Use both models to generate images based on the same set of prompts (both simple and complex).\nIn-context few-shot learning: Give a few evaluation examples to the evaluator.\nBlind scoring: Let the evaluator rate the images based on the criteria without knowing which model created them.\nScore aggregation: Average the scores for each dimension across all prompts to identify overall performance trends.\nComparative analysis: Compare the total and individual dimension scores between models to draw insights on strengths and weaknesses."}, {"title": "E.2 IMAGE EVALUATION METRICS", "content": ""}, {"title": "1) ELEMENT INTEGRATION", "content": "Score on a scale of 0 to 10, in 0.5 increments, where 10 is the best and 0 is the worst.\nDescription: How seamlessly different elements are combined within the image.\nCriteria:\n\u2022 Visual Cohesion: Assess whether elements appear as part of a unified scene rather than disjointed parts.\n\u2022 Object Overlap and Interaction: Check for natural overlaps and interactions between objects, avoiding unnatural placements or intersections."}, {"title": "2) SPATIAL CONSISTENCY", "content": "Score on a scale of 0 to 10, in 0.5 increments, where 10 is the best and 0 is the worst.\nDescription: Uniformity in style, lighting, and perspective across all elements.\nCriteria:\n\u2022 Stylistic Uniformity: All elements should share a consistent artistic style (e.g., realism, cartoonish).\n\u2022 Lighting and Shadows: Ensure consistent light sources and shadow directions to maintain realism.\n\u2022 Perspective Alignment: Elements should adhere to a common perspective, avoiding mis- matched viewpoints."}, {"title": "3) SEMANTIC ACCURACY", "content": "Score on a scale of 0 to 10, in 0.5 increments, where 10 is the best and 0 is the worst.\nDescription: Correct interpretation and representation of each element as described in the prompt.\nCriteria:\n\u2022 Object Accuracy: Objects should match their descriptions in type, attributes, and context.\n\u2022 Action and Interaction: Actions or interactions between objects should be depicted cor- rectly."}, {"title": "4) AESTHETIC QUALITY", "content": "Score on a scale of 0 to 10, in 0.5 increments, where 10 is the best and 0 is the worst.\nDescription: Overall visual appeal and artistic quality of the generated image.\nCriteria:\n\u2022 Color Harmony: Use of color palettes that are visually pleasing and appropriate for the scene.\n\u2022 Composition Balance: Balanced arrangement of elements to create an engaging composi- tion.\n\u2022 Clarity and Sharpness: Images should be clear, with well-defined elements and no un- wanted blurriness."}, {"title": "F ABLATION ANALYSIS", "content": "To enhance our understanding of the proposed methods, we further conduct the following ablation studies in the field of LoRA fusion sequence and caching strategy of non-dominant LoRA based on our proposed CMLORA."}, {"title": "Dominant LoRA Order Sequence Determination", "content": "Building on our previous discussions, we can identify optimal dominant LoRA candidates during the denoising process, leading us to formulate the following combination optimization problem: How to derive the denoising range (step-length) of the activated dominant LoRA?\nUtilizing the structure of our Cached Multi-LoRA (CMLORA) framework, feature maps generated by different LoRAs can be dynamically fused at each inference step. We define the total denoising range (step-length) for a dominant LoRA i as Di. In our configuration, we assume that each LoRA contributes equally, leading us to allocate the dominant range Di uniformly across all active LoRAS throughout the inference process.\nConsider a scenario with a total of T denoising steps and N LoRAs. We set $D_i = [\\frac{T}{N}]$,\u2200i. We have high-frequency LoRA set H and low-frequency LoRA set L. Inspired by the LoRA switch mechanism, we implement a cyclic pattern of dominant LoRAs among the candidates in set H at the beginning of the denoising process, switching the dominant LoRA every step. To ensure convergence during the denoising process, we designate to use the low-frequency LoRA from the low-frequency LoRA set L at the end of Di steps. By implementing this approach, we effectively harness the pronounced dynamics of high-frequency components while simultaneously benefiting from the stabilizing attributes of low-frequency elements, ultimately leading to visual consistency of multi-LoRA composition."}, {"title": "Dominant LORA Scale Wdom", "content": "For the dominant LoRA, we assign a weight denoted as wdom. For the non-dominant LoRAs, we set their weights as $W_{non} = \\frac{N}{W_{dom}+N-1}$, where N is the total number of composed LoRAs. To regulate wdom during the diffusion process, we employ a decaying method. This decaying strategy not only stabilizes the denoising process but also plays a critical role in reducing semantic conflicts between different LoRAs. By gradually attenuating the influence of the dominant LoRAs as the denoising process progresses, it prevents abrupt changes in texture and edge features that could disrupt with global structures. This ensures smoother transitions between the contributions of various LoRAs, leading to a more harmonious integration of both high- and low- frequency components. As a result, the overall semantic coherence is preserved, minimizing the risk of feature misalignment.\nWe initially set the dominant weight scale wdom to N a, where N is the total number of activated LoRAs and a \u2208 R+. This choice allows us to balance the contribution of the dominant LoRA against the collective contribution of the non-dominant LoRAs. To optimize this balance, we conduct a grid search over a in set {0.1,0.2,..., 0.8, 0.9} By adjusting a, we can finetune the influence of the dominant LoRA, ensuring it does not overpower the others. Then we choose the optimal a = 0."}]}