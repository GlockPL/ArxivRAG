{"title": "HR-Agent: A Task-Oriented Dialogue (TOD) LLM Agent Tailored for HR Applications", "authors": ["Weijie Xu", "Jay Desai", "Fanyou Wu", "Josef Valvoda", "Srinivasan H. Sengamedu"], "abstract": "Recent LLM (Large Language Models) advancements benefit many fields such as education and finance, but HR has hundreds of repetitive processes, such as access requests, medical claim filing and time-off submissions, which are unaddressed. We relate these tasks to the LLM agent, which has addressed tasks such as writing assisting and customer support. We present HR-Agent, an efficient, confidential, and HR-specific LLM-based task-oriented dialogue system tailored for automating repetitive HR processes such as medical claims and access requests. Since conversation data is not sent to an LLM during inference, it preserves confidentiality required in HR-related tasks.", "sections": [{"title": "Introduction", "content": "Recent advances in natural language processing (NLP) have been used for many domains such as Law (Sargeant et al., 2024), Finance (Masson and Paroubek, 2024) and Education (Zhao et al., 2021b). However, many HR processes, such as requesting time off, scheduling meetings, submitting tickets for IT issues, or filing medical claims, remain highly inefficient. Automating these processes could save a significant amount of time that would otherwise be spent on repetitive work. This paper investigates how LLM Agent could facilitate such automation. For a LLM Agent to be useful in the HR domain, it must satisfy the following five requirements:\n(1) It must have a fast response time. Employees are less likely to use a chatbot if it cannot complete the task quickly (Hoxmeier and DiCesare, 2000). Research has shown that user satisfaction decreases as response time increases, and a preferable response time should be less than 2 seconds (Shneiderman and Plaisant, 2010).\n(2) The HR Agent must also be extractive. When using a TOD to file a medical claim, users must be able to trust that the system will accurately retrieve the right number.\n(3) Equally important is the versatility of the system \u2013 it must handle the various HR use cases mentioned above.\n(4) Since employee information is highly sensitive, the TOD itself must be confidential.\n(5) Finally, the HR Agent must be HR specific and perform effectively in HR-relevant tasks as suggested by Xu et al. (2024a)\nTo complete the task, these systems rely on Dialogue State Tracking (DST) (Rastogi et al., 2020a), which monitors and predicts user intent and details during conversations."}, {"title": "Related Work", "content": "Schema-Guided Dialogue (SGD) (Rastogi et al., 2020b) is a dialogue dataset with evolving ontologies, introducing new test set slots and services, emphasizing DST performance and zero-shot generalization. SGD-X (Lee et al., 2022) expands on SGD, presenting five additional schema styles. MultiWOZ (Budzianowski et al., 2020) features human-human dialogues using a stable ontology. HR-MultiWOZ (Xu et al., 2024a) is aligned with HR related tasks, but it is too small to be used for training. Collecting data for these datasets is labor-intensive and costly.\nSGD-baseline (Rastogi et al., 2020b), SGP-DST (Ruan et al., 2020), and DS-DST (Zhang et al., 2020) encode utterances and slot schemas jointly to predict relative slots. Multi-Task BERT adopts slot carryover mechanisms, encoding only the preceding system utterance and the current utterance. LUNA (Wang et al., 2022) separately encodes dialogue history, slots, and slot values, learning to predict the correct utterance to condition slot value predictions. However, these methods lack HR specificity and versatility. Seq2Seq-DU (Feng et al., 2021) and AG-DST (Tian et al., 2021) derive states differently, while DaP (Lee et al., 2021) offers two versions, with the latter being slower. D3ST (Zhao et al., 2021a) deciphers the entire dialogue state at once. Although these generative methods, especially when using T5 models, achieve better Joint Goal Accuracy (JGA) in schema-guided dialogue, they suffer from slow response times because of extensive input.\nDespite recent research efforts (Li et al., 2023; Hude\u010dek and Du\u0161ek, 2023; Zhang et al., 2023), LLM based TOD's performance metrics like BLEU scores and success rates remain low, even with models like Alpaca-LoRA-7B (Taori et al., 2023) and ChatGPT. LLMs are also non-extractive and suffer from high inference costs and latency issues (Yang et al., 2023), making real-world TOD system deployment challenging. For instance, using the GPT-4 8K context model via OpenAI's API costs $0.03 for every 1K input tokens and $0.06 for every 1K output tokens."}, {"title": "Methods", "content": "We first used an HR task-specific schema from (Xu et al., 2024a). We then use the question and answer from that dataset to be our training set. We care less about out of utterance response. Subsequently, we format the question and the utterance as an entity extraction task and select the most relevant entity from the utterance. In practice, once we have gathered sufficient schema information, we employ a few APIs to use this structured information for tasks such as drafting emails, creating tickets, and answering questions as illustrated in Figure 2. Our designed HR-Agent system can be used for tasks such as requesting leaves, inquiring about benefits, applying for internal jobs, navigating the onboarding process, requesting training, reporting workplace issues, participating in surveys, and engaging with HR initiatives. It simplifies benefit enrollment, goal setting, safety guidelines, and compliance training. It is confidential because the external LLM is not used for any inference. We use synthetic data from Xu et al. (2024a) to complete the experiment."}, {"title": "Baseline Methods", "content": "Falcon (Almazrouei et al., 2023), a Large Language Model (LLM), is designed for task-oriented dialogue systems. It focuses on optimizing efficiency and utility, aiming to provide fast, accurate responses in various conversational scenarios. MPT (Team, 2023) is a transformer trained from scratch on 1T tokens of text and code. It is an open source, available for commercial use, and matches the quality of LLaMA-7B Deberta (He et al., 2021) Deberta enhances the BERT model with a disentangled attention mechanism for more interpretable attention scores and uses relative position encoding to boost performance in extractive task. Roberta ROBERTa (Liu et al., 2019) is a transformer model pretrained on English data using the Masked Language Modeling technique, masking and predicting 15 percent of input words for bidirectional learning. We use both models finetuned on SQuAD2.0 which performs well on extractive QA. FlanT5 we use the same setup as (Lin et al., 2021b) where we use DDP to train, set up validation loss for early stopping and set max epochs equal to 20."}, {"title": "Entity Selection", "content": "For entity selection, we need to select the relevant entities that could be answered by utterance. We choose FlanT5 as our base model because it contains smaller model size and is explored most in Schema Guided Dialogue literature. Since the entity itself is not informative, we choose to generate questions about the entity because datasets that are used to train Flan are mostly contain questions. Next, we assess 5 models using the test set. We give the same example for each template and average the result of 10 templates for a pretrained model, such as MPT and Falcon. FlanT5 is trained 5 times and the evaluation result is averaged. The model is trained and evaluated using p3.8xlarge. We do not use an accelerator or ONNX for inference to get a fair comparison of the response time. We benchmark Precision, Recall, F1 Score and Response Time.\nOur ideal solution should have high recall but should not output too many entities, which could drastically increase the response time of the TOD system. Decoder-based models perform well in F1 Score but are low on recall. The fine-tuned version of FlanT5 achieves the best F1 score while also achieving the second-best recall. Claude V3 achieves the best recall but tends to select most of the entities and is slow in response. Without data cleaning, FlanT5 tends to choose many first choices, which leads to low recall. We choose FlanT5 trained on filtered data as our entity selection model because it is fast and ia confidential. Since the training set is versatile and HR specific, the trained model also inherits these advantages."}, {"title": "Entity Extraction", "content": "Except Falcon and MPT, we also use Deberta and Roberta for the entity extraction benchmark. We also fine-tuned a small FlanT5 model on synthetic dataset(20K). We compare Rouge 1, Rouge L and Response time for each model. Our goal is to select the model that is extractive and has low response time.\nOur ideal solution has a low response time and a high Rougel score. Claude does not achieve a good Rougel score and takes much longer to train. It fails to use words from the utterance. Based on our selected models, we find that extractive models such as Roberta and Deberta perform well in the extraction task, while decoder-only models such as MPT and Falcon perform poorly. Flan T5 performed the best. Flan T5, trained on a filtered synthetic dataset, further improves the Rougel performance by another 5 percent since it is more extractive. The trained model is also very fast compared to larger models and is comparable to Roberta-based models. Thus, we choose trained FlanT5 as our model for entity extraction."}, {"title": "Question Generation", "content": "Infusing more empathy into the responses is paramount, as it fosters a more human-centric and relatable interaction experience. To achieve that, we use the utterance and the next question to ask as input. We provided this input to Claude-V3 and asked Claude-V3 to rewrite a concise response with empathy, as illustrated in Table 11. To evaluate the performance of Claude3-V3 on rephrasing response with empathy, we want to benchmark against the response generated in the HR-Multiwoz dataset. To achieve that, we first identify response that may reflect negative feelings from the user. We use DistillBert based on a case model finetuned on dataset SST-2 as our sentiment classifier. Since finetuned DistillBert is uncalibrated. Only sentences with a score above 0.998 and classified as negative are selected. We have collected 638 responses from HR-Multiwoz. We then manually rewrite those questions to basic question and leverage Claude3-V3 to rewrite it. Basic question means it only contain question itself without any additional information.\nTo evaluate the effectiveness and human preference for the responses generated by our HR-Agent, we conducted a preference study involving human labelers using Amazon SageMaker Ground Truth (GT). We compared responses generated by HR-Agent (denoted as Response A) with those from the HR-MultiWOZ dataset (denoted as Response B).\nLabelers were presented with dialogue scenarios and asked to choose which response they preferred. The user interface used for this evaluation is shown in Figure 4. Each response was evaluated by three labelers, and the cost per label was $0.0012. The results of this study are illustrated in Figure 3."}, {"title": "System Evaluation", "content": "To demonstrate that our designed system performs best in HR related tasks. We use HR-Multiwoz as our evaluation set. We compared our method with TransferQA (Lin et al., 2021a) and SGP-TOD (Zhang et al., 2023). ZST adapts a sequence-to-sequence model (T5) pre-trained on large QA datasets to track dialogue states by formulating slot-filling tasks as QA problems. We replace T5 by Deberta and Roberta, suggested by HR Multiwoz benchmark leaderboard. SGP-TOD uses prompt engineer to guide the dialogue and extract the relevant fields.\nJoint Goal Accuracy (JGA) and Average Goal Accuracy (AGA) are used to evaluate our models and baselines. For JGA, the model outputs are only counted as correct when all the predicted values exactly match the oracle values. AGA is the average accuracy of the active slots in each turn.\nAs you can see in Table 3, our proposed method achieves the best performance in HR-Multiwoz dataset in terms of JGA and AGA compared to the state-of-the-art methods. This means that the HR Agent works well in HR related SGD tasks."}, {"title": "Prompt", "content": "Prompt we used in the experiment for MPT, Falcon and FlanT5 as you can see in Table 8 and Table 9. Prompt for Claude-V3 is \"The answer is very short and always less than 2 words. Put the answer in  XML tags.\" for entity extraction and \"The answer always contains 2 to 5 choices. Put the answer in  XML tags.\" for entity selection. We use max tokens to sample be 10, temperature be 0.2 and stop sequence be"}, {"title": "Other considerations", "content": "An essential part of this process involves robust fact-checking to validate generated answers, enhancing reliability and credibility. For instance, when identifying a medical provider, the system confirms their details in the database before processing a medical claim. Users can also track the schema throughout the process, ensuring accountability and trustworthiness. Our dataset connects with existing databases to retrieve relevant information and only asks when necessary. After collecting data, users confirm the schema and the task, and we connect to relevant APIs to complete the task. Before putting information into the system, it is important to make information accurate. For example, the time off day collected is today is not informative for the system to track the exact day. To resolve these inaccuracies, we call Claude to auto complete the inaccurate information. For example, the Claude can change tomorrow to November 1st and 98121 to Seattle WA. This can help the system capture the accurate information. We then confirm it with the user before calling APIs to use the structure information. The system can hugely reduce user's inputs to get required information."}, {"title": "Conclusion", "content": "In improving the efficiency of corporate employees, we introduce HR-Agent, a rapid, extractive, and confidential dialogue system tailored to HR needs. Our work encompasses several key contributions: identifying challenges in adapting TOD to HR contexts, devising a swift and domain-specific data generation approach, demonstrating the superior performance of smaller, faster-trained modules over larger models, and ultimately delivering HR-Agent as a solution that markedly enhances HR process efficiency."}, {"title": "Ethical Statement", "content": "This system is a prototype and has not been deployed in production.\nThe deployment of AI applications in the HR space necessitates careful consideration of ethical issues related to safety, privacy, and bias. There is a possibility that, in attempting to assist, AI may cause more harm than benefit. In response, in collaboration with user experience researcher, security reviewer and HR professionals, we have suggested the following steps for developers who plan to use the HR Agent in order to minimize the risks of harm.\nInformed Consent from Users: In the pilot phase, informed consent was obtained from employees using the service. They were made aware that they would be interacting with an AI-based chatbot designed to expedite task completion. It was also communicated that some extracted information might be inaccurate, and users had to verify the correctness of this information before utilizing it for subsequent tasks. To facilitate this, HR Agent should present the collected information at the end of each conversation and request employee confirmation of its accuracy. Developers should ask the employees to participate in a survey after using HR Agent to understand the effectiveness and helpfulness of HR Agent. They should make it clear that HR Agent is used to fill the relevant task and not for anything else. They should provide relevant HR Business Partner contact information as headers to employees when they interact with HR Agent. Guardrail:HR agent should pose clarifying questions when unable to extract relevant entities. The conversation should terminate if clarifying questions for the same entity are repeated more than three times. The developers can use sentiment analysis model to monitor the sentiment of employees every four user responses, and the conversation is ended if the negative sentiment score exceeds 0.5. Developers should provide task relevant internal wiki when they end the conversations. For some applications, guardrails are also in place for ranges of money and time that exceed specific thresholds. It's important to note that HR Agent has limited applications at present, and they should update these guardrails accordingly.\nPrivacy: In the system, information provided by the employees should be kept confidential in a record separate from the employee's general personnel file. Employees have the right to use this record or input this record in other systems or give developers rights to use this record for analysis. This policy follows the Americans with Disabilities Act (ADA and the Genetic Information Nondiscrimination Act (GINA). Please note that all the models in the system should be trained on synthetic data. Developers should not use any real employee data to train the model. Developers also have to make sure the data in the system is in compliance with rigorous internal infoSec policies and standards. For example, security testing includes examining application logs to detect any data leakage into logs.\nNegative Examples/Potential Bias: To mitigate potential biases in generative models, developers should employ an extractive approach. None the less, the effectiveness of extractions could vary with the employee's language fluency. This variation could potentially lead to inefficiencies in the Task-Oriented Dialogue (TOD) system for non-native English speakers. Additionally, the system is prone to errors when extracting multiple entities of the same type, such as time and money from one response. Efforts are underway to understand and address these issues.\nDevelopers should do threat modeling, security testing, penetration test assessment of the system."}, {"title": "Limitations and Risks", "content": "Limitations We have not explore other models for training such as Deberta or LLama2. We have not evaluated the model on real data.\nRisks Because of some privacy concerns, we have not discussed the details of the whole architecture. The risk of deploying this architecture is that the performance may drift a bit on real data since test set is synthetic."}, {"title": "Future Work", "content": "Looking ahead, potential advancements include the capability to generate resumes and emails, interface with various APIs, proficiently answer queries, and identify pertinent tickets, further enhancing the utility and efficiency of the system. To enhance the performance and capabilities of the model, it is crucial to amass a substantial dataset for the fine-tuning of a more extensive model, enabling it to execute multiple tasks concurrently. Essential prerequisites for this advancement encompass the ability to handle longer sequences and the provision of clear, upfront instructions for entity extraction and task execution. Furthermore, illustrating the connections to other agents is vital, offering a comprehensive and interconnected approach to task management and execution, thereby bolstering the overall efficiency and effectiveness of the model. We could leverage topic modeling (Xu et al., 2023b,a, 2024b; Guo et al., 2024) to better understand and segment use cases. We could leverage differential private synthetic data generation mechanism (Madl et al., 2023; Xu et al., 2023c) to avoid potential privacy issues. We can also apply it in hiring process (Howison et al., 2024; Fang et al., 2024)."}, {"title": "Synthetic Example", "content": "We first try to generate data that is similar to these datasets where we have the conversation and schema generated by the conversation. We can use two claude agent where one acts as an employee and another acts as a TOD system. We then use the third claude agent to track the schema. To generate the conversation, the approach needs multiple api call per sample which is costly.\nThere are also many other problems. After a few rounds of generation, the result becomes repetitive even with dramatically different prompts. The language model tends to follow the most probable or common paths given their training data and their priors, and they lack the creativity or the incentive to explore alternative. The conversation can also be irrelevant. Thus, the system trained on these data is less likely to be extractive, versatile and HR specific."}, {"title": "Designed Prompt", "content": "Here is our designed prompt where schema, number1 and number2 change every time. We use output1 and output2 to capture answers for two tasks. We use Claude-V3 model. We use max toke sample equal to 4096. We keep temperature equal 1, top k equal 1 and top p equal 0.6 to have good output length, capture multiple samples at a time and have enough diversity."}, {"title": "Output Example", "content": "Here is an example of the output using Claude V3:\nWe have also tried cheaper option such as Jurassic-2 but we fail to make them follow instruction."}, {"title": "Experiment Setup Appendix", "content": "Various tables related to Experiment Setup are shown in this section."}, {"title": "Data Validation", "content": "We use the following string to put into Vicuna and FlanT5 XXL to validate the data: Question: question Text: text Answer: answer Does tha Answer answer the Question based on Text? The answer could be yes or no\" We only select data with answer contains \"yes\" For Claude, we input 50 in a group and ask model to find line number with the answer equal no. We save inference cost this way."}, {"title": "Mechanical Turk", "content": "We give 0.012 dollar per human labeller per task. We do not enable automated data labeling."}, {"title": "HR Use Case", "content": "HR-Agent systems are used to request leaves, inquire about benefits, retrieve payroll details, apply for internal jobs, navigate the onboarding process, schedule performance reviews, request training, report workplace issues, access policies, participate in surveys, and engage with HR initiatives. It simplifies benefit enrollment, goal setting, safety guidelines, and compliance training."}, {"title": "Data Generation Process", "content": "While there are many Schema-Guided Dialogue datasets discussed in the previous section, these datasets are not HR-specific. Therefore, we need to generate synthetic data for creating a TOD system. We employ Claude for generating synthetic data, which is more cost-effective than GPT-4 in terms of API costs and easily integrates with the AWS Ecosystem. In our search for a cost-effective data generation option, we attempted to use Claude to generate both conversations and schemas. However, after trying various prompts, we found that the generated schema does not always contain entities from the conversation (non-extractive), fails to capture correct information, and remains inconsistent. The chatbot's questions can also become redundant. We provide an example and discuss other options and problems in Appendix A. These issues collectively make the synthetic data challenging to use.\nAs mentioned in the previous section, most models have performed two tasks. The first task is to select the relevant entity, and the second task is to identify the correct answer for that entity (Zhang et al., 2020). Therefore, we considered generating data that can be used for both of these cases and using separate models for each case. We transformed the synthetic data into a different format, where we asked the model to provide the following: utterance, some questions from the same domain, relevant questions that could be asked based on the utterance, and the extracted entity for each answer. We follow (Taori et al., 2023; Wang et al., 2023; Gunasekar et al., 2023) to create prompts. We use a batch process by explicitly asking the model to produce multiple samples. We increase the diversity of papers by randomly selecting a domain from the list of the following domains (See Appendix G for all HR use cases), choosing a random number of questions and a random number of answers. Thus, our proposed model can cover all these use cases and are more versatile. We also provide a few examples and randomly select one to put into prompt for each generation. Our example prompt is shared in Table 5, and we present an example of generated data in Table 6. We have also tried other model options but none of them work as illustrated in Appendix C"}]}