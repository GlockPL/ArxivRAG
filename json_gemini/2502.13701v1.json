{"title": "Causes and Strategies in Multiagent Systems", "authors": ["Sylvia S. Kerkhove", "Natasha Alechina", "Mehdi Dastani"], "abstract": "Causality plays an important role in daily processes, human reasoning, and artificial intelligence. There has however not been much research on causality in multi-agent strategic settings. In this work, we introduce a systematic way to build a multi-agent system model, represented as a concurrent game structure, for a given structural causal model. In the obtained so-called causal concurrent game structure, transitions correspond to interventions on agent variables of the given causal model. The Halpern and Pearl framework of causality is used to determine the effects of a certain value for an agent variable on other variables. The causal concurrent game structure allows us to analyse and reason about causal effects of agents' strategic decisions. We formally investigate the relation between causal concurrent game structures and the original structural causal models.", "sections": [{"title": "1 INTRODUCTION", "content": "Causality plays an important role in Artificial Intelligence [16, 20]. A specific type of causality, called 'actual causality', concerns causal relations between concrete events (e.g. throwing a specific rock shatters a specific bottle) [16]. There is still discussion on what the best definition of actual causality is (see [13, 15, 16] and [7] for some of those definitions). However, most approaches like [13] and [7] use Pearl's [20] structural model framework. In this structural model framework, the world is modelled through variables, which are divided in exogenous and endogenous variables. The former are variables whose values are determined by causes outside of the model and the latter are variables whose values are determined by the variables inside the model (both exogenous and endogenous variables). The functional dependencies between variables are formalised through structural equations. There also exists a rule-based approach that uses logical language to capture causal relations (see [8] and [19]), but we focus on the structural model framework due to its prominence in the literature [1, 7, 10, 12]."}, {"title": "2 BACKGROUND", "content": "In this section, we introduce the structural causal model framework that we will use. We also shortly introduce concurrent game structures and give a formal definition of agent strategies.\nDefinition 2.1 (Causal Model, Causal Setting [16]). A causal model M is a pair (S, F), where S is a signature and F defines a set of structural equations, relating the values of the variables. A signature S is a tuple (U, V, R), where U is a set of exogenous variables, V is a set of endogenous variables and R associates with every variable $X \\in U \\cup V$ a non empty set R(X) of possible values for X.\nA causal setting is a tuple (M, u), where M is a causal model and u a setting for the exogenous variables in U.\nThe exogenous variables are variables whose values depend on factors outside of the model, their causes are not explained by the model [16, 21]. On the other hand, the endogenous variables are fully determined by the variables in the model. Note that with u, we use the bold-face notation to denote that u is a tuple. When we use this bold-face notation for capital letters X and Y, we are slightly abusing notation by treating them both as tuples and as sets. This follows Halpern's use of the vector notation for both concepts [16]. This means that we can write X = x to indicate that the first element of X gets assigned the value of the first element of x and so on, but that we can also write X' C X.\nExample 2.2. Consider the semi-autonomous vehicle example we discussed in the introduction. We can model this example with exogenous binary variables Uo that determines whether there will be an obstacle on the route, and UAtt that determines whether the human driver is paying attention. For the endogenous variables we introduce the binary variables O, indicating that there is an obstacle, Att, indicating that the human driver is paying attention, HD for whether the human driver keeps driving or brakes. Note that we use HD when the human driver keeps driving (\u00acHD indicates that they brake). ODS, indicating that the obstacle detection system detects an obstacle, DA, for whether the driving assistant keeps driving or brakes. Note that we use DA when the human"}, {"title": null, "content": "driver keeps driving (\u00acDA indicates that they brake). And Col, in-dicating a collision. The set U is hence {UO, UAtt} and the set V is hence {O, Att, HD, ODS, DA, Col}. We consider all variables to be Boolean, so for any variable $X \\in U \\cup V$, R(X) = {0, 1}.\nThe following structural equations are defined for this model:\n$O := U_O$\n$Att := U_{Att}$\n$ODS := O$\n$HD := \\neg O \\vee (O \\wedge \\neg Att)$\n$DA := HD \\wedge ODS$\n$Col := DA \\wedge HD \\wedge O$\nA causal network is a directed graph with nodes corresponding to the causal variables in V (and U) with an edge from the node labelled X to the node labelled Y if and only if the structural equation for Y depends on X. In other words, we put an edge from node X to node Y if and only if X can influence the value of Y [17]. We call Y a descendant of X if the graph contains a path from X to Y.\nA model that has an acyclic causal network is called strongly re-cursive [16]. In such models, a setting u of the exogenous variables U fully determines the values of all other (endogenous) variables. We call a causal model with an acyclic causal network recursive be-cause the exogenous variables determine the values of the endoge-nous variables in a recursive manner. As Halpern explains, some endogenous variables only depend on exogenous variables, we call them first-level variables [16]. They get their value directly from the causal setting. After that there are the second-level variables, the endogenous variables that depend on both the first-level vari-ables and possibly on the exogenous variables. Likewise the third-level variables depend on the second-level variables, and possibly on the exogenous and the first-level variables, and so on for higher levels. We only focus on strongly recursive models in this paper.\nExample 2.3. The causal network for the causal model as de-scribed in Example 2.2 is given in Figure 1 (the exogenous vari-ables are not drawn). The graph makes it easy to see that the causal model is recursive, i.e. the causal network does not contain cycles. We can also see the variable levels. O and Att are first-level variables, they only depend on the exogenous variables. HD and ODS only depend on O and Att and hence are second-level variables. DA is a third-level variable, as it depends on second-level variables, and Col is a fourth-level variable, as it depends on both DA and lower-level variables.\nGiven a signature S = (U,V, R), a formula of the form X = x, for $X \\in V$ and $x \\in R(X)$ is called a primitive event [16, 17]. These primitive events can be combined with the Boolean connec-tives \u2227, \u2228 and \u00ac, to form a Boolean combinations of primitive events"}, {"title": null, "content": "[16, 17]. We follow Halpern and use (M, u) |= $\u03c6$ to denote that for-mula $\u03c6$ holds given the values of all variables determined by the causal setting (M, u) (see [16] for details). A causal formula has the form $[Y_1 \\leftarrow y_1,..., Y_k \\leftarrow y_k]\u03c6$, where $\u03c6$ is a Boolean combi-nation of primitive events, $Y_1, ..., Y_k \\in V$ with $Y_i = Y_j$ if and only if i = j, and $y_i \\in R(Y_i)$ for all $1 \\le i \\le k$. Such a formula can be shortened to $[Y \\leftarrow y]\u03c6$, and when k = 0 it is written as just $\u03c6$ [17]. (M, u) |= $[Y \\leftarrow y] (X = x)$ says that after an intervention that sets all variables of Y to y, it must be the case that X = x holds in the causal setting (M, u) (see [16, 17] for more details). We call y a set-ting for the variables in Y. We now have the necessary background to give the modified HP definition of causality:\nDefinition 2.4 (modified HP Definition [16]). X = x is an actual cause of $\u03c6$ in the causal setting (M, u) if the following 3 conditions hold:\nAC1. (M, u) |= X = x and (M, u) |= \u03c6;\nAC2. There is a set W of variables in V and a setting x' of vari-ables in X s.t. if (M, u) |= W = w*, then (M, u) |= $[X \\leftarrow$ x', W \u2190 w*]\u00ac\u03c6.\nAC3. X is minimal; there is no strict subset X' of X s.t. X' = x' satisfies AC1 and AC2, where x' is the restriction of x to the variables in X'.\nIf W = \u2205, we call X = x a but-for cause of \u03c6.\nExample 2.5. Consider our semi-autonomous vehicle example again. Take the causal setting where u = (1, 0), i.e. Uo = 1, there is an obstacle on the route, and UAtt = 0, the human driver is not paying attention. Following the equations provided in Example 2.2, we have that (M, u) |= O \u2227 \u00acAtt \u2227 HD \u2227 ODS \u2227 \u00acDA \u2227 \u00acCol. We want to know which agent was the cause of there being no col-lision. It turns out that both ODS and \u00acDA are but-for causes of Col, i.e., (M, u) |= [ODS \u2190 0]Col and (M, u) |= [DA \u2190 1]Col. After all, if we intervene by turning off the object detection system ODS (setting its value to 0 in our model, i.e., replacing equation ODS := 1 in our model with ODS = 0, which is formally repre-sented as [ODS \u2190 0]), the driving assistant DA will no longer get a signal that there is an obstacle on the route. This gives DA = 1, meaning that the driving assistant will not brake. Because the hu-man driver is distracted in this setting, they will also not brake, and so there will be a collision. Similarly we can also directly inter-vene on the driving assistant by turning it off (setting its value to 1, not braking, in our model by replacing the equation for DA with DA := 1, represented by [DA \u2190 1]) and there will be a collision as well.\nThe aim of this work is to connect this concept of structural causal models and causality to concurrent game structures. We use the following definition of concurrent game structures:"}, {"title": "Definition 2.6 (Concurrent Game Structures [2]). A concurrent game structure (CGS) is a tuple GS = (N, Q, d, \u03b4, \u03a0, \u03c0) with the following components:", "content": "* A natural number N \u2265 1 of agents. We identify the agents with the numbers 1, ..., N.\n* A finite set Q of states.\n* For each agent a \u2208 {1, ..., N} and each state q \u2208 Q, a natural number $d_a(q) \\ge 1$ of moves available at state q to agent a. We identify the moves of agent a at state q with the numbers 1, ..., da(q). For each state q \u2208 Q, a move vector at q is a tuple <$j_1, ..., j_N$> such that $1 \\le j_a \\le d_a(q)$ for each agent a. Given a state q \u2208 Q, we write D(q) for the set {$1, ..., d_1 (q)$} \u00d7... \u00d7 {$1, ..., d_n (q)$} of move vectors. The function D is called move function.\n* For each state q\u2208 Q and each move vector ($j_1, ..., j_N$)\u2208 D(q), a state \u03b4(q, $j_1, ..., j_N$) \u2208 Q that results from state q if every agent a \u2208 {1, ..., N} chooses move ja. The function \u03b4 is called transition function.\n* A finite set \u03a0 of propositions.\n* For each state q \u2208 Q, a set \u03c0(q) \u2286 \u03a0 of propositions true at q. The function \u03c0 is the labelling function.\nWhen we have a CGS, we can reason about what the optimal actions for a coalition of agents would be in a certain situation. We often use the concept of strategies for this.\nDefinition 2.7 (Strategy in Concurrent Game Structures [2]). Given a concurrent game structure S = (N, Q, d, \u03b4, \u03a0, \u03c0), a strategy for agent a \u2208 {1, ..., N} is a function fa, that maps any (non-empty) finite sequence \u03bb of states in Q to an action the agent can take at the last state of the sequence. I.e. if q is the last state of \u03bb, then $f_a(\u03bb) \\le d_a(q)$. We write $F_A = {f_a | a \\in A}$ for a set of strategies of the agents in A \u2286 {1, ..., N}.\nWe now have all preliminaries ready to move on and combine causality with concurrent game structures."}, {"title": "3 FROM CAUSAL MODEL TO CGS", "content": "The goal of this paper is to define a systematic approach to gen-erate a causal CGS based on a strongly recursive structural causal model. The motivation is that we want to compare the strategic ability of coalitions of agents to realise outcomes to causes in the causal model. Similar translations have been attempted by [3, 12] and [18].\nGladyshev et al. make, like us, a distinction between agent and environment variables, and they also construct a CGS that takes the causal structure between agents' decision and environment variables into account [12]. However, they take a 'zoomed out' ap-proach to the causal model by considering every state in the CGS as a causal model. In contrast, in this paper, we are interested in the specific variable values, which we will consider as specific actions in strategic setting. Another difference with our work is that they do not look at the relationship between causality in the original causal model and strategies in the CGS.\nA more similar approach to ours was defined by Baier et al. [3], but they use extensive form games rather than CGS, and do not dis-tinguish between agent and environment variables. Furthermore, while they do show a result relating actual causality in the causal model to some type of strategy in their extensive form game, they only do this for but-for causes, where we consider the modified HP definition as well.\nHammond et al. translate the causal model to a multi-agent in-fluence diagram (MAID) that includes utility variables, with the primary goal of studying rational outcomes of the grand coalition [18]. They hence take a game-theoretic approach, where we take a logic-based approach by focusing on strategic abilities of coalitions"}, {"title": "3.1 Defining a Causal CGS", "content": "In this section we will propose a systematic approach to gener-ate a causal concurrent game structure based on a strongly recur-sive structural causal model. We will use the notion of first-level, second-level and higher-level variables as explained in the previ-ous section to determine in which order the agents of the causal model will get to take actions. For this we define the notion of agent rank:\nDefinition 3.1. An agent ranking function of a causal model M is a function $\u03c1 : V \\rightarrow {0, ..., n}$, where n is the number of distinct variable levels for agent variables in M, such that for all A, B \u2208 Va, \u03c1(\u0391) > \u03c1(\u0392) > 0 if and only if the variable level of A is higher than the variable level of B, and \u03c1(A) = \u03c1(B) if and only if A and B have the same variable level. For all X \u2208 Ve, \u03c1(X) = \u03c1(A) \u2013 1 if \u2203A \u2208 Va such that the variable level of X is lower or equal to the variable level of A, and there is no B\u2208 Va that has a variable level between X and A. If such an A does not exist, i.e. if the variable level of X is higher than the variable level of all A \u2208 Va, then \u03c1(X) = n. The agent rank of a variable A \u2208 Va is \u03c1(A).\nExample 3.2. In the semi-automated vehicle example we say that HD, ODS and DA are the agent variables. We have that n = 2 as HD and ODS are both second-level variables and DA is a third level variable as Example 2.3 discusses. There are hence 2 distinct variable levels for the agent variables. From this, it follows that \u03c1(HD) = \u03c1(ODS) = 1 and \u03c1(DA) = 2, as the variable level of DA is higher than that of HD and ODS and their agent rank needs to be higher than 0 and maximally 2. For the environment variables, we have that \u03c1(O) = \u03c1(Att) = \u03c1(HD) \u2212 1 = 0, because there are no first-level agent variables, so we need a second-level agent vari-able like HD. Finally, we have that \u03c1(Col) = 2, since the variable level of Col is 4 which is higher than all agent variable levels, and hence the agent rank of Col will be the maximum of 2.\nWe will first define several components of the causal CGS sep-arately before putting them all together. From now on, we will as-sume that all causal models are recursive and have variables which can only attain finitely many values. Moreover we assume that a set of agent variables Va \u2286 V is given.\nDefinition 3.3 (States of a causal CGS). Given a causal setting (M, u), let n = $max_{Y \\in V_a} \u03c1(Y)$ be the maximum value of the agent ranks for the agents in Va and let $m_i = \\prod_{Y \\in V_a, \u03c1(Y) \\le i} |R(Y)|$ be the number of possible combinations of action values for agents with an agent rank of no more than i. The set of states of a causal CGS, Q, generated based on (M, u), is given by:\n$Q = {q_{0,0}} \\cup {q_{i,j} | 1 \\le i \\le n \\text{ and } 0 \\le j < m_i}$.\nWe call q0,0 the starting state of the causal CGS. Later, we will see that the evaluation in a state qi,j follows from the actions of agents whose agent variables have agent rank i or less.\nExample 3.4. We will use the causal model for the semi-automated vehicle example to define a causal CGS (see Figure 1). See Example"}, {"title": null, "content": "3.2 for the agent rank of all variables of the causal model. We start with the setting (M, u) with u = (Uo = 1, UAtt = 0). The set of states is then Q = {q0,0, q1,0, q1,1, q1,2, q1,3, q2,0, q2,1, q2,2, q2,3, q2,4, q2,5, q2,6, q2,7}. Note that:\n$\\prod_{Y \\in V_a, \u03c1(Y) \\le 1} |R(Y)| = \\prod_{Y \\in {HD, ODS}} |R(Y)| = |{0,1} \\times {0,1}| = 4$\n and $\\prod_{Y \\in V_a, \u03c1(Y) \\le 2} |R(Y)| = \\prod_{Y \\in {HD, ODS, DA}} |R(Y)| = 8$, so\nfor i = 1, we have j\u2208 {0,..., 3} and for i = 2, we have j\u2208 {0,..., 7}. These are all the states, because the maximum value of the agent rank \u03c1 is 2.\nWe will now define the agent actions in those states.\nDefinition 3.5 (Actions in a causal CGS). Given a causal setting (M, u) and Q the corresponding set of states as defined by Def-inition 3.3. The possible actions for an agent k \u2208 {1, ..., N} in a state qi,j \u2208 Q are $d_k(q_{i,j}) = R(A_k)$, where Ak is the agent variable controlled by agent k, and \u03c1(Ak) = i + 1. Otherwise dk (qi,j) = {0}.\nThe intuition behind this definition is that agent variables that are earlier on a causal path will earlier get to take an action as the agent variables later on a causal path depend on them. The order of agent variables on a causal path can be seen as representing a pro-tocol that determines when each agent has to take its action. We write ak to denote an action of agent k \u2208 N and ai,j = ($a_1, ..., a_N$) to denote an action profile taken in a certain state qi,j, i.e., all ac-tions taken by all agents in state qi,j. It is important to note that for a given index i all states qi,j have the same action profiles that can be taken in them, regardless of the value of j. We denote this set with A\u00a1. Instead of dk for agent k, we will sometimes write dAk for the agent variable Ak corresponding to agent k.\nExample 3.6. We continue with the situation as in Example 3.4. The available actions for each agent in each state are:\n$d_{HD}(q_{0,0}) = d_{ODS}(q_{0,0}) = {0,1}, d_{DA}(q_{0,0}) = 0$,\n$d_{HD}(q_{1,j}) = d_{ODS}(q_{1,j}) = 0$,  $d_{DA}(q_{1,j}) = {0,1}$, Vj\u2208 {0,...,3}, and\n$d_{HD}(q_{2,j}) = d_{ODS}(q_{2,j}) = 0$,    $d_{DA}(q_{2,j}) = 0$, Vj\u2208 {0,..., 7}.\nThese actions must of course lead to transitions to new states.\nDefinition 3.7 (Transitions in a causal CGS). Given a causal set-ting (M, u), Q the corresponding set of states as defined by Def-inition 3.3 and actions as defined by Definition 3.5, the state fol-lowing from the action profile ai,j \u2208 A\u00a1, with i < $max_{X \\in V_a} \u03c1(X)$, is given by the transition function \u03b4, where \u03b4(qi,j, ai,j) = $q_{i+1,j'}$ and $A_i \u00b7 j \\le j' \\le |A_i| \u00b7 (j + 1) \u2013 1$, under the condition that if ai,j \u2260 ai,j', then \u03b4(qi,j, ai,j) \u2260 \u03b4(qi,j, ai,j). If i = $max_{X \\in V_a} \u03c1(X)$, we define \u03b4(qi,j, ai,j) = qi,j. In this case, there is only one possible action profile ai,j consisting of only the 0 action.\nThis definition simply says that every unique action profile in a state leads to a unique new state. This leads to the causal CGS having a tree structure. It is impossible to return to an earlier state and every node can only branch out\nExample 3.8. Continuing with our running example, we will write (1,0,0) for the action profile (HD = 1, ODS = 0, DA = 0). We get that the transitions are:"}, {"title": null, "content": "\u03b4(q0,0, (0,0,0)) = q1,0,  \u03b4(q0,0, (0, 1, 0)) = q1,1,\n\u03b4(q0,0, (1, 0, 0)) = q1,2,  \u03b4(q0,0, (1, 1, 0)) = q1,3,\n\u03b4(q1,0, (0, 0, 0)) = q2,0,  \u03b4(q1,0, (0, 0, 1)) = q2,1,\n\u03b4(q1,1, (0, 0, 0)) = q2,2,  \u03b4(q1,1, (0, 0, 1)) = q2,3,\n\u03b4(q1,2, (0, 0, 0)) = q2,4,  \u03b4(q1,2, (0, 0, 1)) = q2,5,\n\u03b4(q1,3, (0, 0, 0)) = q2,6,  \u03b4(q1,3, (0, 0, 1)) = q2,7,\n\u03b4(q2,j, (0, 0, 0)) = q2,j   \u2200j\u2208 {0,..., 7}.\nNow that we have states, actions and transitions, we just need the evaluations of the states. The evaluation of a state will depend on an initial causal setting and the actions the agents have taken up to this state. The agents fully determine the values of the agent variables, the environment variables follow from these values and the context that was used to define the causal CGS.\nDefinition 3.9 (Evaluation of states in a causal CGS). Given a causal setting, (M, u), the set of all possible propositions for the generated causal CGS is \u03a0 = {X = x | X \u2208 V,x \u2208 R(X)}. The valuation of each state qi,j \u2208 Q, with Q the set of states of the causal CGS according to Definition 3.3, is defined recursively by the labelling function \u03c0, as:\n$\u03c0(q_{0,0}) = {Y = y | (M, u) |= Y = y}$\n$\u03c0(\u03b4(q_{i,j}, a_{i,j})) = {Y = y | (M_{X_{i,j} \\leftarrow x_{i,j},A_{i,j} \\leftarrow a_{i,j}}, u) |= Y = y}$,\nwhere ai,j is an action profile for state qi,j, $A_{i,j} \\leftarrow a_{i,j} := {A_k \\leftarrow a_k | A_k \\in V_a, \u03c1(A_k) = i + 1 \\text{ and } a_k \\in a_{i,j}}$ is an intervention con-structed based on action profile ai,j, and $X_{i,j} \\leftarrow x_{i,j}$ is recursively defined by: $X_{i+1,j'} \\leftarrow X_{i+1,j'} := X_{i,j} \\leftarrow X_{i,j} \\cup A_{i,j}a_{i,j}$, if \u03b4(qi,j, ai,j) = qi+1,j' with $X_{0,0} \\leftarrow x_{0,0} = \\emptyset$.\nDefinition 3.9 says that an agent action leads to an intervention on the causal setting the causal CGS was based upon. We can see Ai,j \u2190 ai,j as the intervention that directly follows from the agent action(s) taken in the state qi,j, Xi,j \u2190 xi,j stores the previous interventions that were made leading up to the state qi,j. We will illustrate this in the following example.\nExample 3.10. We continue with the situation as in Example 3.8. We start with the causal setting where Uo = 1 and UAtt = 0, so \u03c0(q0,0) = {O, \u00acAtt, HD, ODS, \u00acDA, \u00acCol}. To determine \u03c0(q1,0) = \u03c0(\u03b4(q0,0, (0, 0, 0))), we need A0,0 \u2190 a0,0 = {HD \u2190 0, ODS \u2190 0}. This gives us that \u03c0(q1,0) = {Y = y | (MHD\u21900,ODS\u21900, u) |= Y = y} = {O, \u00acAtt, \u00acHD, \u00acODS, \u00acDA, Col}. Similarly we can determine that \u03c0(q1,1) = {O, \u00acAtt, \u00acHD, ODS, \u00acDA, Col}, \u03c0(q1,2) = {O, \u00acAtt, HD, \u00acODS, DA, \u00acCol} and \u03c0(q1,3) = {O, \u00acAtt, HD, ODS, \u00acDA, \u00acCol}. Let us now look at \u03c0(q2,1) = \u03c0(\u03b4(q1,0, (0, 0, 1))). We need X1,0 \u2190 X1,0 = ($X_{0,0}X_{0,0} \\cup A_{0,0} \\leftarrow a_{0,0}$) = \u2205 \u222a {HD \u2190 0, ODS \u2190 0} as we determined above. The new A1,0 a1,0 = {DA \u2190 1} and so \u03c0(q2,1) = {Y = y | (MHD\u21900,ODS\u21900,DA\u21901, u) |= Y = y} = {O, \u00acAtt,\nThe valuations for the other states are determined similarly (and are shown in Figure 2).\nNow that we have these four definitions, we can give the full definition of a causal CGS."}, {"title": "Definition 3.11 (Causal CGS). Given a causal setting, (M, u), a causal concurrent game structure is defined as a tuple GS = (N, Q, d, \u03b4, \u03a0, \u03c0) where N = |Va|, every agent only controls one agent vari-able, Q is a set of states, as defined by Definition 3.3. For every", "content": "agent k \u2208 {1, ..., N}, dk (qi,j) gives the moves available to this agent in state qi, j \u2208 Q, as given by Definition 3.5. The transition function \u03b4 is defined as in Definition 3.7. The set of possible propositions \u03a0 and the valuation function \u03c0 are given by Definition 3.9.\nWe can now add the results of the previous examples together and give a full causal CGS for the semi-automated vehicle example.\nExample 3.12. Using Definition 3.11, we define N = |Va| = |{HD, ODS, DA}| = 3. This gives us a full causal CGS, illustrated in Figure 2."}, {"title": "3.2 Properties of Causal Concurrent Game Structures", "content": "We already mentioned that a causal CGS has a tree structure. In the rest of this paper, we will call states qi,j, with i = $max_{X \\in V_a} \u03c1(\u03a7)$, the leaf-states. We will call actions in states where an agent does not control a variable, i.e. ak = 0, when dk (qi,j) = {0}, with \u03c1(X) \u2260 i+1, no-op actions. It is also useful to define an action path for a state qi, j, that contains all the non no-op actions that led to the state. In other words, the action path contains only the actions that agents took in a state where they could actually choose an action. We will denote this sequence of actions as a[qi,j]. Formally, for $0 \\le k \\le N$, actions $a_k$ are on this set of actions a[qi,j] if and only if \u03c1(Ak) \u2264 i and there exists an action profile $a_{i,j'}$, containing ak, such that $q_{i',j'} \\in [q_{i,j}, i]$ (the history of qi,j) and \u03b4(qi', j', $a_{i',j'}$) \u2208 [qi,j, i]. In other words, an action is on the action path for a state qi, j, if the state qi', j' in which the action is taken lies on the history of qi,j, and the successor of qi',j' can be reached when taking this action.\nOur first result is on the size of the causal CGS.\nPROPOSITION 3.13. Let M = (S,F) be a causal model. The size of the causal CGS generated by M is linear in the size of the extension of F."}, {"title": "PROOF.", "content": "Consider a structural causal model M = (S,F). Ob-serve that F specifies the value of each variable for all possible combinations of values of all other variables. Hence F corresponds to a table of size |V|\u00d7 $\\prod_{X \\in Y} |R(X)|$ (the number of cells), which is actually the extension of F. We now show that the number of states in the causal CGS is $O(\\prod_{Y \\in V_a} |R(Y)|)$.\nBy Definition 3.3 we have that the number of states of the causal CGS, is given by $|Q| = 1 + \\sum_{i=1}^{2} \\prod_{Y \\in V_a, \\rho(Y) \\le i} |R(Y)|$, where $n = max_{Y \\in V_a} \u03c1(Y)$.\nThe number of leaf-states is hence given by $\\prod_{Y \\in V_a} |R(Y)| =:|R(V_a)|$. The number of states for i = n - 1 will be at most half |R(Va), as there will be at least one variable of rank n that is hence not in-cluded in $\\prod_{Y \\in V_a, \u03c1(Y) \\le n-1} |R(Y)|$, and this variable will have at least\ntwo possible values. We can continue this argument until i = 1, which shows us that |Q| is bounded by 1 + 2|R(Va)| + + |R(Va)| + |R(Va)| \u2264 2|R(Va)|. Hence the number of states in the causal CGS is O($\\prod_{Y \\in V_a} |R(Y)|$). Since a causal CGS is a tree and each state has at most one predecessor, the number of transitions (the size of \u03b4) is also O($\\prod_{Y \\in V_a} |R(Y)|$), hence linear in the size of F in the original model."}, {"title": null, "content": "The statement in the following lemma is a direct consequence of the way the valuation of states is determined in a causal CGS. It states that a variable value cannot change in states corresponding to a higher agent rank than the agent rank of the variable itself.\nLEMMA 3.14. Let GS be a causal CGS generated by the causal model M. For any endogenous causal variable X \u2208 V of M, with \u03c1(X) = i, it holds that (X = x) \u2208 \u03c0(qi,j) for some state qi,j of GS, if and only if (X = x) \u2208 \u03c0(qi',j') for all states qi',j' that are descendants of qi, j.\nPROOF. Let (X = x) \u2208 \u03c0(qi,j). Variable values can change in a state due to interventions, but the only new"}]}