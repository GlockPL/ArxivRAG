{"title": "Ten Years of Teaching Empirical Software Engineering in the context of Energy-efficient Software", "authors": ["Ivano Malavolta", "Vincenzo Stoico", "Patricia Lago"], "abstract": "In this chapter we share our experience in running ten editions of the Green Lab course at the Vrije Universiteit Amsterdam, the Netherlands. The course is given in the Software Engineering and Green IT track of the Computer Science Master program of the VU. The course takes place every year over a 2-month period and teaches Computer Science students the fundamentals of Empirical Software Engineering in the context of energy-efficient software. The peculiarity of the course is its research orientation: at the beginning of the course the instructor presents a catalog of scientifically relevant goals, and each team of students signs up for one of them and works together for 2 months on their own experiment for achieving the goal. Each team goes over the classic steps of an empirical study, starting from a precise formulation of the goal and research questions to context definition, selection of experimental subjects and objects, definition of experimental variables, experiment execution, data analysis, and reporting. Over the years, the course became well-known within the Software Engineering community since it led to several scientific studies that have been published at various scientific conferences and journals. Also, students execute their experiments using open-source tools, which are developed and maintained by researchers and other students within the program, thus creating a virtuous community of learners where students exchange ideas, help each other, and learn how to collaboratively contribute to open-source projects in a safe environment.", "sections": [{"title": "1 Introduction", "content": "Developing energy-efficient software is not an option anymore, it is a matter of survival and moral duty. The Track Clean Energy Progress (TCEP)\u00b9 report of 2023 indicates that data centers and data transmission networks contribute, respectively, to the 1-1.5% of the global energy demand [2]. This corresponds to approximately 240-340 TWh for data centers alone, more than double the amount needed to power the Netherlands in 2020 (i.e., 115.88 TWh). Despite evidence that technological improvements helped mitigate their energy demand in the past years, the request for data center resources and network traffic is increasing. Especially with the expansion and large-scale application of AI-based solutions like generative AI (e.g., to create new contents like text, images, and videos) [2, 24], there is growing evidence that the electricity consumption (and likely the carbon footprint) of software will escalate in the next years [64, 63]. With such high stakes, it is fundamental that practitioners follow an evidence- based approach and make informed decisions about the energy efficiency and carbon footprint of their software [39, 46]. In this context, thanks to its roots in insight- and evidence-oriented nature, the importance of Empirical Software Engineering [69] is already prominent among both researchers and practitioners. However, applying empirical methods to assess the energy aspects of software is a difficult endeavour; precisely measuring the energy efficiency of software in a reliable manner requires strong technical skills and it has proven to be very challenging, time-consuming, and technologically fragmented [18, 22]. As such, strong competencies in empirical methods applied to energy-efficient software are in high demand [52]. This chapter is about our experience in running 10 editions of the Green Lab course at the Vrije Universiteit (VU) Amsterdam, the Netherlands. The course is given in the Software Engineering and Green IT (SEG) track of the Computer Science Master program of the VU. The course takes place every year over a 2- month period and teaches Computer Science students the fundamentals of Empirical Software Engineering (ESE) in the context of energy-efficient software. The main peculiarity of the course is its research orientation: at the beginning of the course the instructor presents a catalog of scientifically relevant problems, and each team of students signs up for one of them and works together for 2 months on their empirical study to solve the assigned problem. Each team goes over the classic steps of an empirical study (a la Wohlin et al. [69]), starting from the formulation of the goal and research questions to context definition, selection of experimental subjects and objects, definition of experimental variables, experiment execution, data analysis, and reporting. Over the years, the course became well-known within the international Software Engineering research community since it led to several scientific studies published at various scientific conferences and journals, such as EASE, MOBILESoft, IST journal, ICT4S, etc., even winning best and distinguished paper awards."}, {"title": "2 Educational Context", "content": "As mentioned in Section 1, the Green Lab course is part of the SEG track which provides one of the possible specializations within the 2-year Computer Science Master program at VU Amsterdam. At the time of creating the track [30], the relation between software engineering and energy was barely understood. Green IT, instead, was a term emerging yet resonating among people. Hence, we decided to name the track after this term. However, we used it in its broad definition (so as to include software, too), i.e., \"the study and practice of designing, manufacturing, using, and disposing of computers, servers, and associated subsystems efficiently and effectively with minimal or no impact on the environment\" [41]. The SEG track entails five so-called core courses. Each course counts 6 credits according to the European Credit and Transfer Accumulation System (ECTS), hence counting a total of 30 ECTS. To integrate energy awareness in the track, we have adopted a mix of the distributed approach and the centralized approach identified by Mann et al. [38]. Accordingly, we both revisited pre-existing courses across the whole track (distributed approach) and created a few dedicated specific courses focusing on sustainability whilst also having sustainability issues addressed across the curriculum (blended approach) [38]. The Green Lab belongs to the latter, by teaching competencies that blend empirical software engineering in the specific context of energy-efficient software). Further, we adopted a distributed approach for the other core courses Service Oriented Design, Digital Architecture, and Fundamentals of Adaptive Software (by applying software engineering competencies to practical projects and assignments that include Green IT aspects); and a centralized approach for core course Software Testing (by teaching traditional software engineering competencies that can possibly be used to test software for e.g., detecting energy hotspots [48]). Timewise, the academic year at VU Amsterdam is organized into 2 semesters, each including 3 periods of 2-2-1 month of 8-8-4 weeks, respectively, where the last week is dedicated to exams. From a student perspective, an 8-week period should include two courses that require 50% of the student's time, each, while a 4-week period is dedicated to a single course full-time. For instance, the Green Lab course is taught in an 8-week period, in parallel with another course. Finally, according to the academic level of their learning objectives, courses are categorized as at specialized (400), research-oriented (500), or highly spe- cialized (600) level. For instance, from the academic year 2024/2025 the Green Lab course will be classified as a 500-level course thanks to the consolidation of energy-efficiency software engineering and measurement as fundamental research competencies."}, {"title": "3 Course Design", "content": "This section presents the main educational components of the current edition of the course, including the students' cohort, learning objectives, and teaching team (Section 3.1), course contents and structure (Section 3.2), and assessment method (Section 3.3)."}, {"title": "3.1 Students' cohort, Learning Objectives, and Teaching Team", "content": "In terms of students' cohort, this course has been designed with Computer Science Master students in mind. Given the technical nature of the course, the recommended background knowledge of students attending the course includes: (i) basic statistical analysis techniques (i.e., descriptive statistics) and most common tests and (ii) basic programming/scripting skills. Both requirements are not formally enforced when students enroll in the course, but the lecturer informs students about them in the first lecture of the course, so to set the expectations and to allow students to prepare for the rest of the course. Students are not expected to be knowledgeable of ESE research methods, which are part of the learning objectives of the course. In the last edition of the course (2023/2024 academic year), the course was attended by 91 active students. The course attracts a variety of students coming from several programs and Master tracks. Specifically, within the Computer Science Master program of VU Amsterdam, students' provenance is composed as follows: 43 students of the Software Engineering and Green IT Master track described in Section 2 and 18 students of other tracks within the same Computer Science Master program (14 in the Big Data Engineering track, 2 in the Foundational Computing and Concurrency track, and 2 in the Internet and Web Technology track); a total of 24 students come from international tracks of the Computer Science Master program, of which 20 come from the Software Engineering for the Green Deal (SE4GD) track and 4 come from the Global Software Engineering European Master (GSEEM) track and 1 in the Parallel Computing Systems track); finally, 5 students come from other Master programs, including (i) Parallel Computing Systems at VU Amsterdam, (ii) Computer Systems Security at VU Amsterdam, Human Computing Interaction at Utrecht University, and Computer Science at the University of Zurich. Over the years, students' ages, genders, na- tionalities, scientific backgrounds, and techni- cal skills became more and more heterogeneous. For the sake of students' privacy we do not re- port students' personal demographics.  The heterogeneity of students' technical skills and backgrounds has been taken care when de- signing the course and mitigated in the assess- ment phase of the course by allowing students to work in their projects with the technologies they are more familiar with (see Section 3.3). Upon completion of this course, the learning objectives in Table 1 are achieved. In the table, we report also the levels of learning covered by each learning objective according to the revised version of Bloom's taxonomy of learning [9, 6]. The teaching team is composed of two lecturers and three teaching assistants. The responsibilities of the five members of the teaching team are:"}, {"title": "3.2 Course Contents and Structure", "content": "The course is designed to expose students to the fundamentals of Empirical Software Engineering (learning objective LO1) in the context of energy-efficient software (learning objectives LO2, LO3, LO4, and LO5). As such, the course covers first the basic principles of ESE (e.g., focus on applicability, quantitative vs qualitative research methods); then, given the importance of measurement-based studies in the context of energy-efficient software, it delves into the specifics of the controlled experiment method with software subjects and objects (as opposed to experiments with human subjects [29]). The overall organization of the course is presented in As anticipated in Section 2, the duration of the course is 8 weeks, with lectures and labs being given in the first 7 weeks. In each of the first 7 weeks, there are two 2-hours educational components in which the teaching team gives either a lecture or a lab. The majority of the lectures (depicted in black in Figure 2) are about ESE research methods; those lectures are designed so that (i) their main contents and principles are generic and (ii) the lecturer systematically refers to examples, scientific results, cases, and success stories related to energy-efficient software. This makes the course future-proof for both students and lecturers: (i) students are able to apply the learned ESE research methods also in contexts different from energy- efficient software (e.g., in their final thesis or during their professional career) and (ii) every year, lecturers update only the energy-specific material (e.g., scientific studies, cases) without needing to completely restructure the course. The course includes also a special lecture about how to design and develop green software (L3 \u2013 depicted in blue in Figure 2); this lecture emerged from the students' feedback we received in the previous years of the course, where students were signaling the fact that the course was \"too meta\" on how to measure the energy-efficiency of software, instead of providing concrete advice on how to make software more energy efficient. During lab sessions (depicted in orange in Figure 2), students are assisted for technical operation of the lab equipment as regards measurement and tools (see Sections 4 and 5 for the details). In the labs, students also receive the required training for data analysis and visualization using R and RStudio4. In order to provide students with the wider perspective on ESE methods and/or energy-efficient software, the last educational component of the course is a guest lecture. Throughout the course, students work in teams to perform experiments on energy- efficient software. Students carry out all the phases of a controlled experiment, from experiment design to execution, data analysis, and reporting. Students are provided with examples of experiments coming from state-of-the-art literature, but they will have to choose by themselves the experimental subjects and hypotheses to test. Further details about the project are given in Section 3.3. At the end of every lecture, the lecturer provides a series of (mandatory and optional) readings. The syllabus of the course is defined as follows: Textbook: The book \"Experimentation in Software Engineering\" by Wohlin et al. [69] is the main textbook of the course and the majority of the contents of given lectures follow the same structure of the book. Complementary mandatory readings: the textbook is complemented by (i) chapter 6 and 8 of the book \u201cGuide to advanced Empirical Software Engineering", "Basics of software engineering experimenta- tion\" [28": "about designing and reporting empirical studies. Support material: additional sources are provided to the students as optional material to be used as a manual/documentation in case students need to go deep on specific aspects of their projects. Specifically: Material on ESE research methods: a selection of scientific studies and guide- lines for conducting empirical studies. For example, such studies are about statistical analysis in ESE [20, 42], data analysis in ESE [60], experiment design in ESE [45]. Material on energy efficiency: a selection of studies providing either the big- ger picture about energy-efficient software or methodological guidelines. For example, such studies are about Green IT and green software in general [62], practitioners' perspectives on green software [39, 46], and guidelines for en- ergy measurement and its related issues [7, 47]. Material on statistics and data visualization: a selection of studies and guide- lines about statistics and data visualization in general, e.g., [54] and [53]. Articles on well-conducted experiments (e.g., [51, 32, 14]): a selection of well-designed and reported empirical studies; the lecturer use such studies in class as success stories and as triggers for critical reflection. This part of the syllabus also includes scientific studies emerging from previous editions of the Green Lab (see"}, {"title": "3.3 Assessment", "content": "Teams of 5 students conduct a concrete research project throughout the whole course. Each part of the research project is discussed during the lectures, started during the labs, and completed as homework, so to keep students on track within the course schedule. The goal of the research project is to plan, design, conduct, and report a scientific experiment in the context of the energy efficiency of various types of software (e.g., mobile apps, software libraries, microservices). Each team works on a specific topic in the context of energy-efficient software. In this way, students put into practice the skills and techniques that they have learned during the lectures/labs and develop their practical insights by applying them to real software. In the first lecture of the course, the lecturer provides a list of possible topics, then each team indicates (i) its members, (ii) the technical skills and educational background of each member, and (iii) a set of scores indicating the preferences about each proposed topic. Then, each team is responsible for independently carrying on the experiment on the assigned topic. When possible, the lecturer provides relevant datasets, scripts, and other material to the team in order to smooth the execution of their experiment. Such information is typically provided during the first lecture of the course (contextually to the description of the topics for students' projects), during the first lab, during the in-person discussions with students before or after lectures/labs, or contextually to the grading (i.e., as part of the feedback given to students on their assignments); moreover, in case a new relevant dataset, tool, or scientific study is published, lecturers make an announcement on the web platform of the course about it, so that students can evaluate whether the new material can be used in their project. As shown in Figure 2, each team project is composed of 3 assignments. Each assignment deals with a specific increment of the same research project. The final assignment is a fully-fledged scientific study, including all phases of a classical ESE study reporting on a measurement-based controlled experiment. The sequence of assignments is designed in such a way that their difficulty and required effort grow together with students' deeper understanding of ESE principles, the nuances of their research project, and their experience in terms of energy measurement. We believe that such incremental design of the research project is important to create a safe environment for students to explore and study at the beginning of the course, and then let the project grow together with them during the course. All assignments include a written report describing all the information related to a specific phase of the project. A complete template for Green Lab reports is publicly available on Overleaf7. Written reports contain also a link to a time log, where students record their time; the time log is used only in case of disputes among team members or in case of strong suspicions of fraud. Below we describe the main components of each of the 3 assignments. Assignment 1 \u2013 Context and experiment definition (20% of the final grade). This part is composed of three sub-components: Technical/societal context: students describe (i) the domain (e.g., mobile apps and their market) and the technologies relevant to the experiment, (ii) the main motivation behind the experiment, including examples, apps/tools screenshots, snippets of source code, etc., (iii) a brief overview of the direction of the experiment, and (iii) what the target audience (e.g., software developers) will learn from the results of the experiment. Scientific context: students position their research by elaborating on 5 to 8 related studies that are similar in terms of goal or methodology, with a clear characterization of the novelty of their own experiment with respect to them. Experiment definition: students use the Goal-Question-Metric (GQM) ap- proach [8, 10] to formulate the goal, research questions, and high-level metrics (e.g., power, execution time, energy, CPU usage) of their experiment. Using the GQM approach helps students (and instructors) get a complete and concise overview of the main direction of the experiment. Assignment 2 \u2013 Experiment planning and measurement infrastructure setup (30% of the final grade). This part is composed of two sub-components: Experiment planning: students make a detailed plan about the experiment in terms of (i) subjects' selection/mining, (ii) experimental variables (i.e., dependent and independent variables), (iii) formal definition of experimental hypotheses, (iv) experiment design (i.e., main, co-, fixed, and blocking factors and their organization), (v) data analysis procedure. In this phase, students also provide an estimation of the total duration of the experiment considering the total number of subjects, trials, runs, and estimated execution time for each run; over the years, this proved to be a valuable tool for facilitating students' reasoning on the feasibility of their experiment and take countermeasures, e.g., by reducing the number of subjects or moving from a full-factorial design to an incomplete one. In general, we advise students to design their experiment in such a way that its execution takes less than 40 hours. Measurement infrastructure setup: students present the technical aspects for executing the experiment, which tools they are going to use, which de- vices/servers, and the software/hardware infrastructure they are setting up for the experiment. Assignment 3 \u2013 Experiment execution, data analysis, and reflection (50% of the final grade). This part is composed of five sub-components: Experiment execution: students execute the experiment and collect measures as planned in the second assignment (after having addressed the instructor's feedback). The output of this phase is the raw data collected from the executed experimental runs. Data analysis and results reporting: students check the correctness of the col- lected measures, compute descriptive statistics, perform the statistical analysis for hypotheses testing (with effect size estimation), and synthesize the obtained results in their report providing suitable plots and tables to illustrate the main points of attention. Threats to validity: students reflect and report the threats to the validity of the experiment according to the Cook and Campbell classification [16]. Reflection: students report the main implications and interpretations of the obtained results (possibly grouped by research question). In this phase, since they spent weeks on the technical aspects of the experiment, students tend to have a narrow perspective and focus very much on the low-level, technical aspects of the experiment. So, here students are asked to address directly the target audience of their experiment (i.e., who will benefit from the results of the experiment), as described in the previous assignments; this helps students in getting a wider perspective about their experiment and the general usefulness of their results. Report finalization: students wrap up the project by doing a final complete pass on the report and writing the abstract and conclusion section. Assignment 3 includes also a link to a GitHub repository containing the complete replication package of the experiment. The replication package must contain: (i) source code of the scripts developed for running the experiment, (ii) source code of any software developed for building used dataset, (iii) raw data resulting from the execution of the experiment, (iv) R scripts for data analysis, and (v) any other relevant material for replicating the experiment.  Assignment 3 includes also a link to a video where the team presents the main aspects of the experiment in a complete manner (from the motivation and context, design, execution, to the results, discussion, etc.). Presentations are prepared as groupwork where each student presents individually a part of the experiment. Presentations are assessed as either pass or fail. When grading each assignment, the teaching team provides (i) a quantitative assessment of each part of the assignment according to a shared rubric (available in the supplementary material of this chapter) and, more importantly, (ii) detailed feedback on how to improve the experiment. Intermediate assignments are evaluated and are part of the final assessment of the whole team project (assignment 3). Assignment 3 is a coherent integration of the previous assignments. When working on assignments 2 and 3, student teams are requested to address the feedback provided by the teaching team in the preceding assignment. Over the years, feedback on intermediate assignments proved extremely useful since it allowed the teaching team to (i) ensure the feasibility of the project (in some cases, students tended towards over-promising), (ii) ensure that the difficulty of assigned projects is similar among all projects within the cohort of students, and (iii) steer projects towards scientifically challenging and novel research directions."}, {"title": "4 Equipment and Measurement Infrastructure", "content": "Green Lab empowers researchers and students to explore diverse software-related domains. So far, the Green Lab has been used for experiments on Distributed, Mobile, Robotics, Artificial Intelligence (AI), Virtual Reality (VR) and Embedded software applications. The Green Lab includes a cluster of 7 servers with different specifications. The Green Lab runs Proxmox [23], an open-source server virtualization software, and, therefore, is dedicated to virtualization. Proxmox enables students and researchers to create virtual machines on-demand for testing software systems, executing data analysis, and monitoring other servers. Proxmox supports two virtualization tech- nologies: Kernel-based Virtual Machines and Linux Containers. Moreover, it allows dynamic scaling of resources assigned to each virtual machine, enabling the deploy- ment of different-size workloads at run-time. Proxmox offers a web-based interface for creating, removing, and allocating resources to virtual machines remotely. The cluster also supports containerization. Indeed, container-based applications, such as SockShop [67] and Train Ticket Booking System (TTBS) [21], can be deployed either on a single machine and across the servers. The cluster is configured to offer all the computational resources of the servers, and, thus, supports High-Performance Computing (HPC) applications that need to execute compute-intensive workloads, such as simulation, machine learning models, and data analytics. To do this, we use SLURM [70], an open-source workload manager that handles the distribution and parallelization of computation across the nodes of the cluster. SLURM allows the users to create and distribute computation and monitor the energy consumption and the performance of the jobs and of the nodes within the cluster. Figure 3b describes a typical execution of a job on our cluster. Figure 3b shows the current configuration of our HPC cluster, which includes a head node, i.e., GL4, and four compute nodes, namely GL5, GL6, GL2, and MOX2. The HPC cluster is arranged as a tree, which means that the head node creates and distributes jobs on the compute nodes. A user can set the jobs to be executed, allocate resources to the jobs, retrieve statistics about job execution, and retrieve the output resulting from job execution. These commands are handled by the slurmctld daemon that runs on the head node. This daemon communicates with the slurmd daemons that run on each compute node. Each slurmd daemon is responsible to track job execution and report information to the head node. These statistics include the status of the node, information about job status, as well as job performance, and energy consumption. The head node records the information about job execution in a MySQL database. The interactions between the database and the slurmctld daemon are managed by the slurmdbd daemon that we omitted in Figure 3b for simplicity. The output resulting from jobs execution is stored into a shared folder that is accessible by all the nodes of the cluster. A user can collect the information stored in the database using the sacct command of SLURM and the data contained in the shared folder through SSH. The Green Lab includes about 20 smartphones and 3 tablets for executing experi- ments on mobile applications, including several generations of Google Pixel phones, Samsung J7 phones, etc.. In addition, the Green Lab has 32 Raspberry Pi (of which, 2 Pi 5 Model B, 16 Pi 4 Model B, and 14 Pi 3 Model B) and 8 Arduino Nano to test embedded and IoT software applications. For experiments involving AI models, in addition to using the cluster, the lab has also 3 Jetson Nano development kits. For Robotics Systems, the Green Lab has 5 TurtleBot3 Burger robots (equipped with a camera module and current sensors) and a 4-degree of freedom robot arm (UARM Swift Pro, UFactory). Additional equipment includes wearables, such as Samsung Gear S3, virtual reality visors, i.e., a Google Daydream, and a drone, namely a DJI Tello."}, {"title": "4.1 Measurement Infrastructure", "content": "Green Lab users can track energy consumption and performance of the software running in the lab using both software energy profilers and hardware power meters. The cluster is equipped with two Rittal Power Distribution Unit (PDU) [50] and a Watts Up? Pro [66] that profile the power requested by each node. A Rittal PDU is a power strip that provides reliable power distribution with energy monitoring and measurement for all devices connected to it. A Watts Up? Pro, instead, is a plug power meter that is placed between the device to profile and its power source. Both power meters provide an API to get the measurements. In addition, the Rittal PDU provides a web interface to configure the power strip and monitor the power required by the servers in real time. At the current state, the two Rittal PDU supply and monitor power of all the nodes of the cluster. We use the Watts Up? Pro to profile the power consumption of a node and also of other embedded systems, such as smartphones and Raspberry Pis. The Green Lab provides 3 Watts Up? Pro, including the one connected to the cluster. The Green Lab also features 3 Monsoon Power Monitor [40], which are high-frequency power meters. We mainly use them for experiments involving mobile applications but they can also be used to profile other embedded systems. A Monsoon can be plugged into a device through a USB port, a Main Channel consisting of a positive and a negative terminal, and a BNC connector referred as Auxiliary port in the Monsoon documentation. We use the USB port to profile USB-powered devices and the Main Channel for tracking the battery of our smartphones. The Main Channel can be connected to all devices exposing a positive and negative terminal, such as the pins of a Raspberry Pi. The power consumed by the Raspberry Pis and the Arduino Nano can be monitored also using an INA219 sensor. The INA219 [3] is a current sensor that can be soldered on a board or connected to the board through a breadboard. The Green Lab comprises 5 INA219 at the moment. The above-mentioned physical power meters record the energy consumption of the whole device while running a software application. A handy solution for fine-grained energy consumption measurements are software energy profilers [17]. Software energy profilers avoid direct interaction with the hardware platform and allow more fine-grained measurements on the software. For example, at the process or code block level. Among the most used software profilers, there are powerstat [15], perf [33], and Intel Power Gadget [27]. All the mentioned tools exploit the Running Average Power Limit (RAPL) [26] interface provided by Intel CPUs. At the moment, RAPL is used by most software energy profilers. RAPL estimates the energy consumed by a device according to a power model, which is proven to be accurate on certain architectures, and stores the estimate in a set of registers called model-specific registers (MSRs). SLURM, which we use for the HPC version of Green Lab, also uses RAPL to derive the energy consumed by the jobs executed in the cluster. However, not all nodes in our cluster support RAPL. The older ones, i.e., GL3 and GL4, do not support RAPL. For this reason, GL4 is used only for dispatching jobs and record the measurements in the HPC configuration."}, {"title": "4.2 Guidelines for Proper Use of Equipment", "content": "It is crucial to provide proper instructions to students on how to use the tools and equipment provided for their projects; major misuses of the tools and equipment can affect the completion of their projects or can even lead to physical hardware damage. The definition of the experiment design during Assignment 2, see Section 3.3, is followed by a phase in which the scientific assistants of the S2 Group interact directly with each group to provide them with support material and instruct them on how to use it. The groups are provided by the scientific assistants with credentials to access a limited set of resources, namely CPU cores, RAM, disk, and network bandwidth, on the servers according to the requirements of the experiment, as well as instructions on accessing them, usually through SSH. Scientific assistants provide step-by-step guides for setting up embedded devices like Raspberry Pis, Virtual Reality Headsets, and educational robots, as well as instructions for maintenance. For example, we instruct students to always check and set the voltage provided by the power source (e.g., the Monsoon power meter) to values that are not greater than those supported by the device to be powered (e.g., 5V for the Raspberry Pi). The same applies to the physical power meters, i.e., the Wattsup Power Monitor and the Rittal PDU. In addition, we provide students with material that could be helpful in better understanding the usage of the devices, such as links to the manual of the devices and online user discussions. The Green Lab course includes a lab, mentioned as LAB1 in Section 3.2, that covers the use of software tools to manage experiments, measure performance, and track energy consumption. During the lab, the instructor explains how to set up the tools and provides a live demonstration of how to use them for experimentation. The scientific assistants and the lecturers are available to support the students with technical problems and questions about the usage of measurement tools during the whole course. This is usually accomplished through open discussions on the web platform of the course."}, {"title": "5 Open-Source Tools and Community of Learners", "content": "In the first three editions of the course", "reinvent the wheel\\\" in their scripts in each of their projects. Examples of redundant scripts include tasks such as": "defining the order of execution for experiment trials", "36": ".", "43": ".", "experiments": "i) Robot Runner is dedicated to robotic systems and (ii) Experiment Runner", "57": "follows the same principles as Android Runner", "differences": "i) it communicates with experiment subjects via Robot Operating System (ROS12) messages instead of Android ADB, (ii) the internal diag- nostics checks are specific to ROS-based system, (iii) it is completely independent of the type and number of used subjects (either simulated or real), whereas Android Runner assumes to be interacting with a physical and always-available device, and (iv) the experiment configuration is defined in Python instead of JSON. About the latter point, the rationale for having a Python-based representation of the experiment (instead of JSON) is to allow users to flexibly define the configuration and the busi- ness logic of their experiments in a self-contained manner [57"}]}