{"title": "Predicting Elevated Risk of Hospitalization Following\nEmergency Department Discharges", "authors": ["Dat Hong", "Philip M. Polgreen", "Alberto Maria Segre"], "abstract": "Hospitalizations that follow closely on the heels of\none or more emergency department visits are often symptoms of\nmissed opportunities to form a proper diagnosis. These diagnostic\nerrors imply a failure to recognize the need for hospitalization and\ndeliver appropriate care, and thus also bear important\nconnotations for patient safety. In this paper, we show how data\nmining techniques can be applied to a large existing\nhospitalization data set to learn useful models that predict these\nupcoming hospitalizations with high accuracy. Specifically, we use\nan ensemble of logistics regression, na\u00efve Bayes and association\nrule classifiers to successfully predict hospitalization within 3, 7\nand 14 days of an emergency department discharge. Aside from\nhigh accuracy, one of the advantages of the techniques proposed\nhere is that the resulting classifier is easily inspected and\ninterpreted by humans so that the learned rules can be readily\noperationalized. These rules can then be easily distributed and\napplied directly by physicians in emergency department settings\nto predict the risk of early admission prior to discharging their\nemergency department patients.", "sections": [{"title": "I. INTRODUCTION", "content": "Medical errors are an important source of morbidity and\nmortality [1, 2]. Thus reducing errors is an important patient\nsafety goal and public health priority [1-3]. An increasingly\nrecognized source of medical errors are delayed diagnoses and\nother diagnostic-related errors [4-7]. Delayed diagnoses and\ndiagnostic errors can lead to lead to not only excess healthcare\ncosts, but also negative and even catastrophic outcomes for\npatients [8-10]. Diagnostic delays and other diagnostic-related\nerrors may be especially common in emergency departments\ngiven the high patient loads, fast pace of patient turnover with\nlimited time for observation, the general lack of continuity of\ncare, a lack of detailed information regarding the patient, and\nthe large range of patient acuity. Indeed, analysis of\nmalpractice claims demonstrate the frequency and importance\nof diagnostic delays and errors in emergency departments [11,\n12].\nOne potential marker for quality of care in emergency\ndepartments is unanticipated short-term revisits [13].\nApproximately 7% of patients seen in emergency departments\nreturn in 3 days and 22% within 30 days [14]. While some of\nthose returns may be expected or unavoidable, some of the\nreturns are associated with diagnostic and other errors such as\ninsufficient treatment or care [13]. Thus, excess revisits have\nlong been proposed as a marker of quality for emergency\ndepartment care [15-17]. However, not all revisits are\nunanticipated, nor do the vast majority represent the provision\nof inadequate medical care [18, 19]. Some revisits may be\nscheduled, and some may be due to patient-related factors, such\nas a lack of understanding, anxiety, or progression of disease\n[18, 20]. An estimated 5-20% of revisits are attributable to\nissues related to the possibly less-than-optimal care provided at\nthe index emergency department visit [19]. Not surprisingly,\nhospitalizations following discharge from the emergency room\nare a better marker for tracking quality of care than simply\nnoting return ED visits without hospitalization [21, 22].\nWhile several reports have focused on risk factors\nassociated with returns to the emergency department [23-35],\nfewer have focused on predicting revisits to the emergency\ndepartment or predicting hospitalizations following emergency\ndischarges [36-39]. Among the work that has been done, much\nhas been focused older populations, pediatric populations or\nspecific conditions, limiting their generalizability.\nGiven that hospital admissions following patients'\ndischarges from the emergency department are undesirable, the\ngoal of this paper was to predict patients at high risk for being\nadmitted to the hospital at either 3, 7 or 14 days following a\ndischarge from an emergency department using a large\npopulation-based sample over a large geographic region."}, {"title": "II. METHODS", "content": "A. Diagnostic Errors\nThere are many definitions of missed diagnoses and/or\nmissed opportunities. In this paper we consider diagnoses that\nare \"missed, wrong, or delayed, as detected by some subsequent\ndefinitive test or finding\" [40]. We use a hospital admission\nwithin a fixed time window (3, 7 or 14 days) after an emergency\ndepartment (ED) visit as the \u201csubsequent definitive test\u201d and\nselect patients of interest by looking back in time from these\n\"index\" admissions. The 3, 7 and 14 day windows are\nsuggested by related work on hospital readmissions [41].\nB. Dataset\nThe data used here were extracted from the 2009 Healthcare\nCost and Utilization Project (HCUP) California inpatient\ndatabase (SID) and emergency department database (SEDD).\nThe former contains records of all inpatient discharges from\nshort-term acute care non-federal-government hospitals in\nCalifornia, while the latter contains records of emergency\ndepartment visits that do not lead to immediate hospitalizations.\nEach record includes the principal and secondary diagnoses,\nprocedures performed, demographic information, length of\nstay, admission and discharge status, hospital charges and\npayment sources. California HCUP data patient SID and SEDD\nrecords can be linked across visits using an anonymized patient\nrecord index (visitlink) and simple calendrical calculations\nrelating the implied visit dates (daystoevent), producing a\ncomprehensive view of patient ED visits and hospitalizations\nacross facilities and over time.\nThe 2009 California SEDD dataset contains 9,875,973\ndeidentified ED visits. We remove records that lack patient\nidentifiers (these cannot be linked to the SID data) as well as\nrecords pertaining to pregnant women (a primary CCS code\nbetween 177 (spontaneous abortion) and 196 (other pregnancy\nand delivery including normal) for at least one ED or hospital\nvisit) and children (age < 18), producing a final dataset for\nanalysis consisting of 5,487,722 ED visits. Each ED visit is\nconsidered a diagnostic error if a hospital admission occurs\nwithin 7, 14 or 30 days of an ED visit, excluding hospital\nadmissions for mental illness (an outsize number of\nreadmissions are due to CCS codes associated with mental\nillness, between 650 and 670). The resulting dataset (see Figure\n1) is markedly imbalanced, with only 2% of the records in the\ndataset having a qualifying hospital readmission within a 14-\nday window (and concomitantly smaller percentages for 3 and\n7-day windows).\nC. Feature Selection\nEach dataset record consists of 152 features, including age,\nadmission date, race, length of stay, patient disposition code,\nand so on. 102 of the features correspond to diagnoses,\nprocedure, and injury codes in various coding formats (ICD-9\nand CCS for diagnoses, CPT-4/HCPCS and CCS for\nprocedures, and ICD-9-CM and CCS for injury codes). For this\nstudy, we retain the 21 CCS (Clinical Classification Software)\ncoded diagnosis fields and the 21 CCS-coded procedure fields,\ndropping the (redundant) CPT-4/HCPCS/ICD-9 coded fields\n[42, 43]. The remaining 106 features (56 CCS-coded fields and\n50 other features) are then dummy coded (e.g., the original\nadmission month feature's twelve possible values would be\nrecoded as 12 individual binary variables). Recoding features\nas binary dummy variables is a regression friendly strategy akin\nto binning when the size of the dataset is very large.\nEach record is then augmented with some additional\ntemporal information gleaned from the context of each visit.\nMore specifically, each record receives the following additional\nfeatures:\n\u2022\tNumber of ED visits within last 30 days\n\u2022\tNumber of ED visits to same facility within last 30\ndays\n\u2022\tNumber of hospital visits within last 30 days\n\u2022\tNumber of hospital visits to same facility within last 30\ndays\n\u2022\tNumber of additional ED or hospital visits with same\nprimary CCS code within last 30 days (default 0)\n\u2022\tThe most frequent primary CCS code within the last 30\ndays.\nEach record in the dataset thus contains a total of 3831 binary\nfeatures.\nD. Classification Algorithms\nWe wish to learn to recognize diagnostic errors as defined\nabove based on the features just described. Our approach uses\na weighted combination, or an ensemble, of instances of three\ntypes of learning algorithms: logistic regression, na\u00efve Bayes\nand association rule classification.\nLogistic regression (LR) is a commonly used technique that\nlearns an estimator for the probability of a binary response from\ndata. A LR classifier is a weighted linear combination of terms,\nwhere each term corresponds to an input feature and the weights\nfor each term are fit from training data. Here, LR is provided\naccess to all 3831 dummy coded features for each record in the\nappropriately sized window (3, 7 or 14 day) prior to a candidate\nreadmission and fit to predict the probability of readmission.\nAmong the primary advantages of LR are its simplicity and\ndirect interpretability: simple inspection reveals which features\nare most important, as their weights will be larger than those of"}, {"title": "III. RESULTS", "content": "Table 3 reports the results obtained by each individual\nclassifier as well as the ensemble overall for each of the 3-day,\n7-day and 14-day window cases. In the results reported here,\nlonger windows generally correspond to better AUC values,\nalthough this need not necessarily always be the case. Note also\nthat the ensemble method always outperforms the individual\nclassifiers (see Figure 2).\nExamining the coefficients in the individual LR model\nyields some insight into which features can best be used to\npredict readmission. As might be expected, there is significant\noverlap in these important features across different time\nwindows (3, 7 or 14 days). For example, the number of previous\nhospital visits tends to be an important predictor of readmission,\nwhere patients with frequent hospital visits prior to the ED visit\nwill have a higher probability of readmission. In a similar\nfashion, certain CCS codes (e.g., certain types of cancers, sickle\ncell anemia, encephalitis, cystic fibrosis, etc.) when they appear\nas the primary CCS code associated with a given ED visit are\nalso associated with higher probability of readmission, as are\ncertain injuries (e.g., certain falls, aspirated foreign objects,\nopen wounds, etc.). Coefficient inspection can also lend insight\ninto coding idiosyncrasies: the procedure code for fetal\nmonitoring was found to be associated with near-certain\nreadmission in data that had supposedly excluded pregnant\nwomen. Closer examination revealed that 28% of ED visits\ncoded for fetal monitoring were not also coded for pregnancy,\nand hence had not been removed.\nThe performance of the ARC1 and ARC2 classifiers is also\nquite interesting. ARC1 obtains AUC values that are\ncomparable to NB by matching its rule antecedents against only\nthe primary CCS codes culled from records in the appropriately\nsized window prior to the ED visit in question. ARC2 obtains\nresults of nearly similar quality in terms of AUC by matching\nits rule antecedents against the primary and secondary CCS\ncodes for the current ED visit alone. Furthermore, like for LR,\nARC1 and ARC2 deal with directly interpretable features. By\nlooking at the rules with high confidence and support, we know,\nfor example, what combination of CCS codes in a given ED\nvisit (ARC2) are associated with increased probability of\nreadmission. For our data, a CCS code of 248 (gangrene) when\nco-occurring with 49 (diabetes mellitus without complication),\n114 (peripheral and visceral atherosclerosis), or 211 (other\nconnective tissue disease) is a good indicator of readmission.\nFor ARC1's longitudinal view of primary CCS codes, visits\nwith primary CCS codes of 50 (diabetes mellitus with\ncomplications) and 141 (other disorders of the stomach or\nduodenum) with either 250 (nausea and vomiting) or 251\n(abdominal pain) are similarly associated with high rates of\nreadmission (Table 4 shows top 5 association rule antecedents\nfor both ARC1 and ARC2)."}, {"title": "IV. DISCUSSION", "content": "Our results show that we can, using only administrative data\nwhich is readily and widely available, predict, with a\nreasonably degree of certainty, which patients are likely to be\nhospitalized after leaving the emergency department at 3, 7 and\n14 days. Our results compare favorably to other prediction\nattempts of revisits, hospitalizations or re-hospitalizations may\nof which have longer time horizons (e.g., 30 days) [25, 38, 49-\n55]. Perhaps not surprisingly, some efforts to predict hospital\nadmissions at the time of the index emergency department visit\nat the time of triage (first presentation) using administrative\ndata have been more successful, ROC = 0.85 [56]. Our\napproach, unlike some other machine learning approaches, is\nrelatively interpretable and can be used to selectively help\nphysicians and other healthcare professionals make decisions\nabout whether to (1) admit patients instead of sending them\nhome from the emergency department or (2) allocate resources\nafter a patient leaves the emergency department to help prevent\nfuture hospitalizations.\nUnderstanding the transition between emergency\ndepartment visits and hospitalizations is extremely important\ngiven that over 80% of all unscheduled hospital admissions in\nthe United States originate from emergency department visits\n[57]. In fact, the proportion of admissions originating from the\nED has increased dramatically over the last several years [57].\nThe increase in emergency room use has led to overcrowding\nof emergency departments which in turn affects quality of care\nand patient outcomes [58]. To prevent revisits and bounce\nbacks from emergency departments, multiple approaches have\nbeen applied, including telephone calls following patients\ndischarged to home by nurse navigators and attempts to\nschedule primary care visits for patients discharged to home.\nWhat is needed is an approach to allocate such post-discharge\ninterventions effectively. Many patients in the emergency\ndepartment are not likely to need such interventions. We\nbelieve our approach, by targeting patients that are likely not\nonly to return, but get admitted to the hospital, provides a\npromising target for quality and patient satisfaction initiatives.\nAnd while many projects investigate revisits to the emergency\ndepartment, these projects are descriptive, and focus on\nidentifying risk factors rather than making predictions.\nOur work can also be extended into a decision-support\nsystem. Given that the data we use is generally available, our\noutcome results, based on association rules, are easy to\ninterpret. While the claims data are not available at the time of\ndecision to discharge, all of the information, in theory, that is\nused to generate the discharge data is available. In future work,\nwe need to validate our results in other large geographic regions\n(e.g., states other than California) and with other years. Such\nwork is underway. Ultimately, our decision-support work\ncould help physicians make more informed choices about\npatients on the margin (i.e., patients who for whom it is not\nimmediately clear if they should be admitted to the hospital or\nsent home. Patients who are discharged to home but are flagged\nas high risk for a future admission could be targeted for close\nfollow up with a visit to their primary care, a call from a nurse\nor pharmacist. Indeed, not all patients, even if they are told they\nare likely to be admitted in the future, may wish to be admitted,\nand some may prefer a trial of care at home, prior to an\nadmission [41].\nOur paper has several limitations. First, we use\nadministrative data exclusively and do not include specific\nobservable data that may be important to determine patient\nseverity when presetting to an emergency department (e.g. vital\nsigns, medications, triage assessment from notes). Second, our\ndata are only for the state of California. It is possible, but\nunlikely, that patients seen in California emergency\ndepartments are admitted to a hospital in another state, and we\nwould not know about this. Third, some information that may\nbe important for predicting visits to the emergency department\nare not in our data, for example, health literacy or language\ndifficulties (e.g., patients for whom English is not their primary\nlanguage) [59]. In addition, we have limited information about\nthe hospitals and emergency departments, and institutional\nvalues like teaching status and size may affect patient\noutcomes. Some of this information could be added to our\nmodel by linking our data to information from, for example, the\nAmerican Hospital Association database. Fourth, we did not\nfocus on admissions to the hospital in more than 14 days.\nHistorically, some quality metrics look at revisits to emergency\ndepartments within 72 hours, although there is no empirical\nevidence for looking at this period [14]. A 7-day period may be\na more reasonable period for measuring quality of care in\nemergency departments [60], because revisits to an emergency\ndepartment within 7 days are most likely to be related to the\nsame health problem as the index visit [30]. For this project we\nchose 7 and 14 days based on a work that identified revisits at\n9 days following an initial emergency department based on a\n\"time-to-return-curve\" analysis for identifying potentially\navoidable re-visits to the emergency department [14]. Finally,\none can always learn from larger datasets, or use more features\n(recall only CCS codes were used in ARC1 and ARC2) when\ntraining the underlying learning algorithms.\nDespite these limitations, the results from this pilot study\ndemonstrate that using only a large administrative database, we\ncan develop models that can help predict which patients, after\nleaving the emergency department, are most likely to be\nadmitted to a hospital either within a 3-, 7- or 14-day period.\nThis approach can be used to allocate scarce resources such as\ncalls from nurse navigators and pharmacists. However, it can\nalso be used to investigate new quality metrics and ultimately\ninform the building of diagnostic support tools to automatically\nflag high-risk patients. Finally, because our approach, unlike\nsome machine-learning approaches, which operate like a \u201cblack\nbox\", leads to associate rules that are easy to interpret, we may\nlearn of novel risk factors and combinations of factors,\naccounting for the ordering of events that would be much more\ndifficult to discover using traditional epidemiological methods.\"\n    }"}]}