{"title": "A Universal Model for Human Mobility Prediction", "authors": ["Qingyue Long", "Yuan Yuan", "Yong Li"], "abstract": "Predicting human mobility is crucial for urban planning, traffic control, and emergency response. Mobility behaviors can be categorized into individual and collective, and these behaviors are recorded by diverse mobility data, such as individual trajectory and crowd flow. As different modalities of mobility data, individual trajectory and crowd flow have a close coupling relationship. Crowd flows originate from the bottom-up aggregation of individual trajectories, while the constraints imposed by crowd flows shape these individual trajectories. Existing mobility prediction methods are limited to single tasks due to modal gaps between individual trajectory and crowd flow. In this work, we aim to unify mobility prediction to break through the limitations of task-specific models. We propose a universal human mobility prediction model (named UniMob), which can be applied to both individual trajectory and crowd flow. UniMob leverages a multi-view mobility tokenizer that transforms both trajectory and flow data into spatiotemporal tokens, facilitating unified sequential modeling through a diffusion transformer architecture. To bridge the gap between the different characteristics of these two data modalities, we implement a novel bidirectional individual and collective alignment mechanism. This mechanism enables learning common spatiotemporal patterns from different mobility data, facilitating mutual enhancement of both trajectory and flow predictions. Extensive experiments on real-world datasets validate the superiority of our model over state-of-the-art baselines in trajectory and flow prediction. Especially in noisy and scarce data scenarios, our model achieves the highest performance improvement of more than 14% and 25% in MAPE and Accuracy@5.", "sections": [{"title": "1 INTRODUCTION", "content": "Human mobility data records the movement of human beings in space over time [4, 30, 54]. It supports various activities [53, 56] and reflects the spatiotemporal dynamics of the city [37, 52]. Consequently, predicting human mobility has significant practical implications, such as urban planning [59, 60], traffic control [35, 57], and emergency response [54]. Individual trajectory and crowd flow can be treated as two observations of human mobility that represent two different modalities of mobility data. Individual trajectories describe human mobility behavior from a micro perspective, highlighting personal preferences [61]. Conversely, crowd flows encapsulate human movements from a macro perspective, reflecting collective trends [9]. Crowd flows originate from the bottom-up aggregation of individual trajectories, while individual trajectories are influenced by the constraints imposed by crowd flows. This bidirectional influence between individual and collective contributes to the complexity of human mobility."}, {"title": "2 RELATED WORK", "content": "Mobility Prediction. Mobility prediction can be divided into individual and collective categories. Individual prediction focuses on personal preferences [36]. For example, Qiao et al. [17] and Wang et al. [44] developed a Markov-based model by considering the spatiotemporal characteristics of individual mobility. Collective flow prediction emphasizes modeling collective mobility trends. For example, DeepSTN+ [14] uses a context-aware spatiotemporal neural network for flow prediction. CrowdNet utilizes graph convolutional networks to achieve flow prediction adapted to various spatial and temporal granularities [8]. Researchers have integrated individual and collective mobility data better to understand human mobility [6, 10, 24]. TrGNN [22] uses vehicle trajectories to infer short-term traffic flow, predicting unseen and non-recurring traffic patterns. GETNext [49] constructs a global flow graph to integrate transition patterns into trajectory prediction. With the emergence of large language models (LLMs), researchers have begun exploring their potential in mobility prediction, such as LLM-Mob [45], Agent-Move [13], TrajAgent [12] and CoPB [38]. However, there is still a gap in using LLM to understand and reason about human behavior. Thus, it is necessary to develop foundational models from scratch, specifically trained on pure mobility data. Table 1 compares the advantages of our model with existing solutions. In this work, we build a universal model using different types of mobility data, which can effectively predict both trajectories and flows, demonstrating exceptional robustness.\nDiffusion Models and Foundation Models. We focus on human mobility studies based on diffusion models. DiffTraj [63] and ControlTraj [64] combine the generative capabilities of diffusion models with spatiotemporal features derived from trajectories. PriSTI [28] uses a conditional diffusion framework for spatiotemporal imputation with enhanced prior modeling. TrajGDM [11] utilizes diffusion models to capture the universal mobility pattern in a trajectory dataset. Foundation models have revolutionized natural language processing [1] and computer vision [29] through their ability to generalize across different applications. Building on the success of foundation models in these fields, extending them to the spatiotemporal domain is a natural next step. Although models like UniST [51] and GPD [55], have made some progress in predicting collective dynamics, there remains a significant gap in universal models capable of adapting to various types of mobility data. In this work, we present the UniMob model, marking the first attempt to apply a universal mobility prediction model based on a diffusion transformer. We provide more discussions of diffusion models in Appendix A.1.1."}, {"title": "3 PRELIMINARIES", "content": "3.1 Problem Definition\nHuman mobility data can be divided into two types: individual and collective. Trajectories can describe individual mobility, while flow data can characterize collective mobility.\nDefinition 1: (Individual Trajectory). An individual trajectory can be defined as $X_{traj} = \\{(l_1, t_1), (l_2, t_2), ..., (l_n, t_n)\\}$, where each location $l_i$ is represented as the form in latitude and longitude coordinates or a region ID.\nDefinition 2: (Crowd Flow). Crowd flow includes inflow and outflow, defined as the number of people entering or leaving a region within a given time interval. The crowd flow for a region $I$ can be represented as $X_{flow} \\in \\mathbb{R}^{N \\times T}$, where $T$ is the number of time intervals, and $N$ is the dimension of the flow, such as $N = 2$ for inflow and outflow. The entire city's flow can be represented as $Y \\in \\mathbb{R}^{N \\times T \\times L}$, where $L$ is the number of regions.\nProblem Statement: (Mobility Prediction). Given $p$ historical records of mobility data (which can be trajectory $X^{traj}_{[t-p:t]}$ or flow $X^{flow}_{[t-p:t]}$), our goal is to predict the future $k$ steps $X^{traj}_{[t:t+k]}$ or $X^{flow}_{[t:t+k]}$"}, {"title": "3.2 Denoising Diffusion Probabilistic Model", "content": "Diffusion models use latent variable models, denoted as $p_{\\theta}(x_0) := \\int p_{\\theta}(x_{0:T})dx_{1:T}$. The latent variables $x_1, ..., x_T$ have the same dimension as the data $x_0 \\sim q(x_0)$. The model uses two Markov chains: a forward chain that perturbs data into noise and a reverse chain that converts noise back into data. The forward diffusion process:\n$q(x_{1:T} | x_0) := \\prod_{t=1}^{T} q(x_t | x_{t-1}),$\nwhere $q(x_t | x_{t-1}) := \\mathcal{N}(\\sqrt{1 - \\beta_t}x_{t-1}, \\beta_t I)$. Equivalently, $x_t$ can be expressed as $x_t = \\sqrt{\\alpha_t}x_0 + (1 - \\alpha_t) \\epsilon$ for $\\epsilon \\sim \\mathcal{N}(0, I)$, with $\\alpha_t = \\sum_{i=1}^{t} (1 - \\beta_i)$.\nThe reverse process denoises $x_t$ to retrieve $x_0$, where $x_T \\sim \\mathcal{N}(0, I)$. Assuming $p_{\\theta}(x_{t-1}|x_t)$ follows a normal distribution:\n$\\begin{cases}\np_{\\theta}(x_{0:T}) := p(x_T) \\prod_{t=1}^{T} p_{\\theta}(x_{t-1} | x_t),\np_{\\theta}(x_{t-1} | x_t) := \\mathcal{N}(x_{t-1}; \\mu_{\\theta}(x_t, t), \\sigma_{\\theta}(x_t, t) I)\n\\end{cases}$\nHo et al. [19] introduced denoising diffusion probabilistic models:\n$\\begin{cases}\n\\mu_{\\theta}(x_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} (x_t + \\frac{\\beta_t}{\\sqrt{1 - \\alpha_t}} \\epsilon_{\\theta}(x_t,t)),\n\\sigma_{\\theta}(x_t, t) = \\beta_1^{1/2}, \\beta_t = \\frac{\\beta_t}{1 - \\alpha_t},\nt > 1 \\\nt = 1\n\\end{cases}$\nwhere $\\epsilon_{\\theta}$ is a trainable denoising function. The objective for training the reverse process is:\n$\\min_{\\theta} \\mathcal{L}(\\theta) := \\min_{\\theta} \\mathbb{E}_{x_0 \\sim q(x_0),\\epsilon \\sim \\mathcal{N}(0,1),t} || \\epsilon - \\epsilon_{\\theta}(x_t, t) ||^2,$\nwhere $x_t = \\sqrt{\\alpha_t}x_0 + (1 - \\alpha_t) \\epsilon$. This can be seen as a weighted variational constraint on the negative log-likelihood, reducing the significance of terms at low $t$ when little noise is present."}, {"title": "4 METHOD", "content": "To unify diverse data formats and varied data characteristics, our universal solution includes two key designs: 1) The mobility tokenizer transforms trajectory and flow into a unified spatiotemporal token format, facilitating the utilization of the powerful diffusion transformer architecture. 2) The individual and collective alignment is designed to jointly train different data types within the same model framework, effectively aligning the differences in individual and collective mobility behavior."}, {"title": "4.1 Overall framework", "content": "The framework of UniMob is shown in Figure 2, which consists of four modules:"}, {"title": "4.2 Multi-view Mobility Tokenizer", "content": "To address the challenge of diverse data formats, tokenization is applied to process different data types into a unified sequential format. Subsequently, two encoders capture the spatiotemporal dynamics inherent in the mobility data from multiple views.\n4.2.1 Tokenization. Tokenization is applied to mobility data such as trajectories and flow data, converting it into compact token sequences to enable more efficient computation and standardized processing. We divide the trajectory $X^{traj}$ and flow $X^{flow}$ into several continuous overlapping or non-overlapping tokens, each with a length of $p$. Therefore, the total number of input tokens is $C = \\frac{(T - p)}{Q} + 1$, where $T$ denotes the total number of time intervals and $Q$ represents the horizontal sliding stride.\n4.2.2 Trajectory Encoder. In this module, we model trajectory from the spatial and temporal perspectives. Firstly, to capture the geographical continuity of mobility, we construct a spatial graph $G = (V, E)$. The nodes $V$ represent all visited locations, and the edges $E$ define the connections between these locations. Each edge $e = (u, v)$ is an unordered pair with a positive weight $w_{uv}$, representing the Euclidean distance between locations $u$ and $v$. We use a graph embedding approach $F(.)$ to get the location embedding $S$, which is denoted as follows:\n$S = F(G),$\nWe obtain a spatial embedding matrix $S \\in \\mathbb{R}^{L \\times W}$, where $L$ is the number of regions, and $W$ is the dimension of embedding.\nThen, to capture the periodicity of time, we use temporal embedding matrices $H \\in \\mathbb{R}^{T_h \\times W}$ and $D \\in \\mathbb{R}^{T_a \\times W}$ to represent the time features. $T_h$ is the number of time slots in a day (determined by the sampling frequency), and $T_a = 7$ is the number of days in a week. Finally, the trajectory embedding $R_t$ is obtained by concatenating the spatial and temporal embeddings, represented as:\n$R_t = [S_t; H_t; D_t],$\nwhere $R_t$ is the vector representation of the $t$-th trajectory point.\n4.2.3 Flow Encoder. The flow can obtain corresponding spatial and temporal embeddings like the trajectory. Moreover, the flow has an extra embedding for historical values, achieved by mapping the raw historical time series $X^{flow}_{[t-p:t]}$ into the latent space $V_t \\in \\mathbb{R}^{W}$:\n$V_t = FC(X^{flow}_{[t-p:t]}),$\nwhere $FC(\\cdot)$ is a fully connected layer and $W$ is the dimension of embedding.\nThus, we connect the spatial embedding, the temporal embedding, and historical embedding to obtain the flow embedding $F_t$:\n$F_t = [S_t; H_t; D_t; V_t].$"}, {"title": "4.3 Joint Noise Predictor", "content": "Formally, suppose we have two types of mobility data sampled from the distribution $q(R_0, F_0)$. Our goal is to design a diffusion-based model that can capture some related distributions determined by $q(R_0, F_0)$, specifically the marginal distributions $q(R_0)$ and $q(F_0)$.\nAccording to Bao et al. [3], different forms of distributions can be unified into the general form of $\\mathbb{E}[\\epsilon_R, \\epsilon_F | R_{t_R}, F_{t_F}]$, where $t_R$ and $t_F$ are two different timesteps, and $R_{t_R}$ and $F_{t_F}$ are the corresponding perturbed data. Particularly, a maximum timestep $T$ means marginalizing it. By setting $t_F = T$, we have $\\mathbb{E}[\\epsilon_R | R_{t_R}, F_{T}] \\approx \\mathbb{E}[\\epsilon_R | R_{t_R}]$, which corresponds to the marginal distribution $q(R_0)$. Similarly, by setting $t_R = T$, we have $\\mathbb{E}[\\epsilon_F | F_{t_F}, R_{T}] \\approx \\mathbb{E}[\\epsilon_F | F_{t_F}]$, which corresponds to the marginal distribution $q(F_0)$.\nInspired by the unified view, we learn $\\mathbb{E}[\\epsilon_R, \\epsilon_F | R_{t_R}, F_{t_F}]$ for all $0 \\le t_R, t_k < T$ to model all relevant distributions determined by $q(R_0, F_0)$. We employ a joint noise prediction network $\\epsilon_{\\theta} (R_{t_R}, F_{t_F}, t_R, t_F)$ to predict the noise injected into $R_{t_R}$ and $F_{t_F}$ together:\n$\\epsilon = \\epsilon_{\\theta} (R_{t_R}, F_{t_F}, t_R, t_F),$\nWe train a joint noise prediction network based on the trajectory and flow embeddings obtained in Section 4.2.2. Naturally, to capture the spatiotemporal correlations of mobility data, we use a transformer-based backbone in UniMob to process inputs from different mobility data types."}, {"title": "4.4 Mobility Predictor", "content": "After the denoising process in the latent space is complete, the target of the predictor is to transform the embeddings back into the form of the original data.\n4.4.1 Trajectory Predictor. For the discrete space domain, we add an inverse step at the end of the denoising process, which converts the real-valued embedding of $R_0$ to the probability distribution of locations $d = \\{d_1, d_2, ..., d_v\\}$ as follows:\n$P(E) = (E^TE)^{-1}E^T,$\nwhere $E$ denotes Embedded Matrix, $E^T$ denotes the transpose of matrix $E$, and $(.)^{-1}$ represents the matrix inverse.\n$d = R_0 * P(E),$\nwhere $d$ denotes the probability of visiting each location in the trajectory.\n$i = \\arg \\max(d),$\nwhere $\\arg \\max()$ function is used to find the maximum value index in a vector, and $i$ denotes the next location id.\n4.4.2 Flow Predictor. The regression layer makes predictions based on the following:\n$Y_{[t:t+f]} = FC(F_0),$\nwhere $FC(\\cdot)$ is a fully connected layer and $Y_{[t:t+f]}$ is future flow."}, {"title": "4.5 Bidirectional Individual-Collective Alignment", "content": "To address significant characteristic differences in two modalities of mobility data, we design several alignment mechanisms, including Individual-to-Collective and Collective-to-Individual alignment. These methods enable collaborative perception and complementary expression of multi-source mobility data. After obtaining well-interacted representations of trajectories and flows, we employ the prediction loss from a joint noise prediction network.\n4.5.1 Individual-to-Collective Alignment. The alignment from individuals to collective is designed to aggregate individual movements from the bottom up, collaborating with collective mobility patterns to capture collective dynamics. Thus, we utilize I2C (Individual to Collective) loss to align trajectory with flow. Specifically, we first aggregate multiple trajectory embeddings:\n$R_{all} = R_{u1} + R_{u2} + ... + R_{un},$\nwhere $R_{all}$ is the aggregated trajectory embeddings of multiple users, while $R_{un}$ represents the trajectory embedding of user $u_n$. This aggregated embedding captures and displays the collective behavioral characteristics and trends. Then, we interact this aggregated result with the flow embedding. We can optimize their collaborative representation by maximizing the similarity between these two embeddings:\n$\\mathcal{L}_{I2C} = 1 - \\frac{\\kappa}{\\|u\\| \\|v\\|},$\nThrough the I2C loss, we can more accurately capture and describe the dynamic changes of collective in space and time.\n4.5.2 Collective-to-Individual Alignment. The alignment from the collective to the individual aims to impose constraints on individual behavior through collective mobility patterns, better modeling individual movement preferences. Through contrastive learning, we utilize C2I (Collective to Individual) loss to identify common spatiotemporal patterns in micro-level trajectories and macro-level flows. We determine positive and negative samples based on the spatiotemporal consistency between trajectory data and flow data:"}, {"title": "4.6 Training", "content": "We model the embedding of trajectories and flows using a joint noise prediction network with the following prediction loss function:\n$\\mathcal{L}_{pred} = \\mathbb{E}_{R_0, F_0, \\epsilon_R, \\epsilon_F, t_R, t_F} || \\epsilon_{\\theta} (R_{t_R}, F_{t_F}, t_R, t_F) - [\\epsilon_R, \\epsilon_F]||^2,$\nwhere $[,]$ denotes concatenation, $\\epsilon_R$ and $\\epsilon_F$ are sampled from standard Gaussian distributions, and $t_R$ and $t_e$ are uniformly sampled from $\\{1, 2, ..., T\\}$ independently.\nFinally, the total loss is expressed as:\n$\\mathcal{L}_{total} = \\alpha \\mathcal{L}_{I2C} + \\beta \\mathcal{L}_{C2I} + \\gamma \\mathcal{L}_{pred},$\nThe weights $\\alpha$, $\\beta$, and $\\gamma$ correspond to the three loss terms, allowing the total loss function $\\mathcal{L}_{total}$ to simultaneously enable trajectory and flow interactions and accurately predict mobility."}, {"title": "4.7 Variants", "content": "In the real world, universal models have a wide range of application scenarios and diverse application requirements. For example, in some cases, there is only one type of mobility data available; in other cases, to save computational resources, it is desirable to use a shared set of parameters to perform flow and trajectory predictions simultaneously. Therefore, we design four model variants to ensure our model can flexibly adapt to different application scenarios and possess greater practicality. As shown in Figure 3, these variants are based on whether parameters are shared and whether both types of mobility data are used during testing:\n\n\nUniMob-v1: This variant is designed for scenarios with limited data types and constrained computational resources.\nUniMob-v2: This variant is suitable for scenarios with multiple types of mobility data but needs to save computational resources.\nUniMob-v3: This variant can handle scenarios with rich data types but limited computational resources.\nUniMob-v4: This variant is designed for users with rich data types and ample computational resources."}, {"title": "5 EXPERIMENTS", "content": "5.1 Experimental Settings\n5.1.1 Dataset. We conduct extensive experiments on three real-world mobility datasets from Shanghai, Senegal, and Xinjiang. Each dataset includes both trajectory and flow data. The details of datasets are summarized in Appendix A.2. The experiment section only presents the results for the Shanghai and Senegal datasets. Detailed results for the Xinjiang dataset can be found in Appendix B.\n5.1.2 Baselines. We compare the performance of our model with state-of-the-art baselines. Previous methods could only accomplish one type of mobility data prediction task, so the baseline methods are divided into trajectory and flow prediction. For Flow Prediction, we compared our model with six SOTA baselines (HA [43], VAR [31], ST-ResNet [58], MSDR [27], STID [39], and PriSTI [28]. For Trajectory Prediction, we compared our model with seven SOTA baselines (Markov [16], LSTM [21], DeepMove [15], STAN [32], SNPM [50], TrajGDM [11], and GETNext [49]. We provide the details of baselines in Appendix A.3.\n5.1.3 Metrics. For trajectory prediction, we use Accuracy@k to sort candidate locations by model-predict probabilities and check if the true position falls within the top k predictions. For flow prediction, we choose mean absolute errors (MAE), Mean Absolute Percentage Error (MAPE), and root mean squared errors (RMSE) as the evaluation metrics. MAE is the mean absolute error between predicted and ground truth values. MAPE is the mean absolute percentage error between the predicted and ground truth values. RMSE is the square root of the mean squared error between the predicted and ground truth values."}, {"title": "5.2 Overall Performance", "content": "As shown in Tables 2, our method demonstrates similar or better performance than the state-of-the-art baselines for all tasks on Shanghai and Senegal datasets (Please refer to Table 6 in Appendix B.1 for Xingjiang dataset). We conducted multiple experiments and reported the average performance. In flow and trajectory prediction tasks conducted on multiple real-world datasets, our UniMob model demonstrated the best performance across all evaluation metrics. Specifically, it achieved a performance improvement of over 6% in flow prediction and 3.73% increase in trajectory prediction. Additionally, compared to other baseline methods, only our model can simultaneously perform flow and trajectory predictions, demonstrating that our model design effectively achieves unified human mobility prediction. Furthermore, we used four model variants for each task. Each variant outperformed other baseline methods, maintaining flexibility to handle different scenarios while demonstrating excellent performance. The above conclusions fully demonstrate the feasibility of a unified model in human mobility prediction. Our UniMob model can handle various types of mobility data, showcasing exceptional scalability and robustness. As the first attempt to propose a universal model paradigm for mobility prediction, we have successfully expanded the boundaries of this field.\nNotably, mobility prediction models based on diffusion models, such as PriSTI and TrajGDM, demonstrate superior performance compared to other baselines. This underscores the powerful modeling capability of diffusion models in capturing the spatiotemporal correlations of mobility data. Diffusion models effectively handle dynamics and uncertainties in mobility data through an iterative denoising process, significantly enhancing prediction performance. Therefore, our UniMob model leverages diffusion models to accurately capture spatiotemporal dependencies in mobility data accurately, proving its effectiveness."}, {"title": "5.3 Ablation Study", "content": "To evaluate the impact of each module in UniMob, we conducted ablation experiments, divided into ablations of model design and data usage. Model Design: (1) w/o I2C loss: This variant keeps the model structure unchanged but removes the I2C loss. (2) w/o C2I loss: Similar to the previous one, this variant only removes the C2I loss. (3) w/o shared transformer: In this variant, the flow and trajectory losses no longer share a transformer; instead, each has its independent transformer. Data Usage: (4) w/o flow data: The model is trained using only trajectory data. (5) w/o trajectory data: The model is trained using only flow data.\nThe results of the ablation experiments conducted on the Shanghai and Senegal datasets are shown in Tables 3 and 4 (see Table 7 in Appendix B.2 for the Xinjiang dataset). For the ablation experiments on model design, it is evident that the shared transformer offers limited benefits for interacting with different mobility data types. The most significant performance improvements come from task-specific loss functions. For instance, the I2C loss enhances flow prediction by using aggregated trajectory and flow data for spatiotemporal alignment. Similarly, the C2I loss uses contrastive learning to construct positive samples of flow and trajectory with similar spatiotemporal patterns, thereby aligning macro and micro mobility distribution. These experiments highlight the effectiveness of our approach in aligning trajectory and flow data.\nWe removed different data types for the ablation experiments on data usage and trained the model using only a single type of mobility data. The results showed a significant performance decline. This demonstrates the effectiveness and importance of our model in utilizing different types of mobility data. By combining multiple data types, UniMob can more comprehensively understand and predict human mobility behavior, thereby significantly enhancing the model's overall performance."}, {"title": "5.4 Noise Perturbation", "content": "In real life, mobility data often contains noise. This noise can arise from various sources, such as errors produced by sensors during the collection process or intentionally added by data operators to protect user privacy. To assess our UniMob model's robustness, we added noise to the data and evaluated its performance.\nFor flow data, we introduced varying noise levels to simulate different degrees of data quality. Figure 4 shows that our model's improvement over the best baseline is relatively small without noise. When the noise level reaches 0.3, our model demonstrates a relative improvement of more than 10%. This indicates that compared to other baseline models, UniMob exhibits better robustness in handling noisy data, making it more capable of adapting to flow data with noise for prediction. Moreover, we experimented with adding different noise levels to trajectories. Figure 5 shows that as the noise ratio increases, the improvement of our model relative to the best baseline also increases, achieving a maximum gain of up to 17.82%. Because UniMob integrates two types of mobility data, allowing one type of data to provide the same spatiotemporal dynamics as a supplement when the other type of data is noisy, thereby enhancing the model's robustness. The synergistic effects between different data types can still provide reliable predictions even in noisy data."}, {"title": "5.5 Few-shot Performance", "content": "Similarly, the amount of mobility data may be limited in real-world scenarios due to privacy concerns, data collection challenges, or other constraints. To simulate this situation, we reduce the amount of flow and trajectory data through different operations.\nAs shown in Figure 6, we constructed scenarios with varying proportions of locations having missing flow records. As the proportion of regions with missing flow data increased, our model still demonstrated a significant performance improvement compared to the best baseline. For instance, in the Shanghai dataset, UniMob achieves an improvement of up to 14% when 75% of the region is missing. UniMob's robustness is evident in its ability to maintain high performance despite the absence of a substantial amount of flow data. This is due to its ability to leverage the available trajectory data, compensating for the missing flow information through its joint modeling approach. As shown in Figure 7, we used datasets of different sizes for trajectory data to explore the performance of trajectory prediction with limited data. When the amount of trajectory data is very limited (e.g., only 25% of the dataset), our model shows a 25% improvement in the Shanghai dataset compared to the best baseline. This indicates that when trajectory data is scarce, the flow data provides more diverse mobility patterns, effectively compensating for the lack of trajectory data.\nBy effectively utilizing the spatiotemporal correlations between different types of mobility data, UniMob can provide accurate predictions even in data-scarce environments. UniMob's ability to deliver reliable predictions with limited data highlights its robustness and practical applicability in various scenarios, ensuring dependable performance regardless of data constraints."}, {"title": "6 CONCLUSION", "content": "In this paper, we address an important problem of unified human mobility prediction. We propose a universal human mobility prediction model named UniMob, achieving broad adaptability to various data formats and characteristics. UniMob successfully captures the spatiotemporal dynamics inherent in different modalities of mobility data by unified tokenization and bidirectional alignment between them, enabling unified modeling. Extensive experiments on real-world datasets demonstrate that UniMob outperforms in trajectory and flow prediction. Moreover, UniMob can flexibly adapt to noisy and scarce data scenarios, showcasing its robustness. In the future, we will explore integrating additional urban data modalities, such as weather data, social network data, and GIS data. These factors influence human mobility, we can better predict human mobility patterns by combining them with mobility data."}, {"title": "A. APPENDIX FOR REPRODUCIBILITY", "content": "A.1 Related Work\nA.1.1 Diffusion Models. The diffusion model is a probabilistic generative model first introduced by Sohl-Dickstein et al. [41] and further improved by Ho et al. [19] and Song et al. [42]. As a novel generative model, diffusion models have rapidly advanced in time series and spatio-temporal modeling. Research on time series modeling based on diffusion models is widely applied, such as time series imputation [2, 28], time series generation [25, 26], and time series forecasting [5, 23]. DiffSTG [46] is the first attempt to generalize the widespread denoising diffusion probabilistic models to spatiotemporal graphs (STGs), leading to a novel non-autoregressive framework. KSTDiff [63] designed a knowledge-enhanced denoising network to capture the spatiotemporal dependencies of urban flows and the influence of the urban environment in the denoising process. DiffTraj [63] is a spatiotemporal diffusion probabilistic model for trajectory generation. This model effectively combines the generative capabilities of diffusion models with spatiotemporal features derived from real trajectories. In this work, we introduce the diffusion model for unified mobility prediction adapted to different data types.\n\nA.2 Datasets Details\nWe conducted extensive experiments on three real-world mobility datasets: Shanghai, Senegal, and Xinjiang. The details of datasets are summarized in Table 5. We preprocess the trajectory data for three datasets, filtering out users with fewer than five records per day. For location preprocessing, we map GPS points to predefined grid IDs of a specific granularity. For temporal preprocessing, we organize the time data into fixed intervals, such as hourly or half-hourly segments. Finally, we divide the data into training, validation, and testing sets in a 7:1:2 ratio in chronological order."}, {"title": "A.3 Baselines", "content": "To evaluate the performance of our proposed model, we compared it with state-of-the-art models. Previous methods could only accomplish one type of mobility data prediction task, so the baseline methods are divided into trajectory and flow prediction.\nFlow Prediction. The baselines for flow prediction are as follows:\n* HA [43]: It considers the inflow and outflow to be seasonal processes and employs the average of the previous seasons as the prediction for a week-long period.\n* VAR [31]: This method is vector autoregressive single-step predictor.\n* ST-ResNet [58]: ST-ResNet employs the residual neural network framework to model the temporal closeness, period, and trend properties of crowd flow.\n* MSDR [27]: Multi-Step Dependency Relationship (MSDR) is a brand new variant of recurrent neural networks. Instead of only looking at the hidden state from the latest time step, MSDR explicitly takes those from multiple historical time steps as the input of each time unit.\n* STID [39]: A simple multi-layer perceptron addresses the indistinguishability of time series samples in spatial and temporal dimensions.\n* PriSTI [28]: This method extracts coarse but effective spatiotemporal dependencies from conditional information using a diffusion model, serving as a global context prior.\nTrajectory Prediction. The baselines for trajectory prediction are as follows:\n* Markov Model [16]: The Markov model is a statistical model used to describe the change of states over time. It uses historical trajectory data for location prediction by calculating the transition probabilities between these locations.\n* LSTM [21]: The LSTM network is good at handling sequential data and has the advantage of encoding long-term dependencies, which can naturally be applied to location prediction.\n* DeepMove [15]: The method designs a multimodal embedding recurrent neural network to capture complex sequential transitions by jointly embedding multiple factors that control human mobility.\n* STAN [32]: This model associates non-contiguous but functionally similar visited points that are not adjacent to each other to predict the next location.\n* SNPM [50]: The method constructs a Sequence-based, Dynamic Neighbor Graph (SDNG) to find the similarity neighborhood and develop a Multi-Step Dependency Prediction model.\n* TrajGDM [11]: The method utilizes diffusion models to capture the universal mobility pattern in a trajectory dataset for trajectory prediction.\n* GETNext [49]: The method employs a global trajectory flow map and a novel Graph Enhanced Transformer model to leverage collaborative signals for more accurate trajectory prediction."}, {"title": "B EXPERIMENTAL PERFORMANCE", "content": "B.1 Overall Performance\nTable 6 shows the performance of our universal mobility prediction model on the Xinjiang dataset. UniMob not only accomplishes both trajectory and flow predictions simultaneously but also surpasses current advanced baseline models in all evaluation metrics.\nSpecifically", "aspects": "model design and data utilization. By sequentially removing components of the model design, we identified three design elements that align with different data formats and distributions, each impacting performance, thus validating their effectiveness. Regarding data utilization, by replacing multi-type data with single-type data, we visually demonstrated the performance enhancement brought by using multi-type mobility data in human mobility prediction through our universal model.\nB.3 Noise Perturbation\nDue to biases from sensor collection and artificial noise added for privacy protection, the data used for mobility prediction often contains noise. To verify whether our model can still maintain good predictive capabilities in noisy conditions, we added noise to both the flow and trajectory data. Figure 8 shows that as noise levels increase, our model continues to outperform the best baseline model, and our performance advantage becomes even more pronounced relative to the baseline with increasing noise. This effectively demonstrates the high robustness of our UniMob model.\nB.4 Few-shot Performance\nSimilarly, due to data collection and privacy protection limitations, the amount of mobility data we acquire is often limited. Therefore, we tested the few-shot learning capabilities of our UniMob model. As shown in Figure 9, our model still"}]}