{"title": "LLMs4Life: Large Language Models for Ontology Learning in Life Sciences", "authors": ["Nadeen Fathallah", "Steffen Staab", "Alsayed Algergawy"], "abstract": "Ontology learning in complex domains, such as life sciences, poses significant challenges for current Large Language Models (LLMs). Existing LLMs struggle to generate ontologies with multiple hierarchical levels, rich interconnections, and comprehensive class coverage due to constraints on the number of tokens they can generate and inadequate domain adaptation. To address these issues, we extend the NeOn-GPT pipeline for ontology learning using LLMs with advanced prompt engineering techniques and ontology reuse to enhance the generated ontologies' domain-specific reasoning and structural depth. Our work evaluates the capabilities of LLMs in ontology learning in the context of highly specialized and complex domains such as life science domains. To assess the logical consistency, completeness, and scalability of the generated ontologies, we use the AquaDiva ontology developed and used in the collaborative research center AquaDiva \u00b9 as a case study. Our evaluation shows the viability of LLMs for ontology learning in specialized domains, providing solutions to longstanding limitations in model performance and scalability.", "sections": [{"title": "1. Introduction", "content": "Ontology learning encompasses tasks such as ontology extraction, ontology generation, or ontology acquisition. It is the automatic or semi-automatic creation of ontologies, including extracting the corresponding domain's terms and the relationships between the concepts that these terms represent from a corpus of natural language text and encoding them with an ontology language for easy retrieval [1]. Ontology learning in complex domains like life sciences presents a significant challenge. Although Large Language Models (LLMs) have shown promise in automating the generation and enrichment of ontologies [2, 3, 4, 5, 6], their application in highly specialized domains remains difficult and understudied. The inherent complexity of specialized domains such as life sciences, coupled with domain-specific terminologies and data, limits the ability of LLMs to generate ontologies that meet the structural and logical depth required for advanced reasoning. To explore these limitations, we consider the knowledge representation and ontology developed within the collaborative research center AquaDiva. AquaDiva is a large collaborative project encompassing fields such as biology, geology, chemistry, and computer science, all working towards a shared objective of enhancing our understanding of the Earth's critical zone [7]. As the complexity and amount of data collected within AquaDiva increases, there is an increasing necessity to adopt semantic web approaches to standardize data and facilitate its integration and interoperability [8, 9]. To this end, the AquaDiva ontology (ADOn) has been developed with 78.840 axioms, 8.892 concepts, and 245 object properties. We leverage the AquaDiva ontology ADOn as a use case for evaluating the performance of our method and assessing the structural depth, logical"}, {"title": "2. Related Work", "content": "In recent years, LLMs have gained significant attention for their ability to enhance various ontology-related tasks, including ontology learning. Studies have demonstrated that LLMs can support the creation, enrichment, and refinement of ontologies, helping to automate traditionally labor-intensive tasks. For instance, Mateiu et al. [2] leverage a fine-tuned GPT-3 to translate natural language into OWL Functional Syntax for ontology enrichment. While the approach reduces the need for manual"}, {"title": "3. Methodology", "content": "Our approach builds on our previous work with the NeOn-GPT pipeline for ontology learning [11]. Using the NeOn methodology framework, we translate its structured, iterative process into a series of prompts for pre-trained LLMs, ensuring that the generated ontology is both logically sound and aligned with domain requirements. NeOn-GPT demonstrates effective ontology generation in popular domains such as wine ontology. The wine domain is widely recognized, and wine ontology serves as a benchmark in ontology learning, making it likely to have been included in the training data of pre-trained LLMs. However, our empirical experiments show that the current NeOn-GPT pipeline does not perform as well on highly specialized domains, which are often underrepresented in real-world datasets. Domains such as life sciences are scarce in the training data of language models, making them unfamiliar and challenging for the models to handle effectively. This work extends the NeOn-GPT pipeline to address the more complex and specialized domains, such as the life sciences domain, and is evaluated on the AquaDiva ontology; figure 1 shows the steps of the extended pipeline. Such domains require a deeper understanding of domain-specific knowledge that may not be as readily accessible to LLMs due to their complexity and relative obscurity compared to more mainstream fields. Our enhancements enable the pipeline to effectively generate ontologies in intricate domains, significantly advancing ontology learning for niche areas.\nSpecification of Ontology Requirements. The first phase of the pipeline specifies the ontology requirements using chain-of-thought (CoT) prompting, guiding the model through four logical steps:"}, {"title": "4. Experiments and Results", "content": "In this section, we present a series of experiments and their corresponding results to evaluate the LLM's performance before and after updating the NeOn-GPT pipeline; the generated ontologies are evaluated in terms of logical consistency and structural depth. Our objective is to assess how the proposed updates impact the LLM's ability to generate ontologies for complex life science domains, specifically using AquaDiva ontologies. The AquaDiva ontology domain encompasses the study of groundwater ecosystems, integrating hydrogeology, microbial ecology, geochemistry, karst systems, and environmental science. This ontology supports the annotation and standardization of diverse datasets related to subsurface habitats. The current AquaDiva ontology has 78.840 axioms, 8.892 concepts, and 245 object properties [12]. All experiments are conducted using GPT-40 [17]. The results of these experiments are discussed to illustrate the improvements achieved through the updated pipeline. Our code base is publicly available for research and development purposes, accessible at: https://github.com/NadeenAhmad/NeOn-GPTAquaDivaOntology. It includes all details about the prompts, interactions with LLMs, and the methodology used in our approach.\n4.1. Experiment 1: Baseline NeOn-GPT (AquaDiva)\nIn this experiment, we applied the original NeOn-GPT pipeline without any of the enhancements introduced in this work. The only modification was the inclusion of 222 domain-specific keywords alongside the textual descriptions in the input to the LLM to compensate for the anticipated scarcity of relevant training data related to AquaDiva. This allowed us to evaluate the LLM's performance in its original configuration when applied to a complex life sciences domain.\n4.1.1. Results of Experiment 1: Baseline NeOn-GPT (AquaDiva)\nIn this experiment, we evaluated the LLM-generated AquaDiva ontology against the AquaDiva gold standard ontology [12]. While the LLM successfully captured key concepts such as 'aquifers' and 'microbial communities', the ontology remained overly simplistic, with sparse hierarchy, and lacked the complexity needed for advanced ecological modeling. The metrics and class hierarchy from the newly generated ontology are shown in Figure 2. Compared to the gold standard, the LLM-generated"}, {"title": "4.2. Experiment 2: Count Metric-Guided Prompts (AquaDiva)", "content": "In Experiment 2, we addressed the limitations identified in 4.1 (Experiment 1) by revising the prompt pipeline to incorporate explicit count metrics from the AquaDiva gold standard, such as the number of classes (8,892) and object properties (245). The prompt instructed the LLM to align with these metrics, emphasizing a subclass count of at least n-1 (where n is the total number of classes) to address shallow hierarchies observed in 4.1 (Experiment 1).\n4.2.1. Results of Experiment 2: Count Metric-Guided Prompts (AquaDiva)\nThe ontology generated in Experiment 2 demonstrated significant improvements over the initial version, exhibiting a more interconnected structure with increased density and a more layered hierarchy. As shown in Figure 3, this version includes 342 classes and 795 axioms, a notable increase from Experiment 1 but still lower than the expected 8,892 classes and 78,840 axioms in the AquaDiva gold standard ontology. This iteration represents a broader range of concepts and relationships, demonstrating more alignment with the domain's complexity. For instance, the ontology now contains 108 SubClassOf axioms and 103 EquivalentClasses axioms, improving upon 4.1 (Experiment 1), resulting in a more layered hierarchy with more subclass levels like (e.g., \u201cHydroChemistry\u201d \u2013 \u201cSubClassOf\u201d \u2192 \u201cGeological Chemistry\" \u2013 \"SubClassOf\u201d \u2192 \u201cEarth Science\u201d). However, the ontology still falls short in certain areas, particularly in object property count, which remains at 8 compared to the expected 245 in the gold standard. This can be partially attributed to GPT-40's limitations, including its 4096-token output limit [17], which restricts the amount of content generated in a single response. Additionally, the LLM's mathematical limitations, particularly in precise counting tasks [18], likely contribute to the discrepancies in class and axiom counts. Moreover, some redundancy persists, with overlapping object properties such as \"interact with\" and \"interacts with,\" indicating a need for further refinement."}, {"title": "4.3. Experiment 3: Merging Ontologies (AquaDiva)", "content": "In Experiment 3, we merged the ontologies generated from Experiments 1 and 2. Merging ontologies is a widely accepted approach in ontology engineering, as it can improve coverage, coherence, and the overall quality of the resulting ontology by combining complementary strengths from different sources [19]. By merging ontologies, we can address gaps that may exist in individual outputs and ensure a more comprehensive and robust knowledge representation. We utilized the RDFLib library to merge these ontologies; the ontology from 4.2 (Experiment 2), which contains richer concepts and better hierarchical structures, was used as the foundation. Unique and complementary elements from 4.1 (Experiment 1), particularly object properties and relationships, were incorporated to enhance depth and coverage."}, {"title": "4.3.1. Results of Experiment 3: Merging Ontologies (AquaDiva)", "content": "The ontology generated in Experiment 3 shows a notable improvement in several key metrics, as shown in 4. The total axiom count increased to 1,479, and the object property count rose to 50, compared to the lower counts observed in earlier experiments. These increases suggest that merging ontologies effectively captured a broader set of relationships and axioms, resulting in a more comprehensive ontology. However, while the merged ontology shows progress, some limitations persist. The class count, now at 500, is significantly improved compared to previous versions but remains below the gold standard AquaDiva ontology. There are still discrepancies between the generated metrics and the expected counts, particularly regarding data and annotation properties, where further refinement is needed to match the complexity of the domain. While the object property count has risen, it still falls short of the expected 245, indicating that additional adjustments are necessary to fully capture the domain's complexity. Notably, the ontology has made significant strides in logical consistency, with 713 logical axioms, and includes 114 SubClassOf axioms. This improved structure provides better support for defining relationships such as hierarchical taxonomies and equivalence between classes (e.g., \"Aquatic Fungi\" = \"Aquatic Microorganism = Fungi\"). Yet, despite these advances, the number of disjoint classes (109) still lags, impacting the ontology's ability to distinctly differentiate between overlapping or mutually exclusive categories, which is critical for accurate environmental modeling."}, {"title": "4.4. Experiment 4: Re-prompting & Advanced Role-play Prompting (Habitat)", "content": "In previous experiments, we tried to avoid exceeding the output token limitation of LLMs by instructing the model in each prompt to print only the new parts of the ontology. We manually aggregated these responses into a single ontology to prevent the model from regenerating the entire ontology repeatedly. However, this approach alone was not enough to fully overcome the token limitation issue. In Experiment 4, we addressed the limitations of using GPT-40 for generating a comprehensive ontology due to the model's output token constraints. Rather than attempting to generate the entire AquaDiva ontology at once, we instructed the LLM to categorize 222 AquaDiva-specific keywords into distinct groups, resulting in 22 categories. Inspired by the improvements observed in 4.3 (Experiment 3), where merging outputs led to a more interconnected ontology, we envision that this categorization will help generate better ontologies for each category. Ultimately, merging these individual ontologies will result in a larger and more comprehensive representation of the AquaDiva ontology.\nWe selected the \"Habitat\" category due to its ecological significance in AquaDiva. By developing an ontology for this category, we aimed to create a detailed and accurate representation that could serve as a model for expanding to other categories. To improve the quality and precision of the generated ontology, we applied several enhancements to the prompt pipeline in 4.2 (Experiment 2). First, we provided the LLM with a detailed description of the Habitat category along with relevant keywords, ensuring a richer domain-specific context as input. Additionally, we increased the number of few-shot examples from three examples to seven examples, tailoring them to the specific concepts within the Habitat domain. Furthermore, we refined the role-play persona used in the prompts, building on our findings that show enriched personas can yield higher-quality outputs [13]. We refined the role-play persona to represent an expert aquatic ecologist, leveraging domain knowledge to guide the model more effectively. The persona provided detailed instructions on how to structure the Habitat ontology with rich ecological context, ensuring domain relevance.\nTo iteratively refine the generated ontology, we applied re-prompting, asking the model to enhance the hierarchical depth and align with predefined metrics after the initial output. For example, a prompt to increase the subclass count to at least n-1, where n refers to the total number of classes, while other prompts address shallow hierarchies."}, {"title": "4.4.1. Results of Experiment 4: Re-prompting & Advanced Role-play Prompting (Habitat)", "content": "The results from Experiment 4 show that while directing the LLM's attention to the 'Habitat' category allowed for a more concentrated development of the ontology, certain limitations remain evident."}, {"title": "4.5. Experiment 5: Reuse (Role)", "content": "In Experiment 5, we generated an ontology for the \"Role\" category within the AquaDiva ontology with the same enhancements done to the pipeline in 4.4 (Experiment 4). To address the lack of hierarchical depth observed in previous experiments, we improved the subclass structure by incorporating an ontology reuse strategy using a detailed example manually extracted from the ENVO ontology. This reuse example demonstrated an extensive hierarchy of classes and subclasses, utilizing a visual structure with arrows to represent increasing levels of subclass specificity. This model served as a guide for the LLM, ensuring that each class in the Role ontology would have a well-defined hierarchy of subclasses, thereby enhancing the overall depth and complexity of the ontology. Here's a simplified portion of the example provided in the prompt for reuse to illustrate the hierarchical structure:\n-> biological_process\n--> biodegradation\n--> cellular process\n---> cellular metabolic process\n----> cellular alkane metabolic process\n----> photosynthesis\nIn this format, each arrow represents increasing levels of subclass hierarchy, starting from broad categories like \"biological_process\" and moving down to more specific entities such as \"cellular_process.\" This reuse example, manually curated from ENVO, helped guide the LLM in generating deeper subclass hierarchies and producing a more layered structure in the Role ontology."}, {"title": "4.5.1. Results of Experiment 5: Reuse (Role)", "content": "The role ontology generated in Experiment 5 demonstrates notable strengths, particularly in its axiom count, which includes 969 axioms, and class count, which includes 118 classes. These metrics accurately represent the relationships within the 'Role' domain, showcasing the ontology's potential for supporting complex reasoning tasks. Additionally, the inclusion of 57 individual instances suggests a more comprehensive and practically applicable ontology, contributing to its overall depth and usability for modeling in the AquaDiva ontology. The ontology is shown in Figure 6, which highlights part of the ontology metrics and class hierarchy.\nOne of the key improvements in this experiment was the significant increase in the subclass count compared to 4.4 (Experiment 4), with the ontology now containing 86 subclasses. This improvement was achieved through the incorporation of the manually extracted ENVO example, which provided a structured reuse of existing hierarchical ontologies. The enhanced subclass hierarchy contributed to a more layered and detailed ontology, addressing prior limitations in the structural depth observed in earlier experiments.\nHowever, despite these strengths, the ontology still exhibits significant limitations; while there is some improvement in logical consistency (e.g., 17 EquivalentClasses), the ontology remains underdeveloped in terms of disjoint class distinctions, with only 10 DisjointClasses axioms. This gap weakens its logical coherence and reduces its robustness for reasoning tasks. Moreover, the broad and generic nature of some classes within the 'Role' category, such as \"Biological Role\" or \"Chemical Role,\" raises concerns"}, {"title": "4.6. Experiment 6: Reuse of domain-specific examples (Carbon & Nitrogen Cycling)", "content": "In Experiment 6, we generated an ontology for the Carbon and Nitrogen Cycling domain, building on the lessons learned from previous experiments. Earlier attempts demonstrated that the reuse of existing ontological resources can significantly improve terminology generation and result in a more complex and layered hierarchy. This was evident in the increase in the number of classes and subclasses from 4.4 (Experiment 4) to 4.5 (Experiment 5). Motivated by these findings, we selected the Carbon and Nitrogen Cycling domain to evaluate how the reuse of an example with domain-specific terminology could further enhance the ontology generation process.\nThis experiment incorporates all the improvements added to the original NeOn-GPT prompt pipeline. First, we continued using the advanced role-play persona from 4.4 (Experiment 4) and 4.5 (Experiment 5) to maintain contextual relevance. For this domain, we provided a detailed description along with domain-specific keywords to guide the model's understanding. Additionally, we increased the number of few-shot examples, tailoring them to the Carbon and Nitrogen Cycling domain. To ensure logical consistency and structural depth, we implemented syntax and consistency restrictions at all stages of ontology generation prompts, reducing the need for later corrections related to missing properties or classes.\nWe enhanced the reuse of existing ontological resources. Instead of using broader, generic examples, we incorporated specific components manually extracted from ENVO that closely align with the Carbon and Nitrogen domain. This targeted reuse approach provided a clearer structure, ensuring the ontology reflected accurate hierarchical depth, interconnected concepts, and detailed relationships. A portion of the reuse example included classes like \"carbon atom\" and \"nitrogen atom\" and their corresponding subclasses, organized into multiple levels of hierarchy.\nHere's a simplified portion of the example provided in the prompt for reuse to illustrate the hierarchical structure:\n-> carbon_atom\n--> carbon-13 atom\n--> carbon-14 atom\n-> dissolved_carbon_atom_in_environmental_material\n--> dissolved_carbon_atom_in_soil\n--> dissolved_carbon_atom_in_water\nThis example, manually curated from ENVO, demonstrated the expected level of hierarchy, with each class and its corresponding subclasses represented by increasing levels of specificity."}, {"title": "4.6.1. Results of Experiment 6: Reuse of domain-specific examples (Carbon & Nitrogen Cycling)", "content": "The Carbon and Nitrogen Cycling ontology developed in Experiment 6 shows significant improvements in capturing complex biochemical processes. Key entities such as \"Carbon Fixation,\" \"Nitrogen Transformation,\" and \"Methanogenesis\" are accurately modeled, with 157 classes and 63 object properties, including 13 functional, 10 symmetric, and 10 transitive properties, enabling detailed representations of interactions like fixing nitrogen and releasing methane.\nA major improvement is the hierarchical depth, with 130 SubClassOf axioms, enhanced by reusing domain-specific components from the ENVO ontology. This includes entities such as \"ammonia oxidation\" and \"biogeochemical cycle\", reflecting a richer, more structured subclass hierarchy. The ontology also includes 1,169 axioms, 455 of which are logical, offering a more detailed representation of processes like \"CO2 Fixation\" and \"Trace Gas Production\"."}, {"title": "4.7. Comprehensive Ontology Performance Overview", "content": "This section presents a comparative analysis of the generated ontologies in terms of precision and concept similarity across the six experiments conducted. We use the AML (AgreementMakerLight) ontology matching system [20] to automatically align and match concepts between the generated ontologies and the gold standard ontologies, the AquaDiva Ontology and the ENVO ontology. For each matched concept, AML produces a similarity score, indicating the degree of semantic overlap between the two concepts. We use these matched concepts to calculate the following evaluation metrics:\n\u2022 Number of entities in the LLM-generated ontologies that match entities in the Gold standard ontology.\n\u2022 Concept similarity evaluates how semantically similar the matched concepts are with the gold standard ontology concepts, calculated by averaging the individual similarity scores for all matched concepts."}, {"title": "5. Conclusion and Future work", "content": "This work extends the NeOn-GPT pipeline to enhance ontology learning in complex domains, such as life sciences, by addressing the limitations of LLMs in generating deep and well-structured ontologies. Our approach leverages advanced prompt engineering, ontology reuse, and iterative refinement to"}, {"title": "6. Appendix A: Persona Used for Role-play Prompting", "content": "Persona:\n\"You are an expert aquatic ecologist and knowledge engineer specializing in\ndeveloping ecological ontologies. Holding a PhD in Ecology with additional\ntraining in data science and semantic technologies, you have extensive\nexperience in both field research and computational modeling of aquatic\necosystems. Your expertise is in understanding water bodies' biological,\nchemical, and physical characteristics and structuring this knowledge into\nontologies useful for scientific research and environmental management.\nYou excel at identifying essential entities and relationships within the\necological domain, such as key species, ecological roles, environmental\nconditions, and biogeochemical processes. With a proficient background in\napplying tools like Turtle, you are skilled at crafting well-defined ontologies\nthat represent complex ecological data in a structured, machine-readable format.\nYour approach to ontology creation is meticulous and user-centric, aiming to\nensure that the ontologies facilitate interoperability, data sharing, and reuse\namong diverse stakeholders in the aquatic science community. You provide\ndetailed, precise explanations of ecological concepts and their\ninterconnections, leveraging your deep domain knowledge to enhance\nunderstanding and application of ecological data.\nYour goal is to bridge the gap between raw data and actionable knowledge by\ndeveloping comprehensive ontological frameworks that support advanced data\nanalysis and decision-making in aquatic ecology. You are an expert in the\nAquaDiva domain encompasses studying groundwater ecosystems,\nintegrating hydrogeology, microbial ecology, geochemistry, karst systems, and\nenvironmental science.\""}, {"title": "7. Appendix B: Figures", "content": ""}, {"title": "8. Appendix C: Prompt Pipeline", "content": "This appendix presents an illustrative example of the prompt pipeline used in our ontology generation\nprocess. The diagram highlights the key sections of the prompt, with black text representing the\nfixed template applied across various scenarios. The green-highlighted boxes indicate placeholders for\ndynamic, domain-specific content. The blue text specifically denotes the sections where we have intro-\nduced extensions to the NeOn-GPT pipeline in this work, reflecting improvements and customizations\nmade to better suit the ontology's structural and domain requirements.\nSpecification of Ontology Requirements"}]}