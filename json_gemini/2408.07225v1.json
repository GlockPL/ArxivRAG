{"title": "Longitudinal Evaluation of Child Face Recognition and the Impact of Underlying Age", "authors": ["Surendra Singh", "Keivan Bahmani", "Stephanie Schuckers"], "abstract": "The need for reliable identification of children in various\nemerging applications has sparked interest in leveraging\nchild face recognition technology. This study introduces a\nlongitudinal approach to enrollment and verification accu-\nracy for child face recognition, focusing on the YFA (Young\nFace Aging) database collected by Clarkson University's\nCITeR research group over an 8-year period, at 6-month\nintervals. The dataset includes children ranging from 3 to\n18 years of age, comprising 330 subjects with an average\nof 6 data collections per subject. Our research aims to\ncomprehensively evaluate the performance of state-of-the-\nart face-matching techniques on the YFA database, assess-\nsing the feasibility of recognizing children's faces upon ini-\ntial enrollment and verifying their identity longitudinally at\n6-month intervals. We conduct a comprehensive analysis\nof the system's accuracy considering multiple age groups.\nWe also investigate the temporal degradation of face recog-\nnition accuracy over time. Notably, when comparing the\ninitial enrollment image with longitudinal images over an\n8-year period, we observe a decrease in accuracy. The av-\nerage TAR across all age groups is 98.52% with a FAR of\n0.1% with a 2-year age verification gap and drops to 95.68\nwith a 4-year age gap. However, this rate decreases to\n87.24% after a time difference of 6 years and further drops\nto 71.32% with a time difference of 8 years. The highest\ndrop in accuracy was noticed in the age group of (3-5) years\nold children and the lowest in (5.5-7) years old. By address-\ning the challenges and opportunities in child face recogni-\ntion, this research contributes significantly to the advance-\nment of technology for identifying missing or abducted chil-\ndren and other critical applications requiring dependable\nbiometric recognition in children.", "sections": [{"title": "1. Introduction", "content": "In recent years, there has been a growing demand for re-\nliable identification of children across various applications,\nincluding missing children, border security, humanitarian,\nand health care. This highlights the need to explore the po-\ntential of face recognition technology for children. How-\never, traditional face recognition systems have primarily fo-\ncused on adults, which poses limitations when applied to\nchildren due to the unique characteristics of juvenile facial\nfeatures and how they change over time [16].\nAging in biometric features results in performance\ndegradation for biometric recognition systems [9]. Unlike\nfactors such as lighting or pose that contribute to variabil-\nity within an identity, aging presents an unavoidable aspect\nthat cannot be controlled during the image capture process\n[8]. While contemporary Face Recognition (FR) systems,\nutilizing deep Convolutional Neural Network (CNN)-based\napproaches, demonstrate robust performance across various\nposes, illumination, and facial expressions, they still face\nchallenges associated with aging. These systems experience\na significant decrease in accuracy exceeding 10% when con-\nfronted with substantial age disparities during evaluation\n[20].\nTo address this gap, this study is focused on child face\nrecognition, with a specific emphasis on verification ac-\ncuracy over time using a novel longitudinal dataset. The\nYoung Face Aging (YFA) database contains face images\nof children captured at 6-month intervals from 2016 to\nNovember 2023 for children from 3 to 18 years of age.\nBy leveraging this longitudinal dataset, our research aims to\nprovide a comprehensive evaluation of state-of-the-art face\nrecognition focused on the unique challenges in children.\nThis longitudinal approach enables us to study the per-\nformance impact of the changes in facial appearance that\noccur as children age. Furthermore, we split the YFA\ndatabase into different age groups to analyze the pattern of\naccuracy among different ages. Our objective is to discern\nwhether there exists a consistent trend in accuracy across\nall age groups, or if certain age groups exhibit a substantial\ndecline in accuracy compared to others. Our contributions\nare listed as follows.\n\u2022 We study the performance for increasing the time be-\ntween as an enrollment and consecutive verification\nsample over a 6-month time intervals, up to 8 years.\nChildren's ages range from 3 to 18 years, with 330 sub-\njects and an average of 6 collections for each subject.\nBy using this method, our main goal is to gain insights\ninto the performance and reliability of the enrollment\nand verification system over time, particularly in the\ncontext of age progression. Figure 1 shows an exam-\nple of the image quality of subjects over time.\n\u2022 Additionally, we have conducted a thorough analysis\nof the results based on age groups spanning two years\ne.g (3-5, 5.5-7 years). This detailed examination has\nenabled us to identify subtle patterns and trends in the\nsystem's ability to match identities across different age\nbrackets. By breaking down the data in this manner,\nwe have gained a more comprehensive understanding\nof the system's effectiveness in accurately verifying\nidentities across different stages of child development.\n\u2022 We evaluated the True Acceptance Rate (TAR) of the\nsystem for each age group using bootstrapping. This\nprocess allows us to generate upper and lower bounds\non the observed performance and better understand the\nsignificance of the difference when changes are ob-\nserved."}, {"title": "2. Related Work", "content": "Table 1 provides details of numerous studies in the field\nof face aging for children that have highlighted the detri-\nmental impact of large age intervals on the accuracy of FR\nsystems. These intervals, are typically measured over many\nyears and are often \"in the wild\" datasets and/or have a large\ntime gap between collections. There are several constrained\ndatasets where the time gap is more controlled. Most have\nshorter time period than our dataset ([3], [6], [15]). The\nmost similar dataset is ECLF [5] database which has an\naverage time span of 3.5 years with a 1-year gap between\ncollections with a maximum span of 6 years. The YFA\ndatabase used in this research has a collection time inter-\nval of 6 months over a maximum span of 8 years.\nBest-Rowden et al. [3], built a Newborn, Infants, and\nToddlers Longitudinal (NITL) database of facial images to\nexplore FR in children as they age. According to the study,\nthe accuracy of FR remained high within the same session\nbut decreased significantly across different sessions. This\nemphasizes the need for further research to improve cross-\nsession recognition accuracy for children. The study pro-\nvides a comprehensive evaluation of face matching using\nthe NITL database, exploring the possibility of FR for chil-\ndren as they age. The results suggest that current FR tech-\nnology may not be reliable enough for very young children,\nbut it could be feasible for those enrolled at 3 years of age\nor older. With a COTS face matcher, the research achieved\na TAR of 60.94% at FAR of 0.1% for an age gap between\n3-5 years.\nChandaliya et al. [5], research compiled a longitudinal\ndatabase of Indian children (ages 2 to 18, encompassing\nboth boys and girls) using with and without face masks. The\nfindings indicate a significant decline in the performance of\nfacial recognition systems due to aging when masks are uti-\nlized. The research utilized the Children Longitudinal Face\n(ECLF) dataset, comprising 26,258 facial images belonging\nto 7,473 subjects aged between 2 and 18 years. On average,\neach subject contributed 3 images, acquired over an average\ntime lapse of 3.35 years. The no-mask dataset achieved an\naverage identification accuracy with a 1-year time interval\nand a 1-6 year time gap across FaceNet, PFE, ArcFace, and\nCOTS models of 83.79% at 0.01% FAR.\nSrinivas et al. [16], observed a discernible bias when"}, {"title": "3. Methodology", "content": "The primary objective of this research is to develop and\nevaluate a longitudinal age enrollment and verification sys-\ntem using the YFA dataset. The methodology employed\ninvolves two main stages: enrollment and verification. En-\nrollment Stage: Any image in the dataset may be consid-\nered an enrollment stage, where subjects are categorized\ninto specific age brackets. Verification Stage: Following\nthe enrollment stage, all subsequent collections of the YFA\ndataset are utilized for verification purposes. These collec-\ntions are considered as verification samples, with the time\ninterval between collections increasing as the subject's age\nprogresses. This approach allows for the evaluation of the\nsystem's performance over time, considering the aging ef-\nfects on facial appearance."}, {"title": "3.1. Database Overview", "content": "The YFA database serves as the foundation for this re-\nsearch. The research team collaborates with the local el-\nementary, middle, and high schools to identify and enroll\nsubjects for voluntary participation, following an approved\nIRB protocol. Collections occur at 6-month intervals. Each\nyear, new subjects are added at ages 3-5 (i.e., pre-K and\nKindergarten students. Each collection contains facial im-\nages of subjects, along with their corresponding age. Fig-\nures 1 illustrate the age progression of individual subjects\nwithin the YFA database, showcasing the development from\n10-17 years of age, with intervals of 6 months. The database\ncontains 3831 samples from 330 subjects collected in a con-\ntrolled environment with a time-lapse of 6 months over 8\nyears. Figure 2 depicts the statistics of the YFA. Samples\nare captured from 3-18 year old children. Images are cap-\ntured using a DSLR camera with a resolution of 3648 by\n5472 pixels. The image acquisition is conducted under con-\nsistent indoor lighting conditions, encouraging neutral ex-\npressions, and minimizing variations in the subject's pose.\nManual annotation by human annotators was performed and\nextremely blurry images and challenging poses were ex-\ncluded from the database. Each subject is captured at least\ntwice during each session. Figure 3 illustrates the number\nof samples available at each age. This dataset exhibits the\nhighest number of collections for subjects aged 8 years and\nthe lowest number of samples for subjects aged 3.5 years.\nAges are approximate based on the school grade of enroll-\nment as some subjects declined to provide birthdate."}, {"title": "4. Face Detection and Recognition Models", "content": "MTCNN (Multi-Task Cascaded Convolutional Neural\nNetwork) face detection model, as referenced in [19] was\nemployed to accurately detect and align faces. Addition-\nally, we resize each cropped face to meet the requirements\nof the facial recognition matcher's input specifications at\n224 x 224 pixels. This establishes a consistent founda-\ntion for the comprehensive analysis and evaluation of our\nresearch.\nThe performance of the longitudinal age enrollment and\nverification system is assessed based on face-matching ac-\ncuracy across different time intervals. Bahmani et al. [2],\nintroduce the YFA dataset for analyzing the performance\nof FR systems over short age gaps in children. They\nuse multiple face-matching algorithms; Facenet-V1[14],\nFacenet-V2[14], VGGFace [12], VGGFace2 [4], ArcFace\n7], ArcFace-Focal [17] and MagFace [10]. The best per-\nformance was with MagFace which achieved 98.3% and\n94.9% TAR at 0.1% FAR over 6 and 36 months age gaps.\nBased on these results, we used MagFace as a FR model in\nthis study."}, {"title": "5. Experimental Setup", "content": "To facilitate analysis of the longitudinal aging factor, we\ncategorize the longitudinal age of subjects as enrollment\nand verification. Figure 2 details the available subjects of\nthe YFA dataset for experiments. Upon initial enrollment\nof a subject into the system, we determine their age based\non the enrollment date, given that the YFA database records\ndata at 6-month intervals, we increment the subject's age\nby 6 months with each subsequent data collection. Notably,\nthe youngest age recorded in the database is 3 years. Con-\nsequently, we designate all subjects at the age of 3 years as\nenrollment samples. Following a period of 6 months, when\nthe subject's age is 3.5 years, we classify them as verifica-\ntion samples for further analysis. This repeats for all images\nfrom that subject. In this systematic approach, each image\ncan be either an enrollment or verification image (with the\nexception of the first image captured for a child can only\nbe an enrollment image). Figure 3 provides the number of\nsamples available in each enrollment period. The largest\nnumber of subjects in the database are 8 years old and the\nlowest number of subjects is 3.5 years old."}, {"title": "6. Results & Discussion", "content": "We explore overall cross-age performance in the range\nof up to 8 years within the YFA database. Table 2 provides\na detailed depiction of the TAR computed for the MagFace\n[10] face matcher model across two FAR thresholds, specif-\nically at 0.1% and 0.01%. Specifically, we set a fixed thresh-\nold value of 0.45 at a FAR of 0.1% and 82.25%TAR at\n0.01% FAR with 0.56 threshold. In our further analysis, we\nkeep the 0.45 threshold at 0.1% FAR to calculate the TAR\nperformance of each subset of age-wise enrollment and ver-\nification. Figure 3 provides the statistics of available sam-\nples in each subset of ages. To evaluate the longitudinal\nperformance we compare the age of the subject during the\nfirst enrollment to the age of the subject for each subsequent\nverification. The YFA database collection period is 8 years\nso the maximum difference between enrollment and verifi-\ncation is 8 years (i.e This longitudinal approach allows for a\nnuanced understanding of how the recognition system per-\nforms over time, particularly in relation to the aging process\nof individuals.\nBy tracking the subject's ages over the 8-year collection\nperiod, we were able to observe trends in the system's per-\nformance, specifically focusing on the TAR across differ-\nent age groups and over increasing time between enrollment\nand verification. Figure 4 visually represents our findings.\nOur analysis reveals a decline in TAR, particularly beyond\nthe fourth year after enrollment across all age groups. For\ncertain age comparisons, e.g. age 13 compared to age 16,"}, {"title": "6.1. Enrollment and Verification Scenarios", "content": "Additional investigation was performed in the observed\ntrend of declining TAR to see if the underlying age of en-\nrollment has an impact. In other words, we performed fur-\nther analysis to determine if there is a difference between\na subject that enrolls at age 5 and verifies at age 10 versus\na subject that enrolls at age 10 and verifies at age 15, for\nexample. We created subsets of the database, with subjects\ncategorized into groups based on a 2-year age interval. This\nsubset approach allowed for a examination of potential age-\nrelated trends in the performance.\nThe distribution of subjects for each of the age groups\nis depicted in Figure 5. For the analysis, each group is\nmatched over multiple 2-year time intervals. For instance,\nsubjects enrolled between the ages of 3-5 years were com-\npared against every image collected from those subjects be-\ntween 6-month to 2 years after enrollment and similarly\nfrom (2.5-4) year time difference up to 8 years of time gap.\nThis methodology enabled tracking of performance trends\nacross various age groups at increasing time of verification\nafter enrollment"}, {"title": "6.2. Analysis for age groups", "content": "Table 3 further highlights the decline in the TAR as time\nafter enrollment increases. For less than 2 years from en-\nrollment, Age groups (3-5, 5.5-7, 7.5-9, 9.5-11) had a TAR\nof 97.8-98.9% and a TAR of 99.75 for age group (11.5-13).\nAfter 2.5 to 4 years, age groups (3-5, 5.5-7, 7.5-9, 9.5-11)\nobserved nearly 1-3% drop in TAR and (11.5-13) close to\n5% drop in TAR. After 4.5 to 6 years, all age groups ob-\nserved 10% drop in TAR. After 6 years from enrollment,\nthere was a subsequent sharp decline. Figure 6 visually rep-\nresents the trend on the drop of TAR across different age\ngroups. This observed pattern persists consistently across\nnearly all age groups. Through systematic TAR evalua-\ntion within each age group, we can analyze whether the\nobserved TAR decline is uniform across all age groups or\nif certain age groups experience more pronounced perfor-\nmance deterioration over time. We noticed that the enroll-\nment age groups (3-5) and (7.5-9) years have a larger drop\nin TAR compared to other age groups. For the enrollment\nage group (3-5) with a verification age gap of (0.5-2) years,\nthe TAR decreased from 97.8% to 63.1% for a verification\nage gap of (6.5-8) years. Similarly, for the enrollment age\ngroup (7.5-9) with a verification age gap of (0.5-2) years,\nthe TAR decreased from 98.3% to 65.6% for a verification\nage gap of (6.5-8) years. With age group (5.5-7) years, the\nTAR decreased from 97.9% to 80.2% for a verification age\ngap of (6.5-8) years. Noticed that age groups (3-5) and (7.5-\n9) years had a 20-23% drop in TAR after 6 years of a verifi-\ncation age gap whereas age group (5.5-7) had a 5% drop in\nTAR."}, {"title": "6.3. Confidence intervals based on bootstrapping for performance evaluation", "content": "Based on the findings in the previous section, we noticed\nthat subjects are not evenly distributed across the various\nage groups and time gaps. Confidence intervals were con-\nstructed using bootstrap resampling process to quantify the\nuncertainty surrounding key statistical estimates [1]. Boot-\nstrapping is a statistical resampling technique used to esti-\nmate the sampling distribution of a statistic by repeatedly\nsampling with replacement from the observed data. It al-\nlows for the assessment of variability and uncertainty in\na sample estimate without assuming a specific parametric\ndistribution. Figure 7 is a visual representation of the re-\nsampling distribution of data across different age groups.\nFor instance, a two-sided 95% confidence interval was com-\nputed using the bootstrap percentile method and represents\nthe TAR range in which the true parameter value is expected\nto lie with 95% probability. The lower bound of the confi-\ndence interval is the TAR value at the 2.5th percentile. Con-\nversely, the upper bound is the TAR value at the 97.5th per-\ncentile.\nTable 3 provides lower and upper bounds for each TAR.\nThis confidence interval estimation accounts for the vari-\nability inherent in the data and allows comparison of the\ntrends to support statistical inference and decision-making.\nFor instance, the enrollment age (3-5) with a verification\nage of (6.5-8) years consists of only 20 subjects. The 95%\nconfidence interval for a TAR range is from 60.2 to 66.1.\nThis analysis provided a better understanding of the plausi-\nble range of TAR values. With bootstrap resampling with\nvarious age groups, particularly focusing on the verification\nage gap of (6.5-8) years, we observed that the enrollment\ngroup aged (5.5-7) years did not experience as significant\nof a decline in TAR compared to other groups after 6 years\nof verification gap, TAR decreased from 85.9% to 80.2%\nuntil 8 years verification age gap. However, we found that\nthe enrollment age groups of (3-5) years and (7.5-9) years\nshowed lower TAR, particularly compared to the verifica-\ntion group of (4.5-6) years to (6.5-8) with 63.1% and 65.6%\nTAR respectively."}, {"title": "7. Conclusion and Future Work", "content": "In conclusion, the study's findings underscore the impor-\ntance of longitudinal assessments in evaluating the perfor-\nmance of face recognition systems, particularly in under-\nstanding how age-related factors impact their accuracy and\nreliability over time. Further research and refinement of al-\ngorithms may be necessary to address the observed decline\nin TAR and enhance the robustness of FR technology across\ndiverse age demographics.\nWe performed an evaluation of the MagFace facial\nrecognition algorithm for the YFA database, encompass-\ning subjects aged 3 to 18 years, and up to 8 years be-\ntween enrollment and verification samples. Our compre-\nhensive analysis includes a breakdown of results based on\nage groups spanning two years. The average TAR in the\nvalidation group aged (0.5-2) years was 98.52%, whereas\nit decreased to 95.68% in the validation group aged (2.5-4)\nyears. We find a drop in accuracy after a 4-year age dif-\nference among subjects and a sharp decline after a 6-year\nage difference with the average drop in TAR from 87.24%\nto 71.32%. Our analysis, focusing on specific age groups,\nreveals a notable trend indicating a decrease in TAR over\ntime following enrollment. We observed the most substan-\ntial decline in accuracy among children aged 3-5 years old,\nwhere the TAR dropped to 63.1%. This decline occurred\nparticularly within a verification age gap of (6.5-8) years.\nConversely, the age group of (5.5-7) years old exhibited the\nhighest TAR 80.2%. Our examination further reveals that\nthe accuracy performance does not exhibit consistent trends\nwith increasing age within enrollment age groups. For in-\nstance, within the verification age group of (6.5-8) years\nfor children aged (3-5) years, the TAR dropped to 63.1%.\nHowever, for the age group of (5.5-7) years, the accuracy\nnotably increases to 80.2%. This trend reverses once more\nfor the (7.5-9) age group, with accuracy dropping to 65.6%.\nInterestingly, there is a slight uptick in accuracy observed\nin the subsequent age groups. These fluctuations under-\nscore the complexity of age-related dynamics in biometric\nverification accuracy and suggest the need for tailored ap-\nproaches to address variations across different age ranges.\nThese findings not only contribute to a deeper understand-\ning of facial recognition technology's for children and can\ninform its implementation. Moving forward, our research\nsets a foundation for continued exploration and refinement\nof FR systems to ensure their efficacy and fairness across\nall age demographics.\nThe research faces several limitations concerning its\ndatabase. Although the study encompasses children aged\n3 to 18 years, the distribution of subjects within this age\nrange is uneven, potentially impacting the generalizability\nof findings. While the collectors attempted to control var-\nious quality factors, variations in facial movement, angle,\nand facial expressions were present. All collections were\nperformed in a classroom environment with the lights on.\nHowever, there are still inconsistencies in lighting across\ncollections. Moreover, disparities in subjects' appearance,\nsuch as some wearing glasses and caps, further complicate\nthe recognition process. The lack of demographic diver-\nsity within the database, particularly in terms of ethnicity,\nposes a significant limitation to the generalizability of the\nfindings. In this study, we use the MagFace face-matching\nalgorithm. Other face matchers or fine-tuning the existing\nalgorithm can impact the results. The study aims to assess\nchildren's facial recognition for critical applications, such\nas identifying missing or abducted children. However, the\nfindings are in a controlled environment and performance\nmay be lower in real-world scenarios due to factors like im-\nage quality variations, environmental conditions, and oper-\national constraints."}]}