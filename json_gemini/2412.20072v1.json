{"title": "Extract Information from Hybrid Long Documents Leveraging LLMs: A Framework and Dataset", "authors": ["Chongjian Yue", "Xinrun Xu", "Xiaojun Ma", "Lun Du", "Zhiming Ding", "Shi Han", "Dongmei Zhang", "Qi Zhang"], "abstract": "Large Language Models (LLMs) demonstrate exceptional performance in textual understanding and tabular reasoning tasks. However, their ability to comprehend and analyze hybrid text, containing textual and tabular data, remains unexplored. The hybrid text often appears in the form of hybrid long documents (HLDs), which far exceed the token limit of LLMs. Consequently, we apply an Automated Information Extraction framework (AIE) to enable LLMs to process the HLDs and carry out experiments to analyse four important aspects of information extraction from HLDs. Given the findings: 1) The effective way to select and summarize the useful part of a HLD. 2) An easy table serialization way is enough for LLMs to understand tables. 3) The naive AIE has adaptability in many complex scenarios. 4) The useful prompt engineering to enhance LLMs on HLDs. To address the issue of dataset scarcity in HLDs and support future work, we also propose the Financial Reports Numerical Extraction (FINE) dataset. The dataset and code are publicly available in the attachments.", "sections": [{"title": "I. INTRODUCTION", "content": "Large Language Models (LLMs) have demonstrated exceptional capabilities in understanding, analyzing and reasoning textual and tabular data independently, as evidenced by studies like [1]-[4]. However, their application to hybrid long documents (HLDs), which intricately weave together textual and tabular content, remains relatively unexplored [5]. This work addresses this gap by investigating the potential of LLMs for information extraction from HLDs, introducing an Automated Information Extraction framework called AIE.\nGiven the length constraints of LLMs, directly processing entire HLDs is impractical and simple truncation leads to significant information loss [6]-[9]. AIE tackles this challenge by splitting HLDs into manageable segments and leveraging LLMs to extract relevant information from these segments. Our research delves into four key challenges associated with HLD information extraction: C1. Effective Selection and Summarization of Relevant Segments: With keyword-related information scattered across segments, effectively identifying and summarizing relevant content is crucial. We compare the \"Refine\u201d and \u201cMap-Reduce\u201d summarization strategies, exploring the trade-off between accuracy and efficiency."}, {"title": "II. AIE FRAMEWORK", "content": "To enable LLMs to process HLDs, we propose the Automated Information Extraction (AIE) framework, consisting of four modules: Segmentation, Retrieval, Summarization, and Extraction (Figure 1). AIE segments documents, retrieves keyword-relevant segments based on embedding similarity, summarizes these segments and finally extracts the target value.\nThe Segmentation Module splits HLDs into manageable segments for LLMs. It involves Serialization, converting tables into text using the simple yet effective PLAIN method; Split, dividing overlong elements into smaller sub-elements to avoid information loss; and Merge, concatenating adjacent small elements to maintain semantic relationships.\nThe Retrieval Module employs embedding-based retrieval [10] to avoid processing all segments [11], [12]. It calculates the similarity between each segment and the keyword using the Sentence-Transformer model [13] and retrieves the top-ranked segments.\nThe Summarization Module uses LLMs to generate a concise summary from the retrieved segments, capturing relevant information related to the keyword. We employ the Refine Strategy, which iteratively updates an evolving summary with information from each segment.\nFinally, the Extraction Module extracts the precise numerical value from the generated summary using LLMs and a tailored Extraction Prompt.\nWe utilize three key prompt engineering techniques to enhance AIE's performance: Numerical Precision Enhancement ensures accurate numerical extraction, crucial for financial analysis, using Direct and Shot-Precision methods; Keyword Completion improves IE accuracy by completing incomplete user-provided keywords using document metadata; and Few-Shot Learning guides LLMs to understand the task effectively through a single, well-designed shot."}, {"title": "III. DATASET AND EVALUATION METRICS", "content": "To evaluate LLMs' capacity for HLD comprehension, we conduct experiments using three datasets: FINE: A new dataset with financial KPIs extracted from SEC's EDGAR (Table I). WIKIR [14]: Extracts key-value pairs from Wikipedia pages and Wikidata. MPP [15]: Extracts chemical material properties from scientific papers.\nFINE utilizes the Relative Error Tolerance Accuracy (RETA) metric due to varying numerical precision in financial reports. RETA considers predictions correct if their relative error is within a specified threshold (e.g., RETA X% means predictions with a relative error of no more than X% are considered correct) By setting different RETA levels, we can assess the model's performance according to various practical requirements and gain a comprehensive understanding of its capabilities in IE from financial reports. WIKIR and MPP use Accuracy (Acc) as their ground truth values don't exhibit precision variations."}, {"title": "IV. EXPERIMENT", "content": "We compare our proposed Automated Information Extraction (AIE) framework with a naive LLM-based approach\nAs shown in Figure 4, AIE consistently demonstrates superior performance in handling keyword ambiguity across all RETA levels. AIE achieves a 22.52% lower average RPD for the \u201cRevenue\" pair and a 37.94% lower average RPD for the \"Total Equity\" pair compared to the naive method. This highlights AIE's effectiveness in disambiguating concepts within HLDs.\nTo enable LLMs to process tables, we evaluate four serialization methods: PLAIN, CSV, XML, and HTML. While XML and HTML retain hierarchical table structure using tags, they increase token count and potential table fragmentation. Table II shows that PLAIN and CSV, which prioritize conciseness, outperform XML and HTML in accuracy. This suggests that preserving complete semantic information without excessive structural details is crucial for effective LLM-based table understanding.\nWe analyze the impact of retrieved segment quantity (R@n) on accuracy (Table III). R@3 achieves the highest accuracy across all RETA levels. While retrieving more segments initially improves accuracy (R@1 to R@3), exceeding this threshold leads to a decline, likely due to the introduction of noise or irrelevant information.\nWe compare two common summarization strategies for handling multiple retrieved segments: Refine (iteratively updating a single summary, Figure 1) and Map-Reduce (parallel segment summarization followed by merging, Figure 5). As shown in Table IV, Refine consistently achieves higher accuracy across all RETA levels. However, Map-Reduce offers faster processing due to its parallel nature. Therefore, the choice between these strategies depends on the specific application's requirements, prioritizing either accuracy or efficiency.\nTo improve LLM extraction of precise numerical values, we designed and evaluated six prompt variations (TD-O to TD-RSP), incorporating precision requirements and input-output examples. TD-RSP, combining precision requirements and a precision-inclusive example, consistently achieved the highest accuracy across all fine-grained RETA levels (Table V). Conversely, poorly designed prompts (TD-R, TD-S, TD-RS) negatively impacted accuracy compared to a baseline prompt (TD-O), highlighting the importance of careful prompt engineering for numerical precision.\nWe investigated the impact of keyword completion on LLM performance by evaluating four settings: K (keyword only), K_C (keyword + company), K_T (keyword + time), and K_T_C (keyword + time + company). Table VI clearly shows that providing additional context through company and time information significantly improves accuracy. K_T_C, leveraging the full context, achieves the highest accuracy across all RETA levels, emphasizing the importance of comprehensive keyword completion for effective information extraction.\nFew-shot learning is an important ability of LLMs. To investigate the impact of the number of shots on AIE's performance, we experimented with different numbers of shots, ranging from 0 to 3. As shown in Table VII, the 1-shot setting achieves the highest accuracy across all RETA levels. The performance of 2-shot and 3-shot settings is slightly lower than that of the 1-shot setting but still better than the O-shot setting. This indicates that a single well-designed example can effectively guide LLMs to generate more accurate responses. However, the slight decrease in performance with additional examples could be attributed to the increased complexity of the input or potential inconsistencies among multiple examples, which may confuse the model rather than provide more guidance."}, {"title": "V. RELATED WORK", "content": "Early Information Extraction (IE) relied heavily on rule-based approaches, often targeting specific domains or focusing solely on tables [16], thus missing crucial contextual information. Recent machine learning advancements introduced models like bidirectional RNNs for table understanding and BERT for text processing [17]\u2013[19]. However, QA-focused approaches like FinQA [20], TAT-QA [21], and MULTIHIERTT [22] only analyze specific sections within HLDs."}, {"title": "VI. CONCLUSION", "content": "To enable information extraction from Hybrid Long Documents (HLDs) using LLMs, we propose the Automated Information Extraction (AIE) framework. AIE comprises four modules: Segmentation, Retrieval, Summarization, and Extraction. We introduce Financial Reports Numerical Extraction (FINE), a dataset constructed from financial reports, to analyze AIE's effectiveness. Extensive experiments on FINE demonstrate the impact of each module and showcase AIE's superior performance compared to baseline methods. Furthermore, we validate AIE's strong performance across diverse domains, including scientific papers and Wikipedia, confirming its generalizability and effectiveness in HLD information extraction."}]}