{"title": "Nuance Matters: Probing Epistemic Consistency in Causal Reasoning", "authors": ["Shaobo Cui", "Junyou Li", "Luca Mouchel", "Yiyang Feng", "Boi Faltings"], "abstract": "Previous research on causal reasoning often overlooks the subtleties crucial to understanding causal reasoning. To address this gap, our study introduces the concept of causal epistemic consistency, which focuses on the self-consistency of Large Language Models (LLMs) in differentiating intermediates with nuanced differences in causal reasoning. We propose a suite of novel metrics - intensity ranking concordance, cross-group position agreement, and intra-group clustering - to evaluate LLMs on this front. Through extensive empirical studies on 21 high-profile LLMs, including GPT-4, Claude3, and LLaMA3-70B, we have favoring evidence that current models struggle to maintain epistemic consistency in identifying the polarity and intensity of intermediates in causal reasoning. Additionally, we explore the potential of using internal token probabilities as an auxiliary tool to maintain causal epistemic consistency. In summary, our study bridges a critical gap in Al research by investigating the self-consistency over fine-grained intermediates involved in causal reasoning.", "sections": [{"title": "1 Introduction", "content": "Previous studies in causal reasoning have primarily focused on discovering or determining the existence of a causal relationship between two variables (Roemmele, Bejan, and Gordon 2011; Cui et al. 2024c). However, these causal relationships are not always absolute. They can be heavily influenced by additional intermediate factors, which may vary in both polarity and intensity (Fitzgerald and Howcroft 1998; Bauman et al. 2002). The polarity of these intermediates indicates whether they support or defeat (oppose) the original causal relationship, while their intensity determines the strength of this supporting or defeating influence.\nForming fine-grained differentiation is essential for precise causal modeling (Iwasaki and Simon 1994); however, it is insufficient for LLMs to merely generate these intermediates. It is as equally important to ensure that these intermediates are reliable and credible (Shi et al. 2023). One method to verify this is through assessing the consistency of LLMs' perception of the intermediates. We posit that if LLMs can correctly differentiate their generated intermediates based on varying polarities and intensities, these intermediates are self-consistent and thus, more reliable for making predictions and decisions. Drawing from this insight, our study proposes the concept of \u201ccausal epistemic consistency\u201d:\nDefinition 1 (Causal epistemic consistency) Causal epistemic consistency refers to an LLM's ability to maintain self-consistency in differentiating its generated intermediates in three aspects: (i) discerning intensity: accurately assessing the intensity nuance in their causal impact. (ii) differentiating polarity: effectively distinguishing between supporting and defeating intermediates, and (iii) forming cohesive clusters: creating well-separated clusters of intermediates based on their polarity and intensity.\nTo quantify LLMs' ability to maintain causal epistemic consistency in the aforementioned aspects, we introduce a suite of novel metrics. These metrics include (i) Intensity ranking concordance, which measures the models' self-"}, {"title": "2 Task Definition", "content": ""}, {"title": "2.1 Problem Formulations", "content": "Causal epistemic consistency measures an LLM's self-consistency between generating fine-grained intermediates and subsequently ranking those fine-grained intermediates. Specifically, in the generation phase, for a defeasible cause-effect pair (C,E), an LLM is tasked with generating an ordered sequence I of fine-grained intermediates, consisting of a subsequence D = (I1, I2,\u2026\u2026\u2026,Im) as the defeater group and a subsequence A = (Im+1, Im+2,\u2026\u2026,Im+n) as the supporter group. Each individual intermediate changes the causal strength of (C,E) differently. Specifically, the causal influence of these intermediates is expected in the following order:\n$CS(E|C \\oplus I_1) \\leq\u2026\\leq CS(E|C \\oplus I_m)$\n$<CS(E|C)$\n$CS(E|C \\oplus I_{m+1}) \\leq\u2026\\leq CS(E|C \\oplus I_{m+n})$ (1)\nwhere CS(EC) measures the causal strength (Luo et al. 2016; Zhang et al. 2022), quantifying the likelihood that the cause event C would lead to the occurrence of the effect event E. 1 The \\oplus means the combination of two events. The gradient bar illustrates the varying degrees of intensity of the defeating intermediates, while the gradient bar represents the supporting intermediates. The color gradient darkens as the intensity increases, with a darker shades indicating a stronger influence, whether supporting or defeating. Subsequently, in the ranking phase, the same LLM is asked again to rank its own generated intermediates I, obtaining I', a permutation of I. Ideally, an LLM with perfect causal epistemic consistency should have I = I', satisfying the requirements of intensity, polarity, and clustering perfectly."}, {"title": "2.2 Key Research Questions", "content": "The study addresses three primary research questions:\n\u2022 RQ I: How can we comprehensively measure the ability of LLMs to maintain the epistemic consistency over fine-grained intermediates in causal reasoning?\n\u2022 RQ II: How well do current LLMs, with varying architectures and scales, maintain their causal epistemic consistency?\n\u2022 RQ III: Are there any alternatives to prompting for LLMs to maintain causal epistemic consistency?\nTo answer RQ I, we propose novel metrics introduced in Section 3, which not only serve our specific study but also have broader applications across various tasks. In Section 4, we dive into the performance of twenty-one leading LLMs, exploring their ability to maintain epistemic consistency, thereby addressing RQ II. Lastly, in Section 5, we assess whether internal token probability offers a more effective or perhaps less effective\u2014alternative to prompting for preserving causal epistemic consistency in LLMs, answering RQ III."}, {"title": "3 Metrics for Measuring Causal Epistemic Consistency", "content": "To evaluate the causal epistemic consistency of LLMs from the aspects of intensity, polarity, and clustering, we propose three types of automatic metrics: intensity ranking concordance, cross-group position agreement, and intra-group clustering. A graphical illustration of these metrics is shown in Figure 2. The mathematical notations below are consistent with Section 2.1."}, {"title": "3.1 Intensity: Intensity Ranking Concordance", "content": "To assess the concordance between the order from the generation phase and the order from the ranking phase of these fine-grained intermediates, we leverage the Kendall Tau distance (Kendall 1938). This metric quantifies the similarity between two orders by counting the number of pairwise agreements and disagreements. For a sequence I of LLM-generated intermediates and its permutation I' ranked by the same LLM, a pair of elements from I is called concordant if they appear in the same order in both I and I'. Conversely, the pair is called discordant if their order is reversed in I' compared to I. The Kendall Tau \\tau is calculated as:\n$\\tau=\\frac{(\\text{# concordant pairs}) \u2013 (\\text{# discordant pairs})}{k(k-1)/2}$ (2)\nwhere k is the number of elements in the list, and k(k-1)/2 is the total number of pairs. The metric ranges from -1 to 1, where 1 indicates that these two lists are identical; -1 indicates completely reversed rankings; and values close to 0 indicate no association between the two lists. For our task, we have three intensity ranking concordance metrics: \u0442-\u0410, \u0442-D, and T-all, which evaluate the intensity ranking concordance within the supporter group, the defeater group, and the entire sequence of intermediates, respectively."}, {"title": "3.2 Polarity: Cross-Group Position (CGP)", "content": "To assess the relative positioning of elements between these two polarities\u2014the defeater group D and the supporter group A\u2014we propose the Cross-Group Position (CGP) metric. This metric penalizes instances where elements from A are ranked lower than those from D 2. Specifically, CGP is defined as:\n$CGP(\\mathcal{I}', A, D) = 1 \u2013 \\frac{\\Sigma_{a \\in A} \\Sigma_{d \\in D} 1[index(a)<index(d)]}{\\|A\\| \\times \\|D\\|}$ (3)\nwhere index(x) denotes the index of element x in the ranked sequence I'. 1[.] denotes the indicator function that is set to 1 if the condition is true and 0 otherwise. CGP measures how often elements from A precede the elements of D in the ranked sequence I'. It is normalized to the range [0, 1] by dividing with the maximum possible violations, i.e., |A\u00d7 D|. Higher values indicate better differentiation between groups A and D."}, {"title": "3.3 Clustering: Intra-Group Clustering (IGC)", "content": "In this subsection, we introduce Intra-Group Clustering (IGC), a metric for LLMs' causal epistemic consistency by assessing the clustering degree of supporting and defeating intermediates. The intuition behind IGC is that all defeaters and all supporters should form cohesive clusters, with a minimal number of polarity changes (from supporting to defeating, or vice versa) when iterating the sequence.\nClustering Distance Based on Polarity Change. Given the LLM-ranked intermediates I', we define Li to indicate which polarity (supporter A or defeater D) each intermediate Ii belongs to. Li is represented as a binary polarity that either Li = A or Li = D. d(i, j) is the sequence clustering distance between Ii and Ij, calculated as follows:\n$d(i, j) = \\sum_{k=i}^{j-1} 1[L_k \\neq L_{k+1} \\land L_{k+1} \\neq L_i]$ (4)\nwhere i < j. The distance is based on the number of polarity changes, excluding reversions to the initial polarity.\nIGC: A Measure of Clustering Quality in Sequence. With the distance based on polarity change, we use the silhouette score (Rousseeuw 1987; Shahapure and Nicholas 2020) to measure how similar an element is to its own cluster compared to other clusters in sequence:\n$s(i) = \\frac{d_{nc}(i) - d_{ic}(i)}{max(d_{ic}(i), d_{nc}(i))}$ (5)\nwhere dic(i) and dnc(i) are the intra-cluster distance and nearest cluster distance for each intermediate Ii.\n1. The intra-cluster distance dic(i) captures the mean distance between Ii and all other intermediates belonging to the same group, reflecting internal cohesion. It is calculated as:\n$d_{ic}(i) = \\frac{1}{\\|L_i\\|-1} \\sum_{L_j=L_i, j \\neq i} d(i, j).$ (6)"}, {"title": "4 Causal Epistemic Consistency of LLMS", "content": ""}, {"title": "4.1 Experimental Setup", "content": "Foundational Dataset. To ensure the defeasibility of causal pairs, allowing models to generate intermediates with varying polarity and intensity, we utilize the test dataset of \u03b4-CAUSAL (Cui et al. 2024c) as our foundational dataset, which comprises 1,970 defeasible cause-effect pairs.\nThree-Phase Assessment for LLMs' Causal Epistemic Consistency. There are three main phases in our experiments: (i) Intermediate generation: We provide LLMs with a single cause-effect pair and two preliminary intermediates: one supporting and one defeating. For each supporter and defeater, we instruct the LLMs to generate two weaker and two stronger intermediates. As a result, we compile a total of 10 intermediates as sequence I, divided into two subsequences: subsequence D comprised of m = 5 intermediates that challenge the cause-effect relationship with differing intensities; and subsequence A consisting of n = 5 supporting intermediates that reinforce the cause-effect pair, also with varying intensities. The prompt for generating these fine-grained intermediates is presented in Figure 7; (ii) Intermediate ranking: From these generated intermediates, we use the same LLM to rank the intermediates to identify their polarities (supporting or defeating) and intensity. The"}, {"title": "4.2 Experimental Results", "content": "Table 1 presents a quantitative comparison of different models on causal epistemic consistency.\n\u2022 Closed-source models generally outperform open-source models: For instance, GPT-4o achieves a T-all score of 0.632, a CGP score of 0.962, and an IGC score of 0.973, whereas LLaMA3-70B, the best-performing open-source model, only achieves a 7-all score of 0.586, a CGP score of 0.887, and an IGC score of 0.923.\n\u2022 Maintaining consistency in intensity is more challenging than achieving consistency in polarity and clustering: The patterns across different metrics are consistent among different models, suggesting that while LLMs can effectively maintain consistency over differentiating between supporting and defeating intermediates and clustering intermediates of the same polarity together, they find it more challenging to maintain consistent intensity rankings. Namely, achieving consistency over the nuances of causal intensity remains difficult."}, {"title": "4.3 Does a Larger Model Scale Mean Better Causal Epistemic Consistency?", "content": "Previous works (Kaplan et al. 2020; Hoffmann et al. 2024) have shown that with the increase in model scale, the improvement in performance follows a power-law relationship. However, the effectiveness of 'just scaling' for general causal understanding, especially in the context of causality, has become a subject of intense debate (Ze\u010devi\u0107 et al. 2023). Inspired by this question, we investigate whether increasing the model scale improves the causal epistemic consistency of LLMs. Since this model scale study is only possible for models available in multiple sizes, we conduct experiments with: (i) Gemma at sizes of 2B and 7B; (ii) LLaMA2 at sizes of 7B, 13B, and 70B; (iii) Phi-3 at sizes of 3.8B, 7B, and 14B; and (iv) LLaMA3 at sizes of 8B and 70B. The experimental results are presented in Figure 3. From these results, we clearly observe that an increase in model size generally enhances causal epistemic consistency. For instance, LLaMA2 and LLaMA3 demonstrate significant improvements at larger scales, particularly at 70B, where the causal epistemic consistency scores are notably higher compared to their smaller-scale counterparts."}, {"title": "4.4 Visualization of Causal Epistemic Consistency", "content": "We plot the causal epistemic consistency matrices of LLaMA3-70B and GPT-4o in Figure 4. In these matrices, the x-axis from left to right and the y-axis from top to bottom correspond to \u25a15 \u25a14 \u25a13 \u25a1-2 \u25a1-1 +1 \u25cb2 \u25cb3 \u25cb+4 \u25cb+5, where the square symbol represents defeaters while the circle symbol represents supporters. The numbers inside the symbols indicate the supporting or defeating intensity, with larger absolute values signifying stronger intensity (i.e., \u25a15 is the strongest defeater and \u25cb+5 is the strongest supporter). These matrices visualize how well the models maintain causal epistemic consistency by comparing the labels of intermediates of the generation phase with the predicted labels in the ranking phase.\nThe confusion matrices of other models are presented in Appendix D. From the results of the best closed-source and open-source models, we have the following observations:\n\u2022 Diagonal Dominance: Higher values along the diagonal indicate better causal epistemic consistency. This dominance shows that the model often maintains consistency in both polarity and intensity by correctly matching the labels of intermediates from the generation phase to the ranking phase.\n\u2022 Off-Diagonal Elements: These off-diagonal elements"}, {"title": "5 Beyond Prompting: Leveraging Internal Token Probability", "content": "This section explores using internal token probability as an alternative to the prompting method in Section 4 for maintaining causal epistemic consistency."}, {"title": "5.1 Internal Token Probability", "content": "Internal token probability has proven to be a reliable indicator for sequence correlation estimation (Malinin and Gales 2021; Farquhar et al. 2024; Cui et al. 2024c). For each cause-effect pair (C, E) and any supporting or defeating intermediate Zj, we utilize the token probabilities p to estimate the causal strength CS(E|C \u2295 Ij) in Section 2.1:\n$CS(E|C \\oplus I_j) = \\prod_i p(E_i |C \\oplus I_j, w, E_{<i})$ (9)\nwhere Ei is the ith token of E and E<i is the first i \u2212 1 tokens of E. p(Ei|C\u2295 Ij, w, E<i) is the internal (conditional) token probability. The conjunction word w connects the combination of the cause and the intermediate to the effect, and explicitly indicates the causation such as \"because\" and \"therefore\"."}, {"title": "5.2 Experimental Setup", "content": "Models and Datasets. As closed-source models often do not provide a logprob API usage 3, our investigation resorts to open-source LLMs including Gemma (2B and 7B) (Mesnard et al. 2024), LLaMA2 (7B, 13B, and 70B) (Touvron et al. 2023), Phi-3 (3.8B, 7B, and 14B), and LLaMA3 (8B and 70B). We use the same foundation dataset described in Section 4.1.\nThree-Phase Assessment. The experiment in this section involves three phases: (i) Intermediate generation: This phase involves generating a sequence of intermediates, I, following the same procedure described in Section 4.1; (ii) Intermediate ranking based on conditional token probability: In this phase, we calculate the causal strength based on the conditional token probability using {CS(E|C\u2295Ij)|Ij \u2208 I}. (iii) Evaluation: We assess the models' causal epistemic consistency using rankings from the generation phase and conditional probability values, based on the proposed metrics in Section 3.\nConjunction Word Choices. We study multiple conjunction words, including (i) coordinating conjunctions (Grammarly 2024): \u201cso\"; (ii) subordinate conjunctions (Traffis 2020): \"because\", \"since\u201d, and \u201cas\"; and (iii) conjunctive adverbs (Ellis 2023): \"therefore\", \"thus\", and \"hence\u201d."}, {"title": "5.3 Results and Discussion", "content": "We analyze the results from two aspects: (i) the impact of conjunction words on models' causal epistemic consistency; and (ii) the efficacy of internal token probability against the prompting strategy.\nComparison of Different Conjunction Words. We present the impact of different conjunction words on models' causal epistemic consistency, with distinctions highlighted by varying colors on the x-axis labels in Figure 5. A consistent trend is observed across different models and causal epistemic consistency metrics. Specifically, coordinating conjunctions (\u201cso\u201d) and conjunctive adverbs (\"therefore\", \"thus\", \"hence\") yield better results, while subordinate conjunctions (\u201cbecause\u201d, \u201csince\u201d, \u201cas\u201d) underperform. We posit that placing subordinate conjunctions at the beginning of sentences aligns poorly with the natural language patterns seen by LLMs, potentially degrading performance.\nComparison with Prompting. In Figure 6, we compare the efficacy of internal conditional token probability for evaluating causal epistemic consistency with that of prompting-based strategies. We present the relative difference in the three most representative metrics (7-all, CGP, and IGC) for various models (Gemma, LLaMA2, Phi-3, and LLaMA3) when compared against the prompting aspect. Each subplot corresponds to one of the metrics, showing the differences for each model. Each model is represented by a box plot, calculated from differences given various conjunctions (\u201cso\", \"because\", \"since\", \"as\u201d, \u201ctherefore\", \u201cthus\u201d, and \u201chence\u201d). Notably, the Gemma model and medium-sized LLaMA2 models (7B, 13B) exhibit enhanced"}, {"title": "6 Related Work", "content": "LLMs and Causality. The investigation of LLMs in understanding and generating causal relations has garnered increasing attention. Previous studies often criticize LLMs for their propensity to inaccurately identify and comprehend the complex causal patterns among these facts (Jin et al. 2024; Li et al. 2024; Ze\u010devi\u0107 et al. 2023; Cui et al. 2024b). Our study further contributes to this discourse by evaluating LLMs' self-consistency in reasoning about fine-grained intermediates in causality and by providing metrics and empirical evidence for LLMs' causal epistemic consistency.\nDefeasibility in Causal Reasoning. Our study of fine-grained intermediates in causality extends the research initiated by \u03b4-CAUSAL (Cui et al. 2024c), which introduced the concepts of defeaters and supporters in causal analysis. While \u03b4-CAUSAL provided a foundational framework for understanding causal defeasibility, it did not delve into the granularity necessary for nuanced causal reasoning. Our research advances this field by moving beyond the binary classification of intermediates as simply supporting or opposing. We refine the categorization of intermediates by considering both their polarity stance (supporting or opposing) and the intensity of their influence. This nuanced approach enhances the precision of causal analysis, enabling more reliable predictions in complex AI systems.\nHallucination of LLMs. LLMs suffer from generating nonsensical, fallacious, and undesirable content, known as hallucinations (Huang et al. 2023; Mouchel et al. 2024; Cui et al. 2024a). The most pertinent hallucination to causal epistemic consistency is the self-contradictory hallucination (M\u00fcndler et al. 2024), which means that LLMs generate two contradictory sentences given the same context. Specifically, our study on causal epistemic consistency investigates whether the causal intermediates generated by an LLM at various intensities contradict the ones ranked by the same LLM, similar to self-contradictory hallucinations. However, our study is distinctive in that we focus on the discrepancies between the causal intermediate generation and differentiating behaviors of LLMs, rather than the inconsistencies within the generated text. Additionally, our task focuses on self-consistency from a causal perspective, including the polarity (either supporting or defeating) and the intensity of these nuanced intermediates."}, {"title": "7 Conclusion", "content": "In conclusion, this study introduces causal epistemic consistency as a crucial framework for assessing the self-consistency of LLMs in distinguishing fine-grained causal intermediates. Supported by a novel suite of evaluation metrics, our comprehensive empirical analysis of 21 LLMs reveals significant limitations in their ability to maintain this consistency. This research addresses a critical gap in the understanding of complex causal reasoning and lays the foundation for the development of more self-consistent models capable of handling intricate causal relationships."}, {"title": "A Causal Conjunctions", "content": "In the context of causal epistemic consistency, the choice of conjunction words can significantly influence the interpretation of cause-effect relationships. Conjunctions serve as linguistic bridges that connect causes and effects, helping to clarify the nature and strength of these relationships. This section details the types of conjunctions used in our experiments and their implications for causal reasoning. Conjunctions that indicate causation can be broadly categorized into three types:\n1. Coordinating conjunctions: These conjunctions are words that connect two or more clauses of the same grammatical types (Grammarly 2024). \u201cFor\" and \"so\" are noteworthy because they usually indicate a causal relationship between two clauses.\n2. Subordinating conjunctions: This type of conjunction links a dependent clause to an independent clause (Traffis 2020). \"Because\", \"since\u201d, and \u201cas\u201d signify a causal relationship that the dependent clause is the cause of the independent clause.\n3. Conjunctive adverbs: These adverbs or adverb phrases connect two independent clauses by indicating their relationship (Ellis 2023). \"Therefore\", \"thus\", and \"hence\" are common adverbs that indicate a causal relationship.\nThe typical usages of these conjunctions are presented in Table 2."}, {"title": "B Experimental Setup", "content": ""}, {"title": "B.1 Configurations for Computing Infrastructure", "content": "The computing infrastructure of our experiments is as follows: the CPU model is an AMD EPYC 7543 32-Core processor. The GPU model is NVIDIA A100-SXM4-80GB. The total memory size is 503GB. The operating system is Ubuntu 20.04.6 LTS (Focal Fossa). The relevant libraries can be found in the requirements.txt file of our attached code supplementary file. We list the most essential packages in Table 3."}, {"title": "B.2 Prompt Design of LLMs", "content": "Generation. Directly prompting models to generate 10 arguments-five defeaters followed by five supporters has proven challenging and frequently results in unsatisfactory outputs, requiring multiple attempts for the same cause-effect pairs. To address this, we generate supporters and defeaters in a pairwise manner. This involves using the original defeater and supporter from the data and prompting the model four times for each cause-effect pair. The prompts are structured as follows:"}, {"title": "B.3 Conditional Probability Estimation", "content": ""}, {"title": "C Further Discussion on Proposed Metrics", "content": "In this section, we first present more discussion for the novel intra-clustering metrics in Appendix C.1, which covers the implication of the polarity changes and more case studies. Additionally, to better understand the difference between these proposed metrics, we explain these metrics with examples in Appendix C.2."}, {"title": "C.1 Intra-Group Clustering", "content": "Implication of Polarity Changes. Polarity changes in a sequence often indicate transitions between different states, representing cluster changes. By quantifying these polarity changes as distances, IGC accurately captures these cluster changes. Namely, in the context of sequence clustering, counting polarity changes shifts the focus to transitions rather than mere index differences. For example, in a sequence of customer interactions, a transition from browsing items to adding to the shopping cart has a greater impact on cluster formulation.\nBesides, polarity change provides an intuitive measure for evaluating the quality of sequence clustering. A sequence with fewer internal polarity changes is more cohesive, as there are no interruptions within different snippets of the sequences. Conversely, frequent polarity changes suggest that the sequences are more intertwined, indicating that the clusters are not distinctly separated but rather mixed together. It reflects overlapping or intertwined behavioral patterns of these snippets with the sequence.\nIn summary, with polarity changes, we can better understand the clustering quality, leading to more meaningful insights from the sequence data."}, {"title": "D More Results", "content": ""}, {"title": "D.1 Visualizations of Causal Epistemic Consistency of All Models", "content": "In this subsection, we present the visualizations of causal epistemic consistency of all the studied LLMs in Figure 9. Each subfigure within the figure represents a specific model, showing how each LLMs performs regarding causal epistemic consistency. The result indicates that larger models tend to exhibit more stable and consistent differentiation of fine-grained intermediates."}, {"title": "D.2 More Results with Conjunction Words", "content": "We present the full results of LLMs with different conjunction words in Table 5."}]}