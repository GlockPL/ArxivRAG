{"title": "LAMD: Context-driven Android Malware Detection and Classification with LLMs", "authors": ["Xingzhi Qian", "Xinran Zheng", "Yiling He", "Shuo Yang", "Lorenzo Cavallaro"], "abstract": "The rapid growth of mobile applications has escalated Android malware threats. Although there are numerous detection methods, they often struggle with evolving attacks, dataset biases, and limited explainability. Large Language Models (LLMs) offer a promising alternative with their zero-shot inference and reasoning capabilities. However, applying LLMs to Android malware detection presents two key challenges: (1) the extensive support code in Android applications, often spanning thousands of classes, exceeds LLMs' context limits and obscures malicious behavior within benign functionality; (2) the structural complexity and interdependencies of Android applications surpass LLMs' sequence-based reasoning, fragmenting code analysis and hindering malicious intent inference. To address these challenges, we propose LAMD, a practical context-driven framework to enable LLM-based Android malware detection. LAMD integrates key context extraction to isolate security-critical code regions and construct program structures, then applies tier-wise code reasoning to analyze application behavior progressively, from low-level instructions to high-level semantics, providing final prediction and explanation. A well-designed factual consistency verification mechanism is equipped to mitigate LLM hallucinations from the first tier. Evaluation in real-world settings demonstrates LAMD's effectiveness over conventional detectors, establishing a feasible basis for LLM-driven malware analysis in dynamic threat landscapes.", "sections": [{"title": "1. Introduction", "content": "The rapid expansion of the Android ecosystem has heightened security risks, with malware posing serious threats to user privacy, financial security, and sensitive data. Over the past decade, researchers have developed various Android malware detection techniques, yet these methods face persistent challenges in real-world scenarios. Firstly, the open and evolving nature of Android complicates the detection of adaptive malware [1], [2]. Reliance on specific datasets introduces biases, such as ambiguous timestamps and randomly selected samples [3], which further compromise model reliability. Additionally, conventional detectors often lack explainability that fail to offer clear, human-readable insights into malicious behaviors.\nLarge Language Models (LLMs) offer a promising paradigm shift in malware detection, differing fundamentally from conventional detectors. They achieve zero-shot inference relying on vast pre-trained knowledge instead of specifically labelled datasets [4], [5], allowing them to handle the evolving malware and potential training bias. Furthermore, to bridge the gap of explainability, the advanced generative capabilities of LLMs present an opportunity by providing human-readable comprehension, thereby enhancing malware analysis from both an accuracy and interpretability perspective.\nHowever, despite the potential, LLMs are not omnipotent. Two primary challenges hinder their effectiveness in Android malware detection: (1) Excessive support codes in Android applications: Android malware often comprises"}, {"title": "2. Related Work", "content": "This section reviews conventional Android malware detection, their real-world limitations, and recent advances in LLM-powered Android malware detection, situating our work in this evolving field."}, {"title": "2.1. Learning-based Android Malware Detection", "content": "Learning-based Android malware detectors leverage machine learning or deep learning models to automatically learn patterns from features extracted by static or dynamic analysis, enhancing scalability and adaptability [10]. Due to the high cost of dynamic analysis, most models rely on static feature extraction through reverse engineering [11], [12]. Despite advancements, these models struggle with concept drift, where evolving malware variants degrade performance in real-world deployments [1], [2]. Current works try to mitigate it, some of them focus on exploring robust features [13], [14], [15], [16] and others leverage continual learning [3], [17], [18] or active learning [19], [20] to let models adapt to new distribution. However, these methods either target to specific feature space [13] or introduce high retraining overhead and the risk of label poisoning [21], [22]. An additional challenge is explainability, which is critical for security analysis. Existing methods primarily use feature attribution techniques, providing importance scores without generating human-readable behavioral analysis [23], [24]. To address these limitations, researchers are increasingly exploring LLM-based approaches, which leverage extensive external knowledge and reasoning capabilities to improve malware detection and analysis [25], [26]."}, {"title": "2.2. LLM-powered Malware Detection", "content": "LLMs are increasingly used in security tasks like code analysis [27], vulnerability detection [28], [29], and malware classification [30]. Unlike traditional learning-based models, LLMs offer zero-shot inference capabilities, enabling them to generalize beyond predefined training data and feature spaces [4], [5]. This adaptability leads researchers to explore LLMs for malware detection and analysis, demonstrating their potential in security tasks. However, most studies focus on relatively simple malware ecosystems, such as npm packages [31], PowerShell scripts [32], Linux binaries [30], and JavaScript-based threats [33].\nInitial attempts at LLM-based Android malware detection are limited. Walton et al. [34] proposed a hierarchical"}, {"title": "3. Methodology", "content": "This section outlines the core components of our framework, LAMD, and how they cooperate to detect and understand Android malware efficiently."}, {"title": "3.1. Overall Architecture", "content": "The LAMD framework is designed to extract essential functionalities and their contextual information, enabling LLMs to generate both detection and reasoning results. It consists of two key components: (1) Key Context Extraction and (2) Tier-wise Code Reasoning, detailed as follows:\nKey Context Extraction: This module identifies suspicious APIs as seed points and analyzes their control and data dependencies within the application. It provides a structured representation of key program behaviors by pruning the calling relationships of potentially malicious interactions.\nTier-wise Code Reasoning: To preserve contextual integrity while managing token limitations,"}, {"title": "3.2. Key Context Extraction", "content": "3.2.1. Suspicious API Collection. Malware exploits system vulnerabilities or API permissions to steal data, manipulate resources, or maintain persistence. Many attacks rely on sensitive API calls to implement malicious behaviors. We perform static analysis on APKs to extract suspicious APIs as key context to identify malware. Let $A = \\{a_1,a_2,..., a_n\\}$ be the set of all API calls in an APK. A subset $A_{sus} \\subset A$ is deemed suspicious if it interacts with sensitive components, executes malware-associated operations or exposes sensitive data. These APIs fall into two categories:\nSensitive data access APIs: Many apps handle sensitive data, but assessing developer trustworthiness is challenging. Monitoring APIs accessing such data is crucial. Smartphone OSs enforce permission-based access control, requiring declared permissions for some APIs, while others, like getPrimaryClip(), bypass enforcement. Therefore, an API $a_i$ falls into this category if it either: (1) requires explicit permissions for access control, or (2) grants direct access to sensitive user data without permission enforcement.\nSensitive data transmission APIs: Monitoring potential data exfiltration channels is critical, as malware often exploits these APIs commonly referred to as sink APIs to transmit sensitive information to external entities. An API $a_j$ is classified as suspicious"}, {"title": "3.3. Tier-wise Code Reasoning", "content": "Code reasoning involves analyzing and interpreting code to understand its behavior, identify potential threats, and generate meaningful explanations. We propose a three-tier reasoning strategy that refines APK behavior analysis from fine- to coarse-grained levels, enhancing both prediction accuracy and interpretability. This hierarchical approach improves malicious component identification, mitigates LLM token-length limitations, and captures structural and invocation semantics through separable reasoning, ensuring a more effective and scalable malware detection framework."}, {"title": "3.3.1. Tier 1: Function Behavior Summarization", "content": "In the previous stage, several functions invoking suspicious APIs are extracted and sliced to maintain the related context. Each sliced CFG of the function is fed to LLM to capture low-level code patterns and functionalities."}, {"title": "3.3.2. Tier 2: API Intent Awareness", "content": "The context of a specific API is typically determined by a series of functions. Beyond function invocation relationships, it is crucial to examine how inter-function associations influence the API's intent. Due to diverse contexts, an API may appear in multiple Function Call Graphs (FCGs). For instance, getDeviceId() is benign when used solely for local logging but becomes malicious when invoked within sendImeiToServer(), where it exfiltrates the IMEI to a remote server. Therefore, at this mid-tier, all functions associated with a suspicious API are structured into multiple FCGs to analyze its overall intent. Each node in an FCG is represented by the generated function summary in tier 1."}, {"title": "3.3.4. Factual Consistency Verification", "content": "Generating behavior summaries with LLMs risks hallucinations [41], producing facts inconsistent with instructions. To prevent error"}, {"title": "4. Evaluation", "content": "This section presents a comprehensive evaluation of LAMD, assessing its Android malware detection performance in real-world scenarios and the quality of its generated explanations through a series of experiments. Experiment setup details are shown in Appendix A."}, {"title": "4.1. Dataset Construction", "content": "To ensure a realistic dataset, we adhere to the following principles [3]: (1) Maintain temporal order in training and testing; (2) Preserve the real-world malware-to-benign ratio;"}, {"title": "4.2. Metric", "content": "(1) Classification Metrics. To address class imbalance in Android malware datasets, we use the F1-score to balance precision and recall, while also minimizing False Positive Rate (FPR) and False Negative Rate (FNR) to improve accuracy and reduce manual analysis overhead. Results are reported as percentages. (2) Summarization Metrics. Effective malware analysis provides interpretable insights and aids manual audits. Since malware family identification often requires expert review, initial categorization prioritizes the common sense of behavior patterns. Following prior work [46], we mainly consider six categories: Adware, Backdoor, PUA (Potentially Unwanted Applications), Riskware, Scareware, and Trojan. For evaluation, we adopt a ChatGPT-based metric [47], [48], [49], where GPT-40-mini [50] assesses whether LAMD's detection aligns with the expected behaviors of each category [51]."}, {"title": "4.3. Baseline", "content": "In Android malware detection, an APK serves as input, containing the codebase (e.g., .dex files) and configuration files (e.g., AndroidManifest.xml), which provide behavioral insights like API calls and permissions, represented in vector or graph formats. We evaluate LAMD against Drebin [11], DeepDrebin [12], and Malscan [52] which are representative"}, {"title": "4.4. Evaluation Results", "content": "4.4.1. Malware Detection Performance. \nLAMD improves F1-scores by 23.12% and reduces FNR by 71.59% on average, enhancing detection reliability. While the FPR shows a slight increase, it is less indicative of true performance due to class imbalance, where learning-based methods often misclassify malware as benign because of the dominance of benign sampls. The performance drop in LAMD-R highlights the necessity of hierarchical code summarization, and the slight decline in LAMD-F underscores the role of hallucination mitigation. By refining input code and extracting key information, LAMD minimizes hallucination risks, ensuring more reliable malware detection.\n4.4.2. Effectiveness of explanations. To assess analysis quality, we validate 100 correctly detected malware samples. Results show that 81 out of 100 samples are correctly classified into their respective categories. Due to their less distinct malicious patterns, Adware and Riskware pose greater challenges to accurate analysis compared to other categories, contributing to their higher misclassification rates."}, {"title": "5. Case Study", "content": "This section demonstrates how LAMD overcomes the limitations of current LLMs in Android malware detection. Since LLMs cannot process APKs directly, we use JADX to decompile them, concatenating all pesudo source codes for input Besides GPT-40-mini, we select Gemini 1.5 pro as another comparison, which claims their longest context windows and for its malware detection capabilities.\nFigure 1 highlights key failure cases. In the first example, we decompile a randomly selected sample which contains"}, {"title": "6. Discussion", "content": "While LLMs improve Android malware detection, their general pre-training limits fine-grained behavior analysis. Future research should enhance security expertise through domain-specific fine-tuning or external knowledge integration. Meanwhile, learning-based methods remain essential for capturing overall insights in non-drift scenarios, highlighting effective strategies to combine these two paradigms and maximize their complementary strengths."}, {"title": "7. Conclusion", "content": "Large language models' superior zero-shot inference offers a promising solution for Android malware detectors to handle distribution drift, dataset bias and explainability gaps in real-world scenarios but struggle with excessive support code and complex program structures. To address these challenges, we propose LAMD, the first practical framework enabling LLMs for explainable Android malware detection.\nOur evaluation in the real-world setting demonstrates that LAMD outperforms conventional detectors by effectively analyzing complex structures and semantics. LAMD unlocks LLMs' potential in Android security, paving the way for AI-driven malware analysis."}, {"title": "Appendix A. Experiment Details", "content": "Our experiments are conducted on an RTX A6000 GPU. For LLM-based reasoning, we utilize GPT-40-mini [50], selected for its high efficiency, cost-effectiveness, and strong reasoning capabilities. The Data Relation Coverage (DRC) threshold @ is set to 0.95 to balance computational efficiency and accuracy."}, {"title": "Appendix B. Dataset Description", "content": "B.1. Dataset Source\nWe construct a dataset spanning 2014 to 2023 using samples from the Androzoo [44] platform, a comprehensive"}, {"title": "Appendix C. Data Dependency used for Factual Consistency Verification", "content": "To check factual consistency, we leverage data dependencies that capture relationships between variables and APIs. We focus on five dependencies (see Table 5) as they represent"}, {"title": "Appendix D. Baseline Models", "content": "The details of baseline models are shown as follows:\nDrebin: Drebin [11] detects malware using binary feature vectors derived from nine data types (e.g., hardware components, API calls, permissions) and classifies samples via a linear classifier.\nDeepDrebin: DeepDrebin [12] extends Drebin by replacing the linear classifier with a three-layer deep neural network (DNN) while retaining the same feature space for feature extraction and classification.\nMalscan: Malscan [52] employs a graph-based approach, extracting sensitive API calls from APKs and computing four centrality measures (degree, Katz, proximity, and harmonic wave centralities) as features. We use the optimal feature with a Random Forest classifier, which leads to the lowest overhead."}, {"title": "Appendix E. Backward Slicing Algorithm", "content": "The proposed backward slicing algorithm is shown in Algorithm 1. This backward slicing procedure consists of two phases: variable retrieval and slice extraction. In Stage 1, the algorithm tracks variables that influence the suspicious"}]}