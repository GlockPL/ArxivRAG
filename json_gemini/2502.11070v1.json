{"title": "A Survey on Vulnerability Prioritization: Taxonomy, Metrics, and Research Challenges", "authors": ["YUNING JIANG", "NAY OO", "QIAORAN MENG", "HOON WEI LIM", "BIPLAB SIKDAR"], "abstract": "In today's highly interconnected digital landscape, safeguarding complex infrastructures against cyber threats\nhas become increasingly challenging due to the exponential growth in the number and complexity of vulnera-\nbilities. Resource constraints necessitate effective vulnerability prioritization strategies, focusing efforts on\nthe most critical risks. This paper presents a systematic literature review of 82 studies, introducing a novel\ntaxonomy that categorizes metrics into severity, exploitability, contextual factors, predictive indicators, and\naggregation methods. Our analysis reveals significant gaps in existing approaches and challenges with multi-\ndomain applicability. By emphasizing the need for dynamic, context-aware metrics and scalable solutions,\nwe provide actionable insights to bridge the gap between research and real-world applications. This work\ncontributes to the field by offering a comprehensive framework for evaluating vulnerability prioritization\nmethodologies and setting a research agenda to advance the state of practice.", "sections": [{"title": "1 Introduction", "content": "In today's interconnected and digitized world, securing complex systems is paramount for pro-\ntecting sensitive information and maintaining critical operations. As organizations increasingly\nrely on technology, the number and complexity of vulnerabilities within software and hardware\nsystems have grown exponentially [50]. Effective and timely remediation strategies are essential to\nmitigate potential cyber threats. However, resource constraints and the overwhelming volume of\nvulnerabilities make it impractical to address every potential threat comprehensively [62, 71]. This\nlimitation necessitates the prioritization of vulnerabilities based on their risk."}, {"title": "2 Preliminaries", "content": "In complex systems, ensuring robust security against vulnerabilities is critical for maintaining oper-\national integrity and safeguarding sensitive information. This sub-section introduces a formalized\nrepresentation that focuses on the foundational dimensions of vulnerability prioritization: impact,\nexploitability, and contextual factors. These dimensions are selected for their direct relevance to\ncalculating risk scores and their established role in prioritization frameworks. Additional categories,\nsuch as predictive and aggregated metrics, are later introduced with examples and integrated into\nthe taxonomy presented. By linking the formalism to the taxonomy, this framework provides a\nstructured approach for understanding and evaluating prioritization strategies."}, {"title": "2.1 Key Concepts in Vulnerability Prioritization", "content": null}, {"title": "2.1.1 System and Vulnerability Representation", "content": "We represent a complex system as a set S, consisting\nof N components denoted as C\u00a1, where i \u2208 {1, 2, . . ., N }. Each component C\u00a1 is associated with a\nset of vulnerabilities, where Vij denotes vulnerability j in component C\u00a1. Formally, each component\nis defined as:\nS = {C1, C2, ...,CN}, C\u2081 = {Vi1, Vi2, . . ., Vim}.\nM is the amount of vulnerabilities in component C\u00a1."}, {"title": "2.1.2 Risk Score Calculation", "content": "The risk score RS\u00a1 for each component C\u00a1 is a function of three key\nmetrics:\nRS\u2081 = \u03b1\u00b7 \u0399\u00a1 + \u03b2 \u00b7 E\u00a1 + \u03b3 \u2022 C\u00a1.\nImpact I\u00a1 reflects the potential damage or disruption the vulnerability could cause in the compo-\nnent C\u00a1. It is computed as the sum of the impact scores Iij of each vulnerability j in component C\u00a1:\nSi = \u2211 SVij\nj=1\nThe exploitability score E\u00a1 represents how likely a vulnerability is to be exploited. It combines the\ntime-to-exploit TEij and the availability of an exploit EAij for each vulnerability j in component\nCi:\n\u0395\u2081 = \u2211(TEij EAij).\nj=1\nContextual or environmental factor C\u00a1 captures the criticality of the component and its depen-\ndencies within the system. It is defined as the sum of the criticality level L\u00a1 and system dependence\nDi:\nCi = Li + Di."}, {"title": "2.1.3 Objective Function", "content": "The objective of the vulnerability prioritization process is to minimize\nthe total risk score across all system components:\nMinimize Rtotal = \u03a3RS.\ni=1\nThis ensures that the system prioritizes the most critical vulnerabilities while accounting for\nseverity, exploitability, and environmental factors.\nThe optimization process is subject to two main constraints, namely resource and operational\nconstraints, respectively. Resource constraints suggest that the total remediation time must not\nexceed the available time. Operational constraints mean that the downtime for critical components\nmust be minimized, ensuring that the system remains operational."}, {"title": "2.2 Metrics for Vulnerability Prioritization", "content": "In addition to the foundational metrics (i.e., impact (Ii), exploitability (E\u2081), contextual and environ-\nmental (Ci)) formalized earlier, this sub-section introduces a taxonomy that incorporates Predictive\nMetrics and Aggregated/System-Level Metrics, as presented in Fig. 1. This taxonomy is derived from\na systematic review of 353 papers, of which 82 were selected for detailed analysis. By encompassing\nmultiple dimensions of vulnerability prioritization, the taxonomy addresses the complexities of\ncontemporary cybersecurity challenges, including regulatory pressures, the growing volume of\nvulnerabilities, and the need for holistic risk assessment frameworks."}, {"title": "2.3 Methodologies for Vulnerability Prioritization", "content": "This sub-section categorizes vulnerability prioritization methodologies into five main approaches:\ngraph-based methods, ML and AI-based approaches, multi-objective optimization, rule-based and\nexpert systems, and statistical methods.\nGraph Based Methods model systems and vulnerabilities as interconnected nodes and edges,\nenabling the analysis of attack paths, dependencies, and cascading effects. These methods are\nparticularly effective in complex environments where risks propagate across multiple assets. Struc-\ntural models such as attack graphs, dependency graphs, and Bayesian networks help identify\ncritical vulnerabilities and assess system-wide impacts, making them essential for prioritization in\ninterconnected infrastructures.\nML and AI based Approaches leverage historical and real-time data to predict vulnerability\nrisks and support data-driven decision-making. Techniques such as logistic regression, decision\ntrees, and neural networks enable adaptive scoring, anomaly detection, and exploitation forecasting.\nThese approaches are particularly advantageous in large-scale datasets, where traditional methods\nstruggle to capture evolving attack patterns.\nMulti-Objective Optimization Methods balance competing factors such as impact, exploitabil-\nity, criticality, and resource constraints to generate optimized vulnerability rankings. By leveraging\noptimization algorithms, including genetic algorithms, integer programming, and evolutionary\nmodels, multi-objective approaches systematically evaluate and refine rankings to align with diverse\nsecurity and operational goals.\nRule-Based and Expert Systems apply predefined rules, heuristics, and structured knowledge\n(e.g., ontologies, knowledge graphs) to assess vulnerabilities within specific domains. By integrat-\ning human expertise, they provide context-aware prioritization, ensuring reliable and repeatable\nassessments in environments where standardized models may be insufficient.\nStatistical Methods use regression models, probabilistic techniques, and data distribution\nanalysis to quantify risk factors and rank vulnerabilities. By identifying relationships between\nvariables, these methods establish baseline risk metrics and refine prioritization rankings, providing\na systematic, data-driven foundation for decision-making."}, {"title": "2.4 Existing Standards and Frameworks", "content": "The risk associated with vulnerabilities is often conceptualized using three factors, namely Proba-\nbility, Impact and Threat [119]. Probability quantifies the likelihood of exploitation [30], Impact\nassesses the consequences of a successful exploit, and Threat identifies potential actors or circum-\nstances exploiting the vulnerability.\nCVSS [77] is the leading vulnerability prioritization method. CVSS version 3 (V3), for instance,\ncategorizes metrics into Base, Temporal, and Environmental groups. Base metrics include Ex-\nploitability (Attack Vector, Attack Complexity, Privileges Required, User Interaction), Scope, and\nImpact (Confidentiality, Integrity, Availability). Temporal metrics reflect dynamic aspects like\nexploit techniques and patch availability. Environmental metrics consider deployment contexts.\nThese metrics are aggregated to generate a severity score for vulnerabilities.\nThe Exploit Prediction Scoring System (EPSS) [94] is a statistical model that estimates the\nlikelihood of a vulnerability being exploited in the wild within the next 30 days [53]. It provides\na score between 0 and 1, where a higher score indicates a higher likelihood of exploitation. It\nuses logistic regression to evaluate features such as software vendor, exploit code availability,\nvulnerability characteristics, and associated references.\nIn addition to CVSS and EPSS, the cybersecurity landscape employs various other standards\nand frameworks for vulnerability assessment and management. These include Common Platform\nEnumeration (CPE) [23], Common Weakness Enumeration (CWE) [73], Industrial Control Systems\nCyber Emergency Response Team (ICS-CERT) [52] advisories. The Security Content Automation\nProtocol (SCAP) [78] provides a standardized approach to maintaining system security. Compli-\nance frameworks such as North American Electric Reliability Corporation Critical Infrastructure\nProtection (NERC CIP) [22] and Payment Card Industry Data Security Standard (PCI DSS) [26]\nfurther guide organizations in maintaining robust cybersecurity practices. These diverse tools and\nstandards collectively form a comprehensive ecosystem for vulnerability prioritization and risk\nmanagement."}, {"title": "3 Related Works", "content": "Le et al. [62] provide a comprehensive overview of data-driven software vulnerability (SV) as-\nsessment and prioritization, focusing on the use of ML, deep learning (DL), and NLP techniques\nto automate tasks in the SV management lifecycle. However, their scope is limited to the phases\nbetween SV discovery and remediation, excluding studies that rely solely on manual analysis or\ndescriptive statistics.\nElder et al. [30] focus on methods for assessing the exploitability of vulnerabilities, categorizing\nthem into manual CVSS-based assessments, automated deterministic assessments, and automated\nprobabilistic assessments.\nIn contrast, our work introduces a broader taxonomy that includes compliance and contextual\nmetrics, which have received limited attention in prior surveys. Furthermore, we analyze real-\nworld challenges, such as explainability and vulnerability data quality, which extend beyond the\ndata-driven focus of [62]. By addressing these gaps, our study provides actionable insights into\nimproving vulnerability prioritization frameworks for both research and industrial applications."}, {"title": "4 Methodology", "content": null}, {"title": "4.1 Data Sources", "content": "We conducted a systematic literature review using four major academic databases: ACM Digital\nLibrary, Scopus, IEEE Xplore, and Google Scholar (primarily for snowballing). To ensure compre-\nhensive coverage, we formulated structured queries incorporating key terms related to vulnerability\nprioritization, risk assessment, exploitability, and cybersecurity frameworks. Papers published\nbefore December 2024 were queried, yielding 98 results from ACM Digital Library, 239 from Scopus,\nand 130 from IEEE Xplore. After deduplication and merging across databases, 353 unique papers\nremained."}, {"title": "4.2\nSelection Process", "content": "We applied a two-stage filtering process. First, we conducted title and abstract screening, during\nwhich papers were excluded if they did not explicitly address vulnerability prioritization, risk-based\ndecision-making, or security metric evaluation. We then continued with full-text review, whereby\npapers were assessed for methodological depth, use of structured risk metrics, and validation\ntechniques. The following exclusion criteria were applied:\n\u2022 Irrelevant Content: Studies focusing solely on patch management, general cybersecurity\nframeworks, or qualitative discussions without prioritization-specific analysis.\n\u2022 Non-English Publications: To ensure interpretability and avoid translation inconsistencies.\n\u2022 Non-Peer-Reviewed Sources: Including white papers, blog posts, and non-academic industry\nreports.\nApplying these criteria, 78 papers were selected for detailed review. We further conducted\nforward and backward snowballing, examining references in the selected papers and identifying\nadditional citations. This process led to the inclusion of 4 additional studies, resulting in a final\ndataset of 82 papers for in-depth analysis."}, {"title": "4.3 Data Extraction and Analysis", "content": "The data extraction process was designed to systematically capture key aspects of each selected\nstudy to facilitate a thorough comparative analysis. Beyond collecting fundamental contextual\ninformation, such as the study's objectives, research methodology, key findings, and evaluation or\nvalidation techniques, we performed a detailed manual extraction of specific, targeted data points\nrelevant to vulnerability prioritization.\nTo enhance reliability, two independent reviewers annotated each paper, followed by consensus\ndiscussions to resolve discrepancies. In cases of ambiguity (e.g., distinguishing between rule-based\nand statistical models), a third reviewer conducted tie-breaking assessments to ensure objective\ncategorization.\nThe extracted data points include:\n\u2022 We documented vulnerability prioritization metrics, focusing on severity, exploitability,\ncontextual factors, predictive indicators, and aggregation methods, and other novel metrics\nto provide a comprehensive view.\n\u2022 The risk assessment methodologies and frameworks employed in the studies were systemati-\ncally cataloged. These included graph-based approaches, rule-based systems, ML techniques,\nmulti-objective and statistical methods. We also examined whether the risk assessments were\nstatic or dynamic in nature.\n\u2022 Validation methods, such as case studies, controlled experiments, simulations, and interviews,\nwere analyzed to evaluate reliability and applicability across contexts."}, {"title": "5 Impact Metrics", "content": null}, {"title": "5.1 Definition and Importance", "content": "Impact Metrics quantify the inherent consequences of a vulnerability's exploitation, focusing\non its effects on the confidentiality, integrity, and availability (CIA triad) of the affected system.\nThese metrics evaluate the intrinsic risk posed by a vulnerability without considering contextual\nor exploitability factors."}, {"title": "Inherent Impact Score (IIS\u00a1j)", "content": "represents the inherent impact of vulnerability j in component i,\noften derived from standardized frameworks such as the CVSS base score. Over 70% of reviewed\nstudies, including [6, 59, 105], have utilized CVSS as the primary metric for vulnerability prioriti-\nzation. However, CVSS base score has limitations, including its static nature [61, 95] and lack of\ncontextualization. While widely adopted, CVSS base score does not reflect evolving threats such as\nactive exploitation or new attack vectors. Additionally, it overlooks operational context; a high\nCVSS base score may pose minimal risk in a well-segmented environment, while a low score could\nendanger critical infrastructure in less secure systems."}, {"title": "Component-Level Impact (CLI\u012f)", "content": "measures the potential disruption caused by a vulnerability\nin component i to system performance, data security, or critical functionality [76]."}, {"title": "5.2 Methodology Trends", "content": "Impact metrics are most frequently used in rule-based and expert systems (21 studies), graph-based\napproaches (17 studies), and machine learning (17 studies). Multi-objective methods (8 studies) are\nused to a lesser extent, while statistical methods appear in only 6 studies. Below, we discuss key\nmethodologies and representative studies.\nRule-Based and expert systems rely on predefined rules to assess vulnerability impact. For\nexample, [60] presents a rule-based approach for automating the quantification of security risks\nrelated to SQL injection and cross-site scripting attacks using CVSS. By leveraging vulnerability\nreports from NVD and real-time dynamic analysis of attack vectors (e.g., attacker's IP location,\nprivilege level, and network proximity), the system calculates CVSS vectors to assign risk scores to\ndetected attacks.\n[28] adjusts vulnerability severity scores by modifying the exploitability metrics of the CVSS\nframework, specifically Attack Vector (AV) and Attack Complexity (AC), based on the target\nenvironment's topology and implemented security mechanisms. This adjustment process results"}, {"title": "6 Exploitability Metrics", "content": null}, {"title": "6.1\nDefinition and Importance", "content": "Exploitability Metrics assess the technical ease of exploiting a vulnerability, focusing on factors\nsuch as attack complexity, required privileges, user interaction, and the availability of public exploit"}, {"title": "Public Exploit Availability (PEA\u00a1)", "content": "indicates whether a publicly known exploit exists for\nvulnerabilities in component i. A known exploit increases urgency for remediation [89, 91]."}, {"title": "Time-to-Exploit (TTE\u00bf)", "content": "estimates how soon a functional exploit is likely to emerge in the wild\nfor vulnerabilities in component i. This metric is essential for prioritizing vulnerabilities that may\nsoon have active exploits but are not currently being used in attacks [25]."}, {"title": "Exploit Difficulty (ED\u012f)", "content": "measures the difficulty of exploiting a vulnerability, considering factors\nlike user interaction and the presence of security mechanisms such as firewalls or sandboxing.\nExploit difficulty can be adjusted based on environmental factors, such as the presence of firewalls\nor intrusion detection systems [118]."}, {"title": "6.2 Methodology Trends", "content": "Exploitability metrics are predominantly used in ML-based methods (17 studies) and graph-based\napproaches (13 studies), with rule-based systems (9 studies) and statistical methods (6 studies)\nplaying a secondary role. Multi-objective (2 studies) is the least utilized.\nML techniques are widely applied to predict exploitability by analyzing textual and structured\nvulnerability data. For example, [25] introduces the vulnerabilities' risk of exploitation system (V-\nREx), which prioritizes software security patches based on the estimated probability of exploitation.\nThis probability is computed using interconnected neural networks optimized with a genetic\nalgorithm. V-REx incorporates multiple factors, including exploit availability, severity, and the\nlikelihood of exploitation, to rank vulnerabilities effectively.\n[51] employs multiple ML classifiers to predict the exploitability of newly disclosed vulnerabilities\nusing CVE descriptions, CVSS base scores, and online discussions from Security Focus and Exploit\nDatabase. They evaluate multiple classifiers, finding Logistic Regression to provide the best trade-off\nbetween precision and recall, while Random Forest achieves the highest precision. Pre-trained\nLarge Language Models (LLMs) underperform, acting as majority-class predictors. Their proposed\nmethod also integrates SMOTE (or synthetic minority over-sampling technique) for data balancing,\nwhich improves prediction accuracy in imbalanced datasets.\n[89] uses a combination of a bidirectional long-short term memory (Bi-LSTM) network and\nattention mechanisms to link exploits from Dark Web hacker forums to known vulnerabilities.\nBased on the generated exploit-vulnerability linkages, this metric incorporates factors like exploit\npost date, the number of vulnerabilities on a device and the age of associated exploits to create an\naggregated risk score for devices.\n[91] integrates the availability of exploits, directly influencing the risk score by indicating\nimmediate exploitation potential. In addition, the authors consider the volume of social media\nactivity (e.g., tweets, likes, and retweets), which reflects public attention; engagement in public\ncode repositories (e.g., the number of forks and stars on GitHub), indicating the level of exploit or"}, {"title": "7 Contextual and Environmental Metrics", "content": "Contextual and Environmental Metrics evaluate vulnerability risk based on system-specific\nand organizational factors, such as the criticality of the affected component, potential disruption to\nbusiness operations, and broader financial or reputational implications. These metrics adapt risk\nassessments to reflect the unique context of the deployment environment."}, {"title": "7.1 Definition and Importance", "content": null}, {"title": "7.1.1 Business and System Impact Metrics", "content": "These metrics measure how the vulnerability's impact\nextends beyond the technical scope to affect broader business and system objectives."}, {"title": "Criticality Level (CL\u2081)", "content": "reflects the importance of component i within the overall system. Compo-\nnents critical to business operations or system functionality receive a higher priority in remediation\ndecisions [1, 48]."}, {"title": "Operational Disruption Risk (OD\u2081)", "content": "measures the potential for a vulnerability to disrupt\nessential business processes or cause system downtime [39, 57, 67, 68]."}, {"title": "Business Impact (BI\u012f)", "content": "evaluates the potential financial, regulatory, or reputational damage from\nexploiting a vulnerability in component i [46, 112]."}, {"title": "7.1.2 Network and Host Exposure", "content": "These metrics measure how accessible vulnerable components\nare from external networks or internally exposed surfaces. These metrics help prioritize vulnerabil-\nities based on their level of exposure to potential attackers."}, {"title": "Network Exposure level (NE\u00bf)", "content": "evaluates the degree of exposure of component i to external\nnetworks, such as the internet or unsecured network segments. Vulnerabilities in externally facing\ncomponents, such as web servers or public APIs, pose higher risks and are prioritized accordingly\n[19, 70]."}, {"title": "Host Exposure Level (HE\u2081)", "content": "measures the exposure of component i to potential internal threats\ndue to host-level mis-configurations, open ports, or unnecessary services [107, 119]."}, {"title": "7.1.3 Operational Feasibility Considerations", "content": "These metrics account for factors such as time-to-\nremediation, resource constraints, and regulatory requirements. These metrics are crucial for\nunderstanding the practical challenges in vulnerability remediation and ensuring compliance with\nindustry standards."}, {"title": "Time-to-Remediation (TTR\u00a1)", "content": "estimates the time required to apply a patch or mitigation for\ncomponent i. Vulnerabilities with shorter remediation timelines are prioritized to minimize the\nwindow of exposure, while those with longer timelines may necessitate interim measures, such as\ntemporary mitigations or enhanced monitoring [33, 86, 103, 105]."}, {"title": "Resource Constraints (RC\u2081)", "content": "reflects the availability of resources (e.g., personnel, budget, and\ntools) needed to remediate vulnerabilities in component i. Limited resources necessitate prioritizing\nvulnerabilities that can be resolved with minimal disruption or cost, balancing overall risk mitigation\nwith operational efficiency [33]."}, {"title": "Compliance and Regulatory Impact (CR\u012f)", "content": "assess the legal and regulatory obligations associ-\nated with component i. Vulnerabilities in components subject to regulatory frameworks (e.g., GDPR\nand HIPAA) are prioritized for timely remediation to avoid penalties, legal action, or reputational\ndamage [33]."}, {"title": "7.2 Methodology Trends", "content": "Contextual metrics are heavily utilized in graph-based approaches (21 studies), emphasizing their\nability to model system dependencies and environmental factors. Rule-based systems (17 studies) are"}, {"title": "8 Aggregated and System-Level Metrics", "content": null}, {"title": "8.1\nDefinition and Importance", "content": "Aggregated and System-Level Metrics provide a holistic view of system risk by combining\nmultiple dimensions of risk into a single, comprehensive score. This category accounts for the\noverall impact of vulnerabilities on the entire system, including attack paths and system-wide\ndependencies. These metrics are particularly useful for prioritization in environments with complex\ndependencies, such as supply chains and cloud systems."}, {"title": "Composite Risk Score (CR\u012f)", "content": "for component i combines metrics such as impact, exploitability,\nand exposure into a single score, often weighted based on organizational priorities [14, 119, 120]."}, {"title": "Chained Vulnerability Impact (CV)", "content": "assesses the risk of multi-step attack paths where vul-\nnerabilities in one component enable lateral movement or privilege escalation across the system\n[93]."}, {"title": "Cascading Impact (CI\u2081)", "content": "measures the potential for cascading failures across interconnected\ncomponents due to a single vulnerability. High dependency on vulnerable components can elevate\nsystem-wide risk [16, 58, 115]."}, {"title": "8.2 Methodology Trends", "content": "Research on vulnerability prioritization utilizing aggregation metrics spans rule-based (10 studies),\ngraph-based (7), ML-based (3), and multi-objective optimization (3), and statistical (1) approaches.\nRule-based methods aggregate multiple risk factors by applying structured heuristics for vulnera-\nbility prioritization. [3] employs an attack graph-based penetration testing model to aggregate risk\nacross attack paths in IoT networks. The model integrates exploitability metrics (e.g., programming\nlanguage, exploit availability), impact metrics (e.g., CVSS scores, privilege escalation potential),\nand contextual factors (e.g., network topology, vendor reputation, exploit age). Adjacency matrices\nand NetworkX tools enable the aggregation of attack paths for critical path analysis, identifying\nshortest and most impactful attack routes."}, {"title": "9 Predictive Metrics", "content": null}, {"title": "9.1 Definition and Importance", "content": "Predictive Metrics evaluate how vulnerability risk evolves over time, using models to forecast\nfuture exploitation or impact to inform timely remediation. Predictive metrics forecast future risks by\nleveraging historical data, threat intelligence, and machine learning. These metrics are particularly\nvaluable for proactive risk management, enabling organizations to prioritize vulnerabilities likely\nto be exploited in the near term. Their effectiveness relies heavily on high-quality, real-time data,\nwhich remains a persistent challenge."}, {"title": "Predicted Time-to-Exploit (PTTE\u2081)", "content": "is a model-based estimation of how quickly a vulnerability\nin component i might be exploited after discovery, based on historical trends and threat intelligence\n[34, 51, 116]."}, {"title": "Predictive Risk Score (PR\u012f)", "content": "combines likelihood and impact forecasts into a single risk score\ngenerated by predictive models (e.g., ML techniques), offering a holistic view of future risks [59, 120]."}, {"title": "9.2 Methodology Trends", "content": "Predictive metrics primarily appear in ML-based methods (13 studies), followed by graph-based\nmodels (3 studies). Rule-based systems and statistical models show minimal adoption, with only 2\nstudies each incorporating predictive metrics.\nML models utilize historical and real-time threat intelligence to predict future vulnerability\nexploitation. These approaches integrate text analysis, latent risk estimation, and (un)supervised\nlearning algorithms to refine predictive accuracy. For example, [59] introduces a topic extraction-\nbased risk prediction model, assigning cybersecurity topics to CVEs using Wikipedia-derived text\nfeatures. A time-series risk score is computed by multiplying occurrence and impact metrics, and\nrandom forest models are trained on historical data to forecast future risks.\n[121] employs deep learning for time-dependent exploitability prediction, integrating neural\nnetworks to dynamically adjust risk scores. The model is trained on CVSS metrics, CWE cate-\ngories, software attributes, and text-based features (TF-IDF bi-grams) to classify vulnerabilities\nexploitability. It incorporates two scheduling algorithms: a baseline NP-hard optimization method\nand a group-based scheduling method, which reduces computational complexity by dividing assets\ninto groups.\n[34] presents V-REx, an neural network based vulnerability exploitability prediction system. It\nclassifies vulnerabilities using three neural network models (standard, enhanced, interconnected\nenhanced), leveraging textual features, CVSS scores, and metadata from CVE/NVD sources. The\nsystem fine-tunes hyperparameters using an enhanced genetic algorithm.\nSeveral studies integrate ML with optimization and rule-based reasoning to enhance predictive\nrisk assessment. [120] develops a neuro-symbolic model that prioritizes vulnerabilities based on past\nexploitability trends and future impact potential. A neural network analyzes historical threat data"}, {"title": "10 Discussions", "content": "Through the exploration of key metrics, methodologies, and validation techniques, this section\nsynthesizes the current trends, challenges, and emerging directions in vulnerability prioritization\nresearch."}, {"title": "10.1\nCross-Metric Trends and Insights", "content": null}, {"title": "10.1.1 Metric Usage", "content": "A quantitative analysis of the reviewed studies reveals the prevalence and gaps\nin metric usage. Impact metrics dominate, appearing in 60 of 82 studies, yet they often insufficient\nfor capturing operational relevance or future risks. Exploitability metrics, featured in 40 studies,\nemphasize the technical feasibility of exploitation (e.g., network accessibility, exploit availability)\nbut their integration with other dimensions remains limited. Contextual metrics, present in 48\nstudies, reflect a growing focus on asset criticality and operational relevance. Used in 20 studies,\naggregated metrics combine multiple dimensions of risk but remain under-explored in system-wide\nprioritization frameworks. Predictive metrics, despite their potential for proactive decision-making,\nappear in only 17 studies, indicating a substantial opportunity for further research. Table 1 in the\nAppendix maps the reviewed studies, detailing their use of data sources and metric categories.\nThe integration of multiple metrics remains limited. Only 22 studies combine exploitability and\ncontextual metrics, while predictive and aggregated metrics are seldom jointly applied (only in\n2 studies). These findings emphasize the need for multidimensional approaches that incorporate\noperational and holistic risk assessments."}, {"title": "10.1.2 Methodological Insights", "content": "A balanced interest exists between data-driven techniques (graph-\nbased, ML/AI) and expert-driven methods, each appearing in 24\u201327 studies. Graph-based methods\nare the most frequently employed, appearing in 27 of the reviewed papers. These methods leverage\nnetwork or dependency graphs to model the relationships between system components or vulnera-\nbilities [3, 64, 67, 107, 113]. These graph-based approaches normally aim to propagate risks across\ninterconnected nodes to identify critical vulnerabilities. ML and AI-based methods are utilized in 24\npapers, focusing on predictive analysis and anomaly detection [25, 32, 47, 51, 91]. These approaches\nrely on historical data to train models that prioritize vulnerabilities based on previous exploitation"}, {"title": "10.1.3 Validation Methods", "content": "Validation approaches vary based on methodological choices. Con-\ntrolled experiments are the most common, used in 33 papers [34, 59, 60, 71, 110], particularly for\ngraph-based and ML/AI approaches. These studies focus on evaluating the accuracy and perfor-\nmance of the prioritization models in a controlled setting. Case studies, presented in 27 papers, typi-\ncally focusing on real-world scenarios to validate their proposed methodologies [16, 49, 89, 93, 107].\nCase studies are often selected for their relevance to the systems or networks under considera-\ntion, providing valuable insight into the applicability of the techniques in practice. Simulations,\nappearing in 13 studies, offer an environment to test theoretical models, though their reliance on\nsynthetic data may limit generalizability [57, 96, 106, 115, 119]. Interviews, appearing in 6 papers,\nrepresent a smaller effort to capture expert opinions and contextual insights [4, 11, 43, 55, 68, 89].\nValidation approaches vary based on methodological choices. Controlled experiments are the\nmost common, used in 33 papers [34, 59, 60, 71, 110], particularly for graph-based and ML/AI\napproaches. These studies focus on evaluating the accuracy and performance of the prioritization\nmodels in a controlled setting. Case studies, presented in 27 papers, typically focusing on real-world\nscenarios to validate their proposed methodologies [16, 49, 89, 93, 107]. Case studies are often\nselected for their relevance to the systems or networks under consideration, providing valuable\ninsight into the applicability of the techniques in practice. Simulations, appearing in 13 studies,\noffer an environment to test theoretical models, though their reliance on synthetic data may limit\ngeneralizability [57, 96, 106, 115, 119]. Interviews, appearing in 6 papers, represent a smaller effort\nto capture expert opinions and contextual insights [4, 11, 43, 55, 68, 89]."}, {"title": "10.2 Data Quality Challenges", "content": "Table 1 (Appendix) summarizes the data sources used in the reviewed papers. Most studies rely on\nstandard vulnerability databases such as CVE/NVD (70 out of 82) [59, 76, 108", "86": "nas foundational inputs. For exploitability-oriented assessments, additional sources include exploit\ndatabases (e.g., ExploitDB [89, 118", "120": "Symantec\nattack signatures [4, 18", "118": ".", "91": "GitHub [118", "64": ".", "29": "finds discrepancies in software version vulnerabilities between CVE\nand NVD, with only a fraction of entries matching accurately. Similarly, [111"}]}