{"title": "Neural varifolds: an aggregate representation for quantifying the geometry of point clouds", "authors": ["Juheon Lee", "Xiaohao Cai", "Carola-Bibian Sch\u00f6nlieb", "Simon Masnou"], "abstract": "Point clouds are popular 3D representations for real-life objects (such as in LiDAR and Kinect) due to their detailed and compact representation of surface-based geometry. Recent approaches characterise the geometry of point clouds by bringing deep learning based techniques together with geometric fidelity metrics such as optimal transportation costs (e.g., Chamfer and Wasserstein metrics). In this paper, we propose a new surface geometry characterisation within this realm, namely a neural varifold representation of point clouds. Here the surface is represented as a measure/distribution over both point positions and tangent spaces of point clouds. The varifold representation quantifies not only the surface geometry of point clouds through the manifold-based discrimination, but also subtle geometric consistencies on the surface due to the combined product space. This study proposes neural varifold algorithms to compute the varifold norm between two point clouds using neural networks on point clouds and their neural tangent kernel representations. The proposed neural varifold is evaluated on three different sought-after tasks \u2013 shape matching, few-shot shape classification and shape reconstruction. Detailed evaluation and comparison to the state-of-the-art methods demonstrate that the proposed versatile neural varifold is superior in shape matching and few-shot shape classification, and is competitive for shape reconstruction.", "sections": [{"title": "Introduction", "content": "Point clouds are preferred in more and more applications including computer graphics, autonomous driving, robotics and augmented reality. However, manipulating/editing point clouds data in its raw form is rather cumbersome. Neural networks have made breakthroughs in a wide variety of fields ranging from natural language processing to computer vision. Point cloud data in general lack underlying grid structures. As a result, convolution operations on point cloud data require special techniques including voxelisation [1, 2, 3], graph representations [4, 5, 6] or point-wise convolutions [7, 8, 9]. Geometric deep learning and its variants have addressed technical problems of translating neural networks on point cloud data [5]. With advanced graph theory and harmonic analysis, convolutions on point cloud data can be defined in the context of spectral [4, 10] or spatial [11, 6] domains. Although geometric deep learning on point clouds has successfully achieved top performance in shape classification and segmentation tasks, capturing subtle changes in 3D surface remains challenging due to the unstructured and non-smooth nature of point clouds. A possible direction to learn subtle changes on 3D surface adopts some concepts developed in the field of theoretical geometric analysis. In other words, deep learning architectures might be improved by incorporating theoretical knowledge from geometric analysis. In this work, we introduce concepts"}, {"title": "Related works", "content": "Geometric deep learning on point clouds. PointNet is the first pioneering work on point clouds. It consists of a set of fully connected layers followed by symmetric functions to aggregate feature representations. In other words, PointNet is neural networks on a graph without edge connections. In order to incorporate local neighbourhood information with PointNet, PointNet++ [8] applied PointNet to individual patches of the local neighbourhood, and then stacked them together. PointCNN [17] further refined the PointNet framework with hierarchical X-Conv which calculates inner products of X-transformation and convolution filters of point clouds. Dynamic graph CNN (DGCNN) [6] adopted the graph neural network framework to incorporate local neighbourhood information by applying convolutions over the graph edges and dynamically updating graph for each layer. Furthermore, the tangent convolution architecture [18] incorporated 3D surface geometry by projecting point clouds on local tangent plane, and then applying convolution filters.\nVarifolds. Geometric measure theory provides various tools for understanding, characterising and analysing surface geometry in various contexts, e.g., currents [12], varifolds [13, 15, 16] or normal cycles [19]. Despite their potential use for many applications, few studies have explored real-world applications of varifolds in the context of non-rigid surface registration [13]."}, {"title": "Varifold representations for point clouds", "content": "The notion of varifold arises in geometric measure theory in the context of finding a minimal surface spanning a given closed curve in R\u00b3, which is known as Plateau's problem [20]. Intuitively, the concept of a varifold extends the idea of a differentiable manifold by replacing the requirement for differentiability with the condition of rectifiability [21]. This modification enables the representation of more complex surfaces, including those with singularities. For instance, Figure 1 in [21] presents straightforward examples of varifolds. Let $\u03a9 \\subset C \\mathbb{R}^n$ be an open set. A general oriented d-varifold V"}, {"title": "Definition 3.1 (Rectifiable oriented d-varifolds).", "content": "Let \u03a9C Rn be an open set, X be an oriented d-rectifiable set, and @ be a non-negative measurable function with 0 > 0 Hd-almost everywhere in X. The rectifiable oriented d-varifold V = v(0, X) in \u03a9 is the Radon measure on \u03a9 \u00d7 G(d,n) defined by V = 0\u0389\u03c7\u03bf\u03c2 & \u03b4\u03c4\u2082x, i.e.,\n$\\int_{\\Omega \\times \\breve{G}(d, n)} \u03c6(x,T)d\u03bc(x,T) = \\int_{X} \u03c6(x,T_{x}X)0(x)dH^{d}(x), \\forall \u00a2\\in C_{0}(\\Omega\\times \\breve{G}(d, n)),$\nwhere Co denotes the class of continuous functions vanishing at infinity.\nThe mass of a d-rectifiable varifold V = v(0, X) is the measure ||V|| = 0H%. The non-negative function @ is usually called multiplicity. We assume in the rest of the paper that 0 = 1 for simplicity.\nVarious metrics and topologies can be defined on the space of varifolds. The mass distance defined as follows is a possible choice for a metric:"}, {"title": "Definition 3.2 (Bounded Lipschitz distance).", "content": "Being \u03bc and v two varifolds on a locally compact metric space (X, d), we define\n$\\begin{aligned} d_{B L}(\\mu, \\nu) = \\sup\\left\\{\\int_{\\Omega \\times \\breve{G}(d, n)} \u03c6d\u03bc - \\int_{\\Omega \\times \\breve{G}(d, n)} \u03c6d\u03bd,  \u03c6 \\in C_{0}^{1}(\\Omega \\times \\breve{G}(d, n)), ||\u03c6||_{L i p} \\leq 1, ||\u03c6||_{\\infty} \\leq 1\\right\\}. \\end{aligned}$\nThe bounded Lipschitz distance (flat distance) can handle both problems, we refer for more details to [22] and the references therein. Although the bounded Lipschitz distance dBL can provide theoretical properties for comparing varifolds, in practice, there is no straightforward way to numerically evaluate it. Instead, the kernel approach has been used to evaluate and compare varifolds numerically [13, 14]."}, {"title": "Proposition 3.3.", "content": "[14]. Let kpos and k\u0171 be continuous positive definite kernels on Rn and \u011e(d,n), respectively. Assume in addition that for any x \u2208 Rn, kpos(x,\u00b7) \u2208 Co(Rn). Then kpos \u25ca kg is a positive definite kernel on R\u2033 \u00d7 \u011e(d,n), and the reproducing kernel Hilbert space (RKHS) W associated with kpos \u25ca kg is continuously embedded in Co(R\u2033 \u00d7 G(d,n)), i.e., there exists cw > 0 such that for any \u00a2 \u2208 W, we have ||||\u221e < cw||||w.\nLet Tw: W\u2192 Co(Rn \u00d7 \u011e(d, n)) be the continuous embedding given by Proposition 3.3 and tw* be its adjoint. Then varifolds can be viewed as elements of the dual RKHS W*. Let \u03bc and v be two varifolds. By the Hilbert norm of W*, the pseudo-metric can be induced as follows\n$\\begin{aligned} d_{W^{*}}(\\mu, \\nu)^{2} = & ||\u03bc - \u03bd||_{W^{*}}^{2} \\\\ = & ||\u03bc||_{W^{*}}^{2} - 2\\langle \u03bc, \u03bd\\rangle_{W^{*}} + ||\u03bd||_{W^{*}}^{2}. \\end{aligned}$\nThe above pseudo-metric (since Tw* is not injective in general) is associated with the RKHS W, and it provides an efficient way to compute varifold by separating the positional and Grassmannian components. Indeed, one can derive a bound with respect to dBL if we further assume that RKHS W is continuously embedded into CJ(Rn \u00d7 \u011e(d, n)) [13], i.e.,\n$||\u03bc - \u03bd||_{W^{*}} = \\sup_{\\phi \\in W, ||\\phi||_{W} \\leq 1} \\int \u03c6 d(\u03bc - \u03bd) \\leq c_{W} d_{B L}(\u03bc, \u03bd).$"}, {"title": "Neural tangent kernel.", "content": "The recent advances of neural network theory finds a link between kernel theory and over-parameterised neural networks [23, 24]. If a neural network has a large but finite width, the weights at each layer remain close to its initialisation. Given training data pairs {xi, Yi}1, where xi \u2208 Rdo and yi \u2208 R, let f(0; x\u2081) be a fully connected neural network with L-hidden layers with inputs \u00e6i and parameters 0 = {W(0),b(0),\u2026\u2026\u2026, W(L), 6(L)}. Let d\u0127 be the width of the neural network for each layer h. The neural network function f can be written recursively as\n$\\begin{aligned} f^{(h)}(x) = W^{(h)}g^{(h)}(x)+b^{(h)}, \\quad g^{(h+1)}(x) = \u03c6(f^{(h)}(x)), \\quad h = 0, ..., L, \\end{aligned}$\nwhere g(0) (x) = x and is a non-linear activation function.\nAssume the weights W(h) \u2208 Rdn+1\u00d7dn_and bias b(h) \u2208 Rdh at each layer h are initialised with Gaussian distribution W(h) ~ N(0, 02/dh) and b(h) ~ N(0, 0), respectively. Consider training a neural network by minimising the least square loss function\n$l(\u03b8) = \\frac{1}{2} \\sum_{i=1}^{M}(f(\u03b8; x_{i}) - y_{i})^{2}.$\nSuppose the least square loss l(0) is minimised with an infinitesimally small learning rate, i.e.,\nde = -1(0(t)). Let u(t) = (f(0(t); xi))i\u2208[M] \u2208 RM be the neural network outputs on all xi at time t, and y = (Yi)i\u2208[M] be the desired output. Then u(t) follows the evolution\n$\\begin{aligned} \\frac{du}{dt} = -H(t)(u(t) - y), \\end{aligned}$\nwhere\n$H(t)_{i j} = \\frac{\u2202f(\u03b8(t); x_{i})}{\u2202\u03b8} \\frac{\u2202f(\u03b8(t); x_{j})}{\u2202\u03b8}^{T}.$\nIf the width of the neural network at each layer goes to infinity, i.e., dh \u2192 \u221e, with a fixed training set, then H(t) remains unchanged. Under random initialisation of the parameters \u03b8, \u0397 (0) converges in probability to a deterministic kernel H* \u2013 the \u201cneural tangent kernel\u201d (i.e., NTK) [23]. Indeed, with few known activation functions 4 (e.g., ReLU), the neural tangent kernel H* can be computed by a closed-form solution recursively using Gaussian process [25, 24]. For each layer h, the corresponding covariance function is defined as\n$\\begin{aligned} \\Sigma^{(0)}(x_{i}, x_{j}) = \u03c3_{b}^{2} + \\frac{\u03c3_{w}^{2}}{d_{0}} x_{i}^{T}x_{j}, \\\\ A^{(h)} =  \\begin{bmatrix} \\Sigma^{(h-1)}(x_{i}, x_{i}) & \\Sigma^{(h-1)}(x_{i}, x_{j}) \\\\ \\Sigma^{(h-1)}(x_{j}, x_{i}) & \\Sigma^{(h-1)}(x_{j}, x_{j}) \\end{bmatrix}  \\in \\mathbb{R}^{2 \\times 2}, \\\\ \\Sigma^{(h)}(x_{i}, x_{j}) = \u03c3_{b}^{2} + \u03c3_{w}^{2} \\mathbb{E}_{(u,v) \\sim \\mathcal{N}(0, \\Lambda^{(h)})} [\u03c6(u)\u03c6(v)]. \\end{aligned}$\nIn order to compute the neural tangent kernel, derivative covariance is defined as\n$\\overline{\\Sigma}^{(h)}(x_{i}, x_{j}) = \\mathbb{E}_{(u,v) \\sim \\mathcal{N}(0, \\Lambda^{(h)})} [\u03c6'(u)\u03c6'(v)].$\nThen, with (0) (xi, Xj) = \u03a3(0) (xi, xj), the neural tangent kernel at each layer (h) can be computed as follows\n$\\Theta^{(h)}(x_{i}, x_{j}) = \\overline{\\Sigma}^{(h)}(x_{i}, x_{j}) + \\Theta^{(h-1)}(x_{i}, x_{j}).$\nThe convergence of (L) (xi, xj) to H is proven in Theorem 3.1 in [24]."}, {"title": "Neural varifold computation", "content": "In this section, we present the kernel representation of varifold on point clouds via neural tangent kernel. We first introduce the neural tangent kernel representation of popular neural networks on point clouds [7, 24] by computing the neural tangent kernel for position and Grassmannian components, individually."}, {"title": "Given the set of n point clouds", "content": "S = {S1,S2,\u2026\u2026, sn}, where each point cloud s\u2081 = {P1,P2,\u2026,Pm} is a set of points, and n, m are respectively the number of point clouds and the number of points in each point cloud. Note that the number of points in each point cloud needs not be the same (e.g., |81|7|82|). For simplicity, we below assume different point clouds have the same number of points. Consider PointNet-like architecture that consists of L-hidden layers fully connected neural network shared by all points. For (i, j) \u2208 [m] \u00d7 [m], the covariance matrix (h) (p2, P3) and neural tangent kernel (h) (pz, p\u2081) at layer h are defined and computed in the same way of Equations (10) and (12). Assuming each point pe consists of positional information and surface normal direction such that p; \u2208 R3 \u00d7 S2, the varifold representation can be defined with neural tangent kernel theory in two different ways. One way is to follow the Charon-Trouv\u00e9 approach [13] by computing the position and Grassmannian kernels separately. While the original Charon-Trouv\u00e9 approach uses the radial basis kernel for the positional elements and a Cauchy-Binet kernel for the Grassmannian parts, in our cases, we use the neural tangent kernel representation for both the positional and Grassmannian parts. Let p = {x\u00ee, z\u00ee} \u2208 R\u00b3 \u00d7 S\u00b2 be a pair of position x \u2208 R\u00b3 and its surface normal z\u00ee \u2208 S2, \u00ec = 1, . . ., m. The neural varifold representation is defined as\n$\\Theta_{\\text {varifold }}^{(L)}\\left(p_{\\hat{i}}, p_{\\hat{j}}\\right)=\\Theta_{\\text {pos }}^{(L)}\\left(x_{\\hat{i}}, x_{\\hat{j}}\\right) \\Theta_{\\mathrm{G}}^{(L)}\\left(z_{\\hat{i}}, z_{\\hat{j}}\\right).$\nWe refer the above representation as PointNet-NTK1. As shown in Corollary 3.4 below, PointNet-NTK1 is a valid Charon-Trouv\u00e9 type kernel. From the neural tangent theory of view, PointNet-NTK1 in Equation (13) has two infinite-width neural networks on positional and Grassmannian components separately, and then aggregates information from the neural networks by element-wise product of the two neural tangent kernels."}, {"title": "Corollary 3.4.", "content": "In the limit of resolution going to infinity, neural tangent kernels \u2299pos and \u2299G are continuous positive definite kernels on positions and tangent planes, respectively. The varifold kernel\n$\u0398_{\\text {varifold }}=\\Theta_{\\text {pos }} \\odot \\Theta_{\\mathrm{G}}$ is a positive definite kernel on $R^{n} \\times \\breve{G}(d, n)$ and the associated RKHS W is continuously embedded into $C_{0}(R^{n} \\times \\breve{G}(d,n))$.\nThe other way to define a varifold representation is by treating each point as a 6-dimensional feature\nP\u2081 = {x, z\u00ee } \u2208 R6. In this case, a single neural tangent kernel corresponding to an infinite-width\nneural network can be used, i.e.,\n$\\Theta_{\\text {varifold }}^{(L)}\\left(p_{\\hat{i}}, p_{\\hat{j}}\\right)=\\Theta^{(L)}\\left(\\{x_{\\hat{i}}, z_{\\hat{i}}\\}, \\{x_{\\hat{j}}, z_{\\hat{j}}\\}\\},$\nWe refer it as PointNet-NTK2. Since PointNet-NTK2 does not compute the positional and Grassman-nian kernels separately, it is computationally cheaper than PointNet-NTK1. It cannot be associated in the limit with a Charon-Trouv\u00e9 type kernel, in contrast with PointNet-NTK1, but it remains theoretically well grounded because the explicit coupling of positions and normals is a key aspect of the theory of varifolds that provides strong theoretical guarantees (e.g., convergence, compactness, weak regularity, second-order information, etc.). Furthermore, PointNet-NTK2 falls into the category of neural networks proposed for point clouds [7, 8] that treat point positions and surface normals as 6-feature vectors, and thus PointNet-NTK2 is a natural extension of current neural networks practices for point clouds.\nPointNet-NTK1 and PointNet-NTK2 in Equations (13) and (14) are computing NTK values between two points pa and p\u2081. The above forms can compute only pointwise-relationship in a single point cloud. However, in many point cloud applications, two or more point clouds need to be evaluated. Given the set of point clouds S, one needs to compute a Gram matrix of size \u00een \u00d7 n \u00d7 m \u00d7 m, which is computationally prohibitive in general. In order to reduce the size of the Gram matrix, we aggregate information by summation/average in all elements of varifold, thus forming an \u00een \u00d7 \u00een matrix, i.e.,\n$\\Theta^{\\text {varifold }}\\left(s_{i}, s_{j}\\right)=\\sum_{\\hat{i}\\langle m} \\sum_{\\hat{j}\\\\Theta^{\\text {varifold }}\\left(p_{\\hat{i}} \\in s_{i}, p_{\\hat{j}} \\in s_{j}\\right).$\nAnalogous to Equation (3), the varifold representation varifold can be used as a shape similarity metric between two sets of point clouds si and sj. The varifold metric can be computed as follows\n$||s_{i} - s_{j} ||_{\\text {varifold }}=\u0398^{\\text {varifold }}\\left(s_{i}, s_{i}\\right)-2 \u0398^{\\text {varifold }}\\left(s_{i}, s_{j}\\right)+\u0398^{\\text {varifold }}\\left(s_{j}, s_{j}\\right).$"}, {"title": "Experiments", "content": "Dataset and experimental setting. We evaluate the varifold kernel representations and conduct comparisons on three different sought-after tasks: point cloud based shape matching between two different 3D meshes, point cloud based few-shot shape classification, and point cloud based 3D shape reconstruction. The details of each experiment setup are available at Appendix A.1, and the high-level pseudo-codes for each task are available at Appendex A.4. For ease of reference, we below shorten PointNet-NTK1, PointNet-NTK2, Chamfer distance, Charon-Trouv\u00e9 varifold norm and Earth Mover's distance as NTK1, NTK2, CD, CT and EMD, respectively."}, {"title": "Shape matching", "content": "To evaluate the surface representation using neural varifolds and make comparison with existing shape similarity metrics, synthetic shape matching experiments are conducted. We train MLP networks with 2 hidden layers with width of 64 and 128 units respectively. These networks use various shape similarity metrics as loss functions to deform the given source shape into the target shape (more details are available at Appendix A.1.1).\nFigure 1 shows five examples of shape matching based on various shape similarity metric losses. The neural network trained with CD captures geometric details well, except for the airplane. For hippocampi, CD over smoothes sharp edges; and for the bunny, it over smoothes the ears. While CD matches airplane wing shapes, it is noisier than CT, NTK1, and NTK2 methods. The EMD-trained network performs well on the dolphin shape but struggles with geometric details and surface consistency for other shapes, likely due to insufficient parameters for the transportation plan. More iterations and a lower convergence threshold make training inefficient. Networks trained with NTK1 and NTK2 metrics penalise broken meshes and surface noise, resulting in better mesh quality. NTK2"}, {"title": "Few-shot shape classification", "content": "In this section, the proposed NTKs are firstly compared with the current state-of-the-art few-shot classification methods on the ModelNet40-FS benchmark [26]. ModelNet40-FS benchmark [26] divided different shape categories in ModelNet40 datasets for pre-training the network with 30 classes and then evaluated few-shot shape classification on 10 classes. The experiment was conducted in the standard few-shot learning setup, i.e. N-way K-shot Q-query. The definition of N-way K-shot Q-query is available at Appendix A.1. Table 2 shows the shape classification results on two different few-shot classification setups, i.e., 5way-1shot-15query and 5way-5shot-15query. In the case of the 5way-1shot classification, the current state-of-the-art method PCIA achieves the best results by"}, {"title": "Shape reconstruction", "content": "Shape reconstruction from point clouds is tested for NTK1, SIREN, neural splines, and NKSR. NTK2 is excluded as it is unsuitable for this task. Implementation details are in Appendix A.2. Reconstruction quality is evaluated with CD and EMD metrics. Figure 2 shows examples (e.g., airplane and cabinet) with 2048 points. NTK1 performs better in surface completion and smoothness. Additional visualizations are in Appendix A.6.\nQuantitatively, Table 4 shows the mean and median of using the CD and EMD for 20 shapes ran-domly selected from each of the 13 different shape categories in the ShapeNet dataset. For the CD, NTK1 shows the best aver-age reconstruction results for the airplane, cabinet, car and vessel categories; SIREN shows the best reconstruction results for the chair, display and phone categories; and the neural splines method shows the best reconstruction results for the rest 6 categories. NTK1 based reconstruction achieves the best lowest mean EMD for vessel and cabinet, while neural splines and SIREN achieve the lowest mean EMD for 7 and 5 categories, respectively. NKSR does not achieve the lowest mean CD and EMD for all the categories. In addition, the shape reconstruction results with different number of points (i.e., 512 and 1024) are available at Appendix A.5.4.\nSIREN shows the lowest distance for both CD and EMD followed by NTK1. Surprisingly, the neural splines method underperforms in both the CD and EMD when we consider all the 13 categories. The performance of NTK1 on shape reconstruction is clearly comparable with these state-of-the-art methods. This might be counter-intuitive as it regularises the kernel with additional normal information, this is probably because there is no straightforward way to assign normals on the regular grid coordinates, where the signed distance values are estimated by the kernel regression."}, {"title": "Limitations", "content": "While the proposed neural varifold has advantages over standard baselines, it has limitations. First, it is based on the simpler PointNet architecture. Future research should explore its performance with more advanced architectures like graph convolutions or voxelised point clouds. Second, the quadratic computational complexity of the kernel regime poses a challenge for large datasets. Kernel approximation methods, such as Nystrom approximation, could reduce this complexity, and their performance compared to exact kernels should be evaluated."}, {"title": "Appendix", "content": "A.1 Experimental setup\nA.1.1 Shape matching\nFor point cloud based shape matching, MLP networks consisting of 2 hidden layers (with width size of 64 and 128, respectively) were trained for computing displacement between two shapes, such that one can deform the source shape to the target shape. The neural networks were trained with different shape similarity metric losses including neural varifold. Point clouds of the given shapes were extracted by collecting the centre of triangular meshes of the given shapes, and the corresponding normals were computed by cross product of two edges of the meshes. The first example is deforming the source unit sphere into the target dolphin shape; the second is matching two different cup designs; the third is matching between two hippocampi; the fourth is the shape matching bewteen sphere and Stanford bunny; and the fifth is the shape matching between two different designs of airplane. The data is acquired from the PyTorch3D, SRNFmatch and KeOps GitHub repositories [27, 28, 29]. This experiment evaluates how well the source shape can be deformed based on the chosen shape similarity measure as the loss function. A simple 3-layer MLP network was solely trained with a single shape similarity measure loss, with the learning rate fixed to 1E-3 and the Adam optimiser. The network was trained with popular shape similarity measures including the CD (Chamfer distance), EMD (Earth Mover's distance), CT (Charon-Trouv\u00e9 varifold norm), and the proposed neural varifold norms (NTK1 and NTK2). In the case of CD and EMD, we followed the same method used for shape reconstruction. For varifold metrics, we used Equation (16); note that it is a squared distance commonly used for optimisation. For the numerical evaluation as a metric in Table 1, the square-root of Equation (16) was used. To be consistent with shape classification experiments, we chose the 5-layer NTK1 and 9-layer NTK2 to train and evaluate the similarity between two shapes. The detailed analysis for the role of the neural network layers on shape matching is available at Appendix A.5.2. The final outputs from the networks were evaluated with all of the shape similarity measures used in the experiments.\nA.1.2 Few-shot shape classification\nThe ModelNet40-FS dataset [26] was used in the case of evaluating few-shot learning capability of neural varifold kernels (NTK1 and NTK2) with popular few-shot learning methods including Prototypical Net [30], Relation Net [31], PointBERT [32], and PCIA [26]. The ModelNet40-FS dataset [26] consists of 30 training and 10 unseen classes for training the backbone network and evaluating few-shot shape classification. The implementation of the baseline methods and backbone networks is based on [26]. The computation of the neural varifold kernels (NTK1 and NTK2) is based on the neural tangent library [33]. In this experiment there are two different versions of NTK1 and NTK2s used. First of all, NTK1 and NTK2 are directly computed from the original point cloud features (i.e., positions and their normals). As few-shot learning is usually based on pre-trained neural networks, NTK1 (DGCNN) and NTK2 (DGCNN) are computed from point-wise feature extracted from the backbone Dynamic graph convolutional neural network (DGCNN). DGCNN [6], used in the experiments, consists of 4 EdgeConv layers [26]. The point-wise features are defined as the concatenation of the convolutional features extracted from all 4 EdgeConv layers of the DGCNN. Furthermore, global features are defined as the max-pooling of the point-wise features.\nThe evaluation was conducted using the standard few-shot classification setup: N-way K-shot Q-query. In this setup, N-way refers to the number of classes used for training and evaluation; K-shot indicates the number of samples per class used for training; and Q-query specifies the number of samples per class used for evaluating the classification accuracy. All methods are evaluated in two different few-shot learning scenarios: 5way-1shot-15query and 5way-5shot-15query. It is important to note that the reported accuracy in Table 2 represents the average accuracy and its 95% confidence intervals for 700 test cases (i.e., 700 test cases of N-way K-shot 15query).\nIn addition, we evaluate the scenario when pre-training data/models are not available. In this experimental setup, each method was also trained with a varying number of training samples per class, ranging from 1 to 50, and we evaluated their performance on the full ModelNet10/40 validation datasets. The number of 1024 points and their corresponding normals for each object were sampled from the original meshes of the Princeton ModelNet benchmark [34]. The proposed neural varifold methods are compared with popular neural networks on point clouds including PointNet [7], DGCNN\nA.1.3 Shape reconstruction\nLastly, for shape reconstruction from point clouds, ShapeNet dataset [35] was used. In particular, we followed the data processing and shape reconstruction experiments from [36], i.e., 20 objects from the individual 13 classes were randomly chosen and used for evaluating the shape reconstruc-tion performance. For each shape, 2048 points were sampled from the surface and used for the reconstruction. Our approach was compared with the state-of-the-art shape reconstruction methods including Neural Splines [36], SIREN [37] and neural kernel surface reconstruction (NKSR) [38]. To be consistent with existing point cloud based shape reconstruction literature, CD and EMD were used to evaluate each method. Unlike CD, EMD has a number of different implementations for solving a sub-optimisation problem about the transportation of mass. In this study, we borrowed the EMD implementation code from [39]. In the experiment, we fixed the number of NTK1 network layers as 1. This is because there is no significant performance change when different number of network layers is used. The shape reconstruction using neural varifold is heavily influenced by the approaches from kernel interpolation [40] and neural splines [36]. The implementation details are available at Appendix A.2. In addition, the shape reconstruction results with different number of points (i.e., 512 and 1024) are available at Appendix A.5.4. The visualisation of the ShapeNet reconstruction performance by all the methods compared is available at Appendix A.6."}, {"title": "Kernel based shape reconstruction", "content": "Consider a set of surface points X = {x1,\u2026,Xk} and their corresponding normals Z =\n{21,\u2026, zk} sampled on an unknown surface M, i.e., X C M. Using an implicit surface rep-resentation, all x in M satisfy f(x) = 0 for some suitable function f. The best way to approxi-mate the function f is to generate off-surface points and to interpolate the zero iso-surface. Given\nY = {Y1,\u2026, Yk }, \u2200y\u00ee = 0 and the distance parameter d, we define X\u2081 = {x1-8z1,\uff65\uff65\uff65,Xk-dzk},\nX+ = {x1 + 821,\u00b7\u00b7\u00b7, xk + dzk}, V5 = {\u22128,\u00b7\u00b7\u00b7, -8}, and Y = {8,\u00b7\u00b7\u00b7, 8} in a similar manner.\nTaking the set unions X = XU X\u00bf\u00af\u00af UX, Z = ZUZU Z and Y = YU YU, the training\ndata tuple (Xtrain, Ytrain) = ({X, Z}, \u0176) (cf. symbols Xtrain and Ytest are used for multi point\nclouds) can be used to obtain the implicit representation of the surface.\nLet us define regular voxel grids Xgrid on which all the extended point clouds & lie. Note that there is no straightforward way to define normal vectors on the regular voxel grids, which are required for PointNet-NTK1 computation. Here, we assign their normals Zgrid as the unit normal vector to z-axis. Then the signed distance corresponding to the regular grid Xtest = {Xgrid, Zgrid} can be computed by kernel regression with neural splines or PointNet-NTK1 kernels K(Xtrain, Xtrain) and\nK(Xtest, Xtrain), i.e.,\n$Y_{\\text {test }}=K(X_{\\text {test }}, X_{\\text {train }})[K(X_{\\text {train }}, X_{\\text {train }})+\\lambda I]^{-1} y_{\\text {train }},$\nwhere Ytrain and Ytest are the signed distances for the extended point clouds and the regular grids, respectively. With the marching cube algorithm in [41, 42], the implicit signed distance values on the regular grid with any resolution can be reformulated to the mesh representation.\nShape classification with the full ModelNet dataset\nThe overall shape classification accuracy with neural varifold and the comparison with state-of-the-art methods on both ModelNet10 and ModelNet40 are given in Table 5, where the entire training data is used. The table shows that the finite-width neural network based shape classification methods (i.e., PointNet, PointNet++ and DGCNN) in general outperform the kernel based approaches, i.e., CT,"}, {"title": "Pseudo-code for PointNet-NTK Computation and Its Applications in Shape Matching, Classification, and Reconstruction", "content": "Algorithm 1 PointNet-NTK Computations\nRequire: si = {{X1, Z1},\u2026\u2026, {Xm, Zm}}, $j = {{1,21},\u2026\u2026, {\u00c2m, zm}}, N > 0\nif PointNet-NTK1 then\nX, X \u2190 {X1,X2,\u00b7\u00b7\u00b7, Xm}, {X1,X2,\u2026\u2026, \u00c2m}\nZ, \u017b\u2190 {Z1, Z2,\u2026\u2026, zm}, {21, 22, \u2026\u2026\u2026, zm}\nPos + Algorithm 2 (X, X, N)\nnor + Algorithm 2 (Z, 2, N)\nvarifold \u2190 Posnor\nelse if PointNet-NTK2 then\nP\u2190 {CONCAT(x1, 21),\u00b7\u00b7\u00b7, CONCAT(Xm, Zm)}\nP\u2190 {CONCAT(1, 21),\u2026\u2026\u2026, CONCAT(\u00c2m, 2m)}\nvarifold\nend if\nreturn varifold\n\u2190 Algorithm 2 (P, P, N)\nRemark: As an example, X \u2208 Rm\u00d73 is formed by concatenating all x \u2208 {X1,X2,\u2026\u2026,XmAlgorithm 2 NTK Corresponding to N-layer Infinite-width MLP with ReLU Activation*\nRequire: X, X, N > 0\nInitialise \u0398(0) = \u2211(0) = XXT, dx (0) = (d{\u00ba), d\u00ba\u00ba),...) = diag(XXT),\ndx (0) = (d\u00ba), \u00e2\u00ba),...) = diag(XX)\nfor h1 to N do\n\u03c9\u03c2 (-1) 2-1)/(-1) (-1), i, j = 1,2,..., length(dx\n\u2190\nd(-1) + Fo((-1), d(-1), (-1)), ,d), where (Fo),\n\u03a3(h) + F1(2(-1), d-1), d-1)), where\n(h-1)\nd(h-1\n(F1)=1 = 1-1 (-1) (-1) (1-(-1))2(-1)\n\u0398(h) + (h) + (4)-114\nd \u2190 dxd\nend for\nreturn(h)\n* Although Algorithm 2 assumes the NTK representation corresponding to N-layer MLP with ReLU activation [44, 45, 33], several popular neural network layers have their corresponding closed-form NTK representations [33, 43, 46].\nAlgorithm 3 Shape Matching\nRequire: f (\u00b7; 0), S, T, nmax 0, Niter 0\nwhile nmax > Niter do\nvs \u2208 RISI\u00d73 vertices of S\nds \u2190 f(vs; 0) displacements between S and T\n\u00a7 \u2190 new source shape with deformed vertices vs + ds\nX5,25 \u2190 sample surface points and corresponding normals from \u015c\nXT, ZT\u2190 sample surface points and corresponding normals from T\n$5\u2190 {x5, 25}\nST {XT, ZT}\nCompute ||S5 - ST || varifold in Equation (16) using Algorithm 1\nBackpropagate and update 0\nSS\nNiter Niter + 1\nend while\nRemark: Here f (\u00b7; 0) is a 2-layer MLP neural network, \u03b8 is the weights of the neural network f. S and T are the source and target shapes, respectively.\nAlgorithm 4 Shape Classification\nRequire: Xtrain = {$1,82,\u2026\u2026,81}, Ytrain = {Y1, Y2,\u2026, Y\u0131}, Xtest = {S1+1, Sl+2, ,Sn},\nN > 0, where si = {P1,P2,\u2026\u2026, Pm }, i = 1, 2, ..., \u03b7\nfor i 1 to l do\nfor j 1 to l do\nvarifold (si, Sj) \u2190 Algorithm 1 (si, sj, N)\nAggregate points varifold im im varifold (p; \u2208 si, P\u00f4 \u2208 sj)\nend for\nend for\nfor i 1 + 1 to n do\nfor j + 1 + 1 to n do\nvarifold (Si, Sj) + Algorithm 1 (si, sj, N)\nAggregate points testo varifold im varifold (pz \u2208 Si, P\u00f4 \u2208 Sj)\nend for\nend for\nypredvarifold (X test, Xtrain) (varifold (Xtrain, Xtrain) + AI)\u00af\u00b9ytrain\nAlgorithm 5 Shape Reconstruction+\nRequire: X = {x1,\u00b7\u00b7\u00b7 ,Xk}, Z = {21,\u2026, zk}, Y = {Y1,\u2026\u2026, Yk}, 8, Xgrid, Zgrid, N > 0\nEnsure: y = 0 and \u03b4 > 0\nX5, X+ \u2190 {x1 \u2013 8z1,\u00b7\u00b7\u00b7, Xk \u2014 Szk}, {x1 + 821,\u00b7\u00b7\u00b7,Xk + \u03b4zk}\nV5, V+ \u2190 {\u22128,\u00b7\u00b7\u00b7, -\u0431}, {\u03b4,\u00b7\u00b7\u00b7, \u03b4}\nX, Z, Y\u2190 XU XU X, Z UZ UZ, VUV UVT\nXtrain, Ytrain \u2190 {X, 2}, \u0178\nvarifold (Xtrain, Xtrain) \u2190 Algorithm 1(Xtrain, Xtrain, N)\nXtest \u2190 {Xgrid, Zgrid}\nvarifold (Xtest, Xtrain) \u2190 Algorithm 1 (Xtest, Xtrain, N)\nypred = varifold (Xtest, Xtrain) [varifold (Xtrain, Xtrain) + AI]-1Ytrain\nSrecon \u2190 Marching cube algorithm [42] (Xtest, pred)\nPlease refer to a more detailed explanation of terms and equations in Appendix A.2.\nA.5 Ablation analysis\nA.5.1 Neural varifolds with different number of neural network layers\nThis section shows the shape classification results based on different number of neural network layers. In this experiment, we randomly choose 5 samples per class on the training set of ModelNet40 and evaluate on its validation set. As shown in Section 4, we iterate the experiments 20 times with different random seeds. The key concept of the PointNet [7] is the permutation invariant convolution operations on point clouds. For example, MLP or Conv1D with 1 width convolution window is permutation invariance. In this experiment, we choose different number of either MLP or Conv1D layers, and check how it performs on the ModelNet40 dataset. As shown in Table 6, the classification accuracy of NTK1 with Conv1D operation is lower in comparison with the ones with MLP layers. In particular, 5-layer and 7-layer MLPs show similar performance with the NTK1 architecture, i.e., 69.29% classification accuracy. In order to reduce the computational cost, we recommend fixing the number of layers in NTK1 to 5. In the case of NTK2, its performance increases as more layers are being added for it with both MLP and Conv1D operations. Furthermore, NTK2 with Conv1D operation shows slightly higher classification accuracy in comparison with the ones with MLP layers. The percentage of the performance improvement becomes lower as the number of layers increases. In particular, 9-layer MLP versus 7-layer MLP for NTK2 only brings 0.2% improvement; therefore, it is computationally inefficient to increase the number of layers anymore. Although NTK2 with 9-layer Conv1D achieves 0.08% higher accuracy than the one with 9-layer MLP, NTK2 with 9-layer MLP rather than Conv1D is used for the rest of the experiments in order to make the architecture consistent with the NTK1.\nA.5.2 Shape matching with different number of neural network layers\nTable 7: Ablation analysis for shape matching with respect to different number of neural network layers within NTK psueo-metrics. The number inside of the brackets (\u00b7) indicates the number of layers used for computing the NTK pseudo-metrics.\nIn this section, the behavior of the NTK pseudo-metrics with respect to different number of layers is evaluated. Note that the neural network width is not considered in this scenario as all pseudo-metrics are computed analytically (i.e., infinite-width). In this study, simple shape matching networks were trained solely by NTK psuedo-metrics with different number of layers. Table 7 shows that the shape matching network trained with the 5-layer NTK1 metric achieves the best score with respect to CD, EMD, CT and NTK2 metrics, while the one with the 9-layer NTK1 metric achieves the best score with respect to CT and NTK1 metrics. This is in accordance with the ablation analysis for shape classification, where 5-layer NTK1 achieves the best classification accuracy in the ModelNet10 dataset. In comparison, NTK2 shows a mixed signal. The shape matching network trained with the 1-layer NTK2 metric achieves the best outcome with respect to Chamfer, CT and NTK2 metrics, while the one trained with the 9-layer NTK2 achieves the best results with respect to EMD and CT metrics. The network trained with 5-layer NTK2 shows the best result with respect to the NTK1 metric. This is not exactly in accordance with respect to shape classification with the NTK2 metric, where the shape classification accuracy improves as the number of layers increases. However, training a neural network always involves some non-deterministic nature; therefore, it is yet difficult to conclude whether the number of neural network layers is important for improving the shape matching quality or not.\nA.5.3 Shape classification with different neural network width\nIn this section, we analyse how the neural network width can impact on shape classification using the 9-layer MLP-based NTK2 by varying the width settings from 128, 512, 1024 and 2048 to infinite-width configurations. We trained the model on 5 randomly sampled point clouds per class from the ModelNet10 training set. The evaluation was carried out on the ModelNet10 validation set. This process was repeated five times with different random seeds, and the average shape classification accuracy was computed. Notably, NTK1 was excluded from this experiment due to the absence of a finite-width neural network layer corresponding to the elementwise product between two neural tangent kernels of infinite-width neural networks. The results presented in Table 8 demonstrate that the analytical NTK (infinite-width NTK) outperforms the empirical NTK computed from the corresponding finite-width neural network with a fixed width size. Furthermore, computing empirical NTK with respect to different length of parameters is known to be expensive as the empirical NTK is expressed as the outer product of the Jacobians of the output of the neural network with respect to the parameters. The details of the computational complexity and potential acceleration have been studied in [47]. However, if the finite-width neural networks are trained with the standard way instead of using empirical NTKs on a large dataset (e.g., CIFAR-10), then finite-wdith neural networks can outperform the neural tangent regime with performance significant margins [43, 24]. In other words, there is still a large gap understanding regarding training dynamics between the finite-width neural networks and their empirical neural kernel representations.\nA.5.4 Shape reconstruction with different point cloud sizes\nIn this section, we compare shape reconstruction results with different point cloud sizes, i.e., 512, 1024 and 2048 points. As indicated in Tables 4, 9 and 10, NTK1 and neural splines show that the quality of the reconstructions is degraded as the number of points decreases. For NKSR, its reconstruction quality becomes worse as the number of point clouds decreases for most categories, but few categories (i.e., cabinet and vessel) show the opposite trend. In the case of SIREN, the convergence of the SIREN network plays more important role for the shape reconstruction quality. For example, the shape reconstruction results by SIREN on the airplane category show that the shape reconstruction with 1024 points is better than that with 2048 points. This is due to the non-deterministic nature of DNN libraries, i.e., it is difficult to control the convergence of the SIREN\nnetwork with our current experimental setting 104 epochs. Note that the SIREN reconstruction is computationally much more expensive (around 20~30 minutes) than either the NTK1, neural splines or the NKSR approach (around 1~5 seconds).\nA.6 Visualisation of ShapeNet reconstruction results\nIn this section, we present additional visualisations of shape reconstruction outcomes obtained through three baseline methods (i.e., SIREN, neural splines, and NKSR), along with the proposed NTK1 method, across 13 categories of ShapeNet benchmarks. Five shape reconstruction results are illustrated for each category. Specifically, Figure 3 showcases examples from the Airplane, Bench, and Cabinet categories. Figure 4 exhibits five instances of shape reconstruction outcomes for the Car, Chair, and Display categories. Moving on to Figure 5, it displays examples from the Lamp, Speaker, and Rifle categories. Similarly, Figure 6 demonstrates five instances of shape reconstruction results for the Sofa, Table, and Phone categories. Finally, Figure 7 focuses on the shape reconstruction results for the Vessel category."}]}