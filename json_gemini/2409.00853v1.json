{"title": "JaxLife: An Open-Ended Agentic Simulator", "authors": ["Chris Lu", "Michael Beukman", "Michael Matthews", "Jakob Foerster"], "abstract": "Human intelligence emerged through the process of natural selection and evolution on Earth. We investigate what it would take to re-create this process in silico. While past work has often focused on low-level processes (such as simulating physics or chemistry), we instead take a more targeted approach, aiming to evolve agents that can accumulate open-ended culture and technologies across generations. Towards this, we present JaxLife: an artificial life simulator in which embodied agents, parameterized by deep neural networks, must learn to survive in an expressive world containing programmable systems. First, we describe the environment and show that it can facilitate meaningful Turing-complete computation. We then analyze the evolved emergent agents' behavior, such as rudimentary communication protocols, agriculture, and tool use. Finally, we investigate how complexity scales with the amount of compute used. We believe JaxLife takes a step towards studying evolved behavior in more open-ended simulations.", "sections": [{"title": "Introduction", "content": "Human capabilities, culture and intelligence have emerged from open-ended evolution on Earth (Darwin, 1859). It follows that a multi-billion-year full-fidelity physics simulation of Earth could produce similarly-capable beings. However, such an endeavor is clearly computationally infeasible. To reduce computational costs, one can reduce the fidelity of the simulation, raising the question of which components are necessary for the desired behavior. To answer this, we must specify what behavior or capabilities we would like to potentially emerge from the simulation.\nOne such objective is to evolve agents that are capable of advanced reasoning and tool-use (Parisi, 1997). After all, many of humanity's recent achievements involve mathematical reasoning and technical prowess. It may be the case that low-level control and perception\u2014aspects that many simulations aim to reproduce (Dittrich et al., 2001; Hutton, 2002)\u2014are not necessary to evolve these capabilities. Indeed, even evolving morphologies, as many simulations do (Sims, 1994; Silveira and Massad, 1998; Spector et al., 2007; Bessonov et al., 2015; Pathak et al., 2019; Heinemann, 2024), may not be necessary for the evolution of advanced reasoning.\nFor this reason, we focus on the evolutionary advancements that make humans different from other animals. Recent trends in anthropology focus on the idea of \"cultural accumulation\" (Henrich, 2015) as being the primary evolutionary origins of human intelligence. Cumulative culture is characterized by large amounts of social learning and the persistence and continuous advancement of shared knowledge. Muthukrishna et al. (2018) builds a simple computational model of the emergence of cultural accumulation and finds that it can be facilitated by a small bias towards social learning: If indeed this is humanity's key defining feature, it may not be difficult to replicate in silico.\nOur work is not the first to investigate the emergence of intelligent behavior. Prior works have modeled the emergence of cumulative culture through agent-based models (Muthukrishna et al., 2018; Lu et al., 2022b, ABMs), which are high-level statistical models of agents. However, ABMs have not produced agents that are capable of advanced reasoning and instead model simplified high-level evolutionary dynamics. Similarly, other work in deep reinforcement learning has produced emergent social behaviors (Johanson et al., 2022), communication (Chaabouni et al., 2021), and tool-use (Baker et al., 2019) in games. Each of these settings suffers from the same failure mode: Their environments are not expressive enough to produce truly open-ended expression. For example, agents in these environments cannot reasonably communicate about mathematics or build advanced machines.\nOur work aims to address this gap by allowing high-level agents to interact with and program composable robots that can express useful and meaningful Turing-complete behaviors. We present JaxLife, an artificial life simulator capable of expressing meaningful, Turing-complete behaviors. Our simulator is written entirely in JAX (Bradbury et al., 2018), meaning it can run on hardware accelerators and easily scale to multiple devices. Our contributions are as follows:\n1. We design and implement an agentic simulator where evolved agents must survive, and are able to interact and program robots. We show that these robots can be programmed as useful tools and express meaningful Turing-complete dynamics.\n2. We demonstrate the emergence of rudimentary agriculture, tool use, and communication.\n3. We provide initial estimates for how important features of this simulation scale with the amount of compute provided, enabling rough estimates of expected future behaviors."}, {"title": "Simulation Description", "content": "Our simulation consists of three primary components, terrain, agents, and robots. At every step, all agents simultaneously observe the area around them and perform a set of actions. These actions may influence other agents, the robots, or the terrain. Robots are programmable systems with the same action space as agents. Agents evolve and change their behavior through the evolution of their controlling neural networks, while the terrain controls how difficult certain actions are and how much energy is available. Due to the limited amount of energy, there is selection pressure and agents that tend to eat and reproduce more will tend to pass on their genes more frequently. Agents can also control the terrain by terraforming it, thereby changing its properties. Finally, robots are systems that do not evolve, but can be programmed by agents. These robots possess a large amount of potential complexity and can execute useful behaviors to help agents survive."}, {"title": "Terrain", "content": "The terrain is divided into a grid of cells, each cell possessing several attributes. The primary attributes of each cell are how much energy it has and an energy gain amount, indicating how much energy each cell gains per timestep. Each terrain cell also has a cost associated with each agent action. Finally, each cell has an associated information bit that can be read from and written to by bots but not agents.\nWe implement a weather and climate-like system. At every timestep, the base terrain is slightly altered by adding a small number to the angles used to generate the Perlin noise map (Perlin, 1985). The attributes of each cell also slowly regress to this base state. The speed of this is proportional to the cell's maximum energy amount. This, for instance, can simulate long-term effects such as continental shifts.\nUsing this system, we can represent slowly changing landscapes, as well as the natural tendency of nature to return to its base state if not continually maintained. Finally, since the regression speed is different for different regions, the map contains high-maximum energy areas that quickly revert to their base state and lower-energy areas where changes the agents make have more permanence."}, {"title": "Agents", "content": "Agents require energy to survive and evolve through the process of natural selection. Agents can gain energy by performing the EAT action on terrain cells that have energy. Energy is consumed when performing any action (with the"}, {"title": "Network Architecture", "content": "We parametrize agents using neural networks that process observations and output an action vector (see Fig. 2). All actions can be performed simultaneously, and the strength of the action's effect is determined by the magnitude of the corresponding entry. The network architecture consists of different encoders for agents, robots, and the terrain. The entity embeddings are processed by a self-attention and multi-headed attention block (Vaswani et al., 2017). The result is concatenated with the terrain features and passed to an LSTM (Hochreiter and Schmidhuber, 1997) to incorporate memory. While the agent's networks do not change during their lifetimes, due to the use of a recurrent network, they are able to adapt their behavior when encountering the same observation multiple times."}, {"title": "Reproduction", "content": "Since crossover for fixed-topology neural networks is challenging (Haflidason and Neville, 2009; Pretorius and Pillay, 2024), our agents reproduce asexually, and must have a minimum amount of energy before they can execute the REPRODUCE action. Reproduction copies the agent's weights to a child agent, and random perturbations are also added to these weights. We reinitialize the population-with random networks-if all agents die."}, {"title": "Robots", "content": "We design the robots to have a similar action space to the agents; however, since robots do not reproduce, and we wish them to be programmable, how they obtain their actions must be different to the agents. To simulate the technological advantage of machines, robots update multiple times for every agent update cycle and do not use energy. We decide upon the following scheme and showcase its theoretical complexity and practical uses in the next section.\nEach robot has a program and memory, each of the same size $N_{prog}$. At every step, each robot receives messages from the two closest entities to it, breaking ties using the x-position. This message is the SELF MESSAGE of an agent or the memory of a bot; each of these is also of size $N_{prog}$.\nThe program is a description of a function $f : \\mathbb{R}^{N_{prog}} \\times \\mathbb{R}^{N_{prog}} \\rightarrow \\mathbb{R}^{N_{prog}}$, where the action $a = f(mem, m_1, m_2)$ is the action performed. This action, if the WRITE_SELF_MESSAGE entry is set, can also update the robot's memory. Whenever another robot or agent sends this robot a message, it is interpreted as changing the robot's program.\nWe note here that the dimension of these messages $N_{prog}$ is always more than the action's dimensionality $N_{act}$, therefore, only the first part of the output is used as the action. The final entry, in particular, is interpreted as solely an information bit that allows robots to store and manipulate information.\nInstructions We have the following instructions:\n\u2022 COPY: $f(mem, m_1, m_2) = m_1$\n\u2022 NOOP: $f(mem, m_1, m_2) = mem$\n\u2022 PRODUCT: $f(mem, m_1, m_2) = mem \\odot m_1$\n\u2022 FMA: $f (mem, m_1, m_2) = mem \\odot m_1 + m_2$\n\u2022 XOR: $f (mem, m_1, m_2) = (2 (mem^i \\oplus m_1) - 1) \\odot m_1 + (1 - m_1) mem$, where $\\oplus$ is logical XOR, and the superscript i indicates the information bit of the message.\n\u2022 NAND: $f (mem, m_1, m_2) = 1 - (m_1 \\odot m_2)$\nThe final operation, LOOKUP, uses the information bit from mem, $m_1$ and $m_2$ to construct a 3-bit number, from 0 to 7 inclusive, and uses this index to look up into a table as specified by the program. The result is written to the information bit of the action and replaces the bot's current memory if"}, {"title": "Analyzing Environment Complexity", "content": "Here we discuss the capabilities of the robots in JaxLife. We begin by illustrating useful and practical bots. We then go on to prove our simulation is Turing-complete (Turing, 1936), by showing that it can execute Rule 110 (Cook et al., 2004; Cook, 2009). Finally, we describe how robots can also compute arbitrary boolean functions."}, {"title": "Useful Machines", "content": "In practice, we expect the programs created by agents to be relatively simple at first. However, to illustrate what is practically possible, we manually design some useful robots that can easily be constructed, see Fig. 3.\nAutomated Terraforming These robots are programmed to terraform a large region of the map. This can be implemented by programming robots to move in a consistent direction (e.g. down the map), and perform the TERRAIN_ENERGY_GAIN action. This leads to the terrain becoming more fertile- leading to more food over time.\nPatrolling & Oscillating Robots can also execute more complicated oscillatory behavior, by using the terrain's information bits as waypoints to oscillate over an arbitrary line. This is achieved by reading the current terrain bit, and using the XOR instruction, which inverts the action when paired with an appropriate $m_1$ sent by the closest agent.\nTransportation Robots can also be used to transport agents in a more energy-efficient manner than walking. Suppose the robot's memory is zero, except for the entries associated with MOVE_X and PUSH. The robot's program is the one defined as $f (mem, m_1, m_2) = mem \\odot m1+m2$. This means that the robot will push and move nearby agents whenever they send messages with the move and push entries being nonempty.\nCommunicating Robots can also propagate information across space. We implement this proof-of-concept by using the lookup table instruction, with the lookup table simply copying the information bit of $m_1$. Arranging the robots in a chain such that the robot to the left of it is closer than the one to the right allows the information bit to pass from the left to the right across the map."}, {"title": "Turing-Complete Computation", "content": "We now move on to proving that JaxLife can facilitate universal computation by reducing it to Rule 110-a common technique that has been used in several prior settings; for instance, in Baba is you (Rodriguez, 2019; Su, 2023), the Micron Automata Processor (Wang and Skadron, 2015) and Petri Nets (Zaitsev, 2018).\nConstructing Rule 110 Elementary cellular automata (Wolfram, 2002, ECA) are simple, one-dimensional rules that can lead to complex patterns. An ECA is defined on a grid, with an initial state in the top row, and a local transition rule that transforms the row into the next one; every time step this is applied and a new row is appended. In ECAs, every cell is binary-valued, and the local transition rule of a particular cell depends on it, as well as its left and right neighbors. Using these three binary digits a, b and c, we can construct a binary number $abc_2$ such that $0 = 000_2 \\leq abc_2 \\leq 111_2 = 7$. Each ECA is then an 8-dimensional lookup table, giving the next value of the center cell for each possible three-digit binary number. Rule 110 has the pattern described in Table 1:\nCook et al. (2004) proved that Rule 110 is capable of universal computation, i.e., that it is Turing complete. Here we describe a way in which a particular configuration of JaxLife results in an implementation of Rule 110\u2014showing that it, too, is capable of universal computation. The core idea is to use the terrain's information bit to store the previously computed rows, and to have a single row of robots act as the latest state while moving down the map.\nProgram The program has the LOOKUP_TABLE instruction bit set as 1, all other instruction bits set to zero, and the lookup table is defined as in Table 1.\nMemory The memory is empty, except for three locations:\n1. MOVE_Y = 1: In order to move in the y-direction.\n2. WRITE_TERRAIN = -1: To write the previously-computed bit to the terrain (note that +1 indicates reading and -1 indicates writing).\n3. UPDATE_MEMORY = 1: To save the updated cell state to the robot's memory."}, {"title": "Functional Completeness", "content": "Functional completeness of a set of logical operators states that all possible boolean functions can be realized by composing elements from this. Functionally complete of complete operators include {NAND}, {NOR},{OR,AND,NOT} (Enderton, 2001).\nNAND We note that one of our instructions described above the lookup table-can implement any three-bit truth table, which includes NAND between two inputs, which we refer to as the NAND instruction. We now describe a way to compose logical operators, resulting in functional completeness.\nComposition Suppose we have a vertical line of n input bots $A_1,..., A_n$. We can compute any possible function by having at most n columns of n bots each, that process these input bits, such that the final column has one bot which represents the output. This final bot could then write to the terrain. We describe now how to perform the two necessary operations, NAND and passthrough (i.e., identity).\nConsider two robots A and B in row i that contain the input bits in their information slot. Suppose robot $R_{i+1}$ is positioned such that its closest two agents are A and B. Then, by using the NAND program, it can compute A NAND B and store the result in its memory.\nTo pass bit A unchanged to the next row, suppose that bot A is closest to bot $R_i+1$; it can then use the COPY action to copy the bit unchanged (this could also be implemented using the lookup table to copy the closest robot's bit).\nTemporal Order Due to the temporal nature of our simulation, we cannot compute an arbitrary function in one step. We note that in our above construction, initially, only the input column is correct. Every step ensures that the subsequent column computes the correct function. At the end, the final bot's memory would be correct. Using these two operations, and the temporal structure, the robots in JaxLife can compute any n-variable binary-valued function for arbitrary n."}, {"title": "Results", "content": "In this section, we present the empirical results obtained when running JaxLife. We run the simulation for $2^{16}$ timesteps using a single NVIDIA A100 GPU. We first describe behaviors that we observed, with 128 agents and 32 bots, and then examine quantitative metrics of the complexity of the simulation. Finally, we observe how these results change with scaling the number of agents in the environment."}, {"title": "Emergent Behaviors", "content": "Agriculture and Terraforming: Fig. 5 shows that the agents manage to substantially modify their environment, creating structured regions in which food is produced. We find that this corresponds to a period in which the agents construct striped diagonal regions over which they travel.\nTool-Use: In Fig. 6 we visualize the behavior of the programmed bots. In particular, we find that the bots play a significant role in the stable terraforming behavior we found in Fig. 5, as they move at the same diagonal stripes as the agents while also helping with food production.\nCommunication In Fig. 8f we use \"saliency\" (i.e., the derivative of the agent's action with respect to the input (Simonyan et al., 2013)) as a measure of the use of communication. We find that, over time, agent behaviors tend to be more sensitive to their communication channels, suggesting that they can use the channel to influence each other."}, {"title": "Scaling Results", "content": "To quantitatively measure the complexity of the simulation, we consider several metrics in Figure 8.\n1. Energy Consumption: The total amount of energy available to a civilization is often considered a marker of technological advancement (Kardashev, 1964; Gray, 2020). Inspired by this, we measure the amount of energy per agent consumed by the population of JaxLife."}, {"title": "Related Work", "content": "Early instantiations of the ALife concept include Tierra (Ray, 1996) and Avida (Ofria and Wilke, 2004), which evolved computer programs that compete for finite resources. Geb (Channon, 2006) was the first simulation said to pass the activity statistics test (Bedau et al., 1998) and to be a truly open-ended system. However, all these simulations are relatively simple. Despite their simplicity, however, these simulations can also be used to study the emergence of behavior-such as associative learning and to perform controlled experiments to test various evolutionary theories (Pontes et al., 2020; Moreno and Ofria, 2022; Ferguson and Ofria, 2023).\nRecent work, often stemming from the reinforcement learning (RL) community (Johnson et al., 2016; Charity et al., 2023; Rutherford et al., 2023; Matthews et al., 2024), contains some elements of ALife simulations, and open-endedness (Stanley et al., 2017; Leibo et al., 2019; Clune, 2019) in general. One example is Neural MMO (Suarez et al., 2019), which defines a world of agents competing for a finite amount of resources. These agents are generally trained with RL, instead of competing via natural selection. XLand (Team et al., 2021) similarly defines an expressive collection of multi-agent environments, although much of the interesting variation comes in the form of tasks and worlds rather than agents. However, these environments are generally posed as relatively static learning environments for RL agents instead of environments to study evolutionary and open-ended behavior.\nOther works that are more in the spirit of traditional ALife simulations include MineLand (Yu et al., 2024), which defines a cooperative multi-agent world in Minecraft and the work by Park et al. (2023), which simulates a human-like community using pre-trained language models to interact between agents. Lenia (Chan, 2018) is a cellular automaton that can result in the evolution of a diverse range of creatures with lifelike properties from low-level building blocks. Recent hardware-accelerated ALife works include Alien (Heinemann, 2024), which simulates agents that can evolve different morphologies in a particle-based system, and Biomaker CA (Randazzo and Mordvintsev, 2023) which evolves artificial plants in a grid-based world. While both are powerful simulations, their focus is more on the evolution of lower-level dynamics as opposed to higher-level agentic behaviors."}, {"title": "Conclusion and Future Work", "content": "We introduce JaxLife, where agents must survive and evolve within a changing world, with programmable robots affording unbounded complexity. We believe JaxLife could be used to explore alternative routes to technological and cultural advancements, such as the evolution of mathematics. Using JaxLife to perform hypothesis-driven study of important questions in evolution would be a fruitful avenue for future work. For instance, we could change various hyperparameters of the simulation, or disable components such as communication, to see what effect these changes have on the final outcomes. We also note that the simulation results can vary"}]}