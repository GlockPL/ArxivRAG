{"title": "RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models", "authors": ["Haoyu Chen", "Wenbo Li", "Jinjin Gu", "Jingjing Ren", "Sixiang Chen", "Tian Ye", "Renjing Pei", "Kaiwen Zhou", "Fenglong Song", "Lei Zhu"], "abstract": "Natural images captured by mobile devices often suffer from multiple types of degradation, such as noise, blur, and low light. Traditional image restoration methods require manual selection of specific tasks, algorithms, and execution sequences, which is time-consuming and may yield suboptimal results. All-in-one models, though capable of handling multiple tasks, typically support only a limited range and often produce overly smooth, low-fidelity outcomes due to their broad data distribution fitting. To address these challenges, we first define a new pipeline for restoring images with multiple degradations, and then introduce RestoreAgent, an intelligent image restoration system leveraging multimodal large language models. RestoreAgent autonomously assesses the type and extent of degradation in input images and performs restoration through (1) determining the appropriate restoration tasks, (2) optimizing the task sequence, (3) selecting the most suitable models, and (4) executing the restoration. Experimental results demonstrate the superior performance of RestoreAgent in handling complex degradation, surpassing human experts. Furthermore, the system's modular design facilitates the fast integration of new tasks and models, enhancing its flexibility and scalability for various applications.", "sections": [{"title": "1 Introduction", "content": "Image restoration, a classical research area in computer vision, focuses on recovering high-quality images from degraded observations. Traditional methods are usually tailored to specific tasks like denoising [55, 61, 49, 29, 30, 12, 3], super-resolution [56, 34, 53, 4, 45, 47, 48], and deblurring [28, 22, 51, 32, 44, 17]. However, real-world images often suffer from multiple simultaneous degradations. For example, a low-quality image may exhibit noise, blur, and rain concurrently. There may exist complex interactions and dependencies among different degradation phenomena, and each degradation may require distinct handling methods. The combination and sequence of these methods are crucial for the final restoration outcome. Recent advancements in the field have been driven by leveraging expert knowledge and developing all-in-one models. To provide a thorough understanding of this field and clarify our motivation, we present a detailed analysis below."}, {"title": "1.1 All-in-One Models", "content": "All-in-one models [38, 31, 24, 40, 33, 14, 27, 37, 1, 25] seek to use a single framework to handle multiple degradations simultaneously. By training on multi-task datasets, these models learn to manage various restoration tasks. However, several limitations continue to impede the practicality of these models in complex real-world scenarios:\nRestricted task scope. All-in-one models often struggle to process degradations outside of their training data. Even for the same type of degradation, as shown in Figure 2 a1, these models may have difficulty effectively processing data if the degradation distribution varies between the training and testing sets. Given that existing models only cover a limited number of tasks, employing specialized single-task restoration models is often more flexible and effective.\nCompromised performance. All-in-one models often face trade-offs between generalization and restoration accuracy, as shown in Figure 1. While these models offer improved generalization across a broader range of degradation levels, their performance at specific levels may be compromised. Additionally, because they must handle multiple tasks with largely disparate degradation patterns, the performance for individual tasks may fall short, resulting in overly smoothed outputs. As illustrated in Figure 2 a2, single-task models typically outperform all-in-one models in most scenarios.\nAll-in-one models can, in fact, be integrated into an agent system comprising multiple models, thereby going beyond a single solution. Often, using task-specific models customized for particular degradations and then integrating them with an all-in-one model yields improved performance, as shown by the two examples in Figure 2 a3. This hybrid approach maintains the adaptability of all-in-one models while leveraging the strengths of specialized models."}, {"title": "1.2 Task-Specific Models", "content": "An alternative approach to using all-in-one models, which struggle to effectively address various types of degradation, is to combine several specialized task-specific models, each focusing on a specific degradation type. This modular strategy allows for a more targeted and efficient handling of the different degradations present in the input images. Superior results can be achieved because these specialized models excel in their respective areas."}, {"title": "1.2.1 Fixed or Random Execution Order", "content": "Current methods [50, 24, 14] typically detect the types of degradation in an image and apply the appropriate restoration models in a predetermined order, or manually selected by experts, or chosen at random. Nevertheless, there is a significant drawback to this approach: the processing order has a major impact on the final performance. A predetermined order, even if established by human experts, is not ideal and might fail to successfully restore the image, as demonstrated in Figure 2 b. Two primary causes can be identified for this.\nFirst, applying one restoration method can alter other degradation patterns, rendering the following restoration models ineffective. For example, in an image with haze and rain, if haze is performed first (Figure 2 b), the dehazing model may address the blur but alter the rain distribution, thereby reducing the effectiveness of the deraining model.\nSecond, removing some degradations can be challenging if other degradations have not been addressed first. A common example is the enhancement of low-light images, which often requires denoising as a pre-processing step. Without prior denoising, the results of low-light enhancement are likely to be subpar. In Figure 2 b, we can observe that without prior denoising and deraining, the performance of the dehazing model is significantly compromised.\nIn light of these findings, accurate identification of degradation patterns or careful testing of various task execution sequences is necessary for high-quality restoration. However, the search space grows significantly with the number of tasks. For example, there are 24 possible execution orders for 4 degradation types. Moreover, the number of permutations increases drastically when multiple models are available for a given task, leading to a significant rise in computational complexity."}, {"title": "1.2.2 Fixed or Random Model for a Single Task", "content": "In some scenarios, the system may opt to use a single model for a specific task or randomly select a model from a pool of available options [50]. However, this approach has significant drawbacks. Image restoration is a rapidly evolving field with various models tailored for a specific task, each with unique capabilities and areas of expertise for managing specific scenarios. Using a fixed model or randomly selecting from a pool of models to process complex degradations can lead to suboptimal results. As illustrated in Figure 2 c and Figure 1 a, different denoising models excel at different noise levels. Choosing the right model is crucial for achieving the best result.\nManually selecting the best model is impractical due to the numerous combinations of task execution orders and available models. For example, with 3 degradation types and 3 models per type, there are 162 possible combinations. Evaluating these permutations is time-consuming and labor-intensive. Consequently, we often rely on one or two experienced-based solutions, which may not achieve the desired restoration effect."}, {"title": "1.3 RestoreAgent", "content": "In response to the aforementioned challenges, we propose RestoreAgent, an autonomous and intelligent image restoration system based on a multimodal large language model (MLLM). The MLLM's exposure to vast and diverse data endows it with superior generalization capabilities and has showcased remarkable performance in visual understanding and logical reasoning [46, 35, 18, 39, 43, 6, 62]. Furthermore, its flexibility facilitates the quick addition of new tasks, the definition of desired output formats, and easier human interaction.\nOur framework offers the following functionalities:\n(1) Degradation Type Identification. RestoreAgent automatically identifies the types of degradation present in an input image and determines the corresponding restoration tasks required.\n(2) Adaptive Restoration Sequence. RestoreAgent goes beyond the constraints of predefined, human-specified model execution orders by dynamically evaluating the individual properties of each input image to decide the best sequence for utilizing the restoration models, thereby enhancing the overall efficiency of the image restoration procedure.\n(3) Optimal Model Selection. Based on the specific degradation patterns in the input image, RestoreAgent dynamically selects the most appropriate model from the available pool for each restoration task, ensuring optimal performance.\n(4) Automated Execution. Once the restoration sequence and model selection are determined, RestoreAgent autonomously executes the entire restoration pipeline without the need for manual intervention.\nTo this end, we start by defining the multi-degradation task and constructing a training dataset. This dataset includes paired degraded images (with one or more degradation types) and their ground truth (only for evaluation), along with the optimal task execution sequence and best model choice based on user-preferred goals. We then fine-tune MLLM to enable RestoreAgent to autonomously make task decisions and determine the optimal processing sequence and models. Experiments show that RestoreAgent's decision-making capabilities significantly outperform existing methods and human experts, achieving superior performance in recovering multi-degradation images. Notably, our method can quickly adapt to unseen tasks and models, such as incorporating the desnowing function in just half an hour."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Single-Task Image Restoration", "content": "In the field of single-task image restoration, numerous methods have focused on addressing specific types of image degradation. In denoising, models like DnCNN [59] and RNAN [63] have demonstrated significant effectiveness, among others. In deblurring, algorithms like DeblurGAN [28] and MIMO-UNet [13] and others stand out. For reducing JPEG artifacts, methods such as DCSC [19] and FBCNN [23] are particularly well-suited. Additionally, there are specialized methods for restoration under adverse weather conditions, including dehazing [52, 41], deraining [11, 7], and desnowing [8, 9, 5]. Each task often requires a specialized approach, leading to highly optimized algorithms that achieve sota performance for their specific targets compared to universal approaches."}, {"title": "2.2 All-in-One Image Restoration", "content": "Recent research has explored the development of All-in-One models that attempt to handle multiple degradation types simultaneously within a single framework. This kind of methods are trained to recognize and correct various forms of degradation concurrently. AirNet [31] featuring the contrastive-based degraded encoder and degradation-guided all-in-one restoration network. ADMS [38] uses adaptive filters to efficiently restore images with unknown degradations. TAPE [36] embeds a task-agnostic prior into a transformer, utilizing a two-stage process of pre-training and fine-tuning to enhance image restoration. PromptIR [40] and PIP [33] both utilize uniquely designed prompts to guide their networks. MiOIR [27] employs sequential and prompt learning strategies, which guide the network to incrementally learn individual IR tasks in a sequential manner. MPerceiver [1] employs a multimodal prompt learning approach, utilizing Stable Diffusion priors to achieve high-fidelity all-in-one image restoration."}, {"title": "2.3 Agent in Image Restoration", "content": "Another research direction focuses on more intelligent image restoration systems. One class of such methods employs a toolbox approach to address image degradation separately. RL-Restore [57] prepares a toolbox consisting of small-scale convolutional networks, each specialized in different tasks. The system then learns a policy to select appropriate tools from the toolbox to progressively restore the quality of a corrupted image. However, RL-Restore supports only three types of degradation: blur, noise, and JPEG compression, which constrains its application scenarios and prevents it from utilizing new state-of-the-art models. Clarity ChatGPT [50] combines the conversational intelligence of ChatGPT with multiple image restoration methods. It automatically detects types of image degradation and selects appropriate methods to restore images. Conversely, Clarity ChatGPT identifies the presence of degradation but lacks research and design on the execution order of tasks and the optimal model selection for specific degradations in the input image.\nAnother class involves all-in-one approaches with degradation-aware guidance. InstructIR [14] pioneers a novel approach by utilizing human-written instructions to guide the recovery from various types of degradation. AutoDIR [24] automatically detect and restore images with multiple unknown degradations. LLMRA [25] generates text descriptions and encodes them as context embeddings with degradation information, and integrates these context embeddings into the restoration network. DA-CLIP [37] presents a degradation-aware vision-language model that guides the model to learn high-fidelity image reconstruction. For these all-in-one restoration assistant methods, inherent limitations exist in the practical applications of all-in-one models.\nHow to overcome these limitations, fully leverage the wide array of state-of-the-art models for different tasks available on the market, and determine the optimal execution sequence of image restoration tasks and the most suitable model for specific degradation pattern remain unexplored. This gap presents a significant opportunity for future research in intelligent image restoration systems."}, {"title": "3 RestoreAgent", "content": "In this section, we introduce RestoreAgent, an advanced image restoration agent designed to find the optimal model and execution sequence from a model pool to process images containing multiple degradations. RestoreAgent is built upon a state-of-the-art multimodal large language model, which possesses remarkable reasoning, generalization, and cross-modal understanding capabilities. By leveraging the model's ability to draw insights from vast amounts of multimodal data, establish connections between visual and textual information, and apply that knowledge to new contexts, RestoreAgent can effectively analyze complex image degradation scenarios, infer the most suitable restoration techniques, and generate optimal pipelines that combine the strengths of various specialized models. As a result, RestoreAgent consistently produces high-quality results.\nIn Section 3.1, we first define the problem of identifying the most effective combination and order of models from a given pool to restore images affected by various types of degradation. Next, in Section 3.2.2, we describe the process of constructing the training data for the RestoreAgent. The training data consists of paired samples, each containing a degraded image and its corresponding optimal restoration pipeline. Finally, we detail the training process of RestoreAgent, which involves fine-tuning the Llava-Llama3-8b model using the constructed training data in Section 3.2. By learning from these examples, RestoreAgent acquires the ability to analyze degraded images and generate optimal restoration pipelines based on the available model pool."}, {"title": "3.1 Problem Definition", "content": "We consider a comprehensive set of degradation types, denoted as \\(D = \\{d_1, d_2, ..., d_n\\}\\), where each \\(d_i\\) represents a specific type of image degradation such as noise, JPEG artifacts, blur, rain streaks, fog, and low light conditions. For each degradation type \\(d_i\\), we tailor a model library \\(M_{d_i}\\), comprising models \\(\\{M_{d_i}^1, M_{d_i}^2, ...\\}\\). Each model \\(M_{d_i}^i\\) is specifically trained to mitigate the effects of degradation \\(d_i\\). The problem is formally defined as follows:\nInput: A degraded image I subjected to various degradation types D. A model library \\(\\{M_{d1}, M_{d2},..., M_{dn} \\}\\) tailored for processing D. The user-provided scoring function S for evaluating the image restoration process.\nObjective: Identify the optimal model execution sequence \\(\\sigma = (a_1^{b_1}, a_2^{b_2},..., a_m^{b_m})\\) that maximizes the restoration quality S of the degraded image I, where \\(a_i\\) denotes the degradation type and \\(b_i\\) represents the corresponding model. It is formulated as:\n\\(\\sigma^* = \\arg \\max_{\\sigma \\in S(D,M)} S(I,\\sigma),\\)\nwhere S(D, M) represents the set of all possible sequences of degradation and model pairs.\nBy tackling this problem, we strive to identify the optimal combination of restoration sequence and model selections, ultimately enhancing the quality of images affected by multiple degradations in real-world settings, and thus providing a more effective and efficient solution for complex image restoration tasks."}, {"title": "3.2 RestoreAgent: An Advanced Image Restoration System", "content": ""}, {"title": "3.2.1 RestoreAgent Pipeline", "content": "We introduce an advanced image restoration agent, dubbed RestoreAgent, implemented using the state-of-the-art multimodal model Llava-Llama3-8b [46]. LoRA [21] is utilized to fine-tune both the vision and language modules. As shown in Figure 3, given a degraded input image, RestoreAgent can provide the best decisions, including which image restoration tasks need to be performed, the order of their execution, and which model is most suitable for each task. The model's input consists of a degraded image and the prompt such as User: How to enhance the quality of this image? [Execution history: ...]. In response, RestoreAgent generates an output sequence representing the optimal restoration pipeline, comprising a series of tasks, each associated with a specific model best suited to address particular degradation patterns. In our implementation, the output template is defined as: Agent:1.. 2.. 3. .., ensuring interpretability and actionability.\nRestoreAgent also supports an iterative step-wise decision-making process, reevaluating the state of the image after each restoration step. During this reassessment, the execution history is provided, offering valuable context for decision-making. This allows for real-time strategy adjustments based on cumulative effects and past actions. The system also features a rollback capability, enabling it to revert to a previous state if undesirable results are detected. This combination of iterative evaluation with historical context and rollback allows for finer control over the restoration process, facilitating mid-course corrections."}, {"title": "3.2.2 Data Construction", "content": "To fully leverage the potential of multimodal large models, we construct a substantial dataset of paired training samples. The process begins with applying various types of degradation to an image. Subsequently, we determine the optimal restoration pipeline using model tools for processing. For each image undergoing multiple degradations, a comprehensive search is conducted to identify the best restoration pipeline, as shown in Figure 3. This involves generating all possible permutations of task execution sequences and model combinations, applying each pipeline to the degraded image, and assessing the quality of the restored outputs using a scoring function S(\u0399, \u03c3). By comparing the scores of all permutations, the pipeline with the highest score is selected as the optimal processing strategy & for the given image. Users can choose from various image quality assessment methods as the scoring function, customizing the evaluation process to their specific needs.\n(1) Once we obtain a degraded image along with its corresponding optimal decision results, we can construct the primary part of our dataset. This part consists of degraded images in their original, unprocessed state. For these inputs, the RestoreAgent receives a prompt: \"How to enhance the quality of this image? Execution history: None.\" This scenario trains the model to formulate comprehensive enhancement strategies from scratch, encompassing multiple restoration steps. This part of the data exceeds 23k pairs.\n(2) To foster dynamic decision-making capabilities, we introduce a second category of training instances. Here, the input comprises partially processed images (e.g., after denoising) along with their execution history. This approach enables the RestoreAgent to adapt its predictions based on intermediate results, promoting a more flexible and context-aware enhancement process."}, {"title": "3.3 Discussion", "content": "Comparison with assistants with all-in-one models. Assistants that employ unified models, such as LLMRA [25] and AutoDIR [24], attempt to handle diverse tasks, degradation patterns, and intensities using a single model. As discussed in Section 1.1, these all-in-one models face significant challenges, including restricted task scope and compromised performance, which greatly limit their effectiveness in real-world applications. Conversely, our method leverages various model experts to address specific situations, the upper bound of our pipeline is determined by the latest SOTA models, allowing us to maximally leverage the latest advancements in the field without being constrained by the limitations of an all-in-one model. Furthermore, as detailed in Section 4.4, our RestoreAgent exhibits high efficiency in incorporating new tasks and models, showcasing greater flexibility.\nComparison with assistants with tool use. Image restoration assistants that utilize tool libraries, such as Clarity ChatGPT [50] and RL-Restore [57]. Clarity ChatGPT merely identifies the degradation in images, follows a rigid execution strategy, lacking the ability to make dynamic decisions on task"}, {"title": "4 Experiment", "content": ""}, {"title": "4.1 Experimental Settings", "content": "Scoring function. To construct a comprehensive evaluation system, we integrate multiple diverse metrics. Specifically, we first standardized each individual metric separately and then summed the standardized results. Mathematically, this process can be described as follows. Let \\(X_i\\) represent the i-th metric. We standardize each metric by calculating its z-score: \\(Z_i = \\frac{X_i-\\mu_i}{\\sigma_i}\\) where \\(\\mu_i\\) is the mean and \\(\\sigma_i\\) is the standard deviation of the i-th metric. After standardizing all metrics, we aggregate the standardized scores to form the comprehensive evaluation score S: \\(S = \\sum_{i=1}^{n} Z_i\\) where n is the total number of metrics. This method ensures that each metric contributes equally to the final evaluation, regardless of its original scale. Follow [26, 20], evaluation metrics primarily include PSNR, SSIM, LPIPS [60], and DISTS [16]. These metrics are widely recognized for their ability to"}, {"title": "4.2 Comparisons with Other Strategies", "content": "Compared methods. In this study, we conducted a comparative analysis of RestoreAgent against several alternative approaches:\n\u2022 Random selection of both the task order and the models, assuming accurate determination of task types.\n\u2022 Random task order, but models predicted by RestoreAgent.\n\u2022 Random model selection, but task orders predicted by RestoreAgent.\n\u2022 For all images, using the human expert's predefined order and models, assuming accurate task type determination.\n\u2022 Human expert personally crafting a solution for each image, determining the task sequence and models for each task. This method represents the most common scenario in real-world applications, where a human decides how to restore an image on a case-by-case basis.\nThe human expert in this study has more than five years of research experience in low-level vision. Before crafting solutions, the expert familiarized themselves with each task degradation and the corresponding model's actual performance to ensure they could provide the best human-level solution for each image.\nResults. Table 1 reports the average metric results of our RestoreAgent and other decision-making approaches on seven different degradation combination datasets. Our RestoreAgent is trained to optimize the sum of four normalized metrics, which is the \"balanced\" column in the table, indicating that our model seeks to achieve the best overall performance rather than focusing on a single IQA metric. As shown in Table 1, using a random order and model selection ranked lowest, achieving only a 34.7% performance rating among all possible strategies. By setting predefined sequences and models for image processing by human experts, traditional methods rank in the top 22.1% of all possible strategies. This demonstrates that experience-based predefined rules often used in practical applications are more effective than completely random strategies. Human experts making specific decisions for each test image can further improve upon predefined rules, increasing the ranking from 22.1% to 19.5%. This proves that using the same predefined rules to process all images is not optimal, while individualized decision-making for specific images can better enhance the effects.\nThen, the superior performance of our RestoreAgent (12.9%) over expert-based customization (19.5%) shows that automated and data-driven decision-making in our method clearly outperforms traditional and experience-based human expert judgments. This is because human experts from their own experience can not make precise judgments about the advantageous scenarios of all models and the order of task execution, especially when numerous tasks and models are involved.\nIn contrast, by training on a vast amount of actual data results, the objectives of our RestoreAgent are clear and the best. Moreover, our RestoreAgent leverages a robust vision encoder that discerns minute differences between various types of image degradations and integrates these insights with a LLM trained on a vast dataset of optimal decisions. This integration enables our RestoreAgent to"}, {"title": "4.3 Comparisons with All-in-One Methods", "content": "To demonstrate the limitations of all-in-one methods in handling multi-degraded images, we compared our approach with various types of all-in-one models. To ensure a fair comparison, tests were only conducted on degradation types and datasets that these all-in-one models were trained to support. Moreover, we repeatedly run the all-in-one model as many times as the number of degradation types of the test images to fully leverage its capabilities, thus ensuring a fair comparison. The results are shown in Figure 8 and Table 2. Our RestoreAgent achieved a significant leading advantage across all tested degradation combinations. For the degradation types commonly encountered in traditional image super-resolution, such as noise and JPEG compression artifacts, our approach of using a dedicated restoration model for each degradation type significantly outperformed established methods like Real-ESRGAN and the sota SR method, StableSR. For a broader range of degradation types, our method retained a considerable advantage. Among these all-in-one approaches, InstructIR and AutoDIR, which operate by processing each task type explicitly based on the input prompt, work better. However, these methods still face two major issues: manually predetermined or randomly decided execution order, and using single model to address all types of degradations. These limitations often result in incomplete restoration, as depicted in Figure 8. These results underscore the limitations of all-in-one models, validating our initial hypothesis. RestoreAgent intelligently selects and leveraging the strengths of specialized sota models for each degradation type, demonstrates superior performance and adaptability in handling multi-degraded images compared to the all-in-one paradigm."}, {"title": "4.4 Adapting to Different Optimization Objectives", "content": "As discussed in the method, our proposed method can adapt to various optimization objectives, enabling the decision-making results tailored to specific target criteria. To verify it, we present the results of models trained with different individual metrics as the optimization objective in Table 3. The results indicate that when a model is trained with a single metric, the performance of the corresponding metric can be significantly improved compared to the balanced model. This showcases the adaptability and effectiveness of our method in catering to specific optimization goals."}, {"title": "4.5 Extending for New Tasks and Models", "content": "The proposed RestoreAgent demonstrates remarkable adaptability and extensibility, allowing for swift fine-tuning to accommodate new task types and incorporate additional models. This process incurs minimal costs, making it highly efficient and practical for real-world applications. To validate this capability, we introduced a new task, desnowing, along with its corresponding model. Building upon the RestoreAgent previously trained on six tasks, we performed rapid fine-tuning by integrating"}, {"title": "4.6 Step-wise Re-planning and Rollback", "content": "As mentioned in Section 3.2, RestoreAgent supports iterative decision-making with historical context awareness. It dynamically adjusts strategies during image restoration, reassessing image state after each step and rolling back if needed. As demonstrated in Table 6, we conducted experiments on a complex dataset incorporating four distinct types of image degradation: Motion Blur, Rain, Noise, and JPEG compression. Results show that while the single prediction approach performs well, iterative step-wise replanning further enhances restoration outcomes, allowing for precise control and mid-course corrections. However, the improvement is modest, indicating that the initial decision's performance is already strong. Step-wise replanning thus serves more as a refinement tool, offering incremental yet valuable improvements to an already effective process."}, {"title": "4.7 Alation Study", "content": "Training data amount. To investigate the effect of training data volume on our method, we evaluated the performance of the RestoreAgent model trained on datasets consisting of 7,000, 14,000, and 23,000 data pairs; see Table 4 The results demonstrate that even with the smallest dataset of 7k pairs, our RestoreAgent achieves superior performance over both random and human expert benchmarks. More notably, the training data volume increasing from 7k to 14k incurs a substantial performance improvement with the ranking percentage decreasing from 16.2% to 13.6%. With 23k data pairs, the performance further improves, achieving a ranking percentage of 12.9%. This indicates that using more training data boosts our RestoreAgent model. These findings emphasize the robustness of our approach, demonstrating that while larger datasets do enhance performance, our model already provides significant benefits even with relatively smaller datasets."}, {"title": "5 Limitation and Future Work", "content": "The primary limitation of our study is the confined scope of models and tasks examined. While our research offers valuable insights into RestoreAgent's performance across several degradation scenarios, it does not encompass the full spectrum of restoration models or image degradation tasks currently available.\nAnother limitation pertains to the limited generalization capability of current image restoration models. These models often exhibit a notable decrease in performance or fail to respond adequately when faced with even minor variations in image degradation patterns. This limitation greatly narrows our selection of model tools, requiring us to choose more robust and generalizable model tools. The challenge underscores a critical need in the field of image restoration: future models must go beyond simply overfitting training data. Rather, they should exhibit better generalization and increased efficiency in handling real-world degradation cases."}, {"title": "6 Conclusion", "content": "Our research first identifies several critical factors in processing multi-degraded images. such as the sequence of task execution, the importance of model selection, and the limitations of the all-in-one approach. Building on these insights, we introduce RestoreAgent, an agent model capable of making intelligent processing decisions based on the degradation characteristics of the input image and the user's objectives. Experimental results demonstrate that our pipeline for handling multi-degraded images outperforms the all-in-one approach. Furthermore, the performance of our decision-making results significantly exceeds those made by human experts."}, {"title": "A Appendix / supplemental material", "content": ""}, {"title": "A.1 Model Tool Setings", "content": "As shown in Table 7, for the tasks of denoising and deJPEG, as well as deraining, we employ Restormer [58] as our model. For dehazing, we utilize RIDCP [54], while for motion deblurring, we use DeblurGANv2 [28]. For desnowing, we implement Snowformer [10]. For low-light enhancement, we use Retinexformer [2]. It is noteworthy that the models we are using are not the latest state-of-the-art models, indicating that there is significant room for improvement in our models.\nA crucial consideration in image restoration is the limited generalization capability of many current models, which often fail to maintain performance when faced with subtle variations in image degradation. This necessitates the selection of more robust models. For example, in our approach to denoising, we enhance model generalization by incorporating not only Gaussian noise but also random blur and other noise types during training. This strategy enables the model to address more complex degradation scenarios effectively."}, {"title": "A.2 Testset details", "content": "The specific details of our test set are presented in Table 8, which demonstrates our construction of various combinations of degradation types. Each image in the set contains a minimum of one and a maximum of four types of degradation, with the entire set comprising 200 images."}, {"title": "A.3 Training Setups", "content": "In this study, we incorporate the CLIP pre-trained Vision Transformer (ViT-L/14) [42] as the image encoder to convert input images into visual tokens. For the language model, we utilize the Llama3-7B [46]. Despite their capabilities, pre-trained LLMs fail to provide accurate responses without dataset-specific fine-tuning. To address this, we adopt LoRA [21], a fine-tuning technique that efficiently modifies a limited number of parameters within the model. Following [21], we apply LORA to adjust the projection layers in all self-attention modules of both the vision encoder and the LLM, thereby generating our RestoreAgent. We employ the Xtuner framework [15] to facilitate the training process. For our experimental setup, we configure the LoRA rank to 16. The RestoreAgent undergoes training across ten epochs on 4 NVIDIA RTX A100 GPUs, with a batch size of 32. We employ the Adam optimizer and a learning rate of 0.00002. The total duration of the training process approximates ten hours."}]}