{"title": "Chatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards", "authors": ["Jonathan Reif", "Tom Jeleniewski", "Milapji Singh Gill", "Felix Gehlhoff", "Alexander Fay"], "abstract": "The following contribution introduces a concept that\nemploys Large Language Models (LLMs) and a chatbot interface\nto enhance SPARQL query generation for ontologies, thereby\nfacilitating intuitive access to formalized knowledge. Utilizing\nnatural language inputs, the system converts user inquiries\ninto accurate SPARQL queries that strictly query the factual\ncontent of the ontology, effectively preventing misinformation or\nfabrication by the LLM. To enhance the quality and precision\nof outcomes, additional textual information from established\ndomain-specific standards is integrated into the ontology for\nprecise descriptions of its concepts and relationships. An ex-\nperimental study assesses the accuracy of generated SPARQL\nqueries, revealing significant benefits of using LLMs for querying\nontologies and highlighting areas for future research.", "sections": [{"title": "I. INTRODUCTION", "content": "In the context of Cyber-Physical Systems (CPS) and In-\ndustry 4.0, domain-specific ontologies serve as highly ad-\nvantageous knowledge bases. Ontologies enable efficient data\nintegration and enhance the interoperability of different CPS\nby establishing clear semantics and formalizing domain knowl-\nedge [1]. These attributes are particularly beneficial in in-\ndustrial applications where data is dispersed across various\nheterogeneous sources. Thus, ontologies are essential for man-\ngaging the increasing complexity of CPS engineering, opera-\ntion, and maintenance. Particularly, their use within assistance\nsystems in various Industry 4.0 application scenarios improves\ndecision-making and optimizes processes across different life\ncycle phases of CPS [2, 3, 4].\nHowever, significant challenges exist in facilitating inter-\naction between end users and ontologies. Ontologies are\ninherently complex and not easily understandable, making\nthem difficult for end users to engage with effectively [5].\nTraditionally, knowledge querying is conducted based on\npredefined Competency Questions (CQs) and static SPARQL\nProtocol and RDF Query Language (SPARQL) queries [1].\nThese are neither intuitive for someone without Semantic Web\nexpertise nor user-friendly. Especially in view of the lack\nof ontology experts, this problem is even more critical [1].\nMany users find it difficult to formulate complex SPARQL\nqueries. This significantly limits the flexibility and efficiency\nof knowledge retrieval. In this context, the communication\nbetween a domain-specific ontology and an end user can\nbe substantially improved by employing chatbots and Large\nLanguage Models (LLMs) [5, 6].\nCurrently, LLM-based assistance system experience in-\ncreased significance, driven by the latest accomplishments\nin the LLM community. However, relying solely on LLM-\nbased approaches poses significant risks. Due to the lack\nof traceability of LLMs and their potentially highly creative\ninterpretative abilities, it cannot be ensured that the LLM\nextracts an answer directly from a credible source instead\nof creating its own probability-based responses. As a result,\nincorrect information could be conveyed to the user, potentially\ncausing errors. This poses a significant threat, especially in\nindustrial applications, where the accuracy and correctness\nof answers are crucial, and hallucinated responses generated\nby an LLM could have severe consequences. Therefore, it is\nbeneficial to adopt an approach that combines the advantages\nof ontologies\nthe formal, structured provision of factual\nknowledge with those of LLMs, which offer intuitive and\neasy use. For this reason, we propose a concept to improve the\nprocess of automated SPARQL query generation by leveraging\nLLMs and information from domain-specific standards. This\napproach aims to enhance user-friendliness by providing an\nintuitive interface for querying complex ontologies.\nThe paper is structured as follows: In Sec. II, we intro-\nduce the requirements for the proposed concept and analyze\nrelated work concerning these requirements. Sec. III details\nthe concept. Preliminary results from an initial experimental\nstudy are presented in Sec. IV. Finally, Sec. V summarizes the\ncontribution and depicts future research directions."}, {"title": "II. REQUIREMENTS AND RELATED WORK", "content": "A. Requirements\nR1: Intuitive communication between the user and the\nindividually created ontology\nAs described in Sec. I the use of ontologies can pose sig-\nnificant challenges for non-experts. Therefore, one of the key\nrequirements is to lower the usage barrier by assisting the\nuser in their communication with the ontology. This involves\ncreating an interface or a system that is user-friendly and\nintuitive, allowing users to interact with the ontology in a way\nthat feels natural and straightforward. Thus, users should be"}, {"title": "B. Related Work", "content": "Chen et al. [10] present a semantic embedding framework\nfor Web Ontology Language (OWL) ontologies. It utilizes a\ncombination of random walks and word embedding techniques\nto encode the semantics of OWL ontologies by considering\ntheir graph structure, lexical information, and logical construc-\ntors. The results suggest good accuracy. However, because the\ngeneration of answers is solely based on the use of an LLM,\nthere is no traceability of the generated answers.\nChen et al. [5] introduce a system designed to efficiently\ngenerate SPARQL queries for so-called question answering\nsystems. The primary objective of the system is to reduce\nquery costs while maintaining high accuracy in generating\nSPARQL queries, which are used to retrieve answers from\ndatabases. The approach employs a Recurrent Neural Network\n(RNN) to generate SPARQL queries from learned and labeled\nkeywords. Building on this, Chen et al. [11] describe the\nenhancement of question answering systems through advanced\nNatural Language Processing (NLP) techniques and multi-\nlabel classification also using RNNs. They emphasize the\nuse of NLP to interpret and process user queries in Natural\nLanguage (NL), converting them into a format that can be\nused to generate SPARQL queries effectively. This involves the\nuse of technologies such as tokenization, lemmatization, and\npart-of-speech tagging to understand the semantic structure\nof the queries. Although both publications also pursue the\nidea of translating user questions into SPARQL queries, they\nrefrain from using LLMs [5, 11]. However, Chen et al. [5] also\nemphasize that when converting a user question into query\ngrammar, the accuracy of the generation of the query decides\nwhether an answering system can provide a correct answer."}, {"title": "III. CONCEPT FOR CHATBOT-BASED INTERACTION WITH\nONTOLOGIES", "content": "In the following, a concept is introduced that utilizes a\nchatbot-based interface for user interactions with ontologies,\nproviding flexible querying options. As mentioned in Sec. II,\nprevious approaches utilize LLMs directly as a querying\nmedium. However, this is associated with significant risks\nin industrial settings as explained in Sec. I. Therefore, our\napproach is based on maintaining SPARQL-based querying.\nTo support domain-specific experts with limited expertise\nin handling Semantic Web technologies, LLMs are used in\nthis approach to generate SPARQL queries. The approach is\nillustrated in Fig. 1.\nUsers interact with the ontology via a chat interface, allow-\ning them to pose questions that are processed in the backend.\nThese queries are sent to the LLM through the ChatGPT\nAPI, incorporating predefined prompts, as explained in detail\nin Sec. III-1 and the TBox. By including only the TBox in\nthe prompt, the security advantage is that the explicit ABox\nknowledge stays separate from the LLM and can only be\naccessed through SPARQL queries. This approach ensures\nthat sensitive industrial information remains protected within\nthe company's internal systems. However, the LLM does\nnot directly answer the input question. Instead, it uses the\npredefined prompt to transform the question into a SPARQL\nquery. This query is then returned to the backend and executed\nat the SPARQL endpoint. The results are processed in the\nbackend and displayed to the user through the user interface,\nproviding the answers required.\nThis approach ensures that the LLM produces no incorrect\nor fabricated answers, as only \"true\" results that are embedded\nwithin the model are retrieved without invention or interpre-\ntation. However, while the responses are verifiable because\nthey reflect the model's actual knowledge, they are not fully\nvalidated. Errors may still persist in the generated queries,\nleading to answers that do not match the original question or,\nin some cases, no answers being returned at all.\nConsidering that potential users may not be familiar with the\nterminology used in the ontology, it is crucial to accommodate\ntheir ability to accurately formulate questions via the chat\ninterface. Special attention should be given to the following\naspects to ensure effective user interaction:\n1) Prompts: Given that neither the user nor the LLM\nis aware of the TBox associated with the ontology to be\nqueried, it is essential to supplement the chat-based ques-\ntions with prompts that incorporate the required contextual\nknowledge. These prompts must comprehensively detail the\nTBox, encapsulating the modeling concepts and terminologies\nof the ontology. By integrating extensive descriptions of the\nontology, including its classes, properties, and relations, within\nthe prompts, the LLM can accurately interpret user questions\nand transform them into precise SPARQL queries. For this\nreason, the TBox containing the modeling concept should be\ntransferred together with the user question. These prompts\nincluding the TBox serve as a guide for translating domain-\nspecific knowledge into executable SPARQL queries, thus\nensuring that the LLM grasps the necessary context and\nspecifics for accurate query formulation.\n2) Creating Ontology Design Patterns: In the industrial\ndomain, fixed terminologies defined by industry standards\nare prevalent. For building ontologies, we employ Ontology\nDesign Patterns (ODPs) that adhere to these established stan-\ndards, functioning as templates for creating knowledge graphs.\nHildebrandt et al. [1] outline a methodological approach for\nbuilding ontologies based on ODPs. When these aligned\nODPs, resembling a TBox for the problem domain context,\naccompany the chat-based queries, the LLM can examine the\nstructures and terminology to accurately translate the chat\nquery into SPARQL in accordance with the ODPs.\nEnhancing ODPs with rdfs:comment annotations is crit-\nical, as these provide additional context about the classes,\nobject properties, and data properties. This extra layer of\ncontext assists the LLM in disambiguating terms that may\nbe ambiguous or have multiple interpretations based on their\nliteral meanings. By leveraging rdfs:comment, the LLM\ngains deeper insights into the intended semantics of the ontol-\nogy elements, thereby enhancing its capability to accurately\ntransform user questions into SPARQL queries. This strategy\nensures that the generated queries are more closely aligned\nwith the underlying ontology, minimizing misinterpretations\nand enhancing the reliability of the SPARQL queries."}, {"title": "IV. PRELIMINARY RESULTS", "content": "Experiments were conducted to assess the ability of LLMs\nto generate SPARQL queries consistent with the criteria out-\nlined in Sec. II. The study investigated factors affecting the\nquality of these queries to evaluate the practical use of LLMS\nin this domain. ChatGPT-4o was employed to create SPARQL\nqueries for various ODPs, utilizing prompts that included\nspecific ODP information in plain text and a corresponding\nquestion that the query aimed to answer.\nThe ODPs used in the study were VDI 3682 (Formalized\nProcess Description) [12], DIN EN 61360 (Property Descrip-\ntions of Technical Systems) [13], and VDI 2206 (Descriptions\nof Machine Structures) [14]. Questions were crafted in two\nstyles to assess the influence of phrasing on query quality:\nFirstly, standard-compliant questions (SCQs) were posed, en-\nsuring that the terminology adhered to established standards.\nSecondly, non-standard-compliant questions (NSCQs) were\nformulated, incorporating more generic terminology typical for\na non-expert.\nAdditionally, these questions were posed using ODPs both\nwith and without annotations in rdfs:comment, aiming to\ndetermine if such comments enhance query quality."}, {"title": "V. SUMMARY AND FUTURE WORK", "content": "This paper investigates the suitability of LLMs for gen-\nerating SPARQL queries to simplify user interaction with\nontologies. By combining the intuitive usability of LLM-\nbased chat applications with the formal, structured knowledge\nprovision of ontologies, the proposed concept is particularly\nbeneficial in an industrial context. An experimental study\nusing ChatGPT-4o assessed the accuracy of SPARQL queries\ngenerated under various conditions and highlighted the value\nof incorporating rdfs:comment.\nFuture evaluation will focus on assessing the overall concept\nand exploring which LLMs are best suited for the task.\nDeveloping strategies to reduce errors in SPARQL query gen-\neration, especially for complex queries, is crucial for enhanc-\ning accuracy and reliability. Improving user interaction with\nontology-based systems by refining prompts and optimizing\nhow the ontology context is provided to the language model is\nalso important. Additionally, exploring the impact of detailed\nrdfs:comment on the quality of generated SPARQL queries\nis needed, including testing with more complex ontologies and\nvarying the detail level of rdfs:comment. Implementing\nrobust validation mechanisms is essential to ensure the accu-\nracy and trustworthiness of the generated queries, especially\nin industrial settings where incorrect information can have\nsignificant consequences."}]}