{"title": "Chatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards", "authors": ["Jonathan Reif", "Tom Jeleniewski", "Milapji Singh Gill", "Felix Gehlhoff", "Alexander Fay"], "abstract": "The following contribution introduces a concept that employs Large Language Models (LLMs) and a chatbot interface to enhance SPARQL query generation for ontologies, thereby facilitating intuitive access to formalized knowledge. Utilizing natural language inputs, the system converts user inquiries into accurate SPARQL queries that strictly query the factual content of the ontology, effectively preventing misinformation or fabrication by the LLM. To enhance the quality and precision of outcomes, additional textual information from established domain-specific standards is integrated into the ontology for precise descriptions of its concepts and relationships. An experimental study assesses the accuracy of generated SPARQL queries, revealing significant benefits of using LLMs for querying ontologies and highlighting areas for future research.", "sections": [{"title": "I. INTRODUCTION", "content": "In the context of Cyber-Physical Systems (CPS) and Industry 4.0, domain-specific ontologies serve as highly advantageous knowledge bases. Ontologies enable efficient data integration and enhance the interoperability of different CPS by establishing clear semantics and formalizing domain knowledge [1]. These attributes are particularly beneficial in industrial applications where data is dispersed across various heterogeneous sources. Thus, ontologies are essential for managing the increasing complexity of CPS engineering, operation, and maintenance. Particularly, their use within assistance systems in various Industry 4.0 application scenarios improves decision-making and optimizes processes across different life cycle phases of CPS [2, 3, 4].\nHowever, significant challenges exist in facilitating interaction between end users and ontologies. Ontologies are inherently complex and not easily understandable, making them difficult for end users to engage with effectively [5]. Traditionally, knowledge querying is conducted based on predefined Competency Questions (CQs) and static SPARQL Protocol and RDF Query Language (SPARQL) queries [1]. These are neither intuitive for someone without Semantic Web expertise nor user-friendly. Especially in view of the lack of ontology experts, this problem is even more critical [1]. Many users find it difficult to formulate complex SPARQL queries. This significantly limits the flexibility and efficiency of knowledge retrieval. In this context, the communication between a domain-specific ontology and an end user can be substantially improved by employing chatbots and Large Language Models (LLMs) [5, 6].\nCurrently, LLM-based assistance system experience increased significance, driven by the latest accomplishments in the LLM community. However, relying solely on LLM-based approaches poses significant risks. Due to the lack of traceability of LLMs and their potentially highly creative interpretative abilities, it cannot be ensured that the LLM extracts an answer directly from a credible source instead of creating its own probability-based responses. As a result, incorrect information could be conveyed to the user, potentially causing errors. This poses a significant threat, especially in industrial applications, where the accuracy and correctness of answers are crucial, and hallucinated responses generated by an LLM could have severe consequences. Therefore, it is beneficial to adopt an approach that combines the advantages of ontologies - the formal, structured provision of factual knowledge - with those of LLMs, which offer intuitive and easy use. For this reason, we propose a concept to improve the process of automated SPARQL query generation by leveraging LLMs and information from domain-specific standards. This approach aims to enhance user-friendliness by providing an intuitive interface for querying complex ontologies.\nThe paper is structured as follows: In Sec. II, we introduce the requirements for the proposed concept and analyze related work concerning these requirements. Sec. III details the concept. Preliminary results from an initial experimental study are presented in Sec. IV. Finally, Sec. V summarizes the contribution and depicts future research directions."}, {"title": "II. REQUIREMENTS AND RELATED WORK", "content": "A. Requirements\nR1: Intuitive communication between the user and the individually created ontology\nAs described in Sec. I the use of ontologies can pose significant challenges for non-experts. Therefore, one of the key requirements is to lower the usage barrier by assisting the user in their communication with the ontology. This involves creating an interface or a system that is user-friendly and intuitive, allowing users to interact with the ontology in a way that feels natural and straightforward. Thus, users should be permitted to formulate queries using their own words, rather than being required to use specific terms or codes [7].\nR2: Flexible queries to the ontology based on the user's current information requirements\nGiven the need to facilitate the user's interaction with the ontology, the second requirement is the ability to generate customized queries. These queries should be flexible and adapt to the user's current information needs. This flexibility enhances the user-friendliness of the system and ensures that the user can extract the most relevant and useful information from the ontology [8].\nR3: Accuracy and traceability of answers\nWhile making the ontology user-friendly is important, it would be futile if the information retrieved is not accurate [9]. Therefore, the third requirement is to guarantee the accuracy of the answers provided by the assistance-system. This requirement becomes even more critical in an industrial setting where the accuracy of information is paramount. In this context, the correctness of the answers additionally has to be traceable by users to ensure correctness as inaccurate information can lead to costly mistakes, inefficiencies, and even safety risks. Therefore, the system must be designed to provide precise, reliable, and traceable answers.\nB. Related Work\nChen et al. [10] present a semantic embedding framework for Web Ontology Language (OWL) ontologies. It utilizes a combination of random walks and word embedding techniques to encode the semantics of OWL ontologies by considering their graph structure, lexical information, and logical constructors. The results suggest good accuracy. However, because the generation of answers is solely based on the use of an LLM, there is no traceability of the generated answers.\nChen et al. [5] introduce a system designed to efficiently generate SPARQL queries for so-called question answering systems. The primary objective of the system is to reduce query costs while maintaining high accuracy in generating SPARQL queries, which are used to retrieve answers from databases. The approach employs a Recurrent Neural Network (RNN) to generate SPARQL queries from learned and labeled keywords. Building on this, Chen et al. [11] describe the enhancement of question answering systems through advanced Natural Language Processing (NLP) techniques and multi-label classification also using RNNs. They emphasize the use of NLP to interpret and process user queries in Natural Language (NL), converting them into a format that can be used to generate SPARQL queries effectively. This involves the use of technologies such as tokenization, lemmatization, and part-of-speech tagging to understand the semantic structure of the queries. Although both publications also pursue the idea of translating user questions into SPARQL queries, they refrain from using LLMs [5, 11]. However, Chen et al. [5] also emphasize that when converting a user question into query grammar, the accuracy of the generation of the query decides whether an answering system can provide a correct answer.\nAvila et al. [6] conducted preliminary experiments to evaluate ChatGPT's (GPT-3.5) ability to answer NL questions over a Knowledge Graph (KG) in domains such as families, people, and jobs. Various setups were tested, including direct answering and text-to-SPARQL translation using either or both the TBox and ABox of the KG. The results indicated that the text-to-SPARQL approach utilizing both the TBox and ABox yielded the best performance. Furthermore, Avila et al. [6] present a framework designed to optimize the translation of NL questions into SPARQL queries. It operates in two stages: an offline stage that generates indices mapping KG terms (TBox and ABox) to their Uniform Resource Identifiers (URIs), and an online stage that uses these indices to translate NL questions into SPARQL queries and generate responses. By reducing the number of tokens processed, the framework decreases the likelihood of hallucinations and enhances support for large KGs. However, the effect of providing explanations of the graph to the LLM as well as the level of complexity to which the LLM can generate SPARQL queries in an reliable manner where not examined."}, {"title": "III. CONCEPT FOR CHATBOT-BASED INTERACTION WITH ONTOLOGIES", "content": "In the following, a concept is introduced that utilizes a chatbot-based interface for user interactions with ontologies, providing flexible querying options. As mentioned in Sec. II, previous approaches utilize LLMs directly as a querying medium. However, this is associated with significant risks in industrial settings as explained in Sec. I. Therefore, our approach is based on maintaining SPARQL-based querying. To support domain-specific experts with limited expertise in handling Semantic Web technologies, LLMs are used in this approach to generate SPARQL queries. The approach is illustrated in Fig. 1.\nUsers interact with the ontology via a chat interface, allowing them to pose questions that are processed in the backend. These queries are sent to the LLM through the ChatGPT API, incorporating predefined prompts, as explained in detail in Sec. III-1 and the TBox. By including only the TBox in the prompt, the security advantage is that the explicit ABox knowledge stays separate from the LLM and can only be accessed through SPARQL queries. This approach ensures that sensitive industrial information remains protected within the company's internal systems. However, the LLM does not directly answer the input question. Instead, it uses the predefined prompt to transform the question into a SPARQL query. This query is then returned to the backend and executed at the SPARQL endpoint. The results are processed in the backend and displayed to the user through the user interface, providing the answers required.\nThis approach ensures that the LLM produces no incorrect or fabricated answers, as only \"true\" results that are embedded within the model are retrieved without invention or interpretation. However, while the responses are verifiable because they reflect the model's actual knowledge, they are not fully validated. Errors may still persist in the generated queries, leading to answers that do not match the original question or, in some cases, no answers being returned at all.\nConsidering that potential users may not be familiar with the terminology used in the ontology, it is crucial to accommodate their ability to accurately formulate questions via the chat interface. Special attention should be given to the following aspects to ensure effective user interaction:\n1) Prompts: Given that neither the user nor the LLM is aware of the TBox associated with the ontology to be queried, it is essential to supplement the chat-based questions with prompts that incorporate the required contextual knowledge. These prompts must comprehensively detail the TBox, encapsulating the modeling concepts and terminologies of the ontology. By integrating extensive descriptions of the ontology, including its classes, properties, and relations, within the prompts, the LLM can accurately interpret user questions and transform them into precise SPARQL queries. For this reason, the TBox containing the modeling concept should be transferred together with the user question. These prompts including the TBox serve as a guide for translating domain-specific knowledge into executable SPARQL queries, thus ensuring that the LLM grasps the necessary context and specifics for accurate query formulation.\n2) Creating Ontology Design Patterns: In the industrial domain, fixed terminologies defined by industry standards are prevalent. For building ontologies, we employ Ontology Design Patterns (ODPs) that adhere to these established standards, functioning as templates for creating knowledge graphs. Hildebrandt et al. [1] outline a methodological approach for building ontologies based on ODPs. When these aligned ODPs, resembling a TBox for the problem domain context, accompany the chat-based queries, the LLM can examine the structures and terminology to accurately translate the chat query into SPARQL in accordance with the ODPs.\nEnhancing ODPs with rdfs:comment annotations is critical, as these provide additional context about the classes, object properties, and data properties. This extra layer of context assists the LLM in disambiguating terms that may be ambiguous or have multiple interpretations based on their literal meanings. By leveraging rdfs:comment, the LLM gains deeper insights into the intended semantics of the ontology elements, thereby enhancing its capability to accurately transform user questions into SPARQL queries. This strategy ensures that the generated queries are more closely aligned with the underlying ontology, minimizing misinterpretations and enhancing the reliability of the SPARQL queries."}, {"title": "IV. PRELIMINARY RESULTS", "content": "Experiments were conducted to assess the ability of LLMs to generate SPARQL queries consistent with the criteria outlined in Sec. II. The study investigated factors affecting the quality of these queries to evaluate the practical use of LLMS in this domain. ChatGPT-4o was employed to create SPARQL queries for various ODPs, utilizing prompts that included specific ODP information in plain text and a corresponding question that the query aimed to answer.\nThe ODPs used in the study were VDI 3682 (Formalized Process Description) [12], DIN EN 61360 (Property Descriptions of Technical Systems) [13], and VDI 2206 (Descriptions of Machine Structures) [14]. Questions were crafted in two styles to assess the influence of phrasing on query quality: Firstly, standard-compliant questions (SCQs) were posed, ensuring that the terminology adhered to established standards. Secondly, non-standard-compliant questions (NSCQs) were formulated, incorporating more generic terminology typical for a non-expert.\nAdditionally, these questions were posed using ODPs both with and without annotations in rdfs:comment, aiming to determine if such comments enhance query quality.\nThe complexity of questions was graded into seven categories according to the scheme proposed by Rony et al. [15], shown in Tab. I. Boolean, Count, and Rank represent simpler queries to the ontology, intended to yield a True/False outcome, a numerical count, or a ranking, respectively. Simple, String, and Two Hop require querying more complex graph relationships or more specific words, necessitating a greater semantic understanding. Two Intent is the most complex category, as it essentially requires two responses and the merging of multiple triples. For each category, an example with a SCQ is listed in Tab. I, along with the corresponding ODP. Overall, the experimental study encompasses 28 questions for each ODP, resulting in a total of 84 questions with analyzed results.\nPreliminary results indicate a generally good performance of the tested LLM in generating SPARQL queries. In Tab. II, the questions categories, exhibiting similar patterns in the results, were classified into three clusters. The results show that simpler questions (Boolean, Count, Rank) generally yielded more accurate SPARQL queries, regardless of the presence of rdfs:comment in the tested ontologies. Moreover it was found that precise SCQ formulation significantly affected query quality. However, for more complex questions (e.g., Two Intent), ChatGPT-4o often generated inaccurate or imprecise queries, typically failing to identify the correct instance. The results also suggest that ODPs augmented with rdfs:comment produced queries with greater precision, supporting the hypothesis that detailed comments in ontologies positively impact automated SPARQL query generation. Accordingly, it can be concluded that annotations enhance not only human comprehension of ontologies but also offer significant benefits for LLMs in terms of query generation accuracy and effectiveness. Overall the suitability of LLMS for (automated) SPARQL query generation could be shown."}, {"title": "V. SUMMARY AND FUTURE WORK", "content": "This paper investigates the suitability of LLMs for generating SPARQL queries to simplify user interaction with ontologies. By combining the intuitive usability of LLM-based chat applications with the formal, structured knowledge provision of ontologies, the proposed concept is particularly beneficial in an industrial context. An experimental study using ChatGPT-4o assessed the accuracy of SPARQL queries generated under various conditions and highlighted the value of incorporating rdfs:comment.\nFuture evaluation will focus on assessing the overall concept and exploring which LLMs are best suited for the task.\nDeveloping strategies to reduce errors in SPARQL query generation, especially for complex queries, is crucial for enhancing accuracy and reliability. Improving user interaction with ontology-based systems by refining prompts and optimizing how the ontology context is provided to the language model is also important. Additionally, exploring the impact of detailed rdfs:comment on the quality of generated SPARQL queries is needed, including testing with more complex ontologies and varying the detail level of rdfs:comment. Implementing robust validation mechanisms is essential to ensure the accuracy and trustworthiness of the generated queries, especially in industrial settings where incorrect information can have significant consequences."}]}