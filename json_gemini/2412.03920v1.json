{"title": "A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios", "authors": ["Xiachong Fength", "Longxu Dous", "Ella Li", "Qinghao Wang", "Haochuan Wang", "Yu Guo", "Chang Mah", "Lingpeng Kong"], "abstract": "Game-theoretic scenarios have become pivotal in evaluating the social intelligence of Large Language Model (LLM)-based social agents. While numerous studies have explored these agents in such settings, there is a lack of a comprehensive survey summarizing the current progress. To address this gap, we systematically review existing research on LLM-based social agents within game-theoretic scenarios. Our survey organizes the findings into three core components: Game Framework, Social Agent, and Evaluation Protocol. The game framework encompasses diverse game scenarios, ranging from choice-focusing to communication-focusing games. The social agent part explores agents' preferences, beliefs, and reasoning abilities. The evaluation protocol covers both game-agnostic and game-specific metrics for assessing agent performance. By reflecting on the current research and identifying future research directions, this survey provides insights to advance the development and evaluation of social agents in game-theoretic scenarios.", "sections": [{"title": "Introduction", "content": "The rapid advancement of Large Language Models (LLMs) (Achiam et al., 2023; Team et al., 2023; Jiang et al., 2023; Yang et al., 2024a; Dubey et al., 2024) has achieved exceptional performance across a wide array of applications, including personal assistant (Li et al., 2024b), search engines (Chen et al., 2024b), code generation (Wang et al., 2024b) and embodied intelligence (Liu et al., 2024a). Building on this capability, a growing area of research focuses on employing LLMs as central controllers to develop autonomous agents with human-like decision-making abilities (Sumers et al., 2023; Wang et al., 2024a). This progress brings the realization of Artificial General Intelligence (AGI) within reach (Bubeck et al., 2023), paving the way for a future where human-AI interaction, collaboration, and coexistence shape a shared, symbiotic society (Mahmud et al., 2023). Therefore, it is crucial to evaluate and enhance the social intelligence of AI, particularly LLM-based social agents, as it determines their ability to engage effectively in sophisticated social scenarios (Mathur et al., 2024). Social intelligence is the foundation of all successful interpersonal relationships and is also a prerequisite for AGI (Hunt, 1928; Kihlstrom & Cantor, 2000; Hovy & Yang, 2021). Drawing on insights from both social science and AI research, Li et al. (2024a) has established a comprehensive Social AI Taxonomy, which categorizes social intelligence into three dimensions: situational intelligence, the ability to comprehend the social environment (Derks et al., 2007); cognitive intelligence, the ability to understand others' intents and beliefs (Barnes & Sternberg, 1989); and behavioural intelligence, the ability to behave and interact appropriately (Ford & Tisak, 1983). To evaluate artificial social intelligence, researchers have conducted extensive studies, with particular focus on game-theoretic scenarios, as these studies simultaneously encompass all above three dimensions of social intelligence (Aher et al., 2022; Horton, 2023; Phelps & Russell, 2023; Akata et al., 2023; Brookins & DeBacker, 2023)."}, {"title": "Game Framework", "content": "Game theory, a long-established field in microeconomics, offers a robust mathematical framework for analyzing social interactions among cooperating and competing players, with wide-ranging applications (Fudenberg & Tirole, 1991; Camerer, 2011). Specifically, evaluations in game-theoretic scenarios require social agents to understand the game scenario, infer opponents' actions, and adopt appropriate responses, representing an advanced form of social intelligence (Van Der Hoek et al., 2005; Zhang et al., 2024a). Moreover, the multi-agent participation and dynamic nature of the environment in game scenarios present additional challenges for social agents. Consequently, extensive research has examined social agents within game-theoretic scenarios, offering substantial empirical evidence for understanding their social intelligence (Guo, 2023; Meng, 2024; Mei et al., 2024). However, there is currently a lack of a comprehensive review that summarizes the current progress in this area and considers future directions. To address this gap, we have thoroughly reviewed the existing research on LLM-based social agents in game-theoretic scenarios and have organized the findings according to a meticulously designed taxonomy, as illustrated in Figure 1. Specifically, the taxonomy comprises three main components: Game Framework (\u00a72), Social Agent (\u00a73), and Evaluation Protocol (\u00a74). The Game Framework section includes two parts: Choice-Focusing Game (\u00a72.1) and Communication-Focusing Game (\u00a72.2). Choice-Focusing Game refers to a series of scenarios where participants engage with little to no communication, such as classic game-theoretic games (Brookins & DeBacker, 2023; Hua et al., 2024a) and poker (Yim et al., 2024). Communication-Focusing Game refers to games where communication among participants is a core component, such as negotiation (Bianchi et al., 2024) and diplomacy (Bakhtin et al., 2022)."}, {"title": "2.1 Choice-Focusing Game", "content": "Choice-focusing games are game-theoretic scenarios in which participants make decisions based primarily on observable actions and environmental conditions, with minimal or no communication involved. Existing research focuses on social agents in three types of choice-focusing scenarios: classic game-theoretic games, poker, and auctions. Some game examples are shown in Figure 3. Classic game-theoretic games, such as the prisoner's dilemma, have been distilled by economists from various real-world situations. These games are well-defined, with rigorous mathematical foundations, and can be extended to numerous scenarios (Owen, 2013). Consequently, many studies have utilized these games as testbeds to study social agents. The prisoner's dilemma (Rapoport & Chammah, 1965), as the most famous"}, {"title": "2.2 Communication-Focusing Game", "content": "Communication-focusing games refer to games where communication among participants is a core component, where language itself serves as a strategy, allowing participants to influence the game's progress and outcomes through verbal exchanges. These games emphasize interaction between players, with communication playing a crucial role. Leveraging the powerful language capabilities of LLMs, current research has explored the performance of social agents in various communication-focusing games, including Negotiation, Diplomacy, Werewolf, Avalon, and others. Some game examples are shown in Figure 4. Negotiation involves two or more individuals engaging in discussions to resolve conflicts, achieve mutual benefits, or reach mutually acceptable solutions (Bazerman et al., 2000; Zhan et al., 2024). Given that negotiation encompasses complex game behaviours, including non-zero-sum games, incomplete information games, non-cooperative and cooperative games, as well as repeated games, it represents a highly significant research domain. Abdelnabi et al. (2023) evaluated the negotiation capabilities of social agents by building upon an existing negotiation role-play exercise (Susskind, 1985) and incorporating three negotiation games synthesized using LLMs. By configuring agents with varying incentives, the experimental results revealed that agents' behaviour could be modulated to promote greediness or attack other agents. Meanwhile, other agents in the environment demonstrated the ability to detect intruders. These findings underscore the need for future research to focus on attack and defense mechanisms within multi-agent systems. Bianchi et al. (2024) developed NEGOTIATIONARENA, a platform featuring three types of games: allocating shared resources (ultimatum games), aggregating resources (trading games), and buying/selling goods (price negotiations). Experimental results reveal that LLM agents are also prone to anchoring and numerosity biases. Interestingly,"}, {"title": "3 Social Agent", "content": "In this section, we primarily introduce the core components of social agents, including the preference, belief, and reasoning modules."}, {"title": "3.1 Preference Module", "content": "Preference refers to an individual's subjective inclination toward certain things, reflecting personal tastes, values, or choices in decision-making. Notably, preferences are closely tied to an individual's payoff matrix and ultimate behaviour. In Figure 5, we present three key research questions of the Preference module. Leng & Yuan (2023) explored the impact of GPT-4's intrinsic preferences on decision-making, revealing similarities and differences between the model's decisions and human decisions. Human-like social behaviours observed in GPT-4 include reciprocity preferences, responsiveness to group identity cues, engagement in indirect reciprocity, and social learning capabilities. However, differences emerged as GPT-4 displayed a stronger inclination toward fairness than humans and responded decisively to negative stimuli, often retaliating against perceived uncooperative or harmful behaviours with heightened consistency. In addition, some studies have employed prompt engineering to configure LLMs with different preferences, aiming to investigate how these preferences influence LLM decision-making. Guo (2023) examined how prompting GPT with traits like fairness concern or selfishness influences its decisions, finding that in the ultimatum game, a \"fair\" GPT exhibited \"fair\" behaviour by offering higher amounts and being more likely to reject unfair offers. Phelps & Russell (2023) configured LLMs with four different preferences cooperative, competitive, altruistic, and self-interested and found that LLMs possess a basic ability to form clear preferences based on textual prompts. Noh & Chang (2024), based on the Big Five personality model, found that LLMs with high openness, conscientiousness, and neuroticism exhibited fair tendencies, while those with"}, {"title": "3.2 Belief Module", "content": "Beliefs represent an agent's informational (or mental) state about the world, encompassing its understanding of itself and other agents, and consist of the facts or knowledge the agent considers true (Georgeff et al., 1999). Specifically, beliefs are dynamic and can be updated as the agent perceives environmental changes or receives new information. It is important to note that these beliefs may be accurate (true beliefs) or inaccurate (false beliefs), as they do not always align with reality (Gopnik & Astington, 1988), as shown in Figure 6. Existing research primarily explores three questions: (1) Do agents possess internal beliefs? (2) How can the belief modelling capabilities of agents be enhanced? (3) Can agents revise their beliefs? Regarding the first question, Do agents possess internal beliefs?, current work investigates this from two perspectives: internal representations and external behaviours. From the perspective of internal representations, Zhu et al. (2024b) first demonstrated that LLMs can differentiate between the belief states of multiple agents using simple linear models applied to their intermediate activations. Building on this work, Bortoletto et al. (2024) expanded the experimental setup and found that linear probing accuracy on predicting others' beliefs improves with model size and, more importantly, with fine-tuning. However, Schouten et al. (2024)"}, {"title": "3.3 Reasoning Module", "content": "Reasoning refers to the process of inferring actions based on one's preferences and beliefs, as well as the historical information of other agents. In this context, we focus specifically on strategic reasoning, which involves the intermediate cognitive process of arriving at a final action in complex social scenarios characterized by multiple participants, diverse behaviours, multi-round interactions, dynamic strategies, and changing environments. Chain-of-Thought (Wei et al., 2022) and Tree-of-Thought (Yao et al., 2024), as widely-used reasoning methods, have already been adopted as baseline approaches in various game-theoretic studies (Akata et al., 2023; Costarelli et al., 2024; tse Huang et al., 2024). However, strategic reasoning in social scenarios presents unique challenges. (1) The involvement of multiple participants requires reasoning about the opponents' mental states. (2) The dynamic nature of the environment necessitates proactive exploration and evaluation of current and future possible states. To address the first challenge, existing work relies on machine theory-of-mind to achieve the goal of \"mind reading\". Theory-of-Mind (ToM) is a fundamental psychological process involving the ability to attribute mental states\u2014beliefs, intentions, desires, emotions, knowledge, etc.\u2014to oneself and others (Premack & Woodruff, 1978). The remarkable progress of LLMs has led to increased attention to whether machine ToM exists. Preliminary experiments by Bubeck et al. (2023) and Kosinski (2023) have shown that machine ToM has spontaneously emerged in contemporary LLMs. Consequently, many studies have leveraged machine ToM to enhance LLMs' strategic reasoning abilities in social scenarios. For example, Guo et al. (2023) designed the Suspicion-Agent, which introduces a theory of mind-aware planning approach that leverages higher-order ToM capabilities, considering not only what the opponent might do (first-order ToM) but also what the opponent believes Suspicion-Agent will do (second-order ToM). Wang et al. (2023) proposed the ReCon framework, integrating first-order and second-order perspective transitions to enhance LLM agents' ability to discern and counteract misinformation. Yim et al. (2024) employed a ToM planning method in the Guandan poker game to improve understanding of teammates' and opponents' beliefs and behavioural patterns. Liu et al. (2024b) proposed an intention-guided mechanism to enhance intention understanding, thereby improving game performance. Xu et al. (2023a) introduced Probabilistic Graphical Modeling, enriching LLMs' capabilities in multi-agent environments through ToM reasoning. Additionally, Zhang et al. (2024c) proposed K-Level-Reasoning, validated in two games: guessing 0.8 of the average and survival auction game, essentially a form of high-order ToM reasoning. To address the second challenge, existing work combines LLMs with reinforcement learning (RL) to achieve the goal of behaviour exploration and state evaluation in dynamic game environments. Gandhi et al. (2023) employed in-context learning, using a structured prompt based on search, value assignment, and belief-tracking strategies to solve strategic reasoning problems. Duan et al. (2024a) proposed ReTA, a set of LLM-based modules, including the main actor, reward actor, and anticipation actor, based on the concept of minimax gaming as a problem-solving framework. Zhang et al. (2024d) introduced BIDDER, which explores future states and incorporates backward reasoning during the reasoning process, exploring new states and predicting expected utility, ultimately combining historical and future contexts through bidirectional reasoning. Yang et al. (2024b) proposed SELFGOAL, comprising three modules: the Decomposition Module for decomposing goals, the Search Module for exploring sub-goals, and the Act Module for taking actions. Experiments in various competition and collaboration scenarios demonstrate that SELFGOAL provides precise guidance for high-level goals."}, {"title": "4 Evaluation Protocol", "content": "In this section, we mainly discuss the evaluation protocol for assessing the game-playing performance of social agents."}, {"title": "4.1 Game-Agnostic Evaluation", "content": "Evaluation in a social game scenario refers to the process of assessing and judging the behaviour of social agents across one or more dimensions, either qualitatively or quantitatively. It is worth noting that the establishment of evaluation metrics is closely tied to the credibility of experimental results and the generalizability of conclusions. Game-agnostic evaluation refers to an evaluation approach centred on the outcome of winning or losing the game. Most directly, the outcome (win/loss) of a game serves as the most straightforward evidence for assessing the quality of an LLM's game-playing capabilities. Consequently, win rate is often used as a primary evaluation metric across a wide range of studies. It is worth noting that, since different game scenarios have varying criteria for determining victory, it is necessary to set specific win/loss criteria based on the research context, such as Poker (Huang et al., 2024; Guo et al., 2023; Yim et al., 2024), Werewolf (Xu et al., 2023d;c; Wu et al., 2024b), Avalon (Wang et al., 2023; Shi et al., 2023; Light et al., 2023a), StarCraft II (Ma et al., 2023; Shao et al., 2024), Pok\u00e9mon Battles (Li et al., 2023c), and Murder Mystery Games (Zhu et al., 2024a). Additionally, Duan et al. (2024b) defined a unified metric, Normalized Relative Advantage, to measure the extent to which a participant outperforms or underperforms its opponent."}, {"title": "4.2 Game-Specific Evaluation", "content": "Game-specific evaluation refers to the assessment of an agent's performance in specific aspects of a game. Beyond the most intuitive win rate, current research increasingly focuses on the behavioural patterns and performance paradigms of LLMs across different games. Thus, the establishment of evaluation metrics is closely related to the specific behaviours being assessed. Mao et al. (2023) used survival rates to evaluate LLMs' ability to survive in resource-scarce scenarios. In the context of the prisoner's dilemma, Fontana et al. (2024) evaluated LLMs' behavioural tendencies across five dimensions: niceness, forgiveness, retaliation, emulation, and troublemaking. Guo et al. (2024) based their evaluation on the rationality assumption, using the tracking of payoff changes in auction games to determine whether the model behaves rationally. Ma et al. (2023) introduced metrics such as Population Block Ratio, Resource Utilization Ratio, Average Population Utilization, and Technology Rate to evaluate LLM performance in StarCraft II. Xia et al. (2024) developed the Normalized Profits metric in bargaining scenarios to evaluate the profit-acquiring capabilities of Buyers and Sellers. Zhang et al. (2024d) used average final chips in Limit Texas Hold'em and Pareto Optimality in negotiation to assess LLM performance. Qi et al. (2024) offered evaluation metrics to assess gameplay performance across various dimensions, including population, constructed cities, researched technologies, produced units, and explored territories. Ross et al. (2024) fit utility function parameters to experimental results to determine whether LLMs exhibit human-like behavioural biases. Chen et al. (2023) employed TrueSkill, a well-established game rating system, to evaluate the overall capabilities of LLMs in auctions. In addition to establishing evaluation metrics, some studies have constructed evaluation datasets to assess model capabilities during gameplay. Zhu et al. (2024a) developed the WellPlay evaluation set, using multiple-choice questions to assess the model's ability to understand factual information. Wu et al. (2024a) designed two tasks: Factual Question Answering and Inferential Question Answering, to evaluate the LLMs' ability to grasp information and to reason based on that information."}, {"title": "5 Future Directions", "content": ""}, {"title": "5.1 Standardized Benchmark Generation", "content": "LLMs are pre-trained on vast amounts of data, which often include existing game datasets, raising concerns about data leakage. One approach to address this issue is synthetic data generation (Long et al., 2024). By leveraging existing classic game structures, LLMs can be used to synthesize more diverse game data through context framing (Lor\u00e8 & Heydari, 2024). These newly generated games can serve as out-of-distribution benchmarks for evaluating agents. Additionally, a standardized evaluation framework, similar to OpenCompass (Contributors, 2023), should be developed to formalize future evaluation efforts."}, {"title": "5.2 Reinforcement Learning Agents", "content": "Although current social agents have shown promising performance in various games, existing research also highlights their limitations in multi-round, long-term, and complex game scenarios, where their performance falls short. Thus, relying solely on LLM-driven planning and decision-making is insufficient. To address these challenges, future work should incorporate reinforcement learning (RL)-based agents to enhance state exploration and long-term planning capabilities. In this research paradigm, new challenges will arise, in-"}, {"title": "5.3 Behaviour Pattern Mining", "content": "Existing studies primarily focus on predefined scenarios to examine the behaviour patterns of agents. However, with the advancement of multi-agent simulations, an intriguing direction is the automated discovery of game behaviour patterns that emerge spontaneously from agent interactions. It is important to note that, beyond explicit behaviours like cooperation, coordination, and betrayal, implicit causal relationships and long-term behavioural patterns should also be explored. On one hand, this can lead to a deeper understanding of agents' behavioural preferences and underlying traits. On the other hand, the autonomous emergence of these patterns in agents can offer new perspectives for research in human behavioural studies."}, {"title": "5.4 Pluralistic Game-Theoretic Scenarios", "content": "Even though existing research has made significant progress across various game-theoretic scenarios, there is still a lack of studies focusing on more granular pluralistic game scenarios that involve multiple languages, cultures, values, policies, and goals. Games in pluralistic scenarios introduce additional complexities, such as behaviour preferences shaped by agents' inherent cultural customs and values, as well as belief conflicts driven by dynamic, multi-objective considerations (Orner et al., 2024). These dimensions present new challenges for evaluating social agents and warrant further investigation in future research."}, {"title": "6 Related Works", "content": "The human-like capabilities of LLMs have drawn significant attention from social science researchers, prompting extensive exploration at the intersection of AI and social sciences (Xu et al., 2024a). A key development in this area is the shift from traditional Agent-Based Modeling to LLM-based agents, as explained by Ma et al. (2024) through computational experiments. Numerous studies have since applied LLM-based agents to diverse game scenarios, such as poker, Minecraft, and DOTA II, with more detailed summaries provided by (Xu et al., 2024b; Hu et al., 2024b;a). Furthermore, Zhang et al. (2024b) have analyzed the core strategic reasoning capabilities of these agents, distinguishing them from other reasoning approaches. While the previous reviews provide comprehensive overviews of related fields, our survey specifically focuses on social agents equipped with beliefs, preferences, and reasoning capabilities within diverse game-theoretic scenarios."}, {"title": "7 Conclusion", "content": "We provide a comprehensive summary of existing research on LLM-based social agents in game-theoretic scenarios from three perspectives: game framework, social agents, and evaluation protocol. This interdisciplinary field covers a wide range of topics, including social sciences, economics, decision sciences, and theory of mind. Current studies have primarily explored the more direct external behavioural patterns and internal cognition of social agents. Therefore, future research should focus on developing theoretical frameworks for cognitive representations within LLMs, conducting in-depth analyses of implicit and long-term game behaviour patterns, and enhancing agents' reasoning and planning capabilities in dynamic environments."}]}