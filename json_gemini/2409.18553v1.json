{"title": "Efficient Noise Mitigation for Enhancing Inference Accuracy in DNNs on Mixed-Signal Accelerators", "authors": ["Seyedarmin Azizi", "Mohammad Erfan Sadeghi", "Mehdi Kamal", "Massoud Pedram"], "abstract": "In this paper, we propose a framework to enhance the robustness of the neural models by mitigating the effects of process-induced and aging-related variations of analog computing components on the accuracy of the analog neural networks. We model these variations as the noise affecting the precision of the activations and introduce a denoising block inserted between selected layers of a pre-trained model. We demonstrate that training the denoising block significantly increases the model's robustness against various noise levels. To minimize the overhead associated with adding these blocks, we present an exploration algorithm to identify optimal insertion points for the denoising blocks. Additionally, we propose a specialized architecture to efficiently execute the denoising blocks, which can be integrated into mixed-signal accelerators. We evaluate the effectiveness of our approach using Deep Neural Network (DNN) models trained on the ImageNet and CIFAR-10 datasets. The results show that on average, by accepting 2.03% parameter count overhead, the accuracy drop due to the variations reduces from 31.7% to 1.15%.", "sections": [{"title": "I. INTRODUCTION", "content": "Deep Neural Networks (DNNs) [1]\u2013[3] have become a cornerstone in the field of artificial intelligence and machine learning due to their remarkable ability to model complex data patterns and perform sophisticated tasks. DNNs excel in learning hierarchical representations of data through multiple layers of abstraction, enabling them to automatically extract features and generalize well across a wide variety of tasks such as image recognition, natural language processing, and decision-making in complex environments such as robotics.\nWhile Deep Neural Networks (DNNs) deliver exceptional performance, they incur significant computational costs. Both training and inference require substantial processing power due to the large number of parameters and operations, including both linear and non-linear computations [4]\u2013[7]. Specialized hardware accelerators are essential for efficiently executing these models. Traditional CPUs lack the necessary parallelism for DNN workloads, while GPUs excel in parallel processing but consume high power, limiting their use in energy-constrained environments like edge devices. FPGAs [8]-[11], although customizable hardware accelerators, are fully digital and tend to have relatively high latency compared to GPUs. Additionally, their power consumption, while lower than GPUs in some cases, is still significant, making them less ideal for certain applications requiring extreme power efficiency.\nWhile some accelerators are fully digital, mixed-signal accelerators present a promising alternative, particularly for matrix-vector multiplication (MVM) [12], a critical operation in DNNs. Analog computing [13] is well-suited for MVM, offering significant gains in power efficiency and computational speed. Techniques explored include current-based methods with MOSFETs, charge-based approaches using SRAMs [14], and resistance-based technologies like memristors [15], [16] and phase-change memory (PCM) [17]. However, analog computations face reliability challenges due to process variations during manufacturing and temporal variations over time, which reduce computational accuracy. Addressing these issues to ensure precision and stability in analog accelerators is a key focus of ongoing research.\nTo enhance the reliability of analog-based computations, several techniques have been developed. One common approach is training-based methods [18], [19], where models are trained to tolerate lower-precision operations, thereby increasing their robustness to variations in analog hardware. Additionally, error correction codes (ECC) [20], [21] are used to detect and correct errors introduced during analog computations or data transmission, further improving reliability. Innovations at the device level, such as using more robust materials and advanced fabrication processes, help mitigate the effects of process and temporal variations. Furthermore, stochastic computing [22], [23] offers a probabilistic approach that inherently tolerates errors by relying on statistical properties of computations, thus enhancing reliability.\nIn this work, we introduce a probabilistic denoising module that enhances the robustness of DNNs with minimal hardware overhead. Unlike traditional methods that require retraining the entire model, our approach, inspired by parameter-efficient fine-tuning literature [24]\u2013[26] freezes the main model and trains only the denoising block, utilizing parameter-efficient fine-tuning to reduce time, memory, and computational costs. We also propose an algorithm to determine the optimal placement of the denoising blocks within the network. This flexible method is applicable to any analog-based MVM architecture, addressing reliability challenges from noise and variations in analog hardware. Finally, we present the architecture of the denoising block to demonstrate the feasibility of our approach."}, {"title": "II. BACKGROUND", "content": "A. Denoising in Deep Learning\nThe task of denoising, or recovering clean signals from corrupted observations, has long been a central problem in signal and image processing. Early approaches, such as Wiener filtering [27] and total variation minimization [28], operated based on predefined statistical assumptions about the signal and noise. However, these methods often struggled with real-world complexities, where noise characteristics are not easily modeled by simple assumptions. Deep learning methods, particularly convolutional neural networks (CNNs), have drastically improved denoising performance by learning noise patterns directly from data. A notable example is DnCNN [29], which predicts the residual noise in an image and subtracts it to produce a clean result. This residual learning strategy is effective but computationally expensive due to the use of large convolutional layers for denoising. Autoencoders [30] and generative models like GANs [31] have also been used, with GAN-based denoising [32] leveraging adversarial training to generate realistic clean images. However, these methods typically lack training and inference efficiency.\nProbabilistic models, such as Variational Autoencoders (VAEs) [33] and score-based generative models [34], model noise by capturing the uncertainty inherent in noisy data. These models estimate not just a clean signal but a distribution over possible clean signals, offering robustness in complex noise environments. Diffusion models, such as Denoising Diffusion Probabilistic Models (DDPM) [35], offer a probabilistic framework for denoising by iteratively adding noise in a forward process and learning to reverse this process to recover the original data. The key strength of diffusion models is their stepwise refinement of noisy inputs, allowing for precise noise removal over several iterations. While highly effective, diffusion models are computationally intensive, as they require multiple passes to gradually denoise the signal. In our bottleneck-based denoising block, we take inspiration from diffusion models' probabilistic reasoning by predicting both the mean and variance of the noise in a single pass.\nBottleneck architectures, widely used in networks like ResNets [36], reduce the computational cost of deep models by compressing intermediate representations into lower-dimensional spaces. Depthwise separable convolutions [37] extend this by separating the spatial and channel-wise operations, significantly reducing the number of parameters and computations required.\nB. Analog MVM Reliability\nAnalog-based matrix-vector multiplication (MVM) accelerators have gained attention for their potential to significantly improve power efficiency and computational speed in deep neural networks (DNNs). These accelerators utilize analog computing to perform MVM operations, a fundamental component in both DNN inference and training. By exploiting the continuous properties of analog circuits, they achieve reductions in both the energy required for computation and the on-chip area. Despite these promising advantages, analog MVM accelerators face critical challenges related to reliability, particularly due to noise, process variations, and temporal variations in analog components.\nA key issue affecting the reliability of analog MVM accel-erators is process variations that occur during manufacturing, leading to inconsistencies in device performance for compo-nents such as memristors, phase-change memory (PCM), and MOSFETs. These devices, which rely on properties like cur-rent flow, resistance, and charge storage, are highly susceptible to fabrication deviations. Minor manufacturing inconsistencies can introduce errors in analog computations, diminishing the precision of MVM operations and degrading overall system reliability. Additionally, temporal variations caused by en-vironmental factors like temperature fluctuations and voltage drift can further degrade analog component performance over time, resulting in shifting operational characteristics and reduced computational accuracy. Unlike digital systems, which are resilient to minor changes, analog systems are highly vulnerable to errors induced by these variations, exacerbating reliability issues.\nThe increased noise and reduced precision in MVM oper-ations significantly affect the inference accuracy of DNNs, especially as their scale and complexity grow, leading to degraded overall system performance. In high-accuracy ap-plications, the unreliability of analog MVM accelerators be-comes particularly problematic. Given the critical role of matrix-vector multiplications in DNN performance and the growing interest in mixed-signal systems for edge computing and energy efficiency, addressing the reliability challenges in analog MVM accelerators is essential. Ensuring reliable operation despite process and temporal variations is crucial for maintaining high inference accuracy and enabling the practical deployment of energy-efficient, high-precision DNNs in real-world applications.\nC. Related work\n1) Training-based methods: Previous work, such as [18] and [19], has proposed noise-aware training methods for DNNs. While these methods enhance accuracy by enabling the model to adapt to noisy environments, they require re-training the entire model from scratch, which is particularly time-consuming and computationally expensive, especially for larger DNNs. Furthermore, these approaches often employ low-precision computations to increase the model's robustness to noise, which can negatively affect overall performance.\n2) Stochastic computing based methods: While stochastic computing (SC) offers advantages in energy efficiency and simplicity, it also presents several challenges. One of the primary issues is the inherent loss of precision due to the use of probabilistic bitstreams to represent data, which often results in accuracy trade-offs, especially in more complex neural networks. To achieve higher precision, SC requires longer bitstreams, which can slow down computations and reduce the overall efficiency benefits. Additionally, SC typically necessitates retraining models from scratch, as its computation"}, {"title": "III. METHODOLOGY", "content": "In subsection A, we provide an overview of the denoising mechanism and the mathematical foundation of our framework. In subsection B, we describe the proposed denoising block. Finally, in subsection C, we explain how to determine the optimal placement of the denoising block in a neural network to balance its noise reduction effectiveness with computational overhead. Throughout this section, we denote the given pretrained neural network model (without any noise) as M, and the noisy version which is also equipped with the denoising module, as M*. We use L as the neural network loss and the D as our dataset, which contains the input data samples and the ground truth. Finally, in subsection D, we present a detailed analysis of the denoising block's hardware architecture along with its data flow.\nA. Denoising Overview\nThe denoising process is fundamentally concerned with estimating and mitigating the noise component embedded within a noisy input tensor X. Specifically, given X, which contains an unknown noise component Z (where the clean signal is represented as X - Z), the goal is to predict a denoised output X = X \u2212Z. Here, Z serves as an approximation of the true noise Z. Our denoising framework, inspired by principles from denoising diffusion probabilistic models (DDPMs) [35], assumes that the noise tensor Z follows a Gaussian distribution, Zi ~ N(\u03bc\u03af, \u03c37), where each element of the noise is independently and identically distributed according to a Gaussian distribution characterized by a mean \u00b5i and variance of. The task of denoising can be formalized as a minimization of the expected reconstruction error between the unknown clean signal X \u2013 Z and the predicted denoised signal X = X \u2013 2. Mathematically, this objective can be expressed as:\nmin E_{z} ||X - (X \u2013 Z)||^2 = min E_{z, 2} ||Z \u2013 \\hat{Z}||^2\n= min E_{} ||\\hat{\\mu} + \\hat{\\sigma} \\epsilon - (\\mu + \\sigma \\epsilon)||^2, (1)\nwhere \u2208 ~ No, I) represents a standard normal variable, and \u00fb and 2 are the predicted mean and variance of the noise, respectively. This formulation aims to ensure that the predicted noise closely approximates the true noise component by directly minimizing the discrepancy between their statistical characteristics.\nThe essence of the denoising task lies in accurately pre-dicting the mean \u00fb and variance 62 of the noise, as these parameters allow the reconstruction of an estimate of the noise 2. This approach leverages the Gaussian assumption to model the noise structure, making it feasible to utilize simple yet effective probabilistic estimations. The denoising block leverages these predictions to sample noise as:\n\\hat{Z} = \\hat{\\mu} + \\epsilon \\sqrt{Noise\\_Var} + Noise\\_Mean, (2)\nwhere the predicted variance, Noise_Var = \u00f4\u00b2, specifies the variability, and Noise_Mean \u00fb centers the noise around the predicted mean value. his probabilistic formulation aligns with the operation of denoising diffusion probabilistic models (DDPMs); however, instead of iteratively refining the estimate through multiple denoising steps, we achieve denoising in a single pass, significantly reducing the computational burden. DDPMs employ a U-Net architecture to predict the mean (\u00fb) at each denoising step, systematically removing it from the noisy input to create a less noisy version of the signal. This iterative approach is primarily designed for generative AI tasks, where the quality of denoising is crucial for image synthesis. In contrast, our objective goes beyond the denoising accuracy and focuses on enhancing the overall performance of the neural network for its specific task, particularly under the constraints of mixed-signal hardware that is susceptible to noise. Instead of directly minimizing the denoising error alone, our framework thus integrates the denoising block within the neural network to minimize the task-specific loss L. The denoising parameters \u00fb and \u00f4\u00b2 are optimized to reduce the expectation of the loss at the output of the network M*:\nmin E_{} L(M^*(x), y), \u2200x, y \u2208 D, (3)\nwhere the expectation is taken over the randomness introduced by the variable \u20ac. This formulation underscores the primary innovation of our approach: treating the denoising block as an integrated component of the model rather than an isolated preprocessing step.\nThe overall process involves the following steps: (1) Noise Simulation: The pre-trained model Mis modified by intro-ducing noise into its operations, with parameters \u03bcand o ju-diciously chosen to simulate the non-idealities associated with the target mixed-signal hardware. (2) Denoiser Integration: The denoising block is inserted into the model, resulting in the modified architecture M*. (3) Training the Denoiser: Pa-rameters of the denoising block are trained, while parameters of the original model M remain fixed. This ensures that the computational overhead is minimized, as only a small fraction of the model's total parameters are updated. The assumption that the denoiser's operations are noise-free further simplifies the optimization process, allowing rapid convergence even"}, {"title": "B. Denoising block", "content": "The overall architecture of the proposed denoising block is shown in Fig. 1. The architecture borrows ideas from the bottleneck layer (block) found in neural network architectures like autoencoders and specific kinds of D models. The block processes the noisy input tensor X by first applying a point-wise convolution (1 \u00d7 1 convolution) to reduce the channel dimension of the tensor. This operation is computationally efficient and parameter-light due to the use of a 1 \u00d7 1 filter, which performs channel-wise transformation without altering the spatial dimensions.\nFollowing this, a depth-wise convolution with a kernel size of 3 \u00d7 3 is applied to capture spatial features in the reduced-dimensional representation. To ensure that the predicted noise mean and variance tensors match the dimensions of the input, two parallel point-wise convolutions are subsequently employed. These convolutions are responsible for generating the noise mean and noise variance, while restoring the channel dimensions back to that of the original input. Given that the noise in each element of the input is assumed to follow a normal distribution, the noise estimation can be derived by sampling from a standard normal, scaling it by the predicted variance, and shifting it by the predicted mean according to the equation 2 to obtain 2. The denoised output is then obtained by subtracting the estimated noise from the input:\nX = X \u2212 \\hat{Z} (4)\nA key advantage of the proposed denoising block is its lightweight design, which aligns with the principles of bottleneck architectures. This structure allows the module to be trained with minimal computational overhead, especially since the parameters of the original pretrained model remain fixed during training. This efficient integration ensures that the addition of the denoiser does not significantly impact the overall model's computational cost."}, {"title": "C. Integration of Denoising Block", "content": "Integrating the denoising block after every convolution operation would result in significant computational and latency overheads, making this approach impractical. Therefore, to achieve a balance between denoising effectiveness and computational efficiency, we strategically insert the denoising block after a select few layers of the model. This selective placement aims to optimize performance while minimizing the additional overhead introduced by the denoiser.\nGiven a fixed budget \u03b7 representing the percentage of the denoiser parameters to be utilized, our objective is to design an algorithm that optimally selects the layers where the denoising block should be inserted. Intuitively, the denoising block should be placed after layers whose outputs significantly impact the overall loss of the neural network. To formalize this intuition, we consider the first-order Taylor expansion of the neural network's loss function. Assuming noise is added only to the output of layer l while all other layers remain unchanged, the loss L can be approximated as:\nL(y_l + z) \u2248 L(y_l) + z\u2207_{y_l}L (5)\nwhere y denotes the output of layer l, z represents the noise, and Vy L is the gradient of the loss with respect to the layer's output. This approximation indicates that, for a given noise magnitude, the impact of noise on the model's loss is proportional to the gradient norm of the layer's output feature map. Consequently, layers with the highest gradient norm ||\u2207y\u0131L|| will have the most significant effect on the model's predictions. Therefore, the denoising block should be strategically placed after such layers to maximize its effectiveness while adhering to the parameter budget \u03b7.\nBased on this metric, we propose a heuristic approach to strategically insert the denoising blocks into the DNN model. Specifically, we compute the gradient of the loss with respect to the output feature maps of each layer in the pre-trained model and rank these gradients in descending order of their magnitudes. Denoising blocks are then incrementally added to the layers according to this sorted list, starting with those layers whose gradients have the highest magnitude, until the total parameter count reaches the specified budget \u03b7."}, {"title": "D. Denoiser Hardware Architecture", "content": "The hardware architecture of the implemented denoising block is depicted in Fig. 2. We implemented the denoising block within a digital module to ensure that it operates free from noise and reliability issues, as it is essential for the denoiser itself to remain noise-free.\n1) Overall architecture: The denoiser hardware architecture features a Denoiser Control Unit (DCU), which orchestrates the activation of specific computational blocks, including convolution, leaky ReLU, and noise cancellation modules. The DCU ensures that only the relevant block is activated during each phase of computation. Once a block is enabled, it retrieves the required data such as weights and activa-tions-from memory, executes the necessary operations, and"}, {"title": "2) Noise cancellation architecture:", "content": "The noise cancellation block is responsible for generating noise based on the pre-dicted mean and variance, and subtracting it from the input\u2014a process referred to as denoising or noise cancellation. To implement this, we employed the Box-Muller transform, as shown below:\nZ_1 = \\sqrt{-2ln(U_1)} \u00d7 cos (2\u03c0U_2)\nZ_2 = \\sqrt{-2ln(U_1)} \u00d7 sin (2\u03c0U_2) (6)\nThe random variables U\u2081 and U2 are independent and uniformly distributed, drawn from a uniform(0, 1) distribution, and Z1 and Z2 are normally distributed random variables. To generate these uniform random variables, we utilize multiple Linear Feedback Shift Registers (LFSRs), each initialized with distinct seed values. These LFSRs produce random outputs, which are normalized by dividing by the maximum representable value in the system's numerical format.\nThe normalized outputs of the LFSRs are then passed to Uniform-to-Normal Converters (UNCs), where the normally distributed outputs are generated from the uniform inputs using the Box-Muller transform (equation 6). Since the sum Z+Z2 is constant, we utilize only Z1 to ensure that the generated values remain fully independent. Finally, the Gaussian noise generator uses the generated normal values, along with the predicted noise mean and variance, to produce the predicted noise values based on equation 7.\nZ_1 ~ N(0,1) and Y = Z_1 \u00d7 \u03c3 + \u03bc\nY ~ Guassian(\u03bc, \u03c3\u00b2) (7)\nFinally, the generated noise values are subtracted from the noisy activations to obtain the denoised activations."}, {"title": "IV. RESULTS AND DISCUSSION", "content": "In this section we first provide the experimental setup of our framework, then we detail our main results on the denoising performance and the hardware metrics, including power.\nA. Experimental Setup\nOur experiments involve widely recognized neural network models and datasets. Specifically, we utilize the ImageNet-1k as the pretraining evaluation benchmark, and CIFAR dataset as our transfer learning evaluation benchmarks. We utilize a range of models, including MobileNet-V2 [38], ResNet-18 [29], and EfficientNet-B0 [39], and DenseNet-121 [40]. The pretrained"}, {"title": "V. CONCLUSION", "content": "In conclusion, our method presents an innovative denoising framework that effectively preserves the accuracy of DNNS in mixed-signal accelerators despite the noise introduced by process and temporal variations. Notably, this approach eliminates the need to retrain the entire model while maintaining low latency and minimal power consumption overhead. Additionally, our framework is versatile and can be applied to any mixed-signal DNN accelerator, enhancing the robustness of these models."}]}