{"title": "Few-Shot Classification and Anatomical Localization of Tissues in SPECT Imaging", "authors": ["Mohammed Abdul Hafeez Khan", "Samuel Morries Boddepalli", "Siddhartha Bhattacharyya", "Debasis Mitra"], "abstract": "Accurate classification and anatomical localization are essential for effective medical diagnostics and research, which may be efficiently performed using deep learning techniques. However, availability of limited labeled data poses a significant challenge. To address this, we adapted Prototypical Networks and the Propagation-Reconstruction Network (PRNet) for few-shot classification and localization, respectively, in Single Photon Emission Computed Tomography (SPECT) images. For the proof of concept we used a 2D-sliced image cropped around heart. The Prototypical Network, with a pre-trained ResNet-18 backbone, classified ventricles, myocardium, and liver tissues with 96.67% training and 93.33% validation accuracy. PRNet, adapted for 2D imaging with an encoder-decoder architecture and skip connections, achieved a training loss of 1.395, accurately reconstructing patches and capturing spatial relationships. These results highlight the potential of Prototypical Networks for tissue classification with limited labeled data and PRNet for anatomical landmark localization, paving the way for improved performance in deep learning frameworks.", "sections": [{"title": "I. INTRODUCTION", "content": "In the rapidly advancing domain of medical imaging, accurate classification and anatomical localization of tissues are critical for diagnostic, therapeutic, and research purposes. Recent advances in the application of deep learning techniques have significantly expanded their potential in imaging classification [1] [2]. However, the scarcity of data in the medical domain often necessitates specialized adaptations to meet the stringent demands for precision and reproducibility. This research draws inspiration from two pivotal studies: The development of Prototypical Networks [3], and Propagation Reconstruction Network (PRNet) [4]. These studies form the foundation for our methodologies, adapted and applied to Single Photon Emission Computed Tomography (SPECT) images, focusing on the tissues of the ventricles, myocardium, and liver.\nThe first aim of our study was to address the challenges posed by a severely limited dataset of only 12 SPECT images. To address this shortcoming, we implemented a Few-Shot Learning (FSL) approach, leveraging Prototypical Networks [3]. This approach was tailored to classify segmented tissue mask types\u2014myocardium, ventricles, and liver\u2014by representing each class with a prototype in a learned metric space.\nThe second aim of our study was to accurately determine the anatomical locations of tissues within 2D SPECT images. To achieve this, we adapted the architecture of the PRNet [4], originally designed for 3D CT and MRI images, for 2D convolutional processing. As shown in Fig. 1, we accurately reconstruct patches, capturing spatial relationships to predict the relative spatial coordinates between anatomical landmarks. We reviewed advancements in few-shot learning that have shaped image classification. Koch et al. [5] used Siamese Neural Networks for one-shot image recognition, setting a benchmark for learning with minimal data. Building on this, Shaban et al. [6] enhanced semantic segmentation by adapting Fully Convolutional Networks (FCNs) to new tasks. Similarly, Snell et al. [3] introduced Prototypical Networks to streamline classification by creating class-specific prototypes in a learned metric space. Expanding on these ideas, Rakelly et al. [7] used support images to improve image classification."}, {"title": "II. METHODOLOGY", "content": "To apply Prototypical Network for few-shot classification of myocardium, ventricles, and liver masks, we designed a convolutional neural network (CNN) to map input images to a metric space via the embedding function ff. We used a pretrained ResNet-18 [8] as the backbone, fine-tuning it for the specific few-shot classification task. The forward pass of the Prototypical Network computes classification scores using support and query images. The support images create prototype ck representations for each class k, which are the mean feature vectors of the support examples. Query images x are then classified by computing a softmax over the Euclidean distances d(z, z') to these prototypes, as shown in Eq. 1:\n\n$P(y = k|x) = \\frac{\\exp(-d(f(x), c_k))}{\\sum_{k'} \\exp(-d(f(x), C_{k'}))}$"}, {"title": "B. Propagation-Reconstruction Network (PRNet)", "content": "The Propagation-Reconstruction Network (PRNet) was originally designed for 3D CT and MRI images [4]. We adapted it for 2D slices of SPECT imaging by modifying its configuration from 3D to 2D layers, enabling it to focus on spatial information and accurately identify anatomical landmarks. PRNet includes an encoder, fully connected layers for predicting anatomical positions, and a decoder that reconstructs the original image for validation, as shown in Fig. 1. The model uses self-supervised learning by randomly selecting two points, ci and cj, within an image. The relative offset between them, dji, guides the learning process. Two fixed-size patches, x(ci) and (cj), are cropped around Ci and cj, then processed through PRNet to obtain their 2D anatomical coordinates, a(ci) and a(cj). The predicted offset, d'ji, determines the spatial relationship between the points in the latent vector space. As shown in Eq. 3, PRNet employs a self-supervised loss function Lssl, composed of two main components: the distance loss (Ldis), which quantifies the error in the predicted relative positions, and the reconstruction loss (Lrec), which measures the accuracy of the reconstructed patches xr(ci) and xr(cj), compared to the originally cropped patches.\n$L_{ssl} L_{dis} + L_{rec}$\nIn summary, PRNet provides a self-supervised framework that leverages inherent anatomical similarities across individuals to facilitate landmark localization in medical imaging with minimal reliance on extensive labeled datasets."}, {"title": "III. RESULTS AND DISCUSSION", "content": "The experimental results highlight the effectiveness of both the Prototypical Network and PRNet in their respective tasks. For the Prototypical Network, we used episodic batches for training and testing. Each episode included a fixed number of classes, support images, and query images. As illustrated in Fig. 2, we used 3 support images and 6 query images per class, training the model for 10 episodes with the Adam optimizer (learning rate: 0.001 and cross-entropy loss). The model achieved 96.67% accuracy and 0.486 loss on the training set, and 93.33% accuracy and 0.366 loss on the validation set. It effectively learned to classify tissue types from limited labeled data, demonstrating its proficiency in few-shot learning for classification of SPECT images.\nThe PRNet model, trained using numerous pairs of cropped patches from a single SPECT image via random double cropping, used an encoder-decoder architecture with skip connections to learn relative positions between patches. Training involved minimizing the self-supervised loss Lssl using the Adam optimizer (learning rate: 1e-3). Over 50 epochs, each with 10 iterations, the model achieved a training loss of 1.395, demonstrating its ability to capture spatial relationships and accurately reconstruct input patches, as illustrated in Fig. 1."}, {"title": "IV. CONCLUSION", "content": "In this paper, we addressed the challenges of accurate tissue classification and anatomical localization in SPECT imaging under the constraint of limited data. The Prototypical Network effectively classified myocardium, ventricle, and liver tissues with high training and validation accuracies, demonstrating proficiency in few-shot learning. PRNet, adapted for SPECT imaging, learned spatial relationships between anatomical landmarks and achieved a low training loss, paving the way for integrating and improving segmentation accuracy in deep learning frameworks in the future."}]}