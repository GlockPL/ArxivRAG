{"title": "DANA: Domain-Aware Neurosymbolic Agents for Consistency and Accuracy", "authors": ["Vinh Luong", "Sang Dinh", "Shruti Raghavan", "William Nguyen", "Zooey Nguyen", "Quynh Le", "Hung Vo", "Kentaro Maegaito", "Loc Nguyen", "Thao Nguyen", "Anh Hai Ha", "Christopher Nguyen"], "abstract": "Large Language Models (LLMs) have shown remarkable capabilities, but their inherent probabilistic nature often leads to inconsistency and inaccuracy in complex problem-solving tasks. This paper introduces DANA (Domain-Aware Neurosymbolic Agent), an architecture that addresses these issues by integrating domain-specific knowledge with neurosymbolic approaches. We begin by analyzing current AI architectures, including AutoGPT, LangChain ReAct and OpenAI's ChatGPT, through a neurosymbolic lens, highlighting how their reliance on probabilistic inference contributes to inconsistent outputs. In response, DANA captures and applies domain expertise in both natural-language and symbolic forms, enabling more deterministic and reliable problem-solving behaviors. We implement a variant of DANA using Hierarchical Task Plans (HTPs) in the open-source OpenSSA framework. This implementation achieves over 90% accuracy on the FinanceBench financial-analysis benchmark, significantly outperforming current LLM-based systems in both consistency and accuracy. Application of DANA in physical industries such as semiconductor shows that its flexible architecture for incorporating knowledge is effective in mitigating the probabilistic limitations of LLMs and has potential in tackling complex, real-world problems that require reliability and precision.", "sections": [{"title": "Background & Motivation", "content": "With the rise of large language models (LLMs) as a potent new means for organizing, retrieving and reasoning about diverse information, various attempts have been made to use them for autonomous problem-solving. AutoGPT[6] is an early implementation in this category and has become one of the most followed open-source AI projects since its inception in 2023. Many popular LLM frameworks and ecosystems such as LangChain [10] have followed suit, creating their own agent implementations such as LangChain ReAct[11].\nSo far, the \"agent bloom\" has borne some productive fruits, especially in creative content-generation applications. However, there has not been meaningful success in real-world industry domains that require reliability and precision in solving complex problems, especially when dealing with physical processes and operations. Practitioners have encountered inconsistency and inaccuracy when applying autonomous agents to use cases in which they need determinism and reproducibility and not creativity. These issues stem from LLMs' inherent probabilistic nature, which allows for flexibility and generalization but introduces unpredictability in outputs."}, {"title": "AI System Architectures Through a Neurosymbolic Lens", "content": "To solve a meaningfully complex problem, an AI system needs to perform two principal activities: program search, in which the system comes up with a program for solving the posed problem, and program execution, in which the system runs that program for the solution. The involved program may take various forms, from natural language to symbolic representations such as graphs, hierarchies, or programming-language code."}, {"title": "Review of Recent Planning & Reasoning Literature", "content": "Recent literature on LLM-based planning and reasoning has created many techniques implemented in autonomous agent frameworks. An early approach, and one that continues to inspire new adaptations, is Chain of Thought (CoT) [24]. Zero-shot CoT, also known as single-path reasoning, is effective for straightforward problems but is limited in its capacity to synthesize multiple reasoning paths for the best result. Advancements such as Chain of Thought with Self-Consistency (CoT-SC) [23] address this limitation by reasoning through multiple paths and employing majority voting to determine the most consistent output. The Tree of Thought (ToT) [26] framework expands on CoT-SC by considering planning as a search problem. This approach represents each potential step in a plan as a node in a tree structure. At each step, models evaluate all possible subsequent steps and choose the most appropriate one.\nThe LLM-only CoT/ToT approaches have been hindered by LLMs' inconsistency, and hybrid approaches have been proposed, incorporating traditional symbolic planners into the planning and reasoning process. Techniques such as LLM+P [12] and LLM-DP [4] involve translating natural language into symbolic representations, which are then processed by external planners to aid in decision-making. Although these methods show promise in enhancing planning capabilities, they remain contingent on LLMs' proficiency in accurately converting natural language into symbolic forms. Furthermore, the generated plans may not always align with human preferences.\nResearchers have also increasingly recognized the importance of additional feedback and/or input from the environment, auxiliary models and human experts or users. For instance, ReAct [27] relies on environmental feedback after an action is taken, using it to reason and generate subsequent steps. LLM-Planner [20] employs physical grounding to create and update plans for embodied agents. Voyager [22] enhances its planning by incorporating feedback from program execution progress, errors and self-verification results, which refine future actions. Similarly, Ghost [30] integrates environmental feedback, such as action outcomes and state changes, into its reasoning and decision-making processes. SayPlan [19] uses a scene graph simulator to derive feedback, iteratively adjusting its strategies based on outcomes and state transitions until a successful plan is formed. SelfCheck [16] enables models to evaluate their own step-by-step reasoning, identifying and correcting errors. InterAct [3] uses different models to assist the main model in avoiding errors and"}, {"title": "Review of Recent Neurosymbolic Literature", "content": "Researchers have created techniques that combine the strengths of neural networks and symbolic reasoning to achieve better-controlled outcomes. Xu et al. [25] used symbolic structures as a form of regularization during the training phase of neural networks. This regularization acts as a bridge between neural output vectors and predefined logical constraints, ensuring that the outputs align more closely with logical expectations. Such approaches have been particularly beneficial in domains requiring visual reasoning [14], where they enable models to represent complex structures like scenes, words and sentences with a symbolic concept learner. This combination facilitates more accurate visual understanding and reasoning by integrating symbolic reasoning capabilities with the perceptual power of neural networks. In addition to visual reasoning, neurosymbolic AI has been applied to algorithmic reasoning tasks, particularly in scenarios involving symbolically grounded inputs [5, 5, 21]. Another approach involves generating outputs that are consistent with a predefined symbolic knowledge base [13, 15, 29], thereby addressing the uncertainty and variability inherent in purely neural approaches. By grounding neural network outputs in a symbolic framework, these approaches reduce the ambiguity of the results and ensure adherence to logical rules.\nLLMs have further enabled the combination of the flexibility of neural networks with the rigorous structure of symbolic reasoning, thanks to their ability to generate symbolic representations in formal languages such as Planning Domain Definition Language (PDDL) [12] and First-Order Logic (FOL) [17]. These representations can serve as inputs into traditional symbolic planners [17] or differentiable symbolic programming frameworks [28]. The typical pipeline of translating natural language into logical languages, performing symbolic reasoning and then translating the results back into natural language allows for a more interpretable and controllable AI system, in which the reasoning process is transparent and can be audited or refined. Logic-LM [18] is one of the most notable implementations of this approach. However, a key challenge is formulating correct and effective logical representations for complex problems. Inaccurate formulations lead to inefficiencies and errors in reasoning, as symbolic reasoners struggle to resolve ambiguities or inconsistencies. To address this, Logic-LM++ [9] introduces a process for the system to iteratively refine logical formulations. However, despite these neurosymbolic advancements, without human guidance AI systems still face many challenges in complex, domain-specific problems that require deep expert knowledge."}, {"title": "Analyses of Current AI Architectures", "content": ""}, {"title": "AutoGPT and Related Frameworks & Tools", "content": "AutoGPT is an open-source autonomous agent implementation. Given a problem to solve, an AutoGPT agent creates and then executes a list of tasks for doing so. Whenever it cannot accomplish a task right away, it further creates and executes a decomposed list of sub-tasks. At the individual task level, in addition to processing textually described tasks, an AutoGPT agent can also trigger commands - interchangeably called \"actions\" or \"tools\" - which involves getting or creating and then running Python code for various purposes, including querying information from external sources (e.g., Google Search), manipulating files and exporting data back to the user.\nAutoGPT has inspired a number of derivative or similar autonomous agent implementations, including AgentGPT [1] and GodmodeAI [2], which add functionalities such as data-source connections, human-in-the-loop approval and feedback, and handling of non-text data such as images.\nInterpreted through our neurosymbolic program-search-and-program-execution paradigm, the AutoGPT family creates problem-solving programs by an LLM, without reference to domain-specific knowledge. Dur-"}, {"title": "LangChain ReAct", "content": "LangChain ReAct, another open-source autonomous agent implementation, combines the reasoning-and-acting (ReAct) conceptual framework [27] and the LangChain ecosystem of tools. A LangChain ReAct agent solves a problem by iterative CoT reasoning with evidence collected from the agent's available tools.\nLike AutoGPT, LangChain ReAct creates problem-solving programs by an LLM without reference to domain-specific knowledge. During program execution, textually described tasks are processed by the LLM, while tool-calling tasks are processed by the corresponding LangChain tools - which are all Python functions, some of which may trigger neural (LLM) processing such as retrieval-augmented generation (RAG). There is currently no affordance for on-the-fly programming-code creation and execution.\nLangChain ReAct performs better than typical question-answering engines and RAG agents when multiple information sources and multiple reasoning passes are needed to arrive at a solution. However, its users have also encountered issues of inconsistency [6] and inaccuracy."}, {"title": "OpenAI ChatGPT-4o & Assistant API", "content": "OpenAI's ChatGPT-4o and its corresponding Assistant API exhibit materially improved problem-solving capability, especially in data analysis.\nAlthough the technical architectures of OpenAI's proprietary products are undisclosed, we could speculatively infer certain underlying components and working mechanisms through observing how ChatGPT-4o works. When faced with a complex data-analysis problem, ChatGPT-4o seemingly creates a solution plan that includes Python coding tasks and integrative reasoning tasks. The Python code is created by the GPT-4o LLM and run by a Python interpreter. The plans are likely quite compact - each analysis typically involves up to five code snippets, and seemingly only a couple of integrative reasoning tasks.\nChatGPT-4o has a basic Memory integration that can help retain important facts stated by users. Users can tactically use this Memory mechanism to store relevant domain-specific knowledge, with the hope of enhancing ChatGPT-4o's response quality. Whether and how Memory is leveraged by ChatGPT-4o's in data analysis is unclear.\nReports of ChatGPT-4o's inconsistency and and inaccuracy suggest its architecture is also not rigorously equipped to handle complex analytical scenarios."}, {"title": "Summary and Takeaways from Current Architectures", "content": "The above analyses of current AI architectures are summarized in Table 1.\nThis reveals several common patterns explaining inconsistency and inaccuracy in complex problem-solving:\n1. Reliance on LLMs for program creation from scratch, leading to variability in problem solving approaches;\n2. Heavy involvement of LLMs in program execution, contributing to inconsistency at the individual task level; and\n3. Limited or no incorporation of domain-specific knowledge relevant to problem-solving.\nThese weaknesses suggest that AI-system architectures could be improved by shifting more responsibility to symbolic structures and their more deterministic operations, and by organizing and utilizing relevant domain-specific knowledge."}, {"title": "DANA: Domain-Aware Neurosymbolic Agent", "content": "Based on the above insights, we propose DANA (Domain-Aware Neurosymbolic Agent), an architecture paradigm designed to achieve greater deterministic behavior and ultimately more consistent and accurate output in autonomous problem-solving.\nThe DANA architecture is based on three core principles:\n1. First-class treatment of domain-specific knowledge;\n2. Use of both natural-language and symbolic representations of knowledge; and\n3. Explicit modeling of knowledge-capture (CAPTURE) and knowledge-application (APPLY) processes.\nThese principles are realized through the following key components of DANA:\n1. Knowledge Capture Process: manual and automated methods for receiving, extracting and translation knowledge, and persisting such knowledge in the Knowledge Store and the Program Store for"}, {"title": "Knowledge Store", "content": "The Knowledge Store is a collection of definitions, facts, formulas, expert heuristics and inference rules useful in the concerned domain. This knowledge can be referred to and leveraged in both program search and program execution, providing a foundation of domain-specific information."}, {"title": "Program Store", "content": "The Program Store is a storage of programs known to be applicable to certain well-characterized problems in the concerned domain. Each program comes with descriptive metadata about its purpose, facilitating the program search step during problem-solving. This component allows DANA to quickly identify and apply known solutions to familiar problem types."}, {"title": "Program Search Process with Program Finder & Program Creator", "content": "The Program Finder is a mechanism for finding pre-existing programs applicable to posed problems, by looking into the Program Store and leveraging the domain knowledge in the Knowledge Store.\nThe Program Creator is a mechanism for creating new programs when no applicable pre-existing ones are found in the Program Store. It can leverage the domain knowledge in the Knowledge Store to create more effective and domain-appropriate programs."}, {"title": "Knowledge Capture Process & Knowledge Representations", "content": "Because domain-specific knowledge significantly influences problem-solving quality, DANA treats the capture and representation of facts-and-rules knowledge and known programs as first-class concerns."}, {"title": "Knowledge Capture", "content": "DANA supports two main methods for populating the Knowledge Store and Program Store:\n1. Manual Capture: domain experts or AI engineers directly input knowledge and programs; and\n2. Automated Capture (AC): a Knowledge Encoding Assistant interviews domain experts and automatically encodes their knowledge and problem-solving strategies."}, {"title": "Facts-and-Rules Knowledge Forms", "content": "The facts-and-rules knowledge in DANA can take two forms:\n1. Natural-Language Knowledge (NK): knowledge represented in natural language, easily understandable by humans; and\n2. Symbolic Knowledge (SK): knowledge represented in more formal, symbolic forms (e.g., Prolog relations).\nDuring problem-solving, NK is processed by neural engines (e.g., LLMs) for interpretation and reasoning, while SK is processed by symbolic engines with deterministic operations."}, {"title": "Program Forms", "content": "Likewise, known programs in DANA can also take two forms:\n1. Natural-Language Programs (NP): programs described largely in natural language, e.g., Hierarchical Task Plans (HTPs) with natural-language tasks; and\n2. Symbolic Programs (SP): programs in symbolic forms, such as Python code."}, {"title": "DANA Design Space", "content": "By supporting the above alternative capture methods and knowledge and program forms, DANA can flexibly adapt to different problem domains. The above design choices and their various combinations make up the DANA design space described in Table 2. These permutations and hybrids combining them allow for flexible and versatile AI system designs incorporating diverse knowledge content and formats."}, {"title": "Implementation & Empirical Benchmarking", "content": "To validate the efficacy of DANA, we implemented a specific variant in the open-source OpenSSA framework (https://github.com/aitomatic/openssa/blob/main/openssa/core/agent/dana.py)\nand compared its performance against those of current AI systems on a well-known problem-solving benchmark dataset."}, {"title": "OpenSSA Implementation of DANA", "content": "We implemented the DANA-NK-NP variant, which uses natural-language facts-and-rules knowledge representation and natural-language programs. Implementation details include:\n1. Knowledge Store: a text storage containing domain-specific definitions, facts, formulas, expert heuristics, and rules of thumb, all described in natural language;\n2. Program Format: Hierarchical Task Plans (HTPs) with natural-language task descriptions, which provide a human-understandable means for expressing how a goal can be achieved or a problem solved through hierarchical decomposition;\n3. Program Store: a structured storage containing HTPs, each with a unique name and descriptive metadata about the problem it is designed to solve;\n4. Program Finder: implemented with an LLM for recognizing directly applicable programs for posed problems through descriptive metadata in the Program Store;\n5. Program Creator: implemented with an LLM that can be instructed to decompose a target problem or task into a more detailed HTP with sub-tasks; and\n6. Program Execution Mechanism: utilizes Observe-Orient-Decide-Act reasoning (OODAR) for executing HTPs."}, {"title": "Empirical Benchmarking on FinanceBench", "content": "We evaluated our DANA implementation using the FinanceBench dataset, a collection of 150 financial-analysis cases based on public quarterly and annual financial reports filed with the US Securities and Exchange Commission (SEC), which we classified into increasing difficulty levels detailed in Table 3."}, {"title": "Experiment Setup", "content": "We compared the performance of our DANA implementation against LlamaIndex RAG agents, Lang Chain ReAct agents and OpenAI Assistants, with each system having access to the same SEC filings and tasked to solve the same FinanceBench problems based on such filings (https://github.com/aitomatic/openssa/tree/main/examples/FinanceBench)."}, {"title": "Evaluation Metrics", "content": "We evaluated the systems on two metrics:\n1. Average Accuracy: For each problem, we generated ten solutions from each AI system. We then calculated the percentage of solutions being correct per the FinanceBench ground truths. Performing such scoring across 150 FinanceBench cases and taking an average gave us an Average Accuracy score for the AI system.\n2. Average Consistency: From the same ten solutions generated for each problem from each AI system, we assigned a consistency score for that solution set based on whether those solutions were consistently correct or incorrect per the FinanceBench ground truths, with a 100%-consistency score for an all-correct or all-incorrect solution set, and a 0%-consistency score for a half-correct-and-half-incorrect solution set. Precisely, the consistency score is calculated as twice the absolute difference between 50% and the proportion of the ten solutions being correct. Performing such scoring across 150 FinanceBench cases and taking an average gave us an Average Consistency score for the AI system."}, {"title": "Results", "content": "The metrics in Tables 4 and 5 and Figure 2 demonstrate that, as a multi-step problem-solving tool, DANA is significantly more consistent than LangChain ReAct and OpenAI Assistant. The closest alternative in terms of consistency is LlamaIndex RAG, thanks to it being a one-pass information-retrieval-and-synthesization tool. DANA also outperforms in accuracy, helped by its strength in maintaining consistency through multiple"}, {"title": "DANA in Industrial Workflows: Semiconductor Case Study", "content": "This section describes at a high level an application of DANA in a physical-industry workflow which requires that AI provide highly precise analyses and recommendations."}, {"title": "Use Case Motivation: Semiconductor Etching Recipe Formulation", "content": "The semiconductor industry has many complex design and manufacturing processes - e.g., design rule checking, layout generation, photolithography, etching, deposition, ion implantation, gate oxide formation, insulation, bonding, etc. - which need careful calibration to achieve optimal technical and economic outcomes. Etching recipe formulation is one such intricate task: it involves dozens of machine parameters that affect key physical operations and chemical reactions. A recipe lacking in rigor would result in inefficient cycle times or expensive reliability and quality problems such as etch rate anomalies, mask erosion, pattern distortion, plasma instability and non-uniformity, which negatively impact yield. Hence, the formulation of feasible and optimal etching recipes requires deep domain expertise and time-consuming expert analyses. There is consequently a great need for scaling up and making more available the knowledge of scarce experts in this"}, {"title": "Expertise CAPTURE into DANA Knowledge and Program Stores", "content": "Domain knowledge in etching was acquired from two principal sources: (i) discussions and interviews with etching experts at equipment makers and chip manufacturers, and (ii) public discussion forums in the semiconductor and related scientific research and engineering fields, such as ResearchGate. The knowledge was then organized into two storages that DANA agents could leverage:\n1. Facts-and-Rules Knowledge Store: facts about common gas types and their key properties, rules of thumb about correlations between etch rate changes and key process parameters, trade-offs across ranges of power and pressure parameter settings, and important safety advice to adhere to in etching operations; and\n2. Program Store: step-by-step and hierarchical expert procedures for analyzing the specifications, deciding on possible key parameter values, and judging the likely advantages and disadvantages of different parameter combinations in terms of etching outcomes such as plasma stability and uniformity."}, {"title": "Expertise APPLY through DANA-based Etching Advisor", "content": "An Etching Advisor, an AI agent constructed with the DANA architecture, was given access to the above etching expert Knowledge and Program Stores. Additionally, this Etching Advisor employed SemiKong (https://SemiKong.ai), a semiconductor industry-specific LLM, in its program search and program execution, to further enhance the precision and relevance of its analyses and recommendations. This DANA-based Etching Advisor was then capable of providing operationally sound etching recipes, including pros-and-cons comparisons among feasible alternatives, thus helping process engineers save much analysis time and arrive at their final recipes more quickly."}, {"title": "Implications for Industrial AI System Designs", "content": "This section explores DANA's implications for the design of AI systems in industrial settings, focusing on the role of symbolic structures and operations, the role of domain-specific knowledge and the potential for automated knowledge-to-agent systems."}, {"title": "Role of Symbolic Structures and Deterministic Operations", "content": "One key contributor to DANA's superior consistency is this architecture's more explicit and greater assigned responsibility to symbolic elements in organizing domain-specific knowledge, and in structuring and executing problem-solving programs such as HTPs. The use of symbolic structures and their more deterministic operations significantly reduces the variability in individual processing step results and in how such results are aggregated or consolidated during an entire program's execution.\nAs AI agents are increasingly employed in physical-industry applications, the stringent requirements on consistency shall likely further necessitate symbolic representations and deterministic processing. Current AI system architectures would need to evolve from their current predominant reliance on neural processing in order to be effective in such use cases."}, {"title": "Role of Domain-Specific Knowledge", "content": "First-class treatment of domain-specific knowledge, both in the facts-and-rules form and the program form, is another key driver of DANA's superior consistency and accuracy in complex problem-solving. Such knowledge integration is crucial for success in industrial AI:\n1. Reduced Critical Errors: applications in high-stakes fields such as manufacturing and healthcare greatly need such consistency and accuracy to mitigate the risk of costly or dangerous accidents that can occur with purely data-driven approaches;\n2. Improved Interpretability: domain-specific knowledge representation makes AI decision-making processes more explainable, transparent and interpretable; and\n3. Faster Deployment: leveraging existing domain expertise can accelerate the deployment of AI systems in new industrial contexts, reducing the need for extensive data collection and model training to achieve comparable problem-solving quality."}, {"title": "Automated Knowledge-to-Agent Systems", "content": "The promising performance of DANA points to the potential for developing automated systems that can transform domain knowledge into operational AI agents:\n1. Scalable Expertise: automated knowledge capture mechanisms could allow industries to scale their AI capabilities more efficiently, capturing and operationalizing the knowledge of multiple experts;\n2. Continuous Learning: automated systems with active monitoring and evaluation could potentially update their knowledge bases in real-time, allowing industrial AI to adapt quickly to new information or changing conditions; and\n3. Customization and Specialization: the various DANA variants can be used for tailoring AI systems to specific industrial needs."}, {"title": "Challenges and Future Directions", "content": "While DANA demonstrates significant potential, several challenges remain to be addressed:\n1. Knowledge Elicitation: developing effective methods for extracting and formalizing expert knowledge can be difficult, particularly in highly specialized industrial domains;\n2. Handling Uncertainty: further research is needed to enhance DANA's capabilities in dealing with uncertain or incomplete information; and\n3. Handling Contradictory Knowledge: we need mechanisms to detect and handle contradictions in DANA's Knowledge Store and Program Store - especially those containing large numbers of knowledge items or programs, among which contradictions may be indirect and nuanced - in order to safeguard problem-solving quality, especially in settings where such contradiction is costly or dangerous."}, {"title": "Conclusion", "content": "This paper introduced DANA (Domain-Aware Neurosymbolic Agent), an architecture designed to address the inconsistency and inaccuracy in current LLM-based AI systems. The key contributions of this work include:\n1. An analysis of current AI system architectures through a neurosymbolic lens, identifying limitations of purely probabilistic approaches\n2. DANA, a flexible architecture that combines domain expertise with neurosymbolic integration to enhance consistency and accuracy in problem-solving;\n3. An implementation of DANA in the open-source OpenSSA framework;\n4. Empirical evidence of DANA's superior performance on the FinanceBench dataset over current AI systems;\n5. A case study of applying DANA in a high-stakes physical-industry process, namely semiconductor etching recipe formulation; and\n6. An analysis of DANA's implications for industrial AI system designs, highlighting the importance of symbolic structures and operations, the value of domain-specific knowledge and the potential for automated knowledge-to-agent systems.\nLooking forward, DANA opens up several avenues for future research:\n1. Automated knowledge capture mechanisms to streamline the process of incorporating domain expertise into AI systems;\n2. Hybrid approaches that can dynamically balance between neural and symbolic processing based on the nature of the problem at hand;\n3. Extension of DANA to multi-domain settings, exploring how knowledge can be effectively transferred and applied across different areas of expertise; and\n4. More sophisticated neurosymbolic reasoning techniques that can handle uncertainty and incomplete information more effectively.\nAs AI continues to proliferate in critical real-world industries, approaches like DANA that prioritize consistency, accuracy and domain-specific knowledge can play an important role in building effective and trustworthy AI systems."}]}