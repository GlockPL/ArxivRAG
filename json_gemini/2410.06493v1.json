{"title": "BiC-MPPI: Goal-Pursuing, Sampling-Based Bidirectional Rollout Clustering Path Integral for Trajectory Optimization", "authors": ["Minchan Jung", "Kwang-Ki K. Kim"], "abstract": "This paper introduces the Bidirectional Clustered MPPI (BiC-MPPI) algorithm, a novel trajectory optimization method aimed at enhancing goal-directed guidance within the Model Predictive Path Integral (MPPI) framework. BiC-MPPI incorporates bidirectional dynamics approximations and a new guide cost mechanism, improving both trajectory planning and goal-reaching performance. By leveraging forward and backward rollouts, the bidirectional approach ensures effective trajectory connections between initial and terminal states, while the guide cost helps discover dynamically feasible paths. Experimental results demonstrate that BiC-MPPI outperforms existing MPPI variants in both 2D and 3D environments, achieving higher success rates and competitive computation times across 900 simulations on a modified BARN dataset for autonomous navigation.", "sections": [{"title": "I. INTRODUCTION", "content": "Optimization-based trajectory generation methods have gained significant attention due to advancements in computational performance and optimization algorithms. In the past, trajectories were primarily generated using heuristic approaches such as gird-based motion planners (e.g., Breadth-First Search (BFS), Depth-First Search (DFS), Dijkstra, A* and D* algorithms) and sampling-based motion planners (e.g., Probabilistic Roadmaps (PRM, PRM*), Rapidly-exploring Random Trees (RRT, RRT*), and RRT variants). However, optimization-based trajectory generation techniques with consideration of kinematic or dynamic constraints are now being applied in real time across various industries [1]\u2013[3].\nTrajectory optimization not only generates optimal trajectories but also identifies optimal sequences of actions or inputs using a system model. These approaches can be broadly classified into gradient-based and sampling-based methods. Differential Dynamic Programming (DDP) addresses trajectory optimization through iterative forward and backward sweeps until a specified tolerance is achieved, utilizing gradients and Hessians around a nominal trajectory. With the rapid advancement of GPUs and parallel computation, sampling-based methods, such as Model Predictive Path Integral (MPPI), have gained significant attention. Recently, various techniques have been integrated into the MPPI framework [4]. However, sampling-based methods still face challenges in goal finding. While terminal costs can be applied, they are often limited to a specific target point.\nBidirectional path planning, known for its advantages in goal finding, typically involves solving two-point boundary value problems (BVPs) [5]. However, deriving a closed-form solution is often infeasible, leading to the widespread use of numerical methods [6], [7]. Even without directly solving the BVP, forward rollouts can leverage heuristic information from backward rollouts [8]. Some methods combine MPPI with other optimal control strategies, such as Interior Point Differential Dynamic Programming (IPDDP) [9] or ancillary controllers [10]. These approaches require the integration of additional optimal controllers beyond the standard MPPI framework.\nThis paper proposes the Bidirectional Clustered MPPI (BiC-MPPI), an enhanced trajectory optimization method that improves goal-directed guidance within the MPPI framework. The main contributions of this work are as follows: (i) Bidirectional Approach: Different from existing MPPI variants that operate solely in the forward direction, our method introduces a novel bidirectional path integral approach, which integrates backward dynamics approximations for improved trajectory planning; (ii) Guide Cost: We extend the MPPI framework by incorporating a guide cost mechanism that goes beyond traditional cost functions, which typically rely on terminal costs or target-combined stage costs. This mechanism aids in discovering goal-reaching trajectories by considering dynamically feasible reference trajectories; and (iii) Successful Goal Navigation: Our approach demonstrates superior goal-oriented navigation performance, successfully navigating complex environments and outperforming existing MPPI algorithms in hundreds of test scenarios."}, {"title": "II. BACKGROUND", "content": "For state-space trajectory optimization, we consider the state $x_t \\in \\mathbb{R}^n$ and the input $u_t \\in \\mathbb{R}^m$ with the stage cost $\\psi: \\mathbb{R}^n \\times \\mathbb{R}^m \\rightarrow \\mathbb{R}$ and the terminal state cost $\\phi : \\mathbb{R}^n \\rightarrow \\mathbb{R}$. The associated optimal control problem (OCP) of trajectory optimization can be represented as the following:\n$\\min \\limits_{u_{0:T-1}} \\phi(x_T) + \\sum\\limits_{t=0}^{T-1} \\psi(x_t, u_t)$ \nsubject to $x_{t+1} = f(x_t, u_t), x_0 = x_{init}$\n$g(x_t) \\leq 0, p(x_t) \\notin O, h(u_t) \\leq 0$ \nwhere $x_{init}$ represents the initial condition, $f: \\mathbb{R}^n \\times \\mathbb{R}^m \\rightarrow \\mathbb{R}^n$ denotes the control system dynamics, and the mappings $g: \\mathbb{R}^n \\rightarrow \\mathbb{R}^{l_x}$ and $h : \\mathbb{R}^m \\rightarrow \\mathbb{R}^{l_u}$ represent the state and input constraints, respectively. In addition to these functional state constraints, we also consider the collision avoidance constraint $p(x_t) \\notin O$, where $p : \\mathbb{R}^n \\rightarrow \\mathbb{R}^d$ denotes the position of the state $x_t$, and $O$ represents the obstacle region in the environment."}, {"title": "B. Model Predictive Path Integral", "content": "MPPI, a sampling-based trajectory optimization method, generates random trajectories (samples) with noise-injected inputs $v_t = u_t + \\epsilon_t$, sequentially from the initial state $x_{init}$. The sequence of random noise $\\epsilon_{0:T-1} = (\\epsilon_0,\u00b7\u00b7\u00b7,\\epsilon_{T-1})$ follows a normal distribution $\\mathcal{N}(0, \\Sigma_u)$, with zero mean and covariance matrix $\\Sigma_u \\in \\mathbb{R}^{m\\times m}$. We consider the input constraint set $\\mathcal{U} = \\{u_{0:T-1} \\in \\mathbb{R}^{mT} : h(u_t) < 0 \\text{ for } t = 0, . . ., T \u2013 1\\}$.\nIn sampling-based methods, a large number of trajectories are generated, and a weighted average of the sampled rollout trajectories is used to refine the final path or control input. This weighted averaging ensures that the resulting inputs not only meet specific state conditions but also effectively achieve the navigation goal, all while adhering to physical limits. To prevent the generation of inputs that violate constraints, a projection operator $P_U : \\mathbb{R}^{mT} \\rightarrow \\mathcal{U}$ is employed, defined as:\n$P_U(U) = \\arg \\min \\limits_{U'\\in U} ||U' \u2013 U||_2.$\nHere, $\\mathcal{U}$ represents the input constraint set, which is assumed to be non-empty, closed, and convex. This assumption ensures that the projection $P_U(U)$ always exists and is unique for any $U \\in \\mathbb{R}^{mT}$. In certain cases, such as box-type constraints or second-order cone constraints, closed-form solutions for the projection are available [9], [11]. Since the input constraints are decoupled across time steps, the projection can be applied element-wise for each input $u \\in \\mathbb{R}^m$, where the set $\\mathcal{U} = \\{u \\in \\mathbb{R}^m: h(u) < 0\\}$ is also closed and convex, thereby ensuring feasible inputs at each time step.\nMPPI considers soft constraints by incorporating hard constraints as scalar values within the cost function. It is important to note that the dynamic constraints and initial condition are naturally satisfied through forward rollouts using the dynamics $f$ from $x_{init}$. The cost function is defined as:\n$\\min \\limits_{U} J(U) = \\phi(x_T) + \\sum\\limits_{t=1}^{T-1} \\{\\psi(x_t, u_t) + I_X(x_t)\\}$\nwhere the collision checker $I_X$ is defined by the following indicator function:\n$I_X(x_t) =\\begin{cases}\n    \\infty, & \\text{if } p(x_t) \\in O \\text{ or } g(x_t) > 0\\\\\n    0, & \\text{otherwise}\n\\end{cases}$\nHere, the set $\\mathcal{X} = \\{x \\in \\mathbb{R}^n : g(x) \\leq 0, p(x_t) \\notin O\\}$ denotes the combined state constraint set, which accounts for both the state constraints $g(x_t) \\leq 0$ and the collision avoidance condition $p(x_t) \\notin O$.\nSince a sampled input may violate the input constraints, each sampled input sequence $U^k = (u_0^k,..., u_{T-1}^k)$, where each $u_t^k \\sim \\mathcal{N}(\\bar{u}_t, \\Sigma_u)$, is first projected onto the closed convex set $\\mathcal{U}$ to discard infeasible sampled trajectories. This projection is applied as $U^k \\leftarrow P_U(U^k)$. After generating trajectories with these projected inputs and computing the corresponding costs, the relative weight of each trajectory is calculated. A weighted average of the sampled inputs, forming a convex combination, is then used to determine the optimal control input sequence $U^* = (u_0^*,..., u_{T-1}^*)$:\n$w^k = \\exp(-\\lambda J^k), \\bar{w} = \\sum\\limits_{k=1}^{N_s} w^k, U^* = \\sum\\limits_{k=1}^{N_s} \\frac{w^k}{\\bar{w}} U^k $\nwhere the right-superscript $k$ is the sampling index and $N_s$ is the number of samples. Since each $u_t^k \\in \\mathcal{U}$ for all $k$ and $t$, and $\\mathcal{U}$ is convex, the resulting inputs $u_t^* \\in \\mathcal{U}$ are feasible for all $t = 0,..., T-1$, ensuring that $U^* \\in \\mathcal{U}$."}, {"title": "C. Rollout Clustering MPPI", "content": "Although numerous sampled trajectories are generated, the original naive MPPI typically yields a single path. This approach has limitations in efficiently handling samples when multiple local minima are present. For instance, if a robot encounters an obstacle, both turning left and turning right might be optimal trajectories with identical or similar costs, representing two different local minima. However, since the weighted average calculation (5) considers all samples simultaneously, the resulting trajectory may not necessarily lie within a feasible region. This can lead to situations where $X(U^*) = (x_0, f(x_0, u_0^*), f(f(x_0, u_0^*), u_1^*),\u00b7\u00b7\u00b7, f(..., u_{T-1}^*)) \\notin \\mathcal{X}^{T+1}$, indicating that the trajectory might fall outside the feasible state constraint set $\\mathcal{X}$, even though each individual sampled trajectory is feasible.\nTo avoid generating infeasible trajectories while leveraging the benefits of all sampled trajectories, rollout clustering MPPI is proposed in [12]. The key idea of trajectory clustering can be summarized as follows: After generating and evaluating sample trajectories similarly to the naive MPPI presented in Section II-B, the DBSCAN (Density-Based Spatial Clustering of Applications with Noise) [13] algorithm is applied to cluster the rollout trajectory samples based on the deviations of input sequences and the associated costs. DBSCAN has two main parameters: the minimum number of points $p$ required to define core points, and the maximum distance $\\epsilon_{max}$ used to determine the neighborhood within a specified boundary. For $N_s$ trajectory samples, consider the power set $2^{\\mathcal{N}_s}$, which represents all subsets of $\\mathcal{N}_s$, including the empty set and the set itself. Here, $\\mathcal{N}_s = \\{1, 2, . . ., N_s\\}$ is the index set for sampling. The output of the clustering algorithm is a set of clusters $\\{C_1,..., C_l\\}$, where the clusters satisfy the disjoint-set property $C_i \\cap C_j = \\emptyset$ for all $i \\neq j$, and the complete-set property $\\bigcup_{i=1}^{l}C_i = \\mathcal{N}_s$. Each cluster $C_i\\in 2^{\\mathcal{N}_s}$ contains the indices of the i-th group of clustered trajectories. If no valid clusters are found due to incorrect parameter settings, a fallback strategy is applied by setting $C_1 = \\mathcal{N}_s$ with $l = 1$, including all samples in a single cluster. For each cluster set, the optimal control $U^{C_i}$ for the i-th cluster is computed as in (5), where the weighted sum is calculated over $k\\in C_i$ for each cluster i. Once the clusters are formed, the overall optimal control input is determined as:\n$U^{C*} \\leftarrow \\arg \\min \\limits_{U^{C_1},...,U^{C_I}} J(U^{C}).$"}, {"title": "D. Bidirectional Rollout Kinematics", "content": "To rollout with a sequence of control inputs over a finite horizon with sampling-time intervals, we need a simulation model of the control system corresponding to the kinematics or dynamics.\na) Forward Rollout Kinematics: For forward rollouts using a sampled control input sequence $U^k$, any standard numerical method for solving ordinary differential equations (ODEs), such as $\\dot{x}(s) = F(x(s), u(s))$ with the initial condition $x(0) = x_{init}$, can be employed [14]. In this work, we use the well-known fourth-order Runge-Kutta (RK4) method, defined as follows:\n$\\kappa_1 = dt F(x_t, u_t), \\kappa_2 = dt F(x_t + \\kappa_1/2, u_{t+1}),$\n$\\kappa_3 = dt F(x_t + \\kappa_2/2, u_{t+1}), \\kappa_4 = dt F(x_t + \\kappa_3, u_{t+1})$\n$x_{t+1} = x_t + (\\kappa_1 + 2\\kappa_2 + 2\\kappa_3 + \\kappa_4)/6$\nwhere $x_t = x(t_t)$, $u_t = u(t_t)$, and $u_{t+1} = (u_t + \\epsilon_{t+1})/2$. This formulation slightly deviates from the control system model given in (1), but sampling-based MPPI methods do not require strict adherence to the Markovian nature of the system. Instead, they focus on computing the total cost of a rollout trajectory, given a sampled input sequence over the horizon.\nb) Backward Rollout Kinematics: In our method of bidirectional rollout-based trajectory optimization, the backward dynamics are also required by solving the ordinary differential equation $\\dot{x}(s) = F(x(s), u(s))$ with a final condition $x(T) = x_{goal}$. Similar to the forward RK4 method, the following backward Runge-Kutta (RK4) method is used for backward rollouts with a sampled sequence of control inputs $U^k$:\n$\\kappa_1 = dt F(x_t, u_t), \\kappa_2 = dt F(x_t - \\kappa_1/2, u_{t-1}),$\n$\\kappa_3 = dt F(x_t - \\kappa_2/2, u_{t-1}), \\kappa_4 = dt F(x_t - \\kappa_3, u_{t-1})$\n$x_{t+1} = x_t - (\\kappa_1 + 2\\kappa_2 + 2\\kappa_3 + \\kappa_4)/6$\nwhere $u_{t-1} = (u_t + u_{t-1})/2$. The computation starts with the final condition $x(T) = x_{goal}$ and proceeds backward through the time steps, $t = T, T \u2013 1, ..., 0$."}, {"title": "III. BIC-MPPI ALGORITHM", "content": "This section introduces an extension of classical MPPI, the Bidirectional Clustered MPPI (BiC-MPPI) algorithm, which addresses the limitations of existing MPPI variants and enhances goal-directed trajectory optimization. The BiC-MPPI algorithm, whose pseudocode is provided in Algorithm 1, operates in three main stages:\n1) Bidirectional Clustered Trajectory Generation: In this step, backward and forward trajectory branches are generated using the Clustered MPPI approach. However, instead of directly finding the optimal control input using (6), multiple candidate trajectories are generated. These trajectories provide a broad exploration of the solution space, allowing for more robust trajectory options.\n2) Connection of Trajectory Branches: Once the trajectories are generated, the next step is to select the best connection point between the forward and backward branches. This is done by calculating the distance between the state of the forward branch and the backward branch. The control inputs and states are then concatenated at the joint to form a single, continuous trajectory.\n3) Guide MPPI: In the final step, a modified version of MPPI, called Guide MPPI, is applied. Here, a guide cost is introduced to encourage the trajectory to follow a reference trajectory generated from the concatenated forward-backward connection. This refines the trajectory and ensures that it smoothly pursues the desired path toward the goal, improving overall performance and reducing deviations from the optimal path.\nBy combining these three steps, the BiC-MPPI algorithm enhances the standard MPPI framework, particularly in scenarios with complex dynamics and multiple local minima."}, {"title": "A. Forward & Backward Clustered MPPI", "content": "The first step of the proposed BiC-MPPI is to generate bidirectional clustered trajectories using the forward and backward, i.e., bidirectional, clustered MPPI methods. Our bidirectional clustered trajectory generation works similar to the rollout clustering MPPI proposed in [12], but a main difference is that the results of all clustered trajectories are stored, instead of selecting only one optimal branch among clusters. The following OCP is considered for the forward clustered MPPI strategy:\n$\\min \\limits_{U\\in U} J_f(U) = \\phi_f(x_T) + \\sum\\limits_{t=0}^{T-1} \\{\\psi_f(x_t, u_t) + I_{X_f}(x_t)\\}$\ns.t. $x_{t+1} = f_f(x_t, u_t), x_0 = x_{init}$\nwhere an initial condition $x_{init}$ is given and the discrete-time model $f_f(\\cdot, \\cdot)$ is obtained from the forward RK4 method presented in (7). The cost functions about terminal and stage state ($\\phi_f: \\mathbb{R}^n \\rightarrow \\mathbb{R}$ and $\\psi_f : \\mathbb{R}^n \\times \\mathbb{R}^m \\rightarrow \\mathbb{R}$), and the state-constraint set $\\mathcal{X}_f \\subset \\mathbb{R}^n$ are defined same as the classical MPPI described in Section II-B.\nSame as the forward clustered MPPI, the resulting clusters and their information are stored for the use of connecting the forward and backward rollout clusters of trajectories in"}, {"title": "B. Trajectory Association for Connection", "content": "The previous step generates multiple trajectory candidates in both the forward and backward directions, starting from the initial condition $x_{init}$ and the terminal condition $x_{goal}$, respectively. Assuming that none of these trajectories directly connects the initial and terminal conditions, the next step involves associating or pairing opposite directional branches of trajectory candidates. This ensures a complete trajectory that bridges $x_{init}$ and $x_{goal}$.\nIn this trajectory association process, the nearest points between the forward and backward trajectory branches are identified based on a chosen distance metric. After determining the closest points, each trajectory is cut at its nearest point, and the trimmed forward and backward trajectories are connected at these points, without considering kinematic or state constraints at this stage. This straightforward connection acts as an intermediate step before further refining the overall trajectory in subsequent stages.\nLet $\\mathcal{C}^f = \\{C_1^f,...,C_{I_f}^f\\}$ and $\\mathcal{C}^b = \\{C_1^b,...,C_{I_b}^b\\}$ represent the sets of forward and backward trajectory clusters, respectively, generated in the previous step. Each cluster corresponds to a set of sampled trajectories that share similar costs and states. For the forward trajectories, the state trajectory corresponding to the i-th forward cluster is denoted by: $X^{C_i^f} = (f_x^0, f_x^1,...,f_x^{T_f})$ where $f_x^t$ represents the state at time t in the i-th forward trajectory cluster, and $T_f$ is the time horizon for the forward rollout. Similarly, for the backward trajectories, the state trajectory corresponding to the j-th backward cluster is: $X^{C_j^b} = (b_x^0, b_x^1,...,b_x^{T_b})$ where $b_x^t$ represents the state at time t in the j-th backward trajectory cluster, and $T_b$ is the time horizon for the backward rollout. The backward trajectories begin at $b_x^{T_b} (=x_{goal})$ and proceed to $b_x^0$ (the closest point to the initial state). The input trajectories, denoted as $U^{C_i^f}$ and $U^{C_j^b}$, are defined similarly for both forward and backward clusters, following the respective control inputs applied at each time step.\nFor each forward branch $\\mathcal{C}^f$, the goal is to find an associated backward branch by solving the following optimization problem:\n$(j^*, \\tau, \\tau') = \\arg \\min \\limits_{(j,\\tau,\\tau')} ||f_x^{\\tau} - b_x^{\\tau'}||$ \ns.t. $j\\in \\mathbb{Z}_{1:I_b}, \\tau\\in \\mathbb{Z}_{0:T_f}, \\tau' \\in \\mathbb{Z}_{0:T_b}$\nwhere $\\mathbb{Z}_{I_1:I_2} = \\{I_1, I_1 + 1, . . ., I_2\\}$ is a set of integers between the integers $I_1$ and $I_2$. The objective is to minimize the distance between the forward trajectory state $f_x^{\\tau}$ and the backward trajectory state $b_x^{\\tau'}$, using a chosen distance metric such as Euclidean, Manhattan, or LQR cost metrics [15] to identify the closest points on the forward and backward trajectories.\nOnce the optimization problem (11) is solved, the selected backward branch is denoted as $X^{C_{j^*}^b}$, which is a trimmed version of the backward cluster $X^{C_{j^*}^b}$. This branch starts at the identified cut point $b_x^{\\tau'}$ and extends to the goal state $b_x^{T_b} = x_{goal}$. Similarly, $X^{C_i^f}$ represents the forward branch connecting the initial state $f_x^0 = x_{init}$ to the cut point $f_x^{\\tau}$. The corresponding trimmed input trajectories follow the same pattern as the state trajectories.\nThe result of this trajectory association is the concatenation of the state and control input sequences:\n$\\tilde{U}^{(i)} = \\tilde{U}^{C_i^f}_{0:T-1} \\cup \\tilde{U}^{C_{j^*}^b}_{0:T-1}, \\tilde{X}^{(i)} = X^{C_i^f}_{0:\\tau} \\cup X^{C_{j^*}^b}_{\\tau'+1:T_b}$\nwhere $\\cup$ represents the concatenation of two matrices with compatible dimensions. $Y_{a:b}$ denotes the sequence"}, {"title": "C. Guide MPPI", "content": "In traditional MPPI, these terminal costs serve as distant targets, essentially guiding the system with minimal information along the trajectory. This makes it difficult for sampling-based methods to efficiently generate goal-reaching trajectories, particularly in environments with complex obstacles or dynamics. Furthermore, when the cost function is overly focused on the goal state at a specific time step, it can lead to instability and render the cost function unreliable. Guide MPPI mitigates these issues by incorporating a reference trajectory generated from the concatenated forward and backward branches. The guide cost incentivizes the sampled trajectories to follow this reference, encouraging more accurate and smooth transitions from the initial state to the goal. This method provides intermediate guidance throughout the entire horizon, improving trajectory quality while maintaining the flexibility of sampling-based optimization.\nFor each i-th concatenated clustered trajectory, we define the following guided trajectory optimization:\n$\\min \\limits_{U \\in U} J_g^{(i)}(U; \\tilde{U}^{(i)}, \\tilde{X}^{(i)}) + \\frac{\\epsilon}{\\|X_{T_i} - x_{goal}\\|}$ \ns.t. $x_{t+1} = f_f(x_t, u_t), t = 0, 1, . . . ,T_i; x_0 = x_{init}$\nwhere $J_g^{(i)} (U; \\tilde{U}^{(i)}, \\tilde{X}^{(i)}) = J(U) + d((X,U), (\\tilde{X}^{(i)}, \\tilde{U}^{(i)}))$ and $\\epsilon > 0$ is a small inverse-weight. Here, $J(U)$ is defined similarly to the classical MPPI cost (3), but with the time horizon $T_i$, and it combines state constraints over the intersection $\\mathcal{X} = \\mathcal{X}_f \\cap \\mathcal{X}_b$. The terminal, initial, and stage costs are all included, effectively summing the forward and backward costs, $J_f(\\cdot)$ and $J_b(\\cdot)$, as defined in (9) and (10), respectively. The term $d((X,U), (\\tilde{X}^{(i)}, \\tilde{U}^{(i)}))$ represents a penalty for deviations from the guided trajectory $(\\tilde{X}^{(i)}, \\tilde{U}^{(i)})$, encouraging the trajectories to stay close to this reference.\nBy utilizing information from the previous MPPI stage, this penalty helps ensure that the resulting trajectory is feasible and closely follows the desired path from $x_{init}$ to $x_{goal}$.\nTo derive the optimal control with the guide cost $J_g^{(i)}$, we substitute $J$ with $J_g^{(i)}$ in (3) and (5), allowing us to calculate the optimal trajectory for each selection with the optimal input $U_g^*$. After evaluating all selections, the overall"}, {"title": "IV. SIMULATION EXPERIMENT", "content": "To numerically evaluate the performance of our approach, we conducted simulations in which a differential wheeled mobile robot pursued a given target. The system model for the 2D wheeled mobile robot is described by the following continuous equations:\n$\\dot{x} = v_t \\cos(\\theta_t), \\dot{y} = v_t \\sin(\\theta_t), \\dot{\\theta} = \\omega_t,$\nwhere x and y represent the robot's position, and $\\theta$ denotes its heading angle. The control inputs are linear velocity $v_t$ and angular velocity $\\omega_t$, forming the control vector $u_t = [v_t, \\omega_t]^T$. The following constraints are considered for the OCP:\n$0 \\leq v_t \\leq 1.0, |\\omega_t| \\leq \\frac{\\pi}{4}, (x_t, y_t) \\notin O,$\nwhere the obstacle region O is defined based on the environment configuration.\nWe use the BARN Dataset [16], which contains 300 distinct 2D environments. The process of map modification is illustrated in Fig. 1. Each map is extended from 3m\u00d73m to 3m\u00d75m to create extra free space around the initial and target states, preventing collision. The target state is set as $x_{goal} = [1.5, 5.0, \\pi/2]$, positioned in the upper middle of the map with an upward orientation. The two initial states, $x_{init} = [0.5, 0.0, \\pi/2]$ and $x_{init} = [2.5, 0.0, \\pi/2]$, are used for testing across the 300 different maps, leading to a total of 600 simulation trials.\nWe compare our algorithm with several MPPI variants, including the original MPPI [17], Log-MPPI [18], and Cluster-MPPI [12]. All algorithms use the same control covariance $\\Sigma_u$ to ensure consistency. To account for the bidirectional nature of BiC-MPPI, we double the sample sizes $N(N_f)$ and extend the time horizon $T(T_f)$ for the other MPPI variants, providing a balanced comparison. For performance evaluation, a simulation is deemed successful if the Euclidean distance $||x_{goal} - x_0|| < \\epsilon_{err}$, with $\\epsilon_{err} = 0.1$. If the robot fails to reach the goal within 200 iterations, which allows ample time for the"}, {"title": "V. CONCLUSIONS AND FUTURE WORK", "content": "This paper introduces the Bidirectional Clustered MPPI (BiC-MPPI) algorithm, a novel goal-oriented path integral optimizer. BiC-MPPI integrates kinematic and dynamic constraints, along with initial and terminal state conditions, into a framework capable of managing state and input constraints. Evaluations conducted on the BARN dataset, involving 600 simulations, revealed a 5.60% to 8.23% improvement in success rates compared to existing MPPI variants, while maintaining competitive computation times. In more complex 3D quadrotor landing simulations, BiC-MPPI achieved even more significant performance gains, outperforming three MPPI variants with success rates increasing by 30.68% to 123.33%, excelling in both collision avoidance and computational efficiency. Future work will explore adapting BiC-MPPI for real-time feedback, dynamic environments, moving targets, and scenarios involving multiple intermediate waypoints."}]}