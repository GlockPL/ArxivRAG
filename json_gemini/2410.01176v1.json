{"title": "Generative Diffusion-based Contract Design for Efficient AI Twins Migration in Vehicular Embodied AI Networks", "authors": ["Yue Zhong", "Jiawen Kang", "Jinbo Wen", "Dongdong Ye", "Jiangtian Nie", "Dusit Niyato", "Xiaozheng Gao", "Shengli Xie"], "abstract": "Embodied Artificial Intelligence (AI) is a rapidly advancing field that bridges the gap between cyberspace and physical space, enabling a wide range of applications. This evolution has led to the development of the Vehicular Embodied AI NETwork (VEANET), where advanced AI capabilities are integrated into vehicular systems to enhance autonomous operations and decision-making. Embodied agents, such as Autonomous Vehicles (AVs), are autonomous entities that can perceive their environment and take actions to achieve specific goals, actively interacting with the physical world. Embodied twins are digital models of these embodied agents, with various embodied AI twins for intelligent applications in cyberspace. In VEANET, embodied AI twins act as in-vehicle AI assistants to perform diverse tasks supporting autonomous driving using generative AI models. Due to limited computational resources of AVs, these AVs often offload computationally intensive tasks, such as constructing and updating embodied AI twins, to nearby RoadSide Units (RSUs). However, since the rapid mobility of AVs and the limited provision coverage of a single RSU, embodied AI twins require dynamic migrations from current RSU to other RSUs in real-time, resulting in the challenge of selecting suitable RSUs for efficient embodied AI twins migrations. Given information asymmetry, AVs cannot know the detailed information of RSUs. To this end, in this paper, we construct a multi-dimensional contract theoretical model between AVs and alternative RSUs. Considering that AVs may exhibit irrational behavior, we utilize prospect theory instead of expected utility theory to model the actual utilities of AVs. Finally, we employ a generative diffusion model-based algorithm to identify the optimal contract designs, thus enhancing the efficiency of embodied AI twins migrations. Compared with traditional deep reinforcement learning algorithms, numerical results demonstrate the effectiveness of the proposed scheme.", "sections": [{"title": "I. INTRODUCTION", "content": "Embodied Artificial Intelligence (AI) refers to autonomous systems or robots that demonstrate intelligent behaviors within the physical environment by interacting with their surroundings through their bodies, finding applications across various fields [1]. The advancement of embodied AI in vehicular systems has led to the development of Vehicular Embodied AI NETworks (VEANETs), where vehicles integrate sensory input and motor capabilities to achieve real-time contextual awareness and adaptive decision-making [2]. Embodied agents, including Autonomous Vehicles (AVs) within VEANETS, actively perceive and interact with both virtual and physical environments, enabling them to understand human intentions, decompose complex tasks, and interact effectively with their surroundings [3]. In VEANETs, embodied twins and Al twins have been proposed to enhance the intelligence of networks by integrating Digital Twins (DTs) into embodied AI systems. With an embodied world model serving as the \"brain\" of agents, embodied twins facilitate the transfer of skills from virtual to real-world scenarios [4]. Similar to the concept of DTs [5], embodied twins refer to digital models created through real-time data analytics and simulation, representing the complete life cycle of embodied agents in the virtual environment, encompassing multiple embodied AI twins. Specifically, vehicular embodied AI twins serve as in-vehicle AI assistants performing various tasks in AVs, and require constant updates to ensure real-time synchronization between physical and virtual spaces [6]. These software entities autonomously perform functions within their transportation environment, enabling independent cognition, decision-making and action without drivers, effectively simulating real-world decision-making processes. Depending on diverse demands, AVs equipped with embodied AI twins can offer various services to passengers, such as Augmented Reality (AR) navigation and Intelligent Cruise Control (ICC) [7], thereby providing an interactive and immersive experience for users within the vehicle.\nConsidering the limited resources of an AV, these intensive computational tasks of embodied AI twins need to be offloaded to edge servers in the nearby RoadSide Units (RSUs) with more communicational and computing resources [8]. However, as the AV moves, the AV may leave the current RSU with limited provision coverage. Thus it is hard to guarantee the continuity of in-vehicle services in the AV when its embodied Al twins are still in the current RSU [9]. Therefore, the embodied AI twins must undergo real-time migration from the current RSU to a new RSU to guarantee seamless delivery of in-vehicle services to the AV. This necessitates the development of an incentive framework aimed at encouraging the maximal participation of RSUs in provisioning required resources for embodied AI twins.\nGiven the uncertainty in interactions between RSUs and AVs, AVs may exhibit irrational behavior. Managers often rely on cognitive biases such as regret aversion, confirmation bias, and recency bias, when making complex decisions under time constraints and incomplete information, leading to suboptimal choices [10]. For instance, AVs might favor RSUs that previously provided favorable data, even if less reliable, neglecting more accurate RSUs and resulting in inefficient traffic management and potential safety risks. Consequently, the application of Expected Utility Theory (EUT) to establish the utility of AVs is not considered rational. In light of this, the authors in [11] introduced a novel model of risk attitudes known as Prospect Theory (PT). This model effectively captures empirical evidence of risk-taking behavior, including observed deviations from EUT. There have been studies integrating PT into the construction of utility functions in contract theory to better capture the subjective utility of users in the model [12]\u2013[14]. As a result, leveraging PT allows us to incorporate the subjective utility of AVs, resulting in a more accurate and meaningful model.\nTo tackle the aforementioned challenges, we consider an incentive mechanism utilizing PT for efficient embodied AI twins migration. In this regard, we introduce a contract model designed to incentivize RSUs to provide resources for service provision of embodied AI twins. Recognizing the inherent uncertainty experienced by AVs in uncertain environments, we formulate a novel contract model by incorporating PT. The new contract model facilitates the establishment of a subjective utility function for AVs, which considers their preferences and decision-making processes. Moreover, Generative Diffusion Models (GDMs) present a promising tool for resolving optimization. Therefore, we employ a GDM-based scheme to determine optimal contracts. The main contributions of this paper are summarized as follows:"}, {"title": "II. RELATED WORK", "content": "The concept of \"Embodied Al\" was first derived by Alan Turing from his paper named \"Computing Machinery and Intelligence\", published in 1950, which introduced the idea now widely known as the Turing Test [15]. Turing posed the question of whether machines can think, exploring the possibility of creating agents that exhibit intelligence not only in solving abstract problems in cyberspace but also in performing complex tasks in the physical world. The rapid advancement of embodied AI has expanded its applications across various fields, as shown in Fig. 1, garnering significant attention from the research community [16]. The integration of embodied AI with vehicular networks has led to the emergence of a new paradigm known as VEANETs, where AVs play a pivotal role [2]. By leveraging multi-modal perception and coordinated actions, VEANETs enhance vehicular intelligence, allowing for autonomous navigation and interaction within dynamic, unpredictable environments.\nEmbodied agents are at the core of embodied AI, functioning as intelligent entities that interact with the physical world. The development of Generative AI (GAI) models, e.g., Large Language Models (LLMs), Vision Language Models (VLMs), and Vision Language Action (VLA) models, has significantly enhanced the perception, interaction, and planning capabilities of foundational models [17]. These developments have enabled the creation of versatile embodied agents capable of seamless interaction in both virtual and physical environments, making them an ideal platform for deploying Multi-modal Large Models (MLMs) [18]. Embodied agents are equipped with multi-modal sensors, e.g., cameras, microphones and tactile sensors, enabling them to perceive and interact with their surroundings in real-time [19]. Additionally, they often feature actuators, e.g., robotic arms, wheels or legs, which allow them to physically engage with objects and navigate their environment effectively. Their cognitive abilities enable them to comprehend and operate in complex real-world environments, making real-time decisions in dynamic and unpredictable situations without constant human oversight [3]. AVs equipped with AI-powered sensors and advanced algorithms, exemplify embodied agents within VEANETs, achieving human-like perception and decision-making capabilities [20].\nDTs are virtual counterparts that faithfully represent the complete life cycle of physical objects within a virtual environment [5]. Similarly, embodied twins are digital representations of embodied agents, with embodied AI twins specifically being digital replicas created using AI algorithms to perform sub-tasks or functions of these agents. These AI twins can extend the capabilities they have developed in virtual environments into the real world. In VEANETs, embodied twins represent AVs as digital models within the digital environment, with embodied AI twins serving as in-vehicle virtual assistants, supporting AI-driven services like AR navigation and ICC. Since different in-vehicle services require distinct resource allocations, a single AV offering multiple services may need varied resource distributions from RSUs [21]. The dynamic vehicular physical world contains essential information and attributes of tangible entities, necessitating continuous updates to the real-world characteristics of embodied Al twins in the virtual realm [22]. The interplay between vehicular movement and limited RSU coverage poses challenges, requiring real-time migration of embodied AI twins between RSUs [23]. This process entails transitioning from RSUs currently providing resources to RSUs on the verge of assuming coverage responsibility."}, {"title": "B. Incentive Mechanisms for Twins Migration", "content": "Establishing the virtual space and providing in-vehicle services entail substantial resource consumption, particularly in terms of computing resources required to handle the intensive data, extensive storage resources, and robust network resources necessary to maintain ultra-high-speed and low-latency connections [24]. Therefore, it is imperative to tackle the challenges associated with resource allocation and devise an incentive mechanism that encourages virtual service providers to offer their resources [25]\u2013[27]. In [21], the authors introduced an incentive mechanism for migrating Vehicle Twins (VTs) within the virtual space, addressing the challenge of ensuring uninterrupted services despite limited RSU coverage and vehicle mobility. They proposed an Age of Migration Task (AoMT) metric to measure task freshness and an AoMT-based contract model to incentivize RSUs to contribute sufficient bandwidth resources. In [23], a blockchain-assisted game approach framework was introduced for ensuring reliable VT migration within vehicular metaverses. The authors devised a single-leader multi-followers Stackelberg game involving a chosen coalition of RSU and Vehicular Metaverse Users (VMUs) to incentivize VMUs to engage in VT migrations. In [27], the authors introduced a learning-based incentive mechanism, i.e., the Stackelberg model, for VT migration in vehicular metaverses, addressing the challenge of ensuring seamless experiences for users within vehicles amidst limited RSU coverage and mobility.\nRecent research has begun addressing the resource optimization challenges related to digital twins migration caused by vehicle movement in vehicular metaverses, along with the development of incentive mechanisms. However, these studies remain relatively narrow in scope and do not extend to twins migration within VEANETs. In [28], the authors explored the intersection of environmental sensing, immersive technologies, and embodied cognition to lay the groundwork for embodied digital twins. They proposed leveraging theoretical foundations of embodied cognition to develop research frameworks for advancing the concept, emphasizing the conversion of environmental data into immersive experiences. Although the authors in this paper proposed the concept of \"embodied digital twins\", they did not consider the problem of twins migration. The authors in [3] examined nearly 400 papers, initially presenting a selection of prominent embodied robots and embodied simulation platforms. Subsequently, it delved into discussions on embodied perception, embodied interaction, embodied intelligent bodies, and virtual-to-real migration. However, it did not cover pertinent literature on the migration of twins in VEANETS. Consequently, developing incentive mechanisms for twins migration in VEANETs is crucial for advancing this field."}, {"title": "III. SYSTEM MODEL", "content": "In this section, we introduce the incentive mechanism framework proposed in this paper, as well as the preliminary concepts of PT and GDMs."}, {"title": "A. Multi-dimensional Contract-based Embodied AI twins migration Framework", "content": "AVs continuously generate and execute computationally intensive embodied AI twins tasks to ensure this synchronization within the virtual space [29]. However, due to limitations in local resources, AVs may be unable to handle these tasks and update the tasks. To address this, AVs delegate the execution of computationally intensive embodied AI twins tasks to RSUs equipped with robust computing and communication infrastructure [30]. By offloading these tasks to RSUs, AVs ensure real-time execution and seamless synchronization with the virtual space. Additionally, RSUs can utilize information from the embodied AI twins of AVs to assist in service provision for users within the AVs. Due to the limited service coverage of RSUs and the mobility of AVs, the embodied AI twins need to be migrated from the current RSUs to the next RSUs [23]. We consider hotspot areas, e.g., intersections and areas near commercial streets, there are multiple RSUs in the area, and AVs need to decide the target RSUs to migrate their embodied Al twins to based on the diverse requirements of in-vehicle services. In the interaction between RSUs and AVs, AVs compensate RSUs for services rendered by paying rewards. In contrast, RSUs fulfill their role by provisioning the necessary resources for executing embodied AI twins tasks. Therefore, we introduce an incentive mechanism framework between RSUs and AVs, incentivizing RSUs to offer resources for embodied AI twins migration. The multi-dimensional contract-based embodied AI twins migration framework and the steps for AVs to perform tasks are shown in Fig. 2, and the detailed information is described as follows.\nStep 1: Send embodied AI twins migration requests to the current RSUs: As shown in the middle part of Fig. 2, when AVs are in motion on the road, continuous in-vehicle services cannot be provided to users within the AVs due to the limited service coverage of RSUs. To ensure a seamless immersive experience with AVs, the embodied AI twins should be migrated from current RSUs to other RSUs [21], [23]. To initiate this migration process, AVs send embodied AI twins migration requests to current RSUs. Subsequently, RSUs broadcast their requests to surrounding RSUs, facilitating the seamless transfer of embodied AI twins and the uninterrupted delivery of in-vehicle services to AVs.\nStep 2: Construct a multi-dimensional contract model for embodied AI twins migration between AVs and RSUs: As shown in the left part of Fig. 2, to address the information asymmetry between AVs and RSUs and incentivize RSUs to allocate computing and bandwidth resources for embodied AI twins migration, a contract model is developed, which contains three steps. 1) AVs design multi-dimensional contracts for all types of RSUs, i.e., AVs serve as contract designers, determining the terms of contracts tailored for individual RSUs; 2) RSUs select the contract designed for themselves, i.e., RSUs act as contract choosers, selecting the optimal contract offered by AVs; 3) AVs send the reward to RSUs, i.e., RSUs provide resources for AVs based on the selected contracts and receive the corresponding rewards. This contractual arrangement ensures that both parties are aligned in their objectives, promoting cooperation and resource allocation efficiency during the transaction process [27]. Furthermore, from the left part, we observe that the embodied twins represent the virtual model of AVs, with each embodied twins containing multiple embodied AI twins. We assume that there are $I$ embodied AI twins within an AV. Denote the embodied twins as $E_T$ and the i-th embodied AI twins as $EAIT$ for $0 \\leq i \\leq I$. Since each embodied twins contains several embodied AI twins, we can express the embodied twins as $E_T = \\{EAIT^1,..., E^i_{AIT},......, EAIT^I\\}$.\nStep 3: Receive resources from target RSUs and provide in-vehicle services to users: Once RSUs select the optimal contract, they allocate the designated resources to the embodied AI twins task and receive the corresponding reward. The right side of Fig. 2 illustrates how embodied agents (i.e., AVs), undertake tasks like AR navigation. To accomplish these tasks, embodied agents typically follow these processes [3]: 1) High-level embodied task planning: This process involves breaking down abstract and intricate tasks into specific sub-tasks; 2) Low-level embodied action planning: The agents incrementally execute these sub-tasks by utilizing embodied perception and interaction models. LLMs and VLMs play crucial roles in facilitating embodied task planning. Embodied agents can approach action planning through two strategies: using pre-trained perception and intervention models as tools to systematically complete sub-tasks or by directly deriving action planning from the capabilities of the VLA model [3]. Upon completing the action planning, the embodied AI twins migration is completed, and the embodied AI twins can continue to request resources from RSUs to ensure task execution, enabling AVs to provide seamless in-vehicle services to users."}, {"title": "B. Prospect Theory", "content": "In 1979, two prominent Israeli psychologists, Daniel Kahneman and Amos Tversky, made a significant contribution to the field of decision-making under risk with their paper titled \"Prospect Theory: An Analysis of Decision-Making under Risk\", published in the journal Econometrics [11]. The proposed framework provides valuable insights into the intricacies of decision-making under uncertainty and risk, thus highlighting the limitations of traditional utility-based theories (e.g., EUT) and providing a comprehensive analysis of decision-making in uncertain scenarios. There are two main differences between PT and EUT.\n1. PT integrates subjective probabilities to ascertain the weighting allocated to each potential outcome. Subjective probability is derived from objective probability [14].\n2. Decision-makers employ reference points based on specific objectives to classify outcome returns as either gains or losses in PT. Falling short of this goal is perceived as a loss while exceeding it is deemed a gain [12].\nWe derive the utility function form of PT in the following. We consider a system with k AVs, denoted by the set $K = \\{1,\u2026\u2026\u2026,k,\u2026\u2026,K\\}$. The utility function for all AVs, based on EUT, is defined as\n$U^{EUT} = \\sum_{k=1}^{K} P_kU^{EUT}_{k},$ (1)\nwhere $P_k$ represents the objective probability, and $U^{EUT}_{k}$ denotes the utility of the AV k. In uncertain and risky environments, AVs may exhibit irrational behavior. To address this, we can leverage the fundamental principles of PT to construct a utility function that captures their decision-making process more effectively. The utility function based on PT can be expressed as [13]\n$U^{PT} = \\sum_{k=1}^{K} H(P_k)U^{PT}_{k},$ (2)\nwhere $H(P_k) = exp(-(-log(P_k))^\\alpha)$ represents the inverse S-shape probability weighting function applied to the objective probability $P_{m,n}$. This weighting function introduces a psychological bias, characterized by an underestimation of high-probability events and an overestimation of low-probability events [14]. The rational coefficient \u03b1 is employed to quantify the extent of distortion in the subjective evaluation of objective probabilities, thereby influencing the overall shape of the weighting function [11]. Consequently, $U^{PT}_{k}$ can be calculated as\n$U^{PT}_k = \\begin{cases}  (U^{EUT}_k - U^{ref})^{\\eta^+}, U^{EUT}_k > U^{ref}, \\\\   -\\nu(U^{ref} - U^{EUT}_k)^{\\eta^-}, U^{EUT}_k < U^{ref}, \\\\ \\end{cases}$ (3)\nwhere $ \\eta^+, \\eta^- \\in (0,1]$ serve as weighting factors that capture the distortion of gains and losses, respectively. $ \\nu \\geq 0$ reflects the level of loss aversion. The reference point $U^{ref}_{k}$ is introduced to classify the utility $U^{EUT}_k$ as either a gain or a loss, further enhancing the applicability of the PT framework [12]."}, {"title": "C. Generative Diffusion Models", "content": "The advent of GAI presents transformative potential extending beyond conventional AI paradigms. Unlike conventional AI frameworks predominantly oriented towards the analysis or classification of pre-existing data, GAI possesses the capability to generate novel datasets encompassing various modalities such as textual, visual, auditory, and synthetic temporal sequences, among others [31]. GAI encompasses a diverse array of models and methodologies, e.g., Transformer, Generative Adversarial Networks (GANs), and GDMs, these models and methodologies possess distinct advantages and applications within the realm of AI [32]. Their contributions to the progression of AI exhibit variations, with GDMs standing out as particularly influential in this context, primarily owing to their distinctive methodology for data generation and their aptitude for modeling intricate data distributions [33]. GDMS employ a progressive forward diffusion process based on the initial input data, gradually introducing Gaussian noise. Then, GDMs employ a reverse diffusion process through a denoising network, which iteratively approximates real samples represented as $x \\sim q(x)$ through a series of estimation steps, and $q(x)$ represents the underlying data distribution [32], [34]. Subsequently, the denoising network undergoes training to reverse the noise process and restore both the data and its content, thereby facilitating novel data generation. The following describes the forward and reverse diffusion process in further detail:\n1) Forward diffusion process: Considering a given data distribution $x_0 \\sim q(x_0)$, the forward process in GDMs can be accurately represented as a Markov process comprising T steps. Gaussian noise is applied to the initial sample $x_0$ in the forward diffusion process, resulting in the generation of a series of samples $\\{x_1,x_2,\u2026\u2026,x_T\\}$ [35]. This progression is governed by the transition kernel $q(x_t|x_{t-1})$, which captures the dynamics of the system [36]. By utilizing the chain rule of probability and leveraging the Markov property, the joint distribution of $\\{x_1, x_2,...,x_T\\}$ conditioned on $x_0$ can be decomposed as $ \\prod_{t=1}^{T} q(x_t|x_{t-1})$, i.e.,\n$q(x_1,x_2,\u2026, x_T|x_0) = \\prod_{t=1}^{T} q(x_t|x_{t-1}),$ (4)\n$q(x_t|x_{t-1}) = N(x_t; \\mu_t = \\sqrt{1 - l_t}x_{t-1}, \\Sigma_t = l_t I),$ where $ \\mu_t$ and $ \\Sigma_t$ denote the mean and variance, respectively, of the normal distribution at step t. I represents that each dimension has the same standard deviation $l_t$ and is the identity matrix. To simplify the expression, we define $\\Lambda_t := 1-l_t$ and $\\overline{\\Lambda_t} := \\prod_{i=0}^{t}l_i$. Given the input content $x_0$, sampling the Gaussian vector $ \\epsilon \\sim N(0,I)$, $x_t$ can be obtained by [32]\n$x_t = \\sqrt{\\overline{\\Lambda_t}} x_0 + \\sqrt{(1 - \\overline{\\Lambda_t})}\\epsilon_0,$ (5)\nTherefore, $x_t$ can be obtained by the following distribution\n$x_t \\sim q(x_t/x_{t-1}) = N(x_t; \\sqrt{\\overline{\\Lambda_t}}x_0, (1 - \\overline{\\Lambda_t})I).$ (6)\n2) Reverse diffusion process: Based on the inverse distribution $q(x_{t-1}|x_t)$, it becomes feasible to sample $x_t$ from the standard normal distribution $N(0, I)$ using a reverse process. A crucial factor contributing to the effectiveness of this sampling process is the training of the reverse Markov chain to accurately replicate the time reversal of the forward Markov chain [34]. Nevertheless, accurately estimating the statistical properties of $q(x_{t-1}|x_t)$ necessitates intricate computations involving the data distribution, which poses a formidable challenge. To address this challenge, a parametric model $p_\\theta$ can be employed to approximate the estimation of $q(x_{t-1}|x_t)$ as follows, which is given by [36]\n$p_\\theta(x_{t-1}|x_t) = N(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t)),$ (7)\nwhere $ \\theta$ represents the model parameters. Thus, the trajectory from $x_T$ to $x_0$ is expressed as [32]\n$p_\\theta(x_0,x_1,\u2026,x_T) = p_\\theta(x_T) \\prod_{t=1}^{T} p_\\theta(x_{t-1}|x_t).$ (8)\nAdding conditional information, i.e., g, during the denoising process, $p_\\theta(x_{t-1}|x_t,g)$ can be modeled as a noise prediction model, and the covariance matrix and the mean can be expressed as\n$\\Sigma_\\theta(x_t, g, t) = \\frac{1}{l_t}I,$ (9)\n$\\mu_\\theta (x_t, g,t) = \\frac{1}{\\sqrt{1 - \\overline{\\Lambda_t}}} (x_t - \\frac{\\overline{\\Lambda_t}}{\\sqrt{\\overline{\\Lambda_t}}} \\epsilon_\\theta(x_t, g,t)).$ (10)\nFirstly, a sample $x_T \\sim N(0,I)$ is drawn from the standard normal distribution. Subsequently, sampling from the reverse diffusion chain, parameterized by $\\theta$, is performed as follows\n$x_{t-1} \\vert x_t = \\frac{1}{\\sqrt{l_t}} \\epsilon_\\theta(x_t,g,t) + \\sqrt{\\frac{\\lambda_t}{\\lambda_{t-1}}} \\epsilon.$ (11)\nBy disregarding certain weight terms, the original loss function can be streamlined and simplified to [36]\n$L_t = E_{x_0,\\epsilon \\sim q(x_0),\\epsilon \\sim N(0,I)} [\\vert\\vert \\epsilon - \\epsilon_\\theta (\\sqrt{\\lambda_t}x_0 + \\sqrt{1 - \\lambda_t}\\epsilon, t) \\vert\\vert ^2].$ (12)\nReverse denoising is a fundamental component that reverses the forward denoising process through the learning of a transformation kernel, denoted as $p_\\theta(x_{t-1},x_t)$, which is parameterized by a deep neural network [32]. This kernel facilitates restoring the original data $x_0$ by effectively removing the introduced Gaussian noise."}, {"title": "IV. PROBLEM FORMULATION", "content": "In this section, we introduce a multi-dimensional contract mechanism designed to motivate RSUs to offer bandwidth and computing resources to AVs. Initially, we define the utility functions of RSUs and AVs. Subsequently, we develop a contract theory model and validate its feasibility. Finally, considering the potential for AVs irrationally in uncertain environments, we propose incorporating PT into the framework of the proposed incentive mechanism. The main mathematical notations of this paper are shown in Table I."}, {"title": "A. Utility Functions", "content": "We consider a set of RSUS denoted as $L = \\{1", "\u06f0\u06f0\u06f0": "l", "23": ".", "21": ".", "RSUs": "To facilitate the migration of embodied AI twins for virtual service provision", "37": ".", "38": ".", "39": "an additional expenditure in computing costs arises. The computing energy cost incurred by RSU l can be expressed as $C_l^f = \\xi_l\\mu_l f_l^2$", "25": ".", "40": ".", "AVs": "After embodied AI twins are migrated to RSUs their service scope covers AVs, and the embodied AI twins will obtain resources to perform tasks, allowing AVs to obtain in-vehicle services [23"}, {"39": ".", "41": "the authors introduced a new metric called \u201cMeta-Immersion\u201d to measure the Quality of Experience (QoE) experienced by AVs in virtual services. In our paper, we also employ this virtual immersive metric to measure the satisfaction of AVs receiving in-vehicle services from RSUs. In addition, it takes time for RSUs to transmit service data to AVs, which may cause latency, resulting in a degradation of the service experience of AVs. Therefore, the utility function of AVs should consider the immersion metric, the latency, and the reward, i.e.,\n$U = \\sum_{m=1}^{M} \\sum_{n=1}^{N} (\\alpha M_{m,n} - \\beta D_{m,n} - R_{m,n}),$ (16)\nwhere \u03b1 and \u03b2 are user-centric parameters that can reflect the sensitivity of the users within the AV to the immersion indicator and latency, respectively. $M_{m,n}$ represents the immersion metric of the users within the AV achieved from the type-($\\theta_m, \\sigma_n$) RSUs, and $D_{m,n}$ denotes the latency of the AV receiving in-vehicle services from the type-($\\theta_m, \\sigma_n$) RSUs. A viable mathematical expression for immersion metric can be derived by taking the connectivity coefficient multiplied by the logarithm of the stimulus intensity [42", "26": [42]}, {"26": "n$\\tau_{m,n} = \\begin{cases} In(\\frac{Dv}{\\Phi_1 b_{m,n} + \\Phi_2\\mu_{m,n} f_{m,n}}), &  (\\frac{Dv}{\\Phi_1 b_{m,n} + \\Phi_2\\mu_{m,n} f_{m,n}})  \\geq T_{th},\\\\ 0, &  (\\frac{Dv}{\\Phi_1 b_{m,n} + \\Phi_2\\mu_{m,n} f_{m,n}})  < T_{th}, \\end{cases}$ (18)\nwhere S represents the spectrum efficiency of the HMD device of AVs, while $ \\mu_{m,n}$ signifies the effective capacitance coefficient for the computing chipset associated with the type-($\\theta_m, \\sigma_n$) RSUs. The weights $ \\Phi_1$ and $ \\Phi_2$ are greater than zero and $ \\Phi_1 + \\Phi_2 = 1$, ensuring proper weighting. Building upon this analysis, we define the immersion metric as\n$M_{m,n}=b_{m,n} ln(1+\\frac{p_{m,n} |g"}]}