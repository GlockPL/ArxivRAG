{"title": "CAN A SINGLE TREE OUTPERFORM AN ENTIRE FOREST?", "authors": ["Qiangqiang Mao", "Yankai Cao"], "abstract": "The prevailing mindset is that a single decision tree underperforms classic random forests in testing accuracy, despite its advantages in interpretability and lightweight structure. This study challenges such a mindset by significantly improving the testing accuracy of an oblique regression tree through our gradient-based entire tree optimization framework, making its performance comparable to the classic random forest. Our approach reformulates tree training as a differentiable unconstrained optimization task, employing a scaled sigmoid approximation strategy. To ameliorate numerical instability, we propose an algorithmic scheme that solves a sequence of increasingly accurate approximations. Additionally, a subtree polish strategy is implemented to reduce approximation errors accumulated across the tree. Extensive experiments on 16 datasets demonstrate that our optimized tree outperforms the classic random forest by an average of 2.03% improvements in testing accuracy.", "sections": [{"title": "INTRODUCTION", "content": "The single decision tree attracts significant attention in machine learning primarily due to its inherent interpretability. Its transparent \u201cIF-THEN\u201d decision rules make it highly useful for tasks that require clear decision-making logic behind predictions. However, its adoption is often limited by lower testing accuracy, particularly when compared to tree ensemble methods like the classic random forests (Breiman, 2001). Random forests, built from multiple decision trees, are widely recognized for their superior testing performance over single tree models (Tan & Dowe, 2006), and are considered among the best models for accuracy (Fern\u00e1ndez-Delgado et al., 2014; Grinsztajn et al., 2022). However, a classic random forest, which typically consists of hundreds of decision trees, diminishes\u2014or even eliminates\u2014the interpretability that a single decision tree provides. This trade-off between interpretability and accuracy has become widely accepted, fostering a common mindset that the classic random forest outperforms single decision trees in testing accuracy, though at the expense of interpretability.\nSuch a mindset forces resorting to random forests when high test accuracy is essential, even in cases where a lightweight structure and interpretability are also demanded. For instance, in embedded systems with limited hardware resources and power budgets, a lightweight algorithm like decision tree is ideally preferable due to its fewer parameters and less energy consumption (Narayanan et al., 2007; Alcolea & Resano, 2021); yet, in practice, the subpar performance of a single tree often compels a shift toward tree ensembles, such as random forest (Elsts & McConville, 2021; Van Essen et al., 2012). This shift introduces two major issues: first, it significantly aggregates computational costs and memory consumption due to more parameters from multiple trees. Second, it sacrifices the interpretability, which is crucial in certain decision-support scenarios, such as piece-wise control law in explicit model predictive control (Bemporad et al., 2002) and threshold-based well control optimization in subsurface energy management (Kuk et al., 2022). These two concerns can be effectively addressed by a single decision tree if it could match the accuracy of random forests.\nAiming at a single tree with higher accuracy and fewer parameters, the oblique decision tree, a pivot extension of the classic orthogonal decision tree, holds great potential. Oblique decision trees use linear combination of features to create hyperplane splits. When the underlying data distribution follows hyperplane boundaries, oblique decision trees tend to simply tree structures, generating smaller"}, {"title": "FOUNDATIONS OF OBLIQUE REGRESSION TREE", "content": "In this section, we explore oblique regression trees from an optimization perspective by formulating tree training as an optimization problem. For ease of understanding, we primarily follow the notation for optimal decision trees as used in the original work of Bertsimas & Dunn (2017).\nConsider a dataset comprising n samples denoted as {xi, Yi}=1 with input vectors x \u2208 [0,1]P and true output values yi \u2208 [0,1]. A binary tree of depth D comprises T = 2D+1 \u2212 1 nodes, where each node is indexed by t \u2208 T = {1,\u2026,T} in a breadth-first order. The nodes can be categorized into two types: branch nodes, which execute branching tests and are denoted by indices t\u2208 TB = {1,\u2026, [T/2]}, and leaf nodes denoted by t \u2208 T\u2081 = {[T/2] + 1, \u2026\u2026\u2026 ,T}, responsible for providing regression predictions. Each branch node comprises a split weight at \u2208 RP and a split threshold bt \u2208 R to conduct a branching test (a+xi < bt) for the samples allocated to that particular branch node. If a sample x passes the branching test (axi < bt), it is directed to the left child node at index 2t; otherwise, to the right child node at index 2t + 1. Each leaf node comprise the parameters of kt \u2208 RP and ht \u2208 R to provide a prediction value for current leaf. The training of oblique regression trees involves solving the following optimization problem:\nmin (Yi-Yi)\u00b2, \nA,b,K,h\n s.t. \u00cei = ftree(A, b, K, h, xi), i \u2208 {1,\u2026\u2026, n},\n(1a)\n(1b)\nwhere A = {a1,\u2026, a[T/2] } and b = {b\u2081,\u2026\u2026,b[T/2] } are tree split parameters for branch nodes, K = {k[T/2]+1,\u2026,ky} and h = {h[T/2]+1,\u2026,hr} are leaf prediction parameters. In this work, we consider two types of leaf prediction: (a) linear prediction and (b) constant prediction.\n(a) Tree with linear predictions: Linear predictions involve a linear combination of input features (Quinlan, 1998), representing a general form of leaf predictions. If xi is assigned to leaf node t, the final prediction is described as \u0177\u2081 = kxi + ht.\n(b) Tree with constant predictions: This type is a special case of linear predictions, where K remains zero. It is the most commonly used type in existing decision tree methods, with \u0177\u2081 = ht."}, {"title": "UNCONSTRAINED OPTIMIZATION FORMULATION", "content": "In this work, we reformulate the tree training as an unconstrained optimization task, allowing us to leverage powerful gradient-based optimization frameworks for improved solvability and accuracy.\n3.1 DETERMINISTIC SAMPLE ROUTE FORMULATION\nThe interpretability of decision trees primarily stems from their transparent prediction rules associated with the tree paths from the root to leaf nodes. Identifying a sample's specific tree path, such as \"1 \u2192 2 \u2192 5\" for a sample routed to leaf node 5, is crucial for calculating prediction loss. Specifically, for a leaf node t \u2208 TL, we denote its set of ancestor nodes as At. The subsets A and Ar represent the ancestor nodes traversed via the left branch and right branch, respectively, such that At = AUA. Additionally, we introduce a binary branching test variable Ii,j \u2208 {0,1} to signify whether a sample x\u2081 successfully passes the branching test at the branch node j, defined as\nLi,j = 1 (bj - axi > 0). Here, Ii,j = 1 signifies a successful pass at node j; otherwise, Ii,j = 0.\nSubsequently, the sample routing indicator Pi,t \u2208 {0,1}, determines if sample \u00e6\u00bf is assigned to leaf node t, computed as follows:\nPist = \u03a0 I i,j \u03a0 (1 \u2013 Ii,j),\n(2)\nj\u2208A\nj\u2208Ar"}, {"title": "LOSS FORMULATION AND DIFFERENTIABILITY", "content": "Following the deterministic sample route, the training of oblique regression trees is subsequently reformulated as an unconstrained optimization problem. The objective function L is defined by\nn\nL = \u03a3\u03a3 Pit (Yi - (kxi +ht))\u00b2.\n(3)\ni=1 t\u2208TL\nHere, the variables A, b, K and h are implicitly expressed in terms of Ii,j and Pi,t, as shown in Equation (2). For decision trees with constant predictions, the variable K is always equal to zero.\nIn the computation of gradients of L (as detailed in Figure 2), an exception arises due to the non-differentiability of the indicator function 1(\u00b7) in the calculation of the branching test variable Ii,j. To resolve this issue, we employ the scaled sigmoid function S(\u00b7) as an approximation for the indicator function, resulting in the introduction of the approximated branching test variable denoted as \u00cei,j:\n\u00cei,j = S(bj - axi) = [1 + e-a(bj-a^xi)]\u00af\u00b9,\n(4)\nwhere a represents a critical balance between achieving high approximation accuracy and maintaining stability in optimization processes, while also providing some potential concerns."}, {"title": "OBLIQUE TREE TRAINING THROUGH GRADIENT-BASED OPTIMIZATION", "content": "Our optimization task in Equation (3), incorporating the approximated \u00ce\u00bf\u00a1 obtained from Equation (4), closely approximate the original non-differentiable tree training problem. This task can be efficiently solved through our proposed entire tree optimization framework.\n4.1 ITERATIVE SCALED SIGMOID APPROXIMATION\nIn response to early-mentioned concerns regarding an optimal a, we propose a strategy of iterative scaled sigmoid approximation to enhance the approximation accuracy to indicator functions. The key challenge of lies in the selection of a. A larger a may destabilize optimization process, whereas a smaller a tends to be easier to solve for gradient-based optimization. Our strategy leverage this insight by using a solution from an optimization task with a smaller scale factor to effectively warm-starts optimization with a larger scale factor. By starting with a smaller scale factor and gradually increasing it, this strategy enhance the approximation accuracy, while mitigating numerical instability typically associated with larger scale factors.\nSpecifically, the procedure begins by randomly sampling a set of scale factors within a predetermined range, ensuring a broad exploration of possible a values. These sampled scale factors, denoted as {01,\u2026, an}, are then applied in ascending order, from small to large. We initiate the optimization with the smallest sampled scale factor to generate the initial optimized tree candidate. This candidate then serves as the starting point for the subsequent optimization task with a slightly larger a. This iterative process is repeated until all sampled scale factors have been utilized. Detailed implementation steps are integrated within our systematic optimization framework, Algorithm 1.\n4.2 GRADIENT-BASED ENTIRE TREE OPTIMIZATION FRAMEWORK\nUnlike greedy methods that optimize each node sequentially, our approach concurrently optimizes the entire tree, encompassing tree split parameters A and b at all branch nondes, and leaf prediction parameters K and h at all leaf nodes. Our entire tree optimization, outlined in Algorithm 1, begins at multiple random initialization (Line 4 - 6). This multiple-initialization serves two purposes: First, multi-start increases the chance of finding the optimal solution of the unconstrained reformulation. Second, in Section 4.1, the iterative scaled sigmoid approximation involves randomly sampling scale factors for each iteration. These multiple starts enable sampling diverse scale factors in a wider range, thereby enhancing the robustness and approximation accuracy. For each start, the"}, {"title": "SUBTREE POLISH STRATEGY TO MITIGATE ACCUMULATED APPROXIMATION ERRORS", "content": "Accumulated approximation error analysis: Despite our approximation strategy effectively narrowing the substantial gap to the indicator function at each node, the approximation error can still accumulate across an entire decision tree, particularly in deeper trees with numerous nodes. This accumulation can significantly degrade the training optimality, a concern that has received insufficient attention in the literature. To mitigate these accumulated errors, we propose a subtree polish strategy to further enhance training optimality.\nSubtree polish strategy to improve training optimality: In Algorithm 1, Our method is designed to simultaneously optimize all 2D \u2212 1 branch nodes of an entire tree. Intuitively, once a branch node is optimally identified, we can sequentially polish its subtree, including all child nodes of that branch node, while keeping the rest of the tree fixed. This process forms the basis of our subtree polish strategy, which starts with optimizing the entire tree, establishing an initial best tree candidate.\nFor each branch node, there exists a corresponding subtree that extends from the current branch node to the leaf nodes. As illustrated in Figure 3, the subtree is represented within a dashed triangle. Each subtree is optimized using the same approach as for entire tree in Algorithm 1, while leaving the remaining tree nodes fixed. Each subtree optimization is warm-started with the best tree candidate available at that time. Once a subtree is optimized, we combine it with the fixed tree nodes and update the best tree if the combined tree improves training accuracy. This process then proceeds to"}, {"title": "NUMERICAL EXPERIMENTS AND DISCUSSIONS", "content": "We evaluate our optimized tree with both constant and linear predictions, termed as GET and GET-Linear, against the classic random forests RF (Breiman, 2001). Our analysis covers testing accuracy, the number of parameters and prediction time. Additionally, we assess the capabilities of GET, with other decision tree methods in terms of both training optimality and testing accuracy. Finally, we provide a limitation analysis. The compared tree methods include the baseline CART, greedy methods like HHCART (Wickramarachchi et al., 2015), RandCART (Blaser & Fryzlewicz, 2016), and OC1 (Murthy et al., 1994), existing gradient-based trees such as GradTree (Marton et al., 2023) using a straight-through estimator for non-differentiable splits, and soft decision tree SoftDT (Frosst & Hinton, 2017) using standard sigmoid function for soft approximation, as well as the state-of-the-art heuristic method ORT-LS (Dunn, 2018). These comprehensive experiments are conducted on 16 real-world datasets obtained from UCI machine learning repository (Dua & Graff, 2019) and OpenML (Vanschoren et al., 2014), with sample size ranging from 1,503 to 16,599 and feature number from 4 to 40. Detailed dataset information and specific data usage in our study is provided in Appendix F.1. Comparisons focus on testing and training accuracy in terms of Coefficient of Determination (usually denoted as R\u00b2), and computational time in seconds. The Friedman Rank (Sheskin, 2020) is also used to statistically sort the compared methods according to their testing accuracy, with a lower rank indicating better performance. Comprehensive details on the implementation, algorithm configuration, and computing facilities are provided in Appendix F.2.\n5.1 TESTING ACCURACY COMPARISON AGAINST RANDOM FORESTS\nFor testing accuracy comparison, we conduct depth tuning by cross validation to determine the optimal depth across depths from 1 to 12 for our methods. For a fair comparison, comprehensive hyperparameter tuning is also performed for RF. Specifically, the number of trees in a forest is a critical parameter. It is well-recognized that testing performance improves with an increase in the number of trees; however, the marginal gains become less pronounced as additional trees are added (Probst & Boulesteix, 2018; Oshiro et al., 2012). Accordingly, the number of trees for RF is tuned across a set of {50, 100, 200, 300, 400, 500}. Moreover, the maximum tree depth for RF is tuned over a broader range, from 1 to 50, to potentially capture optimal depth settings, given that RF empirically benefits from overly-deeper trees for enhanced testing accuracy. Other hyperparameters for RF, including the number of features per split and the number of samples per tree, are maintained at default settings. These parameters have been shown to balance the bias-variance trade-off, typically yielding robust performance with default values (Probst & Boulesteix, 2018).\nTesting accuracy comparison: Our GET slightly underperforms RF by 0.17% averaging across 16 datasets. In contrast, GET-Linear significantly outperforms RF by 2.03%, as detailed in Ta-ble 1. This superiority is further supported by the Friedman Rank, where GET-Linear ranking the highest, followed by RF and GET. Among 16 datasets, GET-Linear outperforms RF in 8 datasets. Detailed results for each dataset are given in Appendix F.3. These findings question the"}, {"title": "SUPERIOR TEST ACCURACY ANALYSIS: FROM TRAINING OPTIMALITY PERSPECTIVE", "content": "To figure out the rationale behind the competitive testing accuracy of our optimized tree, we delve into the analysis of training optimality from optimization perspective. Notably, the training of tree with different depth corresponds to different optimization problems, exhibiting different optimization challenge in scalability and performance. To assess the optimization capabilities, the training of a predetermined-depth tree is a common practice in the literature. Therefore, the predetermined depths of D = {2, 4, 8, 12} are used for training accuracy comparison. Detailed results for all compared decision tree methods in terms of training accuracy, testing accuracy and training time are given in Table 3.\nThe effectiveness of our tree optimization approach: Table 3 shows that our method GET outperforms ORT-LS by 5.33%, 2.89% and 0.21% in training accuracy for depths of 2, 4 and 8, respectively, while it outperforms CART by 24.55%, 21.50% and 9.69% across various depths. These improvements in training accuracy verify the efficacy of our tree optimization method to achieve training optimality. Additionally, an increase in training accuracy correlates with improved testing accuracy at depths of 2, 4, and 8, suggesting that an optimized tree with higher training accuracy can potentially yield better testing accuracy before encountering serious overfitting issues. Overfitting, particularly at deeper depth like 12, is simply addressed by tuning an optimal tree depth through cross validation, as discussed in previous subsections.\nAblation study on the strategies of our optimization approach: The observed improvements in training accuracy of our method GET, as reported in Table 3, can be attributed to two key strategies: the iterative scaled sigmoid approximation and the subtree polish strategy. The comparative results, presented in Table 4, illustrate the impact of these strategies on GET. For clarity, in the Table 4, our method that utilizes the iterative scaled sigmoid approximation, is referred to as GET. In contrast, when this strategy is not employed, the method is denoted by specific values of scale factors, such as \u03b1 = 1 and a = 100. Additionally, the subtree polish strategy is evaluated in the table, with the methods labeled as \"GET without subtree polish strategy\" and \"GET with subtree polish strategy\"."}, {"title": "ANALYSIS FOR PARAMETER NUMBER, PREDICTION TIME, AND INTERPRETABILITY", "content": "As discussed in Section 1, random forests usually replace a single decision tree to improve testing accuracy in embedded systems. However, a single tree with comparable accuracy could be preferable due to its lightweight structure and interpretability. In this section, we primarily compare our methods with RF regarding the number of parameters, prediction time, and interpretability.\nComparison of parameter number and testing time: Building on the testing comparison in Table 1, we then assess total parameter number and prediction time, in Table 5. RF contains 324 times more parameters than GET and 119 times more than GET-Linear. The prediction speed of GET, averaged over 10,000 repetitions, is 30 times faster than RF, and GET-Linear is 24 times faster. This comparison shows that our tree achieves competitive accuracy with significantly fewer parameters and faster prediction than RF, thereby saving memory and computational costs.\nInterpretability of our oblique tree: Interpretability can be assessed from two aspects: tree-based prediction logic and the complexity of decision rules. First, RF, in Table 1, uses an average of 309.38 trees for higher accuracy, almost losing the interpretability for final predictions compared to a single tree. Second, RF often results in an overly-deep tree with an average depth of 19.24, significantly deeper than our GET with depth of 6.56. Moreover, as compared in Table 2, GET not only achieves"}, {"title": "LIMITATIONS ANALYSIS OF OUR APPROACH", "content": "Our extensive experiments are conducted on datasets containing less than 20,000 samples, without exploring large-scale datasets. While our approach exhibits great scalability compared to the state-of-the-art heuristic decision tree ORT-LS, it is still thousands of times slower than the heuristic methods CART and RF. This limitation is generally acceptable for a single tree model, particularly because it significantly improves accuracy, aligning with our primary focus on testing accuracy, interpretability, and prediction time. However, the longer training time could potentially limit the application of our method in scenarios involving large-scale datasets.\nAnother limitation arises from inadequate regularization in our optimization approach. As shown in Table 3, while training accuracy for GET improves by 5.07% from depth 8 to 12, testing accuracy conversely drops by 6.58%, indicating a serious overfitting issue. This overfitting issue is more pronounced in decision trees with linear predictions, with more detailed analysis and comparisons provided in Appendix F.4. In response, we preliminarily apply L\u2081 regularization to GET-Linear for the experiments reported in Table 1, leading to a modest improvement in testing accuracy by 0.73%. However, due to the challenges in identifying the optimal regularization strength and potential increases in computational costs, we limited our tuning to only between 0 and a small value of le \u2212 5, without extensive tuning. Despite these efforts, further enhancements in testing accuracy could be achieved through more dedicated regularization strategies."}, {"title": "CONCLUSION", "content": "In conclusion, our development of the gradient-based entire tree optimization method, is not necessarily to bring the best regression tree, but rather to explore the potential of a single decision tree in achieving comparable testing accuracy to the classic random forest. This makes a single tree more preferable for scenarios where a lightweight structure and interpretability are valued alongside predictive performance. Our approach reformulates decision tree training as a differentiable unconstrained optimization task, incorporating an iterative scaled sigmoid approximation. The tree optimization capability is further enhanced by a subtree polish strategy. Extensive experiments show that our optimized tree not only achieves but also statistically confirms its testing accuracy comparable to classic random forest, challenging the mindset that a single decision tree typically underperforms random forests in testing performance.\nOur study does not imply that base tree models are superior to ensemble models. Rather, our optimized tree provides a promising alternative for scenarios where a single decision tree is a perfect target instead of the classic random forest. Furthermore, our proposed approaches can also be extended to forest models using ensemble learning, which we intend to explore in future work."}, {"title": "CERTAIN SCENARIOS REQUIRING DECISION TREES WITH HARD-SPLITS", "content": "Hard-split decision trees and soft decision trees represent fundamentally different models, each suited to different application scenarios. Further, there do exist scenarios where the application of hard-split decision trees is not only more appropriate but also imperative. Below are illustrative examples from several industrial projects that underscore this preference:\nScenario 1: Threshold-based well control optimization in underground hydrogen storage system.\nIn the context of large-scale underground hydrogen storage, the operation of periodic hydrogen injection and production across numerous wells necessitates the design of optimal control strategies. Such decision-making problems can be modeled by decision trees, particularly when decisions center on exceeding specific thresholds. For instance, the reservoir pressure or the production rate exceeding a certain threshold can be regarded as the hard decisions at branch nodes. For these scenarios, hard-split decision trees are more suitable for making clear decisions, which can be easily understood and implemented by field engineers or operators.\nScenario 2: True-false decision-making in law enforcement.\nIn law enforcement, decision-making often involves binary choices, such as whether to prosecute a suspect or not. In this case, hard-split decision trees can be used to make clear decisions based on the evidence and the law, which can be easily interpreted by legal professionals.\nScenario 3: Piece-wise affine control law in explicit model predictive control.\nIn explicit model predictive control, the control law is often represented by piece-wise affine functions, which can be effectively approximated by a hard-split decision tree. The hard decisions at branch nodes can be used to determine the control action based on the state of the system, which can be easily implemented in real-time control systems.\nBeyond the utility of making clear hard decisions, the optimal decision tree model that offers superior predictive performance is also crucial for these scenarios. From the perspective of application scenarios, the motivation and necessity for hard-split optimal decision trees are both intuitive and compelling."}, {"title": "EMPIRICAL ANALYSIS OF THE IMPACT OF SCALE FACTORS ON SCALED SIGMOID APPROXIMATION", "content": "The scale factor a significantly influence the approximation degree to indicator function and the behavior of its gradient in optimization. A larger a leads to a better approximation than sigmoid function, achieving closer proximity to an indicator function as a approaches infinity. Nonetheless, a larger a also results in a more unstable gradient, which may adversely affect the optimization process. Specifically, a larger a may cause the gradient to be too small or even zero, leading to the stagnation of gradient descent.\nThe gradient of scaled sigmoid function, denoted as\nS(x) = (1 + e^{-ax})^{-1} \nas\n= aS(x)(1 \u2013 S(x)). When a is larger, either S(x) or 1 \u2013 S(x) tend towards zero for value of x away from origin, potentially causing the gradient to approach zero. Consequently, the a represents a critical balance between achieving high approximation degree and maintaining stability in optimization processes.\nTo show how the scale factor a impacts the training optimality of the unconstrained optimization problem (our method without using the strategy of iterative scaled sigmoid approximation), we conduct the comparison experiments across different a values at different depths. The findings, summarized in Table 6, reveal the relationship between a and training performance, as measured by the average training accuracy R\u00b2. Notably, we observe that the training accuracy at the extremes of a = 1 (sigmoid function) and a = 1000 are inferior compared to intermediate a values. This observation underscores two critical insights: firstly, relying solely on the sigmoid function (a = 1) yields suboptimal optimization results; secondly, the high a value may not necessarily lead to better optimality."}, {"title": "DETERMINISTIC CALCULATIONS FOR LEAF PREDICTION PARAMETERS", "content": "As outlined in Algorithm 1, our method deterministically calculates the leaf values (i.e., the values of K and h), rather than directly using trained values for K and h. Given a tree with tree split parameters A and b, the deterministic tree path for each sample can be calculated by Equation (2), which allows for determining the total number of samples assigned to a specific leaf node t \u2208 TL.\nFor decision trees with constant predictions, the value of K remains zero. The value of h at a leaf node t is an average of true output values (yi) of the samples assigned to that leaf node t.\nFor decision trees with linear predictions, the prediction at a leaf node is a linear combination of input features by fitting a linear correlation between all samples assigned to that leaf node. The leaf values at a leaf node t, kt and ht, are the linear coefficients determined by linear regression."}, {"title": "HYPERPARAMETERS ANALYSIS OF OUR GRADIENT-BASED ENTIRE TREE OPTIMIZATION APPROACH", "content": "Despite the introduction of additional hyperparameters in gradient-based optimization, tuning them is not typically necessary because their effects are straightforward. To be more specific, the hyperparameters in our gradient-based entire tree optimization approach are as follows:\n(1) The multi-start number start\n(2) The epoch number Nepoch\nThe epoch number Nepoch is another hyperparameter that directly affects training optimality. A higher Nepoch value increases training accuracy, but it also increases computational costs. In practice, Nepoch is also set to balance acceptable computational expenses with desired training accuracy.\n(3) The range of sampled scale factors [Amin, Amax]"}, {"title": "SUBTREE POLISH STRATEGY", "content": "Algorithm 2 The Subtree Polish Strategy\n1: Input: Dataset {xi, Yi}=1, tree depth D, and other parameters in Algorithm 1.\n2: Output: Optimal trainable variables Abest, bbest, K (Zero for the case of GET) and h.\n3: Initially optimize an entire tree as the best tree candidate using Algorithm 1, termed Abest and bbest.\n4: for t \u2208 TB do\n5: Induce a subset {Xt, Yt} of the dataset {xi, Yi}=1 for branch node t after fixing the optimized hyperplanes at its parent nodes.\n6: if |Xt > 1 and unique(Vt) > 1 then\n7: Retrieve dsub-depth subtree results rooted at node t from the tree candidate as the warm start.\n8: Polish the subtree, termed as Asub and bsub, using Algorithm 1.\n9: Replace the corresponding subtree of the current best tree candidate with Asub and bsub from Line 8.\n10: Update the current best tree candidate only if this modification improves training optimality.\n11: end if\n12: end for\n13: Deterministically calculate K and h based on the final best tree candidate Abest and bbest."}, {"title": "THE BASIC SETTING OF NUMERICAL EXPERIMENTS", "content": "F.1 DATASET INFORMATION\nThe 16 real-world dataset from UCI repository (Dua & Graff, 2019) and OpenML (Vanschoren et al., 2014) are used in our numerical experiments. Detailed information about these datasets is summarized in Table 7. The dataset size n and the number of features p are provided in the table.\nTypically, we allocated 75% of the samples for training purposes and the remaining 25% for testing. If an experiment requires cross validation for hyperparameters tuning like tree depth, we then\nF.2 THE IMPLEMENTATION SETTINGS FOR COMPARISON STUDIES\nTo implement our Gradient-based Entire Tree optimization framework, we utilize PyTorch that embeds auto differentiation tools and gradient-based optimizers. Our tree induction method is referred to as GET when applied to trees with constant predictions. In cases of trees with linear predictions, we refer to it as GET-Linear. It should be noted that GET is incorporated our additional subtree polish strategy to mitigate accumulated approximation errors, thereby improving training optimality. In contrast, GET-Linear is not equipped with this strategy, as decision trees with linear predictions generally perform well as observed in our experiments. Moreover, decision trees with linear predictions are prone to overfitting, a risk potentially exacerbated by subtree polish strategy unless carefully regularized. The tendency of these tree to overfit is also evidenced by results from exiting open-source software for model linear trees, discussed in Appendix F.4. Our methods (GET and GET-Linear) are configured with Nepoch = 3000 and Nstart = 10, unless otherwise specified.\nFor benchmarking, the open-source Scikit-learn library in Python is used to implement CART and random forest (RF) methods. The parameter values for these methods are set to default values, unless otherwise specified, such as the specific hyperparameters tuning discussed in Section 5.1. The implementation of HHCART, RandCART and OC1 are adapted from publicly sourced GitHub repository and programmed in Python. We modified their classification-oriented loss functions to adapt for regression tasks. As for the local search method ORT-LS, we reproduce it in Julia due to the absence of open-source code for ORT-LS. The GradTree and SoftDT method are implemented using their respective open-source GitHub repositories, with adjustments made only to the epoch numbers to align with our methods.\nExperiments necessitating CPU computation were executed on the high-performance Oracle HPC Cluster, specifically utilizing the \"BM.Standard.E4.128\" configuration. Each compute node within this cluster is equipped with an \u201cAMD EPYC 7J13 64-Core Processor\u201d. Concurrently, experiments requiring GPU resources were conducted on the \u201cNarval\u201d server, which is equipped with an NVIDIA A100 GPU. Additionally, for the comparative analysis of prediction times as elaborated in Section 5.4, we assessed the prediction speeds of each method on the login node of the \"Cedar\" server."}, {"title": "DETAILED TEST ACCURACY COMPARISON RESULTS ON 16 REAL-WORLD DATASETS", "content": "The testing accuracy (R2) comparison for specific 16 real-world datasets is detailed in Table 8.\nF.4 OVERFITTING ISSUE AND COMPARISON FOR TREES WITH LINEAR PREDICTIONS\nAs discussed in Section 5.5, overfitting issues has been observed with both our method GET and GET-Linear. Upon further comparison of our GET-Linear with the existing open-source library linear-tree, it is evident that the overfitting issues are more pronounced in trees with linear predictions. The open-source software linear-tree exhibits significantly more severe overfitting issues at depths such as 8 and 12, as detailed in Table 9.\nFor our method GET-Linear, although it benefits from the subtree polish strategy, improving training accuracy by 1% to 2.19%, it conversely results in a reduction of testing accuracy by up to 3.24%. This decrease in testing accuracy for GET-Linear begins at relatively small depths, such as 4. Given the susceptibility of trees with linear predictions to overfitting, we opt not to apply the subtree polish strategy to GET-Linear in order to mitigate the risk of exacerbating overfitting issues.\nTo mitigate the overfitting issues for GET-Linear, we preliminarily attempt to apply L\u2081 regularization for trainable variables A. This approach involves incorporating a regularization term into the loss function L below, serving to penalize the complexity of the tree structure. The regularized loss is delineated in Equation (5), where \u5165 denotes the regularization strength and || . ||1 represents the L\u2081 norm.\nn\nT\nLreg = \u03a3\u03a3 Pi,t (Yi - (kxi + ht))\u00b2 + \u03bb \u2211 ||at||1\n(5)\ni=1 tETL\nteTb"}]}