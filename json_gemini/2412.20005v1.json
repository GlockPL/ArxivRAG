{"title": "OneKE: A Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System", "authors": ["Yujie Luo", "Xiangyuan Ru", "Kangwei Liu", "Lin Yuan", "Mengshu Sun", "Ningyu Zhang", "Lei Liang", "Zhiqiang Zhang", "Jun Zhou", "Lanning Wei", "Da Zheng", "Haofen Wang", "Huajun Chen"], "abstract": "We introduce OneKE, a dockerized schema-guided knowledge extraction system, which can extract knowledge from the Web and raw PDF Books, and support various domains (science, news, etc.). Specifically, we design OneKE with multiple agents and a configure knowledge base. Different agents perform their respective roles, enabling support for various extraction scenarios. The configure knowledge base facilitates schema configuration, error case debugging and correction, further improving the performance. Empirical evaluations on benchmark datasets demonstrate OneKE's efficacy, while case studies further elucidate its adaptability to diverse tasks across multiple domains, highlighting its potential for broad applications. We have open-sourced the Code\u00b9 and released a Video2.", "sections": [{"title": "1 Introduction", "content": "Knowledge extraction-obtaining knowledge from data, is a critical component for a wide range of practical systems such as Knowledge Graph (KG) construction [1], Retrieval Augmentation (RAG) [3], and domain-specific applications like scientific discovery [2] and intelligence analysis [7]. The last decades have witnessed the development of various knowledge extraction systems [5, 9, 10]. In particular, with the emergence of Large Language Models (LLMs), new works such as InstructUIE [6], iText2KG [4] and AgentRE [8] have been continuously emerged. However, previous approaches still struggle to effectively extract information from raw data following complex schemas and face challenges in debugging and correcting errors when they occur.\nNote that previous efforts have primarily focused on the capabilities of individual models while neglecting the design of a comprehensive system to address the knowledge extraction task. To this end, we introduce OneKE, a dockerized schema-guided knowledge extraction system. We adopt a multi-agent design with a configure knowledge base to provide knowledge extraction support for various scenarios and error debugging, aiming to meet the practical needs of users as much as possible. Following [6],"}, {"title": "2 Design and Implementation", "content": "OneKE is thoughtfully designed to address the complexities and challenges inherent in knowledge extraction. As shown in Figure 1, the framework is guided by several key considerations that enhance its functionality and adaptability in real-world scenario:\n(1) Adaptability to real-world data. Real-world information extraction tasks often handle raw data, like HTML, PDF, etc. Based on this, the OneKE framework supports a variety of data types rather than pure text. We also reserve a user-defined interface to support new data types in the future.\n(2) Generalization for complex schemas. Practical knowledge extraction scenarios should handle diverse and complex schemas, or even no schema. Thus, we design the OneKE-specific Schema Agent to support both pre-defined schemas and self-schema deduction using LLMs. OneKE also supports various LLMs, including LLaMA, Qwen and ChatGLM, as well as proprietary models like GPT-4, enabling effective knowledge extraction.\n(3) Debugging and fixing errors. Most previous works require retraining the model when encountering error cases. In contrast, we integrate Case Repository into OneKE to equip the model with reflective and error-correcting capabilities, enabling its continuous improvement in knowledge extraction tasks."}, {"title": "2.1 Schema Agent", "content": "To support various task settings and data types, we develop the Schema Agent based on LLMs to generate the corresponding output schema for each task. The primary goal is to preprocess the data, standardize its format and schema, and prepare it for the subsequent information extraction step. To support various real-world data, we utilize the document_loaders module provided by the Langchain, to preprocess the data and perform chunking on long texts. Users can also define new data types, and add custom preprocessing methods. Next, if the user has defined a schema, given a task description and raw data input, the Schema Agent will select the appropriate pre-defined schema from the schema repository in the configure knowledge base. If the user does not provide a schema, the model will generate a unified output schema based on the user's instructions, such as \"Extract characters and background setting\u201d. Users can customize schemas using simple text by updating the schema repository in the Configure Knowledge Base."}, {"title": "2.2 Extraction Agent", "content": "Upon receiving the unified output schema from the Schema Agent, we design the Extraction Agent to utilize LLMs for extracting knowledge, thereby generating the preliminary extraction results. Specifically, this module supports a variety of models, including locally deployed open-source models such as LLaMA, Qwen, and Chat-GLM, as well as API services like OpenAI and DeepSeek. To enhance performance, the Extraction Agent learns from similar cases and applies this knowledge to the extraction process. Relevant cases are retrieved from the Case Repository using semantic similarity"}, {"title": "2.3 Reflection Agent", "content": "To enable debugging and error correction, allowing OneKE to learn from past mistakes, we follow [6] to design the Reflection Agent to facilitate reflection and optimization. By leveraging prior knowledge, the agent refines and improves the initial output from the previous module, ultimately producing the final extraction result. Concretely, the agent leverages external Case Repository, specifically relevant bad cases, to facilitate reflection and correction. In a manner similar to the retrieval approach discussed in Section 2.2, the Reflection Agent fetches bad cases that are most relevant to the current task and extraction text. These relevant bad cases, along with their associated reflective analyses, are subsequently incorporated into the LLM. In this way, the agent can effectively learn from past mistakes, enabling its error correction capabilities to generate accurate answers."}, {"title": "2.4 Configure Knowledge Base", "content": "The Configure Knowledge Base provides essential information for the three agents, including manually defined schemas for various tasks, and historical extraction cases, enhancing the performance and error correction capabilities:\nSchema Repository. In the OneKE system, the Schema Repository provides the pre-defined schema for the Schema Agent, supporting the subsequent extraction process. Specifically, the Schema Repository includes pre-defined output schemas for NER, RE, and EE tasks, along with templates for various data scenarios such as scientific academic papers and news reports. The schemas in the Schema Repository are structured as Pydantic objects, enabling seamless serialization into JSON format for the Extraction Agent. Moreover, this structure allows users to customize new schemas within the repository, thus enhancing adaptability and extensibility.\nCase Repository. To enable debugging and error correction in OneKE, we design the Case Repository, which primarily stores traces of past knowledge extraction cases. This repository supports the Extraction Agent in performing extractions and assists the Reflection Agent in reflecting on and correcting errors. Specifically, knowledge extraction cases stored in Case Repository can be divided into two categories: Correct Cases and Bad Cases. Correct Cases provide the Extraction Agent with reasoning steps of successful extraction, while Bad Cases offer the Reflection Agent warnings about avoidable mistakes. The Case Repository will be automatically updated once a knowledge extraction task is completed. Concretely, this module first generates reasoning steps derived from the correct answer, storing both the correct answer and its reasoning steps in the Correct Case Repository to enhance task understanding. Additionally, the agent compares its answer with the correct one and reflects on its original response to identify potential issues. It then stores the original answer along with the corresponding reflections in the Bad Case Repository for future reference."}, {"title": "3 Evaluation", "content": "Experimental Settings. We evaluate OneKE on the CrossNER and NYT-11-HRL datasets. CrossNER is a cross-domain NER dataset, while NYT-11-HRL focuses on the RE task within the news domain. The performance of OneKE is evaluated on both the LLaMA-3-8B-Instruct and GPT-4-turbo models.\nMain Results. As depicted in Figure 2, the various methods employed in OneKE confer performance enhancements across both NER and RE. Notably, the Case Retrieval method of the Extraction Agent achieves the most significant improvements. Through analysis, we observe that the agent effectively applies the reasoning paths in the provided samples, thereby facilitating accurate extraction. Additionally, by comparing the two different tasks, we observe that the aforementioned Case Retrieval method is more effective for the more challenging RE task, as the intermediate reasoning steps are essential in such complex scenarios. The Case Reflection primarily emphasizes the model's ability to recognize known errors and its capacity for transfer learning regarding those errors, leading to similar improvements across both tasks. We provide case studies of specific application scenarios in the following Section."}, {"title": "4 Application", "content": "In practical applications, the OneKE framework supports diverse data formats (HTML, PDF, Word), accommodating both short and long contexts for seamless integration into various downstream applications. We provide case analyses in the following two representative extraction scenarios.\nWeb News Extraction. In the news domain, OneKE enhances the knowledge extraction of Web news content, thereby facilitating downstream tasks such as effective sentiment monitoring, proactive risk management, as well as a variety of additional applications. As illustrated in Figure 3, the extraction task starts with Extracting key information from news articles on a randomly selected raw HTML page from the web, aiming to identify the overall nature of the news and obtain structured key insights. After parsing the HTML-formatted text, the Schema Agent first identifies its domain and genre as a Politics News Report, offering crucial guidance. Utilizing this metadata, the Schema Agent generates a structured Output Schema in code format that effectively captures the key information"}, {"title": "5 Conclusion and Future Work", "content": "In this paper, we introduce OneKE, a Dockerized Schema-Guided LLM Agent-based Knowledge Extraction System. OneKE is designed for flexible application across a spectrum of extraction tasks in real-world scenarios. It can handle source texts of varying lengths and formats (such as HTML and PDF) while demonstrating the capability to adapt to diverse task configurations, generating a broad range of output schemas tailored to specific requirements. Moreover, the integration of a self-reflection mechanism enables iterative improvement informed by external feedback, thereby enhancing both accuracy and adaptability.\nLong-term Maintenance. We will maintain OneKE over the long term, adding new features and fixing bugs. OneKE is built on a modular architecture that promotes extensibility, and we plan to expand the Configure Knowledge Base by integrating additional domain-specific knowledge from fields such as science, thereby broadening its applicability across domains. To advance document data extraction and comprehension, we plan to develop methodologies for the integration and analysis of diverse chart types and content. We hope OneKE can serve as a helpful tool for researchers and engineers engaging in knowledge extraction with LLMs."}]}