{"title": "Multi-Texture Synthesis through Signal Responsive Neural Cellular Automata", "authors": ["Mirela-Magdalena CATRINA", "Ioana Cristina PLAJER", "Alexandra B\u0102ICOIANU"], "abstract": "Neural Cellular Automata (NCA) have proven to be effective in a variety of fields, with numerous biologically inspired applications. One of the fields, in which NCAs perform well is the generation of textures, modelling global patterns from local interactions governed by uniform and coherent rules. This paper aims to enhance the usability of NCAs in texture synthesis by addressing a shortcoming of current NCA architectures for texture generation, which requires separately trained NCA for each individual texture. In this work, we train a single NCA for the evolution of multiple textures, based on individual examples. Our solution provides texture information in the state of each cell, in the form of an internally coded genomic signal, which enables the NCA to generate the expected texture. Such a neural cellular automaton not only maintains its regenerative capability but also allows for interpolation between learned textures and supports grafting techniques. This demonstrates the ability to edit generated textures and the potential for them to merge and coexist within the same automaton. We also address questions related to the influence of the genomic information and the cost function on the evolution of the NCA.", "sections": [{"title": "1 Introduction", "content": "Texturing is a demanding, complex, and fundamental process in computer graphics [1], referring to the process of mapping a texture, usually provided by an image file, onto a given object. The technique of producing high-quality textures of custom size, which are similar to the given examples without containing artifacts or unnatural repetition is called texture synthesis. The importance of this technique is rapidly increasing due to its extensive use in industries like game and film production, combined with the labor-intensive process of manual texture creation.\nTexture synthesis by procedural generation offers multiple advantages, such as efficient sampling and use of time and memory. A few lines of shader code can create complex, satisfactory patterns and improve the system efficiency compared to sampling from 2D image textures, generated using example-based methods [1, 2, 3]. These parametric methods, varying in diversity and size, provide minimal errors and are highly scalable to any resolution output. It is not unexpected that neural networks have been shown to be a powerful approach to texture synthesis [4, 5, 6].\nRecent work demonstrates the capabilities of neural cellular automata (NCA) for this task and highlights the advantages of using this approach, namely, efficient sampling, compactness of the underlying representations and easy usage through short shader programs [2, 3, 7, 8]. The NCA is employed as a differentiable image parametrization [3, 9] meaning it transforms a given image, which is initially, a gray uniform image, in the style of the given target or example. It is important to underline, that the automaton does not create a pixel-copy of the target image, but it generates an example-based texture. The NCA works as a generator and uses the gradients provided by a pre-trained differentiable model, in order to learn the style of the target. This means that each trained NCA generates one single targeted texture and, consequently, such an approach for large-scale multiple texture generation may become burdensome.\nNevertheless, after multiple experiments and research, we concluded that NCAs could perfectly fit the task of generating textures, given the fact that they model global patterns from local interactions governed by uniform, consistent rules, enhancing structured, near-regular patterns in a compact manner. Therefore, by this study we aim to enhance the usability of NCAs in texture synthesis by training a single neural cellular automaton to evolve into multiple textures, thus increasing the automaton's generalisation capacity. Our solution relies on providing texture information into the seed, as a genomically-coded internal signal that the NCA will interpret and thus yield the expected texture. Particularly, we define a few hidden channels of the cell's state to be genome channels, and use binary encoding for each example image index. As a result our NCA will be able to develop 2, 4, 8 (or any other power of two) number of textures. We detail the process of selecting an optimal baseline for our architecture in Section 2.1 and cover the implementation details of the proposed approach in Section 2.2. The results, consisting of an NCA that evolves up to 8 textures, are showcased in Section 3. Moreover, considering the increased complexity and extended range of behaviours exhibited by the NCA, we explore interpolation behaviour and grafting techniques, further emphasizing the editability of our generated textures and the possibility of multiple textures joining and coexisting in one single automaton. In Section 3, we also address questions relating to the extent to which our NCA uses the genomic information, and proper loss function selection based on the properties of selected example images."}, {"title": "2 Methodology", "content": "In this section we introduce the methodology and the theoretical aspects important to our scope. Firstly we introduce the architecture of an NCA for single texture generation and we describe the way it evolves in a given texture, specifically focusing on the loss function and cell perception methodologies.\nIn the following, we explain the NCA model for multiple texture generation, which is the main scope of our work. The experiments follow the proposed genomic coding in the seed for the development of multiple textures. We explain the reasoning for choosing this type of encoding, as well as the architecture and the training details. Furthermore, we briefly discuss the new behaviour of texture interpolation specific to our NCA and its potential.\nFinally, in this section, we introduce further capabilities of the proposed architecture, like regeneration and grafting. Clear and concise steps are presented for these experiments and the results are detailed in Section 3."}, {"title": "2.1 Single texture generation NCA", "content": "Starting from the architecture discussed in [3] this study aims to determine an optimal baseline for further expanding the NCA for multi-texture generation. Our experiments included choosing optimal perception kernels, an adequate neural network architecture and an appropriate loss function."}, {"title": "2.1.1 Architecture and Inference", "content": "A neural cellular automaton is a model that encompasses cells displayed in a structured manner. er. Different cellular automaton types were developed in literature, each designed for a specific use-case [10, 11, 12, 13, 14].\nFor the texture synthesis task, alive cells are displayed in a grid and each one corresponds to a pixel in the generated texture. The NCA is initialized with a seed state, so, and is guided through time using an update function applied for each cell. At each timestamp, cell states are modified, and thus the expected texture emerges after a few evolution stages. The update rule is learnt by a neural network and outputs the new state of a cell based on its previous state and those of its neighbours.\nEach cell's information is stored in an ns-dimensional state vector, where ns is a hyperparameter of the model. The state vector for each of the cells comprises two components:\n\u2022 3 color channels: the first 3 values of the state vector correlate with the RGB channels, assigning color to the corresponding pixel\n\u2022 nh hidden channels: the following values or channels, designed to facilitate cell communication (nh = ns 3). orangeIn our experiments, we preponderantly used nn \u2208 {9,10,12} hidden channels, specific per-experiment values are detailed in Section 3."}, {"title": "2.1.2 Training of the NCA", "content": "In the current context, training the NCA involves training the neural network that models the update rule. We initialize the NCA with a uniform state and evolve it iteratively for t steps. At timestamp t + 1 we measure the quality of the generated texture against the provided example and apply backpropagation to the neural network. In our experiments, t is a randomly generated number between 32 and 96, as utilized and tested in [3]. The training proccess is illustrated in Figure 3."}, {"title": "Loss function", "content": "Our NCA should imitate a given example's style, not generate a pixel copy of it. Therefore, we must train our state processor, represented by the neural network illustrated in Figure 2, accordingly. Most style transfer methods rely on the distributions of feature maps provided by a neural network whose layers are considered to capture style. We name it an observer or differentiable texture discriminator [9, 15]. We pass the RGB channels of our NCA and the example image through the observer and drive the selected feature maps distributions to match.\nThe NCA uses a trained VGG16 network as the differentiable texture discriminator. The choice of VGG is deliberate, as most style transfer approaches utilize VGG variants due to superior results compared to other architectures [9, 3]. The activations provided by a selection of L = 5 layers from the VGG16 network (conv1-1, conv2-1, conv3-1, conv4-1, conv5-1) is used, considering the architecture as shown in Figure 4. The loss calculation process is illustrated in Figure 5.\nAlthough most texture synthesis algorithms rely on feature distribution matching based on Gram matrices [16, 3], their limitations have been thoroughly discussed. The recent work of [16] demonstrates the superiority of the Sliced Wasserstein Loss (SWL) in capturing the complete set of feature distributions. Therefore, we employ the SW Loss for our experiments.\nWe select feature maps from L layers of the observer network for the target image I, and the generated image, \u00ce. We denote the textural loss by L(I, \u00ce) \u2208 R\u207a. For a layer l we have M\u2081 = h \u00d7 w (w - height, w width) feature vectors: Fm \u2208 Ra,m \u2208 {0,1,..., M\u2081 \u2212 1}, where ca is the depth dimension of the feature map. The set of distributions for these vectors is noted p\u00b9 for the features obtained by passing the example image through the VGG, respectively p\u00b9, obtained by passing the generated image through the VGG.\nThe SWL operates on the sets of distributions p\u00b9 and p\u00b9, for all l \u2208 L. Its value is the sum of the distances between the distributions extracted from I and I at each layer 1, as formalized by\n$$L_{sw} (I, \\hat{I}) = \\sum_{l=1}^L L_{sw} (p^l, \\hat{p^l})$$\n(2)\nThe distance between the distributions p\u00b9 and p is calculated by approximating the optimal transport (OT) between them (note that the transport map is not optimal but the optimized distribution is proven to converge towards the target distribution [16]):\n$$L_{sw}(p^l, \\hat{p^l}) = E_v[L_{SW1D}(p_v^l, \\hat{p_v^l})]$$\n(3)\nThe approximation is done through the SW distance, as defined in Eq 3: the expectation of the one dimensional optimal transport (1D OT) distances after projecting the feature points onto random directions V \u2208 Sa (here, pv and ply correspond to the projections of the feature points on a direction V). Projecting over several directions leads our histogram to converge towards the target histogram [17].\nWe project pl and p\u00b9 feature vectors on a random direction using dot product with the vector V and obtain two sets of scalars. The 1D OT is calculated by sorting the scalars and applying Mean Squared Error (MSE), known also as L2 norm, over the obtained sets:\n$$L_{SW1D}(S, S') = \\frac{1}{|S|} ||sort(S) - sort(S')||^2$$\n(4)\nA simplified visualization of the SWL is illustrated in Figure 6 and a pseudocode for this algorithm is presented in Algorithm 1. First, we reshape the feature tensor of shape h \u00d7 W \u00d7 c\u2081 into M\u2081 \u00d7 Cl. We then project these features over 32 random directions (unit vectors of dimension c\u2081), sort them and measure the L2 distance. The strategy of applying this loss is portrayed in Figure 5. A detail not covered in the figure for simplicity is the overflow loss term, given in equation 5, that we add alongside the SWL to keep all state channels in the interval [-1,1].\n$$L_{overflow} (I) = \\sum_{x \\in I} |x - clip_{[-1,1]}x|$$\n(5)\nNote that clip[-1,1]x returns a vector of the same dimension, with all values clipped in the [-1,1] interval. This stabilises training by preventing drift in latent channels and aids in post-training quantisation [2]. The complete formula for our loss is:\n$$L(I, \\hat{I}) = L_{SW} (I_{RGB}, \\hat{I}) + L_{overflow} (I)$$\n(6)"}, {"title": "Pooling", "content": "We pass NCA states to the training step in batches. A sample pool based strategy is necessary for the long-term stability of the automaton [18, 14, 3], explicitly the behaviour of the NCA outside the few steps considered during training. If no pooling strategy is applied, the behaviour of the automaton after the 96 steps threshold would be unstable. We employ the same strategy presented in [14, 3] meaning we construct a pool of 1024 future textures, and seed states of the NCA. Batches of 8 elements are selected from this pool, and after the training step presented in Figure 3 the new states are placed back into the pool. Also, at batch selection, the highest loss scoring element is replaced with a seed the uniformly initialized image to enforce seed evolution, and texture stability and avoid training on irrelevant hallucinations during the first stages of training."}, {"title": "2.2 Multi-texture generation", "content": "Signals are the central component of animal interaction and an essential part of animal life. Internal signals include hormonal or neural signals within the body, bioelectrical and genomic signals during development [19]. Research studying the integration of internal signals in the morphogenesis model of NCA has been conducted [11, 19, 20], but not in the context of self-organising textures.\nIntegrating internal signals in our NCA boils down to attributing special meaning to a few channels of the cell's hidden state. As illustrated in Figure 7, the hidden nh channels of the hidden state are now divided into nc communication channels and ng genomic channels.\nOur experiments include ng = 1, ng = 2 and, respectively, ng = 3 genomic channels, corresponding to 2, 4 and 8 different textures generated by one NCA. Since we employ the overflow loss to stabilise training, encouraging all channels to hold values in the [-1, 1] interval, we needed an appropriate encoding strategy. Therefore we chose binary encodings, as genome channel values will initially be either 0 or 1. Furthermore, ng genomic channels allow generation of 2ng textures and a texture index in its binary coding will allow (ideally) interpolation with all other textures, an advantage further detailed in Section 2.3. An example further discussed in the results section is depicted in Figure 8 where we see the correspondence between the expected textures and the genomic encoding. The genome channels are set at timestamp 0 for each cell in the automaton as follows: for a frilly texture, we set them to 000, for a stratified texture - 001 and so on. In pseudocode, this translates to the function written in Algorithm 2. In the algorithm, we initialize all cells in the automaton to be of genome g, by setting their last ng channels (seed[:, :, -ng :)) to the binary encoding of the genome index g. All other values are 0."}, {"title": "2.3 Regeneration and Grafting", "content": "A well-studied property of NCAs is regeneration [14]. No adaptation of the training strategy is required for the single-texture experiments, and the automaton inherently regenerates and stabilises the pattern shortly after being damaged. However, slight alterations in the training strategy must be applied for the multi-texture architecture. Without these modifications, the NCA generates patches of different textures instead of regenerating the governing texture. Fortunately, only a few adjustments must be made. The automaton reaches the desired behaviour using the adaptation presented in [9]. During batch sampling from the pool, besides replacing a high-scoring state we also damage the lowest-scoring state. Damaging here refers to randomizing the state vectors for cells contained in a circle of a radius of 15 to 25 pixels. The adapted training procedure is concisely shown in Algorithm 5, as an altered version of Algorithm 4.\nOther experiments include grafting visualizations. Grafting is the act of joining two organisms to continue their growth together. In our case, we consider grafting two or more types of cells, belonging to different genomes, coexisting in one automaton. We do this by initializing, either at timestamp 0 or at a random timestamp, some cells with the seed values of a different genome. By doing this, we enable two textures to coexist and interact in the same automaton. This yields to interesting results, studied in further sections. Cells of different genomes can be structured in multiple ways, by creating concentric circles, stripes etc. of different genome cells. An example for generating a texture where the left half belongs to one genome and the right half belongs to another genome is depicted in Algorithm 6."}, {"title": "3 Results and Discussions", "content": "In order to analyze and evaluate the impact of the different hyperparameters, like size of the first hidden layer and loss function, as well as the influence of the genome on the generation of different texture, a series of experiments were performed. Furthermore the possibility of using the NCA for more complex tasks like interpolation of textures, regeneration of damaged textures and grafting is studied and evaluated.\nThe images for all experiments are selected from the Describable Textures Dataset [22] that groups of 5640 images, organized in 47 terms (categories) inspired by human perception: banded, bubbly, bumpy, frilly etc. Moreover, we selected a few textures from VisTex Database [23]. All experiments were run on T4 GPU and lasted up to 2h each."}, {"title": "3.1 Results of the experiments", "content": "The single texture generation experiments studied the influence of different perception filters on the quality of the generated texture. For these experiments we used a pool of 1024 images with a batch size of 8. Training was performed for 5000 epochs.\nAs represented in Figure 9, the Sobel, Sobely, Laplace filters offer enough representation of the neighbors and lead to significantly better results than learned kernels. Of course, leaving the NCA to train longer may enrich the representation provided by learnt kernels. Still, we consider that it would not quantitatively improve the quality output, but it would only add up to the complexity of the NCA representation. Insight on the influence of image processing filters can be studied in [18], where experiments with other combinations of hardcoded filters have been conducted concerning the influence of such filters on the perception stage.\nThe main focus of this paper is on using a single NCA for the generation of multiple textures, by using the information in the genome channel. Furthermore, some new usages of the NCA were explored. The following experiments and results underline the significance of our work."}, {"title": "3.1.1 Multi-texture generation and interpolation results", "content": "This subsection details the tackled NCA architectures for multi-texture generation. Specifically, we study different state formats, the long-term stability of generated textures, and address interpolation behaviour between learnt genomes. The NCAs are trained for 10000 epochs, with a pool size of 1024 samples and batch size of 8 images. Table 1 summarizes the performed multi-texture experiments.\nThe experiments covered various aspects in the image examples, such as similarity and regularity, and are detailed as follows:\n\u2022 Experiment G2Feasible (G2F) tested whether a proposed genomic coding is enough for the NCA to learn to differentiate between textures. Since the results were satisfactory and the NCA learned to differentiate between the two provided textures, it opened the way for generating more textures and lead to the experiments presented below.\n\u2022 Experiment G4Similar (G4Sim) follows the generation of 4 similar textures by a single NCA, enhancing shared feature representation but struggling with long-term stability of the genomes. The automaton learns to read the genome and differentiate the wanted textures, but, as seen in Figure 10, shows difficulties in maintaining the textures over a large number of iterations. This instability may be prevented by training the NCA for more epochs. All 4-genome experiments training lasted around 1h40min.\n\u2022 Experiment G4Different (G4Diff) aims the generation of different textures by a single NCA, which means that different features must be interpreted and learnt. It successfully demonstrated that the automaton does not depend on shared features between textures for learning and gathers a deeper understanding of the genome and particularizes its behaviour accordingly. This experiment also uncovered an intriguing behaviour for the artificially generated texture regarding global communication along cells. Specifically, the NCA fails to achieve the global organization of the grid texture as provided for genome 2 (01), but it still produces a texture with the style specifics of the example (Figure 11, second top). This means that the NCA learns the difference between the genomes, but fails to understand the global organization required for the highly structured texture. Referencing the G4Sim experiment, we only changed the textures we provided as examples to the automaton.\n\u2022 Experiment G4Structured (G4Str) followed the above observation regarding the NCA behaviour on textures with large repetitive models and trained highly structured patterns that necessitate a broader communication across cells in order to test the extent of the cell's global organisation. The experiments' results hyphened a shortcoming of our approach, as the automaton can not reach the global organisation of such textures although it does imitate the style of smaller patterns (Figure 11, third top). This limitation is tackled in Section 3.3.\n\u2022 Experiments G8Large (G8L) and G8Medium (G8M) followed 8-texture generation on a pack of different textures, both artificially generated and real-life examples. They covered different texture categories, colors and patterns, while offering enough room for interpolation between examples. Experiment G8M was performed in order to optimize the number of parameters of the NCA used in Experiment G8L, downgrading the 10k parameter architecture to a 4270 parameter architecture with similar results, while keeping all the other training details unaltered. Training these experiments lasted approximately 1h40min.\n\u2022 Experiment G8SmallNoR (G8SNR) followed 8-texture generation on the same texture pack as the other 8-genome experiments, with the scope of testing how small can our neural network be. Since G8M exhibited a slow regeneration process, we decided to drop the regeneration expectancy for this experiment. We therefore obtained a 1500 parameter NCA that can generate 8 different textures and that holds stability up until 500 steps. Roughly, this architecture size would be equivalent to 8 NCAs with 187 parameters that correctly generate the expected textures, a hard-to-complete task. However, our approach's disadvantage in this case would be the long-term instability of the genomes. This architecture trained for 1h20min.\nIn Figure 11 we visualize the images generated by our experiments, in groups. The conducted experiments were successful. The automaton learned to evolve numerous textures according to the planted internal signals. Most training experiments were done on an unnecessarily large neural network, as seen in comparing the results between architecture G8L of 10k parameters and architecture G8M of 4k parameters with little impact on output texture quality, visible in the second and third rows of Figure 11. However, the smaller architecture's regeneration process is slowed down. For example, the G8L architecture visually regenerates the first genome in approximately 180 steps, whereas the G8M architecture restores it in approximately 420 steps. Another experiment with an even smaller architecture followed, with 3300 parameters (nc = 5, nf = 60), and the 8 textures was successfully developed similarly to the ones presented above, but the regeneration process lasted 700 steps and the automaton did not recover perfectly. Moreover, the genomes get corrupted around the timestamp 1000.\nFurthermore, we test the NCA's ability to generalize learnt features by analyzing its performance on interpolation tasks. Interpolation is a niche texture generation area [24], of interest in computer graphics [25, 26]. This ability is specific to our NCA architecture, as other NCAs developed for texture synthesis cannot generate multiple textures using one single model."}, {"title": "3.1.2 Regeneration and grafting results", "content": "In addition to the experiments described in the preceding sections, some experiments related to regeneration and grafting have also been performed. These highlight the proposed architecture's extensibility while also providing a stable baseline for texture synthesis using small models.\nRegeneration experiments were carried out to test whether our automaton can consistently inpaint a damaged region. This behaviour is studied in different NCA architectures [3, 14, 19] and the inpainting task is also covered by other texture synthesis architectures [21]. The outcome of our experiments emphasizes the rich representation of the genomic texture that leads to successful regeneration. All of our NCAs trained with the adapted methodology enhanced this behaviour. The NCA of experiment G8M had a slower regeneration process due to its reduced architecture.\nFigure 14 displays the NCA regeneration behaviour before and after adjusting the training methodology, as presented in Algorithm 5 of Section 2.3.\nGrafting experiments highlight the rich context in which textures can be generated and combined. As discussed, interpolation tasks involve blending between existing textures to create a new one, combining features of both in a smooth transition. On the other hand, grafting combines distinct textures onto a single surface and often requires careful alignment and blending for a cohesive appearance.\nWe graft textures by either initializing, at timestamp 0, one NCA with different genomes in the patches we want, or running a NCA on one genome, selecting a patch at a given timestamp and transferring that patch over to another NCA, with different genomes. Of course, given that the combined automaton will continue to evolve iteratively, the patches will modify shape, location and area over time. If this is an unwanted behaviour, we could create the illusion of grafting by running 2 or more instances of the NCA, each with an expected genome, and layering the generated textures over each other by masking unwanted patches for each.\nIn Figure 15 a visual example of the initialization with different genomes for grafting is presented. In Figure 15 (a) the yellow color represents genome 91 = (0,0,1), while the blue color represents genome go = (0,0,0). The shades between yellow and blue represent genomes for which the last channel has intermediate values in the range of [0, 1], enabling a smooth transition between the two textures. Figure Figure 15 (b) illustrates the comparison of the initialization mask with the results of the evolution of the nca at timestamp 30. The results of this initialization on the evolution of the nca at timestamp 110 can be seen in Figure 15 (c).\nFigure 16 illustrates a four textures generated through grafting techniques. We observe that the automaton can develop patches of specific genomes. Moreover, we see a communion where the two or more genomes collide, forming a consistent boundary transition area of cells, whether visualized as a barrier (as seen in (b), (d)) or a smooth transition ((a), (c)). Nevertheless, the transition behavior between genomes remains consistent across the intersection line.\nIn the light of all the described experiments, two main questions arose. Firstly we were intrigued by the role of the generation and stability of the desired texture. Thus we studied if the automaton preserves the genome information in the texture cell during evolution and by this learns to discern between the different textures. The second question was about the influence of the loss function on improving the generation of highly-structured textures that require broad-image communication. The results obtained using two different loss functions were compared. In the following these two aspects are presented in more detail."}, {"title": "3.2 Preservation of the genome", "content": "Given the diversity of the generated textures in our experiments, it is essential to investigate whether the automaton preserves and generates textures based solely on the perception stage and vicinity properties, or if it also maintains genome information to ensure stability.\nTo investigate this issue, we based our approach on experiment G2F, where the two genomes correspond to the same texture in both color and grayscale. The automaton is more unstable given the similarity of the textures, but we cannot attribute this to the vicinity similarity, given the different colours. Therefore, we create two similar textures and test whether the automaton can learn the difference between them and remain stable over time. We selected the dotted_0201 texture [22] (Figure 17 left) and created a similar one by deleting the blue polka-dots (Figure 17 right). Note that other colours were not modified, only the blue dots were deleted.\nWe name this experiment G2Preserve (G2Psv). The state vector of the NCA for these two textures has n\u2083 = 13 values, representing the 3 RGB channels, nc = 9 communication channels and ng = 1 genome channel. The genome channel is set to 0 for the first texture and to 1 for the one without blue dots. We employ nf = 128 filters for the first convolutional layer and train the NCA for 10000 epochs. The training step took 1h30min.\nFigure 18 displays the texture generation results for each of the two genomes after different timestamps. It can be observed that the automaton has learned to differentiate between the two textures despite their extreme similarity, suggesting that the automaton considers the genome throughout evolution.\nWe also remark an intriguing, unexpected behaviour. Monitoring the evolution of the NCA, we notice in the second texture (with genome 1) the emergence of small blew dots at evolution step 60. While not yet prominent, it would have likely continued evolving them into dots akin to those seen in the texture generated by genome 0, had the automaton not considered the genome (see this transformation of blue dots throughout genome 0 generation in Figure 18 steps 60-90). However, for genome 1 the formed dots are dimmed and at step 500 no such dots are in formation, supporting the idea that the automaton does keep the genome information throughout evolution.\nTo further support this hypothesis, we provide two figures constructed in similar manner. Figure 19 illustrates the generated textures alongside the genome channel values for two inferences of this experiment, one with cells' belonging to genome 0 (top two rows) and one with cells' belonging to genome 1 (bottom rows). The genome channel is visualized through the colormap corresponding to the colorbar represented on the right of the image, where black corresponds to a genome channel value of -1, and yellow to a genome channel of 1. We observe that the genome channel values are as expected up until around timestamp 60, for genome 0, the channel's values are close to 0 and for genome 1 the channel's values are close to 1. Although the values converge at later timestamps, we pose that the automaton has assigned certain genomic values to each texture style specifics and uses them, alongside the other channels, to maintain texture stability over time. To support this statement, we direct the attention towards the genome channel for the genome 0 NCA run, at timestamp 500 (last column of row 1 in Figure 19). The lower values, approaching -1, visualized as black and dark-purple dots correspond directly to blue dots in the RGB correspondent of the NCA state (row 0, last column), meaning, the automaton has attributed low genome values to texture features specific to the provided example for genome 0, and higher values otherwise, as the common features represent both genome 0 and 1. For the genome 1 generation (third row) we see higher values overall, no deep purple spots in the genome channel at timestamp 500. The lower genome values correspond to the blue, faded dots and areas that are prone to the generation of such dots in the texture; values are later corrected by the self-organising system.\nWe also provide the last genome channel analysis for textures generated by experiment G2Diff. The textures representing genome 00 and 01 have no similar features, as the ones discussed in the aforementioned example, resulting in a clearer divide between the values representing the last genome channel. The last genome channel values for the top rows keep values around 0, as the values for the generation of genome 01 keep higher values throughout evolution."}, {"title": "3.3 Loss function exploration", "content": "Utilizing the SW loss function, the automaton performs strongly on both near-regular and irregular structures. However, it exhibits weaker performance on textures that necessitate broader communication across the automaton, such as images that contain large repetitive patterns. Examples of such given and generated textures are depicted in Figure 21. It's noteworthy that this behavior is intentional and expected in many cases, as it allows for the capture of fine details while disregarding potential irregularities in the given examples, without straining the texture. The NCA does capture the style of the given image, but does not reach a similar global state. Nevertheless, for the showcased instances, we would prefer the NCA to prioritize learning the knitted, knotted, checkered or tiling structures over focusing solely on the finer details of the examples.\nFor comparison, we employ the loss function termed OTT Loss proposed by [2], specialized for regular patterns. We conducted a 4-genome experiment on the regular patterns of Figure 21 using the architecture details as presented in Section 2.2 for experiment G4Sim, using our SW Loss and OTT Loss respectively. A further comparison of the performance of the two losses is obtained by the 8-genome experiment with 4270 parameters, utilizing the G8M architecture, and the outcomes can be visualized in Figure 22. Both experiments highlight the limitations of each loss: SWL produces favorable results on most textures, while OTT Loss excels in generating structured patterns. Examining the generation of the fibrous texture (Figure 22 g4), it is notable that SWL captures a better understanding of the texture, while OTT Loss generates small dots against a pink background. The interlaced texture (Figure 22 93), characterized by similar colours for foreground lines and background is less accurately captured by the OTT Loss, as are the properties of the frilly texture (Figure 22 go) and pitted texture (Figure 22 95).\nOverall, SWL captures more details, as illustrated in Figure 22, given that both trainings rely on 4270 parameters. However, the OTT Loss addresses the aforementioned shortcoming of the SWL in enhancing broader communication along the cells, as depicted in Figure 21. Regeneration is slowed down using the OTT Loss (from 410 steps for regenerating the first genome to 1210), and interpolation leads to images as displayed in Figure 23 (for comparison with the textures displayed in Figure 13).\nWe conclude that the OTT loss covers the shortcoming of the SW Loss for the NCA, which does not accurately reproduce textures with regular, relatively large patterns. This makes OTT loss the preferred one int the case of such texture (ideally artificial [2]) pattern generation. For a broader approach, we consider that SWL covers most cases of the presented examples. A hybrid approach may also lead to better results for both regular and irregular patterns and is one of the things to consider in future experiments."}, {"title": "4 Conclusions", "content": "Neural cellular automata are an active research field with many promising future opportunities. Self-organising structures are both studied from the software point of view and hardware implementations are emerging. Cell division, regeneration, and grafting offer promising prospects in the context of physics, robotics and swarm robotics, artificial intelligence and biology, offering a captivating approach to studying and understanding dynamic, self-organising systems. Real-time robust synthesis of high-quality texture pictures can be achieved using the lightweight NCA. More significantly, it exhibits an amazing zero-shot generalization capability to several post-training adjustments, including local coordinate transformation, speed control, and resizing.\nThis study aimed at increasing the usability of neural cellular automata in the context of texture generation, pinpointing and providing a solution for the limitation of using for each texture a dedicated automaton. For this scope, we applied the idea of providing model context through internal signals, previously used in NCAs trained for growing models from one cell [19", "3": "."}]}