{"title": "To Retrieve or Not to Retrieve? Uncertainty Detection for Dynamic Retrieval Augmented Generation", "authors": ["Kaustubh D. Dhole"], "abstract": "Retrieval-Augmented Generation equips large language models with the capability to retrieve external knowledge, thereby mitigating hallucinations by incorporating information beyond the model's intrinsic abilities. However, most prior works have focused on invoking retrieval deterministically, which makes it unsuitable for tasks such as long-form question answering. Instead, dynamically performing retrieval by invoking it only when the underlying LLM lacks the required knowledge can be more efficient. In this context, we delve deeper into the question, \"To Retrieve or Not to Retrieve?\" by exploring multiple uncertainty detection methods. We evaluate these methods for the task of long-form question answering, employing dynamic retrieval, and present our comparisons. Our findings suggest that uncertainty detection metrics, such as Degree Matrix Jaccard and Eccentricity, can reduce the number of retrieval calls by almost half, with only a slight reduction in question-answering accuracy.", "sections": [{"title": "1 INTRODUCTION", "content": "Recently, Large Language Models (LLMs) like ChatGPT [21], Gemini [26], and others are showing impressive strides in tasks across numerous benchmarks [25]. This success has been largely owed to their exposure to massive training data and successive fine-tuning of instruction datasets. To increase the helpfulness and decrease the harmfulness of the models, they are being further fine-tuned over preference collections [1, 22, 23].\nFurther, Retrieval Augmented Generation (RAG) [4, 9, 15], in the effort to mitigate hallucinations, enriches these models with domain-specific information and tackles scenarios where the in-trinsic knowledge of the base model falls short. By integrating externally retrieved content during the generation phase, RAG en-hances the model's ability to produce less hallucinatory and domain-conditioned responses. This approach has been particularly valu-able in complex applications such as long-form generation like multi-hop question answering, which often requires multiple re-trievals to address a query comprehensively.\nHowever, to optimize the efficiency of RAG, retrieval should only be invoked when necessary also referred to as conditional retrieval. Previous conditional RAG setups have explored multiple paradigms like low token probabilities [12], external classifiers [27], or low entity popularity [20] as indicators of the LLMs' knowledge gaps. However, most of these methods fall short in either approxi-mating knowledge gaps of the LLMs or lacking the ability to invoke retrieval dynamically.\nOn the other hand, with the potential of LLMs to hallucinate, there has been an increasing interest in uncertainty detection methods to gauge LLMs' confidence in their outputs [10]. Unlike traditional methods that rely on rigid heuristics or external clas-sifiers, uncertainty detection leverages the inherent variability in LLM-generated responses to estimate confidence dynamically.\nFor instance, semantic sets-based UD approaches [17] group re-sponses based on meaning, and use the number of clusters to di-rectly reflect the level of uncertainty - with greater variability sig-naling higher uncertainty. Similarly, spectral methods using eigen-value Laplacians quantify response diversity by identifying strong or weak clustering patterns in pairwise similarity graphs. These approaches align with the probabilistic nature of LLMs as well as adaptively gauge uncertainty based on output coherence, making them more robust against adversarial or ambiguous inputs.\nIn this work, we evaluate if such uncertainty detection meth-ods can indeed enhance the reliability of conditionally invoking retrieval, by measuring its impact on a downstream task of multi-hop question answering.\nIn that regard, we resort to a conditional RAG system and em-ploy numerous uncertainty detection metrics to test the need for invoking retrieval. Our RAG system performs forward-looking ac-tive retrieval in the style of Jiang et al. (2023) [12].\nSpecifically, we contribute the following:\n\u2022 We design a retrieval augmented generation with dynamic retrieval\n\u2022 We perform an exhaustive analysis of various conditions from the \"uncertainty quantification\u201d literature to gauge the best strategy to dynamically retrieve during generation\n\u2022 Based on the results, we present insights for future research\nOur insights are useful to gauge whether uncertainty detection methods can help improve the efficiency of RAG."}, {"title": "2 RELATED WORK", "content": "Here, we summarise some of the related work on uncertainty quan-tification and some active RAG efforts.\nThere has been a lot of recent work on uncertainty quantifi-cation of white box and black box NLG models. Lin et al. [16]"}, {"title": "3 TASKS AND DATASETS", "content": "We conduct experiments on the 2WikiMultihopQA dataset [11], a multi-hop open domain question answering (QA) dataset that tests the reasoning and inference skills of question-answering models. Questions in this dataset generally require two steps of reasoning to deduce the final answer, and the information for each step of rea-soning can be obtained through referencing external information viz., Wikipedia passages."}, {"title": "4 APPROACH", "content": "We now describe our uncertainty-aware, retrieval-augmented gen-eration in the following two subsections."}, {"title": "4.1 Uncertainty Evaluation of Future Sentence", "content": "Given a query q, a retriever R, a text generator G, and a black box uncertainty estimation function U, and partially generated se-quence t<i until time step i, we first generate a temporary sen-tence tn in the style of FLARE [12].\nWe use a prompt template P, which could take the form of a zero-shot or a few-shot instruction. This instruction takes as in-put the query, zero or more retrieved documents d\u2081... dk, and the answer tokens generated until now. Here, we use ti to represent the ith temporary sentence and y<i to represent all the initialised and generated sentences (0... (i - 1)}. t\u00a1 is first obtained without performing retrieval:\nti = P{q, ..., Yi-1}\n(1)\nDuring generation, we evaluate the uncertainty of this tempo-rary sentence tn to gauge if the generator needs more information. If the uncertainty U(tn) exceeds a threshold ou, the model is not certain and may lack the necessary knowledge to provide an accu-rate answer. The next sentence yi is then computed by appending retrieved information to the model context:\nYi =\n   P{d1,..., dk, q..., Yi-1} if U(ti) > \u03b8\u03c5\n   P{q,..., Yi-1} otherwise\nwhere d\u2081... dk are obtained from a retrieval system . \nd1... dk := \u03c6(q)\n(3)"}, {"title": "4.2 Sequence Level Uncertainty Evaluation Measures", "content": "We resort to 5 recently introduced sequence-level uncertainty eval-uation measures. Each of them work in a black box manner without requiring information regarding the model parameters.\nThe high-level strategy of all the methods is the same. Given an input x, first generate n responses through some generator G and then compute pairwise similarity scores of each of the n responses with each other. Using these similarity values, compute an uncer-tainty estimate U(x) or a confidence score.\n\u2022 Semantic Sets: In the black-box approach of [14], the au-thors propose to compute semantic sets i.e. groups of re-sponses that are close together in meaning. These semantic sets of equivalence subsets are computed using a Natural Language Inference (NLI) classifier. Here, the number of se-mantic sets can be regarded as an uncertainty estimate as when the responses differ in meaning, the number of groups increases.\n\u2022 Eigen Value Laplacian: defines the uncertainty estimate by capturing the essence of spectral clustering. First, an ad-jacency matrix is created from the pairwise similarities of re-sponses. Then the matrix is partitioned into clusters, where each cluster corresponds to a distinct \"meaning\" or cate-gory within the responses. The eigenvalues close to one in-dicate strong cluster formations, thus contributing less to the uncertainty estimate, while those further from one sug-gest weaker clustering or more diffuse distributions of re-sponses, hence increasing the uncertainty estimate.\nThe degree matrix of the adjacency graph is also used to compute the uncertainty estimate [18]. A node that is well-connected to other nodes, might be less uncertain. We use two similarity metrics for computing the degree matrix.\n\u2022 Degree Matrix (Jaccard Index): The Jaccard similarity is a light-weight metric where sentences or passages are treated as sets of words, and similarity between responses is com-puted by taking the fraction of the intersection of the two sets and the union of the two sets.\n\u2022 Degree Matrix (NLI): Here, the similarity between responses is computed through classifying entailment relations amongst them. A classifier predicts whether a pair of responses con-tradict, entail, or are neutral to each other."}, {"title": "4.3 Subquery Generation for Retrieval", "content": "We resort to retrieving relevant knowledge to account for the infor-mation that the model is lacking to answer the question. FLARE [12] generates a retrieval query for the missing entity in the temporary sentence by using the sentence with the low probability token re-moved or by prompting an external question generator to generate a question for the missing entity as the answer. We generalize this by instead prompting the model to generate a subquery to figure out the missing information needed to answer the user query in an open-ended manner.\nWe define a subquery generator So which takes in as input few-shot exemplars of subqueries, the current user query q, and the cur-rent partial answer sentences uttered in chain-of-thought [28] fash-ion. It seeks to generate subqueries to get a specific piece of infor-mation not generated in the partial answer sentences but is needed to answer q. Once this subquery is generated, we use this subquery to retrieve additional passages from the external retriever R. These passages are then appended to the user input, and the generation continues."}, {"title": "5 SETUP", "content": "The generator used in all experiments was GPT-3 (davinci-002) [2], and the retriever employed was BM25 through PyTerrier [6, 19].\nThe base code used for conducting the experiments and computing the metrics presented in the tables was obtained from the active RAG setup by Jiang et al. [12]. For uncertainty detection, we resort to the Fadeeva et al. [10]'s LM-Polygraph library.\nSince running GPT-3 (davinci-002) along with many of the un-certainty detection metrics could be expensive to run (due to mak-ing multiple calls), we first perform a run for a small seed set of 25 queries across all metrics and then choose the 3 best metrics for a rerun across a larger set of 75 examples. We perform each run three times."}, {"title": "6 RESULTS", "content": "We now present the results in Tables 1 and 2 for the smaller and the larger sets respectively.\nThe baseline method where retrieval was always invoked yielded an F1 score of 0.552 when using temporary sentences as retrieval queries and 0.538 when subqueries were generated for retrieval but required most number of retrieval operations.\nTriggering retrieval, when uncertainty computed through Ec-centricity i.e. U > 2, led to the highest F1 score of 0.605, with a lesser number of search operations. This approach balanced re-trieval efficiency and task performance better than other methods. It required half the number of search operations than an Always Retrieve approach. Semantic Sets' innovative clustering approach performed poorly, with an F1 score of 0.411. Using entailment-based similarity to compute uncertainty via the Degree Matrix NLI measure achieved an F1 score of 0.535, comparable to the baseline. The lightweight Degree Matrix (Jaccard) necessitated the least number of retrieval operations to perform better than an Always Retrieve baseline.\nTable 2 presents additional performance metrics over a larger set of 75 examples. Notably, the Eccentricity method consistently demonstrated the best balance between retrieval efficiency and per-formance, achieving an average F1 score of 0.561 across differ-ent experimental runs, while reducing unnecessary retrievals com-pared to the baseline.\nDegree Matrix (Jaccard) performed slightly worse in F1 score (0.524) but depended on retrieval the least indicating its potential for applications where minimizing retrieval costs is crucial."}, {"title": "7 CONCLUSION", "content": "Our experiments demonstrate that dynamic retrieval, guided by uncertainty detection, improves the efficiency of retrieval-augmented generation systems, making it useful where retrieval can be expen-sive to compute. Among the methods tested, Eccentricity-based uncertainty detection emerged as the best-performing approach, offering the highest F1 score with a moderate number of retrieval steps and searches. This method effectively balances retrieval effi-ciency with task performance.\nThe Degree Matrix (Jaccard) method also showed promising results, particularly in reducing retrieval costs while maintaining reasonable performance. Conversely, methods such as Semantic Sets and FLARE-Instruct underperformed, highlighting the need for more reliable uncertainty estimators.\nAlthough some black-box uncertainty detection methods require multiple runs of generation, which can be costly, always retrieving may be preferable in RAG applications where lightweight retrieval methods like BM25 suffice. This is also evident from the results on the larger set.\nBesides, we feel that uncertainty detection might become more mainstream as the propensity for hallucination in LLMs increases, and as end applications demand more confidence and interpretabil-ity [9] in their outputs making uncertainty detection a necessity.\nOur work focuses on exploiting uncertainty detection for RAG, es-pecially where retrieval can be expensive like the usage of heavy and composite retrieval systems employing numerous components like reformulation [5, 7, 8], dense retrieval [24], reranking, etc."}, {"title": "8 ETHICAL CONSIDERATIONS", "content": "When evaluating large language models (LLMs), it is essential to adopt a sociotechnical perspective [3], acknowledging that their outputs are influenced by both social contexts and technical design choices. Proper safeguards should be in place to mitigate biases and prevent the generation of harmful or toxic content. Furthermore, the uncertainty detection approaches we employed rely on estima-tions derived from various neural network computations, which are inherently shaped by the data on which the models are trained. Consequently, it is critical to thoroughly test uncertainty detection methods to ensure they meet the requirements of the intended ap-plications.\nDespite these precautions, there remains a possibility that some approaches may misrepresent the level of certainty, as no method is flawless. Therefore, ongoing evaluation and refinement of uncer-tainty detection mechanisms are necessary to minimize inaccura-cies and potential misinterpretations."}]}