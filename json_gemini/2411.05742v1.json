{"title": "Topology-aware Reinforcement Feature Space Reconstruction for Graph Data", "authors": ["Wangyang Ying", "Haoyue Bai", "Kunpeng Liu", "Yanjie Fut"], "abstract": "Feature space is an environment where data points are vectorized to represent the original dataset. Reconstructing a good feature space is essential to augment the Al power of data, improve model generalization, and increase the availability of downstream ML models. Existing literature, such as feature transformation and feature selection, is labor-intensive (e.g., heavy reliance on empirical experience) and mostly designed for tabular data. Moreover, these methods regard data samples as independent, which ignores the unique topological structure when applied to graph data, thus resulting in a suboptimal reconstruction feature space. Can we consider the topological information to automatically reconstruct feature space for graph data without heavy experiential knowledge? To fill this gap, we leverage topology-aware reinforcement learning to automate and optimize feature space reconstruction for graph data. Our approach combines the extraction of core subgraphs to capture essential structural information with a graph neural network (GNN) to encode topological features and reduce computing complexity. Then we introduce three reinforcement agents within a hierarchical structure to systematically generate meaningful features through an iterative process, effectively reconstructing the feature space. This framework provides a principled solution for attributed graph feature space reconstruction. The extensive experiments demonstrate the effectiveness and efficiency of including topological awareness. Our code and data are available at https://tinyurl.com/graphFT123.", "sections": [{"title": "1 INTRODUCTION", "content": "Artificial Intelligence (AI) development typically involves: 1) collecting data, 2) computing data representation (a.k.a., feature space), and 3) applying machine learning (ML) models. In real world practices and deployments, the success of ML models highly relies on the quality of a feature space [2]. Developing an effective feature space is essential because it can reconstruct distance measures, reshape discriminative patterns, and augment the Al readiness (e.g., structural, predictive, interactions, and expression level) of data.\nAmong a variety of data types (e.g., tabular, spatial, temporal, time series, sequence data), graph data exhibit the indispensable ability to capture interconnected and complex relationships, handle non-Euclidean spaces, facilitate information propagation, advance diverse domains (e.g., transportation systems, power grids, social networks, recommendation systems) in a way that traditional data types cannot. We study the problem of feature space reconstruction for attributed graph data. Formally, given an attribute graph described by a node-attribute matrix and an adjacent matrix, prediction labels, and a downstream ML task (e.g., node classification, link prediction, and graph classification),\nthe objective is to automatically transform and reconstruct an optimal explicit feature space for the ML task.\nPrior literature only partially addressed the problem: 1) classic feature engineering techniques, such as, empirical data preprocessing, feature selection [9, 10, 16, 41, 44], and feature generation [20, 46, 47] are essential but labor- intensive. They can't achieve full automation in graph feature space reconstruction. 2) recent automated feature space reconstruction methods [3, 4, 13, 21, 38] are mostly designed for generic tabular data. When applied to graph data, they fail to consider the impact of topology structures of attributed graphs in building a graph feature space. 3) neural graph representation methods [11, 24, 40], such as graph convolutional networks, graph attention networks, learn latent embedding feature representation without knowing attribute/feature names. An interesting problem arises: can we develop an effective, automated explicit feature space reconstruction method for attributed graph data?\nOur insights: a topology-aware reinforcement generative perspective. Our insights are two fold: 1) reinforcement generation: Attributed graph feature space reconstruction can be viewed as an iterative feature cross-based generation decision process. The feature knowledge of attributed graph data can be formulated as machine-learnable policies within a Reinforcement Learning (RL) framework. We show that 1) hierarchical RL can iteratively self-learn feature knowledge as policies to generate meaningful attributed graph features; 2) feature group-group crossing to generate large amounts of features can amplify reinforcement reward signals and accelerate feature space exploration. 2) graph topology awareness: there are two key elements in attributed graphs: (i) node attributes and (ii) graph topology. A native solution is to ignore graph topology and simplify attributed graphs as node attribute tabular data, then apply classic tabular data feature transformation methods. However, graph topology can't be ignored, because the great success of graph neural networks (GNNs) shows the importance of modeling neighborhood information and message passing and aggregation. We leverage graph topology from two angles: (a) large graphs with millions of nodes, exponentially increase computational costs. Topology awareness can help to focus on representative and frequent subgraphs, eliminate noisy nodes, and reduce computational costs. (b) RL needs to perceive the dynamic state updates of an attributed graph during iterative feature reconstruction. Topology awareness allows us to quantify the accurate state representation of an attribute graph via GNNs.\nSummary of technical solutions. Inspired by these insights, we propose a topology-aware reinforcement generative feature construction framework for attributed graphs. This framework has two goals: 1) effectively leveraging attributed graph topology; 2) automatically generating the optimal feature set from node attributes for a downstream ML task. To achieve Goal 1, we propose to mine core subgraphs of the dataset to capture the important and valuable local structure information. Subsequently, we use a GNN to learn the embedding of the subgraph as inputs to RL. To achieve Goal 2, we design three reinforcement agents to automatically decide how to perform feature group-group crossing-based generation: a head feature agent to select the first feature group, an operation agent to select an operation (e.g., +, -, *),\nand a tail feature agent to select the second feature. We develop a hierarchical structure to coordinate agents to share states and learn better generation policies."}, {"title": "2 DEFINITIONS AND PROBLEM STATEMENT", "content": "2.1 Important Definitions\nFeature Cross. We aim to reconstruct feature space for an attributed graph dataset \\(G = (A, X, y)\\). Here, A is an adjacency matrix, \\(X = [f_1, f_2, ..., f_n]\\) is a feature matrix, in which a row is a node and a column is a feature, and y is the target labels of nodes or edges. We apply mathematical operations to transform the original features of the attributed graph into new features (e.g., \\([f_1, f_2] \\rightarrow [sin(f_1), f_1 + f_2]\\)). We employ two types of operations in our proposed method:\n1) unary operations including\u02bblog, exp, sin', etc; 2) binary operations including '+, -, *, /'.\n2.2 Problem Statement\nGiven a graph dataset \\(G = (A, X, y)\\) that includes the adjacency matrix A, the feature matrix X, and the target labels y.\nOur goal is to automatically reconstruct an optimal and explicit feature space \\(X^*\\) for the attributed graph in order to improve a downstream ML task M (e.g., node classifications, link predictions, or graph classifications. For instance,\nwhen M is link prediction, y indicates whether any of two nodes are connected). The objective is given by:\n\\[X^* = \\arg \\max_X(V_M(X, y)),\\]\nwhere X can be viewed as a feature subset that includes multiple graph original features and feature crosses (e.g.,\n\\[f_1, f_3, sin(f_1), ..., f_1 + f_2]\\]), and V is the predictive performance indicator."}, {"title": "3 ATTRIBUTED GRAPH FEATURE TRANSFORMATION LEARNING", "content": "3.1 Overview of Proposed Framework\nFigure 1 illustrates the Topological-Aware Reinforcement (TAR) feature space reconstruction framework includes three steps. 1) Topological Information Capture with Core Subgraphs and GNNs; 2) Graph Feature Grouping for Amplifying Reinforcement Signals; 3) Hierarchical Reinforced Feature Crossing. Specifically, in phase 1, we mine core subgraphs from the original graph, and then we devise a graph neural network to embed the subgraph into a fixed-length embedding vector as inputs to capture the topological information. In phase 2, we cluster the original features (node attributes) into different feature groups by minimizing intra-group feature redundancy, and maximizing inter-group feature distinctness. In phase 3, we develop reinforcement feature crossing between groups to generate multiple features at each time and add generated features to the original feature set. In particular, we develop a hierarchical reinforcement learning method to learn three agents to select the two most informative feature groups and the most appropriate operation. We regard a downstream performance of the reconstructed feature space as a reward, and leverage the Bellman equation [6] to optimize the agents to learn the optimal policies.\n3.2 Topological Information Capture with Core Subgraphs and GNNs\n1) Reshaping Representation: Core Subgraphs as Original Graph Approximations for Fast Attributed Graph Feature Transformation.\nWhy mining frequent subgraphs matters? Frequent subgraphs refer to subgraphs that frequently occur in a given graph, and represent the important relational topology, structures, and characteristics of the graph. We propose a subgraph-based rectified feature-crossing strategy, by mining frequent subgraphs of an attributed graph, thereafter, conducting feature crossing over the node features of frequent subgraphs instead of entire graphs. This strategy can advance 1) transformation efficiency: reduce the number of nodes that participated in attributed graph feature transformation, and reduce computational costs; 2) information quality: remove noise, biased, border nodes, retain core and informative graph structures, and model the most intrinsic graph topology for feature transformation.\nSpotting core subgraphs. Inspired by [43], we employ an efficient and accurate algorithm to identify core subgraphs in the training data, as shown in Figure 2. This algorithm utilizes the Depth-First Search (DFS) to explore subgraphs: 1) Starting from each node to explore subgraphs; 2) progressively expanding subgraphs while computing the support values (the number of occurrences in the dataset). We assign a unique code to each explored path by DFS, representing a subgraph. This strategy can effectively enumerate all core subgraphs to reduce the complexity of the dataset.\n2) Embedding Core Subgraphs: GNN Aggregation for Fixed-Length Graph Representations to Capture Topologi- cal Information.\nWhy embedding core subgraphs matters? Aggregating subgraph representations is essential for capturing the core topological and attribute information of a graph in a way that is both compact and meaningful. By embedding core subgraphs into a fixed-length vector representation, we provide a rich, structured input for reinforcement learning (RL) models. This representation allows the RL agent to leverage both local and global graph information, enabling more effective learning and decision-making. Specifically, the GNN-generated vector captures key structural patterns and interrelationships within the graph, making it an ideal input for RL algorithms that require a consistent and informative state representation. The aggregated vector representations retain the core structural information of subgraphs, enabling the RL model to focus on topological patterns. In essence, this approach combines the strengths of GNNs for encoding graph structure and RL for optimizing decisions based on these embeddings, ultimately leading to more effective solutions for graph feature transformation problems.\nAggregating Core Subgraphs. To capture the structure information inherent in graphs, we use a pre-trained GNN to embed a graph into a fixed-length vector as input. Specifically, given a node v from the graph, we sample its all neighbor nodes \\({u_1, u_2, ..., u_p }\\), where p is the number of neighbors. The \\(h_v\\) and \\(h_u\\) are the node representations of node v and node u respectively. We aggregate the representation of all neighbors by calculating their mean:\n\\[\\bar{h_u} = \\frac{1}{p} \\sum_{i=1}^{p} h_{u_i}\\]\nWe update the representations of node v by:\n\\[h_v = ReLU (W \\cdot CONCAT(h_v, \\bar{h_u})),\\]\nwhere ReLU is the activation function and W is the well-trained weight matrix. Finally, we average all node representa- tions to extract the graph-level representation and regard it as the input of RL.\n3.3 Feature Grouping over Core Subgraphs\nWhy grouping features matters? We propose a strategy to accelerate the exploration and crossing of features; that is, firstly group the features of core subgraph nodes and then perform feature crossing between two feature groups, as opposed to crossing two individual features. In this way, we can generate more crossed features instead of one crossed feature, provide stronger reward feedback, and incentivize agents to update policy learning faster. Another insight is that diversity plays a role in feature crossing. In other words, in a feature space, if the features being crossed exhibit significant information distinctness, it is more likely to generate meaningful new features for augmenting data representation; on the other hand, if the features being crossed are similar, the generated features have low information gain. Based on these two principles, we propose to group subgraph features by information distinctiveness, followed by crossing the feature groups. The two feature groups should satisfy the following conditions: 1) the information between each feature group and the predictive label y should show significant differences; otherwise, the two groups should be further merged; 2) the redundancy between the two feature groups should remain low.\nQuantify feature group-group information distinctness. Given a node attribute matrix \\(X = [f_1, f_2, ..., f_n]\\) of a mined subgraph and target labels y, we quantify feature group-group information distinctness by leveraging mutual information:\n1) Relevance between a feature group and target labels. Formally, given a feature group \\(G_p = [f_1, f_3, ..., f_p]\\) (a subset of the node attribute matrix X), we calculate the relevance by:\n\\[Rel(G_p, y) = \\frac{1}{\\vert G_p \\vert} \\sum_{f_i \\in G_p} I(f_i; y),\\]\nwhere \\(I(;)\\) denotes mutual information and \\(\\vert G_p \\vert\\) is the number of features in group.\n2) Redundancy between two feature groups. Formally, given two feature groups \\(G_p = [f_1, f_3, ..., f_p]\\), \\(G_q = [f_2, f_5, ..., f_q]\\),\nwe calculate the redundancy between two feature groups by:\n\\[Red(G_p, G_q) = \\frac{1}{\\vert G_p \\vert \\cdot \\vert G_q \\vert} \\sum_{f_i \\in G_p} \\sum_{f_j \\in G_q} I(f_i; f_j).\\]\n3) Group information distinctness. We construct a new evaluation metric to quantify the information distinctness between feature groups:\n\\[D(G_p, G_q) = \\frac{\\vert Rel(G_p, y) - Rel(G_q, y) \\vert}{Red(G_p, G_q) + \\delta},\\]\nwhere \\(\\delta\\) is a small positive constant to avoid division by zero errors. We use this evaluation metric to evaluate whether to merge \\(G_p\\) and \\(G_q\\). If the group information distinctness \\(D(G_p, G_q)\\) is very low, which means we should put these two group features together.\nBottom-up node feature grouping of attributed graphs. We leverage a hierarchical bottom-up clustering approach to create small groups first and then combine small groups with low inter-group feature information distinctness into large groups. Our method includes two steps: 1) the initialization stage; 2) the bottom-up merging stage. Specifically, in the initialization stage, given a core subgraph, we use X to represent the node feature matrix, with each row as a node and each column as a feature. We denote X as a set of feature vectors \\([f_1, f_2, ..., f_n]\\). We regard each single feature as a small feature group. In the merging stage, we iterate the following steps: i) calculate the group information distinctness D as described in equation 6 between any two groups, then merge the two groups with the lowest group information distinctness; ii) repeat i) until either the group information distinctness between all feature groups exceeds a predefined threshold or the number of feature groups reaches the minimum number of groups.\n3.4 Hierarchical Reinforced Feature Crossing\nWhy hierarchical reinforcement feature crossing matters? Firstly, explicit feature crosses can generate more interpretable and meaningful new dimensions to form a new feature space. For instance, in a movie recommendation system, crossing features describing age and gender produces a meaningful new dimension to describe subpopulations of users interested in certain types of movies (e.g., 20-year-old females might prefer watching romantic dramas). Secondly, the interaction gain between features is crucial in determining whether to cross features; however, measuring such implicit information gain is challenging. Therefore, reinforcement learning serves as a valuable tool to perform AI based decision-making when feature space mechanisms are unclear. Moreover, feature crossing is based on previously generated features and changes the state of a feature space over time, thus we can formulate it into a Markov decision process. We construct three agents: two for selecting features and one for selecting operations. A simple design is all the three agents are independent. However, we find that feature agents and operation agents mutually influence each other in a cascading fashion, forming a hierarchical structure. Therefore, we use hierarchical reinforcement learning to cross new features.\nLeveraging self-optimizing reinforcement and hierarchical agent structures to cross features. We propose to develop a hierarchical reinforcement crossing framework that includes two feature controllers and one operation controller, each of which in each iteration takes a state as input, conducts an action, and generates a new feature to obtain an updated feature set, as shown in Figure 4. For example, in each iteration, a feature controller firstly selects a feature from the current feature set. Secondly, the operation controller selects an operation based on both the current feature set and the chosen feature. Thirdly, another feature controller selects a feature based on the previous selections. By iterating the three steps, we generate an improved feature set and feed it into a downstream ML model to obtain predictive performances as a reward. The key components of our proposed method are as follows:\n1) State. We input the fixed-length embedding mentioned in Section 3.2 into the RL system as a state, which enables us to capture the crucial topological information of graphs.\n2) Agents. We develop a hierarchical structure with three different agents to select features and then generate new features in each iteration, and each agent is implemented by a deep Q-network (DQN) [29]. Here we take the t-th iteration as an example: i) Head feature agent. Given a subgraph with a node feature matrix \\(X^{t-1} = [G_1, G_2, ..., G_k]\\) generated by the last iteration, where G represents a feature group. We use a pre-trained GNN to transfer \\(X^{t-1}\\) to a vector that represents a state, denoted as \\(g(X^{t-1})\\). The action is to select a head feature group \\(G_i\\) from \\(X^{t-1}\\) by the reinforced agent. ii) Operation agent. The state includes the representation of \\(X^{t-1}\\) and the head feature group \\(G_i\\), denoted as \\(g(X^{t-1}) \\oplus g(G_i)\\). The action is to select an operation o from the operation set by this reinforced agent. iii) Tail feature agent. The state includes the representation of \\(X^{t-1}\\), the head feature group \\(G_i\\) and the selected operation o, denoted as \\(g(X^{t-1}) + g(G_i) + rep(o)\\), where rep() is a function to convert an operation into a vector. The action is to select a tail feature group \\(G_j\\) from \\(X^{t-1}\\) by this agent.\n3) Rewards. When the three agents select two feature groups and an operation: i) If the operator is unary, we directly use \\(G_i\\) and o for feature crossing; ii) If the operator is binary, we select features from \\(G_i\\) and \\(G_j\\) to form feature pairs and then cross them using o. We choose the top k features based on the relevance between the crossed features and target labels to add to the original feature set, forming a new feature set \\(X^t\\). We calculate the reward based on the performance of downstream ML tasks, aiming to evaluate whether the current selections of agents contribute to the information gain of the generated feature set. For a good feature set, each feature should contain as much unique information as possible, resulting in an improved performance of the supervised downstream task. Therefore, for a generated feature set in the current iteration, the reward is defined as:\n\\[r(X^t, y) = V_M(A(X^t), y) - p,\\]\nwhere \\(V_M\\) is the performance (e.g., F1-score) of a downstream task, A means apply the cross to the whole graph, and p is the best performance updated with the iteration. We assign the reward to these three agents: i) Head feature agent: \\(r_i = w_1 * r(X^t, y)\\); ii) Operation agent: \\(r_o = w_2 * r(X^t, y)\\); iii) Tail feature agent: \\(r_j = w_3 * r(X^t, y)\\), where \\(w_i (i \\in 1, 2, 3)\\) is a positive weight.\n4) Policy. We train the three agents by maximizing the discounted and cumulative reward during the iterative feature generation process. We encourage the hierarchical agents to collaborate to generate a feature set that is informative and performs well in the downstream ML task. To simplify equations, we use general notations to illustrate the optimization process of any agent. Here, \\(s_t\\), \\(a_t\\), and \\(r_t\\) represent the current state, action, and reward respectively. We minimize the temporal difference error L converted from the Bellman equation [6], given by:\n\\[L = Q(s_t, a_t) - (r_t + \\gamma * \\max_{a_{t+1}} Q(s_{t+1}, a_{t+1})),\\]\nwhere \\(\\gamma \\in [0, 1]\\) is the discounted factor, and Q is the Q function estimated by the DQN. Upon the convergence of the agent, our expectation is to discover the optimal policy \\(\\pi^*\\), which selects the best action according to the state through the Q-value, which can be formulated as follows:\n\\[\\pi^* = \\arg \\max_a(s_t, a).\\]"}, {"title": "4 EXPERIMENTAL RESULTS", "content": "In this section, we evaluate our method with baselines on node-level, edge-level, and graph-level tasks of graphs. In particular, we wish to answer the following research questions: Q1: How effective is our method under the four datasets for three graph tasks? Q2: How does the subgraphs mining influence both effectiveness and efficiency? Q3: How does the GNN-based state influence the performance? Q4: How does feature grouping affect the outcomes? Q5: What is the comparative training time complexity of our method versus the baselines? Q6: What the reconstructed feature space looks like?\n4.1 Experimental Settings\nStatistics of the datasets. We use 4 public benchmark datasets to conduct experiments. These datasets are from different data domains: 1) Bioinformatics dataset: ENZYMES [33], PROTEINS [7]; 2) Synthetic dataset: Synthie [31]; 3) Small molecules dataset: AIDS [32]. These datasets are publicly available at 1. Statistics of the datasets are summarized in Table 1. We compute the total number of graphs, the number of nodes, the number of average nodes, the number of average edges, the class of graphs, and the class of nodes for each dataset.\nEvaluation. We test the transformed graphs with three widely used graph downstream tasks: 1) Node Classification; 2) Link Prediction; 3) Graph Classification. To ensure fair comparisons and alleviate downstream ML model variance, we utilize a simple Multi-Layer Perceptron (MLP) with fixed hyperparameters and a consistent seed for each task to ensure reproducibility. For link prediction, we randomly sample negative edges with the same number as positive ones. Each dataset is split into 80% training and 20% testing subsets. F1-score, Precision, and Recall are employed as evaluation metrics for the three tasks, and Area Under Curve (AUC) is also used for link prediction. Higher metric values denote higher graph feature space quality. To ensure consistency, we randomly executed our method 10 times, and overall performance is reported as mean plus standard deviation.\nReproducibility. 1) Core Frequent Subgraph Mining: We retain the subgraphs if they appear in the original graphs in more than 10% of all graphs and the subgraphs exit 3 nodes at least. 2) Reinforcement Feature Space Reconstruction: We limited iterations (epochs) to 10, with each iteration consisting of 10 exploration steps. When the number of generated features is fourth of the original feature set size, we performed a feature selection to control the feature set size. All agents were conducted using a DQN with two linear layers activated by ReLU function. We use the Adam optimizer with a 0.01 learning rate, and set the limit of the experience replay memory as 32 and the batch size as 8. The parameters of all baseline models are set based on the default settings of corresponding papers. More details are released in the code.\nEnvironmental Settings. All experiments are conducted on the Ubuntu 22.04.3 LTS operating system, Intel(R) Core(TM) i9-13900KF CPU@ 3GHz, and 1 way RTX 4090 and 32GB of RAM, with the framework of Python 3.11.4 and PyTorch 2.0.1.\nBaseline Algorithms. We compare our method with widely used feature transformation methods: 1) RDG randomly generates feature-operation-feature transformation records to create a new feature space; 2) PCA [38] uses linear feature correlation to generate new features; 3) LDA [3] is a matrix factorization-based method that obtains decomposed latent representation as the generated feature space; 4) ERG first applies a set of operations to each feature to expand the feature space, and then selects key features from it to form a new feature space; 5) NFS [4] embeds the decision-making process of feature transformation into a policy network and utilizes reinforcement learning (RL) to optimize the entire feature transformation process; 6) TTG [21] represents the feature transformation process as a graph and implements an RL-based discrete search method to find the optimal feature set.\n4.2 Overall Performance (RQ1)\nIn this experiment, we aim to respond to research question 1: can our method effectively reconstruct quality feature space to improve downstream tasks? We compare the overall performance of TAR in terms of Precision, Recall, F1-score, and AUC in three wildly used graph tasks. Table 2 shows TAR performs the best in all datasets across different downstream tasks. The underlying driver for this observation is that TAR can accurately capture intricate and valuable topological information through core subgraph mining and GNN-based embedding, and then the hierarchical graph feature crossing policies in TAR incorporate the graph information, feature information distinctness, and valuable feedback to generate informative features for a graph. In conclusion, this experiment validates that our method is more effective in graph feature space reconstruction.\n4.3 Impact of the Subgraph (RQ2)\nOne of the most important novelties of TAR is to involve subgraph mining to focus on the most informative and critical topological structures. To analyze the effectiveness and efficiency of this component, we develop a variant model TAR, which uses the complete graph data instead of subgraphs to reconstruct the feature space. Figure 5 (a)(b)(c) show that TAR can achieve better performance compared to TAR. The underlying driver is that TAR crosses features based on subgraphs, which denoises the graph and enables the crossing strategy tailored to the most critical structures and features, thus better capturing the intrinsic characteristics. Another observation is that TAR achieves better efficiency in terms of training time cost, as shown in Figure 5 (d)(e)(f). The reason is that transforming a complex graph into a simplified subgraph eases the model computation, which reduces the computational complexity. In summary, this experiment demonstrates the effectiveness and efficiency of including subgraphs. The detailed experiment results for all datasets are reported in Table 3.\n4.4 Impact of the GNN-based State (RQ3)\nIn our framework, to capture the structure information of graphs, we adopt a well-trained GNN to embed a graph as a vector by aggregating the neighbors of nodes. Then we input the vector into the reinforcement agents so that the agents can make selection decisions based on the current state. To verify the impact of this component, we develop a variant model TAR+, which replaces the GNN with a descriptive statistics-based dual summarization method [28]. Figure 6 demonstrates that TAR outperforms TAR+ in most cases. The underlying driver for this observation is that TAR uses the GNN to be aware of the topological knowledge in graphs, enabling the model to consider this valuable structure information to reconstruct a better feature space. In conclusion, this experiment shows the importance of considering topological information when reconstructing a feature space for graph datasets. The detailed experiment results for all datasets are reported in Table 4.\n4.5 Impact of the Feature Grouping (RQ4)\nTo further analyze the impact of feature grouping, we removed this component, allowing the reinforcement agents to select an individual feature rather than a group of features within each step, denoted as TAR*. Figure 7 indicates that TAR surpasses TAR* across all datasets. This is attributed to TAR generating more informative features and providing stronger feedback within each iteration. Additionally, TAR generates a greater number of features compared to TAR*, which enhances the exploration of high-order crossed features within fixed steps. Therefore, this experiment underscores the necessity and effectiveness of feature grouping. The detailed experiment results for all datasets are reported in Table 5.\n4.6 Complexity Analysis (RQ5)\nWe compared the computational complexity between TAR and all baselines, as shown in Figure 8. The x-axis illustrates the F1-score achieved in the downstream task of node classification using the PROTEINS dataset, while the y-axis represents the time cost required by each method. The unsupervised baselines, such as PAC and LDA, cost less time, but are less accurate. Compared with the supervised baselines, TAR costs less time than ERG, NFS, and TTG, and costs a little more time than RDG. Remarkably, despite marginally higher time requirements compared to three baseline methods, TAR achieves superior downstream performance, underscoring its ability to balance the effectiveness and efficiency of graph feature reconstruction. We report the complete results for all datasets in Table 6.\n4.7 Reconstructed Feature Space Analysis (RQ6)\nWe select the AIDS dataset as an example to visualize the reconstructed graph-level feature space. In detail, for a specific graph, we calculate the mean of all node embeddings to represent the graph. Then, we use T-SNE [1] to map them into a 2-dimensional space for visualization. Figure 9 shows the visualization results of the original feature space and reconstructed feature space, in which each point represents a unique graph in the AIDS dataset. We can observe that graphs have a better distinctness in the reconstructed feature space. Especially for the graphs in the circle, TAR can divide the graphs into two groups with a clear boundary. As a result, the F1-score of graph classification increases from 0.864 to 0.984, which is a significant improvement. The underlying driver is that TAR can reconstruct the feature space aware of the graph structure information to make the dataset more discriminative, thus achieving better downstream performance."}, {"title": "5 RELATED WORK", "content": "Reinforcement Learning (RL) is a machine learning method of how an intelligent agent ought to take actions in a dynamic environment in order to maximize the cumulative reward [35]. The RL algorithms can be divided into two categories according to the learned policy: value-based and policy-based. Valued-based algorithm [30, 39, 49] estimates the value function or action-value function to learn a policy. Policy-based [36] learns a probability distribution to map state to action directly. Furthermore, an actor-critic reinforcement learning framework is introduced to integrate the benefits of both value-based and policy-based algorithms [34].\nFeature Space Reconstruction aims to derive a new feature set from original features to improve downstream ML tasks [5, 15, 25, 45]. Humans can manually reconstruct a feature space with domain knowledge and empirical experiences, which is explicit, traceable, and explainable, but incomplete and time-consuming. Machine-assistant methods can be divided into two categories: unsupervised and supervised methods. Unsupervised methods don't rely on labels such as Principal Components Analysis (PCA) [38]. PCA is based on a strong assumption of straight linear feature correlation, and only uses addition or subtraction to generate features, leading to only dimensionality reduction rather than an increase. Supervised methods include exhaustive-expansion-reduction approaches [14, 17, 19, 23, 26], iterative-feedback-improvement approaches [22, 37, 52], feature engineering with language models [8, 50], and AutoML techniques [12, 18, 27, 48, 51] that are enabled by reinforcement learning, genetic algorithms, or evolutionary algorithms. However, among a variety of data types [42], all the methods are designed for tabular data, which makes it hard to generalize to graph datasets. In this paper, we develop a topological-aware reinforcement feature space reconstruction method, enabling a better feature space reconstruction for graph datasets."}, {"title": "6 CONCLUSION REMARKS", "content": "In conclusion, our novel framework, which combines graph neural networks and topology-aware reinforcement learning, captures the complex topological structures in graph data to automatically reconstruct the optimal feature space, thereby improving downstream ML tasks. Specifically, our approach captures significant structural details by mining core subgraphs and embedding their information with GNN. Then reinforcement learning agents iteratively generate features, reducing reliance on human intuition. This automated process achieves dual objectives: capturing graph topologies and optimizing feature generation. This framework simplifies feature space reconstruction and improves the performance of machine learning models on graph data. Extensive experiments validate the effectiveness and efficiency of including topological awareness. The superior experimental performance highlights its potential as a valuable approach for graph feature space reconstruction in large quantities of domains, such as bioinformatics, chemistry, etc."}]}