{"title": "Use of What-if Scenarios to Help Explain Artificial Intelligence Models for Neonatal Health", "authors": ["Abdullah Mamun", "Lawrence D. Devoe", "Mark I. Evans", "David W. Britt", "Judith Klein-Seetharaman", "Hassan Ghasemzadeh"], "abstract": "Early detection of intrapartum risk enables interventions to potentially prevent or mitigate adverse labor outcomes such as cerebral palsy. Currently, there is no accurate automated system to predict such events to assist with clinical decision-making. To fill this gap, we propose \"Artificial Intelligence (AI) for Modeling and Explaining Neonatal Health\" (AIMEN), a deep learning framework that not only predicts adverse labor outcomes from maternal, fetal, obstetrical, and intrapartum risk factors but also provides the model's reasoning behind the predictions made. The latter can provide insights into what modifications in the input variables of the model could have changed the predicted outcome. We address the challenges of imbalance and small datasets by synthesizing additional training data using Adaptive Synthetic Sampling (ADASYN) and Conditional Tabular Generative Adversarial Networks (CTGAN). AIMEN uses an ensemble of fully-connected neural networks as the backbone for its classification with the data augmentation supported by either ADASYN or CTGAN. AIMEN, supported by CTGAN, outperforms AIMEN supported by ADASYN in classification. AIMEN can predict a high risk for adverse labor outcomes with an average F1 score of 0.784. It also provides counterfactual explanations that can be achieved by changing 2 to 3 attributes on average. Resources available: https://github.com/ab9mamun/AIMEN.", "sections": [{"title": "1 Introduction", "content": "Electronic fetal monitoring (EFM) involves the continuous recording of fetal heart rate and the mother's uterine contractions during labor, to detect any signs of distress or abnormalities that might indicate potential complications during labor. These complications include or can lead to a large and diverse number of adverse labor outcomes such as fetal hypoxia, acidosis, fetal distress, meconium aspiration, intrauterine growth restriction, preterm birth, neonatal encephalopathy, stillbirth, low Apgar scores, and maternal complications. Misinterpretation of EFM data is a very common allegation in malpractice litigation, claiming that such misinterpretation resulted in a lack of blood and oxygen flow to the fetal brain (birth asphyxia) [29]. Early signs of compromise in the neonate can be linked to a low Apgar [2] score or low arterial pH in the umbilical cord, and then the development of neonatal encephalopathy, a condition of altered consciousness which is suggested by many to be a requisite for cerebral palsy (CP) to have been caused by complications of labor. CP is a lifelong condition that has variable components and etiologies but functionally limits cognitive ability. One of the challenges in predicting adverse labor outcomes such as CP is the lack of standardization of definitions because CP is only one of the many possible adverse outcomes. For example, neonatal data such as arterial"}, {"title": "2 Related Work", "content": "2.1 Al in neonatal health\nAI has affected multiple areas of health care, including obstetrics [15, 26], cardiovascular health [27, 28, 46], metabolic health [3, 19], behavioral health [5, 38], medical imaging [37] and oncology [32, 36] among many others. Ahn and Lee have published an overview of ML for obstetrics [1]. Davidson and Boland recently reviewed 127 distinct studies using AI/ML to improve pregnancy outcomes [11]. However, physicians are often skeptical about AI/ML approaches in medicine in general [20], including obstetrics [39]. Randomized clinical trials (RCTs), the cornerstone of assessing interventions before they are incorporated in clinical practice when applied to AI/ML-assisted interventions have solicited concerns regarding the quality of medical AI/ML RCTs [34]. Transparency and trust as opposed to \"black box\" predictions, alongside evidence-based medicine principles and shared decision-making between patients and clinicians using AI/ML-based risk assessments will be needed to promote their acceptance [20]. Toward this goal, we describe our first steps in developing an AI/ML approach that includes an explainable AI component, CE, to assist clinical decision-making in predicting the high risk of adverse labor outcomes, potentially increasing opportunities for interventions and mitigation. Some recent studies have incorrectly claimed computer systems have been proven to be better than expert clinical management, but all have failed to be implementable [7, 12, 13, 21, 35]. We are therefore closely collaborating with obstetricians to increase the likelihood that the AI/ML system will be useful to them. A major challenge for developing AI/ML methods in this field is the ambiguity in definitions of gold standards and features used for model development. Neonatal data such as arterial umbilical cord blood pH are associated with but not diagnostic of an increased risk of adverse outcomes [22]. Numerous definitions for adverse or abnormal outcomes have been used [17, 42], and more work will be needed to develop better classifiers associated with specific outcomes. This will require larger datasets and the development of such resources is underway [47]. This will also allow the application of more complex and deeper neural network models for future work. To date, such models have only been applied to EFM data, not the other RFs as features [33]. As a note of caution, a recent classification of EFM data using deep learning has also indicated that more data do not always yield better results [43]. However, we believe that there are good opportunities to enhance fetal health monitoring, especially if we combine real-time data analysis [16] with the presentation to the clinical decision-making staff working in labor and delivery units where the AI/ML predictions are transparent, assistive and trustworthy [13]."}, {"title": "2.2 Tabular data classification", "content": "Classification with tabular data can be done with different ML algorithms. While deep learning became the default choice for computer vision and natural language processing problems, decision trees, random forests, and different ensemble methods based on decision trees and their variants are still popular choices for tabular data classification and regression. XGBoost[10], TabNet [4], and DANETS [25] are some of the recent architectures for tabular data classification. XGBoost is a scalable tree-boosting algorithm that utilizes a sequential series of decision trees where every tree corrects the mistakes of its preceding tree. This model has proven to be more accurate than deep neural networks and ensemble methods of concurrent time in multiple instances [10]. The self-supervised learning-based TabNet outperforms XGBoost, decision tree, and other similar methods by a significant margin on numerous datasets [4]. DANETS is a recent model that works well on tabular data classification and regression problems [25]. Recent studies have started exploring the potential of MLPs for computer vision in terms of its performance and scalability [6, 23]. However, the efficacy of multilayer perceptrons (MLP) for tabular data classification did not get enough attention to the best of our knowledge."}, {"title": "2.3 Interpretable ML", "content": "Interpretability is a branch of ML that aims to enhance the transparency, reliability, and trust patients and doctors will place in an intelligent system. Molnar has provided an overview of interpretability in ML [30]. Two common ways of achieving interpretability are either by making the model directly interpretable or by providing explanations of the model's decisions. The quality of an explanation is often difficult to evaluate. A position paper by Doshi-Velez and Kim [14] makes suggestions on classifying and evaluating interpretations provided by ML models. One specific way of achieving interpretability is by providing CEs of a particular example. For a binary classification problem, a CE of a specific prediction for an instance is a real or hypothetical scenario where some attributes of the instance would be altered to reach the opposite prediction. CEs can provide insight into what features are more likely associated with a specific outcome. They can also be used for designing interventions if they are actionable. For example, for a certain disease, the model can suggest that if the patient were 20 years younger, he or she would not face a specific outcome. However, that explanation is not actionable as a person cannot change his or her age. In contrast, a person can change their food intake patterns and risk of insulin resistance. Accuracy, distance, and sparsity are some of the metrics that can be used when evaluating CEs. Accuracy is evaluated by whether the counterfactual example is classified as the opposite class. Distance can be measured with Euclidean distance on the normalized feature set. Finally, the sparsity is the number of features that need to be changed to convert the original outcome to a counterfactual outcome. Brughmans et al. [9] provide the nearest instance to CE whereas Mothilal et al. [31] use gradient descent to find optimal CE based on diversity, sparsity, actionability, and proximity."}, {"title": "3 AIMEN System Design", "content": "3.1 Problem setup and system overview\nThe goal of this paper is to estimate a classifier $f : R^d \\rightarrow {0, 1}$ that predicts an outcome variable $y \\in {0, 1}$ from a state variable $x \\in R^d$. The state variable x is a d-dimensional vector of real numbers and the outcome y is a boolean variable that can be either 0 or 1. In the context of neonatal risk modeling, x is a vector of values of d risk factors: $x_1, x_2, ..., x_d$, and the value of y represents the presence or absence of a specific adverse outcome, for example, high risk of adverse labor outcome. Suppose, we have a dataset D with M number of labor cases with their corresponding risk factors and outcomes, the state vector of the i-th case can be represented by $x^{(i)}$.\nEstimation of the classifier, f, can be done in a supervised learning setting where the weights and biases can be learned by training from the data points of D. Suppose, the test dataset is $D_{test}$ where $D \\cap D_{test} = \\phi$. After training on D, the model f's performance metric on the test set $D_{test}$ is $R(f, D, D_{test})$. If the target performance metric is $R^*$, we will need to train the model on another dataset, S, which can be a real or synthetic dataset, so that $R(f, D \\cup S, D_{test}) \\geq R^*$. Also, $S \\cap D = \\phi$ because any common data point between these two sets is redundant and can be removed from S to update S so that the condition of disjoin is met. For the calculation of the distribution gap between the real dataset and the synthetic dataset, let us also define the loss of the classifier f trained with dataset D and evaluated on test dataset $D_{test}$ as $L(f, D, D_{test})$.\nThis paper aims to solve the problem using the following steps.\n(1) Generate synthetic dataset S using training dataset D"}, {"title": "3.2 Data collection", "content": "Data was collected from 1462 patients. The recorded RFs include preexisting maternal conditions such as diabetes, hypertension, and cholesterol. The fetal, obstetrical, and delivery RFs and EFM data were collected. EFM features include the absence of FHR accelerations, abnormal baseline FHR, and excessive uterine activity. This dataset's full list of RFs can be found in Mamun et al. [26]. A summary of some numeric features of the dataset is available in Table 1. Five cases were excluded because of missing RFs and the dataset was prepared with the remaining 1457 cases."}, {"title": "3.3 Data balancing and augmentation", "content": "A major challenge with this project is the small data size of 1457 cases. Moreover, the data was imbalanced because the number of positive (abnormal) cases was only 112. To address these issues, we increased the size of the training dataset and balanced the dataset with the help of data generation and augmentation tools. Two different methods were used independently with additional customizable options.\nIn the first phase, ADASYN [18] was used to generate synthetic data for the positive class. Then subsets of negative set data and positive set data were randomly sampled so that the size of the negative subset was lower than the size of the positive subset. Then using this sampled data, negative class samples were generated. This process is repeated until the final training dataset is balanced and is at least 5 times larger than the original training dataset. It was done this way so that the final dataset had at least 5000 cases for each class, totaling at least 10000 cases in the training data.\nWe also employed the CTGAN [45] model for synthetic data generation. We balanced and augmented the data in three phases: i. generated positive class data until the dataset was balanced, ii. generated negative class samples until"}, {"title": "3.4 Classification", "content": "The classification was done with ensemble learning with a group of k classifier models ($k \\in N$) that were trained through k-fold cross-validation. Each model was trained with (k-1) folds of training data and validated on the left-out fold. Based on the performance of the validation set, some classifiers were given the voting rights to classify test data. In our experiments, the voting right was given to any classifier that achieved a macro average F1 score higher than 0.7 on its validation set. Finally, weighted voting was done among the qualified classifiers to make predictions on the test set. A classifier with a higher validation score was assigned a higher voting weight. For example, suppose, the weights are $a_1, a_2, ..., a_k$ for the k classifier models. Now, if the prediction probabilities of a particular unseen example, x, by the classifiers are $f_1(x), f_2(x), ..., f_k(x) \\in [0, 1]$ respectively, then the final prediction probability will be"}, {"title": "3.5 Counterfactual explanations", "content": "One major component of the AIMEN system is its ability to highlight important features by providing alternate scenarios where an abnormal labor case could be flipped to a normal case by changing one or more risk factors. The nearest instance CEs [9] were calculated with our prediction module. This method considers the nearest neighbors of a specific example based on Euclidian distance after scaling the data with MinMax scaling. CEs were generated for each abnormal class example from the test set to identify the major contributors to the high risk of adverse labor outcomes and potential interventions."}, {"title": "3.6 Performance Metrics", "content": "As the dataset was highly imbalanced, it was important to evaluate a classifier's performance with multiple metrics besides accuracy. The performance metrics reported are accuracy, sensitivity, specificity, positive class F1 score, negative class F1 score, average F1 score, and area under the receiver operating characteristic curve (AUROC\u00b9). They are described below. Suppose, there are | Dtest | = M test examples and the symbols TP, TN, FP, FN represent the numbers of true positive, true negative, false positive, and false negative predictions respectively. Also, suppose, $y^{(i)}$ is the true label (0 or 1) of i-th test example and $p^{(i)}$ is the predicted probability with which the i-th test example belongs to class 1. Then the evaluation metrics can be calculated as:\n\u2022 Binary cross entropy loss: $\\sum_{i=1}^{M} (y^{(i)} log(p^{(i)}) + (1 - y^{(i)}) log(1 - p^{(i)}))$,\n\u2022 Sensitivity: $\\frac{TP}{TP+FN}$,\n\u2022 Specificity: $\\frac{TN}{TN+FP}$,\n\u2022 Positive predictive value (PPV): $\\frac{TP}{TP+FP}$,\n\u2022 Negative predictive value (NPV): $\\frac{TN}{TN+FN}$,\n\u2022 F1 score for positive class (F1+): $\\frac{2 \\times PPV \\times Sensitivity}{PPV+Sensitivity}$,\n\u2022 F1 score for negative class (F1-): $\\frac{2 \\times NPV \\times Specificity}{NPV+Specificity}$,\n\u2022 Average F1 score (F1): (F1+ + F1-)/2"}, {"title": "4 Results", "content": "We compared several different backbones of AIMEN and investigated different choices of parameters to find the optimal configuration for prediction and CEs."}, {"title": "4.1 CTGAN vs ADASYN", "content": "Synthetic data generation was employed with both CTGAN and ADASYN and overall CTGAN generated data were more helpful for the downstream task. In Fig. 4, we compare different methods of data generation. Data generation with CTGAN allows specifying the categorical variables and the generated values for those variables will be integer values of 0 and 1. For the numerical variables, however, by default, CTGAN generates data that is out of the range seen in training data. For example, labor hours are present in the training data with only integer values \u2265 0. But CTGAN also generated examples with negative values. We conducted multiple rounds of experiments where i) we allowed those negative values to be used for training the classifiers, or ii) we replaced any negative value with 0, as a negative value for a duration does not make sense. Allowing negative values in the generated data for training the models made the downstream task more accurate, as shown in Fig. 4a. This may be because labor starts before a mother comes to the hospital. We would like to emphasize that all the test set results reported in this paper were obtained by evaluating the models on real and unseen data."}, {"title": "4.2 Performance on the training and validation sets", "content": "When a model performs well on both the training and validation metrics, it indicates that it can learn representations and generalize which prepares it well for unseen data. In Fig. 5, we can see that our model achieves macro average F1 scores over 0.9 in most of the training and validation set experiments. This finding indicates that the model is not underfitting or overfitting.\nOne challenge of these experiments is that the training and validation sets have both real and synthetic data. So, if the synthetic data does not represent the distribution of the real data, the performance on the validation set may not equate to the performance on the test set. We therefore tested the results when all the examples were from real data in Fig. 5. We can see that the model achieved an accuracy of 0.789, a sensitivity of 0.632, and a macro average F1 score of 0.784 on a balanced test set of real data. One challenge of evaluating the method on the test set was the small data size. As we had only 112 abnormal class examples in the whole dataset and a large part of them were used in training and data generation, we had to exclude them from the test set. The test set had 38 examples: 19 normal and 19 abnormal. The confusion matrix of Fig. 5 shows that the model identified 12 of the 19 positive class examples, corresponding to a sensitivity of 0.632 while identifying 18 out of 19 negative class examples, corresponding to a specificity of 0.947."}, {"title": "4.3 Different backbones of AIMEN", "content": "Five different neural networks were tested as the backbone of the AIMEN system. The summary of their performance is presented in Table 2. Each backbone was trained and tested five times on different training and test sets and average"}, {"title": "4.4 Effect of decision threshold", "content": "The default decision threshold chosen throughout this paper is 0.5, meaning, the output probability of the classifier is \u2265 0.5, a case is classified as abnormal, otherwise, normal. In Table 2, we can see that the AIMEN v5 system has a sensitivity of 0.516 when the decision threshold is 0.5. To check how the system's performance changes with different decision thresholds, we plot the receiver operating characteristic (ROC) curve and the classification performance of the system in Fig. 6. From this figure, the physicians can decide which decision threshold is suitable for labeling an example as abnormal."}, {"title": "4.5 Evaluating the counterfactuals", "content": "We present two counterfactual examples produced by our methods in Fig. 7. The CEs are evaluated based on the average distance and the average sparsity in our experiments. The average distance is the average Euclidean distance between the normalized real example and the corresponding normalized counterfactual example pairs. The average sparsity is the average number of variables that need to be changed to flip the prediction from abnormal class to normal class. We present a summary of this evaluation in Table 3. The feature dimension of the dataset is 34. An average distance of 0.33 and an average sparsity of 2.50 means that with this method, on average, a CE is located 0.33 units away from a real example in the 34-dimensional hyperspace, and on average 2.5 out of the 34 attributes need to be changed for an abnormal class example to convert to a normal class example."}, {"title": "4.6 Restricted AIMEN (R-AIMEN)", "content": "The default AIMEN model uses CTGAN to generate synthetic data without any restriction. On the other hand, the restricted models require the synthetic data to satisfy the condition that the average silhouette score of the two clusters (positive and negative) must increase from the previous iteration or it has to be higher than 0.3. This restriction makes the data more easily separable. However, in Table 4, it can be seen that this restriction reduces the performance of the classifier based on the average F1 score. The reason may be that this restriction increases the distance between the distribution of the training data and the distribution of the test data because we are only using real data in the test set and this restriction may not follow the true behavior of the data. We developed another system where a requirement of silhouette score on the synthetic data for the negative class was applied but the positive class samples were generated"}, {"title": "4.7 Distribution gaps", "content": "Finally, we compared the validation and test losses to determine the distribution gap, defined as the relative difference between the average validation loss and the average test loss. In Table 5, it can be seen that the distribution gap is lowest in the unrestricted AIMEN. The minimum best validation loss or average validation loss is achieved when the silhouette score is applied to both classes. However, better validation loss does not necessarily translate to better test loss. Applying a silhouette score restriction makes the synthetic data more easily separable, hence the validation loss is lower. However, in this way, the model fails to learn some of the distinctive features of the data as the restricted synthetic data does not follow the true distribution of the data because the real data does not have to be easily separable in general. That is why, despite better validation metrics, R-AIMEN models could not achieve test metrics as good as AIMEN's. Hence, the distribution gap is lowest in the unrestricted AIMEN."}, {"title": "4.8 SHAP values for training and test datasets", "content": "To understand more about the AIMEN system's method of decision-making, we have plotted the SHAP (SHapley Additive explanations) values [24] on 1385 real training cases and 38 real test cases in Fig. 8. On this test set, the macro"}, {"title": "5 Limitations", "content": "It is very important to identify labor risks as early as possible to prevent or mitigate adverse labor outcomes. Our study makes novel and significant contributions toward this goal. We propose a method to train neural networks for classification problems with small datasets. However, it is difficult to properly evaluate the effect of an RF on an outcome without an RCT or an observational study with a large dataset. One challenge is that RCTs may not always be feasible or ethical in the setting of intrapartum care. Our study proposes to address this issue by providing CE for abnormal outcomes, which gives an idea of what factors would have to be different for a normal outcome. This study uses only one counterfactual generation method. The scope of the study for classifiers is limited to fully connected neural networks"}, {"title": "6 Conclusions and Future Work", "content": "Classification with tabular data is challenging, especially when the output classes are highly imbalanced. Our study explored different methods to predict the high risk of adverse labor outcomes and provide CE. We connected neonatal risk modeling, tabular data classification, and CE to address this important problem. Our work overcomes the challenges of limited and imbalanced data by employing generative models for data balancing and augmentation. It highlights the drawbacks of imposing restrictions on the generated data based on separability. Our experiments demonstrate that a systematically chosen neural network supported by an unrestricted CTGAN can outperform the models not supported by a CTGAN and those supported by a restricted CTGAN. Our method predicts the high risk of adverse labor outcomes with a positive class F1 score of 0.75 and an average F1 score of 0.784.\nIn the future, we plan to fine-tune the system for other adverse outcomes such as NICU admission and characteristics of the neonate shortly after birth. Moreover, integrating an option to choose from multiple counterfactual generation methods may better assist physicians by providing solutions from various sources. Neonatal health risk prediction with ML/AI is an understudied topic and we invite researchers to contribute to this important field."}]}