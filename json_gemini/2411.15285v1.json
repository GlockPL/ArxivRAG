{"title": "Forecasting Unseen Points of Interest Visits Using Context and Proximity Priors", "authors": ["Ziyao Li", "Shang-Ling Hsu", "Cyrus Shahabi"], "abstract": "Understanding human mobility behavior is crucial for numerous applications, including crowd management, location-based recommendations, and the estimation of pandemic spread. Machine learning models can predict the Points of Interest (POIs) that individuals are likely to visit in the future by analyzing their historical visit patterns. Previous studies address this problem by learning a POI classifier, where each class corresponds to a POI. However, this limits their applicability to predict a new POI that was not in the training data, such as the opening of new restaurants. To address this challenge, we propose a model designed to predict a new POI outside the training data as long as its context is aligned with the user's interests. Unlike existing approaches that directly predict specific POIs, our model first forecasts the semantic context of potential future POIs, then combines this with a proximity-based prior probability distribution to determine the exact POI. Experimental results on real-world visit data demonstrate that our model outperforms baseline methods that do not account for semantic contexts, achieving a 17% improvement in accuracy. Notably, as new POIs are introduced over time, our model remains robust, exhibiting a lower decline rate in prediction accuracy compared to existing methods.", "sections": [{"title": "I. INTRODUCTION", "content": "POI forecasting is important for understanding and predicting human mobility patterns, which is valuable across various industries and applications. By forecasting the next POI a person or group of people is likely to visit, businesses can make more informed decisions, improve services, and optimize resources. When used iteratively, the forecasting models can generate a synthetic sequence of visits. These models are critical to crowd management, location-based recommendations, pandemic spread estimation, and traffic flow prediction, to name just a few. Specifically, accurate predictions of future POIs can enhance personalized advertising for various venues. Unlike dense trajectory data collected passively from mobile phones or car GPS [1], [2], sequences of visits are typically used for POI forecasting, where each visit represents a user check-in at a specific POI, collected by some location-based social networks (LBSNs) such as Foursquare [3]. Many prior studies approach the task of next POI forecasting by training classifiers, exploring the impact of input features, model architectures, and training techniques on classification performance. More recent work leverages Transformer-based models as a powerful backbone to enhance the model's understanding of visit sequences [4]\u2013[7].\nHowever, due to the system's heavy reliance on known training (i.e., seen) data, its performance significantly deteriorates when a new POI emerges. For example, if a new boba shop opens, nearby users who enjoy boba tea may be inclined to visit. In such cases, the model should be able to predict the boba shop as a potential next POI. However, since the model has not been trained on data that includes the new POI, it lacks awareness of its existence. Consequently, the model cannot assign probabilities to these new POIs. Therefore, unless the most up-to-date data, including visits to new POIs, are continuously available and the model is regularly retrained, its ability to accurately forecast future locations will degrade rapidly. In practice, given the limited availability of real-world sequence-of-visit mobility data, these conditions are rarely met.\nTo overcome this limitation, we propose a novel approach for forecasting the next POI in a sequence of visits by leveraging both the semantic category and location of each POI. Our method follows a simple heuristic: when choosing the next POI, a user is likely to consider both the category and proximity of available POIs. For instance, at noon, the user is more likely to visit a restaurant than a mall, and they would probably prefer a nearby restaurant over a distant one. While we follow prior work in using a Transformer-based model [8] to encode the social and semantic contexts of a user's past visit sequences, instead of directly predicting the next POI\u2014which can lead to missing a new POI\u2014we design the training objective to classify POI semantic categories. We then aggregate the distribution of trip distances as proximity priors and combine both in a probabilistic framework to predict the next POI.\nTo evaluate the effectiveness of our proposed method, we simulate new POIs by (1) varying a temporal threshold in the POI dataset, (2) using that threshold to split the train/test sets, and (3) defining a POI as \u201cnew\u201d if it only appears after the threshold (i.e., it does not appear in the training set). Since our model incorporates both the semantic context and proximity information of POIs, it can predict a new POI during the inference phase, even if the POI was unseen during training. This refinement is particularly advantageous for location-based recommendation systems, where continuously updating human trajectory data and models may not be desirable. By enabling our model to recommend a user's next destination, a newly opened POI is not overlooked due to unfamiliarity, thereby better reflecting how humans make decisions.\nIn summary, the contributions of our work are threefold: (1) we introduce a novel method that combines semantic categories and proximity information to enhance prediction accuracy, (2) we develop a Transformer-based model capable of predicting previously unseen POIs, mitigating the decline in accuracy as more unseen POIs start to populate, and (3) our approach offers a practical solution for location-based recommendation systems by improving the model's ability to recommend newly opened POIs, even in the absence of continuously updated trajectory data. These advancements align the model's behavior more closely with human decision-making processes, offering significant potential for real-world applications."}, {"title": "II. RELATED WORK", "content": "Researchers have explored various strategies to address the challenge of human mobility modeling. Two popular human mobility modeling tasks are trajectory synthesis and next visit forecasting.\na) Trajectory Synthesis: The task of trajectory synthesis involves synthesize a human mobility trajectory, where each point contains a location and a timestamp, which can be as dense as one point per second. [9], [10] For example, MoveSim [9] proposes a framework that contains a urban structure modeling component in the generator for simulating the mobility behavior and mobility regularity-aware loss in the discriminator for distinguishing generated mobility trajectory from real mobility trajectories. Pretrained mobility strategies are also included to increase the accuracy of predictions. Long et al. [10] proposed a trajectory generation mechanism based on a variational autoencoder (VAE), namely VOLUNTEER, utilizing variational point processes to generate user trajectories. The model consists of two key components: the User VAE and the Trajectory VAE. The User VAE captures user-level features through a transformer and extracts relevant user attributes. Meanwhile, the Trajectory VAE generates a sequence of points representing location and time, learning the distribution parameters necessary for accurate trajectory prediction. It also accounts for time intervals by modeling dwell time (as a probability distribution) and travel time, while incorporating various travel modes. The model integrates classical temporal point processes with neural networks to enhance its predictive accuracy.\nb) Next Visit Forecasting: Another line of human mo-bility modeling research studies the next visit forecasting problem [5]\u2013[7], [11]\u2013[22]. We can roughly define the task of next visit forecasting as follows: Given a sequence of visits, where each visit is associated with a location and a time span, such as staying at an office from 9am to 5pm, forecast the next visit of the sequence. Some researchers in this field focuses on POI forecasting, which is a special case of this problem, as they only model visits that are associated with a POI. [5]\u2013[7], [12]\u2013[22]. A notable study is MobTCast [4], which identifies and integrates several types of contexts for POI prediction. They use a Transformer-based feature extractor to obtain the representations of semantic and social mobility features, of which the latter aggregates the visited POI history and semantic category information of other users. Then, they define two training objectives: one is POI location regression, and the other is POI classification. The former is an auxilarity task that is performed only during training. We adapt the visit sequence encoding part of MobTCast to convert the temporal, semantic, social, and spatial contexts in the input sequence of visits into a visit sequence representation.\nWhile prior studies excel in forecasting POIs that exist in the training data, because of the heavy reliance on exposure to POIs during the training phase, many of these methods struggle to accurately predict future visits for POIs unseen in training. To this end, instead of directly predicting the POI and spatial location, we first determine the semantic context and then probabilistically combine it with pre-computed proximity priors to predict the next POI. In this way, newly opened POIs can be predicted although it was previously unfamiliar to the model."}, {"title": "III. PROBLEM FORMULATION", "content": "First, we define a set of POIs P as\n$P := \\{(poi_k, lat_k, lon_k, cat_k) | k \\in \\{1, ...,C_p\\}\\}$ (1)\nwhere $poi_k$ is the ID of the POI, $lat_k$ is the latitude of the POI, $lon_k$ is the longitude of the POI, $cat_k$ is the category code of the POI, and $C_p$ is the total number of POIs.\nThen, define the sequence of POI visits made by user i as:\n$v_i := \\{(user_i, time_j, poi_j) | j \\in \\{1,...,n_i\\}\\}$ (2)\nwhere $user_i$ is the user ID, $time_j$ is the check-in timestamp of the visit, $n_i$ is the total number of visits by user i. Building upon $v_i$, we define an m-user sequence-of-visit dataset V as:\n$V := \\{v_i | i \\in \\{1,...,m\\}\\}$ (3)\nLastly, we define the task of next POI forecasting as follows:\nGiven a set of visits V and a set of POIs P, predict the POI code of the next visit by each user:\n$V^* := \\{(user_i, poi_{n_i+1}) | i = 1, ..., m\\}$ (4)"}, {"title": "IV. BACKGROUND", "content": "In a next POI forecasting task, the solution is typically designed as a POI classifier, which is trained using cross-entropy loss. Cross entropy loss is designed to minimize the discrepancy between the predicted probability distribution and the true distribution of the target classes (POIs)."}, {"title": "V. METHOD", "content": "The overall framework of the proposed method is illustrated in Fig. 1, which consists of three parts: (i) Joint Probability Approximation (Section V-A): the semantic context probabil-ity and the proximity prior probability are combined to predict the next POI. (ii) Semantic Context Prediction (Section V-B): this is used to generate a probability vector of possible POI categories. (iii) Proximity Prior Computation (Section V-C): our approximated prior distribution of the distance between the locations of two consecutive visits. We present each of the above in detail in the following subsections.\nA. Joint Probability Approximation\nTo predict the next POI without training a POI classifier, we approximate the POI distribution with (1) the distribution of the next POI categories and (2) the distribution of the distance from the current POI to the next POI.\nFor simplicity, we first define a binary operator $\\stackrel{i}{=}$ that takes two POIs a, b within the Region of Interest (ROI) as input, and outputs whether their distances to the j-th location of user i (i.e. the location of the j-th visit $poi_j$) are similar:\n$[a \\stackrel{i}{=} b] := [distance (a, poi_j) \\approx distance (b, poi_j)]$ (8)\nwhere distance (a, b) denotes the distance between location a and location b.\nThen, we make a conditional independence assumption between (1) the distribution of the category of the next POI and (2) that of its distance to the user's last location:\n$Pr [poi_{n_i+1} = poi_k | v_i]$\n$\\sim Pr [(cat_{n_i+1} = cat_k) \\land (poi_{n_i+1} \\stackrel{i}{=} poi_k) | V_i ]$ (9)\n$\\sim Pr [cat_{n_i+1} = cat_k | V_i] Pr [poi_{n_i+1} \\stackrel{i}{=} poi_k | V_i]$ (10)\nwhere Pr[ ] denotes a probability function.\nWe approximate each of the two terms in (10) independently in the following subsections. As shown in the same equation, we then arithmetically combine both terms to predict the distribution of the next POI.\nB. Semantic Context Prediction\nTo model the distribution of the categories (semantic con-text) of the next POI visit $Pr [cat_{n_i+1} = cat_k | V_i]$, which is the first term in (10), we first extract complex social and semantic mobility features of $v_i$, the input visit sequence of user i, and transform them into a vector representation of the sequence of visits. Then, we design a semantic context classification objective, predicting the semantic context with a multilayer perceptron (MLP). The parameters of the visit sequence encoder and the semantic context classifier are learned in an end-to-end fashion.\n1) Visit Sequence Encoder: To encode the sequence of vis-its, we adopted MobTCast's semantic-aware mobility feature extractor, which processes three inputs: the POI itself, the timestamp, and the POI's semantic category, and produces a vector representation. We summarize sequence encoding procedure in the following.\nOverall, the user's history trajectory is modeled by a mo-bility feature extraction process that incorporates not only the visited POIs and timestamps, but the semantic context of the POIs. The key idea is that the semantic similarity between different POIs provides valuable insight for predicting future visits, especially in a dynamic context. For example, one who usually visits a restaurant on Friday evenings might be interested in visiting a newly-opened restaurant on a future Friday evening. Although those restaurants are different POIs, their semantic context can all be labeled as Food.\nFirst, we encode the sequence of visits of a user into a vector representation. The inputs are embedded into embeddings (POI, category, and temporal embeddings), which are then concatenated. A Transformer Encoder is then employed to encode the user's sequence-of-visit history by transforming the concatenated embeddings into one vector representation. The self-attention mechanism in the Transformer allows the model to capture dependencies across the entire sequence of visits, and by design, its positional encoding allows itself to capture the temporal order of visits.\nThen, we leverage enhance a visit sequence representations with that of the users having similar visit patterns. To find what users exhibit similar patterns of visits, we construct a co-location matrix and leverage cosine similarity. The co-location matrix is constructed as a user-POI frequency matrix of shape m \u00d7 Cp, where the entry at [i,j], i \u2208 {1,...,m}, j\u2208{1,...,Cp} contains the number visits user i pays to POI j. We take each row of this matrix as one user vector, and use the cosine similarity of pairs of user vectors to determine their visit-pattern similarity. To one user, we define the set of other users with high visit-pattern similarity as their \u201cneighbors.\u201d\nIn the social context extraction process, we first embed the visit sequence of a user and that of their neighbors. Then, we use a multi-head self-attention mechanism to weigh and fuse the visit representations of their neighbors, producing $f_i$, the social-context-enhanced sequence-of-visit representation of user i.\n2) Semantic Context Classification: Given the context-aware feature $f_i$, we forecast the POI semantic context of user i at the next time step $n_i + 1$ by predicting the probability distribution of the category of the next POI:\n$Pr [cat_{n_i+1} | V_i] := softmax(MLP(f_i))$ (11)\nwhere Pr denotes the predicted probability distribution.\nWe treat the next semantic context prediction as a classifi-cation over all semantic contexts, so we use multi-class cross entropy loss to obtain the prediction loss for semantic contexts:\n$L := - \\sum_{s=1}^{C_s}y_s log(Pr [cat_{n_i+1} = cat_s | v_i])$ (12)\nwhere $C_s$ denotes the number of distinct semantic contexts (POI categories), $y_s$ represents the ground truth (0 or 1) that the user i will visit the POI with the s-th semantic context $cat_s$ next.\nC. Proximity Prior Computation\nIn this section, we model how far away the next visit will be from the current one, or the proximity distribution. It is the second term of (10). First, we approximate that conditional probability with its unconditional counterpart.\n$Pr [poi_{n_i+1} \\stackrel{i}{=} poi_k | V_i] \\approx Pr [poi_{n_i+1} \\stackrel{i}{=} poi_k]$ (13)\nTo approximate the latter part of (13), we assume that regardless of the user and the POIs, the distance between two consecutive POI visits made by a user roughly follows a certain probability distribution, named proximity prior distribution P:\ndistance (poi, $poi_{j+1}$) \u223c P \u2200 i, j (14)\nTo approximate the continuous proximity prior distribution P, we produce a discrete probability distribution by grouping the distances consecutive POI visits into counting buckets and normalize the counts to prior probabilities. Finally, we obtain $Pr [poi_{n_i+1} \\stackrel{i}{=} poi_k] = poi_k$ by combining the approximated proximity prior distribution P, the input visit sequence of the i-th user $v_i$, and the candidate POI $poi_k$."}, {"title": "VI. EXPERIMENTS", "content": "A. Experimental Setup\nTo evaluate the effectiveness of a POI forecasting model, we follow prior studies to use top-k accuracy, which measure the proportion of ground truth labels appearing in the k classes with the highest probabilities assigned by the method. We denote a top-k accuracy as Acc@k, where k \u2208 {1,5,10,20}.\nTo examine the effect of the ratios between seen and unseen POIs during inference time, we vary them by finding a temporal threshold, all visits before this point were included in the training set. The remaining visits were evenly and randomly split between testing and validation set. POIs that appeared only after the train-test split are considered \u201cunseen\u201d and are used to evaluate the ability of an approach to predict new POIs. We illustrate this setup in Fig. 3.\nIn our experiments, we used the publicly available, de-identified Foursquare-NYC dataset (FS-NYC) [24], which contains 227,428 POI visits in New York city from April 2012 to February 2013.\nAs for the implementation, we set the length of the obser-vation window to 20, the hidden dimension of Transformer to 128, and the embedding dimensions for POI, semantic, and temporal embeddings to 80, 24, and 24, respectively. We implement our model in PyTorch and train it with an AMD EPYC 7V13 64-core CPU and an NVIDIA A100 80GB GPU.\nB. Results and Discussion\nTable I shows our accuracy in comparison with that of our baseline, MobTCast, when roughly 80% of POIs are unseen to the models during inference time. Notably, our proposed model achieved 17% higher top-20 accuracy when evaluating with the set of unseen POIs. Moreover, even if we evaluate both models with all POIs, our method achieves higher accuracy. This might suggest that our method is more capable of forecasting in a less familiar environment than our baseline.\nWe further test the accuracy of different approaches as there are different an increasing number of unseen POIs relative to the total POIs. This simulates an environment with a number of emerging new POIs. As time passes and more unseen POIS has opened, our approach stays more robust compared to our baseline, as demonstrated in Fig. 4. In fact, regressing these accuracy lines to their line of best fit, the average decrease in slope in 635.417%. Therefore, our model outperforms tremendously in maintaining accuracy over time as the more unseen POIs appear.\nC. Limitations and Future Work\nThe scope of this study is to remain robust with increas-ing proportion of unseen POIs, which is orthogonal to the studies on the accuracy improvement for those seen POIs. We encourage future researchers to explore mechanisms that combines (1) our approach for unseen POIs and (2) another for seen POI, such as MobTCast, to improve the general accuracy for any datasets. For example, one can create a classifier that can dynamically identify whether the next POI will be a seen or unseen one, which could potentially lead to a more comprehensive model for better performance in wider real-world applications."}, {"title": "VII. CONCLUSION", "content": "Our model, which integrates semantic context prediction and proximity priors, addresses the shortcomings of state-of-the-art models for predicting new POIs unseen during training. By combining the semantic context prediction with spatial proximity prediction using a pre-computed proximity priors, our model demonstrates a higher degree of flexibility and adaptability in scenarios where POIs are evolving.\nOur results indicate that this approach outperforms the baseline by 17% in top-20 accuracy when predicting unseen POIs, a critical improvement for real-world applications that has a ever-changing urban landscape. Moreover, our model's accuracy degradation over time, as more unseen POIs are introduced, occurs at a much slower rate compared to existing models. This highlights our model's ability to generalize in the absense of continuously updated trajectory data, making it par-ticularly useful for location-based recommendation systems, as well as as other mobility trajectory prediction applications."}]}