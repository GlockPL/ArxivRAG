{"title": "Revisiting the Graph Reasoning Ability of Large Language Models:\nCase Studies in Translation, Connectivity and Shortest Path", "authors": ["Xinnan Dai", "Qihao Wen", "Yifei Shen", "Hongzhi Wen", "Dongsheng Li", "Jiliang Tang", "Caihua Shan"], "abstract": "Large Language Models (LLMs) have achieved\ngreat success in various reasoning tasks. In this\nwork, we focus on the graph reasoning ability\nof LLMs. Although theoretical studies proved\nthat LLMs are capable of handling graph rea-\nsoning tasks, empirical evaluations reveal nu-\nmerous failures. To deepen our understanding\non this discrepancy, we revisit the ability of\nLLMs on three fundamental graph tasks: graph\ndescription translation, graph connectivity, and\nthe shortest-path problem. Our findings sug-\ngest that LLMs can fail to understand graph\nstructures through text descriptions and exhibit\nvarying performance for all these three funda-\nmental tasks. Meanwhile, we perform a real-\nworld investigation on knowledge graphs and\nmake consistent observations with our findings.\nThe codes and datasets are available.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) have shown re-\nmarkable achievements in a multitude of reasoning\ntasks, ranging from mathematical, commonsense\nand symbolic problem-solving (Luo et al., 2023;\nCreswell et al., 2023), to more specialized applica-\ntions like dialogue systems (Ouyang et al., 2022),\nprogram debugging (Surameery and Shakor, 2023)\nand scientific discovery (Boiko et al., 2023). In\nthis work, we focus on graph reasoning capability,\nwhere LLMs employ an explicit graph, sourced\neither from the input data or external resources, to\ninfer the outcome. This reasoning ability is cru-\ncial and can be applied across various domains,\nsuch as improving question-answering system by\na domain-specific knowledge graph (Huang et al.,\n2022), facilitating planning in autonomous agents\nthrough the tool relation graph (Liu et al., 2024),\nand enhancing robot navigation via physical maps\n(Creswell et al., 2022).\nThere are recent studies initially exploring the\nLLM's graph reasoning capability. On the one\nhand, the theoretical work (Feng et al., 2024)\nproved that LLMs have the ability to mimic a pow-\nerful decision-making framework (i.e., dynamic\nprogramming), to solve the complex tasks. This\nsuggests that LLMs are capable of handling certain\ngraph reasoning tasks that can be formulated as\ndecision-making problems, including breadth-first\nsearch for graph connectivity, and the Dijkstra for\nshortest path problem. On the other hand, recent\nempirical studies, such as GPT4Graph (Guo et al.,\n2023) and NLGraph (Wang et al., 2024), found\nthat LLMs could fail in these graph tasks. This\ndiscrepancy between theoretical expectations and\npractical observations indicates a critical gap in our\ncomprehension of LLMs' graph reasoning abili-"}, {"title": "Related work and Background", "content": "Recent efforts have been made on graph reason-\ning evaluations (Guo et al., 2023; Fatemi et al.,\n2023; McLeish et al., 2024). NLGraph (Wang et al.,\n2024) evaluates LLMs across the 8 fundamental\ngraph reasoning tasks, suggesting that LLMs have\npreliminary graph reasoning abilities. GraphIn-\nstruct (Luo et al., 2024) extends the graph reason-\ning benchmark to 21 classical graph tasks and in-\ntroduces a step masking method to enhance the\ngraph reasoning abilities of LLMs. Additionally,\nVisionGraph (Li et al., 2024) provides a multimodal\nversion of the graph reasoning task benchmark, ex-"}, {"title": "Graph connectivity in theory", "content": "LLMs, through their transformer architecture, have\ndemonstrated essential capabilities for reasoning\ntasks (Giannou et al., 2023; Yang et al., 2023; San-\nford et al., 2024b). Specifically, for the graph rea-\nsoning tasks, de Luca and Fountoulakis (2024) sug-\ngest that looped transformers are able to simulate\nevery step in a graph algorithm. Sanford et al.\n(2024a) reveal that a single-layer transformer is\nsufficient for a naive graph connectivity task."}, {"title": "LLMs for graphs in the applications", "content": "Despite LLMs having capabilities in graph reason-\ning tasks in theory, there remains a gap between\ntext understanding and graph reasoning (Chai et al.,\n2023; Zhao et al., 2023). Therefore, some recent\nwork approves the use of additional tools to help\nLLMs understand graphs. Recent studies have vali-\ndated the use of extra tools to enhance LLMs' com-\nprehension of graphs. GraphEmb (Perozzi et al.,\n2024) employs an encoding function to augment\nprompts with explicit structured information. Ad-\nditionally, GraphWiz (Chen et al., 2024) fine-tunes\nLLMs using graph reasoning datasets to achieve\nhigher performance in graph tasks. However, when\nLLMs are pretrained using text data, their limita-\ntions in graph reasoning tasks remain unclear. In\nthis work, we do a comprehensive study on the fail-\nures of LLMs in graph reasoning tasks. We summa-\nrize and analyze the potential reasons why LLMs\nfail in graph reasoning only using text prompts."}, {"title": "Theoretical support for graph reasoning\ntasks", "content": "Feng et al. (2024) prove that if a task can be decon-\nstructed into subtasks, it can be solved by LLMs.\nBased on this, Wu et al. (2024) offer insights into\ntransforming message-passing processes among\ngraphs into subtasks of message-passing among\nnodes using transition functions, suggesting that\nLLMs are capable of handling graph decision tasks.\nSpecifically, it can be theoretically proven that\ngraph connectivity and shortest-path tasks are two\nexamples of problems solvable by LLMs.\nSuppose that the structure of a graph can be\nrepresented as $G = (X,E,E)$, where X is the\nset of nodes, E is the edge set, and $E$ is the fea-\nture set of the edges. For the graph connectiv-\nity task, we start from node $n_i$ and end at node\n$n_j$. The transition function $F(i, j)$ for the graph"}, {"title": "Limitations of LLMs in graph\nreasoning", "content": "In this section, we empirically revisit the graph\nreasoning ability via case studies. In particular,\nwe introduce three fundamental graph tasks: graph\ndescription translations in Section 3.1, graph con-\nnectivity in Section 3.2, and the shortest path task\nin Section 3.3. Finally, we summarize and analyze\nour findings in Section 3.4."}, {"title": "Graph description translation", "content": "To begin with, we first describe the graph proper-\nties denoted as: G describes a [properties] graph\namong x \u2208 X, where [properties] define the graph\ntypes, such as undirected, directed, or knowledge\ngraphs. Then, we use different graph descriptions\nto introduce their structures.\nWe summarize three types of graph structure de-\nscription methods that have been widely used by\nthe previous works (Fatemi et al., 2023; McLeish\net al., 2024) as shown in Figure 2. They are (1) Ad-\njacency Matrix: describing the adjacency matrix of\na graph; (2) Node List: referring to the neighbors\nof a central node on a graph, and (3) Edges List:\nlisting every edge of a graph. Adjacency Matrix\nis denoted as $A \u2208 R^{N\u00d7N}$, where N is the num-\nber of nodes. In the text description, it encodes a\nparagraph by N \u00d7 N binary tokens.\nNode List uses the neighbors of a central node to\ndescribe a graph. For instance, consider the set of\nsentences $S_N = {s_1,s_2,...,s_N}$, which describes\nthe graph via the neighbors [u] of node $v_i$ with the\nedge feature \u20ac. A single sentence is as follows:\n$s_i$ = Node $v_i$ [relation] Nodes {[$u$, \u20ac]$u\u2208N_{v_i},EEE(v_i,u)$}.\nNote that the [relation] varies across different types\nof graphs. In undirected graphs, we use the rela-\ntion \"is connected to,\" whereas in directed graphs,"}, {"title": "Translations on graph descriptions", "content": "If LLMs can comprehend the structures of a graph,\nsuch understanding should be independent of the\nmethods used to describe the graph. Therefore, to\nverify the ability of LLMs to understand the struc-\ntural information of a graph, we design a graph\ntranslation description task. This task requires\nLLMs to use the input graph description to generate\nvarious descriptions. After that, we will compare\nthese descriptions to determine if they represent the\nsame graph structure.\nNote that the number of tokens in the Adjacency\nMatrix depends on the number of nodes. This sug-\ngests that the Adjacency Matrix may require more\ntokens in dense graphs than Node or Edge Descrip-\ntions, limiting its applicability in the real world\nwhen the graph size is large. Therefore, we only\napply the Adjacency Matrix as the target format\nin the graph description translation task while em-\nploying Node List and Edge List as both source and\ntarget descriptions. It is the same reason that we\nuse Node List and Edge List for graph connectivity"}, {"title": "Revisit graph connectivity task", "content": "Previous studies suggest that large language mod-\nels (LLMs) possess essential capabilities for graph\nconnectivity tasks (Wang et al., 2024; Luo et al.,\n2024), yet they still fail in some instances. To\nfurther investigate the graph connectivity task, we\nbegin by analyzing the samples where failures oc-"}, {"title": "Evaluation Metrics", "content": "Instead of only evaluating the accuracy of graph\nconnectivity, we also want to check if the reasoning\npath to make the prediction can support the predic-\ntion. Thus, the prompt is defined as follows: \"If a\npath exists, present the path formatted as 'Node #1\n-> Node #2.'; If no path is found, state 'No path.'.\nTherefore, to evaluate the reliability of such paths,\nwe design two novel metrics, FidelityAcc (Facc)\nand Path Consistency Ratio (PCR), which are used\nto analyze the correctness of reasoning paths. Facc\nevaluates whether the reasoning path to infer the an-"}, {"title": "Results", "content": "We select tree representative large language mod-\nels, GPT-3 (GPT-3.5-turbo-0301), GPT-4 (GPT-4-\n0125-preview) and LLAMA 3 (LLAMA3.0-70B)\nwith the temperature equal to 0.\nUndirected Graph Results We start with the\nundirected graph datasets and show the results in\nTable 2. First of all, GPT-4 has better reasoning\nability compared with GPT-3 and LLAMA 3 across\nall cases, regardless of the graph difficulty, graph\ndescription or the categories of connectivity.\nSecondly, we have following observations by\ncomparing different connectivity situations: (1)\nThe difficulty of reasoning increases as the path"}, {"title": "The shortest-path problem", "content": "The shortest-path problem is another essential task\ntheoretically proven to be achievable by LLMs, yet\nit fails in practice. Compared to the graph con-\nnectivity task, it is more challenging because it\nrequires not only determining whether nodes are\nconnected but also calculating edge weights to iden-\ntify the shortest path among multiple potential so-\nlutions. Next, we explore if the varied performance\nof LLMs across different connectivity types is also\napplicable to the shortest-path problem.\nExperimental setup We study the shortest-path\nproblem using the Easy datasets from the un-\nweighted graphs as mentioned in Section 3.2. For\nthe weighted graphs, we applied similar strategies\nthat were used in undirected graph generations to\ngenerate the directed and undirected graph datasets.\nThe directed graph datasets include two types,\nwhether there are negative edges in the graphs. Ap-\npendix C.1 Table 13 shows the details. The graph\nstructure descriptions are shown in Appendix A\nResults We use GPT-4 to illustrate an example\nof the shortest-path problem. Table 4 displays the\nresults of LLMs' performance. The findings for"}, {"title": "Analysis of other factors", "content": "In-context learning approaches, including Chain-of-\nThought (CoT) (Wei et al., 2022) and zero-Chain-\nof-Thought (0-CoT) (Kojima et al., 2022), have\nbeen widely utilized in LLMs to enhance their\nreasoning capabilities. Meanwhile, specifically in\ngraph-related tasks, previous works combined the\nprompts with the graph algorithms. However, they\ndo not demonstrate consistent improvement (Wang\net al., 2024). In this subsection, we revisit these\napproaches in detail.\nWe consider several graph algorithms in the ex-\nperiments. For the graph connectivity task, we\nfocus on the Breadth-First Search (BFS) and we\nemploy the Dijkstra algorithms to soleve the short-\nest path problem. We utilize Node descriptions\nto search the connectivity and shortest pathes in\nEasy setting by GPT-4. The prompts examples are\nshown in Appendix B. The results are detailed in\nTable 5.\nThe observations can be summarized as follows:\n(1) In the connectivity task, few-shot examples help\nLLMs recognize isolated components. This is be-\ncause few-shot examples enable the LLMs to cor-\nrectly output 'No connection' when they do not\nfind a connected path. (2) In the shortest path cases,\nfew-shot examples do not consistently lead to bet-\nter performance. However, performance improves\nwhen the Dijkstra-CoT method is applied. This\nsuggests that while LLMs may use multiple strate-\ngies to make decisions, but a specific algorithm can\nguide them toward a unique solution."}, {"title": "The influence of node names", "content": "Fatemi et al. (2023) suggest that different naming\nmethods for graphs can yield varied results. This\nvariation is attributed to the graph node IDs oc-\ncupying the same space as the pre-trained data of\nLLMs. Thus, we further evaluated the impact of\nnaming conventions on nodes for the connectivity\ntask. Table 6 summarizes the results for GPT-4"}, {"title": "A case study on knowledge graphs", "content": "To determine if our findings from previous sections\nare applicable to real-world graphs, we conducted\nthe entity connections on knowledge graphs.\nDataset We used WN18RR (Shang et al., 2019)\nas the base dataset, which provides both ID names\nand Entity names. The ID names consist of strings\nof random numbers, and Entity names are used\nas specific and meaningful identifiers. From its\ntraining set, we randomly selected 150 subgraphs\nbased on ego graphs with a depth of 3. Within\neach subgraph, we identified two nodes with the\nlongest paths and segmented the paths into k'-hops.\nThis strategy allowed us to generate k' question-\nanswer pairs, ranging from 1-hop to k'-hop. Ta-\nble 12 shows the details of our sampled dataset.\nWe take both Node List and Edge List in the exper-"}, {"title": "Conclusion", "content": "We focus on the graph reasoning ability of LLMs\nin this paper. Recently, there exists a discrepancy\nbetween theoretical understanding and empirical\nexperiments, where LLMs can handle complex\ndecision-making tasks in theory, yet empirical find-\nings often show poor performance. To bridge this\ngap, we have revisited fundamental graph-related\ntasks, including translation, graph connectivity and\nshortest path tasks. We construct a balanced and\ncomprehensive dataset to involve various situations\nand obtain extensive observations. Our results\nshow the failure cases of LLMs and reveal that\nLLMs may utilize different algorithms to solve the\ncomplex graph-related task, depending on the input"}, {"title": "K-hops influence on the connectivity\ntask", "content": "In Section 3.2, we have demonstrated that perfor-\nmance in the graph connectivity task is closely re-\nlated to the number of nodes and k-hops in a graph.\nHowever, it is important to note that smaller graphs\ninherently support shorter paths. To fairly assess\nthe impact of k-hops on different graph sizes, we\nfurther evaluate the relations between k-hop and\ngraph density.\nWe create a subset with 100 undirected graphs\nwhere the graph node number is 16 - 36 and the\ndensity is in the range of (0.2,0.4) and evaluate\nthem by Node and Edge List descriptions. The\nresults are shown in Figure 4.\nThe results indicate that 1-hop cases maintain\na very high accuracy regardless of graph density,\nwhile 2-hop and 3-hop cases show a slight accu-\nracy decrease. In contrast, 4-hop and 5-hop cases\nexhibit high accuracy only in sparse graphs but sig-\nnificantly decline when graph density approaches\n0.38. This suggests that LLMs become confused\nas the graph complexity increases.\nComparing the Node List and Edge List descrip-\ntions, it is observed that the Node List exhibits a\nsmaller reduction in performance compared to the\nEdge List. This suggests that the Node List may be\nmore effective in describing complex graphs."}, {"title": "Failed cases", "content": "In this section, we will list some failed cases. We\nmark the added edges in Red and ignored edges in\nGreen."}, {"title": "Translation for Edge List to Node List", "content": "Question: Your task is giving the neighbors of\neach node.G describes an undirected graph among\nnode 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, and 12.\nNode 0 is connected to Node 1. Node 0 is con-\nnected to Node 5. Node 0 is connected to Node 9.\nNode 0 is connected to Node 12. Node 0 is con-\nnected to Node 3. Node 0 is connected to Node\n10. Node 0 is connected to Node 8. Node 0 is\nconnected to Node 11. Node 0 is connected to\nNode 7.\nNode 1 is connected to Node 2. Node 1 is con-\nnected to Node 4. Node 1 is connected to Node\n3. Node 1 is connected to Node 12. Node 1 is\nconnected to Node 9. Node 1 is connected to\nNode 11. Node 1 is connected to Node 10. Node\n1 is connected to Node 5. Node 1 is connected to\nNode 6.\nNode 2 is connected to Node 3. Node 2 is con-\nnected to Node 4. Node 2 is connected to Node 6.\nNode 2 is connected to Node 10. Node 2 is con-\nnected to Node 9. Node 2 is connected to Node\n12. Node 2 is connected to Node 7. Node 2 is\nconnected to Node 11.\nNode 3 is connected to Node 4. Node 3 is con-\nnected to Node 11. Node 3 is connected to Node\n5. Node 3 is connected to Node 10. Node 3 is\nconnected to Node 12. Node 3 is connected to\nNode 8.\nNode 4 is connected to Node 5. Node 4 is con-\nnected to Node 9. Node 4 is connected to Node 8.\nNode 4 is connected to Node 10. Node 4 is con-\nnected to Node 6. Node 4 is connected to Node\n11. Node 4 is connected to Node 7.\nNode 5 is connected to Node 6. Node 5 is con-\nnected to Node 9. Node 5 is connected to Node\n10. Node 5 is connected to Node 7. Node 5 is\nconnected to Node 8.\nNode 6 is connected to Node 7. Node 6 is con-\nnected to Node 9. Node 6 is connected to Node\n12. Node 6 is connected to Node 8.\nNode 7 is connected to Node 8. Node 7 is con-\nnected to Node 10. Node 7 is connected to Node\n9. Node 7 is connected to Node 12.\nNode 8 is connected to Node 9. Node 8 is con-\nnected to Node 12. Node 8 is connected to Node\n10. Node 8 is connected to Node 11.\nNode 9 is connected to Node 10. Node 9 is con-\nnected to Node 11. Node 9 is connected to Node\n12.\nNode 10 is connected to Node 11. Node 10 is\nconnected to Node 12. Node 11 is connected to\nNode 12. For each node, the neighboring nodes\nare listed as follows: \"Node #1: [] Node #2: []\"\nAnswer: Given the connections in the undirected\ngraph, the neighbors of each node can be summa-\nrized as follows:\n- Node 0: [1, 5, 9, 12, 3, 10, 8, 11, 7] - Node 1: [0,\n2, 4, 3, 12, 9, 11, 10, 5, 6] - Node 2: [1, 3, 4, 6,\n10, 9, 12, 7, 11] - Node 3: [0, 1, 2, 4, 11, 5, 10, 12,\n8] - Node 4: [1, 2, 3, 5, 9, 8, 10, 6, 11, 7] - Node\n5: [0, 1, 3, 4, 6, 9, 10, 7, 8] - Node 6: [1, 2, 4, 5,\n7, 9, 12, 8] - Node 7: [0, 2, 4, 5, 6, 8, 10, 9, 12] -\nNode 8: [0, 3, 4, 5, 6, 7, 9, 12, 10, 11] - Node 9:\n[0, 1, 2, 4, 5, 6, 7, 8, 10, 11, 12] - Node 10: [0, 1,\n2, 3, 4, 5, 7, 8, 9, 11, 12] - Node 11: [0, 1, 2, 3, 4,\n8, 9, 10, 12] - Node 12: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n10, 11]"}, {"title": "Translation for Node List to Edge List", "content": "Question: Your task is to identify all the edges\nin a graph and represent them in sparse form.G\ndescribes an undirected graph among 0, 1, 2, 3, 4,\n5, 6, 7, 8, 9, 10, 11, 12, and 13. In this graph:\nNode 0 is connected to nodes 1, 11, 2.\nNode 1 is connected to nodes 0, 2, 3, 4, 9, 11, 7.\nNode 2 is connected to nodes 0, 1, 3, 9, 8, 10.\nNode 3 is connected to nodes 1, 2, 4, 8, 6, 13, 12.\nNode 4 is connected to nodes 1, 3, 5, 10, 9.\nNode 5 is connected to nodes 4, 6, 9, 7.\nNode 6 is connected to nodes 3, 5, 7.\nNode 7 is connected to nodes 1, 5, 6, 8, 12, 9, 11.\nNode 8 is connected to nodes 2, 3, 7, 9, 12, 10."}]}