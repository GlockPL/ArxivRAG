{"title": "FedMSE: Semi-supervised federated learning approach for IoT network intrusion detection", "authors": ["Van Tuan Nguyen", "Razvan Beuran"], "abstract": "This paper proposes a novel federated learning approach for improving IoT network intrusion detection. The rise of IoT has expanded the cyber attack surface, making traditional centralized machine learning methods insufficient due to concerns about data availability, computational resources, transfer costs, and especially privacy preservation. A semi-supervised federated learning model was developed to overcome these issues, combining the Shrink Autoencoder and Centroid one-class classifier (SAE-CEN). This approach enhances the performance of intrusion detection by effectively representing normal network data and accurately identifying anomalies in the decentralized strategy. Additionally, a mean square error-based aggregation algorithm (MSEAvg) was introduced to improve global model performance by prioritizing more accurate local models. The results obtained in our experimental setup, which uses various settings relying on the N-BaIoT dataset and Dirichlet distribution, demonstrate significant improvements in real-world heterogeneous IoT networks in detection accuracy from 93.98\u00b12.90 to 97.30\u00b10.49, reduced learning costs when requiring only 50% of gateways participating in the training process, and robustness in large-scale networks.", "sections": [{"title": "1. Introduction", "content": "The Internet of Things (IoT) has emerged as a trendy technology due to its enormous potential in a variety of industries, including transportation (Derawi et al., 2020), healthcare (Rejeb et al., 2023), and smart cities (Yadav and Vishwakarma, 2018). IoT is the interconnected network of numerous physical objects, often known as things (Sharma et al., 2023). IoT systems are increasing dramatically with new, sophisticated, and modern devices being produced every day. The data generated by an enormous number of interconnected devices is heterogeneous, diverse, and complex. This increases the cyber attack surface affected by several novel IoT anomalies (Vu et al., 2022), such as botnet, DoS, DDoS, and Spoofing. Thus, IoT intrusion detection is a very essential task in new-fashioned IoT networks.\nTo secure system networks and privacy in deployment against cyber risks, an intrusion detection system (IDS) by analyzing and monitoring network traffic is one of the most efficient solutions (Sharma et al., 2023; Idrissi et al., 2023), these approaches are also known as anomaly detection sys-tems in some research. Modern IDSs that leverage machine learning (ML) techniques to detect unseen threats in IoT networks have been studied and adopted widely (Sharma et al., 2023; Vu et al., 2022; Wang et al., 2023). In addition to developing effective data learning models, it is also very im-portant to choose and define learning and deployment strate-gies to face new challenges when IoT networks continuously scale up. Traditional ML methods work in a centralized paradigm, in which one model is trained on a single server using all data collected from connected agents (Guendouzi et al., 2023). In the modern IoT context, this approach depicts some challenges such as computational resource require-ments for training and serving models; data latency when the data transmission distance may be hundreds, even thousands of miles from the server; data transfer cost; particularly data privacy preservation issues due to data leakage when sharing data among agents and server (Abdulrahman et al., 2021). Therefore, Federated Learning (FL) has emerged recently as a cutting-edge approach to solving these problems. Rather than collecting data, training, and serving ML models in a single high-performance computer, FL takes advantage of the computing capabilities of the network client in the distributed mechanism to train the local model itself and protect the local data from being accessed directly from outside (Abdulrahman et al., 2021). Then, the local models will be aggregated to a global model in the server for serving by some methodologies.\nIn recent years, many approaches have been released to take advantage of the power of FL to solve network anomaly detection (Nguyen et al., 2019; Idrissi et al., 2023; Mothukuri et al., 2022; Zhang et al., 2023). However, several issues have been making this task challenging, such as the traffic collected from large-scale IoT networks with different application scenarios is unbalanced and does not have suf-ficient abnormal data for the training process; IoT network is scalable, the kind of IoT devices is very diverse, and gen-erated data is heterogeneous; the aggregation method of the global model is still not optimal for getting a robust model to detect novel attacks effectively and perform efficiently with resource-constrained IoT devices.\nTo tackle these limitations, in this article, we aim to propose FedMSE, a collaborative IoT network intrusion de-tection approach leveraging the Autoencoder-based feature representation method, Mean Squared Error, and FL. The source code was published on Github 1 together with the dataset prepared for this paper. FedMSE enables the strength of identifying unknown cyber threats of semi-supervised learning techniques, and the secure learning process of FL. Each IoT gateway independently trains an intrusion detec-tion model on its locally processed network data without sharing the data with a central server. We use a hybrid approach, constructed by Shrink Autoencoder (SAE) as a feature representation method and Centroid (CEN) as a one-class classifier (Cao et al., 2019), to improve the perfor-mance of intrusion detection in local gateways. Then, we develop a novel federated aggregation algorithm based on Mean Squared Error to enhance the accuracy, efficiency, and robustness of decentralized learning. This new method considers the contribution of local models in the training process and prioritizes more accurate models. The exper-imental evaluation demonstrates the enhancement in IoT network intrusion detection of our proposed approach.\nThe major contributions of this article are the following:\n1. Enabling secure machine learning in IoT network in-trusion detection using federated, and semi-supervised learning.\n2. Proposing a novel FL algorithm to enhance the ability to detect IoT anomalies in heterogeneous environ-ments.\n3. Performing extensive experiments using a famous IoT dataset to evaluate our proposed approach. The exper-imental results present an advancement in distributed IoT network intrusion detection compared to some popular methods.\n4. Conducting a comprehensive analysis of the algo-rithm's robustness in both resource-constrained and large-scale IoT networks. This analysis highlights the practical applications of the proposed approach.\nThe rest of this paper is organized as follows. The next section briefly introduces some fundamental background related to this research. Section 3 highlights some recent research in federated intrusion detection. Our proposed ap-proach is described in Section 4. Section 5 gives the settings of the experiment and analyzes the results given by the pro-posed approach. Finally, we conclude the paper and discuss future work in Section 6."}, {"title": "2. Background", "content": "This section briefly introduces the background knowl-edge related to the intrusion detection system with federated learning."}, {"title": "2.1. Federated learning", "content": "Federated Learning (McMahan et al., 2017) is a novel approach to train machine learning models in a decentralized manner, aiming to address growing concerns about data privacy and the increasing computational power available on edge devices such as smartphones and IoT devices. FL enables the development of machine learning models by leveraging data distributed across multiple devices, referred to as clients or gateways in this research, without transferring the data to a central server. The model on each client device is called the local model, while the aggregated model, ob-tained by combining updates from clients, is known as the global model.\nThe training process is conducted in several consecutive communication rounds until the global model reaches the desired accuracy or meets the specified training criteria (Abdulrahman et al., 2021). Figure 2 depicts the steps of how a communication round occurs:\n1. Model initialization: Firstly, a subset of gateways is selected in the global model with a selection ratio. A global model is initialized and sent to all selected gateways. This is the starting point for the training process.\n2. Local training: Each gateway receives the global model and trains it using its local data. This results in a set of updated local models, each adapted to the data from its respective devices.\n3. Model update: Once all selected devices have done the local training process, optimized weights are sent to the global server.\n4. Global model aggregation: The server aggregates the updates from all local models to form a new global model that has the knowledge of all participants.\n5. Global update: The updated global model is then sent back to all clients in the network for further prediction. This updated model now reflects a more comprehensive understanding based on the combined data from all gateways.\nThe federated aggregation algorithm plays a crucial role in achieving the objectives of FL. Researchers have studied and proposed numerous algorithms for various applications. Among these, FedAvg (McMahan et al., 2017) and Fed-Prox (Li et al., 2020) are the most widely adopted and popular.\nFedAvg is a straightforward algorithm that constructs a global model by calculating the weighted average of param-eters from the client's models based on the number of data samples they hold. The client holding more data gets a higher weight in the aggregation process. The process occurs until the desired model is obtained. This algorithm is simple to implement and suitable for large-scale networks with a lot of participants (Idrissi et al., 2023).\nFedProx is similar to FedAvg but introduces a regulariza-tion term to each client's loss function, penalizing significant deviations of the client model parameters from the previous global model."}, {"title": "2.2. Autoencoder", "content": "Autoencoder (AE) is a feed-forward neural network that consists of an encoder and a decoder (as shown in Figure 1), trying to copy its input to its output (Goodfellow et al., 2016). Let $X = {x_1,...,x^n} \\subset R^n$ be the dataset. Let $\\Phi = (W, b)$,\n$\\Phi = (W', b')$ be weight matrices and bias vectors of the encoder and decoder, correspondingly; $e_p$ and $d_0$ stand for encoder and decoder. The encoder compresses input data $x^i$ to latent representation $h^i$ in a new feature space of the latent layer, then the decoder maps it to the input feature space, getting reconstruction output $x^i$. The AE can be formed as follows:\n$h^i = e_p(x^i) = act_e(Wx^i + b)$ (1a)\n$x^i = d_0(h^i) = act_d(W'h^i + b')$ (1b)\nwhere $act_e$, and $act_d$ are activation functions of the encoder and decoder, respectively.\nAEs are trained by minimizing the differences between the input data and the reconstruction data following Equa-tion 2 using the backpropagation technique:\n$L_{AE}(x^i, x^i) = \\frac{1}{n} \\sum_{i=1}^n ||x^i - x^i||^2$ (2)\nwhere n is the number of data samples.\nIn many applications, especially in network intrusion de-tection, AEs can be used for feature dimension reduction by compressing the original data into a lower-dimension space. The most important characteristics of original complex data can be extracted and represented more effectively in the latent layer, making other machine learning models learn data patterns more easily."}, {"title": "3. Related work", "content": "In this section, we review some recent studies that mo-tivate our research on federated learning for IoT network intrusion detection.\nAs mentioned before, existing network intrusion detec-tion approaches are facing some challenges. The scarcity of labeled anomalous data is one of the major issues in advanced intrusion detection. Despite the vast amount of network traffic data generated by modern and complex IoT networks, there is a notable lack of labeled abnormal data due to privacy issues, limitations of expert knowledge and labeling expenses (Cao et al., 2019). Anomalous network traffic includes computer communication related to system weaknesses and vulnerabilities. Thus, administrators tend to keep the data private to protect their network or client's sensitive information. Moreover, IoT networks generate a huge amount of network data and intrusion behaviors be-come more sophisticated over time, leading to being more challenging to collect, process, and label anomalous traffic in real-world networks that require a significant amount of time and expert knowledge. This absence makes it difficult to use supervised machine learning models to learn the characteristics of available intrusive data. To address this, some semi-supervised learning techniques, such as OCSVM (Zhang et al., 2015), and LOF (Breunig et al., 2000), can be used to model normal data. Especially, AEs have been applied widely in network intrusion detection due to the power of modeling complex characteristics of network data (Cao et al., 2019; Meidan et al., 2018; Idrissi et al., 2023). By modeling the normal data, new data points will be classified based on the reconstruction error of these ones, a higher error suggesting a higher probability of being an anomaly.\nOne of the fundamental challenges in FL is the handling of non-IID (non-Independent and Identically Distributed) data (McMahan et al., 2017). In traditional centralized ma-chine learning, data is typically assumed to be IID, which means that each data point is independent of the others and is drawn from the same distribution. In FL, however, the data on each client device is inherently linked to the user's behavior and usage patterns. Some devices will gen-erate large amounts of data while others contribute very little, resulting in heterogeneity in IoT networks (Sattler et al., 2020). An IoT network can be divided into multi-ple subnetworks, each managed by an IoT gateway, also known as an edge server, and located in a different area. The training data size and distribution of each subnetwork typically vary significantly due to differences in network traffic generated by their specific local environments and applications. This heterogeneity can lead to local models that are poorly representative of the overall population, making the global model work ineffectively in intrusion detection.\nAddressing this issue requires careful consideration of how to weigh contributions from different gateways to ensure that the global model remains fair and representative of all gateways. Both FedAvg and FedProx, mentioned in Section 2, update the global model based on the size of the training data held by local clients. This makes them face challenges in complex distributed networks with dynamic environments where participant availability and data characteristics can vary significantly. In this case, the client that has a large number of data samples may not represent strongly for the whole network.\nIn federated IoT applications, it is also crucial to con-sider some resource constraints aspects such as commu-nication overhead, and computational expense (McMahan et al., 2017; Sattler et al., 2020). Distributed training requires a massive number of clients to participate in the training process, increasing the communication throughput and time consumption. IoT devices have small computational capacity and available resources for training and predicting simulta-neously are limited. More accurate approaches require more complex computational activities, leading to an increase in resource consumption and incident response time. There-fore, choosing a lightweight approach and robust learning strategy is essential in federated IoT intrusion detection.\nThe first research applying FL in IoT intrusion detection is Di\u00f6T (Nguyen et al., 2019), a device-type-specific self-learning framework with a GRU network. It consists of two main components: The security gateway acts as an access point for IoT devices and the IoT security service maintains a set of device-type-specific models. The sys-tem autonomously learns and updates its models without requiring human intervention or labeled data. This allows DIoT to adapt to new device behaviors and emerging threats dynamically. The authors conducted extensive experiments using over 30 IoT devices with Mirai botnet in both labo-ratory and real-world smart home deployment settings. The evaluation showed that DIoT achieved a 95.6% detection rate with zero false alarms in real-world conditions. However, each device type in the system maintains its model on gateways, which can make system management challenging as the scale increases. With heterogeneous IoT networks with various device types and huge amounts of data, IoT gates may suffer from computational overload, affecting the response activities. This research is also limited to the Mirai botnet threats.\nMothukuri et al. utilized LSTM and GRU with the ensemble learning technique to enable on-device learning. The predictions from local GRU models are combined us-ing a Random Forest Classifier (RFC). Each GRU model provides probability values for each potential label (attack type) for a given input. The RFC aggregates the probability values from all GRU models. It uses these probabilities as votes to determine the final prediction. The label with the highest combined probability across all models is selected as the final prediction. Their evaluation demonstrated the performance of the FL approach compared to the non-FL approach with a high anomaly detection rate of 99.5% and a minimal number of false alarms. However, the ability of this approach to detect unknown intrusion is limited due to the supervised learning technique on available attacks. The proposed ensemble approach may be impacted by the het-erogeneity in modern IoT networks and the communication overhead in the prediction phase when requiring all clients to infer new data, and not considering the characteristics of local data.\nFed-ANIDS (Idrissi et al., 2023) is a network-based in-trusion detection approach based on the Autoencoder model similar to our proposal, a semi-supervised learning method. Various autoencoder-based models, including simple Au-toencoders (AE), Variational Autoencoders (VAE), and Ad-versarial Autoencoders (AAE), are utilized for anomaly detection based on reconstruction errors of normal traffic. The FL setting was employed by using FedAvg and FedProx algorithms. The authors conducted several experiments on some well-known network traffic datasets such as USTC-TFC2016, CIC-IDS2017, and CSE-CIC-IDS2018. The re-sults demonstrated that Fed-ANIDS achieves high accuracy in detecting network intrusions while maintaining low false alarm rates and preserving privacy. Additionally, they show that FedProx slightly outperforms FedAvg in terms of ac-curacy. Nevertheless, the findings also highlight the impact of heterogeneous network settings. This approach faces chal-lenges in effectively generalizing to normal network data and performs poorly on unseen data."}, {"title": "4. Proposed approach", "content": "In this paper, we propose FedMSE, an IoT intrusion detection approach using federated learning and a hybrid model based on the Shrink Autoencoder (an Autoencoder variant) and the Centroid algorithm. Figure 2 presents the overall architecture. It consists of two main components as described in the federated learning scheme: (1) SAE-CEN hybrid intrusion detector, (2) MSEAvg aggregation. The details of these two parts are explained in the rest of this section.\nTo feed to the machine learning model, firstly, the net-work data needs to be preprocessed. Network traffic is cap-tured and extracted to tabular features as proposed in Mei-dan et al.. We use the Standard Normalization method to normalize the data to reduce the computational complexity and ensure that all features contribute equally to the training process. The formula for standard scaling (also known as Z-score normalization) is given by:\n$z = \\frac{x - \\mu}{\\sigma}$ (3)\nwhere x is the original feature value, $\\mu$ is the mean of the feature, $\\sigma$ is the standard deviation of the feature."}, {"title": "4.1. Hybrid intrusion detection approach", "content": "By modelling normal network data, an Autoencoder-based model can take advantage of its latent layer to trans-form the original data into a new data space where the data has a smaller number of dimensions and presents the most important characteristics. Hence, some common traditional one-class classifiers can work effectively on this new data to detect anomalies. In this part, a hybrid model is constructed using Shrink Autoencoder (SAE) as a data representation method and Centroid anomaly detection algorithm (CEN) as a detector. This approach is named the SAE-CEN model.\nShrink Autoencoder (SAE) (Cao et al., 2019) is a power-ful data representation model that helps common network intrusion detection algorithms deal with sparse and high-dimensional network data, even with a small amount of train-ing data. This model is an Autoencoder variant since a new regularization term is added to the Autoencoder objective function in Equation 2. The new loss function is formulated as Equation 4. This makes it easier to construct the normal network data in the latent layer.\nThe objective function of the SAE training process is formulated as follows:\n$L_{SA}(x^i; x^i, \\&, h) = \\frac{1}{n} \\sum_{i=1}^n ||x - x^i||^2 + \\lambda \\sum_{i=1}^n ||h^i||^2$ (4)\nwhere $x^i$ and $h^i$ are the reconstruction output and the latent vector of the input $x_i$, correspondingly. The parameter $\\lambda$ controls the trade-off between the two terms in the equation. It is optimized using the Algorithm 1.\nGiven a normal network data set $X_0 = {x^{(1)}, ..., x^{(n)} } \\subset R^d$, the goal of intrusion detection is to determine whether a new data point x has the same probability characteristics as the set $X_0$. A straightforward approach to anomaly detection involves estimating the probability density function (PDF) of the distribution from which the dataset $X_0$ is derived. If a new instance x is located in an area of the distribution where the density is low, it is flagged as anomalous. However, estimating the density of a distribution is a challenging task, particularly in high-dimensional spaces. Another simple way comes from clustering-based algorithms with the assump-tion that normal data instances lie close to their cluster centroid. Meanwhile, abnormal data points are far from the centroid (Chandola et al., 2009), such as the Centroid (CEN) algorithm. The central idea is to leverage the distance from an observation to the centroid of the cluster as the abnormality of the observation. This distance is also known as the anomaly score. A higher score suggests that the data point has a higher probability of being an anomaly. By specifying a threshold, a query data point can be classified as normal or anomalous. The CEN algorithm is a very simple algorithm with no hyper-parameters, and its computational expense is small.\nAfter receiving the best SAE model from the server, the decoder part will be removed, and the encoder will be used as a data manipulator that forms the data in good shape to help CEN work more effectively (Figure 3). This also reduces the time required to respond to incidents. Therefore, the SAE-CEN combination can not only work powerfully to detect anomalies but also respond to incidents rapidly.\nCao et al. (2019) demonstrated that the CEN performed very accurately under the SAE representation data in central-ized network anomaly detection. In this research, we used a federated learning scheme to evaluate the accuracy of this solution in the decentralized IoT intrusion detection task."}, {"title": "4.2. Mean Squared Error-based model aggregation", "content": "The core component in all federated learning architec-tures is the global model aggregation. How effectively the global model is updated decides the power of the FL scheme. This section provides the design of a novel FL algorithm that boosts the performance of an Autoencoder-based model, especially SAE-CEN.\nDuring training a machine learning model, it is nec-essary to control the convergence of the model on both local and global sides to prevent under-fitting and over-fitting problems. In the data preprocessing phase, the server will collect a small processed dataset from all gateways in the network, called development data, that includes normal network data only to validate the global model convergence in each training round. This dataset contains data of all gateways with a uniform distribution. That means that all gateways have the same amount of normal data in this set and the representativeness of the whole IoT network will be ensured. Using processed data also keeps the sensitive information private in local gateways.\nThis research leverages as much as possible the strength of the Autoencoder-based model in modelling normal data and proposes the MSEAvg algorithm to aggregate the global model by comparing the ability of each local model in reconstructing the above development dataset. The model that works better will play a more critical role in updating the global model.\nFigure 2 and Algorithm 2 show the MSEAvg principle and pseudo-code for the whole operation. When all partic-ipants have completed the local training process and sent the optimal weights to the server, each local model uses the development data as input, returns the reconstruction error calculated by the mean squared error of input and output, and is assigned a weight in the updating process based on this error. The smaller error implies a better model for learning normal data, which means a higher weight. After that, the global model will be aggregated by using the Equation 5:\n$W_{global} = \\frac{\\sum_{i=1}^n 1/\\alpha_i \\cdot W_i}{\\sum_{i=1}^n 1/\\alpha_i}$ (5)\nwhere $\\alpha_i$ is the update weight based on MSE loss; $W_i$ is the local model weights."}, {"title": "5. Evaluation", "content": "This section presents the evaluation of our approach and focuses on resolving three research questions that corre-spond to the three experiments below.\n1. RQ1. How does the proposed approach work in IoT federated intrusion detection?\nWe perform Experiment 1 to solve this RQ. Section 5.2 presents the results of this experiment and dis-cusses some findings to examine the ability of our approach in federated IoT network intrusion detection.\n2. RQ2. How does the gateway selection ratio affect federated learning intrusion detection?\nConducting Experiment 2 corresponds to solving RQ2. Section 5.3 shows the results of Experiment 2 to consider the efficiency of our approach with various gateway selection ratios.\n3. RQ3. How does the proposed approach work on large-scale IoT networks?\nThe robustness of the proposed approach in large-scale IoT networks will be investigated with the find-ings of Experiment 3 in Section 5.4."}, {"title": "5.1. Experiment settings", "content": "Below we present the settings used for the experiments we conducted in order to evaluate our approach. The actual experiments will be discussed in Sections 5.2 through 5.4."}, {"title": "5.1.1. IoT network construction", "content": "Relying on the description of non-IID challenges in FL, we conduct experiments in two scenarios, 1) low non-IIDness and 2) high non-IIDness, to evaluate our approach. For the first context, we consider an IoT network in which the gateways have the same topology, device type, and applica-tions, resulting in an equivalent data distribution across these subnetworks. In contrast, the second setting abstracts an IoT network in which subnetworks differ in all topologies, IoT device types, applications, and the number of data records for each device type.\nTo mimic the IoT network for this evaluation, a small partition of the N-BaIoT dataset, with only normal data, is used to make experiments close to practical scenarios. N-BaIoT dataset (Meidan et al., 2018) is designed to aid in the detection of IoT botnet attacks. The dataset was collected from nine commercial IoT devices that were intentionally infected with two prevalent IoT-based botnets: Mirai and Gatfyt. The details of this dataset are described in Table 1.\nFigure 4 shows the experimental data allocation. We consider a 10-gateway IoT network, which means that there are 10 IoT gateways in the network. The gateway data is selected from N-BaIoT data using random algorithms and constraints to ensure the non-IID characteristics of training data. We use the Dirichlet distribution $Dir(\\alpha)$ with n is the number of gateways and $\\alpha$ as the concentration parameter and Jensen-Shannon measurement (JS) to control the non-IIDness of networks. To simulate a homogeneous setting, for each device type k, we sample $p_k \\sim Dir_{10}(1000)$ and allocate the proportion data $p_{k,j}$ of device k for the gateway j, and the measurement is $JS = 0.01$. We do the same process for the heterogeneous setting with the concentration parameter $\\alpha = 0.1995$ and $JS = 0.83$. In the testing phase, some new devices will be added to the network to simulate the dynamics of IoT networks.\nTo solve the RQ3 when considering IoT networks in different network scales, we use the same methodology to select the data in both those contexts for 20-gateway, 30-gateway, 40-gateway, and 50-gateway networks that have 20 gateways, 30 gateways, 40 gateways and 50 gateways in the topology, correspondingly."}, {"title": "5.1.2. Hyperparameters setting", "content": "This research studies the accuracy of Autoencoder and SAE-CEN models under FedAvg, FedProx, and MSEAvg federated learning algorithms. In intrusion detection, it is challenging to determine a threshold that accurately classi-fies a data point as either normal or anomalous. Thus, the Area Under the ROC Curve (AUC) metric (Huang and Ling, 2005) is adopted to evaluate these models at different thresh-olds. We ran each experiment five times and calculated the mean accuracy and standard deviation of the AUC values.\nDue to the lack of anomalies during training, the exper-iment hyperparameters can not be tuned, which is one of the considerable challenges of this work. We set up them using common values. The mini-batch size value is chosen as 12, learning rate Ir = 0.00001, local epoch I = 100, number of global round E = 20, $\\mu = 0.001$ for the FedProx proximal term. In each round, we select half of the gateways to join the training process based on the majority rule. For the SAE shrink parameter, we set the value of 10 as Cao et al. (2019) for balancing shrink loss and MSE loss and employ the Adam optimizer (Kingma and Ba, 2014) along with early stopping techniques (Prechelt, 2012) to train these local models. We split the local training data into 40% for training, 10% for validation, 40% for the development dataset, and 10% for adding to testing set. The early stopping techniques are also used in the global server to control the convergence of the global model on the development dataset. For the number of neurons in the latent layer of the Autoencoder-based model, we configure based on rules of thumb as mentioned in Cao et al. (2016) with the value $m = [1 + \\sqrt{n}]$,\nwhere n is the original space dimension.\nAll experiments were implemented in Python language and run on one KAGAYAKI high-performance computing GPU server at Japan Advanced Institute of Science and Technology, which has an Intel Xeon GOLD 5320 52-core 2.2 GHz CPU, 512 GB DDR4/3200 SDRAM memory, and two NVIDIA A100 48 GB GPUs."}, {"title": "5.2. Experiment 1: Federated intrusion detection performance", "content": "We do the first experiment to examine the detection ability of our approach in every network gateway. Table 2 and Figures 5, 6 present the AUCs obtained by the Au-toencoder and SAE-CEN models under three aggregation algorithms. The results indicate that the larger non-IIDness setting poses greater challenges for machine learning models in detecting anomalies, leading to a decrease in accuracy and less consistency among gateways compared to the low non-IIDness scenario.\nIn the less heterogeneous case, both the Autoencoder and SAE-CEN models have high accuracy for all gateways under all federated learning algorithms, and the Autoencoder is slightly better than SAE-CEN in some algorithms. This sug-gests that the Autoencoder model can effectively generalize the whole data across gateways in this case. The reason may be due to the variability of training data among gateways is not much, all gateways have a similar data distribution, which helps Autoencoder to easily model the data. However, SAE-CEN does not outperform Autoencoder in all algo-rithms. The root cause is related to the architecture of the SAE model. During training, the SAE model must balance two objectives: representing the latent data close to the origin and reconstructing normal data. As a result, the SAE-CEN model cannot show outstanding performance compared to the Autoencoder model in the first scenario. This signifies that in a simple federated learning case, the Autoencoder model is good enough to detect anomalies accurately.\nHowever, in the more heterogeneous setting, the Au-toencoder accuracy drops dramatically under all aggrega-tion algorithms. Meanwhile, SAE-CEN shows excellent ef-fectiveness across all gateways. This can be explained as follows: The training data distribution across gateways is significantly different, and each local Autoencoder model converges in various directions. Thus, when accumulating all local models to a unique model and sending them to all gateways, the new model performance will drop sub-stantially. In contrast, each local SAE-CEN model aims to optimize parameters to create a compact latent space for normal data when trying to force the normal latent data close to the origin. Therefore, the aggregated model will also represent the latent data approximately near the optimal area, enhancing the CEN model's ability to detect unseen data effectively.\nThe results highlight the improvements achieved by FedMSE, brought by the integration of the MSEAvg algo-rithm and the SAE-CEN machine learning model, partic-ularly in the high non-IIDness case. The smaller standard deviation also demonstrates improved consistency among gateways. FedAvg and FedProx update the global models based on the training data size of selected gateways. In the second setting, the gateway holding larger data may not ensure the representativeness of the whole data. For example, in this experiment setting (Figure 4b), Gateway 5 may not be better than Gateway 6. Instead, MSEAvg enhances this by prioritizing updates from models that better model the representative of the whole data. By assigning greater weight to these accurate models, MSEAvg forces the aggregated weights close to the better models. This makes the global model improve the generalization ability and reduces the influence of noisy updates that might cause the abnormal data points to be mixed in the normal latent region. The aggregated model will act more effectively on all subnetworks. Another reason is the behavior inside the SAE model, the SAE model needs to control the trade-off between reconstruction error and shrink error. MSEAvg helps the SAE model form the normal data comprehensively while keeping the latent representation capability. Therefore SAE model can separate the normal data points better than FedAvg and FedProx.\nFigure 7 visualizes the SAE's latent data on the testing dataset in 2D and 3D. The normal cluster that is constructed by MSEAvg is smaller, denser, and closer to the origin than that of FedAvg and FedProx algorithms. This helps the CEN model inside FedMSE work more effectively in detecting abnormal data points, particularly on unseen data when IoT networks innovate."}, {"title": "5.3. Experiment 2: Effects of gateway selection ratio", "content": "In federated learning, the percentage of gateways chosen to participate in the training process can significantly affect the model's performance, efficiency, and communication overhead. There is always a trade-off among these crite-ria in choosing an optimal gateway selection ratio. We do the second experiment to consider FedMSE's efficiency in resource-constrained IoT networks.\nTable 3 and Figure 8, 9 show the average accuracy of comparison candidates under different settings of the gateway selection ratio. The results indicate that the gateway selection ratio affects the consistency among gateways, and FedMSE still shows outstanding power. This is evidenced by changes in the standard deviation and the complexity of algorithms although the mean accuracy fluctuates slightly and all FedAvg, FedProx, and MSEAvg help SAE-CEN have comparable accuracy.\nConsidering the low non-IIDness scenario, data is uni-formly distributed among gateways. Therefore, each gate-way has similar data characteristics, ensuring that even a subset of gateways can provide a representative sample for model training. Therefore, the standard deviation is rela-tively low for all gateway ratios, reflecting consistent perfor-mance among gateways. Autoencoder is sensitive to noise, hence, it tends to drop accuracy when updated by more gateways. This is due to a bit of difference in the data distribution among gateways, making more noise and vari-ability in aggregation compared to a small ratio. The SAE-CEN model performs very accurately and consistently in all settings because of the representation ability as discussed in Experiment 1"}]}