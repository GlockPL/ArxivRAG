{"title": "HEROS-GAN: Honed-Energy Regularized and Optimal Supervised GAN for Enhancing Accuracy and Range of Low-Cost Accelerometers", "authors": ["Yifeng Wang", "Yi Zhao"], "abstract": "Low-cost accelerometers play a crucial role in modern society due to their advantages of small size, ease of integration, wearability, and mass production, making them widely applicable in automotive systems, aerospace, and wearable technology. However, this widely used sensor suffers from severe accuracy and range limitations. To this end, we propose a honed-energy regularized and optimal supervised GAN (HEROS-GAN), which transforms low-cost sensor signals into high-cost equivalents, thereby overcoming the precision and range limitations of low-cost accelerometers. Due to the lack of frame-level paired low-cost and high-cost signals for training, we propose an Optimal Transport Supervision (OTS), which leverages optimal transport theory to explore potential consistency between unpaired data, thereby maximizing supervisory information. Moreover, we propose a Modulated Laplace Energy (MLE), which injects appropriate energy into the generator to encourage it to break range limitations, enhance local changes, and enrich signal details. Given the absence of a dedicated dataset, we specifically establish a Low-cost Accelerometer Signal Enhancement Dataset (LASED) containing tens of thousands of samples, which is the first dataset serving to improve the accuracy and range of accelerometers and is released in Github. Experimental results demonstrate that a GAN combined with either OTS or MLE alone can surpass the previous signal enhancement SOTA methods by an order of magnitude. Integrating both OTS and MLE, the HEROS-GAN achieves remarkable results, which doubles the accelerometer range while reducing signal noise by two orders of magnitude, establishing a benchmark in the accelerometer signal processing.", "sections": [{"title": "Introduction", "content": "Low-cost accelerometers are indispensable in modern technology due to their small size, ease of integration, and widespread availability [Li et al. 2022b; Ehatisham-ul Haq et al. 2021]. In industry, they are used for posture control, navigation, and path planning of machinery. By measuring motion, accelerometers enable the monitoring and control of equipment in complex environments, aiding in structural health monitoring and vehicle dynamic performance testing [Caesar et al. 2020]. On production lines, accelerometers detect abnormal vibrations in real time to predict equipment failures. In smart manufacturing, they assist in positioning and motion control, enhancing product quality and stability [Wang and Zhao 2024d]. In robotics, accelerometers monitor robotic arm movements for precise operations [Gromov et al. 2019; Liu et al. 2020a]. In IoT applications, they ensure optimal operation by monitoring equipment status [Yang et al. 2023]. In communication, accelerometers are used in mobile devices for posture detection and user interaction [Liu et al. 2020b; Li et al. 2023]. They enable automatic screen rotation, step counting, game control, and AR applications, enhancing user convenience and interactivity. In smartphones, accelerometers support gesture recognition, fall detection, and gait analysis, offering intelligent and personalized services [Wang and Zhao 2024b]. In medical and health monitoring, accelerometers have promising applications. Embedded in wearable devices, they allow real-time monitoring of patients' activity and physiological parameters, aiding diagnosis and health management. For example, accelerometers detect falls in the elderly by monitoring sudden changes in body acceleration and providing emergency alerts. They also monitor movements in rehabilitation training, assess recovery progress, and guide exercises.\nHowever, the widely used low-cost accelerometers face significant accuracy and range issues [Malayappan et al. 2022]. Limited accuracy with severe noise hinders low-cost accelerometers in high-precision motion capture and subtle vibration monitoring [Wang, Xu, and Zhao 2024]. In industrial automation, precise machine motion control relies on high-quality acceleration signals, but severe noise can significantly affect the stable operation and control of machines. In medical monitoring, noise interferes with accurately measuring movements and physiological parameters, hindering remote diagnosis and health management [Gupta et al. 2020]. Moreover, low-cost accelerometers typically operate within a range of \u00b12g or \u00b18g, which easily leads to sensor saturation, data loss, and signal distortion in high-dynamic environments. For example, in industrial automation, accurately capturing complex motions requires accelerometers with a range of up to \u00b116g [Niu et al. 2022]. However, industrial-grade accelerometers meeting these requirements are priced between $10 and $20 per unit, which is too expensive for consumer-end deployment. Top-tier accelerometers, like Xsens, can exceed $1500 per unit due to their superior accuracy and range. In comparison, these widely used low-cost accelerometers are available for as little as $0.20 to $0.50 per unit. While affordable, these sensors are inadequate for many demanding applications. In healthcare, low-range accelerometers struggle to detect rapid movements or sudden events, such as falls, where accelerations often surpass 10g, causing missed alerts and defective health monitoring. Therefore, extending the range of low-cost accelerometers is crucial for enabling broader and more robust applications in various realms. In summary, by using advanced algorithms to enhance low-cost sensors, we can achieve high-end performance at a fraction of the cost, offering transformative potential across industries and making cutting-edge experiences accessible to all.\nThe rapid development of artificial intelligence [Xu et al. 2024; Wang et al. 2020; Liu et al. 2024], particularly in generative deep learning models [Li et al. 2024a; Wang and Zhao 2024a], offers promising avenues for enhancing the range and accuracy of low-cost accelerometers. A potential solution lies in training a generative model to map low-cost sensor signals to high-cost ones, thereby improving the quality of low-cost signals. However, it is impractical to obtain frame-by-frame paired data between low-cost and high-cost sensors [Pei et al. 2023]. Unpaired data pose significant challenges in training generative models due to the lack of supervision and guidance [Li et al. 2024b], often resulting in unreliable generated signals that fail to meet the stringent requirements of accelerometer applications. To address the severe problem in training with unpaired data, we propose a HEROS-GAN, which leverages optimal transport theory to maximize the use of supervisory information from unpaired data and injects Laplacian energy into the generator to encourage local changes. The core contributions of this paper are encapsulated in the following four aspects.\n\u2022 We propose to utilize deep learning algorithms for extending accelerometers range for the first time and introduce generative deep learning methods into accelerometer signal processing.\n\u2022 Considering the lack of supervision from unpaired data, we design an Optimal Transport Supervision (OTS) to explore potential correlations within unpaired data, providing the model with as much supervisory information as possible.\n\u2022 We design a Modulated Laplace Energy for GANs, guiding the model to generate more reasonable local changes, thereby enriching the generated signal details and breaking range limitation.\n\u2022 We release the first accelerometer signal enhancement dataset in Github. Based on this dataset, our HEROS-GAN can extend the range of low-cost accelerometer signals from 8g to 16g, while reducing signal noise by an order of magnitude."}, {"title": "Related Work", "content": "Restoring over-range signals for accelerometers is an unexplored area within the current research landscape. Over-range signals are lost when the acceleration of the measured object exceeds the sensor's range, presenting a critical challenge in high dynamic applications such as automotive crash testing, industrial machinery monitoring, and sports science. However, few attempts are dedicated to the accelerometer over-range signal restoration problem. Several factors contribute to the scarcity of research in this area. The nonlinearity and complexity of signal distortion when an accelerometer exceeds its measurement range make the restoration task highly challenging. Also, the recovery of over-range signals is highly context-dependent and relies on experience observing massive data, which is difficult for traditional non-data-driven models [Yang et al. 2024]. Finally, obtaining paired high-range and low-range data for training data-driven models is inherently tricky. The rarity of such paired datasets impedes the development of supervised learning approaches, further complicating the task of over-range signal restoration. Consequently, most existing efforts have focused on improving the dynamic range of sensors through hardware advancements rather than algorithm design [Wu et al. 2024].\nCompared to the rarely explored area of over-range signal restoration, considerable research has focused on reducing noise in accelerometer signals. Traditional signal denoising approaches rely on various filtering techniques, including Kalman filters, Savitzky-Golay filters [Karaim, Noureldin, and Karamat 2019], and empirical mode decomposition [Liu et al. 2020c]. While these methods have proven effective in separating the noise from the signal and improving signal quality, they usually rely on prior knowledge of the signal or noise characteristics [Skog and Handel 2009], causing poor generalization ability. In contrast, data-driven methods learn the denoising function from data without relying on the information about signal characteristics, which can adapt to different sensors and noise patterns. In data-driven approaches, generative deep learning models directly map low-cost signals to high-cost signals, providing a more effective way to enhance signal quality. However, their superior performance typically relies on strictly paired training data, which is impractical to obtain for low-cost and high-cost accelerometers [Wu et al. 2019]. Therefore, few studies have attempted to apply GANs to improve accelerometer signals."}, {"title": "Methodology", "content": "The primary challenge in enhancing low-cost accelerometer signals lies in the inability to obtain strictly paired high-cost and low-cost sensor signals. Consequently, end-to-end methods with fully supervised training are impractical for converting low-quality signals into high-quality ones. To address this, we utilize CycleGAN as the baseline to construct a mapping between unpaired signals of varying qualities. Given the lack of paired data for guidance and supervision, we propose a honed-energy regularized and optimal supervised GAN (HEROS-GAN), as illustrated in Fig. 1. In this architecture, Optimal Transport Supervision (OTS) is designed to mine supervisory information from unpaired data, while Modulated Laplace Energy (MLE) guides the model to generate realistic local changes, thereby enriching signal details."}, {"title": "Optimal Transport Supervision", "content": "Although both high-cost and low-cost signals are fed into the network simultaneously, the absence of paired data precludes the use of simple element-wise constraints (such as L1 or L2 loss), to enforce low-cost signal features approaching high-cost ones. Nonetheless, unpaired data still exhibit similar characteristics within their feature layers [Yang, Wang, and Yang 2021]. To exploit these similarities, we propose the Optimal Transport Supervision (OTS) mechanism to align the features of low-cost signals with those of high-cost signals, thereby maximizing the supervision information obtained from unpaired data.\nAs shown in Fig. 2, the core idea of OTS is to explore similar features hidden in unpaired high-cost and low-cost signals for supervision, which is achieved by employing the optimal transport theory. Let \\(F_L(X_L) = \\{f_{L_1}, f_{L_2},..., f_{L_N}\\} \\in \\mathbb{R}^{N \times d}\\) represent the features of low-cost signals, and \\(F_H(X_H) = \\{f_{H_1}, f_{H_2},...,f_{H_N}\\} \\in \\mathbb{R}^{N \times d}\\) represent the features of high-cost signals. The goal of the optimal transport problem is to find an optimal mapping between these two feature distributions that minimizes the transportation cost. This problem can be formulated as:\n\\(min_{\\Upsilon \\in \\Gamma(F_L, F_H)} \\int_{\\mathcal{X} \times \\mathcal{Y}} c(f_{L_i}, f_{H_j}) d\\gamma(f_{L_i}, f_{H_j})\\)   (1)\nwhere \\(\\Gamma(F_L, F_H)\\) represents the set of all joint distributions that couple \\(F_L\\) and \\(F_H\\), and \\(c(f_{L_i}, f_{H_j})\\) is the cost function, which is defined as \\(c(f_{L_i}, f_{H_j}) = e^{1 - f_{L_i} \\cdot f_{H_j}}\\). The Sinkhorn algorithm can be applied to Eq. 1 for approximating the optimal transport solution, which provides a transport mapping \\(T: \\mathcal{X} \rightarrow \\mathcal{Y}\\) by mining the feature consistency between low-cost and high-cost signals. This mapping allows us to identify and align the most similar features between the two distributions. Subsequently, we can define the OTS loss \\(L_{OTS}\\) to impose appropriate supervision that encourages low-cost signal features to align with certain high-cost signal features.\n\\(L_{OTS} = E_{x_L \\sim P_L, x_H \\sim P_H}[||F_{G_L}(X_L) - T(F_H(X_H))||^2 + ||F_{G_H}(X_H) - T^{-1}(F_L(X_L))||^2]\\)   (2)\nwhere \\(P_L\\) and \\(P_H\\) denote the data distributions for domains of low-cost and high-cost signals. By minimizing \\(L_{OTS}\\), the generative model is encouraged to produce low-cost signal features that are aligned with the high-cost signal features."}, {"title": "Modulated Laplace Energy", "content": "Enhancing the detail of generated signals is crucial for accurately capturing the subtle variations inherent in accelerometer data. Low-cost signals tend to be less sensitive, resulting in less detailed and more simplified signals [Yuan et al. 2024]. In contrast, high-cost accelerometers can capture richer details and finer variations due to their higher sensitivity. This disparity directly affects performance and reliability in applications such as health monitoring, mobile device interactions, and precision engineering. Traditional GANs often struggle to generate these fine-grained details, leading to oversimplified and less realistic signals [Wang and Zhao 2024c]. To address this issue, we leverage the Laplacian operator, denoted as \\(\\nabla^2\\), which measures the second-order derivatives of a function and is effective in highlighting fine details and variations within the signal. Based on Laplacian operator, we propose the concept of Laplace Energy for features in a deep learning architecture, as shown in Equation 3 and 4:\n\\(\\mathcal{E}_{Laplace}(h^{(n)}) = \\sum_{i=2}^{d-1} (2h_i^{(n)} - h_{i-1}^{(n)} - h_{i+1}^{(n)})^2\\)   (3)\n\\(\\nabla^2 h_i^{(n)} = h_{i-1}^{(n)} - 2h_i^{(n)} + h_{i+1}^{(n)}\\)   (4)\nwhere \\(h^{(n)} \\in \\mathbb{R}^d\\) denotes the n-th feature within the network, d is the dimension of the feature, and \\(h_i^{(n)}\\) is the i-th element in the feature \\(h^{(n)}\\). The Laplace Energy evaluates the volatility of the features, with higher Laplace Energy indicating stronger volatility and more significant local variations, while lower energy suggests smoother and less detailed features in the generated signal. An intuitive approach is to design a regularization term based on Laplace Energy to guide the model in enhancing the feature volatility. However, unrestricted enhancement of Laplace Energy is clearly unreasonable, as it could introduce noise and instability in the generated signals. Therefore, we devise a Modulated Laplace Energy (MLE) as shown in Fig. 3, which adaptively injects an appropriate amount of energy into the feature via regulation term \\(R_{MLE}\\).\n\\(R_{MLE} = -log(\\mathcal{E}_{Laplace}) - \\kappa \\cdot log(1 - \\mathcal{E}_{Laplace})\\)   (5)\n\\(\\mathcal{E}_{Laplace} = \\sigma(\\mathcal{E}_{Laplace})\\)   (6)\nwhere \\(\\sigma\\) denotes the sigmoid function, normalizing the Laplace energy to the range (0, 1). \\(\\kappa\\) is a modulation parameter, set to feature kurtosis that is shifted to range (0, +\u221e). This regularization term exhibits important properties. Firstly, when \\(\\mathcal{E}_{Laplace}\\) approaches 0 or 1, \\(R_{MLE}\\) tends towards infinity, imposing a strong penalty on both very low and very high Laplace energy values. So the Laplace energy should remain within a moderate range. For instance, when \\(\\kappa = 1\\), the regularization term is symmetric, and its minimum occurs at \\(\\mathcal{E}_{Laplace} = 0.5\\), thereby avoiding the injection of excessive or insufficient energy.\nSecondly, the modulation parameter \\(\\kappa\\) controls the amount of injected energy by controlling the minimum point of the regularization term. Specifically, high kurtosis (large \\(\\kappa\\)) indicates strong volatility in the feature, necessitating less energy. Under this scenario, a large \\(\\kappa\\) exactly ensures that the minimum of \\(R_{MLE}\\) occurs at a lower value of \\(\\mathcal{E}_{Laplace}\\), leading to lower Laplace energy. Conversely, low kurtosis (small \\(\\kappa\\)) indicates weak volatility, necessitating more energy. Under this scenario, a small \\(\\kappa\\) exactly shifts the minimum of \\(R_{MLE}\\) towards a higher value of \\(\\mathcal{E}_{Laplace}\\), resulting in higher Laplace energy. This adaptive behavior ensures that the MLE mechanism injects the appropriate amount of energy into features based on their volatility characteristics. High-kurtosis features, which are naturally more fluctuating, receive less added energy, while low-kurtosis features, which are naturally smoother, receive more energy to enhance their details. By minimizing \\(R_{MLE}\\), the model generates finely detailed and stable signals, providing effective guidance for generative models in the absence of supervised information."}, {"title": "Experiments and Results", "content": "Given the absence of a dedicated dataset for accelerometer over-range signals, we created a Low-cost Accelerometer Signal Enhancement Dataset (LASED) using 10 different smartphones equipped with built-in accelerometers, which are representative low-cost accelerometers [Jimenez et al. 2009]. The specifications of the smartphones and their internal sensors are detailed in Table 1, where the cost of these sensors does not exceed $0.5. To evaluate our model's robustness, we utilize only one type of smartphone for collecting training data, while the remaining nine smartphones are exclusively used for testing. This setup imposes a significant challenge, requiring the model to generalize across varying hardware specifications, thereby rigorously assessing its performance. Moreover, an eight-camera optical equipment (Nokov Mars2H) is employed to assist in motion capture. During the data collection process, each smartphone is subjected to vigorous shaking in multiple directions to induce signal overload that exceeded the measurement range of the accelerometers. This simulation replicates real-world scenarios where accelerometers encounter high dynamic forces and output overload signals. All experiments are implemented by Pytorch with NVIDIA RTX 4090 GPU and Intel(R) Xeon Gold 6330 CPU."}, {"title": "Evaluation Metrics", "content": "As the study of generating over-range accelerometer signals is relatively unexplored, there is a lack of metrics to evaluate the accuracy of the generated signals. We, therefore, propose two metrics, Clipped Signal Reconstruction Error (CSRE) and Zero-Velocity Residual Error (ZVRE), to assess the effectiveness of over-range reconstruction methods. For CSRE, the high-cost sensor signal \\(S_{hc}(t)\\) is artificially clipped at multiple thresholds \\(\\tau\\) to simulate the signal saturation phenomenon of low-cost sensors with different ranges, resulting in clipped signals \\(S_{clip,\\tau}(t)\\). The reconstruction method is then applied to these clipped signals, producing reconstructed signals \\(S_{recon,\\tau}(t)\\). CSRE is calculated by comparing the reconstructed signals with the original unclipped signals by the formula:\n\\(CSRE_{\\tau} = \\frac{1}{N} \\sum_{t=1}^{N} (S_{hc}(t) - S_{recon,\\tau}(t))^2\\)   (7)\nwhere N is the total number of time frames.\nZVRE measures the physical plausibility of generated accelerometer signals. The physical property that the integral of the acceleration signal over transition period from rest to vigorous shaking and back to rest should be zero for each axis (x, y, and z) is essential for validating the physical accuracy of the generated signals. The ZVRE is calculated as the absolute value of the integrated acceleration, indicating the deviation from the expected zero velocity.\n\\(ZVRE_{axis} = \\int_{0}^{T} a_{axis}(t) dt\\)   (8)\nwhere T denotes the time period. This metric is just zero when the reconstructed signals maintain the zero-velocity condition after periods of motion, thereby validating their physical plausibility. In addition to the proposed CSRE and ZVRE, we employ Allan variance [Pei et al. 2023] to evaluate the accuracy of acceleration signals under static conditions. Allan variance is a classical time-domain technique that provides the quantitative indicators of sensor signal quality, including quantization noise (QN), velocity random walk (VRW), and bias instability (BI)."}, {"title": "Comparative Results", "content": "Recent acceleration denoising methods, including optimized CNN (CNN-0) [Chen, Taha, and Chodavarapu 2022], GRU-LSTM [Han et al. 2021], optimized GRU-LSTM (GRU-LSTM-0) [Boronakhin et al. 2022], and kNN [Engelsman and Klein 2023], rely on fully supervised training by frame-paired high-cost and low-cost signals. However, collecting such paired data under high-dynamic conditions is impractical. To the end, we used clipped and unclipped high-cost signals to train these methods for generating over-range and high-quality signals. Additionally, MATLAB versions released after 2023 introduced an over-range signal reconstruction function based on polynomial fitting techniques, which is one of the few existing methods that directly tackle the issue of signal saturation. Consequently, we included it in our comparative study. Moreover, we introduced some of the latest signal enhancement methods applicable to IMUs for comparison [Yuan and Wang 2023]. All comparative methods were implemented strictly following the procedures described in their papers or using their open-source codes. The results are shown in Table 2.\nThe Clipped Signal Reconstruction Error is tested on clipped high-cost signals. When the clipping is minimal, such as at \\(\\tau = 15g\\), model-driven methods perform well since they only need to fit the small clipped portions without altering the original signal. In contrast, deep learning models (except ours) tend to modify the entire input signal, occasionally resulting in a higher CSRE. However, as the clipping level increases, traditional model-driven methods struggle. They fail to effectively reconstruct larger clipped sections due to their simplistic fitting approach, leading to significant reconstruction errors. To illustrate this, we visualized the CSRE for different methods as \\(\\tau\\) decreased from 15g to 6g, as shown in Fig. 4. It is evident that the CSRE of the proposed HEROS-GAN is much lower than all comparative methods, attributed to the identity loss. This loss preserves the non-clipped parts of the input high-cost signal, enabling accurate reconstruction of the clipped sections without altering the original signal structure, thus handling both minimal and severe clipping scenarios.\nThe Zero-Velocity Residual Error is tested on saturated low-cost signals. Fully supervised methods, trained with high-cost signals, attempt to emulate high-quality signal characteristics, achieving slight reductions in the ZVRE of the test low-cost signals. However, their lack of exposure to low-cost signals limits their effectiveness. In contrast, unsupervised learning methods trained with low-cost signals and model-driven methods never observe high-cost sensor signals, leaving them unaware of the physical plausibility, which causes significant velocity deviations after integration, making these methods ineffective for ZVRE reduction. To demonstrate this, we visualize the ZVRE of the x, y, and z axes for all comparative methods and the raw low-cost signal, as shown in Fig. 5. It can be observed that the HEROS-GAN framework outperforms all comparative methods due to its ability to observe both low-cost and high-cost signals. Despite unpaired signals, our Optimal Transport Supervision mechanism exploits their potential correlations to provide the maximum supervisory information. Consequently, the enhanced signal accurately complies with physical laws, ensuring minimal velocity deviation after the Static-Dynamic-Static process."}, {"title": "Discussion", "content": "The proposed OTS module leverages optimal transport theory to explore potential consistencies between unpaired or weakly-paired data, providing as much supervisory information as possible for generative models and breaking the limitations of strictly paired data. The core idea of OTS lies in aligning features across different data distributions. In multimodal learning, OTS can align feature distributions across modalities, facilitating cross-modal generation, translation, and enhancement tasks. In domain adaptation, OTS can align features from different domains. In medical imaging analysis, where data distributions from different imaging devices (e.g., MRI and CT) vary significantly [Li et al. 2022a], OTS can align the feature distributions across devices, enabling diagnostic model transfer between devices. In robotic perception, OTS can align features from heterogeneous sensors or platforms, supporting multi-platform collaboration and knowledge transfer. In tasks such as remote sensing image processing, unsupervised representation learning, and cross-modal retrieval, the feature alignment capability of OTS can also play a critical role. Moreover, its ability to model optimal mappings between distributions could be extended to decision-making systems, such as reinforcement learning, where it could optimize the transfer of policies between agents operating in different environments. In summary, OTS provides soft yet strict supervision for weakly paired or even unpaired data and features, unlocking hidden consistencies between distributions and uncovering meaningful relationships.\nThe design of the MLE regularization term offers a powerful and flexible approach for controlling model behavior, with a wide range of potential applications in deep learning tasks. Its formulation can be simplified as -log(x) - \\(\\alpha\\)log(1 - x), which serves as a loss function to penalize extreme outputs in deep learning models. More importantly, the parameter \\(\\alpha\\) \u2208 (0, +\u221e) endows the model with the ability to regulate its output preferences. When \\(\\alpha\\) approaches 0, as the regularization term decreases, the model tends to output values close to 1; conversely, when \\(\\alpha\\) approaches +\u221e, the model's output tends towards 0 as the regularization term decreases. By setting \\(\\alpha\\) to reflect specific model characteristics, we can softly guide the model's behavior, avoiding overly rigid constraints. For instance, in this work, \\(\\alpha\\) is set to the kurtosis of the signal features, enabling the model to inject an appropriate amount of Laplacian energy, neither too much nor too little. In tasks like feature alignment or semantic consistency constraints, a suitable \\(\\alpha\\) can be employed to softly regulate the similarity between features, facilitating more natural alignment across different modalities or tasks. Additionally, this regularization term can also be applied to soft adversarial training, where adjusting \\(\\alpha\\) helps balance the model, preventing it from becoming overly biased towards a specific direction. In threshold selection or hyperparameter tuning, it allows the model to adaptively adjust thresholds or hyperparameters based on its intrinsic characteristics by the preference factor \\(\\alpha\\). In summary, this regularization term, with its capability for soft constraints, preserves flexibility while guiding the model's learning process, demonstrating significant versatility and utility."}, {"title": "Conclusion", "content": "The widespread usage of low-cost accelerometers is often limited by their accuracy and range. Due to the lack of paired data, few studies utilize generative models to transfer low-cost accelerometer signals into high-cost equivalents. This paper proposes a HEROS-GAN for signal accuracy and range enhancement based on unpaired data of independently measured low-cost and high-cost accelerometer signals, which integrates with the Optimal Transport Supervision (OTS) and the Modulated Laplace Energy (MLE) modules. The OTS module leverages the optimal transport theory to explore optimal mapping between such unpaired data, thereby maximizing supervisory information. We provide a rigorous mathematical proof to ensure the existence of this optimal mapping and demonstrate that it can converge during training. Moreover, we mathematically prove that OTS can reduce the instability and oscillations of GAN, overcoming one of the key problems for GAN architecture. The MLE module calculates and adaptively adjusts the Laplace energy of features within the generator, promoting local changes and enriching signal details. Considering the absence of dedicated datasets, we release a Low-cost Accelerometer Signal Enhancement Dataset (LASED) in GitHub, providing the first data experimental platform for accelerometer range and accuracy enhancement. We also devise two metrics, Clipped Signal Reconstruction Error (CSRE) and Zero-Velocity Residual Error (ZVRE), to assess the accuracy and physical plausibility of the enhanced signals. Experimental results demonstrate that a CycleGAN combined with either OTS or MLE alone outperforms current SOTA methods in accelerometer signal enhancement with a tenfold improvement. The HEROS-GAN framework, integrating both OTS and MLE, achieves exceptional results, effectively doubling the accelerometer range while reducing signal noise by two orders of magnitude. The physical plausibility of the generated signals (evidenced by the low ZVRE) confirms the practical applicability of HEROS-GAN and sets a standard in acceleration signal processing."}]}