{"title": "Disambiguation of Chinese Polyphones in an End-to-End Framework with Semantic Features Extracted by Pre-trained BERT", "authors": ["Dongyang Dai", "Zhiyong Wu", "Shiyin Kang", "Xixin Wu", "Jia Jia", "Dan Su", "Dong Yu", "Helen Meng"], "abstract": "Grapheme-to-phoneme (G2P) conversion serves as an essential component in Chinese Mandarin text-to-speech (TTS) system, where polyphone disambiguation is the core issue. In this paper, we propose an end-to-end framework to predict the pronunciation of a polyphonic character, which accepts sentence containing polyphonic character as input in the form of Chinese character sequence without the necessity of any preprocessing. The proposed method consists of a pre-trained bidirectional encoder representations from Transformers (BERT) model and a neural network (NN) based classifier. The pre-trained BERT model extracts semantic features from a raw Chinese character sequence and the NN based classifier predicts the polyphonic character's pronunciation according to BERT output. In out experiments, we implemented three classifiers, a fully-connected network based classifier, a long short-term memory (LSTM) network based classifier and a Transformer block based classifier. The experimental results compared with the baseline approach based on LSTM demonstrate that, the pre-trained model extracts effective semantic features, which greatly enhances the performance of polyphone disambiguation. In addition, we also explored the impact of contextual information on polyphone disambiguation.", "sections": [{"title": "1. Introduction", "content": "Text-to-speech (TTS) technology has been widely used in voice-assistants, car navigation, e-books and other products. For language based on graphic symbols like Chinese, it is necessary to convert the input character sequence into phoneme sequence before synthesizing speech. Therefore the grapheme-to-phoneme (G2P) conversion component is essential in Mandarin TTS system.\nA Chinese character may have multiple corresponding pronunciations, which is called polyphonic character. Polyphone disambiguation which predicts the correct pronunciation of a polyphonic character is the core issue in Chinese G2P conversion. Fig.1 depicts the flow of Chinese G2P conversion. If the"}, {"title": "2. The proposed approach", "content": "The proposed framework consists of a pre-trained BERT and NN based classifier. Depicted in Fig.2, the pertained BERT extracts semantic features from a raw Chinese character sequence containing polyphonic character, the following NN based classifier predicts polyphonic character's pronunciation according to BERT output. In our research, we explored the performance of classifiers based on fully-connected network, BLSTM and Transformer block respectively."}, {"title": "2.1. The pre-trained BERT", "content": "The pre-trained BERT accepts raw Chinese character sequence as input and outputs a sequence of semantic features. The BERT's architecture is shown in Fig.3, a character embedding layer and positional embedding layer process the input character sequence respectively before getting the embedding sequence. The following Transformer blocks convert embedding sequence to semantic feature sequence. Because the use of Transformer [12] and BERT have been ubiquitous, the structure of Transformer block will not be described in detail here.\nThe BERT model is pre-trained on a large amount of unlabeled data with two prediction task, predicting the masked input characters and predicting the next sentence. The pre-trained BERT model is expected to learn semantic representings from raw character sequence."}, {"title": "2.2. The NN based classifier", "content": "As the pre-trained BERT extracts semantic features from raw character sequence and the pronunciation of a polyphonic character is determined by its contextual semantics, we can directly predict a polyphonic character's pronunciation according to these semantic features. We assume that the polyphonic word is the ith element of the BERT input sequence, The NN based classifier predicts pronunciation based on BERT output and the value of the subscript i. We explored fully-connected network based classifier, LSTM based classifier and Transformer block based classifier in our research."}, {"title": "2.2.1. Fully-connected network based classifer", "content": "First of all, we use a two-layer fully-connected network to predict the pronunciation of polyphonic character according to the ith element of the BERT output sequence. The fully-connected network based classifier is depicted in Fig..4-(a). The first fully-connected layer is shared by all the polyphonic characters. As for the second fully-connected (output) layer, it is not shared. Each polyphonic character has a separate output layer whose units number is equal to the number of possible pronunciations."}, {"title": "2.2.2. LSTM based classifer", "content": "Indicated by [7], contextual information such as the POS of polyphone's neighbor words can also affect the pronunciation of a polyphonic character. So instead of classifying according to the ith element of Bert output sequence directly, we apply Bidirectional LSTM (BLSTM) to model the contextual information before classifying. The LSTM based classifier is shown in Fig.4-(b). The BERT output sequence is processed by a two-layer BLSTM network first to model the contextual information, then a following unshared output layer predicts the pronunciation of corresponding polyphonic character according to the ith element of LSTM output sequence."}, {"title": "2.2.3. Transformer block based classifier", "content": "Due to the characteristics of the recurrent network, nearby locations have a greater impact than farther locations. In order to better analyze the impact of context information, we use Transformer block to model context information. From the perspective of model structure, information at any position is equally important in Transformer block. The Transformer block based classifier depicted in Fig.4-(c). Two-layer Transformer blocks model the contextual information on the BERT output, the following unshared output layer accepts the ith element of Transformer block as input and predicting the pronunciation of corresponding polyphonic character."}, {"title": "3. Experiment and analysis", "content": ""}, {"title": "3.1. Dataset", "content": "The experiments were conducted on a dataset extracted from TTS corpus in Tencent AI Lab. There are 331,325 sentences containing polyphonic characters in the corpus. We selected polyphonic characters which appear in more than 2,000 sentences accounting for 83.7% of the total polyphonic samples. In our experiments, the dataset was divided into 10 subsets randomly keeping the distribution of polyphonic characters, 8 subsets were used for training, one subset was used as development set and the remaining subset as test set. We conducted 10-fold cross-validations to get the final average result."}, {"title": "3.2. Settings of baseline approach", "content": "We took Shan's LSTM approach for polyphone disambiguation in [7] as baseline (LSTM baseline). The LSTM baseline approach needs word tokenization and POS tagging first on the input character sequence. Then the LSTM based model accepts a character embedding sequence and a contextual POS embedding sequence as input. The character embedding is generated from characters composing the word that contains polyphonic character. The POS sequence considering the neighbor words besides the word containing a polyphonic character.\nFig.5 depicts the LSTM baseline approach. The prediction of pronunciation is viewed as a sequence labeling task. The baseline model accepts embedding sequence concatenated by character embedding sequence and POS embedding sequence, and it outputs a label sequence corresponding to the input characters. In our experiments, we set the hidden units of BLSTM to 512, the number of BLSTM layers to 2 and the contextual size to 1 when constructing POS embedding sequence, identical to the setting in [7]."}, {"title": "3.3. Settings of the proposed approach", "content": "In our experiments, we adopted the pre-trained BERT model provided by Google to extract semantic features from raw Chi-"}, {"title": "3.4. Experimental results and analysis", "content": "The experimantal result is depected in Fig.6. All of our proposed methods outperforms the LSTM baseline, showing that the BERT model preprocessed on a large amount of unlabeled data effectively extracts semantic features, which greatly enhances the performance of pronunciation prediction. Comparing BERT + FC with BERT + LSTM and BERT + Transformer block, We can draw the conclusion that the contextal information can really improve the performance for polyphone disambiguation. BERT + LSTM is better than BERT + Transformer block, indicating that contextual information in adjacent locations are more useful than in distant locations.\u4e2d\u6587\nTo further illustrate the impact of contextual information for polyphone disambiguation, we draw the attention weights cropped around the polyphonic character. Fig.8 shows the average cropped attention weight of all the heads in the first Transformer block on test set. The attention weight is cropped around the polyphonic character with neighboring contextual size 5, which means the size of the cropped attention weight is (11, 11) and the location (5, 5) corresponding to the polyphonic character. It can be seen from Fig.8 that the closer to the position of the polyphonic character, the greater the weight of the attention, which indicates that the closer the context information is to the position of the polyphonic character, the more important it is for polyphone disambiguation. This also explains the reason why the LSTM based classifier is better than the Transformer block based one, LSTM can better model closer information due to the characteristics of the recurrent network."}, {"title": "4. Conclusions", "content": "In this paper, we proposed an end-to-end framework for Chinese polyphone disambiguation. The proposed framework accepts raw Chinese character sequence as input without any preprocessing, and it consists of a pre-trained BERT model and a NN based classifier.\nWe implemented three classifiers based on neural network and conducted experiments together with the LSTM baseline [7]. The experimental results demonstrate that the BERT models pre-trained on a large amount of unsupervised data can effectively extract semantic features, which greatly enhances the performance of polyphone disambiguation. Meanwhile, the contextual information can also improve the result of polyphone disambiguation, especially the closer the context is to the polyphonic character, the greater its influence on polyphone disambiguation."}]}