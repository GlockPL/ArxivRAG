{"title": "Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data", "authors": ["Majid Farhadloot", "Arun Sharma", "Alexey Leontovich", "Svetomir N. Markovic", "Shashi Shekhar"], "abstract": "Given multi-type point maps from different place-types (e.g., tumor regions), our objective is to develop a classifier trained on the source place-type to accurately distinguish between two classes of the target place-type based on their point arrangements. This problem is societally important for many applications, such as generating clinical hypotheses for designing new immunotherapies for cancer treatment. The challenge lies in the spatial variability, the inherent heterogeneity and variation observed in spatial properties or arrangements across different locations (i.e., place-types). Previous techniques focus on self-supervised tasks to learn domain-invariant features and mitigate domain differences; however, they often neglect the underlying spatial arrangements among data points, leading to significant discrepancies across different place-types. We explore a novel multi-task self-learning framework that targets spatial arrangements, such as spatial mix-up masking and spatial contrastive pre-dictive coding, for spatially-delineated domain-adapted AI classification. Experimental results on real-world datasets (e.g., oncology data) show that the proposed framework provides higher prediction accuracy than baseline methods.", "sections": [{"title": "Introduction", "content": "Spatial variability is a prominent feature exhibited by many phenomena. In ecology, spatial variability influences species distribution and ecosystem processes such that different plant species might dominate specific areas due to variations in soil quality, light availability, or moisture levels [1]. In agriculture, to account for spatial variability is essential for optimizing resource management and interventions to maximize crop yield [2]. In medical sciences, spatial variability highlights the interaction between maternal and fetal cells across the placental barrier, a crucial factor in Rh incompatibility where an Rh-negative mother may develop an immune response against her Rh-positive fetus [3]. Therefore, comprehending spatial variability is crucial for understanding spatial patterns and phenomena in various contexts. Section 2 describes a bio-medical application domain showcasing the significance of spatial variability in oncology.\nGiven multi-type point maps (e.g., cellular maps) from different place-types (e.g., tumor regions such as tumor-core or interface), our objective is to develop a classifier that can accurately distinguish between two classes (e.g., responder and non-responder) of the target place-type based on their point arrangements. This classifier will be trained using only source place-type learning samples and unlabeled target place-type instances and primarily relies on self-supervision of the data itself. This problem, referred to as unsupervised domain adaptation, involves classifying data from a target place-type distribution using only labeled samples from a different, source place-type distribution.\nHowever, this problem is challenging due to the following reasons. First, spatial variability presents a significant challenge, wherein includes variations in distributions, density, and other morphological features among different place-types. Patterns and arrangements indicative of a class in one domain might not apply in another. As shown in Fig. 1, Spatial Domain 1 distinguishes between class 1 and class 2 using the arrangements of <circle and triangle>. However, due to spatial variability, this same pattern does not distinguish class labels in Spatial Domain 2, where the distinct arrangement is a three-way relationship among the <circle, triangle, and square> data points. A second challenge is that the success of deep neural networks relies on the availability of large labeled datasets, which are time-consuming and expensive to obtain, especially in medical sciences where domain experts are required for annotations [4].\nDomain adaptation has become an emerging area of research to address these challenges. Most prior studies on domain adaptation for spatially delineated"}, {"title": "An Illustrative Application Domain", "content": "In cancer research, understanding tumor interactions with normal tissues is essential for insights on disease progression and immune therapy development. Multiplexed immunofluorescence (MxIF) imaging, especially relevant for immunocheckpoint inhibitor therapy (ICI), offers a detailed cellular spatial map of tumor and immune cells. Fig. 3, shows a map of different cell types (e.g., tumor and immune cells) with their corresponding locations. Although ICI therapy targets cancer cells by activating specific T lymphocytes, its effectiveness depends on complex spatial arrangements within the tumor microenvironment (TME) [14,15].\nWhile recent studies [16-18] offer insight into TME heterogeneity, modeling its spatial variability is challenging due to factors such as rapid cancer cell proliferation, genetic instability, and the presence of unknown mediator cells with immune and target cells. Figure 2 displays spatial variability across a tissue slide using three colored anatomic structures. Furthermore, the MxIF workflow can sometimes result in compromised data quality due to factors such as tissue loss because of iterative cycles of slide washing/staining. Therefore, by leveraging surrounding anatomical structures within remaining tissue on the slide, our method algorithmically characterizes spatial patterns to enhance pathologists' visual assessments and compensate for compromised areas on the slide, thereby mitigating the impact of poor-quality data."}, {"title": "Problem Formulation", "content": "This section reviews key concepts related to our work and presents the formal problem statement."}, {"title": "Basic concepts", "content": "DEFINITION 1. A place-type is a spatial domain $\\mathcal{X}$ associated with a probability distribution $P(\\mathcal{X})$ over instances $X = \\{P_i = (l_i, c_i)| P_i \\in \\mathcal{X}, i = 1,..., n\\}$, where $c_i$ is a non-spatial categorical attribute, $l_i$ is a two-dimensional vector of spatial point features. The set $\\mathcal{X}$ forms a multi-type point map representing objects (e.g., different cell types) and locations.\nFor instance, Fig. 3 displays three multi-type point maps from different place types (i.e., tumor, interface, and normal) classified based on tumor infiltration and cell population.\nDEFINITION 2. A spatial arrangement is the relative positions, or orientations of spatial objects in a space, as well as the patterns and relationships that emerge from their arrangement.\nFor example, co-location patterns [19, 20] are spatial arrangement where subsets of objects frequently occur in close proximity.\nDEFINITION 3. Spatial variability refers to the inherent heterogeneity and variation observed in a set of spatial patterns, structures, properties or arrangements across spatial domains (i.e., place-types).\nFor example, in Fig. 3, the three selected multi-type point maps (from Fig. 2) depicting place-types (e.g., tumor, interface, and normal regions) illustrate significant spatial variability, revealing variations in cell population across a single tissue sample.\nDEFINITION 4. A spatially-delineated domain adapted classification $\\mathcal{C}$ consists of a labeled source place-type $P_{TS} = {(\\mathcal{X}, \\mathcal{Y})}_1^n$, a target place-type $P_{TT} = {(\\mathcal{X})}_1^m$, and a decision function $f_a$ that incorporates underlying spatial arrangements $\\mathcal{A}$ among data points of source and target place-types by modeling spatial variability to address inherent heterogeneity in spatial patterns across place types. The decision function $f_a$ is defined as $f_a(\\mathbf{x},\\mathbf{x},\\mathcal{A}, \\mathcal{A}) = P(y_k|\\mathbf{x},\\mathbf{x}, \\mathcal{A}, \\mathcal{A})|y_k \\in \\mathcal{Y}, k = 1,..., |\\mathcal{Y}|$, where $\\mathbf{x}$ and $\\mathcal{A}$ represent an instance and corresponding arrangements from target place-type $P_{TT}$, and similarly, $\\mathbf{x}$ and $\\mathcal{A}$ are an instance and arrangements from source place-type $P_{TS}$. The decision function maps instances $\\mathbf{x}$ to label probabilities based on arrangements and variability observed across place-types."}, {"title": "Problem Statement:", "content": "The problem of spatially-delineated domain-adapted unsupervised AI classification of multi-type point maps can be expressed as follows:\nInput:\nA labeled source place-type $P_{TS} = {(\\mathcal{X}, \\mathcal{Y})}_1^n$\nA target place-type $P_{TT} = {(\\mathcal{X})}_1^m$ and $\\mathcal{Y} \\in \\mathcal{Y} = \\{1, . . ., |\\mathcal{Y}|\\}$, where $\\mathcal{V}_s = \\mathcal{V}_T$\nOutput: A domain-adapted classifier $\\mathcal{C}$ for class separation within target place-type $P_{TT}$.\nObjective: Solution quality (e.g., Accuracy, F1-score)\nConstraints:\nSpatial variability,\nunlabeled target place-type instances\nIn this problem, we have access to multi-type point maps from a labeled source place-type $P_{TS} = {(\\mathcal{X}, \\mathcal{Y})}_1^n$ and an unlabeled target place-type $P_{TT} = {(\\mathcal{X})}_1^m$, where each multi-type map is associated with one of two class labels (e.g., responder and non-responder). We assume that the target place-type shares the same label space as the source place-type, denoted $\\mathcal{V}_s = \\mathcal{V}_T$. Both the source place-type $P_{TS}$ and the target place-type $P_{TT}$ are associated with distinct probability distributions $P_S(\\mathcal{X})$ and $P_T(\\mathcal{X})$, respectively. Due to spatial variability, the identically distributed assumption is violated, implying that $P_S(\\mathcal{X}) \\neq P_T(\\mathcal{X})$. The objective of the spatially-delineated domain-adapted AI classifier for unsupervised domain adaptation is to accurately classify target place-type instances based on their spatial arrangements."}, {"title": "Proposed Approach", "content": "In this section, we describe the proposed spatially-delineated domain-adapted AI classifier, which consists of spatially-oriented self-supervised learning tasks divided into two sub-modules: spatial mix-up masking and spatial contrastive predictive coding. To account for spatial variability, we explore various pseudo ground truths to train the network using both source and target instances for unsupervised domain adaptation."}, {"title": "Spatial Mix-up Masking:", "content": "Spatial mix-up masking extends the traditional mix-up technique [21] by applying it to both spatial and non-spatial categorical features of multi-type point maps. This method creates new synthetic samples that serve as spatial intermediates between source and target place-type instances. We define a set of self-supervised learning tasks within the family of spatial mix-up masking. These tasks expose the model to handle a broader range of variations, making it less sensitive to specific place-type characteristics and more attuned to underlying spatial arrangements. The learning tasks also enable the model to adapt to changing data distributions and to learn progressively. The objective focus of these tasks is to discriminate between real (source or target) and mix-up samples."}, {"title": "Spatial Mix-up:", "content": "For each pair of source and target instances, $p^s = (\\mathbf{l}^s = (p_x^s, p_y^s), c^s) \\in \\mathcal{X}_s$ and $p^t = (\\mathbf{l}^t = (p_x^t, p_y^t), c^t) \\in \\mathcal{X}_t$, the mixed spatial and non-spatial categorical attributes are computed as follows:\n1. Mixed spatial attributes:\n$\\mathbf{l}_{mix_i} = \\lambda \\cdot (p_x^s, p_y^s) + (1 - \\lambda) \\cdot (p_x^t, p_y^t), \\lambda \\sim \\beta(\\alpha, \\alpha)$ \n2. Mixed non-spatial categorical attribute:\n$c_{mix_i} = \\begin{cases} c^s & \\text{if } u(0, 1) < \\lambda, \\\\ c^t & \\text{otherwise}. \\end{cases}$ \n,where the random variable $\\lambda$ is drawn from a symmetric $\\beta$ distribution with a range specified by the user-defined parameter $\\alpha$. The non-spatial categorical attribute $c_{mix_i}$ is determined based on a uniform distribution $U$, such that $c_{mix_i}$ is categorized as the source place-type if it is less than $\\lambda$; otherwise, it is categorized as the target place-type. To define our first self-supervised classification task, we consider instances from both the source and target place-types ($P_{TS}$ or $P_{TT}$) as positive samples, while instances derived from the mixed place-type $P_{Tmix}$ are considered negative samples, as follows:\n$\\min_{\\theta_{fea}, \\theta_{clsmix}} L_{clsmix} = \\frac{1}{n}\\sum_{i=1}^{n} [\\mathbb{I}\\{x_i\\in P_{TS}\\cup P_{TT}\\} \\log p_i + \\mathbb{I}\\{x_i\\in P_{Tmix}\\} \\log(1 - p_i)]$,\nwhere $\\mathbb{I}\\{x_i\\in P_{TS}\\cup P_{TT}\\}$ and $\\mathbb{I}\\{x_i\\in P_{Tmix}\\}$ are indicator functions that equal 1 for samples belonging to $P_{TS}$ or $P_{TT}$ (positive samples) and $P_{Tmix}$ (negative samples), respectively, and $p_i$ is the predicted probability of the $i$-th sample being positive."}, {"title": "Spatial Masking:", "content": "A set of predefined geometries (e.g., square, rectangle) is used to mask the same sub-regions from pairs of source and target place-type instances. For each instance, the choice of geometry, the center location of each shape, and the proportion of masking in each batch are randomized to prevent models from overfitting to specific shapes and locations. Once the geometry is defined, all points within the mask from source $P_{TS}$ are replaced by those from target $P_{TT}$. Algorithm 1 details the overall process of spatial mask and mixing, where the output is a mask mix place-type, denoted by $P_{TmaskMix}$, along with ratios of the source and target instances in each instance of $P_{TmaskMix}$. These ratios are detailed in a later part for a regression-like self-supervised task.\nThe second self-supervised classification task involves discriminating among multiple classes. The first and second classes include instances from the source 0 and target 1 place-types, respectively. The third class 2 includes instances that are mixed through local mask mixing perturbation. Given this set of local mask mix-up labels denoted by $L_{maskMix}$, and the total number of samples denoted by $N = n_s + n_t + N_{maskMix}$, the objective for our classifier is as follows:\n$\\min_{\\theta_{fea}, \\theta_{clsmaskMix}} L_{clsmaskMix} = \\frac{1}{N} \\sum_{i=1}^{N} \\sum_{l=1}^{L_{maskMix}}[\\mathbb{I}(l = P_{TS}) \\log p_{i,l}] + [\\mathbb{I}(l = P_{TT}) \\log p_{i,l}] + [\\mathbb{I}(l = P_{TmaskMix}) \\log p_{i,l}]$.\nIn the third self-supervised task, soft-labeling is used where the proportion of the preserved source instance in local mask mixing determines its soft-label, provided that the original label is known. The complementary label represents the proportion of the target instance within the revised mix-up sample. These details are outputted by Algorithm 1. For instance, if the original source instance is labeled as 1 and 80% of it is preserved, the new soft-label for the source component becomes 0.8 of the original label, and the remaining 0.2 reflects the proportion of the target instance in $P_{TmaskMix}$. The objective function for this task is as follows:\n$\\min_{\\theta_{fea}, \\theta_{clssoftMix}} L_{clssoftMix} = \\frac{1}{N} \\sum_{i=1}^{N} [\\alpha_i \\log p_{i,s} + \\beta_i \\log p_{i,T}]$,\nwhere $\\alpha_i$ and $\\beta_i$ are the proportions of the source and target instances in the $i$th mixed instance. For example, if 80% of the mix comes from the source and 20% from the target, then $\\alpha_i = 0.8$ and $\\beta_i = 0.2$. This approach introduces a more local spatial perturbation that encourages the model to adapt its understanding of source data by incorporating spatial arrangements from the target domain, thereby fostering the learning of domain-invariant features. More importantly, this method may also facilitate domain-specific insights, such as in oncology, by using spatial masking to simulate real-world spatial behaviors. For instance, spatial masking could mimic patterns of immune cell infiltration within tumor tissues, where specific regions are masked and replaced with cells from surrounding areas. This approach helps the model learn to recognize spatial variability between different types of tissue (e.g., healthy vs. tumor) while still leveraging the labels from the original source instances."}, {"title": "Spatial Contrastive Predictive Coding:", "content": "Contrastive predictive coding [22] has shown great promise in unsupervised learning by predicting future states in latent space using powerful sequence models such as LSTM and auto-regressive models. However, unlike sequential models that inherently depend on time series, we employ an equivalent notion, that is the \"same place-type\". More precisely, our spatial contrastive predictive coding (SCPC) considers latent representations of instances from the same place-type as similar (i.e., positive pairs), and those from different place-types as dissimilar (i.e., negative pairs), as illustrated in the bottom right of Fig. 4.\nGiven $P_{TS} = {\\mathcal{X}_i\\}_{i=1}^{n_s}$ and $P_{TT} = {\\mathcal{X}_i\\}_{i=1}^{n_t}$ representing the input instances, and the corresponding latent encodings $(z_i^s, z_i^t, z_2^s, z_2^t, ..., z_{n_s}^s, z_{n_t}^t)$ obtained from a DNN architecture (e.g., DGCNN [23], SAMCNet[24]), along with a context vector $c_t$ from a recurrent model (e.g., GRU), then the objective is as follows:\n$L_{SCPC} = -\\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{\\exp(sim(z_j, z_i)/T)}{\\sum_{z_k \\in \\{z_j\\} \\cup \\mathcal{N}(i)} \\exp(sim(z_j, z_k)/T)}$,\nwhere $\\exp(sim(z_j, z_i)/T)$ is the exponential of the similarity score for the positive pair (same place-type), scaled by the temperature parameter $T$, $\\sum_{z_k \\in \\{z_j\\} \\cup \\mathcal{N}(i)}$ is the summation over the positive pair $z_i$ and all negative pairs $z_k$ from the set $\\mathcal{N}(i)$, $sim(z_j, z_k)$ is the similarity score between the predicted latent vector $z_j$ and a negative latent vector $z_k$, and $\\frac{1}{N} \\sum_{i=1}^{N}$ denotes averaging over all instances (i.e., $N = (2)+(t)+ns \\times nt$)."}, {"title": "Validation", "content": "Experimental Settings: Our experiments were designed to answer the following questions.\n1. How does proposed work compared to competing DNN methods?\n2. How does the choice of deep learning architecture for learning spatial relationships affect classification performance?\n3. What impact do spatial self-supervised tasks have on solution quality?\nDatasets: The experiments were conducted using a real-world cancer dataset derived from MxIF images 1.\nThis dataset consists of three distinct place-types: (1) normal denoted as PT1, (2) interface, denoted as PT2, and (3) tumor, denoted as PT3. For place-type PT1, the dataset contained 81 multi-type point maps representing two different clinical outcomes of immune therapy. Of these, 38 sets were labeled as responders, while 43 were classified as non-responders, signifying individuals who progressed and experienced tumor recurrence within a year. For place-type PT2, the dataset contained 145 multi-type point maps. Out of these, 68 were identified as responders, with the remaining 77 labeled as non-responders. Lastly, in place-type PT3, out of the 103 point sets provided, 30 were labeled as responders, and 73 as non-responders. The first classification task (PT1ToPT2) involved training on source place-type (PT\u2081) and testing on target place-type (PT2), while the second task (PT2ToPT1) operated in the opposite direction. The third classification task (PT2ToPT3) entailed training on a source place-type (PT2) and testing on target place-type (PT3), with the fourth task (PT3TOPT2) reversing this direction.\nDataset Preparation: In each classification task, we divided the data into 80% training and 20% testing. Twenty five percent of the training set was selected to be the validation set. Due to the limited number of"}, {"title": "Experiment Results:", "content": "Results of our spatially-delineated domain-adapted AI classification assessment were as follows.\nComparative Analysis: We conducted experiments to evaluate various DNN architectures for the classification tasks described in Section 5.1. The results across all tasks are summarized in Tables 1 and 2. These results demonstrated the superiority of our proposed method over the existing DNN competition, including DANN, DefRec+PCM, and GAST, across most of the classification metrics. Most notably, as shown in Table 1, our method using DGCNN as the encoder improved classification accuracy over the best competitor by margins of 6.0%, 7.0%, and 8.0% in the PT1T0PT2, PT2T0PT1, and PT3T0PT2 classifications, respectively. Similarly, our method with SAMCNet significantly enhanced classification accuracy over the best competitor by margins of 4%, 24%, 18.0%, and 14.0% in the PT1T0PT2, PT2ToPT1, PT2T0PT3, and PT3TOPT2 classifications, respectively, as illustrated in Table 2. More importantly, our method consistently yielded positive adaptation gains, whereas the existing competition often resulted in negative or no adaptation gains compared to the lower bound.\nFrom a clinical perspective, PT2 serves as an intermediate representation between the periphery (PT1) and the core (PT3), reflecting spatial transitions between these regions. This positioning likely facilitates closer alignment with supervised settings when transitioning to PT1 and PT3. Conversely, the greater heterogeneity and class imbalances in PT1 and PT3-compared to the more intermediate PT2-may hinder the model's ability to effectively learn and transfer knowledge to PT2.\nMoreover, it can be observed that the choice of DNN architecture may play a significant role due to the importance of learning spatial relationships in multi-type point maps. Our proposed with SAMCNet as encoder was able to improve accuracy over DGCNN [23] by a margin of 13%, 15%, 6%, and 7% in the PT1T0PT2, PT2T0PT1, PT2ToPT3, and PT3T0PT2 classifications, respectively."}, {"title": "Sensitivity Analysis:", "content": "To evaluate the primary self-supervised learning tasks in our proposed framework, we explored how the model performs with and without these tasks. We focused on key elements like spatial mix-up masking (SMUM) and spatial contrastive predictive coding (SCPC), and we used a variety of classification measures to assess their impact. The findings are presented in Table 3. SAMCNet [24] served as the backbone encoder for this experiment.\nThe results show that using SMUM (Spatial Mix-Up Masking) is beneficial in exposing the model to a diverse set of spatial arrangements and facilitating domain-specific insights, where spatial masking can potentially mimic patterns such as immune cell infiltration within tumor tissues. Similarly, SCPC (Spatial Context Prediction Consistency) is effective in learning spatial arrangements that are consistent within each place-type while distinguishing between different place-types. By applying an autoregressive model that predicts the latent embedding of another instance from the same place-type, SCPC encourages the model to capture meaningful spatial dependencies within each place-type. Yet, the proposed model performs best when both submodules-SMUM and SCPC-are integrated and work together as a cohesive unit."}, {"title": "Case Study", "content": "We conducted a case study aimed at comparing intracellular interactions using our proposed framework versus a supervised learning method on the target place-type, to classify input samples as either responder or non-responder. For this, we utilized a trained SAMCNet [24] DNN to extract features after the point pair prioritization network at layer-4, where the model has learned spatial and prioritization associations. We evaluated the significance of the identified spatial relationships using permutation feature importance. This metric measures the importance of a feature by assessing the decrease in model performance when the feature space is randomly shuffled. Previous studies show the effectiveness of interpretable models that employ hand-constructed spatial quantification methods (e.g., participation ratio [19]), combined with decision tree algorithms [26]. Tables 4 and 5 list the top five most relevant spatial associations found within tumor-core PT3, and a supervised method trained solely on the target place-type samples. The following provides a brief interpretation of these results from a clinical perspective.\nClinical Implications: What is known to correlate with clinical outcomes is the penetration of cytotoxic T lymphocyte cells (CD8) into tumor-core. Thus, the presence of more tumor-infiltrating CD8 cells typically indicates better outcomes. This is because CD8 immune cells are the only ones capable of destroying cancer cells, and they must physically contact these cells to do so. However, not all CD8 cells can kill tumor cells; for example, CD8 immune cells with PD1 receptors can be inhibited by PDL1 ligands (found on tumors or cells surrounding tumors like tumor-infiltrating macrophages), which disable the CD8 cells' ability to kill. Therefore, the effectiveness of an infiltrating CD8 cell is heavily influenced by its immediate environment and the cells surrounding the cancer target cell. This suggests a dynamic relationship involving a target cell (tumor cell), an effector cell (CD8 T cell), and a modulator cell (nearby cell regulating interactions between the target and effector cells).\nOur proposed method demonstrates that factors beyond the \"tumor-cell/CD8 cell\" interaction are relevant, and it suggests that \"macrophages\" may serve as the \u201cmodulator\" cell. Therefore, it is crucial to explore how macrophages can interfere with the CD8/tumor cell interaction and influence the survival of the tumor cell. Macrophages may affect this interaction either through secreted factors that influence both cells as they interact or through molecules expressed on their surface that modulate CD8 cell activity towards the tumor cell. One such model involves the expression of PDL1 on macrophages; PDL1 on the macrophage directly engages the CD8 PD1 receptor to deactivate the CD8 cell, rendering it incapable of killing the tumor cell. However, this is just one of many mechanisms, all of which require close contact between the 'modulator' cell and the CD8-tumor cell complex. Additionally, this cellular arrangement can also be observed through a supervised"}, {"title": "Related Work", "content": "Domain adaptation (DA) addresses the challenge of utilizing a well-labeled source domain dataset to enhance performance on a completely unlabeled target domain dataset. Most prior research in unsupervised domain adaptation for spatially-delineated classification of multi-type point maps is classified into adversarial [5-8] or self-supervised learning approaches [10-13].\nUnsupervised Adversarial Adaptation: Adversarial techniques aim to align source and target domains using a min-max optimization strategy between discriminators and generators [27]. The idea is that the feature representation should be good for the main learning task while being similar enough between the two domains [5,8]. Early work includes the domain adversarial neural network [5], which uses a gradient reversal layer to mitigate distribution shifts and ensure similar feature distributions across the two domains. Adversarial discriminative domain adaptation generalizes domain adaptation by independently mapping source and target domains with untied weights, initializing the target model from a pre-trained source model, and fine-tuning it with adversarial training [28].\nThese frameworks have been adapted for point set domain adaptation. PointDAN[6], the first work to address point set classification via domain adaptation, used adversarial training with maximum classifier discrepancy along with GRL to jointly learn and align both local and global features across source and target domains [6,8]. PointDGAN extends PointDAN by integrating generative adversarial networks (GANs) to generate synthetic point clouds that bridge the gap between source and target domains [29]. Despite fundamental works and significant advancements, adversarial training can still lead to degenerated local minima, potentially resulting in negative adaptation gains.\nSelf-supervised Learning Adaptation: Self-supervised learning techniques focus on designing tasks that do not require labeled data but instead leverage the inherent structure of the data to learn domain-invariant features and mitigate domain differences. Achituve et al. [10] enhanced model training by introducing volume-based and sample-based deformation reconstruction for shape prediction, and point cloud mix-up to estimate proportions of mixed inputs. GAST [12] has introduced a geometry-aware, self-supervised training method that encodes domain-invariant geometric features into semantic representations to mitigate domain discrepancies in point-based representations. Shen et al. [11] leverage implicit representations to capture and preserve the underlying geometry of point sets. The core idea is to align the implicit representations across different domains, moving beyond mere point-wise feature alignment to mitigate domain shifts through geometry-aware implicit representations.\nWhile state-of-the-art methods, all these works overlook the underlying spatial arrangements among data points, leading to substantial discrepancies among different place types. Moreover, similar works [21,30-32] have explored feature alignments between source and target instances in a shared latent space across various data modalities (e.g., images, feature vectors) to mitigate distribution shifts between domains. Our work leverages ideas from these studies to explicitly target both global and local underlying spatial arrangements that respect the inherent structure of the data for domain adaptation across place-types while preserving our understanding of crucial spatial patterns."}, {"title": "Conclusion & Future Work", "content": "We investigated a spatially-delineated domain adapted classification DNN for multi-type point maps. Our approach introduces a multi-task learning framework where surrogate classification tasks through self-supervised tasks are defined to learn representations that capture the underlying spatial arrangements across different place-types. Experiments show that the proposed model outperforms existing DNN techniques.\nFor future research, we aim to integrate domain-specific knowledge into self-supervised learning tasks to better capture spatial relationships across place-types. We also aim to examine the heterogeneity and transitional patterns between source and target place types, focusing on bi-directional domain adaptation strategies to optimize mutual information [33,34]. Additionally, while numerous models have been proposed, limited attention has been given to the data itself. Thus, we plan to investigate spatially-characterized synthetic data generation methods that preserve the structural characteristics of the original data while ensuring privacy. This approach will enable more controlled experimentation and enhance our understanding of spatial variability."}, {"title": "Spatial Mix-up Masking Pseudocode", "content": "The pseudocode detailed in Algorithm 1 presents the proposed spatial mask and mixing process that operates on two distinct multi-type point maps: a set of source point maps $P_{TS} = {x^s}_1^{n_s}$ and a set of target point maps $P_{TT} = {x^t}_1^{n_t}$. The algorithm iteratively processes each instance pair by first selecting a random geometric shape g from a predefined set G and positioning it at random coordinates (gx, gy) to construct a mask $M_g$ whose size is determined by a randomly sampled mask proportion $p_{mask} \\sim U(0.1, 0.5)$; subsequently, points from both the source and target that fall under the mask's area are identified. Next, it performs the mixing operation by replacing the masked source points with corresponding target points to create a mixed instance $x_{mix} = (x^s \\setminus S_{M_g}) \\cup T_{M_g}$, while also computing two additional components: the proportion of unchanged source points $S_{ratio} = \\frac{S_{remaining}}{|x^s|}$ (where $S_{remaining} = |x^s|-|S_{M_g}|$) and the proportion of newly incorporated target points $T_{ratio} = 1- S_{ratio}$, with each mixed instance and its corresponding ratios being stored in the results list that forms the algorithm's final result."}]}