{"title": "Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM", "authors": ["Trisha Das", "Dina Albassam", "Jimeng Sun"], "abstract": "Medical dialogue systems (MDS) enhance patient- physician communication, improve healthcare ac- cessibility, and reduce costs. However, acquiring suitable data to train these systems poses significant challenges. Privacy concerns prevent the use of real conversations, necessitating synthetic alterna- tives. Synthetic dialogue generation from publicly available clinical notes offers a promising solution to this issue, providing realistic data while safe- guarding privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot prompting and a feedback loop to generate and refine high- quality synthetic dialogues. The feedback consists of weighted evaluation scores for similarity and extractiveness. The iterative process ensures dia- logues meet predefined thresholds, achieving supe- rior extractiveness as a result of the feedback loop. Additionally, evaluation shows that the generated dialogues excel in factuality metric compared to the baselines and has comparable diversity scores with GPT4.", "sections": [{"title": "Introduction", "content": "Effective communication between patients and physicians is crucial for accurate diagnosis and treatment planning in healthcare. Medical dialogue systems (MDS) facilitate this communication by enabling inquiries beyond self-reports and provid- ing automated diagnoses and recommendations. MDS help extend medical accessibility, enhance patient experiences, and reduce healthcare costs. However, privacy concerns restrict the use of real patient conversations for MDS training, necessitat- ing the synthesis of dialogues. Clinical notes in Electronic Health Records (EHRs) are written doc- uments that detail a patient's medical history, symp- toms, diagnoses, and treatments during healthcare visits. These notes can be utilized to generate syn- thetic dialogues between patients and physicians to train MDS effectively, ensuring they are well- equipped to handle diverse healthcare scenarios.\nIn this work, our main motivation is to build a model that can generate high quality synthetic dia- logue datasets from clinical notes with the ultimate goal to maintain the following: first, to adhere to HIPAA regulations and mitigate privacy risks as- sociated with real patient data; second, to address the limited availability of benchmark datasets and facilitate the development and evaluation of health- care dialogue systems; third, to overcome the lack of realistic multiturn dialogue datasets, crucial for modeling real-world healthcare conversations.\nTo address these goals, we propose SynDial, a novel approach utilizing publicly available MTS- Dialogue and MIMIC datasets to generate synthetic medical dialogue data, with potential applications in other clinical notes datasets. Our approach em- ploys a single LLM through zero-shot prompting to generate the dialogues, iteratively refining the output until high-quality dialogues are produced. During this iterative process, the generated dia- logues are evaluated using initial thresholds for similarity and extractiveness to ensure they meet desired quality standards. These initial metrics are used solely for refining the dialogues during gener- ation. This iterative process aims for high quality, differentiating our method from earlier work by ensuring the generated dialogues meet predefined thresholds. Additionally, the intrinsic and extrin- sic evaluation results for generated dialogues from SynDial have shown superior results in extrac- tiveness and factuality metrics compared to other baselines. The introduction of a feedback loop is motivated by the need to enhance the quality of the generated dialogues, addressing issues that arise without such iterative refinement."}, {"title": "Related work", "content": ""}, {"title": "Medical Dialogue Systems", "content": "Medical dialogue systems are designed to im- prove interactions between patients and healthcare providers by utilizing advanced natural language processing and machine learning techniques. These systems assist in diagnosing conditions, offering medical advice, and efficiently managing patient data. Various approaches to developing medical dialogue systems include deep reinforcement learn- ing (Tang et al., 2016; Wei et al., 2018; Xu et al., 2019), pretrained language models (Varshney et al., 2023), sequence-to-sequence models (Lin et al., 2019), and meta-learning techniques (Lin et al., 2021). Additionally, some methods incorporate knowledge graphs to enhance the system's under- standing and performance (Lin et al., 2019; Varsh- ney et al., 2023)."}, {"title": "Generating datasets for MDS training", "content": "Recent advancements in MDS have significantly impacted the medical field. Some recent works have been done in generating synthetic patient- physician dialogue as an aim for providing a high quality of synthetic data that can be used for train- ing MDS while protecting patient's privacy. The work in (Wang et al., 2023), proposed \"NoteChat\", a novel multi-agent framework using Large Lan- guage Models (LLMs) to generate synthetic patient- physician dialogues conditioned on clinical notes. NoteChat's structure includes Planning, Roleplay, and Polish modules. The Planning module focuses on knowledge organization to maintain medical logic. The Roleplay module employs two Chat- GPT(GPT3.5Turbo) agents acting as patient and physician to produce interactive dialogues. Fi- nally, the Polish module refines these dialogues to align closely with medical professional standards. The system was evaluated using the MTS-dialogue dataset on extensive intrinsic and extrinsic evalua- tion methods, and demonstrated improved perfor- mance over other models. Another study (Zeng et al., 2020), introduces \"MedDialog,\" a substantial collection of medical dialogues in both Chinese and English, forming the largest known dataset of its kind to date. MedDialog's approach to dialogue generation involves sequence-to-sequence model- ing, utilizing advanced methods like BERT-GPT, to train models capable of producing contextually relevant and medically accurate conversations. The paper explores the effectiveness of these models and evaluates their performance on the MedDia- log dataset, comparing them with other datasets to highlight their comprehensive coverage and diver- sity."}, {"title": "Method", "content": "In this section, we introduce our methodology, SynDial, which forms the core of our research. We will provide a detailed overview of the datasets employed and the evaluation metrics utilized to assess the efficacy of our approach in generating medical dialogues."}, {"title": "SynDial", "content": "The SynDial approach, as illustrated in Figure 1, begins by checking if the clinical note's length nearly exceeds the maximum token input for GPT- 3.5 (if >4000). If it does, the note is first sum- marized by prompting GPT3.5 to makes it < 300 tokens. Subsequently, the clinical note is input into the LLM (GPT-3.5) to generate a dialogue between a patient and physician using zero-shot prompting. The generated dialogue is then initially evaluated and refined using the ROUGE-1 F1 metric for both similarity and extractiveness. Similarity measures how closely the generated dialogue matches a ref- erence dialogue, while extractiveness assesses how much information in the dialogue is directly ex- tracted from the clinical note.\nThe ROUGE-1 F1 score is calculated using the following equation:\nROUGE-1 F1 = 2 \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}}\nwhere precision is the fraction of relevant words retrieved from the generated dialogue, and recall is the fraction of relevant words retrieved from the reference dialogue.\nThe approach is flexible and can be tweaked using the parameter \u03b1, allowing for a balance be- tween extractiveness and similarity. The combined score is calculated using the equation:\ncombined_score = (1-\u03b1)\u00b7score_extr+\u03b1\u00b7score_sim\nIf the dialogue meets predefined thresholds for the combined score, the process terminates, and the dialogue is saved. If not, a feedback loop sends the clinical note back to the LLM, along with the previously calculated similarity and extractiveness scores, to improve the dialogue. This loop contin- ues until the dialogue meets the thresholds or until it has run three times. If it runs three times without meeting the thresholds, the best dialogue generated in terms of the combined score is selected. After evaluating the approach, the same process is ap- plied for other datasets, focusing on extractiveness when ground-truth dialogues are not available."}, {"title": "Datasets", "content": "We utilize two datasets: MIMIC-IV (Johnson et al., 2023) and MTS-Dialogue (Abacha et al., 2023). The MIMIC datasets are large publicly available electronic health records comprising 123,488 pa- tients with 232,263 visits, averaging 1.88 visits per patient. We used 80 samples from the MIMIC-IV dataset for our experiments. Each patient typically has one to two visits, each corresponding to a dis- charge summary. These discharge summaries are used to generate synthetic dialogue datasets.\nThe MTS-Dialogue dataset contains clinical notes and corresponding ground truth conversa- tions for each sample. It includes 1,701 pairs of di- alogues and associated sections from clinical notes, with an overall of 15,969 turns, 18,406 sentences, and 241,685 words in dialogues, and summaries consisting of 5,870 sentences. For our experiments, we used the MTS-Dialogue test dataset contain- ing 20 samples and the training dataset containing 1,200 samples, which were used for fine-tuning Llama2 models during extrinsic evaluation."}, {"title": "Baselines", "content": "\u2022 GPT3.5 and GPT4 both are using one detailed zero-shot instruction prompting to generate the dialogue between patient and physician (Wang et al., 2023).\n\u2022 NoteChat uses two LLMs (GPT3.5Turbo) where one acts as patient and the other as physician to generate a multi-turn conversa- tion(Wang et al., 2023)."}, {"title": "Evaluation metrics", "content": "We evaluate our model and the baseline models based on both intrinsic and extrinsic evaluation metrics."}, {"title": "Intrinsic evaluation", "content": "\u2022 Similarity: ROUGE-F1 is calculated to mea- sure the similarity of the generated conversa- tion and the ground-truth dialogues.\n\u2022 Factuality: Concept-Recall is calculated us- ing GPT3.5 to extract medical concepts from model-generated dialogues and notes to get two corresponding concept lists and then cal- culate the overlap of medical concept.\n\u2022 Extractiveness: ROUGE-F1 of src->hypo as- sesses how much information in the dialogue is extracted directly from the clinical note.\n\u2022 Diversity: Self-BLEU calculates the variety in the generated patient and physician utter- ances."}, {"title": "Extrinsic evaluation", "content": "For extrinsic evaluation, we first finetuned a Llama- 2 models on MTS-Dialogue training dataset and"}, {"title": "Experiments and Results", "content": "In this section, we describe the different experi- ments we have done including comparison with baselines for intrinsic evaluation, extrinsic evalua- tion, reward comparison, robustness check and cost comparisons."}, {"title": "Comparison with baselines", "content": "We compared our model on the MTS-Dialogue dataset with the baseline models. As done in the NoteChat (Wang et al., 2023) paper, we compared four different intrinsic evaluation metrics across all the methods. The metrics (similarity, extrac- tiveness, factuality, diversity) are described in Sec- tion 4. Table 1 shows the comparison among all the methods across all the four intrinsic evaluation metrics. We can clearly see that SynDial is per- forming best for extractiveness and factuality. For our case (with MIMIC dataset), where we do not have the ground truth dialogues available for each clinical note, we find extractiveness and factuality as the most important evaluation metrics. Diversity if SynDial is comparable with GPT4 which is reasonable.\nFor similarity and extractiveness we calculated Rouge1-F1 scores as described in section 4.4.1. We utilize rouge-score 0.1.2 python package (Lin, 2004) for calculating rouge scores. For factuality, we used gpt3.5 to first extract 2 sets of medical concepts from the note and the generated dialogue. Then we use porter stemmer stemming algorithm to process the medical concepts from both sets. Finally, we find the intersection of the sets and cal- culate recall. For diversity, we calculated self-bleu scores inspired by the github repository of (Zhu et al., 2018). We calculated extractiveness and fac- tuality for a subset of 80 samples from the MIMIC IV dataset (Table 2). For MIMIC IV data, we do not have the ground truth dialogues, so we can not calculate similarity with ground truth."}, {"title": "Extrinsic evaluation", "content": "For extrinsic evaluation, we first finetuned a Llama- 2-7b-hf model on the MTS-Dialogue training dataset (1200 samples) and calculated extractive- ness (Rouge 1 F1 score). We also finetuned an- other Llama-2-7b-hf model with MTS-Dialogue training dataset augmented with MIMIC dataset generated by our method. We hope that adding our dataset will improve the score if tested on MTS- Dialogue test data. Table 4 shows the scores for ex- trinsic evaluation. Augmenting the MTS-Dialogue training dataset with synthetic MIMIC dialogues helped to elevate the Rouge 1 F1 score for Conver- sation2Note downstream task."}, {"title": "Experiment for robustness check", "content": "We run the same pipeline (Fig. 1) for three times and average the scores. We find that the scores are not too diverse with only a standard deviation of 0.007 for similarity rouge scores and a standard deviation of 0.003 for extractiveness rouge scores. This experiment shows that the scores are not ran- dom and are consistent enough."}, {"title": "Cost comparison", "content": "We also compared SynDial with NoteChat (Wang et al., 2023) which is the state-of-the-art model that also generates dialogues from clinical notes. SynDial is far cheaper in terms of API calls compared to NoteChat (Figure 2). Also, al- though NoteChat is better in terms of similarity to ground truth dialogues and diversity, we think it is definitely more important to have better extractive- ness and factuality scores."}, {"title": "Limitations and Future Work", "content": "In the initial phase of our research, we utilized 80 samples from the MIMIC IV dataset to demon- strate performance. However, for the forthcoming paper, we plan to incorporate a larger sample size and integrate data from the MIMIC III dataset. Our"}, {"title": "Conclusion", "content": "In this paper, we presented SynDial, a novel ap- proach for generating synthetic patient-physician dialogues from clinical notes using a single large language model (LLM) with a feedback loop mech- anism. Our method addresses the challenges of data scarcity and privacy in training medical dia- logue systems by leveraging publicly available clin- ical notes datasets such as MIMIC-IV and MTS- Dialogue. Through extensive experiments, we demonstrated that SynDial significantly outper- forms existing baseline models in terms of extrac- tiveness and factuality, making it a valuable tool for creating high-quality synthetic dialogue datasets.\nFurthermore, we showed that our approach is cost-effective compared to the state-of-the-art mod- els like NoteChat, which rely on multiple LLM instances. SynDial also provides consistent re- sults across multiple runs, ensuring robustness in the generated dialogues.\nFuture work will focus on scaling up the dataset size and incorporating more advanced feedback mechanisms to further enhance the quality of the generated dialogues. Additionally, we plan to explore the impact of integrating synthetic dia- logues from multiple sources to improve the per- formance of downstream tasks, such as the Conver- sation2Note task.\nOverall, SynDial offers a promising solution for advancing medical dialogue systems while maintaining patient privacy and reducing the de- pendency on real-world data."}, {"title": "Conflicts of interest", "content": "The authors have no competing interests to declare."}, {"title": "Data availability", "content": "The datasets used in this study are pub- licly available. The MIMIC-IV dataset can be accessed at https://physionet.org/ content/mimiciv/2.0/ (Johnson et al., 2023). The MTS-Dialogue dataset is avail- able at https://github.com/abachaa/ MTS-Dialogue (Abacha et al., 2023)."}, {"title": "Appendix", "content": null}, {"title": "Zero-Shot Dialogue Prompting", "content": "The zero-shot prompting used in our approach for dialogue generation is as follows:\nprompt = f\"\"\"\nGiven the clinical note, write a\nconversation between the patient\nand the doctor from the clinical\nnotes so that the main keywords\nare covered.\n\" + \\\n\"(\"the combined rouge score\nfor both extractiveness and\nsimilarity for the previous\ndialog was\n\" + str(combined_score) + \" for this\nnote \" + row['note'] + \\\n\"generate a new one and try\nto improve the accuracy where\nthe extractiveness should\nweigh\"+(1-alpha)+\"and the\nsimilarity should weigh\"+alpha)\nDialogue:\n\"\"\""}, {"title": "Experiments with historical visits", "content": "We tried to incorporate information from previous visit of a patient in the prompt to help generating dialogue for that patient's current visit. However, we notice that the scores do not improve much. Figure 3 shows the score for 5 patients. Each color denotes a different patient. For each patient we plot the Rouge 1 F1 score for generated dialogues independent of the previous visit (denoted with filled circles). We also plot the scores where for each visit (except visit 1 of each patient), the previ- ous visit's dialogue is also used in the prompt and SynDial's pipeline is used to generate dialogues. We see a decrease in overall scores for the second case (x marks in the graph)."}, {"title": "Improvement in Extractiveness Scores", "content": "We conducted a visual analysis to observe the changes in extractiveness scores within the MTS- Dialogue dataset across three iterations, as illus- trated in Figures 4 and 5. It was observed that, out of 20 clinical notes, 11 showed improvements in ex- tractiveness scores across at least two consecutive iterations."}, {"title": "Hyperparameter tuning", "content": "Table 5 shows the similarity and extractiveness scores when we tune the hyperparameter \u03b1 which balances the priority of similarity and extractive- ness. When \u03b1 is 0, then full weight goes to extrac- tiveness. If \u03b1 is 1, the similarity score is calculated only as reward. When there are no ground truth dialogues, we need to select alpha = 0. How- ever, if there are both the notes and corresponding ground truth dialogues the value for \u03b1 can be cho- sen based of the need of the users. From Table 5 we find \u03b1 = 0.1 is good for both similarity and extractiveness."}]}