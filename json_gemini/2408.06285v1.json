{"title": "Synthetic Patient-Physician Dialogue Generation from Clinical Notes Using LLM", "authors": ["Trisha Das", "Dina Albassam", "Jimeng Sun"], "abstract": "Medical dialogue systems (MDS) enhance patient-physician communication, improve healthcare accessibility, and reduce costs. However, acquiring suitable data to train these systems poses significant challenges. Privacy concerns prevent the use of real conversations, necessitating synthetic alternatives. Synthetic dialogue generation from publicly available clinical notes offers a promising solution to this issue, providing realistic data while safeguarding privacy. Our approach, SynDial, uses a single LLM iteratively with zero-shot prompting and a feedback loop to generate and refine high-quality synthetic dialogues. The feedback consists of weighted evaluation scores for similarity and extractiveness. The iterative process ensures dialogues meet predefined thresholds, achieving superior extractiveness as a result of the feedback loop. Additionally, evaluation shows that the generated dialogues excel in factuality metric compared to the baselines and has comparable diversity scores with GPT4.", "sections": [{"title": "Introduction", "content": "Effective communication between patients and physicians is crucial for accurate diagnosis and treatment planning in healthcare. Medical dialogue systems (MDS) facilitate this communication by enabling inquiries beyond self-reports and providing automated diagnoses and recommendations. MDS help extend medical accessibility, enhance patient experiences, and reduce healthcare costs. However, privacy concerns restrict the use of real patient conversations for MDS training, necessitating the synthesis of dialogues. Clinical notes in Electronic Health Records (EHRs) are written documents that detail a patient's medical history, symptoms, diagnoses, and treatments during healthcare visits. These notes can be utilized to generate synthetic dialogues between patients and physicians to train MDS effectively, ensuring they are well-equipped to handle diverse healthcare scenarios.\nIn this work, our main motivation is to build a model that can generate high quality synthetic dialogue datasets from clinical notes with the ultimate goal to maintain the following: first, to adhere to HIPAA regulations and mitigate privacy risks associated with real patient data; second, to address the limited availability of benchmark datasets and facilitate the development and evaluation of healthcare dialogue systems; third, to overcome the lack of realistic multiturn dialogue datasets, crucial for modeling real-world healthcare conversations.\nTo address these goals, we propose SynDial, a novel approach utilizing publicly available MTS-Dialogue and MIMIC datasets to generate synthetic medical dialogue data, with potential applications in other clinical notes datasets. Our approach employs a single LLM through zero-shot prompting to generate the dialogues, iteratively refining the output until high-quality dialogues are produced. During this iterative process, the generated dialogues are evaluated using initial thresholds for similarity and extractiveness to ensure they meet desired quality standards. These initial metrics are used solely for refining the dialogues during generation. This iterative process aims for high quality, differentiating our method from earlier work by ensuring the generated dialogues meet predefined thresholds. Additionally, the intrinsic and extrinsic evaluation results for generated dialogues from SynDial have shown superior results in extractiveness and factuality metrics compared to other baselines. The introduction of a feedback loop is motivated by the need to enhance the quality of the generated dialogues, addressing issues that arise without such iterative refinement."}, {"title": "Related work", "content": ""}, {"title": "Medical Dialogue Systems", "content": "Medical dialogue systems are designed to improve interactions between patients and healthcare providers by utilizing advanced natural language processing and machine learning techniques. These systems assist in diagnosing conditions, offering medical advice, and efficiently managing patient data. Various approaches to developing medical dialogue systems include deep reinforcement learning (Tang et al., 2016; Wei et al., 2018; Xu et al., 2019), pretrained language models (Varshney et al., 2023), sequence-to-sequence models (Lin et al., 2019), and meta-learning techniques (Lin et al., 2021). Additionally, some methods incorporate knowledge graphs to enhance the system's understanding and performance (Lin et al., 2019; Varshney et al., 2023)."}, {"title": "Generating datasets for MDS training", "content": "Recent advancements in MDS have significantly impacted the medical field. Some recent works have been done in generating synthetic patient-physician dialogue as an aim for providing a high quality of synthetic data that can be used for training MDS while protecting patient's privacy. The work in (Wang et al., 2023), proposed \"NoteChat\", a novel multi-agent framework using Large Language Models (LLMs) to generate synthetic patient-physician dialogues conditioned on clinical notes. NoteChat's structure includes Planning, Roleplay, and Polish modules. The Planning module focuses on knowledge organization to maintain medical logic. The Roleplay module employs two Chat-GPT(GPT3.5Turbo) agents acting as patient and physician to produce interactive dialogues. Finally, the Polish module refines these dialogues to align closely with medical professional standards. The system was evaluated using the MTS-dialogue dataset on extensive intrinsic and extrinsic evaluation methods, and demonstrated improved performance over other models. Another study (Zeng et al., 2020), introduces \"MedDialog,\" a substantial collection of medical dialogues in both Chinese and English, forming the largest known dataset of its kind to date. MedDialog's approach to dialogue generation involves sequence-to-sequence modeling, utilizing advanced methods like BERT-GPT, to train models capable of producing contextually relevant and medically accurate conversations. The paper explores the effectiveness of these models and evaluates their performance on the MedDialog dataset, comparing them with other datasets to highlight their comprehensive coverage and diversity."}, {"title": "Method", "content": "In this section, we introduce our methodology, SynDial, which forms the core of our research. We will provide a detailed overview of the datasets employed and the evaluation metrics utilized to assess the efficacy of our approach in generating medical dialogues."}, {"title": "SynDial", "content": "The SynDial approach, as illustrated in Figure 1, begins by checking if the clinical note's length nearly exceeds the maximum token input for GPT-3.5 (if >4000). If it does, the note is first summarized by prompting GPT3.5 to makes it < 300 tokens. Subsequently, the clinical note is input into the LLM (GPT-3.5) to generate a dialogue between a patient and physician using zero-shot prompting. The generated dialogue is then initially evaluated and refined using the ROUGE-1 F1 metric for both similarity and extractiveness. Similarity measures how closely the generated dialogue matches a reference dialogue, while extractiveness assesses how much information in the dialogue is directly extracted from the clinical note.\nThe ROUGE-1 F1 score is calculated using the following equation:\nROUGE-1 F1 = 2*precision*recall/(precision + recall)\nwhere precision is the fraction of relevant words retrieved from the generated dialogue, and recall is the fraction of relevant words retrieved from the reference dialogue.\nThe approach is flexible and can be tweaked using the parameter a, allowing for a balance between extractiveness and similarity. The combined score is calculated using the equation:\ncombined_score = (1-a)*score_extr+a*score_sim\nIf the dialogue meets predefined thresholds for the combined score, the process terminates, and the dialogue is saved. If not, a feedback loop sends the clinical note back to the LLM, along with the previously calculated similarity and extractiveness scores, to improve the dialogue. This loop continues until the dialogue meets the thresholds or until it has run three times. If it runs three times without meeting the thresholds, the best dialogue generated in terms of the combined score is selected. After evaluating the approach, the same process is applied for other datasets, focusing on extractiveness when ground-truth dialogues are not available."}, {"title": "Datasets", "content": "We utilize two datasets: MIMIC-IV (Johnson et al., 2023) and MTS-Dialogue (Abacha et al., 2023). The MIMIC datasets are large publicly available electronic health records comprising 123,488 patients with 232,263 visits, averaging 1.88 visits per patient. We used 80 samples from the MIMIC-IV dataset for our experiments. Each patient typically has one to two visits, each corresponding to a discharge summary. These discharge summaries are used to generate synthetic dialogue datasets.\nThe MTS-Dialogue dataset contains clinical notes and corresponding ground truth conversations for each sample. It includes 1,701 pairs of dialogues and associated sections from clinical notes, with an overall of 15,969 turns, 18,406 sentences, and 241,685 words in dialogues, and summaries consisting of 5,870 sentences. For our experiments, we used the MTS-Dialogue test dataset containing 20 samples and the training dataset containing 1,200 samples, which were used for fine-tuning Llama2 models during extrinsic evaluation."}, {"title": "Baselines", "content": "\u2022 GPT3.5 and GPT4 both are using one detailed zero-shot instruction prompting to generate the dialogue between patient and physician (Wang et al., 2023).\n\u2022 NoteChat uses two LLMs (GPT3.5Turbo) where one acts as patient and the other as physician to generate a multi-turn conversation(Wang et al., 2023)."}, {"title": "Evaluation metrics", "content": "We evaluate our model and the baseline models based on both intrinsic and extrinsic evaluation metrics."}, {"title": "Intrinsic evaluation", "content": "\u2022 Similarity: ROUGE-F1 is calculated to measure the similarity of the generated conversation and the ground-truth dialogues.\n\u2022 Factuality: Concept-Recall is calculated using GPT3.5 to extract medical concepts from model-generated dialogues and notes to get two corresponding concept lists and then calculate the overlap of medical concept.\n\u2022 Extractiveness: ROUGE-F1 of src->hypo assesses how much information in the dialogue is extracted directly from the clinical note.\n\u2022 Diversity: Self-BLEU calculates the variety in the generated patient and physician utterances."}, {"title": "Extrinsic evaluation", "content": "For extrinsic evaluation, we first finetuned a Llama-2 models on MTS-Dialogue training dataset and calculated extractiveness (Rouge 1 F1 score). We also finetuned another similar model with MTS-Dialogue training dataset augmented with MIMIC dataset generated by our method. We hope that adding our dataset will improve the score if tested on MTS-Dialogue test data on the Conversation2Note task."}, {"title": "Experiments and Results", "content": "In this section, we describe the different experiments we have done including comparison with baselines for intrinsic evaluation, extrinsic evaluation, reward comparison, robustness check and cost comparisons."}, {"title": "Comparison with baselines", "content": "We compared our model on the MTS-Dialogue dataset with the baseline models. As done in the NoteChat (Wang et al., 2023) paper, we compared four different intrinsic evaluation metrics across all the methods. The metrics (similarity, extractiveness, factuality, diversity) are described in Section 4. Table 1 shows the comparison among all the methods across all the four intrinsic evaluation metrics. We can clearly see that SynDial is performing best for extractiveness and factuality. For our case (with MIMIC dataset), where we do not have the ground truth dialogues available for each clinical note, we find extractiveness and factuality as the most important evaluation metrics. Diversity if SynDial is comparable with GPT4 which is reasonable.\nFor similarity and extractiveness we calculated Rouge1-F1 scores as described in section 4.4.1. We utilize rouge-score 0.1.2 python package (Lin, 2004) for calculating rouge scores. For factuality, we used gpt3.5 to first extract 2 sets of medical concepts from the note and the generated dialogue. Then we use porter stemmer stemming algorithm to process the medical concepts from both sets. Finally, we find the intersection of the sets and calculate recall. For diversity, we calculated self-bleu scores inspired by the github repository of (Zhu et al., 2018). We calculated extractiveness and factuality for a subset of 80 samples from the MIMIC IV dataset (Table 2). For MIMIC IV data, we do not have the ground truth dialogues, so we can not calculate similarity with ground truth."}, {"title": "Extrinsic evaluation", "content": "For extrinsic evaluation, we first finetuned a Llama-2-7b-hf model on the MTS-Dialogue training dataset (1200 samples) and calculated extractiveness (Rouge 1 F1 score). We also finetuned another Llama-2-7b-hf model with MTS-Dialogue training dataset augmented with MIMIC dataset generated by our method. We hope that adding our dataset will improve the score if tested on MTS-Dialogue test data. Table 4 shows the scores for extrinsic evaluation. Augmenting the MTS-Dialogue training dataset with synthetic MIMIC dialogues helped to elevate the Rouge 1 F1 score for Conversation2Note downstream task."}, {"title": "Experiment for robustness check", "content": "We run the same pipeline (Fig. 1) for three times and average the scores. We find that the scores are not too diverse with only a standard deviation of 0.007 for similarity rouge scores and a standard deviation of 0.003 for extractiveness rouge scores. This experiment shows that the scores are not random and are consistent enough."}, {"title": "Cost comparison", "content": "We also compared SynDial with NoteChat (Wang et al., 2023) which is the state-of-the-art model that also generates dialogues from clinical notes. SynDial is far cheaper in terms of API calls compared to NoteChat (Figure 2). Also, although NoteChat is better in terms of similarity to ground truth dialogues and diversity, we think it is definitely more important to have better extractiveness and factuality scores."}, {"title": "Limitations and Future Work", "content": "In the initial phase of our research, we utilized 80 samples from the MIMIC IV dataset to demonstrate performance. However, for the forthcoming paper, we plan to incorporate a larger sample size and integrate data from the MIMIC III dataset. Our hypothesis that patient history significantly aids in generating dialogues for current visits was refuted by experimental results. Hence, we aim to streamline the process by extracting pertinent information solely from the previous visit to inform prompts for subsequent visits. In future endeavors, we aspire to refine the feedback loop to provide more nuanced and reflective feedback, thereby enhancing the extractiveness of the generated dialogue."}, {"title": "Conclusion", "content": "In this paper, we presented SynDial, a novel approach for generating synthetic patient-physician dialogues from clinical notes using a single large language model (LLM) with a feedback loop mechanism. Our method addresses the challenges of data scarcity and privacy in training medical dialogue systems by leveraging publicly available clinical notes datasets such as MIMIC-IV and MTS-Dialogue. Through extensive experiments, we demonstrated that SynDial significantly outperforms existing baseline models in terms of extractiveness and factuality, making it a valuable tool for creating high-quality synthetic dialogue datasets.\nFurthermore, we showed that our approach is cost-effective compared to the state-of-the-art models like NoteChat, which rely on multiple LLM instances. SynDial also provides consistent results across multiple runs, ensuring robustness in the generated dialogues.\nFuture work will focus on scaling up the dataset size and incorporating more advanced feedback mechanisms to further enhance the quality of the generated dialogues. Additionally, we plan to explore the impact of integrating synthetic dialogues from multiple sources to improve the performance of downstream tasks, such as the Conversation2Note task.\nOverall, SynDial offers a promising solution for advancing medical dialogue systems while maintaining patient privacy and reducing the dependency on real-world data."}, {"title": "Conflicts of interest", "content": "The authors have no competing interests to declare."}, {"title": "Data availability", "content": "The datasets used in this study are publicly available. The MIMIC-IV dataset can be accessed at https://physionet.org/content/mimiciv/2.0/ (Johnson et al., 2023). The MTS-Dialogue dataset is available at https://github.com/abachaa/MTS-Dialogue (Abacha et al., 2023)."}, {"title": "Appendix", "content": ""}, {"title": "Zero-Shot Dialogue Prompting", "content": "The zero-shot prompting used in our approach for dialogue generation is as follows:\nprompt =\n\"Given the clinical note, write a\nconversation between the patient\nand the doctor from the clinical\nnotes so that the main keywords\nare covered.\"\n+\n\"(\"the combined rouge score\nfor both extractiveness and\nsimilarity for the previous\ndialog was\"\nstr(combined_score) +  for this\nnote + row['note'] +\n\"generate a new one and try\nto improve the accuracy where\nthe extractiveness should\nweigh\"+(1-alpha)+\"and the\nsimilarity should weigh\"+alpha)\nDialogue:\n\"\"\""}, {"title": "Experiments with historical visits", "content": "We tried to incorporate information from previous visit of a patient in the prompt to help generating dialogue for that patient's current visit. However, we notice that the scores do not improve much. Figure 3 shows the score for 5 patients. Each color denotes a different patient. For each patient we plot the Rouge 1 F1 score for generated dialogues independent of the previous visit (denoted with filled circles). We also plot the scores where for each visit (except visit 1 of each patient), the previous visit's dialogue is also used in the prompt and SynDial's pipeline is used to generate dialogues. We see a decrease in overall scores for the second case (x marks in the graph)."}, {"title": "Improvement in Extractiveness Scores", "content": "We conducted a visual analysis to observe the changes in extractiveness scores within the MTS-Dialogue dataset across three iterations, as illustrated in Figures 4 and 5. It was observed that, out of 20 clinical notes, 11 showed improvements in extractiveness scores across at least two consecutive iterations."}, {"title": "Hyperparameter tuning", "content": "Table 5 shows the similarity and extractiveness scores when we tune the hyperparameter a which balances the priority of similarity and extractiveness. When a is 0, then full weight goes to extractiveness. If a is 1, the similarity score is calculated only as reward. When there are no ground truth dialogues, we need to select alpha = 0. However, if there are both the notes and corresponding ground truth dialogues the value for a can be chosen based of the need of the users. From Table 5 we find a = 0.1 is good for both similarity and extractiveness."}]}