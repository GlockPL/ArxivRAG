{"title": "Dual Conditional Diffusion Models for Sequential Recommendation", "authors": ["Hongtao Huang", "Chengkai Huang", "Xiaojun Chang", "Wen Hu", "Lina Yao"], "abstract": "Recent advancements in diffusion models have shown promising results in sequential recommendation (SR). However, current diffusion-based methods still exhibit two key limitations. First, they implicitly model the diffusion process for target item embeddings rather than the discrete target item itself, leading to inconsistency in the recommendation process. Second, existing methods rely on either implicit or explicit conditional diffusion models, limiting their ability to fully capture the context of user behavior and leading to less robust target item embeddings. In this paper, we propose the Dual Conditional Diffusion Models for Sequential Recommendation (DCRec), introducing a discrete-to-continuous sequential recommendation diffusion framework. Our framework introduces a complete Markov chain to model the transition from the reversed target item representation to the discrete item index, bridging the discrete and continuous item spaces for diffusion models and ensuring consistency with the diffusion framework. Building on this framework, we present the Dual Conditional Diffusion Transformer (DCDT) that incorporates the implicit conditional and the explicit conditional for diffusion-based SR. Extensive experiments on public benchmark datasets demonstrate that DCRec outperforms state-of-the-art methods.", "sections": [{"title": "1 Introduction", "content": "Sequential recommender systems (SRSs) are designed to produce recommendations by predicting the next item that will capture a user's interest [29]. Despite their effectiveness, existing models represent items with fixed vectors, which limit their ability to capture the latent aspects of items as well as the diverse and uncertain nature of user preferences [17, 35]. Besides, these methods assume that the items with the most user interactions are the most relevant, which puts less-interacted items at a disadvantage and leads to the exposure problem [35]. Diffusion models [8, 9], as an emergent deep generative model, add random noise to input data in a forward process and then recover the original data through a step-by-step reverse denoising process. Their denoising nature aligns well with the SR task, as modeling sequential item recommendations mirrors this step-wise approach [30]. Recent studies on diffusion models for SR [35] follow the paradigm of diffusion models, perturbing the embedding of the target item through a forward diffusion process into a Gaussian prior distribution. Then, they restore the Gaussian distribution iteratively through a reverse denoising process, also referred to as the sampling phase, to recover target representations and recommend items that are most similar to it.\nAlthough these methods have achieved significant performance, current diffusion models for SR are still undergoing some shortcomings. Firstly, existing approaches [35] commonly conduct conditional diffusion-based recommendations by conditioning the reverse denoising process on user behavior sequences. These methods focus on optimizing the diffusion process for the target item embeddings or generating an oracle item embedding for recommendation [18]. However, they do not explicitly model the diffusion process for the discrete target item itself (Gap 1). As illustrated in Figure 1(a), the traditional methods overlook a critical step: mapping the reversed target item representation into the discrete item index space. These methods often determine the recommended item by calculating the similarity (e.g., inner product) between the reversed target item representation and candidate item embeddings, selecting the item with the highest similarity score. While this method works for item ranking, it does not align with the core principles of diffusion models. Diffusion models are inherently probabilistic and continuous, but this step-based on a direct inner product comparison-introduces a deterministic, discrete decision process that breaks the continuous generative flow of diffusion. This inconsistency creates a gap between the optimization directions of the ranking loss for the recommendation task and the denoising loss for the diffusion model, resulting in suboptimal recommendation performance.\nMore importantly, existing diffusion-based SR methods can be broadly classified into two categories: implicit and explicit conditional approaches. As shown in Figure 1(c) and (d), in this paper, Implicit conditional methods refer to treating the user's historical behavior as an implicit feature and integrating them into the generating target item at each diffusion step [15, 17, 35]. In contrast, Explicit conditional methods refer to leverage those historical behaviors as explicit guidance that directly influences the denoising process in diffusion SR [19]. The main difference between the two types of conditioning is that the implicit one can be regarded as a feature fusion with fixed and compressed historical features while the explicit one iteratively interacts with the generating target according to the diffusion progress. However, both approaches have inherent limitations. Implicit conditioning may oversimplify complex user behaviors by compressing them into a single vector,"}, {"title": "2 Related Work", "content": "\u2022 Diffusion Models. Diffusion models, derived from non-equilibrium thermodynamics, have achieved notable success in areas like computer vision, sequence modeling, and audio processing [33]. Two primary paradigms exist unconditional models and conditional models. Unconditional models, such as DDPM [8], aim to push the performance boundaries of generative models. Conditional models incorporate guidance from labels to control generated samples. SGGM [34] conditions on self-produced labels, while You et al. [36] demonstrate how few labels and pseudo-training enhance both large-scale diffusion models and semi-supervised learners. Dhariwal [3] uses classifier guidance to improve sample quality, and Ho and Salimans [10] combine conditional and unconditional scores to balance sample quality and diversity. Multi-modal guidance further enriches the diffusion process, as seen in DiffuSeq [4] for NLP tasks and SDEdit [21] for image translation, with latent diffusion models (LDM) [26] offering flexible, unified semantics. unCLIP [24] and ConPreDiff [32] integrate CLIP latents in text-to-image generation.\n\u2022 Diffusion Model-based Sequential Recommendation. Diffusion models show promise in the sequential recommendation by using user behavior sequences as guidance in the denoising process [17, 30, 35]. DiffuRec [17] corrupts target item embeddings with Gaussian noise and uses a Transformer to iteratively reconstruct them. DreamRec [35] generates the oracle next-item embeddings based on user preferences but struggles with scalability due to its lack of negative sampling. DCDR [19] adopts a discrete diffusion framework for progressive re-ranking. However, current methods face two main issues: they focus on embedding diffusion rather than discrete item generation, leading to inconsistencies, and they rely on implicit or explicit conditioning, limiting the capture of user context and weakening target item embeddings."}, {"title": "3 Preliminary", "content": ""}, {"title": "3.1 Problem Formulation", "content": "Let $U = \\{u_1, u_2, ..., u_{|U|}\\}$ and $Z = \\{z_1, z_2, ..., z_{|z|}\\}$ be the user set and the item set. For each user $u \\in U$, there is a chronological sequence of historical interaction items denoted as $H_z$, where $H_z \\subseteq Z$. Generally, for a user $u$, given their sequence context $H_z = \\{Z_1, Z_2, ..., Z_{n-1}\\}$, the task of an SRS is to predict the next item (target item) $z$ which may interest $u$."}, {"title": "3.2 Diffusion Models for Continuous Domains", "content": "Recently, diffusion models have already demonstrated significant performance in continuous domains like computer vision and audio [8, 9, 13, 26]. Thus, before presenting our diffusion SR model, we briefly recap the diffusion models in continuous domains [8, 20].\nA generative model is expected to match estimation distribution $p_\\theta(e_0)$ to the ground truth distribution $p(e_0)$ as closely as possible, where $\\theta$ represents learnable parameters and $e_0 \\in \\mathbb{R}^d$ is a set of samples. For vanilla continuous diffusion models, they model the sample $e_0$ as a Markov chain with a sequence of latent variables $\\{e_T,..., e_t, e_{t-1},..., e_0\\}$, where $T$ is the diffusion step and $e_T$ is a standard Gaussian, $e_t$ is the intermediate latent variable. By this means, the latent dimension is exactly equal to the data dimension of $e_0$, and the diffusion model progressively recovers $e_0$ from Gaussian noise. Each denoising transition $e_t \\rightarrow e_{t-1}$ is parameterized by a linear Gaussian transition, calculated by a denoising DNN $f_\\theta(e_t, t)$:\n$p_\\theta(e_{t-1}|e_t) = \\mathcal{N}(e_{t-1}; \\mu_\\theta(e_t, t), \\Sigma_\\rho(e_t, t))$\nThus, the joint distribution of diffusion models can be written as:\n$p_\\theta(e_{0:T}) = p_\\theta(e_T) \\prod_{t=1}^T p_\\theta(e_{t-1}|e_t)$ (2)\nwhere, $p_\\theta(e_T) = \\mathcal{N}(e_T; 0, I)$ (3)\nTo train the denoising model $f_\\theta(e_t, t)$, diffusion models first construct a progressive noising process $\\{e_0,..., e_{t-1}, e_t\\}$, known as the forward process. Corresponding to this, the denoising process is called the reverse process. The forward process adds Gaussian noise to $e_0$ step-by-step until the final latent $e_T$ is guaranteed to a standard Gaussian. Each noising transition $e_{t-1} \\rightarrow e_t$ is defined as a linear Gaussian transition $q(e_t|e_{t-1}) = \\mathcal{N}(e_t; \\sqrt{\\alpha_t}e_{t-1}, (1 - \\alpha_t)I)$, where the Gaussian parameters $\\alpha_t \\in (0, 1)$ varies over time step $t$ and controls the noise scale added to the embedding in the current step $t$. Due to the Markov property and the Bayes' theorem, the transition can be rewritten with $e_0$ as:\n$q(e_t|e_{t-1}) = q(e_t|e_{t-1}, e_0) = \\frac{q(e_{t-1}|e_t, e_0)q(e_t|e_0)}{q(e_{t-1}/e_0)}$ (4)\nTo optimize the parameter $\\theta$, the diffusion model is trained to maximize the log-likelihood of $p_\\theta(x)$ according to observed samples $e_0$. This objective can be formulated as arg max log $p_\\theta(e_0)$. Mathematically, we can derive a proxy objective called the Evidence Lower Bound (ELBO), a lower bound of the likelihood term log $p_\\theta(e_0)$. Formally, the equation of the ELBO is:\n$\\mathbb{E}_{q(e_{1:T}|e_0)}[log \\frac{p_\\theta(e_{0:T})}{q(e_{1:T}|e_0)}]$ (5)\nRather than directly maximize the likelihood term, diffusion models minimize the minus ELBO as [8, 20]:\n$\\underset{\\theta}{arg \\, max} \\, log \\, p_\\theta(e_0) \\approx \\underset{\\theta}{arg \\, max} \\, \\mathbb{E}_{q(e_{1:T}|e_0)}[log \\frac{p_\\theta(e_{0:T})}{q(e_{1:T}|e_0)}]$ (6)\n$= \\underset{\\theta}{arg \\, min} \\, \\mathbb{E}_{q(e_{1:T}|e_0)}[log \\frac{q(e_{1:T}|e_0)}{p_\\theta(e_{0:T})}]$\nCombining with Equations (2) and (4), the log term in Equation (7) can be further derived as:\n$log \\frac{q(e_{1:T}|e_0)}{p_\\theta(e_{0:T})} = log \\frac{q(e_{T}|e_0)}{p_\\theta(e_{T})} + \\sum_{t=2}^T log \\frac{q(e_{t-1}|e_t, e_0)}{p_\\theta(e_{t-1}|e_t)} - log p_\\theta(e_0|e_1)$ (8)\nTherefore, based on Equations (7) and (8), the ELBO-based optimization object of parameter $\\theta$ is to minimize:\n$L_{elbo}(e_0) = \\mathbb{E}_{q(e_{1:T}|e_0)}[log \\frac{q(e_{T}|e_0)}{p_\\theta(e_{T})} + \\sum_{t=2}^T log \\frac{q(e_{t-1}|e_t, e_0)}{p_\\theta(e_{t-1}|e_t)} - log p_\\theta(e_0|e_1)]$ (9)\nTo simplify and combine the second and third terms in Equation (9), recent research [20] derivative a simple surrogate objective to obtain a mean-squared error term:\n$L_{elbo}(e_0) = \\mathbb{E}_{q(e_{1:T}|e_0)}[\\sum_{t=1}^T ||f_\\theta(e_t, t) - e_0||^2]$ (10)"}, {"title": "4 Dual Conditional Diffusion Models for Sequential Recommendation", "content": "In this section, we present the comprehensive introduction of our DCRec as shown in Figure 2, which includes both the Sequential Recommendation Diffusion Framework and the Dual Conditional Diffusion Transformer (DCDT). Firstly, we expend the vanilla continuous diffusion to the discrete sequential recommendation task and provide a theoretical-grounded diffusion framework. Then, we introduce the DCDT, our denoising network $f_\\theta$ for diffusion SR under the proposed framework. Finally, we focus on the efficient inference for the DCRec."}, {"title": "4.1 Sequential Recommendation Diffusion Framework", "content": "Continuous diffusion models have achieved remarkable success in domains like vision and audio [13], but their application to SR has been limited due to the inherently discrete nature of the recommended items. Existing diffusion models in SR typically determine the recommended item by computing the similarity (e.g., inner product) between the reversed target item representation and candidate item embeddings, selecting the item with the highest similarity score. While this approach is effective for ranking, it fundamentally conflicts with the principles of diffusion models. Vanilla diffusion models are designed to be probabilistic and continuous. Current diffusion SR approaches [17, 30, 35] directly apply the continuous diffusion framework to the SR task neglecting the discrete-to-continuous transition. This breaks the transition Markov chain, the generative flow that diffusion models rely on, creating a disconnect between the ranking objective and the diffusion model's denoising process. Specifically, this misalignment leads to an inconsistency between the optimization directions of the ranking loss for recommendation and the denoising loss of the diffusion process, resulting in sub-optimal recommendation performance.\nTo address this issue and motivated by diffusion models in text domains [16], we explicitly extend continuous diffusion models to discrete item domains as shown in Figure 2(a). As for discrete target item $z$ from the item pool $Z$, the Markov chain in the forward and reverse processes are extending as $\\{z,..., e_{t-1}, e_t\\}$ and $\\{e_t, ..., e_0, z\\}$. Specifically, to map the discrete variables into continuous domains, we define a learnable embedding function Emb(z). The forward transition process of $z$ is defined as:\n$q_\\phi(e_0|z) = \\mathcal{N}(e_0; Emb(z), 0),$ (11)\nwhere $\\phi$ represents the learnable parameters in Emb(z). As for the reverse process, we define the predicted distribution of $z$ as:\n$P(z|e_0) = \\underset{z}{arg \\, max} \\, cos(e_0, Emb(Z)),$ (12)\nwhere cos() is the cosine similarity between $e_0$ and each item embedding of Emb(Z). However, the transition distribution $p_\\theta (z|e_0)$ lacks a direct analytical formula.\nAfter defining $p_\\theta$ and $q_\\phi$, we extend the ELBO in Equation (7) to include discrete item $z$ as:\n$\\underset{\\phi,\\theta}{arg \\, max} \\, max \\, log \\, p_\\theta (z) \\approx \\underset{\\theta}{arg \\, min} \\, \\mathbb{E}_{q_\\phi(e_{0:T}|z)}[log \\frac{q_\\phi(e_{0:T}|z)}{P_{\\theta\\phi}(z, e_{0:T})}]$ (13)\nand the training objective in Equation (9) is rewritten as:\n$L_{elbo}(z) = \\mathbb{E}_{q_\\phi(e_{0:t}|z)} (L_T + L_t + L_z)$, where (14)\n$\\begin{cases}L_T = log \\frac{q(e_T|e_0)}{P_\\theta(e_T)}, \\\\ L_z = log \\frac{q (e_0/z)}{P(z|e_0)}, \\\\ L_t = \\sum_{t=1}^T ||f_\\theta(e_t, t) - e_0||^2\\end{cases}$ (15)\nThere are three terms of objectives in $L_{elbo}$: the prior matching term $L_T$, the denoising term $L_t$ and the domain transition term $L_z$. The prior matching term $L_T$ is similar to the same term in Equation (9), which requires the forward process to transit the $e_0$ into Gaussian noise $P_\\theta(e_T)$. Continuous diffusion models [8, 9, 13, 20] omit this term since there are no associated trainable parameters. This term is essential in $L_{elbo}$ due to the correlation among $z$, $e_0$ and $\\theta$. This term is equivalent to minimizing $||e_0||^2$. As the second term $L_t$ require $f_\\theta(e_t, t)$ and $e_0$ as close as possible, we transfer the objective $||e_0||^2$ to $||\\sum_{t=1}^T f_\\theta(e_t, t)||^2$ for fully optimize the DNN models.\nThe embedding entropy term $L_z$ can be regarded as a KL-divergence $D_{KL}(q_\\phi(e_0|z)||p_\\theta (z|e_0))$. Although $q_\\phi(e_0|z)$ is a linear transition, the distribution of $p_\\theta(z|e_0)$ is unknown. Therefore, we replace $D_{KL}(q_\\phi(e_0|z)||p_\\theta(z|e_0))$ by $D_{KL}(q(z)||p(z)) = D_{KL}(q(z)||p_f(z))$. The simplified objective of $L_{elbo}$ is:\n$L_{elbo} (z) = \\mathbb{E}_{q_\\phi(e_{0:T}|z)} (L_T + L_t + L_z)$, where (16)"}, {"title": "4.2 Dual Conditional Diffusion Transformer", "content": "In this section, we provide a detailed explanation of the Dual Conditional Diffusion Transformer (DCDT) in DCRec, which is a robust denoising transformer built within the framework in Section 4.1. Previous methods in diffusion-based SR have primarily employed either implicit or explicit conditioning mechanisms to incorporate user behavioral data into the recommendation process [15, 30, 35]. Almost implicit conditional approaches compress the user's historical behavior sequence into a compact representation vector, which is then used to guide the reverse diffusion process [15, 18]. While this method efficiently captures global user preferences, it may inadvertently oversimplify complex user behaviors, losing important sequential and temporal dynamics inherent in the user's interactions. This compression can lead to a loss of valuable information about the order and context of past actions, which are crucial for accurate SRs. Explicit conditioning methods [19], on the other hand, skip the feature compression step and directly introduce the entire sequence of historical item embeddings during the reverse generation process. This allows the model to access detailed step-by-step interactions and capture fine-grained sequential dependencies. However, explicit conditioning on the whole historical information, these methods can be more sensitive to noise and irrelevant actions within the user's behavior sequence, which may hinder the recommendation quality [5, 6].\nTo tackle these limitations, we propose the Dual Conditioned Diffusion Transformer (DCDT) as shown in Figure 3, a novel approach that integrates both implicit and explicit conditioning strategies. By combining the representation of the user's global preferences with the direct utilization of detailed historical behaviors, DCDT leverages the strengths of both methods. The implicit component captures global user interests and long-term behavioral patterns, providing a stable guide for the diffusion process. Simultaneously, the explicit component preserves sequential complexities and temporal dynamics by referencing specific past interactions during generation. DCDT employs a dual conditional diffusion process that incorporates an implicit conditional historical forward process and an explicit conditional reverse process, leading to more accurate recommendations. As shown in Figure 2(b), the dual conditional trajectory (green line) in the reverse diffusion process merges these two guiding signals, preventing the denoising trajectory from being overly influenced by noise or irrelevant historical items. This effectively narrows the trajectory toward the correct target item, improving the precision of the recommendation."}, {"title": "4.2.1 Implicit Conditional Historical Forward Process", "content": "Previous implicit conditional methods tend to encode the user's historical behavior sequences into compact feature representations, which are then used to guide the reverse diffusion process [15, 35]. However, compressing the historical behavior sequences into a single vector might lead to the loss of important sequential information due to the sparse nature of SRSs [6]. In our approach, we avoid this compression step. Instead, we combine the uncompressed historical behavior sequences with the target item and add noise to this combined input before feeding it into the diffusion model. We believe that this allows the diffusion model to generate a more robust representation of the target item, as it can better capture detailed sequential patterns and contextual information from the user's history. For convenience, for our implicit conditional diffusion models, we use $S_0$ to donate the concatenated sequence of the history item sequence $H_0$ and the target $e_0$, where $S_0$ = Concat($H_0$, $e_0$). Thus, we continuously incorporate Gaussian noises into the whole item sequences $S_0$ rather than the target item embedding $e_0$ as follows:\n$q(S_t|S_{t-1}) = \\mathcal{N}(S_t; \\sqrt{\\alpha_t}S_{t-1}, (1 - \\alpha_\\tau)I)$ (20)\n$= \\sqrt{\\alpha_t} S_0 + \\sqrt{1 - \\alpha_t} S_{t-1}$ (21)\nBased on the superposition of Gaussian distribution and Equation (21), we can calculate the transition from $S_0$ to $S_t$ as:\n$q(S_t|S_0) = \\sqrt{\\bar{\\alpha_t}} S_0 + \\sqrt{1 - \\bar{\\alpha_t}} S_T, S_T \\sim \\mathcal{N}(0, I)$ (22)\nwhere $\\bar{\\alpha_t}$ = $\\prod_{t=1}^T \\alpha_t$, and $S_T$ denotes the item embeddings in the forward step $t$. We further add explicit conditioning by adding $H_0$ with a scaling factor $\\delta$ to $S_T$ and rewrite Equation (22) as:\n$q(S_t|S_0) = \\sqrt{\\bar{\\alpha_t}} S_0 + \\sqrt{1 - \\bar{\\alpha_t}} (S_T + \\delta H_0),$ (23)\nTherefore, in the ELBO-based training objective, we can rewrite Equation (17) and Equation (18) as:\n$\\begin{cases}L_T = ||f_\\theta (S_t, t)||^2, \\\\ L_t = ||f_\\theta(S_t, t) - e_0||^2,\\end{cases}$ (24)\nCompared to existing implicit diffusion models-based SR methods [35], our method adds noising the entire user sequence rather than just the target item. This approach allows the following reverse process to explicitly leverage the user's interaction history when generating the target item that aligns with the user's interests, leading to more accurate and relevant recommendations."}, {"title": "4.2.2 Explicit Conditional Reverse Process", "content": "In the context of SR, the restoration process reverses the transition modeling by gradually eliminating the noise and recovering the original sequential patterns of user behavior, thereby restoring the data distribution underlying the user's item preferences. Meanwhile, cross attention as an explicit conditional method has proved effective in classic conditional generation tasks [23, 26]. Therefore, we further introduce the user's item preferences $H_0$ as an explicit conditional signal to the denoising transformer $f_\\theta$ in Equation (24) as:\n$S_0 = f_\\theta (S_t, t, H_0)$ (25)\nFirstly, we introduce the Conditional Layer Normalization, abbreviated as CondLN. In our SR setting, we hope to extend traditional layer normalization to our explicit conditional denoising process. Therefore, we replace the element-wise learnable parameters gain $g$ and bias $b$ of affine transformation in the original Layer Normalization [14] by integrating user interaction sequence $S_0$ and diffusion step embedding $t$. The CondLN can be formulated as:\n$S_t = g' (t, H_0) \\times \\frac{S_t - \\mathbb{E}(S_t)}{\\sqrt{Var(S_t) + \\epsilon}} + b' (t, H_0)$ (26)\nwhere $\\mathbb{E}()$ and $Var()$ denote the mean and standard variance of $S_t$, and $\\epsilon$ denotes the small constant for numerical stability. $g'(.)$"}, {"title": "4.3 Model Inference and Inference Acceleration", "content": "In the Section 4.1 and Section 4.2, we have introduced the optimization process in DCRec and the training of DCDT. The denoising model DCDT is trained to provide predicted $\\hat{S_0}$ to approximate $S_0$. Similar to Equation (2), the inference Markov transition of DCRec can be formulated as:\n$P_\\theta(S_{t-1}|S_t) = \\mathcal{N}(S_{t-1}; \\mu_\\theta(\\hat{S_0}(S_t), t), \\Sigma_\\rho(\\hat{S_0}(S_t), t))$ (35)\nThis can be described as a repeated approximation-and-adjust process since each step aims to predict $\\hat{S_0}(S_t)$ and provide $S_{t-1}$, which is less noise than $S_t$, for the next step. The time cost of inference process linearly increases associated with the increase of the total number of steps. A natural idea for acceleration is that, if the approximation at the early is accurate enough with no need for adjustment, DCRec can directly skip several intermediate steps. Here, we define the number of skipping steps as $k$. We rewrite Equation (35) as:\n$P_\\theta(S_{t-k}|S_t) = \\mathcal{N}(S_{t-k}; \\mu_\\theta(\\hat{S_0} (S_t), t), \\Sigma_\\rho(\\hat{S_0} (S_t), t))$ (36)\nFor our DCRec, we observe that DCDT is robust enough to fulfill Equation (36) at an early stage, which significantly reduces time overhead. We will discuss the details in Section 5.4. For the pseudocode of the inference, please refer to Algorithm. 2 in the Appendix."}, {"title": "5 Experiment", "content": "In this section, we conduct a comprehensive experimental study to address the following research questions (RQs):\n\u2022 RQ1: How does the performance of DCRec compare with other baselines across the datasets in different experiment settings?\n\u2022 RQ2: What is the impact of different components (e.g., reconstruction loss, ranking loss, regularization loss, and DCDT modules) within the DCRec on overall performance?\n\u2022 RQ3: How does DCRec perform in terms of inference efficiency?"}, {"title": "5.1 Experimental Settings", "content": "\u2022 Datasets. We evaluate our proposed DCRec on three publicly available datasets: Amazon 5-core Beauty, Amazon 5-core Toys, and Yelp, following the experimental setup of previous works [1, 17, 39]."}, {"title": "6 Conclusion", "content": "In this paper, we proposed the DCRec to address key limitations in existing diffusion-based sequential recommender systems. By introducing a Markov chain to model item transitions and a dual conditional module to integrate contextual information, our approach improves the consistency of item selection and enhances the generation of target item embedding. Extensive experiments on public datasets validate the effectiveness of DCRec, demonstrating its superiority over state-of-the-art methods in both recommendation accuracy and computational efficiency."}, {"title": "A Algorithm of DCRec Training and Inference", "content": ""}, {"title": "B Dataset Preparation", "content": "We evaluate our proposed DCRec on three publicly accessible datasets in different experiment settings. Table 3 provides a summary of the statistics for each dataset.\n\u2022 Amazon Beauty & Amazon Toys: We choose three representative sub-datasets from Amazon datasets: Beauty and Toys and keep the '5-core' datasets [39] [25] [1], which filter out user-item interaction sequences with length less than 5.\n\u2022 Yelp: Yelp is a well-known business recommendation dataset. Following [2, 31], we only retain the transaction records after Jan. 1st, 2019 in our experiment.\nFor reproducibility, we follow the commonly used benchmark setting of RecBole [38] to set up our experiments. Specifically, for each user, we first discard duplicated interaction sequences and sort the items in each user's sequence chronologically by their timestamp.\nFurthermore, the maximum length of interaction sequences is set to 50. If there are more than 50 interactions in a sequence, we adopt the latest 50 interactions. If the number of interactions in a sequence is less than 50, we make it up to 50 by padding virtual items with the ID of 0. Following the common practice in sequential recommendations, we leave the interactions happening at the latest time as the test dataset and the interactions at the second latest time as the validation dataset [1, 40]."}, {"title": "C Baselines for Comparison", "content": "To evaluate the performance of our model DCRec, we select various representative and/or state-of-the-art recommendation models as baselines.\n\u2022 GRU4Rec [7]: This model uses the GRU to model the user interaction sequence and gives the final recommendation.\n\u2022 Caser [37]: CNN-based approach for SR.\n\u2022 SARSRec [11]: This model employs a single-direction Transformer with a masked encoder to capture explicit correlations between items.\n\u2022 Bert4Rec [27]: replaces the next-item prediction with a Cloze task to fuse information between an item (a view) in a user behavior sequence and its contextual information.\n\u2022 S\u00b3Rec [41]: uses SSL to capture correlation-ship among items, sub-sequences, and associated attributes from the given user behavior sequence. Its modules for mining on attributes are removed because we don't have attributes for items.\n\u2022 CL4SRec [31]: fuses contrastive SSL with a Transformer-based SR model.\n\u2022 ICLRec [2]: leverages latent user intents, learned from unlabeled behavior sequences, to optimize SR (SR) models using contrastive self-supervised learning.\n\u2022 DreamRec [35]: uses the historical interaction sequence as conditional guiding information for the diffusion model to enable personalized recommendations.\n\u2022 SdifRec [30]: introduce the Schr\u00f6dinger Bridge into diffusion-based SR, by replacing the Gaussian prior with the user's current state.\n\u2022 DiffuRec [17]: incorporates a diffusion model into the field of SR, leveraging a Transformer backbone to reconstruct target item representations based on the user's historical interaction behaviors."}, {"title": "D Ablation Study for Partially Noised Input Sequence", "content": "In this paper, we concatenate the history embedding and target item embedding as a sequential input for our denoising model DCDT. As shown in Figure 2, we add noise to the whole input sequence. In this section, motivated by DiffuSeq [4] which is another diffusion model for Q&A task in NLP, we analyze the effectiveness of only adding noise to the target item. The results are shown in Figure 9. It seems that partially adding noise to the target item is worse than adding noise to the whole sequence. The possible reason is the unbalanced noised sequence length. DiffuSeq concatenates the question and answer as an input and only adds noise to the answer sequence. In that case, the question sequence and answer sequence have similar sequence lengths. However, in our SR task, the history sequence is nearly 50x longer than the target. Therefore, the strategy of partially noised input is unfeasible for DCRec."}, {"title": "E Details of Hyper-parameters Analysis", "content": ""}, {"title": "E.1 The Balance Factor \u03bb", "content": "It's worth to note that the optimization in Equations (24) and (31) is a complex and parameter-sensitive multi-objective task. In this section, we detailed analyze the impacts of three types of different A settings, including fix factor Afix, decline factor Adecline and smoothly decline factor Asmooth. We formulate them as follows:\n$A_{fix} = c$\n$A_{decline} = Max - g_d(ep) + Min$\n$A_{smooth} = Max * g_s(ep) + Min$\nwhere c is a constant and ep is the current training epoch. Max and Min denote the upper bound and the lower bound of the decline factor Adecline and Asmooth. $g_d(ep)$ is a decline linear function associated with the current training epoch, while $g_s(ep)$ is another decline exponential function also associated with the epoch. In Table 4 and Figure 10, we illustrate several example settings of A in our experiments and corresponding results are shown in Table 5. We note that those declining settings dramatically improve the model performance compared to the fixed ones. The Asmooth settings are feasible for Toys and Beauty datasets, while Adecline settings are more suitable for the Yelp dataset."}, {"title": "E.2 Other Hyper-parameters Analysis", "content": "We report the experimental results for key hyperparameters on the Beauty dataset, including the noise schedule \u03b2, number of diffusion steps T, and scaling factor \u03b4. In detail, \u03b2 is tuned within {0.01, 0.02, 0.04, 0.06, 0.08, 0.1}, diffusion steps T is tuned within {5, 10, 15, 20, 30, 50, 75, 100, 150, 200} and scaling factor \u03b4 is tuned within {0.1, 0.2"}]}