{"title": "Static and multivariate-temporal attentive fusion transformer for readmission risk prediction", "authors": ["Zhe Sun", "Runzhi Li", "Jing Wang", "Gang Chen", "Siyu Yan", "Lihong Ma"], "abstract": "Background: Accurate short-term readmission prediction of ICU patients is significant in improving the efficiency of resource assignment by assisting physicians in making discharge decisions. Clinically, both individual static static and multivariate temporal data collected from ICU monitors play critical roles in short-term readmission prediction. Informative static and multivariate temporal feature representation capturing and fusion present challenges for accurate readmission prediction. Methods: We propose a novel static and multivariate-temporal attentive fusion transformer (SMTAFormer) to predict short-term readmission of ICU patients by fully leveraging the potential of demographic and dynamic temporal data. In SMTAFormer, we first apply an MLP network and a temporal transformer network to learn useful static and temporal feature representations, respectively. Then, the well-designed static and multivariate temporal feature fusion module is applied to fuse static and temporal feature representations by modeling intra-correlation among multivariate temporal features and constructing inter-correlation between static and multivariate temporal features. Results: We construct a readmission risk assessment (RRA) dataset based on the MIMIC-III dataset. The extensive experiments show that SMTAFormer outperforms advanced methods, in which the accuracy of our proposed method is up to 86.6%, and the area under the receiver operating characteristic curve (AUC) is up to 0.717. Conclusion: Our proposed SMTAFormer can efficiently capture and fuse static and multivariate temporal feature representations. The results show that SMTAFormer significantly improves the short-term readmission prediction performance of ICU patients through comparisons to strong baselines.", "sections": [{"title": "1 Introduction", "content": "Patients of intensive care unit (ICU) with short-term readmission unexpectedly [1-5], may lead to a longer hospital stays [6] and a higher mortality risk [1, 7]. In particular, the short-term readmission rate is one of the most important metrics for ICU quality assessment, which is strongly related to the efficiency of ICU resource assignment.\nClinically, physicians make discharge decisions according to their experience, which is subjective and error-prone. Recent works have indicated that there was a high correlation relationship between the clinical data of patients and the readmission risk [8, 9]. With the development of artificial intelligence (AI) techniques, data-driven based decision methods can weaken the influence of subjective factors. A predictive model can predict the readmission risk of inpatients within short-term after discharge [10], conducing to medical resource assignment. Recently, a lot of AI methods have been applied to medical data analysis and clinical decision making, including multi-scale convolution, recurrent unit (GRU) [11], long short-term memory (LSTM) [12], bidirectional long short-term memory (Bi-LSTM) [13]. Here, we focus on the static and multivariate temporal data. Static data refer to demographic data of patients, such as sex, age, BMI and so on. They remain constant throughout the hospitalization. Multivariate temporal data refer to time sequence data from physiological monitoring, such as blood pressure, blood oxygen, heart rate, and so on. They may vary in real time. They contain different implications for indicating the status of patients. Thus, how to learn informative feature representations from static and multivariate-temporal data and then fuse them are two challenges for short-term readmission prediction.\nTo tackle these two challenges, we propose a static and multivariate-temporal attentive fusion network named SMTAFormer to predict the readmission risk of ICU patients.\nIn SMTAFormer, we first apply an MLP network and a temporal transformer network to learn informative static and temporal feature representations, respectively. Next, a novel static and multivariate-temporal feature fusion module is proposed to fuse static and multivariate-temporal feature representations dynamically. Moreover, we construct a readmission risk assessment (RRA) dataset of ICU patients with essential hypertension based on the MIMIC-III dataset. The extensive experiments on the"}, {"title": "Related Work", "content": "labelRW In the past years, massive machine learning methods have been proposed to address readmission risk prediction tasks. Lin [14] used logistic regression (LR), support vector machine (SVM), random forest (RF) and naive Bayes (NB) to predict readmission risk of ICU patients. They used shallow extraction (e.g., slope and intercept) and deep extraction (e.g., quadratic terms and standard deviation) methods to mine the temporal feature representation. However, the experimental results show that there is little difference between them, and even deep extraction methods slightly reduce model performance.\nRecently, deep learning methods have been widely used to deal with patient electronic health records (EHRs) due to their powerful feature representation learning capability. Morid et al. [15] used a convolutional neural network (CNN) to extract multivariate temporal features of ICU patients. But most deep learning methods belong to recurrent neural networks (RNN) and their variants, such as GRU, LSTM, and Bi-LSTM, as a basis to extract the temporal features, including Patient2vec [16], Deep-Risk [17], RETAIN [18], and Dipole [19]. Given the independence of different features, multichannel techniques were introduced to deal with individual temporal features [20]. With the advent of self-attention mechanism [21], transformers have gradually been used to tackle multivariate temporal data and have achieved considerable results [22-25]. However, these method ignore the significance of static data and multivariate temporal data, which contain various information of patients.\nStatic data and multivariate-temporal data are the two different type of clinical data that describe the status of the patients. They are the same valuable, however it is different to tackle and represent them in data processing. According to the reference that there are mainly four methods to fuse static data and multivariate-temporal data. The first is splicing. One is splicing before entering the model [14]. And the other is splicing in the middle of the model [26]. Always the splicing methods are less persuasive. The second is fusion by loading to RNN. Li [27] set static data as an initial value of the unit of LSTM to fuse with temporal sequences data. This method finished fusion between static and temporal features while it did not expose the correlation between them. It is limited by the amnesia of the RNN model and has poor expressiveness for long time series features. The third is fusion based on gate mechanism. Lim [28] constructed a deep network with gate mechanism to filter temporal data by high relation with static features in timing dimension. However, it missed correlation among multivariate-temporal features. The Last is fusion by attention mechanisms. This method can reflect the correlation between different modality data. For example An [29] and Zhang [30] that they use attention mechanism to fuse static and temporal data. However, it can result in the redundancy of static data, which would result in weakening the performance of models. In this work, we focus on a novel method that fuse static data and multivariate-temporal data, in which we hope to extract the inter correlation between them and further the intra multivariate-temporal data correlation."}, {"title": "Problem Formulation", "content": "In this work, based on static data and multivariate temporal data, we construct a deep learning models to predict readmission risk within 30 days for ICU patients.\nFirstly, as the input of the model: $X = {S, T}$, we build numeric vectors $S\\in R^m$ from the static features of the patients, such as age and sex. The numeric vector $T = {X_1, X_2, ..., X_n}$is built on the multivariate temporal features of the patients, and n is the size of multivariate temporal features. $X_i = {x^i_1, x^i_2,...,x^i_t }$ for each $X_i$, and t is time sequence, $x^i_j \\in R^{d_i} (j\\in [1, 2, ..., t])$.\nFor the outputs: $y \\in (0,1)$. y represents the readmission probability for ICU patients in 30 days. y is the ground truth. It is binary, where 0 indicates that patients are not readmitted within 30 days after discharge. While 1, indicates that patients are readmitted within 30 days."}, {"title": "Method", "content": "In this work, we propose SMTAFormer to predict readmission risk probability of inpatients with clinical data, including static and multivariate temporal features. SMTAFormer comprises static feature representation extraction, multivariate temporal feature representation extraction, static and multivariate temporal feature fusion, and readmission risk prediction.\nFirst, we use a simple MLP network for static feature extraction. Then, we adopt the traditional transformer encoder for learning feature representation of dynamic temporal data. Next, we construct a attentive fusion network, in which an intra temporal multi-head self attention layer followed by an inter static and multivariate temporal multi-head self attention. Lastly, a fully connected layer is used to finish the readmission risk prediction. Figure 2 shows the architecture of SMTAFormer.\nOur objective is to adjust the parameters to optimize the prediction model. It is described as following.\n$fo^* = argmin_{f_\\theta\\in u} [l (f_\\theta(X), y) + \\Alpha p(f_\\theta)]$\nwhere $f_\\theta (X)$ is the prediction model. $\\theta^*$ indicates the optimal parameter set. $l$ is the loss function. $\\Alpha p$ is the regularized term of $\\theta$, and $\\Lambda$ is a hyperparameter. $U$ represents the field of parameters $\\theta$."}, {"title": "Static feature representation extraction", "content": "We construct a simple MLP network to extract static feature representations from static data, which is a combination of a fully-connected (FC) layer and and a ReLU activation function:\n$S = ReLU (SW_s+b_s)$,\nwhere $W_s \\in R^{d\\times m}$ and $b_s \\in R^d$ are learnable parameters, and $S\\in R^d$ represents the generated static feature representations."}, {"title": "Multivariate temporal feature representation extraction", "content": "For multivariate temporal data, we apply a temporal transformer network to capture informative multivariate temporal feature representations. First, we utilize a FC layer to encode the multivariate temporal data followed by positional encoding. Then we construct the multi-head self-attention layer, the feed forward layer and the Add & Normalization layer for learning multivariate temporal feature representations. Finally, an average pooling layer is added to obtain useful multivariate temporal feature representations. It is described as follows:\nGiven multivariate temporal data $X_i \\in R^{t\\times d_i}$. First, we adopt a linear transformation and a ReLU activation function to encode the output $X_i$.\n$E^i = ReLU (X_iW_t+b_t)$\nwhere $W_t \\in R^{d\\times d_i}$ and $b_t \\in R^d$ are learnable parameters. For the same temporal features of the different timing nodes, the learnable parameters are shared. $E_i = {e^i_1,e^i_2,...,e^i_t} \\in R^{t\\times d}$. $E_i$ represents the time series after nonlinear transformation in a single channel. After that, we use positional encoding to add timing information to the time series.\n$P^i = P^i + E^i$\nWhere $P\\in R^{t\\times d}$ represents the position encoding matrix, $P^i \\in R^{t\\times d}$ on behalf of the time series after adding timing information. Then $P^i$ is sent to the encoder to extract temporal features. Here, we introduce the encoder as follows.\nFirstly, the multi-head self-attention mechanism is used to calculate the correlation among the time series.\n$M_i = Concat (head_1, head_2, ..., head_h) W$\n$head_l = Attention (P^iW_Q^l, P^iW_K^l,P^iW_V^l )$\n$Attention (Q, K, V) = softmax (\\frac{QK^T}{\\sqrt{d}})$ V\nwhere $W_Q^l \\in R^{d\\times d}$, $W_K^l \\in R^{d\\times d}$, $W_V^l \\in R^{d\\times d}$, and $W\\in R^{h*d\\times d}$ are training parameters. $W_Q^l$, $W_K^l$, and $W_V^l$ represent the query, Key, and Value matrix in the self-attention mechanism, respectively. The linear transformation matrix W makes the"}, {"title": "Static and multivariate temporal feature fusion", "content": "output $M_i$ of the same shape as $P_i$. The corresponding elements are added by $M_i$ to the original input $P_i$ and through layer normalization.\n$M_i = LayerNormalization (M_i + P^i)$\nwhere $M_i' \\in R^{t\\times d}$. Then the output $M_i$ is fed into the feedforward neural network, which is composed of two linear layers, an activation function ReLU, residual connection, and layer normalization.\n$M_i'' = ReLU ((M_i'W_1+b_1) W_2+b_2)$\n$M_i''' = LayerNormalization (M_i'' + M_i')$ \nThe final output $M^{final} \\in R^{t\\times d}$ is obtained by stacking multiple encoders. Then we adopt an average pooling layer in the time dimension to obtain the temporal characteristics represented under the time length t.\n$m_i = Average Pooling (M^{final})$\nwhere $m_i \\in R^d$.\nIn summary, we get the feature representations of the static and dynamic temporal data as S and $M = {m_1, m_2, ..., m_n}$ separately.\nIn this work, we propose a inter static and multivariate temporal multi-head self-attention module to fuse static and multivariate temporal feature representations adaptively. First, it calculates the correlation among multivariate temporal feature representations. We get a weighted sum of them. Next, the embedded static feature representations is adopted as the source of query to fuse static and temporal features by another multi-head self-attention layer. It can avoid redundant computing operations caused by feeding static features to the model many times. Next is the explanation.\nFirstly, M denotes the correlation of single temporal data.\n$M = Concat (head'_1, head'_2, ..., head'_h) W$\n$head'_l = Attention (MW^l_Q, MW^l_K, MW^l_V)$\nwhere $W^l_Q \\in R^{d\\times d}$, $W^l_K \\in R^{d\\times d}$, $W^l_V \\in R^{d\\times d}$ and $W\\in R^{n*d\\times d}$ are training parameters. $M\\in R^{n\\times d}$ is the representation of characteristics with multi-head slef attention mechanism."}, {"title": "Readmission Task Prediction", "content": "Next, a multi-head attention mechanism is used for the fusion of static and temporal features. We use the static features S as the source of the query. and X is the source of the key and value.\n$X = Concat (S,M)$\n$X = Concat (head''_1, head''_2,..., head''_h) W$\n$head''_l = Attention (SW^{l}_Q,XW^{l}_K,XW^{l}_V)$\nwhere $W^l_Q \\in R^{d\\times d}$, $W^l_K \\in R^{d\\times d}$, $W^l_V \\in R^{d\\times d}$ and $W\\in R^{n*d\\times d}$ are training parameters. $X \\in R^d$ is a vector representation for the fusion of static and temporal features.\nIn the readmission task prediction module, we use two fully connected layers to perform the non-linear transformation. ReLU and Sigmoid are activation functions, respectively.\n$\\hat{y} = Sigmoid (ReLU (XW_3 + b_3) W_4 + b_4)$"}, {"title": "Experiments", "content": "where $W_3 \\in R^{d\\times r}$, $W_4 \\in R^{1\\times r}$, $b_3 \\in R^r$ and $b_4 \\in R^1$ are learnable parameters. $\\hat{y}$ is the output of the model.\nIn this section, we introduce the RRA dataset, data preprocessing, experimental setup, and evaluation metrics. Then, the results and the correlation between static and multivariate temporal characteristics."}, {"title": "Dataset", "content": "It should be emphasized that we choose patients in the ICU with essential hypertension as the readmission research object and construct the experimental dataset from MIMIC-III, named RRA. We follow the suggestions of local cooperative physicians. The benefit is to highlight the correlation between characteristics and disease and to improve model interpretation.\nThe MIMIC-III data set is an open-sourced medical dataset based on patient conditions in the MIT intensive care unit operated by MIT [31]. To build the RRA dataset of ICU patients with essential hypertension, we choose four types of static characteristics referenced by Lin [14]: age, sex, insurance, and race. They are vital signs for reflecting the condition of the patients. We selected 12 temporal characteristics consisting of heart rate, diastolic blood pressure, systolic blood pressure, mean blood pressure, respiration rate, oxygen saturation, body temperature, and Glasgow coma scale."}, {"title": "Data Preprocessing", "content": "Specifically, we select three types of International Classification of Diseases, Version 9 (ICD 9) codes associated with essential hypertension, including 4010, 4011, and 4019. Meanwhile, we remove three types of ICU records, one for patients younger than 18 years of age, the second is for patients who died in the ICU and the last for patients admitted by pregnancy. Based on this, we screen ICU records for ICU stays longer than 24 hours and less than 72 hours. Regarding the labels of the experimental dataset, we make the following definition: a patient returns to the ICU within 30 days after last leaving the ICU, or when the patient died within 30 days, we mark the label as 1, otherwise it is 0.\nFinally, we get 10008 ICU records from ICU patients with essential hypertension, and 1110 data are readmitted to the ICU within 30 days.\nIn the data preprocessing stage, the forward and backward filling method is used to interpolate the missing data. For continuous multivariate temporal data, average is as the unit value. For discrete multivariate-temporal data, we calculate the mode value as the interpolation. Figure 2 shows three examples of discrete multivariate temporal features for continuous and discrete multivariate temporal data, the z-score and one-hot encoding methods are used for standardization, respectively.\nthe training dataset and the test dataset are divided by 9: 1. We use 5-fold cross-validation and binary cross-entropy loss function in the training. Adam is used as the optimizer, with a learning rate of 0.001, the batch size is set to 32, and the epoch is set to 150. We adopt the early stop mechanism to prevent overfitting."}, {"title": "Contrast Methods", "content": "In the experiments, as the experimental contrast, we deploy three baseline methods. They are LR and LSTM and CNN+LSTM, in which all data are processed by single modality, we montage static data at each temporal step. To evaluate our proposed methods SMTAFormer, we make experiments by two stages. Firstly, we contrast different models for different types of data. Because there are three types of data in our dataset that consists of static features, continuous temporal features and discrete temporal features. In which we choose the classic Dense neural network and Multi-scale convolution network and Multi-scale convolution network with learning addition models for static features processing. LSTM and GRU are adopted for continuous temporal features analysis. For another modality, they are static data with temporal feature. We try to use CNN and LSTM models.\nIn the second stage, we focus on the fusion module. We compare three methods consist of SAF (Fusion of self-attention mechanism), CGRN (Gating residual splicing network) and DSAF (Fusion of double self-attention mechanism). In addition, we use Transformer encoder for temporal feature representation."}, {"title": "Evaluation Metrics", "content": "In the experiments, we set metrics as follows: Accuracy Rate (ACC), Precision, recall, and the area under the ROC curve (AUC)."}, {"title": "2 Results", "content": "We mainly analyze the experimental results from two views: feature extraction and feature fusion.\nTable 2 and Table 3 shows performance comparisons among the baseline models and our proposed multimodal and multichannel models. First, table 2 gives that CNN+LSTM[STC] achieves the best prediction results with 0.767 of accuracy and 0.650 of AUC among three baseline models. As for the multimodal and multichannel methods, table 3 lists that all the models outperform baseline models on four metrics."}, {"title": "Visualization of the correlation between static and temporal features", "content": "Particularly, the combination of DNN+LSTM+LSTM obtains the highest AUC value with 0.682. Base on the results of table 3, we choose DNN and LSTM for the static features and continuous temporal features processing in the following experiments.\nTo ascertain the correlation between static and temporal features, samples labeled as lare carefully curated and fed into the training model. Subsequently, the weight matrix of self-attention from various heads in the temporal and static fusion is derived. This weight matrix serves as the representation of the correlation coefficients between the static and temporal features, elegantly depicted in Figure 3.\nDuring the experiments, the heat map was employed for model interpretation. We observe that all 12 temporal features contribute significantly to the prediction task, exerting clinical influence on the readmission of essential hypertension patients. The average temporal correlation coefficient is 0.07485428, with six attributes - glucose, heart rate, mean blood pressure, systolic blood pressure, Glasgow Coma Scale eye score, and Glasgow Coma Scale total score - exceeding this mean value."}, {"title": "Discussion", "content": "In the discourse, it becomes evident that deep learning methodologies exhibit superior performance compared to traditional machine learning approaches for feature extraction. Notably, the static and multi-variate temporal fusion network emerges as the top performer among the methods assessed. However, a critical analysis reveals that the feature fusion method STC introduces redundancies by repetitively incorporating static information, potentially hindering effective model training. The inherent invariance of static data may lead to the generation of noisy data, impeding optimal model performance. Conversely, emphasizing feature extraction from static data through multiple iterations could overlook the crucial temporal vital signs essential for patient discharge decisions. Experimental findings demonstrate that integrating an attention mechanism at each LSTM output step enhances the learning of temporal feature correlations.\nRegarding static and temporal fusion strategies, it is observed that employing a gate mechanism alone proves suboptimal. Conversely, the introduction of a self-attention mechanism following the gating mechanism results in improved AUC performance. The designed TSAF approach strategically incorporates static data only once in the final step to mitigate redundancy issues associated with static data integration."}, {"title": "Conclusions", "content": "In this study, we introduce the Static and Multi-variate Temporal Fusion Network (SMTAFormer) a novel approach leveraging multi-head self-attention for predicting readmission among ICU patients. By integrating static and temporal feature representations while acknowledging feature correlations, our model utilizes multi-head self-attention to capture both intra-correlations among multivariate temporal features and inter-correlations between static and multi-variate temporal features.\nThrough experiments conducted on RRA an essential hypertension readmission dataset extracted from the MIMIC-III database, we achieved promising results with an accuracy of up to 0.866 and an AUC of up to 0.717. Moving forward, our future endeavors include expanding the feature set for enhanced readmission prediction and adapting our methodology to local readmission datasets. Additionally, we aim to address the optimization of patient discharge criteria as a key focus area for further research."}, {"title": "Declarations", "content": ""}]}