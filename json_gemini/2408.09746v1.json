{"title": "ENHANCED CASCADE PROSTATE CANCER CLASSIFIER IN MP-MRI UTILIZING RECALL FEEDBACK ADAPTIVE Loss AND PRIOR KNOWLEDGE-BASED FEATURE EXTRACTION", "authors": ["Kun Luo", "Bowen Zheng", "Shidong Lv", "Jie Tao", "Qiang Wei"], "abstract": "Prostate cancer is the second most common cancer in males worldwide, and mpMRI is commonly used for diagnosis. However, interpreting mpMRI is challenging and requires expertise from radiologists. This highlights the urgent need for automated grading in mpMRI. Existing studies lack integration of clinical prior information and suffer from uneven training sample distribution due to prevalence. Therefore, we propose a solution that incorporates prior knowledge, addresses the issue of uneven medical sample distribution, and maintains high interpretability in mpMRI. Firstly, we introduce Prior Knowledge-Based Feature Extraction, which mathematically models the PI-RADS criteria for prostate cancer as diagnostic information into model training. Secondly, we propose Adaptive Recall Feedback Loss to address the extremely imbalanced data problem. This method adjusts the training dynamically based on accuracy and recall in the validation set, resulting in high accuracy and recall simultaneously in the testing set. Thirdly, we design an Enhanced Cascade Prostate Cancer Classifier that classifies prostate cancer into different levels in an interpretable way, which refines the classification results and helps with clinical intervention. Our method is validated through experiments on the PI-CAI dataset and outperforms other methods with a more balanced result in both accuracy and recall rate.", "sections": [{"title": "1 Introduction", "content": "Prostate cancer is the second most common cancer and the fifth leading cause of cancer-related death for men worldwide. It has the highest incidence rate among male tumors in over half of the countries [1]. Early diagnosis is a prerequisite for subsequent clinical treatment. Therefore, it is crucial to accurately detect clinically significant prostate cancer (csPCa) to avoid overtreatment and reduce mortality. Prostate biopsy is the gold standard for diagnosing csPCa. Currently, biopsies are mostly guided by transrectal ultrasonography (TRUS). However, the difficulty in accurately identifying suspicious nodules using ultrasound poses a challenge, requiring significant expertise. Additionally, biopsy is an invasive procedure that carries risks such as bleeding, infection, and urinary retention. Therefore, a non-invasive and accurate method for diagnosing csPCa is still needed.\nMultiparametric magnetic resonance imaging (mpMRI) has become increasingly popular for diagnosing prostate cancer as it provides both anatomical and functional information. It aids in distinguishing csPCa requiring intervention, minimizing overdiagnosis and overtreatment [2]. However, mpMRI interpretation requires substantial expertise and efforts from radiologists, prompting the urgent need for automatic diagnosis of csPCa to ease interpretation burdens and mitigate treatment risks.\nWith the development of artificial intelligence, deep learning is increasingly being applied to medical imaging and has become one of the most important methods in current medical image analysis [3]. Many researchers have proposed efficient and mature network architectures such as ResNet [4], for tasks such as medical image classification and segmentation. Deep learning automates task-specific information learning, eliminating the need for manual extraction efforts. Although it may sacrifice some medical interpretability, it streamlines processes and yields superior performance in targeted tasks."}, {"title": "1.1 Related works", "content": "Recently, there has been a rise in computer-aided diagnosis (CAD) solutions for prostate cancer (PCa) using mpMRI images [5, 6, 7, 8]. Conventional machine learning methods primarily use image-based approaches or radiomics for binary classification tasks [9, 10]. Although these methods yield satisfactory results, they often struggle with more complex multi-classification problems. Deep learning techniques have been extensively explored to address this issue [11, 12, 13, 14], particularly in the context of multi-classification tasks [15]. however, due to the inherent complexity of the multi-classification problem, the performance is not as satisfactory as in binary classification [16, 17].\nExperience and evidence-based medicine are crucial for medical diagnosis. Exploring the integration of them in analyzing images for downstream tasks remains an ongoing endeavor. Matin Hosseinzadeh incorporate the anatomical segmentation mask as prior knowledge to guide the network's focus on the prostate region and improves classification performance [18]. Alberto Rossi proposed a new deep learning architecture that enables the comparison of new cases with existing cases of prior diagnosis and increase its accuracy [19]. Abhejit Rajagopal improved the classification performance by incorporating prior knowledge of histopathology [20]. Their work utilizes prior information to improve performance, but the information they use is simplistic and superficial. Complicated information such as diagnostic criteria and medical judgment is not fully utilized.\nThe imbalanced sample sizes across diseases and stages may bias the classification towards specific sam-ples. Given the cost of misdiagnosis, prioritizing recall rates for these specific samples is crucial. The loss function is a crucial component in deep learning, and an effective loss function enables the model to identify both positive and negative instances. The conventional cross-entropy loss function faces challenges in multi-classification due to strict data conditions. Tsung-Yi Lin improves it for multi-classification by introducing adjustment factors to handle unequal sample class proportions [21]. Junjiao Tian introduced Recall Loss, a modification of conventional cross-entropy loss, which incorporates recall as a dynamic parameter. The loss is dynamically weighted based on its changing recall rate every epoch [22]. Although these methods have achieved good results, they may not fully suit prostate cancer ISUP classification, especially in distinguishing fewer samples. This potentially leading to locally optimal solutions where samples are classified into a single class, hindering achievement of high recall rates and accuracy simultaneously.\nDiagnosis is a complex process that requires a comprehensive understanding of the disease and the patient's condition. It is often divided into multiple stages, each refining the diagnosis. The detection of csPCa is the classification of ISUP 0-1 and ISUP 2-5, which is considered the simplest task in prostate cancer classification. The classification of ISUP 2-3 versus ISUP 4-5 and ISUP 4 versus ISUP 5 is more complex, which indicate the severity of prostate and different clinical interventions. Currently, there is limited research on these complex tasks. The cascade strategy has been used in prostate cancer imaging to simplify complex problems"}, {"title": "1.2 Contributions", "content": "In this study, we propose the modeling and strategy design for prostate cancer ISUP classification by combining the prior knowledge of grading criteria and diagnostic procedures to address the aforementioned shortcomings. Our specific contributions are as follows:\n\u2022 We propose a novel loss function, Recall Feedback Adaptive Loss (RFAloss), which dynamically adjusts during training to expand the parameter search space and adjust the search direction based on the feedback of recall. This addresses the bias caused by the imbalanced sample distribution. We introduce two dynamic parameters and three hyperparameters, evaluate their roles along with the loss function, and prove that RFAloss achieves high recall rates and maintains relatively high accuracy under suitable hyperparameters.\n\u2022 We introduce a prior knowledge-based feature extraction strategy (F-E) based on the report standards of prostate cancer in mpMRI. We validate the effectiveness of this strategy from both visualization and experimental perspectives. When using the F-E results as additional input, it significantly improves the model's ability to generalize on the test set.\n\u2022 We propose a cascade confidence refinement strategy to improve the diagnostic process for physicians. This strategy allows the classifier to output and fuse results based on clinical practice, resulting in a more balanced confusion matrix even with highly imbalanced samples."}, {"title": "2 MATERIALS AND METHODS", "content": null}, {"title": "2.1 Patient Data and Preprocessing", "content": "We train and validate our method using the public dataset of PI-CAI Challenge [25], which consists of three sequences: T2WI, ADC, and DWI, along with prostate gland segmentation masks and their ISUP labels for 1499 cases. Considering the data imbalanced of different ISUP stages and the prior knowledge of diagnostic standards for prostate cancer in mpMRI, we preprocess the data as follows:"}, {"title": "2.1.1 Prostate Gland Cropping", "content": "The effective region for prostate cancer assessment in the original mpMRI images is primarily confined within the prostate gland. Therefore, we crop and resample the data to ensure that the effective training data are within the largest bounding cuboid of the prostate gland. Additionally, we removed a small number of samples that lacked masks. Finally, we resize both width and length to 224 and normalized the pixel values of each point to be between 0 and 255."}, {"title": "2.1.2 ADC, T2W Image Signal Flipping", "content": "Typical prostate cancer shows a hypointense signal in T2WI and ADC images and a hyperintense signal in DWI. To better model image features, we performed signal flipping on the ADC and T2WI sequences. We processed each layer individually, transforming the original lesion from local hypointense to local hyperintense."}, {"title": "2.1.3 Block Mean Optimization for Ineffective Region in ADC Images", "content": "To mitigate the impact of extreme signal levels in ADC and DWI images, we introduce a 2\u00d72 block mean operator for both channels. This operator identifies regions where the mean value exceeds a threshold $K_{max}$ in ADC but remains below a threshold $K_{min}$ in DWI, labeling these areas as ineffective. Subsequently, we invert the pixel values within these regions of the ADC channel to reduce interference from confusing high signals.\nif $mean(B_{ADC}) > K_{max}, mean(B_{DWI}) < K_{min}$:\n$D_{ADC} = max(D_{ADC}) \u2013 D_{i,j,k}^{ADC}$\n(1)\nwhere B represents the block region, k denotes the k-th layer of the ADC channel, and $B_{i,j,k}$ are the pixel points belonging to the block."}, {"title": "2.2 Prior Knowledge-based Feature Extraction (F-E)", "content": "The assessment of prostate cancer in mpMRI is based on the Prostate Imaging Reporting and Data System (PI-RADS) [26, 27]. Typical prostate cancer shows a hypointense signal in T2WI and ADC images and a hyperintense signal in DWI. The risk of prostate cancer is evaluated by the intensity and the area of the abnormal signal zone. By incorporating this prior knowledge into our model, we improve the generalization ability of the model. This also improve the interpretability of the model, which can help doctors in diagnosis by highlighting areas with a high probability of lesions.\nQuantifying these standards was difficult because signal contrast and local signal range are subjective. To overcome this challenge, we enhanced subjective features by emphasizing important information across different sequences and reducing interference from blurred signals. We quantified local signals by assessing differences in symmetrical positions, where significant intensity discrepancies indicate a high probability of abnormal tissue. Besides, considering that lesions may occur along the gland's axis, we compared the differences between the axial position and surrounding positions. As a result, we refined our theoretical framework and developed the following specific modeling algorithm:"}, {"title": "2.2.1 Symmetrical Difference Algorithm", "content": "To quantify the intensity differences in symmetrical positions, we improve upon the classic difference method to highlight signals in the feature area while suppressing signals in non-feature areas. The intensity difference in symmetrical positions is defined as follows:\n$E_{i,j,k} = D_{i,j,k}^{N} - D_{im-i,j,k}^{N}$\n(2)"}, {"title": "2.2.2 Symmetrically weighted Algorithm", "content": "To capture the differences between the axial line and surrounding positions, we propose a symmetrically weighted algorithm (SW) to quantify the attention to the axial line using a weighted sum and normalization approach. For each row pixel of the image, we designed a weight function that enhances the difference between parts near the axial line and those away from it. Here is the algorithm:\n$w(x) = 1 -0.55 sin(\\frac{\\pi x}{xm})$\n(4)\n$SW(D_{j,k}^{N}) = \\frac{\\sum_{i} w(x) D_{i,j,k}^{N}}{D_{i,j,k}^{N}}$\n(5)"}, {"title": "2.2.3 Feature Fusion Strategy", "content": "To accurately represent the results from the SW and SD algorithm, we chose a normal distribution function with a sharper distinction within a specific interval to fuse the two results:\n$p(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} exp(\\frac{(x - \\mu)^{2}}{2\\sigma^{2}})$   (6)\nTo map p(x) to the interval (0,1), we use X to represent each row and perform the following normalization:\n$W(x) = \\frac{p(x)}{max(p(X))}$   (7)\nTherefore, our feature fusion strategy is as follows:\n$Mix(\\zeta) = W(\\zeta)SW(\\zeta) + (1 - W(\\zeta))SD(\\zeta) ;  \\zeta \\subseteq D$   (8)\nwhere D is the pixel points set of mpMRI.The algorithm generates three feature extraction images from the T2WI, ADC, and DWI channels. Since the T2WI emphasizes texture features, there are relatively fewer local signal differences. We fused the T2W, ADC, and DWI channels using a weighted addition with weights of 1:2:2 to create the final feature map. The feature extraction process is illustrated in Figure 2."}, {"title": "2.3 Recall Feedback Adaptive Loss (RFAloss)", "content": "The training process can be conceptualized as searching for optimal parameters within the parameter space. However, due to the imbalance of data in medical diagnosis, the search process is often biased towards the majority class, leading to suboptimal solutions. Therefore, we constructed a loss function that accurately guides the search direction and widens the search scope. Inspired by control theory, we introduce the Recall Feedback Adaptive Loss:\n$L_{RFA} = \\begin{cases}A P_{l=1} \u2013 (1 \u2013 a) log(P_{l=0}), & c = 0, \\\\-Alog(P_{l=1}) + (1 \u2013 a) P_{l=0}, & c = 1.\\end{cases}$\n(9)\n$A = M \\frac{a^{n_{1}}}{r^{n_{2}}}$   (10)\nwhere P represents the probability of the model's output after softmax, c and l denote the predicted label and the true label, respectively. a and r are the accuracy and recall of the validation. A is used as the adjustment factor. It focuses on positive and negative samples simultaneously and use the accuracy and recall as dynamic feedback to adjusting the A. We control the RFAloss by three hyperparameters $n_{1},n_{2},M$ to guide the search direction. Figure 3 illustrates how the RFAloss works. The design rationale and the mechanism of the RFAloss are detailed in the following sections."}, {"title": "2.3.1 Setting of Base Framework", "content": "A functional loss function consists of a base structure and functional coefficients. The cross-entropy loss function is commonly used base structure. It is defined as follows:\n$L_{CE} = - (y\u22c5log(P) + (1 \u2212y)\u22c5log(1 \u2013 P))$;   (11)\nwhere the y and 1 y restrict the loss function to focus only on one-hot encoded label. In a high-quality binary classification, the one-hot encoded output label should approach 1 and the non-label should approach 0. The model should be trained to meet this criterion. Therefore, our framework should adhere to the following form:"}, {"title": "2.3.2 Setting of Dynamic Differential Feedback Coefficients", "content": "Misdiagnosis and misclassification of disease severity can be costly for physicians. However, the model often classifies cases into the majority class due to the imbalanced data in clinical. Junjiao Tian's Recall Loss [22] attempted to address this issue by adjusting the recall during training to modify the weights of different classes:\n$RecallCE = - \\sum_{c=1}^{C} \\sum_{n:y=c}^{}(1 - R_{c,t})log(p_{n, t})$  (14)"}, {"title": "2.3.3 Setting of Feedback Intensity Hyperparameters", "content": "The proposed loss function in Equation 16 already allows for feedback. We further introduce three adjustable hyperparameters for feedback intensity to control the feedback process: M, $n_{1}$, and $n_{2}$. They are used to improve $A_{o}$ into parameter A as in equation 10, thus allowing control over the loss function. Our proposed loss aims to make the search direction fluctuate toward the ideal direction. The increase in $n_{1}$ and $n_{2}$ exponentially increases the degree of fluctuation. It is important to note that these two parameters, $n_{1}$ and $n_{2}$, should not be too large nor too small. This is because the search direction and search scope will restrict each other. Further elaboration on this topic will be provided in the DISCUSSION section."}, {"title": "2.4 Cascade Refinement Confidence Strategy", "content": "In clinical practice, medical diagnosis is a cascade procedure due to the complex nature of diseases. In artificial intelligence, a cascade model can extract complex features from different levels and use the output of one level as input for the next level. This approach may improve the model's performance when dealing with imbalanced data.\nTherefore, we transformed the overall ISUP classification into a cascade classification task. We trained three classifiers (classifier1, classifier2, and classifier3) to perform binary classifications. Classifier1 distinguishes between levels 0-1 and 2-5,and is utilized for diagnosing csPCa, with ISUP levels 0-1 indicating a benign lesion or non-csPCa. while classifier2 separates levels 2-3 from levels 4-5, determines the appropriate clinical interventions for prostate patients, where ISUP levels 2-3 suggest middle-grade csPCa with a relatively positive prognosis and ISUP levels 4-5 indicate high-grade csPCa with an invasion tendency. classifier 3 focuses on classifying level 4 versus level 5, quantifiing the severity of high-grade csPCa, where surgery may be effective for ISUP level 4 patients but not for ISUP level 5 due to increased invasiveness and malignancy.\nTo refine the confidence of the final classification, we cascaded the results of the three classifiers. This cascade strategy is illustrated in Figure 1. We refine the output probabilities of positive classes for each classifier"}, {"title": "3 EXPERIMENTS", "content": "We conducted multiple experiments to assess the effectiveness of our methods. Since some of the ISUP 0 and 1 labels are generated by artificial intelligence and the significant medical importance of classifying ISUP 2-3 and 4-5, we opted for binary classification (ISUP 2-3 vs. ISUP 4-5) for our Hyperparameter, ablation and Comparison experiments. Finally, we compared the results of cascade confidence refinement using the optimal RFA loss and feature extraction strategy with those obtained from multi-classification based on cross-entropy."}, {"title": "3.1 Experimental Setup", "content": "We conducted all the work on NVIDIA 2080Ti. The dataset was divided into training and test sets in a ratio of 9:1. The training set was further split into a training subset and a validation subset in an 8:2 ratio. William's research [28] has demonstrated that ResNet has a good classification ability for csPCa. Therefore, We utilized a modified three-dimensional convolutional ResNet101 as the backbone architecture. Adam optimizer was employed with an initial learning rate of 0.0005, which was reduced to 1/10 of the original rate at 100 and 200 epochs. A batch size of 16 was utilized, and iterations were continued until reaching 500 epochs or until significant early convergence occurred.\nTaking into account the stochastic nature of the fluctuation search, we save results where accuracy is above 0.7 and recall is above 0.6 as excellent parameters. The set of parameters for the test process is from the excellent parameter set."}, {"title": "3.2 Hyperparameter Experiment for RFA Loss", "content": "To evaluate the general effects of various hyperparameters of the loss function, we conducted the following experiments while keeping other variables constant. Five-fold cross-validation was performed on the training set, and the mean of the optimal results was used as the experimental indicator for the group of hyperparameters.\nFirstly, we conducted four experiments with $n_{1}$ set to 0.25, 0.5, 0.75, and 1 while keeping $n_{2}$ and M fixed at 3 and 0.3 respectively. The goal was to amplify the fluctuation of Equation 10 by adjusting $n_{1}$.\nNext, to assess the influence of $n_{2}$, we set $n_{1}$ = 1 and M = 0.5. We then varied $n_{2}$ from 1 to 3 and evaluated its effect.\nFinally, we conducted an experiment to evaluate the impact of M on the entire system. We controlled $n_{1}$ and $n_{2}$ at values of 1 and 3 respectively, and performed three experiments with different values of M: 0.3, 0.5, and 0.7."}, {"title": "3.3 Ablation Experiments", "content": "To validate the effectiveness of our loss function, we compared it with classical ones such as cross-entropy loss, focal loss, and recall loss. We performed three experiments on training sets with different random seed ,and took the average of the first three best results on the test set as the result of the ablation experiment. This comparison allowed us to verify the feedback effect and final performance of our proposed loss function. Additionally, we assessed the effectiveness of the feature extraction module by integrating it as an additional channel input into different loss functions. Finally, we evaluated the synergistic effect of combining both methods."}, {"title": "3.4 Comparison experiment", "content": "To verify the superiority of our work, we compared it with three methods: M3T [29], HiFuse [30], and MedViT [31]. M3T combines CNN and Transformer model for 3D medical image classification. HiFuse and MedViT"}, {"title": "3.5 Evaluation of Cascaded Refinement Confidence Strategy", "content": "We evaluated the effectiveness of our work by using optimal parameters from ISUP 2-3 and 4-5 classification to perform two binary classification tasks (ISUP 0-1 versus ISUP 2-5, ISUP 4 versus ISUP 5). We compared our proposed method with a baseline six-class ISUP classification based on cross-entropy to assess its efficacy and superiority."}, {"title": "3.6 Evaluation Metrics", "content": "We use recall and accuracy (acc) to evaluate classification performance and compute precision for the samples of interest. In hyperparameter experiments, we propose an acc-recall score(ARS) to simultaneously assess the fusion results of recall and precision with equal weights and different weights. For the comprehensive evaluation, we adopt two metrics: ARS score and F2-Score. In the ablation experiments, we use F2-Score and Area Under the Curve (AUC) as evaluation metrics.\nThe acc-recall score is the geometric mean of recall and accuracy:\n$ARS = \\sqrt{ra}$ (18)\nwhere r represents recall and a represents accuracy.\nThe F-score is a measure of predictive performance. Positive real factor in the F2-Score is 2 to defines recall as twice as important as precision. The AUC is the area under the ROC (Receiver Operating Characteristic) curve. The AUC value ranges from 0.5 to 1, where a higher value closer to 1 indicates greater accuracy in detection methods. An AUC of 0.5 suggests low accuracy and no practical value.\nTo better understand the fluctuation of loss functions and the impact of hyperparameters, we use visualization methods to depict the descent of training losses, which helps with auxiliary analysis and interpretation.To evaluate the effectiveness of our cascaded refinement confidence strategy, the confusion matrix is used."}, {"title": "5 DISCUSSION", "content": null}, {"title": "5.1 Practical Significance of RFAloss Hyperparameters", "content": "We will discuss the effect and interpretable hyperparameters tuning strategies below. $n_{1}$, $n_{2}$, and M are adjustable hyperparameters that affect the accuracy (a), recall rate (r), and equation 15, respectively. The magnitude of the feedback effect can be reflected by the fluctuation of the curves in Figure 4, and the final results are shown in Table 1.\nBased on the results and our original design intent, $n_{2}$ aligns with our hypothesis and has significant effects. It directly affects the recall rate, resulting in an exponential growth in the impact of the recall. This leads to an increase in A and a greater focus on positive examples over negative ones. The results also validate our prediction, as shown in Figure 4b. Increasing $n_{2}$ noticeably increases the amplitude of fluctuations, indicating a stronger penalty on dynamic recall for each update. However, the experiments in Table 1 show that increased fluctuation indicates stronger feedback and a wider search range but does not necessarily lead to improved final metric results.\nWe introduce $n_{1}$ to improve accuracy by directing feedback towards accuracy improvement. In our study, the positive class is significantly underrepresented. Additionally, our loss function is designed to prioritize a high recall rate by predicting more positive examples. Therefore, we attribute the lower accuracy to the scarcity of predictions for negative samples. To improve the accuracy, we need to increase the attention to negative"}, {"title": "5.2 Discussion on Interpretability", "content": "As shown in Figure 6e, the model lacks sensitivity to samples with higher ISUP grades due to two reasons. First, the uneven distribution is caused by disease prevalence. Second, the classification of prostate cancer grades in clinical lacks clear boundaries, making it challenging to train a comprehensive understanding model due to the complexity of ambiguous medical knowledge involved. In clinical practice, diagnosis also follows a stepwise grading approach for clinical decision-making. Our cascaded refinement strategy models this process: Classifier C\u00b9 trains the model for diagnosing csPCa; classifiers C\u00b2 and C\u00b3 differentiate between different degrees of disease severity, reflecting varying levels of clinical intervention.\nOur research focuses on the recall rate in medical tasks. We prioritize modeling the clinical decision-making aspect of Classifier C\u00b2 as it is pivotal. The cascade training directly incorporates optimal hyperparameters from C\u00b2, resulting in outstanding results that demonstrate the superior generality of our loss function.\nLastly, our work consistently aims to assist physicians. Our feature extraction maps can serve as diagnostic aids for doctors, while the cascaded refinement strategy can provide flexible confidence levels based on mpMRI. Practitioners can use individual classifiers for specific clinical applications, enhancing their diagnostic capabilities."}, {"title": "6 CONCLUSIONS", "content": "We propose a recall-guided deep learning-assisted ISUP grading strategy based on mpMRI. Compared to the baseline, our approach improves recall by 29.1%. Our work emphasizes the practical significance by integrating ISUP grading indicators and diagnostic processes of prostate cancer into deep learning. Our primary contribution lies in introducing a universal Recall Feedback Adaptive loss function that prioritizes low prevalence and low quantity labels. This loss function enhances the search direction and scope during the training process. Furthermore, our prior knowledge-based feature extraction strategy amplifies the differences between lesion areas and their surroundings, providing prior information to the model. Under the premise of RFAloss, this approach increases recall by 12.9% and the accuracy is maintained. We implement a cascaded refinement strategy, which results in a diagonal confusion matrix for the recall metric. These methods are valuable references for medical image processing and its practical applications."}]}