{"title": "ENHANCED CASCADE PROSTATE CANCER CLASSIFIER IN\nMP-MRI UTILIZING RECALL FEEDBACK ADAPTIVE Loss\nAND PRIOR KNOWLEDGE-BASED FEATURE EXTRACTION", "authors": ["Kun Luo", "Bowen Zheng", "Shidong Lv", "Jie Tao", "Qiang Wei"], "abstract": "Prostate cancer is the second most common cancer in males worldwide, and mpMRI is\ncommonly used for diagnosis. However, interpreting mpMRI is challenging and requires\nexpertise from radiologists. This highlights the urgent need for automated grading in\nmpMRI. Existing studies lack integration of clinical prior information and suffer from uneven\ntraining sample distribution due to prevalence. Therefore, we propose a solution that\nincorporates prior knowledge, addresses the issue of uneven medical sample distribution,\nand maintains high interpretability in mpMRI. Firstly, we introduce Prior Knowledge-Based\nFeature Extraction, which mathematically models the PI-RADS criteria for prostate cancer as\ndiagnostic information into model training. Secondly, we propose Adaptive Recall Feedback\nLoss to address the extremely imbalanced data problem. This method adjusts the training\ndynamically based on accuracy and recall in the validation set, resulting in high accuracy and\nrecall simultaneously in the testing set. Thirdly, we design an Enhanced Cascade Prostate\nCancer Classifier that classifies prostate cancer into different levels in an interpretable way,\nwhich refines the classification results and helps with clinical intervention. Our method is\nvalidated through experiments on the PI-CAI dataset and outperforms other methods with\na more balanced result in both accuracy and recall rate.", "sections": [{"title": "1 Introduction", "content": "Prostate cancer is the second most common cancer and the fifth leading cause of cancer-related death for\nmen worldwide. It has the highest incidence rate among male tumors in over half of the countries [1]. Early\ndiagnosis is a prerequisite for subsequent clinical treatment. Therefore, it is crucial to accurately detect\nclinically significant prostate cancer (csPCa) to avoid overtreatment and reduce mortality. Prostate biopsy is\nthe gold standard for diagnosing csPCa. Currently, biopsies are mostly guided by transrectal ultrasonography\n(TRUS). However, the difficulty in accurately identifying suspicious nodules using ultrasound poses a challenge,\nrequiring significant expertise. Additionally, biopsy is an invasive procedure that carries risks such as bleeding,\ninfection, and urinary retention. Therefore, a non-invasive and accurate method for diagnosing csPCa is still\nneeded.\nMultiparametric magnetic resonance imaging (mpMRI) has become increasingly popular for diagnosing\nprostate cancer as it provides both anatomical and functional information. It aids in distinguishing csPCa\nrequiring intervention, minimizing overdiagnosis and overtreatment [2]. However, mpMRI interpretation\nrequires substantial expertise and efforts from radiologists, prompting the urgent need for automatic diagnosis\nof csPCa to ease interpretation burdens and mitigate treatment risks.\nWith the development of artificial intelligence, deep learning is increasingly being applied to medical imaging\nand has become one of the most important methods in current medical image analysis [3]. Many researchers\nhave proposed efficient and mature network architectures such as ResNet [4], for tasks such as medical image\nclassification and segmentation. Deep learning automates task-specific information learning, eliminating the\nneed for manual extraction efforts. Although it may sacrifice some medical interpretability, it streamlines\nprocesses and yields superior performance in targeted tasks."}, {"title": "1.1 Related works", "content": "Recently, there has been a rise in computer-aided diagnosis (CAD) solutions for prostate cancer (PCa) using\nmpMRI images [5, 6, 7, 8]. Conventional machine learning methods primarily use image-based approaches or\nradiomics for binary classification tasks [9, 10]. Although these methods yield satisfactory results, they often\nstruggle with more complex multi-classification problems. Deep learning techniques have been extensively\nexplored to address this issue [11, 12, 13, 14], particularly in the context of multi-classification tasks [15].\nhowever, due to the inherent complexity of the multi-classification problem, the performance is not as\nsatisfactory as in binary classification [16, 17].\nExperience and evidence-based medicine are crucial for medical diagnosis. Exploring the integration of them\nin analyzing images for downstream tasks remains an ongoing endeavor. Matin Hosseinzadeh incorporate the\nanatomical segmentation mask as prior knowledge to guide the network's focus on the prostate region and\nimproves classification performance [18]. Alberto Rossi proposed a new deep learning architecture that enables\nthe comparison of new cases with existing cases of prior diagnosis and increase its accuracy [19]. Abhejit\nRajagopal improved the classification performance by incorporating prior knowledge of histopathology [20].\nTheir work utilizes prior information to improve performance, but the information they use is simplistic and\nsuperficial. Complicated information such as diagnostic criteria and medical judgment is not fully utilized.\nThe imbalanced sample sizes across diseases and stages may bias the classification towards specific sam-\nples. Given the cost of misdiagnosis, prioritizing recall rates for these specific samples is crucial. The loss\nfunction is a crucial component in deep learning, and an effective loss function enables the model to identify\nboth positive and negative instances. The conventional cross-entropy loss function faces challenges in multi-\nclassification due to strict data conditions. Tsung-Yi Lin improves it for multi-classification by introducing\nadjustment factors to handle unequal sample class proportions [21]. Junjiao Tian introduced Recall Loss, a\nmodification of conventional cross-entropy loss, which incorporates recall as a dynamic parameter. The loss\nis dynamically weighted based on its changing recall rate every epoch [22]. Although these methods have\nachieved good results, they may not fully suit prostate cancer ISUP classification, especially in distinguishing\nfewer samples. This potentially leading to locally optimal solutions where samples are classified into a single\nclass, hindering achievement of high recall rates and accuracy simultaneously.\nDiagnosis is a complex process that requires a comprehensive understanding of the disease and the patient's\ncondition. It is often divided into multiple stages, each refining the diagnosis. The detection of csPCa is the\nclassification of ISUP 0-1 and ISUP 2-5, which is considered the simplest task in prostate cancer classification.\nThe classification of ISUP 2-3 versus ISUP 4-5 and ISUP 4 versus ISUP 5 is more complex, which indicate\nthe severity of prostate and different clinical interventions. Currently, there is limited research on these\ncomplex tasks. The cascade strategy has been used in prostate cancer imaging to simplify complex problems"}, {"title": "1.2 Contributions", "content": "In this study, we propose the modeling and strategy design for prostate cancer ISUP classification by\ncombining the prior knowledge of grading criteria and diagnostic procedures to address the aforementioned\nshortcomings. Our specific contributions are as follows:\n\u2022 We propose a novel loss function, Recall Feedback Adaptive Loss (RFAloss), which dynamically\nadjusts during training to expand the parameter search space and adjust the search direction based\non the feedback of recall. This addresses the bias caused by the imbalanced sample distribution.\nWe introduce two dynamic parameters and three hyperparameters, evaluate their roles along with\nthe loss function, and prove that RFAloss achieves high recall rates and maintains relatively high\naccuracy under suitable hyperparameters.\n\u2022 We introduce a prior knowledge-based feature extraction strategy (F-E) based on the report standards\nof prostate cancer in mpMRI. We validate the effectiveness of this strategy from both visualization\nand experimental perspectives. When using the F-E results as additional input, it significantly\nimproves the model's ability to generalize on the test set.\n\u2022 We propose a cascade confidence refinement strategy to improve the diagnostic process for physicians.\nThis strategy allows the classifier to output and fuse results based on clinical practice, resulting in a\nmore balanced confusion matrix even with highly imbalanced samples."}, {"title": "2 MATERIALS AND METHODS", "content": ""}, {"title": "2.1 Patient Data and Preprocessing", "content": "We train and validate our method using the public dataset of PI-CAI Challenge [25], which consists of three\nsequences: T2WI, ADC, and DWI, along with prostate gland segmentation masks and their ISUP labels for\n1499 cases. Considering the data imbalanced of different ISUP stages and the prior knowledge of diagnostic\nstandards for prostate cancer in mpMRI, we preprocess the data as follows:"}, {"title": "2.1.1 Prostate Gland Cropping", "content": "The effective region for prostate cancer assessment in the original mpMRI images is primarily confined within\nthe prostate gland. Therefore, we crop and resample the data to ensure that the effective training data\nare within the largest bounding cuboid of the prostate gland. Additionally, we removed a small number of\nsamples that lacked masks. Finally, we resize both width and length to 224 and normalized the pixel values\nof each point to be between 0 and 255."}, {"title": "2.1.2 ADC, T2W Image Signal Flipping", "content": "Typical prostate cancer shows a hypointense signal in T2WI and ADC images and a hyperintense signal in\nDWI. To better model image features, we performed signal flipping on the ADC and T2WI sequences. We\nprocessed each layer individually, transforming the original lesion from local hypointense to local hyperintense."}, {"title": "2.1.3 Block Mean Optimization for Ineffective Region in ADC Images", "content": "To mitigate the impact of extreme signal levels in ADC and DWI images, we introduce a 2\u00d72 block mean\noperator for both channels. This operator identifies regions where the mean value exceeds a threshold Kmax\nin ADC but remains below a threshold Kmin in DWI, labeling these areas as ineffective. Subsequently, we\ninvert the pixel values within these regions of the ADC channel to reduce interference from confusing high\nsignals.\nif mean(BADC) > Kmax, mean(BDWI) < Kmin:\n$D_{k}^{ADC} = max(D^{ADC}) \u2013 D^{ADC}_{B,Y_B}$.\n(1)\nwhere B represents the block region, k denotes the k-th layer of the ADC channel, and B,YB are the pixel\npoints belonging to the block."}, {"title": "2.2 Prior Knowledge-based Feature Extraction (F-E)", "content": "The assessment of prostate cancer in mpMRI is based on the Prostate Imaging Reporting and Data System\n(PI-RADS) [26, 27]. Typical prostate cancer shows a hypointense signal in T2WI and ADC images and a\nhyperintense signal in DWI. The risk of prostate cancer is evaluated by the intensity and the area of the\nabnormal signal zone. By incorporating this prior knowledge into our model, we improve the generalization\nability of the model. This also improve the interpretability of the model, which can help doctors in diagnosis\nby highlighting areas with a high probability of lesions.\nQuantifying these standards was difficult because signal contrast and local signal range are subjective. To\novercome this challenge, we enhanced subjective features by emphasizing important information across\ndifferent sequences and reducing interference from blurred signals. We quantified local signals by assessing\ndifferences in symmetrical positions, where significant intensity discrepancies indicate a high probability\nof abnormal tissue. Besides, considering that lesions may occur along the gland's axis, we compared the\ndifferences between the axial position and surrounding positions. As a result, we refined our theoretical\nframework and developed the following specific modeling algorithm:"}, {"title": "2.2.1 Symmetrical Difference Algorithm", "content": "To quantify the intensity differences in symmetrical positions, we improve upon the classic difference method\nto highlight signals in the feature area while suppressing signals in non-feature areas. The intensity difference\nin symmetrical positions is defined as follows:\n$E_{i,j,k} = D_{i,j,k}^{N} - D_{im-i,j,k}^{N}$\n(2)"}, {"title": "2.2.2 Symmetrically weighted Algorithm", "content": "To capture the differences between the axial line and surrounding positions, we propose a symmetrically\nweighted algorithm (SW) to quantify the attention to the axial line using a weighted sum and normalization\napproach. For each row pixel of the image, we designed a weight function that enhances the difference\nbetween parts near the axial line and those away from it. Here is the algorithm:\nw(x) = 1 -0.55 sin(\\frac{x}{Xm})\n(4)\nSW(Dj,k) = \\frac{\\sum_{i=1}^{Xm} w(x)D_{i,j,k}^{N}}{\\sum w(x)D_{i,j,k}^{N}}\n(5)"}, {"title": "2.2.3 Feature Fusion Strategy", "content": "To accurately represent the results from the SW and SD algorithm, we chose a normal distribution function\nwith a sharper distinction within a specific interval to fuse the two results:\np(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^{2}}} exp(-\\frac{(x - \\mu)^{2}}{2\\sigma^{2}})\n(6)\nTo map p(x) to the interval (0,1), we use X to represent each row and perform the following normalization:\nW(x) = \\frac{p(x)}{max(p(X))}\n(7)\nTherefore, our feature fusion strategy is as follows:\nMix(\\zeta) = W(\u03b6)SW(\u03b6) + (1 \u2212 W(\u03b6))SD(\u03b6) ( CD\n(8)\nwhere D is the pixel points set of mpMRI.The algorithm generates three feature extraction images from the\nT2WI, ADC, and DWI channels. Since the T2WI emphasizes texture features, there are relatively fewer local\nsignal differences. We fused the T2W, ADC, and DWI channels using a weighted addition with weights of\n1:2:2 to create the final feature map. The feature extraction process is illustrated in Figure 2."}, {"title": "2.3 Recall Feedback Adaptive Loss (RFAloss)", "content": "The training process can be conceptualized as searching for optimal parameters within the parameter space.\nHowever, due to the imbalance of data in medical diagnosis, the search process is often biased towards the\nmajority class, leading to suboptimal solutions. Therefore, we constructed a loss function that accurately\nguides the search direction and widens the search scope. Inspired by control theory, we introduce the Recall\nFeedback Adaptive Loss:\nL_{RFA} = \\begin{cases}\nA(P_{l=1} \u2212 (1 \u2212 \u03b1) log(P_{l=0}), & c = 0, \\\\-Alog(P_{l=1}) + (1 \u2212 \u03b1)P_{l=0}, & c = 1.\\end{cases}\n(9)\nA = M (\\frac{1}{n1} \u2212 \u03b1)^{n2}\n(10)\nwhere P represents the probability of the model's output after softmax, c and l denote the predicted label\nand the true label, respectively. \u03b1 and r are the accuracy and recall of the validation. A is used as the\nadjustment factor. It focuses on positive and negative samples simultaneously and use the accuracy and\nrecall as dynamic feedback to adjusting the A. We control the RFAloss by three hyperparameters n1,n2,M\nto guide the search direction. Figure 3 illustrates how the RFAloss works. The design rationale and the\nmechanism of the RFAloss are detailed in the following sections."}, {"title": "2.3.1 Setting of Base Framework", "content": "A functional loss function consists of a base structure and functional coefficients. The cross-entropy loss\nfunction is commonly used base structure. It is defined as follows:\nL_{CE} = - (y \u22c5 log(P) + (1 \u2212y) \u22c5 log(1 \u2013 P))\n(11)\nwhere the y and 1 y restrict the loss function to focus only on one-hot encoded label. In a high-quality\nbinary classification, the one-hot encoded output label should approach 1 and the non-label should approach\n0. The model should be trained to meet this criterion. Therefore, our framework should adhere to the\nfollowing form:"}, {"title": "Lbase", "content": "f(Pc=1) + f(Pc\u22601)\n(12)\nwhere f(P) denotes an operator acting on P. We propose distinct output transformation operators to\ndifferentiate penalties for correctly and incorrectly classified one-hot encoded labels. For correct classifications,\nwe use the operator f(P) = - log(P), while for incorrect classifications, we use f(P) = P. This make the\npenalty exhibits a gradual increase as the predicted probability P diminishes towards zero, while maintaining\na relatively flat when P approaches one. Therefore, we have finally determined the base framework as:\nLbase = Poutput\u2260label - log(Poutput=label)\n(13)"}, {"title": "We believe that this framework", "content": "tends to focus more on correctly classified samples during the early training\nstages, while still considering other labels. This facilitates the values of correct one-hot encoded label approach\n1, while that of incorrect label approach 0."}, {"title": "2.3.2 Setting of Dynamic Differential Feedback Coefficients", "content": "Misdiagnosis and misclassification of disease severity can be costly for physicians. However, the model often\nclassifies cases into the majority class due to the imbalanced data in clinical. Junjiao Tian's Recall Loss [22]\nattempted to address this issue by adjusting the recall during training to modify the weights of different\nclasses:\nRecallCE = \u03a3c=1\u03a3n:y=c \\frac{1}{(1 - R_{c,t})}log(pn, t)\n(14)"}, {"title": "Rc,t represents the recall of class c at optimization step t", "content": "and n : y\u2081 = c denotes all samples. Although this\nloss achieved parameter adjustments along with changes in recall, the change is linear and exhibited low\ndynamic variability. Furthermore, it lacks sufficient differentiation of disease samples and is susceptible to\nlocal optima because it only adjusts one parameter dynamically.\nTherefore, we aim to guide the loss function to search towards the recall of the class of interest. We introduce\ndynamic differential feedback coefficients Ao and 1 a. The coefficient Ao directs the loss function to focus\non the cases of interest, while 1 a guides it to focus on the cases that are not of interest. The feedback\ncoefficient Ao is defined as:\nA_{o} = \\frac{1-\u03b1}{r}\n(15)\nwhere \u03b1 represents accuracy, r represents recall. When the recall in validation is low, both recall and accuracy\nare fed back into the training process. This encourages the model to change its search direction, expand its\nscope, and find the parameter that minimizes loss by maximizing recall and accuracy. Combining Equation\n13, our loss function should be a piecewise function conditioned on the predicted class of the output as follows:\nL_{feedback}=\\begin{cases}\nAoP_{l=1} \u2013 (1 \u2212 \u03b1) log(P_{l=0}), & c = 0, \\\\-A_{0} log (P_{l=1})+(1-\u03b1)P_{l=0}, & c = 1.\\end{cases}\n(16)\nWhen the feedback is triggered, the search scope expanded so that the model can escape the local optima.\nTherefore, instead of using smoothing methods like exponential moving averages, we incorporate average\naccuracy and recall results per five epochs as feedback parameters in the loss function for adaptive feedback.\nThe effect of RFAloss derives from the difference between Ao and 1-a. As Ao changes dynamically during\ntraining, so does the difference between Ao and 1-a. After an iteration with a noticeable difference between\nrecall and accuracy, the baseline of the loss function shifts, leading to a significant change in the gradient\ndescent direction. For example, if the recall changes from 1 to 0.5 after an iteration, the attention of the loss\nfunction to Pi=1 increases from one order of magnitude to two orders of magnitude. Consequently, the model\nprefers to classify Pi=1 correctly and deviate from its original search direction, leading to both a change in\nsearch direction and an expansion of the search scope."}, {"title": "2.3.3 Setting of Feedback Intensity Hyperparameters", "content": "The proposed loss function in Equation 16 already allows for feedback. We further introduce three adjustable\nhyperparameters for feedback intensity to control the feedback process: M, n\u2081, and n2. They are used to\nimprove Ao into parameter A as in equation 10, thus allowing control over the loss function. Our proposed\nloss aims to make the search direction fluctuate toward the ideal direction. The increase in n\u2081 and n2\nexponentially increases the degree of fluctuation. It is important to note that these two parameters, n\u2081 and\nn2, should not be too large nor too small. This is because the search direction and search scope will restrict\neach other. Further elaboration on this topic will be provided in the DISCUSSION section."}, {"title": "2.4 Cascade Refinement Confidence Strategy", "content": "In clinical practice, medical diagnosis is a cascade procedure due to the complex nature of diseases. In\nartificial intelligence, a cascade model can extract complex features from different levels and use the output\nof one level as input for the next level. This approach may improve the model's performance when dealing\nwith imbalanced data.\nTherefore, we transformed the overall ISUP classification into a cascade classification task. We trained three\nclassifiers (classifier1, classifier2, and classifier3) to perform binary classifications. Classifier1 distinguishes\nbetween levels 0-1 and 2-5,and is utilized for diagnosing csPCa, with ISUP levels 0-1 indicating a benign\nlesion or non-csPCa. while classifier2 separates levels 2-3 from levels 4-5, determines the appropriate clinical\ninterventions for prostate patients, where ISUP levels 2-3 suggest middle-grade csPCa with a relatively\npositive prognosis and ISUP levels 4-5 indicate high-grade csPCa with an invasion tendency. classifier 3\nfocuses on classifying level 4 versus level 5, quantifiing the severity of high-grade csPCa, where surgery may\nbe effective for ISUP level 4 patients but not for ISUP level 5 due to increased invasiveness and malignancy.\nTo refine the confidence of the final classification, we cascaded the results of the three classifiers. This cascade\nstrategy is illustrated in Figure 1. We refine the output probabilities of positive classes for each classifier"}, {"title": "because they work independently", "content": "Therefore, we can refine the recall of the subcategory by cascading the\nmultiplication of their relevant recall rates.\nR(C(sub \u2013 v)) = R(Cl=v)R(Cl-sub-v) sub - v C v\n(17)\nwhere R denotes the recall rate of the subcategory, sub v represents a subset of categories included in\nthe category v, and Cm represents the number of classifiers. Through this strategy, we achieved a balanced\nconfusion matrix, even with highly imbalanced samples."}, {"title": "3 EXPERIMENTS", "content": "We conducted multiple experiments to assess the effectiveness of our methods. Since some of the ISUP 0 and\n1 labels are generated by artificial intelligence and the significant medical importance of classifying ISUP 2-3\nand 4-5, we opted for binary classification (ISUP 2-3 vs. ISUP 4-5) for our Hyperparameter, ablation and\nComparison experiments. Finally, we compared the results of cascade confidence refinement using the optimal\nRFA loss and feature extraction strategy with those obtained from multi-classification based on cross-entropy."}, {"title": "3.1 Experimental Setup", "content": "We conducted all the work on NVIDIA 2080Ti. The dataset was divided into training and test sets in a\nratio of 9:1. The training set was further split into a training subset and a validation subset in an 8:2 ratio.\nWilliam's research [28] has demonstrated that ResNet has a good classification ability for csPCa. Therefore,\nWe utilized a modified three-dimensional convolutional ResNet101 as the backbone architecture. Adam\noptimizer was employed with an initial learning rate of 0.0005, which was reduced to 1/10 of the original\nrate at 100 and 200 epochs. A batch size of 16 was utilized, and iterations were continued until reaching 500\nepochs or until significant early convergence occurred.\nTaking into account the stochastic nature of the fluctuation search, we save results where accuracy is above\n0.7 and recall is above 0.6 as excellent parameters. The set of parameters for the test process is from the\nexcellent parameter set."}, {"title": "3.2 Hyperparameter Experiment for RFA Loss", "content": "To evaluate the general effects of various hyperparameters of the loss function, we conducted the following\nexperiments while keeping other variables constant. Five-fold cross-validation was performed on the training set,\nand the mean of the optimal results was used as the experimental indicator for the group of hyperparameters.\nFirstly, we conducted four experiments with n\u2081 set to 0.25, 0.5, 0.75, and 1 while keeping n\u2082 and M fixed at\n3 and 0.3 respectively. The goal was to amplify the fluctuation of Equation 10 by adjusting n\u2081.\nNext, to assess the influence of n2, we set n\u2081 = 1 and M = 0.5. We then varied n2 from 1 to 3 and evaluated\nits effect.\nFinally, we conducted an experiment to evaluate the impact of M on the entire system. We controlled n\u2081\nand n\u2082 at values of 1 and 3 respectively, and performed three experiments with different values of M: 0.3,\n0.5, and 0.7."}, {"title": "3.3 Ablation Experiments", "content": "To validate the effectiveness of our loss function, we compared it with classical ones such as cross-entropy\nloss, focal loss, and recall loss. We performed three experiments on training sets with different random seed\n,and took the average of the first three best results on the test set as the result of the ablation experiment.\nThis comparison allowed us to verify the feedback effect and final performance of our proposed loss function.\nAdditionally, we assessed the effectiveness of the feature extraction module by integrating it as an additional\nchannel input into different loss functions. Finally, we evaluated the synergistic effect of combining both\nmethods."}, {"title": "3.4 Comparison experiment", "content": "To verify the superiority of our work, we compared it with three methods: M3T [29], HiFuse [30], and MedViT\n[31]. M3T combines CNN and Transformer model for 3D medical image classification. HiFuse and MedViT"}, {"title": "are trained on 2D images and then tested on the patient level", "content": "We conducted classification experiment of\nISUP 2-3 vs 4-5 using these three schemes on the PI-CAI data set. We did not find related work for ISUP 2-3\nvs 4-5 classification, so we refer to the experimental results of Gianluca Carloni performing similar work on\nthe PI-CAI data set [32].We used their optimal results as an experimental indicator for the comparison, and\nthey are compared with our scheme on evaluation metrics to illustrate the effectiveness of our method."}, {"title": "3.5 Evaluation of Cascaded Refinement Confidence Strategy", "content": "We evaluated the effectiveness of our work by using optimal parameters from ISUP 2-3 and 4-5 classification\nto perform two binary classification tasks (ISUP 0-1 versus ISUP 2-5, ISUP 4 versus ISUP 5). We compared\nour proposed method with a baseline six-class ISUP classification based on cross-entropy to assess its efficacy\nand superiority."}, {"title": "3.6 Evaluation Metrics", "content": "We use recall and accuracy (acc) to evaluate classification performance and compute precision for the samples\nof interest. In hyperparameter experiments, we propose an acc-recall score(ARS) to simultaneously assess\nthe fusion results of recall and precision with equal weights and different weights. For the comprehensive\nevaluation, we adopt two metrics: ARS score and F2-Score. In the ablation experiments, we use F2-Score\nand Area Under the Curve (AUC) as evaluation metrics.\nThe acc-recall score is the geometric mean of recall and accuracy:\nARS = \u221ara\n(18)\nwhere r represents recall and a represents accuracy.\nThe F-score is a measure of predictive performance. Positive real factor in the F2-Score is 2 to defines recall\nas twice as important as precision. The AUC is the area under the ROC (Receiver Operating Characteristic)\ncurve. The AUC value ranges from 0.5 to 1, where a higher value closer to 1 indicates greater accuracy in\ndetection methods. An AUC of 0.5 suggests low accuracy and no practical value.\nTo better understand the fluctuation of loss functions and the impact of hyperparameters, we use visualization\nmethods to depict the descent of training losses, which helps with auxiliary analysis and interpretation.To\nevaluate the effectiveness of our cascaded refinement confidence strategy, the confusion matrix is used."}, {"title": "4 RESULTS", "content": ""}, {"title": "We first experimented with the hyperparameters of the RFA loss function", "content": "The experimental results are\nshown in Table 1, and the trend of loss reduction is depicted in Figure 4. The performance of experiments n1\nand n2 initially improves but then declines as the variables change progressively. According to the results\nof parameter M, the recall, ARS, and F2-score got the best result when M was set to 0.3. However, as M\nincreases, the values of evaluation metrics noticeably decrease. And the increasing of three hyperparameters\nleads to greater fluctuations in the entire curve. Conversely, when n\u2081 is small, changes in it have less impact."}, {"title": "The experimental results roughly demonstrate the effects of the hyperparameters of the RFA loss function", "content": "However, we observed that the degree of fluctuation does not necessarily impact the final scores, suggesting\nonly a limited correlation. We conducted a detailed analysis of this issue, which will be discussed in the\nDISCUSSION section."}, {"title": "Table 2 summarizes the results of the ablation experiment", "content": "with F-E representing feature extraction. We\nused the cross-entropy loss function as our baseline of ablation experiment. When we applied the recall\nloss function, it predicted all samples as category 1, resulting in a recall rate of 1. When we used the RFA\nloss, the F2-score, AUC had a certain improvement compared to the other loss; In terms of the recall rate,\nthere was an improvement of 16.2% compared to cross-entropy and 29.2% compared to focal loss functions.\nApplying feature extraction improved the F2-score by 20.6%,and the AUC by 13.5% for the Focal loss, while\nthe experimental results of cross-entropy loss decreased. Applying both feature extraction and RFA loss\nsimultaneously improves the F2-score by 7.9%, AUC by 4.8%, and recall rate by 12.9% compared to applying\nRFA alone. Additionally, compared to the baseline, recall rate improves by 29.1%, F2-score improves by\n20.5%, and AUC improves by 10.9%. These results demonstrate that our work significantly improves the\nrecall rate while achieving excellent accuracy."}, {"title": "Table 3 shows the experimental results of the comparative experiment", "content": "The table shows that our method\nhas significantly improved the recall rate, 36.6% higher than the second place, while maintaining the high\naccuracy and AUC."}, {"title": "5 DISCUSSION", "content": ""}, {"title": "5.1 Practical Significance of RFAloss Hyperparameters", "content": "We will discuss the effect and interpretable hyperparameters tuning strategies below. n1, n2, and M are\nadjustable hyperparameters that affect the accuracy (a), recall rate (r), and equation 15, respectively. The\nmagnitude of the feedback effect can be reflected by the fluctuation of the curves in Figure 4, and the final\nresults are shown in Table 1.\nBased on the results and our original design intent, n\u2082 aligns with our hypothesis and has significant effects.\nIt directly affects the recall rate, resulting in an exponential growth in the impact of the recall. This leads\nto an increase in A and a greater focus on positive examples over negative ones. The results also validate\nour prediction, as shown in Figure 4b. Increasing n\u2082 noticeably increases the amplitude of fluctuations,\nindicating a stronger penalty on dynamic recall for each update. However, the experiments in Table 1 show\nthat increased fluctuation indicates stronger feedback and a wider search range but does not necessarily lead\nto improved final metric results.\nWe introduce n\u2081 to improve accuracy by directing feedback towards accuracy improvement. In our study, the\npositive class is significantly underrepresented. Additionally, our loss function is designed to prioritize a high\nrecall rate by predicting more positive examples. Therefore, we attribute the lower accuracy to the scarcity\nof predictions for negative samples. To improve the accuracy, we need to increase the attention to negative"}, {"title": "examples", "content": "When n\u2081 < 0", "follows": "n2 = 3 represents a parameter setting that\nprioritizes recall rate. The curve has greater fluctuation with a high baseline when M = 0.7 compared to\nM = 0.3 and M = 0.5. The curve at M = 0.3"}]}