{"title": "Judgment of Thoughts: Courtroom of the Binary Logical Reasoning in Large Language Models", "authors": ["Sungjune Park", "Daeseon Choi"], "abstract": "This paper proposes a novel prompt engineering technique called Judgment of Thought (JoT) that is specifically tailored for binary logical reasoning tasks. JoT employs three roles-lawyer, prosecutor, and judge-to facilitate more reliable and accurate reasoning by the model. In this framework, the judge utilizes a high-level model, while the lawyer and prosecutor utilize low-level models. This structure helps the judge better understand the responses from both the lawyer and prosecutor, enabling a more accurate judgment. Experimental results on large language model (LLM) benchmark datasets, such as Big-BenchHard and Winogrande, demonstrate that JoT outperforms existing methods, including Chain of Thought (CoT) and Self-Consistency (SC), in binary logical reasoning tasks. Additionally, in real-world tasks, such as Fake News Detection and SMS Spam Detection, JoT shows comparable or improved performance compared to existing techniques. JoT significantly enhances the accuracy and reliability of models in binary reasoning tasks and show potential for practical applicability across various domains. Future research should aim to further broaden the applicability of JoT and optimize its implementation for real-world problem-solving.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the rapid advancement of Artificial Intelligence (AI) and Natural Language Processing (NLP) [1], [2], [3] technologies has driven innovative changes across various industries. In particular, the emergence of Large Language Models (LLMs) [4], [5], [6], [7], [8] has demonstrated human-level performance in a wide range of language processing tasks, including text generation, translation, and sentiment analysis. These models, which are trained on vast amounts of textual data, possess high levels of understanding and generative capabilities. However, to fully leverage their performance, the design of appropriate inputs, or \"prompts\" is essential.\nPrompt engineering [9] refers to the technique of adjusting and optimizing inputs to ensure AI models yield the best possible results. This process involves guiding the model to correctly understand and execute the given tasks by experimenting with various text formats and structures, and analyzing the model's responses to design the optimal prompts. Tailored prompts for specific problem types have the potential to maximize the model's performance.\nAs the diversity and application range of language models expand, the importance of prompt engineering is becoming more pronounced [10]. In various fields, such as information retrieval systems, legal document analysis, and educational knowledge assessment, the design of prompts directly impacts the model's performance and user experience. Well-designed prompts enable the model to accurately grasp the user's intent and provide necessary information effectively [11]. Conversely, inappropriate prompts can lead to model malfunction or inaccurate results. Therefore, prompt engineering has emerged as a significant research topic in the practical application of AI and NLP.\nBinary logical reasoning problems, which must determine whether a given text is true or false, play a critical role in various applications, including information retrieval, sentiment analysis, and fact-checking [12]. Due to the nature of binary inference, where clear true/false judgments are required, even slight differences in prompts can significantly impact the model's performance. This necessitates specialized prompt engineering techniques tailored for binary inference problems to enhance the model's accuracy and reliability.\nThis paper introduces a novel prompt engineering technique specialized for binary inference problems, called Judgment of Thought (JoT). Unlike existing prompt engineering methods that focus on general language generation tasks and mathematical problems, JoT presents a prompt design strategy tailored for binary inference. JoT consists of three units, performing the roles of a lawyer, prosecutor, and judge. The lawyer and prosecutor argue for and against the truth of the given problem, respectively, while the judge considers these arguments and relevant precedents (few-shot examples) to deliver a final verdict. This approach enables the model to perform more accurate and reliable inferences.\nThe remainder of this paper is organized as follows. Section 2 provides an overview of related work, introducing existing prompt engineering techniques. Section 3 details the JoT technique, discussing how the roles of lawyer, prosecutor, and judge contribute to enhancing model performance. Section 4 describes the experimental setup, including the datasets used, model configurations, and evaluation metrics. Section 5 presents the experimental results and analysis, emphasizing that JoT outperforms existing methods in binary inference tasks. Section 6 addresses the challenges and limitations of applying JoT in real-world scenarios, offering potential approaches and future research directions. Finally, Section 7"}, {"title": "II. CURRENT METHODS IN PROMPT ENGINEERING", "content": "Prompt engineering is the technique of crafting specific input prompts to optimize the performance of LLMs. LLMs have demonstrated exceptional abilities in understanding and generating text similar to that of humans, and prompt engineering aims to leverage these capabilities to guide the model in producing desired outputs for specific tasks. There are several key strategies in prompt engineering, as shown in Figure 1, each with its own advantages and applications:\nZero-shot prompting [13], also known as I/O prompting, involves constructing a prompt with only a description of the task without providing any examples. This method relies on the model's pre-trained knowledge and generalization abilities to generate responses. For instance, a simple prompt like \"Translate this text into English\" can be used to perform a translation task. The advantage of zero-shot prompting is that it allows for quick and easy attempts at various tasks, providing immediate responses to new tasks. However, the performance heavily depends on the clarity of the task description and the model's pre-trained knowledge.\nFew-shot prompting [14], [5] involves providing a few examples along with the task description when instructing the model. This helps the model learn patterns from the provided examples and perform similar tasks. For example, using a prompt like \"A cat is a pet. A dog is a pet. A hamster is a pet. A tiger is?\" guides the model to follow a similar pattern for new inputs. Few-shot prompting can offer higher accuracy compared to zero-shot prompting and allows the model to better adapt to specific tasks. This technique is particularly useful for quickly adjusting the model to new concepts or tasks.\nChain-of-Thought (CoT) prompting [15] guides the model to solve complex problems step by step. This method involves breaking down the problem-solving process into logical stages and including examples and solutions in the prompt so that the model performs each step sequentially. For example, a prompt like \"First add the two numbers, then multiply the result by another number\" helps the model systematically solve the problem. This approach is advantageous for solving complex problems methodically and aids the model in reaching the final answer through intermediate steps. It is especially effective for tasks that require multi-step reasoning, such as mathematical problems or tasks involving complex inferences.\nAdditionally, Zero-shot CoT [16] prompting adds the rule \u201cLet's think step by step\u201d to the original prompt, encouraging the model to reason through intermediate steps without examples. Zero-shot CoT allows the model to tackle complex problems by thinking step by step, even without specific examples.\nMoreover, Auto-CoT [17] prompting automates the generation of reasoning chains for examples using Zero-shot CoT, removing the need for manual input. Auto-CoT provides a more efficient and flexible approach by enabling the model to generate logical steps and derive solutions for various problems. This approach is particularly useful for solving repetitive and complex problems.\nSelf-Consistency(SC) [18] prompting involves comparing multiple responses generated by the model for the same prompt and selecting the most consistent answer to replace naive greedy decoding in CoT. This method aims to reduce variability in the model's responses and achieve more reliable results. SC is useful when the model's responses are unstable or uncertain and helps enhance the reliability of the answers.\nPrompt engineering techniques play a crucial role in improving the performance of AI models and obtaining more precise and useful results. Each technique can be applied to specific situations and contributes to deriving optimal results through interaction with the model. By appropriately utilizing these techniques, the full potential of LLMs can be realized across various applications."}, {"title": "III. JUDGMENT OF THOUGHT (JOT)", "content": "JoT is a novel prompt engineering method (see Figure 2) that initializes system messages for units playing the roles of lawyer, prosecutor, and judge. Each unit is assigned its role, and through user prompts, the arguments of the lawyer and prosecutor are collected and passed to the judge for comprehensive judgment and feedback. This process is repeated iteratively. In this setup, the judge uses a higher-level model, while the lawyer and prosecutor use lower-level models. This ensures that the judge better understands the responses of the two models and can deliver a correct judgment. This technique is effective for analyzing and solving complex problems from multiple perspectives.\nIn the first stage, the system messages for the roles of the lawyer, prosecutor, and judge are initialized. The system messages for the lawyer and prosecutor are configured to argue true and false on a binary inference problem, respectively, while the judge is set to make a decision based on the arguments from the lawyer and prosecutor. In this process, the lawyer presents positive arguments for the given problem, while the prosecutor presents negative arguments. Each unit is provided with few-shot examples and reasoning related to the inference problem to help the model learn the logical structure of each role's tasks. This enhances the lawyer's and prosecutor's abilities to analyze the problem and construct their arguments.\nNext, the inference problem, which is the input data to be resolved, is provided to the lawyer and prosecutor through a user prompt. This allows them to analyze the given problem or data and present arguments from their respective positions. In this process, the lawyer and the prosecutor use various pieces of evidence and examples to strengthen their logic. The arguments generated by the lawyer and prosecutor, along with the binary inference problem, are provided to the judge. Based on this, the judge performs overall judgment, feedback, and analysis. The judge makes a decision based on all the provided information and generates feedback and analysis results. The judge considers the arguments of both lawyer and the prosecutor, using various logical approaches and evidence to make a fair judgment. This allows the judge to understand the essence of the problem, analyze the strengths and weaknesses of each argument, and determine the winner between the lawyer and prosecutor.\nThe judge's judgment, feedback, and analysis results are then provided back to the lawyer and prosecutor, including the opponent's arguments. This allows the lawyer and prosecutor to refine their arguments and generate new ones to rebut the opponent's points. In this stage, the lawyer and the prosecutor further strengthen their logic based on the previous judgment and feedback and present additional evidence and logic to rebut the opponent's arguments. This deepens the debate, and the arguments become increasingly sophisticated.\nA new user prompt is then input to the lawyer and prosecutor, and, as before, the opinions of the lawyer and prosecutor are provided to the judge for judgment, feedback, and analysis. Finally, the lawyer and prosecutor make their final arguments considering the judge's previous analysis and their opponent's arguments, and the judge makes a final judgment. Through this process, the lawyer and prosecutor continuously improve their arguments, and the judge works towards a comprehensive solution to the problem. Consequently, the user prompt is progressively refined, leading to more accurate and valid conclusions.\nJoT is a prompt engineering technique that can analyze complex problems from multiple perspectives and derive more precise solutions through these iterative courtroom battles. Utilizing the system messages for each role to approach the problem from various perspectives allows consideration of different aspects that might be missed from a single perspective. This enables JoT to provide comprehensive and balanced problem-solving by examining the issue from multiple viewpoints. Additionally, this process greatly enhances the model's reasoning and logical thinking abilities through the roles and interactions of each unit."}, {"title": "IV. EXPERIMENTS", "content": "In this experiment, we evaluated various prompt engineering techniques using the GPT-3.5 and GPT-40 (omni) models. The model parameters were set to their default value, with temperature=1 and Top p=1, to maximize the diversity of the model outputs and generate a wide range of responses.\nThe dataset used for the experiments consisted of two parts. First, we used Winogrande [19], a dataset designed to address large-scale pronoun resolution problems. Second, to evaluate the advanced language understanding capabilities of the models, we used binary inference problems included in BigBenchHard [20]. These problems include Boolean expressions, causal judgment, formal fallacies, sports understanding, web of lies, and navigate.\nThe Boolean expressions task involves evaluating given Boolean expressions to derive the results. This process involves comparing and combining True and false False values through logical operations to obtain the final outcome. The causal judgement task aims to assess the cause-and-effect relationship in specific situations, determining whether the given cause led to the effect. The formal fallacies task evaluates whether the given argument is deductively valid based on the stated premises. This involves examining the logical validity and consistency between the premises and conclusion. The sports understanding task determines whether specific sports-related terms are used appropriately in context, requiring an understanding of sports-related knowledge and actions. The web of lies task is a logical reasoning task that involves evaluating a series of statements to determine the truthfulness of the final statement, requiring an analysis of the relationships between statements and the resulting truth values. Lastly, the navigate task assesses whether following a series of navigation instructions returns to the starting point, evaluating spatial reasoning and direction-following accuracy.\nAdditionally, for the Real-World Task Application experiment, we used the Fake News [21] and SMS Spam Message [22] datasets. This was to evaluate the models' performance in real-world scenarios and verify their applicability in various text processing tasks.\nThe prompt engineering techniques compared were zero-shot, few-shot, CoT, and SC. These techniques were chosen for their unique characteristics and strengths, allowing us to evaluate their performance across different problem types.\nThe evaluation metrics used were accuracy and F1 Score. Accuracy represents the proportion of correct predictions made by the model, while the F1 Score, a measure of the balance between precision and recall, provides a comprehensive evaluation of the model's performance. These metrics were used to compare and analyze the effectiveness of each prompt engineering technique.\nBy using these evaluation metrics, we compared and analyzed the effectiveness of each prompt engineering technique, providing insights into their performance across various tasks and datasets."}, {"title": "B. Experimental Results", "content": "1) Evaluation on benchmarks: This section presents the results of evaluating the performance of JoT and various prompt engineering techniques based on accuracy and F1 score using the BigBenchHard and Winogrande datasets. The Big-BenchHard dataset was used to evaluate the models' advanced language understanding capabilities through various binary inference problems. The results are shown in Table I.\nFirst, in the Boolean expressions task, JoT showed the highest performance. JoT recorded an accuracy of 0.96 and F1 Score of 0.97, demonstrating its effectiveness in solving logical problems. In contrast, the Few-shot technique of the GPT-40 model, which showed the second highest performance, recorded an accuracy of 0.91 and F1 Score of 0.93. These results indicate that JoT significantly outperforms other techniques in the Boolean expressions task.\nIn the causal judgment task, JoT also showed the highest performance. JoT recorded an accuracy of 0.74 and F1 Score of 0.68, outperforming the SC technique of the GPT-40 model, which recorded an accuracy of 0.67 and F1 Score of 0.65. This indicates that the JoT can analyze and solve causal relationship judgment problems more precisely.\nIn the navigate task, JoT recorded the highest performance with an accuracy of 0.88 and F1 Score of 0.84. The Zero-shot technique of the GPT-40 model, which showed the second highest performance, recorded an accuracy of 0.68 and F1 Score of 0.18. This shows that JoT is very effective in analyzing complex problems from multiple perspectives to derive optimal results, highlighting the inability of other prompt techniques to solve this task.\nIn the sports understanding task, JoT recorded an accuracy of 0.86 and F1 Score of 0.86. However, the highest performing technique was CoT of the GPT-40 model, which recorded an accuracy of 0.90 and F1 Score of 0.88. This indicates that JoT is somewhat less effective than the CoT technique in sports understanding problems.\nIn the web of lies task, JoT recorded very high performance, with an accuracy of 0.87 and F1 Score of 0.87. In contrast, the Zero-shot technique of the GPT-4o model, which showed the second highest performance, recorded an accuracy of 0.54 and F1 Score of 0.54. This indicates that JoT is very effective in analyzing complex problems from multiple perspectives to derive optimal results, highlighting the inability of other prompt techniques to solve this task.\nIn the formal fallacies task, JoT recorded an accuracy of 0.69 and F1 Score of 0.69, outperforming the Few-shot and CoT techniques of the GPT-40 model, which recorded an accuracy of 0.61 and F1 Score of 0.61. This indicates that JoT shows superior performance in solving logical fallacies.\nJoT also showed excellent performance on the Winogrande dataset with an accuracy of 0.87 and F1 Score of 0.86. In contrast, the Zero-shot, CoT, and SC techniques of the GPT-40 model each recorded an accuracy of 0.82 and F1 Score of 0.82. This indicates that JoT shows superior performance in pronoun resolution problems.\nJoT showed excellent performance across various problem types and was particularly effective in solving complex logical problems. This demonstrates that JoT surpasses other prompt engineering techniques of the GPT-40 model in advanced language understanding and reasoning capabilities. In many cases, the JoT technique showed superior performance in both accuracy and F1 Score, demonstrating the validity of this technique."}, {"title": "2) Real-World Task Application", "content": "In this section, we describe our experiments on the Fake News and SMS Spam datasets to evaluate the real-world performance of JoT and various prompt engineering techniques. The results are shown in Table II.\nOn the Fake News dataset, JoT showed outstanding performance, with an accuracy of 0.94, surpassing all other techniques. Specifically, the Zero-shot and CoT techniques of the GPT-3.5-Turbo model each recorded an accuracy of 0.88, while the Few-shot technique of the GPT-40 model recorded an accuracy of 0.92. This indicates that JoT outperforms other techniques in detecting fake news. JoT also recorded an F1 score of 0.94. This performance is superior to those of Zero-shot (0.88), Few-shot (0.86), CoT (0.89), and SC (0.87) of the GPT-3.5-Turbo model. Additionally, the Few-shot technique of the GPT-40 model recorded an F1 Score of 0.92. This indicates that JoT demonstrates excellent performance in both precision and recall. Meanwhile, on the SMS Spam dataset, JoT performed worse than the CoT and SC techniques. JoT recorded an accuracy of 0.94, while the CoT and SC techniques each recorded an accuracy of 0.96. This implies that JoT is less effective in detecting SMS spam compared to other techniques. JoT recorded an F1 Score of 0.96, while the CoT and SC techniques each recorded scores of 0.98. This indicates that JoT showed inferior performance in precision and recall compared to the CoT and SC techniques in SMS spam detection.\nOverall, the analysis indicates that while JoT performs well in various real-world environments, it may be less effective than other prompt engineering techniques on specific datasets. Therefore, further research is required to analyze and optimize JoT across a broader range of datasets and problem types."}, {"title": "3) Ablation Study: Loop and Model Adjustments", "content": "In this section, we analyze the impact of model adjustments and the application of loops on the performance of JoT. For the model adjustment experiment, we measured performance changes by standardizing all roles (judge, lawyer, and prosecutor) to either GPT-40 or GPT-3.5-turbo, instead of using GPT-40 for the judge and GPT-3.5-turbo for the lawyer and prosecutor. Additionally, in the experiment regarding loop application, we compared the results of producing a final judgment through a single decision versus the original method of repeating the process three times and using the majority verdict as the final decision.\nThe results for model adjustments and loop application are as follows. First, when all models were standardized to GPT-3.5-turbo, performance was significantly lower across all tasks compared to the experiment using a mix of GPT-3.5-turbo and GPT-40. This was particularly evident in tasks requiring logical reasoning, such as web of lies, navigate, and causal judgment, where performance dropped substantially. When all models were standardized to GPT-4o, performance improved in the navigate and formal fallacies tasks compared to the mixed model approach, but there were no notable performance improvements in other tasks. In particular, tasks such as web of lies, sports understanding, and Winogrande showed decreased performance. Replacing all roles (lawyer, prosecutor, and judge) with the higher-level model GPT-40 increased costs by 36% (based on OpenAI API Pricing), but overall performance did not improve.\nFor the loop application experiment, the method of producing a final judgment by repeating the process three times and choosing the majority verdict was changed to deriving results from a single judgment. The loop application results showed that performance improved in most tasks when loops were applied. This was especially true in the causal judgment task, which requires logical reasoning and complex problem solving, where accuracy and F1 Scores significantly improved in the experiment mixing GPT-3.5-turbo and GPT-40. This suggests that repeated review processes can increase the system's reliability by producing consistent judgments. However, in some tasks, performance decreased when loops were applied, indicating that loop application may not always be the best choice, depending on the task's nature.\nIn summary, to achieve optimal performance in the JoT system, it is important to decide on the application of loops based on the task's characteristics. Applying loops can enhance overall consistency and reliability, particularly in tasks requiring complex problem-solving and logical reasoning."}, {"title": "V. DISCUSSION", "content": "In this study, JoT demonstrated excellent performance in solving various binary logical reasoning problems using the Fake News and SMS Spam dataset. However, there are several significant gaps between binary logical reasoning problems and real-world binary classification problems. Understanding and overcoming these gaps is essential for the practical application and performance improvement of JoT.\nFirst, there is a difference in the structure and complexity of the data. Binary logical reasoning problems typically rely on clear rules and logic to solve problems, while real-world binary classification problems involve various data sources and forms, often dealing with incomplete and noisy data. For example, the Fake News dataset is based on the text of news articles, which includes various styles, topics, and contexts, making accurate classification difficult with simple logical rules. In contrast, binary logical reasoning problems can be approached with clear rule-based methods, and this difference in complexity can affect performance.\nSecond, there is the issue of bias and diversity in real-world data. Real-world datasets can have biased data distributions, which can negatively impact model performance. One reason that JoT performed worse than the CoT and SC techniques on the SMS Spam dataset is the diversity and variations in actual spam messages. If the bias and diversity of the data are not adequately reflected, the model's generalization ability can decrease.\nThird, there is a need for context and domain knowledge in real-world problems. Binary logical reasoning problems can generally be solved without specific context or domain knowledge. However, real-world binary classification problems may require knowledge of the relevant domain. For example, in detecting fake news, understanding political context, social context, and historical background is important. If JoT is not designed to reflect this domain knowledge, performance degradation can occur in practical applications.\nIn conclusion, there are several gaps between binary logical reasoning problems and real-world binary classification problems, and understanding and overcoming these gaps is crucial for the practical application and performance improvement of JoT. Future research should develop approaches to bridge these gaps and optimize JoT for various real-world applications. This will enable JoT to be more effectively utilized in real-world environments."}, {"title": "B. Practical Application Potential", "content": "The performance of JoT on the Fake News and SMS Spam datasets suggests its strong potential for use in various real-world applications. Notably, the excellent performance of JoT in problems requiring advanced language comprehension and reasoning capabilities indicates its practical applicability across multiple fields.\nFake news is a critical issue that can have social, political, and economic impacts. The outstanding performance of JoT on the Fake News dataset suggests that it could be very useful in detecting and classifying fake news. Media platforms and news providers can utilize JoT to quickly identify and respond to fake news, significantly contributing to the reliability of information.\nThe results on the SMS Spam dataset indicate the potential of the JoT technique in filtering spam messages. Although it performed slightly worse than the CoT and SC techniques, JoT still achieved high accuracy and F1 Scores. By integrating JoT into spam filtering systems, users can reduce unnecessary messages and ensure that important messages are not missed. Additionally, JoT can be useful for analyzing and understanding various linguistic patterns on social media. Social media platforms can use JoT to effectively monitor and respond to hate speech, harassment, misinformation, and other issues. This can improve user experience and enhance the safety and reliability of the platform.\nJoT can also be applied to analyzing medical records and patient notes. By extracting important information from medical records and quickly understanding the patient's condition, JoT can support medical staff in diagnosis and treatment. By analyzing medical records from multiple perspectives through the roles of the examiner, lawyer, and judge in JoT can enhance the quality of medical services and improve patient outcomes.\nIn conclusion, JoT has strong potential for use in various real-world applications. Its excellent performance in problems requiring advanced language comprehension and reasoning capabilities allows it to contribute to solving practical problems across multiple fields. Future research should aim to expand the applicability of JoT and maximize its performance through optimization tailored to each field. This will establish JoT as an important tool in various real-world applications."}, {"title": "VI. CONCLUSION", "content": "This paper proposed a new prompt engineering technique specialized for binary inference problems, called JoT. JOT helps models make more reliable and accurate inferences through three roles: lawyer, prosecutor, and judge. Experimental results on various benchmark datasets showed that JoT consistently outperforms existing CoT and SC techniques in binary inference tasks.\nThe performance of JoT is particularly notable in binary inference tasks with large-scale language models. For instance, JoT demonstrated superior accuracy and reliability compared to existing techniques on various logical reasoning and text classification benchmarks. This indicates that JoT is highly efficient not only in simple text generation or solving mathematical problems but also in complex reasoning tasks.\nHowever, there are several challenges in the practical application of JoT. First, the computational cost of the model may increase, which can limit its use in real-time applications. Second, if the bias and diversity of real-world data are not adequately reflected, the model's generalization ability may decrease. Third, if the need for domain knowledge is not sufficiently addressed, there may be limitations in solving practical problems.\nFuture research should develop approaches to address these challenges and optimize JoT for various real-world applications. This will enable JoT to be used more effectively across different fields."}]}