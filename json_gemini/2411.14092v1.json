{"title": "MetaCropFollow: Few-Shot Adaptation with Meta-Learning for Under-Canopy Navigation", "authors": ["Thomas Woehrle", "Arun N. Sivakumar", "Naveen Uppalapati", "Girish Chowdhary"], "abstract": "Autonomous under-canopy navigation faces additional challenges compared to over-canopy settings - for example the tight spacing between the crop rows, degraded GPS accuracy and excessive clutter. Keypoint-based visual navigation has been shown to perform well in these conditions, however the differences between agricultural environments in terms of lighting, season, soil and crop type mean that a domain shift will likely be encountered at some point of the robot deployment. In this paper, we explore the use of Meta-Learning to overcome this domain shift using a minimal amount of data. We train a base-learner that can quickly adapt to new conditions, enabling more robust navigation in low-data regimes.", "sections": [{"title": "1 Introduction", "content": "Autonomous agricultural robots promise to help solve the problems of higher food production demands, reduced availability of farm labour and higher needs for agricultural sustainability [2, 3].\nBroadly speaking, such robots operate either in over-canopy or under-canopy settings, with the latter being less common but promising, particularly in the case of plant-level monitoring and care.\nHowever, under-canopy conditions bring with them certain challenges, which robots operating over-canopy do not face. Over-canopy robots (e.g. drones, tractors, and combine harvesters) oftentimes\nmake use of RTK (Real-Time Kinematic)-GPS, which can not be reliably used under-canopy because of signal attenuation and multi-path error [4, 5]. Tight-spaced rows and regular occlusions\nbecause of densely growing plants constitute additional difficulties [4].\nVisual navigation using cameras can provide a robust and low-cost solution to these problems. One\nsuch solution is CropFollow++ introduced by Sivakumar et al. [1], which learns to identify keypoints\nto represent the navigation problem. Namely, these key-points are the vanishing point, left intersect-\npoint with the x-axis and right intersect-point with the x-axis. Combined they create a triangle\nrepresenting the traversable area between two rows of crop.\nHowever, the variation across different fields, plant types and seasons (for a sample of this see\nFigure 2) pose a challenge to the system's capability. These variations make robust navigation\ndifficult, since a deployed robot will encounter circumstances it has never seen during training. A\npossible solution to this problem is to create a system, which is capable of adapting to new situations,\nwhile reusing as much of the existing knowledge as possible, and ideally only needing minimal\ninformation about the new domain to adapt to it.\nWe framed this problem as a meta-learning problem, where we learn a base-learner, which is capa-\nble of few-shot adapting to a new environment. For this we used Model-Agnostic Meta-Learning\n(MAML) [6], particularly its variations MAML++ [7] and ANIL [8]. We first establish that a model\ntrained with MAML is capable of learning the underlying representations as well as a conventional\napproach. Then, we evaluate its adaptation capabilities when trained and validated only on a part of\nthe data.\nWe claim that: (i) Our MAML architecture is capable of learning the keypoints as well as the existing\nnon-MAML system. (ii) Our MAML system is superior in adapting to unseen conditions, which it\nis capable of even in situations where the training domain is small and the domain shift big."}, {"title": "2 Approach", "content": "We employed the dataset used in Sivakumar et al. [1], which consists of 28273 images. The images\nwhere taken on 54 different days, each attributed to either the early, late or very late season. Figure\n2 shows the spectrum of images present in the dataset.\nEach of the images has a corresponding label consisting of the coordinates of the three keypoints:\nvanishing point, left intersect-point with the x-axis and right intersect-point with the x-axis."}, {"title": "2.2 Model", "content": "Our model uses a ResNet-18-based encoder [9], pre-trained on ImageNet [10], which together with\na bilinearly upsampling decoder forms a U-Net-like [11] architecture.\nSee Sivakumar et al. [1] for more details regarding the model."}, {"title": "2.3 Training without MAML", "content": "The training without MAML is straightforward. For a given training split (see Table 1), a dataloader\nis created where each of the images inside the days entailed by the split are equally likely to be\nsampled for a certain batch.\nWe train with a learning rate of 1e-4 for 50 epochs. Apart from the fact that no data augmentations\nwere used, our training process in the non-MAML case resembles that described by Sivakumar et al.\n[1]."}, {"title": "2.4 Training with MAML", "content": "MAML requires the definition of tasks [6], from which a support set for inner optimization and a\nquery set for outer loss calculation can be sampled. In our case, the tasks used in a given split are\nthe different days it contains. To obtain a task from a training split, we sample a day from it, where\nthe probability of a day being sampled is proportional to the number of images taken on said day,\nrelative to all images in the split. After we have obtained the task, the support set and query set is\ncreated by sampling images taken during the day associated with this task.\nWe first tried to use vanilla MAML [6]. However, it quickly emerged that vanilla MAML is not\ncapable of learning the representations reliably, even in a setting where all available data is provided.\nThe problem of MAML's sensitivity is discussed in Antoniou et al. [7], which also proposes concrete\nchanges to the model training. In essence, these changes look at the inner optimization steps of\nMAML individually, learning separate learning rates and buffers for them among other optimizations\n(see Appendix A for more details). Applying its techniques lead to a stabilized training and a\nresulting model, which performs better.\nWe also evaluate ANIL (Almost no Inner Loop) which was introduced in Raghu et al. [8]. It proposes\nonly updating the last layer inside the inner loop, making the finetuning process less computationally\nexpensive while at times leading to better performance."}, {"title": "3 Experimental Evaluation", "content": "Our experiments are based on the different data splits presented in Table 1. For each split, we do the\nfollowing:\n1. We run a MAML, ANIL and non-MAML training.\n2. For all of those trainings we choose the checkpoint which performs best in the domain the\nmodel was trained on. For example, for split Early, we only look at the validation loss on\nthe early val data to make a decision on which checkpoint is considered the best.\nThis is an important distinction compared to choosing the checkpoint which performs best\nacross all validation data. Intuitively, it simulates a situation where we only have access\nto data from one season and have to make a decision about which model is best for other\nseasons without having data about them yet.\n3. We evaluate the chosen checkpoint on early, late and very late test data, resulting in 3\ndifferent losses.\nIn the case of non-MAML, we evaluated the model as is, as well as versions which were\nfew-shot finetuned at different learning rates, using the same value of k as we do in MAML,\nthus providing a fair assessment. In our case k was 5, meaning that all models got to use 5\nimages to finetune to a task at hand.\nIn the case of MAML (or MAML++ to be precise), the output of the training process are the\nmodel weights of a base-learner, as well as the learning rates and buffers to be used during\nfinetuning (see LSLR and BNRS in Appendix A). The base-learner is then finetuned on\nk = 5 samples from the day it is being evaluated on."}, {"title": "3.2 Results", "content": "Firstly, we establish that our MAML-based solution is capable of performing equally well as a\nnon-MAML approach, when trained on the entire dataset (see Table 2). This was expected, proofs\nhowever that MAML++ and ANIL++ are capable of learning the representations of the under-canopy\nnavigation problem."}, {"title": "3.2.2 Training Only on Early-Season Data", "content": "Furthermore, we show that our MAML++ system is capable of learning good representations for\nthe whole season even if only trained on the data from one season (see Table 2). The non-MAML\nsystem struggles with this indicating that it is not capable of overcoming big domain shifts. See\nFigure 4 for a visual comparison of the two.\nANIL++ performs bad in this scenario, but there are checkpoints of the ANIL++ training on the\nEarly split, which perform almost as good as MAML++ in the late and very late season. However,\nthose checkpoints perform marginally worse on the early data and as explained in 3.1, we always\nchoose the checkpoint which performs best in the training domain, simulating a setting, where we\nonly have data from this domain."}, {"title": "4 Conclusion", "content": "In this paper, we explored the use of MAML in the case of under-canopy environments, showing\nthat it is superior to a non-MAML approach in overcoming domain shifts using only minimal data\nfrom the target domain.\nNonetheless, a caveat of MAML remains the need for adaptation to each new task to reach its full\nperformance, meaning a model does not work as-is after the training process. In the supervised case,\nthis would mean that new images have to be labeled every time the robot enters a new environment.\nHowever, a inner loop learning in a self-supervised manner could solve this issue, leading to the\nrobot adapting automatically to new environments [12], which is why we see this as a promising\ndirection for future work."}, {"title": "A MAML++ Improvements", "content": "The problem of MAML's sensitivity as we encountered it, is discussed in Antoniou et al. [7], which\nproposes the following changes:\n\u2022 Multi-Step Loss Optimization (MSL) to fix the problem of gradient stability. It does so\nby creating the loss as a weighted sum of the different losses obtained after each inner\nupdate step instead of just the final step.\n\u2022 Derivative Order Annealing (DA) to reduce computational cost. MAML requires the\nsecond order derivative, which is expensive to compute. MAML++ uses the first order ap-\nproximation for a certain number of updates before switching to second order. The authors\nof the paper also found that this can lead to a more stabilized training. We made the same\nfinding (see Appendix B).\n\u2022 Per-Step Batch Normalization Running Statistics (BNRS) to improve generalization\nperformance and speed up optimization. Instead of a single set of running statistics, we\naccumulate N sets (one for each of the N optimization steps) during meta-training and use\nthem for the respective steps during meta-test time.\n\u2022 Per-Step Batch Normalization Weights and Biases (BNWB) to improve generalization\nperformance and speed up optimization. Same reasoning and implementation as BNRS: a\nseparate set of batch norm weights and biases for each of the N inner optimization steps.\n\u2022 Learning Per-Layer Per-Step Learning Rates (LSLR) to improve generalization perfor-\nmance. Instead of a single inner learning rate $\\alpha$, one learning rate for each step and each\nmodel layer is learned during meta-train time and - as above - used at meta-test time during\nfinetuning.\n\u2022 Cosine-Annealing of Meta-Optimizer Learning Rate (CA) to improve generalization\nperformance. Instead of always using the same outer learning rate $\\beta$, episode 1 starts out\nwith $\\beta$ and drops to $\\beta_{min}$ by the last episode, following cosine annealing.\nWe implemented all of the above additions of MAML++, except for BNWB. The result was a model,\nwhich was better at generalizing and also more stable during training compared to vanilla MAML."}, {"title": "B Hyperparameters", "content": "Vanilla MAML already uses more hyperparameters than conventional training. MAML++ extends\nthose with the percentage of iterations to do MSL and the percentage of iterations to do first order\nupdates (DA).\nWe made the following experiences while trying to find the best set of hyperparameters:\n\u2022 Number of episodes: All runs were trained with twenty thousand episodes. Oftentimes\nthey would converge faster for the domain they were trained on (e.g. early season data)\ncompared to other domains. This indicates, that even after the model has learned to per-\nform well on a given task, it continues to learn underlying information, which helps when\nfinetuning in new domains.\nThe fact that we still trained with twenty thousand episodes and not less does not contra-\ndict the statement made in 3.1 regarding choice of the best model based on the training\ndomain performance only. While we made this interesting finding, we still stuck with our\napproach of choosing the model which is best in the training domain, independently of its\nperformance in another domain.\n\u2022 Meta batch size: The number of tasks per outer loop iteration. We consistently used 4 for\nthis throughout our training.\n\u2022 Number of images to use in the inner loop (k): We tried k = 1,3,5,8. And higher k\nunsurprisingly lead to better domain adaptation, since more of the newer domain is learned."}]}