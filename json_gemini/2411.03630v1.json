{"title": "RTify: Aligning Deep Neural Networks with Human Behavioral Decisions", "authors": ["Yu-Ang Cheng", "Ivan Felipe Rodriguez", "Sixuan Chen", "Kohitij Kar", "Takeo Watanabe", "Thomas Serre"], "abstract": "Current neural network models of primate vision focus on replicating overall levels of behavioral accuracy, often neglecting perceptual decisions' rich, dynamic nature. Here, we introduce a novel computational framework to model the dynamics of human behavioral choices by learning to align the temporal dynamics of a recurrent neural network (RNN) to human reaction times (RTs). We describe an approximation that allows us to constrain the number of time steps an RNN takes to solve a task with human RTs. The approach is extensively evaluated against various psychophysics experiments. We also show that the approximation can be used to optimize an \u201cideal-observer\u201d RNN model to achieve an optimal tradeoff between speed and accuracy without human data. The resulting model is found to account well for human RT data. Finally, we use the approximation to train a deep learning implementation of the popular Wong-Wang decision-making model. The model is integrated with a convolutional neural network (CNN) model of visual processing and evaluated using both artificial and natural image stimuli. Overall, we present a novel framework that helps align current vision models with human behavior, bringing us closer to an integrated model of human vision.", "sections": [{"title": "1 Introduction", "content": "Categorizing visual stimuli is crucial for survival, and it requires an organism to make informed decisions in dynamic and noisy environments. This critical aspect of visual perception has driven the development of computational models to understand and replicate these processes. Traditionally, the field has followed two distinct paths.\nOn the one hand, image-computable vision models are used to predict behavioral decisions during (rapid) visual categorization tasks ranging from models of early- [1-3], mid- [4\u20136] and high-level vision [7-9] (see [10] for a review). More recently, these earlier models were superseded by deep convolutional neural networks (CNNs), which have become the de-facto choice for modeling behavioral decision [11-14]. Models are typically evaluated by estimating confidence scores computed for individual images, which are then correlated with similar scores derived for human observers(such as the proportion of correct human responses for each image). Such metrics ignore human reaction times (RTs); hence, current vision models only partially account for human decisions.\nOn the other hand, decision-making models have been used to explain how visual information gets integrated over time \u2013 predicting behavioral choices and RTs jointly. Notably, mathematical models, exemplified by evidence accumulation models such as the drift-diffusion [15\u201317] and linear ballistic"}, {"title": "2 RTify: Overview of the method", "content": "First, we explain how our RTify module is applied to a pre-trained RNN. Then, we will explain how to tune a deep-learning RNN-based implementation of the WW model to RTify feedforward networks.\nWe start with a task-optimized RNN with hidden state ht, which remains frozen. We then train a learnable mapping function fw : Rk \u2192 R that summarizes the state of the neural population at each time step t by mapping the RNN hidden state ht to some \"evidence\": et = fw(ht). At every time step, the evidence is integrated via an \u201cevidence accumulator\u201d \u03a6t = \u2211i=1 ei, and when the accumulated evidence passes a learnable threshold 0, the model is read out, and a decision is made. The time step at which the accumulated evidence first passes this threshold is given by \u0442\u04e9(\u03a6) = min{t : \u03a6t > 0}, and is treated as model RTs. In summary, \u0442\u04e9(\u0424) is directly influenced by the threshold @ and by w through Pt.\nTo align the model RTs with human RTs, or to penalize the model for excessive time steps, we need to optimize a loss function over \u0442\u04e9(\u03a6). In the most general case, we first consider F(\u0442\u04e9(\u03a6)) as our loss function to illustrate how we approximate its gradient. Since our goal is to minimize F, we will need to calculate the gradient JF(\u03c4\u03bf (\u03a6)) and DF(\u0442\u043e (\u03a6)) Following the chain rule, we get\n20\n\u03b8\u03c9\nJF(\u0442\u04e9(\u03a6)) _JF(\u0442\u04e9(\u0424)) \u04d8\u0442\u04e9(\u0424) \u04d8F(\u0442\u04e9(\u0424)) _ \u04d8F(\u0442\u04e9(\u0424)) \u042d\u0442\u04e9(\u0424)\n\u042d\u0442\u043e (\u0424) \u03b8\u03c9\n\u03b8\u03c9 \u042d\u0442\u043e (\u0424)\n(1)\nThis means a crucial step involves estimating the gradient of Te (\u03a6) over the trainable parameters w and @ of the RTify.\nThe primary challenge that arises when extracting the gradient of \u03c4\u03bf (\u03a6) over the trainable parameters w and @ is the non-differentiability of t\u04e9 (\u0424), which prevents the direct use of the backpropagation algorithm. This is because \u0442\u04e9(\u0424) lies in the integer space and requires non-differentiable operations"}, {"title": "2.1 Predicting human decisions with direct \u201csupervision\"", "content": "Human behavioral decisions in the random dot motion (RDM) tasks used in decision-making studies [16, 24, 38] are typically summarized as histograms similar to those shown in Fig. 2. Here, histograms are computed for RTs for correct and incorrect trials corresponding to individual experimental conditions (such as coherence levels shown here; see section 3 for details). Moreover, RTs for incorrect trials are turned into negative RTs. Combined with correct RTs (which stay positive), one single histogram is used for capturing both accuracy (the proportion of positive values) and RTs. To measure the goodness of fit between human RTs and model RTs, we use a mean squared error loss (MSE) between histograms of model RTs and human RTs.\nIn the object recognition task [39], only RTs averaged across all participants were available. We can match human data on a stimulus-by-stimulus basis using the negative correlation loss between model and human RTs."}, {"title": "2.2 Predicting human decisions with \u201cself-penalty\"", "content": "Our framework allows us to develop an \"ideal-observer\u201d RNN model explicitly trained to balance the computational time required for solving a particular classification task and its own accuracy for the task, i.e., a speed-accuracy trade-off.\nTo achieve this, we add a regularizer to the cross-entropy loss to encourage the RNN to jointly maximize task accuracy while minimizing the computational time needed to solve the task. With l as the output logits of the network, y as the output probabilities of the network, and y as the ground truth, we can write our penalty term for a single sample as:\nLself-penalized = LCCE(Y, \u0177) + 1 (ly \u00b7 \u0442\u04e9)\n(4)\nwhere X is a hyperparameter for controlling the strength of the penalty, ly refers to the logit value of the correct label, Te is the model decision time. This penalty means that the model will be penalized for using too much time, especially for higher confidence (higher ly)."}, {"title": "2.3 RTifying feedforward networks", "content": "To integrate temporal dynamics into feedforward neural networks (e.g., CNNs), we describe an RNN module that approximates the WW neural circuit model [22]. The original WW model is a biophysically-realistic neural circuit model of two-alternative forced choices via the temporal"}, {"title": "3 Experiments", "content": "In this section, we validate our RTify framework on two psychophysics datasets: the RDM dataset [24, 38] and a natural image categorization dataset [39]. As a side note, all models were trained on single Nvidia RTX GPUs (Titan/3090/A6000) with 24/24/48GB of memory each. All training can be completed in approximately 48 hours."}, {"title": "3.1 Random dot motion task", "content": "The RDM task is a classic experimental paradigm used to test temporal integration that has been extensively used in psychophysics [40], human imaging [41], and electrophysiology studies [42]. The stimuli in this task consist of dots moving on a screen toward a predefined direction vs. randomly. For each time step, each dot only has a specific probability (coherence) (0.8%, 1.6%, 3.2%, 6.4%, 12.8%, 25.6%, or 51.2%) to move towards the pre-defined direction, making the task non-trivial. The participants must integrate motion information across time and report it when they are sufficiently confident. The original experimental data are from [24,38], where 21 young adult participants performed around 40,000 trials in total over 4 consecutive days.\nFirst, we trained an RNN consisting of 5 convolutional blocks (Convolution, BatchNorm, ReLU, Max pooling) and a 4096-unit LSTM with BPTT. In the original experiment, the stimuli were shown on a 75 Hz CRT monitor for up to 2 seconds, and therefore, we also trained our RNN for the RDM stimuli for 150 frames. The RNN was trained for 100 epochs using the Adam optimizer with a learning rate of 1e-4 at full coherence (c = 99.9%) for the first 10 epochs as a warm-up and le-5 at all coherence levels for the remaining 90 epochs. Next, we trained our two different RTify modules. For fitting human RTs, it was trained for 10,000 epochs, and for self-penalty, it was trained for 20,000 epochs. In both cases, the Adam optimizer were used, and the weights of the task-optimized RNN were frozen while training the RTify modules.\nWe trained the first RTify module to predict human RTs by fitting human RT distributions. Here, positive RTs refer to RT with correct choices, and negative RTs refer to RTs with incorrect choices. Therefore, one distribution incorporates both speed and accuracy information from behavioral choices. Results are shown in Fig. 2. Our RTify model can predict the full RT distribution across all coherence levels. In comparison, the entropy-thresholding approach by [29] fails to capture the full distribution (see Fig. 2 for coherence = 51.2% to 6.4% and Fig. S3 for all coherences). Importantly, our method surpasses entropy-thresholding approach [29] (two-sided Wilcoxon signed-rank test, p < .05; for MSE comparisons, see Fig. 4).\nIt is well known that there is a trade-off between RTs and accuracy in cognitive tasks. To investigate this relationship further, we extended our analysis to examine whether the model's accuracy would"}, {"title": "3.2 Object recognition task", "content": "Unlike previous visual decision-making models, we want to show that our method can also be applied to natural images and multi-class datasets. Specifically, we consider an object recognition task, a classic paradigm used extensively in computer vision [43, 44] and cognitive neuroscience studies [45,46]. The original data is from [39], where 88 participants perform the task through Mturk. The stimuli in this task belong to 10 categories, and for each category, there are 20 natural images taken from the COCO dataset [47] and 112 synthetically generated images with different backgrounds and object positions.\nWe first train our RNN with BPTT to perform a 10-way classification task. In the original study, participants performed a binary classification task. However, since the individual binary pairs were"}, {"title": "3.3 RTifying feedforward neural networks", "content": "Given the prevalence of feedforward networks (e.g. CNNs) and their incredible performance in visual tasks, a natural question is how to align such networks in the temporal domain of decision-making. We thus developed a biologically plausible, multi-class, differentiable RNN module based on the WW recurrent circuit model [21, 22]. This module can be stacked on top of any neural network, even if not recurrent, and can be used to align model RTs with human RTs.\nFor the RDM task, we take a 3D CNN with 6 convolutional blocks (convolution, BatchNorm, ReLU, Max pooling) and an MLP. We train the network for 100 epochs using the Adam optimizer with a learning rate of 1e-4 at full coherence (c = 99.9%) for the first 10 epochs as a warm-up and le-5 at all coherence levels for the remaining 90 epochs. Since this model is not an RNN, it has no temporal dynamics. Therefore, we drop in our WW module and further train the WW module for 5,000 epochs using the Adam optimizer with a learning rate of 1e-4, a StepLR scheduler with a step size of 1,000 and gamma of 0.3, and a grad clip at 1e-5. Interestingly, when we RTify the C3D model using the WW module, it is able to capture the distribution of human RTs across all coherence levels, see Fig. 6A for coherence = 51.2% to 6.4% and Fig. S4 for all coherences, for MSE comparison see Fig. 4). Furthermore, we also observed a human-like classification accuracy for the model when it is solely trained to fit human RTs but not human accuracy (see Fig. 4).\nSimilarly, we take a VGG-19 pre-trained on Imagenet for the object recognition task and fine-tune it on the dataset provided by Kar et al. [39] in a 10-class classification way for the abovementioned reasons. We train the model for 100 epochs using a batch size of 32. The optimizer was AdamW, with a learning rate of 1e-5. We use a OneCycleLR scheduler adjusted after 10 epochs of warm-up. Results show that our RNN achieves 81.6% on a held-out test set. We further train the WW module for 100,000 epochs using the Adam optimizer with a learning rate of le-4 and a grad clip at 0.0001."}, {"title": "4 Conclusion", "content": "We have described a computational framework to train RNNs to learn to dynamically accumulate evidence nonlinearly so that decisions can be made based on a variable number of time steps to approximate human behavioral choices, including both decisions and RTs. We showed that such optimization can be used to fit an RNN directly to human behavioral responses. We also showed that such a framework can be extended to an ideal-observer model whereby the RNN is trained without human data but with self-penalty that encourages the network to make a decision as quickly as possible. Under this setting, human-like behavioral responses naturally emerge from the RNN \u2013 consistent with the hypothesis that humans achieve a speed-accuracy trade-off. Finally, we provided an RNN implementation of a popular neural circuit decision-making model, the WW model, as a trainable deep learning module that can be combined with any vision architecture to fit human behavioral responses. Our computational framework provides a way forward to integrating image-computable models with decision-making models, advancing toward a more comprehensive understanding of the brain mechanisms underlying dynamic vision.\nLimitations Certain limitations will need to be addressed in future work. Most of the human data used in our study remains relatively small-scale and is limited primarily to synthetic images because more naturalistic benchmarks only include behavioral choices [44,50] and lack RT data. To properly evaluate our approach and that of others, larger-scale psychophysics datasets using more realistic visual stimuli will be needed. There is already evidence that large-scale psychophysics data can be used to effectively align AI models with humans [51,52]. We hope this work will encourage researchers to collect novel internet-scale benchmarks that include both behavioral choices and RTs.\nBroader Impacts As AI vision models become more prevalent in our daily lives, ensuring their trustworthy behavior is increasingly important [53, 54]. Our framework contributes to this effort by exploring how to align certain aspects of models' behavior with human responses in specific contexts. While our approach is limited to predicting RT distributions, it constitutes a first step toward more human-aligned AI models."}, {"title": "A.1 Complete derivation of the differentiable framework", "content": "Proposition 1. Let us define T\u1ed5 (Pt) = min{t \u2208 R[1,N] : \u03a6t > 0} as the time in which \u0424+ reaches the threshold of activity 0. Provided that It is continuously differentiable:\n\u2202\u03c4\u03bf _\n\u03b8\u03c9\n2\n1\n\u0424 - \u0424-1\n\u04d8\u0424\n(-\n)\n\u03b8\u03c9\n(5)\nProof. By definition,\nTo (Pt) = min{t \u2208 R[1,N] : \u03a6t > 0}.\nLet us consider a small change \u03a6. By the Taylor expansion, we can write:\n*\n\u0442\u043e (\u0424 + \u03b4\u03a6) \u2248 \u03c4\u03bf (\u03a6) +\n\u041e\u0442,\n\u0434\u0424 \u03b4\u03a6.\nOn the other hand, t is considered a continuous value. By our definition, we can induce a small change in the value of It by introducing a small change in time \u03b4\u03a6, which we can write in the following way:\nPt+st \u2248 It +\n\u2202It\n\u018ft\n\u03b4t\nWithout loss of generality, let us take ot =\n() \u03b4 and then\n\u2202\u03a6\nPt+st \u2248 It + \u018ft\n()-1\n= \u03a6\u03c4 + \u03b4\u03a6\nNow,\n*\n\u0442\u043e (\u0424t + \u03b4\u03a6) = min{t \u2208 R[1,N] : \u03a6t + \u03b4\u03a6 > 0}\n\u2248 min{t \u2208 R[1,N] : \u03a6t+st > 0}\n= min{t \u2208 R[1,N] : \u03a6\n-1\n> 0}\nt+(\uc740)\u00af\u00b9\u03b4\u03a6\nNote that, by definition, if the evidence is evolving by Pt+\u2206. It just means the whole function is moving along the t-axis, and therefore the minimum time to pass the threshold would be given by \u0422\u041e - \u0394, therefore\nmin{t \u2208 R[1,N] : \u03a6\n-1\n> 0} = min{t \u2208 R[1,N] : \u03a6t}\nt+(\uc740)\u00af\u00b9$$} '54}\nFinally, we can join the two sides and obtain:\n\u0442\u043e (\u0424 + \u03b4\u0424) ~ \u315c(\u0424) + \u0434\u0442\u043e \u03b4\u0424 = (\u0424) -\n\u018ft\n*-1\n() \u03b4\u03a6\nThis means that this can be rewritten as\n\u03b4\u03a6 = \u03b4\u03a6\n\u018ft\n\u0434\u0442\u043e\n\u0434\u0424\n= -\n()-1\n\u0434\u0442\u043e\n\u04d8\u0424\n= (\u0424 - \u0424t-1)-1\n\u0434\u0442\u043e - \u0434\u0442\u043e) -1\u2248 \u03b4\u03c9\n\u2202It\n\u0424\n\u03b4\u03a6\n= \u0434\u0442\u043e (1-7)\n\u03c9 \u04d8It\nSo the first part of Eq 2 in the main text is proved."}, {"title": "A.2 Illustration of the RTified WW circuit", "content": "Figure S2: Illustration of the RTified WW circuit. To RTify feedforward neural networks, we used an RNN based on the WW circuit. Here, we consider a binary classification on random moving dots for illustration (A). When receiving a visual input, the two populations sensitive to left/right directions compete with each other (B) and accumulate evidence until one of them reaches a threshold (C). The number of time steps needed for the RNN to reach the threshold is defined as the \"model RT\" and is used to predict human RT. We provide pseudo-code for a more detailed description of the circuit (D). Here, f(x) = \u03b3\u00b7 max(\u0430\u0445 \u2013 b, 0)/(1 \u2013 exp(-d(ax \u2013 b))) is a fixed nonlinear function. And the model and equations marked blue are how we extend WW model."}]}