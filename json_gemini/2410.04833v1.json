{"title": "Multimodal Fusion Strategies for Mapping Biophysical Landscape Features", "authors": ["Lucia Gordon", "Nico Lang", "Catherine Ressijac", "Andrew Davies"], "abstract": "Multimodal aerial data are used to monitor natural systems, and machine learning can significantly accelerate the classification of landscape features within such imagery to benefit ecology and conservation. It remains under-explored, however, how these multiple modalities ought to be fused in a deep learning model. As a step towards filling this gap, we study three strategies (EARLY FUSION, LATE FUSION, and MIXTURE OF EXPERTS) for fusing thermal, RGB, and LiDAR imagery using a dataset of spatially-aligned orthomosaics in these three modalities. In particular, we aim to map three ecologically-relevant biophysical landscape features in African savanna ecosystems: rhino middens, termite mounds, and water. The three fusion strategies differ in whether the modalities are fused early or late, and if late, whether the model learns fixed weights per modality for each class or generates weights for each class adaptively, based on the input. Overall, the three methods have similar macro-averaged performance with LATE FUSION achieving an AUC of 0.698, but their per-class performance varies strongly, with EARLY FUSION achieving the best recall for middens and water and MIXTURE OF EXPERTS achieving the best recall for mounds.", "sections": [{"title": "1 Introduction", "content": "In response to widespread land degradation and biodiversity loss, in its Fifteenth Sustainable Development Goal \"Life on Land,\" the United Nations calls for protecting, restoring, and promoting the sustainable use and management of terrestrial ecosystems [3]. Successfully conserving habitats and species necessitates effective ecosystem and biodiversity monitoring [10]. Towards this goal, ecologists and protected area managers map biophysical landscape features, often through a combination of remote sensing and ground surveys.\nIn African savanna ecosystems, three examples of such features of interest are rhino middens, termite mounds, and water. Rhino middens are communal defecation sites used by rhinos for territorial marking and social communication [9]."}, {"title": "2 Related Work", "content": "This work is an extension of Gordon et al. [5], which develops an active learning methodology for the detection of rhino middens in this same imagery. While the purpose of that work was to demonstrate the success of a domain-inspired active learning technique, this work explores different fusion methods and architectures and also generalizes to a multi-class setting by considering termite mounds and water in addition to rhino middens. Burke et al. [1] summarizes two general fusion strategies. In early fusion, multiple input modalities are stacked and fed into a single neural network as multiple input channels. In contrast, late fusion involves using a separate network for each of the modalities to extract modality-specific features. The features extracted by these multiple networks are then concatenated and fed into a prediction layer."}, {"title": "3 Dataset", "content": "The dataset consists of spatially aligned thermal, RGB, and LiDAR orthomosaics in GeoTIFF format along with latitude-longitude coordinates for the rhino middens, termite mounds, and water bodies in the site, which we gridify into 20x20-m cells (see Figure 2a). We use QGIS to assign each grid cell a label corresponding to the aforementioned landscape feature it contains, and it is labeled \"empty\" if it contains none of them. Because the band number and resolution of the orthomosaics vary across modalities, the same cell is represented by a different-sized tile in each of the modalities: (40,40) for thermal, (3,400,400) for RGB, and (200,200) for LiDAR. As this is a geospatial dataset, we perform a spatially-aware train-validation-test partition [11] (see Figure 2b), taking the first 50 columns of the grid for training, the next 9 for validation, and the remaining 22 for testing. To address the severe class imbalance (most cells are empty), within the training set we randomly undersample grid cells in the empty class and oversample cells in the midden and water classes so that there are 88 cells for each class. The validation set contains 704 empty cells, 12 midden cells, 18 mound cells, and 17 water cells. The test set contains 1,036 empty cells, 10 midden cells, 16 mound cells, and 21 water cells. The dataset is proprietary and sensitive due to rhino poaching but could be made available upon request."}, {"title": "4 Methods", "content": "To address the limited training data (88 cells per class) available, we utilize transfer learning. All our models are based on a ResNet-50 [6] pretrained on ImageNet-1k [2], a dataset of ground-level RGB images. ResNet-50 takes in three-channel images and outputs a vector of class predictions. We modify the final fully connected layer in the architecture to yield a four-dimensional output to match the four classes in our dataset. We adapt the architecture further in various ways to implement three distinct fusion methods visualized in Figure 3."}, {"title": "5 Experiments", "content": "Setup. We use a batch size of 64 and continue training until the AUC on the validation set has been less than the best AUC for more than 10 consecutive epochs. We normalize all the imagery using the training statistics such that each band in the training imagery has mean 0 and standard deviation 1. We perform 50 trials for each method, where the random seed for trial i is i. Training for EARLY FUSION and LATE FUSION utilizes cross entropy loss and MIXTURE OF EXPERTS uses negative log likelihood loss. We use an Adam optimizer with a learning rate of 0.001 for EARLY FUSION and LATE FUSION, and 0.0001 for"}, {"title": "6 Conclusion", "content": "We studied three methods for fusing thermal, RGB, and LiDAR imagery for mapping three biophysical landscape features: rhino middens, termite mounds, and water. EARLY FUSION concatenates multimodal tiles of the same resolution and passes them through a 5-channel ResNet. LATE FUSION passes tiles of different modalities through separate ResNet feature extractors before fusing them in a fully connected layer. MIXTURE OF EXPERTS uses a gating network to weight the predictions from each modality as a function of the input. Overall, the results show that while the three methods have similar macro-averaged performance with LATE FUSION achieving an AUC of 0.698, their per-class performance varies strongly, with EARLY FUSION achieving the best recall for middens and water and MIXTURE OF EXPERTS achieving the best recall for mounds."}]}