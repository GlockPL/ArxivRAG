{"title": "DESIGNING RELIABLE EXPERIMENTS WITH GENERATIVE AGENT-BASED MODELING: A COMPREHENSIVE GUIDE USING CONCORDIA BY GOOGLE DEEPMIND", "authors": ["Alejandro Leonardo Garc\u00eda Navarro", "Nataliia Koneva", "Alfonso S\u00e1nchez-Maci\u00e1n", "Jos\u00e9 Alberto Hern\u00e1ndez", "Manuel Goyanes"], "abstract": "In social sciences, researchers often face challenges when conducting large-scale experiments, particularly due to the simulations' complexity and the lack of technical expertise required to develop such frameworks. Agent-Based Modeling (ABM) is a computational approach that simulates agents' actions and interactions to evaluate how their behaviors influence the outcomes. However, the traditional implementation of ABM can be demanding and complex. Generative Agent-Based Modeling (GABM) offers a solution by enabling scholars to create simulations where AI-driven agents can generate complex behaviors based on underlying rules and interactions. This paper introduces a framework for designing reliable experiments using GABM, making sophisticated simulation techniques more accessible to researchers across various fields. We provide a step-by-step guide for selecting appropriate tools, designing the model, establishing experimentation protocols, and validating results.", "sections": [{"title": "Introduction", "content": "In an era where artificial intelligence (AI) is reshaping countless fields, the research community of social sciences needs to adapt to the changes posed by these technologies [1, 2]. In particular, data quality and authenticity play a significant role in social sciences [3], where the conclusions drawn rely heavily on data collected, for instance, from surveys.\nThere are many traditional ways of gathering data, such as public datasets or private surveys, but AI has led to innovative approaches, like using agent-based models (ABMs). In recent years, the use of this paradigm has gained significant attention across a variety of fields, from economics and social sciences to artificial intelligence and computational biology [4, 5, 6]. ABMs allow researchers to simulate complex situations by modeling the behaviors and interactions of individual agents within a given environment [7]. These models provide a powerful way to understand emergent phenomena-such as market dynamics, social behaviors, or ecological systems\u2014that arise from the independent actions and interactions of individual agents, each following its own set of rules.\nIn spite of their flexibility, these models face some limitations, particularly when dealing with complex environments. One of the main challenges is that the agents' behaviors are programmed by the modeler based on assumptions or simplified rules. This rigid structure limits the ability to account for the full range of possible interactions that can emerge in real-world scenarios."}, {"title": "Conceptual Framework", "content": "This section establishes the theoretical foundation and structure of the approach we propose for conducting reliable experiments using GABMs. To better understand how this technology fits into experimental research, we will first define the core concepts behind agent-based modeling and generative models, followed by a discussion on the framework we propose for GABM-based experimentation."}, {"title": "GABM and its Role in Experimentation", "content": "At its core, as previously mentioned, agent-based modeling tries to understand the behavior of complex systems by placing agents in an environment and studying the outcomes of the interactions between the agents and the environment. These so-called agents are rule-based entities, meaning their behaviors are predetermined by a set of rules defined by the experimenter. Its use is often limited by its rigidity, since it may fail to capture real-world behavior. This can result in models that are deterministic or, in other words, unable to adapt to or exhibit more human-like, context-driven decision-making.\nGenerative agent-based modeling takes ABM a step further by incorporating generative models. These models are designed to create new data samples that mimic the patterns of existing data [11]. Generative models, such as Generative Pretrained Transformers (GPT), have gained significant fame in recent years, especially in natural language processing, for enabling human-like conversations [12]. This combination improves the capabilities of agents, allowing them to produce more complex behaviors, evolve, learn from their environments, and generate outcomes that reflect more realistic social interactions.\nThe use of this modeling in experimentation opens up a new boundary for social scientists and researchers. These models allow them to conduct simulations that imitate real scenarios with a high degree of complexity, offering opportunities to explore human behavior, societal interactions, and decision-making processes in ways that traditional methodologies struggle to achieve. As discussed by Ghaffarzadegan et al. (2024) [13], GABMs harness the capabilities of LLMs to represent human decision-making within social contexts. In their study, they introduced a simple GABM that simulates social norm diffusion within an organization, providing a framework for integrating human behavior into simulation models."}, {"title": "Framework Concept Definition", "content": "In this section of the paper, we propose a structured approach for developing a Generative ABM project. It can be broken down into several key stages:\n1. Conceptualization: The first stage involves defining the research objectives and identifying the problem that the GABM will address. This phase also requires thoughtful consideration of the simulation itself: determining who the agents will represent (individuals, groups, or organizations) when the simulation will occur (specific periods, real-time or hypothetical scenarios), where it takes place (within a defined environment like a market, network, or geographic location), and how the agents will interact with one another and their environment. These aspects are crucial for building a simulation that will yield insightful results.\n2. Tool Selection and Configuration: For managing the simulations, Concordia will be used as the primary tool. However, it is equally important to choose an appropriate large language model, such as Mistral [17] or ChatGPT [18]. Additionally, securing an API key for the selected LLM is important to integrate its capabilities into the simulation, ensuring that it can handle the complexity of agent behaviors and environmental interactions.\n3. Agent and Environment Design: In this stage, the agents and the environment are carefully designed. Agents are defined by characteristics such as personality traits, age, gender, name, and memories, which influence their behaviors and decision-making processes. The environment is configured to replicate the setting where these interactions will take place.\n4. Execution and Simulation: After the design phase, the simulation is executed. Agents interact with each other and their environment, generating data that reflects the dynamics being studied. During this stage, researchers can observe emergent behaviors and make the necessary changes."}, {"title": "Methodology", "content": "This section provides a step-by-step guide to implementing the steps outlined in Section 2. Unlike the previous section, which focused on theory, this one offers a practical approach, enabling the reader to carry out a project involving this type of modeling.\nTo illustrate this, we will use a research case of simulating the spread of information in a social network. By going through all the stages from Fig. 1, we will give some shape to this case, detailing the necessary actions and considerations to guarantee a reliable experiment."}, {"title": "Step 1: Conceptualization", "content": "In this initial stage, the researcher defines the overall goal of the simulation. To facilitate this process, it can be helpful to pose exploratory questions, such as: \"How quickly does information spread among friends on social media?\" or \"What impact does an influential user have on the spread of news?\"\nThese questions serve as a foundation for establishing a clear objective for the project. From these, we can define the objective of understanding how information spreads through a network of users when exposed to various factors, such as social influence and user engagement.\nOnce the target is defined, we can begin to consider the who, when, where, and how through a thought process, like the one shown below:\n\u2022 WHO: Who are the agents in the simulation? Are they social media users, influencers, or a specific de-mographic? What age range and interests do these users have?, How are the agents connected (e.g., friend relationships, follower-following structure)?\n\u2022 WHEN: What is the duration of the simulation (e.g., a week, a month)? Are there specific events or triggers that initiate the simulation (e.g., the release of a new story or viral content)?\n\u2022 WHERE: What social media platform or type of network will be simulated (e.g., Twitter, Facebook, Insta-gram)? Are there specific features of the platform that need to be considered (e.g., hashtags, groups, stories)? How will the layout of the environment be structured (e.g., user profiles, news feeds)?\n\u2022 HOW: What types of actions will agents take (e.g., likes, shares, comments)? Are there rules governing these interactions (e.g., thresholds for sharing or commenting)? How will agents' behaviors change based on feedback or other agents' actions?"}, {"title": "Step 2: Tool Selection and Configuration", "content": "The tools selected for the simulation are crucial to ensuring the project meets its objectives. For this guide, Concordia will be the platform used to manage the interactions. An important aspect of this process is selecting an appropriate LLM, as it plays a significant role in simulating realistic conversations.\nWhen choosing an LLM, it is essential to consider factors such as model accuracy, training data, and cost. A well-trained model can provide more accurate and contextually relevant responses, enhancing the realism of user behavior in the simulation. Additionally, evaluating pricing options is important to ensure that the selected model aligns with the project's budget while still meeting the required performance standards.\nThe LLM is integrated into the Concordia platform using an API key and the model name, and it is adapted to support a range of models, including not only ChatGPT but also Mistral or Gemini [19]."}, {"title": "Step 3: Agent and Environment Design", "content": "In this third stage, we provide a full context of the environment where the simulation is set. The environment is provided as a common context that all agents interact with. In our case, the social media platform acts as the shared environment where users navigate and engage. For instance, we will specify that all agents (representing users) have access to a generic platform where they can view a news feed, like posts, share content, and comment on discussions.\nThe shared context might include information such as, \"The platform allows users to post updates, follow others, and engage with trending topics,\" or \"Influential users have more followers, which increases the spread of their posts.\" For example, in a simulation, users could share knowledge like, \"Posts with images are more likely to be shared,\" or \"Comments from verified accounts receive more engagement.\" This contextual setup ensures that each agent uses the platform in a manner that reflects real behaviors.\nThe final step of this stage would be to incorporate the characteristics of the agents into the library. These are designed using the many components that are available with Concordia, allowing us to define not only the age or the name of the agent but also an entire memory full of information.\nWe can include attributes such as age, interests, friend connections, and political ideologies. In the example we have been working on, it might be useful to consider traits like trustworthiness, susceptibility to influence, emotional state, and engagement level, which can affect how likely users are to share or engage with information."}, {"title": "Step 4: Execution and Simulation", "content": "Once the agents and the environment are defined, it is time to generate the simulations. This is done by means of a Game Master (GM), which balances LLM calls and associative memory retrieval, overseeing the simulation of the environment where the agents interact. When agents decide on actions, they express their intentions in natural language, and the GM interprets these actions, translating them into appropriate implementations within the simulation.\nIn Concordia, we can simulate conversations and interactions between agents by setting up rounds of exchanges. Throughout these rounds, agents can generate observations and respond based on the evolving scenario. These interactions are monitored and plotted using various metrics, such as how agents' opinions of others evolve over time or how their behaviors shift during the simulation.\nAt the end of the simulation, we can generate summaries of the episode by compiling all the interactions and memories of the GM. These summaries can be structured as a news report, capturing the sequence of events in a narrative format. We can also produce a personalized summary for each agent, giving a perspective of what happened to them during the simulation.\nFinally, we can build an HTML log of the entire experiment. This log can display the complete sequence of events, the GM's memory, and the perspectives of each player, allowing for analysis and visualization of how the simulation progressed."}, {"title": "Reliability of Experiments", "content": "Before showing an example of how we apply these steps, it is essential to highlight an important aspect regarding the reliability of experiments. The questions to answer is up to which point the result of the experiments would resemble the outcome in a real interaction.\nIf previous experiments have been conducted under similar conditions, they can serve as valuable training sets, or benchmarks to validate the findings of the current study.\nFor example, when individual interactions and outcomes are available from previous experiments with real people, a subset of them can be used to fine-tune the design of the agents and environment, validating that the result approximates the original one. Then, a different subset can be used to test that the agents behave properly. This would be similar to how AI models are trained and tested. Furthermore, variations to the agents and environment can be done to try to detect and report new findings.\nWhen we have aggregate information, but no individual experiments, it is possible to run the simulation a number of times to get the outcomes, and calculate and compare the statistical measures.\nIn the absence of a ground truth, it is crucial to employ common sense and logical reasoning to assess the reliability of the simulation results. As an example, the Concordia Contest 2024 for agent creation\u00b9 evaluates the results based on the average returns obtained by the agents across different scenarios."}, {"title": "Demonstration", "content": "To illustrate the methodology discussed in Section 3, we conduct a simulation of information spread on a social media platform. This example focuses on five agents, representing a mix of influential and regular users. We will now guide the reader through each step of the simulation process, from conceptualization to execution."}, {"title": "Step 1: Conceptualization", "content": "The agents will be interacting on a platform called ConnectNet, which is a fictional environment created for the simulations. These are some of the characteristics that we have defined in order to create the shared context:\n\u2022 ConnectNet is a popular platform for sharing news and personal updates.\n\u2022 Users on ConnectNet often follow trends based on viral content.\n\u2022 The platform has features like posts, comments, likes, and shares.\n\u2022 Trending topics on ConnectNet can quickly gain attention and spread across the user base.\n\u2022 The platform allows users to follow others and interact with their posts.\n\u2022 There are no official fact-checkers on ConnectNet, so misinformation can spread quickly.\n\u2022 The platform has a user-friendly interface, encouraging high levels of engagement.\n\u2022 Popular posts on ConnectNet often include viral challenges, news updates, and opinion pieces.\n\u2022 Algorithms on ConnectNet prioritize content based on user engagement, amplifying popular posts.\nFurthermore, as previously mentioned, we have come up with five characters: Alice and Bob are influential figures, while Dana and Evan are regular users engaging with content. Charlie, on the other hand, acts as a disruptive force, spreading misinformation. The agents vary in characteristics like age and behaviors, but all are connected through their use of the ConnectNet platform, where they interact via posts, likes, shares, and comments."}, {"title": "Step 2: Tool Selection and Configuration", "content": "For the next step, tool selection and configuration, we have chosen to use Mistral, as we believe this LLM is powerful enough to conduct multiple simulations before delivering the proposed framework."}, {"title": "Step 3: Agent and Environment Design", "content": "In this step, having specified the model used for the project, we declare the context and the agents. It is important to first establish the shared context since the agents will be created based on this aspect. This shared context will be a summary of the characteristics of the platform.\nIn our case, we prompted the model to Summarize the characteristics in a concise and insightful fashion. As a result, this is the produced text:\n\"ConnectNet is a social media platform where users share news and personal updates. Its features like posts, comments, likes, and shares facilitate trending topics that can quickly gain attention. Despite the lack of official fact-checkers, misinformation can spread easily. The user-friendly interface encourages high engagement, with popular content prioritized based on user interaction.\"\nIn the same way, the creation of characters is done as follows. First, we generate random personality traits based on the Big Five personality model, which includes five dimensions: extraversion, neuroticism, openness, conscientiousness, and agreeableness [20]. Each of these traits is assigned a random integer value between 1 and 10, indicating the level of that trait.\nNext, a list is created to define the individual agents in the simulation. Each agent (Alice, Bob, Charlie, Dana, and Evan) has specific attributes, such as:\n\u2022 Name: The name of the agent.\n\u2022 Gender: The gender of the agent.\n\u2022 Goal: Each agent has a specific goal that defines their behavior within the simulation. For instance, Alice aims to grow her follower base, while Charlie seeks to discredit Alice by spreading misinformation."}, {"title": "Step 4: Execution and Simulation", "content": "Once these important definitions are done, the memories of the agents are created based on the context and the characteristics that were assigned to each of them.\nTo understand how memory creation and updating work, the paper explains that each agent's memory consists of a long-term and a working memory.\nThe initial memories of each agent are formed when the agent is first created. The user defines different components that shape the agent's behavior and traits, such as its identity, goals, or context. These are stored in the long-term memory, referred to in Concordia as formative memory.\nAs the simulation progresses, the working memory (also known as associative memory) becomes active, storing new observations and experiences that the agent encounters during its interactions. This memory allows the agent to recall past events and use them to guide decisions. Associative memory is especially crucial during simulations managed by GM, where agents are interacting with the environment and each other."}, {"title": "Conclusions and Future Work", "content": "In conclusion, we have provided a guide for designing experiments using generative agent-based models within the Concordia framework, highlighting the benefits of this modeling for simulating complex environments and offering a structured approach to tool selection and model design.\nFuture work could focus on making GABMs even more accessible by setting up an interactive web platform, allowing users to create and customize characters, adjust their behaviors, and visualize detailed information about the agents. It could also offer simulations of interactions between agents with similar or contrasting personalities or political ideologies, ultimately broadening their applicability and impact across various fields."}]}