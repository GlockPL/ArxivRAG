{"title": "Siamese Multiple Attention Temporal Convolution Networks for Human Mobility Signature Identification", "authors": ["Zhipeng Zheng", "Yuchen Jiang", "Shiyao Zhang", "Xuetao Wei"], "abstract": "The Human Mobility Signature Identification (HuMID) problem stands as a fundamental task within the realm of driving style representation, dedicated to discerning latent driving behaviors and preferences from diverse driver trajectories for driver identification. Its solutions hold significant implications across various domains (e.g., ride-hailing, insurance), wherein their application serves to safeguard users and mitigate potential fraudulent activities. Present HuMID solutions often exhibit limitations in adaptability when confronted with lengthy trajectories, consequently incurring substantial computational overhead. Furthermore, their inability to effectively extract crucial local information further impedes their performance. To address this problem, we propose a Siamese Multiple Attention Temporal Convolutional Network (Siamese MA-TCN) to capitalize on the strengths of both TCN architecture and multi-head self-attention, enabling the proficient extraction of both local and long-term dependencies. Additionally, we devise a novel attention mechanism tailored for the efficient aggregation of multi-scale representations derived from our model. Experimental evaluations conducted on two real-world taxi trajectory datasets reveal that our proposed model effectively extracts both local key information and long-term dependencies. These findings highlight the model's outstanding generalization capabilities, demonstrating its robustness and adaptability across datasets of varying sizes.", "sections": [{"title": "I. INTRODUCTION", "content": "With the widespread adoption of GPS devices, a substantial volume of vehicle trajectory data is generated and accumulated on a daily basis. These data are crucial in triggering a myriad of location-based services (e.g., ride-hailing, navigation, point-of-interest recommendation), thereby fostering the advanced development of intelligent transportation systems. The extraction and utilization of identifiable information embedded within the trajectory data are recognized as pivotal factors within these services. Consequently, one notable downstream task in trajectory identifiable information extraction, known as the Human Mobility Signature Identification (HuMID) problem [1], has garnered substantial research attention. The HuMID problem is defined as the discernment of whether a set of trajectories originates from a claimed specific driver, predicated upon historical trajectories from various drivers. HuMID finds extensive application in impostor detection across multiple domains, including fleet management, ride-hailing, and insurance, which aims at safeguarding the security of service users and detecting possible fraud. For instance, within ride-hailing services, HuMID serves to detect irregular driving patterns and prevent vehicles from being operated by unauthorized individuals, thereby ensuring passenger safety.\nThe HuMID problem can be conceptualized as a pivotal task within the domain of driving style representation, wherein the crux lies in discerning latent driving behaviors and preferences from diverse drivers' trajectories to derive distinctive representations. Prior research in this domain has already made notable contributions. For instance, Chowdhury et al. [2] extracted 137 statistical features from smartphone sensors and used a random forest classifier to classify 4 to 5 drivers with relative accuracy. However, conventional machine-learning approaches rely heavily on extensive human expertise and intricate feature engineering. Therefore, based on the deep learning techniques, there are several existing studies focusing on implicitly extracting intrinsic information from trajectories, since Dong et al. [3] first attempted to use deep neural networks to learn driving style features in 2016.\nDong et al. [4] proposed a unified architecture combining supervised and unsupervised learning, which enhanced the efficacy of learned driving style representations, particularly for novel drivers not encountered during the training phase In addition, Kieu et al. [5] proposed the T2INet, a multi-task deep learning framework, which initially maps trajectories to images based on the map grid, then capturing both geographic and driving behavior features for driver number estimation and driver identification. However, these studies addressing driving style representation as a multi-classification problem exhibit commendable performance solely with a limited cohort of drivers. When confronted with an expansive pool of driver candidates, the performance of these approaches notably deteriorates, rendering them unsuitable for real-world HuMID scenarios.\nTo address tasks characterized by a high number of classes and a limited number of samples per class (e.g., handwritten signature verification and face recognition), the Siamese network structure, as a prominent architecture in metric learning, is frequently employed. Ren et al. [1] initially introduced the siamese network structure for processing spatio-temporal data. They successfully applied this architecture to the HuMID task, which involved 197 drivers not present in the training phase. By employing two siamese Long Short-Term Memory (LSTM) networks, they demonstrate the considerable potential of the siamese network structure in addressing large-scale driver identification problems. However, LSTM, as a variant of recurrent neural networks (RNNs), suffers from sequential computation, where the"}, {"title": "II. RELATED WORK", "content": "A. Driving Style Time-series Deep Learning\nNumerous previous studies [6]\u2013[8] have been dedicated to the exploration of learning driving styles from time series data employing deep learning methodologies. However, these investigations predominantly rely on the utilization of multiple sensor data (e.g., accelerator pedal value, steering signals, etc.) collected from CAN-BUS. These data are not only resource-intensive to procure but also tend to contain redundant information. However, considering the widespread use of in-vehicle GPS devices, vehicle trajectory data is easier to collect and inherently rich in identifiable information. Consequently, leveraging vehicle trajectory data presents a promising avenue for driving style characterization and driver identification endeavors.\nB. Representation Learning with Driver Identification\nTraditional approaches typically rely on classical machine learning algorithms and complex feature engineering, heavily depending on human expertise and failing to fully exploit latent information and potential features in the data. The earliest relevant research based on deep learning methods can be traced back to 2016 when Dong et al. [3] first attempted to learn driving style features directly from GPS data using deep learning. However, supervised learning methods have a clear limitation: the set of identified drivers must be a subset of available labeled drivers during the training phase, making it impossible to identify drivers not included in the labels.\nTo address this drawback, Dong et al. [4] and Kieu et al. [5] have successively proposed deep learning frameworks that combine supervised and unsupervised learning and improve the representation capability of unseen data during the training phase. Liu et al. [9] further considered multiple contextual information, including road conditions, geographic semantics, and traffic conditions, and utilized a semi-supervised Generative Adversarial Network (GAN) to generate more precise representations of driving styles.\nTo solve the problem of insufficient identification accuracy in the case of a large number of classes and few intra-class samples, Ren et al. [1] first introduced the Siamese network structure in the processing of spatio-temporal data for verifying whether paired trajectory data is generated by the same driver. The advantage of this method lies in its ability to identify newly added drivers without historical data while maintaining high accuracy, showcasing the robust potential of the Siamese network structure in addressing large-scale driver identification challenges.\nC. Attention Mechanism on Vehicle Trajectory Data\nAttention mechanism was first proposed by Vaswani et al. [10] in 2017, which proposed a novel way to deal with sequence data by Scaled Dot-Product Attention and Multi-Head Attention. Due to its superior ability to model long-term dependencies in time-series data, the attention mechanism is applied in several kinds of vehicle trajectory analysis tasks, including trajectory prediction [11] [12], traffic forecasting [13], and traffic data imputation [14]. This study endeavors to extend their utility to the driver identification domain. To this end, we introduce multiple attention mechanisms aimed at accentuating pivotal information crucial for driver identification purposes."}, {"title": "III. METHODOLOGY", "content": "A. Overview\nIn this section, we briefly depict the overall architecture of the proposed Siamese Multiple Attention Temporal Convolutional Network (Siamese MA-TCN) framework for human mobility signature identification.\nFirst, we use fully connected networks to learn the profile embedding from the extracted profile features for each input driver. Besides, for the different types (seeking or serving) of input trajectories belonging to a pair of drivers, two MA-TCN networks with identical structures and shared parameters are implemented to generate different trip representations for each type of trajectory for each driver. Subsequently, each driver's trip representations are"}, {"title": "B. MHSA Double ModernTCN Block", "content": "We present the Multi-Head Self-Attention Double ModernTCN Block (MHSA Double ModernTCN Block) as a solution for comprehensively extracting both local and long-term dependencies inherent within trajectories, as depicted in Figure 2. It comprises three core elements: a multi-head self-attention layer and two depthwise separable convolutional residual blocks with the same size of dilation factor. The multi-head self-attention layer is designed to accentuate crucial time-step information within the trajectory sequence, while the depthwise separable convolutional residual blocks are tailored to capture localized features within their respective receptive fields.\n1) Multi-head Self-attention Layer: Given the input sequence \\(I \\in \\mathbb{R}^{\\text{lenmax} \\times d}\\), a scaled dot-product self-attention mechanism is applied as:\n\\[\\text{Head}_i = \\text{Attention}(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V, \\quad (1)\\]\nwhere \\(i\\) stands for the index of the attention head, \\(i \\in \\{1,...,n\\}\\), \\(n\\) is the total number of attention heads, \\(Q, K, V \\in \\mathbb{R}^{\\text{lenmax} \\times d}\\) are obtained from \\(I\\) by linear transformations and \\(d_k = \\frac{d}{n}\\). Subsequently, multiple attention heads are integrated to enhance the model's representational capacity. By incorporating the influence of other time steps in its representation at each time step, global dependencies of trajectory sequences are captured. The final output after passing through the multi-head self-attention layer is as :\n\\[\\text{MultiHead}(Q, K, V) = W_o[\\text{Head}_1,..., \\text{Head}_n] + I, \\quad (2)\\]\nwhere \\(W_o\\) is a learnable parameter matrix, \\(W_o \\in \\mathbb{R}^{d \\times d}\\).\n2) Depthwise Separable Convolutional Residual Blocks:\nTo capture temporal dependencies and local features of trajectories across various granularities, thereby yielding semantically enriched representations, we employ the Temporal Convolutional Network (TCN) architecture featuring dilated convolutions to achieve an expanded receptive field size (RFS) at a reduced computational expense. The RFS is influenced by three parameters: the number of residual blocks (N), the convolution kernel size (K), and the dilation factor (B), defined as follows:\n\\[RFS = \\frac{2(B^N - 1)(K - 1)}{B - 1} + 1. \\quad (3)\\]\nIn addition, in mainstream sequence analysis tasks, existing works [15] [16] demonstrate that larger convolutional kernels are more advantageous in capturing long-term dependencies. We therefore further explore using larger convolutional kernels rather than more residual blocks without sacrificing the RFS when extracting the long-term dependencies on trajectory sequences. To balance the storage and computational expense, depthwise separable convolution is adopted. It decouples traditional convolution operation into depthwise convolution for learning temporal information and pointwise convolution for mixing information across feature channel dimensions, which is designed to greatly reduce the number of parameters, thus saving the overheads. Besides, causal convolution makes the output of a time step rely only on elements of the current time step and earlier, which avoids being affected by padding values at the end of sequences."}, {"title": "C. MA-TCN Network", "content": "Figure 3 illustrates the complete structure of the proposed MA-TCN network. The trajectory input, represented as a sequence of grid coordinates, first passes through the embedding layer [17] thus mapping the discrete values in the input into the embedding space and obtaining a low-dimensional real vector. Such processing helps to discover and share similar patterns among different trajectories. Subsequently, the embedded input tensor is successively fed into a 1\u00d71 convolutional layer and a channel attention layer [18]. The former is used to expand the size of the hidden feature channel dimensions to obtain a richer representation, and the latter is used to further emphasize the information of the key hidden feature channels by assigning different weights to different channels, thus weakening the interference of the non-key features. To extract the local and long-term time dependencies within the trajectories comprehensively, we derive trajectory representations at different scales by stacking the proposed MHSA Double ModernTCN Blocks.\n1) Multi-scale Aggregation Attention: To efficiently aggregate the outputs of the individual time steps obtained from each residual block, a time-wise aggregation attention mechanism is first designed. The contribution of the output of each time step \\(h_j, j \\in \\{1, ..., t\\}\\), (other than the padding time step) to the output of the last non-pad time step of each sequence \\(h_t\\) (i.e., the actual last time step of each trajectory) is first considered on each residual block by assigning different attention weights to them. The attention weight of time step j at the l-th residual block is:\n\\[\\lambda_j(l; \\theta) = \\frac{\\exp((h_j^{(l)})^T W_1 h_t^{(l)})}{\\sum_j \\exp((h_j^{(l)})^T W_1 h_t^{(l)})}, \\quad (4)\\]\nwhere \\(W_1^{(l)}\\) is a learnable parameter matrix at the l-th residual block. The final representation of each residual block is yielded as Equation 5 by weighting and summing the information from all time steps in the time dimension.\n\\[h_l = \\sum_j \\lambda_j(l; \\theta) h_j^{(l)} \\quad (5)\\]\nSubsequently, to highlight representations that have a positive impact on the final result, the previously acquired profile embedding \\(d_{emb}\\) of each driver is selected as the target using a target-specific attention mechanism:\n\\[h_l' = \\text{tanh}(V_a h_l + b_a), \\quad (6)\\]\n\\[\\beta_l = \\frac{\\exp(d_{emb}^T h_l')}{\\sum_n \\exp(d_{emb}^T h_n')}, \\quad (7)\\]\nwhere N is the number of MHSA Double ModernTCN Blocks, and the final trip representation \\(T_r\\) is denoted as:\n\\[T_r = \\sum_{l}^{2N} \\beta_l h_l'. \\quad (8)\\]"}, {"title": "D. Model Training", "content": "1) Data Preprocessing: First, we collect the dataset based on the map data and remove the GPS sampling points that are beyond the investigated area. For the unordered dataset, we sort the dataset by driver ID, and then group the GPS sample points according to the change of status which indicates whether there are passengers on board, and the sample points within a group are regarded as a trajectory. In addition, trajectories containing too few (less than 10) and too many (more than 300) sampling points are excluded. The former may be due to anomalous changes in the status leading to incorrect segmentation of the trajectory, while the latter may contain a large amount of noise. The trajectories are then categorized into seeking and driving trajectories based on status, and drivers with less than 5 trajectories of either type in a single day are deleted because the amount of data is insufficient to explore their patterns. Thereby, we obtain the original sequence of trajectories \\(T = \\{p_1, ..., p_m\\}\\), where \\(p_i = [\\text{lat}_i, \\text{lon}_i, t_i]\\), and \\(i \\in \\{1, ...,m\\}\\), denotes the latitude and longitude of the GPS point at timestamp \\(t_i\\). The average velocity between each point and the next point is further calculated as its corresponding velocity \\(v_i\\), thus updating the sequence of trajectories as \\(T' = \\{[p_1, v_1] ..., [p_m, v_m]\\}\\}.\nTo minimize computational overhead, the investigated area is subsequently divided into equal-sized grid cells with a given side length s in latitude and longitude (\\(s = 0.01^\\circ\\)). Besides, each day is divided into 5-minute intervals for a total of 288 intervals per day, denoted as \\(T = \\text{interval}_k\\), where \\(1 \\leq k \\leq 288\\). Based on these operations, the sequence of trajectories \\(T'\\) can then be represented by a sequence of grid coordinates \\(G = \\{[\\text{glat}_1, \\text{glon}_1, \\text{interval}_1, v_1], ..., [\\text{glat}_m, \\text{glon}_m, \\text{interval}_m, v_m]\\}\\), where \\(\\text{glat}_i\\) stands for the coordinates in the latitude direction, \\(\\text{glon}_i\\) represents the coordinates in the longitude direction in the grid coordinate system, \\(i \\in \\{1,...,m\\}\\). Since the lengths of the trajectories are not equal to each other, for better parallelism, each trajectory is padded to the maximum length of the trajectories \\(\\text{lenmax}\\) in each training batch to get the equal-length sequence \\(G_{pad} \\in \\mathbb{R}^{\\text{lenmax} \\times 4}\\). In addition, the padded trajectories are used to generate a padding mask to label the actual length of each trajectory, thus eliminating the effect of the end padding values on the results during the subsequent attention computation. Recall that we transformed the feature dimensions of \\(G_{pad}\\) by embedding layers and the 1\u00d71 convolutional layer, so that eventually, before entering MHSA Double ModernTCN Block, the trajectory sequence is represented as \\(I \\in \\mathbb{R}^{\\text{lenmax} \\times d}\\)\n2) Loss Function: During the training phase, the binary cross entropy loss is employed as the criterion, aimed at minimizing the dissimilarity metric between trajectories originating from the same driver while maximizing it for those originating from distinct drivers, shown as\n\\[\\min_\\theta - (y\\text{log}(D_\\theta(X_1, X_2)) + (1 - y)\\text{log}(1 - D_\\theta(X_1, X_2)))\\]\n\\[\\text{s.t.} X_1 = (T_{rs,1}, T_{ra,1}, d_1), X_2 = (T_{rs,2}, T_{ra,2}, d_2), \\quad (9)\\]"}, {"title": "IV. EXPERIMENT", "content": "A. Experiment Setting\n1) Data Description: In this section, we evaluate our model on two large-scale datasets:\nWe set the number of MHSA Double ModernTCN\nBlock N to 4, the kernel size of depthwise convolution\nK to 10, and the dilation factor B to 2.\nWe implemented our model using PyTorch. The model is trained using Adam optimizer on the server with 2.1 GHz Intel Xeon E5-2620 v4 CPUs, 128G RAM, and nVidia 2080Ti 11G GPUs. The initial learning rates are 0.0001 and 0.00006 for the Shenzhen and Chengdu datasets, respectively.\nB. Performance Comparison\n1) Evaluation Metrics: In order to assess the efficacy of our proposed model alongside baseline methods, we conduct evaluations based on accuracy, recall, and F1 score,"}, {"title": "V. CONCLUSION", "content": "In this paper, we proposed a Siamese Multiple Attention Temporal Convolutional Network (Siamese MA-TCN) to solve the trajectory identification tasks for pairs of drivers (i.e., Human Mobility Signature Identification). Our model integrates the benefits of the TCN architecture with a multi-head self-attention mechanism to effectively capture multi-scale local features alongside long-term dependencies, facilitated by a specially designed aggregation attention mechanism. We conduct extensive experiments on two large-scale real-world datasets and the results show that our model achieves an efficient balance between performance and computational overhead."}]}