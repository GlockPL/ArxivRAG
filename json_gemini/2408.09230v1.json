{"title": "Siamese Multiple Attention Temporal Convolution Networks for Human Mobility Signature Identification", "authors": ["Zhipeng Zheng", "Yuchen Jiang", "Shiyao Zhang", "Xuetao Wei"], "abstract": "The Human Mobility Signature Identification (HuMID) problem stands as a fundamental task within the realm of driving style representation, dedicated to discerning latent driving behaviors and preferences from diverse driver trajectories for driver identification. Its solutions hold significant implications across various domains (e.g., ride-hailing, insurance), wherein their application serves to safeguard users and mitigate potential fraudulent activities. Present HuMID solutions often exhibit limitations in adaptability when confronted with lengthy trajectories, consequently incurring substantial computational overhead. Furthermore, their inability to effectively extract crucial local information further impedes their performance. To address this problem, we propose a Siamese Multiple Attention Temporal Convolutional Network (Siamese MA-TCN) to capitalize on the strengths of both TCN architecture and multi-head self-attention, enabling the proficient extraction of both local and long-term dependencies. Additionally, we devise a novel attention mechanism tailored for the efficient aggregation of multi-scale representations derived from our model. Experimental evaluations conducted on two real-world taxi trajectory datasets reveal that our proposed model effectively extracts both local key information and long-term dependencies. These findings highlight the model's outstanding generalization capabilities, demonstrating its robustness and adaptability across datasets of varying sizes.", "sections": [{"title": "I. INTRODUCTION", "content": "With the widespread adoption of GPS devices, a substantial volume of vehicle trajectory data is generated and accumulated on a daily basis. These data are crucial in triggering a myriad of location-based services (e.g., ride-hailing, navigation, point-of-interest recommendation), thereby fostering the advanced development of intelligent transportation systems. The extraction and utilization of identifiable information embedded within the trajectory data are recognized as pivotal factors within these services. Consequently, one notable downstream task in trajectory identifiable information extraction, known as the Human Mobility Signature Identification (HuMID) problem [1], has garnered substantial research attention. The HuMID problem is defined as the discernment of whether a set of trajectories originates from a claimed specific driver, predicated upon historical trajectories from various drivers. HuMID finds extensive application in impostor detection across multiple domains, including fleet management, ride-hailing, and insurance, which aims at safeguarding the security of service users and detecting possible fraud. For instance, within ride-hailing services,\nHuMID serves to detect irregular driving patterns and prevent vehicles from being operated by unauthorized individuals, thereby ensuring passenger safety.\nThe HuMID problem can be conceptualized as a pivotal task within the domain of driving style representation, wherein the crux lies in discerning latent driving behaviors and preferences from diverse drivers' trajectories to derive distinctive representations. Prior research in this domain has already made notable contributions. For instance, Chowdhury et al. [2] extracted 137 statistical features from smartphone sensors and used a random forest classifier to classify 4 to 5 drivers with relative accuracy. However, conventional machine-learning approaches rely heavily on extensive human expertise and intricate feature engineering. Therefore, based on the deep learning techniques, there are several existing studies focusing on implicitly extracting intrinsic information from trajectories, since Dong et al. [3] first attempted to use deep neural networks to learn driving style features in 2016.\nDong et al. [4] proposed a unified architecture combining supervised and unsupervised learning, which enhanced the efficacy of learned driving style representations, particularly for novel drivers not encountered during the training phase In addition, Kieu et al. [5] proposed the T2INet, a multi-task deep learning framework, which initially maps trajectories to images based on the map grid, then capturing both geographic and driving behavior features for driver number estimation and driver identification. However, these studies addressing driving style representation as a multi-classification problem exhibit commendable performance solely with a limited cohort of drivers. When confronted with an expansive pool of driver candidates, the performance of these approaches notably deteriorates, rendering them unsuitable for real-world HuMID scenarios.\nTo address tasks characterized by a high number of classes and a limited number of samples per class (e.g., handwritten signature verification and face recognition), the Siamese network structure, as a prominent architecture in metric learning, is frequently employed. Ren et al. [1] initially introduced the siamese network structure for processing spatio-temporal data. They successfully applied this architecture to the HuMID task, which involved 197 drivers not present in the training phase. By employing two siamese Long Short-Term Memory (LSTM) networks, they demonstrate the considerable potential of the siamese network structure in addressing large-scale driver identification problems. However, LSTM, as a variant of recurrent neural networks (RNNs), suffers from sequential computation, where the"}, {"title": "II. RELATED WORK", "content": "output of each unit depends on the outputs of its preceding unit. This characteristic inhibits the exploitation of parallel computing resources, resulting in significant time overheads when processing lengthy trajectories. Additionally, LSTM struggles to efficiently extract spatial information, making it more suitable for processing time series data rather than spatio-temporal trajectory data.\nTo address the aforementioned limitations, we proposed the Multiple Attention Temporal Convolutional Networks (MA-TCN) for multi-scale trajectory representation learning. Augmented with extracted profile features, the Siamese MA-TCN is deployed to discern and characterize the behavioral patterns of an extensive cohort of drivers exclusively relying on GPS trajectory data. The proposed model with flexible receptive fields and better parallelism, offers distinct advantages in capturing long-term dependencies. Moreover, the convolution operation's spatial invariance facilitates the extraction of local spatial information from trajectories. Furthermore, the incorporation of multi-head self-attention, coupled with the proposed multi-scale aggregation attention, attracts more key information across multiple dimensions. Our main contributions are summarized as follows:\n\u2022 We propose Siamese Multiple Attention Temporal Convolutional Networks (Siamese MA-TCN) for human mobility signature identification, in which Siamese MA-TCN is able to efficiently provide accurate predictions while accounting for large-scale driver identifications based on solely trajectory data.\n\u2022 We implement the multi-head self-attention mechanism for acquiring global dependencies and a specially designed aggregation attention mechanism for capturing multi-scale local features from vehicle trajectories. Ablation experiments verified the effectiveness of these components.\n\u2022 We provide comprehensive case studies on two real-world city datasets, and demonstrate the outstanding generalization capabilities of our proposed model.\nNumerous previous studies [6]\u2013[8] have been dedicated to the exploration of learning driving styles from time series data employing deep learning methodologies. However, these investigations predominantly rely on the utilization of multiple sensor data (e.g., accelerator pedal value, steering signals, etc.) collected from CAN-BUS. These data are not only resource-intensive to procure but also tend to contain redundant information. However, considering the widespread use of in-vehicle GPS devices, vehicle trajectory data is easier to collect and inherently rich in identifiable information. Consequently, leveraging vehicle trajectory data presents a promising avenue for driving style characterization and driver identification endeavors.\nTraditional approaches typically rely on classical machine learning algorithms and complex feature engineering, heavily depending on human expertise and failing to fully exploit latent information and potential features in the data. The earliest relevant research based on deep learning methods can be traced back to 2016 when Dong et al. [3] first attempted to learn driving style features directly from GPS data using deep learning. However, supervised learning methods have a clear limitation: the set of identified drivers must be a subset of available labeled drivers during the training phase, making it impossible to identify drivers not included in the labels.\nTo address this drawback, Dong et al. [4] and Kieu et al. [5] have successively proposed deep learning frameworks that combine supervised and unsupervised learning and improve the representation capability of unseen data during the training phase. Liu et al. [9] further considered multiple contextual information, including road conditions, geographic semantics, and traffic conditions, and utilized a semi-supervised Generative Adversarial Network (GAN) to generate more precise representations of driving styles.\nTo solve the problem of insufficient identification accuracy in the case of a large number of classes and few intra-class samples, Ren et al. [1] first introduced the Siamese network structure in the processing of spatio-temporal data for verifying whether paired trajectory data is generated by the same driver. The advantage of this method lies in its ability to identify newly added drivers without historical data while maintaining high accuracy, showcasing the robust potential of the Siamese network structure in addressing large-scale driver identification challenges.\nAttention mechanism was first proposed by Vaswani et al. [10] in 2017, which proposed a novel way to deal with sequence data by Scaled Dot-Product Attention and Multi-Head Attention. Due to its superior ability to model long-term dependencies in time-series data, the attention mechanism is applied in several kinds of vehicle trajectory analysis tasks, including trajectory prediction [11] [12], traffic forecasting [13], and traffic data imputation [14]. This study endeavors to extend their utility to the driver identification domain. To this end, we introduce multiple attention mechanisms aimed at accentuating pivotal information crucial for driver identification purposes."}, {"title": "III. METHODOLOGY", "content": "In this section, we briefly depict the overall architecture of the proposed Siamese Multiple Attention Temporal Convolutional Network (Siamese MA-TCN) framework for human mobility signature identification as Figure 1.\nFirst, we use fully connected networks to learn the profile embedding demb from the extracted profile features for each input driver. Besides, for the different types (seeking or serving) of input trajectories belonging to a pair of drivers, two MA-TCN networks with identical structures and shared parameters are implemented to generate different trip representations for each type of trajectory for each driver. Subsequently, each driver's trip representations are"}, {"title": "B. MHSA Double ModernTCN Block", "content": "We present the Multi-Head Self-Attention Double ModernTCN Block (MHSA Double ModernTCN Block) as a solution for comprehensively extracting both local and long-term dependencies inherent within trajectories, as depicted in Figure 2. It comprises three core elements: a multi-head self-attention layer and two depthwise separable convolutional residual blocks with the same size of dilation factor. The multi-head self-attention layer is designed to accentuate crucial time-step information within the trajectory sequence, while the depthwise separable convolutional residual blocks are tailored to capture localized features within their respective receptive fields.\nGiven the input sequence $I \\in \\mathbb{R}^{\\text{lenmax}\\times d}$, a scaled dot-product self-attention mechanism is applied as:\n$Head_i = Attention(Q, K, V) = \\text{softmax}(\\frac{QK^T}{\\sqrt{d_k}})V$,\nwhere i stands for the index of the attention head, $i \\in \\{1,...,n\\}$, n is the total number of attention heads, $Q, K, V \\in \\mathbb{R}^{\\text{lenmax}\\times d}$ are obtained from I by linear transformations and $d_k = \\frac{d}{n}$. Subsequently, multiple attention heads are integrated to enhance the model's representational capacity. By incorporating the influence of other time steps in its representation at each time step, global dependencies of trajectory sequences are captured. The final output after passing through the multi-head self-attention layer is as :\n$MultiHead(Q, K, V) = W_o[Head_1,..., Head_n] + I$,\nwhere $W_o$ is a learnable parameter matrix, $W_o \\in \\mathbb{R}^{d\\times d}$.\nTo capture temporal dependencies and local features of trajectories across various granularities, thereby yielding semantically enriched representations, we employ the Temporal Convolutional Network (TCN) architecture featuring dilated convolutions to achieve an expanded receptive field size (RFS) at a reduced computational expense. The RFS is influenced by three parameters: the number of residual blocks (N), the convolution kernel size (K), and the dilation factor (B), defined as follows:\n$RFS = \\frac{2(B^N - 1)(K - 1)}{B-1} + 1$.\nIn addition, in mainstream sequence analysis tasks, existing works [15] [16] demonstrate that larger convolutional kernels are more advantageous in capturing long-term dependencies. We therefore further explore using larger convolutional kernels rather than more residual blocks without sacrificing the RFS when extracting the long-term dependencies on trajectory sequences. To balance the storage and computational expense, depthwise separable convolution is adopted. It decouples traditional convolution operation into depthwise convolution for learning temporal information and pointwise convolution for mixing information across feature channel dimensions, which is designed to greatly reduce the number of parameters, thus saving the overheads. Besides, causal convolution makes the output of a time step rely only on elements of the current time step and earlier, which avoids being affected by padding values at the end of sequences."}, {"title": "C. MA-TCN Network", "content": "The trajectory input, represented as a sequence of grid coordinates, first passes through the embedding layer [17] thus mapping the discrete values in the input into the embedding space and obtaining a low-dimensional real vector. Such processing helps to discover and share similar patterns among different trajectories. Subsequently, the embedded input tensor is successively fed into a 1\u00d71 convolutional layer and a channel attention layer [18]. The former is used to expand the size of the hidden feature channel dimensions to obtain a richer representation, and the latter is used to further emphasize the information of the key hidden feature channels by assigning different weights"}, {"title": "D. Model Training", "content": "First, we collect the dataset based on the map data and remove the GPS sampling points that are beyond the investigated area. For the unordered dataset, we sort the dataset by driver ID, and then group the GPS sample points according to the change of status which indicates whether there are passengers on board, and the sample points within a group are regarded as a trajectory. In addition, trajectories containing too few (less than 10) and too many (more than 300) sampling points are excluded. The former may be due to anomalous changes in the status leading to incorrect segmentation of the trajectory, while the latter may contain a large amount of noise. The trajectories are then categorized into seeking and driving trajectories based on status, and drivers with less than 5 trajectories of either type in a single day are deleted because the amount of data is insufficient to explore their patterns. Thereby, we obtain the original sequence of trajectories $T = \\{p_1, ..., p_m\\}$, where $p_i = [\\text{lat}_i, \\text{lon}_i, t_i]$, and $i \\in \\{1, ...,m\\}$, denotes the latitude and longitude of the GPS point at timestamp $t_i$. The average velocity between each point and the next point is further calculated as its corresponding velocity $v_i$, thus updating the sequence of trajectories as $T' = \\{\\[p_1, v_1] ..., \\[p_m, v_m]\\}$.\nTo minimize computational overhead, the investigated area is subsequently divided into equal-sized grid cells with a given side length s in latitude and longitude (s = 0.01\u00b0). Besides, each day is divided into 5-minute intervals for a total of 288 intervals per day, denoted as $T = \\text{interval}_k$, where $1 \\leq k \\leq 288$. Based on these operations, the sequence of trajectories T' can then be represented by a sequence of grid coordinates $G = \\{\\[g_{\\text{lat}_1}, g_{\\text{lon}_1}, \\text{interval}_1, v_1], ..., \\[g_{\\text{lat}_m}, g_{\\text{lon}_m}, \\text{interval}_m, v_m]\\}$, where $g_{\\text{lat}_i}$ stands for the coordinates in the latitude direction, $g_{\\text{lon}_i}$ represents the coordinates in the longitude direction in the grid coordinate system, $i \\in \\{1,...,m\\}$. Since the lengths of the trajectories are not equal to each other, for better parallelism, each trajectory is padded to the maximum length of the trajectories lenmax in each training batch to get the equal-length sequence $G_{\\text{pad}} \\in \\mathbb{R}^{\\text{lenmax}\\times 4}$. In addition, the padded trajectories are used to generate a padding mask to label the actual length of each trajectory, thus eliminating the effect of the end padding values on the results during the subsequent attention computation. Recall that we transformed the feature dimensions of $G_{\\text{pad}}$ by embedding layers and the 1\u00d71 convolutional layer, so that eventually, before entering MHSA Double ModernTCN Block, the trajectory sequence is represented as $I \\in \\mathbb{R}^{\\text{lenmax} \\times d}$\nDuring the training phase, the binary cross entropy loss is employed as the criterion, aimed at minimizing the dissimilarity metric between trajectories originating from the same driver while maximizing it for those originating from distinct drivers, shown as\n$\\min_{\\theta} - (y\\log(D_{\\theta}(X_1, X_2)) + (1 \u2212 y)\\log(1 \u2212 D_{\\theta}(X_1, X_2)))$\ns.t.$X_1 = (Tr_{s,1}, Tr_{a,1}, d_1), X_2 = (Tr_{s,2}, Tr_{a,2},d_2)$,\nwhere it holds that y = 0 if the trajectories belong to the same driver and y = 1 if the trajectories are sampled from two different drivers. $D_{\\theta}(X_1,X_2)$ is the prediction probability of how likely the trajectories belong to the two different drivers."}, {"title": "IV. EXPERIMENT", "content": "In this section, we evaluate our model on two large-scale datasets:\n\u2022 Shenzhen Dataset: The raw Shenzhen dataset contains GPS records collected from taxis in Shenzhen, China during July 2016. There were in total 17,877 taxis equipped with GPS sets, where each GPS set generates a GPS point every 40 seconds on average. We conduct the experiments on the dataset provided in [1], which contains a total of 158,718 trajectories from 697 drivers over 10 workdays, with each trajectory containing an average of about 22 sampled GPS points.\n\u2022 Chengdu Dataset: The raw Chengdu dataset is collected from real-world taxis in Chengdu, China dated from Aug 3rd, 2014 to Aug 29th, 2014. Over 1.4 billion GPS records are collected and over 14,000 taxis are involved [19]. We select a total of 585,483 trajectories of 697 drivers over a complete two-week period, (i.e., 14 days, from Aug 3rd, 2014 to Aug 16th, 2014), for the experiments. Each trajectory contains an average of about 60 sampled GPS points.\nEach GPS sample point in both datasets contains five key data fields, including taxi ID, time stamp, status, latitude, and longitude. Status is a binary value that indicates whether there are passengers on board. For the Shenzhen/Chengdu dataset, we use the data from the first 5/7 days of the 500 drivers for training and the remaining 5/7 days of data from these drivers for validation. Subsequently, the remaining 197 drivers who were not involved in the training were tested using the trajectory data of the latter 5/7 days.\n\u2022 We set the latent feature dimension d to 64. Besides, the hidden size of the multi-head self-attention is also set to 64 and there are 8 attention heads in total.\n\u2022 We set the number of MHSA Double ModernTCN Block N to 4, the kernel size of depthwise convolution K to 10, and the dilation factor B to 2."}, {"title": "B. Performance Comparison", "content": "In order to assess the efficacy of our proposed model alongside baseline methods, we conduct evaluations based on accuracy, recall, and F1 score,"}, {"title": "V. CONCLUSION", "content": "In this paper, we proposed a Siamese Multiple Attention Temporal Convolutional Network (Siamese MA-TCN) to solve the trajectory identification tasks for pairs of drivers (i.e., Human Mobility Signature Identification). Our model integrates the benefits of the TCN architecture with a multi-head self-attention mechanism to effectively capture multi-scale local features alongside long-term dependencies, facilitated by a specially designed aggregation attention mechanism. We conduct extensive experiments on two large-scale real-world datasets and the results show that our model achieves an efficient balance between performance and computational overhead."}]}