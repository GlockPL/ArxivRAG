{"title": "How Should We Represent History in Interpretable Models of Clinical Policies?", "authors": ["Anton Matsson", "Lena Stempfle", "Yaochen Rao", "Zachary R. Margolin", "Heather J. Litman", "Fredrik D. Johansson"], "abstract": "Modeling policies for sequential clinical decision-making based on observational data is useful for describing treatment practices, standardizing frequent patterns in treatment, and evaluating alternative policies. For each task, it is essential that the policy model is interpretable. Learning accurate models requires effectively capturing a patient's state, either through sequence representation learning or carefully crafted summaries of their medical history. While recent work has favored the former, it remains a question as to how histories should best be represented for interpretable policy modeling. Focused on model fit, we systematically compare diverse approaches to summarizing patient history for interpretable modeling of clinical policies across four sequential decision-making tasks. We illustrate differences in the policies learned using various representations by breaking down evaluations by patient subgroups, critical states, and stages of treatment, highlighting challenges specific to common use cases. We find that interpretable sequence models using learned representations perform on par with black-box models across all tasks. Interpretable models using hand-crafted representations perform substantially worse when ignoring history entirely, but are made competitive by incorporating only a few aggregated and recent elements of patient history. The added benefits of using a richer representation are pronounced for subgroups and in specific use cases. This underscores the importance of evaluating policy models in the context of their intended use.", "sections": [{"title": "1. Introduction", "content": "Sequential decision-making is central to the treatment of many medical conditions, both acute and chronic (Chakraborty and Moodie, 2013; Gottesman et al., 2019). The patterns in how treatment decisions depend on available information, aggregated over physicians and patients, are commonly referred to as the behavior policy. Modeling these patterns has several use cases: Explanation: A behavior policy model can provide insights into current treatment strategies and support the development of new clinical guidelines (Pace et al., 2022; H\u00fcy\u00fck et al., 2021; Deuschel et al., 2024); Implementation: Identifying common treatment patterns and standardizing them can reduce practice variation and leverage the collective expertise of many clinicians (Esteva et al., 2017; Hannun et al., 2019); Evaluation: Most approaches to off-policy evaluation of a new policy, such as importance weighting (Precup, 2000), rely on accurate probabilistic models of the behavior policy. All three use cases of behavior policy modeling benefit from an interpretable model. For explanation and implementation, interpretability is even crucial for gaining the trust of end users (Stiglic et al., 2020). In off-policy evaluation, interpretability allows for verifying the model fit, reasoning about omitted confounding variables-variables that affect both treatment decisions and outcomes\u2014and comparing the behavior policy to a target policy representing new clinical guidelines (Matsson and Johansson, 2022). Failing to account for confounders in off-policy evaluation may result in biased estimates of the value of the target policy (Namkoong et al., 2020). To accurately model sequential clinical decision-making and mitigate bias in downstream tasks, it is important to account for the patient's medical history, including previous contexts, treatments, and outcomes (Gottesman et al., 2019). Despite this, several studies neglect historical context, focusing solely on present observations when formulating clinical policies (Javad et al., 2019; Asoh et al., 2013; Utomo et al., 2018; Lin et al., 2018; Weng et al., 2017). This raises the question: How should we represent history in interpretable models of clinical policies?\nThe literature suggests two primary approaches to summarizing patient history: learned sequence representations and hand-crafted summary features. Recent work in interpretable policy modeling favors the former, employing techniques such as recurrent decision trees (Pace et al., 2022) or recurrent neural networks (Deuschel et al., 2024) to create abstract history representations. For individual patients, these models provide policy descriptions based on the most recent patient information, individualized through the encoded history. Other representation learning methods identify prototypes (Li et al., 2018; Ming et al., 2019)-patients that represent larger groups of individuals providing a compact description of the overall policy (Matsson and Johansson, 2022).\nOn the other hand, summarizing history using hand-crafted features is useful for fitting simple, interpretable models such as linear or rule-based classifiers. These are arguably more interpretable at least more transparent (Lipton, 2018)\u2014than representation learning methods, as they explicitly show how historical information influences the current decision. Naturally, the best summary is specific to the problem at hand (Gottesman et al., 2019), but several strategies frequently appear in the literature, such as aggregating patient information across time (Raghu et al., 2017; Komorowski et al., 2018; Guez et al., 2018), using a fixed-sized window of the most recent observations (Bertsimas et al., 2022; Escandell-Montero et al., 2014), or incorporating indicators for past decisions (Bertsimas et al., 2022).\nDespite the popularity of these approaches to summarizing history, they have not been compared systematically in the context of interpretable policy learning. Notably, prior work using representation learning (Pace et al., 2022; Deuschel et al., 2024) has not explored the impact of different history representations during evaluation. Moreover, their methods are primarily evaluated on two small datasets, focusing solely on binary decisions."}, {"title": "2. Interpretable Policy Modeling", "content": "In sequential clinical decision-making, a behavior policy \\(\\mu\\) represents the treatment patterns physicians generate when making decisions for patients. Our task is to estimate an unknown behavior policy \\(\\mu\\) from observational data consisting of \\(n\\) patient sequences of observations (contexts) \\(X_t \\in \\mathcal{X}\\) and medical decisions (actions) \\(A_t \\in \\mathcal{A} = \\{1, . . ., K \\}\\), recorded at each stage \\(t = 1,...,T\\) of treatment. We let \\(H_t := (X_1, A_1, . . ., X_{t-1}, A_{t-1}, X_t)\\) represent the history of contexts and actions up until the current stage \\(t\\). We refer to the basis for a physician's choice of treatment as the state \\(S_t \\in \\mathcal{S}\\) of a patient, assumed to be an unknown function of the history \\(H_t\\) (Sutton and Barto, 2018). In other words, all direct causes of \\(A_t\\) are assumed to be contained in \\(S_t\\) and in \\(H_t\\).\nWe quantify treatment patterns by estimating \\(P_{\\mu}(A_t | S_t)\\), the probability of choosing an action \\(A_t\\) in a state \\(S_t\\) under the behavior policy \\(\\mu\\). In other contexts, this is called propensity estimation (Abadie and Imbens, 2016), policy recovery (Deuschel et al., 2024) or behavior cloning (Torabi et al., 2018). Particular use cases of estimates \\(\\hat{\\mu}(A_t | S_t)\\) may impose additional constraints on the model. To explain sequential clinical decision-making, the model should ideally be fully interpretable, allowing humans to understand its calculations in their entirety. When implementing the policy in clinical practice, it may be sufficient to understand the model's predictions for individual patients to detect errors or unexpected behavior. For off-policy evaluation, the objective is to estimate the importance ratio \\(\\rho\\) of a target policy \\(P_{\\pi}\\) and the behavior policy model \\(p_{\\mu}\\), \\(\\rho = \\frac{P_{\\pi}(A_t|S_t)}{P_{\\mu}(A_t|S_t)}\\) (Precup, 2000). In this case, an interpretable model of the behavior policy allows for, e.g., understanding differences between the policies and detecting violations of policy overlap (Matsson and Johansson, 2022).\nFollowing common practice, we construct the state \\(S_t\\) either as a hand-crafted summary or a learned representation of the history, \\(S_t = f(H_t)\\). Regardless of method and use case, a key challenge in policy estimation is to ensure that \\(S_t\\) retains sufficient information to predict the action \\(A_t\\) (Gottesman et al., 2019). This is especially true for interpretable models which aim to have small, transparent policy descriptions. In particular, the state must account for confounding variables that have a causal effect on both the treatment decision and its outcome. What constitutes a sufficient state depends on the problem. For example, in the treatment of patients with rheumatoid arthritis, is the choice of treatment \\(A_t\\) based solely on the current context \\(X_t\\), including patient demographics, disease activity measures, and presence of comorbidities? Do previous treatments or their outcomes matter? What about their mutual order?\nNext, we discuss two common approaches to summarizing a patient's medical history: learned sequence representations and hand-crafted features formed by history truncation and history aggregation. In our experiments, we use hand-crafted features as building blocks to explore different state constructions."}, {"title": "2.1. Sequence Representation Learning", "content": "Since the space of possible histories \\(H_t\\) grows exponentially with time, the history quickly becomes unwieldy. Sequence models such as recurrent neural networks (RNNs) can be used to learn compact summaries of patient histories to use as the state \\(S_t\\). For example, Wang et al. (2018) used a long short-term memory RNN to summarize the history for dynamic treatment recommendation in intensive care. An RNN is known to be opaque but it is possible to open the black-box by introducing a prototype layer into the architecture (Li et al., 2018; Ming et al., 2019) or using it to parameterize an interpretable model (Deuschel et al., 2024). Another approach is to represent the history using recurrent decision trees Pace et al. (2022). However, such models require post-processing to enable human interpretation."}, {"title": "2.2. History Truncation", "content": "History truncation involves selecting a fixed-sized portion of the most recent history, or parts of it, assuming that distant historical events have limited impact on the current decision. Formally, let \\(H_{(t-k):t} := (X_{t-k}, A_{t-k},..., X_{t-1}, A_{t-1}, X_t)\\), where \\(k \\geq 0\\), be the truncated history until stage \\(t\\). For \\(k = 2\\), as illustrated in Figure 1, \\(H_{(t-2):t}\\) includes the current context \\(X_t\\) and contexts from the two preceding stages, along with the actions taken at stage \\(t-1, t-2\\) and \\(t-3\\). In our experiments, we apply the history window only to variables for which previous observations are assumed to potentially influence the current decision. For example, in Figure 1, assuming regular follow-up visits, the patient's age at stage \\(t-2\\) and \\(t-3\\) is redundant given the current age.\nTruncating sequence data is a common preprocessing step in natural language processing and bioinformatics. In medical applications, Bertsimas et al. (2022) defined the state based on the most recent heart rate observations to learn a message delivery policy for mobile health. Escandell-Montero et al. (2014) optimized anemia treatment by formulating a state based on the treatment dose at stage \\(t - 1, t-2\\) and \\(t-3\\). While truncating history allows for constructing a compact state that captures recent historical events, this representation has two obvious disadvantages. First, truncating the history at a specific time step may exclude critical past information. Second, when \\(t \\leq k\\), the absence of earlier history requires some form of imputation, especially if the behavior policy model, \\(\\hat{\\mu}\\), expects an input of fixed size, which is the case for several models in this work."}, {"title": "2.3. History Aggregation", "content": "History aggregation is applied under the assumption that the temporal order of historical events holds little significance. This method aggregates historical information, such as previous treatment assignments, across time, creating a rough summary of the history. Let \\(X_i\\) be a component of the context vector \\(X_t\\). The observations \\(X_1,..., X_i\\) are combined into a single variable \\(X'_i\\) according to \\(X'_i = agg_t X_i\\), where the aggregation operator can be, e.g., sum, max or mean. Aggregations of binarized actions are defined analogously, \\(A'_t = agg_t A_t\\), and the aggregated history is the set of aggregated observations and actions, \\(H'_t = \\{X'_t, \\bar{A}_{t-1}\\} \\). We apply this operation to variables for which the aggregate is assumed to provide different information than the current observation alone. Again, the age of a patient is an example of a variable for which aggregation provides no extra information. In such cases, we set \\(X'_i = X_i\\).\nThe meaning of history aggregation depends on the aggregation operator and variable type, as illustrated in Figure 1 using the max operator. For numerical variables like CDAI, the aggregate corresponds to the highest observed value. For categorical vari-"}, {"title": "3. Experiments", "content": "We study interpretable models of clinical policies in a series of experiments, aiming to answer the questions raised in Section 1: How does the quality of the model fit depend on the representation method and the level of detail in the state \\(S_t\\)? What factors explain variations in performance across different representation methods? And how does the choice of representation affect common use cases? Recognizing that interpretation is strongly tied to domain knowledge, we do not aim to evaluate the degree of interpretability of the different models. Instead, we seek to understand how the model classes differ in their fit. We compare learning using diverse states based on sequence representation learning and hand-crafted features within decision processes related to four medical conditions: Alzheimer's disease, rheumatoid arthritis, sepsis, and chronic obstructive pulmonary disease."}, {"title": "3.1. Datasets", "content": "Our datasets, as detailed in the \"Data and Code Availability\" statement, illustrate the diversity of sequential clinical decision-making tasks. For instance, the treatment of Alzheimer's disease and rheumatoid arthritis (RA) spans several years, with regularly scheduled follow-up visits to slow disease progression. In contrast, managing sepsis and chronic obstructive pulmonary disease (COPD) in the ICU requires continuous administration of treatments like intravenous fluids, vasopressors, and sedative drugs to preserve the patient's life. In all cases except for ADNI, where decisions are binary, clinicians are faced with multiple treatment options at each stage of care."}, {"title": "3.2. Models", "content": "We include three types of interpretable models based on sequence representation learning: prototype-based models designed for sequential data (PSN) (Ming et al., 2019), recurrent decision trees (RDT) (Pace et al., 2022), and models leveraging the recent contextualized policy recovery framework (CPR) (Deuschel et al., 2024). The latter is developed for binary actions and thus only used for ADNI. For comparison, we learn generalized linear models and rule-based models using hand-crafted history representations. Generalized linear models, particularly logistic regression (LR), are widely used as propensity score models for estimating treatment effects in observational studies (Feng et al., 2012; Spreeuwenberg et al., 2010). Rule-based models, such as decision trees (DT), are commonly employed in clinical decision support systems (Banerjee et al., 2019; Chrimes et al., 2023). For ADNI, we also include risk scores (RS) (Ustun and Rudin, 2019), i.e., scoring systems enabling probabilistic predictions. In addition, we include a multilayer perceptron (MLP) and a recurrent neural network (RNN) in the form of a long short-term memory. These models serve as benchmarks to demonstrate the potential accuracy of policy modeling based on the available data."}, {"title": "3.3. Experimental Setup", "content": "We divide each dataset-ADNI, RA, Sepsis, and COPD into training and testing subsets using an 80/20 split, with 20% of the training dataset aside for model validation. For the ADNI, RA and COPD datasets, we apply one-hot encoding to categorical features. Depending on the type of model, we standardize continuous variables or discretize them into five equally-sized partitions. Missing values are primarily imputed on a patient level by propagating the last valid observation, secondarily using mean imputation or frequent category imputation. The Sepsis dataset is preprocessed as described in Komorowski et al. (2018), with normally distributed data standardized and log-normally distributed data log-transformed before standardization.\nModels based on sequence representation learning are trained used the full history as input, \\(S_t = H_t\\). For other models, we consider the following state representations: \\(X_t, A_{t-1}, \\{X_t, A_{t-1}\\}, H_t, \\{X_t, A_{t-1}, H_t\\}, \\{H_{(t-1):t}, H_t\\}, and \\{H_{(t-2):t}, H_t\\}. Note that \\(\\{X_t, A_{t-1}\\} = H_{(t-0):t}\\). To simplify no-"}, {"title": "3.4. General and Stratified Performance", "content": "In Table 3, we report average test AUROC for each model and dataset, using the different state representations described above, with the sum operator used for history aggregation. Across tasks, we find that the best-performing interpretable model performs on par with RNN, suggesting that interpretable policy modeling is feasible. Accounting for historical infor-"}, {"title": "3.5. Modeling Policies for Explanation, Implementation and Evaluation", "content": "Learning an interpretable model of the behavior policy is required to explain decision-making and can help verify assumptions in off-policy evaluation. But is it generally possible to learn an interpretable model that performs well? And is there a cost associated with it? In Figure 4, we plot AUROC against the number of leaves in decision trees fit to the RA data using four different state representations. We measure AUROC in critical states where a switch of treat-the state representation and/or model is overly simplified, we risk losing precision in rare cases.\nOff-policy evaluation of new policies is often performed using importance weighting, see Section 2. A crucial step is to re-weight observed outcomes by the product of inverse probabilities \\(p_{\\hat{\\mu}}(a_t | s_t)^{-1}\\), where \\(a_t\\) is the action taken in state \\(s_t\\) under the behavior policy. In Figure 6, we inspect the median of inverse probability products obtained with LR and RNN when considering different state representations"}, {"title": "4. Discussion", "content": "In this work, we compared two common approaches to representing patient history for interpretable modeling of clinical policies: hand-crafted summary features and learned sequence representations. In particular, we studied how the quality of the model fit depends on the representation method and the level of detail in history summaries. Across four decision-making tasks, we found it possible to achieve competitive results using simple, manually crafted representations. Combining current patient observations, the most recent treatment, and historical aggregates of prior observations and treatments explained most of the variance in treatment selection. Notably, incorporating recent treatments was critical to model performance. These findings are consistent with clinical guidelines. For example, current recommendations for the management of rheumatoid arthritis fo-cus on broad indicators such as poor prognostic factors rather than details of the patient's medical history (Smolen et al., 2020).\nWe investigated factors that explain variations in performance across different representation methods. For instance, by breaking down the results by patient subgroups and stages of treatment, we were able to identify shortcomings in simplified representations. Additionally, focusing on therapy selection in rheumatoid arthritis, we highlighted challenges associated with common use cases of interpretable policy modeling. For example, using a coarse history may increase variance in off-policy evaluation. In all experiments, interpretable models using learned representations performed comparably to black-box models, suggesting that interpretable policy learning is generally viable.\nWe assumed that all direct causes of treatment selections were captured within the observed patient histories. In practice, we were limited to the variables that were actually measured, which means there could be unmeasured confounders. In ADNI, we observed an average AUROC of 0.6-0.7, suggesting that variance in MRI scan ordering is not fully explained by the available variables. However, the published diagnostic policy for mild cognitive impairment, which can be modeled with the variables used here, shows no clear evidence of omitted variables (Pace et al., 2022). The variance may instead stem from differences across institutions and practitioners.\nAnother limitation is that we examined only a limited set of manually created history summaries. For example, it would be possible to combine different aggregation methods or derive additional features from historical data, such as changes in critical observations over time. We leave this extension for future research. The primary goal of this work was to understand the overarching impact of historical information in policy modeling, rather than to fine-tune representations for individual tasks.\nAn interesting direction for future work is to construct policy models that explicitly depend on the stage of treatment. As shown in Figure 2, current patient observations are important for accurately predicting the initial treatments of sepsis. Later in the process, the treatment is often repeated, suggesting that the patients' conditions stabilize. However, although a simple model may be sufficient to explain overall patterns, it risks introducing severe bias in specific use cases such as policy evaluation."}]}