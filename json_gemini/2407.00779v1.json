{"title": "Towards Faster Matrix Diagonalization with Graph Isomorphism Networks and the AlphaZero Frame-work", "authors": ["Geigh Zollicoffer", "Manish Bhattarai", "Christian F. A. Negre", "Adetokunbo Adedoyin", "Kshitij Bhatta", "Phil Romero", "Anders M. N. Niklasson"], "abstract": "In this paper, we introduce innovative approaches for accelerating the Jacobi method for matrix diagonalization, specifically through the formulation of large matrix diagonalization as a Semi-Markov Decision Process and small matrix diagonalization as a Markov Decision Process. Furthermore, we examine the potential of utilizing scalable architecture between different-sized matrices. During a short training period, our method discovered a significant reduction in the number of steps required for diagonalization and exhibited efficient inference capabilities. Importantly, this approach demonstrated possible scalability to large-sized matrices, indicating its potential for wide-ranging applicability. Upon training completion, we obtain action-state probabilities and transition graphs, which depict transitions between different states. These outputs not only provide insights into the diagonalization process but also pave the way for cost savings pertinent to large-scale matrices. The advancements made in this research enhance the efficacy and scalability of matrix diagonalization, pushing for new possibilities for deployment in practical applications in scientific and engineering domains.", "sections": [{"title": "1 Introduction", "content": "The computational task of diagonalizing a matrix is typically an iterative method, and for real symmetric matrices, the Jacobi eigenvalue algorithm continues to be a popular choice, even among the widely popular Householder and QR algorithms (PHILLIPS & TAYLOR, 1998). However, despite having theoretical guarantees and good accuracy for approximate diagonalization problems,"}, {"title": "2 Related work", "content": "Recent work has demonstrated that the AlphaZero framework is indeed capable of discovering faster solution paths in games, and has recently been used to find significant improvements to NP-Hard computer science problems (Silver et al., 2017; 2018). For example, AlphaTensor (Fawzi et al., 2022) has shown the ability to construct the tensor decomposition problem as a game in order to find faster matrix multiplication algorithms than previously seen before, while AlphaDev (Mankowitz et al., 2023) has shown the ability to search for faster sorting algorithms. (Romero et al., 2023) applies an AlphaZero-based FastEigen framework to discover improvements on the Jacobi Eigenvalue algorithm. We extend the capabilities of this work for diagonalization on larger-scale matrices and single models trained on different sizes through the introduction of semi-Markov decision processes and GIN.\nFinding heuristics to enhance the speed of the Jacobi Eigenvalue algorithm is typically the focal point of many works in this area. (Rusu, 2021) has shown that there exists an improvement in speed by instead only searching for a subset of the matrix's largest eigenvalues, while other work focuses on the parallel implementation aspect of the algorithm. In contrast, our work focuses on the discovery of the full set of eigenvalues of the matrix, for some approximate tolerance set by the user. We aim to study alternative heuristics to decrease the number of rotations needed for the algorithm in general for symmetric matrices.\nScalability tends to be a large issue in many RL problems as well. In particular, issues tend to arise during the process of transferring a model not only to a larger input domain but also to an intractable larger state space. Often times, it is in fact infeasible to learn the true optimal policy in favor of a tractable e-optimal policy. In order to successfully learn an approximate optimal solution, state-value approximations, state abstractions, or action space reduction techniques are typically used (Abel, 2022). In this work, we study the effects of using such techniques (Ben-Assayag &\nEl-Yaniv, 2021) alongside the AlphaZero framework to speed up and visualize the learned rotation heuristics of the Jacobi Eigenvalue algorithm."}, {"title": "3 Background", "content": ""}, {"title": "3.1 Monte Carlo Tree Search (MCTS)", "content": "Monte Carlo Tree Search (MCTS) is a heuristic search algorithm (Chaslot et al., 2008). The core idea behind MCTS is to build a search tree incrementally by simulating random games or trajectories starting from the current state of the game. The search tree comprises nodes representing different states and edges representing possible actions. MCTS allocates computational resources to promising parts of the search space, gradually refining its understanding of which actions lead to favorable outcomes. By leveraging simulations, MCTS can effectively explore the state space and identify"}, {"title": "3.2 Graph Isomorphic Network (GIN)", "content": "The Graph Isomorphic Network, a variant of a graph neural network, has been specifically designed to capture detailed graph structure information as well as the underlying connections and interactions between nodes. According to Xu et al. (2019) and Ma et al. (2022), these networks excel in identifying and encoding the intricate patterns and relationships inherent in graph data. A defining feature of Graph Isomorphic Networks is their ability to handle varying input dimensions, ensuring invariance in how graphs are processed regardless of their size or complexity."}, {"title": "3.3 The Jacobi Cyclic and Classical Jacobi algorithms", "content": ""}, {"title": "The Jacobi Eigenvalue algorithm", "content": "The Jacobi eigenvalue algorithm Wilkinson (1965) is an it-erative method that computes the diagonalization of a real symmetric matrix M through a series of rotations. Each rotation matrix (or Givens rotation Wilkinson (1965)), denoted by J(p,q, \u03b8), is constructed through the equations:\n\\begin{align*}  J(p,q, \\theta)_{k,k} &= 1 \\text{ for } k \\neq i, j, \\\\ J(p,q,\\theta)_{p,p} &= c = J(p,q, \\theta)_{q,q} \\\\ J(p,q,\\theta)_{p,q} &= -s = -J(p,q, \\theta)_{q,p} \\\\ J(p,q,\\theta)_{i,j} &= \\delta_{i,j} \\text{ otherwise.} \\\\ \\end{align*}\nwhere \u03b8 is used for c = cos(\u03b8), and s = sin(\u03b8) and is computed in a way such that the indices p, q of Mi+1 = J(p,q, \u03b8)T M\u00b2 J(p, q, \u03b8) is zero BRODLIE & POWELL (1975). The indices p, q are selected to correspond to an upper diagonal element of M\u00b2, i.e., p > q.\nThe algorithm proceeds as follows for M\u00b2: Choose indices p and q, p \u2260 q, such that mpq is maximized, and perform the rotation through Mi+1 = J(p,q,\u03b8)TM\u00b2J(p,q, \u03b8). Typically, Mi+1 is continuously computed until the summation of the off-diagonal elements of M\u00b2 is smaller than a desired threshold.\nNecessity for the Jacobi Cyclic algorithm Often, the classical Jacobi algorithm becomes infeasible due to an O(n\u00b2) search for |mp,q|. In this scenario, it becomes necessary to implement a cyclic variation of the Jacobi algorithm that avoids an O(n\u00b2) expense. The Jacobi cyclic rotation is a method that simply cycles through all the upper diagonal indices in some cyclic ordering of the class of cyclic orderings C. The same cyclic ordering is often repeated until the summation of the off-diagonal elements of A is smaller than a desired threshold. Given the nature of finite index selection for the goal of diagonalization, we model the cyclic Jacobi method and the classical Jacobi method as a Semi-Markov Decision Process, and as a Markov Decision Process, respectively."}, {"title": "4 Methods", "content": ""}, {"title": "Jacobi Rotations as a Markov Decision Process", "content": "We define the selection of the matrix index to be zeroed out as a fully observable Markov Decision Process (MDP) Puterman (1994), denoted by the tuple M = (S,A,T, R, \u03b3), where S is the state space, A is the action space, T is the transition function T(st\u22121, at-1), R is the reward function, and \u03b3 is the discount factor. The goal is to solve the Markov Decision Process, i.e., find the optimal policy \u03c0*. During self-play of the MCTS algorithm Silver et al. (2017) between two or more players, each state is the current upper diagonal of a matrix in the form of a graph (Figure 8), and we define the transition function to be the resulting matrix after applying the Givens rotation Mi+1 = J(p,q,\u03b8)TMJ(p,q,\u03b8) on the current matrix state M\u00b2. We then define the reward to be +1 for the player reaching the state of a fully diagonalized matrix first, and -1 for all other players. Lastly, the action space at each step consists of all non-zero indices p,q of the upper diagonal of the matrix, from which the agent can select the index to zero out with a Givens rotation."}, {"title": "Jacobi Cyclic Rotations as a Semi-Markov Decision Process", "content": "For cases where understanding the optimal sweep direction can be sufficient to speed up matrix diagonalization, we define the selec-tion of a set of predetermined cyclic orderings of the upper diagonal matrix indices as a Semi-Markov Decision Process (SMDP) Puterman (1994), denoted by the tuple: Mo = {S0, O, T0,Ro, \u03b3o}. Since it has been proven that all complete cyclic orderings will converge Fedorov (2013), we define the option space O to be a set of common cyclic orderings from a class C, illustrated in Figure 1. In contrast to the non-cyclic game expressed above, we construct a dense reward environment. We define the transition function to be the resulting matrix Mi+n after applying the sequence of n primitive Givens rotations on the current matrix state M\u00b2 for all non-zero indices, according to a selected cyclic ordering. While navigating through a sequence, if an index is approximately zero, then it is skipped. Since the strategic selection of sweep sequences plays a crucial role in minimizing the number of primitive rotations required to achieve matrix diagonalization, we define the reward to be er for all r primitive rotations that occurred during the option. If a matrix is not yet diag-onalized after a specified max step count, the agent is penalized by the sum of the upper diagonal elements in the matrix."}, {"title": "5 Results and discussions", "content": ""}, {"title": "5.1 Classic Jacobi Training", "content": "We first aim to outperform the heuristic of selecting the maximum upper diagonal element used in the classic Jacobi algorithm, which we will refer to as the MaxElem policy. MaxElem will serve as the second player in the MDP described in section 4, until it is surpassed. Once surpassed, true self-play between agents commences. To generate symmetric matrices for training data, for smaller matrices N \u2264 5, we generate multiple N \u00d7 N Hamiltonian matrices from a trajectory file (the step-by-step evolution of the position of atomic coordinates used in chemistry applications). Temperatures for each sequence are set at 300K, 400K, and 500K. These matrix sequences are then randomly split into a set of 750 matrices for self-play and 250 matrices for inference. All larger symmetric matrices are randomly generated using JAX PRNG seeding. We utilize the AlphaZero framework as our agent. Due to its lightweight design and potential for transfer, the GIN is selected as the function approximator Silver et al. (2017) to explore possible scaling advantages for different sized matrices Ben-Assayag & El-Yaniv (2021). The MCTS hyperparameter Cpunct, which balances exploration and exploitation in the MCTS tree, is set to \u221a2, and the number of self-play iterations before updating the agent's policy network is set to 200. Once self-play has concluded, the GIN model is then trained for 15 epochs, utilizing a learning rate of 0.001, a dropout rate of 0.3, a hidden dimension size of 128, 5 GINConv layers, and a batch size of 256. We then compare with the best model to decide if the heuristic has improved. For further details on the GIN training procedure, as well as the experimented classic Jacobi rollouts, please refer to appendix (A.2)."}, {"title": "5.2 Classic Jacobi Performance", "content": "We briefly discuss the similarity to the results that FastEigen Romero et al. (2023) achieved for the classic Jacobi algorithm, as our methods also successfully identified faster heuristics for the Jacobi Eigenvalue algorithm for 5 \u00d7 5 matrices compared to the MaxElem heuristic. As illustrated in Figure 2, FastGIN + MCTS computes a heuristic for the Jacobi Eigenvalue algorithm that far exceeds the traditional max element heuristic. A significant interpretation of the results shows the ability to generalize within sets of same-sized matrices. Given that the model(s) were trained on different temperatures of matrices (5 \u00d7 5), and then tested on other temperatures, it is clear that a discernible pattern can be exploited within the matrices. Moreover, the GIN implementation proved to be lightweight in comparison to the heavier FastEigen model. Self-play training for matrices N \u2264 5"}, {"title": "5.3 Scalability", "content": "Scaling up, we observed that the Graph Isomorphic Network (GIN) generally did not perform well with large matrices, even after shifting resources to GPU. We hypothesize that training on smaller graphs likely does not provide enough incentive for the model to plan far ahead to the solution, given that solutions for a 6 \u00d7 6 matrix tend to fall under approximately 40 time steps, in contrast to a 5\u00d75 matrix which is solvable around 7 steps. It may be necessary to devise a state abstraction or an intrinsic reward to reliably explore the state space. Due to this observation, we discontinue the usage of GIN for further experiments and instead rely on a larger convolutional neural network."}, {"title": "5.4 Cyclic Jacobi Training", "content": "In contrast to the FastEigen work, we begin laying the framework towards expanding to real-world applications; further advancing prior work. We aim to analyze transitions found by the AlphaZero algorithm to discover improved cyclic ordering choices for the Jacobi cyclic algorithm. The goal is to construct a distribution of sweeps that perform fewer expected primitive rotations than follow-ing the same initial chosen cyclic patterns repeatedly (as typically done in practice). Hence, we"}, {"title": "6 Cyclic Jacobi Performance", "content": ""}, {"title": "6.1 Transitions Probabilities", "content": "Panels (a), (b), and (c) exhibit the sweep transition probabilities for each corresponding matrix size, detailing the distribution of paths taken at each sweep stage. As initially expected, stochasticity in decision-making increases from 15 \u00d7 15 towards 30 \u00d7 30, and eventually towards 50 \u00d7 50. We hypothesized that as matrices grow larger, the expanding state space and the diluted signal from the discount factor challenge the agent's performance.\nHowever, panels (d), (e), and (f) visually encapsulate the transition graphs, suggesting that although stochasticity in sweep direction increases, there are transitions where selection is approximately deterministic."}, {"title": "6.2 Preferred Directions as a New Heuristic", "content": "Referring back to panel (a), for the 15 \u00d7 15 matrix, the model demonstrates a pronounced preference for policy 4: TopLeftBottomRight, which tends to successfully complete the game within six sweeps. However, as the matrix size increases, the option choices initially seem to become dispersed among a subset of options, particularly favoring diagonal cyclic orderings. This distribution aligns with observations from Figure 7, indicating that such options tend to offer superior performance compared to baseline policies. In essence, Figure 6 provides valuable insights into the efficacy of different sweep strategies and highlights the potential for adaptive policy formulation, which could lead to optimized algorithms capable of handling the computational demands posed by larger matrices with greater efficiency.\nWe begin measuring the potential cost savings as illustrated in Table 2. A concise comparison of rotation counts between the mean performance of the 8 baseline policies and the Alpha Zero implementation is presented across a range of matrix sizes. Baseline policies are defined to follow a predetermined sequence of sweeps to achieve diagonalization. In contrast, Alpha Zero has learned to utilize the option space to discover possible strategies to reduce the number of primitive rotations, by adjusting its sweep patterns dynamically. Table 2 demonstrates the average cost savings of using the Alpha Zero distribution, showing a consistent reduction in the number of primitive rotations required for matrix diagonalization. The percentage savings column quantifies this improvement, revealing that Alpha Zero has the potential to outperform common baselines by a significant margin, particularly as the matrix size increases. The improvements range from around 3.45% for a 25 \u00d7 25 matrix to over 10% for matrices of sizes 15 \u00d7 15 and 20 \u00d7 20, indicating the potential of Alpha Zero for more efficient computational performance in future matrix diagonalization tasks."}, {"title": "7 Conclusion", "content": "We have demonstrated the existence of superior heuristics compared to currently practiced heuristics for both variants of the Jacobi eigenvalue algorithm. We have also witnessed the effectiveness and potential downfalls of utilizing the GIN. Given the computational speed increase in contrast to Romero et al. (2023), we expect that the algorithm has achieved a better formulation to allow for scalability to be more effectively managed when computing the rotation paths in the eigenvalue diagonalization process.\nFor future work, we plan to explore utilizing more robust scalable methods alongside state abstrac-tions to yield general solutions as matrix sizes continue to increase. We will also investigate utilizing learned cyclic orderings to possibly further improve the performance of the classic Jacobi rotation al-gorithm. Finally, we expect to expand the option space as we continue to search for better heuristics for the Jacobi cyclic eigenvalue algorithm."}, {"title": "A.1 Frameworks", "content": ""}, {"title": "A.1.1 Framework for symmetric matrices", "content": "We begin by implementing a symmetric matrix M\u00b2 of size N as graph G = (V, E) with a set of vertices V(G) = {1, ..., N} where N := |V| and edges E(G) = ei,j, where an edge ei,j connects the vertices i and j if they are neighbors. We denote the set of neighborhoods of a vertex v as N(v). We set Gu for all matrices M\u00b2 to be an unweighted lattice graph corresponding to the upper diagonal of M\u00b2 where the value of each vertex vi \u2208 V(G) is the corresponding matrix element M with vertex label (i, i).\nNote that in order to compute the Givens rotation matrix Ji during timestep t for a given Matrix\nM\u00b2:\n\\begin{align*}  J^{t}(i, j, \\theta) &= I_{N} \\\\ r_{k,k} &= 1 \\text{for } k \\neq i,j \\\\ r_{i,i} &= c \\text{ for } k = i,j \\\\ r_{j,i} &= -r_{i,j} = -s  \\end{align*}\nWhere c = cos(\u03b8), and s = sin(\u03b8) are computed in a way s.t JM; = 0 for some M\u00b2 where i, j is selected to correspond to an upper diagonal element, i.e i > j\nFor the GIN implementation, since the full matrix is instead initialized to be a graph during the MCTS search, the computation is instead performed by indexing the element M with a 1-dimension array containing the value of the nodes. Since the 1-dimension array of node values are a vectorized representation of the upper diagonal values of matrix M, each index is computed using the closed formula for a matrix of size N:\n\\begin{align*}Index^{G}_{ij}= \\frac{\\left(N*(N+1)\\right)}{2} - \\frac{\\left(N - i\\right) \\left((N-i+1) + j - i\\right)}{2}\\end{align*}\nThis formulation allows the upper diagonal of the current matrix state to be treated as a graph, and thus larger matrices can be perceived as graphs with additional nodes. Once each matrix has been modeled as a graph G, we allow the GIN to be responsible for the classification problem of deciding the value \u00fb of the state G, learning the optimal policy vector \u00ee, and constructing a reasonable hidden state ht for the current state/graph. We illustrate in this process in detail in Figure (8)."}, {"title": "A.1.2 GIN scalability for matrices", "content": "We further utilize trained GIN models to perform inference on different sized matrices, rather than train from scratch. Therefore, to account for the largest number of paths to explore, we utilize heavy play-outs that prioritize patterns seen in smaller matrices and explore different areas of the Jacobi eigenvalue algorithm that result in fewer rotations made. The usage and construction of all heavy roll-outs are discussed more in section (A.2).\nSince the GIN will be trained/inferenced on different sizes of graphs, it is required that the predicted policy is capable of outputting \u00ee s.t that \u00ee is suitable for all matrix sizes. Note that the starting action space for all dense symmetric matrices of size N at t = 0 is of size $\\frac{N(N-1)}{2}$. Therefore, to allow for a scalable policy, \u00ee is instantiated $\\frac{N_{max}(N_{max}-1)}{2}x 1$, where Nmax is the N dimension of the largest matrix expected for the model to do inference on. Given a smaller matrix, we normalize the vector to account for the smaller inherent action space. An illustration is given by Figure (9).\nOnce \u00fb and \u00ee have been computed, we follow the standard AlphaZero framework MCTS rollout algorithm. Similar to AlphaTensor Fawzi et al. (2022), we compose our dataset of random transitions,"}, {"title": "A.2 Jacobi Heavy Rollouts", "content": "To explore other possible heuristics for Givens rotations other than the max upper diagonal element, we perform a mixture of heavy roll-outs and based on the positioning of the matrix cells. To be exact, we consider the total cardinality of the action space of a given Graph Gr to be: $\\frac{N(N-1)}{2}$\u2013 $|{V(G) : v_i = 0}|$ for any N \u00d7 N Matrix. To reduce the cardinality we first experiment"}, {"title": "with constraining the action space to the N closest elements away from the diagonal, that is the\naction space A\u00e7 is now defined to be A\u00e7 = V(G) :", "content": "\\begin{equation*}  0 \\forall v_i \\in arg \\underset{V(G)' \\subset V(G), |V(G)'|=N} \\text{min}  \\Big \\{ \\sum_{v \\in V(G)'} Man(v, v_i) \\Big \\} \\end{equation*}\nWhere we define Man(v) to be the Manhattan distance of the vertex v from the diagonal of the original matrix. Note that we effectively constrain the action space at each step to at most N with this method.\nIn addition, since our work focuses on finding a reduction of rotations from the original Ja-cobi eigenvalue algorithm, we reduce the maximum depth D of the MCTS search tree. This is done by setting a depth cutoff for the MCTS search which is the amount of rotations the the Jacobi eigenvalue algorithm is expected to take. This allows another dramatic reduction the extensive state space.\nLastly, despite the reduction to the action space and state space maximal depth, there is still an intractable width of paths to explore. To alleviate this issue, we decrease the width of the mcts exploration tree by initially prioritizing search around the original max element heuristic paths, which generates partially synthetic winning sampled paths utilizing both heuristics for the model to learn from. During each ith iteration of self-play, to decide the period of t rotations/timesteps of when the max element heuristic is explored, we generate two random variables Tstart, Tend where Tstart, Tend ~ Uniform(1, D). We then set the MCTS search to explore the max elem heuristic for rotations that occur for timesteps Tstart < t < Tend where t \u2208 [0, D]. After self play has concluded, the max element heuristic is no longer used. The action space Agi returns to N closest elements away from the diagonal and the learned policy of the MCTS search is used to test the currently learned policy. Note that during an iteration of self-play, if Y < X then the max element heuristic will not used for the MCTS search. All adjustments to the AlphaZero self-play are illustrated in algorithm (1)."}]}