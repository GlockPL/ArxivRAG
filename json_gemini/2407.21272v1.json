{"title": "Automated Quantification of Hyperreflective Foci\nin SD-OCT With Diabetic Retinopathy", "authors": ["Idowu Paul Okuwobi", "Zexuan Ji", "Wen Fan", "Songtao Yuan", "Loza Bekalo", "Qiang Chen"], "abstract": "The presence of hyperreflective foci (HFs) is\nrelated to retinal disease progression, and the quantity has\nproven to be a prognostic factor of visual and anatomical\noutcome in various retinal diseases. However, lack of effi-\ncient quantitative tools for evaluating the HFs has deprived\nophthalmologist of assessing the volume of HFs. For this\nreason, we propose an automated quantification algorithm\nto segment and quantify HFs in spectral domain optical\ncoherence tomography (SD-OCT). The proposed algorithm\nconsists of two parallel processes namely: region of inter-\nerest (ROI) generation and HFs estimation. To generate the\nROI, we use morphological reconstruction to obtain the re-\nconstructed image and histogram constructed for data dis-\ntributions and clustering. In parallel, we estimate the HFs\nby extracting the extremal regions from the connected re-\ngions obtained from a component tree. Finally, both the ROI\nand the HFs estimation process are merged to obtain the\nsegmented HFs. The proposed algorithm was tested on 40\n3D SD-OCT volumes from 40 patients diagnosed with non-\nproliferative diabetic retinopathy (NPDR), proliferative dia-\nbetic retinopathy (PDR), and diabetic macular edema (DME).\nThe average dice similarity coefficient (DSC) and correlation\ncoefficient (r) are 69.70%, 0.99 for NPDR, 70.31%, 0.99 for\nPDR, and 71.30%, 0.99 for DME, respectively. The proposed\nalgorithm can provide ophthalmologist with good HFs quan-\ntitative information, such as volume, size, and location of\nthe HFs.", "sections": [{"title": "I. INTRODUCTION", "content": "OPTICAL coherence tomography (OCT) is a paramount\nimaging technique used to image numerous aspects of bi-\nological and medical tissues, such as molecular content, elastic\nparameters, structural information, change of polarization and\nblood flow [1], [2]. Diabetic retinopathy (DR) is one of the most\ncommon causes of vision loss amidst patients with diabetes, and\nalso the dominant cause of blindness among working-age adults\nall over the world [2]. All forms of DR, including diabetic mac-\nula edema (DME), and proliferative diabetic retinopathy (PDR)\nhave the potential to cause severe vision loss and blindness.\nBased on the clinical features, DR is classified into five stages\nnamely mild non-proliferative diabetic retinopathy (NPDR),\nmoderate NPDR, severe NPDR, PDR and DME [3]. NPDR\nis the first stage of DR, which is without any symptoms, and\nthe only way to identify it is by fundus photography and OCT-\nAngiography (OCTA), through which microaneurysms (MA)\ncan be observed. Retinal MA (microscopic blood-filled bulges\nin the artery walls) are the earliest clinical sign of diabetic\nretinopathy, which are accompanied with hyperreflective foci\n(HFs) and visible in spectral domain optical coherence tomog-\nraphy (SD-OCT) image modality as reported by several authors\n[4], [5]. Growing in the number of MA is an evidence of DR\nprogression. DR with MA has 6.2% probability to evolve into\nPDR within a year [6]. With advancement of ischemia, there\nis an increase in contingency of PDR development within one\nyear. This risk development increases from 11.3% to 54.8%\nfrom lower to advanced stage [6]. Hence, there is a need for\nOphthalmologists to efficiently construct an effective diagnos-\ntic procedure that could detect and monitor retinal diseases.\nOne of the metrics that could be used in detecting and mon-\nitoring various retinal diseases (e.g., DR) is the HFs. The pres-\nence and quantity of HFs has a potential that has been proven to\nbe a determining factor with the desired visual and anatomical\noutcomes after treatment in patients with various retinal dis-\neases [7]\u2013[9]. HFs are bright small elements and are scattered\nthrough-out the retinal layers in patients with DR, which was\nfirst reported in SD-OCT by Coscas et al. [10] as depicted in\nFig. 1. Several studies have associated the presence of HFs to\nbe pertinent to progression of disease in various retinal diseases\n[11], [12]. In addition, the existence and location of HFs have\nbeen proposed as a predictive factor of visual and anatomical\noutcome [13]. Quantification of HFs presents the leading step to\nfurther investigate the role of these lesions in pathomorphologic\ndisease dynamics. A quantitative tool for extracting HFs volume\nmay pave way for ophthalmologist in choosing better metrics\nfor treatment strategies. Such a quantitative tool is necessary for\nassessing the OCT image, in order to estimate the HFs volume.\nThis will help ophthalmologist in analyzing the stages of DR.\nManual segmentation and quantification of HFs is error-prone"}, {"title": "II. DATA ACQUISITION", "content": "Forty SD-OCT cubes from 40 patients were included in this\nstudy: 10 patients were diagnosed with NPDR, 14 patients with\nPDR, and 16 patients with DME. These patients were diagnosed\nwith different levels of retinopathy severity of NPDR (mild to\nsevere), PDR (early to advanced), and DME (non-clinically to\nclinically significant). One eye of each patient was used in this\nresearch for the SD-OCT analysis. All patients underwent SD-\nOCT using Cirrus SD-OCT device (Carl Zeiss Meditec, Inc.,\nDublin, CA). The SD-OCT cube covered a 6 \u00d7 6 \u00d7 2 mm\u00b3 area\ncentered on the fovea, which corresponds to a 512 \u00d7 128 \u00d7\n1024 voxels. The 40 SD-OCT cubes from the 40 patients were"}, {"title": "III. METHOD", "content": "We applied bilateral filter (BF) to reduce the noise in the OCT\nimages. Then, the algorithm splits into two parallel processes\nnamely: ROI generation and HFs estimation. Both the ROI and\nthe HFs estimation process were then merged together to obtain\nthe segmented HFs. Fig. 2 summarizes the algorithm."}, {"title": "A. Preprocessing", "content": "We applied the BF [20], [21] and the denoised image is\nobtained as follows:\n$I_f (x) = \\sum_{x_i \\in \\Omega} I (x_i) f_r (||I (x_i) \u2013 I (x)||) g_s (||x_i - x ||)$    (1)\n$I_f$ is the denoised image, $I$ is the input image, $x$ are the co-\nordinates of the pixel to be denoised, $\\Omega$ is the window centered\non $x$, $f_r$ is the range kernel for smoothing variation in inten-\nsities, and $g_s$ is the spatial kernel for smoothing variation in\ncoordinates."}, {"title": "B. Region of Interest (ROI) Generation", "content": "The denoised images were then channeled into two parallel\nprocesses; ROI generation and HFs estimation. To create the\nROI, we clustered the OCT image by labelling each pixel in\nthe image using the pixel\u2019s brightness values (BVs) and simi-\nlarities through their statistical relationships. There are numer-\nous categories of clustering algorithms: grid-based algorithms,\ndensity-based algorithms, hierarchical algorithms, partitional\nalgorithms, and model-based algorithms [22]. In our case, we\ncannot precisely make conclusion that each image pixel belongs\nto only one cluster. It may be possible that some data\u2019s prop-\nerties contribute to more than one cluster. For this purpose, we\npreferred membership value based clustering like fuzzy c-means\nclustering (FCM). We utilized the FCM clustering method. Gen-\nerally, SD-OCT images suffer from poor contrast, noise, limited\nspatial resolution, and other factors. To overcome the problems\nof traditional FCM we introduced: (a) local spatial informa-\ntion using morphological reconstruction (MR) operation, which\nresult in a low computational complexity, (b) modify pixel\u2019s\nmembership by replacing it with local membership filtering that\ndepends only on the spatial neighbors of membership partition,\nand (c) utilized MR to smoothen the images to create a noise im-\nmune FCM, while preserving the image details and eliminating\nthe need for additional filters for noise elimination.\nWe applied clustering on the OCT gray level histogram, while\nwe introduced the local spatial information of the OCT image\nto the objective function of the traditional FCM algorithm. Our\nmodified objective function is given as follows:\n$J_m = \\sum_{l=1}^{q} \\sum_{k=1}^{C} u_{kl}^m ||\\xi_l - v_k||^2 $   (2)\nwhere $\\xi$ is the image reconstructed by MR, $q$ represents the\nnumber of the gray levels contained in $\\xi$, $\\xi_l$ is the gray level,\n$1 \\leq l \\leq q$, $v_k$ represents the prototype value of the $k$th cluster, $c$\ndenotes the number of clusters, $m$ is the weighting exponent on\neach fuzzy membership that determines the amount of fuzziness\nof the resulting classification, $u_{kl}$ denotes the fuzzy membership\nof gray value $l$ with respect to cluster $k$, and\n$\\sum_{l=1}^{q} \\gamma_l = N$  (3)\nwhere $N$ is the overall number of pixels in the image, and $\\xi$ can\nbe calculated as:\n$\\xi = MC (f)$   (4)\nwhere $MC$ is the morphological closing reconstruction, and $f$ is\nthe original image. The optimization problem is converted to an\nunconstrained optimization problem using the Lagrange multi-\nplier technique; therefore, the objective function is minimized\nas:\n$J_m = \\sum_{l=1}^{q} \\sum_{k=1}^{C} u_{kl}^m ||\\xi_l - v_k||^2 - \\sum_l \\lambda_l(\\sum_{k=1}^{C} u_{kl}-1)$   (5)\nwhere $\\lambda$ is a Lagrange multiplier. However, we converted the\nproblem of minimizing the objective function to finding the\nsaddle point of the Lagrange function above, and taking the\nderivatives of the Lagrangian $\\hat{I}_m$ with respect to the parameters\n$u_{kl}$ and $v_k$. We obtained the corresponding results as follows:\n$u_{kl} =  \\frac{||\\xi_l \u2013 v_k ||^{-2/(m-1)}}{\\sum_{i=1}^{q} ||\\xi_i \u2013 v_k ||^{-2/(m-1)}}$   (6)\n$v_k = \\frac{\\sum_{i=1}^{q} u_{ki}^m \\xi_l}{\\sum_{i=1}^{q} u_{ki}^m}$  (7)\nFrom Eq. (6), a membership partition matrix $U_{matrix} =$\n$[u_{kl}]_{C\\times I}$ is obtained. For stable $U_{matrix}$, Eq. (6) and Eq. (7) are\nrepeatedly iterated until $max (U_{matrix}^{(t)} - U_{matrix}^{(t+1)}) < T$, where\n$T$ is the minimal error threshold. Since, $u_{kl}$ is a fuzzy mem-\nbership of gray value of $l$ with respect to cluster $k$, therefore a\nnew membership partition matrix $U_{matrix} = [u_{kl}]_{C\\times N}$ which is\nequal to the original image $f$, and can be obtained as:\n$u_{ki}^{(t)} = u_{kl} \\quad if x_i = \\xi_l$   (8)\nwhere $x_i$ is the gray value of the $i$th pixel. For algorithm ef-\nficiency and performance purposes, we modified the $u_{ki}$ using\nmedian filter as a membership filter as follows:\n$U_{matrix}'' = median filter \\{U_{matrix}'\\}$   (9)\nThe ROI generation algorithm automates in eight working\nsteps, which is presented in Table I. We explain each of the\nsteps involved in the generation of the ROI in detail as fol-\nlows:\nStep 1: Four tunable input parameters are needed to set the\nalgorithm into automation. These parameters are tunable, so that\nthey can be tuned to suit any desired OCT image clustering. In\nthis research, $c = 4$, $m = 2$, $w = 5$, and $T = 0.002$. We are in-\nterested in four clusters; as such the value of c must be 4. Many\nresearchers [23] have proposed and proved that $m = 2$ is the op-\ntimal value for m. In our case, it is also true. After fine tuning by\ntrial-and-error, we observed that any values of $w < 5$ produces\nan undesired result, while for $w > 5$ produces almost the same\nresult as $w = 5$ with additionally huge computational complex-\nity. In addition, we realized that $T = 0.001$ and $T = 0.002$ are\nthe obvious choice for the termination criterion, but the latter\nrequires less computational time. These parameters effect is dis-\ncussed later in Section IV.D. As shown in Fig. 3, there are four\nmajor levels of intensity category in the OCT image used in this\nresearch. The four clusters are (a) highest intensity cluster, (b)"}, {"title": "C. Hyperreflective Foci Estimation", "content": "While generating the ROI, the algorithm also performs the\nestimation of HFs in parallel, which will be discussed in this\nsection. For clarity and better understanding, we briefly give\na summary of the algorithm used in estimating the HFs in\nTable II.\n1) Pixel Sorting: The pixels of the input image $I(x)$ was\nsorted in an increasing order, such that $x_1,x_2,...,x_N \\in A$ is\nthe incremental sorting of the image pixels intensity value, i.e.,\n$I(x_1) \\leq I(x_2) \\leq I(x_N)$   (21)\nhere an image $I(x)$, $x \\in A$ is a function of a set (finite) $A$ with\ntopology $\\tau$. The elements of $A$ are known as pixels, such that$A =$\n$[1,2,..., N]$ and $\\tau$ is induced by four-way neighborhoods and\n$n = 2$. We initiated the sorting processing using the Counting\nsort algorithm [27].\n2) Component Tree: Since our image pixels were sorted ac-\ncordingly, we applied the max-min algorithm [28] in building\nthe component tree. Fig. 7 shows the component tree and il-\nlustrates its working principle, which we will explain below.\nMore detail about the component tree can be found in [28]. Let\nconsider the image $I(x)$ given in Fig. 7(a) associated with the\nfour-connectivity and the total ordering relationship between\nthe pixels of $I(x)$ based on increasing gray levels. A level set\n$S(x)$, $x \\in A$ of the image $I (x)$ is known to contain all the pixels\nwith intensity lower than $I(x)$, i.e.,\n$S (x) = \\{y \\in A : I (y) \\leq I (x)\\}$   (22)\nA path $(x_1,...,x_n)$ is a connected sequence of pixels, in\nwhich $x_1$ and $x_{i+1}$ are four-way neighbors for $i = 1, ..., n -1$.\nIn this work, we express the set of all the extremal regions of the\nimage $I$ as $R(I)$. The extremal regions are distinguished as the\nconnected regions within binary threshold images $I_f (x)$, which\nis obtained from:\n$I_f(x)=\\begin{cases}\n    1, & \\text{I (x)} \\geq g\\\\\n    0, & \\text{otherwise}\n\\end{cases}$   (23)\nwhere $g \\in [min(I(x)) max(I(x))]$. Fig. 7 shows the input im-\nage and various threshold images $I_f (x)$ that are evaluated during\nthe formation of the component tree. During the creation of the\ncomponent tree, each node is assigned the corresponding gray\nvalue $g$ at which it was identified. As such, among all the ex-\ntremal regions $R(I)$, we are only interested in those that satisfy\nthe stability criteria $\\Psi$. The equation for obtaining $\\Psi$ is defined\nas:\n$\\Psi (R^g) = \\frac{|R^{g-\\Delta}| + |R^{g+\\Delta}|}{|R^g|}$   (24)\nhere, $|.|$ denotes the cardinality, $R^g$ presents the region that is\nobtained through thresholding at a gray value $g$, while $\\Delta$ is a\nstability range parameter. Also, $R^{g-\\Delta}$ and $R^{g+\\Delta}$ are the ex-\ntremal regions obtained while moving upwards and downwards\nin the component tree from region $R^g$ until a region $g - \\Delta$ and\n$g+ \\Delta$ is found. In this study, $\\Delta = 0.21$ and $g = 2.10$.\n3) Extremal Regions Extraction: Fig. 8(a) shows all de-\ntected regional maximal in the image and Fig. 8(b) shows\nthe addition of all these pixels to form the maximally con-\nnected regions. Each color in Fig. 8(b) represents different\nextremal region, which is yet to be combined together. In\nhere, we added all sets $T(z) \\cup T(p(z)) \\cup T(p^2 (z)) \\cup \\cup$\n$T(root(z)) = T(root(z))$, where $T(z)$ is defined as the subtree\nfixed at $z$, while $p(z)$ is the parent of $z$ and $root(z)$ represents\nthe root of the tree that hold $z$. We observed that only some sets\nof $S(p^n (z))$ are extremal region, while $S(root(z))$ is invariably\nthe extremal region of the image. Since this embedded all other\nsubsets, it is adequate for us to add them together. The union\noperation is encoded in the forest. We computed the area varia-\ntion for each region, after obtaining the extremal region tree. In\naddition, we selected the maximally stable ones. We obtained the\narea $|R|$ of each region as the first and second order moments as:\n$\\mu(R) = \\frac{1}{|R|}\\sum_{X\\in R} X \\quad, \\Sigma_{R} = \\frac{1}{|R|} \\sum_{X\\in R} (X-\\mu)(X-\\mu)^T$   (25)\nwhere $\\mu$ is the mean. We avoid the use of the centered moment\n$\\sum R$ directly, instead we compute:\n$M (R) = \\frac{1}{|R|} \\sum X X^T$   (26)\nand utilize the fact that $\\Sigma R = M(R) \u2013 \\mu(R)\\mu(R)^T$. This\nis achieved by visiting every pixel of the forest and adding its\nvalue to the parent in breadth first order and from the leaves.\nFinally, we removed duplicated regions caused by noise and\nthe local minimum score which may correspond to several local\nminimums. To remove the duplicated regions, we arranged the\nextremal regions into a tree where $R$ is the parent of $R\u2019$ if\n$R$ immediately contains $R\u2019$. After which, each region $R$ is\nconsidered and the tree is explored to find a region $Q$ for which\n$R = Q^{g-\\Delta}$ and the region $R^{g+\\Delta}$.This is achieved by scanning\nthe regions $R_0 = R$, $R_1 = \\pi(R_0)$, $R_2 = \\pi(R_1)$ and so\non. Therefore, if a region $Q = R_i$ satisfies $Q^{g-\\Delta} = R_0$, then\n$I (R_0) \\leq I (R) \u2013 \\Delta < I (R_1)$   (27)\nsimilarly,\n$I (R) \\leq I (R_0) + \\Delta < I (R_i + 1)$   (28)\nthe duplicated regions can be found by comparing each of the\nmaximally stable $R$ with the maximally stable $R\u2019$ immediately\ncontaining $R$ and removing $R$ if they are too similar. At this\ncleanup phase, we removed regions which have high area vari-\nation above $\\Delta$ and also removed duplicated regions.\n4) Merging: In this stage, the generated ROI and estimated\nHFs were merged together as shown in Fig. 9.\nThe merging was done with the use of logical operation\n(AND), in which all the pixels in the generated ROI and es-\ntimated HFs (Fig. 9) were checked for membership intersection\nand merged. This logical operation returns the Boolean value\ntrue if both operands (generated ROI and estimated HFs) are\ntrue and returns false otherwise. After the merging phase, we"}, {"title": "IV. RESULT AND ANALYSIS", "content": "The ground truth was obtained by two HFs expert raters with\nhigh reliability. A set of guidelines for including and exclud-\ning HFs in the ground truth data set includes: (a) any bright\nregion < 5 pixels should be regarded as speckle noise, (b) the\nregion between RNFL and IS-OS retinal layers are considered\nfor HFs search, (c) similar intensity-like with HFs, such as blood\nvessel reflection, uneven intensity regions, etc. were excluded.\nEach of the raters work independently to obtain the ground\ntruth, and the two expert raters intraclass correlation coefficient\n(ICC) was obtained as ICC = 0.95 with 95% confident in-\nterval = 0.91 \u2013 0.98. ICC estimates and their 95% confident\nintervals were calculated using SPSS statistical package version\n23 (SPSS Inc, Chicago, IL) based on a mean-rating (k = 3),\nabsolute-agreement, 2-way random-effects model. The ground\ntruth rendering reliability level is excellent [29]."}, {"title": "B. Evaluation Parameters", "content": "In this study, all measurements were performed based on the\nHFs volume.\n1) Dice Similarity Coefficient (DSC): Dice is a statistical val-\nidation metric used in evaluating the performance of the repro-\nducibility of the automatic segmentation (A) and the ground\ntruth (G), expressed in percentages in this study as:\n$Dice = \\frac{2 |A_{region} \\cap G_{region}|}{|A_{region}|+|G_{region}|} \\times 100$   (29)\nWe used the volume obtained both by the automatic method\nand the ground truth.\n2) Correlation Coefficient (r): Correlation coefficient is a\nstatistical and numerical metric that measures the degree of\nlinear relationship between two variables that is defined as the\ncovariance of the variables divided by the product of their stan-\ndard deviations. In this study, the two variables are the ground\ntruth (G) volume and the automatic segmentation (A) volume is\nexpressed as:\n$Corr (r_{G,A}) = \\frac{Cov (G, A)}{\\sigma_A \\sigma_G}$   (30)\nwhere $Cov (G, A)$ is the covariance between G and A, $\\sigma_G$ and\n$\\sigma_A$ are the standard deviations of G and A respectively.\n3) Probability Value - p-Value: Probability value is the prob-\nability for a given statistical model that, when the null hypothesis\n(Ho) is true, the statistical model summary (such as the sample\nmean difference between the ground truth and the automatic\nmethod) would be the same as or of greater magnitude than the\nactual observed results. It simply tests a null hypothesis against\nan alternative hypothesis using a dataset."}, {"title": "C. Segmentation Results", "content": "Table III shows the results of the 40 retinal OCT cubes using\nthe metrics of the Section IV.B. The mean dice similarity coeffi-\ncients are 69.70% for NPDR, 70.30% for PDR, and 71.30% for\nDME. To validate this study hypothesis, we utilized the statis-\ntical hypothesis test to ascertain the volume difference between\nour results and the ground truth. We performed a t-test on the vol-\numes of HFs, with alpha = 0.05 significant level. In Table III,\nwe obtained the p-values of 0.510, 0.581, and 0.585 for NPDR,\nPDR, and DME, respectively. Here, we compared the p-values\nobtained to the significance level (alpha) to make conclusion\nabout our hypothesis. More specifically, the new hypothesis has\nno significant difference between the volumes obtained by the\nproposed method and the ground truth."}, {"title": "D. Parameter Evaluation", "content": "For each of the parameters variation, we utilized 40 SD-OCT\ncubes for every varied value of each parameter for these analy-\nses. We computed the DSC to investigate the effect of varying\neach of these parameters on the HFs segmentation accuracy us-\ning the ground truth. Fig. 22 shows the effect of varying the\nvalues of parameter m, w, T, $\\Delta$ and g. From Fig. 22(a), it is\nobserved that, the optimal values of m is 2. In Fig. 22(b), it is\nclear that both w = 1,2,3, and 4 do not produce the desired\nROI based on the DSC value obtained, even though $w \\geq 6$ pro-\nduces the same result as $w = 5$ with an additional computational\ncomplexity. The current computational times for w = 1,3,5\nand 7 are 0.41, 0.63, 0.98, 5.75 seconds to process one B-scan.\nFig. 22(c) shows that T = 0.001 produces the same result with\nthe value of T used in this study but with additional compu-\ntational time of 0.98 second difference per one B-scan, while\nother varied values of T produces lower DSC. Fig. 22(d) shows\nthat $\\Delta = 0.21$ produces an optimal DSC, while $\\Delta < 0.21$ and\n$\\Delta > 0.21$ resulted in declining value of DSC. The effect of g\nis depicted in Fig. 22(e), which shows that as the value of g\nincreases so does the DSC increases, to an optimal value of\ng = 0.21, while the DSC decreases as the value of g increases.\nIn Fig. 23, we show one result of the effect of these varied\nparameters on the generated ROI. In addition, the effect of nor-\nmalization in step 8 of Algorithm 1 is depicted in Fig. 24.\nWithout normalization, the generated ROI remains coarse and\nnon-uniform, as such; sub-regions were formed due to the non-\nuniformity between the regions. More so, $b_{const}$ value is very\ncrucial to the normalization process as shown in Fig. 24. Fig. 25\nshows the effect of g on the HFs segmentation. And Fig. 26\nshows the importance of the preprocessing step to produce the\ndesired result."}, {"title": "V. CONCLUSION", "content": "The quantitative and qualitative comparison of the 40 3D SD-\nOCT datasets from 40 patients diagnosed with DR demonstrates\nthat the proposed method is more effective for HFs quantifica-\ntion than the state-of-the-art methods and computationally ef-\nfective. Our generalization of c = 4 (i.e., four clusters) hold for\nany SD-OCT images with or without diseases, even with more\nsevere diseases than the ones described in this study. Fig. 27\nshows the ROI generated using the algorithm in SD-OCT with\ndifferent retinal diseases. We expect this algorithm to become a\npowerful tool in the segmentation and quantification of HFs."}]}