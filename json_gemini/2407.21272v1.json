{"title": "Automated Quantification of Hyperreflective Foci\nin SD-OCT With Diabetic Retinopathy", "authors": ["Idowu Paul Okuwobi", "Zexuan Ji", "Wen Fan", "Songtao Yuan", "Loza Bekalo", "Qiang Chen"], "abstract": "The presence of hyperreflective foci (HFs) is\nrelated to retinal disease progression, and the quantity has\nproven to be a prognostic factor of visual and anatomical\noutcome in various retinal diseases. However, lack of effi-\ncient quantitative tools for evaluating the HFs has deprived\nophthalmologist of assessing the volume of HFs. For this\nreason, we propose an automated quantification algorithm\nto segment and quantify HFs in spectral domain optical\ncoherence tomography (SD-OCT). The proposed algorithm\nconsists of two parallel processes namely: region of inter-\nest (ROI) generation and HFs estimation. To generate the\nROI, we use morphological reconstruction to obtain the re-\nconstructed image and histogram constructed for data dis-\ntributions and clustering. In parallel, we estimate the HFs\nby extracting the extremal regions from the connected re-\ngions obtained from a component tree. Finally, both the ROI\nand the HFs estimation process are merged to obtain the\nsegmented HFs. The proposed algorithm was tested on 40\n3D SD-OCT volumes from 40 patients diagnosed with non-\nproliferative diabetic retinopathy (NPDR), proliferative dia-\nbetic retinopathy (PDR), and diabetic macular edema (DME).\nThe average dice similarity coefficient (DSC) and correlation\ncoefficient (r) are 69.70%, 0.99 for NPDR, 70.31%, 0.99 for\nPDR, and 71.30%, 0.99 for DME, respectively. The proposed\nalgorithm can provide ophthalmologist with good HFs quan-\ntitative information, such as volume, size, and location of\nthe HFs.", "sections": [{"title": "1. INTRODUCTION", "content": "PTICAL coherence tomography (OCT) is a paramount\nimaging technique used to image numerous aspects of bi-\nological and medical tissues, such as molecular content, elastic\nparameters, structural information, change of polarization and\nblood flow [1], [2]. Diabetic retinopathy (DR) is one of the most\ncommon causes of vision loss amidst patients with diabetes, and\nalso the dominant cause of blindness among working-age adults\nall over the world [2]. All forms of DR, including diabetic mac-\nula edema (DME), and proliferative diabetic retinopathy (PDR)\nhave the potential to cause severe vision loss and blindness.\nBased on the clinical features, DR is classified into five stages\nnamely mild non-proliferative diabetic retinopathy (NPDR),\nmoderate NPDR, severe NPDR, PDR and DME [3]. NPDR\nis the first stage of DR, which is without any symptoms, and\nthe only way to identify it is by fundus photography and O\u0421\u0422-\nAngiography (OCTA), through which microaneurysms (MA)\ncan be observed. Retinal MA (microscopic blood-filled bulges\nin the artery walls) are the earliest clinical sign of diabetic\nretinopathy, which are accompanied with hyperreflective foci\n(HFs) and visible in spectral domain optical coherence tomog-\nraphy (SD-OCT) image modality as reported by several authors\n[4], [5]. Growing in the number of MA is an evidence of DR\nprogression. DR with MA has 6.2% probability to evolve into\nPDR within a year [6]. With advancement of ischemia, there\nis an increase in contingency of PDR development within one\nyear. This risk development increases from 11.3% to 54.8%\nfrom lower to advanced stage [6]. Hence, there is a need for\nOphthalmologists to efficiently construct an effective diagnos-\ntic procedure that could detect and monitor retinal diseases.\nOne of the metrics that could be used in detecting and mon-\nitoring various retinal diseases (e.g., DR) is the HFs. The pres-\nence and quantity of HFs has a potential that has been proven to\nbe a determining factor with the desired visual and anatomical\noutcomes after treatment in patients with various retinal dis-\neases [7]\u2013[9]. HFs are bright small elements and are scattered\nthrough-out the retinal layers in patients with DR, which was\nfirst reported in SD-OCT by Coscas et al. [10] as depicted in\nFig. 1. Several studies have associated the presence of HFs to\nbe pertinent to progression of disease in various retinal diseases\n[11], [12]. In addition, the existence and location of HFs have\nbeen proposed as a predictive factor of visual and anatomical\noutcome [13]. Quantification of HFs presents the leading step to\nfurther investigate the role of these lesions in pathomorphologic\ndisease dynamics. A quantitative tool for extracting HFs volume\nmay pave way for ophthalmologist in choosing better metrics\nfor treatment strategies. Such a quantitative tool is necessary for\nassessing the OCT image, in order to estimate the HFs volume.\nThis will help ophthalmologist in analyzing the stages of DR.\nManual segmentation and quantification of HFs is error-prone"}, {"title": "", "content": "and tedious. An automated method will be more suitable than\nmanual method for such quantitative tool, considering the time\nconstrain and the laborious work to be perform manually.\nRecently, some methods were proposed for the segmentation\nof HFs. Mokhtari et al. [14] proposed an automated detection\nmethod using morphological component analysis. The HFs de-\ntection method operates in two stages. The first stage involves\nextracting distinct candidate points from the retinal layers, and\nthe second stage excludes the retinal nerve fiber layer (RNFL)\nand retinal pigment epithelium (RPE) distinct candidate points\nfrom their result. Only 31 B-scans (a single 2D image within an\nOCT volume) were used in the proposed method in [14], which\nmight not be sufficient to determine the efficiency of the pro-\nposed method. Additionally, discretization of ridgelet transform\nis difficult, and it necessitates interpolation in polar coordinates\nwhich makes ideal reconstructions (inversions) a challenging\ntask. More so, ridgelet transform is not effective in distorted\nretinal layer segmentation, in which edges are curved instead\nof being straight [14]. Okuwobi et al. [15] proposed an auto-\nmated method using Grow-cut method to segment and quan-\ntify HFs in SD-OCT with DR. The proposed method obtained\nsatisfactory results with the dice coefficients comparable with\nthe groundtruth. The proposed method in [15] depends solely\non layers segmentation, which is still a challenge especially\nin eyes with diseases. Till date, there is no known layers seg-\nmentation algorithm suitable for segmenting retinal layers with\ndiseases accurately. Therefore, any algorithm that depends on\nlayers segmentation for segmenting the HFs is liable to error and\nits accuracy depends largely on the accuracy of the layers seg-\nmentation algorithm. Katona et al. [16] proposed an automatic\nmethod for quantizing HFs with deep learning. The method in\n[16] used deep neural networks (DNNs), which were trained\nusing annotated images. They utilized standard artificial neural\nnetworks with one hidden layer, followed by deep rectifier neu-\nral networks (DRNs) and several convolution neural networks\n(CNNs). The network required two types of input data. The\nfirst input is the raw pixel data, and the other input consists of\nfeature vectors. The method [16] required annotated images for\ntraining phase, which is a difficult task. The challenges faced by\nthe method in [16] are as follows: high cost of computational\ntraining phase, high cost of training dataset, and high reliability"}, {"title": "", "content": "of the training datasets. Korot et al. [17] proposed an algorithm\nfor the measure of vitreous HFs (VHRF) in optical coherence\ntomography. Each OCT scan was imported into open source\nImageJ software [18] as a raw volume file. To reduce the signal\nnoise, a median filter was applied to each B-scan. The B-scans\nwere imported into IMARIS software [19] for reconstruction\ninto 3-dimensions (3D), and cropping of the area of interest of\nvitreous and retinal, by removing the subretinal tissues from\nthe analysis. The IMARIS's proprietary quality threshold se-\nlectively identified spots based on signal intensity with respect\nto the background, while the proposed VHRF algorithm identi-\nfied and quantified VHRF. The semi-automatic method in [17]\nrequires too many software's for its operation, which depends\nlargely on the accuracy of the software used, as such it is liable\nto error, tedious, time consuming, and cost inefficient.\nAs shown in Fig. 1, segmentation of HFs is a challenge and\ncomplicated. Fig. 1(a) shows the presence of HFs in SD-OCT\nimage in patient with DR. The HFs are scattered throughout the\nretinal layers ranging from the retinal nerve fiber layer (RNFL)\nto the inner segment outer segment (IS-OS) layer. Fig. 1(b)\nshows the unidentifiable retinal layers with the presence of HFs.\nThe retinal layers are undetectable and unidentifiable, making\nthe segmentation of HFs difficult. Fig. 1(c) shows the varying\nsizes and shapes of the HFs. HFs vary in sizes and shapes, which\nmakes it difficult or rather impossible for researchers to gener-\nalize. Fig. 1(d) shows the weak and fading boundary of the HFs.\nThis characteristic of HFs makes it difficult for any algorithm\nto identify and segment. Fig. 1(e) shows the similarity between\nthe HFs and the background. In most cases, it is very difficult\nto differentiate between the HFs pixels and the background pix-\nels. These and many more are the challenges currently faced\nby researchers in segmenting and quantifying HFs in SD-OCT\nimages. For more details, see [15].\nIn this paper, we proposed an automated method to segment\nand quantify the HFs in SD-OCT images with DR. Our main\ncontributions include: (1) we modified the conventional fuzzy c-\nmean (FCM) algorithm with a new membership function filter,\nwhich yields better results and low computational complexity\nfor the SD-OCT images, (2) we proposed a noise immune FCM\nalgorithm for SD-OCT image clustering, which can simulta-\nneously preserve edges and image details using morphological\nreconstruction (MR), (3) we estimated the HFs position using a\nnew feature by computing the component tree."}, {"title": "II. DATA ACQUISITION", "content": "Forty SD-OCT cubes from 40 patients were included in this\nstudy: 10 patients were diagnosed with NPDR, 14 patients with\nPDR, and 16 patients with DME. These patients were diagnosed\nwith different levels of retinopathy severity of NPDR (mild to\nsevere), PDR (early to advanced), and DME (non-clinically to\nclinically significant). One eye of each patient was used in this\nresearch for the SD-OCT analysis. All patients underwent SD-\nOCT using Cirrus SD-OCT device (Carl Zeiss Meditec, Inc.,\nDublin, CA). The SD-OCT cube covered a 6 \u00d7 6 \u00d7 2 mm\u00b3 area\ncentered on the fovea, which corresponds to a 512 \u00d7 128 \u00d7\n1024 voxels. The 40 SD-OCT cubes from the 40 patients were"}, {"title": "III. METHOD", "content": "We applied bilateral filter (BF) to reduce the noise in the OCT\nimages. Then, the algorithm splits into two parallel processes\nnamely: ROI generation and HFs estimation. Both the ROI and\nthe HFs estimation process were then merged together to obtain\nthe segmented HFs. Fig. 2 summarizes the algorithm."}, {"title": "A. Preprocessing", "content": "We applied the BF [20], [21] and the denoised image is\nobtained as follows:\n\\(I_f (x) = \\sum_{x_i \\in \\Omega} I(x_i) f_r (||I(x_i) - I(x)||) g_s (||x_i - x ||)\\) (1)\n\\(I_f\\) is the denoised image, I is the input image, x are the co-\nordinates of the pixel to be denoised, \\( \\Omega\\)is the window centered\non x, \\(f_r\\) is the range kernel for smoothing variation in inten-\nsities, and \\(g_s\\) is the spatial kernel for smoothing variation in\ncoordinates."}, {"title": "B. Region of Interest (ROI) Generation", "content": "The denoised images were then channeled into two parallel\nprocesses; ROI generation and HFs estimation. To create the\nROI, we clustered the OCT image by labelling each pixel in\nthe image using the pixel's brightness values (BVs) and simi-\nlarities through their statistical relationships. There are numer-\nous categories of clustering algorithms: grid-based algorithms,\ndensity-based algorithms, hierarchical algorithms, partitional\nalgorithms, and model-based algorithms [22]. In our case, we\ncannot precisely make conclusion that each image pixel belongs\nto only one cluster. It may be possible that some data's prop-\nerties contribute to more than one cluster. For this purpose, we\npreferred membership value based clustering like fuzzy c-means\nclustering (FCM). We utilized the FCM clustering method. Gen-\nerally, SD-OCT images suffer from poor contrast, noise, limited"}, {"title": "", "content": "spatial resolution, and other factors. To overcome the problems\nof traditional FCM we introduced: (a) local spatial informa-\ntion using morphological reconstruction (MR) operation, which\nresult in a low computational complexity, (b) modify pixel's\nmembership by replacing it with local membership filtering that\ndepends only on the spatial neighbors of membership partition,\nand (c) utilized MR to smoothen the images to create a noise im-\nmune FCM, while preserving the image details and eliminating\nthe need for additional filters for noise elimination.\nWe applied clustering on the OCT gray level histogram, while\nwe introduced the local spatial information of the OCT image\nto the objective function of the traditional FCM algorithm. Our\nmodified objective function is given as follows:\n\\(J_m = \\sum_{l=1}^{q} \\sum_{k=1}^{C} u_{kl}^m ||\\xi_l - v_k||^2\\) (2)\nwhere \\(\\xi\\) is the image reconstructed by MR, q represents the\nnumber of the gray levels contained in \\(\\xi\\), \\(\\xi_l\\) is the gray level,\n\\(1 \\leq l \\leq q\\), \\(v_k\\) represents the prototype value of the kth cluster, c\ndenotes the number of clusters, m is the weighting exponent on\neach fuzzy membership that determines the amount of fuzziness\nof the resulting classification, \\(u_{kl}\\) denotes the fuzzy membership\nof gray value l with respect to cluster k, and\n\\(\\sum_{l=1}^{q} \\gamma_l = N\\) (3)\nwhere N is the overall number of pixels in the image, and \\(\\xi\\) can\nbe calculated as:\n\\(\\xi = MC (f)\\) (4)\nwhere MC is the morphological closing reconstruction, and f is\nthe original image. The optimization problem is converted to an\nunconstrained optimization problem using the Lagrange multi-\nplier technique; therefore, the objective function is minimized\nas:\n\\(J_m = \\sum_{l=1}^{q} \\sum_{k=1}^{C} u_{kl}^m ||\\xi_l - v_k||^2 - \\sum_{l=1}^{q} \\alpha_l (\\sum_{k=1}^{C} u_{kl} -1)\\) (5)\nwhere \\(\\alpha\\) is a Lagrange multiplier. However, we converted the\nproblem of minimizing the objective function to finding the\nsaddle point of the Lagrange function above, and taking the\nderivatives of the Lagrangian \\(\u00ce_m\\) with respect to the parameters\n\\(u_{kl}\\) and \\(v_k\\). We obtained the corresponding results as follows:\n\\(u_{kl} = \\frac{||\\xi_l - v_k||^{-2/(m-1)}}{\\sum_{i=1}^{q} ||\\xi_l - v_i||^{-2/(m-1)}}\\) (6)\n\\(v_k = \\frac{\\sum_{l=1}^{q} u_{kl}^m \\xi_l}{\\sum_{l=1}^{q} u_{kl}^m}\\) (7)\nFrom Eq. (6), a membership partition matrix \\(U_{matrix} =\n[u_{kl}]_{C \\times I}\\) is obtained. For stable \\(U_{matrix}\\), Eq. (6) and Eq. (7) are\nrepeatedly iterated until \\(max (U_{matrix}^{(t)} - U_{matrix}^{(t+1)})) <T\\), where\nT is the minimal error threshold. Since, u is a fuzzy mem-\nbership of gray value of l with respect to cluster k, therefore a"}, {"title": "", "content": "new membership partition matrix \\(U_{matrix} = [u_{kl}]_{C \\times N}\\) which is\nequal to the original image f, and can be obtained as:\n\\(u_{ki}^{(t)} = u_{kl} \\quad \\text{if } x_i = \\xi_l\\) (8)\nwhere \\(x_i\\) is the gray value of the ith pixel. For algorithm ef-\nficiency and performance purposes, we modified the \\(u_{kl}\\) using\nmedian filter as a membership filter as follows:\n\\(U_{matrix}'' = median filter \\{U_{matrix}'\\}\\) (9)\nThe ROI generation algorithm automates in eight working\nsteps, which is presented in Table I. We explain each of the\nsteps involved in the generation of the ROI in detail as fol-\nlows:\nStep 1: Four tunable input parameters are needed to set the\nalgorithm into automation. These parameters are tunable, so that\nthey can be tuned to suit any desired OCT image clustering. In\nthis research, c = 4, m = 2, w = 5, and T = 0.002. We are in-\nterested in four clusters; as such the value of c must be 4. Many\nresearchers [23] have proposed and proved that m = 2 is the op-\ntimal value for m. In our case, it is also true. After fine tuning by\ntrial-and-error, we observed that any values of w < 5 produces\nan undesired result, while for w > 5 produces almost the same\nresult as w = 5 with additionally huge computational complex-\nity. In addition, we realized that T = 0.001 and T = 0.002 are\nthe obvious choice for the termination criterion, but the latter\nrequires less computational time. These parameters effect is dis-\ncussed later in Section IV.D. As shown in Fig. 3, there are four\nmajor levels of intensity category in the OCT image used in this\nresearch. The four clusters are (a) highest intensity cluster, (b)"}, {"title": "", "content": "high-to-medium intensity cluster, (c) medium-to-low intensity\ncluster, and (d) lowest intensity cluster, as shown in Fig. 3(c).\nThese four levels of intensity were grouped into four clusters,\nsuch that the variation between the pixel's brightness values of\neach cluster could be at its minimum, and the statistical relation-\nship of each cluster is in a considerable range for fuzzification.\nThe fuzzy membership is a relevant parameter during cluster-\ning, as such, proper selection of m value is very crucial. We\nobserved that different values of m always lead to different\npartition memberships. In addition, the clusters will always be\nshaped by the selected value. More so, large m values result in\nunwanted partitions. In this study, we select value m = 2 as the\noptimal value with good results for m as shown in Fig. 3.\nStep 2: After the tunable parameters in step 1 are set, re-\nconstructed image is generated from the utilized image MR.\nHere, we introduced MR to optimize distribution characteristic\nof data before applying FCM algorithm, since MR is capable\nof preserving the object contour and remove unknown noise in\nadvance. We used MR to filter and integrate spatial informa-\ntion into FCM to achieve a better clustering, which produces\nbetter results than the mean and median filters in our case as\nillustrated in Fig. 4. We quantitatively compare the results using\nmean-to-standard deviation ratio (MSR) and contrast-to-noise\nratio (CNR) in method [24] as:\n\\(MSR = \\mu_{\\sigma} / \\sigma_f\\) (10)\n\\(CNR = \\frac{|\\mu_f - \\mu_b|}{\\sqrt{0.5 * (\\sigma_f^2 + \\sigma_b^2)}}\\) (11)\nwhere \\(\\mu_f\\) and \\(\\sigma_f\\) are the mean and the standard deviation of\nthe foreground region (red rectangular box in Fig. 4(a)), while\n\\(\\mu_b\\) and \\(\\sigma_b\\) are the mean and the standard deviation of the back-\nground region (blue rectangular box in Fig. 4(a)). The MSR and\nCNR obtained using the mean filter, median filter and the MR\nare (2.84, 1.54), (2.59, 1.36), and (3.49, 2.07) respectively. We\nobserved that application of both mean and median in denoising\nthe SD-OCT images proved inefficient in comparison with MR,\nas such mean and median filters are not efficient in denoising\nOCT images.\nIn this study, we employed morphological closing MC to\nmanipulate the original image f, since it is more suitable for\ntextural detail smoothing. Therefore, MC can be defined as\nfollows:\n\\(MC (f) = M_{\\delta} (M_M (\\epsilon (f)) (\\delta (M_M^* (\\epsilon (f))))\\) (12)"}, {"title": "", "content": "where \\(\\delta\\) is a dilation operation, \\(\\epsilon\\) is an erosion operation,\n\\(M(g)\\) represents the morphological dilation reconstruction,\nwhich is defined as:\n\\(M_i^\\delta (g) = \\delta^i_f (g)\\) (13)\nwhere g is a marker image, and g \\(\\leq\\) f and i = 1, 2, 3, . . . N.\n\\(M(g)\\) represents the morphological dilation reconstruction,\nwhich is defined as:\n\\(M_i^\\epsilon (g) = \\epsilon^i_f (g)\\) (14)\nwhere g \\(\\geq\\) f. The reconstructed image \\(\\xi\\) can be defined as:\n\\(\\xi_i = \\frac{1}{1 + \\alpha} (x_i + \\alpha \\dot{x_i})\\) (15)\nwhere \\(\\dot{x_i}\\) is a mean value of neighboring pixels lying within\nthe window around \\(x_i\\), where \\(x_i \\in f\\) and \\(\\dot{x_i} \\in MC (f)\\)from Eq.\n(12) and \\(\\alpha\\) controls the intensity of the neighboring effect. For\nmarker image, a structuring element SE is required for both \\(\\delta\\)\nand \\(\\epsilon\\). Therefore, MC is redefined as:\n\\(MC (f) = M_{\\delta} (M_M^* (SE (f)) (SSE (M_{\\epsilon} (ESE (f))))\\) (16)\nWe considered a disk with radius r as our structuring ele-\nment SE, here r = 1. If r = 0, then \\(MC (f) = f\\); else f will be\nsmoothed to different degree with respect to the change in r. As\nsuch, the effect of \\(\\alpha\\) and r are both similar, thus, we can change\n\\(\\xi\\) for \\(MC (f)\\), such that \\(\\alpha\\) can be removed. In that way, we\neliminate the issue of noise estimation, since MR is capable of\neliminating different noise both effectively and efficiently. We\nused MR to integrate spatial information into FCM algorithm\nfor better clustering, because MR is capable of optimizing data\ndistribution without considering the type of noise involved in\nthe data. In addition, we eliminate the difficulty in choosing fil-\nters for the OCT images corrupted with speckle noise. After the\nreconstructed image \\(\\xi\\) was generated, the histogram of \\(\\xi\\) was\ncomputed for data distributions. Histograms give a rough sense\nof the density of the underlying distribution of the data, and\noften for density estimation. Since the rate of convergence of\nFCM algorithm is determined by the distribution characteristics\nof data, we performed clustering on the gray level histogram of\nthe image reconstructed by MR."}, {"title": "", "content": "Step 3 to 4: The FCM algorithm initializes the membership\npartition randomly, and also calculates the centroid center. The\niteration counter is set to zero at the beginning.\nStep 5 to 6: In general, the commonly used modified objective\nfunction for the FCM algorithm is given as follows:\n\\(J_m = \\sum_{i=1}^{N} \\sum_{k=1}^{C} u_{ki}^m ||x_i - v_k||^2 + \\sum_{i=1}^{N} \\sum_{k=1}^{C} G_{ki}\\) (17)\nwhere \\(v_k\\) is the prototype value of the kth cluster, \\(u_{ki}\\) represents\nthe fuzzy membership value of the ith pixel with respect to\ncluster k. N is the total number of pixels in the image, c is\nthe number of clusters, m is a weighting exponent on each fuzzy\nmembership that determines the amount of fuzziness, and fuzzy\nfactor \\(G_{ki}\\) is used to control the influence of neighborhood pixels"}, {"title": "", "content": "on the central pixel. In [25], the fuzzy factor \\(G_{ki}\\) is defined as:\n\\(G_{ki} = \\frac{1}{|N_i|} \\sum_{r \\in N_i} (1 - \\frac{d_{ir}}{d_{ir} + 1}) (u_{kr})^m || x_r - v_k ||^2\\) (18)\nwhere x represents the neighbor of \\(x_i\\), \\(u_{kr}\\) is the neighbors of\n\\(u_{ki}\\), and \\(d_{ir}\\) is the spatial Euclidean distance between pixels \\(x_i\\)\nand \\(x_r\\).\nConsequently, if \\(G_{ki}\\) equals zero, the proposed algorithm in\n[25] will be equal to the conventional FCM algorithm. Mean-\nwhile, replacing \\(G_{ki}\\) in an easy way in which it is unnecessary to\ncalculate the distance between pixels within local spatial neigh-\nbors and the prototype value \\(v_k\\), will save the algorithm a huge\ncomputational time. Because \\(G_{ki}\\) directly decides the compu-\ntational complexity of different clustering algorithm [26]. Here,\nwe introduced membership function filter by replacing the con-\ntribution of \\(G_{ki}\\) with spatial neighborhood information of the\nmembership function partition. We utilized a membership func-\ntion filter to correct the misclassified pixels, as such; our al-\ngorithm avoids the need to compute the distance between the\nneighbors of pixels and the clustering centers. Thus, the modi-\nfied membership function partition can be defined as:\n\\(u_{ki}^{dir + 1} = u_{ki} + \\sum_{r \\in N_i} \\frac{1}{d_{ir} + 1} u_{kr}^{dir}\\) (19)\nwhere \\(d_{ir}\\) is the Euclidean distance between \\(u_{ki}\\) and \\(u_{kr}\\), and\n\\(\\ell_1\\) is the spatial structure information of the membership\nfunction partition. Here, Step 5 of Algorithm 1 uses the mod-\nfied membership function partition of Eq. (19) to update the\nmembership partition matrix instead of Eq. (6).\nStep 7: For every membership partition obtained in each of\nthe FCM iteration, a median filter with a window size 3 \u00d7 3 is\nused in modifying the membership function partition according\nto Eq. (9). The results of the median filtering are normalized with\na filtering window of the same size as the structuring element.\nStep 8\nWe performed normalization on the median filter output using\nEq. 20 as:\n\\(ROInormalize = \\frac{U_{matrix}''}{c* (\\sum U_{matrix}'' + b_{const})}\\) (20)\nhere, \\(b_{const}\\) is a floating-point relative accuracy with a fixed\nvalue of 2-52."}, {"title": "C. Hyperreflective Foci Estimation", "content": "While generating the ROI, the algorithm also performs the\nestimation of HFs in parallel, which will be discussed in this\nsection. For clarity and better understanding, we briefly give\na summary of the algorithm used in estimating the HFs in\nTable II.\n1) Pixel Sorting: The pixels of the input image I(x) was\nsorted in an increasing order, such that \\(X_1,X_2,...,X_N \\in A\\) is\nthe incremental sorting of the image pixels intensity value, i.e.,\n\\(I(x_1) \\leq I(x_2) \\leq I(X_N)\\) (21)\nhere an image I(x), x \\(\\in\\) Ais a function of a set (finite) A with\ntopology T. The elements of A are known as pixels, such thatA =\n[1,2,..., N] and T is induced by four-way neighborhoods and\nn = 2. We initiated the sorting processing using the Counting\nsort algorithm [27].\n2) Component Tree: Since our image pixels were sorted ac-\ncordingly, we applied the max-min algorithm [28] in building\nthe component tree. Fig. 7 shows the component tree and il-\nlustrates its working principle, which we will explain below.\nMore detail about the component tree can be found in [28]. Let\nconsider the image I(x) given in Fig. 7(a) associated with the\nfour-connectivity and the total ordering relationship between\nthe pixels of I(x) based on increasing gray levels. A level set\nS(x), x \\(\\in\\) A of the image I (x) is known to contain all the pixels\nwith intensity lower than I(x), i.e.,\n\\(S (x) = \\{y \\in A : I (y) \\leq I (x)\\}\\) (22)"}, {"title": "", "content": "A path (x1,...,xn) is a connected sequence of pixels, in\nwhich x1 and xi+1 are four-way neighbors for i = 1, ..., n 1.\nIn this work, we express the set of all the extremal regions of the\nimage I as R(I). The extremal regions are distinguished as the\nconnected regions within binary threshold images If (x), which\nis obtained from:\n\\(I^g (x) = \\begin{cases}\n1, & I (x) \\geq g \\\\\n0, & otherwise\n\\end{cases}\\) (23)\nwhere g \\(\\in\\) [min(I(x)) max(I(x))]. Fig. 7 shows the input im-\nage and various threshold images If (x) that are evaluated during\nthe formation of the component tree. During the creation of the\ncomponent tree, each node is assigned the corresponding gray\nvalue g at which it was identified. As such, among all the ex-\ntremal regions R(I), we are only interested in those that satisfy\nthe stability criteria \\(\\Psi\\). The equation for obtaining \\(\\Psi\\) is defined\nas:\n\\(\\Psi (R^g) = \\frac{|R^{g-\\Delta} \\Delta \\cup R^{g+\\Delta}|}{|R^g|}\\) (24)\nhere, |.| denotes the cardinality, R\u00ba presents the region that is\nobtained through thresholding at a gray value g, while A is a\nstability range parameter. Also, \\(R^{g-\\Delta}\\) and \\(R^{g+\\Delta}\\) are the ex-\ntremal regions obtained while moving upwards and downwards\nin the component tree from region R\u00ba until a region g A and\ng+ A is found. In this study, A = 0.21 and g = 2.10.\n3) Extremal Regions Extraction: Fig. 8(a) shows all de-\ntected regional maximal in the image and Fig. 8(b) shows\nthe addition of all these pixels to form the maximally con-\nnected regions. Each color in Fig. 8(b) represents different\nextremal region, which is yet to be combined together. In\nhere, we added all sets \\(T(z) \\cup T(p(z)) \\cup T(p^2 (z)) \\cup\\cup\nT(root(z)) = T(root(z))\\), where T(z) is defined as the subtree\nfixed at z, while p(z) is the parent of z and root(z) represents\nthe root of the tree that hold z. We observed that only some sets\nof S(p\" (z)) are extremal region, while S(root(z)) is invariably\nthe extremal region of the image. Since this embedded all other\nsubsets, it is adequate for us to add them together. The union\noperation is encoded in the forest. We computed the area varia-\ntion for each region, after obtaining the extremal region tree. In\naddition, we selected the maximally stable ones. We obtained the"}, {"title": "", "content": "area |R| of each region as the first and second order moments as:\n\\(\\mu(R) = \\frac{1"}, {"compute": "n\\(M (R) = \\frac{1}{|R|} x x^T\\) (26)\nand utilize the fact that \\(\\sum R = M"}]}