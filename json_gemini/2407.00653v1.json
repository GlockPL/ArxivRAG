{"title": "CHAIN-OF-KNOWLEDGE: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs", "authors": ["Yifei Zhang", "Xintao Wang", "Jiaqing Liang", "Sirui Xia", "Lida Chen", "Yanghua Xiao"], "abstract": "Large Language Models (LLMs) have exhibited impressive proficiency in various natural language processing (NLP) tasks, which involve increasingly complex reasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving new knowledge from existing one. While it has been widely studied in the context of knowledge graphs (KGs), knowledge reasoning in LLMs remains under-explored. In this paper, we introduce CHAIN-OF-KNOWLEDGE, a comprehensive framework for knowledge reasoning, including methodologies for both dataset construction and model learning. For dataset construction, we create KNOWREASON via rule mining on KGs. For model learning, we observe rule overfitting induced by naive training. Hence, we enhance CoK with a trial-and-error mechanism that simulates the human process of internal knowledge exploration. We conduct extensive experiments with KNOWREASON. Our results show the effectiveness of CoK in refining LLMs in not only knowledge reasoning, but also general reasoning benchmarkms.", "sections": [{"title": "1 Introduction", "content": "Large Language models (LLMs) have established new state-of-the-arts across a wide range of natural language processing (NLP) tasks (Brown et al., 2020; Bang et al., 2023). Increasingly, their impressiveness have expanded to complex problems challenging reasoning abilities, including arithmetic reasoning (Cobbe et al., 2021), commonsense reasoning (Talmor et al., 2018), and symbolic reasoning (Srivastava et al., 2022). These reasoning abilities enables LLMs to make informed decisions, solve complex problems, and provide more accurate and relevant responses\nKnowledge reasoning represents an indispensable aspect of reasoning, which combines acquired\nknowledge to derive novel knowledge (Chen et al., 2020), as shown in Figure 1. It shares similarities with commonsense reasoning and symbolic reasoning in its reliance on existing knowledge and logical inference to derive new conclusions. Previously, knowledge reasoning has been extensively studied within the context of knowledge graphs (KGs). KGs represent fact knowledge in the form of relational triples, e.g., (Plato, author_of, The Republic). Knowledge reasoning over KGs is to harness the existing knowledge to infer and derive novel one, typically by explicitly modeling or implicitly learning compositional rules for relational patterns (Sun et al., 2019). This enriches the KGs and supporting downstream tasks such as link prediction (Zhu et al., 2021) and fact classification (Yao et al., 2019). Existing methods for KG reasoning could be distinguished into structured-based methods such as TransE (Bordes et al., 2013) and description-based methods such as LMKE (Wang et al., 2022). However, knowledge reasoning in LLMs remains significantly underexplored, which could serve as a valuable complement to LLM reasoning.\nIn this paper, we propose to integrate this knowledge reasoning ability into LLMs, leveraging KGs. Specifically, we introduce CHAIN-OF-KNOWLEDGE (CoK), a comprehensive learning framework for knowledge reasoning. CoK includes methodologies for both dataset construction and model learning. The dataset construction is based on KGs. As illustrated in Figure 2, it includes three steps: 1) rule mining, which mines compositional rules in KGs; 2) knowledge selection, which identifies interrelated triples matching those rules; and 3) sample generation, which transforms the triples into natural language samples. For model learning, we observe that training LLMs via behavior cloning often leads to rule overfitting and consequent hallucination. Hence, we further enhances CoK with a trial-and-error mechanism, which simulates humans' internal process of knowledge exploration for improved generalizability.\nWe conduct extensive experiments to validate the effectiveness of CoK, which covers both anonymized and regular settings. In the anonymized settings, we replace entity names to ensure analysis uninfluenced by data leakage. In the regular settings, we showcase the value of CoK for not only real-word knowledge reasoning, but also other reasoning benchmarks.\nThe contributions of this paper are mainly summarized as follows:\n\u2022 We introduce the knowledge reasoning task to evaluating and enrich LLMs. Our curated dataset, named KNOWREASON, will be released to facilitate future research in this direction.\n\u2022 We propose CHAIN-OF-KNOWLEDGE (CoK), a comprehensive framework for advancing LLMs' knowledge reasoning ability. CoK provides a detailed method for dataset construction, as well as two learning methods including behavior cloning and trial-and-error."}, {"title": "2 Related Works", "content": "LLM reasoning LLMs have achieved significant success in many NLP tasks and their capabilities have been extended to complex reasoning tasks such as common-sense reasoning (Talmor et al., 2018), arithmetic reasoning (Cobbe et al., 2021), and symbolic reasoning (Srivastava et al., 2022). It has been observed that LLMs perform poorly on reasoning tasks when using standard prompts (Wei et al., 2022). To address this issue, Brown et al. proposed few-shot prompting (Brown et al., 2020), which provides the model with examples of question-answer pairs and has proven effective in reasoning tasks. To further enhance performance, Wei et al. (2022) proposed Chain-of-Thought (CoT) prompting (Wei et al., 2022), which provides the model with input-output examples that include explicit reasoning steps. Different from CoT, Program of Thoughts(PoT) uses language models to express the reasoning process as a program, and then executes the generated programs to derive the answer (Chen et al., 2022). Tree-of-Thought (ToT) extends the concept of CoT by incorporating a hierarchical structure into the reasoning process (Yao et al., 2024). This approach is particularly useful for tasks requiring complex decision-making and reasoning, where multiple pathways must be evaluated to reach the correct solution. Although ToT is effective for decision-making and path selection, it requires access to external information such as context. In contrast, our work introduces the CoK framework to enhance the knowledge reasoning abilities of LLMs by utilizing their internal knowledge base.\nKnowledge Reasoning over KGs Knowledge reasoning is the process of using known knowledge to infer new knowledge (Chen et al., 2020), which is widely used in knowledge graph completion (Zhang et al., 2020). Main approaches to knowledge graph reasoning(KGR) can be broadly classified into four main categories: embedding-based reasoning captures the implicit association"}, {"title": "3 Methodology", "content": "3.1 Preliminaries and Task Formulation\nKnowledge Graphs KGs store collections of facts as triples, denoted as G = {(e, r, e') | e, e' \u2208 E,r \u2208 R}, where E and R represent the sets of entities and relations, respectively.\nAtoms and Rules KGs contain compositional rules that can be extracted or modeled to infer new knowledge. These rules consist of multiple relational atoms., where an atom can be expressed as r(X, Y), where r is a relation and X, Y are variables for entities. A rule in the KGs can be expressed by the following formula:\n$r_h(X, Y) \\leftarrow r_1(X, Z_1) \\land ... \\land r_n(Z_{n-1},Y)$ (1)\nHere, $r_h(X, Y)$ denotes the head atom and denotes the rule head, while $r_1(X, Z_1) ... \\land r_n(Z_{n-1},Y)$ denotes the rule body.\nFor example, in the rule LiveIn(X,Y) \u2190 WorkFor(X, Z1)\u2227LocateIn(Z1y)\u2227LiveIn(X, Y) is the rule head and WorkFor(X, Z1) \u2227 LocateIn(Z1, Y) is the rule body.\nTask Formulation Given an atom $r_h(X, Y)$, where X is known and Y is unknown, we seek to determine Y. Knowledge reasoning involves identifying an appropriate rule, and then utilize the facts that support the rule body to determine the value of Y.\n3.2 Chain-of-Knowledge Data Construction\nIn this section, we will introduce the idea of our CoK method and how we construct the data.\nRule mining In this step, we begin by mining 2-hop rules and then combine them to create 3-hop and 4-hop rules.\nTo derive rules for data construction from triples in the knowledge graph, we utilize a breadth-first approach to sample 2-hop atoms combinations that connect the head entity to the tail entity. The algorithm we use is shown in Appendix A.1 These combinations serve as instances for 2-hop rules. For"}, {"title": "3.3 Chain-of-Knowledge Learning", "content": "Naive Training First, we directly train LLMs on KNOWREASON in a behavior cloning manner. However, we observe a phenomenon called rule overfitting. In this situation, the trained models tend to rely on rules encountered during training, even in the absence of supporting facts.\nTrial and Error Hence, we introduce a trial-and-error (T&E) mechanism to CoK learning, which simulates the human process of exploring over our internal knowledge.\nTo simulate the human process of knowledge reasoning, we humans initially select a plausible rule and start reasoning based on it when presented with a question. During this process, if we realize that we lack a crucial fact required by the rule, we switch to an alternative reasoning path instead of continuing without the essential information.\nHence, we integrate the concept of trial and error with our method, incorporating exploration of the LLM's internal knowledge base into the reasoning process. This approach enables LLMs to discern when to apply a rule and when to backtrace it due to a lack of supporting facts, subsequently switching to a more appropriate rule.\nWe design a symbolic agent to work in conjunction with LLMs to generate exploration path, employing a trial-and-error approach. For each sample, the symbolic agent first selects a possible rule as a candidate path and then searches for supporting facts for the rule in the internal knowledge base of LLMs. If any part of the rule body lacks supporting facts, the process is recorded as an error, and the symbolic agent switches to another rule as the candidate path. This process repeats until a reasoning path with sufficient supporting facts is found, leading to the desired result. The entire exploration process is captured as a data sample, comprising at least one error and the correct reasoning path. This trial and error process is shown in Algorithm 1."}, {"title": "4 Experiments", "content": "4.1 Settings\nDatasets We select Wikidata5m (Wang et al., 2021) as our data source, which is a million-scale knowledge graph dataset that is aligned with Wikidata, facilitating data processing and usage.\nWe construct a dataset KNOWREASON, which includes a knowledge dataset and a CoK dataset. The construction method is detailed in Section 3."}, {"title": "4.2 Results in the Anonymized Settings", "content": "We conduct experiments using each method mentioned in Section 4.1. For our CoK and CoK (T&E) methods, we construct three versions of data for each method using rules of different lengths. This approach allows us to explore the relationship between rule length and the model's knowledge reasoning ability. The results of the experiments are shown in Table 2.\nCoK Effectively Improves LLMs' Knowledge Reasoning Ability. Our results show that both CoK and CoK (T&E) consistently outperform the baselines on all test datasets. Notable, given some CoK examples, ICL-CoK generally outperforms vanilla CoT. However, it still yield relatively low scores, suggesting that LLMs without fine-tuning struggle with knowledge reasoning based on their internal knowledge, despite having key information within their parameters.\nWith Trial & Error, CoK (T&E) Further Improves Performance in OOD Settings. In CoK, the scores for ID dataset are generally higher than those for OOD dataset, demonstrating the phenomenon of rule overfitting, where LLMs rely on reasoning paths encountered during training. This rule overfitting can lead to hallucinations and a loss"}, {"title": "4.3 Results in the Regular Settings", "content": "Downstream Tasks with Regular Settings In regular settings, we train the model with regular data that utilizes real-world entities for data construction, and further test the model on downstream tasks.\nThe results of regular settings are shown in Table 5.\nThe results from the regular setting validate the conclusions drawn from the anonymized experiments: When prompted with CoK examples, ICL-CoK outperforms vanilla CoT on both ID and OOD dataset. Both CoK and CoK (T&E) enhance the LLM's Chain-of-Knowledge capabilities. Furthermore, CoK (T&E) further reduces the LLM's rule dependency, leading to improved performance on OOD dataset.\nTo further investigate the generalization of CoK,"}, {"title": "5 Conclusion", "content": "In this paper, we propose CHAIN-OF-KNOWLEDGE, a comprehensive learning framework designed to integrate knowledge reasoning abilities into LLMs, encompassing methodologies for both data construction and model learning. We construct the KNOWREASON dataset for model training. While CoK effectively enhances LLM performance on knowledge reasoning tasks, it may also lead to rule overfitting. By employing a trial-and-error approach, CoK (T&E) addresses this issue and further improves model performance. Extensive experiments on two reasoning benchmarks demonstrate the generalization of CoK to other reasoning tasks."}, {"title": "Limitations", "content": "Evaluation of the Knowledge Reasoning Ability Because knowledge reasoning in LLMs remains underexplored in previous studies and no public datasets or benchmarks are suitable for our task, the training and testing of the model's knowledge reasoning ability are conducted using the dataset KNOWREASON that we constructed. To address this concern, we strive to ensure the diversity of our dataset.\nData of the Regular Setting is Model-Specific In the regular setting, the entities in the data represent real-world knowledge. To prevent data leakage, we perform knowledge probing on each model, making the regular setting data model-specific. In contrast, for the anonymized setting, we construct data that requires knowledge injection during the continuous pretraining stage but is applicable to all models."}, {"title": "Ethics Statements", "content": "In this paper, we propose the CHAIN-OF-KNOWLEDGE framework, which includes both data construction and a model learning method to enhance the knowledge reasoning ability of LLMs. Our data construction is based on compositional rules from KGs. First, to ensure the reasonableness of our data, we filter the rules based on their confidence. However, there remains a possibility that some rules may still be unreasonable, leading to flawed samples. Second, since we utilize advanced LLMs for sample generation, it is inevitable that biases present in the LLMs may influence the knowledge. To address these ethical concerns, we will optimize the rule mining method and better align the model's output with human cognition."}, {"title": "A Details of CoK data construction", "content": "A.1 Rule minig\nIn the rule mining step, we first use a breadth-first search algorithm to find composite rule instances from raw KGs, the algorithm we use is as Algorithm 2.\nAlgorithm 2: BFS for rule instances\n1 for each triple (A, r1, B) do\n2  if B is in triplets then\n3   for each (r2, C) for the value of B do\n4    if A is in triplets then\n5     for each (r3, C') for the value of A do\n6      if C' == C then\n7       return combination\nA.2 Knowledge Selection\nIn the anonymized setting, after identifying the supporting facts for the rules, additional processing of the data is required. If the head of one instance is part of another instance's body, using this instance for sample generation and model training can lead to data leakage, resulting in an unfair evaluation. To address this issue, we separate the head and body parts within the instances. By traversing all instances, we create a set for the body facts. If an instance's head fact appears in this set, the instance is at risk of data leakage and is therefore discarded.\nA.3 Sample Generation\nKnowledge Dataset The knowledge dataset is used to inject knowledge into LLMs exclusively in anonymized settings. It is employed during the continuous pretraining stage and, as such, is presented in the form of a corpus.\nFor each entity in our knowledge base, we establish a mapping to all related facts. Using these facts, we prompt advanced LLMs to generate a descriptive paragraph, encapsulating the knowledge about the entity. The prompt we use is Prompt A.3\nPrompt 1: prompt for knowledge corpus generation\nRewrite the following sentence as a paragraph describing {{entity}}, taking care not to change the original meaning of the sentence or lose information: {{fact1}} {{fact2}} ... {{factn}}\nTo enhance the model's ability to memorize knowledge, we group related facts of each entity into sets of 10 and input them into the LLMs to generate a corpus. For each entity, we prompt the LLM to generate four different versions of the knowledge corpus. Furthermore, to improve the model's extraction of knowledge from its internal knowledge base, we integrate the corresponding CoK data into the pretraining corpus. Thus, each subset of the CoK dataset with different rule lengths has a corresponding knowledge dataset for pretraining.\nCoK dataset The CoK dataset is used for model learning in the supervise finetuning stage, and has both anonymized and regular setting. We have 3 steps to generate samples for CoK dataset:\n1) Relation Template Generation For each relation, we generate a template sentence which describes the relation of the two entites in the atom. e.g., having an atom CitizenOf(X, Y), the template is {{X is a citizen of Y }}. The prompt we use to generate the relation templates is as follows:\nPrompt 2: prompt for relation template generation\nYou will be given a triple and you should output a sentence which describes the relation between the two entities in the triple, here are some examples:\nTriple: (<ENT1>, citizen of, <ENT2>)\nOutput: <ENT1> is a citizen of <ENT2>.\nTriple: {{triple}}\nOutput:\n2)Question Template Generation For each relation in the rule head, we generate a question template for it. Considering the sufficiency and non-necessity of the rules, and to ensure that each posed question has only one correct answer, we prompt the LLMs to generate a question with possible tone and only question for the unique entity in the atom. The prompt we use to generate question template is as follows:\nPrompt 3: prompt for question template generation\nYou will be provided with a triple, and you should formulate a question that queries the relationship between the two entities. Ensure that the question you generate is in possible tone and has only one correct answer. Here are some examples:\nTriple: (<ENT1>, citizen of, <ENT2>)\nOutput: Which country may <ENT1> be a citizen of?\nTriple: {{triple}}\nOutput:\n3)Sample Generation The sample of CoK dataset"}, {"title": "B Experiment Settings", "content": "B.1 Details of Datasets\nTest Dataset of KNOWREASON The statistic of the test dataset of KNOWREASON is shown in Table 7\nBenchmarks in Downstream Tasks\n\u2022 CommonsenseQA(CSQA) (Talmor et al., 2019) CommonsenseQA is a new multiple-choice question answering dataset that requires different types of commonsense knowledge to predict the correct answers. It contains 12,102 questions with one correct answer and four distractor answers.\n\u2022 AI2 Reasoning Challenge (ARC) (Clark et al., 2018) ARC is a dataset of 7,787 genuine grade-school level, multiple-choice science questions, assembled to encourage research in advanced question-answering. The dataset is partitioned into a Challenge Set(ARC-c) and an Easy Set(ARC-e).\n\u2022 BIG-Bench Hard(BBH) (Suzgun et al., 2022) BBH is a diverse evaluation suite that focuses on tasks believed to be beyond the capabilities of current language models. It focus on a suite of 23 challenging BIG-Bench tasks for which prior language model evaluations did not outperform the average human-rater.\nB.2 Details of Methods\nVanilla CoT In vanilla CoT, we prompt the model simply with {{let's think step by step}}. The prompt we use in as follows:"}]}