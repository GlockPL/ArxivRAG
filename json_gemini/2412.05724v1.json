{"title": "A Tiered GAN Approach for Monet-Style Image Generation", "authors": ["FNU Neha", "Deepshikha Bhati", "Deepak Kumar Shukla", "Md Amiruzzaman"], "abstract": "Generative Adversarial Networks (GANs) have proven to be a powerful tool in generating artistic images, capable of mimicking the styles of renowned painters, such as Claude Monet. This paper introduces a tiered GAN model to progressively refine image quality through a multi-stage process, enhancing the generated images at each step. The model transforms random noise into detailed artistic representations, addressing common challenges such as instability in training, mode collapse, and output quality. This approach combines downsampling and convolutional techniques, enabling the generation of high-quality Monet-style artwork while optimizing computational efficiency. Experimental results demonstrate the architecture's ability to produce foundational artistic structures, though further refinements are necessary for achieving higher levels of realism and fidelity to Monet's style. Future work focuses on improving training methodologies and model complexity to bridge the gap between generated and true artistic images. Additionally, the limitations of traditional GANs in artistic generation are analyzed, and strategies to overcome these shortcomings are proposed.", "sections": [{"title": "I. INTRODUCTION", "content": "Generative Adversarial Networks (GANs) have gained sig-nificant attention in machine learning, particularly in appli-cations such as image generation, style transfer, and dataaugmentation. Introduced by Ian Goodfellow in 2014, GANsconsist of two neural networks a generator (G) and a dis-criminator (D)-engaged in a zero-sum game [1], [2]. Thegenerator (G) creates synthetic data, while the discriminatort (D) evaluates its authenticity relative to a given dataset,such as Monet paintings [3]. This adversarial process drivesboth networks to iteratively improve, enabling G to produceincreasingly indistinguishable outputs (see Figure 1). As aresult, GANs have significantly advanced the generation ofrealistic images, videos, and even text [4], [5]. In medicalimaging, GANs enhance diagnostic image resolution andgenerate synthetic data to supplement limited datasets [6].However, the complexity of deep learning models poseschallenges in understanding their decision-making processes,necessitating interpretability and visualization techniques toimprove transparency [6].\nBuilding on the success of GANs in generating realistic andartistic imagery, this work leverages their capabilities to createimages that mimic the style of Claude Monet [7]. Inspired bythe kaggle competition I'm Something of a Painter Myself[8], the proposed approach utilizes a tiered GAN model toprogressively refine image quality. Starting from random noise,the model generates images through multiple stages, witheach stage producing outputs that are increasingly detailedand stylistically accurate, as shown in Figure 2. This multi-stage process ensures that the G learns to replicate Monet'sdistinctive style, enabling the creation of high-quality artisticimages [9], [10].\nThe key contributions of this work are as follows:\n\u2022\n\u2022\n\u2022\nThe proposed tiered GAN model employs multiple GANs\nin succession to progressively enhance image quality,\ntransforming low-quality inputs into refined representa-tions of Monet's style.\nAn efficient training method is introduced, incorporating\ndownsampling and convolutional layers to enable high-quality artistic generation while optimizing computationalresources.\nAn experimental analysis of GAN limitations in artisticstyle generation is provided, highlighting the shortcom-ings of traditional GAN architectures and proposing po-tential improvements.\nThe paper is organized as follows: Section 2 presents thebackground. Section 3 describes GAN architecture. Section4 discusses the methodology. Section 5 presents the resultsand discussion. Section 6 concludes this work with futuredirections."}, {"title": "II. BACKGROUND", "content": "The field of artistic image generation has progressed sig-nificantly with the advent of GANs, which excel at creatingvisually compelling images. These models are extensively usedin tasks such as style transfer and image refinement. Thissection explores key advancements in GAN architectures, em-phasizing their evolution from domain-to-domain translationto the creation of original artistic content."}, {"title": "A. GANs for Image Generation and Style Transfer", "content": "Conditional GANs, introduced by Mirza et al., enable imagegeneration conditioned on specific input variables, such asclass labels [11]. This extension allows for controlled out-puts but faces stability challenges, particularly with noisy orunbalanced data.\nCycleGAN, developed by Zhu et al., facilitates unpairedimage-to-image translation, enabling style transfer withoutrequiring paired datasets [12]. While effective, CycleGANcan distort image content during translation, affecting fi-delity. StyleGAN, proposed by Karras et al., generates high-resolution images with adjustable styles by disentangling styleand content [13]. Despite its success, StyleGAN demandssignificant computational resources and extensive training,limiting accessibility."}, {"title": "B. Progressive GANs and Image Refinement", "content": "Progressive Growing of GANs (ProGAN), introduced byKarras et al., improves training stability by starting withlow-resolution images and progressively growing to higherresolutions [14]. This approach enhances detail in generatedimages but increases training time and resource demands asresolution grows.\nSuper Resolution GAN (SRGAN), proposed by Ledig et al.,targets image super-resolution by generating high-resolutionimages from low-resolution inputs while maintaining percep-tual quality [15]. However, SRGAN can produce artifacts,particularly in complex textures."}, {"title": "C. GAN Applications in Artistic Image Generation", "content": "Generating artistic images from scratch remains challengingdespite advances in style transfer. Neural style transfer, ex-plored by Gatys et al., applies the artistic style of one imageto another's content [16], but relies on pre-existing contentimages.\nArtGAN, introduced by Tan et al., generates creative imagesby learning complex artistic features from training data [17].It employs classification-aware loss functions to guide diverseartistic style generation but often struggles with inconsistentquality for certain styles and requires large datasets.\nCreative Adversarial Networks (CANs), proposed by El-gammal et al., extend GANs to generate novel artwork byencouraging deviation from existing styles [18]. While capableof originality, CANs can produce overly abstract outputs,requiring careful control.\nGenerating highly detailed and realistic artistic images facespersistent challenges, including instability, mode collapse, andbalancing the generator and discriminator. Techniques likeWasserstein GANs (WGAN) [19] and Spectral Normalization[20] have been applied to stabilize training and enhance imagediversity. This work incorporates these techniques to generateMonet-style images from scratch.\nThe complexity of fine art, characterized by detailed texturesand intricate color compositions, adds to the challenges forGAN-based models. To address this, the proposed tiered GANsystem uses multiple GANs in succession to progressively re-fine outputs, improving quality incrementally. Inspired by AmyJang's Monet CycleGAN tutorial [21], which demonstratesstyle transfer using unpaired datasets, this work generatesMonet-style images directly from random noise rather thantransforming existing images.\nBuilding on the concept of progressive refinement intro-duced by ProGAN [14], they proposed multi-stage GANmodel that transforms random noise into detailed Monet-style images through collaborative refinement. Unlike image-to-image translation models such as CycleGAN; this approachfocuses on generating original content from scratch.\nArchitectural choices were influenced by simpler datasets,such as Fashion MNIST [22], where GANs are effectively usedto generate basic grayscale images. This work extends theseprinciples to create detailed and stylistically accurate Monet-inspired artwork."}, {"title": "III. GENERATIVE ADVERSARIAL NETWORKS (GANs) ARCHITECTURE", "content": "GANs are a class of generative models consisting of twoneural networks, namely Generator (G) and Discriminator(D), trained simultaneously through adversarial learning. Theprimary objective of GANs is to generate synthetic datasamples that are indistinguishable from real data samples."}, {"title": "A. Generator (G)", "content": "A Generator network, denoted as G, maps a noise vector z\u2208 \u211d\u1d48 to a data sample xfake \u2208 \u211d\u207f. The input noise vector z is typically sampled from a simple prior distribution such"}, {"title": "E. Training", "content": "The training involves alternating updates to D and G.Specifically, D is updated to maximize its classification accu-racy, while G is updated to minimize D's ability to distinguishreal from fake samples. The training steps are as follows:\n1) Sample a batch of real data {x\u1d62}\u1d62=1\u1d50 from the datadistribution Pdata(x).\n2) Sample a batch of noise vectors {z\u1d62}\u1d62=1\u1d50 from the noisedistribution pz(z).\n3) Compute D loss LD and update D's parameters \u03b8Dusing backpropagation.\n4) Compute G loss LG and update G's parameters \u03b8G usingbackpropagation.\nD's objective is to maximize:\nmax_{D} E_{x~P_{data}(x)} [log D(x)] + E_{z~p_{z}(z)} [log(1 \u2013 D(G(z))], (6)\nwhile G's objective is to minimize:\nmin_{G} E_{z~p_{z}(z)} [log(1 \u2013 D(G(z)))], (7)\nor equivalently:\nmin_{G} E_{z~p_{z}(z)} [log D(G(z))]. (8)\nThis formulation leads to an equilibrium where G's distribu-tion matches the real data distribution, making it challengingfor D to distinguish between real and fake samples."}, {"title": "IV. METHODOLOGY", "content": "The software was developed using Python 3.9 and Ten-sorFlow framework version 2.16.1. The experiment was con-ducted on Google Colab with 8 cores, utilizing an NVIDIATesla V100 GPU and 32 GB of RAM. The environment wassupported by CUDA 11.8.0 and cuDNN version 8.8.0."}, {"title": "B. Data Preprocessing", "content": "A dataset of RGB images with dimensions (256, 256, 3) wasresized to (128, 128, 1) using nearest-neighbor interpolation.This resizing approach retained the recognizable features ofthe images, ensuring compatibility with our model's require-ments at the chosen resolution. The dataset used, monet_jpg,consists of 300 Monet paintings sized 256 \u00d7 256 in JPEGformat and is publicly available on kaggle [23]."}, {"title": "C. Model", "content": "The initial GAN model utilized random noise as input togenerate full-size Monet paintings, establishing a foundationfor further experimentation. Figure 3 illustrates the MonetGAN architecture, featuring both G and D, as shown in Figure4. These are sequential models incorporating convolutionaland dense layers. Leaky ReLU is employed as the activationfunction in the hidden layers, while the output layer of D usessigmoid activation for binary classification."}, {"title": "D. Input Strategy and Progressive Refinement", "content": "The implementation explored various input strategies for G,beginning with random noise as input, which proved highlychallenging. To address this, a multi-step refinement approachwas developed, where G begins with partially constructedimages and progressively enhances them.\nThis method involved creating four datasets from the orig-inal dataset. These datasets, labeled MF, M1, M2, and M3,represent progressively lower-quality grayscale images withdimensions (128, 128, 1). MF contains the full grayscale imageat half resolution, while M1, M2, and M3 are progressivelydownsampled versions with decreasing detail at each step.\nG refines the image through multiple stages, starting withrandom noise or a low-detail input:\n\u2022\n\u2022\n\u2022\n\u2022\nGAN 1: Generates images for the M3 dataset (lowestquality).\nGAN 2: Refines M3 into M2.\nGAN 3: Refines M2 into M1.\nGAN 4: Produces the final image, MF.\nThe initial version of the model used random noise as theinput, targeting the M3 dataset. A subsequent version incor-porated non-random, downsampled images as input, enablingprogressive refinement from M3 to M2, M2 to M1, and M1to MF, as shown in Figure 5."}, {"title": "E. Training the Tiered GAN System", "content": "The initial experiment aimed to generate Monet-style im-ages from random noise using an input tensor of size(128, 128, 1). This experiment was conducted over 500epochs, with a total training time of approximately 3 hours.Despite this effort, the results were unsatisfactory, as thegenerator (G) consistently produced black images. The limitednumber of training epochs, the relatively small dataset of300 Monet paintings, and insufficient training time likelycontributed to the model's poor performance, revealing theneed for a more robust training approach.\nTo address these issues, a primary tiered GAN system wasimplemented, involving the sequential training of four separateGANs. Each GAN was trained for 2000 epochs, with theduration per epoch ranging from 22 to 27 seconds. Leveragingparallel processing on an NVIDIA Tesla V100 GPU with 8CPU cores in the Google Colab environment, the model wasable to efficiently perform computations such as convolutionaloperations and backpropagation. This parallelism reduced theoverall training time, enabling the completion of 2000 epochsper GAN in approximately 12 hours, a significant improve-ment in computational efficiency. The testing phase, whichinvolved generating images, took approximately 5 minutesper GAN, yielding outputs that progressively improved witheach tier. This multi-stage strategy allowed the system torefine the generated outputs iteratively, enabling better learningfrom the dataset and overcoming the limitations of the initialexperiment.\nParallel processing also facilitated higher scalability, en-abling the system to handle more complex architecturesand experiments without substantial increases in runtime.The tiered GAN approach, by leveraging optimized trainingstrategies and sufficient resources, significantly enhanced themodel's performance and quality of results.\nTo ensure balanced training between G and D, both mod-els were designed with relatively shallow architectures. Thelearning rate for D was set at one-tenth of G's learning rate,specifically 0.0001 for G and 0.00001 for D. The Adamoptimizer was used for both models, with binary crossentropyas the loss function and a batch size of 8."}, {"title": "V. RESULTS AND DISCUSSION", "content": "During training, there were several challenges such asinitial attempts to generate images from random noise yieldedunsatisfactory results, indicating the need for extended trainingdurations and a larger dataset. Memory constraints necessitatedsmaller input sizes, prompting adjustments to the generatorarchitecture, including the use of convolutional layers foreffective downsampling.\nThe tiered GAN system, designed to progressively refineimages, initially failed to produce the desired outputs. Insteadof Monet-like paintings, the system generated tensors withconstant values of 1, highlighting the generator's inability tolearn meaningful features. This required a thorough reevalua-tion of the model's architecture and training strategy. Figures6 show the training loss for each GAN tier, with a high initialloss, particularly for the generator, which gradually decreasesas both the generator and discriminator learn to balanceeach other. Specifically, Figure 6c highlights the continuedrefinement of the model during this phase, where the generatorand discriminator show improved synchronization, reducingloss and producing more coherent outputs."}, {"title": "B. Model Re-evaluation and Alternative Approaches", "content": "Issues were identified in the initial tiered GAN models,particularly with the downsampling convolution layers inthe generator. To address these challenges, two alternativeapproaches were explored: first, using a small array of 128random values and upsampling them to the target image size,as suggested by [22]; second, replacing the input dense layerswith convolutional layers to reduce memory usage and supportlarger input sizes.\nInitial attempts with standard Conv2D layers proved inef-fective. Drawing on methods from [21] and [24], the approachwas adjusted to use deconvolution layers (Conv2DTranspose)for upsampling, along with batch normalization to improvetraining stability and reduce convergence time. Despite thesemodifications, the generated images lacked clarity and artisticresemblance to Monet's style.\nThe use of a smaller 128-element input array with upsam-pling showed better results. While clarity remained a limi-tation, the generated images exhibited recognizable patternsof light and dark areas, indicating that the model had startedlearning relevant features from the dataset.\nThe generated images were evaluated for their resemblanceto Monet's style and ability to capture artistic details. Quanti-tative metrics like training loss monitored model performance,while human evaluation ensured alignment with Monet'sunique style. This combined approach of automated metricsand human assessment identified areas for further refinement"}, {"title": "VI. CONCLUSION AND FUTURE WORK", "content": "This research introduced a tiered GAN architecture to em-ploy multiple GANs sequentially for enhancing image quality,transforming low-quality images into refined representations ofMonet's style. The training methodology efficiently handledlarge images using downsampling and convolutional layers,enabling high-quality artistic generation with limited compu-tational resources.\nExperimental results were mixed; while the system showedpotential, it struggled to fully capture Monet's intricacies. Thelimited dataset of 300 images likely constrained the model'sability to learn complex artistic features. A larger and morediverse dataset could improve the model's performance andlearning capability.\nFuture work will address these challenges through threestrategies: (1) using larger datasets, augmented with bootstrapaggregating (bagging), to enhance prediction stability androbustness [25]; (2) employing distributed computing inspiredby Firebase for efficient processing and synchronization oflarge datasets [26]; and (3) incorporating pre-trained modelsvia Transfer Learning to accelerate convergence and bettercapture Monet's artistic style.\nThese approaches aim to refine the tiered GAN system byleveraging real-time data handling and distributed computing,addressing current limitations in computational resources anddataset size."}]}