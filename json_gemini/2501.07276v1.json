{"title": "BRIDGING SMART METER GAPS: A BENCHMARK OF STATISTICAL, MACHINE LEARNING AND TIME SERIES FOUNDATION MODELS FOR DATA IMPUTATION", "authors": ["Amir Sartipi", "Joaquin Delgado Fernandez", "Sergio Potenciano Menci", "Alessio Magitteri"], "abstract": "The integrity of time series data in smart grids is often compromised by missing values due to sensor failures, transmission errors, or disruptions. Gaps in smart meter data can bias consumption analyses and hinder reliable predictions, causing technical and economic inefficiencies. As smart meter data grows in volume and complexity, conventional techniques struggle with its nonlinear and nonstationary patterns. In this context, Generative Artificial Intelligence offers promising solutions that may outperform traditional statistical methods.\nIn this paper, we evaluate two general-purpose Large Language Models and five Time Series Foundation Models for smart meter data imputation, comparing them with conventional Machine Learning and statistical models. We introduce artificial gaps (30 minutes to one day) into an anonymized public dataset to test inference capabilities. Results show that Time Series Foundation Models, with their contextual understanding and pattern recognition, could significantly enhance imputation accuracy in certain cases. However, the trade-off between computational cost and performance gains remains a critical consideration.", "sections": [{"title": "Introduction", "content": "The energy sector is experiencing a profound transformation with the rise of digital technologies [1]. Particularly the introduction of Smart Meters (SM) fosters the transition to smart grids [2]. SMs help change how energy consumption is monitored and managed by delivering on-demand, granular data on energy use (i.e., gas and electricity) [3]. Their integration unlocks new opportunities for analyzing consumption patterns, optimizing load distribution, and improving overall grid efficiency [4]. SM generate their data as time series data, which tracks energy consumption over time at a given resolution, for example, every 15 minutes. However, their integration and use in SM, especially in the power sector, face challenges, notably concerning data quality and integrity [4, 5]. Issues such as sensor failures, transmission errors, and other disruptions can cause missing values, referred to as gaps, in time series data generated by SMs [5, 6]. These gaps can severely impact data quality, which is critical for many tasks in the power system. For example, SM data supports the development of accurate predictive models for load forecasting, anomaly detection, and grid stability [6].\nTo maintain data quality and integrity in time series data from SMs requires addressing data gaps through estimation and imputation, commonly known as gap-filling. Effective gap-filling directly affects the accuracy of predictive models and decision-making processes. In the power and electricity industry, companies often face missing data challenges. Unlike research environments where data is typically well-prepared and clean, industry settings may still rely on simple, na\u00efve approaches like using the most recent available data point for imputation [7]. This practice can directly impact customers, as electricity consumption data determines the accuracy of the billing.\nThe rise of artificial intelligence (AI) has driven the development of advanced data imputation methods, leveraging the explosion of data produced by SMs. This trend opens new opportunities for Generative Artificial Intelligence (GenAI), including Large Language Models (LLMs) and Time Series Foundation Models (TSFMs), to manage time series datasets and improve tasks such as time series forecasting [8].\nIn this paper, we evaluate different LLMs and TSFMs for gap-filling in smart meter electricity consumption data. Our goal is to assess whether these models are suitable for handling missing data in this domain and to explore their potential given the accessibility of API-based tools like ChatGPT and publicly available TSFMs.\nOur evaluation includes traditional statistical methods, Machine Learning (ML) models, and cutting-edge approaches involving LLMs and TSFMs. We consider both open-source and commercial LLMs, as well as specialized TSFMS designed for time series data, assessing their performance using five metrics focused on accuracy and reliability in the gap-filling task. We apply these models to a public SM dataset recording residential electricity consumption, enabling us to compare the effectiveness of these models in real-world settings and provide insights into the most suitable techniques for various conditions.\nWe structure the remainder of this paper as follows. In Section 2, we provide a brief overview of research conducted in the domains of data imputation, time series, and TSFM. In Section 3, we describe our research approach by outlining the steps taken to conduct our experiments. Section 4 presents the results obtained, followed by a discussion in Section 5. Finally, we conclude the paper and suggest future research directions in Section 6."}, {"title": "Related Work", "content": "The task of data imputation [9] for energy consumption is a common research topic within energy systems. For instance, [10] introduced Cross-Dimensional Attention Discriminating Masked (CDADM), a modified self-attention model specifically designed for energy consumption data imputation. Similarly, [11] proposed clustering and classification-based generative adversarial imputation network (CC-GAIN), a method to estimate missing values in data sets on electricity consumption. Building on data-driven techniques, [12] proposed two imputation methods and compared them to the traditional k-nearest neighbors (KNN) approach. The first method, Historical Data Informed Regression Technique (H-DIRT), constructs a multivariate linear regression model using historical data. The second, Seasonal KNN (SKNN), extends the KNN method by incorporating seasonal trends in time series data. Their evaluation showed that both methods outperformed traditional KNN, with SKNN achieving superior performance. However, H-DIRT remains advantageous in scenarios with minimal imputation tasks due to its lower computational cost while still providing accurate results.\nMeanwhile, [13] reviewed and explored various time series tasks, including data imputation, and introduced Time Series Library (TSLib), a framework that supports imputation and provides benchmarking capabilities across multiple datasets and deep learning time series analysis. Others, such as [14], also reviewed studies on missing data and the method used to guide the selection of data imputation methods for energy benchmarking models. In a similar comparison note, [15] identified a lack of standardized benchmarking frameworks for deep learning-based forecasting algorithms, leading them to develop TSI-Bench, a tool for comparing models in the context of imputation tasks.\nResearch has also focused on benchmarking and comparing models for time series tasks. [16] evaluated traditional statistical models for data imputation on electrical load datasets by introducing artificial gaps for testing. Their results indicated that Kalman smoothing often yielded lower MAE compared to other models tested. Similarly, [17] conducted a benchmarking study on Short-term Load Forecasting (STLF) using four household electricity consumption datasets. They used SeasonalAverage as a baseline model and compared six transformer-based models, including three foundational models and three trained from scratch, alongside an LSTM with Attention architecture. Their findings revealed that foundation models can achieve high accuracy with minimal data and no additional training, highlighting new possibilities for developing more efficient and widely accessible energy forecasting solutions.\nThe development of large pre-trained models for time series data has gained significant attention, aiming to improve tasks like forecasting and imputation; however, [18] also noted that LLMs offer limited performance gains in time series forecasting compared to other methods. TimeGPT builds on this evolving landscape by addressing scalability and complexity through a Transformer-based architecture trained on the largest publicly available time series dataset,"}, {"title": "Research approach", "content": "To benchmark the performance of various models\u2014spanning statistical, ML, and LLMs within the energy sector, we followed this research process. First, we selected a dataset and prepared the data for analysis. Next, we trained ML models and performed inference using the selected TSFM. Finally, we evaluated their performance using a set of standard error metrics to ensure a comprehensive comparison."}, {"title": "Data Preparation", "content": "We used a publicly available dataset containing household energy consumption data from London, which was collected through smart meters in 2013 [24]. It includes energy consumption measurements (kWh) recorded at half-hour intervals over a year for 5567 residential consumers.\nSince the dataset is publicly accessible, available LLMs might have used it during their training. To address this potential concern, we applied an anonymization technique following [25]. The anonymization ensured that any model evaluations would reflect genuine predictive performance, rather than potential recall of previously seen data.\nAfter anonymization, we randomly selected 10 smart meters from the dataset. For each meter, we created 10 random gaps using a uniform random distribution. The gap sizes varied, with a maximum size of up to 48 entries, corresponding to a full day of missing data.  The overall dataset spans a one-year period."}, {"title": "Experiments", "content": "After preparing the data, we selected a range of models across academic and industrial literature for benchmarking. To serve as baseline systems, we included four basic models: Simple Linear Predictor (SLP), Padded Last, Last Week, and Linear Interpolation. These models were chosen because they represent some of the earliest and simplest approaches used for time series forecasting.\nFor statistical and ML models, we focused on widely-used methods in state-of-the-art research. We selected five statistical models: Autoregressive Integrated Moving Average (ARIMA), Holt-Winters, Kalman Smoothing, Seasonal Naive, and Multiple Seasonal Trend (MSTL). Additionally, we included four ML models: XGBoost (XGB), Random Forest, LightGBM (LGBM), and KNN.\nIn the category of LLMs, we included two general-purpose language models: GPT-40 (commercial, closed-source) and Llama 3.1 405B (open-source). Additionally, we incorporated five top-performing TSFMs specifically pre-trained for time series data. Among these, four are publicly available: TimesFM from Google, Moirai-1.1-R-large, Time-MoE, and Chronos-T5 (Large) from Amazon. We also evaluated TimeGPT, a commercial, closed-source model specifically trained on time series data.\nWe leveraged a diverse selection of models from different categories, enabling a well-rounded comparison and evaluation of their performance in the data imputation task by transforming the problem into a forecasting challenge. Our approach involved three key steps: Forward Prediction (FP), Backward Prediction (BP), and finally Interpolation (I).\n1. FP (Forward Prediction): We selected historical data from the left-hand side of a gap in the time series. The length of this historical data was seven days before the gap. Using this historical data, we forecasted values over a horizon equal to the length of the gap, which is referred to as the FP.\n2. BP (Backward Prediction): Similarly, we used historical data from the right-hand side of the gap to generate forecasts over the same horizon length, known as the BP.\n3. I (Interpolation): Once we obtained both forward and backward predictions, we interpolated between these predictions to generate the final imputed values. The interpolation was performed using the following formula:\n$I[i] = \\frac{(BP[i]_R \\cdot i) + (FP[i] \\cdot (L - 1 - i))}{L-1}$ (1)\nwhere:\n\u2022 i is the index within the gap length L.\n\u2022 BP[i]R is the i-th value of the BP (reverted to align with the gap).\n\u2022 FP[i] is the i-th value of the FP.\n\u2022 L is the total length of the gap.\nEquation 1 calculates a weighted average of the forward and backward predictions, with weights decreasing linearly from the FP to the BP as i increases. This results in a smooth transition between the predictions, effectively filling the gap with an interpolated value that balances information from both sides of the gap.\nWe employed the Nixtla stack [39, 40] and scikit-learn [41] to train the statistical and ML models. For the LLM models, we utilized APIs from ThebAI [42] and Nixtla [38], specifically accessing GPT-4 and Llama 3.1 through ThebAI, and the TimeGPT model via Nixtla. The remaining time series forecasting models were executed on an Apple M3 Pro with 18 GB of memory. The cost for using API-based models amounted to approximately 100 Euros for ThebAI services and around 200 Euros for TimeGPT at the time of writing this manuscript."}, {"title": "Evaluation", "content": "We evaluated model performance using five standard error metrics: Mean Absolute Error (MAE), Mean Squared Error (MSE), Symmetric Mean Absolute Percentage Error (SMAPE), Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE). To account for model variability, each metric was computed based on the average of five runs. The error values were first averaged per household and then aggregated across all households. Additionally, we calculated the Standard Deviation (SD) for each metric to provide further insights into model stability and consistency."}, {"title": "Results", "content": "summarizes the performance of the selected models using five evaluation metrics: MAE, MAPE, MSE, RMSE, and SMAPE. Each cell contains two values: the primary value representing the error metric and a secondary value, presented in parentheses, indicating the corresponding SD. The models are categorized into four groups for comparison: Baseline, Statistical, ML, and LLMs.\nIn this study, we used Baseline models as reference methods to establish a fundamental level of data imputation performance for the household electricity consumption dataset. These models rely on simple assumptions and easily accessible data, providing a straightforward benchmark for comparison against more sophisticated techniques.\nAmong these models, the SLP employs a basic extrapolation approach, predicting missing values based solely on preceding data points. This simplicity, however, led to the weakest performance, as SLP struggled to capture the complex patterns inherent in the dataset. In contrast, the Linear Interpolation method proved to be the most effective within the baseline category. By estimating missing values using surrounding data points, it consistently demonstrated lower errors and higher accuracy across all evaluation metrics. While these baseline models are inherently limited, they emphasize the challenge posed by data gaps and underscore the necessity of more advanced imputation methods.\nThe Statistical models analyzed in this study utilize established mathematical and probabilistic techniques to address time-series imputation. Among these methods, Holt Winters demonstrated strong performance, consistently achieving lower error rates across all metrics, making it the most effective statistical model in this category. Its ability to capture both seasonality and trends enabled it to adapt well to the complex patterns within the dataset. Conversely, ARIMA showed the weakest performance in this category, ranking lowest across three of the five evaluation metrics. Kalman Smoothing also faced notable challenges, underperming in two of the five metrics."}, {"title": "Discussion", "content": "The evaluation of ML models, including Random Forest, LGBM, KNN, and XGB, revealed differences in their performance. Random Forest emerged as the strongest model, achieving consistently lower error rates across all metrics. In contrast, XGB recorded the highest error rates, marking it as the weakest performer within this group.\nThe evaluation of LLMs revealed a diverse range of performance levels across the metrics. Time-MoE emerged as the top performer overall, achieving the lowest error rates across most metrics, with the exception of MAPE, where Chronos-T5 (Large) demonstrated superior results.\nIn contrast, Llama 3.1 405B had the weakest performance, recording the highest error rates for four out of five metrics. GPT-40 also displayed relatively poorer results in terms of RMSE. This behavior from Llama and GPT models aligns with expectations, as they are general-purpose models not specifically optimized for time-series tasks.\nPre-trained time series forecasting models typically contain a significantly higher number of parameters compared to traditional machine learning models, resulting in a greater demand for computational power. However, their extensive training across large datasets allows them to perform forecasting tasks even in scenarios where limited data is available. In this study, we evaluated these models' inference performance without fine-tuning on the target data. Our results indicate that, despite the lack of customization, these models often outperform machine learning models trained directly on similar data distributions.\nAdditionally, the training of traditional machine learning models often requires expertise to select features, optimize parameters, and tune hyperparameters. In contrast, pre-trained models, having been optimized on vast datasets, offer a more accessible and user-friendly solution for many applications, reducing the need for extensive domain expertise. This makes them a compelling choice for scenarios where ease of use, generalization, and scalability are prioritized.\nThe results reveal a clear relationship between lower error rates and smaller standard deviations, suggesting that models with superior predictive accuracy are also more stable and reliable. Notably, Time-MoE stands out by achieving the lowest MAE while maintaining relatively low variability, indicating consistent performance across different data samples.\nThe comparison across categories further underscores that statistical and ML models, such as Holt-Winters and Random Forest, offer competitive results with moderate levels of variability. This suggests their effectiveness in capturing underlying trends and seasonality within time series data, even if they exhibit a slightly higher SD compared to more advanced models."}, {"title": "Conclusions and future work", "content": "In this study, we evaluated the performance of traditional statistical methods, ML models, LLMs, and TSFMs for time-series data imputation, using the publicly available London smart meter household dataset. Our findings show that traditional statistical methods, such as Holt-Winters, and ML models, such as Random Forest, performed well in capturing predictable trends, seasonal patterns, and addressing smart meter data gaps. These approaches demonstrated consistent and reliable results, emphasizing their viability for such tasks.\nHowever, TSFMs, particularly TimeMoE, outperformed all other approaches, demonstrating exceptional capabilities in handling data imputation even without specific training on the dataset relying solely on inference. This suggests that TSFMs bring unique advantages for filling data gaps, especially as smart grid data scales in complexity. As TSFMs continue to evolve, they present new opportunities for enhancing predictive accuracy and data management in smart grids. Ultimately, the choice of approach should consider the specific requirements of the imputation task and available computational resources.\nFuture research should focus on fine-tuning open-source pre-trained time series models to optimize their performance for electricity consumption data. Additionally, experiments should be conducted with scenarios involving data gaps longer than one day to better identify models that perform well on extended gaps compared to those excelling with shorter gaps. Another valuable direction is to vary the length of historical data inputs to assess the effectiveness of inference-based predictions and to examine how fine-tuning strategies influence model adaptability. Collectively, these efforts will help identify optimal solutions for data imputation in smart grids, enhancing both predictive accuracy and reliability."}]}