{"title": "MULTIMODAL BANKING DATASET: UNDERSTANDING CLIENT NEEDS THROUGH EVENT SEQUENCES", "authors": ["Mollaev Dzhambulat", "Alexander Kostin", "Postnova Maria", "Ivan Karpukhin", "Ivan Kireev", "Gleb Gusev", "Andrey Savchenko"], "abstract": "Financial organizations collect a huge amount of data about clients that typically has a temporal (sequential) structure and is collected from various sources (modalities). Due to privacy issues, there are no large-scale open-source multimodal datasets of event sequences, which significantly limits the research in this area. In this paper, we present the industrial-scale publicly available multimodal banking dataset, MBD, that contains more than 1.5M corporate clients with several modalities: 950M bank transactions, 1B geo position events, 5M embeddings of dialogues with technical support and monthly aggregated purchases of four bank's products. All entries are properly anonymized from real proprietary bank data. Using this dataset, we introduce a novel benchmark with two business tasks: campaigning (purchase prediction in the next month) and matching of clients. We provide numerical results that demonstrate the superiority of our multi-modal baselines over single-modal techniques for each task. As a result, the proposed dataset can open new perspectives and facilitate the future development of practically important large-scale multimodal algorithms for event sequences.", "sections": [{"title": "1 Introduction", "content": "The ever-growing digital footprint of consumers has led to an explosion of data collected by businesses across all industries. Financial institutions, in particular, gather a vast amount of information about their clients over time, encompassing various aspects of their financial activities. This data, spanning extended periods, is typically annotated with temporal information, forming what is known as event sequences [8, 14, 23, 37]. Description of an event usually contains several heterogeneous fields, numerical and categorical, and processing of event sequence is a separate problem in machine learning different from techniques applied to time series or texts.\nAn important property of event sequences is that these data are often gathered from multiple sources or channels, rendering multimodal. The comprehensive analysis of such data in a joint way is critical for informed decision-making processes within enterprises. The scarcity of publicly available datasets in this domain hampers research and development efforts. Indeed, the significant progress in multimodal data for natural language processing, computer vision, audio, etc., is due to the appearance of large-scale datasets, such as LAION, DataComp, etc. [16]. Unfortunately, though several datasets of event sequences are used in research, e.g., credit card transactions [30] or MIMIC [21], they are either small or contain only one modality. Thus, a gap exists in methodologies designed to tackle the complexity of multimodal event sequence data."}, {"title": "2 Dataset", "content": "Modern innovative banking institutions actively develop AI technologies for customizing their human-oriented technolo-gies and making everyday decisions. A superior level of technologies will lead to new cases of customers' experience, which should form a competitive advantage of services provided, including the speed, accuracy, and price of customer services, including personal credit conditions, individual finance strategy, etc.\nOne of the main benefits of using AI is the ability to analyze large amounts of customer data. This helps banks better understand their customers' needs and offer them the most suitable products and services. Additionally, AI can protect customers from fraud and prevent financial losses. More accurate forecasting of financial risks associated with lending or investing allows us to provide more favorable conditions to more reliable clients.\nThis strategy is more effective if there is a lot of data, so banks strive to accumulate as much information as possible.\nBeing a team of a bank that stores petabytes of data about bank processes and clients, we understand the urgent needs of fintech data scientists in large sets of publicly available temporal data from various sources (bank transactions, client locations, purchased products, etc.) to drive innovation and scientific discovery. Unfortunately, the number of appropriate datasets is limited because providing such data comes with certain risks. Typically, banks are wary of sharing their data due to potential leaks of confidential information or violations of data protection regulations. In addition, the data is considered to have commercial value, and companies do not want to disclose it. To mitigate these risks, it is required to take all necessary steps to ensure data security and remove any identifying information. This allows information to be shared without violating client confidentiality, but this procedure requires significant effort from engineers, managers, and lawyers. Though there exist a small number of properly anonymized banking datasets, such as credit card transactions [30] or AlphaBattle [2], to the best of our knowledge, there are no publicly available large multimodal temporal datasets for banks.\nThus, in this paper, we introduced the first large-scale multimodal banking dataset to support future research on multimodal techniques for event sequences. In particular, we selected several practically important tasks, such as campaigning, i.e., prediction if a client would purchase some of four rather popular products in the next month. Each client is described by sequences of typical bank data: transactions, geo positions where the customer used the bank application, and dialogues with technical support. These data sources ideally highlight the main difficulties in developing multimodal models, namely, asynchronous events in different modalities, various intensities of events, rare/irregular events, and even the absence of some modalities for many clients. Based on our dataset, the researchers will be able to fully take into account cross-modal connections of sequences from multiple sources at the level of individual events.\nThe dataset was collected using the following procedure. At first, we selected a complete sample of clients for two year (2021, 2022) to be able to cover all seasons. Among all customers who had the opportunity to purchase at least one of four products during 2022, we randomly selected 2,186,230 clients, among which 1M customers are labeled by monthly aggregated purchases of each of four products in each month. For these clients, we collected 947,899,612 bank transactions, 1,117,213,760 geo position events, and 5,080,781 dialogues with technical support. Our data raise typical practical challenges for training multimodal models. For example, many clients do not have all three modalities simultaneously because they can never make a transaction, call tech support, or leave their geo trace while running the bank application. Next, all the data were properly anonymized to guarantee the confidentiality and privacy of customer"}, {"title": "2.1 Modalities", "content": "1. Bank transactional data are financial operations (events) carried out between different clients. The sequence of transactions can uniquely characterize the client [8], so this modality plays one of the most important roles in financial planning and recommendations. Thus, the main component of our MBD dataset is each client's transactional history, represented by an event with a timestamp and various attributes of the anonymized counterparty. Clients have 638 transactions on average. \n2. Dialogues. The dialogue data are transcriptions of customer calls to technical support and negotiations between the client and its manager. It is an extremely important source of information about client needs and problems [11]. The audio utterance is fed into a commercial Speech-to-Text algorithm. Personal information, e.g., the client's name, is detected in the text and masked. To further anonymize the dialogue, we feed its text into a pre-trained NLP model\u00b9 and save the resulting embeddings of size 768 in dialogue modality. An example of dialogue data is presented in Fig. 3 in Appendix A. Only 46% of customers contact support and have records of conversations, 98% of them have no more than 10 dialogues per year.\n3. Geostream data contains a sequence of geo-coordinates of a client. To anonymize this modality, the coordinates are encoded using geohashes\u00b2, a geocoding system that converts a geographic location into a short string. Each unique geohash corresponds to a region on the Earth's surface. It is possible to adjust the accuracy and size by removing characters from the end of the code. In our dataset, the coordinates were encoded with a precision of 4, 5, and 6 characters, representing cells of different sizes on the map. In our dataset, there are 43,999 distinct values of geohash_4, 347,698 numbers of geohash_5, and 2,264,404 most precise locations (geohash_6)."}, {"title": "2.2 Data anonymization", "content": "Our dataset contains no personal or confidential information whatsoever. Nevertheless, the event sequences are detailed enough that it could be possible to compare individuals from the publicly accessible portion of the dataset with the original proprietary data. To mitigate this risk, noise has been introduced to the data, ensuring that such comparisons and identification are impossible. The noise patterns were selected by our bank's internal security department. These patterns are applied locally, preserving the overall structure of the data. The specific parameters of the noise are not disclosed to prevent potential attacks on the dataset.\nAll ID fields were hashed with a random salt. All categorical field values was mapped to enumerated indexes. Random noise was added to numerical fields. The noise was added to date fields with preserving hour of original date, which may be the cause the shuffle of local sequence. The dialogue embedding space was divided into regions, which were then shuffled."}, {"title": "3 Benchmark", "content": "In this paper, we formulate two practically important tasks using our new dataset: campaigning and client matching. This section contains details about baseline methods and testing protocols."}, {"title": "3.1 Methods", "content": "To establish performance baselines, we implement several widely-adopted architectures. Our approach prioritizes unsupervised and semi-supervised methods [10], enabling the training of a general-purpose encoder on unlabeled sequential data. Additionally, we incorporate supervised methods that allow for the immediate training of the encoder in a fully supervised manner.\nThe following techniques are implemented in our benchmark to extract features for Transactions and Geostream modalities:\n1. Aggregation Baseline that contains hand-crafted aggregation statistics [8]: 3,000 and 4 features in total for sequences of transactions and geodata, respectively.\n2. COLES (Contrastive Learning for Event Sequences), a self-supervised contrastive model [8] specially devel-oped to obtain representations of such event sequences as bank transactions. The sequence encoder is a GRU (Gated Recurrent Unit) with a hidden size 256.\n3. Two Tabular Transformers from IBM [30]. The first model, TabBERT, adapts BERT to event sequences such as bank transactions. The second model, TabGPT, was initially proposed to generate synthetic tabular sequences. Both models extract 256-dimensional embeddings of an input event sequence. After, we pool output embeddings of the client in result embedding of size 1024, calculating min, max, mean, and std.\nTo obtain representation of a sequence of dialogues, we implemented several straightforward techniques to aggregate the sequence of embeddings of each dialog of a client: 1) mean pooling of all embeddings; and 2) use only the most recent embedding for the date of interest.\nTo demonstrate the potential of multimodal processing of event sequences, we implemented traditional fusion techniques, namely, 1) blending, i.e., a weighted sum of scores (estimates of class posterior probabilities) from single-modal classifier, and 2) late fusion, i.e., learning a classifier for concatenated embeddings from all modalities [20]\nFor supervised methods, we use the following architectures: for unimodal data, we utilize an GRU encoder, while for multimodal data, we employ different GRU encoders for each modality and embeddings from all encoders are"}, {"title": "3.2 Tasks", "content": "The resulting neural network is trained using binary cross-entropy (BCE) loss in multilabel setting. For the GRU encoders we used hidden size 32."}, {"title": "3.2.1 Campaigning task", "content": "In this task, it is required to predict the customer's propensity to purchase four different products in the next month (Fig. 1) given sequences of transactions, geo locations, and dialogues from the beginning of this month. Solutions to this problem are used to plan marketing campaigns and prepare sales communications through various communication channels with the client.\nWe implement an out-of-fold validation protocol to conduct our experiments. The entire client dataset is divided into five folds: four folds are used for training, while the remaining fold is designated for testing. Both the training and testing sets are made publicly available alongside our dataset to enable future researchers to compare performance metrics.\nThe baseline methods outlined earlier are applied as follows. First, we train our models using the training set. Considering the temporal structure of our target, we compute the embedding of each client's history up to one month, focusing on the presence of the target product (Fig. 1). We then evaluate the model using the multi-label classification metric ROC AUC across the 12 months of 2022 and for four binary product labels."}, {"title": "3.2.2 Multimodal Matching", "content": "Multimodal matching [41] involves aligning and comparing different modalities to identify meaningful relationships or connections between them. Frequently, data from multiple sources for the same client are matched using predefined rules or heuristics, which may not always yield optimal results. To enhance the accuracy of this process, specialized identification algorithms are required to more precisely compare different modalities.\nFor the matching task, we employed a framework analogous to CLIP [31]. We utilized GRU encoders to embed pairs of samples from two input modalities, labeling them as either positive matches (i.e., data from the same client) or negative matches (i.e., data from different clients). The model was trained using the InfoNCE loss function [13], which maximizes similarity for positive pairs while minimizing it for negative pairs. To assess the model's performance, we used Recall@1, Recall@50 and Recall@100 metrics."}, {"title": "4 Experiments", "content": "Our models, experiments, and training procedures were implemented in Python, leveraging PyTorch and PyTorch Lightning for deep learning tasks, and PySpark for distributed data processing. We trained the neural networks using NVIDIA V100 GPU, while the boosting models were trained on computational clusters equipped with 600 cores. The reported experiments, including extensive hyperparameters optimization, required approximately 500 hours of computation time."}, {"title": "4.1 Model and training hyperparameters", "content": "We employed the unsupervised baseline methods (CoLES, TabGPT, TabBERT, Aggregation) with default hyperparame-ters from the pytorch-lifestream framework. The PyTorch implementation of the Adam optimizer was utilized, with an initial learning rate of 0.001, coupled with the StepLR scheduler. Models were saved based on the lowest validation loss or the highest validation unsupervised metrics [33], evaluated after each training epoch, with training of 15 epochs.\nWe employed 24-dimensional embeddings for categorical features and clipped the number of categories for features with many unique values. We applied either an identical mapping or a logarithmic transformation for numerical features. We used the gradient boosting algorithm available in PySpark ML for downstream tasks."}, {"title": "4.2 Campaigning task", "content": "In this Subsection, we provide experimental results for the campaigning task in unimodal and multimodal baselines.\nOne of the main objectives of our paper is to provide a real data benchmark to facilitate the development of multimodal algorithms. To achieve this, we must demonstrate that an algorithm outperforming another on our public benchmark will similarly outperform it on real data."}, {"title": "4.3 Multimodal matching task", "content": "In this subsection, we present the results of our proposed multimodal matching benchmark, summarized in Table 3, which includes both transactions and dialogues. Detailed results for other modalities can be found in Appendix B, in Table 9. In this evaluation, we report recall@1, recall@50, and recall@100 for each modality, measured in both directions. For example, in the case of the transaction and geostream pair, we compute both Trx2Geo and Geo2Trx, allowing for an evaluation of alignment from both perspectives.\nOur analysis reveals considerable variation in performance across different modality pairs. Specifically, dialogue data consistently exhibits weaker matching performance compared to other modalities, such as transactions and geostream, which demonstrate significantly stronger alignment. This disparity suggests potential limitations within the dialogue modality, indicating that it may offer less complementary or aligned information. Alternatively, the unique structure of dialogue data may necessitate more sophisticated or specialized techniques for effective integration with other modalities.\nThese findings provide important insights for the advancement of multimodal matching methods, underscoring the need for further refinement."}, {"title": "5 Related Work", "content": ""}, {"title": "5.1 Financial data", "content": "The multitude of services and processes in banks generates a variety of data that can be considered as modalities. Early works such as [29, 26] use feature processing techniques that remove multimodal complexity and present data in tabular form. The Amex dataset[3] improves information content and complexity. Here, a wide range of different financial aggregates are presented as a sequence of historical slices. The development of deep learning methods has led to the ability to work with complexly structured data, such as sequences of events. Quite a few datasets [1, 5, 2], mostly monomodal, presented mainly at ML competitions. To work with such data, both supervised[7, 9, 36] and unsupervised methods[30, 8, 32] are used. Multimodal financial sequential data proposed in DataFusion2022 [4]. There are two sequential modalities, transaction and web clickstream, and two downstream tasks: matching and education level prediction. However, this is an extremely small dataset of 17K clients, and no accurate baseline model is available."}, {"title": "5.2 Other event sequence domains", "content": "Temporal point process[28, 40] model streams of discrete events in continuous time by constructing a neurally multivari-ate point process. The authors use a large collection of datasets from different types of modalities: Media (Retweets[39], MemeTrack[24], Amazon[6], IPTV[25]), Medical (MIMIC-II[22]), Social(Stack Overflow[24], Linkedin[38]) and Financial (Transaction[15]) data. All datasets are independent, and each one is single-modal. EventStreamGPT [27] uses multimodal medical record datasets, MIMIC-IV[21]. The authors propose a GPT-like approach for continuous-time event sequences. The structure of this dataset is close to the MDB. But it must be emphasized that financial data, unlike medical data, contains longer chains of events, more regular patterns, and individual transactions are less informative. These features may influence the quality of the methods used."}, {"title": "5.3 Geostream and dialogues", "content": "Geodata is used for various tasks. One of the uses of geo is a visualization of analytics on a map [17]. However, geo is used here not as a separate modality but as additional tags to the mainstream of tweets. Mobile marketers[12] use geo-targeting for pricing and send personalized recommendations. In [35] geo hashes are used for user mobility detection and prediction.\nWe encode our dialogue entries via a pretrained NLP Model. Previously, such models have already been used[18] for text anonymization tasks. Embeddings preserve the meaning of the text, which was shown in[34]. Pre-trained text embeddings can capture text sentiment and improve text-to-speech models[19]."}, {"title": "6 Limitations", "content": "The study used data from only one company, which may limit the generalizability of the results to other organizations. In addition, the data was subject to de-identification, which limits the possibility of using models trained on this dataset outside of it. Also, the data analysis results can not be generalized. In other words, based on this dataset, it is impossible to draw conclusions regarding specific regions and market characteristics or perform deep text analytics. However, within the dataset, the data is consistent, which allows us to draw correct conclusions about the performance of multimodal or unimodal methods for working with sequences. It is also worth noting that the study was conducted on a sample of clients of a certain segment who had the opportunity to purchase certain products and does not cover all possible groups of consumers."}, {"title": "7 Ethics and Societal Implications", "content": "Our dataset is designed to facilitate the development of algorithms for analyzing complex event data, with the goal of enhancing the accuracy and efficiency of predictive models. Our event data does not contain characteristics such as gender, age, or race, which can be used to discriminate against certain groups of people. This makes the models trained on our dataset more ethical. However, it is important to note that companies must comply with legal grounds and obtain customer consent before collecting and analyzing additional data. It is also worth mentioning the need to ensure the security of data storage and transmission to prevent leakage of confidential information. Failure to comply with these conditions may result in privacy violations."}, {"title": "8 Conclusion and future work", "content": "In this paper, we introduced the first large-scale publicly available multimodal banking dataset, MBD\u00b3, which contains anonymized sequential data (bank transactions, geo position, and technical support dialogues) for 1M bank clients. It can be used to create industrial multimodal models for event sequences to predict client needs. Using this dataset, we present the novel benchmark based on MBD with two practically important tasks: campaigning (purchase prediction for the next month) and matching different modalities of clients. Our experimental results demonstrate that even a simple fusion of multiple data sources improves the overall quality compared to single-modal baselines (Table 2). Also, we show that anonymization does not significantly impact the algorithms' performance, so our dataset is appropriate for choosing the best model that can be implemented in production scenarios. As a result, our work opens new horizons for developing practically relevant large-scale multimodal algorithms for event sequences.\nIn the future, expanding the range of tasks with our dataset is possible. For example, it is possible to estimate the multimodal techniques of the next-event prediction. Moreover, or baseline methods are based on late fusion, so it is very important to study more sophisticated models that consider possible mutual influence between modalities."}]}