{"title": "DrLLM: Prompt-Enhanced Distributed Denial-of-Service Resistance Method with Large Language Models", "authors": ["Zhenyu Yin", "Shang Liu", "Guangyuan Xu"], "abstract": "The increasing number of Distributed Denial of Service (DDoS) attacks poses a major threat to the Internet, highlighting the importance of DDoS mitigation. Most existing approaches require complex training methods to learn data features, which increases the complexity and generality of the application. In this paper, we propose DrLLM, which aims to mine anomalous traffic information in zero-shot scenarios through Large Language Models (LLMs). To bridge the gap between DrLLM and existing approaches, we embed the global and local information of the traffic data into the reasoning paradigm and design three modules, namely Knowledge Embedding, Token Embedding, and Progressive Role Reasoning, for data representation and reasoning. In addition we explore the generalization of prompt engineering in the cybersecurity domain to improve the classification capability of DrLLM. Our ablation experiments demonstrate the applicability of DrLLM in zero-shot scenarios and further demonstrate the potential of LLMs in the network domains. DrLLM implementation code has been open-sourced at https://github.com/liuup/DrLLM.", "sections": [{"title": "I. INTRODUCTION", "content": "The Distributed Deniel-of-Service (DDoS) threats in cyber space are becoming increasingly sophisticated and complex, posing a threat to critical Internet devices and systems including routers, switches or firwalls. Today, the scale of the Internet and the Internet of Things (IoT) is much larger than before, and the demand for network security measures is also increasing [1]. Although the Instrusion Detection System (IDS) countermeasures against DDoS are developing rapidly, network attack events are still increasing. Imperva released their report [2], claiming the DNS attacks increased in number by 215% when comparing H1 2024 with the same period in 2023 and the total number of recorded DDoS attacks surged 111% compared to the previous year.\nOver the past few years, we have witnessed Large Language Models (LLMs), such as ChatGPT [3], Llama [4], Deepseek [5] and the other models [6], [7] have make siginificant influence in artificial intelligence (AI), these LLMs include leading and fancy model architecture, and were trained from mega-billion tokens which compressed with domain knowledge. As generative models, it can not only generate a variety of creative responses to meet user needs, but it is also easy to use and only requires a simple prompt to drive it [8]. The fantastic capability has been proved on neural language processing (NLP), multimodality fusion and other fields [9] [10], which even laying the foundation stone for Artifical General Intelligence (AGI).\nInspired by the success of LLMs in many fields, especially textual information mining. In this paper, we introduce DDOS Resistance Large Language Model (DrLLM) which contains three modules, a novel method that can efficiently extract the vast network traffic knowledge contained in pre-trained LLMS via progressive Role Reasoning pipeline by prompting. With our prompting strategy, by aligning structed network streaming data into text space to preserve the full semantics, we can embed global information and local information in prompt template to enhance the classifiction capability. We evaluated the performance of DrLLM with the public dataset CICD-DoS2019 [11], and we also conducted ablation experiments on zero-shot scenarios to validate the functionality of DrLLM's core modules.\nWe present the following main research contributions:\n\u2022 We propose a progressive DDoS traffic detection framework based on LLMs which is called DrLLM, which can efficiently classify network flow data and improve the interpretability of the classification basis.\n\u2022 We innovatively use Knowledge Embedding to embed the global information of the data into prompting template, and conduct ablation experiments to demonstrate its effectiveness.\n\u2022 We carefully crafted multiple prompting templates and Constrain-of-Deviation (CoD) and Chain-of-Thought (CoT) has been used in Token Embedding module to embed the local information and enhance the classification performance of LLMs."}, {"title": "II. BACKGROUND AND RELATED WORKS", "content": "1) Cyber IDS and Method: For DDoS traffic detection and classification tasks, existing IDSs are usually based on neural network architectures and the final results reached state-of-the-art (SOTA). For the problem of imbalanced data categories in the data set, most methods use upsampling or downsampling. Yisroel Mirsky et al. [12] presented Kitsune based on autoencoders to detect abnormal traffic data. Lucid [13] was a lightweight deep learning solution based on convolutional neural network (CNN) in recource-constrained environments. IDS-INT [14] using transformer-based transfer learning for imbalanced network traffic and the Synthetic Minority Oversampling Technique (SMOTE) is implemented to balance abnormal traffic and detect minority attacks. In practical scenarios, they are mostly deployed on the data plane or control plane of a programmable switch [15], [16] to handle large-scale hybrid and dynamic traffic attacks, and differentiate between normal and abnormal patterns.\n2) LLMs Enhanced Cybersecurity: Large Language Models (LLMs) can excel across various domains, including Neural Language Processing (NLP) and Computer Vision (CV) [3], [4], and recent research in time series forecasting [17], [18], information mining [19], [20] has demonstrated the effectiveness of pre-trained models that can be fine-tuned for various multimodality tasks [21]. In addition, some methods have been proposed and applied to optimize LLMs [8], [22]. Current research demonstrates the potential of leveraging LLMs in network security, it is not only used to detect software vulnerabilities [23], but also to detect DDoS traffic [24] and generate mitigation strategies [25] to safeguard against evolving cyber threats [26]."}, {"title": "III. OVERVIEW AND DESIGN", "content": "DrLLM has two primary objectives: 1. Preserve the same semantic information in tabular data and text data, and establish a new paradigm to align tabular data to text modality. 2. Through specific feature engineering, relying on LLMs to mine network flow data, build progressive reasoning pipeline. In order to achieve these two goals, we designed three main modules for DrLLM: Knowledge Embedding, Token Embedding, and Role Reasoning. The overview of DrLLM architecture is shown in Fig 1.\nThe Knowledge Embedding module is primarily tasked with the extraction of the global information of the dataset and their subsequent embedding into the Knowledge Prompt. The objective is to augment the LLMs' expert knowledge, mitigate output hallucinations, and enhance classification accuracy. The Token Embedding module is primarily tasked with encoding network flow data, aligning tabular data to the text modality, and leveraging multiple technologies to enhance accuracy. The Role Reasoning module is responsible for integrating the aforementioned two modules, constructing the reasoning pipeline, and obtaining classification results through LLMs' output. In general, our objective is to facilitate the analysis of network traffic data by LLMs through the construction of associations between global prior knowledge and local information, thereby enabling the accurate classification of data."}, {"title": "A. Knowledge Embedding", "content": "We assign expert assumptions at the beginning of Knowledge Prompt to converge the reasoning ability of large models to the network field and clarify specific network traffic flow classification tasks. In the zero-shot scenario, for LLMs, the representation of a single data point alone may lack prior information for judgment, because this ignores the global data feature distribution of the dataset. After the data preprocessing, we calculate the 5-tuple characteristics $G_m$ (maximum, minimum, median, mean and variance) for each column in dataset as the global information. This simple and effective method can serve as prior knowledge for LLMs and inform the global data distribution of the dataset in advance. To reduce the output length in this module and increase the efficiency of reasoning, we constrain its output at the end position of the prompt to reduce the output content of this step.\nThe detailed process of Knowledge Embedding is as follows: Assume that for the dataset $D_{nxm}(X) = [X_1, X_2, ..., X_n]^T$, where $X_n = (x_1,x_2,...,x_m)$ and features are $Features = (F_1, F_2,, ... F_m)$, for every column $X_m$, to calculate the maximum a, minimum b, median c, mean d and variance v, and finally get $Global_m = [G_1, G_2, ..., G_m]$, where $G_j = (a_j, b_j, c_j, d_j, v_j){j=1,2,...,m}$. Then construct the string:\n$K(G) = Concat(Global_m \\oplus S)$\nwhere $Concat$ means converting the elements in the vector into strings and concatenating them with $S = (\u201cMax\u201d, \u201cMin\u201d, \u201cMedian\u201d, \u201cMean\u201d, \u201cVariance\u201d)$. Finally we embed $K$ into Knowledge Prompt (KP)."}, {"title": "B. Token Embedding", "content": "In order to enable LLMs such as ChatGPT to understand network flow data, we designed a module called Token Embedding, which uses text to represent the specified information flow. We choose LLMs as our inference backbone, and we will introduce the design of the Token Embedding module below and describe in detail how Constrain-of-Deviation (CoD) and Zero-shot Chain-of-Thought(CoT) in Prompt Engineering improve and enhance the information extraction and classification accuracy of LLMs.\n1) Constrain-of-Deviation (CoD): LLMs with decoder-only architecture are very suitable for generative tasks. They can flexibly generate text and code information, but their current structured content (such as XML or JSON) output capabilities are still weak [27]. When LLMs are integrated into our inference workflows, we need to contrain the outputs to follow specific standards. For the binary classification task of network traffic flow, in order to ensure consistency and predictability of output and reduce the hallucination, we created CoD Prompt to constrain the model to output according to instructions. This simple but very effective method allows us to use regular expressions to extract classification results from the output of LLMs.\n2) Zero-shot Chain-of-Thought(CoT): Zero-shot-CoT [28]is a zero-shot template-based prompting for chain of thought reasoning. Different from few-shot prompting with examples, it can enlighten the LLMs to make progressive thinking and perform complex reasoning for each instruction in a simple but effective pattern. We use CoT to guide the LLMs to progressively analyze the various characteristic values of network flow data and help improve calculation accuracy.\n3) Token Prompt: In the Token Prompt (TP), the specific network traffic task representation is initially indicated and the LLMs are directed to provide a probabilistic judgment based on each piece of data. We then construct Token Prompt based on CoD and Zero-shot-CoT, and use it as the benchmark input of the Token Embedding module. For tabular data of network flows, we treated as a new data modality and embed it into prompt to align it to the text modality, and then feed it into LLMs for reasoning. The specific process is as follows: Given a dataset $D_{nxm}(X) = [X_1, X_2, ..., X_n]^T$, which owns $Feature_m = [F_1, F_2, ..., F_m]$, for every $X_n = [X_1, X_2, ..., X_m]$, we construct the text string $TP_1(F_j, X_i) = Concat(F_j: X_i){j=1,2,...,m,i=1,2,...,n}$ for each piece of data, and then embed $TP_1$ into \u03a4\u03a1."}, {"title": "C. Role Reasoning", "content": "Based on Knowledge Embedding and Token Embedding, we build the progressively Role Reasoning pipeline on top of these two modules. In the first step, we embed the global information into the Knowledge Prompt KP, and feed KP as the first step input into the LLM to obtain the output $R_1$. In the second step, $R_1$ and Token Prompt $TP_1$ are sequentially fed into the LLM for reasoning to obtain the output $R_2$. Finally, we use regular expressions to obtain the classification probability $P_i$ from $R_2$ and calculate the evaluation result $E_i$ with the true value $P_i$ of the data $X_i$."}, {"title": "IV. EXPERIMENTAL EVALUATION", "content": "A. Datasets and Data Preprocessing\nThe DrLLM prototype is implemented with Python 3.11.9. We conducted extensive experiments for DrLLM on CICD-DoS2019 dataset [11]. The original dataset contains approximately 29GB of DDoS traffic data and benign traffic data, each with 88 features. According to the experimental needs, we preprocessed the data and deleted each row of data containing \"NaN\" or \"Inf\" values and we converted all DDoS traffic label to \"Attack\" and make benign traffic data unchanged.\nB. LLM Backbones\nWe evaluate DrLLM in zero-shot scenarios by comparing it with four state-of-the-art LLMs, including GPT-40-mini [29], Llama3-70b [4], Deepseek-chat-v2 [5] and Qwen2-57b-a14b-instruct [30]. We directly call their official application programming interfaces (APIs) in non-streaming mode to enable rapid response and kept the parameters as official default."}, {"title": "C. Prompts and Evaluation Metrics", "content": "As mentioned in Section III-C, we use regular expressions to extract classification probabilities from the output and constrain them using CoD. However, during the evaluation process, we found that the LLMs occasionally outputs in an incorrect format. In order to verify the effectiveness of multiple modules of DrLLM, we carefully crafted four prompt templates $P_0 = BP(BasicPrompt), P_1 = BP + CoD, P_2 = BP + CoD + CoT, P_3 = KP + BP + CoD + CoT$ for comparison. Due to space constraints, we will present the full prompt templates in the open source repository.\nIn addition, in order to evaluate the performance of DrLLM on multiple models and multiple prompts, in this paper, we adopted F1, Recall and AUC as the evaluation metrics during our experiments."}, {"title": "D. Ablation Study", "content": "In order to analyze the effectiveness of DrLLM, we conduct a series of ablation experiments with other state-of-the-art LLMs on our proposed modules. As shown is Table I."}, {"title": "E. LLMs' Output Stability", "content": "During the evaluation process, we checked the outputs of multiple models and found that the outputs of LLMs were not stable and occasionally exhibited unconstrained abnormal behaviors. We collected the abnormal outputs and defined the anomalies as follows:\n1) Confidence Bias: We denotes this problem as $L_1$. In the classification, the model gives confidence for both abnormal and normal traffic, but the sum of their probability results is not 1. This type of problem is more frequent in the case of $P_0$, but after adding CoD, the probability of such problems is greatly reduced, which also indirectly proves the effectiveness of CoD in DrLLM in constraining the output of large models.\n2) Confidence Lost: We denotes this problem as $L_2$. LLMs mean that analysis is impossible and there is a lack of confidence in the predicted probabilities based on the data.\nTable II demonstrates the probability of occurrence of the $L_1$ and $L_2$ in each scenarios. In the $P_0$, the $L_1$ of GPT-40-mini has the highest probability 0.8760, in contrast to DeepSeek-chat-v2 which has the best stability of the $L_1$ at only 0.0309. Overall, comparing to other LLMs, Deepseek-chat-v2 performs most stably in multiple scenarios, but after adding of multiple modules, the $L_1$ of GPT-40-mini drops rapidly to 0.0014 and the $L_2$ to 0.0153, which is comparable to the performance of Deepseek-chat-v2, which is a side-effect of proving the DrLLM multiple modules' effectiveness."}, {"title": "V. CONCLUSION AND FUTURE WORK", "content": "In this paper, we proposed a DDoS resistance method based with Large Language Models which is called DrLLM. We embed the global information and local information with Knowledge Embedding and Token Embedding modules. We design the Progressive Role Reasoning for classification and explore the application of DrLLM in zero-shot scenarios with extensive experiments. The ablation experiments have demonstrated the effectiveness of the individual modules in DrLLM and proved the universality of LLMs in the networking domain. In the future, we will explore the application of retrieval-augmented generation (RAG) in LLMs."}]}